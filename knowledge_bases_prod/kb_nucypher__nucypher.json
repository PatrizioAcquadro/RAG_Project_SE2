[
  "class VerifyVersionCommand(install):\n    \"\"\"Custom command to verify that the git tag matches our version\"\"\"\n    description = 'verify that the git tag matches our version'\n\n    def run(self):\n        tag = os.getenv('CIRCLE_TAG')\n        if tag.startswith('v'):\n            tag = tag[1:]\n\n        version = ABOUT['__version__']\n        if version.startswith('v'):\n            version = version[1:]\n\n        if tag != version:\n            info = \"Git tag: {0} does not match the version of this app: {1}\".format(\n                os.getenv('CIRCLE_TAG'), ABOUT['__version__']\n            )\n            sys.exit(info)",
  "class PostDevelopCommand(develop):\n    \"\"\"\n    Post-installation for development mode.\n    Execute manually with python setup.py develop or automatically included with\n    `pip install -e . -r dev-requirements.txt`.\n    \"\"\"\n    def run(self):\n        \"\"\"development setup scripts (pre-requirements)\"\"\"\n        develop.run(self)\n        subprocess.call(f\"scripts/installation/install_solc.py\")",
  "def read_requirements(path):\n    with open(BASE_DIR / path) as f:\n        _pipenv_flags, *lines = f.read().split('\\n')\n\n    # TODO remove when will be no more git dependencies in requirements.txt\n    # Transforms VCS requirements to PEP 508\n    requirements = []\n    for line in lines:\n        if line.startswith('-e git:') or line.startswith('-e git+') or \\\n                line.startswith('git:') or line.startswith('git+'):\n            # parse out egg=... fragment from VCS URL\n            parsed = urlparse(line)\n            egg_name = parsed.fragment.partition(\"egg=\")[-1]\n            without_fragment = parsed._replace(fragment=\"\").geturl()\n            requirements.append(f\"{egg_name} @ {without_fragment}\")\n        else:\n            requirements.append(line)\n\n    return requirements",
  "def run(self):\n        tag = os.getenv('CIRCLE_TAG')\n        if tag.startswith('v'):\n            tag = tag[1:]\n\n        version = ABOUT['__version__']\n        if version.startswith('v'):\n            version = version[1:]\n\n        if tag != version:\n            info = \"Git tag: {0} does not match the version of this app: {1}\".format(\n                os.getenv('CIRCLE_TAG'), ABOUT['__version__']\n            )\n            sys.exit(info)",
  "def run(self):\n        \"\"\"development setup scripts (pre-requirements)\"\"\"\n        develop.run(self)\n        subprocess.call(f\"scripts/installation/install_solc.py\")",
  "class DevelopmentInstallationRequired(RuntimeError):\n\n    MESSAGE = '''\n    A development installation of nucypher is required to import {importable_name}. \n    Please follow the installation instructions published at:\n    https://docs.nucypher.com/en/latest/installation.html\n    '''\n\n    def __init__(self, importable_name: str, *args, **kwargs):\n        msg = self.MESSAGE.format(importable_name=importable_name)\n        super().__init__(msg, *args, **kwargs)",
  "def __init__(self, importable_name: str, *args, **kwargs):\n        msg = self.MESSAGE.format(importable_name=importable_name)\n        super().__init__(msg, *args, **kwargs)",
  "class StakingProviderInfo(NamedTuple):\n    operator: ChecksumAddress\n    operator_confirmed: bool\n    operator_start_timestamp: int",
  "class PolicyInfo(NamedTuple):\n    disabled: bool\n    sponsor: ChecksumAddress\n    owner: ChecksumAddress\n    fee_rate: Wei\n    start_timestamp: int\n    end_timestamp: int",
  "class ArrangementInfo(NamedTuple):\n    node: ChecksumAddress\n    downtime_index: int\n    last_refunded_period: int",
  "class OperatorBondedTracker(SimpleTask):\n    INTERVAL = 60 * 60  # 1 hour\n\n    class OperatorNoLongerBonded(RuntimeError):\n        \"\"\"Raised when a running node is no longer associated with a staking provider.\"\"\"\n\n    def __init__(self, ursula):\n        self._ursula = ursula\n        super().__init__()\n\n    def run(self) -> None:\n        application_agent = ContractAgency.get_agent(PREApplicationAgent,\n                                                     registry=self._ursula.registry,\n                                                     eth_provider_uri=self._ursula.eth_provider_uri)\n        staking_provider_address = application_agent.get_staking_provider_from_operator(\n            operator_address=self._ursula.operator_address)\n        if staking_provider_address == NULL_ADDRESS:\n            # forcibly shut down ursula\n            self._shutdown_ursula(halt_reactor=True)\n\n    def _shutdown_ursula(self, halt_reactor=False):\n        emitter = StdoutEmitter()\n        emitter.message(f'x [Operator {self._ursula.operator_address} is no longer bonded to any '\n                        f'staking provider] - Commencing auto-shutdown sequence...', color=\"red\")\n        try:\n            raise self.OperatorNoLongerBonded()\n        finally:\n            self._ursula.stop(halt_reactor=halt_reactor)\n\n    def handle_errors(self, failure: Failure) -> None:\n        cleaned_traceback = self.clean_traceback(failure)\n        self.log.warn(f\"Unhandled error during operator bonded check: {cleaned_traceback}\")\n        if failure.check([self.OperatorNoLongerBonded]):\n            # this type of exception we want to propagate because we will shut down\n            failure.raiseException()",
  "class AvailabilityTracker:\n\n    FAST_INTERVAL = 15    # Seconds\n    SLOW_INTERVAL = 60 * 2\n    SEEDING_DURATION = 60\n    MAXIMUM_ALONE_TIME = 120\n\n    MAXIMUM_SCORE = 10.0  # Score\n    SAMPLE_SIZE = 1       # Ursulas\n    SENSITIVITY = 0.5     # Threshold\n    CHARGE_RATE = 0.9     # Measurement Multiplier\n\n    class Unreachable(RuntimeError):\n        pass\n\n    class Solitary(Unreachable):\n        message = \"Cannot connect to any teacher nodes.\"\n\n    class Lonely(Unreachable):\n        message = \"Cannot connect to enough teacher nodes.\"\n\n    def __init__(self, ursula, enforce_loneliness: bool = True):\n\n        self.log = Logger(self.__class__.__name__)\n        self._ursula = ursula\n        self.enforce_loneliness = enforce_loneliness\n\n        self.__excuses = dict()  # List of failure reasons\n        self.__score = 10\n        # 10 == Perfect Score\n        self.warnings = {\n            9: self.mild_warning,\n            7: self.medium_warning,\n            2: self.severe_warning,\n            1: self.shutdown_everything  # 0 is unobtainable\n        }\n\n        self._start_time = None\n        self.__active_measurement = False\n        self.__task = LoopingCall(self.maintain)\n        self.responders = set()\n\n    @property\n    def excuses(self):\n        return self.__excuses\n\n    def mild_warning(self) -> None:\n        self.log.info(f'[UNREACHABLE NOTICE (SCORE {self.score})] This node was recently reported as unreachable.')\n\n    def medium_warning(self) -> None:\n        self.log.warn(f'[UNREACHABLE CAUTION (SCORE {self.score})] This node is reporting as unreachable.'\n                      f'Please check your network and firewall configuration.')\n\n    def severe_warning(self) -> None:\n        self.log.warn(f'[UNREACHABLE WARNING (SCORE {self.score})] '\n                      f'Please check your network and firewall configuration.'\n                      f'Auto-shutdown will commence soon if the services do not become available.')\n\n    def shutdown_everything(self, reason=None, halt_reactor=False):\n        self.log.warn(f'[NODE IS UNREACHABLE (SCORE {self.score})] Commencing auto-shutdown sequence...')\n        self._ursula.stop(halt_reactor=False)\n        try:\n            if reason:\n                raise reason(reason.message)\n            raise self.Unreachable(f'{self._ursula} is unreachable (scored {self.score}).')\n        finally:\n            if halt_reactor:\n                self._halt_reactor()\n\n    @staticmethod\n    def _halt_reactor() -> None:\n        if reactor.running:\n            reactor.stop()\n\n    def handle_measurement_errors(self, crash_on_error: bool = False, *args, **kwargs) -> None:\n\n        if args:\n            failure = args[0]\n            cleaned_traceback = failure.getTraceback().replace('{', '').replace('}', '')  # FIXME: Amazing.\n            self.log.warn(\"Unhandled error during availability check: {}\".format(cleaned_traceback))\n            if crash_on_error:\n                failure.raiseException()\n        else:\n            # Restart on failure\n            if not self.running:\n                self.log.debug(f\"Availability check crashed, restarting...\")\n                self.start(now=True)\n\n    def status(self) -> bool:\n        \"\"\"Returns current indication of availability\"\"\"\n        result = self.score > (self.SENSITIVITY * self.MAXIMUM_SCORE)\n        if not result:\n            for time, reason in self.__excuses.items():\n                self.log.info(f'[{time}] - {reason[\"error\"]}')\n        return result\n\n    @property\n    def running(self) -> bool:\n        return self.__task.running\n\n    def start(self, now: bool = False):\n        if not self.running:\n            self._start_time = maya.now()\n            d = self.__task.start(interval=self.FAST_INTERVAL, now=now)\n            d.addErrback(self.handle_measurement_errors)\n\n    def stop(self) -> None:\n        if self.running:\n            self.__task.stop()\n\n    def maintain(self) -> None:\n        known_nodes_is_smaller_than_sample_size = len(self._ursula.known_nodes) < self.SAMPLE_SIZE\n\n        # If there are no known nodes or too few known nodes, skip this round...\n        # ... but not for longer than the maximum allotted alone time\n        if known_nodes_is_smaller_than_sample_size:\n            if not self._ursula.lonely and self.enforce_loneliness:\n                now = maya.now().epoch\n                delta = now - self._start_time.epoch\n                if delta >= self.MAXIMUM_ALONE_TIME:\n                    self.severe_warning()\n                    reason = self.Solitary if not self._ursula.known_nodes else self.Lonely\n                    self.shutdown_everything(reason=reason)\n            return\n\n        if self.__task.interval == self.FAST_INTERVAL:\n            now = maya.now().epoch\n            delta = now - self._start_time.epoch\n            if delta >= self.SEEDING_DURATION:\n                # Slow down\n                self.__task.interval = self.SLOW_INTERVAL\n                return\n\n        if self.__active_measurement:\n            self.log.debug(f\"Availability check already in progress - skipping this round (Score: {self.score}). \")\n            return  # Abort\n        else:\n            self.log.debug(f\"Continuing to measure availability (Score: {self.score}).\")\n            self.__active_measurement = True\n\n        try:\n            self.measure_sample()\n        finally:\n            self.__active_measurement = False\n\n        delta = maya.now() - self._start_time\n        self.log.info(f\"Current availability score is {self.score} measured since {delta}\")\n        self.issue_warnings()\n\n    def issue_warnings(self, cascade: bool = True) -> None:\n        warnings = sorted(self.warnings.items(), key=lambda t: t[0])\n        for threshold, action in warnings:\n            if self.score <= threshold:\n                action()\n                if not cascade:\n                    # Exit after the first active warning is issued\n                    return\n\n    def sample(self, quantity: int) -> list:\n        population = tuple(self._ursula.known_nodes.values())\n        ursulas = random.sample(population=population, k=quantity)\n        return ursulas\n\n    @property\n    def score(self) -> float:\n        return self.__score\n\n    def record(self, result: bool = None, reason: dict = None) -> None:\n        \"\"\"Score the result and cache it.\"\"\"\n        if (not result) and reason:\n            self.__excuses[maya.now().epoch] = reason\n        if result is None:\n            return  # Actually nevermind, dont score this one...\n        score = int(result) + self.CHARGE_RATE * self.__score\n        if score >= self.MAXIMUM_SCORE:\n            self.__score = self.MAXIMUM_SCORE\n        else:\n            self.__score = score\n        self.log.debug(f\"Recorded new uptime score ({self.score})\")\n\n    def measure_sample(self, ursulas: list = None) -> None:\n        \"\"\"\n        Measure self-availability from a sample of Ursulas or automatically from known nodes.\n        Handle the possibility of unreachable or invalid remote nodes in the sample.\n        \"\"\"\n\n        # TODO: Relocate?\n        Unreachable = (*NodeSeemsToBeDown,\n                       self._ursula.NotStaking,\n                       self._ursula.network_middleware.UnexpectedResponse)\n\n        if not ursulas:\n            ursulas = self.sample(quantity=self.SAMPLE_SIZE)\n\n        for ursula_or_sprout in ursulas:\n            try:\n                self.measure(ursula_or_sprout=ursula_or_sprout)\n            except self._ursula.network_middleware.NotFound:\n                # Ignore this measurement and move on because the remote node is not compatible.\n                self.record(None, reason={\"error\": \"Remote node did not support 'ping' endpoint.\"})\n            except Unreachable as e:\n                # This node is either not an Ursula, not available, does not support uptime checks, or is not staking...\n                # ...do nothing and move on without changing the score.\n                self.log.debug(f'{ursula_or_sprout} responded to uptime check with {e.__class__.__name__}')\n                continue\n\n    def measure(self, ursula_or_sprout: Union['Ursula', NodeSprout]) -> None:\n        \"\"\"Measure self-availability from a single remote node that participates uptime checks.\"\"\"\n        try:\n            response = self._ursula.network_middleware.check_availability(initiator=self._ursula, responder=ursula_or_sprout)\n        except RestMiddleware.BadRequest as e:\n            self.responders.add(ursula_or_sprout.checksum_address)\n            self.record(False, reason=e.reason)\n        else:\n            # Record response\n            self.responders.add(ursula_or_sprout.checksum_address)\n            if response.status_code == 200:\n                self.record(True)\n            elif response.status_code == 400:\n                self.record(False, reason={'failed': f\"{ursula_or_sprout.checksum_address} reported unavailability.\"})\n            else:\n                self.record(None, reason={\"error\": f\"{ursula_or_sprout.checksum_address} returned {response.status_code} from 'ping' endpoint.\"})",
  "class OperatorNoLongerBonded(RuntimeError):\n        \"\"\"Raised when a running node is no longer associated with a staking provider.\"\"\"",
  "def __init__(self, ursula):\n        self._ursula = ursula\n        super().__init__()",
  "def run(self) -> None:\n        application_agent = ContractAgency.get_agent(PREApplicationAgent,\n                                                     registry=self._ursula.registry,\n                                                     eth_provider_uri=self._ursula.eth_provider_uri)\n        staking_provider_address = application_agent.get_staking_provider_from_operator(\n            operator_address=self._ursula.operator_address)\n        if staking_provider_address == NULL_ADDRESS:\n            # forcibly shut down ursula\n            self._shutdown_ursula(halt_reactor=True)",
  "def _shutdown_ursula(self, halt_reactor=False):\n        emitter = StdoutEmitter()\n        emitter.message(f'x [Operator {self._ursula.operator_address} is no longer bonded to any '\n                        f'staking provider] - Commencing auto-shutdown sequence...', color=\"red\")\n        try:\n            raise self.OperatorNoLongerBonded()\n        finally:\n            self._ursula.stop(halt_reactor=halt_reactor)",
  "def handle_errors(self, failure: Failure) -> None:\n        cleaned_traceback = self.clean_traceback(failure)\n        self.log.warn(f\"Unhandled error during operator bonded check: {cleaned_traceback}\")\n        if failure.check([self.OperatorNoLongerBonded]):\n            # this type of exception we want to propagate because we will shut down\n            failure.raiseException()",
  "class Unreachable(RuntimeError):\n        pass",
  "class Solitary(Unreachable):\n        message = \"Cannot connect to any teacher nodes.\"",
  "class Lonely(Unreachable):\n        message = \"Cannot connect to enough teacher nodes.\"",
  "def __init__(self, ursula, enforce_loneliness: bool = True):\n\n        self.log = Logger(self.__class__.__name__)\n        self._ursula = ursula\n        self.enforce_loneliness = enforce_loneliness\n\n        self.__excuses = dict()  # List of failure reasons\n        self.__score = 10\n        # 10 == Perfect Score\n        self.warnings = {\n            9: self.mild_warning,\n            7: self.medium_warning,\n            2: self.severe_warning,\n            1: self.shutdown_everything  # 0 is unobtainable\n        }\n\n        self._start_time = None\n        self.__active_measurement = False\n        self.__task = LoopingCall(self.maintain)\n        self.responders = set()",
  "def excuses(self):\n        return self.__excuses",
  "def mild_warning(self) -> None:\n        self.log.info(f'[UNREACHABLE NOTICE (SCORE {self.score})] This node was recently reported as unreachable.')",
  "def medium_warning(self) -> None:\n        self.log.warn(f'[UNREACHABLE CAUTION (SCORE {self.score})] This node is reporting as unreachable.'\n                      f'Please check your network and firewall configuration.')",
  "def severe_warning(self) -> None:\n        self.log.warn(f'[UNREACHABLE WARNING (SCORE {self.score})] '\n                      f'Please check your network and firewall configuration.'\n                      f'Auto-shutdown will commence soon if the services do not become available.')",
  "def shutdown_everything(self, reason=None, halt_reactor=False):\n        self.log.warn(f'[NODE IS UNREACHABLE (SCORE {self.score})] Commencing auto-shutdown sequence...')\n        self._ursula.stop(halt_reactor=False)\n        try:\n            if reason:\n                raise reason(reason.message)\n            raise self.Unreachable(f'{self._ursula} is unreachable (scored {self.score}).')\n        finally:\n            if halt_reactor:\n                self._halt_reactor()",
  "def _halt_reactor() -> None:\n        if reactor.running:\n            reactor.stop()",
  "def handle_measurement_errors(self, crash_on_error: bool = False, *args, **kwargs) -> None:\n\n        if args:\n            failure = args[0]\n            cleaned_traceback = failure.getTraceback().replace('{', '').replace('}', '')  # FIXME: Amazing.\n            self.log.warn(\"Unhandled error during availability check: {}\".format(cleaned_traceback))\n            if crash_on_error:\n                failure.raiseException()\n        else:\n            # Restart on failure\n            if not self.running:\n                self.log.debug(f\"Availability check crashed, restarting...\")\n                self.start(now=True)",
  "def status(self) -> bool:\n        \"\"\"Returns current indication of availability\"\"\"\n        result = self.score > (self.SENSITIVITY * self.MAXIMUM_SCORE)\n        if not result:\n            for time, reason in self.__excuses.items():\n                self.log.info(f'[{time}] - {reason[\"error\"]}')\n        return result",
  "def running(self) -> bool:\n        return self.__task.running",
  "def start(self, now: bool = False):\n        if not self.running:\n            self._start_time = maya.now()\n            d = self.__task.start(interval=self.FAST_INTERVAL, now=now)\n            d.addErrback(self.handle_measurement_errors)",
  "def stop(self) -> None:\n        if self.running:\n            self.__task.stop()",
  "def maintain(self) -> None:\n        known_nodes_is_smaller_than_sample_size = len(self._ursula.known_nodes) < self.SAMPLE_SIZE\n\n        # If there are no known nodes or too few known nodes, skip this round...\n        # ... but not for longer than the maximum allotted alone time\n        if known_nodes_is_smaller_than_sample_size:\n            if not self._ursula.lonely and self.enforce_loneliness:\n                now = maya.now().epoch\n                delta = now - self._start_time.epoch\n                if delta >= self.MAXIMUM_ALONE_TIME:\n                    self.severe_warning()\n                    reason = self.Solitary if not self._ursula.known_nodes else self.Lonely\n                    self.shutdown_everything(reason=reason)\n            return\n\n        if self.__task.interval == self.FAST_INTERVAL:\n            now = maya.now().epoch\n            delta = now - self._start_time.epoch\n            if delta >= self.SEEDING_DURATION:\n                # Slow down\n                self.__task.interval = self.SLOW_INTERVAL\n                return\n\n        if self.__active_measurement:\n            self.log.debug(f\"Availability check already in progress - skipping this round (Score: {self.score}). \")\n            return  # Abort\n        else:\n            self.log.debug(f\"Continuing to measure availability (Score: {self.score}).\")\n            self.__active_measurement = True\n\n        try:\n            self.measure_sample()\n        finally:\n            self.__active_measurement = False\n\n        delta = maya.now() - self._start_time\n        self.log.info(f\"Current availability score is {self.score} measured since {delta}\")\n        self.issue_warnings()",
  "def issue_warnings(self, cascade: bool = True) -> None:\n        warnings = sorted(self.warnings.items(), key=lambda t: t[0])\n        for threshold, action in warnings:\n            if self.score <= threshold:\n                action()\n                if not cascade:\n                    # Exit after the first active warning is issued\n                    return",
  "def sample(self, quantity: int) -> list:\n        population = tuple(self._ursula.known_nodes.values())\n        ursulas = random.sample(population=population, k=quantity)\n        return ursulas",
  "def score(self) -> float:\n        return self.__score",
  "def record(self, result: bool = None, reason: dict = None) -> None:\n        \"\"\"Score the result and cache it.\"\"\"\n        if (not result) and reason:\n            self.__excuses[maya.now().epoch] = reason\n        if result is None:\n            return  # Actually nevermind, dont score this one...\n        score = int(result) + self.CHARGE_RATE * self.__score\n        if score >= self.MAXIMUM_SCORE:\n            self.__score = self.MAXIMUM_SCORE\n        else:\n            self.__score = score\n        self.log.debug(f\"Recorded new uptime score ({self.score})\")",
  "def measure_sample(self, ursulas: list = None) -> None:\n        \"\"\"\n        Measure self-availability from a sample of Ursulas or automatically from known nodes.\n        Handle the possibility of unreachable or invalid remote nodes in the sample.\n        \"\"\"\n\n        # TODO: Relocate?\n        Unreachable = (*NodeSeemsToBeDown,\n                       self._ursula.NotStaking,\n                       self._ursula.network_middleware.UnexpectedResponse)\n\n        if not ursulas:\n            ursulas = self.sample(quantity=self.SAMPLE_SIZE)\n\n        for ursula_or_sprout in ursulas:\n            try:\n                self.measure(ursula_or_sprout=ursula_or_sprout)\n            except self._ursula.network_middleware.NotFound:\n                # Ignore this measurement and move on because the remote node is not compatible.\n                self.record(None, reason={\"error\": \"Remote node did not support 'ping' endpoint.\"})\n            except Unreachable as e:\n                # This node is either not an Ursula, not available, does not support uptime checks, or is not staking...\n                # ...do nothing and move on without changing the score.\n                self.log.debug(f'{ursula_or_sprout} responded to uptime check with {e.__class__.__name__}')\n                continue",
  "def measure(self, ursula_or_sprout: Union['Ursula', NodeSprout]) -> None:\n        \"\"\"Measure self-availability from a single remote node that participates uptime checks.\"\"\"\n        try:\n            response = self._ursula.network_middleware.check_availability(initiator=self._ursula, responder=ursula_or_sprout)\n        except RestMiddleware.BadRequest as e:\n            self.responders.add(ursula_or_sprout.checksum_address)\n            self.record(False, reason=e.reason)\n        else:\n            # Record response\n            self.responders.add(ursula_or_sprout.checksum_address)\n            if response.status_code == 200:\n                self.record(True)\n            elif response.status_code == 400:\n                self.record(False, reason={'failed': f\"{ursula_or_sprout.checksum_address} reported unavailability.\"})\n            else:\n                self.record(None, reason={\"error\": f\"{ursula_or_sprout.checksum_address} returned {response.status_code} from 'ping' endpoint.\"})",
  "class NodeSprout:\n    \"\"\"\n    An abridged node class designed for optimization of instantiation of > 100 nodes simultaneously.\n    \"\"\"\n    verified_node = False\n\n    def __init__(self, metadata: NodeMetadata):\n        self._metadata = metadata\n        self._metadata_payload = metadata.payload\n\n        # cached properties\n        self._checksum_address = None\n        self._nickname = None\n        self._hash = None\n        self._repr = None\n        self._rest_interface = None\n\n        self._is_finishing = False\n        self._finishing_mutex = Queue()\n\n    def __eq__(self, other):\n        try:\n            other_stamp = other.stamp\n        except (AttributeError, NoSigningPower):\n            return False\n        return bytes(self.stamp) == bytes(other_stamp)\n\n    def __hash__(self):\n        if not self._hash:\n            self._hash = int.from_bytes(bytes(self.stamp), byteorder=\"big\")\n        return self._hash\n\n    def __repr__(self):\n        if not self._repr:\n            self._repr = f\"({self.__class__.__name__})\u21c0{self.nickname}\u21bd ({self.checksum_address})\"\n        return self._repr\n\n    @property\n    def checksum_address(self):\n        if not self._checksum_address:\n            self._checksum_address = to_checksum_address(bytes(self.canonical_address))\n        return self._checksum_address\n\n    @property\n    def canonical_address(self):\n        return self._metadata_payload.staking_provider_address\n\n    @property\n    def nickname(self):\n        if not self._nickname:\n            self._nickname = Nickname.from_seed(self.checksum_address)\n        return self._nickname\n\n    @property\n    def rest_interface(self):\n        if not self._rest_interface:\n            self._rest_interface = InterfaceInfo(self._metadata_payload.host, self._metadata_payload.port)\n        return self._rest_interface\n\n    def rest_url(self):\n        return self.rest_interface.uri\n\n    def metadata(self):\n        return self._metadata\n\n    @property\n    def verifying_key(self):\n        return self._metadata_payload.verifying_key\n\n    @property\n    def encrypting_key(self):\n        return self._metadata_payload.encrypting_key\n\n    @property\n    def operator_signature_from_metadata(self):\n        return self._metadata_payload.operator_signature or NOT_SIGNED\n\n    @property\n    def timestamp(self):\n        return maya.MayaDT(self._metadata_payload.timestamp_epoch)\n\n    @property\n    def stamp(self) -> SignatureStamp:\n        return SignatureStamp(self._metadata_payload.verifying_key)\n\n    @property\n    def domain(self) -> str:\n        return self._metadata_payload.domain\n\n    def finish(self):\n        from nucypher.characters.lawful import Ursula\n\n        crypto_power = CryptoPower()\n        crypto_power.consume_power_up(SigningPower(public_key=self._metadata_payload.verifying_key))\n        crypto_power.consume_power_up(DecryptingPower(public_key=self._metadata_payload.encrypting_key))\n\n        return Ursula(is_me=False,\n                      crypto_power=crypto_power,\n                      rest_host=self._metadata_payload.host,\n                      rest_port=self._metadata_payload.port,\n                      checksum_address=self.checksum_address,\n                      domain=self._metadata_payload.domain,\n                      timestamp=self.timestamp,\n                      operator_signature_from_metadata=self.operator_signature_from_metadata,\n                      certificate=load_der_x509_certificate(self._metadata_payload.certificate_der, backend=default_backend()),\n                      metadata=self._metadata\n                      )\n\n    def mature(self):\n        if self._is_finishing:\n            return self._finishing_mutex.get()\n\n        self._is_finishing = True  # Prevent reentrance.\n        _finishing_mutex = self._finishing_mutex\n\n        mature_node = self.finish()\n        self.__class__ = mature_node.__class__\n        self.__dict__ = mature_node.__dict__\n\n        # As long as we're doing egregious workarounds, here's another one.  # TODO: 1481\n        filepath = mature_node._cert_store_function(certificate=mature_node.certificate, port=mature_node.rest_interface.port)\n        mature_node.certificate_filepath = filepath\n\n        _finishing_mutex.put(self)\n        return self",
  "class DiscoveryCanceller:\n\n    def __init__(self):\n        self.stop_now = False\n\n    def __call__(self, learning_deferred):\n        if self.stop_now:\n            assert False\n        self.stop_now = True",
  "class Learner:\n    \"\"\"\n    Any participant in the \"learning loop\" - a class inheriting from\n    this one has the ability, synchronously or asynchronously,\n    to learn about nodes in the network, verify some essential\n    details about them, and store information about them for later use.\n    \"\"\"\n\n    _SHORT_LEARNING_DELAY = 5\n    _LONG_LEARNING_DELAY = 90\n    LEARNING_TIMEOUT = 10\n    _ROUNDS_WITHOUT_NODES_AFTER_WHICH_TO_SLOW_DOWN = 10\n\n    # For Keeps\n    __DEFAULT_NODE_STORAGE = ForgetfulNodeStorage\n    __DEFAULT_MIDDLEWARE_CLASS = RestMiddleware\n\n    _crashed = False  # moved from Character - why was this in Character and not Learner before\n\n    tracker_class = FleetSensor\n\n    invalid_metadata_message = \"{} has invalid metadata.  The node's stake may have ended, or it is transitioning to a new interface. Ignoring.\"\n\n    _DEBUG_MODE = False\n\n    class NotEnoughNodes(RuntimeError):\n        pass\n\n    class NotEnoughTeachers(NotEnoughNodes):\n        crash_right_now = True\n\n    class UnresponsiveTeacher(ConnectionError):\n        pass\n\n    class NotATeacher(ValueError):\n        \"\"\"\n        Raised when a character cannot be properly utilized because\n        it does not have the proper attributes for learning or verification.\n        \"\"\"\n\n    def __init__(self,\n                 domain: str,\n                 node_class: object = None,\n                 network_middleware: RestMiddleware = None,\n                 start_learning_now: bool = False,\n                 learn_on_same_thread: bool = False,\n                 known_nodes: tuple = None,\n                 seed_nodes: Tuple[tuple] = None,\n                 node_storage=None,\n                 save_metadata: bool = False,\n                 abort_on_learning_error: bool = False,\n                 lonely: bool = False,\n                 verify_node_bonding: bool = True,\n                 include_self_in_the_state: bool = False,\n                 ) -> None:\n\n        self.log = Logger(\"learning-loop\")  # type: Logger\n\n        self.learning_deferred = Deferred()\n        self.domain = domain\n        if not self.federated_only:\n            default_middleware = self.__DEFAULT_MIDDLEWARE_CLASS(registry=self.registry)\n        else:\n            default_middleware = self.__DEFAULT_MIDDLEWARE_CLASS()\n        self.network_middleware = network_middleware or default_middleware\n        self.save_metadata = save_metadata\n        self.start_learning_now = start_learning_now\n        self.learn_on_same_thread = learn_on_same_thread\n\n        self._abort_on_learning_error = abort_on_learning_error\n\n        self.__known_nodes = self.tracker_class(domain=domain, this_node=self if include_self_in_the_state else None)\n        self._verify_node_bonding = verify_node_bonding\n\n        self.lonely = lonely\n        self.done_seeding = False\n        self._learning_deferred = None\n        self._discovery_canceller = DiscoveryCanceller()\n\n        if not node_storage:\n            node_storage = self.__DEFAULT_NODE_STORAGE(federated_only=self.federated_only)\n        self.node_storage = node_storage\n        if save_metadata and node_storage is NO_STORAGE_AVAILABLE:\n            raise ValueError(\"Cannot save nodes without a configured node storage\")\n\n        from nucypher.characters.lawful import Ursula\n        self.node_class = node_class or Ursula\n        self.node_class.set_cert_storage_function(\n            node_storage.store_node_certificate)  # TODO: Fix this temporary workaround for on-disk cert storage.  #1481\n\n        known_nodes = known_nodes or tuple()\n        self.unresponsive_startup_nodes = list()  # TODO: Buckets - Attempt to use these again later  #567\n        for node in known_nodes:\n            try:\n                self.remember_node(node, eager=True, record_fleet_state=False)\n            except self.UnresponsiveTeacher:\n                self.unresponsive_startup_nodes.append(node)\n\n        # This node has not initialized its metadata yet.\n        self.known_nodes.record_fleet_state(skip_this_node=True)\n\n        self.teacher_nodes = deque()\n        self._current_teacher_node = None  # type: Union[Teacher, None]\n        self._learning_task = task.LoopingCall(self.keep_learning_about_nodes)\n\n        if self._DEBUG_MODE:\n            # Very slow, but provides useful info when trying to track down a stray Character.\n            # Seems mostly useful for Bob or federated Ursulas, but perhaps useful for other Characters as well.\n\n            import inspect\n            import os\n            frames = inspect.stack(3)\n            self._learning_task = task.LoopingCall(self.keep_learning_about_nodes, learner=self, frames=frames)\n            self._init_frames = frames\n            from tests.conftest import global_mutable_where_everybody\n            test_name = os.environ[\"PYTEST_CURRENT_TEST\"]\n            global_mutable_where_everybody[test_name].append(self)\n            self._FOR_TEST = test_name\n            ########################\n\n        self._learning_round = 0  # type: int\n        self._rounds_without_new_nodes = 0  # type: int\n        self._seed_nodes = seed_nodes or []\n\n        if self.start_learning_now and not self.lonely:\n            self.start_learning_loop(now=self.learn_on_same_thread)\n\n    @property\n    def known_nodes(self):\n        return self.__known_nodes\n\n    def load_seednodes(self, read_storage: bool = True, record_fleet_state=False):\n        \"\"\"\n        Engage known nodes from storages and pre-fetch hardcoded seednode certificates for node learning.\n\n        TODO: Dehydrate this with nucypher.utilities.seednodes.load_seednodes\n        \"\"\"\n        if self.done_seeding:\n            raise RuntimeError(\"Already finished seeding.  Why try again?  Is this a thread safety problem?\")\n\n        discovered = []\n\n        if self.domain:\n            canonical_sage_uris = TEACHER_NODES.get(self.domain, ())\n\n            for uri in canonical_sage_uris:\n                try:\n                    maybe_sage_node = self.node_class.from_teacher_uri(teacher_uri=uri,\n                                                                       min_stake=0,  # TODO: Where to get this?\n                                                                       federated_only=self.federated_only,\n                                                                       network_middleware=self.network_middleware,\n                                                                       registry=self.registry)\n                except Exception as e:\n                    # TODO: log traceback here?\n                    # TODO: distinguish between versioning errors and other errors?\n                    self.log.warn(f\"Failed to instantiate a node at {uri}: {e}\")\n                else:\n                    new_node = self.remember_node(maybe_sage_node, record_fleet_state=False)\n                    discovered.append(new_node)\n\n        for seednode_metadata in self._seed_nodes:\n\n            node_tag = \"{}|{}:{}\".format(seednode_metadata.checksum_address,\n                                         seednode_metadata.rest_host,\n                                         seednode_metadata.rest_port)\n\n            self.log.debug(f\"Seeding from: {node_tag}\")\n\n            try:\n                seed_node = self.node_class.from_seednode_metadata(seednode_metadata=seednode_metadata,\n                                                                   network_middleware=self.network_middleware,\n                                                                   )\n            except Exception as e:\n                # TODO: log traceback here?\n                # TODO: distinguish between versioning errors and other errors?\n                self.log.warn(f\"Failed to instantiate a node {node_tag}: {e}\")\n            else:\n                new_node = self.remember_node(seed_node, record_fleet_state=False)\n                discovered.append(new_node)\n\n        self.log.info(\"Finished learning about all seednodes.\")\n\n        self.done_seeding = True\n\n        nodes_restored_from_storage = self.read_nodes_from_storage() if read_storage else []\n        discovered.extend(nodes_restored_from_storage)\n\n        if discovered and record_fleet_state:\n            self.known_nodes.record_fleet_state()\n\n        return discovered\n\n    def read_nodes_from_storage(self) -> List:\n        stored_nodes = self.node_storage.all(federated_only=self.federated_only)  # TODO: #466\n\n        restored_from_disk = []\n        invalid_nodes = defaultdict(list)\n        for node in stored_nodes:\n            if node.domain != self.domain:\n                invalid_nodes[node.domain].append(node)\n                continue\n            restored_node = self.remember_node(node, record_fleet_state=False)  # TODO: Validity status 1866\n            restored_from_disk.append(restored_node)\n\n        if invalid_nodes:\n            self.log.warn(f\"We're learning about domain '{self.domain}', but found nodes from other domains; \"\n                          f\"let's ignore them. These domains and nodes are: {dict(invalid_nodes)}\")\n\n        return restored_from_disk\n\n    def remember_node(self,\n                      node,\n                      force_verification_recheck=False,\n                      record_fleet_state=True,\n                      eager: bool = False):\n\n        # UNPARSED\n        # PARSED\n        # METADATA_CHECKED\n        # VERIFIED_CERT\n        # VERIFIED_STAKE\n\n        if node == self:  # No need to remember self.\n            return False\n\n        # First, determine if this is an outdated representation of an already known node.\n        # TODO: #1032 or, since it's closed and will never re-opened, i am the :=\n        with suppress(KeyError):\n            already_known_node = self.known_nodes[node.checksum_address]\n            if not node.timestamp > already_known_node.timestamp:\n                # This node is already known.  We can safely return.\n                return False\n\n        self.known_nodes.record_node(node)  # FIXME - dont always remember nodes, bucket them.\n\n        if self.save_metadata:\n            self.node_storage.store_node_metadata(node=node)\n\n        if eager:\n            node.mature()\n            stranger_certificate = node.certificate\n\n            # Store node's certificate - It has been seen.\n            certificate_filepath = self.node_storage.store_node_certificate(certificate=stranger_certificate, port=node.rest_interface.port)\n\n            # In some cases (seed nodes or other temp stored certs),\n            # this will update the filepath from the temp location to this one.\n            node.certificate_filepath = certificate_filepath\n\n            # Use this to control whether or not this node performs\n            # blockchain calls to determine if stranger nodes are bonded.\n            # Note: self.registry is composed on blockchainy character subclasses.\n            registry = self.registry if self._verify_node_bonding else None  # TODO: Federated mode?\n\n            try:\n                node.verify_node(force=force_verification_recheck,\n                                 network_middleware_client=self.network_middleware.client,\n                                 registry=registry)\n            except SSLError:\n                # TODO: Bucket this node as having bad TLS info - maybe it's an update that hasn't fully propagated?  567\n                return False\n\n            except RestMiddleware.Unreachable:\n                self.log.info(\"No Response while trying to verify node {}|{}\".format(node.rest_interface, node))\n                # TODO: Bucket this node as \"ghost\" or something: somebody else knows about it, but we can't get to it.  567\n                return False\n\n            except node.NotStaking:\n                # TODO: Bucket this node as inactive, and potentially safe to forget.  567\n                self.log.info(\n                    f'StakingProvider:Operator {node.checksum_address}:{node.operator_address} is not actively staking, skipping.')\n                return False\n\n            # TODO: What about InvalidNode?  (for that matter, any SuspiciousActivity)  1714, 567 too really\n\n        if record_fleet_state:\n            self.known_nodes.record_fleet_state()\n\n        return node\n\n    def start_learning_loop(self, now=False):\n        if self._learning_task.running:\n            return False\n        elif now:\n            self.log.info(\"Starting Learning Loop NOW.\")\n            self.learn_from_teacher_node()\n\n            self.learning_deferred = self._learning_task.start(interval=self._SHORT_LEARNING_DELAY)\n            self.learning_deferred.addErrback(self.handle_learning_errors)\n            return self.learning_deferred\n        else:\n            self.log.info(\"Starting Learning Loop.\")\n            learner_deferred = self._learning_task.start(interval=self._SHORT_LEARNING_DELAY, now=False)\n            learner_deferred.addErrback(self.handle_learning_errors)\n            self.learning_deferred = learner_deferred\n            return self.learning_deferred\n\n    def stop_learning_loop(self, reason=None):\n        \"\"\"\n        Only for tests at this point.  Maybe some day for graceful shutdowns.\n        \"\"\"\n        if self._learning_task.running:\n            self._learning_task.stop()\n\n        if self._learning_deferred is RELAX:\n            assert False\n\n        if self._learning_deferred is not None:\n            # self._learning_deferred.cancel()  # TODO: The problem here is that this might already be called.\n            self._discovery_canceller(self._learning_deferred)\n\n        # self.learning_deferred.cancel()  # TODO: The problem here is that there's no way to get a canceller into the LoopingCall.\n\n    def handle_learning_errors(self, failure, *args, **kwargs):\n        _exception = failure.value\n        crash_right_now = getattr(_exception, \"crash_right_now\", False)\n        if self._abort_on_learning_error or crash_right_now:\n            reactor.callFromThread(self._crash_gracefully, failure=failure)\n            self.log.critical(\"Unhandled error during node learning.  Attempting graceful crash.\")\n        else:\n            self.log.warn(f\"Unhandled error during node learning: {failure.getTraceback()}\")\n            if not self._learning_task.running:\n                self.start_learning_loop()  # TODO: Consider a single entry point for this with more elegant pause and unpause.  NRN\n\n    def _crash_gracefully(self, failure=None):\n        \"\"\"\n        A facility for crashing more gracefully in the event that an exception\n        is unhandled in a different thread, especially inside a loop like the acumen loop, Alice's publication loop, or Bob's retrieval loop..\n        \"\"\"\n\n        self._crashed = failure\n\n        # When using Learner._DEBUG_MODE in tests, it may be helpful to uncomment this to be able to introspect.\n        # from tests.conftest import global_mutable_where_everybody\n        # gmwe = global_mutable_where_everybody\n\n        failure.raiseException()\n        # TODO: We don't actually have checksum_address at this level - maybe only Characters can crash gracefully :-)  1711\n        self.log.critical(\"{} crashed with {}\".format(self.checksum_address, failure))\n        reactor.stop()\n\n    def select_teacher_nodes(self):\n        nodes_we_know_about = self.known_nodes.shuffled()\n\n        if not nodes_we_know_about:\n            raise self.NotEnoughTeachers(\"Need some nodes to start learning from.\")\n\n        self.teacher_nodes.extend(nodes_we_know_about)\n\n    def cycle_teacher_node(self):\n        if not self.teacher_nodes:\n            self.select_teacher_nodes()\n        try:\n            self._current_teacher_node = self.teacher_nodes.pop()\n        except IndexError:\n            error = \"Not enough nodes to select a good teacher, Check your network connection then node configuration\"\n            raise self.NotEnoughTeachers(error)\n        self.log.debug(\"Cycled teachers; New teacher is {}\".format(self._current_teacher_node))\n\n    def current_teacher_node(self, cycle=False):\n        if cycle:\n            self.cycle_teacher_node()\n\n        if not self._current_teacher_node:\n            self.cycle_teacher_node()\n\n        teacher = self._current_teacher_node\n\n        return teacher\n\n    def learn_about_nodes_now(self, force=False):\n        if self._learning_task.running:\n            self._learning_task.reset()\n            # self._learning_task()\n        elif not force:\n            self.log.warn(\n                \"Learning loop isn't started; can't learn about nodes now.  You can override this with force=True.\")\n        elif force:\n            # TODO: What if this has been stopped?\n            self.log.info(\"Learning loop wasn't started; forcing start now.\")\n            self._learning_task.start(self._SHORT_LEARNING_DELAY, now=True)\n\n    def keep_learning_about_nodes(self):\n        \"\"\"\n        Continually learn about new nodes.\n        \"\"\"\n\n        # TODO: Allow the user to set eagerness?  1712\n        # TODO: Also, if we do allow eager, don't even defer; block right here.\n\n        self._learning_deferred = Deferred(canceller=self._discovery_canceller)  # TODO: No longer relevant.\n\n        def _discover_or_abort(_first_result):\n            # self.log.debug(f\"{self} learning at {datetime.datetime.now()}\")   # 1712\n            result = self.learn_from_teacher_node(eager=False, canceller=self._discovery_canceller)\n            # self.log.debug(f\"{self} finished learning at {datetime.datetime.now()}\")  # 1712\n            return result\n\n        self._learning_deferred.addCallback(_discover_or_abort)\n        self._learning_deferred.addErrback(self.handle_learning_errors)\n\n        # Instead of None, we might want to pass something useful about the context.\n        # Alternately, it might be nice for learn_from_teacher_node to (some or all of the time) return a Deferred.\n        reactor.callInThread(self._learning_deferred.callback, None)\n        return self._learning_deferred\n\n    # TODO: Dehydrate these next two methods.  NRN\n\n    def block_until_number_of_known_nodes_is(self,\n                                             number_of_nodes_to_know: int,\n                                             timeout: int = 10,\n                                             learn_on_this_thread: bool = False,\n                                             eager: bool = False):\n        start = maya.now()\n        starting_round = self._learning_round\n\n        # if not learn_on_this_thread and self._learning_task.running:\n        #     # Get a head start by firing the looping call now.  If it's very fast, maybe we'll have enough nodes on the first iteration.\n        #     self._learning_task()\n\n        while True:\n            rounds_undertaken = self._learning_round - starting_round\n            if len(self.known_nodes) >= number_of_nodes_to_know:\n                if rounds_undertaken:\n                    self.log.info(\"Learned about enough nodes after {} rounds.\".format(rounds_undertaken))\n                return True\n\n            if not self._learning_task.running:\n                self.log.warn(\"Blocking to learn about nodes, but learning loop isn't running.\")\n            if learn_on_this_thread:\n                try:\n                    self.learn_from_teacher_node(eager=eager)\n                except (requests.exceptions.ReadTimeout, requests.exceptions.ConnectTimeout):\n                    # TODO: Even this \"same thread\" logic can be done off the main thread.  NRN\n                    self.log.warn(\"Teacher was unreachable.  No good way to handle this on the main thread.\")\n\n            # The rest of the fucking owl\n            round_finish = maya.now()\n            elapsed = (round_finish - start).seconds\n            if elapsed > timeout:\n                if len(self.known_nodes) >= number_of_nodes_to_know:  # Last chance!\n                    self.log.info(f\"Learned about enough nodes after {rounds_undertaken} rounds.\")\n                    return True\n                if not self._learning_task.running:\n                    raise RuntimeError(\"Learning loop is not running.  Start it with start_learning().\")\n                elif not reactor.running and not learn_on_this_thread:\n                    raise RuntimeError(\n                        f\"The reactor isn't running, but you're trying to use it for discovery.  You need to start the Reactor in order to use {self} this way.\")\n                else:\n                    raise self.NotEnoughNodes(\"After {} seconds and {} rounds, didn't find {} nodes\".format(\n                        timeout, rounds_undertaken, number_of_nodes_to_know))\n            else:\n                time.sleep(.1)\n\n    def block_until_specific_nodes_are_known(self,\n                                             addresses: Set,\n                                             timeout=LEARNING_TIMEOUT,\n                                             allow_missing=0,\n                                             learn_on_this_thread=False):\n        start = maya.now()\n        starting_round = self._learning_round\n\n        addresses = set(addresses)\n\n        while True:\n            if self._crashed:\n                return self._crashed\n            rounds_undertaken = self._learning_round - starting_round\n            if addresses.issubset(self.known_nodes.addresses()):\n                if rounds_undertaken:\n                    self.log.info(\"Learned about all nodes after {} rounds.\".format(rounds_undertaken))\n                return True\n\n            if learn_on_this_thread:\n                self.learn_from_teacher_node(eager=True)\n            elif not self._learning_task.running:\n                raise RuntimeError(\n                    \"Tried to block while discovering nodes on another thread, but the learning task isn't running.\")\n\n            if (maya.now() - start).seconds > timeout:\n\n                still_unknown = addresses.difference(self.known_nodes.addresses())\n\n                if len(still_unknown) <= allow_missing:\n                    return False\n                else:\n                    raise self.NotEnoughTeachers(\n                        \"After {} seconds and {} rounds, didn't find these {} nodes: {}\".format(\n                            timeout, rounds_undertaken, len(still_unknown), still_unknown))\n            else:\n                time.sleep(.1)\n\n    def _adjust_learning(self, node_list):\n        \"\"\"\n        Takes a list of new nodes, adjusts learning accordingly.\n\n        Currently, simply slows down learning loop when no new nodes have been discovered in a while.\n        TODO: Do other important things - scrub, bucket, etc.  567\n        \"\"\"\n        if node_list:\n            self._rounds_without_new_nodes = 0\n            self._learning_task.interval = self._SHORT_LEARNING_DELAY\n        else:\n            self._rounds_without_new_nodes += 1\n            if self._rounds_without_new_nodes > self._ROUNDS_WITHOUT_NODES_AFTER_WHICH_TO_SLOW_DOWN:\n                self.log.info(\"After {} rounds with no new nodes, it's time to slow down to {} seconds.\".format(\n                    self._ROUNDS_WITHOUT_NODES_AFTER_WHICH_TO_SLOW_DOWN,\n                    self._LONG_LEARNING_DELAY))\n                self._learning_task.interval = self._LONG_LEARNING_DELAY\n\n    def network_bootstrap(self, node_list: list) -> None:\n        for node_addr, port in node_list:\n            new_nodes = self.learn_about_nodes_now(node_addr, port)\n            self.__known_nodes.update(new_nodes)\n\n    def get_nodes_by_ids(self, node_ids):\n        for node_id in node_ids:\n            try:\n                # Scenario 1: We already know about this node.\n                return self.__known_nodes[node_id]\n            except KeyError:\n                raise NotImplementedError\n        # Scenario 2: We don't know about this node, but a nearby node does.\n        # TODO: Build a concurrent pool of lookups here.  NRN\n\n        # Scenario 3: We don't know about this node, and neither does our friend.\n\n    def write_node_metadata(self, node, serializer=bytes) -> str:\n        return self.node_storage.store_node_metadata(node=node)\n\n    def verify_from(self,\n                    stranger: 'Character',\n                    message: bytes,\n                    signature: Signature\n                    ):\n\n        if not signature.verify(verifying_pk=stranger.stamp.as_umbral_pubkey(), message=message):\n            try:\n                node_on_the_other_end = self.node_class.from_seednode_metadata(stranger.seed_node_metadata(),\n                                                                               network_middleware=self.network_middleware)\n                if node_on_the_other_end != stranger:\n                    raise self.node_class.InvalidNode(\n                        f\"Expected to connect to {stranger}, got {node_on_the_other_end} instead.\")\n                else:\n                    raise InvalidSignature(\"Signature for message isn't valid: {}\".format(signature))\n            except (TypeError, AttributeError):\n                raise InvalidSignature(f\"Unable to verify message from stranger: {stranger}\")\n\n    def learn_from_teacher_node(self, eager=False, canceller=None):\n        \"\"\"\n        Sends a request to node_url to find out about known nodes.\n\n        TODO: Does this (and related methods) belong on FleetSensor for portability?\n\n        TODO: A lot of other code can be simplified if this is converted to async def.  That's a project, though.\n        \"\"\"\n        remembered = []\n\n        if not self.done_seeding:\n            try:\n                remembered_seednodes = self.load_seednodes(record_fleet_state=True)\n            except Exception as e:\n                # Even if we aren't aborting on learning errors, we want this to crash the process pronto.\n                e.crash_right_now = True\n                raise\n            else:\n                remembered.extend(remembered_seednodes)\n\n        self._learning_round += 1\n\n        current_teacher = self.current_teacher_node()  # Will raise if there's no available teacher.\n\n        if isinstance(self, Teacher):\n            announce_nodes = [self.metadata()]\n        else:\n            announce_nodes = []\n\n        unresponsive_nodes = set()\n\n        #\n        # Request\n        #\n        if canceller and canceller.stop_now:\n            return RELAX\n\n        try:\n            response = self.network_middleware.get_nodes_via_rest(node=current_teacher,\n                                                                  announce_nodes=announce_nodes,\n                                                                  fleet_state_checksum=self.known_nodes.checksum)\n        # These except clauses apply to the current_teacher itself, not the learned-about nodes.\n        except NodeSeemsToBeDown as e:\n            unresponsive_nodes.add(current_teacher)\n            self.log.info(f\"Teacher {current_teacher.seed_node_metadata(as_teacher_uri=True)} is unreachable: {e}.\")\n            return\n        except current_teacher.InvalidNode as e:\n            # Ugh.  The teacher is invalid.  Rough.\n            # TODO: Bucket separately and report.\n            unresponsive_nodes.add(current_teacher)  # This does nothing.\n            self.known_nodes.mark_as(current_teacher.InvalidNode, current_teacher)\n            self.log.warn(f\"Teacher {str(current_teacher)} is invalid: {e}.\")\n            # TODO (#567): bucket the node as suspicious\n            return\n        except RuntimeError as e:\n            if canceller and canceller.stop_now:\n                # Race condition that seems limited to tests.\n                # TODO: Sort this out.\n                return RELAX\n            else:\n                self.log.warn(\n                    f\"Unhandled error while learning from {str(current_teacher)} \"\n                    f\"(hex={bytes(current_teacher.metadata()).hex()}):{e}.\")\n                raise\n        except Exception as e:\n            self.log.warn(\n                f\"Unhandled error while learning from {str(current_teacher)} \"\n                f\"(hex={bytes(current_teacher.metadata()).hex()}):{e}.\")  # To track down 2345 / 1698\n            raise\n        finally:\n            # Is cycling happening in the right order?\n            self.cycle_teacher_node()\n\n        if response.status_code != 200:\n            self.log.info(\"Bad response from teacher {}: {} - {}\".format(current_teacher, response, response.content))\n            return\n\n        # TODO: we really should be checking this *before* we ask it for a node list,\n        # but currently we may not know this before the REST request (which may mature the node)\n        if self.domain != current_teacher.domain:\n            self.log.debug(f\"{current_teacher} is serving '{current_teacher.domain}', \"\n                           f\"ignore since we are learning about '{self.domain}'\")\n            return  # This node is not serving our domain.\n\n        #\n        # Deserialize\n        #\n        try:\n            metadata = MetadataResponse.from_bytes(response.content)\n        except Exception as e:\n            self.log.warn(f\"Failed to deserialize MetadataResponse from Teacher {current_teacher} ({e}): {response.content}\")\n            return\n\n        try:\n            metadata_payload = metadata.verify(current_teacher.stamp.as_umbral_pubkey())\n        except Exception as e:\n            # TODO (#567): bucket the node as suspicious\n            self.log.warn(\n                f\"Failed to verify MetadataResponse from Teacher {current_teacher} ({e}): {response.content}\")\n            return\n\n        # End edge case handling.\n\n        fleet_state_updated = maya.MayaDT(metadata_payload.timestamp_epoch)\n\n        if not metadata_payload.announce_nodes:\n            # The teacher had the same fleet state\n            self.known_nodes.record_remote_fleet_state(\n                current_teacher.checksum_address,\n                self.known_nodes.checksum,\n                fleet_state_updated,\n                self.known_nodes.population)\n\n            return FLEET_STATES_MATCH\n\n        sprouts = [NodeSprout(node) for node in metadata_payload.announce_nodes]\n\n        for sprout in sprouts:\n            try:\n                node_or_false = self.remember_node(sprout,\n                                                   record_fleet_state=False,\n                                                   # Do we want both of these to be decided by `eager`?\n                                                   eager=eager)\n                if node_or_false is not False:\n                    remembered.append(node_or_false)\n\n                #\n                # Report Failure\n                #\n\n            except NodeSeemsToBeDown:\n                self.log.info(f\"Verification Failed - \"\n                              f\"Cannot establish connection to {sprout}.\")\n\n            # TODO: This whole section is weird; sprouts down have any of these things.\n            except sprout.StampNotSigned:\n                self.log.warn(f'Verification Failed - '\n                              f'{sprout} {NOT_SIGNED}.')\n\n            except sprout.NotStaking:\n                self.log.warn(f'Verification Failed - '\n                              f'{sprout} has no active stakes in the current period '\n                              f'({self.staking_agent.get_current_period()}')\n\n            except sprout.InvalidOperatorSignature:\n                self.log.warn(f'Verification Failed - '\n                              f'{sprout} has an invalid wallet signature for {sprout.operator_signature_from_metadata}')\n\n            except sprout.UnbondedOperator:\n                self.log.warn(f'Verification Failed - '\n                              f'{sprout} is not bonded to a Staker.')\n\n            # TODO: Handle invalid sprouts\n            # except sprout.Invalidsprout:\n            #     self.log.warn(sprout.invalid_metadata_message.format(sprout))\n\n            except NodeSeemsToBeDown as e:\n                message = f\"Node is unreachable: {sprout}. Full error: {e.__str__()} \"\n                self.log.warn(message)\n\n            except SuspiciousActivity:\n                message = f\"Suspicious Activity: Discovered sprout with bad signature: {sprout}.\" \\\n                          f\"Propagated by: {current_teacher}\"\n                self.log.warn(message)\n\n        ###################\n\n        learning_round_log_message = \"Learning round {}.  Teacher: {} knew about {} nodes, {} were new.\"\n        self.log.info(learning_round_log_message.format(self._learning_round,\n                                                        current_teacher,\n                                                        len(sprouts),\n                                                        len(remembered)))\n        if remembered:\n            self.known_nodes.record_fleet_state()\n\n        # Now that we updated all our nodes with the teacher's,\n        # our fleet state checksum should be the same as the teacher's checksum.\n\n        # Is cycling happening in the right order?\n        self.known_nodes.record_remote_fleet_state(\n            current_teacher.checksum_address,\n            self.known_nodes.checksum,\n            fleet_state_updated,\n            len(sprouts))\n\n        return sprouts",
  "class Teacher:\n\n    log = Logger(\"teacher\")\n    synchronous_query_timeout = 20  # How long to wait during REST endpoints for blockchain queries to resolve\n    __DEFAULT_MIN_SEED_STAKE = 0\n\n    def __init__(self,\n                 domain: str,  # TODO: Consider using a Domain type\n                 certificate: Certificate,\n                 certificate_filepath: Path,\n                 ) -> None:\n\n        self.domain = domain\n\n        #\n        # Identity\n        #\n\n        self.certificate = certificate\n        self.certificate_filepath = certificate_filepath\n\n        # Assume unverified\n        self.verified_stamp = False\n        self.verified_operator = False\n        self.verified_metadata = False\n        self.verified_node = False\n\n    class InvalidNode(SuspiciousActivity):\n        \"\"\"Raised when a node has an invalid characteristic - stamp, interface, or address.\"\"\"\n\n    class InvalidStamp(InvalidNode):\n        \"\"\"Base exception class for invalid character stamps\"\"\"\n\n    class StampNotSigned(InvalidStamp):\n        \"\"\"Raised when a node does not have a stamp signature when one is required for verification\"\"\"\n\n    class InvalidOperatorSignature(InvalidStamp):\n        \"\"\"Raised when a stamp fails signature verification or recovers an unexpected worker address\"\"\"\n\n    class NotStaking(InvalidStamp):\n        \"\"\"Raised when a node fails verification because it is not currently staking\"\"\"\n\n    class UnbondedOperator(InvalidNode):\n        \"\"\"Raised when a node fails verification because it is not bonded to a Staker\"\"\"\n\n    class WrongMode(TypeError):\n        \"\"\"Raised when a Character tries to use another Character as decentralized when the latter is federated_only.\"\"\"\n\n    @classmethod\n    def set_cert_storage_function(cls, node_storage_function: Callable):\n        cls._cert_store_function = node_storage_function\n\n    def mature(self, *args, **kwargs):\n        \"\"\"This is the most mature form, so we do nothing.\"\"\"\n        return self\n\n    @classmethod\n    def set_federated_mode(cls, federated_only: bool):\n        cls._federated_only_instances = federated_only\n\n    #\n    # Known Nodes\n    #\n\n    def seed_node_metadata(self, as_teacher_uri=False) -> SeednodeMetadata:\n        if as_teacher_uri:\n            teacher_uri = f'{self.checksum_address}@{self.rest_server.rest_interface.host}:{self.rest_server.rest_interface.port}'\n            return teacher_uri\n        return SeednodeMetadata(\n            self.checksum_address,\n            self.rest_server.rest_interface.host,\n            self.rest_server.rest_interface.port\n        )\n\n    def bytestring_of_known_nodes(self):\n        # TODO (#1537): FleetSensor does metadata-to-byte conversion as well,\n        # we may be able to cache the results there.\n        announce_nodes = [self.metadata()] + [node.metadata() for node in self.known_nodes]\n        response_payload = MetadataResponsePayload(timestamp_epoch=self.known_nodes.timestamp.epoch,\n                                                   announce_nodes=announce_nodes)\n        response = MetadataResponse(self.stamp.as_umbral_signer(), response_payload)\n        return bytes(response)\n\n    def _operator_is_bonded(self, registry: BaseContractRegistry) -> bool:\n        \"\"\"\n        This method assumes the stamp's signature is valid and accurate.\n        As a follow-up, this checks that the worker is bonded to a staking provider, but it may be\n        the case that the \"staking provider\" isn't \"staking\" (e.g., all her tokens have been slashed).\n        \"\"\"\n        application_agent = ContractAgency.get_agent(PREApplicationAgent, registry=registry)  # type: PREApplicationAgent\n        staking_provider_address = application_agent.get_staking_provider_from_operator(operator_address=self.operator_address)\n        if staking_provider_address == NULL_ADDRESS:\n            raise self.UnbondedOperator(f\"Operator {self.operator_address} is not bonded\")\n        return staking_provider_address == self.checksum_address\n\n    def _staking_provider_is_really_staking(self, registry: BaseContractRegistry, eth_provider_uri: Optional[str] = None) -> bool:\n        \"\"\"\n        This method assumes the stamp's signature is valid and accurate.\n        As a follow-up, this checks that the staking provider is, indeed, staking.\n        \"\"\"\n        application_agent = ContractAgency.get_agent(PREApplicationAgent, registry=registry, eth_provider_uri=eth_provider_uri)  # type: PREApplicationAgent\n        is_staking = application_agent.is_authorized(staking_provider=self.checksum_address)  # checksum address here is staking provider\n        return is_staking\n\n    def validate_operator(self, registry: BaseContractRegistry = None, eth_provider_uri: Optional[str] = None) -> None:\n\n        # Federated\n        if self.federated_only:\n            message = \"This node cannot be verified in this manner, \" \\\n                      \"but is OK to use in federated mode if you \" \\\n                      \"have reason to believe it is trustworthy.\"\n            raise self.WrongMode(message)\n\n        # Decentralized\n        else:\n\n            # Try to derive the worker address if it hasn't been derived yet.\n            try:\n                # TODO: This is overtly implicit\n                _operator_address = self.operator_address\n            except Exception as e:\n                raise self.InvalidOperatorSignature(str(e)) from e\n            self.verified_stamp = True  # TODO: Does this belong here?\n\n            # On-chain staking check, if registry is present\n            if registry:\n\n                if not self._operator_is_bonded(registry=registry):  # <-- Blockchain CALL\n                    message = f\"Operator {self.operator_address} is not bonded to staking provider {self.checksum_address}\"\n                    self.log.debug(message)\n                    raise self.UnbondedOperator(message)\n\n                if self._staking_provider_is_really_staking(registry=registry, eth_provider_uri=eth_provider_uri):  # <-- Blockchain CALL\n                    self.log.info(f'Verified operator {self}')\n                    self.verified_operator = True\n                else:\n                    raise self.NotStaking(f\"{self.checksum_address} is not staking\")\n\n            else:\n                self.log.info('No registry provided for staking verification.')\n\n    def validate_metadata_signature(self) -> bool:\n        \"\"\"Checks that the interface info is valid for this node's canonical address.\"\"\"\n        metadata_is_valid = self.metadata().verify()\n        self.verified_metadata = metadata_is_valid\n        if metadata_is_valid:\n            return True\n        else:\n            raise self.InvalidNode(\"Metadata signature is invalid\")\n\n    def validate_metadata(self, registry: BaseContractRegistry = None, eth_provider_uri: Optional[str] = None):\n\n        # Verify the metadata signature\n        if not self.verified_metadata:\n            self.validate_metadata_signature()\n\n        # Verify the identity evidence\n        if self.verified_stamp:\n            return\n\n        # Offline check of valid stamp signature by worker\n        try:\n            self.validate_operator(registry=registry, eth_provider_uri=eth_provider_uri)\n        except self.WrongMode:\n            if bool(registry):\n                raise\n\n    def verify_node(self,\n                    network_middleware_client,\n                    registry: BaseContractRegistry = None,\n                    eth_provider_uri: Optional[str] = None,\n                    certificate_filepath: Optional[Path] = None,\n                    force: bool = False\n                    ) -> bool:\n        \"\"\"\n        Three things happening here:\n\n        * Verify that the stamp matches the address (raises InvalidNode is it's not valid,\n          or WrongMode if it's a federated mode and being verified as a decentralized node)\n\n        * Verify the interface signature (raises InvalidNode if not valid)\n\n        * Connect to the node, make sure that it's up, and that the signature and address we\n          checked are the same ones this node is using now. (raises InvalidNode if not valid;\n          also emits a specific warning depending on which check failed).\n\n        \"\"\"\n\n        if force:\n            self.verified_metadata = False\n            self.verified_node = False\n            self.verified_stamp = False\n            self.verified_operator = False\n\n        if self.verified_node:\n            return True\n\n        if not registry and not self.federated_only:  # TODO: # 466\n            self.log.debug(\"No registry provided for decentralized stranger node verification - \"\n                           \"on-chain Staking verification will not be performed.\")\n\n        # This is both the stamp's client signature and interface metadata check; May raise InvalidNode\n        self.validate_metadata(registry=registry, eth_provider_uri=eth_provider_uri)\n\n        # The node's metadata is valid; let's be sure the interface is in order.\n        if not certificate_filepath:\n            if self.certificate_filepath is CERTIFICATE_NOT_SAVED:\n                self.certificate_filepath = self._cert_store_function(self.certificate, port=self.rest_interface.port)\n            certificate_filepath = self.certificate_filepath\n\n        response_data = network_middleware_client.node_information(host=self.rest_interface.host,\n                                                                   port=self.rest_interface.port)\n\n        try:\n            sprout = self.from_metadata_bytes(response_data)\n        except Exception as e:\n            raise self.InvalidNode(str(e))\n\n        verifying_keys_match = sprout.verifying_key == self.public_keys(SigningPower)\n        encrypting_keys_match = sprout.encrypting_key == self.public_keys(DecryptingPower)\n        addresses_match = sprout.checksum_address == self.checksum_address\n        evidence_matches = sprout.operator_signature_from_metadata == self.operator_signature_from_metadata\n\n        if not all((encrypting_keys_match, verifying_keys_match, addresses_match, evidence_matches)):\n            # Failure\n            if not addresses_match:\n                message = \"Wallet address swapped out.  It appears that someone is trying to defraud this node.\"\n            elif not verifying_keys_match:\n                message = \"Verifying key swapped out.  It appears that someone is impersonating this node.\"\n            else:\n                message = \"Wrong cryptographic material for this node - something fishy going on.\"\n            # TODO: #355 - Optional reporting.\n            raise self.InvalidNode(message)\n        else:\n            # Success\n            self.verified_node = True",
  "def __init__(self, metadata: NodeMetadata):\n        self._metadata = metadata\n        self._metadata_payload = metadata.payload\n\n        # cached properties\n        self._checksum_address = None\n        self._nickname = None\n        self._hash = None\n        self._repr = None\n        self._rest_interface = None\n\n        self._is_finishing = False\n        self._finishing_mutex = Queue()",
  "def __eq__(self, other):\n        try:\n            other_stamp = other.stamp\n        except (AttributeError, NoSigningPower):\n            return False\n        return bytes(self.stamp) == bytes(other_stamp)",
  "def __hash__(self):\n        if not self._hash:\n            self._hash = int.from_bytes(bytes(self.stamp), byteorder=\"big\")\n        return self._hash",
  "def __repr__(self):\n        if not self._repr:\n            self._repr = f\"({self.__class__.__name__})\u21c0{self.nickname}\u21bd ({self.checksum_address})\"\n        return self._repr",
  "def checksum_address(self):\n        if not self._checksum_address:\n            self._checksum_address = to_checksum_address(bytes(self.canonical_address))\n        return self._checksum_address",
  "def canonical_address(self):\n        return self._metadata_payload.staking_provider_address",
  "def nickname(self):\n        if not self._nickname:\n            self._nickname = Nickname.from_seed(self.checksum_address)\n        return self._nickname",
  "def rest_interface(self):\n        if not self._rest_interface:\n            self._rest_interface = InterfaceInfo(self._metadata_payload.host, self._metadata_payload.port)\n        return self._rest_interface",
  "def rest_url(self):\n        return self.rest_interface.uri",
  "def metadata(self):\n        return self._metadata",
  "def verifying_key(self):\n        return self._metadata_payload.verifying_key",
  "def encrypting_key(self):\n        return self._metadata_payload.encrypting_key",
  "def operator_signature_from_metadata(self):\n        return self._metadata_payload.operator_signature or NOT_SIGNED",
  "def timestamp(self):\n        return maya.MayaDT(self._metadata_payload.timestamp_epoch)",
  "def stamp(self) -> SignatureStamp:\n        return SignatureStamp(self._metadata_payload.verifying_key)",
  "def domain(self) -> str:\n        return self._metadata_payload.domain",
  "def finish(self):\n        from nucypher.characters.lawful import Ursula\n\n        crypto_power = CryptoPower()\n        crypto_power.consume_power_up(SigningPower(public_key=self._metadata_payload.verifying_key))\n        crypto_power.consume_power_up(DecryptingPower(public_key=self._metadata_payload.encrypting_key))\n\n        return Ursula(is_me=False,\n                      crypto_power=crypto_power,\n                      rest_host=self._metadata_payload.host,\n                      rest_port=self._metadata_payload.port,\n                      checksum_address=self.checksum_address,\n                      domain=self._metadata_payload.domain,\n                      timestamp=self.timestamp,\n                      operator_signature_from_metadata=self.operator_signature_from_metadata,\n                      certificate=load_der_x509_certificate(self._metadata_payload.certificate_der, backend=default_backend()),\n                      metadata=self._metadata\n                      )",
  "def mature(self):\n        if self._is_finishing:\n            return self._finishing_mutex.get()\n\n        self._is_finishing = True  # Prevent reentrance.\n        _finishing_mutex = self._finishing_mutex\n\n        mature_node = self.finish()\n        self.__class__ = mature_node.__class__\n        self.__dict__ = mature_node.__dict__\n\n        # As long as we're doing egregious workarounds, here's another one.  # TODO: 1481\n        filepath = mature_node._cert_store_function(certificate=mature_node.certificate, port=mature_node.rest_interface.port)\n        mature_node.certificate_filepath = filepath\n\n        _finishing_mutex.put(self)\n        return self",
  "def __init__(self):\n        self.stop_now = False",
  "def __call__(self, learning_deferred):\n        if self.stop_now:\n            assert False\n        self.stop_now = True",
  "class NotEnoughNodes(RuntimeError):\n        pass",
  "class NotEnoughTeachers(NotEnoughNodes):\n        crash_right_now = True",
  "class UnresponsiveTeacher(ConnectionError):\n        pass",
  "class NotATeacher(ValueError):\n        \"\"\"\n        Raised when a character cannot be properly utilized because\n        it does not have the proper attributes for learning or verification.\n        \"\"\"",
  "def __init__(self,\n                 domain: str,\n                 node_class: object = None,\n                 network_middleware: RestMiddleware = None,\n                 start_learning_now: bool = False,\n                 learn_on_same_thread: bool = False,\n                 known_nodes: tuple = None,\n                 seed_nodes: Tuple[tuple] = None,\n                 node_storage=None,\n                 save_metadata: bool = False,\n                 abort_on_learning_error: bool = False,\n                 lonely: bool = False,\n                 verify_node_bonding: bool = True,\n                 include_self_in_the_state: bool = False,\n                 ) -> None:\n\n        self.log = Logger(\"learning-loop\")  # type: Logger\n\n        self.learning_deferred = Deferred()\n        self.domain = domain\n        if not self.federated_only:\n            default_middleware = self.__DEFAULT_MIDDLEWARE_CLASS(registry=self.registry)\n        else:\n            default_middleware = self.__DEFAULT_MIDDLEWARE_CLASS()\n        self.network_middleware = network_middleware or default_middleware\n        self.save_metadata = save_metadata\n        self.start_learning_now = start_learning_now\n        self.learn_on_same_thread = learn_on_same_thread\n\n        self._abort_on_learning_error = abort_on_learning_error\n\n        self.__known_nodes = self.tracker_class(domain=domain, this_node=self if include_self_in_the_state else None)\n        self._verify_node_bonding = verify_node_bonding\n\n        self.lonely = lonely\n        self.done_seeding = False\n        self._learning_deferred = None\n        self._discovery_canceller = DiscoveryCanceller()\n\n        if not node_storage:\n            node_storage = self.__DEFAULT_NODE_STORAGE(federated_only=self.federated_only)\n        self.node_storage = node_storage\n        if save_metadata and node_storage is NO_STORAGE_AVAILABLE:\n            raise ValueError(\"Cannot save nodes without a configured node storage\")\n\n        from nucypher.characters.lawful import Ursula\n        self.node_class = node_class or Ursula\n        self.node_class.set_cert_storage_function(\n            node_storage.store_node_certificate)  # TODO: Fix this temporary workaround for on-disk cert storage.  #1481\n\n        known_nodes = known_nodes or tuple()\n        self.unresponsive_startup_nodes = list()  # TODO: Buckets - Attempt to use these again later  #567\n        for node in known_nodes:\n            try:\n                self.remember_node(node, eager=True, record_fleet_state=False)\n            except self.UnresponsiveTeacher:\n                self.unresponsive_startup_nodes.append(node)\n\n        # This node has not initialized its metadata yet.\n        self.known_nodes.record_fleet_state(skip_this_node=True)\n\n        self.teacher_nodes = deque()\n        self._current_teacher_node = None  # type: Union[Teacher, None]\n        self._learning_task = task.LoopingCall(self.keep_learning_about_nodes)\n\n        if self._DEBUG_MODE:\n            # Very slow, but provides useful info when trying to track down a stray Character.\n            # Seems mostly useful for Bob or federated Ursulas, but perhaps useful for other Characters as well.\n\n            import inspect\n            import os\n            frames = inspect.stack(3)\n            self._learning_task = task.LoopingCall(self.keep_learning_about_nodes, learner=self, frames=frames)\n            self._init_frames = frames\n            from tests.conftest import global_mutable_where_everybody\n            test_name = os.environ[\"PYTEST_CURRENT_TEST\"]\n            global_mutable_where_everybody[test_name].append(self)\n            self._FOR_TEST = test_name\n            ########################\n\n        self._learning_round = 0  # type: int\n        self._rounds_without_new_nodes = 0  # type: int\n        self._seed_nodes = seed_nodes or []\n\n        if self.start_learning_now and not self.lonely:\n            self.start_learning_loop(now=self.learn_on_same_thread)",
  "def known_nodes(self):\n        return self.__known_nodes",
  "def load_seednodes(self, read_storage: bool = True, record_fleet_state=False):\n        \"\"\"\n        Engage known nodes from storages and pre-fetch hardcoded seednode certificates for node learning.\n\n        TODO: Dehydrate this with nucypher.utilities.seednodes.load_seednodes\n        \"\"\"\n        if self.done_seeding:\n            raise RuntimeError(\"Already finished seeding.  Why try again?  Is this a thread safety problem?\")\n\n        discovered = []\n\n        if self.domain:\n            canonical_sage_uris = TEACHER_NODES.get(self.domain, ())\n\n            for uri in canonical_sage_uris:\n                try:\n                    maybe_sage_node = self.node_class.from_teacher_uri(teacher_uri=uri,\n                                                                       min_stake=0,  # TODO: Where to get this?\n                                                                       federated_only=self.federated_only,\n                                                                       network_middleware=self.network_middleware,\n                                                                       registry=self.registry)\n                except Exception as e:\n                    # TODO: log traceback here?\n                    # TODO: distinguish between versioning errors and other errors?\n                    self.log.warn(f\"Failed to instantiate a node at {uri}: {e}\")\n                else:\n                    new_node = self.remember_node(maybe_sage_node, record_fleet_state=False)\n                    discovered.append(new_node)\n\n        for seednode_metadata in self._seed_nodes:\n\n            node_tag = \"{}|{}:{}\".format(seednode_metadata.checksum_address,\n                                         seednode_metadata.rest_host,\n                                         seednode_metadata.rest_port)\n\n            self.log.debug(f\"Seeding from: {node_tag}\")\n\n            try:\n                seed_node = self.node_class.from_seednode_metadata(seednode_metadata=seednode_metadata,\n                                                                   network_middleware=self.network_middleware,\n                                                                   )\n            except Exception as e:\n                # TODO: log traceback here?\n                # TODO: distinguish between versioning errors and other errors?\n                self.log.warn(f\"Failed to instantiate a node {node_tag}: {e}\")\n            else:\n                new_node = self.remember_node(seed_node, record_fleet_state=False)\n                discovered.append(new_node)\n\n        self.log.info(\"Finished learning about all seednodes.\")\n\n        self.done_seeding = True\n\n        nodes_restored_from_storage = self.read_nodes_from_storage() if read_storage else []\n        discovered.extend(nodes_restored_from_storage)\n\n        if discovered and record_fleet_state:\n            self.known_nodes.record_fleet_state()\n\n        return discovered",
  "def read_nodes_from_storage(self) -> List:\n        stored_nodes = self.node_storage.all(federated_only=self.federated_only)  # TODO: #466\n\n        restored_from_disk = []\n        invalid_nodes = defaultdict(list)\n        for node in stored_nodes:\n            if node.domain != self.domain:\n                invalid_nodes[node.domain].append(node)\n                continue\n            restored_node = self.remember_node(node, record_fleet_state=False)  # TODO: Validity status 1866\n            restored_from_disk.append(restored_node)\n\n        if invalid_nodes:\n            self.log.warn(f\"We're learning about domain '{self.domain}', but found nodes from other domains; \"\n                          f\"let's ignore them. These domains and nodes are: {dict(invalid_nodes)}\")\n\n        return restored_from_disk",
  "def remember_node(self,\n                      node,\n                      force_verification_recheck=False,\n                      record_fleet_state=True,\n                      eager: bool = False):\n\n        # UNPARSED\n        # PARSED\n        # METADATA_CHECKED\n        # VERIFIED_CERT\n        # VERIFIED_STAKE\n\n        if node == self:  # No need to remember self.\n            return False\n\n        # First, determine if this is an outdated representation of an already known node.\n        # TODO: #1032 or, since it's closed and will never re-opened, i am the :=\n        with suppress(KeyError):\n            already_known_node = self.known_nodes[node.checksum_address]\n            if not node.timestamp > already_known_node.timestamp:\n                # This node is already known.  We can safely return.\n                return False\n\n        self.known_nodes.record_node(node)  # FIXME - dont always remember nodes, bucket them.\n\n        if self.save_metadata:\n            self.node_storage.store_node_metadata(node=node)\n\n        if eager:\n            node.mature()\n            stranger_certificate = node.certificate\n\n            # Store node's certificate - It has been seen.\n            certificate_filepath = self.node_storage.store_node_certificate(certificate=stranger_certificate, port=node.rest_interface.port)\n\n            # In some cases (seed nodes or other temp stored certs),\n            # this will update the filepath from the temp location to this one.\n            node.certificate_filepath = certificate_filepath\n\n            # Use this to control whether or not this node performs\n            # blockchain calls to determine if stranger nodes are bonded.\n            # Note: self.registry is composed on blockchainy character subclasses.\n            registry = self.registry if self._verify_node_bonding else None  # TODO: Federated mode?\n\n            try:\n                node.verify_node(force=force_verification_recheck,\n                                 network_middleware_client=self.network_middleware.client,\n                                 registry=registry)\n            except SSLError:\n                # TODO: Bucket this node as having bad TLS info - maybe it's an update that hasn't fully propagated?  567\n                return False\n\n            except RestMiddleware.Unreachable:\n                self.log.info(\"No Response while trying to verify node {}|{}\".format(node.rest_interface, node))\n                # TODO: Bucket this node as \"ghost\" or something: somebody else knows about it, but we can't get to it.  567\n                return False\n\n            except node.NotStaking:\n                # TODO: Bucket this node as inactive, and potentially safe to forget.  567\n                self.log.info(\n                    f'StakingProvider:Operator {node.checksum_address}:{node.operator_address} is not actively staking, skipping.')\n                return False\n\n            # TODO: What about InvalidNode?  (for that matter, any SuspiciousActivity)  1714, 567 too really\n\n        if record_fleet_state:\n            self.known_nodes.record_fleet_state()\n\n        return node",
  "def start_learning_loop(self, now=False):\n        if self._learning_task.running:\n            return False\n        elif now:\n            self.log.info(\"Starting Learning Loop NOW.\")\n            self.learn_from_teacher_node()\n\n            self.learning_deferred = self._learning_task.start(interval=self._SHORT_LEARNING_DELAY)\n            self.learning_deferred.addErrback(self.handle_learning_errors)\n            return self.learning_deferred\n        else:\n            self.log.info(\"Starting Learning Loop.\")\n            learner_deferred = self._learning_task.start(interval=self._SHORT_LEARNING_DELAY, now=False)\n            learner_deferred.addErrback(self.handle_learning_errors)\n            self.learning_deferred = learner_deferred\n            return self.learning_deferred",
  "def stop_learning_loop(self, reason=None):\n        \"\"\"\n        Only for tests at this point.  Maybe some day for graceful shutdowns.\n        \"\"\"\n        if self._learning_task.running:\n            self._learning_task.stop()\n\n        if self._learning_deferred is RELAX:\n            assert False\n\n        if self._learning_deferred is not None:\n            # self._learning_deferred.cancel()  # TODO: The problem here is that this might already be called.\n            self._discovery_canceller(self._learning_deferred)",
  "def handle_learning_errors(self, failure, *args, **kwargs):\n        _exception = failure.value\n        crash_right_now = getattr(_exception, \"crash_right_now\", False)\n        if self._abort_on_learning_error or crash_right_now:\n            reactor.callFromThread(self._crash_gracefully, failure=failure)\n            self.log.critical(\"Unhandled error during node learning.  Attempting graceful crash.\")\n        else:\n            self.log.warn(f\"Unhandled error during node learning: {failure.getTraceback()}\")\n            if not self._learning_task.running:\n                self.start_learning_loop()",
  "def _crash_gracefully(self, failure=None):\n        \"\"\"\n        A facility for crashing more gracefully in the event that an exception\n        is unhandled in a different thread, especially inside a loop like the acumen loop, Alice's publication loop, or Bob's retrieval loop..\n        \"\"\"\n\n        self._crashed = failure\n\n        # When using Learner._DEBUG_MODE in tests, it may be helpful to uncomment this to be able to introspect.\n        # from tests.conftest import global_mutable_where_everybody\n        # gmwe = global_mutable_where_everybody\n\n        failure.raiseException()\n        # TODO: We don't actually have checksum_address at this level - maybe only Characters can crash gracefully :-)  1711\n        self.log.critical(\"{} crashed with {}\".format(self.checksum_address, failure))\n        reactor.stop()",
  "def select_teacher_nodes(self):\n        nodes_we_know_about = self.known_nodes.shuffled()\n\n        if not nodes_we_know_about:\n            raise self.NotEnoughTeachers(\"Need some nodes to start learning from.\")\n\n        self.teacher_nodes.extend(nodes_we_know_about)",
  "def cycle_teacher_node(self):\n        if not self.teacher_nodes:\n            self.select_teacher_nodes()\n        try:\n            self._current_teacher_node = self.teacher_nodes.pop()\n        except IndexError:\n            error = \"Not enough nodes to select a good teacher, Check your network connection then node configuration\"\n            raise self.NotEnoughTeachers(error)\n        self.log.debug(\"Cycled teachers; New teacher is {}\".format(self._current_teacher_node))",
  "def current_teacher_node(self, cycle=False):\n        if cycle:\n            self.cycle_teacher_node()\n\n        if not self._current_teacher_node:\n            self.cycle_teacher_node()\n\n        teacher = self._current_teacher_node\n\n        return teacher",
  "def learn_about_nodes_now(self, force=False):\n        if self._learning_task.running:\n            self._learning_task.reset()\n            # self._learning_task()\n        elif not force:\n            self.log.warn(\n                \"Learning loop isn't started; can't learn about nodes now.  You can override this with force=True.\")\n        elif force:\n            # TODO: What if this has been stopped?\n            self.log.info(\"Learning loop wasn't started; forcing start now.\")\n            self._learning_task.start(self._SHORT_LEARNING_DELAY, now=True)",
  "def keep_learning_about_nodes(self):\n        \"\"\"\n        Continually learn about new nodes.\n        \"\"\"\n\n        # TODO: Allow the user to set eagerness?  1712\n        # TODO: Also, if we do allow eager, don't even defer; block right here.\n\n        self._learning_deferred = Deferred(canceller=self._discovery_canceller)  # TODO: No longer relevant.\n\n        def _discover_or_abort(_first_result):\n            # self.log.debug(f\"{self} learning at {datetime.datetime.now()}\")   # 1712\n            result = self.learn_from_teacher_node(eager=False, canceller=self._discovery_canceller)\n            # self.log.debug(f\"{self} finished learning at {datetime.datetime.now()}\")  # 1712\n            return result\n\n        self._learning_deferred.addCallback(_discover_or_abort)\n        self._learning_deferred.addErrback(self.handle_learning_errors)\n\n        # Instead of None, we might want to pass something useful about the context.\n        # Alternately, it might be nice for learn_from_teacher_node to (some or all of the time) return a Deferred.\n        reactor.callInThread(self._learning_deferred.callback, None)\n        return self._learning_deferred",
  "def block_until_number_of_known_nodes_is(self,\n                                             number_of_nodes_to_know: int,\n                                             timeout: int = 10,\n                                             learn_on_this_thread: bool = False,\n                                             eager: bool = False):\n        start = maya.now()\n        starting_round = self._learning_round\n\n        # if not learn_on_this_thread and self._learning_task.running:\n        #     # Get a head start by firing the looping call now.  If it's very fast, maybe we'll have enough nodes on the first iteration.\n        #     self._learning_task()\n\n        while True:\n            rounds_undertaken = self._learning_round - starting_round\n            if len(self.known_nodes) >= number_of_nodes_to_know:\n                if rounds_undertaken:\n                    self.log.info(\"Learned about enough nodes after {} rounds.\".format(rounds_undertaken))\n                return True\n\n            if not self._learning_task.running:\n                self.log.warn(\"Blocking to learn about nodes, but learning loop isn't running.\")\n            if learn_on_this_thread:\n                try:\n                    self.learn_from_teacher_node(eager=eager)\n                except (requests.exceptions.ReadTimeout, requests.exceptions.ConnectTimeout):\n                    # TODO: Even this \"same thread\" logic can be done off the main thread.  NRN\n                    self.log.warn(\"Teacher was unreachable.  No good way to handle this on the main thread.\")\n\n            # The rest of the fucking owl\n            round_finish = maya.now()\n            elapsed = (round_finish - start).seconds\n            if elapsed > timeout:\n                if len(self.known_nodes) >= number_of_nodes_to_know:  # Last chance!\n                    self.log.info(f\"Learned about enough nodes after {rounds_undertaken} rounds.\")\n                    return True\n                if not self._learning_task.running:\n                    raise RuntimeError(\"Learning loop is not running.  Start it with start_learning().\")\n                elif not reactor.running and not learn_on_this_thread:\n                    raise RuntimeError(\n                        f\"The reactor isn't running, but you're trying to use it for discovery.  You need to start the Reactor in order to use {self} this way.\")\n                else:\n                    raise self.NotEnoughNodes(\"After {} seconds and {} rounds, didn't find {} nodes\".format(\n                        timeout, rounds_undertaken, number_of_nodes_to_know))\n            else:\n                time.sleep(.1)",
  "def block_until_specific_nodes_are_known(self,\n                                             addresses: Set,\n                                             timeout=LEARNING_TIMEOUT,\n                                             allow_missing=0,\n                                             learn_on_this_thread=False):\n        start = maya.now()\n        starting_round = self._learning_round\n\n        addresses = set(addresses)\n\n        while True:\n            if self._crashed:\n                return self._crashed\n            rounds_undertaken = self._learning_round - starting_round\n            if addresses.issubset(self.known_nodes.addresses()):\n                if rounds_undertaken:\n                    self.log.info(\"Learned about all nodes after {} rounds.\".format(rounds_undertaken))\n                return True\n\n            if learn_on_this_thread:\n                self.learn_from_teacher_node(eager=True)\n            elif not self._learning_task.running:\n                raise RuntimeError(\n                    \"Tried to block while discovering nodes on another thread, but the learning task isn't running.\")\n\n            if (maya.now() - start).seconds > timeout:\n\n                still_unknown = addresses.difference(self.known_nodes.addresses())\n\n                if len(still_unknown) <= allow_missing:\n                    return False\n                else:\n                    raise self.NotEnoughTeachers(\n                        \"After {} seconds and {} rounds, didn't find these {} nodes: {}\".format(\n                            timeout, rounds_undertaken, len(still_unknown), still_unknown))\n            else:\n                time.sleep(.1)",
  "def _adjust_learning(self, node_list):\n        \"\"\"\n        Takes a list of new nodes, adjusts learning accordingly.\n\n        Currently, simply slows down learning loop when no new nodes have been discovered in a while.\n        TODO: Do other important things - scrub, bucket, etc.  567\n        \"\"\"\n        if node_list:\n            self._rounds_without_new_nodes = 0\n            self._learning_task.interval = self._SHORT_LEARNING_DELAY\n        else:\n            self._rounds_without_new_nodes += 1\n            if self._rounds_without_new_nodes > self._ROUNDS_WITHOUT_NODES_AFTER_WHICH_TO_SLOW_DOWN:\n                self.log.info(\"After {} rounds with no new nodes, it's time to slow down to {} seconds.\".format(\n                    self._ROUNDS_WITHOUT_NODES_AFTER_WHICH_TO_SLOW_DOWN,\n                    self._LONG_LEARNING_DELAY))\n                self._learning_task.interval = self._LONG_LEARNING_DELAY",
  "def network_bootstrap(self, node_list: list) -> None:\n        for node_addr, port in node_list:\n            new_nodes = self.learn_about_nodes_now(node_addr, port)\n            self.__known_nodes.update(new_nodes)",
  "def get_nodes_by_ids(self, node_ids):\n        for node_id in node_ids:\n            try:\n                # Scenario 1: We already know about this node.\n                return self.__known_nodes[node_id]\n            except KeyError:\n                raise NotImplementedError",
  "def write_node_metadata(self, node, serializer=bytes) -> str:\n        return self.node_storage.store_node_metadata(node=node)",
  "def verify_from(self,\n                    stranger: 'Character',\n                    message: bytes,\n                    signature: Signature\n                    ):\n\n        if not signature.verify(verifying_pk=stranger.stamp.as_umbral_pubkey(), message=message):\n            try:\n                node_on_the_other_end = self.node_class.from_seednode_metadata(stranger.seed_node_metadata(),\n                                                                               network_middleware=self.network_middleware)\n                if node_on_the_other_end != stranger:\n                    raise self.node_class.InvalidNode(\n                        f\"Expected to connect to {stranger}, got {node_on_the_other_end} instead.\")\n                else:\n                    raise InvalidSignature(\"Signature for message isn't valid: {}\".format(signature))\n            except (TypeError, AttributeError):\n                raise InvalidSignature(f\"Unable to verify message from stranger: {stranger}\")",
  "def learn_from_teacher_node(self, eager=False, canceller=None):\n        \"\"\"\n        Sends a request to node_url to find out about known nodes.\n\n        TODO: Does this (and related methods) belong on FleetSensor for portability?\n\n        TODO: A lot of other code can be simplified if this is converted to async def.  That's a project, though.\n        \"\"\"\n        remembered = []\n\n        if not self.done_seeding:\n            try:\n                remembered_seednodes = self.load_seednodes(record_fleet_state=True)\n            except Exception as e:\n                # Even if we aren't aborting on learning errors, we want this to crash the process pronto.\n                e.crash_right_now = True\n                raise\n            else:\n                remembered.extend(remembered_seednodes)\n\n        self._learning_round += 1\n\n        current_teacher = self.current_teacher_node()  # Will raise if there's no available teacher.\n\n        if isinstance(self, Teacher):\n            announce_nodes = [self.metadata()]\n        else:\n            announce_nodes = []\n\n        unresponsive_nodes = set()\n\n        #\n        # Request\n        #\n        if canceller and canceller.stop_now:\n            return RELAX\n\n        try:\n            response = self.network_middleware.get_nodes_via_rest(node=current_teacher,\n                                                                  announce_nodes=announce_nodes,\n                                                                  fleet_state_checksum=self.known_nodes.checksum)\n        # These except clauses apply to the current_teacher itself, not the learned-about nodes.\n        except NodeSeemsToBeDown as e:\n            unresponsive_nodes.add(current_teacher)\n            self.log.info(f\"Teacher {current_teacher.seed_node_metadata(as_teacher_uri=True)} is unreachable: {e}.\")\n            return\n        except current_teacher.InvalidNode as e:\n            # Ugh.  The teacher is invalid.  Rough.\n            # TODO: Bucket separately and report.\n            unresponsive_nodes.add(current_teacher)  # This does nothing.\n            self.known_nodes.mark_as(current_teacher.InvalidNode, current_teacher)\n            self.log.warn(f\"Teacher {str(current_teacher)} is invalid: {e}.\")\n            # TODO (#567): bucket the node as suspicious\n            return\n        except RuntimeError as e:\n            if canceller and canceller.stop_now:\n                # Race condition that seems limited to tests.\n                # TODO: Sort this out.\n                return RELAX\n            else:\n                self.log.warn(\n                    f\"Unhandled error while learning from {str(current_teacher)} \"\n                    f\"(hex={bytes(current_teacher.metadata()).hex()}):{e}.\")\n                raise\n        except Exception as e:\n            self.log.warn(\n                f\"Unhandled error while learning from {str(current_teacher)} \"\n                f\"(hex={bytes(current_teacher.metadata()).hex()}):{e}.\")  # To track down 2345 / 1698\n            raise\n        finally:\n            # Is cycling happening in the right order?\n            self.cycle_teacher_node()\n\n        if response.status_code != 200:\n            self.log.info(\"Bad response from teacher {}: {} - {}\".format(current_teacher, response, response.content))\n            return\n\n        # TODO: we really should be checking this *before* we ask it for a node list,\n        # but currently we may not know this before the REST request (which may mature the node)\n        if self.domain != current_teacher.domain:\n            self.log.debug(f\"{current_teacher} is serving '{current_teacher.domain}', \"\n                           f\"ignore since we are learning about '{self.domain}'\")\n            return  # This node is not serving our domain.\n\n        #\n        # Deserialize\n        #\n        try:\n            metadata = MetadataResponse.from_bytes(response.content)\n        except Exception as e:\n            self.log.warn(f\"Failed to deserialize MetadataResponse from Teacher {current_teacher} ({e}): {response.content}\")\n            return\n\n        try:\n            metadata_payload = metadata.verify(current_teacher.stamp.as_umbral_pubkey())\n        except Exception as e:\n            # TODO (#567): bucket the node as suspicious\n            self.log.warn(\n                f\"Failed to verify MetadataResponse from Teacher {current_teacher} ({e}): {response.content}\")\n            return\n\n        # End edge case handling.\n\n        fleet_state_updated = maya.MayaDT(metadata_payload.timestamp_epoch)\n\n        if not metadata_payload.announce_nodes:\n            # The teacher had the same fleet state\n            self.known_nodes.record_remote_fleet_state(\n                current_teacher.checksum_address,\n                self.known_nodes.checksum,\n                fleet_state_updated,\n                self.known_nodes.population)\n\n            return FLEET_STATES_MATCH\n\n        sprouts = [NodeSprout(node) for node in metadata_payload.announce_nodes]\n\n        for sprout in sprouts:\n            try:\n                node_or_false = self.remember_node(sprout,\n                                                   record_fleet_state=False,\n                                                   # Do we want both of these to be decided by `eager`?\n                                                   eager=eager)\n                if node_or_false is not False:\n                    remembered.append(node_or_false)\n\n                #\n                # Report Failure\n                #\n\n            except NodeSeemsToBeDown:\n                self.log.info(f\"Verification Failed - \"\n                              f\"Cannot establish connection to {sprout}.\")\n\n            # TODO: This whole section is weird; sprouts down have any of these things.\n            except sprout.StampNotSigned:\n                self.log.warn(f'Verification Failed - '\n                              f'{sprout} {NOT_SIGNED}.')\n\n            except sprout.NotStaking:\n                self.log.warn(f'Verification Failed - '\n                              f'{sprout} has no active stakes in the current period '\n                              f'({self.staking_agent.get_current_period()}')\n\n            except sprout.InvalidOperatorSignature:\n                self.log.warn(f'Verification Failed - '\n                              f'{sprout} has an invalid wallet signature for {sprout.operator_signature_from_metadata}')\n\n            except sprout.UnbondedOperator:\n                self.log.warn(f'Verification Failed - '\n                              f'{sprout} is not bonded to a Staker.')\n\n            # TODO: Handle invalid sprouts\n            # except sprout.Invalidsprout:\n            #     self.log.warn(sprout.invalid_metadata_message.format(sprout))\n\n            except NodeSeemsToBeDown as e:\n                message = f\"Node is unreachable: {sprout}. Full error: {e.__str__()} \"\n                self.log.warn(message)\n\n            except SuspiciousActivity:\n                message = f\"Suspicious Activity: Discovered sprout with bad signature: {sprout}.\" \\\n                          f\"Propagated by: {current_teacher}\"\n                self.log.warn(message)\n\n        ###################\n\n        learning_round_log_message = \"Learning round {}.  Teacher: {} knew about {} nodes, {} were new.\"\n        self.log.info(learning_round_log_message.format(self._learning_round,\n                                                        current_teacher,\n                                                        len(sprouts),\n                                                        len(remembered)))\n        if remembered:\n            self.known_nodes.record_fleet_state()\n\n        # Now that we updated all our nodes with the teacher's,\n        # our fleet state checksum should be the same as the teacher's checksum.\n\n        # Is cycling happening in the right order?\n        self.known_nodes.record_remote_fleet_state(\n            current_teacher.checksum_address,\n            self.known_nodes.checksum,\n            fleet_state_updated,\n            len(sprouts))\n\n        return sprouts",
  "def __init__(self,\n                 domain: str,  # TODO: Consider using a Domain type\n                 certificate: Certificate,\n                 certificate_filepath: Path,\n                 ) -> None:\n\n        self.domain = domain\n\n        #\n        # Identity\n        #\n\n        self.certificate = certificate\n        self.certificate_filepath = certificate_filepath\n\n        # Assume unverified\n        self.verified_stamp = False\n        self.verified_operator = False\n        self.verified_metadata = False\n        self.verified_node = False",
  "class InvalidNode(SuspiciousActivity):\n        \"\"\"Raised when a node has an invalid characteristic - stamp, interface, or address.\"\"\"",
  "class InvalidStamp(InvalidNode):\n        \"\"\"Base exception class for invalid character stamps\"\"\"",
  "class StampNotSigned(InvalidStamp):\n        \"\"\"Raised when a node does not have a stamp signature when one is required for verification\"\"\"",
  "class InvalidOperatorSignature(InvalidStamp):\n        \"\"\"Raised when a stamp fails signature verification or recovers an unexpected worker address\"\"\"",
  "class NotStaking(InvalidStamp):\n        \"\"\"Raised when a node fails verification because it is not currently staking\"\"\"",
  "class UnbondedOperator(InvalidNode):\n        \"\"\"Raised when a node fails verification because it is not bonded to a Staker\"\"\"",
  "class WrongMode(TypeError):\n        \"\"\"Raised when a Character tries to use another Character as decentralized when the latter is federated_only.\"\"\"",
  "def set_cert_storage_function(cls, node_storage_function: Callable):\n        cls._cert_store_function = node_storage_function",
  "def mature(self, *args, **kwargs):\n        \"\"\"This is the most mature form, so we do nothing.\"\"\"\n        return self",
  "def set_federated_mode(cls, federated_only: bool):\n        cls._federated_only_instances = federated_only",
  "def seed_node_metadata(self, as_teacher_uri=False) -> SeednodeMetadata:\n        if as_teacher_uri:\n            teacher_uri = f'{self.checksum_address}@{self.rest_server.rest_interface.host}:{self.rest_server.rest_interface.port}'\n            return teacher_uri\n        return SeednodeMetadata(\n            self.checksum_address,\n            self.rest_server.rest_interface.host,\n            self.rest_server.rest_interface.port\n        )",
  "def bytestring_of_known_nodes(self):\n        # TODO (#1537): FleetSensor does metadata-to-byte conversion as well,\n        # we may be able to cache the results there.\n        announce_nodes = [self.metadata()] + [node.metadata() for node in self.known_nodes]\n        response_payload = MetadataResponsePayload(timestamp_epoch=self.known_nodes.timestamp.epoch,\n                                                   announce_nodes=announce_nodes)\n        response = MetadataResponse(self.stamp.as_umbral_signer(), response_payload)\n        return bytes(response)",
  "def _operator_is_bonded(self, registry: BaseContractRegistry) -> bool:\n        \"\"\"\n        This method assumes the stamp's signature is valid and accurate.\n        As a follow-up, this checks that the worker is bonded to a staking provider, but it may be\n        the case that the \"staking provider\" isn't \"staking\" (e.g., all her tokens have been slashed).\n        \"\"\"\n        application_agent = ContractAgency.get_agent(PREApplicationAgent, registry=registry)  # type: PREApplicationAgent\n        staking_provider_address = application_agent.get_staking_provider_from_operator(operator_address=self.operator_address)\n        if staking_provider_address == NULL_ADDRESS:\n            raise self.UnbondedOperator(f\"Operator {self.operator_address} is not bonded\")\n        return staking_provider_address == self.checksum_address",
  "def _staking_provider_is_really_staking(self, registry: BaseContractRegistry, eth_provider_uri: Optional[str] = None) -> bool:\n        \"\"\"\n        This method assumes the stamp's signature is valid and accurate.\n        As a follow-up, this checks that the staking provider is, indeed, staking.\n        \"\"\"\n        application_agent = ContractAgency.get_agent(PREApplicationAgent, registry=registry, eth_provider_uri=eth_provider_uri)  # type: PREApplicationAgent\n        is_staking = application_agent.is_authorized(staking_provider=self.checksum_address)  # checksum address here is staking provider\n        return is_staking",
  "def validate_operator(self, registry: BaseContractRegistry = None, eth_provider_uri: Optional[str] = None) -> None:\n\n        # Federated\n        if self.federated_only:\n            message = \"This node cannot be verified in this manner, \" \\\n                      \"but is OK to use in federated mode if you \" \\\n                      \"have reason to believe it is trustworthy.\"\n            raise self.WrongMode(message)\n\n        # Decentralized\n        else:\n\n            # Try to derive the worker address if it hasn't been derived yet.\n            try:\n                # TODO: This is overtly implicit\n                _operator_address = self.operator_address\n            except Exception as e:\n                raise self.InvalidOperatorSignature(str(e)) from e\n            self.verified_stamp = True  # TODO: Does this belong here?\n\n            # On-chain staking check, if registry is present\n            if registry:\n\n                if not self._operator_is_bonded(registry=registry):  # <-- Blockchain CALL\n                    message = f\"Operator {self.operator_address} is not bonded to staking provider {self.checksum_address}\"\n                    self.log.debug(message)\n                    raise self.UnbondedOperator(message)\n\n                if self._staking_provider_is_really_staking(registry=registry, eth_provider_uri=eth_provider_uri):  # <-- Blockchain CALL\n                    self.log.info(f'Verified operator {self}')\n                    self.verified_operator = True\n                else:\n                    raise self.NotStaking(f\"{self.checksum_address} is not staking\")\n\n            else:\n                self.log.info('No registry provided for staking verification.')",
  "def validate_metadata_signature(self) -> bool:\n        \"\"\"Checks that the interface info is valid for this node's canonical address.\"\"\"\n        metadata_is_valid = self.metadata().verify()\n        self.verified_metadata = metadata_is_valid\n        if metadata_is_valid:\n            return True\n        else:\n            raise self.InvalidNode(\"Metadata signature is invalid\")",
  "def validate_metadata(self, registry: BaseContractRegistry = None, eth_provider_uri: Optional[str] = None):\n\n        # Verify the metadata signature\n        if not self.verified_metadata:\n            self.validate_metadata_signature()\n\n        # Verify the identity evidence\n        if self.verified_stamp:\n            return\n\n        # Offline check of valid stamp signature by worker\n        try:\n            self.validate_operator(registry=registry, eth_provider_uri=eth_provider_uri)\n        except self.WrongMode:\n            if bool(registry):\n                raise",
  "def verify_node(self,\n                    network_middleware_client,\n                    registry: BaseContractRegistry = None,\n                    eth_provider_uri: Optional[str] = None,\n                    certificate_filepath: Optional[Path] = None,\n                    force: bool = False\n                    ) -> bool:\n        \"\"\"\n        Three things happening here:\n\n        * Verify that the stamp matches the address (raises InvalidNode is it's not valid,\n          or WrongMode if it's a federated mode and being verified as a decentralized node)\n\n        * Verify the interface signature (raises InvalidNode if not valid)\n\n        * Connect to the node, make sure that it's up, and that the signature and address we\n          checked are the same ones this node is using now. (raises InvalidNode if not valid;\n          also emits a specific warning depending on which check failed).\n\n        \"\"\"\n\n        if force:\n            self.verified_metadata = False\n            self.verified_node = False\n            self.verified_stamp = False\n            self.verified_operator = False\n\n        if self.verified_node:\n            return True\n\n        if not registry and not self.federated_only:  # TODO: # 466\n            self.log.debug(\"No registry provided for decentralized stranger node verification - \"\n                           \"on-chain Staking verification will not be performed.\")\n\n        # This is both the stamp's client signature and interface metadata check; May raise InvalidNode\n        self.validate_metadata(registry=registry, eth_provider_uri=eth_provider_uri)\n\n        # The node's metadata is valid; let's be sure the interface is in order.\n        if not certificate_filepath:\n            if self.certificate_filepath is CERTIFICATE_NOT_SAVED:\n                self.certificate_filepath = self._cert_store_function(self.certificate, port=self.rest_interface.port)\n            certificate_filepath = self.certificate_filepath\n\n        response_data = network_middleware_client.node_information(host=self.rest_interface.host,\n                                                                   port=self.rest_interface.port)\n\n        try:\n            sprout = self.from_metadata_bytes(response_data)\n        except Exception as e:\n            raise self.InvalidNode(str(e))\n\n        verifying_keys_match = sprout.verifying_key == self.public_keys(SigningPower)\n        encrypting_keys_match = sprout.encrypting_key == self.public_keys(DecryptingPower)\n        addresses_match = sprout.checksum_address == self.checksum_address\n        evidence_matches = sprout.operator_signature_from_metadata == self.operator_signature_from_metadata\n\n        if not all((encrypting_keys_match, verifying_keys_match, addresses_match, evidence_matches)):\n            # Failure\n            if not addresses_match:\n                message = \"Wallet address swapped out.  It appears that someone is trying to defraud this node.\"\n            elif not verifying_keys_match:\n                message = \"Verifying key swapped out.  It appears that someone is impersonating this node.\"\n            else:\n                message = \"Wrong cryptographic material for this node - something fishy going on.\"\n            # TODO: #355 - Optional reporting.\n            raise self.InvalidNode(message)\n        else:\n            # Success\n            self.verified_node = True",
  "def _discover_or_abort(_first_result):\n            # self.log.debug(f\"{self} learning at {datetime.datetime.now()}\")   # 1712\n            result = self.learn_from_teacher_node(eager=False, canceller=self._discovery_canceller)\n            # self.log.debug(f\"{self} finished learning at {datetime.datetime.now()}\")  # 1712\n            return result",
  "class ProxyRESTServer:\n\n    log = Logger(\"network-server\")\n\n    def __init__(self,\n                 rest_host: str,\n                 rest_port: int,\n                 hosting_power=None,\n                 rest_app=None\n                 ) -> None:\n\n        self.rest_interface = InterfaceInfo(host=rest_host, port=rest_port)\n        if rest_app:  # if is me\n            self.rest_app = rest_app\n        else:\n            self.rest_app = constants.PUBLIC_ONLY\n\n        self.__hosting_power = hosting_power\n\n    def rest_url(self):\n        return \"{}:{}\".format(self.rest_interface.host, self.rest_interface.port)",
  "def make_rest_app(\n        this_node,\n        log: Logger = Logger(\"http-application-layer\")\n        ) -> Flask:\n    \"\"\"Creates a REST application.\"\"\"\n\n    # A trampoline function for the real REST app,\n    # to ensure that a reference to the node object is not held by the app closure.\n    # One would think that it's enough to only remove a reference to the node,\n    # but `rest_app` somehow holds a reference to itself, Uroboros-like...\n    rest_app = _make_rest_app(weakref.proxy(this_node), log)\n    return rest_app",
  "def _make_rest_app(this_node, log: Logger) -> Flask:\n\n    # TODO: Avoid circular imports :-(\n    from nucypher.characters.lawful import Alice, Bob, Ursula\n\n    _alice_class = Alice\n    _bob_class = Bob\n    _node_class = Ursula\n\n    rest_app = Flask(\"ursula-service\")\n    rest_app.config['MAX_CONTENT_LENGTH'] = MAX_UPLOAD_CONTENT_LENGTH\n\n    @rest_app.route(\"/public_information\")\n    def public_information():\n        \"\"\"REST endpoint for public keys and address.\"\"\"\n        response = Response(response=bytes(this_node.metadata()), mimetype='application/octet-stream')\n        return response\n\n    @rest_app.route('/node_metadata', methods=[\"GET\"])\n    def all_known_nodes():\n        headers = {'Content-Type': 'application/octet-stream'}\n        if this_node._learning_deferred is not RELAX and not this_node._learning_task.running:\n            # Learn when learned about\n            this_node.start_learning_loop()\n\n        # All known nodes + this node\n        response_bytes = this_node.bytestring_of_known_nodes()\n        return Response(response_bytes, headers=headers)\n\n    @rest_app.route('/node_metadata', methods=[\"POST\"])\n    def node_metadata_exchange():\n\n        metadata_request = MetadataRequest.from_bytes(request.data)\n\n        # If these nodes already have the same fleet state, no exchange is necessary.\n\n        learner_fleet_state = request.args.get('fleet')\n        if metadata_request.fleet_state_checksum == this_node.known_nodes.checksum:\n            # log.debug(\"Learner already knew fleet state {}; doing nothing.\".format(learner_fleet_state))  # 1712\n            headers = {'Content-Type': 'application/octet-stream'}\n            # No nodes in the response: same fleet state\n            response_payload = MetadataResponsePayload(timestamp_epoch=this_node.known_nodes.timestamp.epoch,\n                                                       announce_nodes=[])\n            response = MetadataResponse(this_node.stamp.as_umbral_signer(),\n                                        response_payload)\n            return Response(bytes(response), headers=headers)\n\n        if metadata_request.announce_nodes:\n            for metadata in metadata_request.announce_nodes:\n                try:\n                    metadata.verify()\n                except Exception:\n                    # inconsistent metadata\n                    pass\n                else:\n                    this_node.remember_node(NodeSprout(metadata))\n\n        # TODO: generate a new fleet state here?\n\n        # TODO: What's the right status code here?  202?  Different if we already knew about the node(s)?\n        return all_known_nodes()\n\n    @rest_app.route('/reencrypt', methods=[\"POST\"])\n    def reencrypt():\n        # TODO: Cache & Optimize\n        from nucypher.characters.lawful import Bob\n\n        # Deserialize and instantiate the request\n        reenc_request = ReencryptionRequest.from_bytes(request.data)\n\n        # Deserialize and instantiate ConditionLingo from the request data\n        lingos = _deserialize_rust_lingos(reenc_request=reenc_request)\n\n        # requester-supplied reencryption condition context\n        context = json.loads(str(reenc_request.context)) or dict()\n\n        # zip capsules with their respective conditions\n        packets = zip(reenc_request.capsules, lingos)\n\n        # TODO: Detect if we are dealing with PRE or tDec here\n        # TODO: This is for PRE only, relocate HRAC to RE.context\n        hrac = reenc_request.hrac\n\n        # This is either PRE Bob or a CBD requester\n        bob = Bob.from_public_keys(verifying_key=reenc_request.bob_verifying_key)\n        log.info(f\"Reencryption request from {bob} for policy {hrac}\")\n\n        # TODO: Can this be integrated into reencryption conditions?\n        # Stateful revocation by HRAC storage below\n        if hrac in this_node.revoked_policies:\n            return Response(response=f\"Policy with {hrac} has been revoked.\", status=HTTPStatus.UNAUTHORIZED)\n\n        # Alice or Publisher\n        publisher_verifying_key = reenc_request.publisher_verifying_key\n\n        # Bob\n        bob_ip_address = request.remote_addr\n        bob_identity_message = f\"[{bob_ip_address}] Bob({bytes(bob.stamp).hex()})\"\n\n        # Verify & Decrypt KFrag Payload\n        try:\n            verified_kfrag = this_node._decrypt_kfrag(\n                reenc_request.encrypted_kfrag,\n                hrac,\n                publisher_verifying_key\n            )\n        except DecryptingKeypair.DecryptionFailed as e:\n            # TODO: don't we want to record suspicious activities here too?\n            return Response(\n                response=f\"EncryptedKeyFrag decryption failed: {e}\",\n                status=HTTPStatus.FORBIDDEN,\n            )\n        except InvalidSignature as e:\n            message = f'{bob_identity_message} Invalid signature for KeyFrag: {e}.'\n            log.info(message)\n            # TODO (#567): bucket the node as suspicious\n            return Response(message, status=HTTPStatus.UNAUTHORIZED)  # 401 - Unauthorized\n        except Exception as e:\n            message = f'{bob_identity_message} Invalid EncryptedKeyFrag: {e}.'\n            log.info(message)\n            # TODO (#567): bucket the node as suspicious.\n            return Response(message, status=HTTPStatus.BAD_REQUEST)\n\n        # Enforce Reencryption Conditions\n        providers = this_node.condition_providers if not this_node.federated_only else dict()\n        capsules_to_process = list()\n        for capsule, condition_lingo in packets:\n            if condition_lingo:\n                error = evaluate_condition_lingo(\n                    lingo=condition_lingo,\n                    providers=providers,\n                    context=context\n                )\n                if error:\n                    # TODO: This response short-circuits the entire request on falsy condition\n                    #  even if other unrelated capsules (message kits) are present.\n                    return Response(error.message, status=error.status_code)\n            capsules_to_process.append(capsule)\n\n        # FIXME: DISABLED FOR PRE-adapted-TDEC\n        # TODO: Accept multiple payment methods?\n        # Subscription Manager\n        # paid = this_node.payment_method.verify(payee=this_node.checksum_address, request=reenc_request)\n        # if not paid:\n        #     message = f\"{bob_identity_message} Policy {bytes(hrac)} is unpaid.\"\n        #     return Response(message, status=HTTPStatus.PAYMENT_REQUIRED)\n\n        # Re-encrypt\n        # TODO: return a sensible response if it fails (currently results in 500)\n        response = this_node._reencrypt(kfrag=verified_kfrag, capsules=capsules_to_process)\n\n        headers = {'Content-Type': 'application/octet-stream'}\n        return Response(headers=headers, response=bytes(response))\n\n    @rest_app.route('/revoke', methods=['POST'])\n    def revoke():\n        revocation = RevocationOrder.from_bytes(request.data)\n        # TODO: Implement off-chain revocation.\n        return Response(status=HTTPStatus.OK)\n\n    @rest_app.route(\"/ping\", methods=['GET'])\n    def ping():\n        \"\"\"Asks this node: What is my IP address?\"\"\"\n        requester_ip_address = request.remote_addr\n        return Response(requester_ip_address, status=HTTPStatus.OK)\n\n    @rest_app.route(\"/check_availability\", methods=['POST'])\n    def check_availability():\n        \"\"\"Asks this node: Can you access my public information endpoint?\"\"\"\n        try:\n            requesting_ursula = Ursula.from_metadata_bytes(request.data)\n            requesting_ursula.mature()\n        except ValueError:\n            return Response({'error': 'Invalid Ursula'}, status=HTTPStatus.BAD_REQUEST)\n        else:\n            initiator_address, initiator_port = tuple(requesting_ursula.rest_interface)\n\n        # Compare requester and posted Ursula information\n        request_address = request.remote_addr\n        if request_address != initiator_address:\n            message = f'Origin address mismatch: Request origin is {request_address} but metadata claims {initiator_address}.'\n            return Response({'error': message}, status=HTTPStatus.BAD_REQUEST)\n\n        # Make a Sandwich\n        try:\n            requesting_ursula_metadata = this_node.network_middleware.client.node_information(\n                host=initiator_address,\n                port=initiator_port,\n            )\n        except NodeSeemsToBeDown:\n            return Response({'error': 'Unreachable node'}, status=HTTPStatus.BAD_REQUEST)  # ... toasted\n\n        # Compare the results of the outer POST with the inner GET... yum\n        if requesting_ursula_metadata == request.data:\n            return Response(status=HTTPStatus.OK)\n        else:\n            return Response({'error': 'Suspicious node'}, status=HTTPStatus.BAD_REQUEST)\n\n    @rest_app.route('/status/', methods=['GET'])\n    def status():\n        return_json = request.args.get('json') == 'true'\n        omit_known_nodes = request.args.get('omit_known_nodes') == 'true'\n        status_info = this_node.status_info(omit_known_nodes=omit_known_nodes)\n        if return_json:\n            return jsonify(status_info.to_json())\n        headers = {\"Content-Type\": \"text/html\", \"charset\": \"utf-8\"}\n        try:\n            content = status_template.render(status_info)\n        except Exception as e:\n            text_error = mako_exceptions.text_error_template().render()\n            html_error = mako_exceptions.html_error_template().render()\n            log.debug(\"Template Rendering Exception:\\n\" + text_error)\n            return Response(response=html_error, headers=headers, status=HTTPStatus.INTERNAL_SERVER_ERROR)\n        return Response(response=content, headers=headers)\n\n    return rest_app",
  "def __init__(self,\n                 rest_host: str,\n                 rest_port: int,\n                 hosting_power=None,\n                 rest_app=None\n                 ) -> None:\n\n        self.rest_interface = InterfaceInfo(host=rest_host, port=rest_port)\n        if rest_app:  # if is me\n            self.rest_app = rest_app\n        else:\n            self.rest_app = constants.PUBLIC_ONLY\n\n        self.__hosting_power = hosting_power",
  "def rest_url(self):\n        return \"{}:{}\".format(self.rest_interface.host, self.rest_interface.port)",
  "def public_information():\n        \"\"\"REST endpoint for public keys and address.\"\"\"\n        response = Response(response=bytes(this_node.metadata()), mimetype='application/octet-stream')\n        return response",
  "def all_known_nodes():\n        headers = {'Content-Type': 'application/octet-stream'}\n        if this_node._learning_deferred is not RELAX and not this_node._learning_task.running:\n            # Learn when learned about\n            this_node.start_learning_loop()\n\n        # All known nodes + this node\n        response_bytes = this_node.bytestring_of_known_nodes()\n        return Response(response_bytes, headers=headers)",
  "def node_metadata_exchange():\n\n        metadata_request = MetadataRequest.from_bytes(request.data)\n\n        # If these nodes already have the same fleet state, no exchange is necessary.\n\n        learner_fleet_state = request.args.get('fleet')\n        if metadata_request.fleet_state_checksum == this_node.known_nodes.checksum:\n            # log.debug(\"Learner already knew fleet state {}; doing nothing.\".format(learner_fleet_state))  # 1712\n            headers = {'Content-Type': 'application/octet-stream'}\n            # No nodes in the response: same fleet state\n            response_payload = MetadataResponsePayload(timestamp_epoch=this_node.known_nodes.timestamp.epoch,\n                                                       announce_nodes=[])\n            response = MetadataResponse(this_node.stamp.as_umbral_signer(),\n                                        response_payload)\n            return Response(bytes(response), headers=headers)\n\n        if metadata_request.announce_nodes:\n            for metadata in metadata_request.announce_nodes:\n                try:\n                    metadata.verify()\n                except Exception:\n                    # inconsistent metadata\n                    pass\n                else:\n                    this_node.remember_node(NodeSprout(metadata))\n\n        # TODO: generate a new fleet state here?\n\n        # TODO: What's the right status code here?  202?  Different if we already knew about the node(s)?\n        return all_known_nodes()",
  "def reencrypt():\n        # TODO: Cache & Optimize\n        from nucypher.characters.lawful import Bob\n\n        # Deserialize and instantiate the request\n        reenc_request = ReencryptionRequest.from_bytes(request.data)\n\n        # Deserialize and instantiate ConditionLingo from the request data\n        lingos = _deserialize_rust_lingos(reenc_request=reenc_request)\n\n        # requester-supplied reencryption condition context\n        context = json.loads(str(reenc_request.context)) or dict()\n\n        # zip capsules with their respective conditions\n        packets = zip(reenc_request.capsules, lingos)\n\n        # TODO: Detect if we are dealing with PRE or tDec here\n        # TODO: This is for PRE only, relocate HRAC to RE.context\n        hrac = reenc_request.hrac\n\n        # This is either PRE Bob or a CBD requester\n        bob = Bob.from_public_keys(verifying_key=reenc_request.bob_verifying_key)\n        log.info(f\"Reencryption request from {bob} for policy {hrac}\")\n\n        # TODO: Can this be integrated into reencryption conditions?\n        # Stateful revocation by HRAC storage below\n        if hrac in this_node.revoked_policies:\n            return Response(response=f\"Policy with {hrac} has been revoked.\", status=HTTPStatus.UNAUTHORIZED)\n\n        # Alice or Publisher\n        publisher_verifying_key = reenc_request.publisher_verifying_key\n\n        # Bob\n        bob_ip_address = request.remote_addr\n        bob_identity_message = f\"[{bob_ip_address}] Bob({bytes(bob.stamp).hex()})\"\n\n        # Verify & Decrypt KFrag Payload\n        try:\n            verified_kfrag = this_node._decrypt_kfrag(\n                reenc_request.encrypted_kfrag,\n                hrac,\n                publisher_verifying_key\n            )\n        except DecryptingKeypair.DecryptionFailed as e:\n            # TODO: don't we want to record suspicious activities here too?\n            return Response(\n                response=f\"EncryptedKeyFrag decryption failed: {e}\",\n                status=HTTPStatus.FORBIDDEN,\n            )\n        except InvalidSignature as e:\n            message = f'{bob_identity_message} Invalid signature for KeyFrag: {e}.'\n            log.info(message)\n            # TODO (#567): bucket the node as suspicious\n            return Response(message, status=HTTPStatus.UNAUTHORIZED)  # 401 - Unauthorized\n        except Exception as e:\n            message = f'{bob_identity_message} Invalid EncryptedKeyFrag: {e}.'\n            log.info(message)\n            # TODO (#567): bucket the node as suspicious.\n            return Response(message, status=HTTPStatus.BAD_REQUEST)\n\n        # Enforce Reencryption Conditions\n        providers = this_node.condition_providers if not this_node.federated_only else dict()\n        capsules_to_process = list()\n        for capsule, condition_lingo in packets:\n            if condition_lingo:\n                error = evaluate_condition_lingo(\n                    lingo=condition_lingo,\n                    providers=providers,\n                    context=context\n                )\n                if error:\n                    # TODO: This response short-circuits the entire request on falsy condition\n                    #  even if other unrelated capsules (message kits) are present.\n                    return Response(error.message, status=error.status_code)\n            capsules_to_process.append(capsule)\n\n        # FIXME: DISABLED FOR PRE-adapted-TDEC\n        # TODO: Accept multiple payment methods?\n        # Subscription Manager\n        # paid = this_node.payment_method.verify(payee=this_node.checksum_address, request=reenc_request)\n        # if not paid:\n        #     message = f\"{bob_identity_message} Policy {bytes(hrac)} is unpaid.\"\n        #     return Response(message, status=HTTPStatus.PAYMENT_REQUIRED)\n\n        # Re-encrypt\n        # TODO: return a sensible response if it fails (currently results in 500)\n        response = this_node._reencrypt(kfrag=verified_kfrag, capsules=capsules_to_process)\n\n        headers = {'Content-Type': 'application/octet-stream'}\n        return Response(headers=headers, response=bytes(response))",
  "def revoke():\n        revocation = RevocationOrder.from_bytes(request.data)\n        # TODO: Implement off-chain revocation.\n        return Response(status=HTTPStatus.OK)",
  "def ping():\n        \"\"\"Asks this node: What is my IP address?\"\"\"\n        requester_ip_address = request.remote_addr\n        return Response(requester_ip_address, status=HTTPStatus.OK)",
  "def check_availability():\n        \"\"\"Asks this node: Can you access my public information endpoint?\"\"\"\n        try:\n            requesting_ursula = Ursula.from_metadata_bytes(request.data)\n            requesting_ursula.mature()\n        except ValueError:\n            return Response({'error': 'Invalid Ursula'}, status=HTTPStatus.BAD_REQUEST)\n        else:\n            initiator_address, initiator_port = tuple(requesting_ursula.rest_interface)\n\n        # Compare requester and posted Ursula information\n        request_address = request.remote_addr\n        if request_address != initiator_address:\n            message = f'Origin address mismatch: Request origin is {request_address} but metadata claims {initiator_address}.'\n            return Response({'error': message}, status=HTTPStatus.BAD_REQUEST)\n\n        # Make a Sandwich\n        try:\n            requesting_ursula_metadata = this_node.network_middleware.client.node_information(\n                host=initiator_address,\n                port=initiator_port,\n            )\n        except NodeSeemsToBeDown:\n            return Response({'error': 'Unreachable node'}, status=HTTPStatus.BAD_REQUEST)  # ... toasted\n\n        # Compare the results of the outer POST with the inner GET... yum\n        if requesting_ursula_metadata == request.data:\n            return Response(status=HTTPStatus.OK)\n        else:\n            return Response({'error': 'Suspicious node'}, status=HTTPStatus.BAD_REQUEST)",
  "def status():\n        return_json = request.args.get('json') == 'true'\n        omit_known_nodes = request.args.get('omit_known_nodes') == 'true'\n        status_info = this_node.status_info(omit_known_nodes=omit_known_nodes)\n        if return_json:\n            return jsonify(status_info.to_json())\n        headers = {\"Content-Type\": \"text/html\", \"charset\": \"utf-8\"}\n        try:\n            content = status_template.render(status_info)\n        except Exception as e:\n            text_error = mako_exceptions.text_error_template().render()\n            html_error = mako_exceptions.html_error_template().render()\n            log.debug(\"Template Rendering Exception:\\n\" + text_error)\n            return Response(response=html_error, headers=headers, status=HTTPStatus.INTERNAL_SERVER_ERROR)\n        return Response(response=content, headers=headers)",
  "class RetrievalError:\n    def __init__(self, errors: Dict[ChecksumAddress, str]):\n        self.errors = errors",
  "class RetrievalPlan:\n    \"\"\"\n    An emphemeral object providing a service of selecting Ursulas for reencryption requests\n    during retrieval.\n    \"\"\"\n\n    def __init__(self, treasure_map: TreasureMap, retrieval_kits: Sequence[RetrievalKit]):\n\n        self._retrieval_kits = retrieval_kits\n        self._threshold = treasure_map.threshold\n\n        # Records the retrieval results, indexed by capsule\n        self._results = {\n            rk.capsule: {} for rk in retrieval_kits\n        }  # {capsule: {ursula_address: cfrag}}\n\n        # Records the retrieval result errors, indexed by capsule\n        self._errors = {\n            retrieval_kit.capsule: {} for retrieval_kit in retrieval_kits\n        }  # {capsule: {ursula_address: error}}\n\n        # Records the addresses of Ursulas that were already queried, indexed by capsule.\n        self._queried_addresses = {retrieval_kit.capsule: set(retrieval_kit.queried_addresses)\n                                   for retrieval_kit in retrieval_kits}\n\n        # Records the capsules already processed by a corresponding Ursula.\n        # An inverse of `_queried_addresses`.\n        self._processed_capsules = defaultdict(set) # {ursula_address: {capsule}}\n        for retrieval_kit in retrieval_kits:\n            for address in retrieval_kit.queried_addresses:\n                self._processed_capsules[address].add(retrieval_kit.capsule)\n\n        # If we've already retrieved from some addresses before, query them last.\n        # In other words, we try to get the maximum amount of cfrags in our first queries,\n        # to use the time more efficiently.\n        ursulas_to_contact_last = set()\n        for queried_addresses in self._queried_addresses.values():\n            ursulas_to_contact_last |= queried_addresses\n\n        # Randomize Ursulas' priorities\n        ursulas_pick_order = list(treasure_map.destinations) # checksum addresses\n        random.shuffle(ursulas_pick_order) # mutates list in-place\n\n        ursulas_pick_order = [ursula for ursula in ursulas_pick_order\n                              if ursula not in ursulas_to_contact_last]\n        self._ursulas_pick_order = ursulas_pick_order + list(ursulas_to_contact_last)\n\n    def get_work_order(self) -> 'RetrievalWorkOrder':\n        \"\"\"\n        Returns a new retrieval work order based on the current plan state.\n        \"\"\"\n        while self._ursulas_pick_order:\n            ursula_address = self._ursulas_pick_order.pop(0)\n            retrieval_kits: List[RetrievalKit] = list()\n            for rk in self._retrieval_kits:\n                # Only request reencryption for capsules that:\n                # - haven't been processed by this Ursula\n                processed = rk.capsule in self._processed_capsules.get(ursula_address, set())\n                # - don't already have cfrags from `threshold` Ursulas\n                enough = len(self._queried_addresses[rk.capsule]) >= self._threshold\n                if (not processed) and (not enough):\n                    retrieval_kits.append(rk)\n\n            if len(retrieval_kits) > 0:\n                return RetrievalWorkOrder(ursula_address=ursula_address, retrieval_kits=retrieval_kits)\n\n        # Execution will not reach this point if `is_complete()` returned `False` before this call.\n        raise RuntimeError(\"No Ursulas left\")\n\n    def update(self, work_order: 'RetrievalWorkOrder', cfrags: Dict[Capsule, VerifiedCapsuleFrag]):\n        \"\"\"\n        Updates the plan state, recording the cfrags obtained for capsules during a query.\n        \"\"\"\n        for capsule, cfrag in cfrags.items():\n            self._queried_addresses[capsule].add(work_order.ursula_address)\n            self._processed_capsules[work_order.ursula_address].add(capsule)\n            self._results[capsule][work_order.ursula_address] = cfrag\n\n    def update_errors(self,\n                      work_order: \"RetrievalWorkOrder\",\n                      ursula_address: ChecksumAddress,\n                      error_message: str):\n        for capsule in work_order.capsules:\n            self._errors[capsule][ursula_address] = error_message\n\n    def is_complete(self) -> bool:\n        return (\n            # there are no more Ursulas to query\n            not bool(self._ursulas_pick_order) or\n            # all the capsules have enough cfrags for decryption\n            all(len(addresses) >= self._threshold for addresses in self._queried_addresses.values())\n            )\n\n    def results(self) -> Tuple[List[\"RetrievalResult\"], List[RetrievalError]]:\n        results = []\n        errors = []\n        # maintain the same order with both lists\n        for rk in self._retrieval_kits:\n            results.append(\n                RetrievalResult(\n                    {\n                        to_checksum_address(bytes(address)): cfrag\n                        for address, cfrag in self._results[rk.capsule].items()\n                    }\n                )\n            )\n            errors.append(RetrievalError(errors=self._errors[rk.capsule]))\n\n        return results, errors",
  "class RetrievalWorkOrder:\n    \"\"\"A work order issued by a retrieval plan to request reencryption from an Ursula\"\"\"\n\n    def __init__(self, ursula_address: Address, retrieval_kits: List[RetrievalKit]):\n        self.ursula_address = ursula_address\n        self.__retrieval_kits = retrieval_kits\n\n    @property\n    def capsules(self) -> List[Capsule]:\n        return [rk.capsule for rk in self.__retrieval_kits]\n\n    @property\n    def lingos(self) -> Conditions:\n        _lingos = [rk.conditions for rk in self.__retrieval_kits]\n        rust_lingos = _serialize_rust_lingos(_lingos)\n        return rust_lingos",
  "class RetrievalClient:\n    \"\"\"\n    Capsule frag retrieval machinery shared between Bob and Porter.\n    \"\"\"\n\n    def __init__(self, learner: Learner):\n        self._learner = learner\n        self.log = Logger(self.__class__.__name__)\n\n    def _ensure_ursula_availability(self, treasure_map: TreasureMap, timeout=10):\n        \"\"\"\n        Make sure we know enough nodes from the treasure map to decrypt;\n        otherwise block and wait for them to come online.\n        \"\"\"\n\n        # OK, so we're going to need to do some network activity for this retrieval.\n        # Let's make sure we've seeded.\n        if not self._learner.done_seeding:\n            self._learner.learn_from_teacher_node()\n\n        ursulas_in_map = treasure_map.destinations.keys()\n\n        # TODO (#1995): when that issue is fixed, conversion is no longer needed\n        ursulas_in_map = [to_checksum_address(bytes(address)) for address in ursulas_in_map]\n\n        all_known_ursulas = self._learner.known_nodes.addresses()\n\n        # Push all unknown Ursulas from the map in the queue for learning\n        unknown_ursulas = ursulas_in_map - all_known_ursulas\n\n        # If we know enough to decrypt, we can proceed.\n        known_ursulas = ursulas_in_map & all_known_ursulas\n        if len(known_ursulas) >= treasure_map.threshold:\n            return\n\n        # | <--- shares                                            ---> |\n        # | <--- threshold               ---> | <--- allow_missing ---> |\n        # | <--- known_ursulas ---> | <--- unknown_ursulas         ---> |\n        allow_missing = len(treasure_map.destinations) - treasure_map.threshold\n        self._learner.block_until_specific_nodes_are_known(unknown_ursulas,\n                                                           timeout=timeout,\n                                                           allow_missing=allow_missing,\n                                                           learn_on_this_thread=True)\n\n    def _request_reencryption(self,\n                              ursula: 'Ursula',\n                              reencryption_request: ReencryptionRequest,\n                              alice_verifying_key: PublicKey,\n                              policy_encrypting_key: PublicKey,\n                              bob_encrypting_key: PublicKey,\n                              ) -> Dict['Capsule', 'VerifiedCapsuleFrag']:\n        \"\"\"\n        Sends a reencryption request to a single Ursula and processes the results.\n\n        Returns reencrypted capsule frags matched to corresponding capsules.\n        \"\"\"\n\n        middleware = self._learner.network_middleware\n\n        try:\n            response = middleware.reencrypt(ursula, bytes(reencryption_request))\n        except NodeSeemsToBeDown as e:\n            # TODO: What to do here?  Ursula isn't supposed to be down.  NRN\n            message = (f\"Ursula ({ursula}) seems to be down \"\n                       f\"while trying to complete ReencryptionRequest: {reencryption_request}\")\n            self.log.info(message)\n            raise RuntimeError(message) from e\n        except middleware.NotFound as e:\n            # This Ursula claims not to have a matching KFrag.  Maybe this has been revoked?\n            # TODO: What's the thing to do here?\n            # Do we want to track these Ursulas in some way in case they're lying?  #567\n            message = (f\"Ursula ({ursula}) claims not to not know of the policy {reencryption_request.hrac}. \"\n                       f\"Has access been revoked?\")\n            self.log.warn(message)\n            raise RuntimeError(message) from e\n        except middleware.UnexpectedResponse:\n            raise  # TODO: Handle this\n\n        try:\n            reencryption_response = ReencryptionResponse.from_bytes(response.content)\n        except Exception as e:\n            message = f\"Ursula ({ursula}) returned an invalid response: {e}.\"\n            self.log.warn(message)\n            raise RuntimeError(message)\n\n        ursula_verifying_key = ursula.stamp.as_umbral_pubkey()\n\n        try:\n            verified_cfrags = reencryption_response.verify(capsules=reencryption_request.capsules,\n                                                           alice_verifying_key=alice_verifying_key,\n                                                           ursula_verifying_key=ursula_verifying_key,\n                                                           policy_encrypting_key=policy_encrypting_key,\n                                                           bob_encrypting_key=bob_encrypting_key)\n        except InvalidSignature as e:\n            self.log.warn(f\"Invalid signature for ReencryptionResponse: {e}\")\n            raise\n        except VerificationError as e:\n            # In future we may want to remember this Ursula and do something about it\n            self.log.warn(\n                f\"Failed to verify capsule frags in the ReencryptionResponse: {e}\"\n            )\n            raise\n        except Exception as e:\n            message = f\"Failed to verify the ReencryptionResponse ({e.__class__.__name__}): {e}\"\n            self.log.warn(message)\n            raise RuntimeError(message)\n\n        return {capsule: vcfrag for capsule, vcfrag\n                in zip(reencryption_request.capsules, verified_cfrags)}\n\n    def retrieve_cfrags(self,\n                        treasure_map: TreasureMap,\n                        retrieval_kits: Sequence[RetrievalKit],\n                        alice_verifying_key: PublicKey,  # KeyFrag signer's key\n                        bob_encrypting_key: PublicKey,  # User's public key (reencryption target)\n                        bob_verifying_key: PublicKey,\n                        **context) -> Tuple[List[RetrievalResult], List[RetrievalError]]:\n\n        self._ensure_ursula_availability(treasure_map)\n\n        retrieval_plan = RetrievalPlan(treasure_map=treasure_map, retrieval_kits=retrieval_kits)\n\n        while not retrieval_plan.is_complete():\n            # TODO (#2789): Currently we'll only query one Ursula once during the retrieval.\n            # Alternatively we may re-query Ursulas that were offline until the timeout expires.\n\n            work_order = retrieval_plan.get_work_order()\n\n            # TODO (#1995): when that issue is fixed, conversion is no longer needed\n            ursula_checksum_address = to_checksum_address(bytes(work_order.ursula_address))\n\n            if ursula_checksum_address not in self._learner.known_nodes:\n                continue\n\n            ursula = self._learner.known_nodes[ursula_checksum_address]\n\n            try:\n                request_context_string = json.dumps(context)\n            except TypeError:\n                raise InvalidConditionContext(\"'context' must be JSON serializable.\")\n\n            reencryption_request = ReencryptionRequest(\n                capsules=work_order.capsules,\n                conditions=work_order.lingos,\n                context=Context(request_context_string),\n                hrac=treasure_map.hrac,\n                encrypted_kfrag=treasure_map.destinations[work_order.ursula_address],\n                bob_verifying_key=bob_verifying_key,\n                publisher_verifying_key=treasure_map.publisher_verifying_key\n            )\n\n            try:\n                cfrags = self._request_reencryption(ursula=ursula,\n                                                    reencryption_request=reencryption_request,\n                                                    alice_verifying_key=alice_verifying_key,\n                                                    policy_encrypting_key=treasure_map.policy_encrypting_key,\n                                                    bob_encrypting_key=bob_encrypting_key)\n            except Exception as e:\n                exception_message = f\"{e.__class__.__name__}: {e}\"\n                retrieval_plan.update_errors(\n                    work_order, ursula_checksum_address, exception_message\n                )\n                self.log.warn(\n                    f\"Ursula {ursula} failed to reencrypt; {exception_message}\"\n                )\n                continue\n\n            retrieval_plan.update(work_order, cfrags)\n\n        return retrieval_plan.results()",
  "def __init__(self, errors: Dict[ChecksumAddress, str]):\n        self.errors = errors",
  "def __init__(self, treasure_map: TreasureMap, retrieval_kits: Sequence[RetrievalKit]):\n\n        self._retrieval_kits = retrieval_kits\n        self._threshold = treasure_map.threshold\n\n        # Records the retrieval results, indexed by capsule\n        self._results = {\n            rk.capsule: {} for rk in retrieval_kits\n        }  # {capsule: {ursula_address: cfrag}}\n\n        # Records the retrieval result errors, indexed by capsule\n        self._errors = {\n            retrieval_kit.capsule: {} for retrieval_kit in retrieval_kits\n        }  # {capsule: {ursula_address: error}}\n\n        # Records the addresses of Ursulas that were already queried, indexed by capsule.\n        self._queried_addresses = {retrieval_kit.capsule: set(retrieval_kit.queried_addresses)\n                                   for retrieval_kit in retrieval_kits}\n\n        # Records the capsules already processed by a corresponding Ursula.\n        # An inverse of `_queried_addresses`.\n        self._processed_capsules = defaultdict(set) # {ursula_address: {capsule}}\n        for retrieval_kit in retrieval_kits:\n            for address in retrieval_kit.queried_addresses:\n                self._processed_capsules[address].add(retrieval_kit.capsule)\n\n        # If we've already retrieved from some addresses before, query them last.\n        # In other words, we try to get the maximum amount of cfrags in our first queries,\n        # to use the time more efficiently.\n        ursulas_to_contact_last = set()\n        for queried_addresses in self._queried_addresses.values():\n            ursulas_to_contact_last |= queried_addresses\n\n        # Randomize Ursulas' priorities\n        ursulas_pick_order = list(treasure_map.destinations) # checksum addresses\n        random.shuffle(ursulas_pick_order) # mutates list in-place\n\n        ursulas_pick_order = [ursula for ursula in ursulas_pick_order\n                              if ursula not in ursulas_to_contact_last]\n        self._ursulas_pick_order = ursulas_pick_order + list(ursulas_to_contact_last)",
  "def get_work_order(self) -> 'RetrievalWorkOrder':\n        \"\"\"\n        Returns a new retrieval work order based on the current plan state.\n        \"\"\"\n        while self._ursulas_pick_order:\n            ursula_address = self._ursulas_pick_order.pop(0)\n            retrieval_kits: List[RetrievalKit] = list()\n            for rk in self._retrieval_kits:\n                # Only request reencryption for capsules that:\n                # - haven't been processed by this Ursula\n                processed = rk.capsule in self._processed_capsules.get(ursula_address, set())\n                # - don't already have cfrags from `threshold` Ursulas\n                enough = len(self._queried_addresses[rk.capsule]) >= self._threshold\n                if (not processed) and (not enough):\n                    retrieval_kits.append(rk)\n\n            if len(retrieval_kits) > 0:\n                return RetrievalWorkOrder(ursula_address=ursula_address, retrieval_kits=retrieval_kits)\n\n        # Execution will not reach this point if `is_complete()` returned `False` before this call.\n        raise RuntimeError(\"No Ursulas left\")",
  "def update(self, work_order: 'RetrievalWorkOrder', cfrags: Dict[Capsule, VerifiedCapsuleFrag]):\n        \"\"\"\n        Updates the plan state, recording the cfrags obtained for capsules during a query.\n        \"\"\"\n        for capsule, cfrag in cfrags.items():\n            self._queried_addresses[capsule].add(work_order.ursula_address)\n            self._processed_capsules[work_order.ursula_address].add(capsule)\n            self._results[capsule][work_order.ursula_address] = cfrag",
  "def update_errors(self,\n                      work_order: \"RetrievalWorkOrder\",\n                      ursula_address: ChecksumAddress,\n                      error_message: str):\n        for capsule in work_order.capsules:\n            self._errors[capsule][ursula_address] = error_message",
  "def is_complete(self) -> bool:\n        return (\n            # there are no more Ursulas to query\n            not bool(self._ursulas_pick_order) or\n            # all the capsules have enough cfrags for decryption\n            all(len(addresses) >= self._threshold for addresses in self._queried_addresses.values())\n            )",
  "def results(self) -> Tuple[List[\"RetrievalResult\"], List[RetrievalError]]:\n        results = []\n        errors = []\n        # maintain the same order with both lists\n        for rk in self._retrieval_kits:\n            results.append(\n                RetrievalResult(\n                    {\n                        to_checksum_address(bytes(address)): cfrag\n                        for address, cfrag in self._results[rk.capsule].items()\n                    }\n                )\n            )\n            errors.append(RetrievalError(errors=self._errors[rk.capsule]))\n\n        return results, errors",
  "def __init__(self, ursula_address: Address, retrieval_kits: List[RetrievalKit]):\n        self.ursula_address = ursula_address\n        self.__retrieval_kits = retrieval_kits",
  "def capsules(self) -> List[Capsule]:\n        return [rk.capsule for rk in self.__retrieval_kits]",
  "def lingos(self) -> Conditions:\n        _lingos = [rk.conditions for rk in self.__retrieval_kits]\n        rust_lingos = _serialize_rust_lingos(_lingos)\n        return rust_lingos",
  "def __init__(self, learner: Learner):\n        self._learner = learner\n        self.log = Logger(self.__class__.__name__)",
  "def _ensure_ursula_availability(self, treasure_map: TreasureMap, timeout=10):\n        \"\"\"\n        Make sure we know enough nodes from the treasure map to decrypt;\n        otherwise block and wait for them to come online.\n        \"\"\"\n\n        # OK, so we're going to need to do some network activity for this retrieval.\n        # Let's make sure we've seeded.\n        if not self._learner.done_seeding:\n            self._learner.learn_from_teacher_node()\n\n        ursulas_in_map = treasure_map.destinations.keys()\n\n        # TODO (#1995): when that issue is fixed, conversion is no longer needed\n        ursulas_in_map = [to_checksum_address(bytes(address)) for address in ursulas_in_map]\n\n        all_known_ursulas = self._learner.known_nodes.addresses()\n\n        # Push all unknown Ursulas from the map in the queue for learning\n        unknown_ursulas = ursulas_in_map - all_known_ursulas\n\n        # If we know enough to decrypt, we can proceed.\n        known_ursulas = ursulas_in_map & all_known_ursulas\n        if len(known_ursulas) >= treasure_map.threshold:\n            return\n\n        # | <--- shares                                            ---> |\n        # | <--- threshold               ---> | <--- allow_missing ---> |\n        # | <--- known_ursulas ---> | <--- unknown_ursulas         ---> |\n        allow_missing = len(treasure_map.destinations) - treasure_map.threshold\n        self._learner.block_until_specific_nodes_are_known(unknown_ursulas,\n                                                           timeout=timeout,\n                                                           allow_missing=allow_missing,\n                                                           learn_on_this_thread=True)",
  "def _request_reencryption(self,\n                              ursula: 'Ursula',\n                              reencryption_request: ReencryptionRequest,\n                              alice_verifying_key: PublicKey,\n                              policy_encrypting_key: PublicKey,\n                              bob_encrypting_key: PublicKey,\n                              ) -> Dict['Capsule', 'VerifiedCapsuleFrag']:\n        \"\"\"\n        Sends a reencryption request to a single Ursula and processes the results.\n\n        Returns reencrypted capsule frags matched to corresponding capsules.\n        \"\"\"\n\n        middleware = self._learner.network_middleware\n\n        try:\n            response = middleware.reencrypt(ursula, bytes(reencryption_request))\n        except NodeSeemsToBeDown as e:\n            # TODO: What to do here?  Ursula isn't supposed to be down.  NRN\n            message = (f\"Ursula ({ursula}) seems to be down \"\n                       f\"while trying to complete ReencryptionRequest: {reencryption_request}\")\n            self.log.info(message)\n            raise RuntimeError(message) from e\n        except middleware.NotFound as e:\n            # This Ursula claims not to have a matching KFrag.  Maybe this has been revoked?\n            # TODO: What's the thing to do here?\n            # Do we want to track these Ursulas in some way in case they're lying?  #567\n            message = (f\"Ursula ({ursula}) claims not to not know of the policy {reencryption_request.hrac}. \"\n                       f\"Has access been revoked?\")\n            self.log.warn(message)\n            raise RuntimeError(message) from e\n        except middleware.UnexpectedResponse:\n            raise  # TODO: Handle this\n\n        try:\n            reencryption_response = ReencryptionResponse.from_bytes(response.content)\n        except Exception as e:\n            message = f\"Ursula ({ursula}) returned an invalid response: {e}.\"\n            self.log.warn(message)\n            raise RuntimeError(message)\n\n        ursula_verifying_key = ursula.stamp.as_umbral_pubkey()\n\n        try:\n            verified_cfrags = reencryption_response.verify(capsules=reencryption_request.capsules,\n                                                           alice_verifying_key=alice_verifying_key,\n                                                           ursula_verifying_key=ursula_verifying_key,\n                                                           policy_encrypting_key=policy_encrypting_key,\n                                                           bob_encrypting_key=bob_encrypting_key)\n        except InvalidSignature as e:\n            self.log.warn(f\"Invalid signature for ReencryptionResponse: {e}\")\n            raise\n        except VerificationError as e:\n            # In future we may want to remember this Ursula and do something about it\n            self.log.warn(\n                f\"Failed to verify capsule frags in the ReencryptionResponse: {e}\"\n            )\n            raise\n        except Exception as e:\n            message = f\"Failed to verify the ReencryptionResponse ({e.__class__.__name__}): {e}\"\n            self.log.warn(message)\n            raise RuntimeError(message)\n\n        return {capsule: vcfrag for capsule, vcfrag\n                in zip(reencryption_request.capsules, verified_cfrags)}",
  "def retrieve_cfrags(self,\n                        treasure_map: TreasureMap,\n                        retrieval_kits: Sequence[RetrievalKit],\n                        alice_verifying_key: PublicKey,  # KeyFrag signer's key\n                        bob_encrypting_key: PublicKey,  # User's public key (reencryption target)\n                        bob_verifying_key: PublicKey,\n                        **context) -> Tuple[List[RetrievalResult], List[RetrievalError]]:\n\n        self._ensure_ursula_availability(treasure_map)\n\n        retrieval_plan = RetrievalPlan(treasure_map=treasure_map, retrieval_kits=retrieval_kits)\n\n        while not retrieval_plan.is_complete():\n            # TODO (#2789): Currently we'll only query one Ursula once during the retrieval.\n            # Alternatively we may re-query Ursulas that were offline until the timeout expires.\n\n            work_order = retrieval_plan.get_work_order()\n\n            # TODO (#1995): when that issue is fixed, conversion is no longer needed\n            ursula_checksum_address = to_checksum_address(bytes(work_order.ursula_address))\n\n            if ursula_checksum_address not in self._learner.known_nodes:\n                continue\n\n            ursula = self._learner.known_nodes[ursula_checksum_address]\n\n            try:\n                request_context_string = json.dumps(context)\n            except TypeError:\n                raise InvalidConditionContext(\"'context' must be JSON serializable.\")\n\n            reencryption_request = ReencryptionRequest(\n                capsules=work_order.capsules,\n                conditions=work_order.lingos,\n                context=Context(request_context_string),\n                hrac=treasure_map.hrac,\n                encrypted_kfrag=treasure_map.destinations[work_order.ursula_address],\n                bob_verifying_key=bob_verifying_key,\n                publisher_verifying_key=treasure_map.publisher_verifying_key\n            )\n\n            try:\n                cfrags = self._request_reencryption(ursula=ursula,\n                                                    reencryption_request=reencryption_request,\n                                                    alice_verifying_key=alice_verifying_key,\n                                                    policy_encrypting_key=treasure_map.policy_encrypting_key,\n                                                    bob_encrypting_key=bob_encrypting_key)\n            except Exception as e:\n                exception_message = f\"{e.__class__.__name__}: {e}\"\n                retrieval_plan.update_errors(\n                    work_order, ursula_checksum_address, exception_message\n                )\n                self.log.warn(\n                    f\"Ursula {ursula} failed to reencrypt; {exception_message}\"\n                )\n                continue\n\n            retrieval_plan.update(work_order, cfrags)\n\n        return retrieval_plan.results()",
  "class NucypherMiddlewareClient:\n    library = requests\n    timeout = 1.2\n\n    def __init__(self,\n                 registry: Optional['BaseContractRegistry'] = None,\n                 eth_provider_uri: Optional[str] = None,\n                 storage: Optional['NodeStorage'] = None,\n                 *args, **kwargs):\n\n        self.registry = registry\n        self.eth_provider_uri = eth_provider_uri\n        self.storage = storage or ForgetfulNodeStorage()  # for certificate storage\n\n    def get_certificate(self,\n                        host,\n                        port,\n                        timeout=4,\n                        retry_attempts: int = 3,\n                        retry_rate: int = 2,\n                        current_attempt: int = 0):\n\n        socket.setdefaulttimeout(timeout)  # Set Socket Timeout\n\n        try:\n            SSL_LOGGER.debug(f\"Fetching {host}:{port} TLS certificate\")\n            certificate_pem = ssl.get_server_certificate(addr=(host, port))\n            certificate = ssl.PEM_cert_to_DER_cert(certificate_pem)\n\n        except socket.timeout:\n            if current_attempt == retry_attempts:\n                message = f\"No Response from {host}:{port} after {retry_attempts} attempts\"\n                SSL_LOGGER.info(message)\n                raise ConnectionRefusedError(\"No response from {}:{}\".format(host, port))\n            SSL_LOGGER.info(f\"No Response from {host}:{port}. Retrying in {retry_rate} seconds...\")\n            time.sleep(retry_rate)\n            return self.get_certificate(host, port, timeout, retry_attempts, retry_rate, current_attempt + 1)\n\n        except OSError:\n            raise  # TODO: #1835\n\n        certificate = x509.load_der_x509_certificate(certificate, backend=default_backend())\n        filepath = self.storage.store_node_certificate(certificate=certificate, port=port)\n        return certificate, filepath\n\n    @staticmethod\n    def response_cleaner(response):\n        return response\n\n    def verify_and_parse_node_or_host_and_port(self, node_or_sprout, host, port):\n        \"\"\"\n        Does two things:\n        1) Verifies the node (unless it is EXEMPT_FROM_VERIFICATION, like when we initially get its certificate)\n        2) Parses the node into a host and port, or returns the provided host and port.\n        :return: A 3-tuple: host string, certificate, and the library to be used for the connection.\n        \"\"\"\n        if node_or_sprout:\n            if node_or_sprout is not EXEMPT_FROM_VERIFICATION:\n                node = node_or_sprout.mature()  # Morph into a node.\n                node.verify_node(network_middleware_client=self, registry=self.registry, eth_provider_uri=self.eth_provider_uri)\n        return self.parse_node_or_host_and_port(node_or_sprout, host, port)\n\n    def parse_node_or_host_and_port(self, node, host, port):\n        if node:\n            if any((host, port)):\n                raise ValueError(\"Don't pass host and port if you are passing the node.\")\n            host, port = node.rest_interface.host, node.rest_interface.port\n        elif not (host and port):\n            raise ValueError(\"You need to pass either the node or a host and port.\")\n        return host, port, self.library\n\n    def invoke_method(self, method, url, *args, **kwargs):\n        self.clean_params(kwargs)\n        if not kwargs.get(\"timeout\"):\n            if self.timeout:\n                kwargs[\"timeout\"] = self.timeout\n        response = method(url, *args, **kwargs)\n        return response\n\n    def clean_params(self, request_kwargs):\n        \"\"\"\n        No cleaning needed.\n        \"\"\"\n\n    def node_information(self, host, port):\n        # The only time a node is exempt from verification - when we are first getting its info.\n        response = self.get(node_or_sprout=EXEMPT_FROM_VERIFICATION,\n                            host=host, port=port,\n                            path=\"public_information\",\n                            timeout=2)\n        return response.content\n\n    def __getattr__(self, method_name):\n        # Quick sanity check.\n        if method_name not in (\"post\", \"get\", \"put\", \"patch\", \"delete\"):\n            raise TypeError(f\"This client is for HTTP only - you need to use a real HTTP verb, not '{method_name}'.\")\n\n        def method_wrapper(path,\n                           node_or_sprout=None,\n                           host=None,\n                           port=None,\n                           *args, **kwargs):\n\n            # Get interface\n            host, port, http_client = self.verify_and_parse_node_or_host_and_port(node_or_sprout, host, port)\n            endpoint = f\"https://{host}:{port}/{path}\"\n            method = getattr(http_client, method_name)\n\n            response = self._execute_method(node_or_sprout,\n                                            host,\n                                            port,\n                                            method,\n                                            endpoint,\n                                            *args,\n                                            **kwargs)\n            # Handle response\n            cleaned_response = self.response_cleaner(response)\n            if cleaned_response.status_code >= 300:\n\n                if cleaned_response.status_code == HTTPStatus.BAD_REQUEST:\n                    raise RestMiddleware.BadRequest(reason=cleaned_response.content)\n\n                elif cleaned_response.status_code == HTTPStatus.NOT_FOUND:\n                    m = f\"While trying to {method_name} {args} ({kwargs}), server 404'd.  Response: {cleaned_response.content}\"\n                    raise RestMiddleware.NotFound(m)\n\n                elif cleaned_response.status_code == HTTPStatus.PAYMENT_REQUIRED:\n                    # TODO: Use this as a hook to prompt Bob's payment for policy sponsorship\n                    # https://getyarn.io/yarn-clip/ce0d37ba-4984-4210-9a40-c9c9859a3164\n                    raise RestMiddleware.PaymentRequired(cleaned_response.content)\n\n                elif cleaned_response.status_code == HTTPStatus.FORBIDDEN:\n                    raise RestMiddleware.Unauthorized(cleaned_response.content)\n\n                else:\n                    raise RestMiddleware.UnexpectedResponse(cleaned_response.content, status=cleaned_response.status_code)\n\n            return cleaned_response\n\n        return method_wrapper\n\n    def _execute_method(self,\n                        node_or_sprout,\n                        host,\n                        port,\n                        method,\n                        endpoint,\n                        *args, **kwargs):\n        # Use existing cached SSL certificate or fetch fresh copy and retry\n        cached_cert_filepath = Path(self.storage.generate_certificate_filepath(host=host, port=port))\n        if cached_cert_filepath.exists():\n            # already cached try it\n            try:\n                # Send request\n                response = self.invoke_method(method, endpoint, verify=cached_cert_filepath,\n                                              *args, **kwargs)\n\n                # successful use of cached certificate\n                return response\n            except SSLError as e:\n                # ignore this exception - probably means that our cached cert may not be up-to-date.\n                SSL_LOGGER.debug(f\"Cached cert for {host}:{port} is invalid {e}\")\n\n        # Fetch fresh copy of SSL certificate\n        try:\n            certificate, filepath = self.get_certificate(host=host, port=port)\n        except NodeSeemsToBeDown as e:\n            raise RestMiddleware.Unreachable(\n                message=f'Node {node_or_sprout} {host}:{port} is unreachable: {e}')\n\n        # Send request\n        response = self.invoke_method(method, endpoint, verify=filepath,\n                                      *args, **kwargs)\n        return response\n\n    def node_selector(self, node):\n        return node.rest_url(), self.library\n\n    def __len__(self):\n        return 0",
  "class RestMiddleware:\n    log = Logger()\n\n    _client_class = NucypherMiddlewareClient\n\n    class Unreachable(Exception):\n        def __init__(self, message, *args, **kwargs):\n            super().__init__(message, *args, **kwargs)\n\n    class UnexpectedResponse(Exception):\n        def __init__(self, message, status, *args, **kwargs):\n            super().__init__(message, *args, **kwargs)\n            self.status = status\n\n    class NotFound(UnexpectedResponse):\n        def __init__(self, *args, **kwargs):\n            super().__init__(status=HTTPStatus.NOT_FOUND, *args, **kwargs)\n\n    class BadRequest(UnexpectedResponse):\n        def __init__(self, reason, *args, **kwargs):\n            self.reason = reason\n            super().__init__(message=reason, status=HTTPStatus.BAD_REQUEST, *args, **kwargs)\n\n    class PaymentRequired(UnexpectedResponse):\n        \"\"\"Raised for HTTP 402\"\"\"\n        def __init__(self, *args, **kwargs):\n            super().__init__(status=HTTPStatus.PAYMENT_REQUIRED, *args, **kwargs)\n\n    class Unauthorized(UnexpectedResponse):\n        \"\"\"Raised for HTTP 403\"\"\"\n        def __init__(self, *args, **kwargs):\n            super().__init__(status=HTTPStatus.FORBIDDEN, *args, **kwargs)\n\n    def __init__(self, registry=None, eth_provider_uri: str = None):\n        self.client = self._client_class(registry=registry, eth_provider_uri=eth_provider_uri)\n\n    def request_revocation(self, ursula, revocation):\n        # TODO: Implement offchain revocation #2787\n        response = self.client.post(\n            node_or_sprout=ursula,\n            path=f\"revoke\",\n            data=bytes(revocation),\n        )\n        return response\n\n    def reencrypt(self, ursula: 'Ursula', reencryption_request_bytes: bytes):\n        response = self.client.post(\n            node_or_sprout=ursula,\n            path=f\"reencrypt\",\n            data=reencryption_request_bytes,\n            timeout=2\n        )\n        return response\n\n    def check_availability(self, initiator, responder):\n        response = self.client.post(node_or_sprout=responder,\n                                    data=bytes(initiator.metatada()),\n                                    path=\"check_availability\",\n                                    timeout=6,  # Two round trips are expected\n                                    )\n        return response\n\n    def ping(self, node):\n        response = self.client.get(node_or_sprout=node, path=\"ping\", timeout=2)\n        return response\n\n    def get_nodes_via_rest(self,\n                           node,\n                           fleet_state_checksum: FleetStateChecksum,\n                           announce_nodes: Sequence[NodeMetadata]):\n\n        request = MetadataRequest(fleet_state_checksum=fleet_state_checksum,\n                                  announce_nodes=announce_nodes)\n        response = self.client.post(node_or_sprout=node,\n                                    path=\"node_metadata\",\n                                    data=bytes(request),\n                                    )\n        return response",
  "def __init__(self,\n                 registry: Optional['BaseContractRegistry'] = None,\n                 eth_provider_uri: Optional[str] = None,\n                 storage: Optional['NodeStorage'] = None,\n                 *args, **kwargs):\n\n        self.registry = registry\n        self.eth_provider_uri = eth_provider_uri\n        self.storage = storage or ForgetfulNodeStorage()",
  "def get_certificate(self,\n                        host,\n                        port,\n                        timeout=4,\n                        retry_attempts: int = 3,\n                        retry_rate: int = 2,\n                        current_attempt: int = 0):\n\n        socket.setdefaulttimeout(timeout)  # Set Socket Timeout\n\n        try:\n            SSL_LOGGER.debug(f\"Fetching {host}:{port} TLS certificate\")\n            certificate_pem = ssl.get_server_certificate(addr=(host, port))\n            certificate = ssl.PEM_cert_to_DER_cert(certificate_pem)\n\n        except socket.timeout:\n            if current_attempt == retry_attempts:\n                message = f\"No Response from {host}:{port} after {retry_attempts} attempts\"\n                SSL_LOGGER.info(message)\n                raise ConnectionRefusedError(\"No response from {}:{}\".format(host, port))\n            SSL_LOGGER.info(f\"No Response from {host}:{port}. Retrying in {retry_rate} seconds...\")\n            time.sleep(retry_rate)\n            return self.get_certificate(host, port, timeout, retry_attempts, retry_rate, current_attempt + 1)\n\n        except OSError:\n            raise  # TODO: #1835\n\n        certificate = x509.load_der_x509_certificate(certificate, backend=default_backend())\n        filepath = self.storage.store_node_certificate(certificate=certificate, port=port)\n        return certificate, filepath",
  "def response_cleaner(response):\n        return response",
  "def verify_and_parse_node_or_host_and_port(self, node_or_sprout, host, port):\n        \"\"\"\n        Does two things:\n        1) Verifies the node (unless it is EXEMPT_FROM_VERIFICATION, like when we initially get its certificate)\n        2) Parses the node into a host and port, or returns the provided host and port.\n        :return: A 3-tuple: host string, certificate, and the library to be used for the connection.\n        \"\"\"\n        if node_or_sprout:\n            if node_or_sprout is not EXEMPT_FROM_VERIFICATION:\n                node = node_or_sprout.mature()  # Morph into a node.\n                node.verify_node(network_middleware_client=self, registry=self.registry, eth_provider_uri=self.eth_provider_uri)\n        return self.parse_node_or_host_and_port(node_or_sprout, host, port)",
  "def parse_node_or_host_and_port(self, node, host, port):\n        if node:\n            if any((host, port)):\n                raise ValueError(\"Don't pass host and port if you are passing the node.\")\n            host, port = node.rest_interface.host, node.rest_interface.port\n        elif not (host and port):\n            raise ValueError(\"You need to pass either the node or a host and port.\")\n        return host, port, self.library",
  "def invoke_method(self, method, url, *args, **kwargs):\n        self.clean_params(kwargs)\n        if not kwargs.get(\"timeout\"):\n            if self.timeout:\n                kwargs[\"timeout\"] = self.timeout\n        response = method(url, *args, **kwargs)\n        return response",
  "def clean_params(self, request_kwargs):\n        \"\"\"\n        No cleaning needed.\n        \"\"\"",
  "def node_information(self, host, port):\n        # The only time a node is exempt from verification - when we are first getting its info.\n        response = self.get(node_or_sprout=EXEMPT_FROM_VERIFICATION,\n                            host=host, port=port,\n                            path=\"public_information\",\n                            timeout=2)\n        return response.content",
  "def __getattr__(self, method_name):\n        # Quick sanity check.\n        if method_name not in (\"post\", \"get\", \"put\", \"patch\", \"delete\"):\n            raise TypeError(f\"This client is for HTTP only - you need to use a real HTTP verb, not '{method_name}'.\")\n\n        def method_wrapper(path,\n                           node_or_sprout=None,\n                           host=None,\n                           port=None,\n                           *args, **kwargs):\n\n            # Get interface\n            host, port, http_client = self.verify_and_parse_node_or_host_and_port(node_or_sprout, host, port)\n            endpoint = f\"https://{host}:{port}/{path}\"\n            method = getattr(http_client, method_name)\n\n            response = self._execute_method(node_or_sprout,\n                                            host,\n                                            port,\n                                            method,\n                                            endpoint,\n                                            *args,\n                                            **kwargs)\n            # Handle response\n            cleaned_response = self.response_cleaner(response)\n            if cleaned_response.status_code >= 300:\n\n                if cleaned_response.status_code == HTTPStatus.BAD_REQUEST:\n                    raise RestMiddleware.BadRequest(reason=cleaned_response.content)\n\n                elif cleaned_response.status_code == HTTPStatus.NOT_FOUND:\n                    m = f\"While trying to {method_name} {args} ({kwargs}), server 404'd.  Response: {cleaned_response.content}\"\n                    raise RestMiddleware.NotFound(m)\n\n                elif cleaned_response.status_code == HTTPStatus.PAYMENT_REQUIRED:\n                    # TODO: Use this as a hook to prompt Bob's payment for policy sponsorship\n                    # https://getyarn.io/yarn-clip/ce0d37ba-4984-4210-9a40-c9c9859a3164\n                    raise RestMiddleware.PaymentRequired(cleaned_response.content)\n\n                elif cleaned_response.status_code == HTTPStatus.FORBIDDEN:\n                    raise RestMiddleware.Unauthorized(cleaned_response.content)\n\n                else:\n                    raise RestMiddleware.UnexpectedResponse(cleaned_response.content, status=cleaned_response.status_code)\n\n            return cleaned_response\n\n        return method_wrapper",
  "def _execute_method(self,\n                        node_or_sprout,\n                        host,\n                        port,\n                        method,\n                        endpoint,\n                        *args, **kwargs):\n        # Use existing cached SSL certificate or fetch fresh copy and retry\n        cached_cert_filepath = Path(self.storage.generate_certificate_filepath(host=host, port=port))\n        if cached_cert_filepath.exists():\n            # already cached try it\n            try:\n                # Send request\n                response = self.invoke_method(method, endpoint, verify=cached_cert_filepath,\n                                              *args, **kwargs)\n\n                # successful use of cached certificate\n                return response\n            except SSLError as e:\n                # ignore this exception - probably means that our cached cert may not be up-to-date.\n                SSL_LOGGER.debug(f\"Cached cert for {host}:{port} is invalid {e}\")\n\n        # Fetch fresh copy of SSL certificate\n        try:\n            certificate, filepath = self.get_certificate(host=host, port=port)\n        except NodeSeemsToBeDown as e:\n            raise RestMiddleware.Unreachable(\n                message=f'Node {node_or_sprout} {host}:{port} is unreachable: {e}')\n\n        # Send request\n        response = self.invoke_method(method, endpoint, verify=filepath,\n                                      *args, **kwargs)\n        return response",
  "def node_selector(self, node):\n        return node.rest_url(), self.library",
  "def __len__(self):\n        return 0",
  "class Unreachable(Exception):\n        def __init__(self, message, *args, **kwargs):\n            super().__init__(message, *args, **kwargs)",
  "class UnexpectedResponse(Exception):\n        def __init__(self, message, status, *args, **kwargs):\n            super().__init__(message, *args, **kwargs)\n            self.status = status",
  "class NotFound(UnexpectedResponse):\n        def __init__(self, *args, **kwargs):\n            super().__init__(status=HTTPStatus.NOT_FOUND, *args, **kwargs)",
  "class BadRequest(UnexpectedResponse):\n        def __init__(self, reason, *args, **kwargs):\n            self.reason = reason\n            super().__init__(message=reason, status=HTTPStatus.BAD_REQUEST, *args, **kwargs)",
  "class PaymentRequired(UnexpectedResponse):\n        \"\"\"Raised for HTTP 402\"\"\"\n        def __init__(self, *args, **kwargs):\n            super().__init__(status=HTTPStatus.PAYMENT_REQUIRED, *args, **kwargs)",
  "class Unauthorized(UnexpectedResponse):\n        \"\"\"Raised for HTTP 403\"\"\"\n        def __init__(self, *args, **kwargs):\n            super().__init__(status=HTTPStatus.FORBIDDEN, *args, **kwargs)",
  "def __init__(self, registry=None, eth_provider_uri: str = None):\n        self.client = self._client_class(registry=registry, eth_provider_uri=eth_provider_uri)",
  "def request_revocation(self, ursula, revocation):\n        # TODO: Implement offchain revocation #2787\n        response = self.client.post(\n            node_or_sprout=ursula,\n            path=f\"revoke\",\n            data=bytes(revocation),\n        )\n        return response",
  "def reencrypt(self, ursula: 'Ursula', reencryption_request_bytes: bytes):\n        response = self.client.post(\n            node_or_sprout=ursula,\n            path=f\"reencrypt\",\n            data=reencryption_request_bytes,\n            timeout=2\n        )\n        return response",
  "def check_availability(self, initiator, responder):\n        response = self.client.post(node_or_sprout=responder,\n                                    data=bytes(initiator.metatada()),\n                                    path=\"check_availability\",\n                                    timeout=6,  # Two round trips are expected\n                                    )\n        return response",
  "def ping(self, node):\n        response = self.client.get(node_or_sprout=node, path=\"ping\", timeout=2)\n        return response",
  "def get_nodes_via_rest(self,\n                           node,\n                           fleet_state_checksum: FleetStateChecksum,\n                           announce_nodes: Sequence[NodeMetadata]):\n\n        request = MetadataRequest(fleet_state_checksum=fleet_state_checksum,\n                                  announce_nodes=announce_nodes)\n        response = self.client.post(node_or_sprout=node,\n                                    path=\"node_metadata\",\n                                    data=bytes(request),\n                                    )\n        return response",
  "def method_wrapper(path,\n                           node_or_sprout=None,\n                           host=None,\n                           port=None,\n                           *args, **kwargs):\n\n            # Get interface\n            host, port, http_client = self.verify_and_parse_node_or_host_and_port(node_or_sprout, host, port)\n            endpoint = f\"https://{host}:{port}/{path}\"\n            method = getattr(http_client, method_name)\n\n            response = self._execute_method(node_or_sprout,\n                                            host,\n                                            port,\n                                            method,\n                                            endpoint,\n                                            *args,\n                                            **kwargs)\n            # Handle response\n            cleaned_response = self.response_cleaner(response)\n            if cleaned_response.status_code >= 300:\n\n                if cleaned_response.status_code == HTTPStatus.BAD_REQUEST:\n                    raise RestMiddleware.BadRequest(reason=cleaned_response.content)\n\n                elif cleaned_response.status_code == HTTPStatus.NOT_FOUND:\n                    m = f\"While trying to {method_name} {args} ({kwargs}), server 404'd.  Response: {cleaned_response.content}\"\n                    raise RestMiddleware.NotFound(m)\n\n                elif cleaned_response.status_code == HTTPStatus.PAYMENT_REQUIRED:\n                    # TODO: Use this as a hook to prompt Bob's payment for policy sponsorship\n                    # https://getyarn.io/yarn-clip/ce0d37ba-4984-4210-9a40-c9c9859a3164\n                    raise RestMiddleware.PaymentRequired(cleaned_response.content)\n\n                elif cleaned_response.status_code == HTTPStatus.FORBIDDEN:\n                    raise RestMiddleware.Unauthorized(cleaned_response.content)\n\n                else:\n                    raise RestMiddleware.UnexpectedResponse(cleaned_response.content, status=cleaned_response.status_code)\n\n            return cleaned_response",
  "def __init__(self, message, *args, **kwargs):\n            super().__init__(message, *args, **kwargs)",
  "def __init__(self, message, status, *args, **kwargs):\n            super().__init__(message, *args, **kwargs)\n            self.status = status",
  "def __init__(self, *args, **kwargs):\n            super().__init__(status=HTTPStatus.NOT_FOUND, *args, **kwargs)",
  "def __init__(self, reason, *args, **kwargs):\n            self.reason = reason\n            super().__init__(message=reason, status=HTTPStatus.BAD_REQUEST, *args, **kwargs)",
  "def __init__(self, *args, **kwargs):\n            super().__init__(status=HTTPStatus.PAYMENT_REQUIRED, *args, **kwargs)",
  "def __init__(self, *args, **kwargs):\n            super().__init__(status=HTTPStatus.FORBIDDEN, *args, **kwargs)",
  "def get_static_resources():\n    resources = []\n    if os.getenv('NUCYPHER_STATIC_FILES_ROOT'):\n        resources.append(MediaResource(os.getenv('NUCYPHER_STATIC_FILES_ROOT').encode(), namespace=b'statics'))\n    return resources",
  "class SuspiciousActivity(RuntimeError):\n    \"\"\"raised when an action appears to amount to malicious conduct.\"\"\"",
  "def parse_node_uri(uri: str):\n    from nucypher.config.characters import UrsulaConfiguration\n\n    if '@' in uri:\n        checksum_address, uri = uri.split(\"@\")\n        if checksum_address is None:\n            raise ValueError(f\"{uri} is not a valid Teacher URI - no checksum address.\")\n        if not is_checksum_address(checksum_address):\n            raise ValueError(\"{} is not a valid checksum address.\".format(checksum_address))\n    else:\n        checksum_address = None  # federated\n\n    #############################################\n    # Strange logic here to ensure https:// - possibly pursuant to https://bugs.python.org/msg179670\n    # It's not clear that there is any version of python 3.7+ that requires this, so we may\n    # be able to drop it in the near future.\n    if not uri.startswith(\"https://\"):\n        uri = \"https://\" + uri\n    #############################################\n\n    parsed_uri = urlparse(uri)\n\n    if not parsed_uri.scheme:\n        try:\n            parsed_uri = urlparse('https://'+uri)\n        except Exception:\n            raise  # TODO: Do we need even deeper handling/validation here?\n\n    if not parsed_uri.scheme == \"https\":\n        raise ValueError(\"Invalid teacher scheme or protocol. Is the hostname prefixed with 'https://' ?\")\n\n    hostname = parsed_uri.hostname\n    port = parsed_uri.port or UrsulaConfiguration.DEFAULT_REST_PORT\n    return hostname, port, checksum_address",
  "class InterfaceInfo:\n\n    def __init__(self, host, port) -> None:\n        loopback, localhost = LOOPBACK_ADDRESS, 'localhost'\n        self.host = loopback if host == localhost else host\n        self.port = int(port)\n\n    def __iter__(self):\n        yield self.host\n        yield self.port\n\n    @property\n    def uri(self):\n        return u\"{}:{}\".format(self.host, self.port)\n\n    @property\n    def formal_uri(self):\n        return u\"{}://{}\".format('https', self.uri)\n\n    def __repr__(self):\n        return self.uri",
  "def __init__(self, host, port) -> None:\n        loopback, localhost = LOOPBACK_ADDRESS, 'localhost'\n        self.host = loopback if host == localhost else host\n        self.port = int(port)",
  "def __iter__(self):\n        yield self.host\n        yield self.port",
  "def uri(self):\n        return u\"{}:{}\".format(self.host, self.port)",
  "def formal_uri(self):\n        return u\"{}://{}\".format('https', self.uri)",
  "def __repr__(self):\n        return self.uri",
  "class Character(Learner):\n    \"\"\"A base-class for any character in our cryptography protocol narrative.\"\"\"\n\n    _display_name_template = \"({})\u21c0{}\u21bd ({})\"  # Used in __repr__ and in cls.from_bytes\n    _default_crypto_powerups = None\n    _stamp = None\n\n    def __init__(self,\n                 domain: str = None,\n                 known_node_class: object = None,\n                 is_me: bool = True,\n                 federated_only: bool = False,\n                 checksum_address: str = None,\n                 network_middleware: RestMiddleware = None,\n                 keystore: Keystore = None,\n                 crypto_power: CryptoPower = None,\n                 crypto_power_ups: List[CryptoPowerUp] = None,\n                 eth_provider_uri: str = None,\n                 signer: Signer = None,\n                 registry: BaseContractRegistry = None,\n                 include_self_in_the_state: bool = False,\n                 *args, **kwargs\n                 ) -> None:\n\n        \"\"\"\n\n        A participant in the cryptological drama (a screenplay, if you like) of NuCypher.\n\n        Characters can represent users, nodes, wallets, offline devices, or other objects of varying levels of abstraction.\n\n        The Named Characters use this class as a Base, and achieve their individuality from additional methods and PowerUps.\n\n\n        PowerUps\n        ========\n        :param crypto_power: A CryptoPower object; if provided, this will be the character's CryptoPower.\n        :param crypto_power_ups: If crypto_power is not provided, a new one will be made to consume all CryptoPowerUps.\n\n        If neither crypto_power nor crypto_power_ups are provided, we give this\n        Character all CryptoPowerUps listed in their _default_crypto_powerups\n        attribute.\n\n        :param is_me: Set this to True when you want this Character to represent\n            the owner of the configuration under which the program is being run.\n            A Character who is_me can do things that other Characters can't,\n            like run servers, sign messages, and decrypt messages which are\n            encrypted for them.  Typically this will be True for exactly one\n            Character, but there are scenarios in which its imaginable to be\n            represented by zero Characters or by more than one Character.\n\n        \"\"\"\n\n        #\n        # Prologue of the federation\n        #\n\n        # FIXME: excuse me... can I speak to the manager?\n        if is_me:\n            # If this is a federated-is_me-character, assume everyone else is too.\n            self._set_known_node_class(known_node_class, federated_only)\n        else:\n            # What an awful hack.  The last convulsions of #466.  # TODO: Anything else.\n            with suppress(AttributeError):\n                federated_only = known_node_class._federated_only_instances\n\n        if federated_only:\n            if registry or eth_provider_uri:\n                raise ValueError(f\"Cannot init federated-only character with {registry or eth_provider_uri}.\")\n        self.federated_only: bool = federated_only\n\n        ##########################################\n\n        #\n        # Keys & Powers\n        #\n\n        if keystore:\n            crypto_power_ups = list()\n            for power_up in self._default_crypto_powerups:\n                power = keystore.derive_crypto_power(power_class=power_up)\n                crypto_power_ups.append(power)\n        self.keystore = keystore\n\n        if crypto_power and crypto_power_ups:\n            raise ValueError(\"Pass crypto_power or crypto_power_ups (or neither), but not both.\")\n        crypto_power_ups = crypto_power_ups or list()  # type: list\n\n        if crypto_power:\n            self._crypto_power = crypto_power  # type: CryptoPower\n        elif crypto_power_ups:\n            self._crypto_power = CryptoPower(power_ups=crypto_power_ups)\n        else:\n            self._crypto_power = CryptoPower(power_ups=self._default_crypto_powerups)\n\n        #\n        # Self\n        #\n\n        if is_me:\n\n            # Signing Power\n            self.signer = signer\n            try:\n                signing_power = self._crypto_power.power_ups(SigningPower)  # type: SigningPower\n                self._stamp = signing_power.get_signature_stamp()  # type: SignatureStamp\n            except NoSigningPower:\n                self._stamp = NO_SIGNING_POWER\n\n            # Blockchainy\n            if not self.federated_only:\n                self.eth_provider_uri = eth_provider_uri\n                self.registry = registry or InMemoryContractRegistry.from_latest_publication(network=domain)  # See #1580\n            else:\n                self.registry = NO_BLOCKCHAIN_CONNECTION.bool_value(False)\n\n            # REST\n            self.network_middleware = network_middleware or RestMiddleware(registry=self.registry,\n                                                                           eth_provider_uri=eth_provider_uri)\n\n            # Learner\n            Learner.__init__(self,\n                             domain=domain,\n                             network_middleware=self.network_middleware,\n                             node_class=known_node_class,\n                             include_self_in_the_state=include_self_in_the_state,\n                             *args, **kwargs)\n\n            if self.federated_only:\n                try:\n                    derived_federated_address = self.derive_federated_address()\n                except NoSigningPower:\n                    # TODO: Why allow such a character (without signing power) to be created at all?\n                    derived_federated_address = NO_SIGNING_POWER.bool_value(False)\n\n                if checksum_address and (checksum_address != derived_federated_address):\n                    raise ValueError(f\"Provided checksum address {checksum_address} \"\n                                     f\"does not match federated character's verifying key {derived_federated_address}\")\n                checksum_address = derived_federated_address\n\n            self.checksum_address = checksum_address\n\n        #\n        # Stranger\n        #\n\n        else:\n            if network_middleware is not None:\n                raise TypeError(\"Network middleware cannot be attached to a Stranger-Character.\")\n\n            if registry is not None:\n                raise TypeError(\"Registry cannot be attached to stranger-Characters.\")\n\n            verifying_key = self.public_keys(SigningPower)\n            self._stamp = StrangerStamp(verifying_key)\n            self.keystore_dir = STRANGER\n            self.network_middleware = STRANGER\n            self.checksum_address = checksum_address\n\n        self.__setup_nickname(is_me=is_me)\n\n    def __eq__(self, other) -> bool:\n        try:\n            other_stamp = other.stamp\n        except (AttributeError, NoSigningPower):\n            return False\n        return bytes(self.stamp) == bytes(other_stamp)\n\n    def __hash__(self):\n        return int.from_bytes(bytes(self.stamp), byteorder=\"big\")\n\n    def __repr__(self):\n        r = self._display_name_template\n        try:\n            r = r.format(self.__class__.__name__, self.nickname, self.checksum_address)\n        except (NoSigningPower, TypeError):  # TODO: ....yeah?  We can probably do better for a repr here.\n            r = f\"({self.__class__.__name__})\u21c0{self.nickname}\u21bd\"\n        return r\n\n    def __setup_nickname(self, is_me: bool):\n        if not self.checksum_address and not self.federated_only and not is_me:\n            # Sometimes we don't care about the nickname.  For example, if Alice is granting to Bob, she usually\n            # doesn't know or care about his wallet.  Maybe this needs to change?\n            # Currently, if this is a stranger and there's no blockchain connection, we assign NO_NICKNAME:\n            self.nickname = NO_NICKNAME\n        else:\n            try:\n                if not self.checksum_address:\n                    self.nickname = NO_NICKNAME\n                else:\n                    # This can call _set_checksum_address.\n                    self.nickname = Nickname.from_seed(self.checksum_address)\n            except SigningPower.not_found_error:\n                if self.federated_only:\n                    self.nickname = NO_NICKNAME\n                else:\n                    raise\n\n    @property\n    def name(self):\n        return self.__class__.__name__\n\n    @property\n    def stamp(self):\n        if self._stamp is NO_SIGNING_POWER:\n            raise NoSigningPower\n        elif not self._stamp:\n            raise AttributeError(\"SignatureStamp has not been set up yet.\")\n        else:\n            return self._stamp\n\n    @property\n    def canonical_address(self):\n        # TODO: This is wasteful.  #1995\n        return to_canonical_address(self.checksum_address)\n\n    @classmethod\n    def from_config(cls, config, **overrides) -> 'Character':\n        return config.produce(**overrides)\n\n    @classmethod\n    def from_public_keys(cls,\n                         powers_and_material: Dict = None,\n                         verifying_key: Optional[PublicKey] = None,\n                         encrypting_key: Optional[PublicKey] = None,\n                         *args, **kwargs) -> 'Character':\n        \"\"\"\n        Sometimes we discover a Character and, at the same moment,\n        learn the public parts of more of their powers. Here, we take a Dict\n        (powers_and_material) in the format {CryptoPowerUp class: material},\n        where material can be bytes or umbral.PublicKey.\n\n        Each item in the collection will have the CryptoPowerUp instantiated\n        with the given material, and the resulting CryptoPowerUp instance\n        consumed by the Character.\n\n        Alternatively, you can pass directly a verifying public key\n        (for SigningPower) and/or an encrypting public key (for DecryptionPower).\n        \"\"\"\n        crypto_power = CryptoPower()\n\n        if powers_and_material is None:\n            powers_and_material = dict()\n\n        if verifying_key:\n            powers_and_material[SigningPower] = verifying_key\n        if encrypting_key:\n            powers_and_material[DecryptingPower] = encrypting_key\n\n        for power_up, public_key in powers_and_material.items():\n            try:\n                umbral_key = PublicKey.from_bytes(public_key)\n            except TypeError:\n                umbral_key = public_key\n\n            crypto_power.consume_power_up(power_up(public_key=umbral_key))\n\n        return cls(is_me=False, crypto_power=crypto_power, *args, **kwargs)\n\n    def _set_known_node_class(self, known_node_class, federated_only):\n        if not known_node_class:\n            # Once in a while, in tests or demos, we init a plain Character who doesn't already know about its node class.\n            from nucypher.characters.lawful import Ursula\n            known_node_class = Ursula\n        self.known_node_class = known_node_class\n        # If we're federated only, we assume that all other nodes in our domain are as well.\n        known_node_class.set_federated_mode(federated_only)\n\n    # TODO: Unused\n    def store_metadata(self, filepath: Path) -> Path:\n        \"\"\"\n        Save this node to the disk.\n        :param filepath: Output filepath to save node metadata.\n        :return: Output filepath\n        \"\"\"\n\n        return self.node_storage.store_node_metadata(node=self, filepath=filepath)\n\n    def encrypt_for(self,\n                    recipient: 'Character',\n                    plaintext: bytes,\n                    ) -> MessageKit:\n        \"\"\"\n        Encrypts plaintext for recipient actor. Optionally signs the message as well.\n\n        :param recipient: The character whose public key will be used to encrypt\n            cleartext.\n        :param plaintext: The secret to be encrypted.\n        :param sign_plaintext: the cleartext is signed if this is\n            True,  Otherwise, the resulting ciphertext is signed.\n\n        :return: the message kit.\n        \"\"\"\n\n        # TODO: who even uses this method except for tests?\n\n        message_kit = MessageKit(policy_encrypting_key=recipient.public_keys(DecryptingPower),\n                                 plaintext=plaintext)\n        return message_kit\n\n    def public_keys(self, power_up_class: ClassVar):\n        \"\"\"\n        Pass a power_up_class, get the public material for this Character which corresponds to that\n        class - whatever type of object that may be.\n\n        If the Character doesn't have the power corresponding to that class, raises the\n        appropriate PowerUpError (ie, NoSigningPower or NoDecryptingPower).\n        \"\"\"\n        power_up = self._crypto_power.power_ups(power_up_class)\n        return power_up.public_key()\n\n    def derive_federated_address(self):\n        if self.federated_only:\n            verifying_key = self.public_keys(SigningPower)\n            verifying_key_as_eth_key = EthKeyAPI.PublicKey.from_compressed_bytes(bytes(verifying_key))\n            federated_address = verifying_key_as_eth_key.to_checksum_address()\n        else:\n            raise RuntimeError('Federated address can only be derived for federated characters.')\n        return federated_address\n\n    def disenchant(self):\n        self.log.debug(f\"Disenchanting {self}\")\n        Learner.stop_learning_loop(self)",
  "def __init__(self,\n                 domain: str = None,\n                 known_node_class: object = None,\n                 is_me: bool = True,\n                 federated_only: bool = False,\n                 checksum_address: str = None,\n                 network_middleware: RestMiddleware = None,\n                 keystore: Keystore = None,\n                 crypto_power: CryptoPower = None,\n                 crypto_power_ups: List[CryptoPowerUp] = None,\n                 eth_provider_uri: str = None,\n                 signer: Signer = None,\n                 registry: BaseContractRegistry = None,\n                 include_self_in_the_state: bool = False,\n                 *args, **kwargs\n                 ) -> None:\n\n        \"\"\"\n\n        A participant in the cryptological drama (a screenplay, if you like) of NuCypher.\n\n        Characters can represent users, nodes, wallets, offline devices, or other objects of varying levels of abstraction.\n\n        The Named Characters use this class as a Base, and achieve their individuality from additional methods and PowerUps.\n\n\n        PowerUps\n        ========\n        :param crypto_power: A CryptoPower object; if provided, this will be the character's CryptoPower.\n        :param crypto_power_ups: If crypto_power is not provided, a new one will be made to consume all CryptoPowerUps.\n\n        If neither crypto_power nor crypto_power_ups are provided, we give this\n        Character all CryptoPowerUps listed in their _default_crypto_powerups\n        attribute.\n\n        :param is_me: Set this to True when you want this Character to represent\n            the owner of the configuration under which the program is being run.\n            A Character who is_me can do things that other Characters can't,\n            like run servers, sign messages, and decrypt messages which are\n            encrypted for them.  Typically this will be True for exactly one\n            Character, but there are scenarios in which its imaginable to be\n            represented by zero Characters or by more than one Character.\n\n        \"\"\"\n\n        #\n        # Prologue of the federation\n        #\n\n        # FIXME: excuse me... can I speak to the manager?\n        if is_me:\n            # If this is a federated-is_me-character, assume everyone else is too.\n            self._set_known_node_class(known_node_class, federated_only)\n        else:\n            # What an awful hack.  The last convulsions of #466.  # TODO: Anything else.\n            with suppress(AttributeError):\n                federated_only = known_node_class._federated_only_instances\n\n        if federated_only:\n            if registry or eth_provider_uri:\n                raise ValueError(f\"Cannot init federated-only character with {registry or eth_provider_uri}.\")\n        self.federated_only: bool = federated_only\n\n        ##########################################\n\n        #\n        # Keys & Powers\n        #\n\n        if keystore:\n            crypto_power_ups = list()\n            for power_up in self._default_crypto_powerups:\n                power = keystore.derive_crypto_power(power_class=power_up)\n                crypto_power_ups.append(power)\n        self.keystore = keystore\n\n        if crypto_power and crypto_power_ups:\n            raise ValueError(\"Pass crypto_power or crypto_power_ups (or neither), but not both.\")\n        crypto_power_ups = crypto_power_ups or list()  # type: list\n\n        if crypto_power:\n            self._crypto_power = crypto_power  # type: CryptoPower\n        elif crypto_power_ups:\n            self._crypto_power = CryptoPower(power_ups=crypto_power_ups)\n        else:\n            self._crypto_power = CryptoPower(power_ups=self._default_crypto_powerups)\n\n        #\n        # Self\n        #\n\n        if is_me:\n\n            # Signing Power\n            self.signer = signer\n            try:\n                signing_power = self._crypto_power.power_ups(SigningPower)  # type: SigningPower\n                self._stamp = signing_power.get_signature_stamp()  # type: SignatureStamp\n            except NoSigningPower:\n                self._stamp = NO_SIGNING_POWER\n\n            # Blockchainy\n            if not self.federated_only:\n                self.eth_provider_uri = eth_provider_uri\n                self.registry = registry or InMemoryContractRegistry.from_latest_publication(network=domain)  # See #1580\n            else:\n                self.registry = NO_BLOCKCHAIN_CONNECTION.bool_value(False)\n\n            # REST\n            self.network_middleware = network_middleware or RestMiddleware(registry=self.registry,\n                                                                           eth_provider_uri=eth_provider_uri)\n\n            # Learner\n            Learner.__init__(self,\n                             domain=domain,\n                             network_middleware=self.network_middleware,\n                             node_class=known_node_class,\n                             include_self_in_the_state=include_self_in_the_state,\n                             *args, **kwargs)\n\n            if self.federated_only:\n                try:\n                    derived_federated_address = self.derive_federated_address()\n                except NoSigningPower:\n                    # TODO: Why allow such a character (without signing power) to be created at all?\n                    derived_federated_address = NO_SIGNING_POWER.bool_value(False)\n\n                if checksum_address and (checksum_address != derived_federated_address):\n                    raise ValueError(f\"Provided checksum address {checksum_address} \"\n                                     f\"does not match federated character's verifying key {derived_federated_address}\")\n                checksum_address = derived_federated_address\n\n            self.checksum_address = checksum_address\n\n        #\n        # Stranger\n        #\n\n        else:\n            if network_middleware is not None:\n                raise TypeError(\"Network middleware cannot be attached to a Stranger-Character.\")\n\n            if registry is not None:\n                raise TypeError(\"Registry cannot be attached to stranger-Characters.\")\n\n            verifying_key = self.public_keys(SigningPower)\n            self._stamp = StrangerStamp(verifying_key)\n            self.keystore_dir = STRANGER\n            self.network_middleware = STRANGER\n            self.checksum_address = checksum_address\n\n        self.__setup_nickname(is_me=is_me)",
  "def __eq__(self, other) -> bool:\n        try:\n            other_stamp = other.stamp\n        except (AttributeError, NoSigningPower):\n            return False\n        return bytes(self.stamp) == bytes(other_stamp)",
  "def __hash__(self):\n        return int.from_bytes(bytes(self.stamp), byteorder=\"big\")",
  "def __repr__(self):\n        r = self._display_name_template\n        try:\n            r = r.format(self.__class__.__name__, self.nickname, self.checksum_address)\n        except (NoSigningPower, TypeError):  # TODO: ....yeah?  We can probably do better for a repr here.\n            r = f\"({self.__class__.__name__})\u21c0{self.nickname}\u21bd\"\n        return r",
  "def __setup_nickname(self, is_me: bool):\n        if not self.checksum_address and not self.federated_only and not is_me:\n            # Sometimes we don't care about the nickname.  For example, if Alice is granting to Bob, she usually\n            # doesn't know or care about his wallet.  Maybe this needs to change?\n            # Currently, if this is a stranger and there's no blockchain connection, we assign NO_NICKNAME:\n            self.nickname = NO_NICKNAME\n        else:\n            try:\n                if not self.checksum_address:\n                    self.nickname = NO_NICKNAME\n                else:\n                    # This can call _set_checksum_address.\n                    self.nickname = Nickname.from_seed(self.checksum_address)\n            except SigningPower.not_found_error:\n                if self.federated_only:\n                    self.nickname = NO_NICKNAME\n                else:\n                    raise",
  "def name(self):\n        return self.__class__.__name__",
  "def stamp(self):\n        if self._stamp is NO_SIGNING_POWER:\n            raise NoSigningPower\n        elif not self._stamp:\n            raise AttributeError(\"SignatureStamp has not been set up yet.\")\n        else:\n            return self._stamp",
  "def canonical_address(self):\n        # TODO: This is wasteful.  #1995\n        return to_canonical_address(self.checksum_address)",
  "def from_config(cls, config, **overrides) -> 'Character':\n        return config.produce(**overrides)",
  "def from_public_keys(cls,\n                         powers_and_material: Dict = None,\n                         verifying_key: Optional[PublicKey] = None,\n                         encrypting_key: Optional[PublicKey] = None,\n                         *args, **kwargs) -> 'Character':\n        \"\"\"\n        Sometimes we discover a Character and, at the same moment,\n        learn the public parts of more of their powers. Here, we take a Dict\n        (powers_and_material) in the format {CryptoPowerUp class: material},\n        where material can be bytes or umbral.PublicKey.\n\n        Each item in the collection will have the CryptoPowerUp instantiated\n        with the given material, and the resulting CryptoPowerUp instance\n        consumed by the Character.\n\n        Alternatively, you can pass directly a verifying public key\n        (for SigningPower) and/or an encrypting public key (for DecryptionPower).\n        \"\"\"\n        crypto_power = CryptoPower()\n\n        if powers_and_material is None:\n            powers_and_material = dict()\n\n        if verifying_key:\n            powers_and_material[SigningPower] = verifying_key\n        if encrypting_key:\n            powers_and_material[DecryptingPower] = encrypting_key\n\n        for power_up, public_key in powers_and_material.items():\n            try:\n                umbral_key = PublicKey.from_bytes(public_key)\n            except TypeError:\n                umbral_key = public_key\n\n            crypto_power.consume_power_up(power_up(public_key=umbral_key))\n\n        return cls(is_me=False, crypto_power=crypto_power, *args, **kwargs)",
  "def _set_known_node_class(self, known_node_class, federated_only):\n        if not known_node_class:\n            # Once in a while, in tests or demos, we init a plain Character who doesn't already know about its node class.\n            from nucypher.characters.lawful import Ursula\n            known_node_class = Ursula\n        self.known_node_class = known_node_class\n        # If we're federated only, we assume that all other nodes in our domain are as well.\n        known_node_class.set_federated_mode(federated_only)",
  "def store_metadata(self, filepath: Path) -> Path:\n        \"\"\"\n        Save this node to the disk.\n        :param filepath: Output filepath to save node metadata.\n        :return: Output filepath\n        \"\"\"\n\n        return self.node_storage.store_node_metadata(node=self, filepath=filepath)",
  "def encrypt_for(self,\n                    recipient: 'Character',\n                    plaintext: bytes,\n                    ) -> MessageKit:\n        \"\"\"\n        Encrypts plaintext for recipient actor. Optionally signs the message as well.\n\n        :param recipient: The character whose public key will be used to encrypt\n            cleartext.\n        :param plaintext: The secret to be encrypted.\n        :param sign_plaintext: the cleartext is signed if this is\n            True,  Otherwise, the resulting ciphertext is signed.\n\n        :return: the message kit.\n        \"\"\"\n\n        # TODO: who even uses this method except for tests?\n\n        message_kit = MessageKit(policy_encrypting_key=recipient.public_keys(DecryptingPower),\n                                 plaintext=plaintext)\n        return message_kit",
  "def public_keys(self, power_up_class: ClassVar):\n        \"\"\"\n        Pass a power_up_class, get the public material for this Character which corresponds to that\n        class - whatever type of object that may be.\n\n        If the Character doesn't have the power corresponding to that class, raises the\n        appropriate PowerUpError (ie, NoSigningPower or NoDecryptingPower).\n        \"\"\"\n        power_up = self._crypto_power.power_ups(power_up_class)\n        return power_up.public_key()",
  "def derive_federated_address(self):\n        if self.federated_only:\n            verifying_key = self.public_keys(SigningPower)\n            verifying_key_as_eth_key = EthKeyAPI.PublicKey.from_compressed_bytes(bytes(verifying_key))\n            federated_address = verifying_key_as_eth_key.to_checksum_address()\n        else:\n            raise RuntimeError('Federated address can only be derived for federated characters.')\n        return federated_address",
  "def disenchant(self):\n        self.log.debug(f\"Disenchanting {self}\")\n        Learner.stop_learning_loop(self)",
  "class Vladimir(Ursula):\n    \"\"\"\n    The power of Ursula, but with a heart forged deep in the mountains of Microsoft or a State Actor or whatever.\n    \"\"\"\n\n    fraud_address = '0xbad022A87Df21E4c787C7B1effD5077014b8CC45'\n    fraud_key = 'a75d701cc4199f7646909d15f22e2e0ef6094b3e2aa47a188f35f47e8932a7b9'\n\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self._checksum_address = self.fraud_address\n\n    @classmethod\n    def from_target_ursula(cls,\n                           target_ursula: Ursula,\n                           substitute_verifying_key: bool = False,\n                           sign_metadata: bool = False,\n                           ) -> 'Vladimir':\n        \"\"\"\n        Sometimes Vladimir seeks to attack or imitate a *specific* target Ursula.\n\n        TODO: This is probably a more instructive method if it takes a bytes representation instead of the entire Ursula.\n        \"\"\"\n        try:\n            from tests.utils.middleware import EvilMiddleWare\n        except ImportError:\n            raise DevelopmentInstallationRequired(importable_name='tests.utils.middleware.EvilMiddleWare')\n        cls.network_middleware = EvilMiddleWare()\n\n        crypto_power = CryptoPower(power_ups=target_ursula._default_crypto_powerups)\n\n        blockchain = target_ursula.application_agent.blockchain\n        cls.attach_transacting_key(blockchain=blockchain)\n\n        # Vladimir does not care about payment.\n        bogus_payment_method = FreeReencryptions()\n        bogus_payment_method.agent = Mock()\n\n        vladimir = cls(is_me=True,\n                       crypto_power=crypto_power,\n                       domain=TEMPORARY_DOMAIN,\n                       rest_host=target_ursula.rest_interface.host,\n                       rest_port=target_ursula.rest_interface.port,\n                       certificate=target_ursula.certificate,\n                       network_middleware=cls.network_middleware,\n                       checksum_address=cls.fraud_address,\n                       operator_address=cls.fraud_address,\n                       signer=Web3Signer(blockchain.client),\n                       eth_provider_uri=blockchain.eth_provider_uri,\n                       payment_method=bogus_payment_method,\n                       )\n\n        # Let's use the target's public info, and try to make some changes.\n\n        metadata = target_ursula.metadata()\n        metadata_bytes = bytes(metadata)\n\n        # Since it is an object from a Rust extension, we cannot directly modify it,\n        # so we have to replace stuff in the byte representation and then deserialize.\n        # We are replacing objects with constant size,\n        # so it should work regardless of the binary format.\n\n        # Our basic replacement. We want to impersonate the target Ursula.\n        metadata_bytes = metadata_bytes.replace(bytes(metadata.payload.staking_provider_address),\n                                                vladimir.canonical_address)\n\n        # Use our own verifying key\n        if substitute_verifying_key:\n            metadata_bytes = metadata_bytes.replace(bytes(metadata.payload.verifying_key),\n                                                    bytes(vladimir.stamp.as_umbral_pubkey()))\n\n        fake_metadata = NodeMetadata.from_bytes(metadata_bytes)\n\n        # Re-generate metadata signature using our signing key\n        if sign_metadata:\n            fake_metadata = NodeMetadata(vladimir.stamp.as_umbral_signer(), fake_metadata.payload)\n\n        # Put metadata back\n        vladimir._metadata = fake_metadata\n\n        return vladimir\n\n    @classmethod\n    def attach_transacting_key(cls, blockchain):\n        \"\"\"\n        Upload Vladimir's ETH keys to the keychain via web3.\n        \"\"\"\n        try:\n            password = 'iamverybadass'\n            blockchain.w3.provider.ethereum_tester.add_account(cls.fraud_key, password=password)\n        except (ValidationError,):\n            # check if Vlad's key is already on the keystore...\n            if cls.fraud_address in blockchain.client.accounts:\n                return True\n            else:\n                raise\n        return True",
  "class Amonia(Alice):\n    \"\"\"\n    Separated at birth, Alice's sister is lighter than air and has a pungent smell.\n    \"\"\"\n\n    @classmethod\n    def from_lawful_alice(cls, alice):\n        alice_clone = copy(alice)\n        alice_clone.__class__ = cls\n        return alice_clone\n\n    def grant_without_paying(self, *args, **kwargs):\n        \"\"\"I take what I want for free.\"\"\"\n\n        def what_do_you_mean_you_dont_tip(policy, *args, **kwargs):\n            return b\"He convinced me, gimme back my $\"\n\n        with patch(\"nucypher.policy.policies.BlockchainPolicy._publish\", what_do_you_mean_you_dont_tip):\n            return super().grant(*args, **kwargs)\n\n    def circumvent_safegaurds_and_grant_without_paying(self, *args, **kwargs):\n        \"\"\"\n        I am not Alice, and I needn't abide by her sensibilities or raise her Exceptions.\n\n        Can I grant for free if I change the client code to my liking?\n        \"\"\"\n        with patch(\"nucypher.policy.policies.Policy._publish\", self.grant_without_paying):\n            return self.grant_without_paying(*args, **kwargs)",
  "def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self._checksum_address = self.fraud_address",
  "def from_target_ursula(cls,\n                           target_ursula: Ursula,\n                           substitute_verifying_key: bool = False,\n                           sign_metadata: bool = False,\n                           ) -> 'Vladimir':\n        \"\"\"\n        Sometimes Vladimir seeks to attack or imitate a *specific* target Ursula.\n\n        TODO: This is probably a more instructive method if it takes a bytes representation instead of the entire Ursula.\n        \"\"\"\n        try:\n            from tests.utils.middleware import EvilMiddleWare\n        except ImportError:\n            raise DevelopmentInstallationRequired(importable_name='tests.utils.middleware.EvilMiddleWare')\n        cls.network_middleware = EvilMiddleWare()\n\n        crypto_power = CryptoPower(power_ups=target_ursula._default_crypto_powerups)\n\n        blockchain = target_ursula.application_agent.blockchain\n        cls.attach_transacting_key(blockchain=blockchain)\n\n        # Vladimir does not care about payment.\n        bogus_payment_method = FreeReencryptions()\n        bogus_payment_method.agent = Mock()\n\n        vladimir = cls(is_me=True,\n                       crypto_power=crypto_power,\n                       domain=TEMPORARY_DOMAIN,\n                       rest_host=target_ursula.rest_interface.host,\n                       rest_port=target_ursula.rest_interface.port,\n                       certificate=target_ursula.certificate,\n                       network_middleware=cls.network_middleware,\n                       checksum_address=cls.fraud_address,\n                       operator_address=cls.fraud_address,\n                       signer=Web3Signer(blockchain.client),\n                       eth_provider_uri=blockchain.eth_provider_uri,\n                       payment_method=bogus_payment_method,\n                       )\n\n        # Let's use the target's public info, and try to make some changes.\n\n        metadata = target_ursula.metadata()\n        metadata_bytes = bytes(metadata)\n\n        # Since it is an object from a Rust extension, we cannot directly modify it,\n        # so we have to replace stuff in the byte representation and then deserialize.\n        # We are replacing objects with constant size,\n        # so it should work regardless of the binary format.\n\n        # Our basic replacement. We want to impersonate the target Ursula.\n        metadata_bytes = metadata_bytes.replace(bytes(metadata.payload.staking_provider_address),\n                                                vladimir.canonical_address)\n\n        # Use our own verifying key\n        if substitute_verifying_key:\n            metadata_bytes = metadata_bytes.replace(bytes(metadata.payload.verifying_key),\n                                                    bytes(vladimir.stamp.as_umbral_pubkey()))\n\n        fake_metadata = NodeMetadata.from_bytes(metadata_bytes)\n\n        # Re-generate metadata signature using our signing key\n        if sign_metadata:\n            fake_metadata = NodeMetadata(vladimir.stamp.as_umbral_signer(), fake_metadata.payload)\n\n        # Put metadata back\n        vladimir._metadata = fake_metadata\n\n        return vladimir",
  "def attach_transacting_key(cls, blockchain):\n        \"\"\"\n        Upload Vladimir's ETH keys to the keychain via web3.\n        \"\"\"\n        try:\n            password = 'iamverybadass'\n            blockchain.w3.provider.ethereum_tester.add_account(cls.fraud_key, password=password)\n        except (ValidationError,):\n            # check if Vlad's key is already on the keystore...\n            if cls.fraud_address in blockchain.client.accounts:\n                return True\n            else:\n                raise\n        return True",
  "def from_lawful_alice(cls, alice):\n        alice_clone = copy(alice)\n        alice_clone.__class__ = cls\n        return alice_clone",
  "def grant_without_paying(self, *args, **kwargs):\n        \"\"\"I take what I want for free.\"\"\"\n\n        def what_do_you_mean_you_dont_tip(policy, *args, **kwargs):\n            return b\"He convinced me, gimme back my $\"\n\n        with patch(\"nucypher.policy.policies.BlockchainPolicy._publish\", what_do_you_mean_you_dont_tip):\n            return super().grant(*args, **kwargs)",
  "def circumvent_safegaurds_and_grant_without_paying(self, *args, **kwargs):\n        \"\"\"\n        I am not Alice, and I needn't abide by her sensibilities or raise her Exceptions.\n\n        Can I grant for free if I change the client code to my liking?\n        \"\"\"\n        with patch(\"nucypher.policy.policies.Policy._publish\", self.grant_without_paying):\n            return self.grant_without_paying(*args, **kwargs)",
  "def what_do_you_mean_you_dont_tip(policy, *args, **kwargs):\n            return b\"He convinced me, gimme back my $\"",
  "class Alice(Character, BlockchainPolicyAuthor):\n    banner = ALICE_BANNER\n    _default_crypto_powerups = [SigningPower, DecryptingPower, DelegatingPower]\n\n    def __init__(self,\n\n                 # Mode\n                 is_me: bool = True,\n                 federated_only: bool = False,\n                 eth_provider_uri: str = None,\n                 signer=None,\n\n                 # Ownership\n                 checksum_address: str = None,\n\n                 # M of N\n                 threshold: Optional[int] = None,\n                 shares: Optional[int] = None,\n\n                 # Policy Value\n                 rate: int = None,\n                 duration: int = None,\n                 payment_method: PaymentMethod = None,\n\n                 # Policy Storage\n                 store_policy_credentials: bool = None,\n\n                 # Middleware\n                 timeout: int = 10,  # seconds  # TODO: configure  NRN\n                 network_middleware: RestMiddleware = None,\n\n                 *args, **kwargs) -> None:\n\n        #\n        # Fallback Policy Values\n        #\n\n        self.timeout = timeout\n\n        if is_me:\n            self.threshold = threshold\n            self.shares = shares\n\n            self._policy_queue = Queue()\n            self._policy_queue.put(READY)\n        else:\n            self.threshold = STRANGER_ALICE\n            self.shares = STRANGER_ALICE\n\n        Character.__init__(self,\n                           known_node_class=Ursula,\n                           is_me=is_me,\n                           federated_only=federated_only,\n                           eth_provider_uri=eth_provider_uri,\n                           checksum_address=checksum_address,\n                           network_middleware=network_middleware,\n                           *args, **kwargs)\n\n        if is_me and not federated_only:  # TODO: #289\n            if not eth_provider_uri:\n                raise ValueError('ETH Provider URI is required to init a decentralized character.')\n\n            blockchain = BlockchainInterfaceFactory.get_interface(eth_provider_uri=self.eth_provider_uri)\n            signer = signer or Web3Signer(blockchain.client)  # fallback to web3 provider by default for Alice.\n            self.transacting_power = TransactingPower(account=self.checksum_address, signer=signer)\n            self._crypto_power.consume_power_up(self.transacting_power)\n            BlockchainPolicyAuthor.__init__(self,\n                                            domain=self.domain,\n                                            transacting_power=self.transacting_power,\n                                            registry=self.registry,\n                                            eth_provider_uri=eth_provider_uri)\n\n        self.log = Logger(self.__class__.__name__)\n        if is_me:\n\n            # Policy Payment\n            if federated_only and not payment_method:\n                # Federated payments are free by default.\n                payment_method = FreeReencryptions()\n            if not payment_method:\n                raise ValueError('payment_method is a required argument for a local Alice.')\n            self.payment_method = payment_method\n            self.rate = rate\n            self.duration = duration\n\n            # Settings\n            self.active_policies = dict()\n            self.revocation_kits = dict()\n            self.store_policy_credentials = store_policy_credentials\n\n            self.log.info(self.banner)\n\n    def add_active_policy(self, active_policy):\n        \"\"\"\n        Adds a Policy object that is active on the NuCypher network to Alice's\n        `active_policies` dictionary by the policy ID.\n        \"\"\"\n        if active_policy.hrac in self.active_policies:\n            raise KeyError(\"Policy already exists in active_policies.\")\n        self.active_policies[active_policy.hrac] = active_policy\n\n    def generate_kfrags(self,\n                        bob: 'Bob',\n                        label: bytes,\n                        threshold: int = None,\n                        shares: int = None\n                        ) -> List:\n        \"\"\"\n        Generates re-encryption key frags (\"KFrags\") and returns them.\n\n        These KFrags can be used by Ursula to re-encrypt a Capsule for Bob so\n        that he can activate the Capsule.\n\n        :param bob: Bob instance which will be able to decrypt messages re-encrypted with these kfrags.\n        :param m: Minimum number of kfrags needed to activate a Capsule.\n        :param n: Total number of kfrags to generate\n        \"\"\"\n\n        bob_encrypting_key = bob.public_keys(DecryptingPower)\n        delegating_power = self._crypto_power.power_ups(DelegatingPower)\n        policy_key_and_kfrags = delegating_power.generate_kfrags(bob_pubkey_enc=bob_encrypting_key,\n                                                                 signer=self.stamp.as_umbral_signer(),\n                                                                 label=label,\n                                                                 threshold=threshold or self.threshold,\n                                                                 shares=shares or self.shares)\n        return policy_key_and_kfrags\n\n    def create_policy(self, bob: \"Bob\", label: bytes, **policy_params):\n        \"\"\"\n        Create a Policy so that Bob has access to all resources under label.\n        Generates KFrags and attaches them.\n        \"\"\"\n\n        policy_params = self.generate_policy_parameters(**policy_params)\n        shares = policy_params.pop('shares')\n\n        # Generate KFrags\n        public_key, kfrags = self.generate_kfrags(bob=bob,\n                                                  label=label,\n                                                  threshold=policy_params['threshold'],\n                                                  shares=shares)\n        payload = dict(label=label,\n                       bob=bob,\n                       kfrags=kfrags,\n                       public_key=public_key,\n                       **policy_params)\n\n        if self.federated_only:\n            # Use known nodes\n            policy = FederatedPolicy(publisher=self, **payload)\n        else:\n            # Sample from blockchain\n            payload.update(**policy_params)\n            policy = BlockchainPolicy(publisher=self, **payload)\n\n        return policy\n\n    def generate_policy_parameters(self,\n                                   threshold: Optional[int] = None,\n                                   shares: Optional[int] = None,\n                                   duration: Optional[int] = None,\n                                   commencement: Optional[maya.MayaDT] = None,\n                                   expiration: Optional[maya.MayaDT] = None,\n                                   value: Optional[int] = None,\n                                   rate: Optional[int] = None,\n                                   payment_method: Optional[PaymentMethod] = None\n                                   ) -> dict:\n        \"\"\"Construct policy creation from default parameters or overrides.\"\"\"\n\n        if not duration and not expiration:\n            raise ValueError(\"Policy end time must be specified as 'expiration' or 'duration', got neither.\")\n\n        # Merge injected and default params.\n        threshold = threshold or self.threshold\n        shares = shares or self.shares\n        duration = duration or self.duration\n        rate = rate if rate is not None else self.rate  # TODO conflict with CLI default value, see #1709\n        payment_method = payment_method or self.payment_method\n\n        # Calculate Policy Rate, Duration, and Value\n        quote = self.payment_method.quote(\n            shares=shares,\n            duration=duration,\n            commencement=commencement.epoch if commencement else None,\n            expiration=expiration.epoch if expiration else None,\n            rate=rate,\n            value=value\n        )\n\n        params = dict(\n            payment_method=payment_method,\n            threshold=threshold,\n            shares=shares,\n            duration=quote.duration,\n            commencement=quote.commencement,\n            expiration=quote.expiration,\n            rate=quote.rate,\n            value=quote.value\n        )\n        return params\n\n    def _check_grant_requirements(self, policy):\n        \"\"\"Called immediately before granting.\"\"\"\n        # TODO: Do not allow policies with an expiration beyond a node unbonding time.\n\n        # Policy Probationary Period\n        # TODO: Remove when the time is right.\n        # from nucypher.config.constants import END_OF_POLICIES_PROBATIONARY_PERIOD\n        # if policy.expiration > END_OF_POLICIES_PROBATIONARY_PERIOD:\n        #     raise RuntimeError(f\"The requested duration for this policy (until {policy.expiration}) exceeds the \"\n        #                        f\"probationary period ({END_OF_POLICIES_PROBATIONARY_PERIOD}).\")\n\n    def grant(self,\n              bob: \"Bob\",\n              label: bytes,\n              ursulas: set = None,\n              timeout: int = None,\n              **policy_params):\n\n        timeout = timeout or self.timeout\n\n        #\n        # Policy Creation\n        #\n\n        if ursulas:\n            # This might be the first time alice learns about the handpicked Ursulas.\n            for handpicked_ursula in ursulas:\n                self.remember_node(node=handpicked_ursula)\n\n        policy = self.create_policy(bob=bob, label=label, **policy_params)\n        self._check_grant_requirements(policy=policy)\n        self.log.debug(f\"Generated new policy proposal {policy} ... \")\n\n        #\n        # We'll find n Ursulas by default.  It's possible to \"play the field\" by trying different\n        # value and expiration combinations on a limited number of Ursulas;\n        # Users may decide to inject some market strategies here.\n        #\n\n        # If we're federated only, we need to block to make sure we have enough nodes.\n        if self.federated_only and len(self.known_nodes) < policy.shares:\n            good_to_go = self.block_until_number_of_known_nodes_is(number_of_nodes_to_know=policy.shares,\n                                                                   learn_on_this_thread=True,\n                                                                   timeout=timeout)\n            if not good_to_go:\n                raise ValueError(\n                    \"To make a Policy in federated mode, you need to know about \"\n                    \"all the Ursulas you need (in this case, {}); there's no other way to \"\n                    \"know which nodes to use.  Either pass them here or when you make the Policy, \"\n                    \"or run the learning loop on a network with enough Ursulas.\".format(policy.shares))\n\n        self.log.debug(f\"Enacting {policy} ... \")\n        enacted_policy = policy.enact(network_middleware=self.network_middleware, ursulas=ursulas)\n\n        self.add_active_policy(enacted_policy)\n        return enacted_policy\n\n    def get_policy_encrypting_key_from_label(self, label: bytes) -> PublicKey:\n        alice_delegating_power = self._crypto_power.power_ups(DelegatingPower)\n        policy_pubkey = alice_delegating_power.get_pubkey_from_label(label)\n        return policy_pubkey\n\n    def revoke(self,\n               policy: Policy,\n               onchain: bool = True,  # forced to False for federated mode\n               offchain: bool = True\n               ) -> Tuple[TxReceipt, Dict[ChecksumAddress, Tuple['Revocation', Exception]]]:\n\n        if not (offchain or onchain):\n            raise ValueError('offchain or onchain must be True to issue revocation')\n\n        receipt, failed = dict(), dict()\n\n        if onchain and (not self.federated_only):\n            pass\n            # TODO: Decouple onchain revocation from SubscriptionManager or deprecate.\n            # receipt = self.policy_agent.revoke_policy(policy_id=bytes(policy.hrac),\n            #                                           transacting_power=self._crypto_power.power_ups(TransactingPower))\n\n        if offchain:\n            \"\"\"\n            Parses the treasure map and revokes onchain arrangements in it.\n            If any nodes cannot be revoked, then the node_id is added to a\n            dict as a key, and the revocation and Ursula's response is added as\n            a value.\n            \"\"\"\n            try:\n                # Wait for a revocation threshold of nodes to be known ((n - m) + 1)\n                revocation_threshold = ((policy.shares - policy.threshold) + 1)\n                self.block_until_specific_nodes_are_known(\n                    policy.revocation_kit.revokable_addresses,\n                    allow_missing=(policy.shares - revocation_threshold))\n            except self.NotEnoughTeachers:\n                raise  # TODO  NRN\n\n            for node_id in policy.revocation_kit.revokable_addresses:\n                ursula = self.known_nodes[node_id]\n                revocation = policy.revocation_kit[node_id]\n                try:\n                    response = self.network_middleware.request_revocation(ursula, revocation)\n                except self.network_middleware.NotFound:\n                    failed[node_id] = (revocation, self.network_middleware.NotFound)\n                except self.network_middleware.UnexpectedResponse:\n                    failed[node_id] = (revocation, self.network_middleware.UnexpectedResponse)\n                else:\n                    if response.status_code != 200:\n                        message = f\"Failed to revocation for node {node_id} with status code {response.status_code}\"\n                        raise self.ActorError(message)\n\n        return receipt, failed\n\n    def decrypt_message_kit(self, label: bytes, message_kit: MessageKit) -> List[bytes]:\n        \"\"\"\n        Decrypt this Alice's own encrypted data.\n\n        I/O signatures match Bob's retrieve interface.\n        \"\"\"\n\n        delegating_power = self._crypto_power.power_ups(DelegatingPower)\n        decrypting_power = delegating_power.get_decrypting_power_from_label(label)\n        cleartext = decrypting_power.decrypt_message_kit(message_kit)\n\n        # TODO: why does it return a list of cleartexts but takes a single message kit?\n        # Shouldn't it be able to take a list of them too?\n        return [cleartext]",
  "class Bob(Character):\n    banner = BOB_BANNER\n    _default_crypto_powerups = [SigningPower, DecryptingPower]\n\n    class IncorrectCFragsReceived(Exception):\n        \"\"\"\n        Raised when Bob detects incorrect CFrags returned by some Ursulas\n        \"\"\"\n\n        def __init__(self, evidence: List):\n            self.evidence = evidence\n\n    def __init__(self,\n                 is_me: bool = True,\n                 verify_node_bonding: bool = False,\n                 eth_provider_uri: str = None,\n                 *args, **kwargs) -> None:\n\n        Character.__init__(self,\n                           is_me=is_me,\n                           known_node_class=Ursula,\n                           verify_node_bonding=verify_node_bonding,\n                           eth_provider_uri=eth_provider_uri,\n                           *args, **kwargs)\n\n        # Cache of decrypted treasure maps\n        self._treasure_maps: Dict[int, TreasureMap] = {}\n\n        self.log = Logger(self.__class__.__name__)\n        if is_me:\n            self.log.info(self.banner)\n\n    def _decrypt_treasure_map(self,\n                              encrypted_treasure_map: EncryptedTreasureMap,\n                              publisher_verifying_key: PublicKey\n                              ) -> TreasureMap:\n        decrypting_power = self._crypto_power.power_ups(DecryptingPower)\n        return decrypting_power.decrypt_treasure_map(encrypted_treasure_map,\n                                                     publisher_verifying_key=publisher_verifying_key)\n\n    def retrieve(\n            self,\n            message_kits: Sequence[Union[MessageKit, PolicyMessageKit]],\n            alice_verifying_key: PublicKey,  # KeyFrag signer's key\n            encrypted_treasure_map: EncryptedTreasureMap,\n            publisher_verifying_key: Optional[PublicKey] = None,\n            **context,  # TODO: dont use one context to rule them all\n            ) -> List[PolicyMessageKit]:\n        \"\"\"\n        Attempts to retrieve reencrypted capsule fragments\n        corresponding to given message kits from Ursulas.\n\n        Accepts both \"clean\" message kits (obtained from a side channel)\n        and \"loaded\" ones (with earlier retrieved capsule frags attached,\n        along with the addresses of Ursulas they were obtained from).\n\n        Returns a list of loaded message kits corresponding to the input list,\n        with the kits containing the capsule fragments obtained during the retrieval.\n        These kits can be used as an external cache to preserve the cfrags between\n        several retrieval attempts.\n        \"\"\"\n\n        if not publisher_verifying_key:\n            publisher_verifying_key = alice_verifying_key\n        publisher_verifying_key = PublicKey.from_bytes(bytes(publisher_verifying_key))\n\n        # A small optimization to avoid multiple treasure map decryptions.\n        map_hash = hash(bytes(encrypted_treasure_map))\n        if map_hash in self._treasure_maps:\n            treasure_map = self._treasure_maps[map_hash]\n        else:\n            # Have to decrypt the treasure map first to find out what the threshold is.\n            # Otherwise, we could check the message kits for completeness right away.\n            treasure_map = self._decrypt_treasure_map(encrypted_treasure_map, publisher_verifying_key)\n            self._treasure_maps[map_hash] = treasure_map\n\n        # Normalize input\n        message_kits: List[PolicyMessageKit] = [\n            PolicyMessageKit.from_message_kit(message_kit, treasure_map.policy_encrypting_key, treasure_map.threshold)\n                if isinstance(message_kit, MessageKit) else message_kit\n            for message_kit in message_kits\n            ]\n\n        # Clear up all unrelated information from message kits before retrieval.\n        retrieval_kits = [message_kit.as_retrieval_kit() for message_kit in message_kits]\n\n        # Retrieve capsule frags\n        client = RetrievalClient(learner=self)\n        retrieval_results, _ = client.retrieve_cfrags(\n            treasure_map=treasure_map,\n            retrieval_kits=retrieval_kits,\n            alice_verifying_key=alice_verifying_key,\n            bob_encrypting_key=self.public_keys(DecryptingPower),\n            bob_verifying_key=self.stamp.as_umbral_pubkey(),\n            **context\n        )\n\n        # Refill message kits with newly retrieved capsule frags\n        results = []\n        for message_kit, retrieval_result in zip(message_kits, retrieval_results):\n            results.append(message_kit.with_result(retrieval_result))\n\n        return results\n\n    def retrieve_and_decrypt(self, *args, **kwds) -> List[bytes]:\n        \"\"\"\n        Attempts to retrieve reencrypted capsule fragments from Ursulas\n        and decrypt the ciphertexts in the given message kits.\n\n        See ``retrieve()`` for the parameter list.\n        \"\"\"\n\n        message_kits = self.retrieve(*args, **kwds)\n\n        for message_kit in message_kits:\n            if not message_kit.is_decryptable_by_receiver():\n                raise Ursula.NotEnoughUrsulas(f\"Not enough cfrags retrieved to open capsule {message_kit.message_kit.capsule}\")\n\n        cleartexts = []\n        decrypting_power = self._crypto_power.power_ups(DecryptingPower)\n        for message_kit in message_kits:\n            cleartext = decrypting_power.decrypt_message_kit(message_kit)\n            cleartexts.append(cleartext)\n\n        return cleartexts",
  "class Ursula(Teacher, Character, Operator):\n\n    banner = URSULA_BANNER\n    _alice_class = Alice\n\n    _default_crypto_powerups = [\n        SigningPower,\n        DecryptingPower,\n        # TLSHostingPower  # Still considered a default for Ursula, but needs the host context\n    ]\n\n    class NotEnoughUrsulas(Learner.NotEnoughTeachers):\n        \"\"\"\n        All Characters depend on knowing about enough Ursulas to perform their role.\n        This exception is raised when a piece of logic can't proceed without more Ursulas.\n        \"\"\"\n\n    class NotFound(Exception):\n        pass\n\n    def __init__(self,\n\n                 # Ursula\n                 rest_host: str,\n                 rest_port: int,\n                 domain: str,\n                 is_me: bool = True,\n\n                 certificate: Certificate = None,\n                 certificate_filepath: Optional[Path] = None,\n\n                 availability_check: bool = False,  # TODO: Remove from init\n                 metadata: Optional[NodeMetadata] = None,\n\n                 # Blockchain\n                 checksum_address: ChecksumAddress = None,\n                 operator_address: ChecksumAddress = None,  # TODO: deprecate, and rename to \"checksum_address\"\n                 client_password: str = None,\n                 operator_signature_from_metadata=NOT_SIGNED,\n\n                 eth_provider_uri: str = None,\n                 payment_method: PaymentMethod = None,\n\n                 # Character\n                 abort_on_learning_error: bool = False,\n                 federated_only: bool = False,\n                 crypto_power=None,\n                 known_nodes: Iterable[Teacher] = None,\n\n                 **character_kwargs\n                 ):\n\n        Character.__init__(self,\n                           is_me=is_me,\n                           checksum_address=checksum_address,\n                           federated_only=federated_only,\n                           crypto_power=crypto_power,\n                           abort_on_learning_error=abort_on_learning_error,\n                           known_nodes=known_nodes,\n                           domain=domain,\n                           known_node_class=Ursula,\n                           include_self_in_the_state=True,\n                           eth_provider_uri=eth_provider_uri,\n                           **character_kwargs)\n\n        if is_me:\n\n            if metadata:\n                raise ValueError(\"A local node must generate its own metadata.\")\n            self._metadata = None\n\n            # Operating Mode\n            self.known_node_class.set_federated_mode(federated_only)\n\n            # Health Checks\n            self._availability_check = availability_check\n            self._availability_tracker = AvailabilityTracker(ursula=self)\n            if not federated_only:\n                self._operator_bonded_tracker = OperatorBondedTracker(ursula=self)\n\n            # Policy Payment\n            if federated_only and not payment_method:\n                # Federated payments are free by default.\n                payment_method = FreeReencryptions()\n\n            # Decentralized Operator\n            if not federated_only:\n                if not eth_provider_uri:\n                    raise ValueError('ETH Provider URI is required to init a decentralized character.')\n                if not payment_method:\n                    raise ValueError('Payment method is required to init a decentralized character.')\n\n                # TODO: Move to method\n                # Prepare a TransactingPower from worker node's transacting keys\n                transacting_power = TransactingPower(account=operator_address,\n                                                     password=client_password,\n                                                     signer=self.signer,\n                                                     cache=True)\n                self.transacting_power = transacting_power\n                self._crypto_power.consume_power_up(transacting_power)\n\n                # Use this power to substantiate the stamp\n                self.__substantiate_stamp()\n\n                try:\n                    Operator.__init__(self,\n                                      is_me=is_me,\n                                      domain=self.domain,\n                                      transacting_power=self.transacting_power,\n                                      registry=self.registry,\n                                      operator_address=operator_address,\n                                      payment_method=payment_method)\n                except (Exception, self.OperatorError):\n                    # TODO: Do not announce self to \"other nodes\" until this init is finished.\n                    # It's not possible to finish constructing this node.\n                    self.stop(halt_reactor=False)\n                    raise\n\n            # Payment Method\n            # TODO: What value is acceptable here for a remote node?\n            # TODO: Include accepted payment method announcements in metadata?\n            self.payment_method = payment_method\n\n            # Server\n            self.rest_server = self._make_local_server(host=rest_host, port=rest_port)\n\n            # Self-signed TLS certificate of self for Teacher.__init__\n            certificate_filepath = self._crypto_power.power_ups(TLSHostingPower).keypair.certificate_filepath\n            certificate = self._crypto_power.power_ups(TLSHostingPower).keypair.certificate\n\n            # Only *YOU* can prevent forest fires\n            self.revoked_policies: Set[bytes] = set()\n\n            # Care to introduce yourself?\n            message = \"THIS IS YOU: {}: {}\".format(self.__class__.__name__, self)\n            self.log.info(message)\n            self.log.info(self.banner.format(self.nickname))\n\n        else:\n            # Stranger HTTP Server\n            # TODO: Use InterfaceInfo only\n            self.rest_server = ProxyRESTServer(rest_host=rest_host, rest_port=rest_port)\n            self._metadata = metadata\n            self.__operator_address = None\n\n        # Teacher (All Modes)\n        Teacher.__init__(self,\n                         domain=domain,\n                         certificate=certificate,\n                         certificate_filepath=certificate_filepath)\n\n    def __get_hosting_power(self, host: str) -> TLSHostingPower:\n        try:\n            # Pre-existing or injected power\n            tls_hosting_power = self._crypto_power.power_ups(TLSHostingPower)\n        except TLSHostingPower.not_found_error:\n            if self.keystore:\n                # Derive TLS private key from seed\n                tls_hosting_power = self.keystore.derive_crypto_power(TLSHostingPower, host=host)\n            else:\n                # Generate ephemeral private key (\"Dev Mode\")\n                tls_hosting_keypair = HostingKeypair(host=host, generate_certificate=True)\n                tls_hosting_power = TLSHostingPower(keypair=tls_hosting_keypair, host=host)\n            self._crypto_power.consume_power_up(tls_hosting_power)  # Consume!\n        return tls_hosting_power\n\n    def _make_local_server(self, host, port) -> ProxyRESTServer:\n        rest_app = make_rest_app(this_node=self)\n        rest_server = ProxyRESTServer(rest_host=host,\n                                      rest_port=port,\n                                      rest_app=rest_app,\n                                      hosting_power=self.__get_hosting_power(host=host))\n        return rest_server\n\n    def __substantiate_stamp(self):\n        transacting_power = self._crypto_power.power_ups(TransactingPower)\n        signature = transacting_power.sign_message(message=bytes(self.stamp))\n        self.__operator_signature = signature\n        self.__operator_address = transacting_power.account\n        message = f\"Created decentralized identity evidence: {self.__operator_signature[:10].hex()}\"\n        self.log.debug(message)\n\n    @property\n    def operator_signature(self):\n        return self.__operator_signature\n\n    @property\n    def operator_address(self):\n        if not self.federated_only:\n            # TODO (#2875): The reason for the fork here is the difference in available information\n            # for local and remote nodes.\n            # The local node knows its operator address, but doesn't yet know the staker address.\n            # For the remote node, we know its staker address (from the metadata),\n            # but don't know the worker address.\n            # Can this be resolved more elegantly?\n            if getattr(self, 'is_me', False):\n                return self._local_operator_address()\n            else:\n                if not self.__operator_address:\n                    operator_address = to_checksum_address(self.metadata().payload.derive_operator_address())\n                    self.__operator_address = operator_address\n                return self.__operator_address\n        else:\n            raise RuntimeError(\"Federated nodes do not have an operator address\")\n\n    def __preflight(self) -> None:\n        \"\"\"Called immediately before running services\n        If an exception is raised, Ursula startup will be interrupted.\n\n        \"\"\"\n        validate_operator_ip(ip=self.rest_interface.host)\n\n    def run(self,\n            emitter: StdoutEmitter = None,\n            discovery: bool = True,  # TODO: see below\n            availability: bool = False,\n            worker: bool = True,\n            hendrix: bool = True,\n            start_reactor: bool = True,\n            prometheus_config: 'PrometheusMetricsConfig' = None,\n            preflight: bool = True,\n            block_until_ready: bool = True,\n            eager: bool = False\n            ) -> None:\n\n        \"\"\"Schedule and start select ursula services, then optionally start the reactor.\"\"\"\n\n        # Connect to Provider\n        if not self.federated_only:\n            if not BlockchainInterfaceFactory.is_interface_initialized(eth_provider_uri=self.eth_provider_uri):\n                BlockchainInterfaceFactory.initialize_interface(eth_provider_uri=self.eth_provider_uri)\n\n        if preflight:\n            self.__preflight()\n\n        #\n        # Async loops ordered by schedule priority\n        #\n\n        if emitter:\n            emitter.message(f\"Starting services\", color='yellow')\n\n        if discovery and not self.lonely:\n            self.start_learning_loop(now=eager)\n            if emitter:\n                emitter.message(f\"\u2713 Node Discovery ({self.domain.capitalize()})\", color='green')\n\n        if self._availability_check or availability:\n            self._availability_tracker.start(now=eager)\n            if emitter:\n                emitter.message(f\"\u2713 Availability Checks\", color='green')\n\n        if worker and not self.federated_only:\n            if block_until_ready:\n                # Sets (staker's) checksum address; Prevent worker startup before bonding\n                self.block_until_ready()\n\n            work_is_needed = self.get_work_is_needed_check()(self)\n            if work_is_needed:\n                message = \"\u2713 Work Tracking\"\n                self.work_tracker.start(commit_now=True, requirement_func=self.work_tracker.worker.get_work_is_needed_check())  # requirement_func=self._availability_tracker.status)  # TODO: #2277\n            else:\n                message = \"\u2713 Operator already confirmed.  Not starting worktracker.\"\n            if emitter:\n                emitter.message(message, color='green')\n\n        #\n        # Non-order dependant services\n        #\n\n        # Continuous bonded check now that Ursula is all ready to run\n        if not self.federated_only:\n            self._operator_bonded_tracker.start(now=eager)\n            if emitter:\n                emitter.message(f\"\u2713 Start Operator Bonded Tracker\", color='green')\n\n        if prometheus_config:\n            # Locally scoped to prevent import without prometheus explicitly installed\n            from nucypher.utilities.prometheus.metrics import start_prometheus_exporter\n\n            start_prometheus_exporter(ursula=self, prometheus_config=prometheus_config)\n            if emitter:\n                emitter.message(f\"\u2713 Prometheus Exporter\", color='green')\n\n        if hendrix:\n            if emitter:\n                emitter.message(f\"\u2713 Rest Server https://{self.rest_interface}\", color='green')\n\n            deployer = self.get_deployer()\n            deployer.addServices()\n            deployer.catalogServers(deployer.hendrix)\n\n            if not start_reactor:\n                return\n\n            if emitter:\n                emitter.message(\"Working ~ Keep Ursula Online!\", color='blue', bold=True)\n\n            try:\n                deployer.run()  # <--- Blocking Call (Reactor)\n            except Exception as e:\n                self.log.critical(str(e))\n                if emitter:\n                    emitter.message(f\"{e.__class__.__name__} {e}\", color='red', bold=True)\n                raise  # Crash :-(\n\n        elif start_reactor:  # ... without hendrix\n            reactor.run()  # <--- Blocking Call (Reactor)\n\n    def stop(self, halt_reactor: bool = False) -> None:\n        \"\"\"\n        Stop services for partially or fully initialized characters.\n        # CAUTION #\n        \"\"\"\n        self.log.debug(f\"---------Stopping {self}\")\n        # Handles the shutdown of a partially initialized character.\n        with contextlib.suppress(AttributeError):  # TODO: Is this acceptable here, what are alternatives?\n            self._availability_tracker.stop()\n            self.stop_learning_loop()\n            if not self.federated_only:\n                self.work_tracker.stop()\n                self._operator_bonded_tracker.stop()\n        if halt_reactor:\n            reactor.stop()\n\n    def _finalize(self):\n        \"\"\"\n        Cleans up Ursula from objects that may eat up system resources.\n        Useful for testing purposes, where many Ursulas are created and destroyed,\n        and references to them may persist for too long.\n        This method is not needed if all references to the Ursula are released.\n\n        **Warning:** invalidates the Ursula.\n        \"\"\"\n        self.rest_server = INVALIDATED\n\n    def rest_information(self):\n        hosting_power = self._crypto_power.power_ups(TLSHostingPower)\n\n        return (\n            self.rest_server.rest_interface,\n            hosting_power.keypair.certificate,\n            hosting_power.keypair.pubkey\n        )\n\n    @property\n    def rest_interface(self):\n        return self.rest_server.rest_interface\n\n    def get_deployer(self):\n        port = self.rest_interface.port\n        deployer = self._crypto_power.power_ups(TLSHostingPower).get_deployer(rest_app=self.rest_app, port=port)\n        return deployer\n\n    @property\n    def operator_signature_from_metadata(self):\n        return self._metadata.payload.operator_signature or NOT_SIGNED\n\n    def _generate_metadata(self) -> NodeMetadata:\n        # Assuming that the attributes collected there do not change,\n        # so we can cache the result of this method.\n        # TODO: should this be a method of Teacher?\n        timestamp = maya.now()\n        if self.federated_only:\n            operator_signature = None\n        else:\n            operator_signature = self.operator_signature\n        payload = NodeMetadataPayload(staking_provider_address=Address(self.canonical_address),\n                                      domain=self.domain,\n                                      timestamp_epoch=timestamp.epoch,\n                                      operator_signature=operator_signature,\n                                      verifying_key=self.public_keys(SigningPower),\n                                      encrypting_key=self.public_keys(DecryptingPower),\n                                      certificate_der=self.certificate.public_bytes(Encoding.DER),\n                                      host=self.rest_interface.host,\n                                      port=self.rest_interface.port,\n                                      )\n        return NodeMetadata(signer=self.stamp.as_umbral_signer(),\n                            payload=payload)\n\n    def metadata(self):\n        if not self._metadata:\n            self._metadata = self._generate_metadata()\n        return self._metadata\n\n    @property\n    def timestamp(self):\n        return maya.MayaDT(self.metadata().payload.timestamp_epoch)\n\n    #\n    # Alternate Constructors\n    #\n\n    @classmethod\n    def from_metadata_bytes(cls, metadata_bytes):\n        # TODO: should be a method of `NodeSprout`, or maybe `NodeMetadata` *is* `NodeSprout`.\n        # Fix when we get rid of inplace maturation.\n        return NodeSprout(NodeMetadata.from_bytes(metadata_bytes))\n\n    @classmethod\n    def from_rest_url(cls,\n                      network_middleware: RestMiddleware,\n                      host: str,\n                      port: int):\n        response_data = network_middleware.client.node_information(host, port)\n        stranger_ursula_from_public_keys = cls.from_metadata_bytes(response_data)\n        return stranger_ursula_from_public_keys\n\n    @classmethod\n    def from_seednode_metadata(cls, seednode_metadata, *args, **kwargs):\n        \"\"\"\n        Essentially another deserialization method, but this one doesn't reconstruct a complete\n        node from bytes; instead it's just enough to connect to and verify a node.\n\n        NOTE: This is a federated only method.\n        \"\"\"\n        seed_uri = f'{seednode_metadata.checksum_address}@{seednode_metadata.rest_host}:{seednode_metadata.rest_port}'\n        return cls.from_seed_and_stake_info(seed_uri=seed_uri, *args, **kwargs)\n\n    @classmethod\n    def seednode_for_network(cls, network: str) -> 'Ursula':\n        \"\"\"Returns a default seednode ursula for a given network.\"\"\"\n        try:\n            url = TEACHER_NODES[network][0]\n        except KeyError:\n            raise ValueError(f'\"{network}\" is not a known network.')\n        except IndexError:\n            raise ValueError(f'No default seednodes available for \"{network}\".')\n        ursula = cls.from_seed_and_stake_info(seed_uri=url)\n        return ursula\n\n    @classmethod\n    def from_teacher_uri(cls,\n                         federated_only: bool,\n                         teacher_uri: str,\n                         min_stake: int,\n                         network_middleware: RestMiddleware = None,\n                         registry: BaseContractRegistry = None,\n                         retry_attempts: int = 2,\n                         retry_interval: int = 2\n                         ) -> 'Ursula':\n\n        def __attempt(attempt=1, interval=retry_interval) -> Ursula:\n            if attempt >= retry_attempts:\n                raise ConnectionRefusedError(\"Host {} Refused Connection\".format(teacher_uri))\n\n            try:\n                teacher = cls.from_seed_and_stake_info(seed_uri=teacher_uri,\n                                                       federated_only=federated_only,\n                                                       minimum_stake=min_stake,\n                                                       network_middleware=network_middleware,\n                                                       registry=registry)\n\n            except NodeSeemsToBeDown as e:\n                log = Logger(cls.__name__)\n                log.warn(\n                    \"Can't connect to peer (attempt {}).  Will retry in {} seconds.\".format(attempt, interval))\n                time.sleep(interval)\n                return __attempt(attempt=attempt + 1)\n            else:\n                return teacher\n\n        return __attempt()\n\n    @classmethod\n    def from_seed_and_stake_info(cls,\n                                 seed_uri: str,\n                                 federated_only: bool = False,\n                                 minimum_stake: int = 0,\n                                 registry: BaseContractRegistry = None,\n                                 network_middleware: RestMiddleware = None,\n                                 ) -> Union['Ursula', 'NodeSprout']:\n\n        if network_middleware is None:\n            network_middleware = RestMiddleware(registry=registry)\n\n        # Parse node URI\n        host, port, staking_provider_address = parse_node_uri(seed_uri)\n\n        # Fetch the hosts TLS certificate and read the common name\n        try:\n            certificate, _filepath = network_middleware.client.get_certificate(host=host, port=port)\n        except NodeSeemsToBeDown as e:\n            e.args += (f\"While trying to load seednode {seed_uri}\",)\n            e.crash_right_now = True\n            raise\n        real_host = certificate.subject.get_attributes_for_oid(NameOID.COMMON_NAME)[0].value\n\n        # Load the host as a potential seed node\n        potential_seed_node = cls.from_rest_url(\n            host=real_host,\n            port=port,\n            network_middleware=network_middleware,\n        )\n\n        # Check the node's stake (optional)\n        if minimum_stake > 0 and staking_provider_address and not federated_only:\n            application_agent = ContractAgency.get_agent(PREApplicationAgent, registry=registry)\n            seednode_stake = application_agent.get_authorized_stake(staking_provider=staking_provider_address)\n            if seednode_stake < minimum_stake:\n                raise Learner.NotATeacher(f\"{staking_provider_address} is staking less than the specified minimum stake value ({minimum_stake}).\")\n\n        return potential_seed_node\n\n    @classmethod\n    def from_storage(cls,\n                     node_storage: NodeStorage,\n                     checksum_adress: str,\n                     federated_only: bool = False) -> 'Ursula':\n        return node_storage.get(checksum_address=checksum_adress,\n                                federated_only=federated_only)\n\n    #\n    # Properties\n    #\n\n    @property\n    def rest_url(self):\n        try:\n            return self.rest_server.rest_url\n        except AttributeError:\n            raise AttributeError(\"No rest server attached\")\n\n    @property\n    def rest_app(self):\n        rest_app_on_server = self.rest_server.rest_app\n\n        if rest_app_on_server is PUBLIC_ONLY or not rest_app_on_server:\n            m = \"This Ursula doesn't have a REST app attached. If you want one, init with is_me and attach_server.\"\n            raise PowerUpError(m)\n        else:\n            return rest_app_on_server\n\n    def interface_info_with_metadata(self):\n        # TODO: Do we ever actually use this without using the rest of the serialized Ursula?  337\n        return constants.BYTESTRING_IS_URSULA_IFACE_INFO + bytes(self)\n\n    #\n    # Re-Encryption\n    #\n\n    def _decrypt_kfrag(self, encrypted_kfrag: EncryptedKeyFrag, hrac: HRAC, publisher_verifying_key: PublicKey) -> VerifiedKeyFrag:\n        decrypting_power = self._crypto_power.power_ups(DecryptingPower)\n        return decrypting_power.decrypt_kfrag(encrypted_kfrag, hrac, publisher_verifying_key)\n\n    def _reencrypt(self, kfrag: VerifiedKeyFrag, capsules) -> ReencryptionResponse:\n        cfrags = []\n        for capsule in capsules:\n            cfrag = reencrypt(capsule, kfrag)\n            cfrags.append(cfrag)\n            self.log.info(f\"Re-encrypted capsule {capsule} -> made {cfrag}.\")\n        results = list(zip(capsules, cfrags))\n        return ReencryptionResponse(signer=self.stamp.as_umbral_signer(), capsules_and_vcfrags=results)\n\n    def status_info(self, omit_known_nodes: bool = False) -> 'LocalUrsulaStatus':\n\n        domain = self.domain\n        version = nucypher.__version__\n\n        fleet_state = self.known_nodes.latest_state()\n        previous_fleet_states = self.known_nodes.previous_states(4)\n\n        if not omit_known_nodes:\n            known_nodes_info = [self.known_nodes.status_info(node) for node in self.known_nodes]\n        else:\n            known_nodes_info = None\n\n        if not self.federated_only:\n            balance_eth = float(self.eth_balance)\n        else:\n            balance_eth = None\n\n        return LocalUrsulaStatus(nickname=self.nickname,\n                                 staker_address=self.checksum_address,\n                                 operator_address=self.operator_address,\n                                 rest_url=self.rest_url(),\n                                 timestamp=self.timestamp,\n                                 domain=domain,\n                                 version=version,\n                                 fleet_state=fleet_state,\n                                 previous_fleet_states=previous_fleet_states,\n                                 known_nodes=known_nodes_info,\n                                 balance_eth=balance_eth,\n                                 )",
  "class LocalUrsulaStatus(NamedTuple):\n    nickname: Nickname\n    staker_address: ChecksumAddress\n    operator_address: str\n    rest_url: str\n    timestamp: maya.MayaDT\n    domain: str\n    version: str\n    fleet_state: ArchivedFleetState\n    previous_fleet_states: List[ArchivedFleetState]\n    known_nodes: Optional[List[RemoteUrsulaStatus]]\n    balance_eth: float\n\n    def to_json(self) -> Dict[str, Any]:\n        if self.known_nodes is None:\n            known_nodes_json = None\n        else:\n            known_nodes_json = [status.to_json() for status in self.known_nodes]\n        return dict(nickname=self.nickname.to_json(),\n                    staker_address=self.staker_address,\n                    operator_address=self.operator_address,\n                    rest_url=self.rest_url,\n                    timestamp=self.timestamp.iso8601(),\n                    domain=self.domain,\n                    version=self.version,\n                    fleet_state=self.fleet_state.to_json(),\n                    previous_fleet_states=[state.to_json() for state in self.previous_fleet_states],\n                    known_nodes=known_nodes_json,\n                    balance_eth=self.balance_eth,\n                    )",
  "class Enrico(Character):\n    \"\"\"A Character that represents a Data Source that encrypts data for some policy's public key\"\"\"\n\n    banner = ENRICO_BANNER\n    _default_crypto_powerups = [SigningPower]\n\n    def __init__(self,\n                 is_me: bool = True,\n                 policy_encrypting_key: Optional[PublicKey] = None,\n                 *args, **kwargs):\n\n        self._policy_pubkey = policy_encrypting_key\n\n        # Enrico never uses the blockchain (hence federated_only)\n        kwargs['federated_only'] = True\n        kwargs['known_node_class'] = None\n        super().__init__(is_me=is_me, *args, **kwargs)\n\n        self.log = Logger(f'{self.__class__.__name__}-{bytes(self.public_keys(SigningPower)).hex()[:6]}')\n        if is_me:\n            self.log.info(self.banner.format(policy_encrypting_key))\n\n    def encrypt_message(\n        self, plaintext: bytes, conditions: Optional[LingoList] = None\n    ) -> MessageKit:\n        # TODO: #2107 Rename to \"encrypt\"\n        if conditions:\n            # validate\n            validate_condition_lingo(conditions)\n            conditions = Conditions(json.dumps(conditions))\n        message_kit = MessageKit(policy_encrypting_key=self.policy_pubkey,\n                                 plaintext=plaintext,\n                                 conditions=conditions)\n        return message_kit\n\n    @classmethod\n    def from_alice(cls, alice: Alice, label: bytes):\n        \"\"\"\n        :param alice: Not a stranger.  This is your Alice who will derive the policy keypair, leaving Enrico with the public part.\n        :param label: The label with which to derive the key.\n        :return:\n        \"\"\"\n        policy_pubkey_enc = alice.get_policy_encrypting_key_from_label(label)\n        return cls(policy_encrypting_key=policy_pubkey_enc)\n\n    @property\n    def policy_pubkey(self):\n        if not self._policy_pubkey:\n            raise TypeError(\"This Enrico doesn't know which policy encrypting key he used.  Oh well.\")\n        return self._policy_pubkey\n\n    def _set_known_node_class(self, *args, **kwargs):\n        \"\"\"Enrico doesn't init nodes, so it doesn't care what class they are.\"\"\"",
  "def __init__(self,\n\n                 # Mode\n                 is_me: bool = True,\n                 federated_only: bool = False,\n                 eth_provider_uri: str = None,\n                 signer=None,\n\n                 # Ownership\n                 checksum_address: str = None,\n\n                 # M of N\n                 threshold: Optional[int] = None,\n                 shares: Optional[int] = None,\n\n                 # Policy Value\n                 rate: int = None,\n                 duration: int = None,\n                 payment_method: PaymentMethod = None,\n\n                 # Policy Storage\n                 store_policy_credentials: bool = None,\n\n                 # Middleware\n                 timeout: int = 10,  # seconds  # TODO: configure  NRN\n                 network_middleware: RestMiddleware = None,\n\n                 *args, **kwargs) -> None:\n\n        #\n        # Fallback Policy Values\n        #\n\n        self.timeout = timeout\n\n        if is_me:\n            self.threshold = threshold\n            self.shares = shares\n\n            self._policy_queue = Queue()\n            self._policy_queue.put(READY)\n        else:\n            self.threshold = STRANGER_ALICE\n            self.shares = STRANGER_ALICE\n\n        Character.__init__(self,\n                           known_node_class=Ursula,\n                           is_me=is_me,\n                           federated_only=federated_only,\n                           eth_provider_uri=eth_provider_uri,\n                           checksum_address=checksum_address,\n                           network_middleware=network_middleware,\n                           *args, **kwargs)\n\n        if is_me and not federated_only:  # TODO: #289\n            if not eth_provider_uri:\n                raise ValueError('ETH Provider URI is required to init a decentralized character.')\n\n            blockchain = BlockchainInterfaceFactory.get_interface(eth_provider_uri=self.eth_provider_uri)\n            signer = signer or Web3Signer(blockchain.client)  # fallback to web3 provider by default for Alice.\n            self.transacting_power = TransactingPower(account=self.checksum_address, signer=signer)\n            self._crypto_power.consume_power_up(self.transacting_power)\n            BlockchainPolicyAuthor.__init__(self,\n                                            domain=self.domain,\n                                            transacting_power=self.transacting_power,\n                                            registry=self.registry,\n                                            eth_provider_uri=eth_provider_uri)\n\n        self.log = Logger(self.__class__.__name__)\n        if is_me:\n\n            # Policy Payment\n            if federated_only and not payment_method:\n                # Federated payments are free by default.\n                payment_method = FreeReencryptions()\n            if not payment_method:\n                raise ValueError('payment_method is a required argument for a local Alice.')\n            self.payment_method = payment_method\n            self.rate = rate\n            self.duration = duration\n\n            # Settings\n            self.active_policies = dict()\n            self.revocation_kits = dict()\n            self.store_policy_credentials = store_policy_credentials\n\n            self.log.info(self.banner)",
  "def add_active_policy(self, active_policy):\n        \"\"\"\n        Adds a Policy object that is active on the NuCypher network to Alice's\n        `active_policies` dictionary by the policy ID.\n        \"\"\"\n        if active_policy.hrac in self.active_policies:\n            raise KeyError(\"Policy already exists in active_policies.\")\n        self.active_policies[active_policy.hrac] = active_policy",
  "def generate_kfrags(self,\n                        bob: 'Bob',\n                        label: bytes,\n                        threshold: int = None,\n                        shares: int = None\n                        ) -> List:\n        \"\"\"\n        Generates re-encryption key frags (\"KFrags\") and returns them.\n\n        These KFrags can be used by Ursula to re-encrypt a Capsule for Bob so\n        that he can activate the Capsule.\n\n        :param bob: Bob instance which will be able to decrypt messages re-encrypted with these kfrags.\n        :param m: Minimum number of kfrags needed to activate a Capsule.\n        :param n: Total number of kfrags to generate\n        \"\"\"\n\n        bob_encrypting_key = bob.public_keys(DecryptingPower)\n        delegating_power = self._crypto_power.power_ups(DelegatingPower)\n        policy_key_and_kfrags = delegating_power.generate_kfrags(bob_pubkey_enc=bob_encrypting_key,\n                                                                 signer=self.stamp.as_umbral_signer(),\n                                                                 label=label,\n                                                                 threshold=threshold or self.threshold,\n                                                                 shares=shares or self.shares)\n        return policy_key_and_kfrags",
  "def create_policy(self, bob: \"Bob\", label: bytes, **policy_params):\n        \"\"\"\n        Create a Policy so that Bob has access to all resources under label.\n        Generates KFrags and attaches them.\n        \"\"\"\n\n        policy_params = self.generate_policy_parameters(**policy_params)\n        shares = policy_params.pop('shares')\n\n        # Generate KFrags\n        public_key, kfrags = self.generate_kfrags(bob=bob,\n                                                  label=label,\n                                                  threshold=policy_params['threshold'],\n                                                  shares=shares)\n        payload = dict(label=label,\n                       bob=bob,\n                       kfrags=kfrags,\n                       public_key=public_key,\n                       **policy_params)\n\n        if self.federated_only:\n            # Use known nodes\n            policy = FederatedPolicy(publisher=self, **payload)\n        else:\n            # Sample from blockchain\n            payload.update(**policy_params)\n            policy = BlockchainPolicy(publisher=self, **payload)\n\n        return policy",
  "def generate_policy_parameters(self,\n                                   threshold: Optional[int] = None,\n                                   shares: Optional[int] = None,\n                                   duration: Optional[int] = None,\n                                   commencement: Optional[maya.MayaDT] = None,\n                                   expiration: Optional[maya.MayaDT] = None,\n                                   value: Optional[int] = None,\n                                   rate: Optional[int] = None,\n                                   payment_method: Optional[PaymentMethod] = None\n                                   ) -> dict:\n        \"\"\"Construct policy creation from default parameters or overrides.\"\"\"\n\n        if not duration and not expiration:\n            raise ValueError(\"Policy end time must be specified as 'expiration' or 'duration', got neither.\")\n\n        # Merge injected and default params.\n        threshold = threshold or self.threshold\n        shares = shares or self.shares\n        duration = duration or self.duration\n        rate = rate if rate is not None else self.rate  # TODO conflict with CLI default value, see #1709\n        payment_method = payment_method or self.payment_method\n\n        # Calculate Policy Rate, Duration, and Value\n        quote = self.payment_method.quote(\n            shares=shares,\n            duration=duration,\n            commencement=commencement.epoch if commencement else None,\n            expiration=expiration.epoch if expiration else None,\n            rate=rate,\n            value=value\n        )\n\n        params = dict(\n            payment_method=payment_method,\n            threshold=threshold,\n            shares=shares,\n            duration=quote.duration,\n            commencement=quote.commencement,\n            expiration=quote.expiration,\n            rate=quote.rate,\n            value=quote.value\n        )\n        return params",
  "def _check_grant_requirements(self, policy):\n        \"\"\"Called immediately before granting.\"\"\"",
  "def grant(self,\n              bob: \"Bob\",\n              label: bytes,\n              ursulas: set = None,\n              timeout: int = None,\n              **policy_params):\n\n        timeout = timeout or self.timeout\n\n        #\n        # Policy Creation\n        #\n\n        if ursulas:\n            # This might be the first time alice learns about the handpicked Ursulas.\n            for handpicked_ursula in ursulas:\n                self.remember_node(node=handpicked_ursula)\n\n        policy = self.create_policy(bob=bob, label=label, **policy_params)\n        self._check_grant_requirements(policy=policy)\n        self.log.debug(f\"Generated new policy proposal {policy} ... \")\n\n        #\n        # We'll find n Ursulas by default.  It's possible to \"play the field\" by trying different\n        # value and expiration combinations on a limited number of Ursulas;\n        # Users may decide to inject some market strategies here.\n        #\n\n        # If we're federated only, we need to block to make sure we have enough nodes.\n        if self.federated_only and len(self.known_nodes) < policy.shares:\n            good_to_go = self.block_until_number_of_known_nodes_is(number_of_nodes_to_know=policy.shares,\n                                                                   learn_on_this_thread=True,\n                                                                   timeout=timeout)\n            if not good_to_go:\n                raise ValueError(\n                    \"To make a Policy in federated mode, you need to know about \"\n                    \"all the Ursulas you need (in this case, {}); there's no other way to \"\n                    \"know which nodes to use.  Either pass them here or when you make the Policy, \"\n                    \"or run the learning loop on a network with enough Ursulas.\".format(policy.shares))\n\n        self.log.debug(f\"Enacting {policy} ... \")\n        enacted_policy = policy.enact(network_middleware=self.network_middleware, ursulas=ursulas)\n\n        self.add_active_policy(enacted_policy)\n        return enacted_policy",
  "def get_policy_encrypting_key_from_label(self, label: bytes) -> PublicKey:\n        alice_delegating_power = self._crypto_power.power_ups(DelegatingPower)\n        policy_pubkey = alice_delegating_power.get_pubkey_from_label(label)\n        return policy_pubkey",
  "def revoke(self,\n               policy: Policy,\n               onchain: bool = True,  # forced to False for federated mode\n               offchain: bool = True\n               ) -> Tuple[TxReceipt, Dict[ChecksumAddress, Tuple['Revocation', Exception]]]:\n\n        if not (offchain or onchain):\n            raise ValueError('offchain or onchain must be True to issue revocation')\n\n        receipt, failed = dict(), dict()\n\n        if onchain and (not self.federated_only):\n            pass\n            # TODO: Decouple onchain revocation from SubscriptionManager or deprecate.\n            # receipt = self.policy_agent.revoke_policy(policy_id=bytes(policy.hrac),\n            #                                           transacting_power=self._crypto_power.power_ups(TransactingPower))\n\n        if offchain:\n            \"\"\"\n            Parses the treasure map and revokes onchain arrangements in it.\n            If any nodes cannot be revoked, then the node_id is added to a\n            dict as a key, and the revocation and Ursula's response is added as\n            a value.\n            \"\"\"\n            try:\n                # Wait for a revocation threshold of nodes to be known ((n - m) + 1)\n                revocation_threshold = ((policy.shares - policy.threshold) + 1)\n                self.block_until_specific_nodes_are_known(\n                    policy.revocation_kit.revokable_addresses,\n                    allow_missing=(policy.shares - revocation_threshold))\n            except self.NotEnoughTeachers:\n                raise  # TODO  NRN\n\n            for node_id in policy.revocation_kit.revokable_addresses:\n                ursula = self.known_nodes[node_id]\n                revocation = policy.revocation_kit[node_id]\n                try:\n                    response = self.network_middleware.request_revocation(ursula, revocation)\n                except self.network_middleware.NotFound:\n                    failed[node_id] = (revocation, self.network_middleware.NotFound)\n                except self.network_middleware.UnexpectedResponse:\n                    failed[node_id] = (revocation, self.network_middleware.UnexpectedResponse)\n                else:\n                    if response.status_code != 200:\n                        message = f\"Failed to revocation for node {node_id} with status code {response.status_code}\"\n                        raise self.ActorError(message)\n\n        return receipt, failed",
  "def decrypt_message_kit(self, label: bytes, message_kit: MessageKit) -> List[bytes]:\n        \"\"\"\n        Decrypt this Alice's own encrypted data.\n\n        I/O signatures match Bob's retrieve interface.\n        \"\"\"\n\n        delegating_power = self._crypto_power.power_ups(DelegatingPower)\n        decrypting_power = delegating_power.get_decrypting_power_from_label(label)\n        cleartext = decrypting_power.decrypt_message_kit(message_kit)\n\n        # TODO: why does it return a list of cleartexts but takes a single message kit?\n        # Shouldn't it be able to take a list of them too?\n        return [cleartext]",
  "class IncorrectCFragsReceived(Exception):\n        \"\"\"\n        Raised when Bob detects incorrect CFrags returned by some Ursulas\n        \"\"\"\n\n        def __init__(self, evidence: List):\n            self.evidence = evidence",
  "def __init__(self,\n                 is_me: bool = True,\n                 verify_node_bonding: bool = False,\n                 eth_provider_uri: str = None,\n                 *args, **kwargs) -> None:\n\n        Character.__init__(self,\n                           is_me=is_me,\n                           known_node_class=Ursula,\n                           verify_node_bonding=verify_node_bonding,\n                           eth_provider_uri=eth_provider_uri,\n                           *args, **kwargs)\n\n        # Cache of decrypted treasure maps\n        self._treasure_maps: Dict[int, TreasureMap] = {}\n\n        self.log = Logger(self.__class__.__name__)\n        if is_me:\n            self.log.info(self.banner)",
  "def _decrypt_treasure_map(self,\n                              encrypted_treasure_map: EncryptedTreasureMap,\n                              publisher_verifying_key: PublicKey\n                              ) -> TreasureMap:\n        decrypting_power = self._crypto_power.power_ups(DecryptingPower)\n        return decrypting_power.decrypt_treasure_map(encrypted_treasure_map,\n                                                     publisher_verifying_key=publisher_verifying_key)",
  "def retrieve(\n            self,\n            message_kits: Sequence[Union[MessageKit, PolicyMessageKit]],\n            alice_verifying_key: PublicKey,  # KeyFrag signer's key\n            encrypted_treasure_map: EncryptedTreasureMap,\n            publisher_verifying_key: Optional[PublicKey] = None,\n            **context,  # TODO: dont use one context to rule them all\n            ) -> List[PolicyMessageKit]:\n        \"\"\"\n        Attempts to retrieve reencrypted capsule fragments\n        corresponding to given message kits from Ursulas.\n\n        Accepts both \"clean\" message kits (obtained from a side channel)\n        and \"loaded\" ones (with earlier retrieved capsule frags attached,\n        along with the addresses of Ursulas they were obtained from).\n\n        Returns a list of loaded message kits corresponding to the input list,\n        with the kits containing the capsule fragments obtained during the retrieval.\n        These kits can be used as an external cache to preserve the cfrags between\n        several retrieval attempts.\n        \"\"\"\n\n        if not publisher_verifying_key:\n            publisher_verifying_key = alice_verifying_key\n        publisher_verifying_key = PublicKey.from_bytes(bytes(publisher_verifying_key))\n\n        # A small optimization to avoid multiple treasure map decryptions.\n        map_hash = hash(bytes(encrypted_treasure_map))\n        if map_hash in self._treasure_maps:\n            treasure_map = self._treasure_maps[map_hash]\n        else:\n            # Have to decrypt the treasure map first to find out what the threshold is.\n            # Otherwise, we could check the message kits for completeness right away.\n            treasure_map = self._decrypt_treasure_map(encrypted_treasure_map, publisher_verifying_key)\n            self._treasure_maps[map_hash] = treasure_map\n\n        # Normalize input\n        message_kits: List[PolicyMessageKit] = [\n            PolicyMessageKit.from_message_kit(message_kit, treasure_map.policy_encrypting_key, treasure_map.threshold)\n                if isinstance(message_kit, MessageKit) else message_kit\n            for message_kit in message_kits\n            ]\n\n        # Clear up all unrelated information from message kits before retrieval.\n        retrieval_kits = [message_kit.as_retrieval_kit() for message_kit in message_kits]\n\n        # Retrieve capsule frags\n        client = RetrievalClient(learner=self)\n        retrieval_results, _ = client.retrieve_cfrags(\n            treasure_map=treasure_map,\n            retrieval_kits=retrieval_kits,\n            alice_verifying_key=alice_verifying_key,\n            bob_encrypting_key=self.public_keys(DecryptingPower),\n            bob_verifying_key=self.stamp.as_umbral_pubkey(),\n            **context\n        )\n\n        # Refill message kits with newly retrieved capsule frags\n        results = []\n        for message_kit, retrieval_result in zip(message_kits, retrieval_results):\n            results.append(message_kit.with_result(retrieval_result))\n\n        return results",
  "def retrieve_and_decrypt(self, *args, **kwds) -> List[bytes]:\n        \"\"\"\n        Attempts to retrieve reencrypted capsule fragments from Ursulas\n        and decrypt the ciphertexts in the given message kits.\n\n        See ``retrieve()`` for the parameter list.\n        \"\"\"\n\n        message_kits = self.retrieve(*args, **kwds)\n\n        for message_kit in message_kits:\n            if not message_kit.is_decryptable_by_receiver():\n                raise Ursula.NotEnoughUrsulas(f\"Not enough cfrags retrieved to open capsule {message_kit.message_kit.capsule}\")\n\n        cleartexts = []\n        decrypting_power = self._crypto_power.power_ups(DecryptingPower)\n        for message_kit in message_kits:\n            cleartext = decrypting_power.decrypt_message_kit(message_kit)\n            cleartexts.append(cleartext)\n\n        return cleartexts",
  "class NotEnoughUrsulas(Learner.NotEnoughTeachers):\n        \"\"\"\n        All Characters depend on knowing about enough Ursulas to perform their role.\n        This exception is raised when a piece of logic can't proceed without more Ursulas.\n        \"\"\"",
  "class NotFound(Exception):\n        pass",
  "def __init__(self,\n\n                 # Ursula\n                 rest_host: str,\n                 rest_port: int,\n                 domain: str,\n                 is_me: bool = True,\n\n                 certificate: Certificate = None,\n                 certificate_filepath: Optional[Path] = None,\n\n                 availability_check: bool = False,  # TODO: Remove from init\n                 metadata: Optional[NodeMetadata] = None,\n\n                 # Blockchain\n                 checksum_address: ChecksumAddress = None,\n                 operator_address: ChecksumAddress = None,  # TODO: deprecate, and rename to \"checksum_address\"\n                 client_password: str = None,\n                 operator_signature_from_metadata=NOT_SIGNED,\n\n                 eth_provider_uri: str = None,\n                 payment_method: PaymentMethod = None,\n\n                 # Character\n                 abort_on_learning_error: bool = False,\n                 federated_only: bool = False,\n                 crypto_power=None,\n                 known_nodes: Iterable[Teacher] = None,\n\n                 **character_kwargs\n                 ):\n\n        Character.__init__(self,\n                           is_me=is_me,\n                           checksum_address=checksum_address,\n                           federated_only=federated_only,\n                           crypto_power=crypto_power,\n                           abort_on_learning_error=abort_on_learning_error,\n                           known_nodes=known_nodes,\n                           domain=domain,\n                           known_node_class=Ursula,\n                           include_self_in_the_state=True,\n                           eth_provider_uri=eth_provider_uri,\n                           **character_kwargs)\n\n        if is_me:\n\n            if metadata:\n                raise ValueError(\"A local node must generate its own metadata.\")\n            self._metadata = None\n\n            # Operating Mode\n            self.known_node_class.set_federated_mode(federated_only)\n\n            # Health Checks\n            self._availability_check = availability_check\n            self._availability_tracker = AvailabilityTracker(ursula=self)\n            if not federated_only:\n                self._operator_bonded_tracker = OperatorBondedTracker(ursula=self)\n\n            # Policy Payment\n            if federated_only and not payment_method:\n                # Federated payments are free by default.\n                payment_method = FreeReencryptions()\n\n            # Decentralized Operator\n            if not federated_only:\n                if not eth_provider_uri:\n                    raise ValueError('ETH Provider URI is required to init a decentralized character.')\n                if not payment_method:\n                    raise ValueError('Payment method is required to init a decentralized character.')\n\n                # TODO: Move to method\n                # Prepare a TransactingPower from worker node's transacting keys\n                transacting_power = TransactingPower(account=operator_address,\n                                                     password=client_password,\n                                                     signer=self.signer,\n                                                     cache=True)\n                self.transacting_power = transacting_power\n                self._crypto_power.consume_power_up(transacting_power)\n\n                # Use this power to substantiate the stamp\n                self.__substantiate_stamp()\n\n                try:\n                    Operator.__init__(self,\n                                      is_me=is_me,\n                                      domain=self.domain,\n                                      transacting_power=self.transacting_power,\n                                      registry=self.registry,\n                                      operator_address=operator_address,\n                                      payment_method=payment_method)\n                except (Exception, self.OperatorError):\n                    # TODO: Do not announce self to \"other nodes\" until this init is finished.\n                    # It's not possible to finish constructing this node.\n                    self.stop(halt_reactor=False)\n                    raise\n\n            # Payment Method\n            # TODO: What value is acceptable here for a remote node?\n            # TODO: Include accepted payment method announcements in metadata?\n            self.payment_method = payment_method\n\n            # Server\n            self.rest_server = self._make_local_server(host=rest_host, port=rest_port)\n\n            # Self-signed TLS certificate of self for Teacher.__init__\n            certificate_filepath = self._crypto_power.power_ups(TLSHostingPower).keypair.certificate_filepath\n            certificate = self._crypto_power.power_ups(TLSHostingPower).keypair.certificate\n\n            # Only *YOU* can prevent forest fires\n            self.revoked_policies: Set[bytes] = set()\n\n            # Care to introduce yourself?\n            message = \"THIS IS YOU: {}: {}\".format(self.__class__.__name__, self)\n            self.log.info(message)\n            self.log.info(self.banner.format(self.nickname))\n\n        else:\n            # Stranger HTTP Server\n            # TODO: Use InterfaceInfo only\n            self.rest_server = ProxyRESTServer(rest_host=rest_host, rest_port=rest_port)\n            self._metadata = metadata\n            self.__operator_address = None\n\n        # Teacher (All Modes)\n        Teacher.__init__(self,\n                         domain=domain,\n                         certificate=certificate,\n                         certificate_filepath=certificate_filepath)",
  "def __get_hosting_power(self, host: str) -> TLSHostingPower:\n        try:\n            # Pre-existing or injected power\n            tls_hosting_power = self._crypto_power.power_ups(TLSHostingPower)\n        except TLSHostingPower.not_found_error:\n            if self.keystore:\n                # Derive TLS private key from seed\n                tls_hosting_power = self.keystore.derive_crypto_power(TLSHostingPower, host=host)\n            else:\n                # Generate ephemeral private key (\"Dev Mode\")\n                tls_hosting_keypair = HostingKeypair(host=host, generate_certificate=True)\n                tls_hosting_power = TLSHostingPower(keypair=tls_hosting_keypair, host=host)\n            self._crypto_power.consume_power_up(tls_hosting_power)  # Consume!\n        return tls_hosting_power",
  "def _make_local_server(self, host, port) -> ProxyRESTServer:\n        rest_app = make_rest_app(this_node=self)\n        rest_server = ProxyRESTServer(rest_host=host,\n                                      rest_port=port,\n                                      rest_app=rest_app,\n                                      hosting_power=self.__get_hosting_power(host=host))\n        return rest_server",
  "def __substantiate_stamp(self):\n        transacting_power = self._crypto_power.power_ups(TransactingPower)\n        signature = transacting_power.sign_message(message=bytes(self.stamp))\n        self.__operator_signature = signature\n        self.__operator_address = transacting_power.account\n        message = f\"Created decentralized identity evidence: {self.__operator_signature[:10].hex()}\"\n        self.log.debug(message)",
  "def operator_signature(self):\n        return self.__operator_signature",
  "def operator_address(self):\n        if not self.federated_only:\n            # TODO (#2875): The reason for the fork here is the difference in available information\n            # for local and remote nodes.\n            # The local node knows its operator address, but doesn't yet know the staker address.\n            # For the remote node, we know its staker address (from the metadata),\n            # but don't know the worker address.\n            # Can this be resolved more elegantly?\n            if getattr(self, 'is_me', False):\n                return self._local_operator_address()\n            else:\n                if not self.__operator_address:\n                    operator_address = to_checksum_address(self.metadata().payload.derive_operator_address())\n                    self.__operator_address = operator_address\n                return self.__operator_address\n        else:\n            raise RuntimeError(\"Federated nodes do not have an operator address\")",
  "def __preflight(self) -> None:\n        \"\"\"Called immediately before running services\n        If an exception is raised, Ursula startup will be interrupted.\n\n        \"\"\"\n        validate_operator_ip(ip=self.rest_interface.host)",
  "def run(self,\n            emitter: StdoutEmitter = None,\n            discovery: bool = True,  # TODO: see below\n            availability: bool = False,\n            worker: bool = True,\n            hendrix: bool = True,\n            start_reactor: bool = True,\n            prometheus_config: 'PrometheusMetricsConfig' = None,\n            preflight: bool = True,\n            block_until_ready: bool = True,\n            eager: bool = False\n            ) -> None:\n\n        \"\"\"Schedule and start select ursula services, then optionally start the reactor.\"\"\"\n\n        # Connect to Provider\n        if not self.federated_only:\n            if not BlockchainInterfaceFactory.is_interface_initialized(eth_provider_uri=self.eth_provider_uri):\n                BlockchainInterfaceFactory.initialize_interface(eth_provider_uri=self.eth_provider_uri)\n\n        if preflight:\n            self.__preflight()\n\n        #\n        # Async loops ordered by schedule priority\n        #\n\n        if emitter:\n            emitter.message(f\"Starting services\", color='yellow')\n\n        if discovery and not self.lonely:\n            self.start_learning_loop(now=eager)\n            if emitter:\n                emitter.message(f\"\u2713 Node Discovery ({self.domain.capitalize()})\", color='green')\n\n        if self._availability_check or availability:\n            self._availability_tracker.start(now=eager)\n            if emitter:\n                emitter.message(f\"\u2713 Availability Checks\", color='green')\n\n        if worker and not self.federated_only:\n            if block_until_ready:\n                # Sets (staker's) checksum address; Prevent worker startup before bonding\n                self.block_until_ready()\n\n            work_is_needed = self.get_work_is_needed_check()(self)\n            if work_is_needed:\n                message = \"\u2713 Work Tracking\"\n                self.work_tracker.start(commit_now=True, requirement_func=self.work_tracker.worker.get_work_is_needed_check())  # requirement_func=self._availability_tracker.status)  # TODO: #2277\n            else:\n                message = \"\u2713 Operator already confirmed.  Not starting worktracker.\"\n            if emitter:\n                emitter.message(message, color='green')\n\n        #\n        # Non-order dependant services\n        #\n\n        # Continuous bonded check now that Ursula is all ready to run\n        if not self.federated_only:\n            self._operator_bonded_tracker.start(now=eager)\n            if emitter:\n                emitter.message(f\"\u2713 Start Operator Bonded Tracker\", color='green')\n\n        if prometheus_config:\n            # Locally scoped to prevent import without prometheus explicitly installed\n            from nucypher.utilities.prometheus.metrics import start_prometheus_exporter\n\n            start_prometheus_exporter(ursula=self, prometheus_config=prometheus_config)\n            if emitter:\n                emitter.message(f\"\u2713 Prometheus Exporter\", color='green')\n\n        if hendrix:\n            if emitter:\n                emitter.message(f\"\u2713 Rest Server https://{self.rest_interface}\", color='green')\n\n            deployer = self.get_deployer()\n            deployer.addServices()\n            deployer.catalogServers(deployer.hendrix)\n\n            if not start_reactor:\n                return\n\n            if emitter:\n                emitter.message(\"Working ~ Keep Ursula Online!\", color='blue', bold=True)\n\n            try:\n                deployer.run()  # <--- Blocking Call (Reactor)\n            except Exception as e:\n                self.log.critical(str(e))\n                if emitter:\n                    emitter.message(f\"{e.__class__.__name__} {e}\", color='red', bold=True)\n                raise  # Crash :-(\n\n        elif start_reactor:  # ... without hendrix\n            reactor.run()",
  "def stop(self, halt_reactor: bool = False) -> None:\n        \"\"\"\n        Stop services for partially or fully initialized characters.\n        # CAUTION #\n        \"\"\"\n        self.log.debug(f\"---------Stopping {self}\")\n        # Handles the shutdown of a partially initialized character.\n        with contextlib.suppress(AttributeError):  # TODO: Is this acceptable here, what are alternatives?\n            self._availability_tracker.stop()\n            self.stop_learning_loop()\n            if not self.federated_only:\n                self.work_tracker.stop()\n                self._operator_bonded_tracker.stop()\n        if halt_reactor:\n            reactor.stop()",
  "def _finalize(self):\n        \"\"\"\n        Cleans up Ursula from objects that may eat up system resources.\n        Useful for testing purposes, where many Ursulas are created and destroyed,\n        and references to them may persist for too long.\n        This method is not needed if all references to the Ursula are released.\n\n        **Warning:** invalidates the Ursula.\n        \"\"\"\n        self.rest_server = INVALIDATED",
  "def rest_information(self):\n        hosting_power = self._crypto_power.power_ups(TLSHostingPower)\n\n        return (\n            self.rest_server.rest_interface,\n            hosting_power.keypair.certificate,\n            hosting_power.keypair.pubkey\n        )",
  "def rest_interface(self):\n        return self.rest_server.rest_interface",
  "def get_deployer(self):\n        port = self.rest_interface.port\n        deployer = self._crypto_power.power_ups(TLSHostingPower).get_deployer(rest_app=self.rest_app, port=port)\n        return deployer",
  "def operator_signature_from_metadata(self):\n        return self._metadata.payload.operator_signature or NOT_SIGNED",
  "def _generate_metadata(self) -> NodeMetadata:\n        # Assuming that the attributes collected there do not change,\n        # so we can cache the result of this method.\n        # TODO: should this be a method of Teacher?\n        timestamp = maya.now()\n        if self.federated_only:\n            operator_signature = None\n        else:\n            operator_signature = self.operator_signature\n        payload = NodeMetadataPayload(staking_provider_address=Address(self.canonical_address),\n                                      domain=self.domain,\n                                      timestamp_epoch=timestamp.epoch,\n                                      operator_signature=operator_signature,\n                                      verifying_key=self.public_keys(SigningPower),\n                                      encrypting_key=self.public_keys(DecryptingPower),\n                                      certificate_der=self.certificate.public_bytes(Encoding.DER),\n                                      host=self.rest_interface.host,\n                                      port=self.rest_interface.port,\n                                      )\n        return NodeMetadata(signer=self.stamp.as_umbral_signer(),\n                            payload=payload)",
  "def metadata(self):\n        if not self._metadata:\n            self._metadata = self._generate_metadata()\n        return self._metadata",
  "def timestamp(self):\n        return maya.MayaDT(self.metadata().payload.timestamp_epoch)",
  "def from_metadata_bytes(cls, metadata_bytes):\n        # TODO: should be a method of `NodeSprout`, or maybe `NodeMetadata` *is* `NodeSprout`.\n        # Fix when we get rid of inplace maturation.\n        return NodeSprout(NodeMetadata.from_bytes(metadata_bytes))",
  "def from_rest_url(cls,\n                      network_middleware: RestMiddleware,\n                      host: str,\n                      port: int):\n        response_data = network_middleware.client.node_information(host, port)\n        stranger_ursula_from_public_keys = cls.from_metadata_bytes(response_data)\n        return stranger_ursula_from_public_keys",
  "def from_seednode_metadata(cls, seednode_metadata, *args, **kwargs):\n        \"\"\"\n        Essentially another deserialization method, but this one doesn't reconstruct a complete\n        node from bytes; instead it's just enough to connect to and verify a node.\n\n        NOTE: This is a federated only method.\n        \"\"\"\n        seed_uri = f'{seednode_metadata.checksum_address}@{seednode_metadata.rest_host}:{seednode_metadata.rest_port}'\n        return cls.from_seed_and_stake_info(seed_uri=seed_uri, *args, **kwargs)",
  "def seednode_for_network(cls, network: str) -> 'Ursula':\n        \"\"\"Returns a default seednode ursula for a given network.\"\"\"\n        try:\n            url = TEACHER_NODES[network][0]\n        except KeyError:\n            raise ValueError(f'\"{network}\" is not a known network.')\n        except IndexError:\n            raise ValueError(f'No default seednodes available for \"{network}\".')\n        ursula = cls.from_seed_and_stake_info(seed_uri=url)\n        return ursula",
  "def from_teacher_uri(cls,\n                         federated_only: bool,\n                         teacher_uri: str,\n                         min_stake: int,\n                         network_middleware: RestMiddleware = None,\n                         registry: BaseContractRegistry = None,\n                         retry_attempts: int = 2,\n                         retry_interval: int = 2\n                         ) -> 'Ursula':\n\n        def __attempt(attempt=1, interval=retry_interval) -> Ursula:\n            if attempt >= retry_attempts:\n                raise ConnectionRefusedError(\"Host {} Refused Connection\".format(teacher_uri))\n\n            try:\n                teacher = cls.from_seed_and_stake_info(seed_uri=teacher_uri,\n                                                       federated_only=federated_only,\n                                                       minimum_stake=min_stake,\n                                                       network_middleware=network_middleware,\n                                                       registry=registry)\n\n            except NodeSeemsToBeDown as e:\n                log = Logger(cls.__name__)\n                log.warn(\n                    \"Can't connect to peer (attempt {}).  Will retry in {} seconds.\".format(attempt, interval))\n                time.sleep(interval)\n                return __attempt(attempt=attempt + 1)\n            else:\n                return teacher\n\n        return __attempt()",
  "def from_seed_and_stake_info(cls,\n                                 seed_uri: str,\n                                 federated_only: bool = False,\n                                 minimum_stake: int = 0,\n                                 registry: BaseContractRegistry = None,\n                                 network_middleware: RestMiddleware = None,\n                                 ) -> Union['Ursula', 'NodeSprout']:\n\n        if network_middleware is None:\n            network_middleware = RestMiddleware(registry=registry)\n\n        # Parse node URI\n        host, port, staking_provider_address = parse_node_uri(seed_uri)\n\n        # Fetch the hosts TLS certificate and read the common name\n        try:\n            certificate, _filepath = network_middleware.client.get_certificate(host=host, port=port)\n        except NodeSeemsToBeDown as e:\n            e.args += (f\"While trying to load seednode {seed_uri}\",)\n            e.crash_right_now = True\n            raise\n        real_host = certificate.subject.get_attributes_for_oid(NameOID.COMMON_NAME)[0].value\n\n        # Load the host as a potential seed node\n        potential_seed_node = cls.from_rest_url(\n            host=real_host,\n            port=port,\n            network_middleware=network_middleware,\n        )\n\n        # Check the node's stake (optional)\n        if minimum_stake > 0 and staking_provider_address and not federated_only:\n            application_agent = ContractAgency.get_agent(PREApplicationAgent, registry=registry)\n            seednode_stake = application_agent.get_authorized_stake(staking_provider=staking_provider_address)\n            if seednode_stake < minimum_stake:\n                raise Learner.NotATeacher(f\"{staking_provider_address} is staking less than the specified minimum stake value ({minimum_stake}).\")\n\n        return potential_seed_node",
  "def from_storage(cls,\n                     node_storage: NodeStorage,\n                     checksum_adress: str,\n                     federated_only: bool = False) -> 'Ursula':\n        return node_storage.get(checksum_address=checksum_adress,\n                                federated_only=federated_only)",
  "def rest_url(self):\n        try:\n            return self.rest_server.rest_url\n        except AttributeError:\n            raise AttributeError(\"No rest server attached\")",
  "def rest_app(self):\n        rest_app_on_server = self.rest_server.rest_app\n\n        if rest_app_on_server is PUBLIC_ONLY or not rest_app_on_server:\n            m = \"This Ursula doesn't have a REST app attached. If you want one, init with is_me and attach_server.\"\n            raise PowerUpError(m)\n        else:\n            return rest_app_on_server",
  "def interface_info_with_metadata(self):\n        # TODO: Do we ever actually use this without using the rest of the serialized Ursula?  337\n        return constants.BYTESTRING_IS_URSULA_IFACE_INFO + bytes(self)",
  "def _decrypt_kfrag(self, encrypted_kfrag: EncryptedKeyFrag, hrac: HRAC, publisher_verifying_key: PublicKey) -> VerifiedKeyFrag:\n        decrypting_power = self._crypto_power.power_ups(DecryptingPower)\n        return decrypting_power.decrypt_kfrag(encrypted_kfrag, hrac, publisher_verifying_key)",
  "def _reencrypt(self, kfrag: VerifiedKeyFrag, capsules) -> ReencryptionResponse:\n        cfrags = []\n        for capsule in capsules:\n            cfrag = reencrypt(capsule, kfrag)\n            cfrags.append(cfrag)\n            self.log.info(f\"Re-encrypted capsule {capsule} -> made {cfrag}.\")\n        results = list(zip(capsules, cfrags))\n        return ReencryptionResponse(signer=self.stamp.as_umbral_signer(), capsules_and_vcfrags=results)",
  "def status_info(self, omit_known_nodes: bool = False) -> 'LocalUrsulaStatus':\n\n        domain = self.domain\n        version = nucypher.__version__\n\n        fleet_state = self.known_nodes.latest_state()\n        previous_fleet_states = self.known_nodes.previous_states(4)\n\n        if not omit_known_nodes:\n            known_nodes_info = [self.known_nodes.status_info(node) for node in self.known_nodes]\n        else:\n            known_nodes_info = None\n\n        if not self.federated_only:\n            balance_eth = float(self.eth_balance)\n        else:\n            balance_eth = None\n\n        return LocalUrsulaStatus(nickname=self.nickname,\n                                 staker_address=self.checksum_address,\n                                 operator_address=self.operator_address,\n                                 rest_url=self.rest_url(),\n                                 timestamp=self.timestamp,\n                                 domain=domain,\n                                 version=version,\n                                 fleet_state=fleet_state,\n                                 previous_fleet_states=previous_fleet_states,\n                                 known_nodes=known_nodes_info,\n                                 balance_eth=balance_eth,\n                                 )",
  "def to_json(self) -> Dict[str, Any]:\n        if self.known_nodes is None:\n            known_nodes_json = None\n        else:\n            known_nodes_json = [status.to_json() for status in self.known_nodes]\n        return dict(nickname=self.nickname.to_json(),\n                    staker_address=self.staker_address,\n                    operator_address=self.operator_address,\n                    rest_url=self.rest_url,\n                    timestamp=self.timestamp.iso8601(),\n                    domain=self.domain,\n                    version=self.version,\n                    fleet_state=self.fleet_state.to_json(),\n                    previous_fleet_states=[state.to_json() for state in self.previous_fleet_states],\n                    known_nodes=known_nodes_json,\n                    balance_eth=self.balance_eth,\n                    )",
  "def __init__(self,\n                 is_me: bool = True,\n                 policy_encrypting_key: Optional[PublicKey] = None,\n                 *args, **kwargs):\n\n        self._policy_pubkey = policy_encrypting_key\n\n        # Enrico never uses the blockchain (hence federated_only)\n        kwargs['federated_only'] = True\n        kwargs['known_node_class'] = None\n        super().__init__(is_me=is_me, *args, **kwargs)\n\n        self.log = Logger(f'{self.__class__.__name__}-{bytes(self.public_keys(SigningPower)).hex()[:6]}')\n        if is_me:\n            self.log.info(self.banner.format(policy_encrypting_key))",
  "def encrypt_message(\n        self, plaintext: bytes, conditions: Optional[LingoList] = None\n    ) -> MessageKit:\n        # TODO: #2107 Rename to \"encrypt\"\n        if conditions:\n            # validate\n            validate_condition_lingo(conditions)\n            conditions = Conditions(json.dumps(conditions))\n        message_kit = MessageKit(policy_encrypting_key=self.policy_pubkey,\n                                 plaintext=plaintext,\n                                 conditions=conditions)\n        return message_kit",
  "def from_alice(cls, alice: Alice, label: bytes):\n        \"\"\"\n        :param alice: Not a stranger.  This is your Alice who will derive the policy keypair, leaving Enrico with the public part.\n        :param label: The label with which to derive the key.\n        :return:\n        \"\"\"\n        policy_pubkey_enc = alice.get_policy_encrypting_key_from_label(label)\n        return cls(policy_encrypting_key=policy_pubkey_enc)",
  "def policy_pubkey(self):\n        if not self._policy_pubkey:\n            raise TypeError(\"This Enrico doesn't know which policy encrypting key he used.  Oh well.\")\n        return self._policy_pubkey",
  "def _set_known_node_class(self, *args, **kwargs):\n        \"\"\"Enrico doesn't init nodes, so it doesn't care what class they are.\"\"\"",
  "def __init__(self, evidence: List):\n            self.evidence = evidence",
  "def __attempt(attempt=1, interval=retry_interval) -> Ursula:\n            if attempt >= retry_attempts:\n                raise ConnectionRefusedError(\"Host {} Refused Connection\".format(teacher_uri))\n\n            try:\n                teacher = cls.from_seed_and_stake_info(seed_uri=teacher_uri,\n                                                       federated_only=federated_only,\n                                                       minimum_stake=min_stake,\n                                                       network_middleware=network_middleware,\n                                                       registry=registry)\n\n            except NodeSeemsToBeDown as e:\n                log = Logger(cls.__name__)\n                log.warn(\n                    \"Can't connect to peer (attempt {}).  Will retry in {} seconds.\".format(attempt, interval))\n                time.sleep(interval)\n                return __attempt(attempt=attempt + 1)\n            else:\n                return teacher",
  "def derive_key_material_from_password(password: bytes, salt: bytes) -> bytes:\n    \"\"\"\n    Derives a symmetric encryption key seed from a pair of password and salt.\n\n    This is secure, but takes a long time.\n    So only call it once, and use the resulting key material as a seed for specific keys\n    (e.g by passing it to `derive_wrapping_key_from_key_material`, `secret_box_encrypt`\n    or `secret_box_decrypt`)\n\n    :param password: byte-encoded password used to derive a symmetric key\n    :param salt: cryptographic salt added during key derivation\n    :return:\n    \"\"\"\n\n    # WARNING: RFC7914 recommends that you use a 2^20 cost value for sensitive\n    # files. It is NOT recommended to change the `_scrypt_cost` value unless\n    # you know what you are doing.\n    _scrypt_cost = 20\n\n    try:\n        derived_key = Scrypt(\n            salt=salt,\n            length=__MASTER_KEY_LENGTH,\n            n=2 ** _scrypt_cost,\n            r=8,\n            p=1,\n            backend=default_backend()\n        ).derive(password)\n    except InternalError as e:\n        required_memory = 128 * 2**_scrypt_cost * 8 // (10**6)\n        if e.err_code[0].reason == 65:\n            raise MemoryError(\n                \"Scrypt key derivation requires at least {} MB of memory. \"\n                \"Please free up some memory and try again.\".format(required_memory)\n            )\n        else:\n            raise e\n    else:\n        return derived_key",
  "def derive_wrapping_key_from_key_material(key_material: bytes, salt: bytes) -> bytes:\n    \"\"\"\n    Uses HKDF to derive a 32 byte wrapping key to encrypt key material with.\n    \"\"\"\n\n    wrapping_key = HKDF(\n        algorithm=__HKDF_HASH_ALGORITHM,\n        length=__WRAPPING_KEY_LENGTH,\n        salt=salt,\n        info=__WRAPPING_KEY_INFO,\n        backend=default_backend()\n    ).derive(key_material)\n    return wrapping_key",
  "class SecretBoxAuthenticationError(Exception):\n    pass",
  "def secret_box_encrypt(key_material: bytes, salt: bytes, plaintext: bytes) -> bytes:\n    wrapping_key = derive_wrapping_key_from_key_material(key_material, salt)\n    secret_box = SecretBox(wrapping_key)\n    ciphertext = secret_box.encrypt(plaintext)\n    return ciphertext",
  "def secret_box_decrypt(key_material: bytes, salt: bytes, ciphertext: bytes) -> bytes:\n    wrapping_key = derive_wrapping_key_from_key_material(key_material, salt)\n    secret_box = SecretBox(wrapping_key)\n    try:\n        plaintext = secret_box.decrypt(ciphertext)\n    except CryptoError as e:\n        raise SecretBoxAuthenticationError from e\n    return plaintext",
  "class Keypair(object):\n    \"\"\"\n    A parent Keypair class for all types of Keypairs.\n    \"\"\"\n\n    _private_key_source = SecretKey.random\n    _public_key_method = \"public_key\"\n\n    def __init__(self,\n                 private_key=None,\n                 public_key=None,\n                 generate_keys_if_needed=True) -> None:\n        \"\"\"\n        Initalizes a Keypair object with an Umbral key object.\n        :param generate_keys_if_needed: Generate keys or not?\n        \"\"\"\n        if private_key and public_key:\n            raise ValueError(\"Pass either private_key or public_key - not both.\")\n        elif private_key:\n            self.pubkey = getattr(private_key, self._public_key_method)()\n            self._privkey = private_key\n        elif public_key:\n            self.pubkey = public_key\n            self._privkey = constants.PUBLIC_ONLY\n        elif generate_keys_if_needed:\n            self._privkey = self._private_key_source()\n            self.pubkey = getattr(self._privkey, self._public_key_method)()\n        else:\n            raise ValueError(\n                \"Either pass a valid key or, if you want to generate keys, set generate_keys_if_needed to True.\")\n\n    def fingerprint(self):\n        \"\"\"\n        Hashes the key using keccak-256 and returns the hexdigest in bytes.\n\n        :return: Hexdigest fingerprint of key (keccak-256) in bytes\n        \"\"\"\n        return sha3.keccak_256(bytes(self.pubkey)).hexdigest().encode()",
  "class DecryptingKeypair(Keypair):\n    \"\"\"\n    A keypair for Umbral\n    \"\"\"\n\n    class DecryptionFailed(Exception):\n        \"\"\"Raised when decryption fails.\"\"\"\n\n    def __init__(self, *args, **kwargs) -> None:\n        super().__init__(*args, **kwargs)\n\n    def decrypt_message_kit(self, message_kit: MessageKit) -> bytes:\n        \"\"\"\n        Decrypt data encrypted with Umbral.\n\n        :return: bytes\n        \"\"\"\n        try:\n            return message_kit.decrypt(self._privkey)\n        except ValueError as e:\n            raise self.DecryptionFailed() from e\n\n    def decrypt_kfrag(self, ekfrag: EncryptedKeyFrag, hrac: HRAC, publisher_verifying_key: PublicKey) -> VerifiedKeyFrag:\n        return ekfrag.decrypt(self._privkey, hrac, publisher_verifying_key)\n\n    def decrypt_treasure_map(self, etmap: EncryptedTreasureMap, publisher_verifying_key: PublicKey) -> TreasureMap:\n        return etmap.decrypt(self._privkey, publisher_verifying_key)",
  "class SigningKeypair(Keypair):\n    \"\"\"\n    A SigningKeypair that uses ECDSA.\n    \"\"\"\n\n    def __init__(self, *args, **kwargs) -> None:\n        super().__init__(*args, **kwargs)\n\n    def sign(self, message: bytes) -> Signature:\n        \"\"\"\n        Signs the given message and returns a signature.\n\n        :param message: The message to sign\n\n        :return: Signature\n        \"\"\"\n        return Signer(self._privkey).sign(message)\n\n    def get_signature_stamp(self):\n        if self._privkey is constants.PUBLIC_ONLY:\n            return StrangerStamp(verifying_key=self.pubkey)\n        else:\n            signer = Signer(self._privkey)\n            return SignatureStamp(verifying_key=self.pubkey, signer=signer)",
  "class HostingKeypair(Keypair):\n    \"\"\"\n    A keypair for TLS'ing.\n    \"\"\"\n    _private_key_source = ec.generate_private_key\n    _public_key_method = \"public_key\"\n\n    def __init__(self,\n                 host: str,\n                 checksum_address: str = None,\n                 private_key: Union[SecretKey, PublicKey] = None,\n                 certificate=None,\n                 certificate_filepath: Optional[Path] = None,\n                 generate_certificate=False,\n                 ) -> None:\n\n        if private_key:\n            if certificate_filepath:\n                certificate = _read_tls_certificate(filepath=certificate_filepath)\n            super().__init__(private_key=private_key)\n\n        elif certificate:\n            super().__init__(public_key=certificate.public_key())\n\n        elif certificate_filepath:\n            certificate = _read_tls_certificate(filepath=certificate_filepath)\n            super().__init__(public_key=certificate.public_key())\n\n        elif generate_certificate:\n            if not host and checksum_address:\n                message = \"If you don't supply a TLS certificate, one will be generated for you.\" \\\n                          \"But for that, you need to pass a host and checksum address.\"\n                raise TypeError(message)\n            certificate, private_key = generate_self_signed_certificate(host=host, private_key=private_key)\n            super().__init__(private_key=private_key)\n\n        else:\n            raise TypeError(\"You didn't provide a cert, but also told us not to generate keys.  Not sure what to do.\")\n\n        if not certificate_filepath:\n            certificate_filepath = constants.CERTIFICATE_NOT_SAVED\n\n        self.certificate = certificate\n        self.certificate_filepath = certificate_filepath\n\n    def get_deployer(self, rest_app, port):\n        return HendrixDeployTLS(\"start\",\n                                key=self._privkey,\n                                cert=X509.from_cryptography(self.certificate),\n                                context_factory=ExistingKeyTLSContextFactory,\n                                context_factory_kwargs={\"curve_name\": _TLS_CURVE.name, \"sslmethod\": TLSv1_2_METHOD},\n                                options={\n                                    \"wsgi\": rest_app,\n                                    \"https_port\": port,\n                                    \"max_upload_bytes\": MAX_UPLOAD_CONTENT_LENGTH,\n                                    'resources': get_static_resources(),\n                                })",
  "def __init__(self,\n                 private_key=None,\n                 public_key=None,\n                 generate_keys_if_needed=True) -> None:\n        \"\"\"\n        Initalizes a Keypair object with an Umbral key object.\n        :param generate_keys_if_needed: Generate keys or not?\n        \"\"\"\n        if private_key and public_key:\n            raise ValueError(\"Pass either private_key or public_key - not both.\")\n        elif private_key:\n            self.pubkey = getattr(private_key, self._public_key_method)()\n            self._privkey = private_key\n        elif public_key:\n            self.pubkey = public_key\n            self._privkey = constants.PUBLIC_ONLY\n        elif generate_keys_if_needed:\n            self._privkey = self._private_key_source()\n            self.pubkey = getattr(self._privkey, self._public_key_method)()\n        else:\n            raise ValueError(\n                \"Either pass a valid key or, if you want to generate keys, set generate_keys_if_needed to True.\")",
  "def fingerprint(self):\n        \"\"\"\n        Hashes the key using keccak-256 and returns the hexdigest in bytes.\n\n        :return: Hexdigest fingerprint of key (keccak-256) in bytes\n        \"\"\"\n        return sha3.keccak_256(bytes(self.pubkey)).hexdigest().encode()",
  "class DecryptionFailed(Exception):\n        \"\"\"Raised when decryption fails.\"\"\"",
  "def __init__(self, *args, **kwargs) -> None:\n        super().__init__(*args, **kwargs)",
  "def decrypt_message_kit(self, message_kit: MessageKit) -> bytes:\n        \"\"\"\n        Decrypt data encrypted with Umbral.\n\n        :return: bytes\n        \"\"\"\n        try:\n            return message_kit.decrypt(self._privkey)\n        except ValueError as e:\n            raise self.DecryptionFailed() from e",
  "def decrypt_kfrag(self, ekfrag: EncryptedKeyFrag, hrac: HRAC, publisher_verifying_key: PublicKey) -> VerifiedKeyFrag:\n        return ekfrag.decrypt(self._privkey, hrac, publisher_verifying_key)",
  "def decrypt_treasure_map(self, etmap: EncryptedTreasureMap, publisher_verifying_key: PublicKey) -> TreasureMap:\n        return etmap.decrypt(self._privkey, publisher_verifying_key)",
  "def __init__(self, *args, **kwargs) -> None:\n        super().__init__(*args, **kwargs)",
  "def sign(self, message: bytes) -> Signature:\n        \"\"\"\n        Signs the given message and returns a signature.\n\n        :param message: The message to sign\n\n        :return: Signature\n        \"\"\"\n        return Signer(self._privkey).sign(message)",
  "def get_signature_stamp(self):\n        if self._privkey is constants.PUBLIC_ONLY:\n            return StrangerStamp(verifying_key=self.pubkey)\n        else:\n            signer = Signer(self._privkey)\n            return SignatureStamp(verifying_key=self.pubkey, signer=signer)",
  "def __init__(self,\n                 host: str,\n                 checksum_address: str = None,\n                 private_key: Union[SecretKey, PublicKey] = None,\n                 certificate=None,\n                 certificate_filepath: Optional[Path] = None,\n                 generate_certificate=False,\n                 ) -> None:\n\n        if private_key:\n            if certificate_filepath:\n                certificate = _read_tls_certificate(filepath=certificate_filepath)\n            super().__init__(private_key=private_key)\n\n        elif certificate:\n            super().__init__(public_key=certificate.public_key())\n\n        elif certificate_filepath:\n            certificate = _read_tls_certificate(filepath=certificate_filepath)\n            super().__init__(public_key=certificate.public_key())\n\n        elif generate_certificate:\n            if not host and checksum_address:\n                message = \"If you don't supply a TLS certificate, one will be generated for you.\" \\\n                          \"But for that, you need to pass a host and checksum address.\"\n                raise TypeError(message)\n            certificate, private_key = generate_self_signed_certificate(host=host, private_key=private_key)\n            super().__init__(private_key=private_key)\n\n        else:\n            raise TypeError(\"You didn't provide a cert, but also told us not to generate keys.  Not sure what to do.\")\n\n        if not certificate_filepath:\n            certificate_filepath = constants.CERTIFICATE_NOT_SAVED\n\n        self.certificate = certificate\n        self.certificate_filepath = certificate_filepath",
  "def get_deployer(self, rest_app, port):\n        return HendrixDeployTLS(\"start\",\n                                key=self._privkey,\n                                cert=X509.from_cryptography(self.certificate),\n                                context_factory=ExistingKeyTLSContextFactory,\n                                context_factory_kwargs={\"curve_name\": _TLS_CURVE.name, \"sslmethod\": TLSv1_2_METHOD},\n                                options={\n                                    \"wsgi\": rest_app,\n                                    \"https_port\": port,\n                                    \"max_upload_bytes\": MAX_UPLOAD_CONTENT_LENGTH,\n                                    'resources': get_static_resources(),\n                                })",
  "def canonical_address_from_umbral_key(public_key: Union[PublicKey, SignatureStamp]) -> bytes:\n    if isinstance(public_key, SignatureStamp):\n        public_key = public_key.as_umbral_pubkey()\n    pubkey_compressed_bytes = bytes(public_key)\n    eth_pubkey = EthKeyAPI.PublicKey.from_compressed_bytes(pubkey_compressed_bytes)\n    canonical_address = eth_pubkey.to_canonical_address()\n    return canonical_address",
  "def secure_random(num_bytes: int) -> bytes:\n    \"\"\"\n    Returns an amount `num_bytes` of data from the OS's random device.\n    If a randomness source isn't found, returns a `NotImplementedError`.\n    In this case, a secure random source most likely doesn't exist and\n    randomness will have to found elsewhere.\n\n    :param num_bytes: Number of bytes to return.\n\n    :return: bytes\n    \"\"\"\n    # TODO: Should we just use os.urandom or avoid the import w/ this?\n    return SYSTEM_RAND.getrandbits(num_bytes * 8).to_bytes(num_bytes, byteorder='big')",
  "def secure_random_range(min: int, max: int) -> int:\n    \"\"\"\n    Returns a number from a secure random source betwee the range of\n    `min` and `max` - 1.\n\n    :param min: Minimum number in the range\n    :param max: Maximum number in the range\n\n    :return: int\n    \"\"\"\n    return SYSTEM_RAND.randrange(min, max)",
  "def keccak_digest(*messages: bytes) -> bytes:\n    \"\"\"\n    Accepts an iterable containing bytes and digests it returning a\n    Keccak digest of 32 bytes (keccak_256).\n\n    Although we use SHA256 in many cases, we keep keccak handy in order\n    to provide compatibility with the Ethereum blockchain.\n\n    :param bytes: Data to hash\n\n    :rtype: bytes\n    :return: bytestring of digested data\n    \"\"\"\n    _hash = sha3.keccak_256()\n    for message in messages:\n        _hash.update(bytes(message))\n    digest = _hash.digest()\n    return digest",
  "def sha256_digest(*messages: bytes) -> bytes:\n    \"\"\"\n    Accepts an iterable containing bytes and digests it returning a\n    SHA256 digest of 32 bytes\n\n    :param bytes: Data to hash\n\n    :rtype: bytes\n    :return: bytestring of digested data\n    \"\"\"\n    _hash_ctx = hashes.Hash(hashes.SHA256(), backend=backend)\n    for message in messages:\n        _hash_ctx.update(bytes(message))\n    digest = _hash_ctx.finalize()\n    return digest",
  "def recover_address_eip_191(message: bytes, signature: bytes) -> str:\n    \"\"\"\n    Recover checksum address from EIP-191 signature\n    \"\"\"\n    signable_message = encode_defunct(primitive=message)\n    recovery = Account.recover_message(signable_message=signable_message, signature=signature)\n    recovered_address = to_checksum_address(recovery)\n    return recovered_address",
  "def verify_eip_191(address: str, message: bytes, signature: bytes) -> bool:\n    \"\"\"\n    EIP-191 Compatible signature verification for usage with w3.eth.sign.\n    \"\"\"\n    recovered_address = recover_address_eip_191(message=message, signature=signature)\n    signature_is_valid = recovered_address == to_checksum_address(address)\n    return signature_is_valid",
  "class SignatureStamp(object):\n    \"\"\"\n    Can be called to sign something or used to express the signing public\n    key as bytes.\n    \"\"\"\n\n    def __init__(self, verifying_key, signer: Signer = None) -> None:\n        self.__signer = signer\n        self._as_bytes = bytes(verifying_key)\n        self._as_umbral_pubkey = verifying_key\n\n    def __bytes__(self):\n        return self._as_bytes\n\n    def __call__(self, *args, **kwargs):\n        return self.__signer.sign(*args, **kwargs)\n\n    def __hash__(self):\n        return int.from_bytes(self, byteorder=\"big\")\n\n    def __eq__(self, other):\n        return other == bytes(self)\n\n    def __add__(self, other):\n        return bytes(self) + other\n\n    def __radd__(self, other):\n        return other + bytes(self)\n\n    def __len__(self):\n        return len(bytes(self))\n\n    def __bool__(self):\n        return True\n\n    def as_umbral_signer(self):\n        return self.__signer\n\n    def as_umbral_pubkey(self):\n        return self._as_umbral_pubkey\n\n    def fingerprint(self):\n        \"\"\"\n        Hashes the key using keccak-256 and returns the hexdigest in bytes.\n\n        :return: Hexdigest fingerprint of key (keccak-256) in bytes\n        \"\"\"\n        from nucypher.crypto.utils import keccak_digest\n        return keccak_digest(bytes(self)).hex().encode()",
  "class StrangerStamp(SignatureStamp):\n    \"\"\"\n    SignatureStamp of a stranger (ie, can only be used to glean public key, not to sign)\n    \"\"\"\n\n    def __call__(self, *args, **kwargs):\n        from nucypher.crypto.powers import NoSigningPower\n        message = \"This isn't your SignatureStamp; it belongs to (a Stranger).  You can't sign with it.\"\n        raise NoSigningPower(message)",
  "class InvalidSignature(Exception):\n    \"\"\"Raised when a Signature is not valid.\"\"\"",
  "def __init__(self, verifying_key, signer: Signer = None) -> None:\n        self.__signer = signer\n        self._as_bytes = bytes(verifying_key)\n        self._as_umbral_pubkey = verifying_key",
  "def __bytes__(self):\n        return self._as_bytes",
  "def __call__(self, *args, **kwargs):\n        return self.__signer.sign(*args, **kwargs)",
  "def __hash__(self):\n        return int.from_bytes(self, byteorder=\"big\")",
  "def __eq__(self, other):\n        return other == bytes(self)",
  "def __add__(self, other):\n        return bytes(self) + other",
  "def __radd__(self, other):\n        return other + bytes(self)",
  "def __len__(self):\n        return len(bytes(self))",
  "def __bool__(self):\n        return True",
  "def as_umbral_signer(self):\n        return self.__signer",
  "def as_umbral_pubkey(self):\n        return self._as_umbral_pubkey",
  "def fingerprint(self):\n        \"\"\"\n        Hashes the key using keccak-256 and returns the hexdigest in bytes.\n\n        :return: Hexdigest fingerprint of key (keccak-256) in bytes\n        \"\"\"\n        from nucypher.crypto.utils import keccak_digest\n        return keccak_digest(bytes(self)).hex().encode()",
  "def __call__(self, *args, **kwargs):\n        from nucypher.crypto.powers import NoSigningPower\n        message = \"This isn't your SignatureStamp; it belongs to (a Stranger).  You can't sign with it.\"\n        raise NoSigningPower(message)",
  "def _read_tls_certificate(filepath: Path) -> Certificate:\n    \"\"\"Deserialize an X509 certificate from a filepath\"\"\"\n    try:\n        with open(filepath, 'rb') as certificate_file:\n            cert = x509.load_der_x509_certificate(certificate_file.read(), backend=default_backend())\n            return cert\n    except FileNotFoundError:\n        raise FileNotFoundError(\"No SSL certificate found at {}\".format(filepath))",
  "def generate_self_signed_certificate(host: str,\n                                     private_key: SecretKey = None,\n                                     days_valid: int = 365,\n                                     curve: ClassVar[EllipticCurve] = _TLS_CURVE,\n                                     ) -> Tuple[Certificate, _EllipticCurvePrivateKey]:\n\n    if private_key:\n        private_bn = int.from_bytes(private_key.to_secret_bytes(), 'big')\n        private_key = ec.derive_private_key(private_value=private_bn, curve=curve())\n    else:\n        private_key = ec.generate_private_key(curve(), default_backend())\n    public_key = private_key.public_key()\n\n    now = datetime.datetime.utcnow()\n    fields = [x509.NameAttribute(NameOID.COMMON_NAME, host)]\n\n    subject = issuer = x509.Name(fields)\n    cert = x509.CertificateBuilder().subject_name(subject)\n    cert = cert.issuer_name(issuer)\n    cert = cert.public_key(public_key)\n    cert = cert.serial_number(x509.random_serial_number())\n    cert = cert.not_valid_before(now)\n    cert = cert.not_valid_after(now + datetime.timedelta(days=days_valid))\n    cert = cert.add_extension(x509.SubjectAlternativeName([x509.IPAddress(IPv4Address(host))]), critical=False)\n    cert = cert.sign(private_key, hashes.SHA512(), default_backend())\n\n    return cert, private_key",
  "class InvalidPassword(ValueError):\n    pass",
  "def _assemble_keystore(encrypted_secret: bytes, password_salt: bytes, wrapper_salt: bytes) -> Dict[str, Union[str, bytes]]:\n    encoded_key_data = {\n        'version': _KEYSTORE_VERSION,\n        'created': str(time.time()),\n        'key': encrypted_secret,\n        'password_salt': password_salt,\n        'wrapper_salt': wrapper_salt,\n    }\n    return encoded_key_data",
  "def _read_keystore(path: Path, deserializer: Callable) -> Dict[str, Union[str, bytes]]:\n    \"\"\"Parses a keyfile and return decoded, deserialized key data.\"\"\"\n    with open(path, 'rb') as keyfile:\n        key_data = keyfile.read()\n        if deserializer:\n            key_data = deserializer(key_data)\n    return key_data",
  "def _write_keystore(path: Path, payload: Dict[str, bytes], serializer: Callable) -> Path:\n    \"\"\"\n    Creates a permissioned keyfile and save it to the local filesystem.\n    The file must be created in this call, and will fail if the path exists.\n    Returns the filepath string used to write the keyfile.\n\n    Note: getting and setting the umask is not thread-safe!\n\n    See linux open docs: http://man7.org/linux/man-pages/man2/open.2.html\n    ---------------------------------------------------------------------\n    O_CREAT - If pathname does not exist, create it as a regular file.\n\n\n    O_EXCL - Ensure that this call creates the file: if this flag is\n             specified in conjunction with O_CREAT, and pathname already\n             exists, then open() fails with the error EEXIST.\n    ---------------------------------------------------------------------\n    \"\"\"\n\n    if path.exists():\n        raise Keystore.Exists(f\"Private keyfile {path} already exists.\")\n    try:\n        keyfile_descriptor = os.open(path, flags=__PRIVATE_FLAGS, mode=__PRIVATE_MODE)\n    finally:\n        os.umask(0)  # Set the umask to 0 after opening\n    if serializer:\n        payload = serializer(payload)\n    with os.fdopen(keyfile_descriptor, 'wb') as keyfile:\n        keyfile.write(payload)\n    return path",
  "def _serialize_keystore(payload: Dict) -> bytes:\n    for field in ('key', 'password_salt', 'wrapper_salt'):\n        payload[field] = bytes(payload[field]).hex()\n    try:\n        metadata = json.dumps(payload, indent=4)\n    except JSONDecodeError:\n        raise Keystore.Invalid(\"Invalid or corrupted key data\")\n    return bytes(metadata, encoding=FILE_ENCODING)",
  "def _deserialize_keystore(payload: bytes):\n    payload = payload.decode(encoding=FILE_ENCODING)\n    try:\n        payload = json.loads(payload)\n    except JSONDecodeError:\n        raise Keystore.Invalid(\"Invalid or corrupted key data\")\n\n    # TODO: Handle Keystore versioning.\n    # version = payload['version']\n\n    for field in ('key', 'password_salt', 'wrapper_salt'):\n        payload[field] = bytes.fromhex(payload[field])\n    return payload",
  "def generate_keystore_filepath(parent: Path, id: str) -> Path:\n    utc_nowish = int(time.time())  # epoch\n    path = Path(parent) / f'{utc_nowish}-{id}.priv'\n    return path",
  "def validate_keystore_password(password: str) -> List:\n    \"\"\"\n    NOTICE: Do not raise inside this function.\n    \"\"\"\n    rules = (\n        (bool(password), 'Password must not be blank.'),\n        (len(password) >= Keystore._MINIMUM_PASSWORD_LENGTH,\n         f'Password must be at least {Keystore._MINIMUM_PASSWORD_LENGTH} characters long.'),\n    )\n    failures = list()\n    for rule, failure_message in rules:\n        if not rule:\n            failures.append(failure_message)\n    return failures",
  "def validate_keystore_filename(path: Path) -> None:\n    base_name = path.name.rstrip('.' + Keystore._SUFFIX)\n    parts = base_name.split(Keystore._DELIMITER)\n\n    try:\n        created, keystore_id = parts\n    except ValueError:\n        raise Keystore.Invalid(f'{path} is not a valid keystore filename')\n\n    validators = (\n        bool(len(keystore_id) == Keystore._ID_SIZE),\n        all(char in string.hexdigits for char in keystore_id)\n    )\n\n    valid_path = all(validators)\n    if not valid_path:\n        raise Keystore.Invalid(f'{path} is not a valid keystore filename')",
  "def _parse_path(path: Path) -> Tuple[int, str]:\n\n    # validate keystore file\n    if not path.exists():\n        raise Keystore.NotFound(f\"Keystore '{path.absolute()}' does not exist.\")\n    if not path.is_file():\n        raise ValueError('Keystore path must be a file.')\n    if not path.match(f'*{Keystore._DELIMITER}*.{Keystore._SUFFIX}'):\n        Keystore.Invalid(f'{path.absolute()} is not a valid keystore filename')\n\n    # dissect keystore filename\n    validate_keystore_filename(path)\n    base_name = path.name.rstrip('.'+Keystore._SUFFIX)\n    parts = base_name.split(Keystore._DELIMITER)\n    created, keystore_id = parts\n    return created, keystore_id",
  "def _derive_hosting_power(host: str, private_key: SecretKey) -> TLSHostingPower:\n    certificate, private_key = generate_self_signed_certificate(host=host, private_key=private_key)\n    keypair = HostingKeypair(host=host, private_key=private_key, certificate=certificate, generate_certificate=False)\n    power = TLSHostingPower(keypair=keypair, host=host)\n    return power",
  "class Keystore:\n\n    # Wrapping Key\n    _MINIMUM_PASSWORD_LENGTH = 8\n    _ID_SIZE = 32\n\n    # Filepath\n    _DEFAULT_DIR: Path = DEFAULT_CONFIG_ROOT / 'keystore'\n    _DELIMITER = '-'\n    _SUFFIX = 'priv'\n\n    # Powers derivation\n    __HKDF_INFO = {SigningPower: _SIGNING_INFO,\n                   DecryptingPower: _DECRYPTING_INFO,\n                   DelegatingPower: _DELEGATING_INFO,\n                   TLSHostingPower: _TLS_INFO}\n\n    class Exists(FileExistsError):\n        pass\n\n    class Invalid(Exception):\n        pass\n\n    class NotFound(FileNotFoundError):\n        pass\n\n    class Locked(RuntimeError):\n        pass\n\n    class AuthenticationFailed(RuntimeError):\n        pass\n\n    def __init__(self, keystore_path: Path):\n        self.keystore_path = keystore_path\n        self.__created, self.__id = _parse_path(keystore_path)\n        self.__secret = KEYSTORE_LOCKED\n\n    def __decrypt_keystore(self, path: Path, password: str) -> bool:\n        payload = _read_keystore(path, deserializer=_deserialize_keystore)\n        __password_material = derive_key_material_from_password(password=password.encode(),\n                                                                salt=payload['password_salt'])\n        try:\n            self.__secret = secret_box_decrypt(key_material=__password_material,\n                                               ciphertext=payload['key'],\n                                               salt=payload['wrapper_salt'])\n            return True\n        except SecretBoxAuthenticationError:\n            self.__secret = KEYSTORE_LOCKED\n            raise self.AuthenticationFailed\n\n    @staticmethod\n    def __save(secret: bytes, password: str, keystore_dir: Optional[Path] = None) -> Path:\n        failures = validate_keystore_password(password)\n        if failures:\n            # TODO: Ensure this scope is separable from the scope containing the password\n            #       to help avoid unintentional logging of the password.\n            raise InvalidPassword(''.join(failures))\n\n        # Derive verifying key (for use as ID)\n        signing_key = SecretKeyFactory.from_secure_randomness(secret).make_key(_SIGNING_INFO)\n        keystore_id = bytes(signing_key.public_key()).hex()[:Keystore._ID_SIZE]\n\n        # Generate paths\n        keystore_dir = keystore_dir or Keystore._DEFAULT_DIR\n        os.makedirs(abspath(keystore_dir), exist_ok=True, mode=0o700)\n        keystore_path = generate_keystore_filepath(parent=keystore_dir, id=keystore_id)\n\n        # Encrypt secret\n        __password_salt = token_bytes(_SALT_SIZE)\n        __password_material = derive_key_material_from_password(password=password.encode(),\n                                                                salt=__password_salt)\n\n        __wrapper_salt = token_bytes(_SALT_SIZE)\n        encrypted_secret = secret_box_encrypt(plaintext=secret,\n                                              key_material=__password_material,\n                                              salt=__wrapper_salt)\n\n        # Create keystore file\n        keystore_payload = _assemble_keystore(encrypted_secret=encrypted_secret,\n                                              password_salt=__password_salt,\n                                              wrapper_salt=__wrapper_salt)\n        _write_keystore(path=keystore_path, payload=keystore_payload, serializer=_serialize_keystore)\n\n        return keystore_path\n\n    #\n    # Public API\n    #\n\n    @classmethod\n    def load(cls, id: str, keystore_dir: Path = _DEFAULT_DIR) -> 'Keystore':\n        filepath = generate_keystore_filepath(parent=keystore_dir, id=id)\n        instance = cls(keystore_path=filepath)\n        return instance\n\n    @classmethod\n    def import_secure(cls, key_material: bytes, password: str, keystore_dir: Optional[Path] = None) -> 'Keystore':\n        \"\"\"\n        Generate a Keystore using a a custom pre-secured entropy blob.\n        This method of keystore creation does not generate a mnemonic phrase - it is assumed\n        that the provided blob is recoverable and secure.\n        \"\"\"\n        emitter = StdoutEmitter()\n        emitter.message(f'WARNING: Key importing assumes that you have already secured your secret '\n                        f'and can recover it. No mnemonic will be generated.\\n', color='yellow')\n        if len(key_material) != SecretKey.serialized_size():\n            raise ValueError(f'Entropy bytes bust be exactly {SecretKey.serialized_size()}.')\n        path = Keystore.__save(secret=key_material, password=password, keystore_dir=keystore_dir)\n        keystore = cls(keystore_path=path)\n        return keystore\n\n    @classmethod\n    def restore(cls, words: str, password: str, keystore_dir: Optional[Path] = None) -> 'Keystore':\n        \"\"\"Restore a keystore from seed words\"\"\"\n        __mnemonic = Mnemonic(_MNEMONIC_LANGUAGE)\n        __secret = bytes(__mnemonic.to_entropy(words))\n        path = Keystore.__save(secret=__secret, password=password, keystore_dir=keystore_dir)\n        keystore = cls(keystore_path=path)\n        return keystore\n\n    @classmethod\n    def generate(\n            cls, password: str,\n            keystore_dir: Optional[Path] = None,\n            interactive: bool = True,\n            ) -> Union['Keystore', Tuple['Keystore', str]]:\n        \"\"\"Generate a new nucypher keystore for use with characters\"\"\"\n        mnemonic = Mnemonic(_MNEMONIC_LANGUAGE)\n        __words = mnemonic.generate(strength=_ENTROPY_BITS)\n        if interactive:\n            cls._confirm_generate(__words)\n        __secret = bytes(mnemonic.to_entropy(__words))\n        path = Keystore.__save(secret=__secret, password=password, keystore_dir=keystore_dir)\n        keystore = cls(keystore_path=path)\n\n        if interactive:\n            return keystore\n\n        return keystore, __words\n\n    @staticmethod\n    def _confirm_generate(__words: str) -> None:\n        \"\"\"\n        Inform the caller of new keystore seed words generation the console\n        and optionally perform interactive confirmation.\n        \"\"\"\n\n        # notification\n        emitter = StdoutEmitter()\n        emitter.message(f'Backup your seed words, you will not be able to view them again.\\n')\n        emitter.message(f'{__words}\\n', color='cyan')\n        if not click.confirm(\"Have you backed up your seed phrase?\"):\n            emitter.message('Keystore generation aborted.', color='red')\n            raise click.Abort()\n        click.clear()\n\n        # confirmation\n        __response = click.prompt(\"Confirm seed words\")\n        if __response != __words:\n            raise ValueError('Incorrect seed word confirmation. No keystore has been created, try again.')\n        click.clear()\n\n    @property\n    def id(self) -> str:\n        return self.__id\n\n    @property\n    def is_unlocked(self) -> bool:\n        return self.__secret is not KEYSTORE_LOCKED\n\n    def lock(self) -> None:\n        self.__secret = KEYSTORE_LOCKED\n\n    def unlock(self, password: str) -> None:\n        self.__decrypt_keystore(path=self.keystore_path, password=password)\n\n    def derive_crypto_power(self,\n                            power_class: ClassVar[CryptoPowerUp],\n                            *power_args, **power_kwargs\n                            ) -> Union[KeyPairBasedPower, DerivedKeyBasedPower]:\n\n        if not self.is_unlocked:\n            raise Keystore.Locked(f\"{self.id} is locked and must be unlocked before use.\")\n        try:\n            info = self.__HKDF_INFO[power_class]\n        except KeyError:\n            failure_message = f\"{power_class.__name__} is an invalid type for deriving a CryptoPower\"\n            raise TypeError(failure_message)\n        else:\n            __private_key = SecretKeyFactory.from_secure_randomness(self.__secret).make_key(info)\n\n        if power_class is TLSHostingPower:  # TODO: something more elegant?\n            power = _derive_hosting_power(private_key=__private_key, *power_args, **power_kwargs)\n\n        elif issubclass(power_class, KeyPairBasedPower):\n            keypair = power_class._keypair_class(__private_key)\n            power = power_class(keypair=keypair, *power_args, **power_kwargs)\n\n        elif issubclass(power_class, DerivedKeyBasedPower):\n            parent_skf = SecretKeyFactory.from_secure_randomness(self.__secret)\n            child_skf = parent_skf.make_factory(_DELEGATING_INFO)\n            power = power_class(secret_key_factory=child_skf, *power_args, **power_kwargs)\n\n        else:\n            failure_message = f\"{power_class.__name__} is an invalid type for deriving a CryptoPower.\"\n            raise ValueError(failure_message)\n\n        return power",
  "class Exists(FileExistsError):\n        pass",
  "class Invalid(Exception):\n        pass",
  "class NotFound(FileNotFoundError):\n        pass",
  "class Locked(RuntimeError):\n        pass",
  "class AuthenticationFailed(RuntimeError):\n        pass",
  "def __init__(self, keystore_path: Path):\n        self.keystore_path = keystore_path\n        self.__created, self.__id = _parse_path(keystore_path)\n        self.__secret = KEYSTORE_LOCKED",
  "def __decrypt_keystore(self, path: Path, password: str) -> bool:\n        payload = _read_keystore(path, deserializer=_deserialize_keystore)\n        __password_material = derive_key_material_from_password(password=password.encode(),\n                                                                salt=payload['password_salt'])\n        try:\n            self.__secret = secret_box_decrypt(key_material=__password_material,\n                                               ciphertext=payload['key'],\n                                               salt=payload['wrapper_salt'])\n            return True\n        except SecretBoxAuthenticationError:\n            self.__secret = KEYSTORE_LOCKED\n            raise self.AuthenticationFailed",
  "def __save(secret: bytes, password: str, keystore_dir: Optional[Path] = None) -> Path:\n        failures = validate_keystore_password(password)\n        if failures:\n            # TODO: Ensure this scope is separable from the scope containing the password\n            #       to help avoid unintentional logging of the password.\n            raise InvalidPassword(''.join(failures))\n\n        # Derive verifying key (for use as ID)\n        signing_key = SecretKeyFactory.from_secure_randomness(secret).make_key(_SIGNING_INFO)\n        keystore_id = bytes(signing_key.public_key()).hex()[:Keystore._ID_SIZE]\n\n        # Generate paths\n        keystore_dir = keystore_dir or Keystore._DEFAULT_DIR\n        os.makedirs(abspath(keystore_dir), exist_ok=True, mode=0o700)\n        keystore_path = generate_keystore_filepath(parent=keystore_dir, id=keystore_id)\n\n        # Encrypt secret\n        __password_salt = token_bytes(_SALT_SIZE)\n        __password_material = derive_key_material_from_password(password=password.encode(),\n                                                                salt=__password_salt)\n\n        __wrapper_salt = token_bytes(_SALT_SIZE)\n        encrypted_secret = secret_box_encrypt(plaintext=secret,\n                                              key_material=__password_material,\n                                              salt=__wrapper_salt)\n\n        # Create keystore file\n        keystore_payload = _assemble_keystore(encrypted_secret=encrypted_secret,\n                                              password_salt=__password_salt,\n                                              wrapper_salt=__wrapper_salt)\n        _write_keystore(path=keystore_path, payload=keystore_payload, serializer=_serialize_keystore)\n\n        return keystore_path",
  "def load(cls, id: str, keystore_dir: Path = _DEFAULT_DIR) -> 'Keystore':\n        filepath = generate_keystore_filepath(parent=keystore_dir, id=id)\n        instance = cls(keystore_path=filepath)\n        return instance",
  "def import_secure(cls, key_material: bytes, password: str, keystore_dir: Optional[Path] = None) -> 'Keystore':\n        \"\"\"\n        Generate a Keystore using a a custom pre-secured entropy blob.\n        This method of keystore creation does not generate a mnemonic phrase - it is assumed\n        that the provided blob is recoverable and secure.\n        \"\"\"\n        emitter = StdoutEmitter()\n        emitter.message(f'WARNING: Key importing assumes that you have already secured your secret '\n                        f'and can recover it. No mnemonic will be generated.\\n', color='yellow')\n        if len(key_material) != SecretKey.serialized_size():\n            raise ValueError(f'Entropy bytes bust be exactly {SecretKey.serialized_size()}.')\n        path = Keystore.__save(secret=key_material, password=password, keystore_dir=keystore_dir)\n        keystore = cls(keystore_path=path)\n        return keystore",
  "def restore(cls, words: str, password: str, keystore_dir: Optional[Path] = None) -> 'Keystore':\n        \"\"\"Restore a keystore from seed words\"\"\"\n        __mnemonic = Mnemonic(_MNEMONIC_LANGUAGE)\n        __secret = bytes(__mnemonic.to_entropy(words))\n        path = Keystore.__save(secret=__secret, password=password, keystore_dir=keystore_dir)\n        keystore = cls(keystore_path=path)\n        return keystore",
  "def generate(\n            cls, password: str,\n            keystore_dir: Optional[Path] = None,\n            interactive: bool = True,\n            ) -> Union['Keystore', Tuple['Keystore', str]]:\n        \"\"\"Generate a new nucypher keystore for use with characters\"\"\"\n        mnemonic = Mnemonic(_MNEMONIC_LANGUAGE)\n        __words = mnemonic.generate(strength=_ENTROPY_BITS)\n        if interactive:\n            cls._confirm_generate(__words)\n        __secret = bytes(mnemonic.to_entropy(__words))\n        path = Keystore.__save(secret=__secret, password=password, keystore_dir=keystore_dir)\n        keystore = cls(keystore_path=path)\n\n        if interactive:\n            return keystore\n\n        return keystore, __words",
  "def _confirm_generate(__words: str) -> None:\n        \"\"\"\n        Inform the caller of new keystore seed words generation the console\n        and optionally perform interactive confirmation.\n        \"\"\"\n\n        # notification\n        emitter = StdoutEmitter()\n        emitter.message(f'Backup your seed words, you will not be able to view them again.\\n')\n        emitter.message(f'{__words}\\n', color='cyan')\n        if not click.confirm(\"Have you backed up your seed phrase?\"):\n            emitter.message('Keystore generation aborted.', color='red')\n            raise click.Abort()\n        click.clear()\n\n        # confirmation\n        __response = click.prompt(\"Confirm seed words\")\n        if __response != __words:\n            raise ValueError('Incorrect seed word confirmation. No keystore has been created, try again.')\n        click.clear()",
  "def id(self) -> str:\n        return self.__id",
  "def is_unlocked(self) -> bool:\n        return self.__secret is not KEYSTORE_LOCKED",
  "def lock(self) -> None:\n        self.__secret = KEYSTORE_LOCKED",
  "def unlock(self, password: str) -> None:\n        self.__decrypt_keystore(path=self.keystore_path, password=password)",
  "def derive_crypto_power(self,\n                            power_class: ClassVar[CryptoPowerUp],\n                            *power_args, **power_kwargs\n                            ) -> Union[KeyPairBasedPower, DerivedKeyBasedPower]:\n\n        if not self.is_unlocked:\n            raise Keystore.Locked(f\"{self.id} is locked and must be unlocked before use.\")\n        try:\n            info = self.__HKDF_INFO[power_class]\n        except KeyError:\n            failure_message = f\"{power_class.__name__} is an invalid type for deriving a CryptoPower\"\n            raise TypeError(failure_message)\n        else:\n            __private_key = SecretKeyFactory.from_secure_randomness(self.__secret).make_key(info)\n\n        if power_class is TLSHostingPower:  # TODO: something more elegant?\n            power = _derive_hosting_power(private_key=__private_key, *power_args, **power_kwargs)\n\n        elif issubclass(power_class, KeyPairBasedPower):\n            keypair = power_class._keypair_class(__private_key)\n            power = power_class(keypair=keypair, *power_args, **power_kwargs)\n\n        elif issubclass(power_class, DerivedKeyBasedPower):\n            parent_skf = SecretKeyFactory.from_secure_randomness(self.__secret)\n            child_skf = parent_skf.make_factory(_DELEGATING_INFO)\n            power = power_class(secret_key_factory=child_skf, *power_args, **power_kwargs)\n\n        else:\n            failure_message = f\"{power_class.__name__} is an invalid type for deriving a CryptoPower.\"\n            raise ValueError(failure_message)\n\n        return power",
  "class PowerUpError(TypeError):\n    pass",
  "class NoSigningPower(PowerUpError):\n    pass",
  "class NoDecryptingPower(PowerUpError):\n    pass",
  "class NoTransactingPower(PowerUpError):\n    pass",
  "class CryptoPower(object):\n    def __init__(self, power_ups: list = None) -> None:\n        self.__power_ups = {}   # type: dict\n        # TODO: The keys here will actually be IDs for looking up in a Datastore.\n        self.public_keys = {}  # type: dict\n\n        if power_ups is not None:\n            for power_up in power_ups:\n                self.consume_power_up(power_up)\n\n    def __contains__(self, item):\n        try:\n            self.power_ups(item)\n        except PowerUpError:\n            return False\n        else:\n            return True\n\n    def consume_power_up(self, power_up, *args, **kwargs):\n        if isinstance(power_up, CryptoPowerUp):\n            power_up_class = power_up.__class__\n            power_up.activate(*args, **kwargs)\n            power_up_instance = power_up\n        elif CryptoPowerUp in inspect.getmro(power_up):\n            power_up_class = power_up\n            power_up_instance = power_up()\n        else:\n            raise TypeError(\n                (\"power_up must be a subclass of CryptoPowerUp or an instance \"\n                 \"of a CryptoPowerUp subclass.\"))\n        self.__power_ups[power_up_class] = power_up_instance\n\n        if power_up.confers_public_key:\n            self.public_keys[power_up_class] = power_up_instance.public_key()\n\n    def power_ups(self, power_up_class):\n        try:\n            return self.__power_ups[power_up_class]\n        except KeyError:\n            raise power_up_class.not_found_error",
  "class CryptoPowerUp:\n    \"\"\"\n    Gives you MORE CryptoPower!\n    \"\"\"\n    confers_public_key = False\n\n    def activate(self, *args, **kwargs):\n        return",
  "class TransactingPower(CryptoPowerUp):\n    \"\"\"\n    The power to sign ethereum transactions as the custodian of a private key through a signing backend.\n    \"\"\"\n\n    not_found_error = NoTransactingPower\n\n    class AccountLocked(PowerUpError):\n        \"\"\"Raised when signing cannot be performed due to a locked account\"\"\"\n        pass\n\n    @validate_checksum_address\n    def __init__(self,\n                 account: ChecksumAddress,\n                 signer: Signer,\n                 password: str = None,\n                 cache: bool = False):\n        \"\"\"\n        Instantiates a TransactingPower for the given checksum_address.\n        \"\"\"\n\n        # Auth\n        if not signer:\n            raise ValueError('signer is required to init a TransactingPower.')\n        self._signer = signer\n        self.__account = account\n        self.__password = password\n\n        # Config\n        self.__blockchain = None\n        self.__cache = cache\n        self.__activated = False\n\n    def __enter__(self):\n        return self.unlock()\n\n    def __exit__(self, exc_type, exc_val, exc_tb):\n        return self.lock_account()\n\n    def __eq__(self, other):\n        if not isinstance(other, TransactingPower):\n            return False\n        result = bool(self.account == other.account)\n        return result\n\n    #\n    # Properties\n    #\n\n    @property\n    def account(self) -> ChecksumAddress:\n        return self.__account\n\n    @property\n    def is_device(self) -> bool:\n        return self._signer.is_device(account=self.__account)\n\n    #\n    # Power\n    #\n\n    def activate(self, password: str = None) -> None:\n        \"\"\"Called during power consumption\"\"\"\n        self.unlock(password=password)\n        if self.__cache is False:\n            self.__password = None\n\n    def lock_account(self) -> None:\n        self._signer.lock_account(account=self.__account)\n\n    def unlock(self, password: str = None, duration: int = None) -> bool:\n        \"\"\"Unlocks the account with provided or cached password.\"\"\"\n        password = password or self.__password\n        result = self._signer.unlock_account(self.__account,\n                                             password=password,\n                                             duration=duration)\n        return result\n\n    def sign_message(self, message: bytes) -> bytes:\n        \"\"\"Signs the message with the private key of the TransactingPower.\"\"\"\n        signature = self._signer.sign_message(account=self.__account, message=message)\n\n        # This signature will need to be passed to Rust, so we are cleaning the chain identifier\n        # from the recovery byte, bringing it to the standard choice of {0, 1}.\n        return to_standard_signature_bytes(signature)\n\n    def sign_transaction(self, transaction_dict: dict) -> HexBytes:\n        \"\"\"Signs the transaction with the private key of the TransactingPower.\"\"\"\n        return self._signer.sign_transaction(transaction_dict=transaction_dict)",
  "class KeyPairBasedPower(CryptoPowerUp):\n    confers_public_key = True\n    _keypair_class = keypairs.Keypair\n    _default_private_key_class = SecretKey\n\n    def __init__(self, public_key: PublicKey = None, keypair: keypairs.Keypair = None):\n        if keypair and public_key:\n            raise ValueError(\"Pass keypair or pubkey_bytes (or neither), but not both.\")\n        elif keypair:\n            self.keypair = keypair\n        else:\n            # They didn't pass a keypair; we'll make one with the bytes or\n            # Umbral PublicKey if they provided such a thing.\n            if public_key:\n                try:\n                    public_key = public_key.as_umbral_pubkey()\n                except AttributeError:\n                    try:\n                        public_key = PublicKey.from_bytes(public_key)\n                    except TypeError:\n                        public_key = public_key\n                self.keypair = self._keypair_class(\n                    public_key=public_key)\n            else:\n                # They didn't even pass a public key.  We have no choice but to generate a keypair.\n                self.keypair = self._keypair_class(generate_keys_if_needed=True)\n\n    def __getattr__(self, item):\n        if item in self.provides:\n            try:\n                return getattr(self.keypair, item)\n            except AttributeError:\n                message = f\"This {self.__class__} has a keypair, {self.keypair.__class__}, which doesn't provide {item}.\"\n                raise PowerUpError(message)\n        else:\n            raise PowerUpError(\"This {} doesn't provide {}.\".format(self.__class__, item))\n\n    def public_key(self) -> 'PublicKey':\n        return self.keypair.pubkey",
  "class SigningPower(KeyPairBasedPower):\n    _keypair_class = SigningKeypair\n    not_found_error = NoSigningPower\n    provides = (\"sign\", \"get_signature_stamp\")",
  "class DecryptingPower(KeyPairBasedPower):\n    _keypair_class = DecryptingKeypair\n    not_found_error = NoDecryptingPower\n    provides = (\"decrypt_message_kit\", \"decrypt_kfrag\", \"decrypt_treasure_map\")",
  "class DerivedKeyBasedPower(CryptoPowerUp):\n    \"\"\"\n    Rather than rely on an established KeyPair, this type of power\n    derives a key at moments defined by the user.\n    \"\"\"",
  "class DelegatingPower(DerivedKeyBasedPower):\n\n    def __init__(self, secret_key_factory: Optional[SecretKeyFactory] = None):\n        if not secret_key_factory:\n            secret_key_factory = SecretKeyFactory.random()\n        self.__secret_key_factory = secret_key_factory\n\n    def _get_privkey_from_label(self, label):\n        return self.__secret_key_factory.make_key(label)\n\n    def get_pubkey_from_label(self, label):\n        return self._get_privkey_from_label(label).public_key()\n\n    def generate_kfrags(self,\n                        bob_pubkey_enc,\n                        signer,\n                        label: bytes,\n                        threshold: int,\n                        shares: int\n                        ) -> Tuple[PublicKey, List]:\n        \"\"\"\n        Generates re-encryption key frags (\"KFrags\") and returns them.\n\n        These KFrags can be used by Ursula to re-encrypt a Capsule for Bob so\n        that he can activate the Capsule.\n        :param bob_pubkey_enc: Bob's public key\n        :param threshold: Minimum number of KFrags needed to rebuild ciphertext\n        :param shares: Total number of KFrags to generate\n        \"\"\"\n\n        __private_key = self._get_privkey_from_label(label)\n        kfrags = generate_kfrags(delegating_sk=__private_key,\n                                 receiving_pk=bob_pubkey_enc,\n                                 threshold=threshold,\n                                 shares=shares,\n                                 signer=signer,\n                                 sign_delegating_key=False,\n                                 sign_receiving_key=False,\n                                 )\n        return __private_key.public_key(), kfrags\n\n    def get_decrypting_power_from_label(self, label):\n        label_privkey = self._get_privkey_from_label(label)\n        label_keypair = keypairs.DecryptingKeypair(private_key=label_privkey)\n        decrypting_power = DecryptingPower(keypair=label_keypair)\n        return decrypting_power",
  "class TLSHostingPower(KeyPairBasedPower):\n    _keypair_class = HostingKeypair\n    provides = (\"get_deployer\",)\n\n    class NoHostingPower(PowerUpError):\n        pass\n\n    not_found_error = NoHostingPower\n\n    def __init__(self,\n                 host: str,\n                 public_certificate=None,\n                 public_certificate_filepath=None,\n                 *args, **kwargs) -> None:\n\n        if public_certificate and public_certificate_filepath:\n            # TODO: Design decision here: if they do pass both, and they're identical, do we let that slide?  NRN\n            raise ValueError(\"Pass either a public_certificate or a public_certificate_filepath, not both.\")\n\n        if public_certificate:\n            kwargs['keypair'] = HostingKeypair(certificate=public_certificate, host=host)\n        elif public_certificate_filepath:\n            kwargs['keypair'] = HostingKeypair(certificate_filepath=public_certificate_filepath, host=host)\n        super().__init__(*args, **kwargs)",
  "def __init__(self, power_ups: list = None) -> None:\n        self.__power_ups = {}   # type: dict\n        # TODO: The keys here will actually be IDs for looking up in a Datastore.\n        self.public_keys = {}  # type: dict\n\n        if power_ups is not None:\n            for power_up in power_ups:\n                self.consume_power_up(power_up)",
  "def __contains__(self, item):\n        try:\n            self.power_ups(item)\n        except PowerUpError:\n            return False\n        else:\n            return True",
  "def consume_power_up(self, power_up, *args, **kwargs):\n        if isinstance(power_up, CryptoPowerUp):\n            power_up_class = power_up.__class__\n            power_up.activate(*args, **kwargs)\n            power_up_instance = power_up\n        elif CryptoPowerUp in inspect.getmro(power_up):\n            power_up_class = power_up\n            power_up_instance = power_up()\n        else:\n            raise TypeError(\n                (\"power_up must be a subclass of CryptoPowerUp or an instance \"\n                 \"of a CryptoPowerUp subclass.\"))\n        self.__power_ups[power_up_class] = power_up_instance\n\n        if power_up.confers_public_key:\n            self.public_keys[power_up_class] = power_up_instance.public_key()",
  "def power_ups(self, power_up_class):\n        try:\n            return self.__power_ups[power_up_class]\n        except KeyError:\n            raise power_up_class.not_found_error",
  "def activate(self, *args, **kwargs):\n        return",
  "class AccountLocked(PowerUpError):\n        \"\"\"Raised when signing cannot be performed due to a locked account\"\"\"\n        pass",
  "def __init__(self,\n                 account: ChecksumAddress,\n                 signer: Signer,\n                 password: str = None,\n                 cache: bool = False):\n        \"\"\"\n        Instantiates a TransactingPower for the given checksum_address.\n        \"\"\"\n\n        # Auth\n        if not signer:\n            raise ValueError('signer is required to init a TransactingPower.')\n        self._signer = signer\n        self.__account = account\n        self.__password = password\n\n        # Config\n        self.__blockchain = None\n        self.__cache = cache\n        self.__activated = False",
  "def __enter__(self):\n        return self.unlock()",
  "def __exit__(self, exc_type, exc_val, exc_tb):\n        return self.lock_account()",
  "def __eq__(self, other):\n        if not isinstance(other, TransactingPower):\n            return False\n        result = bool(self.account == other.account)\n        return result",
  "def account(self) -> ChecksumAddress:\n        return self.__account",
  "def is_device(self) -> bool:\n        return self._signer.is_device(account=self.__account)",
  "def activate(self, password: str = None) -> None:\n        \"\"\"Called during power consumption\"\"\"\n        self.unlock(password=password)\n        if self.__cache is False:\n            self.__password = None",
  "def lock_account(self) -> None:\n        self._signer.lock_account(account=self.__account)",
  "def unlock(self, password: str = None, duration: int = None) -> bool:\n        \"\"\"Unlocks the account with provided or cached password.\"\"\"\n        password = password or self.__password\n        result = self._signer.unlock_account(self.__account,\n                                             password=password,\n                                             duration=duration)\n        return result",
  "def sign_message(self, message: bytes) -> bytes:\n        \"\"\"Signs the message with the private key of the TransactingPower.\"\"\"\n        signature = self._signer.sign_message(account=self.__account, message=message)\n\n        # This signature will need to be passed to Rust, so we are cleaning the chain identifier\n        # from the recovery byte, bringing it to the standard choice of {0, 1}.\n        return to_standard_signature_bytes(signature)",
  "def sign_transaction(self, transaction_dict: dict) -> HexBytes:\n        \"\"\"Signs the transaction with the private key of the TransactingPower.\"\"\"\n        return self._signer.sign_transaction(transaction_dict=transaction_dict)",
  "def __init__(self, public_key: PublicKey = None, keypair: keypairs.Keypair = None):\n        if keypair and public_key:\n            raise ValueError(\"Pass keypair or pubkey_bytes (or neither), but not both.\")\n        elif keypair:\n            self.keypair = keypair\n        else:\n            # They didn't pass a keypair; we'll make one with the bytes or\n            # Umbral PublicKey if they provided such a thing.\n            if public_key:\n                try:\n                    public_key = public_key.as_umbral_pubkey()\n                except AttributeError:\n                    try:\n                        public_key = PublicKey.from_bytes(public_key)\n                    except TypeError:\n                        public_key = public_key\n                self.keypair = self._keypair_class(\n                    public_key=public_key)\n            else:\n                # They didn't even pass a public key.  We have no choice but to generate a keypair.\n                self.keypair = self._keypair_class(generate_keys_if_needed=True)",
  "def __getattr__(self, item):\n        if item in self.provides:\n            try:\n                return getattr(self.keypair, item)\n            except AttributeError:\n                message = f\"This {self.__class__} has a keypair, {self.keypair.__class__}, which doesn't provide {item}.\"\n                raise PowerUpError(message)\n        else:\n            raise PowerUpError(\"This {} doesn't provide {}.\".format(self.__class__, item))",
  "def public_key(self) -> 'PublicKey':\n        return self.keypair.pubkey",
  "def __init__(self, secret_key_factory: Optional[SecretKeyFactory] = None):\n        if not secret_key_factory:\n            secret_key_factory = SecretKeyFactory.random()\n        self.__secret_key_factory = secret_key_factory",
  "def _get_privkey_from_label(self, label):\n        return self.__secret_key_factory.make_key(label)",
  "def get_pubkey_from_label(self, label):\n        return self._get_privkey_from_label(label).public_key()",
  "def generate_kfrags(self,\n                        bob_pubkey_enc,\n                        signer,\n                        label: bytes,\n                        threshold: int,\n                        shares: int\n                        ) -> Tuple[PublicKey, List]:\n        \"\"\"\n        Generates re-encryption key frags (\"KFrags\") and returns them.\n\n        These KFrags can be used by Ursula to re-encrypt a Capsule for Bob so\n        that he can activate the Capsule.\n        :param bob_pubkey_enc: Bob's public key\n        :param threshold: Minimum number of KFrags needed to rebuild ciphertext\n        :param shares: Total number of KFrags to generate\n        \"\"\"\n\n        __private_key = self._get_privkey_from_label(label)\n        kfrags = generate_kfrags(delegating_sk=__private_key,\n                                 receiving_pk=bob_pubkey_enc,\n                                 threshold=threshold,\n                                 shares=shares,\n                                 signer=signer,\n                                 sign_delegating_key=False,\n                                 sign_receiving_key=False,\n                                 )\n        return __private_key.public_key(), kfrags",
  "def get_decrypting_power_from_label(self, label):\n        label_privkey = self._get_privkey_from_label(label)\n        label_keypair = keypairs.DecryptingKeypair(private_key=label_privkey)\n        decrypting_power = DecryptingPower(keypair=label_keypair)\n        return decrypting_power",
  "class NoHostingPower(PowerUpError):\n        pass",
  "def __init__(self,\n                 host: str,\n                 public_certificate=None,\n                 public_certificate_filepath=None,\n                 *args, **kwargs) -> None:\n\n        if public_certificate and public_certificate_filepath:\n            # TODO: Design decision here: if they do pass both, and they're identical, do we let that slide?  NRN\n            raise ValueError(\"Pass either a public_certificate or a public_certificate_filepath, not both.\")\n\n        if public_certificate:\n            kwargs['keypair'] = HostingKeypair(certificate=public_certificate, host=host)\n        elif public_certificate_filepath:\n            kwargs['keypair'] = HostingKeypair(certificate_filepath=public_certificate_filepath, host=host)\n        super().__init__(*args, **kwargs)",
  "class Economics:\n\n    _default_min_authorization = TToken(40_000, 'T').to_units()\n    _default_min_operator_seconds = 60 * 60 * 24  # one day in seconds\n    _default_fee_rate = Wei(Web3.to_wei(1, 'gwei'))\n\n    # TODO: Reintroduce Adjudicator\n    # Slashing parameters\n    # HASH_ALGORITHM_KECCAK256 = 0\n    # HASH_ALGORITHM_SHA256 = 1\n    # HASH_ALGORITHM_RIPEMD160 = 2\n    # _default_hash_algorithm = HASH_ALGORITHM_SHA256\n    # _default_base_penalty = 2\n    # _default_penalty_history_coefficient = 0\n    # _default_percentage_penalty_coefficient = 100000  # 0.001%\n    # _default_reward_coefficient = 2\n\n    def __init__(self,\n                 min_operator_seconds: int = _default_min_operator_seconds,\n                 min_authorization: int = _default_min_authorization,\n                 fee_rate: Wei = _default_fee_rate,\n\n                 # Adjudicator\n                 # hash_algorithm: int = _default_hash_algorithm,\n                 # base_penalty: int = _default_base_penalty,\n                 # penalty_history_coefficient: int = _default_penalty_history_coefficient,\n                 # percentage_penalty_coefficient: int = _default_percentage_penalty_coefficient,\n                 # reward_coefficient: int = _default_reward_coefficient\n                 ):\n\n        \"\"\"\n        :param min_operator_seconds: Min amount of seconds while an operator can't be changed\n        :param min_authorization: Amount of minimum allowable authorization\n\n        \"\"\"\n        # TODO: Reintroduce Adjudicator\n        # :param hash_algorithm: Hashing algorithm\n        # :param base_penalty: Base for the penalty calculation\n        # :param penalty_history_coefficient: Coefficient for calculating the penalty depending on the history\n        # :param percentage_penalty_coefficient: Coefficient for calculating the percentage penalty\n        # :param reward_coefficient: Coefficient for calculating the reward\n\n        # self.hash_algorithm = hash_algorithm\n        # self.base_penalty = base_penalty\n        # self.penalty_history_coefficient = penalty_history_coefficient\n        # self.percentage_penalty_coefficient = percentage_penalty_coefficient\n        # self.reward_coefficient = reward_coefficient\n\n        self.min_operator_seconds = min_operator_seconds\n        self.min_authorization = min_authorization\n        self.fee_rate = fee_rate\n\n    @property\n    def pre_application_deployment_parameters(self) -> Tuple[int, ...]:\n        \"\"\"Cast coefficient attributes to uint256 compatible type for solidity+EVM\"\"\"\n        deploy_parameters = (  # note: order-sensitive\n            self.min_authorization,\n            self.min_operator_seconds,\n        )\n        return tuple(map(int, deploy_parameters))",
  "class EconomicsFactory:\n    # TODO: Enforce singleton\n\n    __economics = dict()\n\n    @classmethod\n    def get_economics(cls, registry: BaseContractRegistry, eth_provider_uri: Optional[str] = None) -> Economics:\n        registry_id = registry.id\n        try:\n            return cls.__economics[registry_id]\n        except KeyError:\n            economics = EconomicsFactory.retrieve_from_blockchain(registry=registry, eth_provider_uri=eth_provider_uri)\n            cls.__economics[registry_id] = economics\n            return economics\n\n    @staticmethod\n    def retrieve_from_blockchain(registry: BaseContractRegistry, eth_provider_uri: Optional[str] = None) -> Economics:\n\n        # Agents\n        application_agent = ContractAgency.get_agent(PREApplicationAgent, registry=registry, eth_provider_uri=eth_provider_uri)\n\n        # PRE Application\n        min_authorization = application_agent.get_min_authorization()\n        min_operator_seconds = application_agent.get_min_operator_seconds()\n\n        # Adjudicator\n        # TODO: Reintroduce Adjudicator\n        # adjudicator_agent = ContractAgency.get_agent(AdjudicatorAgent, registry=registry, provider_uri=provider_uri)\n        # slashing_parameters = adjudicator_agent.slashing_parameters()\n\n        # Aggregate\n        economics_parameters = dict(min_authorization=min_authorization,\n                                    min_operator_seconds=min_operator_seconds)\n\n        economics = Economics(**economics_parameters)\n\n        return economics",
  "def __init__(self,\n                 min_operator_seconds: int = _default_min_operator_seconds,\n                 min_authorization: int = _default_min_authorization,\n                 fee_rate: Wei = _default_fee_rate,\n\n                 # Adjudicator\n                 # hash_algorithm: int = _default_hash_algorithm,\n                 # base_penalty: int = _default_base_penalty,\n                 # penalty_history_coefficient: int = _default_penalty_history_coefficient,\n                 # percentage_penalty_coefficient: int = _default_percentage_penalty_coefficient,\n                 # reward_coefficient: int = _default_reward_coefficient\n                 ):\n\n        \"\"\"\n        :param min_operator_seconds: Min amount of seconds while an operator can't be changed\n        :param min_authorization: Amount of minimum allowable authorization\n\n        \"\"\"\n        # TODO: Reintroduce Adjudicator\n        # :param hash_algorithm: Hashing algorithm\n        # :param base_penalty: Base for the penalty calculation\n        # :param penalty_history_coefficient: Coefficient for calculating the penalty depending on the history\n        # :param percentage_penalty_coefficient: Coefficient for calculating the percentage penalty\n        # :param reward_coefficient: Coefficient for calculating the reward\n\n        # self.hash_algorithm = hash_algorithm\n        # self.base_penalty = base_penalty\n        # self.penalty_history_coefficient = penalty_history_coefficient\n        # self.percentage_penalty_coefficient = percentage_penalty_coefficient\n        # self.reward_coefficient = reward_coefficient\n\n        self.min_operator_seconds = min_operator_seconds\n        self.min_authorization = min_authorization\n        self.fee_rate = fee_rate",
  "def pre_application_deployment_parameters(self) -> Tuple[int, ...]:\n        \"\"\"Cast coefficient attributes to uint256 compatible type for solidity+EVM\"\"\"\n        deploy_parameters = (  # note: order-sensitive\n            self.min_authorization,\n            self.min_operator_seconds,\n        )\n        return tuple(map(int, deploy_parameters))",
  "def get_economics(cls, registry: BaseContractRegistry, eth_provider_uri: Optional[str] = None) -> Economics:\n        registry_id = registry.id\n        try:\n            return cls.__economics[registry_id]\n        except KeyError:\n            economics = EconomicsFactory.retrieve_from_blockchain(registry=registry, eth_provider_uri=eth_provider_uri)\n            cls.__economics[registry_id] = economics\n            return economics",
  "def retrieve_from_blockchain(registry: BaseContractRegistry, eth_provider_uri: Optional[str] = None) -> Economics:\n\n        # Agents\n        application_agent = ContractAgency.get_agent(PREApplicationAgent, registry=registry, eth_provider_uri=eth_provider_uri)\n\n        # PRE Application\n        min_authorization = application_agent.get_min_authorization()\n        min_operator_seconds = application_agent.get_min_operator_seconds()\n\n        # Adjudicator\n        # TODO: Reintroduce Adjudicator\n        # adjudicator_agent = ContractAgency.get_agent(AdjudicatorAgent, registry=registry, provider_uri=provider_uri)\n        # slashing_parameters = adjudicator_agent.slashing_parameters()\n\n        # Aggregate\n        economics_parameters = dict(min_authorization=min_authorization,\n                                    min_operator_seconds=min_operator_seconds)\n\n        economics = Economics(**economics_parameters)\n\n        return economics",
  "class EventRecord:\n    def __init__(self, event: dict):\n        self.raw_event = dict(event)\n        self.args = dict(event['args'])\n        self.block_number = event['blockNumber']\n        self.transaction_hash = event['transactionHash'].hex()\n\n        try:\n            blockchain = BlockchainInterfaceFactory.get_interface()\n        except BlockchainInterfaceFactory.NoRegisteredInterfaces:\n            self.timestamp = None\n        else:\n            self.timestamp = blockchain.client.w3.eth.get_block(self.block_number)['timestamp']\n\n    def __repr__(self):\n        pairs_to_show = dict(self.args.items())\n        pairs_to_show['block_number'] = self.block_number\n        event_str = \", \".join(f\"{k}: {v}\" for k, v in pairs_to_show.items())\n        r = f\"({self.__class__.__name__}) {event_str}\"\n        return r",
  "class ContractEvents:\n\n    def __init__(self, contract: Contract):\n        self.contract = contract\n        self.names = tuple(e.event_name for e in contract.events)\n\n    def __get_web3_event_by_name(self, event_name: str):\n        if event_name not in self.names:\n            raise TypeError(f\"Event '{event_name}' doesn't exist in this contract. Valid events are {self.names}\")\n        event_method = getattr(self.contract.events, event_name)\n        return event_method\n\n    def __getitem__(self, event_name: str):\n        event_method = self.__get_web3_event_by_name(event_name)\n\n        def wrapper(from_block=None, to_block=None, **argument_filters):\n\n            if from_block is None:\n                from_block = 0  # TODO: we can do better. Get contract creation block.\n            if to_block is None:\n                to_block = 'latest'\n\n            entries = event_method.getLogs(fromBlock=from_block, toBlock=to_block, argument_filters=argument_filters)\n            for entry in entries:\n                yield EventRecord(entry)\n        return wrapper\n\n    def __getattr__(self, event_name: str):\n        return self[event_name]\n\n    def __iter__(self):\n        for event_name in self.names:\n            yield self[event_name]",
  "class ContractEventsThrottler:\n    \"\"\"\n    Enables Contract events to be retrieved in batches.\n    \"\"\"\n    # default to 1000 - smallest default heard about so far (alchemy)\n    DEFAULT_MAX_BLOCKS_PER_CALL = int(os.environ.get(NUCYPHER_EVENTS_THROTTLE_MAX_BLOCKS, 1000))\n\n    def __init__(self,\n                 agent: 'EthereumContractAgent',\n                 event_name: str,\n                 from_block: int,\n                 to_block: int = None,  # defaults to latest block\n                 max_blocks_per_call: int = DEFAULT_MAX_BLOCKS_PER_CALL,\n                 **argument_filters):\n        self.event_filter = agent.events[event_name]\n        self.from_block = from_block\n        self.to_block = to_block if to_block is not None else agent.blockchain.client.block_number\n        # validity check of block range\n        if self.to_block < self.from_block:\n            raise ValueError(f\"Invalid events block range: to_block ({self.to_block}) must be \u2265 \"\n                             f\"from_block ({self.from_block})\")\n\n        self.max_blocks_per_call = max_blocks_per_call\n        self.argument_filters = argument_filters\n\n    def __iter__(self):\n        current_from_block = self.from_block\n        current_to_block = min(self.from_block + self.max_blocks_per_call, self.to_block)\n        while current_from_block <= current_to_block:\n            for event_record in self.event_filter(from_block=current_from_block,\n                                                  to_block=current_to_block,\n                                                  **self.argument_filters):\n                yield event_record\n            # previous block range is inclusive hence the increment\n            current_from_block = current_to_block + 1\n            # update the 'to block' to the lesser of either the next `max_blocks_per_call` blocks,\n            # or the remainder of blocks\n            current_to_block = min(current_from_block + self.max_blocks_per_call, self.to_block)",
  "def __init__(self, event: dict):\n        self.raw_event = dict(event)\n        self.args = dict(event['args'])\n        self.block_number = event['blockNumber']\n        self.transaction_hash = event['transactionHash'].hex()\n\n        try:\n            blockchain = BlockchainInterfaceFactory.get_interface()\n        except BlockchainInterfaceFactory.NoRegisteredInterfaces:\n            self.timestamp = None\n        else:\n            self.timestamp = blockchain.client.w3.eth.get_block(self.block_number)['timestamp']",
  "def __repr__(self):\n        pairs_to_show = dict(self.args.items())\n        pairs_to_show['block_number'] = self.block_number\n        event_str = \", \".join(f\"{k}: {v}\" for k, v in pairs_to_show.items())\n        r = f\"({self.__class__.__name__}) {event_str}\"\n        return r",
  "def __init__(self, contract: Contract):\n        self.contract = contract\n        self.names = tuple(e.event_name for e in contract.events)",
  "def __get_web3_event_by_name(self, event_name: str):\n        if event_name not in self.names:\n            raise TypeError(f\"Event '{event_name}' doesn't exist in this contract. Valid events are {self.names}\")\n        event_method = getattr(self.contract.events, event_name)\n        return event_method",
  "def __getitem__(self, event_name: str):\n        event_method = self.__get_web3_event_by_name(event_name)\n\n        def wrapper(from_block=None, to_block=None, **argument_filters):\n\n            if from_block is None:\n                from_block = 0  # TODO: we can do better. Get contract creation block.\n            if to_block is None:\n                to_block = 'latest'\n\n            entries = event_method.getLogs(fromBlock=from_block, toBlock=to_block, argument_filters=argument_filters)\n            for entry in entries:\n                yield EventRecord(entry)\n        return wrapper",
  "def __getattr__(self, event_name: str):\n        return self[event_name]",
  "def __iter__(self):\n        for event_name in self.names:\n            yield self[event_name]",
  "def __init__(self,\n                 agent: 'EthereumContractAgent',\n                 event_name: str,\n                 from_block: int,\n                 to_block: int = None,  # defaults to latest block\n                 max_blocks_per_call: int = DEFAULT_MAX_BLOCKS_PER_CALL,\n                 **argument_filters):\n        self.event_filter = agent.events[event_name]\n        self.from_block = from_block\n        self.to_block = to_block if to_block is not None else agent.blockchain.client.block_number\n        # validity check of block range\n        if self.to_block < self.from_block:\n            raise ValueError(f\"Invalid events block range: to_block ({self.to_block}) must be \u2265 \"\n                             f\"from_block ({self.from_block})\")\n\n        self.max_blocks_per_call = max_blocks_per_call\n        self.argument_filters = argument_filters",
  "def __iter__(self):\n        current_from_block = self.from_block\n        current_to_block = min(self.from_block + self.max_blocks_per_call, self.to_block)\n        while current_from_block <= current_to_block:\n            for event_record in self.event_filter(from_block=current_from_block,\n                                                  to_block=current_to_block,\n                                                  **self.argument_filters):\n                yield event_record\n            # previous block range is inclusive hence the increment\n            current_from_block = current_to_block + 1\n            # update the 'to block' to the lesser of either the next `max_blocks_per_call` blocks,\n            # or the remainder of blocks\n            current_to_block = min(current_from_block + self.max_blocks_per_call, self.to_block)",
  "def wrapper(from_block=None, to_block=None, **argument_filters):\n\n            if from_block is None:\n                from_block = 0  # TODO: we can do better. Get contract creation block.\n            if to_block is None:\n                to_block = 'latest'\n\n            entries = event_method.getLogs(fromBlock=from_block, toBlock=to_block, argument_filters=argument_filters)\n            for entry in entries:\n                yield EventRecord(entry)",
  "class BaseActor:\n    \"\"\"\n    Concrete base class for any actor that will interface with NuCypher's ethereum smart contracts.\n    \"\"\"\n\n    class ActorError(Exception):\n        pass\n\n    @validate_checksum_address\n    def __init__(self,\n                 domain: Optional[str],\n                 registry: BaseContractRegistry,\n                 transacting_power: Optional[TransactingPower] = None,\n                 checksum_address: Optional[ChecksumAddress] = None,\n                 economics: Optional[Economics] = None):\n\n        if not (bool(checksum_address) ^ bool(transacting_power)):\n            error = f'Pass transacting power or checksum address, got {checksum_address} and {transacting_power}.'\n            raise ValueError(error)\n\n        try:\n            parent_address = self.checksum_address\n            if checksum_address is not None:\n                if parent_address != checksum_address:\n                    raise ValueError(f\"Can't have two different ethereum addresses. \"\n                                     f\"Got {parent_address} and {checksum_address}.\")\n        except AttributeError:\n            if transacting_power:\n                self.checksum_address = transacting_power.account\n            else:\n                self.checksum_address = checksum_address\n\n        self.economics = economics or Economics()\n        self.transacting_power = transacting_power\n        self.registry = registry\n        self.network = domain\n        self._saved_receipts = list()  # track receipts of transmitted transactions\n\n    def __repr__(self):\n        class_name = self.__class__.__name__\n        r = \"{}(address='{}')\"\n        r = r.format(class_name, self.checksum_address)\n        return r\n\n    def __eq__(self, other) -> bool:\n        \"\"\"Actors are equal if they have the same address.\"\"\"\n        try:\n            return bool(self.checksum_address == other.checksum_address)\n        except AttributeError:\n            return False\n\n    @property\n    def eth_balance(self) -> Decimal:\n        \"\"\"Return this actor's current ETH balance\"\"\"\n        blockchain = BlockchainInterfaceFactory.get_interface()  # TODO: EthAgent?  #1509\n        balance = blockchain.client.get_balance(self.wallet_address)\n        return Web3.from_wei(balance, 'ether')\n\n    @property\n    def wallet_address(self):\n        return self.checksum_address",
  "class NucypherTokenActor(BaseActor):\n    \"\"\"\n    Actor to interface with the NuCypherToken contract\n    \"\"\"\n\n    def __init__(self, registry: BaseContractRegistry, **kwargs):\n        super().__init__(registry=registry, **kwargs)\n        self.__token_agent = None\n\n    @property\n    def token_agent(self):\n        if self.__token_agent:\n            return self.__token_agent\n        self.__token_agent = ContractAgency.get_agent(NucypherTokenAgent, registry=self.registry)\n        return self.__token_agent\n\n    @property\n    def token_balance(self) -> NU:\n        \"\"\"Return this actor's current token balance\"\"\"\n        balance = int(self.token_agent.get_balance(address=self.checksum_address))\n        nu_balance = NU(balance, 'NuNit')\n        return nu_balance",
  "class ContractAdministrator(BaseActor):\n    \"\"\"\n    The administrator of network contracts.\n    \"\"\"\n\n    # Note: Deployer classes are sorted by deployment dependency order.\n\n    standard_deployer_classes = (\n        NucypherTokenDeployer,\n        PREApplicationDeployer,\n        SubscriptionManagerDeployer  # TODO: Move to dispatched/upgradeable section\n    )\n\n    dispatched_upgradeable_deployer_classes = (\n        AdjudicatorDeployer,\n    )\n\n    upgradeable_deployer_classes = (\n        *dispatched_upgradeable_deployer_classes,\n    )\n\n    aux_deployer_classes = (\n        # Add more deployer classes here\n    )\n\n    # For ownership transfers.\n    ownable_deployer_classes = (*dispatched_upgradeable_deployer_classes,)\n\n    # Used in the automated deployment series.\n    primary_deployer_classes = (*standard_deployer_classes,\n                                *upgradeable_deployer_classes)\n\n    # Comprehensive collection.\n    all_deployer_classes = (*primary_deployer_classes,\n                            *aux_deployer_classes,\n                            *ownable_deployer_classes)\n\n    class UnknownContract(ValueError):\n        pass\n\n    def __init__(self, *args, **kwargs):\n        self.log = Logger(\"Deployment-Actor\")\n        self.deployers = {d.contract_name: d for d in self.all_deployer_classes}\n        super().__init__(*args, **kwargs)\n\n    def __repr__(self):\n        r = '{name} - {deployer_address})'.format(name=self.__class__.__name__, deployer_address=self.checksum_address)\n        return r\n\n    def __get_deployer(self, contract_name: str):\n        try:\n            Deployer = self.deployers[contract_name]\n        except KeyError:\n            raise self.UnknownContract(contract_name)\n        return Deployer\n\n    def deploy_contract(self,\n                        contract_name: str,\n                        gas_limit: int = None,\n                        deployment_mode=FULL,\n                        ignore_deployed: bool = False,\n                        progress=None,\n                        confirmations: int = 0,\n                        deployment_parameters: dict = None,\n                        emitter=None,\n                        *args, **kwargs,\n                        ) -> Tuple[dict, BaseContractDeployer]:\n\n        if not self.transacting_power:\n            raise self.ActorError('No transacting power available for deployment.')\n\n        deployment_parameters = deployment_parameters or {}\n\n        Deployer = self.__get_deployer(contract_name=contract_name)\n        deployer = Deployer(registry=self.registry, economics=self.economics, *args, **kwargs)\n\n        if Deployer._upgradeable:\n            receipts = deployer.deploy(transacting_power=self.transacting_power,\n                                       gas_limit=gas_limit,\n                                       progress=progress,\n                                       ignore_deployed=ignore_deployed,\n                                       confirmations=confirmations,\n                                       deployment_mode=deployment_mode,\n                                       emitter=emitter,\n                                       **deployment_parameters)\n        else:\n            receipts = deployer.deploy(transacting_power=self.transacting_power,\n                                       gas_limit=gas_limit,\n                                       progress=progress,\n                                       confirmations=confirmations,\n                                       deployment_mode=deployment_mode,\n                                       ignore_deployed=ignore_deployed,\n                                       emitter=emitter,\n                                       **deployment_parameters)\n        return receipts, deployer\n\n    def upgrade_contract(self,\n                         contract_name: str,\n                         confirmations: int,\n                         ignore_deployed: bool = False,\n                         ) -> dict:\n        if not self.transacting_power:\n            raise self.ActorError('No transacting power available for deployment.')\n        Deployer = self.__get_deployer(contract_name=contract_name)\n        deployer = Deployer(registry=self.registry)\n        receipts = deployer.upgrade(transacting_power=self.transacting_power,\n                                    ignore_deployed=ignore_deployed,\n                                    confirmations=confirmations)\n        return receipts\n\n    def retarget_proxy(self,\n                       confirmations: int,\n                       contract_name: str,\n                       target_address: str,\n                       just_build_transaction: bool = False\n                       ):\n        if not self.transacting_power:\n            raise self.ActorError('No transacting power available for deployment.')\n        Deployer = self.__get_deployer(contract_name=contract_name)\n        deployer = Deployer(registry=self.registry)\n        result = deployer.retarget(transacting_power=self.transacting_power,\n                                   target_address=target_address,\n                                   just_build_transaction=just_build_transaction,\n                                   confirmations=confirmations)\n        return result\n\n    def rollback_contract(self, contract_name: str):\n        if not self.transacting_power:\n            raise self.ActorError('No transacting power available for deployment.')\n        Deployer = self.__get_deployer(contract_name=contract_name)\n        deployer = Deployer(registry=self.registry)\n        receipts = deployer.rollback(transacting_power=self.transacting_power)\n        return receipts\n\n    def save_deployment_receipts(self, receipts: dict, filename_prefix: str = 'deployment') -> str:\n        config_root = DEFAULT_CONFIG_ROOT  # We force the use of the default here.\n        filename = f'{filename_prefix}-receipts-{self.deployer_address[:6]}-{maya.now().epoch}.json'\n        filepath = config_root / filename\n        config_root.mkdir(parents=True, exist_ok=True)\n        with open(filepath, 'w') as file:\n            data = dict()\n            for contract_name, contract_receipts in receipts.items():\n                contract_records = dict()\n                for tx_name, receipt in contract_receipts.items():\n                    # Formatting\n                    pretty_receipt = {item: str(result) for item, result in receipt.items()}\n                    contract_records[tx_name] = pretty_receipt\n                data[contract_name] = contract_records\n            data = json.dumps(data, indent=4)\n            file.write(data)\n        return filepath",
  "class Operator(BaseActor):\n\n    READY_TIMEOUT = None  # (None or 0) == indefinite\n    READY_POLL_RATE = 10\n\n    class OperatorError(BaseActor.ActorError):\n        pass\n\n    def __init__(self,\n                 is_me: bool,\n                 payment_method: ContractPayment,\n                 work_tracker: WorkTracker = None,\n                 operator_address: ChecksumAddress = None,\n                 *args, **kwargs):\n\n        super().__init__(*args, **kwargs)\n        self.log = Logger(\"worker\")\n        self.is_me = is_me\n        self.__operator_address = operator_address\n        self.__staking_provider_address = None  # set by block_until_ready\n        if is_me:\n            self.application_agent = ContractAgency.get_agent(PREApplicationAgent, registry=self.registry)\n            self.work_tracker = work_tracker or WorkTracker(worker=self)\n            \n            # Multi-provider support\n            # TODO: Abstract away payment provider\n            eth_chain = self.application_agent.blockchain\n            polygon_chain = payment_method.agent.blockchain\n\n            # TODO: Verify consistency between network names and provider connection?\n            # TODO: Allow bypassing of the enforcement above ^\n            # TODO: Is chain ID stable and completely reliable?\n            self.condition_providers = {\n                eth_chain.client.chain_id: eth_chain.provider,\n                polygon_chain.client.chain_id: polygon_chain.provider\n            }\n\n    def _local_operator_address(self):\n        return self.__operator_address\n\n    @property\n    def wallet_address(self):\n        return self.operator_address\n\n    @property\n    def staking_provider_address(self):\n        if not self.__staking_provider_address:\n            self.__staking_provider_address = self.get_staking_provider_address()\n        return self.__staking_provider_address\n\n    def get_staking_provider_address(self):\n        self.__staking_provider_address = self.application_agent.get_staking_provider_from_operator(self.operator_address)\n        self.checksum_address = self.__staking_provider_address\n        self.nickname = Nickname.from_seed(self.checksum_address)\n        return self.__staking_provider_address\n\n    @property\n    def is_confirmed(self):\n        return self.application_agent.is_operator_confirmed(self.operator_address)\n\n    def confirm_address(self, fire_and_forget: bool = True) -> Union[TxReceipt, HexBytes]:\n        txhash_or_receipt = self.application_agent.confirm_operator_address(self.transacting_power, fire_and_forget=fire_and_forget)\n        return txhash_or_receipt\n\n    def block_until_ready(self, poll_rate: int = None, timeout: int = None):\n        emitter = StdoutEmitter()\n        client = self.application_agent.blockchain.client\n        poll_rate = poll_rate or self.READY_POLL_RATE\n        timeout = timeout or self.READY_TIMEOUT\n        start, funded, bonded = maya.now(), False, False\n        while not (funded and bonded):\n\n            if timeout and ((maya.now() - start).total_seconds() > timeout):\n                message = f\"x Operator was not qualified after {timeout} seconds\"\n                emitter.message(message, color='red')\n                raise self.ActorError(message)\n\n            if not funded:\n                # check for funds\n                ether_balance = client.get_balance(self.operator_address)\n                if ether_balance:\n                    # funds found\n                    funded, balance = True, Web3.from_wei(ether_balance, 'ether')\n                    emitter.message(f\"\u2713 Operator {self.operator_address} is funded with {balance} ETH\", color='green')\n                else:\n                    emitter.message(f\"! Operator {self.operator_address} is not funded with ETH\", color=\"yellow\")\n\n            if (not bonded) and (self.get_staking_provider_address() != NULL_ADDRESS):\n                bonded = True\n                emitter.message(f\"\u2713 Operator {self.operator_address} is bonded to staking provider {self.staking_provider_address}\", color='green')\n            else:\n                emitter.message(f\"! Operator {self.operator_address } is not bonded to a staking provider\", color='yellow')\n\n            time.sleep(poll_rate)\n\n    def get_work_is_needed_check(self):\n        def func(self):\n            # we have not confirmed yet\n            return not self.is_confirmed\n        return func",
  "class BlockchainPolicyAuthor(NucypherTokenActor):\n    \"\"\"Alice base class for blockchain operations, mocking up new policies!\"\"\"\n\n    def __init__(self, eth_provider_uri: str, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.application_agent = ContractAgency.get_agent(\n            PREApplicationAgent,\n            registry=self.registry,\n            eth_provider_uri=eth_provider_uri\n        )\n\n    def create_policy(self, *args, **kwargs):\n        \"\"\"Hence the name, a BlockchainPolicyAuthor can create a BlockchainPolicy with themself as the author.\"\"\"\n        from nucypher.policy.policies import BlockchainPolicy\n        blockchain_policy = BlockchainPolicy(publisher=self, *args, **kwargs)\n        return blockchain_policy",
  "class Investigator(NucypherTokenActor):\n    \"\"\"\n    Actor that reports incorrect CFrags to the Adjudicator contract.\n    In most cases, Bob will act as investigator, but the actor is generic enough than\n    anyone can report CFrags.\n    \"\"\"\n\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.adjudicator_agent = ContractAgency.get_agent(AdjudicatorAgent, registry=self.registry)\n\n    @save_receipt\n    def request_evaluation(self, evidence) -> dict:\n        receipt = self.adjudicator_agent.evaluate_cfrag(evidence=evidence, transacting_power=self.transacting_power)\n        return receipt\n\n    def was_this_evidence_evaluated(self, evidence) -> bool:\n        result = self.adjudicator_agent.was_this_evidence_evaluated(evidence=evidence)\n        return result",
  "class ActorError(Exception):\n        pass",
  "def __init__(self,\n                 domain: Optional[str],\n                 registry: BaseContractRegistry,\n                 transacting_power: Optional[TransactingPower] = None,\n                 checksum_address: Optional[ChecksumAddress] = None,\n                 economics: Optional[Economics] = None):\n\n        if not (bool(checksum_address) ^ bool(transacting_power)):\n            error = f'Pass transacting power or checksum address, got {checksum_address} and {transacting_power}.'\n            raise ValueError(error)\n\n        try:\n            parent_address = self.checksum_address\n            if checksum_address is not None:\n                if parent_address != checksum_address:\n                    raise ValueError(f\"Can't have two different ethereum addresses. \"\n                                     f\"Got {parent_address} and {checksum_address}.\")\n        except AttributeError:\n            if transacting_power:\n                self.checksum_address = transacting_power.account\n            else:\n                self.checksum_address = checksum_address\n\n        self.economics = economics or Economics()\n        self.transacting_power = transacting_power\n        self.registry = registry\n        self.network = domain\n        self._saved_receipts = list()",
  "def __repr__(self):\n        class_name = self.__class__.__name__\n        r = \"{}(address='{}')\"\n        r = r.format(class_name, self.checksum_address)\n        return r",
  "def __eq__(self, other) -> bool:\n        \"\"\"Actors are equal if they have the same address.\"\"\"\n        try:\n            return bool(self.checksum_address == other.checksum_address)\n        except AttributeError:\n            return False",
  "def eth_balance(self) -> Decimal:\n        \"\"\"Return this actor's current ETH balance\"\"\"\n        blockchain = BlockchainInterfaceFactory.get_interface()  # TODO: EthAgent?  #1509\n        balance = blockchain.client.get_balance(self.wallet_address)\n        return Web3.from_wei(balance, 'ether')",
  "def wallet_address(self):\n        return self.checksum_address",
  "def __init__(self, registry: BaseContractRegistry, **kwargs):\n        super().__init__(registry=registry, **kwargs)\n        self.__token_agent = None",
  "def token_agent(self):\n        if self.__token_agent:\n            return self.__token_agent\n        self.__token_agent = ContractAgency.get_agent(NucypherTokenAgent, registry=self.registry)\n        return self.__token_agent",
  "def token_balance(self) -> NU:\n        \"\"\"Return this actor's current token balance\"\"\"\n        balance = int(self.token_agent.get_balance(address=self.checksum_address))\n        nu_balance = NU(balance, 'NuNit')\n        return nu_balance",
  "class UnknownContract(ValueError):\n        pass",
  "def __init__(self, *args, **kwargs):\n        self.log = Logger(\"Deployment-Actor\")\n        self.deployers = {d.contract_name: d for d in self.all_deployer_classes}\n        super().__init__(*args, **kwargs)",
  "def __repr__(self):\n        r = '{name} - {deployer_address})'.format(name=self.__class__.__name__, deployer_address=self.checksum_address)\n        return r",
  "def __get_deployer(self, contract_name: str):\n        try:\n            Deployer = self.deployers[contract_name]\n        except KeyError:\n            raise self.UnknownContract(contract_name)\n        return Deployer",
  "def deploy_contract(self,\n                        contract_name: str,\n                        gas_limit: int = None,\n                        deployment_mode=FULL,\n                        ignore_deployed: bool = False,\n                        progress=None,\n                        confirmations: int = 0,\n                        deployment_parameters: dict = None,\n                        emitter=None,\n                        *args, **kwargs,\n                        ) -> Tuple[dict, BaseContractDeployer]:\n\n        if not self.transacting_power:\n            raise self.ActorError('No transacting power available for deployment.')\n\n        deployment_parameters = deployment_parameters or {}\n\n        Deployer = self.__get_deployer(contract_name=contract_name)\n        deployer = Deployer(registry=self.registry, economics=self.economics, *args, **kwargs)\n\n        if Deployer._upgradeable:\n            receipts = deployer.deploy(transacting_power=self.transacting_power,\n                                       gas_limit=gas_limit,\n                                       progress=progress,\n                                       ignore_deployed=ignore_deployed,\n                                       confirmations=confirmations,\n                                       deployment_mode=deployment_mode,\n                                       emitter=emitter,\n                                       **deployment_parameters)\n        else:\n            receipts = deployer.deploy(transacting_power=self.transacting_power,\n                                       gas_limit=gas_limit,\n                                       progress=progress,\n                                       confirmations=confirmations,\n                                       deployment_mode=deployment_mode,\n                                       ignore_deployed=ignore_deployed,\n                                       emitter=emitter,\n                                       **deployment_parameters)\n        return receipts, deployer",
  "def upgrade_contract(self,\n                         contract_name: str,\n                         confirmations: int,\n                         ignore_deployed: bool = False,\n                         ) -> dict:\n        if not self.transacting_power:\n            raise self.ActorError('No transacting power available for deployment.')\n        Deployer = self.__get_deployer(contract_name=contract_name)\n        deployer = Deployer(registry=self.registry)\n        receipts = deployer.upgrade(transacting_power=self.transacting_power,\n                                    ignore_deployed=ignore_deployed,\n                                    confirmations=confirmations)\n        return receipts",
  "def retarget_proxy(self,\n                       confirmations: int,\n                       contract_name: str,\n                       target_address: str,\n                       just_build_transaction: bool = False\n                       ):\n        if not self.transacting_power:\n            raise self.ActorError('No transacting power available for deployment.')\n        Deployer = self.__get_deployer(contract_name=contract_name)\n        deployer = Deployer(registry=self.registry)\n        result = deployer.retarget(transacting_power=self.transacting_power,\n                                   target_address=target_address,\n                                   just_build_transaction=just_build_transaction,\n                                   confirmations=confirmations)\n        return result",
  "def rollback_contract(self, contract_name: str):\n        if not self.transacting_power:\n            raise self.ActorError('No transacting power available for deployment.')\n        Deployer = self.__get_deployer(contract_name=contract_name)\n        deployer = Deployer(registry=self.registry)\n        receipts = deployer.rollback(transacting_power=self.transacting_power)\n        return receipts",
  "def save_deployment_receipts(self, receipts: dict, filename_prefix: str = 'deployment') -> str:\n        config_root = DEFAULT_CONFIG_ROOT  # We force the use of the default here.\n        filename = f'{filename_prefix}-receipts-{self.deployer_address[:6]}-{maya.now().epoch}.json'\n        filepath = config_root / filename\n        config_root.mkdir(parents=True, exist_ok=True)\n        with open(filepath, 'w') as file:\n            data = dict()\n            for contract_name, contract_receipts in receipts.items():\n                contract_records = dict()\n                for tx_name, receipt in contract_receipts.items():\n                    # Formatting\n                    pretty_receipt = {item: str(result) for item, result in receipt.items()}\n                    contract_records[tx_name] = pretty_receipt\n                data[contract_name] = contract_records\n            data = json.dumps(data, indent=4)\n            file.write(data)\n        return filepath",
  "class OperatorError(BaseActor.ActorError):\n        pass",
  "def __init__(self,\n                 is_me: bool,\n                 payment_method: ContractPayment,\n                 work_tracker: WorkTracker = None,\n                 operator_address: ChecksumAddress = None,\n                 *args, **kwargs):\n\n        super().__init__(*args, **kwargs)\n        self.log = Logger(\"worker\")\n        self.is_me = is_me\n        self.__operator_address = operator_address\n        self.__staking_provider_address = None  # set by block_until_ready\n        if is_me:\n            self.application_agent = ContractAgency.get_agent(PREApplicationAgent, registry=self.registry)\n            self.work_tracker = work_tracker or WorkTracker(worker=self)\n            \n            # Multi-provider support\n            # TODO: Abstract away payment provider\n            eth_chain = self.application_agent.blockchain\n            polygon_chain = payment_method.agent.blockchain\n\n            # TODO: Verify consistency between network names and provider connection?\n            # TODO: Allow bypassing of the enforcement above ^\n            # TODO: Is chain ID stable and completely reliable?\n            self.condition_providers = {\n                eth_chain.client.chain_id: eth_chain.provider,\n                polygon_chain.client.chain_id: polygon_chain.provider\n            }",
  "def _local_operator_address(self):\n        return self.__operator_address",
  "def wallet_address(self):\n        return self.operator_address",
  "def staking_provider_address(self):\n        if not self.__staking_provider_address:\n            self.__staking_provider_address = self.get_staking_provider_address()\n        return self.__staking_provider_address",
  "def get_staking_provider_address(self):\n        self.__staking_provider_address = self.application_agent.get_staking_provider_from_operator(self.operator_address)\n        self.checksum_address = self.__staking_provider_address\n        self.nickname = Nickname.from_seed(self.checksum_address)\n        return self.__staking_provider_address",
  "def is_confirmed(self):\n        return self.application_agent.is_operator_confirmed(self.operator_address)",
  "def confirm_address(self, fire_and_forget: bool = True) -> Union[TxReceipt, HexBytes]:\n        txhash_or_receipt = self.application_agent.confirm_operator_address(self.transacting_power, fire_and_forget=fire_and_forget)\n        return txhash_or_receipt",
  "def block_until_ready(self, poll_rate: int = None, timeout: int = None):\n        emitter = StdoutEmitter()\n        client = self.application_agent.blockchain.client\n        poll_rate = poll_rate or self.READY_POLL_RATE\n        timeout = timeout or self.READY_TIMEOUT\n        start, funded, bonded = maya.now(), False, False\n        while not (funded and bonded):\n\n            if timeout and ((maya.now() - start).total_seconds() > timeout):\n                message = f\"x Operator was not qualified after {timeout} seconds\"\n                emitter.message(message, color='red')\n                raise self.ActorError(message)\n\n            if not funded:\n                # check for funds\n                ether_balance = client.get_balance(self.operator_address)\n                if ether_balance:\n                    # funds found\n                    funded, balance = True, Web3.from_wei(ether_balance, 'ether')\n                    emitter.message(f\"\u2713 Operator {self.operator_address} is funded with {balance} ETH\", color='green')\n                else:\n                    emitter.message(f\"! Operator {self.operator_address} is not funded with ETH\", color=\"yellow\")\n\n            if (not bonded) and (self.get_staking_provider_address() != NULL_ADDRESS):\n                bonded = True\n                emitter.message(f\"\u2713 Operator {self.operator_address} is bonded to staking provider {self.staking_provider_address}\", color='green')\n            else:\n                emitter.message(f\"! Operator {self.operator_address } is not bonded to a staking provider\", color='yellow')\n\n            time.sleep(poll_rate)",
  "def get_work_is_needed_check(self):\n        def func(self):\n            # we have not confirmed yet\n            return not self.is_confirmed\n        return func",
  "def __init__(self, eth_provider_uri: str, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.application_agent = ContractAgency.get_agent(\n            PREApplicationAgent,\n            registry=self.registry,\n            eth_provider_uri=eth_provider_uri\n        )",
  "def create_policy(self, *args, **kwargs):\n        \"\"\"Hence the name, a BlockchainPolicyAuthor can create a BlockchainPolicy with themself as the author.\"\"\"\n        from nucypher.policy.policies import BlockchainPolicy\n        blockchain_policy = BlockchainPolicy(publisher=self, *args, **kwargs)\n        return blockchain_policy",
  "def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.adjudicator_agent = ContractAgency.get_agent(AdjudicatorAgent, registry=self.registry)",
  "def request_evaluation(self, evidence) -> dict:\n        receipt = self.adjudicator_agent.evaluate_cfrag(evidence=evidence, transacting_power=self.transacting_power)\n        return receipt",
  "def was_this_evidence_evaluated(self, evidence) -> bool:\n        result = self.adjudicator_agent.was_this_evidence_evaluated(evidence=evidence)\n        return result",
  "def func(self):\n            # we have not confirmed yet\n            return not self.is_confirmed",
  "def epoch_to_period(epoch: int, seconds_per_period: int) -> int:\n    period = epoch // seconds_per_period\n    return period",
  "def datetime_to_period(datetime: maya.MayaDT, seconds_per_period: int) -> int:\n    \"\"\"Converts a MayaDT instance to a period number.\"\"\"\n    future_period = epoch_to_period(epoch=datetime.epoch, seconds_per_period=seconds_per_period)\n    return int(future_period)",
  "def period_to_epoch(period: int, seconds_per_period: int) -> int:\n    epoch = period * seconds_per_period\n    return epoch",
  "def get_current_period(seconds_per_period: int) -> int:\n    now = maya.now().epoch\n    period = epoch_to_period(epoch=now, seconds_per_period=seconds_per_period)\n    return period",
  "def datetime_at_period(period: int, seconds_per_period: int, start_of_period: bool = False) -> maya.MayaDT:\n    \"\"\"\n    Returns the datetime object at a given period, future, or past.\n    If start_of_period, the datetime object represents the first second of said period.\n    \"\"\"\n    if start_of_period:\n        datetime_at_start_of_period = maya.MayaDT(epoch=period_to_epoch(period, seconds_per_period))\n        return datetime_at_start_of_period\n    else:\n        now = maya.now()\n        current_period = datetime_to_period(datetime=now, seconds_per_period=seconds_per_period)\n        delta_periods = period - current_period\n        target_datetime = now + maya.timedelta(seconds=seconds_per_period) * delta_periods\n        return target_datetime",
  "def calculate_period_duration(future_time: maya.MayaDT, seconds_per_period: int, now: maya.MayaDT = None) -> int:\n    \"\"\"Takes a future MayaDT instance and calculates the duration from now, returning in periods\"\"\"\n    if now is None:\n        now = maya.now()\n    future_period = datetime_to_period(datetime=future_time, seconds_per_period=seconds_per_period)\n    current_period = datetime_to_period(datetime=now, seconds_per_period=seconds_per_period)\n    periods = future_period - current_period\n    return periods",
  "def estimate_block_number_for_period(period: int, seconds_per_period: int,  latest_block: BlockNumber) -> BlockNumber:\n    \"\"\"Logic for getting the approximate block height of the start of the specified period.\"\"\"\n    period_start = datetime_at_period(period=period,\n                                      seconds_per_period=seconds_per_period,\n                                      start_of_period=True)\n    seconds_from_midnight = int((maya.now() - period_start).total_seconds())\n    blocks_from_midnight = seconds_from_midnight // AVERAGE_BLOCK_TIME_IN_SECONDS\n\n    block_number_for_period = latest_block - blocks_from_midnight\n    return block_number_for_period",
  "def etherscan_url(item, network: str, is_token=False) -> str:\n    if network is None or network is UNKNOWN_DEVELOPMENT_CHAIN_ID:\n        raise ValueError(\"A network must be provided\")\n\n    if network == PUBLIC_CHAINS[1]:  # Mainnet chain ID is 1\n        domain = \"https://etherscan.io\"\n    else:\n        testnets_supported_by_etherscan = (PUBLIC_CHAINS[3],  # Ropsten\n                                           PUBLIC_CHAINS[4],  # Rinkeby\n                                           PUBLIC_CHAINS[5],  # Goerli\n                                           PUBLIC_CHAINS[42],  # Kovan\n                                           )\n        if network in testnets_supported_by_etherscan:\n            domain = f\"https://{network.lower()}.etherscan.io\"\n        else:\n            raise ValueError(f\"'{network}' network not supported by Etherscan\")\n\n    if is_address(item):\n        item_type = 'token' if is_token else 'address'\n        item = to_checksum_address(item)\n    elif is_hex(item) and len(item) == 2 + 32*2:  # If it's a hash...\n        item_type = 'tx'\n    else:\n        raise ValueError(f\"Cannot construct etherscan URL for {item}\")\n\n    url = f\"{domain}/{item_type}/{item}\"\n    return url",
  "def prettify_eth_amount(amount, original_denomination: str = 'wei') -> str:\n    \"\"\"\n    Converts any ether `amount` in `original_denomination` and finds a suitable representation based on its length.\n    The options in consideration are representing the amount in wei, gwei or ETH.\n    :param amount: Input amount to prettify\n    :param original_denomination: Denomination used by `amount` (by default, wei is assumed)\n    :return: Shortest representation for `amount`, considering wei, gwei and ETH.\n    \"\"\"\n    try:\n        # First obtain canonical representation in wei. Works for int, float, Decimal and str amounts\n        amount_in_wei = Web3.to_wei(Decimal(amount), original_denomination)\n\n        common_denominations = ('wei', 'gwei', 'ether')\n\n        options = [str(Web3.from_wei(amount_in_wei, d)) for d in common_denominations]\n\n        best_option = min(zip(map(len, options), options, common_denominations))\n        _length, pretty_amount, denomination = best_option\n\n        if denomination == 'ether':\n            denomination = 'ETH'\n        pretty_amount += \" \" + denomination\n\n    except Exception:  # Worst case scenario, we just print the str representation of amount\n        pretty_amount = str(amount)\n\n    return pretty_amount",
  "def get_transaction_name(contract_function: Union[ContractFunction, ContractConstructor]) -> str:\n    deployment = isinstance(contract_function, ContractConstructor)\n    try:\n        transaction_name = contract_function.fn_name.upper()\n    except AttributeError:\n        transaction_name = 'DEPLOY' if deployment else 'UNKNOWN'\n    return transaction_name",
  "class InvalidChecksumAddress(eth_utils.exceptions.ValidationError):\n    pass",
  "def validate_checksum_address(func: Callable) -> Callable:\n    \"\"\"\n    EIP-55 Checksum address validation decorator.\n\n    Inspects the decorated function for input parameters ending with \"_address\",\n    then uses `eth_utils` to validate the addresses' EIP-55 checksum,\n    verifying the input type on failure; Raises TypeError\n    or InvalidChecksumAddress if validation fails, respectively.\n\n    EIP-55 Specification: https://github.com/ethereum/EIPs/blob/master/EIPS/eip-55.md\n    ETH Utils Implementation: https://github.com/ethereum/eth-utils\n\n    \"\"\"\n\n    parameter_name_suffix = '_address'\n    aliases = ('account', 'address')\n    log = Logger('EIP-55-validator')\n\n    @functools.wraps(func)\n    def wrapped(*args, **kwargs):\n\n        # Check for the presence of checksum addresses in this call\n        params = inspect.getcallargs(func, *args, **kwargs)\n        addresses_as_parameters = (parameter_name for parameter_name in params\n                                   if parameter_name.endswith(parameter_name_suffix)\n                                   or parameter_name in aliases)\n\n        for parameter_name in addresses_as_parameters:\n            checksum_address = params[parameter_name]\n\n            if checksum_address in __VERIFIED_ADDRESSES:\n                continue\n\n            signature = inspect.signature(func)\n            parameter_is_optional = signature.parameters[parameter_name].default is None\n            if parameter_is_optional and checksum_address is None or checksum_address is NO_BLOCKCHAIN_CONNECTION:\n                continue\n\n            address_is_valid = eth_utils.is_checksum_address(checksum_address)\n            # OK!\n            if address_is_valid:\n                __VERIFIED_ADDRESSES.add(checksum_address)\n                continue\n\n            # Invalid Type\n            if not isinstance(checksum_address, str):\n                actual_type_name = checksum_address.__class__.__name__\n                message = '{} is an invalid type for parameter \"{}\".'.format(actual_type_name, parameter_name)\n                log.debug(message)\n                raise TypeError(message)\n\n            # Invalid Value\n            message = '\"{}\" is not a valid EIP-55 checksum address.'.format(checksum_address)\n            log.debug(message)\n            raise InvalidChecksumAddress(message)\n        else:\n            return func(*args, **kwargs)\n\n    return wrapped",
  "def only_me(func: Callable) -> Callable:\n    \"\"\"Decorator to enforce invocation of permissioned actor methods\"\"\"\n    @functools.wraps(func)\n    def wrapped(actor=None, *args, **kwargs):\n        if not actor.is_me:\n            raise actor.ActorError(\"You are not {}\".format(actor.__class.__.__name__))\n        return func(actor, *args, **kwargs)\n    return wrapped",
  "def save_receipt(actor_method) -> Callable:  # TODO: rename to \"save_result\"?\n    \"\"\"Decorator to save the result of a function with a timestamp\"\"\"\n    @functools.wraps(actor_method)\n    def wrapped(self, *args, **kwargs) -> dict:\n        receipt_or_txhash = actor_method(self, *args, **kwargs)\n        self._saved_receipts.append((datetime.utcnow(), receipt_or_txhash))\n        return receipt_or_txhash\n    return wrapped",
  "def contract_api(interface: Optional[ContractInterfaces] = UNKNOWN_CONTRACT_INTERFACE) -> Callable:\n    \"\"\"Decorator factory for contract API markers\"\"\"\n\n    def decorator(agent_method: Callable) -> Callable[..., ContractReturnValue]:\n        \"\"\"\n        Marks an agent method as containing contract interactions (transaction or call)\n        and validates outbound checksum addresses for EIP-55 compliance.\n\n        If `COLLECT_CONTRACT_API` is True when running tests,\n        all marked methods will be collected for automatic mocking\n        and integration with pytest fixtures.\n        \"\"\"\n        if COLLECT_CONTRACT_API:\n            agent_method.contract_api = interface\n        agent_method = validate_checksum_address(func=agent_method)\n        return agent_method\n\n    return decorator",
  "def wrapped(*args, **kwargs):\n\n        # Check for the presence of checksum addresses in this call\n        params = inspect.getcallargs(func, *args, **kwargs)\n        addresses_as_parameters = (parameter_name for parameter_name in params\n                                   if parameter_name.endswith(parameter_name_suffix)\n                                   or parameter_name in aliases)\n\n        for parameter_name in addresses_as_parameters:\n            checksum_address = params[parameter_name]\n\n            if checksum_address in __VERIFIED_ADDRESSES:\n                continue\n\n            signature = inspect.signature(func)\n            parameter_is_optional = signature.parameters[parameter_name].default is None\n            if parameter_is_optional and checksum_address is None or checksum_address is NO_BLOCKCHAIN_CONNECTION:\n                continue\n\n            address_is_valid = eth_utils.is_checksum_address(checksum_address)\n            # OK!\n            if address_is_valid:\n                __VERIFIED_ADDRESSES.add(checksum_address)\n                continue\n\n            # Invalid Type\n            if not isinstance(checksum_address, str):\n                actual_type_name = checksum_address.__class__.__name__\n                message = '{} is an invalid type for parameter \"{}\".'.format(actual_type_name, parameter_name)\n                log.debug(message)\n                raise TypeError(message)\n\n            # Invalid Value\n            message = '\"{}\" is not a valid EIP-55 checksum address.'.format(checksum_address)\n            log.debug(message)\n            raise InvalidChecksumAddress(message)\n        else:\n            return func(*args, **kwargs)",
  "def wrapped(actor=None, *args, **kwargs):\n        if not actor.is_me:\n            raise actor.ActorError(\"You are not {}\".format(actor.__class.__.__name__))\n        return func(actor, *args, **kwargs)",
  "def wrapped(self, *args, **kwargs) -> dict:\n        receipt_or_txhash = actor_method(self, *args, **kwargs)\n        self._saved_receipts.append((datetime.utcnow(), receipt_or_txhash))\n        return receipt_or_txhash",
  "def decorator(agent_method: Callable) -> Callable[..., ContractReturnValue]:\n        \"\"\"\n        Marks an agent method as containing contract interactions (transaction or call)\n        and validates outbound checksum addresses for EIP-55 compliance.\n\n        If `COLLECT_CONTRACT_API` is True when running tests,\n        all marked methods will be collected for automatic mocking\n        and integration with pytest fixtures.\n        \"\"\"\n        if COLLECT_CONTRACT_API:\n            agent_method.contract_api = interface\n        agent_method = validate_checksum_address(func=agent_method)\n        return agent_method",
  "class EthereumContractAgent:\n    \"\"\"\n    Base class for ethereum contract wrapper types that interact with blockchain contract instances\n    \"\"\"\n\n    contract_name: str = NotImplemented\n    _forward_address: bool = True\n    _proxy_name: Optional[str] = None\n    _excluded_interfaces: Tuple[str, ...]\n\n    # TODO - #842: Gas Management\n    DEFAULT_TRANSACTION_GAS_LIMITS: Dict[str, Optional[Wei]]\n    DEFAULT_TRANSACTION_GAS_LIMITS = {'default': None}\n\n    class ContractNotDeployed(Exception):\n        \"\"\"Raised when attempting to access a contract that is not deployed on the current network.\"\"\"\n\n    class RequirementError(Exception):\n        \"\"\"\n        Raised when an agent discovers a failed requirement in an invocation to a contract function,\n        usually, a failed `require()`.\n        \"\"\"\n\n    def __init__(self,\n                 registry: BaseContractRegistry = None,  # TODO: Consider make it non-optional again. See comment in InstanceAgent.\n                 eth_provider_uri: Optional[str] = None,\n                 contract: Optional[Contract] = None,\n                 transaction_gas: Optional[Wei] = None,\n                 contract_version: Optional[str] = None):\n\n        self.log = Logger(self.__class__.__name__)\n        self.registry = registry\n\n        self.blockchain = BlockchainInterfaceFactory.get_or_create_interface(eth_provider_uri=eth_provider_uri)\n\n        if not contract:  # Fetch the contract\n            contract = self.blockchain.get_contract_by_name(\n                registry=registry,\n                contract_name=self.contract_name,\n                contract_version=contract_version,\n                proxy_name=self._proxy_name,\n                use_proxy_address=self._forward_address\n            )\n\n        self.__contract = contract\n        self.events = ContractEvents(contract)\n        if not transaction_gas:\n            transaction_gas = EthereumContractAgent.DEFAULT_TRANSACTION_GAS_LIMITS['default']\n        self.transaction_gas = transaction_gas\n\n        self.log.info(\"Initialized new {} for {} with {} and {}\".format(\n            self.__class__.__name__,\n            self.contract.address,\n            self.blockchain.eth_provider_uri,\n            str(self.registry)\n        ))\n\n    def __repr__(self) -> str:\n        class_name = self.__class__.__name__\n        r = \"{}(registry={}, contract={})\"\n        return r.format(class_name, str(self.registry), self.contract_name)\n\n    def __eq__(self, other: Any) -> bool:\n        return bool(self.contract.address == other.contract.address)\n\n    @property  # type: ignore\n    def contract(self) -> Contract:\n        return self.__contract\n\n    @property  # type: ignore\n    def contract_address(self) -> ChecksumAddress:\n        return self.__contract.address\n\n    @property  # type: ignore\n    @contract_api(CONTRACT_ATTRIBUTE)\n    def owner(self) -> Optional[ChecksumAddress]:\n        if not self._proxy_name:\n            # Only upgradeable + ownable contracts can implement ownership transference.\n            return None\n        return self.contract.functions.owner().call()",
  "class NucypherTokenAgent(EthereumContractAgent):\n\n    contract_name: str = NUCYPHER_TOKEN_CONTRACT_NAME\n\n    @contract_api(CONTRACT_CALL)\n    def get_balance(self, address: ChecksumAddress) -> NuNits:\n        \"\"\"Get the NU balance (in NuNits) of a token holder address, or of this contract address\"\"\"\n        balance: int = self.contract.functions.balanceOf(address).call()\n        return NuNits(balance)\n\n    @contract_api(CONTRACT_CALL)\n    def get_allowance(self, owner: ChecksumAddress, spender: ChecksumAddress) -> NuNits:\n        \"\"\"Check the amount of tokens that an owner allowed to a spender\"\"\"\n        allowance: int = self.contract.functions.allowance(owner, spender).call()\n        return NuNits(allowance)\n\n    @contract_api(TRANSACTION)\n    def increase_allowance(self,\n                           transacting_power: TransactingPower,\n                           spender_address: ChecksumAddress,\n                           increase: NuNits\n                           ) -> TxReceipt:\n        \"\"\"Increase the allowance of a spender address funded by a sender address\"\"\"\n        contract_function: ContractFunction = self.contract.functions.increaseAllowance(spender_address, increase)\n        receipt: TxReceipt = self.blockchain.send_transaction(contract_function=contract_function,\n                                                              transacting_power=transacting_power)\n        return receipt\n\n    @contract_api(TRANSACTION)\n    def decrease_allowance(self,\n                           transacting_power: TransactingPower,\n                           spender_address: ChecksumAddress,\n                           decrease: NuNits\n                           ) -> TxReceipt:\n        \"\"\"Decrease the allowance of a spender address funded by a sender address\"\"\"\n        contract_function: ContractFunction = self.contract.functions.decreaseAllowance(spender_address, decrease)\n        receipt: TxReceipt = self.blockchain.send_transaction(contract_function=contract_function,\n                                                              transacting_power=transacting_power)\n        return receipt\n\n    @contract_api(TRANSACTION)\n    def approve_transfer(self,\n                         amount: NuNits,\n                         spender_address: ChecksumAddress,\n                         transacting_power: TransactingPower\n                         ) -> TxReceipt:\n        \"\"\"Approve the spender address to transfer an amount of tokens on behalf of the sender address\"\"\"\n        self._validate_zero_allowance(amount, spender_address, transacting_power)\n\n        payload: TxParams = {'gas': Wei(500_000)}  # TODO #842: gas needed for use with geth! <<<< Is this still open?\n        contract_function: ContractFunction = self.contract.functions.approve(spender_address, amount)\n        receipt: TxReceipt = self.blockchain.send_transaction(contract_function=contract_function,\n                                                              payload=payload,\n                                                              transacting_power=transacting_power)\n        return receipt\n\n    @contract_api(TRANSACTION)\n    def transfer(self, amount: NuNits, target_address: ChecksumAddress, transacting_power: TransactingPower) -> TxReceipt:\n        \"\"\"Transfer an amount of tokens from the sender address to the target address.\"\"\"\n        contract_function: ContractFunction = self.contract.functions.transfer(target_address, amount)\n        receipt: TxReceipt = self.blockchain.send_transaction(contract_function=contract_function,\n                                                              transacting_power=transacting_power)\n        return receipt\n\n    @contract_api(TRANSACTION)\n    def approve_and_call(self,\n                         amount: NuNits,\n                         target_address: ChecksumAddress,\n                         transacting_power: TransactingPower,\n                         call_data: bytes = b'',\n                         gas_limit: Optional[Wei] = None\n                         ) -> TxReceipt:\n        self._validate_zero_allowance(amount, target_address, transacting_power)\n\n        payload = None\n        if gas_limit:  # TODO: Gas management - #842\n            payload = {'gas': gas_limit}\n        approve_and_call: ContractFunction = self.contract.functions.approveAndCall(target_address, amount, call_data)\n        approve_and_call_receipt: TxReceipt = self.blockchain.send_transaction(contract_function=approve_and_call,\n                                                                               transacting_power=transacting_power,\n                                                                               payload=payload)\n        return approve_and_call_receipt\n\n    def _validate_zero_allowance(self, amount, target_address, transacting_power):\n        if amount == 0:\n            return\n        current_allowance = self.get_allowance(owner=transacting_power.account, spender=target_address)\n        if current_allowance != 0:\n            raise self.RequirementError(f\"Token allowance for spender {target_address} must be 0\")",
  "class SubscriptionManagerAgent(EthereumContractAgent):\n\n    contract_name: str = SUBSCRIPTION_MANAGER_CONTRACT_NAME\n    # TODO: A future deployment of SubscriptionManager may have a proxy.\n    #  _proxy_name: str = DISPATCHER_CONTRACT_NAME\n\n    class PolicyInfo(NamedTuple):\n        sponsor: ChecksumAddress\n        owner: ChecksumAddress\n        start_timestamp: int\n        end_timestamp: int\n\n    #\n    # Calls\n    #\n\n    @contract_api(CONTRACT_CALL)\n    def fee_rate(self) -> Wei:\n        result = self.contract.functions.feeRate().call()\n        return Wei(result)\n\n    @contract_api(CONTRACT_CALL)\n    def is_policy_active(self, policy_id: bytes) -> bool:\n        result = self.contract.functions.isPolicyActive(policy_id).call()\n        return result\n\n    @contract_api(CONTRACT_CALL)\n    def fetch_policy(self, policy_id: bytes) -> PolicyInfo:\n        record = self.contract.functions.policies(policy_id).call()\n        policy_info = self.PolicyInfo(\n            sponsor=record[0],\n            start_timestamp=record[1],\n            end_timestamp=record[2],\n            size=record[3],\n            # If the policyOwner addr is null, we return the sponsor addr instead of the owner.\n            owner=record[0] if record[4] == NULL_ADDRESS else record[4]\n        )\n        return policy_info\n\n    #\n    # Transactions\n    #\n\n    @contract_api(TRANSACTION)\n    def create_policy(self,\n                      policy_id: bytes,\n                      transacting_power: TransactingPower,\n                      size: int,\n                      start_timestamp: Timestamp,\n                      end_timestamp: Timestamp,\n                      value: Wei,\n                      owner_address: Optional[ChecksumAddress] = None) -> TxReceipt:\n        owner_address = owner_address or transacting_power.account\n        payload: TxParams = {'value': value}\n        contract_function: ContractFunction = self.contract.functions.createPolicy(\n            policy_id,\n            owner_address,\n            size,\n            start_timestamp,\n            end_timestamp\n        )\n        receipt = self.blockchain.send_transaction(\n            contract_function=contract_function,\n            payload=payload,\n            transacting_power=transacting_power\n        )\n        return receipt",
  "class AdjudicatorAgent(EthereumContractAgent):\n\n    contract_name: str = ADJUDICATOR_CONTRACT_NAME\n    _proxy_name: str = DISPATCHER_CONTRACT_NAME\n\n    @contract_api(TRANSACTION)\n    def evaluate_cfrag(self, evidence, transacting_power: TransactingPower) -> TxReceipt:\n        \"\"\"Submits proof that a worker created wrong CFrag\"\"\"\n        payload: TxParams = {'gas': Wei(500_000)}  # TODO TransactionFails unless gas is provided.\n        contract_function: ContractFunction = self.contract.functions.evaluateCFrag(*evidence.evaluation_arguments())\n        receipt = self.blockchain.send_transaction(contract_function=contract_function,\n                                                   transacting_power=transacting_power,\n                                                   payload=payload)\n        return receipt\n\n    @contract_api(CONTRACT_CALL)\n    def was_this_evidence_evaluated(self, evidence) -> bool:\n        data_hash: bytes = sha256_digest(evidence.task.capsule, evidence.task.cfrag)\n        result: bool = self.contract.functions.evaluatedCFrags(data_hash).call()\n        return result\n\n    @property  # type: ignore\n    @contract_api(CONTRACT_ATTRIBUTE)\n    def staking_escrow_contract(self) -> ChecksumAddress:\n        return self.contract.functions.escrow().call()\n\n    @property  # type: ignore\n    @contract_api(CONTRACT_ATTRIBUTE)\n    def hash_algorithm(self) -> int:\n        return self.contract.functions.hashAlgorithm().call()\n\n    @property  # type: ignore\n    @contract_api(CONTRACT_ATTRIBUTE)\n    def base_penalty(self) -> int:\n        return self.contract.functions.basePenalty().call()\n\n    @property  # type: ignore\n    @contract_api(CONTRACT_ATTRIBUTE)\n    def penalty_history_coefficient(self) -> int:\n        return self.contract.functions.penaltyHistoryCoefficient().call()\n\n    @property  # type: ignore\n    @contract_api(CONTRACT_ATTRIBUTE)\n    def percentage_penalty_coefficient(self) -> int:\n        return self.contract.functions.percentagePenaltyCoefficient().call()\n\n    @property  # type: ignore\n    @contract_api(CONTRACT_ATTRIBUTE)\n    def reward_coefficient(self) -> int:\n        return self.contract.functions.rewardCoefficient().call()\n\n    @contract_api(CONTRACT_CALL)\n    def penalty_history(self, staker_address: str) -> int:\n        return self.contract.functions.penaltyHistory(staker_address).call()\n\n    @contract_api(CONTRACT_CALL)\n    def slashing_parameters(self) -> Tuple[int, ...]:\n        parameter_signatures = (\n            'hashAlgorithm',                    # Hashing algorithm\n            'basePenalty',                      # Base for the penalty calculation\n            'penaltyHistoryCoefficient',        # Coefficient for calculating the penalty depending on the history\n            'percentagePenaltyCoefficient',     # Coefficient for calculating the percentage penalty\n            'rewardCoefficient',                # Coefficient for calculating the reward\n        )\n\n        def _call_function_by_name(name: str) -> int:\n            return getattr(self.contract.functions, name)().call()\n\n        staking_parameters = tuple(map(_call_function_by_name, parameter_signatures))\n        return staking_parameters",
  "class PREApplicationAgent(EthereumContractAgent):\n\n    contract_name: str = PRE_APPLICATION_CONTRACT_NAME\n\n    DEFAULT_PROVIDERS_PAGINATION_SIZE_LIGHT_NODE = int(os.environ.get(NUCYPHER_ENVVAR_STAKING_PROVIDERS_PAGINATION_SIZE_LIGHT_NODE, default=30))\n    DEFAULT_PROVIDERS_PAGINATION_SIZE = int(os.environ.get(NUCYPHER_ENVVAR_STAKING_PROVIDERS_PAGINATION_SIZE, default=1000))\n\n    class NotEnoughStakingProviders(Exception):\n        pass\n\n    class OperatorInfo(NamedTuple):\n        address: ChecksumAddress\n        confirmed: bool\n        start_timestamp: Timestamp\n\n    @contract_api(CONTRACT_CALL)\n    def get_min_authorization(self) -> int:\n        result = self.contract.functions.minAuthorization().call()\n        return result\n\n    @contract_api(CONTRACT_CALL)\n    def get_min_operator_seconds(self) -> int:\n        result = self.contract.functions.minOperatorSeconds().call()\n        return result\n\n    @contract_api(CONTRACT_CALL)\n    def get_staking_provider_from_operator(self, operator_address: ChecksumAddress) -> ChecksumAddress:\n        result = self.contract.functions.stakingProviderFromOperator(operator_address).call()\n        return result\n\n    @contract_api(CONTRACT_CALL)\n    def get_operator_from_staking_provider(self, staking_provider: ChecksumAddress) -> ChecksumAddress:\n        result = self.contract.functions.getOperatorFromStakingProvider(staking_provider).call()\n        return result\n\n    @contract_api(CONTRACT_CALL)\n    def get_beneficiary(self, staking_provider: ChecksumAddress) -> ChecksumAddress:\n        result = self.contract.functions.getBeneficiary(staking_provider).call()\n        return result\n\n    @contract_api(CONTRACT_CALL)\n    def is_operator_confirmed(self, address: ChecksumAddress) -> bool:\n        result = self.contract.functions.isOperatorConfirmed(address).call()\n        return result\n\n    @contract_api(CONTRACT_CALL)\n    def get_staking_provider_info(self, staking_provider: ChecksumAddress) -> StakingProviderInfo:\n        # remove reserved fields\n        info: list = self.contract.functions.stakingProviderInfo(staking_provider).call()\n        return StakingProviderInfo(*info[0:3])\n\n    @contract_api(CONTRACT_CALL)\n    def get_authorized_stake(self, staking_provider: ChecksumAddress) -> int:\n        result = self.contract.functions.authorizedStake(staking_provider).call()\n        return result\n\n    @contract_api(CONTRACT_CALL)\n    def is_authorized(self, staking_provider: ChecksumAddress) -> bool:\n        result = self.contract.functions.isAuthorized(staking_provider).call()\n        return result\n\n    @contract_api(CONTRACT_CALL)\n    def get_staking_providers_population(self) -> int:\n        result = self.contract.functions.getStakingProvidersLength().call()\n        return result\n\n    @contract_api(CONTRACT_CALL)\n    def get_staking_providers(self) -> List[ChecksumAddress]:\n        \"\"\"Returns a list of staking provider addresses\"\"\"\n        num_providers: int = self.get_staking_providers_population()\n        providers: List[ChecksumAddress] = [self.contract.functions.stakingProviders(i).call() for i in range(num_providers)]\n        return providers\n\n    @contract_api(CONTRACT_CALL)\n    def get_active_staking_providers(self, start_index: int, max_results: int) -> Iterable:\n        result = self.contract.functions.getActiveStakingProviders(start_index, max_results).call()\n        return result\n\n    @contract_api(CONTRACT_CALL)\n    def swarm(self) -> Iterable[ChecksumAddress]:\n        for index in range(self.get_staking_providers_population()):\n            address: ChecksumAddress = self.contract.functions.stakingProviders(index).call()\n            yield address\n\n    @contract_api(CONTRACT_CALL)\n    def get_all_active_staking_providers(self, pagination_size: Optional[int] = None) -> Tuple[TuNits, Dict[ChecksumAddress, TuNits]]:\n\n        if pagination_size is None:\n            pagination_size = self.DEFAULT_PROVIDERS_PAGINATION_SIZE_LIGHT_NODE if self.blockchain.is_light else self.DEFAULT_PROVIDERS_PAGINATION_SIZE\n            self.log.debug(f\"Defaulting to pagination size {pagination_size}\")\n        elif pagination_size < 0:\n            raise ValueError(\"Pagination size must be >= 0\")\n\n        if pagination_size > 0:\n            num_providers: int = self.get_staking_providers_population()\n            start_index: int = 0\n            n_tokens: int = 0\n            staking_providers: Dict[int, int] = dict()\n            attempts: int = 0\n            while start_index < num_providers:\n                try:\n                    attempts += 1\n                    active_staking_providers = self.get_active_staking_providers(start_index, pagination_size)\n                except Exception as e:\n                    if 'timeout' not in str(e):\n                        # exception unrelated to pagination size and timeout\n                        raise e\n                    elif pagination_size == 1 or attempts >= 3:\n                        # we tried\n                        raise e\n                    else:\n                        # reduce pagination size and retry\n                        old_pagination_size = pagination_size\n                        pagination_size = old_pagination_size // 2\n                        self.log.debug(f\"Failed staking providers sampling using pagination size = {old_pagination_size}.\"\n                                       f\"Retrying with size {pagination_size}\")\n                else:\n                    temp_authorized_tokens, temp_staking_providers = active_staking_providers\n                    # temp_staking_providers is a list of length-2 lists (address -> authorized tokens)\n                    temp_staking_providers = {address: authorized_tokens for address, authorized_tokens in temp_staking_providers}\n                    n_tokens = n_tokens + temp_authorized_tokens\n                    staking_providers.update(temp_staking_providers)\n                    start_index += pagination_size\n\n        else:\n            n_tokens, temp_staking_providers = self.get_active_staking_providers(start_index=0, max_results=0)\n            staking_providers = {address: authorized_tokens for address, authorized_tokens in temp_staking_providers}\n\n        # staking provider's addresses are returned as uint256 by getActiveStakingProviders(), convert to address objects\n        def checksum_address(address: int) -> ChecksumAddress:\n            return ChecksumAddress(to_checksum_address(address.to_bytes(ETH_ADDRESS_BYTE_LENGTH, 'big')))\n\n        typed_staking_providers = {checksum_address(address): TuNits(authorized_tokens)\n                                   for address, authorized_tokens in staking_providers.items()}\n\n        return TuNits(n_tokens), typed_staking_providers\n\n    def get_staking_provider_reservoir(self,\n                                       without: Iterable[ChecksumAddress] = None,\n                                       pagination_size: Optional[int] = None\n                                       ) -> 'StakingProvidersReservoir':\n\n        # pagination_size = pagination_size or self.get_staking_providers_population()\n        n_tokens, stake_provider_map = self.get_all_active_staking_providers(pagination_size=pagination_size)\n\n        filtered_out = 0\n        if without:\n            for address in without:\n                if address in stake_provider_map:\n                    n_tokens -= stake_provider_map[address]\n                    del stake_provider_map[address]\n                    filtered_out += 1\n\n        self.log.debug(f\"Got {len(stake_provider_map)} staking providers with {n_tokens} total tokens \"\n                       f\"({filtered_out} filtered out)\")\n        if n_tokens == 0:\n            raise self.NotEnoughStakingProviders(f'There are no locked tokens.')\n\n        return StakingProvidersReservoir(stake_provider_map)\n\n    #\n    # Transactions\n    #\n\n    @contract_api(TRANSACTION)\n    def confirm_operator_address(self, transacting_power: TransactingPower, fire_and_forget: bool = True) -> TxReceipt:\n        \"\"\"Confirm the sender's account as a operator\"\"\"\n        contract_function: ContractFunction = self.contract.functions.confirmOperatorAddress()\n        receipt = self.blockchain.send_transaction(contract_function=contract_function,\n                                                   transacting_power=transacting_power,\n                                                   fire_and_forget=fire_and_forget\n                                                   )\n        return receipt\n\n    @contract_api(TRANSACTION)\n    def bond_operator(self, staking_provider: ChecksumAddress, operator: ChecksumAddress, transacting_power: TransactingPower) -> TxReceipt:\n        \"\"\"For use by threshold operator accounts only.\"\"\"\n        contract_function: ContractFunction = self.contract.functions.bondOperator(staking_provider, operator)\n        receipt = self.blockchain.send_transaction(contract_function=contract_function,\n                                                   transacting_power=transacting_power)\n        return receipt",
  "class ContractAgency:\n    \"\"\"Where agents live and die.\"\"\"\n\n    # TODO: Enforce singleton - #1506 - Okay, actually, make this into a module\n    __agents: Dict[str, Dict[Type[EthereumContractAgent], EthereumContractAgent]] = dict()\n\n    @classmethod\n    def get_agent(cls,\n                  agent_class: Type[Agent],\n                  registry: Optional[BaseContractRegistry] = None,\n                  eth_provider_uri: Optional[str] = None,\n                  contract_version: Optional[str] = None\n                  ) -> Agent:\n\n        if not issubclass(agent_class, EthereumContractAgent):\n            raise TypeError(f\"Only agent subclasses can be used from the agency.\")\n\n        if not registry:\n            if len(cls.__agents) == 1:\n                registry_id = list(cls.__agents.keys()).pop()\n            else:\n                raise ValueError(\"Need to specify a registry in order to get an agent from the ContractAgency\")\n        else:\n            registry_id = registry.id\n        try:\n            return cast(Agent, cls.__agents[registry_id][agent_class])\n        except KeyError:\n            agent = cast(Agent, agent_class(registry=registry, eth_provider_uri=eth_provider_uri, contract_version=contract_version))\n            cls.__agents[registry_id] = cls.__agents.get(registry_id, dict())\n            cls.__agents[registry_id][agent_class] = agent\n            return agent\n\n    @staticmethod\n    def _contract_name_to_agent_name(name: str) -> str:\n        if name == NUCYPHER_TOKEN_CONTRACT_NAME:\n            # TODO: Perhaps rename NucypherTokenAgent\n            name = \"NucypherToken\"\n        if name == PRE_APPLICATION_CONTRACT_NAME:\n            name = \"PREApplication\"  # TODO not needed once full PRE Application is used\n        agent_name = f\"{name}Agent\"\n        return agent_name\n\n    @classmethod\n    def get_agent_by_contract_name(cls,\n                                   contract_name: str,\n                                   registry: BaseContractRegistry,\n                                   eth_provider_uri: Optional[str] = None,\n                                   contract_version: Optional[str] = None\n                                   ) -> EthereumContractAgent:\n        agent_name: str = cls._contract_name_to_agent_name(name=contract_name)\n        agents_module = sys.modules[__name__]\n        agent_class: Type[EthereumContractAgent] = getattr(agents_module, agent_name)\n        agent: EthereumContractAgent = cls.get_agent(\n            agent_class=agent_class,\n            registry=registry,\n            eth_provider_uri=eth_provider_uri,\n            contract_version=contract_version\n        )\n        return agent",
  "class WeightedSampler:\n    \"\"\"\n    Samples random elements with probabilities proportional to given weights.\n    \"\"\"\n\n    def __init__(self, weighted_elements: Dict[Any, int]):\n        if weighted_elements:\n            elements, weights = zip(*weighted_elements.items())\n        else:\n            elements, weights = [], []\n        self.totals = list(accumulate(weights))\n        self.elements = elements\n        self.__length = len(self.totals)\n\n    def sample_no_replacement(self, rng, quantity: int) -> list:\n        \"\"\"\n        Samples ``quantity`` of elements from the internal array.\n        The probability of an element to appear is proportional\n        to the weight provided to the constructor.\n\n        The elements will not repeat; every time an element is sampled its weight is set to 0.\n        (does not mutate the object and only applies to the current invocation of the method).\n        \"\"\"\n\n        if quantity == 0:\n            return []\n\n        if quantity > len(self):\n            raise ValueError(\"Cannot sample more than the total amount of elements without replacement\")\n\n        samples = []\n\n        for i in range(quantity):\n            position = rng.randint(0, self.totals[-1] - 1)\n            idx = bisect_right(self.totals, position)\n            samples.append(self.elements[idx])\n\n            # Adjust the totals so that they correspond\n            # to the weight of the element `idx` being set to 0.\n            prev_total = self.totals[idx - 1] if idx > 0 else 0\n            weight = self.totals[idx] - prev_total\n            for j in range(idx, len(self.totals)):\n                self.totals[j] -= weight\n\n        self.__length -= quantity\n\n        return samples\n\n    def __len__(self):\n        return self.__length",
  "class StakingProvidersReservoir:\n\n    def __init__(self, staking_provider_map: Dict[ChecksumAddress, int]):\n        self._sampler = WeightedSampler(staking_provider_map)\n        self._rng = random.SystemRandom()\n\n    def __len__(self):\n        return len(self._sampler)\n\n    def draw(self, quantity):\n        if quantity > len(self):\n            raise PREApplicationAgent.NotEnoughStakingProviders(f'Cannot sample {quantity} out of {len(self)} total staking providers')\n\n        return self._sampler.sample_no_replacement(self._rng, quantity)\n\n    def draw_at_most(self, quantity):\n        return self.draw(min(quantity, len(self)))",
  "class ContractNotDeployed(Exception):\n        \"\"\"Raised when attempting to access a contract that is not deployed on the current network.\"\"\"",
  "class RequirementError(Exception):\n        \"\"\"\n        Raised when an agent discovers a failed requirement in an invocation to a contract function,\n        usually, a failed `require()`.\n        \"\"\"",
  "def __init__(self,\n                 registry: BaseContractRegistry = None,  # TODO: Consider make it non-optional again. See comment in InstanceAgent.\n                 eth_provider_uri: Optional[str] = None,\n                 contract: Optional[Contract] = None,\n                 transaction_gas: Optional[Wei] = None,\n                 contract_version: Optional[str] = None):\n\n        self.log = Logger(self.__class__.__name__)\n        self.registry = registry\n\n        self.blockchain = BlockchainInterfaceFactory.get_or_create_interface(eth_provider_uri=eth_provider_uri)\n\n        if not contract:  # Fetch the contract\n            contract = self.blockchain.get_contract_by_name(\n                registry=registry,\n                contract_name=self.contract_name,\n                contract_version=contract_version,\n                proxy_name=self._proxy_name,\n                use_proxy_address=self._forward_address\n            )\n\n        self.__contract = contract\n        self.events = ContractEvents(contract)\n        if not transaction_gas:\n            transaction_gas = EthereumContractAgent.DEFAULT_TRANSACTION_GAS_LIMITS['default']\n        self.transaction_gas = transaction_gas\n\n        self.log.info(\"Initialized new {} for {} with {} and {}\".format(\n            self.__class__.__name__,\n            self.contract.address,\n            self.blockchain.eth_provider_uri,\n            str(self.registry)\n        ))",
  "def __repr__(self) -> str:\n        class_name = self.__class__.__name__\n        r = \"{}(registry={}, contract={})\"\n        return r.format(class_name, str(self.registry), self.contract_name)",
  "def __eq__(self, other: Any) -> bool:\n        return bool(self.contract.address == other.contract.address)",
  "def contract(self) -> Contract:\n        return self.__contract",
  "def contract_address(self) -> ChecksumAddress:\n        return self.__contract.address",
  "def owner(self) -> Optional[ChecksumAddress]:\n        if not self._proxy_name:\n            # Only upgradeable + ownable contracts can implement ownership transference.\n            return None\n        return self.contract.functions.owner().call()",
  "def get_balance(self, address: ChecksumAddress) -> NuNits:\n        \"\"\"Get the NU balance (in NuNits) of a token holder address, or of this contract address\"\"\"\n        balance: int = self.contract.functions.balanceOf(address).call()\n        return NuNits(balance)",
  "def get_allowance(self, owner: ChecksumAddress, spender: ChecksumAddress) -> NuNits:\n        \"\"\"Check the amount of tokens that an owner allowed to a spender\"\"\"\n        allowance: int = self.contract.functions.allowance(owner, spender).call()\n        return NuNits(allowance)",
  "def increase_allowance(self,\n                           transacting_power: TransactingPower,\n                           spender_address: ChecksumAddress,\n                           increase: NuNits\n                           ) -> TxReceipt:\n        \"\"\"Increase the allowance of a spender address funded by a sender address\"\"\"\n        contract_function: ContractFunction = self.contract.functions.increaseAllowance(spender_address, increase)\n        receipt: TxReceipt = self.blockchain.send_transaction(contract_function=contract_function,\n                                                              transacting_power=transacting_power)\n        return receipt",
  "def decrease_allowance(self,\n                           transacting_power: TransactingPower,\n                           spender_address: ChecksumAddress,\n                           decrease: NuNits\n                           ) -> TxReceipt:\n        \"\"\"Decrease the allowance of a spender address funded by a sender address\"\"\"\n        contract_function: ContractFunction = self.contract.functions.decreaseAllowance(spender_address, decrease)\n        receipt: TxReceipt = self.blockchain.send_transaction(contract_function=contract_function,\n                                                              transacting_power=transacting_power)\n        return receipt",
  "def approve_transfer(self,\n                         amount: NuNits,\n                         spender_address: ChecksumAddress,\n                         transacting_power: TransactingPower\n                         ) -> TxReceipt:\n        \"\"\"Approve the spender address to transfer an amount of tokens on behalf of the sender address\"\"\"\n        self._validate_zero_allowance(amount, spender_address, transacting_power)\n\n        payload: TxParams = {'gas': Wei(500_000)}  # TODO #842: gas needed for use with geth! <<<< Is this still open?\n        contract_function: ContractFunction = self.contract.functions.approve(spender_address, amount)\n        receipt: TxReceipt = self.blockchain.send_transaction(contract_function=contract_function,\n                                                              payload=payload,\n                                                              transacting_power=transacting_power)\n        return receipt",
  "def transfer(self, amount: NuNits, target_address: ChecksumAddress, transacting_power: TransactingPower) -> TxReceipt:\n        \"\"\"Transfer an amount of tokens from the sender address to the target address.\"\"\"\n        contract_function: ContractFunction = self.contract.functions.transfer(target_address, amount)\n        receipt: TxReceipt = self.blockchain.send_transaction(contract_function=contract_function,\n                                                              transacting_power=transacting_power)\n        return receipt",
  "def approve_and_call(self,\n                         amount: NuNits,\n                         target_address: ChecksumAddress,\n                         transacting_power: TransactingPower,\n                         call_data: bytes = b'',\n                         gas_limit: Optional[Wei] = None\n                         ) -> TxReceipt:\n        self._validate_zero_allowance(amount, target_address, transacting_power)\n\n        payload = None\n        if gas_limit:  # TODO: Gas management - #842\n            payload = {'gas': gas_limit}\n        approve_and_call: ContractFunction = self.contract.functions.approveAndCall(target_address, amount, call_data)\n        approve_and_call_receipt: TxReceipt = self.blockchain.send_transaction(contract_function=approve_and_call,\n                                                                               transacting_power=transacting_power,\n                                                                               payload=payload)\n        return approve_and_call_receipt",
  "def _validate_zero_allowance(self, amount, target_address, transacting_power):\n        if amount == 0:\n            return\n        current_allowance = self.get_allowance(owner=transacting_power.account, spender=target_address)\n        if current_allowance != 0:\n            raise self.RequirementError(f\"Token allowance for spender {target_address} must be 0\")",
  "class PolicyInfo(NamedTuple):\n        sponsor: ChecksumAddress\n        owner: ChecksumAddress\n        start_timestamp: int\n        end_timestamp: int",
  "def fee_rate(self) -> Wei:\n        result = self.contract.functions.feeRate().call()\n        return Wei(result)",
  "def is_policy_active(self, policy_id: bytes) -> bool:\n        result = self.contract.functions.isPolicyActive(policy_id).call()\n        return result",
  "def fetch_policy(self, policy_id: bytes) -> PolicyInfo:\n        record = self.contract.functions.policies(policy_id).call()\n        policy_info = self.PolicyInfo(\n            sponsor=record[0],\n            start_timestamp=record[1],\n            end_timestamp=record[2],\n            size=record[3],\n            # If the policyOwner addr is null, we return the sponsor addr instead of the owner.\n            owner=record[0] if record[4] == NULL_ADDRESS else record[4]\n        )\n        return policy_info",
  "def create_policy(self,\n                      policy_id: bytes,\n                      transacting_power: TransactingPower,\n                      size: int,\n                      start_timestamp: Timestamp,\n                      end_timestamp: Timestamp,\n                      value: Wei,\n                      owner_address: Optional[ChecksumAddress] = None) -> TxReceipt:\n        owner_address = owner_address or transacting_power.account\n        payload: TxParams = {'value': value}\n        contract_function: ContractFunction = self.contract.functions.createPolicy(\n            policy_id,\n            owner_address,\n            size,\n            start_timestamp,\n            end_timestamp\n        )\n        receipt = self.blockchain.send_transaction(\n            contract_function=contract_function,\n            payload=payload,\n            transacting_power=transacting_power\n        )\n        return receipt",
  "def evaluate_cfrag(self, evidence, transacting_power: TransactingPower) -> TxReceipt:\n        \"\"\"Submits proof that a worker created wrong CFrag\"\"\"\n        payload: TxParams = {'gas': Wei(500_000)}  # TODO TransactionFails unless gas is provided.\n        contract_function: ContractFunction = self.contract.functions.evaluateCFrag(*evidence.evaluation_arguments())\n        receipt = self.blockchain.send_transaction(contract_function=contract_function,\n                                                   transacting_power=transacting_power,\n                                                   payload=payload)\n        return receipt",
  "def was_this_evidence_evaluated(self, evidence) -> bool:\n        data_hash: bytes = sha256_digest(evidence.task.capsule, evidence.task.cfrag)\n        result: bool = self.contract.functions.evaluatedCFrags(data_hash).call()\n        return result",
  "def staking_escrow_contract(self) -> ChecksumAddress:\n        return self.contract.functions.escrow().call()",
  "def hash_algorithm(self) -> int:\n        return self.contract.functions.hashAlgorithm().call()",
  "def base_penalty(self) -> int:\n        return self.contract.functions.basePenalty().call()",
  "def penalty_history_coefficient(self) -> int:\n        return self.contract.functions.penaltyHistoryCoefficient().call()",
  "def percentage_penalty_coefficient(self) -> int:\n        return self.contract.functions.percentagePenaltyCoefficient().call()",
  "def reward_coefficient(self) -> int:\n        return self.contract.functions.rewardCoefficient().call()",
  "def penalty_history(self, staker_address: str) -> int:\n        return self.contract.functions.penaltyHistory(staker_address).call()",
  "def slashing_parameters(self) -> Tuple[int, ...]:\n        parameter_signatures = (\n            'hashAlgorithm',                    # Hashing algorithm\n            'basePenalty',                      # Base for the penalty calculation\n            'penaltyHistoryCoefficient',        # Coefficient for calculating the penalty depending on the history\n            'percentagePenaltyCoefficient',     # Coefficient for calculating the percentage penalty\n            'rewardCoefficient',                # Coefficient for calculating the reward\n        )\n\n        def _call_function_by_name(name: str) -> int:\n            return getattr(self.contract.functions, name)().call()\n\n        staking_parameters = tuple(map(_call_function_by_name, parameter_signatures))\n        return staking_parameters",
  "class NotEnoughStakingProviders(Exception):\n        pass",
  "class OperatorInfo(NamedTuple):\n        address: ChecksumAddress\n        confirmed: bool\n        start_timestamp: Timestamp",
  "def get_min_authorization(self) -> int:\n        result = self.contract.functions.minAuthorization().call()\n        return result",
  "def get_min_operator_seconds(self) -> int:\n        result = self.contract.functions.minOperatorSeconds().call()\n        return result",
  "def get_staking_provider_from_operator(self, operator_address: ChecksumAddress) -> ChecksumAddress:\n        result = self.contract.functions.stakingProviderFromOperator(operator_address).call()\n        return result",
  "def get_operator_from_staking_provider(self, staking_provider: ChecksumAddress) -> ChecksumAddress:\n        result = self.contract.functions.getOperatorFromStakingProvider(staking_provider).call()\n        return result",
  "def get_beneficiary(self, staking_provider: ChecksumAddress) -> ChecksumAddress:\n        result = self.contract.functions.getBeneficiary(staking_provider).call()\n        return result",
  "def is_operator_confirmed(self, address: ChecksumAddress) -> bool:\n        result = self.contract.functions.isOperatorConfirmed(address).call()\n        return result",
  "def get_staking_provider_info(self, staking_provider: ChecksumAddress) -> StakingProviderInfo:\n        # remove reserved fields\n        info: list = self.contract.functions.stakingProviderInfo(staking_provider).call()\n        return StakingProviderInfo(*info[0:3])",
  "def get_authorized_stake(self, staking_provider: ChecksumAddress) -> int:\n        result = self.contract.functions.authorizedStake(staking_provider).call()\n        return result",
  "def is_authorized(self, staking_provider: ChecksumAddress) -> bool:\n        result = self.contract.functions.isAuthorized(staking_provider).call()\n        return result",
  "def get_staking_providers_population(self) -> int:\n        result = self.contract.functions.getStakingProvidersLength().call()\n        return result",
  "def get_staking_providers(self) -> List[ChecksumAddress]:\n        \"\"\"Returns a list of staking provider addresses\"\"\"\n        num_providers: int = self.get_staking_providers_population()\n        providers: List[ChecksumAddress] = [self.contract.functions.stakingProviders(i).call() for i in range(num_providers)]\n        return providers",
  "def get_active_staking_providers(self, start_index: int, max_results: int) -> Iterable:\n        result = self.contract.functions.getActiveStakingProviders(start_index, max_results).call()\n        return result",
  "def swarm(self) -> Iterable[ChecksumAddress]:\n        for index in range(self.get_staking_providers_population()):\n            address: ChecksumAddress = self.contract.functions.stakingProviders(index).call()\n            yield address",
  "def get_all_active_staking_providers(self, pagination_size: Optional[int] = None) -> Tuple[TuNits, Dict[ChecksumAddress, TuNits]]:\n\n        if pagination_size is None:\n            pagination_size = self.DEFAULT_PROVIDERS_PAGINATION_SIZE_LIGHT_NODE if self.blockchain.is_light else self.DEFAULT_PROVIDERS_PAGINATION_SIZE\n            self.log.debug(f\"Defaulting to pagination size {pagination_size}\")\n        elif pagination_size < 0:\n            raise ValueError(\"Pagination size must be >= 0\")\n\n        if pagination_size > 0:\n            num_providers: int = self.get_staking_providers_population()\n            start_index: int = 0\n            n_tokens: int = 0\n            staking_providers: Dict[int, int] = dict()\n            attempts: int = 0\n            while start_index < num_providers:\n                try:\n                    attempts += 1\n                    active_staking_providers = self.get_active_staking_providers(start_index, pagination_size)\n                except Exception as e:\n                    if 'timeout' not in str(e):\n                        # exception unrelated to pagination size and timeout\n                        raise e\n                    elif pagination_size == 1 or attempts >= 3:\n                        # we tried\n                        raise e\n                    else:\n                        # reduce pagination size and retry\n                        old_pagination_size = pagination_size\n                        pagination_size = old_pagination_size // 2\n                        self.log.debug(f\"Failed staking providers sampling using pagination size = {old_pagination_size}.\"\n                                       f\"Retrying with size {pagination_size}\")\n                else:\n                    temp_authorized_tokens, temp_staking_providers = active_staking_providers\n                    # temp_staking_providers is a list of length-2 lists (address -> authorized tokens)\n                    temp_staking_providers = {address: authorized_tokens for address, authorized_tokens in temp_staking_providers}\n                    n_tokens = n_tokens + temp_authorized_tokens\n                    staking_providers.update(temp_staking_providers)\n                    start_index += pagination_size\n\n        else:\n            n_tokens, temp_staking_providers = self.get_active_staking_providers(start_index=0, max_results=0)\n            staking_providers = {address: authorized_tokens for address, authorized_tokens in temp_staking_providers}\n\n        # staking provider's addresses are returned as uint256 by getActiveStakingProviders(), convert to address objects\n        def checksum_address(address: int) -> ChecksumAddress:\n            return ChecksumAddress(to_checksum_address(address.to_bytes(ETH_ADDRESS_BYTE_LENGTH, 'big')))\n\n        typed_staking_providers = {checksum_address(address): TuNits(authorized_tokens)\n                                   for address, authorized_tokens in staking_providers.items()}\n\n        return TuNits(n_tokens), typed_staking_providers",
  "def get_staking_provider_reservoir(self,\n                                       without: Iterable[ChecksumAddress] = None,\n                                       pagination_size: Optional[int] = None\n                                       ) -> 'StakingProvidersReservoir':\n\n        # pagination_size = pagination_size or self.get_staking_providers_population()\n        n_tokens, stake_provider_map = self.get_all_active_staking_providers(pagination_size=pagination_size)\n\n        filtered_out = 0\n        if without:\n            for address in without:\n                if address in stake_provider_map:\n                    n_tokens -= stake_provider_map[address]\n                    del stake_provider_map[address]\n                    filtered_out += 1\n\n        self.log.debug(f\"Got {len(stake_provider_map)} staking providers with {n_tokens} total tokens \"\n                       f\"({filtered_out} filtered out)\")\n        if n_tokens == 0:\n            raise self.NotEnoughStakingProviders(f'There are no locked tokens.')\n\n        return StakingProvidersReservoir(stake_provider_map)",
  "def confirm_operator_address(self, transacting_power: TransactingPower, fire_and_forget: bool = True) -> TxReceipt:\n        \"\"\"Confirm the sender's account as a operator\"\"\"\n        contract_function: ContractFunction = self.contract.functions.confirmOperatorAddress()\n        receipt = self.blockchain.send_transaction(contract_function=contract_function,\n                                                   transacting_power=transacting_power,\n                                                   fire_and_forget=fire_and_forget\n                                                   )\n        return receipt",
  "def bond_operator(self, staking_provider: ChecksumAddress, operator: ChecksumAddress, transacting_power: TransactingPower) -> TxReceipt:\n        \"\"\"For use by threshold operator accounts only.\"\"\"\n        contract_function: ContractFunction = self.contract.functions.bondOperator(staking_provider, operator)\n        receipt = self.blockchain.send_transaction(contract_function=contract_function,\n                                                   transacting_power=transacting_power)\n        return receipt",
  "def get_agent(cls,\n                  agent_class: Type[Agent],\n                  registry: Optional[BaseContractRegistry] = None,\n                  eth_provider_uri: Optional[str] = None,\n                  contract_version: Optional[str] = None\n                  ) -> Agent:\n\n        if not issubclass(agent_class, EthereumContractAgent):\n            raise TypeError(f\"Only agent subclasses can be used from the agency.\")\n\n        if not registry:\n            if len(cls.__agents) == 1:\n                registry_id = list(cls.__agents.keys()).pop()\n            else:\n                raise ValueError(\"Need to specify a registry in order to get an agent from the ContractAgency\")\n        else:\n            registry_id = registry.id\n        try:\n            return cast(Agent, cls.__agents[registry_id][agent_class])\n        except KeyError:\n            agent = cast(Agent, agent_class(registry=registry, eth_provider_uri=eth_provider_uri, contract_version=contract_version))\n            cls.__agents[registry_id] = cls.__agents.get(registry_id, dict())\n            cls.__agents[registry_id][agent_class] = agent\n            return agent",
  "def _contract_name_to_agent_name(name: str) -> str:\n        if name == NUCYPHER_TOKEN_CONTRACT_NAME:\n            # TODO: Perhaps rename NucypherTokenAgent\n            name = \"NucypherToken\"\n        if name == PRE_APPLICATION_CONTRACT_NAME:\n            name = \"PREApplication\"  # TODO not needed once full PRE Application is used\n        agent_name = f\"{name}Agent\"\n        return agent_name",
  "def get_agent_by_contract_name(cls,\n                                   contract_name: str,\n                                   registry: BaseContractRegistry,\n                                   eth_provider_uri: Optional[str] = None,\n                                   contract_version: Optional[str] = None\n                                   ) -> EthereumContractAgent:\n        agent_name: str = cls._contract_name_to_agent_name(name=contract_name)\n        agents_module = sys.modules[__name__]\n        agent_class: Type[EthereumContractAgent] = getattr(agents_module, agent_name)\n        agent: EthereumContractAgent = cls.get_agent(\n            agent_class=agent_class,\n            registry=registry,\n            eth_provider_uri=eth_provider_uri,\n            contract_version=contract_version\n        )\n        return agent",
  "def __init__(self, weighted_elements: Dict[Any, int]):\n        if weighted_elements:\n            elements, weights = zip(*weighted_elements.items())\n        else:\n            elements, weights = [], []\n        self.totals = list(accumulate(weights))\n        self.elements = elements\n        self.__length = len(self.totals)",
  "def sample_no_replacement(self, rng, quantity: int) -> list:\n        \"\"\"\n        Samples ``quantity`` of elements from the internal array.\n        The probability of an element to appear is proportional\n        to the weight provided to the constructor.\n\n        The elements will not repeat; every time an element is sampled its weight is set to 0.\n        (does not mutate the object and only applies to the current invocation of the method).\n        \"\"\"\n\n        if quantity == 0:\n            return []\n\n        if quantity > len(self):\n            raise ValueError(\"Cannot sample more than the total amount of elements without replacement\")\n\n        samples = []\n\n        for i in range(quantity):\n            position = rng.randint(0, self.totals[-1] - 1)\n            idx = bisect_right(self.totals, position)\n            samples.append(self.elements[idx])\n\n            # Adjust the totals so that they correspond\n            # to the weight of the element `idx` being set to 0.\n            prev_total = self.totals[idx - 1] if idx > 0 else 0\n            weight = self.totals[idx] - prev_total\n            for j in range(idx, len(self.totals)):\n                self.totals[j] -= weight\n\n        self.__length -= quantity\n\n        return samples",
  "def __len__(self):\n        return self.__length",
  "def __init__(self, staking_provider_map: Dict[ChecksumAddress, int]):\n        self._sampler = WeightedSampler(staking_provider_map)\n        self._rng = random.SystemRandom()",
  "def __len__(self):\n        return len(self._sampler)",
  "def draw(self, quantity):\n        if quantity > len(self):\n            raise PREApplicationAgent.NotEnoughStakingProviders(f'Cannot sample {quantity} out of {len(self)} total staking providers')\n\n        return self._sampler.sample_no_replacement(self._rng, quantity)",
  "def draw_at_most(self, quantity):\n        return self.draw(min(quantity, len(self)))",
  "def _call_function_by_name(name: str) -> int:\n            return getattr(self.contract.functions, name)().call()",
  "def checksum_address(address: int) -> ChecksumAddress:\n            return ChecksumAddress(to_checksum_address(address.to_bytes(ETH_ADDRESS_BYTE_LENGTH, 'big')))",
  "class BaseContractDeployer:\n\n    _interface_class = BlockchainDeployerInterface\n\n    agency = NotImplemented\n    contract_name = NotImplemented\n    deployment_steps = NotImplemented\n\n    _upgradeable = NotImplemented\n    _ownable = NotImplemented\n    _proxy_deployer = NotImplemented\n\n    can_be_idle = False\n\n    class ContractDeploymentError(Exception):\n        pass\n\n    class ContractNotDeployed(ContractDeploymentError):\n        pass\n\n    def __init__(self, registry: BaseContractRegistry, economics: Economics = None):\n\n        # Validate\n        self.blockchain = BlockchainInterfaceFactory.get_interface()\n        if not isinstance(self.blockchain, BlockchainDeployerInterface):\n            raise ValueError(\"No deployer interface connection available.\")\n\n        # Defaults\n        self.registry = registry\n        self.deployment_receipts = OrderedDict()\n        self._contract = CONTRACT_NOT_DEPLOYED\n        self.__proxy_contract = NotImplemented\n        self.__economics = economics or Economics()\n\n    @property\n    def economics(self) -> Economics:\n        \"\"\"Read-only access for economics instance.\"\"\"\n        return self.__economics\n\n    @property\n    def contract_address(self) -> str:\n        if self._contract is CONTRACT_NOT_DEPLOYED:\n            raise self.ContractNotDeployed(self.contract_name)\n        address = self._contract.address  # type: str\n        return address\n\n    @property\n    def contract(self):\n        return self._contract\n\n    @property\n    def dispatcher(self):\n        return self.__proxy_contract\n\n    def is_deployed(self, contract_version: str = None) -> bool:\n        try:\n            self.registry.search(contract_name=self.contract_name, contract_version=contract_version)\n        except (BaseContractRegistry.UnknownContract, BaseContractRegistry.NoRegistry):\n            return False\n        else:\n            return True\n\n    def check_deployment_readiness(self,\n                                   deployer_address: ChecksumAddress,\n                                   contract_version: str = None,\n                                   ignore_deployed=False,\n                                   fail=True,\n                                   additional_rules: List[Tuple[bool, str]] = None,\n                                   ) -> Tuple[bool, list]:\n        \"\"\"\n        Iterates through a set of rules required for an ethereum\n        contract deployer to be eligible for deployment returning a\n        tuple or raising an exception if <fail> is True.\n\n        Returns a tuple containing the boolean readiness result and a list of reasons (if any)\n        why the deployer is not ready.\n\n        If fail is set to True, raise a configuration error, instead of returning.\n        \"\"\"\n\n        if not ignore_deployed and contract_version is not None:\n            contract_version, _data = self.blockchain.find_raw_contract_data(contract_name=self.contract_name,\n                                                                             requested_version=contract_version)\n\n        # Compile rules\n        rules = [\n            (ignore_deployed or not self.is_deployed(contract_version),\n             f'Contract {self.contract_name}:{contract_version} already deployed'),\n        ]\n        if additional_rules:\n            rules.extend(additional_rules)\n\n        disqualifications = list()\n        for rule_is_satisfied, failure_reason in rules:\n            if not rule_is_satisfied:                      # If this rule fails...\n                if fail:\n                    raise self.ContractDeploymentError(failure_reason)\n                disqualifications.append(failure_reason)   # ... here's why\n\n        is_ready = len(disqualifications) == 0\n        return is_ready, disqualifications\n\n    def deploy(self,\n               transacting_power: TransactingPower,\n               deployment_mode=FULL,\n               gas_limit: int = None,\n               progress: int = None,\n               emitter=None,\n               **overrides) -> dict:\n        \"\"\"\n        Provides for the setup, deployment, and initialization of ethereum smart contracts.\n        Emits the configured blockchain network transactions for single contract instance publication.\n        \"\"\"\n        raise NotImplementedError\n\n    def make_agent(self) -> EthereumContractAgent:\n        agent = self.agency(registry=self.registry, contract=self._contract)\n        return agent\n\n    def get_latest_enrollment(self) -> VersionedContract:\n        \"\"\"Get the latest enrolled, bare version of the contract from the registry.\"\"\"\n        contract = self.blockchain.get_contract_by_name(contract_name=self.contract_name,\n                                                        registry=self.registry,\n                                                        use_proxy_address=False,\n                                                        enrollment_version='latest')\n        return contract\n\n    def _get_deployed_contract(self):\n        if self.contract is None or self.contract is CONTRACT_NOT_DEPLOYED:\n            proxy_name = None\n            if self._proxy_deployer is not NotImplemented:\n                proxy_name = self._proxy_deployer.contract_name\n            deployed_contract = self.blockchain.get_contract_by_name(contract_name=self.contract_name,\n                                                                     registry=self.registry,\n                                                                     proxy_name=proxy_name)\n        else:\n            deployed_contract = self.contract\n        return deployed_contract",
  "class OwnableContractMixin:\n\n    _ownable = True\n\n    class ContractNotOwnable(RuntimeError):\n        pass\n\n    @property\n    def owner(self) -> ChecksumAddress:\n        if self._upgradeable:\n            # Get the address of the proxy\n            contract = self.get_proxy_deployer()\n        else:\n            # Get the address of the implementation\n            contract = self.blockchain.get_contract_by_name(contract_name=self.contract_name, registry=self.registry)\n        owner_address = ChecksumAddress(contract.contract.functions.owner().call())  # blockchain read\n        return owner_address\n\n    def transfer_ownership(self,\n                           transacting_power: TransactingPower,\n                           new_owner: str,\n                           transaction_gas_limit: int = None\n                           ) -> dict:\n        if not self._ownable:\n            raise self.ContractNotOwnable(f\"{self.contract_name} is not ownable.\")\n\n        if self._upgradeable:\n\n            #\n            # Upgrade Proxy\n            #\n            proxy_deployer = self.get_proxy_deployer()\n            proxy_contract_function = proxy_deployer.contract.functions.transferOwnership(new_owner)\n            receipt = self.blockchain.send_transaction(transacting_power=transacting_power,\n                                                       contract_function=proxy_contract_function,\n                                                       transaction_gas_limit=transaction_gas_limit)\n        else:\n            existing_bare_contract = self.blockchain.get_contract_by_name(contract_name=self.contract_name,\n                                                                          registry=self.registry)\n\n            #\n            # Upgrade Principal\n            #\n\n            contract_function = existing_bare_contract.functions.transferOwnership(new_owner)\n            receipt = self.blockchain.send_transaction(transacting_power=transacting_power,\n                                                       contract_function=contract_function,\n                                                       transaction_gas_limit=transaction_gas_limit)\n        return receipt",
  "class UpgradeableContractMixin:\n\n    _upgradeable = True\n    _proxy_deployer = NotImplemented\n\n    class ContractNotUpgradeable(RuntimeError):\n        pass\n    \n    def deploy(self,\n               deployment_mode=FULL,\n               gas_limit: int = None,\n               progress=None,\n               contract_version: str = \"latest\",\n               ignore_deployed: bool = False\n               ) -> dict:\n        \"\"\"\n        Provides for the setup, deployment, and initialization of ethereum smart contracts.\n        Emits the configured blockchain network transactions for single contract instance publication.\n        \"\"\"\n        if not self._upgradeable:\n            raise self.ContractNotUpgradeable(f\"{self.contract_name} is not upgradeable.\")\n        raise NotImplementedError\n\n    def get_principal_contract(self) -> VersionedContract:\n        \"\"\"\n        Get the on-chain targeted version of the principal contract directly without assembling it with its proxy.\n        \"\"\"\n        if not self._upgradeable:\n            raise self.ContractNotUpgradeable(f\"{self.contract_name} is not upgradeable.\")\n        principal_contract = self.blockchain.get_contract_by_name(contract_name=self.contract_name,\n                                                                  registry=self.registry,\n                                                                  proxy_name=self._proxy_deployer.contract_name,\n                                                                  use_proxy_address=False)\n        return principal_contract\n\n    def get_proxy_contract(self) -> VersionedContract:  # TODO: Method seems unused and untested\n        if not self._upgradeable:\n            raise self.ContractNotUpgradeable(f\"{self.contract_name} is not upgradeable.\")\n        principal_contract = self.get_principal_contract()\n        proxy_contract = self.blockchain.get_proxy_contract(registry=self.registry,\n                                                            target_address=principal_contract.address,\n                                                            proxy_name=self._proxy_deployer.contract_name)\n        return proxy_contract\n\n    def get_proxy_deployer(self) -> BaseContractDeployer:\n        principal_contract = self.get_principal_contract()\n        proxy_deployer = self._proxy_deployer(registry=self.registry,\n                                              target_contract=principal_contract,\n                                              bare=True)  # acquire access to the proxy itself.\n        return proxy_deployer\n\n    def retarget(self,\n                 transacting_power: TransactingPower,\n                 target_address: str,\n                 confirmations: int,\n                 gas_limit: int = None,\n                 just_build_transaction: bool = False):\n        \"\"\"\n        Directly engage a proxy contract for an existing deployment, executing the proxy's\n        upgrade interfaces to verify upgradeability and modify the on-chain contract target.\n        \"\"\"\n\n        if not self._upgradeable:\n            raise self.ContractNotUpgradeable(f\"{self.contract_name} is not upgradeable.\")\n\n        # 1 - Get Proxy Deployer\n        proxy_deployer = self.get_proxy_deployer()\n\n        # 2 - Retarget (or build retarget transaction)\n        if just_build_transaction:\n            transaction = proxy_deployer.build_retarget_transaction(sender_address=transacting_power.account,\n                                                                    new_target=target_address,\n                                                                    gas_limit=gas_limit)\n            return transaction\n        else:\n            receipt = proxy_deployer.retarget(transacting_power=transacting_power,\n                                              new_target=target_address,\n                                              gas_limit=gas_limit,\n                                              confirmations=confirmations)\n            return receipt\n\n    def upgrade(self,\n                transacting_power: TransactingPower,\n                confirmations: int,\n                gas_limit: int = None,\n                contract_version: str = \"latest\",\n                ignore_deployed: bool = False,\n                **overrides):\n        \"\"\"\n        Deploy a new version of a contract, then engage the proxy contract's upgrade interfaces.\n        \"\"\"\n\n        # 1 - Raise if not all-systems-go #\n        if not self._upgradeable:\n            raise self.ContractNotUpgradeable(f\"{self.contract_name} is not upgradeable.\")\n        self.check_deployment_readiness(deployer_address=transacting_power.account,\n                                        contract_version=contract_version,\n                                        ignore_deployed=ignore_deployed)\n\n        # 2 - Get Proxy Deployer\n        proxy_deployer = self.get_proxy_deployer()\n\n        # 3 - Deploy new version\n        new_contract, deploy_receipt = self._deploy_essential(transacting_power=transacting_power,\n                                                              contract_version=contract_version,\n                                                              gas_limit=gas_limit,\n                                                              confirmations=confirmations,\n                                                              **overrides)\n\n        # 4 - Wrap the escrow contract\n        wrapped_contract = self.blockchain._wrap_contract(wrapper_contract=proxy_deployer.contract,\n                                                          target_contract=new_contract)\n\n        # 5 - Set the new Dispatcher target\n        upgrade_receipt = proxy_deployer.retarget(transacting_power=transacting_power,\n                                                  new_target=new_contract.address,\n                                                  gas_limit=gas_limit,\n                                                  confirmations=confirmations)\n\n        # 6 - Respond\n        upgrade_transaction = {'deploy': deploy_receipt, 'retarget': upgrade_receipt}\n        self._contract = wrapped_contract  # Switch the contract for the wrapped one\n        return upgrade_transaction\n\n    def rollback(self, transacting_power:TransactingPower, gas_limit: int = None):\n        \"\"\"\n        Execute an existing deployment's proxy contract, engaging the upgrade rollback interfaces,\n        modifying the proxy's on-chain contract target to the most recent previous target.\n        \"\"\"\n\n        if not self._upgradeable:\n            raise self.ContractNotUpgradeable(f\"{self.contract_name} is not upgradeable.\")\n\n        proxy_deployer = self.get_proxy_deployer()\n        rollback_receipt = proxy_deployer.rollback(transacting_power=transacting_power, gas_limit=gas_limit)\n\n        return rollback_receipt\n\n    def _finish_bare_deployment(self, deployment_receipt: dict, progress=None) -> dict:\n        \"\"\"Used to divert flow control for bare contract deployments.\"\"\"\n        deployment_step_name = self.deployment_steps[0]\n        result = {deployment_step_name: deployment_receipt}\n        self.deployment_receipts.update(result)\n        if progress:\n            progress.update(len(self.deployment_steps))  # Update the progress bar to completion.\n        return result",
  "class NucypherTokenDeployer(BaseContractDeployer):\n\n    agency = NucypherTokenAgent\n    contract_name = agency.contract_name\n    deployment_steps = ('contract_deployment', )\n    _upgradeable = False\n    _ownable = False\n\n    TOTAL_SUPPLY = NU(1_000_000_000, 'NU').to_units()\n\n    def deploy(self,\n               transacting_power: TransactingPower,\n               gas_limit: int = None,\n               progress=None,\n               confirmations: int = 0,\n               deployment_mode=FULL,\n               ignore_deployed: bool = False,\n               emitter=None,\n               **overrides) -> dict:\n        \"\"\"\n        Deploy and publish the NuCypher Token contract\n        to the blockchain network specified in self.blockchain.network.\n\n        Deployment can only ever be executed exactly once!\n        \"\"\"\n        if deployment_mode != FULL:\n            raise self.ContractDeploymentError(f\"{self.contract_name} cannot be deployed in {deployment_mode} mode\")\n\n        self.check_deployment_readiness(deployer_address=transacting_power.account,\n                                        ignore_deployed=ignore_deployed)\n        \n        if emitter:\n            emitter.message(\"\\nNext Transaction: Token Contract Creation\", color='blue', bold=True)\n\n        # WARNING: Order-sensitive!\n        constructor_kwargs = {\"_totalSupplyOfTokens\": self.TOTAL_SUPPLY}\n        constructor_kwargs.update(overrides)\n        constructor_kwargs = {k: v for k, v in constructor_kwargs.items() if v is not None}\n        contract, deployment_receipt = self.blockchain.deploy_contract(transacting_power,\n                                                                       self.registry,\n                                                                       self.contract_name,\n                                                                       gas_limit=gas_limit,\n                                                                       confirmations=confirmations,\n                                                                       **constructor_kwargs)\n        if progress:\n            progress.update(1)\n        self._contract = contract\n        return {self.deployment_steps[0]: deployment_receipt}",
  "class ProxyContractDeployer(BaseContractDeployer):\n\n    contract_name = NotImplemented\n    deployment_steps = ('contract_deployment',)\n    _upgradeable = False\n\n    def __init__(self, target_contract: Contract, bare: bool = False, *args, **kwargs):\n        self.target_contract = target_contract\n        super().__init__(*args, **kwargs)\n        if bare:\n            self._contract = self.blockchain.get_proxy_contract(registry=self.registry,\n                                                                target_address=self.target_contract.address,\n                                                                proxy_name=self.contract_name)\n\n    def deploy(self,\n               transacting_power: TransactingPower,\n               gas_limit: int = None,\n               progress=None,\n               confirmations: int = 0\n               ) -> dict:\n        constructor_args = (self.target_contract.address,)\n        proxy_contract, receipt = self.blockchain.deploy_contract(transacting_power,\n                                                                  self.registry,\n                                                                  self.contract_name,\n                                                                  *constructor_args,\n                                                                  gas_limit=gas_limit,\n                                                                  confirmations=confirmations)\n        if progress:\n            progress.update(1)\n\n        self._contract = proxy_contract\n        receipts = {self.deployment_steps[0]: receipt}\n        self.deployment_receipts.update(receipts)\n        return receipts\n\n    def _validate_retarget(self, new_target: str):\n        if new_target == self.target_contract.address:\n            raise self.ContractDeploymentError(f\"{new_target} is already targeted by {self.contract_name}: {self._contract.address}\")\n        if new_target == self._contract.address:\n            raise self.ContractDeploymentError(f\"{self.contract_name} {self._contract.address} cannot target itself.\")\n\n    def retarget(self,\n                 transacting_power: TransactingPower,\n                 new_target: str,\n                 confirmations: int,\n                 gas_limit: int = None,\n                 ) -> dict:\n        self._validate_retarget(new_target)\n        upgrade_function = self._contract.functions.upgrade(new_target)\n        upgrade_receipt = self.blockchain.send_transaction(contract_function=upgrade_function,\n                                                           transacting_power=transacting_power,\n                                                           transaction_gas_limit=gas_limit,\n                                                           confirmations=confirmations)\n        return upgrade_receipt\n\n    def build_retarget_transaction(self, sender_address: ChecksumAddress, new_target: str, gas_limit: int = None) -> dict:\n        self._validate_retarget(new_target)\n        upgrade_function = self._contract.functions.upgrade(new_target)\n        unsigned_transaction = self.blockchain.build_contract_transaction(sender_address=sender_address,\n                                                                          contract_function=upgrade_function,\n                                                                          transaction_gas_limit=gas_limit)\n        return unsigned_transaction\n\n    def rollback(self,\n                 transacting_power: TransactingPower,\n                 gas_limit: int = None\n                 ) -> dict:\n        origin_args = {}  # TODO: Gas management - #842\n        if gas_limit:\n            origin_args.update({'gas': gas_limit})\n\n        rollback_function = self._contract.functions.rollback()\n        rollback_receipt = self.blockchain.send_transaction(contract_function=rollback_function,\n                                                            transacting_power=transacting_power,\n                                                            payload=origin_args)\n        return rollback_receipt",
  "class DispatcherDeployer(OwnableContractMixin, ProxyContractDeployer):\n    \"\"\"\n    Ethereum smart contract that acts as a proxy to another ethereum contract,\n    used as a means of \"dispatching\" the correct version of the contract to the client\n    \"\"\"\n\n    contract_name = DISPATCHER_CONTRACT_NAME",
  "class StakingEscrowDeployer(BaseContractDeployer, UpgradeableContractMixin, OwnableContractMixin):\n    \"\"\"\n    Deploys the StakingEscrow ethereum contract to the blockchain.  Depends on NucypherTokenAgent\n    \"\"\"\n\n    agency = NotImplemented  # StakingEscrowAgent was here\n    contract_name = 'StakingEscrow'\n    contract_name_stub = \"StakingEscrowStub\"\n\n    can_be_idle = True\n    init_steps = ('stub_deployment', 'dispatcher_deployment')\n    preparation_steps = ('contract_deployment', 'dispatcher_retarget')\n    deployment_steps = preparation_steps\n    _proxy_deployer = DispatcherDeployer\n\n    STUB_MIN_ALLOWED_TOKENS = NU(15_000, 'NU').to_units()\n    STUB_MAX_ALLOWED_TOKENS = NU(30_000_000, 'NU').to_units()\n\n    def __init__(self,\n                 staking_interface: ChecksumAddress = None,\n                 worklock_address: ChecksumAddress = None,\n                 *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.__dispatcher_contract = None\n\n        token_contract_name = NucypherTokenDeployer.contract_name\n        self.token_contract = self.blockchain.get_contract_by_name(registry=self.registry,\n                                                                   contract_name=token_contract_name)\n        self.threshold_staking_address = staking_interface\n        self.worklock_address = worklock_address\n\n    def _deploy_stub(self,\n                     transacting_power: TransactingPower,\n                     gas_limit: int = None,\n                     confirmations: int = 0,\n                     **overrides):\n        constructor_kwargs = {\n            \"_minAllowableLockedTokens\": self.STUB_MIN_ALLOWED_TOKENS,\n            \"_maxAllowableLockedTokens\": self.STUB_MAX_ALLOWED_TOKENS\n        }\n        constructor_kwargs.update(overrides)\n        constructor_kwargs = {k: v for k, v in constructor_kwargs.items() if v is not None}\n        # Force use of the token address from the registry\n        constructor_kwargs.update({\"_token\": self.token_contract.address})\n        the_escrow_contract, deploy_receipt = self.blockchain.deploy_contract(\n            transacting_power,\n            self.registry,\n            self.contract_name_stub,\n            gas_limit=gas_limit,\n            confirmations=confirmations,\n            **constructor_kwargs\n        )\n\n        return the_escrow_contract, deploy_receipt\n\n    def _deploy_essential(self,\n                          transacting_power: TransactingPower,\n                          contract_version: str,\n                          gas_limit: int = None,\n                          confirmations: int = 0,\n                          **overrides):\n        constructor_kwargs = {}\n        constructor_kwargs.update({\"_token\": self.token_contract.address,\n                                   \"_workLock\": self.worklock_address if self.worklock_address is not None else NULL_ADDRESS,\n                                   \"_tStaking\": self.threshold_staking_address})\n        constructor_kwargs.update(overrides)\n        constructor_kwargs = {k: v for k, v in constructor_kwargs.items() if v is not None}\n        the_escrow_contract, deploy_receipt = self.blockchain.deploy_contract(\n            transacting_power,\n            self.registry,\n            self.contract_name,\n            gas_limit=gas_limit,\n            contract_version=contract_version,\n            confirmations=confirmations,\n            **constructor_kwargs\n        )\n\n        return the_escrow_contract, deploy_receipt\n\n    def deploy(self,\n               transacting_power: TransactingPower,\n               deployment_mode=INIT,\n               gas_limit: int = None,\n               progress=None,\n               contract_version: str = \"latest\",\n               ignore_deployed: bool = False,\n               confirmations: int = 0,\n               emitter=None,\n               **overrides\n               ) -> dict:\n        \"\"\"\n        Deploy and publish the StakingEscrow contract\n        to the blockchain network specified in self.blockchain.network.\n\n        Emits the following blockchain network transactions:\n            - StakingEscrow contract deployment\n            - StakingEscrow dispatcher deployment\n            - Transfer reward tokens origin to StakingEscrow contract\n            - StakingEscrow contract initialization\n\n        Returns transaction receipts in a dict.\n        \"\"\"\n\n        if deployment_mode not in (BARE, INIT, FULL):\n            raise ValueError(f\"Invalid deployment mode ({deployment_mode})\")\n\n        # Raise if not all-systems-go\n        self.check_deployment_readiness(deployer_address=transacting_power.account,\n                                        contract_version=contract_version,\n                                        ignore_deployed=ignore_deployed)\n\n        # Build deployment arguments\n        origin_args = {}\n        if gas_limit:\n            origin_args.update({'gas': gas_limit})  # TODO: Gas Management - #842\n\n        if emitter:\n            contract_name = self.contract_name_stub if deployment_mode is INIT else self.contract_name\n            emitter.message(f\"\\nNext Transaction: {contract_name} Contract Creation\", color='blue', bold=True)\n\n        if deployment_mode is INIT:\n            # 1 - Deploy Stub\n            the_escrow_contract, deploy_receipt = self._deploy_stub(transacting_power=transacting_power,\n                                                                    gas_limit=gas_limit,\n                                                                    confirmations=confirmations,\n                                                                    **overrides)\n        else:\n            # 1 - Deploy StakingEscrow\n            the_escrow_contract, deploy_receipt = self._deploy_essential(transacting_power=transacting_power,\n                                                                         contract_version=contract_version,\n                                                                         gas_limit=gas_limit,\n                                                                         confirmations=confirmations,\n                                                                         **overrides)\n\n            # This is the end of bare deployment.\n            if deployment_mode is BARE:\n                self._contract = the_escrow_contract\n                receipts = self._finish_bare_deployment(deployment_receipt=deploy_receipt, progress=progress)\n                return receipts\n\n        if progress:\n            progress.update(1)\n\n        if emitter:\n            emitter.message(f\"\\nNext Transaction: {DispatcherDeployer.contract_name} \"\n                            f\"Contract {'Creation' if deployment_mode is INIT else 'Upgrade'} for {self.contract_name}\",\n                            color='blue', bold=True)\n\n        if deployment_mode is INIT:\n            # 2 - Deploy the dispatcher used for updating this contract #\n            dispatcher_deployer = DispatcherDeployer(registry=self.registry, target_contract=the_escrow_contract)\n\n            dispatcher_receipts = dispatcher_deployer.deploy(transacting_power=transacting_power,\n                                                             gas_limit=gas_limit,\n                                                             confirmations=confirmations)\n            dispatcher_deploy_receipt = dispatcher_receipts[dispatcher_deployer.deployment_steps[0]]\n        else:\n            # 2 - Upgrade dispatcher to the real contract\n            the_stub_contract = self.blockchain.get_contract_by_name(registry=self.registry,\n                                                                     contract_name=self.contract_name_stub)\n            dispatcher_deployer = DispatcherDeployer(registry=self.registry,\n                                                     target_contract=the_stub_contract,\n                                                     bare=True)\n\n            dispatcher_retarget_receipt = dispatcher_deployer.retarget(transacting_power=transacting_power,\n                                                                       new_target=the_escrow_contract.address,\n                                                                       gas_limit=gas_limit,\n                                                                       confirmations=confirmations)\n\n        if progress:\n            progress.update(1)\n\n        # Cache the dispatcher contract\n        dispatcher_contract = dispatcher_deployer.contract\n        self.__dispatcher_contract = dispatcher_contract\n\n        # Wrap the escrow contract\n        wrapped_escrow_contract = self.blockchain._wrap_contract(dispatcher_contract,\n                                                                 target_contract=the_escrow_contract)\n\n        # Switch the contract for the wrapped one\n        self._contract = wrapped_escrow_contract\n\n        if deployment_mode is INIT:\n            preparation_receipts = dict(zip(self.init_steps, (deploy_receipt, dispatcher_deploy_receipt)))\n        else:\n            preparation_receipts = dict(zip(self.preparation_steps, (deploy_receipt, dispatcher_retarget_receipt)))\n        self.deployment_receipts = preparation_receipts\n\n        return preparation_receipts",
  "class SubscriptionManagerDeployer(BaseContractDeployer, OwnableContractMixin):\n\n    agency = SubscriptionManagerAgent\n    contract_name = agency.contract_name\n    deployment_steps = ('contract_deployment', 'initialize')\n    _upgradeable = False\n    _ownable = True\n\n    def deploy(self,\n               transacting_power: TransactingPower,\n               gas_limit: int = None,\n               progress=None,\n               confirmations: int = 0,\n               emitter=None,\n               ignore_deployed: bool = False,\n               deployment_mode=FULL,\n               **overrides) -> dict:\n\n        constructor_kwargs = {}  # placeholder for constructor kwargs\n        constructor_kwargs.update(overrides)\n        constructor_kwargs = {k: v for k, v in constructor_kwargs.items() if v is not None}\n        contract, deployment_receipt = self.blockchain.deploy_contract(transacting_power,\n                                                                       self.registry,\n                                                                       self.contract_name,\n                                                                       gas_limit=gas_limit,\n                                                                       confirmations=confirmations,\n                                                                       **constructor_kwargs)\n\n        self._contract = contract\n\n        tx_args = {}\n        if gas_limit:\n            tx_args.update({'gas': gas_limit})  # TODO: Gas management - 842\n        initialize_function = contract.functions.initialize(self.economics.fee_rate)\n        initialize_receipt = self.blockchain.send_transaction(contract_function=initialize_function,\n                                                              transacting_power=transacting_power,\n                                                              payload=tx_args,\n                                                              confirmations=confirmations)\n        return {self.deployment_steps[0]: deployment_receipt,\n                self.deployment_steps[1]: initialize_receipt}",
  "class AdjudicatorDeployer(BaseContractDeployer, UpgradeableContractMixin, OwnableContractMixin):\n\n    agency = AdjudicatorAgent\n    contract_name = agency.contract_name\n    deployment_steps = ('contract_deployment', 'dispatcher_deployment')\n    _proxy_deployer = DispatcherDeployer\n\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        staking_contract_name = StakingEscrowDeployer.contract_name\n        proxy_name = StakingEscrowDeployer._proxy_deployer.contract_name\n        try:\n            self.staking_contract = self.blockchain.get_contract_by_name(registry=self.registry,\n                                                                         contract_name=staking_contract_name,\n                                                                         proxy_name=proxy_name)\n        except self.registry.UnknownContract:\n            staking_contract_name = StakingEscrowDeployer.contract_name_stub\n            self.staking_contract = self.blockchain.get_contract_by_name(registry=self.registry,\n                                                                         contract_name=staking_contract_name,\n                                                                         proxy_name=proxy_name)\n\n    def check_deployment_readiness(self, deployer_address: ChecksumAddress, *args, **kwargs) -> Tuple[bool, list]:\n        staking_escrow_owner = self.staking_contract.functions.owner().call()\n        adjudicator_deployment_rules = [\n            (deployer_address == staking_escrow_owner,\n             f'{self.contract_name} must be deployed by the owner of {STAKING_ESCROW_CONTRACT_NAME} ({staking_escrow_owner})')\n        ]\n        return super().check_deployment_readiness(deployer_address=deployer_address,\n                                                  additional_rules=adjudicator_deployment_rules,\n                                                  *args, **kwargs)\n\n    def _deploy_essential(self,\n                          transacting_power: TransactingPower,\n                          contract_version: str,\n                          gas_limit: int = None,\n                          confirmations: int = 0,\n                          **overrides):\n        args = self.economics.slashing_deployment_parameters\n        constructor_kwargs = {\n            \"_hashAlgorithm\": args[0],\n            \"_basePenalty\": args[1],\n            \"_penaltyHistoryCoefficient\": args[2],\n            \"_percentagePenaltyCoefficient\": args[3],\n            \"_rewardCoefficient\": args[4]\n        }\n        constructor_kwargs.update(overrides)\n        constructor_kwargs = {k: v for k, v in constructor_kwargs.items() if v is not None}\n        # Force use of the escrow address from the registry\n        constructor_kwargs.update({\"_escrow\": self.staking_contract.address})\n        adjudicator_contract, deploy_receipt = self.blockchain.deploy_contract(transacting_power,\n                                                                               self.registry,\n                                                                               self.contract_name,\n                                                                               gas_limit=gas_limit,\n                                                                               confirmations=confirmations,\n                                                                               contract_version=contract_version,\n                                                                               **constructor_kwargs)\n        return adjudicator_contract, deploy_receipt\n\n    def deploy(self,\n               transacting_power: TransactingPower,\n               deployment_mode=FULL,\n               gas_limit: int = None,\n               progress=None,\n               contract_version: str = \"latest\",\n               ignore_deployed: bool = False,\n               emitter=None,\n               confirmations: int = 0,\n               **overrides) -> Dict[str, str]:\n\n        if deployment_mode not in (BARE, IDLE, FULL):\n            raise ValueError(f\"Invalid deployment mode ({deployment_mode})\")\n\n        self.check_deployment_readiness(deployer_address=transacting_power.account,\n                                        contract_version=contract_version,\n                                        ignore_deployed=ignore_deployed)\n\n        # 1 - Deploy Contract\n        if emitter:\n            emitter.message(f\"\\nNext Transaction: {self.contract_name} Contract Creation\", color='blue', bold=True)\n        adjudicator_contract, deploy_receipt = self._deploy_essential(transacting_power=transacting_power,\n                                                                      contract_version=contract_version,\n                                                                      gas_limit=gas_limit,\n                                                                      confirmations=confirmations,\n                                                                      **overrides)\n\n        # This is the end of bare deployment.\n        if deployment_mode is BARE:\n            self._contract = adjudicator_contract\n            return self._finish_bare_deployment(deployment_receipt=deploy_receipt,\n                                                progress=progress)\n\n        if progress:\n            progress.update(1)\n\n        # 2 - Deploy Proxy\n        if emitter:\n            emitter.message(f\"\\nNext Transaction: {self._proxy_deployer.contract_name} Contract Creation for {self.contract_name}\", color='blue', bold=True)\n        proxy_deployer = self._proxy_deployer(registry=self.registry, target_contract=adjudicator_contract)\n\n        proxy_deploy_receipts = proxy_deployer.deploy(transacting_power=transacting_power,\n                                                      gas_limit=gas_limit, \n                                                      confirmations=confirmations)\n        proxy_deploy_receipt = proxy_deploy_receipts[proxy_deployer.deployment_steps[0]]\n        if progress:\n            progress.update(1)\n\n        # Cache the dispatcher contract\n        proxy_contract = proxy_deployer.contract\n        self.__proxy_contract = proxy_contract\n\n        # Wrap the escrow contract\n        wrapped = self.blockchain._wrap_contract(proxy_contract, target_contract=adjudicator_contract)\n\n        # Switch the contract for the wrapped one\n        adjudicator_contract = wrapped\n\n        # Gather the transaction receipts\n        ordered_receipts = (deploy_receipt, proxy_deploy_receipt)\n        deployment_receipts = dict(zip(self.deployment_steps, ordered_receipts))\n\n        self.deployment_receipts = deployment_receipts\n        self._contract = adjudicator_contract\n\n        return deployment_receipts",
  "class PREApplicationDeployer(BaseContractDeployer):\n\n    agency = PREApplicationAgent\n    contract_name = agency.contract_name\n    deployment_steps = ('contract_deployment', )\n    _upgradeable = False\n\n    def __init__(self, staking_interface: ChecksumAddress = None, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.threshold_staking_interface = staking_interface\n\n    def _deploy_essential(self,\n                          transacting_power: TransactingPower,\n                          gas_limit: int = None,\n                          confirmations: int = 0,\n                          **overrides):\n        constructor_kwargs = {}\n        constructor_kwargs.update({\"_minAuthorization\": self.economics.min_authorization,\n                                   \"_minOperatorSeconds\": self.economics.min_operator_seconds,\n                                   \"_tStaking\": self.threshold_staking_interface})\n        constructor_kwargs.update(overrides)\n        constructor_kwargs = {k: v for k, v in constructor_kwargs.items() if v is not None}\n        the_escrow_contract, deploy_receipt = self.blockchain.deploy_contract(\n            transacting_power,\n            self.registry,\n            self.contract_name,\n            gas_limit=gas_limit,\n            confirmations=confirmations,\n            **constructor_kwargs\n        )\n\n        return the_escrow_contract, deploy_receipt\n\n    def deploy(self,\n               transacting_power: TransactingPower,\n               gas_limit: int = None,\n               confirmations: int = 0,\n               deployment_mode=FULL,\n               ignore_deployed: bool = False,\n               progress=None,\n               emitter=None,\n               **overrides):\n\n        if deployment_mode != FULL:\n            raise self.ContractDeploymentError(f\"{self.contract_name} cannot be deployed in {deployment_mode} mode\")\n\n        self.check_deployment_readiness(deployer_address=transacting_power.account,\n                                        ignore_deployed=ignore_deployed)\n\n        contract, receipt = self._deploy_essential(transacting_power=transacting_power,\n                                                   gas_limit=gas_limit,\n                                                   confirmations=confirmations,\n                                                   **overrides)\n\n        # Update the progress bar\n        if progress:\n            progress.update(1)\n\n        self._contract = contract\n        self.deployment_receipts = dict(zip(self.deployment_steps, (receipt, )))\n        return self.deployment_receipts",
  "class ContractDeploymentError(Exception):\n        pass",
  "class ContractNotDeployed(ContractDeploymentError):\n        pass",
  "def __init__(self, registry: BaseContractRegistry, economics: Economics = None):\n\n        # Validate\n        self.blockchain = BlockchainInterfaceFactory.get_interface()\n        if not isinstance(self.blockchain, BlockchainDeployerInterface):\n            raise ValueError(\"No deployer interface connection available.\")\n\n        # Defaults\n        self.registry = registry\n        self.deployment_receipts = OrderedDict()\n        self._contract = CONTRACT_NOT_DEPLOYED\n        self.__proxy_contract = NotImplemented\n        self.__economics = economics or Economics()",
  "def economics(self) -> Economics:\n        \"\"\"Read-only access for economics instance.\"\"\"\n        return self.__economics",
  "def contract_address(self) -> str:\n        if self._contract is CONTRACT_NOT_DEPLOYED:\n            raise self.ContractNotDeployed(self.contract_name)\n        address = self._contract.address  # type: str\n        return address",
  "def contract(self):\n        return self._contract",
  "def dispatcher(self):\n        return self.__proxy_contract",
  "def is_deployed(self, contract_version: str = None) -> bool:\n        try:\n            self.registry.search(contract_name=self.contract_name, contract_version=contract_version)\n        except (BaseContractRegistry.UnknownContract, BaseContractRegistry.NoRegistry):\n            return False\n        else:\n            return True",
  "def check_deployment_readiness(self,\n                                   deployer_address: ChecksumAddress,\n                                   contract_version: str = None,\n                                   ignore_deployed=False,\n                                   fail=True,\n                                   additional_rules: List[Tuple[bool, str]] = None,\n                                   ) -> Tuple[bool, list]:\n        \"\"\"\n        Iterates through a set of rules required for an ethereum\n        contract deployer to be eligible for deployment returning a\n        tuple or raising an exception if <fail> is True.\n\n        Returns a tuple containing the boolean readiness result and a list of reasons (if any)\n        why the deployer is not ready.\n\n        If fail is set to True, raise a configuration error, instead of returning.\n        \"\"\"\n\n        if not ignore_deployed and contract_version is not None:\n            contract_version, _data = self.blockchain.find_raw_contract_data(contract_name=self.contract_name,\n                                                                             requested_version=contract_version)\n\n        # Compile rules\n        rules = [\n            (ignore_deployed or not self.is_deployed(contract_version),\n             f'Contract {self.contract_name}:{contract_version} already deployed'),\n        ]\n        if additional_rules:\n            rules.extend(additional_rules)\n\n        disqualifications = list()\n        for rule_is_satisfied, failure_reason in rules:\n            if not rule_is_satisfied:                      # If this rule fails...\n                if fail:\n                    raise self.ContractDeploymentError(failure_reason)\n                disqualifications.append(failure_reason)   # ... here's why\n\n        is_ready = len(disqualifications) == 0\n        return is_ready, disqualifications",
  "def deploy(self,\n               transacting_power: TransactingPower,\n               deployment_mode=FULL,\n               gas_limit: int = None,\n               progress: int = None,\n               emitter=None,\n               **overrides) -> dict:\n        \"\"\"\n        Provides for the setup, deployment, and initialization of ethereum smart contracts.\n        Emits the configured blockchain network transactions for single contract instance publication.\n        \"\"\"\n        raise NotImplementedError",
  "def make_agent(self) -> EthereumContractAgent:\n        agent = self.agency(registry=self.registry, contract=self._contract)\n        return agent",
  "def get_latest_enrollment(self) -> VersionedContract:\n        \"\"\"Get the latest enrolled, bare version of the contract from the registry.\"\"\"\n        contract = self.blockchain.get_contract_by_name(contract_name=self.contract_name,\n                                                        registry=self.registry,\n                                                        use_proxy_address=False,\n                                                        enrollment_version='latest')\n        return contract",
  "def _get_deployed_contract(self):\n        if self.contract is None or self.contract is CONTRACT_NOT_DEPLOYED:\n            proxy_name = None\n            if self._proxy_deployer is not NotImplemented:\n                proxy_name = self._proxy_deployer.contract_name\n            deployed_contract = self.blockchain.get_contract_by_name(contract_name=self.contract_name,\n                                                                     registry=self.registry,\n                                                                     proxy_name=proxy_name)\n        else:\n            deployed_contract = self.contract\n        return deployed_contract",
  "class ContractNotOwnable(RuntimeError):\n        pass",
  "def owner(self) -> ChecksumAddress:\n        if self._upgradeable:\n            # Get the address of the proxy\n            contract = self.get_proxy_deployer()\n        else:\n            # Get the address of the implementation\n            contract = self.blockchain.get_contract_by_name(contract_name=self.contract_name, registry=self.registry)\n        owner_address = ChecksumAddress(contract.contract.functions.owner().call())  # blockchain read\n        return owner_address",
  "def transfer_ownership(self,\n                           transacting_power: TransactingPower,\n                           new_owner: str,\n                           transaction_gas_limit: int = None\n                           ) -> dict:\n        if not self._ownable:\n            raise self.ContractNotOwnable(f\"{self.contract_name} is not ownable.\")\n\n        if self._upgradeable:\n\n            #\n            # Upgrade Proxy\n            #\n            proxy_deployer = self.get_proxy_deployer()\n            proxy_contract_function = proxy_deployer.contract.functions.transferOwnership(new_owner)\n            receipt = self.blockchain.send_transaction(transacting_power=transacting_power,\n                                                       contract_function=proxy_contract_function,\n                                                       transaction_gas_limit=transaction_gas_limit)\n        else:\n            existing_bare_contract = self.blockchain.get_contract_by_name(contract_name=self.contract_name,\n                                                                          registry=self.registry)\n\n            #\n            # Upgrade Principal\n            #\n\n            contract_function = existing_bare_contract.functions.transferOwnership(new_owner)\n            receipt = self.blockchain.send_transaction(transacting_power=transacting_power,\n                                                       contract_function=contract_function,\n                                                       transaction_gas_limit=transaction_gas_limit)\n        return receipt",
  "class ContractNotUpgradeable(RuntimeError):\n        pass",
  "def deploy(self,\n               deployment_mode=FULL,\n               gas_limit: int = None,\n               progress=None,\n               contract_version: str = \"latest\",\n               ignore_deployed: bool = False\n               ) -> dict:\n        \"\"\"\n        Provides for the setup, deployment, and initialization of ethereum smart contracts.\n        Emits the configured blockchain network transactions for single contract instance publication.\n        \"\"\"\n        if not self._upgradeable:\n            raise self.ContractNotUpgradeable(f\"{self.contract_name} is not upgradeable.\")\n        raise NotImplementedError",
  "def get_principal_contract(self) -> VersionedContract:\n        \"\"\"\n        Get the on-chain targeted version of the principal contract directly without assembling it with its proxy.\n        \"\"\"\n        if not self._upgradeable:\n            raise self.ContractNotUpgradeable(f\"{self.contract_name} is not upgradeable.\")\n        principal_contract = self.blockchain.get_contract_by_name(contract_name=self.contract_name,\n                                                                  registry=self.registry,\n                                                                  proxy_name=self._proxy_deployer.contract_name,\n                                                                  use_proxy_address=False)\n        return principal_contract",
  "def get_proxy_contract(self) -> VersionedContract:  # TODO: Method seems unused and untested\n        if not self._upgradeable:\n            raise self.ContractNotUpgradeable(f\"{self.contract_name} is not upgradeable.\")\n        principal_contract = self.get_principal_contract()\n        proxy_contract = self.blockchain.get_proxy_contract(registry=self.registry,\n                                                            target_address=principal_contract.address,\n                                                            proxy_name=self._proxy_deployer.contract_name)\n        return proxy_contract",
  "def get_proxy_deployer(self) -> BaseContractDeployer:\n        principal_contract = self.get_principal_contract()\n        proxy_deployer = self._proxy_deployer(registry=self.registry,\n                                              target_contract=principal_contract,\n                                              bare=True)  # acquire access to the proxy itself.\n        return proxy_deployer",
  "def retarget(self,\n                 transacting_power: TransactingPower,\n                 target_address: str,\n                 confirmations: int,\n                 gas_limit: int = None,\n                 just_build_transaction: bool = False):\n        \"\"\"\n        Directly engage a proxy contract for an existing deployment, executing the proxy's\n        upgrade interfaces to verify upgradeability and modify the on-chain contract target.\n        \"\"\"\n\n        if not self._upgradeable:\n            raise self.ContractNotUpgradeable(f\"{self.contract_name} is not upgradeable.\")\n\n        # 1 - Get Proxy Deployer\n        proxy_deployer = self.get_proxy_deployer()\n\n        # 2 - Retarget (or build retarget transaction)\n        if just_build_transaction:\n            transaction = proxy_deployer.build_retarget_transaction(sender_address=transacting_power.account,\n                                                                    new_target=target_address,\n                                                                    gas_limit=gas_limit)\n            return transaction\n        else:\n            receipt = proxy_deployer.retarget(transacting_power=transacting_power,\n                                              new_target=target_address,\n                                              gas_limit=gas_limit,\n                                              confirmations=confirmations)\n            return receipt",
  "def upgrade(self,\n                transacting_power: TransactingPower,\n                confirmations: int,\n                gas_limit: int = None,\n                contract_version: str = \"latest\",\n                ignore_deployed: bool = False,\n                **overrides):\n        \"\"\"\n        Deploy a new version of a contract, then engage the proxy contract's upgrade interfaces.\n        \"\"\"\n\n        # 1 - Raise if not all-systems-go #\n        if not self._upgradeable:\n            raise self.ContractNotUpgradeable(f\"{self.contract_name} is not upgradeable.\")\n        self.check_deployment_readiness(deployer_address=transacting_power.account,\n                                        contract_version=contract_version,\n                                        ignore_deployed=ignore_deployed)\n\n        # 2 - Get Proxy Deployer\n        proxy_deployer = self.get_proxy_deployer()\n\n        # 3 - Deploy new version\n        new_contract, deploy_receipt = self._deploy_essential(transacting_power=transacting_power,\n                                                              contract_version=contract_version,\n                                                              gas_limit=gas_limit,\n                                                              confirmations=confirmations,\n                                                              **overrides)\n\n        # 4 - Wrap the escrow contract\n        wrapped_contract = self.blockchain._wrap_contract(wrapper_contract=proxy_deployer.contract,\n                                                          target_contract=new_contract)\n\n        # 5 - Set the new Dispatcher target\n        upgrade_receipt = proxy_deployer.retarget(transacting_power=transacting_power,\n                                                  new_target=new_contract.address,\n                                                  gas_limit=gas_limit,\n                                                  confirmations=confirmations)\n\n        # 6 - Respond\n        upgrade_transaction = {'deploy': deploy_receipt, 'retarget': upgrade_receipt}\n        self._contract = wrapped_contract  # Switch the contract for the wrapped one\n        return upgrade_transaction",
  "def rollback(self, transacting_power:TransactingPower, gas_limit: int = None):\n        \"\"\"\n        Execute an existing deployment's proxy contract, engaging the upgrade rollback interfaces,\n        modifying the proxy's on-chain contract target to the most recent previous target.\n        \"\"\"\n\n        if not self._upgradeable:\n            raise self.ContractNotUpgradeable(f\"{self.contract_name} is not upgradeable.\")\n\n        proxy_deployer = self.get_proxy_deployer()\n        rollback_receipt = proxy_deployer.rollback(transacting_power=transacting_power, gas_limit=gas_limit)\n\n        return rollback_receipt",
  "def _finish_bare_deployment(self, deployment_receipt: dict, progress=None) -> dict:\n        \"\"\"Used to divert flow control for bare contract deployments.\"\"\"\n        deployment_step_name = self.deployment_steps[0]\n        result = {deployment_step_name: deployment_receipt}\n        self.deployment_receipts.update(result)\n        if progress:\n            progress.update(len(self.deployment_steps))  # Update the progress bar to completion.\n        return result",
  "def deploy(self,\n               transacting_power: TransactingPower,\n               gas_limit: int = None,\n               progress=None,\n               confirmations: int = 0,\n               deployment_mode=FULL,\n               ignore_deployed: bool = False,\n               emitter=None,\n               **overrides) -> dict:\n        \"\"\"\n        Deploy and publish the NuCypher Token contract\n        to the blockchain network specified in self.blockchain.network.\n\n        Deployment can only ever be executed exactly once!\n        \"\"\"\n        if deployment_mode != FULL:\n            raise self.ContractDeploymentError(f\"{self.contract_name} cannot be deployed in {deployment_mode} mode\")\n\n        self.check_deployment_readiness(deployer_address=transacting_power.account,\n                                        ignore_deployed=ignore_deployed)\n        \n        if emitter:\n            emitter.message(\"\\nNext Transaction: Token Contract Creation\", color='blue', bold=True)\n\n        # WARNING: Order-sensitive!\n        constructor_kwargs = {\"_totalSupplyOfTokens\": self.TOTAL_SUPPLY}\n        constructor_kwargs.update(overrides)\n        constructor_kwargs = {k: v for k, v in constructor_kwargs.items() if v is not None}\n        contract, deployment_receipt = self.blockchain.deploy_contract(transacting_power,\n                                                                       self.registry,\n                                                                       self.contract_name,\n                                                                       gas_limit=gas_limit,\n                                                                       confirmations=confirmations,\n                                                                       **constructor_kwargs)\n        if progress:\n            progress.update(1)\n        self._contract = contract\n        return {self.deployment_steps[0]: deployment_receipt}",
  "def __init__(self, target_contract: Contract, bare: bool = False, *args, **kwargs):\n        self.target_contract = target_contract\n        super().__init__(*args, **kwargs)\n        if bare:\n            self._contract = self.blockchain.get_proxy_contract(registry=self.registry,\n                                                                target_address=self.target_contract.address,\n                                                                proxy_name=self.contract_name)",
  "def deploy(self,\n               transacting_power: TransactingPower,\n               gas_limit: int = None,\n               progress=None,\n               confirmations: int = 0\n               ) -> dict:\n        constructor_args = (self.target_contract.address,)\n        proxy_contract, receipt = self.blockchain.deploy_contract(transacting_power,\n                                                                  self.registry,\n                                                                  self.contract_name,\n                                                                  *constructor_args,\n                                                                  gas_limit=gas_limit,\n                                                                  confirmations=confirmations)\n        if progress:\n            progress.update(1)\n\n        self._contract = proxy_contract\n        receipts = {self.deployment_steps[0]: receipt}\n        self.deployment_receipts.update(receipts)\n        return receipts",
  "def _validate_retarget(self, new_target: str):\n        if new_target == self.target_contract.address:\n            raise self.ContractDeploymentError(f\"{new_target} is already targeted by {self.contract_name}: {self._contract.address}\")\n        if new_target == self._contract.address:\n            raise self.ContractDeploymentError(f\"{self.contract_name} {self._contract.address} cannot target itself.\")",
  "def retarget(self,\n                 transacting_power: TransactingPower,\n                 new_target: str,\n                 confirmations: int,\n                 gas_limit: int = None,\n                 ) -> dict:\n        self._validate_retarget(new_target)\n        upgrade_function = self._contract.functions.upgrade(new_target)\n        upgrade_receipt = self.blockchain.send_transaction(contract_function=upgrade_function,\n                                                           transacting_power=transacting_power,\n                                                           transaction_gas_limit=gas_limit,\n                                                           confirmations=confirmations)\n        return upgrade_receipt",
  "def build_retarget_transaction(self, sender_address: ChecksumAddress, new_target: str, gas_limit: int = None) -> dict:\n        self._validate_retarget(new_target)\n        upgrade_function = self._contract.functions.upgrade(new_target)\n        unsigned_transaction = self.blockchain.build_contract_transaction(sender_address=sender_address,\n                                                                          contract_function=upgrade_function,\n                                                                          transaction_gas_limit=gas_limit)\n        return unsigned_transaction",
  "def rollback(self,\n                 transacting_power: TransactingPower,\n                 gas_limit: int = None\n                 ) -> dict:\n        origin_args = {}  # TODO: Gas management - #842\n        if gas_limit:\n            origin_args.update({'gas': gas_limit})\n\n        rollback_function = self._contract.functions.rollback()\n        rollback_receipt = self.blockchain.send_transaction(contract_function=rollback_function,\n                                                            transacting_power=transacting_power,\n                                                            payload=origin_args)\n        return rollback_receipt",
  "def __init__(self,\n                 staking_interface: ChecksumAddress = None,\n                 worklock_address: ChecksumAddress = None,\n                 *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.__dispatcher_contract = None\n\n        token_contract_name = NucypherTokenDeployer.contract_name\n        self.token_contract = self.blockchain.get_contract_by_name(registry=self.registry,\n                                                                   contract_name=token_contract_name)\n        self.threshold_staking_address = staking_interface\n        self.worklock_address = worklock_address",
  "def _deploy_stub(self,\n                     transacting_power: TransactingPower,\n                     gas_limit: int = None,\n                     confirmations: int = 0,\n                     **overrides):\n        constructor_kwargs = {\n            \"_minAllowableLockedTokens\": self.STUB_MIN_ALLOWED_TOKENS,\n            \"_maxAllowableLockedTokens\": self.STUB_MAX_ALLOWED_TOKENS\n        }\n        constructor_kwargs.update(overrides)\n        constructor_kwargs = {k: v for k, v in constructor_kwargs.items() if v is not None}\n        # Force use of the token address from the registry\n        constructor_kwargs.update({\"_token\": self.token_contract.address})\n        the_escrow_contract, deploy_receipt = self.blockchain.deploy_contract(\n            transacting_power,\n            self.registry,\n            self.contract_name_stub,\n            gas_limit=gas_limit,\n            confirmations=confirmations,\n            **constructor_kwargs\n        )\n\n        return the_escrow_contract, deploy_receipt",
  "def _deploy_essential(self,\n                          transacting_power: TransactingPower,\n                          contract_version: str,\n                          gas_limit: int = None,\n                          confirmations: int = 0,\n                          **overrides):\n        constructor_kwargs = {}\n        constructor_kwargs.update({\"_token\": self.token_contract.address,\n                                   \"_workLock\": self.worklock_address if self.worklock_address is not None else NULL_ADDRESS,\n                                   \"_tStaking\": self.threshold_staking_address})\n        constructor_kwargs.update(overrides)\n        constructor_kwargs = {k: v for k, v in constructor_kwargs.items() if v is not None}\n        the_escrow_contract, deploy_receipt = self.blockchain.deploy_contract(\n            transacting_power,\n            self.registry,\n            self.contract_name,\n            gas_limit=gas_limit,\n            contract_version=contract_version,\n            confirmations=confirmations,\n            **constructor_kwargs\n        )\n\n        return the_escrow_contract, deploy_receipt",
  "def deploy(self,\n               transacting_power: TransactingPower,\n               deployment_mode=INIT,\n               gas_limit: int = None,\n               progress=None,\n               contract_version: str = \"latest\",\n               ignore_deployed: bool = False,\n               confirmations: int = 0,\n               emitter=None,\n               **overrides\n               ) -> dict:\n        \"\"\"\n        Deploy and publish the StakingEscrow contract\n        to the blockchain network specified in self.blockchain.network.\n\n        Emits the following blockchain network transactions:\n            - StakingEscrow contract deployment\n            - StakingEscrow dispatcher deployment\n            - Transfer reward tokens origin to StakingEscrow contract\n            - StakingEscrow contract initialization\n\n        Returns transaction receipts in a dict.\n        \"\"\"\n\n        if deployment_mode not in (BARE, INIT, FULL):\n            raise ValueError(f\"Invalid deployment mode ({deployment_mode})\")\n\n        # Raise if not all-systems-go\n        self.check_deployment_readiness(deployer_address=transacting_power.account,\n                                        contract_version=contract_version,\n                                        ignore_deployed=ignore_deployed)\n\n        # Build deployment arguments\n        origin_args = {}\n        if gas_limit:\n            origin_args.update({'gas': gas_limit})  # TODO: Gas Management - #842\n\n        if emitter:\n            contract_name = self.contract_name_stub if deployment_mode is INIT else self.contract_name\n            emitter.message(f\"\\nNext Transaction: {contract_name} Contract Creation\", color='blue', bold=True)\n\n        if deployment_mode is INIT:\n            # 1 - Deploy Stub\n            the_escrow_contract, deploy_receipt = self._deploy_stub(transacting_power=transacting_power,\n                                                                    gas_limit=gas_limit,\n                                                                    confirmations=confirmations,\n                                                                    **overrides)\n        else:\n            # 1 - Deploy StakingEscrow\n            the_escrow_contract, deploy_receipt = self._deploy_essential(transacting_power=transacting_power,\n                                                                         contract_version=contract_version,\n                                                                         gas_limit=gas_limit,\n                                                                         confirmations=confirmations,\n                                                                         **overrides)\n\n            # This is the end of bare deployment.\n            if deployment_mode is BARE:\n                self._contract = the_escrow_contract\n                receipts = self._finish_bare_deployment(deployment_receipt=deploy_receipt, progress=progress)\n                return receipts\n\n        if progress:\n            progress.update(1)\n\n        if emitter:\n            emitter.message(f\"\\nNext Transaction: {DispatcherDeployer.contract_name} \"\n                            f\"Contract {'Creation' if deployment_mode is INIT else 'Upgrade'} for {self.contract_name}\",\n                            color='blue', bold=True)\n\n        if deployment_mode is INIT:\n            # 2 - Deploy the dispatcher used for updating this contract #\n            dispatcher_deployer = DispatcherDeployer(registry=self.registry, target_contract=the_escrow_contract)\n\n            dispatcher_receipts = dispatcher_deployer.deploy(transacting_power=transacting_power,\n                                                             gas_limit=gas_limit,\n                                                             confirmations=confirmations)\n            dispatcher_deploy_receipt = dispatcher_receipts[dispatcher_deployer.deployment_steps[0]]\n        else:\n            # 2 - Upgrade dispatcher to the real contract\n            the_stub_contract = self.blockchain.get_contract_by_name(registry=self.registry,\n                                                                     contract_name=self.contract_name_stub)\n            dispatcher_deployer = DispatcherDeployer(registry=self.registry,\n                                                     target_contract=the_stub_contract,\n                                                     bare=True)\n\n            dispatcher_retarget_receipt = dispatcher_deployer.retarget(transacting_power=transacting_power,\n                                                                       new_target=the_escrow_contract.address,\n                                                                       gas_limit=gas_limit,\n                                                                       confirmations=confirmations)\n\n        if progress:\n            progress.update(1)\n\n        # Cache the dispatcher contract\n        dispatcher_contract = dispatcher_deployer.contract\n        self.__dispatcher_contract = dispatcher_contract\n\n        # Wrap the escrow contract\n        wrapped_escrow_contract = self.blockchain._wrap_contract(dispatcher_contract,\n                                                                 target_contract=the_escrow_contract)\n\n        # Switch the contract for the wrapped one\n        self._contract = wrapped_escrow_contract\n\n        if deployment_mode is INIT:\n            preparation_receipts = dict(zip(self.init_steps, (deploy_receipt, dispatcher_deploy_receipt)))\n        else:\n            preparation_receipts = dict(zip(self.preparation_steps, (deploy_receipt, dispatcher_retarget_receipt)))\n        self.deployment_receipts = preparation_receipts\n\n        return preparation_receipts",
  "def deploy(self,\n               transacting_power: TransactingPower,\n               gas_limit: int = None,\n               progress=None,\n               confirmations: int = 0,\n               emitter=None,\n               ignore_deployed: bool = False,\n               deployment_mode=FULL,\n               **overrides) -> dict:\n\n        constructor_kwargs = {}  # placeholder for constructor kwargs\n        constructor_kwargs.update(overrides)\n        constructor_kwargs = {k: v for k, v in constructor_kwargs.items() if v is not None}\n        contract, deployment_receipt = self.blockchain.deploy_contract(transacting_power,\n                                                                       self.registry,\n                                                                       self.contract_name,\n                                                                       gas_limit=gas_limit,\n                                                                       confirmations=confirmations,\n                                                                       **constructor_kwargs)\n\n        self._contract = contract\n\n        tx_args = {}\n        if gas_limit:\n            tx_args.update({'gas': gas_limit})  # TODO: Gas management - 842\n        initialize_function = contract.functions.initialize(self.economics.fee_rate)\n        initialize_receipt = self.blockchain.send_transaction(contract_function=initialize_function,\n                                                              transacting_power=transacting_power,\n                                                              payload=tx_args,\n                                                              confirmations=confirmations)\n        return {self.deployment_steps[0]: deployment_receipt,\n                self.deployment_steps[1]: initialize_receipt}",
  "def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        staking_contract_name = StakingEscrowDeployer.contract_name\n        proxy_name = StakingEscrowDeployer._proxy_deployer.contract_name\n        try:\n            self.staking_contract = self.blockchain.get_contract_by_name(registry=self.registry,\n                                                                         contract_name=staking_contract_name,\n                                                                         proxy_name=proxy_name)\n        except self.registry.UnknownContract:\n            staking_contract_name = StakingEscrowDeployer.contract_name_stub\n            self.staking_contract = self.blockchain.get_contract_by_name(registry=self.registry,\n                                                                         contract_name=staking_contract_name,\n                                                                         proxy_name=proxy_name)",
  "def check_deployment_readiness(self, deployer_address: ChecksumAddress, *args, **kwargs) -> Tuple[bool, list]:\n        staking_escrow_owner = self.staking_contract.functions.owner().call()\n        adjudicator_deployment_rules = [\n            (deployer_address == staking_escrow_owner,\n             f'{self.contract_name} must be deployed by the owner of {STAKING_ESCROW_CONTRACT_NAME} ({staking_escrow_owner})')\n        ]\n        return super().check_deployment_readiness(deployer_address=deployer_address,\n                                                  additional_rules=adjudicator_deployment_rules,\n                                                  *args, **kwargs)",
  "def _deploy_essential(self,\n                          transacting_power: TransactingPower,\n                          contract_version: str,\n                          gas_limit: int = None,\n                          confirmations: int = 0,\n                          **overrides):\n        args = self.economics.slashing_deployment_parameters\n        constructor_kwargs = {\n            \"_hashAlgorithm\": args[0],\n            \"_basePenalty\": args[1],\n            \"_penaltyHistoryCoefficient\": args[2],\n            \"_percentagePenaltyCoefficient\": args[3],\n            \"_rewardCoefficient\": args[4]\n        }\n        constructor_kwargs.update(overrides)\n        constructor_kwargs = {k: v for k, v in constructor_kwargs.items() if v is not None}\n        # Force use of the escrow address from the registry\n        constructor_kwargs.update({\"_escrow\": self.staking_contract.address})\n        adjudicator_contract, deploy_receipt = self.blockchain.deploy_contract(transacting_power,\n                                                                               self.registry,\n                                                                               self.contract_name,\n                                                                               gas_limit=gas_limit,\n                                                                               confirmations=confirmations,\n                                                                               contract_version=contract_version,\n                                                                               **constructor_kwargs)\n        return adjudicator_contract, deploy_receipt",
  "def deploy(self,\n               transacting_power: TransactingPower,\n               deployment_mode=FULL,\n               gas_limit: int = None,\n               progress=None,\n               contract_version: str = \"latest\",\n               ignore_deployed: bool = False,\n               emitter=None,\n               confirmations: int = 0,\n               **overrides) -> Dict[str, str]:\n\n        if deployment_mode not in (BARE, IDLE, FULL):\n            raise ValueError(f\"Invalid deployment mode ({deployment_mode})\")\n\n        self.check_deployment_readiness(deployer_address=transacting_power.account,\n                                        contract_version=contract_version,\n                                        ignore_deployed=ignore_deployed)\n\n        # 1 - Deploy Contract\n        if emitter:\n            emitter.message(f\"\\nNext Transaction: {self.contract_name} Contract Creation\", color='blue', bold=True)\n        adjudicator_contract, deploy_receipt = self._deploy_essential(transacting_power=transacting_power,\n                                                                      contract_version=contract_version,\n                                                                      gas_limit=gas_limit,\n                                                                      confirmations=confirmations,\n                                                                      **overrides)\n\n        # This is the end of bare deployment.\n        if deployment_mode is BARE:\n            self._contract = adjudicator_contract\n            return self._finish_bare_deployment(deployment_receipt=deploy_receipt,\n                                                progress=progress)\n\n        if progress:\n            progress.update(1)\n\n        # 2 - Deploy Proxy\n        if emitter:\n            emitter.message(f\"\\nNext Transaction: {self._proxy_deployer.contract_name} Contract Creation for {self.contract_name}\", color='blue', bold=True)\n        proxy_deployer = self._proxy_deployer(registry=self.registry, target_contract=adjudicator_contract)\n\n        proxy_deploy_receipts = proxy_deployer.deploy(transacting_power=transacting_power,\n                                                      gas_limit=gas_limit, \n                                                      confirmations=confirmations)\n        proxy_deploy_receipt = proxy_deploy_receipts[proxy_deployer.deployment_steps[0]]\n        if progress:\n            progress.update(1)\n\n        # Cache the dispatcher contract\n        proxy_contract = proxy_deployer.contract\n        self.__proxy_contract = proxy_contract\n\n        # Wrap the escrow contract\n        wrapped = self.blockchain._wrap_contract(proxy_contract, target_contract=adjudicator_contract)\n\n        # Switch the contract for the wrapped one\n        adjudicator_contract = wrapped\n\n        # Gather the transaction receipts\n        ordered_receipts = (deploy_receipt, proxy_deploy_receipt)\n        deployment_receipts = dict(zip(self.deployment_steps, ordered_receipts))\n\n        self.deployment_receipts = deployment_receipts\n        self._contract = adjudicator_contract\n\n        return deployment_receipts",
  "def __init__(self, staking_interface: ChecksumAddress = None, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.threshold_staking_interface = staking_interface",
  "def _deploy_essential(self,\n                          transacting_power: TransactingPower,\n                          gas_limit: int = None,\n                          confirmations: int = 0,\n                          **overrides):\n        constructor_kwargs = {}\n        constructor_kwargs.update({\"_minAuthorization\": self.economics.min_authorization,\n                                   \"_minOperatorSeconds\": self.economics.min_operator_seconds,\n                                   \"_tStaking\": self.threshold_staking_interface})\n        constructor_kwargs.update(overrides)\n        constructor_kwargs = {k: v for k, v in constructor_kwargs.items() if v is not None}\n        the_escrow_contract, deploy_receipt = self.blockchain.deploy_contract(\n            transacting_power,\n            self.registry,\n            self.contract_name,\n            gas_limit=gas_limit,\n            confirmations=confirmations,\n            **constructor_kwargs\n        )\n\n        return the_escrow_contract, deploy_receipt",
  "def deploy(self,\n               transacting_power: TransactingPower,\n               gas_limit: int = None,\n               confirmations: int = 0,\n               deployment_mode=FULL,\n               ignore_deployed: bool = False,\n               progress=None,\n               emitter=None,\n               **overrides):\n\n        if deployment_mode != FULL:\n            raise self.ContractDeploymentError(f\"{self.contract_name} cannot be deployed in {deployment_mode} mode\")\n\n        self.check_deployment_readiness(deployer_address=transacting_power.account,\n                                        ignore_deployed=ignore_deployed)\n\n        contract, receipt = self._deploy_essential(transacting_power=transacting_power,\n                                                   gas_limit=gas_limit,\n                                                   confirmations=confirmations,\n                                                   **overrides)\n\n        # Update the progress bar\n        if progress:\n            progress.update(1)\n\n        self._contract = contract\n        self.deployment_receipts = dict(zip(self.deployment_steps, (receipt, )))\n        return self.deployment_receipts",
  "class NetworksInventory:  # TODO: See #1564\n\n    MAINNET = \"mainnet\"\n    LYNX = \"lynx\"\n    ETH = \"ethereum\"\n    TAPIR = \"tapir\"\n\n    # TODO: Use naming scheme to preserve multiple compatibility with multiple deployments to a single network?\n    POLYGON = 'polygon'\n    MUMBAI = 'mumbai'\n\n    UNKNOWN = 'unknown'  # TODO: Is there a better way to signal an unknown network?\n    DEFAULT = MAINNET\n\n    __to_chain_id_eth = {\n        MAINNET: 1,  # Ethereum Mainnet\n        LYNX: 5,  # Goerli\n        TAPIR: 5,  # Goerli\n    }\n    __to_chain_id_polygon = {\n        # TODO: Use naming scheme?\n        POLYGON: 137,    # Polygon Mainnet\n        MUMBAI: 80001,   # Polygon Testnet (Mumbai)\n    }\n\n    ETH_NETWORKS = tuple(__to_chain_id_eth.keys())\n    POLY_NETWORKS = tuple(__to_chain_id_polygon.keys())\n\n    NETWORKS = ETH_NETWORKS + POLY_NETWORKS\n\n    class UnrecognizedNetwork(RuntimeError):\n        pass\n\n    @classmethod\n    def get_ethereum_chain_id(cls, network):  # TODO: Use this (where?) to make sure we're in the right chain\n        try:\n            return cls.__to_ethereum_chain_id[network]\n        except KeyError:\n            return 1337  # TODO: what about chain id when testing?\n\n    @classmethod\n    def validate_network_name(cls, network_name: str):\n        if network_name not in cls.NETWORKS:\n            raise cls.UnrecognizedNetwork(\n                f\"{network_name} is not a recognized network.\"\n            )",
  "class UnrecognizedNetwork(RuntimeError):\n        pass",
  "def get_ethereum_chain_id(cls, network):  # TODO: Use this (where?) to make sure we're in the right chain\n        try:\n            return cls.__to_ethereum_chain_id[network]\n        except KeyError:\n            return 1337",
  "def validate_network_name(cls, network_name: str):\n        if network_name not in cls.NETWORKS:\n            raise cls.UnrecognizedNetwork(\n                f\"{network_name} is not a recognized network.\"\n            )",
  "class ProviderError(Exception):\n    pass",
  "def _get_IPC_provider(eth_provider_uri) -> BaseProvider:\n    uri_breakdown = urlparse(eth_provider_uri)\n    from nucypher.blockchain.eth.interfaces import BlockchainInterface\n    return IPCProvider(ipc_path=uri_breakdown.path,\n                       timeout=BlockchainInterface.TIMEOUT,\n                       request_kwargs={'timeout': BlockchainInterface.TIMEOUT})",
  "def _get_HTTP_provider(eth_provider_uri) -> BaseProvider:\n    from nucypher.blockchain.eth.interfaces import BlockchainInterface\n    return HTTPProvider(endpoint_uri=eth_provider_uri, request_kwargs={'timeout': BlockchainInterface.TIMEOUT})",
  "def _get_websocket_provider(eth_provider_uri) -> BaseProvider:\n    from nucypher.blockchain.eth.interfaces import BlockchainInterface\n    return WebsocketProvider(endpoint_uri=eth_provider_uri, websocket_kwargs={'timeout': BlockchainInterface.TIMEOUT})",
  "def _get_auto_provider(eth_provider_uri) -> BaseProvider:\n    from web3.auto import w3\n    # how-automated-detection-works: https://web3py.readthedocs.io/en/latest/providers.html\n    connected = w3.isConnected()\n    if not connected:\n        raise ProviderError('Cannot auto-detect node.  Provide a full URI instead.')\n    return w3.provider",
  "def _get_pyevm_test_backend() -> PyEVMBackend:\n    try:\n        # TODO: Consider packaged support of --dev mode with testerchain\n        from tests.constants import PYEVM_GAS_LIMIT, NUMBER_OF_ETH_TEST_ACCOUNTS\n    except ImportError:\n        raise DevelopmentInstallationRequired(importable_name='tests.constants')\n\n    # Initialize\n    genesis_params = PyEVMBackend._generate_genesis_params(overrides={'gas_limit': PYEVM_GAS_LIMIT})\n    pyevm_backend = PyEVMBackend(genesis_parameters=genesis_params)\n    pyevm_backend.reset_to_genesis(genesis_params=genesis_params, num_accounts=NUMBER_OF_ETH_TEST_ACCOUNTS)\n    return pyevm_backend",
  "def _get_ethereum_tester(test_backend: Union[PyEVMBackend, MockBackend]) -> EthereumTesterProvider:\n    eth_tester = EthereumTester(backend=test_backend, auto_mine_transactions=True)\n    provider = EthereumTesterProvider(ethereum_tester=eth_tester)\n    return provider",
  "def _get_pyevm_test_provider(eth_provider_uri) -> BaseProvider:\n    \"\"\" Test provider entry-point\"\"\"\n    # https://github.com/ethereum/eth-tester#pyevm-experimental\n    pyevm_eth_tester = _get_pyevm_test_backend()\n    provider = _get_ethereum_tester(test_backend=pyevm_eth_tester)\n    return provider",
  "def _get_mock_test_provider(eth_provider_uri) -> BaseProvider:\n    # https://github.com/ethereum/eth-tester#mockbackend\n    mock_backend = MockBackend()\n    provider = _get_ethereum_tester(test_backend=mock_backend)\n    return provider",
  "def _get_tester_ganache(eth_provider_uri=None) -> BaseProvider:\n    endpoint_uri = eth_provider_uri or 'http://localhost:7545'\n    return HTTPProvider(endpoint_uri=endpoint_uri)",
  "class CanonicalRegistrySource(ABC):\n\n    logger = Logger('RegistrySource')\n\n    name = NotImplementedError\n    is_primary = NotImplementedError\n\n    def __init__(self, network: str, registry_name: str, *args, **kwargs):\n        if network not in NetworksInventory.NETWORKS:\n            raise ValueError(f\"{self.__class__.__name__} not available for network '{network}'. \"\n                             f\"Valid options are: {list(NetworksInventory.NETWORKS)}\")\n        self.network = network\n        self.registry_name = registry_name\n\n    class RegistrySourceError(Exception):\n        pass\n\n    class RegistrySourceUnavailable(RegistrySourceError):\n        pass\n\n    @abstractmethod\n    def get_publication_endpoint(self) -> str:\n        raise NotImplementedError\n\n    @abstractmethod\n    def fetch_latest_publication(self) -> Union[str, bytes]:\n        raise NotImplementedError\n\n    def __repr__(self):\n        return str(self.get_publication_endpoint())",
  "class GithubRegistrySource(CanonicalRegistrySource):\n\n    _PUBLICATION_REPO = \"nucypher/nucypher\"\n    _BASE_URL = f'https://raw.githubusercontent.com/{_PUBLICATION_REPO}'\n\n    name = \"GitHub Registry Source\"\n    is_primary = True\n\n    def get_publication_endpoint(self) -> str:\n        url = f\"{self._BASE_URL}/development/nucypher/blockchain/eth/contract_registry/{self.network}/{self.registry_name}\"\n        return url\n\n    def fetch_latest_publication(self) -> Union[str, bytes]:\n        # Setup\n        publication_endpoint = self.get_publication_endpoint()\n        self.logger.debug(f\"Downloading contract registry from {publication_endpoint}\")\n        try:\n            # Fetch\n            response = requests.get(publication_endpoint)\n        except requests.exceptions.ConnectionError as e:\n            error = f\"Failed to fetch registry from {publication_endpoint}: {str(e)}\"\n            raise self.RegistrySourceUnavailable(error)\n\n        if response.status_code != 200:\n            error = f\"Failed to fetch registry from {publication_endpoint} with status code {response.status_code}\"\n            raise self.RegistrySourceUnavailable(error)\n\n        registry_data = response.content\n        return registry_data",
  "class EmbeddedRegistrySource(CanonicalRegistrySource):\n    name = \"Embedded Registry Source\"\n    is_primary = False\n\n    def get_publication_endpoint(self) -> Path:\n        filepath = Path(CONTRACT_REGISTRY_BASE / self.network / self.registry_name).absolute()\n        return filepath\n\n    def fetch_latest_publication(self) -> Union[str, bytes]:\n        filepath = self.get_publication_endpoint()\n        self.logger.debug(f\"Reading registry at {filepath.absolute()}\")\n        try:\n            with open(filepath, \"r\") as f:\n                registry_data = f.read()\n            return registry_data\n        except IOError as e:\n            error = f\"Failed to read registry at {filepath.absolute()}: {str(e)}\"\n            raise self.RegistrySourceError(error)",
  "class RegistrySourceManager:\n    logger = Logger('RegistrySource')\n\n    _REMOTE_SOURCES = (\n        GithubRegistrySource,\n        # TODO: Mirror/fallback for contract registry: moar remote sources - #1454\n        # NucypherServersRegistrySource,\n        # IPFSRegistrySource,\n    )  # type: Tuple[Type[CanonicalRegistrySource]]\n\n    _LOCAL_SOURCES = (\n        EmbeddedRegistrySource,\n    )  # type: Tuple[Type[CanonicalRegistrySource]]\n\n    _FALLBACK_CHAIN = _REMOTE_SOURCES + _LOCAL_SOURCES\n\n    class NoSourcesAvailable(Exception):\n        pass\n\n    def __init__(self, sources=None, only_primary: bool = False):\n        if only_primary and sources:\n            raise ValueError(\"Either use 'only_primary' or 'sources', but not both.\")\n        elif only_primary:\n            self.sources = self.get_primary_sources()\n        else:\n            self.sources = list(sources or self._FALLBACK_CHAIN)\n\n    def __getitem__(self, index):\n        return self.sources\n\n    @classmethod\n    def get_primary_sources(cls):\n        return [source for source in cls._FALLBACK_CHAIN if source.is_primary]\n\n    def fetch_latest_publication(self, registry_class, network: str):\n        \"\"\"\n        Get the latest contract registry data available from a registry source chain.\n        \"\"\"\n\n        for registry_source_class in self.sources:\n            if isinstance(registry_source_class, CanonicalRegistrySource):  # i.e., it's not a class, but an instance\n                registry_source = registry_source_class\n                expected = registry_class.REGISTRY_NAME, network\n                actual = registry_source.registry_name, registry_source.network\n                if actual != expected:\n                    raise ValueError(f\"(registry_name, network) should be {expected} but got {actual}\")\n            else:\n                registry_source = registry_source_class(network=network, registry_name=registry_class.REGISTRY_NAME)\n\n            try:\n                if not registry_source.is_primary:\n                    message = f\"Warning: Registry at {registry_source} is not a primary source.\"\n                    self.logger.warn(message)\n                registry_data_bytes = registry_source.fetch_latest_publication()\n            except registry_source.RegistrySourceUnavailable:\n                message = f\"Fetching registry from {registry_source} failed.\"\n                self.logger.warn(message)\n                continue\n            else:\n                return registry_data_bytes, registry_source\n        else:\n            self.logger.warn(\"All known registry sources failed.\")\n            raise self.NoSourcesAvailable",
  "class BaseContractRegistry(ABC):\n    \"\"\"\n    Records known contracts on the disk for future access and utility. This\n    lazily writes to the filesystem during contract enrollment.\n\n    WARNING: Unless you are developing NuCypher, you most likely won't ever need\n    to use this.\n    \"\"\"\n\n    logger = Logger('ContractRegistry')\n\n    _multi_contract = True\n    _contract_name = NotImplemented\n\n    # Registry\n    REGISTRY_NAME = 'contract_registry.json'  # TODO: #1511 Save registry with ID-time-based filename\n    DEVELOPMENT_REGISTRY_NAME = 'dev_contract_registry.json'\n\n    class RegistryError(Exception):\n        pass\n\n    class EmptyRegistry(RegistryError):\n        pass\n\n    class NoRegistry(RegistryError):\n        pass\n\n    class UnknownContract(RegistryError):\n        pass\n\n    class InvalidRegistry(RegistryError):\n        \"\"\"Raised when invalid data is encountered in the registry\"\"\"\n\n    class CantOverwriteRegistry(RegistryError):\n        pass\n\n    def __init__(self, source=None, *args, **kwargs):\n        self.__source = source\n        self.log = Logger(\"registry\")\n        self._id = None\n\n    def __eq__(self, other) -> bool:\n        if self is other:\n            return True  # and that's all\n        return bool(self.id == other.id)\n\n    def __repr__(self) -> str:\n        r = f\"{self.__class__.__name__}(id={self.id[:6]})\"\n        return r\n\n    @property\n    def id(self) -> str:\n        \"\"\"Returns a hexstr of the registry contents.\"\"\"\n        if not self._id:\n            blake = hashlib.blake2b()\n            blake.update(json.dumps(self.read()).encode())\n            self._id = blake.digest().hex()\n        return self._id\n\n    @abstractmethod\n    def _destroy(self) -> None:\n        raise NotImplementedError\n\n    @abstractmethod\n    def write(self, registry_data: list) -> None:\n        raise NotImplementedError\n\n    @abstractmethod\n    def read(self) -> Union[list, dict]:\n        raise NotImplementedError\n\n    @classmethod\n    def from_latest_publication(cls,\n                                *args,\n                                source_manager=None,\n                                network: str = NetworksInventory.DEFAULT,\n                                **kwargs) -> 'BaseContractRegistry':\n        \"\"\"\n        Get the latest contract registry available from a registry source chain.\n        \"\"\"\n        if not source_manager:\n            source_manager = RegistrySourceManager()\n\n        registry_data, source = source_manager.fetch_latest_publication(registry_class=cls, network=network)\n\n        registry_instance = cls(*args, source=source, **kwargs)\n        registry_instance.write(registry_data=json.loads(registry_data))\n        return registry_instance\n\n    @property\n    def source(self) -> 'CanonicalRegistrySource':\n        return self.__source\n\n    @property\n    def enrolled_names(self) -> Iterator:\n        entries = iter(record[0] for record in self.read())\n        return entries\n\n    @property\n    def enrolled_addresses(self) -> Iterator:\n        entries = iter(record[2] for record in self.read())\n        return entries\n\n    def enroll(self, contract_name, contract_address, contract_abi, contract_version) -> None:\n        \"\"\"\n        Enrolls a contract to the chain registry by writing the name, version,\n        address, and abi information to the filesystem as JSON.\n\n        Note: Unless you are developing NuCypher, you most likely won't ever\n        need to use this.\n        \"\"\"\n        contract_data = [contract_name, contract_version, contract_address, contract_abi]\n        try:\n            registry_data = self.read()\n        except self.RegistryError:\n            self.log.info(\"Blank registry encountered: enrolling {}:{}:{}\"\n                          .format(contract_name, contract_version, contract_address))\n            registry_data = list()  # empty registry\n\n        registry_data.append(contract_data)\n        self.write(registry_data)\n        self.log.info(\"Enrolled {}:{}:{} into registry.\".format(contract_name, contract_version, contract_address))\n\n    def search(self, contract_name: str = None, contract_version: str = None, contract_address: str = None) -> tuple:\n        \"\"\"\n        Searches the registry for a contract with the provided name or address\n        and returns the contracts component data.\n        \"\"\"\n        if not (bool(contract_name) ^ bool(contract_address)):\n            raise ValueError(\"Pass contract_name or contract_address, not both.\")\n        if bool(contract_version) and not bool(contract_name):\n            raise ValueError(\"Pass contract_version together with contract_name.\")\n\n        contracts = list()\n        registry_data = self.read()\n\n        try:\n            for contract in registry_data:\n                name, version, address, abi = contract\n                if contract_address == address or \\\n                        contract_name == name and (contract_version is None or version == contract_version):\n                    contracts.append(contract)\n        except ValueError:\n            message = \"Missing or corrupted registry data\"\n            self.log.critical(message)\n            raise self.InvalidRegistry(message)\n\n        if not contracts:\n            raise self.UnknownContract(contract_name)\n\n        if contract_address and len(contracts) > 1:\n            m = f\"Multiple records returned for address {contract_address}\"\n            self.log.critical(m)\n            raise self.InvalidRegistry(m)\n\n        result = tuple(contracts) if contract_name else contracts[0]\n        return result",
  "class LocalContractRegistry(BaseContractRegistry):\n\n    REGISTRY_TYPE = 'contract'\n\n    def __init__(self, filepath: Path, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.__filepath = filepath\n        self.log.info(f\"Using {self.REGISTRY_TYPE} registry {filepath}\")\n\n    def __repr__(self):\n        r = f\"{self.__class__.__name__}(filepath={self.filepath})\"\n        return r\n\n    @property\n    def filepath(self) -> Path:\n        return self.__filepath\n\n    def _swap_registry(self, filepath: Path) -> bool:\n        self.__filepath = filepath\n        return True\n\n    def read(self) -> Union[list, dict]:\n        \"\"\"\n        Reads the registry file and parses the JSON and returns a list.\n        If the file is empty it will return an empty list.\n        If you are modifying or updating the registry file, you _must_ call\n        this function first to get the current state to append to the dict or\n        modify it because _write_registry_file overwrites the file.\n        \"\"\"\n        try:\n            with open(self.filepath, 'r') as registry_file:\n                self.log.debug(\"Reading from registry: filepath {}\".format(self.filepath))\n                registry_file.seek(0)\n                file_data = registry_file.read()\n                if file_data:\n                    try:\n                        registry_data = json.loads(file_data)\n                    except JSONDecodeError:\n                        raise self.RegistryError(f\"Registry contains invalid JSON at '{self.__filepath}'\")\n                else:\n                    registry_data = list() if self._multi_contract else dict()\n\n        except FileNotFoundError:\n            raise self.NoRegistry(\"No registry at filepath: {}\".format(self.filepath))\n\n        except JSONDecodeError:\n            raise\n\n        return registry_data\n\n    def write(self, registry_data: Union[List, Dict]) -> None:\n        \"\"\"\n        Writes the registry data list as JSON to the registry file. If no\n        file exists, it will create it and write the data. If a file does exist\n        it will _overwrite_ everything in it.\n        \"\"\"\n        # Ensure parent path exists\n        self.__filepath.parent.mkdir(parents=True, exist_ok=True)\n\n        with open(self.__filepath, 'w') as registry_file:\n            registry_file.seek(0)\n            registry_file.write(json.dumps(registry_data))\n            registry_file.truncate()\n\n        self._id = None\n\n    def _destroy(self) -> None:\n        self.filepath.unlink()\n\n    @classmethod\n    def from_dict(cls, payload: dict, **overrides) -> 'LocalContractRegistry':\n        payload.update({k: v for k, v in overrides.items() if v is not None})\n        registry = cls(filepath=payload['filepath'])\n        return registry\n\n    def to_dict(self) -> dict:\n        payload = dict(filepath=self.__filepath)\n        return payload",
  "class InMemoryContractRegistry(BaseContractRegistry):\n\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.__registry_data = None\n        self.filepath = \"::memory::\"\n\n    def clear(self):\n        self.__registry_data = None\n\n    def _swap_registry(self, filepath: Path) -> bool:\n        raise NotImplementedError\n\n    def write(self, registry_data: list) -> None:\n        self.__registry_data = json.dumps(registry_data)\n        self._id = None\n\n    def read(self) -> list:\n        try:\n            registry_data = json.loads(self.__registry_data)\n        except TypeError:\n            if self.__registry_data is None:\n                registry_data = list() if self._multi_contract else dict()\n            else:\n                raise\n        return registry_data\n\n    def commit(self, filepath: Optional[Path] = None, overwrite: bool = False) -> Path:\n        \"\"\"writes the current state of the registry to a file\"\"\"\n        if not filepath:\n            filepath = DEFAULT_CONFIG_ROOT / self.REGISTRY_NAME\n        self.log.info(\"Committing in-memory registry to disk.\")\n        if filepath.exists() and not overwrite:\n            existing_registry = LocalContractRegistry(filepath=filepath)\n            raise self.CantOverwriteRegistry(f\"Registry #{existing_registry.id[:16]} exists at {filepath} \"\n                                             f\"while writing Registry #{self.id[:16]}).  \"\n                                             f\"Pass overwrite=True to force it.\")\n        with open(filepath, 'w') as file:\n            file.write(self.__registry_data)\n        self.log.info(\"Wrote in-memory registry to '{}'\".format(filepath))\n        return filepath\n\n    def _destroy(self) -> None:\n        self.__registry_data = dict()",
  "def __init__(self, network: str, registry_name: str, *args, **kwargs):\n        if network not in NetworksInventory.NETWORKS:\n            raise ValueError(f\"{self.__class__.__name__} not available for network '{network}'. \"\n                             f\"Valid options are: {list(NetworksInventory.NETWORKS)}\")\n        self.network = network\n        self.registry_name = registry_name",
  "class RegistrySourceError(Exception):\n        pass",
  "class RegistrySourceUnavailable(RegistrySourceError):\n        pass",
  "def get_publication_endpoint(self) -> str:\n        raise NotImplementedError",
  "def fetch_latest_publication(self) -> Union[str, bytes]:\n        raise NotImplementedError",
  "def __repr__(self):\n        return str(self.get_publication_endpoint())",
  "def get_publication_endpoint(self) -> str:\n        url = f\"{self._BASE_URL}/development/nucypher/blockchain/eth/contract_registry/{self.network}/{self.registry_name}\"\n        return url",
  "def fetch_latest_publication(self) -> Union[str, bytes]:\n        # Setup\n        publication_endpoint = self.get_publication_endpoint()\n        self.logger.debug(f\"Downloading contract registry from {publication_endpoint}\")\n        try:\n            # Fetch\n            response = requests.get(publication_endpoint)\n        except requests.exceptions.ConnectionError as e:\n            error = f\"Failed to fetch registry from {publication_endpoint}: {str(e)}\"\n            raise self.RegistrySourceUnavailable(error)\n\n        if response.status_code != 200:\n            error = f\"Failed to fetch registry from {publication_endpoint} with status code {response.status_code}\"\n            raise self.RegistrySourceUnavailable(error)\n\n        registry_data = response.content\n        return registry_data",
  "def get_publication_endpoint(self) -> Path:\n        filepath = Path(CONTRACT_REGISTRY_BASE / self.network / self.registry_name).absolute()\n        return filepath",
  "def fetch_latest_publication(self) -> Union[str, bytes]:\n        filepath = self.get_publication_endpoint()\n        self.logger.debug(f\"Reading registry at {filepath.absolute()}\")\n        try:\n            with open(filepath, \"r\") as f:\n                registry_data = f.read()\n            return registry_data\n        except IOError as e:\n            error = f\"Failed to read registry at {filepath.absolute()}: {str(e)}\"\n            raise self.RegistrySourceError(error)",
  "class NoSourcesAvailable(Exception):\n        pass",
  "def __init__(self, sources=None, only_primary: bool = False):\n        if only_primary and sources:\n            raise ValueError(\"Either use 'only_primary' or 'sources', but not both.\")\n        elif only_primary:\n            self.sources = self.get_primary_sources()\n        else:\n            self.sources = list(sources or self._FALLBACK_CHAIN)",
  "def __getitem__(self, index):\n        return self.sources",
  "def get_primary_sources(cls):\n        return [source for source in cls._FALLBACK_CHAIN if source.is_primary]",
  "def fetch_latest_publication(self, registry_class, network: str):\n        \"\"\"\n        Get the latest contract registry data available from a registry source chain.\n        \"\"\"\n\n        for registry_source_class in self.sources:\n            if isinstance(registry_source_class, CanonicalRegistrySource):  # i.e., it's not a class, but an instance\n                registry_source = registry_source_class\n                expected = registry_class.REGISTRY_NAME, network\n                actual = registry_source.registry_name, registry_source.network\n                if actual != expected:\n                    raise ValueError(f\"(registry_name, network) should be {expected} but got {actual}\")\n            else:\n                registry_source = registry_source_class(network=network, registry_name=registry_class.REGISTRY_NAME)\n\n            try:\n                if not registry_source.is_primary:\n                    message = f\"Warning: Registry at {registry_source} is not a primary source.\"\n                    self.logger.warn(message)\n                registry_data_bytes = registry_source.fetch_latest_publication()\n            except registry_source.RegistrySourceUnavailable:\n                message = f\"Fetching registry from {registry_source} failed.\"\n                self.logger.warn(message)\n                continue\n            else:\n                return registry_data_bytes, registry_source\n        else:\n            self.logger.warn(\"All known registry sources failed.\")\n            raise self.NoSourcesAvailable",
  "class RegistryError(Exception):\n        pass",
  "class EmptyRegistry(RegistryError):\n        pass",
  "class NoRegistry(RegistryError):\n        pass",
  "class UnknownContract(RegistryError):\n        pass",
  "class InvalidRegistry(RegistryError):\n        \"\"\"Raised when invalid data is encountered in the registry\"\"\"",
  "class CantOverwriteRegistry(RegistryError):\n        pass",
  "def __init__(self, source=None, *args, **kwargs):\n        self.__source = source\n        self.log = Logger(\"registry\")\n        self._id = None",
  "def __eq__(self, other) -> bool:\n        if self is other:\n            return True  # and that's all\n        return bool(self.id == other.id)",
  "def __repr__(self) -> str:\n        r = f\"{self.__class__.__name__}(id={self.id[:6]})\"\n        return r",
  "def id(self) -> str:\n        \"\"\"Returns a hexstr of the registry contents.\"\"\"\n        if not self._id:\n            blake = hashlib.blake2b()\n            blake.update(json.dumps(self.read()).encode())\n            self._id = blake.digest().hex()\n        return self._id",
  "def _destroy(self) -> None:\n        raise NotImplementedError",
  "def write(self, registry_data: list) -> None:\n        raise NotImplementedError",
  "def read(self) -> Union[list, dict]:\n        raise NotImplementedError",
  "def from_latest_publication(cls,\n                                *args,\n                                source_manager=None,\n                                network: str = NetworksInventory.DEFAULT,\n                                **kwargs) -> 'BaseContractRegistry':\n        \"\"\"\n        Get the latest contract registry available from a registry source chain.\n        \"\"\"\n        if not source_manager:\n            source_manager = RegistrySourceManager()\n\n        registry_data, source = source_manager.fetch_latest_publication(registry_class=cls, network=network)\n\n        registry_instance = cls(*args, source=source, **kwargs)\n        registry_instance.write(registry_data=json.loads(registry_data))\n        return registry_instance",
  "def source(self) -> 'CanonicalRegistrySource':\n        return self.__source",
  "def enrolled_names(self) -> Iterator:\n        entries = iter(record[0] for record in self.read())\n        return entries",
  "def enrolled_addresses(self) -> Iterator:\n        entries = iter(record[2] for record in self.read())\n        return entries",
  "def enroll(self, contract_name, contract_address, contract_abi, contract_version) -> None:\n        \"\"\"\n        Enrolls a contract to the chain registry by writing the name, version,\n        address, and abi information to the filesystem as JSON.\n\n        Note: Unless you are developing NuCypher, you most likely won't ever\n        need to use this.\n        \"\"\"\n        contract_data = [contract_name, contract_version, contract_address, contract_abi]\n        try:\n            registry_data = self.read()\n        except self.RegistryError:\n            self.log.info(\"Blank registry encountered: enrolling {}:{}:{}\"\n                          .format(contract_name, contract_version, contract_address))\n            registry_data = list()  # empty registry\n\n        registry_data.append(contract_data)\n        self.write(registry_data)\n        self.log.info(\"Enrolled {}:{}:{} into registry.\".format(contract_name, contract_version, contract_address))",
  "def search(self, contract_name: str = None, contract_version: str = None, contract_address: str = None) -> tuple:\n        \"\"\"\n        Searches the registry for a contract with the provided name or address\n        and returns the contracts component data.\n        \"\"\"\n        if not (bool(contract_name) ^ bool(contract_address)):\n            raise ValueError(\"Pass contract_name or contract_address, not both.\")\n        if bool(contract_version) and not bool(contract_name):\n            raise ValueError(\"Pass contract_version together with contract_name.\")\n\n        contracts = list()\n        registry_data = self.read()\n\n        try:\n            for contract in registry_data:\n                name, version, address, abi = contract\n                if contract_address == address or \\\n                        contract_name == name and (contract_version is None or version == contract_version):\n                    contracts.append(contract)\n        except ValueError:\n            message = \"Missing or corrupted registry data\"\n            self.log.critical(message)\n            raise self.InvalidRegistry(message)\n\n        if not contracts:\n            raise self.UnknownContract(contract_name)\n\n        if contract_address and len(contracts) > 1:\n            m = f\"Multiple records returned for address {contract_address}\"\n            self.log.critical(m)\n            raise self.InvalidRegistry(m)\n\n        result = tuple(contracts) if contract_name else contracts[0]\n        return result",
  "def __init__(self, filepath: Path, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.__filepath = filepath\n        self.log.info(f\"Using {self.REGISTRY_TYPE} registry {filepath}\")",
  "def __repr__(self):\n        r = f\"{self.__class__.__name__}(filepath={self.filepath})\"\n        return r",
  "def filepath(self) -> Path:\n        return self.__filepath",
  "def _swap_registry(self, filepath: Path) -> bool:\n        self.__filepath = filepath\n        return True",
  "def read(self) -> Union[list, dict]:\n        \"\"\"\n        Reads the registry file and parses the JSON and returns a list.\n        If the file is empty it will return an empty list.\n        If you are modifying or updating the registry file, you _must_ call\n        this function first to get the current state to append to the dict or\n        modify it because _write_registry_file overwrites the file.\n        \"\"\"\n        try:\n            with open(self.filepath, 'r') as registry_file:\n                self.log.debug(\"Reading from registry: filepath {}\".format(self.filepath))\n                registry_file.seek(0)\n                file_data = registry_file.read()\n                if file_data:\n                    try:\n                        registry_data = json.loads(file_data)\n                    except JSONDecodeError:\n                        raise self.RegistryError(f\"Registry contains invalid JSON at '{self.__filepath}'\")\n                else:\n                    registry_data = list() if self._multi_contract else dict()\n\n        except FileNotFoundError:\n            raise self.NoRegistry(\"No registry at filepath: {}\".format(self.filepath))\n\n        except JSONDecodeError:\n            raise\n\n        return registry_data",
  "def write(self, registry_data: Union[List, Dict]) -> None:\n        \"\"\"\n        Writes the registry data list as JSON to the registry file. If no\n        file exists, it will create it and write the data. If a file does exist\n        it will _overwrite_ everything in it.\n        \"\"\"\n        # Ensure parent path exists\n        self.__filepath.parent.mkdir(parents=True, exist_ok=True)\n\n        with open(self.__filepath, 'w') as registry_file:\n            registry_file.seek(0)\n            registry_file.write(json.dumps(registry_data))\n            registry_file.truncate()\n\n        self._id = None",
  "def _destroy(self) -> None:\n        self.filepath.unlink()",
  "def from_dict(cls, payload: dict, **overrides) -> 'LocalContractRegistry':\n        payload.update({k: v for k, v in overrides.items() if v is not None})\n        registry = cls(filepath=payload['filepath'])\n        return registry",
  "def to_dict(self) -> dict:\n        payload = dict(filepath=self.__filepath)\n        return payload",
  "def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.__registry_data = None\n        self.filepath = \"::memory::\"",
  "def clear(self):\n        self.__registry_data = None",
  "def _swap_registry(self, filepath: Path) -> bool:\n        raise NotImplementedError",
  "def write(self, registry_data: list) -> None:\n        self.__registry_data = json.dumps(registry_data)\n        self._id = None",
  "def read(self) -> list:\n        try:\n            registry_data = json.loads(self.__registry_data)\n        except TypeError:\n            if self.__registry_data is None:\n                registry_data = list() if self._multi_contract else dict()\n            else:\n                raise\n        return registry_data",
  "def commit(self, filepath: Optional[Path] = None, overwrite: bool = False) -> Path:\n        \"\"\"writes the current state of the registry to a file\"\"\"\n        if not filepath:\n            filepath = DEFAULT_CONFIG_ROOT / self.REGISTRY_NAME\n        self.log.info(\"Committing in-memory registry to disk.\")\n        if filepath.exists() and not overwrite:\n            existing_registry = LocalContractRegistry(filepath=filepath)\n            raise self.CantOverwriteRegistry(f\"Registry #{existing_registry.id[:16]} exists at {filepath} \"\n                                             f\"while writing Registry #{self.id[:16]}).  \"\n                                             f\"Pass overwrite=True to force it.\")\n        with open(filepath, 'w') as file:\n            file.write(self.__registry_data)\n        self.log.info(\"Wrote in-memory registry to '{}'\".format(filepath))\n        return filepath",
  "def _destroy(self) -> None:\n        self.__registry_data = dict()",
  "class ERC20:\n    \"\"\"\n    An amount of ERC20 tokens that doesn't hurt your eyes.\n    Wraps the eth_utils currency conversion methods.\n\n    The easiest way to use ERC20, is to pass an int, Decimal, or str, and denomination string:\n\n    Int:    t = T(100, 'T')\n    Int:    t = T(15000000000000000000000, 'TuNits')\n\n    Decimal:  t = T(Decimal('15042.445'), 'T')\n    String: t = T('10002.302', 'T')\n\n    ...or alternately...\n\n    Decimal: t = T.from_tokens(Decimal('100.50'))\n    Int: t = T.from_units(15000000000000000000000)\n\n    Token quantity is stored internally as an int in the smallest denomination,\n    and all arithmetic operations use this value.\n\n    Using float inputs to this class to represent amounts of NU is supported but not recommended,\n    as floats don't have enough precision to represent some quantities.\n    \"\"\"\n\n    _symbol = None\n    _denominations = {}\n    _unit_name = None\n\n    class InvalidAmount(ValueError):\n        \"\"\"Raised when an invalid input amount is provided\"\"\"\n\n    class InvalidDenomination(ValueError):\n        \"\"\"Raised when an unknown denomination string is passed into __init__\"\"\"\n\n    def __init__(self, value: Union[int, Decimal, str], denomination: str):\n        # super().__init__()\n        # Lookup Conversion\n        try:\n            wrapped_denomination = self._denominations[denomination]\n        except KeyError:\n            raise self.InvalidDenomination(f'\"{denomination}\"')\n\n        # Convert or Raise\n        try:\n            self.__value = currency.to_wei(number=value, unit=wrapped_denomination)\n        except ValueError as e:\n            raise self.__class__.InvalidAmount(f\"{value} is an invalid amount of tokens: {str(e)}\")\n\n    @classmethod\n    def ZERO(cls) -> 'ERC20':\n        return cls(0, cls._unit_name)\n\n    @classmethod\n    def from_units(cls, value: int) -> 'ERC20':\n        return cls(value, denomination=cls._unit_name)\n\n    @classmethod\n    def from_tokens(cls, value: Union[int, Decimal, str]) -> 'ERC20':\n        return cls(value, denomination=cls._symbol)\n\n    def to_tokens(self) -> Decimal:\n        \"\"\"Returns a decimal value of NU\"\"\"\n        return currency.from_wei(self.__value, unit='ether')\n\n    def to_units(self) -> ERC20UNits:\n        \"\"\"Returns an int value in the Unit class for this token\"\"\"\n        return self.__class__._unit(self.__value)\n\n    def __eq__(self, other) -> bool:\n        return int(self) == int(other)\n\n    def __bool__(self) -> bool:\n        if self.__value == 0:\n            return False\n        else:\n            return True\n\n    def __radd__(self, other) -> 'ERC20':\n        return self.__class__(int(self) + int(other), self._unit_name)\n\n    def __add__(self, other) -> 'ERC20':\n        return self.__class__(int(self) + int(other), self._unit_name)\n\n    def __sub__(self, other) -> 'ERC20':\n        return self.__class__(int(self) - int(other), self._unit_name)\n\n    def __rmul__(self, other) -> 'ERC20':\n        return self.__class__(int(self) * int(other), self._unit_name)\n\n    def __mul__(self, other) -> 'ERC20':\n        return self.__class__(int(self) * int(other), self._unit_name)\n\n    def __floordiv__(self, other) -> 'ERC20':\n        return self.__class__(int(self) // int(other), self._unit_name)\n\n    def __gt__(self, other) -> bool:\n        return int(self) > int(other)\n\n    def __ge__(self, other) -> bool:\n        return int(self) >= int(other)\n\n    def __lt__(self, other) -> bool:\n        return int(self) < int(other)\n\n    def __le__(self, other) -> bool:\n        return int(self) <= int(other)\n\n    def __int__(self) -> int:\n        \"\"\"Cast to smallest denomination\"\"\"\n        return int(self.to_units())\n\n    def __round__(self, decimals: int = 0):\n        return self.__class__.from_tokens(round(self.to_tokens(), decimals))\n\n    def __repr__(self) -> str:\n        r = f'{self._symbol}(value={str(self.__value)})'\n        return r\n\n    def __str__(self) -> str:\n        return f'{str(self.to_tokens())} {self._symbol}'",
  "class NU(ERC20):\n    _symbol = 'NU'\n    _denominations = {'NuNit': 'wei', 'NU': 'ether'}\n    _unit_name = 'NuNit'\n    _unit = NuNits",
  "class TToken(ERC20):\n    _symbol = 'T'\n    _denominations = {'TuNit': 'wei', 'T': 'ether'}\n    _unit_name = 'TuNit'\n    _unit = TuNits",
  "class WorkTrackerBase:\n    \"\"\"Baseclass for handling automated transaction tracking...\"\"\"\n\n    CLOCK = reactor\n    INTERVAL_FLOOR = 60 * 15  # fifteen minutes\n    INTERVAL_CEIL = 60 * 180  # three hours\n\n    ALLOWED_DEVIATION = 0.5  # i.e., up to +50% from the expected confirmation time\n\n    def __init__(self, worker, *args, **kwargs):\n\n        super().__init__(*args, **kwargs)\n        self.log = Logger('stake-tracker')\n        self.worker = worker   # TODO: What to call the subject here?  What is a work tracker without \"work\"?\n\n        self._tracking_task = task.LoopingCall(self._do_work)\n        self._tracking_task.clock = self.CLOCK\n\n        self.__pending = dict()  # TODO: Prime with pending worker transactions\n        self.__requirement = None\n        self.__start_time = NOT_STAKING\n        self.__uptime_period = NOT_STAKING\n        self._abort_on_error = False\n\n        self._consecutive_fails = 0\n\n        self._configure(*args)\n        self.gas_strategy = worker.application_agent.blockchain.gas_strategy\n\n    @classmethod\n    def random_interval(cls, fails=None) -> int:\n        if fails is not None and fails > 0:\n            return cls.INTERVAL_FLOOR\n        return random.randint(cls.INTERVAL_FLOOR, cls.INTERVAL_CEIL)\n\n    def max_confirmation_time(self) -> int:\n        expected_time = EXPECTED_CONFIRMATION_TIME_IN_SECONDS[self.gas_strategy]  # FIXME: #2447\n        result = expected_time * (1 + self.ALLOWED_DEVIATION)\n        return result\n\n    def stop(self) -> None:\n        if self._tracking_task.running:\n            self._tracking_task.stop()\n            self.log.info(f\"STOPPED WORK TRACKING\")\n\n    def start(self, commit_now: bool = True, requirement_func: Callable = None, force: bool = False) -> None:\n        \"\"\"\n        High-level stake tracking initialization, this function aims\n        to be safely called at any time - For example, it is okay to call\n        this function multiple times within the same period.\n        \"\"\"\n\n        if self._tracking_task.running and not force:\n            return\n\n        # Add optional confirmation requirement callable\n        self.__requirement = requirement_func\n\n        # Record the start time and period\n        self.__start_time = maya.now()\n\n        self.log.info(f\"START WORK TRACKING (immediate action: {commit_now})\")\n        d = self._tracking_task.start(interval=self.random_interval(fails=self._consecutive_fails), now=commit_now)\n        d.addErrback(self.handle_working_errors)\n\n    def _crash_gracefully(self, failure=None) -> None:\n        \"\"\"\n        A facility for crashing more gracefully in the event that\n        an exception is unhandled in a different thread.\n        \"\"\"\n        self._crashed = failure\n        failure.raiseException()\n\n    def handle_working_errors(self, *args, **kwargs) -> None:\n        failure = args[0]\n        if self._abort_on_error:\n            self.log.critical(f'Unhandled error during node work tracking. {failure!r}',\n                              failure=failure)\n            self.stop()\n            reactor.callFromThread(self._crash_gracefully, failure=failure)\n        else:\n            self.log.warn(f'Unhandled error during work tracking (#{self._consecutive_fails}): {failure.getTraceback()!r}',\n                          failure=failure)\n\n            # the effect of this is that we get one immediate retry.\n            # After that, the random_interval will be honored until\n            # success is achieved\n            commit_now = self._consecutive_fails < 1\n            self._consecutive_fails += 1\n            self.start(commit_now=commit_now)\n\n    def _should_do_work_now(self) -> bool:\n        # TODO: Check for stake expiration and exit\n        if self.__requirement is None:\n            return True\n        r = self.__requirement(self.worker)\n        if not isinstance(r, bool):\n            raise ValueError(f\"'requirement' must return a boolean.\")\n        return r\n\n    @property\n    def pending(self) -> Dict[int, HexBytes]:\n        return self.__pending.copy()\n\n    def __commitments_tracker_is_consistent(self) -> bool:\n        operator_address = self.worker.operator_address\n        tx_count_pending = self.client.get_transaction_count(account=operator_address, pending=True)\n        tx_count_latest = self.client.get_transaction_count(account=operator_address, pending=False)\n        txs_in_mempool = tx_count_pending - tx_count_latest\n\n        if len(self.__pending) == txs_in_mempool:\n            return True  # OK!\n\n        if txs_in_mempool > len(self.__pending):  # We're missing some pending TXs\n            return False\n        else:  # TODO #2429: What to do when txs_in_mempool < len(self.__pending)? What does this imply?\n            return True\n\n    def __track_pending_commitments(self) -> bool:\n        # TODO: Keep a purpose-built persistent log of worker transaction history\n\n        unmined_transactions = 0\n        pending_transactions = self.pending.items()    # note: this must be performed non-mutatively\n        for tx_firing_block_number, txhash in sorted(pending_transactions):\n            if txhash is UNTRACKED_PENDING_TRANSACTION:\n                unmined_transactions += 1\n                continue\n\n            try:\n                confirmed_tx_receipt = self.client.get_transaction_receipt(transaction_hash=txhash)\n            except TransactionNotFound:\n                unmined_transactions += 1  # mark as unmined - Keep tracking it for now\n                continue\n            else:\n                confirmation_block_number = confirmed_tx_receipt['blockNumber']\n                confirmations = confirmation_block_number - tx_firing_block_number\n                self.log.info(f'Commitment transaction {txhash.hex()[:10]} confirmed: {confirmations} confirmations')\n                del self.__pending[tx_firing_block_number]\n\n        if unmined_transactions:\n            s = \"s\" if unmined_transactions > 1 else \"\"\n            self.log.info(f'{unmined_transactions} pending commitment transaction{s} detected.')\n\n        inconsistent_tracker = not self.__commitments_tracker_is_consistent()\n        if inconsistent_tracker:\n            # If we detect there's a mismatch between the number of internally tracked and\n            # pending block transactions, create a special pending TX that accounts for this.\n            # TODO: Detect if this untracked pending transaction is a commitment transaction at all.\n            self.__pending[0] = UNTRACKED_PENDING_TRANSACTION\n            return True\n\n        return bool(self.__pending)\n\n    def __fire_replacement_commitment(self, current_block_number: int, tx_firing_block_number: int) -> None:\n        replacement_txhash = self._fire_commitment()  # replace\n        self.__pending[current_block_number] = replacement_txhash  # track this transaction\n        del self.__pending[tx_firing_block_number]  # assume our original TX is stuck\n\n    def __handle_replacement_commitment(self, current_block_number: int) -> None:\n        tx_firing_block_number, txhash = list(sorted(self.pending.items()))[0]\n        if txhash is UNTRACKED_PENDING_TRANSACTION:\n            # TODO: Detect if this untracked pending transaction is a commitment transaction at all.\n            message = f\"We have an untracked pending transaction. Issuing a replacement transaction.\"\n        else:\n            # If the transaction is still not mined after a max confirmation time\n            # (based on current gas strategy) issue a replacement transaction.\n            wait_time_in_blocks = current_block_number - tx_firing_block_number\n            wait_time_in_seconds = wait_time_in_blocks * AVERAGE_BLOCK_TIME_IN_SECONDS\n            if wait_time_in_seconds < self.max_confirmation_time():\n                self.log.info(f'Waiting for pending commitment transaction to be mined ({txhash.hex()}).')\n                return\n            else:\n                message = f\"We've waited for {wait_time_in_seconds}, but max time is {self.max_confirmation_time()}\" \\\n                          f\" for {self.gas_strategy} gas strategy. Issuing a replacement transaction.\"\n\n        # Send a replacement transaction\n        self.log.info(message)\n        self.__fire_replacement_commitment(current_block_number=current_block_number,\n                                           tx_firing_block_number=tx_firing_block_number)\n\n    def __reset_tracker_state(self) -> None:\n        self.__pending.clear()  # Forget the past. This is a new beginning.\n        self._consecutive_fails = 0\n\n    def _do_work(self) -> None:\n        \"\"\"\n        Async working task for Ursula  # TODO: Split into multiple async tasks\n        \"\"\"\n        if self._all_work_completed():\n            # nothing left to do\n            self.stop()\n            return\n\n        self.log.info(f\"{self.__class__.__name__} is running. Advancing to next work cycle.\")  # TODO: What to call the verb the subject performs?\n\n        # Call once here, and inject later for temporal consistency\n        current_block_number = self.client.block_number\n\n        if self._prep_work_state() is False:\n            return\n\n        # Commitment tracking\n        unmined_transactions = self.__track_pending_commitments()\n        if unmined_transactions:\n            self.log.info('Tracking pending transaction.')\n            self.__handle_replacement_commitment(current_block_number=current_block_number)\n            # while there are known pending transactions, remain in fast interval mode\n            self._tracking_task.interval = self.INTERVAL_FLOOR\n            return  # This cycle is finished.\n        else:\n            # Randomize the next task interval over time, within bounds.\n            self._tracking_task.interval = self.random_interval(fails=self._consecutive_fails)\n\n        # Only perform work this round if the requirements are met\n        if not self._should_do_work_now():\n            self.log.warn(f'COMMIT PREVENTED (callable: \"{self.__requirement.__name__}\") - '\n                          f'Situation does not call for doing work now.')\n\n            # TODO: Follow-up actions for failed requirements\n            return\n\n        if self._final_work_prep_before_transaction() is False:\n            return\n\n        txhash = self._fire_commitment()\n        self.__pending[current_block_number] = txhash\n\n    #  the following four methods are specific to PRE network schemes and must be implemented as below\n    def _configure(self, stakes):\n        \"\"\" post __init__ configuration dealing with contracts or state specific to this PRE flavor\"\"\"\n        raise NotImplementedError\n\n    def _prep_work_state(self) -> bool:\n        \"\"\" configuration perfomed before transaction management in task execution \"\"\"\n        raise NotImplementedError\n\n    def _final_work_prep_before_transaction(self) -> bool:\n        \"\"\" configuration perfomed after transaction management in task execution right before transaction firing\"\"\"\n        raise NotImplementedError()\n\n    def _fire_commitment(self):\n        \"\"\" actually fire the tranasction \"\"\"\n        raise NotImplementedError\n\n    def _all_work_completed(self) -> bool:\n        \"\"\" allows the work tracker to indicate that its work is completed and it can be shut down \"\"\"\n        raise NotImplementedError",
  "class WorkTracker(WorkTrackerBase):\n\n    INTERVAL_FLOOR = 1\n    INTERVAL_CEIL = 2\n\n    def _configure(self, *args):\n        self.application_agent = self.worker.application_agent\n        self.client = self.application_agent.blockchain.client\n\n    def _prep_work_state(self):\n        return True\n\n    def _final_work_prep_before_transaction(self):\n        should_continue = self.worker.get_staking_provider_address() != NULL_ADDRESS\n        if should_continue:\n            return True\n        self.log.warn('COMMIT PREVENTED - Operator is not bonded to a staking provider.')\n        return False\n\n    def _fire_commitment(self):\n        \"\"\"Makes an initial/replacement operator commitment transaction\"\"\"\n        transacting_power = self.worker.transacting_power\n        with transacting_power:\n            txhash = self.worker.confirm_address(fire_and_forget=True)  # < --- blockchain WRITE\n            self.log.info(f\"Confirming operator address {self.worker.operator_address} with staking provider {self.worker.staking_provider_address} - TxHash: {txhash.hex()}\")\n            return txhash\n\n    def _all_work_completed(self) -> bool:\n        # only a one-and-done - work is no longer needed\n        return not self._should_do_work_now()",
  "class InvalidAmount(ValueError):\n        \"\"\"Raised when an invalid input amount is provided\"\"\"",
  "class InvalidDenomination(ValueError):\n        \"\"\"Raised when an unknown denomination string is passed into __init__\"\"\"",
  "def __init__(self, value: Union[int, Decimal, str], denomination: str):\n        # super().__init__()\n        # Lookup Conversion\n        try:\n            wrapped_denomination = self._denominations[denomination]\n        except KeyError:\n            raise self.InvalidDenomination(f'\"{denomination}\"')\n\n        # Convert or Raise\n        try:\n            self.__value = currency.to_wei(number=value, unit=wrapped_denomination)\n        except ValueError as e:\n            raise self.__class__.InvalidAmount(f\"{value} is an invalid amount of tokens: {str(e)}\")",
  "def ZERO(cls) -> 'ERC20':\n        return cls(0, cls._unit_name)",
  "def from_units(cls, value: int) -> 'ERC20':\n        return cls(value, denomination=cls._unit_name)",
  "def from_tokens(cls, value: Union[int, Decimal, str]) -> 'ERC20':\n        return cls(value, denomination=cls._symbol)",
  "def to_tokens(self) -> Decimal:\n        \"\"\"Returns a decimal value of NU\"\"\"\n        return currency.from_wei(self.__value, unit='ether')",
  "def to_units(self) -> ERC20UNits:\n        \"\"\"Returns an int value in the Unit class for this token\"\"\"\n        return self.__class__._unit(self.__value)",
  "def __eq__(self, other) -> bool:\n        return int(self) == int(other)",
  "def __bool__(self) -> bool:\n        if self.__value == 0:\n            return False\n        else:\n            return True",
  "def __radd__(self, other) -> 'ERC20':\n        return self.__class__(int(self) + int(other), self._unit_name)",
  "def __add__(self, other) -> 'ERC20':\n        return self.__class__(int(self) + int(other), self._unit_name)",
  "def __sub__(self, other) -> 'ERC20':\n        return self.__class__(int(self) - int(other), self._unit_name)",
  "def __rmul__(self, other) -> 'ERC20':\n        return self.__class__(int(self) * int(other), self._unit_name)",
  "def __mul__(self, other) -> 'ERC20':\n        return self.__class__(int(self) * int(other), self._unit_name)",
  "def __floordiv__(self, other) -> 'ERC20':\n        return self.__class__(int(self) // int(other), self._unit_name)",
  "def __gt__(self, other) -> bool:\n        return int(self) > int(other)",
  "def __ge__(self, other) -> bool:\n        return int(self) >= int(other)",
  "def __lt__(self, other) -> bool:\n        return int(self) < int(other)",
  "def __le__(self, other) -> bool:\n        return int(self) <= int(other)",
  "def __int__(self) -> int:\n        \"\"\"Cast to smallest denomination\"\"\"\n        return int(self.to_units())",
  "def __round__(self, decimals: int = 0):\n        return self.__class__.from_tokens(round(self.to_tokens(), decimals))",
  "def __repr__(self) -> str:\n        r = f'{self._symbol}(value={str(self.__value)})'\n        return r",
  "def __str__(self) -> str:\n        return f'{str(self.to_tokens())} {self._symbol}'",
  "def __init__(self, worker, *args, **kwargs):\n\n        super().__init__(*args, **kwargs)\n        self.log = Logger('stake-tracker')\n        self.worker = worker   # TODO: What to call the subject here?  What is a work tracker without \"work\"?\n\n        self._tracking_task = task.LoopingCall(self._do_work)\n        self._tracking_task.clock = self.CLOCK\n\n        self.__pending = dict()  # TODO: Prime with pending worker transactions\n        self.__requirement = None\n        self.__start_time = NOT_STAKING\n        self.__uptime_period = NOT_STAKING\n        self._abort_on_error = False\n\n        self._consecutive_fails = 0\n\n        self._configure(*args)\n        self.gas_strategy = worker.application_agent.blockchain.gas_strategy",
  "def random_interval(cls, fails=None) -> int:\n        if fails is not None and fails > 0:\n            return cls.INTERVAL_FLOOR\n        return random.randint(cls.INTERVAL_FLOOR, cls.INTERVAL_CEIL)",
  "def max_confirmation_time(self) -> int:\n        expected_time = EXPECTED_CONFIRMATION_TIME_IN_SECONDS[self.gas_strategy]  # FIXME: #2447\n        result = expected_time * (1 + self.ALLOWED_DEVIATION)\n        return result",
  "def stop(self) -> None:\n        if self._tracking_task.running:\n            self._tracking_task.stop()\n            self.log.info(f\"STOPPED WORK TRACKING\")",
  "def start(self, commit_now: bool = True, requirement_func: Callable = None, force: bool = False) -> None:\n        \"\"\"\n        High-level stake tracking initialization, this function aims\n        to be safely called at any time - For example, it is okay to call\n        this function multiple times within the same period.\n        \"\"\"\n\n        if self._tracking_task.running and not force:\n            return\n\n        # Add optional confirmation requirement callable\n        self.__requirement = requirement_func\n\n        # Record the start time and period\n        self.__start_time = maya.now()\n\n        self.log.info(f\"START WORK TRACKING (immediate action: {commit_now})\")\n        d = self._tracking_task.start(interval=self.random_interval(fails=self._consecutive_fails), now=commit_now)\n        d.addErrback(self.handle_working_errors)",
  "def _crash_gracefully(self, failure=None) -> None:\n        \"\"\"\n        A facility for crashing more gracefully in the event that\n        an exception is unhandled in a different thread.\n        \"\"\"\n        self._crashed = failure\n        failure.raiseException()",
  "def handle_working_errors(self, *args, **kwargs) -> None:\n        failure = args[0]\n        if self._abort_on_error:\n            self.log.critical(f'Unhandled error during node work tracking. {failure!r}',\n                              failure=failure)\n            self.stop()\n            reactor.callFromThread(self._crash_gracefully, failure=failure)\n        else:\n            self.log.warn(f'Unhandled error during work tracking (#{self._consecutive_fails}): {failure.getTraceback()!r}',\n                          failure=failure)\n\n            # the effect of this is that we get one immediate retry.\n            # After that, the random_interval will be honored until\n            # success is achieved\n            commit_now = self._consecutive_fails < 1\n            self._consecutive_fails += 1\n            self.start(commit_now=commit_now)",
  "def _should_do_work_now(self) -> bool:\n        # TODO: Check for stake expiration and exit\n        if self.__requirement is None:\n            return True\n        r = self.__requirement(self.worker)\n        if not isinstance(r, bool):\n            raise ValueError(f\"'requirement' must return a boolean.\")\n        return r",
  "def pending(self) -> Dict[int, HexBytes]:\n        return self.__pending.copy()",
  "def __commitments_tracker_is_consistent(self) -> bool:\n        operator_address = self.worker.operator_address\n        tx_count_pending = self.client.get_transaction_count(account=operator_address, pending=True)\n        tx_count_latest = self.client.get_transaction_count(account=operator_address, pending=False)\n        txs_in_mempool = tx_count_pending - tx_count_latest\n\n        if len(self.__pending) == txs_in_mempool:\n            return True  # OK!\n\n        if txs_in_mempool > len(self.__pending):  # We're missing some pending TXs\n            return False\n        else:  # TODO #2429: What to do when txs_in_mempool < len(self.__pending)? What does this imply?\n            return True",
  "def __track_pending_commitments(self) -> bool:\n        # TODO: Keep a purpose-built persistent log of worker transaction history\n\n        unmined_transactions = 0\n        pending_transactions = self.pending.items()    # note: this must be performed non-mutatively\n        for tx_firing_block_number, txhash in sorted(pending_transactions):\n            if txhash is UNTRACKED_PENDING_TRANSACTION:\n                unmined_transactions += 1\n                continue\n\n            try:\n                confirmed_tx_receipt = self.client.get_transaction_receipt(transaction_hash=txhash)\n            except TransactionNotFound:\n                unmined_transactions += 1  # mark as unmined - Keep tracking it for now\n                continue\n            else:\n                confirmation_block_number = confirmed_tx_receipt['blockNumber']\n                confirmations = confirmation_block_number - tx_firing_block_number\n                self.log.info(f'Commitment transaction {txhash.hex()[:10]} confirmed: {confirmations} confirmations')\n                del self.__pending[tx_firing_block_number]\n\n        if unmined_transactions:\n            s = \"s\" if unmined_transactions > 1 else \"\"\n            self.log.info(f'{unmined_transactions} pending commitment transaction{s} detected.')\n\n        inconsistent_tracker = not self.__commitments_tracker_is_consistent()\n        if inconsistent_tracker:\n            # If we detect there's a mismatch between the number of internally tracked and\n            # pending block transactions, create a special pending TX that accounts for this.\n            # TODO: Detect if this untracked pending transaction is a commitment transaction at all.\n            self.__pending[0] = UNTRACKED_PENDING_TRANSACTION\n            return True\n\n        return bool(self.__pending)",
  "def __fire_replacement_commitment(self, current_block_number: int, tx_firing_block_number: int) -> None:\n        replacement_txhash = self._fire_commitment()  # replace\n        self.__pending[current_block_number] = replacement_txhash  # track this transaction\n        del self.__pending[tx_firing_block_number]",
  "def __handle_replacement_commitment(self, current_block_number: int) -> None:\n        tx_firing_block_number, txhash = list(sorted(self.pending.items()))[0]\n        if txhash is UNTRACKED_PENDING_TRANSACTION:\n            # TODO: Detect if this untracked pending transaction is a commitment transaction at all.\n            message = f\"We have an untracked pending transaction. Issuing a replacement transaction.\"\n        else:\n            # If the transaction is still not mined after a max confirmation time\n            # (based on current gas strategy) issue a replacement transaction.\n            wait_time_in_blocks = current_block_number - tx_firing_block_number\n            wait_time_in_seconds = wait_time_in_blocks * AVERAGE_BLOCK_TIME_IN_SECONDS\n            if wait_time_in_seconds < self.max_confirmation_time():\n                self.log.info(f'Waiting for pending commitment transaction to be mined ({txhash.hex()}).')\n                return\n            else:\n                message = f\"We've waited for {wait_time_in_seconds}, but max time is {self.max_confirmation_time()}\" \\\n                          f\" for {self.gas_strategy} gas strategy. Issuing a replacement transaction.\"\n\n        # Send a replacement transaction\n        self.log.info(message)\n        self.__fire_replacement_commitment(current_block_number=current_block_number,\n                                           tx_firing_block_number=tx_firing_block_number)",
  "def __reset_tracker_state(self) -> None:\n        self.__pending.clear()  # Forget the past. This is a new beginning.\n        self._consecutive_fails = 0",
  "def _do_work(self) -> None:\n        \"\"\"\n        Async working task for Ursula  # TODO: Split into multiple async tasks\n        \"\"\"\n        if self._all_work_completed():\n            # nothing left to do\n            self.stop()\n            return\n\n        self.log.info(f\"{self.__class__.__name__} is running. Advancing to next work cycle.\")  # TODO: What to call the verb the subject performs?\n\n        # Call once here, and inject later for temporal consistency\n        current_block_number = self.client.block_number\n\n        if self._prep_work_state() is False:\n            return\n\n        # Commitment tracking\n        unmined_transactions = self.__track_pending_commitments()\n        if unmined_transactions:\n            self.log.info('Tracking pending transaction.')\n            self.__handle_replacement_commitment(current_block_number=current_block_number)\n            # while there are known pending transactions, remain in fast interval mode\n            self._tracking_task.interval = self.INTERVAL_FLOOR\n            return  # This cycle is finished.\n        else:\n            # Randomize the next task interval over time, within bounds.\n            self._tracking_task.interval = self.random_interval(fails=self._consecutive_fails)\n\n        # Only perform work this round if the requirements are met\n        if not self._should_do_work_now():\n            self.log.warn(f'COMMIT PREVENTED (callable: \"{self.__requirement.__name__}\") - '\n                          f'Situation does not call for doing work now.')\n\n            # TODO: Follow-up actions for failed requirements\n            return\n\n        if self._final_work_prep_before_transaction() is False:\n            return\n\n        txhash = self._fire_commitment()\n        self.__pending[current_block_number] = txhash",
  "def _configure(self, stakes):\n        \"\"\" post __init__ configuration dealing with contracts or state specific to this PRE flavor\"\"\"\n        raise NotImplementedError",
  "def _prep_work_state(self) -> bool:\n        \"\"\" configuration perfomed before transaction management in task execution \"\"\"\n        raise NotImplementedError",
  "def _final_work_prep_before_transaction(self) -> bool:\n        \"\"\" configuration perfomed after transaction management in task execution right before transaction firing\"\"\"\n        raise NotImplementedError()",
  "def _fire_commitment(self):\n        \"\"\" actually fire the tranasction \"\"\"\n        raise NotImplementedError",
  "def _all_work_completed(self) -> bool:\n        \"\"\" allows the work tracker to indicate that its work is completed and it can be shut down \"\"\"\n        raise NotImplementedError",
  "def _configure(self, *args):\n        self.application_agent = self.worker.application_agent\n        self.client = self.application_agent.blockchain.client",
  "def _prep_work_state(self):\n        return True",
  "def _final_work_prep_before_transaction(self):\n        should_continue = self.worker.get_staking_provider_address() != NULL_ADDRESS\n        if should_continue:\n            return True\n        self.log.warn('COMMIT PREVENTED - Operator is not bonded to a staking provider.')\n        return False",
  "def _fire_commitment(self):\n        \"\"\"Makes an initial/replacement operator commitment transaction\"\"\"\n        transacting_power = self.worker.transacting_power\n        with transacting_power:\n            txhash = self.worker.confirm_address(fire_and_forget=True)  # < --- blockchain WRITE\n            self.log.info(f\"Confirming operator address {self.worker.operator_address} with staking provider {self.worker.staking_provider_address} - TxHash: {txhash.hex()}\")\n            return txhash",
  "def _all_work_completed(self) -> bool:\n        # only a one-and-done - work is no longer needed\n        return not self._should_do_work_now()",
  "class VersionedContract(Contract):\n    version = None",
  "class BlockchainInterface:\n    \"\"\"\n    Interacts with a solidity compiler and a registry in order to instantiate compiled\n    ethereum contracts with the given web3 provider backend.\n    \"\"\"\n\n    TIMEOUT = 600  # seconds  # TODO: Correlate with the gas strategy - #2070\n\n    DEFAULT_GAS_STRATEGY = 'fast'\n    GAS_STRATEGIES = WEB3_GAS_STRATEGIES\n\n    Web3 = Web3  # TODO: This is name-shadowing the actual Web3. Is this intentional?\n\n    _CONTRACT_FACTORY = VersionedContract\n\n    class InterfaceError(Exception):\n        pass\n\n    class NoProvider(InterfaceError):\n        pass\n\n    class UnsupportedProvider(InterfaceError):\n        pass\n\n    class ConnectionFailed(InterfaceError):\n        pass\n\n    class UnknownContract(InterfaceError):\n        pass\n\n    REASONS = {\n        INSUFFICIENT_ETH: 'insufficient funds for gas * price + value',\n    }\n\n    class TransactionFailed(InterfaceError):\n\n        IPC_CODE = -32000\n\n        def __init__(self,\n                     message: str,\n                     transaction_dict: dict,\n                     contract_function: Union[ContractFunction, ContractConstructor],\n                     *args):\n\n            self.base_message = message\n            self.name = get_transaction_name(contract_function=contract_function)\n            self.payload = transaction_dict\n            self.contract_function = contract_function\n            self.failures = {\n                BlockchainInterface.REASONS[INSUFFICIENT_ETH]: self.insufficient_eth\n            }\n            self.message = self.failures.get(self.base_message, self.default)\n            super().__init__(self.message, *args)\n\n        @property\n        def default(self) -> str:\n            sender = self.payload[\"from\"]\n            message = f'{self.name} from {sender[:6]}... \\n' \\\n                      f'Sender balance: {prettify_eth_amount(self.get_balance())} \\n' \\\n                      f'Reason: {self.base_message} \\n' \\\n                      f'Transaction: {self.payload}'\n            return message\n\n        def get_balance(self):\n            blockchain = BlockchainInterfaceFactory.get_interface()\n            balance = blockchain.client.get_balance(account=self.payload['from'])\n            return balance\n\n        @property\n        def insufficient_eth(self) -> str:\n            try:\n                transaction_fee = self.payload['gas'] * self.payload['gasPrice']\n            except KeyError:\n                return self.default\n            else:\n                cost = transaction_fee + self.payload.get('value', 0)\n                message = f'{self.name} from {self.payload[\"from\"][:8]} - {self.base_message}.' \\\n                          f'Calculated cost is {prettify_eth_amount(cost)},' \\\n                          f'but sender only has {prettify_eth_amount(self.get_balance())}.'\n            return message\n\n    def __init__(self,\n                 emitter=None,  # TODO # 1754\n                 poa: bool = None,\n                 light: bool = False,\n                 eth_provider_uri: str = NO_BLOCKCHAIN_CONNECTION,\n                 eth_provider: BaseProvider = NO_BLOCKCHAIN_CONNECTION,\n                 gas_strategy: Optional[Union[str, Callable]] = None,\n                 max_gas_price: Optional[int] = None):\n\n        \"\"\"\n        TODO: #1502 - Move to API docs.\n\n         Filesystem          Configuration           Node              Client                  EVM\n        ================ ====================== =============== =====================  ===========================\n\n         Solidity Files -- SolidityCompiler -                      --- HTTPProvider ------ ...\n                                            |                    |\n                                            |                    |\n                                            |                    |\n                                            - *BlockchainInterface* -- IPCProvider ----- External EVM (geth, parity...)\n                                                       |         |\n                                                       |         |\n                                                 TestProvider ----- EthereumTester -------------\n                                                                                                |\n                                                                                                |\n                                                                                        PyEVM (Development Chain)\n\n         ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n         Runtime Files --                 --BlockchainInterface ----> Registry\n                        |                |             ^\n                        |                |             |\n                        |                |             |\n         Key Files ------ CharacterConfiguration     Agent                          ... (Contract API)\n                        |                |             ^\n                        |                |             |\n                        |                |             |\n                        |                |           Actor                          ...Blockchain-Character API)\n                        |                |             ^\n                        |                |             |\n                        |                |             |\n         Config File ---                  --------- Character                       ... (Public API)\n                                                       ^\n                                                       |\n                                                     Human\n\n\n        The Blockchain is the junction of the solidity compiler, a contract registry, and a collection of\n        web3 network providers as a means of interfacing with the ethereum blockchain to execute\n        or deploy contract code on the network.\n\n\n        Compiler and Registry Usage\n        -----------------------------\n\n        Contracts are freshly re-compiled if an instance of SolidityCompiler is passed; otherwise,\n        The registry will read contract data saved to disk that is be used to retrieve contact address and op-codes.\n        Optionally, A registry instance can be passed instead.\n\n\n        Provider Usage\n        ---------------\n        https: // github.com / ethereum / eth - tester     # available-backends\n\n\n        * HTTP Provider - Web3 HTTP provider, typically JSON RPC 2.0 over HTTP\n        * Websocket Provider - Web3 WS provider, typically JSON RPC 2.0 over WS, supply endpoint uri and websocket=True\n        * IPC Provider - Web3 File based IPC provider transported over standard I/O\n        * Custom Provider - A pre-initialized web3.py provider instance to attach to this interface\n\n        \"\"\"\n\n        self.log = Logger('Blockchain')\n        self.poa = poa\n        self.eth_provider_uri = eth_provider_uri\n        self._eth_provider = eth_provider\n        self.w3 = NO_BLOCKCHAIN_CONNECTION\n        self.client = NO_BLOCKCHAIN_CONNECTION\n        self.is_light = light\n\n        # TODO: Not ready to give users total flexibility. Let's stick for the moment to known values. See #2447\n        if gas_strategy not in ('slow', 'medium', 'fast', 'free', None):  # FIXME: What is 'None' doing here?\n            raise ValueError(f\"'{gas_strategy}' is an invalid gas strategy\")\n        self.gas_strategy = gas_strategy or self.DEFAULT_GAS_STRATEGY\n        self.max_gas_price = max_gas_price\n\n    def __repr__(self):\n        r = '{name}({uri})'.format(name=self.__class__.__name__, uri=self.eth_provider_uri)\n        return r\n\n    def get_blocktime(self):\n        return self.client.get_blocktime()\n\n    @property\n    def is_connected(self) -> bool:\n        \"\"\"\n        https://web3py.readthedocs.io/en/stable/__provider.html#examples-using-automated-detection\n        \"\"\"\n        if self.client is NO_BLOCKCHAIN_CONNECTION:\n            return False\n        return self.client.is_connected\n\n    @classmethod\n    def get_gas_strategy(cls, gas_strategy: Union[str, Callable] = None) -> Callable:\n        try:\n            gas_strategy = cls.GAS_STRATEGIES[gas_strategy]\n        except KeyError:\n            if gas_strategy:\n                if not callable(gas_strategy):\n                    raise ValueError(f\"{gas_strategy} must be callable to be a valid gas strategy.\")\n            else:\n                gas_strategy = cls.GAS_STRATEGIES[cls.DEFAULT_GAS_STRATEGY]\n        return gas_strategy\n\n    def attach_middleware(self):\n        chain_id = int(self.client.chain_id)\n        if self.poa is None:  # If POA is not set explicitly, try to autodetect from chain id\n            self.poa = chain_id in POA_CHAINS\n\n        self.log.debug(f'Ethereum chain: {self.client.chain_name} (chain_id={chain_id}, poa={self.poa})')\n\n        # For use with Proof-Of-Authority test-blockchains\n        if self.poa is True:\n            self.log.debug('Injecting POA middleware at layer 0')\n            self.client.inject_middleware(geth_poa_middleware, layer=0)\n\n        self.client.add_middleware(middleware.time_based_cache_middleware)\n        # self.client.add_middleware(middleware.latest_block_based_cache_middleware)  # TODO: This line causes failed tests and nonce reuse in tests. See #2348.\n        self.client.add_middleware(middleware.simple_cache_middleware)\n\n        self.configure_gas_strategy()\n\n    def configure_gas_strategy(self, gas_strategy: Optional[Callable] = None) -> None:\n\n        if gas_strategy:\n            reported_gas_strategy = f\"fixed/{gas_strategy.name}\"\n\n        elif isinstance(self.client, InfuraClient):\n            gas_strategy = construct_datafeed_median_strategy(speed=self.gas_strategy)\n            reported_gas_strategy = f\"datafeed/{self.gas_strategy}\"\n\n        else:\n            reported_gas_strategy = f\"web3/{self.gas_strategy}\"\n            gas_strategy = self.get_gas_strategy(self.gas_strategy)\n\n        configuration_message = f\"Using gas strategy '{reported_gas_strategy}'\"\n\n        if self.max_gas_price:\n            __price = Web3.to_wei(self.max_gas_price, 'gwei')  # from gwei to wei\n            gas_strategy = max_price_gas_strategy_wrapper(gas_strategy=gas_strategy, max_gas_price_wei=__price)\n            configuration_message += f\", with a max price of {self.max_gas_price} gwei.\"\n\n        self.client.set_gas_strategy(gas_strategy=gas_strategy)\n\n        # TODO: This line must not be called prior to establishing a connection\n        #        Move it down to a lower layer, near the client.\n        # gwei_gas_price = Web3.from_wei(self.client.gas_price_for_transaction(), 'gwei')\n\n        self.log.info(configuration_message)\n        # self.log.debug(f\"Gas strategy currently reports a gas price of {gwei_gas_price} gwei.\")\n\n    def connect(self):\n\n        eth_provider_uri = self.eth_provider_uri\n        self.log.info(f\"Using external Web3 Provider '{self.eth_provider_uri}'\")\n\n        # Attach Provider\n        self._attach_eth_provider(eth_provider=self._eth_provider, eth_provider_uri=eth_provider_uri)\n        self.log.info(\"Connecting to {}\".format(self.eth_provider_uri))\n        if self._eth_provider is NO_BLOCKCHAIN_CONNECTION:\n            raise self.NoProvider(\"There are no configured blockchain providers\")\n\n        # Connect if not connected\n        try:\n            self.w3 = self.Web3(provider=self._eth_provider)\n            self.client = EthereumClient.from_w3(w3=self.w3)\n        except requests.ConnectionError:  # RPC\n            raise self.ConnectionFailed(f'Connection Failed - {str(self.eth_provider_uri)} - is RPC enabled?')\n        except FileNotFoundError:         # IPC File Protocol\n            raise self.ConnectionFailed(f'Connection Failed - {str(self.eth_provider_uri)} - is IPC enabled?')\n        else:\n            self.attach_middleware()\n\n        return self.is_connected\n\n    @property\n    def provider(self) -> BaseProvider:\n        return self._eth_provider\n\n    def _attach_eth_provider(self,\n                             eth_provider: Optional[BaseProvider] = None,\n                             eth_provider_uri: str = None) -> None:\n        \"\"\"\n        https://web3py.readthedocs.io/en/latest/providers.html#providers\n        \"\"\"\n\n        if not eth_provider_uri and not eth_provider:\n            raise self.NoProvider(\"No URI or provider instances supplied.\")\n\n        if eth_provider_uri and not eth_provider:\n            uri_breakdown = urlparse(eth_provider_uri)\n\n            if uri_breakdown.scheme == 'tester':\n                providers = {\n                    'pyevm': _get_pyevm_test_provider,\n                    'mock': _get_mock_test_provider\n                }\n                provider_scheme = uri_breakdown.netloc\n\n            else:\n                providers = {\n                    'auto': _get_auto_provider,\n                    'ipc': _get_IPC_provider,\n                    'file': _get_IPC_provider,\n                    'ws': _get_websocket_provider,\n                    'wss': _get_websocket_provider,\n                    'http': _get_HTTP_provider,\n                    'https': _get_HTTP_provider,\n                }\n                provider_scheme = uri_breakdown.scheme\n\n            # auto-detect for file based ipc\n            if not provider_scheme:\n                if Path(eth_provider_uri).is_file():\n                    # file is available - assume ipc/file scheme\n                    provider_scheme = 'file'\n                    self.log.info(f\"Auto-detected provider scheme as 'file://' for provider {eth_provider_uri}\")\n\n            try:\n                self._eth_provider = providers[provider_scheme](eth_provider_uri)\n            except KeyError:\n                raise self.UnsupportedProvider(f\"{eth_provider_uri} is an invalid or unsupported blockchain provider URI\")\n            else:\n                self.eth_provider_uri = eth_provider_uri or NO_BLOCKCHAIN_CONNECTION\n        else:\n            self._eth_provider = eth_provider\n\n    @classmethod\n    def _handle_failed_transaction(cls,\n                                   exception: Exception,\n                                   transaction_dict: dict,\n                                   contract_function: Union[ContractFunction, ContractConstructor],\n                                   logger: Logger = None\n                                   ) -> None:\n        \"\"\"\n        Re-raising error handler and context manager for transaction broadcast or\n        build failure events at the interface layer. This method is a last line of defense\n        against unhandled exceptions caused by transaction failures and must raise an exception.\n        # TODO: #1504 - Additional Handling of validation failures (gas limits, invalid fields, etc.)\n        \"\"\"\n\n        response = exception.args[0]\n\n        # Assume this error is formatted as an RPC response\n        try:\n            code = int(response['code'])\n            message = response['message']\n        except Exception:\n            # TODO: #1504 - Try even harder to determine if this is insufficient funds causing the issue,\n            #               This may be best handled at the agent or actor layer for registry and token interactions.\n            # Worst case scenario - raise the exception held in context implicitly\n            raise exception\n\n        if code != cls.TransactionFailed.IPC_CODE:\n            # Only handle client-specific exceptions\n            # https://www.jsonrpc.org/specification Section 5.1\n            raise exception\n\n        if logger:\n            logger.critical(message)  # simple context\n\n        transaction_failed = cls.TransactionFailed(message=message,  # rich error (best case)\n                                                   contract_function=contract_function,\n                                                   transaction_dict=transaction_dict)\n        raise transaction_failed from exception\n\n    def __log_transaction(self, transaction_dict: dict, contract_function: ContractFunction):\n        \"\"\"\n        Format and log a transaction dict and return the transaction name string.\n        This method *must not* mutate the original transaction dict.\n        \"\"\"\n        # Do not mutate the original transaction dict\n        tx = dict(transaction_dict).copy()\n\n        # Format\n        if tx.get('to'):\n            tx['to'] = to_checksum_address(contract_function.address)\n        try:\n            tx['selector'] = contract_function.selector\n        except AttributeError:\n            pass\n        tx['from'] = to_checksum_address(tx['from'])\n        tx.update({f: prettify_eth_amount(v) for f, v in tx.items() if f in ('gasPrice', 'value')})\n        payload_pprint = ', '.join(\"{}: {}\".format(k, v) for k, v in tx.items())\n\n        # Log\n        transaction_name = get_transaction_name(contract_function=contract_function)\n        self.log.debug(f\"[TX-{transaction_name}] | {payload_pprint}\")\n\n    @validate_checksum_address\n    def build_payload(self,\n                      sender_address: str,\n                      payload: dict = None,\n                      transaction_gas_limit: int = None,\n                      use_pending_nonce: bool = True,\n                      ) -> dict:\n\n        nonce = self.client.get_transaction_count(account=sender_address, pending=use_pending_nonce)\n        base_payload = {'nonce': nonce, 'from': sender_address}\n\n        # Aggregate\n        if not payload:\n            payload = {}\n        payload.update(base_payload)\n        # Explicit gas override - will skip gas estimation in next operation.\n        if transaction_gas_limit:\n            payload['gas'] = int(transaction_gas_limit)\n        return payload\n\n    @validate_checksum_address\n    def build_contract_transaction(self,\n                                   contract_function: ContractFunction,\n                                   sender_address: str,\n                                   payload: dict = None,\n                                   transaction_gas_limit: Optional[int] = None,\n                                   gas_estimation_multiplier: Optional[float] = None,\n                                   use_pending_nonce: Optional[bool] = None,\n                                   ) -> dict:\n\n        if transaction_gas_limit is not None:\n            self.log.warn(\"The transaction gas limit of {transaction_gas_limit} will override gas estimation attempts\")\n\n        # Sanity checks for the gas estimation multiplier\n        if gas_estimation_multiplier is not None:\n            if not 1 <= gas_estimation_multiplier <= 3:  # Arbitrary upper bound.\n                raise ValueError(f\"The gas estimation multiplier should be a float between 1 and 3, \"\n                                 f\"but we received {gas_estimation_multiplier}.\")\n\n        payload = self.build_payload(sender_address=sender_address,\n                                     payload=payload,\n                                     transaction_gas_limit=transaction_gas_limit,\n                                     use_pending_nonce=use_pending_nonce)\n        self.__log_transaction(transaction_dict=payload, contract_function=contract_function)\n        try:\n            if 'gas' not in payload:  # i.e., transaction_gas_limit is not None\n                # As web3 build_transaction() will estimate gas with block identifier \"pending\" by default,\n                # explicitly estimate gas here with block identifier 'latest' if not otherwise specified\n                # as a pending transaction can cause gas estimation to fail, notably in case of worklock refunds.\n                payload['gas'] = contract_function.estimate_gas(payload, block_identifier='latest')\n            transaction_dict = contract_function.build_transaction(payload)\n        except (TestTransactionFailed, ValidationError, ValueError) as error:\n            # Note: Geth (1.9.15) raises ValueError in the same condition that pyevm raises ValidationError here.\n            # Treat this condition as \"Transaction Failed\" during gas estimation.\n            raise self._handle_failed_transaction(exception=error,\n                                                  transaction_dict=payload,\n                                                  contract_function=contract_function,\n                                                  logger=self.log)\n\n        # Increase the estimated gas limit according to the gas estimation multiplier, if any.\n        if gas_estimation_multiplier and not transaction_gas_limit:\n            gas_estimation = transaction_dict['gas']\n            overestimation = int(math.ceil(gas_estimation * gas_estimation_multiplier))\n            self.log.debug(f\"Gas limit for this TX was increased from {gas_estimation} to {overestimation}, \"\n                           f\"using a multiplier of {gas_estimation_multiplier}.\")\n            transaction_dict['gas'] = overestimation\n            # TODO: What if we're going over the block limit? Not likely, but perhaps worth checking (NRN)\n\n        return transaction_dict\n\n    def sign_and_broadcast_transaction(self,\n                                       transacting_power: TransactingPower,\n                                       transaction_dict: TransactionDict,\n                                       transaction_name: str = \"\",\n                                       confirmations: int = 0,\n                                       fire_and_forget: bool = False\n                                       ) -> Union[TxReceipt, HexBytes]:\n        \"\"\"\n        Takes a transaction dictionary, signs it with the configured signer, then broadcasts the signed\n        transaction using the ethereum provider's eth_sendRawTransaction RPC endpoint.\n        Optionally blocks for receipt and confirmation with 'confirmations', and 'fire_and_forget' flags.\n\n        If 'fire and forget' is True this method returns the transaction hash only, without waiting for a receipt -\n        otherwise return the transaction receipt.\n\n        \"\"\"\n        #\n        # Setup\n        #\n\n        # TODO # 1754 - Move this to singleton - I do not approve... nor does Bogdan?\n        if GlobalLoggerSettings._json_ipc:\n            emitter = JSONRPCStdoutEmitter()\n        else:\n            emitter = StdoutEmitter()\n\n        #\n        # Sign\n        #\n\n        # TODO: Show the USD Price:  https://api.coinmarketcap.com/v1/ticker/ethereum/\n        \n        try:\n            # post-london fork transactions (Type 2)\n            max_unit_price = transaction_dict['maxFeePerGas']\n            tx_type = 'EIP-1559'\n        except KeyError:\n            # pre-london fork \"legacy\" transactions (Type 0)\n            max_unit_price = transaction_dict['gasPrice']\n            tx_type = 'Legacy'\n\n        max_price_gwei = Web3.from_wei(max_unit_price, 'gwei')\n        max_cost_wei = max_unit_price * transaction_dict['gas']\n        max_cost = Web3.from_wei(max_cost_wei, 'ether')\n\n        if transacting_power.is_device:\n            emitter.message(f'Confirm transaction {transaction_name} on hardware wallet... '\n                            f'({max_cost} ETH @ {max_price_gwei} gwei)',\n                            color='yellow')\n        signed_raw_transaction = transacting_power.sign_transaction(transaction_dict)\n\n        #\n        # Broadcast\n        #\n        emitter.message(f'Broadcasting {transaction_name} {tx_type} Transaction ({max_cost} ETH @ {max_price_gwei} gwei)',\n                        color='yellow')\n        try:\n            txhash = self.client.send_raw_transaction(signed_raw_transaction)  # <--- BROADCAST\n            emitter.message(f'TXHASH {txhash.hex()}', color='yellow')\n        except (TestTransactionFailed, ValueError):\n            raise  # TODO: Unify with Transaction failed handling -- Entry point for _handle_failed_transaction\n        else:\n            if fire_and_forget:\n                return txhash\n\n        #\n        # Receipt\n        #\n\n        try:  # TODO: Handle block confirmation exceptions\n            waiting_for = 'receipt'\n            if confirmations:\n                waiting_for = f'{confirmations} confirmations'\n            emitter.message(f'Waiting {self.TIMEOUT} seconds for {waiting_for}', color='yellow')\n            receipt = self.client.wait_for_receipt(txhash, timeout=self.TIMEOUT, confirmations=confirmations)\n        except TimeExhausted:\n            # TODO: #1504 - Handle transaction timeout\n            raise\n        else:\n            self.log.debug(f\"[RECEIPT-{transaction_name}] | txhash: {receipt['transactionHash'].hex()}\")\n\n        #\n        # Confirmations\n        #\n\n        # Primary check\n        transaction_status = receipt.get('status', UNKNOWN_TX_STATUS)\n        if transaction_status == 0:\n            failure = f\"Transaction transmitted, but receipt returned status code 0. \" \\\n                      f\"Full receipt: \\n {pprint.pformat(receipt, indent=2)}\"\n            raise self.InterfaceError(failure)\n\n        if transaction_status is UNKNOWN_TX_STATUS:\n            self.log.info(f\"Unknown transaction status for {txhash} (receipt did not contain a status field)\")\n\n            # Secondary check\n            tx = self.client.get_transaction(txhash)\n            if tx[\"gas\"] == receipt[\"gasUsed\"]:\n                raise self.InterfaceError(f\"Transaction consumed 100% of transaction gas.\"\n                                          f\"Full receipt: \\n {pprint.pformat(receipt, indent=2)}\")\n\n        return receipt\n\n    @validate_checksum_address\n    def send_transaction(self,\n                         contract_function: Union[ContractFunction, ContractConstructor],\n                         transacting_power: TransactingPower,\n                         payload: dict = None,\n                         transaction_gas_limit: Optional[int] = None,\n                         gas_estimation_multiplier: Optional[float] = 1.15,  # TODO: Workaround for #2635, #2337\n                         confirmations: int = 0,\n                         fire_and_forget: bool = False,  # do not wait for receipt.  See #2385\n                         replace: bool = False,\n                         ) -> Union[TxReceipt, HexBytes]:\n\n        if fire_and_forget:\n            if confirmations > 0:\n                raise ValueError(\"Transaction Prevented: \"\n                                 \"Cannot use 'confirmations' and 'fire_and_forget' options together.\")\n\n            use_pending_nonce = False  # TODO: #2385\n        else:\n            use_pending_nonce = replace  # TODO: #2385\n\n        transaction = self.build_contract_transaction(contract_function=contract_function,\n                                                      sender_address=transacting_power.account,\n                                                      payload=payload,\n                                                      transaction_gas_limit=transaction_gas_limit,\n                                                      gas_estimation_multiplier=gas_estimation_multiplier,\n                                                      use_pending_nonce=use_pending_nonce)\n\n        # Get transaction name\n        try:\n            transaction_name = contract_function.fn_name.upper()\n        except AttributeError:\n            transaction_name = 'DEPLOY' if isinstance(contract_function, ContractConstructor) else 'UNKNOWN'\n\n        txhash_or_receipt = self.sign_and_broadcast_transaction(transacting_power=transacting_power,\n                                                                transaction_dict=transaction,\n                                                                transaction_name=transaction_name,\n                                                                confirmations=confirmations,\n                                                                fire_and_forget=fire_and_forget)\n        return txhash_or_receipt\n\n    def get_contract_by_name(self,\n                             registry: BaseContractRegistry,\n                             contract_name: str,\n                             contract_version: str = None,\n                             enrollment_version: Union[int, str] = None,\n                             proxy_name: str = None,\n                             use_proxy_address: bool = True\n                             ) -> VersionedContract:\n        \"\"\"\n        Instantiate a deployed contract from registry data,\n        and assimilate it with its proxy if it is upgradeable.\n        \"\"\"\n\n        target_contract_records = registry.search(contract_name=contract_name, contract_version=contract_version)\n        if not target_contract_records:\n            raise self.UnknownContract(f\"No such contract records with name {contract_name}:{contract_version}.\")\n\n        if contract_version and len(target_contract_records) != 1:\n            # Assert single contract record returned\n            raise self.InterfaceError(f\"Registry is potentially corrupt - multiple {contract_name} \"\n                                      f\"contract records with the same version {contract_version}\")\n\n        if proxy_name:\n            if contract_version:\n                # contract version was specified - need more information related to proxy\n                target_all_contract_records = registry.search(contract_name=contract_name)\n            else:\n                # we don't need a separate copy of original result\n                target_all_contract_records = target_contract_records\n\n            # Lookup proxies; Search for a published proxy that targets this contract record\n            proxy_records = registry.search(contract_name=proxy_name)\n            results = list()\n\n            for proxy_name, proxy_version, proxy_address, proxy_abi in proxy_records:\n                proxy_contract = self.client.w3.eth.contract(abi=proxy_abi,\n                                                             address=proxy_address,\n                                                             version=proxy_version,\n                                                             ContractFactoryClass=self._CONTRACT_FACTORY)\n                # Read this dispatcher's current target address from the blockchain\n                proxy_live_target_address = proxy_contract.functions.target().call()\n\n                # either proxy is targeting latest version of contract\n                # or\n                # use older version of the same contract\n                for target_name, target_version, target_address, target_abi in target_all_contract_records:\n                    if target_address == proxy_live_target_address:\n                        if contract_version:\n                            # contract_version specified - use specific contract\n                            target_version = target_contract_records[0][1]\n                            target_abi = target_contract_records[0][3]\n\n                        if use_proxy_address:\n                            triplet = (proxy_address, target_version, target_abi)\n                        else:\n                            triplet = (target_address, target_version, target_abi)\n                    else:\n                        continue\n\n                    results.append(triplet)\n\n            if len(results) > 1:\n                address, _version, _abi = results[0]\n                message = \"Multiple {} deployments are targeting {}\".format(proxy_name, address)\n                raise self.InterfaceError(message.format(contract_name))\n            else:\n                try:\n                    selected_address, selected_version, selected_abi = results[0]\n                except IndexError:\n                    raise self.UnknownContract(\n                        f\"There are no Dispatcher records targeting '{contract_name}':{contract_version}\")\n\n        else:\n            # TODO: use_proxy_address doesnt' work in this case. Should we raise if used?\n            # NOTE: 0 must be allowed as a valid version number\n            if len(target_contract_records) != 1:\n                if enrollment_version is None:\n                    m = f\"{len(target_contract_records)} records enrolled \" \\\n                        f\"for contract {contract_name}:{contract_version} \" \\\n                        f\"and no version index was supplied.\"\n                    raise self.InterfaceError(m)\n                enrollment_version = self.__get_enrollment_version_index(name=contract_name,\n                                                                         contract_version=contract_version,\n                                                                         version_index=enrollment_version,\n                                                                         enrollments=len(target_contract_records))\n\n            else:\n                enrollment_version = -1  # default\n\n            _contract_name, selected_version, selected_address, selected_abi = target_contract_records[enrollment_version]\n\n        # Create the contract from selected sources\n        unified_contract = self.client.w3.eth.contract(abi=selected_abi,\n                                                       address=selected_address,\n                                                       version=selected_version,\n                                                       ContractFactoryClass=self._CONTRACT_FACTORY)\n\n        return unified_contract\n\n    @staticmethod\n    def __get_enrollment_version_index(version_index: Union[int, str],\n                                       enrollments: int,\n                                       name: str,\n                                       contract_version: str):\n        version_names = {'latest': -1, 'earliest': 0}\n        try:\n            version = version_names[version_index]\n        except KeyError:\n            try:\n                version = int(version_index)\n            except ValueError:\n                what_is_this = version_index\n                raise ValueError(f\"'{what_is_this}' is not a valid enrollment version number\")\n            else:\n                if version > enrollments - 1:\n                    message = f\"Version index '{version}' is larger than the number of enrollments \" \\\n                              f\"for {name}:{contract_version}.\"\n                    raise ValueError(message)\n        return version",
  "class BlockchainDeployerInterface(BlockchainInterface):\n\n    TIMEOUT = 600  # seconds\n    _CONTRACT_FACTORY = VersionedContract\n\n    # TODO: Make more func - use as a parameter\n    # Source directories to (recursively) compile\n    SOURCES: List[SourceBundle] = [\n        SourceBundle(base_path=SOLIDITY_SOURCE_ROOT),\n    ]\n\n    _raw_contract_cache = NO_COMPILATION_PERFORMED\n\n    class NoDeployerAddress(RuntimeError):\n        pass\n\n    class DeploymentFailed(RuntimeError):\n        pass\n\n    def connect(self, compile_now: bool = True, ignore_solidity_check: bool = False) -> bool:\n        super().connect()\n        if compile_now:\n            # Execute the compilation if we're recompiling\n            # Otherwise read compiled contract data from the registry.\n            check = not ignore_solidity_check\n            compiled_contracts = multiversion_compile(source_bundles=self.SOURCES, compiler_version_check=check)\n            self._raw_contract_cache = compiled_contracts\n        return self.is_connected\n\n    @validate_checksum_address\n    def deploy_contract(self,\n                        transacting_power: TransactingPower,\n                        registry: BaseContractRegistry,\n                        contract_name: str,\n                        *constructor_args,\n                        enroll: bool = True,\n                        gas_limit: int = None,\n                        confirmations: int = 0,\n                        contract_version: str = 'latest',\n                        **constructor_kwargs\n                        ) -> Tuple[VersionedContract, TxReceipt]:\n        \"\"\"\n        Retrieve compiled interface data from the cache and\n        return an instantiated deployed contract\n        \"\"\"\n\n        #\n        # Build the deployment transaction #\n        #\n\n        deploy_transaction = dict()\n        if gas_limit:\n            deploy_transaction.update({'gas': gas_limit})\n\n        pprint_args = ', '.join(list(map(str, constructor_args)) + list(f\"{k}={v}\" for k, v in constructor_kwargs.items()))\n\n        contract_factory = self.get_contract_factory(contract_name=contract_name, version=contract_version)\n        self.log.info(f\"Deploying contract {contract_name}:{contract_factory.version} with \"\n                      f\"deployer address {transacting_power.account} \"\n                      f\"and parameters {pprint_args}\")\n\n        constructor_function = contract_factory.constructor(*constructor_args, **constructor_kwargs)\n        constructor_calldata = encode_constructor_arguments(self.client.w3,\n                                                            constructor_function,\n                                                            *constructor_args,\n                                                            **constructor_kwargs)\n        if constructor_calldata:\n            self.log.info(f\"Constructor calldata: {constructor_calldata}\")\n\n        #\n        # Transmit the deployment tx #\n        #\n\n        receipt = self.send_transaction(contract_function=constructor_function,\n                                        transacting_power=transacting_power,\n                                        payload=deploy_transaction,\n                                        confirmations=confirmations)\n\n        # Success\n        address = receipt['contractAddress']\n        self.log.info(f\"Confirmed {contract_name}:{contract_factory.version} deployment: new address {address}\")\n\n        #\n        # Instantiate & Enroll contract\n        #\n\n        contract = self.client.w3.eth.contract(address=address,\n                                               abi=contract_factory.abi,\n                                               version=contract_factory.version,\n                                               ContractFactoryClass=self._CONTRACT_FACTORY)\n\n        if enroll is True:\n            registry.enroll(contract_name=contract_name,\n                            contract_address=contract.address,\n                            contract_abi=contract.abi,\n                            contract_version=contract.version)\n\n        return contract, receipt  # receipt\n\n    def find_raw_contract_data(self, contract_name: str, requested_version: str = 'latest') -> Tuple[str, dict]:\n        try:\n            contract_data = self._raw_contract_cache[contract_name]\n        except KeyError:\n            raise self.UnknownContract('{} is not a locally compiled contract.'.format(contract_name))\n        except TypeError:\n            if self._raw_contract_cache is NO_COMPILATION_PERFORMED:\n                message = \"The local contract compiler cache is empty because no compilation was performed.\"\n                raise self.InterfaceError(message)\n            raise\n\n        try:\n            return requested_version, contract_data[requested_version]\n        except KeyError:\n            if requested_version != 'latest' and requested_version != 'earliest':\n                available = ', '.join(contract_data.keys())\n                raise self.UnknownContract(f'Version {contract_name} of contract {contract_name} is not a locally compiled. '\n                                           f'Available versions: {available}')\n\n        if len(contract_data.keys()) == 1:\n            return next(iter(contract_data.items()))\n\n        # Get the latest or the earliest versions\n        current_version_parsed = (-1, -1, -1)\n        current_version = None\n        current_data = None\n        for version, data in contract_data.items():\n            major, minor, patch = [int(v) for v in version[1:].split(\".\", 3)]\n            if current_version_parsed[0] == -1 or \\\n               requested_version == 'latest' and (major, minor, patch) > current_version_parsed or \\\n               requested_version == 'earliest' and (major, minor, patch) < current_version_parsed:\n                current_version_parsed = (major, minor, patch)\n                current_data = data\n                current_version = version\n        return current_version, current_data\n\n    def __get_contract_interface(self,\n                                 contract_name: str,\n                                 version: str = 'latest',\n                                 address: ChecksumAddress = None) -> VersionedContract:\n        \"\"\"Retrieve compiled interface data from the cache and return web3 contract\"\"\"\n        version, interface = self.find_raw_contract_data(contract_name, version)\n        contract = self.client.w3.eth.contract(abi=interface['abi'],\n                                               bytecode=interface['evm']['bytecode']['object'],\n                                               version=version,\n                                               address=address,\n                                               ContractFactoryClass=self._CONTRACT_FACTORY)\n        return contract\n\n    def get_contract_instance(self,\n                              address: ChecksumAddress,\n                              contract_name: str,\n                              version: str = 'latest') -> VersionedContract:\n        \"\"\"Retrieve compiled contract data from the cache and return web3 contract instantiated for some address\"\"\"\n        contract_instance = self.__get_contract_interface(address=address, contract_name=contract_name, version=version)\n        return contract_instance\n\n    def get_contract_factory(self, contract_name: str, version: str = 'latest') -> VersionedContract:\n        \"\"\"Retrieve compiled contract data from the cache and return web3 contract factory\"\"\"\n        contract_factory = self.__get_contract_interface(contract_name=contract_name, version=version)\n        return contract_factory\n\n    def _wrap_contract(self,\n                       wrapper_contract: VersionedContract,\n                       target_contract: VersionedContract\n                       ) -> VersionedContract:\n        \"\"\"\n        Used for upgradeable contracts; Returns a new contract object assembled\n        with its own address but the abi of the other.\n        \"\"\"\n\n        # Wrap the contract\n        wrapped_contract = self.client.w3.eth.contract(abi=target_contract.abi,\n                                                       address=wrapper_contract.address,\n                                                       version=target_contract.version,\n                                                       ContractFactoryClass=self._CONTRACT_FACTORY)\n        return wrapped_contract\n\n    @validate_checksum_address\n    def get_proxy_contract(self,\n                           registry: BaseContractRegistry,\n                           target_address: str,\n                           proxy_name: str) -> VersionedContract:\n\n        # Lookup proxies; Search for a registered proxy that targets this contract record\n        records = registry.search(contract_name=proxy_name)\n\n        dispatchers = list()\n        for name, version, address, abi in records:\n            proxy_contract = self.client.w3.eth.contract(abi=abi,\n                                                         address=address,\n                                                         version=version,\n                                                         ContractFactoryClass=self._CONTRACT_FACTORY)\n\n            # Read this dispatchers target address from the blockchain\n            proxy_live_target_address = proxy_contract.functions.target().call()\n\n            if proxy_live_target_address == target_address:\n                dispatchers.append(proxy_contract)\n\n        if len(dispatchers) > 1:\n            message = f\"Multiple Dispatcher deployments are targeting {target_address}\"\n            raise self.InterfaceError(message)\n\n        try:\n            return dispatchers[0]\n        except IndexError:\n            raise self.UnknownContract(f\"No registered Dispatcher deployments target {target_address}\")",
  "class BlockchainInterfaceFactory:\n    \"\"\"\n    Canonical source of bound blockchain interfaces.\n    \"\"\"\n\n    _instance = None\n    _interfaces = dict()\n    _default_interface_class = BlockchainInterface\n\n    class CachedInterface(NamedTuple):\n        interface: BlockchainInterface\n        emitter: StdoutEmitter\n\n    class FactoryError(Exception):\n        pass\n\n    class NoRegisteredInterfaces(FactoryError):\n        pass\n\n    class InterfaceNotInitialized(FactoryError):\n        pass\n\n    class InterfaceAlreadyInitialized(FactoryError):\n        pass\n\n    def __new__(cls, *args, **kwargs):\n        if not cls._instance:\n            cls._instance = super().__new__(cls, *args, **kwargs)\n        return cls._instance\n\n    @classmethod\n    def is_interface_initialized(cls, eth_provider_uri: str) -> bool:\n        \"\"\"\n        Returns True if there is an existing connection with an equal eth_provider_uri.\n        \"\"\"\n        return bool(cls._interfaces.get(eth_provider_uri, False))\n\n    @classmethod\n    def register_interface(cls,\n                           interface: BlockchainInterface,\n                           emitter=None,\n                           force: bool = False\n                           ) -> None:\n\n        eth_provider_uri = interface.eth_provider_uri\n        if (eth_provider_uri in cls._interfaces) and not force:\n            raise cls.InterfaceAlreadyInitialized(f\"A connection already exists for {eth_provider_uri}. \"\n                                                  \"Use .get_interface instead.\")\n        cached = cls.CachedInterface(interface=interface, emitter=emitter)\n        cls._interfaces[eth_provider_uri] = cached\n\n    @classmethod\n    def initialize_interface(cls,\n                             eth_provider_uri: str,\n                             emitter=None,\n                             interface_class: Interfaces = None,\n                             *interface_args,\n                             **interface_kwargs\n                             ) -> None:\n        if not eth_provider_uri:\n            # Prevent empty strings and Falsy\n            raise BlockchainInterface.UnsupportedProvider(f\"'{eth_provider_uri}' is not a valid provider URI\")\n\n        if eth_provider_uri in cls._interfaces:\n            raise cls.InterfaceAlreadyInitialized(f\"A connection already exists for {eth_provider_uri}.  \"\n                                                  f\"Use .get_interface instead.\")\n\n        # Interface does not exist, initialize a new one.\n        if not interface_class:\n            interface_class = cls._default_interface_class\n        interface = interface_class(eth_provider_uri=eth_provider_uri,\n                                    *interface_args,\n                                    **interface_kwargs)\n\n        cls._interfaces[eth_provider_uri] = cls.CachedInterface(interface=interface, emitter=emitter)\n\n    @classmethod\n    def get_interface(cls, eth_provider_uri: str = None) -> Interfaces:\n\n        # Try to get an existing cached interface.\n        if eth_provider_uri:\n            try:\n                cached_interface = cls._interfaces[eth_provider_uri]\n            except KeyError:\n                raise cls.InterfaceNotInitialized(f\"There is no connection for {eth_provider_uri}. \"\n                                                  f\"Call .initialize_connection, then try again.\")\n\n        # Try to use the most recently created interface by default.\n        else:\n            try:\n                cached_interface = list(cls._interfaces.values())[-1]\n            except IndexError:\n                raise cls.NoRegisteredInterfaces(f\"There is no existing blockchain connection.\")\n\n        # Connect and Sync\n        interface, emitter = cached_interface\n        if not interface.is_connected:\n            interface.connect()\n        return interface\n\n    @classmethod\n    def get_or_create_interface(cls,\n                                eth_provider_uri: str,\n                                *interface_args,\n                                **interface_kwargs\n                                ) -> BlockchainInterface:\n        try:\n            interface = cls.get_interface(eth_provider_uri=eth_provider_uri)\n        except (cls.InterfaceNotInitialized, cls.NoRegisteredInterfaces):\n            cls.initialize_interface(eth_provider_uri=eth_provider_uri, *interface_args, **interface_kwargs)\n            interface = cls.get_interface(eth_provider_uri=eth_provider_uri)\n        return interface",
  "class InterfaceError(Exception):\n        pass",
  "class NoProvider(InterfaceError):\n        pass",
  "class UnsupportedProvider(InterfaceError):\n        pass",
  "class ConnectionFailed(InterfaceError):\n        pass",
  "class UnknownContract(InterfaceError):\n        pass",
  "class TransactionFailed(InterfaceError):\n\n        IPC_CODE = -32000\n\n        def __init__(self,\n                     message: str,\n                     transaction_dict: dict,\n                     contract_function: Union[ContractFunction, ContractConstructor],\n                     *args):\n\n            self.base_message = message\n            self.name = get_transaction_name(contract_function=contract_function)\n            self.payload = transaction_dict\n            self.contract_function = contract_function\n            self.failures = {\n                BlockchainInterface.REASONS[INSUFFICIENT_ETH]: self.insufficient_eth\n            }\n            self.message = self.failures.get(self.base_message, self.default)\n            super().__init__(self.message, *args)\n\n        @property\n        def default(self) -> str:\n            sender = self.payload[\"from\"]\n            message = f'{self.name} from {sender[:6]}... \\n' \\\n                      f'Sender balance: {prettify_eth_amount(self.get_balance())} \\n' \\\n                      f'Reason: {self.base_message} \\n' \\\n                      f'Transaction: {self.payload}'\n            return message\n\n        def get_balance(self):\n            blockchain = BlockchainInterfaceFactory.get_interface()\n            balance = blockchain.client.get_balance(account=self.payload['from'])\n            return balance\n\n        @property\n        def insufficient_eth(self) -> str:\n            try:\n                transaction_fee = self.payload['gas'] * self.payload['gasPrice']\n            except KeyError:\n                return self.default\n            else:\n                cost = transaction_fee + self.payload.get('value', 0)\n                message = f'{self.name} from {self.payload[\"from\"][:8]} - {self.base_message}.' \\\n                          f'Calculated cost is {prettify_eth_amount(cost)},' \\\n                          f'but sender only has {prettify_eth_amount(self.get_balance())}.'\n            return message",
  "def __init__(self,\n                 emitter=None,  # TODO # 1754\n                 poa: bool = None,\n                 light: bool = False,\n                 eth_provider_uri: str = NO_BLOCKCHAIN_CONNECTION,\n                 eth_provider: BaseProvider = NO_BLOCKCHAIN_CONNECTION,\n                 gas_strategy: Optional[Union[str, Callable]] = None,\n                 max_gas_price: Optional[int] = None):\n\n        \"\"\"\n        TODO: #1502 - Move to API docs.\n\n         Filesystem          Configuration           Node              Client                  EVM\n        ================ ====================== =============== =====================  ===========================\n\n         Solidity Files -- SolidityCompiler -                      --- HTTPProvider ------ ...\n                                            |                    |\n                                            |                    |\n                                            |                    |\n                                            - *BlockchainInterface* -- IPCProvider ----- External EVM (geth, parity...)\n                                                       |         |\n                                                       |         |\n                                                 TestProvider ----- EthereumTester -------------\n                                                                                                |\n                                                                                                |\n                                                                                        PyEVM (Development Chain)\n\n         ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n         Runtime Files --                 --BlockchainInterface ----> Registry\n                        |                |             ^\n                        |                |             |\n                        |                |             |\n         Key Files ------ CharacterConfiguration     Agent                          ... (Contract API)\n                        |                |             ^\n                        |                |             |\n                        |                |             |\n                        |                |           Actor                          ...Blockchain-Character API)\n                        |                |             ^\n                        |                |             |\n                        |                |             |\n         Config File ---                  --------- Character                       ... (Public API)\n                                                       ^\n                                                       |\n                                                     Human\n\n\n        The Blockchain is the junction of the solidity compiler, a contract registry, and a collection of\n        web3 network providers as a means of interfacing with the ethereum blockchain to execute\n        or deploy contract code on the network.\n\n\n        Compiler and Registry Usage\n        -----------------------------\n\n        Contracts are freshly re-compiled if an instance of SolidityCompiler is passed; otherwise,\n        The registry will read contract data saved to disk that is be used to retrieve contact address and op-codes.\n        Optionally, A registry instance can be passed instead.\n\n\n        Provider Usage\n        ---------------\n        https: // github.com / ethereum / eth - tester     # available-backends\n\n\n        * HTTP Provider - Web3 HTTP provider, typically JSON RPC 2.0 over HTTP\n        * Websocket Provider - Web3 WS provider, typically JSON RPC 2.0 over WS, supply endpoint uri and websocket=True\n        * IPC Provider - Web3 File based IPC provider transported over standard I/O\n        * Custom Provider - A pre-initialized web3.py provider instance to attach to this interface\n\n        \"\"\"\n\n        self.log = Logger('Blockchain')\n        self.poa = poa\n        self.eth_provider_uri = eth_provider_uri\n        self._eth_provider = eth_provider\n        self.w3 = NO_BLOCKCHAIN_CONNECTION\n        self.client = NO_BLOCKCHAIN_CONNECTION\n        self.is_light = light\n\n        # TODO: Not ready to give users total flexibility. Let's stick for the moment to known values. See #2447\n        if gas_strategy not in ('slow', 'medium', 'fast', 'free', None):  # FIXME: What is 'None' doing here?\n            raise ValueError(f\"'{gas_strategy}' is an invalid gas strategy\")\n        self.gas_strategy = gas_strategy or self.DEFAULT_GAS_STRATEGY\n        self.max_gas_price = max_gas_price",
  "def __repr__(self):\n        r = '{name}({uri})'.format(name=self.__class__.__name__, uri=self.eth_provider_uri)\n        return r",
  "def get_blocktime(self):\n        return self.client.get_blocktime()",
  "def is_connected(self) -> bool:\n        \"\"\"\n        https://web3py.readthedocs.io/en/stable/__provider.html#examples-using-automated-detection\n        \"\"\"\n        if self.client is NO_BLOCKCHAIN_CONNECTION:\n            return False\n        return self.client.is_connected",
  "def get_gas_strategy(cls, gas_strategy: Union[str, Callable] = None) -> Callable:\n        try:\n            gas_strategy = cls.GAS_STRATEGIES[gas_strategy]\n        except KeyError:\n            if gas_strategy:\n                if not callable(gas_strategy):\n                    raise ValueError(f\"{gas_strategy} must be callable to be a valid gas strategy.\")\n            else:\n                gas_strategy = cls.GAS_STRATEGIES[cls.DEFAULT_GAS_STRATEGY]\n        return gas_strategy",
  "def attach_middleware(self):\n        chain_id = int(self.client.chain_id)\n        if self.poa is None:  # If POA is not set explicitly, try to autodetect from chain id\n            self.poa = chain_id in POA_CHAINS\n\n        self.log.debug(f'Ethereum chain: {self.client.chain_name} (chain_id={chain_id}, poa={self.poa})')\n\n        # For use with Proof-Of-Authority test-blockchains\n        if self.poa is True:\n            self.log.debug('Injecting POA middleware at layer 0')\n            self.client.inject_middleware(geth_poa_middleware, layer=0)\n\n        self.client.add_middleware(middleware.time_based_cache_middleware)\n        # self.client.add_middleware(middleware.latest_block_based_cache_middleware)  # TODO: This line causes failed tests and nonce reuse in tests. See #2348.\n        self.client.add_middleware(middleware.simple_cache_middleware)\n\n        self.configure_gas_strategy()",
  "def configure_gas_strategy(self, gas_strategy: Optional[Callable] = None) -> None:\n\n        if gas_strategy:\n            reported_gas_strategy = f\"fixed/{gas_strategy.name}\"\n\n        elif isinstance(self.client, InfuraClient):\n            gas_strategy = construct_datafeed_median_strategy(speed=self.gas_strategy)\n            reported_gas_strategy = f\"datafeed/{self.gas_strategy}\"\n\n        else:\n            reported_gas_strategy = f\"web3/{self.gas_strategy}\"\n            gas_strategy = self.get_gas_strategy(self.gas_strategy)\n\n        configuration_message = f\"Using gas strategy '{reported_gas_strategy}'\"\n\n        if self.max_gas_price:\n            __price = Web3.to_wei(self.max_gas_price, 'gwei')  # from gwei to wei\n            gas_strategy = max_price_gas_strategy_wrapper(gas_strategy=gas_strategy, max_gas_price_wei=__price)\n            configuration_message += f\", with a max price of {self.max_gas_price} gwei.\"\n\n        self.client.set_gas_strategy(gas_strategy=gas_strategy)\n\n        # TODO: This line must not be called prior to establishing a connection\n        #        Move it down to a lower layer, near the client.\n        # gwei_gas_price = Web3.from_wei(self.client.gas_price_for_transaction(), 'gwei')\n\n        self.log.info(configuration_message)",
  "def connect(self):\n\n        eth_provider_uri = self.eth_provider_uri\n        self.log.info(f\"Using external Web3 Provider '{self.eth_provider_uri}'\")\n\n        # Attach Provider\n        self._attach_eth_provider(eth_provider=self._eth_provider, eth_provider_uri=eth_provider_uri)\n        self.log.info(\"Connecting to {}\".format(self.eth_provider_uri))\n        if self._eth_provider is NO_BLOCKCHAIN_CONNECTION:\n            raise self.NoProvider(\"There are no configured blockchain providers\")\n\n        # Connect if not connected\n        try:\n            self.w3 = self.Web3(provider=self._eth_provider)\n            self.client = EthereumClient.from_w3(w3=self.w3)\n        except requests.ConnectionError:  # RPC\n            raise self.ConnectionFailed(f'Connection Failed - {str(self.eth_provider_uri)} - is RPC enabled?')\n        except FileNotFoundError:         # IPC File Protocol\n            raise self.ConnectionFailed(f'Connection Failed - {str(self.eth_provider_uri)} - is IPC enabled?')\n        else:\n            self.attach_middleware()\n\n        return self.is_connected",
  "def provider(self) -> BaseProvider:\n        return self._eth_provider",
  "def _attach_eth_provider(self,\n                             eth_provider: Optional[BaseProvider] = None,\n                             eth_provider_uri: str = None) -> None:\n        \"\"\"\n        https://web3py.readthedocs.io/en/latest/providers.html#providers\n        \"\"\"\n\n        if not eth_provider_uri and not eth_provider:\n            raise self.NoProvider(\"No URI or provider instances supplied.\")\n\n        if eth_provider_uri and not eth_provider:\n            uri_breakdown = urlparse(eth_provider_uri)\n\n            if uri_breakdown.scheme == 'tester':\n                providers = {\n                    'pyevm': _get_pyevm_test_provider,\n                    'mock': _get_mock_test_provider\n                }\n                provider_scheme = uri_breakdown.netloc\n\n            else:\n                providers = {\n                    'auto': _get_auto_provider,\n                    'ipc': _get_IPC_provider,\n                    'file': _get_IPC_provider,\n                    'ws': _get_websocket_provider,\n                    'wss': _get_websocket_provider,\n                    'http': _get_HTTP_provider,\n                    'https': _get_HTTP_provider,\n                }\n                provider_scheme = uri_breakdown.scheme\n\n            # auto-detect for file based ipc\n            if not provider_scheme:\n                if Path(eth_provider_uri).is_file():\n                    # file is available - assume ipc/file scheme\n                    provider_scheme = 'file'\n                    self.log.info(f\"Auto-detected provider scheme as 'file://' for provider {eth_provider_uri}\")\n\n            try:\n                self._eth_provider = providers[provider_scheme](eth_provider_uri)\n            except KeyError:\n                raise self.UnsupportedProvider(f\"{eth_provider_uri} is an invalid or unsupported blockchain provider URI\")\n            else:\n                self.eth_provider_uri = eth_provider_uri or NO_BLOCKCHAIN_CONNECTION\n        else:\n            self._eth_provider = eth_provider",
  "def _handle_failed_transaction(cls,\n                                   exception: Exception,\n                                   transaction_dict: dict,\n                                   contract_function: Union[ContractFunction, ContractConstructor],\n                                   logger: Logger = None\n                                   ) -> None:\n        \"\"\"\n        Re-raising error handler and context manager for transaction broadcast or\n        build failure events at the interface layer. This method is a last line of defense\n        against unhandled exceptions caused by transaction failures and must raise an exception.\n        # TODO: #1504 - Additional Handling of validation failures (gas limits, invalid fields, etc.)\n        \"\"\"\n\n        response = exception.args[0]\n\n        # Assume this error is formatted as an RPC response\n        try:\n            code = int(response['code'])\n            message = response['message']\n        except Exception:\n            # TODO: #1504 - Try even harder to determine if this is insufficient funds causing the issue,\n            #               This may be best handled at the agent or actor layer for registry and token interactions.\n            # Worst case scenario - raise the exception held in context implicitly\n            raise exception\n\n        if code != cls.TransactionFailed.IPC_CODE:\n            # Only handle client-specific exceptions\n            # https://www.jsonrpc.org/specification Section 5.1\n            raise exception\n\n        if logger:\n            logger.critical(message)  # simple context\n\n        transaction_failed = cls.TransactionFailed(message=message,  # rich error (best case)\n                                                   contract_function=contract_function,\n                                                   transaction_dict=transaction_dict)\n        raise transaction_failed from exception",
  "def __log_transaction(self, transaction_dict: dict, contract_function: ContractFunction):\n        \"\"\"\n        Format and log a transaction dict and return the transaction name string.\n        This method *must not* mutate the original transaction dict.\n        \"\"\"\n        # Do not mutate the original transaction dict\n        tx = dict(transaction_dict).copy()\n\n        # Format\n        if tx.get('to'):\n            tx['to'] = to_checksum_address(contract_function.address)\n        try:\n            tx['selector'] = contract_function.selector\n        except AttributeError:\n            pass\n        tx['from'] = to_checksum_address(tx['from'])\n        tx.update({f: prettify_eth_amount(v) for f, v in tx.items() if f in ('gasPrice', 'value')})\n        payload_pprint = ', '.join(\"{}: {}\".format(k, v) for k, v in tx.items())\n\n        # Log\n        transaction_name = get_transaction_name(contract_function=contract_function)\n        self.log.debug(f\"[TX-{transaction_name}] | {payload_pprint}\")",
  "def build_payload(self,\n                      sender_address: str,\n                      payload: dict = None,\n                      transaction_gas_limit: int = None,\n                      use_pending_nonce: bool = True,\n                      ) -> dict:\n\n        nonce = self.client.get_transaction_count(account=sender_address, pending=use_pending_nonce)\n        base_payload = {'nonce': nonce, 'from': sender_address}\n\n        # Aggregate\n        if not payload:\n            payload = {}\n        payload.update(base_payload)\n        # Explicit gas override - will skip gas estimation in next operation.\n        if transaction_gas_limit:\n            payload['gas'] = int(transaction_gas_limit)\n        return payload",
  "def build_contract_transaction(self,\n                                   contract_function: ContractFunction,\n                                   sender_address: str,\n                                   payload: dict = None,\n                                   transaction_gas_limit: Optional[int] = None,\n                                   gas_estimation_multiplier: Optional[float] = None,\n                                   use_pending_nonce: Optional[bool] = None,\n                                   ) -> dict:\n\n        if transaction_gas_limit is not None:\n            self.log.warn(\"The transaction gas limit of {transaction_gas_limit} will override gas estimation attempts\")\n\n        # Sanity checks for the gas estimation multiplier\n        if gas_estimation_multiplier is not None:\n            if not 1 <= gas_estimation_multiplier <= 3:  # Arbitrary upper bound.\n                raise ValueError(f\"The gas estimation multiplier should be a float between 1 and 3, \"\n                                 f\"but we received {gas_estimation_multiplier}.\")\n\n        payload = self.build_payload(sender_address=sender_address,\n                                     payload=payload,\n                                     transaction_gas_limit=transaction_gas_limit,\n                                     use_pending_nonce=use_pending_nonce)\n        self.__log_transaction(transaction_dict=payload, contract_function=contract_function)\n        try:\n            if 'gas' not in payload:  # i.e., transaction_gas_limit is not None\n                # As web3 build_transaction() will estimate gas with block identifier \"pending\" by default,\n                # explicitly estimate gas here with block identifier 'latest' if not otherwise specified\n                # as a pending transaction can cause gas estimation to fail, notably in case of worklock refunds.\n                payload['gas'] = contract_function.estimate_gas(payload, block_identifier='latest')\n            transaction_dict = contract_function.build_transaction(payload)\n        except (TestTransactionFailed, ValidationError, ValueError) as error:\n            # Note: Geth (1.9.15) raises ValueError in the same condition that pyevm raises ValidationError here.\n            # Treat this condition as \"Transaction Failed\" during gas estimation.\n            raise self._handle_failed_transaction(exception=error,\n                                                  transaction_dict=payload,\n                                                  contract_function=contract_function,\n                                                  logger=self.log)\n\n        # Increase the estimated gas limit according to the gas estimation multiplier, if any.\n        if gas_estimation_multiplier and not transaction_gas_limit:\n            gas_estimation = transaction_dict['gas']\n            overestimation = int(math.ceil(gas_estimation * gas_estimation_multiplier))\n            self.log.debug(f\"Gas limit for this TX was increased from {gas_estimation} to {overestimation}, \"\n                           f\"using a multiplier of {gas_estimation_multiplier}.\")\n            transaction_dict['gas'] = overestimation\n            # TODO: What if we're going over the block limit? Not likely, but perhaps worth checking (NRN)\n\n        return transaction_dict",
  "def sign_and_broadcast_transaction(self,\n                                       transacting_power: TransactingPower,\n                                       transaction_dict: TransactionDict,\n                                       transaction_name: str = \"\",\n                                       confirmations: int = 0,\n                                       fire_and_forget: bool = False\n                                       ) -> Union[TxReceipt, HexBytes]:\n        \"\"\"\n        Takes a transaction dictionary, signs it with the configured signer, then broadcasts the signed\n        transaction using the ethereum provider's eth_sendRawTransaction RPC endpoint.\n        Optionally blocks for receipt and confirmation with 'confirmations', and 'fire_and_forget' flags.\n\n        If 'fire and forget' is True this method returns the transaction hash only, without waiting for a receipt -\n        otherwise return the transaction receipt.\n\n        \"\"\"\n        #\n        # Setup\n        #\n\n        # TODO # 1754 - Move this to singleton - I do not approve... nor does Bogdan?\n        if GlobalLoggerSettings._json_ipc:\n            emitter = JSONRPCStdoutEmitter()\n        else:\n            emitter = StdoutEmitter()\n\n        #\n        # Sign\n        #\n\n        # TODO: Show the USD Price:  https://api.coinmarketcap.com/v1/ticker/ethereum/\n        \n        try:\n            # post-london fork transactions (Type 2)\n            max_unit_price = transaction_dict['maxFeePerGas']\n            tx_type = 'EIP-1559'\n        except KeyError:\n            # pre-london fork \"legacy\" transactions (Type 0)\n            max_unit_price = transaction_dict['gasPrice']\n            tx_type = 'Legacy'\n\n        max_price_gwei = Web3.from_wei(max_unit_price, 'gwei')\n        max_cost_wei = max_unit_price * transaction_dict['gas']\n        max_cost = Web3.from_wei(max_cost_wei, 'ether')\n\n        if transacting_power.is_device:\n            emitter.message(f'Confirm transaction {transaction_name} on hardware wallet... '\n                            f'({max_cost} ETH @ {max_price_gwei} gwei)',\n                            color='yellow')\n        signed_raw_transaction = transacting_power.sign_transaction(transaction_dict)\n\n        #\n        # Broadcast\n        #\n        emitter.message(f'Broadcasting {transaction_name} {tx_type} Transaction ({max_cost} ETH @ {max_price_gwei} gwei)',\n                        color='yellow')\n        try:\n            txhash = self.client.send_raw_transaction(signed_raw_transaction)  # <--- BROADCAST\n            emitter.message(f'TXHASH {txhash.hex()}', color='yellow')\n        except (TestTransactionFailed, ValueError):\n            raise  # TODO: Unify with Transaction failed handling -- Entry point for _handle_failed_transaction\n        else:\n            if fire_and_forget:\n                return txhash\n\n        #\n        # Receipt\n        #\n\n        try:  # TODO: Handle block confirmation exceptions\n            waiting_for = 'receipt'\n            if confirmations:\n                waiting_for = f'{confirmations} confirmations'\n            emitter.message(f'Waiting {self.TIMEOUT} seconds for {waiting_for}', color='yellow')\n            receipt = self.client.wait_for_receipt(txhash, timeout=self.TIMEOUT, confirmations=confirmations)\n        except TimeExhausted:\n            # TODO: #1504 - Handle transaction timeout\n            raise\n        else:\n            self.log.debug(f\"[RECEIPT-{transaction_name}] | txhash: {receipt['transactionHash'].hex()}\")\n\n        #\n        # Confirmations\n        #\n\n        # Primary check\n        transaction_status = receipt.get('status', UNKNOWN_TX_STATUS)\n        if transaction_status == 0:\n            failure = f\"Transaction transmitted, but receipt returned status code 0. \" \\\n                      f\"Full receipt: \\n {pprint.pformat(receipt, indent=2)}\"\n            raise self.InterfaceError(failure)\n\n        if transaction_status is UNKNOWN_TX_STATUS:\n            self.log.info(f\"Unknown transaction status for {txhash} (receipt did not contain a status field)\")\n\n            # Secondary check\n            tx = self.client.get_transaction(txhash)\n            if tx[\"gas\"] == receipt[\"gasUsed\"]:\n                raise self.InterfaceError(f\"Transaction consumed 100% of transaction gas.\"\n                                          f\"Full receipt: \\n {pprint.pformat(receipt, indent=2)}\")\n\n        return receipt",
  "def send_transaction(self,\n                         contract_function: Union[ContractFunction, ContractConstructor],\n                         transacting_power: TransactingPower,\n                         payload: dict = None,\n                         transaction_gas_limit: Optional[int] = None,\n                         gas_estimation_multiplier: Optional[float] = 1.15,  # TODO: Workaround for #2635, #2337\n                         confirmations: int = 0,\n                         fire_and_forget: bool = False,  # do not wait for receipt.  See #2385\n                         replace: bool = False,\n                         ) -> Union[TxReceipt, HexBytes]:\n\n        if fire_and_forget:\n            if confirmations > 0:\n                raise ValueError(\"Transaction Prevented: \"\n                                 \"Cannot use 'confirmations' and 'fire_and_forget' options together.\")\n\n            use_pending_nonce = False  # TODO: #2385\n        else:\n            use_pending_nonce = replace  # TODO: #2385\n\n        transaction = self.build_contract_transaction(contract_function=contract_function,\n                                                      sender_address=transacting_power.account,\n                                                      payload=payload,\n                                                      transaction_gas_limit=transaction_gas_limit,\n                                                      gas_estimation_multiplier=gas_estimation_multiplier,\n                                                      use_pending_nonce=use_pending_nonce)\n\n        # Get transaction name\n        try:\n            transaction_name = contract_function.fn_name.upper()\n        except AttributeError:\n            transaction_name = 'DEPLOY' if isinstance(contract_function, ContractConstructor) else 'UNKNOWN'\n\n        txhash_or_receipt = self.sign_and_broadcast_transaction(transacting_power=transacting_power,\n                                                                transaction_dict=transaction,\n                                                                transaction_name=transaction_name,\n                                                                confirmations=confirmations,\n                                                                fire_and_forget=fire_and_forget)\n        return txhash_or_receipt",
  "def get_contract_by_name(self,\n                             registry: BaseContractRegistry,\n                             contract_name: str,\n                             contract_version: str = None,\n                             enrollment_version: Union[int, str] = None,\n                             proxy_name: str = None,\n                             use_proxy_address: bool = True\n                             ) -> VersionedContract:\n        \"\"\"\n        Instantiate a deployed contract from registry data,\n        and assimilate it with its proxy if it is upgradeable.\n        \"\"\"\n\n        target_contract_records = registry.search(contract_name=contract_name, contract_version=contract_version)\n        if not target_contract_records:\n            raise self.UnknownContract(f\"No such contract records with name {contract_name}:{contract_version}.\")\n\n        if contract_version and len(target_contract_records) != 1:\n            # Assert single contract record returned\n            raise self.InterfaceError(f\"Registry is potentially corrupt - multiple {contract_name} \"\n                                      f\"contract records with the same version {contract_version}\")\n\n        if proxy_name:\n            if contract_version:\n                # contract version was specified - need more information related to proxy\n                target_all_contract_records = registry.search(contract_name=contract_name)\n            else:\n                # we don't need a separate copy of original result\n                target_all_contract_records = target_contract_records\n\n            # Lookup proxies; Search for a published proxy that targets this contract record\n            proxy_records = registry.search(contract_name=proxy_name)\n            results = list()\n\n            for proxy_name, proxy_version, proxy_address, proxy_abi in proxy_records:\n                proxy_contract = self.client.w3.eth.contract(abi=proxy_abi,\n                                                             address=proxy_address,\n                                                             version=proxy_version,\n                                                             ContractFactoryClass=self._CONTRACT_FACTORY)\n                # Read this dispatcher's current target address from the blockchain\n                proxy_live_target_address = proxy_contract.functions.target().call()\n\n                # either proxy is targeting latest version of contract\n                # or\n                # use older version of the same contract\n                for target_name, target_version, target_address, target_abi in target_all_contract_records:\n                    if target_address == proxy_live_target_address:\n                        if contract_version:\n                            # contract_version specified - use specific contract\n                            target_version = target_contract_records[0][1]\n                            target_abi = target_contract_records[0][3]\n\n                        if use_proxy_address:\n                            triplet = (proxy_address, target_version, target_abi)\n                        else:\n                            triplet = (target_address, target_version, target_abi)\n                    else:\n                        continue\n\n                    results.append(triplet)\n\n            if len(results) > 1:\n                address, _version, _abi = results[0]\n                message = \"Multiple {} deployments are targeting {}\".format(proxy_name, address)\n                raise self.InterfaceError(message.format(contract_name))\n            else:\n                try:\n                    selected_address, selected_version, selected_abi = results[0]\n                except IndexError:\n                    raise self.UnknownContract(\n                        f\"There are no Dispatcher records targeting '{contract_name}':{contract_version}\")\n\n        else:\n            # TODO: use_proxy_address doesnt' work in this case. Should we raise if used?\n            # NOTE: 0 must be allowed as a valid version number\n            if len(target_contract_records) != 1:\n                if enrollment_version is None:\n                    m = f\"{len(target_contract_records)} records enrolled \" \\\n                        f\"for contract {contract_name}:{contract_version} \" \\\n                        f\"and no version index was supplied.\"\n                    raise self.InterfaceError(m)\n                enrollment_version = self.__get_enrollment_version_index(name=contract_name,\n                                                                         contract_version=contract_version,\n                                                                         version_index=enrollment_version,\n                                                                         enrollments=len(target_contract_records))\n\n            else:\n                enrollment_version = -1  # default\n\n            _contract_name, selected_version, selected_address, selected_abi = target_contract_records[enrollment_version]\n\n        # Create the contract from selected sources\n        unified_contract = self.client.w3.eth.contract(abi=selected_abi,\n                                                       address=selected_address,\n                                                       version=selected_version,\n                                                       ContractFactoryClass=self._CONTRACT_FACTORY)\n\n        return unified_contract",
  "def __get_enrollment_version_index(version_index: Union[int, str],\n                                       enrollments: int,\n                                       name: str,\n                                       contract_version: str):\n        version_names = {'latest': -1, 'earliest': 0}\n        try:\n            version = version_names[version_index]\n        except KeyError:\n            try:\n                version = int(version_index)\n            except ValueError:\n                what_is_this = version_index\n                raise ValueError(f\"'{what_is_this}' is not a valid enrollment version number\")\n            else:\n                if version > enrollments - 1:\n                    message = f\"Version index '{version}' is larger than the number of enrollments \" \\\n                              f\"for {name}:{contract_version}.\"\n                    raise ValueError(message)\n        return version",
  "class NoDeployerAddress(RuntimeError):\n        pass",
  "class DeploymentFailed(RuntimeError):\n        pass",
  "def connect(self, compile_now: bool = True, ignore_solidity_check: bool = False) -> bool:\n        super().connect()\n        if compile_now:\n            # Execute the compilation if we're recompiling\n            # Otherwise read compiled contract data from the registry.\n            check = not ignore_solidity_check\n            compiled_contracts = multiversion_compile(source_bundles=self.SOURCES, compiler_version_check=check)\n            self._raw_contract_cache = compiled_contracts\n        return self.is_connected",
  "def deploy_contract(self,\n                        transacting_power: TransactingPower,\n                        registry: BaseContractRegistry,\n                        contract_name: str,\n                        *constructor_args,\n                        enroll: bool = True,\n                        gas_limit: int = None,\n                        confirmations: int = 0,\n                        contract_version: str = 'latest',\n                        **constructor_kwargs\n                        ) -> Tuple[VersionedContract, TxReceipt]:\n        \"\"\"\n        Retrieve compiled interface data from the cache and\n        return an instantiated deployed contract\n        \"\"\"\n\n        #\n        # Build the deployment transaction #\n        #\n\n        deploy_transaction = dict()\n        if gas_limit:\n            deploy_transaction.update({'gas': gas_limit})\n\n        pprint_args = ', '.join(list(map(str, constructor_args)) + list(f\"{k}={v}\" for k, v in constructor_kwargs.items()))\n\n        contract_factory = self.get_contract_factory(contract_name=contract_name, version=contract_version)\n        self.log.info(f\"Deploying contract {contract_name}:{contract_factory.version} with \"\n                      f\"deployer address {transacting_power.account} \"\n                      f\"and parameters {pprint_args}\")\n\n        constructor_function = contract_factory.constructor(*constructor_args, **constructor_kwargs)\n        constructor_calldata = encode_constructor_arguments(self.client.w3,\n                                                            constructor_function,\n                                                            *constructor_args,\n                                                            **constructor_kwargs)\n        if constructor_calldata:\n            self.log.info(f\"Constructor calldata: {constructor_calldata}\")\n\n        #\n        # Transmit the deployment tx #\n        #\n\n        receipt = self.send_transaction(contract_function=constructor_function,\n                                        transacting_power=transacting_power,\n                                        payload=deploy_transaction,\n                                        confirmations=confirmations)\n\n        # Success\n        address = receipt['contractAddress']\n        self.log.info(f\"Confirmed {contract_name}:{contract_factory.version} deployment: new address {address}\")\n\n        #\n        # Instantiate & Enroll contract\n        #\n\n        contract = self.client.w3.eth.contract(address=address,\n                                               abi=contract_factory.abi,\n                                               version=contract_factory.version,\n                                               ContractFactoryClass=self._CONTRACT_FACTORY)\n\n        if enroll is True:\n            registry.enroll(contract_name=contract_name,\n                            contract_address=contract.address,\n                            contract_abi=contract.abi,\n                            contract_version=contract.version)\n\n        return contract, receipt",
  "def find_raw_contract_data(self, contract_name: str, requested_version: str = 'latest') -> Tuple[str, dict]:\n        try:\n            contract_data = self._raw_contract_cache[contract_name]\n        except KeyError:\n            raise self.UnknownContract('{} is not a locally compiled contract.'.format(contract_name))\n        except TypeError:\n            if self._raw_contract_cache is NO_COMPILATION_PERFORMED:\n                message = \"The local contract compiler cache is empty because no compilation was performed.\"\n                raise self.InterfaceError(message)\n            raise\n\n        try:\n            return requested_version, contract_data[requested_version]\n        except KeyError:\n            if requested_version != 'latest' and requested_version != 'earliest':\n                available = ', '.join(contract_data.keys())\n                raise self.UnknownContract(f'Version {contract_name} of contract {contract_name} is not a locally compiled. '\n                                           f'Available versions: {available}')\n\n        if len(contract_data.keys()) == 1:\n            return next(iter(contract_data.items()))\n\n        # Get the latest or the earliest versions\n        current_version_parsed = (-1, -1, -1)\n        current_version = None\n        current_data = None\n        for version, data in contract_data.items():\n            major, minor, patch = [int(v) for v in version[1:].split(\".\", 3)]\n            if current_version_parsed[0] == -1 or \\\n               requested_version == 'latest' and (major, minor, patch) > current_version_parsed or \\\n               requested_version == 'earliest' and (major, minor, patch) < current_version_parsed:\n                current_version_parsed = (major, minor, patch)\n                current_data = data\n                current_version = version\n        return current_version, current_data",
  "def __get_contract_interface(self,\n                                 contract_name: str,\n                                 version: str = 'latest',\n                                 address: ChecksumAddress = None) -> VersionedContract:\n        \"\"\"Retrieve compiled interface data from the cache and return web3 contract\"\"\"\n        version, interface = self.find_raw_contract_data(contract_name, version)\n        contract = self.client.w3.eth.contract(abi=interface['abi'],\n                                               bytecode=interface['evm']['bytecode']['object'],\n                                               version=version,\n                                               address=address,\n                                               ContractFactoryClass=self._CONTRACT_FACTORY)\n        return contract",
  "def get_contract_instance(self,\n                              address: ChecksumAddress,\n                              contract_name: str,\n                              version: str = 'latest') -> VersionedContract:\n        \"\"\"Retrieve compiled contract data from the cache and return web3 contract instantiated for some address\"\"\"\n        contract_instance = self.__get_contract_interface(address=address, contract_name=contract_name, version=version)\n        return contract_instance",
  "def get_contract_factory(self, contract_name: str, version: str = 'latest') -> VersionedContract:\n        \"\"\"Retrieve compiled contract data from the cache and return web3 contract factory\"\"\"\n        contract_factory = self.__get_contract_interface(contract_name=contract_name, version=version)\n        return contract_factory",
  "def _wrap_contract(self,\n                       wrapper_contract: VersionedContract,\n                       target_contract: VersionedContract\n                       ) -> VersionedContract:\n        \"\"\"\n        Used for upgradeable contracts; Returns a new contract object assembled\n        with its own address but the abi of the other.\n        \"\"\"\n\n        # Wrap the contract\n        wrapped_contract = self.client.w3.eth.contract(abi=target_contract.abi,\n                                                       address=wrapper_contract.address,\n                                                       version=target_contract.version,\n                                                       ContractFactoryClass=self._CONTRACT_FACTORY)\n        return wrapped_contract",
  "def get_proxy_contract(self,\n                           registry: BaseContractRegistry,\n                           target_address: str,\n                           proxy_name: str) -> VersionedContract:\n\n        # Lookup proxies; Search for a registered proxy that targets this contract record\n        records = registry.search(contract_name=proxy_name)\n\n        dispatchers = list()\n        for name, version, address, abi in records:\n            proxy_contract = self.client.w3.eth.contract(abi=abi,\n                                                         address=address,\n                                                         version=version,\n                                                         ContractFactoryClass=self._CONTRACT_FACTORY)\n\n            # Read this dispatchers target address from the blockchain\n            proxy_live_target_address = proxy_contract.functions.target().call()\n\n            if proxy_live_target_address == target_address:\n                dispatchers.append(proxy_contract)\n\n        if len(dispatchers) > 1:\n            message = f\"Multiple Dispatcher deployments are targeting {target_address}\"\n            raise self.InterfaceError(message)\n\n        try:\n            return dispatchers[0]\n        except IndexError:\n            raise self.UnknownContract(f\"No registered Dispatcher deployments target {target_address}\")",
  "class CachedInterface(NamedTuple):\n        interface: BlockchainInterface\n        emitter: StdoutEmitter",
  "class FactoryError(Exception):\n        pass",
  "class NoRegisteredInterfaces(FactoryError):\n        pass",
  "class InterfaceNotInitialized(FactoryError):\n        pass",
  "class InterfaceAlreadyInitialized(FactoryError):\n        pass",
  "def __new__(cls, *args, **kwargs):\n        if not cls._instance:\n            cls._instance = super().__new__(cls, *args, **kwargs)\n        return cls._instance",
  "def is_interface_initialized(cls, eth_provider_uri: str) -> bool:\n        \"\"\"\n        Returns True if there is an existing connection with an equal eth_provider_uri.\n        \"\"\"\n        return bool(cls._interfaces.get(eth_provider_uri, False))",
  "def register_interface(cls,\n                           interface: BlockchainInterface,\n                           emitter=None,\n                           force: bool = False\n                           ) -> None:\n\n        eth_provider_uri = interface.eth_provider_uri\n        if (eth_provider_uri in cls._interfaces) and not force:\n            raise cls.InterfaceAlreadyInitialized(f\"A connection already exists for {eth_provider_uri}. \"\n                                                  \"Use .get_interface instead.\")\n        cached = cls.CachedInterface(interface=interface, emitter=emitter)\n        cls._interfaces[eth_provider_uri] = cached",
  "def initialize_interface(cls,\n                             eth_provider_uri: str,\n                             emitter=None,\n                             interface_class: Interfaces = None,\n                             *interface_args,\n                             **interface_kwargs\n                             ) -> None:\n        if not eth_provider_uri:\n            # Prevent empty strings and Falsy\n            raise BlockchainInterface.UnsupportedProvider(f\"'{eth_provider_uri}' is not a valid provider URI\")\n\n        if eth_provider_uri in cls._interfaces:\n            raise cls.InterfaceAlreadyInitialized(f\"A connection already exists for {eth_provider_uri}.  \"\n                                                  f\"Use .get_interface instead.\")\n\n        # Interface does not exist, initialize a new one.\n        if not interface_class:\n            interface_class = cls._default_interface_class\n        interface = interface_class(eth_provider_uri=eth_provider_uri,\n                                    *interface_args,\n                                    **interface_kwargs)\n\n        cls._interfaces[eth_provider_uri] = cls.CachedInterface(interface=interface, emitter=emitter)",
  "def get_interface(cls, eth_provider_uri: str = None) -> Interfaces:\n\n        # Try to get an existing cached interface.\n        if eth_provider_uri:\n            try:\n                cached_interface = cls._interfaces[eth_provider_uri]\n            except KeyError:\n                raise cls.InterfaceNotInitialized(f\"There is no connection for {eth_provider_uri}. \"\n                                                  f\"Call .initialize_connection, then try again.\")\n\n        # Try to use the most recently created interface by default.\n        else:\n            try:\n                cached_interface = list(cls._interfaces.values())[-1]\n            except IndexError:\n                raise cls.NoRegisteredInterfaces(f\"There is no existing blockchain connection.\")\n\n        # Connect and Sync\n        interface, emitter = cached_interface\n        if not interface.is_connected:\n            interface.connect()\n        return interface",
  "def get_or_create_interface(cls,\n                                eth_provider_uri: str,\n                                *interface_args,\n                                **interface_kwargs\n                                ) -> BlockchainInterface:\n        try:\n            interface = cls.get_interface(eth_provider_uri=eth_provider_uri)\n        except (cls.InterfaceNotInitialized, cls.NoRegisteredInterfaces):\n            cls.initialize_interface(eth_provider_uri=eth_provider_uri, *interface_args, **interface_kwargs)\n            interface = cls.get_interface(eth_provider_uri=eth_provider_uri)\n        return interface",
  "def __init__(self,\n                     message: str,\n                     transaction_dict: dict,\n                     contract_function: Union[ContractFunction, ContractConstructor],\n                     *args):\n\n            self.base_message = message\n            self.name = get_transaction_name(contract_function=contract_function)\n            self.payload = transaction_dict\n            self.contract_function = contract_function\n            self.failures = {\n                BlockchainInterface.REASONS[INSUFFICIENT_ETH]: self.insufficient_eth\n            }\n            self.message = self.failures.get(self.base_message, self.default)\n            super().__init__(self.message, *args)",
  "def default(self) -> str:\n            sender = self.payload[\"from\"]\n            message = f'{self.name} from {sender[:6]}... \\n' \\\n                      f'Sender balance: {prettify_eth_amount(self.get_balance())} \\n' \\\n                      f'Reason: {self.base_message} \\n' \\\n                      f'Transaction: {self.payload}'\n            return message",
  "def get_balance(self):\n            blockchain = BlockchainInterfaceFactory.get_interface()\n            balance = blockchain.client.get_balance(account=self.payload['from'])\n            return balance",
  "def insufficient_eth(self) -> str:\n            try:\n                transaction_fee = self.payload['gas'] * self.payload['gasPrice']\n            except KeyError:\n                return self.default\n            else:\n                cost = transaction_fee + self.payload.get('value', 0)\n                message = f'{self.name} from {self.payload[\"from\"][:8]} - {self.base_message}.' \\\n                          f'Calculated cost is {prettify_eth_amount(cost)},' \\\n                          f'but sender only has {prettify_eth_amount(self.get_balance())}.'\n            return message",
  "class Web3ClientError(Exception):\n    pass",
  "class Web3ClientConnectionFailed(Web3ClientError):\n    pass",
  "class Web3ClientUnexpectedVersionString(Web3ClientError):\n    pass",
  "class EthereumClient:\n    is_local = False\n\n    # These two are used by Infura\n    GETH = 'Geth'\n    BOR = 'bor'\n\n    PARITY = 'Parity'\n    ALT_PARITY = 'Parity-Ethereum'\n    GANACHE = 'EthereumJS TestRPC'\n\n    ETHEREUM_TESTER = 'EthereumTester'  # (PyEVM)\n\n    BLOCK_CONFIRMATIONS_POLLING_TIME = 3  # seconds\n    TRANSACTION_POLLING_TIME = 0.5  # seconds\n    COOLING_TIME = 5  # seconds\n    STALECHECK_ALLOWABLE_DELAY = 30  # seconds\n\n    class ConnectionNotEstablished(RuntimeError):\n        pass\n\n    class SyncTimeout(RuntimeError):\n        pass\n\n    class UnknownAccount(ValueError):\n        pass\n\n    class TransactionBroadcastError(RuntimeError):\n        pass\n\n    class NotEnoughConfirmations(TransactionBroadcastError):\n        pass\n\n    class TransactionTimeout(TransactionBroadcastError):\n        pass\n\n    class ChainReorganizationDetected(TransactionBroadcastError):\n        \"\"\"Raised when block confirmations logic detects that a TX was lost due to a chain reorganization\"\"\"\n\n        error_message = (\"Chain re-organization detected: Transaction {transaction_hash} was reported to be in \"\n                         \"block {block_hash}, but it's not there anymore\")\n\n        def __init__(self, receipt):\n            self.receipt = receipt\n            self.message = self.error_message.format(transaction_hash=Web3.toHex(receipt['transactionHash']),\n                                                     block_hash=Web3.toHex(receipt['blockHash']))\n            super().__init__(self.message)\n\n    def __init__(self,\n                 w3,\n                 node_technology: str,\n                 version: str,\n                 platform: str,\n                 backend: str):\n\n        self.w3 = w3\n        self.node_technology = node_technology\n        self.node_version = version\n        self.platform = platform\n        self.backend = backend\n        self.log = Logger(self.__class__.__name__)\n\n        self._add_default_middleware()\n\n    def _add_default_middleware(self):\n        # default retry functionality\n        self.log.debug('Adding RPC retry middleware to client')\n        self.add_middleware(RetryRequestMiddleware)\n\n    @classmethod\n    def _get_variant(cls, w3):\n        return cls\n\n    @classmethod\n    def from_w3(cls, w3: Web3) -> 'EthereumClient':\n        \"\"\"\n\n        Client version strings:\n\n        Geth    -> 'Geth/v1.4.11-stable-fed692f6/darwin/go1.7'\n        Parity  -> 'Parity-Ethereum/v2.5.1-beta-e0141f8-20190510/x86_64-linux-gnu/rustc1.34.1'\n        Ganache -> 'EthereumJS TestRPC/v2.1.5/ethereum-js'\n        PyEVM   -> 'EthereumTester/0.1.0b39/linux/python3.6.7'\n        Bor     -> 'bor/v0.2.13-beta2-c227a072/linux-amd64/go1.17.5'\n        \"\"\"\n        clients = {\n\n            # Geth\n            cls.GETH: GethClient,\n            cls.BOR: BorClient,\n\n            # Parity\n            cls.PARITY: ParityClient,\n            cls.ALT_PARITY: ParityClient,\n\n            # Test Clients\n            cls.GANACHE: GanacheClient,\n            cls.ETHEREUM_TESTER: EthereumTesterClient,\n        }\n\n        try:\n            client_data = w3.clientVersion.split('/')\n            node_technology = client_data[0]\n            ClientSubclass = clients[node_technology]\n\n        except (ValueError, IndexError):\n            raise ValueError(f\"Invalid client version string. Got '{w3.clientVersion}'\")\n\n        except KeyError:\n            raise NotImplementedError(f'{w3.clientVersion} is not a supported ethereum client')\n\n        client_kwargs = {\n            'node_technology': node_technology,\n            'version': client_data[1],\n            'backend': client_data[-1],\n            'platform': client_data[2] if len(client_data) == 4 else None  # Platform is optional\n        }\n\n        instance = ClientSubclass._get_variant(w3)(w3, **client_kwargs)\n        return instance\n\n    @property\n    def peers(self):\n        raise NotImplementedError\n\n    @property\n    def chain_name(self) -> str:\n        chain_inventory = LOCAL_CHAINS if self.is_local else PUBLIC_CHAINS\n        name = chain_inventory.get(self.chain_id, UNKNOWN_DEVELOPMENT_CHAIN_ID)\n        return name\n\n    def lock_account(self, account) -> bool:\n        if self.is_local:\n            return True\n        return NotImplemented\n\n    def unlock_account(self, account, password, duration=None) -> bool:\n        if self.is_local:\n            return True\n        return NotImplemented\n\n    @property\n    def is_connected(self):\n        return self.w3.is_connected()\n\n    @property\n    def etherbase(self) -> str:\n        return self.w3.eth.accounts[0]\n\n    @property\n    def accounts(self):\n        return self.w3.eth.accounts\n\n    def get_balance(self, account):\n        return self.w3.eth.get_balance(account)\n\n    def inject_middleware(self, middleware, **kwargs):\n        self.w3.middleware_onion.inject(middleware, **kwargs)\n\n    def add_middleware(self, middleware):\n        self.w3.middleware_onion.add(middleware)\n\n    def set_gas_strategy(self, gas_strategy):\n        self.w3.eth.set_gas_price_strategy(gas_strategy)\n\n    @property\n    def chain_id(self) -> int:\n        try:\n            # from hex-str\n            return int(self.w3.eth.chain_id, 16)\n        except TypeError:\n            # from str\n            return int(self.w3.eth.chain_id)\n\n    @property\n    def net_version(self) -> int:\n        return int(self.w3.net.version)\n\n    def get_contract(self, **kwargs) -> Contract:\n        return self.w3.eth.contract(**kwargs)\n\n    @property\n    def gas_price(self) -> Wei:\n        \"\"\"\n        Returns client's gas price. Underneath, it uses the eth_gasPrice JSON-RPC method\n        \"\"\"\n        return self.w3.eth.gas_price\n\n    def gas_price_for_transaction(self, transaction=None) -> Wei:\n        \"\"\"\n        Obtains a gas price via the current gas strategy, if any; otherwise, it resorts to the client's gas price.\n        This method mirrors the behavior of web3._utils.transactions when building transactions.\n        \"\"\"\n        return self.w3.eth.generate_gas_price(transaction) or self.gas_price\n\n    @property\n    def block_number(self) -> BlockNumber:\n        return self.w3.eth.block_number\n\n    @property\n    def coinbase(self) -> ChecksumAddress:\n        return self.w3.eth.coinbase\n\n    def wait_for_receipt(self,\n                         transaction_hash: str,\n                         timeout: float,\n                         confirmations: int = 0) -> TxReceipt:\n        receipt: TxReceipt = None\n        if confirmations:\n            # If we're waiting for confirmations, we may as well let pass some time initially to make everything easier\n            time.sleep(self.COOLING_TIME)\n\n            # We'll keep trying to get receipts until there are enough confirmations or the timeout happens\n            with Timeout(seconds=timeout, exception=self.TransactionTimeout) as timeout_context:\n                while not receipt:\n                    try:\n                        receipt = self.block_until_enough_confirmations(transaction_hash=transaction_hash,\n                                                                        timeout=timeout,\n                                                                        confirmations=confirmations)\n                    except (self.ChainReorganizationDetected, self.NotEnoughConfirmations, TimeExhausted):\n                        timeout_context.sleep(self.BLOCK_CONFIRMATIONS_POLLING_TIME)\n                        continue\n\n        else:\n            # If not asking for confirmations, just use web3 and assume the returned receipt is final\n            try:\n                receipt = self.w3.eth.wait_for_transaction_receipt(\n                    transaction_hash=transaction_hash,\n                    timeout=timeout,\n                    poll_latency=self.TRANSACTION_POLLING_TIME\n                )\n            except TimeExhausted:\n                raise  # TODO: #1504 - Handle transaction timeout\n\n        return receipt\n\n    def block_until_enough_confirmations(self, transaction_hash: str, timeout: float, confirmations: int) -> dict:\n\n        receipt: TxReceipt = self.w3.eth.wait_for_transaction_receipt(\n            transaction_hash=transaction_hash,\n            timeout=timeout,\n            poll_latency=self.TRANSACTION_POLLING_TIME\n        )\n\n        preliminary_block_hash = Web3.toHex(receipt['blockHash'])\n        tx_block_number = Web3.toInt(receipt['blockNumber'])\n        self.log.info(f\"Transaction {Web3.toHex(transaction_hash)} is preliminarily included in \"\n                      f\"block {preliminary_block_hash}\")\n\n        confirmations_timeout = self._calculate_confirmations_timeout(confirmations)\n        confirmations_so_far = 0\n        with Timeout(seconds=confirmations_timeout, exception=self.NotEnoughConfirmations) as timeout_context:\n            while confirmations_so_far < confirmations:\n                timeout_context.sleep(self.BLOCK_CONFIRMATIONS_POLLING_TIME)\n                self.check_transaction_is_on_chain(receipt=receipt)\n                confirmations_so_far = self.block_number - tx_block_number\n                self.log.info(f\"We have {confirmations_so_far} confirmations. \"\n                              f\"Waiting for {confirmations - confirmations_so_far} more.\")\n            return receipt\n\n    @staticmethod\n    def _calculate_confirmations_timeout(confirmations):\n        confirmations_timeout = 3 * AVERAGE_BLOCK_TIME_IN_SECONDS * confirmations\n        return confirmations_timeout\n\n    def check_transaction_is_on_chain(self, receipt: TxReceipt) -> bool:\n        transaction_hash = Web3.toHex(receipt['transactionHash'])\n        try:\n            new_receipt = self.w3.eth.get_transaction_receipt(transaction_hash)\n        except TransactionNotFound:\n            reorg_detected = True\n        else:\n            reorg_detected = receipt['blockHash'] != new_receipt['blockHash']\n\n        if reorg_detected:\n            exception = self.ChainReorganizationDetected(receipt=receipt)\n            self.log.info(exception.message)\n            raise exception\n            # TODO: Consider adding an optional param in this exception to include extra info (e.g. new block)\n        return True\n\n    def sign_transaction(self, transaction_dict: dict) -> bytes:\n        raise NotImplementedError\n\n    def get_transaction(self, transaction_hash) -> dict:\n        return self.w3.eth.get_transaction(transaction_hash)\n\n    def get_transaction_receipt(self, transaction_hash) -> Union[dict, None]:\n        return self.w3.eth.get_transaction_receipt(transaction_hash)\n\n    def get_transaction_count(self, account: str, pending: bool) -> int:\n        block_identifier = 'pending' if pending else 'latest'\n        return self.w3.eth.get_transaction_count(account, block_identifier)\n\n    def send_transaction(self, transaction_dict: dict) -> str:\n        return self.w3.eth.send_transaction(transaction_dict)\n\n    def send_raw_transaction(self, transaction_bytes: bytes) -> str:\n        return self.w3.eth.send_raw_transaction(transaction_bytes)\n\n    def sign_message(self, account: str, message: bytes) -> str:\n        \"\"\"\n        Calls the appropriate signing function for the specified account on the\n        backend. If the backend is based on eth-tester, then it uses the\n        eth-tester signing interface to do so.\n        \"\"\"\n        return self.w3.eth.sign(account, data=message)\n\n    def get_blocktime(self):\n        highest_block = self.w3.eth.get_block('latest')\n        now = highest_block['timestamp']\n        return now\n\n    def get_block(self, block_identifier):\n        return self.w3.eth.get_block(block_identifier)\n\n    def _has_latest_block(self) -> bool:\n        # TODO: Investigate using `web3.middleware.make_stalecheck_middleware` #2060\n        # check that our local chain data is up to date\n        return (time.time() - self.get_blocktime()) < self.STALECHECK_ALLOWABLE_DELAY\n\n    def parse_transaction_data(self, transaction):\n        return transaction.input",
  "class GethClient(EthereumClient):\n\n    @classmethod\n    def _get_variant(cls, w3):\n        endpoint_uri = getattr(w3.provider, 'endpoint_uri', '')\n        if 'infura' in endpoint_uri:\n            return InfuraClient\n        elif 'alchemyapi.io' in endpoint_uri:\n            return AlchemyClient\n\n        return cls\n\n    @property\n    def is_local(self):\n        return self.chain_id not in PUBLIC_CHAINS\n\n    @property\n    def peers(self):\n        return self.w3.geth.admin.peers()\n\n    def new_account(self, password: str) -> str:\n        new_account = self.w3.geth.personal.new_account(password)\n        return to_checksum_address(new_account)  # cast and validate\n\n    def unlock_account(self, account: str, password: str, duration: int = None):\n        if self.is_local:\n            return True\n        debug_message = f\"Unlocking account {account}\"\n\n        if duration is None:\n            debug_message += f\" for 5 minutes\"\n        elif duration == 0:\n            debug_message += f\" indefinitely\"\n        elif duration > 0:\n            debug_message += f\" for {duration} seconds\"\n\n        if password is None:\n            debug_message += \" with no password.\"\n\n        self.log.debug(debug_message)\n        return self.w3.geth.personal.unlock_account(account, password, duration)\n\n    def lock_account(self, account):\n        return self.w3.geth.personal.lock_account(account)\n\n    def sign_transaction(self, transaction_dict: dict) -> bytes:\n\n        # Do not include a 'to' field for contract creation.\n        if transaction_dict['to'] == b'':\n            transaction_dict = dissoc(transaction_dict, 'to')\n\n        # Sign\n        result = self.w3.eth.sign_transaction(transaction_dict)\n\n        # Return RLP bytes\n        rlp_encoded_transaction = result.raw\n        return rlp_encoded_transaction\n\n    @property\n    def wallets(self):\n        return self.w3.geth.personal.list_wallets()",
  "class BorClient(GethClient):\n    \"\"\"Geth to Bor adapter\"\"\"",
  "class ParityClient(EthereumClient):\n\n    @property\n    def peers(self) -> list:\n        \"\"\"\n        TODO: Look for web3.py support for Parity Peers endpoint\n        \"\"\"\n        return self.w3.manager.request_blocking(\"parity_netPeers\", [])\n\n    def new_account(self, password: str) -> str:\n        new_account = self.w3.parity.personal.new_account(password)\n        return to_checksum_address(new_account)  # cast and validate\n\n    def unlock_account(self, account, password, duration: int = None) -> bool:\n        return self.w3.parity.personal.unlock_account(account, password, duration)\n\n    def lock_account(self, account):\n        return self.w3.parity.personal.lock_account(account)",
  "class GanacheClient(EthereumClient):\n    is_local = True\n\n    def unlock_account(self, *args, **kwargs) -> bool:\n        return True",
  "class InfuraClient(EthereumClient):\n    is_local = False\n    TRANSACTION_POLLING_TIME = 2  # seconds\n\n    def _add_default_middleware(self):\n        # default retry functionality\n        self.log.debug('Adding Infura RPC retry middleware to client')\n        self.add_middleware(InfuraRetryRequestMiddleware)\n\n    def unlock_account(self, *args, **kwargs) -> bool:\n        return True",
  "class AlchemyClient(EthereumClient):\n\n    def _add_default_middleware(self):\n        # default retry functionality\n        self.log.debug('Adding Alchemy RPC retry middleware to client')\n        self.add_middleware(AlchemyRetryRequestMiddleware)",
  "class EthereumTesterClient(EthereumClient):\n    is_local = True\n\n    def unlock_account(self, account, password, duration: int = None) -> bool:\n        \"\"\"Returns True if the testing backend keystore has control of the given address.\"\"\"\n        account = to_checksum_address(account)\n        keystore_accounts = self.w3.provider.ethereum_tester.get_accounts()\n        if account in keystore_accounts:\n            return True\n        else:\n            return self.w3.provider.ethereum_tester.unlock_account(account=account,\n                                                                   password=password,\n                                                                   unlock_seconds=duration)\n\n    def lock_account(self, account) -> bool:\n        \"\"\"Returns True if the testing backend keystore has control of the given address.\"\"\"\n        account = to_canonical_address(account)\n        keystore_accounts = self.w3.provider.ethereum_tester.backend.get_accounts()\n        if account in keystore_accounts:\n            return True\n        else:\n            return self.w3.provider.ethereum_tester.lock_account(account=account)\n\n    def new_account(self, password: str) -> str:\n        insecure_account = self.w3.provider.ethereum_tester.add_account(private_key=os.urandom(32).hex(),\n                                                                        password=password)\n        return insecure_account\n\n    def __get_signing_key(self, account: bytes):\n        \"\"\"Get signing key of test account\"\"\"\n        account = to_canonical_address(account)\n        try:\n            signing_key = self.w3.provider.ethereum_tester.backend._key_lookup[account]._raw_key\n        except KeyError:\n            raise self.UnknownAccount(account)\n        return signing_key\n\n    def sign_transaction(self, transaction_dict: dict) -> bytes:\n        # Sign using a local private key\n        address = to_canonical_address(transaction_dict['from'])\n        signing_key = self.__get_signing_key(account=address)\n        signed_transaction = self.w3.eth.account.sign_transaction(transaction_dict, private_key=signing_key)\n        rlp_transaction = signed_transaction.rawTransaction\n        return rlp_transaction\n\n    def sign_message(self, account: str, message: bytes) -> str:\n        \"\"\"Sign, EIP-191 (Geth) Style\"\"\"\n        signing_key = self.__get_signing_key(account=account)\n        signable_message = encode_defunct(primitive=message)\n        signature_and_stuff = Account.sign_message(signable_message=signable_message, private_key=signing_key)\n        return signature_and_stuff['signature']\n\n    def parse_transaction_data(self, transaction):\n        return transaction.data",
  "class ConnectionNotEstablished(RuntimeError):\n        pass",
  "class SyncTimeout(RuntimeError):\n        pass",
  "class UnknownAccount(ValueError):\n        pass",
  "class TransactionBroadcastError(RuntimeError):\n        pass",
  "class NotEnoughConfirmations(TransactionBroadcastError):\n        pass",
  "class TransactionTimeout(TransactionBroadcastError):\n        pass",
  "class ChainReorganizationDetected(TransactionBroadcastError):\n        \"\"\"Raised when block confirmations logic detects that a TX was lost due to a chain reorganization\"\"\"\n\n        error_message = (\"Chain re-organization detected: Transaction {transaction_hash} was reported to be in \"\n                         \"block {block_hash}, but it's not there anymore\")\n\n        def __init__(self, receipt):\n            self.receipt = receipt\n            self.message = self.error_message.format(transaction_hash=Web3.toHex(receipt['transactionHash']),\n                                                     block_hash=Web3.toHex(receipt['blockHash']))\n            super().__init__(self.message)",
  "def __init__(self,\n                 w3,\n                 node_technology: str,\n                 version: str,\n                 platform: str,\n                 backend: str):\n\n        self.w3 = w3\n        self.node_technology = node_technology\n        self.node_version = version\n        self.platform = platform\n        self.backend = backend\n        self.log = Logger(self.__class__.__name__)\n\n        self._add_default_middleware()",
  "def _add_default_middleware(self):\n        # default retry functionality\n        self.log.debug('Adding RPC retry middleware to client')\n        self.add_middleware(RetryRequestMiddleware)",
  "def _get_variant(cls, w3):\n        return cls",
  "def from_w3(cls, w3: Web3) -> 'EthereumClient':\n        \"\"\"\n\n        Client version strings:\n\n        Geth    -> 'Geth/v1.4.11-stable-fed692f6/darwin/go1.7'\n        Parity  -> 'Parity-Ethereum/v2.5.1-beta-e0141f8-20190510/x86_64-linux-gnu/rustc1.34.1'\n        Ganache -> 'EthereumJS TestRPC/v2.1.5/ethereum-js'\n        PyEVM   -> 'EthereumTester/0.1.0b39/linux/python3.6.7'\n        Bor     -> 'bor/v0.2.13-beta2-c227a072/linux-amd64/go1.17.5'\n        \"\"\"\n        clients = {\n\n            # Geth\n            cls.GETH: GethClient,\n            cls.BOR: BorClient,\n\n            # Parity\n            cls.PARITY: ParityClient,\n            cls.ALT_PARITY: ParityClient,\n\n            # Test Clients\n            cls.GANACHE: GanacheClient,\n            cls.ETHEREUM_TESTER: EthereumTesterClient,\n        }\n\n        try:\n            client_data = w3.clientVersion.split('/')\n            node_technology = client_data[0]\n            ClientSubclass = clients[node_technology]\n\n        except (ValueError, IndexError):\n            raise ValueError(f\"Invalid client version string. Got '{w3.clientVersion}'\")\n\n        except KeyError:\n            raise NotImplementedError(f'{w3.clientVersion} is not a supported ethereum client')\n\n        client_kwargs = {\n            'node_technology': node_technology,\n            'version': client_data[1],\n            'backend': client_data[-1],\n            'platform': client_data[2] if len(client_data) == 4 else None  # Platform is optional\n        }\n\n        instance = ClientSubclass._get_variant(w3)(w3, **client_kwargs)\n        return instance",
  "def peers(self):\n        raise NotImplementedError",
  "def chain_name(self) -> str:\n        chain_inventory = LOCAL_CHAINS if self.is_local else PUBLIC_CHAINS\n        name = chain_inventory.get(self.chain_id, UNKNOWN_DEVELOPMENT_CHAIN_ID)\n        return name",
  "def lock_account(self, account) -> bool:\n        if self.is_local:\n            return True\n        return NotImplemented",
  "def unlock_account(self, account, password, duration=None) -> bool:\n        if self.is_local:\n            return True\n        return NotImplemented",
  "def is_connected(self):\n        return self.w3.is_connected()",
  "def etherbase(self) -> str:\n        return self.w3.eth.accounts[0]",
  "def accounts(self):\n        return self.w3.eth.accounts",
  "def get_balance(self, account):\n        return self.w3.eth.get_balance(account)",
  "def inject_middleware(self, middleware, **kwargs):\n        self.w3.middleware_onion.inject(middleware, **kwargs)",
  "def add_middleware(self, middleware):\n        self.w3.middleware_onion.add(middleware)",
  "def set_gas_strategy(self, gas_strategy):\n        self.w3.eth.set_gas_price_strategy(gas_strategy)",
  "def chain_id(self) -> int:\n        try:\n            # from hex-str\n            return int(self.w3.eth.chain_id, 16)\n        except TypeError:\n            # from str\n            return int(self.w3.eth.chain_id)",
  "def net_version(self) -> int:\n        return int(self.w3.net.version)",
  "def get_contract(self, **kwargs) -> Contract:\n        return self.w3.eth.contract(**kwargs)",
  "def gas_price(self) -> Wei:\n        \"\"\"\n        Returns client's gas price. Underneath, it uses the eth_gasPrice JSON-RPC method\n        \"\"\"\n        return self.w3.eth.gas_price",
  "def gas_price_for_transaction(self, transaction=None) -> Wei:\n        \"\"\"\n        Obtains a gas price via the current gas strategy, if any; otherwise, it resorts to the client's gas price.\n        This method mirrors the behavior of web3._utils.transactions when building transactions.\n        \"\"\"\n        return self.w3.eth.generate_gas_price(transaction) or self.gas_price",
  "def block_number(self) -> BlockNumber:\n        return self.w3.eth.block_number",
  "def coinbase(self) -> ChecksumAddress:\n        return self.w3.eth.coinbase",
  "def wait_for_receipt(self,\n                         transaction_hash: str,\n                         timeout: float,\n                         confirmations: int = 0) -> TxReceipt:\n        receipt: TxReceipt = None\n        if confirmations:\n            # If we're waiting for confirmations, we may as well let pass some time initially to make everything easier\n            time.sleep(self.COOLING_TIME)\n\n            # We'll keep trying to get receipts until there are enough confirmations or the timeout happens\n            with Timeout(seconds=timeout, exception=self.TransactionTimeout) as timeout_context:\n                while not receipt:\n                    try:\n                        receipt = self.block_until_enough_confirmations(transaction_hash=transaction_hash,\n                                                                        timeout=timeout,\n                                                                        confirmations=confirmations)\n                    except (self.ChainReorganizationDetected, self.NotEnoughConfirmations, TimeExhausted):\n                        timeout_context.sleep(self.BLOCK_CONFIRMATIONS_POLLING_TIME)\n                        continue\n\n        else:\n            # If not asking for confirmations, just use web3 and assume the returned receipt is final\n            try:\n                receipt = self.w3.eth.wait_for_transaction_receipt(\n                    transaction_hash=transaction_hash,\n                    timeout=timeout,\n                    poll_latency=self.TRANSACTION_POLLING_TIME\n                )\n            except TimeExhausted:\n                raise  # TODO: #1504 - Handle transaction timeout\n\n        return receipt",
  "def block_until_enough_confirmations(self, transaction_hash: str, timeout: float, confirmations: int) -> dict:\n\n        receipt: TxReceipt = self.w3.eth.wait_for_transaction_receipt(\n            transaction_hash=transaction_hash,\n            timeout=timeout,\n            poll_latency=self.TRANSACTION_POLLING_TIME\n        )\n\n        preliminary_block_hash = Web3.toHex(receipt['blockHash'])\n        tx_block_number = Web3.toInt(receipt['blockNumber'])\n        self.log.info(f\"Transaction {Web3.toHex(transaction_hash)} is preliminarily included in \"\n                      f\"block {preliminary_block_hash}\")\n\n        confirmations_timeout = self._calculate_confirmations_timeout(confirmations)\n        confirmations_so_far = 0\n        with Timeout(seconds=confirmations_timeout, exception=self.NotEnoughConfirmations) as timeout_context:\n            while confirmations_so_far < confirmations:\n                timeout_context.sleep(self.BLOCK_CONFIRMATIONS_POLLING_TIME)\n                self.check_transaction_is_on_chain(receipt=receipt)\n                confirmations_so_far = self.block_number - tx_block_number\n                self.log.info(f\"We have {confirmations_so_far} confirmations. \"\n                              f\"Waiting for {confirmations - confirmations_so_far} more.\")\n            return receipt",
  "def _calculate_confirmations_timeout(confirmations):\n        confirmations_timeout = 3 * AVERAGE_BLOCK_TIME_IN_SECONDS * confirmations\n        return confirmations_timeout",
  "def check_transaction_is_on_chain(self, receipt: TxReceipt) -> bool:\n        transaction_hash = Web3.toHex(receipt['transactionHash'])\n        try:\n            new_receipt = self.w3.eth.get_transaction_receipt(transaction_hash)\n        except TransactionNotFound:\n            reorg_detected = True\n        else:\n            reorg_detected = receipt['blockHash'] != new_receipt['blockHash']\n\n        if reorg_detected:\n            exception = self.ChainReorganizationDetected(receipt=receipt)\n            self.log.info(exception.message)\n            raise exception\n            # TODO: Consider adding an optional param in this exception to include extra info (e.g. new block)\n        return True",
  "def sign_transaction(self, transaction_dict: dict) -> bytes:\n        raise NotImplementedError",
  "def get_transaction(self, transaction_hash) -> dict:\n        return self.w3.eth.get_transaction(transaction_hash)",
  "def get_transaction_receipt(self, transaction_hash) -> Union[dict, None]:\n        return self.w3.eth.get_transaction_receipt(transaction_hash)",
  "def get_transaction_count(self, account: str, pending: bool) -> int:\n        block_identifier = 'pending' if pending else 'latest'\n        return self.w3.eth.get_transaction_count(account, block_identifier)",
  "def send_transaction(self, transaction_dict: dict) -> str:\n        return self.w3.eth.send_transaction(transaction_dict)",
  "def send_raw_transaction(self, transaction_bytes: bytes) -> str:\n        return self.w3.eth.send_raw_transaction(transaction_bytes)",
  "def sign_message(self, account: str, message: bytes) -> str:\n        \"\"\"\n        Calls the appropriate signing function for the specified account on the\n        backend. If the backend is based on eth-tester, then it uses the\n        eth-tester signing interface to do so.\n        \"\"\"\n        return self.w3.eth.sign(account, data=message)",
  "def get_blocktime(self):\n        highest_block = self.w3.eth.get_block('latest')\n        now = highest_block['timestamp']\n        return now",
  "def get_block(self, block_identifier):\n        return self.w3.eth.get_block(block_identifier)",
  "def _has_latest_block(self) -> bool:\n        # TODO: Investigate using `web3.middleware.make_stalecheck_middleware` #2060\n        # check that our local chain data is up to date\n        return (time.time() - self.get_blocktime()) < self.STALECHECK_ALLOWABLE_DELAY",
  "def parse_transaction_data(self, transaction):\n        return transaction.input",
  "def _get_variant(cls, w3):\n        endpoint_uri = getattr(w3.provider, 'endpoint_uri', '')\n        if 'infura' in endpoint_uri:\n            return InfuraClient\n        elif 'alchemyapi.io' in endpoint_uri:\n            return AlchemyClient\n\n        return cls",
  "def is_local(self):\n        return self.chain_id not in PUBLIC_CHAINS",
  "def peers(self):\n        return self.w3.geth.admin.peers()",
  "def new_account(self, password: str) -> str:\n        new_account = self.w3.geth.personal.new_account(password)\n        return to_checksum_address(new_account)",
  "def unlock_account(self, account: str, password: str, duration: int = None):\n        if self.is_local:\n            return True\n        debug_message = f\"Unlocking account {account}\"\n\n        if duration is None:\n            debug_message += f\" for 5 minutes\"\n        elif duration == 0:\n            debug_message += f\" indefinitely\"\n        elif duration > 0:\n            debug_message += f\" for {duration} seconds\"\n\n        if password is None:\n            debug_message += \" with no password.\"\n\n        self.log.debug(debug_message)\n        return self.w3.geth.personal.unlock_account(account, password, duration)",
  "def lock_account(self, account):\n        return self.w3.geth.personal.lock_account(account)",
  "def sign_transaction(self, transaction_dict: dict) -> bytes:\n\n        # Do not include a 'to' field for contract creation.\n        if transaction_dict['to'] == b'':\n            transaction_dict = dissoc(transaction_dict, 'to')\n\n        # Sign\n        result = self.w3.eth.sign_transaction(transaction_dict)\n\n        # Return RLP bytes\n        rlp_encoded_transaction = result.raw\n        return rlp_encoded_transaction",
  "def wallets(self):\n        return self.w3.geth.personal.list_wallets()",
  "def peers(self) -> list:\n        \"\"\"\n        TODO: Look for web3.py support for Parity Peers endpoint\n        \"\"\"\n        return self.w3.manager.request_blocking(\"parity_netPeers\", [])",
  "def new_account(self, password: str) -> str:\n        new_account = self.w3.parity.personal.new_account(password)\n        return to_checksum_address(new_account)",
  "def unlock_account(self, account, password, duration: int = None) -> bool:\n        return self.w3.parity.personal.unlock_account(account, password, duration)",
  "def lock_account(self, account):\n        return self.w3.parity.personal.lock_account(account)",
  "def unlock_account(self, *args, **kwargs) -> bool:\n        return True",
  "def _add_default_middleware(self):\n        # default retry functionality\n        self.log.debug('Adding Infura RPC retry middleware to client')\n        self.add_middleware(InfuraRetryRequestMiddleware)",
  "def unlock_account(self, *args, **kwargs) -> bool:\n        return True",
  "def _add_default_middleware(self):\n        # default retry functionality\n        self.log.debug('Adding Alchemy RPC retry middleware to client')\n        self.add_middleware(AlchemyRetryRequestMiddleware)",
  "def unlock_account(self, account, password, duration: int = None) -> bool:\n        \"\"\"Returns True if the testing backend keystore has control of the given address.\"\"\"\n        account = to_checksum_address(account)\n        keystore_accounts = self.w3.provider.ethereum_tester.get_accounts()\n        if account in keystore_accounts:\n            return True\n        else:\n            return self.w3.provider.ethereum_tester.unlock_account(account=account,\n                                                                   password=password,\n                                                                   unlock_seconds=duration)",
  "def lock_account(self, account) -> bool:\n        \"\"\"Returns True if the testing backend keystore has control of the given address.\"\"\"\n        account = to_canonical_address(account)\n        keystore_accounts = self.w3.provider.ethereum_tester.backend.get_accounts()\n        if account in keystore_accounts:\n            return True\n        else:\n            return self.w3.provider.ethereum_tester.lock_account(account=account)",
  "def new_account(self, password: str) -> str:\n        insecure_account = self.w3.provider.ethereum_tester.add_account(private_key=os.urandom(32).hex(),\n                                                                        password=password)\n        return insecure_account",
  "def __get_signing_key(self, account: bytes):\n        \"\"\"Get signing key of test account\"\"\"\n        account = to_canonical_address(account)\n        try:\n            signing_key = self.w3.provider.ethereum_tester.backend._key_lookup[account]._raw_key\n        except KeyError:\n            raise self.UnknownAccount(account)\n        return signing_key",
  "def sign_transaction(self, transaction_dict: dict) -> bytes:\n        # Sign using a local private key\n        address = to_canonical_address(transaction_dict['from'])\n        signing_key = self.__get_signing_key(account=address)\n        signed_transaction = self.w3.eth.account.sign_transaction(transaction_dict, private_key=signing_key)\n        rlp_transaction = signed_transaction.rawTransaction\n        return rlp_transaction",
  "def sign_message(self, account: str, message: bytes) -> str:\n        \"\"\"Sign, EIP-191 (Geth) Style\"\"\"\n        signing_key = self.__get_signing_key(account=account)\n        signable_message = encode_defunct(primitive=message)\n        signature_and_stuff = Account.sign_message(signable_message=signable_message, private_key=signing_key)\n        return signature_and_stuff['signature']",
  "def parse_transaction_data(self, transaction):\n        return transaction.data",
  "def __init__(self, receipt):\n            self.receipt = receipt\n            self.message = self.error_message.format(transaction_hash=Web3.toHex(receipt['transactionHash']),\n                                                     block_hash=Web3.toHex(receipt['blockHash']))\n            super().__init__(self.message)",
  "class CompilationError(RuntimeError):\n    \"\"\"\n    Raised when there is a problem compiling nucypher contracts\n    or with the expected compiler configuration.\n    \"\"\"",
  "class ProgrammingError(RuntimeError):\n    \"\"\"Caused by a human error in code\"\"\"",
  "def extract_version(compiled_contract_outputs: dict) -> str:\n    \"\"\"\n    Returns the source specified version of a compiled solidity contract.\n    Examines compiled contract output for devdoc details and perform a fulltext search for a source version specifier.\n    \"\"\"\n    try:\n        devdoc: Dict[str, str] = compiled_contract_outputs['devdoc']\n    except KeyError:\n        # Edge Case\n        # ---------\n        # If this block is reached, the compiler did not produce results for devdoc at all.\n        # Ensure 'devdoc' is listed in `CONTRACT_OUTPUTS` and that solc is the latest version.\n        raise CompilationError(f'Solidity compiler did not output devdoc.'\n                               f'Check the contract output compiler settings.')\n    else:\n        title = devdoc.get('title', '')\n\n    try:\n        devdoc_details: str = devdoc['details']\n    except KeyError:\n        # This is acceptable behaviour, most likely an un-versioned contract\n        SOLC_LOGGER.debug(f'No solidity source version specified.')\n        return DEFAULT_VERSION_STRING\n\n    # RE Full Match\n    raw_matches = DEVDOC_VERSION_PATTERN.fullmatch(devdoc_details)\n\n    # Positive match(es)\n    if raw_matches:\n        matches = raw_matches.groups()\n        if len(matches) != 1:  # sanity check\n            # Severe Edge Case\n            # -----------------\n            # \"Impossible\" situation: If this block is ever reached,\n            # the regular expression matching contract versions\n            # inside devdoc details matched multiple groups (versions).\n            # If you are here, and this exception is raised - do not panic!\n            # This most likely means there is a programming error\n            # in the `VERSION_PATTERN` regular expression or the surrounding logic.\n            raise ProgrammingError(f\"Multiple version matches in {title} devdoc.\")\n        version = matches[0]  # good match\n        return version        # OK\n    else:\n        # Negative match: Devdoc included without a version\n        SOLC_LOGGER.debug(f\"Contract {title} not versioned.\")\n        return DEFAULT_VERSION_STRING",
  "def validate_merge(existing_version: CompiledContractOutputs,\n                   new_version: CompiledContractOutputs,\n                   version_specifier: str) -> None:\n    \"\"\"Compare with incoming compiled contract data\"\"\"\n    new_title = new_version['devdoc'].get('title')\n    versioned: bool = version_specifier != DEFAULT_VERSION_STRING\n    if versioned and new_title:\n        existing_title = existing_version['devdoc'].get('title')\n        if existing_title == new_title:  # This is the same contract\n            # TODO this code excludes hash of metadata, it's not perfect because format of metadata could change\n            # ideally use a proper CBOR parser\n            existing_bytecode = METADATA_HASH_PATTERN.sub('', existing_version['evm']['bytecode']['object'])\n            new_bytecode = METADATA_HASH_PATTERN.sub('', new_version['evm']['bytecode']['object'])\n            if not existing_bytecode == new_bytecode:\n                message = f\"Two solidity sources ({new_title}, {existing_title}) specify version '{version_specifier}' \" \\\n                          \"but have different compiled bytecode. Ensure that the devdoc version is \" \\\n                          \"accurately updated before trying again.\"\n                raise CompilationError(message)",
  "def merge_contract_sources(*compiled_sources):\n    return merge(*compiled_sources)",
  "def merge_contract_outputs(*compiled_versions) -> VersionedContractOutputs:\n    versioned_outputs = dict()\n\n    for bundle in compiled_versions:\n\n        for contract_outputs in bundle:\n            version = extract_version(compiled_contract_outputs=contract_outputs)\n\n            try:\n                existing_version = versioned_outputs[version]\n\n            except KeyError:\n                # New Version Entry\n                bytecode = METADATA_HASH_PATTERN.sub('', contract_outputs['evm']['bytecode']['object'])\n                if len(bytecode) > 0:\n                    for existing_version, existing_contract_outputs in versioned_outputs.items():\n                        existing_bytecode = METADATA_HASH_PATTERN.sub('', existing_contract_outputs['evm']['bytecode']['object'])\n                        if bytecode == existing_bytecode:\n                            raise CompilationError(\n                                f\"Two solidity sources compiled identical bytecode for versions {version} and {existing_version}. \"\n                                \"Ensure the correct solidity paths are targeted for compilation.\")\n                versioned_outputs[version] = contract_outputs\n\n            else:\n                # Existing Version Update\n                validate_merge(existing_version=existing_version,\n                               new_version=contract_outputs,\n                               version_specifier=version)\n                versioned_outputs[version] = contract_outputs\n\n    return VersionedContractOutputs(versioned_outputs)",
  "class ABI(Dict):\n    inputs: List\n    name: str\n    outputs: List[Dict[str, str]]\n    stateMutability: str\n    type: str",
  "class CompiledContractOutputs(Dict):\n    abi: ABI\n    devdoc: Dict[str, Union[str, Dict[str, str]]]\n    evm: Dict[str, Dict]\n    userdoc: Dict",
  "class CompilerConfiguration(Dict):\n    language: str\n    sources: Dict[str, Dict[str, str]]\n    settings: Dict",
  "class SourceBundle(NamedTuple):\n    base_path: Path\n    other_paths: Tuple[Path, ...] = tuple()",
  "def prepare_source_configuration(sources: Dict[str, Path]) -> CompilerSources:\n    input_sources = dict()\n    for source_name, path in sources.items():\n        source_url = path.resolve(strict=True)  # require source path existence\n        input_sources[source_name] = dict(urls=[str(source_url)])\n    return input_sources",
  "def prepare_remappings_configuration(base_path: Path) -> Dict:\n    remappings_array = list()\n    for i, value in enumerate(REMAPPINGS):\n        remappings_array.append(f\"{value}={str(base_path / value)}\")\n    remappings = dict(remappings=remappings_array)\n    return remappings",
  "def compile_sources(source_bundle: SourceBundle, version_check: bool = True) -> Dict:\n    \"\"\"Compiled solidity contracts for a single source directory\"\"\"\n    sources = collect_sources(source_bundle=source_bundle)\n    source_config = prepare_source_configuration(sources=sources)\n    solc_configuration = merge(BASE_COMPILER_CONFIGURATION, dict(sources=source_config))  # does not mutate.\n\n    remappings_config = prepare_remappings_configuration(base_path=source_bundle.base_path)\n    solc_configuration['settings'].update(remappings_config)\n\n    version: VersionString = VersionString(SOLIDITY_COMPILER_VERSION) if version_check else None\n    allow_paths = [source_bundle.base_path, *source_bundle.other_paths]\n    compiler_output = __execute(compiler_version=version, input_config=solc_configuration, allow_paths=allow_paths)\n    return compiler_output",
  "def multiversion_compile(source_bundles: List[SourceBundle],\n                         compiler_version_check: bool = True\n                         ) -> VersionedContractOutputs:\n    \"\"\"Compile contracts from `source_dirs` and aggregate the resulting source contract outputs by version\"\"\"\n    raw_compiler_results: List[CompiledContractOutputs] = list()\n    for bundle in source_bundles:\n        compile_result = compile_sources(source_bundle=bundle,\n                                         version_check=compiler_version_check)\n        raw_compiler_results.append(compile_result['contracts'])\n    raw_compiled_contracts = itertools.chain.from_iterable(output.values() for output in raw_compiler_results)\n    versioned_contract_outputs = VersionedContractOutputs(merge_with(merge_contract_outputs, *raw_compiled_contracts))\n    return versioned_contract_outputs",
  "def __execute(compiler_version: VersionString, input_config: Dict, allow_paths: Optional[List[str]]):\n    \"\"\"Executes the solcx command and underlying solc wrapper\"\"\"\n\n    # Lazy import to allow for optional installation of solcx\n    try:\n        from solcx.install import get_executable\n        from solcx.main import compile_standard\n    except ImportError:\n        raise DevelopmentInstallationRequired(importable_name='solcx')\n\n    # Prepare Solc Command\n    solc_binary_path: Path = get_executable(version=compiler_version)\n\n    _allow_paths = ',' + ','.join(str(p) for p in allow_paths)\n\n    # Execute Compilation\n    try:\n        compiler_output = compile_standard(input_data=input_config,\n                                           allow_paths=_allow_paths,\n                                           solc_binary=solc_binary_path)\n    except FileNotFoundError:\n        raise CompilationError(\"The solidity compiler is not at the specified path. \"\n                               \"Check that the file exists and is executable.\")\n    except PermissionError:\n        raise CompilationError(f\"The solidity compiler binary at {solc_binary_path} is not executable. \"\n                               \"Check the file's permissions.\")\n\n    errors = compiler_output.get('errors')\n    if errors:\n        formatted = '\\n'.join([error['formattedMessage'] for error in errors])\n        SOLC_LOGGER.warn(f\"Errors during compilation: \\n{formatted}\")\n\n    SOLC_LOGGER.info(f\"Successfully compiled {len(compiler_output)} sources with {OPTIMIZER_RUNS} optimization runs\")\n    return compiler_output",
  "def source_filter(filename: str) -> bool:\n    \"\"\"Helper function for filtering out contracts not intended for compilation\"\"\"\n    contains_ignored_prefix: bool = any(prefix in filename for prefix in IGNORE_CONTRACT_PREFIXES)\n    is_solidity_file: bool = filename.endswith('.sol')\n    return is_solidity_file and not contains_ignored_prefix",
  "def collect_sources(source_bundle: SourceBundle) -> Dict[str, Path]:\n    \"\"\"\n    Combines sources bundle paths. Walks source_dir top-down to the bottom filepath of\n    each subdirectory recursively nd filtrates by __source_filter, setting values into `source_paths`.\n    \"\"\"\n    source_paths = dict()\n    combined_paths = (source_bundle.base_path, *source_bundle.other_paths)\n    for source_dir in combined_paths:\n        source_walker: Iterator = os.walk(top=source_dir, topdown=True)\n        for root, dirs, files in source_walker:            # Collect single directory\n            for filename in filter(source_filter, files):  # Collect files in source dir\n                path = Path(root) / filename\n                if filename in source_paths:\n                    raise RuntimeError(f'\"{filename}\" source is already collected. Verify source bundle filepaths.'\n                                       f' Existing {source_paths[filename]}; Duplicate {path}.')\n                source_paths[filename] = path\n                SOLC_LOGGER.debug(f\"Collecting solidity source {path}\")\n        SOLC_LOGGER.info(f\"Collected {len(source_paths)} solidity source files at {source_bundle}\")\n    return source_paths",
  "class Signer(ABC):\n\n    _SIGNERS = NotImplemented  # set dynamically in __init__.py\n\n    log = Logger(__qualname__)\n\n    class SignerError(Exception):\n        \"\"\"Base exception class for signer errors\"\"\"\n\n    class InvalidSignerURI(SignerError):\n        \"\"\"Raised when an invalid signer URI is detected\"\"\"\n\n    class AccountLocked(SignerError):\n        def __init__(self, account: str):\n            self.message = f'{account} is locked.'\n            super().__init__(self.message)\n\n    class UnknownAccount(SignerError):\n        def __init__(self, account: str):\n            self.message = f'Unknown account {account}.'\n            super().__init__(self.message)\n\n    class AuthenticationFailed(SignerError):\n        \"\"\"Raised when ACCESS DENIED\"\"\"\n\n    @classmethod\n    @abstractmethod\n    def uri_scheme(cls) -> str:\n        return NotImplemented\n\n    @classmethod\n    def from_signer_uri(cls, uri: str, testnet: bool = False) -> 'Signer':\n        parsed = urlparse(uri)\n        scheme = parsed.scheme if parsed.scheme else parsed.path\n        try:\n            signer_class = cls._SIGNERS[scheme]\n        except KeyError:\n            # This block can be considered the \"pass-through\"\n            # for providers to be used as external signers.\n            try:\n                from nucypher.blockchain.eth.signers.software import Web3Signer\n                signer = Web3Signer.from_signer_uri(uri=uri)\n            except cls.InvalidSignerURI:\n                message = f'{uri} is not a valid signer URI.  Available schemes: {\", \".join(cls._SIGNERS)}'\n                raise cls.InvalidSignerURI(message)\n            return signer\n        signer = signer_class.from_signer_uri(uri=uri, testnet=testnet)\n        return signer\n\n    @abstractmethod\n    def is_device(self, account: str) -> bool:\n        \"\"\"Some signing client support both software and hardware wallets,\n        this method is implemented as a boolean to tell the difference.\"\"\"\n        return NotImplemented\n\n    @property\n    @abstractmethod\n    def accounts(self) -> List[ChecksumAddress]:\n        return NotImplemented\n\n    @abstractmethod\n    def unlock_account(self, account: str, password: str, duration: int = None) -> bool:\n        return NotImplemented\n\n    @abstractmethod\n    def lock_account(self, account: str) -> str:\n        return NotImplemented\n\n    @abstractmethod\n    def sign_transaction(self, transaction_dict: dict) -> HexBytes:\n        return NotImplemented\n\n    @abstractmethod\n    def sign_message(self, account: str, message: bytes, **kwargs) -> HexBytes:\n        return NotImplemented",
  "class SignerError(Exception):\n        \"\"\"Base exception class for signer errors\"\"\"",
  "class InvalidSignerURI(SignerError):\n        \"\"\"Raised when an invalid signer URI is detected\"\"\"",
  "class AccountLocked(SignerError):\n        def __init__(self, account: str):\n            self.message = f'{account} is locked.'\n            super().__init__(self.message)",
  "class UnknownAccount(SignerError):\n        def __init__(self, account: str):\n            self.message = f'Unknown account {account}.'\n            super().__init__(self.message)",
  "class AuthenticationFailed(SignerError):\n        \"\"\"Raised when ACCESS DENIED\"\"\"",
  "def uri_scheme(cls) -> str:\n        return NotImplemented",
  "def from_signer_uri(cls, uri: str, testnet: bool = False) -> 'Signer':\n        parsed = urlparse(uri)\n        scheme = parsed.scheme if parsed.scheme else parsed.path\n        try:\n            signer_class = cls._SIGNERS[scheme]\n        except KeyError:\n            # This block can be considered the \"pass-through\"\n            # for providers to be used as external signers.\n            try:\n                from nucypher.blockchain.eth.signers.software import Web3Signer\n                signer = Web3Signer.from_signer_uri(uri=uri)\n            except cls.InvalidSignerURI:\n                message = f'{uri} is not a valid signer URI.  Available schemes: {\", \".join(cls._SIGNERS)}'\n                raise cls.InvalidSignerURI(message)\n            return signer\n        signer = signer_class.from_signer_uri(uri=uri, testnet=testnet)\n        return signer",
  "def is_device(self, account: str) -> bool:\n        \"\"\"Some signing client support both software and hardware wallets,\n        this method is implemented as a boolean to tell the difference.\"\"\"\n        return NotImplemented",
  "def accounts(self) -> List[ChecksumAddress]:\n        return NotImplemented",
  "def unlock_account(self, account: str, password: str, duration: int = None) -> bool:\n        return NotImplemented",
  "def lock_account(self, account: str) -> str:\n        return NotImplemented",
  "def sign_transaction(self, transaction_dict: dict) -> HexBytes:\n        return NotImplemented",
  "def sign_message(self, account: str, message: bytes, **kwargs) -> HexBytes:\n        return NotImplemented",
  "def __init__(self, account: str):\n            self.message = f'{account} is locked.'\n            super().__init__(self.message)",
  "def __init__(self, account: str):\n            self.message = f'Unknown account {account}.'\n            super().__init__(self.message)",
  "class Web3Signer(Signer):\n\n    def __init__(self, client):\n        super().__init__()\n        self.__client = client\n\n    @classmethod\n    def uri_scheme(cls) -> str:\n        return NotImplemented  # web3 signer uses a \"passthrough\" scheme\n\n    @classmethod\n    def from_signer_uri(cls, uri: str, testnet: bool = False) -> 'Web3Signer':\n        from nucypher.blockchain.eth.interfaces import BlockchainInterface, BlockchainInterfaceFactory\n        try:\n            blockchain = BlockchainInterfaceFactory.get_or_create_interface(eth_provider_uri=uri)\n        except BlockchainInterface.UnsupportedProvider:\n            raise cls.InvalidSignerURI(uri)\n        signer = cls(client=blockchain.client)\n        return signer\n\n    def is_connected(self) -> bool:\n        return self.__client.w3.isConnected()\n\n    @property\n    def accounts(self) -> List[str]:\n        return self.__client.accounts\n\n    @validate_checksum_address\n    def is_device(self, account: str):\n        try:\n            # TODO: Temporary fix for #1128 and #1385. It's ugly af, but it works. Move somewhere else?\n            wallets = self.__client.wallets\n        except AttributeError:\n            return False\n        else:\n            HW_WALLET_URL_PREFIXES = ('trezor', 'ledger')\n            hw_accounts = [w['accounts'] for w in wallets if w['url'].startswith(HW_WALLET_URL_PREFIXES)]\n            hw_addresses = [to_checksum_address(account['address']) for sublist in hw_accounts for account in sublist]\n            return account in hw_addresses\n\n    @validate_checksum_address\n    def unlock_account(self, account: str, password: str, duration: int = None):\n        if self.is_device(account=account):\n            unlocked = True\n        else:\n            unlocked = self.__client.unlock_account(account=account, password=password, duration=duration)\n        return unlocked\n\n    @validate_checksum_address\n    def lock_account(self, account: str):\n        if self.is_device(account=account):\n            result = None  # TODO: Force Disconnect Devices?\n        else:\n            result = self.__client.lock_account(account=account)\n        return result\n\n    @validate_checksum_address\n    def sign_message(self, account: str, message: bytes, **kwargs) -> HexBytes:\n        signature = self.__client.sign_message(account=account, message=message)\n        return HexBytes(signature)\n\n    def sign_transaction(self, transaction_dict: dict) -> HexBytes:\n        signed_raw_transaction = self.__client.sign_transaction(transaction_dict=transaction_dict)\n        return signed_raw_transaction",
  "class KeystoreSigner(Signer):\n    \"\"\"Local Web3 signer implementation supporting keystore files\"\"\"\n\n    __keys: Dict[str, dict]\n    __signers: Dict[str, LocalAccount]\n\n    class InvalidKeyfile(Signer.SignerError, RuntimeError):\n        \"\"\"\n        Raised when a keyfile is corrupt or otherwise invalid.\n        Keystore must be in the geth wallet format.\n        \"\"\"\n\n    def __init__(self, path: Path, testnet: bool = False):\n        super().__init__()\n        self.__path = path\n        self.__keys = dict()\n        self.__signers = dict()\n        self.__read_keystore(path=path)\n        self.testnet = testnet\n\n    def __del__(self):\n        # TODO: Might need a finally block or exception context handling\n        if self.__keys:\n            for account in self.__keys:\n                self.lock_account(account)\n\n    @classmethod\n    def uri_scheme(cls) -> str:\n        return 'keystore'\n\n    def __read_keystore(self, path: Path) -> None:\n        \"\"\"Read the keystore directory from the disk and populate accounts.\"\"\"\n        try:\n            if path.is_dir():\n                paths = (entry for entry in path.iterdir() if entry.is_file())\n            elif path.is_file():\n                paths = (path,)\n            else:\n                raise self.InvalidSignerURI(f'Invalid keystore file or directory \"{path}\"')\n        except FileNotFoundError:\n            raise self.InvalidSignerURI(f'No such keystore file or directory \"{path}\"')\n        except OSError as exc:\n            raise self.InvalidSignerURI(f'Error accessing keystore file or directory \"{path}\": {exc}')\n        for path in paths:\n            account, key_metadata = self.__handle_keyfile(path=path)\n            self.__keys[account] = key_metadata\n\n    @staticmethod\n    def __read_keyfile(path: Path) -> tuple:\n        \"\"\"Read an individual keystore key file from the disk\"\"\"\n        with open(path, 'r') as keyfile:\n            key_metadata = json.load(keyfile)\n        address = key_metadata['address']\n        return address, key_metadata\n\n    def __handle_keyfile(self, path: Path) -> Tuple[str, dict]:\n        \"\"\"\n        Read a single keystore file from the disk and return its decoded json contents then internally\n        cache it on the keystore instance. Raises InvalidKeyfile if the keyfile is missing or corrupted.\n        \"\"\"\n        try:\n            address, key_metadata = self.__read_keyfile(path=path)\n        except FileNotFoundError:\n            error = f\"No such keyfile '{path}'\"\n            raise self.InvalidKeyfile(error)\n        except JSONDecodeError:\n            error = f\"Invalid JSON in keyfile at {path}\"\n            raise self.InvalidKeyfile(error)\n        except KeyError:\n            error = f\"Keyfile does not contain address field at '{path}'\"\n            raise self.InvalidKeyfile(error)\n        else:\n            if not is_address(address):\n                raise self.InvalidKeyfile(f\"'{path}' does not contain a valid ethereum address\")\n            address = to_checksum_address(address)\n        return address, key_metadata\n\n    @validate_checksum_address\n    def __get_signer(self, account: str) -> LocalAccount:\n        \"\"\"Lookup a known keystore account by its checksum address or raise an error\"\"\"\n        try:\n            return self.__signers[account]\n        except KeyError:\n            if account not in self.__keys:\n                raise self.UnknownAccount(account=account)\n            else:\n                raise self.AccountLocked(account=account)\n\n    #\n    # Public API\n    #\n\n    @property\n    def path(self) -> Path:\n        \"\"\"Read only access to the keystore path\"\"\"\n        return self.__path\n\n    @classmethod\n    def from_signer_uri(cls, uri: str, testnet: bool = False) -> 'Signer':\n        \"\"\"Return a keystore signer from URI string i.e. keystore:///my/path/keystore \"\"\"\n        decoded_uri = urlparse(uri)\n        if decoded_uri.scheme != cls.uri_scheme() or decoded_uri.netloc:\n            raise cls.InvalidSignerURI(uri)\n        path = decoded_uri.path\n        if not path:\n            raise cls.InvalidSignerURI('Blank signer URI - No keystore path provided')\n        return cls(path=Path(path), testnet=testnet)\n\n    @validate_checksum_address\n    def is_device(self, account: str) -> bool:\n        return False  # Keystore accounts are never devices.\n\n    @property\n    def accounts(self) -> List[str]:\n        \"\"\"Return a list of known keystore accounts read from\"\"\"\n        return list(self.__keys.keys())\n\n    @validate_checksum_address\n    def unlock_account(self, account: str, password: str, duration: int = None) -> bool:\n        \"\"\"\n        Decrypt the signing material from the key metadata file and cache it on\n        the keystore instance is decryption is successful.\n        \"\"\"\n        if not self.__signers.get(account):\n            try:\n                key_metadata = self.__keys[account]\n            except KeyError:\n                raise self.UnknownAccount(account=account)\n            try:\n                signing_key = Account.from_key(Account.decrypt(key_metadata, password))\n                self.__signers[account] = signing_key\n            except TypeError:\n                if not password:\n                    # It is possible that password is None here passed from the above layer\n                    # causing Account.decrypt to crash, expecting a value for password.\n                    raise self.AuthenticationFailed('No password supplied to unlock account.')\n                raise\n            except ValueError as e:\n                raise self.AuthenticationFailed(\"Invalid or incorrect ethereum account password.\") from e\n        return True\n\n    @validate_checksum_address\n    def lock_account(self, account: str) -> bool:\n        \"\"\"\n        Deletes a local signer by its checksum address or raises UnknownAccount if\n        the address is not a member of this keystore.  Returns True if the account is no longer\n        tracked and was successfully locked.\n        \"\"\"\n        try:\n            self.__signers.pop(account)  # mutate\n        except KeyError:\n            if account not in self.accounts:\n                raise self.UnknownAccount(account=account)\n        return account not in self.__signers\n\n    @validate_checksum_address\n    def sign_transaction(self, transaction_dict: dict) -> HexBytes:\n        \"\"\"\n        Produce a raw signed ethereum transaction signed by the account specified\n        in the 'from' field of the transaction dictionary.\n        \"\"\"\n\n        sender = transaction_dict['from']\n        signer = self.__get_signer(account=sender)\n\n        # TODO: Handle this at a higher level?\n        # Do not include a 'to' field for contract creation.\n        if not transaction_dict['to']:\n            transaction_dict = dissoc(transaction_dict, 'to')\n\n        raw_transaction = signer.sign_transaction(transaction_dict=transaction_dict).rawTransaction\n        return raw_transaction\n\n    @validate_checksum_address\n    def sign_message(self, account: str, message: bytes, **kwargs) -> HexBytes:\n        signer = self.__get_signer(account=account)\n        signature = signer.sign_message(signable_message=encode_defunct(primitive=message)).signature\n        return HexBytes(signature)",
  "def __init__(self, client):\n        super().__init__()\n        self.__client = client",
  "def uri_scheme(cls) -> str:\n        return NotImplemented",
  "def from_signer_uri(cls, uri: str, testnet: bool = False) -> 'Web3Signer':\n        from nucypher.blockchain.eth.interfaces import BlockchainInterface, BlockchainInterfaceFactory\n        try:\n            blockchain = BlockchainInterfaceFactory.get_or_create_interface(eth_provider_uri=uri)\n        except BlockchainInterface.UnsupportedProvider:\n            raise cls.InvalidSignerURI(uri)\n        signer = cls(client=blockchain.client)\n        return signer",
  "def is_connected(self) -> bool:\n        return self.__client.w3.isConnected()",
  "def accounts(self) -> List[str]:\n        return self.__client.accounts",
  "def is_device(self, account: str):\n        try:\n            # TODO: Temporary fix for #1128 and #1385. It's ugly af, but it works. Move somewhere else?\n            wallets = self.__client.wallets\n        except AttributeError:\n            return False\n        else:\n            HW_WALLET_URL_PREFIXES = ('trezor', 'ledger')\n            hw_accounts = [w['accounts'] for w in wallets if w['url'].startswith(HW_WALLET_URL_PREFIXES)]\n            hw_addresses = [to_checksum_address(account['address']) for sublist in hw_accounts for account in sublist]\n            return account in hw_addresses",
  "def unlock_account(self, account: str, password: str, duration: int = None):\n        if self.is_device(account=account):\n            unlocked = True\n        else:\n            unlocked = self.__client.unlock_account(account=account, password=password, duration=duration)\n        return unlocked",
  "def lock_account(self, account: str):\n        if self.is_device(account=account):\n            result = None  # TODO: Force Disconnect Devices?\n        else:\n            result = self.__client.lock_account(account=account)\n        return result",
  "def sign_message(self, account: str, message: bytes, **kwargs) -> HexBytes:\n        signature = self.__client.sign_message(account=account, message=message)\n        return HexBytes(signature)",
  "def sign_transaction(self, transaction_dict: dict) -> HexBytes:\n        signed_raw_transaction = self.__client.sign_transaction(transaction_dict=transaction_dict)\n        return signed_raw_transaction",
  "class InvalidKeyfile(Signer.SignerError, RuntimeError):\n        \"\"\"\n        Raised when a keyfile is corrupt or otherwise invalid.\n        Keystore must be in the geth wallet format.\n        \"\"\"",
  "def __init__(self, path: Path, testnet: bool = False):\n        super().__init__()\n        self.__path = path\n        self.__keys = dict()\n        self.__signers = dict()\n        self.__read_keystore(path=path)\n        self.testnet = testnet",
  "def __del__(self):\n        # TODO: Might need a finally block or exception context handling\n        if self.__keys:\n            for account in self.__keys:\n                self.lock_account(account)",
  "def uri_scheme(cls) -> str:\n        return 'keystore'",
  "def __read_keystore(self, path: Path) -> None:\n        \"\"\"Read the keystore directory from the disk and populate accounts.\"\"\"\n        try:\n            if path.is_dir():\n                paths = (entry for entry in path.iterdir() if entry.is_file())\n            elif path.is_file():\n                paths = (path,)\n            else:\n                raise self.InvalidSignerURI(f'Invalid keystore file or directory \"{path}\"')\n        except FileNotFoundError:\n            raise self.InvalidSignerURI(f'No such keystore file or directory \"{path}\"')\n        except OSError as exc:\n            raise self.InvalidSignerURI(f'Error accessing keystore file or directory \"{path}\": {exc}')\n        for path in paths:\n            account, key_metadata = self.__handle_keyfile(path=path)\n            self.__keys[account] = key_metadata",
  "def __read_keyfile(path: Path) -> tuple:\n        \"\"\"Read an individual keystore key file from the disk\"\"\"\n        with open(path, 'r') as keyfile:\n            key_metadata = json.load(keyfile)\n        address = key_metadata['address']\n        return address, key_metadata",
  "def __handle_keyfile(self, path: Path) -> Tuple[str, dict]:\n        \"\"\"\n        Read a single keystore file from the disk and return its decoded json contents then internally\n        cache it on the keystore instance. Raises InvalidKeyfile if the keyfile is missing or corrupted.\n        \"\"\"\n        try:\n            address, key_metadata = self.__read_keyfile(path=path)\n        except FileNotFoundError:\n            error = f\"No such keyfile '{path}'\"\n            raise self.InvalidKeyfile(error)\n        except JSONDecodeError:\n            error = f\"Invalid JSON in keyfile at {path}\"\n            raise self.InvalidKeyfile(error)\n        except KeyError:\n            error = f\"Keyfile does not contain address field at '{path}'\"\n            raise self.InvalidKeyfile(error)\n        else:\n            if not is_address(address):\n                raise self.InvalidKeyfile(f\"'{path}' does not contain a valid ethereum address\")\n            address = to_checksum_address(address)\n        return address, key_metadata",
  "def __get_signer(self, account: str) -> LocalAccount:\n        \"\"\"Lookup a known keystore account by its checksum address or raise an error\"\"\"\n        try:\n            return self.__signers[account]\n        except KeyError:\n            if account not in self.__keys:\n                raise self.UnknownAccount(account=account)\n            else:\n                raise self.AccountLocked(account=account)",
  "def path(self) -> Path:\n        \"\"\"Read only access to the keystore path\"\"\"\n        return self.__path",
  "def from_signer_uri(cls, uri: str, testnet: bool = False) -> 'Signer':\n        \"\"\"Return a keystore signer from URI string i.e. keystore:///my/path/keystore \"\"\"\n        decoded_uri = urlparse(uri)\n        if decoded_uri.scheme != cls.uri_scheme() or decoded_uri.netloc:\n            raise cls.InvalidSignerURI(uri)\n        path = decoded_uri.path\n        if not path:\n            raise cls.InvalidSignerURI('Blank signer URI - No keystore path provided')\n        return cls(path=Path(path), testnet=testnet)",
  "def is_device(self, account: str) -> bool:\n        return False",
  "def accounts(self) -> List[str]:\n        \"\"\"Return a list of known keystore accounts read from\"\"\"\n        return list(self.__keys.keys())",
  "def unlock_account(self, account: str, password: str, duration: int = None) -> bool:\n        \"\"\"\n        Decrypt the signing material from the key metadata file and cache it on\n        the keystore instance is decryption is successful.\n        \"\"\"\n        if not self.__signers.get(account):\n            try:\n                key_metadata = self.__keys[account]\n            except KeyError:\n                raise self.UnknownAccount(account=account)\n            try:\n                signing_key = Account.from_key(Account.decrypt(key_metadata, password))\n                self.__signers[account] = signing_key\n            except TypeError:\n                if not password:\n                    # It is possible that password is None here passed from the above layer\n                    # causing Account.decrypt to crash, expecting a value for password.\n                    raise self.AuthenticationFailed('No password supplied to unlock account.')\n                raise\n            except ValueError as e:\n                raise self.AuthenticationFailed(\"Invalid or incorrect ethereum account password.\") from e\n        return True",
  "def lock_account(self, account: str) -> bool:\n        \"\"\"\n        Deletes a local signer by its checksum address or raises UnknownAccount if\n        the address is not a member of this keystore.  Returns True if the account is no longer\n        tracked and was successfully locked.\n        \"\"\"\n        try:\n            self.__signers.pop(account)  # mutate\n        except KeyError:\n            if account not in self.accounts:\n                raise self.UnknownAccount(account=account)\n        return account not in self.__signers",
  "def sign_transaction(self, transaction_dict: dict) -> HexBytes:\n        \"\"\"\n        Produce a raw signed ethereum transaction signed by the account specified\n        in the 'from' field of the transaction dictionary.\n        \"\"\"\n\n        sender = transaction_dict['from']\n        signer = self.__get_signer(account=sender)\n\n        # TODO: Handle this at a higher level?\n        # Do not include a 'to' field for contract creation.\n        if not transaction_dict['to']:\n            transaction_dict = dissoc(transaction_dict, 'to')\n\n        raw_transaction = signer.sign_transaction(transaction_dict=transaction_dict).rawTransaction\n        return raw_transaction",
  "def sign_message(self, account: str, message: bytes, **kwargs) -> HexBytes:\n        signer = self.__get_signer(account=account)\n        signature = signer.sign_message(signable_message=encode_defunct(primitive=message)).signature\n        return HexBytes(signature)",
  "class RetryRequestMiddleware:\n    \"\"\"\n    Automatically retries rpc requests whenever a 429 status code is returned.\n    \"\"\"\n    def __init__(self,\n                 make_request: Callable[[RPCEndpoint, Any], RPCResponse],\n                 w3: Web3,\n                 retries: int = 3,\n                 exponential_backoff: bool = True):\n        self.w3 = w3\n        self.make_request = make_request\n        self.retries = retries\n        self.exponential_backoff = exponential_backoff\n        self.logger = Logger(self.__class__.__name__)\n\n    def is_request_result_retry(self, result: Union[RPCResponse, Exception]) -> bool:\n        # default retry functionality - look for 429 codes\n        # override for additional checks\n        if isinstance(result, HTTPError):\n            # HTTPError 429\n            status_code = result.response.status_code\n            if status_code == 429:\n                return True\n        elif not isinstance(result, Exception):\n            # must be RPCResponse\n            if 'error' in result:\n                error = result['error']\n                # either instance of RPCError or str\n                if not isinstance(error, str) and error.get('code') == 429:\n                    return True\n\n        # not retry result\n        return False\n\n    def __call__(self, method, params):\n        result = None\n        num_iterations = 1 + self.retries  # initial call and subsequent retries\n        for i in range(num_iterations):\n            try:\n                response = self.make_request(method, params)\n            except Exception as e:  # type: ignore\n                result = e\n            else:\n                result = response\n\n            # completed request\n            if not self.is_request_result_retry(result):\n                if i > 0:\n                    # not initial call and retry was actually performed\n                    self.logger.debug(f'Retried rpc request completed after {i} retries')\n                break\n\n            # max retries with no completion\n            if i == self.retries:\n                self.logger.warn(f'RPC request retried {self.retries} times but was not completed')\n                break\n\n            # backoff before next call\n            if self.exponential_backoff:\n                time.sleep(2 ** (i + 1))  # exponential back-off - 2^(retry number)\n\n        if isinstance(result, Exception):\n            raise result\n        else:\n            # RPCResponse\n            return result",
  "class AlchemyRetryRequestMiddleware(RetryRequestMiddleware):\n    \"\"\"\n    Automatically retries rpc requests whenever a 429 status code or Alchemy-specific error message is returned.\n    \"\"\"\n\n    def is_request_result_retry(self, result: Union[RPCResponse, Exception]) -> bool:\n        \"\"\"\n        Check Alchemy request result for Alchemy-specific retry message.\n        \"\"\"\n        # perform additional Alchemy-specific checks\n        # - Websocket result:\n        #   {'code': -32000,\n        #    'message': 'Your app has exceeded its compute units per second capacity. If you have retries enabled, you\n        #              can safely ignore this message. If not, check out https://docs.alchemyapi.io/guides/rate-limits'}\n        #\n        #\n        # - HTTP result: is a requests.exception.HTTPError with status code 429\n        # (will be checked in original `is_request_result_retry`)\n\n        if super().is_request_result_retry(result):\n            return True\n\n        if not isinstance(result, Exception):\n            # RPCResponse\n            if 'error' in result:\n                error = result['error']\n                if isinstance(error, str):\n                    return 'retries' in error\n                else:\n                    # RPCError TypeDict\n                    return 'retries' in error.get('message')\n        # else\n        #     exception already checked by superclass - no need to check here\n\n        # not a retry result\n        return False",
  "class InfuraRetryRequestMiddleware(RetryRequestMiddleware):\n    \"\"\"\n    Automatically retries rpc requests whenever a 429 status code or Infura-specific error message is returned.\n    \"\"\"\n\n    def is_request_result_retry(self, result: Union[RPCResponse, Exception]) -> bool:\n        \"\"\"\n        Check Infura request result for Infura-specific retry message.\n        \"\"\"\n        # see https://infura.io/docs/ethereum/json-rpc/ratelimits\n        # {\n        #   \"jsonrpc\": \"2.0\",\n        #   \"id\": 1,\n        #   \"error\": {\n        #     \"code\": -32005,\n        #     \"message\": \"project ID request rate exceeded\",\n        #     \"data\": {\n        #       \"see\": \"https://infura.io/docs/ethereum/jsonrpc/ratelimits\",\n        #       \"current_rps\": 13.333,\n        #       \"allowed_rps\": 10.0,\n        #       \"backoff_seconds\": 30.0,\n        #     }\n        #   }\n        # }\n        if super().is_request_result_retry(result):\n            return True\n\n        if not isinstance(result, Exception):\n            # RPCResponse\n            if 'error' in result:\n                error = result['error']\n                if not isinstance(error, str):\n                    # RPCError TypeDict\n                    # TODO should we utilize infura's backoff_seconds value in response?\n                    return error.get('code') == -32005 and 'rate exceeded' in error.get('message')\n        # else\n        #     exceptions already checked by superclass - no need to check here\n\n        # not a retry result\n        return False",
  "def __init__(self,\n                 make_request: Callable[[RPCEndpoint, Any], RPCResponse],\n                 w3: Web3,\n                 retries: int = 3,\n                 exponential_backoff: bool = True):\n        self.w3 = w3\n        self.make_request = make_request\n        self.retries = retries\n        self.exponential_backoff = exponential_backoff\n        self.logger = Logger(self.__class__.__name__)",
  "def is_request_result_retry(self, result: Union[RPCResponse, Exception]) -> bool:\n        # default retry functionality - look for 429 codes\n        # override for additional checks\n        if isinstance(result, HTTPError):\n            # HTTPError 429\n            status_code = result.response.status_code\n            if status_code == 429:\n                return True\n        elif not isinstance(result, Exception):\n            # must be RPCResponse\n            if 'error' in result:\n                error = result['error']\n                # either instance of RPCError or str\n                if not isinstance(error, str) and error.get('code') == 429:\n                    return True\n\n        # not retry result\n        return False",
  "def __call__(self, method, params):\n        result = None\n        num_iterations = 1 + self.retries  # initial call and subsequent retries\n        for i in range(num_iterations):\n            try:\n                response = self.make_request(method, params)\n            except Exception as e:  # type: ignore\n                result = e\n            else:\n                result = response\n\n            # completed request\n            if not self.is_request_result_retry(result):\n                if i > 0:\n                    # not initial call and retry was actually performed\n                    self.logger.debug(f'Retried rpc request completed after {i} retries')\n                break\n\n            # max retries with no completion\n            if i == self.retries:\n                self.logger.warn(f'RPC request retried {self.retries} times but was not completed')\n                break\n\n            # backoff before next call\n            if self.exponential_backoff:\n                time.sleep(2 ** (i + 1))  # exponential back-off - 2^(retry number)\n\n        if isinstance(result, Exception):\n            raise result\n        else:\n            # RPCResponse\n            return result",
  "def is_request_result_retry(self, result: Union[RPCResponse, Exception]) -> bool:\n        \"\"\"\n        Check Alchemy request result for Alchemy-specific retry message.\n        \"\"\"\n        # perform additional Alchemy-specific checks\n        # - Websocket result:\n        #   {'code': -32000,\n        #    'message': 'Your app has exceeded its compute units per second capacity. If you have retries enabled, you\n        #              can safely ignore this message. If not, check out https://docs.alchemyapi.io/guides/rate-limits'}\n        #\n        #\n        # - HTTP result: is a requests.exception.HTTPError with status code 429\n        # (will be checked in original `is_request_result_retry`)\n\n        if super().is_request_result_retry(result):\n            return True\n\n        if not isinstance(result, Exception):\n            # RPCResponse\n            if 'error' in result:\n                error = result['error']\n                if isinstance(error, str):\n                    return 'retries' in error\n                else:\n                    # RPCError TypeDict\n                    return 'retries' in error.get('message')\n        # else\n        #     exception already checked by superclass - no need to check here\n\n        # not a retry result\n        return False",
  "def is_request_result_retry(self, result: Union[RPCResponse, Exception]) -> bool:\n        \"\"\"\n        Check Infura request result for Infura-specific retry message.\n        \"\"\"\n        # see https://infura.io/docs/ethereum/json-rpc/ratelimits\n        # {\n        #   \"jsonrpc\": \"2.0\",\n        #   \"id\": 1,\n        #   \"error\": {\n        #     \"code\": -32005,\n        #     \"message\": \"project ID request rate exceeded\",\n        #     \"data\": {\n        #       \"see\": \"https://infura.io/docs/ethereum/jsonrpc/ratelimits\",\n        #       \"current_rps\": 13.333,\n        #       \"allowed_rps\": 10.0,\n        #       \"backoff_seconds\": 30.0,\n        #     }\n        #   }\n        # }\n        if super().is_request_result_retry(result):\n            return True\n\n        if not isinstance(result, Exception):\n            # RPCResponse\n            if 'error' in result:\n                error = result['error']\n                if not isinstance(error, str):\n                    # RPCError TypeDict\n                    # TODO should we utilize infura's backoff_seconds value in response?\n                    return error.get('code') == -32005 and 'rate exceeded' in error.get('message')\n        # else\n        #     exceptions already checked by superclass - no need to check here\n\n        # not a retry result\n        return False",
  "class RevocationKit:\n\n    def __init__(self, treasure_map, signer: SignatureStamp):\n        # TODO: move to core and make a method of TreasureMap?\n        self.revocations = dict()\n        for staking_provider_address, encrypted_kfrag in treasure_map.destinations.items():\n            address = Address(to_canonical_address(bytes(staking_provider_address)))\n            self.revocations[staking_provider_address] = RevocationOrder(signer=signer.as_umbral_signer(),\n                                                                         staking_provider_address=address,\n                                                                         encrypted_kfrag=encrypted_kfrag)\n\n    def __iter__(self):\n        return iter(self.revocations.values())\n\n    def __getitem__(self, ursula_address: ChecksumAddress):\n        # TODO (#1995): when that issue is fixed, conversion is no longer needed\n        return self.revocations[Address(to_canonical_address(ursula_address))]\n\n    def __len__(self):\n        return len(self.revocations)\n\n    def __eq__(self, other):\n        return self.revocations == other.revocations\n\n    @property\n    def revokable_addresses(self):\n        \"\"\"Returns a Set of revokable addresses in the checksum address formatting\"\"\"\n        # TODO (#1995): when that issue is fixed, conversion is no longer needed\n        return set([to_checksum_address(bytes(address)) for address in self.revocations.keys()])\n\n    def add_confirmation(self, ursula_address, signed_receipt):\n        \"\"\"Adds a signed confirmation of Ursula's ability to revoke the node.\"\"\"\n        raise NotImplementedError",
  "def __init__(self, treasure_map, signer: SignatureStamp):\n        # TODO: move to core and make a method of TreasureMap?\n        self.revocations = dict()\n        for staking_provider_address, encrypted_kfrag in treasure_map.destinations.items():\n            address = Address(to_canonical_address(bytes(staking_provider_address)))\n            self.revocations[staking_provider_address] = RevocationOrder(signer=signer.as_umbral_signer(),\n                                                                         staking_provider_address=address,\n                                                                         encrypted_kfrag=encrypted_kfrag)",
  "def __iter__(self):\n        return iter(self.revocations.values())",
  "def __getitem__(self, ursula_address: ChecksumAddress):\n        # TODO (#1995): when that issue is fixed, conversion is no longer needed\n        return self.revocations[Address(to_canonical_address(ursula_address))]",
  "def __len__(self):\n        return len(self.revocations)",
  "def __eq__(self, other):\n        return self.revocations == other.revocations",
  "def revokable_addresses(self):\n        \"\"\"Returns a Set of revokable addresses in the checksum address formatting\"\"\"\n        # TODO (#1995): when that issue is fixed, conversion is no longer needed\n        return set([to_checksum_address(bytes(address)) for address in self.revocations.keys()])",
  "def add_confirmation(self, ursula_address, signed_receipt):\n        \"\"\"Adds a signed confirmation of Ursula's ability to revoke the node.\"\"\"\n        raise NotImplementedError",
  "class Policy(ABC):\n    \"\"\"\n    An edict by Alice, arranged with n Ursulas, to perform re-encryption for a specific Bob.\n    \"\"\"\n\n    log = Logger(\"Policy\")\n\n    class PolicyException(Exception):\n        \"\"\"Base exception for policy exceptions\"\"\"\n\n    class NotEnoughUrsulas(PolicyException):\n        \"\"\"\n        Raised when a Policy cannot be generated due an insufficient\n        number of available qualified network nodes.\n        \"\"\"\n\n    def __init__(self,\n                 publisher: 'Alice',\n                 label: bytes,\n                 bob: 'Bob',\n                 kfrags: Sequence[VerifiedKeyFrag],\n                 public_key: PublicKey,\n                 threshold: int,\n                 expiration: maya.MayaDT,\n                 commencement: maya.MayaDT,\n                 value: int,\n                 rate: int,\n                 duration: int,\n                 payment_method: 'PaymentMethod'\n                 ):\n\n        self.threshold = threshold\n        self.shares = len(kfrags)\n        self.label = label\n        self.bob = bob\n        self.kfrags = kfrags\n        self.public_key = public_key\n        self.commencement = commencement\n        self.expiration = expiration\n        self.duration = duration\n        self.value = value\n        self.rate = rate\n        self.nodes = None  # set by publication\n\n        self.publisher = publisher\n        self.hrac = HRAC(publisher_verifying_key=self.publisher.stamp.as_umbral_pubkey(),\n                         bob_verifying_key=self.bob.stamp.as_umbral_pubkey(),\n                         label=self.label)\n        self.payment_method = payment_method\n        self.payment_method.validate_price(shares=self.shares, value=value, duration=duration)\n\n    def __repr__(self):\n        return f\"{self.__class__.__name__}:{bytes(self.hrac).hex()[:6]}\"\n\n    @abstractmethod\n    def _make_reservoir(self, handpicked_addresses: Sequence[ChecksumAddress]) -> MergedReservoir:\n        \"\"\"Builds a `MergedReservoir` to use for drawing addresses to send proposals to.\"\"\"\n        raise NotImplementedError\n\n    def _publish(self, ursulas: List['Ursula']) -> Dict:\n        self.nodes = [ursula.checksum_address for ursula in ursulas]\n        receipt = self.payment_method.pay(policy=self)\n        return receipt\n\n    def _ping_node(self, address: ChecksumAddress, network_middleware: RestMiddleware) -> 'Ursula':\n        # Handles edge case when provided address is not a known peer.\n        if address not in self.publisher.known_nodes:\n            raise RuntimeError(f\"{address} is not a known peer\")\n\n        ursula = self.publisher.known_nodes[address]\n        response = network_middleware.ping(node=ursula)\n        status_code = response.status_code\n\n        if status_code == 200:\n            return ursula\n        else:\n            raise RuntimeError(f\"{ursula} is not available for selection ({status_code}).\")\n\n    def _sample(self,\n                network_middleware: RestMiddleware,\n                ursulas: Optional[Iterable['Ursula']] = None,\n                timeout: int = 10,\n                ) -> List['Ursula']:\n        \"\"\"Send concurrent requests to the /ping HTTP endpoint of nodes drawn from the reservoir.\"\"\"\n\n        ursulas = ursulas or []\n        handpicked_addresses = [ChecksumAddress(ursula.checksum_address) for ursula in ursulas]\n\n        self.publisher.block_until_number_of_known_nodes_is(self.shares, learn_on_this_thread=True, eager=True)\n        reservoir = self._make_reservoir(handpicked_addresses)\n        value_factory = PrefetchStrategy(reservoir, self.shares)\n\n        def worker(address) -> 'Ursula':\n            return self._ping_node(address, network_middleware)\n\n        worker_pool = WorkerPool(\n            worker=worker,\n            value_factory=value_factory,\n            target_successes=self.shares,\n            timeout=timeout,\n            stagger_timeout=1\n        )\n        worker_pool.start()\n        try:\n            successes = worker_pool.block_until_target_successes()\n        except (WorkerPool.OutOfValues, WorkerPool.TimedOut):\n            # It's possible to raise some other exceptions here but we will use the logic below.\n            successes = worker_pool.get_successes()\n        finally:\n            worker_pool.cancel()\n            worker_pool.join()\n        failures = worker_pool.get_failures()\n\n        accepted_addresses = \", \".join(ursula.checksum_address for ursula in successes.values())\n        if len(successes) < self.shares:\n            rejections = \"\\n\".join(f\"{address}: {value}\" for address, (type_, value, traceback) in failures.items())\n            message = \"Failed to contact enough sampled nodes.\\n\"\\\n                      f\"Selected:\\n{accepted_addresses}\\n\" \\\n                      f\"Unavailable:\\n{rejections}\"\n            self.log.debug(message)\n            raise self.NotEnoughUrsulas(message)\n\n        self.log.debug(f\"Selected nodes for policy: {accepted_addresses}\")\n        ursulas = list(successes.values())\n        return ursulas\n\n    def enact(self, network_middleware: RestMiddleware, ursulas: Optional[Iterable['Ursula']] = None) -> 'EnactedPolicy':\n        \"\"\"Attempts to enact the policy, returns an `EnactedPolicy` object on success.\"\"\"\n\n        ursulas = self._sample(network_middleware=network_middleware, ursulas=ursulas)\n        self._publish(ursulas=ursulas)\n\n        assigned_kfrags = {\n            Address(ursula.canonical_address): (ursula.public_keys(DecryptingPower), vkfrag)\n            for ursula, vkfrag in zip(ursulas, self.kfrags)\n        }\n\n        treasure_map = TreasureMap(signer=self.publisher.stamp.as_umbral_signer(),\n                                   hrac=self.hrac,\n                                   policy_encrypting_key=self.public_key,\n                                   assigned_kfrags=assigned_kfrags,\n                                   threshold=self.threshold)\n\n        enc_treasure_map = treasure_map.encrypt(signer=self.publisher.stamp.as_umbral_signer(),\n                                                recipient_key=self.bob.public_keys(DecryptingPower))\n\n        # TODO: Signal revocation without using encrypted kfrag\n        revocation_kit = RevocationKit(treasure_map=treasure_map, signer=self.publisher.stamp)\n\n        enacted_policy = EnactedPolicy(self.hrac,\n                                       self.label,\n                                       self.public_key,\n                                       treasure_map.threshold,\n                                       enc_treasure_map,\n                                       revocation_kit,\n                                       self.publisher.stamp.as_umbral_pubkey())\n\n        return enacted_policy",
  "class FederatedPolicy(Policy):\n\n    def _make_reservoir(self, handpicked_addresses: List[ChecksumAddress]):\n        \"\"\"Returns a federated node reservoir for creating a federated policy.\"\"\"\n        return make_federated_staker_reservoir(known_nodes=self.publisher.known_nodes,\n                                               include_addresses=handpicked_addresses)",
  "class BlockchainPolicy(Policy):\n\n    def _make_reservoir(self, handpicked_addresses: List[ChecksumAddress]):\n        \"\"\"Returns a reservoir of staking nodes to create a decentralized policy.\"\"\"\n        reservoir = make_decentralized_staking_provider_reservoir(application_agent=self.publisher.application_agent,\n                                                                  include_addresses=handpicked_addresses)\n        return reservoir",
  "class EnactedPolicy:\n\n    def __init__(self,\n                 hrac: HRAC,\n                 label: bytes,\n                 public_key: PublicKey,\n                 threshold: int,\n                 treasure_map: 'EncryptedTreasureMap',\n                 revocation_kit: RevocationKit,\n                 publisher_verifying_key: PublicKey):\n\n        self.hrac = hrac\n        self.label = label\n        self.public_key = public_key\n        self.treasure_map = treasure_map\n        self.revocation_kit = revocation_kit\n        self.threshold = threshold\n        self.shares = len(self.revocation_kit)\n        self.publisher_verifying_key = publisher_verifying_key",
  "class PolicyException(Exception):\n        \"\"\"Base exception for policy exceptions\"\"\"",
  "class NotEnoughUrsulas(PolicyException):\n        \"\"\"\n        Raised when a Policy cannot be generated due an insufficient\n        number of available qualified network nodes.\n        \"\"\"",
  "def __init__(self,\n                 publisher: 'Alice',\n                 label: bytes,\n                 bob: 'Bob',\n                 kfrags: Sequence[VerifiedKeyFrag],\n                 public_key: PublicKey,\n                 threshold: int,\n                 expiration: maya.MayaDT,\n                 commencement: maya.MayaDT,\n                 value: int,\n                 rate: int,\n                 duration: int,\n                 payment_method: 'PaymentMethod'\n                 ):\n\n        self.threshold = threshold\n        self.shares = len(kfrags)\n        self.label = label\n        self.bob = bob\n        self.kfrags = kfrags\n        self.public_key = public_key\n        self.commencement = commencement\n        self.expiration = expiration\n        self.duration = duration\n        self.value = value\n        self.rate = rate\n        self.nodes = None  # set by publication\n\n        self.publisher = publisher\n        self.hrac = HRAC(publisher_verifying_key=self.publisher.stamp.as_umbral_pubkey(),\n                         bob_verifying_key=self.bob.stamp.as_umbral_pubkey(),\n                         label=self.label)\n        self.payment_method = payment_method\n        self.payment_method.validate_price(shares=self.shares, value=value, duration=duration)",
  "def __repr__(self):\n        return f\"{self.__class__.__name__}:{bytes(self.hrac).hex()[:6]}\"",
  "def _make_reservoir(self, handpicked_addresses: Sequence[ChecksumAddress]) -> MergedReservoir:\n        \"\"\"Builds a `MergedReservoir` to use for drawing addresses to send proposals to.\"\"\"\n        raise NotImplementedError",
  "def _publish(self, ursulas: List['Ursula']) -> Dict:\n        self.nodes = [ursula.checksum_address for ursula in ursulas]\n        receipt = self.payment_method.pay(policy=self)\n        return receipt",
  "def _ping_node(self, address: ChecksumAddress, network_middleware: RestMiddleware) -> 'Ursula':\n        # Handles edge case when provided address is not a known peer.\n        if address not in self.publisher.known_nodes:\n            raise RuntimeError(f\"{address} is not a known peer\")\n\n        ursula = self.publisher.known_nodes[address]\n        response = network_middleware.ping(node=ursula)\n        status_code = response.status_code\n\n        if status_code == 200:\n            return ursula\n        else:\n            raise RuntimeError(f\"{ursula} is not available for selection ({status_code}).\")",
  "def _sample(self,\n                network_middleware: RestMiddleware,\n                ursulas: Optional[Iterable['Ursula']] = None,\n                timeout: int = 10,\n                ) -> List['Ursula']:\n        \"\"\"Send concurrent requests to the /ping HTTP endpoint of nodes drawn from the reservoir.\"\"\"\n\n        ursulas = ursulas or []\n        handpicked_addresses = [ChecksumAddress(ursula.checksum_address) for ursula in ursulas]\n\n        self.publisher.block_until_number_of_known_nodes_is(self.shares, learn_on_this_thread=True, eager=True)\n        reservoir = self._make_reservoir(handpicked_addresses)\n        value_factory = PrefetchStrategy(reservoir, self.shares)\n\n        def worker(address) -> 'Ursula':\n            return self._ping_node(address, network_middleware)\n\n        worker_pool = WorkerPool(\n            worker=worker,\n            value_factory=value_factory,\n            target_successes=self.shares,\n            timeout=timeout,\n            stagger_timeout=1\n        )\n        worker_pool.start()\n        try:\n            successes = worker_pool.block_until_target_successes()\n        except (WorkerPool.OutOfValues, WorkerPool.TimedOut):\n            # It's possible to raise some other exceptions here but we will use the logic below.\n            successes = worker_pool.get_successes()\n        finally:\n            worker_pool.cancel()\n            worker_pool.join()\n        failures = worker_pool.get_failures()\n\n        accepted_addresses = \", \".join(ursula.checksum_address for ursula in successes.values())\n        if len(successes) < self.shares:\n            rejections = \"\\n\".join(f\"{address}: {value}\" for address, (type_, value, traceback) in failures.items())\n            message = \"Failed to contact enough sampled nodes.\\n\"\\\n                      f\"Selected:\\n{accepted_addresses}\\n\" \\\n                      f\"Unavailable:\\n{rejections}\"\n            self.log.debug(message)\n            raise self.NotEnoughUrsulas(message)\n\n        self.log.debug(f\"Selected nodes for policy: {accepted_addresses}\")\n        ursulas = list(successes.values())\n        return ursulas",
  "def enact(self, network_middleware: RestMiddleware, ursulas: Optional[Iterable['Ursula']] = None) -> 'EnactedPolicy':\n        \"\"\"Attempts to enact the policy, returns an `EnactedPolicy` object on success.\"\"\"\n\n        ursulas = self._sample(network_middleware=network_middleware, ursulas=ursulas)\n        self._publish(ursulas=ursulas)\n\n        assigned_kfrags = {\n            Address(ursula.canonical_address): (ursula.public_keys(DecryptingPower), vkfrag)\n            for ursula, vkfrag in zip(ursulas, self.kfrags)\n        }\n\n        treasure_map = TreasureMap(signer=self.publisher.stamp.as_umbral_signer(),\n                                   hrac=self.hrac,\n                                   policy_encrypting_key=self.public_key,\n                                   assigned_kfrags=assigned_kfrags,\n                                   threshold=self.threshold)\n\n        enc_treasure_map = treasure_map.encrypt(signer=self.publisher.stamp.as_umbral_signer(),\n                                                recipient_key=self.bob.public_keys(DecryptingPower))\n\n        # TODO: Signal revocation without using encrypted kfrag\n        revocation_kit = RevocationKit(treasure_map=treasure_map, signer=self.publisher.stamp)\n\n        enacted_policy = EnactedPolicy(self.hrac,\n                                       self.label,\n                                       self.public_key,\n                                       treasure_map.threshold,\n                                       enc_treasure_map,\n                                       revocation_kit,\n                                       self.publisher.stamp.as_umbral_pubkey())\n\n        return enacted_policy",
  "def _make_reservoir(self, handpicked_addresses: List[ChecksumAddress]):\n        \"\"\"Returns a federated node reservoir for creating a federated policy.\"\"\"\n        return make_federated_staker_reservoir(known_nodes=self.publisher.known_nodes,\n                                               include_addresses=handpicked_addresses)",
  "def _make_reservoir(self, handpicked_addresses: List[ChecksumAddress]):\n        \"\"\"Returns a reservoir of staking nodes to create a decentralized policy.\"\"\"\n        reservoir = make_decentralized_staking_provider_reservoir(application_agent=self.publisher.application_agent,\n                                                                  include_addresses=handpicked_addresses)\n        return reservoir",
  "def __init__(self,\n                 hrac: HRAC,\n                 label: bytes,\n                 public_key: PublicKey,\n                 threshold: int,\n                 treasure_map: 'EncryptedTreasureMap',\n                 revocation_kit: RevocationKit,\n                 publisher_verifying_key: PublicKey):\n\n        self.hrac = hrac\n        self.label = label\n        self.public_key = public_key\n        self.treasure_map = treasure_map\n        self.revocation_kit = revocation_kit\n        self.threshold = threshold\n        self.shares = len(self.revocation_kit)\n        self.publisher_verifying_key = publisher_verifying_key",
  "def worker(address) -> 'Ursula':\n            return self._ping_node(address, network_middleware)",
  "class PaymentMethod(ABC):\n    \"\"\"Extends ReencryptionPrerequisite to facilitate policy payment and payment verification.\"\"\"\n\n    class Quote(NamedTuple):\n        rate: int\n        value: int\n        commencement: int  # epoch\n        expiration: int    # epoch\n        duration: int      # seconds or periods\n        shares: int\n\n    @abstractmethod\n    def pay(self, policy: Policy) -> Dict:\n        \"\"\"Carry out payment for the given policy.\"\"\"\n        raise NotImplemented\n\n    @property\n    @abstractmethod\n    def rate(self) -> int:\n        \"\"\"The cost of this payment method per unit.\"\"\"\n        raise NotImplemented\n\n    @abstractmethod\n    def quote(self,\n              shares: int,\n              duration: Optional[int] = None,\n              commencement: Optional[Timestamp] = None,\n              expiration: Optional[int] = None,\n              value: Optional[int] = None,\n              rate: Optional[int] = None\n              ) -> Quote:\n        \"\"\"Generates a valid quote for this payment method using pricing details.\"\"\"\n        raise NotImplemented\n\n    @abstractmethod\n    def validate_price(self,\n                       shares: int,\n                       value: int,\n                       duration: int) -> None:\n        raise NotImplemented",
  "class ContractPayment(PaymentMethod, ABC):\n    \"\"\"Baseclass for on-chain policy payment; Requires a blockchain connection.\"\"\"\n\n    ONCHAIN = True\n    _AGENT = NotImplemented\n\n    class Quote(PaymentMethod.Quote):\n        rate: Wei\n        value: Wei\n\n    def __init__(self,\n                 eth_provider: str,\n                 network: str,\n                 registry: Optional[BaseContractRegistry] = None,\n                 *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.provider = eth_provider\n        self.network = network\n        if not registry:\n            registry = InMemoryContractRegistry.from_latest_publication(network=network)\n        self.registry = registry\n        self.__agent = None  # delay blockchain/registry reads until later\n\n    @property\n    def agent(self):\n        \"\"\"Returns an instance of the agent used to carry out contract payments.\"\"\"\n        if self.__agent:\n            return self.__agent  # get cache\n        agent = ContractAgency.get_agent(\n            agent_class=self._AGENT,\n            eth_provider_uri=self.provider,\n            registry=self.registry\n        )\n        self.__agent = agent\n        return self.__agent",
  "class SubscriptionManagerPayment(ContractPayment):\n    \"\"\"Handle policy payment using the SubscriptionManager contract.\"\"\"\n\n    _AGENT = SubscriptionManagerAgent\n    NAME = 'SubscriptionManager'\n\n    def verify(self, payee: ChecksumAddress, request: ReencryptionRequest) -> bool:\n        \"\"\"Verify policy payment by reading the SubscriptionManager contract\"\"\"\n        result = self.agent.is_policy_active(policy_id=bytes(request.hrac))\n        return result\n\n    def pay(self, policy: BlockchainPolicy) -> TxReceipt:\n        \"\"\"Writes a new policy to the SubscriptionManager contract.\"\"\"\n        receipt = self.agent.create_policy(\n            value=policy.value,                   # wei\n            policy_id=bytes(policy.hrac),         # bytes16 _policyID\n            size=len(policy.kfrags),              # uint16\n            start_timestamp=policy.commencement,  # uint16\n            end_timestamp=policy.expiration,      # uint16\n            transacting_power=policy.publisher.transacting_power\n        )\n        return receipt\n\n    @property\n    def rate(self) -> Wei:\n        fixed_rate = self.agent.fee_rate()\n        return Wei(fixed_rate)\n\n    def quote(self,\n              shares: int,\n              commencement: Optional[Timestamp] = None,\n              expiration: Optional[Timestamp] = None,\n              duration: Optional[int] = None,\n              value: Optional[Wei] = None,\n              rate: Optional[Wei] = None,\n              *args, **kwargs\n              ) -> PaymentMethod.Quote:\n        \"\"\"\n        A quote for the SubscriptionManager is calculated as rate * duration seconds\n        \"\"\"\n        # TODO: This section is over-complicated and needs improvement but works for basic cases.\n\n        # invalid input\n        if rate:\n            raise ValueError(f\"{self._AGENT.contract_name} uses a fixed rate.\")\n        if not any((duration, expiration, value)):\n            raise ValueError(\"Policy end time must be specified with 'expiration', 'duration' or 'value'.\")\n        if sum(True for i in (commencement, expiration, duration, value, rate) if i is not None and i < 0) > 0:\n            raise ValueError(f\"Negative policy parameters are not allowed. Be positive.\")\n\n        if not commencement:\n            if expiration and duration:\n                commencement = expiration - duration  # reverse\n            else:\n                commencement = maya.now().epoch  # start now\n\n        if not duration:\n            if expiration and commencement:\n                duration = expiration - commencement\n\n        q = self.Quote(\n            rate=Wei(self.rate),\n            value=Wei(self.rate * duration * shares),\n            shares=shares,\n            commencement=Timestamp(commencement),\n            expiration=Timestamp(expiration),\n            duration=duration\n        )\n        return q\n\n    def validate_price(self, value: Wei, duration: Wei, shares: int, *args, **kwargs) -> bool:\n        expected_price = Wei(shares * duration * self.rate)\n        if value != expected_price:\n            raise ValueError(f\"Policy value ({value}) doesn't match expected value ({expected_price})\")\n        return True",
  "class FreeReencryptions(PaymentMethod):\n    \"\"\"Useful for private federations and testing.\"\"\"\n\n    ONCHAIN = False\n    NAME = 'Free'\n\n    def verify(self, payee: ChecksumAddress, request: ReencryptionRequest) -> bool:\n        return True\n\n    def pay(self, policy: Policy) -> Dict:\n        receipt = f'Receipt for free policy {bytes(policy.hrac).hex()}.'\n        return dict(receipt=receipt.encode())\n\n    @property\n    def rate(self) -> int:\n        return 0\n\n    def quote(self,\n              shares: int,\n              commencement: Optional[Timestamp] = None,\n              expiration: Optional[Timestamp] = None,\n              duration: Optional[int] = None,\n              *args, **kwargs\n              ) -> PaymentMethod.Quote:\n        return self.Quote(\n            value=0,\n            rate=0,\n            shares=shares,\n            duration=duration,\n            commencement=commencement,\n            expiration=expiration\n        )\n\n    def validate_price(self, *args, **kwargs) -> bool:\n        return True",
  "class Quote(NamedTuple):\n        rate: int\n        value: int\n        commencement: int  # epoch\n        expiration: int    # epoch\n        duration: int      # seconds or periods\n        shares: int",
  "def pay(self, policy: Policy) -> Dict:\n        \"\"\"Carry out payment for the given policy.\"\"\"\n        raise NotImplemented",
  "def rate(self) -> int:\n        \"\"\"The cost of this payment method per unit.\"\"\"\n        raise NotImplemented",
  "def quote(self,\n              shares: int,\n              duration: Optional[int] = None,\n              commencement: Optional[Timestamp] = None,\n              expiration: Optional[int] = None,\n              value: Optional[int] = None,\n              rate: Optional[int] = None\n              ) -> Quote:\n        \"\"\"Generates a valid quote for this payment method using pricing details.\"\"\"\n        raise NotImplemented",
  "def validate_price(self,\n                       shares: int,\n                       value: int,\n                       duration: int) -> None:\n        raise NotImplemented",
  "class Quote(PaymentMethod.Quote):\n        rate: Wei\n        value: Wei",
  "def __init__(self,\n                 eth_provider: str,\n                 network: str,\n                 registry: Optional[BaseContractRegistry] = None,\n                 *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.provider = eth_provider\n        self.network = network\n        if not registry:\n            registry = InMemoryContractRegistry.from_latest_publication(network=network)\n        self.registry = registry\n        self.__agent = None",
  "def agent(self):\n        \"\"\"Returns an instance of the agent used to carry out contract payments.\"\"\"\n        if self.__agent:\n            return self.__agent  # get cache\n        agent = ContractAgency.get_agent(\n            agent_class=self._AGENT,\n            eth_provider_uri=self.provider,\n            registry=self.registry\n        )\n        self.__agent = agent\n        return self.__agent",
  "def verify(self, payee: ChecksumAddress, request: ReencryptionRequest) -> bool:\n        \"\"\"Verify policy payment by reading the SubscriptionManager contract\"\"\"\n        result = self.agent.is_policy_active(policy_id=bytes(request.hrac))\n        return result",
  "def pay(self, policy: BlockchainPolicy) -> TxReceipt:\n        \"\"\"Writes a new policy to the SubscriptionManager contract.\"\"\"\n        receipt = self.agent.create_policy(\n            value=policy.value,                   # wei\n            policy_id=bytes(policy.hrac),         # bytes16 _policyID\n            size=len(policy.kfrags),              # uint16\n            start_timestamp=policy.commencement,  # uint16\n            end_timestamp=policy.expiration,      # uint16\n            transacting_power=policy.publisher.transacting_power\n        )\n        return receipt",
  "def rate(self) -> Wei:\n        fixed_rate = self.agent.fee_rate()\n        return Wei(fixed_rate)",
  "def quote(self,\n              shares: int,\n              commencement: Optional[Timestamp] = None,\n              expiration: Optional[Timestamp] = None,\n              duration: Optional[int] = None,\n              value: Optional[Wei] = None,\n              rate: Optional[Wei] = None,\n              *args, **kwargs\n              ) -> PaymentMethod.Quote:\n        \"\"\"\n        A quote for the SubscriptionManager is calculated as rate * duration seconds\n        \"\"\"\n        # TODO: This section is over-complicated and needs improvement but works for basic cases.\n\n        # invalid input\n        if rate:\n            raise ValueError(f\"{self._AGENT.contract_name} uses a fixed rate.\")\n        if not any((duration, expiration, value)):\n            raise ValueError(\"Policy end time must be specified with 'expiration', 'duration' or 'value'.\")\n        if sum(True for i in (commencement, expiration, duration, value, rate) if i is not None and i < 0) > 0:\n            raise ValueError(f\"Negative policy parameters are not allowed. Be positive.\")\n\n        if not commencement:\n            if expiration and duration:\n                commencement = expiration - duration  # reverse\n            else:\n                commencement = maya.now().epoch  # start now\n\n        if not duration:\n            if expiration and commencement:\n                duration = expiration - commencement\n\n        q = self.Quote(\n            rate=Wei(self.rate),\n            value=Wei(self.rate * duration * shares),\n            shares=shares,\n            commencement=Timestamp(commencement),\n            expiration=Timestamp(expiration),\n            duration=duration\n        )\n        return q",
  "def validate_price(self, value: Wei, duration: Wei, shares: int, *args, **kwargs) -> bool:\n        expected_price = Wei(shares * duration * self.rate)\n        if value != expected_price:\n            raise ValueError(f\"Policy value ({value}) doesn't match expected value ({expected_price})\")\n        return True",
  "def verify(self, payee: ChecksumAddress, request: ReencryptionRequest) -> bool:\n        return True",
  "def pay(self, policy: Policy) -> Dict:\n        receipt = f'Receipt for free policy {bytes(policy.hrac).hex()}.'\n        return dict(receipt=receipt.encode())",
  "def rate(self) -> int:\n        return 0",
  "def quote(self,\n              shares: int,\n              commencement: Optional[Timestamp] = None,\n              expiration: Optional[Timestamp] = None,\n              duration: Optional[int] = None,\n              *args, **kwargs\n              ) -> PaymentMethod.Quote:\n        return self.Quote(\n            value=0,\n            rate=0,\n            shares=shares,\n            duration=duration,\n            commencement=commencement,\n            expiration=expiration\n        )",
  "def validate_price(self, *args, **kwargs) -> bool:\n        return True",
  "def make_federated_staker_reservoir(known_nodes: FleetSensor,\n                                    exclude_addresses: Optional[Iterable[ChecksumAddress]] = None,\n                                    include_addresses: Optional[Iterable[ChecksumAddress]] = None):\n    \"\"\"Get a sampler object containing the federated stakers.\"\"\"\n    # needs to not include both exclude and include addresses\n    # so that they aren't included in reservoir, include_address will be re-added to reservoir afterwards\n    include_addresses = include_addresses or ()\n    exclusion_set = set(include_addresses) | set(exclude_addresses or ())\n    addresses = {}\n    for ursula in known_nodes:\n        if ursula.checksum_address in exclusion_set:\n            continue\n        addresses[ursula.checksum_address] = 1\n\n    # add include addresses\n    return MergedReservoir(include_addresses, StakingProvidersReservoir(addresses))",
  "def make_decentralized_staking_provider_reservoir(application_agent: PREApplicationAgent,\n                                                  exclude_addresses: Optional[Iterable[ChecksumAddress]] = None,\n                                                  include_addresses: Optional[Iterable[ChecksumAddress]] = None,\n                                                  pagination_size: int = None):\n    \"\"\"Get a sampler object containing the currently registered staking providers.\"\"\"\n\n    # needs to not include both exclude and include addresses\n    # so that they aren't included in reservoir, include_address will be re-added to reservoir afterwards\n    include_addresses = include_addresses or ()\n    without_set = set(include_addresses) | set(exclude_addresses or ())\n    try:\n        reservoir = application_agent.get_staking_provider_reservoir(without=without_set, pagination_size=pagination_size)\n    except PREApplicationAgent.NotEnoughStakingProviders:\n        # TODO: do that in `get_staking_provider_reservoir()`?\n        reservoir = StakingProvidersReservoir({})\n\n    # add include addresses\n    return MergedReservoir(include_addresses, reservoir)",
  "class MergedReservoir:\n    \"\"\"\n    A reservoir made of a list of addresses and a StakingProviderReservoir.\n    Draws the values from the list first, then from StakingProviderReservoir,\n    then returns None on subsequent calls.\n    \"\"\"\n\n    def __init__(self, values: Iterable, reservoir: StakingProvidersReservoir):\n        self.values = list(values)\n        self.reservoir = reservoir\n\n    def __call__(self) -> Optional[ChecksumAddress]:\n        if self.values:\n            return self.values.pop(0)\n        elif len(self.reservoir) > 0:\n            return self.reservoir.draw(1)[0]\n        else:\n            return None",
  "class PrefetchStrategy:\n    \"\"\"\n    Encapsulates the batch draw strategy from a reservoir.\n    Determines how many values to draw based on the number of values\n    that have already led to successes.\n    \"\"\"\n\n    def __init__(self, reservoir: MergedReservoir, need_successes: int):\n        self.reservoir = reservoir\n        self.need_successes = need_successes\n\n    def __call__(self, successes: int) -> Optional[List[ChecksumAddress]]:\n        batch = []\n        for i in range(self.need_successes - successes):\n            value = self.reservoir()\n            if value is None:\n                break\n            batch.append(value)\n        if not batch:\n            return None\n        return batch",
  "def __init__(self, values: Iterable, reservoir: StakingProvidersReservoir):\n        self.values = list(values)\n        self.reservoir = reservoir",
  "def __call__(self) -> Optional[ChecksumAddress]:\n        if self.values:\n            return self.values.pop(0)\n        elif len(self.reservoir) > 0:\n            return self.reservoir.draw(1)[0]\n        else:\n            return None",
  "def __init__(self, reservoir: MergedReservoir, need_successes: int):\n        self.reservoir = reservoir\n        self.need_successes = need_successes",
  "def __call__(self, successes: int) -> Optional[List[ChecksumAddress]]:\n        batch = []\n        for i in range(self.need_successes - successes):\n            value = self.reservoir()\n            if value is None:\n                break\n            batch.append(value)\n        if not batch:\n            return None\n        return batch",
  "class PolicyMessageKit:\n\n    @classmethod\n    def from_message_kit(cls,\n                         message_kit: MessageKit,\n                         policy_encrypting_key: PublicKey,\n                         threshold: int\n                         ) -> 'PolicyMessageKit':\n        return cls(policy_encrypting_key, threshold, RetrievalResult.empty(), message_kit)\n\n    def __init__(self,\n                 policy_encrypting_key: PublicKey,\n                 threshold: int,\n                 result: 'RetrievalResult',\n                 message_kit: MessageKit,\n                 ):\n        self.message_kit = message_kit\n        self.policy_encrypting_key = policy_encrypting_key\n        self.threshold = threshold\n        self._result = result\n\n    def as_retrieval_kit(self) -> RetrievalKit:\n        return RetrievalKit(\n            capsule=self.message_kit.capsule,\n            queried_addresses=self._result.canonical_addresses(),\n            conditions=self.message_kit.conditions,\n        )\n\n    def decrypt(self, sk: SecretKey) -> bytes:\n        return self.message_kit.decrypt_reencrypted(sk,\n                                                    self.policy_encrypting_key,\n                                                    list(self._result.cfrags.values()))\n\n    def is_decryptable_by_receiver(self) -> bool:\n        return len(self._result.cfrags) >= self.threshold\n\n    def with_result(self, result: 'RetrievalResult') -> 'PolicyMessageKit':\n        return PolicyMessageKit(policy_encrypting_key=self.policy_encrypting_key,\n                                threshold=self.threshold,\n                                result=self._result.with_result(result),\n                                message_kit=self.message_kit)\n\n    @property\n    def conditions(self) -> Conditions:\n        return self.message_kit.conditions",
  "class RetrievalResult:\n    \"\"\"\n    An object representing retrieval results for a single capsule.\n    \"\"\"\n\n    @classmethod\n    def empty(cls):\n        return cls({})\n\n    def __init__(self, cfrags: Dict[ChecksumAddress, VerifiedCapsuleFrag]):\n        self.cfrags = cfrags\n\n    def canonical_addresses(self) -> Set[Address]:\n        # TODO (#1995): propagate this to use canonical addresses everywhere\n        return set([Address(to_canonical_address(address)) for address in self.cfrags])\n\n    def with_result(self, result: 'RetrievalResult') -> 'RetrievalResult':\n        \"\"\"\n        Joins two RetrievalResult objects.\n\n        If both objects contain cfrags from the same Ursula,\n        the one from `result` will be kept.\n        \"\"\"\n        # TODO: would `+` or `|` operator be more suitable here?\n\n        # TODO: check for overlap?\n        new_cfrags = dict(self.cfrags)\n        new_cfrags.update(result.cfrags)\n        return RetrievalResult(cfrags=new_cfrags)",
  "def from_message_kit(cls,\n                         message_kit: MessageKit,\n                         policy_encrypting_key: PublicKey,\n                         threshold: int\n                         ) -> 'PolicyMessageKit':\n        return cls(policy_encrypting_key, threshold, RetrievalResult.empty(), message_kit)",
  "def __init__(self,\n                 policy_encrypting_key: PublicKey,\n                 threshold: int,\n                 result: 'RetrievalResult',\n                 message_kit: MessageKit,\n                 ):\n        self.message_kit = message_kit\n        self.policy_encrypting_key = policy_encrypting_key\n        self.threshold = threshold\n        self._result = result",
  "def as_retrieval_kit(self) -> RetrievalKit:\n        return RetrievalKit(\n            capsule=self.message_kit.capsule,\n            queried_addresses=self._result.canonical_addresses(),\n            conditions=self.message_kit.conditions,\n        )",
  "def decrypt(self, sk: SecretKey) -> bytes:\n        return self.message_kit.decrypt_reencrypted(sk,\n                                                    self.policy_encrypting_key,\n                                                    list(self._result.cfrags.values()))",
  "def is_decryptable_by_receiver(self) -> bool:\n        return len(self._result.cfrags) >= self.threshold",
  "def with_result(self, result: 'RetrievalResult') -> 'PolicyMessageKit':\n        return PolicyMessageKit(policy_encrypting_key=self.policy_encrypting_key,\n                                threshold=self.threshold,\n                                result=self._result.with_result(result),\n                                message_kit=self.message_kit)",
  "def conditions(self) -> Conditions:\n        return self.message_kit.conditions",
  "def empty(cls):\n        return cls({})",
  "def __init__(self, cfrags: Dict[ChecksumAddress, VerifiedCapsuleFrag]):\n        self.cfrags = cfrags",
  "def canonical_addresses(self) -> Set[Address]:\n        # TODO (#1995): propagate this to use canonical addresses everywhere\n        return set([Address(to_canonical_address(address)) for address in self.cfrags])",
  "def with_result(self, result: 'RetrievalResult') -> 'RetrievalResult':\n        \"\"\"\n        Joins two RetrievalResult objects.\n\n        If both objects contain cfrags from the same Ursula,\n        the one from `result` will be kept.\n        \"\"\"\n        # TODO: would `+` or `|` operator be more suitable here?\n\n        # TODO: check for overlap?\n        new_cfrags = dict(self.cfrags)\n        new_cfrags.update(result.cfrags)\n        return RetrievalResult(cfrags=new_cfrags)",
  "def _resolve_abi(\n        w3: Web3,\n        method: str,\n        standard_contract_type: Optional[str] = None,\n        function_abi: Optional[ABIFunction] = None,\n) -> ABIFunction:\n    \"\"\"Resolves the contract an/or function ABI from a standard contract name\"\"\"\n\n    if not (function_abi or standard_contract_type):\n        raise InvalidCondition(\n            f\"Ambiguous ABI - Supply either an ABI or a standard contract type ({STANDARD_ABI_CONTRACT_TYPES}).\"\n        )\n\n    if standard_contract_type:\n        try:\n            # Lookup the standard ABI given it's ERC standard name (standard contract type)\n            contract_abi = STANDARD_ABIS[standard_contract_type]\n        except KeyError:\n            raise InvalidCondition(\n                f\"Invalid standard contract type {standard_contract_type}; Must be one of {STANDARD_ABI_CONTRACT_TYPES}\"\n            )\n\n        try:\n            # Extract all function ABIs from the contract's ABI.\n            # Will raise a ValueError if there is not exactly one match.\n            function_abi = w3.eth.contract(abi=contract_abi).get_function_by_name(method).abi\n        except ValueError as e:\n            raise InvalidCondition(str(e))\n\n    return ABIFunction(function_abi)",
  "def _resolve_any_context_variables(\n        parameters: List[Any], return_value_test: ReturnValueTest, **context\n):\n    processed_parameters = []\n    for p in parameters:\n        # TODO needs additional support for ERC1155 which has lists of values\n        # context variables can only be strings, but other types of parameters can be passed\n        if is_context_variable(p):\n            p = get_context_value(context_variable=p, **context)\n        processed_parameters.append(p)\n\n    v = return_value_test.value\n    if is_context_variable(v):\n        v = get_context_value(context_variable=v, **context)\n    k = return_value_test.key\n    if is_context_variable(k):\n        k = get_context_value(context_variable=k, **context)\n    processed_return_value_test = ReturnValueTest(\n        return_value_test.comparator, value=v, key=k\n    )\n\n    return processed_parameters, processed_return_value_test",
  "def _validate_chain(chain: int) -> None:\n    if not isinstance(chain, int):\n        raise ValueError(f'\"The chain\" field of c a condition must be the '\n                         f'integer of a chain ID (got \"{chain}\").')\n    if chain not in _CONDITION_CHAINS:\n        raise InvalidCondition(\n            f\"chain ID {chain} is not a permitted \"\n            f\"blockchain for condition evaluation.\"\n        )",
  "class RPCCondition(ReencryptionCondition):\n    ALLOWED_METHODS = (\n\n        # Contract\n        'balanceOf',\n\n        # RPC\n        'eth_getBalance',\n    )  # TODO other allowed methods (tDEC #64)\n\n    class Schema(CamelCaseSchema):\n        SKIP_VALUES = (None,)\n        name = fields.Str(required=False)\n        chain = fields.Int(required=True)\n        method = fields.Str(required=True)\n        parameters = fields.List(fields.Field, attribute='parameters', required=False)\n        return_value_test = fields.Nested(ReturnValueTest.ReturnValueTestSchema(), required=True)\n\n        @post_load\n        def make(self, data, **kwargs):\n            return RPCCondition(**data)\n\n    def __repr__(self) -> str:\n        r = f'{self.__class__.__name__}(function={self.method}, chain={self.chain})'\n        return r\n\n    def __init__(\n        self,\n        chain: int,\n        method: str,\n        return_value_test: ReturnValueTest,\n        name: Optional[str] = None,\n        parameters: Optional[List[Any]] = None,\n    ):\n\n        # Validate input\n        # TODO: Additional validation (function is valid for ABI, RVT validity, standard contract name validity, etc.)\n        _validate_chain(chain=chain)\n\n        # internal\n        self.name = name\n        self.chain = chain\n        self.method = self.validate_method(method=method)\n\n        # test\n        self.parameters = parameters  # input\n        self.return_value_test = return_value_test  # output\n\n    def validate_method(self, method):\n        if method not in self.ALLOWED_METHODS:\n            raise InvalidCondition(\n                f\"'{method}' is not a permitted RPC endpoint for condition evaluation.\"\n            )\n        if not method.startswith('eth_'):\n            raise InvalidCondition(\n                f\"Only 'eth_' RPC methods are accepted for condition evaluation; '{method}' is not permitted.\"\n            )\n        return method\n\n    def _configure_provider(self, providers: Dict[int, BaseProvider]):\n        \"\"\"Binds the condition's contract function to a blockchian provider for evaluation\"\"\"\n        try:\n            provider = providers[self.chain]\n        except KeyError:\n            raise NoConnectionToChain(chain=self.chain)\n\n        # Instantiate a local web3 instance\n        self.w3 = Web3(provider)\n\n        # This next block validates that the actual web3 provider is *actually*\n        # connected to the condition's chain ID by reading its RPC endpoint.\n        provider_chain = self.w3.eth.chain_id\n        if provider_chain != self.chain:\n            raise InvalidCondition(\n                f\"This condition can only be evaluated on chain ID {self.chain} but the provider's \"\n                f\"connection is to chain ID {provider_chain}\"\n            )\n        return provider\n\n    def _get_web3_py_function(self, rpc_method: str):\n        web3_py_method = camel_case_to_snake(rpc_method)\n        rpc_function = getattr(\n            self.w3.eth, web3_py_method\n        )  # bind contract function (only exposes the eth API)\n        return rpc_function\n\n    def _execute_call(self, parameters: List[Any]) -> Any:\n        \"\"\"Execute onchain read and return result.\"\"\"\n        rpc_endpoint_, rpc_method = self.method.split(\"_\", 1)\n        rpc_function = self._get_web3_py_function(rpc_method)\n        rpc_result = rpc_function(*parameters)  # RPC read\n        return rpc_result\n\n    def verify(self, providers: Dict[int, BaseProvider], **context) -> Tuple[bool, Any]:\n        \"\"\"\n        Verifies the onchain condition is met by performing a\n        read operation and evaluating the return value test.\n        \"\"\"\n        self._configure_provider(providers=providers)\n        parameters, return_value_test = _resolve_any_context_variables(\n            self.parameters, self.return_value_test, **context\n        )\n        try:\n            result = self._execute_call(parameters=parameters)\n        except Exception as e:\n            raise RPCExecutionFailed(f\"Contract call '{self.method}' failed: {e}\")\n\n        eval_result = return_value_test.eval(result)  # test\n        return eval_result, result",
  "class ContractCondition(RPCCondition):\n    class Schema(RPCCondition.Schema):\n        standard_contract_type = fields.Str(required=False)\n        contract_address = fields.Str(required=True)\n        function_abi = fields.Dict(required=False)\n\n        @post_load\n        def make(self, data, **kwargs):\n            return ContractCondition(**data)\n\n        @validates_schema\n        def check_standard_contract_type_or_function_abi(self, data, **kwargs):\n            standard_contract_type = data.get(\"standard_contract_type\")\n            function_abi = data.get(\"function_abi\")\n            if not (bool(standard_contract_type) ^ bool(function_abi)):\n                raise InvalidCondition(\n                    f\"Provide 'standardContractType' or 'functionAbi'; got ({standard_contract_type}, {function_abi}).\"\n                )\n\n    def __init__(\n        self,\n        contract_address: ChecksumAddress,\n        standard_contract_type: Optional[str] = None,\n        function_abi: Optional[ABIFunction] = None,\n        *args,\n        **kwargs\n    ):\n        # internal\n        super().__init__(*args, **kwargs)\n        self.w3 = Web3()  # used to instantiate contract function without a provider\n\n        if not (bool(standard_contract_type) ^ bool(function_abi)):\n            raise InvalidCondition(\n                f\"Provide 'standard_contract_type' or 'function_abi'; got ({standard_contract_type}, {function_abi}).\"\n            )\n\n        # preprocessing\n        contract_address = to_checksum_address(contract_address)\n\n        # spec\n        self.contract_address = contract_address\n        self.standard_contract_type = standard_contract_type\n        self.function_abi = function_abi\n        self.contract_function = self._get_unbound_contract_function()\n\n    def __repr__(self) -> str:\n        r = f'{self.__class__.__name__}(function={self.method}, ' \\\n            f'contract={self.contract_address[:6]}..., ' \\\n            f'chain={self.chain})'\n        return r\n\n    def validate_method(self, method):\n        return method\n\n    def _configure_provider(self, *args, **kwargs):\n        super()._configure_provider(*args, **kwargs)\n        self.contract_function.w3 = self.w3\n\n    def _get_unbound_contract_function(self) -> ContractFunction:\n        \"\"\"Gets an unbound contract function to evaluate for this condition\"\"\"\n        function_abi = _resolve_abi(\n            w3=self.w3,\n            standard_contract_type=self.standard_contract_type,\n            method=self.method,\n            function_abi=self.function_abi,\n        )\n        try:\n            contract = self.w3.eth.contract(\n                address=self.contract_address, abi=[function_abi]\n            )\n            contract_function = getattr(contract.functions, self.method)\n            return contract_function\n        except Exception as e:\n            raise InvalidCondition(\n                f\"Unable to find contract function, '{self.method}', for condition: {e}\"\n            )\n\n    def _execute_call(self, parameters: List[Any]) -> Any:\n        \"\"\"Execute onchain read and return result.\"\"\"\n        bound_contract_function = self.contract_function(\n            *parameters\n        )  # bind contract function\n        contract_result = bound_contract_function.call()  # onchain read\n        return contract_result",
  "class Schema(CamelCaseSchema):\n        SKIP_VALUES = (None,)\n        name = fields.Str(required=False)\n        chain = fields.Int(required=True)\n        method = fields.Str(required=True)\n        parameters = fields.List(fields.Field, attribute='parameters', required=False)\n        return_value_test = fields.Nested(ReturnValueTest.ReturnValueTestSchema(), required=True)\n\n        @post_load\n        def make(self, data, **kwargs):\n            return RPCCondition(**data)",
  "def __repr__(self) -> str:\n        r = f'{self.__class__.__name__}(function={self.method}, chain={self.chain})'\n        return r",
  "def __init__(\n        self,\n        chain: int,\n        method: str,\n        return_value_test: ReturnValueTest,\n        name: Optional[str] = None,\n        parameters: Optional[List[Any]] = None,\n    ):\n\n        # Validate input\n        # TODO: Additional validation (function is valid for ABI, RVT validity, standard contract name validity, etc.)\n        _validate_chain(chain=chain)\n\n        # internal\n        self.name = name\n        self.chain = chain\n        self.method = self.validate_method(method=method)\n\n        # test\n        self.parameters = parameters  # input\n        self.return_value_test = return_value_test",
  "def validate_method(self, method):\n        if method not in self.ALLOWED_METHODS:\n            raise InvalidCondition(\n                f\"'{method}' is not a permitted RPC endpoint for condition evaluation.\"\n            )\n        if not method.startswith('eth_'):\n            raise InvalidCondition(\n                f\"Only 'eth_' RPC methods are accepted for condition evaluation; '{method}' is not permitted.\"\n            )\n        return method",
  "def _configure_provider(self, providers: Dict[int, BaseProvider]):\n        \"\"\"Binds the condition's contract function to a blockchian provider for evaluation\"\"\"\n        try:\n            provider = providers[self.chain]\n        except KeyError:\n            raise NoConnectionToChain(chain=self.chain)\n\n        # Instantiate a local web3 instance\n        self.w3 = Web3(provider)\n\n        # This next block validates that the actual web3 provider is *actually*\n        # connected to the condition's chain ID by reading its RPC endpoint.\n        provider_chain = self.w3.eth.chain_id\n        if provider_chain != self.chain:\n            raise InvalidCondition(\n                f\"This condition can only be evaluated on chain ID {self.chain} but the provider's \"\n                f\"connection is to chain ID {provider_chain}\"\n            )\n        return provider",
  "def _get_web3_py_function(self, rpc_method: str):\n        web3_py_method = camel_case_to_snake(rpc_method)\n        rpc_function = getattr(\n            self.w3.eth, web3_py_method\n        )  # bind contract function (only exposes the eth API)\n        return rpc_function",
  "def _execute_call(self, parameters: List[Any]) -> Any:\n        \"\"\"Execute onchain read and return result.\"\"\"\n        rpc_endpoint_, rpc_method = self.method.split(\"_\", 1)\n        rpc_function = self._get_web3_py_function(rpc_method)\n        rpc_result = rpc_function(*parameters)  # RPC read\n        return rpc_result",
  "def verify(self, providers: Dict[int, BaseProvider], **context) -> Tuple[bool, Any]:\n        \"\"\"\n        Verifies the onchain condition is met by performing a\n        read operation and evaluating the return value test.\n        \"\"\"\n        self._configure_provider(providers=providers)\n        parameters, return_value_test = _resolve_any_context_variables(\n            self.parameters, self.return_value_test, **context\n        )\n        try:\n            result = self._execute_call(parameters=parameters)\n        except Exception as e:\n            raise RPCExecutionFailed(f\"Contract call '{self.method}' failed: {e}\")\n\n        eval_result = return_value_test.eval(result)  # test\n        return eval_result, result",
  "class Schema(RPCCondition.Schema):\n        standard_contract_type = fields.Str(required=False)\n        contract_address = fields.Str(required=True)\n        function_abi = fields.Dict(required=False)\n\n        @post_load\n        def make(self, data, **kwargs):\n            return ContractCondition(**data)\n\n        @validates_schema\n        def check_standard_contract_type_or_function_abi(self, data, **kwargs):\n            standard_contract_type = data.get(\"standard_contract_type\")\n            function_abi = data.get(\"function_abi\")\n            if not (bool(standard_contract_type) ^ bool(function_abi)):\n                raise InvalidCondition(\n                    f\"Provide 'standardContractType' or 'functionAbi'; got ({standard_contract_type}, {function_abi}).\"\n                )",
  "def __init__(\n        self,\n        contract_address: ChecksumAddress,\n        standard_contract_type: Optional[str] = None,\n        function_abi: Optional[ABIFunction] = None,\n        *args,\n        **kwargs\n    ):\n        # internal\n        super().__init__(*args, **kwargs)\n        self.w3 = Web3()  # used to instantiate contract function without a provider\n\n        if not (bool(standard_contract_type) ^ bool(function_abi)):\n            raise InvalidCondition(\n                f\"Provide 'standard_contract_type' or 'function_abi'; got ({standard_contract_type}, {function_abi}).\"\n            )\n\n        # preprocessing\n        contract_address = to_checksum_address(contract_address)\n\n        # spec\n        self.contract_address = contract_address\n        self.standard_contract_type = standard_contract_type\n        self.function_abi = function_abi\n        self.contract_function = self._get_unbound_contract_function()",
  "def __repr__(self) -> str:\n        r = f'{self.__class__.__name__}(function={self.method}, ' \\\n            f'contract={self.contract_address[:6]}..., ' \\\n            f'chain={self.chain})'\n        return r",
  "def validate_method(self, method):\n        return method",
  "def _configure_provider(self, *args, **kwargs):\n        super()._configure_provider(*args, **kwargs)\n        self.contract_function.w3 = self.w3",
  "def _get_unbound_contract_function(self) -> ContractFunction:\n        \"\"\"Gets an unbound contract function to evaluate for this condition\"\"\"\n        function_abi = _resolve_abi(\n            w3=self.w3,\n            standard_contract_type=self.standard_contract_type,\n            method=self.method,\n            function_abi=self.function_abi,\n        )\n        try:\n            contract = self.w3.eth.contract(\n                address=self.contract_address, abi=[function_abi]\n            )\n            contract_function = getattr(contract.functions, self.method)\n            return contract_function\n        except Exception as e:\n            raise InvalidCondition(\n                f\"Unable to find contract function, '{self.method}', for condition: {e}\"\n            )",
  "def _execute_call(self, parameters: List[Any]) -> Any:\n        \"\"\"Execute onchain read and return result.\"\"\"\n        bound_contract_function = self.contract_function(\n            *parameters\n        )  # bind contract function\n        contract_result = bound_contract_function.call()  # onchain read\n        return contract_result",
  "def make(self, data, **kwargs):\n            return RPCCondition(**data)",
  "def make(self, data, **kwargs):\n            return ContractCondition(**data)",
  "def check_standard_contract_type_or_function_abi(self, data, **kwargs):\n            standard_contract_type = data.get(\"standard_contract_type\")\n            function_abi = data.get(\"function_abi\")\n            if not (bool(standard_contract_type) ^ bool(function_abi)):\n                raise InvalidCondition(\n                    f\"Provide 'standardContractType' or 'functionAbi'; got ({standard_contract_type}, {function_abi}).\"\n                )",
  "class UserAddress(EIP712Struct):\n    address = String()\n    blockNumber = Uint()\n    blockHash = Bytes(32)\n    signatureText = String()",
  "def _recover_user_address(**context) -> ChecksumAddress:\n    # Expected format:\n    # {\n    #     \":userAddress\":\n    #         {\n    #             \"signature\": \"<signature>\",\n    #             \"address\": \"<address>\",\n    #             \"typedData\": \"<a complicated EIP712 data structure>\"\n    #         }\n    # }\n\n    # setup\n    try:\n        user_address_info = context[USER_ADDRESS_CONTEXT]\n        signature = user_address_info[\"signature\"]\n        user_address = to_checksum_address(user_address_info[\"address\"])\n        eip712_message = user_address_info[\"typedData\"]\n        message, domain = UserAddress.from_message(eip712_message)\n        signable_message = SignableMessage(\n            HexBytes(_EIP712_VERSION_BYTE),\n            header=domain.hash_struct(),\n            body=message.hash_struct(),\n        )\n    except Exception as e:\n        # data could not be processed\n        raise InvalidContextVariableData(\n            f'Invalid data provided for \"{USER_ADDRESS_CONTEXT}\"; {e.__class__.__name__} - {e}'\n        )\n\n    # actual verification\n    try:\n        address_for_signature = Account.recover_message(\n            signable_message=signable_message, signature=signature\n        )\n        if address_for_signature == user_address:\n            return user_address\n    except Exception as e:\n        # exception during verification\n        raise ContextVariableVerificationFailed(\n            f\"Could not determine address of signature for '{USER_ADDRESS_CONTEXT}'; {e.__class__.__name__} - {e}\"\n        )\n\n    # verification failed - addresses don't match\n    raise ContextVariableVerificationFailed(\n        f\"Signer address for '{USER_ADDRESS_CONTEXT}' signature does not match; expected {user_address}\"\n    )",
  "def is_context_variable(variable) -> bool:\n    return isinstance(variable, str) and variable.startswith(_CONTEXT_PREFIX)",
  "def get_context_value(context_variable: str, **context) -> Any:\n    try:\n        func = _DIRECTIVES[\n            context_variable\n        ]  # These are special context vars that will pre-processed by ursula\n    except KeyError:\n        # fallback for context variable without directive - assume key,value pair\n        # handles the case for user customized context variables\n        value = context.get(context_variable)\n        if value is None:\n            raise RequiredContextVariable(\n                f'No value provided for unrecognized context variable \"{context_variable}\"'\n            )\n    else:\n        value = func(**context)  # required inputs here\n\n    return value",
  "class EvalError(NamedTuple):\n    message: str\n    status_code: int",
  "def to_camelcase(s):\n    parts = iter(s.split(\"_\"))\n    return next(parts) + \"\".join(i.title() for i in parts)",
  "def camel_case_to_snake(data: str) -> str:\n    data = re.sub(r\"(?<!^)(?=[A-Z])\", \"_\", data).lower()\n    return data",
  "class CamelCaseSchema(Schema):\n    \"\"\"Schema that uses camel-case for its external representation\n    and snake-case for its internal representation.\n    \"\"\"\n\n    SKIP_VALUES: Tuple = tuple()\n\n    def on_bind_field(self, field_name, field_obj):\n        field_obj.data_key = to_camelcase(field_obj.data_key or field_name)\n\n    @post_dump\n    def remove_skip_values(self, data, **kwargs):\n        return {\n            key: value for key, value in data.items() if value not in self.SKIP_VALUES\n        }",
  "def resolve_condition_lingo(\n    data: Dict,\n) -> Union[Type[\"Operator\"], Type[\"ReencryptionCondition\"]]:\n    \"\"\"\n    TODO: This feels like a jenky way to resolve data types from JSON blobs, but it works.\n    Inspects a given bloc of JSON and attempts to resolve it's intended  datatype within the\n    conditions expression framework.\n    \"\"\"\n    # TODO: This is ugly but avoids circular imports :-|\n    from nucypher.policy.conditions.evm import ContractCondition, RPCCondition\n    from nucypher.policy.conditions.lingo import Operator\n    from nucypher.policy.conditions.time import TimeCondition\n\n    # Inspect\n    method = data.get(\"method\")\n    operator = data.get(\"operator\")\n    contract = data.get(\"contractAddress\")\n\n    # Resolve\n    if method:\n        if method == TimeCondition.METHOD:\n            return TimeCondition\n        elif contract:\n            return ContractCondition\n        elif method.startswith(_ETH):\n            return RPCCondition\n    elif operator:\n        return Operator\n    else:\n        raise InvalidConditionLingo(\n            f\"Cannot resolve condition lingo type from data {data}\"\n        )",
  "def deserialize_condition_lingo(\n    data: LingoListEntry,\n) -> Union[\"Operator\", \"ReencryptionCondition\"]:\n    \"\"\"Deserialization helper for condition lingo\"\"\"\n    if isinstance(data, str):\n        data = json.loads(data)\n    lingo_class = resolve_condition_lingo(data=data)\n    instance = lingo_class.from_dict(data)\n    return instance",
  "def validate_condition_lingo(conditions: LingoList) -> None:\n    for c in conditions:\n        lingo_class = resolve_condition_lingo(data=c)\n        lingo_class.validate(data=c)",
  "def evaluate_condition_lingo(\n    lingo: \"ConditionLingo\",\n    providers: Optional[Dict[int, BaseProvider]] = None,\n    context: Optional[ContextDict] = None,\n    log: Logger = __LOGGER,\n) -> Optional[EvalError]:\n    \"\"\"\n    Evaluates condition lingo with the give providers and user supplied context.\n    If all conditions are satisfied this function returns None.\n\n    # TODO: Evaluate all conditions even if one fails and report the result\n    \"\"\"\n\n    # Setup (don't use mutable defaults and support federated mode)\n    context = context or dict()\n    providers = providers or dict()\n    error = None\n\n    # Evaluate\n    try:\n        log.info(f\"Evaluating access conditions {lingo}\")\n        result = lingo.eval(providers=providers, **context)\n        if not result:\n            # explicit condition failure\n            error = EvalError(\n                \"Decryption conditions not satisfied\", HTTPStatus.FORBIDDEN\n            )\n    except ReturnValueEvaluationError as e:\n        error = EvalError(\n            f\"Unable to evaluate return value: {e}\",\n            HTTPStatus.BAD_REQUEST,\n        )\n    except InvalidConditionLingo as e:\n        error = EvalError(\n            f\"Invalid condition grammar: {e}\",\n            HTTPStatus.BAD_REQUEST,\n        )\n    except InvalidCondition as e:\n        error = EvalError(\n            f\"Incorrect value provided for condition: {e}\",\n            HTTPStatus.BAD_REQUEST,\n        )\n    except RequiredContextVariable as e:\n        # TODO: be more specific and name the missing inputs, etc\n        error = EvalError(f\"Missing required inputs: {e}\", HTTPStatus.BAD_REQUEST)\n    except InvalidContextVariableData as e:\n        error = EvalError(\n            f\"Invalid data provided for context variable: {e}\",\n            HTTPStatus.BAD_REQUEST,\n        )\n    except ContextVariableVerificationFailed as e:\n        error = EvalError(\n            f\"Context variable data could not be verified: {e}\",\n            HTTPStatus.FORBIDDEN,\n        )\n    except NoConnectionToChain as e:\n        error = EvalError(\n            f\"Node does not have a connection to chain ID {e.chain}: {e}\",\n            HTTPStatus.NOT_IMPLEMENTED,\n        )\n    except ConditionEvaluationFailed as e:\n        error = EvalError(\n            f\"Decryption condition not evaluated: {e}\", HTTPStatus.BAD_REQUEST\n        )\n    except Exception as e:\n        # TODO: Unsure why we ended up here\n        message = (\n            f\"Unexpected exception while evaluating \"\n            f\"decryption condition ({e.__class__.__name__}): {e}\"\n        )\n        error = EvalError(message, HTTPStatus.INTERNAL_SERVER_ERROR)\n        log.warn(message)\n\n    if error:\n        error = EvalError(*error)\n        log.info(error.message)  # log error message\n\n    return error",
  "def on_bind_field(self, field_name, field_obj):\n        field_obj.data_key = to_camelcase(field_obj.data_key or field_name)",
  "def remove_skip_values(self, data, **kwargs):\n        return {\n            key: value for key, value in data.items() if value not in self.SKIP_VALUES\n        }",
  "class _Serializable:\n    class Schema(Schema):\n        field = NotImplemented\n\n    def to_json(self) -> str:\n        schema = self.Schema()\n        data = schema.dumps(self)\n        return data\n\n    @classmethod\n    def from_json(cls, data) -> '_Serializable':\n        data = json.loads(data)\n        schema = cls.Schema()\n        instance = schema.load(data)\n        return instance\n\n    def to_dict(self):\n        schema = self.Schema()\n        data = schema.dump(self)\n        return data\n\n    @classmethod\n    def from_dict(cls, data) -> '_Serializable':\n        schema = cls.Schema()\n        instance = schema.load(data)\n        return instance\n\n    def __bytes__(self) -> bytes:\n        json_payload = self.to_json().encode()\n        b64_json_payload = b64encode(json_payload)\n        return b64_json_payload\n\n    @classmethod\n    def from_bytes(cls, data: bytes) -> '_Serializable':\n        json_payload = b64decode(data).decode()\n        instance = cls.from_json(json_payload)\n        return instance",
  "class ReencryptionCondition(_Serializable, ABC):\n\n    class Schema(Schema):\n        name = NotImplemented\n\n    @abstractmethod\n    def verify(self, *args, **kwargs) -> Tuple[bool, Any]:\n        \"\"\"Returns the boolean result of the evaluation and the returned value in a two-tuple.\"\"\"\n        return NotImplemented\n\n    @classmethod\n    def validate(cls, data: Dict) -> None:\n        errors = cls.Schema().validate(data=data)\n        if errors:\n            raise InvalidCondition(f\"Invalid {cls.__name__}: {errors}\")",
  "class Schema(Schema):\n        field = NotImplemented",
  "def to_json(self) -> str:\n        schema = self.Schema()\n        data = schema.dumps(self)\n        return data",
  "def from_json(cls, data) -> '_Serializable':\n        data = json.loads(data)\n        schema = cls.Schema()\n        instance = schema.load(data)\n        return instance",
  "def to_dict(self):\n        schema = self.Schema()\n        data = schema.dump(self)\n        return data",
  "def from_dict(cls, data) -> '_Serializable':\n        schema = cls.Schema()\n        instance = schema.load(data)\n        return instance",
  "def __bytes__(self) -> bytes:\n        json_payload = self.to_json().encode()\n        b64_json_payload = b64encode(json_payload)\n        return b64_json_payload",
  "def from_bytes(cls, data: bytes) -> '_Serializable':\n        json_payload = b64decode(data).decode()\n        instance = cls.from_json(json_payload)\n        return instance",
  "class Schema(Schema):\n        name = NotImplemented",
  "def verify(self, *args, **kwargs) -> Tuple[bool, Any]:\n        \"\"\"Returns the boolean result of the evaluation and the returned value in a two-tuple.\"\"\"\n        return NotImplemented",
  "def validate(cls, data: Dict) -> None:\n        errors = cls.Schema().validate(data=data)\n        if errors:\n            raise InvalidCondition(f\"Invalid {cls.__name__}: {errors}\")",
  "class InvalidConditionLingo(Exception):\n    \"\"\"Invalid lingo grammar.\"\"\"",
  "class InvalidLogicalOperator(Exception):\n    \"\"\"Invalid definition of logical lingo operator.\"\"\"",
  "class NoConnectionToChain(RuntimeError):\n    \"\"\"Raised when a node does not have an associated provider for a chain.\"\"\"\n\n    def __init__(self, chain: int):\n        self.chain = chain\n        message = f\"No connection to chain ID {chain}\"\n        super().__init__(message)",
  "class ReturnValueEvaluationError(Exception):\n    \"\"\"Issue with Return Value and Key\"\"\"",
  "class InvalidConditionContext(Exception):\n    \"\"\"Raised when invalid context is encountered.\"\"\"",
  "class RequiredContextVariable(InvalidConditionContext):\n    \"\"\"No value provided for context variable\"\"\"",
  "class InvalidContextVariableData(InvalidConditionContext):\n    \"\"\"Context variable could not be processed\"\"\"",
  "class ContextVariableVerificationFailed(InvalidConditionContext):\n    \"\"\"Issue with using the provided context variable.\"\"\"",
  "class InvalidCondition(ValueError):\n    \"\"\"Invalid value for condition.\"\"\"",
  "class ConditionEvaluationFailed(Exception):\n    \"\"\"Could not evaluate condition.\"\"\"",
  "class RPCExecutionFailed(ConditionEvaluationFailed):\n    \"\"\"Raised when an exception is raised from an RPC call.\"\"\"",
  "def __init__(self, chain: int):\n        self.chain = chain\n        message = f\"No connection to chain ID {chain}\"\n        super().__init__(message)",
  "class TimeCondition(ReencryptionCondition):\n    METHOD = 'timelock'\n\n    class Schema(CamelCaseSchema):\n        SKIP_VALUES = (None,)\n        name = fields.Str(required=False)\n        method = fields.Str(dump_default=\"timelock\", required=True)\n        return_value_test = fields.Nested(\n            ReturnValueTest.ReturnValueTestSchema(), required=True\n        )\n\n        @post_load\n        def make(self, data, **kwargs):\n            return TimeCondition(**data)\n\n    def __repr__(self) -> str:\n        r = f'{self.__class__.__name__}(timestamp={self.return_value_test.value})'\n        return r\n\n    def __init__(\n        self,\n        return_value_test: ReturnValueTest,\n        method: str = METHOD,\n        name: Optional[str] = None,\n    ):\n        if method != self.METHOD:\n            raise InvalidCondition(\n                f\"{self.__class__.__name__} must be instantiated with the {self.METHOD} method.\"\n            )\n        self.return_value_test = return_value_test\n        self.name = name\n\n    @property\n    def method(self):\n        return self.METHOD\n\n    @property\n    def timestamp(self):\n        return self.return_value_test.value\n\n    def verify(self, *args, **kwargs) -> Tuple[bool, float]:\n        eval_time = time.time()   # system  clock\n        return self.return_value_test.eval(data=eval_time), eval_time",
  "class Schema(CamelCaseSchema):\n        SKIP_VALUES = (None,)\n        name = fields.Str(required=False)\n        method = fields.Str(dump_default=\"timelock\", required=True)\n        return_value_test = fields.Nested(\n            ReturnValueTest.ReturnValueTestSchema(), required=True\n        )\n\n        @post_load\n        def make(self, data, **kwargs):\n            return TimeCondition(**data)",
  "def __repr__(self) -> str:\n        r = f'{self.__class__.__name__}(timestamp={self.return_value_test.value})'\n        return r",
  "def __init__(\n        self,\n        return_value_test: ReturnValueTest,\n        method: str = METHOD,\n        name: Optional[str] = None,\n    ):\n        if method != self.METHOD:\n            raise InvalidCondition(\n                f\"{self.__class__.__name__} must be instantiated with the {self.METHOD} method.\"\n            )\n        self.return_value_test = return_value_test\n        self.name = name",
  "def method(self):\n        return self.METHOD",
  "def timestamp(self):\n        return self.return_value_test.value",
  "def verify(self, *args, **kwargs) -> Tuple[bool, float]:\n        eval_time = time.time()   # system  clock\n        return self.return_value_test.eval(data=eval_time), eval_time",
  "def make(self, data, **kwargs):\n            return TimeCondition(**data)",
  "class OperatorDict(TypedDict):\n    operator: Literal[\"and\", \"or\"]",
  "class ReturnValueTestDict(TypedDict):\n    comparator: OperatorLiteral\n    value: Any\n    key: NotRequired[Union[str, int]]",
  "class _ReencryptionConditionDict(TypedDict):\n    name: NotRequired[str]",
  "class TimeConditionDict(_ReencryptionConditionDict):\n    method: Literal[\"timelock\"]\n    returnValueTest: ReturnValueTestDict",
  "class RPCConditionDict(_ReencryptionConditionDict):\n    chain: int\n    method: str\n    parameters: NotRequired[List[Any]]\n    returnValueTest: ReturnValueTestDict",
  "class ContractConditionDict(RPCConditionDict):\n    contractAddress: str\n    standardContractType: NotRequired[str]\n    functionAbi: NotRequired[ABIFunction]",
  "def _serialize_rust_lingos(lingos: List[Conditions]) -> Conditions:\n    lingo_lists = list()\n    for lingo in lingos:\n        if lingo:\n            lingo = json.loads((str(lingo)))\n        lingo_lists.append(lingo)\n    rust_lingos = Conditions(json.dumps(lingo_lists))\n    return rust_lingos",
  "def _deserialize_rust_lingos(reenc_request: ReencryptionRequest):\n    \"\"\"Shim for nucypher-core lingos\"\"\"\n    json_lingos = json.loads(str(reenc_request.conditions))\n    lingo = [ConditionLingo.from_list(lingo) if lingo else None for lingo in json_lingos]\n    return lingo",
  "class Operator:\n    OPERATORS = (\"and\", \"or\")\n\n    def __init__(self, _operator: str):\n        if _operator not in self.OPERATORS:\n            raise InvalidLogicalOperator(f\"{_operator} is not a valid operator\")\n        self.operator = _operator\n\n    def __str__(self) -> str:\n        return self.operator\n\n    def to_dict(self) -> OperatorDict:\n        # strict typing of operator value (must be a literal)\n        if self.operator == \"and\":\n            return {\"operator\": \"and\"}\n        else:\n            return {\"operator\": \"or\"}\n\n    @classmethod\n    def from_dict(cls, data: OperatorDict) -> \"Operator\":\n        cls.validate(data)\n        instance = cls(_operator=data[\"operator\"])\n        return instance\n\n    @classmethod\n    def from_json(cls, data) -> 'Operator':\n        data = json.loads(data)\n        instance = cls.from_dict(data)\n        return instance\n\n    def to_json(self) -> str:\n        data = self.to_dict()\n        json_data = json.dumps(data)\n        return json_data\n\n    @classmethod\n    def validate(cls, data: Dict) -> None:\n        try:\n            _operator = data[\"operator\"]\n        except KeyError:\n            raise InvalidLogicalOperator(f\"Invalid operator data: {data}\")\n\n        if _operator not in cls.OPERATORS:\n            raise InvalidLogicalOperator(f\"{_operator} is not a valid operator\")",
  "class ReturnValueTest:\n    class InvalidExpression(ValueError):\n        pass\n\n    _COMPARATOR_FUNCTIONS = {\n        \"==\": pyoperator.eq,\n        \"!=\": pyoperator.ne,\n        \">\": pyoperator.gt,\n        \"<\": pyoperator.lt,\n        \"<=\": pyoperator.le,\n        \">=\": pyoperator.ge,\n    }\n    COMPARATORS = tuple(_COMPARATOR_FUNCTIONS)\n\n    class ReturnValueTestSchema(CamelCaseSchema):\n        SKIP_VALUES = (None,)\n        comparator = fields.Str(required=True)\n        value = fields.Raw(\n            allow_none=False, required=True\n        )  # any valid type (excludes None)\n        key = fields.Raw(allow_none=True)\n\n        @post_load\n        def make(self, data, **kwargs):\n            return ReturnValueTest(**data)\n\n    def __init__(self, comparator: str, value: Any, key: Optional[Union[int, str]] = None):\n        if comparator not in self.COMPARATORS:\n            raise self.InvalidExpression(\n                f'\"{comparator}\" is not a permitted comparator.'\n            )\n\n        if not isinstance(key, (int, str)) and key is not None:\n            raise self.InvalidExpression(\n                f'\"{key}\" is not a permitted key. Must be a string or integer.'\n            )\n\n        if not is_context_variable(value):\n            # verify that value is valid, but don't set it here so as not to change the value;\n            # it will be sanitized at eval time. Need to maintain serialization/deserialization\n            # consistency\n            self._sanitize_value(value)\n\n        self.comparator = comparator\n        self.value = value\n        self.key = key\n\n    def _sanitize_value(self, value):\n        try:\n            return ast.literal_eval(str(value))\n        except Exception:\n            raise self.InvalidExpression(f'\"{value}\" is not a permitted value.')\n\n    def _process_data(self, data: Any) -> Any:\n        \"\"\"\n        If a key is specified, return the value at that key in the data if data is a dict or list-like.\n        Otherwise, return the data.\n        \"\"\"\n        processed_data = data\n        if self.key is not None:\n            if isinstance(data, dict):\n                try:\n                    processed_data = data[self.key]\n                except KeyError:\n                    raise ReturnValueEvaluationError(\n                        f\"Key '{self.key}' not found in return data.\"\n                    )\n            elif isinstance(self.key, int) and isinstance(data, (list, tuple)):\n                try:\n                    processed_data = data[self.key]\n                except IndexError:\n                    raise ReturnValueEvaluationError(\n                        f\"Index '{self.key}' not found in return data.\"\n                    )\n            else:\n                raise ReturnValueEvaluationError(\n                    f\"Key: {self.key} and Value: {data} are not compatible types.\"\n                )\n\n        return processed_data\n\n    def eval(self, data) -> bool:\n        if is_context_variable(self.value) or is_context_variable(self.key):\n            # programming error if we get here\n            raise RuntimeError(\n                f\"Return value comparator contains an unprocessed context variable (key={self.key}, value={self.value}) and is not valid \"\n                f\"for condition evaluation.\"\n            )\n\n        processed_data = self._process_data(data)\n        left_operand = self._sanitize_value(processed_data)\n        right_operand = self._sanitize_value(self.value)\n        result = self._COMPARATOR_FUNCTIONS[self.comparator](left_operand, right_operand)\n        return result",
  "class ConditionLingo:\n    \"\"\"\n    A Collection of re-encryption conditions evaluated as a compound boolean expression.\n\n    This is an alternate implementation of the condition expression format used in\n    the Lit Protocol (https://github.com/LIT-Protocol); credit to the authors for inspiring this work.\n    \"\"\"\n\n    def __init__(self, conditions: List[Union[ReencryptionCondition, Operator]]):\n        \"\"\"\n        The input list *must* be structured as follows:\n        condition\n        operator\n        condition\n        ...\n        \"\"\"\n        self._validate_grammar(lingo=conditions)\n        self.conditions = conditions\n        self.id = md5(bytes(self)).hexdigest()[:6]\n\n    @staticmethod\n    def _validate_grammar(lingo) -> None:\n        if len(lingo) % 2 == 0:\n            raise InvalidConditionLingo(\n                \"conditions must be odd length, ever other element being an operator\"\n            )\n        for index, element in enumerate(lingo):\n            if (not index % 2) and not (isinstance(element, ReencryptionCondition)):\n                raise InvalidConditionLingo(\n                    f\"{index} element must be a condition; Got {type(element)}.\"\n                )\n            elif (index % 2) and (not isinstance(element, Operator)):\n                raise InvalidConditionLingo(\n                    f\"{index} element must be an operator; Got {type(element)}.\"\n                )\n\n    @classmethod\n    def from_list(cls, payload: LingoList) -> \"ConditionLingo\":\n        conditions = [deserialize_condition_lingo(c) for c in payload]\n        instance = cls(conditions=conditions)\n        return instance\n\n    def to_list(self) -> LingoList:  # TODO: __iter__ ?\n        payload = [c.to_dict() for c in self.conditions]\n        return payload\n\n    def to_json(self) -> str:\n        data = json.dumps(self.to_list())\n        return data\n\n    @classmethod\n    def from_json(cls, data: str) -> 'ConditionLingo':\n        payload = json.loads(data)\n        instance = cls.from_list(payload=payload)\n        return instance\n\n    def to_base64(self) -> bytes:\n        data = base64.b64encode(self.to_json().encode())\n        return data\n\n    @classmethod\n    def from_base64(cls, data: bytes) -> 'ConditionLingo':\n        decoded_json = base64.b64decode(data).decode()\n        instance = cls.from_json(decoded_json)\n        return instance\n\n    def __bytes__(self) -> bytes:\n        data = self.to_json().encode()\n        return data\n\n    def __repr__(self):\n        return f\"{self.__class__.__name__} (id={self.id} | size={len(bytes(self))})\"\n\n    def __eval(self, eval_string: str):\n        # TODO: Additional protection and/or sanitation here\n        result = eval(eval_string)\n        return result\n\n    def __process(self, *args, **kwargs) -> Iterator:\n        # TODO: Prevent this lino from bein evaluated if this node does not have\n        #       a connection to all the required blockchains (optimization)\n        for task in self.conditions:\n            if isinstance(task, ReencryptionCondition):\n                condition = task\n                result, value = condition.verify(*args, **kwargs)\n                yield result\n            elif isinstance(task, Operator):\n                yield task\n            else:\n                raise InvalidConditionLingo(\n                    f\"Unrecognized type {type(task)} for ConditionLingo\"\n                )\n\n    def eval(self, *args, **kwargs) -> bool:\n        data = self.__process(*args, **kwargs)\n        # [True, <Operator>, False] -> 'True or False'\n        eval_string = ' '.join(str(e) for e in data)\n        result = self.__eval(eval_string=eval_string)\n        return result",
  "def __init__(self, _operator: str):\n        if _operator not in self.OPERATORS:\n            raise InvalidLogicalOperator(f\"{_operator} is not a valid operator\")\n        self.operator = _operator",
  "def __str__(self) -> str:\n        return self.operator",
  "def to_dict(self) -> OperatorDict:\n        # strict typing of operator value (must be a literal)\n        if self.operator == \"and\":\n            return {\"operator\": \"and\"}\n        else:\n            return {\"operator\": \"or\"}",
  "def from_dict(cls, data: OperatorDict) -> \"Operator\":\n        cls.validate(data)\n        instance = cls(_operator=data[\"operator\"])\n        return instance",
  "def from_json(cls, data) -> 'Operator':\n        data = json.loads(data)\n        instance = cls.from_dict(data)\n        return instance",
  "def to_json(self) -> str:\n        data = self.to_dict()\n        json_data = json.dumps(data)\n        return json_data",
  "def validate(cls, data: Dict) -> None:\n        try:\n            _operator = data[\"operator\"]\n        except KeyError:\n            raise InvalidLogicalOperator(f\"Invalid operator data: {data}\")\n\n        if _operator not in cls.OPERATORS:\n            raise InvalidLogicalOperator(f\"{_operator} is not a valid operator\")",
  "class InvalidExpression(ValueError):\n        pass",
  "class ReturnValueTestSchema(CamelCaseSchema):\n        SKIP_VALUES = (None,)\n        comparator = fields.Str(required=True)\n        value = fields.Raw(\n            allow_none=False, required=True\n        )  # any valid type (excludes None)\n        key = fields.Raw(allow_none=True)\n\n        @post_load\n        def make(self, data, **kwargs):\n            return ReturnValueTest(**data)",
  "def __init__(self, comparator: str, value: Any, key: Optional[Union[int, str]] = None):\n        if comparator not in self.COMPARATORS:\n            raise self.InvalidExpression(\n                f'\"{comparator}\" is not a permitted comparator.'\n            )\n\n        if not isinstance(key, (int, str)) and key is not None:\n            raise self.InvalidExpression(\n                f'\"{key}\" is not a permitted key. Must be a string or integer.'\n            )\n\n        if not is_context_variable(value):\n            # verify that value is valid, but don't set it here so as not to change the value;\n            # it will be sanitized at eval time. Need to maintain serialization/deserialization\n            # consistency\n            self._sanitize_value(value)\n\n        self.comparator = comparator\n        self.value = value\n        self.key = key",
  "def _sanitize_value(self, value):\n        try:\n            return ast.literal_eval(str(value))\n        except Exception:\n            raise self.InvalidExpression(f'\"{value}\" is not a permitted value.')",
  "def _process_data(self, data: Any) -> Any:\n        \"\"\"\n        If a key is specified, return the value at that key in the data if data is a dict or list-like.\n        Otherwise, return the data.\n        \"\"\"\n        processed_data = data\n        if self.key is not None:\n            if isinstance(data, dict):\n                try:\n                    processed_data = data[self.key]\n                except KeyError:\n                    raise ReturnValueEvaluationError(\n                        f\"Key '{self.key}' not found in return data.\"\n                    )\n            elif isinstance(self.key, int) and isinstance(data, (list, tuple)):\n                try:\n                    processed_data = data[self.key]\n                except IndexError:\n                    raise ReturnValueEvaluationError(\n                        f\"Index '{self.key}' not found in return data.\"\n                    )\n            else:\n                raise ReturnValueEvaluationError(\n                    f\"Key: {self.key} and Value: {data} are not compatible types.\"\n                )\n\n        return processed_data",
  "def eval(self, data) -> bool:\n        if is_context_variable(self.value) or is_context_variable(self.key):\n            # programming error if we get here\n            raise RuntimeError(\n                f\"Return value comparator contains an unprocessed context variable (key={self.key}, value={self.value}) and is not valid \"\n                f\"for condition evaluation.\"\n            )\n\n        processed_data = self._process_data(data)\n        left_operand = self._sanitize_value(processed_data)\n        right_operand = self._sanitize_value(self.value)\n        result = self._COMPARATOR_FUNCTIONS[self.comparator](left_operand, right_operand)\n        return result",
  "def __init__(self, conditions: List[Union[ReencryptionCondition, Operator]]):\n        \"\"\"\n        The input list *must* be structured as follows:\n        condition\n        operator\n        condition\n        ...\n        \"\"\"\n        self._validate_grammar(lingo=conditions)\n        self.conditions = conditions\n        self.id = md5(bytes(self)).hexdigest()[:6]",
  "def _validate_grammar(lingo) -> None:\n        if len(lingo) % 2 == 0:\n            raise InvalidConditionLingo(\n                \"conditions must be odd length, ever other element being an operator\"\n            )\n        for index, element in enumerate(lingo):\n            if (not index % 2) and not (isinstance(element, ReencryptionCondition)):\n                raise InvalidConditionLingo(\n                    f\"{index} element must be a condition; Got {type(element)}.\"\n                )\n            elif (index % 2) and (not isinstance(element, Operator)):\n                raise InvalidConditionLingo(\n                    f\"{index} element must be an operator; Got {type(element)}.\"\n                )",
  "def from_list(cls, payload: LingoList) -> \"ConditionLingo\":\n        conditions = [deserialize_condition_lingo(c) for c in payload]\n        instance = cls(conditions=conditions)\n        return instance",
  "def to_list(self) -> LingoList:  # TODO: __iter__ ?\n        payload = [c.to_dict() for c in self.conditions]\n        return payload",
  "def to_json(self) -> str:\n        data = json.dumps(self.to_list())\n        return data",
  "def from_json(cls, data: str) -> 'ConditionLingo':\n        payload = json.loads(data)\n        instance = cls.from_list(payload=payload)\n        return instance",
  "def to_base64(self) -> bytes:\n        data = base64.b64encode(self.to_json().encode())\n        return data",
  "def from_base64(cls, data: bytes) -> 'ConditionLingo':\n        decoded_json = base64.b64decode(data).decode()\n        instance = cls.from_json(decoded_json)\n        return instance",
  "def __bytes__(self) -> bytes:\n        data = self.to_json().encode()\n        return data",
  "def __repr__(self):\n        return f\"{self.__class__.__name__} (id={self.id} | size={len(bytes(self))})\"",
  "def __eval(self, eval_string: str):\n        # TODO: Additional protection and/or sanitation here\n        result = eval(eval_string)\n        return result",
  "def __process(self, *args, **kwargs) -> Iterator:\n        # TODO: Prevent this lino from bein evaluated if this node does not have\n        #       a connection to all the required blockchains (optimization)\n        for task in self.conditions:\n            if isinstance(task, ReencryptionCondition):\n                condition = task\n                result, value = condition.verify(*args, **kwargs)\n                yield result\n            elif isinstance(task, Operator):\n                yield task\n            else:\n                raise InvalidConditionLingo(\n                    f\"Unrecognized type {type(task)} for ConditionLingo\"\n                )",
  "def eval(self, *args, **kwargs) -> bool:\n        data = self.__process(*args, **kwargs)\n        # [True, <Operator>, False] -> 'True or False'\n        eval_string = ' '.join(str(e) for e in data)\n        result = self.__eval(eval_string=eval_string)\n        return result",
  "def make(self, data, **kwargs):\n            return ReturnValueTest(**data)",
  "class NicknameCharacter:\n\n    def __init__(self, symbol: str, color_name: str, color_hex: str):\n        self.symbol = symbol\n        self.color_name = color_name\n        self.color_hex = color_hex\n        self._text = color_name + \" \" + _SYMBOLS[symbol]\n\n    def to_json(self):\n        return dict(symbol=self.symbol,\n                    color_name=self.color_name,\n                    color_hex=self.color_hex)\n\n    def __str__(self):\n        return self._text",
  "class Nickname:\n\n    @classmethod\n    def from_seed(cls, seed, length: int = 2):\n        # TODO: #1823 - Workaround for new nickname every restart\n        # if not seed:\n        #     raise ValueError(\"No checksum provided to derive nickname.\")\n        rng = random.Random(seed)\n        nickname_symbols = rng.sample(list(_SYMBOLS), length)\n        nickname_colors = rng.sample(_COLORS, length)\n        characters = [\n            NicknameCharacter(symbol, color['color'], color['hex'])\n            for symbol, color in zip(nickname_symbols, nickname_colors)]\n        return cls(characters)\n\n    def __init__(self, characters: List[NicknameCharacter]):\n        self._text = \" \".join(str(character) for character in characters)\n        self.icon = \"[\" + \"\".join(character.symbol for character in characters) + \"]\"\n        self.characters = characters\n\n    def to_json(self):\n        return dict(text=self._text,\n                    icon=self.icon,\n                    characters=[character.to_json() for character in self.characters])\n\n    def __str__(self):\n        return self._text",
  "def __init__(self, symbol: str, color_name: str, color_hex: str):\n        self.symbol = symbol\n        self.color_name = color_name\n        self.color_hex = color_hex\n        self._text = color_name + \" \" + _SYMBOLS[symbol]",
  "def to_json(self):\n        return dict(symbol=self.symbol,\n                    color_name=self.color_name,\n                    color_hex=self.color_hex)",
  "def __str__(self):\n        return self._text",
  "def from_seed(cls, seed, length: int = 2):\n        # TODO: #1823 - Workaround for new nickname every restart\n        # if not seed:\n        #     raise ValueError(\"No checksum provided to derive nickname.\")\n        rng = random.Random(seed)\n        nickname_symbols = rng.sample(list(_SYMBOLS), length)\n        nickname_colors = rng.sample(_COLORS, length)\n        characters = [\n            NicknameCharacter(symbol, color['color'], color['hex'])\n            for symbol, color in zip(nickname_symbols, nickname_colors)]\n        return cls(characters)",
  "def __init__(self, characters: List[NicknameCharacter]):\n        self._text = \" \".join(str(character) for character in characters)\n        self.icon = \"[\" + \"\".join(character.symbol for character in characters) + \"]\"\n        self.characters = characters",
  "def to_json(self):\n        return dict(text=self._text,\n                    icon=self.icon,\n                    characters=[character.to_json() for character in self.characters])",
  "def __str__(self):\n        return self._text",
  "class ArchivedFleetState(NamedTuple):\n\n    checksum: str\n    nickname: Nickname\n    timestamp: maya.MayaDT\n    population: int\n\n    def to_json(self):\n        return dict(checksum=bytes(self.checksum).hex(),\n                    nickname=self.nickname.to_json(),\n                    timestamp=self.timestamp.rfc2822(),\n                    population=self.population)",
  "class StateDiff(NamedTuple):\n    this_node_updated: bool\n    nodes_updated: List[ChecksumAddress]\n    nodes_removed: List[ChecksumAddress]\n\n    def empty(self):\n        return not self.this_node_updated and not self.nodes_updated and not self.nodes_removed",
  "class FleetState:\n    \"\"\"\n    Fleet state as perceived by a local Ursula.\n\n    Assumptions we're based on:\n\n    - Every supplied node object, after its constructor has finished,\n      has a ``.checksum_address`` and ``bytes()`` (metadata)\n    - checksum address or metadata do not change for the same Python object\n    - ``this_node`` (the owner of FleetSensor) may not have metadata initially\n      (when the constructor is first called), but will have one at the time of the first\n      `record_fleet_state()` call.\n    - The metadata of ``this_node`` **can** change.\n    - For the purposes of the fleet state, nodes with different metadata are considered different,\n      even if they have the same checksum address.\n    \"\"\"\n\n    @classmethod\n    def new(cls, this_node: Optional['Ursula'] = None) -> 'FleetState':\n        this_node_ref = weakref.ref(this_node) if this_node else None\n        # `this_node` might not have its metadata available yet.\n        this_node_metadata = None\n\n        return cls(nodes={},\n                   this_node_ref=this_node_ref,\n                   this_node_metadata=this_node_metadata)\n\n    def __init__(self,\n                 nodes: Dict[ChecksumAddress, 'Ursula'],\n                 this_node_ref: Optional[weakref.ReferenceType],\n                 this_node_metadata: Optional[NodeMetadata]):\n        self.checksum = FleetStateChecksum(this_node=this_node_metadata,\n                                           other_nodes=[node.metadata() for node in nodes.values()])\n        self.nickname = Nickname.from_seed(bytes(self.checksum), length=1)\n        self._nodes = nodes\n        self.timestamp = maya.now()\n        self._this_node_ref = this_node_ref\n        self._this_node_metadata = this_node_metadata\n\n    def archived(self) -> ArchivedFleetState:\n        return ArchivedFleetState(checksum=self.checksum,\n                                  nickname=self.nickname,\n                                  timestamp=self.timestamp,\n                                  population=self.population)\n\n    def _calculate_diff(self,\n                        this_node_updated: bool,\n                        nodes_to_add: Iterable['Ursula'],\n                        nodes_to_remove: Iterable[ChecksumAddress]\n                        ) -> StateDiff:\n\n        nodes_updated = []\n        for node in nodes_to_add:\n            if node.checksum_address in nodes_to_remove:\n                continue\n            unknown = node.checksum_address not in self._nodes\n            if unknown or bytes(self._nodes[node.checksum_address].metadata()) != bytes(node.metadata()):\n                nodes_updated.append(node.checksum_address)\n\n        nodes_removed = []\n        for checksum_address in nodes_to_remove:\n            if checksum_address in self._nodes:\n                nodes_removed.append(checksum_address)\n\n        return StateDiff(this_node_updated=this_node_updated,\n                         nodes_updated=nodes_updated,\n                         nodes_removed=nodes_removed)\n\n    def with_updated_nodes(self,\n                           nodes_to_add: Iterable['Ursula'],\n                           nodes_to_remove: Iterable[ChecksumAddress],\n                           skip_this_node: bool = False,\n                           ) -> 'FleetState':\n\n        if self._this_node_ref is not None and not skip_this_node:\n            this_node = self._this_node_ref()\n            this_node_metadata = this_node.metadata()\n            this_node_updated = self._this_node_metadata != this_node_metadata\n            this_node_list = [this_node]\n        else:\n            this_node_metadata = self._this_node_metadata\n            this_node_updated = False\n            this_node_list = []\n\n        diff = self._calculate_diff(this_node_updated, nodes_to_add, nodes_to_remove)\n\n        if not diff.empty():\n            # TODO: if nodes were kept in a Merkle tree,\n            # we'd have to only recalculate log(N) checksums.\n            # Is it worth it?\n            nodes = dict(self._nodes)\n            nodes_to_add_dict = {node.checksum_address: node for node in nodes_to_add}\n            for checksum_address in diff.nodes_updated:\n                new_node = nodes_to_add_dict[checksum_address]\n                nodes[checksum_address] = new_node\n            for checksum_address in diff.nodes_removed:\n                del nodes[checksum_address]\n        else:\n            nodes = self._nodes\n\n        new_state = FleetState(nodes=nodes,\n                               this_node_ref=self._this_node_ref,\n                               this_node_metadata=this_node_metadata)\n\n        return new_state, diff\n\n    @property\n    def population(self) -> int:\n        \"\"\"Returns the number of all known nodes, including itself, if applicable.\"\"\"\n        return len(self) + int(self._this_node_metadata is not None)\n\n    def __getitem__(self, checksum_address):\n        return self._nodes[checksum_address]\n\n    def addresses(self) -> KeysView:\n        return self._nodes.keys()\n\n    def __bool__(self):\n        return len(self) != 0\n\n    def __contains__(self, item):\n        if isinstance(item, str):\n            return item in self._nodes\n        else:\n            return item.checksum_address in self._nodes\n\n    def __iter__(self):\n        yield from self._nodes.values()\n\n    def __len__(self):\n        return len(self._nodes)\n\n    def shuffled(self) -> List['Ursula']:\n        nodes_we_know_about = list(self._nodes.values())\n        random.shuffle(nodes_we_know_about)\n        return nodes_we_know_about\n\n    def to_json(self) -> Dict:\n        return dict(nickname=self.nickname.to_json(),\n                    updated=self.timestamp.rfc2822())\n\n    @property\n    def icon(self) -> str:\n        return self.nickname.icon\n\n    def items(self):\n        return self._nodes.items()\n\n    def values(self):\n        return self._nodes.values()\n\n    def __str__(self):\n        return '{checksum} \u21c0{nickname}\u21bd {icon} '.format(icon=self.nickname.icon,\n                                                        nickname=self.nickname,\n                                                        checksum=bytes(self.checksum).hex()[:7])\n\n    def __repr__(self):\n        return f\"FleetState({self.checksum}, {self._nodes}, {self._this_node_ref}, {self._this_node_metadata})\"",
  "class FleetSensor:\n    \"\"\"\n    A representation of a fleet of NuCypher nodes.\n\n    If `this_node` is provided, it will be included in the state checksum\n    (but not returned during iteration/lookups).\n    \"\"\"\n    log = Logger(\"Learning\")\n\n    def __init__(self, domain: str, this_node: Optional['Ursula'] = None):\n\n        self._domain = domain\n\n        self._current_state = FleetState.new(this_node)\n        self._archived_states = deque([self._current_state.archived()], maxlen=5)\n        self._remote_states = {}\n        self._remote_last_seen = {}\n\n        # temporary accumulator for new nodes to avoid updating the fleet state every time\n        self._nodes_to_add = set()\n        self._nodes_to_remove = set()  # Beginning of bucketing.\n\n        self._auto_update_state = False\n\n    def record_node(self, node: 'Ursula'):\n\n        if node.domain == self._domain:\n            # Replace the existing object with a newer object, even if they're equal\n            # (this object can be mutated externally).\n            # This behavior is supposed to be consistent with that of the node storage\n            # (where a newer object with the same `checksum_address` replaces an older one).\n            if node in self._nodes_to_add:\n                self._nodes_to_add.remove(node)\n            self._nodes_to_add.add(node)\n\n            if self._auto_update_state:\n                self.log.info(f\"Updating fleet state after saving node {node}\")\n                self.record_fleet_state()\n        else:\n            msg = f\"Rejected node {node} because its domain is '{node.domain}' but we're only tracking '{self._domain}'\"\n            self.log.warn(msg)\n\n    def __getitem__(self, item):\n        return self._current_state[item]\n\n    def __bool__(self):\n        return bool(self._current_state)\n\n    def __contains__(self, item):\n        \"\"\"\n        Checks if the node *with the same metadata* is recorded in the current state.\n        Does not compare ``item`` with the owner node of this FleetSensor.\n        \"\"\"\n        return item in self._current_state\n\n    def __iter__(self):\n        yield from self._current_state\n\n    def __len__(self):\n        return len(self._current_state)\n\n    def __repr__(self):\n        return f\"FleetSensor({self._current_state.__repr__()})\"\n\n    @property\n    def current_state(self):\n        return self._current_state\n\n    @property\n    def checksum(self):\n        return self._current_state.checksum\n\n    @property\n    def population(self):\n        return self._current_state.population\n\n    @property\n    def nickname(self):\n        return self._current_state.nickname\n\n    @property\n    def icon(self) -> str:\n        return self._current_state.icon\n\n    @property\n    def timestamp(self):\n        return self._current_state.timestamp\n\n    def items(self):\n        return self._current_state.items()\n\n    def values(self):\n        return self._current_state.values()\n\n    def latest_state(self) -> ArchivedFleetState:\n        # `_archived_states` is never empty, one state is created in the constructor\n        return self._archived_states[-1]\n\n    def previous_states(self, quantity: int) -> List[ArchivedFleetState]:\n        \"\"\"\n        Returns at most ``quantity`` latest archived states (*not* including the current one),\n        in chronological order.\n        \"\"\"\n        # `_archived_states` is never empty, one state is created in the constructor\n        previous_states_num = min(len(self._archived_states) - 1, quantity)\n        return list(self._archived_states)[-previous_states_num-1:-1]\n\n    def addresses(self):\n        return self._current_state.addresses()\n\n    def record_fleet_state(self, skip_this_node: bool = False) -> StateDiff:\n        new_state, diff = self._current_state.with_updated_nodes(nodes_to_add=self._nodes_to_add,\n                                                                 nodes_to_remove=self._nodes_to_remove,\n                                                                 skip_this_node=skip_this_node)\n\n        self._nodes_to_add = set()\n        self._nodes_to_remove = set()\n        self._current_state = new_state\n\n        # TODO: set a limit on the number of archived states?\n        # Two ways to collect archived states:\n        # 1. (current) add a state to the archive every time it changes\n        # 2. (possible) keep a dictionary of known states\n        #    and bump the timestamp of a previously encountered one\n        if not diff.empty():\n            archived_state = new_state.archived()\n            self._archived_states.append(archived_state)\n\n        return diff\n\n    def shuffled(self):\n        return self._current_state.shuffled()\n\n    def mark_as(self, label: Exception, node: 'Ursula'):\n        # TODO: for now we're not using `label` in any way, so we're just ignoring it\n        self._nodes_to_remove.add(node.checksum_address)\n\n    def record_remote_fleet_state(self,\n                                  checksum_address: ChecksumAddress,\n                                  state_checksum: FleetStateChecksum,\n                                  timestamp: maya.MayaDT,\n                                  population: int):\n\n        if checksum_address not in self._current_state:\n            raise KeyError(f\"A node {checksum_address} is not present in the current fleet state\")\n\n        nickname = Nickname.from_seed(bytes(state_checksum), length=1)\n        state = ArchivedFleetState(checksum=state_checksum,\n                                   nickname=nickname,\n                                   timestamp=timestamp,\n                                   population=population)\n\n        self._remote_last_seen[checksum_address] = maya.now()\n        self._remote_states[checksum_address] = state\n\n    def status_info(self, checksum_address_or_node: Union[ChecksumAddress, 'Ursula']) -> 'RemoteUrsulaStatus':\n\n        if isinstance(checksum_address_or_node, str):\n            node = self[checksum_address_or_node]\n        else:\n            node = checksum_address_or_node\n\n        recorded_fleet_state = self._remote_states.get(node.checksum_address, None)\n        last_learned_from = self._remote_last_seen.get(node.checksum_address, None)\n        operator_address = node.operator_address if node.verified_node else None\n\n        return RemoteUrsulaStatus(verified=node.verified_node,\n                                  nickname=node.nickname,\n                                  staker_address=node.checksum_address,\n                                  operator_address=operator_address,\n                                  rest_url=node.rest_url(),\n                                  timestamp=node.timestamp,\n                                  last_learned_from=last_learned_from,\n                                  recorded_fleet_state=recorded_fleet_state,\n                                  )",
  "class RemoteUrsulaStatus(NamedTuple):\n    verified: bool\n    nickname: Nickname\n    staker_address: ChecksumAddress\n    operator_address: Optional[ChecksumAddress]\n    rest_url: str\n    timestamp: maya.MayaDT\n    recorded_fleet_state: Optional[ArchivedFleetState]\n    last_learned_from: Optional[maya.MayaDT]\n\n    def to_json(self) -> Dict[str, Any]:\n        if self.recorded_fleet_state is None:\n            recorded_fleet_state_json = None\n        else:\n            recorded_fleet_state_json = self.recorded_fleet_state.to_json()\n        if self.last_learned_from is None:\n            last_learned_from_json = None\n        else:\n            last_learned_from_json = self.last_learned_from.iso8601()\n        return dict(verified=self.verified,\n                    nickname=self.nickname.to_json(),\n                    staker_address=self.staker_address,\n                    operator_address=self.operator_address,\n                    rest_url=self.rest_url,\n                    timestamp=self.timestamp.iso8601(),\n                    recorded_fleet_state=recorded_fleet_state_json,\n                    last_learned_from=last_learned_from_json)",
  "def to_json(self):\n        return dict(checksum=bytes(self.checksum).hex(),\n                    nickname=self.nickname.to_json(),\n                    timestamp=self.timestamp.rfc2822(),\n                    population=self.population)",
  "def empty(self):\n        return not self.this_node_updated and not self.nodes_updated and not self.nodes_removed",
  "def new(cls, this_node: Optional['Ursula'] = None) -> 'FleetState':\n        this_node_ref = weakref.ref(this_node) if this_node else None\n        # `this_node` might not have its metadata available yet.\n        this_node_metadata = None\n\n        return cls(nodes={},\n                   this_node_ref=this_node_ref,\n                   this_node_metadata=this_node_metadata)",
  "def __init__(self,\n                 nodes: Dict[ChecksumAddress, 'Ursula'],\n                 this_node_ref: Optional[weakref.ReferenceType],\n                 this_node_metadata: Optional[NodeMetadata]):\n        self.checksum = FleetStateChecksum(this_node=this_node_metadata,\n                                           other_nodes=[node.metadata() for node in nodes.values()])\n        self.nickname = Nickname.from_seed(bytes(self.checksum), length=1)\n        self._nodes = nodes\n        self.timestamp = maya.now()\n        self._this_node_ref = this_node_ref\n        self._this_node_metadata = this_node_metadata",
  "def archived(self) -> ArchivedFleetState:\n        return ArchivedFleetState(checksum=self.checksum,\n                                  nickname=self.nickname,\n                                  timestamp=self.timestamp,\n                                  population=self.population)",
  "def _calculate_diff(self,\n                        this_node_updated: bool,\n                        nodes_to_add: Iterable['Ursula'],\n                        nodes_to_remove: Iterable[ChecksumAddress]\n                        ) -> StateDiff:\n\n        nodes_updated = []\n        for node in nodes_to_add:\n            if node.checksum_address in nodes_to_remove:\n                continue\n            unknown = node.checksum_address not in self._nodes\n            if unknown or bytes(self._nodes[node.checksum_address].metadata()) != bytes(node.metadata()):\n                nodes_updated.append(node.checksum_address)\n\n        nodes_removed = []\n        for checksum_address in nodes_to_remove:\n            if checksum_address in self._nodes:\n                nodes_removed.append(checksum_address)\n\n        return StateDiff(this_node_updated=this_node_updated,\n                         nodes_updated=nodes_updated,\n                         nodes_removed=nodes_removed)",
  "def with_updated_nodes(self,\n                           nodes_to_add: Iterable['Ursula'],\n                           nodes_to_remove: Iterable[ChecksumAddress],\n                           skip_this_node: bool = False,\n                           ) -> 'FleetState':\n\n        if self._this_node_ref is not None and not skip_this_node:\n            this_node = self._this_node_ref()\n            this_node_metadata = this_node.metadata()\n            this_node_updated = self._this_node_metadata != this_node_metadata\n            this_node_list = [this_node]\n        else:\n            this_node_metadata = self._this_node_metadata\n            this_node_updated = False\n            this_node_list = []\n\n        diff = self._calculate_diff(this_node_updated, nodes_to_add, nodes_to_remove)\n\n        if not diff.empty():\n            # TODO: if nodes were kept in a Merkle tree,\n            # we'd have to only recalculate log(N) checksums.\n            # Is it worth it?\n            nodes = dict(self._nodes)\n            nodes_to_add_dict = {node.checksum_address: node for node in nodes_to_add}\n            for checksum_address in diff.nodes_updated:\n                new_node = nodes_to_add_dict[checksum_address]\n                nodes[checksum_address] = new_node\n            for checksum_address in diff.nodes_removed:\n                del nodes[checksum_address]\n        else:\n            nodes = self._nodes\n\n        new_state = FleetState(nodes=nodes,\n                               this_node_ref=self._this_node_ref,\n                               this_node_metadata=this_node_metadata)\n\n        return new_state, diff",
  "def population(self) -> int:\n        \"\"\"Returns the number of all known nodes, including itself, if applicable.\"\"\"\n        return len(self) + int(self._this_node_metadata is not None)",
  "def __getitem__(self, checksum_address):\n        return self._nodes[checksum_address]",
  "def addresses(self) -> KeysView:\n        return self._nodes.keys()",
  "def __bool__(self):\n        return len(self) != 0",
  "def __contains__(self, item):\n        if isinstance(item, str):\n            return item in self._nodes\n        else:\n            return item.checksum_address in self._nodes",
  "def __iter__(self):\n        yield from self._nodes.values()",
  "def __len__(self):\n        return len(self._nodes)",
  "def shuffled(self) -> List['Ursula']:\n        nodes_we_know_about = list(self._nodes.values())\n        random.shuffle(nodes_we_know_about)\n        return nodes_we_know_about",
  "def to_json(self) -> Dict:\n        return dict(nickname=self.nickname.to_json(),\n                    updated=self.timestamp.rfc2822())",
  "def icon(self) -> str:\n        return self.nickname.icon",
  "def items(self):\n        return self._nodes.items()",
  "def values(self):\n        return self._nodes.values()",
  "def __str__(self):\n        return '{checksum} \u21c0{nickname}\u21bd {icon} '.format(icon=self.nickname.icon,\n                                                        nickname=self.nickname,\n                                                        checksum=bytes(self.checksum).hex()[:7])",
  "def __repr__(self):\n        return f\"FleetState({self.checksum}, {self._nodes}, {self._this_node_ref}, {self._this_node_metadata})\"",
  "def __init__(self, domain: str, this_node: Optional['Ursula'] = None):\n\n        self._domain = domain\n\n        self._current_state = FleetState.new(this_node)\n        self._archived_states = deque([self._current_state.archived()], maxlen=5)\n        self._remote_states = {}\n        self._remote_last_seen = {}\n\n        # temporary accumulator for new nodes to avoid updating the fleet state every time\n        self._nodes_to_add = set()\n        self._nodes_to_remove = set()  # Beginning of bucketing.\n\n        self._auto_update_state = False",
  "def record_node(self, node: 'Ursula'):\n\n        if node.domain == self._domain:\n            # Replace the existing object with a newer object, even if they're equal\n            # (this object can be mutated externally).\n            # This behavior is supposed to be consistent with that of the node storage\n            # (where a newer object with the same `checksum_address` replaces an older one).\n            if node in self._nodes_to_add:\n                self._nodes_to_add.remove(node)\n            self._nodes_to_add.add(node)\n\n            if self._auto_update_state:\n                self.log.info(f\"Updating fleet state after saving node {node}\")\n                self.record_fleet_state()\n        else:\n            msg = f\"Rejected node {node} because its domain is '{node.domain}' but we're only tracking '{self._domain}'\"\n            self.log.warn(msg)",
  "def __getitem__(self, item):\n        return self._current_state[item]",
  "def __bool__(self):\n        return bool(self._current_state)",
  "def __contains__(self, item):\n        \"\"\"\n        Checks if the node *with the same metadata* is recorded in the current state.\n        Does not compare ``item`` with the owner node of this FleetSensor.\n        \"\"\"\n        return item in self._current_state",
  "def __iter__(self):\n        yield from self._current_state",
  "def __len__(self):\n        return len(self._current_state)",
  "def __repr__(self):\n        return f\"FleetSensor({self._current_state.__repr__()})\"",
  "def current_state(self):\n        return self._current_state",
  "def checksum(self):\n        return self._current_state.checksum",
  "def population(self):\n        return self._current_state.population",
  "def nickname(self):\n        return self._current_state.nickname",
  "def icon(self) -> str:\n        return self._current_state.icon",
  "def timestamp(self):\n        return self._current_state.timestamp",
  "def items(self):\n        return self._current_state.items()",
  "def values(self):\n        return self._current_state.values()",
  "def latest_state(self) -> ArchivedFleetState:\n        # `_archived_states` is never empty, one state is created in the constructor\n        return self._archived_states[-1]",
  "def previous_states(self, quantity: int) -> List[ArchivedFleetState]:\n        \"\"\"\n        Returns at most ``quantity`` latest archived states (*not* including the current one),\n        in chronological order.\n        \"\"\"\n        # `_archived_states` is never empty, one state is created in the constructor\n        previous_states_num = min(len(self._archived_states) - 1, quantity)\n        return list(self._archived_states)[-previous_states_num-1:-1]",
  "def addresses(self):\n        return self._current_state.addresses()",
  "def record_fleet_state(self, skip_this_node: bool = False) -> StateDiff:\n        new_state, diff = self._current_state.with_updated_nodes(nodes_to_add=self._nodes_to_add,\n                                                                 nodes_to_remove=self._nodes_to_remove,\n                                                                 skip_this_node=skip_this_node)\n\n        self._nodes_to_add = set()\n        self._nodes_to_remove = set()\n        self._current_state = new_state\n\n        # TODO: set a limit on the number of archived states?\n        # Two ways to collect archived states:\n        # 1. (current) add a state to the archive every time it changes\n        # 2. (possible) keep a dictionary of known states\n        #    and bump the timestamp of a previously encountered one\n        if not diff.empty():\n            archived_state = new_state.archived()\n            self._archived_states.append(archived_state)\n\n        return diff",
  "def shuffled(self):\n        return self._current_state.shuffled()",
  "def mark_as(self, label: Exception, node: 'Ursula'):\n        # TODO: for now we're not using `label` in any way, so we're just ignoring it\n        self._nodes_to_remove.add(node.checksum_address)",
  "def record_remote_fleet_state(self,\n                                  checksum_address: ChecksumAddress,\n                                  state_checksum: FleetStateChecksum,\n                                  timestamp: maya.MayaDT,\n                                  population: int):\n\n        if checksum_address not in self._current_state:\n            raise KeyError(f\"A node {checksum_address} is not present in the current fleet state\")\n\n        nickname = Nickname.from_seed(bytes(state_checksum), length=1)\n        state = ArchivedFleetState(checksum=state_checksum,\n                                   nickname=nickname,\n                                   timestamp=timestamp,\n                                   population=population)\n\n        self._remote_last_seen[checksum_address] = maya.now()\n        self._remote_states[checksum_address] = state",
  "def status_info(self, checksum_address_or_node: Union[ChecksumAddress, 'Ursula']) -> 'RemoteUrsulaStatus':\n\n        if isinstance(checksum_address_or_node, str):\n            node = self[checksum_address_or_node]\n        else:\n            node = checksum_address_or_node\n\n        recorded_fleet_state = self._remote_states.get(node.checksum_address, None)\n        last_learned_from = self._remote_last_seen.get(node.checksum_address, None)\n        operator_address = node.operator_address if node.verified_node else None\n\n        return RemoteUrsulaStatus(verified=node.verified_node,\n                                  nickname=node.nickname,\n                                  staker_address=node.checksum_address,\n                                  operator_address=operator_address,\n                                  rest_url=node.rest_url(),\n                                  timestamp=node.timestamp,\n                                  last_learned_from=last_learned_from,\n                                  recorded_fleet_state=recorded_fleet_state,\n                                  )",
  "def to_json(self) -> Dict[str, Any]:\n        if self.recorded_fleet_state is None:\n            recorded_fleet_state_json = None\n        else:\n            recorded_fleet_state_json = self.recorded_fleet_state.to_json()\n        if self.last_learned_from is None:\n            last_learned_from_json = None\n        else:\n            last_learned_from_json = self.last_learned_from.iso8601()\n        return dict(verified=self.verified,\n                    nickname=self.nickname.to_json(),\n                    staker_address=self.staker_address,\n                    operator_address=self.operator_address,\n                    rest_url=self.rest_url,\n                    timestamp=self.timestamp.iso8601(),\n                    recorded_fleet_state=recorded_fleet_state_json,\n                    last_learned_from=last_learned_from_json)",
  "def generate_events_csv_filepath(contract_name: str, event_name: str) -> Path:\n    return Path(f'{contract_name}_{event_name}_{maya.now().datetime().strftime(\"%Y-%m-%d_%H-%M-%S\")}.csv')",
  "def write_events_to_csv_file(csv_file: Path,\n                             agent: EthereumContractAgent,\n                             event_name: str,\n                             argument_filters: Dict = None,\n                             from_block: Optional[BlockIdentifier] = 0,\n                             to_block: Optional[BlockIdentifier] = 'latest') -> bool:\n    \"\"\"\n    Write events to csv file.\n    :return: True if data written to file, False if there was no event data to write\n    \"\"\"\n    event_type = agent.contract.events[event_name]\n    entries = event_type.getLogs(fromBlock=from_block, toBlock=to_block, argument_filters=argument_filters)\n    if not entries:\n        return False\n\n    with open(csv_file, mode='w') as events_file:\n        events_writer = None\n        for event_record in entries:\n            event_record = EventRecord(event_record)\n            event_row = OrderedDict()\n            event_row['event_name'] = event_name\n            event_row['block_number'] = event_record.block_number\n            event_row['unix_timestamp'] = event_record.timestamp\n            event_row['date'] = maya.MayaDT(event_record.timestamp).iso8601()\n            event_row.update(dict(event_record.args.items()))\n            if events_writer is None:\n                events_writer = csv.DictWriter(events_file, fieldnames=event_row.keys())\n                events_writer.writeheader()\n            events_writer.writerow(event_row)\n    return True",
  "class SimpleTask(ABC):\n    \"\"\"Simple Twisted Looping Call abstract base class.\"\"\"\n    INTERVAL = 60  # 60s default\n\n    def __init__(self):\n        self.log = Logger(self.__class__.__name__)\n        self.__task = LoopingCall(self.run)\n\n    @property\n    def running(self) -> bool:\n        \"\"\"Determine whether the task is already running.\"\"\"\n        return self.__task.running\n\n    def start(self, now: bool = False):\n        \"\"\"Start task.\"\"\"\n        if not self.running:\n            d = self.__task.start(interval=self.INTERVAL, now=now)\n            d.addErrback(self.handle_errors)\n\n    def stop(self):\n        \"\"\"Stop task.\"\"\"\n        if self.running:\n            self.__task.stop()\n\n    @abstractmethod\n    def run(self):\n        \"\"\"Task method that should be periodically run.\"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def handle_errors(self, *args, **kwargs):\n        \"\"\"Error callback for error handling during execution.\"\"\"\n        raise NotImplementedError\n\n    @staticmethod\n    def clean_traceback(failure: Failure) -> str:\n        # FIXME: Amazing.\n        cleaned_traceback = failure.getTraceback().replace('{', '').replace('}', '')\n        return cleaned_traceback",
  "def __init__(self):\n        self.log = Logger(self.__class__.__name__)\n        self.__task = LoopingCall(self.run)",
  "def running(self) -> bool:\n        \"\"\"Determine whether the task is already running.\"\"\"\n        return self.__task.running",
  "def start(self, now: bool = False):\n        \"\"\"Start task.\"\"\"\n        if not self.running:\n            d = self.__task.start(interval=self.INTERVAL, now=now)\n            d.addErrback(self.handle_errors)",
  "def stop(self):\n        \"\"\"Stop task.\"\"\"\n        if self.running:\n            self.__task.stop()",
  "def run(self):\n        \"\"\"Task method that should be periodically run.\"\"\"\n        raise NotImplementedError",
  "def handle_errors(self, *args, **kwargs):\n        \"\"\"Error callback for error handling during execution.\"\"\"\n        raise NotImplementedError",
  "def clean_traceback(failure: Failure) -> str:\n        # FIXME: Amazing.\n        cleaned_traceback = failure.getTraceback().replace('{', '').replace('}', '')\n        return cleaned_traceback",
  "class Success:\n    def __init__(self, value, result):\n        self.value = value\n        self.result = result",
  "class Failure:\n    def __init__(self, value, exc_info):\n        self.value = value\n        self.exc_info = exc_info",
  "class Cancelled(Exception):\n    pass",
  "class FutureResult:\n\n    def __init__(self, value=None, exc_info=None):\n        self.value = value\n        self.exc_info = exc_info",
  "class Future:\n    \"\"\"\n    A simplified future object. Can be set to some value (all further sets are ignored),\n    can be waited on.\n    \"\"\"\n\n    def __init__(self):\n        self._lock = Lock()\n        self._set_event = Event()\n        self._value = None\n\n    def _set(self, value):\n        with self._lock:\n            if not self._set_event.is_set():\n                self._value = value\n                self._set_event.set()\n\n    def set(self, value):\n        self._set(FutureResult(value=value))\n\n    def set_exception(self):\n        exc_info = sys.exc_info()\n        self._set(FutureResult(exc_info=exc_info))\n\n    def is_set(self):\n        return self._set_event.is_set()\n\n    def get(self):\n        self._set_event.wait()\n\n        if self._value.exc_info is not None:\n            (exc_type, exc_value, exc_traceback) = self._value.exc_info\n            if exc_value is None:\n                exc_value = exc_type()\n            if exc_value.__traceback__ is not exc_traceback:\n                raise exc_value.with_traceback(exc_traceback)\n            raise exc_value\n        else:\n            return self._value.value",
  "class WorkerPoolException(Exception):\n    \"\"\"Generalized exception class for WorkerPool failures.\"\"\"\n    def __init__(self, message_prefix: str, failures: Dict):\n        self.failures = failures\n\n        # craft message\n        msg = message_prefix\n        if self.failures:\n            msg = f\"{message_prefix} ({len(self.failures)} failures recorded)\"\n        super().__init__(msg)\n\n    def get_tracebacks(self) -> Dict[Any, str]:\n        \"\"\"Returns values and associated tracebacks of execution failures.\"\"\"\n        exc_tracebacks = {}\n        for value, exc_info in self.failures.items():\n            _, exception, tb = exc_info\n            f = io.StringIO()\n            traceback.print_tb(tb, file=f)\n            exc_tracebacks[value] = f\"{f.getvalue()}\\n{exception}\"\n\n        return exc_tracebacks",
  "class WorkerPool:\n    \"\"\"\n    A generalized class that can start multiple workers in a thread pool with values\n    drawn from the given value factory object,\n    and wait for their completion and a given number of successes\n    (a worker returning something without throwing an exception).\n    \"\"\"\n\n    class TimedOut(WorkerPoolException):\n        \"\"\"Raised if waiting for the target number of successes timed out.\"\"\"\n        def __init__(self, timeout: float, *args, **kwargs):\n            self.timeout = timeout\n            super().__init__(message_prefix=f\"Execution timed out after {timeout}s\",\n                             *args, **kwargs)\n\n    class OutOfValues(WorkerPoolException):\n        \"\"\"Raised if the value factory is out of values, but the target number was not reached.\"\"\"\n        def __init__(self, *args, **kwargs):\n            super().__init__(message_prefix=\"Execution stopped before completion - not enough available values\",\n                             *args, **kwargs)\n\n    def __init__(self,\n                 worker: Callable[[Any], Any],\n                 value_factory: Callable[[int], Optional[List[Any]]],\n                 target_successes,\n                 timeout: float,\n                 stagger_timeout: float = 0,\n                 threadpool_size: int = None):\n\n        # TODO: make stagger_timeout a part of the value factory?\n\n        self._worker = worker\n        self._value_factory = value_factory\n        self._timeout = timeout\n        self._stagger_timeout = stagger_timeout\n        self._target_successes = target_successes\n\n        thread_pool_kwargs = {}\n        if threadpool_size is not None:\n            thread_pool_kwargs['minthreads'] = threadpool_size\n            thread_pool_kwargs['maxthreads'] = threadpool_size\n        self._threadpool = ThreadPool(**thread_pool_kwargs)\n\n        # These three tasks must be run in separate threads\n        # to avoid being blocked by workers in the thread pool.\n        self._bail_on_timeout_thread = Thread(target=self._bail_on_timeout)\n        self._produce_values_thread = Thread(target=self._produce_values)\n        self._process_results_thread = Thread(target=self._process_results)\n\n        self._successes = {}\n        self._failures = {}\n        self._started_tasks = 0\n        self._finished_tasks = 0\n\n        self._cancel_event = Event()\n        self._result_queue = Queue()\n        self._target_value = Future()\n        self._producer_error = Future()\n        self._results_lock = Lock()\n        self._threadpool_stop_lock = Lock()\n        self._threadpool_stopped = False\n\n    def start(self):\n        # TODO: check if already started?\n        self._threadpool.start()\n        self._produce_values_thread.start()\n        self._process_results_thread.start()\n        self._bail_on_timeout_thread.start()\n\n    def cancel(self):\n        \"\"\"\n        Cancels the tasks enqueued in the thread pool and stops the producer thread.\n        \"\"\"\n        self._cancel_event.set()\n\n    def _stop_threadpool(self):\n        # This can be called from multiple threads\n        # (`join()` itself can be called from multiple threads,\n        # and we also attempt to stop the pool from the `_process_results()` thread).\n        with self._threadpool_stop_lock:\n            if not self._threadpool_stopped:\n                self._threadpool.stop()\n                self._threadpool_stopped = True\n\n    def _check_for_producer_error(self):\n        # Check for any unexpected exceptions in the producer thread\n        if self._producer_error.is_set():\n            # Will raise if Future was set with an exception\n            self._producer_error.get()\n\n    def join(self):\n        \"\"\"\n        Waits for all the threads to finish.\n        Can be called several times.\n        \"\"\"\n        self._produce_values_thread.join()\n        self._process_results_thread.join()\n        self._bail_on_timeout_thread.join()\n\n        # In most cases `_threadpool` will be stopped by the `_process_results()` thread.\n        # But in case there's some unexpected bug in its code, we're making sure the pool is stopped\n        # to avoid the whole process hanging.\n        self._stop_threadpool()\n\n        self._check_for_producer_error()\n\n    def _sleep(self, timeout):\n        \"\"\"\n        Sleeps for a given timeout, can be interrupted by a cancellation event.\n        \"\"\"\n        if self._cancel_event.wait(timeout):\n            raise Cancelled\n\n    def block_until_target_successes(self) -> Dict:\n        \"\"\"\n        Blocks until the target number of successes is reached.\n        Returns a dictionary of values matched to results.\n        Can be called several times.\n        \"\"\"\n        self._check_for_producer_error()\n\n        result = self._target_value.get()\n        if result == TIMEOUT_TRIGGERED:\n            raise self.TimedOut(timeout=self._timeout, failures=self.get_failures())\n        elif result == PRODUCER_STOPPED:\n            raise self.OutOfValues(failures=self.get_failures())\n        return result\n\n    def get_failures(self) -> Dict:\n        \"\"\"\n        Get the current failures, as a dictionary of values to thrown exceptions.\n        \"\"\"\n        with self._results_lock:\n            return dict(self._failures)\n\n    def get_successes(self) -> Dict:\n        \"\"\"\n        Get the current successes, as a dictionary of values to worker return values.\n        \"\"\"\n        with self._results_lock:\n            return dict(self._successes)\n\n    def _bail_on_timeout(self):\n        \"\"\"\n        A service thread that cancels the pool on timeout.\n        \"\"\"\n        if not self._cancel_event.wait(timeout=self._timeout):\n            self._target_value.set(TIMEOUT_TRIGGERED)\n        self._cancel_event.set()\n\n    def _worker_wrapper(self, value):\n        \"\"\"\n        A wrapper that catches exceptions thrown by the worker\n        and sends the results to the processing thread.\n        \"\"\"\n        try:\n            # If we're in the cancelled state, interrupt early\n            self._sleep(0)\n\n            result = self._worker(value)\n            self._result_queue.put(Success(value, result))\n        except Cancelled as e:\n            self._result_queue.put(e)\n        except BaseException as e:\n            self._result_queue.put(Failure(value, sys.exc_info()))\n\n    def _process_results(self):\n        \"\"\"\n        A service thread that processes worker results\n        and waits for the target number of successes to be reached.\n        \"\"\"\n        producer_stopped = False\n        success_event_reached = False\n        while True:\n            result = self._result_queue.get()\n\n            if result == PRODUCER_STOPPED:\n                producer_stopped = True\n            else:\n                self._finished_tasks += 1\n                if isinstance(result, Success):\n                    with self._results_lock:\n                        self._successes[result.value] = result.result\n                        len_successes = len(self._successes)\n                    if not success_event_reached and len_successes == self._target_successes:\n                        # A protection for the case of repeating values.\n                        # Only trigger the target value once.\n                        success_event_reached = True\n                        self._target_value.set(self.get_successes())\n                if isinstance(result, Failure):\n                    with self._results_lock:\n                        self._failures[result.value] = result.exc_info\n\n            if success_event_reached:\n                # no need to continue processing results\n                self.cancel()  # to cancel the timeout thread\n                break\n\n            if producer_stopped and self._finished_tasks == self._started_tasks:\n                self.cancel()  # to cancel the timeout thread\n                self._target_value.set(PRODUCER_STOPPED)\n                break\n\n        self._stop_threadpool()\n\n    def _produce_values(self):\n        while True:\n            try:\n                with self._results_lock:\n                    len_successes = len(self._successes)\n                batch = self._value_factory(len_successes)\n                if not batch:\n                    break\n\n                self._started_tasks += len(batch)\n                for value in batch:\n                    # There is a possible race between `callInThread()` and `stop()`,\n                    # But we never execute them at the same time,\n                    # because `join()` checks that the producer thread is stopped.\n                    self._threadpool.callInThread(self._worker_wrapper, value)\n\n                self._sleep(self._stagger_timeout)\n\n            except Cancelled:\n                break\n\n            except BaseException:\n                self._producer_error.set_exception()\n                self.cancel()\n                break\n\n        self._result_queue.put(PRODUCER_STOPPED)",
  "def __init__(self, value, result):\n        self.value = value\n        self.result = result",
  "def __init__(self, value, exc_info):\n        self.value = value\n        self.exc_info = exc_info",
  "def __init__(self, value=None, exc_info=None):\n        self.value = value\n        self.exc_info = exc_info",
  "def __init__(self):\n        self._lock = Lock()\n        self._set_event = Event()\n        self._value = None",
  "def _set(self, value):\n        with self._lock:\n            if not self._set_event.is_set():\n                self._value = value\n                self._set_event.set()",
  "def set(self, value):\n        self._set(FutureResult(value=value))",
  "def set_exception(self):\n        exc_info = sys.exc_info()\n        self._set(FutureResult(exc_info=exc_info))",
  "def is_set(self):\n        return self._set_event.is_set()",
  "def get(self):\n        self._set_event.wait()\n\n        if self._value.exc_info is not None:\n            (exc_type, exc_value, exc_traceback) = self._value.exc_info\n            if exc_value is None:\n                exc_value = exc_type()\n            if exc_value.__traceback__ is not exc_traceback:\n                raise exc_value.with_traceback(exc_traceback)\n            raise exc_value\n        else:\n            return self._value.value",
  "def __init__(self, message_prefix: str, failures: Dict):\n        self.failures = failures\n\n        # craft message\n        msg = message_prefix\n        if self.failures:\n            msg = f\"{message_prefix} ({len(self.failures)} failures recorded)\"\n        super().__init__(msg)",
  "def get_tracebacks(self) -> Dict[Any, str]:\n        \"\"\"Returns values and associated tracebacks of execution failures.\"\"\"\n        exc_tracebacks = {}\n        for value, exc_info in self.failures.items():\n            _, exception, tb = exc_info\n            f = io.StringIO()\n            traceback.print_tb(tb, file=f)\n            exc_tracebacks[value] = f\"{f.getvalue()}\\n{exception}\"\n\n        return exc_tracebacks",
  "class TimedOut(WorkerPoolException):\n        \"\"\"Raised if waiting for the target number of successes timed out.\"\"\"\n        def __init__(self, timeout: float, *args, **kwargs):\n            self.timeout = timeout\n            super().__init__(message_prefix=f\"Execution timed out after {timeout}s\",\n                             *args, **kwargs)",
  "class OutOfValues(WorkerPoolException):\n        \"\"\"Raised if the value factory is out of values, but the target number was not reached.\"\"\"\n        def __init__(self, *args, **kwargs):\n            super().__init__(message_prefix=\"Execution stopped before completion - not enough available values\",\n                             *args, **kwargs)",
  "def __init__(self,\n                 worker: Callable[[Any], Any],\n                 value_factory: Callable[[int], Optional[List[Any]]],\n                 target_successes,\n                 timeout: float,\n                 stagger_timeout: float = 0,\n                 threadpool_size: int = None):\n\n        # TODO: make stagger_timeout a part of the value factory?\n\n        self._worker = worker\n        self._value_factory = value_factory\n        self._timeout = timeout\n        self._stagger_timeout = stagger_timeout\n        self._target_successes = target_successes\n\n        thread_pool_kwargs = {}\n        if threadpool_size is not None:\n            thread_pool_kwargs['minthreads'] = threadpool_size\n            thread_pool_kwargs['maxthreads'] = threadpool_size\n        self._threadpool = ThreadPool(**thread_pool_kwargs)\n\n        # These three tasks must be run in separate threads\n        # to avoid being blocked by workers in the thread pool.\n        self._bail_on_timeout_thread = Thread(target=self._bail_on_timeout)\n        self._produce_values_thread = Thread(target=self._produce_values)\n        self._process_results_thread = Thread(target=self._process_results)\n\n        self._successes = {}\n        self._failures = {}\n        self._started_tasks = 0\n        self._finished_tasks = 0\n\n        self._cancel_event = Event()\n        self._result_queue = Queue()\n        self._target_value = Future()\n        self._producer_error = Future()\n        self._results_lock = Lock()\n        self._threadpool_stop_lock = Lock()\n        self._threadpool_stopped = False",
  "def start(self):\n        # TODO: check if already started?\n        self._threadpool.start()\n        self._produce_values_thread.start()\n        self._process_results_thread.start()\n        self._bail_on_timeout_thread.start()",
  "def cancel(self):\n        \"\"\"\n        Cancels the tasks enqueued in the thread pool and stops the producer thread.\n        \"\"\"\n        self._cancel_event.set()",
  "def _stop_threadpool(self):\n        # This can be called from multiple threads\n        # (`join()` itself can be called from multiple threads,\n        # and we also attempt to stop the pool from the `_process_results()` thread).\n        with self._threadpool_stop_lock:\n            if not self._threadpool_stopped:\n                self._threadpool.stop()\n                self._threadpool_stopped = True",
  "def _check_for_producer_error(self):\n        # Check for any unexpected exceptions in the producer thread\n        if self._producer_error.is_set():\n            # Will raise if Future was set with an exception\n            self._producer_error.get()",
  "def join(self):\n        \"\"\"\n        Waits for all the threads to finish.\n        Can be called several times.\n        \"\"\"\n        self._produce_values_thread.join()\n        self._process_results_thread.join()\n        self._bail_on_timeout_thread.join()\n\n        # In most cases `_threadpool` will be stopped by the `_process_results()` thread.\n        # But in case there's some unexpected bug in its code, we're making sure the pool is stopped\n        # to avoid the whole process hanging.\n        self._stop_threadpool()\n\n        self._check_for_producer_error()",
  "def _sleep(self, timeout):\n        \"\"\"\n        Sleeps for a given timeout, can be interrupted by a cancellation event.\n        \"\"\"\n        if self._cancel_event.wait(timeout):\n            raise Cancelled",
  "def block_until_target_successes(self) -> Dict:\n        \"\"\"\n        Blocks until the target number of successes is reached.\n        Returns a dictionary of values matched to results.\n        Can be called several times.\n        \"\"\"\n        self._check_for_producer_error()\n\n        result = self._target_value.get()\n        if result == TIMEOUT_TRIGGERED:\n            raise self.TimedOut(timeout=self._timeout, failures=self.get_failures())\n        elif result == PRODUCER_STOPPED:\n            raise self.OutOfValues(failures=self.get_failures())\n        return result",
  "def get_failures(self) -> Dict:\n        \"\"\"\n        Get the current failures, as a dictionary of values to thrown exceptions.\n        \"\"\"\n        with self._results_lock:\n            return dict(self._failures)",
  "def get_successes(self) -> Dict:\n        \"\"\"\n        Get the current successes, as a dictionary of values to worker return values.\n        \"\"\"\n        with self._results_lock:\n            return dict(self._successes)",
  "def _bail_on_timeout(self):\n        \"\"\"\n        A service thread that cancels the pool on timeout.\n        \"\"\"\n        if not self._cancel_event.wait(timeout=self._timeout):\n            self._target_value.set(TIMEOUT_TRIGGERED)\n        self._cancel_event.set()",
  "def _worker_wrapper(self, value):\n        \"\"\"\n        A wrapper that catches exceptions thrown by the worker\n        and sends the results to the processing thread.\n        \"\"\"\n        try:\n            # If we're in the cancelled state, interrupt early\n            self._sleep(0)\n\n            result = self._worker(value)\n            self._result_queue.put(Success(value, result))\n        except Cancelled as e:\n            self._result_queue.put(e)\n        except BaseException as e:\n            self._result_queue.put(Failure(value, sys.exc_info()))",
  "def _process_results(self):\n        \"\"\"\n        A service thread that processes worker results\n        and waits for the target number of successes to be reached.\n        \"\"\"\n        producer_stopped = False\n        success_event_reached = False\n        while True:\n            result = self._result_queue.get()\n\n            if result == PRODUCER_STOPPED:\n                producer_stopped = True\n            else:\n                self._finished_tasks += 1\n                if isinstance(result, Success):\n                    with self._results_lock:\n                        self._successes[result.value] = result.result\n                        len_successes = len(self._successes)\n                    if not success_event_reached and len_successes == self._target_successes:\n                        # A protection for the case of repeating values.\n                        # Only trigger the target value once.\n                        success_event_reached = True\n                        self._target_value.set(self.get_successes())\n                if isinstance(result, Failure):\n                    with self._results_lock:\n                        self._failures[result.value] = result.exc_info\n\n            if success_event_reached:\n                # no need to continue processing results\n                self.cancel()  # to cancel the timeout thread\n                break\n\n            if producer_stopped and self._finished_tasks == self._started_tasks:\n                self.cancel()  # to cancel the timeout thread\n                self._target_value.set(PRODUCER_STOPPED)\n                break\n\n        self._stop_threadpool()",
  "def _produce_values(self):\n        while True:\n            try:\n                with self._results_lock:\n                    len_successes = len(self._successes)\n                batch = self._value_factory(len_successes)\n                if not batch:\n                    break\n\n                self._started_tasks += len(batch)\n                for value in batch:\n                    # There is a possible race between `callInThread()` and `stop()`,\n                    # But we never execute them at the same time,\n                    # because `join()` checks that the producer thread is stopped.\n                    self._threadpool.callInThread(self._worker_wrapper, value)\n\n                self._sleep(self._stagger_timeout)\n\n            except Cancelled:\n                break\n\n            except BaseException:\n                self._producer_error.set_exception()\n                self.cancel()\n                break\n\n        self._result_queue.put(PRODUCER_STOPPED)",
  "def __init__(self, timeout: float, *args, **kwargs):\n            self.timeout = timeout\n            super().__init__(message_prefix=f\"Execution timed out after {timeout}s\",\n                             *args, **kwargs)",
  "def __init__(self, *args, **kwargs):\n            super().__init__(message_prefix=\"Execution stopped before completion - not enough available values\",\n                             *args, **kwargs)",
  "class UnknownIPAddress(RuntimeError):\n    pass",
  "class InvalidOperatorIP(RuntimeError):\n    \"\"\"Raised when an Ursula is using an invalid IP address for it's server.\"\"\"",
  "def validate_operator_ip(ip: str) -> None:\n    if ip in RESERVED_IP_ADDRESSES:\n        raise InvalidOperatorIP(f\"{ip} is not a valid or permitted operator IP address. \"\n                                f\"Verify the 'rest_host' configuration value is set to the \"\n                                f\"external IPV4 address\")",
  "def _request(url: str, certificate=None) -> Union[str, None]:\n    \"\"\"\n    Utility function to send a GET request to a URL returning it's\n    text content or None, suppressing all errors. Certificate is\n    needed if the remote URL source is self-signed.\n    \"\"\"\n    try:\n        # 'None' or 'True' will verify self-signed certificates\n        response = requests.get(url, verify=certificate)\n    except RequestErrors:\n        return None\n    if response.status_code == 200:\n        return response.text",
  "def _request_from_node(teacher,\n                       client: Optional[NucypherMiddlewareClient] = None,\n                       timeout: int = 2,\n                       log: Logger = IP_DETECTION_LOGGER\n                       ) -> Union[str, None]:\n    if not client:\n        client = NucypherMiddlewareClient()\n    try:\n        response = client.get(node_or_sprout=teacher, path=f\"ping\", timeout=timeout)  # TLS certificate logic within\n    except RestMiddleware.UnexpectedResponse:\n        # 404, 405, 500, All server response codes handled by will be caught here.\n        return  # Default teacher does not support this request - just move on.\n    except NodeSeemsToBeDown:\n        # This node is unreachable.  Move on.\n        return\n    if response.status_code == 200:\n        try:\n            ip = str(ip_address(response.text))\n        except ValueError:\n            error = f'Teacher {teacher} returned an invalid IP response; Got {response.text}'\n            raise UnknownIPAddress(error)\n        log.info(f'Fetched external IP address ({ip}) from teacher ({teacher}).')\n        return ip\n    else:\n        # Something strange happened... move on anyways.\n        log.debug(f'Failed to get external IP from teacher node ({teacher} returned {response.status_code})')",
  "def get_external_ip_from_default_teacher(network: str,\n                                         federated_only: bool = False,\n                                         registry: Optional[BaseContractRegistry] = None,\n                                         log: Logger = IP_DETECTION_LOGGER\n                                         ) -> Union[str, None]:\n\n    # Prevents circular imports\n    from nucypher.characters.lawful import Ursula\n    from nucypher.network.nodes import TEACHER_NODES\n\n    if federated_only and registry:\n        raise ValueError('Federated mode must not be true if registry is provided.')\n\n    base_error = 'Cannot determine IP using default teacher'\n\n    if network not in TEACHER_NODES:\n        log.debug(f'{base_error}: Unknown network \"{network}\".')\n        return\n\n    ####\n    # TODO: Clean this mess #1481 (Federated Mode)\n    node_storage = LocalFileBasedNodeStorage(federated_only=federated_only)\n    Ursula.set_cert_storage_function(node_storage.store_node_certificate)\n    Ursula.set_federated_mode(federated_only)\n    #####\n\n    external_ip = None\n    for teacher_uri in TEACHER_NODES[network]:\n        try:\n            teacher = Ursula.from_teacher_uri(teacher_uri=teacher_uri,\n                                              federated_only=federated_only,\n                                              min_stake=0)  # TODO: Handle customized min stake here.\n            # TODO: Pass registry here to verify stake (not essential here since it's a hardcoded node)\n            external_ip = _request_from_node(teacher=teacher)\n            # Found a reachable teacher, return from loop\n            if external_ip:\n                break\n        except NodeSeemsToBeDown:\n            # Teacher is unreachable, try next one\n            continue\n\n    if not external_ip:\n        log.debug(f'{base_error}: No teacher available for network \"{network}\".')\n        return\n\n    return external_ip",
  "def get_external_ip_from_known_nodes(known_nodes: FleetSensor,\n                                     sample_size: int = 3,\n                                     log: Logger = IP_DETECTION_LOGGER\n                                     ) -> Union[str, None]:\n    \"\"\"\n    Randomly select a sample of peers to determine the external IP address\n    of this host. The first node to reply successfully will be used.\n    # TODO: Parallelize the requests and compare results.\n    \"\"\"\n    if len(known_nodes) < sample_size:\n        return  # There are too few known nodes\n    sample = random.sample(list(known_nodes), sample_size)\n    client = NucypherMiddlewareClient()\n    for node in sample:\n        ip = _request_from_node(teacher=node, client=client)\n        if ip:\n            log.info(f'Fetched external IP address ({ip}) from randomly selected known nodes.')\n            return ip",
  "def get_external_ip_from_centralized_source(log: Logger = IP_DETECTION_LOGGER) -> Union[str, None]:\n    \"\"\"Use hardcoded URL to determine the external IP address of this host.\"\"\"\n    ip = _request(url=CENTRALIZED_IP_ORACLE_URL)\n    if ip:\n        log.info(f'Fetched external IP address ({ip}) from centralized source ({CENTRALIZED_IP_ORACLE_URL}).')\n    return ip",
  "def determine_external_ip_address(network: str, known_nodes: FleetSensor = None) -> str:\n    \"\"\"\n    Attempts to automatically determine the external IP in the following priority:\n    1. Randomly Selected Known Nodes\n    2. The Default Teacher URI from RestMiddleware\n    3. A centralized IP address service\n\n    If the IP address cannot be determined for any reason UnknownIPAddress is raised.\n    \"\"\"\n    rest_host = None\n\n    # primary source\n    if known_nodes:\n        rest_host = get_external_ip_from_known_nodes(known_nodes=known_nodes)\n\n    # fallback 1\n    if not rest_host:\n        rest_host = get_external_ip_from_default_teacher(network=network)\n\n    # fallback 2\n    if not rest_host:\n        rest_host = get_external_ip_from_centralized_source()\n\n    # complete failure!\n    if not rest_host:\n        raise UnknownIPAddress('External IP address detection failed')\n    return rest_host",
  "class Datafeed(ABC):\n\n    class DatafeedError(RuntimeError):\n        \"\"\"Base class for exceptions concerning Datafeeds\"\"\"\n\n    name = NotImplemented\n    api_url = NotImplemented  # TODO: Deal with API keys\n\n    def _probe_feed(self):\n        try:\n            response = requests.get(self.api_url)\n        except requests.exceptions.ConnectionError as e:\n            error = f\"Failed to probe feed at {self.api_url}: {str(e)}\"\n            raise self.DatafeedError(error)\n\n        if response.status_code != 200:\n            error = f\"Failed to probe feed at {self.api_url} with status code {response.status_code}\"\n            raise self.DatafeedError(error)\n\n        self._raw_data = response.json()\n\n    def __repr__(self):\n        return f\"{self.name} ({self.api_url})\"",
  "class EthereumGasPriceDatafeed(Datafeed):\n    \"\"\"Base class for Ethereum gas price data feeds\"\"\"\n\n    _speed_names = NotImplemented\n    _default_speed = NotImplemented\n\n    _speed_equivalence_classes = {\n        SLOW: ('slow', 'safeLow', 'low'),\n        MEDIUM: ('medium', 'standard', 'average'),\n        FAST: ('fast', 'high'),\n        FASTEST: ('fastest', )\n    }\n\n    @abstractmethod\n    def _parse_gas_prices(self):\n        return NotImplementedError\n\n    def get_gas_price(self, speed: Optional[str] = None) -> Wei:\n        speed = speed or self._default_speed\n        self._parse_gas_prices()\n        gas_price_wei = Wei(self.gas_prices[self.get_canonical_speed(speed)])\n        return gas_price_wei\n\n    @classmethod\n    def construct_gas_strategy(cls, speed: Optional[str] = None):\n        def gas_price_strategy(web3: Web3, transaction_params: TxParams = None) -> Wei:\n            feed = cls()\n            gas_price = feed.get_gas_price(speed=speed)\n            return gas_price\n        return gas_price_strategy\n\n    @classmethod\n    def get_canonical_speed(cls, speed: str):\n        for canonical_speed, speed_names in cls._speed_equivalence_classes.items():\n            if speed.lower() in map(str.lower, speed_names):\n                return canonical_speed\n        else:\n            all_speed_names = [name for names in cls._speed_equivalence_classes.values() for name in names]\n            suggestion = get_close_matches(speed, all_speed_names, n=1)\n            if not suggestion:\n                message = f\"'{speed}' is not a valid speed name.\"\n            else:\n                suggestion = suggestion.pop()\n                message = f\"'{speed}' is not a valid speed name. Did you mean '{suggestion}'?\"\n            raise LookupError(message)",
  "class EtherchainGasPriceDatafeed(EthereumGasPriceDatafeed):\n    \"\"\"Gas price datafeed from Etherchain\"\"\"\n\n    name = \"Etherchain datafeed\"\n    api_url = \"https://www.etherchain.org/api/gasPriceOracle\"\n    _speed_names = {\n        SLOW: 'safeLow',\n        MEDIUM: 'standard',\n        FAST: 'fast',\n        FASTEST: 'fastest'\n    }\n    _default_speed = 'fast'\n\n    def _parse_gas_prices(self):\n        self._probe_feed()\n        self.gas_prices = {self.get_canonical_speed(k): int(Web3.to_wei(v, 'gwei')) for k, v in self._raw_data.items()}",
  "class UpvestGasPriceDatafeed(EthereumGasPriceDatafeed):\n    \"\"\"Gas price datafeed from Upvest\"\"\"\n\n    name = \"Upvest datafeed\"\n    api_url = \"https://fees.upvest.co/estimate_eth_fees\"\n    _speed_names = {\n        SLOW: 'slow',\n        MEDIUM: 'medium',\n        FAST: 'fast',\n        FASTEST: 'fastest'\n    }\n    _default_speed = 'fastest'\n\n    def _parse_gas_prices(self):\n        self._probe_feed()\n        self.gas_prices = {self.get_canonical_speed(k): int(Web3.to_wei(v, 'gwei'))\n                           for k, v in self._raw_data['estimates'].items()}",
  "class ZoltuGasPriceDatafeed(EthereumGasPriceDatafeed):\n    \"\"\"Gas price datafeed from gas-oracle.zoltu.io\"\"\"\n\n    name = \"gas-oracle.zoltu.io datafeed\"\n    api_url = \"https://gas-oracle.zoltu.io\"\n    _speed_names = {\n        SLOW: 'percentile_40',\n        MEDIUM: 'percentile_75',\n        FAST: 'percentile_95',\n        FASTEST: 'percentile_98'\n    }\n    _default_speed = 'fast'\n\n    def _parse_gas_prices(self):\n        self._probe_feed()\n        self.gas_prices = dict()\n        for canonical_speed_name, zoltu_speed in self._speed_names.items():\n            gwei_price = self._raw_data[zoltu_speed].split(\" \")[0]\n            wei_price = int(Web3.to_wei(gwei_price, 'gwei'))\n            self.gas_prices[canonical_speed_name] = wei_price",
  "class DatafeedError(RuntimeError):\n        \"\"\"Base class for exceptions concerning Datafeeds\"\"\"",
  "def _probe_feed(self):\n        try:\n            response = requests.get(self.api_url)\n        except requests.exceptions.ConnectionError as e:\n            error = f\"Failed to probe feed at {self.api_url}: {str(e)}\"\n            raise self.DatafeedError(error)\n\n        if response.status_code != 200:\n            error = f\"Failed to probe feed at {self.api_url} with status code {response.status_code}\"\n            raise self.DatafeedError(error)\n\n        self._raw_data = response.json()",
  "def __repr__(self):\n        return f\"{self.name} ({self.api_url})\"",
  "def _parse_gas_prices(self):\n        return NotImplementedError",
  "def get_gas_price(self, speed: Optional[str] = None) -> Wei:\n        speed = speed or self._default_speed\n        self._parse_gas_prices()\n        gas_price_wei = Wei(self.gas_prices[self.get_canonical_speed(speed)])\n        return gas_price_wei",
  "def construct_gas_strategy(cls, speed: Optional[str] = None):\n        def gas_price_strategy(web3: Web3, transaction_params: TxParams = None) -> Wei:\n            feed = cls()\n            gas_price = feed.get_gas_price(speed=speed)\n            return gas_price\n        return gas_price_strategy",
  "def get_canonical_speed(cls, speed: str):\n        for canonical_speed, speed_names in cls._speed_equivalence_classes.items():\n            if speed.lower() in map(str.lower, speed_names):\n                return canonical_speed\n        else:\n            all_speed_names = [name for names in cls._speed_equivalence_classes.values() for name in names]\n            suggestion = get_close_matches(speed, all_speed_names, n=1)\n            if not suggestion:\n                message = f\"'{speed}' is not a valid speed name.\"\n            else:\n                suggestion = suggestion.pop()\n                message = f\"'{speed}' is not a valid speed name. Did you mean '{suggestion}'?\"\n            raise LookupError(message)",
  "def _parse_gas_prices(self):\n        self._probe_feed()\n        self.gas_prices = {self.get_canonical_speed(k): int(Web3.to_wei(v, 'gwei')) for k, v in self._raw_data.items()}",
  "def _parse_gas_prices(self):\n        self._probe_feed()\n        self.gas_prices = {self.get_canonical_speed(k): int(Web3.to_wei(v, 'gwei'))\n                           for k, v in self._raw_data['estimates'].items()}",
  "def _parse_gas_prices(self):\n        self._probe_feed()\n        self.gas_prices = dict()\n        for canonical_speed_name, zoltu_speed in self._speed_names.items():\n            gwei_price = self._raw_data[zoltu_speed].split(\" \")[0]\n            wei_price = int(Web3.to_wei(gwei_price, 'gwei'))\n            self.gas_prices[canonical_speed_name] = wei_price",
  "def gas_price_strategy(web3: Web3, transaction_params: TxParams = None) -> Wei:\n            feed = cls()\n            gas_price = feed.get_gas_price(speed=speed)\n            return gas_price",
  "def initialize_sentry(dsn: str):\n    try:\n        import sentry_sdk\n        from sentry_sdk.integrations.logging import LoggingIntegration\n    except ImportError:\n        raise ImportError('Sentry SDK is not installed. Please install it and try again.')\n\n    import logging\n\n    # Logger ignore list\n    ignored_loggers = ()\n\n    def before_breadcrumb(crumb, hint):\n        logger = crumb.get('category')\n        if logger in ignored_loggers:\n            return\n        return crumb\n\n    def before_send(event, hint):\n        logger = event.get('logger')\n        if logger in ignored_loggers:\n            return\n        return event\n\n    sentry_logging = LoggingIntegration(\n        level=logging.DEBUG,  # Capture debug and above as breadcrumbs\n        event_level=logging.ERROR  # Send errors as events\n    )\n    sentry_sdk.init(\n        dsn=dsn,\n        release=nucypher.__version__,\n        integrations=[sentry_logging],\n        before_breadcrumb=before_breadcrumb,\n        before_send=before_send\n    )",
  "class GlobalLoggerSettings:\n\n    log_level = LogLevel.levelWithName(\"info\")\n    _json_ipc = False  # TODO: Oh no... #1754\n\n    @classmethod\n    def set_log_level(cls, log_level_name):\n        cls.log_level = LogLevel.levelWithName(log_level_name)\n\n    @classmethod\n    def start_console_logging(cls):\n        globalLogPublisher.addObserver(console_observer)\n\n    @classmethod\n    def stop_console_logging(cls):\n        globalLogPublisher.removeObserver(console_observer)\n\n    @classmethod\n    @contextmanager\n    def pause_all_logging_while(cls):\n        former_observers = tuple(globalLogPublisher._observers)\n        for observer in former_observers:\n            globalLogPublisher.removeObserver(observer)\n        yield\n        for observer in former_observers:\n            globalLogPublisher.addObserver(observer)\n\n    @classmethod\n    def start_text_file_logging(cls):\n        globalLogPublisher.addObserver(get_text_file_observer())\n\n    @classmethod\n    def stop_text_file_logging(cls):\n        globalLogPublisher.removeObserver(get_text_file_observer())\n\n    @classmethod\n    def start_json_file_logging(cls):\n        globalLogPublisher.addObserver(get_json_file_observer())\n\n    @classmethod\n    def stop_json_file_logging(cls):\n        globalLogPublisher.removeObserver(get_json_file_observer())\n\n    @classmethod\n    def start_sentry_logging(cls, dsn: str):\n        _SentryInitGuard.init(dsn)\n        globalLogPublisher.addObserver(sentry_observer)\n\n    @classmethod\n    def stop_sentry_logging(cls):\n        globalLogPublisher.removeObserver(sentry_observer)",
  "def console_observer(event):\n    if event['log_level'] >= GlobalLoggerSettings.log_level:\n        print(formatEvent(event))",
  "class _SentryInitGuard:\n    initialized = False\n    dsn = None\n\n    @classmethod\n    def init(cls, dsn: str = NUCYPHER_SENTRY_ENDPOINT):\n        if not cls.initialized:\n            initialize_sentry(dsn)\n        else:\n            raise ValueError(f\"Sentry has been already initialized with DSN {cls.dsn}\")",
  "def sentry_observer(event):\n    try:\n        from sentry_sdk import capture_exception, add_breadcrumb\n    except ImportError:\n        raise ImportError('Sentry SDK is not installed. Please install it and try again.')\n\n    # Handle breadcrumbs...\n    if not event.get('isError') or 'failure' not in event:\n        add_breadcrumb(level=event.get('log_level').name,\n                       message=event.get('log_format'),\n                       category=event.get('log_namespace'))\n        return\n\n    # ...Handle Failures\n    f = event['failure']\n    capture_exception((f.type, f.value, f.getTracebackObject()))",
  "def _ensure_dir_exists(path):\n    pathlib.Path(path).mkdir(parents=True, exist_ok=True)",
  "def get_json_file_observer(name=DEFAULT_JSON_LOG_FILENAME, path=USER_LOG_DIR):\n    _ensure_dir_exists(path)\n    logfile = LogFile(name=name, directory=path, rotateLength=MAXIMUM_LOG_SIZE, maxRotatedFiles=MAX_LOG_FILES)\n    observer = jsonFileLogObserver(outFile=logfile)\n    return observer",
  "def get_text_file_observer(name=DEFAULT_LOG_FILENAME, path=USER_LOG_DIR):\n    _ensure_dir_exists(path)\n    logfile = LogFile(name=name, directory=path, rotateLength=MAXIMUM_LOG_SIZE, maxRotatedFiles=MAX_LOG_FILES)\n    observer = FileLogObserver(formatEvent=formatEventAsClassicLogText, outFile=logfile)\n    return observer",
  "class Logger(TwistedLogger):\n    \"\"\"Drop-in replacement of Twisted's Logger, patching the emit() method to tolerate inputs with curly braces,\n    i.e., not compliant with PEP 3101.\n\n    See Issue #724 and, particularly, https://github.com/nucypher/nucypher/issues/724#issuecomment-600190455\"\"\"\n\n    @classmethod\n    def escape_format_string(cls, string):\n        \"\"\"\n        Escapes all curly braces from a PEP-3101's format string.\n        \"\"\"\n        escaped_string = string.replace(\"{\", \"{{\").replace(\"}\", \"}}\")\n        return escaped_string\n\n    def emit(self, level, format=None, **kwargs):\n        clean_format = self.escape_format_string(str(format))\n        super().emit(level=level, format=clean_format, **kwargs)",
  "def before_breadcrumb(crumb, hint):\n        logger = crumb.get('category')\n        if logger in ignored_loggers:\n            return\n        return crumb",
  "def before_send(event, hint):\n        logger = event.get('logger')\n        if logger in ignored_loggers:\n            return\n        return event",
  "def set_log_level(cls, log_level_name):\n        cls.log_level = LogLevel.levelWithName(log_level_name)",
  "def start_console_logging(cls):\n        globalLogPublisher.addObserver(console_observer)",
  "def stop_console_logging(cls):\n        globalLogPublisher.removeObserver(console_observer)",
  "def pause_all_logging_while(cls):\n        former_observers = tuple(globalLogPublisher._observers)\n        for observer in former_observers:\n            globalLogPublisher.removeObserver(observer)\n        yield\n        for observer in former_observers:\n            globalLogPublisher.addObserver(observer)",
  "def start_text_file_logging(cls):\n        globalLogPublisher.addObserver(get_text_file_observer())",
  "def stop_text_file_logging(cls):\n        globalLogPublisher.removeObserver(get_text_file_observer())",
  "def start_json_file_logging(cls):\n        globalLogPublisher.addObserver(get_json_file_observer())",
  "def stop_json_file_logging(cls):\n        globalLogPublisher.removeObserver(get_json_file_observer())",
  "def start_sentry_logging(cls, dsn: str):\n        _SentryInitGuard.init(dsn)\n        globalLogPublisher.addObserver(sentry_observer)",
  "def stop_sentry_logging(cls):\n        globalLogPublisher.removeObserver(sentry_observer)",
  "def init(cls, dsn: str = NUCYPHER_SENTRY_ENDPOINT):\n        if not cls.initialized:\n            initialize_sentry(dsn)\n        else:\n            raise ValueError(f\"Sentry has been already initialized with DSN {cls.dsn}\")",
  "def escape_format_string(cls, string):\n        \"\"\"\n        Escapes all curly braces from a PEP-3101's format string.\n        \"\"\"\n        escaped_string = string.replace(\"{\", \"{{\").replace(\"}\", \"}}\")\n        return escaped_string",
  "def emit(self, level, format=None, **kwargs):\n        clean_format = self.escape_format_string(str(format))\n        super().emit(level=level, format=clean_format, **kwargs)",
  "class GasStrategyError(RuntimeError):\n    \"\"\"\n    Generic exception when retrieving a gas price using a gas strategy\n    \"\"\"",
  "def max_price_gas_strategy_wrapper(gas_strategy: Callable, max_gas_price_wei: int) -> Callable:\n    \"\"\"\n    Puts a cap on the prices resulting from a given gas strategy.\n    \"\"\"\n\n    def _wrapper(*args, **kwargs):\n        gas_price = gas_strategy(*args, **kwargs)\n        if gas_price > max_gas_price_wei:\n            gas_price = max_gas_price_wei\n        return gas_price\n\n    return _wrapper",
  "def construct_datafeed_median_strategy(speed: Optional[str] = None) -> Callable:\n    def datafeed_median_gas_price_strategy(web3: Web3, transaction_params: TxParams = None) -> Wei:\n        feeds = (UpvestGasPriceDatafeed, ZoltuGasPriceDatafeed)  # removed EtherchainGasPriceDatafeed due to EIP-1559\n\n        prices = []\n        for gas_price_feed_class in feeds:\n            try:\n                gas_strategy = gas_price_feed_class.construct_gas_strategy(speed=speed)\n                gas_price = gas_strategy(web3, transaction_params)\n            except Exception:\n                # some problem; onward and upward\n                continue\n            else:\n                prices.append(gas_price)\n\n        if prices:\n            median_price = statistics.median(prices)\n            return int(median_price)  # must return an int\n        else:  # Worst-case scenario, we get the price from the ETH node itself\n            return rpc_gas_price_strategy(web3, transaction_params)\n    return datafeed_median_gas_price_strategy",
  "def web3_gas_strategy_wrapper(web3_gas_strategy, speed):\n    \"\"\"\n    Enriches the web3 exceptions thrown by gas strategies\n    \"\"\"\n    def _wrapper(*args, **kwargs):\n        try:\n            return web3_gas_strategy(*args, **kwargs)\n        except ValidationError as e:\n            raise GasStrategyError(f\"Calling the '{speed}' web3 gas strategy failed. \"\n                                   f\"Verify your Ethereum provider connection and syncing status.\") from e\n\n    _wrapper.name = speed\n\n    return _wrapper",
  "def construct_fixed_price_gas_strategy(gas_price, denomination: str = \"wei\") -> Callable:\n    gas_price_in_wei = Web3.to_wei(gas_price, denomination)\n\n    def _fixed_price_strategy(web3: Web3, transaction_params: TxParams = None) -> Wei:\n        return gas_price_in_wei\n\n    _fixed_price_strategy.name = f\"{round(Web3.from_wei(gas_price_in_wei, 'gwei'))}gwei\"\n\n    return _fixed_price_strategy",
  "def _wrapper(*args, **kwargs):\n        gas_price = gas_strategy(*args, **kwargs)\n        if gas_price > max_gas_price_wei:\n            gas_price = max_gas_price_wei\n        return gas_price",
  "def datafeed_median_gas_price_strategy(web3: Web3, transaction_params: TxParams = None) -> Wei:\n        feeds = (UpvestGasPriceDatafeed, ZoltuGasPriceDatafeed)  # removed EtherchainGasPriceDatafeed due to EIP-1559\n\n        prices = []\n        for gas_price_feed_class in feeds:\n            try:\n                gas_strategy = gas_price_feed_class.construct_gas_strategy(speed=speed)\n                gas_price = gas_strategy(web3, transaction_params)\n            except Exception:\n                # some problem; onward and upward\n                continue\n            else:\n                prices.append(gas_price)\n\n        if prices:\n            median_price = statistics.median(prices)\n            return int(median_price)  # must return an int\n        else:  # Worst-case scenario, we get the price from the ETH node itself\n            return rpc_gas_price_strategy(web3, transaction_params)",
  "def _wrapper(*args, **kwargs):\n        try:\n            return web3_gas_strategy(*args, **kwargs)\n        except ValidationError as e:\n            raise GasStrategyError(f\"Calling the '{speed}' web3 gas strategy failed. \"\n                                   f\"Verify your Ethereum provider connection and syncing status.\") from e",
  "def _fixed_price_strategy(web3: Web3, transaction_params: TxParams = None) -> Wei:\n        return gas_price_in_wei",
  "def encode_constructor_arguments(web3: Web3,\n                                 constructor_function: ContractConstructor,\n                                 *constructor_args, **constructor_kwargs) -> HexStr:\n    \"\"\"\n    Takes a web3 constructor function and the arguments passed to it, and produces an encoding hex string\n    of the constructor arguments, following the standard ABI encoding conventions.\n    If there's no constructor, it returns None.\n    \"\"\"\n    constructor_abi = get_constructor_abi(constructor_function.abi)\n    if constructor_abi:\n        arguments = merge_args_and_kwargs(constructor_abi, constructor_args, constructor_kwargs)\n        data = encode_abi(web3, constructor_abi, arguments)\n    else:\n        data = None\n    return data",
  "def connect_web3_provider(eth_provider_uri: str) -> None:\n    \"\"\"\n    Convenience function for connecting to an ethereum provider now.\n    This may be used to optimize the startup time of some applications by\n    establishing the connection eagerly.\n    \"\"\"\n    from nucypher.blockchain.eth.interfaces import BlockchainInterfaceFactory\n\n    if not BlockchainInterfaceFactory.is_interface_initialized(eth_provider_uri=eth_provider_uri):\n        BlockchainInterfaceFactory.initialize_interface(eth_provider_uri=eth_provider_uri)\n    interface = BlockchainInterfaceFactory.get_interface(eth_provider_uri=eth_provider_uri)\n    interface.connect()",
  "def null_stream():\n    return open(os.devnull, 'w')",
  "class StdoutEmitter:\n\n    class MethodNotFound(BaseException):\n        \"\"\"Cannot find interface method to handle request\"\"\"\n\n    transport_serializer = str\n    default_color = 'white'\n\n    # sys.stdout.write() TODO: doesn't work well with click_runner's output capture\n    default_sink_callable = partial(print, flush=True)\n\n    def __init__(self,\n                 sink: Callable = None,\n                 verbosity: int = 1):\n\n        self.name = self.__class__.__name__.lower()\n        self.sink = sink or self.default_sink_callable\n        self.verbosity = verbosity\n        self.log = Logger(self.name)\n\n    def clear(self):\n        if self.verbosity >= 1:\n            click.clear()\n\n    def message(self,\n                message: str,\n                color: str = None,\n                bold: bool = False,\n                verbosity: int = 1):\n        self.echo(message, color=color or self.default_color, bold=bold, verbosity=verbosity)\n        self.log.debug(message)\n\n    def echo(self,\n             message: str = None,\n             color: str = None,\n             bold: bool = False,\n             nl: bool = True,\n             verbosity: int = 0):\n        if verbosity <= self.verbosity:\n            click.secho(message=message, fg=color or self.default_color, bold=bold, nl=nl)\n\n    def banner(self, banner):\n        if self.verbosity >= 1:\n            click.echo(banner)\n\n    def ipc(self, response: dict, request_id: int, duration):\n        # WARNING: Do not log in this block\n        if self.verbosity >= 1:\n            for k, v in response.items():\n                click.secho(message=f'{k} ...... {v}', fg=self.default_color)\n\n    def pretty(self, response):\n        if self.verbosity >= 1:\n            click.secho(\"-\" * 90, fg='cyan')\n            for k, v in response.items():\n                click.secho(k, bold=True)\n                click.secho(message=str(v), fg=self.default_color)\n                click.secho(\"-\"*90, fg='cyan')\n\n    def error(self, e):\n        if self.verbosity >= 1:\n            e_str = str(e)\n            click.echo(message=e_str, color=\"red\")\n            self.log.info(e_str)\n\n    def get_stream(self, verbosity: int = 0):\n        if verbosity <= self.verbosity:\n            return click.get_text_stream('stdout')\n        else:\n            return null_stream()",
  "class MethodNotFound(BaseException):\n        \"\"\"Cannot find interface method to handle request\"\"\"",
  "def __init__(self,\n                 sink: Callable = None,\n                 verbosity: int = 1):\n\n        self.name = self.__class__.__name__.lower()\n        self.sink = sink or self.default_sink_callable\n        self.verbosity = verbosity\n        self.log = Logger(self.name)",
  "def clear(self):\n        if self.verbosity >= 1:\n            click.clear()",
  "def message(self,\n                message: str,\n                color: str = None,\n                bold: bool = False,\n                verbosity: int = 1):\n        self.echo(message, color=color or self.default_color, bold=bold, verbosity=verbosity)\n        self.log.debug(message)",
  "def echo(self,\n             message: str = None,\n             color: str = None,\n             bold: bool = False,\n             nl: bool = True,\n             verbosity: int = 0):\n        if verbosity <= self.verbosity:\n            click.secho(message=message, fg=color or self.default_color, bold=bold, nl=nl)",
  "def banner(self, banner):\n        if self.verbosity >= 1:\n            click.echo(banner)",
  "def ipc(self, response: dict, request_id: int, duration):\n        # WARNING: Do not log in this block\n        if self.verbosity >= 1:\n            for k, v in response.items():\n                click.secho(message=f'{k} ...... {v}', fg=self.default_color)",
  "def pretty(self, response):\n        if self.verbosity >= 1:\n            click.secho(\"-\" * 90, fg='cyan')\n            for k, v in response.items():\n                click.secho(k, bold=True)\n                click.secho(message=str(v), fg=self.default_color)\n                click.secho(\"-\"*90, fg='cyan')",
  "def error(self, e):\n        if self.verbosity >= 1:\n            e_str = str(e)\n            click.echo(message=e_str, color=\"red\")\n            self.log.info(e_str)",
  "def get_stream(self, verbosity: int = 0):\n        if verbosity <= self.verbosity:\n            return click.get_text_stream('stdout')\n        else:\n            return null_stream()",
  "class PrometheusMetricsConfig:\n    \"\"\"Prometheus configuration.\"\"\"\n    def __init__(self,\n                 port: int,\n                 metrics_prefix: str,\n                 listen_address: str = '',  # default to localhost ip\n                 collection_interval: int = 90,  # every 1.5 minutes\n                 start_now: bool = False):\n\n        if not port:\n            raise ValueError('port must be provided')\n        if not metrics_prefix:\n            raise ValueError('metrics prefix must be provided')\n\n        self.port = port\n        self.metrics_prefix = metrics_prefix\n        self.listen_address = listen_address\n        self.collection_interval = collection_interval\n        self.start_now = start_now",
  "class MetricsEncoder(json.JSONEncoder):\n    def default(self, obj):\n        if isinstance(obj, Timestamp):\n            return obj.__float__()\n        return json.JSONEncoder.default(self, obj)",
  "class JSONMetricsResource(Resource):\n    \"\"\"\n    Twisted ``Resource`` that serves prometheus in JSON.\n    \"\"\"\n    isLeaf = True\n\n    def __init__(self, registry=REGISTRY):\n        super().__init__()\n        self.registry = registry\n\n    def render_GET(self, request):\n        request.setHeader(b'Content-Type', \"text/json\")\n        return self.generate_latest_json()\n\n    @staticmethod\n    def get_exemplar(sample, metric):\n        if not sample.exemplar:\n            return {}\n        elif metric.type not in ('histogram', 'gaugehistogram') or not sample.name.endswith('_bucket'):\n            raise ValueError(\n                \"Metric {} has exemplars, but is not a \"\n                \"histogram bucket\".format(metric.name)\n            )\n        return {\n            \"labels\": sample.exemplar.labels,\n            \"value\": floatToGoString(sample.exemplar.value),\n            \"timestamp\": sample.exemplar.timestamp\n        }\n\n    def get_sample(self, sample, metric):\n        return {\n            \"sample_name\": sample.name,\n            \"labels\": sample.labels,\n            \"value\": floatToGoString(sample.value),\n            \"timestamp\": sample.timestamp,\n            \"exemplar\": self.get_exemplar(sample, metric)\n        }\n\n    def get_metric(self, metric):\n        return {\n            \"samples\": [self.get_sample(sample, metric) for sample in metric.samples],\n            \"help\": metric.documentation,\n            \"type\": metric.type\n        }\n\n    def generate_latest_json(self):\n        \"\"\"\n        Returns the prometheus from the registry\n        in latest JSON format as a string.\n        \"\"\"\n        output = {}\n        for metric in self.registry.collect():\n            try:\n                output[metric.name] = self.get_metric(metric)\n            except Exception as exception:\n                exception.args = (exception.args or ('',)) + (metric,)\n                raise\n\n        json_dump = json.dumps(output, cls=MetricsEncoder).encode('utf-8')\n        return json_dump",
  "def collect_prometheus_metrics(metrics_collectors: List[MetricsCollector]) -> None:\n    for collector in metrics_collectors:\n        collector.collect()",
  "def start_prometheus_exporter(ursula: 'Ursula',\n                              prometheus_config: PrometheusMetricsConfig,\n                              registry: CollectorRegistry = REGISTRY) -> None:\n    \"\"\"Configure, collect, and serve prometheus metrics.\"\"\"\n    from prometheus_client.twisted import MetricsResource\n    from twisted.web.resource import Resource\n    from twisted.web.server import Site\n\n    metrics_collectors = create_metrics_collectors(ursula)\n    # initialize collectors\n    for collector in metrics_collectors:\n        collector.initialize(metrics_prefix=prometheus_config.metrics_prefix, registry=registry)\n\n    # TODO: was never used\n    # \"requests_counter\": Counter(f'{metrics_prefix}_http_failures', 'HTTP Failures', ['method', 'endpoint']),\n\n    # Scheduling\n    metrics_task = task.LoopingCall(collect_prometheus_metrics,\n                                    metrics_collectors=metrics_collectors)\n    metrics_task.start(interval=prometheus_config.collection_interval,\n                       now=prometheus_config.start_now)\n\n    # WSGI Service\n    root = Resource()\n    root.putChild(b'metrics', MetricsResource())\n    root.putChild(b'json_metrics', JSONMetricsResource())\n    factory = Site(root)\n    reactor.listenTCP(prometheus_config.port, factory, interface=prometheus_config.listen_address)",
  "def create_metrics_collectors(ursula: \"Ursula\") -> List[MetricsCollector]:\n    \"\"\"Create collectors used to obtain metrics.\"\"\"\n    collectors: List[MetricsCollector] = [UrsulaInfoMetricsCollector(ursula=ursula)]\n\n    if not ursula.federated_only:\n        # Blockchain prometheus\n        # TODO possible include information about payment\n        collectors.append(BlockchainMetricsCollector(eth_provider_uri=ursula.eth_provider_uri))\n\n        # Staking Provider prometheus\n        collectors.append(\n            StakingProviderMetricsCollector(\n                staking_provider_address=ursula.checksum_address,\n                contract_registry=ursula.registry,\n            )\n        )\n\n        # Operator prometheus\n        collectors.append(\n            OperatorMetricsCollector(\n                domain=ursula.domain,\n                operator_address=ursula.operator_address,\n                contract_registry=ursula.registry,\n            )\n        )\n\n    return collectors",
  "def __init__(self,\n                 port: int,\n                 metrics_prefix: str,\n                 listen_address: str = '',  # default to localhost ip\n                 collection_interval: int = 90,  # every 1.5 minutes\n                 start_now: bool = False):\n\n        if not port:\n            raise ValueError('port must be provided')\n        if not metrics_prefix:\n            raise ValueError('metrics prefix must be provided')\n\n        self.port = port\n        self.metrics_prefix = metrics_prefix\n        self.listen_address = listen_address\n        self.collection_interval = collection_interval\n        self.start_now = start_now",
  "def default(self, obj):\n        if isinstance(obj, Timestamp):\n            return obj.__float__()\n        return json.JSONEncoder.default(self, obj)",
  "def __init__(self, registry=REGISTRY):\n        super().__init__()\n        self.registry = registry",
  "def render_GET(self, request):\n        request.setHeader(b'Content-Type', \"text/json\")\n        return self.generate_latest_json()",
  "def get_exemplar(sample, metric):\n        if not sample.exemplar:\n            return {}\n        elif metric.type not in ('histogram', 'gaugehistogram') or not sample.name.endswith('_bucket'):\n            raise ValueError(\n                \"Metric {} has exemplars, but is not a \"\n                \"histogram bucket\".format(metric.name)\n            )\n        return {\n            \"labels\": sample.exemplar.labels,\n            \"value\": floatToGoString(sample.exemplar.value),\n            \"timestamp\": sample.exemplar.timestamp\n        }",
  "def get_sample(self, sample, metric):\n        return {\n            \"sample_name\": sample.name,\n            \"labels\": sample.labels,\n            \"value\": floatToGoString(sample.value),\n            \"timestamp\": sample.timestamp,\n            \"exemplar\": self.get_exemplar(sample, metric)\n        }",
  "def get_metric(self, metric):\n        return {\n            \"samples\": [self.get_sample(sample, metric) for sample in metric.samples],\n            \"help\": metric.documentation,\n            \"type\": metric.type\n        }",
  "def generate_latest_json(self):\n        \"\"\"\n        Returns the prometheus from the registry\n        in latest JSON format as a string.\n        \"\"\"\n        output = {}\n        for metric in self.registry.collect():\n            try:\n                output[metric.name] = self.get_metric(metric)\n            except Exception as exception:\n                exception.args = (exception.args or ('',)) + (metric,)\n                raise\n\n        json_dump = json.dumps(output, cls=MetricsEncoder).encode('utf-8')\n        return json_dump",
  "class MetricsCollector(ABC):\n    \"\"\"Metrics Collector Interface.\"\"\"\n    class CollectorError(Exception):\n        pass\n\n    class CollectorNotInitialized(Exception):\n        \"\"\"Raised when the Collector was not initialized before being used.\"\"\"\n\n    @abstractmethod\n    def initialize(self, metrics_prefix: str, registry: CollectorRegistry) -> None:\n        \"\"\"Initialize metrics collector.\"\"\"\n        return NotImplemented\n\n    @abstractmethod\n    def collect(self) -> None:\n        \"\"\"Collect relevant metrics.\"\"\"\n        return NotImplemented",
  "class BaseMetricsCollector(MetricsCollector):\n    \"\"\"\n    Base metrics collector that checks whether collector was initialized before used.\n\n    Subclasses should initialize the self.metrics member in their initialize() method since the\n    self.metrics member is used to determine whether initialize was called, and if not an exception is raised.\n    \"\"\"\n    def __init__(self):\n        self.metrics: Dict = None\n\n    def collect(self) -> None:\n        if self.metrics is None:\n            raise self.CollectorNotInitialized\n\n        self._collect_internal()\n\n    @abstractmethod\n    def _collect_internal(self):\n        \"\"\"\n        Called by collect() - subclasses should override this method instead of collect() to ensure that the\n        initialization check is always performed.\n        \"\"\"\n        # created so that the initialization check does not have to be specified by all subclasses of\n        # BaseMetricsCollector; instead it is performed automatically by collect()\n        return NotImplemented",
  "class UrsulaInfoMetricsCollector(BaseMetricsCollector):\n    \"\"\"Collector for Ursula specific metrics.\"\"\"\n    def __init__(self, ursula: 'Ursula'):\n        super().__init__()\n        self.ursula = ursula\n\n    def initialize(self, metrics_prefix: str, registry: CollectorRegistry) -> None:\n        self.metrics = {\n            \"host_info\": Info(\n                f\"{metrics_prefix}_host\", \"Ursula info\", registry=registry\n            ),\n            \"learning_status\": Enum(\n                f\"{metrics_prefix}_node_discovery\",\n                \"Learning loop status\",\n                states=[\"starting\", \"running\", \"stopped\"],\n                registry=registry,\n            ),\n            \"known_nodes_gauge\": Gauge(\n                f\"{metrics_prefix}_known_nodes\",\n                \"Number of currently known nodes\",\n                registry=registry,\n            ),\n            \"reencryption_requests_gauge\": Gauge(\n                f\"{metrics_prefix}_reencryption_requests\",\n                \"Number of accepted work orders\",\n                registry=registry,\n            ),\n        }\n\n    def _collect_internal(self) -> None:\n        # info\n        base_payload = {\n            \"app_version\": nucypher.__version__,\n            \"host\": str(self.ursula.rest_interface),\n            \"domain\": self.ursula.domain,\n            \"nickname\": str(self.ursula.nickname),\n            \"nickname_icon\": self.ursula.nickname.icon,\n        }\n\n        self.metrics[\"learning_status\"].state('running' if self.ursula._learning_task.running else 'stopped')\n        self.metrics[\"known_nodes_gauge\"].set(len(self.ursula.known_nodes))\n\n        if not self.ursula.federated_only:\n            decentralized_payload = {\n                \"staking_provider_address\": self.ursula.checksum_address,\n                \"operator_address\": self.ursula.operator_address,\n            }\n            base_payload.update(decentralized_payload)\n\n        self.metrics[\"host_info\"].info(base_payload)",
  "class BlockchainMetricsCollector(BaseMetricsCollector):\n    \"\"\"Collector for Blockchain specific metrics.\"\"\"\n    def __init__(self, eth_provider_uri: str):\n        super().__init__()\n        self.eth_provider_uri = eth_provider_uri\n\n    def initialize(self, metrics_prefix: str, registry: CollectorRegistry) -> None:\n        self.metrics = {\n            \"eth_chain_id\": Gauge(\n                f\"{metrics_prefix}_eth_chain_id\", \"Ethereum Chain ID\", registry=registry\n            ),\n            \"eth_current_block_number\": Gauge(\n                f\"{metrics_prefix}_eth_block_number\",\n                \"Current Ethereum block\",\n                registry=registry,\n            ),\n        }\n\n    def _collect_internal(self) -> None:\n        blockchain = BlockchainInterfaceFactory.get_or_create_interface(eth_provider_uri=self.eth_provider_uri)\n        self.metrics[\"eth_chain_id\"].set(blockchain.client.chain_id)\n        self.metrics[\"eth_current_block_number\"].set(blockchain.client.block_number)",
  "class StakingProviderMetricsCollector(BaseMetricsCollector):\n    \"\"\"Collector for Staking Provider associated metrics.\"\"\"\n\n    def __init__(\n        self,\n        staking_provider_address: ChecksumAddress,\n        contract_registry: BaseContractRegistry,\n    ):\n        super().__init__()\n        self.staking_provider_address = staking_provider_address\n        self.contract_registry = contract_registry\n\n    def initialize(self, metrics_prefix: str, registry: CollectorRegistry) -> None:\n        self.metrics = {\n            \"active_stake_gauge\": Gauge(\n                f\"{metrics_prefix}_associated_active_stake\",\n                \"Total amount of T staked (adapted NU/KEEP and liquid T)\",\n                registry=registry,\n            ),\n            \"operator_confirmed_gauge\": Gauge(\n                f\"{metrics_prefix}_operator_confirmed\",\n                \"Operator already confirmed\",\n                registry=registry,\n            ),\n            \"operator_start_gauge\": Gauge(\n                f\"{metrics_prefix}_operator_start_timestamp\",\n                \"Operator start timestamp\",\n                registry=registry,\n            ),\n        }\n\n    def _collect_internal(self) -> None:\n        application_agent = ContractAgency.get_agent(\n            PREApplicationAgent, registry=self.contract_registry\n        )\n        authorized = application_agent.get_authorized_stake(\n            staking_provider=self.staking_provider_address\n        )\n        self.metrics[\"active_stake_gauge\"].set(int(authorized))\n\n        staking_provider_info = application_agent.get_staking_provider_info(\n            staking_provider=self.staking_provider_address\n        )\n        self.metrics[\"operator_confirmed_gauge\"].set(\n            staking_provider_info.operator_confirmed\n        )\n        self.metrics[\"operator_start_gauge\"].set(\n            staking_provider_info.operator_start_timestamp\n        )",
  "class OperatorMetricsCollector(BaseMetricsCollector):\n    \"\"\"Collector for Operator specific metrics.\"\"\"\n    def __init__(self, domain: str, operator_address: ChecksumAddress, contract_registry: BaseContractRegistry):\n        super().__init__()\n        self.domain = domain\n        self.operator_address = operator_address\n        self.contract_registry = contract_registry\n\n    def initialize(self, metrics_prefix: str, registry: CollectorRegistry) -> None:\n        self.metrics = {\n            \"operator_eth_balance_gauge\": Gauge(\n                f\"{metrics_prefix}_operator_eth_balance\",\n                \"Operator Ethereum balance\",\n                registry=registry,\n            ),\n        }\n\n    def _collect_internal(self) -> None:\n        operator_token_actor = NucypherTokenActor(\n            registry=self.contract_registry,\n            domain=self.domain,\n            checksum_address=self.operator_address,\n        )\n        self.metrics[\"operator_eth_balance_gauge\"].set(\n            float(operator_token_actor.eth_balance)\n        )",
  "class EventMetricsCollector(BaseMetricsCollector):\n    \"\"\"General collector for emitted events.\"\"\"\n    def __init__(self,\n                 event_name: str,\n                 event_args_config: Dict[str, tuple],\n                 argument_filters: Dict[str, str],\n                 contract_agent_class: Type[EthereumContractAgent],\n                 contract_registry: BaseContractRegistry):\n        super().__init__()\n        self.event_name = event_name\n        self.contract_agent_class = contract_agent_class\n        self.contract_registry = contract_registry\n\n        contract_agent = ContractAgency.get_agent(self.contract_agent_class, registry=self.contract_registry)\n        # this way we don't have to deal with 'latest' at all\n        self.filter_current_from_block = contract_agent.blockchain.client.block_number\n        self.filter_arguments = argument_filters\n        self.event_args_config = event_args_config\n\n    def initialize(self, metrics_prefix: str, registry: CollectorRegistry) -> None:\n        self.metrics = dict()\n        for arg_name in self.event_args_config:\n            metric_class, metric_name, metric_doc = self.event_args_config[arg_name]\n            metric_key = self._get_arg_metric_key(arg_name)\n            self.metrics[metric_key] = metric_class(metric_name, metric_doc, registry=registry)\n\n    def _collect_internal(self) -> None:\n        contract_agent = ContractAgency.get_agent(self.contract_agent_class, registry=self.contract_registry)\n        from_block = self.filter_current_from_block\n        to_block = contract_agent.blockchain.client.block_number\n        if from_block >= to_block:\n            # we've already checked the latest block and waiting for a new block\n            # nothing to see here\n            return\n\n        # update last block checked for the next round - from/to block range is inclusive\n        # increment before potentially long running execution to improve concurrency handling\n        self.filter_current_from_block = to_block + 1\n\n        events_throttler = ContractEventsThrottler(agent=contract_agent,\n                                                   event_name=self.event_name,\n                                                   from_block=from_block,\n                                                   to_block=to_block,\n                                                   **self.filter_arguments)\n        for event_record in events_throttler:\n            self._event_occurred(event_record.raw_event)\n\n    def _event_occurred(self, event) -> None:\n        for arg_name in self.event_args_config:\n            metric_key = self._get_arg_metric_key(arg_name)\n            if arg_name == \"block_number\":\n                self.metrics[metric_key].set(event[\"blockNumber\"])\n                continue\n            self.metrics[metric_key].set(event['args'][arg_name])\n\n    def _get_arg_metric_key(self, arg_name: str):\n        return f'{self.event_name}_{arg_name}'",
  "class CollectorError(Exception):\n        pass",
  "class CollectorNotInitialized(Exception):\n        \"\"\"Raised when the Collector was not initialized before being used.\"\"\"",
  "def initialize(self, metrics_prefix: str, registry: CollectorRegistry) -> None:\n        \"\"\"Initialize metrics collector.\"\"\"\n        return NotImplemented",
  "def collect(self) -> None:\n        \"\"\"Collect relevant metrics.\"\"\"\n        return NotImplemented",
  "def __init__(self):\n        self.metrics: Dict = None",
  "def collect(self) -> None:\n        if self.metrics is None:\n            raise self.CollectorNotInitialized\n\n        self._collect_internal()",
  "def _collect_internal(self):\n        \"\"\"\n        Called by collect() - subclasses should override this method instead of collect() to ensure that the\n        initialization check is always performed.\n        \"\"\"\n        # created so that the initialization check does not have to be specified by all subclasses of\n        # BaseMetricsCollector; instead it is performed automatically by collect()\n        return NotImplemented",
  "def __init__(self, ursula: 'Ursula'):\n        super().__init__()\n        self.ursula = ursula",
  "def initialize(self, metrics_prefix: str, registry: CollectorRegistry) -> None:\n        self.metrics = {\n            \"host_info\": Info(\n                f\"{metrics_prefix}_host\", \"Ursula info\", registry=registry\n            ),\n            \"learning_status\": Enum(\n                f\"{metrics_prefix}_node_discovery\",\n                \"Learning loop status\",\n                states=[\"starting\", \"running\", \"stopped\"],\n                registry=registry,\n            ),\n            \"known_nodes_gauge\": Gauge(\n                f\"{metrics_prefix}_known_nodes\",\n                \"Number of currently known nodes\",\n                registry=registry,\n            ),\n            \"reencryption_requests_gauge\": Gauge(\n                f\"{metrics_prefix}_reencryption_requests\",\n                \"Number of accepted work orders\",\n                registry=registry,\n            ),\n        }",
  "def _collect_internal(self) -> None:\n        # info\n        base_payload = {\n            \"app_version\": nucypher.__version__,\n            \"host\": str(self.ursula.rest_interface),\n            \"domain\": self.ursula.domain,\n            \"nickname\": str(self.ursula.nickname),\n            \"nickname_icon\": self.ursula.nickname.icon,\n        }\n\n        self.metrics[\"learning_status\"].state('running' if self.ursula._learning_task.running else 'stopped')\n        self.metrics[\"known_nodes_gauge\"].set(len(self.ursula.known_nodes))\n\n        if not self.ursula.federated_only:\n            decentralized_payload = {\n                \"staking_provider_address\": self.ursula.checksum_address,\n                \"operator_address\": self.ursula.operator_address,\n            }\n            base_payload.update(decentralized_payload)\n\n        self.metrics[\"host_info\"].info(base_payload)",
  "def __init__(self, eth_provider_uri: str):\n        super().__init__()\n        self.eth_provider_uri = eth_provider_uri",
  "def initialize(self, metrics_prefix: str, registry: CollectorRegistry) -> None:\n        self.metrics = {\n            \"eth_chain_id\": Gauge(\n                f\"{metrics_prefix}_eth_chain_id\", \"Ethereum Chain ID\", registry=registry\n            ),\n            \"eth_current_block_number\": Gauge(\n                f\"{metrics_prefix}_eth_block_number\",\n                \"Current Ethereum block\",\n                registry=registry,\n            ),\n        }",
  "def _collect_internal(self) -> None:\n        blockchain = BlockchainInterfaceFactory.get_or_create_interface(eth_provider_uri=self.eth_provider_uri)\n        self.metrics[\"eth_chain_id\"].set(blockchain.client.chain_id)\n        self.metrics[\"eth_current_block_number\"].set(blockchain.client.block_number)",
  "def __init__(\n        self,\n        staking_provider_address: ChecksumAddress,\n        contract_registry: BaseContractRegistry,\n    ):\n        super().__init__()\n        self.staking_provider_address = staking_provider_address\n        self.contract_registry = contract_registry",
  "def initialize(self, metrics_prefix: str, registry: CollectorRegistry) -> None:\n        self.metrics = {\n            \"active_stake_gauge\": Gauge(\n                f\"{metrics_prefix}_associated_active_stake\",\n                \"Total amount of T staked (adapted NU/KEEP and liquid T)\",\n                registry=registry,\n            ),\n            \"operator_confirmed_gauge\": Gauge(\n                f\"{metrics_prefix}_operator_confirmed\",\n                \"Operator already confirmed\",\n                registry=registry,\n            ),\n            \"operator_start_gauge\": Gauge(\n                f\"{metrics_prefix}_operator_start_timestamp\",\n                \"Operator start timestamp\",\n                registry=registry,\n            ),\n        }",
  "def _collect_internal(self) -> None:\n        application_agent = ContractAgency.get_agent(\n            PREApplicationAgent, registry=self.contract_registry\n        )\n        authorized = application_agent.get_authorized_stake(\n            staking_provider=self.staking_provider_address\n        )\n        self.metrics[\"active_stake_gauge\"].set(int(authorized))\n\n        staking_provider_info = application_agent.get_staking_provider_info(\n            staking_provider=self.staking_provider_address\n        )\n        self.metrics[\"operator_confirmed_gauge\"].set(\n            staking_provider_info.operator_confirmed\n        )\n        self.metrics[\"operator_start_gauge\"].set(\n            staking_provider_info.operator_start_timestamp\n        )",
  "def __init__(self, domain: str, operator_address: ChecksumAddress, contract_registry: BaseContractRegistry):\n        super().__init__()\n        self.domain = domain\n        self.operator_address = operator_address\n        self.contract_registry = contract_registry",
  "def initialize(self, metrics_prefix: str, registry: CollectorRegistry) -> None:\n        self.metrics = {\n            \"operator_eth_balance_gauge\": Gauge(\n                f\"{metrics_prefix}_operator_eth_balance\",\n                \"Operator Ethereum balance\",\n                registry=registry,\n            ),\n        }",
  "def _collect_internal(self) -> None:\n        operator_token_actor = NucypherTokenActor(\n            registry=self.contract_registry,\n            domain=self.domain,\n            checksum_address=self.operator_address,\n        )\n        self.metrics[\"operator_eth_balance_gauge\"].set(\n            float(operator_token_actor.eth_balance)\n        )",
  "def __init__(self,\n                 event_name: str,\n                 event_args_config: Dict[str, tuple],\n                 argument_filters: Dict[str, str],\n                 contract_agent_class: Type[EthereumContractAgent],\n                 contract_registry: BaseContractRegistry):\n        super().__init__()\n        self.event_name = event_name\n        self.contract_agent_class = contract_agent_class\n        self.contract_registry = contract_registry\n\n        contract_agent = ContractAgency.get_agent(self.contract_agent_class, registry=self.contract_registry)\n        # this way we don't have to deal with 'latest' at all\n        self.filter_current_from_block = contract_agent.blockchain.client.block_number\n        self.filter_arguments = argument_filters\n        self.event_args_config = event_args_config",
  "def initialize(self, metrics_prefix: str, registry: CollectorRegistry) -> None:\n        self.metrics = dict()\n        for arg_name in self.event_args_config:\n            metric_class, metric_name, metric_doc = self.event_args_config[arg_name]\n            metric_key = self._get_arg_metric_key(arg_name)\n            self.metrics[metric_key] = metric_class(metric_name, metric_doc, registry=registry)",
  "def _collect_internal(self) -> None:\n        contract_agent = ContractAgency.get_agent(self.contract_agent_class, registry=self.contract_registry)\n        from_block = self.filter_current_from_block\n        to_block = contract_agent.blockchain.client.block_number\n        if from_block >= to_block:\n            # we've already checked the latest block and waiting for a new block\n            # nothing to see here\n            return\n\n        # update last block checked for the next round - from/to block range is inclusive\n        # increment before potentially long running execution to improve concurrency handling\n        self.filter_current_from_block = to_block + 1\n\n        events_throttler = ContractEventsThrottler(agent=contract_agent,\n                                                   event_name=self.event_name,\n                                                   from_block=from_block,\n                                                   to_block=to_block,\n                                                   **self.filter_arguments)\n        for event_record in events_throttler:\n            self._event_occurred(event_record.raw_event)",
  "def _event_occurred(self, event) -> None:\n        for arg_name in self.event_args_config:\n            metric_key = self._get_arg_metric_key(arg_name)\n            if arg_name == \"block_number\":\n                self.metrics[metric_key].set(event[\"blockNumber\"])\n                continue\n            self.metrics[metric_key].set(event['args'][arg_name])",
  "def _get_arg_metric_key(self, arg_name: str):\n        return f'{self.event_name}_{arg_name}'",
  "def cast_paths_from(cls, payload):\n    \"\"\"\n    A serialization helper.\n    Iterates over constructor arguments of `cls` and `cls` parents. Finds arguments\n    of type `pathlib.Path` or `Optional[pathlib.Path]`. Based on this, it casts\n    corresponding values in `payload` from `str` to `pathlib.Path` or None.\n    \"\"\"\n    constructor_args = get_type_hints(cls.__init__)\n    for ancestor in cls.__mro__:\n        constructor_args.update(get_type_hints(ancestor.__init__))\n    paths_only = [\n        arg for (arg, type_) in constructor_args.items()\n        if type_ == Path or type_ == Optional[Path]\n    ]\n    for key in paths_only:\n        if key in payload:\n            payload[key] = Path(payload[key]) if payload[key] else None\n    return payload",
  "class BaseConfiguration(ABC):\n    \"\"\"\n    Abstract base class for saving a JSON serializable version of the subclass's attributes\n    to the disk exported by `static_payload`, generating an optionally unique filename,\n    and restoring a subclass instance from the written JSON file by passing the deserialized\n    values to the subclass's constructor.\n\n    Implementation:\n\n    `NAME` and `def static_payload` are required for subclasses, for example:\n\n    .. code::\n\n        class MyItem(BaseConfiguration):\n            _NAME = 'my-item'\n\n    AND\n\n    .. code::\n\n        def static_payload(self) -> dict:\n            payload = dict(**super().static_payload(), key=value)\n            return payload\n\n    OR\n\n    .. code::\n\n        def static_payload(self) -> dict:\n            subclass_payload = {'key': 'value'}\n            payload = {**super().static_payload(), **subclass_payload}\n            return payload\n\n    Filepath Generation\n\n    Default behavior *avoids* overwriting an existing configuration file:\n\n    - The name of the JSON file to write/read from is determined by `NAME`.\n      When calling `to_configuration_file`.\n\n    - If the default path (i.e. `my-item.json`) already  exists and, optionally,\n      `override` is set to `False`, then a `modifer` is appended to the name (i.e. `my-item-<MODIFIER>.json`).\n\n    - If `modifier` is `None` and override is `False`, `FileExistsError` will be raised.\n\n    If the subclass implementation has a global unique identifier, an additional method override\n    to `to_configuration_file` will automate the renaming process.\n\n    .. code::\n\n        def to_configuration_file(*args, **kwargs) -> str:\n            filepath = super().to_configuration_file(modifier=<MODIFIER>, *args, **kwargs)\n            return filepath\n    \"\"\"\n\n    NAME = NotImplemented\n    _CONFIG_FILE_EXTENSION = 'json'\n\n    INDENTATION = 2\n    DEFAULT_CONFIG_ROOT = constants.DEFAULT_CONFIG_ROOT\n\n    VERSION = NotImplemented\n\n    class ConfigurationError(RuntimeError):\n        pass\n\n    class InvalidConfiguration(ConfigurationError):\n        pass\n\n    class NoConfigurationRoot(InvalidConfiguration):\n        pass\n\n    class OldVersion(InvalidConfiguration):\n        pass\n\n    def __init__(self,\n                 config_root: Optional[Path] = None,\n                 filepath: Optional[Path] = None,\n                 *args, **kwargs):\n\n        if self.NAME is NotImplemented:\n            error = f'NAME must be implemented on BaseConfiguration subclass {self.__class__.__name__}'\n            raise TypeError(error)\n\n        self.config_root = config_root or self.DEFAULT_CONFIG_ROOT\n        if not filepath:\n            filepath = self.config_root / self.generate_filename()\n        self.filepath = filepath\n\n        super().__init__()\n\n    @abstractmethod\n    def static_payload(self) -> dict:\n        \"\"\"\n        Return a dictionary of JSON serializable configuration key/value pairs\n        matching the input specification of this classes __init__.\n\n        Recommended subclass implementations:\n\n        ```\n        payload = dict(**super().static_payload(), key=value)\n        return payload\n        ```\n\n        OR\n\n        ```\n        subclass_payload = {'key': 'value'}\n        payload = {**super().static_payload(), **subclass_payload}\n        return payload\n        ```\n\n        \"\"\"\n        payload = dict(config_root=self.config_root)\n        return payload\n\n    @classmethod\n    def generate_filename(cls, modifier: str = None) -> str:\n        \"\"\"\n        Generates the configuration filename with an optional modification string.\n\n        :param modifier: String to modify default filename with.\n        :return: The generated filepath string.\n        \"\"\"\n        name = cls.NAME.lower()\n        if modifier:\n            name += f'-{modifier}'\n        filename = f'{name}.{cls._CONFIG_FILE_EXTENSION.lower()}'\n        return filename\n\n    @classmethod\n    def default_filepath(cls, config_root: Optional[Path] = None) -> Path:\n        \"\"\"\n        Generates the default configuration filepath for the class.\n\n        :return: The generated filepath string\n        \"\"\"\n        filename = cls.generate_filename()\n        default_path = (config_root or cls.DEFAULT_CONFIG_ROOT) / filename\n        return default_path\n\n    def generate_filepath(self, filepath: Optional[Path] = None, modifier: str = None, override: bool = False) -> Path:\n        \"\"\"\n        Generates a filepath for saving to writing to a configuration file.\n\n        Default behavior *avoids* overwriting an existing configuration file:\n\n        - The filepath exists and a filename `modifier` is not provided, then `FileExistsError` will be raised.\n        - The modified filepath exists, then `FileExistsError` will be raised.\n\n        To allow re-generation of an existing filepath, set `override` to True.\n\n        :param filepath: A custom filepath to use for configuration.\n        :param modifier: A unique string to modify the filename if the file already exists.\n        :param override: Allow generation of an existing filepath.\n        :return: The generated filepath.\n\n        \"\"\"\n        if not filepath:\n            filename = self.generate_filename()\n            filepath = self.config_root / filename\n        if filepath.exists() and not override:\n            if not modifier:\n                raise FileExistsError(f\"{filepath} exists and no filename modifier supplied.\")\n            filename = self.generate_filename(modifier=modifier)\n            filepath = self.config_root / filename\n        self.filepath = filepath\n        return filepath\n\n    def _ensure_config_root_exists(self) -> None:\n        \"\"\"\n        Before writing to a configuration file, ensures that\n        self.config_root exists on the filesystem.\n\n        :return: None.\n        \"\"\"\n        if not self.config_root.exists():\n            try:\n                self.config_root.mkdir(mode=0o755)\n            except FileNotFoundError:\n                self.config_root.mkdir(parents=True, mode=0o755)\n\n    @classmethod\n    def peek(cls, filepath: Path, field: str) -> Union[str, None]:\n        payload = cls._read_configuration_file(filepath=filepath)\n        try:\n            result = payload[field]\n        except KeyError:\n            raise cls.ConfigurationError(f\"Cannot peek; No such configuration field '{field}', options are {list(payload.keys())}\")\n        return result\n\n    def to_configuration_file(self, filepath: Optional[Path] = None, modifier: str = None, override: bool = False) -> Path:\n        filepath = self.generate_filepath(filepath=filepath, modifier=modifier, override=override)\n        self._ensure_config_root_exists()\n        filepath = self._write_configuration_file(filepath=filepath, override=override)\n        return filepath\n\n    @classmethod\n    def from_configuration_file(cls, filepath: Optional[Path] = None, **overrides) -> 'BaseConfiguration':\n        filepath = filepath or cls.default_filepath()\n        payload = cls._read_configuration_file(filepath=filepath)\n        instance = cls(filepath=filepath, **payload, **overrides)\n        return instance\n\n    @classmethod\n    def _read_configuration_file(cls, filepath: Path) -> dict:\n        \"\"\"Reads `filepath` and returns the deserialized JSON payload dict.\"\"\"\n        with open(filepath, 'r') as file:\n            raw_contents = file.read()\n            payload = cls.deserialize(raw_contents, payload_label=str(filepath))\n        return payload\n\n    def _write_configuration_file(self, filepath: Path, override: bool = False) -> Path:\n        \"\"\"Writes to `filepath` and returns the written filepath.  Raises `FileExistsError` if the file exists.\"\"\"\n        if filepath.exists() and not override:\n            raise FileExistsError(f\"{filepath} exists and no filename modifier supplied.\")\n        with open(filepath, 'w') as file:\n            file.write(self.serialize())\n        return filepath\n\n    def serialize(self, serializer=json.dumps) -> str:\n        \"\"\"Returns the JSON serialized output of `static_payload`\"\"\"\n        def _stringify_paths(d: dict):\n            for key, value in d.items():\n                if isinstance(value, Path):\n                    d[key] = str(value)\n                if isinstance(value, dict):\n                    _stringify_paths(value)\n\n        payload = self.static_payload()\n        _stringify_paths(payload)\n        payload['version'] = self.VERSION\n        serialized_payload = serializer(payload, indent=self.INDENTATION)\n        return serialized_payload\n\n    @classmethod\n    def deserialize(cls, payload: str, deserializer=json.loads, payload_label: Optional[str] = None) -> dict:\n        \"\"\"Returns the JSON deserialized content of `payload`\"\"\"\n        deserialized_payload = deserializer(payload)\n        version = deserialized_payload.pop('version', UNKNOWN_VERSION)\n        if version != cls.VERSION:\n            label = f\"'{payload_label}' \" if payload_label else \"\"\n            raise cls.OldVersion(f\"Configuration {label} is the wrong version \"\n                                 f\"Expected version {cls.VERSION}; Got version {version}\")\n\n        deserialized_payload = cast_paths_from(cls, deserialized_payload)\n        return deserialized_payload\n\n    def update(self, filepath: Optional[Path] = None, **updates) -> None:\n        for field, value in updates.items():\n            try:\n                getattr(self, field)\n            except AttributeError:\n                raise self.ConfigurationError(f\"Cannot update '{field}'. It is an invalid configuration field.\")\n            else:\n                setattr(self, field, value)\n        # just write the configuration file, file exists and we are overriding\n        self._write_configuration_file(filepath=filepath, override=True)",
  "class CharacterConfiguration(BaseConfiguration):\n    \"\"\"\n    'Sideways Engagement' of Character classes; a reflection of input parameters.\n    \"\"\"\n\n    VERSION = 4  # bump when static payload scheme changes\n\n    CHARACTER_CLASS = NotImplemented\n    MNEMONIC_KEYSTORE = False\n    DEFAULT_DOMAIN = NetworksInventory.DEFAULT\n    DEFAULT_NETWORK_MIDDLEWARE = RestMiddleware\n    TEMP_CONFIGURATION_DIR_PREFIX = 'tmp-nucypher'\n    SIGNER_ENVVAR = None\n\n    # When we begin to support other threshold schemes,\n    # this will be one of the concepts that makes us want a factory.  #571\n    known_node_class = Ursula\n\n    # Gas\n    DEFAULT_GAS_STRATEGY = 'fast'\n\n    # Payments\n    DEFAULT_PAYMENT_METHOD = 'SubscriptionManager'\n    DEFAULT_PAYMENT_NETWORK = 'polygon'\n    DEFAULT_FEDERATED_PAYMENT_METHOD = 'Free'\n\n    # Fields specified here are *not* passed into the Character's constructor\n    # and can be understood as configuration fields only.\n    _CONFIG_FIELDS = ('config_root',\n                      'poa',\n                      'light',\n                      'registry_filepath',\n                      'gas_strategy',\n                      'max_gas_price',  # gwei\n                      'signer_uri',\n                      'keystore_path',\n                      'payment_provider',\n                      'payment_network'\n                      )\n\n    def __init__(self,\n\n                 # Base\n                 emitter=None,\n                 config_root: Optional[Path] = None,\n                 filepath: Optional[Path] = None,\n\n                 # Mode\n                 dev_mode: bool = False,\n                 federated_only: bool = False,\n\n                 # Identity\n                 checksum_address: str = None,\n                 crypto_power: CryptoPower = None,\n\n                 # Keystore\n                 keystore: Keystore = None,\n                 keystore_path: Optional[Path] = None,\n\n                 # Learner\n                 learn_on_same_thread: bool = False,\n                 abort_on_learning_error: bool = False,\n                 start_learning_now: bool = True,\n\n                 # Network\n                 domain: str = DEFAULT_DOMAIN,\n                 network_middleware: RestMiddleware = None,\n                 lonely: bool = False,\n\n                 # Node Storage\n                 known_nodes: set = None,\n                 node_storage: NodeStorage = None,\n                 reload_metadata: bool = True,\n                 save_metadata: bool = True,\n\n                 # Blockchain\n                 poa: bool = None,\n                 light: bool = False,\n                 eth_provider_uri: str = None,\n                 gas_strategy: Union[Callable, str] = DEFAULT_GAS_STRATEGY,\n                 max_gas_price: Optional[int] = None,\n                 signer_uri: str = None,\n\n                 # Payments\n                 # TODO: Resolve code prefixing below, possibly with the use of nested configuration fields\n                 payment_method: str = None,\n                 payment_provider: str = None,\n                 payment_network: str = None,\n\n                 # Registries\n                 registry: BaseContractRegistry = None,\n                 registry_filepath: Optional[Path] = None,\n                 policy_registry: BaseContractRegistry = None,\n                 policy_registry_filepath: Optional[Path] = None,\n\n                 # Deployed Operators\n                 worker_data: dict = None\n                 ):\n\n        self.log = Logger(self.__class__.__name__)\n\n        # This constant is used to signal that a path can be generated if one is not provided.\n        UNINITIALIZED_CONFIGURATION.bool_value(False)\n\n        # Identity\n        # NOTE: NodeConfigurations can only be used with Self-Characters\n        self.is_me = True\n        self.checksum_address = checksum_address\n\n        # Keystore\n        self.crypto_power = crypto_power\n        if keystore_path and not keystore:\n            keystore = Keystore(keystore_path=keystore_path)\n        self.__keystore = self.__keystore = keystore or NO_KEYSTORE_ATTACHED.bool_value(False)\n        self.keystore_dir = Path(keystore.keystore_path).parent if keystore else UNINITIALIZED_CONFIGURATION\n\n        # Contract Registry\n        if registry and registry_filepath:\n            if registry.filepath != registry_filepath:\n                error = f\"Inconsistent registry filepaths for '{registry.filepath.absolute()}'\" \\\n                        f\" and '{registry_filepath.absolute()}'.\"\n                raise ValueError(error)\n            else:\n                self.log.warn(f\"Registry and registry filepath were both passed.\")\n        self.registry = registry or NO_BLOCKCHAIN_CONNECTION.bool_value(False)\n        self.registry_filepath = registry_filepath or UNINITIALIZED_CONFIGURATION\n\n        self.policy_registry = policy_registry or NO_BLOCKCHAIN_CONNECTION.bool_value(False)\n        self.policy_registry_filepath = policy_registry_filepath or UNINITIALIZED_CONFIGURATION\n\n        # Blockchain\n        self.poa = poa\n        self.is_light = light\n        self.eth_provider_uri = eth_provider_uri or NO_BLOCKCHAIN_CONNECTION\n        self.signer_uri = signer_uri or None\n\n        # Learner\n        self.federated_only = federated_only\n        self.domain = domain\n        self.learn_on_same_thread = learn_on_same_thread\n        self.abort_on_learning_error = abort_on_learning_error\n        self.start_learning_now = start_learning_now\n        self.save_metadata = save_metadata\n        self.reload_metadata = reload_metadata\n        self.known_nodes = known_nodes or set()  # handpicked\n        self.lonely = lonely\n\n        # Configuration\n        self.__dev_mode = dev_mode\n        self.config_file_location = filepath or UNINITIALIZED_CONFIGURATION\n        self.config_root = UNINITIALIZED_CONFIGURATION\n\n        # Deployed Operators\n        self.worker_data = worker_data\n\n        #\n        # Federated vs. Blockchain arguments consistency\n        #\n\n        #\n        # Federated\n        #\n\n        if self.federated_only:\n            # Check for incompatible values\n            blockchain_args = {'filepath': registry_filepath,\n                               'poa': poa,\n                               'eth_provider_uri': eth_provider_uri,\n                               'payment_provider': payment_provider,\n                               'gas_strategy': gas_strategy,\n                               'max_gas_price': max_gas_price}\n            if any(blockchain_args.values()):\n                bad_args = \", \".join(f\"{arg}={val}\" for arg, val in blockchain_args.items() if val)\n                self.log.warn(f\"Arguments {bad_args} are incompatible with federated_only. \"\n                              f\"Overridden with a sane default.\")\n\n                # Clear decentralized attributes to ensure consistency with a\n                # federated configuration.\n                self.poa = False\n                self.is_light = False\n                self.eth_provider_uri = None\n                self.registry_filepath = None\n                self.policy_registry_filepath = None\n                self.gas_strategy = None\n                self.max_gas_price = None\n\n            # Federated Payments\n            self.payment_method = payment_method or self.DEFAULT_FEDERATED_PAYMENT_METHOD\n            self.payment_network = payment_network\n            self.payment_provider = payment_provider\n\n        #\n        # Decentralized\n        #\n\n        else:\n            self.gas_strategy = gas_strategy\n            self.max_gas_price = max_gas_price  # gwei\n            is_initialized = BlockchainInterfaceFactory.is_interface_initialized(eth_provider_uri=self.eth_provider_uri)\n            if not is_initialized and eth_provider_uri:\n                BlockchainInterfaceFactory.initialize_interface(eth_provider_uri=self.eth_provider_uri,\n                                                                poa=self.poa,\n                                                                light=self.is_light,\n                                                                emitter=emitter,\n                                                                gas_strategy=self.gas_strategy,\n                                                                max_gas_price=self.max_gas_price)\n            else:\n                self.log.warn(f\"Using existing blockchain interface connection ({self.eth_provider_uri}).\")\n\n            if not self.registry:\n                # TODO: These two code blocks are untested.\n                if not self.registry_filepath:  # TODO: Registry URI  (goerli://speedynet.json) :-)\n                    self.log.info(f\"Fetching latest registry from source.\")\n                    self.registry = InMemoryContractRegistry.from_latest_publication(network=self.domain)\n                else:\n                    self.registry = LocalContractRegistry(filepath=self.registry_filepath)\n                    self.log.info(f\"Using local registry ({self.registry}).\")\n\n            self.testnet = self.domain != NetworksInventory.MAINNET\n            self.signer = Signer.from_signer_uri(self.signer_uri, testnet=self.testnet)\n\n            #\n            # Onchain Payments & Policies\n            #\n\n            # FIXME: Enforce this for Ursula/Alice but not Bob?\n            from nucypher.config.characters import BobConfiguration\n            if not isinstance(self, BobConfiguration):\n                # if not payment_provider:\n                #     raise self.ConfigurationError(\"payment provider is required.\")\n                self.payment_method = payment_method or self.DEFAULT_PAYMENT_METHOD\n                self.payment_network = payment_network or self.DEFAULT_PAYMENT_NETWORK\n                self.payment_provider = payment_provider or (self.eth_provider_uri or None)  # default to L1 payments\n\n                # TODO: Dedupe\n                if not self.policy_registry:\n                    if not self.policy_registry_filepath:\n                        self.log.info(f\"Fetching latest policy registry from source.\")\n                        self.policy_registry = InMemoryContractRegistry.from_latest_publication(network=self.payment_network)\n                    else:\n                        self.policy_registry = LocalContractRegistry(filepath=self.policy_registry_filepath)\n                        self.log.info(f\"Using local policy registry ({self.policy_registry}).\")\n\n        if dev_mode:\n            self.__temp_dir = UNINITIALIZED_CONFIGURATION\n            self._setup_node_storage()\n            self.initialize(password=DEVELOPMENT_CONFIGURATION)\n        else:\n            self.__temp_dir = LIVE_CONFIGURATION\n            self.config_root = config_root or self.DEFAULT_CONFIG_ROOT\n            self._cache_runtime_filepaths()\n            self._setup_node_storage(node_storage=node_storage)\n\n        # Network\n        self.network_middleware = network_middleware or self.DEFAULT_NETWORK_MIDDLEWARE(registry=self.registry)\n        \n        super().__init__(filepath=self.config_file_location, config_root=self.config_root)\n\n    def __call__(self, **character_kwargs):\n        return self.produce(**character_kwargs)\n\n    @property\n    def keystore(self) -> Keystore:\n        return self.__keystore\n\n    def attach_keystore(self, keystore: Keystore) -> None:\n        self.__keystore = keystore\n\n    @classmethod\n    def checksum_address_from_filepath(cls, filepath: Path) -> str:\n        pattern = re.compile(r'''\n                             (^\\w+)-\n                             (0x{1}           # Then, 0x the start of the string, exactly once\n                             [0-9a-fA-F]{40}) # Followed by exactly 40 hex chars\n                             ''',\n                             re.VERBOSE)\n\n        filename = filepath.name\n        match = pattern.match(filename)\n\n        if match:\n            character_name, checksum_address = match.groups()\n        else:\n            # Extract from default by \"peeking\" inside the configuration file.\n            default_name = cls.generate_filename()\n            if filename == default_name:\n                checksum_address = cls.peek(filepath=filepath, field='checksum_address')\n            else:\n                raise ValueError(f\"Cannot extract checksum from filepath '{filepath}'\")\n\n        if not is_checksum_address(checksum_address):\n            raise RuntimeError(f\"Invalid checksum address detected in configuration file at '{filepath}'.\")\n        return checksum_address\n\n    def update(self, **kwargs) -> None:\n        \"\"\"\n        A facility for updating existing attributes on existing configuration instances.\n\n        Warning: This method allows mutation and may result in an inconsistent configuration.\n        \"\"\"\n        # config file should exist and we we override -> no need for modifier\n        return super().update(filepath=self.config_file_location, **kwargs)\n\n    @classmethod\n    def generate(cls, password: str, key_material: Optional[bytes] = None, *args, **kwargs):\n        \"\"\"Shortcut: Hook-up a new initial installation and configuration.\"\"\"\n        node_config = cls(dev_mode=False, *args, **kwargs)\n        node_config.initialize(key_material=key_material, password=password)\n        return node_config\n\n    def cleanup(self) -> None:\n        if self.__dev_mode:\n            self.__temp_dir.cleanup()\n\n    @property\n    def dev_mode(self) -> bool:\n        return self.__dev_mode\n\n    def _setup_node_storage(self, node_storage=None) -> None:\n        # TODO: Disables node metadata persistence..\n        # if self.dev_mode:\n        #     node_storage = ForgetfulNodeStorage(registry=self.registry, federated_only=self.federated_only)\n\n        # TODO: Forcibly clears the filesystem of any stored node metadata and certificates...\n        local_node_storage = LocalFileBasedNodeStorage(\n            registry=self.registry,\n            config_root=self.config_root,\n            federated_only=self.federated_only\n        )\n        local_node_storage.clear()\n        self.log.info(f'Cleared peer metadata from {local_node_storage.root_dir}')\n\n        # TODO: Always sets up nodes for in-memory node metadata storage\n        node_storage = ForgetfulNodeStorage(registry=self.registry, federated_only=self.federated_only)\n        self.node_storage = node_storage\n\n    def forget_nodes(self) -> None:\n        self.node_storage.clear()\n        message = \"Removed all stored node node metadata and certificates\"\n        self.log.debug(message)\n\n    def destroy(self) -> None:\n        \"\"\"Parse a node configuration and remove all associated files from the filesystem\"\"\"\n        self.config_file_location.unlink()\n\n    def generate_parameters(self, **overrides) -> dict:\n        \"\"\"\n        Warning: This method allows mutation and may result in an inconsistent configuration.\n        \"\"\"\n        merged_parameters = {**self.static_payload(), **self.dynamic_payload, **overrides}\n        character_init_params = filter(lambda t: t[0] not in self._CONFIG_FIELDS, merged_parameters.items())\n        return dict(character_init_params)\n\n    def produce(self, **overrides) -> CHARACTER_CLASS:\n        \"\"\"Initialize a new character instance and return it.\"\"\"\n        merged_parameters = self.generate_parameters(**overrides)\n        character = self.CHARACTER_CLASS(**merged_parameters)\n        return character\n\n    @classmethod\n    def assemble(cls, filepath: Optional[Path] = None, **overrides) -> dict:\n        \"\"\"\n        Warning: This method allows mutation and may result in an inconsistent configuration.\n        \"\"\"\n        payload = cls._read_configuration_file(filepath=filepath)\n        node_storage = cls.load_node_storage(storage_payload=payload['node_storage'],\n                                             federated_only=payload['federated_only'])\n        max_gas_price = payload.get('max_gas_price')  # gwei\n        if max_gas_price:\n            max_gas_price = Decimal(max_gas_price)\n\n        # Assemble\n        payload.update(dict(node_storage=node_storage, max_gas_price=max_gas_price))\n        payload = cast_paths_from(cls, payload)\n\n        # Filter out None values from **overrides to detect, well, overrides...\n        # Acts as a shim for optional CLI flags.\n        overrides = {k: v for k, v in overrides.items() if v is not None}\n        payload = {**payload, **overrides}\n        return payload\n\n    @classmethod\n    def from_configuration_file(cls,\n                                filepath: Optional[Path] = None,\n                                **overrides  # < ---- Inlet for CLI Flags\n                                ) -> 'CharacterConfiguration':\n        \"\"\"Initialize a CharacterConfiguration from a JSON file.\"\"\"\n        filepath = filepath or cls.default_filepath()\n        assembled_params = cls.assemble(filepath=filepath, **overrides)\n        node_configuration = cls(filepath=filepath, **assembled_params)\n        return node_configuration\n\n    def validate(self) -> bool:\n\n        # Top-level\n        if not self.config_root.exists():\n            raise self.ConfigurationError(f'No configuration directory found at {self.config_root}.')\n\n        # Sub-paths\n        filepaths = self.runtime_filepaths\n        for field, path in filepaths.items():\n            if path and not path.exists():\n                message = 'Missing configuration file or directory: {}.'\n                if 'registry' in path:\n                    message += ' Did you mean to pass --federated-only?'\n                raise CharacterConfiguration.InvalidConfiguration(message.format(path))\n        return True\n\n    def static_payload(self) -> dict:\n        \"\"\"JSON-Exported static configuration values for initializing Ursula\"\"\"\n        keystore_path = str(self.keystore.keystore_path) if self.keystore else None\n        payload = dict(\n\n            # Identity\n            federated_only=self.federated_only,\n            checksum_address=self.checksum_address,\n            keystore_path=keystore_path,\n\n            # Behavior\n            domain=self.domain,\n            learn_on_same_thread=self.learn_on_same_thread,\n            abort_on_learning_error=self.abort_on_learning_error,\n            start_learning_now=self.start_learning_now,\n            save_metadata=self.save_metadata,\n            node_storage=self.node_storage.payload(),\n            lonely=self.lonely,\n        )\n\n        # Optional values (mode)\n        if not self.federated_only:\n            if self.eth_provider_uri:\n                if not self.signer_uri:\n                    self.signer_uri = self.eth_provider_uri\n                payload.update(dict(eth_provider_uri=self.eth_provider_uri,\n                                    poa=self.poa,\n                                    light=self.is_light,\n                                    signer_uri=self.signer_uri))\n            if self.registry_filepath:\n                payload.update(dict(registry_filepath=self.registry_filepath))\n\n            # Gas Price\n            __max_price = str(self.max_gas_price) if self.max_gas_price else None\n            payload.update(dict(gas_strategy=self.gas_strategy, max_gas_price=__max_price))\n\n        # Merge with base payload\n        base_payload = super().static_payload()\n        base_payload.update(payload)\n\n        return payload\n\n    @property\n    def dynamic_payload(self) -> dict:\n        \"\"\"\n        Exported dynamic configuration values for initializing Ursula.\n        These values are used to init a character instance but are *not*\n        saved to the JSON configuration.\n        \"\"\"\n        payload = dict()\n        if not self.federated_only:\n            payload.update(dict(registry=self.registry, signer=self.signer))\n\n        payload.update(dict(network_middleware=self.network_middleware or self.DEFAULT_NETWORK_MIDDLEWARE(),\n                            known_nodes=self.known_nodes,\n                            node_storage=self.node_storage,\n                            keystore=self.keystore,\n                            crypto_power_ups=self.derive_node_power_ups()))\n\n        return payload\n\n    def generate_filepath(self, filepath: Optional[Path] = None, modifier: str = None, override: bool = False) -> Path:\n        modifier = modifier or self.checksum_address\n        filepath = super().generate_filepath(filepath=filepath, modifier=modifier, override=override)\n        return filepath\n\n    @property\n    def runtime_filepaths(self) -> dict:\n        filepaths = dict(config_root=self.config_root,\n                         keystore_dir=self.keystore_dir,\n                         registry_filepath=self.registry_filepath)\n        return filepaths\n\n    @classmethod\n    def generate_runtime_filepaths(cls, config_root: Path) -> dict:\n        \"\"\"Dynamically generate paths based on configuration root directory\"\"\"\n        filepaths = dict(config_root=config_root,\n                         config_file_location=config_root / cls.generate_filename(),\n                         keystore_dir=config_root / 'keystore')\n        return filepaths\n\n    def _cache_runtime_filepaths(self) -> None:\n        \"\"\"Generate runtime filepaths and cache them on the config object\"\"\"\n        filepaths = self.generate_runtime_filepaths(config_root=self.config_root)\n        for field, filepath in filepaths.items():\n            if getattr(self, field) is UNINITIALIZED_CONFIGURATION:\n                setattr(self, field, filepath)\n\n    def derive_node_power_ups(self) -> List[CryptoPowerUp]:\n        power_ups = list()\n        if self.is_me and not self.dev_mode:\n            for power_class in self.CHARACTER_CLASS._default_crypto_powerups:\n                power_up = self.keystore.derive_crypto_power(power_class)\n                power_ups.append(power_up)\n        return power_ups\n\n    def initialize(self, password: str, key_material: Optional[bytes] = None) -> str:\n        \"\"\"Initialize a new configuration and write installation files to disk.\"\"\"\n\n        # Development\n        if self.dev_mode:\n            self.__temp_dir = TemporaryDirectory(prefix=self.TEMP_CONFIGURATION_DIR_PREFIX)\n            self.config_root = Path(self.__temp_dir.name)\n\n        # Persistent\n        else:\n            self._ensure_config_root_exists()\n            self.write_keystore(key_material=key_material,\n                                password=password,\n                                interactive=self.MNEMONIC_KEYSTORE)\n\n        self._cache_runtime_filepaths()\n        self.node_storage.initialize()\n\n        # Validate\n        if not self.__dev_mode:\n            self.validate()\n\n        # Success\n        message = \"Created nucypher installation files at {}\".format(self.config_root)\n        self.log.debug(message)\n        return Path(self.config_root)\n\n    def write_keystore(self, password: str, key_material: Optional[bytes] = None, interactive: bool = True) -> Keystore:\n        if key_material:\n            self.__keystore = Keystore.import_secure(key_material=key_material,\n                                                     password=password,\n                                                     keystore_dir=self.keystore_dir)\n        else:\n            if interactive:\n                self.__keystore = Keystore.generate(password=password,\n                                                    keystore_dir=self.keystore_dir,\n                                                    interactive=interactive)\n            else:\n                self.__keystore, _ = Keystore.generate(password=password,\n                                                       keystore_dir=self.keystore_dir,\n                                                       interactive=interactive)\n\n        return self.keystore\n\n    @classmethod\n    def load_node_storage(cls, storage_payload: dict, federated_only: bool):\n        from nucypher.config.storages import NodeStorage\n        node_storage_subclasses = {storage._name: storage for storage in NodeStorage.__subclasses__()}\n        storage_type = storage_payload[NodeStorage._TYPE_LABEL]\n        storage_class = node_storage_subclasses[storage_type]\n        node_storage = storage_class.from_payload(payload=storage_payload, federated_only=federated_only)\n        return node_storage\n\n    def configure_payment_method(self):\n        # TODO: finalize config fields\n        # Strategy-Based (current implementation, inflexible & hardcoded)\n        # 'payment_strategy': 'SubscriptionManager'\n        # 'payment_network': 'matic'\n        # 'payment_provider': 'https:///matic.infura.io....'\n        # Contract-Targeted (alternative implementation, flexible & generic)\n        # 'payment': {\n        #     'contract': '0xdeadbeef'\n        #     'abi': '/home/abi/sm.json'\n        #     'function': 'isPolicyActive'\n        #     'provider': 'https:///matic.infura.io....'\n        # }\n\n        try:\n            payment_class = PAYMENT_METHODS[self.payment_method]\n        except KeyError:\n            raise KeyError(f'Unknown payment verifier \"{self.payment_method}\"')\n\n        if payment_class.ONCHAIN:\n            # on-chain payment strategies require a blockchain connection\n            payment_strategy = payment_class(network=self.payment_network,\n                                             eth_provider=self.payment_provider,\n                                             registry=self.policy_registry)\n        else:\n            payment_strategy = payment_class()\n        return payment_strategy",
  "class ConfigurationError(RuntimeError):\n        pass",
  "class InvalidConfiguration(ConfigurationError):\n        pass",
  "class NoConfigurationRoot(InvalidConfiguration):\n        pass",
  "class OldVersion(InvalidConfiguration):\n        pass",
  "def __init__(self,\n                 config_root: Optional[Path] = None,\n                 filepath: Optional[Path] = None,\n                 *args, **kwargs):\n\n        if self.NAME is NotImplemented:\n            error = f'NAME must be implemented on BaseConfiguration subclass {self.__class__.__name__}'\n            raise TypeError(error)\n\n        self.config_root = config_root or self.DEFAULT_CONFIG_ROOT\n        if not filepath:\n            filepath = self.config_root / self.generate_filename()\n        self.filepath = filepath\n\n        super().__init__()",
  "def static_payload(self) -> dict:\n        \"\"\"\n        Return a dictionary of JSON serializable configuration key/value pairs\n        matching the input specification of this classes __init__.\n\n        Recommended subclass implementations:\n\n        ```\n        payload = dict(**super().static_payload(), key=value)\n        return payload\n        ```\n\n        OR\n\n        ```\n        subclass_payload = {'key': 'value'}\n        payload = {**super().static_payload(), **subclass_payload}\n        return payload\n        ```\n\n        \"\"\"\n        payload = dict(config_root=self.config_root)\n        return payload",
  "def generate_filename(cls, modifier: str = None) -> str:\n        \"\"\"\n        Generates the configuration filename with an optional modification string.\n\n        :param modifier: String to modify default filename with.\n        :return: The generated filepath string.\n        \"\"\"\n        name = cls.NAME.lower()\n        if modifier:\n            name += f'-{modifier}'\n        filename = f'{name}.{cls._CONFIG_FILE_EXTENSION.lower()}'\n        return filename",
  "def default_filepath(cls, config_root: Optional[Path] = None) -> Path:\n        \"\"\"\n        Generates the default configuration filepath for the class.\n\n        :return: The generated filepath string\n        \"\"\"\n        filename = cls.generate_filename()\n        default_path = (config_root or cls.DEFAULT_CONFIG_ROOT) / filename\n        return default_path",
  "def generate_filepath(self, filepath: Optional[Path] = None, modifier: str = None, override: bool = False) -> Path:\n        \"\"\"\n        Generates a filepath for saving to writing to a configuration file.\n\n        Default behavior *avoids* overwriting an existing configuration file:\n\n        - The filepath exists and a filename `modifier` is not provided, then `FileExistsError` will be raised.\n        - The modified filepath exists, then `FileExistsError` will be raised.\n\n        To allow re-generation of an existing filepath, set `override` to True.\n\n        :param filepath: A custom filepath to use for configuration.\n        :param modifier: A unique string to modify the filename if the file already exists.\n        :param override: Allow generation of an existing filepath.\n        :return: The generated filepath.\n\n        \"\"\"\n        if not filepath:\n            filename = self.generate_filename()\n            filepath = self.config_root / filename\n        if filepath.exists() and not override:\n            if not modifier:\n                raise FileExistsError(f\"{filepath} exists and no filename modifier supplied.\")\n            filename = self.generate_filename(modifier=modifier)\n            filepath = self.config_root / filename\n        self.filepath = filepath\n        return filepath",
  "def _ensure_config_root_exists(self) -> None:\n        \"\"\"\n        Before writing to a configuration file, ensures that\n        self.config_root exists on the filesystem.\n\n        :return: None.\n        \"\"\"\n        if not self.config_root.exists():\n            try:\n                self.config_root.mkdir(mode=0o755)\n            except FileNotFoundError:\n                self.config_root.mkdir(parents=True, mode=0o755)",
  "def peek(cls, filepath: Path, field: str) -> Union[str, None]:\n        payload = cls._read_configuration_file(filepath=filepath)\n        try:\n            result = payload[field]\n        except KeyError:\n            raise cls.ConfigurationError(f\"Cannot peek; No such configuration field '{field}', options are {list(payload.keys())}\")\n        return result",
  "def to_configuration_file(self, filepath: Optional[Path] = None, modifier: str = None, override: bool = False) -> Path:\n        filepath = self.generate_filepath(filepath=filepath, modifier=modifier, override=override)\n        self._ensure_config_root_exists()\n        filepath = self._write_configuration_file(filepath=filepath, override=override)\n        return filepath",
  "def from_configuration_file(cls, filepath: Optional[Path] = None, **overrides) -> 'BaseConfiguration':\n        filepath = filepath or cls.default_filepath()\n        payload = cls._read_configuration_file(filepath=filepath)\n        instance = cls(filepath=filepath, **payload, **overrides)\n        return instance",
  "def _read_configuration_file(cls, filepath: Path) -> dict:\n        \"\"\"Reads `filepath` and returns the deserialized JSON payload dict.\"\"\"\n        with open(filepath, 'r') as file:\n            raw_contents = file.read()\n            payload = cls.deserialize(raw_contents, payload_label=str(filepath))\n        return payload",
  "def _write_configuration_file(self, filepath: Path, override: bool = False) -> Path:\n        \"\"\"Writes to `filepath` and returns the written filepath.  Raises `FileExistsError` if the file exists.\"\"\"\n        if filepath.exists() and not override:\n            raise FileExistsError(f\"{filepath} exists and no filename modifier supplied.\")\n        with open(filepath, 'w') as file:\n            file.write(self.serialize())\n        return filepath",
  "def serialize(self, serializer=json.dumps) -> str:\n        \"\"\"Returns the JSON serialized output of `static_payload`\"\"\"\n        def _stringify_paths(d: dict):\n            for key, value in d.items():\n                if isinstance(value, Path):\n                    d[key] = str(value)\n                if isinstance(value, dict):\n                    _stringify_paths(value)\n\n        payload = self.static_payload()\n        _stringify_paths(payload)\n        payload['version'] = self.VERSION\n        serialized_payload = serializer(payload, indent=self.INDENTATION)\n        return serialized_payload",
  "def deserialize(cls, payload: str, deserializer=json.loads, payload_label: Optional[str] = None) -> dict:\n        \"\"\"Returns the JSON deserialized content of `payload`\"\"\"\n        deserialized_payload = deserializer(payload)\n        version = deserialized_payload.pop('version', UNKNOWN_VERSION)\n        if version != cls.VERSION:\n            label = f\"'{payload_label}' \" if payload_label else \"\"\n            raise cls.OldVersion(f\"Configuration {label} is the wrong version \"\n                                 f\"Expected version {cls.VERSION}; Got version {version}\")\n\n        deserialized_payload = cast_paths_from(cls, deserialized_payload)\n        return deserialized_payload",
  "def update(self, filepath: Optional[Path] = None, **updates) -> None:\n        for field, value in updates.items():\n            try:\n                getattr(self, field)\n            except AttributeError:\n                raise self.ConfigurationError(f\"Cannot update '{field}'. It is an invalid configuration field.\")\n            else:\n                setattr(self, field, value)\n        # just write the configuration file, file exists and we are overriding\n        self._write_configuration_file(filepath=filepath, override=True)",
  "def __init__(self,\n\n                 # Base\n                 emitter=None,\n                 config_root: Optional[Path] = None,\n                 filepath: Optional[Path] = None,\n\n                 # Mode\n                 dev_mode: bool = False,\n                 federated_only: bool = False,\n\n                 # Identity\n                 checksum_address: str = None,\n                 crypto_power: CryptoPower = None,\n\n                 # Keystore\n                 keystore: Keystore = None,\n                 keystore_path: Optional[Path] = None,\n\n                 # Learner\n                 learn_on_same_thread: bool = False,\n                 abort_on_learning_error: bool = False,\n                 start_learning_now: bool = True,\n\n                 # Network\n                 domain: str = DEFAULT_DOMAIN,\n                 network_middleware: RestMiddleware = None,\n                 lonely: bool = False,\n\n                 # Node Storage\n                 known_nodes: set = None,\n                 node_storage: NodeStorage = None,\n                 reload_metadata: bool = True,\n                 save_metadata: bool = True,\n\n                 # Blockchain\n                 poa: bool = None,\n                 light: bool = False,\n                 eth_provider_uri: str = None,\n                 gas_strategy: Union[Callable, str] = DEFAULT_GAS_STRATEGY,\n                 max_gas_price: Optional[int] = None,\n                 signer_uri: str = None,\n\n                 # Payments\n                 # TODO: Resolve code prefixing below, possibly with the use of nested configuration fields\n                 payment_method: str = None,\n                 payment_provider: str = None,\n                 payment_network: str = None,\n\n                 # Registries\n                 registry: BaseContractRegistry = None,\n                 registry_filepath: Optional[Path] = None,\n                 policy_registry: BaseContractRegistry = None,\n                 policy_registry_filepath: Optional[Path] = None,\n\n                 # Deployed Operators\n                 worker_data: dict = None\n                 ):\n\n        self.log = Logger(self.__class__.__name__)\n\n        # This constant is used to signal that a path can be generated if one is not provided.\n        UNINITIALIZED_CONFIGURATION.bool_value(False)\n\n        # Identity\n        # NOTE: NodeConfigurations can only be used with Self-Characters\n        self.is_me = True\n        self.checksum_address = checksum_address\n\n        # Keystore\n        self.crypto_power = crypto_power\n        if keystore_path and not keystore:\n            keystore = Keystore(keystore_path=keystore_path)\n        self.__keystore = self.__keystore = keystore or NO_KEYSTORE_ATTACHED.bool_value(False)\n        self.keystore_dir = Path(keystore.keystore_path).parent if keystore else UNINITIALIZED_CONFIGURATION\n\n        # Contract Registry\n        if registry and registry_filepath:\n            if registry.filepath != registry_filepath:\n                error = f\"Inconsistent registry filepaths for '{registry.filepath.absolute()}'\" \\\n                        f\" and '{registry_filepath.absolute()}'.\"\n                raise ValueError(error)\n            else:\n                self.log.warn(f\"Registry and registry filepath were both passed.\")\n        self.registry = registry or NO_BLOCKCHAIN_CONNECTION.bool_value(False)\n        self.registry_filepath = registry_filepath or UNINITIALIZED_CONFIGURATION\n\n        self.policy_registry = policy_registry or NO_BLOCKCHAIN_CONNECTION.bool_value(False)\n        self.policy_registry_filepath = policy_registry_filepath or UNINITIALIZED_CONFIGURATION\n\n        # Blockchain\n        self.poa = poa\n        self.is_light = light\n        self.eth_provider_uri = eth_provider_uri or NO_BLOCKCHAIN_CONNECTION\n        self.signer_uri = signer_uri or None\n\n        # Learner\n        self.federated_only = federated_only\n        self.domain = domain\n        self.learn_on_same_thread = learn_on_same_thread\n        self.abort_on_learning_error = abort_on_learning_error\n        self.start_learning_now = start_learning_now\n        self.save_metadata = save_metadata\n        self.reload_metadata = reload_metadata\n        self.known_nodes = known_nodes or set()  # handpicked\n        self.lonely = lonely\n\n        # Configuration\n        self.__dev_mode = dev_mode\n        self.config_file_location = filepath or UNINITIALIZED_CONFIGURATION\n        self.config_root = UNINITIALIZED_CONFIGURATION\n\n        # Deployed Operators\n        self.worker_data = worker_data\n\n        #\n        # Federated vs. Blockchain arguments consistency\n        #\n\n        #\n        # Federated\n        #\n\n        if self.federated_only:\n            # Check for incompatible values\n            blockchain_args = {'filepath': registry_filepath,\n                               'poa': poa,\n                               'eth_provider_uri': eth_provider_uri,\n                               'payment_provider': payment_provider,\n                               'gas_strategy': gas_strategy,\n                               'max_gas_price': max_gas_price}\n            if any(blockchain_args.values()):\n                bad_args = \", \".join(f\"{arg}={val}\" for arg, val in blockchain_args.items() if val)\n                self.log.warn(f\"Arguments {bad_args} are incompatible with federated_only. \"\n                              f\"Overridden with a sane default.\")\n\n                # Clear decentralized attributes to ensure consistency with a\n                # federated configuration.\n                self.poa = False\n                self.is_light = False\n                self.eth_provider_uri = None\n                self.registry_filepath = None\n                self.policy_registry_filepath = None\n                self.gas_strategy = None\n                self.max_gas_price = None\n\n            # Federated Payments\n            self.payment_method = payment_method or self.DEFAULT_FEDERATED_PAYMENT_METHOD\n            self.payment_network = payment_network\n            self.payment_provider = payment_provider\n\n        #\n        # Decentralized\n        #\n\n        else:\n            self.gas_strategy = gas_strategy\n            self.max_gas_price = max_gas_price  # gwei\n            is_initialized = BlockchainInterfaceFactory.is_interface_initialized(eth_provider_uri=self.eth_provider_uri)\n            if not is_initialized and eth_provider_uri:\n                BlockchainInterfaceFactory.initialize_interface(eth_provider_uri=self.eth_provider_uri,\n                                                                poa=self.poa,\n                                                                light=self.is_light,\n                                                                emitter=emitter,\n                                                                gas_strategy=self.gas_strategy,\n                                                                max_gas_price=self.max_gas_price)\n            else:\n                self.log.warn(f\"Using existing blockchain interface connection ({self.eth_provider_uri}).\")\n\n            if not self.registry:\n                # TODO: These two code blocks are untested.\n                if not self.registry_filepath:  # TODO: Registry URI  (goerli://speedynet.json) :-)\n                    self.log.info(f\"Fetching latest registry from source.\")\n                    self.registry = InMemoryContractRegistry.from_latest_publication(network=self.domain)\n                else:\n                    self.registry = LocalContractRegistry(filepath=self.registry_filepath)\n                    self.log.info(f\"Using local registry ({self.registry}).\")\n\n            self.testnet = self.domain != NetworksInventory.MAINNET\n            self.signer = Signer.from_signer_uri(self.signer_uri, testnet=self.testnet)\n\n            #\n            # Onchain Payments & Policies\n            #\n\n            # FIXME: Enforce this for Ursula/Alice but not Bob?\n            from nucypher.config.characters import BobConfiguration\n            if not isinstance(self, BobConfiguration):\n                # if not payment_provider:\n                #     raise self.ConfigurationError(\"payment provider is required.\")\n                self.payment_method = payment_method or self.DEFAULT_PAYMENT_METHOD\n                self.payment_network = payment_network or self.DEFAULT_PAYMENT_NETWORK\n                self.payment_provider = payment_provider or (self.eth_provider_uri or None)  # default to L1 payments\n\n                # TODO: Dedupe\n                if not self.policy_registry:\n                    if not self.policy_registry_filepath:\n                        self.log.info(f\"Fetching latest policy registry from source.\")\n                        self.policy_registry = InMemoryContractRegistry.from_latest_publication(network=self.payment_network)\n                    else:\n                        self.policy_registry = LocalContractRegistry(filepath=self.policy_registry_filepath)\n                        self.log.info(f\"Using local policy registry ({self.policy_registry}).\")\n\n        if dev_mode:\n            self.__temp_dir = UNINITIALIZED_CONFIGURATION\n            self._setup_node_storage()\n            self.initialize(password=DEVELOPMENT_CONFIGURATION)\n        else:\n            self.__temp_dir = LIVE_CONFIGURATION\n            self.config_root = config_root or self.DEFAULT_CONFIG_ROOT\n            self._cache_runtime_filepaths()\n            self._setup_node_storage(node_storage=node_storage)\n\n        # Network\n        self.network_middleware = network_middleware or self.DEFAULT_NETWORK_MIDDLEWARE(registry=self.registry)\n        \n        super().__init__(filepath=self.config_file_location, config_root=self.config_root)",
  "def __call__(self, **character_kwargs):\n        return self.produce(**character_kwargs)",
  "def keystore(self) -> Keystore:\n        return self.__keystore",
  "def attach_keystore(self, keystore: Keystore) -> None:\n        self.__keystore = keystore",
  "def checksum_address_from_filepath(cls, filepath: Path) -> str:\n        pattern = re.compile(r'''\n                             (^\\w+)-\n                             (0x{1}           # Then, 0x the start of the string, exactly once\n                             [0-9a-fA-F]{40}) # Followed by exactly 40 hex chars\n                             ''',\n                             re.VERBOSE)\n\n        filename = filepath.name\n        match = pattern.match(filename)\n\n        if match:\n            character_name, checksum_address = match.groups()\n        else:\n            # Extract from default by \"peeking\" inside the configuration file.\n            default_name = cls.generate_filename()\n            if filename == default_name:\n                checksum_address = cls.peek(filepath=filepath, field='checksum_address')\n            else:\n                raise ValueError(f\"Cannot extract checksum from filepath '{filepath}'\")\n\n        if not is_checksum_address(checksum_address):\n            raise RuntimeError(f\"Invalid checksum address detected in configuration file at '{filepath}'.\")\n        return checksum_address",
  "def update(self, **kwargs) -> None:\n        \"\"\"\n        A facility for updating existing attributes on existing configuration instances.\n\n        Warning: This method allows mutation and may result in an inconsistent configuration.\n        \"\"\"\n        # config file should exist and we we override -> no need for modifier\n        return super().update(filepath=self.config_file_location, **kwargs)",
  "def generate(cls, password: str, key_material: Optional[bytes] = None, *args, **kwargs):\n        \"\"\"Shortcut: Hook-up a new initial installation and configuration.\"\"\"\n        node_config = cls(dev_mode=False, *args, **kwargs)\n        node_config.initialize(key_material=key_material, password=password)\n        return node_config",
  "def cleanup(self) -> None:\n        if self.__dev_mode:\n            self.__temp_dir.cleanup()",
  "def dev_mode(self) -> bool:\n        return self.__dev_mode",
  "def _setup_node_storage(self, node_storage=None) -> None:\n        # TODO: Disables node metadata persistence..\n        # if self.dev_mode:\n        #     node_storage = ForgetfulNodeStorage(registry=self.registry, federated_only=self.federated_only)\n\n        # TODO: Forcibly clears the filesystem of any stored node metadata and certificates...\n        local_node_storage = LocalFileBasedNodeStorage(\n            registry=self.registry,\n            config_root=self.config_root,\n            federated_only=self.federated_only\n        )\n        local_node_storage.clear()\n        self.log.info(f'Cleared peer metadata from {local_node_storage.root_dir}')\n\n        # TODO: Always sets up nodes for in-memory node metadata storage\n        node_storage = ForgetfulNodeStorage(registry=self.registry, federated_only=self.federated_only)\n        self.node_storage = node_storage",
  "def forget_nodes(self) -> None:\n        self.node_storage.clear()\n        message = \"Removed all stored node node metadata and certificates\"\n        self.log.debug(message)",
  "def destroy(self) -> None:\n        \"\"\"Parse a node configuration and remove all associated files from the filesystem\"\"\"\n        self.config_file_location.unlink()",
  "def generate_parameters(self, **overrides) -> dict:\n        \"\"\"\n        Warning: This method allows mutation and may result in an inconsistent configuration.\n        \"\"\"\n        merged_parameters = {**self.static_payload(), **self.dynamic_payload, **overrides}\n        character_init_params = filter(lambda t: t[0] not in self._CONFIG_FIELDS, merged_parameters.items())\n        return dict(character_init_params)",
  "def produce(self, **overrides) -> CHARACTER_CLASS:\n        \"\"\"Initialize a new character instance and return it.\"\"\"\n        merged_parameters = self.generate_parameters(**overrides)\n        character = self.CHARACTER_CLASS(**merged_parameters)\n        return character",
  "def assemble(cls, filepath: Optional[Path] = None, **overrides) -> dict:\n        \"\"\"\n        Warning: This method allows mutation and may result in an inconsistent configuration.\n        \"\"\"\n        payload = cls._read_configuration_file(filepath=filepath)\n        node_storage = cls.load_node_storage(storage_payload=payload['node_storage'],\n                                             federated_only=payload['federated_only'])\n        max_gas_price = payload.get('max_gas_price')  # gwei\n        if max_gas_price:\n            max_gas_price = Decimal(max_gas_price)\n\n        # Assemble\n        payload.update(dict(node_storage=node_storage, max_gas_price=max_gas_price))\n        payload = cast_paths_from(cls, payload)\n\n        # Filter out None values from **overrides to detect, well, overrides...\n        # Acts as a shim for optional CLI flags.\n        overrides = {k: v for k, v in overrides.items() if v is not None}\n        payload = {**payload, **overrides}\n        return payload",
  "def from_configuration_file(cls,\n                                filepath: Optional[Path] = None,\n                                **overrides  # < ---- Inlet for CLI Flags\n                                ) -> 'CharacterConfiguration':\n        \"\"\"Initialize a CharacterConfiguration from a JSON file.\"\"\"\n        filepath = filepath or cls.default_filepath()\n        assembled_params = cls.assemble(filepath=filepath, **overrides)\n        node_configuration = cls(filepath=filepath, **assembled_params)\n        return node_configuration",
  "def validate(self) -> bool:\n\n        # Top-level\n        if not self.config_root.exists():\n            raise self.ConfigurationError(f'No configuration directory found at {self.config_root}.')\n\n        # Sub-paths\n        filepaths = self.runtime_filepaths\n        for field, path in filepaths.items():\n            if path and not path.exists():\n                message = 'Missing configuration file or directory: {}.'\n                if 'registry' in path:\n                    message += ' Did you mean to pass --federated-only?'\n                raise CharacterConfiguration.InvalidConfiguration(message.format(path))\n        return True",
  "def static_payload(self) -> dict:\n        \"\"\"JSON-Exported static configuration values for initializing Ursula\"\"\"\n        keystore_path = str(self.keystore.keystore_path) if self.keystore else None\n        payload = dict(\n\n            # Identity\n            federated_only=self.federated_only,\n            checksum_address=self.checksum_address,\n            keystore_path=keystore_path,\n\n            # Behavior\n            domain=self.domain,\n            learn_on_same_thread=self.learn_on_same_thread,\n            abort_on_learning_error=self.abort_on_learning_error,\n            start_learning_now=self.start_learning_now,\n            save_metadata=self.save_metadata,\n            node_storage=self.node_storage.payload(),\n            lonely=self.lonely,\n        )\n\n        # Optional values (mode)\n        if not self.federated_only:\n            if self.eth_provider_uri:\n                if not self.signer_uri:\n                    self.signer_uri = self.eth_provider_uri\n                payload.update(dict(eth_provider_uri=self.eth_provider_uri,\n                                    poa=self.poa,\n                                    light=self.is_light,\n                                    signer_uri=self.signer_uri))\n            if self.registry_filepath:\n                payload.update(dict(registry_filepath=self.registry_filepath))\n\n            # Gas Price\n            __max_price = str(self.max_gas_price) if self.max_gas_price else None\n            payload.update(dict(gas_strategy=self.gas_strategy, max_gas_price=__max_price))\n\n        # Merge with base payload\n        base_payload = super().static_payload()\n        base_payload.update(payload)\n\n        return payload",
  "def dynamic_payload(self) -> dict:\n        \"\"\"\n        Exported dynamic configuration values for initializing Ursula.\n        These values are used to init a character instance but are *not*\n        saved to the JSON configuration.\n        \"\"\"\n        payload = dict()\n        if not self.federated_only:\n            payload.update(dict(registry=self.registry, signer=self.signer))\n\n        payload.update(dict(network_middleware=self.network_middleware or self.DEFAULT_NETWORK_MIDDLEWARE(),\n                            known_nodes=self.known_nodes,\n                            node_storage=self.node_storage,\n                            keystore=self.keystore,\n                            crypto_power_ups=self.derive_node_power_ups()))\n\n        return payload",
  "def generate_filepath(self, filepath: Optional[Path] = None, modifier: str = None, override: bool = False) -> Path:\n        modifier = modifier or self.checksum_address\n        filepath = super().generate_filepath(filepath=filepath, modifier=modifier, override=override)\n        return filepath",
  "def runtime_filepaths(self) -> dict:\n        filepaths = dict(config_root=self.config_root,\n                         keystore_dir=self.keystore_dir,\n                         registry_filepath=self.registry_filepath)\n        return filepaths",
  "def generate_runtime_filepaths(cls, config_root: Path) -> dict:\n        \"\"\"Dynamically generate paths based on configuration root directory\"\"\"\n        filepaths = dict(config_root=config_root,\n                         config_file_location=config_root / cls.generate_filename(),\n                         keystore_dir=config_root / 'keystore')\n        return filepaths",
  "def _cache_runtime_filepaths(self) -> None:\n        \"\"\"Generate runtime filepaths and cache them on the config object\"\"\"\n        filepaths = self.generate_runtime_filepaths(config_root=self.config_root)\n        for field, filepath in filepaths.items():\n            if getattr(self, field) is UNINITIALIZED_CONFIGURATION:\n                setattr(self, field, filepath)",
  "def derive_node_power_ups(self) -> List[CryptoPowerUp]:\n        power_ups = list()\n        if self.is_me and not self.dev_mode:\n            for power_class in self.CHARACTER_CLASS._default_crypto_powerups:\n                power_up = self.keystore.derive_crypto_power(power_class)\n                power_ups.append(power_up)\n        return power_ups",
  "def initialize(self, password: str, key_material: Optional[bytes] = None) -> str:\n        \"\"\"Initialize a new configuration and write installation files to disk.\"\"\"\n\n        # Development\n        if self.dev_mode:\n            self.__temp_dir = TemporaryDirectory(prefix=self.TEMP_CONFIGURATION_DIR_PREFIX)\n            self.config_root = Path(self.__temp_dir.name)\n\n        # Persistent\n        else:\n            self._ensure_config_root_exists()\n            self.write_keystore(key_material=key_material,\n                                password=password,\n                                interactive=self.MNEMONIC_KEYSTORE)\n\n        self._cache_runtime_filepaths()\n        self.node_storage.initialize()\n\n        # Validate\n        if not self.__dev_mode:\n            self.validate()\n\n        # Success\n        message = \"Created nucypher installation files at {}\".format(self.config_root)\n        self.log.debug(message)\n        return Path(self.config_root)",
  "def write_keystore(self, password: str, key_material: Optional[bytes] = None, interactive: bool = True) -> Keystore:\n        if key_material:\n            self.__keystore = Keystore.import_secure(key_material=key_material,\n                                                     password=password,\n                                                     keystore_dir=self.keystore_dir)\n        else:\n            if interactive:\n                self.__keystore = Keystore.generate(password=password,\n                                                    keystore_dir=self.keystore_dir,\n                                                    interactive=interactive)\n            else:\n                self.__keystore, _ = Keystore.generate(password=password,\n                                                       keystore_dir=self.keystore_dir,\n                                                       interactive=interactive)\n\n        return self.keystore",
  "def load_node_storage(cls, storage_payload: dict, federated_only: bool):\n        from nucypher.config.storages import NodeStorage\n        node_storage_subclasses = {storage._name: storage for storage in NodeStorage.__subclasses__()}\n        storage_type = storage_payload[NodeStorage._TYPE_LABEL]\n        storage_class = node_storage_subclasses[storage_type]\n        node_storage = storage_class.from_payload(payload=storage_payload, federated_only=federated_only)\n        return node_storage",
  "def configure_payment_method(self):\n        # TODO: finalize config fields\n        # Strategy-Based (current implementation, inflexible & hardcoded)\n        # 'payment_strategy': 'SubscriptionManager'\n        # 'payment_network': 'matic'\n        # 'payment_provider': 'https:///matic.infura.io....'\n        # Contract-Targeted (alternative implementation, flexible & generic)\n        # 'payment': {\n        #     'contract': '0xdeadbeef'\n        #     'abi': '/home/abi/sm.json'\n        #     'function': 'isPolicyActive'\n        #     'provider': 'https:///matic.infura.io....'\n        # }\n\n        try:\n            payment_class = PAYMENT_METHODS[self.payment_method]\n        except KeyError:\n            raise KeyError(f'Unknown payment verifier \"{self.payment_method}\"')\n\n        if payment_class.ONCHAIN:\n            # on-chain payment strategies require a blockchain connection\n            payment_strategy = payment_class(network=self.payment_network,\n                                             eth_provider=self.payment_provider,\n                                             registry=self.policy_registry)\n        else:\n            payment_strategy = payment_class()\n        return payment_strategy",
  "def _stringify_paths(d: dict):\n            for key, value in d.items():\n                if isinstance(value, Path):\n                    d[key] = str(value)\n                if isinstance(value, dict):\n                    _stringify_paths(value)",
  "class UrsulaConfiguration(CharacterConfiguration):\n\n    from nucypher.characters.lawful import Ursula\n    CHARACTER_CLASS = Ursula\n    NAME = CHARACTER_CLASS.__name__.lower()\n\n    DEFAULT_REST_PORT = 9151\n    DEFAULT_DEVELOPMENT_REST_HOST = LOOPBACK_ADDRESS\n    DEFAULT_DEVELOPMENT_REST_PORT = 10151\n    DEFAULT_AVAILABILITY_CHECKS = False\n    LOCAL_SIGNERS_ALLOWED = True\n    SIGNER_ENVVAR = NUCYPHER_ENVVAR_OPERATOR_ETH_PASSWORD\n    MNEMONIC_KEYSTORE = True\n\n    def __init__(self,\n                 rest_host: str = None,\n                 operator_address: str = None,\n                 dev_mode: bool = False,\n                 keystore_path: Optional[Path] = None,\n                 rest_port: int = None,\n                 certificate: Certificate = None,\n                 availability_check: bool = None,\n                 *args, **kwargs) -> None:\n\n        if dev_mode:\n            rest_host = rest_host or self.DEFAULT_DEVELOPMENT_REST_HOST\n            if not rest_port:\n                rest_port = self.DEFAULT_DEVELOPMENT_REST_PORT\n        else:\n            if not rest_host:\n                raise ValueError('rest_host is required for live workers.')\n            if not rest_port:\n                rest_port = self.DEFAULT_REST_PORT\n\n        self.rest_port = rest_port\n        self.rest_host = rest_host\n        self.certificate = certificate\n        self.operator_address = operator_address\n        self.availability_check = availability_check if availability_check is not None else self.DEFAULT_AVAILABILITY_CHECKS\n        super().__init__(dev_mode=dev_mode, keystore_path=keystore_path, *args, **kwargs)\n\n    @classmethod\n    def checksum_address_from_filepath(cls, filepath: Path) -> str:\n        \"\"\"\n        Extracts worker address by \"peeking\" inside the ursula configuration file.\n        \"\"\"\n        checksum_address = cls.peek(filepath=filepath, field='checksum_address')\n        federated = bool(cls.peek(filepath=filepath, field='federated_only'))\n        if not federated:\n            checksum_address = cls.peek(filepath=filepath, field='operator_address')\n\n        if not is_checksum_address(checksum_address):\n            raise RuntimeError(f\"Invalid checksum address detected in configuration file at '{filepath}'.\")\n        return checksum_address\n\n    def generate_runtime_filepaths(self, config_root: Path) -> dict:\n        base_filepaths = super().generate_runtime_filepaths(config_root=config_root)\n        filepaths = dict()\n        base_filepaths.update(filepaths)\n        return base_filepaths\n\n    def generate_filepath(self, modifier: str = None, *args, **kwargs) -> Path:\n        filepath = super().generate_filepath(modifier=modifier or self.keystore.id[:8], *args, **kwargs)\n        return filepath\n\n    def static_payload(self) -> dict:\n        payload = dict(\n            operator_address=self.operator_address,\n            rest_host=self.rest_host,\n            rest_port=self.rest_port,\n            availability_check=self.availability_check,\n\n            # TODO: Resolve variable prefixing below (uses nested configuration fields?)\n            payment_method=self.payment_method,\n            payment_provider=self.payment_provider,\n            payment_network=self.payment_network\n        )\n        return {**super().static_payload(), **payload}\n\n    @property\n    def dynamic_payload(self) -> dict:\n        payload = dict(\n            network_middleware=self.network_middleware,\n            certificate=self.certificate,\n            payment_method=self.configure_payment_method()\n        )\n        return {**super().dynamic_payload, **payload}\n\n    def produce(self, **overrides):\n        \"\"\"Produce a new Ursula from configuration\"\"\"\n\n        merged_parameters = self.generate_parameters(**overrides)\n        ursula = self.CHARACTER_CLASS(**merged_parameters)\n        return ursula\n\n    @classmethod\n    def deserialize(cls, payload: str, deserializer=json.loads, payload_label: Optional[str] = None) -> dict:\n        deserialized_payload = super().deserialize(payload, deserializer, payload_label)\n        return deserialized_payload\n\n    @classmethod\n    def assemble(cls, filepath: Optional[Path] = None, **overrides) -> dict:\n        payload = super().assemble(filepath, **overrides)\n        return payload",
  "class AliceConfiguration(CharacterConfiguration):\n    from nucypher.characters.lawful import Alice\n\n    CHARACTER_CLASS = Alice\n    NAME = CHARACTER_CLASS.__name__.lower()\n\n    # TODO: Best (Sane) Defaults\n    DEFAULT_THRESHOLD = 2\n    DEFAULT_SHARES = 3\n\n    DEFAULT_STORE_POLICIES = True\n    DEFAULT_STORE_CARDS = True\n\n    SIGNER_ENVVAR = NUCYPHER_ENVVAR_ALICE_ETH_PASSWORD\n\n    _CONFIG_FIELDS = (\n        *CharacterConfiguration._CONFIG_FIELDS,\n        'store_policies',\n        'store_cards',\n    )\n\n    def __init__(self,\n                 threshold: int = None,\n                 shares: int = None,\n                 rate: int = None,\n                 duration: int = None,\n                 store_policies: bool = DEFAULT_STORE_POLICIES,\n                 store_cards: bool = DEFAULT_STORE_CARDS,\n                 *args, **kwargs):\n\n        super().__init__(*args, **kwargs)\n\n        # Storage\n        self.store_policies = store_policies\n        self.store_cards = store_cards\n\n        # Policy Value Defaults\n        self.rate = rate\n        self.duration = duration\n        self.threshold = threshold or self.DEFAULT_THRESHOLD\n        self.shares = shares or self.DEFAULT_SHARES\n\n    def static_payload(self) -> dict:\n        payload = dict(\n            threshold=self.threshold,\n            shares=self.shares,\n            store_policies=self.store_policies,\n            store_cards=self.store_cards,\n            payment_network=self.payment_network,\n            payment_provider=self.payment_provider,\n            payment_method=self.payment_method\n        )\n        if not self.federated_only:\n            if self.rate:\n                payload['rate'] = self.rate\n            if self.duration:\n                payload['duration'] = self.duration\n        return {**super().static_payload(), **payload}\n\n    @property\n    def dynamic_payload(self) -> dict:\n        payload = dict(payment_method=self.configure_payment_method())\n        return {**super().dynamic_payload, **payload}",
  "class BobConfiguration(CharacterConfiguration):\n    from nucypher.characters.lawful import Bob\n\n    CHARACTER_CLASS = Bob\n    NAME = CHARACTER_CLASS.__name__.lower()\n    DEFAULT_STORE_POLICIES = True\n    DEFAULT_STORE_CARDS = True\n    SIGNER_ENVVAR = NUCYPHER_ENVVAR_BOB_ETH_PASSWORD\n\n    _CONFIG_FIELDS = (\n        *CharacterConfiguration._CONFIG_FIELDS,\n        'store_policies',\n        'store_cards'\n    )\n\n    def __init__(self,\n                 store_policies: bool = DEFAULT_STORE_POLICIES,\n                 store_cards: bool = DEFAULT_STORE_CARDS,\n                 *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.store_policies = store_policies\n        self.store_cards = store_cards\n\n    def static_payload(self) -> dict:\n        payload = dict(\n            store_policies=self.store_policies,\n            store_cards=self.store_cards\n        )\n        return {**super().static_payload(), **payload}",
  "def __init__(self,\n                 rest_host: str = None,\n                 operator_address: str = None,\n                 dev_mode: bool = False,\n                 keystore_path: Optional[Path] = None,\n                 rest_port: int = None,\n                 certificate: Certificate = None,\n                 availability_check: bool = None,\n                 *args, **kwargs) -> None:\n\n        if dev_mode:\n            rest_host = rest_host or self.DEFAULT_DEVELOPMENT_REST_HOST\n            if not rest_port:\n                rest_port = self.DEFAULT_DEVELOPMENT_REST_PORT\n        else:\n            if not rest_host:\n                raise ValueError('rest_host is required for live workers.')\n            if not rest_port:\n                rest_port = self.DEFAULT_REST_PORT\n\n        self.rest_port = rest_port\n        self.rest_host = rest_host\n        self.certificate = certificate\n        self.operator_address = operator_address\n        self.availability_check = availability_check if availability_check is not None else self.DEFAULT_AVAILABILITY_CHECKS\n        super().__init__(dev_mode=dev_mode, keystore_path=keystore_path, *args, **kwargs)",
  "def checksum_address_from_filepath(cls, filepath: Path) -> str:\n        \"\"\"\n        Extracts worker address by \"peeking\" inside the ursula configuration file.\n        \"\"\"\n        checksum_address = cls.peek(filepath=filepath, field='checksum_address')\n        federated = bool(cls.peek(filepath=filepath, field='federated_only'))\n        if not federated:\n            checksum_address = cls.peek(filepath=filepath, field='operator_address')\n\n        if not is_checksum_address(checksum_address):\n            raise RuntimeError(f\"Invalid checksum address detected in configuration file at '{filepath}'.\")\n        return checksum_address",
  "def generate_runtime_filepaths(self, config_root: Path) -> dict:\n        base_filepaths = super().generate_runtime_filepaths(config_root=config_root)\n        filepaths = dict()\n        base_filepaths.update(filepaths)\n        return base_filepaths",
  "def generate_filepath(self, modifier: str = None, *args, **kwargs) -> Path:\n        filepath = super().generate_filepath(modifier=modifier or self.keystore.id[:8], *args, **kwargs)\n        return filepath",
  "def static_payload(self) -> dict:\n        payload = dict(\n            operator_address=self.operator_address,\n            rest_host=self.rest_host,\n            rest_port=self.rest_port,\n            availability_check=self.availability_check,\n\n            # TODO: Resolve variable prefixing below (uses nested configuration fields?)\n            payment_method=self.payment_method,\n            payment_provider=self.payment_provider,\n            payment_network=self.payment_network\n        )\n        return {**super().static_payload(), **payload}",
  "def dynamic_payload(self) -> dict:\n        payload = dict(\n            network_middleware=self.network_middleware,\n            certificate=self.certificate,\n            payment_method=self.configure_payment_method()\n        )\n        return {**super().dynamic_payload, **payload}",
  "def produce(self, **overrides):\n        \"\"\"Produce a new Ursula from configuration\"\"\"\n\n        merged_parameters = self.generate_parameters(**overrides)\n        ursula = self.CHARACTER_CLASS(**merged_parameters)\n        return ursula",
  "def deserialize(cls, payload: str, deserializer=json.loads, payload_label: Optional[str] = None) -> dict:\n        deserialized_payload = super().deserialize(payload, deserializer, payload_label)\n        return deserialized_payload",
  "def assemble(cls, filepath: Optional[Path] = None, **overrides) -> dict:\n        payload = super().assemble(filepath, **overrides)\n        return payload",
  "def __init__(self,\n                 threshold: int = None,\n                 shares: int = None,\n                 rate: int = None,\n                 duration: int = None,\n                 store_policies: bool = DEFAULT_STORE_POLICIES,\n                 store_cards: bool = DEFAULT_STORE_CARDS,\n                 *args, **kwargs):\n\n        super().__init__(*args, **kwargs)\n\n        # Storage\n        self.store_policies = store_policies\n        self.store_cards = store_cards\n\n        # Policy Value Defaults\n        self.rate = rate\n        self.duration = duration\n        self.threshold = threshold or self.DEFAULT_THRESHOLD\n        self.shares = shares or self.DEFAULT_SHARES",
  "def static_payload(self) -> dict:\n        payload = dict(\n            threshold=self.threshold,\n            shares=self.shares,\n            store_policies=self.store_policies,\n            store_cards=self.store_cards,\n            payment_network=self.payment_network,\n            payment_provider=self.payment_provider,\n            payment_method=self.payment_method\n        )\n        if not self.federated_only:\n            if self.rate:\n                payload['rate'] = self.rate\n            if self.duration:\n                payload['duration'] = self.duration\n        return {**super().static_payload(), **payload}",
  "def dynamic_payload(self) -> dict:\n        payload = dict(payment_method=self.configure_payment_method())\n        return {**super().dynamic_payload, **payload}",
  "def __init__(self,\n                 store_policies: bool = DEFAULT_STORE_POLICIES,\n                 store_cards: bool = DEFAULT_STORE_CARDS,\n                 *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.store_policies = store_policies\n        self.store_cards = store_cards",
  "def static_payload(self) -> dict:\n        payload = dict(\n            store_policies=self.store_policies,\n            store_cards=self.store_cards\n        )\n        return {**super().static_payload(), **payload}",
  "class NodeStorage(ABC):\n    _name = NotImplemented\n    _TYPE_LABEL = 'storage_type'\n\n    TLS_CERTIFICATE_ENCODING = Encoding.PEM\n    TLS_CERTIFICATE_EXTENSION = '.{}'.format(TLS_CERTIFICATE_ENCODING.name.lower())\n\n    class NodeStorageError(Exception):\n        pass\n\n    class UnknownNode(NodeStorageError):\n        pass\n\n    def __init__(self,\n                 federated_only: bool = False,  # TODO# 466\n                 character_class=None,\n                 registry: BaseContractRegistry = None,\n                 ) -> None:\n\n        from nucypher.characters.lawful import Ursula\n\n        self.log = Logger(self.__class__.__name__)\n        self.registry = registry\n        self.federated_only = federated_only\n        self.character_class = character_class or Ursula\n\n    def __getitem__(self, item):\n        return self.get(checksum_address=item, federated_only=self.federated_only)\n\n    def __setitem__(self, key, value):\n        return self.store_node_metadata(node=value)\n\n    def __iter__(self):\n        return self.all(federated_only=self.federated_only)\n\n    @property\n    @abstractmethod\n    def source(self) -> str:\n        \"\"\"Human readable source string\"\"\"\n        return NotImplemented\n\n    def encode_node_bytes(self, node_bytes):\n        return binascii.hexlify(node_bytes)\n\n    def decode_node_bytes(self, encoded_node) -> bytes:\n        return binascii.unhexlify(encoded_node)\n\n    def _read_common_name(self, certificate: Certificate):\n        x509 = OpenSSL.crypto.X509.from_cryptography(certificate)\n        subject_components = x509.get_subject().get_components()\n        common_name_as_bytes = subject_components[0][1]\n        common_name_from_cert = common_name_as_bytes.decode()\n        return common_name_from_cert\n\n    def _write_tls_certificate(self,\n                               port: int,  # used to avoid duplicate certs with the same IP\n                               certificate: Certificate,\n                               force: bool = True) -> Path:\n\n        # Read\n        x509 = OpenSSL.crypto.X509.from_cryptography(certificate)\n        subject_components = x509.get_subject().get_components()\n        common_name_as_bytes = subject_components[0][1]\n        common_name_on_certificate = common_name_as_bytes.decode()\n        host = common_name_on_certificate\n\n        certificate_filepath = self.generate_certificate_filepath(host=host, port=port)\n        certificate_already_exists = certificate_filepath.is_file()\n        if force is False and certificate_already_exists:\n            raise FileExistsError('A TLS certificate already exists at {}.'.format(certificate_filepath))\n\n        # Write\n        certificate_filepath.parent.mkdir(parents=True, exist_ok=True)\n        with open(certificate_filepath, 'wb') as certificate_file:\n            public_pem_bytes = certificate.public_bytes(self.TLS_CERTIFICATE_ENCODING)\n            certificate_file.write(public_pem_bytes)\n\n        self.log.debug(f\"Saved TLS certificate for {host} to {certificate_filepath}\")\n        return certificate_filepath\n\n    @abstractmethod\n    def store_node_certificate(self, certificate: Certificate, port: int) -> Path:\n        raise NotImplementedError\n\n    @abstractmethod\n    def store_node_metadata(self, node, filepath: Optional[Path] = None) -> Path:\n        \"\"\"Save a single node's metadata and tls certificate\"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def generate_certificate_filepath(self, host: str, port: int) -> Path:\n        raise NotImplementedError\n\n    @abstractmethod\n    def payload(self) -> dict:\n        raise NotImplementedError\n\n    @classmethod\n    @abstractmethod\n    def from_payload(self, data: dict, *args, **kwargs) -> 'NodeStorage':\n        \"\"\"Instantiate a storage object from a dictionary\"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def initialize(self):\n        \"\"\"One-time initialization steps to establish a node storage backend\"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def all(self, federated_only: bool, certificates_only: bool = False) -> set:\n        \"\"\"Return s set of all stored nodes\"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def get(self, checksum_address: str, federated_only: bool):\n        \"\"\"Retrieve a single stored node\"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def clear(self) -> bool:\n        \"\"\"Remove all stored nodes\"\"\"\n        raise NotImplementedError",
  "class ForgetfulNodeStorage(NodeStorage):\n    _name = ':memory:'\n    __base_prefix = \"nucypher-tmp-certs-\"\n\n    def __init__(self, parent_dir: Optional[Path] = None, *args, **kwargs) -> None:\n        super().__init__(*args, **kwargs)\n        self.__metadata = dict()\n\n        # Certificates\n        self.__certificates = dict()\n        self.__temporary_certificates = list()\n        self._temp_certificates_dir = Path(tempfile.mkdtemp(prefix=self.__base_prefix, dir=parent_dir))\n\n    @property\n    def source(self) -> str:\n        \"\"\"Human readable source string\"\"\"\n        return self._name\n\n    def all(self, federated_only: bool, certificates_only: bool = False) -> set:\n        return set(self.__certificates.values() if certificates_only else self.__metadata.values())\n\n    @validate_checksum_address\n    def get(self,\n            federated_only: bool,\n            host: str = None,\n            stamp: SignatureStamp = None,\n            certificate_only: bool = False):\n\n        if not bool(stamp) ^ bool(host):\n            message = \"Either pass stamp or host; Not both. Got ({} {})\".format(stamp, host)\n            raise ValueError(message)\n\n        if certificate_only is True:\n            try:\n                return self.__certificates[stamp or host]\n            except KeyError:\n                raise self.UnknownNode\n        else:\n            try:\n                return self.__metadata[stamp or host]\n            except KeyError:\n                raise self.UnknownNode\n\n    def forget(self) -> bool:\n        for temp_certificate in self.__temporary_certificates:\n            temp_certificate.unlink()\n        return len(self.__temporary_certificates) == 0\n\n    def store_node_certificate(self, certificate: Certificate, port: int) -> Path:\n        filepath = self._write_tls_certificate(certificate=certificate, port=port)\n        return filepath\n\n    def store_node_metadata(self, node, filepath: Optional[Path] = None) -> bytes:\n        self.__metadata[node.stamp] = node\n        return self.__metadata[node.stamp]\n\n    def generate_certificate_filepath(self, host: str, port: int) -> Path:\n        filename = f'{host}:{port}.pem'\n        filepath = self._temp_certificates_dir / filename\n        return filepath\n\n    def clear(self, metadata: bool = True, certificates: bool = True) -> None:\n        \"\"\"Forget all stored nodes and certificates\"\"\"\n        if metadata is True:\n            self.__metadata = dict()\n        if certificates is True:\n            self.__certificates = dict()\n\n    def payload(self) -> dict:\n        payload = {self._TYPE_LABEL: self._name}\n        return payload\n\n    @classmethod\n    def from_payload(cls, payload: dict, *args, **kwargs) -> 'ForgetfulNodeStorage':\n        \"\"\"Alternate constructor to create a storage instance from JSON-like configuration\"\"\"\n        if payload[cls._TYPE_LABEL] != cls._name:\n            raise cls.NodeStorageError\n        return cls(*args, **kwargs)\n\n    def initialize(self):\n        self.__metadata = dict()\n        self.__certificates = dict()",
  "class LocalFileBasedNodeStorage(NodeStorage):\n    _name = 'local'\n    __METADATA_FILENAME_TEMPLATE = '{}.node'\n\n    class NoNodeMetadataFileFound(FileNotFoundError, NodeStorage.UnknownNode):\n        pass\n\n    class InvalidNodeMetadata(NodeStorage.NodeStorageError):\n        \"\"\"Node metadata is corrupt or not possible to parse\"\"\"\n\n    def __init__(self,\n                 config_root: Optional[Path] = None,\n                 storage_root: Optional[Path] = None,\n                 metadata_dir: Optional[Path] = None,\n                 certificates_dir: Optional[Path] = None,\n                 *args, **kwargs\n                 ) -> None:\n\n        super().__init__(*args, **kwargs)\n        self.log = Logger(self.__class__.__name__)\n\n        self.root_dir = storage_root\n        self.metadata_dir = metadata_dir\n        self.certificates_dir = certificates_dir\n        self._cache_storage_filepaths(config_root=config_root)\n\n    @property\n    def source(self) -> Path:\n        \"\"\"Human readable source string\"\"\"\n        return self.root_dir\n\n    def encode_node_bytes(self, node_bytes) -> bytes:\n        return node_bytes\n\n    def decode_node_bytes(self, encoded_node) -> bytes:\n        return encoded_node\n\n    @staticmethod\n    def _generate_storage_filepaths(config_root: Optional[Path] = None,\n                                    storage_root: Optional[Path] = None,\n                                    metadata_dir: Optional[Path] = None,\n                                    certificates_dir: Optional[Path] = None):\n\n        storage_root = storage_root or ((config_root or DEFAULT_CONFIG_ROOT) / 'known_nodes')\n        metadata_dir = metadata_dir or storage_root / 'metadata'\n        certificates_dir = certificates_dir or storage_root / 'certificates'\n\n        payload = {'storage_root': storage_root,\n                   'metadata_dir': metadata_dir,\n                   'certificates_dir': certificates_dir}\n\n        return payload\n\n    def _cache_storage_filepaths(self, config_root: Optional[Path] = None):\n        filepaths = self._generate_storage_filepaths(config_root=config_root,\n                                                     storage_root=self.root_dir,\n                                                     metadata_dir=self.metadata_dir,\n                                                     certificates_dir=self.certificates_dir)\n        self.root_dir = filepaths['storage_root']\n        self.metadata_dir = filepaths['metadata_dir']\n        self.certificates_dir = filepaths['certificates_dir']\n\n    #\n    # Certificates\n    #\n\n    @validate_checksum_address\n    def __get_certificate_filename(self, host: str, port: int) -> str:\n        return f'{host}:{port}.{Encoding.PEM.name.lower()}'\n\n    def __get_certificate_filepath(self, certificate_filename: str) -> Path:\n        return self.certificates_dir / certificate_filename\n\n    def generate_certificate_filepath(self, host: str, port: int) -> Path:\n        certificate_filename = self.__get_certificate_filename(host=host, port=port)\n        certificate_filepath = self.__get_certificate_filepath(certificate_filename=certificate_filename)\n        return certificate_filepath\n\n    @validate_checksum_address\n    def __read_node_tls_certificate(self, filepath: Optional[Path] = None) -> Certificate:\n        \"\"\"Deserialize an X509 certificate from a filepath\"\"\"\n        try:\n            with open(filepath, 'rb') as certificate_file:\n                certificate = x509.load_der_x509_certificate(certificate_file.read(), backend=default_backend())\n                return certificate\n        except FileNotFoundError:\n            raise FileNotFoundError(\"No SSL certificate found at {}\".format(filepath))\n\n    #\n    # Metadata\n    #\n\n    def __generate_metadata_filepath(self, stamp: Union[SignatureStamp, bytes, str], metadata_dir: Optional[Path] = None) -> Path:\n        if isinstance(stamp, SignatureStamp):\n            stamp = bytes(stamp)\n        if isinstance(stamp, str):\n            stamp = bytes.fromhex(stamp)\n        stamp = stamp.hex()\n        metadata_path = metadata_dir or self.metadata_dir / self.__METADATA_FILENAME_TEMPLATE.format(stamp)\n        return metadata_path\n\n    def __read_metadata(self, filepath: Path):\n\n        from nucypher.characters.lawful import Ursula\n\n        try:\n            with open(filepath, \"rb\") as seed_file:\n                seed_file.seek(0)\n                node_bytes = self.decode_node_bytes(seed_file.read())\n                node = Ursula.from_metadata_bytes(node_bytes)\n        except FileNotFoundError:\n            raise self.NoNodeMetadataFileFound\n        except Exception as e:\n            raise self.InvalidNodeMetadata from e\n\n        return node\n\n    def __write_metadata(self, filepath: Path, node):\n        filepath.parent.mkdir(parents=True, exist_ok=True)\n        with open(filepath, \"wb\") as f:\n            f.write(self.encode_node_bytes(bytes(node.metadata())))\n        self.log.info(\"Wrote new node metadata to filesystem {}\".format(filepath))\n        return filepath\n\n    #\n    # API\n    #\n    def all(self, federated_only: bool, certificates_only: bool = False) -> Set[Union[Any, Certificate]]:\n        filenames = list((self.certificates_dir if certificates_only else self.metadata_dir).iterdir())\n        self.log.info(\"Found {} known node metadata files at {}\".format(len(filenames), self.metadata_dir))\n\n        known_certificates = set()\n        if certificates_only:\n            for filename in filenames:\n                certificate = self.__read_node_tls_certificate(self.certificates_dir / filename)\n                known_certificates.add(certificate)\n            return known_certificates\n\n        else:\n            known_nodes = set()\n            invalid_metadata = []\n            for filename in filenames:\n                metadata_path = self.metadata_dir / filename\n                try:\n                    node = self.__read_metadata(filepath=metadata_path)\n                except self.NodeStorageError:\n                    invalid_metadata.append(filename)\n                else:\n                    known_nodes.add(node)\n\n            if invalid_metadata:\n                self.log.warn(f\"Couldn't read metadata in {self.metadata_dir} for the following files: {invalid_metadata}\")\n            return known_nodes\n\n    @validate_checksum_address\n    def get(self, stamp: Union[SignatureStamp, str], federated_only: bool, certificate_only: bool = False):\n        if certificate_only is True:\n            certificate = self.__read_node_tls_certificate(stamp=stamp)\n            return certificate\n        metadata_path = self.__generate_metadata_filepath(stamp=stamp)\n        node = self.__read_metadata(filepath=metadata_path)\n        return node\n\n    def store_node_certificate(self, certificate: Certificate, port: int, force: bool = True):\n        certificate_filepath = self._write_tls_certificate(certificate=certificate, port=port, force=force)\n        return certificate_filepath\n\n    def store_node_metadata(self, node, filepath: Optional[Path] = None) -> Path:\n        filepath = self.__generate_metadata_filepath(stamp=node.stamp, metadata_dir=filepath)\n        self.__write_metadata(filepath=filepath, node=node)\n        return filepath\n\n    def clear(self, metadata: bool = True, certificates: bool = True) -> None:\n        \"\"\"Forget all stored nodes and certificates\"\"\"\n\n        def __destroy_dir_contents(path: Path) -> None:\n            if not path.is_dir():\n                return\n            for dir_item in path.iterdir():\n                if dir_item.is_file():\n                    dir_item.unlink()\n\n        if metadata is True:\n            __destroy_dir_contents(self.metadata_dir)\n        if certificates is True:\n            __destroy_dir_contents(self.certificates_dir)\n\n        return\n\n    def payload(self) -> dict:\n        payload = {\n            'storage_type': self._name,\n            'storage_root': str(self.root_dir.absolute()),\n            'metadata_dir': str(self.metadata_dir.absolute()),\n            'certificates_dir': str(self.certificates_dir.absolute())\n        }\n        return payload\n\n    @classmethod\n    def from_payload(cls, payload: dict, *args, **kwargs) -> 'LocalFileBasedNodeStorage':\n        storage_type = payload[cls._TYPE_LABEL]\n        if not storage_type == cls._name:\n            raise cls.NodeStorageError(\"Wrong storage type. got {}\".format(storage_type))\n        del payload['storage_type']\n\n        payload = cast_paths_from(cls, payload)\n\n        return cls(*args, **payload, **kwargs)\n\n    def initialize(self):\n        storage_dirs = (self.root_dir, self.metadata_dir, self.certificates_dir)\n        for storage_dir in storage_dirs:\n            try:\n                storage_dir.mkdir(mode=0o755)\n            except FileExistsError:\n                message = \"There are pre-existing files at {}\".format(self.root_dir)\n                self.log.info(message)\n            except FileNotFoundError:\n                raise self.NodeStorageError(\"There is no existing configuration at {}\".format(self.root_dir))",
  "class TemporaryFileBasedNodeStorage(LocalFileBasedNodeStorage):\n    _name = 'tmp'\n\n    def __init__(self, *args, **kwargs):\n        self.__temp_metadata_dir = None\n        self.__temp_certificates_dir = None\n        self.__temp_root_dir = None\n        super().__init__(metadata_dir=self.__temp_metadata_dir,\n                         certificates_dir=self.__temp_certificates_dir,\n                         storage_root=self.__temp_root_dir,\n                         *args, **kwargs)\n\n    # TODO: Pending fix for 1554.\n    # def __del__(self):\n    #     if self.__temp_metadata_dir is not None:\n    #         shutil.rmtree(self.__temp_metadata_dir, ignore_errors=True)\n    #         shutil.rmtree(self.__temp_certificates_dir, ignore_errors=True)\n\n    def initialize(self):\n        # Root\n        self.__temp_root_dir = tempfile.mkdtemp(prefix=\"nucypher-tmp-nodes-\")\n        self.root_dir = self.__temp_root_dir\n\n        # Metadata\n        self.__temp_metadata_dir = Path(self.__temp_root_dir) / \"metadata\"\n        self.metadata_dir = self.__temp_metadata_dir\n\n        # Certificates\n        self.__temp_certificates_dir = Path(self.__temp_root_dir) / \"certs\"\n        self.certificates_dir = self.__temp_certificates_dir",
  "class NodeStorageError(Exception):\n        pass",
  "class UnknownNode(NodeStorageError):\n        pass",
  "def __init__(self,\n                 federated_only: bool = False,  # TODO# 466\n                 character_class=None,\n                 registry: BaseContractRegistry = None,\n                 ) -> None:\n\n        from nucypher.characters.lawful import Ursula\n\n        self.log = Logger(self.__class__.__name__)\n        self.registry = registry\n        self.federated_only = federated_only\n        self.character_class = character_class or Ursula",
  "def __getitem__(self, item):\n        return self.get(checksum_address=item, federated_only=self.federated_only)",
  "def __setitem__(self, key, value):\n        return self.store_node_metadata(node=value)",
  "def __iter__(self):\n        return self.all(federated_only=self.federated_only)",
  "def source(self) -> str:\n        \"\"\"Human readable source string\"\"\"\n        return NotImplemented",
  "def encode_node_bytes(self, node_bytes):\n        return binascii.hexlify(node_bytes)",
  "def decode_node_bytes(self, encoded_node) -> bytes:\n        return binascii.unhexlify(encoded_node)",
  "def _read_common_name(self, certificate: Certificate):\n        x509 = OpenSSL.crypto.X509.from_cryptography(certificate)\n        subject_components = x509.get_subject().get_components()\n        common_name_as_bytes = subject_components[0][1]\n        common_name_from_cert = common_name_as_bytes.decode()\n        return common_name_from_cert",
  "def _write_tls_certificate(self,\n                               port: int,  # used to avoid duplicate certs with the same IP\n                               certificate: Certificate,\n                               force: bool = True) -> Path:\n\n        # Read\n        x509 = OpenSSL.crypto.X509.from_cryptography(certificate)\n        subject_components = x509.get_subject().get_components()\n        common_name_as_bytes = subject_components[0][1]\n        common_name_on_certificate = common_name_as_bytes.decode()\n        host = common_name_on_certificate\n\n        certificate_filepath = self.generate_certificate_filepath(host=host, port=port)\n        certificate_already_exists = certificate_filepath.is_file()\n        if force is False and certificate_already_exists:\n            raise FileExistsError('A TLS certificate already exists at {}.'.format(certificate_filepath))\n\n        # Write\n        certificate_filepath.parent.mkdir(parents=True, exist_ok=True)\n        with open(certificate_filepath, 'wb') as certificate_file:\n            public_pem_bytes = certificate.public_bytes(self.TLS_CERTIFICATE_ENCODING)\n            certificate_file.write(public_pem_bytes)\n\n        self.log.debug(f\"Saved TLS certificate for {host} to {certificate_filepath}\")\n        return certificate_filepath",
  "def store_node_certificate(self, certificate: Certificate, port: int) -> Path:\n        raise NotImplementedError",
  "def store_node_metadata(self, node, filepath: Optional[Path] = None) -> Path:\n        \"\"\"Save a single node's metadata and tls certificate\"\"\"\n        raise NotImplementedError",
  "def generate_certificate_filepath(self, host: str, port: int) -> Path:\n        raise NotImplementedError",
  "def payload(self) -> dict:\n        raise NotImplementedError",
  "def from_payload(self, data: dict, *args, **kwargs) -> 'NodeStorage':\n        \"\"\"Instantiate a storage object from a dictionary\"\"\"\n        raise NotImplementedError",
  "def initialize(self):\n        \"\"\"One-time initialization steps to establish a node storage backend\"\"\"\n        raise NotImplementedError",
  "def all(self, federated_only: bool, certificates_only: bool = False) -> set:\n        \"\"\"Return s set of all stored nodes\"\"\"\n        raise NotImplementedError",
  "def get(self, checksum_address: str, federated_only: bool):\n        \"\"\"Retrieve a single stored node\"\"\"\n        raise NotImplementedError",
  "def clear(self) -> bool:\n        \"\"\"Remove all stored nodes\"\"\"\n        raise NotImplementedError",
  "def __init__(self, parent_dir: Optional[Path] = None, *args, **kwargs) -> None:\n        super().__init__(*args, **kwargs)\n        self.__metadata = dict()\n\n        # Certificates\n        self.__certificates = dict()\n        self.__temporary_certificates = list()\n        self._temp_certificates_dir = Path(tempfile.mkdtemp(prefix=self.__base_prefix, dir=parent_dir))",
  "def source(self) -> str:\n        \"\"\"Human readable source string\"\"\"\n        return self._name",
  "def all(self, federated_only: bool, certificates_only: bool = False) -> set:\n        return set(self.__certificates.values() if certificates_only else self.__metadata.values())",
  "def get(self,\n            federated_only: bool,\n            host: str = None,\n            stamp: SignatureStamp = None,\n            certificate_only: bool = False):\n\n        if not bool(stamp) ^ bool(host):\n            message = \"Either pass stamp or host; Not both. Got ({} {})\".format(stamp, host)\n            raise ValueError(message)\n\n        if certificate_only is True:\n            try:\n                return self.__certificates[stamp or host]\n            except KeyError:\n                raise self.UnknownNode\n        else:\n            try:\n                return self.__metadata[stamp or host]\n            except KeyError:\n                raise self.UnknownNode",
  "def forget(self) -> bool:\n        for temp_certificate in self.__temporary_certificates:\n            temp_certificate.unlink()\n        return len(self.__temporary_certificates) == 0",
  "def store_node_certificate(self, certificate: Certificate, port: int) -> Path:\n        filepath = self._write_tls_certificate(certificate=certificate, port=port)\n        return filepath",
  "def store_node_metadata(self, node, filepath: Optional[Path] = None) -> bytes:\n        self.__metadata[node.stamp] = node\n        return self.__metadata[node.stamp]",
  "def generate_certificate_filepath(self, host: str, port: int) -> Path:\n        filename = f'{host}:{port}.pem'\n        filepath = self._temp_certificates_dir / filename\n        return filepath",
  "def clear(self, metadata: bool = True, certificates: bool = True) -> None:\n        \"\"\"Forget all stored nodes and certificates\"\"\"\n        if metadata is True:\n            self.__metadata = dict()\n        if certificates is True:\n            self.__certificates = dict()",
  "def payload(self) -> dict:\n        payload = {self._TYPE_LABEL: self._name}\n        return payload",
  "def from_payload(cls, payload: dict, *args, **kwargs) -> 'ForgetfulNodeStorage':\n        \"\"\"Alternate constructor to create a storage instance from JSON-like configuration\"\"\"\n        if payload[cls._TYPE_LABEL] != cls._name:\n            raise cls.NodeStorageError\n        return cls(*args, **kwargs)",
  "def initialize(self):\n        self.__metadata = dict()\n        self.__certificates = dict()",
  "class NoNodeMetadataFileFound(FileNotFoundError, NodeStorage.UnknownNode):\n        pass",
  "class InvalidNodeMetadata(NodeStorage.NodeStorageError):\n        \"\"\"Node metadata is corrupt or not possible to parse\"\"\"",
  "def __init__(self,\n                 config_root: Optional[Path] = None,\n                 storage_root: Optional[Path] = None,\n                 metadata_dir: Optional[Path] = None,\n                 certificates_dir: Optional[Path] = None,\n                 *args, **kwargs\n                 ) -> None:\n\n        super().__init__(*args, **kwargs)\n        self.log = Logger(self.__class__.__name__)\n\n        self.root_dir = storage_root\n        self.metadata_dir = metadata_dir\n        self.certificates_dir = certificates_dir\n        self._cache_storage_filepaths(config_root=config_root)",
  "def source(self) -> Path:\n        \"\"\"Human readable source string\"\"\"\n        return self.root_dir",
  "def encode_node_bytes(self, node_bytes) -> bytes:\n        return node_bytes",
  "def decode_node_bytes(self, encoded_node) -> bytes:\n        return encoded_node",
  "def _generate_storage_filepaths(config_root: Optional[Path] = None,\n                                    storage_root: Optional[Path] = None,\n                                    metadata_dir: Optional[Path] = None,\n                                    certificates_dir: Optional[Path] = None):\n\n        storage_root = storage_root or ((config_root or DEFAULT_CONFIG_ROOT) / 'known_nodes')\n        metadata_dir = metadata_dir or storage_root / 'metadata'\n        certificates_dir = certificates_dir or storage_root / 'certificates'\n\n        payload = {'storage_root': storage_root,\n                   'metadata_dir': metadata_dir,\n                   'certificates_dir': certificates_dir}\n\n        return payload",
  "def _cache_storage_filepaths(self, config_root: Optional[Path] = None):\n        filepaths = self._generate_storage_filepaths(config_root=config_root,\n                                                     storage_root=self.root_dir,\n                                                     metadata_dir=self.metadata_dir,\n                                                     certificates_dir=self.certificates_dir)\n        self.root_dir = filepaths['storage_root']\n        self.metadata_dir = filepaths['metadata_dir']\n        self.certificates_dir = filepaths['certificates_dir']",
  "def __get_certificate_filename(self, host: str, port: int) -> str:\n        return f'{host}:{port}.{Encoding.PEM.name.lower()}'",
  "def __get_certificate_filepath(self, certificate_filename: str) -> Path:\n        return self.certificates_dir / certificate_filename",
  "def generate_certificate_filepath(self, host: str, port: int) -> Path:\n        certificate_filename = self.__get_certificate_filename(host=host, port=port)\n        certificate_filepath = self.__get_certificate_filepath(certificate_filename=certificate_filename)\n        return certificate_filepath",
  "def __read_node_tls_certificate(self, filepath: Optional[Path] = None) -> Certificate:\n        \"\"\"Deserialize an X509 certificate from a filepath\"\"\"\n        try:\n            with open(filepath, 'rb') as certificate_file:\n                certificate = x509.load_der_x509_certificate(certificate_file.read(), backend=default_backend())\n                return certificate\n        except FileNotFoundError:\n            raise FileNotFoundError(\"No SSL certificate found at {}\".format(filepath))",
  "def __generate_metadata_filepath(self, stamp: Union[SignatureStamp, bytes, str], metadata_dir: Optional[Path] = None) -> Path:\n        if isinstance(stamp, SignatureStamp):\n            stamp = bytes(stamp)\n        if isinstance(stamp, str):\n            stamp = bytes.fromhex(stamp)\n        stamp = stamp.hex()\n        metadata_path = metadata_dir or self.metadata_dir / self.__METADATA_FILENAME_TEMPLATE.format(stamp)\n        return metadata_path",
  "def __read_metadata(self, filepath: Path):\n\n        from nucypher.characters.lawful import Ursula\n\n        try:\n            with open(filepath, \"rb\") as seed_file:\n                seed_file.seek(0)\n                node_bytes = self.decode_node_bytes(seed_file.read())\n                node = Ursula.from_metadata_bytes(node_bytes)\n        except FileNotFoundError:\n            raise self.NoNodeMetadataFileFound\n        except Exception as e:\n            raise self.InvalidNodeMetadata from e\n\n        return node",
  "def __write_metadata(self, filepath: Path, node):\n        filepath.parent.mkdir(parents=True, exist_ok=True)\n        with open(filepath, \"wb\") as f:\n            f.write(self.encode_node_bytes(bytes(node.metadata())))\n        self.log.info(\"Wrote new node metadata to filesystem {}\".format(filepath))\n        return filepath",
  "def all(self, federated_only: bool, certificates_only: bool = False) -> Set[Union[Any, Certificate]]:\n        filenames = list((self.certificates_dir if certificates_only else self.metadata_dir).iterdir())\n        self.log.info(\"Found {} known node metadata files at {}\".format(len(filenames), self.metadata_dir))\n\n        known_certificates = set()\n        if certificates_only:\n            for filename in filenames:\n                certificate = self.__read_node_tls_certificate(self.certificates_dir / filename)\n                known_certificates.add(certificate)\n            return known_certificates\n\n        else:\n            known_nodes = set()\n            invalid_metadata = []\n            for filename in filenames:\n                metadata_path = self.metadata_dir / filename\n                try:\n                    node = self.__read_metadata(filepath=metadata_path)\n                except self.NodeStorageError:\n                    invalid_metadata.append(filename)\n                else:\n                    known_nodes.add(node)\n\n            if invalid_metadata:\n                self.log.warn(f\"Couldn't read metadata in {self.metadata_dir} for the following files: {invalid_metadata}\")\n            return known_nodes",
  "def get(self, stamp: Union[SignatureStamp, str], federated_only: bool, certificate_only: bool = False):\n        if certificate_only is True:\n            certificate = self.__read_node_tls_certificate(stamp=stamp)\n            return certificate\n        metadata_path = self.__generate_metadata_filepath(stamp=stamp)\n        node = self.__read_metadata(filepath=metadata_path)\n        return node",
  "def store_node_certificate(self, certificate: Certificate, port: int, force: bool = True):\n        certificate_filepath = self._write_tls_certificate(certificate=certificate, port=port, force=force)\n        return certificate_filepath",
  "def store_node_metadata(self, node, filepath: Optional[Path] = None) -> Path:\n        filepath = self.__generate_metadata_filepath(stamp=node.stamp, metadata_dir=filepath)\n        self.__write_metadata(filepath=filepath, node=node)\n        return filepath",
  "def clear(self, metadata: bool = True, certificates: bool = True) -> None:\n        \"\"\"Forget all stored nodes and certificates\"\"\"\n\n        def __destroy_dir_contents(path: Path) -> None:\n            if not path.is_dir():\n                return\n            for dir_item in path.iterdir():\n                if dir_item.is_file():\n                    dir_item.unlink()\n\n        if metadata is True:\n            __destroy_dir_contents(self.metadata_dir)\n        if certificates is True:\n            __destroy_dir_contents(self.certificates_dir)\n\n        return",
  "def payload(self) -> dict:\n        payload = {\n            'storage_type': self._name,\n            'storage_root': str(self.root_dir.absolute()),\n            'metadata_dir': str(self.metadata_dir.absolute()),\n            'certificates_dir': str(self.certificates_dir.absolute())\n        }\n        return payload",
  "def from_payload(cls, payload: dict, *args, **kwargs) -> 'LocalFileBasedNodeStorage':\n        storage_type = payload[cls._TYPE_LABEL]\n        if not storage_type == cls._name:\n            raise cls.NodeStorageError(\"Wrong storage type. got {}\".format(storage_type))\n        del payload['storage_type']\n\n        payload = cast_paths_from(cls, payload)\n\n        return cls(*args, **payload, **kwargs)",
  "def initialize(self):\n        storage_dirs = (self.root_dir, self.metadata_dir, self.certificates_dir)\n        for storage_dir in storage_dirs:\n            try:\n                storage_dir.mkdir(mode=0o755)\n            except FileExistsError:\n                message = \"There are pre-existing files at {}\".format(self.root_dir)\n                self.log.info(message)\n            except FileNotFoundError:\n                raise self.NodeStorageError(\"There is no existing configuration at {}\".format(self.root_dir))",
  "def __init__(self, *args, **kwargs):\n        self.__temp_metadata_dir = None\n        self.__temp_certificates_dir = None\n        self.__temp_root_dir = None\n        super().__init__(metadata_dir=self.__temp_metadata_dir,\n                         certificates_dir=self.__temp_certificates_dir,\n                         storage_root=self.__temp_root_dir,\n                         *args, **kwargs)",
  "def initialize(self):\n        # Root\n        self.__temp_root_dir = tempfile.mkdtemp(prefix=\"nucypher-tmp-nodes-\")\n        self.root_dir = self.__temp_root_dir\n\n        # Metadata\n        self.__temp_metadata_dir = Path(self.__temp_root_dir) / \"metadata\"\n        self.metadata_dir = self.__temp_metadata_dir\n\n        # Certificates\n        self.__temp_certificates_dir = Path(self.__temp_root_dir) / \"certs\"\n        self.certificates_dir = self.__temp_certificates_dir",
  "def __destroy_dir_contents(path: Path) -> None:\n            if not path.is_dir():\n                return\n            for dir_item in path.iterdir():\n                if dir_item.is_file():\n                    dir_item.unlink()",
  "def setup_emitter(general_config, banner: str = None) -> StdoutEmitter:\n    emitter = general_config.emitter\n    if banner:\n        emitter.banner(banner)\n    return emitter",
  "def make_cli_character(character_config,\n                       emitter,\n                       unlock_keystore: bool = True,\n                       unlock_signer: bool = True,\n                       teacher_uri: str = None,\n                       min_stake: int = 0,\n                       json_ipc: bool = False,\n                       **config_args\n                       ) -> Character:\n\n    #\n    # Pre-Init\n    #\n\n    # Handle KEYSTORE\n    if unlock_keystore:\n        unlock_nucypher_keystore(emitter,\n                                 character_configuration=character_config,\n                                 password=get_nucypher_password(emitter=emitter, confirm=False))\n\n    # Handle Signer/Wallet\n    if unlock_signer:\n        unlock_signer_account(config=character_config, json_ipc=json_ipc)\n\n    # Handle Teachers\n    # TODO: Is this still relevant?  Is it better to DRY this up by doing it later?\n    sage_nodes = list()\n\n    #\n    # Character Init\n    #\n\n    # Produce Character\n    if teacher_uri:\n        maybe_sage_node = character_config.known_node_class.from_teacher_uri(\n            teacher_uri=teacher_uri,\n            min_stake=min_stake,\n            federated_only=character_config.federated_only,\n            network_middleware=character_config.network_middleware,\n            registry=character_config.registry\n        )\n        sage_nodes.append(maybe_sage_node)\n\n    CHARACTER = character_config(known_nodes=sage_nodes,\n                                 network_middleware=character_config.network_middleware,\n                                 **config_args)\n\n    #\n    # Post-Init\n    #\n\n    # Federated\n    if character_config.federated_only:\n        emitter.message(FEDERATED_WARNING, color='yellow')\n\n    emitter.message(f\"Loaded {CHARACTER.__class__.__name__} ({CHARACTER.domain})\", color='green')\n    return CHARACTER",
  "def establish_deployer_registry(emitter,\n                                network: str = None,\n                                registry_infile: Optional[Path] = None,\n                                registry_outfile: Optional[Path] = None,\n                                use_existing_registry: bool = False,\n                                download_registry: bool = False,\n                                dev: bool = False\n                                ) -> BaseContractRegistry:\n    if download_registry:\n        registry = InMemoryContractRegistry.from_latest_publication(network=network)\n        emitter.message(PRODUCTION_REGISTRY_ADVISORY.format(source=registry.source))\n        return registry\n\n    # Establish a contract registry from disk if specified\n    filepath = registry_infile\n    default_registry_filepath = DEFAULT_CONFIG_ROOT / BaseContractRegistry.REGISTRY_NAME\n    if registry_outfile:\n        # mutative usage of existing registry\n        registry_infile = registry_infile or default_registry_filepath\n        if use_existing_registry:\n            try:\n                _result = shutil.copyfile(registry_infile, registry_outfile)\n            except shutil.SameFileError:\n                raise click.BadArgumentUsage(f\"--registry-infile and --registry-outfile must not be the same path '{registry_infile}'.\")\n        filepath = registry_outfile\n\n    if dev:\n        # TODO: Need a way to detect a geth --dev registry filepath here. (then deprecate the --dev flag)\n        filepath = DEFAULT_CONFIG_ROOT / BaseContractRegistry.DEVELOPMENT_REGISTRY_NAME\n\n    registry_filepath = filepath or default_registry_filepath\n\n    # All Done.\n    registry = LocalContractRegistry(filepath=registry_filepath)\n    emitter.message(LOCAL_REGISTRY_ADVISORY.format(registry_filepath=registry_filepath))\n    return registry",
  "def get_registry(network: str, registry_filepath: Optional[Path] = None) -> BaseContractRegistry:\n    if registry_filepath:\n        registry = LocalContractRegistry(filepath=registry_filepath)\n    else:\n        registry = InMemoryContractRegistry.from_latest_publication(network=network)\n    return registry",
  "def connect_to_blockchain(emitter: StdoutEmitter,\n                          eth_provider_uri: str,\n                          debug: bool = False,\n                          light: bool = False\n                          ) -> BlockchainInterface:\n    try:\n        # Note: Conditional for test compatibility.\n        if not BlockchainInterfaceFactory.is_interface_initialized(eth_provider_uri=eth_provider_uri):\n            BlockchainInterfaceFactory.initialize_interface(eth_provider_uri=eth_provider_uri,\n                                                            light=light,\n                                                            emitter=emitter)\n        emitter.echo(message=CONNECTING_TO_BLOCKCHAIN)\n        blockchain = BlockchainInterfaceFactory.get_interface(eth_provider_uri=eth_provider_uri)\n        return blockchain\n    except Exception as e:\n        if debug:\n            raise\n        emitter.echo(str(e), bold=True, color='red')\n        raise click.Abort",
  "def initialize_deployer_interface(emitter: StdoutEmitter,\n                                  poa: bool,\n                                  eth_provider_uri,\n                                  ignore_solidity_check: bool,\n                                  gas_strategy: str = None,\n                                  max_gas_price: int = None\n                                  ) -> BlockchainDeployerInterface:\n    if not BlockchainInterfaceFactory.is_interface_initialized(eth_provider_uri=eth_provider_uri):\n        deployer_interface = BlockchainDeployerInterface(eth_provider_uri=eth_provider_uri,\n                                                         poa=poa,\n                                                         gas_strategy=gas_strategy,\n                                                         max_gas_price=max_gas_price)\n        BlockchainInterfaceFactory.register_interface(interface=deployer_interface, emitter=emitter)\n    else:\n        deployer_interface = BlockchainInterfaceFactory.get_interface(eth_provider_uri=eth_provider_uri)\n    deployer_interface.connect(ignore_solidity_check=ignore_solidity_check)\n    return deployer_interface",
  "def get_env_bool(var_name: str, default: bool) -> bool:\n    if var_name in os.environ:\n        # TODO: which is better: to fail on an incorrect envvar, or to use the default?\n        # Currently doing the former.\n        return strtobool(os.environ[var_name])\n    else:\n        return default",
  "def ensure_config_root(config_root: Path) -> None:\n    \"\"\"Ensure config root exists, because we need a default place to put output files.\"\"\"\n    config_root = config_root or DEFAULT_CONFIG_ROOT\n    if not config_root.exists():\n        config_root.mkdir(parents=True)",
  "def deployer_pre_launch_warnings(emitter: StdoutEmitter, etherscan: bool, hw_wallet: bool) -> None:\n    if not hw_wallet:\n        emitter.echo(NO_HARDWARE_WALLET_WARNING, color='yellow')\n    if etherscan:\n        emitter.echo(ETHERSCAN_FLAG_ENABLED_WARNING, color='yellow')\n    else:\n        emitter.echo(ETHERSCAN_FLAG_DISABLED_WARNING, color='yellow')",
  "def parse_event_filters_into_argument_filters(event_filters: Tuple[str]) -> Dict:\n    \"\"\"\n    Converts tuple of entries of the form <filter_name>=<filter_value> into a dict\n    of filter_name (key) -> filter_value (value) entries. Filter values can only be strings, but if the filter\n    value can be converted to an int, then it is converted, otherwise it remains a string.\n    \"\"\"\n    argument_filters = dict()\n    for event_filter in event_filters:\n        event_filter_split = event_filter.split('=')\n        if len(event_filter_split) != 2:\n            raise ValueError(f\"Invalid filter format: {event_filter}\")\n        key = event_filter_split[0]\n        value = event_filter_split[1]\n        # events are only indexed by string or int values\n        if value.isnumeric():\n            value = int(value)\n        argument_filters[key] = value\n    return argument_filters",
  "def retrieve_events(emitter: StdoutEmitter,\n                    agent: EthereumContractAgent,\n                    event_name: str,\n                    from_block: BlockIdentifier,\n                    to_block: BlockIdentifier,\n                    argument_filters: Dict,\n                    csv_output_file: Optional[Path] = None) -> None:\n    if csv_output_file:\n        if csv_output_file.exists():\n            click.confirm(CONFIRM_OVERWRITE_EVENTS_CSV_FILE.format(csv_file=csv_output_file), abort=True)\n        available_events = write_events_to_csv_file(csv_file=csv_output_file,\n                                                    agent=agent,\n                                                    event_name=event_name,\n                                                    from_block=from_block,\n                                                    to_block=to_block,\n                                                    argument_filters=argument_filters)\n        if available_events:\n            emitter.echo(f\"{agent.contract_name}::{event_name} events written to {csv_output_file}\",\n                         bold=True,\n                         color='green')\n        else:\n            emitter.echo(f'No {agent.contract_name}::{event_name} events found', color='yellow')\n    else:\n        event = agent.contract.events[event_name]\n        emitter.echo(f\"{event_name}:\", bold=True, color='yellow')\n        entries = event.getLogs(fromBlock=from_block, toBlock=to_block, argument_filters=argument_filters)\n        for event_record in entries:\n            emitter.echo(f\"  - {EventRecord(event_record)}\")",
  "class ChecksumAddress(click.ParamType):\n    name = 'checksum_address'\n\n    def convert(self, value, param, ctx):\n        try:\n            value = to_checksum_address(value=value)\n        except ValueError as e:\n            self.fail(\"Invalid ethereum address\")\n        else:\n            return value",
  "class IPv4Address(click.ParamType):\n    name = 'ipv4_address'\n\n    def convert(self, value, param, ctx):\n        try:\n            _address = ip_address(value)\n        except ValueError:\n            self.fail(\"Invalid IP Address\")\n        else:\n            return value",
  "class OperatorIPAddress(IPv4Address):\n    name = 'operator_ip'\n\n    def convert(self, value, param, ctx):\n        _ip = super().convert(value, param, ctx)\n        try:\n            validate_operator_ip(ip=_ip)\n        except InvalidOperatorIP as e:\n            self.fail(str(e))\n        return value",
  "class DecimalType(click.ParamType):\n    name = 'decimal'\n\n    def convert(self, value, param, ctx):\n        try:\n            return Decimal(value)\n        except DecimalException:\n            self.fail(f\"'{value}' is an invalid decimal number\")",
  "class DecimalRange(DecimalType):\n    name = 'decimal_range'\n\n    def __init__(self, min=None, max=None, clamp=False):\n        self.min = min\n        self.max = max\n        self.clamp = clamp\n\n    def convert(self, value, param, ctx):\n        rv = DecimalType.convert(self, value, param, ctx)\n        if self.clamp:\n            if self.min is not None and rv < self.min:\n                return self.min\n            if self.max is not None and rv > self.max:\n                return self.max\n        if self.min is not None and rv < self.min or \\\n           self.max is not None and rv > self.max:\n            if self.min is None:\n                self.fail(f'{rv} is bigger than the maximum valid value {self.max}')\n            elif self.max is None:\n                self.fail(f'{rv} is smaller than the minimum valid value {self.min}')\n            else:\n                self.fail(f'{rv} is not in the valid range of {self.min} to {self.max}')\n        return rv",
  "class NuCypherNetworkName(click.ParamType):\n    name = 'nucypher_network_name'\n\n    def __init__(self, validate: bool = True):\n        self.validate = bool(validate)\n\n    def convert(self, value, param, ctx):\n        if self.validate:\n            network = str(value).lower()\n            if network not in NetworksInventory.ETH_NETWORKS:\n                self.fail(\n                    f\"'{value}' is not a recognized network. Valid options are: {list(NetworksInventory.ETH_NETWORKS)}\"\n                )\n            else:\n                return network\n        else:\n            return value",
  "class UmbralPublicKeyHex(click.ParamType):\n    name = 'nucypher_umbral_public_key'\n\n    def __init__(self, validate: bool = True):\n        self.validate = bool(validate)\n\n    def convert(self, value, param, ctx):\n        if self.validate:\n            try:\n                _key = PublicKey.from_bytes(bytes.fromhex(value))\n            except (InternalError, ValueError):\n                self.fail(f\"'{value}' is not a valid nucypher public key.\")\n        return value",
  "def convert(self, value, param, ctx):\n        try:\n            value = to_checksum_address(value=value)\n        except ValueError as e:\n            self.fail(\"Invalid ethereum address\")\n        else:\n            return value",
  "def convert(self, value, param, ctx):\n        try:\n            _address = ip_address(value)\n        except ValueError:\n            self.fail(\"Invalid IP Address\")\n        else:\n            return value",
  "def convert(self, value, param, ctx):\n        _ip = super().convert(value, param, ctx)\n        try:\n            validate_operator_ip(ip=_ip)\n        except InvalidOperatorIP as e:\n            self.fail(str(e))\n        return value",
  "def convert(self, value, param, ctx):\n        try:\n            return Decimal(value)\n        except DecimalException:\n            self.fail(f\"'{value}' is an invalid decimal number\")",
  "def __init__(self, min=None, max=None, clamp=False):\n        self.min = min\n        self.max = max\n        self.clamp = clamp",
  "def convert(self, value, param, ctx):\n        rv = DecimalType.convert(self, value, param, ctx)\n        if self.clamp:\n            if self.min is not None and rv < self.min:\n                return self.min\n            if self.max is not None and rv > self.max:\n                return self.max\n        if self.min is not None and rv < self.min or \\\n           self.max is not None and rv > self.max:\n            if self.min is None:\n                self.fail(f'{rv} is bigger than the maximum valid value {self.max}')\n            elif self.max is None:\n                self.fail(f'{rv} is smaller than the minimum valid value {self.min}')\n            else:\n                self.fail(f'{rv} is not in the valid range of {self.min} to {self.max}')\n        return rv",
  "def __init__(self, validate: bool = True):\n        self.validate = bool(validate)",
  "def convert(self, value, param, ctx):\n        if self.validate:\n            network = str(value).lower()\n            if network not in NetworksInventory.ETH_NETWORKS:\n                self.fail(\n                    f\"'{value}' is not a recognized network. Valid options are: {list(NetworksInventory.ETH_NETWORKS)}\"\n                )\n            else:\n                return network\n        else:\n            return value",
  "def __init__(self, validate: bool = True):\n        self.validate = bool(validate)",
  "def convert(self, value, param, ctx):\n        if self.validate:\n            try:\n                _key = PublicKey.from_bytes(bytes.fromhex(value))\n            except (InternalError, ValueError):\n                self.fail(f\"'{value}' is not a valid nucypher public key.\")\n        return value",
  "class GroupGeneralConfig:\n    __option_name__ = 'general_config'\n\n    verbosity = 0\n\n    # Environment Variables\n    config_root = DEFAULT_CONFIG_ROOT\n    sentry_endpoint = os.environ.get(\"NUCYPHER_SENTRY_DSN\", NUCYPHER_SENTRY_ENDPOINT)\n    log_to_sentry = get_env_bool(\"NUCYPHER_SENTRY_LOGS\", False)\n    log_to_file = get_env_bool(\"NUCYPHER_FILE_LOGS\", True)\n\n    def __init__(self,\n                 json_ipc: bool,\n                 verbose: bool,\n                 quiet: bool,\n                 no_logs: bool,\n                 console_logs: bool,\n                 file_logs: bool,\n                 sentry_logs: bool,\n                 log_level: bool,\n                 debug: bool):\n\n        self.log = Logger(self.__class__.__name__)\n\n        # Session Emitter for pre and post character control engagement.\n        if verbose and quiet:\n            raise click.BadOptionUsage(\n                option_name=\"quiet\",\n                message=\"--verbose and --quiet are mutually exclusive \"\n                        \"and cannot be used at the same time.\")\n\n        if verbose:\n            GroupGeneralConfig.verbosity = 2\n        elif quiet:\n            GroupGeneralConfig.verbosity = 0\n        else:\n            GroupGeneralConfig.verbosity = 1\n\n        if json_ipc:\n            GlobalLoggerSettings._json_ipc = True  # TODO #1754\n            emitter = JSONRPCStdoutEmitter(verbosity=GroupGeneralConfig.verbosity)\n        else:\n            emitter = StdoutEmitter(verbosity=GroupGeneralConfig.verbosity)\n\n        self.emitter = emitter\n\n        if verbose:\n            self.emitter.message(\"Verbose mode is enabled\", color='blue')\n\n        # Logging\n        if debug and no_logs:\n            message = \"--debug and --no-logs cannot be used at the same time.\"\n            raise click.BadOptionUsage(option_name=\"no-logs\", message=message)\n\n        # Defaults\n        if file_logs is None:\n            file_logs = self.log_to_file\n        if sentry_logs is None:\n            sentry_logs = self.log_to_sentry\n\n        if debug:\n            console_logs = True\n            file_logs = True\n            sentry_logs = False\n            log_level = 'debug'\n\n        if no_logs:\n            console_logs = False\n            file_logs = False\n            sentry_logs = False\n        if json_ipc:\n            console_logs = False\n\n        GlobalLoggerSettings.set_log_level(log_level_name=log_level)\n\n        if console_logs:\n            GlobalLoggerSettings.start_console_logging()\n        if file_logs:\n            GlobalLoggerSettings.start_text_file_logging()\n            GlobalLoggerSettings.start_json_file_logging()\n        if sentry_logs:\n            GlobalLoggerSettings.start_sentry_logging(self.sentry_endpoint)\n        if json_ipc:\n            GlobalLoggerSettings.stop_console_logging()  # JSON-RPC Protection\n\n        self.debug = debug\n        self.json_ipc = json_ipc",
  "def __init__(self,\n                 json_ipc: bool,\n                 verbose: bool,\n                 quiet: bool,\n                 no_logs: bool,\n                 console_logs: bool,\n                 file_logs: bool,\n                 sentry_logs: bool,\n                 log_level: bool,\n                 debug: bool):\n\n        self.log = Logger(self.__class__.__name__)\n\n        # Session Emitter for pre and post character control engagement.\n        if verbose and quiet:\n            raise click.BadOptionUsage(\n                option_name=\"quiet\",\n                message=\"--verbose and --quiet are mutually exclusive \"\n                        \"and cannot be used at the same time.\")\n\n        if verbose:\n            GroupGeneralConfig.verbosity = 2\n        elif quiet:\n            GroupGeneralConfig.verbosity = 0\n        else:\n            GroupGeneralConfig.verbosity = 1\n\n        if json_ipc:\n            GlobalLoggerSettings._json_ipc = True  # TODO #1754\n            emitter = JSONRPCStdoutEmitter(verbosity=GroupGeneralConfig.verbosity)\n        else:\n            emitter = StdoutEmitter(verbosity=GroupGeneralConfig.verbosity)\n\n        self.emitter = emitter\n\n        if verbose:\n            self.emitter.message(\"Verbose mode is enabled\", color='blue')\n\n        # Logging\n        if debug and no_logs:\n            message = \"--debug and --no-logs cannot be used at the same time.\"\n            raise click.BadOptionUsage(option_name=\"no-logs\", message=message)\n\n        # Defaults\n        if file_logs is None:\n            file_logs = self.log_to_file\n        if sentry_logs is None:\n            sentry_logs = self.log_to_sentry\n\n        if debug:\n            console_logs = True\n            file_logs = True\n            sentry_logs = False\n            log_level = 'debug'\n\n        if no_logs:\n            console_logs = False\n            file_logs = False\n            sentry_logs = False\n        if json_ipc:\n            console_logs = False\n\n        GlobalLoggerSettings.set_log_level(log_level_name=log_level)\n\n        if console_logs:\n            GlobalLoggerSettings.start_console_logging()\n        if file_logs:\n            GlobalLoggerSettings.start_text_file_logging()\n            GlobalLoggerSettings.start_json_file_logging()\n        if sentry_logs:\n            GlobalLoggerSettings.start_sentry_logging(self.sentry_endpoint)\n        if json_ipc:\n            GlobalLoggerSettings.stop_console_logging()  # JSON-RPC Protection\n\n        self.debug = debug\n        self.json_ipc = json_ipc",
  "def nucypher_cli():\n    \"\"\"Top level command for all things nucypher.\"\"\"",
  "def option_alice_verifying_key(required: bool = False):\n    return click.option(\n        '--alice-verifying-key',\n        '-avk',\n        help=\"Alice's verifying key as a hexadecimal string\",\n        type=click.STRING,\n        required=required)",
  "def option_contract_name(required: bool = False,\n                         valid_options: Sequence[str] = NUCYPHER_CONTRACT_NAMES):\n    return click.option(\n        '--contract-name',\n        help=\"Specify a single contract by name\",\n        type=click.Choice(valid_options),\n        required=required\n    )",
  "def option_discovery_port(default=None):\n    return click.option(\n        '--discovery-port',\n        help=\"The host port to run node discovery services on\",\n        type=NETWORK_PORT,\n        default=default)",
  "def option_label(required: bool = False):\n    return click.option(\n        '--label',\n        help=\"The label for a policy\",\n        type=click.STRING,\n        required=required)",
  "def option_message_kit(required: bool = False, multiple: bool = False):\n    return click.option(\n        '--message-kit',\n        help='The message kit unicode string encoded in base64',\n        type=click.STRING,\n        multiple=multiple,\n        required=required)",
  "def option_network(required: bool = False,\n                   default: str = None,  # NetworksInventory.DEFAULT is not a good global default (2214)\n                   validate: bool = False):\n    return click.option(\n        '--network',\n        help=\"NuCypher Network/Domain Name\",\n        type=NuCypherNetworkName(validate=validate),\n        required=required,\n        default=default)",
  "def option_policy_encrypting_key(required: bool = False):\n    return click.option(\n        '--policy-encrypting-key',\n        help=\"Encrypting Public Key for Policy as hexadecimal string\",\n        type=click.STRING,\n        required=required)",
  "def option_eth_provider_uri(default=None, required: bool = False):\n    return click.option(\n        '--eth-provider', 'eth_provider_uri',\n        help=\"Blockchain provider's URI i.e. 'file:///path/to/geth.ipc'\",\n        type=click.STRING,\n        required=required,\n        default=default\n    )",
  "def group_options(option_class, **options):\n    argnames = sorted(list(options.keys()))\n    decorators = list(options.values())\n\n    if isinstance(option_class, str):\n        option_name = option_class\n        option_class = namedtuple(option_class, argnames)\n    else:\n        option_name = option_class.__option_name__\n\n    def _decorator(func):\n\n        @functools.wraps(func)\n        def wrapper(**kwargs):\n            to_group = {}\n            for name in argnames:\n                if name not in kwargs:\n                    raise ValueError(\n                        f\"When trying to group CLI options into {option_name}, \"\n                        f\"{name} was not found among arguments\")\n                to_group[name] = kwargs[name]\n                del kwargs[name]\n\n            kwargs[option_name] = option_class(**to_group)\n            return func(**kwargs)\n\n        for dec in decorators:\n            wrapper = dec(wrapper)\n\n        return wrapper\n\n    return _decorator",
  "def wrap_option(handler, **options):\n\n    assert len(options) == 1\n    name = list(options)[0]\n    dec = options[name]\n\n    @functools.wraps(handler)\n    def _decorator(func):\n\n        @functools.wraps(func)\n        def wrapper(**kwargs):\n            if name not in kwargs:\n                raise ValueError(\n                        f\"When trying to wrap a CLI option with {handler}, \"\n                        f\"{name} was not found among arguments\")\n            option_val = kwargs[name]\n            option_name, new_val = handler(option_val)\n            del kwargs[name]\n            kwargs[option_name] = new_val\n            return func(**kwargs)\n\n        wrapper = dec(wrapper)\n\n        return wrapper\n\n    return _decorator",
  "def process_middleware(mock_networking) -> tuple:\n    #################\n    # MUST NOT RAISE!\n    #################\n    try:\n        from tests.utils.middleware import MockRestMiddleware\n    except ImportError:\n        # It's okay to not crash here despite not having the tests package available.\n        logger = Logger(\"CLI-Middleware-Optional-Handler\")\n        logger.info('--mock-networking flag is unavailable without dev install.')\n    if mock_networking:\n        middleware = MockRestMiddleware()\n    else:\n        from nucypher.network.middleware import RestMiddleware\n        middleware = RestMiddleware()\n    return 'middleware', middleware",
  "def _decorator(func):\n\n        @functools.wraps(func)\n        def wrapper(**kwargs):\n            to_group = {}\n            for name in argnames:\n                if name not in kwargs:\n                    raise ValueError(\n                        f\"When trying to group CLI options into {option_name}, \"\n                        f\"{name} was not found among arguments\")\n                to_group[name] = kwargs[name]\n                del kwargs[name]\n\n            kwargs[option_name] = option_class(**to_group)\n            return func(**kwargs)\n\n        for dec in decorators:\n            wrapper = dec(wrapper)\n\n        return wrapper",
  "def _decorator(func):\n\n        @functools.wraps(func)\n        def wrapper(**kwargs):\n            if name not in kwargs:\n                raise ValueError(\n                        f\"When trying to wrap a CLI option with {handler}, \"\n                        f\"{name} was not found among arguments\")\n            option_val = kwargs[name]\n            option_name, new_val = handler(option_val)\n            del kwargs[name]\n            kwargs[option_name] = new_val\n            return func(**kwargs)\n\n        wrapper = dec(wrapper)\n\n        return wrapper",
  "def wrapper(**kwargs):\n            to_group = {}\n            for name in argnames:\n                if name not in kwargs:\n                    raise ValueError(\n                        f\"When trying to group CLI options into {option_name}, \"\n                        f\"{name} was not found among arguments\")\n                to_group[name] = kwargs[name]\n                del kwargs[name]\n\n            kwargs[option_name] = option_class(**to_group)\n            return func(**kwargs)",
  "def wrapper(**kwargs):\n            if name not in kwargs:\n                raise ValueError(\n                        f\"When trying to wrap a CLI option with {handler}, \"\n                        f\"{name} was not found among arguments\")\n            option_val = kwargs[name]\n            option_name, new_val = handler(option_val)\n            del kwargs[name]\n            kwargs[option_name] = new_val\n            return func(**kwargs)",
  "def select_client_account(emitter,\n                          eth_provider_uri: str = None,\n                          signer: Signer = None,\n                          signer_uri: str = None,\n                          prompt: str = None,\n                          default: int = 0,\n                          registry: BaseContractRegistry = None,\n                          show_eth_balance: bool = False,\n                          show_nu_balance: bool = False,\n                          show_staking: bool = False,\n                          network: str = None,\n                          poa: bool = None\n                          ) -> str:\n    \"\"\"\n    Interactively select an ethereum wallet account from a table of nucypher account metadata.\n\n    Note: Showing ETH and/or NU balances, causes an eager blockchain connection.\n    \"\"\"\n\n    if signer and signer_uri:\n        raise ValueError('Pass either signer or signer_uri but not both.')\n\n    if not any((eth_provider_uri, signer_uri, signer)):\n        raise ValueError(\"At least a provider URI, signer URI or signer must be provided to select an account\")\n\n    if eth_provider_uri:\n        # Connect to the blockchain in order to select an account\n        if not BlockchainInterfaceFactory.is_interface_initialized(eth_provider_uri=eth_provider_uri):\n            BlockchainInterfaceFactory.initialize_interface(eth_provider_uri=eth_provider_uri, poa=poa, emitter=emitter)\n        if not signer_uri:\n            signer_uri = eth_provider_uri\n\n    blockchain = BlockchainInterfaceFactory.get_interface(eth_provider_uri=eth_provider_uri)\n\n    if signer_uri and not signer:\n        testnet = network != NetworksInventory.MAINNET\n        signer = Signer.from_signer_uri(signer_uri, testnet=testnet)\n\n    # Display accounts info\n    if show_nu_balance or show_staking:  # Lazy registry fetching\n        if not registry:\n            if not network:\n                raise ValueError(\"Pass network name or registry; Got neither.\")\n            registry = InMemoryContractRegistry.from_latest_publication(network=network)\n\n    enumerated_accounts = dict(enumerate(signer.accounts))\n    if len(enumerated_accounts) < 1:\n        emitter.echo(NO_ETH_ACCOUNTS, color='red', bold=True)\n        raise click.Abort()\n    elif len(enumerated_accounts) == 1:\n        # There are no choices if there is only one available address.\n        return enumerated_accounts[0]\n\n    # Display account info\n    headers = ['Account']\n    if show_staking:\n        headers.append('Staking')\n    if show_eth_balance:\n        headers.append('ETH')\n    if show_nu_balance:\n        headers.append('NU')\n\n    rows = list()\n    for index, account in enumerated_accounts.items():\n        row = [account]\n        if show_staking:\n            staker = Staker(domain=network, checksum_address=account, registry=registry)\n            staker.refresh_stakes()\n            is_staking = 'Yes' if bool(staker.stakes) else 'No'\n            row.append(is_staking)\n        if show_eth_balance:\n            ether_balance = Web3.from_wei(blockchain.client.get_balance(account), 'ether')\n            row.append(f'{ether_balance} ETH')\n        if show_nu_balance:\n            token_agent = ContractAgency.get_agent(NucypherTokenAgent, registry=registry)\n            token_balance = NU.from_units(token_agent.get_balance(account, registry))\n            row.append(token_balance)\n        rows.append(row)\n    emitter.echo(tabulate(rows, headers=headers, showindex='always'))\n\n    # Prompt the user for selection, and return\n    prompt = prompt or GENERIC_SELECT_ACCOUNT\n    account_range = click.IntRange(min=0, max=len(enumerated_accounts)-1)\n    choice = click.prompt(prompt, type=account_range, default=default)\n    chosen_account = enumerated_accounts[choice]\n\n    emitter.echo(SELECTED_ACCOUNT.format(choice=choice, chosen_account=chosen_account), color='blue')\n    return chosen_account",
  "def select_network(emitter: StdoutEmitter, network_type: str, message: Optional[str] = None) -> str:\n    \"\"\"Interactively select a network from nucypher networks inventory list\"\"\"\n    emitter.message(message=message or str(), color=\"yellow\")\n    if network_type == NetworksInventory.ETH:\n        network_list = NetworksInventory.ETH_NETWORKS\n    elif network_type == NetworksInventory.POLYGON:\n        network_list = NetworksInventory.POLY_NETWORKS\n    else:\n        raise(ValueError(\"Network type must be either 'eth' or 'polygon'\"))\n    rows = [[n] for n in network_list]\n    emitter.echo(tabulate(rows, showindex=\"always\"))\n    choice = click.prompt(\n        SELECT_NETWORK,\n        default=0,\n        type=click.IntRange(0, len(rows) - 1),\n    )\n    network = network_list[choice]\n    return network",
  "def select_config_file(emitter: StdoutEmitter,\n                       config_class: Type[CharacterConfiguration],\n                       config_root: Optional[Path] = None,\n                       checksum_address: str = None,\n                       ) -> Path:\n    \"\"\"\n    Selects a nucypher character configuration file from the disk automatically or interactively.\n\n    Behaviour\n    ~~~~~~~~~\n\n    - If checksum address is supplied by parameter or operator address env var - confirm there is a corresponding\n      file on the disk or raise ValueError.\n\n    - If there is only one configuration file for the character, automatically return its filepath.\n\n    - If there are multiple character configurations on the disk in the same configuration root,\n      use interactive selection.\n\n    - Aborts if there are no configurations associated with the supplied character configuration class.\n\n    \"\"\"\n\n    config_root = config_root or DEFAULT_CONFIG_ROOT\n    config_files = get_config_filepaths(config_class=config_class, config_root=config_root)\n    if not config_files:\n        emitter.message(NO_CONFIGURATIONS_ON_DISK.format(name=config_class.NAME.capitalize(),\n                                                         command=config_class.NAME), color='red')\n        raise click.Abort()\n\n    checksum_address = checksum_address or os.environ.get(NUCYPHER_ENVVAR_OPERATOR_ADDRESS, None)  # TODO: Deprecate operator_address in favor of checksum_address\n\n    parsed_config_files = list()\n    parsed_addresses_and_filenames = list()\n    # parse configuration files for checksum address values\n    for fp in config_files:\n        try:\n            config_checksum_address = config_class.checksum_address_from_filepath(fp)\n            if checksum_address and config_checksum_address == checksum_address:\n                # matching configuration file found, no need to continue - return filepath\n                return fp\n\n            parsed_config_files.append(fp)\n            parsed_addresses_and_filenames.append([config_checksum_address, Path(fp).name])  # store checksum & filename\n        except config_class.OldVersion:\n            # no use causing entire usage to crash if file can't be used anyway - inform the user; they can\n            # decide for themself\n            emitter.echo(IGNORE_OLD_CONFIGURATION.format(config_file=fp), color='yellow')\n\n    if checksum_address:\n        # shouldn't get here if checksum address was specified and corresponding file found\n        raise ValueError(f\"'{checksum_address}' is not a known {config_class.NAME} configuration account.\")\n\n    if not parsed_config_files:\n        # No available configuration files\n        emitter.message(NO_CONFIGURATIONS_ON_DISK.format(name=config_class.NAME.capitalize(),\n                                                         command=config_class.NAME),\n                        color='red')\n        raise click.Abort()\n    elif len(parsed_config_files) > 1:\n        #\n        # Interactive\n        #\n        emitter.echo(f\"\\nConfiguration Directory: {config_root}\\n\")\n\n        parsed_addresses_and_filenames = tuple(parsed_addresses_and_filenames)  # must be tuple-of-iterables for tabulation\n\n        # Display account info\n        headers = ['Account', 'Configuration File']\n        emitter.echo(tabulate(parsed_addresses_and_filenames, headers=headers, showindex='always'))\n\n        # Prompt the user for selection, and return\n        prompt = f\"Select {config_class.NAME} configuration\"\n        account_range = click.IntRange(min=0, max=len(parsed_config_files) - 1)\n        choice = click.prompt(prompt, type=account_range, default=0)\n        config_file = parsed_config_files[choice]\n        emitter.echo(f\"Selected {choice}: {config_file}\", color='blue')\n    else:\n        # Default: Only one config file, use it.\n        config_file = parsed_config_files[0]\n        emitter.echo(DEFAULT_TO_LONE_CONFIG_FILE.format(config_class=config_class.NAME.capitalize(),\n                                                        config_file=config_file))\n\n    return config_file",
  "def get_password_from_prompt(prompt: str = GENERIC_PASSWORD_PROMPT, envvar: str = None, confirm: bool = False) -> str:\n    \"\"\"Collect a password interactively, preferring an env var is one is provided and set.\"\"\"\n    password = NO_PASSWORD\n    if envvar:\n        password = os.environ.get(envvar, NO_PASSWORD)\n    if password is NO_PASSWORD:  # Collect password, prefer env var\n        password = click.prompt(prompt, confirmation_prompt=confirm, hide_input=True)\n    return password",
  "def get_client_password(checksum_address: str, envvar: str = None, confirm: bool = False) -> str:\n    \"\"\"Interactively collect an ethereum client password\"\"\"\n    client_password = get_password_from_prompt(prompt=COLLECT_ETH_PASSWORD.format(checksum_address=checksum_address),\n                                               envvar=envvar,\n                                               confirm=confirm)\n    return client_password",
  "def unlock_signer_account(config: CharacterConfiguration, json_ipc: bool) -> None:\n\n    # TODO: Remove this block after deprecating 'operator_address'\n    from nucypher.config.characters import UrsulaConfiguration\n    if isinstance(config, UrsulaConfiguration):\n        account = config.operator_address\n    else:\n        account = config.checksum_address\n\n    eth_password_is_needed = all((not config.federated_only,\n                                  not config.signer.is_device(account=account),\n                                  not config.dev_mode))\n\n    __password = None\n    if eth_password_is_needed:\n        if json_ipc and not os.environ.get(config.SIGNER_ENVVAR):\n            raise ValueError(f'{config.SIGNER_ENVVAR} is required to use JSON IPC mode.')\n        __password = get_client_password(checksum_address=account, envvar=config.SIGNER_ENVVAR)\n    config.signer.unlock_account(account=config.checksum_address, password=__password)",
  "def get_nucypher_password(emitter, confirm: bool = False, envvar=NUCYPHER_ENVVAR_KEYSTORE_PASSWORD) -> str:\n    \"\"\"Interactively collect a nucypher password\"\"\"\n    prompt = COLLECT_NUCYPHER_PASSWORD\n    if confirm:\n        emitter.message(PASSWORD_COLLECTION_NOTICE)\n        prompt += f\" ({Keystore._MINIMUM_PASSWORD_LENGTH} character minimum)\"\n    keystore_password = get_password_from_prompt(prompt=prompt, confirm=confirm, envvar=envvar)\n    return keystore_password",
  "def unlock_nucypher_keystore(emitter: StdoutEmitter, password: str, character_configuration: CharacterConfiguration) -> bool:\n    \"\"\"Unlocks a nucypher keystore and attaches it to the supplied configuration if successful.\"\"\"\n    emitter.message(DECRYPTING_CHARACTER_KEYSTORE.format(name=character_configuration.NAME.capitalize()), color='yellow')\n\n    # precondition\n    if character_configuration.dev_mode:\n        return True  # Dev accounts are always unlocked\n\n    # unlock\n    character_configuration.keystore.unlock(password=password)  # Takes ~3 seconds, ~1GB Ram\n    return True",
  "def recover_keystore(emitter) -> None:\n    emitter.message('This procedure will recover your nucypher keystore from mnemonic seed words. '\n                    'You will need to provide the entire mnemonic (space seperated) in the correct '\n                    'order and choose a new password.', color='cyan')\n    click.confirm('Do you want to continue', abort=True)\n    __words = click.prompt(\"Enter nucypher keystore seed words\")\n    word_count = len(__words.split())\n    if word_count != _WORD_COUNT:\n        emitter.message(f'Invalid mnemonic - Number of words must be {str(_WORD_COUNT)}, but only got {word_count}')\n    __password = get_nucypher_password(emitter=emitter, confirm=True)\n    keystore = Keystore.restore(words=__words, password=__password)\n    emitter.message(f'Recovered nucypher keystore {keystore.id} to \\n {keystore.keystore_path}', color='green')",
  "def forget(emitter: StdoutEmitter, configuration: CharacterConfiguration) -> None:\n    \"\"\"Forget all known nodes via storage\"\"\"\n    click.confirm(CONFIRM_FORGET_NODES, abort=True)\n    configuration.forget_nodes()\n    emitter.message(SUCCESSFUL_FORGET_NODES, color='red')",
  "def get_config_filepaths(config_class: Type[CharacterConfiguration], config_root: Optional[Path] = None) -> List:\n    #\n    # Scrape disk for configuration files\n    #\n    config_root = config_root or DEFAULT_CONFIG_ROOT\n    default_config_file = glob.glob(str(config_class.default_filepath(config_root=config_root)))\n\n    # updated glob pattern for secondary configuration files accommodates for:\n    # 1. configuration files with \"0x...\" checksum address as suffix - including older ursula config files\n    # 2. newer (ursula) configuration files which use signing_pub_key[:8] as hex as the suffix\n    glob_pattern = f'{config_root.absolute()}/{config_class.NAME}-[0-9a-fA-F]*.{config_class._CONFIG_FILE_EXTENSION}'\n\n    secondary_config_files = sorted(glob.glob(glob_pattern))  # sort list to make order deterministic\n    config_files = [*default_config_file, *secondary_config_files]\n    config_files = [Path(f) for f in config_files]\n    return config_files",
  "def get_or_update_configuration(emitter: StdoutEmitter,\n                                filepath: Path,\n                                config_class: Type[CharacterConfiguration],\n                                updates: Optional[dict] = None) -> None:\n    \"\"\"\n    Utility for writing updates to an existing configuration file then displaying the result.\n    If the config file is invalid, try very hard to display the problem.  If there are no updates,\n    the config file will be displayed without changes.\n    \"\"\"\n    try:\n        config = config_class.from_configuration_file(filepath=filepath)\n    except FileNotFoundError:\n        return handle_missing_configuration_file(character_config_class=config_class, config_file=filepath)\n    except config_class.ConfigurationError:\n        return handle_invalid_configuration_file(emitter=emitter, config_class=config_class, filepath=filepath)\n\n    emitter.echo(f\"{config_class.NAME.capitalize()} Configuration {filepath} \\n {'='*55}\")\n    if updates:\n        pretty_fields = ', '.join(updates)\n        emitter.message(SUCCESSFUL_UPDATE_CONFIGURATION_VALUES.format(fields=pretty_fields), color='yellow')\n        config.update(**updates)\n    emitter.echo(config.serialize())",
  "def destroy_configuration(emitter: StdoutEmitter,\n                          character_config: CharacterConfiguration,\n                          force: bool = False) -> None:\n    \"\"\"Destroy a character configuration and report rhe result with an emitter.\"\"\"\n    if not force:\n        confirm_destroy_configuration(config=character_config)\n    character_config.destroy()\n    emitter.message(SUCCESSFUL_DESTRUCTION, color='green')\n    character_config.log.debug(SUCCESSFUL_DESTRUCTION)",
  "def handle_missing_configuration_file(character_config_class: Type[CharacterConfiguration],\n                                      init_command_hint: str = None,\n                                      config_file: Optional[Path] = None) -> None:\n    \"\"\"Display a message explaining there is no configuration file to use and abort the current operation.\"\"\"\n    config_file_location = config_file or character_config_class.default_filepath()\n    init_command = init_command_hint or f\"{character_config_class.NAME} init\"\n    name = character_config_class.NAME.capitalize()\n    message = MISSING_CONFIGURATION_FILE.format(name=name, init_command=init_command)\n    raise click.FileError(filename=str(config_file_location.absolute()), hint=message)",
  "def handle_invalid_configuration_file(emitter: StdoutEmitter,\n                                      config_class: Type[CharacterConfiguration],\n                                      filepath: Path) -> None:\n    \"\"\"\n    Attempt to deserialize a config file that is not a valid nucypher character configuration\n    as a means of user-friendly debugging. :-)  I hope this helps!\n    \"\"\"\n    # Issue warning for invalid configuration...\n    emitter.message(INVALID_CONFIGURATION_FILE_WARNING.format(filepath=filepath))\n    try:\n        # ... but try to display it anyways\n        response = config_class._read_configuration_file(filepath=filepath)\n        emitter.echo(json.dumps(response, indent=4))\n        raise config_class.ConfigurationError\n    except (TypeError, JSONDecodeError):\n        emitter.message(INVALID_JSON_IN_CONFIGURATION_WARNING.format(filepath=filepath))\n        # ... sorry.. we tried as hard as we could\n        raise",
  "def collect_operator_ip_address(emitter: StdoutEmitter, network: str, force: bool = False) -> str:\n\n    # From node swarm\n    try:\n        message = f'Detecting external IP address automatically'\n        emitter.message(message, verbosity=2)\n        ip = determine_external_ip_address(network=network)\n    except UnknownIPAddress:\n        if force:\n            raise\n        emitter.message('Cannot automatically determine external IP address - input required')\n        ip = click.prompt(COLLECT_URSULA_IPV4_ADDRESS, type=OPERATOR_IP)\n\n    # Confirmation\n    if not force:\n        if not click.confirm(CONFIRM_URSULA_IPV4_ADDRESS.format(rest_host=ip)):\n            ip = click.prompt(COLLECT_URSULA_IPV4_ADDRESS, type=OPERATOR_IP)\n\n    validate_operator_ip(ip=ip)\n    return ip",
  "def perform_startup_ip_check(emitter: StdoutEmitter, ursula: Ursula, force: bool = False) -> None:\n    \"\"\"\n    Used on ursula startup to determine if the external\n    IP address is consistent with the configuration's values.\n    \"\"\"\n    try:\n        external_ip = determine_external_ip_address(network=ursula.domain, known_nodes=ursula.known_nodes)\n    except UnknownIPAddress:\n        message = 'Cannot automatically determine external IP address'\n        emitter.message(message)\n        return  # TODO: crash, or not to crash... that is the question\n    rest_host = ursula.rest_interface.host\n    try:\n        validate_operator_ip(ip=rest_host)\n    except InvalidOperatorIP:\n        message = f'{rest_host} is not a valid or permitted operator IP address.  Set the correct external IP then try again\\n' \\\n                  f'automatic configuration -> nucypher ursula config ip-address\\n' \\\n                  f'manual configuration    -> nucypher ursula config --rest-host <IP ADDRESS>'\n        emitter.message(message)\n        return\n\n    ip_mismatch = external_ip != rest_host\n    if ip_mismatch and not force:\n        error = f'\\nx External IP address ({external_ip}) does not match configuration ({ursula.rest_interface.host}).\\n'\n        hint = f\"Run 'nucypher ursula config ip-address' to reconfigure the IP address then try \" \\\n               f\"again or use --no-ip-checkup to bypass this check (not recommended).\\n\"\n        emitter.message(error, color='red')\n        emitter.message(hint, color='yellow')\n        raise click.Abort()\n    else:\n        emitter.message('\u2713 External IP matches configuration', 'green')",
  "def confirm_deployment(emitter: StdoutEmitter, deployer_interface: BlockchainDeployerInterface) -> bool:\n    \"\"\"\n    Interactively confirm deployment by asking the user to type the ALL CAPS name of\n    the network they are deploying to or 'DEPLOY' if the network if not a known public chain.\n\n    Aborts if the confirmation word is incorrect.\n    \"\"\"\n    if deployer_interface.client.chain_name == UNKNOWN_DEVELOPMENT_CHAIN_ID or deployer_interface.client.is_local:\n        expected_chain_name = 'DEPLOY'\n    else:\n        expected_chain_name = deployer_interface.client.chain_name\n    if click.prompt(f\"Type '{expected_chain_name.upper()}' to continue\") != expected_chain_name.upper():\n        emitter.echo(ABORT_DEPLOYMENT, color='red', bold=True)\n        raise click.Abort(ABORT_DEPLOYMENT)\n    return True",
  "def confirm_destroy_configuration(config: CharacterConfiguration) -> bool:\n    \"\"\"Interactively confirm destruction of nucypher configuration files\"\"\"\n    # TODO: This is a workaround for ursula - needs follow up\n    confirmation = CHARACTER_DESTRUCTION.format(name=config.NAME,\n                                                root=config.config_root,\n                                                keystore=config.keystore_dir,\n                                                nodestore=config.node_storage.source,\n                                                config=config.filepath)\n    click.confirm(confirmation, abort=True)\n    return True",
  "def verify_upgrade_details(blockchain: Union[BlockchainDeployerInterface, BlockchainInterface],\n                           registry: LocalContractRegistry,\n                           deployer: Type[BaseContractDeployer],\n                           ) -> None:\n    \"\"\"\n    Compares the versions of two 'implementation' contracts using a local and source registry.\n    \"\"\"\n\n    old_contract: VersionedContract = blockchain.get_contract_by_name(\n        registry=registry,\n        contract_name=deployer.contract_name,\n        proxy_name=deployer.agency._proxy_name,\n        use_proxy_address=False\n    )\n\n    new_contract = blockchain.find_raw_contract_data(contract_name=deployer.contract_name)\n    new_version = new_contract[0]  # Handle index error?\n\n    click.confirm(CONFIRM_VERSIONED_UPGRADE.format(contract_name=deployer.contract_name,\n                                                   old_version=old_contract.version,\n                                                   new_version=new_version), abort=True)",
  "def paint_staged_deployment(emitter, deployer_interface, administrator) -> None:\n    emitter.clear()\n    emitter.banner(NU_BANNER)\n    emitter.echo(f\"Current Time ........ {maya.now().iso8601()}\")\n    emitter.echo(f\"ETH Provider URI .... {deployer_interface.eth_provider_uri}\")\n    emitter.echo(f\"Block ............... {deployer_interface.client.block_number}\")\n    emitter.echo(f\"Gas Price ........... {deployer_interface.client.gas_price}\")\n    emitter.echo(f\"Deployer Address .... {administrator.checksum_address}\")\n    emitter.echo(f\"ETH ................. {administrator.eth_balance}\")\n    emitter.echo(f\"Chain ID ............ {deployer_interface.client.chain_id}\")\n    emitter.echo(f\"Chain Name .......... {deployer_interface.client.chain_name}\")\n\n    # Ask - Last chance to gracefully abort. This step cannot be forced.\n    emitter.echo(\"\\nDeployment successfully staged.\", color='green')",
  "def paint_contract_deployment(emitter,\n                              contract_name: str,\n                              contract_address: str,\n                              receipts: dict,\n                              chain_name: str = None,\n                              open_in_browser: bool = False):\n    # TODO: switch to using an explicit emitter\n\n    is_token_contract = contract_name == NUCYPHER_TOKEN_CONTRACT_NAME\n\n    # Paint heading\n    heading = f'\\r{\" \"*80}\\n{contract_name} ({contract_address})'\n    emitter.echo(heading, bold=True)\n    emitter.echo('*' * (42 + 3 + len(contract_name)))\n    try:\n        url = etherscan_url(item=contract_address, network=chain_name, is_token=is_token_contract)\n    except ValueError as e:\n        emitter.log.info(\"Failed Etherscan URL construction: \" + str(e))\n    else:\n        emitter.echo(f\" See {url}\\n\")\n\n    # Paint Transactions\n    for tx_name, receipt in receipts.items():\n        paint_receipt_summary(emitter=emitter,\n                              receipt=receipt,\n                              chain_name=chain_name,\n                              transaction_type=tx_name)\n\n    if open_in_browser:\n        try:\n            url = etherscan_url(item=contract_address,\n                                network=chain_name,\n                                is_token=is_token_contract)\n        except ValueError as e:\n            emitter.log.info(\"Failed Etherscan URL construction: \" + str(e))\n        else:\n            webbrowser.open_new_tab(url)",
  "def paint_deployer_contract_inspection(emitter, registry, deployer_address) -> None:\n\n    blockchain = BlockchainInterfaceFactory.get_interface()\n\n    sep = '-' * 45\n    emitter.echo(sep)\n\n    provider_info = f\"\"\"\n\n* Web3 Provider\n====================================================================\n\nETH Provider URI ......... {blockchain.eth_provider_uri}\nRegistry  ................ {registry.filepath}\n\n* Standard Deployments\n=====================================================================\n\"\"\"\n    emitter.echo(provider_info)\n\n    try:\n        token_agent = ContractAgency.get_agent(NucypherTokenAgent, registry=registry)\n        token_contract_info = f\"\"\"\n\n{token_agent.contract_name} ........... {token_agent.contract_address}\n    ~ Ethers ............ {Web3.from_wei(blockchain.client.get_balance(token_agent.contract_address), 'ether')} ETH\n    ~ Tokens ............ {NU.from_units(token_agent.get_balance(token_agent.contract_address))}\"\"\"\n    except BaseContractRegistry.UnknownContract:\n        message = f\"\\n{NucypherTokenAgent.contract_name} is not enrolled in {registry.filepath}\"\n        emitter.echo(message, color='yellow')\n        emitter.echo(sep, nl=False)\n    else:\n        emitter.echo(token_contract_info)\n\n    banner = \"\"\"\n* Proxy-Contract Deployments\n=====================================================================\"\"\"\n    emitter.echo(banner)\n\n    from nucypher.blockchain.eth.actors import ContractAdministrator\n    for contract_deployer_class in ContractAdministrator.dispatched_upgradeable_deployer_classes:\n        try:\n            bare_contract = blockchain.get_contract_by_name(contract_name=contract_deployer_class.contract_name,\n                                                            proxy_name=DispatcherDeployer.contract_name,\n                                                            registry=registry,\n                                                            use_proxy_address=False)\n\n            dispatcher_deployer = DispatcherDeployer(registry=registry,\n                                                     target_contract=bare_contract,\n                                                     bare=True)  # acquire agency for the dispatcher itself.\n\n            agent = contract_deployer_class.agency(registry=registry, contract=bare_contract)\n\n            proxy_payload = f\"\"\"\n{agent.contract_name} .... {bare_contract.address}\n    ~ Version ............ {bare_contract.version}\n    ~ Owner .............. {bare_contract.functions.owner().call()}\n    ~ Ethers ............. {Web3.from_wei(blockchain.client.get_balance(bare_contract.address), 'ether')} ETH\n    ~ Tokens ............. {NU.from_units(token_agent.get_balance(bare_contract.address))}\n    ~ Dispatcher ......... {dispatcher_deployer.contract_address}\n        ~ Owner .......... {dispatcher_deployer.contract.functions.owner().call()}\n        ~ Target ......... {dispatcher_deployer.contract.functions.target().call()}\n        ~ Ethers ......... {Web3.from_wei(blockchain.client.get_balance(dispatcher_deployer.contract_address), 'ether')} ETH\n        ~ Tokens ......... {NU.from_units(token_agent.get_balance(dispatcher_deployer.contract_address))}\"\"\"\n            emitter.echo(proxy_payload)\n            emitter.echo(sep, nl=False)\n\n        except BaseContractRegistry.UnknownContract:\n            message = f\"\\n{contract_deployer_class.contract_name} is not enrolled in {registry.filepath}\"\n            emitter.echo(message, color='yellow')\n            emitter.echo(sep, nl=False)",
  "def paint_contract_status(registry, emitter):\n    blockchain = BlockchainInterfaceFactory.get_interface()\n    application_agent = ContractAgency.get_agent(PREApplicationAgent, registry=registry)\n    contracts = f\"\"\"\n| Contract Deployments |\n{application_agent.contract_name} .............. {application_agent.contract_address}\n    \"\"\"\n\n    blockchain = f\"\"\"\n| '{blockchain.client.chain_name}' Blockchain Network |\nGas Price ................ {Web3.from_wei(blockchain.client.gas_price, 'gwei')} Gwei\nETH Provider URI ......... {blockchain.eth_provider_uri}\nRegistry ................. {registry.filepath}\n    \"\"\"\n\n    staking = f\"\"\"\n| PREApplication |\nStaking Provider Population ....... {application_agent.get_staking_providers_population()}\n    \"\"\"\n\n    sep = '-' * 45\n    emitter.echo(sep)\n    emitter.echo(contracts)\n    emitter.echo(sep)\n    emitter.echo(blockchain)\n    emitter.echo(sep)\n    emitter.echo(staking)\n    emitter.echo(sep)",
  "def build_fleet_state_status(ursula) -> str:\n    return str(ursula.known_nodes.current_state)",
  "def paint_node_status(emitter, ursula, start_time):\n    ursula.mature()  # Just to be sure\n\n    # Build Learning status line\n    learning_status = \"Unknown\"\n    if ursula._learning_task.running:\n        learning_status = \"Learning at {}s Intervals\".format(ursula._learning_task.interval)\n    elif not ursula._learning_task.running:\n        learning_status = \"Not Learning\"\n\n    teacher = 'Current Teacher ..... No Teacher Connection'\n    if ursula._current_teacher_node:\n        teacher = 'Current Teacher ..... {}'.format(ursula._current_teacher_node)\n\n    # Build FleetState status line\n    fleet_state = build_fleet_state_status(ursula=ursula)\n\n    stats = ['\u21c0URSULA {}\u21bd'.format(ursula.nickname.icon),\n             '{}'.format(ursula),\n             'Uptime .............. {}'.format(maya.now() - start_time),\n             'Start Time .......... {}'.format(start_time.slang_time()),\n             'Fleet State.......... {}'.format(fleet_state),\n             'Learning Status ..... {}'.format(learning_status),\n             'Learning Round ...... Round #{}'.format(ursula._learning_round),\n             'Operating Mode ...... {}'.format('Federated' if ursula.federated_only else 'Decentralized'),\n             'Rest Interface ...... {}'.format(ursula.rest_url()),\n             'Node Storage Type ... {}'.format(ursula.node_storage._name.capitalize()),\n             'Known Nodes ......... {}'.format(len(ursula.known_nodes)),\n             teacher]\n\n    if not ursula.federated_only:\n        operator_address = 'Operator Address ...... {}'.format(ursula.operator_address)\n        current_period = f'Current Period ...... {ursula.application_agent.get_current_period()}'\n        stats.extend([current_period, operator_address])\n\n    if ursula._availability_tracker:\n        if ursula._availability_tracker.running:\n            score = 'Availability Score .. {} ({} responders)'.format(ursula._availability_tracker.score, len(ursula._availability_tracker.responders))\n        else:\n            score = 'Availability Score .. Disabled'\n\n        stats.append(score)\n\n    emitter.echo('\\n' + '\\n'.join(stats) + '\\n')",
  "def paint_known_nodes(emitter, ursula) -> None:\n    # Gather Data\n    known_nodes = ursula.known_nodes\n    number_of_known_nodes = len(ursula.node_storage.all(federated_only=ursula.federated_only))\n    seen_nodes = len(ursula.node_storage.all(federated_only=ursula.federated_only, certificates_only=True))\n\n    # Operating Mode\n    federated_only = ursula.federated_only\n    if federated_only:\n        emitter.echo(\"Configured in Federated Only mode\", color='green')\n\n    # Heading\n    label = \"Known Nodes (connected {} / seen {})\".format(number_of_known_nodes, seen_nodes)\n    heading = '\\n' + label + \" \" * (45 - len(label))\n    emitter.echo(heading, bold=True)\n\n    # Build FleetState status line\n    fleet_state = build_fleet_state_status(ursula=ursula)\n    fleet_status_line = 'Fleet State {}'.format(fleet_state)\n    emitter.echo(fleet_status_line, color='blue', bold=True)\n\n    # Legend\n    color_index = {\n        'self': 'yellow',\n        'known': 'white',\n        'seednode': 'blue'\n    }\n\n    # Legend\n    # for node_type, color in color_index.items():\n    #     emitter.echo('{0:<6} | '.format(node_type), color=color, nl=False)\n    # emitter.echo('\\n')\n\n    seednode_addresses = list(bn.checksum_address for bn in SEEDNODES)\n\n    for node in known_nodes:\n        row_template = \"{} | {}\"\n        node_type = 'known'\n        if node.checksum_address == ursula.checksum_address:\n            node_type = 'self'\n            row_template += ' ({})'.format(node_type)\n        elif node.checksum_address in seednode_addresses:\n            node_type = 'seednode'\n            row_template += ' ({})'.format(node_type)\n        emitter.echo(row_template.format(node.rest_url().ljust(20), node), color=color_index[node_type])",
  "def paint_receipt_summary(emitter, receipt, chain_name: str = None, transaction_type=None, eth_provider_uri: str = None):\n    tx_hash = receipt['transactionHash'].hex()\n    emitter.echo(\"OK\", color='green', nl=False, bold=True)\n    if transaction_type:\n        emitter.echo(f\" | {transaction_type} | {tx_hash}\", color='yellow', nl=False)\n    else:\n        emitter.echo(f\" | {tx_hash}\", color='yellow', nl=False)\n    emitter.echo(f\" ({receipt['gasUsed']} gas)\")\n    emitter.echo(f\"Block #{receipt['blockNumber']} | {receipt['blockHash'].hex()}\")\n\n    if not chain_name:\n        blockchain = BlockchainInterfaceFactory.get_interface(eth_provider_uri=eth_provider_uri)\n        chain_name = blockchain.client.chain_name\n    try:\n        url = etherscan_url(item=tx_hash, network=chain_name)\n    except ValueError as e:\n        emitter.log.info(\"Failed Etherscan URL construction: \" + str(e))\n    else:\n        emitter.echo(f\" See {url}\\n\")",
  "def echo_version(ctx, param, value):\n    if not value or ctx.resilient_parsing:\n        return\n    click.secho(NUCYPHER_BANNER, bold=True)\n    ctx.exit()",
  "def echo_solidity_version(ctx, param, value):\n    if not value or ctx.resilient_parsing:\n        return\n    click.secho(f\"Supported solidity version: {SOLIDITY_COMPILER_VERSION}\", bold=True)\n    ctx.exit()",
  "def echo_config_root_path(ctx, param, value):\n    if not value or ctx.resilient_parsing:\n        return\n    click.secho(str(DEFAULT_CONFIG_ROOT.absolute()))\n    ctx.exit()",
  "def echo_logging_root_path(ctx, param, value):\n    if not value or ctx.resilient_parsing:\n        return\n    click.secho(str(USER_LOG_DIR.absolute()))\n    ctx.exit()",
  "def paint_new_installation_help(emitter, new_configuration, filepath):\n    character_config_class = new_configuration.__class__\n    character_name = character_config_class.NAME.lower()\n    if new_configuration.keystore != NO_KEYSTORE_ATTACHED:\n        maybe_public_key = new_configuration.keystore.id\n    else:\n        maybe_public_key = \"(no keystore attached)\"\n    emitter.message(f\"Generated keystore\", color='green')\n    emitter.message(f\"\"\"\n    \nPublic Key:   {maybe_public_key}\nPath to Keystore: {new_configuration.keystore_dir}\n\n- You can share your public key with anyone. Others need it to interact with you.\n- Never share secret keys with anyone! \n- Backup your keystore! Character keys are required to interact with the protocol!\n- Remember your password! Without the password, it's impossible to decrypt the key!\n\n\"\"\")\n\n    default_config_filepath = True\n    if new_configuration.default_filepath() != filepath:\n        default_config_filepath = False\n    emitter.message(f'Generated configuration file at {\"default\" if default_config_filepath else \"non-default\"} '\n                    f'filepath {filepath}', color='green')\n\n    # add hint about --config-file\n    if not default_config_filepath:\n        emitter.message(f'* NOTE: for a non-default configuration filepath use `--config-file \"{filepath}\"` '\n                        f'with subsequent `{character_name}` CLI commands', color='yellow')\n\n    # Ursula\n    if character_name == 'ursula':\n        hint = '''\n* Review configuration  -> nucypher ursula config\n* Start working         -> nucypher ursula run\n'''\n\n    else:\n        raise ValueError(f'Unknown character type \"{character_name}\"')\n\n    emitter.echo(hint, color='green')",
  "class ActorOptions:\n\n    __option_name__ = 'actor_options'\n\n    def __init__(self,\n                 eth_provider_uri: str,\n                 deployer_address: str,\n                 contract_name: str,\n                 registry_infile: Path,\n                 registry_outfile: Path,\n                 hw_wallet: bool,\n                 dev: bool,\n                 force: bool,\n                 poa: bool,\n                 config_root: Path,\n                 etherscan: bool,\n                 ignore_solidity_check,\n                 gas_strategy: str,\n                 max_gas_price: int,  # gwei\n                 signer_uri: str,\n                 network: str\n                 ):\n\n        self.eth_provider_uri = eth_provider_uri\n        self.signer_uri = signer_uri\n        self.gas_strategy = gas_strategy\n        self.max_gas_price = max_gas_price\n        self.deployer_address = deployer_address\n        self.contract_name = contract_name\n        self.registry_infile = registry_infile\n        self.registry_outfile = registry_outfile\n        self.hw_wallet = hw_wallet\n        self.dev = dev\n        self.force = force\n        self.config_root = config_root\n        self.etherscan = etherscan\n        self.poa = poa\n        self.ignore_solidity_check = ignore_solidity_check\n        self.network = network\n\n    def create_actor(self,\n                     emitter: StdoutEmitter,\n                     ) -> Tuple[ContractAdministrator, str, BlockchainInterface, BaseContractRegistry]:\n\n        ensure_config_root(self.config_root)\n        deployer_interface = initialize_deployer_interface(poa=self.poa,\n                                                           eth_provider_uri=self.eth_provider_uri,\n                                                           emitter=emitter,\n                                                           ignore_solidity_check=self.ignore_solidity_check,\n                                                           gas_strategy=self.gas_strategy,\n                                                           max_gas_price=self.max_gas_price)\n\n        # Warnings\n        deployer_pre_launch_warnings(emitter, self.etherscan, self.hw_wallet)\n\n        #\n        # Establish Registry\n        #\n\n        local_registry = establish_deployer_registry(emitter=emitter,\n                                                     use_existing_registry=bool(self.contract_name),  # TODO: Issue #2314\n                                                     registry_infile=self.registry_infile,\n                                                     registry_outfile=self.registry_outfile,\n                                                     dev=self.dev,\n                                                     network=self.network)\n        #\n        # Make Authenticated Deployment Actor\n        #\n\n        # Verify Address & collect password\n        testnet = deployer_interface.client.chain_name != PUBLIC_CHAINS[1]  # Mainnet\n        signer = Signer.from_signer_uri(self.signer_uri, testnet=testnet)\n        deployer_address = self.deployer_address\n        if not deployer_address:\n            deployer_address = select_client_account(emitter=emitter,\n                                                     prompt=SELECT_DEPLOYER_ACCOUNT,\n                                                     registry=local_registry,\n                                                     eth_provider_uri=self.eth_provider_uri,\n                                                     signer=signer,\n                                                     show_eth_balance=True)\n\n        if not self.force:\n            click.confirm(CONFIRM_SELECTED_ACCOUNT.format(address=deployer_address), abort=True)\n\n        # Authenticate\n        password_required = all((not signer.is_device(account=deployer_address),\n                                 not deployer_interface.client.is_local,\n                                 not self.hw_wallet))\n        if password_required:\n            password = get_client_password(checksum_address=deployer_address)\n            signer.unlock_account(password=password, account=deployer_address)\n        transacting_power = TransactingPower(signer=signer, account=deployer_address)\n\n        # Produce Actor\n        ADMINISTRATOR = ContractAdministrator(registry=local_registry,\n                                              domain=self.network,\n                                              transacting_power=transacting_power)\n\n        # Verify ETH Balance\n        emitter.echo(DEPLOYER_BALANCE.format(eth_balance=ADMINISTRATOR.eth_balance))\n        if transacting_power and ADMINISTRATOR.eth_balance == 0:\n            emitter.echo(DEPLOYER_ADDRESS_ZERO_ETH, color='red', bold=True)\n            raise click.Abort()\n        return ADMINISTRATOR, deployer_address, deployer_interface, local_registry",
  "def deploy():\n    \"\"\"Manage contract and registry deployment.\"\"\"",
  "def download_registry(general_config, config_root, registry_outfile, network, force):\n    \"\"\"Download the latest registry.\"\"\"\n\n    # Setup\n    emitter = general_config.emitter\n    ensure_config_root(config_root)\n    github_source = GithubRegistrySource(network=network, registry_name=BaseContractRegistry.REGISTRY_NAME)\n    source_manager = RegistrySourceManager(sources=[github_source])\n\n    if not force:\n        prompt = CONFIRM_MANUAL_REGISTRY_DOWNLOAD.format(source=github_source)\n        click.confirm(prompt, abort=True)\n    try:\n        registry = InMemoryContractRegistry.from_latest_publication(source_manager=source_manager, network=network)\n    except RegistrySourceManager.NoSourcesAvailable:\n        emitter.message(REGISTRY_NOT_AVAILABLE, color=\"red\")\n        raise click.Abort\n\n    try:\n        output_filepath = registry.commit(filepath=registry_outfile, overwrite=force)\n    except InMemoryContractRegistry.CantOverwriteRegistry:\n        emitter.message(CANNOT_OVERWRITE_REGISTRY, color=\"red\")\n        raise click.Abort\n    emitter.message(SUCCESSFUL_REGISTRY_DOWNLOAD.format(output_filepath=output_filepath), color=\"green\")",
  "def inspect(general_config, eth_provider_uri, config_root, registry_infile, deployer_address,\n            poa, ignore_solidity_check, network):\n    \"\"\"Echo owner information and bare contract metadata.\"\"\"\n    emitter = general_config.emitter\n    ensure_config_root(config_root)\n    initialize_deployer_interface(poa=poa,\n                                  eth_provider_uri=eth_provider_uri,\n                                  emitter=emitter,\n                                  ignore_solidity_check=ignore_solidity_check)\n    download_required = not bool(registry_infile)\n    registry = establish_deployer_registry(emitter=emitter,\n                                           registry_infile=registry_infile,\n                                           download_registry=download_required,\n                                           network=network if download_required else None)\n    paint_deployer_contract_inspection(emitter=emitter,\n                                       registry=registry,\n                                       deployer_address=deployer_address)",
  "def upgrade(general_config, actor_options, retarget, target_address, ignore_deployed, confirmations):\n    \"\"\"Upgrade NuCypher existing proxy contract deployments.\"\"\"\n\n    #\n    # Setup\n    #\n\n    emitter = general_config.emitter\n    ADMINISTRATOR, deployer_address, blockchain, local_registry = actor_options.create_actor(emitter)\n\n    #\n    # Pre-flight\n    #\n\n    contract_name = actor_options.contract_name\n    if not contract_name:\n        raise click.BadArgumentUsage(message=click.style(\"--contract-name is required when using --upgrade\", fg=\"red\"))\n\n    try:\n        # Check contract name exists\n        Deployer = ADMINISTRATOR.deployers[contract_name]\n    except KeyError:\n        message = UNKNOWN_CONTRACT_NAME.format(contract_name=contract_name, constants=ADMINISTRATOR.deployers.keys())\n        emitter.error(message)\n        raise click.Abort()\n    deployer = Deployer(registry=local_registry)\n\n    # Check deployer address is owner\n    if Deployer._ownable and deployer_address != deployer.owner:  # blockchain read\n        emitter.error(DEPLOYER_IS_NOT_OWNER.format(deployer_address=deployer_address,\n                                                  contract_name=contract_name,\n                                                  agent=deployer.make_agent()))\n        raise click.Abort()\n    else:\n        emitter.echo('\u2713 Verified deployer address as contract owner', color='green')\n\n    #\n    # Business\n    #\n\n    if retarget:\n        if not target_address:\n            raise click.BadArgumentUsage(message=click.style(\"--target-address is required when using --retarget\", fg=\"red\"))\n        if not actor_options.force:\n            click.confirm(CONFIRM_RETARGET.format(contract_name=contract_name, target_address=target_address), abort=True)\n        receipt = ADMINISTRATOR.retarget_proxy(contract_name=contract_name,target_address=target_address, confirmations=confirmations)\n        message = SUCCESSFUL_RETARGET.format(contract_name=contract_name, target_address=target_address)\n        emitter.message(message, color='green')\n        paint_receipt_summary(emitter=emitter, receipt=receipt)\n        return  # Exit\n\n    else:\n        github_registry = establish_deployer_registry(emitter=emitter,\n                                                      download_registry=True,\n                                                      network=actor_options.network)\n        if not actor_options.force:\n\n            # Check for human verification of versioned upgrade details\n            click.confirm(CONFIRM_BEGIN_UPGRADE.format(contract_name=contract_name), abort=True)\n            if deployer._ownable:  # Only ownable + upgradeable contracts apply\n                verify_upgrade_details(blockchain=blockchain,\n                                       registry=github_registry,\n                                       deployer=deployer)\n\n        # Success\n        receipts = ADMINISTRATOR.upgrade_contract(contract_name=contract_name,\n                                                  ignore_deployed=ignore_deployed,\n                                                  confirmations=confirmations)\n        emitter.message(SUCCESSFUL_UPGRADE.format(contract_name=contract_name), color='green')\n\n        for name, receipt in receipts.items():\n            paint_receipt_summary(emitter=emitter, receipt=receipt)\n        emitter.echo(REGISTRY_PUBLICATION_HINT.format(contract_name=contract_name,\n                                                      local_registry=local_registry,\n                                                      network=actor_options.network), color='blue')\n        emitter.echo(ETHERSCAN_VERIFY_HINT.format(solc_version=SOLIDITY_COMPILER_VERSION), color='blue')\n        return",
  "def rollback(general_config, actor_options):\n    \"\"\"Rollback a proxy contract's target.\"\"\"\n    emitter = general_config.emitter\n    ADMINISTRATOR, _, _, _ = actor_options.create_actor(emitter)\n    if not actor_options.contract_name:\n        raise click.BadArgumentUsage(message=click.style(\"--contract-name is required when using --rollback\", fg=\"red\"))\n    receipt = ADMINISTRATOR.rollback_contract(contract_name=actor_options.contract_name)\n    paint_receipt_summary(emitter=emitter, receipt=receipt)",
  "def contracts(general_config, actor_options, mode, activate, gas, ignore_deployed, confirmations, parameters):\n    \"\"\"Compile and deploy contracts.\"\"\"\n\n    emitter = general_config.emitter\n    ADMINISTRATOR, _, deployer_interface, local_registry = actor_options.create_actor(emitter)\n    chain_name = deployer_interface.client.chain_name\n\n    deployment_parameters = {}\n    if parameters:\n        with open(parameters) as json_file:\n            deployment_parameters = json.load(json_file)\n\n    contract_name = actor_options.contract_name\n    deployment_mode = constants.__getattr__(mode.upper())  # TODO: constant sorrow\n    try:\n        contract_deployer_class = ADMINISTRATOR.deployers[contract_name]\n    except KeyError:\n        message = UNKNOWN_CONTRACT_NAME.format(contract_name=contract_name, constants=ADMINISTRATOR.deployers.keys())\n        emitter.error(message)\n        raise click.Abort()\n\n    if activate:\n        # For the moment, only StakingEscrow can be activated\n        staking_escrow_deployer = contract_deployer_class(registry=ADMINISTRATOR.registry)\n        if contract_name != STAKING_ESCROW_CONTRACT_NAME or not staking_escrow_deployer.ready_to_activate:\n            raise click.BadOptionUsage(option_name=\"--activate\",\n                                       message=click.style(f\"You can only activate an idle instance of {STAKING_ESCROW_CONTRACT_NAME}\", fg=\"red\"))\n\n        escrow_address = staking_escrow_deployer._get_deployed_contract().address\n        prompt = CONFIRM_NETWORK_ACTIVATION.format(staking_escrow_name=STAKING_ESCROW_CONTRACT_NAME,\n                                                   staking_escrow_address=escrow_address)\n        click.confirm(prompt, abort=True)\n\n        receipts = staking_escrow_deployer.activate(transacting_power=ADMINISTRATOR.transacting_power,\n                                                    gas_limit=gas,\n                                                    confirmations=confirmations)\n        for tx_name, receipt in receipts.items():\n            paint_receipt_summary(emitter=emitter,\n                                  receipt=receipt,\n                                  chain_name=chain_name,\n                                  transaction_type=tx_name)\n        return  # Exit\n\n    # Stage Deployment\n    paint_staged_deployment(deployer_interface=deployer_interface, administrator=ADMINISTRATOR, emitter=emitter)\n\n    # Confirm Trigger Deployment\n    if not confirm_deployment(emitter=emitter, deployer_interface=deployer_interface):\n        raise click.Abort()\n\n    # Deploy\n    emitter.echo(CONTRACT_DEPLOYMENT_SERIES_BEGIN_ADVISORY.format(contract_name=contract_name))\n    receipts, agent = ADMINISTRATOR.deploy_contract(contract_name=contract_name,\n                                                    gas_limit=gas,\n                                                    deployment_mode=deployment_mode,\n                                                    ignore_deployed=ignore_deployed,\n                                                    confirmations=confirmations,\n                                                    deployment_parameters=deployment_parameters)\n\n    # Report\n    paint_contract_deployment(contract_name=contract_name,\n                              contract_address=agent.contract_address,\n                              receipts=receipts,\n                              emitter=emitter,\n                              chain_name=chain_name,\n                              open_in_browser=actor_options.etherscan)\n\n    # Success\n    registry_outfile = local_registry.filepath\n    emitter.echo(SUCCESSFUL_REGISTRY_CREATION.format(registry_outfile=registry_outfile), bold=True, color='blue')",
  "def transfer_ownership(general_config, actor_options, target_address, gas):\n    \"\"\"Transfer ownership of contracts to another address.\"\"\"\n    emitter = general_config.emitter\n    ADMINISTRATOR, _, _, _ = actor_options.create_actor(emitter)\n\n    if not target_address:\n        target_address = click.prompt(PROMPT_NEW_OWNER_ADDRESS, type=EIP55_CHECKSUM_ADDRESS)\n\n    contract_name = actor_options.contract_name\n    if not contract_name:\n        raise click.MissingParameter(param=\"--contract-name\", message=\"You need to specify an ownable contract\")\n\n    try:\n        contract_deployer_class = ADMINISTRATOR.deployers[contract_name]\n    except KeyError:\n        message = UNKNOWN_CONTRACT_NAME.format(contract_name=contract_name,\n                                               contracts=ADMINISTRATOR.ownable_deployer_classes.keys())\n        emitter.echo(message, color='red', bold=True)\n        raise click.Abort()\n\n    if contract_deployer_class not in ADMINISTRATOR.ownable_deployer_classes:\n        message = CONTRACT_IS_NOT_OWNABLE.format(contract_name=contract_name)\n        emitter.echo(message, color='red', bold=True)\n        raise click.Abort()\n\n    contract_deployer = contract_deployer_class(registry=ADMINISTRATOR.registry)\n    receipt = contract_deployer.transfer_ownership(transacting_power=ADMINISTRATOR.transacting_power,\n                                                   new_owner=target_address,\n                                                   transaction_gas_limit=gas)\n    paint_receipt_summary(emitter=emitter, receipt=receipt)",
  "def __init__(self,\n                 eth_provider_uri: str,\n                 deployer_address: str,\n                 contract_name: str,\n                 registry_infile: Path,\n                 registry_outfile: Path,\n                 hw_wallet: bool,\n                 dev: bool,\n                 force: bool,\n                 poa: bool,\n                 config_root: Path,\n                 etherscan: bool,\n                 ignore_solidity_check,\n                 gas_strategy: str,\n                 max_gas_price: int,  # gwei\n                 signer_uri: str,\n                 network: str\n                 ):\n\n        self.eth_provider_uri = eth_provider_uri\n        self.signer_uri = signer_uri\n        self.gas_strategy = gas_strategy\n        self.max_gas_price = max_gas_price\n        self.deployer_address = deployer_address\n        self.contract_name = contract_name\n        self.registry_infile = registry_infile\n        self.registry_outfile = registry_outfile\n        self.hw_wallet = hw_wallet\n        self.dev = dev\n        self.force = force\n        self.config_root = config_root\n        self.etherscan = etherscan\n        self.poa = poa\n        self.ignore_solidity_check = ignore_solidity_check\n        self.network = network",
  "def create_actor(self,\n                     emitter: StdoutEmitter,\n                     ) -> Tuple[ContractAdministrator, str, BlockchainInterface, BaseContractRegistry]:\n\n        ensure_config_root(self.config_root)\n        deployer_interface = initialize_deployer_interface(poa=self.poa,\n                                                           eth_provider_uri=self.eth_provider_uri,\n                                                           emitter=emitter,\n                                                           ignore_solidity_check=self.ignore_solidity_check,\n                                                           gas_strategy=self.gas_strategy,\n                                                           max_gas_price=self.max_gas_price)\n\n        # Warnings\n        deployer_pre_launch_warnings(emitter, self.etherscan, self.hw_wallet)\n\n        #\n        # Establish Registry\n        #\n\n        local_registry = establish_deployer_registry(emitter=emitter,\n                                                     use_existing_registry=bool(self.contract_name),  # TODO: Issue #2314\n                                                     registry_infile=self.registry_infile,\n                                                     registry_outfile=self.registry_outfile,\n                                                     dev=self.dev,\n                                                     network=self.network)\n        #\n        # Make Authenticated Deployment Actor\n        #\n\n        # Verify Address & collect password\n        testnet = deployer_interface.client.chain_name != PUBLIC_CHAINS[1]  # Mainnet\n        signer = Signer.from_signer_uri(self.signer_uri, testnet=testnet)\n        deployer_address = self.deployer_address\n        if not deployer_address:\n            deployer_address = select_client_account(emitter=emitter,\n                                                     prompt=SELECT_DEPLOYER_ACCOUNT,\n                                                     registry=local_registry,\n                                                     eth_provider_uri=self.eth_provider_uri,\n                                                     signer=signer,\n                                                     show_eth_balance=True)\n\n        if not self.force:\n            click.confirm(CONFIRM_SELECTED_ACCOUNT.format(address=deployer_address), abort=True)\n\n        # Authenticate\n        password_required = all((not signer.is_device(account=deployer_address),\n                                 not deployer_interface.client.is_local,\n                                 not self.hw_wallet))\n        if password_required:\n            password = get_client_password(checksum_address=deployer_address)\n            signer.unlock_account(password=password, account=deployer_address)\n        transacting_power = TransactingPower(signer=signer, account=deployer_address)\n\n        # Produce Actor\n        ADMINISTRATOR = ContractAdministrator(registry=local_registry,\n                                              domain=self.network,\n                                              transacting_power=transacting_power)\n\n        # Verify ETH Balance\n        emitter.echo(DEPLOYER_BALANCE.format(eth_balance=ADMINISTRATOR.eth_balance))\n        if transacting_power and ADMINISTRATOR.eth_balance == 0:\n            emitter.echo(DEPLOYER_ADDRESS_ZERO_ETH, color='red', bold=True)\n            raise click.Abort()\n        return ADMINISTRATOR, deployer_address, deployer_interface, local_registry",
  "def is_authorized(emitter, staking_provider: ChecksumAddress, agent: PREApplicationAgent) -> None:\n    _authorized = agent.is_authorized(staking_provider=staking_provider)\n    if not _authorized:\n        emitter.message(STAKING_PROVIDER_UNAUTHORIZED.format(provider=staking_provider), color='red')\n        raise click.Abort()",
  "def is_bonded(agent, staking_provider: ChecksumAddress, return_address: bool = False) -> Union[bool, Tuple[bool, ChecksumAddress]]:\n    onchain_operator = agent.get_operator_from_staking_provider(staking_provider=staking_provider)\n    result = onchain_operator != NULL_ADDRESS\n    if not return_address:\n        return result\n    return result, onchain_operator",
  "def check_bonding_requirements(emitter, agent: PREApplicationAgent, staking_provider: ChecksumAddress) -> None:\n    blockchain = agent.blockchain\n    now = blockchain.get_blocktime()\n    commencement = agent.get_staking_provider_info(staking_provider=staking_provider).operator_start_timestamp\n    min_seconds = agent.get_min_operator_seconds()\n    termination = (commencement + min_seconds)\n    if now < termination:\n        emitter.error(BONDING_TIME.format(date=maya.MayaDT(termination)))\n        raise click.Abort()",
  "def bond(registry_filepath, eth_provider_uri, signer_uri, operator_address, staking_provider, network, force):\n    \"\"\"\n    Bond an operator to a staking provider.\n    The staking provider must be authorized to use the PREApplication.\n    \"\"\"\n\n    #\n    # Setup\n    #\n\n    emitter = StdoutEmitter()\n    connect_to_blockchain(eth_provider_uri=eth_provider_uri, emitter=emitter)\n    if not signer_uri:\n        emitter.message('--signer is required', color='red')\n        raise click.Abort()\n    if not network:\n        network = select_network(emitter=emitter, network_type=NetworksInventory.ETH)\n\n    signer = Signer.from_signer_uri(signer_uri)\n    transacting_power = TransactingPower(account=staking_provider, signer=signer)\n    registry = get_registry(network=network, registry_filepath=registry_filepath)\n    agent = ContractAgency.get_agent(PREApplicationAgent, registry=registry)\n\n    #\n    # Checks\n    #\n\n    # Check for authorization\n    is_authorized(emitter=emitter, agent=agent, staking_provider=staking_provider)\n\n    # Check bonding\n    if is_bonded(agent=agent, staking_provider=staking_provider, return_address=False):\n        # operator is already set - check timing\n        check_bonding_requirements(emitter=emitter, agent=agent, staking_provider=staking_provider)\n\n    # Check for pre-existing staking providers for this operator\n    onchain_staking_provider = agent.get_staking_provider_from_operator(operator_address=operator_address)\n    if onchain_staking_provider != NULL_ADDRESS:\n        emitter.message(ALREADY_BONDED.format(provider=onchain_staking_provider, operator=operator_address), color='red')\n        raise click.Abort()  # dont steal bananas\n\n    # Check that operator is not human\n    if staking_provider != operator_address:\n        # if the operator has a beneficiary it is the staking provider.\n        beneficiary = agent.get_beneficiary(staking_provider=operator_address)\n        if beneficiary != NULL_ADDRESS:\n            emitter.message(UNEXPECTED_HUMAN_OPERATOR, color='red')\n            raise click.Abort()\n\n    #\n    # Bond\n    #\n\n    if not force:\n        click.confirm(CONFIRM_BONDING.format(provider=staking_provider, operator=operator_address), abort=True)\n    transacting_power.unlock(password=get_client_password(checksum_address=staking_provider, envvar=NUCYPHER_ENVVAR_STAKING_PROVIDER_ETH_PASSWORD))\n    emitter.echo(BONDING.format(operator=operator_address))\n    receipt = agent.bond_operator(operator=operator_address, transacting_power=transacting_power, staking_provider=staking_provider)\n    paint_receipt_summary(receipt=receipt, emitter=emitter)",
  "def unbond(registry_filepath, eth_provider_uri, signer_uri, staking_provider, network, force):\n    \"\"\"Unbonds an operator from an authorized staking provider.\"\"\"\n\n    #\n    # Setup\n    #\n    \n    emitter = StdoutEmitter()\n    if not signer_uri:\n        emitter.message('--signer is required', color='red')\n        raise click.Abort()\n    if not network:\n        network = select_network(emitter=emitter, network_type=NetworksInventory.ETH)\n\n    connect_to_blockchain(eth_provider_uri=eth_provider_uri, emitter=emitter)\n    registry = get_registry(network=network, registry_filepath=registry_filepath)\n    agent = ContractAgency.get_agent(PREApplicationAgent, registry=registry)\n    signer = Signer.from_signer_uri(signer_uri)\n    transacting_power = TransactingPower(account=staking_provider, signer=signer)\n\n    #\n    # Check\n    #\n    \n    bonded, onchain_operator_address = is_bonded(agent=agent, staking_provider=staking_provider, return_address=True)\n    if not bonded:\n        emitter.message(NOT_BONDED.format(provider=staking_provider), color='red')\n        raise click.Abort()\n    check_bonding_requirements(emitter=emitter, agent=agent, staking_provider=staking_provider)\n\n    #\n    # Unbond\n    #\n\n    if not force:\n        click.confirm(CONFIRM_UNBONDING.format(provider=staking_provider, operator=onchain_operator_address), abort=True)\n    transacting_power.unlock(password=get_client_password(checksum_address=staking_provider, envvar=NUCYPHER_ENVVAR_STAKING_PROVIDER_ETH_PASSWORD))\n    emitter.echo(UNBONDING.format(operator=onchain_operator_address))\n    receipt = agent.bond_operator(operator=NULL_ADDRESS, transacting_power=transacting_power, staking_provider=staking_provider)\n    paint_receipt_summary(receipt=receipt, emitter=emitter)",
  "class RegistryOptions:\n\n    __option_name__ = 'registry_options'\n\n    def __init__(self, eth_provider_uri, poa, registry_filepath, light, network):\n        self.eth_provider_uri = eth_provider_uri\n        self.poa = poa\n        self.registry_filepath = registry_filepath\n        self.light = light\n        self.network = network\n\n    def setup(self, general_config) -> tuple:\n        emitter = setup_emitter(general_config)\n        registry = get_registry(network=self.network, registry_filepath=self.registry_filepath)\n        blockchain = connect_to_blockchain(emitter=emitter, eth_provider_uri=self.eth_provider_uri)\n        return emitter, registry, blockchain",
  "def status():\n    \"\"\"Echo a snapshot of live NuCypher Network metadata.\"\"\"",
  "def network(general_config, registry_options):\n    \"\"\"Overall information of the NuCypher Network.\"\"\"\n    emitter, registry, blockchain = registry_options.setup(general_config=general_config)\n    paint_contract_status(registry, emitter=emitter)",
  "def staking_providers(general_config, registry_options, staking_provider_address):\n    \"\"\"Show relevant information about staking providers.\"\"\"\n    emitter, registry, blockchain = registry_options.setup(general_config=general_config)\n    application_agent = ContractAgency.get_agent(PREApplicationAgent, registry=registry)\n    staking_providers_list = [staking_provider_address] if staking_provider_address else application_agent.get_staking_providers()\n    emitter.echo(staking_providers_list)",
  "def events(general_config, registry_options, contract_name, from_block, to_block, event_name, csv, csv_file, event_filters, legacy):\n    \"\"\"Show events associated with NuCypher contracts.\"\"\"\n\n    if csv or csv_file:\n        if csv and csv_file:\n            raise click.BadOptionUsage(option_name='--event-filter',\n                                       message=click.style('Pass either --csv or --csv-file, not both.', fg=\"red\"))\n\n        # ensure that event name is specified - different events would have different columns in the csv file\n        if csv_file and not all((event_name, contract_name)):\n            # TODO consider a single csv that just gets appended to for each event\n            #  - each appended event adds their column names first\n            #  - single report-type functionality, see #2561\n            raise click.BadOptionUsage(option_name='--csv-file, --event-name, --contract_name',\n                                       message=click.style('--event-name and --contract-name must be specified when outputting to '\n                                               'specific file using --csv-file; alternatively use --csv', fg=\"red\"))\n    if not contract_name:\n        if event_name:\n            raise click.BadOptionUsage(option_name='--event-name', message=click.style('--event-name requires --contract-name', fg=\"red\"))\n        # FIXME should we force a contract name to be specified?\n        # default to PREApplication contract\n        contract_names = [PREApplicationAgent.contract_name]\n    else:\n        contract_names = [contract_name]\n\n    emitter, registry, blockchain = registry_options.setup(general_config=general_config)\n\n    if from_block is None:\n        # by default, this command only shows events of the current period\n        blocks_since_yesterday_kinda = ((60*60*24)//AVERAGE_BLOCK_TIME_IN_SECONDS)\n        from_block = blockchain.client.block_number - blocks_since_yesterday_kinda\n    if to_block is None:\n        to_block = 'latest'\n    else:\n        # validate block range\n        if from_block > to_block:\n            raise click.BadOptionUsage(option_name='--to-block, --from-block',\n                                       message=click.style(f'Invalid block range provided, '\n                                               f'from-block ({from_block}) > to-block ({to_block})', fg=\"red\"))\n\n    # event argument filters\n    argument_filters = None\n    if event_filters:\n        try:\n            argument_filters = parse_event_filters_into_argument_filters(event_filters)\n        except ValueError as e:\n            raise click.BadOptionUsage(option_name='--event-filter',\n                                       message=click.style(f'Event filter must be specified as name-value pairs of '\n                                               f'the form `<name>=<value>` - {str(e)}', fg=\"red\"))\n\n    emitter.echo(f\"Retrieving events from block {from_block} to {to_block}\")\n\n    contract_version = None\n    if legacy and contract_name in LEGACY_CONTRACT_VERSIONS:\n        contract_version = LEGACY_CONTRACT_VERSIONS[contract_name]\n\n    for contract_name in contract_names:\n        if legacy:\n            versioned_contract = blockchain.get_contract_by_name(\n                registry=registry,\n                contract_name=contract_name,\n                contract_version=contract_version,\n                proxy_name='Dispatcher',\n                use_proxy_address=True\n               )\n            agent = EthereumContractAgent(contract=versioned_contract)\n            agent.contract_name = contract_name\n        else:\n            agent = ContractAgency.get_agent_by_contract_name(\n                contract_name=contract_name,\n                contract_version=contract_version,\n                registry=registry\n            )\n\n        if event_name and event_name not in agent.events.names:\n            raise click.BadOptionUsage(option_name='--event-name, --contract_name',\n                                       message=click.style(f'{contract_name} contract does not have an event named {event_name}', fg=\"red\"))\n\n        title = f\" {agent.contract_name} Events \".center(40, \"-\")\n        emitter.echo(f\"\\n{title}\\n\", bold=True, color='green')\n        names = agent.events.names if not event_name else [event_name]\n        for name in names:\n            # csv output file - one per (contract_name, event_name) pair\n            csv_output_file = csv_file\n            if csv or csv_output_file:\n                if not csv_output_file:\n                    csv_output_file = generate_events_csv_filepath(contract_name=agent.contract_name, event_name=name)\n\n            retrieve_events(emitter=emitter,\n                            agent=agent,\n                            event_name=name,  # None is fine - just means all events\n                            from_block=from_block,\n                            to_block=to_block,\n                            argument_filters=argument_filters,\n                            csv_output_file=csv_output_file)",
  "def __init__(self, eth_provider_uri, poa, registry_filepath, light, network):\n        self.eth_provider_uri = eth_provider_uri\n        self.poa = poa\n        self.registry_filepath = registry_filepath\n        self.light = light\n        self.network = network",
  "def setup(self, general_config) -> tuple:\n        emitter = setup_emitter(general_config)\n        registry = get_registry(network=self.network, registry_filepath=self.registry_filepath)\n        blockchain = connect_to_blockchain(emitter=emitter, eth_provider_uri=self.eth_provider_uri)\n        return emitter, registry, blockchain",
  "class UrsulaConfigOptions:\n\n    __option_name__ = 'config_options'\n\n    def __init__(self,\n                 eth_provider_uri: str,\n                 operator_address: str,\n                 federated_only: bool,\n                 rest_host: str,\n                 rest_port: int,\n                 network: str,\n                 registry_filepath: Path,\n                 policy_registry_filepath: Path,\n                 dev: bool,\n                 poa: bool,\n                 light: bool,\n                 gas_strategy: str,\n                 max_gas_price: int,  # gwei\n                 signer_uri: str,\n                 availability_check: bool,\n                 lonely: bool,\n                 payment_method: str,\n                 payment_provider: str,\n                 payment_network: str\n                 ):\n\n        if federated_only:\n            if registry_filepath or policy_registry_filepath:\n                raise click.BadOptionUsage(option_name=\"--registry-filepath\",\n                                           message=click.style(\"--registry-filepath and --policy-registry-filepath cannot be used in federated mode.\", fg=\"red\"))\n\n        self.eth_provider_uri = eth_provider_uri\n        self.signer_uri = signer_uri\n        self.operator_address = operator_address\n        self.federated_only = federated_only\n        self.rest_host = rest_host\n        self.rest_port = rest_port  # FIXME: not used in generate()\n        self.domain = network\n        self.registry_filepath = registry_filepath\n        self.policy_registry_filepath = policy_registry_filepath\n        self.dev = dev\n        self.poa = poa\n        self.light = light\n        self.gas_strategy = gas_strategy\n        self.max_gas_price = max_gas_price\n        self.availability_check = availability_check\n        self.lonely = lonely\n        self.payment_method = payment_method\n        self.payment_provider = payment_provider\n        self.payment_network = payment_network\n\n    def create_config(self, emitter, config_file):\n        if self.dev:\n            return UrsulaConfiguration(\n                emitter=emitter,\n                dev_mode=True,\n                domain=TEMPORARY_DOMAIN,\n                poa=self.poa,\n                light=self.light,\n                registry_filepath=self.registry_filepath,\n                policy_registry_filepath=self.policy_registry_filepath,\n                eth_provider_uri=self.eth_provider_uri,\n                signer_uri=self.signer_uri,\n                gas_strategy=self.gas_strategy,\n                max_gas_price=self.max_gas_price,\n                checksum_address=self.operator_address,\n                federated_only=self.federated_only,\n                rest_host=self.rest_host,\n                rest_port=self.rest_port,\n                availability_check=self.availability_check,\n                payment_method=self.payment_method,\n                payment_provider=self.payment_provider,\n                payment_network=self.payment_network\n            )\n        else:\n            if not config_file:\n                config_file = select_config_file(emitter=emitter,\n                                                 checksum_address=self.operator_address,\n                                                 config_class=UrsulaConfiguration)\n            try:\n                return UrsulaConfiguration.from_configuration_file(\n                    emitter=emitter,\n                    filepath=config_file,\n                    domain=self.domain,\n                    registry_filepath=self.registry_filepath,\n                    policy_registry_filepath=self.policy_registry_filepath,\n                    eth_provider_uri=self.eth_provider_uri,\n                    signer_uri=self.signer_uri,\n                    gas_strategy=self.gas_strategy,\n                    max_gas_price=self.max_gas_price,\n                    rest_host=self.rest_host,\n                    rest_port=self.rest_port,\n                    poa=self.poa,\n                    light=self.light,\n                    federated_only=self.federated_only,\n                    availability_check=self.availability_check,\n                    payment_method=self.payment_method,\n                    payment_provider=self.payment_provider,\n                    payment_network=self.payment_network\n                )\n            except FileNotFoundError:\n                return handle_missing_configuration_file(character_config_class=UrsulaConfiguration, config_file=config_file)\n            except Keystore.AuthenticationFailed as e:\n                emitter.error(str(e))\n                # TODO: Exit codes (not only for this, but for other exceptions)\n                return click.get_current_context().exit(1)\n\n    def generate_config(self, emitter, config_root, force, key_material):\n\n        if self.dev:\n            raise RuntimeError('Persistent configurations cannot be created in development mode.')\n\n        if (not self.operator_address) and not self.federated_only:\n            prompt = \"Select operator account\"\n            self.operator_address = select_client_account(emitter=emitter,\n                                                          prompt=prompt,\n                                                          eth_provider_uri=self.eth_provider_uri,\n                                                          signer_uri=self.signer_uri)\n\n        # Resolve rest host\n        if not self.rest_host:\n            self.rest_host = collect_operator_ip_address(emitter, network=self.domain, force=force)\n\n        return UrsulaConfiguration.generate(password=get_nucypher_password(emitter=emitter, confirm=True),\n                                            key_material=bytes.fromhex(key_material) if key_material else None,\n                                            config_root=config_root,\n                                            rest_host=self.rest_host,\n                                            rest_port=self.rest_port,\n                                            domain=self.domain,\n                                            federated_only=self.federated_only,\n                                            operator_address=self.operator_address,\n                                            registry_filepath=self.registry_filepath,\n                                            policy_registry_filepath=self.policy_registry_filepath,\n                                            eth_provider_uri=self.eth_provider_uri,\n                                            signer_uri=self.signer_uri,\n                                            gas_strategy=self.gas_strategy,\n                                            max_gas_price=self.max_gas_price,\n                                            poa=self.poa,\n                                            light=self.light,\n                                            availability_check=self.availability_check,\n                                            payment_method=self.payment_method,\n                                            payment_provider=self.payment_provider,\n                                            payment_network=self.payment_network\n                                            )\n\n    def get_updates(self) -> dict:\n        payload = dict(rest_host=self.rest_host,\n                       rest_port=self.rest_port,\n                       domain=self.domain,\n                       federated_only=self.federated_only,\n                       operator_address=self.operator_address,\n                       registry_filepath=self.registry_filepath,\n                       policy_registry_filepath=self.policy_registry_filepath,\n                       eth_provider_uri=self.eth_provider_uri,\n                       signer_uri=self.signer_uri,\n                       gas_strategy=self.gas_strategy,\n                       max_gas_price=self.max_gas_price,\n                       poa=self.poa,\n                       light=self.light,\n                       availability_check=self.availability_check,\n                       payment_method=self.payment_method,\n                       payment_provider=self.payment_provider,\n                       payment_network=self.payment_network\n                       )\n        # Depends on defaults being set on Configuration classes, filtrates None values\n        updates = {k: v for k, v in payload.items() if v is not None}\n        return updates",
  "class UrsulaCharacterOptions:\n\n    __option_name__ = 'character_options'\n\n    def __init__(self, config_options: UrsulaConfigOptions, teacher_uri, min_stake):\n        self.config_options = config_options\n        self.teacher_uri = teacher_uri\n        self.min_stake = min_stake\n\n    def create_character(self, emitter, config_file, json_ipc, load_seednodes=True):\n        ursula_config = self.config_options.create_config(emitter, config_file)\n        password_required = all((not ursula_config.federated_only,\n                                 not self.config_options.dev,\n                                 not json_ipc))\n        __password = None\n        if password_required:\n            __password = get_client_password(checksum_address=ursula_config.operator_address,\n                                             envvar=NUCYPHER_ENVVAR_OPERATOR_ETH_PASSWORD)\n\n        try:\n            URSULA = make_cli_character(character_config=ursula_config,\n                                        emitter=emitter,\n                                        min_stake=self.min_stake,\n                                        teacher_uri=self.teacher_uri,\n                                        unlock_keystore=not self.config_options.dev,\n                                        client_password=__password,\n                                        unlock_signer=False,  # Ursula's unlock is managed separately using client_password.\n                                        lonely=self.config_options.lonely,\n                                        start_learning_now=load_seednodes,\n                                        json_ipc=json_ipc)\n            return ursula_config, URSULA\n\n        except Keystore.AuthenticationFailed as e:\n            emitter.error(str(e))\n            # TODO: Exit codes (not only for this, but for other exceptions)\n            return click.get_current_context().exit(1)",
  "def ursula():\n    \"\"\"\"Ursula the Untrusted\" PRE Re-encryption node management commands.\"\"\"",
  "def init(general_config, config_options, force, config_root, key_material):\n    \"\"\"Create a new Ursula node configuration.\"\"\"\n    emitter = setup_emitter(general_config, config_options.operator_address)\n    _pre_launch_warnings(emitter, dev=None, force=force)\n    if not config_root:\n        config_root = general_config.config_root\n    if not config_options.federated_only and not config_options.eth_provider_uri:\n        raise click.BadOptionUsage('--eth-provider', message=click.style(\"--eth-provider is required to initialize a new ursula.\", fg=\"red\"))\n    if not config_options.federated_only and not config_options.payment_provider:\n        raise click.BadOptionUsage('--payment-provider', message=click.style(\"--payment-provider is required to initialize a new ursula.\", fg=\"red\"))\n    if not config_options.federated_only and not config_options.domain:\n        config_options.domain = select_network(emitter, message=\"Select Staking Network\", network_type=NetworksInventory.ETH)\n    if not config_options.federated_only and not config_options.payment_network:\n        config_options.payment_network = select_network(emitter, message=\"Select Payment Network\", network_type=NetworksInventory.POLYGON)\n    ursula_config = config_options.generate_config(emitter=emitter,\n                                                   config_root=config_root,\n                                                   force=force,\n                                                   key_material=key_material)\n    filepath = ursula_config.to_configuration_file()\n    paint_new_installation_help(emitter, new_configuration=ursula_config, filepath=filepath)",
  "def recover(general_config, config_options):\n    # TODO: Combine with work in PR #2682\n    # TODO: Integrate regeneration of configuration files\n    emitter = setup_emitter(general_config, config_options.operator_address)\n    recover_keystore(emitter=emitter)",
  "def destroy(general_config, config_options, config_file, force):\n    \"\"\"Delete Ursula node configuration.\"\"\"\n    emitter = setup_emitter(general_config, config_options.operator_address)\n    _pre_launch_warnings(emitter, dev=config_options.dev, force=force)\n    ursula_config = config_options.create_config(emitter, config_file)\n    destroy_configuration(emitter, character_config=ursula_config, force=force)",
  "def forget(general_config, config_options, config_file):\n    \"\"\"Forget all known nodes.\"\"\"\n    emitter = setup_emitter(general_config, config_options.operator_address)\n    _pre_launch_warnings(emitter, dev=config_options.dev, force=None)\n    ursula_config = config_options.create_config(emitter, config_file)\n    forget_nodes(emitter, configuration=ursula_config)",
  "def run(general_config, character_options, config_file, dry_run, prometheus, metrics_port,\n        metrics_listen_address, metrics_prefix, metrics_interval, force, ip_checkup):\n    \"\"\"Run an \"Ursula\" node.\"\"\"\n\n    emitter = setup_emitter(general_config)\n    dev_mode = character_options.config_options.dev\n    lonely = character_options.config_options.lonely\n\n    if prometheus and not metrics_port:\n        # Require metrics port when using prometheus\n        raise click.BadOptionUsage(option_name='metrics-port',\n                                   message=click.style('--metrics-port is required when using --prometheus', fg=\"red\"))\n\n    _pre_launch_warnings(emitter, dev=dev_mode, force=None)\n\n    prometheus_config: 'PrometheusMetricsConfig' = None\n    if prometheus and not dev_mode:\n        # Locally scoped to prevent import without prometheus explicitly installed\n        from nucypher.utilities.prometheus.metrics import PrometheusMetricsConfig\n        prometheus_config = PrometheusMetricsConfig(port=metrics_port,\n                                                    metrics_prefix=metrics_prefix,\n                                                    listen_address=metrics_listen_address,\n                                                    collection_interval=metrics_interval)\n\n    ursula_config, URSULA = character_options.create_character(emitter=emitter,\n                                                               config_file=config_file,\n                                                               json_ipc=general_config.json_ipc)\n\n    if ip_checkup and not (dev_mode or lonely):\n        # Always skip startup IP checks for dev and lonely modes.\n        perform_startup_ip_check(emitter=emitter, ursula=URSULA, force=force)\n\n    try:\n        URSULA.run(emitter=emitter,\n                   start_reactor=not dry_run,\n                   prometheus_config=prometheus_config,\n                   preflight=not dev_mode)\n    finally:\n        if dry_run:\n            URSULA.stop()",
  "def save_metadata(general_config, character_options, config_file):\n    \"\"\"Manually write node metadata to disk without running.\"\"\"\n    emitter = setup_emitter(general_config, character_options.config_options.operator_address)\n    _pre_launch_warnings(emitter, dev=character_options.config_options.dev, force=None)\n    _, URSULA = character_options.create_character(emitter, config_file, general_config.json_ipc, load_seednodes=False)\n    metadata_path = URSULA.write_node_metadata(node=URSULA)\n    emitter.message(SUCCESSFUL_MANUALLY_SAVE_METADATA.format(metadata_path=metadata_path), color='green')",
  "def config(general_config, config_options, config_file, force, action):\n    \"\"\"\n    View and optionally update the Ursula node's configuration.\n\n    \\b\n    Sub-Commands\n    ~~~~~~~~~~~~~\n    ip-address - automatically detect and configure the external IP address.\n\n    \"\"\"\n    emitter = setup_emitter(general_config, config_options.operator_address)\n    if not config_file:\n        config_file = select_config_file(emitter=emitter,\n                                         checksum_address=config_options.operator_address,\n                                         config_class=UrsulaConfiguration)\n    if action == 'ip-address':\n        rest_host = collect_operator_ip_address(emitter=emitter, network=config_options.domain, force=force)\n        config_options.rest_host = rest_host\n    elif action:\n        emitter.error(f'\"{action}\" is not a valid command.')\n        raise click.Abort()\n    updates = config_options.get_updates()\n    get_or_update_configuration(emitter=emitter,\n                                config_class=UrsulaConfiguration,\n                                filepath=config_file,\n                                updates=updates)",
  "def _pre_launch_warnings(emitter, dev, force):\n    if dev:\n        emitter.echo(DEVELOPMENT_MODE_WARNING, color='yellow', verbosity=1)\n    if force:\n        emitter.echo(FORCE_MODE_WARNING, color='yellow', verbosity=1)",
  "def __init__(self,\n                 eth_provider_uri: str,\n                 operator_address: str,\n                 federated_only: bool,\n                 rest_host: str,\n                 rest_port: int,\n                 network: str,\n                 registry_filepath: Path,\n                 policy_registry_filepath: Path,\n                 dev: bool,\n                 poa: bool,\n                 light: bool,\n                 gas_strategy: str,\n                 max_gas_price: int,  # gwei\n                 signer_uri: str,\n                 availability_check: bool,\n                 lonely: bool,\n                 payment_method: str,\n                 payment_provider: str,\n                 payment_network: str\n                 ):\n\n        if federated_only:\n            if registry_filepath or policy_registry_filepath:\n                raise click.BadOptionUsage(option_name=\"--registry-filepath\",\n                                           message=click.style(\"--registry-filepath and --policy-registry-filepath cannot be used in federated mode.\", fg=\"red\"))\n\n        self.eth_provider_uri = eth_provider_uri\n        self.signer_uri = signer_uri\n        self.operator_address = operator_address\n        self.federated_only = federated_only\n        self.rest_host = rest_host\n        self.rest_port = rest_port  # FIXME: not used in generate()\n        self.domain = network\n        self.registry_filepath = registry_filepath\n        self.policy_registry_filepath = policy_registry_filepath\n        self.dev = dev\n        self.poa = poa\n        self.light = light\n        self.gas_strategy = gas_strategy\n        self.max_gas_price = max_gas_price\n        self.availability_check = availability_check\n        self.lonely = lonely\n        self.payment_method = payment_method\n        self.payment_provider = payment_provider\n        self.payment_network = payment_network",
  "def create_config(self, emitter, config_file):\n        if self.dev:\n            return UrsulaConfiguration(\n                emitter=emitter,\n                dev_mode=True,\n                domain=TEMPORARY_DOMAIN,\n                poa=self.poa,\n                light=self.light,\n                registry_filepath=self.registry_filepath,\n                policy_registry_filepath=self.policy_registry_filepath,\n                eth_provider_uri=self.eth_provider_uri,\n                signer_uri=self.signer_uri,\n                gas_strategy=self.gas_strategy,\n                max_gas_price=self.max_gas_price,\n                checksum_address=self.operator_address,\n                federated_only=self.federated_only,\n                rest_host=self.rest_host,\n                rest_port=self.rest_port,\n                availability_check=self.availability_check,\n                payment_method=self.payment_method,\n                payment_provider=self.payment_provider,\n                payment_network=self.payment_network\n            )\n        else:\n            if not config_file:\n                config_file = select_config_file(emitter=emitter,\n                                                 checksum_address=self.operator_address,\n                                                 config_class=UrsulaConfiguration)\n            try:\n                return UrsulaConfiguration.from_configuration_file(\n                    emitter=emitter,\n                    filepath=config_file,\n                    domain=self.domain,\n                    registry_filepath=self.registry_filepath,\n                    policy_registry_filepath=self.policy_registry_filepath,\n                    eth_provider_uri=self.eth_provider_uri,\n                    signer_uri=self.signer_uri,\n                    gas_strategy=self.gas_strategy,\n                    max_gas_price=self.max_gas_price,\n                    rest_host=self.rest_host,\n                    rest_port=self.rest_port,\n                    poa=self.poa,\n                    light=self.light,\n                    federated_only=self.federated_only,\n                    availability_check=self.availability_check,\n                    payment_method=self.payment_method,\n                    payment_provider=self.payment_provider,\n                    payment_network=self.payment_network\n                )\n            except FileNotFoundError:\n                return handle_missing_configuration_file(character_config_class=UrsulaConfiguration, config_file=config_file)\n            except Keystore.AuthenticationFailed as e:\n                emitter.error(str(e))\n                # TODO: Exit codes (not only for this, but for other exceptions)\n                return click.get_current_context().exit(1)",
  "def generate_config(self, emitter, config_root, force, key_material):\n\n        if self.dev:\n            raise RuntimeError('Persistent configurations cannot be created in development mode.')\n\n        if (not self.operator_address) and not self.federated_only:\n            prompt = \"Select operator account\"\n            self.operator_address = select_client_account(emitter=emitter,\n                                                          prompt=prompt,\n                                                          eth_provider_uri=self.eth_provider_uri,\n                                                          signer_uri=self.signer_uri)\n\n        # Resolve rest host\n        if not self.rest_host:\n            self.rest_host = collect_operator_ip_address(emitter, network=self.domain, force=force)\n\n        return UrsulaConfiguration.generate(password=get_nucypher_password(emitter=emitter, confirm=True),\n                                            key_material=bytes.fromhex(key_material) if key_material else None,\n                                            config_root=config_root,\n                                            rest_host=self.rest_host,\n                                            rest_port=self.rest_port,\n                                            domain=self.domain,\n                                            federated_only=self.federated_only,\n                                            operator_address=self.operator_address,\n                                            registry_filepath=self.registry_filepath,\n                                            policy_registry_filepath=self.policy_registry_filepath,\n                                            eth_provider_uri=self.eth_provider_uri,\n                                            signer_uri=self.signer_uri,\n                                            gas_strategy=self.gas_strategy,\n                                            max_gas_price=self.max_gas_price,\n                                            poa=self.poa,\n                                            light=self.light,\n                                            availability_check=self.availability_check,\n                                            payment_method=self.payment_method,\n                                            payment_provider=self.payment_provider,\n                                            payment_network=self.payment_network\n                                            )",
  "def get_updates(self) -> dict:\n        payload = dict(rest_host=self.rest_host,\n                       rest_port=self.rest_port,\n                       domain=self.domain,\n                       federated_only=self.federated_only,\n                       operator_address=self.operator_address,\n                       registry_filepath=self.registry_filepath,\n                       policy_registry_filepath=self.policy_registry_filepath,\n                       eth_provider_uri=self.eth_provider_uri,\n                       signer_uri=self.signer_uri,\n                       gas_strategy=self.gas_strategy,\n                       max_gas_price=self.max_gas_price,\n                       poa=self.poa,\n                       light=self.light,\n                       availability_check=self.availability_check,\n                       payment_method=self.payment_method,\n                       payment_provider=self.payment_provider,\n                       payment_network=self.payment_network\n                       )\n        # Depends on defaults being set on Configuration classes, filtrates None values\n        updates = {k: v for k, v in payload.items() if v is not None}\n        return updates",
  "def __init__(self, config_options: UrsulaConfigOptions, teacher_uri, min_stake):\n        self.config_options = config_options\n        self.teacher_uri = teacher_uri\n        self.min_stake = min_stake",
  "def create_character(self, emitter, config_file, json_ipc, load_seednodes=True):\n        ursula_config = self.config_options.create_config(emitter, config_file)\n        password_required = all((not ursula_config.federated_only,\n                                 not self.config_options.dev,\n                                 not json_ipc))\n        __password = None\n        if password_required:\n            __password = get_client_password(checksum_address=ursula_config.operator_address,\n                                             envvar=NUCYPHER_ENVVAR_OPERATOR_ETH_PASSWORD)\n\n        try:\n            URSULA = make_cli_character(character_config=ursula_config,\n                                        emitter=emitter,\n                                        min_stake=self.min_stake,\n                                        teacher_uri=self.teacher_uri,\n                                        unlock_keystore=not self.config_options.dev,\n                                        client_password=__password,\n                                        unlock_signer=False,  # Ursula's unlock is managed separately using client_password.\n                                        lonely=self.config_options.lonely,\n                                        start_learning_now=load_seednodes,\n                                        json_ipc=json_ipc)\n            return ursula_config, URSULA\n\n        except Keystore.AuthenticationFailed as e:\n            emitter.error(str(e))\n            # TODO: Exit codes (not only for this, but for other exceptions)\n            return click.get_current_context().exit(1)",
  "def merge_and_update(source: Dict, destination: Dict):\n    \"\"\"Update values in source dictionary and merge it to the destination dictionary\"\"\"\n\n    for key, value in source.items():\n        if isinstance(value, dict):\n            destination[key] = merge_and_update(value, destination.get(key, {}))\n        else:\n            # | symbol causes warnings in docs compilation\n            # doubles ` symbol to make it as code piece in rst\n            # TODO find library that will fix this or make our own\n            value = value.replace('`', '``').replace('|', '') if isinstance(value, str) else value\n            destination[key] = value\n    return destination",
  "def generate_doc() -> None:\n    \"\"\"Compile solidity contracts, extract json docs and generate rst files from them\"\"\"\n\n    GlobalLoggerSettings.start_console_logging()\n\n    base_dir = Path(__file__).parent.parent.parent.resolve()\n    solidity_source_root = base_dir / 'nucypher' / 'blockchain' / 'eth' / 'sol' / 'source'\n\n    bundle = SourceBundle(base_path=solidity_source_root)\n    contracts = multiversion_compile(source_bundles=[bundle])\n\n    # Prepare folders\n    base_path = base_dir / 'docs' / 'source' / 'contracts_api'\n    base_path.mkdir(exist_ok=True)\n    for dir in CONTRACTS.keys():\n        category_path = base_path / dir\n        category_path.mkdir(exist_ok=True)\n\n    contract_names = {contract for contracts in CONTRACTS.values() for contract in contracts}\n    patch()\n    for contract, data in contracts.items():\n        if contract not in contract_names:\n            continue\n\n        # Merge, update and generate resulting rst\n        no_version = next(iter(data.values()))\n        docs = merge_and_update(no_version[\"userdoc\"], dict())\n        docs = merge_and_update(no_version[\"devdoc\"], docs)\n        rst = schema2rst(docs, \"kind,version,title\", contract)\n\n        # Find proper category and write file\n        category_path = base_path\n        for category, contracts in CONTRACTS.items():\n            if contract in contracts:\n                category_path /= category\n        with open(category_path / f\"{contract}.rst\", 'w') as file:\n            file.write(rst)",
  "def schema2rst(data: dict, excluded_key: str, tree_name: str):\n    \"\"\"Mimics parser.schema2rst method with string input parameters\"\"\"\n\n    tree = TreeNode(tree_name)\n\n    rst = RST_DIRECTIVES\n    TreeNode.dict2tree(data, tree, excluded_key)\n    rst += _traverse_bfs(tree, _node2rst)\n    return rst",
  "def patch():\n    \"\"\"Remove putting quotes in strings while handling json schema\"\"\"\n\n    def _literal(val):\n        return val\n\n    import jsonschema2rst\n    jsonschema2rst.rst_utils.literal = _literal",
  "def _literal(val):\n        return val",
  "def spin_up_federated_ursulas(quantity: int = FLEET_POPULATION):\n\n    # Ports\n    starting_port = DEMO_NODE_STARTING_PORT\n    ports = list(map(str, range(starting_port, starting_port + quantity)))\n\n    ursula_processes = list()\n    for index, port in enumerate(ports):\n\n        args = ['nucypher',\n                'ursula', 'run',\n                '--debug',\n                '--rest-port', port,\n                '--teacher', TEACHER_URI,\n                '--federated-only',\n                '--dev',\n                ]\n\n        env = {'PATH': os.environ['PATH'],\n               'NUCYPHER_SENTRY_LOGS': '0',\n               'NUCYPHER_FILE_LOGS': '0',\n               'LC_ALL': 'en_US.UTF-8',\n               'LANG': 'en_US.UTF-8'}\n\n        childFDs = {0: 0,\n                    1: 1,\n                    2: 2}\n\n        class UrsulaProcessProtocol(protocol.Protocol):\n\n            def __init__(self, command):\n                self.command = command\n\n            def processEnded(self, reason, *args, **kwargs):\n                print(reason.value)\n\n        processProtocol = UrsulaProcessProtocol(command=args)\n        p = reactor.spawnProcess(processProtocol, 'nucypher', args, env=env, childFDs=childFDs)\n        ursula_processes.append(p)\n\n    reactor.run()",
  "class UrsulaProcessProtocol(protocol.Protocol):\n\n            def __init__(self, command):\n                self.command = command\n\n            def processEnded(self, reason, *args, **kwargs):\n                print(reason.value)",
  "def __init__(self, command):\n                self.command = command",
  "def processEnded(self, reason, *args, **kwargs):\n                print(reason.value)",
  "def get_solc_config_path() -> Path:\n    # Note: This script is sensitive to the working directory.\n    nucypher = Path(__file__).parent.parent.parent.resolve() / 'nucypher'\n    config_path = nucypher / 'blockchain' / 'eth' / 'sol' / '__conf__.py'\n    return config_path",
  "def get_packaged_solc_version() -> str:\n    \"\"\"Returns the solidity version specified in the embedded configuration file\"\"\"\n    solc_config = get_solc_config_path()\n    metadata = dict()\n    with open(str(solc_config)) as f:\n        exec(f.read(), metadata)  # noqa\n    version = metadata['SOLIDITY_COMPILER_VERSION']\n    return version",
  "def get_solc_version() -> str:\n    \"\"\"\n    Returns a solidity version string.  Resolves the solidity version in the following priority:\n\n    HIGH PRIORITY\n    1. Command line argument\n    2. Environment variable\n    3. Packaged contract version\n    LOW PRIORITY\n    \"\"\"\n    try:\n        version = sys.argv[1]  # 1\n    except IndexError:\n        try:\n            version = os.environ['NUCYPHER_SOLIDITY_VERSION']  # 2\n        except KeyError:\n            version = get_packaged_solc_version()  # 3\n    return version",
  "def install_solc(version: str) -> None:\n    \"\"\"Install the solidity compiler binary to the system for the specified version then set it as the default.\"\"\"\n    try:\n        from solcx import install_solc, set_solc_version\n    except ImportError:\n        error = f\"Failed to install solc, py-solc-x  is not found. \" \\\n                f\"Install with 'pip install py-solc-x' and try again.\"\n        raise ImportError(error)\n\n    install_solc(version)",
  "def main():\n    version = get_solc_version()\n    print(f\"Fetched solc version {version} from source configuration\")\n\n    install_solc(version=version)\n    print(f\"Successfully installed solc {version}\")",
  "def create_venv(parent_path: Path) -> Path:\n    if hasattr(sys, 'real_prefix'):\n        # python is currently running inside a venv\n        # pip_path = Path(sys.executable).parent\n        raise RuntimeError(\"Disable venv and try again.\")\n\n    venv_path = parent_path / 'package-smoke-test'\n    pip_path = venv_path / 'bin' / 'pip'\n\n    venv.create(venv_path, with_pip=True)\n    assert Path.exists(venv_path), f'venv path \"{venv_path}\" does not exist.'\n    assert Path.exists(pip_path), f'pip executable not found at \"{pip_path}\"'\n\n    subprocess.run([pip_path, 'install', '-U', 'pip', 'setuptools'], check=True)\n    return venv_path",
  "def find_wheel(project_path: Path) -> Path:\n    wheels = list(project_path.glob('dist/*.whl'))\n    if len(wheels) != 1:\n        raise Exception(f\"Expected one wheel. Instead found: {wheels} in project {project_path.absolute()}\")\n    return wheels[0]",
  "def install_wheel(venv_path: Path, wheel_path: Path, extras: Tuple[str, ...] = ()) -> None:\n    if extras:\n        extra_suffix = f\"[{','.join(extras)}]\"\n    else:\n        extra_suffix = \"\"\n    subprocess.run([venv_path / 'bin' / 'pip', 'install', f\"{wheel_path}{extra_suffix}\"], check=True)",
  "def test_install_local_wheel() -> None:\n    with TemporaryDirectory() as tmpdir:\n        venv_path = create_venv(Path(tmpdir))\n        wheel_path = find_wheel(Path('.'))\n        install_wheel(venv_path, wheel_path)\n        print(\"Installed\", wheel_path.absolute(), \"to\", venv_path)\n        print(f\"Activate with `source {venv_path}/bin/activate`\")\n        input(\"Press enter when the test has completed. The directory will be deleted.\")",
  "def configuration_v3_to_v4(filepath: str):\n    \"\"\"Updates configuration file v3 to v4 by remapping 'domains' to 'domain'\"\"\"\n\n    # Read + deserialize\n    with open(filepath, 'r') as file:\n        contents = file.read()\n    config = json.loads(contents)\n\n    try:\n        # Check we have version 1 indeed\n        existing_version = config['version']\n        if existing_version != OLD_VERSION:\n            raise RuntimeError(f'Existing configuration is not version {OLD_VERSION}; Got version {existing_version}')\n\n        # Make a copy of the original file\n        backup_filepath = filepath+BACKUP_SUFFIX\n        os.rename(filepath, backup_filepath)\n        print(f'Backed up existing configuration to {backup_filepath}')\n\n        # Apply updates\n        worker_address = config['worker_address']\n        del config['worker_address']  # deprecated\n        config['operator_address'] = worker_address\n        config['version'] = NEW_VERSION\n\n    except KeyError:\n        raise RuntimeError(f'Invalid {OLD_VERSION} configuration file.')\n\n    # Commit updates\n    with open(filepath, 'w') as file:\n        file.write(json.dumps(config, indent=4))\n    print(f'OK! Migrated configuration file from v{OLD_VERSION} -> v{NEW_VERSION}.')",
  "def configuration_v1_to_v2(filepath: str):\n    \"\"\"Updates configuration file v1 to v2 by remapping 'domains' to 'domain'\"\"\"\n\n    # Read + deserialize\n    with open(filepath, 'r') as file:\n        contents = file.read()\n    config = json.loads(contents)\n\n    try:\n        # Check we have version 1 indeed\n        existing_version = config['version']\n        if existing_version != OLD_VERSION:\n            raise RuntimeError(f'Existing configuration is not version 1; Got version {existing_version}')\n\n        # Make a copy of the original file\n        backup_filepath = filepath+BACKUP_SUFFIX\n        os.rename(filepath, backup_filepath)\n        print(f'Backed up existing configuration to {backup_filepath}')\n\n        # Get current domain value\n        domains = config['domains']\n        domain = domains[0]\n        if len(domains) > 1:\n            print(f'Multiple domains configured, using the first one ({domain}).')\n\n        # Apply updates\n        del config['domains']  # deprecated\n        config['domain'] = domain\n        config['version'] = NEW_VERSION\n    except KeyError:\n        raise RuntimeError(f'Invalid {OLD_VERSION} configuration file.')\n\n    # Commit updates\n    with open(filepath, 'w') as file:\n        file.write(json.dumps(config, indent=4))\n    print('OK! Migrated configuration file from v1 -> v2.')",
  "class InvalidNewsFragment(RuntimeError):\n    pass"
]