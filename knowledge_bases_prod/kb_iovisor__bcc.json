[
  "def _stars(val, val_max, width):\n    i = 0\n    text = \"\"\n    while (1):\n        if (i > (width * val / val_max) - 1) or (i > width - 1):\n            break\n        text += \"*\"\n        i += 1\n    if val > val_max:\n        text = text[:-1] + \"+\"\n    return text",
  "def _print_log2_hist(vals, val_type, strip_leading_zero):\n    global stars_max\n    log2_dist_max = 64\n    idx_max = -1\n    val_max = 0\n\n    for i, v in enumerate(vals):\n        if v > 0: idx_max = i\n        if v > val_max: val_max = v\n\n    if idx_max <= 32:\n        header = \"     %-19s : count     distribution\"\n        body = \"%10d -> %-10d : %-8d |%-*s|\"\n        stars = stars_max\n    else:\n        header = \"               %-29s : count     distribution\"\n        body = \"%20d -> %-20d : %-8d |%-*s|\"\n        stars = int(stars_max / 2)\n\n    if idx_max > 0:\n        print(header % val_type)\n\n    for i in range(1, idx_max + 1):\n        low = (1 << i) >> 1\n        high = (1 << i) - 1\n        if (low == high):\n            low -= 1\n        val = vals[i]\n\n        if strip_leading_zero:\n            if val:\n                print(body % (low, high, val, stars,\n                              _stars(val, val_max, stars)))\n                strip_leading_zero = False\n        else:\n            print(body % (low, high, val, stars,\n                          _stars(val, val_max, stars)))",
  "def _print_linear_hist(vals, val_type):\n    global stars_max\n    log2_dist_max = 64\n    idx_max = -1\n    val_max = 0\n\n    for i, v in enumerate(vals):\n        if v > 0: idx_max = i\n        if v > val_max: val_max = v\n\n    header = \"     %-13s : count     distribution\"\n    body = \"        %-10d : %-8d |%-*s|\"\n    stars = stars_max\n\n    if idx_max >= 0:\n        print(header % val_type);\n    for i in range(0, idx_max + 1):\n        val = vals[i]\n        print(body % (i, val, stars,\n                      _stars(val, val_max, stars)))",
  "def Table(bpf, map_id, map_fd, keytype, leaftype, **kwargs):\n    \"\"\"Table(bpf, map_id, map_fd, keytype, leaftype, **kwargs)\n\n    Create a python object out of a reference to a bpf table handle\"\"\"\n\n    ttype = lib.bpf_table_type_id(bpf.module, map_id)\n    t = None\n    if ttype == BPF_MAP_TYPE_HASH:\n        t = HashTable(bpf, map_id, map_fd, keytype, leaftype)\n    elif ttype == BPF_MAP_TYPE_ARRAY:\n        t = Array(bpf, map_id, map_fd, keytype, leaftype)\n    elif ttype == BPF_MAP_TYPE_PROG_ARRAY:\n        t = ProgArray(bpf, map_id, map_fd, keytype, leaftype)\n    elif ttype == BPF_MAP_TYPE_PERF_EVENT_ARRAY:\n        t = PerfEventArray(bpf, map_id, map_fd, keytype, leaftype)\n    elif ttype == BPF_MAP_TYPE_PERCPU_HASH:\n        t = PerCpuHash(bpf, map_id, map_fd, keytype, leaftype, **kwargs)\n    elif ttype == BPF_MAP_TYPE_PERCPU_ARRAY:\n        t = PerCpuArray(bpf, map_id, map_fd, keytype, leaftype, **kwargs)\n    elif ttype == BPF_MAP_TYPE_LPM_TRIE:\n        t = LpmTrie(bpf, map_id, map_fd, keytype, leaftype)\n    elif ttype == BPF_MAP_TYPE_STACK_TRACE:\n        t = StackTrace(bpf, map_id, map_fd, keytype, leaftype)\n    elif ttype == BPF_MAP_TYPE_LRU_HASH:\n        t = LruHash(bpf, map_id, map_fd, keytype, leaftype)\n    elif ttype == BPF_MAP_TYPE_LRU_PERCPU_HASH:\n        t = LruPerCpuHash(bpf, map_id, map_fd, keytype, leaftype)\n    elif ttype == BPF_MAP_TYPE_CGROUP_ARRAY:\n        t = CgroupArray(bpf, map_id, map_fd, keytype, leaftype)\n    elif ttype == BPF_MAP_TYPE_DEVMAP:\n        t = DevMap(bpf, map_id, map_fd, keytype, leaftype)\n    elif ttype == BPF_MAP_TYPE_CPUMAP:\n        t = CpuMap(bpf, map_id, map_fd, keytype, leaftype)\n    if t == None:\n        raise Exception(\"Unknown table type %d\" % ttype)\n    return t",
  "class TableBase(MutableMapping):\n\n    def __init__(self, bpf, map_id, map_fd, keytype, leaftype):\n        self.bpf = bpf\n        self.map_id = map_id\n        self.map_fd = map_fd\n        self.Key = keytype\n        self.Leaf = leaftype\n        self.ttype = lib.bpf_table_type_id(self.bpf.module, self.map_id)\n        self.flags = lib.bpf_table_flags_id(self.bpf.module, self.map_id)\n        self._cbs = {}\n\n    def key_sprintf(self, key):\n        buf = ct.create_string_buffer(ct.sizeof(self.Key) * 8)\n        res = lib.bpf_table_key_snprintf(self.bpf.module, self.map_id, buf,\n                                         len(buf), ct.byref(key))\n        if res < 0:\n            raise Exception(\"Could not printf key\")\n        return buf.value\n\n    def leaf_sprintf(self, leaf):\n        buf = ct.create_string_buffer(ct.sizeof(self.Leaf) * 8)\n        res = lib.bpf_table_leaf_snprintf(self.bpf.module, self.map_id, buf,\n                                          len(buf), ct.byref(leaf))\n        if res < 0:\n            raise Exception(\"Could not printf leaf\")\n        return buf.value\n\n    def key_scanf(self, key_str):\n        key = self.Key()\n        res = lib.bpf_table_key_sscanf(self.bpf.module, self.map_id, key_str,\n                                       ct.byref(key))\n        if res < 0:\n            raise Exception(\"Could not scanf key\")\n        return key\n\n    def leaf_scanf(self, leaf_str):\n        leaf = self.Leaf()\n        res = lib.bpf_table_leaf_sscanf(self.bpf.module, self.map_id, leaf_str,\n                                        ct.byref(leaf))\n        if res < 0:\n            raise Exception(\"Could not scanf leaf\")\n        return leaf\n\n    def __getitem__(self, key):\n        leaf = self.Leaf()\n        res = lib.bpf_lookup_elem(self.map_fd, ct.byref(key), ct.byref(leaf))\n        if res < 0:\n            raise KeyError\n        return leaf\n\n    def __setitem__(self, key, leaf):\n        res = lib.bpf_update_elem(self.map_fd, ct.byref(key), ct.byref(leaf), 0)\n        if res < 0:\n            errstr = os.strerror(ct.get_errno())\n            raise Exception(\"Could not update table: %s\" % errstr)\n\n    def __delitem__(self, key):\n        res = lib.bpf_delete_elem(self.map_fd, ct.byref(key))\n        if res < 0:\n            raise KeyError\n\n    # override the MutableMapping's implementation of these since they\n    # don't handle KeyError nicely\n    def itervalues(self):\n        for key in self:\n            # a map entry may be deleted in between discovering the key and\n            # fetching the value, suppress such errors\n            try:\n                yield self[key]\n            except KeyError:\n                pass\n\n    def iteritems(self):\n        for key in self:\n            try:\n                yield (key, self[key])\n            except KeyError:\n                pass\n\n    def items(self):\n        return [item for item in self.iteritems()]\n\n    def values(self):\n        return [value for value in self.itervalues()]\n\n    def clear(self):\n        # default clear uses popitem, which can race with the bpf prog\n        for k in self.keys():\n            self.__delitem__(k)\n\n    def zero(self):\n        # Even though this is not very efficient, we grab the entire list of\n        # keys before enumerating it. This helps avoid a potential race where\n        # the leaf assignment changes a hash table bucket that is being\n        # enumerated by the same loop, and may lead to a hang.\n        for k in list(self.keys()):\n            self[k] = self.Leaf()\n\n    def __iter__(self):\n        return TableBase.Iter(self)\n\n    def iter(self): return self.__iter__()\n    def keys(self): return self.__iter__()\n\n    class Iter(object):\n        def __init__(self, table):\n            self.table = table\n            self.key = None\n        def __iter__(self):\n            return self\n        def __next__(self):\n            return self.next()\n        def next(self):\n            self.key = self.table.next(self.key)\n            return self.key\n\n    def next(self, key):\n        next_key = self.Key()\n\n        if key is None:\n            res = lib.bpf_get_first_key(self.map_fd, ct.byref(next_key),\n                                        ct.sizeof(self.Key))\n        else:\n            res = lib.bpf_get_next_key(self.map_fd, ct.byref(key),\n                                       ct.byref(next_key))\n\n        if res < 0:\n            raise StopIteration()\n        return next_key\n\n    def print_log2_hist(self, val_type=\"value\", section_header=\"Bucket ptr\",\n            section_print_fn=None, bucket_fn=None, strip_leading_zero=None,\n            bucket_sort_fn=None):\n        \"\"\"print_log2_hist(val_type=\"value\", section_header=\"Bucket ptr\",\n                           section_print_fn=None, bucket_fn=None,\n                           strip_leading_zero=None, bucket_sort_fn=None):\n\n        Prints a table as a log2 histogram. The table must be stored as\n        log2. The val_type argument is optional, and is a column header.\n        If the histogram has a secondary key, multiple tables will print\n        and section_header can be used as a header description for each.\n        If section_print_fn is not None, it will be passed the bucket value\n        to format into a string as it sees fit. If bucket_fn is not None,\n        it will be used to produce a bucket value for the histogram keys.\n        If the value of strip_leading_zero is not False, prints a histogram\n        that is omitted leading zeros from the beginning.\n        If bucket_sort_fn is not None, it will be used to sort the buckets\n        before iterating them, and it is useful when there are multiple fields\n        in the secondary key.\n        The maximum index allowed is log2_index_max (65), which will\n        accommodate any 64-bit integer in the histogram.\n        \"\"\"\n        if isinstance(self.Key(), ct.Structure):\n            tmp = {}\n            f1 = self.Key._fields_[0][0]\n            f2 = self.Key._fields_[1][0]\n            for k, v in self.items():\n                bucket = getattr(k, f1)\n                if bucket_fn:\n                    bucket = bucket_fn(bucket)\n                vals = tmp[bucket] = tmp.get(bucket, [0] * log2_index_max)\n                slot = getattr(k, f2)\n                vals[slot] = v.value\n\n            buckets = list(tmp.keys())\n            if bucket_sort_fn:\n                buckets = bucket_sort_fn(buckets)\n\n            for bucket in buckets:\n                vals = tmp[bucket]\n                if section_print_fn:\n                    print(\"\\n%s = %s\" % (section_header,\n                        section_print_fn(bucket)))\n                else:\n                    print(\"\\n%s = %r\" % (section_header, bucket))\n                _print_log2_hist(vals, val_type, strip_leading_zero)\n        else:\n            vals = [0] * log2_index_max\n            for k, v in self.items():\n                vals[k.value] = v.value\n            _print_log2_hist(vals, val_type, strip_leading_zero)\n\n    def print_linear_hist(self, val_type=\"value\", section_header=\"Bucket ptr\",\n            section_print_fn=None, bucket_fn=None, bucket_sort_fn=None):\n        \"\"\"print_linear_hist(val_type=\"value\", section_header=\"Bucket ptr\",\n                           section_print_fn=None, bucket_fn=None,\n                           bucket_sort_fn=None)\n\n        Prints a table as a linear histogram. This is intended to span integer\n        ranges, eg, from 0 to 100. The val_type argument is optional, and is a\n        column header.  If the histogram has a secondary key, multiple tables\n        will print and section_header can be used as a header description for\n        each.  If section_print_fn is not None, it will be passed the bucket\n        value to format into a string as it sees fit. If bucket_fn is not None,\n        it will be used to produce a bucket value for the histogram keys.\n        If bucket_sort_fn is not None, it will be used to sort the buckets\n        before iterating them, and it is useful when there are multiple fields\n        in the secondary key.\n        The maximum index allowed is linear_index_max (1025), which is hoped\n        to be sufficient for integer ranges spanned.\n        \"\"\"\n        if isinstance(self.Key(), ct.Structure):\n            tmp = {}\n            f1 = self.Key._fields_[0][0]\n            f2 = self.Key._fields_[1][0]\n            for k, v in self.items():\n                bucket = getattr(k, f1)\n                if bucket_fn:\n                    bucket = bucket_fn(bucket)\n                vals = tmp[bucket] = tmp.get(bucket, [0] * linear_index_max)\n                slot = getattr(k, f2)\n                vals[slot] = v.value\n\n            buckets = tmp.keys()\n            if bucket_sort_fn:\n                buckets = bucket_sort_fn(buckets)\n\n            for bucket in buckets:\n                vals = tmp[bucket]\n                if section_print_fn:\n                    print(\"\\n%s = %s\" % (section_header,\n                        section_print_fn(bucket)))\n                else:\n                    print(\"\\n%s = %r\" % (section_header, bucket))\n                _print_linear_hist(vals, val_type)\n        else:\n            vals = [0] * linear_index_max\n            for k, v in self.items():\n                try:\n                    vals[k.value] = v.value\n                except IndexError:\n                    # Improve error text. If the limit proves a nusiance, this\n                    # function be rewritten to avoid having one.\n                    raise IndexError((\"Index in print_linear_hist() of %d \" +\n                        \"exceeds max of %d.\") % (k.value, linear_index_max))\n            _print_linear_hist(vals, val_type)",
  "class HashTable(TableBase):\n    def __init__(self, *args, **kwargs):\n        super(HashTable, self).__init__(*args, **kwargs)\n\n    def __len__(self):\n        i = 0\n        for k in self: i += 1\n        return i",
  "class LruHash(HashTable):\n    def __init__(self, *args, **kwargs):\n        super(LruHash, self).__init__(*args, **kwargs)",
  "class ArrayBase(TableBase):\n    def __init__(self, *args, **kwargs):\n        super(ArrayBase, self).__init__(*args, **kwargs)\n        self.max_entries = int(lib.bpf_table_max_entries_id(self.bpf.module,\n                self.map_id))\n\n    def _normalize_key(self, key):\n        if isinstance(key, int):\n            if key < 0:\n                key = len(self) + key\n            key = self.Key(key)\n        if not isinstance(key, ct._SimpleCData):\n            raise IndexError(\"Array index must be an integer type\")\n        if key.value >= len(self):\n            raise IndexError(\"Array index out of range\")\n        return key\n\n    def __len__(self):\n        return self.max_entries\n\n    def __getitem__(self, key):\n        key = self._normalize_key(key)\n        return super(ArrayBase, self).__getitem__(key)\n\n    def __setitem__(self, key, leaf):\n        key = self._normalize_key(key)\n        super(ArrayBase, self).__setitem__(key, leaf)\n\n    def __delitem__(self, key):\n        key = self._normalize_key(key)\n        super(ArrayBase, self).__delitem__(key)\n\n    def clearitem(self, key):\n        key = self._normalize_key(key)\n        leaf = self.Leaf()\n        res = lib.bpf_update_elem(self.map_fd, ct.byref(key), ct.byref(leaf), 0)\n        if res < 0:\n            raise Exception(\"Could not clear item\")\n\n    def __iter__(self):\n        return ArrayBase.Iter(self, self.Key)\n\n    class Iter(object):\n        def __init__(self, table, keytype):\n            self.Key = keytype\n            self.table = table\n            self.i = -1\n\n        def __iter__(self):\n            return self\n        def __next__(self):\n            return self.next()\n        def next(self):\n            self.i += 1\n            if self.i == len(self.table):\n                raise StopIteration()\n            return self.Key(self.i)",
  "class Array(ArrayBase):\n    def __init__(self, *args, **kwargs):\n        super(Array, self).__init__(*args, **kwargs)\n\n    def __delitem__(self, key):\n        # Delete in Array type does not have an effect, so zero out instead\n        self.clearitem(key)",
  "class ProgArray(ArrayBase):\n    def __init__(self, *args, **kwargs):\n        super(ProgArray, self).__init__(*args, **kwargs)\n\n    def __setitem__(self, key, leaf):\n        if isinstance(leaf, int):\n            leaf = self.Leaf(leaf)\n        if isinstance(leaf, self.bpf.Function):\n            leaf = self.Leaf(leaf.fd)\n        super(ProgArray, self).__setitem__(key, leaf)",
  "class FileDesc:\n    def __init__(self, fd):\n        if (fd is None) or (fd < 0):\n            raise Exception(\"Invalid file descriptor\")\n        self.fd = fd\n\n    def clean_up(self):\n        if (self.fd is not None) and (self.fd >= 0):\n            os.close(self.fd)\n            self.fd = None\n\n    def __del__(self):\n        self.clean_up()\n\n    def __enter__(self, *args, **kwargs):\n        return self\n\n    def __exit__(self, *args, **kwargs):\n        self.clean_up()",
  "class CgroupArray(ArrayBase):\n    def __init__(self, *args, **kwargs):\n        super(CgroupArray, self).__init__(*args, **kwargs)\n\n    def __setitem__(self, key, leaf):\n        if isinstance(leaf, int):\n            super(CgroupArray, self).__setitem__(key, self.Leaf(leaf))\n        elif isinstance(leaf, str):\n            # TODO: Add os.O_CLOEXEC once we move to Python version >3.3\n            with FileDesc(os.open(leaf, os.O_RDONLY)) as f:\n                super(CgroupArray, self).__setitem__(key, self.Leaf(f.fd))\n        else:\n            raise Exception(\"Cgroup array key must be either FD or cgroup path\")",
  "class PerfEventArray(ArrayBase):\n\n    def __init__(self, *args, **kwargs):\n        super(PerfEventArray, self).__init__(*args, **kwargs)\n        self._open_key_fds = {}\n\n    def __del__(self):\n        keys = list(self._open_key_fds.keys())\n        for key in keys:\n            del self[key]\n\n    def __delitem__(self, key):\n        if key not in self._open_key_fds:\n            return\n        # Delete entry from the array\n        super(PerfEventArray, self).__delitem__(key)\n        key_id = (id(self), key)\n        if key_id in self.bpf.perf_buffers:\n            # The key is opened for perf ring buffer\n            lib.perf_reader_free(self.bpf.perf_buffers[key_id])\n            del self.bpf.perf_buffers[key_id]\n            del self._cbs[key]\n        else:\n            # The key is opened for perf event read\n            lib.bpf_close_perf_event_fd(self._open_key_fds[key])\n        del self._open_key_fds[key]\n\n    def open_perf_buffer(self, callback, page_cnt=8, lost_cb=None):\n        \"\"\"open_perf_buffers(callback)\n\n        Opens a set of per-cpu ring buffer to receive custom perf event\n        data from the bpf program. The callback will be invoked for each\n        event submitted from the kernel, up to millions per second. Use\n        page_cnt to change the size of the per-cpu ring buffer. The value\n        must be a power of two and defaults to 8.\n        \"\"\"\n\n        if page_cnt & (page_cnt - 1) != 0:\n            raise Exception(\"Perf buffer page_cnt must be a power of two\")\n\n        for i in get_online_cpus():\n            self._open_perf_buffer(i, callback, page_cnt, lost_cb)\n\n    def _open_perf_buffer(self, cpu, callback, page_cnt, lost_cb):\n        def raw_cb_(_, data, size):\n            try:\n                callback(cpu, data, size)\n            except IOError as e:\n                if e.errno == errno.EPIPE:\n                    exit()\n                else:\n                    raise e\n        def lost_cb_(_, lost):\n            try:\n                lost_cb(lost)\n            except IOError as e:\n                if e.errno == errno.EPIPE:\n                    exit()\n                else:\n                    raise e\n        fn = _RAW_CB_TYPE(raw_cb_)\n        lost_fn = _LOST_CB_TYPE(lost_cb_) if lost_cb else ct.cast(None, _LOST_CB_TYPE)\n        reader = lib.bpf_open_perf_buffer(fn, lost_fn, None, -1, cpu, page_cnt)\n        if not reader:\n            raise Exception(\"Could not open perf buffer\")\n        fd = lib.perf_reader_fd(reader)\n        self[self.Key(cpu)] = self.Leaf(fd)\n        self.bpf.perf_buffers[(id(self), cpu)] = reader\n        # keep a refcnt\n        self._cbs[cpu] = (fn, lost_fn)\n        # The actual fd is held by the perf reader, add to track opened keys\n        self._open_key_fds[cpu] = -1\n\n    def _open_perf_event(self, cpu, typ, config):\n        fd = lib.bpf_open_perf_event(typ, config, -1, cpu)\n        if fd < 0:\n            raise Exception(\"bpf_open_perf_event failed\")\n        self[self.Key(cpu)] = self.Leaf(fd)\n        self._open_key_fds[cpu] = fd\n\n    def open_perf_event(self, typ, config):\n        \"\"\"open_perf_event(typ, config)\n\n        Configures the table such that calls from the bpf program to\n        table.perf_read(CUR_CPU_IDENTIFIER) will return the hardware\n        counter denoted by event ev on the local cpu.\n        \"\"\"\n        for i in get_online_cpus():\n            self._open_perf_event(i, typ, config)",
  "class PerCpuHash(HashTable):\n    def __init__(self, *args, **kwargs):\n        self.reducer = kwargs.pop(\"reducer\", None)\n        super(PerCpuHash, self).__init__(*args, **kwargs)\n        self.sLeaf = self.Leaf\n        self.total_cpu = len(get_possible_cpus())\n        # This needs to be 8 as hard coded into the linux kernel.\n        self.alignment = ct.sizeof(self.sLeaf) % 8\n        if self.alignment is 0:\n            self.Leaf = self.sLeaf * self.total_cpu\n        else:\n            # Currently Float, Char, un-aligned structs are not supported\n            if self.sLeaf == ct.c_uint:\n                self.Leaf = ct.c_uint64 * self.total_cpu\n            elif self.sLeaf == ct.c_int:\n                self.Leaf = ct.c_int64 * self.total_cpu\n            else:\n                raise IndexError(\"Leaf must be aligned to 8 bytes\")\n\n    def getvalue(self, key):\n        result = super(PerCpuHash, self).__getitem__(key)\n        if self.alignment is 0:\n            ret = result\n        else:\n            ret = (self.sLeaf * self.total_cpu)()\n            for i in range(0, self.total_cpu):\n                ret[i] = result[i]\n        return ret\n\n    def __getitem__(self, key):\n        if self.reducer:\n            return reduce(self.reducer, self.getvalue(key))\n        else:\n            return self.getvalue(key)\n\n    def __setitem__(self, key, leaf):\n        super(PerCpuHash, self).__setitem__(key, leaf)\n\n    def sum(self, key):\n        if isinstance(self.Leaf(), ct.Structure):\n            raise IndexError(\"Leaf must be an integer type for default sum functions\")\n        return self.sLeaf(sum(self.getvalue(key)))\n\n    def max(self, key):\n        if isinstance(self.Leaf(), ct.Structure):\n            raise IndexError(\"Leaf must be an integer type for default max functions\")\n        return self.sLeaf(max(self.getvalue(key)))\n\n    def average(self, key):\n        result = self.sum(key)\n        return result.value / self.total_cpu",
  "class LruPerCpuHash(PerCpuHash):\n    def __init__(self, *args, **kwargs):\n        super(LruPerCpuHash, self).__init__(*args, **kwargs)",
  "class PerCpuArray(ArrayBase):\n    def __init__(self, *args, **kwargs):\n        self.reducer = kwargs.pop(\"reducer\", None)\n        super(PerCpuArray, self).__init__(*args, **kwargs)\n        self.sLeaf = self.Leaf\n        self.total_cpu = len(get_possible_cpus())\n        # This needs to be 8 as hard coded into the linux kernel.\n        self.alignment = ct.sizeof(self.sLeaf) % 8\n        if self.alignment is 0:\n            self.Leaf = self.sLeaf * self.total_cpu\n        else:\n            # Currently Float, Char, un-aligned structs are not supported\n            if self.sLeaf == ct.c_uint:\n                self.Leaf = ct.c_uint64 * self.total_cpu\n            elif self.sLeaf == ct.c_int:\n                self.Leaf = ct.c_int64 * self.total_cpu\n            else:\n                raise IndexError(\"Leaf must be aligned to 8 bytes\")\n\n    def getvalue(self, key):\n        result = super(PerCpuArray, self).__getitem__(key)\n        if self.alignment is 0:\n            ret = result\n        else:\n            ret = (self.sLeaf * self.total_cpu)()\n            for i in range(0, self.total_cpu):\n                ret[i] = result[i]\n        return ret\n\n    def __getitem__(self, key):\n        if (self.reducer):\n            return reduce(self.reducer, self.getvalue(key))\n        else:\n            return self.getvalue(key)\n\n    def __setitem__(self, key, leaf):\n        super(PerCpuArray, self).__setitem__(key, leaf)\n\n    def __delitem__(self, key):\n        # Delete in this type does not have an effect, so zero out instead\n        self.clearitem(key)\n\n    def sum(self, key):\n        if isinstance(self.Leaf(), ct.Structure):\n            raise IndexError(\"Leaf must be an integer type for default sum functions\")\n        return self.sLeaf(sum(self.getvalue(key)))\n\n    def max(self, key):\n        if isinstance(self.Leaf(), ct.Structure):\n            raise IndexError(\"Leaf must be an integer type for default max functions\")\n        return self.sLeaf(max(self.getvalue(key)))\n\n    def average(self, key):\n        result = self.sum(key)\n        return result.value / self.total_cpu",
  "class LpmTrie(TableBase):\n    def __init__(self, *args, **kwargs):\n        super(LpmTrie, self).__init__(*args, **kwargs)\n\n    def __len__(self):\n        raise NotImplementedError",
  "class StackTrace(TableBase):\n    MAX_DEPTH = 127\n    BPF_F_STACK_BUILD_ID = (1<<5)\n    BPF_STACK_BUILD_ID_EMPTY =  0 #can't get stacktrace\n    BPF_STACK_BUILD_ID_VALID = 1 #valid build-id,ip\n    BPF_STACK_BUILD_ID_IP = 2 #fallback to ip\n\n    def __init__(self, *args, **kwargs):\n        super(StackTrace, self).__init__(*args, **kwargs)\n\n    class StackWalker(object):\n        def __init__(self, stack, flags, resolve=None):\n            self.stack = stack\n            self.n = -1\n            self.resolve = resolve\n            self.flags = flags\n\n        def __iter__(self):\n            return self\n\n        def __next__(self):\n            return self.next()\n\n        def next(self):\n            self.n += 1\n            if self.n == StackTrace.MAX_DEPTH:\n                raise StopIteration()\n\n            if self.flags & StackTrace.BPF_F_STACK_BUILD_ID:\n              addr = self.stack.trace[self.n]\n              if addr.status == StackTrace.BPF_STACK_BUILD_ID_IP or \\\n                 addr.status == StackTrace.BPF_STACK_BUILD_ID_EMPTY:\n                  raise StopIteration()\n            else:\n              addr = self.stack.ip[self.n]\n\n            if addr == 0 :\n                raise StopIteration()\n\n            return self.resolve(addr) if self.resolve else addr\n\n    def walk(self, stack_id, resolve=None):\n        return StackTrace.StackWalker(self[self.Key(stack_id)], self.flags, resolve)\n\n    def __len__(self):\n        i = 0\n        for k in self: i += 1\n        return i\n\n    def clear(self):\n        pass",
  "class DevMap(ArrayBase):\n    def __init__(self, *args, **kwargs):\n        super(DevMap, self).__init__(*args, **kwargs)",
  "class CpuMap(ArrayBase):\n    def __init__(self, *args, **kwargs):\n        super(CpuMap, self).__init__(*args, **kwargs)",
  "def __init__(self, bpf, map_id, map_fd, keytype, leaftype):\n        self.bpf = bpf\n        self.map_id = map_id\n        self.map_fd = map_fd\n        self.Key = keytype\n        self.Leaf = leaftype\n        self.ttype = lib.bpf_table_type_id(self.bpf.module, self.map_id)\n        self.flags = lib.bpf_table_flags_id(self.bpf.module, self.map_id)\n        self._cbs = {}",
  "def key_sprintf(self, key):\n        buf = ct.create_string_buffer(ct.sizeof(self.Key) * 8)\n        res = lib.bpf_table_key_snprintf(self.bpf.module, self.map_id, buf,\n                                         len(buf), ct.byref(key))\n        if res < 0:\n            raise Exception(\"Could not printf key\")\n        return buf.value",
  "def leaf_sprintf(self, leaf):\n        buf = ct.create_string_buffer(ct.sizeof(self.Leaf) * 8)\n        res = lib.bpf_table_leaf_snprintf(self.bpf.module, self.map_id, buf,\n                                          len(buf), ct.byref(leaf))\n        if res < 0:\n            raise Exception(\"Could not printf leaf\")\n        return buf.value",
  "def key_scanf(self, key_str):\n        key = self.Key()\n        res = lib.bpf_table_key_sscanf(self.bpf.module, self.map_id, key_str,\n                                       ct.byref(key))\n        if res < 0:\n            raise Exception(\"Could not scanf key\")\n        return key",
  "def leaf_scanf(self, leaf_str):\n        leaf = self.Leaf()\n        res = lib.bpf_table_leaf_sscanf(self.bpf.module, self.map_id, leaf_str,\n                                        ct.byref(leaf))\n        if res < 0:\n            raise Exception(\"Could not scanf leaf\")\n        return leaf",
  "def __getitem__(self, key):\n        leaf = self.Leaf()\n        res = lib.bpf_lookup_elem(self.map_fd, ct.byref(key), ct.byref(leaf))\n        if res < 0:\n            raise KeyError\n        return leaf",
  "def __setitem__(self, key, leaf):\n        res = lib.bpf_update_elem(self.map_fd, ct.byref(key), ct.byref(leaf), 0)\n        if res < 0:\n            errstr = os.strerror(ct.get_errno())\n            raise Exception(\"Could not update table: %s\" % errstr)",
  "def __delitem__(self, key):\n        res = lib.bpf_delete_elem(self.map_fd, ct.byref(key))\n        if res < 0:\n            raise KeyError",
  "def itervalues(self):\n        for key in self:\n            # a map entry may be deleted in between discovering the key and\n            # fetching the value, suppress such errors\n            try:\n                yield self[key]\n            except KeyError:\n                pass",
  "def iteritems(self):\n        for key in self:\n            try:\n                yield (key, self[key])\n            except KeyError:\n                pass",
  "def items(self):\n        return [item for item in self.iteritems()]",
  "def values(self):\n        return [value for value in self.itervalues()]",
  "def clear(self):\n        # default clear uses popitem, which can race with the bpf prog\n        for k in self.keys():\n            self.__delitem__(k)",
  "def zero(self):\n        # Even though this is not very efficient, we grab the entire list of\n        # keys before enumerating it. This helps avoid a potential race where\n        # the leaf assignment changes a hash table bucket that is being\n        # enumerated by the same loop, and may lead to a hang.\n        for k in list(self.keys()):\n            self[k] = self.Leaf()",
  "def __iter__(self):\n        return TableBase.Iter(self)",
  "def iter(self): return self.__iter__()",
  "def keys(self): return self.__iter__()",
  "class Iter(object):\n        def __init__(self, table):\n            self.table = table\n            self.key = None\n        def __iter__(self):\n            return self\n        def __next__(self):\n            return self.next()\n        def next(self):\n            self.key = self.table.next(self.key)\n            return self.key",
  "def next(self, key):\n        next_key = self.Key()\n\n        if key is None:\n            res = lib.bpf_get_first_key(self.map_fd, ct.byref(next_key),\n                                        ct.sizeof(self.Key))\n        else:\n            res = lib.bpf_get_next_key(self.map_fd, ct.byref(key),\n                                       ct.byref(next_key))\n\n        if res < 0:\n            raise StopIteration()\n        return next_key",
  "def print_log2_hist(self, val_type=\"value\", section_header=\"Bucket ptr\",\n            section_print_fn=None, bucket_fn=None, strip_leading_zero=None,\n            bucket_sort_fn=None):\n        \"\"\"print_log2_hist(val_type=\"value\", section_header=\"Bucket ptr\",\n                           section_print_fn=None, bucket_fn=None,\n                           strip_leading_zero=None, bucket_sort_fn=None):\n\n        Prints a table as a log2 histogram. The table must be stored as\n        log2. The val_type argument is optional, and is a column header.\n        If the histogram has a secondary key, multiple tables will print\n        and section_header can be used as a header description for each.\n        If section_print_fn is not None, it will be passed the bucket value\n        to format into a string as it sees fit. If bucket_fn is not None,\n        it will be used to produce a bucket value for the histogram keys.\n        If the value of strip_leading_zero is not False, prints a histogram\n        that is omitted leading zeros from the beginning.\n        If bucket_sort_fn is not None, it will be used to sort the buckets\n        before iterating them, and it is useful when there are multiple fields\n        in the secondary key.\n        The maximum index allowed is log2_index_max (65), which will\n        accommodate any 64-bit integer in the histogram.\n        \"\"\"\n        if isinstance(self.Key(), ct.Structure):\n            tmp = {}\n            f1 = self.Key._fields_[0][0]\n            f2 = self.Key._fields_[1][0]\n            for k, v in self.items():\n                bucket = getattr(k, f1)\n                if bucket_fn:\n                    bucket = bucket_fn(bucket)\n                vals = tmp[bucket] = tmp.get(bucket, [0] * log2_index_max)\n                slot = getattr(k, f2)\n                vals[slot] = v.value\n\n            buckets = list(tmp.keys())\n            if bucket_sort_fn:\n                buckets = bucket_sort_fn(buckets)\n\n            for bucket in buckets:\n                vals = tmp[bucket]\n                if section_print_fn:\n                    print(\"\\n%s = %s\" % (section_header,\n                        section_print_fn(bucket)))\n                else:\n                    print(\"\\n%s = %r\" % (section_header, bucket))\n                _print_log2_hist(vals, val_type, strip_leading_zero)\n        else:\n            vals = [0] * log2_index_max\n            for k, v in self.items():\n                vals[k.value] = v.value\n            _print_log2_hist(vals, val_type, strip_leading_zero)",
  "def print_linear_hist(self, val_type=\"value\", section_header=\"Bucket ptr\",\n            section_print_fn=None, bucket_fn=None, bucket_sort_fn=None):\n        \"\"\"print_linear_hist(val_type=\"value\", section_header=\"Bucket ptr\",\n                           section_print_fn=None, bucket_fn=None,\n                           bucket_sort_fn=None)\n\n        Prints a table as a linear histogram. This is intended to span integer\n        ranges, eg, from 0 to 100. The val_type argument is optional, and is a\n        column header.  If the histogram has a secondary key, multiple tables\n        will print and section_header can be used as a header description for\n        each.  If section_print_fn is not None, it will be passed the bucket\n        value to format into a string as it sees fit. If bucket_fn is not None,\n        it will be used to produce a bucket value for the histogram keys.\n        If bucket_sort_fn is not None, it will be used to sort the buckets\n        before iterating them, and it is useful when there are multiple fields\n        in the secondary key.\n        The maximum index allowed is linear_index_max (1025), which is hoped\n        to be sufficient for integer ranges spanned.\n        \"\"\"\n        if isinstance(self.Key(), ct.Structure):\n            tmp = {}\n            f1 = self.Key._fields_[0][0]\n            f2 = self.Key._fields_[1][0]\n            for k, v in self.items():\n                bucket = getattr(k, f1)\n                if bucket_fn:\n                    bucket = bucket_fn(bucket)\n                vals = tmp[bucket] = tmp.get(bucket, [0] * linear_index_max)\n                slot = getattr(k, f2)\n                vals[slot] = v.value\n\n            buckets = tmp.keys()\n            if bucket_sort_fn:\n                buckets = bucket_sort_fn(buckets)\n\n            for bucket in buckets:\n                vals = tmp[bucket]\n                if section_print_fn:\n                    print(\"\\n%s = %s\" % (section_header,\n                        section_print_fn(bucket)))\n                else:\n                    print(\"\\n%s = %r\" % (section_header, bucket))\n                _print_linear_hist(vals, val_type)\n        else:\n            vals = [0] * linear_index_max\n            for k, v in self.items():\n                try:\n                    vals[k.value] = v.value\n                except IndexError:\n                    # Improve error text. If the limit proves a nusiance, this\n                    # function be rewritten to avoid having one.\n                    raise IndexError((\"Index in print_linear_hist() of %d \" +\n                        \"exceeds max of %d.\") % (k.value, linear_index_max))\n            _print_linear_hist(vals, val_type)",
  "def __init__(self, *args, **kwargs):\n        super(HashTable, self).__init__(*args, **kwargs)",
  "def __len__(self):\n        i = 0\n        for k in self: i += 1\n        return i",
  "def __init__(self, *args, **kwargs):\n        super(LruHash, self).__init__(*args, **kwargs)",
  "def __init__(self, *args, **kwargs):\n        super(ArrayBase, self).__init__(*args, **kwargs)\n        self.max_entries = int(lib.bpf_table_max_entries_id(self.bpf.module,\n                self.map_id))",
  "def _normalize_key(self, key):\n        if isinstance(key, int):\n            if key < 0:\n                key = len(self) + key\n            key = self.Key(key)\n        if not isinstance(key, ct._SimpleCData):\n            raise IndexError(\"Array index must be an integer type\")\n        if key.value >= len(self):\n            raise IndexError(\"Array index out of range\")\n        return key",
  "def __len__(self):\n        return self.max_entries",
  "def __getitem__(self, key):\n        key = self._normalize_key(key)\n        return super(ArrayBase, self).__getitem__(key)",
  "def __setitem__(self, key, leaf):\n        key = self._normalize_key(key)\n        super(ArrayBase, self).__setitem__(key, leaf)",
  "def __delitem__(self, key):\n        key = self._normalize_key(key)\n        super(ArrayBase, self).__delitem__(key)",
  "def clearitem(self, key):\n        key = self._normalize_key(key)\n        leaf = self.Leaf()\n        res = lib.bpf_update_elem(self.map_fd, ct.byref(key), ct.byref(leaf), 0)\n        if res < 0:\n            raise Exception(\"Could not clear item\")",
  "def __iter__(self):\n        return ArrayBase.Iter(self, self.Key)",
  "class Iter(object):\n        def __init__(self, table, keytype):\n            self.Key = keytype\n            self.table = table\n            self.i = -1\n\n        def __iter__(self):\n            return self\n        def __next__(self):\n            return self.next()\n        def next(self):\n            self.i += 1\n            if self.i == len(self.table):\n                raise StopIteration()\n            return self.Key(self.i)",
  "def __init__(self, *args, **kwargs):\n        super(Array, self).__init__(*args, **kwargs)",
  "def __delitem__(self, key):\n        # Delete in Array type does not have an effect, so zero out instead\n        self.clearitem(key)",
  "def __init__(self, *args, **kwargs):\n        super(ProgArray, self).__init__(*args, **kwargs)",
  "def __setitem__(self, key, leaf):\n        if isinstance(leaf, int):\n            leaf = self.Leaf(leaf)\n        if isinstance(leaf, self.bpf.Function):\n            leaf = self.Leaf(leaf.fd)\n        super(ProgArray, self).__setitem__(key, leaf)",
  "def __init__(self, fd):\n        if (fd is None) or (fd < 0):\n            raise Exception(\"Invalid file descriptor\")\n        self.fd = fd",
  "def clean_up(self):\n        if (self.fd is not None) and (self.fd >= 0):\n            os.close(self.fd)\n            self.fd = None",
  "def __del__(self):\n        self.clean_up()",
  "def __enter__(self, *args, **kwargs):\n        return self",
  "def __exit__(self, *args, **kwargs):\n        self.clean_up()",
  "def __init__(self, *args, **kwargs):\n        super(CgroupArray, self).__init__(*args, **kwargs)",
  "def __setitem__(self, key, leaf):\n        if isinstance(leaf, int):\n            super(CgroupArray, self).__setitem__(key, self.Leaf(leaf))\n        elif isinstance(leaf, str):\n            # TODO: Add os.O_CLOEXEC once we move to Python version >3.3\n            with FileDesc(os.open(leaf, os.O_RDONLY)) as f:\n                super(CgroupArray, self).__setitem__(key, self.Leaf(f.fd))\n        else:\n            raise Exception(\"Cgroup array key must be either FD or cgroup path\")",
  "def __init__(self, *args, **kwargs):\n        super(PerfEventArray, self).__init__(*args, **kwargs)\n        self._open_key_fds = {}",
  "def __del__(self):\n        keys = list(self._open_key_fds.keys())\n        for key in keys:\n            del self[key]",
  "def __delitem__(self, key):\n        if key not in self._open_key_fds:\n            return\n        # Delete entry from the array\n        super(PerfEventArray, self).__delitem__(key)\n        key_id = (id(self), key)\n        if key_id in self.bpf.perf_buffers:\n            # The key is opened for perf ring buffer\n            lib.perf_reader_free(self.bpf.perf_buffers[key_id])\n            del self.bpf.perf_buffers[key_id]\n            del self._cbs[key]\n        else:\n            # The key is opened for perf event read\n            lib.bpf_close_perf_event_fd(self._open_key_fds[key])\n        del self._open_key_fds[key]",
  "def open_perf_buffer(self, callback, page_cnt=8, lost_cb=None):\n        \"\"\"open_perf_buffers(callback)\n\n        Opens a set of per-cpu ring buffer to receive custom perf event\n        data from the bpf program. The callback will be invoked for each\n        event submitted from the kernel, up to millions per second. Use\n        page_cnt to change the size of the per-cpu ring buffer. The value\n        must be a power of two and defaults to 8.\n        \"\"\"\n\n        if page_cnt & (page_cnt - 1) != 0:\n            raise Exception(\"Perf buffer page_cnt must be a power of two\")\n\n        for i in get_online_cpus():\n            self._open_perf_buffer(i, callback, page_cnt, lost_cb)",
  "def _open_perf_buffer(self, cpu, callback, page_cnt, lost_cb):\n        def raw_cb_(_, data, size):\n            try:\n                callback(cpu, data, size)\n            except IOError as e:\n                if e.errno == errno.EPIPE:\n                    exit()\n                else:\n                    raise e\n        def lost_cb_(_, lost):\n            try:\n                lost_cb(lost)\n            except IOError as e:\n                if e.errno == errno.EPIPE:\n                    exit()\n                else:\n                    raise e\n        fn = _RAW_CB_TYPE(raw_cb_)\n        lost_fn = _LOST_CB_TYPE(lost_cb_) if lost_cb else ct.cast(None, _LOST_CB_TYPE)\n        reader = lib.bpf_open_perf_buffer(fn, lost_fn, None, -1, cpu, page_cnt)\n        if not reader:\n            raise Exception(\"Could not open perf buffer\")\n        fd = lib.perf_reader_fd(reader)\n        self[self.Key(cpu)] = self.Leaf(fd)\n        self.bpf.perf_buffers[(id(self), cpu)] = reader\n        # keep a refcnt\n        self._cbs[cpu] = (fn, lost_fn)\n        # The actual fd is held by the perf reader, add to track opened keys\n        self._open_key_fds[cpu] = -1",
  "def _open_perf_event(self, cpu, typ, config):\n        fd = lib.bpf_open_perf_event(typ, config, -1, cpu)\n        if fd < 0:\n            raise Exception(\"bpf_open_perf_event failed\")\n        self[self.Key(cpu)] = self.Leaf(fd)\n        self._open_key_fds[cpu] = fd",
  "def open_perf_event(self, typ, config):\n        \"\"\"open_perf_event(typ, config)\n\n        Configures the table such that calls from the bpf program to\n        table.perf_read(CUR_CPU_IDENTIFIER) will return the hardware\n        counter denoted by event ev on the local cpu.\n        \"\"\"\n        for i in get_online_cpus():\n            self._open_perf_event(i, typ, config)",
  "def __init__(self, *args, **kwargs):\n        self.reducer = kwargs.pop(\"reducer\", None)\n        super(PerCpuHash, self).__init__(*args, **kwargs)\n        self.sLeaf = self.Leaf\n        self.total_cpu = len(get_possible_cpus())\n        # This needs to be 8 as hard coded into the linux kernel.\n        self.alignment = ct.sizeof(self.sLeaf) % 8\n        if self.alignment is 0:\n            self.Leaf = self.sLeaf * self.total_cpu\n        else:\n            # Currently Float, Char, un-aligned structs are not supported\n            if self.sLeaf == ct.c_uint:\n                self.Leaf = ct.c_uint64 * self.total_cpu\n            elif self.sLeaf == ct.c_int:\n                self.Leaf = ct.c_int64 * self.total_cpu\n            else:\n                raise IndexError(\"Leaf must be aligned to 8 bytes\")",
  "def getvalue(self, key):\n        result = super(PerCpuHash, self).__getitem__(key)\n        if self.alignment is 0:\n            ret = result\n        else:\n            ret = (self.sLeaf * self.total_cpu)()\n            for i in range(0, self.total_cpu):\n                ret[i] = result[i]\n        return ret",
  "def __getitem__(self, key):\n        if self.reducer:\n            return reduce(self.reducer, self.getvalue(key))\n        else:\n            return self.getvalue(key)",
  "def __setitem__(self, key, leaf):\n        super(PerCpuHash, self).__setitem__(key, leaf)",
  "def sum(self, key):\n        if isinstance(self.Leaf(), ct.Structure):\n            raise IndexError(\"Leaf must be an integer type for default sum functions\")\n        return self.sLeaf(sum(self.getvalue(key)))",
  "def max(self, key):\n        if isinstance(self.Leaf(), ct.Structure):\n            raise IndexError(\"Leaf must be an integer type for default max functions\")\n        return self.sLeaf(max(self.getvalue(key)))",
  "def average(self, key):\n        result = self.sum(key)\n        return result.value / self.total_cpu",
  "def __init__(self, *args, **kwargs):\n        super(LruPerCpuHash, self).__init__(*args, **kwargs)",
  "def __init__(self, *args, **kwargs):\n        self.reducer = kwargs.pop(\"reducer\", None)\n        super(PerCpuArray, self).__init__(*args, **kwargs)\n        self.sLeaf = self.Leaf\n        self.total_cpu = len(get_possible_cpus())\n        # This needs to be 8 as hard coded into the linux kernel.\n        self.alignment = ct.sizeof(self.sLeaf) % 8\n        if self.alignment is 0:\n            self.Leaf = self.sLeaf * self.total_cpu\n        else:\n            # Currently Float, Char, un-aligned structs are not supported\n            if self.sLeaf == ct.c_uint:\n                self.Leaf = ct.c_uint64 * self.total_cpu\n            elif self.sLeaf == ct.c_int:\n                self.Leaf = ct.c_int64 * self.total_cpu\n            else:\n                raise IndexError(\"Leaf must be aligned to 8 bytes\")",
  "def getvalue(self, key):\n        result = super(PerCpuArray, self).__getitem__(key)\n        if self.alignment is 0:\n            ret = result\n        else:\n            ret = (self.sLeaf * self.total_cpu)()\n            for i in range(0, self.total_cpu):\n                ret[i] = result[i]\n        return ret",
  "def __getitem__(self, key):\n        if (self.reducer):\n            return reduce(self.reducer, self.getvalue(key))\n        else:\n            return self.getvalue(key)",
  "def __setitem__(self, key, leaf):\n        super(PerCpuArray, self).__setitem__(key, leaf)",
  "def __delitem__(self, key):\n        # Delete in this type does not have an effect, so zero out instead\n        self.clearitem(key)",
  "def sum(self, key):\n        if isinstance(self.Leaf(), ct.Structure):\n            raise IndexError(\"Leaf must be an integer type for default sum functions\")\n        return self.sLeaf(sum(self.getvalue(key)))",
  "def max(self, key):\n        if isinstance(self.Leaf(), ct.Structure):\n            raise IndexError(\"Leaf must be an integer type for default max functions\")\n        return self.sLeaf(max(self.getvalue(key)))",
  "def average(self, key):\n        result = self.sum(key)\n        return result.value / self.total_cpu",
  "def __init__(self, *args, **kwargs):\n        super(LpmTrie, self).__init__(*args, **kwargs)",
  "def __len__(self):\n        raise NotImplementedError",
  "def __init__(self, *args, **kwargs):\n        super(StackTrace, self).__init__(*args, **kwargs)",
  "class StackWalker(object):\n        def __init__(self, stack, flags, resolve=None):\n            self.stack = stack\n            self.n = -1\n            self.resolve = resolve\n            self.flags = flags\n\n        def __iter__(self):\n            return self\n\n        def __next__(self):\n            return self.next()\n\n        def next(self):\n            self.n += 1\n            if self.n == StackTrace.MAX_DEPTH:\n                raise StopIteration()\n\n            if self.flags & StackTrace.BPF_F_STACK_BUILD_ID:\n              addr = self.stack.trace[self.n]\n              if addr.status == StackTrace.BPF_STACK_BUILD_ID_IP or \\\n                 addr.status == StackTrace.BPF_STACK_BUILD_ID_EMPTY:\n                  raise StopIteration()\n            else:\n              addr = self.stack.ip[self.n]\n\n            if addr == 0 :\n                raise StopIteration()\n\n            return self.resolve(addr) if self.resolve else addr",
  "def walk(self, stack_id, resolve=None):\n        return StackTrace.StackWalker(self[self.Key(stack_id)], self.flags, resolve)",
  "def __len__(self):\n        i = 0\n        for k in self: i += 1\n        return i",
  "def clear(self):\n        pass",
  "def __init__(self, *args, **kwargs):\n        super(DevMap, self).__init__(*args, **kwargs)",
  "def __init__(self, *args, **kwargs):\n        super(CpuMap, self).__init__(*args, **kwargs)",
  "def __init__(self, table):\n            self.table = table\n            self.key = None",
  "def __iter__(self):\n            return self",
  "def __next__(self):\n            return self.next()",
  "def next(self):\n            self.key = self.table.next(self.key)\n            return self.key",
  "def __init__(self, table, keytype):\n            self.Key = keytype\n            self.table = table\n            self.i = -1",
  "def __iter__(self):\n            return self",
  "def __next__(self):\n            return self.next()",
  "def next(self):\n            self.i += 1\n            if self.i == len(self.table):\n                raise StopIteration()\n            return self.Key(self.i)",
  "def raw_cb_(_, data, size):\n            try:\n                callback(cpu, data, size)\n            except IOError as e:\n                if e.errno == errno.EPIPE:\n                    exit()\n                else:\n                    raise e",
  "def lost_cb_(_, lost):\n            try:\n                lost_cb(lost)\n            except IOError as e:\n                if e.errno == errno.EPIPE:\n                    exit()\n                else:\n                    raise e",
  "def __init__(self, stack, flags, resolve=None):\n            self.stack = stack\n            self.n = -1\n            self.resolve = resolve\n            self.flags = flags",
  "def __iter__(self):\n            return self",
  "def __next__(self):\n            return self.next()",
  "def next(self):\n            self.n += 1\n            if self.n == StackTrace.MAX_DEPTH:\n                raise StopIteration()\n\n            if self.flags & StackTrace.BPF_F_STACK_BUILD_ID:\n              addr = self.stack.trace[self.n]\n              if addr.status == StackTrace.BPF_STACK_BUILD_ID_IP or \\\n                 addr.status == StackTrace.BPF_STACK_BUILD_ID_EMPTY:\n                  raise StopIteration()\n            else:\n              addr = self.stack.ip[self.n]\n\n            if addr == 0 :\n                raise StopIteration()\n\n            return self.resolve(addr) if self.resolve else addr",
  "def _read_cpu_range(path):\n    cpus = []\n    with open(path, 'r') as f:\n        cpus_range_str = f.read()\n        for cpu_range in cpus_range_str.split(','):\n            rangeop = cpu_range.find('-')\n            if rangeop == -1:\n                cpus.append(int(cpu_range))\n            else:\n                start = int(cpu_range[:rangeop])\n                end = int(cpu_range[rangeop+1:])\n                cpus.extend(range(start, end+1))\n    return cpus",
  "def get_online_cpus():\n    return _read_cpu_range('/sys/devices/system/cpu/online')",
  "def get_possible_cpus():\n    return _read_cpu_range('/sys/devices/system/cpu/possible')",
  "def detect_language(candidates, pid):\n    res = lib.bcc_procutils_language(pid)\n    language = ct.cast(res, ct.c_char_p).value.decode()\n    return language if language in candidates else None",
  "def printb(s, file=sys.stdout, nl=1):\n    \"\"\"\n    printb(s)\n\n    print a bytes object to stdout and flush\n    \"\"\"\n    buf = file.buffer if hasattr(file, \"buffer\") else file\n\n    buf.write(s)\n    if nl:\n        buf.write(b\"\\n\")\n    file.flush()",
  "class ArgString(object):\n    \"\"\"\n    ArgString(arg)\n\n    encapsulate a system argument that can be easily coerced to a bytes()\n    object, which is better for comparing to kernel or probe data (which should\n    never be en/decode()'ed).\n    \"\"\"\n    def __init__(self, arg):\n        if sys.version_info[0] >= 3:\n            self.s = arg\n        else:\n            self.s = arg.decode(FILESYSTEMENCODING)\n\n    def __bytes__(self):\n        return self.s.encode(FILESYSTEMENCODING)\n\n    def __str__(self):\n        return self.__bytes__()",
  "def warn_with_traceback(message, category, filename, lineno, file=None, line=None):\n    log = file if hasattr(file, \"write\") else sys.stderr\n    traceback.print_stack(f=sys._getframe(2), file=log)\n    log.write(warnings.formatwarning(message, category, filename, lineno, line))",
  "def _assert_is_bytes(arg):\n    if arg is None:\n        return arg\n    if _strict_bytes:\n        assert type(arg) is bytes, \"not a bytes object: %r\" % arg\n    elif type(arg) is not bytes:\n        warnings.warn(\"not a bytes object: %r\" % arg, DeprecationWarning, 2)\n        return ArgString(arg).__bytes__()\n    return arg",
  "def __init__(self, arg):\n        if sys.version_info[0] >= 3:\n            self.s = arg\n        else:\n            self.s = arg.decode(FILESYSTEMENCODING)",
  "def __bytes__(self):\n        return self.s.encode(FILESYSTEMENCODING)",
  "def __str__(self):\n        return self.__bytes__()",
  "def _parse_syscall(line):\n    parts = line.split()\n    return (int(parts[0]), parts[1].strip())",
  "def syscall_name(syscall_num):\n    \"\"\"Return the syscall name for the particular syscall number.\"\"\"\n    return syscalls.get(syscall_num, b\"[unknown: %d]\" % syscall_num)",
  "class bcc_symbol(ct.Structure):\n    _fields_ = [\n            ('name', ct.c_char_p),\n            ('demangle_name', ct.c_char_p),\n            ('module', ct.POINTER(ct.c_char)),\n            ('offset', ct.c_ulonglong),\n        ]",
  "class bcc_ip_offset_union(ct.Union):\n  _fields_ = [\n          ('offset', ct.c_uint64),\n          ('ip', ct.c_uint64)\n        ]",
  "class bcc_stacktrace_build_id(ct.Structure):\n    _fields_ = [\n            ('status', ct.c_uint32),\n            ('build_id',ct.c_ubyte*20),\n            ('u',bcc_ip_offset_union)\n         ]",
  "class bcc_symbol_option(ct.Structure):\n    _fields_ = [\n            ('use_debug_file', ct.c_int),\n            ('check_debug_file_crc', ct.c_int),\n            ('use_symbol_type', ct.c_uint),\n        ]",
  "class bcc_usdt(ct.Structure):\n    _fields_ = [\n            ('provider', ct.c_char_p),\n            ('name', ct.c_char_p),\n            ('bin_path', ct.c_char_p),\n            ('semaphore', ct.c_ulonglong),\n            ('num_locations', ct.c_int),\n            ('num_arguments', ct.c_int),\n        ]",
  "class bcc_usdt_location(ct.Structure):\n    _fields_ = [\n            ('address', ct.c_ulonglong),\n            ('bin_path', ct.c_char_p),\n        ]",
  "class BCC_USDT_ARGUMENT_FLAGS(object):\n    NONE = 0x0\n    CONSTANT = 0x1\n    DEREF_OFFSET = 0x2\n    DEREF_IDENT = 0x4\n    BASE_REGISTER_NAME = 0x8\n    INDEX_REGISTER_NAME = 0x10\n    SCALE = 0x20",
  "class bcc_usdt_argument(ct.Structure):\n    _fields_ = [\n            ('size', ct.c_int),\n            ('valid', ct.c_int),\n            ('constant', ct.c_int),\n            ('deref_offset', ct.c_int),\n            ('deref_ident', ct.c_char_p),\n            ('base_register_name', ct.c_char_p),\n            ('index_register_name', ct.c_char_p),\n            ('scale', ct.c_int)\n        ]",
  "def _get_num_open_probes():\n    global _num_open_probes\n    return _num_open_probes",
  "class SymbolCache(object):\n    def __init__(self, pid):\n        self.cache = lib.bcc_symcache_new(\n                pid, ct.cast(None, ct.POINTER(bcc_symbol_option)))\n\n    def resolve(self, addr, demangle):\n        \"\"\"\n        Return a tuple of the symbol (function), its offset from the beginning\n        of the function, and the module in which it lies. For example:\n            (\"start_thread\", 0x202, \"/usr/lib/.../libpthread-2.24.so\")\n        If the symbol cannot be found but we know which module it is in,\n        return the module name and the offset from the beginning of the\n        module. If we don't even know the module, return the absolute\n        address as the offset.\n        \"\"\"\n\n        sym = bcc_symbol()\n        if demangle:\n            res = lib.bcc_symcache_resolve(self.cache, addr, ct.byref(sym))\n        else:\n            res = lib.bcc_symcache_resolve_no_demangle(self.cache, addr,\n                                                       ct.byref(sym))\n        if res < 0:\n            if sym.module and sym.offset:\n                return (None, sym.offset,\n                        ct.cast(sym.module, ct.c_char_p).value)\n            return (None, addr, None)\n        if demangle:\n            name_res = sym.demangle_name\n            lib.bcc_symbol_free_demangle_name(ct.byref(sym))\n        else:\n            name_res = sym.name\n        return (name_res, sym.offset, ct.cast(sym.module, ct.c_char_p).value)\n\n    def resolve_name(self, module, name):\n        module = _assert_is_bytes(module)\n        name = _assert_is_bytes(name)\n        addr = ct.c_ulonglong()\n        if lib.bcc_symcache_resolve_name(self.cache, module, name,\n                ct.byref(addr)) < 0:\n            return -1\n        return addr.value",
  "class PerfType:\n    # From perf_type_id in uapi/linux/perf_event.h\n    HARDWARE = 0\n    SOFTWARE = 1",
  "class PerfHWConfig:\n    # From perf_hw_id in uapi/linux/perf_event.h\n    CPU_CYCLES = 0\n    INSTRUCTIONS = 1\n    CACHE_REFERENCES = 2\n    CACHE_MISSES = 3\n    BRANCH_INSTRUCTIONS = 4\n    BRANCH_MISSES = 5\n    BUS_CYCLES = 6\n    STALLED_CYCLES_FRONTEND = 7\n    STALLED_CYCLES_BACKEND = 8\n    REF_CPU_CYCLES = 9",
  "class PerfSWConfig:\n    # From perf_sw_id in uapi/linux/perf_event.h\n    CPU_CLOCK = 0\n    TASK_CLOCK = 1\n    PAGE_FAULTS = 2\n    CONTEXT_SWITCHES = 3\n    CPU_MIGRATIONS = 4\n    PAGE_FAULTS_MIN = 5\n    PAGE_FAULTS_MAJ = 6\n    ALIGNMENT_FAULTS = 7\n    EMULATION_FAULTS = 8\n    DUMMY = 9\n    BPF_OUTPUT = 10",
  "class BPF(object):\n    # From bpf_prog_type in uapi/linux/bpf.h\n    SOCKET_FILTER = 1\n    KPROBE = 2\n    SCHED_CLS = 3\n    SCHED_ACT = 4\n    TRACEPOINT = 5\n    XDP = 6\n    PERF_EVENT = 7\n    CGROUP_SKB = 8\n    CGROUP_SOCK = 9\n    LWT_IN = 10\n    LWT_OUT = 11\n    LWT_XMIT = 12\n    SOCK_OPS = 13\n    SK_SKB = 14\n    CGROUP_DEVICE = 15\n    SK_MSG = 16\n    RAW_TRACEPOINT = 17\n    CGROUP_SOCK_ADDR = 18\n\n    # from xdp_action uapi/linux/bpf.h\n    XDP_ABORTED = 0\n    XDP_DROP = 1\n    XDP_PASS = 2\n    XDP_TX = 3\n    XDP_REDIRECT = 4\n\n    _probe_repl = re.compile(b\"[^a-zA-Z0-9_]\")\n    _sym_caches = {}\n    _bsymcache =  lib.bcc_buildsymcache_new()\n\n    _auto_includes = {\n        \"linux/time.h\": [\"time\"],\n        \"linux/fs.h\": [\"fs\", \"file\"],\n        \"linux/blkdev.h\": [\"bio\", \"request\"],\n        \"linux/slab.h\": [\"alloc\"],\n        \"linux/netdevice.h\": [\"sk_buff\", \"net_device\"]\n    }\n\n    _syscall_prefixes = [\n        b\"sys_\",\n        b\"__x64_sys_\",\n        b\"__x32_compat_sys_\",\n        b\"__ia32_compat_sys_\",\n        b\"__arm64_sys_\",\n    ]\n\n    # BPF timestamps come from the monotonic clock. To be able to filter\n    # and compare them from Python, we need to invoke clock_gettime.\n    # Adapted from http://stackoverflow.com/a/1205762\n    CLOCK_MONOTONIC = 1         # see <linux/time.h>\n\n    class timespec(ct.Structure):\n        _fields_ = [('tv_sec', ct.c_long), ('tv_nsec', ct.c_long)]\n\n    _librt = ct.CDLL('librt.so.1', use_errno=True)\n    _clock_gettime = _librt.clock_gettime\n    _clock_gettime.argtypes = [ct.c_int, ct.POINTER(timespec)]\n\n    @classmethod\n    def monotonic_time(cls):\n        \"\"\"monotonic_time()\n        Returns the system monotonic time from clock_gettime, using the\n        CLOCK_MONOTONIC constant. The time returned is in nanoseconds.\n        \"\"\"\n        t = cls.timespec()\n        if cls._clock_gettime(cls.CLOCK_MONOTONIC, ct.byref(t)) != 0:\n            errno = ct.get_errno()\n            raise OSError(errno, os.strerror(errno))\n        return t.tv_sec * 1e9 + t.tv_nsec\n\n    @classmethod\n    def generate_auto_includes(cls, program_words):\n        \"\"\"\n        Generates #include statements automatically based on a set of\n        recognized types such as sk_buff and bio. The input is all the words\n        that appear in the BPF program, and the output is a (possibly empty)\n        string of #include statements, such as \"#include <linux/fs.h>\".\n        \"\"\"\n        headers = \"\"\n        for header, keywords in cls._auto_includes.items():\n            for keyword in keywords:\n                for word in program_words:\n                    if keyword in word and header not in headers:\n                        headers += \"#include <%s>\\n\" % header\n        return headers\n\n    # defined for compatibility reasons, to be removed\n    Table = Table\n\n    class Function(object):\n        def __init__(self, bpf, name, fd):\n            self.bpf = bpf\n            self.name = name\n            self.fd = fd\n\n    @staticmethod\n    def _find_file(filename):\n        \"\"\" If filename is invalid, search in ./ of argv[0] \"\"\"\n        if filename:\n            if not os.path.isfile(filename):\n                argv0 = ArgString(sys.argv[0])\n                t = b\"/\".join([os.path.abspath(os.path.dirname(argv0.__str__())), filename])\n                if os.path.isfile(t):\n                    filename = t\n                else:\n                    raise Exception(\"Could not find file %s\" % filename)\n        return filename\n\n    @staticmethod\n    def find_exe(bin_path):\n        \"\"\"\n        find_exe(bin_path)\n\n        Traverses the PATH environment variable, looking for the first\n        directory that contains an executable file named bin_path, and\n        returns the full path to that file, or None if no such file\n        can be found. This is meant to replace invocations of the\n        \"which\" shell utility, which doesn't have portable semantics\n        for skipping aliases.\n        \"\"\"\n        # Source: http://stackoverflow.com/a/377028\n        def is_exe(fpath):\n            return os.path.isfile(fpath) and \\\n                os.access(fpath, os.X_OK)\n\n        fpath, fname = os.path.split(bin_path)\n        if fpath:\n            if is_exe(bin_path):\n                return bin_path\n        else:\n            for path in os.environ[\"PATH\"].split(os.pathsep):\n                path = path.strip('\"')\n                exe_file = os.path.join(path, bin_path)\n                if is_exe(exe_file):\n                    return exe_file\n        return None\n\n    def __init__(self, src_file=b\"\", hdr_file=b\"\", text=None, debug=0,\n            cflags=[], usdt_contexts=[]):\n        \"\"\"Create a new BPF module with the given source code.\n\n        Note:\n            All fields are marked as optional, but either `src_file` or `text`\n            must be supplied, and not both.\n\n        Args:\n            src_file (Optional[str]): Path to a source file for the module\n            hdr_file (Optional[str]): Path to a helper header file for the `src_file`\n            text (Optional[str]): Contents of a source file for the module\n            debug (Optional[int]): Flags used for debug prints, can be |'d together\n                                   See \"Debug flags\" for explanation\n        \"\"\"\n\n        src_file = _assert_is_bytes(src_file)\n        hdr_file = _assert_is_bytes(hdr_file)\n        text = _assert_is_bytes(text)\n\n        self.kprobe_fds = {}\n        self.uprobe_fds = {}\n        self.tracepoint_fds = {}\n        self.raw_tracepoint_fds = {}\n        self.perf_buffers = {}\n        self.open_perf_events = {}\n        self.tracefile = None\n        atexit.register(self.cleanup)\n\n        self.debug = debug\n        self.funcs = {}\n        self.tables = {}\n        self.module = None\n        cflags_array = (ct.c_char_p * len(cflags))()\n        for i, s in enumerate(cflags): cflags_array[i] = bytes(ArgString(s))\n        if text:\n            ctx_array = (ct.c_void_p * len(usdt_contexts))()\n            for i, usdt in enumerate(usdt_contexts):\n                ctx_array[i] = ct.c_void_p(usdt.get_context())\n            usdt_text = lib.bcc_usdt_genargs(ctx_array, len(usdt_contexts))\n            if usdt_text is None:\n                raise Exception(\"can't generate USDT probe arguments; \" +\n                                \"possible cause is missing pid when a \" +\n                                \"probe in a shared object has multiple \" +\n                                \"locations\")\n            text = usdt_text + text\n\n        if text:\n            self.module = lib.bpf_module_create_c_from_string(text,\n                    self.debug, cflags_array, len(cflags_array))\n            if not self.module:\n                raise Exception(\"Failed to compile BPF text\")\n        else:\n            src_file = BPF._find_file(src_file)\n            hdr_file = BPF._find_file(hdr_file)\n            if src_file.endswith(b\".b\"):\n                self.module = lib.bpf_module_create_b(src_file, hdr_file,\n                        self.debug)\n            else:\n                self.module = lib.bpf_module_create_c(src_file, self.debug,\n                        cflags_array, len(cflags_array))\n            if not self.module:\n                raise Exception(\"Failed to compile BPF module %s\" % src_file)\n\n        for usdt_context in usdt_contexts:\n            usdt_context.attach_uprobes(self)\n\n        # If any \"kprobe__\" or \"tracepoint__\" or \"raw_tracepoint__\"\n        # prefixed functions were defined,\n        # they will be loaded and attached here.\n        self._trace_autoload()\n\n    def load_funcs(self, prog_type=KPROBE):\n        \"\"\"load_funcs(prog_type=KPROBE)\n\n        Load all functions in this BPF module with the given type.\n        Returns a list of the function handles.\"\"\"\n\n        fns = []\n        for i in range(0, lib.bpf_num_functions(self.module)):\n            func_name = lib.bpf_function_name(self.module, i)\n            fns.append(self.load_func(func_name, prog_type))\n\n        return fns\n\n    def load_func(self, func_name, prog_type):\n        func_name = _assert_is_bytes(func_name)\n        if func_name in self.funcs:\n            return self.funcs[func_name]\n        if not lib.bpf_function_start(self.module, func_name):\n            raise Exception(\"Unknown program %s\" % func_name)\n        log_level = 0\n        if (self.debug & DEBUG_BPF_REGISTER_STATE):\n            log_level = 2\n        elif (self.debug & DEBUG_BPF):\n            log_level = 1\n        fd = lib.bpf_prog_load(prog_type, func_name,\n                lib.bpf_function_start(self.module, func_name),\n                lib.bpf_function_size(self.module, func_name),\n                lib.bpf_module_license(self.module),\n                lib.bpf_module_kern_version(self.module),\n                log_level, None, 0);\n\n        if fd < 0:\n            atexit.register(self.donothing)\n            if ct.get_errno() == errno.EPERM:\n                raise Exception(\"Need super-user privileges to run\")\n\n            errstr = os.strerror(ct.get_errno())\n            raise Exception(\"Failed to load BPF program %s: %s\" %\n                            (func_name, errstr))\n\n        fn = BPF.Function(self, func_name, fd)\n        self.funcs[func_name] = fn\n\n        return fn\n\n    def dump_func(self, func_name):\n        \"\"\"\n        Return the eBPF bytecodes for the specified function as a string\n        \"\"\"\n        func_name = _assert_is_bytes(func_name)\n        if not lib.bpf_function_start(self.module, func_name):\n            raise Exception(\"Unknown program %s\" % func_name)\n\n        start, = lib.bpf_function_start(self.module, func_name),\n        size, = lib.bpf_function_size(self.module, func_name),\n        return ct.string_at(start, size)\n\n    str2ctype = {\n        u\"_Bool\": ct.c_bool,\n        u\"char\": ct.c_char,\n        u\"wchar_t\": ct.c_wchar,\n        u\"unsigned char\": ct.c_ubyte,\n        u\"short\": ct.c_short,\n        u\"unsigned short\": ct.c_ushort,\n        u\"int\": ct.c_int,\n        u\"unsigned int\": ct.c_uint,\n        u\"long\": ct.c_long,\n        u\"unsigned long\": ct.c_ulong,\n        u\"long long\": ct.c_longlong,\n        u\"unsigned long long\": ct.c_ulonglong,\n        u\"float\": ct.c_float,\n        u\"double\": ct.c_double,\n        u\"long double\": ct.c_longdouble,\n        u\"__int128\": ct.c_int64 * 2,\n        u\"unsigned __int128\": ct.c_uint64 * 2,\n    }\n    @staticmethod\n    def _decode_table_type(desc):\n        if isinstance(desc, basestring):\n            return BPF.str2ctype[desc]\n        anon = []\n        fields = []\n        for t in desc[1]:\n            if len(t) == 2:\n                fields.append((t[0], BPF._decode_table_type(t[1])))\n            elif len(t) == 3:\n                if isinstance(t[2], list):\n                    fields.append((t[0], BPF._decode_table_type(t[1]) * t[2][0]))\n                elif isinstance(t[2], int):\n                    fields.append((t[0], BPF._decode_table_type(t[1]), t[2]))\n                elif isinstance(t[2], basestring) and (\n                        t[2] == u\"union\" or t[2] == u\"struct\" or\n                        t[2] == u\"struct_packed\"):\n                    name = t[0]\n                    if name == \"\":\n                        name = \"__anon%d\" % len(anon)\n                        anon.append(name)\n                    fields.append((name, BPF._decode_table_type(t)))\n                else:\n                    raise Exception(\"Failed to decode type %s\" % str(t))\n            else:\n                raise Exception(\"Failed to decode type %s\" % str(t))\n        base = ct.Structure\n        is_packed = False\n        if len(desc) > 2:\n            if desc[2] == u\"union\":\n                base = ct.Union\n            elif desc[2] == u\"struct\":\n                base = ct.Structure\n            elif desc[2] == u\"struct_packed\":\n                base = ct.Structure\n                is_packed = True\n        if is_packed:\n            cls = type(str(desc[0]), (base,), dict(_anonymous_=anon, _pack_=1,\n                _fields_=fields))\n        else:\n            cls = type(str(desc[0]), (base,), dict(_anonymous_=anon,\n                _fields_=fields))\n        return cls\n\n    def get_table(self, name, keytype=None, leaftype=None, reducer=None):\n        name = _assert_is_bytes(name)\n        map_id = lib.bpf_table_id(self.module, name)\n        map_fd = lib.bpf_table_fd(self.module, name)\n        if map_fd < 0:\n            raise KeyError\n        if not keytype:\n            key_desc = lib.bpf_table_key_desc(self.module, name).decode(\"utf-8\")\n            if not key_desc:\n                raise Exception(\"Failed to load BPF Table %s key desc\" % name)\n            keytype = BPF._decode_table_type(json.loads(key_desc))\n        if not leaftype:\n            leaf_desc = lib.bpf_table_leaf_desc(self.module, name).decode(\"utf-8\")\n            if not leaf_desc:\n                raise Exception(\"Failed to load BPF Table %s leaf desc\" % name)\n            leaftype = BPF._decode_table_type(json.loads(leaf_desc))\n        return Table(self, map_id, map_fd, keytype, leaftype, reducer=reducer)\n\n    def __getitem__(self, key):\n        if key not in self.tables:\n            self.tables[key] = self.get_table(key)\n        return self.tables[key]\n\n    def __setitem__(self, key, leaf):\n        self.tables[key] = leaf\n\n    def __len__(self):\n        return len(self.tables)\n\n    def __delitem__(self, key):\n        del self.tables[key]\n\n    def __iter__(self):\n        return self.tables.__iter__()\n\n    @staticmethod\n    def attach_raw_socket(fn, dev):\n        dev = _assert_is_bytes(dev)\n        if not isinstance(fn, BPF.Function):\n            raise Exception(\"arg 1 must be of type BPF.Function\")\n        sock = lib.bpf_open_raw_sock(dev)\n        if sock < 0:\n            errstr = os.strerror(ct.get_errno())\n            raise Exception(\"Failed to open raw device %s: %s\" % (dev, errstr))\n        res = lib.bpf_attach_socket(sock, fn.fd)\n        if res < 0:\n            errstr = os.strerror(ct.get_errno())\n            raise Exception(\"Failed to attach BPF to device %s: %s\"\n                    % (dev, errstr))\n        fn.sock = sock\n\n    @staticmethod\n    def get_kprobe_functions(event_re):\n        with open(\"%s/../kprobes/blacklist\" % TRACEFS, \"rb\") as blacklist_f:\n            blacklist = set([line.rstrip().split()[1] for line in blacklist_f])\n        fns = []\n\n        in_init_section = 0\n        in_irq_section = 0\n        with open(\"/proc/kallsyms\", \"rb\") as avail_file:\n            for line in avail_file:\n                (t, fn) = line.rstrip().split()[1:3]\n                # Skip all functions defined between __init_begin and\n                # __init_end\n                if in_init_section == 0:\n                    if fn == b'__init_begin':\n                        in_init_section = 1\n                        continue\n                elif in_init_section == 1:\n                    if fn == b'__init_end':\n                        in_init_section = 2\n                    continue\n                # Skip all functions defined between __irqentry_text_start and\n                # __irqentry_text_end\n                if in_irq_section == 0:\n                    if fn == b'__irqentry_text_start':\n                        in_irq_section = 1\n                        continue\n                elif in_irq_section == 1:\n                    if fn == b'__irqentry_text_end':\n                        in_irq_section = 2\n                    continue\n                # All functions defined as NOKPROBE_SYMBOL() start with the\n                # prefix _kbl_addr_*, blacklisting them by looking at the name\n                # allows to catch also those symbols that are defined in kernel\n                # modules.\n                if fn.startswith(b'_kbl_addr_'):\n                    continue\n                # Explicitly blacklist perf-related functions, they are all\n                # non-attachable.\n                elif fn.startswith(b'__perf') or fn.startswith(b'perf_'):\n                    continue\n                if (t.lower() in [b't', b'w']) and re.match(event_re, fn) \\\n                    and fn not in blacklist:\n                    fns.append(fn)\n        return set(fns)     # Some functions may appear more than once\n\n    def _check_probe_quota(self, num_new_probes):\n        global _num_open_probes\n        if _num_open_probes + num_new_probes > _probe_limit:\n            raise Exception(\"Number of open probes would exceed global quota\")\n\n    def _add_kprobe_fd(self, name, fd):\n        global _num_open_probes\n        self.kprobe_fds[name] = fd\n        _num_open_probes += 1\n\n    def _del_kprobe_fd(self, name):\n        global _num_open_probes\n        del self.kprobe_fds[name]\n        _num_open_probes -= 1\n \n    def _add_uprobe_fd(self, name, fd):\n        global _num_open_probes\n        self.uprobe_fds[name] = fd\n        _num_open_probes += 1\n\n    def _del_uprobe_fd(self, name):\n        global _num_open_probes\n        del self.uprobe_fds[name]\n        _num_open_probes -= 1\n\n    # Find current system's syscall prefix by testing on the BPF syscall.\n    # If no valid value found, will return the first possible value which\n    # would probably lead to error in later API calls.\n    def get_syscall_prefix(self):\n        for prefix in self._syscall_prefixes:\n            if self.ksymname(b\"%sbpf\" % prefix) != -1:\n                return prefix\n        return self._syscall_prefixes[0]\n\n    # Given a syscall's name, return the full Kernel function name with current\n    # system's syscall prefix. For example, given \"clone\" the helper would\n    # return \"sys_clone\" or \"__x64_sys_clone\".\n    def get_syscall_fnname(self, name):\n        name = _assert_is_bytes(name)\n        return self.get_syscall_prefix() + name\n\n    # Given a Kernel function name that represents a syscall but already has a\n    # prefix included, transform it to current system's prefix. For example,\n    # if \"sys_clone\" provided, the helper may translate it to \"__x64_sys_clone\".\n    def fix_syscall_fnname(self, name):\n        name = _assert_is_bytes(name)\n        for prefix in self._syscall_prefixes:\n            if name.startswith(prefix):\n                return self.get_syscall_fnname(name[len(prefix):])\n        return name\n       \n    def attach_kprobe(self, event=b\"\", event_off=0, fn_name=b\"\", event_re=b\"\"):\n        event = _assert_is_bytes(event)\n        fn_name = _assert_is_bytes(fn_name)\n        event_re = _assert_is_bytes(event_re)\n\n        # allow the caller to glob multiple functions together\n        if event_re:\n            matches = BPF.get_kprobe_functions(event_re)\n            self._check_probe_quota(len(matches))\n            for line in matches:\n                try:\n                    self.attach_kprobe(event=line, fn_name=fn_name)\n                except:\n                    pass\n            return\n\n        self._check_probe_quota(1)\n        fn = self.load_func(fn_name, BPF.KPROBE)\n        ev_name = b\"p_\" + event.replace(b\"+\", b\"_\").replace(b\".\", b\"_\")\n        fd = lib.bpf_attach_kprobe(fn.fd, 0, ev_name, event, event_off)\n        if fd < 0:\n            raise Exception(\"Failed to attach BPF program %s to kprobe %s\" %\n                            (fn_name, event))\n        self._add_kprobe_fd(ev_name, fd)\n        return self\n\n    def attach_kretprobe(self, event=b\"\", fn_name=b\"\", event_re=b\"\"):\n        event = _assert_is_bytes(event)\n        fn_name = _assert_is_bytes(fn_name)\n        event_re = _assert_is_bytes(event_re)\n\n        # allow the caller to glob multiple functions together\n        if event_re:\n            for line in BPF.get_kprobe_functions(event_re):\n                try:\n                    self.attach_kretprobe(event=line, fn_name=fn_name)\n                except:\n                    pass\n            return\n\n        self._check_probe_quota(1)\n        fn = self.load_func(fn_name, BPF.KPROBE)\n        ev_name = b\"r_\" + event.replace(b\"+\", b\"_\").replace(b\".\", b\"_\")\n        fd = lib.bpf_attach_kprobe(fn.fd, 1, ev_name, event, 0)\n        if fd < 0:\n            raise Exception(\"Failed to attach BPF program %s to kretprobe %s\" %\n                            (fn_name, event))\n        self._add_kprobe_fd(ev_name, fd)\n        return self\n\n    def detach_kprobe_event(self, ev_name):\n        if ev_name not in self.kprobe_fds:\n            raise Exception(\"Kprobe %s is not attached\" % ev_name)\n        res = lib.bpf_close_perf_event_fd(self.kprobe_fds[ev_name])\n        if res < 0:\n            raise Exception(\"Failed to close kprobe FD\")\n        res = lib.bpf_detach_kprobe(ev_name)\n        if res < 0:\n            raise Exception(\"Failed to detach BPF from kprobe\")\n        self._del_kprobe_fd(ev_name)\n\n    def detach_kprobe(self, event):\n        event = _assert_is_bytes(event)\n        ev_name = b\"p_\" + event.replace(b\"+\", b\"_\").replace(b\".\", b\"_\")\n        self.detach_kprobe_event(ev_name)\n\n    def detach_kretprobe(self, event):\n        event = _assert_is_bytes(event)\n        ev_name = b\"r_\" + event.replace(b\"+\", b\"_\").replace(b\".\", b\"_\")\n        self.detach_kprobe_event(ev_name)\n\n    @staticmethod\n    def attach_xdp(dev, fn, flags=0):\n        '''\n            This function attaches a BPF function to a device on the device\n            driver level (XDP)\n        '''\n        dev = _assert_is_bytes(dev)\n        if not isinstance(fn, BPF.Function):\n            raise Exception(\"arg 1 must be of type BPF.Function\")\n        res = lib.bpf_attach_xdp(dev, fn.fd, flags)\n        if res < 0:\n            err_no = ct.get_errno()\n            if err_no == errno.EBADMSG:\n                raise Exception(\"Internal error while attaching BPF to device,\"+\n                    \" try increasing the debug level!\")\n            else:\n                errstr = os.strerror(err_no)\n                raise Exception(\"Failed to attach BPF to device %s: %s\"\n                            % (dev, errstr))\n\n    @staticmethod\n    def remove_xdp(dev, flags=0):\n        '''\n            This function removes any BPF function from a device on the\n            device driver level (XDP)\n        '''\n        dev = _assert_is_bytes(dev)\n        res = lib.bpf_attach_xdp(dev, -1, flags)\n        if res < 0:\n            errstr = os.strerror(ct.get_errno())\n            raise Exception(\"Failed to detach BPF from device %s: %s\"\n                            % (dev, errstr))\n\n\n\n    @classmethod\n    def _check_path_symbol(cls, module, symname, addr, pid):\n        module = _assert_is_bytes(module)\n        symname = _assert_is_bytes(symname)\n        sym = bcc_symbol()\n        c_pid = 0 if pid == -1 else pid\n        if lib.bcc_resolve_symname(\n            module, symname,\n            addr or 0x0, c_pid,\n            ct.cast(None, ct.POINTER(bcc_symbol_option)),\n            ct.byref(sym),\n        ) < 0:\n            raise Exception(\"could not determine address of symbol %s\" % symname)\n        module_path = ct.cast(sym.module, ct.c_char_p).value\n        lib.bcc_procutils_free(sym.module)\n        return module_path, sym.offset\n\n    @staticmethod\n    def find_library(libname):\n        libname = _assert_is_bytes(libname)\n        res = lib.bcc_procutils_which_so(libname, 0)\n        if not res:\n            return None\n        libpath = ct.cast(res, ct.c_char_p).value\n        lib.bcc_procutils_free(res)\n        return libpath\n\n    @staticmethod\n    def get_tracepoints(tp_re):\n        results = []\n        events_dir = os.path.join(TRACEFS, \"events\")\n        for category in os.listdir(events_dir):\n            cat_dir = os.path.join(events_dir, category)\n            if not os.path.isdir(cat_dir):\n                continue\n            for event in os.listdir(cat_dir):\n                evt_dir = os.path.join(cat_dir, event)\n                if os.path.isdir(evt_dir):\n                    tp = (\"%s:%s\" % (category, event))\n                    if re.match(tp_re, tp):\n                        results.append(tp)\n        return results\n\n    @staticmethod\n    def tracepoint_exists(category, event):\n        evt_dir = os.path.join(TRACEFS, \"events\", category, event)\n        return os.path.isdir(evt_dir)\n\n    def attach_tracepoint(self, tp=b\"\", tp_re=b\"\", fn_name=b\"\"):\n        \"\"\"attach_tracepoint(tp=\"\", tp_re=\"\", fn_name=\"\")\n\n        Run the bpf function denoted by fn_name every time the kernel tracepoint\n        specified by 'tp' is hit. The optional parameters pid, cpu, and group_fd\n        can be used to filter the probe. The tracepoint specification is simply\n        the tracepoint category and the tracepoint name, separated by a colon.\n        For example: sched:sched_switch, syscalls:sys_enter_bind, etc.\n\n        Instead of a tracepoint name, a regular expression can be provided in\n        tp_re. The program will then attach to tracepoints that match the\n        provided regular expression.\n\n        To obtain a list of kernel tracepoints, use the tplist tool or cat the\n        file /sys/kernel/debug/tracing/available_events.\n\n        Examples:\n            BPF(text).attach_tracepoint(tp=\"sched:sched_switch\", fn_name=\"on_switch\")\n            BPF(text).attach_tracepoint(tp_re=\"sched:.*\", fn_name=\"on_switch\")\n        \"\"\"\n\n        tp = _assert_is_bytes(tp)\n        tp_re = _assert_is_bytes(tp_re)\n        fn_name = _assert_is_bytes(fn_name)\n        if tp_re:\n            for tp in BPF.get_tracepoints(tp_re):\n                self.attach_tracepoint(tp=tp, fn_name=fn_name)\n            return\n\n        fn = self.load_func(fn_name, BPF.TRACEPOINT)\n        (tp_category, tp_name) = tp.split(b':')\n        fd = lib.bpf_attach_tracepoint(fn.fd, tp_category, tp_name)\n        if fd < 0:\n            raise Exception(\"Failed to attach BPF program %s to tracepoint %s\" %\n                            (fn_name, tp))\n        self.tracepoint_fds[tp] = fd\n        return self\n\n    def attach_raw_tracepoint(self, tp=b\"\", fn_name=b\"\"):\n        \"\"\"attach_raw_tracepoint(self, tp=b\"\", fn_name=b\"\")\n\n        Run the bpf function denoted by fn_name every time the kernel tracepoint\n        specified by 'tp' is hit. The bpf function should be loaded as a\n        RAW_TRACEPOINT type. The fn_name is the kernel tracepoint name,\n        e.g., sched_switch, sys_enter_bind, etc.\n\n        Examples:\n            BPF(text).attach_raw_tracepoint(tp=\"sched_switch\", fn_name=\"on_switch\")\n        \"\"\"\n\n        tp = _assert_is_bytes(tp)\n        if tp in self.raw_tracepoint_fds:\n            raise Exception(\"Raw tracepoint %s has been attached\" % tp)\n\n        fn_name = _assert_is_bytes(fn_name)\n        fn = self.load_func(fn_name, BPF.RAW_TRACEPOINT)\n        fd = lib.bpf_attach_raw_tracepoint(fn.fd, tp)\n        if fd < 0:\n            raise Exception(\"Failed to attach BPF to raw tracepoint\")\n        self.raw_tracepoint_fds[tp] = fd;\n        return self\n\n    def detach_raw_tracepoint(self, tp=b\"\"):\n        \"\"\"detach_raw_tracepoint(tp=\"\")\n\n        Stop running the bpf function that is attached to the kernel tracepoint\n        specified by 'tp'.\n\n        Example: bpf.detach_raw_tracepoint(\"sched_switch\")\n        \"\"\"\n\n        tp = _assert_is_bytes(tp)\n        if tp not in self.raw_tracepoint_fds:\n            raise Exception(\"Raw tracepoint %s is not attached\" % tp)\n        os.close(self.raw_tracepoint_fds[tp])\n        del self.raw_tracepoint_fds[tp]\n\n    @staticmethod\n    def support_raw_tracepoint():\n        # kernel symbol \"bpf_find_raw_tracepoint\" indicates raw_tracepint support\n        if BPF.ksymname(\"bpf_find_raw_tracepoint\") != -1:\n            return True\n        return False\n\n    def detach_tracepoint(self, tp=b\"\"):\n        \"\"\"detach_tracepoint(tp=\"\")\n\n        Stop running a bpf function that is attached to the kernel tracepoint\n        specified by 'tp'.\n\n        Example: bpf.detach_tracepoint(\"sched:sched_switch\")\n        \"\"\"\n\n        tp = _assert_is_bytes(tp)\n        if tp not in self.tracepoint_fds:\n            raise Exception(\"Tracepoint %s is not attached\" % tp)\n        res = lib.bpf_close_perf_event_fd(self.tracepoint_fds[tp])\n        if res < 0:\n            raise Exception(\"Failed to detach BPF from tracepoint\")\n        (tp_category, tp_name) = tp.split(b':')\n        res = lib.bpf_detach_tracepoint(tp_category, tp_name)\n        if res < 0:\n            raise Exception(\"Failed to detach BPF from tracepoint\")\n        del self.tracepoint_fds[tp]\n\n    def _attach_perf_event(self, progfd, ev_type, ev_config,\n            sample_period, sample_freq, pid, cpu, group_fd):\n        res = lib.bpf_attach_perf_event(progfd, ev_type, ev_config,\n                sample_period, sample_freq, pid, cpu, group_fd)\n        if res < 0:\n            raise Exception(\"Failed to attach BPF to perf event\")\n        return res\n\n    def attach_perf_event(self, ev_type=-1, ev_config=-1, fn_name=b\"\",\n            sample_period=0, sample_freq=0, pid=-1, cpu=-1, group_fd=-1):\n        fn_name = _assert_is_bytes(fn_name)\n        fn = self.load_func(fn_name, BPF.PERF_EVENT)\n        res = {}\n        if cpu >= 0:\n            res[cpu] = self._attach_perf_event(fn.fd, ev_type, ev_config,\n                    sample_period, sample_freq, pid, cpu, group_fd)\n        else:\n            for i in get_online_cpus():\n                res[i] = self._attach_perf_event(fn.fd, ev_type, ev_config,\n                        sample_period, sample_freq, pid, i, group_fd)\n        self.open_perf_events[(ev_type, ev_config)] = res\n\n    def detach_perf_event(self, ev_type=-1, ev_config=-1):\n        try:\n            fds = self.open_perf_events[(ev_type, ev_config)]\n        except KeyError:\n            raise Exception(\"Perf event type {} config {} not attached\".format(\n                ev_type, ev_config))\n\n        res = 0\n        for fd in fds.values():\n            res = lib.bpf_close_perf_event_fd(fd) or res\n        if res != 0:\n            raise Exception(\"Failed to detach BPF from perf event\")\n        del self.open_perf_events[(ev_type, ev_config)]\n\n    @staticmethod\n    def get_user_functions(name, sym_re):\n        return set([name for (name, _) in\n                    BPF.get_user_functions_and_addresses(name, sym_re)])\n\n    @staticmethod\n    def get_user_addresses(name, sym_re):\n        \"\"\"\n        We are returning addresses here instead of symbol names because it\n        turns out that the same name may appear multiple times with different\n        addresses, and the same address may appear multiple times with the same\n        name. We can't attach a uprobe to the same address more than once, so\n        it makes sense to return the unique set of addresses that are mapped to\n        a symbol that matches the provided regular expression.\n        \"\"\"\n        return set([address for (_, address) in\n                    BPF.get_user_functions_and_addresses(name, sym_re)])\n\n    @staticmethod\n    def get_user_functions_and_addresses(name, sym_re):\n        name = _assert_is_bytes(name)\n        sym_re = _assert_is_bytes(sym_re)\n        addresses = []\n        def sym_cb(sym_name, addr):\n            dname = sym_name\n            if re.match(sym_re, dname):\n                addresses.append((dname, addr))\n            return 0\n\n        res = lib.bcc_foreach_function_symbol(name, _SYM_CB_TYPE(sym_cb))\n        if res < 0:\n            raise Exception(\"Error %d enumerating symbols in %s\" % (res, name))\n        return addresses\n\n    def _get_uprobe_evname(self, prefix, path, addr, pid):\n        if pid == -1:\n            return b\"%s_%s_0x%x\" % (prefix, self._probe_repl.sub(b\"_\", path), addr)\n        else:\n            # if pid is valid, put pid in the name, so different pid\n            # can have different event names\n            return b\"%s_%s_0x%x_%d\" % (prefix, self._probe_repl.sub(b\"_\", path), addr, pid)\n\n    def attach_uprobe(self, name=b\"\", sym=b\"\", sym_re=b\"\", addr=None,\n            fn_name=b\"\", pid=-1):\n        \"\"\"attach_uprobe(name=\"\", sym=\"\", sym_re=\"\", addr=None, fn_name=\"\"\n                         pid=-1)\n\n        Run the bpf function denoted by fn_name every time the symbol sym in\n        the library or binary 'name' is encountered. The real address addr may\n        be supplied in place of sym. Optional parameters pid, cpu, and group_fd\n        can be used to filter the probe.\n\n        Instead of a symbol name, a regular expression can be provided in\n        sym_re. The uprobe will then attach to symbols that match the provided\n        regular expression.\n\n        Libraries can be given in the name argument without the lib prefix, or\n        with the full path (/usr/lib/...). Binaries can be given only with the\n        full path (/bin/sh). If a PID is given, the uprobe will attach to the\n        version of the library used by the process.\n\n        Example: BPF(text).attach_uprobe(\"c\", \"malloc\")\n                 BPF(text).attach_uprobe(\"/usr/bin/python\", \"main\")\n        \"\"\"\n\n        name = _assert_is_bytes(name)\n        sym = _assert_is_bytes(sym)\n        sym_re = _assert_is_bytes(sym_re)\n        fn_name = _assert_is_bytes(fn_name)\n\n        if sym_re:\n            addresses = BPF.get_user_addresses(name, sym_re)\n            self._check_probe_quota(len(addresses))\n            for sym_addr in addresses:\n                self.attach_uprobe(name=name, addr=sym_addr,\n                                   fn_name=fn_name, pid=pid)\n            return\n\n        (path, addr) = BPF._check_path_symbol(name, sym, addr, pid)\n\n        self._check_probe_quota(1)\n        fn = self.load_func(fn_name, BPF.KPROBE)\n        ev_name = self._get_uprobe_evname(b\"p\", path, addr, pid)\n        fd = lib.bpf_attach_uprobe(fn.fd, 0, ev_name, path, addr, pid)\n        if fd < 0:\n            raise Exception(\"Failed to attach BPF to uprobe\")\n        self._add_uprobe_fd(ev_name, fd)\n        return self\n\n    def attach_uretprobe(self, name=b\"\", sym=b\"\", sym_re=b\"\", addr=None,\n            fn_name=b\"\", pid=-1):\n        \"\"\"attach_uretprobe(name=\"\", sym=\"\", sym_re=\"\", addr=None, fn_name=\"\"\n                            pid=-1)\n\n        Run the bpf function denoted by fn_name every time the symbol sym in\n        the library or binary 'name' finishes execution. See attach_uprobe for\n        meaning of additional parameters.\n        \"\"\"\n\n        name = _assert_is_bytes(name)\n        sym = _assert_is_bytes(sym)\n        sym_re = _assert_is_bytes(sym_re)\n        fn_name = _assert_is_bytes(fn_name)\n\n        if sym_re:\n            for sym_addr in BPF.get_user_addresses(name, sym_re):\n                self.attach_uretprobe(name=name, addr=sym_addr,\n                                      fn_name=fn_name, pid=pid)\n            return\n\n        (path, addr) = BPF._check_path_symbol(name, sym, addr, pid)\n\n        self._check_probe_quota(1)\n        fn = self.load_func(fn_name, BPF.KPROBE)\n        ev_name = self._get_uprobe_evname(b\"r\", path, addr, pid)\n        fd = lib.bpf_attach_uprobe(fn.fd, 1, ev_name, path, addr, pid)\n        if fd < 0:\n            raise Exception(\"Failed to attach BPF to uretprobe\")\n        self._add_uprobe_fd(ev_name, fd)\n        return self\n\n    def detach_uprobe_event(self, ev_name):\n        if ev_name not in self.uprobe_fds:\n            raise Exception(\"Uprobe %s is not attached\" % ev_name)\n        res = lib.bpf_close_perf_event_fd(self.uprobe_fds[ev_name])\n        if res < 0:\n            raise Exception(\"Failed to detach BPF from uprobe\")\n        res = lib.bpf_detach_uprobe(ev_name)\n        if res < 0:\n            raise Exception(\"Failed to detach BPF from uprobe\")\n        self._del_uprobe_fd(ev_name)\n\n    def detach_uprobe(self, name=b\"\", sym=b\"\", addr=None, pid=-1):\n        \"\"\"detach_uprobe(name=\"\", sym=\"\", addr=None, pid=-1)\n\n        Stop running a bpf function that is attached to symbol 'sym' in library\n        or binary 'name'.\n        \"\"\"\n\n        name = _assert_is_bytes(name)\n        sym = _assert_is_bytes(sym)\n        (path, addr) = BPF._check_path_symbol(name, sym, addr, pid)\n        ev_name = self._get_uprobe_evname(b\"p\", path, addr, pid)\n        self.detach_uprobe_event(ev_name)\n\n    def detach_uretprobe(self, name=b\"\", sym=b\"\", addr=None, pid=-1):\n        \"\"\"detach_uretprobe(name=\"\", sym=\"\", addr=None, pid=-1)\n\n        Stop running a bpf function that is attached to symbol 'sym' in library\n        or binary 'name'.\n        \"\"\"\n\n        name = _assert_is_bytes(name)\n        sym = _assert_is_bytes(sym)\n\n        (path, addr) = BPF._check_path_symbol(name, sym, addr, pid)\n        ev_name = self._get_uprobe_evname(b\"r\", path, addr, pid)\n        self.detach_uprobe_event(ev_name)\n\n    def _trace_autoload(self):\n        for i in range(0, lib.bpf_num_functions(self.module)):\n            func_name = lib.bpf_function_name(self.module, i)\n            if func_name.startswith(b\"kprobe__\"):\n                fn = self.load_func(func_name, BPF.KPROBE)\n                self.attach_kprobe(\n                    event=self.fix_syscall_fnname(func_name[8:]),\n                    fn_name=fn.name)\n            elif func_name.startswith(b\"kretprobe__\"):\n                fn = self.load_func(func_name, BPF.KPROBE)\n                self.attach_kretprobe(\n                    event=self.fix_syscall_fnname(func_name[11:]),\n                    fn_name=fn.name)\n            elif func_name.startswith(b\"tracepoint__\"):\n                fn = self.load_func(func_name, BPF.TRACEPOINT)\n                tp = fn.name[len(b\"tracepoint__\"):].replace(b\"__\", b\":\")\n                self.attach_tracepoint(tp=tp, fn_name=fn.name)\n            elif func_name.startswith(b\"raw_tracepoint__\"):\n                fn = self.load_func(func_name, BPF.RAW_TRACEPOINT)\n                tp = fn.name[len(b\"raw_tracepoint__\"):]\n                self.attach_raw_tracepoint(tp=tp, fn_name=fn.name)\n\n    def trace_open(self, nonblocking=False):\n        \"\"\"trace_open(nonblocking=False)\n\n        Open the trace_pipe if not already open\n        \"\"\"\n        if not self.tracefile:\n            self.tracefile = open(\"%s/trace_pipe\" % TRACEFS, \"rb\")\n            if nonblocking:\n                fd = self.tracefile.fileno()\n                fl = fcntl.fcntl(fd, fcntl.F_GETFL)\n                fcntl.fcntl(fd, fcntl.F_SETFL, fl | os.O_NONBLOCK)\n        return self.tracefile\n\n    def trace_fields(self, nonblocking=False):\n        \"\"\"trace_fields(nonblocking=False)\n\n        Read from the kernel debug trace pipe and return a tuple of the\n        fields (task, pid, cpu, flags, timestamp, msg) or None if no\n        line was read (nonblocking=True)\n        \"\"\"\n        while True:\n            line = self.trace_readline(nonblocking)\n            if not line and nonblocking: return (None,) * 6\n            # don't print messages related to lost events\n            if line.startswith(b\"CPU:\"): continue\n            task = line[:16].lstrip()\n            line = line[17:]\n            ts_end = line.find(b\":\")\n            pid, cpu, flags, ts = line[:ts_end].split()\n            cpu = cpu[1:-1]\n            # line[ts_end:] will have \": [sym_or_addr]: msgs\"\n            # For trace_pipe debug output, the addr typically\n            # is invalid (e.g., 0x1). For kernel 4.12 or earlier,\n            # if address is not able to match a kernel symbol,\n            # nothing will be printed out. For kernel 4.13 and later,\n            # however, the illegal address will be printed out.\n            # Hence, both cases are handled here.\n            line = line[ts_end + 1:]\n            sym_end = line.find(b\":\")\n            msg = line[sym_end + 2:]\n            return (task, int(pid), int(cpu), flags, float(ts), msg)\n\n    def trace_readline(self, nonblocking=False):\n        \"\"\"trace_readline(nonblocking=False)\n\n        Read from the kernel debug trace pipe and return one line\n        If nonblocking is False, this will block until ctrl-C is pressed.\n        \"\"\"\n\n        trace = self.trace_open(nonblocking)\n\n        line = None\n        try:\n            line = trace.readline(1024).rstrip()\n        except IOError:\n            pass\n        return line\n\n    def trace_print(self, fmt=None):\n        \"\"\"trace_print(self, fmt=None)\n\n        Read from the kernel debug trace pipe and print on stdout.\n        If fmt is specified, apply as a format string to the output. See\n        trace_fields for the members of the tuple\n        example: trace_print(fmt=\"pid {1}, msg = {5}\")\n        \"\"\"\n\n        while True:\n            if fmt:\n                fields = self.trace_fields(nonblocking=False)\n                if not fields: continue\n                line = fmt.format(*fields)\n            else:\n                line = self.trace_readline(nonblocking=False)\n            print(line)\n            sys.stdout.flush()\n\n    @staticmethod\n    def _sym_cache(pid):\n        \"\"\"_sym_cache(pid)\n\n        Returns a symbol cache for the specified PID.\n        The kernel symbol cache is accessed by providing any PID less than zero.\n        \"\"\"\n        if pid < 0 and pid != -1:\n            pid = -1\n        if not pid in BPF._sym_caches:\n            BPF._sym_caches[pid] = SymbolCache(pid)\n        return BPF._sym_caches[pid]\n\n    @staticmethod\n    def sym(addr, pid, show_module=False, show_offset=False, demangle=True):\n        \"\"\"sym(addr, pid, show_module=False, show_offset=False)\n\n        Translate a memory address into a function name for a pid, which is\n        returned. When show_module is True, the module name is also included.\n        When show_offset is True, the instruction offset as a hexadecimal\n        number is also included in the string.\n\n        A pid of less than zero will access the kernel symbol cache.\n\n        Example output when both show_module and show_offset are True:\n            \"start_thread+0x202 [libpthread-2.24.so]\"\n\n        Example output when both show_module and show_offset are False:\n            \"start_thread\"\n        \"\"\"\n\n        #addr is of type stacktrace_build_id\n        #so invoke the bsym address resolver\n        typeofaddr = str(type(addr))\n        if typeofaddr.find('bpf_stack_build_id') != -1:\n          sym = bcc_symbol()\n          b = bcc_stacktrace_build_id()\n          b.status = addr.status\n          b.build_id = addr.build_id\n          b.u.offset = addr.offset;\n          res = lib.bcc_buildsymcache_resolve(BPF._bsymcache,\n                                              ct.byref(b),\n                                              ct.byref(sym))\n          if res < 0:\n            if sym.module and sym.offset:\n              name,offset,module = (None, sym.offset,\n                        ct.cast(sym.module, ct.c_char_p).value)\n            else:\n              name, offset, module = (None, addr, None)\n          else:\n            name, offset, module = (sym.name, sym.offset,\n                                    ct.cast(sym.module, ct.c_char_p).value)\n        else:\n          name, offset, module = BPF._sym_cache(pid).resolve(addr, demangle)\n\n        offset = b\"+0x%x\" % offset if show_offset and name is not None else b\"\"\n        name = name or b\"[unknown]\"\n        name = name + offset\n        module = b\" [%s]\" % os.path.basename(module) \\\n            if show_module and module is not None else b\"\"\n        return name + module\n\n    @staticmethod\n    def ksym(addr, show_module=False, show_offset=False):\n        \"\"\"ksym(addr)\n\n        Translate a kernel memory address into a kernel function name, which is\n        returned. When show_module is True, the module name (\"kernel\") is also\n        included. When show_offset is true, the instruction offset as a\n        hexadecimal number is also included in the string.\n\n        Example output when both show_module and show_offset are True:\n            \"default_idle+0x0 [kernel]\"\n        \"\"\"\n        return BPF.sym(addr, -1, show_module, show_offset, False)\n\n    @staticmethod\n    def ksymname(name):\n        \"\"\"ksymname(name)\n\n        Translate a kernel name into an address. This is the reverse of\n        ksym. Returns -1 when the function name is unknown.\"\"\"\n        return BPF._sym_cache(-1).resolve_name(None, name)\n\n    def num_open_kprobes(self):\n        \"\"\"num_open_kprobes()\n\n        Get the number of open K[ret]probes. Can be useful for scenarios where\n        event_re is used while attaching and detaching probes.\n        \"\"\"\n        return len(self.kprobe_fds)\n\n    def num_open_uprobes(self):\n        \"\"\"num_open_uprobes()\n\n        Get the number of open U[ret]probes.\n        \"\"\"\n        return len(self.uprobe_fds)\n\n    def num_open_tracepoints(self):\n        \"\"\"num_open_tracepoints()\n\n        Get the number of open tracepoints.\n        \"\"\"\n        return len(self.tracepoint_fds)\n\n    def perf_buffer_poll(self, timeout = -1):\n        \"\"\"perf_buffer_poll(self)\n\n        Poll from all open perf ring buffers, calling the callback that was\n        provided when calling open_perf_buffer for each entry.\n        \"\"\"\n        readers = (ct.c_void_p * len(self.perf_buffers))()\n        for i, v in enumerate(self.perf_buffers.values()):\n            readers[i] = v\n        lib.perf_reader_poll(len(readers), readers, timeout)\n\n    def kprobe_poll(self, timeout = -1):\n        \"\"\"kprobe_poll(self)\n\n        Deprecated. Use perf_buffer_poll instead.\n        \"\"\"\n        self.perf_buffer_poll(timeout)\n\n    def free_bcc_memory(self):\n        return lib.bcc_free_memory()\n\n    @staticmethod\n    def add_module(modname):\n      \"\"\"add_module(modname)\n\n        Add a library or exe to buildsym cache\n      \"\"\"\n      try:\n        lib.bcc_buildsymcache_add_module(BPF._bsymcache, modname.encode())\n      except Exception as e:\n        print(\"Error adding module to build sym cache\"+str(e))\n\n    def donothing(self):\n        \"\"\"the do nothing exit handler\"\"\"\n\n    def cleanup(self):\n        # Clean up opened probes\n        for k, v in list(self.kprobe_fds.items()):\n            self.detach_kprobe_event(k)\n        for k, v in list(self.uprobe_fds.items()):\n            self.detach_uprobe_event(k)\n        for k, v in list(self.tracepoint_fds.items()):\n            self.detach_tracepoint(k)\n        for k, v in list(self.raw_tracepoint_fds.items()):\n            self.detach_raw_tracepoint(k)\n\n        # Clean up opened perf ring buffer and perf events\n        table_keys = list(self.tables.keys())\n        for key in table_keys:\n            if isinstance(self.tables[key], PerfEventArray):\n                del self.tables[key]\n        for (ev_type, ev_config) in list(self.open_perf_events.keys()):\n            self.detach_perf_event(ev_type, ev_config)\n        if self.tracefile:\n            self.tracefile.close()\n            self.tracefile = None\n        if self.module:\n            lib.bpf_module_destroy(self.module)\n            self.module = None\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, exc_type, exc_val, exc_tb):\n        self.cleanup()",
  "def __init__(self, pid):\n        self.cache = lib.bcc_symcache_new(\n                pid, ct.cast(None, ct.POINTER(bcc_symbol_option)))",
  "def resolve(self, addr, demangle):\n        \"\"\"\n        Return a tuple of the symbol (function), its offset from the beginning\n        of the function, and the module in which it lies. For example:\n            (\"start_thread\", 0x202, \"/usr/lib/.../libpthread-2.24.so\")\n        If the symbol cannot be found but we know which module it is in,\n        return the module name and the offset from the beginning of the\n        module. If we don't even know the module, return the absolute\n        address as the offset.\n        \"\"\"\n\n        sym = bcc_symbol()\n        if demangle:\n            res = lib.bcc_symcache_resolve(self.cache, addr, ct.byref(sym))\n        else:\n            res = lib.bcc_symcache_resolve_no_demangle(self.cache, addr,\n                                                       ct.byref(sym))\n        if res < 0:\n            if sym.module and sym.offset:\n                return (None, sym.offset,\n                        ct.cast(sym.module, ct.c_char_p).value)\n            return (None, addr, None)\n        if demangle:\n            name_res = sym.demangle_name\n            lib.bcc_symbol_free_demangle_name(ct.byref(sym))\n        else:\n            name_res = sym.name\n        return (name_res, sym.offset, ct.cast(sym.module, ct.c_char_p).value)",
  "def resolve_name(self, module, name):\n        module = _assert_is_bytes(module)\n        name = _assert_is_bytes(name)\n        addr = ct.c_ulonglong()\n        if lib.bcc_symcache_resolve_name(self.cache, module, name,\n                ct.byref(addr)) < 0:\n            return -1\n        return addr.value",
  "class timespec(ct.Structure):\n        _fields_ = [('tv_sec', ct.c_long), ('tv_nsec', ct.c_long)]",
  "def monotonic_time(cls):\n        \"\"\"monotonic_time()\n        Returns the system monotonic time from clock_gettime, using the\n        CLOCK_MONOTONIC constant. The time returned is in nanoseconds.\n        \"\"\"\n        t = cls.timespec()\n        if cls._clock_gettime(cls.CLOCK_MONOTONIC, ct.byref(t)) != 0:\n            errno = ct.get_errno()\n            raise OSError(errno, os.strerror(errno))\n        return t.tv_sec * 1e9 + t.tv_nsec",
  "def generate_auto_includes(cls, program_words):\n        \"\"\"\n        Generates #include statements automatically based on a set of\n        recognized types such as sk_buff and bio. The input is all the words\n        that appear in the BPF program, and the output is a (possibly empty)\n        string of #include statements, such as \"#include <linux/fs.h>\".\n        \"\"\"\n        headers = \"\"\n        for header, keywords in cls._auto_includes.items():\n            for keyword in keywords:\n                for word in program_words:\n                    if keyword in word and header not in headers:\n                        headers += \"#include <%s>\\n\" % header\n        return headers",
  "class Function(object):\n        def __init__(self, bpf, name, fd):\n            self.bpf = bpf\n            self.name = name\n            self.fd = fd",
  "def _find_file(filename):\n        \"\"\" If filename is invalid, search in ./ of argv[0] \"\"\"\n        if filename:\n            if not os.path.isfile(filename):\n                argv0 = ArgString(sys.argv[0])\n                t = b\"/\".join([os.path.abspath(os.path.dirname(argv0.__str__())), filename])\n                if os.path.isfile(t):\n                    filename = t\n                else:\n                    raise Exception(\"Could not find file %s\" % filename)\n        return filename",
  "def find_exe(bin_path):\n        \"\"\"\n        find_exe(bin_path)\n\n        Traverses the PATH environment variable, looking for the first\n        directory that contains an executable file named bin_path, and\n        returns the full path to that file, or None if no such file\n        can be found. This is meant to replace invocations of the\n        \"which\" shell utility, which doesn't have portable semantics\n        for skipping aliases.\n        \"\"\"\n        # Source: http://stackoverflow.com/a/377028\n        def is_exe(fpath):\n            return os.path.isfile(fpath) and \\\n                os.access(fpath, os.X_OK)\n\n        fpath, fname = os.path.split(bin_path)\n        if fpath:\n            if is_exe(bin_path):\n                return bin_path\n        else:\n            for path in os.environ[\"PATH\"].split(os.pathsep):\n                path = path.strip('\"')\n                exe_file = os.path.join(path, bin_path)\n                if is_exe(exe_file):\n                    return exe_file\n        return None",
  "def __init__(self, src_file=b\"\", hdr_file=b\"\", text=None, debug=0,\n            cflags=[], usdt_contexts=[]):\n        \"\"\"Create a new BPF module with the given source code.\n\n        Note:\n            All fields are marked as optional, but either `src_file` or `text`\n            must be supplied, and not both.\n\n        Args:\n            src_file (Optional[str]): Path to a source file for the module\n            hdr_file (Optional[str]): Path to a helper header file for the `src_file`\n            text (Optional[str]): Contents of a source file for the module\n            debug (Optional[int]): Flags used for debug prints, can be |'d together\n                                   See \"Debug flags\" for explanation\n        \"\"\"\n\n        src_file = _assert_is_bytes(src_file)\n        hdr_file = _assert_is_bytes(hdr_file)\n        text = _assert_is_bytes(text)\n\n        self.kprobe_fds = {}\n        self.uprobe_fds = {}\n        self.tracepoint_fds = {}\n        self.raw_tracepoint_fds = {}\n        self.perf_buffers = {}\n        self.open_perf_events = {}\n        self.tracefile = None\n        atexit.register(self.cleanup)\n\n        self.debug = debug\n        self.funcs = {}\n        self.tables = {}\n        self.module = None\n        cflags_array = (ct.c_char_p * len(cflags))()\n        for i, s in enumerate(cflags): cflags_array[i] = bytes(ArgString(s))\n        if text:\n            ctx_array = (ct.c_void_p * len(usdt_contexts))()\n            for i, usdt in enumerate(usdt_contexts):\n                ctx_array[i] = ct.c_void_p(usdt.get_context())\n            usdt_text = lib.bcc_usdt_genargs(ctx_array, len(usdt_contexts))\n            if usdt_text is None:\n                raise Exception(\"can't generate USDT probe arguments; \" +\n                                \"possible cause is missing pid when a \" +\n                                \"probe in a shared object has multiple \" +\n                                \"locations\")\n            text = usdt_text + text\n\n        if text:\n            self.module = lib.bpf_module_create_c_from_string(text,\n                    self.debug, cflags_array, len(cflags_array))\n            if not self.module:\n                raise Exception(\"Failed to compile BPF text\")\n        else:\n            src_file = BPF._find_file(src_file)\n            hdr_file = BPF._find_file(hdr_file)\n            if src_file.endswith(b\".b\"):\n                self.module = lib.bpf_module_create_b(src_file, hdr_file,\n                        self.debug)\n            else:\n                self.module = lib.bpf_module_create_c(src_file, self.debug,\n                        cflags_array, len(cflags_array))\n            if not self.module:\n                raise Exception(\"Failed to compile BPF module %s\" % src_file)\n\n        for usdt_context in usdt_contexts:\n            usdt_context.attach_uprobes(self)\n\n        # If any \"kprobe__\" or \"tracepoint__\" or \"raw_tracepoint__\"\n        # prefixed functions were defined,\n        # they will be loaded and attached here.\n        self._trace_autoload()",
  "def load_funcs(self, prog_type=KPROBE):\n        \"\"\"load_funcs(prog_type=KPROBE)\n\n        Load all functions in this BPF module with the given type.\n        Returns a list of the function handles.\"\"\"\n\n        fns = []\n        for i in range(0, lib.bpf_num_functions(self.module)):\n            func_name = lib.bpf_function_name(self.module, i)\n            fns.append(self.load_func(func_name, prog_type))\n\n        return fns",
  "def load_func(self, func_name, prog_type):\n        func_name = _assert_is_bytes(func_name)\n        if func_name in self.funcs:\n            return self.funcs[func_name]\n        if not lib.bpf_function_start(self.module, func_name):\n            raise Exception(\"Unknown program %s\" % func_name)\n        log_level = 0\n        if (self.debug & DEBUG_BPF_REGISTER_STATE):\n            log_level = 2\n        elif (self.debug & DEBUG_BPF):\n            log_level = 1\n        fd = lib.bpf_prog_load(prog_type, func_name,\n                lib.bpf_function_start(self.module, func_name),\n                lib.bpf_function_size(self.module, func_name),\n                lib.bpf_module_license(self.module),\n                lib.bpf_module_kern_version(self.module),\n                log_level, None, 0);\n\n        if fd < 0:\n            atexit.register(self.donothing)\n            if ct.get_errno() == errno.EPERM:\n                raise Exception(\"Need super-user privileges to run\")\n\n            errstr = os.strerror(ct.get_errno())\n            raise Exception(\"Failed to load BPF program %s: %s\" %\n                            (func_name, errstr))\n\n        fn = BPF.Function(self, func_name, fd)\n        self.funcs[func_name] = fn\n\n        return fn",
  "def dump_func(self, func_name):\n        \"\"\"\n        Return the eBPF bytecodes for the specified function as a string\n        \"\"\"\n        func_name = _assert_is_bytes(func_name)\n        if not lib.bpf_function_start(self.module, func_name):\n            raise Exception(\"Unknown program %s\" % func_name)\n\n        start, = lib.bpf_function_start(self.module, func_name),\n        size, = lib.bpf_function_size(self.module, func_name),\n        return ct.string_at(start, size)",
  "def _decode_table_type(desc):\n        if isinstance(desc, basestring):\n            return BPF.str2ctype[desc]\n        anon = []\n        fields = []\n        for t in desc[1]:\n            if len(t) == 2:\n                fields.append((t[0], BPF._decode_table_type(t[1])))\n            elif len(t) == 3:\n                if isinstance(t[2], list):\n                    fields.append((t[0], BPF._decode_table_type(t[1]) * t[2][0]))\n                elif isinstance(t[2], int):\n                    fields.append((t[0], BPF._decode_table_type(t[1]), t[2]))\n                elif isinstance(t[2], basestring) and (\n                        t[2] == u\"union\" or t[2] == u\"struct\" or\n                        t[2] == u\"struct_packed\"):\n                    name = t[0]\n                    if name == \"\":\n                        name = \"__anon%d\" % len(anon)\n                        anon.append(name)\n                    fields.append((name, BPF._decode_table_type(t)))\n                else:\n                    raise Exception(\"Failed to decode type %s\" % str(t))\n            else:\n                raise Exception(\"Failed to decode type %s\" % str(t))\n        base = ct.Structure\n        is_packed = False\n        if len(desc) > 2:\n            if desc[2] == u\"union\":\n                base = ct.Union\n            elif desc[2] == u\"struct\":\n                base = ct.Structure\n            elif desc[2] == u\"struct_packed\":\n                base = ct.Structure\n                is_packed = True\n        if is_packed:\n            cls = type(str(desc[0]), (base,), dict(_anonymous_=anon, _pack_=1,\n                _fields_=fields))\n        else:\n            cls = type(str(desc[0]), (base,), dict(_anonymous_=anon,\n                _fields_=fields))\n        return cls",
  "def get_table(self, name, keytype=None, leaftype=None, reducer=None):\n        name = _assert_is_bytes(name)\n        map_id = lib.bpf_table_id(self.module, name)\n        map_fd = lib.bpf_table_fd(self.module, name)\n        if map_fd < 0:\n            raise KeyError\n        if not keytype:\n            key_desc = lib.bpf_table_key_desc(self.module, name).decode(\"utf-8\")\n            if not key_desc:\n                raise Exception(\"Failed to load BPF Table %s key desc\" % name)\n            keytype = BPF._decode_table_type(json.loads(key_desc))\n        if not leaftype:\n            leaf_desc = lib.bpf_table_leaf_desc(self.module, name).decode(\"utf-8\")\n            if not leaf_desc:\n                raise Exception(\"Failed to load BPF Table %s leaf desc\" % name)\n            leaftype = BPF._decode_table_type(json.loads(leaf_desc))\n        return Table(self, map_id, map_fd, keytype, leaftype, reducer=reducer)",
  "def __getitem__(self, key):\n        if key not in self.tables:\n            self.tables[key] = self.get_table(key)\n        return self.tables[key]",
  "def __setitem__(self, key, leaf):\n        self.tables[key] = leaf",
  "def __len__(self):\n        return len(self.tables)",
  "def __delitem__(self, key):\n        del self.tables[key]",
  "def __iter__(self):\n        return self.tables.__iter__()",
  "def attach_raw_socket(fn, dev):\n        dev = _assert_is_bytes(dev)\n        if not isinstance(fn, BPF.Function):\n            raise Exception(\"arg 1 must be of type BPF.Function\")\n        sock = lib.bpf_open_raw_sock(dev)\n        if sock < 0:\n            errstr = os.strerror(ct.get_errno())\n            raise Exception(\"Failed to open raw device %s: %s\" % (dev, errstr))\n        res = lib.bpf_attach_socket(sock, fn.fd)\n        if res < 0:\n            errstr = os.strerror(ct.get_errno())\n            raise Exception(\"Failed to attach BPF to device %s: %s\"\n                    % (dev, errstr))\n        fn.sock = sock",
  "def get_kprobe_functions(event_re):\n        with open(\"%s/../kprobes/blacklist\" % TRACEFS, \"rb\") as blacklist_f:\n            blacklist = set([line.rstrip().split()[1] for line in blacklist_f])\n        fns = []\n\n        in_init_section = 0\n        in_irq_section = 0\n        with open(\"/proc/kallsyms\", \"rb\") as avail_file:\n            for line in avail_file:\n                (t, fn) = line.rstrip().split()[1:3]\n                # Skip all functions defined between __init_begin and\n                # __init_end\n                if in_init_section == 0:\n                    if fn == b'__init_begin':\n                        in_init_section = 1\n                        continue\n                elif in_init_section == 1:\n                    if fn == b'__init_end':\n                        in_init_section = 2\n                    continue\n                # Skip all functions defined between __irqentry_text_start and\n                # __irqentry_text_end\n                if in_irq_section == 0:\n                    if fn == b'__irqentry_text_start':\n                        in_irq_section = 1\n                        continue\n                elif in_irq_section == 1:\n                    if fn == b'__irqentry_text_end':\n                        in_irq_section = 2\n                    continue\n                # All functions defined as NOKPROBE_SYMBOL() start with the\n                # prefix _kbl_addr_*, blacklisting them by looking at the name\n                # allows to catch also those symbols that are defined in kernel\n                # modules.\n                if fn.startswith(b'_kbl_addr_'):\n                    continue\n                # Explicitly blacklist perf-related functions, they are all\n                # non-attachable.\n                elif fn.startswith(b'__perf') or fn.startswith(b'perf_'):\n                    continue\n                if (t.lower() in [b't', b'w']) and re.match(event_re, fn) \\\n                    and fn not in blacklist:\n                    fns.append(fn)\n        return set(fns)",
  "def _check_probe_quota(self, num_new_probes):\n        global _num_open_probes\n        if _num_open_probes + num_new_probes > _probe_limit:\n            raise Exception(\"Number of open probes would exceed global quota\")",
  "def _add_kprobe_fd(self, name, fd):\n        global _num_open_probes\n        self.kprobe_fds[name] = fd\n        _num_open_probes += 1",
  "def _del_kprobe_fd(self, name):\n        global _num_open_probes\n        del self.kprobe_fds[name]\n        _num_open_probes -= 1",
  "def _add_uprobe_fd(self, name, fd):\n        global _num_open_probes\n        self.uprobe_fds[name] = fd\n        _num_open_probes += 1",
  "def _del_uprobe_fd(self, name):\n        global _num_open_probes\n        del self.uprobe_fds[name]\n        _num_open_probes -= 1",
  "def get_syscall_prefix(self):\n        for prefix in self._syscall_prefixes:\n            if self.ksymname(b\"%sbpf\" % prefix) != -1:\n                return prefix\n        return self._syscall_prefixes[0]",
  "def get_syscall_fnname(self, name):\n        name = _assert_is_bytes(name)\n        return self.get_syscall_prefix() + name",
  "def fix_syscall_fnname(self, name):\n        name = _assert_is_bytes(name)\n        for prefix in self._syscall_prefixes:\n            if name.startswith(prefix):\n                return self.get_syscall_fnname(name[len(prefix):])\n        return name",
  "def attach_kprobe(self, event=b\"\", event_off=0, fn_name=b\"\", event_re=b\"\"):\n        event = _assert_is_bytes(event)\n        fn_name = _assert_is_bytes(fn_name)\n        event_re = _assert_is_bytes(event_re)\n\n        # allow the caller to glob multiple functions together\n        if event_re:\n            matches = BPF.get_kprobe_functions(event_re)\n            self._check_probe_quota(len(matches))\n            for line in matches:\n                try:\n                    self.attach_kprobe(event=line, fn_name=fn_name)\n                except:\n                    pass\n            return\n\n        self._check_probe_quota(1)\n        fn = self.load_func(fn_name, BPF.KPROBE)\n        ev_name = b\"p_\" + event.replace(b\"+\", b\"_\").replace(b\".\", b\"_\")\n        fd = lib.bpf_attach_kprobe(fn.fd, 0, ev_name, event, event_off)\n        if fd < 0:\n            raise Exception(\"Failed to attach BPF program %s to kprobe %s\" %\n                            (fn_name, event))\n        self._add_kprobe_fd(ev_name, fd)\n        return self",
  "def attach_kretprobe(self, event=b\"\", fn_name=b\"\", event_re=b\"\"):\n        event = _assert_is_bytes(event)\n        fn_name = _assert_is_bytes(fn_name)\n        event_re = _assert_is_bytes(event_re)\n\n        # allow the caller to glob multiple functions together\n        if event_re:\n            for line in BPF.get_kprobe_functions(event_re):\n                try:\n                    self.attach_kretprobe(event=line, fn_name=fn_name)\n                except:\n                    pass\n            return\n\n        self._check_probe_quota(1)\n        fn = self.load_func(fn_name, BPF.KPROBE)\n        ev_name = b\"r_\" + event.replace(b\"+\", b\"_\").replace(b\".\", b\"_\")\n        fd = lib.bpf_attach_kprobe(fn.fd, 1, ev_name, event, 0)\n        if fd < 0:\n            raise Exception(\"Failed to attach BPF program %s to kretprobe %s\" %\n                            (fn_name, event))\n        self._add_kprobe_fd(ev_name, fd)\n        return self",
  "def detach_kprobe_event(self, ev_name):\n        if ev_name not in self.kprobe_fds:\n            raise Exception(\"Kprobe %s is not attached\" % ev_name)\n        res = lib.bpf_close_perf_event_fd(self.kprobe_fds[ev_name])\n        if res < 0:\n            raise Exception(\"Failed to close kprobe FD\")\n        res = lib.bpf_detach_kprobe(ev_name)\n        if res < 0:\n            raise Exception(\"Failed to detach BPF from kprobe\")\n        self._del_kprobe_fd(ev_name)",
  "def detach_kprobe(self, event):\n        event = _assert_is_bytes(event)\n        ev_name = b\"p_\" + event.replace(b\"+\", b\"_\").replace(b\".\", b\"_\")\n        self.detach_kprobe_event(ev_name)",
  "def detach_kretprobe(self, event):\n        event = _assert_is_bytes(event)\n        ev_name = b\"r_\" + event.replace(b\"+\", b\"_\").replace(b\".\", b\"_\")\n        self.detach_kprobe_event(ev_name)",
  "def attach_xdp(dev, fn, flags=0):\n        '''\n            This function attaches a BPF function to a device on the device\n            driver level (XDP)\n        '''\n        dev = _assert_is_bytes(dev)\n        if not isinstance(fn, BPF.Function):\n            raise Exception(\"arg 1 must be of type BPF.Function\")\n        res = lib.bpf_attach_xdp(dev, fn.fd, flags)\n        if res < 0:\n            err_no = ct.get_errno()\n            if err_no == errno.EBADMSG:\n                raise Exception(\"Internal error while attaching BPF to device,\"+\n                    \" try increasing the debug level!\")\n            else:\n                errstr = os.strerror(err_no)\n                raise Exception(\"Failed to attach BPF to device %s: %s\"\n                            % (dev, errstr))",
  "def remove_xdp(dev, flags=0):\n        '''\n            This function removes any BPF function from a device on the\n            device driver level (XDP)\n        '''\n        dev = _assert_is_bytes(dev)\n        res = lib.bpf_attach_xdp(dev, -1, flags)\n        if res < 0:\n            errstr = os.strerror(ct.get_errno())\n            raise Exception(\"Failed to detach BPF from device %s: %s\"\n                            % (dev, errstr))",
  "def _check_path_symbol(cls, module, symname, addr, pid):\n        module = _assert_is_bytes(module)\n        symname = _assert_is_bytes(symname)\n        sym = bcc_symbol()\n        c_pid = 0 if pid == -1 else pid\n        if lib.bcc_resolve_symname(\n            module, symname,\n            addr or 0x0, c_pid,\n            ct.cast(None, ct.POINTER(bcc_symbol_option)),\n            ct.byref(sym),\n        ) < 0:\n            raise Exception(\"could not determine address of symbol %s\" % symname)\n        module_path = ct.cast(sym.module, ct.c_char_p).value\n        lib.bcc_procutils_free(sym.module)\n        return module_path, sym.offset",
  "def find_library(libname):\n        libname = _assert_is_bytes(libname)\n        res = lib.bcc_procutils_which_so(libname, 0)\n        if not res:\n            return None\n        libpath = ct.cast(res, ct.c_char_p).value\n        lib.bcc_procutils_free(res)\n        return libpath",
  "def get_tracepoints(tp_re):\n        results = []\n        events_dir = os.path.join(TRACEFS, \"events\")\n        for category in os.listdir(events_dir):\n            cat_dir = os.path.join(events_dir, category)\n            if not os.path.isdir(cat_dir):\n                continue\n            for event in os.listdir(cat_dir):\n                evt_dir = os.path.join(cat_dir, event)\n                if os.path.isdir(evt_dir):\n                    tp = (\"%s:%s\" % (category, event))\n                    if re.match(tp_re, tp):\n                        results.append(tp)\n        return results",
  "def tracepoint_exists(category, event):\n        evt_dir = os.path.join(TRACEFS, \"events\", category, event)\n        return os.path.isdir(evt_dir)",
  "def attach_tracepoint(self, tp=b\"\", tp_re=b\"\", fn_name=b\"\"):\n        \"\"\"attach_tracepoint(tp=\"\", tp_re=\"\", fn_name=\"\")\n\n        Run the bpf function denoted by fn_name every time the kernel tracepoint\n        specified by 'tp' is hit. The optional parameters pid, cpu, and group_fd\n        can be used to filter the probe. The tracepoint specification is simply\n        the tracepoint category and the tracepoint name, separated by a colon.\n        For example: sched:sched_switch, syscalls:sys_enter_bind, etc.\n\n        Instead of a tracepoint name, a regular expression can be provided in\n        tp_re. The program will then attach to tracepoints that match the\n        provided regular expression.\n\n        To obtain a list of kernel tracepoints, use the tplist tool or cat the\n        file /sys/kernel/debug/tracing/available_events.\n\n        Examples:\n            BPF(text).attach_tracepoint(tp=\"sched:sched_switch\", fn_name=\"on_switch\")\n            BPF(text).attach_tracepoint(tp_re=\"sched:.*\", fn_name=\"on_switch\")\n        \"\"\"\n\n        tp = _assert_is_bytes(tp)\n        tp_re = _assert_is_bytes(tp_re)\n        fn_name = _assert_is_bytes(fn_name)\n        if tp_re:\n            for tp in BPF.get_tracepoints(tp_re):\n                self.attach_tracepoint(tp=tp, fn_name=fn_name)\n            return\n\n        fn = self.load_func(fn_name, BPF.TRACEPOINT)\n        (tp_category, tp_name) = tp.split(b':')\n        fd = lib.bpf_attach_tracepoint(fn.fd, tp_category, tp_name)\n        if fd < 0:\n            raise Exception(\"Failed to attach BPF program %s to tracepoint %s\" %\n                            (fn_name, tp))\n        self.tracepoint_fds[tp] = fd\n        return self",
  "def attach_raw_tracepoint(self, tp=b\"\", fn_name=b\"\"):\n        \"\"\"attach_raw_tracepoint(self, tp=b\"\", fn_name=b\"\")\n\n        Run the bpf function denoted by fn_name every time the kernel tracepoint\n        specified by 'tp' is hit. The bpf function should be loaded as a\n        RAW_TRACEPOINT type. The fn_name is the kernel tracepoint name,\n        e.g., sched_switch, sys_enter_bind, etc.\n\n        Examples:\n            BPF(text).attach_raw_tracepoint(tp=\"sched_switch\", fn_name=\"on_switch\")\n        \"\"\"\n\n        tp = _assert_is_bytes(tp)\n        if tp in self.raw_tracepoint_fds:\n            raise Exception(\"Raw tracepoint %s has been attached\" % tp)\n\n        fn_name = _assert_is_bytes(fn_name)\n        fn = self.load_func(fn_name, BPF.RAW_TRACEPOINT)\n        fd = lib.bpf_attach_raw_tracepoint(fn.fd, tp)\n        if fd < 0:\n            raise Exception(\"Failed to attach BPF to raw tracepoint\")\n        self.raw_tracepoint_fds[tp] = fd;\n        return self",
  "def detach_raw_tracepoint(self, tp=b\"\"):\n        \"\"\"detach_raw_tracepoint(tp=\"\")\n\n        Stop running the bpf function that is attached to the kernel tracepoint\n        specified by 'tp'.\n\n        Example: bpf.detach_raw_tracepoint(\"sched_switch\")\n        \"\"\"\n\n        tp = _assert_is_bytes(tp)\n        if tp not in self.raw_tracepoint_fds:\n            raise Exception(\"Raw tracepoint %s is not attached\" % tp)\n        os.close(self.raw_tracepoint_fds[tp])\n        del self.raw_tracepoint_fds[tp]",
  "def support_raw_tracepoint():\n        # kernel symbol \"bpf_find_raw_tracepoint\" indicates raw_tracepint support\n        if BPF.ksymname(\"bpf_find_raw_tracepoint\") != -1:\n            return True\n        return False",
  "def detach_tracepoint(self, tp=b\"\"):\n        \"\"\"detach_tracepoint(tp=\"\")\n\n        Stop running a bpf function that is attached to the kernel tracepoint\n        specified by 'tp'.\n\n        Example: bpf.detach_tracepoint(\"sched:sched_switch\")\n        \"\"\"\n\n        tp = _assert_is_bytes(tp)\n        if tp not in self.tracepoint_fds:\n            raise Exception(\"Tracepoint %s is not attached\" % tp)\n        res = lib.bpf_close_perf_event_fd(self.tracepoint_fds[tp])\n        if res < 0:\n            raise Exception(\"Failed to detach BPF from tracepoint\")\n        (tp_category, tp_name) = tp.split(b':')\n        res = lib.bpf_detach_tracepoint(tp_category, tp_name)\n        if res < 0:\n            raise Exception(\"Failed to detach BPF from tracepoint\")\n        del self.tracepoint_fds[tp]",
  "def _attach_perf_event(self, progfd, ev_type, ev_config,\n            sample_period, sample_freq, pid, cpu, group_fd):\n        res = lib.bpf_attach_perf_event(progfd, ev_type, ev_config,\n                sample_period, sample_freq, pid, cpu, group_fd)\n        if res < 0:\n            raise Exception(\"Failed to attach BPF to perf event\")\n        return res",
  "def attach_perf_event(self, ev_type=-1, ev_config=-1, fn_name=b\"\",\n            sample_period=0, sample_freq=0, pid=-1, cpu=-1, group_fd=-1):\n        fn_name = _assert_is_bytes(fn_name)\n        fn = self.load_func(fn_name, BPF.PERF_EVENT)\n        res = {}\n        if cpu >= 0:\n            res[cpu] = self._attach_perf_event(fn.fd, ev_type, ev_config,\n                    sample_period, sample_freq, pid, cpu, group_fd)\n        else:\n            for i in get_online_cpus():\n                res[i] = self._attach_perf_event(fn.fd, ev_type, ev_config,\n                        sample_period, sample_freq, pid, i, group_fd)\n        self.open_perf_events[(ev_type, ev_config)] = res",
  "def detach_perf_event(self, ev_type=-1, ev_config=-1):\n        try:\n            fds = self.open_perf_events[(ev_type, ev_config)]\n        except KeyError:\n            raise Exception(\"Perf event type {} config {} not attached\".format(\n                ev_type, ev_config))\n\n        res = 0\n        for fd in fds.values():\n            res = lib.bpf_close_perf_event_fd(fd) or res\n        if res != 0:\n            raise Exception(\"Failed to detach BPF from perf event\")\n        del self.open_perf_events[(ev_type, ev_config)]",
  "def get_user_functions(name, sym_re):\n        return set([name for (name, _) in\n                    BPF.get_user_functions_and_addresses(name, sym_re)])",
  "def get_user_addresses(name, sym_re):\n        \"\"\"\n        We are returning addresses here instead of symbol names because it\n        turns out that the same name may appear multiple times with different\n        addresses, and the same address may appear multiple times with the same\n        name. We can't attach a uprobe to the same address more than once, so\n        it makes sense to return the unique set of addresses that are mapped to\n        a symbol that matches the provided regular expression.\n        \"\"\"\n        return set([address for (_, address) in\n                    BPF.get_user_functions_and_addresses(name, sym_re)])",
  "def get_user_functions_and_addresses(name, sym_re):\n        name = _assert_is_bytes(name)\n        sym_re = _assert_is_bytes(sym_re)\n        addresses = []\n        def sym_cb(sym_name, addr):\n            dname = sym_name\n            if re.match(sym_re, dname):\n                addresses.append((dname, addr))\n            return 0\n\n        res = lib.bcc_foreach_function_symbol(name, _SYM_CB_TYPE(sym_cb))\n        if res < 0:\n            raise Exception(\"Error %d enumerating symbols in %s\" % (res, name))\n        return addresses",
  "def _get_uprobe_evname(self, prefix, path, addr, pid):\n        if pid == -1:\n            return b\"%s_%s_0x%x\" % (prefix, self._probe_repl.sub(b\"_\", path), addr)\n        else:\n            # if pid is valid, put pid in the name, so different pid\n            # can have different event names\n            return b\"%s_%s_0x%x_%d\" % (prefix, self._probe_repl.sub(b\"_\", path), addr, pid)",
  "def attach_uprobe(self, name=b\"\", sym=b\"\", sym_re=b\"\", addr=None,\n            fn_name=b\"\", pid=-1):\n        \"\"\"attach_uprobe(name=\"\", sym=\"\", sym_re=\"\", addr=None, fn_name=\"\"\n                         pid=-1)\n\n        Run the bpf function denoted by fn_name every time the symbol sym in\n        the library or binary 'name' is encountered. The real address addr may\n        be supplied in place of sym. Optional parameters pid, cpu, and group_fd\n        can be used to filter the probe.\n\n        Instead of a symbol name, a regular expression can be provided in\n        sym_re. The uprobe will then attach to symbols that match the provided\n        regular expression.\n\n        Libraries can be given in the name argument without the lib prefix, or\n        with the full path (/usr/lib/...). Binaries can be given only with the\n        full path (/bin/sh). If a PID is given, the uprobe will attach to the\n        version of the library used by the process.\n\n        Example: BPF(text).attach_uprobe(\"c\", \"malloc\")\n                 BPF(text).attach_uprobe(\"/usr/bin/python\", \"main\")\n        \"\"\"\n\n        name = _assert_is_bytes(name)\n        sym = _assert_is_bytes(sym)\n        sym_re = _assert_is_bytes(sym_re)\n        fn_name = _assert_is_bytes(fn_name)\n\n        if sym_re:\n            addresses = BPF.get_user_addresses(name, sym_re)\n            self._check_probe_quota(len(addresses))\n            for sym_addr in addresses:\n                self.attach_uprobe(name=name, addr=sym_addr,\n                                   fn_name=fn_name, pid=pid)\n            return\n\n        (path, addr) = BPF._check_path_symbol(name, sym, addr, pid)\n\n        self._check_probe_quota(1)\n        fn = self.load_func(fn_name, BPF.KPROBE)\n        ev_name = self._get_uprobe_evname(b\"p\", path, addr, pid)\n        fd = lib.bpf_attach_uprobe(fn.fd, 0, ev_name, path, addr, pid)\n        if fd < 0:\n            raise Exception(\"Failed to attach BPF to uprobe\")\n        self._add_uprobe_fd(ev_name, fd)\n        return self",
  "def attach_uretprobe(self, name=b\"\", sym=b\"\", sym_re=b\"\", addr=None,\n            fn_name=b\"\", pid=-1):\n        \"\"\"attach_uretprobe(name=\"\", sym=\"\", sym_re=\"\", addr=None, fn_name=\"\"\n                            pid=-1)\n\n        Run the bpf function denoted by fn_name every time the symbol sym in\n        the library or binary 'name' finishes execution. See attach_uprobe for\n        meaning of additional parameters.\n        \"\"\"\n\n        name = _assert_is_bytes(name)\n        sym = _assert_is_bytes(sym)\n        sym_re = _assert_is_bytes(sym_re)\n        fn_name = _assert_is_bytes(fn_name)\n\n        if sym_re:\n            for sym_addr in BPF.get_user_addresses(name, sym_re):\n                self.attach_uretprobe(name=name, addr=sym_addr,\n                                      fn_name=fn_name, pid=pid)\n            return\n\n        (path, addr) = BPF._check_path_symbol(name, sym, addr, pid)\n\n        self._check_probe_quota(1)\n        fn = self.load_func(fn_name, BPF.KPROBE)\n        ev_name = self._get_uprobe_evname(b\"r\", path, addr, pid)\n        fd = lib.bpf_attach_uprobe(fn.fd, 1, ev_name, path, addr, pid)\n        if fd < 0:\n            raise Exception(\"Failed to attach BPF to uretprobe\")\n        self._add_uprobe_fd(ev_name, fd)\n        return self",
  "def detach_uprobe_event(self, ev_name):\n        if ev_name not in self.uprobe_fds:\n            raise Exception(\"Uprobe %s is not attached\" % ev_name)\n        res = lib.bpf_close_perf_event_fd(self.uprobe_fds[ev_name])\n        if res < 0:\n            raise Exception(\"Failed to detach BPF from uprobe\")\n        res = lib.bpf_detach_uprobe(ev_name)\n        if res < 0:\n            raise Exception(\"Failed to detach BPF from uprobe\")\n        self._del_uprobe_fd(ev_name)",
  "def detach_uprobe(self, name=b\"\", sym=b\"\", addr=None, pid=-1):\n        \"\"\"detach_uprobe(name=\"\", sym=\"\", addr=None, pid=-1)\n\n        Stop running a bpf function that is attached to symbol 'sym' in library\n        or binary 'name'.\n        \"\"\"\n\n        name = _assert_is_bytes(name)\n        sym = _assert_is_bytes(sym)\n        (path, addr) = BPF._check_path_symbol(name, sym, addr, pid)\n        ev_name = self._get_uprobe_evname(b\"p\", path, addr, pid)\n        self.detach_uprobe_event(ev_name)",
  "def detach_uretprobe(self, name=b\"\", sym=b\"\", addr=None, pid=-1):\n        \"\"\"detach_uretprobe(name=\"\", sym=\"\", addr=None, pid=-1)\n\n        Stop running a bpf function that is attached to symbol 'sym' in library\n        or binary 'name'.\n        \"\"\"\n\n        name = _assert_is_bytes(name)\n        sym = _assert_is_bytes(sym)\n\n        (path, addr) = BPF._check_path_symbol(name, sym, addr, pid)\n        ev_name = self._get_uprobe_evname(b\"r\", path, addr, pid)\n        self.detach_uprobe_event(ev_name)",
  "def _trace_autoload(self):\n        for i in range(0, lib.bpf_num_functions(self.module)):\n            func_name = lib.bpf_function_name(self.module, i)\n            if func_name.startswith(b\"kprobe__\"):\n                fn = self.load_func(func_name, BPF.KPROBE)\n                self.attach_kprobe(\n                    event=self.fix_syscall_fnname(func_name[8:]),\n                    fn_name=fn.name)\n            elif func_name.startswith(b\"kretprobe__\"):\n                fn = self.load_func(func_name, BPF.KPROBE)\n                self.attach_kretprobe(\n                    event=self.fix_syscall_fnname(func_name[11:]),\n                    fn_name=fn.name)\n            elif func_name.startswith(b\"tracepoint__\"):\n                fn = self.load_func(func_name, BPF.TRACEPOINT)\n                tp = fn.name[len(b\"tracepoint__\"):].replace(b\"__\", b\":\")\n                self.attach_tracepoint(tp=tp, fn_name=fn.name)\n            elif func_name.startswith(b\"raw_tracepoint__\"):\n                fn = self.load_func(func_name, BPF.RAW_TRACEPOINT)\n                tp = fn.name[len(b\"raw_tracepoint__\"):]\n                self.attach_raw_tracepoint(tp=tp, fn_name=fn.name)",
  "def trace_open(self, nonblocking=False):\n        \"\"\"trace_open(nonblocking=False)\n\n        Open the trace_pipe if not already open\n        \"\"\"\n        if not self.tracefile:\n            self.tracefile = open(\"%s/trace_pipe\" % TRACEFS, \"rb\")\n            if nonblocking:\n                fd = self.tracefile.fileno()\n                fl = fcntl.fcntl(fd, fcntl.F_GETFL)\n                fcntl.fcntl(fd, fcntl.F_SETFL, fl | os.O_NONBLOCK)\n        return self.tracefile",
  "def trace_fields(self, nonblocking=False):\n        \"\"\"trace_fields(nonblocking=False)\n\n        Read from the kernel debug trace pipe and return a tuple of the\n        fields (task, pid, cpu, flags, timestamp, msg) or None if no\n        line was read (nonblocking=True)\n        \"\"\"\n        while True:\n            line = self.trace_readline(nonblocking)\n            if not line and nonblocking: return (None,) * 6\n            # don't print messages related to lost events\n            if line.startswith(b\"CPU:\"): continue\n            task = line[:16].lstrip()\n            line = line[17:]\n            ts_end = line.find(b\":\")\n            pid, cpu, flags, ts = line[:ts_end].split()\n            cpu = cpu[1:-1]\n            # line[ts_end:] will have \": [sym_or_addr]: msgs\"\n            # For trace_pipe debug output, the addr typically\n            # is invalid (e.g., 0x1). For kernel 4.12 or earlier,\n            # if address is not able to match a kernel symbol,\n            # nothing will be printed out. For kernel 4.13 and later,\n            # however, the illegal address will be printed out.\n            # Hence, both cases are handled here.\n            line = line[ts_end + 1:]\n            sym_end = line.find(b\":\")\n            msg = line[sym_end + 2:]\n            return (task, int(pid), int(cpu), flags, float(ts), msg)",
  "def trace_readline(self, nonblocking=False):\n        \"\"\"trace_readline(nonblocking=False)\n\n        Read from the kernel debug trace pipe and return one line\n        If nonblocking is False, this will block until ctrl-C is pressed.\n        \"\"\"\n\n        trace = self.trace_open(nonblocking)\n\n        line = None\n        try:\n            line = trace.readline(1024).rstrip()\n        except IOError:\n            pass\n        return line",
  "def trace_print(self, fmt=None):\n        \"\"\"trace_print(self, fmt=None)\n\n        Read from the kernel debug trace pipe and print on stdout.\n        If fmt is specified, apply as a format string to the output. See\n        trace_fields for the members of the tuple\n        example: trace_print(fmt=\"pid {1}, msg = {5}\")\n        \"\"\"\n\n        while True:\n            if fmt:\n                fields = self.trace_fields(nonblocking=False)\n                if not fields: continue\n                line = fmt.format(*fields)\n            else:\n                line = self.trace_readline(nonblocking=False)\n            print(line)\n            sys.stdout.flush()",
  "def _sym_cache(pid):\n        \"\"\"_sym_cache(pid)\n\n        Returns a symbol cache for the specified PID.\n        The kernel symbol cache is accessed by providing any PID less than zero.\n        \"\"\"\n        if pid < 0 and pid != -1:\n            pid = -1\n        if not pid in BPF._sym_caches:\n            BPF._sym_caches[pid] = SymbolCache(pid)\n        return BPF._sym_caches[pid]",
  "def sym(addr, pid, show_module=False, show_offset=False, demangle=True):\n        \"\"\"sym(addr, pid, show_module=False, show_offset=False)\n\n        Translate a memory address into a function name for a pid, which is\n        returned. When show_module is True, the module name is also included.\n        When show_offset is True, the instruction offset as a hexadecimal\n        number is also included in the string.\n\n        A pid of less than zero will access the kernel symbol cache.\n\n        Example output when both show_module and show_offset are True:\n            \"start_thread+0x202 [libpthread-2.24.so]\"\n\n        Example output when both show_module and show_offset are False:\n            \"start_thread\"\n        \"\"\"\n\n        #addr is of type stacktrace_build_id\n        #so invoke the bsym address resolver\n        typeofaddr = str(type(addr))\n        if typeofaddr.find('bpf_stack_build_id') != -1:\n          sym = bcc_symbol()\n          b = bcc_stacktrace_build_id()\n          b.status = addr.status\n          b.build_id = addr.build_id\n          b.u.offset = addr.offset;\n          res = lib.bcc_buildsymcache_resolve(BPF._bsymcache,\n                                              ct.byref(b),\n                                              ct.byref(sym))\n          if res < 0:\n            if sym.module and sym.offset:\n              name,offset,module = (None, sym.offset,\n                        ct.cast(sym.module, ct.c_char_p).value)\n            else:\n              name, offset, module = (None, addr, None)\n          else:\n            name, offset, module = (sym.name, sym.offset,\n                                    ct.cast(sym.module, ct.c_char_p).value)\n        else:\n          name, offset, module = BPF._sym_cache(pid).resolve(addr, demangle)\n\n        offset = b\"+0x%x\" % offset if show_offset and name is not None else b\"\"\n        name = name or b\"[unknown]\"\n        name = name + offset\n        module = b\" [%s]\" % os.path.basename(module) \\\n            if show_module and module is not None else b\"\"\n        return name + module",
  "def ksym(addr, show_module=False, show_offset=False):\n        \"\"\"ksym(addr)\n\n        Translate a kernel memory address into a kernel function name, which is\n        returned. When show_module is True, the module name (\"kernel\") is also\n        included. When show_offset is true, the instruction offset as a\n        hexadecimal number is also included in the string.\n\n        Example output when both show_module and show_offset are True:\n            \"default_idle+0x0 [kernel]\"\n        \"\"\"\n        return BPF.sym(addr, -1, show_module, show_offset, False)",
  "def ksymname(name):\n        \"\"\"ksymname(name)\n\n        Translate a kernel name into an address. This is the reverse of\n        ksym. Returns -1 when the function name is unknown.\"\"\"\n        return BPF._sym_cache(-1).resolve_name(None, name)",
  "def num_open_kprobes(self):\n        \"\"\"num_open_kprobes()\n\n        Get the number of open K[ret]probes. Can be useful for scenarios where\n        event_re is used while attaching and detaching probes.\n        \"\"\"\n        return len(self.kprobe_fds)",
  "def num_open_uprobes(self):\n        \"\"\"num_open_uprobes()\n\n        Get the number of open U[ret]probes.\n        \"\"\"\n        return len(self.uprobe_fds)",
  "def num_open_tracepoints(self):\n        \"\"\"num_open_tracepoints()\n\n        Get the number of open tracepoints.\n        \"\"\"\n        return len(self.tracepoint_fds)",
  "def perf_buffer_poll(self, timeout = -1):\n        \"\"\"perf_buffer_poll(self)\n\n        Poll from all open perf ring buffers, calling the callback that was\n        provided when calling open_perf_buffer for each entry.\n        \"\"\"\n        readers = (ct.c_void_p * len(self.perf_buffers))()\n        for i, v in enumerate(self.perf_buffers.values()):\n            readers[i] = v\n        lib.perf_reader_poll(len(readers), readers, timeout)",
  "def kprobe_poll(self, timeout = -1):\n        \"\"\"kprobe_poll(self)\n\n        Deprecated. Use perf_buffer_poll instead.\n        \"\"\"\n        self.perf_buffer_poll(timeout)",
  "def free_bcc_memory(self):\n        return lib.bcc_free_memory()",
  "def add_module(modname):\n      \"\"\"add_module(modname)\n\n        Add a library or exe to buildsym cache\n      \"\"\"\n      try:\n        lib.bcc_buildsymcache_add_module(BPF._bsymcache, modname.encode())\n      except Exception as e:\n        print(\"Error adding module to build sym cache\"+str(e))",
  "def donothing(self):\n        \"\"\"the do nothing exit handler\"\"\"",
  "def cleanup(self):\n        # Clean up opened probes\n        for k, v in list(self.kprobe_fds.items()):\n            self.detach_kprobe_event(k)\n        for k, v in list(self.uprobe_fds.items()):\n            self.detach_uprobe_event(k)\n        for k, v in list(self.tracepoint_fds.items()):\n            self.detach_tracepoint(k)\n        for k, v in list(self.raw_tracepoint_fds.items()):\n            self.detach_raw_tracepoint(k)\n\n        # Clean up opened perf ring buffer and perf events\n        table_keys = list(self.tables.keys())\n        for key in table_keys:\n            if isinstance(self.tables[key], PerfEventArray):\n                del self.tables[key]\n        for (ev_type, ev_config) in list(self.open_perf_events.keys()):\n            self.detach_perf_event(ev_type, ev_config)\n        if self.tracefile:\n            self.tracefile.close()\n            self.tracefile = None\n        if self.module:\n            lib.bpf_module_destroy(self.module)\n            self.module = None",
  "def __enter__(self):\n        return self",
  "def __exit__(self, exc_type, exc_val, exc_tb):\n        self.cleanup()",
  "def __init__(self, bpf, name, fd):\n            self.bpf = bpf\n            self.name = name\n            self.fd = fd",
  "def is_exe(fpath):\n            return os.path.isfile(fpath) and \\\n                os.access(fpath, os.X_OK)",
  "def sym_cb(sym_name, addr):\n            dname = sym_name\n            if re.match(sym_re, dname):\n                addresses.append((dname, addr))\n            return 0",
  "class Perf(object):\n        class perf_event_attr(ct.Structure):\n                _fields_ = [\n                        ('type', ct.c_uint),\n                        ('size', ct.c_uint),\n                        ('config', ct.c_ulong),\n                        ('sample_period', ct.c_ulong),\n                        ('sample_type', ct.c_ulong),\n                        ('read_format', ct.c_ulong),\n                        ('flags', ct.c_ulong),\n                        ('wakeup_events', ct.c_uint),\n                        ('IGNORE3', ct.c_uint),\n                        ('IGNORE4', ct.c_ulong),\n                        ('IGNORE5', ct.c_ulong),\n                        ('IGNORE6', ct.c_ulong),\n                        ('IGNORE7', ct.c_uint),\n                        ('IGNORE8', ct.c_int),\n                        ('IGNORE9', ct.c_ulong),\n                        ('IGNORE10', ct.c_uint),\n                        ('IGNORE11', ct.c_uint)\n                ]\n\n        # x86 specific, from arch/x86/include/generated/uapi/asm/unistd_64.h\n        NR_PERF_EVENT_OPEN = 298\n\n        #\n        # Selected constants from include/uapi/linux/perf_event.h.\n        # Values copied during Linux 4.7 series.\n        #\n\n        # perf_type_id\n        PERF_TYPE_HARDWARE = 0\n        PERF_TYPE_SOFTWARE = 1\n        PERF_TYPE_TRACEPOINT = 2\n        PERF_TYPE_HW_CACHE = 3\n\n        # perf_event_sample_format\n        PERF_SAMPLE_RAW = 1024      # it's a u32; could also try zero args\n\n        # perf_event_attr\n        PERF_ATTR_FLAG_FREQ = 1024\n\n        # perf_event.h\n        PERF_FLAG_FD_CLOEXEC = 8\n        PERF_EVENT_IOC_SET_FILTER = 1074275334\n        PERF_EVENT_IOC_ENABLE = 9216\n\n        # fetch syscall routines\n        libc = ct.CDLL('libc.so.6', use_errno=True)\n        syscall = libc.syscall          # not declaring vararg types\n        ioctl = libc.ioctl              # not declaring vararg types\n\n        @staticmethod\n        def _open_for_cpu(cpu, attr):\n                pfd = Perf.syscall(Perf.NR_PERF_EVENT_OPEN, ct.byref(attr),\n                                   attr.pid, cpu, -1,\n                                   Perf.PERF_FLAG_FD_CLOEXEC)\n                if pfd < 0:\n                        errno_ = ct.get_errno()\n                        raise OSError(errno_, os.strerror(errno_))\n\n                if attr.type == Perf.PERF_TYPE_TRACEPOINT:\n                    if Perf.ioctl(pfd, Perf.PERF_EVENT_IOC_SET_FILTER,\n                                  \"common_pid == -17\") < 0:\n                            errno_ = ct.get_errno()\n                            raise OSError(errno_, os.strerror(errno_))\n\n                # we don't setup the perf ring buffers, as we won't read them\n\n                if Perf.ioctl(pfd, Perf.PERF_EVENT_IOC_ENABLE, 0) < 0:\n                        errno_ = ct.get_errno()\n                        raise OSError(errno_, os.strerror(errno_))\n\n        @staticmethod\n        def perf_event_open(tpoint_id, pid=-1, ptype=PERF_TYPE_TRACEPOINT,\n                            freq=0):\n                attr = Perf.perf_event_attr()\n                attr.config = tpoint_id\n                attr.pid = pid\n                attr.type = ptype\n                attr.sample_type = Perf.PERF_SAMPLE_RAW\n                if freq > 0:\n                    # setup sampling\n                    attr.flags = Perf.PERF_ATTR_FLAG_FREQ   # no mmap or comm\n                    attr.sample_period = freq\n                else:\n                    attr.sample_period = 1\n                attr.wakeup_events = 9999999                # don't wake up\n\n                for cpu in get_online_cpus():\n                        Perf._open_for_cpu(cpu, attr)",
  "class perf_event_attr(ct.Structure):\n                _fields_ = [\n                        ('type', ct.c_uint),\n                        ('size', ct.c_uint),\n                        ('config', ct.c_ulong),\n                        ('sample_period', ct.c_ulong),\n                        ('sample_type', ct.c_ulong),\n                        ('read_format', ct.c_ulong),\n                        ('flags', ct.c_ulong),\n                        ('wakeup_events', ct.c_uint),\n                        ('IGNORE3', ct.c_uint),\n                        ('IGNORE4', ct.c_ulong),\n                        ('IGNORE5', ct.c_ulong),\n                        ('IGNORE6', ct.c_ulong),\n                        ('IGNORE7', ct.c_uint),\n                        ('IGNORE8', ct.c_int),\n                        ('IGNORE9', ct.c_ulong),\n                        ('IGNORE10', ct.c_uint),\n                        ('IGNORE11', ct.c_uint)\n                ]",
  "def _open_for_cpu(cpu, attr):\n                pfd = Perf.syscall(Perf.NR_PERF_EVENT_OPEN, ct.byref(attr),\n                                   attr.pid, cpu, -1,\n                                   Perf.PERF_FLAG_FD_CLOEXEC)\n                if pfd < 0:\n                        errno_ = ct.get_errno()\n                        raise OSError(errno_, os.strerror(errno_))\n\n                if attr.type == Perf.PERF_TYPE_TRACEPOINT:\n                    if Perf.ioctl(pfd, Perf.PERF_EVENT_IOC_SET_FILTER,\n                                  \"common_pid == -17\") < 0:\n                            errno_ = ct.get_errno()\n                            raise OSError(errno_, os.strerror(errno_))\n\n                # we don't setup the perf ring buffers, as we won't read them\n\n                if Perf.ioctl(pfd, Perf.PERF_EVENT_IOC_ENABLE, 0) < 0:\n                        errno_ = ct.get_errno()\n                        raise OSError(errno_, os.strerror(errno_))",
  "def perf_event_open(tpoint_id, pid=-1, ptype=PERF_TYPE_TRACEPOINT,\n                            freq=0):\n                attr = Perf.perf_event_attr()\n                attr.config = tpoint_id\n                attr.pid = pid\n                attr.type = ptype\n                attr.sample_type = Perf.PERF_SAMPLE_RAW\n                if freq > 0:\n                    # setup sampling\n                    attr.flags = Perf.PERF_ATTR_FLAG_FREQ   # no mmap or comm\n                    attr.sample_period = freq\n                else:\n                    attr.sample_period = 1\n                attr.wakeup_events = 9999999                # don't wake up\n\n                for cpu in get_online_cpus():\n                        Perf._open_for_cpu(cpu, attr)",
  "class USDTException(Exception):\n    pass",
  "class USDTProbeArgument(object):\n    def __init__(self, argument):\n        self.signed = argument.size < 0\n        self.size = abs(argument.size)\n        self.valid = argument.valid\n        if self.valid & BCC_USDT_ARGUMENT_FLAGS.CONSTANT != 0:\n            self.constant = argument.constant\n        if self.valid & BCC_USDT_ARGUMENT_FLAGS.DEREF_OFFSET != 0:\n            self.deref_offset = argument.deref_offset\n        if self.valid & BCC_USDT_ARGUMENT_FLAGS.DEREF_IDENT != 0:\n            self.deref_ident = argument.deref_ident\n        if self.valid & BCC_USDT_ARGUMENT_FLAGS.BASE_REGISTER_NAME != 0:\n            self.base_register_name = argument.base_register_name\n        if self.valid & BCC_USDT_ARGUMENT_FLAGS.INDEX_REGISTER_NAME != 0:\n            self.index_register_name = argument.index_register_name\n        if self.valid & BCC_USDT_ARGUMENT_FLAGS.SCALE != 0:\n            self.scale = argument.scale\n\n    def _size_prefix(self):\n        return \"%d %s bytes\" % \\\n                (self.size, \"signed  \" if self.signed else \"unsigned\")\n\n    def _format(self):\n        # This mimics the logic in cc/usdt_args.cc that gives meaning to the\n        # various argument settings. A change there will require a change here.\n        if self.valid & BCC_USDT_ARGUMENT_FLAGS.CONSTANT != 0:\n            return \"%d\" % self.constant\n        if self.valid & BCC_USDT_ARGUMENT_FLAGS.DEREF_OFFSET == 0:\n            return \"%s\" % self.base_register_name\n        if self.valid & BCC_USDT_ARGUMENT_FLAGS.DEREF_OFFSET != 0 and \\\n           self.valid & BCC_USDT_ARGUMENT_FLAGS.DEREF_IDENT == 0:\n            if self.valid & BCC_USDT_ARGUMENT_FLAGS.INDEX_REGISTER_NAME != 0:\n                index_offset = \" + %s\" % self.index_register_name\n                if self.valid & BCC_USDT_ARGUMENT_FLAGS.SCALE != 0:\n                    index_offset += \" * %d\" % self.scale\n            else:\n                index_offset = \"\"\n            sign = '+' if self.deref_offset >= 0 else '-'\n            return \"*(%s %s %d%s)\" % (self.base_register_name,\n                                    sign, abs(self.deref_offset), index_offset)\n        if self.valid & BCC_USDT_ARGUMENT_FLAGS.DEREF_OFFSET != 0 and \\\n           self.valid & BCC_USDT_ARGUMENT_FLAGS.DEREF_IDENT != 0 and \\\n           self.valid & BCC_USDT_ARGUMENT_FLAGS.BASE_REGISTER_NAME != 0 and \\\n           self.base_register_name == \"ip\":\n            sign = '+' if self.deref_offset >= 0 else '-'\n            return \"*(&%s %s %d)\" % (self.deref_ident,\n                                     sign, abs(self.deref_offset))\n        # If we got here, this is an unrecognized case. Doesn't mean it's\n        # necessarily bad, so just provide the raw data. It just means that\n        # other tools won't be able to work with this argument.\n        return \"unrecognized argument format, flags %d\" % self.valid\n\n    def __str__(self):\n        return \"%s @ %s\" % (self._size_prefix(), self._format())",
  "class USDTProbeLocation(object):\n    def __init__(self, probe, index, location):\n        self.probe = probe\n        self.index = index\n        self.num_arguments = probe.num_arguments\n        self.address = location.address\n        self.bin_path = location.bin_path\n\n    def __str__(self):\n        return \"%s 0x%x\" % (self.bin_path, self.address)\n\n    def get_argument(self, index):\n        arg = bcc_usdt_argument()\n        res = lib.bcc_usdt_get_argument(self.probe.context, self.probe.provider,\n                                        self.probe.name,\n                                        self.index, index, ct.byref(arg))\n        if res != 0:\n            raise USDTException(\n                    \"error retrieving probe argument %d location %d\" %\n                    (index, self.index))\n        return USDTProbeArgument(arg)",
  "class USDTProbe(object):\n    def __init__(self, context, probe):\n        self.context = context\n        self.provider = probe.provider\n        self.name = probe.name\n        self.bin_path = probe.bin_path\n        self.semaphore = probe.semaphore\n        self.num_locations = probe.num_locations\n        self.num_arguments = probe.num_arguments\n\n    def __str__(self):\n        return \"%s:%s [sema 0x%x]\" % \\\n               (self.provider, self.name, self.semaphore)\n\n    def short_name(self):\n        return \"%s:%s\" % (self.provider, self.name)\n\n    def get_location(self, index):\n        loc = bcc_usdt_location()\n        res = lib.bcc_usdt_get_location(self.context, self.provider, self.name,\n                                        index, ct.byref(loc))\n        if res != 0:\n            raise USDTException(\"error retrieving probe location %d\" % index)\n        return USDTProbeLocation(self, index, loc)",
  "class USDT(object):\n    def __init__(self, pid=None, path=None):\n        if pid and pid != -1:\n            self.pid = pid\n            if path:\n                self.context = lib.bcc_usdt_new_frompid(pid, path.encode('ascii'))\n            else:\n                self.context = lib.bcc_usdt_new_frompid(pid, ct.c_char_p(0))\n            if self.context == None:\n                raise USDTException(\"USDT failed to instrument PID %d\" % pid)\n        elif path:\n            self.path = path\n            self.context = lib.bcc_usdt_new_frompath(path.encode('ascii'))\n            if self.context == None:\n                raise USDTException(\"USDT failed to instrument path %s\" % path)\n        else:\n            raise USDTException(\n                    \"either a pid or a binary path must be specified\")\n\n    def __del__(self):\n        lib.bcc_usdt_close(self.context)\n\n    def enable_probe(self, probe, fn_name):\n        if lib.bcc_usdt_enable_probe(self.context, probe.encode('ascii'),\n                fn_name.encode('ascii')) != 0:\n            raise USDTException(\n                    (\"failed to enable probe '%s'; a possible cause \" +\n                     \"can be that the probe requires a pid to enable\") %\n                     probe\n                  )\n\n    def enable_probe_or_bail(self, probe, fn_name):\n        if lib.bcc_usdt_enable_probe(self.context, probe.encode('ascii'),\n                fn_name.encode('ascii')) != 0:\n            print(\n\"\"\"Error attaching USDT probes: the specified pid might not contain the\ngiven language's runtime, or the runtime was not built with the required\nUSDT probes. Look for a configure flag similar to --with-dtrace or\n--enable-dtrace. To check which probes are present in the process, use the\ntplist tool.\"\"\")\n            sys.exit(1)\n\n    def get_context(self):\n        return self.context\n\n    def get_text(self):\n        ctx_array = (ct.c_void_p * 1)()\n        ctx_array[0] = ct.c_void_p(self.context)\n        return lib.bcc_usdt_genargs(ctx_array, 1).decode()\n\n    def get_probe_arg_ctype(self, probe_name, arg_index):\n        return lib.bcc_usdt_get_probe_argctype(\n            self.context, probe_name.encode('ascii'), arg_index).decode()\n\n    def enumerate_probes(self):\n        probes = []\n        def _add_probe(probe):\n            probes.append(USDTProbe(self.context, probe.contents))\n\n        lib.bcc_usdt_foreach(self.context, _USDT_CB(_add_probe))\n        return probes\n\n    # This is called by the BPF module's __init__ when it realizes that there\n    # is a USDT context and probes need to be attached.\n    def attach_uprobes(self, bpf):\n        probes = self.enumerate_active_probes()\n        for (binpath, fn_name, addr, pid) in probes:\n            bpf.attach_uprobe(name=binpath.decode(), fn_name=fn_name.decode(),\n                              addr=addr, pid=pid)\n\n    def enumerate_active_probes(self):\n        probes = []\n        def _add_probe(binpath, fn_name, addr, pid):\n            probes.append((binpath, fn_name, addr, pid))\n\n        lib.bcc_usdt_foreach_uprobe(self.context, _USDT_PROBE_CB(_add_probe))\n        return probes",
  "def __init__(self, argument):\n        self.signed = argument.size < 0\n        self.size = abs(argument.size)\n        self.valid = argument.valid\n        if self.valid & BCC_USDT_ARGUMENT_FLAGS.CONSTANT != 0:\n            self.constant = argument.constant\n        if self.valid & BCC_USDT_ARGUMENT_FLAGS.DEREF_OFFSET != 0:\n            self.deref_offset = argument.deref_offset\n        if self.valid & BCC_USDT_ARGUMENT_FLAGS.DEREF_IDENT != 0:\n            self.deref_ident = argument.deref_ident\n        if self.valid & BCC_USDT_ARGUMENT_FLAGS.BASE_REGISTER_NAME != 0:\n            self.base_register_name = argument.base_register_name\n        if self.valid & BCC_USDT_ARGUMENT_FLAGS.INDEX_REGISTER_NAME != 0:\n            self.index_register_name = argument.index_register_name\n        if self.valid & BCC_USDT_ARGUMENT_FLAGS.SCALE != 0:\n            self.scale = argument.scale",
  "def _size_prefix(self):\n        return \"%d %s bytes\" % \\\n                (self.size, \"signed  \" if self.signed else \"unsigned\")",
  "def _format(self):\n        # This mimics the logic in cc/usdt_args.cc that gives meaning to the\n        # various argument settings. A change there will require a change here.\n        if self.valid & BCC_USDT_ARGUMENT_FLAGS.CONSTANT != 0:\n            return \"%d\" % self.constant\n        if self.valid & BCC_USDT_ARGUMENT_FLAGS.DEREF_OFFSET == 0:\n            return \"%s\" % self.base_register_name\n        if self.valid & BCC_USDT_ARGUMENT_FLAGS.DEREF_OFFSET != 0 and \\\n           self.valid & BCC_USDT_ARGUMENT_FLAGS.DEREF_IDENT == 0:\n            if self.valid & BCC_USDT_ARGUMENT_FLAGS.INDEX_REGISTER_NAME != 0:\n                index_offset = \" + %s\" % self.index_register_name\n                if self.valid & BCC_USDT_ARGUMENT_FLAGS.SCALE != 0:\n                    index_offset += \" * %d\" % self.scale\n            else:\n                index_offset = \"\"\n            sign = '+' if self.deref_offset >= 0 else '-'\n            return \"*(%s %s %d%s)\" % (self.base_register_name,\n                                    sign, abs(self.deref_offset), index_offset)\n        if self.valid & BCC_USDT_ARGUMENT_FLAGS.DEREF_OFFSET != 0 and \\\n           self.valid & BCC_USDT_ARGUMENT_FLAGS.DEREF_IDENT != 0 and \\\n           self.valid & BCC_USDT_ARGUMENT_FLAGS.BASE_REGISTER_NAME != 0 and \\\n           self.base_register_name == \"ip\":\n            sign = '+' if self.deref_offset >= 0 else '-'\n            return \"*(&%s %s %d)\" % (self.deref_ident,\n                                     sign, abs(self.deref_offset))\n        # If we got here, this is an unrecognized case. Doesn't mean it's\n        # necessarily bad, so just provide the raw data. It just means that\n        # other tools won't be able to work with this argument.\n        return \"unrecognized argument format, flags %d\" % self.valid",
  "def __str__(self):\n        return \"%s @ %s\" % (self._size_prefix(), self._format())",
  "def __init__(self, probe, index, location):\n        self.probe = probe\n        self.index = index\n        self.num_arguments = probe.num_arguments\n        self.address = location.address\n        self.bin_path = location.bin_path",
  "def __str__(self):\n        return \"%s 0x%x\" % (self.bin_path, self.address)",
  "def get_argument(self, index):\n        arg = bcc_usdt_argument()\n        res = lib.bcc_usdt_get_argument(self.probe.context, self.probe.provider,\n                                        self.probe.name,\n                                        self.index, index, ct.byref(arg))\n        if res != 0:\n            raise USDTException(\n                    \"error retrieving probe argument %d location %d\" %\n                    (index, self.index))\n        return USDTProbeArgument(arg)",
  "def __init__(self, context, probe):\n        self.context = context\n        self.provider = probe.provider\n        self.name = probe.name\n        self.bin_path = probe.bin_path\n        self.semaphore = probe.semaphore\n        self.num_locations = probe.num_locations\n        self.num_arguments = probe.num_arguments",
  "def __str__(self):\n        return \"%s:%s [sema 0x%x]\" % \\\n               (self.provider, self.name, self.semaphore)",
  "def short_name(self):\n        return \"%s:%s\" % (self.provider, self.name)",
  "def get_location(self, index):\n        loc = bcc_usdt_location()\n        res = lib.bcc_usdt_get_location(self.context, self.provider, self.name,\n                                        index, ct.byref(loc))\n        if res != 0:\n            raise USDTException(\"error retrieving probe location %d\" % index)\n        return USDTProbeLocation(self, index, loc)",
  "def __init__(self, pid=None, path=None):\n        if pid and pid != -1:\n            self.pid = pid\n            if path:\n                self.context = lib.bcc_usdt_new_frompid(pid, path.encode('ascii'))\n            else:\n                self.context = lib.bcc_usdt_new_frompid(pid, ct.c_char_p(0))\n            if self.context == None:\n                raise USDTException(\"USDT failed to instrument PID %d\" % pid)\n        elif path:\n            self.path = path\n            self.context = lib.bcc_usdt_new_frompath(path.encode('ascii'))\n            if self.context == None:\n                raise USDTException(\"USDT failed to instrument path %s\" % path)\n        else:\n            raise USDTException(\n                    \"either a pid or a binary path must be specified\")",
  "def __del__(self):\n        lib.bcc_usdt_close(self.context)",
  "def enable_probe(self, probe, fn_name):\n        if lib.bcc_usdt_enable_probe(self.context, probe.encode('ascii'),\n                fn_name.encode('ascii')) != 0:\n            raise USDTException(\n                    (\"failed to enable probe '%s'; a possible cause \" +\n                     \"can be that the probe requires a pid to enable\") %\n                     probe\n                  )",
  "def enable_probe_or_bail(self, probe, fn_name):\n        if lib.bcc_usdt_enable_probe(self.context, probe.encode('ascii'),\n                fn_name.encode('ascii')) != 0:\n            print(\n\"\"\"Error attaching USDT probes: the specified pid might not contain the\ngiven language's runtime, or the runtime was not built with the required\nUSDT probes. Look for a configure flag similar to --with-dtrace or\n--enable-dtrace. To check which probes are present in the process, use the\ntplist tool.\"\"\")\n            sys.exit(1)",
  "def get_context(self):\n        return self.context",
  "def get_text(self):\n        ctx_array = (ct.c_void_p * 1)()\n        ctx_array[0] = ct.c_void_p(self.context)\n        return lib.bcc_usdt_genargs(ctx_array, 1).decode()",
  "def get_probe_arg_ctype(self, probe_name, arg_index):\n        return lib.bcc_usdt_get_probe_argctype(\n            self.context, probe_name.encode('ascii'), arg_index).decode()",
  "def enumerate_probes(self):\n        probes = []\n        def _add_probe(probe):\n            probes.append(USDTProbe(self.context, probe.contents))\n\n        lib.bcc_usdt_foreach(self.context, _USDT_CB(_add_probe))\n        return probes",
  "def attach_uprobes(self, bpf):\n        probes = self.enumerate_active_probes()\n        for (binpath, fn_name, addr, pid) in probes:\n            bpf.attach_uprobe(name=binpath.decode(), fn_name=fn_name.decode(),\n                              addr=addr, pid=pid)",
  "def enumerate_active_probes(self):\n        probes = []\n        def _add_probe(binpath, fn_name, addr, pid):\n            probes.append((binpath, fn_name, addr, pid))\n\n        lib.bcc_usdt_foreach_uprobe(self.context, _USDT_PROBE_CB(_add_probe))\n        return probes",
  "def _add_probe(probe):\n            probes.append(USDTProbe(self.context, probe.contents))",
  "def _add_probe(binpath, fn_name, addr, pid):\n            probes.append((binpath, fn_name, addr, pid))",
  "def flags2str(flags):\n    arr = [];\n    if flags & TCPHDR_FIN:\n        arr.append(\"FIN\");\n    if flags & TCPHDR_SYN:\n        arr.append(\"SYN\");\n    if flags & TCPHDR_RST:\n        arr.append(\"RST\");\n    if flags & TCPHDR_PSH:\n        arr.append(\"PSH\");\n    if flags & TCPHDR_ACK:\n        arr.append(\"ACK\");\n    if flags & TCPHDR_URG:\n        arr.append(\"URG\");\n    if flags & TCPHDR_ECE:\n        arr.append(\"ECE\");\n    if flags & TCPHDR_CWR:\n        arr.append(\"CWR\");\n    return \"|\".join(arr);",
  "class EbpfType(object):\n    __doc__ = \"Base class for representing a P4 type\"\n\n    def __init__(self, hlirType):\n        self.hlirType = hlirType\n\n    # Methods to override\n\n    def serialize(self, serializer):\n        # the type itself\n        raise CompilationException(True, \"Method must be overridden\")\n\n    def declare(self, serializer, identifier, asPointer):\n        # declaration of an identifier with this type\n        # asPointer is a boolean;\n        # if true, the identifier is declared as a pointer\n        raise CompilationException(True, \"Method must be overridden\")\n\n    def emitInitializer(self, serializer):\n        # A default initializer suitable for this type\n        raise CompilationException(True, \"Method must be overridden\")\n\n    def declareArray(self, serializer, identifier, size):\n        # Declare an identifier with an array type with the specified size\n        raise CompilationException(True, \"Method must be overridden\")",
  "def __init__(self, hlirType):\n        self.hlirType = hlirType",
  "def serialize(self, serializer):\n        # the type itself\n        raise CompilationException(True, \"Method must be overridden\")",
  "def declare(self, serializer, identifier, asPointer):\n        # declaration of an identifier with this type\n        # asPointer is a boolean;\n        # if true, the identifier is declared as a pointer\n        raise CompilationException(True, \"Method must be overridden\")",
  "def emitInitializer(self, serializer):\n        # A default initializer suitable for this type\n        raise CompilationException(True, \"Method must be overridden\")",
  "def declareArray(self, serializer, identifier, size):\n        # Declare an identifier with an array type with the specified size\n        raise CompilationException(True, \"Method must be overridden\")",
  "class EbpfTypeFactory(object):\n    def __init__(self, config):\n        self.type_map = {}\n        self.config = config\n\n    def build(self, hlirType, asMetadata):\n        name = hlirType.name\n        if hlirType.name in self.type_map:\n            retval = self.type_map[name]\n            if ((not asMetadata and isinstance(retval, EbpfMetadataType)) or\n                (asMetadata and isinstance(retval, EbpfHeaderType))):\n                raise CompilationException(\n                    True, \"Same type used both as a header and metadata {0}\",\n                    hlirType)\n\n        if isinstance(hlirType, p4_header):\n            if asMetadata:\n                type = EbpfMetadataType(hlirType, self.config)\n            else:\n                type = EbpfHeaderType(hlirType, self.config)\n        else:\n            raise CompilationException(True, \"Unexpected type {0}\", hlirType)\n        self.registerType(name, type)\n        return type\n\n    def registerType(self, name, ebpfType):\n        self.type_map[name] = ebpfType",
  "def __init__(self, config):\n        self.type_map = {}\n        self.config = config",
  "def build(self, hlirType, asMetadata):\n        name = hlirType.name\n        if hlirType.name in self.type_map:\n            retval = self.type_map[name]\n            if ((not asMetadata and isinstance(retval, EbpfMetadataType)) or\n                (asMetadata and isinstance(retval, EbpfHeaderType))):\n                raise CompilationException(\n                    True, \"Same type used both as a header and metadata {0}\",\n                    hlirType)\n\n        if isinstance(hlirType, p4_header):\n            if asMetadata:\n                type = EbpfMetadataType(hlirType, self.config)\n            else:\n                type = EbpfHeaderType(hlirType, self.config)\n        else:\n            raise CompilationException(True, \"Unexpected type {0}\", hlirType)\n        self.registerType(name, type)\n        return type",
  "def registerType(self, name, ebpfType):\n        self.type_map[name] = ebpfType",
  "class EbpfParser(object):\n    def __init__(self, hlirParser):  # hlirParser is a P4 parser\n        self.parser = hlirParser\n        self.name = hlirParser.name\n\n    def serialize(self, serializer, program):\n        assert isinstance(serializer, programSerializer.ProgramSerializer)\n        assert isinstance(program, ebpfProgram.EbpfProgram)\n\n        serializer.emitIndent()\n        serializer.appendFormat(\"{0}: \", self.name)\n        serializer.blockStart()\n        for op in self.parser.call_sequence:\n            self.serializeOperation(serializer, op, program)\n\n        self.serializeBranch(serializer, self.parser.branch_on,\n                             self.parser.branch_to, program)\n\n        serializer.blockEnd(True)\n\n    def serializeSelect(self, selectVarName, serializer, branch_on, program):\n        # selectVarName - name of temp variable to use for the select expression\n        assert isinstance(selectVarName, str)\n        assert isinstance(serializer, programSerializer.ProgramSerializer)\n        assert isinstance(program, ebpfProgram.EbpfProgram)\n\n        totalWidth = 0\n        switchValue = \"\"\n        for e in branch_on:\n            if isinstance(e, p4_field):\n                instance = e.instance\n                assert isinstance(instance, p4_header_instance)\n                index = \"\"\n\n                if ebpfProgram.EbpfProgram.isArrayElementInstance(instance):\n                    ebpfStack = program.getStackInstance(instance.base_name)\n                    assert isinstance(ebpfStack, ebpfInstance.EbpfHeaderStack)\n\n                    if isinstance(instance.index, int):\n                        index = \"[\" + str(instance.index) + \"]\"\n                    elif instance.index is P4_NEXT:\n                        index = \"[\" + ebpfStack.indexVar + \"]\"\n                    else:\n                        raise CompilationException(True,\n                            \"Unexpected index for array {0}\", instance.index)\n                    basetype = ebpfStack.basetype\n                    name = ebpfStack.name\n                else:\n                    ebpfHeader = program.getInstance(instance.name)\n                    assert isinstance(ebpfHeader, ebpfInstance.EbpfHeader)\n                    basetype = ebpfHeader.type\n                    name = ebpfHeader.name\n\n                ebpfField = basetype.getField(e.name)\n                assert isinstance(ebpfField, ebpfStructType.EbpfField)\n\n                totalWidth += ebpfField.widthInBits()\n                fieldReference = (program.headerStructName + \".\" + name +\n                                  index + \".\" + ebpfField.name)\n\n                if switchValue == \"\":\n                    switchValue = fieldReference\n                else:\n                    switchValue = (\"(\" + switchValue + \" << \" +\n                                   str(ebpfField.widthInBits()) + \")\")\n                    switchValue = switchValue + \" | \" + fieldReference\n            elif isinstance(e, tuple):\n                switchValue = self.currentReferenceAsString(e, program)\n            else:\n                raise CompilationException(\n                    True, \"Unexpected element in match {0}\", e)\n\n        if totalWidth > 32:\n            raise NotSupportedException(\"{0}: Matching on {1}-bit value\",\n                                        branch_on, totalWidth)\n        serializer.emitIndent()\n        serializer.appendFormat(\"{0}32 {1} = {2};\",\n                                program.config.uprefix,\n                                selectVarName, switchValue)\n        serializer.newline()\n\n    def generatePacketLoad(self, startBit, width, alignment, program):\n        # Generates an expression that does a load_*, shift and mask\n        # to load 'width' bits starting at startBit from the current\n        # packet offset.\n        # alignment is an integer <= 8 that holds the current alignment\n        # of of the packet offset.\n        assert width > 0\n        assert alignment < 8\n        assert isinstance(startBit, int)\n        assert isinstance(width, int)\n        assert isinstance(alignment, int)\n\n        firstBitIndex = startBit + alignment\n        lastBitIndex = startBit + width + alignment - 1\n        firstWordIndex = firstBitIndex / 8\n        lastWordIndex = lastBitIndex / 8\n\n        wordsToRead = lastWordIndex - firstWordIndex + 1\n        if wordsToRead == 1:\n            load = \"load_byte\"\n            loadSize = 8\n        elif wordsToRead == 2:\n            load = \"load_half\"\n            loadSize = 16\n        elif wordsToRead <= 4:\n            load = \"load_word\"\n            loadSize = 32\n        elif wordsToRead <= 8:\n            load = \"load_dword\"\n            loadSize = 64\n        else:\n            raise CompilationException(True, \"Attempt to load more than 1 word\")\n\n        readtype = program.config.uprefix + str(loadSize)\n        loadInstruction = \"{0}({1}, ({2} + {3}) / 8)\".format(\n            load, program.packetName, program.offsetVariableName, startBit)\n        shift = loadSize - alignment - width\n        load = \"(({0}) >> ({1}))\".format(loadInstruction, shift)\n        if width != loadSize:\n            mask = \" & EBPF_MASK({0}, {1})\".format(readtype, width)\n        else:\n            mask = \"\"\n        return load + mask\n\n    def currentReferenceAsString(self, tpl, program):\n        # a string describing an expression of the form current(position, width)\n        # The assumption is that at this point the packet cursor is ALWAYS\n        # byte aligned.  This should be true because headers are supposed\n        # to have sizes an integral number of bytes.\n        assert isinstance(tpl, tuple)\n        if len(tpl) != 2:\n            raise CompilationException(\n                True, \"{0} Expected a tuple with 2 elements\", tpl)\n\n        minIndex = tpl[0]\n        totalWidth = tpl[1]\n        result = self.generatePacketLoad(\n            minIndex, totalWidth, 0, program) # alignment is 0\n        return result\n\n    def serializeCases(self, selectVarName, serializer, branch_to, program):\n        assert isinstance(selectVarName, str)\n        assert isinstance(serializer, programSerializer.ProgramSerializer)\n        assert isinstance(program, ebpfProgram.EbpfProgram)\n\n        branches = 0\n        seenDefault = False\n        for e in branch_to.keys():\n            serializer.emitIndent()\n            value = branch_to[e]\n\n            if isinstance(e, int):\n                serializer.appendFormat(\"if ({0} == {1})\", selectVarName, e)\n            elif isinstance(e, tuple):\n                serializer.appendFormat(\n                    \"if (({0} & {1}) == {2})\", selectVarName, e[0], e[1])\n            elif isinstance(e, p4_parse_value_set):\n                raise NotSupportedException(\"{0}: Parser value sets\", e)\n            elif e is P4_DEFAULT:\n                seenDefault = True\n                if branches > 0:\n                    serializer.append(\"else\")\n            else:\n                raise CompilationException(\n                    True, \"Unexpected element in match case {0}\", e)\n\n            branches += 1\n            serializer.newline()\n            serializer.increaseIndent()\n            serializer.emitIndent()\n\n            label = program.getLabel(value)\n\n            if isinstance(value, p4_parse_state):\n                serializer.appendFormat(\"goto {0};\", label)\n            elif isinstance(value, p4_table):\n                serializer.appendFormat(\"goto {0};\", label)\n            elif isinstance(value, p4_conditional_node):\n                serializer.appendFormat(\"goto {0};\", label)\n            elif isinstance(value, p4_parser_exception):\n                raise CompilationException(True, \"Not yet implemented\")\n            else:\n                raise CompilationException(\n                    True, \"Unexpected element in match case {0}\", value)\n\n            serializer.decreaseIndent()\n            serializer.newline()\n\n        # Must create default if it is missing\n        if not seenDefault:\n            serializer.emitIndent()\n            serializer.appendFormat(\n                \"{0} = p4_pe_unhandled_select;\", program.errorName)\n            serializer.newline()\n            serializer.emitIndent()\n            serializer.appendFormat(\"default: goto end;\")\n            serializer.newline()\n\n    def serializeBranch(self, serializer, branch_on, branch_to, program):\n        assert isinstance(serializer, programSerializer.ProgramSerializer)\n        assert isinstance(program, ebpfProgram.EbpfProgram)\n\n        if branch_on == []:\n            dest = branch_to.values()[0]\n            serializer.emitIndent()\n            name = program.getLabel(dest)\n            serializer.appendFormat(\"goto {0};\", name)\n            serializer.newline()\n        elif isinstance(branch_on, list):\n            tmpvar = program.generateNewName(\"tmp\")\n            self.serializeSelect(tmpvar, serializer, branch_on, program)\n            self.serializeCases(tmpvar, serializer, branch_to, program)\n        else:\n            raise CompilationException(\n                True, \"Unexpected branch_on {0}\", branch_on)\n\n    def serializeOperation(self, serializer, op, program):\n        assert isinstance(serializer, programSerializer.ProgramSerializer)\n        assert isinstance(program, ebpfProgram.EbpfProgram)\n\n        operation = op[0]\n        if operation is parse_call.extract:\n            self.serializeExtract(serializer, op[1], program)\n        elif operation is parse_call.set:\n            self.serializeMetadataSet(serializer, op[1], op[2], program)\n        else:\n            raise CompilationException(\n                True, \"Unexpected operation in parser {0}\", op)\n\n    def serializeFieldExtract(self, serializer, headerInstanceName,\n                              index, field, alignment, program):\n        assert isinstance(index, str)\n        assert isinstance(headerInstanceName, str)\n        assert isinstance(field, ebpfStructType.EbpfField)\n        assert isinstance(serializer, programSerializer.ProgramSerializer)\n        assert isinstance(alignment, int)\n        assert isinstance(program, ebpfProgram.EbpfProgram)\n\n        fieldToExtractTo = headerInstanceName + index + \".\" + field.name\n\n        serializer.emitIndent()\n        width = field.widthInBits()\n        if field.name == \"valid\":\n            serializer.appendFormat(\n                \"{0}.{1} = 1;\", program.headerStructName, fieldToExtractTo)\n            serializer.newline()\n            return\n\n        serializer.appendFormat(\"if ({0}->len < BYTES({1} + {2})) \",\n                                program.packetName,\n                                program.offsetVariableName, width)\n        serializer.blockStart()\n        serializer.emitIndent()\n        serializer.appendFormat(\"{0} = p4_pe_header_too_short;\",\n                                program.errorName)\n        serializer.newline()\n        serializer.emitIndent()\n        serializer.appendLine(\"goto end;\")\n        # TODO: jump to correct exception handler\n        serializer.blockEnd(True)\n\n        if width <= 32:\n            serializer.emitIndent()\n            load = self.generatePacketLoad(0, width, alignment, program)\n\n            serializer.appendFormat(\"{0}.{1} = {2};\",\n                                    program.headerStructName,\n                                    fieldToExtractTo, load)\n            serializer.newline()\n        else:\n            # Destination is bigger than 4 bytes and\n            # represented as a byte array.\n            if alignment == 0:\n                shift = 0\n            else:\n                shift = 8 - alignment\n\n            assert shift >= 0\n            if shift == 0:\n                method = \"load_byte\"\n            else:\n                method = \"load_half\"\n            b = (width + 7) / 8\n            for i in range(0, b):\n                serializer.emitIndent()\n                serializer.appendFormat(\"{0}.{1}[{2}] = ({3}8)\",\n                                        program.headerStructName,\n                                        fieldToExtractTo, i,\n                                        program.config.uprefix)\n                serializer.appendFormat(\"(({0}({1}, ({2} / 8) + {3}) >> {4})\",\n                                        method, program.packetName,\n                                        program.offsetVariableName, i, shift)\n                if (i == b - 1) and (width % 8 != 0):\n                    serializer.appendFormat(\" & EBPF_MASK({0}8, {1})\",\n                                            program.config.uprefix, width % 8)\n                serializer.append(\")\")\n                serializer.endOfStatement(True)\n\n        serializer.emitIndent()\n        serializer.appendFormat(\"{0} += {1};\",\n                                program.offsetVariableName, width)\n        serializer.newline()\n\n    def serializeExtract(self, serializer, headerInstance, program):\n        assert isinstance(serializer, programSerializer.ProgramSerializer)\n        assert isinstance(headerInstance, p4_header_instance)\n        assert isinstance(program, ebpfProgram.EbpfProgram)\n\n        if ebpfProgram.EbpfProgram.isArrayElementInstance(headerInstance):\n            ebpfStack = program.getStackInstance(headerInstance.base_name)\n            assert isinstance(ebpfStack, ebpfInstance.EbpfHeaderStack)\n\n            # write bounds check\n            serializer.emitIndent()\n            serializer.appendFormat(\"if ({0} >= {1}) \",\n                                    ebpfStack.indexVar, ebpfStack.arraySize)\n            serializer.blockStart()\n            serializer.emitIndent()\n            serializer.appendFormat(\"{0} = p4_pe_index_out_of_bounds;\",\n                                    program.errorName)\n            serializer.newline()\n            serializer.emitIndent()\n            serializer.appendLine(\"goto end;\")\n            serializer.blockEnd(True)\n\n            if isinstance(headerInstance.index, int):\n                index = \"[\" + str(headerInstance.index) + \"]\"\n            elif headerInstance.index is P4_NEXT:\n                index = \"[\" + ebpfStack.indexVar + \"]\"\n            else:\n                raise CompilationException(\n                    True, \"Unexpected index for array {0}\",\n                    headerInstance.index)\n            basetype = ebpfStack.basetype\n        else:\n            ebpfHeader = program.getHeaderInstance(headerInstance.name)\n            basetype = ebpfHeader.type\n            index = \"\"\n\n        # extract all fields\n        alignment = 0\n        for field in basetype.fields:\n            assert isinstance(field, ebpfStructType.EbpfField)\n\n            self.serializeFieldExtract(serializer, headerInstance.base_name,\n                                       index, field, alignment, program)\n            alignment += field.widthInBits()\n            alignment = alignment % 8\n\n        if ebpfProgram.EbpfProgram.isArrayElementInstance(headerInstance):\n            # increment stack index\n            ebpfStack = program.getStackInstance(headerInstance.base_name)\n            assert isinstance(ebpfStack, ebpfInstance.EbpfHeaderStack)\n\n            # write bounds check\n            serializer.emitIndent()\n            serializer.appendFormat(\"{0}++;\", ebpfStack.indexVar)\n            serializer.newline()\n\n    def serializeMetadataSet(self, serializer, field, value, program):\n        assert isinstance(serializer, programSerializer.ProgramSerializer)\n        assert isinstance(program, ebpfProgram.EbpfProgram)\n        assert isinstance(field, p4_field)\n\n        dest = program.getInstance(field.instance.name)\n        assert isinstance(dest, ebpfInstance.SimpleInstance)\n        destType = dest.type\n        assert isinstance(destType, ebpfStructType.EbpfStructType)\n        destField = destType.getField(field.name)\n\n        if destField.widthInBits() > 32:\n            useMemcpy = True\n            bytesToCopy = destField.widthInBits() / 8\n            if destField.widthInBits() % 8 != 0:\n                raise CompilationException(\n                    True,\n                    \"{0}: Not implemented: wide field w. sz not multiple of 8\",\n                    field)\n        else:\n            useMemcpy = False\n            bytesToCopy = None # not needed, but compiler is confused\n\n        serializer.emitIndent()\n        destination = \"{0}.{1}.{2}\".format(\n            program.metadataStructName, dest.name, destField.name)\n        if isinstance(value, int):\n            source = str(value)\n            if useMemcpy:\n                raise CompilationException(\n                    True,\n                    \"{0}: Not implemented: copying from wide constant\",\n                    value)\n        elif isinstance(value, tuple):\n            source = self.currentReferenceAsString(value, program)\n        elif isinstance(value, p4_field):\n            source = program.getInstance(value.instance.name)\n            if isinstance(source, ebpfInstance.EbpfMetadata):\n                sourceStruct = program.metadataStructName\n            else:\n                sourceStruct = program.headerStructName\n            source = \"{0}.{1}.{2}\".format(sourceStruct, source.name, value.name)\n        else:\n            raise CompilationException(\n                True, \"Unexpected type for parse_call.set {0}\", value)\n\n        if useMemcpy:\n            serializer.appendFormat(\"memcpy(&{0}, &{1}, {2})\",\n                                    destination, source, bytesToCopy)\n        else:\n            serializer.appendFormat(\"{0} = {1}\", destination, source)\n\n        serializer.endOfStatement(True)",
  "def __init__(self, hlirParser):  # hlirParser is a P4 parser\n        self.parser = hlirParser\n        self.name = hlirParser.name",
  "def serialize(self, serializer, program):\n        assert isinstance(serializer, programSerializer.ProgramSerializer)\n        assert isinstance(program, ebpfProgram.EbpfProgram)\n\n        serializer.emitIndent()\n        serializer.appendFormat(\"{0}: \", self.name)\n        serializer.blockStart()\n        for op in self.parser.call_sequence:\n            self.serializeOperation(serializer, op, program)\n\n        self.serializeBranch(serializer, self.parser.branch_on,\n                             self.parser.branch_to, program)\n\n        serializer.blockEnd(True)",
  "def serializeSelect(self, selectVarName, serializer, branch_on, program):\n        # selectVarName - name of temp variable to use for the select expression\n        assert isinstance(selectVarName, str)\n        assert isinstance(serializer, programSerializer.ProgramSerializer)\n        assert isinstance(program, ebpfProgram.EbpfProgram)\n\n        totalWidth = 0\n        switchValue = \"\"\n        for e in branch_on:\n            if isinstance(e, p4_field):\n                instance = e.instance\n                assert isinstance(instance, p4_header_instance)\n                index = \"\"\n\n                if ebpfProgram.EbpfProgram.isArrayElementInstance(instance):\n                    ebpfStack = program.getStackInstance(instance.base_name)\n                    assert isinstance(ebpfStack, ebpfInstance.EbpfHeaderStack)\n\n                    if isinstance(instance.index, int):\n                        index = \"[\" + str(instance.index) + \"]\"\n                    elif instance.index is P4_NEXT:\n                        index = \"[\" + ebpfStack.indexVar + \"]\"\n                    else:\n                        raise CompilationException(True,\n                            \"Unexpected index for array {0}\", instance.index)\n                    basetype = ebpfStack.basetype\n                    name = ebpfStack.name\n                else:\n                    ebpfHeader = program.getInstance(instance.name)\n                    assert isinstance(ebpfHeader, ebpfInstance.EbpfHeader)\n                    basetype = ebpfHeader.type\n                    name = ebpfHeader.name\n\n                ebpfField = basetype.getField(e.name)\n                assert isinstance(ebpfField, ebpfStructType.EbpfField)\n\n                totalWidth += ebpfField.widthInBits()\n                fieldReference = (program.headerStructName + \".\" + name +\n                                  index + \".\" + ebpfField.name)\n\n                if switchValue == \"\":\n                    switchValue = fieldReference\n                else:\n                    switchValue = (\"(\" + switchValue + \" << \" +\n                                   str(ebpfField.widthInBits()) + \")\")\n                    switchValue = switchValue + \" | \" + fieldReference\n            elif isinstance(e, tuple):\n                switchValue = self.currentReferenceAsString(e, program)\n            else:\n                raise CompilationException(\n                    True, \"Unexpected element in match {0}\", e)\n\n        if totalWidth > 32:\n            raise NotSupportedException(\"{0}: Matching on {1}-bit value\",\n                                        branch_on, totalWidth)\n        serializer.emitIndent()\n        serializer.appendFormat(\"{0}32 {1} = {2};\",\n                                program.config.uprefix,\n                                selectVarName, switchValue)\n        serializer.newline()",
  "def generatePacketLoad(self, startBit, width, alignment, program):\n        # Generates an expression that does a load_*, shift and mask\n        # to load 'width' bits starting at startBit from the current\n        # packet offset.\n        # alignment is an integer <= 8 that holds the current alignment\n        # of of the packet offset.\n        assert width > 0\n        assert alignment < 8\n        assert isinstance(startBit, int)\n        assert isinstance(width, int)\n        assert isinstance(alignment, int)\n\n        firstBitIndex = startBit + alignment\n        lastBitIndex = startBit + width + alignment - 1\n        firstWordIndex = firstBitIndex / 8\n        lastWordIndex = lastBitIndex / 8\n\n        wordsToRead = lastWordIndex - firstWordIndex + 1\n        if wordsToRead == 1:\n            load = \"load_byte\"\n            loadSize = 8\n        elif wordsToRead == 2:\n            load = \"load_half\"\n            loadSize = 16\n        elif wordsToRead <= 4:\n            load = \"load_word\"\n            loadSize = 32\n        elif wordsToRead <= 8:\n            load = \"load_dword\"\n            loadSize = 64\n        else:\n            raise CompilationException(True, \"Attempt to load more than 1 word\")\n\n        readtype = program.config.uprefix + str(loadSize)\n        loadInstruction = \"{0}({1}, ({2} + {3}) / 8)\".format(\n            load, program.packetName, program.offsetVariableName, startBit)\n        shift = loadSize - alignment - width\n        load = \"(({0}) >> ({1}))\".format(loadInstruction, shift)\n        if width != loadSize:\n            mask = \" & EBPF_MASK({0}, {1})\".format(readtype, width)\n        else:\n            mask = \"\"\n        return load + mask",
  "def currentReferenceAsString(self, tpl, program):\n        # a string describing an expression of the form current(position, width)\n        # The assumption is that at this point the packet cursor is ALWAYS\n        # byte aligned.  This should be true because headers are supposed\n        # to have sizes an integral number of bytes.\n        assert isinstance(tpl, tuple)\n        if len(tpl) != 2:\n            raise CompilationException(\n                True, \"{0} Expected a tuple with 2 elements\", tpl)\n\n        minIndex = tpl[0]\n        totalWidth = tpl[1]\n        result = self.generatePacketLoad(\n            minIndex, totalWidth, 0, program) # alignment is 0\n        return result",
  "def serializeCases(self, selectVarName, serializer, branch_to, program):\n        assert isinstance(selectVarName, str)\n        assert isinstance(serializer, programSerializer.ProgramSerializer)\n        assert isinstance(program, ebpfProgram.EbpfProgram)\n\n        branches = 0\n        seenDefault = False\n        for e in branch_to.keys():\n            serializer.emitIndent()\n            value = branch_to[e]\n\n            if isinstance(e, int):\n                serializer.appendFormat(\"if ({0} == {1})\", selectVarName, e)\n            elif isinstance(e, tuple):\n                serializer.appendFormat(\n                    \"if (({0} & {1}) == {2})\", selectVarName, e[0], e[1])\n            elif isinstance(e, p4_parse_value_set):\n                raise NotSupportedException(\"{0}: Parser value sets\", e)\n            elif e is P4_DEFAULT:\n                seenDefault = True\n                if branches > 0:\n                    serializer.append(\"else\")\n            else:\n                raise CompilationException(\n                    True, \"Unexpected element in match case {0}\", e)\n\n            branches += 1\n            serializer.newline()\n            serializer.increaseIndent()\n            serializer.emitIndent()\n\n            label = program.getLabel(value)\n\n            if isinstance(value, p4_parse_state):\n                serializer.appendFormat(\"goto {0};\", label)\n            elif isinstance(value, p4_table):\n                serializer.appendFormat(\"goto {0};\", label)\n            elif isinstance(value, p4_conditional_node):\n                serializer.appendFormat(\"goto {0};\", label)\n            elif isinstance(value, p4_parser_exception):\n                raise CompilationException(True, \"Not yet implemented\")\n            else:\n                raise CompilationException(\n                    True, \"Unexpected element in match case {0}\", value)\n\n            serializer.decreaseIndent()\n            serializer.newline()\n\n        # Must create default if it is missing\n        if not seenDefault:\n            serializer.emitIndent()\n            serializer.appendFormat(\n                \"{0} = p4_pe_unhandled_select;\", program.errorName)\n            serializer.newline()\n            serializer.emitIndent()\n            serializer.appendFormat(\"default: goto end;\")\n            serializer.newline()",
  "def serializeBranch(self, serializer, branch_on, branch_to, program):\n        assert isinstance(serializer, programSerializer.ProgramSerializer)\n        assert isinstance(program, ebpfProgram.EbpfProgram)\n\n        if branch_on == []:\n            dest = branch_to.values()[0]\n            serializer.emitIndent()\n            name = program.getLabel(dest)\n            serializer.appendFormat(\"goto {0};\", name)\n            serializer.newline()\n        elif isinstance(branch_on, list):\n            tmpvar = program.generateNewName(\"tmp\")\n            self.serializeSelect(tmpvar, serializer, branch_on, program)\n            self.serializeCases(tmpvar, serializer, branch_to, program)\n        else:\n            raise CompilationException(\n                True, \"Unexpected branch_on {0}\", branch_on)",
  "def serializeOperation(self, serializer, op, program):\n        assert isinstance(serializer, programSerializer.ProgramSerializer)\n        assert isinstance(program, ebpfProgram.EbpfProgram)\n\n        operation = op[0]\n        if operation is parse_call.extract:\n            self.serializeExtract(serializer, op[1], program)\n        elif operation is parse_call.set:\n            self.serializeMetadataSet(serializer, op[1], op[2], program)\n        else:\n            raise CompilationException(\n                True, \"Unexpected operation in parser {0}\", op)",
  "def serializeFieldExtract(self, serializer, headerInstanceName,\n                              index, field, alignment, program):\n        assert isinstance(index, str)\n        assert isinstance(headerInstanceName, str)\n        assert isinstance(field, ebpfStructType.EbpfField)\n        assert isinstance(serializer, programSerializer.ProgramSerializer)\n        assert isinstance(alignment, int)\n        assert isinstance(program, ebpfProgram.EbpfProgram)\n\n        fieldToExtractTo = headerInstanceName + index + \".\" + field.name\n\n        serializer.emitIndent()\n        width = field.widthInBits()\n        if field.name == \"valid\":\n            serializer.appendFormat(\n                \"{0}.{1} = 1;\", program.headerStructName, fieldToExtractTo)\n            serializer.newline()\n            return\n\n        serializer.appendFormat(\"if ({0}->len < BYTES({1} + {2})) \",\n                                program.packetName,\n                                program.offsetVariableName, width)\n        serializer.blockStart()\n        serializer.emitIndent()\n        serializer.appendFormat(\"{0} = p4_pe_header_too_short;\",\n                                program.errorName)\n        serializer.newline()\n        serializer.emitIndent()\n        serializer.appendLine(\"goto end;\")\n        # TODO: jump to correct exception handler\n        serializer.blockEnd(True)\n\n        if width <= 32:\n            serializer.emitIndent()\n            load = self.generatePacketLoad(0, width, alignment, program)\n\n            serializer.appendFormat(\"{0}.{1} = {2};\",\n                                    program.headerStructName,\n                                    fieldToExtractTo, load)\n            serializer.newline()\n        else:\n            # Destination is bigger than 4 bytes and\n            # represented as a byte array.\n            if alignment == 0:\n                shift = 0\n            else:\n                shift = 8 - alignment\n\n            assert shift >= 0\n            if shift == 0:\n                method = \"load_byte\"\n            else:\n                method = \"load_half\"\n            b = (width + 7) / 8\n            for i in range(0, b):\n                serializer.emitIndent()\n                serializer.appendFormat(\"{0}.{1}[{2}] = ({3}8)\",\n                                        program.headerStructName,\n                                        fieldToExtractTo, i,\n                                        program.config.uprefix)\n                serializer.appendFormat(\"(({0}({1}, ({2} / 8) + {3}) >> {4})\",\n                                        method, program.packetName,\n                                        program.offsetVariableName, i, shift)\n                if (i == b - 1) and (width % 8 != 0):\n                    serializer.appendFormat(\" & EBPF_MASK({0}8, {1})\",\n                                            program.config.uprefix, width % 8)\n                serializer.append(\")\")\n                serializer.endOfStatement(True)\n\n        serializer.emitIndent()\n        serializer.appendFormat(\"{0} += {1};\",\n                                program.offsetVariableName, width)\n        serializer.newline()",
  "def serializeExtract(self, serializer, headerInstance, program):\n        assert isinstance(serializer, programSerializer.ProgramSerializer)\n        assert isinstance(headerInstance, p4_header_instance)\n        assert isinstance(program, ebpfProgram.EbpfProgram)\n\n        if ebpfProgram.EbpfProgram.isArrayElementInstance(headerInstance):\n            ebpfStack = program.getStackInstance(headerInstance.base_name)\n            assert isinstance(ebpfStack, ebpfInstance.EbpfHeaderStack)\n\n            # write bounds check\n            serializer.emitIndent()\n            serializer.appendFormat(\"if ({0} >= {1}) \",\n                                    ebpfStack.indexVar, ebpfStack.arraySize)\n            serializer.blockStart()\n            serializer.emitIndent()\n            serializer.appendFormat(\"{0} = p4_pe_index_out_of_bounds;\",\n                                    program.errorName)\n            serializer.newline()\n            serializer.emitIndent()\n            serializer.appendLine(\"goto end;\")\n            serializer.blockEnd(True)\n\n            if isinstance(headerInstance.index, int):\n                index = \"[\" + str(headerInstance.index) + \"]\"\n            elif headerInstance.index is P4_NEXT:\n                index = \"[\" + ebpfStack.indexVar + \"]\"\n            else:\n                raise CompilationException(\n                    True, \"Unexpected index for array {0}\",\n                    headerInstance.index)\n            basetype = ebpfStack.basetype\n        else:\n            ebpfHeader = program.getHeaderInstance(headerInstance.name)\n            basetype = ebpfHeader.type\n            index = \"\"\n\n        # extract all fields\n        alignment = 0\n        for field in basetype.fields:\n            assert isinstance(field, ebpfStructType.EbpfField)\n\n            self.serializeFieldExtract(serializer, headerInstance.base_name,\n                                       index, field, alignment, program)\n            alignment += field.widthInBits()\n            alignment = alignment % 8\n\n        if ebpfProgram.EbpfProgram.isArrayElementInstance(headerInstance):\n            # increment stack index\n            ebpfStack = program.getStackInstance(headerInstance.base_name)\n            assert isinstance(ebpfStack, ebpfInstance.EbpfHeaderStack)\n\n            # write bounds check\n            serializer.emitIndent()\n            serializer.appendFormat(\"{0}++;\", ebpfStack.indexVar)\n            serializer.newline()",
  "def serializeMetadataSet(self, serializer, field, value, program):\n        assert isinstance(serializer, programSerializer.ProgramSerializer)\n        assert isinstance(program, ebpfProgram.EbpfProgram)\n        assert isinstance(field, p4_field)\n\n        dest = program.getInstance(field.instance.name)\n        assert isinstance(dest, ebpfInstance.SimpleInstance)\n        destType = dest.type\n        assert isinstance(destType, ebpfStructType.EbpfStructType)\n        destField = destType.getField(field.name)\n\n        if destField.widthInBits() > 32:\n            useMemcpy = True\n            bytesToCopy = destField.widthInBits() / 8\n            if destField.widthInBits() % 8 != 0:\n                raise CompilationException(\n                    True,\n                    \"{0}: Not implemented: wide field w. sz not multiple of 8\",\n                    field)\n        else:\n            useMemcpy = False\n            bytesToCopy = None # not needed, but compiler is confused\n\n        serializer.emitIndent()\n        destination = \"{0}.{1}.{2}\".format(\n            program.metadataStructName, dest.name, destField.name)\n        if isinstance(value, int):\n            source = str(value)\n            if useMemcpy:\n                raise CompilationException(\n                    True,\n                    \"{0}: Not implemented: copying from wide constant\",\n                    value)\n        elif isinstance(value, tuple):\n            source = self.currentReferenceAsString(value, program)\n        elif isinstance(value, p4_field):\n            source = program.getInstance(value.instance.name)\n            if isinstance(source, ebpfInstance.EbpfMetadata):\n                sourceStruct = program.metadataStructName\n            else:\n                sourceStruct = program.headerStructName\n            source = \"{0}.{1}.{2}\".format(sourceStruct, source.name, value.name)\n        else:\n            raise CompilationException(\n                True, \"Unexpected type for parse_call.set {0}\", value)\n\n        if useMemcpy:\n            serializer.appendFormat(\"memcpy(&{0}, &{1}, {2})\",\n                                    destination, source, bytesToCopy)\n        else:\n            serializer.appendFormat(\"{0} = {1}\", destination, source)\n\n        serializer.endOfStatement(True)",
  "class ProgramSerializer(object):\n    def __init__(self):\n        self.program = \"\"\n        self.eol = \"\\n\"\n        self.currentIndent = 0\n        self.INDENT_AMOUNT = 4  # default indent amount\n\n    def __str__(self):\n        return self.program\n\n    def increaseIndent(self):\n        self.currentIndent += self.INDENT_AMOUNT\n\n    def decreaseIndent(self):\n        self.currentIndent -= self.INDENT_AMOUNT\n        if self.currentIndent < 0:\n            raise CompilationException(True, \"Negative indentation level\")\n\n    def toString(self):\n        return self.program\n\n    def space(self):\n        self.append(\" \")\n\n    def newline(self):\n        self.program += self.eol\n\n    def endOfStatement(self, addNewline):\n        self.append(\";\")\n        if addNewline:\n            self.newline()\n\n    def append(self, string):\n        self.program += str(string)\n\n    def appendFormat(self, format, *args):\n        string = format.format(*args)\n        self.append(string)\n\n    def appendLine(self, string):\n        self.append(string)\n        self.newline()\n\n    def emitIndent(self):\n        self.program += \" \" * self.currentIndent\n\n    def blockStart(self):\n        self.append(\"{\")\n        self.newline()\n        self.increaseIndent()\n\n    def blockEnd(self, addNewline):\n        self.decreaseIndent()\n        self.emitIndent()\n        self.append(\"}\")\n        if addNewline:\n            self.newline()",
  "def __init__(self):\n        self.program = \"\"\n        self.eol = \"\\n\"\n        self.currentIndent = 0\n        self.INDENT_AMOUNT = 4",
  "def __str__(self):\n        return self.program",
  "def increaseIndent(self):\n        self.currentIndent += self.INDENT_AMOUNT",
  "def decreaseIndent(self):\n        self.currentIndent -= self.INDENT_AMOUNT\n        if self.currentIndent < 0:\n            raise CompilationException(True, \"Negative indentation level\")",
  "def toString(self):\n        return self.program",
  "def space(self):\n        self.append(\" \")",
  "def newline(self):\n        self.program += self.eol",
  "def endOfStatement(self, addNewline):\n        self.append(\";\")\n        if addNewline:\n            self.newline()",
  "def append(self, string):\n        self.program += str(string)",
  "def appendFormat(self, format, *args):\n        string = format.format(*args)\n        self.append(string)",
  "def appendLine(self, string):\n        self.append(string)\n        self.newline()",
  "def emitIndent(self):\n        self.program += \" \" * self.currentIndent",
  "def blockStart(self):\n        self.append(\"{\")\n        self.newline()\n        self.increaseIndent()",
  "def blockEnd(self, addNewline):\n        self.decreaseIndent()\n        self.emitIndent()\n        self.append(\"}\")\n        if addNewline:\n            self.newline()",
  "class EbpfProgram(object):\n    def __init__(self, name, hlir, isRouter, config):\n        \"\"\"Representation of an EbpfProgram (in fact,\n        a C program that is converted to EBPF)\"\"\"\n        assert isinstance(hlir, HLIR)\n        assert isinstance(isRouter, bool)\n        assert isinstance(config, target.TargetConfig)\n\n        self.hlir = hlir\n        self.name = name\n        self.uniqueNameCounter = 0\n        self.config = config\n        self.isRouter = isRouter\n        self.reservedPrefix = \"ebpf_\"\n\n        assert isinstance(config, target.TargetConfig)\n\n        self.packetName = self.reservedPrefix + \"packet\"\n        self.dropBit = self.reservedPrefix + \"drop\"\n        self.license = \"GPL\"\n        self.offsetVariableName = self.reservedPrefix + \"packetOffsetInBits\"\n        self.zeroKeyName = self.reservedPrefix + \"zero\"\n        self.arrayIndexType = self.config.uprefix + \"32\"\n        # all array tables must be indexed with u32 values\n\n        self.errorName = self.reservedPrefix + \"error\"\n        self.functionName = self.reservedPrefix + \"filter\"\n        self.egressPortName = \"egress_port\" # Hardwired in P4 definition\n\n        self.typeFactory = typeFactory.EbpfTypeFactory(config)\n        self.errorCodes = [\n            \"p4_pe_no_error\",\n            \"p4_pe_index_out_of_bounds\",\n            \"p4_pe_out_of_packet\",\n            \"p4_pe_header_too_long\",\n            \"p4_pe_header_too_short\",\n            \"p4_pe_unhandled_select\",\n            \"p4_pe_checksum\"]\n\n        self.actions = []\n        self.conditionals = []\n        self.tables = []\n        self.headers = []   # header instances\n        self.metadata = []  # metadata instances\n        self.stacks = []    # header stack instances EbpfHeaderStack\n        self.parsers = []   # all parsers\n        self.deparser = None\n        self.entryPoints = []  # control-flow entry points from parser\n        self.counters = []\n        self.entryPointLabels = {}  # maps p4_node from entryPoints\n                                    # to labels in the C program\n        self.egressEntry = None\n\n        self.construct()\n\n        self.headersStructTypeName = self.reservedPrefix + \"headers_t\"\n        self.headerStructName = self.reservedPrefix + \"headers\"\n        self.metadataStructTypeName = self.reservedPrefix + \"metadata_t\"\n        self.metadataStructName = self.reservedPrefix + \"metadata\"\n\n    def construct(self):\n        if len(self.hlir.p4_field_list_calculations) > 0:\n            raise NotSupportedException(\n                \"{0} calculated field\",\n                self.hlir.p4_field_list_calculations.values()[0].name)\n\n        for h in self.hlir.p4_header_instances.values():\n            if h.max_index is not None:\n                assert isinstance(h, p4_header_instance)\n                if h.index == 0:\n                    # header stack; allocate only for zero-th index\n                    indexVarName = self.generateNewName(h.base_name + \"_index\")\n                    stack = ebpfInstance.EbpfHeaderStack(\n                        h, indexVarName, self.typeFactory)\n                    self.stacks.append(stack)\n            elif h.metadata:\n                metadata = ebpfInstance.EbpfMetadata(h, self.typeFactory)\n                self.metadata.append(metadata)\n            else:\n                header = ebpfInstance.EbpfHeader(h, self.typeFactory)\n                self.headers.append(header)\n\n        for p in self.hlir.p4_parse_states.values():\n            parser = ebpfParser.EbpfParser(p)\n            self.parsers.append(parser)\n\n        for a in self.hlir.p4_actions.values():\n            if self.isInternalAction(a):\n                continue\n            action = ebpfAction.EbpfAction(a, self)\n            self.actions.append(action)\n\n        for c in self.hlir.p4_counters.values():\n            counter = ebpfCounter.EbpfCounter(c, self)\n            self.counters.append(counter)\n\n        for t in self.hlir.p4_tables.values():\n            table = ebpfTable.EbpfTable(t, self, self.config)\n            self.tables.append(table)\n\n        for n in self.hlir.p4_ingress_ptr.keys():\n            self.entryPoints.append(n)\n\n        for n in self.hlir.p4_conditional_nodes.values():\n            conditional = ebpfConditional.EbpfConditional(n, self)\n            self.conditionals.append(conditional)\n\n        self.egressEntry = self.hlir.p4_egress_ptr\n        self.deparser = ebpfDeparser.EbpfDeparser(self.hlir)\n\n    def isInternalAction(self, action):\n        # This is a heuristic really to guess which actions are built-in\n        # Unfortunately there seems to be no other way to do this\n        return action.lineno < 0\n\n    @staticmethod\n    def isArrayElementInstance(headerInstance):\n        assert isinstance(headerInstance, p4_header_instance)\n        return headerInstance.max_index is not None\n\n    def emitWarning(self, formatString, *message):\n        assert isinstance(formatString, str)\n        print(\"WARNING: \", formatString.format(*message))\n\n    def toC(self, serializer):\n        assert isinstance(serializer, programSerializer.ProgramSerializer)\n\n        self.generateIncludes(serializer)\n        self.generatePreamble(serializer)\n        self.generateTypes(serializer)\n        self.generateTables(serializer)\n\n        serializer.newline()\n        serializer.emitIndent()\n        self.config.serializeCodeSection(serializer)\n        serializer.newline()\n        serializer.emitIndent()\n        serializer.appendFormat(\"int {0}(struct __sk_buff* {1}) \",\n                                self.functionName, self.packetName)\n        serializer.blockStart()\n\n        self.generateHeaderInstance(serializer)\n        serializer.append(\" = \")\n        self.generateInitializeHeaders(serializer)\n        serializer.endOfStatement(True)\n\n        self.generateMetadataInstance(serializer)\n        serializer.append(\" = \")\n        self.generateInitializeMetadata(serializer)\n        serializer.endOfStatement(True)\n\n        self.createLocalVariables(serializer)\n        serializer.newline()\n\n        serializer.emitIndent()\n        serializer.appendLine(\"goto start;\")\n\n        self.generateParser(serializer)\n        self.generatePipeline(serializer)\n\n        self.generateDeparser(serializer)\n\n        serializer.emitIndent()\n        serializer.appendLine(\"end:\")\n        serializer.emitIndent()\n\n        if isinstance(self.config, target.KernelSamplesConfig):\n            serializer.appendFormat(\"return {0};\", self.dropBit)\n            serializer.newline()\n        elif isinstance(self.config, target.BccConfig):\n            if self.isRouter:\n                serializer.appendFormat(\"if (!{0})\", self.dropBit)\n                serializer.newline()\n                serializer.increaseIndent()\n                serializer.emitIndent()\n                serializer.appendFormat(\n                    \"bpf_clone_redirect({0}, {1}.standard_metadata.{2}, 0);\",\n                    self.packetName, self.metadataStructName,\n                    self.egressPortName)\n                serializer.newline()\n                serializer.decreaseIndent()\n\n                serializer.emitIndent()\n                serializer.appendLine(\n                    \"return TC_ACT_SHOT /* drop packet; clone is forwarded */;\")\n            else:\n                serializer.appendFormat(\n                    \"return {1} ? TC_ACT_SHOT : TC_ACT_PIPE;\",\n                    self.dropBit)\n                serializer.newline()\n        else:\n            raise CompilationException(\n                True, \"Unexpected target configuration {0}\",\n                self.config.targetName)\n        serializer.blockEnd(True)\n\n        self.generateLicense(serializer)\n\n        serializer.append(self.config.postamble)\n\n    def generateLicense(self, serializer):\n        self.config.serializeLicense(serializer, self.license)\n\n    # noinspection PyMethodMayBeStatic\n    def generateIncludes(self, serializer):\n        assert isinstance(serializer, programSerializer.ProgramSerializer)\n        serializer.append(self.config.getIncludes())\n\n    def getLabel(self, p4node):\n        # C label that corresponds to this point in the control-flow\n        if p4node is None:\n            return \"end\"\n        elif isinstance(p4node, p4_parse_state):\n            label = p4node.name\n            self.entryPointLabels[p4node.name] = label\n        if p4node.name not in self.entryPointLabels:\n            label = self.generateNewName(p4node.name)\n            self.entryPointLabels[p4node.name] = label\n        return self.entryPointLabels[p4node.name]\n\n    # noinspection PyMethodMayBeStatic\n    def generatePreamble(self, serializer):\n        assert isinstance(serializer, programSerializer.ProgramSerializer)\n\n        serializer.emitIndent()\n        serializer.append(\"enum ErrorCode \")\n        serializer.blockStart()\n        for error in self.errorCodes:\n            serializer.emitIndent()\n            serializer.appendFormat(\"{0},\", error)\n            serializer.newline()\n        serializer.blockEnd(False)\n        serializer.endOfStatement(True)\n        serializer.newline()\n\n        serializer.appendLine(\n            \"#define EBPF_MASK(t, w) ((((t)(1)) << (w)) - (t)1)\")\n        serializer.appendLine(\"#define BYTES(w) ((w + 7) / 8)\")\n\n        self.config.generateDword(serializer)\n\n    # noinspection PyMethodMayBeStatic\n    def generateNewName(self, base):  # base is a string\n        \"\"\"Generates a fresh name based on the specified base name\"\"\"\n        # TODO: this should be made \"safer\"\n        assert isinstance(base, str)\n\n        base += \"_\" + str(self.uniqueNameCounter)\n        self.uniqueNameCounter += 1\n        return base\n\n    def generateTypes(self, serializer):\n        assert isinstance(serializer, programSerializer.ProgramSerializer)\n\n        for t in self.typeFactory.type_map.values():\n            t.serialize(serializer)\n\n        # generate a new struct type for the packet itself\n        serializer.appendFormat(\"struct {0} \", self.headersStructTypeName)\n        serializer.blockStart()\n        for h in self.headers:\n            serializer.emitIndent()\n            h.declare(serializer)\n            serializer.endOfStatement(True)\n\n        for h in self.stacks:\n            assert isinstance(h, ebpfInstance.EbpfHeaderStack)\n\n            serializer.emitIndent()\n            h.declare(serializer)\n            serializer.endOfStatement(True)\n\n        serializer.blockEnd(False)\n        serializer.endOfStatement(True)\n\n        # generate a new struct type for the metadata\n        serializer.appendFormat(\"struct {0} \", self.metadataStructTypeName)\n        serializer.blockStart()\n        for h in self.metadata:\n            assert isinstance(h, ebpfInstance.EbpfMetadata)\n\n            serializer.emitIndent()\n            h.declare(serializer)\n            serializer.endOfStatement(True)\n        serializer.blockEnd(False)\n        serializer.endOfStatement(True)\n\n    def generateTables(self, serializer):\n        assert isinstance(serializer, programSerializer.ProgramSerializer)\n\n        for t in self.tables:\n            t.serialize(serializer, self)\n\n        for c in self.counters:\n            c.serialize(serializer, self)\n\n    def generateHeaderInstance(self, serializer):\n        assert isinstance(serializer, programSerializer.ProgramSerializer)\n\n        serializer.emitIndent()\n        serializer.appendFormat(\n            \"struct {0} {1}\", self.headersStructTypeName, self.headerStructName)\n\n    def generateInitializeHeaders(self, serializer):\n        assert isinstance(serializer, programSerializer.ProgramSerializer)\n\n        serializer.blockStart()\n        for h in self.headers:\n            serializer.emitIndent()\n            serializer.appendFormat(\".{0} = \", h.name)\n            h.type.emitInitializer(serializer)\n            serializer.appendLine(\",\")\n        serializer.blockEnd(False)\n\n    def generateMetadataInstance(self, serializer):\n        assert isinstance(serializer, programSerializer.ProgramSerializer)\n\n        serializer.emitIndent()\n        serializer.appendFormat(\n            \"struct {0} {1}\",\n            self.metadataStructTypeName,\n            self.metadataStructName)\n\n    def generateDeparser(self, serializer):\n        self.deparser.serialize(serializer, self)\n\n    def generateInitializeMetadata(self, serializer):\n        assert isinstance(serializer, programSerializer.ProgramSerializer)\n\n        serializer.blockStart()\n        for h in self.metadata:\n            serializer.emitIndent()\n            serializer.appendFormat(\".{0} = \", h.name)\n            h.emitInitializer(serializer)\n            serializer.appendLine(\",\")\n        serializer.blockEnd(False)\n\n    def createLocalVariables(self, serializer):\n        assert isinstance(serializer, programSerializer.ProgramSerializer)\n\n        serializer.emitIndent()\n        serializer.appendFormat(\"unsigned {0} = 0;\", self.offsetVariableName)\n        serializer.newline()\n\n        serializer.emitIndent()\n        serializer.appendFormat(\n            \"enum ErrorCode {0} = p4_pe_no_error;\", self.errorName)\n        serializer.newline()\n\n        serializer.emitIndent()\n        serializer.appendFormat(\n            \"{0}8 {1} = 0;\", self.config.uprefix, self.dropBit)\n        serializer.newline()\n\n        serializer.emitIndent()\n        serializer.appendFormat(\n            \"{0} {1} = 0;\", self.arrayIndexType, self.zeroKeyName)\n        serializer.newline()\n\n        for h in self.stacks:\n            serializer.emitIndent()\n            serializer.appendFormat(\n                \"{0}8 {0} = 0;\", self.config.uprefix, h.indexVar)\n            serializer.newline()\n\n    def getStackInstance(self, name):\n        assert isinstance(name, str)\n\n        for h in self.stacks:\n            if h.name == name:\n                assert isinstance(h, ebpfInstance.EbpfHeaderStack)\n                return h\n        raise CompilationException(\n            True, \"Could not locate header stack named {0}\", name)\n\n    def getHeaderInstance(self, name):\n        assert isinstance(name, str)\n\n        for h in self.headers:\n            if h.name == name:\n                assert isinstance(h, ebpfInstance.EbpfHeader)\n                return h\n        raise CompilationException(\n            True, \"Could not locate header instance named {0}\", name)\n\n    def getInstance(self, name):\n        assert isinstance(name, str)\n\n        for h in self.headers:\n            if h.name == name:\n                return h\n        for h in self.metadata:\n            if h.name == name:\n                return h\n        raise CompilationException(\n            True, \"Could not locate instance named {0}\", name)\n\n    def getAction(self, p4action):\n        assert isinstance(p4action, p4_action)\n        for a in self.actions:\n            if a.name == p4action.name:\n                return a\n\n        newAction = ebpfAction.BuiltinAction(p4action)\n        self.actions.append(newAction)\n        return newAction\n\n    def getTable(self, name):\n        assert isinstance(name, str)\n        for t in self.tables:\n            if t.name == name:\n                return t\n        raise CompilationException(\n            True, \"Could not locate table named {0}\", name)\n\n    def getCounter(self, name):\n        assert isinstance(name, str)\n        for t in self.counters:\n            if t.name == name:\n                return t\n        raise CompilationException(\n            True, \"Could not locate counters named {0}\", name)\n\n    def getConditional(self, name):\n        assert isinstance(name, str)\n        for c in self.conditionals:\n            if c.name == name:\n                return c\n        raise CompilationException(\n            True, \"Could not locate conditional named {0}\", name)\n\n    def generateParser(self, serializer):\n        assert isinstance(serializer, programSerializer.ProgramSerializer)\n        for p in self.parsers:\n            p.serialize(serializer, self)\n\n    def generateIngressPipeline(self, serializer):\n        assert isinstance(serializer, programSerializer.ProgramSerializer)\n        for t in self.tables:\n            assert isinstance(t, ebpfTable.EbpfTable)\n            serializer.emitIndent()\n            serializer.appendFormat(\"{0}:\", t.name)\n            serializer.newline()\n\n    def generateControlFlowNode(self, serializer, node, nextEntryPoint):\n        # nextEntryPoint is used as a target whenever the target is None\n        # nextEntryPoint may also be None\n        if isinstance(node, p4_table):\n            table = self.getTable(node.name)\n            assert isinstance(table, ebpfTable.EbpfTable)\n            table.serializeCode(serializer, self, nextEntryPoint)\n        elif isinstance(node, p4_conditional_node):\n            conditional = self.getConditional(node.name)\n            assert isinstance(conditional, ebpfConditional.EbpfConditional)\n            conditional.generateCode(serializer, self, nextEntryPoint)\n        else:\n            raise CompilationException(\n                True, \"{0} Unexpected control flow node \", node)\n\n    def generatePipelineInternal(self, serializer, nodestoadd, nextEntryPoint):\n        assert isinstance(serializer, programSerializer.ProgramSerializer)\n        assert isinstance(nodestoadd, set)\n\n        done = set()\n        while len(nodestoadd) > 0:\n            todo = nodestoadd.pop()\n            if todo in done:\n                continue\n            if todo is None:\n                continue\n\n            print(\"Generating \", todo.name)\n\n            done.add(todo)\n            self.generateControlFlowNode(serializer, todo, nextEntryPoint)\n\n            for n in todo.next_.values():\n                nodestoadd.add(n)\n\n    def generatePipeline(self, serializer):\n        todo = set()\n        for e in self.entryPoints:\n            todo.add(e)\n        self.generatePipelineInternal(serializer, todo, self.egressEntry)\n        todo = set()\n        todo.add(self.egressEntry)\n        self.generatePipelineInternal(serializer, todo, None)",
  "def __init__(self, name, hlir, isRouter, config):\n        \"\"\"Representation of an EbpfProgram (in fact,\n        a C program that is converted to EBPF)\"\"\"\n        assert isinstance(hlir, HLIR)\n        assert isinstance(isRouter, bool)\n        assert isinstance(config, target.TargetConfig)\n\n        self.hlir = hlir\n        self.name = name\n        self.uniqueNameCounter = 0\n        self.config = config\n        self.isRouter = isRouter\n        self.reservedPrefix = \"ebpf_\"\n\n        assert isinstance(config, target.TargetConfig)\n\n        self.packetName = self.reservedPrefix + \"packet\"\n        self.dropBit = self.reservedPrefix + \"drop\"\n        self.license = \"GPL\"\n        self.offsetVariableName = self.reservedPrefix + \"packetOffsetInBits\"\n        self.zeroKeyName = self.reservedPrefix + \"zero\"\n        self.arrayIndexType = self.config.uprefix + \"32\"\n        # all array tables must be indexed with u32 values\n\n        self.errorName = self.reservedPrefix + \"error\"\n        self.functionName = self.reservedPrefix + \"filter\"\n        self.egressPortName = \"egress_port\" # Hardwired in P4 definition\n\n        self.typeFactory = typeFactory.EbpfTypeFactory(config)\n        self.errorCodes = [\n            \"p4_pe_no_error\",\n            \"p4_pe_index_out_of_bounds\",\n            \"p4_pe_out_of_packet\",\n            \"p4_pe_header_too_long\",\n            \"p4_pe_header_too_short\",\n            \"p4_pe_unhandled_select\",\n            \"p4_pe_checksum\"]\n\n        self.actions = []\n        self.conditionals = []\n        self.tables = []\n        self.headers = []   # header instances\n        self.metadata = []  # metadata instances\n        self.stacks = []    # header stack instances EbpfHeaderStack\n        self.parsers = []   # all parsers\n        self.deparser = None\n        self.entryPoints = []  # control-flow entry points from parser\n        self.counters = []\n        self.entryPointLabels = {}  # maps p4_node from entryPoints\n                                    # to labels in the C program\n        self.egressEntry = None\n\n        self.construct()\n\n        self.headersStructTypeName = self.reservedPrefix + \"headers_t\"\n        self.headerStructName = self.reservedPrefix + \"headers\"\n        self.metadataStructTypeName = self.reservedPrefix + \"metadata_t\"\n        self.metadataStructName = self.reservedPrefix + \"metadata\"",
  "def construct(self):\n        if len(self.hlir.p4_field_list_calculations) > 0:\n            raise NotSupportedException(\n                \"{0} calculated field\",\n                self.hlir.p4_field_list_calculations.values()[0].name)\n\n        for h in self.hlir.p4_header_instances.values():\n            if h.max_index is not None:\n                assert isinstance(h, p4_header_instance)\n                if h.index == 0:\n                    # header stack; allocate only for zero-th index\n                    indexVarName = self.generateNewName(h.base_name + \"_index\")\n                    stack = ebpfInstance.EbpfHeaderStack(\n                        h, indexVarName, self.typeFactory)\n                    self.stacks.append(stack)\n            elif h.metadata:\n                metadata = ebpfInstance.EbpfMetadata(h, self.typeFactory)\n                self.metadata.append(metadata)\n            else:\n                header = ebpfInstance.EbpfHeader(h, self.typeFactory)\n                self.headers.append(header)\n\n        for p in self.hlir.p4_parse_states.values():\n            parser = ebpfParser.EbpfParser(p)\n            self.parsers.append(parser)\n\n        for a in self.hlir.p4_actions.values():\n            if self.isInternalAction(a):\n                continue\n            action = ebpfAction.EbpfAction(a, self)\n            self.actions.append(action)\n\n        for c in self.hlir.p4_counters.values():\n            counter = ebpfCounter.EbpfCounter(c, self)\n            self.counters.append(counter)\n\n        for t in self.hlir.p4_tables.values():\n            table = ebpfTable.EbpfTable(t, self, self.config)\n            self.tables.append(table)\n\n        for n in self.hlir.p4_ingress_ptr.keys():\n            self.entryPoints.append(n)\n\n        for n in self.hlir.p4_conditional_nodes.values():\n            conditional = ebpfConditional.EbpfConditional(n, self)\n            self.conditionals.append(conditional)\n\n        self.egressEntry = self.hlir.p4_egress_ptr\n        self.deparser = ebpfDeparser.EbpfDeparser(self.hlir)",
  "def isInternalAction(self, action):\n        # This is a heuristic really to guess which actions are built-in\n        # Unfortunately there seems to be no other way to do this\n        return action.lineno < 0",
  "def isArrayElementInstance(headerInstance):\n        assert isinstance(headerInstance, p4_header_instance)\n        return headerInstance.max_index is not None",
  "def emitWarning(self, formatString, *message):\n        assert isinstance(formatString, str)\n        print(\"WARNING: \", formatString.format(*message))",
  "def toC(self, serializer):\n        assert isinstance(serializer, programSerializer.ProgramSerializer)\n\n        self.generateIncludes(serializer)\n        self.generatePreamble(serializer)\n        self.generateTypes(serializer)\n        self.generateTables(serializer)\n\n        serializer.newline()\n        serializer.emitIndent()\n        self.config.serializeCodeSection(serializer)\n        serializer.newline()\n        serializer.emitIndent()\n        serializer.appendFormat(\"int {0}(struct __sk_buff* {1}) \",\n                                self.functionName, self.packetName)\n        serializer.blockStart()\n\n        self.generateHeaderInstance(serializer)\n        serializer.append(\" = \")\n        self.generateInitializeHeaders(serializer)\n        serializer.endOfStatement(True)\n\n        self.generateMetadataInstance(serializer)\n        serializer.append(\" = \")\n        self.generateInitializeMetadata(serializer)\n        serializer.endOfStatement(True)\n\n        self.createLocalVariables(serializer)\n        serializer.newline()\n\n        serializer.emitIndent()\n        serializer.appendLine(\"goto start;\")\n\n        self.generateParser(serializer)\n        self.generatePipeline(serializer)\n\n        self.generateDeparser(serializer)\n\n        serializer.emitIndent()\n        serializer.appendLine(\"end:\")\n        serializer.emitIndent()\n\n        if isinstance(self.config, target.KernelSamplesConfig):\n            serializer.appendFormat(\"return {0};\", self.dropBit)\n            serializer.newline()\n        elif isinstance(self.config, target.BccConfig):\n            if self.isRouter:\n                serializer.appendFormat(\"if (!{0})\", self.dropBit)\n                serializer.newline()\n                serializer.increaseIndent()\n                serializer.emitIndent()\n                serializer.appendFormat(\n                    \"bpf_clone_redirect({0}, {1}.standard_metadata.{2}, 0);\",\n                    self.packetName, self.metadataStructName,\n                    self.egressPortName)\n                serializer.newline()\n                serializer.decreaseIndent()\n\n                serializer.emitIndent()\n                serializer.appendLine(\n                    \"return TC_ACT_SHOT /* drop packet; clone is forwarded */;\")\n            else:\n                serializer.appendFormat(\n                    \"return {1} ? TC_ACT_SHOT : TC_ACT_PIPE;\",\n                    self.dropBit)\n                serializer.newline()\n        else:\n            raise CompilationException(\n                True, \"Unexpected target configuration {0}\",\n                self.config.targetName)\n        serializer.blockEnd(True)\n\n        self.generateLicense(serializer)\n\n        serializer.append(self.config.postamble)",
  "def generateLicense(self, serializer):\n        self.config.serializeLicense(serializer, self.license)",
  "def generateIncludes(self, serializer):\n        assert isinstance(serializer, programSerializer.ProgramSerializer)\n        serializer.append(self.config.getIncludes())",
  "def getLabel(self, p4node):\n        # C label that corresponds to this point in the control-flow\n        if p4node is None:\n            return \"end\"\n        elif isinstance(p4node, p4_parse_state):\n            label = p4node.name\n            self.entryPointLabels[p4node.name] = label\n        if p4node.name not in self.entryPointLabels:\n            label = self.generateNewName(p4node.name)\n            self.entryPointLabels[p4node.name] = label\n        return self.entryPointLabels[p4node.name]",
  "def generatePreamble(self, serializer):\n        assert isinstance(serializer, programSerializer.ProgramSerializer)\n\n        serializer.emitIndent()\n        serializer.append(\"enum ErrorCode \")\n        serializer.blockStart()\n        for error in self.errorCodes:\n            serializer.emitIndent()\n            serializer.appendFormat(\"{0},\", error)\n            serializer.newline()\n        serializer.blockEnd(False)\n        serializer.endOfStatement(True)\n        serializer.newline()\n\n        serializer.appendLine(\n            \"#define EBPF_MASK(t, w) ((((t)(1)) << (w)) - (t)1)\")\n        serializer.appendLine(\"#define BYTES(w) ((w + 7) / 8)\")\n\n        self.config.generateDword(serializer)",
  "def generateNewName(self, base):  # base is a string\n        \"\"\"Generates a fresh name based on the specified base name\"\"\"\n        # TODO: this should be made \"safer\"\n        assert isinstance(base, str)\n\n        base += \"_\" + str(self.uniqueNameCounter)\n        self.uniqueNameCounter += 1\n        return base",
  "def generateTypes(self, serializer):\n        assert isinstance(serializer, programSerializer.ProgramSerializer)\n\n        for t in self.typeFactory.type_map.values():\n            t.serialize(serializer)\n\n        # generate a new struct type for the packet itself\n        serializer.appendFormat(\"struct {0} \", self.headersStructTypeName)\n        serializer.blockStart()\n        for h in self.headers:\n            serializer.emitIndent()\n            h.declare(serializer)\n            serializer.endOfStatement(True)\n\n        for h in self.stacks:\n            assert isinstance(h, ebpfInstance.EbpfHeaderStack)\n\n            serializer.emitIndent()\n            h.declare(serializer)\n            serializer.endOfStatement(True)\n\n        serializer.blockEnd(False)\n        serializer.endOfStatement(True)\n\n        # generate a new struct type for the metadata\n        serializer.appendFormat(\"struct {0} \", self.metadataStructTypeName)\n        serializer.blockStart()\n        for h in self.metadata:\n            assert isinstance(h, ebpfInstance.EbpfMetadata)\n\n            serializer.emitIndent()\n            h.declare(serializer)\n            serializer.endOfStatement(True)\n        serializer.blockEnd(False)\n        serializer.endOfStatement(True)",
  "def generateTables(self, serializer):\n        assert isinstance(serializer, programSerializer.ProgramSerializer)\n\n        for t in self.tables:\n            t.serialize(serializer, self)\n\n        for c in self.counters:\n            c.serialize(serializer, self)",
  "def generateHeaderInstance(self, serializer):\n        assert isinstance(serializer, programSerializer.ProgramSerializer)\n\n        serializer.emitIndent()\n        serializer.appendFormat(\n            \"struct {0} {1}\", self.headersStructTypeName, self.headerStructName)",
  "def generateInitializeHeaders(self, serializer):\n        assert isinstance(serializer, programSerializer.ProgramSerializer)\n\n        serializer.blockStart()\n        for h in self.headers:\n            serializer.emitIndent()\n            serializer.appendFormat(\".{0} = \", h.name)\n            h.type.emitInitializer(serializer)\n            serializer.appendLine(\",\")\n        serializer.blockEnd(False)",
  "def generateMetadataInstance(self, serializer):\n        assert isinstance(serializer, programSerializer.ProgramSerializer)\n\n        serializer.emitIndent()\n        serializer.appendFormat(\n            \"struct {0} {1}\",\n            self.metadataStructTypeName,\n            self.metadataStructName)",
  "def generateDeparser(self, serializer):\n        self.deparser.serialize(serializer, self)",
  "def generateInitializeMetadata(self, serializer):\n        assert isinstance(serializer, programSerializer.ProgramSerializer)\n\n        serializer.blockStart()\n        for h in self.metadata:\n            serializer.emitIndent()\n            serializer.appendFormat(\".{0} = \", h.name)\n            h.emitInitializer(serializer)\n            serializer.appendLine(\",\")\n        serializer.blockEnd(False)",
  "def createLocalVariables(self, serializer):\n        assert isinstance(serializer, programSerializer.ProgramSerializer)\n\n        serializer.emitIndent()\n        serializer.appendFormat(\"unsigned {0} = 0;\", self.offsetVariableName)\n        serializer.newline()\n\n        serializer.emitIndent()\n        serializer.appendFormat(\n            \"enum ErrorCode {0} = p4_pe_no_error;\", self.errorName)\n        serializer.newline()\n\n        serializer.emitIndent()\n        serializer.appendFormat(\n            \"{0}8 {1} = 0;\", self.config.uprefix, self.dropBit)\n        serializer.newline()\n\n        serializer.emitIndent()\n        serializer.appendFormat(\n            \"{0} {1} = 0;\", self.arrayIndexType, self.zeroKeyName)\n        serializer.newline()\n\n        for h in self.stacks:\n            serializer.emitIndent()\n            serializer.appendFormat(\n                \"{0}8 {0} = 0;\", self.config.uprefix, h.indexVar)\n            serializer.newline()",
  "def getStackInstance(self, name):\n        assert isinstance(name, str)\n\n        for h in self.stacks:\n            if h.name == name:\n                assert isinstance(h, ebpfInstance.EbpfHeaderStack)\n                return h\n        raise CompilationException(\n            True, \"Could not locate header stack named {0}\", name)",
  "def getHeaderInstance(self, name):\n        assert isinstance(name, str)\n\n        for h in self.headers:\n            if h.name == name:\n                assert isinstance(h, ebpfInstance.EbpfHeader)\n                return h\n        raise CompilationException(\n            True, \"Could not locate header instance named {0}\", name)",
  "def getInstance(self, name):\n        assert isinstance(name, str)\n\n        for h in self.headers:\n            if h.name == name:\n                return h\n        for h in self.metadata:\n            if h.name == name:\n                return h\n        raise CompilationException(\n            True, \"Could not locate instance named {0}\", name)",
  "def getAction(self, p4action):\n        assert isinstance(p4action, p4_action)\n        for a in self.actions:\n            if a.name == p4action.name:\n                return a\n\n        newAction = ebpfAction.BuiltinAction(p4action)\n        self.actions.append(newAction)\n        return newAction",
  "def getTable(self, name):\n        assert isinstance(name, str)\n        for t in self.tables:\n            if t.name == name:\n                return t\n        raise CompilationException(\n            True, \"Could not locate table named {0}\", name)",
  "def getCounter(self, name):\n        assert isinstance(name, str)\n        for t in self.counters:\n            if t.name == name:\n                return t\n        raise CompilationException(\n            True, \"Could not locate counters named {0}\", name)",
  "def getConditional(self, name):\n        assert isinstance(name, str)\n        for c in self.conditionals:\n            if c.name == name:\n                return c\n        raise CompilationException(\n            True, \"Could not locate conditional named {0}\", name)",
  "def generateParser(self, serializer):\n        assert isinstance(serializer, programSerializer.ProgramSerializer)\n        for p in self.parsers:\n            p.serialize(serializer, self)",
  "def generateIngressPipeline(self, serializer):\n        assert isinstance(serializer, programSerializer.ProgramSerializer)\n        for t in self.tables:\n            assert isinstance(t, ebpfTable.EbpfTable)\n            serializer.emitIndent()\n            serializer.appendFormat(\"{0}:\", t.name)\n            serializer.newline()",
  "def generateControlFlowNode(self, serializer, node, nextEntryPoint):\n        # nextEntryPoint is used as a target whenever the target is None\n        # nextEntryPoint may also be None\n        if isinstance(node, p4_table):\n            table = self.getTable(node.name)\n            assert isinstance(table, ebpfTable.EbpfTable)\n            table.serializeCode(serializer, self, nextEntryPoint)\n        elif isinstance(node, p4_conditional_node):\n            conditional = self.getConditional(node.name)\n            assert isinstance(conditional, ebpfConditional.EbpfConditional)\n            conditional.generateCode(serializer, self, nextEntryPoint)\n        else:\n            raise CompilationException(\n                True, \"{0} Unexpected control flow node \", node)",
  "def generatePipelineInternal(self, serializer, nodestoadd, nextEntryPoint):\n        assert isinstance(serializer, programSerializer.ProgramSerializer)\n        assert isinstance(nodestoadd, set)\n\n        done = set()\n        while len(nodestoadd) > 0:\n            todo = nodestoadd.pop()\n            if todo in done:\n                continue\n            if todo is None:\n                continue\n\n            print(\"Generating \", todo.name)\n\n            done.add(todo)\n            self.generateControlFlowNode(serializer, todo, nextEntryPoint)\n\n            for n in todo.next_.values():\n                nodestoadd.add(n)",
  "def generatePipeline(self, serializer):\n        todo = set()\n        for e in self.entryPoints:\n            todo.add(e)\n        self.generatePipelineInternal(serializer, todo, self.egressEntry)\n        todo = set()\n        todo.add(self.egressEntry)\n        self.generatePipelineInternal(serializer, todo, None)",
  "class EbpfActionData(object):\n    def __init__(self, name, argtype):\n        self.name = name\n        self.argtype = argtype",
  "class EbpfActionBase(object):\n    def __init__(self, p4action):\n        self.name = p4action.name\n        self.hliraction = p4action\n        self.builtin = False\n        self.arguments = []\n\n    def serializeArgumentsAsStruct(self, serializer):\n        serializer.emitIndent()\n        serializer.appendFormat(\"/* no arguments for {0} */\", self.name)\n        serializer.newline()\n\n    def serializeBody(self, serializer, valueName, program):\n        serializer.emitIndent()\n        serializer.appendFormat(\"/* no body for {0} */\", self.name)\n        serializer.newline()\n\n    def __str__(self):\n        return \"EbpfAction({0})\".format(self.name)",
  "class EbpfAction(EbpfActionBase):\n    unsupported = [\n        # The following cannot be done in EBPF\n        \"add_header\", \"remove_header\", \"execute_meter\",\n        \"clone_ingress_pkt_to_egress\",\n        \"clone_egress_pkt_to_egress\", \"generate_digest\", \"resubmit\",\n        \"modify_field_with_hash_based_offset\", \"truncate\", \"push\", \"pop\",\n        # The following could be done, but are not yet implemented\n        # The situation with copy_header is complicated,\n        # because we don't do checksums\n        \"copy_header\", \"count\",\n        \"register_read\", \"register_write\"]\n\n    # noinspection PyUnresolvedReferences\n    def __init__(self, p4action, program):\n        super(EbpfAction, self).__init__(p4action)\n        assert isinstance(p4action, p4_action)\n        assert isinstance(program, ebpfProgram.EbpfProgram)\n\n        self.builtin = False\n        self.invalid = False  # a leaf action which is never\n                              # called from a table can be invalid.\n\n        for i in range(0, len(p4action.signature)):\n            param = p4action.signature[i]\n            width = p4action.signature_widths[i]\n            if width is None:\n                self.invalid = True\n                return\n            argtype = ebpfScalarType.EbpfScalarType(p4action, width,\n                                                    False, program.config)\n            actionData = EbpfActionData(param, argtype)\n            self.arguments.append(actionData)\n\n    def serializeArgumentsAsStruct(self, serializer):\n        if self.invalid:\n            raise CompilationException(True,\n                \"{0} Attempting to generate code for an invalid action\",\n                                       self.hliraction)\n\n        # Build a struct containing all action arguments.\n        serializer.emitIndent()\n        serializer.append(\"struct \")\n        serializer.blockStart()\n        assert isinstance(serializer, ProgramSerializer)\n        for arg in self.arguments:\n            assert isinstance(arg, EbpfActionData)\n            serializer.emitIndent()\n            argtype = arg.argtype\n            assert isinstance(argtype, ebpfType.EbpfType)\n            argtype.declare(serializer, arg.name, False)\n            serializer.endOfStatement(True)\n        serializer.blockEnd(False)\n        serializer.space()\n        serializer.append(self.name)\n        serializer.endOfStatement(True)\n\n    def serializeBody(self, serializer, dataContainer, program):\n        if self.invalid:\n            raise CompilationException(True,\n                \"{0} Attempting to generate code for an invalid action\",\n                                       self.hliraction)\n\n        # TODO: generate PARALLEL implementation\n        # dataContainer is a string containing the variable name\n        # containing the action data\n        assert isinstance(serializer, ProgramSerializer)\n        assert isinstance(program, ebpfProgram.EbpfProgram)\n        assert isinstance(dataContainer, str)\n        callee_list = self.hliraction.flat_call_sequence\n        for e in callee_list:\n            action = e[0]\n            assert isinstance(action, p4_action)\n            arguments = e[1]\n            assert isinstance(arguments, list)\n            self.serializeCallee(self, action, arguments, serializer,\n                                 dataContainer, program)\n\n    def checkSize(self, call, args, program):\n        size = None\n        for a in args:\n            if a is None:\n                continue\n            if size is None:\n                size = a\n            elif a != size:\n                program.emitWarning(\n                    \"{0}: Arguments do not have the same size {1} and {2}\",\n                    call, size, a)\n        return size\n\n    @staticmethod\n    def translateActionToOperator(actionName):\n        if actionName == \"add\" or actionName == \"add_to_field\":\n            return \"+\"\n        elif actionName == \"bit_and\":\n            return \"&\"\n        elif actionName == \"bit_or\":\n            return \"|\"\n        elif actionName == \"bit_xor\":\n            return \"^\"\n        elif actionName == \"subtract\" or actionName == \"subtract_from_field\":\n            return \"-\"\n        else:\n            raise CompilationException(True,\n                                       \"Unexpected primitive action {0}\",\n                                       actionName)\n\n    def serializeCount(self, caller, arguments, serializer,\n                       dataContainer, program):\n        assert isinstance(serializer, ProgramSerializer)\n        assert isinstance(program, ebpfProgram.EbpfProgram)\n        assert isinstance(arguments, list)\n        assert len(arguments) == 2\n\n        counter = arguments[0]\n        index = ArgInfo(arguments[1], caller, dataContainer, program)\n        ctr = program.getCounter(counter.name)\n        assert isinstance(ctr, ebpfCounter.EbpfCounter)\n        serializer.emitIndent()\n        serializer.blockStart()\n\n        # This is actually incorrect, since the key is not always an u32.\n        # This code is currently disabled\n        key = program.reservedPrefix + \"index\"\n        serializer.emitIndent()\n        serializer.appendFormat(\"u32 {0} = {1};\", key, index.asString)\n        serializer.newline()\n\n        ctr.serializeCode(key, serializer, program)\n\n        serializer.blockEnd(True)\n\n    def serializeCallee(self, caller, callee, arguments,\n                        serializer, dataContainer, program):\n        if self.invalid:\n            raise CompilationException(\n                True,\n                \"{0} Attempting to generate code for an invalid action\",\n                self.hliraction)\n\n        assert isinstance(serializer, ProgramSerializer)\n        assert isinstance(program, ebpfProgram.EbpfProgram)\n        assert isinstance(callee, p4_action)\n        assert isinstance(arguments, list)\n\n        if callee.name in EbpfAction.unsupported:\n            raise NotSupportedException(\"{0}\", callee)\n\n        # This is not yet ready\n        #if callee.name == \"count\":\n        #    self.serializeCount(caller, arguments,\n        #                        serializer, dataContainer, program)\n        #    return\n\n        serializer.emitIndent()\n        args = self.transformArguments(arguments, caller,\n                                       dataContainer, program)\n        if callee.name == \"modify_field\":\n            dst = args[0]\n            src = args[1]\n\n            size = self.checkSize(callee,\n                                  [a.widthInBits() for a in args],\n                                  program)\n            if size is None:\n                raise CompilationException(\n                    True, \"Cannot infer width for arguments {0}\",\n                    callee)\n            elif size <= 32:\n                serializer.appendFormat(\"{0} = {1};\",\n                                        dst.asString,\n                                        src.asString)\n            else:\n                if not dst.isLvalue:\n                    raise NotSupportedException(\n                        \"Constants wider than 32-bit: {0}({1})\",\n                        dst.caller, dst.asString)\n                if not src.isLvalue:\n                    raise NotSupportedException(\n                        \"Constants wider than 32-bit: {0}({1})\",\n                        src.caller, src.asString)\n                serializer.appendFormat(\"memcpy(&{0}, &{1}, {2});\",\n                                        dst.asString,\n                                        src.asString,\n                                        size / 8)\n        elif (callee.name == \"add\" or\n             callee.name == \"bit_and\" or\n             callee.name == \"bit_or\" or\n             callee.name == \"bit_xor\" or\n             callee.name == \"subtract\"):\n            size = self.checkSize(callee,\n                                  [a.widthInBits() for a in args],\n                                  program)\n            if size is None:\n                raise CompilationException(\n                    True,\n                    \"Cannot infer width for arguments {0}\",\n                    callee)\n            if size > 32:\n                raise NotSupportedException(\"{0}: Arithmetic on {1}-bits\",\n                                            callee, size)\n            op = EbpfAction.translateActionToOperator(callee.name)\n            serializer.appendFormat(\"{0} = {1} {2} {3};\",\n                                    args[0].asString,\n                                    args[1].asString,\n                                    op,\n                                    args[2].asString)\n        elif (callee.name == \"add_to_field\" or\n              callee.name == \"subtract_from_field\"):\n            size = self.checkSize(callee,\n                                  [a.widthInBits() for a in args],\n                                  program)\n            if size is None:\n                raise CompilationException(\n                    True, \"Cannot infer width for arguments {0}\", callee)\n            if size > 32:\n                raise NotSupportedException(\n                    \"{0}: Arithmetic on {1}-bits\", callee, size)\n\n            op = EbpfAction.translateActionToOperator(callee.name)\n            serializer.appendFormat(\"{0} = {0} {1} {2};\",\n                                    args[0].asString,\n                                    op,\n                                    args[1].asString)\n        elif callee.name == \"no_op\":\n            serializer.append(\"/* noop */\")\n        elif callee.name == \"drop\":\n            serializer.appendFormat(\"{0} = 1;\", program.dropBit)\n        elif callee.name == \"push\" or callee.name == \"pop\":\n            raise CompilationException(\n                True, \"{0} push/pop not yet implemented\", callee)\n        else:\n            raise CompilationException(\n                True, \"Unexpected primitive action {0}\", callee)\n        serializer.newline()\n\n    def transformArguments(self, arguments, caller, dataContainer, program):\n        result = []\n        for a in arguments:\n            t = ArgInfo(a, caller, dataContainer, program)\n            result.append(t)\n        return result",
  "class BuiltinAction(EbpfActionBase):\n    def __init__(self, p4action):\n        super(BuiltinAction, self).__init__(p4action)\n        self.builtin = True\n\n    def serializeBody(self, serializer, valueName, program):\n        # This is ugly; there should be a better way\n        if self.name == \"drop\":\n            serializer.emitIndent()\n            serializer.appendFormat(\"{0} = 1;\", program.dropBit)\n            serializer.newline()\n        else:\n            serializer.emitIndent()\n            serializer.appendFormat(\"/* no body for {0} */\", self.name)\n            serializer.newline()",
  "class ArgInfo(object):\n    # noinspection PyUnresolvedReferences\n    # Represents an argument passed to an action\n    def __init__(self, argument, caller, dataContainer, program):\n        self.width = None\n        self.asString = None\n        self.isLvalue = True\n        self.caller = caller\n\n        assert isinstance(program, ebpfProgram.EbpfProgram)\n        assert isinstance(caller, EbpfAction)\n\n        if isinstance(argument, int):\n            self.asString = str(argument)\n            self.isLvalue = False\n            # size is unknown\n        elif isinstance(argument, p4_field):\n            if ebpfProgram.EbpfProgram.isArrayElementInstance(\n                    argument.instance):\n                if isinstance(argument.instance.index, int):\n                    index = \"[\" + str(argument.instance.index) + \"]\"\n                else:\n                    raise CompilationException(\n                        True,\n                        \"Unexpected index for array {0}\",\n                        argument.instance.index)\n                stackInstance = program.getStackInstance(\n                    argument.instance.base_name)\n                assert isinstance(stackInstance, ebpfInstance.EbpfHeaderStack)\n                fieldtype = stackInstance.basetype.getField(argument.name)\n                self.width = fieldtype.widthInBits()\n                self.asString = \"{0}.{1}{3}.{2}\".format(\n                    program.headerStructName,\n                    stackInstance.name, argument.name, index)\n            else:\n                instance = program.getInstance(argument.instance.base_name)\n                if isinstance(instance, ebpfInstance.EbpfHeader):\n                    parent = program.headerStructName\n                else:\n                    parent = program.metadataStructName\n                fieldtype = instance.type.getField(argument.name)\n                self.width = fieldtype.widthInBits()\n                self.asString = \"{0}.{1}.{2}\".format(\n                    parent, instance.name, argument.name)\n        elif isinstance(argument, p4_signature_ref):\n            refarg = caller.arguments[argument.idx]\n            self.asString = \"{0}->u.{1}.{2}\".format(\n                dataContainer, caller.name, refarg.name)\n            self.width = caller.arguments[argument.idx].argtype.widthInBits()\n        elif isinstance(argument, p4_header_instance):\n            # This could be a header array element\n            # Unfortunately for push and pop, the user mean the whole array,\n            # but the representation contains just the first element here.\n            # This looks like a bug in the HLIR.\n            if ebpfProgram.EbpfProgram.isArrayElementInstance(argument):\n                if isinstance(argument.index, int):\n                    index = \"[\" + str(argument.index) + \"]\"\n                else:\n                    raise CompilationException(\n                        True,\n                        \"Unexpected index for array {0}\", argument.index)\n                stackInstance = program.getStackInstance(argument.base_name)\n                assert isinstance(stackInstance, ebpfInstance.EbpfHeaderStack)\n                fieldtype = stackInstance.basetype\n                self.width = fieldtype.widthInBits()\n                self.asString = \"{0}.{1}{2}\".format(\n                    program.headerStructName, stackInstance.name, index)\n            else:\n                instance = program.getInstance(argument.name)\n                instancetype = instance.type\n                self.width = instancetype.widthInBits()\n                self.asString = \"{0}.{1}\".format(\n                    program.headerStructName, argument.name)\n        else:\n            raise CompilationException(\n                True, \"Unexpected action argument {0}\", argument)\n\n    def widthInBits(self):\n        return self.width",
  "def __init__(self, name, argtype):\n        self.name = name\n        self.argtype = argtype",
  "def __init__(self, p4action):\n        self.name = p4action.name\n        self.hliraction = p4action\n        self.builtin = False\n        self.arguments = []",
  "def serializeArgumentsAsStruct(self, serializer):\n        serializer.emitIndent()\n        serializer.appendFormat(\"/* no arguments for {0} */\", self.name)\n        serializer.newline()",
  "def serializeBody(self, serializer, valueName, program):\n        serializer.emitIndent()\n        serializer.appendFormat(\"/* no body for {0} */\", self.name)\n        serializer.newline()",
  "def __str__(self):\n        return \"EbpfAction({0})\".format(self.name)",
  "def __init__(self, p4action, program):\n        super(EbpfAction, self).__init__(p4action)\n        assert isinstance(p4action, p4_action)\n        assert isinstance(program, ebpfProgram.EbpfProgram)\n\n        self.builtin = False\n        self.invalid = False  # a leaf action which is never\n                              # called from a table can be invalid.\n\n        for i in range(0, len(p4action.signature)):\n            param = p4action.signature[i]\n            width = p4action.signature_widths[i]\n            if width is None:\n                self.invalid = True\n                return\n            argtype = ebpfScalarType.EbpfScalarType(p4action, width,\n                                                    False, program.config)\n            actionData = EbpfActionData(param, argtype)\n            self.arguments.append(actionData)",
  "def serializeArgumentsAsStruct(self, serializer):\n        if self.invalid:\n            raise CompilationException(True,\n                \"{0} Attempting to generate code for an invalid action\",\n                                       self.hliraction)\n\n        # Build a struct containing all action arguments.\n        serializer.emitIndent()\n        serializer.append(\"struct \")\n        serializer.blockStart()\n        assert isinstance(serializer, ProgramSerializer)\n        for arg in self.arguments:\n            assert isinstance(arg, EbpfActionData)\n            serializer.emitIndent()\n            argtype = arg.argtype\n            assert isinstance(argtype, ebpfType.EbpfType)\n            argtype.declare(serializer, arg.name, False)\n            serializer.endOfStatement(True)\n        serializer.blockEnd(False)\n        serializer.space()\n        serializer.append(self.name)\n        serializer.endOfStatement(True)",
  "def serializeBody(self, serializer, dataContainer, program):\n        if self.invalid:\n            raise CompilationException(True,\n                \"{0} Attempting to generate code for an invalid action\",\n                                       self.hliraction)\n\n        # TODO: generate PARALLEL implementation\n        # dataContainer is a string containing the variable name\n        # containing the action data\n        assert isinstance(serializer, ProgramSerializer)\n        assert isinstance(program, ebpfProgram.EbpfProgram)\n        assert isinstance(dataContainer, str)\n        callee_list = self.hliraction.flat_call_sequence\n        for e in callee_list:\n            action = e[0]\n            assert isinstance(action, p4_action)\n            arguments = e[1]\n            assert isinstance(arguments, list)\n            self.serializeCallee(self, action, arguments, serializer,\n                                 dataContainer, program)",
  "def checkSize(self, call, args, program):\n        size = None\n        for a in args:\n            if a is None:\n                continue\n            if size is None:\n                size = a\n            elif a != size:\n                program.emitWarning(\n                    \"{0}: Arguments do not have the same size {1} and {2}\",\n                    call, size, a)\n        return size",
  "def translateActionToOperator(actionName):\n        if actionName == \"add\" or actionName == \"add_to_field\":\n            return \"+\"\n        elif actionName == \"bit_and\":\n            return \"&\"\n        elif actionName == \"bit_or\":\n            return \"|\"\n        elif actionName == \"bit_xor\":\n            return \"^\"\n        elif actionName == \"subtract\" or actionName == \"subtract_from_field\":\n            return \"-\"\n        else:\n            raise CompilationException(True,\n                                       \"Unexpected primitive action {0}\",\n                                       actionName)",
  "def serializeCount(self, caller, arguments, serializer,\n                       dataContainer, program):\n        assert isinstance(serializer, ProgramSerializer)\n        assert isinstance(program, ebpfProgram.EbpfProgram)\n        assert isinstance(arguments, list)\n        assert len(arguments) == 2\n\n        counter = arguments[0]\n        index = ArgInfo(arguments[1], caller, dataContainer, program)\n        ctr = program.getCounter(counter.name)\n        assert isinstance(ctr, ebpfCounter.EbpfCounter)\n        serializer.emitIndent()\n        serializer.blockStart()\n\n        # This is actually incorrect, since the key is not always an u32.\n        # This code is currently disabled\n        key = program.reservedPrefix + \"index\"\n        serializer.emitIndent()\n        serializer.appendFormat(\"u32 {0} = {1};\", key, index.asString)\n        serializer.newline()\n\n        ctr.serializeCode(key, serializer, program)\n\n        serializer.blockEnd(True)",
  "def serializeCallee(self, caller, callee, arguments,\n                        serializer, dataContainer, program):\n        if self.invalid:\n            raise CompilationException(\n                True,\n                \"{0} Attempting to generate code for an invalid action\",\n                self.hliraction)\n\n        assert isinstance(serializer, ProgramSerializer)\n        assert isinstance(program, ebpfProgram.EbpfProgram)\n        assert isinstance(callee, p4_action)\n        assert isinstance(arguments, list)\n\n        if callee.name in EbpfAction.unsupported:\n            raise NotSupportedException(\"{0}\", callee)\n\n        # This is not yet ready\n        #if callee.name == \"count\":\n        #    self.serializeCount(caller, arguments,\n        #                        serializer, dataContainer, program)\n        #    return\n\n        serializer.emitIndent()\n        args = self.transformArguments(arguments, caller,\n                                       dataContainer, program)\n        if callee.name == \"modify_field\":\n            dst = args[0]\n            src = args[1]\n\n            size = self.checkSize(callee,\n                                  [a.widthInBits() for a in args],\n                                  program)\n            if size is None:\n                raise CompilationException(\n                    True, \"Cannot infer width for arguments {0}\",\n                    callee)\n            elif size <= 32:\n                serializer.appendFormat(\"{0} = {1};\",\n                                        dst.asString,\n                                        src.asString)\n            else:\n                if not dst.isLvalue:\n                    raise NotSupportedException(\n                        \"Constants wider than 32-bit: {0}({1})\",\n                        dst.caller, dst.asString)\n                if not src.isLvalue:\n                    raise NotSupportedException(\n                        \"Constants wider than 32-bit: {0}({1})\",\n                        src.caller, src.asString)\n                serializer.appendFormat(\"memcpy(&{0}, &{1}, {2});\",\n                                        dst.asString,\n                                        src.asString,\n                                        size / 8)\n        elif (callee.name == \"add\" or\n             callee.name == \"bit_and\" or\n             callee.name == \"bit_or\" or\n             callee.name == \"bit_xor\" or\n             callee.name == \"subtract\"):\n            size = self.checkSize(callee,\n                                  [a.widthInBits() for a in args],\n                                  program)\n            if size is None:\n                raise CompilationException(\n                    True,\n                    \"Cannot infer width for arguments {0}\",\n                    callee)\n            if size > 32:\n                raise NotSupportedException(\"{0}: Arithmetic on {1}-bits\",\n                                            callee, size)\n            op = EbpfAction.translateActionToOperator(callee.name)\n            serializer.appendFormat(\"{0} = {1} {2} {3};\",\n                                    args[0].asString,\n                                    args[1].asString,\n                                    op,\n                                    args[2].asString)\n        elif (callee.name == \"add_to_field\" or\n              callee.name == \"subtract_from_field\"):\n            size = self.checkSize(callee,\n                                  [a.widthInBits() for a in args],\n                                  program)\n            if size is None:\n                raise CompilationException(\n                    True, \"Cannot infer width for arguments {0}\", callee)\n            if size > 32:\n                raise NotSupportedException(\n                    \"{0}: Arithmetic on {1}-bits\", callee, size)\n\n            op = EbpfAction.translateActionToOperator(callee.name)\n            serializer.appendFormat(\"{0} = {0} {1} {2};\",\n                                    args[0].asString,\n                                    op,\n                                    args[1].asString)\n        elif callee.name == \"no_op\":\n            serializer.append(\"/* noop */\")\n        elif callee.name == \"drop\":\n            serializer.appendFormat(\"{0} = 1;\", program.dropBit)\n        elif callee.name == \"push\" or callee.name == \"pop\":\n            raise CompilationException(\n                True, \"{0} push/pop not yet implemented\", callee)\n        else:\n            raise CompilationException(\n                True, \"Unexpected primitive action {0}\", callee)\n        serializer.newline()",
  "def transformArguments(self, arguments, caller, dataContainer, program):\n        result = []\n        for a in arguments:\n            t = ArgInfo(a, caller, dataContainer, program)\n            result.append(t)\n        return result",
  "def __init__(self, p4action):\n        super(BuiltinAction, self).__init__(p4action)\n        self.builtin = True",
  "def serializeBody(self, serializer, valueName, program):\n        # This is ugly; there should be a better way\n        if self.name == \"drop\":\n            serializer.emitIndent()\n            serializer.appendFormat(\"{0} = 1;\", program.dropBit)\n            serializer.newline()\n        else:\n            serializer.emitIndent()\n            serializer.appendFormat(\"/* no body for {0} */\", self.name)\n            serializer.newline()",
  "def __init__(self, argument, caller, dataContainer, program):\n        self.width = None\n        self.asString = None\n        self.isLvalue = True\n        self.caller = caller\n\n        assert isinstance(program, ebpfProgram.EbpfProgram)\n        assert isinstance(caller, EbpfAction)\n\n        if isinstance(argument, int):\n            self.asString = str(argument)\n            self.isLvalue = False\n            # size is unknown\n        elif isinstance(argument, p4_field):\n            if ebpfProgram.EbpfProgram.isArrayElementInstance(\n                    argument.instance):\n                if isinstance(argument.instance.index, int):\n                    index = \"[\" + str(argument.instance.index) + \"]\"\n                else:\n                    raise CompilationException(\n                        True,\n                        \"Unexpected index for array {0}\",\n                        argument.instance.index)\n                stackInstance = program.getStackInstance(\n                    argument.instance.base_name)\n                assert isinstance(stackInstance, ebpfInstance.EbpfHeaderStack)\n                fieldtype = stackInstance.basetype.getField(argument.name)\n                self.width = fieldtype.widthInBits()\n                self.asString = \"{0}.{1}{3}.{2}\".format(\n                    program.headerStructName,\n                    stackInstance.name, argument.name, index)\n            else:\n                instance = program.getInstance(argument.instance.base_name)\n                if isinstance(instance, ebpfInstance.EbpfHeader):\n                    parent = program.headerStructName\n                else:\n                    parent = program.metadataStructName\n                fieldtype = instance.type.getField(argument.name)\n                self.width = fieldtype.widthInBits()\n                self.asString = \"{0}.{1}.{2}\".format(\n                    parent, instance.name, argument.name)\n        elif isinstance(argument, p4_signature_ref):\n            refarg = caller.arguments[argument.idx]\n            self.asString = \"{0}->u.{1}.{2}\".format(\n                dataContainer, caller.name, refarg.name)\n            self.width = caller.arguments[argument.idx].argtype.widthInBits()\n        elif isinstance(argument, p4_header_instance):\n            # This could be a header array element\n            # Unfortunately for push and pop, the user mean the whole array,\n            # but the representation contains just the first element here.\n            # This looks like a bug in the HLIR.\n            if ebpfProgram.EbpfProgram.isArrayElementInstance(argument):\n                if isinstance(argument.index, int):\n                    index = \"[\" + str(argument.index) + \"]\"\n                else:\n                    raise CompilationException(\n                        True,\n                        \"Unexpected index for array {0}\", argument.index)\n                stackInstance = program.getStackInstance(argument.base_name)\n                assert isinstance(stackInstance, ebpfInstance.EbpfHeaderStack)\n                fieldtype = stackInstance.basetype\n                self.width = fieldtype.widthInBits()\n                self.asString = \"{0}.{1}{2}\".format(\n                    program.headerStructName, stackInstance.name, index)\n            else:\n                instance = program.getInstance(argument.name)\n                instancetype = instance.type\n                self.width = instancetype.widthInBits()\n                self.asString = \"{0}.{1}\".format(\n                    program.headerStructName, argument.name)\n        else:\n            raise CompilationException(\n                True, \"Unexpected action argument {0}\", argument)",
  "def widthInBits(self):\n        return self.width",
  "class EbpfConditional(object):\n    @staticmethod\n    def translate(op):\n        if op == \"not\":\n            return \"!\"\n        elif op == \"or\":\n            return \"||\"\n        elif op == \"and\":\n            return \"&&\"\n        return op\n\n    def __init__(self, p4conditional, program):\n        assert isinstance(p4conditional, p4_conditional_node)\n        assert isinstance(program, ebpfProgram.EbpfProgram)\n        self.hlirconditional = p4conditional\n        self.name = p4conditional.name\n\n    def emitNode(self, node, serializer, program):\n        if isinstance(node, p4_expression):\n            self.emitExpression(node, serializer, program, False)\n        elif node is None:\n            pass\n        elif isinstance(node, int):\n            serializer.append(node)\n        elif isinstance(node, p4_header_instance):\n            header = program.getInstance(node.name)\n            assert isinstance(header, ebpfInstance.EbpfHeader)\n            # TODO: stacks?\n            serializer.appendFormat(\n                \"{0}.{1}\", program.headerStructName, header.name)\n        elif isinstance(node, p4_field):\n            instance = node.instance\n            einstance = program.getInstance(instance.name)\n            if isinstance(einstance, ebpfInstance.EbpfHeader):\n                base = program.headerStructName\n            else:\n                base = program.metadataStructName\n            serializer.appendFormat(\n                \"{0}.{1}.{2}\", base, einstance.name, node.name)\n        else:\n            raise CompilationException(True, \"{0} Unexpected expression \", node)\n\n    def emitExpression(self, expression, serializer, program, toplevel):\n        assert isinstance(serializer, ProgramSerializer)\n        assert isinstance(program, ebpfProgram.EbpfProgram)\n        assert isinstance(expression, p4_expression)\n        assert isinstance(toplevel, bool)\n        left = expression.left\n        op = expression.op\n        right = expression.right\n\n        assert isinstance(op, str)\n\n        if op == \"valid\":\n            self.emitNode(right, serializer, program)\n            serializer.append(\".valid\")\n            return\n\n        if not toplevel:\n            serializer.append(\"(\")\n        self.emitNode(left, serializer, program)\n        op = EbpfConditional.translate(op)\n        serializer.append(op)\n        self.emitNode(right, serializer, program)\n        if not toplevel:\n            serializer.append(\")\")\n\n    def generateCode(self, serializer, program, nextNode):\n        assert isinstance(serializer, ProgramSerializer)\n        assert isinstance(program, ebpfProgram.EbpfProgram)\n        serializer.emitIndent()\n        serializer.blockStart()\n\n        trueBranch = self.hlirconditional.next_[True]\n        if trueBranch is None:\n            trueBranch = nextNode\n        falseBranch = self.hlirconditional.next_[False]\n        if falseBranch is None:\n            falseBranch = nextNode\n\n        serializer.emitIndent()\n        serializer.appendFormat(\"{0}:\", program.getLabel(self.hlirconditional))\n        serializer.newline()\n\n        serializer.emitIndent()\n        serializer.append(\"if (\")\n        self.emitExpression(\n            self.hlirconditional.condition, serializer, program, True)\n        serializer.appendLine(\")\")\n\n        serializer.increaseIndent()\n        label = program.getLabel(trueBranch)\n        serializer.emitIndent()\n        serializer.appendFormat(\"goto {0};\", label)\n        serializer.newline()\n        serializer.decreaseIndent()\n\n        serializer.emitIndent()\n        serializer.appendLine(\"else\")\n        serializer.increaseIndent()\n        label = program.getLabel(falseBranch)\n        serializer.emitIndent()\n        serializer.appendFormat(\"goto {0};\", label)\n        serializer.newline()\n        serializer.decreaseIndent()\n\n        serializer.blockEnd(True)",
  "def translate(op):\n        if op == \"not\":\n            return \"!\"\n        elif op == \"or\":\n            return \"||\"\n        elif op == \"and\":\n            return \"&&\"\n        return op",
  "def __init__(self, p4conditional, program):\n        assert isinstance(p4conditional, p4_conditional_node)\n        assert isinstance(program, ebpfProgram.EbpfProgram)\n        self.hlirconditional = p4conditional\n        self.name = p4conditional.name",
  "def emitNode(self, node, serializer, program):\n        if isinstance(node, p4_expression):\n            self.emitExpression(node, serializer, program, False)\n        elif node is None:\n            pass\n        elif isinstance(node, int):\n            serializer.append(node)\n        elif isinstance(node, p4_header_instance):\n            header = program.getInstance(node.name)\n            assert isinstance(header, ebpfInstance.EbpfHeader)\n            # TODO: stacks?\n            serializer.appendFormat(\n                \"{0}.{1}\", program.headerStructName, header.name)\n        elif isinstance(node, p4_field):\n            instance = node.instance\n            einstance = program.getInstance(instance.name)\n            if isinstance(einstance, ebpfInstance.EbpfHeader):\n                base = program.headerStructName\n            else:\n                base = program.metadataStructName\n            serializer.appendFormat(\n                \"{0}.{1}.{2}\", base, einstance.name, node.name)\n        else:\n            raise CompilationException(True, \"{0} Unexpected expression \", node)",
  "def emitExpression(self, expression, serializer, program, toplevel):\n        assert isinstance(serializer, ProgramSerializer)\n        assert isinstance(program, ebpfProgram.EbpfProgram)\n        assert isinstance(expression, p4_expression)\n        assert isinstance(toplevel, bool)\n        left = expression.left\n        op = expression.op\n        right = expression.right\n\n        assert isinstance(op, str)\n\n        if op == \"valid\":\n            self.emitNode(right, serializer, program)\n            serializer.append(\".valid\")\n            return\n\n        if not toplevel:\n            serializer.append(\"(\")\n        self.emitNode(left, serializer, program)\n        op = EbpfConditional.translate(op)\n        serializer.append(op)\n        self.emitNode(right, serializer, program)\n        if not toplevel:\n            serializer.append(\")\")",
  "def generateCode(self, serializer, program, nextNode):\n        assert isinstance(serializer, ProgramSerializer)\n        assert isinstance(program, ebpfProgram.EbpfProgram)\n        serializer.emitIndent()\n        serializer.blockStart()\n\n        trueBranch = self.hlirconditional.next_[True]\n        if trueBranch is None:\n            trueBranch = nextNode\n        falseBranch = self.hlirconditional.next_[False]\n        if falseBranch is None:\n            falseBranch = nextNode\n\n        serializer.emitIndent()\n        serializer.appendFormat(\"{0}:\", program.getLabel(self.hlirconditional))\n        serializer.newline()\n\n        serializer.emitIndent()\n        serializer.append(\"if (\")\n        self.emitExpression(\n            self.hlirconditional.condition, serializer, program, True)\n        serializer.appendLine(\")\")\n\n        serializer.increaseIndent()\n        label = program.getLabel(trueBranch)\n        serializer.emitIndent()\n        serializer.appendFormat(\"goto {0};\", label)\n        serializer.newline()\n        serializer.decreaseIndent()\n\n        serializer.emitIndent()\n        serializer.appendLine(\"else\")\n        serializer.increaseIndent()\n        label = program.getLabel(falseBranch)\n        serializer.emitIndent()\n        serializer.appendFormat(\"goto {0};\", label)\n        serializer.newline()\n        serializer.decreaseIndent()\n\n        serializer.blockEnd(True)",
  "class EbpfInstanceBase(object):\n    def __init__(self):\n        pass",
  "class SimpleInstance(EbpfInstanceBase):\n    # A header or a metadata instance (but not array elements)\n    def __init__(self, hlirInstance, factory, isMetadata):\n        super(SimpleInstance, self).__init__()\n        self.hlirInstance = hlirInstance\n        self.name = hlirInstance.base_name\n        self.type = factory.build(hlirInstance.header_type, isMetadata)\n\n    def declare(self, serializer):\n        assert isinstance(serializer, ProgramSerializer)\n        self.type.declare(serializer, self.name, False)",
  "class EbpfHeader(SimpleInstance):\n    \"\"\" Represents a header instance from a P4 program \"\"\"\n    def __init__(self, hlirHeaderInstance, factory):\n        super(EbpfHeader, self).__init__(hlirHeaderInstance, factory, False)\n        if hlirHeaderInstance.metadata:\n            raise CompilationException(True, \"Metadata passed to EpbfHeader\")\n        if hlirHeaderInstance.index is not None:\n            self.name += \"_\" + str(hlirHeaderInstance.index)",
  "class EbpfMetadata(SimpleInstance):\n    \"\"\"Represents a metadata instance from a P4 program\"\"\"\n    def __init__(self, hlirMetadataInstance, factory):\n        super(EbpfMetadata, self).__init__(hlirMetadataInstance, factory, True)\n        if not hlirMetadataInstance.metadata:\n            raise CompilationException(\n                True, \"Header instance passed to EpbfMetadata {0}\",\n                hlirMetadataInstance)\n        if hlirMetadataInstance.index is not None:\n            raise CompilationException(\n                True, \"Unexpected metadata array {0}\", self.hlirInstance)\n        if hasattr(hlirMetadataInstance, \"initializer\"):\n            self.initializer = hlirMetadataInstance.initializer\n        else:\n            self.initializer = None\n\n    def emitInitializer(self, serializer):\n        assert isinstance(serializer, ProgramSerializer)\n        if self.initializer is None:\n            self.type.emitInitializer(serializer)\n        else:\n            for key in self.initializer.keys():\n                serializer.appendFormat(\n                    \".{0} = {1},\", key, self.initializer[key])",
  "class EbpfHeaderStack(EbpfInstanceBase):\n    \"\"\"Represents a header stack instance; there is one instance of\n    this class for each STACK, and not for each\n    element of the stack, as in the HLIR\"\"\"\n    def __init__(self, hlirInstance, indexVar, factory):\n        super(EbpfHeaderStack, self).__init__()\n\n        # indexVar: name of the ebpf variable that\n        # holds the current index for this stack\n        assert isinstance(indexVar, str)\n        assert isinstance(factory, typeFactory.EbpfTypeFactory)\n        assert isinstance(hlirInstance, p4_header_instance)\n\n        self.indexVar = indexVar\n        self.name = hlirInstance.base_name\n        self.basetype = factory.build(hlirInstance.header_type, False)\n        assert isinstance(self.basetype, EbpfType)\n        self.arraySize = hlirInstance.max_index + 1\n        self.hlirInstance = hlirInstance\n\n    def declare(self, serializer):\n        assert isinstance(serializer, ProgramSerializer)\n        self.basetype.declareArray(serializer, self.name, self.arraySize)",
  "def __init__(self):\n        pass",
  "def __init__(self, hlirInstance, factory, isMetadata):\n        super(SimpleInstance, self).__init__()\n        self.hlirInstance = hlirInstance\n        self.name = hlirInstance.base_name\n        self.type = factory.build(hlirInstance.header_type, isMetadata)",
  "def declare(self, serializer):\n        assert isinstance(serializer, ProgramSerializer)\n        self.type.declare(serializer, self.name, False)",
  "def __init__(self, hlirHeaderInstance, factory):\n        super(EbpfHeader, self).__init__(hlirHeaderInstance, factory, False)\n        if hlirHeaderInstance.metadata:\n            raise CompilationException(True, \"Metadata passed to EpbfHeader\")\n        if hlirHeaderInstance.index is not None:\n            self.name += \"_\" + str(hlirHeaderInstance.index)",
  "def __init__(self, hlirMetadataInstance, factory):\n        super(EbpfMetadata, self).__init__(hlirMetadataInstance, factory, True)\n        if not hlirMetadataInstance.metadata:\n            raise CompilationException(\n                True, \"Header instance passed to EpbfMetadata {0}\",\n                hlirMetadataInstance)\n        if hlirMetadataInstance.index is not None:\n            raise CompilationException(\n                True, \"Unexpected metadata array {0}\", self.hlirInstance)\n        if hasattr(hlirMetadataInstance, \"initializer\"):\n            self.initializer = hlirMetadataInstance.initializer\n        else:\n            self.initializer = None",
  "def emitInitializer(self, serializer):\n        assert isinstance(serializer, ProgramSerializer)\n        if self.initializer is None:\n            self.type.emitInitializer(serializer)\n        else:\n            for key in self.initializer.keys():\n                serializer.appendFormat(\n                    \".{0} = {1},\", key, self.initializer[key])",
  "def __init__(self, hlirInstance, indexVar, factory):\n        super(EbpfHeaderStack, self).__init__()\n\n        # indexVar: name of the ebpf variable that\n        # holds the current index for this stack\n        assert isinstance(indexVar, str)\n        assert isinstance(factory, typeFactory.EbpfTypeFactory)\n        assert isinstance(hlirInstance, p4_header_instance)\n\n        self.indexVar = indexVar\n        self.name = hlirInstance.base_name\n        self.basetype = factory.build(hlirInstance.header_type, False)\n        assert isinstance(self.basetype, EbpfType)\n        self.arraySize = hlirInstance.max_index + 1\n        self.hlirInstance = hlirInstance",
  "def declare(self, serializer):\n        assert isinstance(serializer, ProgramSerializer)\n        self.basetype.declareArray(serializer, self.name, self.arraySize)",
  "class Node(object):\n    def __init__(self, n):\n        self.n = n\n        self.edges = set()\n\n    def add_edge_to(self, other):\n        assert(isinstance(other, Node))\n        self.edges.add(other)\n\n    def __str__(self):\n        return str(self.n)",
  "class Graph(object):\n    def __init__(self):\n        self.nodes = {}\n        self.root = None\n\n    def add_node(self, node):\n        assert(node not in self.nodes)\n        self.nodes[node] = Node(node)\n\n    def __contains__(self, node):\n        return node in self.nodes\n\n    def get_node(self, node):\n        return self.nodes[node]\n\n    def produce_topo_sorting(self):\n        def visit(node, topo_sorting, sequence=None):\n            if sequence is not None:\n                sequence += [str(node)]\n            if node._behavioral_topo_sorting_mark == 1:\n                if sequence is not None:\n                    print(\"cycle\", sequence)\n                return False\n            if node._behavioral_topo_sorting_mark != 2:\n                node._behavioral_topo_sorting_mark = 1\n                for next_node in node.edges:\n                    res = visit(next_node, topo_sorting, sequence)\n                    if not res:\n                        return False\n                node._behavioral_topo_sorting_mark = 2\n                topo_sorting.insert(0, node.n)\n            return True\n\n        has_cycle = False\n        topo_sorting = []\n\n        for node in self.nodes.values():\n            # 0 is unmarked, 1 is temp, 2 is permanent\n            node._behavioral_topo_sorting_mark = 0\n        for node in self.nodes.values():\n            if node._behavioral_topo_sorting_mark == 0:\n                if not visit(node, topo_sorting, sequence=[]):\n                    has_cycle = True\n                    break\n        # removing mark\n        for node in self.nodes.values():\n            del node._behavioral_topo_sorting_mark\n\n        if has_cycle:\n            return None\n\n        return topo_sorting",
  "def __init__(self, n):\n        self.n = n\n        self.edges = set()",
  "def add_edge_to(self, other):\n        assert(isinstance(other, Node))\n        self.edges.add(other)",
  "def __str__(self):\n        return str(self.n)",
  "def __init__(self):\n        self.nodes = {}\n        self.root = None",
  "def add_node(self, node):\n        assert(node not in self.nodes)\n        self.nodes[node] = Node(node)",
  "def __contains__(self, node):\n        return node in self.nodes",
  "def get_node(self, node):\n        return self.nodes[node]",
  "def produce_topo_sorting(self):\n        def visit(node, topo_sorting, sequence=None):\n            if sequence is not None:\n                sequence += [str(node)]\n            if node._behavioral_topo_sorting_mark == 1:\n                if sequence is not None:\n                    print(\"cycle\", sequence)\n                return False\n            if node._behavioral_topo_sorting_mark != 2:\n                node._behavioral_topo_sorting_mark = 1\n                for next_node in node.edges:\n                    res = visit(next_node, topo_sorting, sequence)\n                    if not res:\n                        return False\n                node._behavioral_topo_sorting_mark = 2\n                topo_sorting.insert(0, node.n)\n            return True\n\n        has_cycle = False\n        topo_sorting = []\n\n        for node in self.nodes.values():\n            # 0 is unmarked, 1 is temp, 2 is permanent\n            node._behavioral_topo_sorting_mark = 0\n        for node in self.nodes.values():\n            if node._behavioral_topo_sorting_mark == 0:\n                if not visit(node, topo_sorting, sequence=[]):\n                    has_cycle = True\n                    break\n        # removing mark\n        for node in self.nodes.values():\n            del node._behavioral_topo_sorting_mark\n\n        if has_cycle:\n            return None\n\n        return topo_sorting",
  "def visit(node, topo_sorting, sequence=None):\n            if sequence is not None:\n                sequence += [str(node)]\n            if node._behavioral_topo_sorting_mark == 1:\n                if sequence is not None:\n                    print(\"cycle\", sequence)\n                return False\n            if node._behavioral_topo_sorting_mark != 2:\n                node._behavioral_topo_sorting_mark = 1\n                for next_node in node.edges:\n                    res = visit(next_node, topo_sorting, sequence)\n                    if not res:\n                        return False\n                node._behavioral_topo_sorting_mark = 2\n                topo_sorting.insert(0, node.n)\n            return True",
  "class EbpfScalarType(EbpfType):\n    __doc__ = \"Represents a scalar type\"\n    def __init__(self, parent, widthInBits, isSigned, config):\n        super(EbpfScalarType, self).__init__(None)\n        assert isinstance(widthInBits, int)\n        assert isinstance(isSigned, bool)\n        self.width = widthInBits\n        self.isSigned = isSigned\n        self.config = config\n        if widthInBits is P4_AUTO_WIDTH:\n            raise NotSupportedException(\"{0} Variable-width field\", parent)\n\n    def widthInBits(self):\n        return self.width\n\n    @staticmethod\n    def bytesRequired(width):\n        return (width + 7) / 8\n\n    def asString(self):\n        if self.isSigned:\n            prefix = self.config.iprefix\n        else:\n            prefix = self.config.uprefix\n\n        if self.width <= 8:\n            name = prefix + \"8\"\n        elif self.width <= 16:\n            name = prefix + \"16\"\n        elif self.width <= 32:\n            name = prefix + \"32\"\n        else:\n            name = \"char*\"\n        return name\n\n    def alignment(self):\n        if self.width <= 8:\n            return 1\n        elif self.width <= 16:\n            return 2\n        elif self.width <= 32:\n            return 4\n        else:\n            return 1  # Char array\n\n    def serialize(self, serializer):\n        assert isinstance(serializer, ProgramSerializer)\n        serializer.append(self.asString())\n\n    def declareArray(self, serializer, identifier, size):\n        raise CompilationException(\n            True, \"Arrays of base type not expected in P4\")\n\n    def declare(self, serializer, identifier, asPointer):\n        assert isinstance(serializer, ProgramSerializer)\n        assert isinstance(asPointer, bool)\n        assert isinstance(identifier, str)\n\n        if self.width <= 32:\n            self.serialize(serializer)\n            if asPointer:\n                serializer.append(\"*\")\n            serializer.space()\n            serializer.append(identifier)\n        else:\n            if asPointer:\n                serializer.append(\"char*\")\n            else:\n                serializer.appendFormat(\n                    \"char {0}[{1}]\", identifier,\n                    EbpfScalarType.bytesRequired(self.width))\n\n    def emitInitializer(self, serializer):\n        assert isinstance(serializer, ProgramSerializer)\n        serializer.append(\"0\")",
  "def __init__(self, parent, widthInBits, isSigned, config):\n        super(EbpfScalarType, self).__init__(None)\n        assert isinstance(widthInBits, int)\n        assert isinstance(isSigned, bool)\n        self.width = widthInBits\n        self.isSigned = isSigned\n        self.config = config\n        if widthInBits is P4_AUTO_WIDTH:\n            raise NotSupportedException(\"{0} Variable-width field\", parent)",
  "def widthInBits(self):\n        return self.width",
  "def bytesRequired(width):\n        return (width + 7) / 8",
  "def asString(self):\n        if self.isSigned:\n            prefix = self.config.iprefix\n        else:\n            prefix = self.config.uprefix\n\n        if self.width <= 8:\n            name = prefix + \"8\"\n        elif self.width <= 16:\n            name = prefix + \"16\"\n        elif self.width <= 32:\n            name = prefix + \"32\"\n        else:\n            name = \"char*\"\n        return name",
  "def alignment(self):\n        if self.width <= 8:\n            return 1\n        elif self.width <= 16:\n            return 2\n        elif self.width <= 32:\n            return 4\n        else:\n            return 1",
  "def serialize(self, serializer):\n        assert isinstance(serializer, ProgramSerializer)\n        serializer.append(self.asString())",
  "def declareArray(self, serializer, identifier, size):\n        raise CompilationException(\n            True, \"Arrays of base type not expected in P4\")",
  "def declare(self, serializer, identifier, asPointer):\n        assert isinstance(serializer, ProgramSerializer)\n        assert isinstance(asPointer, bool)\n        assert isinstance(identifier, str)\n\n        if self.width <= 32:\n            self.serialize(serializer)\n            if asPointer:\n                serializer.append(\"*\")\n            serializer.space()\n            serializer.append(identifier)\n        else:\n            if asPointer:\n                serializer.append(\"char*\")\n            else:\n                serializer.appendFormat(\n                    \"char {0}[{1}]\", identifier,\n                    EbpfScalarType.bytesRequired(self.width))",
  "def emitInitializer(self, serializer):\n        assert isinstance(serializer, ProgramSerializer)\n        serializer.append(\"0\")",
  "def produce_parser_topo_sorting(hlir):\n    # This function is copied from the P4 behavioral model implementation\n    header_graph = Graph()\n\n    def walk_rec(hlir, parse_state, prev_hdr_node, tag_stacks_index):\n        assert(isinstance(parse_state, p4_parse_state))\n        for call in parse_state.call_sequence:\n            call_type = call[0]\n            if call_type == parse_call.extract:\n                hdr = call[1]\n\n                if hdr.virtual:\n                    base_name = hdr.base_name\n                    current_index = tag_stacks_index[base_name]\n                    if current_index > hdr.max_index:\n                        return\n                    tag_stacks_index[base_name] += 1\n                    name = base_name + \"[%d]\" % current_index\n                    hdr = hlir.p4_header_instances[name]\n\n                if hdr not in header_graph:\n                    header_graph.add_node(hdr)\n                hdr_node = header_graph.get_node(hdr)\n\n                if prev_hdr_node:\n                    prev_hdr_node.add_edge_to(hdr_node)\n                else:\n                    header_graph.root = hdr\n                prev_hdr_node = hdr_node\n\n        for branch_case, next_state in parse_state.branch_to.items():\n            if not next_state:\n                continue\n            if not isinstance(next_state, p4_parse_state):\n                continue\n            walk_rec(hlir, next_state, prev_hdr_node, tag_stacks_index.copy())\n\n    start_state = hlir.p4_parse_states[\"start\"]\n    walk_rec(hlir, start_state, None, defaultdict(int))\n\n    header_topo_sorting = header_graph.produce_topo_sorting()\n\n    return header_topo_sorting",
  "class EbpfDeparser(object):\n    def __init__(self, hlir):\n        header_topo_sorting = produce_parser_topo_sorting(hlir)\n        self.headerOrder = [hdr.name for hdr in header_topo_sorting]\n\n    def serialize(self, serializer, program):\n        assert isinstance(serializer, ProgramSerializer)\n        assert isinstance(program, ebpfProgram.EbpfProgram)\n\n        serializer.emitIndent()\n        serializer.blockStart()\n        serializer.emitIndent()\n        serializer.appendLine(\"/* Deparser */\")\n        serializer.emitIndent()\n        serializer.appendFormat(\"{0} = 0;\", program.offsetVariableName)\n        serializer.newline()\n        for h in self.headerOrder:\n            header = program.getHeaderInstance(h)\n            self.serializeHeaderEmit(header, serializer, program)\n        serializer.blockEnd(True)\n\n    def serializeHeaderEmit(self, header, serializer, program):\n        assert isinstance(header, ebpfInstance.EbpfHeader)\n        assert isinstance(serializer, ProgramSerializer)\n        assert isinstance(program, ebpfProgram.EbpfProgram)\n        p4header = header.hlirInstance\n        assert isinstance(p4header, p4_header_instance)\n\n        serializer.emitIndent()\n        serializer.appendFormat(\"if ({0}.{1}.valid) \",\n                                program.headerStructName, header.name)\n        serializer.blockStart()\n\n        if ebpfProgram.EbpfProgram.isArrayElementInstance(p4header):\n            ebpfStack = program.getStackInstance(p4header.base_name)\n            assert isinstance(ebpfStack, ebpfInstance.EbpfHeaderStack)\n\n            if isinstance(p4header.index, int):\n                index = \"[\" + str(headerInstance.index) + \"]\"\n            elif p4header.index is P4_NEXT:\n                index = \"[\" + ebpfStack.indexVar + \"]\"\n            else:\n                raise CompilationException(\n                    True, \"Unexpected index for array {0}\",\n                    p4header.index)\n            basetype = ebpfStack.basetype\n        else:\n            ebpfHeader = program.getHeaderInstance(p4header.name)\n            basetype = ebpfHeader.type\n            index = \"\"\n\n        alignment = 0\n        for field in basetype.fields:\n            assert isinstance(field, ebpfStructType.EbpfField)\n\n            self.serializeFieldEmit(serializer, p4header.base_name,\n                                    index, field, alignment, program)\n            alignment += field.widthInBits()\n            alignment = alignment % 8\n        serializer.blockEnd(True)\n\n    def serializeFieldEmit(self, serializer, name, index,\n                           field, alignment, program):\n        assert isinstance(index, str)\n        assert isinstance(name, str)\n        assert isinstance(field, ebpfStructType.EbpfField)\n        assert isinstance(serializer, ProgramSerializer)\n        assert isinstance(alignment, int)\n        assert isinstance(program, ebpfProgram.EbpfProgram)\n\n        if field.name == \"valid\":\n            return\n\n        fieldToEmit = (program.headerStructName + \".\" + name +\n                       index + \".\" + field.name)\n        width = field.widthInBits()\n        if width <= 32:\n            store = self.generatePacketStore(fieldToEmit, 0, alignment,\n                                             width, program)\n            serializer.emitIndent()\n            serializer.appendLine(store)\n        else:\n            # Destination is bigger than 4 bytes and\n            # represented as a byte array.\n            b = (width + 7) / 8\n            for i in range(0, b):\n                serializer.emitIndent()\n                store = self.generatePacketStore(fieldToEmit + \"[\"+str(i)+\"]\",\n                                                 i,\n                                                 alignment,\n                                                 8, program)\n                serializer.appendLine(store)\n\n        serializer.emitIndent()\n        serializer.appendFormat(\"{0} += {1};\",\n                                program.offsetVariableName, width)\n        serializer.newline()\n\n    def generatePacketStore(self, value, offset, alignment, width, program):\n        assert width > 0\n        assert alignment < 8\n        assert isinstance(width, int)\n        assert isinstance(alignment, int)\n\n        return \"bpf_dins_pkt({0}, {1} / 8 + {2}, {3}, {4}, {5});\".format(\n            program.packetName,\n            program.offsetVariableName,\n            offset,\n            alignment,\n            width,\n            value\n        )",
  "def walk_rec(hlir, parse_state, prev_hdr_node, tag_stacks_index):\n        assert(isinstance(parse_state, p4_parse_state))\n        for call in parse_state.call_sequence:\n            call_type = call[0]\n            if call_type == parse_call.extract:\n                hdr = call[1]\n\n                if hdr.virtual:\n                    base_name = hdr.base_name\n                    current_index = tag_stacks_index[base_name]\n                    if current_index > hdr.max_index:\n                        return\n                    tag_stacks_index[base_name] += 1\n                    name = base_name + \"[%d]\" % current_index\n                    hdr = hlir.p4_header_instances[name]\n\n                if hdr not in header_graph:\n                    header_graph.add_node(hdr)\n                hdr_node = header_graph.get_node(hdr)\n\n                if prev_hdr_node:\n                    prev_hdr_node.add_edge_to(hdr_node)\n                else:\n                    header_graph.root = hdr\n                prev_hdr_node = hdr_node\n\n        for branch_case, next_state in parse_state.branch_to.items():\n            if not next_state:\n                continue\n            if not isinstance(next_state, p4_parse_state):\n                continue\n            walk_rec(hlir, next_state, prev_hdr_node, tag_stacks_index.copy())",
  "def __init__(self, hlir):\n        header_topo_sorting = produce_parser_topo_sorting(hlir)\n        self.headerOrder = [hdr.name for hdr in header_topo_sorting]",
  "def serialize(self, serializer, program):\n        assert isinstance(serializer, ProgramSerializer)\n        assert isinstance(program, ebpfProgram.EbpfProgram)\n\n        serializer.emitIndent()\n        serializer.blockStart()\n        serializer.emitIndent()\n        serializer.appendLine(\"/* Deparser */\")\n        serializer.emitIndent()\n        serializer.appendFormat(\"{0} = 0;\", program.offsetVariableName)\n        serializer.newline()\n        for h in self.headerOrder:\n            header = program.getHeaderInstance(h)\n            self.serializeHeaderEmit(header, serializer, program)\n        serializer.blockEnd(True)",
  "def serializeHeaderEmit(self, header, serializer, program):\n        assert isinstance(header, ebpfInstance.EbpfHeader)\n        assert isinstance(serializer, ProgramSerializer)\n        assert isinstance(program, ebpfProgram.EbpfProgram)\n        p4header = header.hlirInstance\n        assert isinstance(p4header, p4_header_instance)\n\n        serializer.emitIndent()\n        serializer.appendFormat(\"if ({0}.{1}.valid) \",\n                                program.headerStructName, header.name)\n        serializer.blockStart()\n\n        if ebpfProgram.EbpfProgram.isArrayElementInstance(p4header):\n            ebpfStack = program.getStackInstance(p4header.base_name)\n            assert isinstance(ebpfStack, ebpfInstance.EbpfHeaderStack)\n\n            if isinstance(p4header.index, int):\n                index = \"[\" + str(headerInstance.index) + \"]\"\n            elif p4header.index is P4_NEXT:\n                index = \"[\" + ebpfStack.indexVar + \"]\"\n            else:\n                raise CompilationException(\n                    True, \"Unexpected index for array {0}\",\n                    p4header.index)\n            basetype = ebpfStack.basetype\n        else:\n            ebpfHeader = program.getHeaderInstance(p4header.name)\n            basetype = ebpfHeader.type\n            index = \"\"\n\n        alignment = 0\n        for field in basetype.fields:\n            assert isinstance(field, ebpfStructType.EbpfField)\n\n            self.serializeFieldEmit(serializer, p4header.base_name,\n                                    index, field, alignment, program)\n            alignment += field.widthInBits()\n            alignment = alignment % 8\n        serializer.blockEnd(True)",
  "def serializeFieldEmit(self, serializer, name, index,\n                           field, alignment, program):\n        assert isinstance(index, str)\n        assert isinstance(name, str)\n        assert isinstance(field, ebpfStructType.EbpfField)\n        assert isinstance(serializer, ProgramSerializer)\n        assert isinstance(alignment, int)\n        assert isinstance(program, ebpfProgram.EbpfProgram)\n\n        if field.name == \"valid\":\n            return\n\n        fieldToEmit = (program.headerStructName + \".\" + name +\n                       index + \".\" + field.name)\n        width = field.widthInBits()\n        if width <= 32:\n            store = self.generatePacketStore(fieldToEmit, 0, alignment,\n                                             width, program)\n            serializer.emitIndent()\n            serializer.appendLine(store)\n        else:\n            # Destination is bigger than 4 bytes and\n            # represented as a byte array.\n            b = (width + 7) / 8\n            for i in range(0, b):\n                serializer.emitIndent()\n                store = self.generatePacketStore(fieldToEmit + \"[\"+str(i)+\"]\",\n                                                 i,\n                                                 alignment,\n                                                 8, program)\n                serializer.appendLine(store)\n\n        serializer.emitIndent()\n        serializer.appendFormat(\"{0} += {1};\",\n                                program.offsetVariableName, width)\n        serializer.newline()",
  "def generatePacketStore(self, value, offset, alignment, width, program):\n        assert width > 0\n        assert alignment < 8\n        assert isinstance(width, int)\n        assert isinstance(alignment, int)\n\n        return \"bpf_dins_pkt({0}, {1} / 8 + {2}, {3}, {4}, {5});\".format(\n            program.packetName,\n            program.offsetVariableName,\n            offset,\n            alignment,\n            width,\n            value\n        )",
  "class TargetConfig(object):\n    def __init__(self, target):\n        self.targetName = target\n\n    def getIncludes(self):\n        return \"\"\n\n    def serializeLookup(self, serializer, tableName, key, value):\n        serializer.appendFormat(\"{0} = bpf_map_lookup_elem(&{1}, &{2});\",\n                                value, tableName, key)\n\n    def serializeUpdate(self, serializer, tableName, key, value):\n        serializer.appendFormat(\n            \"bpf_map_update_elem(&{0}, &{1}, &{2}, BPF_ANY);\",\n            tableName, key, value)\n\n    def serializeLicense(self, serializer, licenseString):\n        assert isinstance(serializer, ProgramSerializer)\n        serializer.emitIndent()\n        serializer.appendFormat(\n            \"char _license[] {0}(\\\"license\\\") = \\\"{1}\\\";\",\n            self.config.section, licenseString)\n        serializer.newline()\n\n    def serializeCodeSection(self, serializer):\n        assert isinstance(serializer, ProgramSerializer)\n        serializer.appendFormat(\"{0}(\\\"{1}\\\")\", self.section, self.entrySection)\n\n    def serializeTableDeclaration(self, serializer, tableName,\n                                  isHash, keyType, valueType, size):\n        assert isinstance(serializer, ProgramSerializer)\n        assert isinstance(tableName, str)\n        assert isinstance(isHash, bool)\n        assert isinstance(keyType, str)\n        assert isinstance(valueType, str)\n        assert isinstance(size, int)\n\n        serializer.emitIndent()\n        serializer.appendFormat(\"struct {0} {1}(\\\"maps\\\") {2} = \",\n                                self.tableName, self.section, tableName)\n        serializer.blockStart()\n\n        serializer.emitIndent()\n        serializer.append(\".type = \")\n        if isHash:\n            serializer.appendLine(\"BPF_MAP_TYPE_HASH,\")\n        else:\n            serializer.appendLine(\"BPF_MAP_TYPE_ARRAY,\")\n\n        serializer.emitIndent()\n        serializer.appendFormat(\".{0} = sizeof(struct {1}), \",\n                                self.tableKeyAttribute, keyType)\n        serializer.newline()\n\n        serializer.emitIndent()\n        serializer.appendFormat(\".{0} = sizeof(struct {1}), \",\n                                self.tableValueAttribute, valueType)\n        serializer.newline()\n\n        serializer.emitIndent()\n        serializer.appendFormat(\".{0} = {1}, \", self.tableSizeAttribute, size)\n        serializer.newline()\n\n        serializer.blockEnd(False)\n        serializer.endOfStatement(True)\n\n    def generateDword(self, serializer):\n        serializer.appendFormat(\n            \"static inline {0}64 load_dword(void *skb, {0}64 off)\",\n            self.uprefix)\n        serializer.newline()\n        serializer.blockStart()\n        serializer.emitIndent()\n        serializer.appendFormat(\n            (\"return (({0}64)load_word(skb, off) << 32) | \" +\n             \"load_word(skb, off + 4);\"),\n            self.uprefix)\n        serializer.newline()\n        serializer.blockEnd(True)",
  "class KernelSamplesConfig(TargetConfig):\n    def __init__(self):\n        super(SocketConfig, self).__init__(\"Socket\")\n        self.entrySection = \"socket1\"\n        self.section = \"SEC\"\n        self.uprefix = \"u\"\n        self.iprefix = \"i\"\n        self.tableKeyAttribute = \"key_size\"\n        self.tableValueAttribute = \"value_size\"\n        self.tableSizeAttribute = \"max_entries\"\n        self.tableName = \"bpf_map_def\"\n        self.postamble = \"\"\n\n    def getIncludes(self):\n        return \"\"\"\n#include <uapi/linux/bpf.h>\n#include <uapi/linux/if_ether.h>\n#include <uapi/linux/if_packet.h>\n#include <uapi/linux/ip.h>\n#include <linux/skbuff.h>\n#include <linux/netdevice.h>\n#include \"bpf_helpers.h\"\n\"\"\"",
  "class BccConfig(TargetConfig):\n    def __init__(self):\n        super(BccConfig, self).__init__(\"BCC\")\n        self.uprefix = \"u\"\n        self.iprefix = \"i\"\n        self.postamble = \"\"\n\n    def serializeTableDeclaration(self, serializer, tableName,\n                                  isHash, keyType, valueType, size):\n        assert isinstance(serializer, ProgramSerializer)\n        assert isinstance(tableName, str)\n        assert isinstance(isHash, bool)\n        assert isinstance(keyType, str)\n        assert isinstance(valueType, str)\n        assert isinstance(size, int)\n\n        serializer.emitIndent()\n        if isHash:\n            kind = \"hash\"\n        else:\n            kind = \"array\"\n        serializer.appendFormat(\n            \"BPF_TABLE(\\\"{0}\\\", {1}, {2}, {3}, {4});\",\n            kind, keyType, valueType, tableName, size)\n        serializer.newline()\n\n    def serializeLookup(self, serializer, tableName, key, value):\n        serializer.appendFormat(\"{0} = {1}.lookup(&{2});\",\n                                value, tableName, key)\n\n    def serializeUpdate(self, serializer, tableName, key, value):\n        serializer.appendFormat(\"{0}.update(&{1}, &{2});\",\n                                tableName, key, value)\n\n    def generateDword(self, serializer):\n        pass\n\n    def serializeCodeSection(self, serializer):\n        pass\n\n    def getIncludes(self):\n        return \"\"\"\n#include <uapi/linux/bpf.h>\n#include <uapi/linux/if_ether.h>\n#include <uapi/linux/if_packet.h>\n#include <uapi/linux/ip.h>\n#include <linux/skbuff.h>\n#include <linux/netdevice.h>\n#include <linux/pkt_cls.h>\n\"\"\"\n\n    def serializeLicense(self, serializer, licenseString):\n        assert isinstance(serializer, ProgramSerializer)\n        pass",
  "def __init__(self, target):\n        self.targetName = target",
  "def getIncludes(self):\n        return \"\"",
  "def serializeLookup(self, serializer, tableName, key, value):\n        serializer.appendFormat(\"{0} = bpf_map_lookup_elem(&{1}, &{2});\",\n                                value, tableName, key)",
  "def serializeUpdate(self, serializer, tableName, key, value):\n        serializer.appendFormat(\n            \"bpf_map_update_elem(&{0}, &{1}, &{2}, BPF_ANY);\",\n            tableName, key, value)",
  "def serializeLicense(self, serializer, licenseString):\n        assert isinstance(serializer, ProgramSerializer)\n        serializer.emitIndent()\n        serializer.appendFormat(\n            \"char _license[] {0}(\\\"license\\\") = \\\"{1}\\\";\",\n            self.config.section, licenseString)\n        serializer.newline()",
  "def serializeCodeSection(self, serializer):\n        assert isinstance(serializer, ProgramSerializer)\n        serializer.appendFormat(\"{0}(\\\"{1}\\\")\", self.section, self.entrySection)",
  "def serializeTableDeclaration(self, serializer, tableName,\n                                  isHash, keyType, valueType, size):\n        assert isinstance(serializer, ProgramSerializer)\n        assert isinstance(tableName, str)\n        assert isinstance(isHash, bool)\n        assert isinstance(keyType, str)\n        assert isinstance(valueType, str)\n        assert isinstance(size, int)\n\n        serializer.emitIndent()\n        serializer.appendFormat(\"struct {0} {1}(\\\"maps\\\") {2} = \",\n                                self.tableName, self.section, tableName)\n        serializer.blockStart()\n\n        serializer.emitIndent()\n        serializer.append(\".type = \")\n        if isHash:\n            serializer.appendLine(\"BPF_MAP_TYPE_HASH,\")\n        else:\n            serializer.appendLine(\"BPF_MAP_TYPE_ARRAY,\")\n\n        serializer.emitIndent()\n        serializer.appendFormat(\".{0} = sizeof(struct {1}), \",\n                                self.tableKeyAttribute, keyType)\n        serializer.newline()\n\n        serializer.emitIndent()\n        serializer.appendFormat(\".{0} = sizeof(struct {1}), \",\n                                self.tableValueAttribute, valueType)\n        serializer.newline()\n\n        serializer.emitIndent()\n        serializer.appendFormat(\".{0} = {1}, \", self.tableSizeAttribute, size)\n        serializer.newline()\n\n        serializer.blockEnd(False)\n        serializer.endOfStatement(True)",
  "def generateDword(self, serializer):\n        serializer.appendFormat(\n            \"static inline {0}64 load_dword(void *skb, {0}64 off)\",\n            self.uprefix)\n        serializer.newline()\n        serializer.blockStart()\n        serializer.emitIndent()\n        serializer.appendFormat(\n            (\"return (({0}64)load_word(skb, off) << 32) | \" +\n             \"load_word(skb, off + 4);\"),\n            self.uprefix)\n        serializer.newline()\n        serializer.blockEnd(True)",
  "def __init__(self):\n        super(SocketConfig, self).__init__(\"Socket\")\n        self.entrySection = \"socket1\"\n        self.section = \"SEC\"\n        self.uprefix = \"u\"\n        self.iprefix = \"i\"\n        self.tableKeyAttribute = \"key_size\"\n        self.tableValueAttribute = \"value_size\"\n        self.tableSizeAttribute = \"max_entries\"\n        self.tableName = \"bpf_map_def\"\n        self.postamble = \"\"",
  "def getIncludes(self):\n        return \"\"\"\n#include <uapi/linux/bpf.h>\n#include <uapi/linux/if_ether.h>\n#include <uapi/linux/if_packet.h>\n#include <uapi/linux/ip.h>\n#include <linux/skbuff.h>\n#include <linux/netdevice.h>\n#include \"bpf_helpers.h\"\n\"\"\"",
  "def __init__(self):\n        super(BccConfig, self).__init__(\"BCC\")\n        self.uprefix = \"u\"\n        self.iprefix = \"i\"\n        self.postamble = \"\"",
  "def serializeTableDeclaration(self, serializer, tableName,\n                                  isHash, keyType, valueType, size):\n        assert isinstance(serializer, ProgramSerializer)\n        assert isinstance(tableName, str)\n        assert isinstance(isHash, bool)\n        assert isinstance(keyType, str)\n        assert isinstance(valueType, str)\n        assert isinstance(size, int)\n\n        serializer.emitIndent()\n        if isHash:\n            kind = \"hash\"\n        else:\n            kind = \"array\"\n        serializer.appendFormat(\n            \"BPF_TABLE(\\\"{0}\\\", {1}, {2}, {3}, {4});\",\n            kind, keyType, valueType, tableName, size)\n        serializer.newline()",
  "def serializeLookup(self, serializer, tableName, key, value):\n        serializer.appendFormat(\"{0} = {1}.lookup(&{2});\",\n                                value, tableName, key)",
  "def serializeUpdate(self, serializer, tableName, key, value):\n        serializer.appendFormat(\"{0}.update(&{1}, &{2});\",\n                                tableName, key, value)",
  "def generateDword(self, serializer):\n        pass",
  "def serializeCodeSection(self, serializer):\n        pass",
  "def getIncludes(self):\n        return \"\"\"\n#include <uapi/linux/bpf.h>\n#include <uapi/linux/if_ether.h>\n#include <uapi/linux/if_packet.h>\n#include <uapi/linux/ip.h>\n#include <linux/skbuff.h>\n#include <linux/netdevice.h>\n#include <linux/pkt_cls.h>\n\"\"\"",
  "def serializeLicense(self, serializer, licenseString):\n        assert isinstance(serializer, ProgramSerializer)\n        pass",
  "class EbpfTableKeyField(object):\n    def __init__(self, fieldname, instance, field, mask):\n        assert isinstance(instance, ebpfInstance.EbpfInstanceBase)\n        assert isinstance(field, ebpfStructType.EbpfField)\n\n        self.keyFieldName = fieldname\n        self.instance = instance\n        self.field = field\n        self.mask = mask\n\n    def serializeType(self, serializer):\n        assert isinstance(serializer, ProgramSerializer)\n        ftype = self.field.type\n        serializer.emitIndent()\n        ftype.declare(serializer, self.keyFieldName, False)\n        serializer.endOfStatement(True)\n\n    def serializeConstruction(self, keyName, serializer, program):\n        assert isinstance(serializer, ProgramSerializer)\n        assert isinstance(keyName, str)\n        assert isinstance(program, ebpfProgram.EbpfProgram)\n\n        if self.mask is not None:\n            maskExpression = \" & {0}\".format(self.mask)\n        else:\n            maskExpression = \"\"\n\n        if isinstance(self.instance, ebpfInstance.EbpfMetadata):\n            base = program.metadataStructName\n        else:\n            base = program.headerStructName\n\n        if isinstance(self.instance, ebpfInstance.SimpleInstance):\n            source = \"{0}.{1}.{2}\".format(\n                base, self.instance.name, self.field.name)\n        else:\n            assert isinstance(self.instance, ebpfInstance.EbpfHeaderStack)\n            source = \"{0}.{1}[{2}].{3}\".format(\n                base, self.instance.name,\n                self.instance.hlirInstance.index, self.field.name)\n        destination = \"{0}.{1}\".format(keyName, self.keyFieldName)\n        size = self.field.widthInBits()\n\n        serializer.emitIndent()\n        if size <= 32:\n            serializer.appendFormat(\"{0} = ({1}){2};\",\n                                    destination, source, maskExpression)\n        else:\n            if maskExpression != \"\":\n                raise NotSupportedException(\n                    \"{0} Mask wider than 32 bits\", self.field.hlirType)\n            serializer.appendFormat(\n                \"memcpy(&{0}, &{1}, {2});\", destination, source, size / 8)\n\n        serializer.newline()",
  "class EbpfTableKey(object):\n    def __init__(self, match_fields, program):\n        assert isinstance(program, ebpfProgram.EbpfProgram)\n\n        self.expressions = []\n        self.fields = []\n        self.masks = []\n        self.fieldNamePrefix = \"key_field_\"\n        self.program = program\n\n        fieldNumber = 0\n        for f in match_fields:\n            field = f[0]\n            matchType = f[1]\n            mask = f[2]\n\n            if ((matchType is p4_match_type.P4_MATCH_TERNARY) or\n                (matchType is p4_match_type.P4_MATCH_LPM) or\n                (matchType is p4_match_type.P4_MATCH_RANGE)):\n                raise NotSupportedException(\n                    False, \"Match type {0}\", matchType)\n\n            if matchType is p4_match_type.P4_MATCH_VALID:\n                # we should be really checking the valid field;\n                # p4_field is a header instance\n                assert isinstance(field, p4_header_instance)\n                instance = field\n                fieldname = \"valid\"\n            else:\n                assert isinstance(field, p4_field)\n                instance = field.instance\n                fieldname = field.name\n\n            if ebpfProgram.EbpfProgram.isArrayElementInstance(instance):\n                ebpfStack = program.getStackInstance(instance.base_name)\n                assert isinstance(ebpfStack, ebpfInstance.EbpfHeaderStack)\n                basetype = ebpfStack.basetype\n                eInstance = program.getStackInstance(instance.base_name)\n            else:\n                ebpfHeader = program.getInstance(instance.name)\n                assert isinstance(ebpfHeader, ebpfInstance.SimpleInstance)\n                basetype = ebpfHeader.type\n                eInstance = program.getInstance(instance.name)\n\n            ebpfField = basetype.getField(fieldname)\n            assert isinstance(ebpfField, ebpfStructType.EbpfField)\n\n            fieldName = self.fieldNamePrefix + str(fieldNumber)\n            fieldNumber += 1\n            keyField = EbpfTableKeyField(fieldName, eInstance, ebpfField, mask)\n\n            self.fields.append(keyField)\n            self.masks.append(mask)\n\n    @staticmethod\n    def fieldRank(field):\n        assert isinstance(field, EbpfTableKeyField)\n        return field.field.type.alignment()\n\n    def serializeType(self, serializer, keyTypeName):\n        assert isinstance(serializer, ProgramSerializer)\n        serializer.emitIndent()\n        serializer.appendFormat(\"struct {0} \", keyTypeName)\n        serializer.blockStart()\n\n        # Sort fields in decreasing size; this will ensure that\n        # there is no padding.\n        # Padding may cause the ebpf verification to fail,\n        # since padding fields are not initalized\n        fieldOrder = sorted(\n            self.fields, key=EbpfTableKey.fieldRank, reverse=True)\n        for f in fieldOrder:\n            assert isinstance(f, EbpfTableKeyField)\n            f.serializeType(serializer)\n\n        serializer.blockEnd(False)\n        serializer.endOfStatement(True)\n\n    def serializeConstruction(self, serializer, keyName, program):\n        serializer.emitIndent()\n        serializer.appendLine(\"/* construct key */\")\n\n        for f in self.fields:\n            f.serializeConstruction(keyName, serializer, program)",
  "class EbpfTable(object):\n    # noinspection PyUnresolvedReferences\n    def __init__(self, hlirtable, program, config):\n        assert isinstance(hlirtable, p4_table)\n        assert isinstance(program, ebpfProgram.EbpfProgram)\n\n        self.name = hlirtable.name\n        self.hlirtable = hlirtable\n        self.config = config\n\n        self.defaultActionMapName = (program.reservedPrefix +\n                                     self.name + \"_miss\")\n        self.key = EbpfTableKey(hlirtable.match_fields, program)\n        self.size = hlirtable.max_size\n        if self.size is None:\n            program.emitWarning(\n                \"{0} does not specify a max_size; using 1024\", hlirtable)\n            self.size = 1024\n        self.isHash = True  # TODO: try to guess arrays when possible\n        self.dataMapName = self.name\n        self.actionEnumName = program.generateNewName(self.name + \"_actions\")\n        self.keyTypeName = program.generateNewName(self.name + \"_key\")\n        self.valueTypeName = program.generateNewName(self.name + \"_value\")\n        self.actions = []\n\n        if hlirtable.action_profile is not None:\n            raise NotSupportedException(\"{0}: action_profile tables\",\n                                        hlirtable)\n        if hlirtable.support_timeout:\n            program.emitWarning(\"{0}: table timeout {1}; ignoring\",\n                                hlirtable, NotSupportedException.archError)\n\n        self.counters = []\n        if (hlirtable.attached_counters is not None):\n            for c in hlirtable.attached_counters:\n                ctr = program.getCounter(c.name)\n                assert isinstance(ctr, ebpfCounter.EbpfCounter)\n                self.counters.append(ctr)\n\n        if (len(hlirtable.attached_meters) > 0 or\n            len(hlirtable.attached_registers) > 0):\n            program.emitWarning(\"{0}: meters/registers {1}; ignored\",\n                                hlirtable, NotSupportedException.archError)\n\n        for a in hlirtable.actions:\n            action = program.getAction(a)\n            self.actions.append(action)\n\n    def serializeKeyType(self, serializer):\n        assert isinstance(serializer, ProgramSerializer)\n        self.key.serializeType(serializer, self.keyTypeName)\n\n    def serializeActionArguments(self, serializer, action):\n        assert isinstance(serializer, ProgramSerializer)\n        assert isinstance(action, ebpfAction.EbpfActionBase)\n        action.serializeArgumentsAsStruct(serializer)\n\n    def serializeValueType(self, serializer):\n        assert isinstance(serializer, ProgramSerializer)\n        #  create an enum with tags for all actions\n        serializer.emitIndent()\n        serializer.appendFormat(\"enum {0} \", self.actionEnumName)\n        serializer.blockStart()\n\n        for a in self.actions:\n            name = a.name\n            serializer.emitIndent()\n            serializer.appendFormat(\"{0}_{1},\", self.name, name)\n            serializer.newline()\n\n        serializer.blockEnd(False)\n        serializer.endOfStatement(True)\n\n        # a type-safe union: a struct with a tag and an union\n        serializer.emitIndent()\n        serializer.appendFormat(\"struct {0} \", self.valueTypeName)\n        serializer.blockStart()\n\n        serializer.emitIndent()\n        #serializer.appendFormat(\"enum {0} action;\", self.actionEnumName)\n        # teporary workaround bcc bug\n        serializer.appendFormat(\"{0}32 action;\",\n                                self.config.uprefix)\n        serializer.newline()\n\n        serializer.emitIndent()\n        serializer.append(\"union \")\n        serializer.blockStart()\n\n        for a in self.actions:\n            self.serializeActionArguments(serializer, a)\n\n        serializer.blockEnd(False)\n        serializer.space()\n        serializer.appendLine(\"u;\")\n        serializer.blockEnd(False)\n        serializer.endOfStatement(True)\n\n    def serialize(self, serializer, program):\n        assert isinstance(serializer, ProgramSerializer)\n        assert isinstance(program, ebpfProgram.EbpfProgram)\n\n        self.serializeKeyType(serializer)\n        self.serializeValueType(serializer)\n\n        self.config.serializeTableDeclaration(\n            serializer, self.dataMapName, self.isHash,\n            \"struct \" + self.keyTypeName,\n            \"struct \" + self.valueTypeName, self.size)\n        self.config.serializeTableDeclaration(\n            serializer, self.defaultActionMapName, False,\n            program.arrayIndexType, \"struct \" + self.valueTypeName, 1)\n\n    def serializeCode(self, serializer, program, nextNode):\n        assert isinstance(serializer, ProgramSerializer)\n        assert isinstance(program, ebpfProgram.EbpfProgram)\n\n        hitVarName = program.reservedPrefix + \"hit\"\n        keyname = \"key\"\n        valueName = \"value\"\n\n        serializer.newline()\n        serializer.emitIndent()\n        serializer.appendFormat(\"{0}:\", program.getLabel(self))\n        serializer.newline()\n\n        serializer.emitIndent()\n        serializer.blockStart()\n\n        serializer.emitIndent()\n        serializer.appendFormat(\"{0}8 {1};\", program.config.uprefix, hitVarName)\n        serializer.newline()\n\n        serializer.emitIndent()\n        serializer.appendFormat(\"struct {0} {1} = {{}};\", self.keyTypeName, keyname)\n        serializer.newline()\n\n        serializer.emitIndent()\n        serializer.appendFormat(\n            \"struct {0} *{1};\", self.valueTypeName, valueName)\n        serializer.newline()\n\n        self.key.serializeConstruction(serializer, keyname, program)\n\n        serializer.emitIndent()\n        serializer.appendFormat(\"{0} = 1;\", hitVarName)\n        serializer.newline()\n\n        serializer.emitIndent()\n        serializer.appendLine(\"/* perform lookup */\")\n        serializer.emitIndent()\n        program.config.serializeLookup(\n            serializer, self.dataMapName, keyname, valueName)\n        serializer.newline()\n\n        serializer.emitIndent()\n        serializer.appendFormat(\"if ({0} == NULL) \", valueName)\n        serializer.blockStart()\n\n        serializer.emitIndent()\n        serializer.appendFormat(\"{0} = 0;\", hitVarName)\n        serializer.newline()\n\n        serializer.emitIndent()\n        serializer.appendLine(\"/* miss; find default action */\")\n        serializer.emitIndent()\n        program.config.serializeLookup(\n            serializer, self.defaultActionMapName,\n            program.zeroKeyName, valueName)\n        serializer.newline()\n        serializer.blockEnd(True)\n\n        if len(self.counters) > 0:\n            serializer.emitIndent()\n            serializer.append(\"else \")\n            serializer.blockStart()\n            for c in self.counters:\n                assert isinstance(c, ebpfCounter.EbpfCounter)\n                if c.autoIncrement:\n                    serializer.emitIndent()\n                    serializer.blockStart()\n                    c.serializeCode(keyname, serializer, program)\n                    serializer.blockEnd(True)\n            serializer.blockEnd(True)\n\n        serializer.emitIndent()\n        serializer.appendFormat(\"if ({0} != NULL) \", valueName)\n        serializer.blockStart()\n        serializer.emitIndent()\n        serializer.appendLine(\"/* run action */\")\n        self.runAction(serializer, self.name, valueName, program, nextNode)\n\n        nextNode = self.hlirtable.next_\n        if \"hit\" in nextNode:\n            node = nextNode[\"hit\"]\n            if node is None:\n                node = nextNode\n            label = program.getLabel(node)\n            serializer.emitIndent()\n            serializer.appendFormat(\"if (hit) goto {0};\", label)\n            serializer.newline()\n\n            node = nextNode[\"miss\"]\n            if node is None:\n                node = nextNode\n            label = program.getLabel(node)\n            serializer.emitIndent()\n            serializer.appendFormat(\"else goto {0};\", label)\n            serializer.newline()\n\n        serializer.blockEnd(True)\n        if not \"hit\" in nextNode:\n            # Catch-all\n            serializer.emitIndent()\n            serializer.appendFormat(\"goto end;\")\n            serializer.newline()\n\n        serializer.blockEnd(True)\n\n    def runAction(self, serializer, tableName, valueName, program, nextNode):\n        serializer.emitIndent()\n        serializer.appendFormat(\"switch ({0}->action) \", valueName)\n        serializer.blockStart()\n\n        for a in self.actions:\n            assert isinstance(a, ebpfAction.EbpfActionBase)\n\n            serializer.emitIndent()\n            serializer.appendFormat(\"case {0}_{1}: \", tableName, a.name)\n            serializer.newline()\n            serializer.emitIndent()\n            serializer.blockStart()\n            a.serializeBody(serializer, valueName, program)\n            serializer.blockEnd(True)\n            serializer.emitIndent()\n\n            nextNodes = self.hlirtable.next_\n            if a.hliraction in nextNodes:\n                node = nextNodes[a.hliraction]\n                if node is None:\n                    node = nextNode\n                label = program.getLabel(node)\n                serializer.appendFormat(\"goto {0};\", label)\n            else:\n                serializer.appendFormat(\"break;\")\n            serializer.newline()\n\n        serializer.blockEnd(True)",
  "def __init__(self, fieldname, instance, field, mask):\n        assert isinstance(instance, ebpfInstance.EbpfInstanceBase)\n        assert isinstance(field, ebpfStructType.EbpfField)\n\n        self.keyFieldName = fieldname\n        self.instance = instance\n        self.field = field\n        self.mask = mask",
  "def serializeType(self, serializer):\n        assert isinstance(serializer, ProgramSerializer)\n        ftype = self.field.type\n        serializer.emitIndent()\n        ftype.declare(serializer, self.keyFieldName, False)\n        serializer.endOfStatement(True)",
  "def serializeConstruction(self, keyName, serializer, program):\n        assert isinstance(serializer, ProgramSerializer)\n        assert isinstance(keyName, str)\n        assert isinstance(program, ebpfProgram.EbpfProgram)\n\n        if self.mask is not None:\n            maskExpression = \" & {0}\".format(self.mask)\n        else:\n            maskExpression = \"\"\n\n        if isinstance(self.instance, ebpfInstance.EbpfMetadata):\n            base = program.metadataStructName\n        else:\n            base = program.headerStructName\n\n        if isinstance(self.instance, ebpfInstance.SimpleInstance):\n            source = \"{0}.{1}.{2}\".format(\n                base, self.instance.name, self.field.name)\n        else:\n            assert isinstance(self.instance, ebpfInstance.EbpfHeaderStack)\n            source = \"{0}.{1}[{2}].{3}\".format(\n                base, self.instance.name,\n                self.instance.hlirInstance.index, self.field.name)\n        destination = \"{0}.{1}\".format(keyName, self.keyFieldName)\n        size = self.field.widthInBits()\n\n        serializer.emitIndent()\n        if size <= 32:\n            serializer.appendFormat(\"{0} = ({1}){2};\",\n                                    destination, source, maskExpression)\n        else:\n            if maskExpression != \"\":\n                raise NotSupportedException(\n                    \"{0} Mask wider than 32 bits\", self.field.hlirType)\n            serializer.appendFormat(\n                \"memcpy(&{0}, &{1}, {2});\", destination, source, size / 8)\n\n        serializer.newline()",
  "def __init__(self, match_fields, program):\n        assert isinstance(program, ebpfProgram.EbpfProgram)\n\n        self.expressions = []\n        self.fields = []\n        self.masks = []\n        self.fieldNamePrefix = \"key_field_\"\n        self.program = program\n\n        fieldNumber = 0\n        for f in match_fields:\n            field = f[0]\n            matchType = f[1]\n            mask = f[2]\n\n            if ((matchType is p4_match_type.P4_MATCH_TERNARY) or\n                (matchType is p4_match_type.P4_MATCH_LPM) or\n                (matchType is p4_match_type.P4_MATCH_RANGE)):\n                raise NotSupportedException(\n                    False, \"Match type {0}\", matchType)\n\n            if matchType is p4_match_type.P4_MATCH_VALID:\n                # we should be really checking the valid field;\n                # p4_field is a header instance\n                assert isinstance(field, p4_header_instance)\n                instance = field\n                fieldname = \"valid\"\n            else:\n                assert isinstance(field, p4_field)\n                instance = field.instance\n                fieldname = field.name\n\n            if ebpfProgram.EbpfProgram.isArrayElementInstance(instance):\n                ebpfStack = program.getStackInstance(instance.base_name)\n                assert isinstance(ebpfStack, ebpfInstance.EbpfHeaderStack)\n                basetype = ebpfStack.basetype\n                eInstance = program.getStackInstance(instance.base_name)\n            else:\n                ebpfHeader = program.getInstance(instance.name)\n                assert isinstance(ebpfHeader, ebpfInstance.SimpleInstance)\n                basetype = ebpfHeader.type\n                eInstance = program.getInstance(instance.name)\n\n            ebpfField = basetype.getField(fieldname)\n            assert isinstance(ebpfField, ebpfStructType.EbpfField)\n\n            fieldName = self.fieldNamePrefix + str(fieldNumber)\n            fieldNumber += 1\n            keyField = EbpfTableKeyField(fieldName, eInstance, ebpfField, mask)\n\n            self.fields.append(keyField)\n            self.masks.append(mask)",
  "def fieldRank(field):\n        assert isinstance(field, EbpfTableKeyField)\n        return field.field.type.alignment()",
  "def serializeType(self, serializer, keyTypeName):\n        assert isinstance(serializer, ProgramSerializer)\n        serializer.emitIndent()\n        serializer.appendFormat(\"struct {0} \", keyTypeName)\n        serializer.blockStart()\n\n        # Sort fields in decreasing size; this will ensure that\n        # there is no padding.\n        # Padding may cause the ebpf verification to fail,\n        # since padding fields are not initalized\n        fieldOrder = sorted(\n            self.fields, key=EbpfTableKey.fieldRank, reverse=True)\n        for f in fieldOrder:\n            assert isinstance(f, EbpfTableKeyField)\n            f.serializeType(serializer)\n\n        serializer.blockEnd(False)\n        serializer.endOfStatement(True)",
  "def serializeConstruction(self, serializer, keyName, program):\n        serializer.emitIndent()\n        serializer.appendLine(\"/* construct key */\")\n\n        for f in self.fields:\n            f.serializeConstruction(keyName, serializer, program)",
  "def __init__(self, hlirtable, program, config):\n        assert isinstance(hlirtable, p4_table)\n        assert isinstance(program, ebpfProgram.EbpfProgram)\n\n        self.name = hlirtable.name\n        self.hlirtable = hlirtable\n        self.config = config\n\n        self.defaultActionMapName = (program.reservedPrefix +\n                                     self.name + \"_miss\")\n        self.key = EbpfTableKey(hlirtable.match_fields, program)\n        self.size = hlirtable.max_size\n        if self.size is None:\n            program.emitWarning(\n                \"{0} does not specify a max_size; using 1024\", hlirtable)\n            self.size = 1024\n        self.isHash = True  # TODO: try to guess arrays when possible\n        self.dataMapName = self.name\n        self.actionEnumName = program.generateNewName(self.name + \"_actions\")\n        self.keyTypeName = program.generateNewName(self.name + \"_key\")\n        self.valueTypeName = program.generateNewName(self.name + \"_value\")\n        self.actions = []\n\n        if hlirtable.action_profile is not None:\n            raise NotSupportedException(\"{0}: action_profile tables\",\n                                        hlirtable)\n        if hlirtable.support_timeout:\n            program.emitWarning(\"{0}: table timeout {1}; ignoring\",\n                                hlirtable, NotSupportedException.archError)\n\n        self.counters = []\n        if (hlirtable.attached_counters is not None):\n            for c in hlirtable.attached_counters:\n                ctr = program.getCounter(c.name)\n                assert isinstance(ctr, ebpfCounter.EbpfCounter)\n                self.counters.append(ctr)\n\n        if (len(hlirtable.attached_meters) > 0 or\n            len(hlirtable.attached_registers) > 0):\n            program.emitWarning(\"{0}: meters/registers {1}; ignored\",\n                                hlirtable, NotSupportedException.archError)\n\n        for a in hlirtable.actions:\n            action = program.getAction(a)\n            self.actions.append(action)",
  "def serializeKeyType(self, serializer):\n        assert isinstance(serializer, ProgramSerializer)\n        self.key.serializeType(serializer, self.keyTypeName)",
  "def serializeActionArguments(self, serializer, action):\n        assert isinstance(serializer, ProgramSerializer)\n        assert isinstance(action, ebpfAction.EbpfActionBase)\n        action.serializeArgumentsAsStruct(serializer)",
  "def serializeValueType(self, serializer):\n        assert isinstance(serializer, ProgramSerializer)\n        #  create an enum with tags for all actions\n        serializer.emitIndent()\n        serializer.appendFormat(\"enum {0} \", self.actionEnumName)\n        serializer.blockStart()\n\n        for a in self.actions:\n            name = a.name\n            serializer.emitIndent()\n            serializer.appendFormat(\"{0}_{1},\", self.name, name)\n            serializer.newline()\n\n        serializer.blockEnd(False)\n        serializer.endOfStatement(True)\n\n        # a type-safe union: a struct with a tag and an union\n        serializer.emitIndent()\n        serializer.appendFormat(\"struct {0} \", self.valueTypeName)\n        serializer.blockStart()\n\n        serializer.emitIndent()\n        #serializer.appendFormat(\"enum {0} action;\", self.actionEnumName)\n        # teporary workaround bcc bug\n        serializer.appendFormat(\"{0}32 action;\",\n                                self.config.uprefix)\n        serializer.newline()\n\n        serializer.emitIndent()\n        serializer.append(\"union \")\n        serializer.blockStart()\n\n        for a in self.actions:\n            self.serializeActionArguments(serializer, a)\n\n        serializer.blockEnd(False)\n        serializer.space()\n        serializer.appendLine(\"u;\")\n        serializer.blockEnd(False)\n        serializer.endOfStatement(True)",
  "def serialize(self, serializer, program):\n        assert isinstance(serializer, ProgramSerializer)\n        assert isinstance(program, ebpfProgram.EbpfProgram)\n\n        self.serializeKeyType(serializer)\n        self.serializeValueType(serializer)\n\n        self.config.serializeTableDeclaration(\n            serializer, self.dataMapName, self.isHash,\n            \"struct \" + self.keyTypeName,\n            \"struct \" + self.valueTypeName, self.size)\n        self.config.serializeTableDeclaration(\n            serializer, self.defaultActionMapName, False,\n            program.arrayIndexType, \"struct \" + self.valueTypeName, 1)",
  "def serializeCode(self, serializer, program, nextNode):\n        assert isinstance(serializer, ProgramSerializer)\n        assert isinstance(program, ebpfProgram.EbpfProgram)\n\n        hitVarName = program.reservedPrefix + \"hit\"\n        keyname = \"key\"\n        valueName = \"value\"\n\n        serializer.newline()\n        serializer.emitIndent()\n        serializer.appendFormat(\"{0}:\", program.getLabel(self))\n        serializer.newline()\n\n        serializer.emitIndent()\n        serializer.blockStart()\n\n        serializer.emitIndent()\n        serializer.appendFormat(\"{0}8 {1};\", program.config.uprefix, hitVarName)\n        serializer.newline()\n\n        serializer.emitIndent()\n        serializer.appendFormat(\"struct {0} {1} = {{}};\", self.keyTypeName, keyname)\n        serializer.newline()\n\n        serializer.emitIndent()\n        serializer.appendFormat(\n            \"struct {0} *{1};\", self.valueTypeName, valueName)\n        serializer.newline()\n\n        self.key.serializeConstruction(serializer, keyname, program)\n\n        serializer.emitIndent()\n        serializer.appendFormat(\"{0} = 1;\", hitVarName)\n        serializer.newline()\n\n        serializer.emitIndent()\n        serializer.appendLine(\"/* perform lookup */\")\n        serializer.emitIndent()\n        program.config.serializeLookup(\n            serializer, self.dataMapName, keyname, valueName)\n        serializer.newline()\n\n        serializer.emitIndent()\n        serializer.appendFormat(\"if ({0} == NULL) \", valueName)\n        serializer.blockStart()\n\n        serializer.emitIndent()\n        serializer.appendFormat(\"{0} = 0;\", hitVarName)\n        serializer.newline()\n\n        serializer.emitIndent()\n        serializer.appendLine(\"/* miss; find default action */\")\n        serializer.emitIndent()\n        program.config.serializeLookup(\n            serializer, self.defaultActionMapName,\n            program.zeroKeyName, valueName)\n        serializer.newline()\n        serializer.blockEnd(True)\n\n        if len(self.counters) > 0:\n            serializer.emitIndent()\n            serializer.append(\"else \")\n            serializer.blockStart()\n            for c in self.counters:\n                assert isinstance(c, ebpfCounter.EbpfCounter)\n                if c.autoIncrement:\n                    serializer.emitIndent()\n                    serializer.blockStart()\n                    c.serializeCode(keyname, serializer, program)\n                    serializer.blockEnd(True)\n            serializer.blockEnd(True)\n\n        serializer.emitIndent()\n        serializer.appendFormat(\"if ({0} != NULL) \", valueName)\n        serializer.blockStart()\n        serializer.emitIndent()\n        serializer.appendLine(\"/* run action */\")\n        self.runAction(serializer, self.name, valueName, program, nextNode)\n\n        nextNode = self.hlirtable.next_\n        if \"hit\" in nextNode:\n            node = nextNode[\"hit\"]\n            if node is None:\n                node = nextNode\n            label = program.getLabel(node)\n            serializer.emitIndent()\n            serializer.appendFormat(\"if (hit) goto {0};\", label)\n            serializer.newline()\n\n            node = nextNode[\"miss\"]\n            if node is None:\n                node = nextNode\n            label = program.getLabel(node)\n            serializer.emitIndent()\n            serializer.appendFormat(\"else goto {0};\", label)\n            serializer.newline()\n\n        serializer.blockEnd(True)\n        if not \"hit\" in nextNode:\n            # Catch-all\n            serializer.emitIndent()\n            serializer.appendFormat(\"goto end;\")\n            serializer.newline()\n\n        serializer.blockEnd(True)",
  "def runAction(self, serializer, tableName, valueName, program, nextNode):\n        serializer.emitIndent()\n        serializer.appendFormat(\"switch ({0}->action) \", valueName)\n        serializer.blockStart()\n\n        for a in self.actions:\n            assert isinstance(a, ebpfAction.EbpfActionBase)\n\n            serializer.emitIndent()\n            serializer.appendFormat(\"case {0}_{1}: \", tableName, a.name)\n            serializer.newline()\n            serializer.emitIndent()\n            serializer.blockStart()\n            a.serializeBody(serializer, valueName, program)\n            serializer.blockEnd(True)\n            serializer.emitIndent()\n\n            nextNodes = self.hlirtable.next_\n            if a.hliraction in nextNodes:\n                node = nextNodes[a.hliraction]\n                if node is None:\n                    node = nextNode\n                label = program.getLabel(node)\n                serializer.appendFormat(\"goto {0};\", label)\n            else:\n                serializer.appendFormat(\"break;\")\n            serializer.newline()\n\n        serializer.blockEnd(True)",
  "class CompilationException(Exception):\n    \"\"\"Signals an error during compilation\"\"\"\n    def __init__(self, isBug, format, *message):\n        # isBug: indicates that this is a compiler bug\n        super(CompilationException, self).__init__()\n\n        assert isinstance(format, str)\n        assert isinstance(isBug, bool)\n        self.message = message\n        self.format = format\n        self.isBug = isBug\n\n    def show(self):\n        # TODO: format this message nicely\n        return self.format.format(*self.message)",
  "class NotSupportedException(Exception):\n    archError = \" not supported by EBPF\"\n\n    def __init__(self, format, *message):\n        super(NotSupportedException, self).__init__()\n\n        assert isinstance(format, str)\n        self.message = message\n        self.format = format\n\n    def show(self):\n        # TODO: format this message nicely\n        return (self.format + NotSupportedException.archError).format(\n            *self.message)",
  "def __init__(self, isBug, format, *message):\n        # isBug: indicates that this is a compiler bug\n        super(CompilationException, self).__init__()\n\n        assert isinstance(format, str)\n        assert isinstance(isBug, bool)\n        self.message = message\n        self.format = format\n        self.isBug = isBug",
  "def show(self):\n        # TODO: format this message nicely\n        return self.format.format(*self.message)",
  "def __init__(self, format, *message):\n        super(NotSupportedException, self).__init__()\n\n        assert isinstance(format, str)\n        self.message = message\n        self.format = format",
  "def show(self):\n        # TODO: format this message nicely\n        return (self.format + NotSupportedException.archError).format(\n            *self.message)",
  "class EbpfCounter(object):\n    # noinspection PyUnresolvedReferences\n    def __init__(self, hlircounter, program):\n        assert isinstance(hlircounter, p4_counter)\n        assert isinstance(program, ebpfProgram.EbpfProgram)\n\n        self.name = hlircounter.name\n        self.hlircounter = hlircounter\n\n        width = hlircounter.min_width\n        # ebpf counters only work on 64-bits\n        if width <= 64:\n            self.valueTypeName = program.config.uprefix + \"64\"\n        else:\n            raise NotSupportedException(\n                \"{0}: Counters with {1} bits\", hlircounter, width)\n\n        self.dataMapName = self.name\n\n        if ((hlircounter.binding is None) or\n            (hlircounter.binding[0] != P4_DIRECT)):\n            raise NotSupportedException(\n                \"{0}: counter which is not direct\", hlircounter)\n\n        self.autoIncrement = (hlircounter.binding != None and\n                              hlircounter.binding[0] == P4_DIRECT)\n\n        if hlircounter.type is P4_COUNTER_BYTES:\n            self.increment = \"{0}->len\".format(program.packetName)\n        else:\n            self.increment = \"1\"\n\n    def getSize(self, program):\n        if self.hlircounter.instance_count is not None:\n            return self.hlircounter.instance_count\n        if self.autoIncrement:\n            return self.getTable(program).size\n        program.emitWarning(\n            \"{0} does not specify a max_size; using 1024\", self.hlircounter)\n        return 1024\n\n    def getTable(self, program):\n        table = program.getTable(self.hlircounter.binding[1].name)\n        assert isinstance(table, ebpfTable.EbpfTable)\n        return table\n\n    def serialize(self, serializer, program):\n        assert isinstance(serializer, ProgramSerializer)\n\n        # Direct counters have the same key as the associated table\n        # Static counters have integer keys\n        if self.autoIncrement:\n            keyTypeName = \"struct \" + self.getTable(program).keyTypeName\n        else:\n            keyTypeName = program.config.uprefix + \"32\"\n        program.config.serializeTableDeclaration(\n            serializer, self.dataMapName, True, keyTypeName,\n            self.valueTypeName, self.getSize(program))\n\n    def serializeCode(self, keyname, serializer, program):\n        assert isinstance(serializer, ProgramSerializer)\n        assert isinstance(program, ebpfProgram.EbpfProgram)\n\n        serializer.emitIndent()\n        serializer.appendFormat(\"/* Update counter {0} */\", self.name)\n        serializer.newline()\n\n        valueName = \"ctrvalue\"\n        initValuename = \"init_val\"\n\n        serializer.emitIndent()\n        serializer.appendFormat(\"{0} *{1};\", self.valueTypeName, valueName)\n        serializer.newline()\n        serializer.emitIndent()\n        serializer.appendFormat(\"{0} {1};\", self.valueTypeName, initValuename)\n        serializer.newline()\n\n        serializer.emitIndent()\n        serializer.appendLine(\"/* perform lookup */\")\n        serializer.emitIndent()\n        program.config.serializeLookup(\n            serializer, self.dataMapName, keyname, valueName)\n        serializer.newline()\n\n        serializer.emitIndent()\n        serializer.appendFormat(\"if ({0} != NULL) \", valueName)\n        serializer.newline()\n        serializer.increaseIndent()\n        serializer.emitIndent()\n        serializer.appendFormat(\"__sync_fetch_and_add({0}, {1});\",\n                                valueName, self.increment)\n        serializer.newline()\n        serializer.decreaseIndent()\n        serializer.emitIndent()\n\n        serializer.append(\"else \")\n        serializer.blockStart()\n        serializer.emitIndent()\n        serializer.appendFormat(\"{0} = {1};\", initValuename, self.increment)\n        serializer.newline()\n\n        serializer.emitIndent()\n        program.config.serializeUpdate(\n            serializer, self.dataMapName, keyname, initValuename)\n        serializer.newline()\n        serializer.blockEnd(True)",
  "def __init__(self, hlircounter, program):\n        assert isinstance(hlircounter, p4_counter)\n        assert isinstance(program, ebpfProgram.EbpfProgram)\n\n        self.name = hlircounter.name\n        self.hlircounter = hlircounter\n\n        width = hlircounter.min_width\n        # ebpf counters only work on 64-bits\n        if width <= 64:\n            self.valueTypeName = program.config.uprefix + \"64\"\n        else:\n            raise NotSupportedException(\n                \"{0}: Counters with {1} bits\", hlircounter, width)\n\n        self.dataMapName = self.name\n\n        if ((hlircounter.binding is None) or\n            (hlircounter.binding[0] != P4_DIRECT)):\n            raise NotSupportedException(\n                \"{0}: counter which is not direct\", hlircounter)\n\n        self.autoIncrement = (hlircounter.binding != None and\n                              hlircounter.binding[0] == P4_DIRECT)\n\n        if hlircounter.type is P4_COUNTER_BYTES:\n            self.increment = \"{0}->len\".format(program.packetName)\n        else:\n            self.increment = \"1\"",
  "def getSize(self, program):\n        if self.hlircounter.instance_count is not None:\n            return self.hlircounter.instance_count\n        if self.autoIncrement:\n            return self.getTable(program).size\n        program.emitWarning(\n            \"{0} does not specify a max_size; using 1024\", self.hlircounter)\n        return 1024",
  "def getTable(self, program):\n        table = program.getTable(self.hlircounter.binding[1].name)\n        assert isinstance(table, ebpfTable.EbpfTable)\n        return table",
  "def serialize(self, serializer, program):\n        assert isinstance(serializer, ProgramSerializer)\n\n        # Direct counters have the same key as the associated table\n        # Static counters have integer keys\n        if self.autoIncrement:\n            keyTypeName = \"struct \" + self.getTable(program).keyTypeName\n        else:\n            keyTypeName = program.config.uprefix + \"32\"\n        program.config.serializeTableDeclaration(\n            serializer, self.dataMapName, True, keyTypeName,\n            self.valueTypeName, self.getSize(program))",
  "def serializeCode(self, keyname, serializer, program):\n        assert isinstance(serializer, ProgramSerializer)\n        assert isinstance(program, ebpfProgram.EbpfProgram)\n\n        serializer.emitIndent()\n        serializer.appendFormat(\"/* Update counter {0} */\", self.name)\n        serializer.newline()\n\n        valueName = \"ctrvalue\"\n        initValuename = \"init_val\"\n\n        serializer.emitIndent()\n        serializer.appendFormat(\"{0} *{1};\", self.valueTypeName, valueName)\n        serializer.newline()\n        serializer.emitIndent()\n        serializer.appendFormat(\"{0} {1};\", self.valueTypeName, initValuename)\n        serializer.newline()\n\n        serializer.emitIndent()\n        serializer.appendLine(\"/* perform lookup */\")\n        serializer.emitIndent()\n        program.config.serializeLookup(\n            serializer, self.dataMapName, keyname, valueName)\n        serializer.newline()\n\n        serializer.emitIndent()\n        serializer.appendFormat(\"if ({0} != NULL) \", valueName)\n        serializer.newline()\n        serializer.increaseIndent()\n        serializer.emitIndent()\n        serializer.appendFormat(\"__sync_fetch_and_add({0}, {1});\",\n                                valueName, self.increment)\n        serializer.newline()\n        serializer.decreaseIndent()\n        serializer.emitIndent()\n\n        serializer.append(\"else \")\n        serializer.blockStart()\n        serializer.emitIndent()\n        serializer.appendFormat(\"{0} = {1};\", initValuename, self.increment)\n        serializer.newline()\n\n        serializer.emitIndent()\n        program.config.serializeUpdate(\n            serializer, self.dataMapName, keyname, initValuename)\n        serializer.newline()\n        serializer.blockEnd(True)",
  "def positive_int(val):\n    try:\n        ival = int(val)\n    except ValueError:\n        raise argparse.ArgumentTypeError(\"must be an integer\")\n\n    if ival < 0:\n        raise argparse.ArgumentTypeError(\"must be positive\")\n    return ival",
  "def positive_nonzero_int(val):\n    ival = positive_int(val)\n    if ival == 0:\n        raise argparse.ArgumentTypeError(\"must be nonzero\")\n    return ival",
  "def signal_ignore(signal, frame):\n    print()",
  "class Probe(object):\n        probe_count = 0\n        streq_index = 0\n        max_events = None\n        event_count = 0\n        first_ts = 0\n        print_time = False\n        use_localtime = True\n        time_field = False\n        print_cpu = False\n        print_address = False\n        tgid = -1\n        pid = -1\n        page_cnt = None\n\n        @classmethod\n        def configure(cls, args):\n                cls.max_events = args.max_events\n                cls.print_time = args.timestamp or args.time\n                cls.use_localtime = not args.timestamp\n                cls.time_field = cls.print_time and (not cls.use_localtime)\n                cls.print_cpu = args.print_cpu\n                cls.print_address = args.address\n                cls.first_ts = BPF.monotonic_time()\n                cls.tgid = args.tgid or -1\n                cls.pid = args.pid or -1\n                cls.page_cnt = args.buffer_pages\n                cls.bin_cmp = args.bin_cmp\n\n        def __init__(self, probe, string_size, kernel_stack, user_stack):\n                self.usdt = None\n                self.streq_functions = \"\"\n                self.raw_probe = probe\n                self.string_size = string_size\n                self.kernel_stack = kernel_stack\n                self.user_stack = user_stack\n                Probe.probe_count += 1\n                self._parse_probe()\n                self.probe_num = Probe.probe_count\n                self.probe_name = \"probe_%s_%d\" % \\\n                                (self._display_function(), self.probe_num)\n                self.probe_name = re.sub(r'[^A-Za-z0-9_]', '_',\n                                         self.probe_name)\n\n                # compiler can generate proper codes for function\n                # signatures with \"syscall__\" prefix\n                if self.is_syscall_kprobe:\n                        self.probe_name = \"syscall__\" + self.probe_name[6:]\n\n        def __str__(self):\n                return \"%s:%s:%s FLT=%s ACT=%s/%s\" % (self.probe_type,\n                        self.library, self._display_function(), self.filter,\n                        self.types, self.values)\n\n        def is_default_action(self):\n                return self.python_format == \"\"\n\n        def _bail(self, error):\n                raise ValueError(\"error in probe '%s': %s\" %\n                                 (self.raw_probe, error))\n\n        def _parse_probe(self):\n                text = self.raw_probe\n\n                # There might be a function signature preceding the actual\n                # filter/print part, or not. Find the probe specifier first --\n                # it ends with either a space or an open paren ( for the\n                # function signature part.\n                #                                          opt. signature\n                #                               probespec       |      rest\n                #                               ---------  ----------   --\n                (spec, sig, rest) = re.match(r'([^ \\t\\(]+)(\\([^\\(]*\\))?(.*)',\n                                             text).groups()\n\n                self._parse_spec(spec)\n                # Remove the parens\n                self.signature = sig[1:-1] if sig else None\n                if self.signature and self.probe_type in ['u', 't']:\n                        self._bail(\"USDT and tracepoint probes can't have \" +\n                                   \"a function signature; use arg1, arg2, \" +\n                                   \"... instead\")\n\n                text = rest.lstrip()\n                # If we now have a (, wait for the balanced closing ) and that\n                # will be the predicate\n                self.filter = None\n                if len(text) > 0 and text[0] == \"(\":\n                        balance = 1\n                        for i in range(1, len(text)):\n                                if text[i] == \"(\":\n                                        balance += 1\n                                if text[i] == \")\":\n                                        balance -= 1\n                                if balance == 0:\n                                        self._parse_filter(text[:i + 1])\n                                        text = text[i + 1:]\n                                        break\n                        if self.filter is None:\n                                self._bail(\"unmatched end of predicate\")\n\n                if self.filter is None:\n                        self.filter = \"1\"\n\n                # The remainder of the text is the printf action\n                self._parse_action(text.lstrip())\n\n        def _parse_spec(self, spec):\n                parts = spec.split(\":\")\n                # Two special cases: 'func' means 'p::func', 'lib:func' means\n                # 'p:lib:func'. Other combinations need to provide an empty\n                # value between delimiters, e.g. 'r::func' for a kretprobe on\n                # the function func.\n                if len(parts) == 1:\n                        parts = [\"p\", \"\", parts[0]]\n                elif len(parts) == 2:\n                        parts = [\"p\", parts[0], parts[1]]\n                if len(parts[0]) == 0:\n                        self.probe_type = \"p\"\n                elif parts[0] in [\"p\", \"r\", \"t\", \"u\"]:\n                        self.probe_type = parts[0]\n                else:\n                        self._bail(\"probe type must be '', 'p', 't', 'r', \" +\n                                   \"or 'u', but got '%s'\" % parts[0])\n                if self.probe_type == \"t\":\n                        self.tp_category = parts[1]\n                        self.tp_event = parts[2]\n                        self.library = \"\"       # kernel\n                        self.function = \"\"      # from TRACEPOINT_PROBE\n                elif self.probe_type == \"u\":\n                        self.library = ':'.join(parts[1:-1])\n                        self.usdt_name = parts[-1]\n                        self.function = \"\"      # no function, just address\n                        # We will discover the USDT provider by matching on\n                        # the USDT name in the specified library\n                        self._find_usdt_probe()\n                else:\n                        self.library = ':'.join(parts[1:-1])\n                        self.function = parts[-1]\n\n                # only x64 syscalls needs checking, no other syscall wrapper yet.\n                self.is_syscall_kprobe = False\n                if self.probe_type == \"p\" and len(self.library) == 0 and \\\n                   self.function[:10] == \"__x64_sys_\":\n                        self.is_syscall_kprobe = True\n\n        def _find_usdt_probe(self):\n                target = Probe.pid if Probe.pid and Probe.pid != -1 \\\n                                   else Probe.tgid\n                self.usdt = USDT(path=self.library, pid=target)\n                for probe in self.usdt.enumerate_probes():\n                        if probe.name == self.usdt_name.encode('ascii'):\n                                return  # Found it, will enable later\n                self._bail(\"unrecognized USDT probe %s\" % self.usdt_name)\n\n        def _parse_filter(self, filt):\n                self.filter = self._rewrite_expr(filt)\n\n        def _parse_types(self, fmt):\n                for match in re.finditer(\n                            r'[^%]%(s|u|d|lu|llu|ld|lld|hu|hd|x|lx|llx|c|K|U)', fmt):\n                        self.types.append(match.group(1))\n                fmt = re.sub(r'([^%]%)(u|d|lu|llu|ld|lld|hu|hd)', r'\\1d', fmt)\n                fmt = re.sub(r'([^%]%)(x|lx|llx)', r'\\1x', fmt)\n                fmt = re.sub('%K|%U', '%s', fmt)\n                self.python_format = fmt.strip('\"')\n\n        def _parse_action(self, action):\n                self.values = []\n                self.types = []\n                self.python_format = \"\"\n                if len(action) == 0:\n                        return\n\n                action = action.strip()\n                match = re.search(r'(\\\".*?\\\"),?(.*)', action)\n                if match is None:\n                        self._bail(\"expected format string in \\\"s\")\n\n                self.raw_format = match.group(1)\n                self._parse_types(self.raw_format)\n                for part in re.split('(?<!\"),', match.group(2)):\n                        part = self._rewrite_expr(part)\n                        if len(part) > 0:\n                                self.values.append(part)\n\n        aliases_arg = {\n                \"arg1\": \"PT_REGS_PARM1(ctx)\",\n                \"arg2\": \"PT_REGS_PARM2(ctx)\",\n                \"arg3\": \"PT_REGS_PARM3(ctx)\",\n                \"arg4\": \"PT_REGS_PARM4(ctx)\",\n                \"arg5\": \"PT_REGS_PARM5(ctx)\",\n                \"arg6\": \"PT_REGS_PARM6(ctx)\",\n        }\n\n        aliases_indarg = {\n                \"arg1\": \"({u64 _val; struct pt_regs *_ctx = (struct pt_regs *)PT_REGS_PARM1(ctx);\"\n                        \"  bpf_probe_read(&_val, sizeof(_val), &(PT_REGS_PARM1(_ctx))); _val;})\",\n                \"arg2\": \"({u64 _val; struct pt_regs *_ctx = (struct pt_regs *)PT_REGS_PARM1(ctx);\"\n                        \"  bpf_probe_read(&_val, sizeof(_val), &(PT_REGS_PARM2(_ctx))); _val;})\",\n                \"arg3\": \"({u64 _val; struct pt_regs *_ctx = (struct pt_regs *)PT_REGS_PARM1(ctx);\"\n                        \"  bpf_probe_read(&_val, sizeof(_val), &(PT_REGS_PARM3(_ctx))); _val;})\",\n                \"arg4\": \"({u64 _val; struct pt_regs *_ctx = (struct pt_regs *)PT_REGS_PARM1(ctx);\"\n                        \"  bpf_probe_read(&_val, sizeof(_val), &(PT_REGS_PARM4(_ctx))); _val;})\",\n                \"arg5\": \"({u64 _val; struct pt_regs *_ctx = (struct pt_regs *)PT_REGS_PARM1(ctx);\"\n                        \"  bpf_probe_read(&_val, sizeof(_val), &(PT_REGS_PARM5(_ctx))); _val;})\",\n                \"arg6\": \"({u64 _val; struct pt_regs *_ctx = (struct pt_regs *)PT_REGS_PARM1(ctx);\"\n                        \"  bpf_probe_read(&_val, sizeof(_val), &(PT_REGS_PARM6(_ctx))); _val;})\",\n        }\n\n        aliases_common = {\n                \"retval\": \"PT_REGS_RC(ctx)\",\n                \"$uid\": \"(unsigned)(bpf_get_current_uid_gid() & 0xffffffff)\",\n                \"$gid\": \"(unsigned)(bpf_get_current_uid_gid() >> 32)\",\n                \"$pid\": \"(unsigned)(bpf_get_current_pid_tgid() & 0xffffffff)\",\n                \"$tgid\": \"(unsigned)(bpf_get_current_pid_tgid() >> 32)\",\n                \"$cpu\": \"bpf_get_smp_processor_id()\",\n                \"$task\" : \"((struct task_struct *)bpf_get_current_task())\"\n        }\n\n        def _generate_streq_function(self, string):\n                fname = \"streq_%d\" % Probe.streq_index\n                Probe.streq_index += 1\n                self.streq_functions += \"\"\"\nstatic inline bool %s(char const *ignored, uintptr_t str) {\n        char needle[] = %s;\n        char haystack[sizeof(needle)];\n        bpf_probe_read(&haystack, sizeof(haystack), (void *)str);\n        for (int i = 0; i < sizeof(needle) - 1; ++i) {\n                if (needle[i] != haystack[i]) {\n                        return false;\n                }\n        }\n        return true;\n}\n                \"\"\" % (fname, string)\n                return fname\n\n        def _rewrite_expr(self, expr):\n                if self.is_syscall_kprobe:\n                    for alias, replacement in Probe.aliases_indarg.items():\n                        expr = expr.replace(alias, replacement)\n                else:\n                    for alias, replacement in Probe.aliases_arg.items():\n                        # For USDT probes, we replace argN values with the\n                        # actual arguments for that probe obtained using\n                        # bpf_readarg_N macros emitted at BPF construction.\n                        if self.probe_type == \"u\":\n                                continue\n                        expr = expr.replace(alias, replacement)\n                for alias, replacement in Probe.aliases_common.items():\n                    expr = expr.replace(alias, replacement)\n                if self.bin_cmp:\n                    STRCMP_RE = 'STRCMP\\\\(\\\"([^\"]+)\\\\\"'\n                else:\n                    STRCMP_RE = 'STRCMP\\\\((\"[^\"]+\\\\\")'\n                matches = re.finditer(STRCMP_RE, expr)\n                for match in matches:\n                        string = match.group(1)\n                        fname = self._generate_streq_function(string)\n                        expr = expr.replace(\"STRCMP\", fname, 1)\n                return expr\n\n        p_type = {\"u\": ct.c_uint, \"d\": ct.c_int, \"lu\": ct.c_ulong,\n                  \"ld\": ct.c_long,\n                  \"llu\": ct.c_ulonglong, \"lld\": ct.c_longlong,\n                  \"hu\": ct.c_ushort, \"hd\": ct.c_short,\n                  \"x\": ct.c_uint, \"lx\": ct.c_ulong, \"llx\": ct.c_ulonglong,\n                  \"c\": ct.c_ubyte,\n                  \"K\": ct.c_ulonglong, \"U\": ct.c_ulonglong}\n\n        def _generate_python_field_decl(self, idx, fields):\n                field_type = self.types[idx]\n                if field_type == \"s\":\n                        ptype = ct.c_char * self.string_size\n                else:\n                        ptype = Probe.p_type[field_type]\n                fields.append((\"v%d\" % idx, ptype))\n\n        def _generate_python_data_decl(self):\n                self.python_struct_name = \"%s_%d_Data\" % \\\n                                (self._display_function(), self.probe_num)\n                fields = []\n                if self.time_field:\n                    fields.append((\"timestamp_ns\", ct.c_ulonglong))\n                if self.print_cpu:\n                    fields.append((\"cpu\", ct.c_int))\n                fields.extend([\n                        (\"tgid\", ct.c_uint),\n                        (\"pid\", ct.c_uint),\n                        (\"comm\", ct.c_char * 16)       # TASK_COMM_LEN\n                ])\n                for i in range(0, len(self.types)):\n                        self._generate_python_field_decl(i, fields)\n                if self.kernel_stack:\n                        fields.append((\"kernel_stack_id\", ct.c_int))\n                if self.user_stack:\n                        fields.append((\"user_stack_id\", ct.c_int))\n                return type(self.python_struct_name, (ct.Structure,),\n                            dict(_fields_=fields))\n\n        c_type = {\"u\": \"unsigned int\", \"d\": \"int\",\n                  \"lu\": \"unsigned long\", \"ld\": \"long\",\n                  \"llu\": \"unsigned long long\", \"lld\": \"long long\",\n                  \"hu\": \"unsigned short\", \"hd\": \"short\",\n                  \"x\": \"unsigned int\", \"lx\": \"unsigned long\",\n                  \"llx\": \"unsigned long long\",\n                  \"c\": \"char\", \"K\": \"unsigned long long\",\n                  \"U\": \"unsigned long long\"}\n        fmt_types = c_type.keys()\n\n        def _generate_field_decl(self, idx):\n                field_type = self.types[idx]\n                if field_type == \"s\":\n                        return \"char v%d[%d];\\n\" % (idx, self.string_size)\n                if field_type in Probe.fmt_types:\n                        return \"%s v%d;\\n\" % (Probe.c_type[field_type], idx)\n                self._bail(\"unrecognized format specifier %s\" % field_type)\n\n        def _generate_data_decl(self):\n                # The BPF program will populate values into the struct\n                # according to the format string, and the Python program will\n                # construct the final display string.\n                self.events_name = \"%s_events\" % self.probe_name\n                self.struct_name = \"%s_data_t\" % self.probe_name\n                self.stacks_name = \"%s_stacks\" % self.probe_name\n                stack_table = \"BPF_STACK_TRACE(%s, 1024);\" % self.stacks_name \\\n                              if (self.kernel_stack or self.user_stack) else \"\"\n                data_fields = \"\"\n                for i, field_type in enumerate(self.types):\n                        data_fields += \"        \" + \\\n                                       self._generate_field_decl(i)\n                time_str = \"u64 timestamp_ns;\" if self.time_field else \"\"\n                cpu_str = \"int cpu;\" if self.print_cpu else \"\"\n                kernel_stack_str = \"       int kernel_stack_id;\" \\\n                                   if self.kernel_stack else \"\"\n                user_stack_str = \"       int user_stack_id;\" \\\n                                 if self.user_stack else \"\"\n\n                text = \"\"\"\nstruct %s\n{\n%s\n%s\n        u32 tgid;\n        u32 pid;\n        char comm[TASK_COMM_LEN];\n%s\n%s\n%s\n};\n\nBPF_PERF_OUTPUT(%s);\n%s\n\"\"\"\n                return text % (self.struct_name, time_str, cpu_str, data_fields,\n                               kernel_stack_str, user_stack_str,\n                               self.events_name, stack_table)\n\n        def _generate_field_assign(self, idx):\n                field_type = self.types[idx]\n                expr = self.values[idx].strip()\n                text = \"\"\n                if self.probe_type == \"u\" and expr[0:3] == \"arg\":\n                        arg_index = int(expr[3])\n                        arg_ctype = self.usdt.get_probe_arg_ctype(\n                                self.usdt_name, arg_index - 1)\n                        text = (\"        %s %s = 0;\\n\" +\n                                \"        bpf_usdt_readarg(%s, ctx, &%s);\\n\") \\\n                                % (arg_ctype, expr, expr[3], expr)\n\n                if field_type == \"s\":\n                        return text + \"\"\"\n        if (%s != 0) {\n                void *__tmp = (void *)%s;\n                bpf_probe_read(&__data.v%d, sizeof(__data.v%d), __tmp);\n        }\n                \"\"\" % (expr, expr, idx, idx)\n                if field_type in Probe.fmt_types:\n                        return text + \"        __data.v%d = (%s)%s;\\n\" % \\\n                                        (idx, Probe.c_type[field_type], expr)\n                self._bail(\"unrecognized field type %s\" % field_type)\n\n        def _generate_usdt_filter_read(self):\n            text = \"\"\n            if self.probe_type != \"u\":\n                    return text\n            for arg, _ in Probe.aliases_arg.items():\n                    if not (arg in self.filter):\n                            continue\n                    arg_index = int(arg.replace(\"arg\", \"\"))\n                    arg_ctype = self.usdt.get_probe_arg_ctype(\n                            self.usdt_name, arg_index - 1)\n                    if not arg_ctype:\n                            self._bail(\"Unable to determine type of {} \"\n                                       \"in the filter\".format(arg))\n                    text += \"\"\"\n        {} {}_filter;\n        bpf_usdt_readarg({}, ctx, &{}_filter);\n                    \"\"\".format(arg_ctype, arg, arg_index, arg)\n                    self.filter = self.filter.replace(\n                            arg, \"{}_filter\".format(arg))\n            return text\n\n        def generate_program(self, include_self):\n                data_decl = self._generate_data_decl()\n                if Probe.pid != -1:\n                        pid_filter = \"\"\"\n        if (__pid != %d) { return 0; }\n                \"\"\" % Probe.pid\n                # uprobes can have a built-in tgid filter passed to\n                # attach_uprobe, hence the check here -- for kprobes, we\n                # need to do the tgid test by hand:\n                elif len(self.library) == 0 and Probe.tgid != -1:\n                        pid_filter = \"\"\"\n        if (__tgid != %d) { return 0; }\n                \"\"\" % Probe.tgid\n                elif not include_self:\n                        pid_filter = \"\"\"\n        if (__tgid == %d) { return 0; }\n                \"\"\" % os.getpid()\n                else:\n                        pid_filter = \"\"\n\n                prefix = \"\"\n                signature = \"struct pt_regs *ctx\"\n                if self.signature:\n                        signature += \", \" + self.signature\n\n                data_fields = \"\"\n                for i, expr in enumerate(self.values):\n                        data_fields += self._generate_field_assign(i)\n\n                if self.probe_type == \"t\":\n                        heading = \"TRACEPOINT_PROBE(%s, %s)\" % \\\n                                  (self.tp_category, self.tp_event)\n                        ctx_name = \"args\"\n                else:\n                        heading = \"int %s(%s)\" % (self.probe_name, signature)\n                        ctx_name = \"ctx\"\n\n                time_str = \"\"\"\n        __data.timestamp_ns = bpf_ktime_get_ns();\"\"\" if self.time_field else \"\"\n                cpu_str = \"\"\"\n        __data.cpu = bpf_get_smp_processor_id();\"\"\" if self.print_cpu else \"\"\n                stack_trace = \"\"\n                if self.user_stack:\n                        stack_trace += \"\"\"\n        __data.user_stack_id = %s.get_stackid(\n          %s, BPF_F_REUSE_STACKID | BPF_F_USER_STACK\n        );\"\"\" % (self.stacks_name, ctx_name)\n                if self.kernel_stack:\n                        stack_trace += \"\"\"\n        __data.kernel_stack_id = %s.get_stackid(\n          %s, BPF_F_REUSE_STACKID\n        );\"\"\" % (self.stacks_name, ctx_name)\n\n                text = heading + \"\"\"\n{\n        u64 __pid_tgid = bpf_get_current_pid_tgid();\n        u32 __tgid = __pid_tgid >> 32;\n        u32 __pid = __pid_tgid; // implicit cast to u32 for bottom half\n        %s\n        %s\n        %s\n        if (!(%s)) return 0;\n\n        struct %s __data = {0};\n        %s\n        %s\n        __data.tgid = __tgid;\n        __data.pid = __pid;\n        bpf_get_current_comm(&__data.comm, sizeof(__data.comm));\n%s\n%s\n        %s.perf_submit(%s, &__data, sizeof(__data));\n        return 0;\n}\n\"\"\"\n                text = text % (pid_filter, prefix,\n                               self._generate_usdt_filter_read(), self.filter,\n                               self.struct_name, time_str, cpu_str, data_fields,\n                               stack_trace, self.events_name, ctx_name)\n\n                return self.streq_functions + data_decl + \"\\n\" + text\n\n        @classmethod\n        def _time_off_str(cls, timestamp_ns):\n                return \"%.6f\" % (1e-9 * (timestamp_ns - cls.first_ts))\n\n        def _display_function(self):\n                if self.probe_type == 'p' or self.probe_type == 'r':\n                        return self.function\n                elif self.probe_type == 'u':\n                        return self.usdt_name\n                else:   # self.probe_type == 't'\n                        return self.tp_event\n\n        def print_stack(self, bpf, stack_id, tgid):\n            if stack_id < 0:\n                print(\"        %d\" % stack_id)\n                return\n\n            stack = list(bpf.get_table(self.stacks_name).walk(stack_id))\n            for addr in stack:\n                print(\"        \", end=\"\")\n                if Probe.print_address:\n                    print(\"%16x \" % addr, end=\"\")\n                print(\"%s\" % (bpf.sym(addr, tgid,\n                                     show_module=True, show_offset=True)))\n\n        def _format_message(self, bpf, tgid, values):\n                # Replace each %K with kernel sym and %U with user sym in tgid\n                kernel_placeholders = [i for i, t in enumerate(self.types)\n                                       if t == 'K']\n                user_placeholders = [i for i, t in enumerate(self.types)\n                                     if t == 'U']\n                for kp in kernel_placeholders:\n                        values[kp] = bpf.ksym(values[kp], show_offset=True)\n                for up in user_placeholders:\n                        values[up] = bpf.sym(values[up], tgid,\n                                           show_module=True, show_offset=True)\n                return self.python_format % tuple(values)\n\n        def print_event(self, bpf, cpu, data, size):\n                # Cast as the generated structure type and display\n                # according to the format string in the probe.\n                event = ct.cast(data, ct.POINTER(self.python_struct)).contents\n                values = map(lambda i: getattr(event, \"v%d\" % i),\n                             range(0, len(self.values)))\n                msg = self._format_message(bpf, event.tgid, values)\n                if Probe.print_time:\n                    time = strftime(\"%H:%M:%S\") if Probe.use_localtime else \\\n                           Probe._time_off_str(event.timestamp_ns)\n                    print(\"%-8s \" % time[:8], end=\"\")\n                if Probe.print_cpu:\n                    print(\"%-3s \" % event.cpu, end=\"\")\n                print(\"%-7d %-7d %-15s %-16s %s\" %\n                      (event.tgid, event.pid,\n                       event.comm.decode('utf-8', 'replace'),\n                       self._display_function(), msg))\n\n                if self.kernel_stack:\n                        self.print_stack(bpf, event.kernel_stack_id, -1)\n                if self.user_stack:\n                        self.print_stack(bpf, event.user_stack_id, event.tgid)\n                if self.user_stack or self.kernel_stack:\n                        print(\"\")\n\n                Probe.event_count += 1\n                if Probe.max_events is not None and \\\n                   Probe.event_count >= Probe.max_events:\n                        exit()\n\n        def attach(self, bpf, verbose):\n                if len(self.library) == 0:\n                        self._attach_k(bpf)\n                else:\n                        self._attach_u(bpf)\n                self.python_struct = self._generate_python_data_decl()\n                callback = partial(self.print_event, bpf)\n                bpf[self.events_name].open_perf_buffer(callback,\n                        page_cnt=self.page_cnt)\n\n        def _attach_k(self, bpf):\n                if self.probe_type == \"r\":\n                        bpf.attach_kretprobe(event=self.function,\n                                             fn_name=self.probe_name)\n                elif self.probe_type == \"p\":\n                        bpf.attach_kprobe(event=self.function,\n                                          fn_name=self.probe_name)\n                # Note that tracepoints don't need an explicit attach\n\n        def _attach_u(self, bpf):\n                libpath = BPF.find_library(self.library)\n                if libpath is None:\n                        # This might be an executable (e.g. 'bash')\n                        libpath = BPF.find_exe(self.library)\n                if libpath is None or len(libpath) == 0:\n                        self._bail(\"unable to find library %s\" % self.library)\n\n                if self.probe_type == \"u\":\n                        pass    # Was already enabled by the BPF constructor\n                elif self.probe_type == \"r\":\n                        bpf.attach_uretprobe(name=libpath,\n                                             sym=self.function,\n                                             fn_name=self.probe_name,\n                                             pid=Probe.tgid)\n                else:\n                        bpf.attach_uprobe(name=libpath,\n                                          sym=self.function,\n                                          fn_name=self.probe_name,\n                                          pid=Probe.tgid)",
  "class Tool(object):\n        DEFAULT_PERF_BUFFER_PAGES = 64\n        examples = \"\"\"\nEXAMPLES:\n\ntrace do_sys_open\n        Trace the open syscall and print a default trace message when entered\ntrace 'do_sys_open \"%s\", arg2'\n        Trace the open syscall and print the filename being opened\ntrace 'sys_read (arg3 > 20000) \"read %d bytes\", arg3'\n        Trace the read syscall and print a message for reads >20000 bytes\ntrace 'r::do_sys_open \"%llx\", retval'\n        Trace the return from the open syscall and print the return value\ntrace 'c:open (arg2 == 42) \"%s %d\", arg1, arg2'\n        Trace the open() call from libc only if the flags (arg2) argument is 42\ntrace 'c:malloc \"size = %d\", arg1'\n        Trace malloc calls and print the size being allocated\ntrace 'p:c:write (arg1 == 1) \"writing %d bytes to STDOUT\", arg3'\n        Trace the write() call from libc to monitor writes to STDOUT\ntrace 'r::__kmalloc (retval == 0) \"kmalloc failed!\"'\n        Trace returns from __kmalloc which returned a null pointer\ntrace 'r:c:malloc (retval) \"allocated = %x\", retval'\n        Trace returns from malloc and print non-NULL allocated buffers\ntrace 't:block:block_rq_complete \"sectors=%d\", args->nr_sector'\n        Trace the block_rq_complete kernel tracepoint and print # of tx sectors\ntrace 'u:pthread:pthread_create (arg4 != 0)'\n        Trace the USDT probe pthread_create when its 4th argument is non-zero\ntrace 'p::SyS_nanosleep(struct timespec *ts) \"sleep for %lld ns\", ts->tv_nsec'\n        Trace the nanosleep syscall and print the sleep duration in ns\ntrace -I 'linux/fs.h' \\\\\n      'p::uprobe_register(struct inode *inode) \"a_ops = %llx\", inode->i_mapping->a_ops'\n        Trace the uprobe_register inode mapping ops, and the symbol can be found\n        in /proc/kallsyms\ntrace -I 'kernel/sched/sched.h' \\\\\n      'p::__account_cfs_rq_runtime(struct cfs_rq *cfs_rq) \"%d\", cfs_rq->runtime_remaining'\n        Trace the cfs scheduling runqueue remaining runtime. The struct cfs_rq is defined\n        in kernel/sched/sched.h which is in kernel source tree and not in kernel-devel\n        package.  So this command needs to run at the kernel source tree root directory\n        so that the added header file can be found by the compiler.\ntrace -I 'net/sock.h' \\\\\n      'udpv6_sendmsg(struct sock *sk) (sk->sk_dport == 13568)'\n        Trace udpv6 sendmsg calls only if socket's destination port is equal\n        to 53 (DNS; 13568 in big endian order)\ntrace -I 'linux/fs_struct.h' 'mntns_install \"users = %d\", $task->fs->users'\n        Trace the number of users accessing the file system of the current task\n\"\"\"\n\n        def __init__(self):\n                parser = argparse.ArgumentParser(description=\"Attach to \" +\n                  \"functions and print trace messages.\",\n                  formatter_class=argparse.RawDescriptionHelpFormatter,\n                  epilog=Tool.examples)\n                parser.add_argument(\"-b\", \"--buffer-pages\", type=int,\n                  default=Tool.DEFAULT_PERF_BUFFER_PAGES,\n                  help=\"number of pages to use for perf_events ring buffer \"\n                       \"(default: %(default)d)\")\n                # we'll refer to the userspace concepts of \"pid\" and \"tid\" by\n                # their kernel names -- tgid and pid -- inside the script\n                parser.add_argument(\"-p\", \"--pid\", type=int, metavar=\"PID\",\n                  dest=\"tgid\", help=\"id of the process to trace (optional)\")\n                parser.add_argument(\"-L\", \"--tid\", type=int, metavar=\"TID\",\n                  dest=\"pid\", help=\"id of the thread to trace (optional)\")\n                parser.add_argument(\"-v\", \"--verbose\", action=\"store_true\",\n                  help=\"print resulting BPF program code before executing\")\n                parser.add_argument(\"-Z\", \"--string-size\", type=int,\n                  default=80, help=\"maximum size to read from strings\")\n                parser.add_argument(\"-S\", \"--include-self\",\n                  action=\"store_true\",\n                  help=\"do not filter trace's own pid from the trace\")\n                parser.add_argument(\"-M\", \"--max-events\", type=int,\n                  help=\"number of events to print before quitting\")\n                parser.add_argument(\"-t\", \"--timestamp\", action=\"store_true\",\n                  help=\"print timestamp column (offset from trace start)\")\n                parser.add_argument(\"-T\", \"--time\", action=\"store_true\",\n                  help=\"print time column\")\n                parser.add_argument(\"-C\", \"--print_cpu\", action=\"store_true\",\n                  help=\"print CPU id\")\n                parser.add_argument(\"-B\", \"--bin_cmp\", action=\"store_true\",\n                  help=\"allow to use STRCMP with binary values\")\n                parser.add_argument(\"-K\", \"--kernel-stack\",\n                  action=\"store_true\", help=\"output kernel stack trace\")\n                parser.add_argument(\"-U\", \"--user-stack\",\n                  action=\"store_true\", help=\"output user stack trace\")\n                parser.add_argument(\"-a\", \"--address\", action=\"store_true\",\n                  help=\"print virtual address in stacks\")\n                parser.add_argument(metavar=\"probe\", dest=\"probes\", nargs=\"+\",\n                  help=\"probe specifier (see examples)\")\n                parser.add_argument(\"-I\", \"--include\", action=\"append\",\n                  metavar=\"header\",\n                  help=\"additional header files to include in the BPF program \"\n                       \"as either full path, \"\n                       \"or relative to current working directory, \"\n                       \"or relative to default kernel header search path\")\n                parser.add_argument(\"--ebpf\", action=\"store_true\",\n                  help=argparse.SUPPRESS)\n                self.args = parser.parse_args()\n                if self.args.tgid and self.args.pid:\n                        parser.error(\"only one of -p and -L may be specified\")\n\n        def _create_probes(self):\n                Probe.configure(self.args)\n                self.probes = []\n                for probe_spec in self.args.probes:\n                        self.probes.append(Probe(\n                                probe_spec, self.args.string_size,\n                                self.args.kernel_stack, self.args.user_stack))\n\n        def _generate_program(self):\n                self.program = \"\"\"\n#include <linux/ptrace.h>\n#include <linux/sched.h>        /* For TASK_COMM_LEN */\n\n\"\"\"\n                for include in (self.args.include or []):\n                        if include.startswith((\".\", \"/\")):\n                                include = os.path.abspath(include)\n                                self.program += \"#include \\\"%s\\\"\\n\" % include\n                        else:\n                                self.program += \"#include <%s>\\n\" % include\n                self.program += BPF.generate_auto_includes(\n                        map(lambda p: p.raw_probe, self.probes))\n                for probe in self.probes:\n                        self.program += probe.generate_program(\n                                        self.args.include_self)\n\n                if self.args.verbose or self.args.ebpf:\n                        print(self.program)\n                        if self.args.ebpf:\n                                exit()\n\n        def _attach_probes(self):\n                usdt_contexts = []\n                for probe in self.probes:\n                    if probe.usdt:\n                        # USDT probes must be enabled before the BPF object\n                        # is initialized, because that's where the actual\n                        # uprobe is being attached.\n                        probe.usdt.enable_probe(\n                                probe.usdt_name, probe.probe_name)\n                        if self.args.verbose:\n                                print(probe.usdt.get_text())\n                        usdt_contexts.append(probe.usdt)\n                self.bpf = BPF(text=self.program, usdt_contexts=usdt_contexts)\n                for probe in self.probes:\n                        if self.args.verbose:\n                                print(probe)\n                        probe.attach(self.bpf, self.args.verbose)\n\n        def _main_loop(self):\n                all_probes_trivial = all(map(Probe.is_default_action,\n                                             self.probes))\n\n                # Print header\n                if self.args.timestamp or self.args.time:\n                    print(\"%-8s \" % \"TIME\", end=\"\");\n                if self.args.print_cpu:\n                    print(\"%-3s \" % \"CPU\", end=\"\");\n                print(\"%-7s %-7s %-15s %-16s %s\" %\n                      (\"PID\", \"TID\", \"COMM\", \"FUNC\",\n                      \"-\" if not all_probes_trivial else \"\"))\n\n                while True:\n                        self.bpf.perf_buffer_poll()\n\n        def run(self):\n                try:\n                        self._create_probes()\n                        self._generate_program()\n                        self._attach_probes()\n                        self._main_loop()\n                except:\n                        exc_info = sys.exc_info()\n                        sys_exit = exc_info[0] is SystemExit\n                        if self.args.verbose:\n                                traceback.print_exc()\n                        elif not sys_exit:\n                                print(exc_info[1])\n                        exit(0 if sys_exit else 1)",
  "def configure(cls, args):\n                cls.max_events = args.max_events\n                cls.print_time = args.timestamp or args.time\n                cls.use_localtime = not args.timestamp\n                cls.time_field = cls.print_time and (not cls.use_localtime)\n                cls.print_cpu = args.print_cpu\n                cls.print_address = args.address\n                cls.first_ts = BPF.monotonic_time()\n                cls.tgid = args.tgid or -1\n                cls.pid = args.pid or -1\n                cls.page_cnt = args.buffer_pages\n                cls.bin_cmp = args.bin_cmp",
  "def __init__(self, probe, string_size, kernel_stack, user_stack):\n                self.usdt = None\n                self.streq_functions = \"\"\n                self.raw_probe = probe\n                self.string_size = string_size\n                self.kernel_stack = kernel_stack\n                self.user_stack = user_stack\n                Probe.probe_count += 1\n                self._parse_probe()\n                self.probe_num = Probe.probe_count\n                self.probe_name = \"probe_%s_%d\" % \\\n                                (self._display_function(), self.probe_num)\n                self.probe_name = re.sub(r'[^A-Za-z0-9_]', '_',\n                                         self.probe_name)\n\n                # compiler can generate proper codes for function\n                # signatures with \"syscall__\" prefix\n                if self.is_syscall_kprobe:\n                        self.probe_name = \"syscall__\" + self.probe_name[6:]",
  "def __str__(self):\n                return \"%s:%s:%s FLT=%s ACT=%s/%s\" % (self.probe_type,\n                        self.library, self._display_function(), self.filter,\n                        self.types, self.values)",
  "def is_default_action(self):\n                return self.python_format == \"\"",
  "def _bail(self, error):\n                raise ValueError(\"error in probe '%s': %s\" %\n                                 (self.raw_probe, error))",
  "def _parse_probe(self):\n                text = self.raw_probe\n\n                # There might be a function signature preceding the actual\n                # filter/print part, or not. Find the probe specifier first --\n                # it ends with either a space or an open paren ( for the\n                # function signature part.\n                #                                          opt. signature\n                #                               probespec       |      rest\n                #                               ---------  ----------   --\n                (spec, sig, rest) = re.match(r'([^ \\t\\(]+)(\\([^\\(]*\\))?(.*)',\n                                             text).groups()\n\n                self._parse_spec(spec)\n                # Remove the parens\n                self.signature = sig[1:-1] if sig else None\n                if self.signature and self.probe_type in ['u', 't']:\n                        self._bail(\"USDT and tracepoint probes can't have \" +\n                                   \"a function signature; use arg1, arg2, \" +\n                                   \"... instead\")\n\n                text = rest.lstrip()\n                # If we now have a (, wait for the balanced closing ) and that\n                # will be the predicate\n                self.filter = None\n                if len(text) > 0 and text[0] == \"(\":\n                        balance = 1\n                        for i in range(1, len(text)):\n                                if text[i] == \"(\":\n                                        balance += 1\n                                if text[i] == \")\":\n                                        balance -= 1\n                                if balance == 0:\n                                        self._parse_filter(text[:i + 1])\n                                        text = text[i + 1:]\n                                        break\n                        if self.filter is None:\n                                self._bail(\"unmatched end of predicate\")\n\n                if self.filter is None:\n                        self.filter = \"1\"\n\n                # The remainder of the text is the printf action\n                self._parse_action(text.lstrip())",
  "def _parse_spec(self, spec):\n                parts = spec.split(\":\")\n                # Two special cases: 'func' means 'p::func', 'lib:func' means\n                # 'p:lib:func'. Other combinations need to provide an empty\n                # value between delimiters, e.g. 'r::func' for a kretprobe on\n                # the function func.\n                if len(parts) == 1:\n                        parts = [\"p\", \"\", parts[0]]\n                elif len(parts) == 2:\n                        parts = [\"p\", parts[0], parts[1]]\n                if len(parts[0]) == 0:\n                        self.probe_type = \"p\"\n                elif parts[0] in [\"p\", \"r\", \"t\", \"u\"]:\n                        self.probe_type = parts[0]\n                else:\n                        self._bail(\"probe type must be '', 'p', 't', 'r', \" +\n                                   \"or 'u', but got '%s'\" % parts[0])\n                if self.probe_type == \"t\":\n                        self.tp_category = parts[1]\n                        self.tp_event = parts[2]\n                        self.library = \"\"       # kernel\n                        self.function = \"\"      # from TRACEPOINT_PROBE\n                elif self.probe_type == \"u\":\n                        self.library = ':'.join(parts[1:-1])\n                        self.usdt_name = parts[-1]\n                        self.function = \"\"      # no function, just address\n                        # We will discover the USDT provider by matching on\n                        # the USDT name in the specified library\n                        self._find_usdt_probe()\n                else:\n                        self.library = ':'.join(parts[1:-1])\n                        self.function = parts[-1]\n\n                # only x64 syscalls needs checking, no other syscall wrapper yet.\n                self.is_syscall_kprobe = False\n                if self.probe_type == \"p\" and len(self.library) == 0 and \\\n                   self.function[:10] == \"__x64_sys_\":\n                        self.is_syscall_kprobe = True",
  "def _find_usdt_probe(self):\n                target = Probe.pid if Probe.pid and Probe.pid != -1 \\\n                                   else Probe.tgid\n                self.usdt = USDT(path=self.library, pid=target)\n                for probe in self.usdt.enumerate_probes():\n                        if probe.name == self.usdt_name.encode('ascii'):\n                                return  # Found it, will enable later\n                self._bail(\"unrecognized USDT probe %s\" % self.usdt_name)",
  "def _parse_filter(self, filt):\n                self.filter = self._rewrite_expr(filt)",
  "def _parse_types(self, fmt):\n                for match in re.finditer(\n                            r'[^%]%(s|u|d|lu|llu|ld|lld|hu|hd|x|lx|llx|c|K|U)', fmt):\n                        self.types.append(match.group(1))\n                fmt = re.sub(r'([^%]%)(u|d|lu|llu|ld|lld|hu|hd)', r'\\1d', fmt)\n                fmt = re.sub(r'([^%]%)(x|lx|llx)', r'\\1x', fmt)\n                fmt = re.sub('%K|%U', '%s', fmt)\n                self.python_format = fmt.strip('\"')",
  "def _parse_action(self, action):\n                self.values = []\n                self.types = []\n                self.python_format = \"\"\n                if len(action) == 0:\n                        return\n\n                action = action.strip()\n                match = re.search(r'(\\\".*?\\\"),?(.*)', action)\n                if match is None:\n                        self._bail(\"expected format string in \\\"s\")\n\n                self.raw_format = match.group(1)\n                self._parse_types(self.raw_format)\n                for part in re.split('(?<!\"),', match.group(2)):\n                        part = self._rewrite_expr(part)\n                        if len(part) > 0:\n                                self.values.append(part)",
  "def _generate_streq_function(self, string):\n                fname = \"streq_%d\" % Probe.streq_index\n                Probe.streq_index += 1\n                self.streq_functions += \"\"\"\nstatic inline bool %s(char const *ignored, uintptr_t str) {\n        char needle[] = %s;\n        char haystack[sizeof(needle)];\n        bpf_probe_read(&haystack, sizeof(haystack), (void *)str);\n        for (int i = 0; i < sizeof(needle) - 1; ++i) {\n                if (needle[i] != haystack[i]) {\n                        return false;\n                }\n        }\n        return true;\n}\n                \"\"\" % (fname, string)\n                return fname",
  "def _rewrite_expr(self, expr):\n                if self.is_syscall_kprobe:\n                    for alias, replacement in Probe.aliases_indarg.items():\n                        expr = expr.replace(alias, replacement)\n                else:\n                    for alias, replacement in Probe.aliases_arg.items():\n                        # For USDT probes, we replace argN values with the\n                        # actual arguments for that probe obtained using\n                        # bpf_readarg_N macros emitted at BPF construction.\n                        if self.probe_type == \"u\":\n                                continue\n                        expr = expr.replace(alias, replacement)\n                for alias, replacement in Probe.aliases_common.items():\n                    expr = expr.replace(alias, replacement)\n                if self.bin_cmp:\n                    STRCMP_RE = 'STRCMP\\\\(\\\"([^\"]+)\\\\\"'\n                else:\n                    STRCMP_RE = 'STRCMP\\\\((\"[^\"]+\\\\\")'\n                matches = re.finditer(STRCMP_RE, expr)\n                for match in matches:\n                        string = match.group(1)\n                        fname = self._generate_streq_function(string)\n                        expr = expr.replace(\"STRCMP\", fname, 1)\n                return expr",
  "def _generate_python_field_decl(self, idx, fields):\n                field_type = self.types[idx]\n                if field_type == \"s\":\n                        ptype = ct.c_char * self.string_size\n                else:\n                        ptype = Probe.p_type[field_type]\n                fields.append((\"v%d\" % idx, ptype))",
  "def _generate_python_data_decl(self):\n                self.python_struct_name = \"%s_%d_Data\" % \\\n                                (self._display_function(), self.probe_num)\n                fields = []\n                if self.time_field:\n                    fields.append((\"timestamp_ns\", ct.c_ulonglong))\n                if self.print_cpu:\n                    fields.append((\"cpu\", ct.c_int))\n                fields.extend([\n                        (\"tgid\", ct.c_uint),\n                        (\"pid\", ct.c_uint),\n                        (\"comm\", ct.c_char * 16)       # TASK_COMM_LEN\n                ])\n                for i in range(0, len(self.types)):\n                        self._generate_python_field_decl(i, fields)\n                if self.kernel_stack:\n                        fields.append((\"kernel_stack_id\", ct.c_int))\n                if self.user_stack:\n                        fields.append((\"user_stack_id\", ct.c_int))\n                return type(self.python_struct_name, (ct.Structure,),\n                            dict(_fields_=fields))",
  "def _generate_field_decl(self, idx):\n                field_type = self.types[idx]\n                if field_type == \"s\":\n                        return \"char v%d[%d];\\n\" % (idx, self.string_size)\n                if field_type in Probe.fmt_types:\n                        return \"%s v%d;\\n\" % (Probe.c_type[field_type], idx)\n                self._bail(\"unrecognized format specifier %s\" % field_type)",
  "def _generate_data_decl(self):\n                # The BPF program will populate values into the struct\n                # according to the format string, and the Python program will\n                # construct the final display string.\n                self.events_name = \"%s_events\" % self.probe_name\n                self.struct_name = \"%s_data_t\" % self.probe_name\n                self.stacks_name = \"%s_stacks\" % self.probe_name\n                stack_table = \"BPF_STACK_TRACE(%s, 1024);\" % self.stacks_name \\\n                              if (self.kernel_stack or self.user_stack) else \"\"\n                data_fields = \"\"\n                for i, field_type in enumerate(self.types):\n                        data_fields += \"        \" + \\\n                                       self._generate_field_decl(i)\n                time_str = \"u64 timestamp_ns;\" if self.time_field else \"\"\n                cpu_str = \"int cpu;\" if self.print_cpu else \"\"\n                kernel_stack_str = \"       int kernel_stack_id;\" \\\n                                   if self.kernel_stack else \"\"\n                user_stack_str = \"       int user_stack_id;\" \\\n                                 if self.user_stack else \"\"\n\n                text = \"\"\"\nstruct %s\n{\n%s\n%s\n        u32 tgid;\n        u32 pid;\n        char comm[TASK_COMM_LEN];\n%s\n%s\n%s\n};\n\nBPF_PERF_OUTPUT(%s);\n%s\n\"\"\"\n                return text % (self.struct_name, time_str, cpu_str, data_fields,\n                               kernel_stack_str, user_stack_str,\n                               self.events_name, stack_table)",
  "def _generate_field_assign(self, idx):\n                field_type = self.types[idx]\n                expr = self.values[idx].strip()\n                text = \"\"\n                if self.probe_type == \"u\" and expr[0:3] == \"arg\":\n                        arg_index = int(expr[3])\n                        arg_ctype = self.usdt.get_probe_arg_ctype(\n                                self.usdt_name, arg_index - 1)\n                        text = (\"        %s %s = 0;\\n\" +\n                                \"        bpf_usdt_readarg(%s, ctx, &%s);\\n\") \\\n                                % (arg_ctype, expr, expr[3], expr)\n\n                if field_type == \"s\":\n                        return text + \"\"\"\n        if (%s != 0) {\n                void *__tmp = (void *)%s;\n                bpf_probe_read(&__data.v%d, sizeof(__data.v%d), __tmp);\n        }\n                \"\"\" % (expr, expr, idx, idx)\n                if field_type in Probe.fmt_types:\n                        return text + \"        __data.v%d = (%s)%s;\\n\" % \\\n                                        (idx, Probe.c_type[field_type], expr)\n                self._bail(\"unrecognized field type %s\" % field_type)",
  "def _generate_usdt_filter_read(self):\n            text = \"\"\n            if self.probe_type != \"u\":\n                    return text\n            for arg, _ in Probe.aliases_arg.items():\n                    if not (arg in self.filter):\n                            continue\n                    arg_index = int(arg.replace(\"arg\", \"\"))\n                    arg_ctype = self.usdt.get_probe_arg_ctype(\n                            self.usdt_name, arg_index - 1)\n                    if not arg_ctype:\n                            self._bail(\"Unable to determine type of {} \"\n                                       \"in the filter\".format(arg))\n                    text += \"\"\"\n        {} {}_filter;\n        bpf_usdt_readarg({}, ctx, &{}_filter);\n                    \"\"\".format(arg_ctype, arg, arg_index, arg)\n                    self.filter = self.filter.replace(\n                            arg, \"{}_filter\".format(arg))\n            return text",
  "def generate_program(self, include_self):\n                data_decl = self._generate_data_decl()\n                if Probe.pid != -1:\n                        pid_filter = \"\"\"\n        if (__pid != %d) { return 0; }\n                \"\"\" % Probe.pid\n                # uprobes can have a built-in tgid filter passed to\n                # attach_uprobe, hence the check here -- for kprobes, we\n                # need to do the tgid test by hand:\n                elif len(self.library) == 0 and Probe.tgid != -1:\n                        pid_filter = \"\"\"\n        if (__tgid != %d) { return 0; }\n                \"\"\" % Probe.tgid\n                elif not include_self:\n                        pid_filter = \"\"\"\n        if (__tgid == %d) { return 0; }\n                \"\"\" % os.getpid()\n                else:\n                        pid_filter = \"\"\n\n                prefix = \"\"\n                signature = \"struct pt_regs *ctx\"\n                if self.signature:\n                        signature += \", \" + self.signature\n\n                data_fields = \"\"\n                for i, expr in enumerate(self.values):\n                        data_fields += self._generate_field_assign(i)\n\n                if self.probe_type == \"t\":\n                        heading = \"TRACEPOINT_PROBE(%s, %s)\" % \\\n                                  (self.tp_category, self.tp_event)\n                        ctx_name = \"args\"\n                else:\n                        heading = \"int %s(%s)\" % (self.probe_name, signature)\n                        ctx_name = \"ctx\"\n\n                time_str = \"\"\"\n        __data.timestamp_ns = bpf_ktime_get_ns();\"\"\" if self.time_field else \"\"\n                cpu_str = \"\"\"\n        __data.cpu = bpf_get_smp_processor_id();\"\"\" if self.print_cpu else \"\"\n                stack_trace = \"\"\n                if self.user_stack:\n                        stack_trace += \"\"\"\n        __data.user_stack_id = %s.get_stackid(\n          %s, BPF_F_REUSE_STACKID | BPF_F_USER_STACK\n        );\"\"\" % (self.stacks_name, ctx_name)\n                if self.kernel_stack:\n                        stack_trace += \"\"\"\n        __data.kernel_stack_id = %s.get_stackid(\n          %s, BPF_F_REUSE_STACKID\n        );\"\"\" % (self.stacks_name, ctx_name)\n\n                text = heading + \"\"\"\n{\n        u64 __pid_tgid = bpf_get_current_pid_tgid();\n        u32 __tgid = __pid_tgid >> 32;\n        u32 __pid = __pid_tgid; // implicit cast to u32 for bottom half\n        %s\n        %s\n        %s\n        if (!(%s)) return 0;\n\n        struct %s __data = {0};\n        %s\n        %s\n        __data.tgid = __tgid;\n        __data.pid = __pid;\n        bpf_get_current_comm(&__data.comm, sizeof(__data.comm));\n%s\n%s\n        %s.perf_submit(%s, &__data, sizeof(__data));\n        return 0;\n}\n\"\"\"\n                text = text % (pid_filter, prefix,\n                               self._generate_usdt_filter_read(), self.filter,\n                               self.struct_name, time_str, cpu_str, data_fields,\n                               stack_trace, self.events_name, ctx_name)\n\n                return self.streq_functions + data_decl + \"\\n\" + text",
  "def _time_off_str(cls, timestamp_ns):\n                return \"%.6f\" % (1e-9 * (timestamp_ns - cls.first_ts))",
  "def _display_function(self):\n                if self.probe_type == 'p' or self.probe_type == 'r':\n                        return self.function\n                elif self.probe_type == 'u':\n                        return self.usdt_name\n                else:   # self.probe_type == 't'\n                        return self.tp_event",
  "def print_stack(self, bpf, stack_id, tgid):\n            if stack_id < 0:\n                print(\"        %d\" % stack_id)\n                return\n\n            stack = list(bpf.get_table(self.stacks_name).walk(stack_id))\n            for addr in stack:\n                print(\"        \", end=\"\")\n                if Probe.print_address:\n                    print(\"%16x \" % addr, end=\"\")\n                print(\"%s\" % (bpf.sym(addr, tgid,\n                                     show_module=True, show_offset=True)))",
  "def _format_message(self, bpf, tgid, values):\n                # Replace each %K with kernel sym and %U with user sym in tgid\n                kernel_placeholders = [i for i, t in enumerate(self.types)\n                                       if t == 'K']\n                user_placeholders = [i for i, t in enumerate(self.types)\n                                     if t == 'U']\n                for kp in kernel_placeholders:\n                        values[kp] = bpf.ksym(values[kp], show_offset=True)\n                for up in user_placeholders:\n                        values[up] = bpf.sym(values[up], tgid,\n                                           show_module=True, show_offset=True)\n                return self.python_format % tuple(values)",
  "def print_event(self, bpf, cpu, data, size):\n                # Cast as the generated structure type and display\n                # according to the format string in the probe.\n                event = ct.cast(data, ct.POINTER(self.python_struct)).contents\n                values = map(lambda i: getattr(event, \"v%d\" % i),\n                             range(0, len(self.values)))\n                msg = self._format_message(bpf, event.tgid, values)\n                if Probe.print_time:\n                    time = strftime(\"%H:%M:%S\") if Probe.use_localtime else \\\n                           Probe._time_off_str(event.timestamp_ns)\n                    print(\"%-8s \" % time[:8], end=\"\")\n                if Probe.print_cpu:\n                    print(\"%-3s \" % event.cpu, end=\"\")\n                print(\"%-7d %-7d %-15s %-16s %s\" %\n                      (event.tgid, event.pid,\n                       event.comm.decode('utf-8', 'replace'),\n                       self._display_function(), msg))\n\n                if self.kernel_stack:\n                        self.print_stack(bpf, event.kernel_stack_id, -1)\n                if self.user_stack:\n                        self.print_stack(bpf, event.user_stack_id, event.tgid)\n                if self.user_stack or self.kernel_stack:\n                        print(\"\")\n\n                Probe.event_count += 1\n                if Probe.max_events is not None and \\\n                   Probe.event_count >= Probe.max_events:\n                        exit()",
  "def attach(self, bpf, verbose):\n                if len(self.library) == 0:\n                        self._attach_k(bpf)\n                else:\n                        self._attach_u(bpf)\n                self.python_struct = self._generate_python_data_decl()\n                callback = partial(self.print_event, bpf)\n                bpf[self.events_name].open_perf_buffer(callback,\n                        page_cnt=self.page_cnt)",
  "def _attach_k(self, bpf):\n                if self.probe_type == \"r\":\n                        bpf.attach_kretprobe(event=self.function,\n                                             fn_name=self.probe_name)\n                elif self.probe_type == \"p\":\n                        bpf.attach_kprobe(event=self.function,\n                                          fn_name=self.probe_name)",
  "def _attach_u(self, bpf):\n                libpath = BPF.find_library(self.library)\n                if libpath is None:\n                        # This might be an executable (e.g. 'bash')\n                        libpath = BPF.find_exe(self.library)\n                if libpath is None or len(libpath) == 0:\n                        self._bail(\"unable to find library %s\" % self.library)\n\n                if self.probe_type == \"u\":\n                        pass    # Was already enabled by the BPF constructor\n                elif self.probe_type == \"r\":\n                        bpf.attach_uretprobe(name=libpath,\n                                             sym=self.function,\n                                             fn_name=self.probe_name,\n                                             pid=Probe.tgid)\n                else:\n                        bpf.attach_uprobe(name=libpath,\n                                          sym=self.function,\n                                          fn_name=self.probe_name,\n                                          pid=Probe.tgid)",
  "def __init__(self):\n                parser = argparse.ArgumentParser(description=\"Attach to \" +\n                  \"functions and print trace messages.\",\n                  formatter_class=argparse.RawDescriptionHelpFormatter,\n                  epilog=Tool.examples)\n                parser.add_argument(\"-b\", \"--buffer-pages\", type=int,\n                  default=Tool.DEFAULT_PERF_BUFFER_PAGES,\n                  help=\"number of pages to use for perf_events ring buffer \"\n                       \"(default: %(default)d)\")\n                # we'll refer to the userspace concepts of \"pid\" and \"tid\" by\n                # their kernel names -- tgid and pid -- inside the script\n                parser.add_argument(\"-p\", \"--pid\", type=int, metavar=\"PID\",\n                  dest=\"tgid\", help=\"id of the process to trace (optional)\")\n                parser.add_argument(\"-L\", \"--tid\", type=int, metavar=\"TID\",\n                  dest=\"pid\", help=\"id of the thread to trace (optional)\")\n                parser.add_argument(\"-v\", \"--verbose\", action=\"store_true\",\n                  help=\"print resulting BPF program code before executing\")\n                parser.add_argument(\"-Z\", \"--string-size\", type=int,\n                  default=80, help=\"maximum size to read from strings\")\n                parser.add_argument(\"-S\", \"--include-self\",\n                  action=\"store_true\",\n                  help=\"do not filter trace's own pid from the trace\")\n                parser.add_argument(\"-M\", \"--max-events\", type=int,\n                  help=\"number of events to print before quitting\")\n                parser.add_argument(\"-t\", \"--timestamp\", action=\"store_true\",\n                  help=\"print timestamp column (offset from trace start)\")\n                parser.add_argument(\"-T\", \"--time\", action=\"store_true\",\n                  help=\"print time column\")\n                parser.add_argument(\"-C\", \"--print_cpu\", action=\"store_true\",\n                  help=\"print CPU id\")\n                parser.add_argument(\"-B\", \"--bin_cmp\", action=\"store_true\",\n                  help=\"allow to use STRCMP with binary values\")\n                parser.add_argument(\"-K\", \"--kernel-stack\",\n                  action=\"store_true\", help=\"output kernel stack trace\")\n                parser.add_argument(\"-U\", \"--user-stack\",\n                  action=\"store_true\", help=\"output user stack trace\")\n                parser.add_argument(\"-a\", \"--address\", action=\"store_true\",\n                  help=\"print virtual address in stacks\")\n                parser.add_argument(metavar=\"probe\", dest=\"probes\", nargs=\"+\",\n                  help=\"probe specifier (see examples)\")\n                parser.add_argument(\"-I\", \"--include\", action=\"append\",\n                  metavar=\"header\",\n                  help=\"additional header files to include in the BPF program \"\n                       \"as either full path, \"\n                       \"or relative to current working directory, \"\n                       \"or relative to default kernel header search path\")\n                parser.add_argument(\"--ebpf\", action=\"store_true\",\n                  help=argparse.SUPPRESS)\n                self.args = parser.parse_args()\n                if self.args.tgid and self.args.pid:\n                        parser.error(\"only one of -p and -L may be specified\")",
  "def _create_probes(self):\n                Probe.configure(self.args)\n                self.probes = []\n                for probe_spec in self.args.probes:\n                        self.probes.append(Probe(\n                                probe_spec, self.args.string_size,\n                                self.args.kernel_stack, self.args.user_stack))",
  "def _generate_program(self):\n                self.program = \"\"\"\n#include <linux/ptrace.h>\n#include <linux/sched.h>        /* For TASK_COMM_LEN */\n\n\"\"\"\n                for include in (self.args.include or []):\n                        if include.startswith((\".\", \"/\")):\n                                include = os.path.abspath(include)\n                                self.program += \"#include \\\"%s\\\"\\n\" % include\n                        else:\n                                self.program += \"#include <%s>\\n\" % include\n                self.program += BPF.generate_auto_includes(\n                        map(lambda p: p.raw_probe, self.probes))\n                for probe in self.probes:\n                        self.program += probe.generate_program(\n                                        self.args.include_self)\n\n                if self.args.verbose or self.args.ebpf:\n                        print(self.program)\n                        if self.args.ebpf:\n                                exit()",
  "def _attach_probes(self):\n                usdt_contexts = []\n                for probe in self.probes:\n                    if probe.usdt:\n                        # USDT probes must be enabled before the BPF object\n                        # is initialized, because that's where the actual\n                        # uprobe is being attached.\n                        probe.usdt.enable_probe(\n                                probe.usdt_name, probe.probe_name)\n                        if self.args.verbose:\n                                print(probe.usdt.get_text())\n                        usdt_contexts.append(probe.usdt)\n                self.bpf = BPF(text=self.program, usdt_contexts=usdt_contexts)\n                for probe in self.probes:\n                        if self.args.verbose:\n                                print(probe)\n                        probe.attach(self.bpf, self.args.verbose)",
  "def _main_loop(self):\n                all_probes_trivial = all(map(Probe.is_default_action,\n                                             self.probes))\n\n                # Print header\n                if self.args.timestamp or self.args.time:\n                    print(\"%-8s \" % \"TIME\", end=\"\");\n                if self.args.print_cpu:\n                    print(\"%-3s \" % \"CPU\", end=\"\");\n                print(\"%-7s %-7s %-15s %-16s %s\" %\n                      (\"PID\", \"TID\", \"COMM\", \"FUNC\",\n                      \"-\" if not all_probes_trivial else \"\"))\n\n                while True:\n                        self.bpf.perf_buffer_poll()",
  "def run(self):\n                try:\n                        self._create_probes()\n                        self._generate_program()\n                        self._attach_probes()\n                        self._main_loop()\n                except:\n                        exc_info = sys.exc_info()\n                        sys_exit = exc_info[0] is SystemExit\n                        if self.args.verbose:\n                                traceback.print_exc()\n                        elif not sys_exit:\n                                print(exc_info[1])\n                        exit(0 if sys_exit else 1)",
  "def range_check(string):\n    value = int(string)\n    if value < 1:\n        msg = \"value must be stricly positive, got %d\" % (value,)\n        raise argparse.ArgumentTypeError(msg)\n    return value",
  "def pid_to_comm(pid):\n    try:\n        comm = open(\"/proc/%d/comm\" % pid, \"r\").read().rstrip()\n        return comm\n    except IOError:\n        return str(pid)",
  "def get_ipv4_session_key(k):\n    return TCPSessionKey(pid=k.pid,\n                         laddr=inet_ntop(AF_INET, pack(\"I\", k.saddr)),\n                         lport=k.lport,\n                         daddr=inet_ntop(AF_INET, pack(\"I\", k.daddr)),\n                         dport=k.dport)",
  "def get_ipv6_session_key(k):\n    return TCPSessionKey(pid=k.pid,\n                         laddr=inet_ntop(AF_INET6, k.saddr),\n                         lport=k.lport,\n                         daddr=inet_ntop(AF_INET6, k.daddr),\n                         dport=k.dport)",
  "class Probe(object):\n        next_probe_index = 0\n        streq_index = 0\n        aliases = {\"$PID\": \"(bpf_get_current_pid_tgid() >> 32)\"}\n\n        def _substitute_aliases(self, expr):\n                if expr is None:\n                        return expr\n                for alias, subst in Probe.aliases.items():\n                        expr = expr.replace(alias, subst)\n                return expr\n\n        def _parse_signature(self):\n                params = map(str.strip, self.signature.split(','))\n                self.param_types = {}\n                for param in params:\n                        # If the type is a pointer, the * can be next to the\n                        # param name. Other complex types like arrays are not\n                        # supported right now.\n                        index = param.rfind('*')\n                        index = index if index != -1 else param.rfind(' ')\n                        param_type = param[0:index + 1].strip()\n                        param_name = param[index + 1:].strip()\n                        self.param_types[param_name] = param_type\n\n        def _generate_entry(self):\n                self.entry_probe_func = self.probe_func_name + \"_entry\"\n                text = \"\"\"\nint PROBENAME(struct pt_regs *ctx SIGNATURE)\n{\n        u64 __pid_tgid = bpf_get_current_pid_tgid();\n        u32 __pid      = __pid_tgid;        // lower 32 bits\n        u32 __tgid     = __pid_tgid >> 32;  // upper 32 bits\n        PID_FILTER\n        COLLECT\n        return 0;\n}\n\"\"\"\n                text = text.replace(\"PROBENAME\", self.entry_probe_func)\n                text = text.replace(\"SIGNATURE\",\n                     \"\" if len(self.signature) == 0 else \", \" + self.signature)\n                text = text.replace(\"PID_FILTER\", self._generate_pid_filter())\n                collect = \"\"\n                for pname in self.args_to_probe:\n                        param_hash = self.hashname_prefix + pname\n                        if pname == \"__latency\":\n                                collect += \"\"\"\nu64 __time = bpf_ktime_get_ns();\n%s.update(&__pid, &__time);\n                        \"\"\" % param_hash\n                        else:\n                                collect += \"%s.update(&__pid, &%s);\\n\" % \\\n                                           (param_hash, pname)\n                text = text.replace(\"COLLECT\", collect)\n                return text\n\n        def _generate_entry_probe(self):\n                # Any $entry(name) expressions result in saving that argument\n                # when entering the function.\n                self.args_to_probe = set()\n                regex = r\"\\$entry\\((\\w+)\\)\"\n                for expr in self.exprs:\n                        for arg in re.finditer(regex, expr):\n                                self.args_to_probe.add(arg.group(1))\n                for arg in re.finditer(regex, self.filter):\n                        self.args_to_probe.add(arg.group(1))\n                if any(map(lambda expr: \"$latency\" in expr, self.exprs)) or \\\n                   \"$latency\" in self.filter:\n                        self.args_to_probe.add(\"__latency\")\n                        self.param_types[\"__latency\"] = \"u64\"    # nanoseconds\n                for pname in self.args_to_probe:\n                        if pname not in self.param_types:\n                                raise ValueError(\"$entry(%s): no such param\" %\n                                                 arg)\n\n                self.hashname_prefix = \"%s_param_\" % self.probe_hash_name\n                text = \"\"\n                for pname in self.args_to_probe:\n                        # Each argument is stored in a separate hash that is\n                        # keyed by pid.\n                        text += \"BPF_HASH(%s, u32, %s);\\n\" % \\\n                             (self.hashname_prefix + pname,\n                              self.param_types[pname])\n                text += self._generate_entry()\n                return text\n\n        def _generate_retprobe_prefix(self):\n                # After we're done here, there are __%s_val variables for each\n                # argument we needed to probe using $entry(name), and they all\n                # have values (which isn't necessarily the case if we missed\n                # the method entry probe).\n                text = \"\"\n                self.param_val_names = {}\n                for pname in self.args_to_probe:\n                        val_name = \"__%s_val\" % pname\n                        text += \"%s *%s = %s.lookup(&__pid);\\n\" % \\\n                                (self.param_types[pname], val_name,\n                                 self.hashname_prefix + pname)\n                        text += \"if (%s == 0) { return 0 ; }\\n\" % val_name\n                        self.param_val_names[pname] = val_name\n                return text\n\n        def _replace_entry_exprs(self):\n                for pname, vname in self.param_val_names.items():\n                        if pname == \"__latency\":\n                                entry_expr = \"$latency\"\n                                val_expr = \"(bpf_ktime_get_ns() - *%s)\" % vname\n                        else:\n                                entry_expr = \"$entry(%s)\" % pname\n                                val_expr = \"(*%s)\" % vname\n                        for i in range(0, len(self.exprs)):\n                                self.exprs[i] = self.exprs[i].replace(\n                                                entry_expr, val_expr)\n                        self.filter = self.filter.replace(entry_expr,\n                                                          val_expr)\n\n        def _attach_entry_probe(self):\n                if self.is_user:\n                        self.bpf.attach_uprobe(name=self.library,\n                                               sym=self.function,\n                                               fn_name=self.entry_probe_func,\n                                               pid=self.pid or -1)\n                else:\n                        self.bpf.attach_kprobe(event=self.function,\n                                               fn_name=self.entry_probe_func)\n\n        def _bail(self, error):\n                raise ValueError(\"error parsing probe '%s': %s\" %\n                                 (self.raw_spec, error))\n\n        def _validate_specifier(self):\n                # Everything after '#' is the probe label, ignore it\n                spec = self.raw_spec.split('#')[0]\n                parts = spec.strip().split(':')\n                if len(parts) < 3:\n                        self._bail(\"at least the probe type, library, and \" +\n                                   \"function signature must be specified\")\n                if len(parts) > 6:\n                        self._bail(\"extraneous ':'-separated parts detected\")\n                if parts[0] not in [\"r\", \"p\", \"t\", \"u\"]:\n                        self._bail(\"probe type must be 'p', 'r', 't', or 'u'\" +\n                                   \" but got '%s'\" % parts[0])\n                if re.match(r\"\\S+\\(.*\\)\", parts[2]) is None:\n                        self._bail((\"function signature '%s' has an invalid \" +\n                                    \"format\") % parts[2])\n\n        def _parse_expr_types(self, expr_types):\n                if len(expr_types) == 0:\n                        self._bail(\"no expr types specified\")\n                self.expr_types = expr_types.split(',')\n\n        def _parse_exprs(self, exprs):\n                if len(exprs) == 0:\n                        self._bail(\"no exprs specified\")\n                self.exprs = exprs.split(',')\n\n        def _make_valid_identifier(self, ident):\n                return re.sub(r'[^A-Za-z0-9_]', '_', ident)\n\n        def __init__(self, tool, type, specifier):\n                self.usdt_ctx = None\n                self.streq_functions = \"\"\n                self.pid = tool.args.pid\n                self.cumulative = tool.args.cumulative or False\n                self.raw_spec = specifier\n                self._validate_specifier()\n\n                spec_and_label = specifier.split('#')\n                self.label = spec_and_label[1] \\\n                             if len(spec_and_label) == 2 else None\n\n                parts = spec_and_label[0].strip().split(':')\n                self.type = type    # hist or freq\n                self.probe_type = parts[0]\n                fparts = parts[2].split('(')\n                self.function = fparts[0].strip()\n                if self.probe_type == \"t\":\n                        self.library = \"\"       # kernel\n                        self.tp_category = parts[1]\n                        self.tp_event = self.function\n                elif self.probe_type == \"u\":\n                        self.library = parts[1]\n                        self.probe_func_name = self._make_valid_identifier(\n                                \"%s_probe%d\" %\n                                (self.function, Probe.next_probe_index))\n                        self._enable_usdt_probe()\n                else:\n                        self.library = parts[1]\n                self.is_user = len(self.library) > 0\n                self.signature = fparts[1].strip()[:-1]\n                self._parse_signature()\n\n                # If the user didn't specify an expression to probe, we probe\n                # the retval in a ret probe, or simply the value \"1\" otherwise.\n                self.is_default_expr = len(parts) < 5\n                if not self.is_default_expr:\n                        self._parse_expr_types(parts[3])\n                        self._parse_exprs(parts[4])\n                        if len(self.exprs) != len(self.expr_types):\n                                self._bail(\"mismatched # of exprs and types\")\n                        if self.type == \"hist\" and len(self.expr_types) > 1:\n                                self._bail(\"histograms can only have 1 expr\")\n                else:\n                        if not self.probe_type == \"r\" and self.type == \"hist\":\n                                self._bail(\"histograms must have expr\")\n                        self.expr_types = \\\n                          [\"u64\" if not self.probe_type == \"r\" else \"int\"]\n                        self.exprs = \\\n                          [\"1\" if not self.probe_type == \"r\" else \"$retval\"]\n                self.filter = \"\" if len(parts) != 6 else parts[5]\n                self._substitute_exprs()\n\n                # Do we need to attach an entry probe so that we can collect an\n                # argument that is required for an exit (return) probe?\n                def check(expr):\n                        keywords = [\"$entry\", \"$latency\"]\n                        return any(map(lambda kw: kw in expr, keywords))\n                self.entry_probe_required = self.probe_type == \"r\" and \\\n                        (any(map(check, self.exprs)) or check(self.filter))\n\n                self.probe_func_name = self._make_valid_identifier(\n                        \"%s_probe%d\" %\n                        (self.function, Probe.next_probe_index))\n                self.probe_hash_name = self._make_valid_identifier(\n                        \"%s_hash%d\" %\n                        (self.function, Probe.next_probe_index))\n                Probe.next_probe_index += 1\n\n        def _enable_usdt_probe(self):\n                self.usdt_ctx = USDT(path=self.library, pid=self.pid)\n                self.usdt_ctx.enable_probe(\n                        self.function, self.probe_func_name)\n\n        def _generate_streq_function(self, string):\n                fname = \"streq_%d\" % Probe.streq_index\n                Probe.streq_index += 1\n                self.streq_functions += \"\"\"\nstatic inline bool %s(char const *ignored, char const *str) {\n        char needle[] = %s;\n        char haystack[sizeof(needle)];\n        bpf_probe_read(&haystack, sizeof(haystack), (void *)str);\n        for (int i = 0; i < sizeof(needle) - 1; ++i) {\n                if (needle[i] != haystack[i]) {\n                        return false;\n                }\n        }\n        return true;\n}\n                \"\"\" % (fname, string)\n                return fname\n\n        def _substitute_exprs(self):\n                def repl(expr):\n                        expr = self._substitute_aliases(expr)\n                        matches = re.finditer('STRCMP\\\\((\"[^\"]+\\\\\")', expr)\n                        for match in matches:\n                                string = match.group(1)\n                                fname = self._generate_streq_function(string)\n                                expr = expr.replace(\"STRCMP\", fname, 1)\n                        return expr.replace(\"$retval\", \"PT_REGS_RC(ctx)\")\n                for i in range(0, len(self.exprs)):\n                        self.exprs[i] = repl(self.exprs[i])\n                self.filter = repl(self.filter)\n\n        def _is_string(self, expr_type):\n                return expr_type == \"char*\" or expr_type == \"char *\"\n\n        def _generate_hash_field(self, i):\n                if self._is_string(self.expr_types[i]):\n                        return \"struct __string_t v%d;\\n\" % i\n                else:\n                        return \"%s v%d;\\n\" % (self.expr_types[i], i)\n\n        def _generate_usdt_arg_assignment(self, i):\n                expr = self.exprs[i]\n                if self.probe_type == \"u\" and expr[0:3] == \"arg\":\n                        arg_index = int(expr[3])\n                        arg_ctype = self.usdt_ctx.get_probe_arg_ctype(\n                                self.function, arg_index - 1)\n                        return (\"        %s %s = 0;\\n\" +\n                                \"        bpf_usdt_readarg(%s, ctx, &%s);\\n\") \\\n                                % (arg_ctype, expr, expr[3], expr)\n                else:\n                        return \"\"\n\n        def _generate_field_assignment(self, i):\n                text = self._generate_usdt_arg_assignment(i)\n                if self._is_string(self.expr_types[i]):\n                        return (text + \"        bpf_probe_read(&__key.v%d.s,\" +\n                                \" sizeof(__key.v%d.s), (void *)%s);\\n\") % \\\n                                (i, i, self.exprs[i])\n                else:\n                        return text + \"        __key.v%d = %s;\\n\" % \\\n                               (i, self.exprs[i])\n\n        def _generate_hash_decl(self):\n                if self.type == \"hist\":\n                        return \"BPF_HISTOGRAM(%s, %s);\" % \\\n                               (self.probe_hash_name, self.expr_types[0])\n                else:\n                        text = \"struct %s_key_t {\\n\" % self.probe_hash_name\n                        for i in range(0, len(self.expr_types)):\n                                text += self._generate_hash_field(i)\n                        text += \"};\\n\"\n                        text += \"BPF_HASH(%s, struct %s_key_t, u64);\\n\" % \\\n                                (self.probe_hash_name, self.probe_hash_name)\n                        return text\n\n        def _generate_key_assignment(self):\n                if self.type == \"hist\":\n                        return self._generate_usdt_arg_assignment(0) + \\\n                               (\"%s __key = %s;\\n\" %\n                                (self.expr_types[0], self.exprs[0]))\n                else:\n                        text = \"struct %s_key_t __key = {};\\n\" % \\\n                                self.probe_hash_name\n                        for i in range(0, len(self.exprs)):\n                                text += self._generate_field_assignment(i)\n                        return text\n\n        def _generate_hash_update(self):\n                if self.type == \"hist\":\n                        return \"%s.increment(bpf_log2l(__key));\" % \\\n                                self.probe_hash_name\n                else:\n                        return \"%s.increment(__key);\" % self.probe_hash_name\n\n        def _generate_pid_filter(self):\n                # Kernel probes need to explicitly filter pid, because the\n                # attach interface doesn't support pid filtering\n                if self.pid is not None and not self.is_user:\n                        return \"if (__tgid != %d) { return 0; }\" % self.pid\n                else:\n                        return \"\"\n\n        def generate_text(self):\n                program = \"\"\n                probe_text = \"\"\"\nDATA_DECL\n                \"\"\" + (\n                    \"TRACEPOINT_PROBE(%s, %s)\" %\n                    (self.tp_category, self.tp_event)\n                    if self.probe_type == \"t\"\n                    else \"int PROBENAME(struct pt_regs *ctx SIGNATURE)\") + \"\"\"\n{\n        u64 __pid_tgid = bpf_get_current_pid_tgid();\n        u32 __pid      = __pid_tgid;        // lower 32 bits\n        u32 __tgid     = __pid_tgid >> 32;  // upper 32 bits\n        PID_FILTER\n        PREFIX\n        if (!(FILTER)) return 0;\n        KEY_EXPR\n        COLLECT\n        return 0;\n}\n\"\"\"\n                prefix = \"\"\n                signature = \"\"\n\n                # If any entry arguments are probed in a ret probe, we need\n                # to generate an entry probe to collect them\n                if self.entry_probe_required:\n                        program += self._generate_entry_probe()\n                        prefix += self._generate_retprobe_prefix()\n                        # Replace $entry(paramname) with a reference to the\n                        # value we collected when entering the function:\n                        self._replace_entry_exprs()\n\n                if self.probe_type == \"p\" and len(self.signature) > 0:\n                        # Only entry uprobes/kprobes can have user-specified\n                        # signatures. Other probes force it to ().\n                        signature = \", \" + self.signature\n\n                program += probe_text.replace(\"PROBENAME\",\n                                              self.probe_func_name)\n                program = program.replace(\"SIGNATURE\", signature)\n                program = program.replace(\"PID_FILTER\",\n                                          self._generate_pid_filter())\n\n                decl = self._generate_hash_decl()\n                key_expr = self._generate_key_assignment()\n                collect = self._generate_hash_update()\n                program = program.replace(\"DATA_DECL\", decl)\n                program = program.replace(\"KEY_EXPR\", key_expr)\n                program = program.replace(\"FILTER\",\n                        \"1\" if len(self.filter) == 0 else self.filter)\n                program = program.replace(\"COLLECT\", collect)\n                program = program.replace(\"PREFIX\", prefix)\n\n                return self.streq_functions + program\n\n        def _attach_u(self):\n                libpath = BPF.find_library(self.library)\n                if libpath is None:\n                        libpath = BPF.find_exe(self.library)\n                if libpath is None or len(libpath) == 0:\n                        self._bail(\"unable to find library %s\" % self.library)\n\n                if self.probe_type == \"r\":\n                        self.bpf.attach_uretprobe(name=libpath,\n                                                  sym=self.function,\n                                                  fn_name=self.probe_func_name,\n                                                  pid=self.pid or -1)\n                else:\n                        self.bpf.attach_uprobe(name=libpath,\n                                               sym=self.function,\n                                               fn_name=self.probe_func_name,\n                                               pid=self.pid or -1)\n\n        def _attach_k(self):\n                if self.probe_type == \"t\":\n                        pass    # Nothing to do for tracepoints\n                elif self.probe_type == \"r\":\n                        self.bpf.attach_kretprobe(event=self.function,\n                                             fn_name=self.probe_func_name)\n                else:\n                        self.bpf.attach_kprobe(event=self.function,\n                                          fn_name=self.probe_func_name)\n\n        def attach(self, bpf):\n                self.bpf = bpf\n                if self.probe_type == \"u\":\n                        return\n                if self.is_user:\n                        self._attach_u()\n                else:\n                        self._attach_k()\n                if self.entry_probe_required:\n                        self._attach_entry_probe()\n\n        def _v2s(self, v):\n                # Most fields can be converted with plain str(), but strings\n                # are wrapped in a __string_t which has an .s field\n                if \"__string_t\" in type(v).__name__:\n                        return str(v.s)\n                return str(v)\n\n        def _display_expr(self, i):\n                # Replace ugly latency calculation with $latency\n                expr = self.exprs[i].replace(\n                        \"(bpf_ktime_get_ns() - *____latency_val)\", \"$latency\")\n                # Replace alias values back with the alias name\n                for alias, subst in Probe.aliases.items():\n                        expr = expr.replace(subst, alias)\n                # Replace retval expression with $retval\n                expr = expr.replace(\"PT_REGS_RC(ctx)\", \"$retval\")\n                # Replace ugly (*__param_val) expressions with param name\n                return re.sub(r\"\\(\\*__(\\w+)_val\\)\", r\"\\1\", expr)\n\n        def _display_key(self, key):\n                if self.is_default_expr:\n                        if not self.probe_type == \"r\":\n                                return \"total calls\"\n                        else:\n                                return \"retval = %s\" % str(key.v0)\n                else:\n                        # The key object has v0, ..., vk fields containing\n                        # the values of the expressions from self.exprs\n                        def str_i(i):\n                                key_i = self._v2s(getattr(key, \"v%d\" % i))\n                                return \"%s = %s\" % \\\n                                        (self._display_expr(i), key_i)\n                        return \", \".join(map(str_i, range(0, len(self.exprs))))\n\n        def display(self, top):\n                data = self.bpf.get_table(self.probe_hash_name)\n                if self.type == \"freq\":\n                        print(self.label or self.raw_spec)\n                        print(\"\\t%-10s %s\" % (\"COUNT\", \"EVENT\"))\n                        sdata = sorted(data.items(), key=lambda p: p[1].value)\n                        if top is not None:\n                                sdata = sdata[-top:]\n                        for key, value in sdata:\n                                # Print some nice values if the user didn't\n                                # specify an expression to probe\n                                if self.is_default_expr:\n                                        if not self.probe_type == \"r\":\n                                                key_str = \"total calls\"\n                                        else:\n                                                key_str = \"retval = %s\" % \\\n                                                          self._v2s(key.v0)\n                                else:\n                                        key_str = self._display_key(key)\n                                print(\"\\t%-10s %s\" %\n                                      (str(value.value), key_str))\n                elif self.type == \"hist\":\n                        label = self.label or (self._display_expr(0)\n                                if not self.is_default_expr else \"retval\")\n                        data.print_log2_hist(val_type=label)\n                if not self.cumulative:\n                        data.clear()\n\n        def __str__(self):\n                return self.label or self.raw_spec",
  "class Tool(object):\n        examples = \"\"\"\nProbe specifier syntax:\n        {p,r,t,u}:{[library],category}:function(signature)[:type[,type...]:expr[,expr...][:filter]][#label]\nWhere:\n        p,r,t,u    -- probe at function entry, function exit, kernel\n                      tracepoint, or USDT probe\n                      in exit probes: can use $retval, $entry(param), $latency\n        library    -- the library that contains the function\n                      (leave empty for kernel functions)\n        category   -- the category of the kernel tracepoint (e.g. net, sched)\n        function   -- the function name to trace (or tracepoint name)\n        signature  -- the function's parameters, as in the C header\n        type       -- the type of the expression to collect (supports multiple)\n        expr       -- the expression to collect (supports multiple)\n        filter     -- the filter that is applied to collected values\n        label      -- the label for this probe in the resulting output\n\nEXAMPLES:\n\nargdist -H 'p::__kmalloc(u64 size):u64:size'\n        Print a histogram of allocation sizes passed to kmalloc\n\nargdist -p 1005 -C 'p:c:malloc(size_t size):size_t:size:size==16'\n        Print a frequency count of how many times process 1005 called malloc\n        with an allocation size of 16 bytes\n\nargdist -C 'r:c:gets():char*:(char*)$retval#snooped strings'\n        Snoop on all strings returned by gets()\n\nargdist -H 'r::__kmalloc(size_t size):u64:$latency/$entry(size)#ns per byte'\n        Print a histogram of nanoseconds per byte from kmalloc allocations\n\nargdist -C 'p::__kmalloc(size_t sz, gfp_t flags):size_t:sz:flags&GFP_ATOMIC'\n        Print frequency count of kmalloc allocation sizes that have GFP_ATOMIC\n\nargdist -p 1005 -C 'p:c:write(int fd):int:fd' -T 5\n        Print frequency counts of how many times writes were issued to a\n        particular file descriptor number, in process 1005, but only show\n        the top 5 busiest fds\n\nargdist -p 1005 -H 'r:c:read()'\n        Print a histogram of results (sizes) returned by read() in process 1005\n\nargdist -C 'r::__vfs_read():u32:$PID:$latency > 100000'\n        Print frequency of reads by process where the latency was >0.1ms\n\nargdist -H 'r::__vfs_read(void *file, void *buf, size_t count):size_t:\n            $entry(count):$latency > 1000000'\n        Print a histogram of read sizes that were longer than 1ms\n\nargdist -H \\\\\n        'p:c:write(int fd, const void *buf, size_t count):size_t:count:fd==1'\n        Print a histogram of buffer sizes passed to write() across all\n        processes, where the file descriptor was 1 (STDOUT)\n\nargdist -C 'p:c:fork()#fork calls'\n        Count fork() calls in libc across all processes\n        Can also use funccount.py, which is easier and more flexible\n\nargdist -H 't:block:block_rq_complete():u32:args->nr_sector'\n        Print histogram of number of sectors in completing block I/O requests\n\nargdist -C 't:irq:irq_handler_entry():int:args->irq'\n        Aggregate interrupts by interrupt request (IRQ)\n\nargdist -C 'u:pthread:pthread_start():u64:arg2' -p 1337\n        Print frequency of function addresses used as a pthread start function,\n        relying on the USDT pthread_start probe in process 1337\n\nargdist -H 'p:c:sleep(u32 seconds):u32:seconds' \\\\\n        -H 'p:c:nanosleep(struct timespec *req):long:req->tv_nsec'\n        Print histograms of sleep() and nanosleep() parameter values\n\nargdist -p 2780 -z 120 \\\\\n        -C 'p:c:write(int fd, char* buf, size_t len):char*:buf:fd==1'\n        Spy on writes to STDOUT performed by process 2780, up to a string size\n        of 120 characters\n\nargdist -I 'kernel/sched/sched.h' \\\\\n        -C 'p::__account_cfs_rq_runtime(struct cfs_rq *cfs_rq):s64:cfs_rq->runtime_remaining'\n        Trace on the cfs scheduling runqueue remaining runtime. The struct cfs_rq is defined\n        in kernel/sched/sched.h which is in kernel source tree and not in kernel-devel\n        package.  So this command needs to run at the kernel source tree root directory\n        so that the added header file can be found by the compiler.\n\"\"\"\n\n        def __init__(self):\n                parser = argparse.ArgumentParser(description=\"Trace a \" +\n                  \"function and display a summary of its parameter values.\",\n                  formatter_class=argparse.RawDescriptionHelpFormatter,\n                  epilog=Tool.examples)\n                parser.add_argument(\"-p\", \"--pid\", type=int,\n                  help=\"id of the process to trace (optional)\")\n                parser.add_argument(\"-z\", \"--string-size\", default=80,\n                  type=int,\n                  help=\"maximum string size to read from char* arguments\")\n                parser.add_argument(\"-i\", \"--interval\", default=1, type=int,\n                  help=\"output interval, in seconds (default 1 second)\")\n                parser.add_argument(\"-d\", \"--duration\", type=int,\n                  help=\"total duration of trace, in seconds\")\n                parser.add_argument(\"-n\", \"--number\", type=int, dest=\"count\",\n                  help=\"number of outputs\")\n                parser.add_argument(\"-v\", \"--verbose\", action=\"store_true\",\n                  help=\"print resulting BPF program code before executing\")\n                parser.add_argument(\"-c\", \"--cumulative\", action=\"store_true\",\n                  help=\"do not clear histograms and freq counts at \" +\n                       \"each interval\")\n                parser.add_argument(\"-T\", \"--top\", type=int,\n                  help=\"number of top results to show (not applicable to \" +\n                  \"histograms)\")\n                parser.add_argument(\"-H\", \"--histogram\", action=\"append\",\n                  dest=\"histspecifier\", metavar=\"specifier\",\n                  help=\"probe specifier to capture histogram of \" +\n                  \"(see examples below)\")\n                parser.add_argument(\"-C\", \"--count\", action=\"append\",\n                  dest=\"countspecifier\", metavar=\"specifier\",\n                  help=\"probe specifier to capture count of \" +\n                  \"(see examples below)\")\n                parser.add_argument(\"-I\", \"--include\", action=\"append\",\n                  metavar=\"header\",\n                  help=\"additional header files to include in the BPF program \"\n                       \"as either full path, \"\n                       \"or relative to relative to current working directory, \"\n                       \"or relative to default kernel header search path\")\n                self.args = parser.parse_args()\n                self.usdt_ctx = None\n\n        def _create_probes(self):\n                self.probes = []\n                for specifier in (self.args.countspecifier or []):\n                        self.probes.append(Probe(self, \"freq\", specifier))\n                for histspecifier in (self.args.histspecifier or []):\n                        self.probes.append(Probe(self, \"hist\", histspecifier))\n                if len(self.probes) == 0:\n                        print(\"at least one specifier is required\")\n                        exit(1)\n\n        def _generate_program(self):\n                bpf_source = \"\"\"\nstruct __string_t { char s[%d]; };\n\n#include <uapi/linux/ptrace.h>\n                \"\"\" % self.args.string_size\n                for include in (self.args.include or []):\n                        if include.startswith((\".\", \"/\")):\n                                include = os.path.abspath(include)\n                                bpf_source += \"#include \\\"%s\\\"\\n\" % include\n                        else:\n                                bpf_source += \"#include <%s>\\n\" % include\n\n                bpf_source += BPF.generate_auto_includes(\n                                map(lambda p: p.raw_spec, self.probes))\n                for probe in self.probes:\n                        bpf_source += probe.generate_text()\n                if self.args.verbose:\n                        for text in [probe.usdt_ctx.get_text()\n                                     for probe in self.probes\n                                     if probe.usdt_ctx]:\n                            print(text)\n                        print(bpf_source)\n                usdt_contexts = [probe.usdt_ctx\n                                 for probe in self.probes if probe.usdt_ctx]\n                self.bpf = BPF(text=bpf_source, usdt_contexts=usdt_contexts)\n\n        def _attach(self):\n                for probe in self.probes:\n                        probe.attach(self.bpf)\n                if self.args.verbose:\n                        print(\"open uprobes: %s\" % list(self.bpf.uprobe_fds.keys()))\n                        print(\"open kprobes: %s\" % list(self.bpf.kprobe_fds.keys()))\n\n        def _main_loop(self):\n                count_so_far = 0\n                seconds = 0\n                while True:\n                        try:\n                                sleep(self.args.interval)\n                                seconds += self.args.interval\n                        except KeyboardInterrupt:\n                                exit()\n                        print(\"[%s]\" % strftime(\"%H:%M:%S\"))\n                        for probe in self.probes:\n                                probe.display(self.args.top)\n                        count_so_far += 1\n                        if self.args.count is not None and \\\n                           count_so_far >= self.args.count:\n                                exit()\n                        if self.args.duration and \\\n                           seconds >= self.args.duration:\n                                exit()\n\n        def run(self):\n                try:\n                        self._create_probes()\n                        self._generate_program()\n                        self._attach()\n                        self._main_loop()\n                except:\n                        exc_info = sys.exc_info()\n                        sys_exit = exc_info[0] is SystemExit\n                        if self.args.verbose:\n                                traceback.print_exc()\n                        elif not sys_exit:\n                                print(exc_info[1])\n                        exit(0 if sys_exit else 1)",
  "def _substitute_aliases(self, expr):\n                if expr is None:\n                        return expr\n                for alias, subst in Probe.aliases.items():\n                        expr = expr.replace(alias, subst)\n                return expr",
  "def _parse_signature(self):\n                params = map(str.strip, self.signature.split(','))\n                self.param_types = {}\n                for param in params:\n                        # If the type is a pointer, the * can be next to the\n                        # param name. Other complex types like arrays are not\n                        # supported right now.\n                        index = param.rfind('*')\n                        index = index if index != -1 else param.rfind(' ')\n                        param_type = param[0:index + 1].strip()\n                        param_name = param[index + 1:].strip()\n                        self.param_types[param_name] = param_type",
  "def _generate_entry(self):\n                self.entry_probe_func = self.probe_func_name + \"_entry\"\n                text = \"\"\"\nint PROBENAME(struct pt_regs *ctx SIGNATURE)\n{\n        u64 __pid_tgid = bpf_get_current_pid_tgid();\n        u32 __pid      = __pid_tgid;        // lower 32 bits\n        u32 __tgid     = __pid_tgid >> 32;  // upper 32 bits\n        PID_FILTER\n        COLLECT\n        return 0;\n}\n\"\"\"\n                text = text.replace(\"PROBENAME\", self.entry_probe_func)\n                text = text.replace(\"SIGNATURE\",\n                     \"\" if len(self.signature) == 0 else \", \" + self.signature)\n                text = text.replace(\"PID_FILTER\", self._generate_pid_filter())\n                collect = \"\"\n                for pname in self.args_to_probe:\n                        param_hash = self.hashname_prefix + pname\n                        if pname == \"__latency\":\n                                collect += \"\"\"\nu64 __time = bpf_ktime_get_ns();\n%s.update(&__pid, &__time);\n                        \"\"\" % param_hash\n                        else:\n                                collect += \"%s.update(&__pid, &%s);\\n\" % \\\n                                           (param_hash, pname)\n                text = text.replace(\"COLLECT\", collect)\n                return text",
  "def _generate_entry_probe(self):\n                # Any $entry(name) expressions result in saving that argument\n                # when entering the function.\n                self.args_to_probe = set()\n                regex = r\"\\$entry\\((\\w+)\\)\"\n                for expr in self.exprs:\n                        for arg in re.finditer(regex, expr):\n                                self.args_to_probe.add(arg.group(1))\n                for arg in re.finditer(regex, self.filter):\n                        self.args_to_probe.add(arg.group(1))\n                if any(map(lambda expr: \"$latency\" in expr, self.exprs)) or \\\n                   \"$latency\" in self.filter:\n                        self.args_to_probe.add(\"__latency\")\n                        self.param_types[\"__latency\"] = \"u64\"    # nanoseconds\n                for pname in self.args_to_probe:\n                        if pname not in self.param_types:\n                                raise ValueError(\"$entry(%s): no such param\" %\n                                                 arg)\n\n                self.hashname_prefix = \"%s_param_\" % self.probe_hash_name\n                text = \"\"\n                for pname in self.args_to_probe:\n                        # Each argument is stored in a separate hash that is\n                        # keyed by pid.\n                        text += \"BPF_HASH(%s, u32, %s);\\n\" % \\\n                             (self.hashname_prefix + pname,\n                              self.param_types[pname])\n                text += self._generate_entry()\n                return text",
  "def _generate_retprobe_prefix(self):\n                # After we're done here, there are __%s_val variables for each\n                # argument we needed to probe using $entry(name), and they all\n                # have values (which isn't necessarily the case if we missed\n                # the method entry probe).\n                text = \"\"\n                self.param_val_names = {}\n                for pname in self.args_to_probe:\n                        val_name = \"__%s_val\" % pname\n                        text += \"%s *%s = %s.lookup(&__pid);\\n\" % \\\n                                (self.param_types[pname], val_name,\n                                 self.hashname_prefix + pname)\n                        text += \"if (%s == 0) { return 0 ; }\\n\" % val_name\n                        self.param_val_names[pname] = val_name\n                return text",
  "def _replace_entry_exprs(self):\n                for pname, vname in self.param_val_names.items():\n                        if pname == \"__latency\":\n                                entry_expr = \"$latency\"\n                                val_expr = \"(bpf_ktime_get_ns() - *%s)\" % vname\n                        else:\n                                entry_expr = \"$entry(%s)\" % pname\n                                val_expr = \"(*%s)\" % vname\n                        for i in range(0, len(self.exprs)):\n                                self.exprs[i] = self.exprs[i].replace(\n                                                entry_expr, val_expr)\n                        self.filter = self.filter.replace(entry_expr,\n                                                          val_expr)",
  "def _attach_entry_probe(self):\n                if self.is_user:\n                        self.bpf.attach_uprobe(name=self.library,\n                                               sym=self.function,\n                                               fn_name=self.entry_probe_func,\n                                               pid=self.pid or -1)\n                else:\n                        self.bpf.attach_kprobe(event=self.function,\n                                               fn_name=self.entry_probe_func)",
  "def _bail(self, error):\n                raise ValueError(\"error parsing probe '%s': %s\" %\n                                 (self.raw_spec, error))",
  "def _validate_specifier(self):\n                # Everything after '#' is the probe label, ignore it\n                spec = self.raw_spec.split('#')[0]\n                parts = spec.strip().split(':')\n                if len(parts) < 3:\n                        self._bail(\"at least the probe type, library, and \" +\n                                   \"function signature must be specified\")\n                if len(parts) > 6:\n                        self._bail(\"extraneous ':'-separated parts detected\")\n                if parts[0] not in [\"r\", \"p\", \"t\", \"u\"]:\n                        self._bail(\"probe type must be 'p', 'r', 't', or 'u'\" +\n                                   \" but got '%s'\" % parts[0])\n                if re.match(r\"\\S+\\(.*\\)\", parts[2]) is None:\n                        self._bail((\"function signature '%s' has an invalid \" +\n                                    \"format\") % parts[2])",
  "def _parse_expr_types(self, expr_types):\n                if len(expr_types) == 0:\n                        self._bail(\"no expr types specified\")\n                self.expr_types = expr_types.split(',')",
  "def _parse_exprs(self, exprs):\n                if len(exprs) == 0:\n                        self._bail(\"no exprs specified\")\n                self.exprs = exprs.split(',')",
  "def _make_valid_identifier(self, ident):\n                return re.sub(r'[^A-Za-z0-9_]', '_', ident)",
  "def __init__(self, tool, type, specifier):\n                self.usdt_ctx = None\n                self.streq_functions = \"\"\n                self.pid = tool.args.pid\n                self.cumulative = tool.args.cumulative or False\n                self.raw_spec = specifier\n                self._validate_specifier()\n\n                spec_and_label = specifier.split('#')\n                self.label = spec_and_label[1] \\\n                             if len(spec_and_label) == 2 else None\n\n                parts = spec_and_label[0].strip().split(':')\n                self.type = type    # hist or freq\n                self.probe_type = parts[0]\n                fparts = parts[2].split('(')\n                self.function = fparts[0].strip()\n                if self.probe_type == \"t\":\n                        self.library = \"\"       # kernel\n                        self.tp_category = parts[1]\n                        self.tp_event = self.function\n                elif self.probe_type == \"u\":\n                        self.library = parts[1]\n                        self.probe_func_name = self._make_valid_identifier(\n                                \"%s_probe%d\" %\n                                (self.function, Probe.next_probe_index))\n                        self._enable_usdt_probe()\n                else:\n                        self.library = parts[1]\n                self.is_user = len(self.library) > 0\n                self.signature = fparts[1].strip()[:-1]\n                self._parse_signature()\n\n                # If the user didn't specify an expression to probe, we probe\n                # the retval in a ret probe, or simply the value \"1\" otherwise.\n                self.is_default_expr = len(parts) < 5\n                if not self.is_default_expr:\n                        self._parse_expr_types(parts[3])\n                        self._parse_exprs(parts[4])\n                        if len(self.exprs) != len(self.expr_types):\n                                self._bail(\"mismatched # of exprs and types\")\n                        if self.type == \"hist\" and len(self.expr_types) > 1:\n                                self._bail(\"histograms can only have 1 expr\")\n                else:\n                        if not self.probe_type == \"r\" and self.type == \"hist\":\n                                self._bail(\"histograms must have expr\")\n                        self.expr_types = \\\n                          [\"u64\" if not self.probe_type == \"r\" else \"int\"]\n                        self.exprs = \\\n                          [\"1\" if not self.probe_type == \"r\" else \"$retval\"]\n                self.filter = \"\" if len(parts) != 6 else parts[5]\n                self._substitute_exprs()\n\n                # Do we need to attach an entry probe so that we can collect an\n                # argument that is required for an exit (return) probe?\n                def check(expr):\n                        keywords = [\"$entry\", \"$latency\"]\n                        return any(map(lambda kw: kw in expr, keywords))\n                self.entry_probe_required = self.probe_type == \"r\" and \\\n                        (any(map(check, self.exprs)) or check(self.filter))\n\n                self.probe_func_name = self._make_valid_identifier(\n                        \"%s_probe%d\" %\n                        (self.function, Probe.next_probe_index))\n                self.probe_hash_name = self._make_valid_identifier(\n                        \"%s_hash%d\" %\n                        (self.function, Probe.next_probe_index))\n                Probe.next_probe_index += 1",
  "def _enable_usdt_probe(self):\n                self.usdt_ctx = USDT(path=self.library, pid=self.pid)\n                self.usdt_ctx.enable_probe(\n                        self.function, self.probe_func_name)",
  "def _generate_streq_function(self, string):\n                fname = \"streq_%d\" % Probe.streq_index\n                Probe.streq_index += 1\n                self.streq_functions += \"\"\"\nstatic inline bool %s(char const *ignored, char const *str) {\n        char needle[] = %s;\n        char haystack[sizeof(needle)];\n        bpf_probe_read(&haystack, sizeof(haystack), (void *)str);\n        for (int i = 0; i < sizeof(needle) - 1; ++i) {\n                if (needle[i] != haystack[i]) {\n                        return false;\n                }\n        }\n        return true;\n}\n                \"\"\" % (fname, string)\n                return fname",
  "def _substitute_exprs(self):\n                def repl(expr):\n                        expr = self._substitute_aliases(expr)\n                        matches = re.finditer('STRCMP\\\\((\"[^\"]+\\\\\")', expr)\n                        for match in matches:\n                                string = match.group(1)\n                                fname = self._generate_streq_function(string)\n                                expr = expr.replace(\"STRCMP\", fname, 1)\n                        return expr.replace(\"$retval\", \"PT_REGS_RC(ctx)\")\n                for i in range(0, len(self.exprs)):\n                        self.exprs[i] = repl(self.exprs[i])\n                self.filter = repl(self.filter)",
  "def _is_string(self, expr_type):\n                return expr_type == \"char*\" or expr_type == \"char *\"",
  "def _generate_hash_field(self, i):\n                if self._is_string(self.expr_types[i]):\n                        return \"struct __string_t v%d;\\n\" % i\n                else:\n                        return \"%s v%d;\\n\" % (self.expr_types[i], i)",
  "def _generate_usdt_arg_assignment(self, i):\n                expr = self.exprs[i]\n                if self.probe_type == \"u\" and expr[0:3] == \"arg\":\n                        arg_index = int(expr[3])\n                        arg_ctype = self.usdt_ctx.get_probe_arg_ctype(\n                                self.function, arg_index - 1)\n                        return (\"        %s %s = 0;\\n\" +\n                                \"        bpf_usdt_readarg(%s, ctx, &%s);\\n\") \\\n                                % (arg_ctype, expr, expr[3], expr)\n                else:\n                        return \"\"",
  "def _generate_field_assignment(self, i):\n                text = self._generate_usdt_arg_assignment(i)\n                if self._is_string(self.expr_types[i]):\n                        return (text + \"        bpf_probe_read(&__key.v%d.s,\" +\n                                \" sizeof(__key.v%d.s), (void *)%s);\\n\") % \\\n                                (i, i, self.exprs[i])\n                else:\n                        return text + \"        __key.v%d = %s;\\n\" % \\\n                               (i, self.exprs[i])",
  "def _generate_hash_decl(self):\n                if self.type == \"hist\":\n                        return \"BPF_HISTOGRAM(%s, %s);\" % \\\n                               (self.probe_hash_name, self.expr_types[0])\n                else:\n                        text = \"struct %s_key_t {\\n\" % self.probe_hash_name\n                        for i in range(0, len(self.expr_types)):\n                                text += self._generate_hash_field(i)\n                        text += \"};\\n\"\n                        text += \"BPF_HASH(%s, struct %s_key_t, u64);\\n\" % \\\n                                (self.probe_hash_name, self.probe_hash_name)\n                        return text",
  "def _generate_key_assignment(self):\n                if self.type == \"hist\":\n                        return self._generate_usdt_arg_assignment(0) + \\\n                               (\"%s __key = %s;\\n\" %\n                                (self.expr_types[0], self.exprs[0]))\n                else:\n                        text = \"struct %s_key_t __key = {};\\n\" % \\\n                                self.probe_hash_name\n                        for i in range(0, len(self.exprs)):\n                                text += self._generate_field_assignment(i)\n                        return text",
  "def _generate_hash_update(self):\n                if self.type == \"hist\":\n                        return \"%s.increment(bpf_log2l(__key));\" % \\\n                                self.probe_hash_name\n                else:\n                        return \"%s.increment(__key);\" % self.probe_hash_name",
  "def _generate_pid_filter(self):\n                # Kernel probes need to explicitly filter pid, because the\n                # attach interface doesn't support pid filtering\n                if self.pid is not None and not self.is_user:\n                        return \"if (__tgid != %d) { return 0; }\" % self.pid\n                else:\n                        return \"\"",
  "def generate_text(self):\n                program = \"\"\n                probe_text = \"\"\"\nDATA_DECL\n                \"\"\" + (\n                    \"TRACEPOINT_PROBE(%s, %s)\" %\n                    (self.tp_category, self.tp_event)\n                    if self.probe_type == \"t\"\n                    else \"int PROBENAME(struct pt_regs *ctx SIGNATURE)\") + \"\"\"\n{\n        u64 __pid_tgid = bpf_get_current_pid_tgid();\n        u32 __pid      = __pid_tgid;        // lower 32 bits\n        u32 __tgid     = __pid_tgid >> 32;  // upper 32 bits\n        PID_FILTER\n        PREFIX\n        if (!(FILTER)) return 0;\n        KEY_EXPR\n        COLLECT\n        return 0;\n}\n\"\"\"\n                prefix = \"\"\n                signature = \"\"\n\n                # If any entry arguments are probed in a ret probe, we need\n                # to generate an entry probe to collect them\n                if self.entry_probe_required:\n                        program += self._generate_entry_probe()\n                        prefix += self._generate_retprobe_prefix()\n                        # Replace $entry(paramname) with a reference to the\n                        # value we collected when entering the function:\n                        self._replace_entry_exprs()\n\n                if self.probe_type == \"p\" and len(self.signature) > 0:\n                        # Only entry uprobes/kprobes can have user-specified\n                        # signatures. Other probes force it to ().\n                        signature = \", \" + self.signature\n\n                program += probe_text.replace(\"PROBENAME\",\n                                              self.probe_func_name)\n                program = program.replace(\"SIGNATURE\", signature)\n                program = program.replace(\"PID_FILTER\",\n                                          self._generate_pid_filter())\n\n                decl = self._generate_hash_decl()\n                key_expr = self._generate_key_assignment()\n                collect = self._generate_hash_update()\n                program = program.replace(\"DATA_DECL\", decl)\n                program = program.replace(\"KEY_EXPR\", key_expr)\n                program = program.replace(\"FILTER\",\n                        \"1\" if len(self.filter) == 0 else self.filter)\n                program = program.replace(\"COLLECT\", collect)\n                program = program.replace(\"PREFIX\", prefix)\n\n                return self.streq_functions + program",
  "def _attach_u(self):\n                libpath = BPF.find_library(self.library)\n                if libpath is None:\n                        libpath = BPF.find_exe(self.library)\n                if libpath is None or len(libpath) == 0:\n                        self._bail(\"unable to find library %s\" % self.library)\n\n                if self.probe_type == \"r\":\n                        self.bpf.attach_uretprobe(name=libpath,\n                                                  sym=self.function,\n                                                  fn_name=self.probe_func_name,\n                                                  pid=self.pid or -1)\n                else:\n                        self.bpf.attach_uprobe(name=libpath,\n                                               sym=self.function,\n                                               fn_name=self.probe_func_name,\n                                               pid=self.pid or -1)",
  "def _attach_k(self):\n                if self.probe_type == \"t\":\n                        pass    # Nothing to do for tracepoints\n                elif self.probe_type == \"r\":\n                        self.bpf.attach_kretprobe(event=self.function,\n                                             fn_name=self.probe_func_name)\n                else:\n                        self.bpf.attach_kprobe(event=self.function,\n                                          fn_name=self.probe_func_name)",
  "def attach(self, bpf):\n                self.bpf = bpf\n                if self.probe_type == \"u\":\n                        return\n                if self.is_user:\n                        self._attach_u()\n                else:\n                        self._attach_k()\n                if self.entry_probe_required:\n                        self._attach_entry_probe()",
  "def _v2s(self, v):\n                # Most fields can be converted with plain str(), but strings\n                # are wrapped in a __string_t which has an .s field\n                if \"__string_t\" in type(v).__name__:\n                        return str(v.s)\n                return str(v)",
  "def _display_expr(self, i):\n                # Replace ugly latency calculation with $latency\n                expr = self.exprs[i].replace(\n                        \"(bpf_ktime_get_ns() - *____latency_val)\", \"$latency\")\n                # Replace alias values back with the alias name\n                for alias, subst in Probe.aliases.items():\n                        expr = expr.replace(subst, alias)\n                # Replace retval expression with $retval\n                expr = expr.replace(\"PT_REGS_RC(ctx)\", \"$retval\")\n                # Replace ugly (*__param_val) expressions with param name\n                return re.sub(r\"\\(\\*__(\\w+)_val\\)\", r\"\\1\", expr)",
  "def _display_key(self, key):\n                if self.is_default_expr:\n                        if not self.probe_type == \"r\":\n                                return \"total calls\"\n                        else:\n                                return \"retval = %s\" % str(key.v0)\n                else:\n                        # The key object has v0, ..., vk fields containing\n                        # the values of the expressions from self.exprs\n                        def str_i(i):\n                                key_i = self._v2s(getattr(key, \"v%d\" % i))\n                                return \"%s = %s\" % \\\n                                        (self._display_expr(i), key_i)\n                        return \", \".join(map(str_i, range(0, len(self.exprs))))",
  "def display(self, top):\n                data = self.bpf.get_table(self.probe_hash_name)\n                if self.type == \"freq\":\n                        print(self.label or self.raw_spec)\n                        print(\"\\t%-10s %s\" % (\"COUNT\", \"EVENT\"))\n                        sdata = sorted(data.items(), key=lambda p: p[1].value)\n                        if top is not None:\n                                sdata = sdata[-top:]\n                        for key, value in sdata:\n                                # Print some nice values if the user didn't\n                                # specify an expression to probe\n                                if self.is_default_expr:\n                                        if not self.probe_type == \"r\":\n                                                key_str = \"total calls\"\n                                        else:\n                                                key_str = \"retval = %s\" % \\\n                                                          self._v2s(key.v0)\n                                else:\n                                        key_str = self._display_key(key)\n                                print(\"\\t%-10s %s\" %\n                                      (str(value.value), key_str))\n                elif self.type == \"hist\":\n                        label = self.label or (self._display_expr(0)\n                                if not self.is_default_expr else \"retval\")\n                        data.print_log2_hist(val_type=label)\n                if not self.cumulative:\n                        data.clear()",
  "def __str__(self):\n                return self.label or self.raw_spec",
  "def __init__(self):\n                parser = argparse.ArgumentParser(description=\"Trace a \" +\n                  \"function and display a summary of its parameter values.\",\n                  formatter_class=argparse.RawDescriptionHelpFormatter,\n                  epilog=Tool.examples)\n                parser.add_argument(\"-p\", \"--pid\", type=int,\n                  help=\"id of the process to trace (optional)\")\n                parser.add_argument(\"-z\", \"--string-size\", default=80,\n                  type=int,\n                  help=\"maximum string size to read from char* arguments\")\n                parser.add_argument(\"-i\", \"--interval\", default=1, type=int,\n                  help=\"output interval, in seconds (default 1 second)\")\n                parser.add_argument(\"-d\", \"--duration\", type=int,\n                  help=\"total duration of trace, in seconds\")\n                parser.add_argument(\"-n\", \"--number\", type=int, dest=\"count\",\n                  help=\"number of outputs\")\n                parser.add_argument(\"-v\", \"--verbose\", action=\"store_true\",\n                  help=\"print resulting BPF program code before executing\")\n                parser.add_argument(\"-c\", \"--cumulative\", action=\"store_true\",\n                  help=\"do not clear histograms and freq counts at \" +\n                       \"each interval\")\n                parser.add_argument(\"-T\", \"--top\", type=int,\n                  help=\"number of top results to show (not applicable to \" +\n                  \"histograms)\")\n                parser.add_argument(\"-H\", \"--histogram\", action=\"append\",\n                  dest=\"histspecifier\", metavar=\"specifier\",\n                  help=\"probe specifier to capture histogram of \" +\n                  \"(see examples below)\")\n                parser.add_argument(\"-C\", \"--count\", action=\"append\",\n                  dest=\"countspecifier\", metavar=\"specifier\",\n                  help=\"probe specifier to capture count of \" +\n                  \"(see examples below)\")\n                parser.add_argument(\"-I\", \"--include\", action=\"append\",\n                  metavar=\"header\",\n                  help=\"additional header files to include in the BPF program \"\n                       \"as either full path, \"\n                       \"or relative to relative to current working directory, \"\n                       \"or relative to default kernel header search path\")\n                self.args = parser.parse_args()\n                self.usdt_ctx = None",
  "def _create_probes(self):\n                self.probes = []\n                for specifier in (self.args.countspecifier or []):\n                        self.probes.append(Probe(self, \"freq\", specifier))\n                for histspecifier in (self.args.histspecifier or []):\n                        self.probes.append(Probe(self, \"hist\", histspecifier))\n                if len(self.probes) == 0:\n                        print(\"at least one specifier is required\")\n                        exit(1)",
  "def _generate_program(self):\n                bpf_source = \"\"\"\nstruct __string_t { char s[%d]; };\n\n#include <uapi/linux/ptrace.h>\n                \"\"\" % self.args.string_size\n                for include in (self.args.include or []):\n                        if include.startswith((\".\", \"/\")):\n                                include = os.path.abspath(include)\n                                bpf_source += \"#include \\\"%s\\\"\\n\" % include\n                        else:\n                                bpf_source += \"#include <%s>\\n\" % include\n\n                bpf_source += BPF.generate_auto_includes(\n                                map(lambda p: p.raw_spec, self.probes))\n                for probe in self.probes:\n                        bpf_source += probe.generate_text()\n                if self.args.verbose:\n                        for text in [probe.usdt_ctx.get_text()\n                                     for probe in self.probes\n                                     if probe.usdt_ctx]:\n                            print(text)\n                        print(bpf_source)\n                usdt_contexts = [probe.usdt_ctx\n                                 for probe in self.probes if probe.usdt_ctx]\n                self.bpf = BPF(text=bpf_source, usdt_contexts=usdt_contexts)",
  "def _attach(self):\n                for probe in self.probes:\n                        probe.attach(self.bpf)\n                if self.args.verbose:\n                        print(\"open uprobes: %s\" % list(self.bpf.uprobe_fds.keys()))\n                        print(\"open kprobes: %s\" % list(self.bpf.kprobe_fds.keys()))",
  "def _main_loop(self):\n                count_so_far = 0\n                seconds = 0\n                while True:\n                        try:\n                                sleep(self.args.interval)\n                                seconds += self.args.interval\n                        except KeyboardInterrupt:\n                                exit()\n                        print(\"[%s]\" % strftime(\"%H:%M:%S\"))\n                        for probe in self.probes:\n                                probe.display(self.args.top)\n                        count_so_far += 1\n                        if self.args.count is not None and \\\n                           count_so_far >= self.args.count:\n                                exit()\n                        if self.args.duration and \\\n                           seconds >= self.args.duration:\n                                exit()",
  "def run(self):\n                try:\n                        self._create_probes()\n                        self._generate_program()\n                        self._attach()\n                        self._main_loop()\n                except:\n                        exc_info = sys.exc_info()\n                        sys_exit = exc_info[0] is SystemExit\n                        if self.args.verbose:\n                                traceback.print_exc()\n                        elif not sys_exit:\n                                print(exc_info[1])\n                        exit(0 if sys_exit else 1)",
  "def check(expr):\n                        keywords = [\"$entry\", \"$latency\"]\n                        return any(map(lambda kw: kw in expr, keywords))",
  "def repl(expr):\n                        expr = self._substitute_aliases(expr)\n                        matches = re.finditer('STRCMP\\\\((\"[^\"]+\\\\\")', expr)\n                        for match in matches:\n                                string = match.group(1)\n                                fname = self._generate_streq_function(string)\n                                expr = expr.replace(\"STRCMP\", fname, 1)\n                        return expr.replace(\"$retval\", \"PT_REGS_RC(ctx)\")",
  "def str_i(i):\n                                key_i = self._v2s(getattr(key, \"v%d\" % i))\n                                return \"%s = %s\" % \\\n                                        (self._display_expr(i), key_i)",
  "def usage():\n    print(\"USAGE: %s [-Ch] {PTS | /dev/ttydev}  # try -h for help\" % argv[0])\n    exit()",
  "class Data(ct.Structure):\n    _fields_ = [\n        (\"count\", ct.c_int),\n        (\"buf\", ct.c_char * BUFSIZE)\n    ]",
  "def print_event(cpu, data, size):\n    event = ct.cast(data, ct.POINTER(Data)).contents\n    print(\"%s\" % event.buf[0:event.count].decode('utf-8', 'replace'), end=\"\")\n    sys.stdout.flush()",
  "class Data(ct.Structure):\n    _fields_ = [\n        (\"time\", ct.c_ulonglong),\n        (\"stack_id\", ct.c_longlong),\n        (\"cpu\", ct.c_int),\n        (\"id\", ct.c_ulonglong),\n        (\"addrs\", ct.c_int * 4),\n        (\"comm\", ct.c_char * TASK_COMM_LEN),\n    ]",
  "def get_syms(kstack):\n    syms = []\n\n    for addr in kstack:\n        s = b.ksym(addr, show_offset=True)\n        syms.append(s)\n\n    return syms",
  "def print_event(cpu, data, size):\n    try:\n        global b\n        event = ct.cast(data, ct.POINTER(Data)).contents\n        stack_traces = b['stack_traces']\n        stext = b.ksymname('_stext')\n\n        print(\"===================================\")\n        print(\"TASK: %s (pid %5d tid %5d) Total Time: %-9.3fus\\n\\n\" % (event.comm, \\\n            (event.id >> 32), (event.id & 0xffffffff), float(event.time) / 1000), end=\"\")\n        print(\"Section start: {} -> {}\".format(b.ksym(stext + event.addrs[0]), b.ksym(stext + event.addrs[1])))\n        print(\"Section end:   {} -> {}\".format(b.ksym(stext + event.addrs[2]), b.ksym(stext + event.addrs[3])))\n\n        if event.stack_id >= 0:\n            kstack = stack_traces.walk(event.stack_id)\n            syms = get_syms(kstack)\n            if not syms:\n                return\n\n            for s in syms:\n                print(\"  \", end=\"\")\n                print(\"%s\" % s)\n        else:\n            print(\"NO STACK FOUND DUE TO COLLISION\")\n        print(\"===================================\")\n        print(\"\")\n    except Exception:\n        sys.exit(0)",
  "def signal_ignore(signal, frame):\n    print()",
  "def get_meminfo():\n    result = dict()\n\n    for line in open('/proc/meminfo'):\n        k = line.split(':', 3)\n        v = k[1].split()\n        result[k[0]] = int(v[0])\n    return result",
  "class Allocation(object):\n    def __init__(self, stack, size):\n        self.stack = stack\n        self.count = 1\n        self.size = size\n\n    def update(self, size):\n        self.count += 1\n        self.size += size",
  "def run_command_get_output(command):\n        p = subprocess.Popen(command.split(),\n                stdout=subprocess.PIPE, stderr=subprocess.STDOUT)\n        return iter(p.stdout.readline, b'')",
  "def run_command_get_pid(command):\n        p = subprocess.Popen(command.split())\n        return p.pid",
  "def print_outstanding():\n        print(\"[%s] Top %d stacks with outstanding allocations:\" %\n              (datetime.now().strftime(\"%H:%M:%S\"), top_stacks))\n        alloc_info = {}\n        allocs = bpf[\"allocs\"]\n        stack_traces = bpf[\"stack_traces\"]\n        for address, info in sorted(allocs.items(), key=lambda a: a[1].size):\n                if BPF.monotonic_time() - min_age_ns < info.timestamp_ns:\n                        continue\n                if info.stack_id < 0:\n                        continue\n                if info.stack_id in alloc_info:\n                        alloc_info[info.stack_id].update(info.size)\n                else:\n                        stack = list(stack_traces.walk(info.stack_id))\n                        combined = []\n                        for addr in stack:\n                                combined.append(bpf.sym(addr, pid,\n                                        show_module=True, show_offset=True))\n                        alloc_info[info.stack_id] = Allocation(combined,\n                                                               info.size)\n                if args.show_allocs:\n                        print(\"\\taddr = %x size = %s\" %\n                              (address.value, info.size))\n        to_show = sorted(alloc_info.values(),\n                         key=lambda a: a.size)[-top_stacks:]\n        for alloc in to_show:\n                print(\"\\t%d bytes in %d allocations from stack\\n\\t\\t%s\" %\n                      (alloc.size, alloc.count, b\"\\n\\t\\t\".join(alloc.stack)))",
  "def print_outstanding_combined():\n        stack_traces = bpf[\"stack_traces\"]\n        stacks = sorted(bpf[\"combined_allocs\"].items(),\n                        key=lambda a: -a[1].total_size)\n        cnt = 1\n        entries = []\n        for stack_id, info in stacks:\n                try:\n                        trace = []\n                        for addr in stack_traces.walk(stack_id.value):\n                                sym = bpf.sym(addr, pid,\n                                                      show_module=True,\n                                                      show_offset=True)\n                                trace.append(sym)\n                        trace = \"\\n\\t\\t\".join(trace)\n                except KeyError:\n                        trace = \"stack information lost\"\n\n                entry = (\"\\t%d bytes in %d allocations from stack\\n\\t\\t%s\" %\n                         (info.total_size, info.number_of_allocs, trace))\n                entries.append(entry)\n\n                cnt += 1\n                if cnt > top_stacks:\n                        break\n\n        print(\"[%s] Top %d stacks with outstanding allocations:\" %\n              (datetime.now().strftime(\"%H:%M:%S\"), top_stacks))\n\n        print('\\n'.join(reversed(entries)))",
  "def __init__(self, stack, size):\n        self.stack = stack\n        self.count = 1\n        self.size = size",
  "def update(self, size):\n        self.count += 1\n        self.size += size",
  "def attach_probes(sym, fn_prefix=None, can_fail=False):\n                if fn_prefix is None:\n                        fn_prefix = sym\n\n                try:\n                        bpf.attach_uprobe(name=obj, sym=sym,\n                                          fn_name=fn_prefix + \"_enter\",\n                                          pid=pid)\n                        bpf.attach_uretprobe(name=obj, sym=sym,\n                                             fn_name=fn_prefix + \"_exit\",\n                                             pid=pid)\n                except Exception:\n                        if can_fail:\n                                return\n                        else:\n                                raise",
  "class Data(ct.Structure):\n    _fields_ = [\n        (\"pid\", ct.c_uint),\n        (\"type\", ct.c_int),\n        (\"comm\", ct.c_char * TASK_COMM_LEN),\n        (\"filename\", ct.c_char * MAX_FILE_LEN),\n    ]",
  "def print_event(cpu, data, size):\n    event = ct.cast(data, ct.POINTER(Data)).contents\n    print(\"%-11.6f %-6d %-16s %1s %s\" % (\n            time.time() - start_ts, event.pid,\n            event.comm.decode('utf-8', 'replace'), mode_s[event.type],\n            event.filename.decode('utf-8', 'replace')))",
  "class Data(ct.Structure):\n    _fields_ = [\n        (\"pid\", ct.c_uint),\n        (\"ppid\", ct.c_uint),\n        (\"comm\", ct.c_char * TASK_COMM_LEN),\n        (\"type\", ct.c_int),\n        (\"argv\", ct.c_char * ARGSIZE),\n        (\"retval\", ct.c_int),\n    ]",
  "class EventType(object):\n    EVENT_ARG = 0\n    EVENT_RET = 1",
  "def get_ppid(pid):\n    try:\n        with open(\"/proc/%d/status\" % pid) as status:\n            for line in status:\n                if line.startswith(\"PPid:\"):\n                    return int(line.split()[1])\n    except IOError:\n        pass\n    return 0",
  "def print_event(cpu, data, size):\n    event = ct.cast(data, ct.POINTER(Data)).contents\n\n    skip = False\n\n    if event.type == EventType.EVENT_ARG:\n        argv[event.pid].append(event.argv)\n    elif event.type == EventType.EVENT_RET:\n        if event.retval != 0 and not args.fails:\n            skip = True\n        if args.name and not re.search(bytes(args.name), event.comm):\n            skip = True\n        if args.line and not re.search(bytes(args.line),\n                                       b' '.join(argv[event.pid])):\n            skip = True\n        if args.quote:\n            argv[event.pid] = [\n                \"\\\"\" + arg.replace(\"\\\"\", \"\\\\\\\"\") + \"\\\"\"\n                for arg in argv[event.pid]\n            ]\n\n        if not skip:\n            if args.timestamp:\n                print(\"%-8.3f\" % (time.time() - start_ts), end=\"\")\n            ppid = event.ppid if event.ppid > 0 else get_ppid(event.pid)\n            ppid = b\"%d\" % ppid if ppid > 0 else b\"?\"\n            argv_text = b' '.join(argv[event.pid]).replace(b'\\n', b'\\\\n')\n            printb(b\"%-16s %-6d %-6s %3d %s\" % (event.comm, event.pid,\n                   ppid, event.retval, argv_text))\n        try:\n            del(argv[event.pid])\n        except Exception:\n            pass",
  "class Data(ct.Structure):\n    _fields_ = [\n        (\"ts\", ct.c_ulonglong)\n    ]",
  "def print_event(cpu, data, size):\n    event = ct.cast(data, ct.POINTER(Data)).contents\n    print(\"%-18.9f sync()\" % (float(event.ts) / 1000000))",
  "class Data(ct.Structure):\n    _fields_ = [\n        (\"id\",      ct.c_ulonglong),\n        (\"ts\",      ct.c_ulonglong),\n        (\"sys\",     ct.c_int),\n        (\"key\",     ct.c_ulong),\n        (\"size\",    ct.c_ulong),\n        (\"shmflg\",  ct.c_ulong),\n        (\"shmid\",   ct.c_ulong),\n        (\"cmd\",     ct.c_ulong),\n        (\"buf\",     ct.c_ulong),\n        (\"shmaddr\", ct.c_ulong),\n        (\"ret\",     ct.c_ulong),\n        (\"comm\",    ct.c_char * TASK_COMM_LEN),\n    ]",
  "def sys_name(sys):\n    switcher = {\n        SYS_SHMGET: \"SHMGET\",\n        SYS_SHMAT:  \"SHMAT\",\n        SYS_SHMDT:  \"SHMDT\",\n        SYS_SHMCTL: \"SHMCTL\",\n    }\n    return switcher.get(sys, \"N/A\")",
  "def shmflg_str(val, flags):\n    cur = filter(lambda x : x['value'] & val, flags)\n    str = \"0x%x\" % val\n\n    if (not val):\n        return str\n\n    str += \" (\"\n    cnt = 0\n    for x in cur:\n        if cnt:\n            str += \"|\"\n        str +=  x['name']\n        val &= ~x['value']\n        cnt += 1\n\n    if val != 0 or not cnt:\n        if cnt:\n            str += \"|\"\n        str += \"0%o\" % val\n\n    str += \")\"\n    return str",
  "def print_event(cpu, data, size):\n    event = ct.cast(data, ct.POINTER(Data)).contents\n    global initial_ts\n\n    if not initial_ts:\n        initial_ts = event.ts\n\n    if args.name and bytes(args.name) not in event.comm:\n        return\n\n    if args.timestamp:\n        delta = event.ts - initial_ts\n        print(\"%-14.9f\" % (float(delta) / 1000000), end=\"\")\n\n    print(\"%-6d %-16s %6s %16lx \" %\n          (event.id & 0xffffffff if args.tid else event.id >> 32,\n           event.comm.decode(), sys_name(event.sys), event.ret), end = '')\n\n    if event.sys == SYS_SHMGET:\n        print(\"key: 0x%lx, size: %lu, shmflg: %s\" %\n              (event.key, event.size, shmflg_str(event.shmflg, shmget_flags)))\n\n    if event.sys == SYS_SHMAT:\n        print(\"shmid: 0x%lx, shmaddr: 0x%lx, shmflg: %s\" %\n              (event.shmid, event.shmaddr, shmflg_str(event.shmflg, shmat_flags)))\n\n    if event.sys == SYS_SHMDT:\n        print(\"shmaddr: 0x%lx\" % (event.shmaddr))\n\n    if event.sys == SYS_SHMCTL:\n        print(\"shmid: 0x%lx, cmd: %lu, buf: 0x%x\" % (event.shmid, event.cmd, event.buf))",
  "def signal_ignore(signal, frame):\n    print()",
  "def get_meminfo():\n    result = {}\n\n    for line in open('/proc/meminfo'):\n        k = line.split(':', 3)\n        v = k[1].split()\n        result[k[0]] = int(v[0])\n    return result",
  "def get_processes_stats(\n        bpf,\n        sort_field=DEFAULT_SORT_FIELD,\n        sort_reverse=False):\n    '''\n    Return a tuple containing:\n    buffer\n    cached\n    list of tuple with per process cache stats\n    '''\n    counts = bpf.get_table(\"counts\")\n    stats = defaultdict(lambda: defaultdict(int))\n    for k, v in counts.items():\n        stats[\"%d-%d-%s\" % (k.pid, k.uid, k.comm.decode('utf-8', 'replace'))][k.ip] = v.value\n    stats_list = []\n\n    for pid, count in sorted(stats.items(), key=lambda stat: stat[0]):\n        rtaccess = 0\n        wtaccess = 0\n        mpa = 0\n        mbd = 0\n        apcl = 0\n        apd = 0\n        access = 0\n        misses = 0\n        rhits = 0\n        whits = 0\n\n        for k, v in count.items():\n            if re.match(b'mark_page_accessed', bpf.ksym(k)) is not None:\n                mpa = max(0, v)\n\n            if re.match(b'mark_buffer_dirty', bpf.ksym(k)) is not None:\n                mbd = max(0, v)\n\n            if re.match(b'add_to_page_cache_lru', bpf.ksym(k)) is not None:\n                apcl = max(0, v)\n\n            if re.match(b'account_page_dirtied', bpf.ksym(k)) is not None:\n                apd = max(0, v)\n\n            # access = total cache access incl. reads(mpa) and writes(mbd)\n            # misses = total of add to lru which we do when we write(mbd)\n            # and also the mark the page dirty(same as mbd)\n            access = (mpa + mbd)\n            misses = (apcl + apd)\n\n            # rtaccess is the read hit % during the sample period.\n            # wtaccess is the write hit % during the smaple period.\n            if mpa > 0:\n                rtaccess = float(mpa) / (access + misses)\n            if apcl > 0:\n                wtaccess = float(apcl) / (access + misses)\n\n            if wtaccess != 0:\n                whits = 100 * wtaccess\n            if rtaccess != 0:\n                rhits = 100 * rtaccess\n\n        _pid, uid, comm = pid.split('-', 2)\n        stats_list.append(\n            (int(_pid), uid, comm,\n             access, misses, mbd,\n             rhits, whits))\n\n    stats_list = sorted(\n        stats_list, key=lambda stat: stat[sort_field], reverse=sort_reverse\n    )\n    counts.clear()\n    return stats_list",
  "def handle_loop(stdscr, args):\n    # don't wait on key press\n    stdscr.nodelay(1)\n    # set default sorting field\n    sort_field = FIELDS.index(DEFAULT_FIELD)\n    sort_reverse = False\n\n    # load BPF program\n    bpf_text = \"\"\"\n\n    #include <uapi/linux/ptrace.h>\n    struct key_t {\n        u64 ip;\n        u32 pid;\n        u32 uid;\n        char comm[16];\n    };\n\n    BPF_HASH(counts, struct key_t);\n\n    int do_count(struct pt_regs *ctx) {\n        struct key_t key = {};\n        u64 pid = bpf_get_current_pid_tgid();\n        u32 uid = bpf_get_current_uid_gid();\n\n        key.ip = PT_REGS_IP(ctx);\n        key.pid = pid & 0xFFFFFFFF;\n        key.uid = uid & 0xFFFFFFFF;\n        bpf_get_current_comm(&(key.comm), 16);\n\n        counts.increment(key);\n        return 0;\n    }\n\n    \"\"\"\n    b = BPF(text=bpf_text)\n    b.attach_kprobe(event=\"add_to_page_cache_lru\", fn_name=\"do_count\")\n    b.attach_kprobe(event=\"mark_page_accessed\", fn_name=\"do_count\")\n    b.attach_kprobe(event=\"account_page_dirtied\", fn_name=\"do_count\")\n    b.attach_kprobe(event=\"mark_buffer_dirty\", fn_name=\"do_count\")\n\n    exiting = 0\n\n    while 1:\n        s = stdscr.getch()\n        if s == ord('q'):\n            exiting = 1\n        elif s == ord('r'):\n            sort_reverse = not sort_reverse\n        elif s == ord('<'):\n            sort_field = max(0, sort_field - 1)\n        elif s == ord('>'):\n            sort_field = min(len(FIELDS) - 1, sort_field + 1)\n        try:\n            sleep(args.interval)\n        except KeyboardInterrupt:\n            exiting = 1\n            # as cleanup can take many seconds, trap Ctrl-C:\n            signal.signal(signal.SIGINT, signal_ignore)\n\n        # Get memory info\n        mem = get_meminfo()\n        cached = int(mem[\"Cached\"]) / 1024\n        buff = int(mem[\"Buffers\"]) / 1024\n\n        process_stats = get_processes_stats(\n            b,\n            sort_field=sort_field,\n            sort_reverse=sort_reverse)\n        stdscr.clear()\n        stdscr.addstr(\n            0, 0,\n            \"%-8s Buffers MB: %.0f / Cached MB: %.0f \"\n            \"/ Sort: %s / Order: %s\" % (\n                strftime(\"%H:%M:%S\"), buff, cached, FIELDS[sort_field],\n                sort_reverse and \"descending\" or \"ascending\"\n            )\n        )\n\n        # header\n        stdscr.addstr(\n            1, 0,\n            \"{0:8} {1:8} {2:16} {3:8} {4:8} {5:8} {6:10} {7:10}\".format(\n                *FIELDS\n            ),\n            curses.A_REVERSE\n        )\n        (height, width) = stdscr.getmaxyx()\n        for i, stat in enumerate(process_stats):\n            uid = int(stat[1])\n            try:\n                username = pwd.getpwuid(uid)[0]\n            except KeyError:\n                # `pwd` throws a KeyError if the user cannot be found. This can\n                # happen e.g. when the process is running in a cgroup that has\n                # different users from the host.\n                username = 'UNKNOWN({})'.format(uid)\n\n            stdscr.addstr(\n                i + 2, 0,\n                \"{0:8} {username:8.8} {2:16} {3:8} {4:8} \"\n                \"{5:8} {6:9.1f}% {7:9.1f}%\".format(\n                    *stat, username=username\n                )\n            )\n            if i > height - 4:\n                break\n        stdscr.refresh()\n        if exiting:\n            print(\"Detaching...\")\n            return",
  "def parse_arguments():\n    parser = argparse.ArgumentParser(\n        description='show Linux page cache hit/miss statistics including read '\n                    'and write hit % per processes in a UI like top.'\n    )\n    parser.add_argument(\n        'interval', type=int, default=5, nargs='?',\n        help='Interval between probes.'\n    )\n\n    args = parser.parse_args()\n    return args",
  "class Data(ct.Structure):\n    _fields_ = [\n        (\"pid\", ct.c_ulonglong),\n        (\"str\", ct.c_char * STR_DATA)\n    ]",
  "def print_event(cpu, data, size):\n    event = ct.cast(data, ct.POINTER(Data)).contents\n    print(\"%-9s %-6d %s\" % (strftime(\"%H:%M:%S\"), event.pid,\n                            event.str.decode('utf-8', 'replace')))",
  "class Data(ct.Structure):\n    _fields_ = [\n        (\"pid\", ct.c_ulonglong),\n        (\"ts_ns\", ct.c_ulonglong),\n        (\"ret\", ct.c_int),\n        (\"comm\", ct.c_char * TASK_COMM_LEN),\n        (\"fname\", ct.c_char * NAME_MAX)\n    ]",
  "def print_event(cpu, data, size):\n    event = ct.cast(data, ct.POINTER(Data)).contents\n    global start_ts\n    global prev_ts\n    global delta\n    global cont\n\n    # split return value into FD and errno columns\n    if event.ret >= 0:\n        fd_s = event.ret\n        err = 0\n    else:\n        fd_s = -1\n        err = - event.ret\n\n    if start_ts == 0:\n        start_ts = event.ts_ns\n\n    if args.timestamp:\n        print(\"%-14.9f\" % (float(event.ts_ns - start_ts) / 1000000000), end=\"\")\n\n    print(\"%-6d %-16s %4d %3d %s\" % (event.pid,\n        event.comm.decode('utf-8', 'replace'), fd_s, err,\n        event.fname.decode('utf-8', 'replace')))",
  "def mask_to_int(n):\n    return ((1 << n) - 1) << (32 - n)",
  "def parse_subnets(subnets):\n    m = []\n    for s in subnets:\n        parts = s.split(\"/\")\n        if len(parts) != 2:\n            msg = \"Subnet [%s] is invalid, please refer to the examples.\" % s\n            raise ValueError(msg)\n        netaddr_int = 0\n        mask_int = 0\n        try:\n            netaddr_int = struct.unpack(\"!I\", socket.inet_aton(parts[0]))[0]\n        except:\n            msg = (\"Invalid net address in subnet [%s], \" +\n                \"please refer to the examples.\") % s\n            raise ValueError(msg)\n        try:\n            mask_int = int(parts[1])\n        except:\n            msg = \"Invalid mask in subnet [%s]. Mask must be an int\" % s\n            raise ValueError(msg)\n        if mask_int < 0 or mask_int > 32:\n            msg = (\"Invalid mask in subnet [%s]. Must be an \" +\n                \"int between 0 and 32.\") % s\n            raise ValueError(msg)\n        mask_int = mask_to_int(int(parts[1]))\n        m.append([s, netaddr_int, mask_int])\n    return m",
  "def generate_bpf_subnets(subnets):\n    template = \"\"\"\n        if (!categorized && (__NET_ADDR__ & __NET_MASK__) ==\n             (dst & __NET_MASK__)) {\n          struct index_key_t key = {.index = __POS__};\n          ipv4_send_bytes.increment(key, size);\n          categorized = 1;\n        }\n    \"\"\"\n    bpf = ''\n    for i, s in enumerate(subnets):\n        branch = template\n        branch = branch.replace(\"__NET_ADDR__\", str(socket.htonl(s[1])))\n        branch = branch.replace(\"__NET_MASK__\", str(socket.htonl(s[2])))\n        branch = branch.replace(\"__POS__\", str(i))\n        bpf += branch\n    return bpf",
  "def signal_ignore(signal, frame):\n    print()",
  "class Data_ipv4(ct.Structure):\n    _fields_ = [\n        (\"ts_us\", ct.c_ulonglong),\n        (\"skaddr\", ct.c_ulonglong),\n        (\"saddr\", ct.c_uint),\n        (\"daddr\", ct.c_uint),\n        (\"span_us\", ct.c_ulonglong),\n        (\"pid\", ct.c_uint),\n        (\"ports\", ct.c_uint),\n        (\"oldstate\", ct.c_uint),\n        (\"newstate\", ct.c_uint),\n        (\"task\", ct.c_char * TASK_COMM_LEN)\n    ]",
  "class Data_ipv6(ct.Structure):\n    _fields_ = [\n        (\"ts_us\", ct.c_ulonglong),\n        (\"skaddr\", ct.c_ulonglong),\n        (\"saddr\", (ct.c_ulonglong * 2)),\n        (\"daddr\", (ct.c_ulonglong * 2)),\n        (\"span_us\", ct.c_ulonglong),\n        (\"pid\", ct.c_uint),\n        (\"ports\", ct.c_uint),\n        (\"oldstate\", ct.c_uint),\n        (\"newstate\", ct.c_uint),\n        (\"task\", ct.c_char * TASK_COMM_LEN)\n    ]",
  "def tcpstate2str(state):\n    # from include/net/tcp_states.h:\n    tcpstate = {\n        1: \"ESTABLISHED\",\n        2: \"SYN_SENT\",\n        3: \"SYN_RECV\",\n        4: \"FIN_WAIT1\",\n        5: \"FIN_WAIT2\",\n        6: \"TIME_WAIT\",\n        7: \"CLOSE\",\n        8: \"CLOSE_WAIT\",\n        9: \"LAST_ACK\",\n        10: \"LISTEN\",\n        11: \"CLOSING\",\n        12: \"NEW_SYN_RECV\",\n    }\n\n    if state in tcpstate:\n        return tcpstate[state]\n    else:\n        return str(state)",
  "def journal_fields(event, addr_family):\n    addr_pfx = 'IPV4'\n    if addr_family == AF_INET6:\n        addr_pfx = 'IPV6'\n\n    fields = {\n        # Standard fields described in systemd.journal-fields(7). journal.send\n        # will fill in CODE_LINE, CODE_FILE, and CODE_FUNC for us. If we're\n        # root and specify OBJECT_PID, systemd-journald will add other OBJECT_*\n        # fields for us.\n        'SYSLOG_IDENTIFIER': 'tcpstates',\n        'PRIORITY': 5,\n        '_SOURCE_REALTIME_TIMESTAMP': time() * 1000000,\n        'OBJECT_PID': str(event.pid),\n        'OBJECT_COMM': event.task.decode('utf-8', 'replace'),\n        # Custom fields, aka \"stuff we sort of made up\".\n        'OBJECT_' + addr_pfx + '_SOURCE_ADDRESS': inet_ntop(addr_family, pack(\"I\", event.saddr)),\n        'OBJECT_TCP_SOURCE_PORT': str(event.ports >> 32),\n        'OBJECT_' + addr_pfx + '_DESTINATION_ADDRESS': inet_ntop(addr_family, pack(\"I\", event.daddr)),\n        'OBJECT_TCP_DESTINATION_PORT': str(event.ports & 0xffffffff),\n        'OBJECT_TCP_OLD_STATE': tcpstate2str(event.oldstate),\n        'OBJECT_TCP_NEW_STATE': tcpstate2str(event.newstate),\n        'OBJECT_TCP_SPAN_TIME': str(event.span_us)\n        }\n\n    msg_format_string = (u\"%(OBJECT_COMM)s \" +\n        u\"%(OBJECT_\" + addr_pfx + \"_SOURCE_ADDRESS)s \" +\n        u\"%(OBJECT_TCP_SOURCE_PORT)s \u2192 \" +\n        u\"%(OBJECT_\" + addr_pfx + \"_DESTINATION_ADDRESS)s \" +\n        u\"%(OBJECT_TCP_DESTINATION_PORT)s \" +\n        u\"%(OBJECT_TCP_OLD_STATE)s \u2192 %(OBJECT_TCP_NEW_STATE)s\")\n    fields['MESSAGE'] = msg_format_string % (fields)\n\n    if getuid() == 0:\n        del fields['OBJECT_COMM'] # Handled by systemd-journald\n\n    return fields",
  "def print_ipv4_event(cpu, data, size):\n    event = ct.cast(data, ct.POINTER(Data_ipv4)).contents\n    global start_ts\n    if args.time:\n        if args.csv:\n            print(\"%s,\" % strftime(\"%H:%M:%S\"), end=\"\")\n        else:\n            print(\"%-8s \" % strftime(\"%H:%M:%S\"), end=\"\")\n    if args.timestamp:\n        if start_ts == 0:\n            start_ts = event.ts_us\n        delta_s = (float(event.ts_us) - start_ts) / 1000000\n        if args.csv:\n            print(\"%.6f,\" % delta_s, end=\"\")\n        else:\n            print(\"%-9.6f \" % delta_s, end=\"\")\n    print(format_string % (event.skaddr, event.pid, event.task.decode('utf-8', 'replace'),\n        \"4\" if args.wide or args.csv else \"\",\n        inet_ntop(AF_INET, pack(\"I\", event.saddr)), event.ports >> 32,\n        inet_ntop(AF_INET, pack(\"I\", event.daddr)), event.ports & 0xffffffff,\n        tcpstate2str(event.oldstate), tcpstate2str(event.newstate),\n        float(event.span_us) / 1000))\n    if args.journal:\n        journal.send(**journal_fields(event, AF_INET))",
  "def print_ipv6_event(cpu, data, size):\n    event = ct.cast(data, ct.POINTER(Data_ipv6)).contents\n    global start_ts\n    if args.time:\n        if args.csv:\n            print(\"%s,\" % strftime(\"%H:%M:%S\"), end=\"\")\n        else:\n            print(\"%-8s \" % strftime(\"%H:%M:%S\"), end=\"\")\n    if args.timestamp:\n        if start_ts == 0:\n            start_ts = event.ts_us\n        delta_s = (float(event.ts_us) - start_ts) / 1000000\n        if args.csv:\n            print(\"%.6f,\" % delta_s, end=\"\")\n        else:\n            print(\"%-9.6f \" % delta_s, end=\"\")\n    print(format_string % (event.skaddr, event.pid, event.task.decode('utf-8', 'replace'),\n        \"6\" if args.wide or args.csv else \"\",\n        inet_ntop(AF_INET6, event.saddr), event.ports >> 32,\n        inet_ntop(AF_INET6, event.daddr), event.ports & 0xffffffff,\n        tcpstate2str(event.oldstate), tcpstate2str(event.newstate),\n        float(event.span_us) / 1000))\n    if args.journal:\n        journal.send(**journal_fields(event, AF_INET6))",
  "class Data_ipv4(ct.Structure):\n    _fields_ = [\n        (\"pid\", ct.c_uint),\n        (\"ip\", ct.c_ulonglong),\n        (\"saddr\", ct.c_uint),\n        (\"daddr\", ct.c_uint),\n        (\"lport\", ct.c_ushort),\n        (\"dport\", ct.c_ushort),\n        (\"state\", ct.c_ulonglong),\n        (\"type\", ct.c_ulonglong)\n    ]",
  "class Data_ipv6(ct.Structure):\n    _fields_ = [\n        (\"pid\", ct.c_uint),\n        (\"ip\", ct.c_ulonglong),\n        (\"saddr\", (ct.c_ulonglong * 2)),\n        (\"daddr\", (ct.c_ulonglong * 2)),\n        (\"lport\", ct.c_ushort),\n        (\"dport\", ct.c_ushort),\n        (\"state\", ct.c_ulonglong),\n        (\"type\", ct.c_ulonglong)\n    ]",
  "def print_ipv4_event(cpu, data, size):\n    event = ct.cast(data, ct.POINTER(Data_ipv4)).contents\n    print(\"%-8s %-6d %-2d %-20s %1s> %-20s %s\" % (\n        strftime(\"%H:%M:%S\"), event.pid, event.ip,\n        \"%s:%d\" % (inet_ntop(AF_INET, pack('I', event.saddr)), event.lport),\n        type[event.type],\n        \"%s:%s\" % (inet_ntop(AF_INET, pack('I', event.daddr)), event.dport),\n        tcpstate[event.state]))",
  "def print_ipv6_event(cpu, data, size):\n    event = ct.cast(data, ct.POINTER(Data_ipv6)).contents\n    print(\"%-8s %-6d %-2d %-20s %1s> %-20s %s\" % (\n        strftime(\"%H:%M:%S\"), event.pid, event.ip,\n        \"%s:%d\" % (inet_ntop(AF_INET6, event.saddr), event.lport),\n        type[event.type],\n        \"%s:%d\" % (inet_ntop(AF_INET6, event.daddr), event.dport),\n        tcpstate[event.state]))",
  "def depict_cnt(counts_tab, l3prot='ipv4'):\n    for k, v in sorted(counts_tab.items(), key=lambda counts: counts[1].value):\n        depict_key = \"\"\n        ep_fmt = \"[%s]#%d\"\n        if l3prot == 'ipv4':\n            depict_key = \"%-20s <-> %-20s\" % (ep_fmt % (inet_ntop(AF_INET, pack('I', k.saddr)), k.lport),\n                                              ep_fmt % (inet_ntop(AF_INET, pack('I', k.daddr)), k.dport))\n        else:\n            depict_key = \"%-20s <-> %-20s\" % (ep_fmt % (inet_ntop(AF_INET6, k.saddr), k.lport),\n                                              ep_fmt % (inet_ntop(AF_INET6, k.daddr), k.dport))\n\n        print (\"%s %10d\" % (depict_key, v.value))",
  "class Data(ct.Structure):\n    _fields_ = [\n        (\"id\", ct.c_ulonglong),\n        (\"ts\", ct.c_ulonglong),\n        (\"uid\", ct.c_uint32),\n        (\"ret\", ct.c_int),\n        (\"comm\", ct.c_char * TASK_COMM_LEN),\n        (\"fname\", ct.c_char * NAME_MAX),\n        (\"flags\", ct.c_int),\n    ]",
  "def print_event(cpu, data, size):\n    event = ct.cast(data, ct.POINTER(Data)).contents\n    global initial_ts\n\n    # split return value into FD and errno columns\n    if event.ret >= 0:\n        fd_s = event.ret\n        err = 0\n    else:\n        fd_s = -1\n        err = - event.ret\n\n    if not initial_ts:\n        initial_ts = event.ts\n\n    if args.failed and (event.ret >= 0):\n        return\n\n    if args.name and bytes(args.name) not in event.comm:\n        return\n\n    if args.timestamp:\n        delta = event.ts - initial_ts\n        print(\"%-14.9f\" % (float(delta) / 1000000), end=\"\")\n\n    if args.print_uid:\n        print(\"%-6d\" % event.uid, end=\"\")\n\n    print(\"%-6d %-16s %4d %3d \" %\n          (event.id & 0xffffffff if args.tid else event.id >> 32,\n           event.comm.decode('utf-8', 'replace'), fd_s, err), end=\"\")\n\n    if args.extended_fields:\n        print(\"%08o \" % event.flags, end=\"\")\n\n    printb(b'%s' % event.fname)",
  "class Data_ipv4(ct.Structure):\n    _fields_ = [\n        (\"pid\", ct.c_uint),\n        (\"ip\", ct.c_ulonglong),\n        (\"saddr\", ct.c_uint),\n        (\"daddr\", ct.c_uint),\n        (\"sport\", ct.c_ushort),\n        (\"dport\", ct.c_ushort),\n        (\"state\", ct.c_ubyte),\n        (\"tcpflags\", ct.c_ubyte),\n        (\"stack_id\", ct.c_ulong)\n    ]",
  "class Data_ipv6(ct.Structure):\n    _fields_ = [\n        (\"pid\", ct.c_uint),\n        (\"ip\", ct.c_ulonglong),\n        (\"saddr\", (ct.c_ulonglong * 2)),\n        (\"daddr\", (ct.c_ulonglong * 2)),\n        (\"sport\", ct.c_ushort),\n        (\"dport\", ct.c_ushort),\n        (\"state\", ct.c_ubyte),\n        (\"tcpflags\", ct.c_ubyte),\n        (\"stack_id\", ct.c_ulong)\n    ]",
  "def print_ipv4_event(cpu, data, size):\n    event = ct.cast(data, ct.POINTER(Data_ipv4)).contents\n    print(\"%-8s %-6d %-2d %-20s > %-20s %s (%s)\" % (\n        strftime(\"%H:%M:%S\"), event.pid, event.ip,\n        \"%s:%d\" % (inet_ntop(AF_INET, pack('I', event.saddr)), event.sport),\n        \"%s:%s\" % (inet_ntop(AF_INET, pack('I', event.daddr)), event.dport),\n        tcp.tcpstate[event.state], tcp.flags2str(event.tcpflags)))\n    for addr in stack_traces.walk(event.stack_id):\n        sym = b.ksym(addr, show_offset=True)\n        print(\"\\t%s\" % sym)\n    print(\"\")",
  "def print_ipv6_event(cpu, data, size):\n    event = ct.cast(data, ct.POINTER(Data_ipv6)).contents\n    print(\"%-8s %-6d %-2d %-20s > %-20s %s (%s)\" % (\n        strftime(\"%H:%M:%S\"), event.pid, event.ip,\n        \"%s:%d\" % (inet_ntop(AF_INET6, event.saddr), event.sport),\n        \"%s:%d\" % (inet_ntop(AF_INET6, event.daddr), event.dport),\n        tcp.tcpstate[event.state], tcp.flags2str(event.tcpflags)))\n    for addr in stack_traces.walk(event.stack_id):\n        sym = b.ksym(addr, show_offset=True)\n        print(\"\\t%s\" % sym)\n    print(\"\")",
  "class Data(ct.Structure):\n    _fields_ = [\n        (\"pid\", ct.c_ulonglong),\n        (\"delta\", ct.c_ulonglong),\n        (\"comm\", ct.c_char * TASK_COMM_LEN),\n        (\"host\", ct.c_char * 80)\n    ]",
  "def print_event(cpu, data, size):\n    event = ct.cast(data, ct.POINTER(Data)).contents\n    print(\"%-9s %-6d %-16s %10.2f %s\" % (strftime(\"%H:%M:%S\"), event.pid,\n        event.comm.decode('utf-8', 'replace'), (float(event.delta) / 1000000),\n        event.host.decode('utf-8', 'replace')))",
  "def usage():\n    print(\"USAGE: %s [interval [count]]\" % argv[0])\n    exit()",
  "class Data(ct.Structure):\n    _fields_ = [\n        (\"pid\", ct.c_ulonglong),\n        (\"timestamp\", ct.c_ulonglong),\n        (\"delta\", ct.c_ulonglong),\n        (\"query\", ct.c_char * 256)\n    ]",
  "def print_event(cpu, data, size):\n    event = ct.cast(data, ct.POINTER(Data)).contents\n    print(\"%-14.6f %-6d %8.3f %s\" % (\n        float(event.timestamp - start) / 1000000000,\n        event.pid, float(event.delta) / 1000000, event.query))",
  "class Data(ct.Structure):\n    _fields_ = [\n        (\"ts_us\", ct.c_ulonglong),\n        (\"type\", ct.c_ulonglong),\n        (\"size\", ct.c_ulonglong),\n        (\"offset\", ct.c_ulonglong),\n        (\"delta_us\", ct.c_ulonglong),\n        (\"pid\", ct.c_ulonglong),\n        (\"task\", ct.c_char * TASK_COMM_LEN),\n        (\"file\", ct.c_char * DNAME_INLINE_LEN)\n    ]",
  "def print_event(cpu, data, size):\n    event = ct.cast(data, ct.POINTER(Data)).contents\n\n    type = 'R'\n    if event.type == 1:\n        type = 'W'\n    elif event.type == 2:\n        type = 'O'\n    elif event.type == 3:\n        type = 'S'\n\n    if (csv):\n        print(\"%d,%s,%d,%s,%d,%d,%d,%s\" % (\n            event.ts_us, event.task.decode('utf-8', 'replace'), event.pid,\n            type, event.size, event.offset, event.delta_us,\n            event.file.decode('utf-8', 'replace')))\n        return\n    print(\"%-8s %-14.14s %-6s %1s %-7s %-8d %7.2f %s\" % (strftime(\"%H:%M:%S\"),\n        event.task.decode('utf-8', 'replace'), event.pid, type, event.size,\n        event.offset / 1024, float(event.delta_us) / 1000,\n        event.file.decode('utf-8', 'replace')))",
  "class Data(ct.Structure):\n    _fields_ = [\n        (\"fpid\", ct.c_ulonglong),\n        (\"tpid\", ct.c_ulonglong),\n        (\"pages\", ct.c_ulonglong),\n        (\"fcomm\", ct.c_char * TASK_COMM_LEN),\n        (\"tcomm\", ct.c_char * TASK_COMM_LEN)\n    ]",
  "def print_event(cpu, data, size):\n    event = ct.cast(data, ct.POINTER(Data)).contents\n    with open(loadavg) as stats:\n        avgline = stats.read().rstrip()\n    print((\"%s Triggered by PID %d (\\\"%s\\\"), OOM kill of PID %d (\\\"%s\\\")\"\n        \", %d pages, loadavg: %s\") % (strftime(\"%H:%M:%S\"), event.fpid,\n        event.fcomm.decode('utf-8', 'replace'), event.tpid,\n        event.tcomm.decode('utf-8', 'replace'), event.pages, avgline))",
  "class TCPIPV4Evt(ctypes.Structure):\n    _fields_ = [\n            (\"ts_ns\", ctypes.c_ulonglong),\n            (\"type\", ctypes.c_uint),\n            (\"pid\", ctypes.c_uint),\n            (\"comm\", ctypes.c_char * TASK_COMM_LEN),\n            (\"ip\", ctypes.c_ubyte),\n            (\"saddr\", ctypes.c_uint),\n            (\"daddr\", ctypes.c_uint),\n            (\"sport\", ctypes.c_ushort),\n            (\"dport\", ctypes.c_ushort),\n            (\"netns\", ctypes.c_uint)\n    ]",
  "class TCPIPV6Evt(ctypes.Structure):\n    _fields_ = [\n            (\"ts_ns\", ctypes.c_ulonglong),\n            (\"type\", ctypes.c_uint),\n            (\"pid\", ctypes.c_uint),\n            (\"comm\", ctypes.c_char * TASK_COMM_LEN),\n            (\"ip\", ctypes.c_ubyte),\n            (\"saddr\", (ctypes.c_ulong * 2)),\n            (\"daddr\", (ctypes.c_ulong * 2)),\n            (\"sport\", ctypes.c_ushort),\n            (\"dport\", ctypes.c_ushort),\n            (\"netns\", ctypes.c_uint)\n    ]",
  "def print_ipv4_event(cpu, data, size):\n    event = ctypes.cast(data, ctypes.POINTER(TCPIPV4Evt)).contents\n    global start_ts\n\n    if args.timestamp:\n        if start_ts == 0:\n            start_ts = event.ts_ns\n        if args.verbose:\n            print(\"%-14d\" % (event.ts_ns - start_ts), end=\"\")\n        else:\n            print(\"%-9.3f\" % ((event.ts_ns - start_ts) / 1000000000.0), end=\"\")\n    if event.type == 1:\n        type_str = \"C\"\n    elif event.type == 2:\n        type_str = \"A\"\n    elif event.type == 3:\n        type_str = \"X\"\n    else:\n        type_str = \"U\"\n\n    if args.verbose:\n        print(\"%-12s \" % (verbose_types[type_str]), end=\"\")\n    else:\n        print(\"%-2s \" % (type_str), end=\"\")\n\n    print(\"%-6d %-16s %-2d %-16s %-16s %-6d %-6d\" %\n          (event.pid, event.comm.decode('utf-8', 'replace'),\n           event.ip,\n           inet_ntop(AF_INET, pack(\"I\", event.saddr)),\n           inet_ntop(AF_INET, pack(\"I\", event.daddr)),\n           event.sport,\n           event.dport), end=\"\")\n    if args.verbose and not args.netns:\n        print(\" %-8d\" % event.netns)\n    else:\n        print()",
  "def print_ipv6_event(cpu, data, size):\n    event = ctypes.cast(data, ctypes.POINTER(TCPIPV6Evt)).contents\n    global start_ts\n    if args.timestamp:\n        if start_ts == 0:\n            start_ts = event.ts_ns\n        if args.verbose:\n            print(\"%-14d\" % (event.ts_ns - start_ts), end=\"\")\n        else:\n            print(\"%-9.3f\" % ((event.ts_ns - start_ts) / 1000000000.0), end=\"\")\n    if event.type == 1:\n        type_str = \"C\"\n    elif event.type == 2:\n        type_str = \"A\"\n    elif event.type == 3:\n        type_str = \"X\"\n    else:\n        type_str = \"U\"\n\n    if args.verbose:\n        print(\"%-12s \" % (verbose_types[type_str]), end=\"\")\n    else:\n        print(\"%-2s \" % (type_str), end=\"\")\n\n    print(\"%-6d %-16s %-2d %-16s %-16s %-6d %-6d\" %\n          (event.pid, event.comm.decode('utf-8', 'replace'),\n           event.ip,\n           \"[\" + inet_ntop(AF_INET6, event.saddr) + \"]\",\n           \"[\" + inet_ntop(AF_INET6, event.daddr) + \"]\",\n           event.sport,\n           event.dport), end=\"\")\n    if args.verbose and not args.netns:\n        print(\" %-8d\" % event.netns)\n    else:\n        print()",
  "def inet_ntoa(addr):\n    dq = ''\n    for i in range(0, 4):\n        dq = dq + str(addr & 0xff)\n        if (i != 3):\n            dq = dq + '.'\n        addr = addr >> 8\n    return dq",
  "def check_runnable_weight_field():\n    # Define the bpf program for checking purpose\n    bpf_check_text = \"\"\"\n#include <linux/sched.h>\nunsigned long dummy(struct sched_entity *entity)\n{\n    return entity->runnable_weight;\n}\n\"\"\"\n\n    # Get a temporary file name\n    tmp_file = NamedTemporaryFile(delete=False)\n    tmp_file.close();\n\n    # Duplicate and close stderr (fd = 2)\n    old_stderr = dup(2)\n    close(2)\n\n    # Open a new file, should get fd number 2\n    # This will avoid printing llvm errors on the screen\n    fd = open(tmp_file.name, O_WRONLY)\n    try:\n        t = BPF(text=bpf_check_text)\n        success_compile = True\n    except:\n        success_compile = False\n\n    # Release the fd 2, and next dup should restore old stderr\n    close(fd)\n    dup(old_stderr)\n    close(old_stderr)\n\n    # remove the temporary file and return\n    unlink(tmp_file.name)\n    return success_compile",
  "class Data_ipv4(ct.Structure):\n    _fields_ = [\n        (\"ts_us\", ct.c_ulonglong),\n        (\"pid\", ct.c_uint),\n        (\"saddr\", ct.c_uint),\n        (\"daddr\", ct.c_uint),\n        (\"ports\", ct.c_ulonglong),\n        (\"rx_b\", ct.c_ulonglong),\n        (\"tx_b\", ct.c_ulonglong),\n        (\"span_us\", ct.c_ulonglong),\n        (\"task\", ct.c_char * TASK_COMM_LEN)\n    ]",
  "class Data_ipv6(ct.Structure):\n    _fields_ = [\n        (\"ts_us\", ct.c_ulonglong),\n        (\"pid\", ct.c_uint),\n        (\"saddr\", (ct.c_ulonglong * 2)),\n        (\"daddr\", (ct.c_ulonglong * 2)),\n        (\"ports\", ct.c_ulonglong),\n        (\"rx_b\", ct.c_ulonglong),\n        (\"tx_b\", ct.c_ulonglong),\n        (\"span_us\", ct.c_ulonglong),\n        (\"task\", ct.c_char * TASK_COMM_LEN)\n    ]",
  "def print_ipv4_event(cpu, data, size):\n    event = ct.cast(data, ct.POINTER(Data_ipv4)).contents\n    global start_ts\n    if args.time:\n        if args.csv:\n            print(\"%s,\" % strftime(\"%H:%M:%S\"), end=\"\")\n        else:\n            print(\"%-8s \" % strftime(\"%H:%M:%S\"), end=\"\")\n    if args.timestamp:\n        if start_ts == 0:\n            start_ts = event.ts_us\n        delta_s = (float(event.ts_us) - start_ts) / 1000000\n        if args.csv:\n            print(\"%.6f,\" % delta_s, end=\"\")\n        else:\n            print(\"%-9.6f \" % delta_s, end=\"\")\n    print(format_string % (event.pid, event.task.decode('utf-8', 'replace'),\n        \"4\" if args.wide or args.csv else \"\",\n        inet_ntop(AF_INET, pack(\"I\", event.saddr)), event.ports >> 32,\n        inet_ntop(AF_INET, pack(\"I\", event.daddr)), event.ports & 0xffffffff,\n        event.tx_b / 1024, event.rx_b / 1024, float(event.span_us) / 1000))",
  "def print_ipv6_event(cpu, data, size):\n    event = ct.cast(data, ct.POINTER(Data_ipv6)).contents\n    global start_ts\n    if args.time:\n        if args.csv:\n            print(\"%s,\" % strftime(\"%H:%M:%S\"), end=\"\")\n        else:\n            print(\"%-8s \" % strftime(\"%H:%M:%S\"), end=\"\")\n    if args.timestamp:\n        if start_ts == 0:\n            start_ts = event.ts_us\n        delta_s = (float(event.ts_us) - start_ts) / 1000000\n        if args.csv:\n            print(\"%.6f,\" % delta_s, end=\"\")\n        else:\n            print(\"%-9.6f \" % delta_s, end=\"\")\n    print(format_string % (event.pid, event.task.decode('utf-8', 'replace'),\n        \"6\" if args.wide or args.csv else \"\",\n        inet_ntop(AF_INET6, event.saddr), event.ports >> 32,\n        inet_ntop(AF_INET6, event.daddr), event.ports & 0xffffffff,\n        event.tx_b / 1024, event.rx_b / 1024, float(event.span_us) / 1000))",
  "def signal_ignore(signal, frame):\n    print()",
  "def handle_errno(errstr):\n    try:\n        return abs(int(errstr))\n    except ValueError:\n        pass\n\n    try:\n        return getattr(errno, errstr)\n    except AttributeError:\n        raise argparse.ArgumentTypeError(\"couldn't map %s to an errno\" % errstr)",
  "def print_stats():\n    if args.latency:\n        print_latency_stats()\n    else:\n        print_count_stats()",
  "def comm_for_pid(pid):\n    try:\n        return open(\"/proc/%d/comm\" % pid, \"rb\").read().strip()\n    except Exception:\n        return b\"[unknown]\"",
  "def agg_colval(key):\n    if args.process:\n        return b\"%-6d %-15s\" % (key.value, comm_for_pid(key.value))\n    else:\n        return syscall_name(key.value)",
  "def print_count_stats():\n    data = bpf[\"data\"]\n    print(\"[%s]\" % strftime(\"%H:%M:%S\"))\n    print(\"%-22s %8s\" % (agg_colname, \"COUNT\"))\n    for k, v in sorted(data.items(), key=lambda kv: -kv[1].value)[:args.top]:\n        if k.value == 0xFFFFFFFF:\n            continue    # happens occasionally, we don't need it\n        printb(b\"%-22s %8d\" % (agg_colval(k), v.value))\n    print(\"\")\n    data.clear()",
  "def print_latency_stats():\n    data = bpf[\"data\"]\n    print(\"[%s]\" % strftime(\"%H:%M:%S\"))\n    print(\"%-22s %8s %16s\" % (agg_colname, \"COUNT\", time_colname))\n    for k, v in sorted(data.items(),\n                       key=lambda kv: -kv[1].total_ns)[:args.top]:\n        if k.value == 0xFFFFFFFF:\n            continue    # happens occasionally, we don't need it\n        printb((b\"%-22s %8d \" + (b\"%16.6f\" if args.milliseconds else b\"%16.3f\")) %\n               (agg_colval(k), v.count,\n                v.total_ns / (1e6 if args.milliseconds else 1e3)))\n    print(\"\")\n    data.clear()",
  "class Data(ct.Structure):\n    _fields_ = [\n        (\"mode\", ct.c_int),\n        (\"pid\", ct.c_uint),\n        (\"sz\", ct.c_uint),\n        (\"delta_us\", ct.c_ulonglong),\n        (\"name_len\", ct.c_uint),\n        (\"name\", ct.c_char * DNAME_INLINE_LEN),\n        (\"comm\", ct.c_char * TASK_COMM_LEN),\n    ]",
  "def print_event(cpu, data, size):\n    event = ct.cast(data, ct.POINTER(Data)).contents\n\n    ms = float(event.delta_us) / 1000\n    name = event.name.decode('utf-8', 'replace')\n    if event.name_len > DNAME_INLINE_LEN:\n        name = name[:-3] + \"...\"\n\n    print(\"%-8.3f %-14.14s %-6s %1s %-7s %7.2f %s\" % (\n        time.time() - start_ts, event.comm.decode('utf-8', 'replace'),\n        event.pid, mode_s[event.mode], event.sz, ms, name))",
  "class Data(ct.Structure):\n    _fields_ = [\n        (\"ts_us\", ct.c_ulonglong),\n        (\"type\", ct.c_ulonglong),\n        (\"size\", ct.c_ulonglong),\n        (\"offset\", ct.c_ulonglong),\n        (\"delta_us\", ct.c_ulonglong),\n        (\"pid\", ct.c_ulonglong),\n        (\"task\", ct.c_char * TASK_COMM_LEN),\n        (\"file\", ct.c_char * DNAME_INLINE_LEN)\n    ]",
  "def print_event(cpu, data, size):\n    event = ct.cast(data, ct.POINTER(Data)).contents\n\n    type = 'R'\n    if event.type == 1:\n        type = 'W'\n    elif event.type == 2:\n        type = 'O'\n    elif event.type == 3:\n        type = 'G'\n\n    if(csv):\n        print(\"%d,%s,%d,%s,%d,%d,%d,%s\" % (\n            event.ts_us, event.task, event.pid, type, event.size,\n            event.offset, event.delta_us, event.file))\n        return\n    print(\"%-8s %-14.14s %-6s %1s %-7s %-8d %7.2f %s\" %\n          (strftime(\"%H:%M:%S\"),\n           event.task.decode('utf-8', 'replace'),\n           event.pid,\n           type,\n           event.size,\n           event.offset / 1024,\n           float(event.delta_us) / 1000,\n           event.file.decode('utf-8', 'replace')))",
  "class Data(ct.Structure):\n    _fields_ = [\n        (\"pid\", ct.c_uint),\n        (\"delta\", ct.c_ulonglong),\n        (\"comm\", ct.c_char * TASK_COMM_LEN),\n        (\"fname\", ct.c_char * DNAME_INLINE_LEN)\n    ]",
  "def print_event(cpu, data, size):\n    event = ct.cast(data, ct.POINTER(Data)).contents\n    print(\"%-8s %-6d %-16s %-7.2f %s\" % (strftime(\"%H:%M:%S\"), event.pid,\n        event.comm.decode('utf-8', 'replace'), float(event.delta) / 1000,\n        event.fname.decode('utf-8', 'replace')))",
  "def print_tpoint_format(category, event):\n        fmt = open(os.path.join(event_root, category, event, \"format\")) \\\n              .readlines()\n        for line in fmt:\n                match = re.search(r'field:([^;]*);', line)\n                if match is None:\n                        continue\n                parts = match.group(1).split()\n                field_name = parts[-1:][0]\n                field_type = \" \".join(parts[:-1])\n                if field_name.startswith(\"common_\"):\n                        continue\n                print(\"    %s %s;\" % (field_type, field_name))",
  "def print_tpoint(category, event):\n        tpoint = \"%s:%s\" % (category, event)\n        if not args.filter or fnmatch.fnmatch(tpoint, args.filter):\n                print(tpoint)\n                if args.verbosity > 0:\n                        print_tpoint_format(category, event)",
  "def print_tracepoints():\n        for category in os.listdir(event_root):\n                cat_dir = os.path.join(event_root, category)\n                if not os.path.isdir(cat_dir):\n                        continue\n                for event in os.listdir(cat_dir):\n                        evt_dir = os.path.join(cat_dir, event)\n                        if os.path.isdir(evt_dir):\n                                print_tpoint(category, event)",
  "def print_usdt_argument_details(location):\n        for idx in range(0, location.num_arguments):\n                arg = location.get_argument(idx)\n                print(\"    argument #%d %s\" % (idx + 1, arg))",
  "def print_usdt_details(probe):\n        if args.verbosity > 0:\n                print(probe)\n                if args.verbosity > 1:\n                        for idx in range(0, probe.num_locations):\n                                loc = probe.get_location(idx)\n                                print(\"  location #%d %s\" % (idx + 1, loc))\n                                print_usdt_argument_details(loc)\n                else:\n                        print(\"  %d location(s)\" % probe.num_locations)\n                        print(\"  %d argument(s)\" % probe.num_arguments)\n        else:\n                print(\"%s %s:%s\" %\n                      (probe.bin_path, probe.provider, probe.name))",
  "def print_usdt(pid, lib):\n        reader = USDT(path=lib, pid=pid)\n        probes_seen = []\n        for probe in reader.enumerate_probes():\n                probe_name = probe.short_name()\n                if not args.filter or fnmatch.fnmatch(probe_name, args.filter):\n                        if probe_name in probes_seen:\n                                continue\n                        probes_seen.append(probe_name)\n                        print_usdt_details(probe)",
  "def pid_to_comm(pid):\n        try:\n            comm = open(\"/proc/%d/comm\" % pid, \"r\").read()\n            return \"%d %s\" % (pid, comm)\n        except IOError:\n            return str(pid)",
  "class Data(ct.Structure):\n    _fields_ = [\n        (\"ts_us\", ct.c_ulonglong),\n        (\"type\", ct.c_ulonglong),\n        (\"size\", ct.c_ulonglong),\n        (\"offset\", ct.c_ulonglong),\n        (\"delta_us\", ct.c_ulonglong),\n        (\"pid\", ct.c_ulonglong),\n        (\"task\", ct.c_char * TASK_COMM_LEN),\n        (\"file\", ct.c_char * DNAME_INLINE_LEN)\n    ]",
  "def print_event(cpu, data, size):\n    event = ct.cast(data, ct.POINTER(Data)).contents\n\n    type = 'R'\n    if event.type == 1:\n        type = 'W'\n    elif event.type == 2:\n        type = 'O'\n    elif event.type == 3:\n        type = 'S'\n\n    if (csv):\n        print(\"%d,%s,%d,%s,%d,%d,%d,%s\" % (\n            event.ts_us, event.task.decode('utf-8', 'replace'), event.pid,\n            type, event.size, event.offset, event.delta_us,\n            event.file.decode('utf-8', 'replace')))\n        return\n    print(\"%-8s %-14.14s %-6s %1s %-7s %-8d %7.2f %s\" % (strftime(\"%H:%M:%S\"),\n        event.task.decode('utf-8', 'replace'), event.pid, type, event.size,\n        event.offset / 1024, float(event.delta_us) / 1000,\n        event.file.decode('utf-8', 'replace')))",
  "def positive_int(val):\n    try:\n        ival = int(val)\n    except ValueError:\n        raise argparse.ArgumentTypeError(\"must be an integer\")\n\n    if ival < 0:\n        raise argparse.ArgumentTypeError(\"must be positive\")\n    return ival",
  "def positive_nonzero_int(val):\n    ival = positive_int(val)\n    if ival == 0:\n        raise argparse.ArgumentTypeError(\"must be nonzero\")\n    return ival",
  "def stack_id_err(stack_id):\n    # -EFAULT in get_stackid normally means the stack-trace is not availible,\n    # Such as getting kernel stack trace in userspace code\n    return (stack_id < 0) and (stack_id != -errno.EFAULT)",
  "def signal_ignore(signal, frame):\n    print()",
  "def bail(error):\n    print(\"Error: \" + error)\n    exit(1)",
  "def signal_ignore(signal, frame):\n    print()",
  "def print_section(key):\n    if not library:\n        return BPF.sym(key[0], -1)\n    else:\n        return \"%s [%d]\" % (BPF.sym(key[0], key[1]), key[1])",
  "class Data(ct.Structure):\n    _fields_ = [\n        (\"id\",      ct.c_ulonglong),\n        (\"ts\",      ct.c_ulonglong),\n        (\"action\",  ct.c_int),\n        (\"sock_fd\", ct.c_int),\n        (\"fd_cnt\",  ct.c_int),\n        (\"fd\",      ct.c_int  * MAX_FD),\n        (\"comm\",    ct.c_char * TASK_COMM_LEN),\n    ]",
  "def get_file(pid, fd):\n    proc = \"/proc/%d/fd/%d\" % (pid, fd)\n    try:\n        return os.readlink(proc)\n    except OSError as err:\n        return \"N/A\"",
  "def print_event(cpu, data, size):\n    event = ct.cast(data, ct.POINTER(Data)).contents\n    tid = event.id & 0xffffffff;\n\n    cnt = min(MAX_FD, event.fd_cnt);\n\n    if args.name and bytes(args.name) not in event.comm:\n        return\n\n    for i in range(0, cnt):\n        global initial_ts\n\n        if not initial_ts:\n            initial_ts = event.ts\n\n        if args.timestamp:\n            delta = event.ts - initial_ts\n            print(\"%-14.9f\" % (float(delta) / 1000000), end=\"\")\n\n        print(\"%-6s %-6d %-16s \" %\n              (\"SEND\" if event.action == ACTION_SEND else \"RECV\",\n               tid, event.comm.decode()), end = '')\n\n        sock = \"%d:%s\" % (event.sock_fd, get_file(tid, event.sock_fd))\n        print(\"%-25s \" % sock, end = '')\n\n        fd = event.fd[i]\n        fd_file = get_file(tid, fd) if event.action == ACTION_SEND else \"\"\n        print(\"%-5d %s\" % (fd, fd_file))",
  "class DiGraph(object):\n    '''\n    Adapted from networkx: http://networkx.github.io/\n    Represents a directed graph. Edges can store (key, value) attributes.\n    '''\n\n    def __init__(self):\n        # Map of node -> set of nodes\n        self.adjacency_map = {}\n        # Map of (node1, node2) -> map string -> arbitrary attribute\n        # This will not be copied in subgraph()\n        self.attributes_map = {}\n\n    def neighbors(self, node):\n        return self.adjacency_map.get(node, set())\n\n    def edges(self):\n        edges = []\n        for node, neighbors in self.adjacency_map.items():\n            for neighbor in neighbors:\n                edges.append((node, neighbor))\n        return edges\n\n    def nodes(self):\n        return self.adjacency_map.keys()\n\n    def attributes(self, node1, node2):\n        return self.attributes_map[(node1, node2)]\n\n    def add_edge(self, node1, node2, **kwargs):\n        if node1 not in self.adjacency_map:\n            self.adjacency_map[node1] = set()\n        if node2 not in self.adjacency_map:\n            self.adjacency_map[node2] = set()\n        self.adjacency_map[node1].add(node2)\n        self.attributes_map[(node1, node2)] = kwargs\n\n    def remove_node(self, node):\n        self.adjacency_map.pop(node, None)\n        for _, neighbors in self.adjacency_map.items():\n            neighbors.discard(node)\n\n    def subgraph(self, nodes):\n        graph = DiGraph()\n        for node in nodes:\n            for neighbor in self.neighbors(node):\n                if neighbor in nodes:\n                    graph.add_edge(node, neighbor)\n        return graph\n\n    def node_link_data(self):\n        '''\n        Returns the graph as a dictionary in a format that can be\n        serialized.\n        '''\n        data = {\n            'directed': True,\n            'multigraph': False,\n            'graph': {},\n            'links': [],\n            'nodes': [],\n        }\n\n        # Do one pass to build a map of node -> position in nodes\n        node_to_number = {}\n        for node in self.adjacency_map.keys():\n            node_to_number[node] = len(data['nodes'])\n            data['nodes'].append({'id': node})\n\n        # Do another pass to build the link information\n        for node, neighbors in self.adjacency_map.items():\n            for neighbor in neighbors:\n                link = self.attributes_map[(node, neighbor)].copy()\n                link['source'] = node_to_number[node]\n                link['target'] = node_to_number[neighbor]\n                data['links'].append(link)\n        return data",
  "def strongly_connected_components(G):\n    '''\n    Adapted from networkx: http://networkx.github.io/\n    Parameters\n    ----------\n    G : DiGraph\n    Returns\n    -------\n    comp : generator of sets\n        A generator of sets of nodes, one for each strongly connected\n        component of G.\n    '''\n    preorder = {}\n    lowlink = {}\n    scc_found = {}\n    scc_queue = []\n    i = 0  # Preorder counter\n    for source in G.nodes():\n        if source not in scc_found:\n            queue = [source]\n            while queue:\n                v = queue[-1]\n                if v not in preorder:\n                    i = i + 1\n                    preorder[v] = i\n                done = 1\n                v_nbrs = G.neighbors(v)\n                for w in v_nbrs:\n                    if w not in preorder:\n                        queue.append(w)\n                        done = 0\n                        break\n                if done == 1:\n                    lowlink[v] = preorder[v]\n                    for w in v_nbrs:\n                        if w not in scc_found:\n                            if preorder[w] > preorder[v]:\n                                lowlink[v] = min([lowlink[v], lowlink[w]])\n                            else:\n                                lowlink[v] = min([lowlink[v], preorder[w]])\n                    queue.pop()\n                    if lowlink[v] == preorder[v]:\n                        scc_found[v] = True\n                        scc = {v}\n                        while (\n                            scc_queue and preorder[scc_queue[-1]] > preorder[v]\n                        ):\n                            k = scc_queue.pop()\n                            scc_found[k] = True\n                            scc.add(k)\n                        yield scc\n                    else:\n                        scc_queue.append(v)",
  "def simple_cycles(G):\n    '''\n    Adapted from networkx: http://networkx.github.io/\n    Parameters\n    ----------\n    G : DiGraph\n    Returns\n    -------\n    cycle_generator: generator\n       A generator that produces elementary cycles of the graph.\n       Each cycle is represented by a list of nodes along the cycle.\n    '''\n\n    def _unblock(thisnode, blocked, B):\n        stack = set([thisnode])\n        while stack:\n            node = stack.pop()\n            if node in blocked:\n                blocked.remove(node)\n                stack.update(B[node])\n                B[node].clear()\n\n    # Johnson's algorithm requires some ordering of the nodes.\n    # We assign the arbitrary ordering given by the strongly connected comps\n    # There is no need to track the ordering as each node removed as processed.\n    # save the actual graph so we can mutate it here\n    # We only take the edges because we do not want to\n    # copy edge and node attributes here.\n    subG = G.subgraph(G.nodes())\n    sccs = list(strongly_connected_components(subG))\n    while sccs:\n        scc = sccs.pop()\n        # order of scc determines ordering of nodes\n        startnode = scc.pop()\n        # Processing node runs 'circuit' routine from recursive version\n        path = [startnode]\n        blocked = set()  # vertex: blocked from search?\n        closed = set()  # nodes involved in a cycle\n        blocked.add(startnode)\n        B = defaultdict(set)  # graph portions that yield no elementary circuit\n        stack = [(startnode, list(subG.neighbors(startnode)))]\n        while stack:\n            thisnode, nbrs = stack[-1]\n            if nbrs:\n                nextnode = nbrs.pop()\n                if nextnode == startnode:\n                    yield path[:]\n                    closed.update(path)\n                elif nextnode not in blocked:\n                    path.append(nextnode)\n                    stack.append((nextnode, list(subG.neighbors(nextnode))))\n                    closed.discard(nextnode)\n                    blocked.add(nextnode)\n                    continue\n            # done with nextnode... look for more neighbors\n            if not nbrs:  # no more nbrs\n                if thisnode in closed:\n                    _unblock(thisnode, blocked, B)\n                else:\n                    for nbr in subG.neighbors(thisnode):\n                        if thisnode not in B[nbr]:\n                            B[nbr].add(thisnode)\n                stack.pop()\n                path.pop()\n        # done processing this node\n        subG.remove_node(startnode)\n        H = subG.subgraph(scc)  # make smaller to avoid work in SCC routine\n        sccs.extend(list(strongly_connected_components(H)))",
  "def find_cycle(graph):\n    '''\n    Looks for a cycle in the graph. If found, returns the first cycle.\n    If nodes a1, a2, ..., an are in a cycle, then this returns:\n        [(a1,a2), (a2,a3), ... (an-1,an), (an, a1)]\n    Otherwise returns an empty list.\n    '''\n    cycles = list(simple_cycles(graph))\n    if cycles:\n        nodes = cycles[0]\n        nodes.append(nodes[0])\n        edges = []\n        prev = nodes[0]\n        for node in nodes[1:]:\n            edges.append((prev, node))\n            prev = node\n        return edges\n    else:\n        return []",
  "def print_cycle(binary, graph, edges, thread_info, print_stack_trace_fn):\n    '''\n    Prints the cycle in the mutex graph in the following format:\n\n    Potential Deadlock Detected!\n\n    Cycle in lock order graph: M0 => M1 => M2 => M0\n\n    for (m, n) in cycle:\n        Mutex n acquired here while holding Mutex m in thread T:\n            [ stack trace ]\n\n        Mutex m previously acquired by thread T here:\n            [ stack trace ]\n\n    for T in all threads:\n        Thread T was created here:\n            [ stack trace ]\n    '''\n\n    # List of mutexes in the cycle, first and last repeated\n    nodes_in_order = []\n    # Map mutex address -> readable alias\n    node_addr_to_name = {}\n    for counter, (m, n) in enumerate(edges):\n        nodes_in_order.append(m)\n        # For global or static variables, try to symbolize the mutex address.\n        symbol = symbolize_with_objdump(binary, m)\n        if symbol:\n            symbol += ' '\n        node_addr_to_name[m] = 'Mutex M%d (%s0x%016x)' % (counter, symbol, m)\n    nodes_in_order.append(nodes_in_order[0])\n\n    print('----------------\\nPotential Deadlock Detected!\\n')\n    print(\n        'Cycle in lock order graph: %s\\n' %\n        (' => '.join([node_addr_to_name[n] for n in nodes_in_order]))\n    )\n\n    # Set of threads involved in the lock inversion\n    thread_pids = set()\n\n    # For each edge in the cycle, print where the two mutexes were held\n    for (m, n) in edges:\n        thread_pid = graph.attributes(m, n)['thread_pid']\n        thread_comm = graph.attributes(m, n)['thread_comm']\n        first_mutex_stack_id = graph.attributes(m, n)['first_mutex_stack_id']\n        second_mutex_stack_id = graph.attributes(m, n)['second_mutex_stack_id']\n        thread_pids.add(thread_pid)\n        print(\n            '%s acquired here while holding %s in Thread %d (%s):' % (\n                node_addr_to_name[n], node_addr_to_name[m], thread_pid,\n                thread_comm\n            )\n        )\n        print_stack_trace_fn(second_mutex_stack_id)\n        print('')\n        print(\n            '%s previously acquired by the same Thread %d (%s) here:' %\n            (node_addr_to_name[m], thread_pid, thread_comm)\n        )\n        print_stack_trace_fn(first_mutex_stack_id)\n        print('')\n\n    # Print where the threads were created, if available\n    for thread_pid in thread_pids:\n        parent_pid, stack_id, parent_comm = thread_info.get(\n            thread_pid, (None, None, None)\n        )\n        if parent_pid:\n            print(\n                'Thread %d created by Thread %d (%s) here: ' %\n                (thread_pid, parent_pid, parent_comm)\n            )\n            print_stack_trace_fn(stack_id)\n        else:\n            print(\n                'Could not find stack trace where Thread %d was created' %\n                thread_pid\n            )\n        print('')",
  "def symbolize_with_objdump(binary, addr):\n    '''\n    Searches the binary for the address using objdump. Returns the symbol if\n    it is found, otherwise returns empty string.\n    '''\n    try:\n        command = (\n            'objdump -tT %s | grep %x | awk {\\'print $NF\\'} | c++filt' %\n            (binary, addr)\n        )\n        output = subprocess.check_output(command, shell=True)\n        return output.decode('utf-8').strip()\n    except subprocess.CalledProcessError:\n        return ''",
  "def strlist(s):\n    '''Given a comma-separated string, returns a list of substrings'''\n    return s.strip().split(',')",
  "def main():\n    examples = '''Examples:\n    deadlock_detector 181        # Analyze PID 181\n\n    deadlock_detector 181 --binary /lib/x86_64-linux-gnu/libpthread.so.0\n                                 # Analyze PID 181 and locks from this binary.\n                                 # If tracing a process that is running from\n                                 # a dynamically-linked binary, this argument\n                                 # is required and should be the path to the\n                                 # pthread library.\n\n    deadlock_detector 181 --verbose\n                                 # Analyze PID 181 and print statistics about\n                                 # the mutex wait graph.\n\n    deadlock_detector 181 --lock-symbols my_mutex_lock1,my_mutex_lock2 \\\\\n        --unlock-symbols my_mutex_unlock1,my_mutex_unlock2\n                                 # Analyze PID 181 and trace custom mutex\n                                 # symbols instead of pthread mutexes.\n\n    deadlock_detector 181 --dump-graph graph.json\n                                 # Analyze PID 181 and dump the mutex wait\n                                 # graph to graph.json.\n    '''\n    parser = argparse.ArgumentParser(\n        description=(\n            'Detect potential deadlocks (lock inversions) in a running binary.'\n            '\\nMust be run as root.'\n        ),\n        formatter_class=argparse.RawDescriptionHelpFormatter,\n        epilog=examples,\n    )\n    parser.add_argument('pid', type=int, help='Pid to trace')\n    # Binaries with `:` in the path will fail to attach uprobes on kernels\n    # running without this patch: https://lkml.org/lkml/2017/1/13/585.\n    # Symlinks to the binary without `:` in the path can get around this issue.\n    parser.add_argument(\n        '--binary',\n        type=str,\n        default='',\n        help='If set, trace the mutexes from the binary at this path. '\n        'For statically-linked binaries, this argument is not required. '\n        'For dynamically-linked binaries, this argument is required and '\n        'should be the path of the pthread library the binary is using. '\n        'Example: /lib/x86_64-linux-gnu/libpthread.so.0',\n    )\n    parser.add_argument(\n        '--dump-graph',\n        type=str,\n        default='',\n        help='If set, this will dump the mutex graph to the specified file.',\n    )\n    parser.add_argument(\n        '--verbose',\n        action='store_true',\n        help='Print statistics about the mutex wait graph.',\n    )\n    parser.add_argument(\n        '--lock-symbols',\n        type=strlist,\n        default=['pthread_mutex_lock'],\n        help='Comma-separated list of lock symbols to trace. Default is '\n        'pthread_mutex_lock. These symbols cannot be inlined in the binary.',\n    )\n    parser.add_argument(\n        '--unlock-symbols',\n        type=strlist,\n        default=['pthread_mutex_unlock'],\n        help='Comma-separated list of unlock symbols to trace. Default is '\n        'pthread_mutex_unlock. These symbols cannot be inlined in the binary.',\n    )\n    args = parser.parse_args()\n    if not args.binary:\n        try:\n            args.binary = os.readlink('/proc/%d/exe' % args.pid)\n        except OSError as e:\n            print('%s. Is the process (pid=%d) running?' % (str(e), args.pid))\n            sys.exit(1)\n\n    bpf = BPF(src_file=b'deadlock_detector.c')\n\n    # Trace where threads are created\n    bpf.attach_kretprobe(event=bpf.get_syscall_fnname('clone'), fn_name='trace_clone')\n\n    # We must trace unlock first, otherwise in the time we attached the probe\n    # on lock() and have not yet attached the probe on unlock(), a thread can\n    # acquire mutexes and release them, but the release events will not be\n    # traced, resulting in noisy reports.\n    for symbol in args.unlock_symbols:\n        try:\n            bpf.attach_uprobe(\n                name=args.binary,\n                sym=symbol,\n                fn_name='trace_mutex_release',\n                pid=args.pid,\n            )\n        except Exception as e:\n            print('%s. Failed to attach to symbol: %s' % (str(e), symbol))\n            sys.exit(1)\n    for symbol in args.lock_symbols:\n        try:\n            bpf.attach_uprobe(\n                name=args.binary,\n                sym=symbol,\n                fn_name='trace_mutex_acquire',\n                pid=args.pid,\n            )\n        except Exception as e:\n            print('%s. Failed to attach to symbol: %s' % (str(e), symbol))\n            sys.exit(1)\n\n    def print_stack_trace(stack_id):\n        '''Closure that prints the symbolized stack trace.'''\n        for addr in bpf.get_table('stack_traces').walk(stack_id):\n            line = bpf.sym(addr, args.pid)\n            # Try to symbolize with objdump if we cannot with bpf.\n            if line == '[unknown]':\n                symbol = symbolize_with_objdump(args.binary, addr)\n                if symbol:\n                    line = symbol\n            print('@ %016x %s' % (addr, line))\n\n    print('Tracing... Hit Ctrl-C to end.')\n    while True:\n        try:\n            # Map of child thread pid -> parent info\n            thread_info = {\n                child.value: (parent.parent_pid, parent.stack_id, parent.comm)\n                for child, parent in bpf.get_table('thread_to_parent').items()\n            }\n\n            # Mutex wait directed graph. Nodes are mutexes. Edge (A,B) exists\n            # if there exists some thread T where lock(A) was called and\n            # lock(B) was called before unlock(A) was called.\n            graph = DiGraph()\n            for key, leaf in bpf.get_table('edges').items():\n                graph.add_edge(\n                    key.mutex1,\n                    key.mutex2,\n                    thread_pid=leaf.thread_pid,\n                    thread_comm=leaf.comm.decode('utf-8'),\n                    first_mutex_stack_id=leaf.mutex1_stack_id,\n                    second_mutex_stack_id=leaf.mutex2_stack_id,\n                )\n            if args.verbose:\n                print(\n                    'Mutexes: %d, Edges: %d' %\n                    (len(graph.nodes()), len(graph.edges()))\n                )\n            if args.dump_graph:\n                with open(args.dump_graph, 'w') as f:\n                    data = graph.node_link_data()\n                    f.write(json.dumps(data, indent=2))\n\n            cycle = find_cycle(graph)\n            if cycle:\n                print_cycle(\n                    args.binary, graph, cycle, thread_info, print_stack_trace\n                )\n                sys.exit(1)\n\n            time.sleep(1)\n        except KeyboardInterrupt:\n            break",
  "def __init__(self):\n        # Map of node -> set of nodes\n        self.adjacency_map = {}\n        # Map of (node1, node2) -> map string -> arbitrary attribute\n        # This will not be copied in subgraph()\n        self.attributes_map = {}",
  "def neighbors(self, node):\n        return self.adjacency_map.get(node, set())",
  "def edges(self):\n        edges = []\n        for node, neighbors in self.adjacency_map.items():\n            for neighbor in neighbors:\n                edges.append((node, neighbor))\n        return edges",
  "def nodes(self):\n        return self.adjacency_map.keys()",
  "def attributes(self, node1, node2):\n        return self.attributes_map[(node1, node2)]",
  "def add_edge(self, node1, node2, **kwargs):\n        if node1 not in self.adjacency_map:\n            self.adjacency_map[node1] = set()\n        if node2 not in self.adjacency_map:\n            self.adjacency_map[node2] = set()\n        self.adjacency_map[node1].add(node2)\n        self.attributes_map[(node1, node2)] = kwargs",
  "def remove_node(self, node):\n        self.adjacency_map.pop(node, None)\n        for _, neighbors in self.adjacency_map.items():\n            neighbors.discard(node)",
  "def subgraph(self, nodes):\n        graph = DiGraph()\n        for node in nodes:\n            for neighbor in self.neighbors(node):\n                if neighbor in nodes:\n                    graph.add_edge(node, neighbor)\n        return graph",
  "def node_link_data(self):\n        '''\n        Returns the graph as a dictionary in a format that can be\n        serialized.\n        '''\n        data = {\n            'directed': True,\n            'multigraph': False,\n            'graph': {},\n            'links': [],\n            'nodes': [],\n        }\n\n        # Do one pass to build a map of node -> position in nodes\n        node_to_number = {}\n        for node in self.adjacency_map.keys():\n            node_to_number[node] = len(data['nodes'])\n            data['nodes'].append({'id': node})\n\n        # Do another pass to build the link information\n        for node, neighbors in self.adjacency_map.items():\n            for neighbor in neighbors:\n                link = self.attributes_map[(node, neighbor)].copy()\n                link['source'] = node_to_number[node]\n                link['target'] = node_to_number[neighbor]\n                data['links'].append(link)\n        return data",
  "def _unblock(thisnode, blocked, B):\n        stack = set([thisnode])\n        while stack:\n            node = stack.pop()\n            if node in blocked:\n                blocked.remove(node)\n                stack.update(B[node])\n                B[node].clear()",
  "def print_stack_trace(stack_id):\n        '''Closure that prints the symbolized stack trace.'''\n        for addr in bpf.get_table('stack_traces').walk(stack_id):\n            line = bpf.sym(addr, args.pid)\n            # Try to symbolize with objdump if we cannot with bpf.\n            if line == '[unknown]':\n                symbol = symbolize_with_objdump(args.binary, addr)\n                if symbol:\n                    line = symbol\n            print('@ %016x %s' % (addr, line))",
  "class Data(ct.Structure):\n    _fields_ = [\n            (\"timestamp_ns\", ct.c_ulonglong),\n            (\"pid\", ct.c_uint),\n            (\"comm\", ct.c_char * TASK_COMM_LEN),\n            (\"v0\", ct.c_char * MAX_BUF_SIZE),\n            (\"len\", ct.c_uint)\n    ]",
  "def print_event_write(cpu, data, size):\n    print_event(cpu, data, size, \"WRITE/SEND\")",
  "def print_event_read(cpu, data, size):\n    print_event(cpu, data, size, \"READ/RECV\")",
  "def print_event(cpu, data, size, rw):\n    global start\n    event = ct.cast(data, ct.POINTER(Data)).contents\n\n    # Filter events by command\n    if args.comm:\n        if not args.comm == event.comm:\n            return\n\n    if start == 0:\n        start = event.timestamp_ns\n    time_s = (float(event.timestamp_ns - start)) / 1000000000\n\n    s_mark = \"-\" * 5 + \" DATA \" + \"-\" * 5\n\n    e_mark = \"-\" * 5 + \" END DATA \" + \"-\" * 5\n\n    truncated_bytes = event.len - MAX_BUF_SIZE\n    if truncated_bytes > 0:\n        e_mark = \"-\" * 5 + \" END DATA (TRUNCATED, \" + str(truncated_bytes) + \\\n                \" bytes lost) \" + \"-\" * 5\n\n    fmt = \"%-12s %-18.9f %-16s %-6d %-6d\\n%s\\n%s\\n%s\\n\\n\"\n    print(fmt % (rw, time_s, event.comm.decode('utf-8', 'replace'),\n                 event.pid, event.len, s_mark,\n                 event.v0.decode('utf-8', 'replace'), e_mark))",
  "class Data(ct.Structure):\n    _fields_ = [\n        (\"pid\", ct.c_ulonglong),\n        (\"comm\", ct.c_char * TASK_COMM_LEN),\n        (\"disk\", ct.c_char * DISK_NAME_LEN)\n    ]",
  "def print_event(cpu, data, size):\n    event = ct.cast(data, ct.POINTER(Data)).contents\n    print(\"%-8s %-6d %-16s %s\" % (strftime(\"%H:%M:%S\"), event.pid,\n        event.comm.decode('utf-8', 'replace'),\n        event.disk.decode('utf-8', 'replace')))",
  "def usage():\n    print(\"USAGE: %s [interval [count]]\" % argv[0])\n    exit()",
  "def positive_float(val):\n    try:\n        ival = float(val)\n    except ValueError:\n        raise argparse.ArgumentTypeError(\"must be a float\")\n\n    if ival < 0:\n        raise argparse.ArgumentTypeError(\"must be positive\")\n    return ival",
  "class Data_ipv4(ct.Structure):\n    _fields_ = [\n        (\"ts_us\", ct.c_ulonglong),\n        (\"pid\", ct.c_uint),\n        (\"saddr\", ct.c_uint),\n        (\"daddr\", ct.c_uint),\n        (\"ip\", ct.c_ulonglong),\n        (\"dport\", ct.c_ushort),\n        (\"delta_us\", ct.c_ulonglong),\n        (\"task\", ct.c_char * TASK_COMM_LEN)\n    ]",
  "class Data_ipv6(ct.Structure):\n    _fields_ = [\n        (\"ts_us\", ct.c_ulonglong),\n        (\"pid\", ct.c_uint),\n        (\"saddr\", (ct.c_ulonglong * 2)),\n        (\"daddr\", (ct.c_ulonglong * 2)),\n        (\"ip\", ct.c_ulonglong),\n        (\"dport\", ct.c_ushort),\n        (\"delta_us\", ct.c_ulonglong),\n        (\"task\", ct.c_char * TASK_COMM_LEN)\n    ]",
  "def print_ipv4_event(cpu, data, size):\n    event = ct.cast(data, ct.POINTER(Data_ipv4)).contents\n    global start_ts\n    if args.timestamp:\n        if start_ts == 0:\n            start_ts = event.ts_us\n        print(\"%-9.3f\" % ((float(event.ts_us) - start_ts) / 1000000), end=\"\")\n    print(\"%-6d %-12.12s %-2d %-16s %-16s %-5d %.2f\" % (event.pid,\n        event.task.decode('utf-8', 'replace'), event.ip,\n        inet_ntop(AF_INET, pack(\"I\", event.saddr)),\n        inet_ntop(AF_INET, pack(\"I\", event.daddr)), event.dport,\n        float(event.delta_us) / 1000))",
  "def print_ipv6_event(cpu, data, size):\n    event = ct.cast(data, ct.POINTER(Data_ipv6)).contents\n    global start_ts\n    if args.timestamp:\n        if start_ts == 0:\n            start_ts = event.ts_us\n        print(\"%-9.3f\" % ((float(event.ts_us) - start_ts) / 1000000), end=\"\")\n    print(\"%-6d %-12.12s %-2d %-16s %-16s %-5d %.2f\" % (event.pid,\n        event.task.decode('utf-8', 'replace'), event.ip,\n        inet_ntop(AF_INET6, event.saddr), inet_ntop(AF_INET6, event.daddr),\n        event.dport, float(event.delta_us) / 1000))",
  "class Enum(set):\n    def __getattr__(self, name):\n        if name in self:\n            return name\n        raise AttributeError",
  "class Data(ct.Structure):\n    _fields_ = [\n        (\"tgid\", ct.c_uint32),\n        (\"pid\", ct.c_uint32),\n        (\"uid\", ct.c_uint32),\n        (\"cap\", ct.c_int),\n        (\"audit\", ct.c_int),\n        (\"comm\", ct.c_char * TASK_COMM_LEN),\n    ] + ([(\"kernel_stack_id\", ct.c_int)] if args.kernel_stack else []) \\\n      + ([(\"user_stack_id\", ct.c_int)] if args.user_stack else [])",
  "def stack_id_err(stack_id):\n    # -EFAULT in get_stackid normally means the stack-trace is not availible,\n    # Such as getting kernel stack trace in userspace code\n    return (stack_id < 0) and (stack_id != -errno.EFAULT)",
  "def print_stack(bpf, stack_id, stack_type, tgid):\n    if stack_id_err(stack_id):\n        print(\"    [Missed %s Stack]\" % stack_type)\n        return\n    stack = list(bpf.get_table(\"stacks\").walk(stack_id))\n    for addr in stack:\n        print(\"        \", end=\"\")\n        print(\"%s\" % (bpf.sym(addr, tgid, show_module=True, show_offset=True)))",
  "def print_event(bpf, cpu, data, size):\n    event = ct.cast(data, ct.POINTER(Data)).contents\n\n    if event.cap in capabilities:\n        name = capabilities[event.cap]\n    else:\n        name = \"?\"\n    print(\"%-9s %-6d %-6d %-6d %-16s %-4d %-20s %d\" % (strftime(\"%H:%M:%S\"),\n        event.uid, event.pid, event.tgid, event.comm.decode('utf-8', 'replace'),\n        event.cap, name, event.audit))\n    if args.kernel_stack:\n        print_stack(bpf, event.kernel_stack_id, StackType.Kernel, -1)\n    if args.user_stack:\n        print_stack(bpf, event.user_stack_id, StackType.User, event.tgid)",
  "def __getattr__(self, name):\n        if name in self:\n            return name\n        raise AttributeError",
  "def vec_to_name(vec):\n    # copied from softirq_to_name() in kernel/softirq.c\n    # may need updates if new softirq handlers are added\n    return [\"hi\", \"timer\", \"net_tx\", \"net_rx\", \"block\", \"irq_poll\",\n            \"tasklet\", \"sched\", \"hrtimer\", \"rcu\"][vec]",
  "def print_hist():\n    print(\"[%s]\" % strftime(\"%H:%M:%S\"))\n    latencies.print_log2_hist(\"query latency (%s)\" %\n                              (\"us\" if args.microseconds else \"ms\"))\n    print(\"\")\n    latencies.clear()",
  "class Probe(object):\n    def __init__(self, pattern, kernel_stack, user_stack, use_regex=False,\n                 pid=None, per_pid=False):\n        \"\"\"Init a new probe.\n\n        Init the probe from the pattern provided by the user. The supported\n        patterns mimic the 'trace' and 'argdist' tools, but are simpler because\n        we don't have to distinguish between probes and retprobes.\n\n            func            -- probe a kernel function\n            lib:func        -- probe a user-space function in the library 'lib'\n            p::func         -- same thing as 'func'\n            p:lib:func      -- same thing as 'lib:func'\n            t:cat:event     -- probe a kernel tracepoint\n            u:lib:probe     -- probe a USDT tracepoint\n        \"\"\"\n        self.kernel_stack = kernel_stack\n        self.user_stack = user_stack\n        parts = pattern.split(':')\n        if len(parts) == 1:\n            parts = [\"p\", \"\", parts[0]]\n        elif len(parts) == 2:\n            parts = [\"p\", parts[0], parts[1]]\n        elif len(parts) == 3:\n            if parts[0] == \"t\":\n                parts = [\"t\", \"\", \"%s:%s\" % tuple(parts[1:])]\n            if parts[0] not in [\"p\", \"t\", \"u\"]:\n                raise Exception(\"Type must be 'p', 't', or 'u', but got %s\" %\n                                parts[0])\n        else:\n            raise Exception(\"Too many ':'-separated components in pattern %s\" %\n                            pattern)\n\n        (self.type, self.library, self.pattern) = parts\n        if not use_regex:\n            self.pattern = self.pattern.replace('*', '.*')\n            self.pattern = '^' + self.pattern + '$'\n\n        if (self.type == \"p\" and self.library) or self.type == \"u\":\n            libpath = BPF.find_library(self.library)\n            if libpath is None:\n                # This might be an executable (e.g. 'bash')\n                libpath = BPF.find_exe(self.library)\n            if libpath is None or len(libpath) == 0:\n                raise Exception(\"unable to find library %s\" % self.library)\n            self.library = libpath\n\n        self.pid = pid\n        self.per_pid = per_pid\n        self.matched = 0\n\n    def is_kernel_probe(self):\n        return self.type == \"t\" or (self.type == \"p\" and self.library == \"\")\n\n    def attach(self):\n        if self.type == \"p\":\n            if self.library:\n                self.bpf.attach_uprobe(name=self.library,\n                                       sym_re=self.pattern,\n                                       fn_name=\"trace_count\",\n                                       pid=self.pid or -1)\n                self.matched = self.bpf.num_open_uprobes()\n            else:\n                self.bpf.attach_kprobe(event_re=self.pattern,\n                                       fn_name=\"trace_count\")\n                self.matched = self.bpf.num_open_kprobes()\n        elif self.type == \"t\":\n            self.bpf.attach_tracepoint(tp_re=self.pattern,\n                                       fn_name=\"trace_count\")\n            self.matched = self.bpf.num_open_tracepoints()\n        elif self.type == \"u\":\n            pass    # Nothing to do -- attach already happened in `load`\n\n        if self.matched == 0:\n            raise Exception(\"No functions matched by pattern %s\" %\n                            self.pattern)\n\n    def load(self):\n        ctx_name = \"ctx\"\n        stack_trace = \"\"\n        if self.user_stack:\n                stack_trace += \"\"\"\n                    key.user_stack_id = stack_traces.get_stackid(\n                      %s, BPF_F_REUSE_STACKID | BPF_F_USER_STACK\n                    );\"\"\" % (ctx_name)\n        else:\n                stack_trace += \"key.user_stack_id = -1;\"\n        if self.kernel_stack:\n                stack_trace += \"\"\"\n                    key.kernel_stack_id = stack_traces.get_stackid(\n                      %s, BPF_F_REUSE_STACKID\n                    );\"\"\" % (ctx_name)\n        else:\n                stack_trace += \"key.kernel_stack_id = -1;\"\n\n        trace_count_text = \"\"\"\nint trace_count(void *ctx) {\n    FILTER\n    struct key_t key = {};\n    key.tgid = GET_TGID;\n    STORE_COMM\n    %s\n    counts.increment(key);\n    return 0;\n}\n        \"\"\"\n        trace_count_text = trace_count_text % (stack_trace)\n\n        bpf_text = \"\"\"#include <uapi/linux/ptrace.h>\n#include <linux/sched.h>\n\nstruct key_t {\n    // no pid (thread ID) so that we do not needlessly split this key\n    u32 tgid;\n    int kernel_stack_id;\n    int user_stack_id;\n    char name[TASK_COMM_LEN];\n};\n\nBPF_HASH(counts, struct key_t);\nBPF_STACK_TRACE(stack_traces, 1024);\n        \"\"\"\n\n        # We really mean the tgid from the kernel's perspective, which is in\n        # the top 32 bits of bpf_get_current_pid_tgid().\n        if self.is_kernel_probe() and self.pid:\n            trace_count_text = trace_count_text.replace('FILTER',\n                ('u32 pid; pid = bpf_get_current_pid_tgid() >> 32; ' +\n                'if (pid != %d) { return 0; }') % (self.pid))\n        else:\n            trace_count_text = trace_count_text.replace('FILTER', '')\n\n        # We need per-pid statistics when tracing a user-space process, because\n        # the meaning of the symbols depends on the pid. We also need them if\n        # per-pid statistics were requested with -P, or for user stacks.\n        if self.per_pid or not self.is_kernel_probe() or self.user_stack:\n            trace_count_text = trace_count_text.replace('GET_TGID',\n                                        'bpf_get_current_pid_tgid() >> 32')\n            trace_count_text = trace_count_text.replace('STORE_COMM',\n                        'bpf_get_current_comm(&key.name, sizeof(key.name));')\n        else:\n            # kernel stacks only. skip splitting on PID so these aggregate\n            # together, and don't store the process name.\n            trace_count_text = trace_count_text.replace(\n                                    'GET_TGID', '0xffffffff')\n            trace_count_text = trace_count_text.replace('STORE_COMM', '')\n\n        self.usdt = None\n        if self.type == \"u\":\n            self.usdt = USDT(path=self.library, pid=self.pid)\n            for probe in self.usdt.enumerate_probes():\n                if not self.pid and (probe.bin_path != self.library):\n                    continue\n                if re.match(self.pattern, probe.name):\n                    # This hack is required because the bpf_usdt_readarg\n                    # functions generated need different function names for\n                    # each attached probe. If we just stick to trace_count,\n                    # we'd get multiple bpf_usdt_readarg helpers with the same\n                    # name when enabling more than one USDT probe.\n                    new_func = \"trace_count_%d\" % self.matched\n                    bpf_text += trace_count_text.replace(\n                                            \"trace_count\", new_func)\n                    self.usdt.enable_probe(probe.name, new_func)\n                    self.matched += 1\n            if debug:\n                print(self.usdt.get_text())\n        else:\n            bpf_text += trace_count_text\n\n        if debug:\n            print(bpf_text)\n        self.bpf = BPF(text=bpf_text,\n                       usdt_contexts=[self.usdt] if self.usdt else [])",
  "class Tool(object):\n    def __init__(self):\n        examples = \"\"\"examples:\n    ./stackcount submit_bio         # count kernel stack traces for submit_bio\n    ./stackcount -d ip_output       # include a user/kernel stack delimiter\n    ./stackcount -s ip_output       # show symbol offsets\n    ./stackcount -sv ip_output      # show offsets and raw addresses (verbose)\n    ./stackcount 'tcp_send*'        # count stacks for funcs matching tcp_send*\n    ./stackcount -r '^tcp_send.*'   # same as above, using regular expressions\n    ./stackcount -Ti 5 ip_output    # output every 5 seconds, with timestamps\n    ./stackcount -p 185 ip_output   # count ip_output stacks for PID 185 only\n    ./stackcount -p 185 c:malloc    # count stacks for malloc in PID 185\n    ./stackcount t:sched:sched_fork # count stacks for sched_fork tracepoint\n    ./stackcount -p 185 u:node:*    # count stacks for all USDT probes in node\n    ./stackcount -K t:sched:sched_switch   # kernel stacks only\n    ./stackcount -U t:sched:sched_switch   # user stacks only\n        \"\"\"\n        parser = argparse.ArgumentParser(\n            description=\"Count events and their stack traces\",\n            formatter_class=argparse.RawDescriptionHelpFormatter,\n            epilog=examples)\n        parser.add_argument(\"-p\", \"--pid\", type=int,\n            help=\"trace this PID only\")\n        parser.add_argument(\"-i\", \"--interval\",\n            help=\"summary interval, seconds\")\n        parser.add_argument(\"-D\", \"--duration\",\n            help=\"total duration of trace, seconds\")\n        parser.add_argument(\"-T\", \"--timestamp\", action=\"store_true\",\n            help=\"include timestamp on output\")\n        parser.add_argument(\"-r\", \"--regexp\", action=\"store_true\",\n            help=\"use regular expressions. Default is \\\"*\\\" wildcards only.\")\n        parser.add_argument(\"-s\", \"--offset\", action=\"store_true\",\n            help=\"show address offsets\")\n        parser.add_argument(\"-P\", \"--perpid\", action=\"store_true\",\n            help=\"display stacks separately for each process\")\n        parser.add_argument(\"-K\", \"--kernel-stacks-only\",\n            action=\"store_true\", help=\"kernel stack only\", default=False)\n        parser.add_argument(\"-U\", \"--user-stacks-only\",\n            action=\"store_true\", help=\"user stack only\", default=False)\n        parser.add_argument(\"-v\", \"--verbose\", action=\"store_true\",\n            help=\"show raw addresses\")\n        parser.add_argument(\"-d\", \"--delimited\", action=\"store_true\",\n            help=\"insert delimiter between kernel/user stacks\")\n        parser.add_argument(\"-f\", \"--folded\", action=\"store_true\",\n            help=\"output folded format\")\n        parser.add_argument(\"--debug\", action=\"store_true\",\n            help=\"print BPF program before starting (for debugging purposes)\")\n        parser.add_argument(\"pattern\",\n            help=\"search expression for events\")\n        self.args = parser.parse_args()\n        global debug\n        debug = self.args.debug\n\n        if self.args.duration and not self.args.interval:\n            self.args.interval = self.args.duration\n        if not self.args.interval:\n            self.args.interval = 99999999\n\n        if self.args.kernel_stacks_only and self.args.user_stacks_only:\n            print(\"ERROR: -K and -U are mutually exclusive. If you want \" +\n                \"both stacks, that is the default.\")\n            exit()\n        if not self.args.kernel_stacks_only and not self.args.user_stacks_only:\n            self.kernel_stack = True\n            self.user_stack = True\n        else:\n            self.kernel_stack = self.args.kernel_stacks_only\n            self.user_stack = self.args.user_stacks_only\n\n        self.probe = Probe(self.args.pattern,\n                           self.kernel_stack, self.user_stack,\n                           self.args.regexp, self.args.pid, self.args.perpid)\n        self.need_delimiter = self.args.delimited and not (\n                    self.args.kernel_stacks_only or self.args.user_stacks_only)\n\n    def _print_kframe(self, addr):\n        print(\"  \", end=\"\")\n        if self.args.verbose:\n            print(\"%-16x \" % addr, end=\"\")\n        if self.args.offset:\n            print(\"%s\" % self.probe.bpf.ksym(addr, show_offset=True))\n        else:\n            print(\"%s\" % self.probe.bpf.ksym(addr))\n\n    def _print_uframe(self, addr, pid):\n        print(\"  \", end=\"\")\n        if self.args.verbose:\n            print(\"%-16x \" % addr, end=\"\")\n        if self.args.offset:\n            print(\"%s\" % self.probe.bpf.sym(addr, pid, show_offset=True))\n        else:\n            print(\"%s\" % self.probe.bpf.sym(addr, pid))\n\n    @staticmethod\n    def _signal_ignore(signal, frame):\n        print()\n\n    def _print_comm(self, comm, pid):\n        print(\"    %s [%d]\" % (comm, pid))\n\n    def run(self):\n        self.probe.load()\n        self.probe.attach()\n        if not self.args.folded:\n            print(\"Tracing %d functions for \\\"%s\\\"... Hit Ctrl-C to end.\" %\n                  (self.probe.matched, self.args.pattern))\n        b = self.probe.bpf\n        exiting = 0 if self.args.interval else 1\n        seconds = 0\n        while True:\n            try:\n                sleep(int(self.args.interval))\n                seconds += int(self.args.interval)\n            except KeyboardInterrupt:\n                exiting = 1\n                # as cleanup can take many seconds, trap Ctrl-C:\n                signal.signal(signal.SIGINT, Tool._signal_ignore)\n            if self.args.duration and seconds >= int(self.args.duration):\n                exiting = 1\n\n            if not self.args.folded:\n                print()\n            if self.args.timestamp:\n                print(\"%-8s\\n\" % strftime(\"%H:%M:%S\"), end=\"\")\n\n            counts = self.probe.bpf[\"counts\"]\n            stack_traces = self.probe.bpf[\"stack_traces\"]\n            self.comm_cache = {}\n            for k, v in sorted(counts.items(),\n                               key=lambda counts: counts[1].value):\n                user_stack = [] if k.user_stack_id < 0 else \\\n                    stack_traces.walk(k.user_stack_id)\n                kernel_stack = [] if k.kernel_stack_id < 0 else \\\n                    stack_traces.walk(k.kernel_stack_id)\n\n                if self.args.folded:\n                    # print folded stack output\n                    user_stack = list(user_stack)\n                    kernel_stack = list(kernel_stack)\n                    line = [k.name.decode('utf-8', 'replace')] + \\\n                        [b.sym(addr, k.tgid) for addr in\n                        reversed(user_stack)] + \\\n                        (self.need_delimiter and [\"-\"] or []) + \\\n                        [b.ksym(addr) for addr in reversed(kernel_stack)]\n                    print(\"%s %d\" % (\";\".join(line), v.value))\n                else:\n                    # print multi-line stack output\n                    for addr in kernel_stack:\n                        self._print_kframe(addr)\n                    if self.need_delimiter:\n                        print(\"    --\")\n                    for addr in user_stack:\n                        self._print_uframe(addr, k.tgid)\n                    if not self.args.pid and k.tgid != 0xffffffff:\n                        self._print_comm(k.name, k.tgid)\n                    print(\"    %d\\n\" % v.value)\n            counts.clear()\n\n            if exiting:\n                if not self.args.folded:\n                    print(\"Detaching...\")\n                exit()",
  "def __init__(self, pattern, kernel_stack, user_stack, use_regex=False,\n                 pid=None, per_pid=False):\n        \"\"\"Init a new probe.\n\n        Init the probe from the pattern provided by the user. The supported\n        patterns mimic the 'trace' and 'argdist' tools, but are simpler because\n        we don't have to distinguish between probes and retprobes.\n\n            func            -- probe a kernel function\n            lib:func        -- probe a user-space function in the library 'lib'\n            p::func         -- same thing as 'func'\n            p:lib:func      -- same thing as 'lib:func'\n            t:cat:event     -- probe a kernel tracepoint\n            u:lib:probe     -- probe a USDT tracepoint\n        \"\"\"\n        self.kernel_stack = kernel_stack\n        self.user_stack = user_stack\n        parts = pattern.split(':')\n        if len(parts) == 1:\n            parts = [\"p\", \"\", parts[0]]\n        elif len(parts) == 2:\n            parts = [\"p\", parts[0], parts[1]]\n        elif len(parts) == 3:\n            if parts[0] == \"t\":\n                parts = [\"t\", \"\", \"%s:%s\" % tuple(parts[1:])]\n            if parts[0] not in [\"p\", \"t\", \"u\"]:\n                raise Exception(\"Type must be 'p', 't', or 'u', but got %s\" %\n                                parts[0])\n        else:\n            raise Exception(\"Too many ':'-separated components in pattern %s\" %\n                            pattern)\n\n        (self.type, self.library, self.pattern) = parts\n        if not use_regex:\n            self.pattern = self.pattern.replace('*', '.*')\n            self.pattern = '^' + self.pattern + '$'\n\n        if (self.type == \"p\" and self.library) or self.type == \"u\":\n            libpath = BPF.find_library(self.library)\n            if libpath is None:\n                # This might be an executable (e.g. 'bash')\n                libpath = BPF.find_exe(self.library)\n            if libpath is None or len(libpath) == 0:\n                raise Exception(\"unable to find library %s\" % self.library)\n            self.library = libpath\n\n        self.pid = pid\n        self.per_pid = per_pid\n        self.matched = 0",
  "def is_kernel_probe(self):\n        return self.type == \"t\" or (self.type == \"p\" and self.library == \"\")",
  "def attach(self):\n        if self.type == \"p\":\n            if self.library:\n                self.bpf.attach_uprobe(name=self.library,\n                                       sym_re=self.pattern,\n                                       fn_name=\"trace_count\",\n                                       pid=self.pid or -1)\n                self.matched = self.bpf.num_open_uprobes()\n            else:\n                self.bpf.attach_kprobe(event_re=self.pattern,\n                                       fn_name=\"trace_count\")\n                self.matched = self.bpf.num_open_kprobes()\n        elif self.type == \"t\":\n            self.bpf.attach_tracepoint(tp_re=self.pattern,\n                                       fn_name=\"trace_count\")\n            self.matched = self.bpf.num_open_tracepoints()\n        elif self.type == \"u\":\n            pass    # Nothing to do -- attach already happened in `load`\n\n        if self.matched == 0:\n            raise Exception(\"No functions matched by pattern %s\" %\n                            self.pattern)",
  "def load(self):\n        ctx_name = \"ctx\"\n        stack_trace = \"\"\n        if self.user_stack:\n                stack_trace += \"\"\"\n                    key.user_stack_id = stack_traces.get_stackid(\n                      %s, BPF_F_REUSE_STACKID | BPF_F_USER_STACK\n                    );\"\"\" % (ctx_name)\n        else:\n                stack_trace += \"key.user_stack_id = -1;\"\n        if self.kernel_stack:\n                stack_trace += \"\"\"\n                    key.kernel_stack_id = stack_traces.get_stackid(\n                      %s, BPF_F_REUSE_STACKID\n                    );\"\"\" % (ctx_name)\n        else:\n                stack_trace += \"key.kernel_stack_id = -1;\"\n\n        trace_count_text = \"\"\"\nint trace_count(void *ctx) {\n    FILTER\n    struct key_t key = {};\n    key.tgid = GET_TGID;\n    STORE_COMM\n    %s\n    counts.increment(key);\n    return 0;\n}\n        \"\"\"\n        trace_count_text = trace_count_text % (stack_trace)\n\n        bpf_text = \"\"\"#include <uapi/linux/ptrace.h>\n#include <linux/sched.h>\n\nstruct key_t {\n    // no pid (thread ID) so that we do not needlessly split this key\n    u32 tgid;\n    int kernel_stack_id;\n    int user_stack_id;\n    char name[TASK_COMM_LEN];\n};\n\nBPF_HASH(counts, struct key_t);\nBPF_STACK_TRACE(stack_traces, 1024);\n        \"\"\"\n\n        # We really mean the tgid from the kernel's perspective, which is in\n        # the top 32 bits of bpf_get_current_pid_tgid().\n        if self.is_kernel_probe() and self.pid:\n            trace_count_text = trace_count_text.replace('FILTER',\n                ('u32 pid; pid = bpf_get_current_pid_tgid() >> 32; ' +\n                'if (pid != %d) { return 0; }') % (self.pid))\n        else:\n            trace_count_text = trace_count_text.replace('FILTER', '')\n\n        # We need per-pid statistics when tracing a user-space process, because\n        # the meaning of the symbols depends on the pid. We also need them if\n        # per-pid statistics were requested with -P, or for user stacks.\n        if self.per_pid or not self.is_kernel_probe() or self.user_stack:\n            trace_count_text = trace_count_text.replace('GET_TGID',\n                                        'bpf_get_current_pid_tgid() >> 32')\n            trace_count_text = trace_count_text.replace('STORE_COMM',\n                        'bpf_get_current_comm(&key.name, sizeof(key.name));')\n        else:\n            # kernel stacks only. skip splitting on PID so these aggregate\n            # together, and don't store the process name.\n            trace_count_text = trace_count_text.replace(\n                                    'GET_TGID', '0xffffffff')\n            trace_count_text = trace_count_text.replace('STORE_COMM', '')\n\n        self.usdt = None\n        if self.type == \"u\":\n            self.usdt = USDT(path=self.library, pid=self.pid)\n            for probe in self.usdt.enumerate_probes():\n                if not self.pid and (probe.bin_path != self.library):\n                    continue\n                if re.match(self.pattern, probe.name):\n                    # This hack is required because the bpf_usdt_readarg\n                    # functions generated need different function names for\n                    # each attached probe. If we just stick to trace_count,\n                    # we'd get multiple bpf_usdt_readarg helpers with the same\n                    # name when enabling more than one USDT probe.\n                    new_func = \"trace_count_%d\" % self.matched\n                    bpf_text += trace_count_text.replace(\n                                            \"trace_count\", new_func)\n                    self.usdt.enable_probe(probe.name, new_func)\n                    self.matched += 1\n            if debug:\n                print(self.usdt.get_text())\n        else:\n            bpf_text += trace_count_text\n\n        if debug:\n            print(bpf_text)\n        self.bpf = BPF(text=bpf_text,\n                       usdt_contexts=[self.usdt] if self.usdt else [])",
  "def __init__(self):\n        examples = \"\"\"examples:\n    ./stackcount submit_bio         # count kernel stack traces for submit_bio\n    ./stackcount -d ip_output       # include a user/kernel stack delimiter\n    ./stackcount -s ip_output       # show symbol offsets\n    ./stackcount -sv ip_output      # show offsets and raw addresses (verbose)\n    ./stackcount 'tcp_send*'        # count stacks for funcs matching tcp_send*\n    ./stackcount -r '^tcp_send.*'   # same as above, using regular expressions\n    ./stackcount -Ti 5 ip_output    # output every 5 seconds, with timestamps\n    ./stackcount -p 185 ip_output   # count ip_output stacks for PID 185 only\n    ./stackcount -p 185 c:malloc    # count stacks for malloc in PID 185\n    ./stackcount t:sched:sched_fork # count stacks for sched_fork tracepoint\n    ./stackcount -p 185 u:node:*    # count stacks for all USDT probes in node\n    ./stackcount -K t:sched:sched_switch   # kernel stacks only\n    ./stackcount -U t:sched:sched_switch   # user stacks only\n        \"\"\"\n        parser = argparse.ArgumentParser(\n            description=\"Count events and their stack traces\",\n            formatter_class=argparse.RawDescriptionHelpFormatter,\n            epilog=examples)\n        parser.add_argument(\"-p\", \"--pid\", type=int,\n            help=\"trace this PID only\")\n        parser.add_argument(\"-i\", \"--interval\",\n            help=\"summary interval, seconds\")\n        parser.add_argument(\"-D\", \"--duration\",\n            help=\"total duration of trace, seconds\")\n        parser.add_argument(\"-T\", \"--timestamp\", action=\"store_true\",\n            help=\"include timestamp on output\")\n        parser.add_argument(\"-r\", \"--regexp\", action=\"store_true\",\n            help=\"use regular expressions. Default is \\\"*\\\" wildcards only.\")\n        parser.add_argument(\"-s\", \"--offset\", action=\"store_true\",\n            help=\"show address offsets\")\n        parser.add_argument(\"-P\", \"--perpid\", action=\"store_true\",\n            help=\"display stacks separately for each process\")\n        parser.add_argument(\"-K\", \"--kernel-stacks-only\",\n            action=\"store_true\", help=\"kernel stack only\", default=False)\n        parser.add_argument(\"-U\", \"--user-stacks-only\",\n            action=\"store_true\", help=\"user stack only\", default=False)\n        parser.add_argument(\"-v\", \"--verbose\", action=\"store_true\",\n            help=\"show raw addresses\")\n        parser.add_argument(\"-d\", \"--delimited\", action=\"store_true\",\n            help=\"insert delimiter between kernel/user stacks\")\n        parser.add_argument(\"-f\", \"--folded\", action=\"store_true\",\n            help=\"output folded format\")\n        parser.add_argument(\"--debug\", action=\"store_true\",\n            help=\"print BPF program before starting (for debugging purposes)\")\n        parser.add_argument(\"pattern\",\n            help=\"search expression for events\")\n        self.args = parser.parse_args()\n        global debug\n        debug = self.args.debug\n\n        if self.args.duration and not self.args.interval:\n            self.args.interval = self.args.duration\n        if not self.args.interval:\n            self.args.interval = 99999999\n\n        if self.args.kernel_stacks_only and self.args.user_stacks_only:\n            print(\"ERROR: -K and -U are mutually exclusive. If you want \" +\n                \"both stacks, that is the default.\")\n            exit()\n        if not self.args.kernel_stacks_only and not self.args.user_stacks_only:\n            self.kernel_stack = True\n            self.user_stack = True\n        else:\n            self.kernel_stack = self.args.kernel_stacks_only\n            self.user_stack = self.args.user_stacks_only\n\n        self.probe = Probe(self.args.pattern,\n                           self.kernel_stack, self.user_stack,\n                           self.args.regexp, self.args.pid, self.args.perpid)\n        self.need_delimiter = self.args.delimited and not (\n                    self.args.kernel_stacks_only or self.args.user_stacks_only)",
  "def _print_kframe(self, addr):\n        print(\"  \", end=\"\")\n        if self.args.verbose:\n            print(\"%-16x \" % addr, end=\"\")\n        if self.args.offset:\n            print(\"%s\" % self.probe.bpf.ksym(addr, show_offset=True))\n        else:\n            print(\"%s\" % self.probe.bpf.ksym(addr))",
  "def _print_uframe(self, addr, pid):\n        print(\"  \", end=\"\")\n        if self.args.verbose:\n            print(\"%-16x \" % addr, end=\"\")\n        if self.args.offset:\n            print(\"%s\" % self.probe.bpf.sym(addr, pid, show_offset=True))\n        else:\n            print(\"%s\" % self.probe.bpf.sym(addr, pid))",
  "def _signal_ignore(signal, frame):\n        print()",
  "def _print_comm(self, comm, pid):\n        print(\"    %s [%d]\" % (comm, pid))",
  "def run(self):\n        self.probe.load()\n        self.probe.attach()\n        if not self.args.folded:\n            print(\"Tracing %d functions for \\\"%s\\\"... Hit Ctrl-C to end.\" %\n                  (self.probe.matched, self.args.pattern))\n        b = self.probe.bpf\n        exiting = 0 if self.args.interval else 1\n        seconds = 0\n        while True:\n            try:\n                sleep(int(self.args.interval))\n                seconds += int(self.args.interval)\n            except KeyboardInterrupt:\n                exiting = 1\n                # as cleanup can take many seconds, trap Ctrl-C:\n                signal.signal(signal.SIGINT, Tool._signal_ignore)\n            if self.args.duration and seconds >= int(self.args.duration):\n                exiting = 1\n\n            if not self.args.folded:\n                print()\n            if self.args.timestamp:\n                print(\"%-8s\\n\" % strftime(\"%H:%M:%S\"), end=\"\")\n\n            counts = self.probe.bpf[\"counts\"]\n            stack_traces = self.probe.bpf[\"stack_traces\"]\n            self.comm_cache = {}\n            for k, v in sorted(counts.items(),\n                               key=lambda counts: counts[1].value):\n                user_stack = [] if k.user_stack_id < 0 else \\\n                    stack_traces.walk(k.user_stack_id)\n                kernel_stack = [] if k.kernel_stack_id < 0 else \\\n                    stack_traces.walk(k.kernel_stack_id)\n\n                if self.args.folded:\n                    # print folded stack output\n                    user_stack = list(user_stack)\n                    kernel_stack = list(kernel_stack)\n                    line = [k.name.decode('utf-8', 'replace')] + \\\n                        [b.sym(addr, k.tgid) for addr in\n                        reversed(user_stack)] + \\\n                        (self.need_delimiter and [\"-\"] or []) + \\\n                        [b.ksym(addr) for addr in reversed(kernel_stack)]\n                    print(\"%s %d\" % (\";\".join(line), v.value))\n                else:\n                    # print multi-line stack output\n                    for addr in kernel_stack:\n                        self._print_kframe(addr)\n                    if self.need_delimiter:\n                        print(\"    --\")\n                    for addr in user_stack:\n                        self._print_uframe(addr, k.tgid)\n                    if not self.args.pid and k.tgid != 0xffffffff:\n                        self._print_comm(k.name, k.tgid)\n                    print(\"    %d\\n\" % v.value)\n            counts.clear()\n\n            if exiting:\n                if not self.args.folded:\n                    print(\"Detaching...\")\n                exit()",
  "class Data_ipv4(ct.Structure):\n    _fields_ = [\n        (\"ts_us\", ct.c_ulonglong),\n        (\"pid\", ct.c_uint),\n        (\"saddr\", ct.c_uint),\n        (\"daddr\", ct.c_uint),\n        (\"ip\", ct.c_ulonglong),\n        (\"lport\", ct.c_ushort),\n        (\"task\", ct.c_char * TASK_COMM_LEN)\n    ]",
  "class Data_ipv6(ct.Structure):\n    _fields_ = [\n        (\"ts_us\", ct.c_ulonglong),\n        (\"pid\", ct.c_uint),\n        (\"saddr\", (ct.c_ulonglong * 2)),\n        (\"daddr\", (ct.c_ulonglong * 2)),\n        (\"ip\", ct.c_ulonglong),\n        (\"lport\", ct.c_ushort),\n        (\"task\", ct.c_char * TASK_COMM_LEN)\n    ]",
  "def print_ipv4_event(cpu, data, size):\n    event = ct.cast(data, ct.POINTER(Data_ipv4)).contents\n    global start_ts\n    if args.timestamp:\n        if start_ts == 0:\n            start_ts = event.ts_us\n        print(\"%-9.3f\" % ((float(event.ts_us) - start_ts) / 1000000), end=\"\")\n    printb(b\"%-6d %-12.12s %-2d %-16s %-16s %-4d\" % (event.pid,\n        event.task, event.ip,\n        inet_ntop(AF_INET, pack(\"I\", event.daddr)).encode(),\n        inet_ntop(AF_INET, pack(\"I\", event.saddr)).encode(),\n        event.lport))",
  "def print_ipv6_event(cpu, data, size):\n    event = ct.cast(data, ct.POINTER(Data_ipv6)).contents\n    global start_ts\n    if args.timestamp:\n        if start_ts == 0:\n            start_ts = event.ts_us\n        print(\"%-9.3f\" % ((float(event.ts_us) - start_ts) / 1000000), end=\"\")\n    printb(b\"%-6d %-12.12s %-2d %-16s %-16s %-4d\" % (event.pid,\n        event.task, event.ip,\n        inet_ntop(AF_INET6, event.daddr).encode(),\n        inet_ntop(AF_INET6, event.saddr).encode(),\n        event.lport))",
  "class Data_ipv4(ct.Structure):\n    _fields_ = [\n        (\"ts_us\", ct.c_ulonglong),\n        (\"pid\", ct.c_uint),\n        (\"uid\", ct.c_uint),\n        (\"saddr\", ct.c_uint),\n        (\"daddr\", ct.c_uint),\n        (\"ip\", ct.c_ulonglong),\n        (\"dport\", ct.c_ushort),\n        (\"task\", ct.c_char * TASK_COMM_LEN)\n    ]",
  "class Data_ipv6(ct.Structure):\n    _fields_ = [\n        (\"ts_us\", ct.c_ulonglong),\n        (\"pid\", ct.c_uint),\n        (\"uid\", ct.c_uint),\n        (\"saddr\", (ct.c_ulonglong * 2)),\n        (\"daddr\", (ct.c_ulonglong * 2)),\n        (\"ip\", ct.c_ulonglong),\n        (\"dport\", ct.c_ushort),\n        (\"task\", ct.c_char * TASK_COMM_LEN)\n    ]",
  "def print_ipv4_event(cpu, data, size):\n    event = ct.cast(data, ct.POINTER(Data_ipv4)).contents\n    global start_ts\n    if args.timestamp:\n        if start_ts == 0:\n            start_ts = event.ts_us\n        print(\"%-9.3f\" % ((float(event.ts_us) - start_ts) / 1000000), end=\"\")\n    if args.print_uid:\n        print(\"%-6d\" % event.uid, end=\"\")\n    printb(b\"%-6d %-12.12s %-2d %-16s %-16s %-4d\" % (event.pid,\n        event.task, event.ip,\n        inet_ntop(AF_INET, pack(\"I\", event.saddr)).encode(),\n        inet_ntop(AF_INET, pack(\"I\", event.daddr)).encode(), event.dport))",
  "def print_ipv6_event(cpu, data, size):\n    event = ct.cast(data, ct.POINTER(Data_ipv6)).contents\n    global start_ts\n    if args.timestamp:\n        if start_ts == 0:\n            start_ts = event.ts_us\n        print(\"%-9.3f\" % ((float(event.ts_us) - start_ts) / 1000000), end=\"\")\n    if args.print_uid:\n        print(\"%-6d\" % event.uid, end=\"\")\n    printb(b\"%-6d %-12.12s %-2d %-16s %-16s %-4d\" % (event.pid,\n        event.task, event.ip,\n        inet_ntop(AF_INET6, event.saddr).encode(), inet_ntop(AF_INET6, event.daddr).encode(),\n        event.dport))",
  "class Probe:\n    errno_mapping = {\n        \"kmalloc\": \"-ENOMEM\",\n        \"bio\": \"-EIO\",\n        \"alloc_page\" : \"true\",\n    }\n\n    @classmethod\n    def configure(cls, mode, probability, count):\n        cls.mode = mode\n        cls.probability = probability\n        cls.count = count\n\n    def __init__(self, func, preds, length, entry):\n        # length of call chain\n        self.length = length\n        self.func = func\n        self.preds = preds\n        self.is_entry = entry\n\n    def _bail(self, err):\n        raise ValueError(\"error in probe '%s': %s\" %\n                (self.spec, err))\n\n    def _get_err(self):\n        return Probe.errno_mapping[Probe.mode]\n\n    def _get_if_top(self):\n        # ordering guarantees that if this function is top, the last tup is top\n        chk = self.preds[0][1] == 0\n        if not chk:\n            return \"\"\n\n        if Probe.probability == 1:\n            early_pred = \"false\"\n        else:\n            early_pred = \"bpf_get_prandom_u32() > %s\" % str(int((1<<32)*Probe.probability))\n        # init the map\n        # dont do an early exit here so the singular case works automatically\n        # have an early exit for probability option\n        enter = \"\"\"\n        /*\n         * Early exit for probability case\n         */\n        if (%s)\n               return 0;\n        /*\n         * Top level function init map\n         */\n        struct pid_struct p_struct = {0, 0};\n        m.insert(&pid, &p_struct);\n        \"\"\" % early_pred\n\n        # kill the entry\n        exit = \"\"\"\n        /*\n         * Top level function clean up map\n         */\n        m.delete(&pid);\n        \"\"\"\n\n        return enter if self.is_entry else exit\n\n    def _get_heading(self):\n\n        # we need to insert identifier and ctx into self.func\n        # gonna make a lot of formatting assumptions to make this work\n        left = self.func.find(\"(\")\n        right = self.func.rfind(\")\")\n\n        # self.event and self.func_name need to be accessible\n        self.event = self.func[0:left]\n        self.func_name = self.event + (\"_entry\" if self.is_entry else \"_exit\")\n        func_sig = \"struct pt_regs *ctx\"\n\n        # assume theres something in there, no guarantee its well formed\n        if right > left + 1 and self.is_entry:\n            func_sig += \", \" + self.func[left + 1:right]\n\n        return \"int %s(%s)\" % (self.func_name, func_sig)\n\n    def _get_entry_logic(self):\n        # there is at least one tup(pred, place) for this function\n        text = \"\"\"\n\n        if (p->conds_met >= %s)\n                return 0;\n        if (p->conds_met == %s && %s) {\n                p->stack[%s] = p->curr_call;\n                p->conds_met++;\n        }\"\"\"\n        text = text % (self.length, self.preds[0][1], self.preds[0][0],\n                self.preds[0][1])\n\n        # for each additional pred\n        for tup in self.preds[1:]:\n            text += \"\"\"\n        else if (p->conds_met == %s && %s) {\n                p->stack[%s] = p->curr_call;\n                p->conds_met++;\n        }\n            \"\"\" % (tup[1], tup[0], tup[1])\n        return text\n\n    def _generate_entry(self):\n        prog = self._get_heading() + \"\"\"\n{\n        u32 pid = bpf_get_current_pid_tgid();\n        %s\n\n        struct pid_struct *p = m.lookup(&pid);\n\n        if (!p)\n                return 0;\n\n        /*\n         * preparation for predicate, if necessary\n         */\n         %s\n        /*\n         * Generate entry logic\n         */\n        %s\n\n        p->curr_call++;\n\n        return 0;\n}\"\"\"\n\n        prog = prog % (self._get_if_top(), self.prep, self._get_entry_logic())\n        return prog\n\n    # only need to check top of stack\n    def _get_exit_logic(self):\n        text = \"\"\"\n        if (p->conds_met < 1 || p->conds_met >= %s)\n                return 0;\n\n        if (p->stack[p->conds_met - 1] == p->curr_call)\n                p->conds_met--;\n        \"\"\"\n        return text % str(self.length + 1)\n\n    def _generate_exit(self):\n        prog = self._get_heading() + \"\"\"\n{\n        u32 pid = bpf_get_current_pid_tgid();\n\n        struct pid_struct *p = m.lookup(&pid);\n\n        if (!p)\n                return 0;\n\n        p->curr_call--;\n\n        /*\n         * Generate exit logic\n         */\n        %s\n        %s\n        return 0;\n}\"\"\"\n\n        prog = prog % (self._get_exit_logic(), self._get_if_top())\n\n        return prog\n\n    # Special case for should_fail_whatever\n    def _generate_bottom(self):\n        pred = self.preds[0][0]\n        text = self._get_heading() + \"\"\"\n{\n        u32 overriden = 0;\n        int zero = 0;\n        u32* val;\n\n        val = count.lookup(&zero);\n        if (val)\n            overriden = *val;\n\n        /*\n         * preparation for predicate, if necessary\n         */\n         %s\n        /*\n         * If this is the only call in the chain and predicate passes\n         */\n        if (%s == 1 && %s && overriden < %s) {\n                count.increment(zero);\n                bpf_override_return(ctx, %s);\n                return 0;\n        }\n        u32 pid = bpf_get_current_pid_tgid();\n\n        struct pid_struct *p = m.lookup(&pid);\n\n        if (!p)\n                return 0;\n\n        /*\n         * If all conds have been met and predicate passes\n         */\n        if (p->conds_met == %s && %s && overriden < %s) {\n                count.increment(zero);\n                bpf_override_return(ctx, %s);\n        }\n        return 0;\n}\"\"\"\n        return text % (self.prep, self.length, pred, Probe.count,\n                self._get_err(), self.length - 1, pred, Probe.count,\n                self._get_err())\n\n    # presently parses and replaces STRCMP\n    # STRCMP exists because string comparison is inconvenient and somewhat buggy\n    # https://github.com/iovisor/bcc/issues/1617\n    def _prepare_pred(self):\n        self.prep = \"\"\n        for i in range(len(self.preds)):\n            new_pred = \"\"\n            pred = self.preds[i][0]\n            place = self.preds[i][1]\n            start, ind = 0, 0\n            while start < len(pred):\n                ind = pred.find(\"STRCMP(\", start)\n                if ind == -1:\n                    break\n                new_pred += pred[start:ind]\n                # 7 is len(\"STRCMP(\")\n                start = pred.find(\")\", start + 7) + 1\n\n                # then ind ... start is STRCMP(...)\n                ptr, literal = pred[ind + 7:start - 1].split(\",\")\n                literal = literal.strip()\n\n                # x->y->z, some string literal\n                # we make unique id with place_ind\n                uuid = \"%s_%s\" % (place, ind)\n                unique_bool = \"is_true_%s\" % uuid\n                self.prep += \"\"\"\n        char *str_%s = %s;\n        bool %s = true;\\n\"\"\" % (uuid, ptr.strip(), unique_bool)\n\n                check = \"\\t%s &= *(str_%s++) == '%%s';\\n\" % (unique_bool, uuid)\n\n                for ch in literal:\n                    self.prep += check % ch\n                self.prep += check % r'\\0'\n                new_pred += unique_bool\n\n            new_pred += pred[start:]\n            self.preds[i] = (new_pred, place)\n\n    def generate_program(self):\n        # generate code to work around various rewriter issues\n        self._prepare_pred()\n\n        # special case for bottom\n        if self.preds[-1][1] == self.length - 1:\n            return self._generate_bottom()\n\n        return self._generate_entry() if self.is_entry else self._generate_exit()\n\n    def attach(self, bpf):\n        if self.is_entry:\n            bpf.attach_kprobe(event=self.event,\n                    fn_name=self.func_name)\n        else:\n            bpf.attach_kretprobe(event=self.event,\n                    fn_name=self.func_name)",
  "class Tool:\n\n    examples =\"\"\"\nEXAMPLES:\n# ./inject.py kmalloc -v 'SyS_mount()'\n    Fails all calls to syscall mount\n# ./inject.py kmalloc -v '(true) => SyS_mount()(true)'\n    Explicit rewriting of above\n# ./inject.py kmalloc -v 'mount_subtree() => btrfs_mount()'\n    Fails btrfs mounts only\n# ./inject.py kmalloc -v 'd_alloc_parallel(struct dentry *parent, const struct \\\\\n    qstr *name)(STRCMP(name->name, 'bananas'))'\n    Fails dentry allocations of files named 'bananas'\n# ./inject.py kmalloc -v -P 0.01 'SyS_mount()'\n    Fails calls to syscall mount with 1% probability\n    \"\"\"\n    # add cases as necessary\n    error_injection_mapping = {\n        \"kmalloc\": \"should_failslab(struct kmem_cache *s, gfp_t gfpflags)\",\n        \"bio\": \"should_fail_bio(struct bio *bio)\",\n        \"alloc_page\": \"should_fail_alloc_page(gfp_t gfp_mask, unsigned int order)\",\n    }\n\n    def __init__(self):\n        parser = argparse.ArgumentParser(description=\"Fail specified kernel\" +\n                \" functionality when call chain and predicates are met\",\n                formatter_class=argparse.RawDescriptionHelpFormatter,\n                epilog=Tool.examples)\n        parser.add_argument(dest=\"mode\", choices=[\"kmalloc\", \"bio\", \"alloc_page\"],\n                help=\"indicate which base kernel function to fail\")\n        parser.add_argument(metavar=\"spec\", dest=\"spec\",\n                help=\"specify call chain\")\n        parser.add_argument(\"-I\", \"--include\", action=\"append\",\n                metavar=\"header\",\n                help=\"additional header files to include in the BPF program\")\n        parser.add_argument(\"-P\", \"--probability\", default=1,\n                metavar=\"probability\", type=float,\n                help=\"probability that this call chain will fail\")\n        parser.add_argument(\"-v\", \"--verbose\", action=\"store_true\",\n                help=\"print BPF program\")\n        parser.add_argument(\"-c\", \"--count\", action=\"store\", default=-1,\n                help=\"Number of fails before bypassing the override\")\n        self.args = parser.parse_args()\n\n        self.program = \"\"\n        self.spec = self.args.spec\n        self.map = {}\n        self.probes = []\n        self.key = Tool.error_injection_mapping[self.args.mode]\n\n    # create_probes and associated stuff\n    def _create_probes(self):\n        self._parse_spec()\n        Probe.configure(self.args.mode, self.args.probability, self.args.count)\n        # self, func, preds, total, entry\n\n        # create all the pair probes\n        for fx, preds in self.map.items():\n\n            # do the enter\n            self.probes.append(Probe(fx, preds, self.length, True))\n\n            if self.key == fx:\n                continue\n\n            # do the exit\n            self.probes.append(Probe(fx, preds, self.length, False))\n\n    def _parse_frames(self):\n        # sentinel\n        data = self.spec + '\\0'\n        start, count = 0, 0\n\n        frames = []\n        cur_frame = []\n        i = 0\n        last_frame_added = 0\n\n        while i < len(data):\n            # improper input\n            if count < 0:\n                raise Exception(\"Check your parentheses\")\n            c = data[i]\n            count += c == '('\n            count -= c == ')'\n            if not count:\n                if c == '\\0' or (c == '=' and data[i + 1] == '>'):\n                    # This block is closing a chunk. This means cur_frame must\n                    # have something in it.\n                    if not cur_frame:\n                        raise Exception(\"Cannot parse spec, missing parens\")\n                    if len(cur_frame) == 2:\n                        frame = tuple(cur_frame)\n                    elif cur_frame[0][0] == '(':\n                        frame = self.key, cur_frame[0]\n                    else:\n                        frame = cur_frame[0], '(true)'\n                    frames.append(frame)\n                    del cur_frame[:]\n                    i += 1\n                    start = i + 1\n                elif c == ')':\n                    cur_frame.append(data[start:i + 1].strip())\n                    start = i + 1\n                    last_frame_added = start\n            i += 1\n\n        # We only permit spaces after the last frame\n        if self.spec[last_frame_added:].strip():\n            raise Exception(\"Invalid characters found after last frame\");\n        # improper input\n        if count:\n            raise Exception(\"Check your parentheses\")\n        return frames\n\n    def _parse_spec(self):\n        frames = self._parse_frames()\n        frames.reverse()\n\n        absolute_order = 0\n        for f in frames:\n            # default case\n            func, pred = f[0], f[1]\n\n            if not self._validate_predicate(pred):\n                raise Exception(\"Invalid predicate\")\n            if not self._validate_identifier(func):\n                raise Exception(\"Invalid function identifier\")\n            tup = (pred, absolute_order)\n\n            if func not in self.map:\n                self.map[func] = [tup]\n            else:\n                self.map[func].append(tup)\n\n            absolute_order += 1\n\n        if self.key not in self.map:\n            self.map[self.key] = [('(true)', absolute_order)]\n            absolute_order += 1\n\n        self.length = absolute_order\n\n    def _validate_identifier(self, func):\n        # We've already established paren balancing. We will only look for\n        # identifier validity here.\n        paren_index = func.find(\"(\")\n        potential_id = func[:paren_index]\n        pattern = '[_a-zA-z][_a-zA-Z0-9]*$'\n        if re.match(pattern, potential_id):\n            return True\n        return False\n\n    def _validate_predicate(self, pred):\n\n        if len(pred) > 0 and pred[0] == \"(\":\n            open = 1\n            for i in range(1, len(pred)):\n                if pred[i] == \"(\":\n                    open += 1\n                elif pred[i] == \")\":\n                    open -= 1\n            if open != 0:\n                # not well formed, break\n                return False\n\n        return True\n\n    def _def_pid_struct(self):\n        text = \"\"\"\nstruct pid_struct {\n    u64 curr_call; /* book keeping to handle recursion */\n    u64 conds_met; /* stack pointer */\n    u64 stack[%s];\n};\n\"\"\" % self.length\n        return text\n\n    def _attach_probes(self):\n        self.bpf = BPF(text=self.program)\n        for p in self.probes:\n            p.attach(self.bpf)\n\n    def _generate_program(self):\n        # leave out auto includes for now\n        self.program += '#include <linux/mm.h>\\n'\n        for include in (self.args.include or []):\n            self.program += \"#include <%s>\\n\" % include\n\n        self.program += self._def_pid_struct()\n        self.program += \"BPF_HASH(m, u32, struct pid_struct);\\n\"\n        self.program += \"BPF_ARRAY(count, u32, 1);\\n\"\n\n        for p in self.probes:\n            self.program += p.generate_program() + \"\\n\"\n\n        if self.args.verbose:\n            print(self.program)\n\n    def _main_loop(self):\n        while True:\n            try:\n                self.bpf.perf_buffer_poll()\n            except KeyboardInterrupt:\n                exit()\n\n    def run(self):\n        self._create_probes()\n        self._generate_program()\n        self._attach_probes()\n        self._main_loop()",
  "def configure(cls, mode, probability, count):\n        cls.mode = mode\n        cls.probability = probability\n        cls.count = count",
  "def __init__(self, func, preds, length, entry):\n        # length of call chain\n        self.length = length\n        self.func = func\n        self.preds = preds\n        self.is_entry = entry",
  "def _bail(self, err):\n        raise ValueError(\"error in probe '%s': %s\" %\n                (self.spec, err))",
  "def _get_err(self):\n        return Probe.errno_mapping[Probe.mode]",
  "def _get_if_top(self):\n        # ordering guarantees that if this function is top, the last tup is top\n        chk = self.preds[0][1] == 0\n        if not chk:\n            return \"\"\n\n        if Probe.probability == 1:\n            early_pred = \"false\"\n        else:\n            early_pred = \"bpf_get_prandom_u32() > %s\" % str(int((1<<32)*Probe.probability))\n        # init the map\n        # dont do an early exit here so the singular case works automatically\n        # have an early exit for probability option\n        enter = \"\"\"\n        /*\n         * Early exit for probability case\n         */\n        if (%s)\n               return 0;\n        /*\n         * Top level function init map\n         */\n        struct pid_struct p_struct = {0, 0};\n        m.insert(&pid, &p_struct);\n        \"\"\" % early_pred\n\n        # kill the entry\n        exit = \"\"\"\n        /*\n         * Top level function clean up map\n         */\n        m.delete(&pid);\n        \"\"\"\n\n        return enter if self.is_entry else exit",
  "def _get_heading(self):\n\n        # we need to insert identifier and ctx into self.func\n        # gonna make a lot of formatting assumptions to make this work\n        left = self.func.find(\"(\")\n        right = self.func.rfind(\")\")\n\n        # self.event and self.func_name need to be accessible\n        self.event = self.func[0:left]\n        self.func_name = self.event + (\"_entry\" if self.is_entry else \"_exit\")\n        func_sig = \"struct pt_regs *ctx\"\n\n        # assume theres something in there, no guarantee its well formed\n        if right > left + 1 and self.is_entry:\n            func_sig += \", \" + self.func[left + 1:right]\n\n        return \"int %s(%s)\" % (self.func_name, func_sig)",
  "def _get_entry_logic(self):\n        # there is at least one tup(pred, place) for this function\n        text = \"\"\"\n\n        if (p->conds_met >= %s)\n                return 0;\n        if (p->conds_met == %s && %s) {\n                p->stack[%s] = p->curr_call;\n                p->conds_met++;\n        }\"\"\"\n        text = text % (self.length, self.preds[0][1], self.preds[0][0],\n                self.preds[0][1])\n\n        # for each additional pred\n        for tup in self.preds[1:]:\n            text += \"\"\"\n        else if (p->conds_met == %s && %s) {\n                p->stack[%s] = p->curr_call;\n                p->conds_met++;\n        }\n            \"\"\" % (tup[1], tup[0], tup[1])\n        return text",
  "def _generate_entry(self):\n        prog = self._get_heading() + \"\"\"\n{\n        u32 pid = bpf_get_current_pid_tgid();\n        %s\n\n        struct pid_struct *p = m.lookup(&pid);\n\n        if (!p)\n                return 0;\n\n        /*\n         * preparation for predicate, if necessary\n         */\n         %s\n        /*\n         * Generate entry logic\n         */\n        %s\n\n        p->curr_call++;\n\n        return 0;\n}\"\"\"\n\n        prog = prog % (self._get_if_top(), self.prep, self._get_entry_logic())\n        return prog",
  "def _get_exit_logic(self):\n        text = \"\"\"\n        if (p->conds_met < 1 || p->conds_met >= %s)\n                return 0;\n\n        if (p->stack[p->conds_met - 1] == p->curr_call)\n                p->conds_met--;\n        \"\"\"\n        return text % str(self.length + 1)",
  "def _generate_exit(self):\n        prog = self._get_heading() + \"\"\"\n{\n        u32 pid = bpf_get_current_pid_tgid();\n\n        struct pid_struct *p = m.lookup(&pid);\n\n        if (!p)\n                return 0;\n\n        p->curr_call--;\n\n        /*\n         * Generate exit logic\n         */\n        %s\n        %s\n        return 0;\n}\"\"\"\n\n        prog = prog % (self._get_exit_logic(), self._get_if_top())\n\n        return prog",
  "def _generate_bottom(self):\n        pred = self.preds[0][0]\n        text = self._get_heading() + \"\"\"\n{\n        u32 overriden = 0;\n        int zero = 0;\n        u32* val;\n\n        val = count.lookup(&zero);\n        if (val)\n            overriden = *val;\n\n        /*\n         * preparation for predicate, if necessary\n         */\n         %s\n        /*\n         * If this is the only call in the chain and predicate passes\n         */\n        if (%s == 1 && %s && overriden < %s) {\n                count.increment(zero);\n                bpf_override_return(ctx, %s);\n                return 0;\n        }\n        u32 pid = bpf_get_current_pid_tgid();\n\n        struct pid_struct *p = m.lookup(&pid);\n\n        if (!p)\n                return 0;\n\n        /*\n         * If all conds have been met and predicate passes\n         */\n        if (p->conds_met == %s && %s && overriden < %s) {\n                count.increment(zero);\n                bpf_override_return(ctx, %s);\n        }\n        return 0;\n}\"\"\"\n        return text % (self.prep, self.length, pred, Probe.count,\n                self._get_err(), self.length - 1, pred, Probe.count,\n                self._get_err())",
  "def _prepare_pred(self):\n        self.prep = \"\"\n        for i in range(len(self.preds)):\n            new_pred = \"\"\n            pred = self.preds[i][0]\n            place = self.preds[i][1]\n            start, ind = 0, 0\n            while start < len(pred):\n                ind = pred.find(\"STRCMP(\", start)\n                if ind == -1:\n                    break\n                new_pred += pred[start:ind]\n                # 7 is len(\"STRCMP(\")\n                start = pred.find(\")\", start + 7) + 1\n\n                # then ind ... start is STRCMP(...)\n                ptr, literal = pred[ind + 7:start - 1].split(\",\")\n                literal = literal.strip()\n\n                # x->y->z, some string literal\n                # we make unique id with place_ind\n                uuid = \"%s_%s\" % (place, ind)\n                unique_bool = \"is_true_%s\" % uuid\n                self.prep += \"\"\"\n        char *str_%s = %s;\n        bool %s = true;\\n\"\"\" % (uuid, ptr.strip(), unique_bool)\n\n                check = \"\\t%s &= *(str_%s++) == '%%s';\\n\" % (unique_bool, uuid)\n\n                for ch in literal:\n                    self.prep += check % ch\n                self.prep += check % r'\\0'\n                new_pred += unique_bool\n\n            new_pred += pred[start:]\n            self.preds[i] = (new_pred, place)",
  "def generate_program(self):\n        # generate code to work around various rewriter issues\n        self._prepare_pred()\n\n        # special case for bottom\n        if self.preds[-1][1] == self.length - 1:\n            return self._generate_bottom()\n\n        return self._generate_entry() if self.is_entry else self._generate_exit()",
  "def attach(self, bpf):\n        if self.is_entry:\n            bpf.attach_kprobe(event=self.event,\n                    fn_name=self.func_name)\n        else:\n            bpf.attach_kretprobe(event=self.event,\n                    fn_name=self.func_name)",
  "def __init__(self):\n        parser = argparse.ArgumentParser(description=\"Fail specified kernel\" +\n                \" functionality when call chain and predicates are met\",\n                formatter_class=argparse.RawDescriptionHelpFormatter,\n                epilog=Tool.examples)\n        parser.add_argument(dest=\"mode\", choices=[\"kmalloc\", \"bio\", \"alloc_page\"],\n                help=\"indicate which base kernel function to fail\")\n        parser.add_argument(metavar=\"spec\", dest=\"spec\",\n                help=\"specify call chain\")\n        parser.add_argument(\"-I\", \"--include\", action=\"append\",\n                metavar=\"header\",\n                help=\"additional header files to include in the BPF program\")\n        parser.add_argument(\"-P\", \"--probability\", default=1,\n                metavar=\"probability\", type=float,\n                help=\"probability that this call chain will fail\")\n        parser.add_argument(\"-v\", \"--verbose\", action=\"store_true\",\n                help=\"print BPF program\")\n        parser.add_argument(\"-c\", \"--count\", action=\"store\", default=-1,\n                help=\"Number of fails before bypassing the override\")\n        self.args = parser.parse_args()\n\n        self.program = \"\"\n        self.spec = self.args.spec\n        self.map = {}\n        self.probes = []\n        self.key = Tool.error_injection_mapping[self.args.mode]",
  "def _create_probes(self):\n        self._parse_spec()\n        Probe.configure(self.args.mode, self.args.probability, self.args.count)\n        # self, func, preds, total, entry\n\n        # create all the pair probes\n        for fx, preds in self.map.items():\n\n            # do the enter\n            self.probes.append(Probe(fx, preds, self.length, True))\n\n            if self.key == fx:\n                continue\n\n            # do the exit\n            self.probes.append(Probe(fx, preds, self.length, False))",
  "def _parse_frames(self):\n        # sentinel\n        data = self.spec + '\\0'\n        start, count = 0, 0\n\n        frames = []\n        cur_frame = []\n        i = 0\n        last_frame_added = 0\n\n        while i < len(data):\n            # improper input\n            if count < 0:\n                raise Exception(\"Check your parentheses\")\n            c = data[i]\n            count += c == '('\n            count -= c == ')'\n            if not count:\n                if c == '\\0' or (c == '=' and data[i + 1] == '>'):\n                    # This block is closing a chunk. This means cur_frame must\n                    # have something in it.\n                    if not cur_frame:\n                        raise Exception(\"Cannot parse spec, missing parens\")\n                    if len(cur_frame) == 2:\n                        frame = tuple(cur_frame)\n                    elif cur_frame[0][0] == '(':\n                        frame = self.key, cur_frame[0]\n                    else:\n                        frame = cur_frame[0], '(true)'\n                    frames.append(frame)\n                    del cur_frame[:]\n                    i += 1\n                    start = i + 1\n                elif c == ')':\n                    cur_frame.append(data[start:i + 1].strip())\n                    start = i + 1\n                    last_frame_added = start\n            i += 1\n\n        # We only permit spaces after the last frame\n        if self.spec[last_frame_added:].strip():\n            raise Exception(\"Invalid characters found after last frame\");\n        # improper input\n        if count:\n            raise Exception(\"Check your parentheses\")\n        return frames",
  "def _parse_spec(self):\n        frames = self._parse_frames()\n        frames.reverse()\n\n        absolute_order = 0\n        for f in frames:\n            # default case\n            func, pred = f[0], f[1]\n\n            if not self._validate_predicate(pred):\n                raise Exception(\"Invalid predicate\")\n            if not self._validate_identifier(func):\n                raise Exception(\"Invalid function identifier\")\n            tup = (pred, absolute_order)\n\n            if func not in self.map:\n                self.map[func] = [tup]\n            else:\n                self.map[func].append(tup)\n\n            absolute_order += 1\n\n        if self.key not in self.map:\n            self.map[self.key] = [('(true)', absolute_order)]\n            absolute_order += 1\n\n        self.length = absolute_order",
  "def _validate_identifier(self, func):\n        # We've already established paren balancing. We will only look for\n        # identifier validity here.\n        paren_index = func.find(\"(\")\n        potential_id = func[:paren_index]\n        pattern = '[_a-zA-z][_a-zA-Z0-9]*$'\n        if re.match(pattern, potential_id):\n            return True\n        return False",
  "def _validate_predicate(self, pred):\n\n        if len(pred) > 0 and pred[0] == \"(\":\n            open = 1\n            for i in range(1, len(pred)):\n                if pred[i] == \"(\":\n                    open += 1\n                elif pred[i] == \")\":\n                    open -= 1\n            if open != 0:\n                # not well formed, break\n                return False\n\n        return True",
  "def _def_pid_struct(self):\n        text = \"\"\"\nstruct pid_struct {\n    u64 curr_call; /* book keeping to handle recursion */\n    u64 conds_met; /* stack pointer */\n    u64 stack[%s];\n};\n\"\"\" % self.length\n        return text",
  "def _attach_probes(self):\n        self.bpf = BPF(text=self.program)\n        for p in self.probes:\n            p.attach(self.bpf)",
  "def _generate_program(self):\n        # leave out auto includes for now\n        self.program += '#include <linux/mm.h>\\n'\n        for include in (self.args.include or []):\n            self.program += \"#include <%s>\\n\" % include\n\n        self.program += self._def_pid_struct()\n        self.program += \"BPF_HASH(m, u32, struct pid_struct);\\n\"\n        self.program += \"BPF_ARRAY(count, u32, 1);\\n\"\n\n        for p in self.probes:\n            self.program += p.generate_program() + \"\\n\"\n\n        if self.args.verbose:\n            print(self.program)",
  "def _main_loop(self):\n        while True:\n            try:\n                self.bpf.perf_buffer_poll()\n            except KeyboardInterrupt:\n                exit()",
  "def run(self):\n        self._create_probes()\n        self._generate_program()\n        self._attach_probes()\n        self._main_loop()",
  "class Data(ct.Structure):\n    _fields_ = [\n        (\"id\", ct.c_ulonglong),\n        (\"tgid_pid\", ct.c_ulonglong),\n        (\"start_ns\", ct.c_ulonglong),\n        (\"duration_ns\", ct.c_ulonglong),\n        (\"retval\", ct.c_ulonglong),\n        (\"comm\", ct.c_char * TASK_COMM_LEN)\n    ] + ([(\"args\", ct.c_ulonglong * 6)] if args.arguments else []) + \\\n            ([(\"user_stack_id\", ct.c_int)] if args.user_stack else []) + \\\n            ([(\"kernel_stack_id\", ct.c_int),(\"kernel_ip\", ct.c_ulonglong)] if args.kernel_stack else [])",
  "def time_str(event):\n    if args.time:\n        return \"%-10s \" % time.strftime(\"%H:%M:%S\")\n    if args.timestamp:\n        global earliest_ts\n        if earliest_ts == 0:\n            earliest_ts = event.start_ns\n        return \"%-10.6f \" % ((event.start_ns - earliest_ts) / 1000000000.0)\n    return \"\"",
  "def args_str(event):\n    if not args.arguments:\n        return \"\"\n    return str.join(\" \", [\"0x%x\" % arg for arg in event.args[:args.arguments]])",
  "def print_stack(event):\n    user_stack = []\n    stack_traces = b.get_table(\"stacks\")\n\n    if args.user_stack and event.user_stack_id > 0:\n        user_stack = stack_traces.walk(event.user_stack_id)\n\n    kernel_stack = []\n    if args.kernel_stack and event.kernel_stack_id > 0:\n        kernel_tmp = stack_traces.walk(event.kernel_stack_id)\n\n        # fix kernel stack\n        for addr in kernel_tmp:\n            kernel_stack.append(addr)\n\n    do_delimiter = user_stack and kernel_stack\n\n    if args.folded:\n        # print folded stack output\n        user_stack = list(user_stack)\n        kernel_stack = list(kernel_stack)\n        line = [event.comm.decode('utf-8', 'replace')] + \\\n            [b.sym(addr, event.tgid_pid) for addr in reversed(user_stack)] + \\\n            (do_delimiter and [\"-\"] or []) + \\\n            [b.ksym(addr) for addr in reversed(kernel_stack)]\n        print(\"%s %d\" % (\";\".join(line), 1))\n    else:\n        # print default multi-line stack output.\n        for addr in kernel_stack:\n            print(\"    %s\" % b.ksym(addr))\n        for addr in user_stack:\n            print(\"    %s\" % b.sym(addr, event.tgid_pid))",
  "def print_event(cpu, data, size):\n    event = ct.cast(data, ct.POINTER(Data)).contents\n    ts = float(event.duration_ns) / time_multiplier\n    if not args.folded:\n        print((time_str(event) + \"%-14.14s %-6s %7.2f %16x %s %s\") %\n            (event.comm.decode('utf-8', 'replace'), event.tgid_pid >> 32,\n             ts, event.retval, args.functions[event.id], args_str(event)))\n    if args.user_stack or args.kernel_stack:\n        print_stack(event)",
  "def comm_for_pid(pid):\n    try:\n        return open(\"/proc/%d/comm\" % pid).read().strip()\n    except:\n        return \"[unknown]\"",
  "def parse_probes(typ):\n    if args.verbosity > 1:\n        print(\"open %ss:\" % typ)\n    for probe in open(\"/sys/kernel/debug/tracing/%s_events\" % typ):\n        # Probes opened by bcc have a specific pattern that includes the pid\n        # of the requesting process.\n        match = re.search('_bcc_(\\\\d+)\\\\s', probe)\n        if match:\n            pid = int(match.group(1))\n            counts[(pid, typ)] = counts.get((pid, typ), 0) + 1\n        if args.verbosity > 1:\n            print(probe.strip())\n    if args.verbosity > 1:\n        print(\"\")",
  "def find_bpf_fds(pid):\n    root = '/proc/%d/fd' % pid\n    for fd in os.listdir(root):\n        try:\n            link = os.readlink(os.path.join(root, fd))\n        except OSError:\n            continue\n        match = re.match('.*bpf-(\\\\w+)', link)\n        if match:\n            tup = (pid, match.group(1))\n            counts[tup] = counts.get(tup, 0) + 1",
  "class Data(ct.Structure):\n    _fields_ = [\n        (\"pid\", ct.c_ulonglong),\n        (\"rwflag\", ct.c_ulonglong),\n        (\"delta\", ct.c_ulonglong),\n        (\"sector\", ct.c_ulonglong),\n        (\"len\", ct.c_ulonglong),\n        (\"ts\", ct.c_ulonglong),\n        (\"disk_name\", ct.c_char * DISK_NAME_LEN),\n        (\"name\", ct.c_char * TASK_COMM_LEN)\n    ]",
  "def print_event(cpu, data, size):\n    event = ct.cast(data, ct.POINTER(Data)).contents\n\n    val = -1\n    global start_ts\n    global prev_ts\n    global delta\n\n    if event.rwflag == 1:\n        rwflg = \"W\"\n\n    if event.rwflag == 0:\n        rwflg = \"R\"\n\n    if not re.match(b'\\?', event.name):\n        val = event.sector\n\n    if start_ts == 0:\n        prev_ts = start_ts\n\n    if start_ts == 1:\n        delta = float(delta) + (event.ts - prev_ts)\n\n    print(\"%-14.9f %-14.14s %-6s %-7s %-2s %-9s %-7s %7.2f\" % (\n        delta / 1000000, event.name.decode('utf-8', 'replace'), event.pid,\n        event.disk_name.decode('utf-8', 'replace'), rwflg, val,\n        event.len, float(event.delta) / 1000000))\n\n    prev_ts = event.ts\n    start_ts = 1",
  "def positive_int(val):\n    try:\n        ival = int(val)\n    except ValueError:\n        raise argparse.ArgumentTypeError(\"must be an integer\")\n\n    if ival < 0:\n        raise argparse.ArgumentTypeError(\"must be positive\")\n    return ival",
  "def positive_nonzero_int(val):\n    ival = positive_int(val)\n    if ival == 0:\n        raise argparse.ArgumentTypeError(\"must be nonzero\")\n    return ival",
  "def stack_id_err(stack_id):\n    # -EFAULT in get_stackid normally means the stack-trace is not availible,\n    # Such as getting kernel stack trace in userspace code\n    return (stack_id < 0) and (stack_id != -errno.EFAULT)",
  "def signal_ignore(signal, frame):\n    print()",
  "def aksym(addr):\n    if args.annotations:\n        return b.ksym(addr) + \"_[k]\".encode()\n    else:\n        return b.ksym(addr)",
  "class EventType(object):\n    EVENT_MOUNT = 0\n    EVENT_MOUNT_SOURCE = 1\n    EVENT_MOUNT_TARGET = 2\n    EVENT_MOUNT_TYPE = 3\n    EVENT_MOUNT_DATA = 4\n    EVENT_MOUNT_RET = 5\n    EVENT_UMOUNT = 6\n    EVENT_UMOUNT_TARGET = 7\n    EVENT_UMOUNT_RET = 8",
  "class EnterData(ctypes.Structure):\n    _fields_ = [\n        ('mnt_ns', ctypes.c_uint),\n        ('comm', ctypes.c_char * TASK_COMM_LEN),\n        ('flags', ctypes.c_ulong),\n    ]",
  "class DataUnion(ctypes.Union):\n    _fields_ = [\n        ('enter', EnterData),\n        ('str', ctypes.c_char * MAX_STR_LEN),\n        ('retval', ctypes.c_int),\n    ]",
  "class Event(ctypes.Structure):\n    _fields_ = [\n        ('type', ctypes.c_uint),\n        ('pid', ctypes.c_uint),\n        ('tgid', ctypes.c_uint),\n        ('union', DataUnion),\n    ]",
  "def _decode_flags(flags, flag_list):\n    str_flags = []\n    for flag, bit in flag_list:\n        if flags & bit:\n            str_flags.append(flag)\n        flags &= ~bit\n    if flags or not str_flags:\n        str_flags.append('0x{:x}'.format(flags))\n    return str_flags",
  "def decode_flags(flags, flag_list):\n    return '|'.join(_decode_flags(flags, flag_list))",
  "def decode_mount_flags(flags):\n    str_flags = []\n    if flags & MS_MGC_MSK == MS_MGC_VAL:\n        flags &= ~MS_MGC_MSK\n        str_flags.append('MS_MGC_VAL')\n    str_flags.extend(_decode_flags(flags, MOUNT_FLAGS))\n    return '|'.join(str_flags)",
  "def decode_umount_flags(flags):\n    return decode_flags(flags, UMOUNT_FLAGS)",
  "def decode_errno(retval):\n    try:\n        return '-' + errno.errorcode[-retval]\n    except KeyError:\n        return str(retval)",
  "def escape_character(c):\n    try:\n        return _escape_chars[c]\n    except KeyError:\n        if 0x20 <= c <= 0x7e:\n            return chr(c)\n        else:\n            return '\\\\x{:02x}'.format(c)",
  "def print_event(mounts, umounts, cpu, data, size):\n    event = ctypes.cast(data, ctypes.POINTER(Event)).contents\n\n    try:\n        if event.type == EventType.EVENT_MOUNT:\n            mounts[event.pid] = {\n                'pid': event.pid,\n                'tgid': event.tgid,\n                'mnt_ns': event.union.enter.mnt_ns,\n                'comm': event.union.enter.comm,\n                'flags': event.union.enter.flags,\n            }\n        elif event.type == EventType.EVENT_MOUNT_SOURCE:\n            mounts[event.pid]['source'] = event.union.str\n        elif event.type == EventType.EVENT_MOUNT_TARGET:\n            mounts[event.pid]['target'] = event.union.str\n        elif event.type == EventType.EVENT_MOUNT_TYPE:\n            mounts[event.pid]['type'] = event.union.str\n        elif event.type == EventType.EVENT_MOUNT_DATA:\n            # XXX: data is not always a NUL-terminated string\n            mounts[event.pid]['data'] = event.union.str\n        elif event.type == EventType.EVENT_UMOUNT:\n            umounts[event.pid] = {\n                'pid': event.pid,\n                'tgid': event.tgid,\n                'mnt_ns': event.union.enter.mnt_ns,\n                'comm': event.union.enter.comm,\n                'flags': event.union.enter.flags,\n            }\n        elif event.type == EventType.EVENT_UMOUNT_TARGET:\n            umounts[event.pid]['target'] = event.union.str\n        elif (event.type == EventType.EVENT_MOUNT_RET or\n              event.type == EventType.EVENT_UMOUNT_RET):\n            if event.type == EventType.EVENT_MOUNT_RET:\n                syscall = mounts.pop(event.pid)\n                call = ('mount({source}, {target}, {type}, {flags}, {data}) ' +\n                        '= {retval}').format(\n                    source=decode_mount_string(syscall['source']),\n                    target=decode_mount_string(syscall['target']),\n                    type=decode_mount_string(syscall['type']),\n                    flags=decode_mount_flags(syscall['flags']),\n                    data=decode_mount_string(syscall['data']),\n                    retval=decode_errno(event.union.retval))\n            else:\n                syscall = umounts.pop(event.pid)\n                call = 'umount({target}, {flags}) = {retval}'.format(\n                    target=decode_mount_string(syscall['target']),\n                    flags=decode_umount_flags(syscall['flags']),\n                    retval=decode_errno(event.union.retval))\n            print('{:16} {:<7} {:<7} {:<11} {}'.format(\n                syscall['comm'].decode('utf-8', 'replace'), syscall['tgid'],\n                syscall['pid'], syscall['mnt_ns'], call))\n    except KeyError:\n        # This might happen if we lost an event.\n        pass",
  "def main():\n    parser = argparse.ArgumentParser(\n        description='trace mount() and umount() syscalls'\n    )\n    parser.add_argument(\"--ebpf\", action=\"store_true\",\n        help=argparse.SUPPRESS)\n    args = parser.parse_args()\n\n    mounts = {}\n    umounts = {}\n    if args.ebpf:\n        print(bpf_text)\n        exit()\n    b = bcc.BPF(text=bpf_text)\n    mount_fnname = b.get_syscall_fnname(\"mount\")\n    b.attach_kprobe(event=mount_fnname, fn_name=\"syscall__mount\")\n    b.attach_kretprobe(event=mount_fnname, fn_name=\"do_ret_sys_mount\")\n    umount_fnname = b.get_syscall_fnname(\"umount\")\n    b.attach_kprobe(event=umount_fnname, fn_name=\"syscall__umount\")\n    b.attach_kretprobe(event=umount_fnname, fn_name=\"do_ret_sys_umount\")\n    b['events'].open_perf_buffer(\n        functools.partial(print_event, mounts, umounts))\n    print('{:16} {:<7} {:<7} {:<11} {}'.format(\n        'COMM', 'PID', 'TID', 'MNT_NS', 'CALL'))\n    while True:\n        try:\n            b.perf_buffer_poll()\n        except KeyboardInterrupt:\n            exit()",
  "def decode_mount_string(s):\n        return '\"{}\"'.format(''.join(escape_character(ord(c)) for c in s))",
  "def decode_mount_string(s):\n        return '\"{}\"'.format(''.join(escape_character(c) for c in s))",
  "def signal_ignore(signal_value, frame):\n    print()",
  "class Data(ct.Structure):\n    _fields_ = [\n        (\"pid\", ct.c_ulonglong),\n        (\"tpid\", ct.c_int),\n        (\"sig\", ct.c_int),\n        (\"ret\", ct.c_int),\n        (\"comm\", ct.c_char * TASK_COMM_LEN)\n    ]",
  "def print_event(cpu, data, size):\n    event = ct.cast(data, ct.POINTER(Data)).contents\n\n    if (args.failed and (event.ret >= 0)):\n        return\n\n    printb(b\"%-9s %-6d %-16s %-4d %-6d %d\" % (strftime(\"%H:%M:%S\").encode('ascii'),\n        event.pid, event.comm, event.sig, event.tpid, event.ret))",
  "class Data(ct.Structure):\n    _fields_ = [\n        (\"ts_us\", ct.c_ulonglong),\n        (\"type\", ct.c_ulonglong),\n        (\"size\", ct.c_ulonglong),\n        (\"offset\", ct.c_ulonglong),\n        (\"delta_us\", ct.c_ulonglong),\n        (\"pid\", ct.c_ulonglong),\n        (\"task\", ct.c_char * TASK_COMM_LEN),\n        (\"file\", ct.c_char * DNAME_INLINE_LEN)\n    ]",
  "def print_event(cpu, data, size):\n    event = ct.cast(data, ct.POINTER(Data)).contents\n\n    type = 'R'\n    if event.type == 1:\n        type = 'W'\n    elif event.type == 2:\n        type = 'O'\n    elif event.type == 3:\n        type = 'S'\n\n    if (csv):\n        print(\"%d,%s,%d,%s,%d,%d,%d,%s\" % (\n            event.ts_us, event.task, event.pid, type, event.size,\n            event.offset, event.delta_us, event.file))\n        return\n    print(\"%-8s %-14.14s %-6s %1s %-7s %-8d %7.2f %s\" % (strftime(\"%H:%M:%S\"),\n        event.task, event.pid, type, event.size, event.offset / 1024,\n        float(event.delta_us) / 1000, event.file))",
  "class Data(ct.Structure):\n    _fields_ = [\n        (\"pid\", ct.c_uint),\n        (\"task\", ct.c_char * TASK_COMM_LEN),\n        (\"delta_us\", ct.c_ulonglong),\n    ]",
  "def print_event(cpu, data, size):\n    event = ct.cast(data, ct.POINTER(Data)).contents\n    print(\"%-8s %-16s %-6s %14s\" % (strftime(\"%H:%M:%S\"), event.task, event.pid, event.delta_us))",
  "class ListenEvt(ct.Structure):\n    _fields_ = [\n        (\"ts_us\", ct.c_ulonglong),\n        (\"pid_tgid\", ct.c_ulonglong),\n        (\"backlog\", ct.c_ulonglong),\n        (\"netns\", ct.c_ulonglong),\n        (\"proto\", ct.c_ulonglong),\n        (\"lport\", ct.c_ulonglong),\n        (\"laddr\", ct.c_ulonglong * 2),\n        (\"task\", ct.c_char * TASK_COMM_LEN)\n    ]",
  "def event_printer(show_netns):\n    def print_event(cpu, data, size):\n        # Decode event\n        event = ct.cast(data, ct.POINTER(ListenEvt)).contents\n\n        pid = event.pid_tgid & 0xffffffff\n        proto_family = event.proto & 0xff\n        proto_type = event.proto >> 16 & 0xff\n\n        if proto_family == SOCK_STREAM:\n            protocol = \"TCP\"\n        elif proto_family == SOCK_DGRAM:\n            protocol = \"UDP\"\n        else:\n            protocol = \"UNK\"\n\n        address = \"\"\n        if proto_type == AF_INET:\n            protocol += \"v4\"\n            address = inet_ntop(AF_INET, pack(\"I\", event.laddr[0]))\n        elif proto_type == AF_INET6:\n            address = inet_ntop(AF_INET6, event.laddr)\n            protocol += \"v6\"\n\n        # Display\n        if show_netns:\n            printb(b\"%-6d %-12.12s %-12s %-6s %-8s %-5s %-39s\" % (\n                pid, event.task, event.netns, protocol, event.backlog,\n                event.lport, address,\n            ))\n        else:\n            printb(b\"%-6d %-12.12s %-6s %-8s %-5s %-39s\" % (\n                pid, event.task, protocol, event.backlog,\n                event.lport, address,\n            ))\n\n    return print_event",
  "def print_event(cpu, data, size):\n        # Decode event\n        event = ct.cast(data, ct.POINTER(ListenEvt)).contents\n\n        pid = event.pid_tgid & 0xffffffff\n        proto_family = event.proto & 0xff\n        proto_type = event.proto >> 16 & 0xff\n\n        if proto_family == SOCK_STREAM:\n            protocol = \"TCP\"\n        elif proto_family == SOCK_DGRAM:\n            protocol = \"UDP\"\n        else:\n            protocol = \"UNK\"\n\n        address = \"\"\n        if proto_type == AF_INET:\n            protocol += \"v4\"\n            address = inet_ntop(AF_INET, pack(\"I\", event.laddr[0]))\n        elif proto_type == AF_INET6:\n            address = inet_ntop(AF_INET6, event.laddr)\n            protocol += \"v6\"\n\n        # Display\n        if show_netns:\n            printb(b\"%-6d %-12.12s %-12s %-6s %-8s %-5s %-39s\" % (\n                pid, event.task, event.netns, protocol, event.backlog,\n                event.lport, address,\n            ))\n        else:\n            printb(b\"%-6d %-12.12s %-6s %-8s %-5s %-39s\" % (\n                pid, event.task, protocol, event.backlog,\n                event.lport, address,\n            ))",
  "def signal_ignore(signal_value, frame):\n    print()",
  "def verify_limit(num):\n    probe_limit = 1000\n    if num > probe_limit:\n        raise Exception(\"maximum of %d probes allowed, attempted %d\" %\n                        (probe_limit, num))",
  "class Probe(object):\n    def __init__(self, pattern, use_regex=False, pid=None):\n        \"\"\"Init a new probe.\n\n        Init the probe from the pattern provided by the user. The supported\n        patterns mimic the 'trace' and 'argdist' tools, but are simpler because\n        we don't have to distinguish between probes and retprobes.\n\n            func            -- probe a kernel function\n            lib:func        -- probe a user-space function in the library 'lib'\n            /path:func      -- probe a user-space function in binary '/path'\n            p::func         -- same thing as 'func'\n            p:lib:func      -- same thing as 'lib:func'\n            t:cat:event     -- probe a kernel tracepoint\n            u:lib:probe     -- probe a USDT tracepoint\n        \"\"\"\n        parts = bytes(pattern).split(b':')\n        if len(parts) == 1:\n            parts = [b\"p\", b\"\", parts[0]]\n        elif len(parts) == 2:\n            parts = [b\"p\", parts[0], parts[1]]\n        elif len(parts) == 3:\n            if parts[0] == b\"t\":\n                parts = [b\"t\", b\"\", b\"%s:%s\" % tuple(parts[1:])]\n            if parts[0] not in [b\"p\", b\"t\", b\"u\"]:\n                raise Exception(\"Type must be 'p', 't', or 'u', but got %s\" %\n                                parts[0])\n        else:\n            raise Exception(\"Too many ':'-separated components in pattern %s\" %\n                            pattern)\n\n        (self.type, self.library, self.pattern) = parts\n        if not use_regex:\n            self.pattern = self.pattern.replace(b'*', b'.*')\n            self.pattern = b'^' + self.pattern + b'$'\n\n        if (self.type == b\"p\" and self.library) or self.type == b\"u\":\n            libpath = BPF.find_library(self.library)\n            if libpath is None:\n                # This might be an executable (e.g. 'bash')\n                libpath = BPF.find_exe(self.library)\n            if libpath is None or len(libpath) == 0:\n                raise Exception(\"unable to find library %s\" % self.library)\n            self.library = libpath\n\n        self.pid = pid\n        self.matched = 0\n        self.trace_functions = {}   # map location number to function name\n\n    def is_kernel_probe(self):\n        return self.type == b\"t\" or (self.type == b\"p\" and self.library == b\"\")\n\n    def attach(self):\n        if self.type == b\"p\" and not self.library:\n            for index, function in self.trace_functions.items():\n                self.bpf.attach_kprobe(\n                        event=function,\n                        fn_name=\"trace_count_%d\" % index)\n        elif self.type == b\"p\" and self.library:\n            for index, function in self.trace_functions.items():\n                self.bpf.attach_uprobe(\n                        name=self.library,\n                        sym=function,\n                        fn_name=\"trace_count_%d\" % index,\n                        pid=self.pid or -1)\n        elif self.type == b\"t\":\n            for index, function in self.trace_functions.items():\n                self.bpf.attach_tracepoint(\n                        tp=function,\n                        fn_name=\"trace_count_%d\" % index)\n        elif self.type == b\"u\":\n            pass    # Nothing to do -- attach already happened in `load`\n\n    def _add_function(self, template, probe_name):\n        new_func = b\"trace_count_%d\" % self.matched\n        text = template.replace(b\"PROBE_FUNCTION\", new_func)\n        text = text.replace(b\"LOCATION\", b\"%d\" % self.matched)\n        self.trace_functions[self.matched] = probe_name\n        self.matched += 1\n        return text\n\n    def _generate_functions(self, template):\n        self.usdt = None\n        text = b\"\"\n        if self.type == b\"p\" and not self.library:\n            functions = BPF.get_kprobe_functions(self.pattern)\n            verify_limit(len(functions))\n            for function in functions:\n                text += self._add_function(template, function)\n        elif self.type == b\"p\" and self.library:\n            # uprobes are tricky because the same function may have multiple\n            # addresses, and the same address may be mapped to multiple\n            # functions. We aren't allowed to create more than one uprobe\n            # per address, so track unique addresses and ignore functions that\n            # map to an address that we've already seen. Also ignore functions\n            # that may repeat multiple times with different addresses.\n            addresses, functions = (set(), set())\n            functions_and_addresses = BPF.get_user_functions_and_addresses(\n                                        self.library, self.pattern)\n            verify_limit(len(functions_and_addresses))\n            for function, address in functions_and_addresses:\n                if address in addresses or function in functions:\n                    continue\n                addresses.add(address)\n                functions.add(function)\n                text += self._add_function(template, function)\n        elif self.type == b\"t\":\n            tracepoints = BPF.get_tracepoints(self.pattern)\n            verify_limit(len(tracepoints))\n            for tracepoint in tracepoints:\n                text += self._add_function(template, tracepoint)\n        elif self.type == b\"u\":\n            self.usdt = USDT(path=self.library, pid=self.pid)\n            matches = []\n            for probe in self.usdt.enumerate_probes():\n                if not self.pid and (probe.bin_path != self.library):\n                    continue\n                if re.match(self.pattern, probe.name):\n                    matches.append(probe.name)\n            verify_limit(len(matches))\n            for match in matches:\n                new_func = b\"trace_count_%d\" % self.matched\n                text += self._add_function(template, match)\n                self.usdt.enable_probe(match, new_func)\n            if debug:\n                print(self.usdt.get_text())\n        return text\n\n    def load(self):\n        trace_count_text = b\"\"\"\nint PROBE_FUNCTION(void *ctx) {\n    FILTER\n    int loc = LOCATION;\n    u64 *val = counts.lookup(&loc);\n    if (!val) {\n        return 0;   // Should never happen, # of locations is known\n    }\n    (*val)++;\n    return 0;\n}\n        \"\"\"\n        bpf_text = b\"\"\"#include <uapi/linux/ptrace.h>\n\nBPF_ARRAY(counts, u64, NUMLOCATIONS);\n        \"\"\"\n\n        # We really mean the tgid from the kernel's perspective, which is in\n        # the top 32 bits of bpf_get_current_pid_tgid().\n        if self.pid:\n            trace_count_text = trace_count_text.replace(b'FILTER',\n                b\"\"\"u32 pid = bpf_get_current_pid_tgid() >> 32;\n                   if (pid != %d) { return 0; }\"\"\" % self.pid)\n        else:\n            trace_count_text = trace_count_text.replace(b'FILTER', b'')\n\n        bpf_text += self._generate_functions(trace_count_text)\n        bpf_text = bpf_text.replace(b\"NUMLOCATIONS\",\n                                    b\"%d\" % len(self.trace_functions))\n        if debug:\n            print(bpf_text)\n\n        if self.matched == 0:\n            raise Exception(\"No functions matched by pattern %s\" %\n                            self.pattern)\n\n        self.bpf = BPF(text=bpf_text,\n                       usdt_contexts=[self.usdt] if self.usdt else [])\n        self.clear()    # Initialize all array items to zero\n\n    def counts(self):\n        return self.bpf[\"counts\"]\n\n    def clear(self):\n        counts = self.bpf[\"counts\"]\n        for location, _ in list(self.trace_functions.items()):\n            counts[counts.Key(location)] = counts.Leaf()",
  "class Tool(object):\n    def __init__(self):\n        examples = \"\"\"examples:\n    ./funccount 'vfs_*'             # count kernel fns starting with \"vfs\"\n    ./funccount -r '^vfs.*'         # same as above, using regular expressions\n    ./funccount -Ti 5 'vfs_*'       # output every 5 seconds, with timestamps\n    ./funccount -d 10 'vfs_*'       # trace for 10 seconds only\n    ./funccount -p 185 'vfs_*'      # count vfs calls for PID 181 only\n    ./funccount t:sched:sched_fork  # count calls to the sched_fork tracepoint\n    ./funccount -p 185 u:node:gc*   # count all GC USDT probes in node, PID 185\n    ./funccount c:malloc            # count all malloc() calls in libc\n    ./funccount go:os.*             # count all \"os.*\" calls in libgo\n    ./funccount -p 185 go:os.*      # count all \"os.*\" calls in libgo, PID 185\n    ./funccount ./test:read*        # count \"read*\" calls in the ./test binary\n    \"\"\"\n        parser = argparse.ArgumentParser(\n            description=\"Count functions, tracepoints, and USDT probes\",\n            formatter_class=argparse.RawDescriptionHelpFormatter,\n            epilog=examples)\n        parser.add_argument(\"-p\", \"--pid\", type=int,\n            help=\"trace this PID only\")\n        parser.add_argument(\"-i\", \"--interval\",\n            help=\"summary interval, seconds\")\n        parser.add_argument(\"-d\", \"--duration\",\n            help=\"total duration of trace, seconds\")\n        parser.add_argument(\"-T\", \"--timestamp\", action=\"store_true\",\n            help=\"include timestamp on output\")\n        parser.add_argument(\"-r\", \"--regexp\", action=\"store_true\",\n            help=\"use regular expressions. Default is \\\"*\\\" wildcards only.\")\n        parser.add_argument(\"-D\", \"--debug\", action=\"store_true\",\n            help=\"print BPF program before starting (for debugging purposes)\")\n        parser.add_argument(\"pattern\",\n            type=ArgString,\n            help=\"search expression for events\")\n        self.args = parser.parse_args()\n        global debug\n        debug = self.args.debug\n        self.probe = Probe(self.args.pattern, self.args.regexp, self.args.pid)\n        if self.args.duration and not self.args.interval:\n            self.args.interval = self.args.duration\n        if not self.args.interval:\n            self.args.interval = 99999999\n\n    @staticmethod\n    def _signal_ignore(signal, frame):\n        print()\n\n    def run(self):\n        self.probe.load()\n        self.probe.attach()\n        print(\"Tracing %d functions for \\\"%s\\\"... Hit Ctrl-C to end.\" %\n              (self.probe.matched, bytes(self.args.pattern)))\n        exiting = 0 if self.args.interval else 1\n        seconds = 0\n        while True:\n            try:\n                sleep(int(self.args.interval))\n                seconds += int(self.args.interval)\n            except KeyboardInterrupt:\n                exiting = 1\n                # as cleanup can take many seconds, trap Ctrl-C:\n                signal.signal(signal.SIGINT, Tool._signal_ignore)\n            if self.args.duration and seconds >= int(self.args.duration):\n                exiting = 1\n\n            print()\n            if self.args.timestamp:\n                print(\"%-8s\\n\" % strftime(\"%H:%M:%S\"), end=\"\")\n\n            print(\"%-36s %8s\" % (\"FUNC\", \"COUNT\"))\n            counts = self.probe.counts()\n            for k, v in sorted(counts.items(),\n                               key=lambda counts: counts[1].value):\n                if v.value == 0:\n                    continue\n                print(\"%-36s %8d\" %\n                      (self.probe.trace_functions[k.value], v.value))\n\n            if exiting:\n                print(\"Detaching...\")\n                exit()\n            else:\n                self.probe.clear()",
  "def __init__(self, pattern, use_regex=False, pid=None):\n        \"\"\"Init a new probe.\n\n        Init the probe from the pattern provided by the user. The supported\n        patterns mimic the 'trace' and 'argdist' tools, but are simpler because\n        we don't have to distinguish between probes and retprobes.\n\n            func            -- probe a kernel function\n            lib:func        -- probe a user-space function in the library 'lib'\n            /path:func      -- probe a user-space function in binary '/path'\n            p::func         -- same thing as 'func'\n            p:lib:func      -- same thing as 'lib:func'\n            t:cat:event     -- probe a kernel tracepoint\n            u:lib:probe     -- probe a USDT tracepoint\n        \"\"\"\n        parts = bytes(pattern).split(b':')\n        if len(parts) == 1:\n            parts = [b\"p\", b\"\", parts[0]]\n        elif len(parts) == 2:\n            parts = [b\"p\", parts[0], parts[1]]\n        elif len(parts) == 3:\n            if parts[0] == b\"t\":\n                parts = [b\"t\", b\"\", b\"%s:%s\" % tuple(parts[1:])]\n            if parts[0] not in [b\"p\", b\"t\", b\"u\"]:\n                raise Exception(\"Type must be 'p', 't', or 'u', but got %s\" %\n                                parts[0])\n        else:\n            raise Exception(\"Too many ':'-separated components in pattern %s\" %\n                            pattern)\n\n        (self.type, self.library, self.pattern) = parts\n        if not use_regex:\n            self.pattern = self.pattern.replace(b'*', b'.*')\n            self.pattern = b'^' + self.pattern + b'$'\n\n        if (self.type == b\"p\" and self.library) or self.type == b\"u\":\n            libpath = BPF.find_library(self.library)\n            if libpath is None:\n                # This might be an executable (e.g. 'bash')\n                libpath = BPF.find_exe(self.library)\n            if libpath is None or len(libpath) == 0:\n                raise Exception(\"unable to find library %s\" % self.library)\n            self.library = libpath\n\n        self.pid = pid\n        self.matched = 0\n        self.trace_functions = {}",
  "def is_kernel_probe(self):\n        return self.type == b\"t\" or (self.type == b\"p\" and self.library == b\"\")",
  "def attach(self):\n        if self.type == b\"p\" and not self.library:\n            for index, function in self.trace_functions.items():\n                self.bpf.attach_kprobe(\n                        event=function,\n                        fn_name=\"trace_count_%d\" % index)\n        elif self.type == b\"p\" and self.library:\n            for index, function in self.trace_functions.items():\n                self.bpf.attach_uprobe(\n                        name=self.library,\n                        sym=function,\n                        fn_name=\"trace_count_%d\" % index,\n                        pid=self.pid or -1)\n        elif self.type == b\"t\":\n            for index, function in self.trace_functions.items():\n                self.bpf.attach_tracepoint(\n                        tp=function,\n                        fn_name=\"trace_count_%d\" % index)\n        elif self.type == b\"u\":\n            pass",
  "def _add_function(self, template, probe_name):\n        new_func = b\"trace_count_%d\" % self.matched\n        text = template.replace(b\"PROBE_FUNCTION\", new_func)\n        text = text.replace(b\"LOCATION\", b\"%d\" % self.matched)\n        self.trace_functions[self.matched] = probe_name\n        self.matched += 1\n        return text",
  "def _generate_functions(self, template):\n        self.usdt = None\n        text = b\"\"\n        if self.type == b\"p\" and not self.library:\n            functions = BPF.get_kprobe_functions(self.pattern)\n            verify_limit(len(functions))\n            for function in functions:\n                text += self._add_function(template, function)\n        elif self.type == b\"p\" and self.library:\n            # uprobes are tricky because the same function may have multiple\n            # addresses, and the same address may be mapped to multiple\n            # functions. We aren't allowed to create more than one uprobe\n            # per address, so track unique addresses and ignore functions that\n            # map to an address that we've already seen. Also ignore functions\n            # that may repeat multiple times with different addresses.\n            addresses, functions = (set(), set())\n            functions_and_addresses = BPF.get_user_functions_and_addresses(\n                                        self.library, self.pattern)\n            verify_limit(len(functions_and_addresses))\n            for function, address in functions_and_addresses:\n                if address in addresses or function in functions:\n                    continue\n                addresses.add(address)\n                functions.add(function)\n                text += self._add_function(template, function)\n        elif self.type == b\"t\":\n            tracepoints = BPF.get_tracepoints(self.pattern)\n            verify_limit(len(tracepoints))\n            for tracepoint in tracepoints:\n                text += self._add_function(template, tracepoint)\n        elif self.type == b\"u\":\n            self.usdt = USDT(path=self.library, pid=self.pid)\n            matches = []\n            for probe in self.usdt.enumerate_probes():\n                if not self.pid and (probe.bin_path != self.library):\n                    continue\n                if re.match(self.pattern, probe.name):\n                    matches.append(probe.name)\n            verify_limit(len(matches))\n            for match in matches:\n                new_func = b\"trace_count_%d\" % self.matched\n                text += self._add_function(template, match)\n                self.usdt.enable_probe(match, new_func)\n            if debug:\n                print(self.usdt.get_text())\n        return text",
  "def load(self):\n        trace_count_text = b\"\"\"\nint PROBE_FUNCTION(void *ctx) {\n    FILTER\n    int loc = LOCATION;\n    u64 *val = counts.lookup(&loc);\n    if (!val) {\n        return 0;   // Should never happen, # of locations is known\n    }\n    (*val)++;\n    return 0;\n}\n        \"\"\"\n        bpf_text = b\"\"\"#include <uapi/linux/ptrace.h>\n\nBPF_ARRAY(counts, u64, NUMLOCATIONS);\n        \"\"\"\n\n        # We really mean the tgid from the kernel's perspective, which is in\n        # the top 32 bits of bpf_get_current_pid_tgid().\n        if self.pid:\n            trace_count_text = trace_count_text.replace(b'FILTER',\n                b\"\"\"u32 pid = bpf_get_current_pid_tgid() >> 32;\n                   if (pid != %d) { return 0; }\"\"\" % self.pid)\n        else:\n            trace_count_text = trace_count_text.replace(b'FILTER', b'')\n\n        bpf_text += self._generate_functions(trace_count_text)\n        bpf_text = bpf_text.replace(b\"NUMLOCATIONS\",\n                                    b\"%d\" % len(self.trace_functions))\n        if debug:\n            print(bpf_text)\n\n        if self.matched == 0:\n            raise Exception(\"No functions matched by pattern %s\" %\n                            self.pattern)\n\n        self.bpf = BPF(text=bpf_text,\n                       usdt_contexts=[self.usdt] if self.usdt else [])\n        self.clear()",
  "def counts(self):\n        return self.bpf[\"counts\"]",
  "def clear(self):\n        counts = self.bpf[\"counts\"]\n        for location, _ in list(self.trace_functions.items()):\n            counts[counts.Key(location)] = counts.Leaf()",
  "def __init__(self):\n        examples = \"\"\"examples:\n    ./funccount 'vfs_*'             # count kernel fns starting with \"vfs\"\n    ./funccount -r '^vfs.*'         # same as above, using regular expressions\n    ./funccount -Ti 5 'vfs_*'       # output every 5 seconds, with timestamps\n    ./funccount -d 10 'vfs_*'       # trace for 10 seconds only\n    ./funccount -p 185 'vfs_*'      # count vfs calls for PID 181 only\n    ./funccount t:sched:sched_fork  # count calls to the sched_fork tracepoint\n    ./funccount -p 185 u:node:gc*   # count all GC USDT probes in node, PID 185\n    ./funccount c:malloc            # count all malloc() calls in libc\n    ./funccount go:os.*             # count all \"os.*\" calls in libgo\n    ./funccount -p 185 go:os.*      # count all \"os.*\" calls in libgo, PID 185\n    ./funccount ./test:read*        # count \"read*\" calls in the ./test binary\n    \"\"\"\n        parser = argparse.ArgumentParser(\n            description=\"Count functions, tracepoints, and USDT probes\",\n            formatter_class=argparse.RawDescriptionHelpFormatter,\n            epilog=examples)\n        parser.add_argument(\"-p\", \"--pid\", type=int,\n            help=\"trace this PID only\")\n        parser.add_argument(\"-i\", \"--interval\",\n            help=\"summary interval, seconds\")\n        parser.add_argument(\"-d\", \"--duration\",\n            help=\"total duration of trace, seconds\")\n        parser.add_argument(\"-T\", \"--timestamp\", action=\"store_true\",\n            help=\"include timestamp on output\")\n        parser.add_argument(\"-r\", \"--regexp\", action=\"store_true\",\n            help=\"use regular expressions. Default is \\\"*\\\" wildcards only.\")\n        parser.add_argument(\"-D\", \"--debug\", action=\"store_true\",\n            help=\"print BPF program before starting (for debugging purposes)\")\n        parser.add_argument(\"pattern\",\n            type=ArgString,\n            help=\"search expression for events\")\n        self.args = parser.parse_args()\n        global debug\n        debug = self.args.debug\n        self.probe = Probe(self.args.pattern, self.args.regexp, self.args.pid)\n        if self.args.duration and not self.args.interval:\n            self.args.interval = self.args.duration\n        if not self.args.interval:\n            self.args.interval = 99999999",
  "def _signal_ignore(signal, frame):\n        print()",
  "def run(self):\n        self.probe.load()\n        self.probe.attach()\n        print(\"Tracing %d functions for \\\"%s\\\"... Hit Ctrl-C to end.\" %\n              (self.probe.matched, bytes(self.args.pattern)))\n        exiting = 0 if self.args.interval else 1\n        seconds = 0\n        while True:\n            try:\n                sleep(int(self.args.interval))\n                seconds += int(self.args.interval)\n            except KeyboardInterrupt:\n                exiting = 1\n                # as cleanup can take many seconds, trap Ctrl-C:\n                signal.signal(signal.SIGINT, Tool._signal_ignore)\n            if self.args.duration and seconds >= int(self.args.duration):\n                exiting = 1\n\n            print()\n            if self.args.timestamp:\n                print(\"%-8s\\n\" % strftime(\"%H:%M:%S\"), end=\"\")\n\n            print(\"%-36s %8s\" % (\"FUNC\", \"COUNT\"))\n            counts = self.probe.counts()\n            for k, v in sorted(counts.items(),\n                               key=lambda counts: counts[1].value):\n                if v.value == 0:\n                    continue\n                print(\"%-36s %8d\" %\n                      (self.probe.trace_functions[k.value], v.value))\n\n            if exiting:\n                print(\"Detaching...\")\n                exit()\n            else:\n                self.probe.clear()",
  "def positive_int(val):\n    try:\n        ival = int(val)\n    except ValueError:\n        raise argparse.ArgumentTypeError(\"must be an integer\")\n\n    if ival < 0:\n        raise argparse.ArgumentTypeError(\"must be positive\")\n    return ival",
  "def positive_nonzero_int(val):\n    ival = positive_int(val)\n    if ival == 0:\n        raise argparse.ArgumentTypeError(\"must be nonzero\")\n    return ival",
  "def stack_id_err(stack_id):\n    # -EFAULT in get_stackid normally means the stack-trace is not availible,\n    # Such as getting kernel stack trace in userspace code\n    return (stack_id < 0) and (stack_id != -errno.EFAULT)",
  "def signal_ignore(signal, frame):\n    print()",
  "class Data(ct.Structure):\n    _fields_ = [\n        (\"ts_us\", ct.c_ulonglong),\n        (\"type\", ct.c_ulonglong),\n        (\"size\", ct.c_ulonglong),\n        (\"offset\", ct.c_ulonglong),\n        (\"delta_us\", ct.c_ulonglong),\n        (\"pid\", ct.c_ulonglong),\n        (\"task\", ct.c_char * TASK_COMM_LEN),\n        (\"file\", ct.c_char * DNAME_INLINE_LEN)\n    ]",
  "def print_event(cpu, data, size):\n    event = ct.cast(data, ct.POINTER(Data)).contents\n\n    type = 'R'\n    if event.type == 1:\n        type = 'W'\n    elif event.type == 2:\n        type = 'O'\n    elif event.type == 3:\n        type = 'S'\n\n    if (csv):\n        print(\"%d,%s,%d,%s,%d,%d,%d,%s\" % (\n            event.ts_us, event.task.decode('utf-8', 'replace'), event.pid,\n            type, event.size, event.offset, event.delta_us,\n            event.file.decode('utf-8', 'replace')))\n        return\n    print(\"%-8s %-14.14s %-6s %1s %-7s %-8d %7.2f %s\" % (strftime(\"%H:%M:%S\"),\n        event.task.decode('utf-8', 'replace'), event.pid, type, event.size,\n        event.offset / 1024, float(event.delta_us) / 1000,\n        event.file.decode('utf-8', 'replace')))",
  "def usage():\n    print(\"USAGE: mysqld_latency PID [min_ms]\")\n    exit()",
  "class Data(ct.Structure):\n    _fields_ = [\n        (\"pid\", ct.c_ulonglong),\n        (\"ts\", ct.c_ulonglong),\n        (\"delta\", ct.c_ulonglong),\n        (\"query\", ct.c_char * QUERY_MAX)\n    ]",
  "def print_event(cpu, data, size):\n    global start\n    event = ct.cast(data, ct.POINTER(Data)).contents\n    if start == 0:\n        start = event.ts\n    print(\"%-14.6f %-6d %8.3f %s\" % (float(event.ts - start) / 1000000000,\n        event.pid, float(event.delta) / 1000000, event.query))",
  "class Data(ct.Structure):\n    _fields_ = [\n        (\"ts\", ct.c_ulonglong),\n        (\"cpu\", ct.c_ulonglong),\n        (\"len\", ct.c_ulonglong)\n    ]",
  "def print_event(cpu, data, size):\n    event = ct.cast(data, ct.POINTER(Data)).contents\n    samples[event.ts] = {}\n    samples[event.ts]['cpu'] = event.cpu\n    samples[event.ts]['len'] = event.len",
  "class ThreadEvent(ct.Structure):\n    _fields_ = [\n        (\"runtime_id\", ct.c_ulonglong),\n        (\"native_id\", ct.c_ulonglong),\n        (\"type\", ct.c_char * 8),\n        (\"name\", ct.c_char * 80),\n        ]",
  "def print_event(cpu, data, size):\n    event = ct.cast(data, ct.POINTER(ThreadEvent)).contents\n    name = event.name\n    if event.type == \"pthread\":\n        name = bpf.sym(event.runtime_id, args.pid, show_module=True)\n        tid = event.native_id\n    else:\n        tid = \"R=%s/N=%s\" % (event.runtime_id, event.native_id)\n    print(\"%-8.3f %-16s %-8s %-30s\" % (\n        time.time() - start_ts, tid, event.type, name))",
  "def enable_probe(probe_name, func_name, read_class, read_method, is_return):\n    global program, trace_template, usdt\n    depth = \"*depth + 1\" if not is_return else \"*depth | (1ULL << 63)\"\n    update = \"++(*depth);\" if not is_return else \"if (*depth) --(*depth);\"\n    filter_class = \"if (!prefix_class(data.clazz)) { return 0; }\" \\\n                   if args.clazz else \"\"\n    filter_method = \"if (!prefix_method(data.method)) { return 0; }\" \\\n                   if args.method else \"\"\n    program += trace_template.replace(\"NAME\", func_name)                \\\n                             .replace(\"READ_CLASS\", read_class)         \\\n                             .replace(\"READ_METHOD\", read_method)       \\\n                             .replace(\"FILTER_CLASS\", filter_class)     \\\n                             .replace(\"FILTER_METHOD\", filter_method)   \\\n                             .replace(\"DEPTH\", depth)                   \\\n                             .replace(\"UPDATE\", update)\n    usdt.enable_probe_or_bail(probe_name, func_name)",
  "class CallEvent(ct.Structure):\n    _fields_ = [\n        (\"depth\", ct.c_ulonglong),\n        (\"pid\", ct.c_ulonglong),\n        (\"clazz\", ct.c_char * 80),\n        (\"method\", ct.c_char * 80)\n        ]",
  "def print_event(cpu, data, size):\n    event = ct.cast(data, ct.POINTER(CallEvent)).contents\n    depth = event.depth & (~(1 << 63))\n    direction = \"<- \" if event.depth & (1 << 63) else \"-> \"\n    print(\"%-3d %-6d %-6d %-8.3f %-40s\" % (cpu, event.pid >> 32,\n        event.pid & 0xFFFFFFFF, time.time() - start_ts,\n        (\"  \" * (depth - 1)) + direction + \\\n            event.clazz.decode('utf-8', 'replace') + \".\" + \\\n            event.method.decode('utf-8', 'replace')))",
  "def get_data():\n    # Will be empty when no language was specified for tracing\n    if args.latency:\n        data = list(map(lambda kv: (kv[0].clazz.decode('utf-8', 'replace') \\\n                                    + \".\" + \\\n                                    kv[0].method.decode('utf-8', 'replace'),\n                                   (kv[1].num_calls, kv[1].total_ns)),\n                   bpf[\"times\"].items()))\n    else:\n        data = list(map(lambda kv: (kv[0].clazz.decode('utf-8', 'replace') \\\n                                    + \".\" + \\\n                                    kv[0].method.decode('utf-8', 'replace'),\n                                   (kv[1].value, 0)),\n                   bpf[\"counts\"].items()))\n\n    if args.syscalls:\n        if args.latency:\n            syscalls = map(lambda kv: (syscall_name(kv[0].value).decode('utf-8', 'replace'),\n                                       (kv[1].num_calls, kv[1].total_ns)),\n                           bpf[\"systimes\"].items())\n            data.extend(syscalls)\n        else:\n            syscalls = map(lambda kv: (syscall_name(kv[0].value).decode('utf-8', 'replace'),\n                                       (kv[1].value, 0)),\n                           bpf[\"syscounts\"].items())\n            data.extend(syscalls)\n\n    return sorted(data, key=lambda kv: kv[1][1 if args.latency else 0])",
  "def clear_data():\n    if args.latency:\n        bpf[\"times\"].clear()\n    else:\n        bpf[\"counts\"].clear()\n\n    if args.syscalls:\n        if args.latency:\n            bpf[\"systimes\"].clear()\n        else:\n            bpf[\"syscounts\"].clear()",
  "class Category(object):\n    THREAD = \"THREAD\"\n    METHOD = \"METHOD\"\n    OBJNEW = \"OBJNEW\"\n    CLOAD = \"CLOAD\"\n    EXCP = \"EXCP\"\n    GC = \"GC\"",
  "class Probe(object):\n    def __init__(self, language, procnames, events):\n        \"\"\"\n        Initialize a new probe object with a specific language, set of process\n        names to monitor for that language, and a dictionary of events and\n        categories. The dictionary is a mapping of USDT probe names (such as\n        'gc__start') to event categories supported by this tool -- from the\n        Category class.\n        \"\"\"\n        self.language = language\n        self.procnames = procnames\n        self.events = events\n\n    def _find_targets(self):\n        \"\"\"Find pids where the comm is one of the specified list\"\"\"\n        self.targets = {}\n        all_pids = [int(pid) for pid in os.listdir('/proc') if pid.isdigit()]\n        for pid in all_pids:\n            try:\n                comm = open('/proc/%d/comm' % pid).read().strip()\n                if comm in self.procnames:\n                    cmdline = open('/proc/%d/cmdline' % pid).read()\n                    self.targets[pid] = cmdline.replace('\\0', ' ')\n            except IOError:\n                continue    # process may already have terminated\n\n    def _enable_probes(self):\n        self.usdts = []\n        for pid in self.targets:\n            try:\n                usdt = USDT(pid=pid)\n            except USDTException:\n                # avoid race condition on pid going away.\n                print(\"failed to instrument %d\" % pid, file=sys.stderr)\n                continue\n            for event in self.events:\n                try:\n                    usdt.enable_probe(event, \"%s_%s\" % (self.language, event))\n                except Exception:\n                    # This process might not have a recent version of the USDT\n                    # probes enabled, or might have been compiled without USDT\n                    # probes at all. The process could even have been shut down\n                    # and the pid been recycled. We have to gracefully handle\n                    # the possibility that we can't attach probes to it at all.\n                    pass\n            self.usdts.append(usdt)\n\n    def _generate_tables(self):\n        text = \"\"\"\nBPF_HASH(%s_%s_counts, u32, u64);   // pid to event count\n        \"\"\"\n        return str.join('', [text % (self.language, event)\n                             for event in self.events])\n\n    def _generate_functions(self):\n        text = \"\"\"\nint %s_%s(void *ctx) {\n    u64 *valp, zero = 0;\n    u32 tgid = bpf_get_current_pid_tgid() >> 32;\n    valp = %s_%s_counts.lookup_or_init(&tgid, &zero);\n    ++(*valp);\n    return 0;\n}\n        \"\"\"\n        lang = self.language\n        return str.join('', [text % (lang, event, lang, event)\n                             for event in self.events])\n\n    def get_program(self):\n        self._find_targets()\n        self._enable_probes()\n        return self._generate_tables() + self._generate_functions()\n\n    def get_usdts(self):\n        return self.usdts\n\n    def get_counts(self, bpf):\n        \"\"\"Return a map of event counts per process\"\"\"\n        event_dict = dict([(category, 0) for category in self.events.values()])\n        result = dict([(pid, event_dict.copy()) for pid in self.targets])\n        for event, category in self.events.items():\n            counts = bpf[\"%s_%s_counts\" % (self.language, event)]\n            for pid, count in counts.items():\n                if pid.value not in result:\n                    print(\"result was not found for %d\" % pid.value, file=sys.stderr)\n                    continue\n                result[pid.value][category] = count.value\n            counts.clear()\n        return result\n\n    def cleanup(self):\n        self.usdts = None",
  "class Tool(object):\n    def _parse_args(self):\n        examples = \"\"\"examples:\n  ./ustat              # stats for all languages, 1 second refresh\n  ./ustat -C           # don't clear the screen\n  ./ustat -l java      # Java processes only\n  ./ustat 5            # 5 second summaries\n  ./ustat 5 10         # 5 second summaries, 10 times only\n        \"\"\"\n        parser = argparse.ArgumentParser(\n            description=\"Activity stats from high-level languages.\",\n            formatter_class=argparse.RawDescriptionHelpFormatter,\n            epilog=examples)\n        parser.add_argument(\"-l\", \"--language\",\n            choices=[\"java\", \"node\", \"perl\", \"php\", \"python\", \"ruby\", \"tcl\"],\n            help=\"language to trace (default: all languages)\")\n        parser.add_argument(\"-C\", \"--noclear\", action=\"store_true\",\n            help=\"don't clear the screen\")\n        parser.add_argument(\"-S\", \"--sort\",\n            choices=[cat.lower() for cat in dir(Category) if cat.isupper()],\n            help=\"sort by this field (descending order)\")\n        parser.add_argument(\"-r\", \"--maxrows\", default=20, type=int,\n            help=\"maximum rows to print, default 20\")\n        parser.add_argument(\"-d\", \"--debug\", action=\"store_true\",\n            help=\"Print the resulting BPF program (for debugging purposes)\")\n        parser.add_argument(\"interval\", nargs=\"?\", default=1, type=int,\n            help=\"output interval, in seconds\")\n        parser.add_argument(\"count\", nargs=\"?\", default=99999999, type=int,\n            help=\"number of outputs\")\n        parser.add_argument(\"--ebpf\", action=\"store_true\",\n            help=argparse.SUPPRESS)\n        self.args = parser.parse_args()\n\n    def _create_probes(self):\n        probes_by_lang = {\n                \"java\": Probe(\"java\", [\"java\"], {\n                    \"gc__begin\": Category.GC,\n                    \"mem__pool__gc__begin\": Category.GC,\n                    \"thread__start\": Category.THREAD,\n                    \"class__loaded\": Category.CLOAD,\n                    \"object__alloc\": Category.OBJNEW,\n                    \"method__entry\": Category.METHOD,\n                    \"ExceptionOccurred__entry\": Category.EXCP\n                    }),\n                \"node\": Probe(\"node\", [\"node\"], {\n                    \"gc__start\": Category.GC\n                    }),\n                \"perl\": Probe(\"perl\", [\"perl\"], {\n                    \"sub__entry\": Category.METHOD\n                    }),\n                \"php\": Probe(\"php\", [\"php\"], {\n                    \"function__entry\": Category.METHOD,\n                    \"compile__file__entry\": Category.CLOAD,\n                    \"exception__thrown\": Category.EXCP\n                    }),\n                \"python\": Probe(\"python\", [\"python\"], {\n                    \"function__entry\": Category.METHOD,\n                    \"gc__start\": Category.GC\n                    }),\n                \"ruby\": Probe(\"ruby\", [\"ruby\", \"irb\"], {\n                    \"method__entry\": Category.METHOD,\n                    \"cmethod__entry\": Category.METHOD,\n                    \"gc__mark__begin\": Category.GC,\n                    \"gc__sweep__begin\": Category.GC,\n                    \"object__create\": Category.OBJNEW,\n                    \"hash__create\": Category.OBJNEW,\n                    \"string__create\": Category.OBJNEW,\n                    \"array__create\": Category.OBJNEW,\n                    \"require__entry\": Category.CLOAD,\n                    \"load__entry\": Category.CLOAD,\n                    \"raise\": Category.EXCP\n                    }),\n                \"tcl\": Probe(\"tcl\", [\"tclsh\", \"wish\"], {\n                    \"proc__entry\": Category.METHOD,\n                    \"obj__create\": Category.OBJNEW\n                    }),\n                }\n\n        if self.args.language:\n            self.probes = [probes_by_lang[self.args.language]]\n        else:\n            self.probes = probes_by_lang.values()\n\n    def _attach_probes(self):\n        program = str.join('\\n', [p.get_program() for p in self.probes])\n        if self.args.debug or self.args.ebpf:\n            print(program)\n            if self.args.ebpf:\n                exit()\n            for probe in self.probes:\n                print(\"Attached to %s processes:\" % probe.language,\n                        str.join(', ', map(str, probe.targets)))\n        self.bpf = BPF(text=program)\n        usdts = [usdt for probe in self.probes for usdt in probe.get_usdts()]\n        # Filter out duplicates when we have multiple processes with the same\n        # uprobe. We are attaching to these probes manually instead of using\n        # the USDT support from the bcc module, because the USDT class attaches\n        # to each uprobe with a specific pid. When there is more than one\n        # process from some language, we end up attaching more than once to the\n        # same uprobe (albeit with different pids), which is not allowed.\n        # Instead, we use a global attach (with pid=-1).\n        uprobes = set([(path, func, addr) for usdt in usdts\n                       for (path, func, addr, _)\n                       in usdt.enumerate_active_probes()])\n        for (path, func, addr) in uprobes:\n            self.bpf.attach_uprobe(name=path, fn_name=func, addr=addr, pid=-1)\n\n    def _detach_probes(self):\n        for probe in self.probes:\n            probe.cleanup()     # Cleans up USDT contexts\n        self.bpf.cleanup()      # Cleans up all attached probes\n        self.bpf = None\n\n    def _loop_iter(self):\n        self._attach_probes()\n        try:\n            sleep(self.args.interval)\n        except KeyboardInterrupt:\n            self.exiting = True\n\n        if not self.args.noclear:\n            call(\"clear\")\n        else:\n            print()\n        with open(\"/proc/loadavg\") as stats:\n            print(\"%-8s loadavg: %s\" % (strftime(\"%H:%M:%S\"), stats.read()))\n        print(\"%-6s %-20s %-10s %-6s %-10s %-8s %-6s %-6s\" % (\n            \"PID\", \"CMDLINE\", \"METHOD/s\", \"GC/s\", \"OBJNEW/s\",\n            \"CLOAD/s\", \"EXC/s\", \"THR/s\"))\n\n        line = 0\n        counts = {}\n        targets = {}\n        for probe in self.probes:\n            counts.update(probe.get_counts(self.bpf))\n            targets.update(probe.targets)\n        if self.args.sort:\n            sort_field = self.args.sort.upper()\n            counts = sorted(counts.items(),\n                            key=lambda kv: -kv[1].get(sort_field, 0))\n        else:\n            counts = sorted(counts.items(), key=lambda kv: kv[0])\n        for pid, stats in counts:\n            print(\"%-6d %-20s %-10d %-6d %-10d %-8d %-6d %-6d\" % (\n                  pid, targets[pid][:20],\n                  stats.get(Category.METHOD, 0) / self.args.interval,\n                  stats.get(Category.GC, 0) / self.args.interval,\n                  stats.get(Category.OBJNEW, 0) / self.args.interval,\n                  stats.get(Category.CLOAD, 0) / self.args.interval,\n                  stats.get(Category.EXCP, 0) / self.args.interval,\n                  stats.get(Category.THREAD, 0) / self.args.interval\n                  ))\n            line += 1\n            if line >= self.args.maxrows:\n                break\n        self._detach_probes()\n\n    def run(self):\n        self._parse_args()\n        self._create_probes()\n        print('Tracing... Output every %d secs. Hit Ctrl-C to end' %\n              self.args.interval)\n        countdown = self.args.count\n        self.exiting = False\n        while True:\n            self._loop_iter()\n            countdown -= 1\n            if self.exiting or countdown == 0:\n                print(\"Detaching...\")\n                exit()",
  "def __init__(self, language, procnames, events):\n        \"\"\"\n        Initialize a new probe object with a specific language, set of process\n        names to monitor for that language, and a dictionary of events and\n        categories. The dictionary is a mapping of USDT probe names (such as\n        'gc__start') to event categories supported by this tool -- from the\n        Category class.\n        \"\"\"\n        self.language = language\n        self.procnames = procnames\n        self.events = events",
  "def _find_targets(self):\n        \"\"\"Find pids where the comm is one of the specified list\"\"\"\n        self.targets = {}\n        all_pids = [int(pid) for pid in os.listdir('/proc') if pid.isdigit()]\n        for pid in all_pids:\n            try:\n                comm = open('/proc/%d/comm' % pid).read().strip()\n                if comm in self.procnames:\n                    cmdline = open('/proc/%d/cmdline' % pid).read()\n                    self.targets[pid] = cmdline.replace('\\0', ' ')\n            except IOError:\n                continue",
  "def _enable_probes(self):\n        self.usdts = []\n        for pid in self.targets:\n            try:\n                usdt = USDT(pid=pid)\n            except USDTException:\n                # avoid race condition on pid going away.\n                print(\"failed to instrument %d\" % pid, file=sys.stderr)\n                continue\n            for event in self.events:\n                try:\n                    usdt.enable_probe(event, \"%s_%s\" % (self.language, event))\n                except Exception:\n                    # This process might not have a recent version of the USDT\n                    # probes enabled, or might have been compiled without USDT\n                    # probes at all. The process could even have been shut down\n                    # and the pid been recycled. We have to gracefully handle\n                    # the possibility that we can't attach probes to it at all.\n                    pass\n            self.usdts.append(usdt)",
  "def _generate_tables(self):\n        text = \"\"\"\nBPF_HASH(%s_%s_counts, u32, u64);   // pid to event count\n        \"\"\"\n        return str.join('', [text % (self.language, event)\n                             for event in self.events])",
  "def _generate_functions(self):\n        text = \"\"\"\nint %s_%s(void *ctx) {\n    u64 *valp, zero = 0;\n    u32 tgid = bpf_get_current_pid_tgid() >> 32;\n    valp = %s_%s_counts.lookup_or_init(&tgid, &zero);\n    ++(*valp);\n    return 0;\n}\n        \"\"\"\n        lang = self.language\n        return str.join('', [text % (lang, event, lang, event)\n                             for event in self.events])",
  "def get_program(self):\n        self._find_targets()\n        self._enable_probes()\n        return self._generate_tables() + self._generate_functions()",
  "def get_usdts(self):\n        return self.usdts",
  "def get_counts(self, bpf):\n        \"\"\"Return a map of event counts per process\"\"\"\n        event_dict = dict([(category, 0) for category in self.events.values()])\n        result = dict([(pid, event_dict.copy()) for pid in self.targets])\n        for event, category in self.events.items():\n            counts = bpf[\"%s_%s_counts\" % (self.language, event)]\n            for pid, count in counts.items():\n                if pid.value not in result:\n                    print(\"result was not found for %d\" % pid.value, file=sys.stderr)\n                    continue\n                result[pid.value][category] = count.value\n            counts.clear()\n        return result",
  "def cleanup(self):\n        self.usdts = None",
  "def _parse_args(self):\n        examples = \"\"\"examples:\n  ./ustat              # stats for all languages, 1 second refresh\n  ./ustat -C           # don't clear the screen\n  ./ustat -l java      # Java processes only\n  ./ustat 5            # 5 second summaries\n  ./ustat 5 10         # 5 second summaries, 10 times only\n        \"\"\"\n        parser = argparse.ArgumentParser(\n            description=\"Activity stats from high-level languages.\",\n            formatter_class=argparse.RawDescriptionHelpFormatter,\n            epilog=examples)\n        parser.add_argument(\"-l\", \"--language\",\n            choices=[\"java\", \"node\", \"perl\", \"php\", \"python\", \"ruby\", \"tcl\"],\n            help=\"language to trace (default: all languages)\")\n        parser.add_argument(\"-C\", \"--noclear\", action=\"store_true\",\n            help=\"don't clear the screen\")\n        parser.add_argument(\"-S\", \"--sort\",\n            choices=[cat.lower() for cat in dir(Category) if cat.isupper()],\n            help=\"sort by this field (descending order)\")\n        parser.add_argument(\"-r\", \"--maxrows\", default=20, type=int,\n            help=\"maximum rows to print, default 20\")\n        parser.add_argument(\"-d\", \"--debug\", action=\"store_true\",\n            help=\"Print the resulting BPF program (for debugging purposes)\")\n        parser.add_argument(\"interval\", nargs=\"?\", default=1, type=int,\n            help=\"output interval, in seconds\")\n        parser.add_argument(\"count\", nargs=\"?\", default=99999999, type=int,\n            help=\"number of outputs\")\n        parser.add_argument(\"--ebpf\", action=\"store_true\",\n            help=argparse.SUPPRESS)\n        self.args = parser.parse_args()",
  "def _create_probes(self):\n        probes_by_lang = {\n                \"java\": Probe(\"java\", [\"java\"], {\n                    \"gc__begin\": Category.GC,\n                    \"mem__pool__gc__begin\": Category.GC,\n                    \"thread__start\": Category.THREAD,\n                    \"class__loaded\": Category.CLOAD,\n                    \"object__alloc\": Category.OBJNEW,\n                    \"method__entry\": Category.METHOD,\n                    \"ExceptionOccurred__entry\": Category.EXCP\n                    }),\n                \"node\": Probe(\"node\", [\"node\"], {\n                    \"gc__start\": Category.GC\n                    }),\n                \"perl\": Probe(\"perl\", [\"perl\"], {\n                    \"sub__entry\": Category.METHOD\n                    }),\n                \"php\": Probe(\"php\", [\"php\"], {\n                    \"function__entry\": Category.METHOD,\n                    \"compile__file__entry\": Category.CLOAD,\n                    \"exception__thrown\": Category.EXCP\n                    }),\n                \"python\": Probe(\"python\", [\"python\"], {\n                    \"function__entry\": Category.METHOD,\n                    \"gc__start\": Category.GC\n                    }),\n                \"ruby\": Probe(\"ruby\", [\"ruby\", \"irb\"], {\n                    \"method__entry\": Category.METHOD,\n                    \"cmethod__entry\": Category.METHOD,\n                    \"gc__mark__begin\": Category.GC,\n                    \"gc__sweep__begin\": Category.GC,\n                    \"object__create\": Category.OBJNEW,\n                    \"hash__create\": Category.OBJNEW,\n                    \"string__create\": Category.OBJNEW,\n                    \"array__create\": Category.OBJNEW,\n                    \"require__entry\": Category.CLOAD,\n                    \"load__entry\": Category.CLOAD,\n                    \"raise\": Category.EXCP\n                    }),\n                \"tcl\": Probe(\"tcl\", [\"tclsh\", \"wish\"], {\n                    \"proc__entry\": Category.METHOD,\n                    \"obj__create\": Category.OBJNEW\n                    }),\n                }\n\n        if self.args.language:\n            self.probes = [probes_by_lang[self.args.language]]\n        else:\n            self.probes = probes_by_lang.values()",
  "def _attach_probes(self):\n        program = str.join('\\n', [p.get_program() for p in self.probes])\n        if self.args.debug or self.args.ebpf:\n            print(program)\n            if self.args.ebpf:\n                exit()\n            for probe in self.probes:\n                print(\"Attached to %s processes:\" % probe.language,\n                        str.join(', ', map(str, probe.targets)))\n        self.bpf = BPF(text=program)\n        usdts = [usdt for probe in self.probes for usdt in probe.get_usdts()]\n        # Filter out duplicates when we have multiple processes with the same\n        # uprobe. We are attaching to these probes manually instead of using\n        # the USDT support from the bcc module, because the USDT class attaches\n        # to each uprobe with a specific pid. When there is more than one\n        # process from some language, we end up attaching more than once to the\n        # same uprobe (albeit with different pids), which is not allowed.\n        # Instead, we use a global attach (with pid=-1).\n        uprobes = set([(path, func, addr) for usdt in usdts\n                       for (path, func, addr, _)\n                       in usdt.enumerate_active_probes()])\n        for (path, func, addr) in uprobes:\n            self.bpf.attach_uprobe(name=path, fn_name=func, addr=addr, pid=-1)",
  "def _detach_probes(self):\n        for probe in self.probes:\n            probe.cleanup()     # Cleans up USDT contexts\n        self.bpf.cleanup()      # Cleans up all attached probes\n        self.bpf = None",
  "def _loop_iter(self):\n        self._attach_probes()\n        try:\n            sleep(self.args.interval)\n        except KeyboardInterrupt:\n            self.exiting = True\n\n        if not self.args.noclear:\n            call(\"clear\")\n        else:\n            print()\n        with open(\"/proc/loadavg\") as stats:\n            print(\"%-8s loadavg: %s\" % (strftime(\"%H:%M:%S\"), stats.read()))\n        print(\"%-6s %-20s %-10s %-6s %-10s %-8s %-6s %-6s\" % (\n            \"PID\", \"CMDLINE\", \"METHOD/s\", \"GC/s\", \"OBJNEW/s\",\n            \"CLOAD/s\", \"EXC/s\", \"THR/s\"))\n\n        line = 0\n        counts = {}\n        targets = {}\n        for probe in self.probes:\n            counts.update(probe.get_counts(self.bpf))\n            targets.update(probe.targets)\n        if self.args.sort:\n            sort_field = self.args.sort.upper()\n            counts = sorted(counts.items(),\n                            key=lambda kv: -kv[1].get(sort_field, 0))\n        else:\n            counts = sorted(counts.items(), key=lambda kv: kv[0])\n        for pid, stats in counts:\n            print(\"%-6d %-20s %-10d %-6d %-10d %-8d %-6d %-6d\" % (\n                  pid, targets[pid][:20],\n                  stats.get(Category.METHOD, 0) / self.args.interval,\n                  stats.get(Category.GC, 0) / self.args.interval,\n                  stats.get(Category.OBJNEW, 0) / self.args.interval,\n                  stats.get(Category.CLOAD, 0) / self.args.interval,\n                  stats.get(Category.EXCP, 0) / self.args.interval,\n                  stats.get(Category.THREAD, 0) / self.args.interval\n                  ))\n            line += 1\n            if line >= self.args.maxrows:\n                break\n        self._detach_probes()",
  "def run(self):\n        self._parse_args()\n        self._create_probes()\n        print('Tracing... Output every %d secs. Hit Ctrl-C to end' %\n              self.args.interval)\n        countdown = self.args.count\n        self.exiting = False\n        while True:\n            self._loop_iter()\n            countdown -= 1\n            if self.exiting or countdown == 0:\n                print(\"Detaching...\")\n                exit()",
  "class Probe(object):\n    def __init__(self, begin, end, begin_save, end_save, formatter):\n        self.begin = begin\n        self.end = end\n        self.begin_save = begin_save\n        self.end_save = end_save\n        self.formatter = formatter\n\n    def generate(self):\n        text = \"\"\"\nint trace_%s(struct pt_regs *ctx) {\n    u64 pid = bpf_get_current_pid_tgid();\n    struct entry_t e = {};\n    e.start_ns = bpf_ktime_get_ns();\n    %s\n    entry.update(&pid, &e);\n    return 0;\n}\nint trace_%s(struct pt_regs *ctx) {\n    u64 elapsed;\n    struct entry_t *e;\n    struct gc_event_t event = {};\n    u64 pid = bpf_get_current_pid_tgid();\n    e = entry.lookup(&pid);\n    if (!e) {\n        return 0;   // missed the entry event on this thread\n    }\n    elapsed = bpf_ktime_get_ns() - e->start_ns;\n    if (elapsed < %d) {\n        return 0;\n    }\n    event.elapsed_ns = elapsed;\n    %s\n    gcs.perf_submit(ctx, &event, sizeof(event));\n    return 0;\n}\n        \"\"\" % (self.begin, self.begin_save, self.end,\n               args.minimum * 1000000, self.end_save)\n        return text\n\n    def attach(self):\n        usdt.enable_probe_or_bail(self.begin, \"trace_%s\" % self.begin)\n        usdt.enable_probe_or_bail(self.end, \"trace_%s\" % self.end)\n\n    def format(self, data):\n        return self.formatter(data)",
  "class GCEvent(ct.Structure):\n    _fields_ = [\n        (\"probe_index\", ct.c_ulonglong),\n        (\"elapsed_ns\", ct.c_ulonglong),\n        (\"field1\", ct.c_ulonglong),\n        (\"field2\", ct.c_ulonglong),\n        (\"field3\", ct.c_ulonglong),\n        (\"field4\", ct.c_ulonglong),\n        (\"string1\", ct.c_char * 32),\n        (\"string2\", ct.c_char * 32)\n        ]",
  "def print_event(cpu, data, size):\n    event = ct.cast(data, ct.POINTER(GCEvent)).contents\n    elapsed = event.elapsed_ns / 1000000 if args.milliseconds else \\\n              event.elapsed_ns / 1000\n    description = probes[event.probe_index].format(event)\n    if args.filter and args.filter not in description:\n        return\n    print(\"%-8.3f %-8.2f %s\" % (time.time() - start_ts, elapsed, description))",
  "def __init__(self, begin, end, begin_save, end_save, formatter):\n        self.begin = begin\n        self.end = end\n        self.begin_save = begin_save\n        self.end_save = end_save\n        self.formatter = formatter",
  "def generate(self):\n        text = \"\"\"\nint trace_%s(struct pt_regs *ctx) {\n    u64 pid = bpf_get_current_pid_tgid();\n    struct entry_t e = {};\n    e.start_ns = bpf_ktime_get_ns();\n    %s\n    entry.update(&pid, &e);\n    return 0;\n}\nint trace_%s(struct pt_regs *ctx) {\n    u64 elapsed;\n    struct entry_t *e;\n    struct gc_event_t event = {};\n    u64 pid = bpf_get_current_pid_tgid();\n    e = entry.lookup(&pid);\n    if (!e) {\n        return 0;   // missed the entry event on this thread\n    }\n    elapsed = bpf_ktime_get_ns() - e->start_ns;\n    if (elapsed < %d) {\n        return 0;\n    }\n    event.elapsed_ns = elapsed;\n    %s\n    gcs.perf_submit(ctx, &event, sizeof(event));\n    return 0;\n}\n        \"\"\" % (self.begin, self.begin_save, self.end,\n               args.minimum * 1000000, self.end_save)\n        return text",
  "def attach(self):\n        usdt.enable_probe_or_bail(self.begin, \"trace_%s\" % self.begin)\n        usdt.enable_probe_or_bail(self.end, \"trace_%s\" % self.end)",
  "def format(self, data):\n        return self.formatter(data)",
  "def formatter(e):\n        \"%s %s used=%d->%d max=%d->%d\" % \\\n            (e.string1, e.string2, e.field1, e.field3, e.field2, e.field4)",
  "def formatter(event):\n        \"gen %d GC collected %d objects\" % \\\n            (event.field1, event.field2)",
  "def signal_ignore(signal, frame):\n    print()",
  "def decode_stack(bpf, pid, info):\n        stack = \"\"\n        if info.num_frames <= 0:\n                return \"???\"\n        for i in range(0, info.num_frames):\n                addr = info.callstack[i]\n                stack += \" %s ;\" % bpf.sym(addr, pid, show_offset=True)\n        return stack",
  "def run_command_get_output(command):\n        p = subprocess.Popen(command.split(),\n                stdout=subprocess.PIPE, stderr=subprocess.STDOUT)\n        return iter(p.stdout.readline, b'')",
  "def run_command_get_pid(command):\n        p = subprocess.Popen(command.split())\n        return p.pid",
  "def print_outstanding():\n        stacks = {}\n        print(\"[%s] Top %d stacks with outstanding allocations:\" %\n              (datetime.now().strftime(\"%H:%M:%S\"), top_stacks))\n        allocs = bpf_program.get_table(\"allocs\")\n        for address, info in sorted(allocs.items(), key=lambda a: a[1].size):\n                if BPF.monotonic_time() - min_age_ns < info.timestamp_ns:\n                        continue\n                stack = decode_stack(bpf_program, pid, info)\n                if stack in stacks:\n                        stacks[stack] = (stacks[stack][0] + 1,\n                                         stacks[stack][1] + info.size)\n                else:\n                        stacks[stack] = (1, info.size)\n                if args.show_allocs:\n                        print(\"\\taddr = %x size = %s\" %\n                              (address.value, info.size))\n        to_show = sorted(stacks.items(), key=lambda s: s[1][1])[-top_stacks:]\n        for stack, (count, size) in to_show:\n                print(\"\\t%d bytes in %d allocations from stack\\n\\t\\t%s\" %\n                      (size, count, stack.replace(\";\", \"\\n\\t\\t\")))",
  "class Data(ct.Structure):\n    _fields_ = [\n        (\"fpid\", ct.c_ulonglong),\n        (\"tpid\", ct.c_ulonglong),\n        (\"pages\", ct.c_ulonglong),\n        (\"fcomm\", ct.c_char * TASK_COMM_LEN),\n        (\"tcomm\", ct.c_char * TASK_COMM_LEN)\n    ]",
  "def print_event(cpu, data, size):\n    event = ct.cast(data, ct.POINTER(Data)).contents\n    with open(loadavg) as stats:\n        avgline = stats.read().rstrip()\n    print((\"%s Triggered by PID %d (\\\"%s\\\"), OOM kill of PID %d (\\\"%s\\\")\"\n        \", %d pages, loadavg: %s\") % (strftime(\"%H:%M:%S\"), event.fpid,\n        event.fcomm.decode('utf-8', 'replace'), event.tpid,\n        event.tcomm.decode('utf-8', 'replace'), event.pages, avgline))",
  "def signal_ignore(signal, frame):\n    print()",
  "def signal_ignore(signal, frame):\n    print()",
  "def print_frame(addr):\n    print(\"  \", end=\"\")\n    if verbose:\n        print(\"%-16x \" % addr, end=\"\")\n    print(b.ksym(addr, show_offset=offset))",
  "def inet_ntoa(addr):\n    dq = ''\n    for i in range(0, 4):\n        dq = dq + str(addr & 0xff)\n        if (i != 3):\n            dq = dq + '.'\n        addr = addr >> 8\n    return dq",
  "def inet_ntoa(addr):\n    dq = ''\n    for i in range(0, 4):\n        dq = dq + str(addr & 0xff)\n        if (i != 3):\n            dq = dq + '.'\n        addr = addr >> 8\n    return dq",
  "def positive_int(val):\n    try:\n        ival = int(val)\n    except ValueError:\n        raise argparse.ArgumentTypeError(\"must be an integer\")\n\n    if ival < 0:\n        raise argparse.ArgumentTypeError(\"must be positive\")\n    return ival",
  "def positive_nonzero_int(val):\n    ival = positive_int(val)\n    if ival == 0:\n        raise argparse.ArgumentTypeError(\"must be nonzero\")\n    return ival",
  "def signal_ignore(signal, frame):\n    print()",
  "def aksym(addr):\n    if args.annotations:\n        return b.ksym(addr) + \"_[k]\"\n    else:\n        return b.ksym(addr)",
  "def signal_ignore(signal, frame):\n    print()"
]