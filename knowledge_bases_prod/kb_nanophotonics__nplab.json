[
  "class TextDisplay(HasTraits):\n    string =  String()\n\n    view= View( Item('string',show_label=False, springy=True, style='custom' ))",
  "class CaptureThread(Thread):\n    def run(self):\n        self.display.string = 'Camera started\\n' + self.display.string\n        n_img = 0\n        while not self.wants_abort:\n            sleep(.5)\n            n_img += 1\n            self.display.string += '%d image captured\\n' % n_img\n        self.display.string += 'Camera stopped\\n'",
  "class Camera(HasTraits):\n    start_stop_capture = Button()\n    display = Instance(TextDisplay)\n    capture_thread = Instance(CaptureThread)\n\n    view = View( Item('start_stop_capture', show_label=False ))\n\n    def _start_stop_capture_fired(self):\n        if self.capture_thread and self.capture_thread.isAlive():\n            self.capture_thread.wants_abort = True\n        else:\n            self.capture_thread = CaptureThread()\n            self.capture_thread.wants_abort = False\n            self.capture_thread.display = self.display\n            self.capture_thread.start()",
  "class MainWindow(HasTraits):\n    display = Instance(TextDisplay, ())\n\n    camera = Instance(Camera)\n\n    def _camera_default(self):\n        return Camera(display=self.display)\n\n    view = View('display', 'camera', style=\"custom\", resizable=True)",
  "def run(self):\n        self.display.string = 'Camera started\\n' + self.display.string\n        n_img = 0\n        while not self.wants_abort:\n            sleep(.5)\n            n_img += 1\n            self.display.string += '%d image captured\\n' % n_img\n        self.display.string += 'Camera stopped\\n'",
  "def _start_stop_capture_fired(self):\n        if self.capture_thread and self.capture_thread.isAlive():\n            self.capture_thread.wants_abort = True\n        else:\n            self.capture_thread = CaptureThread()\n            self.capture_thread.wants_abort = False\n            self.capture_thread.display = self.display\n            self.capture_thread.start()",
  "def _camera_default(self):\n        return Camera(display=self.display)",
  "def attributes_from_dict(group_or_dataset, dict_of_attributes):\n    \"\"\"Update the metadata of an HDF5 object with a dictionary.\"\"\"\n    attrs = group_or_dataset.attrs\n    for key, value in list(dict_of_attributes.items()):\n        if value is not None:\n            try:\n                attrs[key] = value\n            except TypeError:\n                print(\"Warning, metadata {0}='{1}' can't be saved in HDF5.  Saving with str()\".format(key, value))\n                attrs[key] = str(value)",
  "def h5_item_number(group_or_dataset):\n    \"\"\"Returns the number at the end of a group/dataset name, or None.\"\"\"\n    m = re.search(r\"(\\d+)$\", group_or_dataset.name)  # match numbers at the end of the name\n    return int(m.groups()[0]) if m else None",
  "def get_data_dir(destination='local', rel_path='Desktop/Data'):\n    \"\"\"Creates a path to a specified data storage location.\"\"\"\n    if destination == 'local':\n        home_dir = os.path.expanduser('~')\n        path = os.path.join(home_dir, rel_path)\n    elif destination == 'server':\n        if sys.platform == 'windows':\n            network_dir = 'R:'\n        elif sys.platform == 'darwin':\n            network_dir = '/Volumes/NPHome'\n        path = os.path.join(network_dir, rel_path)\n    if not os.path.exists(path):\n        os.makedirs(path)\n    return path",
  "def get_filename(data_dir, basename='data', fformat='.h5'):\n    \"\"\"Creates a dated directory path and returns a file name to open a file there.\"\"\"\n    date = datetime.datetime.now()\n    output_dir = os.path.join(data_dir, str(date.year),\n                              '{:02d}'.format(date.month)+'. '+date.strftime('%b'),\n                              '{:02d}'.format(date.day))\n    if not os.path.exists(output_dir): os.makedirs(output_dir)\n    file_path = os.path.join(output_dir,basename+fformat)\n    return file_path",
  "def get_unique_filename(data_dir, basename='data', fformat='.h5'):\n    \"\"\"Creates a dated directory path and returns a unique file name to open a file there.\"\"\"\n    date = datetime.datetime.now()\n    output_dir = os.path.join(data_dir, str(date.year),\n                              '{:02d}'.format(date.month)+'. '+date.strftime('%b'),\n                              '{:02d}'.format(date.day), basename+'s')\n    if not os.path.exists(output_dir): os.makedirs(output_dir)\n    unique_id = 1\n    file_path = os.path.join(output_dir,basename+'_'+str(unique_id)+fformat)\n    while os.path.exists(file_path):\n        unique_id += 1\n        file_path = os.path.join(output_dir,basename+'_'+str(unique_id)+fformat)\n    return file_path",
  "def get_file(destination='local', rel_path='Desktop/Data',\n             basename='data', fformat='.h5', set_current=True):\n    \"\"\"Convenience function to quickly get a current DataFile object.\"\"\"\n    data_dir = get_data_dir(destination, rel_path)\n    fname = get_filename(data_dir, basename, fformat)\n    f = DataFile(fname)\n    if set_current:\n        f.make_current()\n    return f",
  "def transpose_datafile(data_set):\n    ''' A function that opens a datafile, transposes and resaves'''\n    parent = data_set.parent\n    transposed_datafile = np.copy(data_set[...].T)\n    file_name = data_set.name.split('/')[-1]\n    del parent[file_name]\n    parent.create_dataset(file_name,data = transposed_datafile)",
  "def wrap_h5py_item(item):\n    \"\"\"Wrap an h5py object: groups are returned as Group objects, datasets are unchanged.\"\"\"\n    if isinstance(item, h5py.Group):\n        # wrap groups before returning them (this makes our group objects rather than h5py.Group)\n        return Group(item.id)\n    else:\n        return item",
  "def ensure_str(str_or_bytes):\n    if type(str_or_bytes) in (bytes, np.bytes_):\n        return str_or_bytes.decode()\n    return str(str_or_bytes)",
  "def sort_by_timestamp(hdf5_group):\n    \"\"\"a quick function for sorting hdf5 groups (or files or dictionarys...) by timestamp \"\"\"\n    keys = list(hdf5_group.keys())\n    try:\n        time_stamps = []\n        for value in list(hdf5_group.values()):\n\n            time_stamp_str = ensure_str(value.attrs['creation_timestamp'])\n            try:\n                time_stamp_float = datetime.datetime.strptime(time_stamp_str,\"%Y-%m-%dT%H:%M:%S.%f\")\n            except ValueError:\n                time_stamp_str =  time_stamp_str+'.0'\n                time_stamp_float = datetime.datetime.strptime(time_stamp_str,\"%Y-%m-%dT%H:%M:%S.%f\")\n            time_stamps.append(time_stamp_float)\n        keys = np.array(keys)[np.argsort(time_stamps)]\n    except KeyError:\n        keys.sort(key=lambda n: n.split('_')[-1] if '_' in n else n)\n    items_lists = [(key, hdf5_group[key]) for key in keys]\n    return items_lists",
  "class Group(h5py.Group, ShowGUIMixin):\n    \"\"\"HDF5 Group, a collection of datasets and subgroups.\n\n    NPLab \"wraps\" h5py's Group objects to provide extra functions.\n    \"\"\"\n\n    def __getitem__(self, key):\n        item = super(Group, self).__getitem__(key)  # get the dataset or group\n        return wrap_h5py_item(item) #wrap as a Group if necessary\n        \n    @property\n    def parent(self):\n        \"\"\"Return the group to which this object belongs.\"\"\"\n        return wrap_h5py_item(super(Group,self).parent)\n\n    def find_unique_name(self, name):\n        \"\"\"Find a unique name for a subgroup or dataset in this group.\n\n        :param name: If this contains a %d placeholder, it will be replaced with the lowest integer such that the new name is unique.  If no %d is included, _%d will be appended to the name if the name already exists in this group.\n        \"\"\"\n        if \"%d\" not in name and name not in list(self.keys()):\n            return name  # simplest case: it's a unique name\n        else:\n            n = 0\n            if \"%d\" not in name:\n                name += \"_%d\"\n            while (name % n) in self:\n                n += 1  # increase the number until the name's unique\n            return (name % n)\n\n    def numbered_items(self, name):\n        \"\"\"Get a list of datasets/groups that have a given name + number,\n        sorted by the number appended to the end.\n\n        This function is intended to return items saved with\n        auto_increment=True, in the order they were added (by default they\n        come in alphabetical order, so 10 comes before 2).  `name` is the\n        name passed in without the _0 suffix.\n        \"\"\"\n        items = [wrap_h5py_item(v) for k, v in list(self.items())\n                 if k.startswith(name)  # only items that start with `name`\n                 and re.match(r\"_*(\\d+)$\", k[len(name):])]  # and end with numbers\n        return sorted(items, key=h5_item_number)\n\n    def count_numbered_items(self, name):\n        \"\"\"Count the number of items that would be returned by numbered_items\n        \n        If all you need to do is count how many items match a name, this is\n        a faster way to do it than len(group.numbered_items(\"name\")).\n        \"\"\"\n        n = 0\n        for k in list(self.keys()):\n            if k.startswith(name) and re.match(r\"_*(\\d+)$\", k[len(name):]):\n                n += 1\n                return n\n\n    def create_group(self, name, attrs=None, auto_increment=True, timestamp=True):\n        \"\"\"Create a new group, ensuring we don't overwrite old ones.\n\n        A new group is created within this group, with the specified name.\n        If auto_increment is True (the default) then a number is used to ensure\n        the name is unique.\n\n        :param name: The name of the new group.  May contain a %d placeholder\n        as described in find_unique_name()\n        :param auto_increment: True by default, which invokes the unique name\n        behaviour described in find_unique_name.  Set this to False to cause\n        an error if the desired name exists already.\n        \"\"\"\n        if auto_increment and name is not None:\n            name = self.find_unique_name(name) #name is None if creating via the dict interface\n        g = super(Group, self).create_group(name)\n        if timestamp:\n            g.attrs.create('creation_timestamp', datetime.datetime.now().isoformat().encode())\n        if attrs is not None:\n            attributes_from_dict(g, attrs)\n        return Group(g.id)  # make sure it's wrapped!\n\n    def require_group(self, name):\n        \"\"\"Return a subgroup, creating it if it does not exist.\"\"\"\n        return Group(super(Group, self).require_group(name).id)  # wrap the returned group\n\n    def create_dataset(self, name, auto_increment=True, shape=None, dtype=None,\n                       data=None, attrs=None, timestamp=True,autoflush = True, *args, **kwargs):\n        \"\"\"Create a new dataset, optionally with an auto-incrementing name.\n\n        :param name: the name of the new dataset\n        :param auto_increment: if True (default), add a number to the dataset name to\n            ensure it's unique.  To force the addition of a number, append %d to the dataset name.\n        :param shape: a tuple describing the dimensions of the data (only needed if data is not specified)\n        :param dtype: data type to be saved (if not specifying data)\n        :param data: a numpy array or equivalent, to be saved - this specifies dtype and shape.\n        :param attrs: a dictionary of metadata to be saved with the data\n        :param timestamp: if True (default), we save a \"creation_timestamp\" attribute with the current time.\n\n        Further arguments are passed to h5py.Group.create_dataset.\n        \"\"\"\n        if auto_increment and name is not None: #name is None if we are creating via the dict interface\n            name = self.find_unique_name(name)\n        dset = super(Group, self).create_dataset(name, shape, dtype, data, *args, **kwargs)\n        if timestamp:\n            dset.attrs.create('creation_timestamp', datetime.datetime.now().isoformat().encode())\n        if hasattr(data, \"attrs\"): #if we have an ArrayWithAttrs, use the attrs!\n            attributes_from_dict(dset, data.attrs)\n        if attrs is not None:\n            attributes_from_dict(dset, attrs)  # quickly set the attributes\n        if autoflush==True:\n            dset.file.flush()\n        return dset\n\n    create_dataset.__doc__ += '\\n\\n'+h5py.Group.create_dataset.__doc__\n\n    def require_dataset(self, name, auto_increment=True, shape=None, dtype=None, data=None, attrs=None, timestamp=True,\n                        *args, **kwargs):\n        \"\"\"Require a new dataset, optionally with an auto-incrementing name.\"\"\"\n        if name not in self:\n            dset = self.create_dataset(name, auto_increment, shape, dtype, data, attrs, timestamp,\n                                       *args, **kwargs)\n        else:\n            dset = self[name]\n        return dset\n\n    def create_resizable_dataset(self, name, shape=(0,), maxshape=(None,), auto_increment=True, dtype=None, attrs=None, timestamp=True,\n                                 *args, **kwargs):\n        \"\"\"See create_dataset documentation\"\"\"\n        return self.create_dataset(name, auto_increment, shape, dtype, attrs, timestamp,\n                                   maxshape=maxshape, chunks=True, *args, **kwargs)\n\n    def require_resizable_dataset(self, name, shape=(0,), maxshape=(None,), auto_increment=True, dtype=None, attrs=None, timestamp=True,\n                                  *args, **kwargs):\n        \"\"\"Create a resizeable dataset, or return the dataset if it exists.\"\"\"\n        if name not in self:\n            dset = self.create_resizable_dataset(name, shape, maxshape, auto_increment, dtype, attrs, timestamp,\n                                                 *args, **kwargs)\n        else:\n            dset = self[name]\n        return dset\n\n    def update_attrs(self, attribute_dict):\n        \"\"\"Update (create or modify) the attributes of this group.\"\"\"\n        attributes_from_dict(self, attribute_dict)\n\n    def append_dataset(self, name, value, dtype=None):\n        \"\"\"Append the given data to an existing dataset, creating it if it doesn't exist.\"\"\"\n        if name not in self:\n            if hasattr(value, 'shape'):\n                shape = (0,)+value.shape\n                maxshape = (None,)+value.shape\n            elif isinstance(value, Sequence):\n                shape = (0, len(value))\n                maxshape = (None, len(value))  # tuple(None for i in shape)\n            else:\n                shape=(0,)\n                maxshape = (None,)\n            dset = self.require_dataset(name, shape=shape, dtype=dtype,\n                                        maxshape=maxshape, chunks=True)\n        else:\n            dset = self[name]\n        index = dset.shape[0]\n        dset.resize(index+1,0)\n        dset[index,...] = value\n\n    def get_qt_ui(self):\n        \"\"\"Return a file browser widget for this group.\"\"\"\n        # Sorry about the dynamic import - the alternative is always\n        # requiring Qt to access data files, and I think that's worse.\n        from nplab.ui.hdf5_browser import HDF5Browser\n        return HDF5Browser(self)\n\n    @property\n    def basename(self):\n        \"\"\"Return the last part of self.name, i.e. just the final component of the path.\"\"\"\n        return self.name.rsplit(\"/\", 1)[-1]\n        \n    def timestamp_sorted_items(self):\n        \"\"\"Return a sorted list of items \"\"\"\n        return sort_by_timestamp(self)",
  "class DataFile(Group):\n    \"\"\"Represent an HDF5 file object.\n\n    For the moment, this just represents the root group, as it's far easier!  May\n    change in the future...\n    \"\"\"\n\n    def __init__(self, name, mode='a', save_version_info=False,\n                 update_current_group=True, *args, **kwargs):\n        \"\"\"Open or create an HDF5 file.\n\n        :param name: The filename/path of the HDF5 file to open or create, or an h5py File object\n        :param mode: Mode to open the file in, one of:\n            r\n                Read-only, file must exist\n            r+\n                Read/write, file must exist\n            w\n                Create the file, deleting it if it exists\n            w-\n                Create the file, fail with an error if it exists\n            a\n                Open read/write if the file exists, otherwise create it.\n        :param save_version_info: If True (default), save a string attribute at top-level\n        with information about the current module and system.\n        \"\"\"\n        if isinstance(name, h5py.Group):\n            f = name #if it's already an open file, just use it\n        else:\n            f = h5py.File(name, mode, *args, **kwargs)  # open the file\n            try:\n                f = h5py.File(name, mode, *args, **kwargs)\n            except OSError as e:\n                print(\"problem opening file\", e)            \n                if os.path.getsize(name) < 100 and mode == 'a': #1kB/10\n                    os.remove(name) # dirty hack to work around mode=a not working\n                                        # if the file is empty\n                else:\n                    raise e\n                f = h5py.File(name, mode, *args, **kwargs)\n        \n        \n        \n        super(DataFile, self).__init__(f.id)  # initialise a Group object with the root group of the file (saves re-wrapping all the functions for File)\n        if save_version_info and self.file.mode != 'r':\n            #Save version information if needed\n            n=0\n            while \"version_info_%04d\" % n in self.attrs:\n                n += 1\n            try:\n                self.attrs.create(\"version_info_%04d\" % n, np.string_(nplab.utils.version.version_info_string()))\n            except:\n               print(\"Error: could not save version information\")\n        self.update_current_group = update_current_group\n        \n\n    def flush(self):\n        self.file.flush()\n\n    def close(self):\n        self.file.close()\n\n    def make_current(self):\n        \"\"\"Set this as the default location for all new data.\"\"\"\n        global _current_datafile\n        _current_datafile = self\n        \n    @property\n    def filename(self):\n        \"\"\" Returns the filename (full path) of the current datafile \"\"\"\n        return self.file.filename\n     \n    @property\n    def dirname(self):\n        \"\"\" Returns the path of the datafolder the current datafile is in\"\"\"\n        return os.path.dirname(self.file.filename)",
  "def current(create_if_none=True, create_if_closed=True, mode='a',working_directory = None):\n    \"\"\"Return the current data file, creating one if it does not exist.\n\n    Arguments:\n        create_if_none : bool (optional, default True)\n            Attempt to pop up a file dialog and create a new file if necessary.\n            The default is True, i.e. do this if there's no current file.\n        create_if_closed: bool (optional, default True)\n            If the current data file is closed, create a new one.\n        mode : str (optional, default 'a')\n            The HDF5 mode to use for the file.  Sensible modes would be:\n                'a': create if it doesn't exist, or append to an existing file\n                'r': read-only\n                'w-': read-write, delete the file if it already exists\n                'r+': read-write, file must exist already.\n    \"\"\"\n    # TODO: if file previously used but closed don't ask to recreate but use config to open\n    global _current_datafile\n    if create_if_closed:  # try to access the file - if it's closed, it will fail\n        try:\n            list(_current_datafile.keys())\n        except:  # if the file is closed, set it to none so we make a new one.\n            _current_datafile = None\n\n    if _current_datafile is None and create_if_none:\n        print(\"No current data file, attempting to create...\")\n        if working_directory==None:\n            working_directory=os.getcwd()\n        try:  # we try to pop up a Qt file dialog\n            import nplab.utils.gui\n            from nplab.utils.gui import QtGui\n            from nplab.utils.gui import QtWidgets\n            app = nplab.utils.gui.get_qt_app()  # ensure Qt is running\n            fname = QtWidgets.QFileDialog.getSaveFileName(\n                caption=\"Select Data File\",\n                directory=os.path.join(working_directory, datetime.date.today().strftime(\"%Y-%m-%d.h5\")),\n                filter=\"HDF5 Data (*.h5 *.hdf5)\",\n                options=QtWidgets.QFileDialog.DontConfirmOverwrite,\n            )\n            if not isinstance(fname, str):\n                fname = fname[0]  # work around version-dependent Qt behaviour :(\n            if len(fname) > 0:\n                print(fname)\n                if not \".\" in fname:\n                    fname += \".h5\"\n                set_current(fname, mode=mode)\n            #                if os.path.isfile(fname): #FIXME: dirty hack to work around mode=a not working\n            #                    set_current(fname,mode='r+')\n            #                else:\n            #                    set_current(fname,mode='w-') #create the datafile\n            else:\n                print(\"Cancelled by the user.\")\n        except Exception as e:\n            print(\"File dialog went wrong :(\")\n            print(e)\n\n    if _current_datafile is not None:\n        return _current_datafile  # if there is a file (or we created one) return it\n    else:\n        raise IOError(\"Sorry, there is no current file to return.\")",
  "def set_current(datafile, **kwargs):\n    \"\"\"Set the current datafile, specified by either an HDF5 file object or a filepath\"\"\"\n    global _current_datafile\n    if isinstance(datafile, DataFile):\n        _current_datafile = datafile\n        return _current_datafile\n    elif isinstance(datafile, h5py.Group):\n        _current_datafile = DataFile(datafile)\n        return _current_datafile\n    else:\n        print(\"opening file: \", datafile)\n        _current_datafile = DataFile(datafile, **kwargs)  # open a new datafile\n        return _current_datafile",
  "def set_temporary_current_datafile():\n    \"\"\"Create a temporary datafile, for testing purposes.\"\"\"\n    nplab.log(\"WARNING: using a temporary file\")\n    print(\"WARNING: using a file in memory as the current datafile.  DATA WILL NOT BE SAVED.\")\n    df = h5py.File(\"temporary_file.h5\", driver='core', backing_store=False)\n    return set_current(df)",
  "def close_current():\n    \"\"\"Close the current datafile\"\"\"\n    if _current_datafile is not None:\n        try:\n            _current_datafile.close()\n        except:\n            print(\"Error closing the data file\")",
  "def set_current_group(selected_object):\n    '''Grabs the currently selected group, using the parent group if a dataset is selected.\n    This only works if the datafile the group resides in is the current datafile'''\n    global _current_group\n    try:\n        if type(selected_object) == DummyHDF5Group:\n            potential_group = list(selected_object.values())[0]\n        else:\n            potential_group = selected_object\n        if type(selected_object) == Group or type(selected_object)==h5py.Group:\n            _current_group =  wrap_h5py_item(selected_object)\n        else:\n            _current_group = wrap_h5py_item(potential_group.parent)\n    except AttributeError:\n        _current_group = current()",
  "def open_file(set_current_bool = True,mode = 'a'):\n    \"\"\"Open an existing data file\"\"\"\n    global _current_datafile\n    try:  # we try to pop up a Qt file dialog\n        import nplab.utils.gui\n        from nplab.utils.gui import QtGui,QtWidgets\n        app = nplab.utils.gui.get_qt_app()  # ensure Qt is running\n        fname = QtWidgets.QFileDialog.getOpenFileName(\n            caption=\"Select Existing Data File\",\n            directory=os.path.join(os.getcwd()),\n            filter=\"HDF5 Data (*.h5 *.hdf5)\",\n#            options=qtgui.QFileDialog.DontConfirmOverwrite,\n        )\n        if not isinstance(fname, str):\n            fname = fname[0]  # work around version-dependent Qt behaviour :(\n        if len(fname) > 0:\n            print(fname)\n            if set_current_bool == True:\n                set_current(fname, mode=mode)\n            else:\n                return DataFile(fname,mode = mode )\n        else:\n            print(\"Cancelled by the user.\")\n    except Exception as e:\n            print(\"File dialog went wrong :(\")\n            print(e)\n\n    return _current_datafile",
  "def create_file(set_current_bool = False,mode = 'a'):\n    \"\"\"Create a data file\"\"\"\n    global _current_datafile\n    try:  # we try to pop up a Qt file dialog\n        import nplab.utils.gui\n        from nplab.utils.gui import QtGui,QtWidgets\n        app = nplab.utils.gui.get_qt_app()  # ensure Qt is running\n        fname = QtWidgets.QFileDialog.getSaveFileName(\n            caption=\"Select Existing Data File\",\n            directory=os.path.join(os.getcwd()),\n            filter=\"HDF5 Data (*.h5 *.hdf5)\",\n#            options=qtgui.QFileDialog.DontConfirmOverwrite,\n        )\n        if not isinstance(fname, str):\n            fname = fname[0]  # work around version-dependent Qt behaviour :(\n        if len(fname) > 0:\n            print(fname)\n            if set_current_bool == True:\n                set_current(fname, mode=mode)\n            else:\n                return DataFile(fname,mode = mode )\n        else:\n            print(\"Cancelled by the user.\")\n    except Exception as e:\n            print(\"File dialog went wrong :(\")\n            print(e)\n\n    return _current_datafile",
  "def __getitem__(self, key):\n        item = super(Group, self).__getitem__(key)  # get the dataset or group\n        return wrap_h5py_item(item)",
  "def parent(self):\n        \"\"\"Return the group to which this object belongs.\"\"\"\n        return wrap_h5py_item(super(Group,self).parent)",
  "def find_unique_name(self, name):\n        \"\"\"Find a unique name for a subgroup or dataset in this group.\n\n        :param name: If this contains a %d placeholder, it will be replaced with the lowest integer such that the new name is unique.  If no %d is included, _%d will be appended to the name if the name already exists in this group.\n        \"\"\"\n        if \"%d\" not in name and name not in list(self.keys()):\n            return name  # simplest case: it's a unique name\n        else:\n            n = 0\n            if \"%d\" not in name:\n                name += \"_%d\"\n            while (name % n) in self:\n                n += 1  # increase the number until the name's unique\n            return (name % n)",
  "def numbered_items(self, name):\n        \"\"\"Get a list of datasets/groups that have a given name + number,\n        sorted by the number appended to the end.\n\n        This function is intended to return items saved with\n        auto_increment=True, in the order they were added (by default they\n        come in alphabetical order, so 10 comes before 2).  `name` is the\n        name passed in without the _0 suffix.\n        \"\"\"\n        items = [wrap_h5py_item(v) for k, v in list(self.items())\n                 if k.startswith(name)  # only items that start with `name`\n                 and re.match(r\"_*(\\d+)$\", k[len(name):])]  # and end with numbers\n        return sorted(items, key=h5_item_number)",
  "def count_numbered_items(self, name):\n        \"\"\"Count the number of items that would be returned by numbered_items\n        \n        If all you need to do is count how many items match a name, this is\n        a faster way to do it than len(group.numbered_items(\"name\")).\n        \"\"\"\n        n = 0\n        for k in list(self.keys()):\n            if k.startswith(name) and re.match(r\"_*(\\d+)$\", k[len(name):]):\n                n += 1\n                return n",
  "def create_group(self, name, attrs=None, auto_increment=True, timestamp=True):\n        \"\"\"Create a new group, ensuring we don't overwrite old ones.\n\n        A new group is created within this group, with the specified name.\n        If auto_increment is True (the default) then a number is used to ensure\n        the name is unique.\n\n        :param name: The name of the new group.  May contain a %d placeholder\n        as described in find_unique_name()\n        :param auto_increment: True by default, which invokes the unique name\n        behaviour described in find_unique_name.  Set this to False to cause\n        an error if the desired name exists already.\n        \"\"\"\n        if auto_increment and name is not None:\n            name = self.find_unique_name(name) #name is None if creating via the dict interface\n        g = super(Group, self).create_group(name)\n        if timestamp:\n            g.attrs.create('creation_timestamp', datetime.datetime.now().isoformat().encode())\n        if attrs is not None:\n            attributes_from_dict(g, attrs)\n        return Group(g.id)",
  "def require_group(self, name):\n        \"\"\"Return a subgroup, creating it if it does not exist.\"\"\"\n        return Group(super(Group, self).require_group(name).id)",
  "def create_dataset(self, name, auto_increment=True, shape=None, dtype=None,\n                       data=None, attrs=None, timestamp=True,autoflush = True, *args, **kwargs):\n        \"\"\"Create a new dataset, optionally with an auto-incrementing name.\n\n        :param name: the name of the new dataset\n        :param auto_increment: if True (default), add a number to the dataset name to\n            ensure it's unique.  To force the addition of a number, append %d to the dataset name.\n        :param shape: a tuple describing the dimensions of the data (only needed if data is not specified)\n        :param dtype: data type to be saved (if not specifying data)\n        :param data: a numpy array or equivalent, to be saved - this specifies dtype and shape.\n        :param attrs: a dictionary of metadata to be saved with the data\n        :param timestamp: if True (default), we save a \"creation_timestamp\" attribute with the current time.\n\n        Further arguments are passed to h5py.Group.create_dataset.\n        \"\"\"\n        if auto_increment and name is not None: #name is None if we are creating via the dict interface\n            name = self.find_unique_name(name)\n        dset = super(Group, self).create_dataset(name, shape, dtype, data, *args, **kwargs)\n        if timestamp:\n            dset.attrs.create('creation_timestamp', datetime.datetime.now().isoformat().encode())\n        if hasattr(data, \"attrs\"): #if we have an ArrayWithAttrs, use the attrs!\n            attributes_from_dict(dset, data.attrs)\n        if attrs is not None:\n            attributes_from_dict(dset, attrs)  # quickly set the attributes\n        if autoflush==True:\n            dset.file.flush()\n        return dset",
  "def require_dataset(self, name, auto_increment=True, shape=None, dtype=None, data=None, attrs=None, timestamp=True,\n                        *args, **kwargs):\n        \"\"\"Require a new dataset, optionally with an auto-incrementing name.\"\"\"\n        if name not in self:\n            dset = self.create_dataset(name, auto_increment, shape, dtype, data, attrs, timestamp,\n                                       *args, **kwargs)\n        else:\n            dset = self[name]\n        return dset",
  "def create_resizable_dataset(self, name, shape=(0,), maxshape=(None,), auto_increment=True, dtype=None, attrs=None, timestamp=True,\n                                 *args, **kwargs):\n        \"\"\"See create_dataset documentation\"\"\"\n        return self.create_dataset(name, auto_increment, shape, dtype, attrs, timestamp,\n                                   maxshape=maxshape, chunks=True, *args, **kwargs)",
  "def require_resizable_dataset(self, name, shape=(0,), maxshape=(None,), auto_increment=True, dtype=None, attrs=None, timestamp=True,\n                                  *args, **kwargs):\n        \"\"\"Create a resizeable dataset, or return the dataset if it exists.\"\"\"\n        if name not in self:\n            dset = self.create_resizable_dataset(name, shape, maxshape, auto_increment, dtype, attrs, timestamp,\n                                                 *args, **kwargs)\n        else:\n            dset = self[name]\n        return dset",
  "def update_attrs(self, attribute_dict):\n        \"\"\"Update (create or modify) the attributes of this group.\"\"\"\n        attributes_from_dict(self, attribute_dict)",
  "def append_dataset(self, name, value, dtype=None):\n        \"\"\"Append the given data to an existing dataset, creating it if it doesn't exist.\"\"\"\n        if name not in self:\n            if hasattr(value, 'shape'):\n                shape = (0,)+value.shape\n                maxshape = (None,)+value.shape\n            elif isinstance(value, Sequence):\n                shape = (0, len(value))\n                maxshape = (None, len(value))  # tuple(None for i in shape)\n            else:\n                shape=(0,)\n                maxshape = (None,)\n            dset = self.require_dataset(name, shape=shape, dtype=dtype,\n                                        maxshape=maxshape, chunks=True)\n        else:\n            dset = self[name]\n        index = dset.shape[0]\n        dset.resize(index+1,0)\n        dset[index,...] = value",
  "def get_qt_ui(self):\n        \"\"\"Return a file browser widget for this group.\"\"\"\n        # Sorry about the dynamic import - the alternative is always\n        # requiring Qt to access data files, and I think that's worse.\n        from nplab.ui.hdf5_browser import HDF5Browser\n        return HDF5Browser(self)",
  "def basename(self):\n        \"\"\"Return the last part of self.name, i.e. just the final component of the path.\"\"\"\n        return self.name.rsplit(\"/\", 1)[-1]",
  "def timestamp_sorted_items(self):\n        \"\"\"Return a sorted list of items \"\"\"\n        return sort_by_timestamp(self)",
  "def __init__(self, name, mode='a', save_version_info=False,\n                 update_current_group=True, *args, **kwargs):\n        \"\"\"Open or create an HDF5 file.\n\n        :param name: The filename/path of the HDF5 file to open or create, or an h5py File object\n        :param mode: Mode to open the file in, one of:\n            r\n                Read-only, file must exist\n            r+\n                Read/write, file must exist\n            w\n                Create the file, deleting it if it exists\n            w-\n                Create the file, fail with an error if it exists\n            a\n                Open read/write if the file exists, otherwise create it.\n        :param save_version_info: If True (default), save a string attribute at top-level\n        with information about the current module and system.\n        \"\"\"\n        if isinstance(name, h5py.Group):\n            f = name #if it's already an open file, just use it\n        else:\n            f = h5py.File(name, mode, *args, **kwargs)  # open the file\n            try:\n                f = h5py.File(name, mode, *args, **kwargs)\n            except OSError as e:\n                print(\"problem opening file\", e)            \n                if os.path.getsize(name) < 100 and mode == 'a': #1kB/10\n                    os.remove(name) # dirty hack to work around mode=a not working\n                                        # if the file is empty\n                else:\n                    raise e\n                f = h5py.File(name, mode, *args, **kwargs)\n        \n        \n        \n        super(DataFile, self).__init__(f.id)  # initialise a Group object with the root group of the file (saves re-wrapping all the functions for File)\n        if save_version_info and self.file.mode != 'r':\n            #Save version information if needed\n            n=0\n            while \"version_info_%04d\" % n in self.attrs:\n                n += 1\n            try:\n                self.attrs.create(\"version_info_%04d\" % n, np.string_(nplab.utils.version.version_info_string()))\n            except:\n               print(\"Error: could not save version information\")\n        self.update_current_group = update_current_group",
  "def flush(self):\n        self.file.flush()",
  "def close(self):\n        self.file.close()",
  "def make_current(self):\n        \"\"\"Set this as the default location for all new data.\"\"\"\n        global _current_datafile\n        _current_datafile = self",
  "def filename(self):\n        \"\"\" Returns the filename (full path) of the current datafile \"\"\"\n        return self.file.filename",
  "def dirname(self):\n        \"\"\" Returns the path of the datafolder the current datafile is in\"\"\"\n        return os.path.dirname(self.file.filename)",
  "def software_lockin(t, signal, reference, harmonic=1, trigger=None, smoothing=None, basis='cartesian'):\n    \"\"\"\n    Extract the amplitude and phase of a signal component at a frequency set by a reference\n    signal.\n\n    :param t: a numpy array of time values\n    :param signal: a numpy\n    :param reference:\n    :param harmonic:\n    :param trigger:\n    :param smoothing:\n    :param basis: cartesian (x,y) or polar (r,theta) return\n    :return: Depending on the basis, either a cartesian (real, imaginary) pair of values is\n             returned or a polar amplitude and angle (phase) pair of values.\n\n    :rtype : object\n    \"\"\"\n    assert len(signal) == len(t) and len(reference) == len(t), 'all arrays must be the same length.'\n    if type(t) != np.ndarray:\n        t = np.array(t)  # casting t to numpy array for boolean slicing\n    # find the zero crossings of the reference signal to determine its frequency and phase.\n    # a rising edge is used only\n    cond1 = reference[:-1] < np.mean(reference)\n    cond2 = reference[1:] >= np.mean(reference)\n    zero_crossings = t[cond1 & cond2]  # these are the points in time that are zero\n    # fit a line to the zero crossing\n    n = np.arange(zero_crossings.size)  # number of rising triggers\n    p = np.polyfit(n, zero_crossings, 1)  # result is p[0]*t + p[1]\n    # extract the frequency and phase of the reference wave\n    omega_r = old_div(2*np.pi,p[0])\n    phi_r = -omega_r*p[1]  # if the phase is not between 0 and 2pi its ok since its put into an exp\n    ref = np.exp(-1j*harmonic*(omega_r*t + phi_r))  # construct the reference waveform\n    cmplx = 2j*np.mean(signal*ref)  # multiply signal with reference\n    x = cmplx.real\n    y = cmplx.imag\n    if basis == 'cartesian':\n        return x, y\n    elif basis == 'polar':\n        return cart2pol(x, y)",
  "def cart2pol(x, y):\n    \"\"\"\n    Converts (x,y) cartesian coordinates to (r,theta) polar coordinates.\n\n    :param x:\n    :param y:\n    :return:\n    \"\"\"\n    return np.sqrt(x**2 + y**2), np.angle(x + 1j*y)",
  "def find_centroid(img, x=None, y=None, threshold=None):\n    \"\"\"\n    Find the centroid of an image using image moments.\n\n    Note that x and y in this case are defined as img[y][x], where x\n\n    :param img: 2d numpy array of the image\n    :param x: 1d numpy array corresponding to the rows of the image\n    :param y: 1d numpy array corresponding to the columns of the image\n    :param threshold: bottom fraction of the background-subtracted image to remove\n                      before calculating image moments\n    :return: Returns the x and y centroids\n\n    :rtype : float, float\n    \"\"\"\n    img = img.copy()  # img is copied since it is later modified\n    # get x and y or create if necessary (pixel coordinates)\n    if x is None:\n        x = np.arange(img.shape[-1])\n    elif y is None:\n        y = np.arange(img.shape[-2])\n    if img.shape != (y.size, x.size):\n        raise ValueError('Shape of img(y,x) does not match (x,y)')\n    # remove background - the maximum value of the outer array elements and threshold to 0\n    bkgd = np.concatenate((img[0, :],  # bottom\n                           img[-1, :],  # top\n                           img[:, 0].flatten(),  # left\n                           img[:, -1].flatten())  # right\n                          ).max()\n    img *= (img - bkgd >= 0)\n    # apply threshold\n    if threshold is not None:\n        threshold = threshold*img.max() + (1 - threshold)*img.min()  # n(x-y)+y = nx +y(1-n)\n        img *= (img >= threshold)\n    # calculate moments\n    m10 = np.sum(y.reshape(img.shape[0], 1) * img)\n    m01 = np.sum(x.reshape(1, img.shape[1]) * img)\n    m00 = np.sum(img)\n    centroid_x = old_div(m01, m00)\n    centroid_y = old_div(m10, m00)\n    return centroid_x, centroid_y",
  "def measure_fwhm(img, x=None, y=None, return_curve=False):\n    if x is None:\n        x = np.arange(img.shape[-1])\n    if y is None:\n        y = np.arange(img.shape[-2])\n    # create initial guess parameters for gaussian fit\n    cx, cy = find_centroid(img, x, y)\n    xdata = np.sum(img, axis=0)\n    ydata = np.sum(img, axis=1)\n    p0_x = [xdata.min(), xdata.max() - xdata.min(), cx, old_div((x.max() - x.min()), 2)]\n    p0_y = [ydata.min(), ydata.max() - ydata.min(), cy, old_div((y.max() - y.min()), 2)]\n    popt_x, pcov_x = curve_fit(gaussian, x, xdata, p0_x)\n    popt_y, pcov_y = curve_fit(gaussian, y, ydata, p0_y)\n    fwhm_x = 2 * np.sqrt(2 * np.log(2)) * popt_x[3]\n    fwhm_y = 2 * np.sqrt(2 * np.log(2)) * popt_y[3]\n    if return_curve:\n        return fwhm_x, fwhm_y, xdata, ydata, popt_x, popt_y\n    else:\n        return fwhm_x, fwhm_y",
  "class IviumDataFile(object):\n    def __init__(self, data_file):\n        self.params = {}\n        self.parse_data(data_file)\n\n    def parse_data(self, data_file):\n        with open(data_file, 'r') as f:\n            lines = [l.strip() for l in f.readlines()]\n            for line in lines:\n                if '=' in line:\n                    param, value = line.split('=')\n                    self.params[param] = value\n                if 'primary_data' in line:\n                    i = lines.index(line)\n                    #for j in range(i, i+6): print j, lines[j]\n                    self.data = np.genfromtxt(data_file, skip_header=i+4, skip_footer=2,\n                                           usecols=(0,1,2),\n                                           names=('x', 'y', 'z'),\n                                           #missing_values = 'x',\n                                           #filling_values = 0,\n                                           autostrip=True, unpack=True,\n                                           )",
  "class IviumDataFileStr(object):\n    def __init__(self, data_file_str):\n        self.params = {}\n        self.parse_data(data_file_str)\n\n    def parse_data(self, data_file_str):\n        s = StringIO(data_file_str)\n        lines = [l.strip() for l in s.readlines()]\n        print(len(lines))\n        for line in lines:\n            if '=' in line:\n                param, value = line.split('=')\n                self.params[param] = value\n            if 'primary_data' in line:\n                i = lines.index(line)\n                print('starting from line {0:d}/{1:d}'.format(i, len(lines)), lines[i])\n                #print lines\n                #for j in range(i, i+6): print j, lines[j]\n                self.data = np.genfromtxt(StringIO(data_file_str), skip_header=i+4, skip_footer=3,\n                                       usecols=(0,1,2),\n                                       names=('x', 'y', 'z'),\n                                       #missing_values = 'x',\n                                       #filling_values = 0,\n                                       autostrip=True, unpack=True,\n                                       )",
  "class IviumDataSet(object):\n    def __init__(self, data_set):\n        self.sets = []\n        self.parse_set2(data_set)\n\n    def parse_set(self, data_set):\n        with open(data_set, 'r') as f:\n            data_set = f.read()\n        data = [s.strip() for s in data_set.split('QR') if s.strip() != '' and s.strip() != '=']\n        print(len(data))\n        print(data)\n\n    def parse_set2(self, data_set):\n        with open(data_set, 'r') as f:\n            lines = f.readlines()\n            indices = [i for i in range(len(lines)) if 'QR=QR' in lines[i]]\n            print(indices)\n            #for i in indices: print lines[i]\n            sets = [lines[indices[n]:indices[n+1]] for n in range(len(indices)-1)]\n            sets.append(lines[indices[-1]:])\n            self.sets = [IviumDataFileStr(''.join(x)) for x in sets[1:]]",
  "def __init__(self, data_file):\n        self.params = {}\n        self.parse_data(data_file)",
  "def parse_data(self, data_file):\n        with open(data_file, 'r') as f:\n            lines = [l.strip() for l in f.readlines()]\n            for line in lines:\n                if '=' in line:\n                    param, value = line.split('=')\n                    self.params[param] = value\n                if 'primary_data' in line:\n                    i = lines.index(line)\n                    #for j in range(i, i+6): print j, lines[j]\n                    self.data = np.genfromtxt(data_file, skip_header=i+4, skip_footer=2,\n                                           usecols=(0,1,2),\n                                           names=('x', 'y', 'z'),\n                                           #missing_values = 'x',\n                                           #filling_values = 0,\n                                           autostrip=True, unpack=True,\n                                           )",
  "def __init__(self, data_file_str):\n        self.params = {}\n        self.parse_data(data_file_str)",
  "def parse_data(self, data_file_str):\n        s = StringIO(data_file_str)\n        lines = [l.strip() for l in s.readlines()]\n        print(len(lines))\n        for line in lines:\n            if '=' in line:\n                param, value = line.split('=')\n                self.params[param] = value\n            if 'primary_data' in line:\n                i = lines.index(line)\n                print('starting from line {0:d}/{1:d}'.format(i, len(lines)), lines[i])\n                #print lines\n                #for j in range(i, i+6): print j, lines[j]\n                self.data = np.genfromtxt(StringIO(data_file_str), skip_header=i+4, skip_footer=3,\n                                       usecols=(0,1,2),\n                                       names=('x', 'y', 'z'),\n                                       #missing_values = 'x',\n                                       #filling_values = 0,\n                                       autostrip=True, unpack=True,\n                                       )",
  "def __init__(self, data_set):\n        self.sets = []\n        self.parse_set2(data_set)",
  "def parse_set(self, data_set):\n        with open(data_set, 'r') as f:\n            data_set = f.read()\n        data = [s.strip() for s in data_set.split('QR') if s.strip() != '' and s.strip() != '=']\n        print(len(data))\n        print(data)",
  "def parse_set2(self, data_set):\n        with open(data_set, 'r') as f:\n            lines = f.readlines()\n            indices = [i for i in range(len(lines)) if 'QR=QR' in lines[i]]\n            print(indices)\n            #for i in indices: print lines[i]\n            sets = [lines[indices[n]:indices[n+1]] for n in range(len(indices)-1)]\n            sets.append(lines[indices[-1]:])\n            self.sets = [IviumDataFileStr(''.join(x)) for x in sets[1:]]",
  "class Raman_Spectrum(object):\n    #Object class containing spectral data and metadata for single Raman spectrum\n    def __init__(self, filename, timestamp, metadata, laserWl, laserPower, absLaserPower, integrationTime,\n                 accumulations, nScans, wavenumbers, ramanIntensities, absRamanIntensities):\n        self.filename = filename\n        self.timestamp = timestamp\n        self.metadata = metadata\n        self.laserWl = laserWl\n        self.laserPower = laserPower\n        self.absLaserPower = absLaserPower\n        self.integrationTime = integrationTime\n        self.accumulations = accumulations\n        self.nScans = nScans\n        self.wavenumbers = wavenumbers\n        self.ramanIntensities = ramanIntensities\n        self.absRamanIntensities = absRamanIntensities",
  "def extractRamanSpc(path, bg_path = False, combine_statics = False, encoding = 'utf-8'):\n    '''Takes all .spc files from a directory and creates Raman_Spectrum object for each and also background subtracts, if specified\n       .spc files must be directly exported at time of measurement. \n       Also plots table for background files if user specifies bg_table = True'''\n\n    '''Actual power values for each % laser power in \u03bcW. Measured on 09/05/2017.'''\n\n    print('Gathering .spc (meta)data from %s...' % path.split('\\\\')[-1])\n\n    p532 = { 0.0001 :    0.01,\n             0.05   :    4.75,\n             0.1    :   12.08,\n             0.5    :   49.6 ,\n             1.0    :   88.1 ,\n             5.0    :  666.  ,\n            10.0    : 1219.  ,\n            50.0    : 5360.  ,\n           100.0    : 9650.   }\n\n    p633 = { 0.0001 :    0.01,\n             0.05   :    1.  ,\n             0.1    :    2.  ,\n             0.5    :   10.  ,\n             1.0    :   20.  ,\n             5.0    :  112.  ,\n            10.0    :  226.  ,\n            50.0    : 1130.  ,\n           100.0    : 2200.   }\n\n    p785 = { 0.0001 :    0.17,\n             0.05   :    8.8 ,\n             0.1    :   19.1 ,\n             0.5    :   47.8 ,\n             1.0    :  104.  ,\n             5.0    :  243.  ,\n            10.0    :  537.  ,\n            50.0    : 1210.  ,\n           100.0    : 2130.   }\n\n    powerConverter = {532 : p532, 633 : p633, 785 : p785} #Assigns each laser power dictionary to the appropriate wavelength.\n\n    os.chdir(path)\n    spcFiles = sorted([f for f in os.listdir('.') if f.endswith('.spc')])\n    spectra = []\n\n    for n, spcFile in enumerate(spcFiles):\n        filename = spcFile[:-4] #Removes extension from filename string\n        print(filename)\n        f = spc.File(spcFile)\n        plt.show()\n        #try:\n        #    f = spc.File(spcFile) #Create File object from .spc file\n        #except:\n        #    print(filename)\n        #    f = spc.File(spcFile) #Create File object from .spc file\n\n        metadata = {}\n        fLogDict = {}\n        \n        fDicts = [f.__dict__, f.log_dict]#main dictionaries containing spectral metadata\n        newFDicts = [metadata, fLogDict]\n        \n        for dictN, fDict in enumerate(fDicts):\n            for k in list(fDict.keys()):\n                i = fDict[k]\n                #print('%s (%s) = %s (%s)' % (k, type(k), i, type(i)))\n                if type(k) == bytes:\n                    k = k.decode()#spc module is written in python 2 and hasn't been updated yet; this ensures all strings are in the same (unicode) format\n                if type(i) == bytes:\n                    try:\n                        i = i.decode()\n                    except:\n                        continue\n                    \n                if k.startswith(' '):#spc module imperfectly pulls data from some files and includes extra spaces in the dict keys\n                    k = k[1:]\n                if k.endswith(' '):\n                    k = k[:-1]\n\n                if k in ['log_content', 'log_other', 'x']:\n                    continue\n                    \n                newFDicts[dictN][k] = i\n            #print('%s (%s) = %s (%s)' % (k, type(k), i, type(i)))\n\n        metadata.update(fLogDict)\n        tStamp = []\n\n        for unit in ['year', 'month', 'day', 'hour', 'minute']:#the timestamp values are actually arbitrary, so this is obsolete\n            if unit == 'year':\n                zFill = 4\n            else:\n                zFill = 2\n            try:\n                metadata[unit]\n                tStamp.append(str(metadata[unit]).zfill(zFill))\n            except:\n                tStamp.append(str(0).zfill(zFill))\n\n        try:\n            timestamp = np.datetime64('%s-%s-%sT%s:%s' % tuple(tStamp))\n        except:\n            timestamp = 'N/A'\n\n        try:\n            laserWl = int(fLogDict['Laser'][7:10]) #Grabs appropriate part of laser wavelength entry from log and converts to integer (must be 3 characters long)\n        except:\n            laserWl = 'N/A'\n\n        if 'Laser_power' in list(fLogDict.keys()):\n            laserPower = float(fLogDict['Laser_power'][13:-1]) #Grabs numeric part of string containing laser power info and converts to float\n        elif 'ND Transmission' in list(fLogDict.keys()):\n            laserPower = float(('').join([char for char in fLogDict['ND Transmission'].split(' ')[1] if char == '.' or char.isdigit()]))\n        else:\n            print(fLogDict.keys())\n            laserPower = 'Undefined'\n\n        if laserPower in [0.0001, 0.05, 0.1, 0.5, 1.0, 5.0, 10.0, 50.0, 100.0]:\n            absLaserPower = float(powerConverter[laserWl][laserPower]) #Returns absolute laser power (in uW), given laser wavelength and % laser power.\n\n        else:\n            absLaserPower = 'Undefined' #To avoid errors if laser power is not recorded correctly\n\n        integrationTime = float(fLogDict['Exposure_time'][6:])\n\n        accumulations = int(fLogDict['Accumulations'].split(': ')[-1])#number of scans\n        \n        wavenumbers = f.x #Pulls x data from spc file\n        nScans = int(metadata['fnsub']) #Number of Raman spectra contained within the spc file (>1 if file contains a kinetic scan)\n        ramanIntensities = np.array([f.sub[i].y for i in range(nScans)]) #Builds list of y data arrays\n        if absLaserPower != 'Undefined':\n            #print(filename, absLaserPower)\n            absRamanIntensities = np.array([spectrum*1000/(absLaserPower*integrationTime*float(accumulations/1000)) for spectrum in ramanIntensities])\n\n        else:\n            absRamanIntensities = ['N/A'] * nScans\n\n        if nScans == 1:\n            ramanIntensities = ramanIntensities[0] #Reduces to single array if not a kinetic scan\n            absRamanIntensities = absRamanIntensities[0] #Also for this\n\n        spectra.append(Raman_Spectrum(filename, timestamp, metadata, laserWl, laserPower, absLaserPower, integrationTime, accumulations, nScans,\n                                      wavenumbers, ramanIntensities, absRamanIntensities))\n\n        #except Exception as e:\n        #    print 'Something went wrong with %s:' % filename\n        #    print e\n        #    continue\n\n    return spectra",
  "def populateH5(spectra, h5File, nameOnly = False):\n\n    print('\\nPopulating h5 file...')\n\n    with h5py.File(h5File, 'a') as f:\n        gSpectra = f.create_group('Spectra')\n\n        for n, spectrum in enumerate(spectra):\n            \n            if len(spectra) < 10:\n                name = 'Spectrum %01d: %s' % (n, spectrum.filename)\n            elif len(spectra) < 100:\n                name = 'Spectrum %02d: %s' % (n, spectrum.filename)\n            elif len(spectra) < 1000:\n                name = 'Spectrum %03d: %s' % (n, spectrum.filename)\n            elif len(spectra) < 10000:\n                name = 'Spectrum %04d: %s' % (n, spectrum.filename)\n            \n            if nameOnly == True:\n                name = spectrum.filename\n\n            gSpectrum = gSpectra.create_group(name)\n            attrs = spectrum.metadata\n            mainAttrs = {'Original Filename' : spectrum.filename,\n                         'Laser Wavelength'  : spectrum.laserWl,\n                         'Laser Power (%)'   : spectrum.laserPower,\n                         'Laser Power (uW)'  : spectrum.absLaserPower,\n                         'Integration Time'  : spectrum.integrationTime,\n                         'Accumulations'     : spectrum.accumulations,\n                         'Number of Scans'   : spectrum.nScans,\n                         'Wavenumbers'       : spectrum.wavenumbers,\n                         'Timestamp'         : str(spectrum.timestamp)}\n\n            attrs.update(mainAttrs)\n            \n            for key in attrs:\n\n                try:\n                    gSpectrum.attrs[key] = attrs[key]\n                except:\n                    continue\n\n            x = spectrum.wavenumbers\n            yRaw = spectrum.ramanIntensities\n            yAbs = spectrum.absRamanIntensities\n            \n            if type(yAbs) == str or type(yAbs[0]) == str:\n                yAbs = np.zeros(len(x))\n\n            if spectrum.nScans == 1:\n                if spectrum.ramanIntensities.max() != 0:\n                    yNorm = spectrum.ramanIntensities/spectrum.ramanIntensities.max()\n                else:\n                    yNorm = spectrum.ramanIntensities\n\n            else:\n                yNorm = []\n                \n                for yData in spectrum.ramanIntensities:\n                    if np.count_nonzero(yData) > 0:\n                        yDataNorm = yData/yData.max()\n                    else:\n                        yDataNorm = yData\n                    yNorm.append(yDataNorm)\n\n                yNorm = np.array(yNorm)\n\n            dRaw = gSpectrum.create_dataset('Raman (cts)', data = yRaw)\n            dRaw.attrs['wavelengths'] = x\n            dAbs = gSpectrum.create_dataset('Raman (cts mw^-1 s^-1)', data = np.array(yAbs))\n            dAbs.attrs['wavelengths'] = dRaw.attrs['wavelengths']\n            dNorm = gSpectrum.create_dataset('Raman (normalised)', data = yNorm)\n            dNorm.attrs['wavelengths'] = dRaw.attrs['wavelengths']\n\n        gRaw = f.create_group('All Raw')\n        gAbs = f.create_group('All Abs')\n        gNorm = f.create_group('All Norm')\n\n        if nameOnly == False:\n            spectraNames = sorted(f['Spectra'].keys(), key = lambda spectrumName: int(spectrumName.split(':')[0][9:]))\n        else:\n            spectraNames = sorted(f['Spectra'].keys())\n\n        for spectrumName in spectraNames:\n            dRaw = f['Spectra'][spectrumName]['Raman (cts)']\n            dRaw = gRaw.create_dataset(spectrumName, data = dRaw)\n            dRaw.attrs.update(f['Spectra'][spectrumName].attrs)\n            dRaw.attrs.update(f['Spectra'][spectrumName]['Raman (cts)'].attrs)\n\n            dAbs = f['Spectra'][spectrumName]['Raman (cts mw^-1 s^-1)']\n            dAbs = gAbs.create_dataset(spectrumName, data = dAbs)\n            dAbs.attrs.update(f['Spectra'][spectrumName].attrs)\n            dAbs.attrs.update(f['Spectra'][spectrumName]['Raman (cts mw^-1 s^-1)'].attrs)\n\n            dNorm = f['Spectra'][spectrumName]['Raman (normalised)']\n            dNorm = gNorm.create_dataset(spectrumName, data = dNorm)\n            dNorm.attrs.update(f['Spectra'][spectrumName].attrs)\n            dNorm.attrs.update(f['Spectra'][spectrumName]['Raman (normalised)'].attrs)\n\n    print('\\th5 file populated\\n')",
  "def createOutputFile(filename):\n\n    '''Auto-increments new filename if file exists'''\n\n    print('\\nCreating output file...')\n\n    outputFile = '%s.h5' % filename\n\n    if outputFile in os.listdir('.'):\n        print('\\n%s already exists' % outputFile)\n        n = 0\n        outputFile = '%s_%s.h5' % (filename, n)\n\n        while outputFile in os.listdir('.'):\n            print('%s already exists' % outputFile)\n            n += 1\n            outputFile = '%s_%s.h5' % (filename, n)\n\n    print('\\tOutput file %s created' % outputFile)\n    return outputFile",
  "def run(encoding = 'utf-8', nameOnly = False):\n    rootDir = os.getcwd()\n    spectra = extractRamanSpc(rootDir, encoding = encoding)\n    dirName = '%s Raman Data' % rootDir.split('\\\\')[-1]\n    h5FileName = createOutputFile(dirName)\n    populateH5(spectra, h5FileName, nameOnly = nameOnly)",
  "def __init__(self, filename, timestamp, metadata, laserWl, laserPower, absLaserPower, integrationTime,\n                 accumulations, nScans, wavenumbers, ramanIntensities, absRamanIntensities):\n        self.filename = filename\n        self.timestamp = timestamp\n        self.metadata = metadata\n        self.laserWl = laserWl\n        self.laserPower = laserPower\n        self.absLaserPower = absLaserPower\n        self.integrationTime = integrationTime\n        self.accumulations = accumulations\n        self.nScans = nScans\n        self.wavenumbers = wavenumbers\n        self.ramanIntensities = ramanIntensities\n        self.absRamanIntensities = absRamanIntensities",
  "def blocks():\n\n\tN = 2048\n\tt = np.linspace(0,1,N)\n\n\tTj = [0.1,0.13,0.15,0.23,0.25,0.40,0.44,0.65,0.76,0.78,0.81]\n\tHj = [4,-5,3,-4,5,-4.2,2.1,4.3,-3.1,2.1,-4.2]\n\tdef K(t):\n\t\treturn (1 + np.sign(t))/2.0\n\ty = np.zeros(t.shape)\n\tfor tj,hj in zip(Tj,Hj):\n\t\ty = y + hj*K(t - tj)\n\n\treturn t,4*y",
  "def bumps():\n\tN = 2048\n\tt = np.linspace(0,1,N)\n\n\tTj = [0.1,0.13,0.15,0.23,0.25,0.40,0.44,0.65,0.76,0.78,0.81]\n\tHj = [4,5,3,4,5,4.2,2.1,4.3,3.1,5.1,4.2]\n\tWj = [0.005,0.005,0.006,0.01,0.01,0.03,0.01,0.01,0.005,0.008,0.005]\n\tdef K(t):\n\t\treturn (1 + np.absolute(t))**-4\n\ty = np.zeros(t.shape)\n\tfor (tj,hj,wj) in zip(Tj,Hj,Wj):\n\t\ty = y + hj*K(old_div((t - tj),wj))\n\treturn t,10*y",
  "def heavisine():\n\tN = 2048\n\tt = np.linspace(0,1,N)\n\n\ty = 4*np.sin(4*np.pi*t) - np.sign(t-0.3)-np.sign(0.72-t)\n\treturn t,y*(10.0/4.0)",
  "def doppler():\n\tN = 2048\n\tt = np.linspace(0,1,N)\n\teps = 0.05\n\ty = np.sqrt(t*(1-t))*np.sin(old_div(2*np.pi*(1+eps),(t+eps)))\n\treturn t,y*(12.5/0.5)",
  "def SUREThresh(coefs):\n\t'''\n\tSingle level SURE adaptive thresholding of wavelet coefficients from:\n\t'Adapting to Unknown Smoothness via Wavelet Shrinkage', D. Donoho, I. Johnstone,\n\tDec 1995\n\n\tPerforms softmax thresholding of wavelet coefficients ('coefs') at this level. \n\tThreshold is selected by minimization of SURE objective for threshold ('t') values in range:\n\t0 < t < sqrt(2*log(d)) where 'd' is the number of coefficients at this level.\n\t\n\tFor more details see paper.\n\n\tArgs:\n        coefs (float list): Single level wavelet coefficients.\n\n    Returns:\n        float list: Softmax thresholded wavelet coefficients.\n\n\t'''\n\td = coefs.shape[0]\n\tt_max = np.sqrt(2*np.log(d))\n\tt_min = 0\n\tdef SURE(t):\n\t\treturn d-2*np.sum(np.abs(coefs) <= t) + np.sum(np.minimum(coefs,t)**2)\n\n\ttrsh = minimize_scalar(SURE,bounds=[t_min,t_max]).x\n\tdef soft_threshold(y):\n\n\t\ta = np.absolute(y) - trsh\n\t\tsgn = np.sign(y)\n\t\tif a <= 0:\n\t\t\treturn 0\n\t\telse:\n\t\t\treturn sgn*a\n\t\n\tthresholded = np.vectorize(soft_threshold)(coefs)\n\t\n\treturn thresholded",
  "def SUREShrink(data):\n\t'''\n\tMultilevel SURE adaptive thresholding of wavelet coefficients from:\n\t'Adapting to Unknown Smoothness via Wavelet Shrinkage', D. Donoho, I. Johnstone,\n\tDec 1995\n\n\tPerforms adaptive SURE denoising of input signal ('data') by adaptive softmax thresholding\n\teach level of wavelet coefficients representing the original signal. Works under the assumption\n\tof Gaussian additive noise in the case when energy signal is concentrated in relatively\n\tfew wavelet transform components allowing softmax thresholding to remove unwanted noise contributions.\n\n\tArgs:\n        data (float list): .\n\n    Returns:\n        float list: SUREShrink Denoised signal.\n\n\t'''\n\tmode = \"periodic\"\n\twl = \"sym8\"\n\tn = data.shape[0]\n\tJ = np.ceil(np.log2(n))\n\t\n\tdwt = pywt.wavedec(data,wavelet=wl,mode=mode)  \n\n\tfor i in range(len(dwt)):\n\t\tdwt[i] = SUREThresh(dwt[i])\n\n\treturn pywt.waverec(dwt,wavelet=wl,mode=mode)",
  "def SkellamThresh(wavelet_coefs,scaling_coefs):\n\tyi = wavelet_coefs\n\tti = scaling_coefs\n\t# print len(yi), len(ti)\n\td = yi.shape[0]\n\tt_max = np.sqrt(2*np.log(d))\n\tt_min = 0\n\n\tdef SkellamObjective(t):\n\t\t\tt1 = np.sum(np.sign(np.abs(yi)-t)*ti)\n\t\t\tt2 = np.sum(np.minimum(yi**2,np.ones(yi.shape)*t**2))\n\t\t\tt3 = -t*np.sum(np.abs(yi)==t)\n\t\t\t# print t1,t2,t3\n\t\t\treturn np.sum([t1,t2,t3])\n\n\n\tdef SS(t):\n\t\tt1 = np.sum(np.sign(np.abs(yi)-t)*ti)\n\t\tt2 = np.sum(np.minimum(yi**2,np.ones(yi.shape)*t**2))\n\t\tt3 = -t*np.sum(np.abs(yi)==t)\n\t\t# print t1,t2,t3\n\t\treturn np.sum([t1,t2,t3])\n\n\ttrsh = minimize_scalar(SkellamObjective,bounds=[t_min,t_max]).x\n\t# print \"threshold\", trsh\n\tdef soft_threshold(y):\n\n\t\ta = np.absolute(y) - trsh\n\t\tsgn = np.sign(y)\n\t\tif a <= 0:\n\t\t\treturn 0\n\t\telse:\n\t\t\treturn sgn*a\n\n\t# sigma_x = np.std(yi)\n\t# def adjusted_threshold(y,t):\n\t# \tif np.abs(y) >= (np.sqrt(2)*t)/sigma_x:\n\t# \t\treturn -np.sign(y)*(np.sqrt(2)*t)/sigma_x\n\t# \telse:\n\t# \t\treturn -y\n\n\t# thresholded = np.zeros(yi.shape)\n\t# for i in range(yi.shape[0]):\n\t# \tthresholded[i] = adjusted_threshold(y=yi[i],t=ti[i])\n\t# soft threshold:\n\tthresholded = np.vectorize(soft_threshold)(yi)\n\treturn thresholded",
  "def multiscale_function_apply(func,wavelet_name,max_level=None):\n\n\tdef multiscale_apply(ys,):\n\t\t# print len(ys)\n\t\twl = pywt.Wavelet(wavelet_name)\n\t\t\n\t\tif max_level is None:\n\t\t\tlevel = pywt.dwt_max_level(len(ys),wl)\n\t\telse:\n\t\t\tlevel = max_level\n\n\t\tcoeffs_list = []\n\t\ta = ys\n\t\tfor i in range(level):\n\t\t\ta, d = pywt.dwt(a, wavelet=wl)\n\t\t\tf = func(approx =a, detail=d)\n\t\t\tcoeffs_list.append(f)\n\t\tcoeffs_list.append(a)\n\t\tcoeffs_list.reverse()\n\t\treturn coeffs_list\n\n\treturn multiscale_apply",
  "def SkellamShrink(data,max_level=-1):\n\t'''\n\tBased on: Skellam Shrinkage: Wavelet-Based Intensity Estimation for Inhomogeneous Poisson data\n\tRelated papers: Fast Haar-Wavelet denoising of multidimensional fluorescence microscopy data\n\t'''\n\n\tmode = \"periodic\"\n\twl = \"haar\"\n\tn = data.shape[0]\n\tJ = np.ceil(np.log2(n))\n\t\n\tdef identify(approx,detail):\n\t\treturn detail\n\n\tdef skellam(approx,detail):\n\t\treturn SkellamThresh(wavelet_coefs=detail,scaling_coefs=approx)\n\n\tif max_level == -1 :\n\t\tf = multiscale_function_apply(func=skellam,wavelet_name=wl)\n\telse:\n\t\tf = multiscale_function_apply(func=skellam,wavelet_name=wl,max_level=max_level)\n\tdwt = f(data)\n\treturn pywt.waverec(dwt,wavelet=wl,mode=mode)",
  "def plot_test_functions():\n\tfig, [[ax1,ax2],[ax3,ax4]] = plt.subplots(2,2)\n\t\n\txs,ys = blocks()\n\tax1.plot(xs,ys)\n\tax1.set_title(\"Original Blocks\")\n\t\n\txs,ys = bumps()\n\tax2.plot(xs,ys)\n\tax2.set_title(\"Original Bumps\")\n\n\txs,ys = heavisine()\n\tax3.plot(xs,ys)\n\tax3.set_title(\"Original HeaviSine\")\n\n\txs,ys = doppler()\n\tax4.plot(xs,ys)\n\tax4.set_title(\"Original Doppler\")\n\n\tplt.show()",
  "def plot_noisy_test_functions():\n\tN = 2048\n\tnoise = np.random.normal(loc=0,scale=1.0,size=N)\n\tfig, [[ax1,ax2],[ax3,ax4]] = plt.subplots(2,2)\n\t\n\txs,ys = blocks()\n\tax1.plot(xs,ys+noise)\n\tax1.set_title(\"Noisy Blocks (noise~N(0,1)\")\n\t\n\txs,ys = bumps()\n\tax2.plot(xs,ys+noise)\n\tax2.set_title(\"Noisy Bumps (noise~N(0,1)\")\n\n\txs,ys = heavisine()\n\tax3.plot(xs,ys+noise)\n\tax3.set_title(\"Noisy HeaviSine (noise~N(0,1)\")\n\n\txs,ys = doppler()\n\tax4.plot(xs,ys+noise)\n\tax4.set_title(\"Noisy Doppler (noise~N(0,1)\")\n\n\tplt.show()",
  "def plot_denoised_functions():\n\tN = 2048\n\tnoise = np.random.normal(loc=0,scale=1.0,size=N)\n\tfig, [[ax1,ax2],[ax3,ax4]] = plt.subplots(2,2)\n\taxarr = [ax1,ax2,ax3,ax4]\n\t\n\tfor i,f in enumerate([blocks,bumps,heavisine,doppler]):\n\t\txs,ys = f()\n\t\tys = ys + noise\n\t\tdenoised = SUREShrink(ys)\n\t\taxarr[i].plot(xs,denoised)\n\t\taxarr[i].set_title(\"Denoised {}\".format(f.__name__))\n\tplt.show()",
  "def K(t):\n\t\treturn (1 + np.sign(t))/2.0",
  "def K(t):\n\t\treturn (1 + np.absolute(t))**-4",
  "def SURE(t):\n\t\treturn d-2*np.sum(np.abs(coefs) <= t) + np.sum(np.minimum(coefs,t)**2)",
  "def soft_threshold(y):\n\n\t\ta = np.absolute(y) - trsh\n\t\tsgn = np.sign(y)\n\t\tif a <= 0:\n\t\t\treturn 0\n\t\telse:\n\t\t\treturn sgn*a",
  "def SkellamObjective(t):\n\t\t\tt1 = np.sum(np.sign(np.abs(yi)-t)*ti)\n\t\t\tt2 = np.sum(np.minimum(yi**2,np.ones(yi.shape)*t**2))\n\t\t\tt3 = -t*np.sum(np.abs(yi)==t)\n\t\t\t# print t1,t2,t3\n\t\t\treturn np.sum([t1,t2,t3])",
  "def SS(t):\n\t\tt1 = np.sum(np.sign(np.abs(yi)-t)*ti)\n\t\tt2 = np.sum(np.minimum(yi**2,np.ones(yi.shape)*t**2))\n\t\tt3 = -t*np.sum(np.abs(yi)==t)\n\t\t# print t1,t2,t3\n\t\treturn np.sum([t1,t2,t3])",
  "def soft_threshold(y):\n\n\t\ta = np.absolute(y) - trsh\n\t\tsgn = np.sign(y)\n\t\tif a <= 0:\n\t\t\treturn 0\n\t\telse:\n\t\t\treturn sgn*a",
  "def multiscale_apply(ys,):\n\t\t# print len(ys)\n\t\twl = pywt.Wavelet(wavelet_name)\n\t\t\n\t\tif max_level is None:\n\t\t\tlevel = pywt.dwt_max_level(len(ys),wl)\n\t\telse:\n\t\t\tlevel = max_level\n\n\t\tcoeffs_list = []\n\t\ta = ys\n\t\tfor i in range(level):\n\t\t\ta, d = pywt.dwt(a, wavelet=wl)\n\t\t\tf = func(approx =a, detail=d)\n\t\t\tcoeffs_list.append(f)\n\t\tcoeffs_list.append(a)\n\t\tcoeffs_list.reverse()\n\t\treturn coeffs_list",
  "def identify(approx,detail):\n\t\treturn detail",
  "def skellam(approx,detail):\n\t\treturn SkellamThresh(wavelet_coefs=detail,scaling_coefs=approx)",
  "def get_ellipse_contour(input_image):\n\n\toutput_image = input_image\n\n\t# print np.min(output_image)\n\t# print np.max(output_image)\n\n\toutput_image = (255*(output_image-np.min(output_image))/float(np.max(output_image)))\n\toutput_image = output_image.astype(np.uint8)\n\toutput_image = cv2.Canny(output_image,30,100)\n\n\n\t# dialation and\n\tdialate_kernel = np.ones((7,7),np.uint8)\n\terode_kernel = np.ones((4,4),np.uint8)\n\n\t\n\tfor i in range(0,3):\n\n\t\toutput_image = cv2.dilate(output_image,dialate_kernel)\n\t\toutput_image = cv2.erode(output_image,erode_kernel)\n\t\t\n\t#find contours of each image:\n\toutput_image,contours, hierarchy = cv2.findContours(output_image,cv2.RETR_TREE ,cv2.CHAIN_APPROX_NONE )\n\n\t#find areas of the contours:\n\tcontours_area = [(cnt,cv2.contourArea(cnt)) for cnt in contours]\n\tareas = [x[1] for x in contours_area]\n\tlargest_contour = [cnt for (cnt,area) in contours_area if area == max(areas) ][0]\n\n\t# ellipse = cv2.fitEllipse(cnt)\n\t# print \"ELLIPSE:\", ellipse\n\t# cv2.ellipse(img,ellipse,(0,255,0),1)\n\n\n\thull = cv2.convexHull(largest_contour)\n\txs = hull[:,0,0]\n\tys = hull[:,0,1]\n\n\treturn np.asarray([xs,ys]).T",
  "def get_images():\n\tparticles = list(datafile[FOLDERPATH].keys())\n\tregex = re.compile(TAG)\n\t#laser zero order\n\toutp = []\n\tfor particle in particles:\n\t\ttry:\n\t\t\tmeasurements= list(datafile[FOLDERPATH][particle].keys())\n\t\t\tfor m in measurements:\n\t\t\t\tif regex.match(m):\n\t\t\t\t\toutp.append( datafile[FOLDERPATH][particle][m])\n\t\texcept Exception as e:\n\t\t\tprint(e)\n\t\t\tprint(\"Skipping:\", particle)\n\n\treturn outp",
  "def get_contour_area(contour):\n\treturn skimage.measure.moments(contour)[0,0]",
  "def make_vertex_mask(vertices,image_shape):\n\tpolygonPath = Path(vertices)\n\tmask = np.zeros(image_shape)\n\tfor i in range(image_shape[0]):\n\t\tfor j in range(image_shape[1]):\n\t\t\tif polygonPath.contains_points([[j,i]]): #ordering of indices is wrong way around to usual, but works!\n\t\t\t\tmask[i,j] = 1\n\treturn mask",
  "def get_bounding_box(vertices):\n\txs = vertices[:,0]\n\tys = vertices[:,1]\n\n\txmin,xmax= np.min(xs),np.max(xs)\n\tymin,ymax = np.min(ys),np.max(ys)\n\n\toutp = np.asarray([[xmin,ymin],[xmin,ymax],[xmax,ymax],[xmax,ymin]])\n\treturn outp,[xmin,ymin,xmax,ymax]",
  "def apply_snake(image,contour):\n\t#contour - acts as best guess\n\tcontour_xs = contour[:,0]\n\tcontour_ys = contour[:,1]\n\tinit = np.asarray([contour_xs,contour_ys]).T\n\tsnake = skimage.segmentation.active_contour(image, init, alpha=0.005, beta=0.1, w_line=1e6, w_edge=1e7, gamma=0.01, bc='periodic', max_px_move=1.0, max_iterations=2500, convergence=0.1)\n\tsnake_xs,snake_ys = snake[:,0],snake[:,1]\n\treturn snake",
  "def run_watershed(image,markers):\n\treturn skimage.segmentation.watershed(image, markers, connectivity=1, offset=None, mask=None, compactness=0, watershed_line=False)",
  "def kmeans(image,nsegments):\n\treturn skimage.segmentation.slic(image, n_segments=100, compactness=10.0, max_iter=10, sigma=0, spacing=None, multichannel=True, convert2lab=False, enforce_connectivity=False, min_size_factor=0.5, max_size_factor=3, slic_zero=False)",
  "def plot_multiscale(images,figname,valid = None):\n\tfig, axarr = plt.subplots(2,2*len(images), figsize=(36,4))\n\tfor i,img in enumerate(images):\n\t\taxarr[0][2*i].imshow(img,cmap=\"gray\")\n\t\t\n\t\tfor x in range(img.shape[0]):\n\t\t\txs = img[x,:]\n\t\t\taxarr[1][2*i].plot(xs)\n\t\t\n\t\tfor y in range(img.shape[1]):\n\t\t\tys = img[:,y]\n\t\t\taxarr[0][2*i+1].plot(ys)\n\t\t\n\tif valid != None:\n\t\tfig.suptitle(\"Matched pattern? : {0}\".format(valid))\n\n\tplt.savefig(\"{0}_pyramid\".format(figname))\n\tplt.close(fig)\n\t\n\t# fig.close()\n\treturn",
  "def get_largest_binary_convex_hull(image):\n\t#assume image is binary\n\treturn skimage.morphology.convex_hull_object(image)",
  "def get_lowest_level_set(image):\n\tlevel_set = np.zeros(image.shape)\n\tlevel_set[image < 0.25] = 1\n\treturn level_set",
  "def process_image(image,figname):\n\tcontour = get_ellipse_contour(image)\n\tellipse = cv2.fitEllipse(contour)\n\n\tbbox,boxlims = get_bounding_box(contour)\n\tmask =make_vertex_mask(bbox,image.shape)\n\t\n\tcontour_xs = contour[:,0]\n\tcontour_ys = contour[:,1]\n\n\tmasked_image = mask*image\n\tmasked_image = masked_image[boxlims[1]+1:min(80,boxlims[3]),boxlims[0]+1:min(80,boxlims[2])] \n\n\tk = np.sqrt(2)\n\tsigma = 1.0\n\tsigmas = [sigma,sigma*k**2,sigma*k**3,sigma*k**4,sigma*k**5]\n\tgaussians = [skimage.filters.gaussian(masked_image,s) for s in sigmas]\n\tDoG = []\n\tfor i in range(1,len(gaussians)):\n\t\tDoG.append(gaussians[i]-gaussians[i-1])\n\n\tprint(\"DoGs-------------------------\", len(DoG))\n\tfor d in DoG:\n\t\tprint(d)\n\tDoG = [d + np.min(d) for d in DoG]\n\tDoG = [d-np.min(d) for d in DoG]\n\tDoG = [old_div(d,np.max(d)) for d in DoG]\n\n\tprod = DoG[1]*DoG[2]*DoG[3]\n\tprod = prod - np.min(prod)\n\tprod = old_div(prod,np.max(prod))\n\n\tlevel_set = get_lowest_level_set(prod)\n\tparticle_contour = get_ellipse_contour(level_set)\n\tparticleMask = make_vertex_mask(particle_contour,prod.shape)\n\tnp_only = prod-prod*((get_largest_binary_convex_hull(level_set)-1)*-1)\n\n\tconvolved = skimage.feature.canny(np_only,1,0.2,0.7)#correlate2d(np_only,npmask)\n\t\n\tconvolved = skimage.morphology.binary_closing(convolved)\n\tconvolved = skimage.morphology.binary_dilation(convolved)\n\t\n\n\tedge_segmented = skimage.measure.label(convolved)\n\n\tfill_segmented = np.zeros(edge_segmented.shape)\n\tfill_segmented[edge_segmented==0] = 1\n\tfill_segmented = skimage.measure.label(fill_segmented)\n\n\tfill_segments = separate_segments(fill_segmented)\n\n\t# edge_segments = separate_segments(edge_segmented)\n\t# for i in range(len(edge_segments)):\n\t\t\n\t# \t(cx,cy) = CoM_image(edge_segments[i])\n\t# \taxarr[0][i].imshow(edge_segments[i],cmap=\"gray\")\n\t# \tcv2.circle(edge_segments[i],(cx,cy),1,(255,255,0),1)\n\t\t\n\tdef valid_segment(img, cx,cy,max_radius=5):\n\t\tfor x in range(img.shape[0]):\n\t\t\tfor y in range(img.shape[1]):\n\t\t\t\tif img[x,y] > 0:\n\t\t\t\t\tif  (x - cx)**2 + (y-cy)**2 < max_radius**2:\n\t\t\t\t\t\tpass \n\t\t\t\t\telse:\n\t\t\t\t\t\treturn False\n\t\treturn True\n\n\tdef nonzero_pixels(image):\n\t\tcount = 0\n\t\tfor i in range(image.shape[0]):\n\t\t\tfor j in range(image.shape[1]):\n\t\t\t\tif image[i,j] > 0 :\n\t\t\t\t\tcount = count + 1\n\t\treturn count\n\n\tdef has_valid_segment(image,max_radius = 5):\n\t\tseparated = separate_segments(image)\n\t\tvalid_segments = []\n\n\t\tfor i in range(len(separated)):\n\t\t\timg = separated[i]\n\t\t\t(cx,cy) = CoM_image(img)\n\t\t\tif valid_segment(img,cx,cy,max_radius) and nonzero_pixels(img)>4:\n\t\t\t\tys,xs = draw.circle_perimeter(cy,cx, max_radius)\n\t\t\t\tfor (x,y) in zip(xs,ys):\n\t\t\t\t\tif (x >=0 and x < img.shape[0]) and (y >=0 and y < img.shape[1]):\n\t\t\t\t\t\timg[x,y] = 1\n\t\t\t\t# img[xs,ys] = 1 \n\t\t\t\tvalid_segments.append(img)\n\n\t\treturn valid_segments\n\n\tfilled_valid_segments = has_valid_segment(fill_segmented, 5)\n\tedge_valid_segments = has_valid_segment(edge_segmented,8)\n\n\tif len(filled_valid_segments) > 0:\n\t\tfilled_valid = np.sum(np.asarray(filled_valid_segments),axis=0)\n\telse:\n\t\tfilled_valid = np.zeros(masked_image.shape)\n\n\tif len(edge_valid_segments) > 0:\n\t\tedge_valid = np.sum(np.asarray(edge_valid_segments),axis=0)\n\telse:\n\t\tedge_valid = np.zeros(masked_image.shape)\n\n\n\n\timages = [masked_image] + DoG + [prod,np_only,edge_segmented, fill_segmented,filled_valid, edge_valid]\n\tplot_multiscale(images,figname,valid=\"Filled: {0},Edge: {1}\".format(len(filled_valid_segments) > 0, len(edge_valid_segments) > 0))\n\n\treturn images",
  "def zero_pad(img,xdim,ydim):\n\tif img.shape[0] < xdim or img.shape[1] < ydim:\n\t\toutp = np.zeros((xdim,ydim))\n\t\toutp[0:img.shape[0],0:img.shape[1]] = img\n\t\treturn outp\n\telif img.shape[0] == xdim and img.shape[1] == ydim:\n\t\treturn img\n\telse:\n\t\traise ValueError(\"Failed!\")",
  "def separate_segments(image):\n\timage = image.astype(int)\n\timage = image - np.min(image)\n\tassert(np.min(image)==0)\n\tsegments = []*np.max(image)\n\t# print segments\n\n\tfor i in range(np.max(image)+1):\n\t\tx = np.zeros(image.shape)\n\t\tx[image==i] = 1\n\t\tsegments.append(x)\n\treturn segments",
  "def CoM_image(image):\n\n\tit = 0\n\tjt = 0\n\tnum = 0\n\tfor i in range(image.shape[0]):\n\t\tfor j in range(image.shape[1]):\n\t\t\tif image[i,j] > 0:\n\t\t\t\tit = it + i\n\t\t\t\tjt = jt + j\n\t\t\t\tnum = num + 1\n\t# num = float(image.shape[0]*image.shape[1])\n\tnum = float(num)\n\tcx = int(round(old_div(it,num)))\n\tcy = int(round(old_div(jt,num)))\n\n\t# M = cv2.moments(image)\n\t# print M\n\t# cx = int(M['m10']/float(M['m00']))\n\t# cy = int(M['m01']/float(M['m00']))\n\treturn (cx,cy)",
  "def main():\n\timages = get_images()\n\n\timages = [image[50:150,750:850] for image in images]\n\t\n\t# i=49\n\t# image = images[i]\n\t# test_img = process_image(image,\"fig_test\",-1,-1)\n\t# xdim,ydim = test_img[0].shape[0],test_img[0].shape[1]\n\t# xdim = image.shape[0]\n\t# ydim = image.shape[1]\n\tlimit = len(images)\n\tmultiscale_images = []\n\t\t\n\tfor i,image in enumerate(images):\n\t\tif i < 2:\n\t\t\tpass\n\t\telif i < limit:\n\t\t\toutput_img =process_image(image,\"fig{}\".format(i))\n\t\t\tmultiscale_images=multiscale_images + [output_img]\n\n\txmax = 0\n\tymax = 0\n\tfor imgs in multiscale_images:\n\t\tdimx, dimy = imgs[0].shape[0],imgs[0].shape[1]\n\t\txmax,ymax = max(dimx,xmax),max(dimy,ymax)\n\t\tfor i in imgs:\n\t\t\tassert((i.shape[0],i.shape[1])==(dimx,dimy))",
  "def valid_segment(img, cx,cy,max_radius=5):\n\t\tfor x in range(img.shape[0]):\n\t\t\tfor y in range(img.shape[1]):\n\t\t\t\tif img[x,y] > 0:\n\t\t\t\t\tif  (x - cx)**2 + (y-cy)**2 < max_radius**2:\n\t\t\t\t\t\tpass \n\t\t\t\t\telse:\n\t\t\t\t\t\treturn False\n\t\treturn True",
  "def nonzero_pixels(image):\n\t\tcount = 0\n\t\tfor i in range(image.shape[0]):\n\t\t\tfor j in range(image.shape[1]):\n\t\t\t\tif image[i,j] > 0 :\n\t\t\t\t\tcount = count + 1\n\t\treturn count",
  "def has_valid_segment(image,max_radius = 5):\n\t\tseparated = separate_segments(image)\n\t\tvalid_segments = []\n\n\t\tfor i in range(len(separated)):\n\t\t\timg = separated[i]\n\t\t\t(cx,cy) = CoM_image(img)\n\t\t\tif valid_segment(img,cx,cy,max_radius) and nonzero_pixels(img)>4:\n\t\t\t\tys,xs = draw.circle_perimeter(cy,cx, max_radius)\n\t\t\t\tfor (x,y) in zip(xs,ys):\n\t\t\t\t\tif (x >=0 and x < img.shape[0]) and (y >=0 and y < img.shape[1]):\n\t\t\t\t\t\timg[x,y] = 1\n\t\t\t\t# img[xs,ys] = 1 \n\t\t\t\tvalid_segments.append(img)\n\n\t\treturn valid_segments",
  "def Fraction(Signal):\n\t\"\"\"\n\tFunction takes a list of numbers. Returns to fraction of inter-element changes follwed by a change in the same direction.\n\t\"\"\"\n\tSame,Different=0,0\n\tfor i in range(len(Signal))[1:-1]:\n\t\tif Signal[i]>=Signal[i-1]:\n\t\t\tA=1\n\t\telse:\n\t\t\tA=0\n\t\tif Signal[i+1]>=Signal[i]:\n\t\t\tB=1\n\t\telse:\n\t\t\tB=0\n\t\tif A==B:\n\t\t\tSame+=1\n\t\telse:\n\t\t\tDifferent+=1\n\treturn float(Same)/(Same+Different)",
  "def Sigmoid(x,O,S):\n\t\"\"\"\n\tSigmoid function defiend by offset O and scale S\n\t\"\"\"\n\treturn 1./(1.+np.exp(old_div(-(x-O),S)))",
  "def Grad(x,y):\n\t\"\"\"\n\tEstimates gradient of y wrt x\n\t\"\"\"\n\tOutput=(np.array(np.array(y).tolist()+[y[-1],y[-2]]))-(np.array([y[1],y[0]]+np.array(y).tolist()))\n\tOutput/=(np.array(np.array(x).tolist()+[x[-1],x[-2]]))-(np.array([x[1],x[0]]+np.array(x).tolist()))\n\treturn Output[1:-1]",
  "def Run(Signal):\n\t\"\"\"\n\tMain funtion. Returns smoothed Signal\n\t\"\"\"\n\n\t#--Quickly sample parameter space---\n\tSmooth=[0]\n\tScore=[Fraction(Signal)]\n\tn=1\n\twhile n<len(Signal):\n\t\tSmooth.append(n)\n\t\tScore.append(Fraction(ndimf.gaussian_filter(Signal,n)))\n\t\tn*=2\n\n\t#--Interpolate parameter space\n\ty=scint.interp1d(Smooth,Score,kind='cubic')(np.linspace(0,np.max(Smooth),1000))\n\tx=np.linspace(0,np.max(Smooth),1000)\n\n\t#--Find elbow--\n\n\tG=Grad(x,y)\n\tGG=Grad(x,G)\n\n\tMax=np.argmax(np.abs(GG))\n\tPoly=np.polyfit(x[Max-1:Max+2],np.abs(GG)[Max-1:Max+2],2)\n\tMax=old_div(-Poly[1],(2*Poly[0]))\n\n\t#--Repeat porces on smaller, more accurate region--\n\n\tSmooth=np.linspace(0,2*Max,len(Score))\n\tScore=[]\n\tfor i in Smooth:\n\t\tScore.append(Fraction(ndimf.gaussian_filter(Signal,i)))\n\tScore=np.array(Score)\n\n\tG=Grad(Smooth,Score)\n\tGG=Grad(Smooth,G)\n\n\tMax=np.argmax(np.abs(GG))\n\tPoly=np.polyfit(x[Max-1:Max+2],np.abs(GG)[Max-1:Max+2],2)\n\tMax=old_div(-Poly[1],(2*Poly[0]))\n\n\t#---Perform smooth---\n\n\treturn ndimf.gaussian_filter(Signal,Max*2)",
  "def process_datafile_spectrum(h5object):\n    \"\"\"Process a spectrum for a h5file dataset\"\"\"\n    Data = np.array(h5object)\n    if 'variable_int_enabled' in list(h5object.attrs.keys()):\n        variable_int = h5object.attrs['variable_int_enabled']\n    else:\n        variable_int =False\n    if 'averaging_enabled' in list(h5object.attrs.keys()):\n        if h5object.attrs['averaging_enabled']:\n            Data = np.mean(Data,axis = 0)\n    if ((variable_int == True) and #Check for variable integration time and that the background_int and reference_int are not none\n                ((h5object.attrs['background_int'] != h5object.attrs['integration_time'] \n                    and (h5object.attrs['background_int'] != None))\n                or (h5object.attrs['reference_int'] != h5object.attrs['integration_time'] \n                    and (h5object.attrs['reference_int'] != None)))):\n        if h5object.attrs['background_int'] != None:\n            if h5object.attrs['reference_int'] != None:\n                Data = (old_div((Data-(h5object.attrs['background_constant']+h5object.attrs['background_gradient']*h5object.attrs['integration_time'])), \n                                (old_div((h5object.attrs['reference']-(h5object.attrs['background_constant']+h5object.attrs['background_gradient']*h5object.attrs['reference_int']))\n                                *h5object.attrs['integration_time'],h5object.attrs['reference_int']))))\n            else:\n                Data = Data-(h5object.attrs['background_constant']+h5object.attrs['background_gradient']*h5object.attrs['integration_time'])\n    else:\n        if 'background' in list(h5object.attrs.keys()):\n            if len(Data) == len(np.array(h5object.attrs['background'])):\n                Data = Data - np.array(h5object.attrs['background'])\n            if 'reference' in list(h5object.attrs.keys()):\n                if len(Data) == len(np.array(h5object.attrs['reference'])):\n                    Data = old_div(Data,(np.array(h5object.attrs['reference']) - np.array(h5object.attrs['background'])))\n    if 'absorption_enabled' in list(h5object.attrs.keys()):\n        if h5object.attrs['absorption_enabled']:\n            Data = np.log10(old_div(1,np.array(Data)))\n    return Data",
  "def wavelength2wavenumber(wavelengths,laser_wavelength):\n    \"\"\"Input in nm output in cm^-1 \"\"\"\n    return 1.0/(laser_wavelength*1E-7)-(1.0/(wavelengths*1E-7))",
  "def wavenumber2wavelength(wavenumbers,laser_wavelength):\n    \"\"\"Input in nm and cm^-1 output in nm \"\"\"\n    return 1.0/(1.0/(laser_wavelength)-(wavenumbers*1E-7))",
  "def makeDir(dirName):\n    if dirName not in os.listdir('.'):\n        os.mkdir(dirName)",
  "def getCol(n, dSetSize, cmap, rev = False):    \n    cIndex = n*256/dSetSize\n    #print(cIndex)\n    if rev == True:\n        cIndex = 256 - cIndex\n    color = cmap(int(cIndex))\n    return color",
  "def trapNumInt(x, y):\n    \n    for n, i in enumerate(x):\n        if n == 0:\n            area = 0\n            continue\n\n        h = i - x[n-1]\n        y1 = y[n]\n        y0 = y[n-1]\n        yAvg = np.average([y0, y1])\n        aI = yAvg*h\n        area += aI\n    \n    return area",
  "def lorentzian(x, height, center, fwhm):\n    I = height\n    x0 = center\n    gamma = fwhm/2\n    numerator = gamma**2\n    denominator = (x - x0)**2 + gamma**2\n    quot = numerator/denominator\n    \n    y = I*quot\n    return y",
  "def gaussian(x, height, center, fwhm, offset = 0):\n\n    '''Gaussian as a function of height, centre, fwhm and offset'''\n    a = height\n    b = center\n    c = fwhm\n\n    N = 4*np.log(2)*(x - b)**2\n    D = c**2\n    F = -N/D\n    E = np.exp(F)\n    y = a*E\n    y += offset\n\n    return y",
  "def baseline_als(y, lam, p, niter=10):\n    L = len(y)\n    D = sparse.diags([1,-2,1],[0,-1,-2], shape=(L,L-2))\n    w = np.ones(L)\n    for i in range(niter):\n        W = sparse.spdiags(w, 0, L, L)\n        Z = W + lam * D.dot(D.transpose())\n        z = spsolve(Z, w*y)\n        w = p * (y > z) + (1-p) * (y < z)\n    return z",
  "def nmToEv(nm):\n    wavelength = nm*1e-9\n    c = 299792458\n    h = 6.62607015e-34\n    joules = h*c/wavelength\n    e = 1.60217662e-19\n    eV = joules / e\n    return eV",
  "def evToNm(eV):\n    e = 1.60217662e-19\n    joules = eV * e\n    c = 299792458\n    h = 6.62607015e-34\n    wavelength = h*c/joules\n    nm = wavelength * 1e9\n    return nm",
  "class ExtinctionSpectrum:\n    def makeNull(self):\n        self.dimerCenter = np.nan\n        self.dimerHeight = np.nan\n        self.dimerFwhm = np.nan\n        self.chainCenter = np.nan\n        self.chainHeight = np.nan\n        self.chainFwhm = np.nan\n\n    def debug(self):\n        self.debug = True\n\n    def __init__(self, x, y, startWl = 420, endWl = 950, initSpec = None):\n        self.makeNull()\n        \n        if x is None:\n            return\n\n        self.xRaw = mpf.removeNaNs(x)\n        self.yRaw = mpf.removeNaNs(y)\n\n        self.startWl = startWl\n        self.endWl = endWl\n        self.xTrunc, self.yTrunc = mpf.truncateSpectrum(self.xRaw, self.yRaw, startWl = self.startWl, finishWl = self.endWl)\n        self.ySmooth = mpf.butterLowpassFiltFilt(self.yTrunc, cutoff = 1100, fs = 70000)\n        self.debug = False\n        self.specMaxWl = None\n\n        if initSpec is not None:            \n            initX, initY, initYSmooth = initSpec.xTrunc, initSpec.yTrunc, initSpec.ySmooth\n            initAunpWl = initX[initYSmooth.argmax()]\n\n            if not np.all(initX == self.xTrunc):\n                initY = np.interp(self.xTrunc, initX, initY)\n                initYSmooth = mpf.butterLowpassFiltFilt(initY)            \n\n            aunpIndex = initYSmooth.argmax()\n            initAunpWl = self.xTrunc[aunpIndex]\n\n            initY -= initYSmooth[-1] - self.ySmooth[-1]\n            initYSmooth -= initYSmooth[-1] - self.ySmooth[-1]\n\n            scaling = self.ySmooth[aunpIndex]/initYSmooth[aunpIndex]\n\n            self.aunpSpec = initY*scaling\n            self.ySub = self.yTrunc - initY*scaling\n            self.ySubSmooth = self.ySmooth - initYSmooth*scaling\n            \n        else:\n            self.aunpSpec = None\n            self.ySub = self.yTrunc\n        \n    def fitAggPeaks(self, dimerWl = None, plot = False):\n        '''\n        InitY is monomeric AuNP spectrum, scaled if necessary. Must have same length as x and y\n        '''\n        x, y = self.xTrunc, self.ySub\n        ySmooth = mpf.butterLowpassFiltFilt(y, cutoff = 1200, fs = 65000)\n        mindices = mpf.detectMinima(ySmooth)\n\n        if plot == True:\n            plt.plot(x, y)\n            plt.plot(x, ySmooth)\n            plt.show()\n\n        mindices = mindices[np.where(x[mindices] > 500)]\n        startMindex = mindices[0] if len(mindices) > 0 else abs(x-500).argmin()\n        #startMindex = int(np.round(np.average([startMindex, abs(x-600).argmin()])))\n\n        xFit, yFit, yFitSmooth = x[startMindex:], y[startMindex:], ySmooth[startMindex:]\n        yFit -= yFitSmooth.min()\n        yFitSmooth -= yFitSmooth.min()\n        self.specMaxWl = xFit[yFitSmooth.argmax()]\n\n        if dimerWl is None:\n            initDimerWl = self.specMaxWl\n            dimerIndex = abs(xFit-initDimerWl).argmin()\n            initDimerHeight = yFitSmooth.max()\n        else:\n            initDimerWl = dimerWl\n            dimerIndex = abs(xFit-initDimerWl).argmin()\n            initDimerHeight = yFitSmooth[dimerIndex]\n\n        yOffset = -yFitSmooth.min()\n        yFit += yOffset\n        initDimerHeight += yOffset\n        yFitSmooth += yOffset\n\n        xFit = -nmToEv(xFit)\n        xFitNm = evToNm(-xFit)\n        initDimerWl = xFit[dimerIndex]\n\n        try:\n            dimerHalfMaxDex = abs(yFitSmooth[:dimerIndex] - initDimerHeight/2).argmin()\n        except:\n            if self.debug == True:\n                print(dimerWl, initDimerWl, dimerIndex)\n            return\n\n        initDimerFwhm = 2*(initDimerWl - xFit[dimerHalfMaxDex])\n        initDimerFwhmEv = nmToEv(xFit[dimerIndex] - initDimerFwhm/2) - nmToEv(xFit[dimerIndex] + initDimerFwhm/2)\n        #initDimerFwhmEv = abs(xFit[dimerHalfMaxDex] - xFit[2*dimerIndex - dimerHalfMaxDex])\n        \n        dimerInit = lorentzian(xFit, initDimerHeight, initDimerWl, initDimerFwhm)\n\n        dimerInit -= dimerInit[0] - yFitSmooth[0]\n        dimerInit *= initDimerHeight/dimerInit.max()\n\n        chainInit = yFitSmooth - dimerInit\n        initChainIndex = dimerIndex + chainInit[dimerIndex:].argmax()\n\n        if plot == True:\n            plt.plot(xFit, yFit)\n            plt.plot(xFit[dimerIndex:initChainIndex], chainInit[dimerIndex:initChainIndex], zorder = 10)\n            plt.plot(xFit, dimerInit)\n            plt.plot(xFit, chainInit)\n            plt.plot(xFit[initChainIndex], chainInit[initChainIndex], 'o')\n            #plt.plot(xFit[chainHalfMaxDex], chainInit[chainHalfMaxDex], 'ko')\n            plt.plot(xFit, dimerInit + chainInit, 'r--')\n            plt.show()\n\n        aggMod = LorentzianModel(prefix = 'Dimer_')\n        aggModPars = aggMod.guess(dimerInit, x = xFit)\n        aggModPars['Dimer_center'].set(initDimerWl, min = initDimerWl-initDimerFwhm/2, max = initDimerWl+initDimerFwhm/2)\n        aggModPars['Dimer_sigma'].set(initDimerFwhm/2)\n        aggModPars['Dimer_height'].set(initDimerHeight*2/3, max = initDimerHeight, min = 0)\n        aggModPars['Dimer_amplitude'].set(min = 0)\n\n        if initChainIndex < dimerIndex:\n            chainMode = False\n        else:\n            chainMode = True\n            initChainWl, initChainHeight = xFit[initChainIndex], chainInit[initChainIndex]\n\n            try:\n                chainHalfMaxDex = dimerIndex + abs(chainInit[dimerIndex:initChainIndex] - initChainHeight/2).argmin()\n            except:\n                chainHalfMaxDex = np.average([initChainIndex, dimerHalfMaxDex])               \n\n                if self.debug == True:\n                    print(initChainIndex, chainInit[dimerIndex:initChainIndex])\n                    plt.plot(xFitNm, yFit)\n                    plt.plot(xFitNm[dimerHalfMaxDex], yFitSmooth[dimerHalfMaxDex], 'o')\n                    plt.plot(xFitNm, dimerInit)\n                    plt.plot(xFitNm, chainInit)\n                    plt.plot(xFitNm[dimerIndex], chainInit[dimerIndex], 'ro')\n                    plt.plot(xFitNm[initChainIndex], chainInit[initChainIndex], 'ko')\n                    plt.show()\n                chainMode = False\n\n            initChainFwhm = 2*(initChainWl - xFit[chainHalfMaxDex])\n            try:\n                #initChainFwhmEv = abs(xFit[chainHalfMaxDex] - xFit[max(2*initChainIndex - chainHalfMaxDex, len(xFit) - 1)])\n                initChainFwhmEv = nmToEv(initChainWl - initChainFwhm/2) - nmToEv(initChainWl + initChainFwhm/2)\n            except:\n                if self.debug == True:\n                    print(chainHalfMaxDex, 2*initChainIndex - chainHalfMaxDex)\n                chainMode = False\n\n            if chainMode == True:\n                chainInit = lorentzian(xFit, initChainHeight, initChainWl, initChainFwhm)\n                gModC = LorentzianModel(prefix = 'Chain_')\n                parsC = gModC.guess(chainInit, x = xFit)\n                parsC['Chain_sigma'].set(initChainFwhm/2)\n                parsC['Chain_height'].set(initChainHeight*2/3, max = initChainHeight, min = 0)\n                parsC['Chain_amplitude'].set(min = 0)\n\n                aggMod += gModC            \n                aggModPars.update(parsC)\n\n                aggModPars['Chain_center'].set(initChainWl, min = initDimerWl)\n\n        aggFit = aggMod.fit(yFit, aggModPars, x = xFit)\n        xTruncEv = evToNm(-self.xTrunc)\n        yAggFit = aggFit.eval(x = xTruncEv)\n        finalParams = aggFit.params\n        comps = aggFit.eval_components(x = xTruncEv)\n\n        xFit = evToNm(-xFit)\n\n        if plot == True:\n            plt.plot(self.xTrunc, self.ySub, 'k')\n            plt.plot(self.xTrunc, yAggFit, 'r')\n            for comp in comps.keys():\n                print(comp)\n                plt.plot(self.xTrunc, comps[comp], label = comp)\n            plt.legend(loc = 0)\n            plt.xlim(self.startWl, self.endWl)\n            plt.xlabel('Wavelength (nm)')\n            plt.ylabel('$\\Delta$A')\n            plt.show()\n\n        self.dimerCenterEv = finalParams['Dimer_center'].value\n        self.dimerCenter = evToNm(-self.dimerCenterEv)\n        self.dimerHeight = comps['Dimer_'].max()\n        self.dimerFwhmEv = finalParams['Dimer_fwhm'].value\n        self.dimerFwhm = abs(evToNm(self.dimerCenterEv + self.dimerFwhmEv) - evToNm(self.dimerCenterEv - self.dimerFwhmEv))\n        self.dimerFit = comps['Dimer_']\n\n        if chainMode == True:\n            self.chainCenterEv = finalParams['Chain_center'].value\n            self.chainCenter = evToNm(-self.chainCenterEv)\n            self.chainHeight = comps['Chain_'].max()\n            self.chainFwhmEv = finalParams['Chain_fwhm'].value\n            self.chainFwhm = abs(evToNm(self.chainCenterEv + self.chainFwhmEv) - evToNm(self.chainCenterEv - self.chainFwhmEv))\n            self.chainFit = comps['Chain_']\n        else:\n            self.chainCenter = np.nan\n            self.chainCenterEv = np.nan\n            self.chainHeight = np.nan\n            self.chainFwhm = np.nan\n            self.chainFwhmEv = np.nan\n            self.chainFit = np.zeros(len(self.xTrunc))\n\n    def findDimerIndex(self, plot = False, returnAll = False):\n        x = self.xTrunc\n        ySmooth = mpf.butterLowpassFiltFilt(self.ySub, cutoff = 1200, fs = 65000)\n        dimerWl = self.dimerCenter\n\n        if dimerWl == None:\n            self.dimerWl = None\n\n            if plot == True:\n                #print('Dimer Wl is None')\n                plt.plot(x, ySmooth)\n                plt.show()\n\n            return\n\n        elif dimerWl < 600:\n            self.dimerWl = None\n            #print('Dimer Wl < 600')\n\n            #if plot == True:\n            #    plt.plot(*mpf.truncateSpectrum(x, self.ySub, startWl = 550, finishWl = 900))                \n            #    plt.show()\n            return\n\n        dimerIndex = abs(self.xTrunc - dimerWl).argmin()   \n        y = self.ySub/ySmooth[dimerIndex]\n        xy1 = mpf.truncateSpectrum(x, y, startWl = 500, finishWl = 600)\n        x2, y2 = mpf.truncateSpectrum(x, y, startWl = 600, finishWl = 900)\n        ySmooth = mpf.butterLowpassFiltFilt(y2, cutoff = 1200, fs = 65000)\n        y2 /= ySmooth.max()\n        ySmooth /= ySmooth.max()\n        \n        mindices = mpf.detectMinima(ySmooth)\n        \n        if len(mindices) == 0:\n            mindices = [0]\n        \n        if x2[mindices[0]] > 700:\n            mindices = [0]\n\n        xDimer = x2[mindices[0]:]\n        yDimer = y2[mindices[0]:]\n        ySmooth = ySmooth[mindices[0]:]\n        dimerIndex = ySmooth.argmax()\n\n        self.dimerWl = xDimer[dimerIndex]\n\n        #try:\n        #    mpf.getFWHM(xDimer, yDimer, maxdex = dimerIndex)\n        #except:\n        #    print('fwhmdfgd failed')\n        fwhm, center, height = mpf.getFWHM(xDimer, ySmooth, maxdex = dimerIndex, fwhmFactor = 1.3)\n        xLorz, yLorz = mpf.truncateSpectrum(xDimer, yDimer, startWl = max(xDimer.min(), center-5-fwhm/2), endWl = min(xDimer.max(), center+5+fwhm/2))\n        lMod = LorentzianModel()\n        lModPars = lMod.guess(ySmooth, x = xDimer)\n        lModPars['center'].set(center, min = center-fwhm/2, max = center+fwhm/2)\n        lModPars['sigma'].set(fwhm/2)\n        lModPars['height'].set(height, max = height*1.5, min = 0)\n        lModPars['amplitude'].set(min = 0)\n        \n        lOut = lMod.fit(yLorz, lModPars, x = xLorz)\n        lFit = lOut.eval(x = xDimer)\n        self.dimerFwhm = lOut.params['fwhm'].value\n\n        if plot == True:\n            fig, (ax1, ax2) = plt.subplots(2, sharex = True)\n            ax1.plot(self.xTrunc, self.yTrunc)\n\n            if self.aunpSpec is not None:\n                ax1.plot(self.xTrunc, self.aunpSpec, 'k--')\n\n            ax2.plot(xDimer, lFit, 'r--')\n            ax1.plot(self.xTrunc, self.ySub)\n            ax2.plot(x2, y2, alpha = 0.5, lw = 5)\n            ax2.plot(xDimer, yDimer, alpha = 0.5)\n            ax2.plot(xDimer, ySmooth)\n            ax2.plot(xDimer[dimerIndex], ySmooth[dimerIndex], 'o', ms = 20, alpha = 0.5)\n            ax2.set_xlim(420, 900)\n            ax2.set_xlabel('Wavelength (nm)')\n            plt.subplots_adjust(hspace = 0)\n            ax1.set_ylabel('Absorbance')\n            ax2.set_ylabel('$\\Delta$A')\n            ax1.set_yticks([])\n            ax2.set_yticks([])\n            ax1.set_title(r'$\\lambda_{\\mathrm{Dimer}}$ = %.2f nm' % self.dimerWl)\n            plt.show()\n\n        if returnAll == True:\n            self.xDimer = xDimer\n            self.yDimer = yDimer\n            self.yDimerSmooth = ySmooth\n            self.x2 = x2\n            self.y2 = y2",
  "class AggExtDataset:\n    '''\n    Class containing (x, y, t) data and methods for an aggregate extinction timescan\n    dSet must be a 2-dimensional h5py.Dataset Object from an open h5py.File('a') Object\n    '''\n    def __init__(self, dSet, dataName = None, exptName = None, startWl = 420, endWl = 950, initSpec = None, startPointPlot = False, startPointThresh = 2, tInit = 15,\n                 saveFigs = False):\n        self.x = dSet.attrs['wavelengths'][()]\n        self.t = dSet.attrs['start times'][()]\n        self.dSet = dSet\n\n        self.dataName = dataName if dataName is not None else dSet.name.strip('/')\n\n        if exptName is not None:\n            dSet.attrs['Experiment Name'] = self.exptName = exptName\n\n        bg = dSet.attrs['background'][()]\n        ref = dSet.attrs['reference'][()]\n        ref -= bg\n        yData = dSet[()] - bg\n        yData /= ref\n\n        self.yData = np.log10(1/yData)\n        self.startWl = startWl\n        self.endWl = endWl\n\n        self.saveFigs = saveFigs\n\n        if 'AggInc' in dSet.attrs.keys():\n            self.startPoint = dSet.attrs['Start Point']\n            self.endPoint   = dSet.attrs['End Point']\n            self.trapDiff   = dSet.attrs['AggInc']\n\n        else:\n            self.findStartPoint(plot = startPointPlot, thresh = startPointThresh, tInit = tInit)\n            dSet.attrs['Start Point'] = self.startPoint\n            dSet.attrs['End Point'] = self.endPoint\n            dSet.attrs['AggInc'] = self.trapDiff\n\n        if initSpec == False:\n            self.initSpec = None\n\n        elif initSpec is None:  \n            if 'AuNP Spectrum' in dSet.attrs.keys():\n                x = dSet.attrs['AuNP Wavelengths'][()]\n                y = dSet.attrs['AuNP Spectrum'][()]\n                self.initSpec = ExtinctionSpectrum(x, y)\n\n            self.initSpec = findAunpSpectrum(dSet.file.filename)\n        else:\n            self.initSpec = initSpec\n\n        if 'Dimer Centers' in dSet.attrs.keys():\n            self.dimerCenters = dSet.attrs['Dimer Centers']\n            self.dimerHeights = dSet.attrs['Dimer Heights']\n            self.dimerFwhms   = dSet.attrs['Dimer Fwhms']\n\n            self.chainHeights = dSet.attrs['Chain Heights']\n            self.chainFwhms   = dSet.attrs['Chain Fwhms']\n            self.chainCenters = dSet.attrs['Chain Centers']\n\n    def findStartPoint(self, plot = False, thresh = 2, tInit = 15):\n        x = self.x\n        t = self.t \n        yData = self.yData\n\n        startIndex = abs(x-600).argmin()\n        endIndex = abs(x-900).argmin()\n\n        trapInts = np.asarray([np.trapz(y[startIndex:endIndex], x = x[startIndex:endIndex]) for y in yData])\n        trapIntMaxs = np.array([i for i in mpf.detectMinima(-trapInts) if t[i] < tInit])\n\n        if len(trapIntMaxs) == 0:\n            trapIntMaxs = np.array([0])\n\n        trapIntMins = np.array([i for i in mpf.detectMinima(trapInts) if t[i] < tInit and i > trapIntMaxs.max()])\n\n        if len(trapIntMins) == 0:\n            trapAvg = np.average([i for t, i in zip(t, trapInts) if t > tInit])\n\n            d1 = mpf.centDiff(t, trapInts)\n            trapIntMaxs = np.array([i for i in mpf.detectMinima(trapInts) if t[i] < tInit and trapInts[i] > trapAvg*thresh])\n\n            if len(trapIntMaxs) == 0:\n                trapIntMaxs = np.array([0])\n\n            trapIntMins = np.array([i for i in mpf.detectMinima(d1) if t[i] < tInit and i > trapIntMaxs.max() and trapInts[i] < trapAvg*thresh])\n\n            if plot == True:\n                fig = plt.figure()\n                ax1 = fig.add_subplot(111)\n                ax2 = ax1.twinx()\n                ax1.plot(t, trapInts)\n                ax2.plot(t, d1, 'k')\n                ax1.plot(t[trapIntMaxs], trapInts[trapIntMaxs], 'ro')\n                ax1.plot(t[trapIntMins], trapInts[trapIntMins], 'go')\n\n                plt.show()\n\n        startPoint = trapIntMins.min()\n        endPoint = startPoint + trapInts[startPoint:].argmax()\n\n        if endPoint < startPoint + 30:\n            endPoint = len(trapInts) - 1\n\n        self.trapDiff = trapInts[endPoint] - trapInts[startPoint]\n\n        if plot == True:\n            print(trapInts[endPoint] - trapInts[startPoint])\n            plt.plot(t, trapInts)\n            plt.plot(t[startPoint], trapInts[startPoint], 'go')\n            plt.plot(t[endPoint], trapInts[endPoint], 'ro')\n            #plt.xlim(*t[stEnd])\n            plt.xlabel('Time (s)')\n            plt.ylabel('Integrated aggregate modes')\n            plt.show()\n        \n        self.startPoint = startPoint\n        self.endPoint = endPoint\n\n    def inputStartPoint(self, startPoint):\n        self.startPoint = startPoint\n\n    def inputEndPoint(self, endPoint):\n        self.endPoint = endPoint\n\n    def fitSpectra(self, dSet, dimerPlot = False, debug = False):\n        x = self.x\n        yData = self.yData\n\n        scanTimes = self.t\n        startPoint = self.startPoint\n        endPoint = self.endPoint\n\n        initSpec = self.initSpec\n\n        specDict = {}\n\n        nummers = np.arange(20, 101, 20)\n\n        if len(yData[startPoint:]) > 500:\n            nummers = np.arange(10, 101, 10)\n\n        if len(yData[startPoint:]) > 1500:\n            nummers = np.arange(5, 101, 5)\n\n        totalFitStart = time.time()\n        print('\\n0% complete')\n        failures = 0\n\n        initDimerWl = None\n\n        for n, (y, t) in enumerate(zip(yData[startPoint:], scanTimes[startPoint:]), startPoint):\n            dimerWl = None if n == 0 else dSet.attrs.get('Dimer Guess', None)\n            spectrum = ExtinctionSpectrum(x, y, initSpec = initSpec, startWl = self.startWl, endWl = self.endWl)\n            if debug == True:\n                spectrum.debug()\n            try:\n                spectrum.fitAggPeaks(dimerWl = dimerWl)\n            except:\n                #print(f'Spectrum {n} failed')\n                plt.close('all')\n                #spectrum.fitAggPeaks(dimerWl = dimerWl)\n                spectrum.makeNull()\n                failures += 1\n\n            if initDimerWl is None:\n                spectrum.findDimerIndex(plot = dimerPlot)\n                initDimerWl = spectrum.dimerWl          \n\n            if (n == 0 or dimerWl is None) and spectrum.specMaxWl is not None:\n                dSet.attrs['Dimer Guess'] = spectrum.specMaxWl\n\n            if spectrum.dimerCenter is None:\n                failures += 1\n\n            specDict[n] = spectrum\n\n            if 100 * n//len(yData[startPoint:]) in nummers:\n                currentTime = time.time() - totalFitStart\n                mins = int(currentTime//60)\n                secs = currentTime % 60\n                print(f'{nummers[0]}% ({n} spectra) analysed in {mins} min {secs:.3f} sec')\n                nummers = nummers[1:]\n\n        if initDimerWl is not None:\n            dSet.attrs['Dimer Wavelength (t0)'] = initDimerWl\n            print(f'\\nDimer Wavelength = {initDimerWl}\\n')\n        else:\n            dSet.attrs['Dimer Wavelength (t0)'] = 'N/A'\n            print(f'\\nNo dimer peak detected\\n')\n\n        print\n\n        nSpectra = np.arange(len(yData))\n\n        if failures > len(yData)/5:\n            print('\\nLots of fits failed for this one (can be an issue with low concentrations)')\n\n        self.dimerCenters = np.array([specDict.get(n, ExtinctionSpectrum(None, None)).dimerCenter for n in nSpectra])\n        self.chainCenters = np.array([specDict.get(n, ExtinctionSpectrum(None, None)).chainCenter for n in nSpectra])\n\n        dimerWlAvg = np.nanmean(self.dimerCenters)\n        dimerWlStd = np.nanstd(self.dimerCenters)\n        self.dimerCenters = np.array([i if abs(dimerWlAvg - i) < dimerWlStd*3 else np.nan for i in self.dimerCenters])\n\n        chainWlAvg = np.nanmean(self.chainCenters[2:10])\n        chainWlStd = np.nanstd(self.chainCenters[2:10])\n        self.chainCenters[:10] = np.array([i if (abs(chainWlAvg - i) < chainWlStd*2 and i > self.dimerCenters[n] and i > 0) else np.nan for n, i in enumerate(self.chainCenters[:10])])\n\n        dSet.attrs['Dimer Centers'] = self.dimerCenters \n        dSet.attrs['Chain Centers'] = self.chainCenters \n\n        dSet.attrs['Dimer Heights'] = self.dimerHeights = np.array([specDict.get(n, ExtinctionSpectrum(None, None)).dimerHeight for n in nSpectra])\n        dSet.attrs['Dimer Fwhms']   = self.dimerFwhms   = np.array([specDict.get(n, ExtinctionSpectrum(None, None)).dimerFwhm   for n in nSpectra])\n        \n        dSet.attrs['Chain Heights'] = self.chainHeights = np.array([specDict.get(n, ExtinctionSpectrum(None, None)).chainHeight for n in nSpectra])\n        dSet.attrs['Chain Fwhms']   = self.chainFwhms   = np.array([specDict.get(n, ExtinctionSpectrum(None, None)).chainFwhm   for n in nSpectra])\n\n    def plotIndividual(self, specN = 0, plotDimer = False, plotChain = False, plotProgress = False, saveFig = None, returnOnly = False):\n        makeDir('Plots')\n        dataName = self.dataName\n        if '/' in dataName:\n            dataName = dataName.split('/')[-1]\n\n        x = self.x\n        yData = self.yData\n\n        scanTimes = self.t\n        startPoint = self.startPoint\n        specN += startPoint\n        endPoint = self.endPoint\n        initSpec = self.initSpec\n\n        saveFig = self.saveFigs if saveFig is None else saveFig\n\n        y = yData[specN]\n        spectrum = ExtinctionSpectrum(x, y, initSpec = initSpec, startWl = self.startWl, endWl = self.endWl)\n        xTrunc, yTrunc, ySub = spectrum.xTrunc, spectrum.yTrunc, spectrum.ySub\n\n        if returnOnly == True:\n            return xTrunc, ySub\n\n        print(f'Plotting {dataName} Spectrum {specN}...')\n\n        if any([plotDimer, plotChain]):\n            spectrum.fitAggPeaks(plot = plotProgress)\n\n        fig, (ax1, ax2) = plt.subplots(2, sharex = True)\n        ax1.plot(xTrunc, yTrunc)\n        ax2.plot(xTrunc, ySub)\n\n        if plotDimer == True:\n            dimerX, dimerY = spectrum.dimerCenter, spectrum.dimerHeight\n            dimerLorentz = spectrum.dimerFit\n            ax2.plot(xTrunc, dimerLorentz)\n            ax2.plot(dimerX, dimerY, 'ro')\n\n        if plotChain == True:\n            chainX, chainY = spectrum.chainCenter, spectrum.chainHeight\n            chainLorentz = spectrum.chainFit\n            ax2.plot(xTrunc, chainLorentz)\n            ax2.plot(chainX, chainY, 'o', color = 'darkred')\n\n        if all([plotDimer, plotChain]):\n            ax2.plot(xTrunc, dimerLorentz + chainLorentz)\n\n        fig.suptitle(dataName)\n        ax1.set_xlim(xTrunc.min(), xTrunc.max())\n        ax2.set_xlim(ax1.get_xlim())\n        ax2.set_xlabel('Wavelength (nm)')\n        ax1.set_ylabel('Absorbance')\n        ax2.set_ylabel('A - A$_{\\mathrm{AuNP}}$')\n        plt.subplots_adjust(hspace = 0.05)\n\n        if saveFig == True:\n            imgFName = f'Plots/{dataName}.svg'\n            fig.savefig(imgFName, bbox_inches = 'tight')\n            print(f'Saved as {imgFName}')\n            plt.close('all')\n\n        else:\n            plt.show()\n\n    def plotSpectra(self, cmap = 'jet', saveFig = None, redDots = False):\n        print('Plotting...\\n')\n        makeDir('Plots')\n        dataName = self.dataName\n        if '/' in dataName:\n            dataName = dataName.split('/')[-1]\n\n        saveFig = self.saveFigs if saveFig is None else saveFig\n\n        x = self.x\n        yData = self.yData\n\n        scanTimes = self.t\n        startPoint = self.startPoint\n        endPoint = self.endPoint\n\n        initSpec = self.initSpec\n\n        nCols = len(yData[startPoint:endPoint])\n\n        fig, (ax1, ax2) = plt.subplots(2, sharex = True)\n        initX, initY = initSpec.xTrunc, initSpec.yTrunc\n        ax1.plot(initX, initY, 'k')\n        cmap = plt.get_cmap(cmap, nCols)\n\n        for n, (y, t) in enumerate(zip(yData[startPoint:], scanTimes[startPoint:]), startPoint):\n            spectrum = ExtinctionSpectrum(x, y, initSpec = initSpec, startWl = self.startWl, endWl = self.endWl)\n            xTrunc, yTrunc, ySub = spectrum.xTrunc, spectrum.yTrunc, spectrum.ySub\n            \n            if n > nCols:\n                color = 'gray'\n                alpha = 0.5\n            else:\n                color = cmap(n)\n                alpha = 1\n\n            dimerX, dimerY = self.dimerCenters[n], self.dimerHeights[n]\n            chainX, chainY = self.chainCenters[n], self.chainHeights[n]\n\n            ax1.plot(xTrunc, yTrunc, color = color, zorder = -n)\n            ax2.plot(xTrunc, ySub, color = color, alpha = alpha, zorder = -2*n)\n\n            if redDots == True:\n                ax2.plot(dimerX, dimerY, 'ro', zorder = n)\n                ax2.plot(chainX, chainY, 'o', color = 'darkred', zorder = n)            \n\n        fig.suptitle(dataName)\n        ax1.set_xlim(xTrunc.min(), xTrunc.max())\n        ax2.set_xlim(ax1.get_xlim())\n        ax2.set_xlabel('Wavelength (nm)')\n        ax1.set_ylabel('Absorbance')\n        ax2.set_ylabel('A - A$_{\\mathrm{AuNP}}$')\n        plt.subplots_adjust(hspace = 0.05)\n        if saveFig == True:\n            imgFName = f'Plots/{dataName}.png'\n            fig.savefig(imgFName, bbox_inches = 'tight')\n            print(f'Saved as {imgFName}')\n            plt.close('all')\n\n        else:\n            plt.show()        \n\n    def plotOverviews(self, saveFig = True):\n        makeDir('Plots')\n        dataName = self.dataName\n        if '/' in dataName:\n            dataName = dataName.split('/')[-1]\n        startPoint = self.startPoint\n        t = self.t[startPoint:]\n        dimerX = self.dimerCenters[startPoint:]\n        dimerY = self.dimerHeights[startPoint:]\n        dimerW = self.dimerFwhms[startPoint:]\n\n        chainX = self.chainCenters[startPoint:]\n        chainY = self.chainHeights[startPoint:]\n        chainW = self.chainFwhms[startPoint:]\n\n        fig = plt.figure()\n        ax1 = fig.add_subplot(111)\n\n        dXPlot = ax1.plot(t, dimerX, 'o-', label = '$\\lambda_\\mathrm{Dimer}$')\n        cXPlot = ax1.plot(t, chainX, 'o-', label = '$\\lambda_\\mathrm{Chain}$')\n        ax1.legend(loc = 0)\n\n        ax1.set_xlabel('Time (s)')\n        ax1.set_ylabel('Peak Wavelength (nm)')\n        plt.title(dataName)\n        if saveFig == True:\n            imgFName = f'Plots/{dataName} wl vs t.svg'\n            fig.savefig(imgFName, bbox_inches = 'tight')\n            print(f'Saved as {imgFName}')\n            plt.close('all')\n\n        else:\n            plt.show()\n\n        fig = plt.figure()\n        ax = fig.add_subplot(111)\n        ax.plot(t, dimerY, 'o-', color = dXPlot[0].get_color(), label = 'Dimer')\n        ax.plot(t, chainY, 'o-', color = cXPlot[0].get_color(), label = 'Chain')\n        ax.set_xlabel('Time (s)')\n        ax.set_ylabel('Peak Absorbance')\n        plt.title(dataName)\n        if saveFig == True:\n            imgFName = f'Plots/{dataName} i vs t.svg'\n            fig.savefig(imgFName, bbox_inches = 'tight')\n            print(f'Saved as {imgFName}')\n            plt.close('all')\n\n        else:\n            plt.show()\n\n        print('')\n\n    def extractDimerSpectrum(self, plot = True, endWl = 900, limit = 15):\n        x = self.x\n        yData = self.yData[self.startPoint:]\n        \n        dimerWl = None\n        n = 0\n        while dimerWl is None and n < limit:        \n            spectrum = ExtinctionSpectrum(x, yData[n], endWl = endWl, initSpec = self.initSpec)\n            xTrunc, ySub = spectrum.xTrunc, spectrum.ySub\n\n            try:\n                spectrum.fitAggPeaks(dimerWl = dimerWl)\n                spectrum.findDimerIndex(plot = plot)\n                dimerWl = spectrum.dimerWl\n                dimerFwhm = spectrum.dimerFwhm\n\n            except:\n                print(f'Spectrum {n + self.startPoint} failed for {self.dataName}')\n                dimerWl = None\n                dimerFwhm = None\n                \n            n += 1\n\n        self.dimerWl = dimerWl\n        self.dimerFwhm = dimerFwhm\n        \n        if n >= 15:\n            print('\\tDimer detection failed')\n            return spectrum\n            \n        elif n > 0:\n            print(f'\\tSucceeded for Spectrum {n + self.startPoint}')\n        \n        print(f'\\tDimer Wl = {dimerWl:.2f} nm')\n        print(f'\\tFWHM = {dimerFwhm:.2f} nm\\n')\n\n        return spectrum",
  "class AggExtH5File():\n\n    def __init__(self, filename):\n        self.filename = filename\n        self.dSetNames = self.getDsetNames(nDims = 2)\n        self.spectraNames = self.getDsetNames(nDims = 1)\n        self.initialiseDatasets()\n        self.initSpec = self.findAunpSpectrum()\n\n    def getDsetNames(self, nDims = 2):\n        with h5py.File(self.filename, 'r') as f:\n            dSetNames = []\n            f.visit(dSetNames.append)\n            dSetNames = [dSetName for dSetName in dSetNames if isinstance(f[dSetName], h5py.Dataset)]\n            \n            return [dSetName for dSetName in dSetNames if f[dSetName][()].ndim == nDims]\n\n    def initialiseDatasets(self):\n        print('Initialising timescan data...')\n\n        with h5py.File(self.filename, 'a') as f:\n            for dSetName in self.dSetNames:\n                if 'Start Point' not in f[dSetName].attrs.keys():\n                    print(f'\\t{dSetName}')\n                    dataSet = AggExtDataset(f[dSetName], dataName = dSetName, initSpec = False)\n\n        print('\\n\\tData initialised\\n')\n\n    def updateAunpSpecs(self, x, y):        \n        with h5py.File(self.filename, 'a') as f:\n            for dSetNames in self.dSetNames:\n                f[dSetNames].attrs['AuNP Spectrum'] = y\n                f[dSetNames].attrs['AuNP Wavelengths'] = x\n\n    def findAunpSpectrum(self, reUse = True, extH5File = None):\n        '''\n        searches through h5 file for non-aggregated AuNP spectrum\n        '''\n        h5File = self.filename\n        if extH5File is not None:\n            currH5File = h5File\n            h5File = extH5File\n\n        print(f'Searching for AuNP monomer spectrum candidates in {h5File}...')\n\n        timeScans = self.dSetNames\n        singleSpecs = self.spectraNames\n\n        with h5py.File(h5File, 'a') as f:\n            candidates = []\n\n            for i in timeScans:\n                if reUse == True:\n                    if 'AuNP Spectrum' in f[i].attrs.keys():\n                        y = f[i].attrs['AuNP Spectrum']\n                        x = f[i].attrs['AuNP Wavelengths']\n                        print('\\tAuNP monomer spectrum found\\n')\n\n                        if extH5File is not None:\n                            updateAunpSpecs(currH5File, x, y)\n                        \n                        return ExtinctionSpectrum(x, y)\n\n                if 'AggInc' not in f[i].attrs.keys():\n                    dataset = AggExtDataset(f[i], initSpec = False)\n\n            allSpecs = sorted([i for i in timeScans if 'AggInc' in f[i].attrs.keys()], key = lambda i: f[i].attrs['AggInc'])\n            allSingles = singleSpecs\n\n            #for specName in allSpecs:\n            #    if 'AuNP Spectrum' in f[specName].attrs.keys():\n            #        return f[specName].attrs['AuNP Spectrum'][()]\n\n            integrals = []\n\n            for i in allSingles:\n                spectrum = f[i]\n                x = spectrum.attrs['wavelengths'][()]\n                y = spectrum[()]\n                bg = spectrum.attrs['background'][()] \n                ref = spectrum.attrs['reference'][()] \n                ref -= bg\n                y -= bg\n                y /= ref\n                y = np.log10(1/y)\n\n                candidates.append((x, y))\n                xTrunc, yTrunc = mpf.truncateSpectrum(x, y, startWl = 600, finishWl = 970)\n                integrals.append(np.trapz(yTrunc, x = xTrunc))        \n\n            for dSetName in allSpecs:\n                dSpectra = f[dSetName]\n                x = dSpectra.attrs['wavelengths'][()] \n                startPoint = dSpectra.attrs['Start Point']\n                y = dSpectra[()][startPoint]\n                bg = dSpectra.attrs['background'][()] \n                ref = dSpectra.attrs['reference'][()] \n                ref -= bg\n                y -= bg\n                y /= ref\n                y = np.log10(1/y)\n\n                candidates.append((x, y))\n                xTrunc, yTrunc = mpf.truncateSpectrum(x, y, startWl = 600, finishWl = 970)\n                integrals.append(np.trapz(yTrunc, x = xTrunc))\n\n            candidates = [i[0] for i in sorted(zip(candidates, integrals), key = lambda i: i[1])]\n\n            if len(candidates) == 0:\n                print('agfsfghfsgh')\n\n            for n, (x, y) in enumerate(candidates):\n                xTrunc, yTrunc = mpf.truncateSpectrum(x, y, startWl = 400, finishWl = 950)\n                \n                plt.plot(xTrunc, yTrunc)\n                plt.xlim(xTrunc.min(), xTrunc.max())\n                plt.title(f'Attempt {n}')\n                plt.show()\n\n                query = 'Is this AuNP monomer spectrum acceptable? There should be no visible dimer peak.\\n**If any aggregation is visible, enter \"n\" until you find one without it**  \\\n                                  \\nEnter y to accept; n to find another spectrum; x to exit; anything else to see more options\\n\\n'\n\n                if n > 0:\n                    query = 'y to accept; n to find another spectrum; x to exit; anything else to see more options\\n\\n'\n            \n                decision = input(query)\n\n                if decision == 'y':\n                    print('\\nOk, saving this for future use. Please wait while Dataset attributes are updated...')\n                    for specName in allSpecs:\n                        self.updateAunpSpecs(x, y)\n                        if extH5File is not None:\n                            self.updateAunpSpecs(currH5File, x, y)\n                        f[specName].attrs['AuNP Spectrum'] = y\n                        f[specName].attrs['AuNP Wavelengths'] = x\n                    print('\\tDone\\n')\n                    return ExtinctionSpectrum(x, y)\n                \n                elif decision == 'n':\n                    continue\n                elif decision == 'x':\n                    print(1/0)\n                else:\n                    break\n\n            query = ''.join(['No monomeric AuNP spectrum found. Please select an option to continue:\\n',\n                             '\\t1. Specify a different .h5 file with a monomeric AuNP spectrum\\n', \n                             '\\t2. Manually specify \"initSpec = [x, y]\" when calling fitAllSpectra\\n',\n                             '\\t3. Manually add AuNP xy data to the .h5 file before running again\\n\\n'])\n\n            decision = input(query)\n\n            while decision not in ['1', '2', '3', 1, 2, 3]:\n                if decision == 'x':\n                    break\n                decision = input('Please enter 1, 2 or 3. Enter x to exit:\\n\\n')            \n\n            if decision in [1, '1']:\n                extH5File = input(\"Please enter the full path to the .h5 file containing your spectrum:\\n\\n\")\n\n                while not extH5File.endswith('.h5'):\n                    if not extH5File.endswith('.h5'):\n                        extH5File = input('Are you sure this is correct? Please try again:\\n\\n')\n                    if extH5File == 'x':\n                        break\n\n                extH5File = '/'.join(extH5File.split('\\\\'))\n            \n                aunpSpec = self.findAunpSpectrum(reUse = True, extH5File = extH5File)\n                print('AuNP Spectrum successfully added')\n\n                return aunpSpec\n\n            elif decision in [2, '2']:\n                print('Find some appropriate [x, y] data and run fitAllSpectra again, specifying \"initSpec = [x, y]\"')\n                print(1/0)\n\n            elif decision in [3, '3']:\n                print(\"Find some appropriate y data and save it as a new Dataset in the current hdf5 File with Dataset.attrs['wavelengths'] = x, then try again\")\n                print(1/0)\n\n            print(1/0)\n\n    def findDimerPeaks(self, plot = True, endWl = 900):\n        specDict = {}\n\n        initSpec = self.initSpec\n\n        with h5py.File(self.filename, 'a') as f:\n            for dSetName in self.dSetNames[:]:\n                print(dSetName)\n                initSpecs = []\n                dimerWls = []\n                dataSet = AggExtDataset(f[dSetName], initSpec = self.initSpec, saveFigs = False, endWl = endWl)\n                \n                dimerSpectrum = dataSet.extractDimerSpectrum(plot = plot, endWl = endWl)\n                dimerWl = dataSet.dimerWl\n                dimerFwhm = dataSet.dimerFwhm\n                specDict[dSetName] = {'xy' : [dimerSpectrum.xTrunc, dimerSpectrum.ySub], 'dimerWl' : 0 if dimerWl is None else dimerWl, 'dimerFwhm' : 0 if dimerWl is None else dimerFwhm}\n\n                f[dSetName].attrs['Dimer Wavelength (t0)'] = dimerWl if dimerWl is not None else np.nan\n\n        print('Done')\n\n        self.dimerSpecDict = specDict\n\n        return specDict\n\n    def fitAllSpectra(self, nameDict = {}, dimerPlot = False, saveFigs = True, startWl = 420, endWl = 950, startPointPlot = False, startPointThresh = 2, \n                      tInit = 15, debug = False):\n\n        print('Beginning fit\\n')\n\n        with h5py.File(self.filename, 'a') as f:\n            for specN, dataName in enumerate(self.dSetNames):\n                exptName = nameDict.get(dataName.split('/')[-1], None)\n                print(dataName)\n                if exptName is not None:\n                    print(f'\\t(= {exptName})')\n                dSpectra = f[dataName]\n                if len(dSpectra[()]) == 1:\n                    continue\n\n                dataSet = AggExtDataset(dSpectra, dataName = dataName, exptName = exptName, initSpec = self.initSpec, startWl = startWl, endWl = endWl, \n                                        startPointPlot = startPointPlot, startPointThresh = startPointThresh, tInit = tInit)\n                dataSet.fitSpectra(dSpectra, dimerPlot = dimerPlot, debug = debug)\n                makeDir('Plots')\n                dataSet.plotSpectra(saveFig = saveFigs)\n                dataSet.plotOverviews(saveFig = saveFigs)\n\n        print('\\nAll done')",
  "def makeNull(self):\n        self.dimerCenter = np.nan\n        self.dimerHeight = np.nan\n        self.dimerFwhm = np.nan\n        self.chainCenter = np.nan\n        self.chainHeight = np.nan\n        self.chainFwhm = np.nan",
  "def debug(self):\n        self.debug = True",
  "def __init__(self, x, y, startWl = 420, endWl = 950, initSpec = None):\n        self.makeNull()\n        \n        if x is None:\n            return\n\n        self.xRaw = mpf.removeNaNs(x)\n        self.yRaw = mpf.removeNaNs(y)\n\n        self.startWl = startWl\n        self.endWl = endWl\n        self.xTrunc, self.yTrunc = mpf.truncateSpectrum(self.xRaw, self.yRaw, startWl = self.startWl, finishWl = self.endWl)\n        self.ySmooth = mpf.butterLowpassFiltFilt(self.yTrunc, cutoff = 1100, fs = 70000)\n        self.debug = False\n        self.specMaxWl = None\n\n        if initSpec is not None:            \n            initX, initY, initYSmooth = initSpec.xTrunc, initSpec.yTrunc, initSpec.ySmooth\n            initAunpWl = initX[initYSmooth.argmax()]\n\n            if not np.all(initX == self.xTrunc):\n                initY = np.interp(self.xTrunc, initX, initY)\n                initYSmooth = mpf.butterLowpassFiltFilt(initY)            \n\n            aunpIndex = initYSmooth.argmax()\n            initAunpWl = self.xTrunc[aunpIndex]\n\n            initY -= initYSmooth[-1] - self.ySmooth[-1]\n            initYSmooth -= initYSmooth[-1] - self.ySmooth[-1]\n\n            scaling = self.ySmooth[aunpIndex]/initYSmooth[aunpIndex]\n\n            self.aunpSpec = initY*scaling\n            self.ySub = self.yTrunc - initY*scaling\n            self.ySubSmooth = self.ySmooth - initYSmooth*scaling\n            \n        else:\n            self.aunpSpec = None\n            self.ySub = self.yTrunc",
  "def fitAggPeaks(self, dimerWl = None, plot = False):\n        '''\n        InitY is monomeric AuNP spectrum, scaled if necessary. Must have same length as x and y\n        '''\n        x, y = self.xTrunc, self.ySub\n        ySmooth = mpf.butterLowpassFiltFilt(y, cutoff = 1200, fs = 65000)\n        mindices = mpf.detectMinima(ySmooth)\n\n        if plot == True:\n            plt.plot(x, y)\n            plt.plot(x, ySmooth)\n            plt.show()\n\n        mindices = mindices[np.where(x[mindices] > 500)]\n        startMindex = mindices[0] if len(mindices) > 0 else abs(x-500).argmin()\n        #startMindex = int(np.round(np.average([startMindex, abs(x-600).argmin()])))\n\n        xFit, yFit, yFitSmooth = x[startMindex:], y[startMindex:], ySmooth[startMindex:]\n        yFit -= yFitSmooth.min()\n        yFitSmooth -= yFitSmooth.min()\n        self.specMaxWl = xFit[yFitSmooth.argmax()]\n\n        if dimerWl is None:\n            initDimerWl = self.specMaxWl\n            dimerIndex = abs(xFit-initDimerWl).argmin()\n            initDimerHeight = yFitSmooth.max()\n        else:\n            initDimerWl = dimerWl\n            dimerIndex = abs(xFit-initDimerWl).argmin()\n            initDimerHeight = yFitSmooth[dimerIndex]\n\n        yOffset = -yFitSmooth.min()\n        yFit += yOffset\n        initDimerHeight += yOffset\n        yFitSmooth += yOffset\n\n        xFit = -nmToEv(xFit)\n        xFitNm = evToNm(-xFit)\n        initDimerWl = xFit[dimerIndex]\n\n        try:\n            dimerHalfMaxDex = abs(yFitSmooth[:dimerIndex] - initDimerHeight/2).argmin()\n        except:\n            if self.debug == True:\n                print(dimerWl, initDimerWl, dimerIndex)\n            return\n\n        initDimerFwhm = 2*(initDimerWl - xFit[dimerHalfMaxDex])\n        initDimerFwhmEv = nmToEv(xFit[dimerIndex] - initDimerFwhm/2) - nmToEv(xFit[dimerIndex] + initDimerFwhm/2)\n        #initDimerFwhmEv = abs(xFit[dimerHalfMaxDex] - xFit[2*dimerIndex - dimerHalfMaxDex])\n        \n        dimerInit = lorentzian(xFit, initDimerHeight, initDimerWl, initDimerFwhm)\n\n        dimerInit -= dimerInit[0] - yFitSmooth[0]\n        dimerInit *= initDimerHeight/dimerInit.max()\n\n        chainInit = yFitSmooth - dimerInit\n        initChainIndex = dimerIndex + chainInit[dimerIndex:].argmax()\n\n        if plot == True:\n            plt.plot(xFit, yFit)\n            plt.plot(xFit[dimerIndex:initChainIndex], chainInit[dimerIndex:initChainIndex], zorder = 10)\n            plt.plot(xFit, dimerInit)\n            plt.plot(xFit, chainInit)\n            plt.plot(xFit[initChainIndex], chainInit[initChainIndex], 'o')\n            #plt.plot(xFit[chainHalfMaxDex], chainInit[chainHalfMaxDex], 'ko')\n            plt.plot(xFit, dimerInit + chainInit, 'r--')\n            plt.show()\n\n        aggMod = LorentzianModel(prefix = 'Dimer_')\n        aggModPars = aggMod.guess(dimerInit, x = xFit)\n        aggModPars['Dimer_center'].set(initDimerWl, min = initDimerWl-initDimerFwhm/2, max = initDimerWl+initDimerFwhm/2)\n        aggModPars['Dimer_sigma'].set(initDimerFwhm/2)\n        aggModPars['Dimer_height'].set(initDimerHeight*2/3, max = initDimerHeight, min = 0)\n        aggModPars['Dimer_amplitude'].set(min = 0)\n\n        if initChainIndex < dimerIndex:\n            chainMode = False\n        else:\n            chainMode = True\n            initChainWl, initChainHeight = xFit[initChainIndex], chainInit[initChainIndex]\n\n            try:\n                chainHalfMaxDex = dimerIndex + abs(chainInit[dimerIndex:initChainIndex] - initChainHeight/2).argmin()\n            except:\n                chainHalfMaxDex = np.average([initChainIndex, dimerHalfMaxDex])               \n\n                if self.debug == True:\n                    print(initChainIndex, chainInit[dimerIndex:initChainIndex])\n                    plt.plot(xFitNm, yFit)\n                    plt.plot(xFitNm[dimerHalfMaxDex], yFitSmooth[dimerHalfMaxDex], 'o')\n                    plt.plot(xFitNm, dimerInit)\n                    plt.plot(xFitNm, chainInit)\n                    plt.plot(xFitNm[dimerIndex], chainInit[dimerIndex], 'ro')\n                    plt.plot(xFitNm[initChainIndex], chainInit[initChainIndex], 'ko')\n                    plt.show()\n                chainMode = False\n\n            initChainFwhm = 2*(initChainWl - xFit[chainHalfMaxDex])\n            try:\n                #initChainFwhmEv = abs(xFit[chainHalfMaxDex] - xFit[max(2*initChainIndex - chainHalfMaxDex, len(xFit) - 1)])\n                initChainFwhmEv = nmToEv(initChainWl - initChainFwhm/2) - nmToEv(initChainWl + initChainFwhm/2)\n            except:\n                if self.debug == True:\n                    print(chainHalfMaxDex, 2*initChainIndex - chainHalfMaxDex)\n                chainMode = False\n\n            if chainMode == True:\n                chainInit = lorentzian(xFit, initChainHeight, initChainWl, initChainFwhm)\n                gModC = LorentzianModel(prefix = 'Chain_')\n                parsC = gModC.guess(chainInit, x = xFit)\n                parsC['Chain_sigma'].set(initChainFwhm/2)\n                parsC['Chain_height'].set(initChainHeight*2/3, max = initChainHeight, min = 0)\n                parsC['Chain_amplitude'].set(min = 0)\n\n                aggMod += gModC            \n                aggModPars.update(parsC)\n\n                aggModPars['Chain_center'].set(initChainWl, min = initDimerWl)\n\n        aggFit = aggMod.fit(yFit, aggModPars, x = xFit)\n        xTruncEv = evToNm(-self.xTrunc)\n        yAggFit = aggFit.eval(x = xTruncEv)\n        finalParams = aggFit.params\n        comps = aggFit.eval_components(x = xTruncEv)\n\n        xFit = evToNm(-xFit)\n\n        if plot == True:\n            plt.plot(self.xTrunc, self.ySub, 'k')\n            plt.plot(self.xTrunc, yAggFit, 'r')\n            for comp in comps.keys():\n                print(comp)\n                plt.plot(self.xTrunc, comps[comp], label = comp)\n            plt.legend(loc = 0)\n            plt.xlim(self.startWl, self.endWl)\n            plt.xlabel('Wavelength (nm)')\n            plt.ylabel('$\\Delta$A')\n            plt.show()\n\n        self.dimerCenterEv = finalParams['Dimer_center'].value\n        self.dimerCenter = evToNm(-self.dimerCenterEv)\n        self.dimerHeight = comps['Dimer_'].max()\n        self.dimerFwhmEv = finalParams['Dimer_fwhm'].value\n        self.dimerFwhm = abs(evToNm(self.dimerCenterEv + self.dimerFwhmEv) - evToNm(self.dimerCenterEv - self.dimerFwhmEv))\n        self.dimerFit = comps['Dimer_']\n\n        if chainMode == True:\n            self.chainCenterEv = finalParams['Chain_center'].value\n            self.chainCenter = evToNm(-self.chainCenterEv)\n            self.chainHeight = comps['Chain_'].max()\n            self.chainFwhmEv = finalParams['Chain_fwhm'].value\n            self.chainFwhm = abs(evToNm(self.chainCenterEv + self.chainFwhmEv) - evToNm(self.chainCenterEv - self.chainFwhmEv))\n            self.chainFit = comps['Chain_']\n        else:\n            self.chainCenter = np.nan\n            self.chainCenterEv = np.nan\n            self.chainHeight = np.nan\n            self.chainFwhm = np.nan\n            self.chainFwhmEv = np.nan\n            self.chainFit = np.zeros(len(self.xTrunc))",
  "def findDimerIndex(self, plot = False, returnAll = False):\n        x = self.xTrunc\n        ySmooth = mpf.butterLowpassFiltFilt(self.ySub, cutoff = 1200, fs = 65000)\n        dimerWl = self.dimerCenter\n\n        if dimerWl == None:\n            self.dimerWl = None\n\n            if plot == True:\n                #print('Dimer Wl is None')\n                plt.plot(x, ySmooth)\n                plt.show()\n\n            return\n\n        elif dimerWl < 600:\n            self.dimerWl = None\n            #print('Dimer Wl < 600')\n\n            #if plot == True:\n            #    plt.plot(*mpf.truncateSpectrum(x, self.ySub, startWl = 550, finishWl = 900))                \n            #    plt.show()\n            return\n\n        dimerIndex = abs(self.xTrunc - dimerWl).argmin()   \n        y = self.ySub/ySmooth[dimerIndex]\n        xy1 = mpf.truncateSpectrum(x, y, startWl = 500, finishWl = 600)\n        x2, y2 = mpf.truncateSpectrum(x, y, startWl = 600, finishWl = 900)\n        ySmooth = mpf.butterLowpassFiltFilt(y2, cutoff = 1200, fs = 65000)\n        y2 /= ySmooth.max()\n        ySmooth /= ySmooth.max()\n        \n        mindices = mpf.detectMinima(ySmooth)\n        \n        if len(mindices) == 0:\n            mindices = [0]\n        \n        if x2[mindices[0]] > 700:\n            mindices = [0]\n\n        xDimer = x2[mindices[0]:]\n        yDimer = y2[mindices[0]:]\n        ySmooth = ySmooth[mindices[0]:]\n        dimerIndex = ySmooth.argmax()\n\n        self.dimerWl = xDimer[dimerIndex]\n\n        #try:\n        #    mpf.getFWHM(xDimer, yDimer, maxdex = dimerIndex)\n        #except:\n        #    print('fwhmdfgd failed')\n        fwhm, center, height = mpf.getFWHM(xDimer, ySmooth, maxdex = dimerIndex, fwhmFactor = 1.3)\n        xLorz, yLorz = mpf.truncateSpectrum(xDimer, yDimer, startWl = max(xDimer.min(), center-5-fwhm/2), endWl = min(xDimer.max(), center+5+fwhm/2))\n        lMod = LorentzianModel()\n        lModPars = lMod.guess(ySmooth, x = xDimer)\n        lModPars['center'].set(center, min = center-fwhm/2, max = center+fwhm/2)\n        lModPars['sigma'].set(fwhm/2)\n        lModPars['height'].set(height, max = height*1.5, min = 0)\n        lModPars['amplitude'].set(min = 0)\n        \n        lOut = lMod.fit(yLorz, lModPars, x = xLorz)\n        lFit = lOut.eval(x = xDimer)\n        self.dimerFwhm = lOut.params['fwhm'].value\n\n        if plot == True:\n            fig, (ax1, ax2) = plt.subplots(2, sharex = True)\n            ax1.plot(self.xTrunc, self.yTrunc)\n\n            if self.aunpSpec is not None:\n                ax1.plot(self.xTrunc, self.aunpSpec, 'k--')\n\n            ax2.plot(xDimer, lFit, 'r--')\n            ax1.plot(self.xTrunc, self.ySub)\n            ax2.plot(x2, y2, alpha = 0.5, lw = 5)\n            ax2.plot(xDimer, yDimer, alpha = 0.5)\n            ax2.plot(xDimer, ySmooth)\n            ax2.plot(xDimer[dimerIndex], ySmooth[dimerIndex], 'o', ms = 20, alpha = 0.5)\n            ax2.set_xlim(420, 900)\n            ax2.set_xlabel('Wavelength (nm)')\n            plt.subplots_adjust(hspace = 0)\n            ax1.set_ylabel('Absorbance')\n            ax2.set_ylabel('$\\Delta$A')\n            ax1.set_yticks([])\n            ax2.set_yticks([])\n            ax1.set_title(r'$\\lambda_{\\mathrm{Dimer}}$ = %.2f nm' % self.dimerWl)\n            plt.show()\n\n        if returnAll == True:\n            self.xDimer = xDimer\n            self.yDimer = yDimer\n            self.yDimerSmooth = ySmooth\n            self.x2 = x2\n            self.y2 = y2",
  "def __init__(self, dSet, dataName = None, exptName = None, startWl = 420, endWl = 950, initSpec = None, startPointPlot = False, startPointThresh = 2, tInit = 15,\n                 saveFigs = False):\n        self.x = dSet.attrs['wavelengths'][()]\n        self.t = dSet.attrs['start times'][()]\n        self.dSet = dSet\n\n        self.dataName = dataName if dataName is not None else dSet.name.strip('/')\n\n        if exptName is not None:\n            dSet.attrs['Experiment Name'] = self.exptName = exptName\n\n        bg = dSet.attrs['background'][()]\n        ref = dSet.attrs['reference'][()]\n        ref -= bg\n        yData = dSet[()] - bg\n        yData /= ref\n\n        self.yData = np.log10(1/yData)\n        self.startWl = startWl\n        self.endWl = endWl\n\n        self.saveFigs = saveFigs\n\n        if 'AggInc' in dSet.attrs.keys():\n            self.startPoint = dSet.attrs['Start Point']\n            self.endPoint   = dSet.attrs['End Point']\n            self.trapDiff   = dSet.attrs['AggInc']\n\n        else:\n            self.findStartPoint(plot = startPointPlot, thresh = startPointThresh, tInit = tInit)\n            dSet.attrs['Start Point'] = self.startPoint\n            dSet.attrs['End Point'] = self.endPoint\n            dSet.attrs['AggInc'] = self.trapDiff\n\n        if initSpec == False:\n            self.initSpec = None\n\n        elif initSpec is None:  \n            if 'AuNP Spectrum' in dSet.attrs.keys():\n                x = dSet.attrs['AuNP Wavelengths'][()]\n                y = dSet.attrs['AuNP Spectrum'][()]\n                self.initSpec = ExtinctionSpectrum(x, y)\n\n            self.initSpec = findAunpSpectrum(dSet.file.filename)\n        else:\n            self.initSpec = initSpec\n\n        if 'Dimer Centers' in dSet.attrs.keys():\n            self.dimerCenters = dSet.attrs['Dimer Centers']\n            self.dimerHeights = dSet.attrs['Dimer Heights']\n            self.dimerFwhms   = dSet.attrs['Dimer Fwhms']\n\n            self.chainHeights = dSet.attrs['Chain Heights']\n            self.chainFwhms   = dSet.attrs['Chain Fwhms']\n            self.chainCenters = dSet.attrs['Chain Centers']",
  "def findStartPoint(self, plot = False, thresh = 2, tInit = 15):\n        x = self.x\n        t = self.t \n        yData = self.yData\n\n        startIndex = abs(x-600).argmin()\n        endIndex = abs(x-900).argmin()\n\n        trapInts = np.asarray([np.trapz(y[startIndex:endIndex], x = x[startIndex:endIndex]) for y in yData])\n        trapIntMaxs = np.array([i for i in mpf.detectMinima(-trapInts) if t[i] < tInit])\n\n        if len(trapIntMaxs) == 0:\n            trapIntMaxs = np.array([0])\n\n        trapIntMins = np.array([i for i in mpf.detectMinima(trapInts) if t[i] < tInit and i > trapIntMaxs.max()])\n\n        if len(trapIntMins) == 0:\n            trapAvg = np.average([i for t, i in zip(t, trapInts) if t > tInit])\n\n            d1 = mpf.centDiff(t, trapInts)\n            trapIntMaxs = np.array([i for i in mpf.detectMinima(trapInts) if t[i] < tInit and trapInts[i] > trapAvg*thresh])\n\n            if len(trapIntMaxs) == 0:\n                trapIntMaxs = np.array([0])\n\n            trapIntMins = np.array([i for i in mpf.detectMinima(d1) if t[i] < tInit and i > trapIntMaxs.max() and trapInts[i] < trapAvg*thresh])\n\n            if plot == True:\n                fig = plt.figure()\n                ax1 = fig.add_subplot(111)\n                ax2 = ax1.twinx()\n                ax1.plot(t, trapInts)\n                ax2.plot(t, d1, 'k')\n                ax1.plot(t[trapIntMaxs], trapInts[trapIntMaxs], 'ro')\n                ax1.plot(t[trapIntMins], trapInts[trapIntMins], 'go')\n\n                plt.show()\n\n        startPoint = trapIntMins.min()\n        endPoint = startPoint + trapInts[startPoint:].argmax()\n\n        if endPoint < startPoint + 30:\n            endPoint = len(trapInts) - 1\n\n        self.trapDiff = trapInts[endPoint] - trapInts[startPoint]\n\n        if plot == True:\n            print(trapInts[endPoint] - trapInts[startPoint])\n            plt.plot(t, trapInts)\n            plt.plot(t[startPoint], trapInts[startPoint], 'go')\n            plt.plot(t[endPoint], trapInts[endPoint], 'ro')\n            #plt.xlim(*t[stEnd])\n            plt.xlabel('Time (s)')\n            plt.ylabel('Integrated aggregate modes')\n            plt.show()\n        \n        self.startPoint = startPoint\n        self.endPoint = endPoint",
  "def inputStartPoint(self, startPoint):\n        self.startPoint = startPoint",
  "def inputEndPoint(self, endPoint):\n        self.endPoint = endPoint",
  "def fitSpectra(self, dSet, dimerPlot = False, debug = False):\n        x = self.x\n        yData = self.yData\n\n        scanTimes = self.t\n        startPoint = self.startPoint\n        endPoint = self.endPoint\n\n        initSpec = self.initSpec\n\n        specDict = {}\n\n        nummers = np.arange(20, 101, 20)\n\n        if len(yData[startPoint:]) > 500:\n            nummers = np.arange(10, 101, 10)\n\n        if len(yData[startPoint:]) > 1500:\n            nummers = np.arange(5, 101, 5)\n\n        totalFitStart = time.time()\n        print('\\n0% complete')\n        failures = 0\n\n        initDimerWl = None\n\n        for n, (y, t) in enumerate(zip(yData[startPoint:], scanTimes[startPoint:]), startPoint):\n            dimerWl = None if n == 0 else dSet.attrs.get('Dimer Guess', None)\n            spectrum = ExtinctionSpectrum(x, y, initSpec = initSpec, startWl = self.startWl, endWl = self.endWl)\n            if debug == True:\n                spectrum.debug()\n            try:\n                spectrum.fitAggPeaks(dimerWl = dimerWl)\n            except:\n                #print(f'Spectrum {n} failed')\n                plt.close('all')\n                #spectrum.fitAggPeaks(dimerWl = dimerWl)\n                spectrum.makeNull()\n                failures += 1\n\n            if initDimerWl is None:\n                spectrum.findDimerIndex(plot = dimerPlot)\n                initDimerWl = spectrum.dimerWl          \n\n            if (n == 0 or dimerWl is None) and spectrum.specMaxWl is not None:\n                dSet.attrs['Dimer Guess'] = spectrum.specMaxWl\n\n            if spectrum.dimerCenter is None:\n                failures += 1\n\n            specDict[n] = spectrum\n\n            if 100 * n//len(yData[startPoint:]) in nummers:\n                currentTime = time.time() - totalFitStart\n                mins = int(currentTime//60)\n                secs = currentTime % 60\n                print(f'{nummers[0]}% ({n} spectra) analysed in {mins} min {secs:.3f} sec')\n                nummers = nummers[1:]\n\n        if initDimerWl is not None:\n            dSet.attrs['Dimer Wavelength (t0)'] = initDimerWl\n            print(f'\\nDimer Wavelength = {initDimerWl}\\n')\n        else:\n            dSet.attrs['Dimer Wavelength (t0)'] = 'N/A'\n            print(f'\\nNo dimer peak detected\\n')\n\n        print\n\n        nSpectra = np.arange(len(yData))\n\n        if failures > len(yData)/5:\n            print('\\nLots of fits failed for this one (can be an issue with low concentrations)')\n\n        self.dimerCenters = np.array([specDict.get(n, ExtinctionSpectrum(None, None)).dimerCenter for n in nSpectra])\n        self.chainCenters = np.array([specDict.get(n, ExtinctionSpectrum(None, None)).chainCenter for n in nSpectra])\n\n        dimerWlAvg = np.nanmean(self.dimerCenters)\n        dimerWlStd = np.nanstd(self.dimerCenters)\n        self.dimerCenters = np.array([i if abs(dimerWlAvg - i) < dimerWlStd*3 else np.nan for i in self.dimerCenters])\n\n        chainWlAvg = np.nanmean(self.chainCenters[2:10])\n        chainWlStd = np.nanstd(self.chainCenters[2:10])\n        self.chainCenters[:10] = np.array([i if (abs(chainWlAvg - i) < chainWlStd*2 and i > self.dimerCenters[n] and i > 0) else np.nan for n, i in enumerate(self.chainCenters[:10])])\n\n        dSet.attrs['Dimer Centers'] = self.dimerCenters \n        dSet.attrs['Chain Centers'] = self.chainCenters \n\n        dSet.attrs['Dimer Heights'] = self.dimerHeights = np.array([specDict.get(n, ExtinctionSpectrum(None, None)).dimerHeight for n in nSpectra])\n        dSet.attrs['Dimer Fwhms']   = self.dimerFwhms   = np.array([specDict.get(n, ExtinctionSpectrum(None, None)).dimerFwhm   for n in nSpectra])\n        \n        dSet.attrs['Chain Heights'] = self.chainHeights = np.array([specDict.get(n, ExtinctionSpectrum(None, None)).chainHeight for n in nSpectra])\n        dSet.attrs['Chain Fwhms']   = self.chainFwhms   = np.array([specDict.get(n, ExtinctionSpectrum(None, None)).chainFwhm   for n in nSpectra])",
  "def plotIndividual(self, specN = 0, plotDimer = False, plotChain = False, plotProgress = False, saveFig = None, returnOnly = False):\n        makeDir('Plots')\n        dataName = self.dataName\n        if '/' in dataName:\n            dataName = dataName.split('/')[-1]\n\n        x = self.x\n        yData = self.yData\n\n        scanTimes = self.t\n        startPoint = self.startPoint\n        specN += startPoint\n        endPoint = self.endPoint\n        initSpec = self.initSpec\n\n        saveFig = self.saveFigs if saveFig is None else saveFig\n\n        y = yData[specN]\n        spectrum = ExtinctionSpectrum(x, y, initSpec = initSpec, startWl = self.startWl, endWl = self.endWl)\n        xTrunc, yTrunc, ySub = spectrum.xTrunc, spectrum.yTrunc, spectrum.ySub\n\n        if returnOnly == True:\n            return xTrunc, ySub\n\n        print(f'Plotting {dataName} Spectrum {specN}...')\n\n        if any([plotDimer, plotChain]):\n            spectrum.fitAggPeaks(plot = plotProgress)\n\n        fig, (ax1, ax2) = plt.subplots(2, sharex = True)\n        ax1.plot(xTrunc, yTrunc)\n        ax2.plot(xTrunc, ySub)\n\n        if plotDimer == True:\n            dimerX, dimerY = spectrum.dimerCenter, spectrum.dimerHeight\n            dimerLorentz = spectrum.dimerFit\n            ax2.plot(xTrunc, dimerLorentz)\n            ax2.plot(dimerX, dimerY, 'ro')\n\n        if plotChain == True:\n            chainX, chainY = spectrum.chainCenter, spectrum.chainHeight\n            chainLorentz = spectrum.chainFit\n            ax2.plot(xTrunc, chainLorentz)\n            ax2.plot(chainX, chainY, 'o', color = 'darkred')\n\n        if all([plotDimer, plotChain]):\n            ax2.plot(xTrunc, dimerLorentz + chainLorentz)\n\n        fig.suptitle(dataName)\n        ax1.set_xlim(xTrunc.min(), xTrunc.max())\n        ax2.set_xlim(ax1.get_xlim())\n        ax2.set_xlabel('Wavelength (nm)')\n        ax1.set_ylabel('Absorbance')\n        ax2.set_ylabel('A - A$_{\\mathrm{AuNP}}$')\n        plt.subplots_adjust(hspace = 0.05)\n\n        if saveFig == True:\n            imgFName = f'Plots/{dataName}.svg'\n            fig.savefig(imgFName, bbox_inches = 'tight')\n            print(f'Saved as {imgFName}')\n            plt.close('all')\n\n        else:\n            plt.show()",
  "def plotSpectra(self, cmap = 'jet', saveFig = None, redDots = False):\n        print('Plotting...\\n')\n        makeDir('Plots')\n        dataName = self.dataName\n        if '/' in dataName:\n            dataName = dataName.split('/')[-1]\n\n        saveFig = self.saveFigs if saveFig is None else saveFig\n\n        x = self.x\n        yData = self.yData\n\n        scanTimes = self.t\n        startPoint = self.startPoint\n        endPoint = self.endPoint\n\n        initSpec = self.initSpec\n\n        nCols = len(yData[startPoint:endPoint])\n\n        fig, (ax1, ax2) = plt.subplots(2, sharex = True)\n        initX, initY = initSpec.xTrunc, initSpec.yTrunc\n        ax1.plot(initX, initY, 'k')\n        cmap = plt.get_cmap(cmap, nCols)\n\n        for n, (y, t) in enumerate(zip(yData[startPoint:], scanTimes[startPoint:]), startPoint):\n            spectrum = ExtinctionSpectrum(x, y, initSpec = initSpec, startWl = self.startWl, endWl = self.endWl)\n            xTrunc, yTrunc, ySub = spectrum.xTrunc, spectrum.yTrunc, spectrum.ySub\n            \n            if n > nCols:\n                color = 'gray'\n                alpha = 0.5\n            else:\n                color = cmap(n)\n                alpha = 1\n\n            dimerX, dimerY = self.dimerCenters[n], self.dimerHeights[n]\n            chainX, chainY = self.chainCenters[n], self.chainHeights[n]\n\n            ax1.plot(xTrunc, yTrunc, color = color, zorder = -n)\n            ax2.plot(xTrunc, ySub, color = color, alpha = alpha, zorder = -2*n)\n\n            if redDots == True:\n                ax2.plot(dimerX, dimerY, 'ro', zorder = n)\n                ax2.plot(chainX, chainY, 'o', color = 'darkred', zorder = n)            \n\n        fig.suptitle(dataName)\n        ax1.set_xlim(xTrunc.min(), xTrunc.max())\n        ax2.set_xlim(ax1.get_xlim())\n        ax2.set_xlabel('Wavelength (nm)')\n        ax1.set_ylabel('Absorbance')\n        ax2.set_ylabel('A - A$_{\\mathrm{AuNP}}$')\n        plt.subplots_adjust(hspace = 0.05)\n        if saveFig == True:\n            imgFName = f'Plots/{dataName}.png'\n            fig.savefig(imgFName, bbox_inches = 'tight')\n            print(f'Saved as {imgFName}')\n            plt.close('all')\n\n        else:\n            plt.show()",
  "def plotOverviews(self, saveFig = True):\n        makeDir('Plots')\n        dataName = self.dataName\n        if '/' in dataName:\n            dataName = dataName.split('/')[-1]\n        startPoint = self.startPoint\n        t = self.t[startPoint:]\n        dimerX = self.dimerCenters[startPoint:]\n        dimerY = self.dimerHeights[startPoint:]\n        dimerW = self.dimerFwhms[startPoint:]\n\n        chainX = self.chainCenters[startPoint:]\n        chainY = self.chainHeights[startPoint:]\n        chainW = self.chainFwhms[startPoint:]\n\n        fig = plt.figure()\n        ax1 = fig.add_subplot(111)\n\n        dXPlot = ax1.plot(t, dimerX, 'o-', label = '$\\lambda_\\mathrm{Dimer}$')\n        cXPlot = ax1.plot(t, chainX, 'o-', label = '$\\lambda_\\mathrm{Chain}$')\n        ax1.legend(loc = 0)\n\n        ax1.set_xlabel('Time (s)')\n        ax1.set_ylabel('Peak Wavelength (nm)')\n        plt.title(dataName)\n        if saveFig == True:\n            imgFName = f'Plots/{dataName} wl vs t.svg'\n            fig.savefig(imgFName, bbox_inches = 'tight')\n            print(f'Saved as {imgFName}')\n            plt.close('all')\n\n        else:\n            plt.show()\n\n        fig = plt.figure()\n        ax = fig.add_subplot(111)\n        ax.plot(t, dimerY, 'o-', color = dXPlot[0].get_color(), label = 'Dimer')\n        ax.plot(t, chainY, 'o-', color = cXPlot[0].get_color(), label = 'Chain')\n        ax.set_xlabel('Time (s)')\n        ax.set_ylabel('Peak Absorbance')\n        plt.title(dataName)\n        if saveFig == True:\n            imgFName = f'Plots/{dataName} i vs t.svg'\n            fig.savefig(imgFName, bbox_inches = 'tight')\n            print(f'Saved as {imgFName}')\n            plt.close('all')\n\n        else:\n            plt.show()\n\n        print('')",
  "def extractDimerSpectrum(self, plot = True, endWl = 900, limit = 15):\n        x = self.x\n        yData = self.yData[self.startPoint:]\n        \n        dimerWl = None\n        n = 0\n        while dimerWl is None and n < limit:        \n            spectrum = ExtinctionSpectrum(x, yData[n], endWl = endWl, initSpec = self.initSpec)\n            xTrunc, ySub = spectrum.xTrunc, spectrum.ySub\n\n            try:\n                spectrum.fitAggPeaks(dimerWl = dimerWl)\n                spectrum.findDimerIndex(plot = plot)\n                dimerWl = spectrum.dimerWl\n                dimerFwhm = spectrum.dimerFwhm\n\n            except:\n                print(f'Spectrum {n + self.startPoint} failed for {self.dataName}')\n                dimerWl = None\n                dimerFwhm = None\n                \n            n += 1\n\n        self.dimerWl = dimerWl\n        self.dimerFwhm = dimerFwhm\n        \n        if n >= 15:\n            print('\\tDimer detection failed')\n            return spectrum\n            \n        elif n > 0:\n            print(f'\\tSucceeded for Spectrum {n + self.startPoint}')\n        \n        print(f'\\tDimer Wl = {dimerWl:.2f} nm')\n        print(f'\\tFWHM = {dimerFwhm:.2f} nm\\n')\n\n        return spectrum",
  "def __init__(self, filename):\n        self.filename = filename\n        self.dSetNames = self.getDsetNames(nDims = 2)\n        self.spectraNames = self.getDsetNames(nDims = 1)\n        self.initialiseDatasets()\n        self.initSpec = self.findAunpSpectrum()",
  "def getDsetNames(self, nDims = 2):\n        with h5py.File(self.filename, 'r') as f:\n            dSetNames = []\n            f.visit(dSetNames.append)\n            dSetNames = [dSetName for dSetName in dSetNames if isinstance(f[dSetName], h5py.Dataset)]\n            \n            return [dSetName for dSetName in dSetNames if f[dSetName][()].ndim == nDims]",
  "def initialiseDatasets(self):\n        print('Initialising timescan data...')\n\n        with h5py.File(self.filename, 'a') as f:\n            for dSetName in self.dSetNames:\n                if 'Start Point' not in f[dSetName].attrs.keys():\n                    print(f'\\t{dSetName}')\n                    dataSet = AggExtDataset(f[dSetName], dataName = dSetName, initSpec = False)\n\n        print('\\n\\tData initialised\\n')",
  "def updateAunpSpecs(self, x, y):        \n        with h5py.File(self.filename, 'a') as f:\n            for dSetNames in self.dSetNames:\n                f[dSetNames].attrs['AuNP Spectrum'] = y\n                f[dSetNames].attrs['AuNP Wavelengths'] = x",
  "def findAunpSpectrum(self, reUse = True, extH5File = None):\n        '''\n        searches through h5 file for non-aggregated AuNP spectrum\n        '''\n        h5File = self.filename\n        if extH5File is not None:\n            currH5File = h5File\n            h5File = extH5File\n\n        print(f'Searching for AuNP monomer spectrum candidates in {h5File}...')\n\n        timeScans = self.dSetNames\n        singleSpecs = self.spectraNames\n\n        with h5py.File(h5File, 'a') as f:\n            candidates = []\n\n            for i in timeScans:\n                if reUse == True:\n                    if 'AuNP Spectrum' in f[i].attrs.keys():\n                        y = f[i].attrs['AuNP Spectrum']\n                        x = f[i].attrs['AuNP Wavelengths']\n                        print('\\tAuNP monomer spectrum found\\n')\n\n                        if extH5File is not None:\n                            updateAunpSpecs(currH5File, x, y)\n                        \n                        return ExtinctionSpectrum(x, y)\n\n                if 'AggInc' not in f[i].attrs.keys():\n                    dataset = AggExtDataset(f[i], initSpec = False)\n\n            allSpecs = sorted([i for i in timeScans if 'AggInc' in f[i].attrs.keys()], key = lambda i: f[i].attrs['AggInc'])\n            allSingles = singleSpecs\n\n            #for specName in allSpecs:\n            #    if 'AuNP Spectrum' in f[specName].attrs.keys():\n            #        return f[specName].attrs['AuNP Spectrum'][()]\n\n            integrals = []\n\n            for i in allSingles:\n                spectrum = f[i]\n                x = spectrum.attrs['wavelengths'][()]\n                y = spectrum[()]\n                bg = spectrum.attrs['background'][()] \n                ref = spectrum.attrs['reference'][()] \n                ref -= bg\n                y -= bg\n                y /= ref\n                y = np.log10(1/y)\n\n                candidates.append((x, y))\n                xTrunc, yTrunc = mpf.truncateSpectrum(x, y, startWl = 600, finishWl = 970)\n                integrals.append(np.trapz(yTrunc, x = xTrunc))        \n\n            for dSetName in allSpecs:\n                dSpectra = f[dSetName]\n                x = dSpectra.attrs['wavelengths'][()] \n                startPoint = dSpectra.attrs['Start Point']\n                y = dSpectra[()][startPoint]\n                bg = dSpectra.attrs['background'][()] \n                ref = dSpectra.attrs['reference'][()] \n                ref -= bg\n                y -= bg\n                y /= ref\n                y = np.log10(1/y)\n\n                candidates.append((x, y))\n                xTrunc, yTrunc = mpf.truncateSpectrum(x, y, startWl = 600, finishWl = 970)\n                integrals.append(np.trapz(yTrunc, x = xTrunc))\n\n            candidates = [i[0] for i in sorted(zip(candidates, integrals), key = lambda i: i[1])]\n\n            if len(candidates) == 0:\n                print('agfsfghfsgh')\n\n            for n, (x, y) in enumerate(candidates):\n                xTrunc, yTrunc = mpf.truncateSpectrum(x, y, startWl = 400, finishWl = 950)\n                \n                plt.plot(xTrunc, yTrunc)\n                plt.xlim(xTrunc.min(), xTrunc.max())\n                plt.title(f'Attempt {n}')\n                plt.show()\n\n                query = 'Is this AuNP monomer spectrum acceptable? There should be no visible dimer peak.\\n**If any aggregation is visible, enter \"n\" until you find one without it**  \\\n                                  \\nEnter y to accept; n to find another spectrum; x to exit; anything else to see more options\\n\\n'\n\n                if n > 0:\n                    query = 'y to accept; n to find another spectrum; x to exit; anything else to see more options\\n\\n'\n            \n                decision = input(query)\n\n                if decision == 'y':\n                    print('\\nOk, saving this for future use. Please wait while Dataset attributes are updated...')\n                    for specName in allSpecs:\n                        self.updateAunpSpecs(x, y)\n                        if extH5File is not None:\n                            self.updateAunpSpecs(currH5File, x, y)\n                        f[specName].attrs['AuNP Spectrum'] = y\n                        f[specName].attrs['AuNP Wavelengths'] = x\n                    print('\\tDone\\n')\n                    return ExtinctionSpectrum(x, y)\n                \n                elif decision == 'n':\n                    continue\n                elif decision == 'x':\n                    print(1/0)\n                else:\n                    break\n\n            query = ''.join(['No monomeric AuNP spectrum found. Please select an option to continue:\\n',\n                             '\\t1. Specify a different .h5 file with a monomeric AuNP spectrum\\n', \n                             '\\t2. Manually specify \"initSpec = [x, y]\" when calling fitAllSpectra\\n',\n                             '\\t3. Manually add AuNP xy data to the .h5 file before running again\\n\\n'])\n\n            decision = input(query)\n\n            while decision not in ['1', '2', '3', 1, 2, 3]:\n                if decision == 'x':\n                    break\n                decision = input('Please enter 1, 2 or 3. Enter x to exit:\\n\\n')            \n\n            if decision in [1, '1']:\n                extH5File = input(\"Please enter the full path to the .h5 file containing your spectrum:\\n\\n\")\n\n                while not extH5File.endswith('.h5'):\n                    if not extH5File.endswith('.h5'):\n                        extH5File = input('Are you sure this is correct? Please try again:\\n\\n')\n                    if extH5File == 'x':\n                        break\n\n                extH5File = '/'.join(extH5File.split('\\\\'))\n            \n                aunpSpec = self.findAunpSpectrum(reUse = True, extH5File = extH5File)\n                print('AuNP Spectrum successfully added')\n\n                return aunpSpec\n\n            elif decision in [2, '2']:\n                print('Find some appropriate [x, y] data and run fitAllSpectra again, specifying \"initSpec = [x, y]\"')\n                print(1/0)\n\n            elif decision in [3, '3']:\n                print(\"Find some appropriate y data and save it as a new Dataset in the current hdf5 File with Dataset.attrs['wavelengths'] = x, then try again\")\n                print(1/0)\n\n            print(1/0)",
  "def findDimerPeaks(self, plot = True, endWl = 900):\n        specDict = {}\n\n        initSpec = self.initSpec\n\n        with h5py.File(self.filename, 'a') as f:\n            for dSetName in self.dSetNames[:]:\n                print(dSetName)\n                initSpecs = []\n                dimerWls = []\n                dataSet = AggExtDataset(f[dSetName], initSpec = self.initSpec, saveFigs = False, endWl = endWl)\n                \n                dimerSpectrum = dataSet.extractDimerSpectrum(plot = plot, endWl = endWl)\n                dimerWl = dataSet.dimerWl\n                dimerFwhm = dataSet.dimerFwhm\n                specDict[dSetName] = {'xy' : [dimerSpectrum.xTrunc, dimerSpectrum.ySub], 'dimerWl' : 0 if dimerWl is None else dimerWl, 'dimerFwhm' : 0 if dimerWl is None else dimerFwhm}\n\n                f[dSetName].attrs['Dimer Wavelength (t0)'] = dimerWl if dimerWl is not None else np.nan\n\n        print('Done')\n\n        self.dimerSpecDict = specDict\n\n        return specDict",
  "def fitAllSpectra(self, nameDict = {}, dimerPlot = False, saveFigs = True, startWl = 420, endWl = 950, startPointPlot = False, startPointThresh = 2, \n                      tInit = 15, debug = False):\n\n        print('Beginning fit\\n')\n\n        with h5py.File(self.filename, 'a') as f:\n            for specN, dataName in enumerate(self.dSetNames):\n                exptName = nameDict.get(dataName.split('/')[-1], None)\n                print(dataName)\n                if exptName is not None:\n                    print(f'\\t(= {exptName})')\n                dSpectra = f[dataName]\n                if len(dSpectra[()]) == 1:\n                    continue\n\n                dataSet = AggExtDataset(dSpectra, dataName = dataName, exptName = exptName, initSpec = self.initSpec, startWl = startWl, endWl = endWl, \n                                        startPointPlot = startPointPlot, startPointThresh = startPointThresh, tInit = tInit)\n                dataSet.fitSpectra(dSpectra, dimerPlot = dimerPlot, debug = debug)\n                makeDir('Plots')\n                dataSet.plotSpectra(saveFig = saveFigs)\n                dataSet.plotOverviews(saveFig = saveFigs)\n\n        print('\\nAll done')",
  "def single_pulse_MPE(wavelength,pulse_width = 100E-15,divergence = 1.1):\n    \"\"\" A single pulse MPE calculator for pulsed systems, units are nm,t, and mrad\n    Currently only works for 100fs to 10 ps pulses or ms->seconds of exposure\"\"\"\n    if wavelength>400 and wavelength<450:\n        c3 = 1\n    elif wavelength > 450 and wavelength<600:\n        c3 = 10.0**(0.02*(wavelength-450))\n    elif wavelength>700 and wavelength<1050:\n        c4 = 10.0**(0.002*(wavelength-700))\n    elif wavelength>1050 and wavelength<1400:\n        c4 = 5\n    if wavelength>400 and wavelength<1400:\n        if divergence<1.5:\n            c6 = 1\n            T2 = 10\n        elif divergence>1.5 and divergence<100:\n            c6 = divergence/1.5\n            T2 = 10*10**((divergence-1.5)/98.5)\n        elif divergence>100.0:\n            c6 = 100.0/1.5\n            T2 = 100.0 \n    if wavelength>1050 and wavelength<=1150:\n        c7 = 1\n    if wavelength>1150 and wavelength<=1200:\n        c7 = 10.0**(0.018*(wavelength-1150))\n    if wavelength>1200 and wavelength <=1400:\n        c7 = 8\n        \n    if pulse_width>99E-15 and pulse_width<10E-11:\n        if wavelength>400 and wavelength<=700:\n            return 1.5E-4*c6\n        if wavelength>700 and wavelength<=1050:\n            return 1.5E-4*c4*c6\n        if wavelength>1050 and wavelength<=1400:\n            return 1.5E-3*c6*c7\n        if wavelength>1400 and wavelength<=1500:\n            return 1E12*pulse_width\n        if wavelength>1500 and wavelength<=1800:\n            return 1E13*pulse_width\n        if wavelength>1800 and wavelength<=2600:\n            return 1E12*pulse_width\n        if wavelength>2600:\n            return 1E11*pulse_width\n    if pulse_width>=1E-3 and pulse_width<=10:\n        if wavelength>400 and wavelength<=700:\n            return 18*pulse_width**0.75*c6\n        if wavelength>700 and wavelength<=1050:\n            return 18*pulse_width**0.75*c6*c4\n        if wavelength>1050 and wavelength<=1400:\n            return 90.0*pulse_width**0.75*c6*c7\n        if wavelength>1400 and wavelength<=1500:\n            return 5600*pulse_width**0.25\n        if wavelength>1500 and wavelength<=1800:\n            return 10**4\n        if wavelength>1800 and wavelength<=2600:\n            return 5600*pulse_width**0.25   \n        if wavelength>2600:\n            return 5600*pulse_width**0.25",
  "def power_at_dist(power,distance):\n    '''power at a distance from a scattering point '''\n    surface_area = 2.0*np.pi*distance**2\n    return old_div(power,surface_area)",
  "def calculate_MPEs(wavelength,pulse_width = 100E-15,divergence = 1.1,frequency = 80E6):\n    '''Calculate the Three different MPE's required for pulsed lasers'''\n    mpe_single = single_pulse_MPE(wavelength,pulse_width,divergence)\n    if wavelength>=400 and wavelength<=700:\n        mpe_average = single_pulse_MPE(wavelength,0.25,divergence)\n        num_pulses = (0.25*frequency)\n        mpe_average=old_div(mpe_average,num_pulses)\n    else:\n        mpe_average = single_pulse_MPE(wavelength,10.0,divergence)\n        num_pulses= (10*frequency)\n        mpe_average = old_div(mpe_average,num_pulses)\n    mpe_train = mpe_single*num_pulses**(-0.25)\n    return np.array((mpe_single, mpe_average, mpe_train))*frequency",
  "def load_h5(location='.'):\n    '''return the latest h5 in a given directory. If location is left blank,\n    loads the latest file in the current directory.'''\n    path = Path(location)\n    candidates_dates = [(f, [int(m) for m in match.groups()]) for f in path.iterdir()\\\n                        if (match := re.match(H5_TEMPLATE, f.name))]\n    if candidates_dates:\n        return h5py.File(path / max(candidates_dates, key=lambda cd: cd[1])[0], 'r') \n    else:\n        raise ValueError('No suitable h5 file found')",
  "def latest_scan(file):\n    '''returns the last ParticleScannerScan in a file'''\n    return file[max(file, key=lambda x: int(x.split('_')[-1])\n                    if x.startswith('ParticleScannerScan') else -1)]",
  "class Spectrum(np.ndarray):\n    '''acts a an ndarray, but has a wavelengths attribute,\n    and several useful methods for spectra. Can be 1 or 2d (time series/z-scan)'''\n    \n    def __new__(cls, spectrum, wavelengths, *args, **kwargs):\n        '''boilerplate numpy subclassing'''\n        assert len(wavelengths) == np.shape(spectrum)[-1]\n\n        obj = np.asarray(spectrum).view(cls)\n        obj.wavelengths = np.asarray(wavelengths)\n        return obj\n\n    def __array_finalize__(self, obj):\n        '''boilerplate numpy subclassing'''\n        if obj is None:\n            return\n        if not obj.shape:\n            return np.array(obj)\n        self.wavelengths = getattr(\n            obj, 'wavelengths', np.arange(obj.shape[-1]))\n     \n    def __reduce__(self):\n        # Get the parent's __reduce__ tuple\n        pickled_state = super().__reduce__()\n        # Create our own tuple to pass to __setstate__\n        new_state = pickled_state[2] + (self.wavelengths,)\n        # Return a tuple that replaces the parent's __setstate__ tuple with our own\n        return (pickled_state[0], pickled_state[1], new_state)\n\n    def __setstate__(self, state):\n        self.wavelengths = state[-1]  # Set the info attribute\n        # Call the parent's __setstate__ with the other tuple elements.\n        super().__setstate__(state[0:-1])\n\n    @classmethod\n    def from_h5(cls, dataset):\n        '''create instance using a h5 dataset.\n        will background-subtract and reference the spectrum if these\n        attributes are saved'''    \n        attrs = dataset.attrs\n        ref = attrs.get('reference', 1)\n        bg = attrs.get('background', 0)\n        return cls((dataset[()]-bg)/(ref-bg), dataset.attrs['wavelengths'])\n\n    @property\n    def wl(self):\n        '''convenient for accessing wavelengths'''\n        return self.wavelengths\n\n    @wl.setter\n    def wl(self, value):\n        '''convenient for accessing wavelengths'''\n        self.wavelengths = np.array(value)\n\n    @property\n    def x(self):\n        '''abstraction of x axis for using shifts or wavelengths'''\n        return self.wavelengths # wavelengths unless subclassed\n\n    def split(self, lower=-np.inf, upper=np.inf):\n        '''returns the spectrum between the upper and lower bounds'''\n        if upper < lower:\n            upper, lower = lower, upper\n        condition = (lower <= self.x) & (self.x < upper)  \n        # '<=' allows recombination of an array into the original\n        return self.__class__(self.T[condition].T, self.x[condition])\n\n    def norm(self):\n        '''return an spectrum divided by its largest value'''\n        return self.__class__(self/self.ravel().max(), self.x)\n    \n    def squash(self):\n        '''condense a time_series into one spectrum'''\n        return self.__class__(self.sum(axis=0), self.x)\n    \n    def smooth(self, sigma):\n        '''smooth using scipy.ndimage.guassian_smooth'''\n        return self.__class__(gaussian_filter(self, sigma), self.x)\n    \n    def savgol_smooth(self, *args, **kwargs):\n        return self.__class__(savgol_filter(self, *args, **kwargs), self.x)\n    \n    def remove_cosmic_ray(self,\n                          thresh=5,\n                          smooth=30,\n                          max_iterations=10):\n        '''wrapper around remove_cosmic_ray to allow 2d or 1d spectra\n        to be passed'''\n        func = lambda s: remove_cosmic_ray(s,\n                                           thresh=thresh,\n                                           smooth=smooth,\n                                           max_iterations=max_iterations)\n        if len(self.shape) == 2:\n            return self.__class__([func(s) for s in self], \n                                  self.x,)\n        return self.__class__(func(self), self.x)",
  "class RamanSpectrum(Spectrum):\n    '''\n    Uses shifts as its x axis. These are the values used in split() etc. \n    When creating, either supply shifts directly, or they'll be calculated\n    the first time they're accessed using wavelengths and laser_wavelength.\n    \n    To use with a different laser wavelength, change the class attribute \n    after importing:\n    >>> RamanSpectrum.laser_wavelength = 785.\n    \n    if you frequently use two wavelengths in the same analysis, create a \n    subclass:\n    >>> class RamanSpectrum785(RamanSpectrum):\n            laser_wavelength = 785.\n        class RamanSpectrum532(RamanSpectrum):\n            laser_wavelength = 532.\n        \n    '''\n    \n    laser_wavelength = 632.8\n    def __new__(cls, \n                spectrum,\n                shifts=None,\n                wavelengths=None,\n                *args, **kwargs):\n        assert not (shifts is None and wavelengths is None),\\\n        'must supply shifts or wavelengths'\n        obj = np.asarray(spectrum).view(cls)\n        if wavelengths is not None:\n            wavelengths = np.asarray(wavelengths)\n        obj.wavelengths = wavelengths\n        if shifts is not None:\n            shifts = np.asarray(shifts)\n        obj._shifts = shifts\n        \n        obj.laser_wavelength = cls.laser_wavelength \n        # stops existing instances' laser_wavelength being changed by changing\n        # the class attribute \n        return obj\n\n    def __array_finalize__(self, obj):\n\n        if obj is None:\n            return\n        if not obj.shape:\n            return np.array(obj)\n        self.wavelengths = getattr(obj,\n                                   'wavelengths',\n                                   np.arange(obj.shape[-1]))\n        self._shifts = getattr(obj, '_shifts', None)\n    \n    def __reduce__(self):\n        # Get the parent's __reduce__ tuple\n        pickled_state = super().__reduce__()\n        # Create our own tuple to pass to __setstate__\n        new_state = pickled_state[2] + (self.wavelengths,)\n        # Return a tuple that replaces the parent's __setstate__ tuple with our own\n        return (pickled_state[0], pickled_state[1], new_state)\n\n    def __setstate__(self, state):\n        self.wavelengths = state[-1]  # Set the info attribute\n        # Call the parent's __setstate__ with the other tuple elements.\n        super().__setstate__(state[0:-1])\n        \n    @classmethod\n    def from_h5(cls, dataset):\n        '''create instance using a h5 dataset.\n        will background-subtract and reference the spectrum if these\n        attributes are saved'''    \n        attrs = dataset.attrs\n        ref = attrs.get('reference', 1)\n        bg = attrs.get('background', 0)\n        return cls((dataset[()]-bg)/(ref-bg), wavelengths=dataset.attrs['wavelengths'])\n    \n    @cached_property # only ever calculated once per instance\n    def shifts(self):\n        if self._shifts is None:\n            return (1./(self.laser_wavelength*1e-9) - 1./(self.wl*1e-9))/100.\n        return self._shifts\n    \n    @property\n    def x(self):\n        return self.shifts",
  "def remove_cosmic_ray(spectrum, thresh=5, smooth=30, max_iterations=10):\n    '''\n    \n    a way of removing cosmic rays from spectra. Mainly tested with Dark-Field\n    spectra, as the spikiness of Raman makes it very difficult to do simply.\n    \n    thresh: the height above the noise level a given data point should be \n            to be considered a cosmic ray. Lower values will remove smaller cosmic rays,\n            but may start to remove higher parts of the noise if too low.\n    smooth: the 'sigma' value used to smooth the spectrum,\n            see scipy.ndimage.gaussian_filter. Should be high enough to\n            so that the shape of the spectrum is conserved, but the cosmic ray\n            is almost gone. \n    max_iterations: \n        maximum iterations. Shouldn't matter how high it is as most spectra\n        are done in 1-3. \n    \n    '''\n    _len = len(spectrum)\n    cleaned = np.copy(spectrum) # prevent modification in place\n    \n    for i in range(max_iterations): \n        noise_spectrum = cleaned/gaussian_filter(cleaned, smooth)\n        # ^ should be a flat, noisy line, with a large spike where there's\n        # a cosmic ray.\n        noise_level = np.sqrt(np.var(noise_spectrum)) \n        # average deviation of a datapoint from the mean\n        mean_noise = noise_spectrum.mean() # should be == 1\n        spikes = np.arange(_len)[noise_spectrum > mean_noise+(thresh*noise_level)]\n        # the indices of the datapoints that are above the threshold\n       \n        # now we add all data points to either side of the spike that are \n        # above the noise level (but not necessarily the thresh*noise_level)\n        rays = set()\n        for spike in spikes:\n            for side in (-1, 1): # left and right\n                step = 0\n                while 0 <= (coord := spike+(side*step)) <= _len-1:\n                    # staying in the spectrum\n                    \n                    if noise_spectrum[coord] > mean_noise + noise_level:\n                        rays.add(coord)\n                        step += 1\n                    else:\n                        break\n        rays = list(rays) # convert to list for indexing\n        if rays: # if there are any cosmic rays\n            cleaned[rays] = gaussian_filter(cleaned, smooth)[rays]\n            # replace the regions with the smooothed spectrum\n            continue # and repeat, as the smoothed spectrum will still be \n                     # quite affected by the cosmic ray. \n                     \n        # until no cosmic rays are found\n        return cleaned\n    return cleaned",
  "def __new__(cls, spectrum, wavelengths, *args, **kwargs):\n        '''boilerplate numpy subclassing'''\n        assert len(wavelengths) == np.shape(spectrum)[-1]\n\n        obj = np.asarray(spectrum).view(cls)\n        obj.wavelengths = np.asarray(wavelengths)\n        return obj",
  "def __array_finalize__(self, obj):\n        '''boilerplate numpy subclassing'''\n        if obj is None:\n            return\n        if not obj.shape:\n            return np.array(obj)\n        self.wavelengths = getattr(\n            obj, 'wavelengths', np.arange(obj.shape[-1]))",
  "def __reduce__(self):\n        # Get the parent's __reduce__ tuple\n        pickled_state = super().__reduce__()\n        # Create our own tuple to pass to __setstate__\n        new_state = pickled_state[2] + (self.wavelengths,)\n        # Return a tuple that replaces the parent's __setstate__ tuple with our own\n        return (pickled_state[0], pickled_state[1], new_state)",
  "def __setstate__(self, state):\n        self.wavelengths = state[-1]  # Set the info attribute\n        # Call the parent's __setstate__ with the other tuple elements.\n        super().__setstate__(state[0:-1])",
  "def from_h5(cls, dataset):\n        '''create instance using a h5 dataset.\n        will background-subtract and reference the spectrum if these\n        attributes are saved'''    \n        attrs = dataset.attrs\n        ref = attrs.get('reference', 1)\n        bg = attrs.get('background', 0)\n        return cls((dataset[()]-bg)/(ref-bg), dataset.attrs['wavelengths'])",
  "def wl(self):\n        '''convenient for accessing wavelengths'''\n        return self.wavelengths",
  "def wl(self, value):\n        '''convenient for accessing wavelengths'''\n        self.wavelengths = np.array(value)",
  "def x(self):\n        '''abstraction of x axis for using shifts or wavelengths'''\n        return self.wavelengths",
  "def split(self, lower=-np.inf, upper=np.inf):\n        '''returns the spectrum between the upper and lower bounds'''\n        if upper < lower:\n            upper, lower = lower, upper\n        condition = (lower <= self.x) & (self.x < upper)  \n        # '<=' allows recombination of an array into the original\n        return self.__class__(self.T[condition].T, self.x[condition])",
  "def norm(self):\n        '''return an spectrum divided by its largest value'''\n        return self.__class__(self/self.ravel().max(), self.x)",
  "def squash(self):\n        '''condense a time_series into one spectrum'''\n        return self.__class__(self.sum(axis=0), self.x)",
  "def smooth(self, sigma):\n        '''smooth using scipy.ndimage.guassian_smooth'''\n        return self.__class__(gaussian_filter(self, sigma), self.x)",
  "def savgol_smooth(self, *args, **kwargs):\n        return self.__class__(savgol_filter(self, *args, **kwargs), self.x)",
  "def remove_cosmic_ray(self,\n                          thresh=5,\n                          smooth=30,\n                          max_iterations=10):\n        '''wrapper around remove_cosmic_ray to allow 2d or 1d spectra\n        to be passed'''\n        func = lambda s: remove_cosmic_ray(s,\n                                           thresh=thresh,\n                                           smooth=smooth,\n                                           max_iterations=max_iterations)\n        if len(self.shape) == 2:\n            return self.__class__([func(s) for s in self], \n                                  self.x,)\n        return self.__class__(func(self), self.x)",
  "def __new__(cls, \n                spectrum,\n                shifts=None,\n                wavelengths=None,\n                *args, **kwargs):\n        assert not (shifts is None and wavelengths is None),\\\n        'must supply shifts or wavelengths'\n        obj = np.asarray(spectrum).view(cls)\n        if wavelengths is not None:\n            wavelengths = np.asarray(wavelengths)\n        obj.wavelengths = wavelengths\n        if shifts is not None:\n            shifts = np.asarray(shifts)\n        obj._shifts = shifts\n        \n        obj.laser_wavelength = cls.laser_wavelength \n        # stops existing instances' laser_wavelength being changed by changing\n        # the class attribute \n        return obj",
  "def __array_finalize__(self, obj):\n\n        if obj is None:\n            return\n        if not obj.shape:\n            return np.array(obj)\n        self.wavelengths = getattr(obj,\n                                   'wavelengths',\n                                   np.arange(obj.shape[-1]))\n        self._shifts = getattr(obj, '_shifts', None)",
  "def __reduce__(self):\n        # Get the parent's __reduce__ tuple\n        pickled_state = super().__reduce__()\n        # Create our own tuple to pass to __setstate__\n        new_state = pickled_state[2] + (self.wavelengths,)\n        # Return a tuple that replaces the parent's __setstate__ tuple with our own\n        return (pickled_state[0], pickled_state[1], new_state)",
  "def __setstate__(self, state):\n        self.wavelengths = state[-1]  # Set the info attribute\n        # Call the parent's __setstate__ with the other tuple elements.\n        super().__setstate__(state[0:-1])",
  "def from_h5(cls, dataset):\n        '''create instance using a h5 dataset.\n        will background-subtract and reference the spectrum if these\n        attributes are saved'''    \n        attrs = dataset.attrs\n        ref = attrs.get('reference', 1)\n        bg = attrs.get('background', 0)\n        return cls((dataset[()]-bg)/(ref-bg), wavelengths=dataset.attrs['wavelengths'])",
  "def shifts(self):\n        if self._shifts is None:\n            return (1./(self.laser_wavelength*1e-9) - 1./(self.wl*1e-9))/100.\n        return self._shifts",
  "def x(self):\n        return self.shifts",
  "def get_window(N, window_type =\"hamming\"):\n\tif window_type == \"hamming\":\n\t\t#Symmetric window for filter design? But doing spectral analysis\n\t\treturn scipy.signal.hamming(N,sym=False)\n\telif window_type == \"hann\":\n\t\treturn scipy.signal.hann(N,sym=False)",
  "def correlation_align(signal_0,signal_1,upsampling=1.0,return_integer_shift=True):\n\t#Returns the shift (integer) which signal_1 must be moved to \n\t#Align it with signal_0. Upsampling used to provide higher resolution.\n\tN = signal_0.shape[0]\n\t# assert(signal_0.shape==signal_1.shape)\n\n\tif upsampling > 1.0:\n\t\traise ValueError(\"Forbidden\")\n\t\t#TODO replace resample\n\t\t# signal_0 = scipy.signal.resample(signal_0,int(np.round(N*upsampling)))\n\t\t# signal_1 = scipy.signal.resample(signal_1,int(np.round(N*upsampling)))\n\t\tN = int(np.round(N*upsampling))\n\n\txcorr = correlate(in1=signal_0,in2=signal_1, method='fft',mode=\"same\")\n\tfull_precision_shift = shift = (np.round(N/2.0)-np.argmax(xcorr))/float(upsampling)\n\tinteger_shift = int(np.round(shift))\n\tif return_integer_shift == True:\n\t\treturn integer_shift,xcorr\n\telse:\n\t\treturn full_precision_shift,xcorr",
  "def overlap_align(signal_0, signal_1):\n\tpass",
  "def demo():\n\tN = 1014\n\tsignal0 = np.zeros(N)\n\tsignal0[300:500] = 1\n\tsignal1 = np.zeros(N)\n\tsignal1[350:550] = 1\n\n\tsignal0 = signal0 + np.random.normal(0,0.1,N)\n\tsignal1 = signal1 + np.random.normal(0,0.1,N)\n\t\n\n\tfig, axarr = plt.subplots(2)\n\tup = 1.0\n\tshift, xcorr = correlation_align(signal0,signal1,upsampling=up)\n\t\n\txs = np.array(list(range(0,N)))\n\taxarr[0].plot(xs,signal0,label=\"signal0\")\n\taxarr[0].plot(xs,signal1,label=\"signal1\")\n\taxarr[0].plot(xs-shift,signal1,label=\"signal1_shifted\")\n\taxarr[0].legend()\n\taxarr[1].plot(xcorr)\n\tplt.show()",
  "def save_rejected(rejected, path=None, overwrite=False):\n    '''saves an iterable of particle names. by default it loads the previous .txt\n    and saves the union of the new and previous ones'''\n    if path is None: path = Path()\n    existing = set() if overwrite else load_rejected(path)\n    with open(path / 'rejected.txt', 'w') as f:\n        f.truncate(0)\n        f.write('\\n'.join(existing | rejected))",
  "def load_rejected(path=Path()):\n    '''returns the contents of rejected.txt if it exists, or an empty set'''\n    if (file := path / 'rejected.txt').exists():\n        with open(path / file) as f:\n            rejected = set(l.strip() for l in f.readlines())\n    else:\n        rejected = set()\n    return rejected",
  "def distance(p1, p2):\n    '''distance between two points'''\n    return ((p1[0] - p2[0])**2 + (p1[1] - p2[1])**2)**0.5",
  "class ParticleProximityExcluder(QtWidgets.QWidget):\n    '''the general idea is that this widget identifies the particles in each \n    thumb image, and if any of them are too close to the central particle, \n    it is 'rejected'.'''\n    exclusion_radius = DumbNotifiedProperty(13)\n\n    def __init__(self, scan, image_name='CWL.thumb_image_0'):\n        super().__init__()\n        self.scan = scan\n        self.image_name = image_name\n        self.image = scan['Tiles']['tile_0'][()]\n        # pick a tile to test the filter settings - analysis is done on thumb images though.\n        self._construct()  # make the widget\n        self.update_image()\n        self.show()\n\n    def _construct(self):\n\n        layout = QtWidgets.QHBoxLayout()\n        self.resize(1200, 700)\n        self.img_widget = pg.ImageView(parent=self)\n\n        layout.addWidget(self.img_widget)\n        control_layout = QtWidgets.QVBoxLayout()\n        ibox = QuickControlBox('exclusion settings')\n        ibox.add_spinbox('exclusion_radius', 0, 100, 1)\n        ibox.auto_connect_by_name(controlled_object=self)\n        control_layout.addWidget(ibox)\n        # ie.valueChanged.connect(lambda x: setattr(self, 'image_exclusion_fraction', x)) # gui to prop\n        # register_for_property_changes(self, 'image_exclusion_fraction', ie.setValue)\n\n        register_for_property_changes(self, 'exclusion_radius',\n                                      self.update_image)  # prop to image\n        self.filter_box = Image_Filter_box()\n        control_layout.addWidget(self.filter_box.get_qt_ui())\n        self.filter_box.connect_function_to_property_changes(self.update_image)\n        self.run_pushButton = QtWidgets.QPushButton('Run')\n        self.run_pushButton.clicked.connect(self.run)\n        control_layout.addWidget(self.run_pushButton)\n        control_box = QtWidgets.QFrame()\n        control_box.setLayout(control_layout)\n        layout.addWidget(control_box)\n        self.setLayout(layout)\n\n    def update_image(self, *value):\n        \"\"\"\n        Apply live updates to the example image as the image filtering properties are changed\n        \"\"\"\n\n        filtered_image = self.filter_box.current_filter(self.image)\n        im = np.copy(filtered_image)\n        if self.filter_box.current_filter_index == 1:\n            centers, radii = self.filter_box.STBOC_with_size_filter(\n                self.image, return_centers_and_radii=True)\n            for c, r in zip(\n                    centers, radii\n            ):  # draw a white circle, if any red circle overlaps both particles should be discarded\n\n                im = cv2.circle(im, tuple(c[::-1]), self.exclusion_radius + r,\n                                (255, 255, 255), 1)\n        self.img_widget.setImage(im)\n\n    def run(self, path=None, overwrite=False):\n        rejected = set()\n        for name, group in tqdm(list(self.scan.items())):\n            if not name.startswith('Particle'): continue\n            im = group[self.image_name]\n            im_center = tuple(np.array(im.shape)[:2] // 2)\n            centers_radii = self.filter_box.STBOC_with_size_filter(\n                im[()], return_centers_and_radii=True)\n\n            if centers_radii is not None and len(centers_radii) > 1:\n                center, radius = min(zip(*centers_radii),\n                                     key=lambda c: distance(c[0], im_center))\n                within = [\n                    distance(c, center) < r + radius + self.exclusion_radius\n                    for c, r in zip(*centers_radii)\n                ]\n                if sum(within) > 1:  # itself is always within radius\n                    rejected.add(name)\n        save_rejected(rejected, path=path, overwrite=overwrite)",
  "def __init__(self, scan, image_name='CWL.thumb_image_0'):\n        super().__init__()\n        self.scan = scan\n        self.image_name = image_name\n        self.image = scan['Tiles']['tile_0'][()]\n        # pick a tile to test the filter settings - analysis is done on thumb images though.\n        self._construct()  # make the widget\n        self.update_image()\n        self.show()",
  "def _construct(self):\n\n        layout = QtWidgets.QHBoxLayout()\n        self.resize(1200, 700)\n        self.img_widget = pg.ImageView(parent=self)\n\n        layout.addWidget(self.img_widget)\n        control_layout = QtWidgets.QVBoxLayout()\n        ibox = QuickControlBox('exclusion settings')\n        ibox.add_spinbox('exclusion_radius', 0, 100, 1)\n        ibox.auto_connect_by_name(controlled_object=self)\n        control_layout.addWidget(ibox)\n        # ie.valueChanged.connect(lambda x: setattr(self, 'image_exclusion_fraction', x)) # gui to prop\n        # register_for_property_changes(self, 'image_exclusion_fraction', ie.setValue)\n\n        register_for_property_changes(self, 'exclusion_radius',\n                                      self.update_image)  # prop to image\n        self.filter_box = Image_Filter_box()\n        control_layout.addWidget(self.filter_box.get_qt_ui())\n        self.filter_box.connect_function_to_property_changes(self.update_image)\n        self.run_pushButton = QtWidgets.QPushButton('Run')\n        self.run_pushButton.clicked.connect(self.run)\n        control_layout.addWidget(self.run_pushButton)\n        control_box = QtWidgets.QFrame()\n        control_box.setLayout(control_layout)\n        layout.addWidget(control_box)\n        self.setLayout(layout)",
  "def update_image(self, *value):\n        \"\"\"\n        Apply live updates to the example image as the image filtering properties are changed\n        \"\"\"\n\n        filtered_image = self.filter_box.current_filter(self.image)\n        im = np.copy(filtered_image)\n        if self.filter_box.current_filter_index == 1:\n            centers, radii = self.filter_box.STBOC_with_size_filter(\n                self.image, return_centers_and_radii=True)\n            for c, r in zip(\n                    centers, radii\n            ):  # draw a white circle, if any red circle overlaps both particles should be discarded\n\n                im = cv2.circle(im, tuple(c[::-1]), self.exclusion_radius + r,\n                                (255, 255, 255), 1)\n        self.img_widget.setImage(im)",
  "def run(self, path=None, overwrite=False):\n        rejected = set()\n        for name, group in tqdm(list(self.scan.items())):\n            if not name.startswith('Particle'): continue\n            im = group[self.image_name]\n            im_center = tuple(np.array(im.shape)[:2] // 2)\n            centers_radii = self.filter_box.STBOC_with_size_filter(\n                im[()], return_centers_and_radii=True)\n\n            if centers_radii is not None and len(centers_radii) > 1:\n                center, radius = min(zip(*centers_radii),\n                                     key=lambda c: distance(c[0], im_center))\n                within = [\n                    distance(c, center) < r + radius + self.exclusion_radius\n                    for c, r in zip(*centers_radii)\n                ]\n                if sum(within) > 1:  # itself is always within radius\n                    rejected.add(name)\n        save_rejected(rejected, path=path, overwrite=overwrite)",
  "class DarkfieldExcluder():\n    '''excludes particles who's darkfield spectrum peaks below a threshold (set by a user) '''\n\n    def __init__(self, scan, DF_name='lab.z_scan0',cutoff_wavelength=650, sigma=6):\n        # DF_name is the name of the group of the darkfield data,\n        # if the global maximum of the darkfield spectrum is below cutoff_wavelength the particle will be excluded\n        # sigma is the width of the gaussian filter used for smoothing\n        self.scan = scan\n        self.DF_name = DF_name\n        # the DF maximum should be above this wavelength:\n        self.cutoff_wavelength = cutoff_wavelength\n        self.sigma = sigma  # smoothing weight\n        self.fig_dir = Path() / 'spectra figures'  # may not exist yet\n\n    def run(self, plot=False, overwrite=True):\n        if plot:\n            if not self.fig_dir.exists(\n            ):  # make the folder if it doesn't exist\n                self.fig_dir.mkdir()\n\n        rejected = set() if overwrite else load_rejected()\n        total = len(self.scan)\n        for name, group in tqdm(list(self.scan.items())):\n            if not name.startswith('Particle'):\n                continue\n            temp_spec=Spectrum.from_h5(group[self.DF_name]) # extracts the DF spectrum from file\n            spec= temp_spec.split(450, 950).max(axis=0).remove_cosmic_ray() # cleans and makes a single spectrum\n            wl=spec.wl # extracts wavelength vector\n            smoothed_spec = ndimage.gaussian_filter1d(spec, sigma=self.sigma,axis=0) # smooth data\n            max_ind=np.where(smoothed_spec==np.max(smoothed_spec))[0] # finds the global maximum\n            wl_max=wl[max_ind] # finds the wavelength of global maximum\n            reject_flag=False\n            if wl_max <= self.cutoff_wavelength:\n                rejected.add(name)\n                reject_flag=True\n\n            if plot:\n                plt.figure(figsize=(9, 3), dpi=80)\n                status = 'rejected' if reject_flag else 'accepted'\n                plt.suptitle(f'{name}, {status}')\n                plt.plot(wl,spec)\n                plt.plot(wl,smoothed_spec)\n                plt.vlines(self.cutoff_wavelength,np.min(spec), np.max(spec), colors=None, linestyles='dashed')\n                plt.savefig(self.fig_dir / f'DF_{name}.png')\n                plt.close()\n        save_rejected(rejected)\n        print(f'{(len(rejected) / total)*100}% rejected')",
  "def __init__(self, scan, DF_name='lab.z_scan0',cutoff_wavelength=650, sigma=6):\n        # DF_name is the name of the group of the darkfield data,\n        # if the global maximum of the darkfield spectrum is below cutoff_wavelength the particle will be excluded\n        # sigma is the width of the gaussian filter used for smoothing\n        self.scan = scan\n        self.DF_name = DF_name\n        # the DF maximum should be above this wavelength:\n        self.cutoff_wavelength = cutoff_wavelength\n        self.sigma = sigma  # smoothing weight\n        self.fig_dir = Path() / 'spectra figures'",
  "def run(self, plot=False, overwrite=True):\n        if plot:\n            if not self.fig_dir.exists(\n            ):  # make the folder if it doesn't exist\n                self.fig_dir.mkdir()\n\n        rejected = set() if overwrite else load_rejected()\n        total = len(self.scan)\n        for name, group in tqdm(list(self.scan.items())):\n            if not name.startswith('Particle'):\n                continue\n            temp_spec=Spectrum.from_h5(group[self.DF_name]) # extracts the DF spectrum from file\n            spec= temp_spec.split(450, 950).max(axis=0).remove_cosmic_ray() # cleans and makes a single spectrum\n            wl=spec.wl # extracts wavelength vector\n            smoothed_spec = ndimage.gaussian_filter1d(spec, sigma=self.sigma,axis=0) # smooth data\n            max_ind=np.where(smoothed_spec==np.max(smoothed_spec))[0] # finds the global maximum\n            wl_max=wl[max_ind] # finds the wavelength of global maximum\n            reject_flag=False\n            if wl_max <= self.cutoff_wavelength:\n                rejected.add(name)\n                reject_flag=True\n\n            if plot:\n                plt.figure(figsize=(9, 3), dpi=80)\n                status = 'rejected' if reject_flag else 'accepted'\n                plt.suptitle(f'{name}, {status}')\n                plt.plot(wl,spec)\n                plt.plot(wl,smoothed_spec)\n                plt.vlines(self.cutoff_wavelength,np.min(spec), np.max(spec), colors=None, linestyles='dashed')\n                plt.savefig(self.fig_dir / f'DF_{name}.png')\n                plt.close()\n        save_rejected(rejected)\n        print(f'{(len(rejected) / total)*100}% rejected')",
  "def center_of_mass(grey_image, circle_position, radius):\n    '''given an image, get the center of mass of a circle in that image'''\n    YY, XX = np.meshgrid(*list(map(range, grey_image.shape)),\n                         indexing='ij')  # np coords\n    dist_from_center = np.sqrt((XX - circle_position[0])**2 +\n                               (YY - circle_position[1])**2)\n    mask = dist_from_center <= radius\n    def com(coords): return int(np.average(coords, weights=mask * grey_image))\n    return com(XX), com(YY)",
  "class MonotonousImageExcluder():\n    '''the idea is that if a particle is isolated, a plot of image intensity vs.\n    radius should decrease monotonously. This rejects a particle if it doesn't'''\n\n    def __init__(self,\n                 scan,\n                 image_name='CWL.thumb_image_0',\n                 exclusion_radius=13,  # pixels\n                 maxima_region_fraction=0.5,\n                 sigma=2):\n        self.scan = scan\n        self.image_name = image_name\n        # radius over which intensity should always decrease\n        self.exclusion_radius = exclusion_radius\n        # only look for maxima after this fraction of the exclusion radius. This helps with ring-like DF images\n        self.maxima_region_fraction = maxima_region_fraction\n        self.sigma = sigma  # smoothing weight\n        self.fig_dir = Path() / 'exclusion figures'  # may not exist yet\n\n    def run(self, plot=False, overwrite=True):\n        if plot:\n            if not self.fig_dir.exists(\n            ):  # make the folder if it doesn't exist\n                self.fig_dir.mkdir()\n\n        rejected = set() if overwrite else load_rejected()\n        total = len(self.scan)\n        for name, group in tqdm(list(self.scan.items())):\n            if not name.startswith('Particle'):\n                continue\n            im = group[self.image_name]\n            im_center = tuple(np.array(im.shape)[:2] // 2)\n            grey_image = im[()].sum(axis=-1)\n            smoothed_image = ndimage.gaussian_filter(grey_image, self.sigma)\n\n            com = center_of_mass(grey_image, im_center, self.exclusion_radius)\n            YY, XX = np.meshgrid(*list(map(range, grey_image.shape)),\n                                 indexing='ij')  # np coords\n            dist_from_center = np.sqrt((XX - com[0])**2 + (YY - com[1])**2)\n\n            radially_averaged = []\n            radii = np.arange(self.exclusion_radius)\n            for inner, outer in zip(radii, radii[1:]):\n                mask = np.logical_and(dist_from_center <= outer,\n                                      dist_from_center > inner)\n                radially_averaged.append(\n                    np.percentile(smoothed_image[mask], 95))\n            radially_averaged.append(0)\n            # so if the intensity was increasing at the edge of the plot,\n            # it's recognized as a local maximum, and rejected.\n\n            maxima = signal.argrelextrema(\n                np.array(radially_averaged)[\n                    int(self.exclusion_radius*self.maxima_region_fraction):],\n                np.greater,\n            )[0]\n            if len(maxima):\n                rejected.add(name)\n\n            if plot:\n                fig, axs = plt.subplots(1, 3, figsize=(9, 3), dpi=80)\n                status = 'rejected' if len(maxima) else 'accepted'\n                fig.suptitle(f'{name}, {status}')\n                axs[0].imshow(cv2.circle(\n                    im[()], com, self.exclusion_radius, (255, 255, 255), 1))\n                axs[0].plot(*com, 'ko')\n                axs[1].plot(radii, radially_averaged)\n                axs[2].imshow(smoothed_image)\n                fig.savefig(self.fig_dir / f'{name}.png')\n                plt.close(fig)\n        save_rejected(rejected)\n        print(f'{(len(rejected) / total)*100}% rejected')",
  "def com(coords): return int(np.average(coords, weights=mask * grey_image))",
  "def __init__(self,\n                 scan,\n                 image_name='CWL.thumb_image_0',\n                 exclusion_radius=13,  # pixels\n                 maxima_region_fraction=0.5,\n                 sigma=2):\n        self.scan = scan\n        self.image_name = image_name\n        # radius over which intensity should always decrease\n        self.exclusion_radius = exclusion_radius\n        # only look for maxima after this fraction of the exclusion radius. This helps with ring-like DF images\n        self.maxima_region_fraction = maxima_region_fraction\n        self.sigma = sigma  # smoothing weight\n        self.fig_dir = Path() / 'exclusion figures'",
  "def run(self, plot=False, overwrite=True):\n        if plot:\n            if not self.fig_dir.exists(\n            ):  # make the folder if it doesn't exist\n                self.fig_dir.mkdir()\n\n        rejected = set() if overwrite else load_rejected()\n        total = len(self.scan)\n        for name, group in tqdm(list(self.scan.items())):\n            if not name.startswith('Particle'):\n                continue\n            im = group[self.image_name]\n            im_center = tuple(np.array(im.shape)[:2] // 2)\n            grey_image = im[()].sum(axis=-1)\n            smoothed_image = ndimage.gaussian_filter(grey_image, self.sigma)\n\n            com = center_of_mass(grey_image, im_center, self.exclusion_radius)\n            YY, XX = np.meshgrid(*list(map(range, grey_image.shape)),\n                                 indexing='ij')  # np coords\n            dist_from_center = np.sqrt((XX - com[0])**2 + (YY - com[1])**2)\n\n            radially_averaged = []\n            radii = np.arange(self.exclusion_radius)\n            for inner, outer in zip(radii, radii[1:]):\n                mask = np.logical_and(dist_from_center <= outer,\n                                      dist_from_center > inner)\n                radially_averaged.append(\n                    np.percentile(smoothed_image[mask], 95))\n            radially_averaged.append(0)\n            # so if the intensity was increasing at the edge of the plot,\n            # it's recognized as a local maximum, and rejected.\n\n            maxima = signal.argrelextrema(\n                np.array(radially_averaged)[\n                    int(self.exclusion_radius*self.maxima_region_fraction):],\n                np.greater,\n            )[0]\n            if len(maxima):\n                rejected.add(name)\n\n            if plot:\n                fig, axs = plt.subplots(1, 3, figsize=(9, 3), dpi=80)\n                status = 'rejected' if len(maxima) else 'accepted'\n                fig.suptitle(f'{name}, {status}')\n                axs[0].imshow(cv2.circle(\n                    im[()], com, self.exclusion_radius, (255, 255, 255), 1))\n                axs[0].plot(*com, 'ko')\n                axs[1].plot(radii, radially_averaged)\n                axs[2].imshow(smoothed_image)\n                fig.savefig(self.fig_dir / f'{name}.png')\n                plt.close(fig)\n        save_rejected(rejected)\n        print(f'{(len(rejected) / total)*100}% rejected')",
  "def reject(group, plot_function, cutoff=5000):\n    rejected = load_rejected()\n    group_len = len(next(iter(\n        group.values())))  # number of datasets in each particle group\n    scan = {  # read the scan into a dictionary (but not memory)\n        n: p\n        for n, p in group.items() if (\n            n.startswith('Particle')  # has the right name\n            and (n not in rejected)  # hasn't been rejected by another script\n            )  # is full (nothing went wrong)\n    }\n    scan = {k: scan[k] for k in sorted(scan,\n                                       key=lambda k: int(k.split('_')[-1]))}\n    \n    for name, particle in tqdm(scan.items()):\n        if int(name.split('_')[-1]) > cutoff: \n            rejected.add(name)\n        elif (len(particle) != group_len):\n            rejected.add(name)\n        else:\n            plot_function(particle, name)\n            plt.pause(0.1)\n            \n            ar = input('a/d = accept/decline: ').strip().lower()\n            if ar == 'a':\n                pass\n            if ar == 'd':\n                rejected.add(name)\n        save_rejected(rejected)\n    return rejected",
  "def plot_function(particle):\n        fig, ax = plt.subplots(1, 3, figsize=(30, 10)) #3 subplots, feel free to use more\n        z = particle['z_scan']\n        ax[0].plot(z)\n        r = particle['SERS']\n        ax[1].pcolormesh(r)\n        img = particle['image']\n        ax[2].imshow(img)",
  "def Sigmoid(x,O,S):\n\treturn 1./(1.+np.exp(-(old_div((x-O),S))))",
  "def Polynomial(x,Anchors,Anchor_Values):\n\treturn  np.polyval(np.polyfit(Anchors,Anchor_Values,len(Anchors)-1),x)",
  "def L(x,H,C,W):\n\treturn old_div(H,(1.+((old_div((x-C),W))**2)))",
  "def Fit(Shift,Signal,Poly_Order_AS=4,Poly_Order_S=4,Smoothing_Width=30,Noise_Smoothing=2,Peak_Threshold_Window=5,Default_Peak_Width=10.,Minimum_Peak_Width=5.,Maximum_Peak_Width=30.,Iterations=2,Allowed_Peak_Fraction_In_Notch=0.1):\n\t\n\tSmooth=ndimf.gaussian_filter(Signal,old_div(Smoothing_Width,np.median(np.abs(np.diff(Shift)))))\n\n\t#--Gradient: Find notch filter--\n\n\tx=np.linspace(np.min(Shift),np.max(Shift),int(np.round(old_div((np.max(Shift)-np.min(Shift)),np.min(np.abs(np.diff(Shift))))))+1)\n\ty=scintp.interp1d(Shift,Smooth,kind='cubic')(x)\n\n\tA=np.array(np.array(y).tolist()+[y[-1],y[-2]])\n\tB=np.array([y[1],y[0]]+np.array(y).tolist())\n\n\tGrad=(A-B)[1:-1]\n\n\tx2=np.linspace(0,np.min([np.max(Shift),-np.min(Shift)]),int(np.round(old_div((np.max(Shift)-np.min(Shift)),np.min(np.abs(np.diff(Shift))))))+1)\n\ty2=scintp.interp1d(x,Grad,kind='cubic')(x2)-scintp.interp1d(x,Grad,kind='cubic')(-x2)\n\n\tNotch_Filter_Edge=x2[np.argmax(y2)]\n\n\t#--Set up initial background estimate for the highest signal spectrum--\n\t\n\tSmooth=ndimf.gaussian_filter(Signal,Noise_Smoothing)\n\tConstant=np.min(Smooth)\n\n\tAS_Anchors=[]\n\tAS_Anchor_Values=[]\n\n\tPosition=np.argmin(np.abs(Shift+Notch_Filter_Edge))\n\twhile Smooth[Position-1]>Smooth[Position]:\n\t\tPosition-=1\n\n\tAS_Anchors.append(copy.deepcopy(Shift[Position]))\n\tAS_Anchor_Values.append(copy.deepcopy(Smooth[Position])-Constant)\n\n\tEdges=np.round(np.linspace(0,Position,Poly_Order_AS+2)).astype(int)\n\n\tfor i in range(len(Edges))[1:-1]:\n\t\tBest=np.argmin(Smooth[Edges[i-1]:Edges[i]])+Edges[i-1]\n\t\tAS_Anchors.append(Shift[Best])\n\t\tAS_Anchor_Values.append(Smooth[Best]-Constant)\n\n\tAS_Anchor_Values=AS_Anchor_Values[1:]+[AS_Anchor_Values[0]]\n\tAS_Anchors=AS_Anchors[1:]+[AS_Anchors[0]]\n\n\n\tS_Anchors=[]\n\tS_Anchor_Values=[]\n\n\tPosition=np.argmin(np.abs(Shift-Notch_Filter_Edge))\n\twhile Smooth[Position+1]>Smooth[Position]:\n\t\tPosition+=1\n\n\tEdges=np.round(np.linspace(Position,len(Smooth)-1,Poly_Order_S+2)).astype(int)\n\n\tS_Anchors.append(copy.deepcopy(Shift[Position]))\n\tS_Anchor_Values.append(copy.deepcopy(Smooth[Position])-Constant)\n\n\tfor i in range(len(Edges))[2:]:\n\t\tBest=np.argmin(Smooth[Edges[i-1]:Edges[i]])+Edges[i-1]\n\t\tS_Anchors.append(Shift[Best])\n\t\tS_Anchor_Values.append(Smooth[Best]-Constant)\n\n\tdef Generate(Vector):\n\t\tConstant=Vector[0]\n\t\tSigmoid_Data_AS=Vector[1:3]\n\t\tSigmoid_Data_S=Vector[3:5]\n\t\tPoly_AS=Vector[5:6+Poly_Order_AS]\n\t\tPoly_S=Vector[6+Poly_Order_AS:7+Poly_Order_AS+Poly_Order_S]\n\t\tLaser_Leak=Vector[7+Poly_Order_AS+Poly_Order_S:10+Poly_Order_AS+Poly_Order_S]\n\n\t\tOutput=Shift*0\n\t\tOutput+=Polynomial(Shift,AS_Anchors,Poly_AS)*(Shift<0)\n\t\tOutput+=Polynomial(Shift,S_Anchors,Poly_S)*(Shift>=0)\n\t\t\n\n\t\tMask=Sigmoid(Shift,*Sigmoid_Data_AS)+Sigmoid(Shift,*Sigmoid_Data_S)\n\n\t\treturn (Output*Mask)+Constant+L(Shift,*Laser_Leak)\n\n\tVector=[Constant,-Notch_Filter_Edge,-1.,Notch_Filter_Edge,1.]\n\tfor i in AS_Anchor_Values:\n\t\tVector.append(i)\n\tfor i in S_Anchor_Values:\n\t\tVector.append(i)\n\tVector+=[1.,0.,10.]\n\n\t#--Optimise Notch Edges--\n\n\tdef Loss(Input):\n\t\tV=copy.deepcopy(Vector)\n\t\tfor i in range(4):\n\t\t\tV[i+1]=Input[i]\n\t\treturn np.sum(np.abs(Generate(V)-Signal))\n\n\tVector[1:5]=spo.minimize(Loss,Vector[1:5]).x.tolist()\n\n\t#--Add Laser Leak--\n\n\tdef Loss(Input):\n\t\tV=copy.deepcopy(Vector)\n\t\tfor i in range(3):\n\t\t\tV[i-3]=Input[i]\n\t\treturn np.sum(np.abs(Generate(V)-Signal))\n\n\tVector[-3]=np.max(Smooth[np.argmin(np.abs(Shift+10)):np.argmin(np.abs(Shift-10))])-Constant\n\tVector[-3:]=spo.minimize(Loss,Vector[-3:]).x.tolist()\n\n\t#--Iterate Background---\n\n\tMask=(Shift*0).astype(bool)\n\n\tEnd=False\n\tdef Loss(Vector):\n\t\tGen=Generate(Vector)\n\t\treturn np.sum(np.abs(Gen-Signal)[Mask==False])\n\n\twhile End is False:\n\t\tVector=spo.minimize(Loss,Vector).x.tolist()\n\n\t\tSub=Signal-Generate(Vector)\n\t\tBelow=Sub[Sub<0]\n\t\tStd=np.mean(np.square(Below))**0.5\n\n\t\tAbove_Std=(Sub>=Std)\n\t\tif Peak_Threshold_Window%2==0:\n\t\t\tPeak_Threshold_Window+=1\n\t\tSkip=old_div((Peak_Threshold_Window-1),2)\n\t\tPossible_Peak=[]\n\t\tfor i in range(Skip):\n\t\t\tPossible_Peak.append(False)\n\t\tfor i in range(len(Above_Std))[Skip:-Skip]:\n\t\t\tif np.sum(Above_Std[i-Skip:i-Skip+Peak_Threshold_Window])==Peak_Threshold_Window:\n\t\t\t\tPossible_Peak.append(True)\n\t\t\telse:\n\t\t\t\tPossible_Peak.append(False)\n\t\tfor i in range(Skip):\n\t\t\tPossible_Peak.append(False)\n\n\t\tPossible_Peak=np.array(Possible_Peak)\n\n\t\tif np.sum(Possible_Peak==Mask)==len(Possible_Peak):\n\t\t\tEnd=True\n\t\telse:\n\t\t\tMask=Possible_Peak\n\n\tdef Generate_Peaks(Input):\n\t\tOutput=Shift*0\n\t\tn=0\n\t\twhile n<len(Input):\n\t\t\tOutput+=L(Shift,*Input[n:n+3])\n\t\t\tn+=3\n\t\tOutput*=(Sigmoid(Shift,*Vector[1:3])+Sigmoid(Shift,*Vector[3:5]))\n\t\treturn Output\n\n\tdef Sub_Loss(Input):\n\t\treturn np.sum(np.abs(Generate_Peaks(Input)-Sub))\n\n\tPeaks_Vector=[]\n\tfor Iteration in range(Iterations):\n\t\tprint('Iteration:',Iteration+1)\n\n\t\tBounds=[]\n\t\tfor i in range(old_div(len(Peaks_Vector),3)):\n\t\t\tBounds+=[(0,np.inf),(-np.inf,np.inf),(Minimum_Peak_Width,Maximum_Peak_Width)]\n\n\t\tEnd=False\n\t\twhile End is False:\n\n\t\t\t#print Peaks_Vector\n\n\t\t\tSub=Signal-Generate(Vector)-Generate_Peaks(Peaks_Vector)\n\n\t\t\tBelow=Sub[Sub<0]\n\t\t\tStd=np.mean(np.square(Below))**0.5\n\n\t\t\tAbove_Std=(Sub>=Std)\n\n\t\t\tif Peak_Threshold_Window%2==0:\n\t\t\t\tPeak_Threshold_Window+=1\n\t\t\tSkip=old_div((Peak_Threshold_Window-1),2)\n\t\t\tPossible_Peak=[]\n\t\t\tfor i in range(Skip):\n\t\t\t\tPossible_Peak.append(False)\n\t\t\tfor i in range(len(Above_Std))[Skip:-Skip]:\n\t\t\t\tif np.sum(Above_Std[i-Skip:i-Skip+Peak_Threshold_Window])==Peak_Threshold_Window:\n\t\t\t\t\tPossible_Peak.append(True)\n\t\t\t\telse:\n\t\t\t\t\tPossible_Peak.append(False)\n\t\t\tfor i in range(Skip):\n\t\t\t\tPossible_Peak.append(False)\n\n\t\t\tPossible_Peak=np.array(Possible_Peak)\n\t\t\tif np.sum(Possible_Peak)>0:\n\n\t\t\t\tSub=Signal-Generate(Vector)\n\t\t\t\tLoss=[]\n\t\t\t\tChecked=[]\n\t\t\t\tfor i in np.array(list(range(len(Shift))))[Possible_Peak]:\n\t\t\t\t\tLoss.append(np.sum(np.abs(L(Shift,np.max([Sub[i],0]),Shift[i],Default_Peak_Width)-Sub)))\n\t\t\t\t\tChecked.append(i)\n\t\t\t\t\n\t\t\t\tPeaks_Vector+=[Sub[Checked[np.argmin(Loss)]],Shift[Checked[np.argmin(Loss)]],Default_Peak_Width]\n\t\t\t\tBounds+=[(0,np.inf),(-np.inf,np.inf),(Minimum_Peak_Width,Maximum_Peak_Width)]\n\n\t\t\t\tn=0\n\t\t\t\twhile n<len(Peaks_Vector):\n\t\t\t\t\tPeaks_Vector[n+2]=Default_Peak_Width\n\t\t\t\t\tn+=3\n\n\t\t\t\tPeaks_Vector=spo.minimize(Sub_Loss,Peaks_Vector,bounds=Bounds).x.tolist()\n\n\t\t\t\tHeights=[]\n\t\t\t\tn=0\n\t\t\t\twhile n<len(Peaks_Vector):\n\t\t\t\t\tHeights.append(Peaks_Vector[n])\n\t\t\t\t\tn+=3\n\t\t\t\tif np.min(Heights)<Std:\n\t\t\t\t\tNon_Zero=[]\n\t\t\t\t\tn=0\n\t\t\t\t\twhile n<len(Peaks_Vector):\n\t\t\t\t\t\tif Peaks_Vector[n]>=Std:\n\t\t\t\t\t\t\tNon_Zero+=Peaks_Vector[n:n+3]\n\t\t\t\t\t\tn+=3\n\t\t\t\t\tPeaks_Vector=Non_Zero\n\t\t\t\t\tEnd=True\n\n\t\t\telse:\n\t\t\t\tEnd=True\n\n\t\t#---Full_Optimize---\n\n\t\tdef Full_Generate(x,*Input):\n\t\t\tConstant=Input[0]\n\t\t\tSigmoid_Data_AS=Input[1:3]\n\t\t\tSigmoid_Data_S=Input[3:5]\n\t\t\tPoly_AS=Input[5:6+Poly_Order_AS]\n\t\t\tPoly_S=Input[6+Poly_Order_AS:7+Poly_Order_AS+Poly_Order_S]\n\t\t\tLaser_Leak=Input[7+Poly_Order_AS+Poly_Order_S:10+Poly_Order_AS+Poly_Order_S]\n\n\t\t\tPeaks=Input[10+Poly_Order_AS+Poly_Order_S:]\n\n\t\t\tOutput=Shift*0\n\t\t\tOutput+=Polynomial(Shift,AS_Anchors,Poly_AS)*(Shift<0)\n\t\t\tOutput+=Polynomial(Shift,S_Anchors,Poly_S)*(Shift>=0)\n\t\t\tn=0\n\t\t\twhile n<len(Peaks):\n\t\t\t\tOutput+=L(Shift,*Peaks[n:n+3])\n\t\t\t\tn+=3\n\n\t\t\tMask=Sigmoid(Shift,*Sigmoid_Data_AS)+Sigmoid(Shift,*Sigmoid_Data_S)\n\n\t\t\treturn (Output*Mask)+Constant+L(Shift,*Laser_Leak)\n\n\t\tdef Full_Loss(Input):\n\t\t\treturn np.sum(np.abs(Full_Generate(None,*Input)-Signal))\n\n\t\tFull_Bounds=[]\n\t\tfor i in Vector:\n\t\t\tFull_Bounds.append((-np.inf,np.inf))\t\n\t\tfor i in range(old_div(len(Peaks_Vector),3)):\n\t\t\tFull_Bounds+=[(0,np.inf),(-np.inf,np.inf),(Minimum_Peak_Width,Maximum_Peak_Width)]\n\t\t\t\n\n\t\tOutput=spo.minimize(Full_Loss,Vector+Peaks_Vector,bounds=Full_Bounds).x.tolist()\n\t\tVector=Output[:len(Vector)]\n\t\tPeaks_Vector=Output[len(Vector):]\n\n\t\t#---Test for Redundent Peaks---\n\n\t\tSub=Signal-Generate(Vector)\n\n\t\tCurrent_Loss=Sub_Loss(Peaks_Vector)\n\n\t\tBounds=[[],[]]\n\t\tfor i in Peaks_Vector:\n\t\t\tBounds[0]+=[0,-np.inf,0]\n\t\t\tBounds[1]+=[np.inf,np.inf,np.inf]\n\t\tBounds[0]=Bounds[:-3]\n\t\tBounds[1]=Bounds[:-3]\n\n\t\tEnd=False\n\t\tdef To_Fit(x,*Input):\n\t\t\treturn Generate_Peaks(Input)\n\t\twhile End is False:\n\t\t\tprint(old_div(len(Peaks_Vector),3))\n\t\t\tOptions=[]\n\t\t\tLoss=[]\n\t\t\tfor i in range(old_div(len(Peaks_Vector),3)):\n\t\t\t\ttry:\n\t\t\t\t\tOptions.append(spo.curve_fit(To_Fit,Shift,Sub,Peaks_Vector[:i*3]+Peaks_Vector[i*3+3:],bounds=Bounds)[0].tolist())\n\t\t\t\t\tLoss.append(Sub_Loss(Options[-1]))\n\t\t\t\texcept RuntimeError:\n\t\t\t\t\tOptions.append(None)\n\t\t\t\t\tLoss.append(np.inf)\n\t\t\tif np.min(Loss)<Current_Loss:\n\t\t\t\tArg=np.argmin(Loss)\n\t\t\t\tPeaks_Vector=Peaks_Vector[:Arg*3]+Peaks_Vector[Arg*3+3:]\n\t\t\t\tBounds[0]=Bounds[:-3]\n\t\t\t\tBounds[1]=Bounds[:-3]\n\n\t\t\t\tFull_Bounds=[]\n\t\t\t\tfor i in Vector:\n\t\t\t\t\tFull_Bounds.append((-np.inf,np.inf))\t\n\t\t\t\tfor i in range(old_div(len(Peaks_Vector),3)):\n\t\t\t\t\tFull_Bounds+=[(0,np.inf),(-np.inf,np.inf),(Minimum_Peak_Width,Maximum_Peak_Width)]\n\t\t\t\tOutput=spo.minimize(Full_Loss,Vector+Peaks_Vector,bounds=Full_Bounds).x.tolist()\n\t\t\t\tVector=Output[:len(Vector)]\n\t\t\t\tPeaks_Vector=Output[len(Vector):]\n\t\t\t\t\n\t\t\t\tSub=Signal-Generate(Vector)\n\t\t\t\tCurrent_Loss=Sub_Loss(Peaks_Vector)\n\t\t\telse:\n\t\t\t\tEnd=True\n\n\t\t#--Edge of notch could be spoofed with fake peak, check for this---\n\n\t\tMask=Sigmoid(Shift,*Vector[1:3])+Sigmoid(Shift,*Vector[3:5])\n\n\t\tTemp=[]\n\t\tfor i in range(old_div(len(Peaks_Vector),3)):\n\t\t\tPeak=L(Shift,*Peaks_Vector[i*3:i*3+3])\n\t\t\tFraction=old_div(scint.simps(Peak*Mask,Shift),scint.simps(Peak,Shift))\n\t\t\tif 1.-Fraction<Allowed_Peak_Fraction_In_Notch:\n\t\t\t\tTemp+=Peaks_Vector[i*3:i*3+3]\n\n\t\tPeaks_Vector=Temp\n\t\n\tBackground_Removed=Signal-Generate(Vector)\n\tFit=Full_Generate(None,*(Vector+Peaks_Vector))\n\tNo_Background_Fit=Full_Generate(None,*(Vector+Peaks_Vector))-Generate(Vector)\n\n\tPeak_Dictionary={'Centres':[],'Widths':[],'Heights':[]}\n\n\tCentres=[]\n\tfor i in range(old_div(len(Peaks_Vector),3)):\n\t\tCentres.append(Peaks_Vector[i*3+1])\n\twhile np.sum(np.isinf(Centres))!=len(Centres):\n\t\tArg=np.argmin(Centres)\n\t\tPeak_Dictionary['Centres'].append(Peaks_Vector[Arg*3+1])\n\t\tPeak_Dictionary['Widths'].append(Peaks_Vector[Arg*3+2])\n\t\tPeak_Dictionary['Heights'].append(Peaks_Vector[Arg*3])\n\t\tCentres[Arg]=np.inf\n\n\treturn np.array([Fit,Background_Removed,No_Background_Fit]),Peak_Dictionary",
  "def Generate(Vector):\n\t\tConstant=Vector[0]\n\t\tSigmoid_Data_AS=Vector[1:3]\n\t\tSigmoid_Data_S=Vector[3:5]\n\t\tPoly_AS=Vector[5:6+Poly_Order_AS]\n\t\tPoly_S=Vector[6+Poly_Order_AS:7+Poly_Order_AS+Poly_Order_S]\n\t\tLaser_Leak=Vector[7+Poly_Order_AS+Poly_Order_S:10+Poly_Order_AS+Poly_Order_S]\n\n\t\tOutput=Shift*0\n\t\tOutput+=Polynomial(Shift,AS_Anchors,Poly_AS)*(Shift<0)\n\t\tOutput+=Polynomial(Shift,S_Anchors,Poly_S)*(Shift>=0)\n\t\t\n\n\t\tMask=Sigmoid(Shift,*Sigmoid_Data_AS)+Sigmoid(Shift,*Sigmoid_Data_S)\n\n\t\treturn (Output*Mask)+Constant+L(Shift,*Laser_Leak)",
  "def Loss(Input):\n\t\tV=copy.deepcopy(Vector)\n\t\tfor i in range(4):\n\t\t\tV[i+1]=Input[i]\n\t\treturn np.sum(np.abs(Generate(V)-Signal))",
  "def Loss(Input):\n\t\tV=copy.deepcopy(Vector)\n\t\tfor i in range(3):\n\t\t\tV[i-3]=Input[i]\n\t\treturn np.sum(np.abs(Generate(V)-Signal))",
  "def Loss(Vector):\n\t\tGen=Generate(Vector)\n\t\treturn np.sum(np.abs(Gen-Signal)[Mask==False])",
  "def Generate_Peaks(Input):\n\t\tOutput=Shift*0\n\t\tn=0\n\t\twhile n<len(Input):\n\t\t\tOutput+=L(Shift,*Input[n:n+3])\n\t\t\tn+=3\n\t\tOutput*=(Sigmoid(Shift,*Vector[1:3])+Sigmoid(Shift,*Vector[3:5]))\n\t\treturn Output",
  "def Sub_Loss(Input):\n\t\treturn np.sum(np.abs(Generate_Peaks(Input)-Sub))",
  "def Full_Generate(x,*Input):\n\t\t\tConstant=Input[0]\n\t\t\tSigmoid_Data_AS=Input[1:3]\n\t\t\tSigmoid_Data_S=Input[3:5]\n\t\t\tPoly_AS=Input[5:6+Poly_Order_AS]\n\t\t\tPoly_S=Input[6+Poly_Order_AS:7+Poly_Order_AS+Poly_Order_S]\n\t\t\tLaser_Leak=Input[7+Poly_Order_AS+Poly_Order_S:10+Poly_Order_AS+Poly_Order_S]\n\n\t\t\tPeaks=Input[10+Poly_Order_AS+Poly_Order_S:]\n\n\t\t\tOutput=Shift*0\n\t\t\tOutput+=Polynomial(Shift,AS_Anchors,Poly_AS)*(Shift<0)\n\t\t\tOutput+=Polynomial(Shift,S_Anchors,Poly_S)*(Shift>=0)\n\t\t\tn=0\n\t\t\twhile n<len(Peaks):\n\t\t\t\tOutput+=L(Shift,*Peaks[n:n+3])\n\t\t\t\tn+=3\n\n\t\t\tMask=Sigmoid(Shift,*Sigmoid_Data_AS)+Sigmoid(Shift,*Sigmoid_Data_S)\n\n\t\t\treturn (Output*Mask)+Constant+L(Shift,*Laser_Leak)",
  "def Full_Loss(Input):\n\t\t\treturn np.sum(np.abs(Full_Generate(None,*Input)-Signal))",
  "def To_Fit(x,*Input):\n\t\t\treturn Generate_Peaks(Input)",
  "def Quick_Sort(List,Argument):\n\t\t#Sorts a List based on the numberimal value of the Argument element.\n\t\tdef Split(List,Argument):\n\t\t\t#List is list of lists to seperate\n\t\t\t#Argument is list argument to seperate via\n\n\t\t\tOutput=[[],[]]\n\n\t\t\tPivot=[]\n\t\t\tfor i in List:\n\t\t\t\tPivot.append(i[Argument])\n\t\t\tif len(Pivot)==2:\n\t\t\t\tPivot=max(Pivot)\n\t\t\telse:\n\t\t\t\tPivot=np.random.choice(Pivot)\n\n\t\t\tfor i in List:\n\t\t\t\tif i[Argument]<Pivot:\n\t\t\t\t\tOutput[0].append(i)\n\t\t\t\telse:\n\t\t\t\t\tOutput[1].append(i)\n\t\t\treturn Output\n\n\t\tdef Same(List,Argument):\n\t\t\tfor i in List:\n\t\t\t\tif i[Argument]!=List[0][Argument]:\n\t\t\t\t\treturn False\n\t\t\treturn True\n\n\t\tSorted=[]\n\t\tTo_Sort=[List]\n\t\twhile len(To_Sort)>0:\n\t\t\tSorting=To_Sort[0]\n\t\t\tTo_Sort=To_Sort[1:]\n\t\t\tif Same(Sorting,Argument) is True:\n\t\t\t\tSorted+=Sorting\n\t\t\telse:\n\t\t\t\tTo_Sort=Split(Sorting,Argument)+To_Sort\n\t\treturn Sorted",
  "def Wavelet_Estimate_Width(x_axis,Signal,Maximum_Width,Smooth_Loss_Function=2):\n\t#Uses the CWT to estimate the typical peak FWHM in the signal\n\t#First, intepolates the signal onto a linear x_scale with the smallest spacing present in the signal\n\t#Completes CWT and sums over the position coordinate, leaving scale\n\t#Does minor smooth, and takes scale at maximum as FWHM\n\n\tInt=scint.splrep(x_axis,Signal)\n\n\tStep=np.min(np.abs(np.diff(x_axis)))\n\n\tNew=scint.splev(np.arange(x_axis[0],x_axis[-1],Step),Int)\n\n\tScales=np.arange(1,np.ceil(old_div(Maximum_Width,Step)),1)\n\n\tScore=np.diff(np.sum(pywt.cwt(New,Scales,'gaus1')[0],axis=1))\n\n\tScore=ndimf.gaussian_filter(Score,Smooth_Loss_Function)\n\n\tScale=Scales[np.argmax(Score)]*Step\n\n\treturn Scale",
  "def L(x,H,C,W):\n\t\"\"\"\n\tDefines a lorentzian\n\t\"\"\"\n\treturn old_div(H,(1.+((old_div((x-C),W))**2)))",
  "def Multi_L(x,*Params):\n\t\"\"\"\n\tDefines a sum of Lorentzians. Params goes Height1,Centre1, Width1,Height2.....\n\t\"\"\"\n\tOutput=0\n\tn=0\n\twhile n<len(Params):\n\t\tOutput+=L(x,*Params[n:n+3])\n\t\tn+=3\n\treturn Output",
  "def G(x,H,C,W):\n\t\"\"\"\n\tDefines a gaussian\n\t\"\"\"\n\treturn H*np.exp(-0.5*((old_div((x-C),W))**2))",
  "def Multi_G(x,*Params):\n\t\"\"\"\n\tDefines a sum of LGuassians. Params goes Height1,Centre1, Width1,Height2.....\n\t\"\"\"\n\tOutput=0\n\tn=0\n\twhile n<len(Params):\n\t\tOutput+=G(x,*Params[n:n+3])\n\t\tn+=3\n\treturn Output",
  "def Add_New_Peak(x_axis,Signal,Current_Peaks,Width,Maximum_Width,Regions=50,Peak_Type='L'):\n\t\"\"\"\n\tGiven a signal (x_axis and Signal 1D arrays) and a pre-existing set of peaks (Current Peaks=list in form [Height1,Centre1,Width1,Height2...]), this function\n\ttrys to find to best place for a new peak.\n\n\tThe x-axis is slit into Regions equal regions. In each in turn, a peak in placed randomly and optimized without being allowed to leave that region.\n\n\tThis peak can be gaussian or Lorentzian depending on the Peak_Type argument 'G' or 'L' .\n\n\tThe peak has a default width parameter Width and Max Width Maximum_Width.\n\n\tThe peak that casued the greated reduction in fitting loss is chosen.\n\t\"\"\"\n\n\t#-----Calc. size of x_axis regions-------\n\tSections=old_div((np.max(x_axis)-np.min(x_axis)),Regions)\n\tStart=np.min(x_axis)\n\n\tResults=[]\n\tLoss_Results=[]\n\n\t#-------What does the curve look like with the current peaks?--------\n\tif len(Current_Peaks)==0:\n\t\tCurrent=np.array(x_axis)*0\n\telse:\n\t\tif Peak_Type=='L':\n\t\t\tCurrent=Multi_L(x_axis,*Current_Peaks)\n\t\telse:\n\t\t\tCurrent=Multi_G(x_axis,*Current_Peaks)\n\n\t#-------Set up Loss function--------\t\n\t\t\t\n\tif Peak_Type=='L':\n\t\tdef Loss(Vector):\n\t\t\treturn np.sum(np.abs(Current+L(x_axis,*Vector)-Signal))\n\telse:\n\t\tdef Loss(Vector):\n\t\t\treturn np.sum(np.abs(Current+G(x_axis,*Vector)-Signal))\n\n\t#-----Minimise loss in each region--------- \n\n\tfor i in range(Regions):\n\t\tBounds=[(0,np.inf),(i*Sections+Start,(i+1)*Sections+Start),(0,Maximum_Width)]\n\t\tCentre=(i+np.random.rand())*Sections+Start\n\t\tHeight=Signal[np.argmin(np.abs(x_axis-Centre))]-np.min(Signal)\n\t\tVector=[Height,Centre,Width]\n\n\t\tOpt=spo.minimize(Loss,Vector,bounds=Bounds).x\n\n\t\tResults.append(Opt)\n\t\tLoss_Results.append(Loss(Opt))\n\n\t#------Select most effective peak postion\n\n\treturn Results[np.argmin(Loss_Results)].tolist()",
  "def Optimise_Prexisting_Peaks(x_axis,Signal,Peak_Params,Max_Width,Peak_Type='L'):\n\t\"\"\"\n\tGiven a signal and an existing close fit, optimises it. First optimises just the peak heights, then all the parameters.\n\t\"\"\"\n\tPeaks=[]\n\tVector=[]\n\tn=0\n\twhile n<len(Peak_Params):\n\t\tif Peak_Type=='L':\n\t\t\tPeaks.append(L(x_axis,1,Peak_Params[n+1],Peak_Params[n+2]))\n\t\telse:\n\t\t\tPeaks.append(G(x_axis,1,Peak_Params[n+1],Peak_Params[n+2]))\n\t\tVector.append(Peak_Params[n])\n\t\tn+=3\n\n\tBounds=[]\n\tfor i in Vector:\n\t\tBounds.append((0,np.inf))\n\n\tdef Loss(Vector):\n\t\tOutput=0.\n\t\tfor i in range(len(Vector)):\n\t\t\tOutput+=Vector[i]*Peaks[i]\n\t\treturn np.sum(np.abs(Output-Signal))\n\n\tHeights=spo.minimize(Loss,Vector,bounds=Bounds).x\n\n\tVector=[]\n\tBounds=[]\n\n\tfor i in range(len(Heights)):\n\t\tVector+=[Heights[i],Peak_Params[i*3+1],Peak_Params[i*3+2]]\n\t\tBounds+=[(0,np.inf),(np.min(x_axis),np.max(x_axis)),(0,Max_Width)]\n\n\tif Peak_Type=='L':\n\t\tdef Loss(Vector):\n\t\t\treturn np.sum(np.abs(Multi_L(x_axis,*Vector)-Signal))\n\telse:\n\t\tdef Loss(Vector):\n\t\t\treturn np.sum(np.abs(Multi_G(x_axis,*Vector)-Signal))\n\n\treturn spo.minimize(Loss,Vector,bounds=Bounds).x.tolist()",
  "def Run(x_axis,Signal,Maximum_FWHM=40,Regions=50,Minimum_Width_Factor=0.1,Peak_Type='L',Print=True,Initial_Fit=None):\n\t\"\"\"\n\tMain function. Explained at top. \n\t\"\"\"\n\n\tif Regions>len(Signal):\n\t\tRegions=len(Signal)\n\n\tif Peak_Type=='L':\n\t\tdef Loss(Vector):\n\t\t\treturn np.sum(np.abs(Multi_L(x_axis,*Vector)-Signal))\n\t\tWidth=Wavelet_Estimate_Width(x_axis,Signal,Maximum_FWHM)*0.5\n\t\tMax_Width=Maximum_FWHM*0.5\n\n\telse:\n\t\tdef Loss(Vector):\n\t\t\treturn np.sum(np.abs(Multi_G(x_axis,*Vector)-Signal))\n\t\tWidth=old_div(Wavelet_Estimate_Width(x_axis,Signal,Maximum_FWHM),((2.*np.log(2.))**0.5))\n\t\tMax_Width=old_div(Maximum_FWHM,((2.*np.log(2.))**0.5))\n\n\tMinimum_Width=Width*Minimum_Width_Factor\n\n\tLoss_Results=[]\n\tResults=[[]]\n\twhile Regions<=len(Signal):\n\n\t\tif Initial_Fit is None:\n\n\t\t\tResult=copy.deepcopy(Results[-1])+Add_New_Peak(x_axis,Signal,Results[-1],Width,Max_Width,Regions=Regions)\n\n\t\t\tBounds=[]\n\t\t\tn=0\n\t\t\twhile n<len(Result):\n\t\t\t\tBounds+=[(0,np.inf),(np.min(x_axis),np.max(x_axis)),(0,Max_Width)]\n\t\t\t\tn+=3\n\n\t\t\tOpt=spo.minimize(Loss,Result,bounds=Bounds).x.tolist()\n\n\t\t\tOutput=[]\n\t\t\tn=0\n\t\t\twhile n<len(Opt):\n\t\t\t\tif Opt[n]!=0 and Opt[n+2]>Minimum_Width:\n\t\t\t\t\tOutput+=Opt[n:n+3]\n\t\t\t\tn+=3\n\n\t\telse:\n\t\t\tOutput=Optimise_Prexisting_Peaks(x_axis,Signal,Initial_Fit,Max_Width,Peak_Type)\n\t\t\tInitial_Fit=None\n\n\t\tResults.append(Output)\n\t\tLoss_Results.append(Loss(Output))\n\n\t\tif Print is True:\n\t\t\tprint('Iteration ',len(Loss_Results),', Peaks Found: ',old_div(len(Results[-1]),3))\n\n\t\t#---Check to increase region by x5\n\t\tif len(Loss_Results)>1:\n\t\t\tif Loss_Results[-1]>=Loss_Results[-2]: #Has loss gone up?\n\t\t\t\tRegions*=5\n\t\t\telif len(Results[-1])==len(Results[-2]): #Otherwise, same number of peaks?\n\t\t\t\tOld,Current=[],[]\n\t\t\t\tn=0\n\t\t\t\twhile n<len(Results[-2]):\n\t\t\t\t\tOld.append([Results[-2][n+1],Results[-2][n+2]])\n\t\t\t\t\tCurrent.append([Results[-1][n+1],Results[-1][n+2]]) #Collect peak positions and widths for last two iterations\n\t\t\t\t\tn+=3\n\n\t\t\t\tOld=Quick_Sort(Old,0) #Order old iteration in position order\n\n\t\t\t\tTemp=[]\n\t\t\t\tCurrent=np.array(np.transpose(Current))\n\t\t\t\tfor i in Old:\n\t\t\t\t\tArg=np.argmin(np.abs(Current[0]-i[0]))\n\t\t\t\t\tTemp.append([Current[0][Arg],Current[1][Arg]])  #For each old peak, find the closest new peak\n\t\t\t\t\tCurrent[0][Arg]=np.inf \n\t\t\t\tCurrent=Temp\n\n\t\t\t\tEnd=False\n\t\t\t\twhile End is False:\n\t\t\t\t\tEnd=True\n\t\t\t\t\tfor i in range(len(Old))[1:]:  #Check that swapping any adjacent sets of new peaks doesn't imporve the match between old and new peaks\n\t\t\t\t\t\tDelta=abs(Old[i-1][0]-Current[i-1][0])+abs(Old[i][0]-Current[i][0])-abs(Old[i-1][0]-Current[i][0])-abs(Old[i][0]-Current[i-1][0])\n\t\t\t\t\t\tif Delta>0:\n\t\t\t\t\t\t\tEnd=False\n\t\t\t\t\t\t\tCurrent=Current[:i-1]+[Current[i],Current[i-1]]+Current[i+1:]\n\t\t\t\t\n\t\t\t\tCurrent=np.transpose(Current)\n\t\t\t\tOld=np.transpose(Old)\n\t\t\t\tif Peak_Type=='L': #Scale widths to FWHM\n\t\t\t\t\tCurrent[1]*=2 \n\t\t\t\t\tOld[1]*=2 \n\t\t\t\telse:\n\t\t\t\t\tOld[1]*=((2.*np.log(2.))**0.5)\n\t\t\t\t\tCurrent[1]*=((2.*np.log(2.))**0.5)\n\n\t\t\t\tSeperation=np.abs(Old[0]-Current[0])\n\t\t\t\tThreshold=(Old[1]+Old[0])*0.125\n\n\t\t\t\tif True not in (Seperation>=Threshold).tolist():  #Check if all peaks have moved by less than 0.25 FWHM\n\t\t\t\t\tRegions*=5\n\n\n\tif Peak_Type=='L':\n\t\tdef Final_Fitting_Function(x,*Params):\n\t\t\treturn Multi_L(x,*Params[1:])+Params[0]\n\telse:\n\t\tdef Final_Fitting_Function(x,*Params):\n\t\t\treturn Multi_G(x,*Params[1:])+Params[0]\n\n\tOutput=None\n\twhile Output is None and len(Results)>0:\n\t\tBL,BU=[0],[np.inf]\n\t\tn=0\n\t\twhile n<len(Results[-1]):\n\t\t\tBL+=[0,np.min(x_axis),0]\n\t\t\tBU+=[np.inf,np.max(x_axis),Max_Width]\n\t\t\tn+=3\n\t\ttry:\n\t\t\tFits=spo.curve_fit(Final_Fitting_Function,x_axis,Signal,[0]+Results[-1],bounds=(BL,BU))\n\t\t\tFits=[Fits[0],np.sqrt(np.diag(Fits[1]))]\n\t\t\tOutput=[Fits[0][1:],Fits[1][1:]]\n\t\texcept RuntimeError:\n\t\t\tResults=Results[:-1]\n\n\tif Output is None:\n\t\tOutput=[None,None]\n\n\treturn Output",
  "def Worker_Function(x_axis,Signal,Maximum_FWHM,Regions,Minimum_Width_Factor,Peak_Type,Initial_Fit,Number):\n\t\tFit=Run(x_axis,Signal,Maximum_FWHM,Regions,Minimum_Width_Factor,Peak_Type,Initial_Fit=Initial_Fit,Print=False)\n\t\tprint('Fit Spectrum:',Number)\n\t\treturn [Fit,Number]",
  "def Fit_Set_of_Spectra(x_axis,Signals,Maximum_FWHM=40,Regions=50,Minimum_Width_Factor=0.1,Peak_Type='L',Cores=2,Utilise_Persistent=False):\n\n\t\"\"\"\n\tUtilises multiprocessing to run a set of fits in parrallel.\n\t\"\"\"\n\n\tif Utilise_Persistent is True:\n\t\tMedian_Signal=np.median(Signals,axis=0)\n\t\tInitial_Peaks=Run(x_axis,Median_Signal,Maximum_FWHM,Regions,Minimum_Width_Factor,Peak_Type,Print=False)[0]\n\telse:\n\t\tInitial_Peaks=None\n\n\tProcesses=[]\n\tPool=mp.Pool(processes=Cores)\n\n\tfor i in range(len(Signals)):\n\t\tProcesses.append(Pool.apply_async(Worker_Function,args=(x_axis,Signals[i],Maximum_FWHM,Regions,Minimum_Width_Factor,Peak_Type,Initial_Peaks,i)))\n\t\n\tResults=[p.get() for p in Processes]\n\n\tPool.close()\n\n\tResults=Quick_Sort(Results,1)\n\n\tfor i in range(len(Results)):\n\t\tResults[i]=Results[i][0]\n\n\treturn Results",
  "def Split(List,Argument):\n\t\t\t#List is list of lists to seperate\n\t\t\t#Argument is list argument to seperate via\n\n\t\t\tOutput=[[],[]]\n\n\t\t\tPivot=[]\n\t\t\tfor i in List:\n\t\t\t\tPivot.append(i[Argument])\n\t\t\tif len(Pivot)==2:\n\t\t\t\tPivot=max(Pivot)\n\t\t\telse:\n\t\t\t\tPivot=np.random.choice(Pivot)\n\n\t\t\tfor i in List:\n\t\t\t\tif i[Argument]<Pivot:\n\t\t\t\t\tOutput[0].append(i)\n\t\t\t\telse:\n\t\t\t\t\tOutput[1].append(i)\n\t\t\treturn Output",
  "def Same(List,Argument):\n\t\t\tfor i in List:\n\t\t\t\tif i[Argument]!=List[0][Argument]:\n\t\t\t\t\treturn False\n\t\t\treturn True",
  "def Loss(Vector):\n\t\tOutput=0.\n\t\tfor i in range(len(Vector)):\n\t\t\tOutput+=Vector[i]*Peaks[i]\n\t\treturn np.sum(np.abs(Output-Signal))",
  "def Loss(Vector):\n\t\t\treturn np.sum(np.abs(Current+L(x_axis,*Vector)-Signal))",
  "def Loss(Vector):\n\t\t\treturn np.sum(np.abs(Current+G(x_axis,*Vector)-Signal))",
  "def Loss(Vector):\n\t\t\treturn np.sum(np.abs(Multi_L(x_axis,*Vector)-Signal))",
  "def Loss(Vector):\n\t\t\treturn np.sum(np.abs(Multi_G(x_axis,*Vector)-Signal))",
  "def Loss(Vector):\n\t\t\treturn np.sum(np.abs(Multi_L(x_axis,*Vector)-Signal))",
  "def Loss(Vector):\n\t\t\treturn np.sum(np.abs(Multi_G(x_axis,*Vector)-Signal))",
  "def Final_Fitting_Function(x,*Params):\n\t\t\treturn Multi_L(x,*Params[1:])+Params[0]",
  "def Final_Fitting_Function(x,*Params):\n\t\t\treturn Multi_G(x,*Params[1:])+Params[0]",
  "def Grad(Array):\n\t\"\"\"\n\tReturns something prop to the grad of 1D array Array. Does central difference method with mirroring.\n\t\"\"\"\n\tA=np.array(Array.tolist()+[Array[-1],Array[-2]])\n\tB=np.array([Array[1],Array[0]]+Array.tolist())\n\treturn (A-B)[1:-1]",
  "def Find_Zeroes(Array):\n\t\"\"\"\n\tFind the zero crossing points in a 1D array Array, using linear interpolation\n\t\"\"\"\n\tOutput=[]\n\tfor i in range(len(Array))[1:]:\n\t\tif Array[i]==0:\n\t\t\tOutput.append(float(i))\n\t\telse:\n\t\t\tif i!=0:\n\t\t\t\tif ((int((Array[i]>0))*2)-1)*((int((Array[i-1]>0))*2)-1)==-1:\n\t\t\t\t\tFrac=old_div(Array[i-1],(Array[i-1]-Array[i]))\n\t\t\t\t\tOutput.append(i+Frac-1)\n\treturn Output",
  "def Find_Maxima(Array):\n\t\"\"\"\n\tFind all local maxima in 1d array Array\n\t\"\"\"\n\tDiff=Grad(Array)\n\tStationary=Find_Zeroes(Diff)\n\tCurv=Grad(Diff)\n\tOutput=[]\n\tfor i in Stationary:\n\t\tValue=((Curv[int(i)+1]-Curv[int(i)])*i%1)+Curv[int(i)]\n\t\tif Value<0:\n\t\t\tOutput.append(i)\n\treturn Output",
  "def L(x,H,C,W):\n\t\"\"\"\n\tDefines a lorentzian\n\t\"\"\"\n\treturn old_div(H,(1.+((old_div((x-C),W))**2)))",
  "def Multi_L_Constant(x,*Params):\n\t\"\"\"\n\tDefines a contant plus a sum of Lorentzians. Params goes Constant, Height1,Centre1, Width1,Height2.....\n\t\"\"\"\n\tOutput=Params[0]\n\tn=1\n\twhile n<len(Params):\n\t\tOutput+=L(x,*Params[n:n+3])\n\t\tn+=3\n\treturn Output",
  "def Attempt_To_Fit(Shift,Array,Peak_Shifts,Peak_Heights,Width,Minimum_Height=0):\n\t\"\"\"\n\tGiven a raman Shift and spectrum Array, with guesses for possible Peak_Shifts and Peak_Heights with a single guess for the Width, attempts to fit the peaks.\n\tFits rejected if Height<Minimum_Height\n\t\"\"\"\n\tNumber_Of_Peaks=len(Peak_Shifts)\n\n\tdef Generate_Peak_Selections(Number,Options):\n\t\tLevels=Options-Number\n\t\tOutput=[list(range(Options))]\n\t\tfor i in range(Levels):\n\t\t\tNew_Output=[]\n\t\t\tfor j in Output:\n\t\t\t\tfor k in range(len(j)):\n\t\t\t\t\tNew=sorted(j[:k]+j[k+1:])\n\t\t\t\t\tif New not in New_Output:\n\t\t\t\t\t\tNew_Output.append(New)\n\t\t\tOutput=New_Output\n\t\treturn Output\n\n\twhile Number_Of_Peaks>0:\n\n\t\tOptions=Generate_Peak_Selections(Number_Of_Peaks,len(Peak_Shifts))\n\n\t\tParameters=[]\n\n\t\tfor Option in Options:\n\t\t\tInitial=[0.]\n\t\t\tL_Bounds=[-np.inf]\n\t\t\tU_Bounds=[np.inf]\n\t\t\tfor i in Option:\n\t\t\t\tInitial+=[Peak_Heights[i],Peak_Shifts[i],Width]\n\t\t\t\tL_Bounds+=[0,np.min(Shift),0]\n\t\t\t\tU_Bounds+=[np.inf,np.max(Shift),np.inf]\n\t\t\t\t#print Initial\n\t\t\ttry:\n\t\t\t\tParams=spo.curve_fit(Multi_L_Constant,Shift,Array,Initial,bounds=(L_Bounds,U_Bounds))\n\t\t\t\tParams=[Params[0],np.sqrt(np.diag(Params[1]))]\n\n\t\t\t\t#print Params\n\t\t\t\t\t\t\n\t\t\t\tFail=False\n\t\t\t\tn=1\n\t\t\t\twhile n<len(Params[0]):\n\t\t\t\t\tif (Params[0][n]-Params[0][0])<Minimum_Height:\n\t\t\t\t\t\tFail=True\n\t\t\t\t\tn+=3\n\t\t\t\tif True in (Params[0][1:]<np.abs(Params[1][1:])).tolist():\n\t\t\t\t\tFail=True\n\t\t\t\tn=1\n\t\t\t\twhile n<len(Params[0])-3:\n\t\t\t\t\tif (Params[0][n+2]+Params[0][n+5])>abs((Params[0][n+1]-Params[0][n+4])):\n\t\t\t\t\t\tFail=True\n\t\t\t\t\tn+=3\n\t\t\t\tif Fail is False:\n\t\t\t\t\tParameters.append(Params[0])\n\t\t\texcept RuntimeError:\n\t\t\t\t\tDump=None\n\n\t\tif len(Parameters)>0:\n\t\t\tLoss=[]\n\t\t\tfor i in Parameters:\n\t\t\t\tLoss.append(np.sum(np.abs(Array-Multi_L_Constant(Shift,*i))))\n\t\t\treturn Parameters[np.argmin(Loss)]\n\n\t\tNumber_Of_Peaks-=1\n\treturn None",
  "def Run(Input,Shift,Width=10,Smoothing_Factor=5,Noise_Threshold=2):\n\t\"\"\"\n\tMain Function, described above\n\t\"\"\"\n\tSmooth=imf.gaussian_filter(Input,Smoothing_Factor)\n\tMaxima=Find_Maxima(Smooth)\n\tThreshold=Noise_Threshold*np.std(Grad(Input))\n\tPeak_Shifts=[]\n\tPeak_Heights=[]\n\tfor i in Maxima:\n\t\tH=((Input[int(i)+1]-Input[int(i)])*i%1)+Input[int(i)]\n\t\tif H>=Threshold:\n\t\t\tPeak_Heights.append(H)\n\t\t\tPeak_Shifts.append(((Shift[int(i)+1]-Shift[int(i)])*i%1)+Shift[int(i)])\n\tFirst_Draft=Attempt_To_Fit(Shift,Smooth,Peak_Shifts,Peak_Heights,Width,Threshold)\n\t\n\tif First_Draft is None:\n\t\treturn [None,None]\n\n\tL_Bounds=[-np.inf]\n\tU_Bounds=[np.inf]\n\n\tn=1\n\twhile n<len(First_Draft):\n\t\tL_Bounds+=[0,-np.inf,0]\n\t\tU_Bounds+=[np.inf,np.inf,np.inf]\n\t\tn+=3\t\n\n\ttry:\n\t\tParams=spo.curve_fit(Multi_L_Constant,Shift,Input,First_Draft,bounds=(L_Bounds,U_Bounds))\n\t\tParams=[Params[0],np.sqrt(np.diag(Params[1]))]\n\t\tParams=[Params[0][1:],Params[1][1:]]\n\t\treturn Params\n\texcept RuntimeError:\n\t\treturn [None,None]",
  "def Generate_Peak_Selections(Number,Options):\n\t\tLevels=Options-Number\n\t\tOutput=[list(range(Options))]\n\t\tfor i in range(Levels):\n\t\t\tNew_Output=[]\n\t\t\tfor j in Output:\n\t\t\t\tfor k in range(len(j)):\n\t\t\t\t\tNew=sorted(j[:k]+j[k+1:])\n\t\t\t\t\tif New not in New_Output:\n\t\t\t\t\t\tNew_Output.append(New)\n\t\t\tOutput=New_Output\n\t\treturn Output",
  "def sm(spec, sigma=3):\n    return gaussian_filter(spec, sigma)",
  "def truncate(counts, wavelengths, lower_cutoff, upper_cutoff, return_indices_only=False):\n    '''\n    truncates a spectrum between upper and lower bounds. returns counts, wavelenghts pair.\n    works with any x-axis (cm-1), not just wavelengths\n    '''\n    l = 0\n    for index, wl in enumerate(wavelengths):\n        if wl >= lower_cutoff:\n\n            l = index\n            break\n\n    u = False\n    for index, wl in enumerate(wavelengths[l:]):\n        if wl >= upper_cutoff:\n            u = index+l\n            break\n    if return_indices_only == False:\n        if u == False:\n            return counts[l:], wavelengths[l:]\n        else:\n            return counts[l:u], wavelengths[l:u]\n    else:\n        return l, u",
  "def find_closest(value_to_match, array):\n    '''Taking an input value and array, it searches for the value and index in the array which is closest to the input value '''\n    if len(array) == 1:\n        return array[0], 0, np.absolute(value_to_match - array[0])\n    residual = [np.absolute(value-value_to_match) for value in array]\n    # value, index, residual\n    return array[np.argmin(residual)], np.argmin(residual), min(residual)",
  "def cm_to_omega(cm):\n    '''\n    converts cm^-1 to angular frequency\n    '''\n    return 2*np.pi*constants.c*100.*cm",
  "def reshape(List, n):\n    while len(List) >= n:\n        yield List[:n]\n        List = List[n:]",
  "class fullfit(object):\n    def __init__(self,\n                 spec,\n                 shifts,\n                 lineshape='L',\n                 order=7,\n                 transmission=None,\n                 bg_function='poly',\n                 vary_const_bg=True):\n\n        self.spec = np.array(spec)\n        self.shifts = np.array(shifts)\n        self.order = order\n        self.peaks = []\n\n        self.peak_bounds = []\n\n        self.asymm_peaks = None\n        self.transmission = np.ones(len(spec))\n        if transmission is not None:\n            self.transmission *= transmission\n        if lineshape == 'L':\n            self.line = lambda H, C, W: self.L(self.shifts, H, C, W)\n        if lineshape == 'G':\n            self.line = lambda H, C, W: self.G(self.shifts, H, C, W)\n        self.lineshape = lineshape\n\n        self.bg_type = bg_function\n        if bg_function == 'exponential':\n            self.bg_function = self.exponential\n        if bg_function == 'exponential2':\n            self.bg_function = self.exponential2\n        self.vary_const_bg = vary_const_bg\n        if bg_function == 'exponential' or bg_function == 'exponential2':\n            if vary_const_bg != True:\n                self.bg_bounds = ([0, 0, 0, ], [np.inf, np.inf, 1e-9])\n            else:\n                self.bg_bounds = ([0, 0, 0, ], [np.inf, np.inf, np.inf])\n\n    @staticmethod\n    def L(x, H, C, W):  # height centre width\n        \"\"\"\n        Defines a lorentzian\n        \"\"\"\n        return H/(1.+((x-C)/W)**2)\n\n    @staticmethod\n    def G(x, H, C, W):\n        '''\n        A Gaussian\n        '''\n        return H*np.exp(-((x-C)/W)**2)\n\n    def multi_line(self, parameters):\n        \"\"\"\n        returns a sum of Lorenzians/Gaussians. \n        \"\"\"\n        return np.sum(np.array([self.line(*peak) for peak in parameters]), axis=0)\n\n    def exponential(self, A, T, bg):\n        '''\n        uses the transmission for the exponential term, not the constant background.\n        '''\n        omega = -cm_to_omega(self.shifts)\n        return ((A*(np.exp((constants.hbar/constants.k)*omega/T) - 1))**-1)*interp(self.shifts, self.transmission)(self.shifts) + bg\n\n    def exponential2(self, A, T, bg):\n        '''\n        uses the a more conplicated exponential \n        '''\n        omega = -cm_to_omega(self.shifts)\n        return A*(((np.exp((constants.hbar/constants.k)*omega/T) - 1)**-1)+(np.exp((constants.hbar/constants.k)*omega/298.) - 1)**-1)*interp(self.shifts, self.transmission)(self.shifts) + bg\n\n    def exponential_loss(self, bg_p):\n        '''\n        evaluates fit of exponential to spectrum-signal\n        '''\n        residual = self.bg_function(self.shifts, *bg_p) - self.bg\n        above = residual[residual > 0]\n        below = residual[residual < 0]\n        obj = np.sum(np.absolute(above))+np.sum(np.array(below)**2)\n        return obj\n\n    def plot_result(self):\n        '''\n        plots the spectrum and the individual peaks, and their sums\n\n        '''\n        plt.figure()\n        plt.plot(self.shifts, self.spec)\n        plt.plot(self.shifts, self.bg)\n        for peak in self.peaks:\n            plt.plot(self.shifts, self.bg+self.line(*peak)*self.transmission)\n        plt.plot(self.shifts, self.bg + self.multi_line(self.peaks)\n                 * self.transmission, linestyle='--', color='k')\n\n    def plot_asymm_result(self):\n        '''\n        plots the spectrum and the individual after aysmmetrization\n        '''\n        plt.figure()\n        plt.plot(self.shifts, self.spec)\n        plt.plot(self.shifts, self.bg)\n        for asymmpeak in self.asymm_peaks:\n\n            plt.plot(self.shifts, self.bg +\n                     self.asymm_line(asymmpeak)*self.transmission)\n\n    def add_new_peak(self):\n        '''\n        lifted from Iterative_Raman_Fitting\n        '''\n        # -----Calc. size of x_axis regions-------\n        sectionsize = (np.max(self.shifts)-np.min(self.shifts)) / \\\n            float(self.regions)\n        Start = np.min(self.shifts)\n\n        results = []\n        loss_results = []\n\n        \n        if not len(self.peaks):\n            Current = np.array(self.shifts)*0\n        else:\n            Current = self.multi_line(self.peaks)\n\n   \n\n        def loss(params):\n            # *self.multi_L(self.shifts,*self.peaks))# if this overlaps with another lorentzian it's biased against it\n            return np.sum(np.abs(Current+self.line(*params)-self.signal))\n\n        for i in range(int(self.regions)):\n            bounds = [(0, np.inf), (i*sectionsize+Start, (i+1) *\n                                    sectionsize+Start), (0, max(self.shifts)-min(self.shifts))]\n            Centre = (i+np.random.rand())*sectionsize+Start\n            try:\n                Height = max(truncate(self.signal, self.shifts, i*sectionsize +\n                                      Start, (i+1)*sectionsize+Start)[0])-min(self.signal)\n            except:\n                Height = self.noise_threshold\n            params = [Height, Centre, self.width]\n\n            params = minimize(loss, params, bounds=bounds).x.tolist()\n\n            results.append(params)\n            loss_results.append(loss(params))\n\n        sorted_indices = np.argsort(loss_results)\n\n        self.peak_added = False\n        i = -1\n        # test the top 50% of peaks\n        while self.peak_added == False and i < (len(loss_results) - 1):\n            i += 1\n            peak_candidate = results[sorted_indices[i]]\n            # has a height, minimum width - maximum width are within bounds\n            if peak_candidate[0] > self.noise_threshold and self.maxwidth > peak_candidate[2] > self.minwidth:\n                if len(self.peaks) != 0:\n                    dump, peak, residual = find_closest(\n                        peak_candidate[1], np.transpose(self.peaks)[1])\n                    # is far enough away from existing peaks\n                    if residual > self.min_peak_spacing*self.peaks[peak][2]:\n                        self.peaks.append(peak_candidate)\n                        self.peak_added = True\n\n                else:  # If no existing peaks, accept it\n                    self.peaks.append(peak_candidate)\n                    self.peak_added = True\n            else:\n                # print(peak_candidate[0], self.noise_threshold, self.maxwidth, peak_candidate[2],self.minwidth)\n                pass\n        if self.peak_added:  # TODO store these values\n\n            self.peak_bounds.append(self.bound)  # height, position, width\n            if self.verbose:\n                print('peak added')\n        if not self.peak_added and self.verbose:\n            print('no suitable peaks to add')\n\n    def initial_bg_poly(self):\n        '''\n        takes an inital guess at the background.\n        takes the local minima of the smoothed spectrum, weighted by how far they are to other minima, and fits to these.\n        weighting is to prioritise flatter portions of the spectrum (which would naturally have fewer minima)\n\n        '''\n\n        smoothed = sm(self.spec)\n        self.bg_indices = argrelextrema(smoothed, np.less)[0]\n        while len(self.bg_indices) < 3*self.order:\n            self.bg_indices = np.append(self.bg_indices,\n                                        min(np.random.randint(0,\n                                                              high=len(\n                                                                  self.spec),\n                                                              size=(10,)),\n                                            key=lambda i: self.spec[i]))\n        self.bg_vals = smoothed[self.bg_indices]\n\n        residuals = []\n        for index in self.bg_indices:\n            residuals.append(find_closest(\n                index, np.setdiff1d(self.bg_indices, index))[2])\n        norm_fac = 5./max(residuals)\n        extra_lens = norm_fac*np.array(residuals)\n        for bg_index, extra_len in zip(self.bg_indices, extra_lens):\n            extra_len = int(extra_len)\n            if extra_len < 1:\n                extra_len = 1\n            for extra in np.arange(extra_len)+1:\n                try:\n                    self.bg_vals.append(smoothed[bg_index+extra])\n                    self.bg_indices.append(bg_index+extra)\n                except:\n                    pass\n                try:\n                    self.bg_vals.append(smoothed[bg_index-extra])\n                    self.bg_indices.append(bg_index-extra)\n                except:\n                    pass\n        edges = np.arange(5)+1\n        edges = np.append(edges, -edges).tolist()\n        self.bg_indices = np.append(self.bg_indices, edges)\n        self.bg_vals = np.append(self.bg_vals, smoothed[edges])\n\n        if self.bg_type == 'poly':\n            self.bg_bound = (min(self.spec), max(self.spec))\n            self.bg_bounds = []\n            while len(self.bg_bounds) < len(self.bg_vals):\n                self.bg_bounds.append(self.bg_bound)\n            self.bg_p = np.polyfit(\n                self.shifts[self.bg_indices], self.bg_vals, self.order)\n            self.bg = np.polyval(self.bg_p, self.shifts)\n\n        else:\n            if self.vary_const_bg == False:\n                self.bg_p = curve_fit(self.bg_function, self.shifts[self.bg_indices], self.bg_vals, p0=[\n                                      0.5*max(self.spec), 300, 1E-10], maxfev=100000, bounds=self.bg_bounds)[0]\n            else:\n                self.bg_p = curve_fit(self.bg_function, self.shifts[self.bg_indices], self.bg_vals, p0=[\n                                      0.5*max(self.spec), 300, min(self.spec)], maxfev=100000, bounds=self.bg_bounds)[0]\n            self.bg = self.bg_function(self.shifts, *self.bg_p)\n        self.signal = np.array(self.spec - self.bg)/self.transmission\n\n    def bg_loss(self, bg_p):\n        '''\n        evaluates the fit of the background to spectrum-peaks\n        '''\n\n        fit = np.polyval(bg_p, self.shifts)\n        residual = self.spec - self.peaks_evaluated - fit\n        above = residual[residual > 0]\n        below = residual[residual < 0]\n        obj = np.sum(np.absolute(above))+10*np.sum(np.array(below))**4\n\n        return obj\n\n    def optimize_bg(self):  # takes bg_vals\n        '''\n        it's important to note that the parameter optimised isn't the polynomial coefficients bg_p , \n        but the points taken on the spectrum-peaks curve (bg_vals) at positions bg_indices, decided by initial_bg_poly().\n        This is because it's easy to put the bounds of the minimum and maximum of the spectrum on these to improve optimisation time. (maybe)\n        '''\n        if self.asymm_peaks_stack == None:\n            self.peaks_evaluated = self.multi_line(\n                self.shifts, self.peaks)*self.transmission\n        else:\n            self.peaks_evaluated = self.asymm_multi_line(\n                self.shifts, self.asymm_peaks)*self.transmission\n\n        if self.bg_type == 'poly':\n            self.bg_p = minimize(self.bg_loss, self.bg_p).x.tolist()\n            self.bg = np.polyval(self.bg_p, self.shifts)\n            self.signal = (old_div(np.array(self.spec - self.bg),\n                                   self.transmission)).tolist()\n        elif self.bg_type == 'exponential' or self.bg_type == 'exponential2':\n\n            self.bg_p = curve_fit(self.bg_function,\n                                  self.shifts,\n                                  self.spec -\n                                  self.multi_line(\n                                      self.shifts, self.peaks)*self.transmission,\n                                  p0=self.bg_p,\n                                  bounds=self.bg_bounds,\n                                  maxfev=10000)[0]\n            self.bg = self.bg_function(self.shifts, *self.bg_p)\n\n    @staticmethod\n    def peaks_to_matrix(peak_array):\n        '''\n        converts a 1d peak_array into a 2d one\n        '''\n\n        return [peak for peak in reshape(peak_array, 3)]\n\n    def peak_loss(self, peaks):\n        '''\n        evalutes difference between the fitted peaks and the signal (spectrum - background)\n        '''\n        fit = self.multi_line(self.peaks_to_matrix(peaks))\n        obj = np.sum(np.square(self.signal - fit))\n        return obj\n\n    def optimize_peaks(self):\n        '''\n        optimizes the height, centres and widths of all peaks\n        '''\n        if len(self.peaks) < 2:\n            return\n        bounds = []\n        for bound in self.peak_bounds:\n            bounds.extend(bound)\n        self.peaks = self.peaks_to_matrix(\n            minimize(self.peak_loss, np.ravel(self.peaks), bounds=bounds).x.tolist())\n\n    def optimize_centre_and_width(self):\n        '''\n        optimizes the centres(positions) and widths of the peakss for a given heights.\n        '''\n        if len(self.peaks) < 2:\n            return\n        heights = np.transpose(self.peaks)[0]\n        centres_and_widths = np.transpose(self.peaks)[1:]\n        # centres_and_widths = np.ravel(centres_and_widths)\n        width_bound = (self.minwidth, self.maxwidth)\n        centre_and_width_bounds = []\n        for centre, width in zip(*centres_and_widths):\n            centre_and_width_bounds.extend(\n                [(centre-width, centre+width), (width_bound)])  # height, position, width\n\n        def multi_line_centres_and_widths(centres_and_widths):\n            \"\"\"\n            Defines a sum of Lorentzians. Params goes Height1,Centre1, Width1,Height2.....\n            \"\"\"\n            params = [[h, c, w] for h, (c, w) in zip(\n                heights, reshape(centres_and_widths, 2))]\n            return self.multi_line(params)\n\n        def loss_centres_and_widths(centres_and_widths):\n            fit = multi_line_centres_and_widths(centres_and_widths)\n            obj = np.sum(np.square(self.signal - fit))\n            return obj\n        centres_and_widths = minimize(loss_centres_and_widths, np.ravel(\n            centres_and_widths, 'F'), bounds=centre_and_width_bounds).x\n        self.peaks = [[h, c, w] for h, (c, w) in zip(\n            heights, reshape(centres_and_widths, 2))]\n\n    def optimize_heights(self):\n        '''\n        crudely gets the maximum of the signal within the peak width as an estimate for the peak height\n        '''\n        if len(self.peaks) < 1:\n            return\n        else:\n\n            for index, peak in enumerate(self.peaks):\n                try:\n                    self.peaks[index][0] = max(\n                        truncate(self.signal, self.shifts, peak[1]-peak[2]/4., peak[1]+peak[2]/4.)[0])\n                except:\n                    self.peaks[index][0] = self.signal[find_closest(\n                        peak[2], self.shifts)[1]]\n\n    def loss_function(self):\n        '''\n        evaluates the overall (bg+peaks) fit to the spectrum\n        '''\n\n        fit = self.bg + self.multi_line(self.peaks)*self.transmission\n        obj = np.sum(np.square(self.spec - fit))\n        return obj\n\n    def optimize_peaks_and_bg(self):\n        '''\n        optimizes the peaks and background in one procedure, \n        allowing for better interplay of peaks and bg\n        '''\n        if self.bg_type == 'poly':\n            def loss(peaks_and_bg):\n                fit = np.polyval(peaks_and_bg[:self.order+1], self.shifts)\n                fit += self.multi_line(self.peaks_to_matrix(\n                    peaks_and_bg[self.order+1:]))*self.transmission\n                residual = self.spec - fit\n                above = residual[residual > 0]\n                below = residual[residual < 0]\n                # prioritises fitting the background to lower data points\n                obj = np.sum(np.absolute(above))+np.sum(np.array(below)**2)\n                return obj\n            peaks_and_bg = np.append(self.bg_p, np.ravel(self.peaks))\n            bounds = [(-np.inf, np.inf) for p in self.bg_p]\n            if len(self.peaks):\n                for bound in self.peak_bounds:\n                    bounds.extend(bound)\n            peaks_and_bg = minimize(\n                loss, peaks_and_bg, bounds=bounds).x.tolist()\n\n            self.bg_p = peaks_and_bg[:self.order+1]\n            self.peaks = self.peaks_to_matrix(peaks_and_bg[self.order+1:])\n            self.bg = np.polyval(self.bg_p, self.shifts)\n        else:\n            def loss(peaks_and_bg):\n                fit = self.bg_function(peaks_and_bg[:3])\n                fit += self.multi_line(peaks_and_bg[3:])*self.transmission\n                residual = self.spec - fit\n                above = residual[residual > 0]\n                below = residual[residual < 0]\n                # prioritises fitting the background to lower data points\n                obj = np.sum(np.absolute(above))+np.sum(np.array(below)**2)\n                return obj\n            peaks_and_bg = np.append(self.bg_p, self.peaks)\n            if self.vary_const_bg == False:\n                bounds = [(0, max(self.spec)*10),\n                          (100, 1000),\n                          (min(self.spec*0.7), 1e-9)]\n            else:\n                bounds = [(0, max(self.spec)*10),\n                          (100, 1000),\n                          (min(self.spec*0.7), max(self.spec))]\n\n            bounds.extend(self.peak_bounds)\n            peaks_and_bg = minimize(loss, peaks_and_bg, bounds=bounds).x\n            self.bg_p = peaks_and_bg[:3]\n            self.peaks = self.peaks_to_matrix(peaks_and_bg[3:])\n            self.bg = self.bg_function(self.shifts, *self.bg_p)\n\n    def optimize_asymm(self):\n        '''\n        allows the peaks to become asymmetric by raising either side of the peaks to separate exponents (alpha and beta) \n        '''\n        width_alpha_beta = []\n        asymmbounds = []\n        if self.asymm_peaks is None:\n            self.asymm_peaks_stack = []\n\n            for peak in self.peaks:\n                # initial alpha, beta\n                width_alpha_beta.extend([peak[2], 1., 1.])\n                asymmbounds.extend([(peak[2]/5., peak[2]*5),\n                                    (0.8, 1.2),\n                                    (0.8, 1.2)])\n            asymmbounds = np.array(asymmbounds)\n        else:\n\n            for asymm_peak in self.asymm_peaks:\n                width_alpha_beta.extend([asymm_peak[2],\n                                         asymm_peak[3],\n                                         asymm_peak[4]])\n                asymmbounds.extend([(old_div(asymm_peak[2], 5), asymm_peak[2]*5),\n                                    (0.9, 1.1),\n                                    (0.9, 1.1)])\n\n        def asymmloss(width_alpha_beta):\n            width_alpha_beta_stack = self.peaks_to_matrix(width_alpha_beta)\n            params = []\n            for peak, width_alpha_beta in zip(self.peaks, width_alpha_beta_stack):\n                params.append([*peak[0:2], *width_alpha_beta])\n            fit = self.asymm_multi_line(params)\n            obj = np.sum(np.square(self.signal - fit))\n            return obj\n\n        width_alpha_beta = minimize(\n            asymmloss, width_alpha_beta, bounds=asymmbounds).x.tolist()\n        wab_stack = self.peaks_to_matrix(width_alpha_beta)\n        self.asymm_peaks = [[*peak[0:2], *width_alpha_beta]\n                            for peak, width_alpha_beta in zip(self.peaks, wab_stack)]\n\n    def asymm_line(self, asymmpeak):\n        '''\n        defines an asymmetric lineshape - depends on whether initial lineshape is L or G\n        '''\n\n        alpha = np.true_divide(self.line(\n            asymmpeak[0], asymmpeak[1], asymmpeak[2]), asymmpeak[0])**asymmpeak[3]\n        alpha = truncate(alpha, self.shifts, -np.inf, asymmpeak[1])[0]\n\n        alpha *= asymmpeak[0]\n        beta = np.true_divide(self.line(\n            asymmpeak[0], asymmpeak[1], asymmpeak[2]), asymmpeak[0])**asymmpeak[4]\n        beta = truncate(beta, self.shifts, asymmpeak[1], np.inf)[0]\n        beta *= asymmpeak[0]\n        return np.append(alpha, beta)\n\n    def asymm_multi_line(self, params):  # params is 2d\n        '''\n        outputs sum of many asymmetric peaks\n        '''\n\n        return np.sum([self.asymm_line(asymmpeak) for asymmpeak in params], axis=0)\n\n    def dummy_run(self,\n                 initial_fit=None,\n                 add_peaks=True,\n                 allow_asymmetry=False,\n                 minwidth=8,\n                 maxwidth=30,\n                 regions=20, noise_factor=2,\n                 min_peak_spacing=5,\n                 comparison_thresh=0.05,\n                 verbose=False):\n        '''\n        handy to test other scripts quickly\n        '''\n\n        self.initial_bg_poly()\n        self.minwidth = minwidth\n        self.maxwidth = maxwidth\n#        if initial_fit is not None:\n#            self.peaks = initial_fit\n#            self.peaks_stack = np.reshape(self.peaks, [len(self.peaks)/3, 3])\n#            self.optimize_heights\n#            #self.optimize_centre_and_width()\n\n        smoothed = sm(self.spec)\n        maxima = argrelextrema(smoothed, np.greater)[0]\n        heights = smoothed[maxima]\n        maxima = maxima[np.argsort(heights)[-5:]]\n        heights = smoothed[maxima]\n\n        centres = self.shifts[maxima]\n        widths = np.ones(len(maxima))*PEAKWIDTH\n\n        self.peaks = np.transpose(np.stack([heights, centres, widths]))\n\n        self.optimize_heights\n        self.optimize_centre_and_width()\n        print(\"I'm a dummy!\")\n\n    def run(self, *args, **kwargs):\n        if DUMMY:\n            self.dummy_run(*args, **kwargs)\n        else:\n            self._run(*args, **kwargs)\n\n    def _run(self,\n             initial_fit=None,\n             add_peaks=True,\n             allow_asymmetry=False,\n             minwidth=2.5,\n             maxwidth=20,\n             regions=10,\n             noise_factor=0.1,\n             min_peak_spacing=3.1,\n             comparison_thresh=0.01,\n             verbose=False):\n        '''\n        described at the top\n        '''\n        if self.lineshape == 'L':\n            self.maxwidth = maxwidth/2.\n            self.minwidth = minwidth/2.\n        if self.lineshape == 'G':\n            self.maxwidth = maxwidth/0.95\n            self.minwidth = minwidth/0.95\n        self.verbose = verbose\n        self.min_peak_spacing = min_peak_spacing\n        self.width = PEAKWIDTH  # a guess for the peak width\n        \n        noise = np.sqrt(np.var(self.spec/gaussian_filter(self.spec, 40))).mean()\n\n        self.noise_threshold = noise_factor*noise\n\n        # number of regions the spectrum will be split into to add a new peak\n        self.regions = regions\n        if self.regions > len(self.spec):\n            # can't be have more regions than points in spectrum\n            self.regions = len(self.spec)//2\n\n        self.initial_bg_poly()  # takes a guess at the background\n        if self.noise_threshold>np.max(self.signal):\n            self.noise_threshold=np.min(self.signal)\n        height_bound = (self.noise_threshold, np.max(self.signal))\n        \n        pos_bound = (np.min(self.shifts), np.max(self.shifts))\n        width_bound = (self.minwidth, self.maxwidth)\n\n        self.bound = [height_bound, pos_bound, width_bound]\n\n        if initial_fit is not None:\n            self.peaks = initial_fit\n            if add_peaks == False:\n                # if regions is bigger than the spectrum length, then no peaks are added\n                self.regions = len(self.spec)+1\n            self.peaks_stack = self.peaks_to_matrix(\n                self.peaks)  # 2d array of peak parameters\n            # bounds for the peak parameters\n            height_bound = (self.noise_threshold, max(self.signal))\n            pos_bound = (np.min(self.shifts), np.max(self.shifts))\n            width_bound = (self.minwidth, self.maxwidth)\n            self.peak_bounds = [self.bound for _ in self.peaks]\n            # creates a bound for each peak\n            self.optimize_heights()  # see functions for descriptions\n            self.optimize_centre_and_width()\n\n            self.optimize_peaks()\n        while self.regions <= len(self.spec):\n            if verbose == True:\n                print('Region fraction: ', np.around(\n                    self.regions/float(len(self.spec)), decimals=2))\n            existing_loss_score = self.loss_function()  # measure of fit 'goodness'\n            Old = self.peaks  # peaks before new one added\n            self.add_new_peak()  # adds a peak\n            if verbose == True:\n                print('# of peaks:', len(self.peaks))\n#            self.optimize_heights\n#            self.optimize_centre_and_width()\n            self.optimize_peaks_and_bg()  # optimizes\n            new_loss_score = self.loss_function()\n\n            # ---Check to increase regions\n            if new_loss_score >= existing_loss_score:  # if fit has worsened, delete last peak\n                if self.peak_added:\n                    self.peaks = self.peaks[:-1]\n                    self.peak_bounds = self.peak_bounds[:-1]\n                    if verbose:\n                        print('peak removed as it made the fit worse')\n                self.regions *= 4  # increase regions, as this is a sign fit is nearly finished\n\n            elif not self.peak_added:  # Otherwise, same number of peaks?\n                #                self.optimize_bg()\n                #                self.optimize_heights() # fails if no peaks\n                #                self.optimize_centre_and_width()\n                #                self.optimize_peaks()\n                self.optimize_peaks_and_bg()\n                New = self.peaks\n                New_trnsp = np.transpose(New)\n                residual = []\n                for old_peak in Old:\n                    # returns index of the new peak which matches it\n                    new_peak = find_closest(old_peak[1], New_trnsp[1])[1]\n                    old_height = old_peak[0]\n                    old_pos = old_peak[1]/self.width\n                    new_height = New[new_peak][0]/old_height\n                    # normalise the height and position parameters to add them into one comparison score\n                    new_pos = New[new_peak][1]/self.width\n                    # the difference between old and new for each peak\n                    residual.append(np.linalg.norm(\n                        np.array([1, old_pos])-np.array([new_height, new_pos])))\n                comparison = np.array(residual) > comparison_thresh\n                if type(comparison) == bool:  # happens if only 1 peak\n                    if comparison == False:\n                        self.regions *= 5\n                else:\n                    # if none of the peaks have changed by more than comparison_thresh fraction\n                    if all(comparison) == False:\n                        self.regions *= 5\n                        if verbose:\n                            print(\n                                \"peaks haven't changed significantly; regions increased\")\n            elif not len(self.peaks):  # if there wasn't a peak added, try harder\n                self.regions *= 5\n\n        # ---One last round of optimization for luck: can comment these in and out as you see fit.\n#        self.optimize_bg()\n#\n        self.optimize_peaks_and_bg()\n        self.optimize_heights()\n        self.optimize_centre_and_width()\n        self.optimize_peaks()\n        if allow_asymmetry:\n            if verbose:\n                print('asymmetrizing')\n            self.optimize_asymm()",
  "def __init__(self,\n                 spec,\n                 shifts,\n                 lineshape='L',\n                 order=7,\n                 transmission=None,\n                 bg_function='poly',\n                 vary_const_bg=True):\n\n        self.spec = np.array(spec)\n        self.shifts = np.array(shifts)\n        self.order = order\n        self.peaks = []\n\n        self.peak_bounds = []\n\n        self.asymm_peaks = None\n        self.transmission = np.ones(len(spec))\n        if transmission is not None:\n            self.transmission *= transmission\n        if lineshape == 'L':\n            self.line = lambda H, C, W: self.L(self.shifts, H, C, W)\n        if lineshape == 'G':\n            self.line = lambda H, C, W: self.G(self.shifts, H, C, W)\n        self.lineshape = lineshape\n\n        self.bg_type = bg_function\n        if bg_function == 'exponential':\n            self.bg_function = self.exponential\n        if bg_function == 'exponential2':\n            self.bg_function = self.exponential2\n        self.vary_const_bg = vary_const_bg\n        if bg_function == 'exponential' or bg_function == 'exponential2':\n            if vary_const_bg != True:\n                self.bg_bounds = ([0, 0, 0, ], [np.inf, np.inf, 1e-9])\n            else:\n                self.bg_bounds = ([0, 0, 0, ], [np.inf, np.inf, np.inf])",
  "def L(x, H, C, W):  # height centre width\n        \"\"\"\n        Defines a lorentzian\n        \"\"\"\n        return H/(1.+((x-C)/W)**2)",
  "def G(x, H, C, W):\n        '''\n        A Gaussian\n        '''\n        return H*np.exp(-((x-C)/W)**2)",
  "def multi_line(self, parameters):\n        \"\"\"\n        returns a sum of Lorenzians/Gaussians. \n        \"\"\"\n        return np.sum(np.array([self.line(*peak) for peak in parameters]), axis=0)",
  "def exponential(self, A, T, bg):\n        '''\n        uses the transmission for the exponential term, not the constant background.\n        '''\n        omega = -cm_to_omega(self.shifts)\n        return ((A*(np.exp((constants.hbar/constants.k)*omega/T) - 1))**-1)*interp(self.shifts, self.transmission)(self.shifts) + bg",
  "def exponential2(self, A, T, bg):\n        '''\n        uses the a more conplicated exponential \n        '''\n        omega = -cm_to_omega(self.shifts)\n        return A*(((np.exp((constants.hbar/constants.k)*omega/T) - 1)**-1)+(np.exp((constants.hbar/constants.k)*omega/298.) - 1)**-1)*interp(self.shifts, self.transmission)(self.shifts) + bg",
  "def exponential_loss(self, bg_p):\n        '''\n        evaluates fit of exponential to spectrum-signal\n        '''\n        residual = self.bg_function(self.shifts, *bg_p) - self.bg\n        above = residual[residual > 0]\n        below = residual[residual < 0]\n        obj = np.sum(np.absolute(above))+np.sum(np.array(below)**2)\n        return obj",
  "def plot_result(self):\n        '''\n        plots the spectrum and the individual peaks, and their sums\n\n        '''\n        plt.figure()\n        plt.plot(self.shifts, self.spec)\n        plt.plot(self.shifts, self.bg)\n        for peak in self.peaks:\n            plt.plot(self.shifts, self.bg+self.line(*peak)*self.transmission)\n        plt.plot(self.shifts, self.bg + self.multi_line(self.peaks)\n                 * self.transmission, linestyle='--', color='k')",
  "def plot_asymm_result(self):\n        '''\n        plots the spectrum and the individual after aysmmetrization\n        '''\n        plt.figure()\n        plt.plot(self.shifts, self.spec)\n        plt.plot(self.shifts, self.bg)\n        for asymmpeak in self.asymm_peaks:\n\n            plt.plot(self.shifts, self.bg +\n                     self.asymm_line(asymmpeak)*self.transmission)",
  "def add_new_peak(self):\n        '''\n        lifted from Iterative_Raman_Fitting\n        '''\n        # -----Calc. size of x_axis regions-------\n        sectionsize = (np.max(self.shifts)-np.min(self.shifts)) / \\\n            float(self.regions)\n        Start = np.min(self.shifts)\n\n        results = []\n        loss_results = []\n\n        \n        if not len(self.peaks):\n            Current = np.array(self.shifts)*0\n        else:\n            Current = self.multi_line(self.peaks)\n\n   \n\n        def loss(params):\n            # *self.multi_L(self.shifts,*self.peaks))# if this overlaps with another lorentzian it's biased against it\n            return np.sum(np.abs(Current+self.line(*params)-self.signal))\n\n        for i in range(int(self.regions)):\n            bounds = [(0, np.inf), (i*sectionsize+Start, (i+1) *\n                                    sectionsize+Start), (0, max(self.shifts)-min(self.shifts))]\n            Centre = (i+np.random.rand())*sectionsize+Start\n            try:\n                Height = max(truncate(self.signal, self.shifts, i*sectionsize +\n                                      Start, (i+1)*sectionsize+Start)[0])-min(self.signal)\n            except:\n                Height = self.noise_threshold\n            params = [Height, Centre, self.width]\n\n            params = minimize(loss, params, bounds=bounds).x.tolist()\n\n            results.append(params)\n            loss_results.append(loss(params))\n\n        sorted_indices = np.argsort(loss_results)\n\n        self.peak_added = False\n        i = -1\n        # test the top 50% of peaks\n        while self.peak_added == False and i < (len(loss_results) - 1):\n            i += 1\n            peak_candidate = results[sorted_indices[i]]\n            # has a height, minimum width - maximum width are within bounds\n            if peak_candidate[0] > self.noise_threshold and self.maxwidth > peak_candidate[2] > self.minwidth:\n                if len(self.peaks) != 0:\n                    dump, peak, residual = find_closest(\n                        peak_candidate[1], np.transpose(self.peaks)[1])\n                    # is far enough away from existing peaks\n                    if residual > self.min_peak_spacing*self.peaks[peak][2]:\n                        self.peaks.append(peak_candidate)\n                        self.peak_added = True\n\n                else:  # If no existing peaks, accept it\n                    self.peaks.append(peak_candidate)\n                    self.peak_added = True\n            else:\n                # print(peak_candidate[0], self.noise_threshold, self.maxwidth, peak_candidate[2],self.minwidth)\n                pass\n        if self.peak_added:  # TODO store these values\n\n            self.peak_bounds.append(self.bound)  # height, position, width\n            if self.verbose:\n                print('peak added')\n        if not self.peak_added and self.verbose:\n            print('no suitable peaks to add')",
  "def initial_bg_poly(self):\n        '''\n        takes an inital guess at the background.\n        takes the local minima of the smoothed spectrum, weighted by how far they are to other minima, and fits to these.\n        weighting is to prioritise flatter portions of the spectrum (which would naturally have fewer minima)\n\n        '''\n\n        smoothed = sm(self.spec)\n        self.bg_indices = argrelextrema(smoothed, np.less)[0]\n        while len(self.bg_indices) < 3*self.order:\n            self.bg_indices = np.append(self.bg_indices,\n                                        min(np.random.randint(0,\n                                                              high=len(\n                                                                  self.spec),\n                                                              size=(10,)),\n                                            key=lambda i: self.spec[i]))\n        self.bg_vals = smoothed[self.bg_indices]\n\n        residuals = []\n        for index in self.bg_indices:\n            residuals.append(find_closest(\n                index, np.setdiff1d(self.bg_indices, index))[2])\n        norm_fac = 5./max(residuals)\n        extra_lens = norm_fac*np.array(residuals)\n        for bg_index, extra_len in zip(self.bg_indices, extra_lens):\n            extra_len = int(extra_len)\n            if extra_len < 1:\n                extra_len = 1\n            for extra in np.arange(extra_len)+1:\n                try:\n                    self.bg_vals.append(smoothed[bg_index+extra])\n                    self.bg_indices.append(bg_index+extra)\n                except:\n                    pass\n                try:\n                    self.bg_vals.append(smoothed[bg_index-extra])\n                    self.bg_indices.append(bg_index-extra)\n                except:\n                    pass\n        edges = np.arange(5)+1\n        edges = np.append(edges, -edges).tolist()\n        self.bg_indices = np.append(self.bg_indices, edges)\n        self.bg_vals = np.append(self.bg_vals, smoothed[edges])\n\n        if self.bg_type == 'poly':\n            self.bg_bound = (min(self.spec), max(self.spec))\n            self.bg_bounds = []\n            while len(self.bg_bounds) < len(self.bg_vals):\n                self.bg_bounds.append(self.bg_bound)\n            self.bg_p = np.polyfit(\n                self.shifts[self.bg_indices], self.bg_vals, self.order)\n            self.bg = np.polyval(self.bg_p, self.shifts)\n\n        else:\n            if self.vary_const_bg == False:\n                self.bg_p = curve_fit(self.bg_function, self.shifts[self.bg_indices], self.bg_vals, p0=[\n                                      0.5*max(self.spec), 300, 1E-10], maxfev=100000, bounds=self.bg_bounds)[0]\n            else:\n                self.bg_p = curve_fit(self.bg_function, self.shifts[self.bg_indices], self.bg_vals, p0=[\n                                      0.5*max(self.spec), 300, min(self.spec)], maxfev=100000, bounds=self.bg_bounds)[0]\n            self.bg = self.bg_function(self.shifts, *self.bg_p)\n        self.signal = np.array(self.spec - self.bg)/self.transmission",
  "def bg_loss(self, bg_p):\n        '''\n        evaluates the fit of the background to spectrum-peaks\n        '''\n\n        fit = np.polyval(bg_p, self.shifts)\n        residual = self.spec - self.peaks_evaluated - fit\n        above = residual[residual > 0]\n        below = residual[residual < 0]\n        obj = np.sum(np.absolute(above))+10*np.sum(np.array(below))**4\n\n        return obj",
  "def optimize_bg(self):  # takes bg_vals\n        '''\n        it's important to note that the parameter optimised isn't the polynomial coefficients bg_p , \n        but the points taken on the spectrum-peaks curve (bg_vals) at positions bg_indices, decided by initial_bg_poly().\n        This is because it's easy to put the bounds of the minimum and maximum of the spectrum on these to improve optimisation time. (maybe)\n        '''\n        if self.asymm_peaks_stack == None:\n            self.peaks_evaluated = self.multi_line(\n                self.shifts, self.peaks)*self.transmission\n        else:\n            self.peaks_evaluated = self.asymm_multi_line(\n                self.shifts, self.asymm_peaks)*self.transmission\n\n        if self.bg_type == 'poly':\n            self.bg_p = minimize(self.bg_loss, self.bg_p).x.tolist()\n            self.bg = np.polyval(self.bg_p, self.shifts)\n            self.signal = (old_div(np.array(self.spec - self.bg),\n                                   self.transmission)).tolist()\n        elif self.bg_type == 'exponential' or self.bg_type == 'exponential2':\n\n            self.bg_p = curve_fit(self.bg_function,\n                                  self.shifts,\n                                  self.spec -\n                                  self.multi_line(\n                                      self.shifts, self.peaks)*self.transmission,\n                                  p0=self.bg_p,\n                                  bounds=self.bg_bounds,\n                                  maxfev=10000)[0]\n            self.bg = self.bg_function(self.shifts, *self.bg_p)",
  "def peaks_to_matrix(peak_array):\n        '''\n        converts a 1d peak_array into a 2d one\n        '''\n\n        return [peak for peak in reshape(peak_array, 3)]",
  "def peak_loss(self, peaks):\n        '''\n        evalutes difference between the fitted peaks and the signal (spectrum - background)\n        '''\n        fit = self.multi_line(self.peaks_to_matrix(peaks))\n        obj = np.sum(np.square(self.signal - fit))\n        return obj",
  "def optimize_peaks(self):\n        '''\n        optimizes the height, centres and widths of all peaks\n        '''\n        if len(self.peaks) < 2:\n            return\n        bounds = []\n        for bound in self.peak_bounds:\n            bounds.extend(bound)\n        self.peaks = self.peaks_to_matrix(\n            minimize(self.peak_loss, np.ravel(self.peaks), bounds=bounds).x.tolist())",
  "def optimize_centre_and_width(self):\n        '''\n        optimizes the centres(positions) and widths of the peakss for a given heights.\n        '''\n        if len(self.peaks) < 2:\n            return\n        heights = np.transpose(self.peaks)[0]\n        centres_and_widths = np.transpose(self.peaks)[1:]\n        # centres_and_widths = np.ravel(centres_and_widths)\n        width_bound = (self.minwidth, self.maxwidth)\n        centre_and_width_bounds = []\n        for centre, width in zip(*centres_and_widths):\n            centre_and_width_bounds.extend(\n                [(centre-width, centre+width), (width_bound)])  # height, position, width\n\n        def multi_line_centres_and_widths(centres_and_widths):\n            \"\"\"\n            Defines a sum of Lorentzians. Params goes Height1,Centre1, Width1,Height2.....\n            \"\"\"\n            params = [[h, c, w] for h, (c, w) in zip(\n                heights, reshape(centres_and_widths, 2))]\n            return self.multi_line(params)\n\n        def loss_centres_and_widths(centres_and_widths):\n            fit = multi_line_centres_and_widths(centres_and_widths)\n            obj = np.sum(np.square(self.signal - fit))\n            return obj\n        centres_and_widths = minimize(loss_centres_and_widths, np.ravel(\n            centres_and_widths, 'F'), bounds=centre_and_width_bounds).x\n        self.peaks = [[h, c, w] for h, (c, w) in zip(\n            heights, reshape(centres_and_widths, 2))]",
  "def optimize_heights(self):\n        '''\n        crudely gets the maximum of the signal within the peak width as an estimate for the peak height\n        '''\n        if len(self.peaks) < 1:\n            return\n        else:\n\n            for index, peak in enumerate(self.peaks):\n                try:\n                    self.peaks[index][0] = max(\n                        truncate(self.signal, self.shifts, peak[1]-peak[2]/4., peak[1]+peak[2]/4.)[0])\n                except:\n                    self.peaks[index][0] = self.signal[find_closest(\n                        peak[2], self.shifts)[1]]",
  "def loss_function(self):\n        '''\n        evaluates the overall (bg+peaks) fit to the spectrum\n        '''\n\n        fit = self.bg + self.multi_line(self.peaks)*self.transmission\n        obj = np.sum(np.square(self.spec - fit))\n        return obj",
  "def optimize_peaks_and_bg(self):\n        '''\n        optimizes the peaks and background in one procedure, \n        allowing for better interplay of peaks and bg\n        '''\n        if self.bg_type == 'poly':\n            def loss(peaks_and_bg):\n                fit = np.polyval(peaks_and_bg[:self.order+1], self.shifts)\n                fit += self.multi_line(self.peaks_to_matrix(\n                    peaks_and_bg[self.order+1:]))*self.transmission\n                residual = self.spec - fit\n                above = residual[residual > 0]\n                below = residual[residual < 0]\n                # prioritises fitting the background to lower data points\n                obj = np.sum(np.absolute(above))+np.sum(np.array(below)**2)\n                return obj\n            peaks_and_bg = np.append(self.bg_p, np.ravel(self.peaks))\n            bounds = [(-np.inf, np.inf) for p in self.bg_p]\n            if len(self.peaks):\n                for bound in self.peak_bounds:\n                    bounds.extend(bound)\n            peaks_and_bg = minimize(\n                loss, peaks_and_bg, bounds=bounds).x.tolist()\n\n            self.bg_p = peaks_and_bg[:self.order+1]\n            self.peaks = self.peaks_to_matrix(peaks_and_bg[self.order+1:])\n            self.bg = np.polyval(self.bg_p, self.shifts)\n        else:\n            def loss(peaks_and_bg):\n                fit = self.bg_function(peaks_and_bg[:3])\n                fit += self.multi_line(peaks_and_bg[3:])*self.transmission\n                residual = self.spec - fit\n                above = residual[residual > 0]\n                below = residual[residual < 0]\n                # prioritises fitting the background to lower data points\n                obj = np.sum(np.absolute(above))+np.sum(np.array(below)**2)\n                return obj\n            peaks_and_bg = np.append(self.bg_p, self.peaks)\n            if self.vary_const_bg == False:\n                bounds = [(0, max(self.spec)*10),\n                          (100, 1000),\n                          (min(self.spec*0.7), 1e-9)]\n            else:\n                bounds = [(0, max(self.spec)*10),\n                          (100, 1000),\n                          (min(self.spec*0.7), max(self.spec))]\n\n            bounds.extend(self.peak_bounds)\n            peaks_and_bg = minimize(loss, peaks_and_bg, bounds=bounds).x\n            self.bg_p = peaks_and_bg[:3]\n            self.peaks = self.peaks_to_matrix(peaks_and_bg[3:])\n            self.bg = self.bg_function(self.shifts, *self.bg_p)",
  "def optimize_asymm(self):\n        '''\n        allows the peaks to become asymmetric by raising either side of the peaks to separate exponents (alpha and beta) \n        '''\n        width_alpha_beta = []\n        asymmbounds = []\n        if self.asymm_peaks is None:\n            self.asymm_peaks_stack = []\n\n            for peak in self.peaks:\n                # initial alpha, beta\n                width_alpha_beta.extend([peak[2], 1., 1.])\n                asymmbounds.extend([(peak[2]/5., peak[2]*5),\n                                    (0.8, 1.2),\n                                    (0.8, 1.2)])\n            asymmbounds = np.array(asymmbounds)\n        else:\n\n            for asymm_peak in self.asymm_peaks:\n                width_alpha_beta.extend([asymm_peak[2],\n                                         asymm_peak[3],\n                                         asymm_peak[4]])\n                asymmbounds.extend([(old_div(asymm_peak[2], 5), asymm_peak[2]*5),\n                                    (0.9, 1.1),\n                                    (0.9, 1.1)])\n\n        def asymmloss(width_alpha_beta):\n            width_alpha_beta_stack = self.peaks_to_matrix(width_alpha_beta)\n            params = []\n            for peak, width_alpha_beta in zip(self.peaks, width_alpha_beta_stack):\n                params.append([*peak[0:2], *width_alpha_beta])\n            fit = self.asymm_multi_line(params)\n            obj = np.sum(np.square(self.signal - fit))\n            return obj\n\n        width_alpha_beta = minimize(\n            asymmloss, width_alpha_beta, bounds=asymmbounds).x.tolist()\n        wab_stack = self.peaks_to_matrix(width_alpha_beta)\n        self.asymm_peaks = [[*peak[0:2], *width_alpha_beta]\n                            for peak, width_alpha_beta in zip(self.peaks, wab_stack)]",
  "def asymm_line(self, asymmpeak):\n        '''\n        defines an asymmetric lineshape - depends on whether initial lineshape is L or G\n        '''\n\n        alpha = np.true_divide(self.line(\n            asymmpeak[0], asymmpeak[1], asymmpeak[2]), asymmpeak[0])**asymmpeak[3]\n        alpha = truncate(alpha, self.shifts, -np.inf, asymmpeak[1])[0]\n\n        alpha *= asymmpeak[0]\n        beta = np.true_divide(self.line(\n            asymmpeak[0], asymmpeak[1], asymmpeak[2]), asymmpeak[0])**asymmpeak[4]\n        beta = truncate(beta, self.shifts, asymmpeak[1], np.inf)[0]\n        beta *= asymmpeak[0]\n        return np.append(alpha, beta)",
  "def asymm_multi_line(self, params):  # params is 2d\n        '''\n        outputs sum of many asymmetric peaks\n        '''\n\n        return np.sum([self.asymm_line(asymmpeak) for asymmpeak in params], axis=0)",
  "def dummy_run(self,\n                 initial_fit=None,\n                 add_peaks=True,\n                 allow_asymmetry=False,\n                 minwidth=8,\n                 maxwidth=30,\n                 regions=20, noise_factor=2,\n                 min_peak_spacing=5,\n                 comparison_thresh=0.05,\n                 verbose=False):\n        '''\n        handy to test other scripts quickly\n        '''\n\n        self.initial_bg_poly()\n        self.minwidth = minwidth\n        self.maxwidth = maxwidth\n#        if initial_fit is not None:\n#            self.peaks = initial_fit\n#            self.peaks_stack = np.reshape(self.peaks, [len(self.peaks)/3, 3])\n#            self.optimize_heights\n#            #self.optimize_centre_and_width()\n\n        smoothed = sm(self.spec)\n        maxima = argrelextrema(smoothed, np.greater)[0]\n        heights = smoothed[maxima]\n        maxima = maxima[np.argsort(heights)[-5:]]\n        heights = smoothed[maxima]\n\n        centres = self.shifts[maxima]\n        widths = np.ones(len(maxima))*PEAKWIDTH\n\n        self.peaks = np.transpose(np.stack([heights, centres, widths]))\n\n        self.optimize_heights\n        self.optimize_centre_and_width()\n        print(\"I'm a dummy!\")",
  "def run(self, *args, **kwargs):\n        if DUMMY:\n            self.dummy_run(*args, **kwargs)\n        else:\n            self._run(*args, **kwargs)",
  "def _run(self,\n             initial_fit=None,\n             add_peaks=True,\n             allow_asymmetry=False,\n             minwidth=2.5,\n             maxwidth=20,\n             regions=10,\n             noise_factor=0.1,\n             min_peak_spacing=3.1,\n             comparison_thresh=0.01,\n             verbose=False):\n        '''\n        described at the top\n        '''\n        if self.lineshape == 'L':\n            self.maxwidth = maxwidth/2.\n            self.minwidth = minwidth/2.\n        if self.lineshape == 'G':\n            self.maxwidth = maxwidth/0.95\n            self.minwidth = minwidth/0.95\n        self.verbose = verbose\n        self.min_peak_spacing = min_peak_spacing\n        self.width = PEAKWIDTH  # a guess for the peak width\n        \n        noise = np.sqrt(np.var(self.spec/gaussian_filter(self.spec, 40))).mean()\n\n        self.noise_threshold = noise_factor*noise\n\n        # number of regions the spectrum will be split into to add a new peak\n        self.regions = regions\n        if self.regions > len(self.spec):\n            # can't be have more regions than points in spectrum\n            self.regions = len(self.spec)//2\n\n        self.initial_bg_poly()  # takes a guess at the background\n        if self.noise_threshold>np.max(self.signal):\n            self.noise_threshold=np.min(self.signal)\n        height_bound = (self.noise_threshold, np.max(self.signal))\n        \n        pos_bound = (np.min(self.shifts), np.max(self.shifts))\n        width_bound = (self.minwidth, self.maxwidth)\n\n        self.bound = [height_bound, pos_bound, width_bound]\n\n        if initial_fit is not None:\n            self.peaks = initial_fit\n            if add_peaks == False:\n                # if regions is bigger than the spectrum length, then no peaks are added\n                self.regions = len(self.spec)+1\n            self.peaks_stack = self.peaks_to_matrix(\n                self.peaks)  # 2d array of peak parameters\n            # bounds for the peak parameters\n            height_bound = (self.noise_threshold, max(self.signal))\n            pos_bound = (np.min(self.shifts), np.max(self.shifts))\n            width_bound = (self.minwidth, self.maxwidth)\n            self.peak_bounds = [self.bound for _ in self.peaks]\n            # creates a bound for each peak\n            self.optimize_heights()  # see functions for descriptions\n            self.optimize_centre_and_width()\n\n            self.optimize_peaks()\n        while self.regions <= len(self.spec):\n            if verbose == True:\n                print('Region fraction: ', np.around(\n                    self.regions/float(len(self.spec)), decimals=2))\n            existing_loss_score = self.loss_function()  # measure of fit 'goodness'\n            Old = self.peaks  # peaks before new one added\n            self.add_new_peak()  # adds a peak\n            if verbose == True:\n                print('# of peaks:', len(self.peaks))\n#            self.optimize_heights\n#            self.optimize_centre_and_width()\n            self.optimize_peaks_and_bg()  # optimizes\n            new_loss_score = self.loss_function()\n\n            # ---Check to increase regions\n            if new_loss_score >= existing_loss_score:  # if fit has worsened, delete last peak\n                if self.peak_added:\n                    self.peaks = self.peaks[:-1]\n                    self.peak_bounds = self.peak_bounds[:-1]\n                    if verbose:\n                        print('peak removed as it made the fit worse')\n                self.regions *= 4  # increase regions, as this is a sign fit is nearly finished\n\n            elif not self.peak_added:  # Otherwise, same number of peaks?\n                #                self.optimize_bg()\n                #                self.optimize_heights() # fails if no peaks\n                #                self.optimize_centre_and_width()\n                #                self.optimize_peaks()\n                self.optimize_peaks_and_bg()\n                New = self.peaks\n                New_trnsp = np.transpose(New)\n                residual = []\n                for old_peak in Old:\n                    # returns index of the new peak which matches it\n                    new_peak = find_closest(old_peak[1], New_trnsp[1])[1]\n                    old_height = old_peak[0]\n                    old_pos = old_peak[1]/self.width\n                    new_height = New[new_peak][0]/old_height\n                    # normalise the height and position parameters to add them into one comparison score\n                    new_pos = New[new_peak][1]/self.width\n                    # the difference between old and new for each peak\n                    residual.append(np.linalg.norm(\n                        np.array([1, old_pos])-np.array([new_height, new_pos])))\n                comparison = np.array(residual) > comparison_thresh\n                if type(comparison) == bool:  # happens if only 1 peak\n                    if comparison == False:\n                        self.regions *= 5\n                else:\n                    # if none of the peaks have changed by more than comparison_thresh fraction\n                    if all(comparison) == False:\n                        self.regions *= 5\n                        if verbose:\n                            print(\n                                \"peaks haven't changed significantly; regions increased\")\n            elif not len(self.peaks):  # if there wasn't a peak added, try harder\n                self.regions *= 5\n\n        # ---One last round of optimization for luck: can comment these in and out as you see fit.\n#        self.optimize_bg()\n#\n        self.optimize_peaks_and_bg()\n        self.optimize_heights()\n        self.optimize_centre_and_width()\n        self.optimize_peaks()\n        if allow_asymmetry:\n            if verbose:\n                print('asymmetrizing')\n            self.optimize_asymm()",
  "def loss(params):\n            # *self.multi_L(self.shifts,*self.peaks))# if this overlaps with another lorentzian it's biased against it\n            return np.sum(np.abs(Current+self.line(*params)-self.signal))",
  "def multi_line_centres_and_widths(centres_and_widths):\n            \"\"\"\n            Defines a sum of Lorentzians. Params goes Height1,Centre1, Width1,Height2.....\n            \"\"\"\n            params = [[h, c, w] for h, (c, w) in zip(\n                heights, reshape(centres_and_widths, 2))]\n            return self.multi_line(params)",
  "def loss_centres_and_widths(centres_and_widths):\n            fit = multi_line_centres_and_widths(centres_and_widths)\n            obj = np.sum(np.square(self.signal - fit))\n            return obj",
  "def asymmloss(width_alpha_beta):\n            width_alpha_beta_stack = self.peaks_to_matrix(width_alpha_beta)\n            params = []\n            for peak, width_alpha_beta in zip(self.peaks, width_alpha_beta_stack):\n                params.append([*peak[0:2], *width_alpha_beta])\n            fit = self.asymm_multi_line(params)\n            obj = np.sum(np.square(self.signal - fit))\n            return obj",
  "def loss(peaks_and_bg):\n                fit = np.polyval(peaks_and_bg[:self.order+1], self.shifts)\n                fit += self.multi_line(self.peaks_to_matrix(\n                    peaks_and_bg[self.order+1:]))*self.transmission\n                residual = self.spec - fit\n                above = residual[residual > 0]\n                below = residual[residual < 0]\n                # prioritises fitting the background to lower data points\n                obj = np.sum(np.absolute(above))+np.sum(np.array(below)**2)\n                return obj",
  "def loss(peaks_and_bg):\n                fit = self.bg_function(peaks_and_bg[:3])\n                fit += self.multi_line(peaks_and_bg[3:])*self.transmission\n                residual = self.spec - fit\n                above = residual[residual > 0]\n                below = residual[residual < 0]\n                # prioritises fitting the background to lower data points\n                obj = np.sum(np.absolute(above))+np.sum(np.array(below)**2)\n                return obj",
  "def Select_Time_Range(Min,Max):\n\t\"\"\"\n\tAsks the user for lower and upper spectrum numbers. Min and Max define the allowed range for these values.\n\t\"\"\"\n\n\tContinue=False\n\n\twhile Continue is False:\n\n\t\tLower=None\n\t\twhile Lower is None:\n\t\t\tInput=eval(input('Please Enter a Lower Spectrum Number (Type \\'Cancel\\' to cancel): '))\n\t\t\tif str(Input).upper()=='CANCEL':\n\t\t\t\treturn None,None\n\t\t\telse:\n\t\t\t\ttry:\n\t\t\t\t\tInput=int(Input)\n\t\t\t\t\tif Input<Min or Input>Max:\n\t\t\t\t\t\tprint('Invalid')\n\t\t\t\t\telse:\n\t\t\t\t\t\tLower=Input\n\t\t\t\texcept ValueError:\n\t\t\t\t\tprint('Invalid')\n\n\t\tUpper=None\n\t\twhile Upper is None:\n\t\t\tInput=eval(input('Please Enter a Upper Spectrum Number (Type \\'Cancel\\' to cancel): '))\n\t\t\tif str(Input).upper()=='CANCEL':\n\t\t\t\treturn None,None\n\t\t\telse:\n\t\t\t\ttry:\n\t\t\t\t\tInput=int(Input)\n\t\t\t\t\tif Input<Min or Input>Max or Input<=Lower:\n\t\t\t\t\t\tprint('Invalid')\n\t\t\t\t\telse:\n\t\t\t\t\t\tUpper=Input\n\t\t\t\texcept ValueError:\n\t\t\t\t\tprint('Invalid')\n\n\t\tInput=eval(input('Continue with range '+str(Lower)+' to '+str(Upper)+'? (Y/N): '))\n\t\tif str(Input).upper()=='Y':\n\t\t\tContinue=True\n\n\treturn Lower,Upper",
  "def Select_Peaks(Array,Threshold,Color='r',Extra_Lines=None,colormap='inferno'):\n\t\"\"\"\n\tAllows the select vertical lines on the array, and returns their x-axis positions.\n\tArray is an array. Threshold thresholds the colormap. Color is color of lines to draw. Extra lines goes \n\tas [[List of Lines,Color],[List of Lines,Color] etc] and ditactes extra lines to be drawn on the image.\n\t\"\"\"\n\n\tPeaks=[]\n\tEnd=[False]\n\tDraw=[True]\n\n\tpl.ion()\n\tfig=pl.figure()\n\n\tif Threshold is None:\n\t\tThreshold=np.max(Array)\n\tStep=0.1*(Threshold-np.min(Array))\n\tThreshold=[Threshold,np.min(Array)]\n\n\tdef Mouse_Press(event):\n\t\tif event.button==1:\n\t\t\tPeaks.append(event.xdata)\n\t\tif event.button==3 and len(Peaks)>0:\n\t\t\tPeaks.remove(Peaks[-1])\n\t\tDraw[0]=True\n\n\tdef Button_Press(event):\n\t\tif event.key=='enter':\n\t\t\tEnd[0]=True\n\n\tdef Scroll(event):\n\t\tif event.button=='up':\n\t\t\tThreshold[0]+=Step\n\t\tif event.button=='down':\n\t\t\tThreshold[0]-=Step\n\t\t\tif Threshold[0]<=Threshold[1]:\n\t\t\t\tThreshold[0]+=Step\n\t\tDraw[0]=True\n\n\tfig.canvas.mpl_connect('key_press_event', Button_Press)\n\tfig.canvas.mpl_connect('button_press_event', Mouse_Press)\n\tfig.canvas.mpl_connect('scroll_event', Scroll)\n\n\n\twhile End[0] is False:\n\t\tpl.pause(0.05)\n\t\tif Draw[0] is True:\n\t\t\tDraw[0]=False\n\t\t\tpl.clf()\n\t\t\tpl.imshow(Array,interpolation='None',origin='lower',cmap=colormap,aspect=float(len(Array[0]))/len(Array),vmax=Threshold[0])\n\t\t\tpl.xlabel('Array Element')\n\t\t\tpl.ylabel('Spectrum')\n\t\t\tfor i in Peaks:\n\t\t\t\tpl.plot([i,i],[0,len(Array)-1],Color+'--')\n\t\t\tif Extra_Lines is not None:\n\t\t\t\tfor i in Extra_Lines[0]:\n\t\t\t\t\tpl.plot([i,i],[0,len(Array)-1],Extra_Lines[1]+'--')\n\t\t\tpl.xlim([0,len(Array[0])])\n\t\t\tpl.ylim([0,len(Array)])\n\tpl.ioff()\n\tpl.close()\n\n\treturn Peaks",
  "def Input_Width():\n\tOutput=None\n\twhile Output is None:\n\t\tInput=eval(input('Please Enter an Approximate Peak Width in Given X-Axis Units (Type \\'Cancel\\' to cancel): '))\n\t\tif str(Input).upper()=='CANCEL':\n\t\t\t\treturn None\n\t\telse:\n\t\t\ttry:\n\t\t\t\tInput=int(Input)\n\t\t\t\tif Input<=0:\n\t\t\t\t\tprint('Invalid')\n\t\t\t\telse:\n\t\t\t\t\tOutput=Input\n\t\t\texcept ValueError:\n\t\t\t\tprint('Invalid')\n\treturn Output",
  "def Input_Core_Number():\n\t\"\"\"\n\tAsks the user for a number of cores to use\n\t\"\"\"\n\tMaximum=mp.cpu_count()\n\tOutput=None\n\twhile Output is None:\n\t\tInput=eval(input('Please Enter the Number of CPU Cores to Utilise: '))\n\t\ttry:\n\t\t\tInput=int(Input)\n\t\t\tif Input<=0:\n\t\t\t\tprint('Invalid: Negative/Zero')\n\t\t\telse:\n\t\t\t\tif Input>Maximum:\n\t\t\t\t\tprint('Invalid: This number of CPU cores is not available')\n\t\t\t\telse:\n\t\t\t\t\tOutput=Input\n\t\texcept ValueError:\n\t\t\tprint('Invalid')\n\treturn Output",
  "def Quick_Sort(List,Argument):\n\t#Sorts a List based on the numberimal value of the Argument element.\n\tdef Split(List,Argument):\n\t\t#List is list of lists to seperate\n\t\t#Argument is lsit argument to seperate via\n\n\t\tOutput=[[],[]]\n\n\t\tPivot=[]\n\t\tfor i in List:\n\t\t\tPivot.append(i[Argument])\n\t\tif len(Pivot)==2:\n\t\t\tPivot=max(Pivot)\n\t\telse:\n\t\t\tPivot=np.random.choice(Pivot)\n\n\t\tfor i in List:\n\t\t\tif i[Argument]<Pivot:\n\t\t\t\tOutput[0].append(i)\n\t\t\telse:\n\t\t\t\tOutput[1].append(i)\n\t\treturn Output\n\n\tdef Same(List,Argument):\n\t\tfor i in List:\n\t\t\tif i[Argument]!=List[0][Argument]:\n\t\t\t\treturn False\n\t\treturn True\n\n\tSorted=[]\n\tTo_Sort=[List]\n\twhile len(To_Sort)>0:\n\t\tSorting=To_Sort[0]\n\t\tTo_Sort=To_Sort[1:]\n\t\tif Same(Sorting,Argument) is True:\n\t\t\tSorted+=Sorting\n\t\telse:\n\t\t\tTo_Sort=Split(Sorting,Argument)+To_Sort\n\treturn Sorted",
  "def Lorentzian(x,Centre,Width,Height):\n\t\"\"\"\n\tDefines a Lorentzian\n\t\"\"\"\n\treturn old_div(Height,(1+((old_div((x-Centre),Width))**2)))",
  "def Constant_plus_Lorentzians(x,*Params):\n\t\"\"\"\n\tDefines a constant plus an arbitary sum of Lorentzians\n\t\"\"\"\n\tOutput=Params[0]\n\tn=1\n\twhile n<len(Params):\n\t\tOutput+=Lorentzian(x,*Params[n:n+3])\n\t\tn+=3\n\treturn Output",
  "def Fitting_Worker(Function,x,y,Initial,Bounds,Label):\n\t\"\"\"\n\tWorker to complete the fitting. Function is function to fit. x and y is the data. Initial is a guess for the fitting parameters.\n\tBounds are the bounds for the fitting. Label is a number labelling which spectrum is being fit here. Returns [Parameters, Errors] which can \n\tall be None if the fitting fails.\n\t\"\"\"\n\ttry:\n\t\tOutput=spo.curve_fit(Function,x,y,Initial,bounds=Bounds)\n\t\tOutput=[Output[0],np.sqrt(np.diag(Output[1])),Label]\n\texcept RuntimeError:\n\t\tOutput=[]\n\t\twhile len(Output)<len(Initial):\n\t\t\tOutput.append(None)\n\t\tOutput=[Output,Output,Label]\n\treturn Output",
  "def Run_Fitting(Array,x_axis,Center_Guesses,Width_Guess,Cores):\n\t\"\"\"\n\tTakes an array, the x_axis list, guesses for the peak positions (Center_Guesses) and a peak width (Width_Guess) and completes the fitting using Cores cores.\n\t\"\"\"\n\n\tBounds_Lower=[-np.inf]\n\tBounds_Upper=[np.inf]\n\tfor i in range(len(Center_Guesses)):\n\t\tBounds_Lower+=[x_axis[0],0,0]\n\t\tBounds_Upper+=[x_axis[-1],np.inf,np.inf]\n\n\tProcesses=[]\n\tPool=mp.Pool(processes=Cores)\n\n\tfor i in range(len(Array)):\n\n\t\tHeights=[]\n\n\t\tfor j in Center_Guesses:\n\t\t\tLower_x=j-(0.5*Width_Guess)\n\t\t\tUpper_x=j+(0.5*Width_Guess)\n\t\t\tLower_element=0\n\t\t\twhile x_axis[Lower_element]<Lower_x:\n\t\t\t\tLower_element+=1\n\t\t\tUpper_element=Lower_element\n\t\t\twhile x_axis[Upper_element]<Upper_x:\n\t\t\t\tUpper_element+=1\n\t\t\tHeights.append(np.max(Array[i][Lower_element:Upper_element])-np.min(Array[i][Lower_element:Upper_element]))\n\n\t\tInitial=[0.]\n\t\tfor j in range(len(Center_Guesses)):\n\t\t\tInitial+=[Center_Guesses[j],Width_Guess,Heights[j]]\n\n\t\tProcesses.append(Pool.apply_async(Fitting_Worker,args=(Constant_plus_Lorentzians,x_axis,Array[i],Initial,(Bounds_Lower,Bounds_Upper),i)))\n\n\tResults=[p.get() for p in Processes]\n\n\tPool.close()\n\n\tResults=Quick_Sort(Results,2)\n\n\tfor i in range(len(Results)):\n\t\tResults[i]=Results[i][:-1]\n\n\treturn Results",
  "def Convert_to_x_value(Element,x_axis):\n\t\"\"\"\n\tConverts a postions in terms of an Element value in the array into its approx value along the x_axis.\n\t\"\"\"\n\tx0=x_axis[int(Element)]\n\tx1=x_axis[int(Element)+1]\n\tWeight=Element%1\n\treturn (Weight*(x1-x0))+x0",
  "def Run(Array,x_axis,Threshold=None,colormap='inferno'):\n\t\"\"\"\n\tRuns the fitting, including the UI. Array is the array to fit. x_axis is the corresponding x axis values. Threshold \n\tis a value to threshold the images of the array.\n\t\"\"\"\n\n\t#---------Select time range---------------\n\tLower,Upper=Select_Time_Range(0,len(Array)-1)\n\tif Lower is None:\n\t\treturn\n\t\n\tTo_Fit=Array[Lower:Upper+1]\n\n\t#----------Select Peaks-------------\n\n\tprint('==========')\n\tprint(\"Please use your left mouse button to select peaks to track. Use your right mouse button to erase the last selection. Press Enter when done.\")\n\tprint('==========')\n\n\tPeaks=Select_Peaks(To_Fit,Threshold,colormap=colormap)\n\tPeaks=sorted(Peaks)\n\n\t#-------------Select Interpeak Bounds\n\n\tprint('==========')\n\tprint(\"Fitting will be faster and less likely to fail if each spectrum is split into sections.\")\n\tprint(\"Please use your left mouse button to select section boundaries. Use your right mouse button to erase the last selection. Press Enter when done.\")\n\tprint('==========')\n\n\tBounds=Select_Peaks(To_Fit,Threshold,'w',[Peaks,'r'],colormap=colormap)\n\tBounds=sorted(Bounds)\n\tBounds=[0]+Bounds+[len(To_Fit[0])]\n\n\t#--------Select Peak Width------\n\n\tWidth=Input_Width()\n\tif Width is None:\n\t\treturn\n\n\t#------Select Cores to Run-------\n\n\tCores=Input_Core_Number()\n\n\t#----Define array sections to fit-----\n\n\tSections=[]\n\tn=1\n\twhile n<len(Bounds):\n\t\tIn_Bounds=[]\n\t\tfor i in Peaks:\n\t\t\tif i>Bounds[n-1] and i<Bounds[n]:\n\t\t\t\tIn_Bounds.append(i)\n\t\tif len(In_Bounds)>0:\n\t\t\tSections.append([Bounds[n-1],Bounds[n],In_Bounds])\n\t\tn+=1\n\n\t#-----Convert Peak Guesses to Correct units------\n\n\tfor i in range(len(Sections)):\n\t\tfor j in range(len(Sections[i][2])):\n\t\t\tSections[i][2][j]=Convert_to_x_value(Sections[i][2][j],x_axis)\n\n\t#----Hold------\n\n\t#Hold=eval((input('Press Enter to Begin'))) #removed as I found an error I don't know how to fix, but code works fine - Demelza\n\n\t#---------Fit Array Sections----------------\n\n\tResults=[]\n\n\tfor i in Sections:\n\t\tprint('Fitting.....')\n\t\tResults.append(Run_Fitting(np.transpose(np.transpose(To_Fit)[int(i[0]):int(i[1])]),x_axis[int(i[0]):int(i[1])],i[2],Width,Cores))\n\n\tOutput=[]\n\tfor i in range(len(To_Fit)):\n\t\tOutput.append([[],[]])\n\t\tfor j in Results:\n\t\t\tif isinstance(j[i][0],list) is True:\n\t\t\t\tOutput[-1][0]+=j[i][0][1:]\n\t\t\telse:\n\t\t\t\tOutput[-1][0]+=j[i][0][1:].tolist()\n\t\t\tif isinstance(j[i][1],list) is True:\n\t\t\t\tOutput[-1][1]+=j[i][1][1:]\n\t\t\telse:\n\t\t\t\tOutput[-1][1]+=j[i][1][1:].tolist()\n\treturn Output",
  "def View_Results(Array,x_axis,Start_Spectrum,End_Spectrum,Fit,Threshold=None):\n\tTo_Show=Array[Start_Spectrum:End_Spectrum]\n\tpl.imshow(To_Show,interpolation='None',origin='lower',cmap='inferno',aspect=float(len(To_Show[0]))/len(To_Show),vmax=Threshold)\n\n\tPeaks=[]\n\tfor i in Fit:\n\t\tPeak=[]\n\t\tn=0\n\t\twhile n<len(i[0]):\n\t\t\tPeak.append(i[0][n])\n\t\t\tn+=3\n\t\tPeaks.append(Peak)\n\tPeaks=np.array(Peaks)\n\tPeaks=np.transpose(Peaks)\n\n\tfor i in Peaks:\n\t\tTo_Plot=[]\n\t\tfor j in i:\n\t\t\tif j is not None:\n\t\t\t\tn=0\n\t\t\t\twhile x_axis[n]<j:\n\t\t\t\t\tn+=1\n\t\t\t\tWeight=old_div((j-x_axis[n-1]),(x_axis[n]-x_axis[n-1]))\n\t\t\t\tTo_Plot.append(n-1.+Weight)\n\t\t\telse:\n\t\t\t\tTo_Plot.append(None)\n\t\tpl.plot(To_Plot,list(range(len(To_Show))),'b-')\n\tpl.xlim([0,len(To_Show[0])])\n\tpl.ylim([0,len(To_Show)])\n\t\n\tpl.show()",
  "def View_Results_Video(Array,x_axis,Start_Spectrum,End_Spectrum,Fit,Frame_Time=0.1):\n\tTo_Show=Array[Start_Spectrum:End_Spectrum]\n\t\n\tPeaks=[]\n\tfor i in Fit:\n\t\tPeak=[]\n\t\tn=0\n\t\twhile n<len(i[0]):\n\t\t\tPeak.append(i[0][n])\n\t\t\tn+=3\n\t\tPeaks.append(Peak)\n\tPeaks=np.array(Peaks)\n\tPeaks=np.transpose(Peaks)\n\n\tfor i in range(len(To_Show)):\n\t\tpl.plot(x_axis,To_Show[i],'k-')\n\t\tfor j in Peaks[i]:\n\t\t\tif j is not None:\n\t\t\t\tpl.plot([j,j],[0,np.max(To_Show[i])],'r-')\n\t\tpl.show()\n\t\tpl.pause(Frame_Time)\n\t\tpl.clf()\n\tpl.close()",
  "def Reorder_Peaks(Fits):\n\t\"\"\"\n\tFunction to reorder the fits to minimise the crosstalk between adjacent peaks.\n\t\"\"\"\n\tStart=0\n\twhile Start<len(Fits) and None in Fits[Start][0]:\n\t\tStart+=1\n\tif Start==len(Fits):\n\t\tprint('No fully sucessfull fits detected!')\n\t\treturn\n\telse:\n\t\tResults=[Fits[Start]]\n\t\tCurrent=[]\n\t\tfor i in range(old_div(len(Fits[Start][0]),3)):\n\t\t\tCurrent.append(Fits[Start][0][i*3])\n\t\tTo_Sort=Start+1\n\t\twhile To_Sort<len(Fits):\n\t\t\tprint(To_Sort)\n\t\t\tSorting_Positions=[]\n\t\t\tfor i in range(old_div(len(Fits[To_Sort][0]),3)):\n\t\t\t\tSorting_Positions.append(Fits[To_Sort][0][i*3])\n\t\t\tSorting_Order=list(range(len(Sorting_Positions)))\n\t\t\tTrigger=True\n\t\t\twhile Trigger is True:\n\t\t\t\tTrigger=False\n\t\t\t\tPos1=0\n\t\t\t\twhile Pos1<len(Sorting_Order):\n\t\t\t\t\tPos2=Pos1+1\n\t\t\t\t\twhile Pos2<len(Sorting_Order):\n\t\t\t\t\t\tChange=0\n\t\t\t\t\t\tif Sorting_Positions[Sorting_Order[Pos1]] is not None:\n\t\t\t\t\t\t\tChange+=abs(Current[Pos1]-Sorting_Positions[Sorting_Order[Pos1]])-abs(Current[Pos2]-Sorting_Positions[Sorting_Order[Pos1]])\n\t\t\t\t\t\tif Sorting_Positions[Sorting_Order[Pos2]] is not None:\n\t\t\t\t\t\t\tChange+=abs(Current[Pos2]-Sorting_Positions[Sorting_Order[Pos2]])-abs(Current[Pos1]-Sorting_Positions[Sorting_Order[Pos2]])\n\t\t\t\t\n\t\t\t\t\t\tif Change>0:\n\t\t\t\t\t\t\tTemp=Sorting_Order[Pos1]\n\t\t\t\t\t\t\tSorting_Order[Pos1]=Sorting_Order[Pos2]\n\t\t\t\t\t\t\tSorting_Order[Pos2]=Temp\n\t\t\t\t\t\t\tTrigger=True\n\t\t\t\t\t\tPos2+=1\n\t\t\t\t\tPos1+=1\n\t\t\tResult=[[],[]]\n\t\t\tfor i in Sorting_Order:\n\t\t\t\tResult[0]+=Fits[To_Sort][0][i*3:(i+1)*3]\n\t\t\t\tResult[1]+=Fits[To_Sort][1][i*3:(i+1)*3]\n\t\t\tResults.append(Result)\n\t\t\tCurrent_new=[]\n\t\t\tfor i in range(old_div(len(Result[0]),3)):\n\t\t\t\tif Result[0][i*3] is not None:\n\t\t\t\t\tCurrent_new.append(Result[0][i*3])\n\t\t\t\telse:\n\t\t\t\t\tCurrent_new.append(Current[i])\n\t\t\tCurrent=Current_new\n\t\t\tTo_Sort+=1\n\n\t\tCurrent=[]\n\t\tfor i in range(old_div(len(Fits[Start][0]),3)):\n\t\t\tCurrent.append(Fits[Start][0][i*3])\n\t\tTo_Sort=Start-1\n\t\twhile To_Sort>=0:\n\t\t\tprint(To_Sort)\n\t\t\tSorting_Positions=[]\n\t\t\tfor i in range(old_div(len(Fits[To_Sort][0]),3)):\n\t\t\t\tSorting_Positions.append(Fits[To_Sort][0][i*3])\n\t\t\tSorting_Order=list(range(len(Sorting_Positions)))\n\t\t\tTrigger=True\n\t\t\twhile Trigger is True:\n\t\t\t\tTrigger=False\n\t\t\t\tPos1=0\n\t\t\t\twhile Pos1<len(Sorting_Order):\n\t\t\t\t\tPos2=Pos1+1\n\t\t\t\t\twhile Pos2<len(Sorting_Order):\n\t\t\t\t\t\tChange=0\n\t\t\t\t\t\tif Sorting_Positions[Sorting_Order[Pos1]] is not None:\n\t\t\t\t\t\t\tChange+=abs(Current[Pos1]-Sorting_Positions[Sorting_Order[Pos1]])-abs(Current[Pos2]-Sorting_Positions[Sorting_Order[Pos1]])\n\t\t\t\t\t\tif Sorting_Positions[Sorting_Order[Pos2]] is not None:\n\t\t\t\t\t\t\tChange+=abs(Current[Pos2]-Sorting_Positions[Sorting_Order[Pos2]])-abs(Current[Pos1]-Sorting_Positions[Sorting_Order[Pos2]])\n\t\t\t\t\t\t\n\t\t\t\t\t\tif Change>0:\n\t\t\t\t\t\t\tTemp=Sorting_Order[Pos1]\n\t\t\t\t\t\t\tSorting_Order[Pos1]=Sorting_Order[Pos2]\n\t\t\t\t\t\t\tSorting_Order[Pos2]=Temp\n\t\t\t\t\t\t\tTrigger=True\n\t\t\t\t\t\tPos2+=1\n\t\t\t\t\tPos1+=1\n\t\t\tResult=[[],[]]\n\t\t\tfor i in Sorting_Order:\n\t\t\t\tResult[0]+=Fits[To_Sort][0][i*3:(i+1)*3]\n\t\t\t\tResult[1]+=Fits[To_Sort][1][i*3:(i+1)*3]\n\t\t\tResults=[Result]+Results\n\t\t\tCurrent_new=[]\n\t\t\tfor i in range(old_div(len(Result[0]),3)):\n\t\t\t\tif Result[0][i*3] is not None:\n\t\t\t\t\tCurrent_new.append(Result[0][i*3])\n\t\t\t\telse:\n\t\t\t\t\tCurrent_new.append(Current[i])\n\t\t\tCurrent=Current_new\n\t\t\tTo_Sort-=1\n\n\treturn Results",
  "def Mouse_Press(event):\n\t\tif event.button==1:\n\t\t\tPeaks.append(event.xdata)\n\t\tif event.button==3 and len(Peaks)>0:\n\t\t\tPeaks.remove(Peaks[-1])\n\t\tDraw[0]=True",
  "def Button_Press(event):\n\t\tif event.key=='enter':\n\t\t\tEnd[0]=True",
  "def Scroll(event):\n\t\tif event.button=='up':\n\t\t\tThreshold[0]+=Step\n\t\tif event.button=='down':\n\t\t\tThreshold[0]-=Step\n\t\t\tif Threshold[0]<=Threshold[1]:\n\t\t\t\tThreshold[0]+=Step\n\t\tDraw[0]=True",
  "def Split(List,Argument):\n\t\t#List is list of lists to seperate\n\t\t#Argument is lsit argument to seperate via\n\n\t\tOutput=[[],[]]\n\n\t\tPivot=[]\n\t\tfor i in List:\n\t\t\tPivot.append(i[Argument])\n\t\tif len(Pivot)==2:\n\t\t\tPivot=max(Pivot)\n\t\telse:\n\t\t\tPivot=np.random.choice(Pivot)\n\n\t\tfor i in List:\n\t\t\tif i[Argument]<Pivot:\n\t\t\t\tOutput[0].append(i)\n\t\t\telse:\n\t\t\t\tOutput[1].append(i)\n\t\treturn Output",
  "def Same(List,Argument):\n\t\tfor i in List:\n\t\t\tif i[Argument]!=List[0][Argument]:\n\t\t\t\treturn False\n\t\treturn True",
  "class GraphWidget(pg.PlotWidget):\n    '''\n    template for an interactive graph\n    \n    Input: \n        equation: should be a function of only 1 variable (x). \n            Parameters to be varied should be a Parameter object.\n        xlim: interval over which the function will be plotted\n        ylim: currently does nothing\n        \n    make use of xlabel and ylabel methods!\n        \n    '''\n    def __init__(self, *args, \n                 xlim=(-10,10),\n                 ylim=(0,100),\n                 title='graph',\n                 xlabel = 'X axis',\n                 ylabel = 'Y axis'):\n        super().__init__(title=title)\n        self.equations = args\n        self.xlim = xlim\n        self.ylim = ylim\n        self.title(title)\n        self.xlabel(xlabel)\n        self.ylabel(ylabel)\n        self.hasLegend=False\n        self.addLegend()\n        graphs.append(self)\n    \n    @property\n    def x(self):\n        return np.linspace(*self.xlim, num=200)\n    \n    @property\n    def ys(self):\n        return [equation(self.x).astype(np.float64) for equation in self.equations]\n        \n    def update(self):\n        def name(eq): # takes the name of the function the first time,\n        #and returns none after to stop the legend from exploding\n            if self.hasLegend: return None\n            return str(eq).split(' ')[1]\n            \n        self.clearPlots() \n        for i, (y, eq) in enumerate(zip( self.ys, self.equations)):  \n            self.plot(self.x, y, pen=(i,len(self.equations)), name=name(eq))\n\n    def xlabel(self, label):\n        self.setLabel('bottom', label)\n    def ylabel(self, label):\n        self.setLabel('left', label)\n    def title(self, title):\n        self._title = title\n        self.setTitle(title)\n    def export(self):\n        print('x, y(s):',self.x, self.ys, sep='\\n')",
  "class GraphGroup(QtWidgets.QGroupBox):\n    '''\n    feed me GraphWidget objects and \n    I'll lay them out horizontally\n    '''\n    def __init__(self, graphs):\n        super().__init__('Graphs')\n        self.setLayout(QtWidgets.QGridLayout())\n        self.graphs = graphs\n        graphs_per_row = 5 if len(graphs)>12 else 4\n        for i,g in enumerate(graphs):    \n            self.layout().addWidget(graphs[i], i//graphs_per_row, i%graphs_per_row)\n\n    def update_graphs(self):\n        for g in self.graphs:\n            g.update()\n            g.hasLegend = True\n    def export(self):\n        for g in self.graphs:\n            print('Graph:', g._title)\n            g.export()",
  "class FloatMathMixin():\n    '''allows any class to be used like a float,\n    assuming it has a __float__ method.\n    '''\n    def __add__(self, other):\n        return float(self) + np.array(other)\n    def __sub__(self, other):\n        return float(self) - np.array(other)\n    def __mul__(self, other):\n        return float(self)*np.array(other)\n    def __truediv__(self,other):\n        return float(self)/np.array(other)\n    def __pow__(self, other):\n        return float(self)**np.array(other)\n    \n    def __radd__(self, other):\n        return self.__add__(other)\n    def __rsub__(self, other):\n        return self.__sub__(other)\n    def __rmul__(self,other):\n        return self.__mul__(other)\n    def __rtruediv__(self,other):\n        return self.__truediv__(other)\n    def __rpow__(self, other):\n        return self.__pow__(other)",
  "class Parameter(QtWidgets.QWidget, FloatMathMixin):\n    '''\n    Representation of a parameter to be varied in an equation.\n    Takes its value from the Gui.\n    Supports basic array math.\n    \n    Inputs:\n        name: the label the parameter will have in the gui\n        Default: its initial value\n        Min: minimum value allowed to be entered in the gui\n        Max: maximum...\n        \n    '''\n    \n    param_changed = QtCore.Signal(float)\n    def __init__(self, name, Default=1, Min=-100_000, Max=100_000, units=None, slider=False):\n        \n        super().__init__()\n        self.name = name\n        self.slider = slider\n        self.units = f' ({units})' if units is not None else ''\n        self.setLayout(QtWidgets.QFormLayout())\n        self.box =  QtWidgets.QSlider(QtCore.Qt.Horizontal) if slider else QtWidgets.QDoubleSpinBox()\n        self.label = QtWidgets.QLabel(self.name+self.units)\n        self.layout().addWidget(self.label)\n        self.box.setMinimum(Min)\n        self.box.setMaximum(Max)\n        self.layout().addWidget(self.box)\n        self.box.setValue(Default)\n        self.box.valueChanged.connect(self.changed)\n        self.changed()\n        parameters.append(self)\n        \n    def changed(self):\n        if self.slider:\n            self.label.setText(str(self))\n        self.param_changed.emit(1)\n        \n    def __float__(self):\n        return float(self.box.value())\n    def __repr__(self):\n        return str(float(self))\n    def __str__(self):\n        return f'{self.name}: {float(self)} {self.units}'",
  "class ParameterGroupBox(QtWidgets.QGroupBox):\n    '''\n    feed me parameters and i'll add spinBoxes for them, and \n    emit a signal when they're changed to update the graphs. \n    '''\n    param_changed = QtCore.Signal(float)\n    def __init__(self, parameters):\n        super().__init__('Parameter controls')\n        self.parameters = parameters\n        self.setLayout(QtWidgets.QHBoxLayout())\n        for p in self.parameters:\n            self.layout().addWidget(p)\n            p.param_changed.connect(self.param_changed.emit)\n    def export(self):\n        for p in self.parameters:\n            print(p)",
  "class LivePlotWindow(QtWidgets.QMainWindow):\n    '''Puts the graphing and parameter widgets together'''\n    def __init__(self, style='Fusion'):\n        app = QtWidgets.QApplication.instance()\n        if app is None:\n            app = QtGui.QApplication([])\n        app.setStyleSheet(qdarkstyle.load_stylesheet())\n            \n        super().__init__()\n        layout = QtWidgets.QVBoxLayout()\n        self.resize(1500,1500)\n        self.graphing_group = GraphGroup(graphs)#graphing_group\n        self.parameter_widget = ParameterGroupBox(parameters)\n        layout.addWidget(self.graphing_group)\n        # export_button = QtGui.QPushButton('Export values')\n        # export_button.clicked.connect(self.export)\n        # layout.addWidget(export_button)\n        layout.addWidget(self.parameter_widget)\n        self.setWindowTitle('Live Plotting')\n        # self.setWindowIcon(QtGui.QIcon('bessel.png'))\n        self.setWindowIcon(QtGui.QIcon('maxwell.png'))\n        self.widget = QtWidgets.QWidget()\n        self.widget.setLayout(layout)\n        self.setCentralWidget(self.widget)\n        self.parameter_widget.param_changed.connect(self.update_graphs)\n        self.update_graphs()\n        self.show()\n    \n    def update_graphs(self):\n        self.graphing_group.update_graphs()        \n    \n    def export(self):\n        self.graphing_group.export()\n        self.parameter_widget.export()",
  "def __init__(self, *args, \n                 xlim=(-10,10),\n                 ylim=(0,100),\n                 title='graph',\n                 xlabel = 'X axis',\n                 ylabel = 'Y axis'):\n        super().__init__(title=title)\n        self.equations = args\n        self.xlim = xlim\n        self.ylim = ylim\n        self.title(title)\n        self.xlabel(xlabel)\n        self.ylabel(ylabel)\n        self.hasLegend=False\n        self.addLegend()\n        graphs.append(self)",
  "def x(self):\n        return np.linspace(*self.xlim, num=200)",
  "def ys(self):\n        return [equation(self.x).astype(np.float64) for equation in self.equations]",
  "def update(self):\n        def name(eq): # takes the name of the function the first time,\n        #and returns none after to stop the legend from exploding\n            if self.hasLegend: return None\n            return str(eq).split(' ')[1]\n            \n        self.clearPlots() \n        for i, (y, eq) in enumerate(zip( self.ys, self.equations)):  \n            self.plot(self.x, y, pen=(i,len(self.equations)), name=name(eq))",
  "def xlabel(self, label):\n        self.setLabel('bottom', label)",
  "def ylabel(self, label):\n        self.setLabel('left', label)",
  "def title(self, title):\n        self._title = title\n        self.setTitle(title)",
  "def export(self):\n        print('x, y(s):',self.x, self.ys, sep='\\n')",
  "def __init__(self, graphs):\n        super().__init__('Graphs')\n        self.setLayout(QtWidgets.QGridLayout())\n        self.graphs = graphs\n        graphs_per_row = 5 if len(graphs)>12 else 4\n        for i,g in enumerate(graphs):    \n            self.layout().addWidget(graphs[i], i//graphs_per_row, i%graphs_per_row)",
  "def update_graphs(self):\n        for g in self.graphs:\n            g.update()\n            g.hasLegend = True",
  "def export(self):\n        for g in self.graphs:\n            print('Graph:', g._title)\n            g.export()",
  "def __add__(self, other):\n        return float(self) + np.array(other)",
  "def __sub__(self, other):\n        return float(self) - np.array(other)",
  "def __mul__(self, other):\n        return float(self)*np.array(other)",
  "def __truediv__(self,other):\n        return float(self)/np.array(other)",
  "def __pow__(self, other):\n        return float(self)**np.array(other)",
  "def __radd__(self, other):\n        return self.__add__(other)",
  "def __rsub__(self, other):\n        return self.__sub__(other)",
  "def __rmul__(self,other):\n        return self.__mul__(other)",
  "def __rtruediv__(self,other):\n        return self.__truediv__(other)",
  "def __rpow__(self, other):\n        return self.__pow__(other)",
  "def __init__(self, name, Default=1, Min=-100_000, Max=100_000, units=None, slider=False):\n        \n        super().__init__()\n        self.name = name\n        self.slider = slider\n        self.units = f' ({units})' if units is not None else ''\n        self.setLayout(QtWidgets.QFormLayout())\n        self.box =  QtWidgets.QSlider(QtCore.Qt.Horizontal) if slider else QtWidgets.QDoubleSpinBox()\n        self.label = QtWidgets.QLabel(self.name+self.units)\n        self.layout().addWidget(self.label)\n        self.box.setMinimum(Min)\n        self.box.setMaximum(Max)\n        self.layout().addWidget(self.box)\n        self.box.setValue(Default)\n        self.box.valueChanged.connect(self.changed)\n        self.changed()\n        parameters.append(self)",
  "def changed(self):\n        if self.slider:\n            self.label.setText(str(self))\n        self.param_changed.emit(1)",
  "def __float__(self):\n        return float(self.box.value())",
  "def __repr__(self):\n        return str(float(self))",
  "def __str__(self):\n        return f'{self.name}: {float(self)} {self.units}'",
  "def __init__(self, parameters):\n        super().__init__('Parameter controls')\n        self.parameters = parameters\n        self.setLayout(QtWidgets.QHBoxLayout())\n        for p in self.parameters:\n            self.layout().addWidget(p)\n            p.param_changed.connect(self.param_changed.emit)",
  "def export(self):\n        for p in self.parameters:\n            print(p)",
  "def __init__(self, style='Fusion'):\n        app = QtWidgets.QApplication.instance()\n        if app is None:\n            app = QtGui.QApplication([])\n        app.setStyleSheet(qdarkstyle.load_stylesheet())\n            \n        super().__init__()\n        layout = QtWidgets.QVBoxLayout()\n        self.resize(1500,1500)\n        self.graphing_group = GraphGroup(graphs)#graphing_group\n        self.parameter_widget = ParameterGroupBox(parameters)\n        layout.addWidget(self.graphing_group)\n        # export_button = QtGui.QPushButton('Export values')\n        # export_button.clicked.connect(self.export)\n        # layout.addWidget(export_button)\n        layout.addWidget(self.parameter_widget)\n        self.setWindowTitle('Live Plotting')\n        # self.setWindowIcon(QtGui.QIcon('bessel.png'))\n        self.setWindowIcon(QtGui.QIcon('maxwell.png'))\n        self.widget = QtWidgets.QWidget()\n        self.widget.setLayout(layout)\n        self.setCentralWidget(self.widget)\n        self.parameter_widget.param_changed.connect(self.update_graphs)\n        self.update_graphs()\n        self.show()",
  "def update_graphs(self):\n        self.graphing_group.update_graphs()",
  "def export(self):\n        self.graphing_group.export()\n        self.parameter_widget.export()",
  "def equation1(x):\n        return A*x**2 + B*x**2 - C*x + D",
  "def equation2(x):\n        return (A/x**2)**(B/C)",
  "def eq3(x):\n        return A**np.sin(C*x)/D*x",
  "def eq4(x):\n        return (np.sin(A*x)/B*x) + D",
  "def eq5(x):  \n        y = np.arange(len(x), dtype=np.float64)\n        y[len(x)//2]=np.nan\n        return y\n        return eq3(x)[::-1]",
  "def name(eq): # takes the name of the function the first time,\n        #and returns none after to stop the legend from exploding\n            if self.hasLegend: return None\n            return str(eq).split(' ')[1]",
  "class OverviewViewer(HasTraits):\n    figure = Instance(Figure, ())\n    scan_number = Range(0,136,0)\n    group_number = Range(0,6,6)\n    traits_view = View(\n                    VGroup(\n                        Item(name = \"scan_number\"),\n                        Item(name = \"group_number\"),\n                        Item('figure', editor = MPLFigureEditor(),\n                               show_label = False, label = \"Last Alignment\", springy = True),\n                    ),\n                    resizable = True, title = \"Overview Viewer\",\n                )\n    \n    def __init__(self, hdf5file):\n        super(OverviewViewer, self).__init__()\n        \n        if isinstance(hdf5file, h5py.File):\n            self._hdf5file = hdf5file\n        \n        else:\n            self._hdf5file=h5py.File(hdf5file)\n        self._group_number_changed()\n#        self._scan_number_changed()\n    \n    def __del__(self):\n        self._hdf5file.close()\n    \n    def _group_number_changed(self):\n        self._scan_number_changed()\n    \n    def _scan_number_changed(self):\n        \n        try:\n            \n            try:\n                g = self._hdf5file[\"ParticleScannerScan_%d/\" % (self.group_number)]\n            \n            except Exception as e:\n                print(\"error switching to ParticleScannerScan_%d/\\n\" % (self.group_number))\n                raise e\n            \n            image = g[\"reconstructed_tiles\" % self.scan_number]\n            #image2 = g[\"overview_image_%d_thresholded\" % self.scan_number]\n            self.replot(image)#, image2)\n        \n        except:\n            print(\"out of range :(\")\n    \n    def replot(self, image):  #, image2):\n        #plot the image on the left\n        ax = self.figure.axes\n        \n        if not ax[0].images:\n            ax[0].imshow(image)\n            #ax[1].imshow(image2)\n        \n        else:\n            ax[0].images[0].set_array(image)\n            #ax[1].images[0].set_array(image2)\n        \n        canvas = self.figure.canvas\n        \n        if canvas is not None:\n            canvas.draw()",
  "class ScanViewer(HasTraits):\n    figure = Instance(Figure, ())\n    scan_number = Range(0,100000,0)\n    group_number = Range(0,6,1)\n    use_reference = Bool(True)\n    background_subtract = Bool(True)\n    reference_threshold = Range(0,200000,10000)\n    traits_view = View(\n                    VGroup(\n                        Item(name=\"scan_number\"),\n                        Item(name=\"group_number\"),\n                        Item(name=\"use_reference\"),\n                        Item(name=\"reference_threshold\"),\n                        Item(name=\"background_subtract\"),\n                        Item('figure', editor=MPLFigureEditor(),\n                               show_label=False, label=\"Last Alignment\",springy=True),\n                    ),\n                    resizable=True, title=\"Scan Viewer\",\n                )\n    \n    def __init__(self,hdf5file):\n        super(ScanViewer, self).__init__()\n        \n        if isinstance(hdf5file,h5py.Group) or isinstance(hdf5file,h5py.File):\n            self._hdf5file = hdf5file\n        \n        else:\n            self._hdf5file=h5py.File(hdf5file)\n        \n        self.figure.add_axes((0,0,0.5,1))\n        self.figure.add_axes((0.5,0,0.5,1))\n        self.refresh_data()\n#        self._scan_number_changed()\n    \n    def __del__(self):\n        self._hdf5file.close()\n    \n    @on_trait_change(\"use_reference,background_subtract,scan_number,group_number\")\n    \n    def refresh_data(self):\n        print(\"switching to scan %d\" % self.scan_number)\n        \n        try:\n            g = self._hdf5file[\"ParticleScannerScan_%d/Particle_%d\" % (self.group_number,self.scan_number)]\n        \n        except Exception as e:\n            print(\"Error switching to ParticleScannerScan_%d/Particle_%d\\n\" % (self.group_number,self.scan_number))\n            print(e)\n            return False\n        \n        image = g['CWL.thumb_image_0']\n        zscan = g['alinger.z_scan_0']\n        spectrum = np.mean(zscan, axis=0)\n        wavelengths = zscan.attrs.get(\"wavelengths\")\n        reference = zscan.attrs.get(\"reference\")\n        background = zscan.attrs.get(\"background\")\n        \n        if self.background_subtract or self.use_reference:\n            spectrum -= background\n        \n        if self.use_reference: \n            mask = [r < self.reference_threshold for r in (reference-background)] #mask dodgy pixels\n            spectrum = np.ma.masked_array(spectrum, mask=mask)\n            reference = np.ma.masked_array(reference, mask=mask)\n            wavelengths = np.ma.masked_array(wavelengths, mask=mask)\n            background = np.ma.masked_array(background, mask=mask)\n            spectrum /= abs(reference - background)+0.001\n        \n        self.replot(image[old_div(image.shape[0],2)-50:old_div(image.shape[0],2)+50,old_div(image.shape[1],2)-50:old_div(image.shape[1],2)+50,], zscan, wavelengths, spectrum)\n    \n    def replot(self, image, zscan, wavelengths, spectrum):\n        fig = self.figure\n        \n        if fig is None: return #don't plot to a non-existent figure...\n        fig.clf() #clear the plot\n        \n        ax0=fig.add_axes((0.05,0.53,0.32,0.42)) #plot the overview image\n        ax0.imshow(image, extent=(0,1,0,1))#, aspect=\"equal\")\n        ax0.plot([0.5,0.5],[0.2,0.8],\"w-\")\n        ax0.plot([0.2,0.8],[0.5,0.5],\"w-\")\n        ax0.get_xaxis().set_visible(False)\n        ax0.get_yaxis().set_visible(False)\n        ax0.set_title(\"Particle Image\")\n        \n        ax1=fig.add_axes((0.05,0.08,0.32,0.42)) #plot the z stack\n        ax1.imshow(zscan, extent=(wavelengths.min(), wavelengths.max(), -4, 4), aspect=\"auto\", cmap=\"cubehelix\")\n        ax1.set_xlabel(\"Wavelength/nm\")\n        ax1.set_ylabel(\"Z/um\")        \n        \n        ax2=fig.add_axes((0.5,0.08,0.47,0.87)) #plot the spectrum\n        ax2.plot(wavelengths, spectrum)\n        ax2.set_xlabel(\"Wavelength/nm\")\n        ax2.set_ylabel(\"Z-averaged Spectrum\")\n        \n        if self.figure.canvas is not None: self.figure.canvas.draw()",
  "def fit_gaussians_to_z_scan(z_scan, z=None, background=None, threshold=0.2, smoothing_width=1.5):\n    \"\"\"Fit a Gaussian to the spectrometer counts vs Z curve for each spectrometer pixel.\n    \n    Parameters:\n        z_scan: 2D array (will be converted to numpy.ndarray) of spectra vs\n            Z, where Z is the first index and wavelength is the second.\n        z: 1D array of Z values for each row of z_scan.  If z_scan is an HDF5\n            dataset with attribute 'dz', this will be used by default.\n        background: 1D array containing a dark spectrum which is subtracted\n            from the z_scan.  Defaults to HDF5 attribute 'background' as above.\n            \n    Return value: spectrum, peak_z, standard_deviation, background, r\n        spectrum: peak height for the fitted Gaussian at each wavelength\n        peak_z: Z value at which the peak height occurs\n        standard_deviation: width of the Gaussian\n        background: revised version of the supplied (or extracted) background,\n            if the Gaussian fit suggests there is a constant background.\n        r: correlation coefficient between fitted and actual curve, which can\n            be a useful diagnostic as to how well the fit worked.\n    \n    N.B. You can re-run the fit, specifying the returned background - this may\n    improve accuracy, though the effect seems minimal now that it uses a\n    threshold to find the peak.  If the SNR of your data is particularly low,\n    or you might have peaks very close to the edge, it may make sense to\n    increase the threshold.\n    \"\"\"\n    if z is None: #try to find the Z values of the different spectra from metadata if not specified\n        \n        try:\n            z = z_scan.attrs.get('dz') #this should work for datasets in an HDF5 file\n        \n        except:\n            print(\"Warning: no valid z positions were found, using indices instead\")\n            z = list(range(z_scan.shape[0])) #fall back to indices\n    \n    if background is None: #similarly, get a head-start on the background from metadata\n        \n        try:\n            background = z_scan.attrs.get('background') #this should work for datasets in an HDF5 file\n        \n        except:\n            z = np.zeros(z_scan.shape[1]) #fall back to zero.  NB it will take a *really* long time to converge like this...\n    \n    Particle_array = np.array(z_scan, dtype = np.float) - background #first prepare background-subtracted, thresholded arrays\n    scan_s = scipy.ndimage.filters.gaussian_filter1d(Particle_array, smoothing_width, axis = 0, mode = 'nearest')\n    scan_s[scan_s < 0.] = 0. #smooth and remove negative points so that we don't get NaNs\n    scan_t = old_div((scan_s - scan_s.min(axis = 0)), (scan_s.max(axis = 0)-scan_s.min(axis = 0))) - threshold\n    scan_t[scan_t < 0.] = 0. #background-subtracted, thresholded version of Particle_array - used for finding the peak\n    #Now the fitting starts: find the centroid and width of the distribution in Z (the threshold helps avoid bias from background):\n    peak_z = old_div(np.sum(scan_t * z[:, np.newaxis], axis = 0), np.sum(scan_t, axis = 0))#the z[np.newaxis,:] is \"numpy broadcasting\", google it!\n    standard_deviation = np.sqrt(old_div(np.sum(scan_s * (z[:, np.newaxis] - peak_z) ** 2, axis = 0), np.sum(scan_s, axis = 0))) \n    #Next, construct a Gaussian in Z with the right parameters and use linear least squares to fit offset/peak to the data\n    gaussians = np.exp(old_div(-(z[:, np.newaxis] - peak_z[np.newaxis, :]) ** 2, (2 * standard_deviation ** 2)))\n    var_x = np.var(gaussians, axis = 0)\n    mean_x = np.mean(gaussians, axis = 0)\n    var_y = np.var(Particle_array, axis = 0)\n    mean_y = np.mean(Particle_array, axis = 0)\n    covariance = np.mean((gaussians - mean_x) * (Particle_array - mean_y), axis = 0)\n    slopes = old_div(covariance, var_x)\n    intercepts = mean_y - slopes * mean_x\n    peak_height = slopes\n    r = old_div(covariance, np.sqrt(var_x * var_y))\n    return peak_height, peak_z, standard_deviation, background + intercepts, r",
  "def extract_all_spectra(datafile, outputfile):\n    \"\"\"Go through a file, extract all the spectra, and save in an output file.\"\"\"\n    group_names = [k for k in datafile if \"ParticleScannerScan_\" in k]\n    \n    group_names = sorted(group_names, key = lambda group_name: len(datafile[group_name]))[::-1] #Sort ParticleScannerScan_ groups in order of size, so that the largest dataset (usually the one of interest) is named \"scan0\" in the summary file.\n    \n    for n, group_name in enumerate(group_names):\n        data_group = datafile[group_name]\n        save_group = outputfile.require_group('particleScanSummaries/scan%s' % n)\n        Particle_groups = [group for key, group in list(data_group.items()) if \"Particle_\" in key] #filter out scan groups from overview images, etc.\n\n        if len(Particle_groups) > 0:\n            shape = (len(Particle_groups), Particle_groups[0]['alinger.z_scan_0'].attrs.get('wavelengths').shape[0])\n            #these datasets will save the fit parameters to each spectrum in the current scan\n            spectra = save_group.create_dataset(\"spectra\", shape)\n            \n            for name, value in list(Particle_groups[0]['alinger.z_scan_0'].attrs.items()):\n                spectra.attrs.create(name, value)\n            \n            peak_z = save_group.create_dataset(\"peak_z\", shape)\n            standard_deviation = save_group.create_dataset(\"standard_deviation\", shape)\n            fitted_background = save_group.create_dataset(\"fitted_background\", shape)\n            correlation_coefficient = save_group.create_dataset(\"correlation_coefficient\", shape)\n            \n            for i in range(len(Particle_groups)):\n                \n                try:\n                    spectra[i, :], peak_z[i, :], standard_deviation[i, :], fitted_background[i, :], correlation_coefficient[i, :] = fit_gaussians_to_z_scan(data_group['Particle_%d/alinger.z_scan_0' % i])\n                \n                except Exception as e:\n                    print(\"Failed to get alinger.z_scan_0 in group %s.\" % group_name)\n                    raise e",
  "def __init__(self, hdf5file):\n        super(OverviewViewer, self).__init__()\n        \n        if isinstance(hdf5file, h5py.File):\n            self._hdf5file = hdf5file\n        \n        else:\n            self._hdf5file=h5py.File(hdf5file)\n        self._group_number_changed()",
  "def __del__(self):\n        self._hdf5file.close()",
  "def _group_number_changed(self):\n        self._scan_number_changed()",
  "def _scan_number_changed(self):\n        \n        try:\n            \n            try:\n                g = self._hdf5file[\"ParticleScannerScan_%d/\" % (self.group_number)]\n            \n            except Exception as e:\n                print(\"error switching to ParticleScannerScan_%d/\\n\" % (self.group_number))\n                raise e\n            \n            image = g[\"reconstructed_tiles\" % self.scan_number]\n            #image2 = g[\"overview_image_%d_thresholded\" % self.scan_number]\n            self.replot(image)#, image2)\n        \n        except:\n            print(\"out of range :(\")",
  "def replot(self, image):  #, image2):\n        #plot the image on the left\n        ax = self.figure.axes\n        \n        if not ax[0].images:\n            ax[0].imshow(image)\n            #ax[1].imshow(image2)\n        \n        else:\n            ax[0].images[0].set_array(image)\n            #ax[1].images[0].set_array(image2)\n        \n        canvas = self.figure.canvas\n        \n        if canvas is not None:\n            canvas.draw()",
  "def __init__(self,hdf5file):\n        super(ScanViewer, self).__init__()\n        \n        if isinstance(hdf5file,h5py.Group) or isinstance(hdf5file,h5py.File):\n            self._hdf5file = hdf5file\n        \n        else:\n            self._hdf5file=h5py.File(hdf5file)\n        \n        self.figure.add_axes((0,0,0.5,1))\n        self.figure.add_axes((0.5,0,0.5,1))\n        self.refresh_data()",
  "def __del__(self):\n        self._hdf5file.close()",
  "def refresh_data(self):\n        print(\"switching to scan %d\" % self.scan_number)\n        \n        try:\n            g = self._hdf5file[\"ParticleScannerScan_%d/Particle_%d\" % (self.group_number,self.scan_number)]\n        \n        except Exception as e:\n            print(\"Error switching to ParticleScannerScan_%d/Particle_%d\\n\" % (self.group_number,self.scan_number))\n            print(e)\n            return False\n        \n        image = g['CWL.thumb_image_0']\n        zscan = g['alinger.z_scan_0']\n        spectrum = np.mean(zscan, axis=0)\n        wavelengths = zscan.attrs.get(\"wavelengths\")\n        reference = zscan.attrs.get(\"reference\")\n        background = zscan.attrs.get(\"background\")\n        \n        if self.background_subtract or self.use_reference:\n            spectrum -= background\n        \n        if self.use_reference: \n            mask = [r < self.reference_threshold for r in (reference-background)] #mask dodgy pixels\n            spectrum = np.ma.masked_array(spectrum, mask=mask)\n            reference = np.ma.masked_array(reference, mask=mask)\n            wavelengths = np.ma.masked_array(wavelengths, mask=mask)\n            background = np.ma.masked_array(background, mask=mask)\n            spectrum /= abs(reference - background)+0.001\n        \n        self.replot(image[old_div(image.shape[0],2)-50:old_div(image.shape[0],2)+50,old_div(image.shape[1],2)-50:old_div(image.shape[1],2)+50,], zscan, wavelengths, spectrum)",
  "def replot(self, image, zscan, wavelengths, spectrum):\n        fig = self.figure\n        \n        if fig is None: return #don't plot to a non-existent figure...\n        fig.clf() #clear the plot\n        \n        ax0=fig.add_axes((0.05,0.53,0.32,0.42)) #plot the overview image\n        ax0.imshow(image, extent=(0,1,0,1))#, aspect=\"equal\")\n        ax0.plot([0.5,0.5],[0.2,0.8],\"w-\")\n        ax0.plot([0.2,0.8],[0.5,0.5],\"w-\")\n        ax0.get_xaxis().set_visible(False)\n        ax0.get_yaxis().set_visible(False)\n        ax0.set_title(\"Particle Image\")\n        \n        ax1=fig.add_axes((0.05,0.08,0.32,0.42)) #plot the z stack\n        ax1.imshow(zscan, extent=(wavelengths.min(), wavelengths.max(), -4, 4), aspect=\"auto\", cmap=\"cubehelix\")\n        ax1.set_xlabel(\"Wavelength/nm\")\n        ax1.set_ylabel(\"Z/um\")        \n        \n        ax2=fig.add_axes((0.5,0.08,0.47,0.87)) #plot the spectrum\n        ax2.plot(wavelengths, spectrum)\n        ax2.set_xlabel(\"Wavelength/nm\")\n        ax2.set_ylabel(\"Z-averaged Spectrum\")\n        \n        if self.figure.canvas is not None: self.figure.canvas.draw()",
  "class VirtualDimer:\n    def __init__(self, np_size, gap_size, gap_ri, env_ri = 1, conductance = 0, inductance = None, facet_width = None):\n        self.np_size = np_size #AuNP diameter in nm\n        self.gap_size = gap_size #Gap size in nm\n        self.gap_ri = gap_ri #RI of nanocavity\n        self.env_ri = env_ri #RI of surrounding medium\n        self.conductance = conductance #in G0\n        self.inductance = inductance # some integer value; don't ask me, I'm not a physicist\n        self.facet_width = facet_width if facet_width is not None else np_size/4#in nm\n\n        self.initialize_constants()\n        self.calc_chi()\n        self.calc_theta()\n        self.calc_eta()\n        self.calc_eps_inf()\n        self.calc_cavity_wl()\n        self.calc_antenna_wl()\n        self.calc_mixing()\n    \n    def initialize_constants(self):\n        self.c = 2.99792458e8 # in m/s\n        self.plasma_wl = 146 # in nm, Constant for Au\n        self.plasma_freq = 2 * np.pi * 2.99792458e8 / (self.plasma_wl * 1e-9) #radial frequency, Constant for Au\n        self.eps_0 = pow((pow(2.9979e8, 2) * 4 * np.pi * 1e-7), -1) #Constant in F/m (SI units)\n        self.cond_quant = 7.74809173e-5 #Constant\n    \n    def calc_chi(self):\n        self.chi = 1.0242 + self.np_size*0.012785 - 0.0001375*pow(self.np_size, 2)\n\n    def wl_to_ev(self, wl):\n        return 1239.8419745831507/wl#converts between eV and nm\n\n    def calc_theta(self):\n        theta_degrees = 27.171 - 0.091802*self.np_size + 0.00096972*pow(self.np_size, 2) + 1.8442e-5*pow(self.np_size, 3)\n        self.theta = theta_degrees*(np.pi/180)\n\n    def calc_eta(self):\n        self.eta = (pow(self.gap_ri, self.chi)/self.env_ri)*np.log(1 + ((self.np_size/2)*pow(self.theta, 2)/(2*self.gap_size)))\n\n    def calc_eps_inf(self):\n        \"calculates the correct eps_inf for a given NP size\"\n        self.eps_inf = 9.38 - 0.00339*self.np_size + 0.00021*pow(self.np_size, 2)\n    \n    def calc_cavity_wl(self): # calculates energies of lowest mode\n        wp = self.wl_to_ev(self.plasma_wl)\n        en = wp/np.sqrt(self.eps_inf + self.facet_width*(self.gap_ri**2)/(self.gap_size * 4.2)) # alpha antinodes: in NPoMv2 {4.2,9.4,15} to fit better?\n        \n        self.cavity_wl = self.wl_to_ev(en)\n\n    def calc_antenna_wl(self):#calculates coupled mode for spherical dimer using Felix Benz's circuit model\n        wd = 1/np.sqrt(4*self.eta*self.gap_ri + 2*self.gap_ri + self.eps_inf)\n        \n        if self.conductance == 0:\n            self.antenna_wl = self.plasma_wl/wd\n        \n        else:            \n            Cs = 2*np.pi*(self.np_size/2)*self.eps_0*self.gap_ri*1e-9\n            induct_fh = self.inductance*1e-15\n            gam = -induct_fh*Cs*pow(self.plasma_freq, 2)\n\n            condS = np.multiply(self.cond_quant, self.conductance)\n            de = 1/pow((condS*induct_fh*self.plasma_freq), 2)\n\n            bq = de + pow(wd, 2)*(4*self.env_ri/gam - 1)\n            cq = -de * pow(wd, 2)\n            sqt = np.sqrt(pow(bq, 2) - 4*cq)\n            self.antenna_wl = self.plasma_wl*np.sqrt(2/(sqt - bq))\n\n    def calc_mixing(self): # calculates coupled plasmon from cavity mode coupled to antenna mode\n        e1 = self.wl_to_ev(self.antenna_wl) # antenna mode, around 746nm\n        e2 = self.wl_to_ev(self.cavity_wl) # cavity mode\n        eo = 0.5*(e1 + e2) - np.sqrt(0.25*(e2 - e1)**2 + 0.11**2) # V=0.09 in NPoMv2 for 5 modes, increase to match\n        \n        self.coupled_wl = self.wl_to_ev(eo)",
  "def __init__(self, np_size, gap_size, gap_ri, env_ri = 1, conductance = 0, inductance = None, facet_width = None):\n        self.np_size = np_size #AuNP diameter in nm\n        self.gap_size = gap_size #Gap size in nm\n        self.gap_ri = gap_ri #RI of nanocavity\n        self.env_ri = env_ri #RI of surrounding medium\n        self.conductance = conductance #in G0\n        self.inductance = inductance # some integer value; don't ask me, I'm not a physicist\n        self.facet_width = facet_width if facet_width is not None else np_size/4#in nm\n\n        self.initialize_constants()\n        self.calc_chi()\n        self.calc_theta()\n        self.calc_eta()\n        self.calc_eps_inf()\n        self.calc_cavity_wl()\n        self.calc_antenna_wl()\n        self.calc_mixing()",
  "def initialize_constants(self):\n        self.c = 2.99792458e8 # in m/s\n        self.plasma_wl = 146 # in nm, Constant for Au\n        self.plasma_freq = 2 * np.pi * 2.99792458e8 / (self.plasma_wl * 1e-9) #radial frequency, Constant for Au\n        self.eps_0 = pow((pow(2.9979e8, 2) * 4 * np.pi * 1e-7), -1) #Constant in F/m (SI units)\n        self.cond_quant = 7.74809173e-5",
  "def calc_chi(self):\n        self.chi = 1.0242 + self.np_size*0.012785 - 0.0001375*pow(self.np_size, 2)",
  "def wl_to_ev(self, wl):\n        return 1239.8419745831507/wl",
  "def calc_theta(self):\n        theta_degrees = 27.171 - 0.091802*self.np_size + 0.00096972*pow(self.np_size, 2) + 1.8442e-5*pow(self.np_size, 3)\n        self.theta = theta_degrees*(np.pi/180)",
  "def calc_eta(self):\n        self.eta = (pow(self.gap_ri, self.chi)/self.env_ri)*np.log(1 + ((self.np_size/2)*pow(self.theta, 2)/(2*self.gap_size)))",
  "def calc_eps_inf(self):\n        \"calculates the correct eps_inf for a given NP size\"\n        self.eps_inf = 9.38 - 0.00339*self.np_size + 0.00021*pow(self.np_size, 2)",
  "def calc_cavity_wl(self): # calculates energies of lowest mode\n        wp = self.wl_to_ev(self.plasma_wl)\n        en = wp/np.sqrt(self.eps_inf + self.facet_width*(self.gap_ri**2)/(self.gap_size * 4.2)) # alpha antinodes: in NPoMv2 {4.2,9.4,15} to fit better?\n        \n        self.cavity_wl = self.wl_to_ev(en)",
  "def calc_antenna_wl(self):#calculates coupled mode for spherical dimer using Felix Benz's circuit model\n        wd = 1/np.sqrt(4*self.eta*self.gap_ri + 2*self.gap_ri + self.eps_inf)\n        \n        if self.conductance == 0:\n            self.antenna_wl = self.plasma_wl/wd\n        \n        else:            \n            Cs = 2*np.pi*(self.np_size/2)*self.eps_0*self.gap_ri*1e-9\n            induct_fh = self.inductance*1e-15\n            gam = -induct_fh*Cs*pow(self.plasma_freq, 2)\n\n            condS = np.multiply(self.cond_quant, self.conductance)\n            de = 1/pow((condS*induct_fh*self.plasma_freq), 2)\n\n            bq = de + pow(wd, 2)*(4*self.env_ri/gam - 1)\n            cq = -de * pow(wd, 2)\n            sqt = np.sqrt(pow(bq, 2) - 4*cq)\n            self.antenna_wl = self.plasma_wl*np.sqrt(2/(sqt - bq))",
  "def calc_mixing(self): # calculates coupled plasmon from cavity mode coupled to antenna mode\n        e1 = self.wl_to_ev(self.antenna_wl) # antenna mode, around 746nm\n        e2 = self.wl_to_ev(self.cavity_wl) # cavity mode\n        eo = 0.5*(e1 + e2) - np.sqrt(0.25*(e2 - e1)**2 + 0.11**2) # V=0.09 in NPoMv2 for 5 modes, increase to match\n        \n        self.coupled_wl = self.wl_to_ev(eo)",
  "def findH5File(rootDir, mostRecent = True, nameFormat = 'date'):\n    '''\n    Finds either oldest or most recent .h5 file in a folder containing specified string\n    '''\n\n    os.chdir(rootDir)\n\n    if mostRecent == True:\n        n = -1\n\n    else:\n        n = 0\n\n    if nameFormat == 'date':\n        h5Files = sorted([i for i in os.listdir('.') if re.match('\\d\\d\\d\\d-[01]\\d-[0123]\\d', i[:10])\n                         and (i.endswith('.h5') or i.endswith('.hdf5'))],\n                        key = lambda i: os.path.getmtime(i))\n\n    else:\n        h5Files = sorted([i for i in os.listdir('.') if i.startswith(nameFormat)\n                         and (i.endswith('.h5') or i.endswith('.hdf5'))],\n                        key = lambda i: os.path.getmtime(i))\n\n    if len(h5Files) == 0:\n        print('\\nNo H5 file found')\n        return None\n\n    else:\n        h5File = h5Files[n]\n\n    print('\\tH5 file %s found' % h5File)\n\n    return h5File",
  "def createOutputFile(filename):\n\n    '''Auto-increments new filename if file exists. Outputs name of file to be created as a string'''\n\n    print('\\nCreating output file...')\n\n    outputFile = '%s.h5' % filename\n\n    if outputFile in os.listdir('.'):\n        print('\\n%s already exists' % outputFile)\n        n = 0\n        outputFile = '%s_%s.h5' % (filename, n)\n\n        while outputFile in os.listdir('.'):\n            print('%s already exists' % outputFile)\n            n += 1\n            outputFile = '%s_%s.h5' % (filename, n)\n\n    print('\\tOutput file %s created' % outputFile)\n\n    return outputFile",
  "def printEnd():\n    print('%s%s%sv gud' % ('\\t' * randint(0, 12), '\\n' * randint(0, 5), ' ' * randint(0, 4)))\n    print('%s%swow' % ('\\n' * randint(2, 5), ' ' * randint(5, 55)))\n    print('%s%ssuch python' % ('\\n' * randint(0, 5), ' ' * randint(0, 55)))\n    print('%s%swow' % ('\\n' * randint(2, 5), ' ' * randint(5, 55)))\n    print('%s%smany spectra' % ('\\n' * randint(0, 5), ' ' * randint(10, 55)))\n    print('%s%swow' % ('\\n' * randint(2, 5), ' ' * randint(5, 55)))\n    print('%s%smuch calculation' % ('\\n' * randint(0, 5), ' ' * randint(8, 55)))\n    print('%s%swow' % ('\\n' * randint(2, 5), ' ' * randint(5, 55)))\n    print('\\n' * randint(0, 7))",
  "def detectMinima(array, threshold = 0, returnBool = False):\n    '''\n    detectMinima(array) -> mIndices\n    Finds the turning points within a 1D array and returns the indices of the minima.\n    '''\n    mIndices = []\n\n    if (len(array) < 3):\n        return mIndices\n\n    neutral, rising, falling = np.arange(3)\n\n    def getState(a, b):\n        if a < b: return rising\n        if a > b: return falling\n        return neutral\n\n    ps = getState(array[0], array[1])\n    begin = 1\n\n    for i in range(2, len(array)):\n        s = getState(array[i - 1], array[i])\n\n        if s != neutral:\n\n            if ps != neutral and ps != s:\n\n                if s != falling:\n                    mIndices.append((begin + i - 1)//2)\n\n            begin = i\n            ps = s\n\n    if threshold > 0:\n        yRange = array.max() - array.min()\n        threshold = array.max() - threshold*yRange\n        mIndices = [i for i in mIndices if array[i] < threshold]\n\n    if returnBool == True and len(mIndices) == 0:\n        return False\n\n    return np.array(mIndices)",
  "def butterLowpassFiltFilt(data, cutoff = 2000, fs = 20000, order=5):\n    '''Smoothes data without shifting it'''\n\n    padded = False\n\n    if len(data) < 18:\n        padded = True\n        pad = 18 - len(data)/2\n        startPad = np.array([data[0]] * (int(pad) + 1))\n        endPad = np.array([data[0]] * (int(pad) + 1))\n        data = np.concatenate((startPad, data, endPad))\n\n    nyq = 0.5 * fs\n    normalCutoff = cutoff/nyq\n    b, a = butter(order, normalCutoff, btype='low', analog=False)\n    yFiltered = filtfilt(b, a, data)\n\n    if padded == True:\n        yFiltered = yFiltered[len(startPad):-len(endPad)]\n\n    return yFiltered",
  "def truncateSpectrum(x, y, startWl = 450, finishWl = 900):\n    '''\n    Truncates xy data spectrum within a specified wavelength range. Useful for removing high and low-end noise.\n    Default range is 450-900 nm\n    '''\n    x = np.array(x)\n    y = np.array(y)\n    reverse = False\n\n    if x[0] > x[-1]:\n        reverse = True\n        x = x[::-1]\n        y = y[::-1]\n\n    if x[0] > startWl:#Adds pad to start of y so that output size isn't affected\n        xStart = np.arange(x[0], startWl - 2, x[0] - x[1])[1:][::-1]\n        yStart = np.array([np.average(y[:5])] * len(xStart))\n        x = np.concatenate((xStart, x))\n        y = np.concatenate((yStart, y))\n\n    if x[-1] < finishWl:#adds pad at end\n        xFin = np.arange(x[-1], finishWl + 2, x[1] - x[0])[1:]\n        yFin =  np.array([np.average(y[-5:])] * len(xFin))\n        x = np.concatenate((x, xFin))\n        y = np.concatenate((y, yFin))\n\n    startIndex = (abs(x - startWl)).argmin()\n    finishIndex = (abs(x - finishWl)).argmin()\n\n    xTrunc = np.array(x[startIndex:finishIndex])\n    yTrunc = np.array(y[startIndex:finishIndex])\n\n    if reverse == True:\n        xTrunc = xTrunc[::-1]\n        yTrunc = yTrunc[::-1]\n\n    if xTrunc.size <= 10 and x.size <= 100:\n\n        if startWl > finishWl:\n            wl1 = finishWl\n            wl2 = startWl\n            startWl = wl1\n            finishWl = wl2\n\n        xTrunc, yTrunc = np.transpose(np.array([[i, y[n]] for n, i in enumerate(x) if startWl < i < finishWl]))\n\n    return np.array([xTrunc, yTrunc])",
  "def checkCentering(zScan, dz = None):\n\n    if dz is None:\n        dz = np.linspace(-3, 3, len(zScan))\n\n    zScanTransposed = np.transpose(zScan) #Transpose to look at scan at each wavelength\n\n    startDex = 132 #500 nm; np.where(x > 500)[0][0]\n    finDex = 553 #820 nm; np.where(x > 820)[0][0] - 1\n\n    scanMaxs = np.max(zScanTransposed[startDex:finDex], axis = 1) #Find total intensity of each scan in region 500 - 820 nm; too much noise at longer wavelengths\n    fs = 50000\n    scanMaxsSmooth = butterLowpassFiltFilt(scanMaxs, cutoff = 1500, fs = fs) #Smoothes the 'spectrum'\n    maxWlIndices = detectMinima(-scanMaxsSmooth) + startDex #finds indices of main spectral 'peaks'\n\n    while len(maxWlIndices) > 4:\n        #unrealistic, so have another go with stronger smoothing\n        fs += 3000\n        scanMaxsSmooth = butterLowpassFiltFilt(scanMaxs, cutoff = 1500, fs = fs)\n        maxWlIndices = detectMinima(-scanMaxsSmooth) + startDex\n\n    maxWlIndices = np.array([np.arange(i - 2, i + 3) for i in maxWlIndices]).flatten()\n    #adds a few either side of each peak for luck\n\n    brightScans = np.array([scan for scan in zScanTransposed[maxWlIndices]])\n    #List of corresponding z-stacks\n    testFactor = 0\n    dZInterp = np.linspace(-3, 3, 41)\n\n    for z in brightScans:\n        z[0] = z[1]\n        z -= z.min()\n        z = np.interp(dZInterp, dz, z)     \n\n        iEdge = np.trapz(z[:10]) + np.trapz(z[-(10):])\n        iMid = np.trapz(z[10:-10])\n        testFactor += iMid/iEdge\n\n    testFactor /= len(maxWlIndices)\n    \n    if testFactor > 3.6:      \n        #print(f'Aligned ({testFactor:.2f})')\n        return True\n    else:      \n        #print(f'Misaligned ({testFactor:.2f})')\n        return False",
  "def lInterp(Value1,Value2,Frac):\n    #Value 1 and 2 are two numbers. Frac is between 0 and 1 and tells you fractionally how far between the two values you want ot interpolate\n\n    m=Value2-Value1\n    c=Value1\n\n    return (m*Frac)+c",
  "def condenseZscan(zScan, returnMaxs = False, dz = None, threshold = 0.2, Smoothing_width = 1.5, aligned = True, avgZScans = False):\n    \"\"\"\n    zScan is assumed to already be background subtracted and referenced.\n    \"\"\"\n    if aligned == False:\n        '''\n        If NP and/or collection path off-centre, centroid method is inaccurate.\n        Alternative method takes maximum (or average, if specified) value for each wavelength.\n        '''\n\n        centroids = np.array([scan[2:].argmax() + 2 for scan in np.transpose(zScan)])\n        centroids = np.where(centroids == 0, np.nan, centroids)\n        centroids = np.where(centroids == len(dz) - 1, np.nan, centroids).astype(np.float64)\n        centroids = mpf.removeNaNs(centroids, nBuff = 1)\n        #print(centroids)\n        centroidsSmuth = butterLowpassFiltFilt(centroids, cutoff = 900, fs = 80000)\n        #print(centroidsSmuth)\n\n        if True in np.isfinite(centroidsSmuth):\n            centroids = centroidsSmuth\n\n        centroids = mpf.removeNaNs(centroids)\n\n    else:\n        '''\n        Z Scan is thresholded and the centroid taken for each wavelength\n        '''\n        zThresh = mpf.removeNaNs(zScan, buff = True)\n        zThresh = zThresh.astype(np.float64)\n        zThresh = (zThresh - zThresh.min(axis = 0))/(zThresh.max(axis = 0) - zThresh.min(axis = 0))\n        zThresh -= threshold\n        zThresh *= (zThresh > 0) #Normalise and Threshold array\n        ones = np.zeros([zScan.shape[1]]) + 1\n        positions = np.array([ones*n for n in np.arange(zScan.shape[0])]).astype(np.float64)\n\n        centroids = np.sum((zThresh*positions), axis = 0)/np.sum(zThresh, axis = 0) #Find Z centroid position for each wavelength\n        centroids = mpf.removeNaNs(centroids)\n\n    zT = np.transpose(zScan)\n\n    output = []\n    zProfile = []\n\n    for n, centroid in enumerate(centroids):\n        try:\n            if len(zT[n]) < len(dz):\n                print('Wl %s z stack too short' % n)\n        except Exception as e:\n            print(dz, zT)\n            print(f'{n} failed in z stack')\n            if len(zT[n]) < len(dz):\n                print('Wl %s z stack too short' % n)\n        \n        if not np.isfinite(centroid):\n            if n == 0:\n                centroid = centroids[n + 1]\n            else:\n                centroid = centroids[n - 1]\n\n        try:\n            lower = int(centroid)\n        except:\n            print('aaaaaaa')\n            #print(centroids)\n\n        upper = lower + 1\n\n        frac = centroid - lower\n\n        if centroid == centroids[-1] or upper == len(dz):\n            upper -= 1\n            frac = 0\n\n        try:\n            output.append(lInterp(zT[n][lower], zT[n][upper], frac))\n            zProfile.append(lInterp(dz[lower], dz[upper], frac))\n        except Exception as e:\n            print(n, lower, upper, frac)\n            aligned = False\n            avgZScans = True\n            print(e)\n            #raise e\n\n    if aligned == False and avgZScans == True:\n        print('Averaging')\n        output = np.average(zScan, axis = 0)\n\n    return np.array(output), np.array(zProfile)",
  "def consoliData(rootDir):\n    os.chdir(rootDir)\n    print('Consolidating data')\n    print('Searching for raw data file...')\n\n    try:\n        inputFile = findH5File(rootDir, nameFormat = 'date')\n    except:\n        print('File not found')\n\n    with h5py.File(inputFile, 'a') as ipf:\n        if 'particleScans' in ipf.keys():\n            fileType = 'pre-2018'\n\n        elif 'nplab_log' in ipf.keys():\n            fileType = 'post-2018'\n\n        else:\n            print('File format not recognised')\n            return\n\n        if fileType == 'pre-2018':\n            ipf = ipf['particleScans']\n            gScanFormat = 'scan'\n            gParticleFormat = 'z_scan_'\n\n        elif fileType == 'post-2018':\n            gScanFormat = 'ParticleScannerScan_'\n            gParticleFormat = 'Particle_'\n\n        print('Sorting scans by size...')\n\n        allScans = sorted([groupName for groupName in ipf.keys() if groupName.startswith(gScanFormat) and '%s0' % gParticleFormat in ipf[groupName].keys()],\n                              key = lambda groupName: len(ipf[groupName].keys()))[::-1]\n\n        if len(allScans) <= 1:\n            print('No extra scans to consolidate')\n            return\n\n        for scanName in allScans:\n            if len([i for i in ipf[scanName].keys() if i.startswith('Tiles')]) > 1:\n                print('Data already consolidated')\n                return\n\n        finalScanNo = sorted([groupName for groupName in ipf.keys() if groupName.startswith(gScanFormat)],\n                              key = lambda groupName: int(groupName.split('_')[-1]))[-1].split('_')[-1]\n        newScanNo = int(finalScanNo) + 1\n        consolidatedScan = ipf.create_group('%s%s' % (gScanFormat, newScanNo))\n\n        for n, scanName in enumerate(allScans):\n            if scanName == '%s%s' % (gScanFormat, newScanNo):\n                continue\n            print('Looking for data in %s...' % scanName)\n            if '%s0' % gParticleFormat in ipf[scanName].keys():\n                particleGroups = [i for i in ipf[scanName].keys() if i.startswith(gParticleFormat)]\n                print('\\tData found for %s particles' % len(particleGroups))\n                scanN = scanName.split('_')[-1]\n                gTiles = consolidatedScan.create_group('Tiles_%s' % scanN)\n                for tileName in ipf[scanName]['Tiles'].keys():\n                    dTileOld = ipf[scanName]['Tiles'][tileName]\n                    dTileNew = gTiles.create_dataset(tileName, data = dTileOld)\n                    dTileNew.attrs.update(dTileOld.attrs)\n\n                dReconTilesOld = ipf[scanName]['reconstructed_tiles']\n                dReconTilesnew = consolidatedScan.create_dataset('reconstructed_tiles_%s' % scanN,\n                                                              data = dReconTilesOld)\n                dReconTilesnew.attrs.update(dReconTilesOld.attrs)\n\n                existingParticles = sorted([i for i in consolidatedScan.keys() if i.startswith(gParticleFormat)],\n                                                key = lambda i: int(i.split('_')[-1]))\n\n                for particleN, groupName in enumerate(particleGroups):\n                    gParticleOld = ipf[scanName][groupName]\n                    if groupName in consolidatedScan.keys():\n                        particleNNew = particleN + int(existingParticles[-1].split('_')[-1]) + 1\n                        newGroupName = '%s%s' % (gParticleFormat, particleNNew)\n                    else:\n                        newGroupName = groupName\n\n                    gParticleNew = consolidatedScan.create_group(newGroupName)\n                    gParticleNew.attrs.update(gParticleOld.attrs)\n                    for dataName in gParticleOld.keys():\n                        print(type(gParticleOld[dataName]))\n                        try:\n                            newDataset = gParticleNew.create_dataset(dataName, data = gParticleOld[dataName])\n                        except:\n                            print(type(gParticleOld[dataName]))\n                        newDataset.attrs.update(gParticleOld[dataName].attrs)",
  "def extractAllSpectra(rootDir, returnIndividual = True, pl = False, dodgyThreshold = 0.4, start = 0, finish = 0,\n                      raiseExceptions = True, customScan = None, consolidated = False, extractZ = True, avgZScans = False):\n\n    os.chdir(rootDir)\n\n    print('Searching for raw data file...')\n\n    try:\n        inputFile = findH5File(rootDir, nameFormat = 'date')\n    except:\n        print('File not found')\n\n    print('About to extract data from %s' % inputFile)\n    if customScan is not None:\n        outputFile = createOutputFile(f'summary_{customScan}')\n    else:\n        outputFile = createOutputFile('summary')\n\n    with h5py.File(inputFile, 'a') as ipf:\n        \n        if 'particleScans' in ipf.keys():\n            fileType = 'pre-2018'\n\n        elif 'nplab_log' in ipf.keys():\n            fileType = 'post-2018'\n\n        else:\n            print('File format not recognised')\n            return\n\n        with h5py.File(outputFile, 'a') as opf:\n\n            gAllOut = opf.create_group('particleScanSummaries')\n            dParticleFormat = None\n\n            if returnIndividual == True:\n                gInd = opf.create_group('Individual NPoM Spectra')\n\n            if fileType == 'pre-2018':\n                ipf = ipf['particleScans']\n                gScanFormat = 'scan'\n                gParticleFormat = 'z_scan_'\n                dParticleFormat = 'z_scan'\n\n            elif fileType == 'post-2018':\n                gScanFormat = 'ParticleScannerScan_'\n                gParticleFormat = 'Particle_'\n\n            allScans = sorted([groupName for groupName in list(ipf.keys()) if groupName.startswith(gScanFormat)],\n                              key = lambda groupName: len(list(ipf[groupName].keys())))[::-1]\n\n            if customScan is not None:\n                allScans = [customScan]\n\n            if fileType == 'post-2018':\n                particleN = 0\n                while dParticleFormat is None:                    \n                    for dSetName in list(ipf[allScans[0]]['Particle_'+str(particleN)].keys()):\n                        if dSetName.startswith('alinger.z_scan') or dSetName.startswith('zScan') or dSetName.startswith('z_scan_0'):\n                            dParticleFormat = dSetName\n                            break\n                    \n                    particleN += 1\n\n            for n, scanName in enumerate(allScans):\n\n                if len(ipf[scanName]) < 15:\n                    continue\n\n                if consolidated == True and n > 0:\n                    continue\n\n                nummers = list(range(10, 101, 10))\n                scanStart = time.time()\n\n                dodgyParticles = []\n                dodgyCount = 0\n\n                gScan = gAllOut.create_group('scan%s' % n)\n\n                if returnIndividual == True:\n                    gIndScan = gInd.create_group('scan%s' % n)\n\n                spectra = []\n                zProfiles = []\n                centereds = []\n                attrs = {}\n                scan = ipf[scanName]\n                particleGroups = sorted([groupName for groupName in list(scan.keys()) if groupName.startswith(gParticleFormat)],\n                                         key = lambda groupName: int(groupName.split('_')[-1]))\n\n                print('%s particles found in %s' % (len(particleGroups), scanName))\n                print('\\n0% complete')\n\n                if finish == 0:\n                    particleGroups = particleGroups[start:]\n\n                else:\n                    particleGroups = particleGroups[start:finish]\n\n                referenced = False\n\n                cancelled = 0\n\n                for nn, groupName in enumerate(particleGroups):\n                    nn += cancelled\n\n                    if 100 * nn//len(particleGroups) in nummers:\n                        currentTime = time.time() - scanStart\n                        mins = int(currentTime/60)\n                        secs = np.round((currentTime % 60)*100)/100\n                        print('%s%% (%s particles) complete in %s min %s sec' % (nummers[0], nn, mins, secs))\n                        nummers = nummers[1:]\n\n                    particleGroup = scan[groupName]\n                    \n                    if dParticleFormat not in particleGroup.keys():\n                        for dSetName in particleGroup.keys():\n                            if dSetName.startswith('alinger.z_scan') or dSetName.startswith('zScan'):\n                                dParticleFormat = dSetName\n                                \n                    try:\n                        zScan = particleGroup[dParticleFormat]\n                    \n                        x = zScan.attrs['wavelengths']\n                        bg = zScan.attrs['background']\n                        ref = zScan.attrs['reference']\n\n                    except:\n                        print('Z-Stack not found in %s' % (groupName))\n                        cancelled += 1\n                        continue\n\n                    if referenced == False:\n\n                        for key in zScan.attrs.keys():\n                            attrs[key] = zScan.attrs[key]\n\n                        x = zScan.attrs['wavelengths']\n                        bg = zScan.attrs['background']\n                        ref = zScan.attrs['reference']\n                        ref -= bg\n                        ref = np.where(ref != 0, ref, 1)\n                        try:\n                            dz = zScan.attrs['dz']\n                        except:\n                            if len(zScan) == 10:\n                                dz = np.linspace(-3, 3, 10)\n                            else:\n                                dz = np.linspace(-2.7, 2.7, (len(zScan)))\n\n                        referenced = True\n\n                    z = zScan[()] - bg #Background subtraction of entire z-scan\n                    z /= ref #Normalise to reference\n\n                    if raiseExceptions == True:\n                        centered = checkCentering(z, dz = dz)\n\n                    else:\n                        try:\n                            centered = checkCentering(z, dz = dz)\n\n                        except Exception as e:\n                            print('Alignment check failed for Particle %s because %s' % (nn, e))\n                            centered = False\n\n                    y, zProfile = condenseZscan(z, returnMaxs = extractZ, dz = dz, aligned = centered, avgZScans = avgZScans)\n                    \n                    if extractZ == True:\n                        zProfiles.append(zProfile)\n\n                    if centered == False:\n                        dodgyParticles.append(nn)\n                        dodgyCount += 1\n\n                        if 0 < dodgyCount < 50:\n                            print('Particle %s not centred properly or too close to another' % nn)\n\n                        elif dodgyCount == 50:\n                            print('\\nMore than 50 dodgy Z scans found. I\\'ll stop clogging up your screen. Assume there are more.\\n')\n\n                    spectra.append(y)\n                    if returnIndividual == True:\n                        gSpectrum = gIndScan.create_dataset('Spectrum %s' % nn, data = y)\n                        gSpectrum.attrs['wavelengths'] = x\n                        gSpectrum.attrs['Properly centred?'] = centered\n                        gSpectrum.attrs['Z Profile'] = zProfile\n\n                currentTime = time.time() - scanStart\n\n                mins = int(currentTime/60)\n                secs = (np.round((currentTime % 60)*100))/100\n                print('100%% (%s particles) complete in %s min %s sec' % (nn, mins, secs))\n                percentDefocused = old_div(100 * len(dodgyParticles), len(spectra))\n\n                if old_div(percentDefocused, 100) > dodgyThreshold:\n                    alignment = 'Poor'\n                    print('\\n\\n***Warning: lots of messy spectra (~%s%%). Data may not be reliable. Check nanoparticle alignment***\\n' % percentDefocused)\n\n                else:\n                    alignment = 'Good'\n\n                print('\\nAdding condensed spectra to %s/spectra...' % scanName)\n\n                spectra = np.array(spectra)\n                dScan = gScan.create_dataset('spectra', data = spectra)\n                dScan.attrs['Collection spot alignment'] = alignment\n                dScan.attrs['Misaligned particle numbers'] = dodgyParticles\n                dScan.attrs['%% particles misaligned'] = percentDefocused       \n\n                dScan.attrs.update(attrs)\n\n                print(f'{len(spectra)} spectra condensed and added to summary file\\n')\n\n    return outputFile",
  "def collectPlBackgrounds(inputFile):\n    '''inputFile must be open hdf5 file object'''\n\n    gPlBg = inputFile['PL Background']\n\n    powerDict = {}\n    freqDict = {}\n\n    for key in list(gPlBg.keys()):\n        dPlBg = gPlBg[key]\n\n        if 'laser_power' in list(dPlBg.attrs.keys()):\n            laserPower = dPlBg.attrs['laser_power']\n\n        else:\n            laserPower = int(key.split(' ')[1].split('_')[0])\n\n        if laserPower in list(powerDict.keys()):\n            freqDict[laserPower] += 1\n            powerDict[laserPower] += dPlBg[()]\n\n        else:\n            freqDict[laserPower] = 1\n            powerDict[laserPower] = dPlBg[()]\n\n    for key in list(powerDict.keys()):\n        powerDict[laserPower] /= freqDict[laserPower]\n\n    return powerDict",
  "def threshold(array, threshold):\n    return np.where(array > threshold, array, threshold)",
  "def getFWHM(x, y, fwhmFactor = 1.1, smooth = False, peakpos = 0):\n    '''Estimates FWHM of largest peak in a given dataset'''\n    '''Also returns xy coords of peak'''\n\n    if smooth == True:\n        y = butterLowpassFiltFilt(y)\n\n    maxdices = detectMinima(-y)\n\n    if len(maxdices) == 0:\n\n        if peakpos != 0:\n            maxdices = np.array([abs(x - peakpos).argmin()])\n\n        else:\n            return None, None, None\n\n    yMax = y[maxdices].max()\n    halfMax = old_div(yMax,2)\n    maxdex = maxdices[y[maxdices].argmax()]\n    xMax = x[maxdex]\n\n    halfDex1 = abs(y[:maxdex][::-1] - halfMax).argmin()\n    halfDex2 = abs(y[maxdex:] - halfMax).argmin()\n\n    xHalf1 = x[:maxdex][::-1][halfDex1]\n    xHalf2 = x[maxdex:][halfDex2]\n\n    hwhm1 = abs(xMax - xHalf1)\n    hwhm2 = abs(xMax - xHalf2)\n    hwhms = [hwhm1, hwhm2]\n\n    hwhmMax, hwhmMin = max(hwhms), min(hwhms)\n\n    if hwhmMax > hwhmMin*fwhmFactor:\n        fwhm = hwhmMin * 2\n\n    else:\n        fwhm = sum(hwhms)\n\n    return fwhm, xMax, yMax",
  "def gaussian(x, height, center, fwhm, offset = 0):\n\n    '''Gaussian as a function of height, centre, fwhm and offset'''\n    a = height\n    b = center\n    c = fwhm\n\n    N = 4*np.log(2)*(x - b)**2\n    D = c**2\n    F = -(old_div(N, D))\n    E = np.exp(F)\n    y = a*E\n    y += offset\n\n    return y",
  "def trapInt(x, y):\n    '''Calculates area under curve using trapezoid method'''\n    '''x and y must have same first dimension'''\n\n    area = 0\n\n    for n, i in enumerate(x[:-1]):\n        h = x[n + 1] - x[n]\n        a = y[n]\n        b = y[n + 1]\n        area += old_div(h*(a + b),2)\n\n    return area",
  "def boltzmann(x, height, center, x0 = 0):\n    '''\n    Maxwell-Boltzmann probability density function with xmax (center), ymax (height) and x offset (x0) as inputs\n    '''\n    X = x - x0\n    center = center - x0\n    a = center/np.sqrt(2)\n    A = height*np.sqrt(np.pi/2)*(a*np.exp(1)/2)\n    return A*np.sqrt(2/np.pi)*(X**2*np.exp(-X**2/(2*a**2)))/a**3",
  "def baseline_als(y, lam, p, niter=10):\n    L = len(y)\n    D = sparse.diags([1,-2,1],[0,-1,-2], shape=(L,L-2))\n    w = np.ones(L)\n    for i in range(niter):\n        W = sparse.spdiags(w, 0, L, L)\n        Z = W + lam * D.dot(D.transpose())\n        z = spsolve(Z, w*y)\n        w = p * (y > z) + (1-p) * (y < z)\n    return z",
  "def approximateLaserBg(xPl, yPl, yDf, plRange = [540, 820], plot = False):\n    xTrunc, yTrunc = truncateSpectrum(xPl, yPl, startWl = 505, finishWl = plRange[1])#removes spike from laser leak\n    x2, y2 = truncateSpectrum(xPl, yPl, startWl = plRange[1], finishWl = 900)\n    xDfTrunc, yDfTrunc = truncateSpectrum(xPl, yDf, startWl = 505)\n    yDfSmooth = mpf.butterLowpassFiltFilt(yDfTrunc)\n    \n    dfMax = yDfSmooth.max()\n    \n    if np.isfinite(dfMax):\n        yDfNorm = yDf/dfMax\n    else:\n        dfMax = yDfTrunc.max()\n        yDfNorm = yDf/dfMax\n    \n    for xN, yN in zip(xDfTrunc, yDfTrunc):\n        if not np.isfinite(yN):\n            #print(f'nan value at {xN} nm for {groupName}')\n            plt.plot(xDfTrunc, yDfTrunc)\n            #plt.title(groupName)\n            plt.show()\n        \n    yDfNorm = np.where(yDfNorm >= 0, np.sqrt(abs(yDfNorm)), -np.sqrt(abs(yDfNorm)))\n    yDfNorm = np.where(yDfNorm != 0, yDfNorm, np.nan)\n    yPl /= yDfNorm\n    yRef = mpf.removeNaNs(yPl)\n    \n    x1, y1 = truncateSpectrum(xPl, yRef, startWl = 505, finishWl = plRange[0])\n\n    \n    xJoin = np.concatenate((x1, x2))\n    yJoin = np.concatenate((y1, y2))\n    yJoinMin = np.average(y2[-len(y2)//5:])\n    yJoin -= max(yJoinMin, 1e-4)\n    #xJoin = x2\n    #yJoin = y2\n\n    expMod0 = ExponentialModel(prefix = 'Exp0_')\n    expPars = expMod0.make_params(Exp0_amplitude = 1.6e23, Exp0_decay = 8.5)\n    expPars['Exp0_amplitude'].set(min = 0)\n\n    expMod1 = ExponentialModel(prefix = 'Exp1_')\n    expPars1 = expMod1.make_params(Exp1_amplitude = 2, Exp1_decay = 90)\n    expPars1['Exp1_amplitude'].set(min = 0)\n\n    expMod = expMod0 + expMod1\n    expPars.update(expPars1)\n    initFit = expMod.eval(expPars, x = xTrunc)\n\n    expOut = expMod.fit(yJoin, expPars, x = xJoin, nan_policy = 'propagate')\n    yFit = expOut.eval(x = xPl)\n    yFit += yJoinMin\n    yOut = yPl - yFit\n    yOut = mpf.removeNaNs(yOut)\n\n    if plot == True:\n        fig, (ax0, ax1, ax2) = plt.subplots(3, sharex = True, figsize = (10, 12))\n        ax_df = ax0.twinx()\n        yTruncSub = truncateSpectrum(xPl, yOut, startWl = 505, finishWl = plRange[1])[1]\n        ax2.plot(xTrunc, yTruncSub, label = 'PL (Processed)', color = plt.cm.Dark2(0))\n        yTruncFit = truncateSpectrum(xPl, yFit, startWl = 505, finishWl = plRange[1])[1]\n        ax0.plot(xTrunc, yTrunc, label = 'PL (Raw)', color = plt.cm.Dark2(1))\n        yTruncRef = truncateSpectrum(xPl, yPl, startWl = 505, finishWl = plRange[1])[1]\n        refPlot = ax1.plot(xTrunc, yTruncRef, label = 'PL (Corrected)', color = plt.cm.Dark2(2))\n        ax1.plot(x2, y2, color = refPlot[0].get_color())\n        xDf, yDf = truncateSpectrum(xPl, yDf, startWl = 505, finishWl = plRange[1])\n        ax_df.plot(xDf, yDf, 'k', alpha = 0.5)\n        ax0.plot([], 'k', alpha = 0.5, label = 'DF Spectrum')\n        comps = expOut.eval_components(x = xTrunc)\n        #print(expOut.params)\n        for compN, compName in enumerate(comps.keys()):\n            ax1.plot(xTrunc, comps[compName] + yJoinMin, '--', label = f'Exp {compN}', color = plt.cm.Dark2(4 + compN))\n        ax1.plot(xTrunc, yTruncFit, label = 'Exp Sum', color = plt.cm.Dark2(3))\n        #ax1.plot(xTrunc, initFit, 'k--', label = 'init')\n\n        ax1.legend()\n        ax0.legend(loc = 'upper left', bbox_to_anchor = (0.15, 1))\n        ax2.legend()\n        ax1.set_ylabel('PL Intensity')\n        ax_df.set_ylabel('DF Intensity', rotation = 270, va = 'bottom')\n        ax2.set_xlim(505, plRange[1])\n        ax2.set_ylim(bottom = 0)\n        ax2.set_xlabel('Wavelength (nm)')\n\n        for ax in (ax0, ax1, ax2, ax_df):\n            ax.set_yticks([])\n\n        plt.subplots_adjust(hspace = 0)\n        plt.show()\n\n    return yOut, yRef",
  "def subtractPlBg(xPl, yPl, plBg, xDf, yDf, remove0 = False, returnArea = True, startWl = 505):\n    plBg = truncateSpectrum(xPl, plBg, startWl = startWl, finishWl = 1000)[1]\n    xDf, yDf = truncateSpectrum(xDf, yDf, startWl = startWl, finishWl = 1000)\n    yDf = threshold(yDf, 2e-4)\n    xPl, yPl = truncateSpectrum(xPl, yPl, startWl = startWl, finishWl = 1000)\n\n    fig, ax1 = plt.subplots()\n    ax2 = ax1.twinx()\n    \n    ax2.plot(xDf, yDf, 'k', alpha = 0.5)\n    #ax1.plot(xPl, plBg)\n\n    bgMin = np.average(plBg[-10:])\n    yMin = np.average(yPl[-10:])    \n\n    bgScaled = plBg - bgMin\n\n    ySub = yPl - yMin\n    ax1.plot(xPl, ySub, 'k', lw = 2)\n\n    bgScale = ySub[0]/bgScaled[0]\n\n    bgScaled *= bgScale\n    bgScaled += yMin\n    ax1.plot(xPl, bgScaled)\n\n    ySub = yPl - bgScaled\n    yRef = ySub/np.sqrt(yDf/yDf.max())\n\n    ySmooth = butterLowpassFiltFilt(yRef, cutoff = 1000, fs = 90000)\n    xTrunc, yTrunc = truncateSpectrum(xPl, ySmooth, startWl = startWl, finishWl = 600)\n\n    fwhm, center, height = getFWHM(xTrunc, yTrunc, smooth = True, peakpos = 545)\n    yBoltz = boltzmann(xPl, height, center, x0 = startWl)\n\n    if remove0 == True:\n        yRef -= yBoltz\n\n    plt.show()\n\n    if returnArea == True:\n        area = trapInt(xPl, yPl)\n        return xPl, yRef, yBoltz, area, bgScale\n\n    return xPl, yRef, yBoltz",
  "def exponential(x, amp, shift, decay, const):\n    '''y = const + amp when x = 0'''\n    '''stepth of curve inversely proportional to decay'''\n    return const + (amp*np.exp(old_div(-(x-shift),decay)))",
  "def removeLaserLeak(x, y, plotAll = False, plotFinal = False, plRange = [580, 850]):\n\n    def loss(decays):\n        '''x and y must be externally defined'''\n        diff = approximateLaserBg(x, y, decays = decays, optimise = True, plot = False)[-1]\n        return diff\n\n    decaysGuess = [50, 50, 50]\n    decays = spo.minimize(loss, decaysGuess, bounds = [(30, 70)] * 3).x\n\n    xTrunc, yBld = approximateLaserBg(x, y, decays = decays, plot = plotAll)\n\n    if plotFinal == True:\n        plt.plot(xTrunc, yBld)\n        plt.show()\n\n    return xTrunc, yBld",
  "def transferPlSpectra(rootDir, start = 0, finish = 0, startWl = 505, plRange = [580, 820], \n                      plGroupName = 'PL Spectra', laserBgPlot = False):\n\n    os.chdir(rootDir)\n\n    try:\n        inputFile = mpf.findH5File(rootDir, nameFormat = 'date')\n    except:\n        print('File not found')\n        return\n\n    print('\\nAbout to extract PL data from %s' % inputFile)\n    print('\\tLooking for summary file...')\n\n    outputFile = mpf.findH5File(rootDir, nameFormat = 'summary')\n\n    if outputFile == None:\n        print('\\tNo summary file exists; creating a new one')\n        outputFile = createOutputFile('summary')\n\n    with h5py.File(inputFile, 'a') as ipf:\n\n        if 'particleScans' in ipf.keys():\n            fileType = 'pre-2018'\n\n        elif 'nplab_log' in list(ipf.keys()):\n            fileType = 'post-2018'\n\n        else:\n            print('File format not recognised')\n            return\n\n        with h5py.File(outputFile, 'a') as opf:\n\n            if 'NPoM PL Spectra' not in list(opf.keys()):\n                opf.create_group('NPoM PL Spectra')\n\n            gPl = opf['NPoM PL Spectra']\n            gAllPl = opf['particleScanSummaries']\n\n            if fileType == 'pre-2018':\n                ipf = ipf['particleScans']\n                gScanFormat = 'scan'\n                gParticleFormat = 'z_scan_'\n\n            elif fileType == 'post-2018':\n                gScanFormat = 'ParticleScannerScan_'\n                gParticleFormat = 'Particle_'\n\n\n            allScans = sorted([groupName for groupName in list(ipf.keys()) if groupName.startswith(gScanFormat)],\n                              key = lambda groupName: len(list(ipf[groupName].keys())))[::-1]\n            dParticleFormat = None\n            if fileType == 'post-2018':\n                particleN = 0\n                while dParticleFormat is None:                    \n                    for dSetName in list(ipf[allScans[0]][f'Particle_{particleN}'].keys()):\n                        if dSetName.startswith('alinger.z_scan') or dSetName.startswith('zScan'):\n                            dParticleFormat = dSetName\n                            break\n                    \n                    particleN += 1\n\n            for n, scanName in enumerate(allScans):\n\n                if len(ipf[scanName]) < 15:\n                    continue\n\n                if 'scan%s' % n not in list(gPl.keys()):\n                    gPl.create_group('scan%s' % n)\n\n                gPlScan = gPl['scan%s' % n]\n\n                if 'scan%s' % n not in list(gAllPl.keys()):\n                    gPl.create_group('scan%s' % n)\n\n                gAllPlScan = gAllPl['scan%s' % n]\n\n                scan = ipf[scanName]\n                particleGroups = sorted([groupName for groupName in list(scan.keys()) if groupName.startswith(gParticleFormat)],\n                                key = lambda groupName: int(groupName.split('_')[-1]))\n\n                print('%s particles found in %s' % (len(particleGroups), scanName))\n                x_temp = opf[f'particleScanSummaries/scan{n}/spectra'].attrs['wavelengths']\n\n                if finish == 0:\n                    particleGroups = particleGroups[start:]\n\n                else:\n                    particleGroups = particleGroups[start:finish]\n\n                nummers = list(range(10, 101, 10))\n                scanStart = time.time()\n\n                plSpectra = []\n                \n                for nn, groupName in enumerate(particleGroups):\n                    if nn > 25 and len(plSpectra) == 0:\n                        print('\\nNo PL Spectra detected after 25 particles. Setting PL = False')\n                        print()\n                        pl = False\n                        return outputFile, pl\n\n                    particleGroup = scan[groupName]\n                    plGroupNames = [i for i in ['dark field with irradiation', 'PL Spectra'] if i in particleGroup.keys()]\n                    \n                    if len(plGroupNames) > 0:\n                        plGroupName = plGroupNames[0]\n                        if nn == 0:\n                            print(plGroupName)\n                    \n                    if dParticleFormat not in particleGroup.keys():\n                        for dSetName in particleGroup.keys():\n                            if dSetName.startswith('alinger.z_scan') or dSetName.startswith('zScan'):\n                                dParticleFormat = dSetName\n                                                    \n                    if dParticleFormat not in particleGroup.keys():\n                        print(f'No Z-Stack in {groupName}')                    \n                        y_temp = np.zeros(len(x_temp))\n                        plSpectra.append(y_temp)\n                        plSpecName = f'PL Spectrum {nn}'\n                        \n                        if plSpecName not in list(gPlScan.keys()):\n                            gPlScan.create_dataset(plSpecName, data = y_temp)\n\n                        dPl = gPlScan[plSpecName]\n                        dPl.attrs['wavelengths'] = x_temp\n                        continue\n\n                    bg = particleGroup[dParticleFormat].attrs['background']\n                    ref = particleGroup[dParticleFormat].attrs['reference']\n\n                    if int(old_div(100 * nn, len(particleGroups))) in nummers:\n                        currentTime = time.time() - scanStart\n                        mins = int(old_div(currentTime, 60))\n                        secs = old_div((np.round((currentTime % 60)*100)),100)\n                        print('%s%% (%s spectra) transferred in %s min %s sec' % (nummers[0], nn, mins, secs))\n                        nummers = nummers[1:]\n\n                    if plGroupName not in particleGroup.keys():\n                        print(f'{plGroupName} not found in {groupName}')\n                        print('No PL spectra in %s' % (groupName))\n                        y_temp = np.zeros(len(x_temp))\n                        plSpectra.append(y_temp)\n                        plSpecName = f'PL Spectrum {nn}'\n                        \n                        if plSpecName not in list(gPlScan.keys()):\n                            gPlScan.create_dataset(plSpecName, data = y_temp)\n\n                        dPl = gPlScan[plSpecName]\n                        dPl.attrs['wavelengths'] = x_temp\n                        continue\n\n                    plGroup = particleGroup[plGroupName]\n\n                    maxDict = {}\n                    plSpecNames = [i for i in list(plGroup.keys()) if i.startswith('PL')]\n\n                    if len(plSpecNames) == 0:\n                        print('No PL spectrum found for %s' % groupName)\n                        y_temp = np.zeros(len(x_temp))\n                        plSpectra.append(y_temp)\n                        plSpecName = f'PL Spectrum {nn}'\n                        \n                        if plSpecName not in list(gPlScan.keys()):\n                            gPlScan.create_dataset(plSpecName, data = y_temp)\n\n                        dPl = gPlScan[plSpecName]\n                        dPl.attrs['wavelengths'] = x_temp\n                        continue\n\n                    for specName in plSpecNames:\n                        plData = plGroup[specName]\n\n                        if 'wavelengths' not in list(plData.attrs.keys()):\n                            try:\n                                plData.attrs['wavelengths'] = scan['Particle_0/%s' % dParticleFormat].attrs['wavelengths']\n\n                            except Exception as e:\n                                print('Unable to find wavelength data (%s)' % e)\n\n                        x = plData.attrs['wavelengths']\n                        y = plData[()]\n\n                        xTrunc, yTrunc = truncateSpectrum(x, y, startWl = plRange[0], finishWl = plRange[1])\n                        ySmooth = butterLowpassFiltFilt(y)\n                        maxima = detectMinima(-ySmooth)\n\n                        if len(maxima) == 0:\n                            continue\n\n                        yAvg = np.average(ySmooth[maxima])\n                        maxDict[yAvg] = specName\n\n                    if len(maxDict.keys()) > 0:\n                        maxPlName = maxDict[max(maxDict.keys())]\n                    else:\n                        print(groupName, plGroup.keys())\n                        maxPlName = plSpecNames[0]\n\n                    plData = plGroup[maxPlName]\n                    \n                    try:\n                        bg = plData.attrs.get('background', bg)\n                        ref = plData.attrs.get('reference', ref)\n                        xPl = plData.attrs['wavelengths']\n                        timeStamp = plData.attrs['creation_timestamp']\n                        laserPower = plData.attrs['laser_power']\n                        plSpecName = f'PL Spectrum {nn}'\n                    except Exception as e:\n                        plSpecName = f'PL Spectrum {nn}'\n                        print(f'{plSpecName} transfer failed because {e}')\n\n                    yRaw = (plData[()] - bg)/ref\n                    dfBefore = opf[f'Individual NPoM Spectra/scan0/Spectrum {nn}']\n                    xDf = dfBefore.attrs['wavelengths']\n                    yDf = dfBefore[()]\n\n                    yPl, yRef = approximateLaserBg(xPl, yRaw, yDf, plRange = plRange, plot = laserBgPlot)\n                    \n                    #xPl, yRef, yBoltz, area, bgScale = subtractPlBg(xPl, y, plBg, xDf, yDf, remove0 = False, returnArea = True)\n                    plSpectra.append(yPl)\n\n                    if plSpecName not in list(gPlScan.keys()):\n                        gPlScan.create_dataset(plSpecName, data = yPl)\n\n                    dPl = gPlScan[plSpecName]\n                    dPl.attrs['wavelengths'] = xPl\n                    dPl.attrs['Raw Spectrum'] = yRef\n                    #dPl.attrs['Total Area'] = area\n                    #dPl.attrs['Background Scale Factor'] = bgScale\n\n                    attrNames = ['creation_timestamp', 'integration_time', 'laser_power', 'model_name', 'serial_number', 'tec_temperature']\n\n                    for attrName in attrNames:\n                        if attrName in plData.attrs.keys():\n                            dPl.attrs[attrName] = plData.attrs[attrName]\n\n                    '''if dParticleFormat in particleGroup.keys():\n                        dfData = particleGroup[dParticleFormat]\n\n                        x = dfData.attrs['wavelengths']\n                        z = dfData[()] - bg\n                        z /= ref\n                        try:\n                            dz = dfData.attrs['dz']\n                        except:\n                            if len(z) == 10:\n                                dz = np.linspace(-3, 3, 10)\n                            else:\n                                dz = np.linspace(-2.7, 2.7, (len(z)))\n                                \n                        dfData = condenseZscan(z, dz = dz)\n\n                    else:\n                        dfSpecNames = [specName for specName in list(plGroup.keys()) if specName.startswith('DF') and\n                                       plGroup[specName].attrs['creation_timestamp'] > timeStamp]\n\n                        if len(dfSpecNames) > 0:\n                            dfSpecName = dfSpecNames[1]\n                            dfData = plGroup[dfSpecName][()]\n\n                            if dfData.max() > 777:\n                                dfData = dfData - bg #Background subtraction\n                                dfData /= ref #Normalise to reference\n\n                        else:\n                            dfData = 'N/A' \n\n                    dPl.attrs['DF After'] = dfData#truncateSpectrum(x, dfData, startWl = startWl, finishWl = 1000)[1]'''\n                \n                plSpectra = np.array(plSpectra)\n                dAll = gAllPlScan.create_dataset('PL spectra', data = plSpectra)\n                dAll.attrs['laser_power'] = laserPower\n                #dAll.attrs['Average PL Background'] = plBgDict[laserPower]\n                dAll.attrs['wavelengths'] = xPl\n                print(f'\\t{len(plSpectra)} PL spectra transferred to summary file')\n\n    currentTime = time.time() - scanStart\n    mins = int(old_div(currentTime, 60))\n    secs = old_div((np.round((currentTime % 60)*100)),100)\n    print('100%% complete in %s min %s sec' % (mins, secs))\n\n    \n\n    return outputFile, True",
  "def getState(a, b):\n        if a < b: return rising\n        if a > b: return falling\n        return neutral",
  "def loss(decays):\n        '''x and y must be externally defined'''\n        diff = approximateLaserBg(x, y, decays = decays, optimise = True, plot = False)[-1]\n        return diff",
  "def closest(iterable, val):\n    ''' return the closest element in an iterable to val'''\n    return min(iterable, key=lambda e: abs(e - val))",
  "def closest_index(iterable, val):\n    ''' return its index'''\n    return min(enumerate(iterable), key=lambda i_e: abs(i_e[0] - val))[1]",
  "def forMatches(i, nameFormat, extension = ['h5', 'hdf5']):\n    '''Checks if a filename begins with a specified string and ends with specified extension(s)'''\n    if type(extension) == str:\n        extension = [extension]\n    if i.split('.')[-1] not in extension:\n        return False\n    if nameFormat == 'date':\n        return bool(re.match('\\d\\d\\d\\d-[01]\\d-[0123]\\d', i[:10]))\n    else:\n        return i.startswith(nameFormat)",
  "def findH5File(rootDir, mostRecent = True, nameFormat = 'date', printProgress = True, extension = 'h5'):\n    '''\n    Finds either oldest or most recent file in a folder using specified name format and extension, using forMatches() above\n    Default name format ('date') is yyyy-mm-dd, default extension is .h5\n    '''\n    os.chdir(rootDir)\n\n    if printProgress == True:\n        print(f'Searching for {\"most recent\" if mostRecent == True else \"oldest\"} instance of {\"yyyy-mm-dd\" if nameFormat == \"date\" else nameFormat}(...){extension}...')\n\n    h5Files = sorted([i for i in os.listdir() \n                      if forMatches(i, nameFormat, extension = ['h5', 'hdf5'] if extension == 'h5' else extension)],#finds list of filenames with yyyy-mm-dd(...).h(df)5 format\n                      key = lambda i: os.path.getmtime(i))#sorts them by date and picks either oldest or newest depending on value of 'mostRecent'\n\n    if len(h5Files) > 0:\n        h5File = h5Files[-1 if mostRecent == True else 0]\n        if printProgress == True:\n            print(f'\\tH5 file {h5File} found\\n')\n    else:\n        h5File = None\n        if printProgress == True:\n            print(f'\\tH5 file with name format \"{nameFormat}\" not found in {os.getcwd()}\\n')\n    \n    return h5File",
  "def removeNaNs(y, buff = True, cutoff = 1500, fs = 60000, nBuff = None):\n    '''\n    Replaces NaN values in n-dimensional array\n    if buff != False or nBuff != False: (better for noisy data)\n        replaces NaNs with values from smoothed array\n        (nBuff is included for compatibility with older codes calling this function)\n    else: (better for clean data)\n        replaces NaNs with linear interpolation between adjacent points\n\n    Input = 1D array or list.\n    Output = copy of same array/list with no NaNs\n    Array size is preserved\n    '''\n\n    y = np.array(y)\n\n    if nBuff is not None:\n        buff = nBuff\n\n    if len(np.shape(y)) > 1:\n        y = np.array([removeNaNs(ySub, buff = buff, cutoff = cutoff, fs = fs) for ySub in y])\n\n    if len(np.where(np.isnan(y))[0]) == 0:\n        return y\n\n    elif not np.any(np.isfinite(y)):\n        print('Entire array is NaNs!')\n        return y\n\n    x = np.arange(0, len(y))\n    yTrunc = np.delete(y, np.where(np.isnan(y)))\n    xTrunc = np.delete(x, np.where(np.isnan(y)))\n    yInterp = np.interp(x, xTrunc, yTrunc)\n    \n    if buff:\n        ySmoothInterp = butterLowpassFiltFilt(yInterp, cutoff = cutoff, fs = fs)\n        yInterp = np.where(np.isnan(y), ySmoothInterp, y)\n\n    return yInterp",
  "def removeCosmicRays(x, y, reference = 1, factor = 15, chonk = 1):\n\n    '''\n    Looks for large sharp spikes in spectrum via 1st derivative\n    Threshold of \"large\" determined by 'factor'; smaller factor picks up more peaks but also more false positives\n    If correecting a referenced DF spectrum (or similar), reference = reference spectrum (1D array). Otherwise, reference= 1\n    Erases a small window around each spike and replaces it with a straight line via the removeNaNs function\n    '''\n\n    newY = np.copy(y)\n    cosmicRay = True#Guilty until proven innocent\n    iteration = 0\n    rayDex = 0\n    nSteps = chonk\n\n    while cosmicRay == True and iteration < 20:\n        d1 = centDiff(x, newY)#takes dy/dx via central difference method\n        d1 *= np.sqrt(reference)#de-references the spectrum to enhance cosmic ray detection in noisy regions\n\n        d1 = abs(d1)#takes magnitude of first derivative\n        d1Med = np.median(d1)#finds median gradient -> dy/dx should be larger than this for a cosmic ray\n\n        if old_div(max(d1),d1Med) > factor:#if the maximum dy/dx value is more than a certain mutliple of the median, a cosmic ray exists\n            oldRayDex = rayDex\n            rayDex = d1.argmax() - 1#cosmic ray spike happens just before largest |dy/dx| value\n\n            if abs(rayDex - oldRayDex) < 5:#if a cosmic ray still exists near where the old one was 'removed':\n                nSteps += 1#the erasure window is iteratively widened\n\n            else:#otherwise, just clean up to one data point either side\n                nSteps = chonk\n\n            iteration += 1\n\n            for i in np.linspace(0 - nSteps, nSteps, 2*nSteps + 1):#for a window centred around the spike\n                if rayDex + int(i) < len(newY):\n                    newY[rayDex + int(i)] = np.nan #erase the data points\n\n            newY = removeNaNs(newY)#linearly interpolate between data points adjacent to the spike\n\n        else:#if no 'large' spikes exist in the spectrum\n            cosmicRay = False #no cosmic rays left to fix\n\n    return newY",
  "def truncateSpectrum(x, y, startWl = 450, endWl = 900, xOnly = False, buff = 0, **kwargs):\n    '''\n    Truncates xy data spectrum within a specified wavelength range\n    Useful for removing high and low-end noise or analysing certain spectral regions\n    x and y must be 1D array-like objects of identical length\n    Default range is 450-900 nm (good for lab 3)\n    If y == None, (specifically, if type(y) == type(None)) or xOnly == True, function returns truncated x array only\n    Zeros added to start/end of arrays if startWl or finishWl lie outside the x range. \n        Set buff = 1 to replace zero with initial/final y vals instead\n        Sef buff = False to disable this and only return data inside the x range\n    '''\n\n    if 'finishWl' in kwargs.keys():\n        endWl = kwargs['finishWl']\n\n    x = np.array(x)\n    if buff != 0:\n        if buff == None:\n            startWl = max(startWl, x.min())\n            endWl = min(endWl, x.max())\n\n    if type(y) == type(None) or xOnly == True:\n        xOnly = True\n        y = np.zeros(len(x))\n\n    y = np.array(y)\n\n    reverse = False\n\n    if x[0] > x[-1]:#if x is in descending order, x and y are reversed\n        reverse = True\n        x = x[::-1]\n        y = y[::-1]\n\n    if x[0] > startWl:#if truncation window extends below spectral range:\n        xStart = np.arange(x[0], startWl - 2, x[0] - x[1])[1:][::-1]\n        if buff == 0:\n            yStart = np.zeros(len(xStart))\n        elif buff == 'nan':\n            yStart = np.zeros(len(xStart))\n            yStart *= np.nan\n        else:\n            yStart = np.array([np.average(y[:5])] * len(xStart))\n        x = np.concatenate((xStart, x))\n        y = np.concatenate((yStart, y))#Adds buffer to start of x and y to ensure the truncated length is still defined by startWl and finishWl\n\n    if x[-1] < endWl:#if truncation window extends above spectral range:\n        xFin = np.arange(x[-1], endWl + 2, x[1] - x[0])[1:]\n        if buff == 0:\n            yFin = np.zeros(len(xFin))\n        elif buff == 'nan':\n            yFin = np.zeros(len(xFin))\n            yFin *= np.nan\n        else:\n            yFin = np.array([np.average(y[-5:])] * len(xFin))\n        x = np.concatenate((x, xFin))\n        y = np.concatenate((y, yFin))#Adds buffer to end of x and y to ensure the truncated length is still defined by startWl and finishWl\n\n    startIndex = (abs(x - startWl)).argmin()#finds index corresponding to startWl\n    finishIndex = (abs(x - endWl)).argmin()#index corresponding to finishWl\n\n    xTrunc = np.array(x[startIndex:finishIndex])#truncates x using these indices\n    yTrunc = np.array(y[startIndex:finishIndex])#truncates y using these indices\n\n    if reverse == True:#if the spectrum had to be reversed earlier, this flips it back.\n        xTrunc = xTrunc[::-1]\n        yTrunc = yTrunc[::-1]\n\n    if xTrunc.size <= 10 and x.size <= 100:#sometimes fails for very short arrays; this extra bit works better in those cases\n\n        if startWl > endWl:\n            wl1 = endWl\n            wl2 = startWl\n            startWl = wl1\n            endWl = wl2\n\n        xTrunc, yTrunc = np.transpose(np.array([[i, y[n]] for n, i in enumerate(x) if startWl < i < endWl]))\n\n    if xOnly == True:\n        return xTrunc\n\n    return np.array([xTrunc, yTrunc])",
  "def retrieveData(directory, summaryNameFormat = 'summary', first = 0, last = 0, attrsOnly = False, \n                 customScan = None):\n\n    '''\n    Retrieves darkfield data and metadata from summary file\n    Use 'first' and 'last' to truncate dataset if necessary. Setting last = 0 -> last = (end of dataset). Useful if initial spectra failed or if someone switched the lights on in the morning\n    '''\n\n    summaryFile = findH5File(directory, nameFormat = summaryNameFormat)#looks for most recent file titled 'summary(...).h(df)5 in current directory\n\n    if attrsOnly == False:\n        print('Retrieving data...')\n\n    else:\n        print('Retrieving sample attributes...')\n\n    with h5py.File(summaryFile, 'a') as f: # opens summary file\n        \n        if customScan is None:\n            mainDatasetName = sorted([scan for scan in list(f['particleScanSummaries/'].keys())],\n                               key = lambda scan: len(f['particleScanSummaries/'][scan]['spectra']))[-1]#finds largest datset. Useful if you had to stop and start your particle tracking before leaving it overnight\n        else:\n            mainDatasetName = f'scan{customScan}'\n            \n        mainDataset = f['particleScanSummaries/'][mainDatasetName]['spectra']#opens dataset object\n        summaryAttrs = {key : mainDataset.attrs[key] for key in list(mainDataset.attrs.keys())}#creates python dictionary from dataset attributes/metadata\n\n        if attrsOnly == True:#If you only want the metadata to update your main output file\n            print('\\tInfo retrieved from %s' % mainDatasetName)\n            print('\\t\\t%s spectra in total\\n' % len(mainDataset))\n            return summaryAttrs\n\n        if last == 0:\n            spectra = mainDataset[()][first:]\n        else:\n            spectra = mainDataset[()][first:last]#truncates dataset, if specified\n        wavelengths = summaryAttrs['wavelengths'][()]#x axis\n\n        print('\\t%s spectra retrieved from %s\\n' % (len(spectra), mainDatasetName))\n\n        print('Removing cosmic ray events...')\n\n        prepStart = time.time()\n\n        wavelengths = removeNaNs(wavelengths)#what it says on the tin\n        reference = summaryAttrs['reference']#for use in cosmic ray removal\n\n        for n, spectrum in enumerate(spectra):\n\n            try:\n                newSpectrum = removeCosmicRays(wavelengths, spectrum, reference = reference)#attempts to remove cosmic rays from spectrum\n\n                if False in np.where(newSpectrum == newSpectrum[0], True, False):#if removeCosmicRays and removeNaNs have worked properly\n                    spectra[n] = newSpectrum#replaces spectrum with cleaned up version\n\n                else:\n                    print('Cosmic ray removal failed for spectrum %s' % n)\n\n            except Exception as e:\n                print('Cosmic ray removal failed for spectrum %s because %s' % (n, e))\n                pass\n\n        prepEnd = time.time()\n        prepTime = prepEnd - prepStart\n\n        print('\\tAll cosmic rays removed in %.2f seconds\\n' % (prepTime))\n\n        print('Cleaning up NaN values...')\n\n        prepStart = time.time()\n\n        spectra = np.array([removeNaNs(spectrum) for spectrum in spectra])#Extra NaN removal in case removeCosmicRays failed\n\n        prepEnd = time.time()\n        prepTime = prepEnd - prepStart#time elapsed\n\n        print('\\tAll spectra cleared of NaNs in %.2f seconds\\n' % (prepTime))\n\n        return wavelengths, spectra, summaryAttrs",
  "def retrievePlData(directory, summaryNameFormat = 'summary', first = 0, last = 0):\n    '''\n    Retrieves photolumineasence data and metadata from summary file\n    Use 'first' and 'last' to truncate dataset if necessary. Setting last = 0 -> last = (end of dataset). Useful if initial spectra failed or if someone switched the lights on in the morning\n    '''\n    summaryFile = findH5File(directory, nameFormat = summaryNameFormat) #looks for most recent file titled 'summary(...).h(df)5 in current directory\n\n    print('Retrieving PL data...')\n\n    with h5py.File(summaryFile, 'a') as f:#Opens summary file\n\n        gPlName = sorted([scan for scan in list(f['particleScanSummaries/'].keys())],\n                           key = lambda scan: len(f['particleScanSummaries/'][scan]['spectra']))[-1]#finds largest datset. Useful if you had to stop and start your particle tracking before leaving it overnight\n        reference = f['particleScanSummaries/%s/spectra' % gPlName].attrs['reference'][()]#gets reference from DF spectra metadata\n\n        gPl = f['NPoM PL Spectra/%s' % gPlName]#opens dataset object\n\n        if last == 0:\n            last = len(list(gPl.keys()))#last = 0 -> last = (end of dataset)\n\n        dPlNames = sorted(list(gPl.keys()), key = lambda dPlName: int(dPlName.split(' ')[-1]))[first:last]#creates list of PL spectrum names within specified bounds\n        print('\\t%s PL spectra retrieved from %s\\n' % (len(dPlNames), gPlName))\n        print('Removing cosmic ray events...')\n        prepStart = time.time()\n\n        xPl = gPl[dPlNames[0]].attrs['wavelengths']#x axis\n        xPl = removeNaNs(xPl)#what it says on the tin\n\n        reference = truncateSpectrum(xPl, reference, startWl = xPl[0], finishWl = xPl[-1])[1]\n        reference = np.append(reference, reference[-1])#for processing post-PL DF\n\n        plData = np.array([gPl[dPlName][()] for dPlName in dPlNames])#collects all PL spectra of interest\n        plSpectRaw = np.array([gPl[dPlName].attrs['Raw Spectrum'][()] for dPlName in dPlNames])#collects all PL spectra of interest\n        #dfAfter = np.array([gPl[dPlName].attrs['DF After'][()] for dPlName in dPlNames])#collects corresponding DF spectra\n        #areas = np.array([gPl[dPlName].attrs['Total Area'] for dPlName in dPlNames])#corresponding integrated PL intensities\n        #bgScales = np.array([gPl[dPlName].attrs['Background Scale Factor'] for dPlName in dPlNames])#corresponding scaling factors for PL background subtraction\n\n        for n, plSpectrum in enumerate(plData):\n\n            try:\n                plSpectrum = removeCosmicRays(xPl, plSpectrum, reference = plSpectrum)#attempts to remove cosmic rays from PL spectrum\n\n                if False in np.where(plSpectrum == plSpectrum[0], True, False):#if removeCosmicRays and removeNaNs have worked properly\n                    plData[n] = plSpectrum#replaces PL spectrum with cleaned up version\n\n                else:\n                    print('Cosmic ray removal failed for PL spectrum spectrum %s' % n)\n\n            except:\n                pass\n\n        prepEnd = time.time()\n        prepTime = prepEnd - prepStart#time elapsed\n\n        print('\\tAll cosmic rays removed in %.2f seconds\\n' % (prepTime))\n        print('Cleaning up NaN values...')\n\n        prepStart = time.time()\n\n        for n, plSpec in enumerate(plData):\n            if not np.any(np.isfinite(plSpec)):\n                print(f'PL Spectrum {n + first}')\n                plt.plot(xPl, plSpec)\n                plt.show()\n\n        plData = np.array([removeNaNs(plSpec) for plSpec in plData])#Extra NaN removal in case removeCosmicRays failed\n        #dfAfter = np.array([removeNaNs(dfSpectrum) for dfSpectrum in dfAfter])#Extra NaN removal in case removeCosmicRays failed\n        #dfAfter = None\n        prepEnd = time.time()\n        prepTime = prepEnd - prepStart#time elapsed\n\n        print('\\tAll spectra cleared of NaNs in %.2f seconds\\n' % (prepTime))\n\n        return xPl, plData, plSpectRaw",
  "def determineVLims(zData, threshold = 1e-4):\n    '''\n    Calculates appropriate intensity limits for 2D plot based on frequency distribution of intensities.\n    '''\n\n    zFlat = zData.flatten()\n    frequencies, bins = np.histogram(zFlat, bins = 100, density = False)\n    freqThresh = frequencies.max()*threshold\n    binCentres = np.array([np.average([bins[n], bins[n + 1]]) for n in range(len(bins) - 1)])\n    binsThreshed = binCentres[np.nonzero(np.where((frequencies > freqThresh), frequencies, 0))]\n    vMin = binsThreshed[0]\n    vMax = binsThreshed[-1]\n\n    return vMin, vMax",
  "def plotStackedMap(x, yData, imgName = 'Stack', plotTitle = 'Stack', closeFigures = False, init = False, vThresh = 1e-4,\n                   xLims = (450, 900)):\n\n    '''\n    Plots stack of xy data.\n    x = 1d array\n    y = list/array of 1d arrays. Must all be the same length as x.\n    Stacks will be saved as [imgName].png in 'Stacks'\n    If init == False, image will be saved in current directory\n    '''\n\n    if init == True:\n        print('Plotting %s...' % imgName)\n        stackStartTime = time.time()\n\n    elif init == False:\n\n        if 'Stacks' not in os.listdir('.'):\n            os.mkdir('Stacks')\n\n    #try:\n    xStack = x # Wavelength range\n    yStack = np.arange(len(yData)) # Number of spectra\n    zStack = np.vstack(yData) # Spectral data\n\n    #vmin, vmax = determineVLims(zStack, threshold = vThresh)\n\n    fig = plt.figure(figsize = (9, 7))\n\n    plt.pcolormesh(xStack, yStack, zStack, cmap = 'inferno', vmin = 0, vmax = 6)\n    plt.xlim(xLims)\n    plt.xlabel('Wavelength (nm)', fontsize = 14)\n    plt.ylabel('Spectrum #', fontsize = 14)\n    cbar = plt.colorbar()\n    cbar.set_ticks([])\n    cbar.set_label('Intensity (a.u.)', fontsize = 14)\n    plt.ylim(min(yStack), max(yStack))\n    plt.yticks(fontsize = 14)\n    plt.xticks(fontsize = 14)\n    plt.title(plotTitle)\n\n    if not imgName.endswith('.png'):\n        imgName = '%s.png' % imgName\n\n    if init == True:\n        imgPath = imgName\n\n    elif init == False:\n        imgPath = 'Stacks/%s' % (imgName)\n\n    fig.savefig(imgPath, bbox_inches = 'tight')\n\n    if closeFigures == True:\n        plt.close('all')\n\n    if init == True:\n        stackEndTime = time.time()\n        timeElapsed = stackEndTime - stackStartTime\n\n        print('\\tInitial stack plotted in %s seconds\\n' % timeElapsed)",
  "def plotInitStack(x, yData, imgName = 'Initial Stack', closeFigures = True, vThresh = 2e-4):\n    '''Quickly plots stack of all DF spectra before doing the full analysis. Useful for quickly assessing the dataset quality'''\n\n    yDataTrunc = np.array([truncateSpectrum(x, spectrum)[1] for spectrum in yData])#truncate to NPoM range\n    xStack = truncateSpectrum(x, yData[0])[0]#x axis\n\n    transIndex = abs(xStack - 533).argmin()\n    yDataTrunc = np.array([old_div(spectrum, spectrum[transIndex]) for spectrum in yDataTrunc])#normalise to ~transverse mode\n\n    plotStackedMap(xStack, yDataTrunc, imgName = imgName, plotTitle = imgName, closeFigures = closeFigures, init = True, vThresh = vThresh)",
  "def plotInitPlStack(xPl, plData, imgName = 'Initial PL Stack', closeFigures = True, vThresh = 5e-5):\n    '''Same as above, but for PL data'''\n\n    yDataTrunc = np.array([truncateSpectrum(xPl, plSpectrum, startWl = 580)[1] for plSpectrum in plData])# truncate to remove laser leak\n    xStack = truncateSpectrum(xPl, plData[0], startWl = 580)[0] # x axis\n    yDataTrunc = np.array([old_div(plSpectrum, plSpectrum[0]) for plSpectrum in yDataTrunc])# normalise to 580 nm value\n    plotStackedMap(xStack, yDataTrunc, imgName = imgName, plotTitle = imgName, closeFigures = closeFigures, vThresh = vThresh, init = True, xLims = (580, 900))",
  "def createOutputFile(filename, printProgress = True):\n\n    '''Auto-increments new filename if file exists'''\n\n    if printProgress == True:\n        print('Creating output file...')\n\n    outputFile = filename\n\n    if not (filename.endswith('.h5') or filename.endswith('.hdf5')):\n        outputFile = '%s.h5' % filename\n\n    if outputFile in os.listdir('.'):\n        if printProgress == True:\n            print('\\t%s already exists' % outputFile)\n        n = 0\n        outputFile = '%s_%s.h5' % (filename, n)\n\n        while outputFile in os.listdir('.'):\n            if printProgress == True:\n                print('\\t%s already exists' % outputFile)\n            n += 1\n            outputFile = '%s_%s.h5' % (filename, n)\n\n    if printProgress == True:\n        print('\\tOutput file %s created\\n' % outputFile)\n    return outputFile",
  "def butterLowpassFiltFilt(data, cutoff = 1500, fs = 60000, order=5):\n    '''Smoothes data without shifting it'''\n\n    padded = False\n\n    if len(data) < 18:\n        padded = True\n        pad = 18 - old_div(len(data),2)\n        startPad = np.array([data[0]] * (int(pad) + 1))\n        endPad = np.array([data[0]] * (int(pad) + 1))\n        data = np.concatenate((startPad, data, endPad))\n\n    nyq = 0.5 * fs\n    normalCutoff = old_div(cutoff, nyq)\n    b, a = butter(order, normalCutoff, btype='low', analog=False)\n    yFiltered = filtfilt(b, a, data)\n\n    if padded == True:\n        yFiltered = yFiltered[len(startPad):-len(endPad)]\n\n    return yFiltered",
  "def printEnd():\n    '''Some Doge approval for when you finish'''\n\n    print('%s%s%sv gud' % ('\\t' * randint(0, 12), '\\n' * randint(0, 5), ' ' * randint(0, 4)))\n    print('%s%ssuch python' % ('\\n' * randint(0, 5), ' ' * randint(0, 55)))\n    print('%s%smany spectra' % ('\\n' * randint(0, 5), ' ' * randint(10, 55)))\n    print('%s%smuch fitting' % ('\\n' * randint(0, 5), ' ' * randint(8, 55)))\n    print('%s%swow' % ('\\n' * randint(2, 5), ' ' * randint(5, 55)))\n    print('\\n' * randint(0, 7))",
  "def detectMinima(array, threshold = None, returnBool = False):\n    '''\n    detectMinima(array) -> mIndices\n    Finds the turning points within a 1D array and returns the indices of the minima.\n    '''\n    mIndices = []\n\n    if (len(array) < 3):\n        return mIndices\n\n    neutral, rising, falling = np.arange(3)\n\n    def getState(a, b):\n        if a < b: return rising\n        if a > b: return falling\n        return neutral\n\n    ps = getState(array[0], array[1])\n    begin = 1\n\n    for i in range(2, len(array)):\n        s = getState(array[i - 1], array[i])\n\n        if s != neutral:\n\n            if ps != neutral and ps != s:\n\n                if s != falling:\n                    mIndices.append((begin + i - 1)//2)\n\n            begin = i\n            ps = s\n\n    if threshold is not None:\n        yRange = array.max() - array.min()\n        threshold = array.max() - threshold*yRange\n        mIndices = [i for i in mIndices if array[i] < threshold]\n\n    if returnBool == True and len(mIndices) == 0:\n        return False\n\n    return np.array(mIndices)",
  "def testIfNpom(x, y, lower = 0.05, upper = 2.5, NpomThreshold = 1.5, startWl = 450):\n    '''Filters out spectra that are obviously not from NPoMs'''\n\n    isNpom = False #Guilty until proven innocent\n\n    '''To be accepted as an NPoM, you must first pass four trials'''\n\n    x = np.array(x)\n    y = np.array(y)\n\n    try:\n        [xTrunc, yTrunc] = truncateSpectrum(x, y, startWl = startWl, endWl = 900)\n        [xUpper, yUpper] = truncateSpectrum(x, y, startWl = 900, endWl = x.max())\n        yTrunc -= yTrunc.min()\n\n    except Exception as e:\n        print('NPoM test failed because %s' % e)\n        return False\n\n    '''Trial the first: do you have a reasonable signal?'''\n\n    YuNoNpom = 'Signal too low'\n\n    if np.sum(yTrunc) > lower and (y.min() > -0.1 or startWl >= 500):\n        #If sum of all intensities lies outside a given range, it's probably not an NPoM\n        #Can adjust range to suit system\n\n        YuNoNpom = 'CM region too weak'\n\n        '''Trial the second: do you slant in the correct direction?'''\n\n        firstHalf = yTrunc[:int(old_div(len(yTrunc),3))]\n        secondHalf = yTrunc[int(old_div(len(yTrunc),3)):]\n\n        if np.sum(firstHalf) < np.sum(secondHalf) * NpomThreshold:\n            #NPoM spectra generally have greater total signal at longer wavelengths due to coupled mode\n\n            YuNoNpom = 'Just Noise'\n\n            '''Trial the third: are you more than just noise?'''\n\n            if np.sum(yTrunc)*3 > old_div(np.sum(yUpper), NpomThreshold):\n                #If the sum of the noise after 900 nm is greater than that of the spectrum itself, it's probably crap\n\n                YuNoNpom = 'Too few peaks detected'\n\n                '''Trial the fourth: do you have more than one maximum?'''\n\n                ySmooth = butterLowpassFiltFilt(y)\n                minima = detectMinima(-ySmooth)\n\n                if len(minima) > 1:\n                    #NPoM spectra usually have more than one distinct peak, separated by a minimum\n                    isNpom = True\n                    YuNoNpom = 'N/A'\n\n    return isNpom, YuNoNpom",
  "def testIfDouble(x, y, doublesThreshold = 2, lowerLimit = 600, plot = False, raiseExceptions = True, startWl = 450, endWl = 900):\n    isDouble = False\n    isNpom = True\n\n    xy = truncateSpectrum(x, y, startWl = startWl, endWl = endWl)\n    xTrunc = xy[0]\n    yTrunc = xy[1]\n    ySmooth = butterLowpassFiltFilt(yTrunc)\n\n    mIndices = detectMinima(ySmooth)\n    maxdices = detectMinima(-ySmooth)\n\n    if len(mIndices) == 0 or len(maxdices) == 0:\n        isNpom = False\n        isDouble = 'N/A'\n        return isNpom, isDouble\n\n    xMins = xTrunc[mIndices]\n    yMins = ySmooth[mIndices]\n    mins = list(zip(xMins, yMins))\n\n    xMaxs = xTrunc[maxdices]\n    yMaxs = ySmooth[maxdices]\n    maxs = list(zip(xMaxs, yMaxs))\n\n    if len(yMaxs) == 0:\n        isNpom = False\n        isDouble = 'N/A'\n\n    else:\n        try:\n            yMax = max(yMaxs)\n\n        except Exception as e:\n            if raiseExceptions == True:\n                pass\n\n            else:\n                print(e)\n                return False\n\n        maxsSortedY = sorted([i for i in maxs if i[0] > lowerLimit], key = lambda maximum: maximum[1])\n\n        yMax = maxsSortedY[-1][1]\n        xMax = maxsSortedY[-1][0]\n        yMax2 = 0\n        xMax2 = 0\n\n        if plot:\n            xTrough, yTrough = ([],[])\n            xMax2, yMax2 = ([], [])\n\n        if len(maxsSortedY) > 1:\n            xMax2, yMax2 = maxsSortedY[-2]                \n            xTrough, yTrough = sorted([i for i in mins if xMax2 < i[0] < xMax or xMax2 > i[0] > xMax], key = lambda i: i[1])[0]\n\n            if yMax2 - yTrough > (yMax - yTrough)/doublesThreshold and xMax2 > lowerLimit and abs(xMax - xMax2) > 30:\n                isDouble = True\n\n            #except:\n            #    isDouble = False\n        else:\n            isDouble = False\n\n        if xMax < lowerLimit:\n            isNpom = False\n            isDouble = 'N/A'\n\n    if plot == True or plot == 'all' or plot == 'double test':\n\n        if isDouble == True:\n            title = 'Double Peak'\n\n        elif isDouble == False:\n            title = 'Single Peak'\n\n        elif isDouble == 'N/A':\n            title = 'No Peak'\n\n        plt.figure(figsize = (8, 6))\n        plt.plot(x, y, 'purple', lw = 0.3, label = 'Raw')\n        plt.xlabel('Wavelength (nm)')\n        plt.ylabel('Intensity')\n        plt.plot(xTrunc, ySmooth, 'g', label = 'Smoothed')\n        plt.plot(xMins, yMins, 'ko', label = 'Minima')\n        plt.plot(xMaxs, yMaxs, 'go', label = 'Maxima')\n        plt.plot(xTrough, yTrough, 'bo', label = 'Trough')\n        plt.plot(xMax, yMax, 'ro', label = 'Max')\n        plt.plot(xMax2, yMax2, 'ro', label = 'Max2')\n        plt.legend(loc = 0, ncol = 3)\n        plt.ylim(0, ySmooth.max()*1.23)\n        plt.xlim(450, 900)\n        plt.title(title)\n        plt.show()\n\n    xMaxx = [xMax, xMax2][np.array([yMax, yMax2]).argmax()]\n    yMaxx = max(yMax, yMax2)\n\n    return isNpom, isDouble, xMaxx, yMaxx",
  "def centDiff(x, y):\n\n    '''Numerically calculates dy/dx using central difference method'''\n\n    x1 = np.concatenate((x[:2][::-1], x))\n    x2 = np.concatenate((x, x[-2:][::-1]))\n    dx = x2 - x1\n    dx = dx[1:-1]\n\n    y1 = np.concatenate((y[:2][::-1], y))\n    y2 = np.concatenate((y, y[-2:][::-1]))\n    dy = y2 - y1\n    dy = dy[1:-1]\n\n    if 0 in dx:\n        dx = removeNaNs(np.where(dx == 0, dx, np.nan))\n\n    d = (old_div(dy,dx))\n    d /= 2\n\n    return d",
  "def normToTrans(x, y, transNorm = 1, troughNorm = 0.61, transInit = 533, startWl = 450, plot = False):\n\n    xTrunc, yTrunc = truncateSpectrum(x, y, startWl = startWl, finishWl = 600)#Truncate data from 450 to 600 nm\n\n    ySmooth = butterLowpassFiltFilt(yTrunc)#Smooth data\n\n    #try:\n\n    mIndices = detectMinima(ySmooth)#Find minima\n\n    if len(mIndices) > 0 or startWl > 470:\n        if len(mIndices) > 0:\n            yMins = ySmooth[mIndices]\n            xMins = xTrunc[mIndices]\n            mins = np.array(list(zip(xMins, yMins)))#Corresponding (x, y) values\n\n        d1 = centDiff(xTrunc, ySmooth)\n        d2 = centDiff(xTrunc, d1)\n        d2Mindices = detectMinima(d2)\n        trandex = abs(xTrunc[d2Mindices] - transInit).argmin()#Closest minimum in second derivative to 533 nm is likely the transverse mode\n        transWl = xTrunc[d2Mindices][trandex]\n        trandex = abs(xTrunc - transWl).argmin()\n\n        if startWl > 470:\n            t0 = ySmooth[trandex]\n            initMinWl = 'N/A'\n            yNorm = y/(ySmooth[trandex]*transNorm)\n\n            if plot == True:\n                plt.plot(xTrunc, yTrunc)\n                plt.plot(xTrunc, ySmooth)\n                plt.plot(transWl, t0, 'o')\n                plt.show()\n\n            return yNorm, initMinWl, t0, transWl\n\n        initMins = [minimum for minimum in mins if minimum[0] < transWl]#Minima occuring before transverse mode\n\n        if len(initMins) == 0:\n            d2Maxdices = detectMinima(-d2)\n            yMins = ySmooth[d2Maxdices]\n            xMins = xTrunc[d2Maxdices]\n            mins = np.array(list(zip(xMins, yMins)))\n\n            initMins = [minimum for minimum in mins if minimum[0] < transWl]\n\n        initMinWls = np.array(list(zip(*mins))[0])\n        initMinHeights = np.array(list(zip(*mins))[1])\n        initMindex = abs(initMinWls - transInit).argmin()\n        initMinWl = initMinWls[initMindex]\n\n        a0 = initMinHeights[initMindex]\n        t0 = ySmooth[trandex]\n        tInit = ySmooth[abs(xTrunc - transInit).argmin()]\n\n        if tInit/ySmooth[trandex] > 2:\n            t0 = tInit\n            transWl = transInit\n\n        aN = troughNorm\n        tN = transNorm\n\n        if False:#a0 < t0:\n            yNorm = y - a0\n            yNorm /= (t0 - a0)\n            yNorm *= (tN - aN)\n            yNorm += aN\n\n        else:\n            yNorm = y - ySmooth.min()\n            yNorm /= t0\n            yNorm = y/t0\n\n    else:\n        yNorm = y - ySmooth.min()\n        trandex = abs(xTrunc - transInit).argmin()\n        transWl = xTrunc[trandex]\n        t0 = ySmooth[trandex]\n        yNorm /= t0\n        initMinWl = 'N/A'\n\n    if plot == True:\n        plt.plot(xTrunc, yTrunc)\n        plt.plot(xTrunc, ySmooth)\n        plt.plot(transWl, t0, 'o')\n\n        if initMinWl != 'N/A':\n            plt.plot(initMinWl, ySmooth[initMindex], 'o')\n        plt.show()\n\n    return yNorm, initMinWl, t0, transWl",
  "def testIfWeirdPeak(x, y, factor = 1.4, transWl = 533, startWl = 450, upperLimit = 670, plot = False, debug = False):\n\n    '''\n    Probes NPoM spectrum for presence of 'weird' sharp peak at ~600 nm\n    Truncates spectrum from 450 to 670 nm, smoothes and finds maxima\n    If maximum is greater than transverse mode intensity by a certain factor and at a longer wavelength, spectrum has the weird peak.\n    '''\n\n    xy = truncateSpectrum(x, y, startWl = startWl, finishWl = upperLimit)\n\n    xTrunc = xy[0]\n    yTrunc = xy[1]\n\n    yTruncSmooth = butterLowpassFiltFilt(yTrunc)\n    transHeight = yTruncSmooth[abs(xTrunc - transWl).argmin()]\n    yMaxs = detectMinima(-yTruncSmooth)\n\n    if len(yMaxs) == 0:\n        return False\n\n    peakHeight = yTruncSmooth[yMaxs].max()\n    peakWl = xTrunc[yTruncSmooth.argmax()]\n\n    if peakHeight >= transHeight * factor and peakWl > transWl:\n        weird = True\n\n    else:\n        weird = False\n\n    if plot == 'all' or plot == True:\n\n        if weird == True:\n            color = 'k'\n\n        elif weird == False:\n            color = 'b'\n\n        plt.plot(xTrunc, yTrunc, color = color)\n        plt.plot(peakWl, peakHeight, 'ro')\n        plt.plot(transWl, transHeight, 'go')\n        plt.xlabel('Wavelength (nm)')\n        plt.ylabel('Scattered Intensity')\n        plt.title('Weird peak = %s' % weird)\n        plt.show()\n\n    if debug == True:\n        return weird, peakHeight, peakWl\n\n    else:\n        return weird",
  "def getFWHM(x, y, maxdex = None, fwhmFactor = 1.1, smooth = False, peakpos = 0, peakType = 'gaussian', reverse = False):\n    '''Estimates FWHM of largest peak in a given dataset if maxdex == None'''\n    '''If maxdex is specified, estimates FWHM of peak centred at that point'''\n    '''Also returns xy coords of peak'''\n\n    if smooth == True:\n        y = butterLowpassFiltFilt(y)\n\n    if reverse == True:\n        x = x[::-1]\n        y = y[::-1]\n        if maxdex is not None:\n            maxdex = -maxdex\n\n    if maxdex is None:\n        maxdex = y.argmax()\n        if maxdex == 0:\n            maxdex = 1\n        elif maxdex == len(y) - 1:\n            maxdex = len(y) - 2\n            \n    yMax = y[maxdex]\n    xMax = x[maxdex]\n    \n    halfMax = yMax/2\n    \n    halfDex1 = abs(y[:maxdex][::-1] - halfMax).argmin()\n    halfDex2 = abs(y[maxdex:] - halfMax).argmin()\n\n    xHalf1 = x[:maxdex][::-1][halfDex1]\n    xHalf2 = x[maxdex:][halfDex2]\n\n    hwhm1 = abs(xMax - xHalf1)\n    hwhm2 = abs(xMax - xHalf2)\n    hwhms = np.array([hwhm1, hwhm2])\n    halfDexs = np.array([maxdex - halfDex1, halfDex2 + maxdex])\n\n    hwhmMax, hwhmMin = hwhms.max(), hwhms.min()\n    halfDexMax, halfDexMin =  halfDexs[hwhms.argmax()], halfDexs[hwhms.argmin()]\n\n    if y[halfDexMin] < np.average(yMax * 0.55):\n        if hwhmMax > hwhmMin*fwhmFactor:\n            fwhm = hwhmMin * 2\n\n        else:\n            fwhm = sum(hwhms)\n        halfDex = halfDexMin\n    else:\n        fwhm = hwhmMax * 2\n        halfDex = halfDexMax\n\n    return fwhm, xMax, yMax",
  "def lorentzian(x, height, center, fwhm):\n    I = height\n    x0 = center\n    gamma = fwhm/2\n    numerator = gamma**2\n    denominator = (x - x0)**2 + gamma**2\n    quot = numerator/denominator\n    \n    y = I*quot\n    return y",
  "def gaussian(x, height, center, fwhm, offset = 0):\n    '''Gaussian as a function of height, centre, fwhm and offset'''\n    a = height\n    b = center\n    c = fwhm\n\n    N = 4*np.log(2)*(x - b)**2\n    D = c**2\n    F = -(N/D)\n    E = np.exp(F)\n    y = a*E\n    y += offset\n\n    return y",
  "def gaussArea(height, fwhm):\n    h = height\n    c = fwhm\n    area = h*np.sqrt(old_div((np.pi*c**2),(4*np.log(2))))\n\n    return area",
  "def findMainPeaks(x, y, fwhmFactor = 1.1, plot = False, midpoint = 680, weirdPeak = True, startWl = 450, \n                  upperCutoff = 900, cutoff = 80000, fs = 1200):\n    peakFindMetadata = {}\n\n    xy = truncateSpectrum(x, y, startWl = startWl, finishWl = upperCutoff)\n    xTrunc = xy[0]\n    yTrunc = xy[1]\n\n    ySmooth = butterLowpassFiltFilt(yTrunc)\n\n    mIndices = detectMinima(ySmooth)\n\n    xMins = xTrunc[mIndices]\n    yMins = ySmooth[mIndices]\n\n    mins = [[xMin, yMins[n]] for n, xMin in enumerate(xMins)]\n    minsSorted = sorted(mins, key = lambda minimum: abs(minimum[0] - midpoint))\n\n    try:\n        if abs(minsSorted[0][1] - minsSorted[1][1]) > ySmooth.max() * 0.6:\n            midMin = sorted(minsSorted[:2], key = lambda minimum: minimum[1])[0][0]\n\n        else:\n            midMin = xMins[abs(xMins - midpoint).argmin()]\n\n    except:\n        midMin = xMins[abs(xMins - midpoint).argmin()]\n\n    initMin = xMins[0]\n\n    if initMin == midMin:\n        initMin = 450\n\n    xy1 = truncateSpectrum(xTrunc, ySmooth, startWl = initMin, finishWl = midMin)\n    xy2 = truncateSpectrum(xTrunc, ySmooth, startWl = midMin, finishWl = 987)\n\n    if weirdPeak == True:\n        x1 = xy1[0]\n        y1 = xy1[1]\n\n        fwhm, xMax, yMax = getFWHM(x1, y1, fwhmFactor = fwhmFactor)\n\n        peakFindMetadata['Weird peak FWHM'] = fwhm\n        peakFindMetadata['Weird peak intensity'] = yMax\n        peakFindMetadata['Weird peak wavelength'] = xMax\n        weirdGauss = [gaussian(i, yMax, xMax, fwhm) for i in x]\n\n    else:\n        peakFindMetadata['Weird peak FWHM'] = 'N/A'\n        peakFindMetadata['Weird peak intensity'] = 'N/A'\n        peakFindMetadata['Weird peak wavelength'] = 'N/A'\n        weirdGauss = 'N/A'\n\n    x2 = xy2[0]\n    y2 = xy2[1]\n\n    fwhm, xMax, yMax = getFWHM(x2, y2, fwhmFactor = fwhmFactor)\n\n    if fwhm > 150:\n        isNpom2, isDouble, xMax, yMax = testIfDouble(x, y, lowerLimit = midpoint, startWl = startWl, endWl = upperCutoff,\n                                                     plot = False)\n        fwhm = 'N/A'\n\n    if xMax > upperCutoff * 0.95:\n        peakFindMetadata['NPoM?'] = False\n        peakFindMetadata['Not NPoM because'] = 'CM Wl too high'  \n        peakFindMetadata['Coupled mode FWHM'] = 'N/A'\n        peakFindMetadata['Coupled mode intensity'] = 'N/A'\n        peakFindMetadata['Coupled mode wavelength'] = 'N/A'\n\n        return peakFindMetadata, 'N/A', 'N/A'  \n    else:\n        peakFindMetadata['NPoM?'] = True\n\n    peakFindMetadata['Coupled mode FWHM'] = fwhm\n    peakFindMetadata['Coupled mode intensity'] = yMax\n    peakFindMetadata['Coupled mode wavelength'] = xMax\n\n    if 'N/A' not in [fwhm, yMax, xMax]:\n        cmGauss = gaussian(x, yMax, xMax, fwhm)\n    else:\n        cmGauss = 'N/A'\n\n    if plot == True or plot == 'all':\n        weirdHeight = peakFindMetadata['Weird peak intensity']\n        weirdWl = peakFindMetadata['Weird peak wavelength']\n        weirdFwhm = peakFindMetadata['Weird peak FWHM']\n\n        cmHeight = peakFindMetadata['Coupled mode intensity']\n        cmWl = peakFindMetadata['Coupled mode wavelength']\n        cmFwhm = peakFindMetadata['Coupled mode FWHM']\n\n        if weirdWl != 'N/A' and weirdFwhm != 'N/A':\n            weirdFwhmHorizX = np.linspace(weirdWl - weirdFwhm/2, weirdWl + weirdFwhm/2, 2)\n            weirdFwhmHorizY = np.array([weirdHeight/2] * 2)\n            cmFwhmHorizX = np.linspace(cmWl - (cmFwhm/2), cmWl + (cmFwhm/2), 2)\n            cmFwhmHorizY = np.array([(cmHeight/2)] * 2)\n\n            plt.plot(weirdFwhmHorizX, weirdFwhmHorizY, 'k', lw = 0.4)\n            plt.plot(cmFwhmHorizX, cmFwhmHorizY, 'k', lw = 0.4)\n            plt.plot(x, weirdGauss, 'k', lw = 0.5)\n\n        plt.plot(x, y, 'purple', lw = 0.3, label = 'Raw')\n        plt.plot(x2, y2, 'r', zorder = 100, label = 'x2y2')\n        plt.xlabel('Wavelength (nm)')\n        plt.ylabel('Intensity')\n        plt.plot(xTrunc, ySmooth, 'g', label = 'Smoothed')\n        if type(cmGauss) != str:\n            plt.plot(x, cmGauss, 'k', lw = 0.5)\n        plt.plot(xMax, yMax, 'o', label = 'CM Peak')\n        plt.xlim(450, 900)\n        plt.ylim(0, ySmooth.max()*1.1)\n        plt.legend(loc = 0)\n        plt.show()\n\n    return peakFindMetadata, weirdGauss, cmGauss",
  "def analyseNpomSpectrum(x, y, cutoff = 1500, fs = 60000, doublesThreshold = 2, cmLowLim = 580, \n                        raiseExceptions = False, plot = False, pl = False,\n                        weirdFactor = 1.4, transPeakPos = 533, peakFindMidpoint = 680, \n                        avg = False, startWl = 450, upperCutoff = 900):\n    yRaw = np.array(y)\n    xRaw = np.array(x)\n    if pl == True:\n        startWl = 500\n\n    endWl = upperCutoff\n\n    allMetadataKeys = [\n                      'NPoM?',\n                      'Not NPoM because',\n                      'Weird Peak?',\n                      'Weird peak intensity (normalised)',\n                      'Weird peak wavelength',\n                      'Weird peak FWHM',\n                      'Weird peak intensity (raw)',\n                      'Weird peak FWHM (raw)',\n                      'Double Peak?',\n                      'Transverse mode wavelength',\n                      'Transverse mode intensity (normalised)',\n                      'Transverse mode intensity (raw)',\n                      'Coupled mode wavelength',\n                      'Coupled mode intensity (normalised)',\n                      'Coupled mode FWHM',\n                      'Coupled mode FWHM (raw)',\n                      'Coupled mode intensity (raw)',\n                      'Intensity ratio (normalised)',\n                      'Intensity ratio (raw)',\n                      'Raw data',\n                      'Raw data (normalised)',\n                      'wavelengths',\n                       ]\n\n    metadata = {key : 'N/A' for key in allMetadataKeys}\n    metadata['Raw data'] = yRaw\n    metadata['wavelengths'] = xRaw\n\n    '''Testing if NPoM'''\n\n    isNpom1, YuNoNpom = testIfNpom(xRaw, yRaw, startWl = startWl)\n    isNpom2, isDouble, xMax, yMax = testIfDouble(xRaw, yRaw, doublesThreshold = doublesThreshold, lowerLimit = cmLowLim, \n                                     raiseExceptions = raiseExceptions, startWl = startWl, endWl = endWl,\n                                     plot = plot)\n\n    if isNpom1 == True and isNpom2 == True:\n        isNpom = True\n\n    else:\n        isNpom = False\n\n    if isNpom2 == False:\n        YuNoNpom = 'Spectral maximum < specified cm lower limit (%s nm)' % cmLowLim\n\n    if avg == True:\n       isNpom = True\n       YuNoNpom = 'N/A'\n\n    metadata['Double Peak?'] = isDouble\n    metadata['NPoM?'] = isNpom\n    metadata['Not NPoM because'] = YuNoNpom\n\n    if isNpom == True:\n        yRawNorm, initMinWl, transHeight, transWl = normToTrans(xRaw, yRaw, transNorm = 1, troughNorm = 0.61, \n                                                                transInit = transPeakPos, plot = plot,\n                                                                startWl = startWl)\n        metadata['Raw data (normalised)'] = yRawNorm\n        metadata['Transverse mode wavelength'] = transWl\n        metadata['Transverse mode intensity (raw)'] = transHeight\n        metadata['Transverse mode intensity (normalised)'] = 1.\n\n        weird = testIfWeirdPeak(x, y, factor = weirdFactor, upperLimit = peakFindMidpoint, plot = plot, transWl = transWl, startWl = startWl)\n        metadata['Weird Peak?'] = weird\n\n        rawPeakFindMetadata, weirdGauss, cmGauss = findMainPeaks(xRaw, yRaw, fwhmFactor = 1.1, plot = plot, midpoint = peakFindMidpoint,\n                                                                 weirdPeak = weird, startWl = startWl, upperCutoff = upperCutoff)\n\n        if rawPeakFindMetadata['NPoM?'] == False:\n            metadata['NPoM?'] = False\n            metadata['Not NPoM because'] = rawPeakFindMetadata['Not NPoM because']\n            return metadata\n\n        metadata['Coupled mode intensity (raw)'] = rawPeakFindMetadata['Coupled mode intensity']\n        metadata['Coupled mode FWHM (raw)'] = rawPeakFindMetadata['Coupled mode FWHM']\n        metadata['Coupled mode wavelength'] = rawPeakFindMetadata['Coupled mode wavelength']\n        metadata['Weird peak intensity (raw)'] = rawPeakFindMetadata['Weird peak intensity']\n        metadata['Weird peak FWHM (raw)'] = rawPeakFindMetadata['Weird peak FWHM']\n        metadata['Weird peak wavelength'] = rawPeakFindMetadata['Weird peak wavelength']\n\n        normPeakFindMetadata, weirdGauss, cmGauss = findMainPeaks(x, yRawNorm, fwhmFactor = 1.1, plot = plot, midpoint = peakFindMidpoint,\n                                                                  weirdPeak = weird, startWl = startWl, upperCutoff = upperCutoff)\n\n        if normPeakFindMetadata['NPoM?'] == False:\n            metadata['NPoM?'] = False\n            metadata['Not NPoM because'] = normPeakFindMetadata['Not NPoM because']\n            return metadata\n\n        metadata['Coupled mode intensity (normalised)'] = normPeakFindMetadata['Coupled mode intensity']\n        metadata['Coupled mode FWHM (normalised)'] = normPeakFindMetadata['Coupled mode FWHM']\n        metadata['Weird peak intensity (normalised)'] = normPeakFindMetadata['Weird peak intensity']\n        metadata['Weird peak FWHM (normalised)'] = normPeakFindMetadata['Weird peak FWHM']\n\n        if isDouble == True:\n            metadata['Coupled mode FWHM'] = 'N/A'\n            metadata['Coupled mode FWHM (raw)'] = 'N/A'\n\n        normIntensityRatio = metadata['Coupled mode intensity (normalised)']/metadata['Transverse mode intensity (normalised)']\n        rawIntensityRatio = metadata['Coupled mode intensity (raw)']/metadata['Transverse mode intensity (raw)']\n\n        metadata['Intensity ratio (normalised)'] = normIntensityRatio\n        metadata['Intensity ratio (raw)'] = rawIntensityRatio\n\n    return metadata",
  "def calcNoise(y, ySmooth, windowSize = 5):\n\n    '''Calculates noise using moving window'''\n\n    if windowSize % 2 != 0:\n        windowSize += 1\n\n    noise = y - ySmooth\n    newNoise = np.concatenate((noise[:old_div(windowSize,2)][::-1], noise, noise[old_div(-windowSize,2):][::-1]))\n    noiseLevel = np.array([np.std(newNoise[n:n + windowSize]) for n, i in enumerate(noise)])\n\n    return noiseLevel",
  "def evToNm(eV):\n    e = 1.60217662e-19\n    joules = eV * e\n    c = 299792458\n    h = 6.62607015e-34\n    wavelength = h*c/joules\n    nm = wavelength * 1e9\n    return nm",
  "def nmToEv(nm):\n    wavelength = nm*1e-9\n    c = 299792458\n    h = 6.62607015e-34\n    joules = h*c/wavelength\n    e = 1.60217662e-19\n    eV = joules / e\n    return eV",
  "def boltzmannDist(x, a, A):\n    return A*np.sqrt(2/np.pi)*(x**2*np.exp(-x**2/(2*a**2)))/a**3",
  "def findGausses(x, y, fwhmFactor = 1.8, regStart = 505, regEnd = 600, initPeakPos = 545, noiseThresh = 1,\n                windowLength = 221, polyorder = 7, cutoff = 1000, fs = 80000, noiseWindow = 20, savGol = True):\n\n    if savGol == True:\n        ySmooth = sgFilt(y, window_length = windowLength, polyorder = polyorder)\n    else:\n        ySmooth = y\n\n    ySmooth = butterLowpassFiltFilt(ySmooth, cutoff = cutoff, fs = fs)\n    noise = calcNoise(y, ySmooth)\n\n    xTrunc, yTrunc = truncateSpectrum(x, ySmooth, startWl = regStart, finishWl = regEnd)\n    inMins = detectMinima(-yTrunc)\n\n    while len(inMins) == 0:\n        regEnd += 5\n        xTrunc, yTrunc = truncateSpectrum(x, ySmooth, startWl = regStart, finishWl = regEnd)\n        inMins = detectMinima(-yTrunc)\n\n        if regEnd > 900:\n            break\n\n    fwhm, center, height = getFWHM(xTrunc, yTrunc, smooth = True, fwhmFactor = fwhmFactor, peakpos = initPeakPos)\n    peakMetadata = {}\n    peakMetadata['Peak_0'] = {'Height' : height, 'Center' : center, 'FWHM' : fwhm,\n                              'Fit' : gaussian(x, height, center, fwhm)}\n\n    if fwhm is not None:\n        yGauss = gaussian(x, height, center, fwhm)\n        ySub = y - yGauss\n\n    else:\n        return peakMetadata\n\n    for n in range(1, 10):\n        if savGol == True:\n            try:\n                ySmooth = sgFilt(ySub, window_length = windowLength, polyorder = polyorder)\n            except:\n                if np.average(y) < 0:\n                    return peakMetadata\n\n        ySmooth = butterLowpassFiltFilt(ySmooth, cutoff = cutoff, fs = fs)\n        noise = calcNoise(y, ySmooth, windowSize = noiseWindow)\n        oldCenter = peakMetadata['Peak_%s' % (n - 1)]['Center']\n        maxdices = detectMinima(-ySmooth)\n\n        maxdices = [i for i in maxdices if x[i] > oldCenter and ySmooth[i] > 0 and ySmooth[i] > noise[i]*noiseThresh]\n\n        if len(maxdices) == 0:\n            break\n\n        if len(maxdices)> 1:\n            upLim = x[maxdices[1]]\n\n        else:\n            upLim = x.max()\n\n        xTrunc, yTrunc = truncateSpectrum(x, ySmooth, startWl = oldCenter, finishWl = upLim)\n        fwhm, center, height = getFWHM(xTrunc, yTrunc, smooth = True, fwhmFactor = fwhmFactor, peakpos = x[maxdices[0]])\n        #fwhm, center, height = getFWHM(x, ySmooth, smooth = True, fwhmFactor = fwhmFactor, peakpos = x[y[maxdices].argmax()])\n\n        if np.nan in [fwhm, center, height] or 0. in [fwhm, center, height]:\n            break\n\n        #print fwhm, center, height\n\n        peakMetadata[f'Peak_{n}'] = {'Height' : height, 'Center' : center, 'FWHM' : fwhm,\n                                       'Fit' : gaussian(x, height, center, fwhm)}\n\n        ySub -= peakMetadata[f'Peak_{n}']['Fit']\n\n    return peakMetadata",
  "def makeGausses(x, pars):\n\n    peakMetadata = {}\n    peakPars = []\n\n    for n, par in enumerate(pars):\n        peakPars.append(par)\n\n        if len(peakPars) == 3:\n            gauss = gaussian(x, peakPars[0], peakPars[1], peakPars[2])#height, center, fwhm\n            peakMetadata['Peak_%s' % n] = {'Height' : peakPars[0], 'Center' : peakPars[1], 'FWHM' : peakPars[2],\n                                           'Area' : gaussArea(peakPars[0], peakPars[2]), 'Fit' : gauss}\n\n            peakPars = []\n\n    return peakMetadata",
  "def gaussLmFit(x, y, fwhmFactor = 1.8, regStart = 505, regEnd = 630, initPeakPos = 545, noiseThresh = 1,\n                  windowLength = 251, polyorder = 6, cutoff = 1000, fs = 80000, noiseWindow = 20, savGol = True):\n    peakMetadata = findGausses(x, y, fwhmFactor = fwhmFactor, regStart = regStart, regEnd = regEnd,\n                               initPeakPos = initPeakPos, noiseThresh = noiseThresh, windowLength = windowLength,\n                               polyorder = polyorder, cutoff = cutoff, fs = fs, noiseWindow = noiseWindow, savGol = savGol)\n\n    print(f'{len(peakMetadata.keys())} Peaks found')\n    print(peakMetadata['Peak_0'].keys())\n    return(peakMetadata)",
  "def gaussMinimize(x, y, fwhmFactor = 1.8, regStart = 505, regEnd = 630, initPeakPos = 545, noiseThresh = 1,\n                  windowLength = 251, polyorder = 6, cutoff = 1000, fs = 80000, noiseWindow = 20, savGol = True):\n\n    peakMetadata = findGausses(x, y, fwhmFactor = fwhmFactor, regStart = regStart, regEnd = regEnd,\n                               initPeakPos = initPeakPos, noiseThresh = noiseThresh, windowLength = windowLength,\n                               polyorder = polyorder, cutoff = cutoff, fs = fs, noiseWindow = noiseWindow, savGol = savGol)\n\n    def calcGaussResiduals(pars):\n        '''pars = list of lists of gaussian parameters (center, height, fwhm)'''\n\n        fit = np.zeros(len(x))\n        peakPars = []\n\n        for n, par in enumerate(pars):\n            peakPars.append(par)\n\n            if len(peakPars) == 3:\n                gauss = gaussian(x, peakPars[0], peakPars[1], peakPars[2])#height, center, fwhm\n                fit += gauss\n                peakPars = []\n\n        diff = np.sum(abs(y - fit))\n\n        return diff\n\n    peaks = sorted(peakMetadata.keys(), key = lambda peak: int(peak.split('_')[1]))\n    bounds = []\n    parsGuess = []\n\n    for n, peak in enumerate(peaks):\n        height = peakMetadata[peak]['Height']\n        center = peakMetadata[peak]['Center']\n        fwhm = peakMetadata[peak]['FWHM']\n\n        heightBound = height/2, height*2\n\n        if n == 0 and n < len(peaks) - 1:\n            center1 = peakMetadata[peaks[n + 1]]['Center']\n            maxlim = np.average([center, center1, center1])\n            centerBound = (x.min(), maxlim)\n\n        elif n == len(peaks) - 1:\n            center0 = peakMetadata[peaks[n - 1]]['Center']\n            minLim = np.average([center0, center0, center])\n            centerBound = (minLim, x.max())\n\n        elif 0 < n <  len(peaks) - 1:\n            center0 = peakMetadata[peaks[n - 1]]['Center']\n            center1 = peakMetadata[peaks[n + 1]]['Center']\n            minLim = np.average([center0, center0, center])\n            maxlim = np.average([center, center1, center1])\n            centerBound = (minLim, maxlim)\n\n        else:\n            centerBound = (x.min(), x.max())\n\n        fwhmBound = (10, 10*height)\n\n        parsGuess.append(height)\n        parsGuess.append(center)\n        parsGuess.append(fwhm)\n\n        bounds.append(heightBound)\n        bounds.append(centerBound)\n        bounds.append(fwhmBound)\n\n    newPars = spo.minimize(calcGaussResiduals, parsGuess, bounds = bounds).x\n\n    peakMetadata.update(makeGausses(x, newPars))\n\n    #peaks = sorted(list(peakMetadata.keys()), key = lambda peak: peakMetadata[peak]['Center'])\n\n    #print 'Heights : %s' % [peakMetadata[i]['Height'] for i in peaks]\n    #print 'FWHMs : %s' % [peakMetadata[i]['FWHM'] for i in peaks]\n    #print 'Areas : %s' % [peakMetadata[i]['Area'] for i in peaks]\n    #print 'H/W: %s' % [peakMetadata[i]['FWHM']/peakMetadata[i]['Height'] for i in peaks]\n\n    return peakMetadata",
  "def analysePlSpectrum(x, y, cutoff = 1200, fs = 70000, plRange = [540, 820], raiseExceptions = False, plot = False):\n\n    plMetadataKeys = ['Fit Error', 'Peak Heights', 'Peak FWHMs', 'Fit', 'Peak Centers']\n    plMetadata = {key : 'N/A' for key in plMetadataKeys}\n    plMetadata['NPoM?'] = True #Innocent until proven guilty\n\n    xTrunc, yTrunc = truncateSpectrum(x, y, startWl = plRange[0], finishWl = plRange[1])\n    \n    yPlTrunc = removeCosmicRays(xTrunc, yTrunc)\n    ySmooth = butterLowpassFiltFilt(yPlTrunc, cutoff = cutoff, fs = fs)\n    #if np.sum(ySmooth) > 0.03:\n    yMin = 0#ySmooth.min()\n    yTrunc -= yMin\n    ySmooth -= yMin    \n    \n    d1 = centDiff(xTrunc, ySmooth)\n    d2 = centDiff(xTrunc, d1)\n    d2Mins = detectMinima(d2)\n    d2Mins = np.array([i for i in d2Mins if ySmooth[i] > (ySmooth.max())*0.1])\n    \n    if plot == True:\n        fig, ax1 = plt.subplots()\n        ax2 = ax1.twinx()\n        ax1.plot(xTrunc, yTrunc)\n        ax1.plot(xTrunc, ySmooth)\n        ax2.plot(xTrunc, d2)\n        if len(d2Mins) > 0:\n            ax1.plot(xTrunc[d2Mins], ySmooth[d2Mins], 'o')\n        plt.title(f'Peak Identifier\\n{ySmooth.max() - ySmooth.min()}')\n        plt.show()\n\n    if len(d2Mins) == 0:\n        d2Mins = np.array([len(xTrunc)//2])\n        \n    for gN, i in enumerate(d2Mins):\n        gModN = GaussianModel(prefix = f'g{gN}_')\n        \n        parsN = gModN.make_params()\n        parsN[f'g{gN}_amplitude'].set(yTrunc[i]*5, min = 0, max = yTrunc.max())\n        parsN[f'g{gN}_height'].set(max = yTrunc.max())\n        parsN[f'g{gN}_center'].set(xTrunc[i], min = xTrunc[i] - 20, max = xTrunc[i] + 20)\n        parsN[f'g{gN}_sigma'].set(20, max = 30)\n        \n        if gN == 0:\n            gMod = gModN\n            pars = parsN\n        else:\n            gMod += gModN\n            pars.update(parsN)\n                    \n    yInit = gMod.eval(pars, x = xTrunc)\n  \n    gOut = gMod.fit(ySmooth, pars, x = xTrunc, nan_policy = 'propagate')\n\n    yFit = gOut.best_fit\n    yFitFull = gOut.eval(x = x)\n    comps = gOut.eval_components()\n\n    if plot == True:\n        for comp in comps.keys():\n            plt.plot(xTrunc, comps[comp], 'k--', label = comp)\n        plt.plot(xTrunc, yTrunc)\n        plt.plot(xTrunc, yFit, 'g-')\n        plt.plot(xTrunc, yInit)\n        plt.show()\n\n    plMetadata['Fit'] = yFitFull\n    plMetadata['Peak Heights'] = np.array([gOut.params[f'g{n}_height'].value for n, i in enumerate(d2Mins)])\n    plMetadata['Peak Centers'] = np.array([gOut.params[f'g{n}_center'].value for n, i in enumerate(d2Mins)])\n    plMetadata['Peak FWHMs'] = np.array([gOut.params[f'g{n}_fwhm'].value for n, i in enumerate(d2Mins)])\n    plMetadata['Fit Error'] = np.std(gOut.residual)\n\n    if True not in np.where(plMetadata['Peak Heights'] > 0, True, False):# If spectrum only has negative peaks, there is no fluorescence\n        plMetadata['NPoM?'] = False\n\n    return plMetadata",
  "def analysePlSpectrumFindGauss(x, y, windowLength = 221, polyorder = 7, cutoff = 1000, fs = 80000, raiseExceptions = False, plot = False, \n    specNo = 0, noiseThresh = 0.8,\n                      savGol = True):\n\n    plMetadataKeys = ['Fit Error', 'Peak Heights', 'Peak FWHMs', 'Fit', 'Peak Centers']\n    plMetadata = {key : 'N/A' for key in plMetadataKeys}\n    plMetadata['NPoM?'] = True #Innocent until proven guilty\n\n    peakMetadata = gaussMinimize(x, y, windowLength = windowLength, polyorder = polyorder, cutoff = cutoff, fs = fs, \n                        noiseThresh = noiseThresh, fwhmFactor = 1.8,\n                                 savGol = savGol)\n\n    fit = np.zeros(len(x))\n\n    for peak in peakMetadata.keys():\n        gauss = peakMetadata[peak]['Fit']\n\n        if plot == True or plot == 'all':\n            plt.plot(x, gauss, 'b--')\n\n        if peak != 'Peak 0':\n            fit += gauss\n\n    if plot == True or plot == 'all':\n        plt.plot(x, y, 'g-', lw = 0.5)\n        plt.plot(x, fit, 'k')\n        plt.show()\n\n    peaks = sorted(peakMetadata.keys(), key = lambda k: int(k.split('_')[1]))\n\n    plMetadata['Peak Heights'] = np.array([peakMetadata[peak]['Height'] for peak in peaks])\n\n    if True not in np.where(plMetadata['Peak Heights'] > 0, True, False):# If spectrum only has negative peaks, there is no fluorescence\n        plMetadata['NPoM?'] = False\n\n    plMetadata['Peak Centers'] = [peakMetadata[peak]['Center'] for peak in peaks]\n    plMetadata['Peak FWHMs'] = [peakMetadata[peak]['FWHM'] for peak in peaks]\n    plMetadata['Peak Fits'] = [peakMetadata[peak]['Fit'] for peak in peaks]\n    plMetadata['Fit'] = fit\n    residual = y - fit\n    plMetadata['Fit Error'] = np.std(residual)\n    \n    return plMetadata",
  "def plotAllStacks(outputFileName, sort = False, closeFigures = True, vThresh = 2e-4, sortingMethod = 'all', npom_types = None):\n    stackStart = time.time()\n\n    print('Plotting stacked spectral maps...')\n\n    with h5py.File(outputFileName, 'a') as opf:\n        date = opf['All Spectra (Raw)'].attrs['Date measured']\n\n        if npom_types is None:\n            npom_types = opf['NPoMs'].keys()\n\n        for groupName in npom_types:\n            gSpectra = opf['NPoMs/%s/Normalised' % groupName]\n            spectraNames = sorted(list(gSpectra.keys()), key = lambda spectrumName: int(spectrumName[9:]))\n            try:\n                x = gSpectra[spectraNames[0]].attrs['wavelengths']\n            except:\n                print('No data for %s' % groupName)\n                continue\n\n            yData = [gSpectra[spectrumName][()] for spectrumName in spectraNames]\n\n            if sort == True:\n                if sortingMethod in ['all', None]:\n                    sortingMethods = ['Coupled mode wavelength', 'Transverse mode wavelength', 'Weird peak wavelength',\n                                      'Coupled mode intensity (raw)', 'Transverse mode intensity (raw)', 'Weird peak intensity (raw)']\n\n                elif type(sortingMethod) != list:\n                    sortingMethods = sortingMethod\n\n                else:\n                    sortingMethods = sortingMethod\n\n                for sortingMethod in sortingMethods:\n                    sortingMethodTitle = (' ').join(sortingMethod.split(' ')[:3])\n                    plotTitle = '%s\\n%s by %s' % (date.decode(), groupName, sortingMethodTitle)\n                    imgName = f'{groupName} by {sortingMethodTitle}'\n                    print(f'\\t{imgName}')\n\n                    try:\n                        spectraNames = sorted(gSpectra.keys(), \n                                              key = lambda spectrumName: gSpectra[spectrumName].attrs[sortingMethod])\n                    except:\n                        print(sortingMethod)\n                        for i in gSpectra.keys():\n                            print(gSpectra[i].attrs[sortingMethod])\n\n                    yData = [gSpectra[spectrumName][()] for spectrumName in spectraNames]\n\n                    plotStackedMap(x, yData, imgName = imgName, plotTitle = plotTitle, closeFigures = closeFigures, \n                                   vThresh = vThresh)\n\n            else:\n                spectraNames = sorted(list(gSpectra.keys()), key = lambda spectrumName: int(spectrumName[9:]))\n                \n                try:\n                    x = gSpectra[spectraNames[0]].attrs['wavelengths']\n                except:\n                    print('No data for %s' % groupName)\n                    continue\n\n                yData = [gSpectra[spectrumName][()] for spectrumName in spectraNames]\n\n                imgName = '%s in order of measurement' % (groupName)\n                plotStackedMap(x, yData, imgName = imgName, plotTitle = imgName, closeFigures = closeFigures, vThresh = vThresh)\n\n    stackEnd = time.time()\n    timeElapsed = stackEnd - stackStart\n    print('\\tStacks plotted in %s seconds\\n' % timeElapsed)",
  "def histyFit(frequencies, bins, nPeaks = 1, xMaxs = [], yMaxs = []):\n\n    if len(xMaxs) > 0:\n        nPeaks = len(xMaxs)\n\n    if nPeaks == 1:\n        gMod = GaussianModel()\n        pars = gMod.guess(frequencies, x = bins)\n        out = gMod.fit(frequencies, pars, x = bins)#Performs the fit, based on initial guesses\n        resonance = out.params['center'].value\n        stderr = out.params['center'].stderr\n        fwhm = out.params['fwhm'].value\n        sigma = out.params['sigma'].value\n        fit = out.best_fit\n\n        print('\\t\\tAverage peakpos: %s +/- %s nm' % (resonance, stderr))\n        print('\\t\\tFWHM: %s nm\\n' % fwhm)\n\n    else:\n        gMod = GaussianModel(prefix = 'g0_')\n        pars = gMod.guess(frequencies, x = bins)\n\n        center = xMaxs[0]\n        height = yMaxs[0]\n\n        pars['g0_center'].set(center, min = bins.min(), max = (xMaxs[1] + xMaxs[0])/2)\n        pars['g0_height'].set(height, min = 0)\n\n        for n in range(nPeaks)[1:]:\n\n            if n == nPeaks - 1:\n                cMax = bins.max()\n\n            else:\n                cMax = (xMaxs[n] + xMaxs[n + 1])/2\n\n            cMin = (xMaxs[n] + xMaxs[n - 1])/2\n\n            center = xMaxs[n]\n            height = yMaxs[n]\n\n            gModN = GaussianModel(prefix = 'g%s_' % n)\n            parsN = gModN.guess(frequencies, x = bins)\n            parsN['g%s_center' % n].set(center, min = cMin, max = cMax)\n            parsN['g%s_height' % n].set(height, min = 0)\n\n            gMod += gModN\n            pars.update(parsN)\n\n        out = gMod.fit(frequencies, pars, x = bins)\n        fit = out.best_fit\n        resonance = []\n        stderr = []\n        fwhm = []\n        sigma = []\n\n        for n in range(nPeaks):\n            resonance.append(out.params['g%s_center' % n].value)\n            stderr.append(out.params['g%s_center' % n].stderr)\n            fwhm.append(out.params['g%s_fwhm' % n].value)\n            sigma.append(out.params['g%s_sigma' % n].value)\n\n        #try:\n        print('\\t\\tAverage peak positions: %s nm' % [float('%.02f' % i) for i in resonance])\n        try:\n            print('\\t\\tStdErrs: %s nm' % [float('%.02f' % i) for i in stderr])\n        except:\n            print(f'\\t\\tStdErrs: {stderr} nm')\n            stderr = np.zeros(len(stderr))\n        print('\\t\\tFWHMs: %s nm\\n' % [float('%.02f' % i) for i in fwhm])\n\n        #except:\n        #    stderr = np.zeros(len(stderr))\n        #    print('\\t\\tAverage peak positions: %s' % resonance)\n        #    print('\\t\\tStdErrs: %s' % stderr)\n        #    print('\\t\\tFWHMs: %s nm\\n' % fwhm)\n    return resonance, stderr, fwhm, sigma, fit",
  "def reduceNoise(y, factor = 10, cutoff = 1500, fs = 60000):\n    ySmooth = butterLowpassFiltFilt(y, cutoff = cutoff, fs = fs)\n    yNoise = y - ySmooth\n    yNoise /= factor\n    y = ySmooth + yNoise\n    return y",
  "def plotHistogram(outputFileName, npomType = 'All NPoMs', startWl = 450, endWl = 987, binNumber = 80, plot = True, minBinFactor = 5, closeFigures = False,\n                  irThreshold = 8, cmLowLim = 580, density = False, nPeaks = 1, peaks = None):\n\n    plotStart = time.time()\n\n    if 'Histograms' not in os.listdir('.'):\n        os.mkdir('Histograms')\n\n    print('Preparing to create DF histogram...')\n    print('\\tFilter: %s' % npomType)\n\n    with h5py.File(outputFileName, 'a') as opf:\n        date = opf['All Spectra (Raw)'].attrs['Date measured']\n        gSpectra = opf['NPoMs/%s/Normalised' % npomType]\n        gSpecRaw = opf['NPoMs/%s/Raw' % npomType]\n\n        spectraNames = sorted([i for i in list(gSpectra.keys())\n                               if gSpectra[i].attrs['Coupled mode wavelength'] != 'N/A'\n                               and cmLowLim < gSpectra[i].attrs['Coupled mode wavelength'] < endWl],\n                              key = lambda i: int(i[9:]))\n\n        x = gSpectra[spectraNames[0]].attrs['wavelengths']\n\n        peakPositions = [gSpectra[i].attrs['Coupled mode wavelength']\n                         for n, i in enumerate(spectraNames)]\n\n        frequencies, bins = np.histogram(peakPositions, bins = 80, range = (450., 900.), density = density)\n        binSize = bins[1] - bins[0]\n        print('\\tFrequency distribution created for %s DF spectra' % len(spectraNames))\n\n        print('\\tPerforming Gaussian fit')\n\n        if peaks is not None:\n            yMaxs = [frequencies[abs(xMax - bins[:-1]).argmin()] for xMax in peaks]\n            xMaxs = []\n        else:\n            yMaxs = []\n            xMaxs = []\n\n        try:\n            resonance, stderr, fwhm, sigma, fit = histyFit(frequencies, bins[:-1], nPeaks = nPeaks, xMaxs = xMaxs, yMaxs = yMaxs)\n\n        except Exception as e:\n            print(e)\n            resonance = 'N/A'\n            stderr = 'N/A'\n            fwhm = 'N/A'\n            sigma = 'N/A'\n\n        print('\\tCollecting and averaging spectra for plot...')\n\n        yDataBinned = []\n        yDataRawBinned = []\n        binnedSpectraList = {}\n\n        for n, binEdge in enumerate(bins[:-1]):\n            binSpecNames = np.array([i for i in spectraNames\n                                     if binEdge < gSpectra[i].attrs['Coupled mode wavelength'] < bins[n + 1]\n                                     and gSpectra[i].attrs['Intensity ratio (normalised)'] < irThreshold\n                                     and truncateSpectrum(x, gSpectra[i][()]).min() > -irThreshold])\n\n            binnedSpectraList[binEdge] = binSpecNames\n\n            if len(binSpecNames) > 0:\n                avgSpec = old_div(np.sum(np.array([gSpectra[i][()] for i in binSpecNames]), 0), len(binSpecNames))\n                avgSpecRaw = old_div(np.sum(np.array([gSpecRaw[i][()] for i in binSpecNames]), 0), len(binSpecNames))\n\n            else:\n                avgSpec = np.zeros(len(x))\n                avgSpecRaw = np.zeros(len(x))\n\n            yDataBinned.append(avgSpec)\n            yDataRawBinned.append(avgSpecRaw)\n\n        yDataBinned = np.array(yDataBinned)\n        yDataRawBinned = np.array(yDataRawBinned)\n\n        if minBinFactor == 0:\n            minBin = 0\n\n        else:\n            minBin = old_div(max(frequencies),minBinFactor)\n\n        if plot == True:\n            print('\\tPlotting Histogram...')\n            fig = plt.figure(figsize = (8, 6))\n\n            cmap = plt.get_cmap('jet')\n\n            ax1 = fig.add_subplot(111)\n            ax1.set_zorder(1)\n            ax2 = ax1.twinx()\n            ax2.set_zorder(0)\n            ax1.patch.set_visible(False)\n\n            yDataPlot = []\n            freqsPlot = []\n            binsPlot = []\n            yMax = 0\n            yMin = 7\n\n            for n, yDatum in enumerate(yDataBinned):\n\n                if frequencies[n] > minBin:\n                    yDataPlot.append(yDatum)\n                    freqsPlot.append(frequencies[n])\n                    binsPlot.append(bins[n])\n\n            yDataPlot = np.array(yDataPlot)\n            freqsPlot = np.array(freqsPlot)\n            binsPlot = np.array(binsPlot)\n\n            colors = [cmap(256 - n*(old_div(256,len(yDataPlot)))) for n, yDataSum in enumerate(yDataPlot)][::-1]\n\n            for n, yDataSum in enumerate(yDataPlot):\n\n                ySmooth = reduceNoise(yDataSum, factor = 7)\n                currentYMax = truncateSpectrum(x, ySmooth)[1].max()\n                currentYMin = truncateSpectrum(x, ySmooth)[1].min()\n\n                if currentYMax > yMax:\n                    yMax = currentYMax\n\n                if currentYMin < yMin:\n                    yMin = currentYMin\n\n                ax1.plot(x, ySmooth, lw = 0.7, color = colors[n])\n\n            ax1.set_ylim(0, yMax * 1.45)\n            ax1.set_ylabel('Normalised Intensity', fontsize = 18)\n            ax1.tick_params(labelsize = 15)\n            ax1.set_xlabel('Wavelength (nm)', fontsize = 18)\n            ax2.bar(bins[:-1], frequencies, color = 'grey', width = 0.8*binSize, alpha = 0.8, linewidth = 0.6)\n            ax2.bar(binsPlot, freqsPlot, color = colors, width = 0.8*binSize, alpha = 0.4, linewidth = 1)\n            ax2.plot(bins[:-1], fit, 'k--')\n            ax2.set_xlim(450, 900)\n            ax2.set_ylim(0, max(frequencies)*1.05)\n            ax2.set_ylabel('Frequency', fontsize = 18, rotation = 270)\n            ax2.yaxis.set_label_coords(1.11, 0.5)\n            ax2.set_yticks([int(tick) for tick in ax2.get_yticks() if tick > 0][:-1])\n            ax2.tick_params(labelsize = 15)            \n            #plt.title('%s: %s\\nRes = %s $\\pm$ %s\\nFWHM = %s' % (date.decode(), npomType, str(resonance), str(stderr), str(fwhm)))\n\n            fig.tight_layout()\n\n            if not npomType.endswith('.png'):\n                npomType += '.png'\n            \n            fig.savefig('Histograms/DF %s' % (npomType), bbox_inches = 'tight')\n\n            if closeFigures == True:\n                plt.close('all')\n\n            else:\n                plt.show()\n\n            plotEnd = time.time()\n            plotTime = plotEnd - plotStart\n            print('\\tHistogram plotted in %.02f seconds\\n' % plotTime)\n\n    return frequencies, bins, yDataBinned, yDataRawBinned, binnedSpectraList, x, resonance, stderr, fwhm, sigma, fit",
  "def plotHistAndFit(outputFileName, npomType = 'All NPoMs', startWl = 450, endWl = 987, binNumber = 80, plot = True,\n                  minBinFactor = 5, closeFigures = False, irThreshold = 8, nPeaks = 1):\n\n    #try:\n\n    dfHistyBits = plotHistogram(outputFileName, npomType = npomType, minBinFactor = minBinFactor, closeFigures = closeFigures, \n                                irThreshold = irThreshold, plot = plot, nPeaks = nPeaks, endWl = endWl)\n    dfHistyBits = list(dfHistyBits)\n    \n    for n, val in enumerate(dfHistyBits):\n        if type(val) == type(None):\n            dfHistyBits[n] = np.nan\n    \n    frequencies = dfHistyBits[0]\n    bins = dfHistyBits[1]\n    yDataBinned = dfHistyBits[2]\n    binnedSpectraList = dfHistyBits[4]\n    histyWl = dfHistyBits[5]\n    avgResonance = dfHistyBits[6]\n    stderr = dfHistyBits[7]\n    fwhm = dfHistyBits[8]\n    sigma = dfHistyBits[9]\n    fit = dfHistyBits[10]\n\n    #except:\n    #    print '\\tHistogram plot failed for %s' % npomType\n    #    return\n\n    with h5py.File(outputFileName, 'a') as opf:\n\n        if 'Histogram data' in opf['NPoMs/%s' % npomType]:\n            del opf['NPoMs/%s/Histogram data' % npomType]\n\n        gHist = opf.create_group('NPoMs/%s/Histogram data' % npomType)\n        gSpectraBinned = gHist.create_group('Binned y data')\n        gHist.attrs['Average resonance'] = avgResonance\n        gHist.attrs['Error'] = stderr\n        gHist.attrs['FWHM'] = fwhm\n        gHist.attrs['Standard deviation'] = sigma\n        gHist.attrs['Gaussian Fit'] = fit\n        gHist.attrs['wavelengths'] = histyWl\n\n        gHist['Bins'] = bins\n        gHist['Frequencies'] = frequencies\n\n        gHist['Frequencies'].attrs['wavelengths'] = gHist['Bins']\n        binSize = bins[1] - bins[0]\n        binsSorted = sorted(bins[:-1], key = lambda binStart: float(binStart))\n\n        for binStart in binsSorted:\n            binnedSpectraList[binStart] = sorted(binnedSpectraList[binStart], key = lambda spectrum: int(spectrum.split(' ')[-1]))\n\n        wLenned = False\n\n        for n, binStart in enumerate(binsSorted):\n            if len(binnedSpectraList[binStart]) > 0:\n\n                binEnd = binStart + binSize\n                binName = 'Bin %.02d' % n\n                gBin = gSpectraBinned.create_group(binName)\n\n                gBin.attrs['Bin start (nm)'] = binStart\n                gBin.attrs['Bin end (nm)'] = binEnd\n                gBin['Sum'] = yDataBinned[n]\n\n                if wLenned == False:\n                    wlenN = n\n                    gBin['Sum'].attrs['wavelengths'] = histyWl\n                    wLenned = True\n\n                else:\n                    gBin['Sum'].attrs['wavelengths'] = gSpectraBinned['Bin %s/Sum' % wlenN].attrs['wavelengths']\n\n                for spectrumName in binnedSpectraList[binStart]:\n                    gBin[spectrumName] = opf['NPoMs/%s/Raw/%s' % (npomType, spectrumName)]\n                    gBin[spectrumName].attrs.update(opf['NPoMs/%s/Raw/%s' % (npomType, spectrumName)].attrs)",
  "def plotDfPlHistogram(outputFileName, npomType = 'All NPoMs', startWl = 450, endWl = 987, binNumber = 80, plot = True, minBinFactor = 5, \n                      closeFigures = False, irThreshold = 8, cmLowLim = 580, density = False, nPeaks = 1, peaks = None, plFactor = 5000, vectorImg = False):\n\n    plotStart = time.time()\n\n    if 'Histograms' not in os.listdir('.'):\n        os.mkdir('Histograms')\n        \n    plt.rcParams['xtick.direction'] = 'in'\n\n    print('Preparing to create DF histogram...')\n    print('\\tFilter: %s' % npomType)\n\n    with h5py.File(outputFileName, 'a') as opf:\n        date = opf['All Spectra (Raw)'].attrs['Date measured']\n        experimentName = os.getcwd().split('\\\\')[-1]\n        gSpectra = opf['NPoMs/%s/Normalised' % npomType]\n        gSpecRaw = opf['NPoMs/%s/Raw' % npomType]\n        gPlSpectra = opf['NPoMs/%s/PL Data' % npomType]\n\n        spectraNames = sorted([i for i in list(gSpectra.keys())\n                               if gSpectra[i].attrs['Coupled mode wavelength'] != 'N/A'\n                               and cmLowLim < gSpectra[i].attrs['Coupled mode wavelength'] < endWl],\n                              key = lambda i: int(i[9:]))\n\n        x = gSpectra[spectraNames[0]].attrs['wavelengths']\n\n        peakPositions = [gSpectra[i].attrs['Coupled mode wavelength']\n                         for n, i in enumerate(spectraNames)]\n\n        frequencies, bins = np.histogram(peakPositions, bins = 80, range = (450., 900.), density = density)\n        binSize = bins[1] - bins[0]\n        print('\\tFrequency distribution created for %s DF spectra' % len(spectraNames))\n\n        print('\\tPerforming Gaussian fit')\n\n        if peaks is not None:\n            yMaxs = [frequencies[abs(xMax - bins[:-1]).argmin()] for xMax in peaks]\n            xMaxs = []\n        else:\n            yMaxs = []\n            xMaxs = []\n\n        try:\n            resonance, stderr, fwhm, sigma, fit = histyFit(frequencies, bins[:-1], nPeaks = nPeaks, xMaxs = xMaxs, yMaxs = yMaxs)\n\n        except Exception as e:\n            print(e)\n            resonance = 'N/A'\n            stderr = 'N/A'\n            fwhm = 'N/A'\n            sigma = 'N/A'\n\n        print('\\tCollecting and averaging spectra for plot...')\n\n        yDataBinned = []\n        yDataRawBinned = []\n        plDataBinned = []\n        binnedSpectraList = {}\n\n        for n, binEdge in enumerate(bins[:-1]):\n            binSpecNames = np.array([i for i in spectraNames\n                                     if binEdge < gSpectra[i].attrs['Coupled mode wavelength'] < bins[n + 1]\n                                     and gSpectra[i].attrs['Intensity ratio (normalised)'] < irThreshold\n                                     and truncateSpectrum(x, gSpectra[i][()]).min() > -irThreshold])\n\n            binnedSpectraList[binEdge] = binSpecNames\n\n            if len(binSpecNames) > 0:\n                avgSpec = np.sum(np.array([gSpectra[i][()] for i in binSpecNames]), 0)/len(binSpecNames)\n                avgSpecRaw = np.sum(np.array([gSpecRaw[i][()] for i in binSpecNames]), 0)/len(binSpecNames)\n                avgPlSpec = np.sum(np.array([gPlSpectra[f'PL {i}'][()] for i in binSpecNames]), 0)/len(binSpecNames)\n                \n                #xTrunc, avgPlTrunc = truncateSpectrum(x, avgPlSpec, startWl = 540, finishWl = 800)\n                #plt.plot(xTrunc, avgPlTrunc)\n                #plt.show()\n\n            else:\n                avgSpec = np.zeros(len(x))\n                avgSpecRaw = np.zeros(len(x))\n                avgPlSpec = np.zeros(len(x))\n\n            yDataBinned.append(avgSpec)\n            yDataRawBinned.append(avgSpecRaw)\n            plDataBinned.append(avgPlSpec)\n\n        yDataBinned = np.array(yDataBinned)\n        yDataRawBinned = np.array(yDataRawBinned)\n        plDataBinned = np.array(plDataBinned)\n\n        if minBinFactor == 0:\n            minBin = 0\n\n        else:\n            minBin = (max(frequencies)/minBinFactor)\n\n        if plot == True:\n            print('\\tPlotting Histogram...')\n            fig = plt.figure(figsize = (8, 6))          \n            ax1 = fig.add_subplot(111)\n            ax1.set_zorder(1)\n            ax2 = ax1.twinx()\n            ax2.set_zorder(0)\n            ax1.patch.set_visible(False)\n\n            yDataPlot = []\n            plDataPlot = []\n            freqsPlot = []\n            binsPlot = []\n            yMax = 0\n\n            for n, yDatum in enumerate(yDataBinned):\n\n                if frequencies[n] > minBin:\n                    yDataPlot.append(yDatum)\n                    plDataPlot.append(plDataBinned[n])\n                    freqsPlot.append(frequencies[n])\n                    binsPlot.append(bins[n])\n\n            yDataPlot = np.array(yDataPlot)\n            plDataPlot = np.array(plDataPlot)\n            freqsPlot = np.array(freqsPlot)\n            binsPlot = np.array(binsPlot)\n\n            nColors = len(yDataPlot)\n            cmap = plt.get_cmap('jet', len(yDataPlot))\n\n            #colors = [cmap(256 - n*(old_div(256,len(yDataPlot)))) for n, yDataSum in enumerate(yDataPlot)][::-1]\n            colors = [cmap(n) for n in range(nColors)]\n\n            for n, (yDataSum, plDataSum) in enumerate(zip(yDataPlot, plDataPlot)):\n                xTrunc, yTrunc = truncateSpectrum(x, yDataSum, startWl = 500, endWl = 900)\n                xPlTrunc, yPlTrunc = truncateSpectrum(x, plDataSum, startWl = 540, endWl = 800)\n\n                ySmooth = reduceNoise(yTrunc, factor = 7)\n                yPlSmooth = reduceNoise(yPlTrunc, factor = 7)\n\n                yMax = max(ySmooth.max(), yPlSmooth.max()*plFactor, yMax)\n                ax1.plot(xTrunc, ySmooth, lw = 0.7, alpha = 0.5, color = cmap(n))#colors[n])\n                ax1.plot(xPlTrunc, yPlSmooth*plFactor, lw = 0.7, color = cmap(n))\n\n            if 'MTPP' in experimentName:\n                metalCentre = experimentName.split('-MTPP')[0][-2:]\n                if 'CB' in experimentName:\n                    cbType = experimentName.split('CB')[1][0]\n                    cbN = 4\n                    mtppN = {'7' : 1, '8' : 2}[cbType]\n                    solnSpecName = f'{metalCentre}-MTPP {mtppN};{cbN} CB[{cbType}].csv'\n                else:\n                    solnSpecName = f'{metalCentre}-MTPP MeOH + MeCN.csv'\n\n                csvDir = r'C:\\Users\\car72\\Documents\\PhD\\Thesis\\Figs\\MTPP\\Chem\\Experiments\\PL\\csvs'\n                csvFile = os.path.join(csvDir, solnSpecName)\n                csvData = np.transpose(np.genfromtxt(csvFile, delimiter = ',', dtype = float))\n                solnPlX = csvData[0]\n                #print(csvData[1].max())\n                solnPlY = csvData[1]/40\n                ax1.plot(solnPlX, solnPlY, lw = 2, color = 'k', zorder = -5, label = 'Solution PL Spectrum')\n\n            plt.rcParams['xtick.direction'] = 'in'\n            #ax1.set_ylim(0, max(yMax*1.05, 7))\n            ax1.set_ylim(0, 9.5)\n            ax1.set_yticks([])\n            #ax1.set_ylabel('Normalised Intensity', fontsize = 18)\n            #ax1.tick_params(labelsize = 15)\n            #ax1.set_xlabel('Wavelength (nm)', fontsize = 18)\n            ax2.bar(bins[:-1], frequencies, color = 'grey', width = 0.8*binSize, alpha = 0.8, linewidth = 0.6)\n            ax2.bar(binsPlot, freqsPlot, color = colors, width = 0.8*binSize, alpha = 0.4, linewidth = 1)\n            ax2.plot(bins[:-1], fit, 'k--')\n            #ax2.set_xlim(450, 900)\n            ax2.set_xlim(500, 900)\n            ax2.set_ylim(0, max(frequencies)*1.05)\n            #ax2.set_ylabel('Frequency', fontsize = 18, rotation = 270)\n            #ax2.yaxis.set_label_coords(1.11, 0.5)\n            #ax2.set_yticks([int(tick) for tick in ax2.get_yticks() if tick > 0][:-1])\n            ax2.set_yticks([])\n            #ax2.tick_params(labelsize = 15)            \n            #plt.title('%s: %s\\nRes = %s $\\pm$ %s\\nFWHM = %s' % (experimentName, npomType, str(resonance), str(stderr), str(fwhm)))\n\n            fig.tight_layout()             \n\n            if not npomType.endswith('.png'):\n                npomType += '.png'\n\n            if vectorImg == True:\n                npomType = npomType.replace('.png', '.svg')\n\n            \n            fig.savefig('Histograms/DF PL %s' % (npomType), bbox_inches = 'tight')\n\n            if closeFigures == True:\n                plt.close('all')\n\n            else:\n                plt.show()\n\n            plotEnd = time.time()\n            plotTime = plotEnd - plotStart\n            print('\\tHistogram plotted in %.02f seconds\\n' % plotTime)\n\n    return frequencies, bins, yDataBinned, yDataRawBinned, binnedSpectraList, x, resonance, stderr, fwhm, sigma, fit",
  "def plotPlHistogram(outputFileName, npomType = 'All NPoMs', startWl = 505, endWl = 900, plRange = [540, 820], binNumber = 80, \n                    plot = True, minBinFactor = 50, closeFigures = False, peak = 'all', peaks = None):\n\n    plotStart = time.time()\n    binWidth = (900-505)/binNumber\n    binNumber = int((endWl - startWl)/binWidth)\n    print(f'{binNumber} PL bins')\n    plt.rcParams['xtick.direction'] = 'in'\n\n    if 'Histograms' not in os.listdir('.'):\n        os.mkdir('Histograms')\n\n    print('Preparing to create PL histogram...')\n    print('\\tFilter: %s' % npomType)\n\n    with h5py.File(outputFileName, 'a') as opf:\n        date = opf['All Spectra (Raw)'].attrs['Date measured']\n        gSpectra = opf['NPoMs/%s/PL Data (Normalised)' % npomType]\n        gSpecRaw = opf['NPoMs/%s/PL Data' % npomType]\n\n        alignedSpecNames = opf['NPoMs/Aligned NPoMs/Raw'].keys()\n        if len(alignedSpecNames) == 0:\n            alignedSpecNames = reCheckCentering()\n\n        spectraNames = sorted([i for i in gSpectra.keys() if gSpectra[i][()].max() < 10 and i[3:] in alignedSpecNames],\n                               key = lambda i: int(i.split(' ')[-1]))\n        x = gSpectra[spectraNames[0]].attrs['wavelengths']\n        spectra = np.array([gSpectra[i][()] for i in spectraNames])\n        rawSpectra = np.array([gSpectra[i].attrs['Raw Spectrum'][()] for i in spectraNames])\n        peakVals = np.array([np.array(list(zip(gSpecRaw[i].attrs['Peak Centers'], gSpecRaw[i].attrs['Peak Heights'])))\n                                  for i in spectraNames if not any(gSpectra[i].attrs['Peak Heights'] > gSpectra[i][()][184:553].max()*1.1)])\n\n        peakVals = np.concatenate(peakVals)\n        peakVals = np.array([i for i in peakVals if (plRange[0] < i[0] and i[0] < plRange[1])])\n        #print(peakVals)\n        peakVals = sorted(peakVals, key = lambda peak: peak[1])[:-1]\n        #print(peakVals[::-1])\n\n        peakVals = np.transpose(peakVals)\n        peakPositions = peakVals[0]\n        peakHeights = peakVals[1]\n\n        frequencies, bins = np.histogram(peakPositions, bins = binNumber, range = (startWl, endWl), density = False, weights = peakHeights)\n        frequencies /= len(peakPositions)\n        binSize = bins[1] - bins[0]\n\n        #plt.bar(bins[:-1], frequencies, color = 'grey', width = 0.8*binSize, alpha = 0.8, linewidth = 0.6)\n        #plt.show()\n\n        print('\\tFrequency distribution created for %s PL spectra' % len(spectraNames))\n\n        print('\\tPerforming Gaussian fits')\n\n        #try:\n        freqInterp = np.interp(x, bins[:-1], frequencies)\n        #freqInterp = removeCosmicRays(x, freqInterp)\n        #freqInterp = removeNaNs(freqInterp)\n        freqSmooth = butterLowpassFiltFilt(freqInterp, cutoff = 1400, fs = 70000)\n\n        if peaks is None:\n            peaks = detectMinima(-freqSmooth)\n            peaks = np.array([i for i in peaks if freqSmooth.max()/freqSmooth[i] < minBinFactor])\n\n        else:\n            peaks = np.array([abs(x - peak).argmin() for peak in peaks])\n\n        xMaxs = x[peaks]\n        yMaxs = freqSmooth[peaks]\n        #plt.plot(x, freqSmooth)\n        #plt.plot(xMaxs, yMaxs, 'o')\n        #plt.show()\n        nPeaks = len(peaks)\n\n        resonance, stderr, fwhm, sigma, fit = histyFit(frequencies, bins[:-1], nPeaks = nPeaks, xMaxs = xMaxs, yMaxs = yMaxs)\n\n        if nPeaks == 1:\n            resonance = [resonance]\n            stderr = [stderr]\n            fwhm = [fwhm]\n            sigma = [sigma]\n\n        #for n, res in enumerate(resonance):\n        #print '\\t\\tAverage peakpos: %s' % (resonance)\n        #print '\\t\\tFWHM: %s nm\\n' % fwhm\n\n        #except Exception as e:\n        #    print 'Gaussfit for histogram failed because %s' % e\n        #    resonance = 'N/A'\n        #    stderr = 'N/A'\n        #    fwhm = 'N/A'\n        #    sigma = 'N/A'\n\n        print('\\tCollecting and averaging spectra for plot...')\n\n        yDataBinned = []\n        yDataRawBinned = []\n        binnedSpecDict = {binEdge : [] for binEdge in bins[:-1]}\n        binnedSpecDictRaw = {binEdge : [] for binEdge in bins[:-1]}\n        binnedSpecNames = {binEdge : [] for binEdge in bins[:-1]}\n\n        print('\\t\\tSorting spectra into bins...')\n        sortStart = time.time()\n\n        for specN, i in enumerate(spectraNames):\n            peakCenters = gSpectra[i].attrs['Peak Centers'][()]\n            for n, binEdge in enumerate(bins[:-1]):\n                if True in (peakCenters > binEdge) and True in (peakCenters < bins[n + 1]):\n                    binnedSpecDict[binEdge].append(spectra[specN])\n                    binnedSpecDictRaw[binEdge].append(rawSpectra[specN])\n                    binnedSpecNames[binEdge].append(i)\n\n        print(f'\\t\\tSorted in {time.time() - sortStart:.2f} seconds')\n        print('\\t\\tAveraging binned spectra...')\n\n        for n, binEdge in enumerate(bins[:-1]):#for each bin\n            #print(n)\n\n            #binSpecNames = np.array([i for i in spectraNames\n            #                         if True in (gSpectra[i].attrs['Peak Centers'][()] > binEdge)\n            #                         and True in (gSpectra[i].attrs['Peak Centers'][()] < bins[n + 1])])\n\n            #binnedSpectraList[binEdge] = binSpecNames #list of names added to the bin's entry in a dictionary\n            binnedSpectra = np.array(binnedSpecDict[binEdge])\n            binnedSpectRaw = np.array(binnedSpecDictRaw[binEdge])\n\n            if len(binnedSpectra) > 0:#if there are spectra that fit this criteria\n                #print(f'Averaging spectra in bin {n}')\n                avgSpec = np.average(binnedSpectra, 0)#take the average\n                #xTrunc, avgSpecTrunc = truncateSpectrum(x, avgSpec, startWl = plRange[0], finishWl = plRange[1])\n                #avgSpec /= avgSpec.max()\n\n                #print('Averaged')\n\n                if abs(avgSpec.max()) > 100: #this means something has gone wrong with initial analysis\n                    print('\\n\\tAnomaly detected in bin %s (%s nm)' % (n, binEdge))\n                    print('\\tSearching for offending spectra...')\n                    specFound = False\n\n                    for binSpecName, binnedSpectrum in zip(binnedSpecNames[binEdge], binnedSpectra):\n                        if binnedSpectrum.max() > 100:\n                            print('\\t%s looks dodgy. Max point = %s' % (binSpecName, binnedSpectrum.max()))\n                            specFound = True\n\n                    if specFound == False:\n                        print('\\tCulprit not found. Please investigate the following spectra:')\n                        print(binnedSpecNames[binEdge])\n\n                avgSpecRaw = np.average(binnedSpectRaw, 0)\n                #avgSpecRaw = truncateSpectrum(x, avgSpecRaw, startWl = plRange[0], finishWl = plRange[1])[1]\n\n            else:\n                avgSpec = np.zeros(len(x))\n                avgSpecRaw = np.zeros(len(x))\n\n            yDataBinned.append(avgSpec)\n            yDataRawBinned.append(avgSpecRaw)\n\n        yDataBinned = np.array(yDataBinned)\n        yDataRawBinned = np.array(yDataRawBinned)\n        yMax = max([truncateSpectrum(x, i, startWl = plRange[0], finishWl = plRange[1])[1].max() for i in yDataRawBinned])\n\n        print('\\tPlotting Histogram...')\n\n        if minBinFactor == 0:\n            minBin = 0\n\n        else:\n            minBin = max(frequencies)/minBinFactor\n\n        if plot == True:\n            fig = plt.figure(figsize = (10, 7))\n\n            cmap = plt.get_cmap('jet')\n\n            ax1 = fig.add_subplot(111)\n            ax1.set_zorder(1)\n            ax2 = ax1.twinx()\n            ax2.set_zorder(0)\n            ax1.patch.set_visible(False)\n            ax1.ticklabel_format(style = 'scientific', scilimits = (0, 3))\n            ax2.ticklabel_format(style = 'scientific', scilimits = (0, 3))\n\n            yDataPlot = []\n            yDataRawPlot = []\n            freqsPlot = []\n            binsPlot = []\n\n            for n, yDatum in enumerate(yDataBinned):\n\n                if frequencies[n] > minBin:\n                    yDataPlot.append(yDatum)\n                    yDataRawPlot.append(yDataRawBinned[n])\n                    freqsPlot.append(frequencies[n])\n                    binsPlot.append(bins[n])\n\n            yDataPlot = np.array(yDataPlot)\n            yDataRawPlot = np.array(yDataRawPlot)\n            freqsPlot = np.array(freqsPlot)\n            binsPlot = np.array(binsPlot)\n\n            colors = [cmap(256 - n*(256//len(yDataPlot))) for n, yDataSum in enumerate(yDataPlot)][::-1]\n\n            #if peak.lower() != 'all':\n\n            yMax = 0\n\n            for n, yDataSum in enumerate(yDataPlot):\n                #xRawPlot, yRawPlot = truncateSpectrum(x, yDataRawPlot[n], startWl = startWl, finishWl = 820)\n                xPlot, yPlot = truncateSpectrum(x, yDataSum, startWl = plRange[0], finishWl = plRange[1])\n                #xNorm, yNorm = truncateSpectrum(x, yDataRawPlot[n], startWl = startWl, finishWl = plRange[1])\n                yNorm = removeCosmicRays(xPlot, yPlot)\n                yMax = max(yMax, yNorm.max())\n                #yPlot = reduceNoise(yPlot, cutoff = 1500, fs = 60000, factor = np.log10(1/yMax) + 2)\n                #ax1.plot(xPlot, yPlot/2, lw = 0.7, color = colors[n])\n                #ax1.plot(xRawPlot, yRawPlot, lw = 0.7, color = colors[n])\n                #ax1.plot(x, ySmooth, lw = 0.7, color = colors[n])\n\n            for n, yDataSum in enumerate(yDataPlot):\n                #xRawPlot, yRawPlot = truncateSpectrum(x, yDataRawPlot[n], startWl = startWl, finishWl = 820)\n                xPlot, yPlot = truncateSpectrum(x, yDataSum, startWl = plRange[0], finishWl = plRange[1])\n                #xNorm, yNorm = truncateSpectrum(x, yDataRawPlot[n], startWl = startWl, finishWl = plRange[1])\n                #yNorm = removeCosmicRays(xPlot, yPlot)\n                #yMax = max(yMax, yNorm.max())\n                yPlot = reduceNoise(yPlot, cutoff = 1500, fs = 60000, factor = np.log10(1/yMax) + 2)\n                ax1.plot(xPlot, yPlot/2, lw = 0.7, color = colors[n], alpha = 0.7)\n                #ax1.plot(xRawPlot, yRawPlot, lw = 0.7, color = colors[n])\n                #ax1.plot(x, ySmooth, lw = 0.7, color = colors[n])\n\n            #yMax *= 0.5\n\n            #if peak.lower() != 'all':\n            ax1.set_ylim(0, yMax)#yMax * 1.45)\n            #ax1.set_ylim(0, 0.0024)#yMax * 1.45)\n            ax1.set_ylabel('Intensity', fontsize = 20)\n            ax1.tick_params(labelsize = 18)\n            ax1.set_xlabel('Wavelength (nm)', fontsize = 20)\n\n            ax2.bar(bins[:-1], frequencies, color = 'grey', width = 0.8*binSize, alpha = 0.8, linewidth = 0.6)\n            ax2.bar(binsPlot, freqsPlot, color = colors, width = 0.8*binSize, alpha = 0.4, linewidth = 1)\n            ax2.set_xlim(500, 900)\n            ax2.set_ylim(0, max(frequencies)*1.05)\n\n            plt.rcParams['figure.titlesize'] = 20\n            plt.rcParams['axes.titlesize'] = 20\n\n            if peak.lower() != 'all':\n                ax2.set_ylabel('Frequency', fontsize = 20)#, rotation = 270)\n                ax2.yaxis.set_label_coords(1.11, 0.5)\n                ax2.set_yticks([int(tick) for tick in ax2.get_yticks() if tick > 0][:-1])\n                plt.title(f'{date.decode()}: {npomType}\\nRes = {resonance:.2f} $\\pm$ {stderr:.2f}\\nFWHM = %s' % (str(resonance), str(stderr), str(fwhm)))\n\n            else:\n                ax2.set_ylabel('Frequency', fontsize = 18)\n                ax3 = ax1.twinx()\n                ax3.patch.set_visible(False)                \n                #ax3.plot(bins[:-1], fit, 'k--', zorder = 100, lw = 3)\n                ax3.set_xlim(ax2.get_xlim())\n                #ax3.set_xticks([])\n                ax3.set_ylim(ax2.get_ylim())\n                ax3.set_yticks([])\n                ax3.set_zorder(10)\n                ax3.patch.set_visible(False)\n                #ax3.plot(bins[:-1], fit, 'k--', zorder = 100, lw = 3)\n                if type(date) != str:\n                    date = date.decode()\n\n                try:\n                    plt.title('%s: %s\\n%s peaks at:\\n%s' % (date, npomType, nPeaks, str([float('%.02f' % i) for i in resonance])[1:-1]))\n                except:\n                    plt.title('%s: %s' % (date, npomType))\n \n            experimentName = os.getcwd().split('\\\\')[-1]\n\n            if 'MTPP' in experimentName:\n                metalCentre = experimentName.split('-MTPP')[0][-2:]\n                if 'CB' in experimentName:\n                    cbType = experimentName.split('CB')[1][0]\n                    cbN = 4\n                    if f'{cbType}' == '8':\n                        mtppN = 2\n                    elif f'{cbType}' == '7':\n                        mtppN = 1\n                        \n                    solnSpecName = f'{metalCentre}-MTPP {mtppN};{cbN} CB[{cbType}].csv'\n                else:\n                    solnSpecName = f'{metalCentre}-MTPP H2O Only.csv'\n\n                plt.title(solnSpecName.replace('H2', 'H$_2$').replace(';', ':')[:-4])\n\n                csvDir = r'C:\\Users\\car72\\Documents\\PhD\\Thesis\\Figs\\MTPP\\Chem\\Experiments\\PL\\csvs'\n                csvFile = os.path.join(csvDir, solnSpecName)\n                csvData = np.transpose(np.genfromtxt(csvFile, delimiter = ',', dtype = float))\n                solnPlX = csvData[0]\n                #print(csvData[1].max())\n                solnPlY = (csvData[1]/153)*yMax*0.66\n                ax1.plot(solnPlX, solnPlY, lw = 2, color = 'k', zorder = -5, label = 'Solution PL Spectrum')\n\n            ax2.tick_params(labelsize = 18)\n            ax1.legend(loc = 0)\n            fig.tight_layout()\n\n            if not npomType.endswith('.png'):\n                npomType += '.png'\n\n            fig.savefig('Histograms/PL %s' % (npomType), bbox_inches = 'tight')\n\n            if closeFigures == True:\n                plt.close('all')\n\n            else:\n                plt.show()\n\n            plotEnd = time.time()\n            plotTime = plotEnd - plotStart\n            print('\\tHistogram plotted in %.02f seconds\\n' % plotTime)\n\n    return frequencies, bins, yDataBinned, yDataRawBinned, binnedSpecNames, x, resonance, stderr, fwhm, sigma, fit",
  "def plotPlHistAndFit(outputFileName, npomType = 'All NPoMs', startWl = 504, endWl = 900, plRange = [540, 820], binNumber = 80, plot = True,\n                     minBinFactor = 10, closeFigures = False, peak = 'all', peaks = None):\n\n    #try:\n    plHistyBits = plotPlHistogram(outputFileName, npomType = npomType, startWl = startWl, endWl = endWl, binNumber = binNumber, \n                                  minBinFactor = minBinFactor, peak = peak, plRange = plRange,\n                                  closeFigures = closeFigures, plot = plot, peaks = peaks)\n\n    frequencies = plHistyBits[0] \n    bins = plHistyBits[1]\n    yDataBinned = plHistyBits[2]\n    binnedSpectraList = plHistyBits[4]\n    histyWl = plHistyBits[5]\n    avgResonance = plHistyBits[6]\n    stderr = plHistyBits[7]\n    fwhm = plHistyBits[8]\n    sigma = plHistyBits[9]\n    fit = plHistyBits[10]\n    #except:\n    #    print '\\tHistogram plot failed for %s' % npomType\n    #    return\n\n    print('\\tUpdating histogram metadata in h5 file...')\n\n    with h5py.File(outputFileName, 'a') as opf:\n\n        if 'PL Histogram data' in opf['NPoMs/%s' % npomType]:\n            del opf['NPoMs/%s/PL Histogram data' % npomType]\n\n        gHist = opf.create_group('NPoMs/%s/PL Histogram data' % npomType)\n        gSpectraBinned = gHist.create_group('Binned y data')\n\n        gHist.attrs['Average resonance'] = avgResonance\n        gHist.attrs['Error'] = stderr\n\n        gHist.attrs['FWHM'] = fwhm\n        gHist.attrs['Standard deviation'] = sigma\n        gHist.attrs['Gaussian Fit'] = fit\n        gHist.attrs['wavelengths'] = histyWl\n\n        gHist['Bins'] = bins\n        gHist['Frequencies'] = frequencies\n\n        gHist['Frequencies'].attrs['wavelengths'] = gHist['Bins']\n        binSize = bins[1] - bins[0]\n        binsSorted = sorted(bins[:-1], key = lambda binStart: float(binStart))\n\n        for binStart in binsSorted:\n            binnedSpectraList[binStart] = sorted(binnedSpectraList[binStart], key = lambda spectrum: int(spectrum.split(' ')[-1]))\n\n        wLenned = False\n\n        print('\\t\\tUpdating binned spectral data...')\n        print('\\t\\t\\t(Might take a few minutes)\\n')\n\n        for n, binStart in enumerate(binsSorted):\n            if len(binnedSpectraList[binStart]) > 0:\n\n                binEnd = binStart + binSize\n                binName = f'Bin {n:02}'\n                #print(binName)\n                gBin = gSpectraBinned.create_group(binName)\n\n                gBin.attrs['Bin start (nm)'] = binStart\n                gBin.attrs['Bin end (nm)'] = binEnd\n                gBin['Sum'] = yDataBinned[n]\n\n                if wLenned == False:\n                    wlenN = n\n                    gBin['Sum'].attrs['wavelengths'] = histyWl\n                    wLenned = True\n\n                else:                    \n                    gBin['Sum'].attrs['wavelengths'] = gSpectraBinned[f'Bin {wlenN:02}/Sum'].attrs['wavelengths']\n\n                for spectrumName in binnedSpectraList[binStart]:\n                    gBin[spectrumName] = opf['NPoMs/%s/PL Data/%s' % (npomType, spectrumName)]\n                    gBin[spectrumName].attrs.update(opf['NPoMs/%s/PL Data/%s' % (npomType, spectrumName)].attrs)",
  "def plotAllHists(outputFileName, closeFigures = True, irThreshold = 8, minBinFactor = 5, plotAll = True, pl = False,\n                 npomTypes = 'all', upperCutoff = 900, lowerCutoff = 580):\n    histPlotStart = time.time()\n\n    if npomTypes == 'all':\n        npomTypes = ['All NPoMs', 'Non-Weird-Peakers', 'Weird Peakers', 'Ideal NPoMs', 'Doubles', 'Singles']\n\n    for npomType in npomTypes:\n        plotHistAndFit(outputFileName, npomType = npomType, irThreshold = irThreshold, minBinFactor = minBinFactor,\n                       closeFigures = closeFigures, endWl = upperCutoff, startWl = lowerCutoff)\n\n        if pl == True:\n             plotPlHistAndFit(outputFileName, npomType = npomType, minBinFactor = minBinFactor*10, closeFigures = closeFigures, peak = 'all')\n             plotDfPlHistogram(outputFileName, npomType = npomType, minBinFactor = minBinFactor, closeFigures = closeFigures, irThreshold = irThreshold, \n                            plot = plotAll)\n\n    histPlotEnd = time.time()\n    histTimeElapsed = histPlotEnd - histPlotStart\n    print('\\tAll histograa plotted in %.02f seconds\\n' % histTimeElapsed)",
  "def plotHistComb2D(outputFileName, npomType = 'All NPoMs', dfStartWl = 450, dfEndWl = 987, plStartWl = 504,\n                   plEndWl = 900, binNumber = 80, plot = True, minBinFactor = 5, closeFigures = False,\n                   irThreshold = 8, cmLowLim = 580):\n\n    with h5py.File(outputFileName, 'a') as opf:\n\n        dfKeys = ['Coupled Mode', 'Coupled Mode Intensity', 'Weird peak wavelength', 'Weird peak intensity']\n        plKeys = ['PL Peaks', 'PL Signal']\n\n        scatterKeys = np.concatenate([['%s vs %s' % (dfKey, plKey) for dfKey in dfKeys] for plKey in plKeys]).ravel()\n\n        print(scatterKeys)\n        scatterDict = {key : [] for key in scatterKeys}\n\n        gDf = opf['NPoMs/%s/Raw' % npomType]\n        gPl = opf['NPoMs/%s/PL Data' % npomType]\n        spectraNames = sorted(list(gDf.keys()), key = lambda i: int(i.split(' ')[-1]))\n\n        for spectrumName in spectraNames:\n            dfSpectrum = gDf[spectrumName]\n            n = int(spectrumName.split(' ')[-1])\n            plSpecName = 'PL Spectrum %s' % n\n            plSpectrum = gPl[plSpecName]\n\n            cmWl = dfSpectrum.attrs['Coupled mode wavelength']\n            cmH = dfSpectrum.attrs['Coupled mode intensity (raw)']\n\n            wrdWl = dfSpectrum.attrs['Weird peak wavelength']\n            wrdH = dfSpectrum.attrs['Weird peak intensity (raw)']\n\n            plWls = plSpectrum.attrs['Peak Centers']\n            plArea = plSpectrum.attrs['Total Area']\n\n            scatterDict['Coupled Mode vs PL Signal'].append(np.array([cmWl, plArea]))\n            scatterDict['Coupled Mode Intensity vs PL Signal'].append(np.array([cmH, plArea]))\n\n            if wrdWl != 'N/A':\n                scatterDict['Weird peak intensity vs PL Signal'].append(np.array([wrdH, plArea]))\n                scatterDict['Weird peak wavelength vs PL Signal'].append(np.array([wrdWl, plArea]))\n\n            for wl in plWls:\n                scatterDict['Coupled Mode vs PL Peaks'].append(np.array([cmWl, wl]))\n                scatterDict['Coupled Mode Intensity vs PL Peaks'].append(np.array([cmH, wl]))\n\n                if wrdWl != 'N/A':\n                    scatterDict['Weird peak intensity vs PL Peaks'].append(np.array([wrdH, wl]))\n                    scatterDict['Weird peak wavelength vs PL Peaks'].append(np.array([wrdWl, wl]))\n\n\n        for key in list(scatterDict.keys()):\n            scatterDict[key] = np.transpose(np.array(scatterDict[key]))\n            x = scatterDict[key][0]\n            y = scatterDict[key][1]\n\n            plt.plot(x, y, '.')\n            plt.xlabel(key.split(' vs ')[0])\n            plt.ylabel(key.split(' vs ')[-1])\n            plt.title(key)\n            plt.show()",
  "def getCorrectionCurve():\n    rootDir = os.getcwd()\n    curveDir = r'R:\\3-Temporary\\car72\\Igor Bits'\n    found = False\n\n    while not found:\n        try:\n            os.chdir(curveDir)\n            found = True\n        except:\n            curveDir = input(f'Failed to find {curveDir}. Please connect to NP server and press enter. Otherwise, enter alternative directory or \"x\" to cancel: ')\n            if curveDir in ['c', 'x', 'exit', 'cancel', 'esc']:\n                return None\n\n    curveFile = 'correction_curve.txt'\n    found = False\n    print(f'Searching for {curveFile}...')\n\n    while not found:\n        try:\n            curveData = np.genfromtxt(curveFile, delimiter = '\\t')\n            found = True\n        except:\n            curveFile = input(f'Failed to find {curveFile}. Please enter correct filename or type \"x\" to cancel: ')\n            if curveFile in ['c', 'x', 'exit', 'cancel', 'esc']:\n                return None\n\n    return np.transpose(curveData)",
  "def reCheckCentering():\n    summaryFile = findH5File(os.getcwd(), nameFormat = 'summary', mostRecent = True)\n    with h5py.File(summaryFile, 'r') as ipf:\n        return [specName for specName in ipf['Individual NPoM Spectra/scan0'].keys() if ipf['Individual NPoM Spectra/scan0'][specName].attrs['Properly centred?'] == True]",
  "def plot_ir_grid(ax):\n    ri_lines = {'1.0' : np.array([[720., 690., 643., 622.], [4.81481, 3.7037, 2.31481, 1.38889]]),\n                        '1.2' : np.array([[754., 720., 671., 645.], [5.64815, 4.44444, 2.87037, 1.85185]]),\n                        '1.4' : np.array([[788., 751., 701., 669.], [6.11111, 5., 3.33333, 2.22222]]),\n                        '1.6' : np.array([[824., 788., 730., 694.], [6.48148, 5.64815, 3.61111, 2.68519]]),\n                        '1.8' : np.array([[867., 820., 757., 717.], [6.75926, 6.01852, 3.88889, 2.96296]])\n            }\n\n    d_lines =  {'0.5': np.array([[720., 754., 788., 824., 867.], [4.81481, 5.64815, 6.11111, 6.48148, 6.75926]]),\n                            '1'  : np.array([[690., 720., 751., 788., 820.], [3.7037, 4.44444, 5., 5.64815, 6.01852]]),\n                            '2'  : np.array([[643., 671., 701., 730., 757.], [2.31481, 2.87037, 3.33333, 3.61111, 3.88889]]),\n                            '3'  : np.array([[622., 645., 669., 694., 717.], [1.38889, 1.85185, 2.22222, 2.68519, 2.96296]])\n                }\n\n\n    for label, xy in ri_lines.items():\n        ax.plot(*xy, 'k-', lw = 0.5)\n\n    for label, xy in d_lines.items():\n        ax.plot(*xy, 'r--', lw = 1)\n\n    y_lim = np.array(ax.get_ylim())\n    x_lim = np.array(ax.get_xlim())\n\n    y_range = y_lim.max() - y_lim.min()\n    x_range = x_lim.max() - x_lim.min()\n\n    label_buff = 0.02\n    y_buff = y_range*label_buff\n    x_buff = x_range*label_buff\n\n    for label, (x_ri, y_ri) in ri_lines.items():\n        ax.plot(x_ri, y_ri, 'k-', lw = 1, alpha = 0.7, zorder = -5)\n        ax.text(x_ri.min() + x_buff, y_ri.min() - y_buff, label, ha = 'center', va = 'top', \n                transform = ax.transData)\n\n        if label == '1.8':\n            ax.text(x_ri.min() + 4*x_buff, y_ri.min() - y_buff, '$n_{\\mathrm{g}}$', ha = 'left', va = 'top', \n                    transform = ax.transData)\n\n    for label, (x_d, y_d) in d_lines.items():\n        ax.plot(x_d, y_d, 'r--', lw = 1, alpha = 0.7, zorder = -5)\n        ax.text(x_d.min() - x_buff, y_d.min(), f'{label}', ha = 'right', va = 'center', \n                 transform = ax.transData)\n\n        if label == '0.5':\n            ax.text(x_d.min() - x_buff, y_d.min() + 4*y_buff, '$d$ (nm)', ha = 'right', va = 'center', \n                     transform = ax.transData)",
  "def plotIntensityRatios(outputFileName, plotName = 'All NPoMs', dataType = 'Raw', cMap = 'afmhot_r', closeFigures = False, \n                        plot = True, corrPars = [1.0763150264374398e-16, -4.955034954727432e-13, 9.679921256656744e-10, -1.0400936324948906e-06, 0.0006638040249482491, -0.2516124765012756, 52.43996030260027, -4633.856249916117],\n                        returnCentroid = True, filename = None, y_lim = [1, 7], x_lim = [550, 900], dir_title = False, spec_range = None):\n\n    if 'Intensity ratios' not in os.listdir('.'):\n        os.mkdir('Intensity ratios')\n\n    if plot == True:\n        print('Plotting intensity ratios for %s, %s...' % (plotName, dataType))\n\n    else:\n        print('Gathering intensity ratiosfor %s, %s...' % (plotName, dataType))\n\n    with h5py.File(outputFileName, 'a') as opf:\n        misaligned_npoms = opf['Misaligned NPoMs'].keys()\n        if len(misaligned_npoms) == 0:\n            alignedSpecNames = reCheckCentering()\n\n        #print(misaligned_npoms)\n        date = opf['All Spectra (Raw)'].attrs['Date measured']\n        gSpectra = opf['NPoMs/%s/%s' % (plotName, dataType)]\n        #misaligned_npoms = opf['Misaligned NPoMs']\n        spectraNames = [i for i in gSpectra.keys() if i not in misaligned_npoms]# and gSpectra[i].attrs['Aligned?'] == True]\n\n        if spec_range is not None:\n            spec_range = np.array(spec_range)\n            if len(spec_range.shape) == 1:\n                spec_range = np.array([spec_range])\n\n            allowed_spectra = []\n\n            for sub_range in spec_range:\n                if sub_range[1] == 0:\n                    sub_range[1] = len(gSpectra.keys()) - 1\n                if sub_range[0] == -1:\n                    print('No intensity ratios to plot')\n                    return None, None, None, None\n\n                allowed_spectra += [f'Spectrum {spec_n}' for spec_n in np.arange(*sub_range)]\n\n            spectraNames = sorted([i for i in spectraNames if i in allowed_spectra], key = lambda i: int(i.split(' ')[-1]))\n            #print(spectraNames)\n\n        dataType = dataType.lower()\n\n        x = np.array([gSpectra[spectrumName].attrs['Coupled mode wavelength'] for spectrumName in spectraNames])\n        y = np.array([gSpectra[spectrumName].attrs[f'Intensity ratio ({dataType})'] for spectrumName in spectraNames])\n\n        if corrPars is not None:\n            xCorr = np.linspace(450, 900, 1000)\n            yCorr = np.poly1d(corrPars)(xCorr)\n            for n, xi in enumerate(x):\n                y[n] *= (yCorr[abs(xi - xCorr).argmin()])\n\n\n        if plot == True:\n            frequencies, bins = np.histogram(y, bins = 80, range = (0, 10), density = False)\n            #print(frequencies, bins)\n            binSize = bins[1] - bins[0]\n\n            print('  Fitting Hist')\n            gMod1 = GaussianModel(prefix = 'g1_')\n            pars1 = gMod1.make_params(amplitude = frequencies.max()/2, center = bins[:-1][frequencies.argmax()]*0.66, sigma = 1)\n\n            gMod2 = GaussianModel(prefix = 'g2_')\n            pars2 = gMod2.make_params(amplitude = frequencies.max()/2, center = bins[:-1][frequencies.argmax()]*1.33, sigma = 1)\n\n            gMod = gMod1 + gMod2\n            pars = pars1\n            pars.update(pars2)\n\n            xCont = np.linspace(bins.min(), bins.max(), 500)\n\n            gOut = gMod.fit(frequencies, pars, x = bins[:-1])\n            gFit = gOut.best_fit\n            gFitCont = gOut.eval(x = xCont)\n            IR_centres = np.array([[gOut.params[f'g{g_n}_{param}'].value \n                                    for param in ['center', 'height']]\n                                   for g_n in [1, 2]])\n\n            opf[f'NPoMs/{plotName}'].attrs['IR Freq Peaks'] = IR_centres\n            opf[f'NPoMs/{plotName}'].attrs['IR Dist Max'] = xCont[gFitCont.argmax()]\n\n            fig = plt.figure()\n\n            plt.bar(bins[:-1], frequencies, width = 0.8*binSize, alpha = 0.8, linewidth = 0.6)\n            plt.plot(bins[:-1], gFit, 'k--')\n            if dir_title == True:\n                title = os.path.split(os.getcwd())[-1]\n                plt.title(title)\n            plt.xticks(np.linspace(0, 10, 6))\n            plt.xlabel('$I_{\\mathrm{C}}/I_{\\mathrm{T}}$')\n            plt.ylabel('Frequency')\n\n            filename = f'{plotName}, {dataType}' if filename is None else f'{filename}'\n            \n            if not filename.endswith('.png'):\n                filename = f'{filename}.png'\n\n            fig.savefig(f'Intensity ratios/1D IR Histogram {filename}')\n            plt.show()\n\n            rc_params = dict(plt.rcParams)\n            import seaborn as sns\n            #sns.set_style('white')\n            plt.rcParams.update(rc_params)\n\n            n_bins = 80 \n            \n            x_lim = np.array(x_lim)\n            x_range = x_lim.max() - x_lim.min()\n            hist_xlim = x_lim + np.array([0., x_range/n_bins])\n            xedges = np.linspace(*hist_xlim, n_bins)\n\n            y_lim = np.array(y_lim)\n            y_range = y_lim.max() - y_lim.min()\n            hist_ylim = y_lim + np.array([1., y_range/n_bins])\n            yedges = np.linspace(*hist_ylim, n_bins)\n                                    \n            H, xedges, yedges = np.histogram2d(x, y, bins = (xedges, yedges), density = True)\n            H = H.T\n            H /= H.max()\n            X, Y = np.meshgrid(xedges, yedges)\n            Xc, Yc = np.meshgrid(xedges[:-1], yedges[:-1])\n\n            fig, ax = plt.subplots(figsize = (9, 9))\n            cmap = plt.get_cmap(cMap)\n\n            gridsize = 200\n            if len(x) > 3000:\n                gridsize = 100\n\n            ax_s = sns.kdeplot(x, y=y, ax=ax, cmap = cmap, n_levels = 40, gridsize=200)\n\n            axColls = ax.collections\n            #print(axColls)\n\n            for n, line in enumerate(axColls):\n                total = len(axColls)\n\n                if n == int(np.round(total/2)):\n                    line.set_linestyle('-')\n                    line.set_edgecolor(cmap(256))\n                    line.set_facecolor(cmap(50))\n                    line.set_alpha(0.5)\n                    line.set_zorder(2)\n\n                elif n == int(np.round(total * 0.95)):\n                    line.set_edgecolor(cmap(256))\n                    line.set_facecolor(cmap(256))\n                    line.set_alpha(0.9)\n                    line.set_zorder(100)\n                    lineDict = line.properties()\n                    #print(lineDict)\n                    path = lineDict['paths'][0].vertices.T\n                    centroid = np.average(path, axis = 1)\n                    ax.plot(*centroid, 'ro', ms = 25, zorder = 101)\n                    for centre in IR_centres:\n                        ax.plot(centroid[0], centre[0], 'bo', ms = 15, zorder = 102)\n\n                else:\n                    line.set_linestyle(':')\n                    line.set_alpha(0.3)\n\n\n            ax.pcolormesh(X, Y, H, cmap = cmap, vmin = 0.1, vmax = 1, zorder = 1)\n\n            ax.set_xlim(*x_lim)\n            ax.set_ylim(*y_lim)\n\n            plot_ir_grid(ax)\n\n            ax.set_ylabel('Intensity Ratio')\n            ax.tick_params(which = 'both')\n            ax.set_xlabel('Coupled Mode Resonance')\n            #ax.set_xticksize(fontsize = 15)\n\n            if dir_title == True:\n                plt.title(title)\n\n            else:\n                if type(date) != str:\n                    date = date.decode()\n                plt.title('%s\\n%s,%s' % (date, plotName, dataType))\n\n            ax.patch.set_visible(False)\n\n            #fig.tight_layout()\n        \n            fig.savefig(f'Intensity ratios/{filename}', bbox_inches = 'tight', transparent = True)\n            if closeFigures == True:\n                plt.close('all')\n\n            else:\n                plt.show()\n\n            plt.show()\n\n\n            print('\\tIntensity ratios plotted\\n')\n\n        else:\n            print('\\tIntensity ratios gathered\\n')\n\n        opf[f'NPoMs/{plotName}'].attrs['CM Resonances'] = x\n        opf[f'NPoMs/{plotName}'].attrs['Intensity Ratios'] = y\n        opf[f'NPoMs/{plotName}'].attrs['Intensity Ratio Centroid'] = centroid\n        opf[f'NPoMs/{plotName}'].attrs['Intensity Ratio Contour'] = path\n\n\n    if returnCentroid == False:\n        return x, y\n    else:\n        return x, y, centroid, path",
  "def plotAllIntensityRatios(outputFileName, closeFigures = True, plot = True):\n\n    print('Plotting all intensity ratios...\\n')\n    irStart = time.time()\n\n    with h5py.File(outputFileName, 'a') as opf:\n        plotNames = list(opf['NPoMs'].keys())\n\n        for plotName in plotNames:\n            for dataType in ['Raw', 'Normalised']:\n                _, _, centroid, path = plotIntensityRatios(outputFileName, plotName = plotName, dataType = dataType, closeFigures = closeFigures, plot = plot)\n\n            opf['NPoMs'][plotName].attrs['Intensity Ratio Centroid'] = centroid\n            opf['NPoMs'][plotName].attrs['Intensity Ratio Contour'] = path\n\n    irEnd = time.time()\n    timeElapsed = irEnd - irStart\n\n    print('\\tAll intensity ratios plotted in %s seconds\\n' % timeElapsed)",
  "def visualiseIntensityRatios(outputFileName):\n\n    '''outputFileName = h5py filename in current directory'''\n    '''Plots all spectra with lines indicating calculated peak heights and positions'''\n\n    irVisStart = time.time()\n\n    print('Visualising intensity ratios for individual spectra...')\n\n    with h5py.File(outputFileName, 'a') as opf:\n        gNPoMs = opf['NPoMs/All NPoMs/Raw']\n\n        if 'Intensity ratio measurements' in list(opf['NPoMs/All NPoMs'].keys()):\n            overWrite = True\n            gIrVis = opf['NPoMs/All NPoMs/Intensity ratio measurements']\n\n        else:\n            overWrite = False\n            gIrVis = opf['NPoMs/All NPoMs'].create_group('Intensity ratio measurements')\n\n        spectraNames = sorted(list(gNPoMs.keys()), key = lambda spectrumName: int(spectrumName[9:]))\n\n        for n, spectrumName in enumerate(spectraNames):\n            spectrum = gNPoMs[spectrumName]\n            intensityRatio = spectrum.attrs['Intensity ratio (raw)']\n\n            if intensityRatio != 'N/A':\n                zeroLine = np.array([0, 0])\n                transHeight = spectrum.attrs['Transverse mode intensity (raw)']\n                transWl = spectrum.attrs['Transverse mode wavelength']\n                cmHeight = spectrum.attrs['Coupled mode intensity (raw)']\n                cmWl = spectrum.attrs['Coupled mode wavelength']\n                xTransVert = np.array([transWl] * 10)\n                yTransVert = np.linspace(0, transHeight, 10)\n                xCmVert = np.array([cmWl] * 10)\n                yCmVert = np.linspace(0, cmHeight, 10)\n                transHoriz = np.array([transHeight] * 10)\n                cmHoriz = np.array([cmHeight] * 10)\n\n                if overWrite:\n                    gSpecIrVis = gIrVis[spectrumName]\n\n                else:\n                    gSpecIrVis = gIrVis.create_group(spectrumName)\n\n                gSpecIrVis['Raw'] = gNPoMs[spectrumName]\n                gSpecIrVis['Raw'].attrs['wavelengths'] = gNPoMs[spectrumName].attrs['wavelengths']\n                wavelengths = gNPoMs[spectrumName].attrs['wavelengths']\n\n                if n == 0:\n\n                    gSpecIrVis['Zero'] = zeroLine\n                    gSpecIrVis['Zero'].attrs['wavelengths'] = np.array([wavelengths[0], wavelengths[1]])\n\n                else:\n                    gSpecIrVis['Zero'] = gIrVis[spectraNames[0]]['Zero']\n                    gSpecIrVis['Zero'].attrs.update(gIrVis[spectraNames[0]]['Zero'].attrs)\n\n                gSpecIrVis['Transverse mode position'] = yTransVert\n                gSpecIrVis['Transverse mode position'].attrs['wavelengths'] = xTransVert\n\n                gSpecIrVis['Coupled mode position'] = yCmVert\n                gSpecIrVis['Coupled mode position'].attrs['wavelengths'] = xCmVert\n\n                gSpecIrVis['Transverse mode height'] = transHoriz\n                gSpecIrVis['Transverse mode height'].attrs['wavelengths'] = np.array([wavelengths[0], wavelengths[1]])\n\n                gSpecIrVis['Coupled mode height'] = cmHoriz\n                gSpecIrVis['Coupled mode height'].attrs['wavelengths'] = np.array([wavelengths[0], wavelengths[1]])\n\n    irVisEnd = time.time()\n    timeElapsed = irVisEnd - irVisStart\n    print('\\tIntensity ratios visualised in %s seconds\\n' % timeElapsed)",
  "def calcGroupAttrAvgs(group):\n    '''group must be instance of (open) hdf5 group object'''\n\n    spectraNames = sorted([spectrumName for spectrumName in list(group.keys()) if spectrumName != 'Sum'],\n                                           key = lambda spectrumName: int(spectrumName[9:]))\n    attrAvgs = {}\n\n    for spectrumName in spectraNames:\n        spectrum = group[spectrumName]\n\n        for attrName in list(spectrum.attrs.keys()):\n            attrVal = spectrum.attrs[attrName]\n\n            if type(attrVal) in [int, float]:\n\n                if attrName in list(attrAvgs.keys()):\n                    attrAvgs[attrName].append(attrVal)\n\n                else:\n                    attrAvgs[attrName] = [attrVal]\n\n    for attrName in list(attrAvgs.keys()):\n        attrAvgs[attrName] = np.average(np.array(attrAvgs[attrName]))\n\n    group.attrs.update(attrAvgs)",
  "def calcAllPeakAverages(outputFileName, groupAvgs = True, histAvgs = True, singleBin = False, peakPos = 0, npTypes = 'all'):\n    '''If singleBin = False, function averages peak data from all NPoM spectra'''\n    '''If True, specify wavelength and function will average peak data from all spectra contained in that histogram bin'''\n\n    peakAvgStart = time.time()\n\n    print('Collecting peak averages...')\n\n    with h5py.File(outputFileName, 'a') as opf:\n\n        gNPoMs = opf['NPoMs']\n        if npTypes == 'all':\n            npTypes = ['All NPoMs', 'Non-Weird-Peakers', 'Weird Peakers', 'Ideal NPoMs', 'Doubles', 'Singles']\n        for npType in npTypes:\n\n            try:\n\n                if histAvgs == True:\n\n                    histBins = gNPoMs['%s/Histogram data/Binned y data' % npType]\n                    binNames = sorted(list(histBins.keys()), key = lambda binName: int(binName[4:]))\n\n                    if singleBin == False:\n\n                        for binName in binNames:\n                            gBin = histBins[binName]\n                            calcGroupAttrAvgs(gBin)\n\n                    elif singleBin == True:\n\n                        binNames = [binName for binName in binNames if\n                                    histBins[binName].attrs['Bin start (nm)'] < peakPos < histBins[binName].attrs['Bin end (nm)']]\n\n                        for binName in binNames:\n                            gBin = histBins[binName]\n                            calcGroupAttrAvgs(gBin)\n\n                if groupAvgs == True:\n                    gSpectra = gNPoMs['%s/Normalised' % npType]\n                    calcGroupAttrAvgs(gSpectra)\n\n            except Exception as e:\n                print('Peak data collection failed for %s because %s' % (npType, e))\n\n\n    peakAvgEnd = time.time()\n    timeElapsed = peakAvgEnd - peakAvgStart\n\n    print('\\tPeak averages collected in %s seconds\\n' % timeElapsed)",
  "def analyseRepresentative(outputFileName, peakFindMidpoint = 680, npTypes = 'all'):\n    print('Collecting representative spectrum info...')\n\n    with h5py.File(outputFileName, 'a') as opf:\n\n        gNPoMs = opf['NPoMs']\n        if npTypes == 'all':\n            npTypes = ['All NPoMs', 'Non-Weird-Peakers', 'Weird Peakers', 'Ideal NPoMs', 'Doubles', 'Singles']\n\n        for npType in npTypes:\n\n            try:\n                gHist = gNPoMs['%s/Histogram data' % npType]\n\n            except:\n                print('Data not found for %s' % npType)\n                continue\n\n            cmPeakPos = gHist.attrs['Average resonance']\n            histBins = gHist['Binned y data']\n            binNames = list(histBins.keys())\n            biggestBinName = binNames[np.array([len(histBins[binName]) for binName in binNames]).argmax()]\n            avgBinNames = [binName for binName in binNames if\n                           histBins[binName].attrs['Bin start (nm)'] < cmPeakPos < histBins[binName].attrs['Bin end (nm)']]\n\n            print('\\t%s' % npType)\n            print('\\t\\tBin with largest population:', biggestBinName)\n\n            for binName in binNames:\n\n                try:\n                    gBin = histBins[binName]\n                    dAvg = gBin['Sum']\n                    x = dAvg.attrs['wavelengths']\n                    y = dAvg[()]\n                    avgMetadata = analyseNpomSpectrum(x, y, avg = True, peakFindMidpoint = peakFindMidpoint)\n                    gBin.attrs.update(avgMetadata)\n                    dAvg.attrs.update(avgMetadata)\n\n                except Exception as e:\n\n                    if str(e) == 'arrays used as indices must be of integer (or boolean) type':\n                          print('\\t\\t%s empty; analysis failed' % binName)\n\n                    else:\n                        print('\\t\\t%s analysis failed because %s' % (binName, e))\n\n            if 'Modal representative spectrum' in list(gHist.keys()):\n                del gHist['Modal representative spectrum']\n\n            gHist['Modal representative spectrum'] = histBins[biggestBinName]['Sum']\n            gHist['Modal representative spectrum'].attrs.update(histBins[biggestBinName]['Sum'].attrs)\n            gHist['Modal representative spectrum'].attrs['Bin'] = biggestBinName\n\n            for n, binName in enumerate(avgBinNames):\n\n                if len(avgBinNames) <= 1:\n                    n = ''\n\n                else:\n                    n = ' %s' % n\n\n                if 'Average representative spectrum%s' % n in list(gHist.keys()):\n                    del gHist['Average representative spectrum%s' % n]\n\n                gHist['Average representative spectrum%s' % n] = histBins[binName]['Sum']\n                gHist['Average representative spectrum%s' % n].attrs.update(histBins[binName]['Sum'].attrs)\n                gHist['Average representative spectrum%s' % n].attrs['Bin'] = binName\n\n    print('\\n\\tRepresentative spectrum info collected\\n')",
  "def doStats(outputFileName, closeFigures = True, stacks = True, hist = True, allHists = True, irThreshold = 8,\n            minBinFactor = 5, intensityRatios = False, npomTypes = 'all', peakAvgs = True, analRep = True,\n            peakFindMidpoint = 680, pl = False, groupAvgs = True, histAvgs = True, raiseExceptions = True,\n            upperCutoff = 850, lowerCutoff = 580, sortStacks = False, sortStacksMethod = None):\n\n    if stacks == True:\n        if raiseExceptions == True:\n            plotAllStacks(outputFileName, closeFigures = closeFigures, sort = sortStacks, sortingMethod = sortStacksMethod)\n        else:\n            try:\n                plotAllStacks(outputFileName, closeFigures = closeFigures)\n            except Exception as e:\n                print('Stacks plotting failed becuse %s' % e)\n\n    if hist == True:\n        plotAll = allHists\n        if raiseExceptions == True:\n            plotAllHists(outputFileName, closeFigures = closeFigures, irThreshold = irThreshold, minBinFactor = minBinFactor,\n                         plotAll = plotAll, pl = pl, npomTypes = npomTypes, upperCutoff = upperCutoff, lowerCutoff = lowerCutoff)\n        else:\n            try:\n                plotAllHists(outputFileName, closeFigures = closeFigures, irThreshold = irThreshold, minBinFactor = minBinFactor,\n                         plotAll = plotAll, pl = pl, npomTypes = npomTypes, upperCutoff = upperCutoff, lowerCutoff = lowerCutoff)\n            except Exception as e:\n                print('Histogram plot failed becuse %s' % e)\n\n    if intensityRatios == True:\n        if raiseExceptions == True:\n            plotAllIntensityRatios(outputFileName, closeFigures = closeFigures, plot = True)\n            visualiseIntensityRatios(outputFileName)\n        else:\n            try:\n                plotAllIntensityRatios(outputFileName, closeFigures = closeFigures, plot = True)\n            except Exception as e:\n                print('Intensity ratio plots failed becuse %s' % e)\n            try:\n                visualiseIntensityRatios(outputFileName)\n            except Exception as e:\n                print('Intensity ratio visualisation failed becuse %s' % e)\n\n    if peakAvgs == True:\n        if raiseExceptions == True:\n            calcAllPeakAverages(outputFileName, groupAvgs = groupAvgs, histAvgs = histAvgs, singleBin = False, npTypes = npomTypes)\n        else:\n            try:\n                calcAllPeakAverages(outputFileName, groupAvgs = groupAvgs, histAvgs = histAvgs, singleBin = False, npTypes = npomTypes)\n            except Exception as e:\n                print('Peak average collection failed becuse %s' % e)\n                \n    if analRep == True:\n        if raiseExceptions == True:\n            analyseRepresentative(outputFileName, peakFindMidpoint = peakFindMidpoint, npTypes = npomTypes)\n        else:\n            try:\n                analyseRepresentative(outputFileName, peakFindMidpoint = peakFindMidpoint, npTypes = npomTypes)\n            except Exception as e:\n                print('Representative spectrum analysis failed because %s' % e)",
  "def sortSpectra(rootDir, outputFileName, stats = True, closeFigures = True, npSize = 80, npomTypes = ['Perfect NPoMs'], sortStacks = False, \n                sortStacksMethod = None):\n    \n    summaryAttrs = retrieveData(rootDir, attrsOnly = True)\n    \n    absoluteStartTime = time.time()\n    \n    peakFindMidpointDict = {80: 680, 70 : 630, 60 : 580, 50 : 550, 40 : 540}\n    peakFindMidpoint = peakFindMidpointDict[npSize]\n                            \n    with h5py.File(outputFileName, 'a') as opf:\n        try:\n            gAllRaw = opf['All Spectra (Raw)']\n        except Exception as e:\n            print(opf.keys())\n            raise(e)\n\n        gNPoMs = opf['NPoMs']        \n        gAllNPoMs = gNPoMs['All NPoMs']\n        gAllNPoMsNorm = gAllNPoMs['Normalised']\n            \n        \n        if 'Aligned NPoMs' not in gNPoMs.keys():\n            gAligned = gNPoMs.create_group('Aligned NPoMs')\n            gAlignedRaw = gAligned.create_group('Raw')\n            gAlignedNorm = gAligned.create_group('Normalised')\n        \n        gAligned = gNPoMs['Aligned NPoMs']\n        gAlignedRaw = gAligned['Raw']\n        gAlignedNorm = gAligned['Normalised']\n\n        if 'Perfect NPoMs' in npomTypes:\n            gIdeal = gNPoMs['Ideal NPoMs']\n            gIdealRaw = gIdeal['Raw']\n            gIdealNorm = gIdeal['Normalised']   \n            if 'Perfect NPoMs' not in gNPoMs.keys():\n                gPerfect = gNPoMs.create_group('Perfect NPoMs')\n                gPerfectRaw = gPerfect.create_group('Raw')\n                gPerfectNorm = gPerfect.create_group('Normalised')\n            \n            gPerfect = gNPoMs['Perfect NPoMs']\n            gPerfectRaw = gPerfect['Raw']\n            gPerfectNorm = gPerfect['Normalised']\n\n        if 'Weird Peakers' in npomTypes:\n            if 'Weird Peakers' not in gNPoMs.keys():\n                gWeirds = gNPoMs.create_group('Weird Peakers')\n                gWeirds.create_group('Raw')\n                gWeirds.create_group('Normalised')\n\n            gWeirds = gNPoMs['Weird Peakers']\n            gWeirdsRaw = gWeirds['Raw']\n            gWeirdsNorm = gWeirds['Normalised']\n\n        if 'Non-Weird-Peakers' in npomTypes:\n            if 'Non-Weird-Peakers' not in gNPoMs.keys():\n                gNormal = gNPoMs.create_group('Non-Weird-Peakers')\n                gNormal.create_group('Raw')\n                gNormal.create_group('Normalised')\n\n            gNormal = gNPoMs['Non-Weird-Peakers']\n            gNormalRaw = gNormal['Raw']\n            gNormalNorm = gNormal['Normalised']\n\n        totalFitStart = time.time()\n        \n        print('Sorting spectra...')\n        \n        for n, spectrumName in enumerate(sorted(gAllRaw.keys(), key = lambda spectrumName: int(spectrumName.split(' ')[-1]))):\n            try:\n\n                if 'Aligned NPoMs' in npomTypes:                            \n                    if 'Misaligned particle numbers' in summaryAttrs.keys():\n                        if n not in summaryAttrs['Misaligned particle numbers']:\n\n                            if 'Aligned NPoMs' in gNPoMs.keys():\n                                if spectrumName not in gAlignedRaw.keys():\n                                    gAlignedRaw[spectrumName] = gAllRaw[spectrumName]\n                                \n                                gAlignedRaw[spectrumName].attrs.update(gAllRaw[spectrumName].attrs)\n                                \n                            if 'Spectrum %s' % n in gAllNPoMsNorm.keys():\n                                if spectrumName not in gAlignedNorm.keys():\n                                    gAlignedNorm[spectrumName] = gAllNPoMsNorm[spectrumName]\n                                gAlignedNorm[spectrumName].attrs.update(gAllNPoMsNorm[spectrumName].attrs)\n                    else:\n                        if 'Aligned NPoMs' in gNPoMs.keys() and 'Spectrum %s' % n in gAllNPoMsNorm.keys():\n                            if spectrumName not in gAlignedRaw.keys():\n                                gAlignedRaw[spectrumName] = gAllRaw[spectrumName]\n                            gAlignedRaw[spectrumName].attrs.update(gAllRaw[spectrumName].attrs)\n\n                            if spectrumName not in gAlignedNorm.keys():\n                                gAlignedNorm[spectrumName] = gAllNPoMsNorm[spectrumName]\n                            gAlignedNorm[spectrumName].attrs.update(gAllNPoMsNorm[spectrumName].attrs)\n                \n                    if spectrumName in gAlignedRaw.keys() and spectrumName in gIdealRaw.keys():\n                        if spectrumName not in gPerfectRaw.keys():\n                            gPerfectRaw[spectrumName] = gAllRaw[spectrumName]\n                        gPerfectRaw[spectrumName].attrs.update(gAllRaw[spectrumName].attrs)\n                    \n                    if spectrumName in gAlignedNorm.keys() and spectrumName in gIdealNorm.keys():\n                        if spectrumName not in gPerfectNorm.keys():\n                            gPerfectNorm[spectrumName] = gAllNPoMsNorm[spectrumName]\n                        gPerfectNorm[spectrumName].attrs.update(gAllNPoMsNorm[spectrumName].attrs)\n\n                specAttrs = gAllRaw[spectrumName].attrs\n\n                if 'Weird Peakers' in npomTypes:\n\n                    if spectrumName in gAllNPoMsNorm.keys():\n                        if specAttrs['Weird Peak?'] == True:\n                            try:\n                                gWeirdsRaw[spectrumName] = gAllRaw[spectrumName]\n                            except:\n                                pass\n                            gWeirdsRaw[spectrumName].attrs.update(gAllRaw[spectrumName].attrs)\n\n                            try:\n                                gWeirdsNorm[spectrumName] = gAllRaw[spectrumName]\n                            except:\n                                pass\n                            gWeirdsNorm[spectrumName].attrs.update(gAllRaw[spectrumName].attrs)\n\n                        else:\n                            if 'Non-Weird-Peakers' in npomTypes:\n                                try:\n                                    gNormalRaw[spectrumName] = gAllRaw[spectrumName]\n                                except:\n                                    pass\n                                gNormalRaw[spectrumName].attrs.update(gAllRaw[spectrumName].attrs)\n                                try:\n                                    gNormalNorm[spectrumName] = gAllNPoMsNorm[spectrumName]\n                                except:\n                                    pass\n                                gNormalNorm[spectrumName].attrs.update(gAllRaw[spectrumName].attrs)\n\n            except Exception as e:\n                print('%s failed because %s' % (spectrumName, e))\n                raise(e)\n\n    currentTime = time.time() - totalFitStart\n    mins = int(old_div(currentTime, 60))\n    secs = old_div((np.round((currentTime % 60)*100)),100)\n    print('100%% (%s spectra) analysed in %s min %s sec\\n' % (n, mins, secs))\n    \n    if stats == True:\n        doStats(outputFileName, closeFigures = True, stacks = False, peakFindMidpoint = peakFindMidpoint,\n                pl = False, npomTypes = npomTypes, groupAvgs = False, sortStacks = sortStacks, sortStacksMethod = sortStacksMethod)\n    \n    absoluteEndTime = time.time()\n    timeElapsed = absoluteEndTime - absoluteStartTime\n    mins = int(old_div(timeElapsed, 60))\n    secs = int(np.round(timeElapsed % 60))\n    \n    printEnd()\n    \n    with h5py.File(outputFileName, 'a') as opf:\n    \n        if mins > 30:\n            print('\\nM8 that took ages')\n        \n        gAllRaw = opf['All Spectra (Raw)']\n        nTotal = len(list(gAllRaw.keys()))\n                \n        if 'Failed Spectra' in opf.keys():\n            gFailed = opf['Failed Spectra']\n            nFailed = len(gFailed)\n            print(type(nFailed))\n            \n            if nFailed == 0:\n                print('\\nFinished in %s min %s sec. Smooth sailing.' % (mins, secs))\n        \n            if nFailed == 1:\n                print('\\nPhew... finished in %s min %s sec with only %s failure' % (mins, secs, len(gFailed)))\n        \n            elif nFailed > nTotal * 2:\n                print('\\nHmmm... finished in %s min %s sec but with %s failures and only %s successful fits' % (mins, secs, len(gFailed),\n                                                                                                                len(gAllRaw) - len(gFailed)))\n            else:\n                print('\\nPhew... finished in %s min %s sec with only %s failures' % (mins, secs, len(gFailed)))\n        \n        else:\n            print('\\nFinished in %s min %s sec. Smooth sailing.' % (mins, secs))\n        \n        print('')",
  "def fitAllSpectra(rootDir, outputFileName, npSize = 80, summaryAttrs = False, first = 0, last = 0, stats = True, pl = False, raiseExceptions = False,\n                  raiseSpecExceptions = False, closeFigures = True, customScan = None, npomTypes = 'all', stacks = 'all', sortOnly = False, intensityRatios = False,\n                  upperCutoff = 900, lowerCutoff = None, sortStacks = False, sortStacksMethod = None):\n    \n    if sortOnly == True:\n        sortSpectra(rootDir, outputFileName, stats = stats, npomTypes = npomTypes)\n        return\n\n    absoluteStartTime = time.time()\n\n    x, yData, summaryAttrs = retrieveData(rootDir, first = first, last = last, customScan = customScan)\n    plotInitStack(x, yData, imgName = 'Initial DF Stack', closeFigures = closeFigures)\n\n    if pl == True:\n        xPl, plData, plSpectRaw = retrievePlData(rootDir, first = first, last = last)\n        plotInitPlStack(xPl, plData, imgName = 'Initial PL Stack', closeFigures = closeFigures)\n        \n    peakFindMidpointDict = {80: 680, 70 : 630, 60 : 580, 50 : 550, 40 : 540}\n    peakFindMidpoint = peakFindMidpointDict[npSize]\n    cmLowLimDict = {80: 580, 70 : 560, 60 : 540, 50 : 520, 40 : 500}\n    cmLowLim = cmLowLimDict[npSize]\n\n    if lowerCutoff is not None:\n        cmLowLim = lowerCutoff\n\n    #if last == 0:\n    #    last = len(yData)\n\n    print('Beginning fit procedure...')\n    if pl == True:\n        print('\\tPL Fit performs a multi-gaussian fit, so this might take a while')\n        \n    with h5py.File(outputFileName, 'a') as opf:\n        gAllRaw = opf.create_group('All Spectra (Raw)')\n\n        if summaryAttrs:\n\n            try:\n                gAllRaw.attrs['Date measured'] = summaryAttrs['creation_timestamp'][:10]\n            except:\n                gAllRaw.attrs['Date measured'] = summaryAttrs['timestamp'][:10]\n\n        gFailed = opf.create_group('Failed Spectra')\n        gMisaligned = opf.create_group('Misaligned NPoMs')\n        gNonPoms = opf.create_group('Non-NPoMs')\n        gNPoMs = opf.create_group('NPoMs')\n\n        gAllNPoMs = gNPoMs.create_group('All NPoMs')\n        gAllNPoMsRaw = gAllNPoMs.create_group('Raw')\n        gAllNPoMsNorm = gAllNPoMs.create_group('Normalised')\n\n        gAligned = gNPoMs.create_group('Aligned NPoMs')\n        gAlignedRaw = gAligned.create_group('Raw')\n        gAlignedNorm = gAligned.create_group('Normalised')\n\n        gDoubles = gNPoMs.create_group('Doubles')\n        gDoublesRaw = gDoubles.create_group('Raw')\n        gDoublesNorm = gDoubles.create_group('Normalised')\n\n        gSingles = gNPoMs.create_group('Singles')\n        gSinglesRaw = gSingles.create_group('Raw')\n        gSinglesNorm = gSingles.create_group('Normalised')\n\n        gWeirds = gNPoMs.create_group('Weird Peakers')\n        gWeirdsRaw = gWeirds.create_group('Raw')\n        gWeirdsNorm = gWeirds.create_group('Normalised')\n\n        gNormal = gNPoMs.create_group('Non-Weird-Peakers')\n        gNormalRaw = gNormal.create_group('Raw')\n        gNormalNorm = gNormal.create_group('Normalised')\n\n        gIdeal = gNPoMs.create_group('Ideal NPoMs')\n        gIdealRaw = gIdeal.create_group('Raw')\n        gIdealNorm = gIdeal.create_group('Normalised')\n        \n        gPerfect = gNPoMs.create_group('Perfect NPoMs')\n        gPerfectRaw = gPerfect.create_group('Raw')\n        gPerfectNorm = gPerfect.create_group('Normalised')\n\n        if pl == True:\n            gFailedPl = opf.create_group('Failed PL Spectra')\n            gAllPl = opf.create_group('All PL Spectra')\n            gAllNPoMsPl = gAllNPoMs.create_group('PL Data')\n            gDoublesPl = gDoubles.create_group('PL Data')\n            gSinglesPl = gSingles.create_group('PL Data')\n            gWeirdsPl = gWeirds.create_group('PL Data')\n            gNormalPl = gNormal.create_group('PL Data')\n            gIdealPl = gIdeal.create_group('PL Data')\n            gPerfectPl = gPerfect.create_group('PL Data')\n            gNonPomsPl = gNonPoms.create_group('PL Data')\n            gAlignedPl = gAligned.create_group('PL Data')\n\n            gAllNPoMsPlNorm = gAllNPoMs.create_group('PL Data (Normalised)')\n            gDoublesPlNorm = gDoubles.create_group('PL Data (Normalised)')\n            gSinglesPlNorm = gSingles.create_group('PL Data (Normalised)')\n            gWeirdsPlNorm = gWeirds.create_group('PL Data (Normalised)')\n            gNormalPlNorm = gNormal.create_group('PL Data (Normalised)')\n            gIdealPlNorm = gIdeal.create_group('PL Data (Normalised)')\n            gPerfectPlNorm = gPerfect.create_group('PL Data (Normalised)')\n            gAlignedPlNorm = gAligned.create_group('PL Data (Normalised)')\n\n        if summaryAttrs:\n            if 'Misaligned particle numbers' in summaryAttrs.keys():\n                misalignedParticleNumbers = summaryAttrs['Misaligned particle numbers']\n            else:\n                print('Misaligned particles not recorded')\n                misalignedParticleNumbers = []\n                  \n        if len(yData) > 2500:\n            print('\\tAbout to fit %s spectra. This may take a while...' % len(yData))\n\n        nummers = np.arange(5, 101, 5)\n        totalFitStart = time.time()\n        print('\\n0% complete')\n\n        startWl = 450 if pl == False else 500\n       \n        for n, spectrum in enumerate(yData):\n            nn = n # Keeps track of our progress through our list of spectra\n            n = n + first # For correlation with particle groups in original dataset\n            #print(nn, n)\n\n            if 100 * nn//len(yData[:]) in nummers:\n                currentTime = time.time() - totalFitStart\n                mins = currentTime//60\n                secs = np.round((currentTime % 60)*100)//100\n                print('%s%% (%s spectra) analysed in %s min %s sec' % (nummers[0], nn, mins, secs))\n                nummers = nummers[1:]\n\n            spectrumName = 'Spectrum %s' % n\n            gAllRaw[spectrumName] = spectrum\n            gAllRaw[spectrumName].attrs['Aligned?'] = True if n in misalignedParticleNumbers else False\n            plMetadataKeys = ['Fit Error', 'Peak Heights', 'Peak FWHMs', 'Fit', 'Peak Centers', 'NPoM?']\n            plSpecAttrs = {key : 'N/A' for key in plMetadataKeys}\n\n            if nn == 0:\n                gAllRaw[spectrumName].attrs['wavelengths'] = x\n\n            else:\n                gAllRaw[spectrumName].attrs['wavelengths'] = gAllRaw['Spectrum %s' % first].attrs['wavelengths']\n\n            if pl == True:\n                plSpectrum = plData[nn]\n                plSpectrumRaw = plSpectRaw[nn]\n                #if dfAfter:\n                #    dfAfterPl = dfAfter[nn]\n                #plArea = areas[nn]\n                #plBgScale = bgScales[nn]\n\n                plSpecName = 'PL Spectrum %s' % n\n                gAllPl[plSpecName] = plSpectrum\n                #gAllPl[plSpecName].attrs['DF After'] = dfAfterPl\n                #gAllPl[plSpecName].attrs['Total Area'] = plArea\n                #gAllPl[plSpecName].attrs['Background Scale Factor'] = plBgScale\n\n                if nn == 0:\n                    gAllPl[plSpecName].attrs['wavelengths'] = xPl\n\n                else:\n                    gAllPl[plSpecName].attrs['wavelengths'] = gAllPl['PL Spectrum %s' % first].attrs['wavelengths']\n                    \n            if raiseExceptions == True:\n                    specAttrs = analyseNpomSpectrum(x, spectrum, peakFindMidpoint = peakFindMidpoint, raiseExceptions = raiseSpecExceptions,\n                                                    cmLowLim = cmLowLim, upperCutoff = upperCutoff, startWl = startWl)#Main spectral analysis function\n\n                    if pl == True:\n                        plSpecAttrs = analysePlSpectrum(xPl, plSpectrum, raiseExceptions = raiseSpecExceptions)#Main PL analysis function\n                        plSpecAttrs['Raw Spectrum'] = plSpectrumRaw\n            else:\n\n                try:\n                    specAttrs = analyseNpomSpectrum(x, spectrum, peakFindMidpoint = peakFindMidpoint, cmLowLim = cmLowLim,\n                                                    raiseExceptions = raiseSpecExceptions, upperCutoff = upperCutoff)#Main spectral analysis function\n                    plMetadataKeys = ['Fit Error', 'Peak Heights', 'Peak FWHMs', 'Fit', 'Peak Centers', 'NPoM?']\n                    plSpecAttrs = {key : 'N/A' for key in plMetadataKeys}\n\n                except Exception as e:\n\n                    print('DF %s failed because %s' % (spectrumName, e))\n                    gAllRaw[spectrumName].attrs['Failure reason'] = str(e)\n                    gAllRaw[spectrumName].attrs['wavelengths'] = gAllRaw['Spectrum %s' % first].attrs['wavelengths']\n                    gFailed[spectrumName] = gAllRaw[spectrumName]\n                    gFailed[spectrumName].attrs['Failure reason'] = gAllRaw[spectrumName].attrs['Failure reason']\n                    gFailed[spectrumName].attrs['wavelengths'] = gAllRaw[spectrumName].attrs['wavelengths']\n                    plMetadataKeys = ['Fit Error', 'Peak Heights', 'Peak FWHMs', 'Fit', 'Peak Centers', 'NPoM?']\n                    plSpecAttrs = {key : 'N/A' for key in plMetadataKeys}\n\n                    if pl != True:\n                        continue\n\n                if pl == True:\n\n                    try:\n                        plSpecAttrs = analysePlSpectrum(xPl, plSpectrum, raiseExceptions = raiseSpecExceptions)#Main PL analysis function\n                        plSpecAttrs['Raw Spectrum'] = plSpectrumRaw\n                    except Exception as e:\n\n                        print('%s failed because %s' % (plSpecName, e))\n                        gAllPl[plSpecName].attrs['Failure reason'] = str(e)\n                        gAllPl[plSpecName].attrs['wavelengths'] = gAllPl['PL Spectrum %s' % first].attrs['wavelengths']\n                        gFailedPl[plSpecName] = gAllRaw[plSpecName]\n                        gFailedPl[plSpecName].attrs['Failure reason'] = gAllPl[plSpecName].attrs['Failure reason']\n                        gFailedPl[plSpecName].attrs['wavelengths'] = gAllPl[plSpecName].attrs['wavelengths']\n                        plMetadataKeys = ['Fit Error', 'Peak Heights', 'Peak FWHMs', 'Fit', 'Peak Centers']\n                        plSpecAttrs = {key : 'N/A' for key in plMetadataKeys}\n                        plSpecAttrs['Raw Spectrum'] = plSpectrumRaw\n                        continue\n\n            if ['Raw data'] in list(specAttrs.keys()):\n                del specAttrs['Raw data']\n\n            gAllRaw[spectrumName].attrs.update(specAttrs)\n\n            if pl == True:\n                gAllPl[plSpecName].attrs.update(plSpecAttrs)  \n\n            if False in [specAttrs['NPoM?'], plSpecAttrs['NPoM?']]:\n                gNonPoms[spectrumName] = gAllRaw[spectrumName]\n                gNonPoms[spectrumName].attrs.update(gAllRaw[spectrumName].attrs)\n\n                if pl == True:\n                    gNonPomsPl[plSpecName] = gAllPl[plSpecName]\n                    gNonPomsPl[plSpecName].attrs.update(gAllPl[plSpecName].attrs)\n\n            else:                \n                gAllNPoMsRaw[spectrumName] = gAllRaw[spectrumName]\n                gAllNPoMsNorm[spectrumName] = gAllRaw[spectrumName].attrs['Raw data (normalised)']\n\n                del gAllRaw[spectrumName].attrs['Raw data (normalised)']\n\n                gAllNPoMsRaw[spectrumName].attrs.update(gAllRaw[spectrumName].attrs)\n                gAllNPoMsNorm[spectrumName].attrs.update(gAllRaw[spectrumName].attrs)               \n\n                if pl == True:\n                    gAllNPoMsPl[plSpecName] = gAllPl[plSpecName]\n                    gAllNPoMsPl[plSpecName].attrs.update(gAllPl[plSpecName].attrs)\n\n                    if type(gAllPl[plSpecName].attrs['Fit']) != str and abs(gAllPl[plSpecName].attrs['Fit'][()].max()) > 1:\n                        gAllNPoMsPlNorm[plSpecName] = old_div(gAllPl[plSpecName][()], gAllPl[plSpecName].attrs['Fit'][()].max())\n                        gAllNPoMsPlNorm[plSpecName].attrs.update(gAllPl[plSpecName].attrs)\n                        gAllNPoMsPlNorm[plSpecName].attrs['Peak Heights'] = old_div(gAllPl[plSpecName].attrs['Peak Heights'][()], gAllPl[plSpecName].attrs['Fit'][()].max())\n\n                    else:\n                        gAllNPoMsPlNorm[plSpecName] = old_div(gAllPl[plSpecName][()], gAllPl[plSpecName][()].max())\n                        gAllNPoMsPlNorm[plSpecName].attrs.update(gAllPl[plSpecName].attrs)\n                        gAllNPoMsPlNorm[plSpecName].attrs['Peak Heights'] = old_div(gAllPl[plSpecName].attrs['Peak Heights'][()], gAllPl[plSpecName][()].max())\n\n                if n not in misalignedParticleNumbers:\n                    gAlignedRaw[spectrumName] = gAllNPoMsRaw[spectrumName]\n                    gAlignedRaw[spectrumName].attrs.update(gAllNPoMsRaw[spectrumName].attrs)\n\n                    gAlignedNorm[spectrumName] = gAllNPoMsNorm[spectrumName]\n                    gAlignedNorm[spectrumName].attrs.update(gAllNPoMsNorm[spectrumName].attrs)\n\n                    if pl == True:\n                        gAlignedPl[plSpecName] = gAllNPoMsPl[plSpecName]\n                        gAlignedPl[plSpecName].attrs.update(gAllNPoMsPl[plSpecName].attrs)\n\n                        gAlignedPlNorm[plSpecName] = gAllNPoMsPlNorm[plSpecName]\n                        gAlignedPlNorm[plSpecName].attrs.update(gAllNPoMsPlNorm[plSpecName].attrs)\n\n                if specAttrs['Double Peak?'] == True:\n                    gDoublesRaw[spectrumName] = gAllNPoMsRaw[spectrumName]\n                    gDoublesRaw[spectrumName].attrs.update(gAllNPoMsRaw[spectrumName].attrs)\n\n                    gDoublesNorm[spectrumName] = gAllNPoMsNorm[spectrumName]\n                    gDoublesNorm[spectrumName].attrs.update(gAllNPoMsNorm[spectrumName].attrs)\n\n                    if pl == True:\n                        gDoublesPl[plSpecName] = gAllNPoMsPl[plSpecName]\n                        gDoublesPl[plSpecName].attrs.update(gAllNPoMsPl[plSpecName].attrs)\n\n                        gDoublesPlNorm[plSpecName] = gAllNPoMsPlNorm[plSpecName]\n                        gDoublesPlNorm[plSpecName].attrs.update(gAllNPoMsPlNorm[plSpecName].attrs)\n\n                else:\n                    gSinglesRaw[spectrumName] = gAllNPoMsRaw[spectrumName]\n                    gSinglesRaw[spectrumName].attrs.update(gAllNPoMsRaw[spectrumName].attrs)\n\n                    gSinglesNorm[spectrumName] = gAllNPoMsNorm[spectrumName]\n                    gSinglesNorm[spectrumName].attrs.update(gAllNPoMsNorm[spectrumName].attrs)\n\n                    if pl == True:\n                        gSinglesPl[plSpecName] = gAllNPoMsPl[plSpecName]\n                        gSinglesPl[plSpecName].attrs.update(gAllNPoMsPl[plSpecName].attrs)\n\n                        gSinglesPlNorm[plSpecName] = gAllNPoMsPlNorm[plSpecName]\n                        gSinglesPlNorm[plSpecName].attrs.update(gAllNPoMsPlNorm[plSpecName].attrs)\n\n\n                if specAttrs['Weird Peak?'] == True:\n                    gWeirdsRaw[spectrumName] = gAllNPoMsRaw[spectrumName]\n                    gWeirdsRaw[spectrumName].attrs.update(gAllNPoMsRaw[spectrumName].attrs)\n\n                    gWeirdsNorm[spectrumName] = gAllNPoMsNorm[spectrumName]\n                    gWeirdsNorm[spectrumName].attrs.update(gAllNPoMsNorm[spectrumName].attrs)\n\n                    if pl == True:\n                        gWeirdsPl[plSpecName] = gAllNPoMsPl[plSpecName]\n                        gWeirdsPl[plSpecName].attrs.update(gAllNPoMsPl[plSpecName].attrs)\n\n                        gWeirdsPlNorm[plSpecName] = gAllNPoMsPlNorm[plSpecName]\n                        gWeirdsPlNorm[plSpecName].attrs.update(gAllNPoMsPlNorm[plSpecName].attrs)\n\n                else:\n                    gNormalRaw[spectrumName] = gAllNPoMsRaw[spectrumName]\n                    gNormalRaw[spectrumName].attrs.update(gAllNPoMsRaw[spectrumName].attrs)\n\n                    gNormalNorm[spectrumName] = gAllNPoMsNorm[spectrumName]\n                    gNormalNorm[spectrumName].attrs.update(gAllNPoMsNorm[spectrumName].attrs)\n\n                    if pl == True:\n                        gNormalPl[plSpecName] = gAllNPoMsPl[plSpecName]\n                        gNormalPl[plSpecName].attrs.update(gAllNPoMsPl[plSpecName].attrs)\n\n                        gNormalPlNorm[plSpecName] = gAllNPoMsPlNorm[plSpecName]\n                        gNormalPlNorm[plSpecName].attrs.update(gAllNPoMsPlNorm[plSpecName].attrs)\n\n                if specAttrs['Weird Peak?'] == False and specAttrs['Double Peak?'] == False:\n                    gIdealRaw[spectrumName] = gAllNPoMsRaw[spectrumName]\n                    gIdealRaw[spectrumName].attrs.update(gAllNPoMsRaw[spectrumName].attrs)\n\n                    gIdealNorm[spectrumName] = gAllNPoMsNorm[spectrumName]\n                    gIdealNorm[spectrumName].attrs.update(gAllNPoMsNorm[spectrumName].attrs)\n                    \n                    if spectrumName in list(gAlignedRaw.keys()):\n                        gPerfectRaw[spectrumName] = gAllRaw[spectrumName]\n                        gPerfectRaw[spectrumName].attrs.update(gAllRaw[spectrumName].attrs)\n                    \n                    if spectrumName in list(gAlignedNorm.keys()):\n                        gPerfectNorm[spectrumName] = gAllRaw[spectrumName]\n                        gPerfectNorm[spectrumName].attrs.update(gAllRaw[spectrumName].attrs)\n                    \n\n                    if pl == True:\n                        gIdealPl[plSpecName] = gAllNPoMsPl[plSpecName]\n                        gIdealPl[plSpecName].attrs.update(gAllNPoMsPl[plSpecName].attrs)\n\n                        gIdealPlNorm[plSpecName] = gAllNPoMsPlNorm[plSpecName]\n                        gIdealPlNorm[plSpecName].attrs.update(gAllNPoMsPlNorm[plSpecName].attrs)\n                        \n                        if spectrumName in list(gAlignedRaw.keys()):\n                            gPerfectPl[spectrumName] = gAllPl[plSpecName]\n                            gPerfectPl[spectrumName].attrs.update(gAllPl[plSpecName].attrs)\n                        \n                        if spectrumName in list(gAlignedNorm.keys()):\n                            gPerfectPlNorm[plSpecName] = gAllNPoMsPlNorm[plSpecName]\n                            gPerfectPlNorm[plSpecName].attrs.update(gAllNPoMsPlNorm[plSpecName].attrs)\n\n    currentTime = time.time() - totalFitStart\n    mins = int(old_div(currentTime, 60))\n    secs = old_div((np.round((currentTime % 60)*100)),100)\n    print('100%% (%s spectra) analysed in %s min %s sec\\n' % (nn, mins, secs))\n\n    if stats == True:\n        doStats(outputFileName, closeFigures = closeFigures, peakFindMidpoint = peakFindMidpoint, pl = pl, npomTypes = npomTypes, \n                raiseExceptions = raiseExceptions, sortStacks = sortStacks, sortStacksMethod = sortStacksMethod, intensityRatios = intensityRatios)\n\n    absoluteEndTime = time.time()\n    timeElapsed = absoluteEndTime - absoluteStartTime\n    mins = int(old_div(timeElapsed, 60))\n    secs = int(np.round(timeElapsed % 60))\n\n    printEnd()\n\n    with h5py.File(outputFileName, 'a') as opf:\n        \n        if mins > 30:\n            print('\\nM8 that took ages')\n        \n        gAllRaw = opf['All Spectra (Raw)']\n        nTotal = len(list(gAllRaw.keys()))\n                \n        if 'Failed Spectra' in opf.keys():\n            gFailed = opf['Failed Spectra']\n            nFailed = len(list(gFailed.keys()))\n            \n            if nFailed == 0:\n                print('\\nFinished in %s min %s sec. Smooth sailing.' % (mins, secs))\n\n            if nFailed == 1:\n                print('\\nPhew... finished in %s min %s sec with only %s failure' % (mins, secs, len(gFailed)))\n\n            elif nFailed > nTotal * 2:\n                print('\\nHmmm... finished in %s min %s sec but with %s failures and only %s successful fits' % (mins, secs, len(gFailed),\n                                                                                                                len(gAllRaw) - len(gFailed)))\n            else:\n                print('\\nPhew... finished in %s min %s sec with only %s failures' % (mins, secs, len(gFailed)))\n\n        else:\n            print('\\nFinished in %s min %s sec. Smooth sailing.' % (mins, secs))\n\n        print('')",
  "def getState(a, b):\n        if a < b: return rising\n        if a > b: return falling\n        return neutral",
  "def calcGaussResiduals(pars):\n        '''pars = list of lists of gaussian parameters (center, height, fwhm)'''\n\n        fit = np.zeros(len(x))\n        peakPars = []\n\n        for n, par in enumerate(pars):\n            peakPars.append(par)\n\n            if len(peakPars) == 3:\n                gauss = gaussian(x, peakPars[0], peakPars[1], peakPars[2])#height, center, fwhm\n                fit += gauss\n                peakPars = []\n\n        diff = np.sum(abs(y - fit))\n\n        return diff",
  "def irradiate(time = 10.0,laser_power = 10,number_of_spec = 10):\n    spectrum_list = []\n    for i in range(number_of_spec):\n        spectrum_list.append(spec.read_spectrum())\n    attrs = spec.metadata\n    attrs['hi'] = 5\n    return ArrayWithAttrs(spectrum_list,attrs = attrs)",
  "def recenter_particle():\n    feature = wizard.current_feature\n    CWL.move_to_feature(feature, ignore_z_pos = True)",
  "def takePlBg(laserPower):\n    print('Taking PL Background...')\n    cube = CubeLaser('COM4')\n    shutter = Uniblitz('COM9')\n    shutter.open_shutter()\n    \n    if 'PL Background' not in list(wizard.data_file.keys()):\n        wizard.data_file.create_group('PL Background')\n        \n    gPlBg = wizard.data_file['PL Background']\n    cube.set_power(laserPower)\n    time.sleep(1.0)  \n    gPlBg.create_dataset(name = 'Power %s' % (laserPower), data = spec.read_spectrum(),\n                                                  attrs = {'laser_power' : laserPower,\n                                                           'wavelengths' : spec.get_wavelengths()})\n    \n    gPlBg.attrs.update(spec.metadata)\n    time.sleep(1.0)\n    cube.set_power(0)\n    time.sleep(0.5)\n    shutter.close_shutter()\n    cube.close()\n    shutter.close()\n    print('\\tPL Background successfully measured')",
  "def laserOn(laserPower):\n    cube = CubeLaser('COM4')\n    cube.mode_switch()\n    shutter = Uniblitz('COM9')\n    shutter.open_shutter()\n    cube.set_power(laserPower)",
  "def laserOff():\n    cube = CubeLaser('COM4')\n    shutter = Uniblitz('COM9')\n    cube.set_power(0)\n    shutter.close_shutter()\n    cube.close()\n    shutter.close()",
  "def df_pl_with_laser_scan(power_iter=1, number_of_iter=1, laser_power=3, number_of_spec=2, Increment=1,\n                          cam_exposure = 600, cam_gain = 23):\n    \"\"\"\n    Laser irradiation for particle tracking program \n    \"\"\"\n    irad_group = wizard.particle_group.create_group('dark field with irradiation')\n    \n    log = wizard.data_file['nplab_log']\n    lastEventName = sorted(list(log.keys()), key = lambda event: log[event].attrs['creation_timestamp'])[-1]\n    lastEvent = str(log[lastEventName])\n    \n    if 'error centering on feature' in lastEvent.lower():\n        print('Readjusting camera exposure and gain')\n        CWL.camera.exposure = cam_exposure\n        CWL.camera.gain = cam_gain\n        print('Exposure set to %s, gain to %s' % (cam_exposure, cam_gain))\n        shutter = Uniblitz('COM9')\n        shutter.open_shutter()\n        shutter.close_shutter()\n        shutter.close()\n        \n    cube = CubeLaser('COM4')\n    cube.mode_switch()\n    shutter = Uniblitz('COM9')\n    laser_power = laser_power\n    for i in range (power_iter):\n        for i in range (number_of_iter):#while stop_event.is_set()==False and iterations<spectra_num:            \n\n            try:\n                shutter.open_shutter()\n            except Exception as e:\n                print(e, end=' ')\n                print('shutter operation failure')\n        \n            try:\n                cube.set_power(laser_power)\n                time.sleep(1.0)\n            except Exception as e:\n                print(e, end=' ')\n                print('laser power write fail')\n            print(laser_power)\n            for i in range(number_of_spec):\n                dIrad = irad_group.create_dataset(name = 'PL_%s_%s' % (laser_power, i),\n                                                  data = spec.read_spectrum(),\n                                                  attrs = {'laser_power' : laser_power,\n                                                           'wavelengths' : spec.get_wavelengths()})\n                dIrad.attrs.update(spec.metadata)\n            \n            try:\n                cube.set_power(0)\n                shutter.close_shutter()\n            except Exception as e:\n                print(e, end=' ')\n                print('laser power write fail')\n            print(laser_power)\n            time.sleep(1) \n        laser_power=laser_power+Increment\n    cube.close()\n    shutter.close()",
  "def run(raiseExceptions = raiseExceptions, intensityRatios = intensityRatios, \n        statsOnly = statsOnly, pl = pl, npSize = npSize, npomTypes = npomTypes, consolidateScans = consolidateScans,\n        customScan = customScan, extractFirst = extractFirst, avgZScans = avgZScans, upperCutoff = upperCutoff, \n        lowerCutoff = lowerCutoff,startSpec = startSpec, finishSpec = finishSpec):\n    \n    print('\\tModules imported')\n    absoluteStartTime = time.time()\n\n    if statsOnly == True:\n        outputFileName = mpf.findH5File(os.getcwd(), nameFormat = 'MultiPeakFitOutput', mostRecent = True)#finds the most recent file with given name format\n        mpf.doStats(outputFileName, stacks = False, pl = pl, npomTypes = npomTypes, intensityRatios = intensityRatios, \n                    upperCutoff = upperCutoff, lowerCutoff = lowerCutoff)\n\n    else:\n\n        #if consolidateScans == True:\n        #    cdf.consoliData(os.getcwd())\n        \n        if extractFirst == True:\n            summaryFile = cdf.extractAllSpectra(os.getcwd(), returnIndividual = True, start = startSpec,\n                                                finish = finishSpec, raiseExceptions = raiseExceptions, customScan = customScan,\n                                                consolidated = consolidateScans, avgZScans = avgZScans)#condenses Z-stack (inc. background subtraction and referencing) for each particle and makes summary file\n    \n            if pl == True:\n                summaryFile, pl = cdf.transferPlSpectra(os.getcwd(), startWl = 505, start = startSpec,\n                                                    finish = finishSpec)#background subtracts each PL spectra and transfers them to the existing summary file\n\n        #summaryFile = 'summary.h5' #use this instead of the above functions if you already have a summary file\n\n        if raiseExceptions == True:\n            outputFileName = mpf.createOutputFile('MultiPeakFitOutput')\n            mpf.fitAllSpectra(os.getcwd(), outputFileName, npSize = npSize, first = startSpec, last = finishSpec,\n                              pl = pl, closeFigures = True, stats = True, npomTypes = npomTypes,\n                              raiseExceptions = raiseExceptions, raiseSpecExceptions = raiseExceptions, \n                              intensityRatios = intensityRatios, upperCutoff = upperCutoff, lowerCutoff = lowerCutoff)\n\n\n            print('\\nData fitting complete')\n\n        else:\n            try:\n                outputFileName = mpf.createOutputFile('MultiPeakFitOutput')\n                mpf.fitAllSpectra(os.getcwd(), outputFileName, npSize = npSize, first = startSpec, last = finishSpec,\n                                  pl = pl, closeFigures = True, stats = True, npomTypes = npomTypes, lowerCutoff = lowerCutoff,\n                                  raiseExceptions = raiseExceptions, raiseSpecExceptions = raiseExceptions, \n                                  intensityRatios = intensityRatios, upperCutoff = upperCutoff)\n\n                print('\\nData fitting complete')\n\n            except Exception as e:\n                print('\\nData fitting failed because %s' % (e))\n\n    plt.close('all')\n    absoluteEndTime = time.time()\n    timeElapsed = absoluteEndTime - absoluteStartTime\n\n    hours = int(old_div(timeElapsed, 3600))\n    mins = int(np.round(old_div((timeElapsed % 3600),60)))\n    secs = int(np.round(timeElapsed % 60))\n\n    if hours > 0:\n        print('\\nM8 that took ages. %s hours %s min %s sec' % (hours, mins, secs))\n\n    else:\n        print('\\nFinished in %s min %s sec' % (mins, secs))",
  "def Linear_Interpolation(Value1,Value2,Frac):\n    #Value 1 and 2 are two numbers. Frac is between 0 and 1 and tells you fractionally how far between the two values you want ot interpolate\n\n    m=Value2-Value1\n    c=Value1\n\n    return (m*Frac)+c",
  "def Run(Z_Scan,Threshold=0.2, Smoothing_width=1.5):\n    \"\"\"\n    Here, the Z_Scan is assumed to already by background subtracted and referenced.\n    \"\"\"\n\n    Thresholded=np.nan_to_num(Z_Scan)\n\n    Thresholded=Thresholded.astype(np.float64)\n    Thresholded=(Thresholded - Thresholded.min(axis=0))/(Thresholded.max(axis=0)-Thresholded.min(axis=0))\n    Thresholded-=Threshold\n    Thresholded*=(Thresholded>0)       #Normalise and Threshold array\n\n    Ones=np.zeros([Z_Scan.shape[1]])+1\n    Positions=[]\n    while len(Positions)<Z_Scan.shape[0]:\n        Positions.append(Ones*len(Positions))\n    Positions=np.array(Positions).astype(np.float64)\n\n    Centroids=np.sum((Thresholded*Positions),axis=0)/np.sum(Thresholded,axis=0) #Find Z centroid position for each wavelength\n    \n    Centroids=np.nan_to_num(Centroids)\n    \n    Rotated=np.transpose(Z_Scan)\n    print('Zt = ', Rotated[20])\n\n    Output=[]\n    n=0\n    while n<len(Centroids):\n        Lower=int(Centroids[n])\n        Upper=Lower+1\n\n        Frac=Centroids[n]-Lower\n        if Upper==len(Rotated[n]):\n            Upper-=1\n            Frac=0\n        #if Lower==len(Rotated):\n            #Lower-=1\n\n        #print Lower,Upper\n\n        Output.append(Linear_Interpolation(Rotated[n][Lower],Rotated[n][Upper],Frac))\n\n        n+=1\n\n    return np.array(Output), np.array(Centroids)",
  "def Polynomial(x,Anchors,Anchor_Values):\n\t\"\"\"\n\tDefines a polynomial by the points it passed through. Anchors are points x, Anchor_Values are point y.\n\t\"\"\"\n\treturn np.polyval(np.polyfit(Anchors,Anchor_Values,len(Anchors)-1),x)",
  "def Initial_Guess(x,y,Order=3):\n\t\"\"\"\n\tFind smallest signal values in equally sized chunks of y\n\t\"\"\"\n\tEdges=np.round(np.linspace(0,len(y)-1,Order+2)).astype(int)\n\tAnchors=[]\n\tAnchor_Values=[]\n\tfor i in range(len(Edges))[1:]:\n\t\tArg=np.argmin(y[Edges[i-1]:Edges[i]])+Edges[i-1]\n\t\tAnchors.append(Arg)\n\t\tAnchor_Values.append(y[Arg])\n\treturn Anchors,Anchor_Values",
  "def Update_Polynomial(x,y,Mask,Anchors,Anchor_Values):\n\t\"\"\"\n\tOptimise polynomial defined by Anchors and Anchor_Values to fit (x,y) elements defined by bool Mask\n\t\"\"\"\n\tdef Loss(Anchor_Values):\n\t\treturn np.sum(np.abs((Polynomial(x,Anchors,Anchor_Values)-y)[Mask]))\n\treturn spo.minimize(Loss,Anchor_Values).x",
  "def Run(x,y,Poly_Order=4,Auto_Remove=True,Maximum_Iterations=100):\n\t\"\"\"\n\tMain function. Described above.\n\t\"\"\"\n\tIteration=0\n\n\tAnchors,Anchor_Values=Initial_Guess(x,y,Poly_Order)\n\n\tMask=(np.array(y)*0+1).astype(bool)\n\n\twhile True:\n\t\tAnchor_Values=Update_Polynomial(x,y,Mask,Anchors,Anchor_Values)\n\n\t\tNoise_Elements=(np.array(y)-Polynomial(x,Anchors,Anchor_Values))[np.array(y)<Polynomial(x,Anchors,Anchor_Values)]\n\t\tNoise=np.mean(np.square(Noise_Elements))**0.5\n\n\t\tNew_Mask=(np.array(y)<=(Polynomial(x,Anchors,Anchor_Values)+Noise))\n\n\t\tIteration+=1\n\n\t\tif np.sum(New_Mask==Mask)==len(Mask) or Iteration==Maximum_Iterations:\n\t\t\tBG=Polynomial(x,Anchors,Anchor_Values)\n\t\t\tif Auto_Remove is True:\n\t\t\t\treturn y-BG\n\t\t\telse:\n\t\t\t\treturn BG \n\t\telse:\n\t\t\tMask=New_Mask",
  "def Loss(Anchor_Values):\n\t\treturn np.sum(np.abs((Polynomial(x,Anchors,Anchor_Values)-y)[Mask]))",
  "def Construct_Background(Gradient,Not_Allowed,Window,Signal_Length):\n\t\"\"\"\n\tFunction that takes a list of gradients (Gradient), a list indicating whether points represent possible peak postions (Not_Allowed), the window size\n\tand the length of the signal and reconstructs the BG signal + a constant.\n\t\"\"\"\n\n\t#---Estimate gradient at each position----\n\n\tAverage=[]\n\twhile len(Average)<Signal_Length:\n\t\tAverage.append([])\n\n\tfor i in range(len(Gradient)):\n\t\tif Not_Allowed[i] is False and Not_Allowed[i+Window] is False:\n\t\t\tn=0\n\t\t\twhile n<=Window:\n\t\t\t\tAverage[n+i].append(Gradient[i])\n\t\t\t\tn+=1\n\n\t#--- Ensure every point has a gradient----\n\n\tif len(Average[0])==0:\n\t\tAverage[0]=[0]\n\tfor i in range(len(Average)):\n\t\tif len(Average[i])==0:\n\t\t\tAverage[i]=Average[i-1]\n\n\t#---Integrate up output------\n\n\tOutput=[0.]\n\tfor i in Average:\n\t\tOutput.append(Output[-1]+np.median(i))\n\n\treturn np.array(Output[:-1])",
  "def Run(Signal,Window=50,Maximum_Iterations=10,Peak_Tolerance=0.5):\n\t\"\"\"\n\tMain function, explained at the top of the page.\n\t\"\"\"\n\n\t#---Ensure Window fits contraints---\n\n\tWindow=int(Window)\n\tif Window<2:\n\t\tWindow=2\n\n\t#--Calcuate gradients-------\n\n\tGradient=[]\n\tn=Window\n\twhile n<len(Signal):\n\t\tGradient.append(float(Signal[n]-Signal[n-Window])/Window)\n\t\tn+=1\n\tNot_Allowed=[]\n\twhile len(Not_Allowed)<len(Signal):\n\t\tNot_Allowed.append(False)\n\n\t#----Initial estimate-----\n\n\tBackground=Construct_Background(Gradient,Not_Allowed,Window,len(Signal))\n\n\tClean=np.array(Signal)-Background\n\tClean=Clean-np.median(Clean)\n\n\t#---Calculate number of points over the noise threshold that correspond to a possible peak\n\n\tPoint_Run=0\n\twhile 100.*((1./6)**Point_Run)>Peak_Tolerance:\n\t\tPoint_Run+=1\n\n\t#---Iterate background estimation, ignoring possible peak positions-----\n\n\tIterate=True\n\tIterations=0\n\twhile Iterate is True and Iterations<Maximum_Iterations:\n\t\tIterations+=1\n\t\tPossible_Peak_Regions=[]\n\t\tCurrent_Run=[]\n\t\tThreshold=np.median(np.abs(Clean))\n\t\tfor i in range(len(Signal)):\n\t\t\tif Clean[i]>=Threshold:\n\t\t\t\tCurrent_Run.append(i)\n\t\t\telse:\n\t\t\t\tif len(Current_Run)>=Point_Run:\n\t\t\t\t\tPossible_Peak_Regions+=Current_Run\n\t\t\t\tCurrent_Run=[]\n\t\tif len(Current_Run)>=Point_Run:\n\t\t\tPossible_Peak_Regions+=Current_Run\n\n\t\tNew_Not_Allowed=[]\n\t\tfor i in range(len(Signal)):\n\t\t\tif i in Possible_Peak_Regions:\n\t\t\t\tNew_Not_Allowed.append(True)\n\t\t\telse:\n\t\t\t\tNew_Not_Allowed.append(False)\n\n\t\tif np.array_equal(Not_Allowed,New_Not_Allowed)==False:\n\t\t\tNot_Allowed=New_Not_Allowed\n\t\t\tBackground=Construct_Background(Gradient,Not_Allowed,Window,len(Signal))\n\t\t\tClean=np.array(Signal)-Background\n\t\t\tClean=Clean-np.median(Clean)\n\t\telse:\n\t\t\tIterate=False\n\n\treturn Clean",
  "def Find_Weights(Background,Data):\n\t\"\"\"\n\tGiven a background fit (Background) and a spectrum (Data), calculates the probabilities for seeing the number of counts observed or greater\n\tat each wavelength assuming they are Poisson distributed with means at the background fit value.\n\t\"\"\"\n\tWeights=[]\n\tfor i in range(len(Background)):\n\t\tWeights.append(1-stat.poisson.cdf(Data[i],Background[i]))\n\treturn Weights",
  "def Iterative_Step(Data,Current_Params,Degree,Return_BG=False):\n\t\"\"\"\n\tGiven a spectrum and background fit, updates the background fit. \n\n\tData=1D array for spectrum. Current_Params=List of polynomial coefficents for the BG fit, highest power first. Degree=order of polynomial fit. \n\n\tIf Return_BG=False, the next polynomial coefficents will be returned. If Return_BG=True, the 1D array of the background for the \n\tINPUT coefficents is also returned.\n\t\"\"\"\n\n\tBackground=np.polyval(Current_Params,list(range(len(Data))))\n\tBackground*=(Background>0)  #For a Poisson distribution, negative values are meaningless\n\n\tWeights=Find_Weights(Background,Data)\n\t\n\tPoly_Params=np.polyfit(list(range(len(Data))),Data,Degree,w=Weights)\n\n\tif Return_BG is False:\n\t\treturn Poly_Params\n\telse:\n\t\treturn Poly_Params,Background",
  "def Run(Data,Degree,Threshold=0.0001,Max_Steps=None,Auto_Remove=True):\n\t\"\"\"\n\tMain function that completes the background subtraction. \n\n\tData=1D array for spectrum. Degree is the polynomial degree to fit. The initial sum squared difference between the first two backgrounds is \n\tcalculated. The function returns when this sum between two successive background fits is less than Threshold*the original difference. If\n\tMax_Steps is a number, the function will automatically return after Max_Steps iterations. \n\n\tIf Auto_Remove is True, the background subtracted spectrum is returned. If it is False, the Background is returned.\n\t\"\"\"\n\n\tBackground=None\n\tIntial_Difference=None\n\tEnd=False\n\n\tParams=np.polyfit(list(range(len(Data))),Data,Degree)\n\n\tSteps=0\n\n\twhile End is False:\n\t\tParams,New_Background=Iterative_Step(Data,Params,Degree,True)\n\t\tif Background is None:\n\t\t\tBackground=New_Background\n\t\telse:\n\t\t\tDifference=np.sum(np.square(np.array(New_Background)-np.array(Background)))**0.5\n\t\t\tif Intial_Difference is None:\n\t\t\t\tIntial_Difference=Difference\n\t\t\telse:\n\t\t\t\tif Difference<Threshold*Intial_Difference:\n\t\t\t\t\tEnd=True\n\t\t\t\telse:\n\t\t\t\t\tBackground=New_Background\n\t\tif Max_Steps is not None:\n\t\t\tif Steps>Max_Steps:\n\t\t\t\tEnd=True\n\t\tSteps+=1\n\n\tBackground=np.polyval(Params,list(range(len(Data))))\n\tBackground*=(Background>0)\n\n\tif Auto_Remove is True:\n\t\treturn np.array(Data)-np.array(Background)\n\telse:\n\t\treturn np.array(Background)",
  "def baseline_als(y, lam, p, niter=10):\n    \"\"\"\n    y is the spectrum\n    lam is the smoothness, should be between 10**2 and 10**9\n    p is asymmetry, should be between 0.001 and 0.1\n    \"\"\"\n    L = len(y)\n    D = sparse.diags([1, -2, 1], [0, -1, -2], shape=(L, L - 2))\n    w = np.ones(L)\n    for _ in range(niter):\n        W = sparse.spdiags(w, 0, L, L)\n        Z = W + lam * D.dot(D.transpose())\n        z = spsolve(Z, w * y)\n        w = p * (y > z) + (1 - p) * (y < z)\n    return z",
  "def als(y, lam=10**3, p=0.01, niter=10):\n    return baseline_als(y, lam, p, niter=niter)",
  "class FigureCanvasWithDeferredDraw(FigureCanvas):\n    # This class allows us to use Qt's event loop to draw the canvas from\n    # the GUI thread, even if the call comes from outside the GUI thread.\n    # this is necessary if you want to plot from a background thread.\n    ask_for_redraw = QtCore.Signal()\n\n    def __init__(self, figure):\n        FigureCanvas.__init__(self, figure)\n        # We connect the ask_for_redraw signal to the FigureCanvas's draw() method.\n        # using a QueuedConnection ensures that draw() is correctly called in the\n        # application's main GUI thread.\n        self.ask_for_redraw.connect(self.draw, type=QtCore.Qt.QueuedConnection)\n\n    def draw_in_main_loop(self):\n        \"\"\"Draw the canvas, but do so in the Qt main loop to avoid threading nasties.\"\"\"\n        self.ask_for_redraw.emit()",
  "def __init__(self, figure):\n        FigureCanvas.__init__(self, figure)\n        # We connect the ask_for_redraw signal to the FigureCanvas's draw() method.\n        # using a QueuedConnection ensures that draw() is correctly called in the\n        # application's main GUI thread.\n        self.ask_for_redraw.connect(self.draw, type=QtCore.Qt.QueuedConnection)",
  "def draw_in_main_loop(self):\n        \"\"\"Draw the canvas, but do so in the Qt main loop to avoid threading nasties.\"\"\"\n        self.ask_for_redraw.emit()",
  "class HDF5ItemViewer(QtWidgets.QWidget, UiTools):\n    \"\"\"A Qt Widget for visualising one HDF5 element (group or dataset).\"\"\"\n    def __init__(self, \n                 item=None, \n                 parent=None, \n                 figure_widget=None,\n                 show_controls=True, \n                 show_refresh=True,\n                 show_default_button=True,\n                 show_copy=True,\n                 renderer_combobox=None,\n                 refresh_button=None,\n                 copy_button=None,\n                 default_button=None,\n                 ):\n        \"\"\"Create a viewer widget for any dataset or datagroup object\n        \n        Arguments:\n        item : HDF5 group or dataset (optional)\n            The dataset (or group) to display\n        parent : QWidget (optional)\n            The Qt parent of the widget.\n        show_controls : bool (optional)\n            If True (default), show the refresh button and combobox.  If False,\n            just show the renderer.\n        show_refresh : bool (optional)\n            If show_controls is True, this sets whether the refresh button is\n            visible.\n        renderer_combobox : QComboBox (optional)\n            If this is specified, use the supplied combobox instead of creating\n            a new one.  You probably want to specify show_controls=False.\n        refresh_button : QPushButton (optional)\n            If specified, use the supplied button instead of creating one.\n        copy_button : QPushButton (optional)\n            If specified, use the supplied button instead of creating one.\n        default_button : QPushButton (optional)\n            If specified, use the supplied button to select the default \n            rendererinstead of creating one.\n        \"\"\"\n        super(HDF5ItemViewer, self).__init__(parent)\n        \n        if figure_widget is None: \n            self.figure_widget = QtWidgets.QWidget()\n        else:\n            self.figure_widget = figure_widget\n            \n        if renderer_combobox is None:       \n            self.renderer_combobox = QtWidgets.QComboBox()\n        else:\n            self.renderer_combobox = renderer_combobox\n        self.renderer_combobox.activated[int].connect(self.renderer_selected)        \n        \n        if refresh_button is None:\n            self.refresh_button = QtWidgets.QPushButton()\n            self.refresh_button.setText(\"Refresh Figure\")\n        else:\n            self.refresh_button = refresh_button\n        self.refresh_button.clicked.connect(self.refresh)\n        \n        if default_button is None:\n            self.default_button = QtWidgets.QPushButton()\n            self.default_button.setText(\"Default Renderer\")\n        else:\n            self.default_button = default_button\n        self.default_button.clicked.connect(self.default_renderer)\n        \n        if copy_button is None:\n            self.copy_button = QtWidgets.QPushButton()\n            self.copy_button.setText(\"Copy Figure\")\n        else:\n            self.copy_button = copy_button\n        self.copy_button.clicked.connect(self.CopyActivated)\n        self.clipboard = QtWidgets.QApplication.clipboard()\n\n        self.setLayout(QtWidgets.QVBoxLayout())\n        self.layout().addWidget(self.figure_widget, stretch=1)\n        self.layout().setContentsMargins(0,0,0,0)\n        \n        self.renderers = list()\n        \n        if show_controls: # this part may be broken\n            hb = QtWidgets.QHBoxLayout()\n            hb.addWidget(self.renderer_combobox, stretch=1)\n            if show_refresh:\n                hb.addWidget(self.refresh_button, stretch=0)\n            if show_copy:\n                hb.addWidget(self.copy_button, stretch=0)\n            if show_default_button:\n                hb.addWidget(self.default_button, stretch=0)\n            self.layout().addLayout(hb, stretch=0)\n        \n    _data = None\n        \n    @property\n    def data(self):\n        \"\"\"The dataset or group we are displaying\"\"\"\n        return self._data\n        \n    @data.setter\n    def data(self, newdata):\n        if newdata is None:\n            return None\n        \n        self._data = newdata\n\n        # When data changes, update the list of renderers\n        \n        renderers = suitable_renderers(self.data)\n        combobox = self.renderer_combobox\n        previous_selection = combobox.currentIndex() # remember previous choice\n        try:#Attempt to keep the same range\n            previous_view_rect = self.figure_widget.figureWidget.viewRect()\n        except AttributeError:\n            previous_view_rect = None\n            \n        combobox.clear()\n        for i, renderer in enumerate(renderers):\n            combobox.addItem(renderer.__name__, renderer)\n            \n        # Attempt to keep the same renderer as we had before - or use the \n        # \"best\" one.  NB setting the current index will trigger the renderer\n        # to be created in renderer_selected\n        try:\n            if previous_selection == 0:\n                raise ValueError() # if we didn't choose the last renderer, just\n                            # pick the best one.  Otherwise, try to use the same\n                            # renderer as we used before\n            else:\n                index = renderers.index(self.renderer.__class__)\n                combobox.setCurrentIndex(index)\n                try:\n                    self.renderer_selected(index)\n                except Exception as e:\n                    print('The selected renderer failed becasue',e)\n\n        except ValueError:\n            combobox.setCurrentIndex(0)\n            self.renderer_selected(0)\n        if previous_view_rect != None:\n            try:\n                self.figure_widget.figureWidget.setRange(previous_view_rect, padding=0)                                      \n            except AttributeError:\n                pass\n    \n    _renderer = None\n    \n    def default_renderer(self):\n        self.renderer_combobox.setCurrentIndex(0)\n        self.renderer_selected(0)\n        self.refresh()\n    \n    @property\n    def renderer(self):\n        \"\"\"The data renderer currently in use in the widget\"\"\"\n        return self._renderer\n        \n    @renderer.setter\n    def renderer(self, new_renderer):\n        self._renderer = new_renderer\n        # Replace the current renderer in the GUI with the new one:\n        self.figure_widget = self.replace_widget(self.layout(), self.figure_widget, new_renderer)\n    \n    def renderer_selected(self, index):\n        \"\"\"Change the figure widget to use the selected renderer.\"\"\"\n        # The class of the renderer is stored as the combobox data\n        RendererClass = self.renderer_combobox.itemData(index)\n        try:\n            self.renderer = RendererClass(self.data, self)\n        except TypeError:\n            # If the box is empty (e.g. it's just been cleared) use a blank widget\n            self.renderer = QtWidgets.QWidget()\n        \n    def refresh(self):\n        \"\"\"Re-render the data, using the current renderer (if it is still appropriate)\"\"\"\n        self.data = self.data\n\n    \n    def CopyActivated(self):\n        \"\"\"Copy an image of the currently-displayed figure.\"\"\"\n        ## TO DO: move this to the HDF5 viewer\n        print('yes')",
  "def split_number_from_name(name):\n    \"\"\"Return a tuple with the name and an integer to allow sorting.\"\"\"\n    basename = name.rstrip('0123456789')\n    try:\n        return (basename, int(name[len(basename):-1]))\n    except:\n        return (basename, -1)",
  "def igorOpen(dataset):\n    \"\"\"Open the currently-selected item in Igor Pro. If this is not working check your IGOR path!\"\"\"\n    igorpath = '\"C:\\\\Program Files (x86)\\\\WaveMetrics\\\\Igor Pro Folder\\\\Igor.exe\"'\n    igortmpfile = os.path.dirname(os.path.realpath(__file__))+'\\Igor'\n    igortmpfile=igortmpfile.replace(\"\\\\\",\"\\\\\\\\\")\n    print(igortmpfile)\n    open(igortmpfile, 'w').close()\n    print(\"attempting to open {} in Igor\".format(dataset))\n    if isinstance(dataset,h5py.Dataset):\n        dset = dataset\n        data = np.asarray(dset[...])\n\n        if data.ndim == 2:\n            # RWB: why do we do this?  Why not just use a 2D text file and skip rescaling??\n            from PIL import Image\n            rescaled = ((2**16/ data.max()) * (data - data.min())).astype(np.uint8)\n\n            im = Image.fromarray(rescaled.transpose())\n            im.save(igortmpfile+'.tif')\n\n            command='/X \"ImageLoad/T=tiff/N= h5Data'+' \\\"'+ igortmpfile+'.tif\\\"\"'\n            subprocess.Popen(igorpath+' '+command)\n        else:\n            print(dataset)\n            np.savetxt(igortmpfile+'.txt', data, header=dataset.name)\n            subprocess.Popen( igorpath+' '+ igortmpfile+'.txt')",
  "class HDF5TreeItem(object):\n    \"\"\"A simple class to represent items in an HDF5 tree\"\"\"\n    def __init__(self, data_file, parent, name, row):\n        \"\"\"Create a new item for an HDF5 tree\n\n        data_file : HDF5 data file\n            This is the file (NB must be the top-level group) containing everything\n        parent : HDF5TreeItem\n            The parent of the current item\n        name : string\n            The name of the current item (should be parent.name plus an extra component)\n        row : int\n            The index of the current item in the parent's children.\n        \"\"\"\n        self.data_file = data_file\n        self.parent = parent\n        self.name = name\n        self.row = row\n        if parent is not None:\n            assert name.startswith(parent.name)\n            assert name in data_file\n\n    @property\n    def basename(self):\n        \"\"\"The last component of the item's path in the HDF5 file\"\"\"\n        return self.name.rsplit('/')[-1]\n\n    _has_children = None\n    @property\n    def has_children(self):\n        \"\"\"Whether or not this item has children\"\"\"\n        if self._has_children is None:\n            #print(self.name)\n            self._has_children = hasattr(self.data_file[self.name], \"keys\")\n        return self._has_children\n\n    _children = None\n    @property\n    def children(self):\n        \"\"\"Children of the current item (as HDF5TreeItems)\"\"\"\n        if self.has_children is False:\n            return []\n        if self._children is None:\n            keys = list(self.data_file[self.name].keys())\n            try:\n                time_stamps = []\n                for value in self.data_file[self.name].values():\n                   \n                    try:\n                        time_stamp_str = value.attrs['creation_timestamp']\n                    except AttributeError:\n                        print(value)\n                        print('has no creation_timestamp attribute.')\n                        time_stamp_str = '2021-01-01T01:01:01.000001'\n                    #if type(time_stamp_str) is bytes:\n                    if isinstance(time_stamp_str, bytes):\n                        time_stamp_str = time_stamp_str.decode() #b'somestring'.decode('UTF-8')\n                    #print(time_stamp_str)\n                    try:\n                        time_stamp_float = datetime.datetime.strptime(time_stamp_str, \"%Y-%m-%dT%H:%M:%S.%f\")\n                    except ValueError:\n                        time_stamp_str =  time_stamp_str+'.0'\n                        time_stamp_float = datetime.datetime.strptime(time_stamp_str,\"%Y-%m-%dT%H:%M:%S.%f\")\n                    time_stamps.append(time_stamp_float)\n                keys = np.array(keys)[np.argsort(time_stamps)]\n            except KeyError:\n                keys.sort(key=split_number_from_name)\n            \n            self._children = [HDF5TreeItem(self.data_file, self, self.name.rstrip(\"/\") + \"/\" + k, i)\n                              for i, k in enumerate(keys)]\n        return self._children\n\n    def purge_children(self):\n        \"\"\"Empty the cached list of children\"\"\"\n        try:\n            if self._children is not None:\n                for child in self._children:\n                    child.purge_children() # We must delete them all the way down!\n                    self._children.remove(child)\n                    del child # Not sure if this is needed...\n                self._children = None\n            self._has_children = None\n        except:\n            print(\"{} failed to purge its children\".format(self.name))\n\n    @property\n    def h5item(self):\n        \"\"\"The underlying HDF5 item for this tree item.\"\"\"\n        assert self.name in self.data_file, \"Error, {} is no longer a valid HDF5 item\".format(self.name)\n        return self.data_file[self.name]\n\n    def __del__(self):\n        self.purge_children()",
  "def print_tree(item, prefix=\"\"):\n    \"\"\"Recursively print the HDF5 tree for debug purposes\"\"\"\n    if len(prefix) > 16:\n        return # recursion guard\n    print(prefix + item.basename)\n    if item.has_children:\n        for child in item.children:\n            print_tree(child, prefix + \"  \")",
  "class HDF5ItemModel(QtCore.QAbstractItemModel):\n    \"\"\"This model takes its data from an HDF5 Group for display in a tree.\n\n    It loads the file as the tree is expanded for speed - in the future it might implement sanity checks to\n    abort loading very long folders.\n    \"\"\"\n    def __init__(self, data_group):\n        \"\"\"Represent an HDF5 group to a QTreeView or similar.\n        :type data_group: nplab.datafile.Group\n        \"\"\"\n        super(HDF5ItemModel, self).__init__()\n        self.root_item = None\n        self.data_group = data_group\n        \n    _data_group = None\n    @property\n    def data_group(self):\n        \"\"\"The HDF5 group object we're representing\"\"\"\n        return self._data_group\n    \n    @data_group.setter\n    def data_group(self, new_data_group):\n        \"\"\"Set the data group represented by the model\"\"\"\n        if self.root_item is not None:\n            del self.root_item\n        self._data_group = new_data_group\n        self.root_item = HDF5TreeItem(new_data_group.file, None, new_data_group.name, 0)\n\n    def _index_to_item(self, index):\n        \"\"\"Return an HDF5TreeItem for a given index\"\"\"\n        if index.isValid():\n            return index.internalPointer()\n        else:\n            return self.root_item\n\n    def index(self, row, column, parent_index):\n        \"\"\"Return the index of the <row>th child of parent\n\n        :type row: int\n        :type column: int\n        :type parent: QtCore.QModelIndex\n        \"\"\"\n        try:\n            parent = self._index_to_item(parent_index)\n            return self.createIndex(row, column, parent.children[row])\n        except:\n            return QtCore.QModelIndex()\n\n    def parent(self, index=None):\n        \"\"\"Find the index of the parent of the item at a given index.\"\"\"\n        try:\n            parent = self._index_to_item(index).parent\n            return self.createIndex(parent.row, 0, parent)\n        except:\n            # Something went wrong with finding the parent so return an invalid index\n            return QtCore.QModelIndex()\n\n    def flags(self, index):\n        \"\"\"Return flags telling Qt what to do with the item\"\"\"\n        return QtCore.Qt.ItemIsSelectable | QtCore.Qt.ItemIsEnabled\n\n    def data(self, index, role):\n        \"\"\"The data represented by this item.\"\"\"\n        if role == QtCore.Qt.DisplayRole:\n            return self._index_to_item(index).basename\n        else:\n            return None\n\n    def headerData(self, section, orientation, role=None):\n        \"\"\"Return the header names - an empty string here!\"\"\"\n        return [\"\"]\n\n    def rowCount(self, index):\n        \"\"\"The number of rows exposed by the model\"\"\"\n        try:\n            item = self._index_to_item(index)\n            assert item.has_children\n            return len(item.children)\n        except:\n            # if it doesn't have keys, assume there are no children.\n            return 0\n\n    def hasChildren(self, index):\n        \"\"\"Whether or not this object has children\"\"\"\n        return self._index_to_item(index).has_children\n        #try:\n        #    assert hasattr(self._index_to_item(index), \"keys\")\n        #    return True\n        #except:\n        #    return False\n\n    def columnCount(self, index=None, *args, **kwargs):\n        \"\"\"Return the number of columns\"\"\"\n        return 1\n\n    def refresh_tree(self):\n        \"\"\"Reload the HDF5 tree, resetting the model\n\n        This causes all cached HDF5 tree information to be deleted, and any views\n        using this model will automatically reload.\n        \"\"\"\n        self.beginResetModel()\n        self.root_item.purge_children()\n        self.endResetModel()\n\n    def selected_h5item_from_view(self, treeview):\n        \"\"\"Given a treeview object, return the selection, as an HDF5 object, or a work-alike for multiple selection.\n\n        If one item is selected, we will return the HDF5 group or dataset that is selected.  If multiple items are\n        selected, we will return a dummy HDF5 group containing all selected items.\n        \"\"\"\n        items = [self._index_to_item(index) for index in treeview.selectedIndexes()]\n        if len(items) == 1:\n            return items[0].h5item\n        elif len(items) > 1:\n            return DummyHDF5Group({item.name: item.h5item for item in items})\n        else:\n            return None\n\n    def set_up_treeview(self, treeview):\n        \"\"\"Correctly configure a QTreeView to use this model.\n\n        This will set the HDF5ItemModel as the tree's model (data source), and in the future\n        may set up context menus, etc. as appropriate.\"\"\"\n        treeview.setModel(self) # Make the tree view use this object as its model\n        # Set up a callback to allow us to customise the context menu\n        treeview.setContextMenuPolicy(QtCore.Qt.CustomContextMenu)\n        treeview.customContextMenuRequested.connect(functools.partial(self.context_menu, treeview))\n        # Allow multiple objects to be selected\n        treeview.setSelectionMode(QtWidgets.QAbstractItemView.ExtendedSelection)\n\n    def context_menu(self, treeview, position):\n        \"\"\"Generate a right-click menu for the items\"\"\"\n        menu = QtWidgets.QMenu()\n        actions = {}\n\n        for operation in ['Refresh tree']:\n            actions[operation] = menu.addAction(operation)\n        action = menu.exec_(treeview.viewport().mapToGlobal(position))\n\n\n        if action == actions['Refresh tree']:\n            self.refresh_tree()",
  "class HDF5TreeWidget(QtWidgets.QTreeView):\n    \"\"\"A TreeView for looking at an HDF5 tree\"\"\"\n    def __init__(self, datafile, **kwargs):\n        \"\"\"Create a TreeView widget that views the contents of an HDF5 tree.\n\n        Arguments:\n            datafile : nplab.datafile.Group\n            the HDF5 tree to show\n\n        Additional keyword arguments are passed to the QTreeView constructor.\n        You may want to include parent, for example.\"\"\"\n        QtWidgets.QTreeView.__init__(self, **kwargs)\n\n        self.model = HDF5ItemModel(datafile)\n        self.model.set_up_treeview(self)\n        self.sizePolicy().setHorizontalStretch(0)\n\n    def selected_h5item(self):\n        \"\"\"Return the current selection as an HDF5 item.\"\"\"\n        return self.model.selected_h5item_from_view(self)\n\n    def __del__(self):\n        del self.model",
  "class HDF5Browser(QtWidgets.QWidget, UiTools):\n    \"\"\"A Qt Widget for fbrowsing an HDF5 file and graphing the data.\n    \"\"\"\n\n    def __init__(self, data_file, parent=None):\n        super(HDF5Browser, self).__init__(parent)\n        self.data_file = df.DataFile(data_file)\n        self.treeWidget = HDF5TreeWidget(data_file,\n                                         parent=self)\n        self.selection_model = self.treeWidget.selectionModel() \n        self.selection_model.selectionChanged.connect(self.selection_changed)\n        self.viewer = HDF5ItemViewer(parent=self, \n                                     show_controls=True,\n                                     )\n        self.refresh_tree_button = QtWidgets.QPushButton() #Create a refresh button\n        self.refresh_tree_button.setText(\"Refresh Tree\")\n        \n        #adding the refresh button\n        self.treelayoutwidget = QtWidgets.QWidget()     #construct a widget which can then contain the refresh button and the tree\n        self.treelayoutwidget.setLayout(QtWidgets.QVBoxLayout())\n        self.treelayoutwidget.layout().addWidget(self.treeWidget)\n        self.treelayoutwidget.layout().addWidget(self.refresh_tree_button) \n        \n        self.refresh_tree_button.clicked.connect(self.treeWidget.model.refresh_tree)\n\n        splitter = QtWidgets.QSplitter()\n        splitter.addWidget(self.treelayoutwidget)       #Add newly constructed widget (treeview and button) to the splitter\n        splitter.addWidget(self.viewer)\n        self.setLayout(QtWidgets.QHBoxLayout())\n        self.layout().addWidget(splitter)\n\n\n    def sizeHint(self):\n        return QtCore.QSize(1024,768)\n\n    def selection_changed(self, selected, deselected):\n        \"\"\"Callback function to update the displayed item when the tree selection changes.\"\"\"\n        try:\n            self.viewer.data = self.treeWidget.selected_h5item()\n            print(self.viewer.data)\n            if self.data_file.update_current_group:\n                df.set_current_group(self.treeWidget.selected_h5item())\n\n        except Exception as e:\n            \n            print(e, 'That could be corrupted')\n         \n            \n\n    def __del__(self):\n        pass",
  "def __init__(self, \n                 item=None, \n                 parent=None, \n                 figure_widget=None,\n                 show_controls=True, \n                 show_refresh=True,\n                 show_default_button=True,\n                 show_copy=True,\n                 renderer_combobox=None,\n                 refresh_button=None,\n                 copy_button=None,\n                 default_button=None,\n                 ):\n        \"\"\"Create a viewer widget for any dataset or datagroup object\n        \n        Arguments:\n        item : HDF5 group or dataset (optional)\n            The dataset (or group) to display\n        parent : QWidget (optional)\n            The Qt parent of the widget.\n        show_controls : bool (optional)\n            If True (default), show the refresh button and combobox.  If False,\n            just show the renderer.\n        show_refresh : bool (optional)\n            If show_controls is True, this sets whether the refresh button is\n            visible.\n        renderer_combobox : QComboBox (optional)\n            If this is specified, use the supplied combobox instead of creating\n            a new one.  You probably want to specify show_controls=False.\n        refresh_button : QPushButton (optional)\n            If specified, use the supplied button instead of creating one.\n        copy_button : QPushButton (optional)\n            If specified, use the supplied button instead of creating one.\n        default_button : QPushButton (optional)\n            If specified, use the supplied button to select the default \n            rendererinstead of creating one.\n        \"\"\"\n        super(HDF5ItemViewer, self).__init__(parent)\n        \n        if figure_widget is None: \n            self.figure_widget = QtWidgets.QWidget()\n        else:\n            self.figure_widget = figure_widget\n            \n        if renderer_combobox is None:       \n            self.renderer_combobox = QtWidgets.QComboBox()\n        else:\n            self.renderer_combobox = renderer_combobox\n        self.renderer_combobox.activated[int].connect(self.renderer_selected)        \n        \n        if refresh_button is None:\n            self.refresh_button = QtWidgets.QPushButton()\n            self.refresh_button.setText(\"Refresh Figure\")\n        else:\n            self.refresh_button = refresh_button\n        self.refresh_button.clicked.connect(self.refresh)\n        \n        if default_button is None:\n            self.default_button = QtWidgets.QPushButton()\n            self.default_button.setText(\"Default Renderer\")\n        else:\n            self.default_button = default_button\n        self.default_button.clicked.connect(self.default_renderer)\n        \n        if copy_button is None:\n            self.copy_button = QtWidgets.QPushButton()\n            self.copy_button.setText(\"Copy Figure\")\n        else:\n            self.copy_button = copy_button\n        self.copy_button.clicked.connect(self.CopyActivated)\n        self.clipboard = QtWidgets.QApplication.clipboard()\n\n        self.setLayout(QtWidgets.QVBoxLayout())\n        self.layout().addWidget(self.figure_widget, stretch=1)\n        self.layout().setContentsMargins(0,0,0,0)\n        \n        self.renderers = list()\n        \n        if show_controls: # this part may be broken\n            hb = QtWidgets.QHBoxLayout()\n            hb.addWidget(self.renderer_combobox, stretch=1)\n            if show_refresh:\n                hb.addWidget(self.refresh_button, stretch=0)\n            if show_copy:\n                hb.addWidget(self.copy_button, stretch=0)\n            if show_default_button:\n                hb.addWidget(self.default_button, stretch=0)\n            self.layout().addLayout(hb, stretch=0)",
  "def data(self):\n        \"\"\"The dataset or group we are displaying\"\"\"\n        return self._data",
  "def data(self, newdata):\n        if newdata is None:\n            return None\n        \n        self._data = newdata\n\n        # When data changes, update the list of renderers\n        \n        renderers = suitable_renderers(self.data)\n        combobox = self.renderer_combobox\n        previous_selection = combobox.currentIndex() # remember previous choice\n        try:#Attempt to keep the same range\n            previous_view_rect = self.figure_widget.figureWidget.viewRect()\n        except AttributeError:\n            previous_view_rect = None\n            \n        combobox.clear()\n        for i, renderer in enumerate(renderers):\n            combobox.addItem(renderer.__name__, renderer)\n            \n        # Attempt to keep the same renderer as we had before - or use the \n        # \"best\" one.  NB setting the current index will trigger the renderer\n        # to be created in renderer_selected\n        try:\n            if previous_selection == 0:\n                raise ValueError() # if we didn't choose the last renderer, just\n                            # pick the best one.  Otherwise, try to use the same\n                            # renderer as we used before\n            else:\n                index = renderers.index(self.renderer.__class__)\n                combobox.setCurrentIndex(index)\n                try:\n                    self.renderer_selected(index)\n                except Exception as e:\n                    print('The selected renderer failed becasue',e)\n\n        except ValueError:\n            combobox.setCurrentIndex(0)\n            self.renderer_selected(0)\n        if previous_view_rect != None:\n            try:\n                self.figure_widget.figureWidget.setRange(previous_view_rect, padding=0)                                      \n            except AttributeError:\n                pass",
  "def default_renderer(self):\n        self.renderer_combobox.setCurrentIndex(0)\n        self.renderer_selected(0)\n        self.refresh()",
  "def renderer(self):\n        \"\"\"The data renderer currently in use in the widget\"\"\"\n        return self._renderer",
  "def renderer(self, new_renderer):\n        self._renderer = new_renderer\n        # Replace the current renderer in the GUI with the new one:\n        self.figure_widget = self.replace_widget(self.layout(), self.figure_widget, new_renderer)",
  "def renderer_selected(self, index):\n        \"\"\"Change the figure widget to use the selected renderer.\"\"\"\n        # The class of the renderer is stored as the combobox data\n        RendererClass = self.renderer_combobox.itemData(index)\n        try:\n            self.renderer = RendererClass(self.data, self)\n        except TypeError:\n            # If the box is empty (e.g. it's just been cleared) use a blank widget\n            self.renderer = QtWidgets.QWidget()",
  "def refresh(self):\n        \"\"\"Re-render the data, using the current renderer (if it is still appropriate)\"\"\"\n        self.data = self.data",
  "def CopyActivated(self):\n        \"\"\"Copy an image of the currently-displayed figure.\"\"\"\n        ## TO DO: move this to the HDF5 viewer\n        print('yes')",
  "def __init__(self, data_file, parent, name, row):\n        \"\"\"Create a new item for an HDF5 tree\n\n        data_file : HDF5 data file\n            This is the file (NB must be the top-level group) containing everything\n        parent : HDF5TreeItem\n            The parent of the current item\n        name : string\n            The name of the current item (should be parent.name plus an extra component)\n        row : int\n            The index of the current item in the parent's children.\n        \"\"\"\n        self.data_file = data_file\n        self.parent = parent\n        self.name = name\n        self.row = row\n        if parent is not None:\n            assert name.startswith(parent.name)\n            assert name in data_file",
  "def basename(self):\n        \"\"\"The last component of the item's path in the HDF5 file\"\"\"\n        return self.name.rsplit('/')[-1]",
  "def has_children(self):\n        \"\"\"Whether or not this item has children\"\"\"\n        if self._has_children is None:\n            #print(self.name)\n            self._has_children = hasattr(self.data_file[self.name], \"keys\")\n        return self._has_children",
  "def children(self):\n        \"\"\"Children of the current item (as HDF5TreeItems)\"\"\"\n        if self.has_children is False:\n            return []\n        if self._children is None:\n            keys = list(self.data_file[self.name].keys())\n            try:\n                time_stamps = []\n                for value in self.data_file[self.name].values():\n                   \n                    try:\n                        time_stamp_str = value.attrs['creation_timestamp']\n                    except AttributeError:\n                        print(value)\n                        print('has no creation_timestamp attribute.')\n                        time_stamp_str = '2021-01-01T01:01:01.000001'\n                    #if type(time_stamp_str) is bytes:\n                    if isinstance(time_stamp_str, bytes):\n                        time_stamp_str = time_stamp_str.decode() #b'somestring'.decode('UTF-8')\n                    #print(time_stamp_str)\n                    try:\n                        time_stamp_float = datetime.datetime.strptime(time_stamp_str, \"%Y-%m-%dT%H:%M:%S.%f\")\n                    except ValueError:\n                        time_stamp_str =  time_stamp_str+'.0'\n                        time_stamp_float = datetime.datetime.strptime(time_stamp_str,\"%Y-%m-%dT%H:%M:%S.%f\")\n                    time_stamps.append(time_stamp_float)\n                keys = np.array(keys)[np.argsort(time_stamps)]\n            except KeyError:\n                keys.sort(key=split_number_from_name)\n            \n            self._children = [HDF5TreeItem(self.data_file, self, self.name.rstrip(\"/\") + \"/\" + k, i)\n                              for i, k in enumerate(keys)]\n        return self._children",
  "def purge_children(self):\n        \"\"\"Empty the cached list of children\"\"\"\n        try:\n            if self._children is not None:\n                for child in self._children:\n                    child.purge_children() # We must delete them all the way down!\n                    self._children.remove(child)\n                    del child # Not sure if this is needed...\n                self._children = None\n            self._has_children = None\n        except:\n            print(\"{} failed to purge its children\".format(self.name))",
  "def h5item(self):\n        \"\"\"The underlying HDF5 item for this tree item.\"\"\"\n        assert self.name in self.data_file, \"Error, {} is no longer a valid HDF5 item\".format(self.name)\n        return self.data_file[self.name]",
  "def __del__(self):\n        self.purge_children()",
  "def __init__(self, data_group):\n        \"\"\"Represent an HDF5 group to a QTreeView or similar.\n        :type data_group: nplab.datafile.Group\n        \"\"\"\n        super(HDF5ItemModel, self).__init__()\n        self.root_item = None\n        self.data_group = data_group",
  "def data_group(self):\n        \"\"\"The HDF5 group object we're representing\"\"\"\n        return self._data_group",
  "def data_group(self, new_data_group):\n        \"\"\"Set the data group represented by the model\"\"\"\n        if self.root_item is not None:\n            del self.root_item\n        self._data_group = new_data_group\n        self.root_item = HDF5TreeItem(new_data_group.file, None, new_data_group.name, 0)",
  "def _index_to_item(self, index):\n        \"\"\"Return an HDF5TreeItem for a given index\"\"\"\n        if index.isValid():\n            return index.internalPointer()\n        else:\n            return self.root_item",
  "def index(self, row, column, parent_index):\n        \"\"\"Return the index of the <row>th child of parent\n\n        :type row: int\n        :type column: int\n        :type parent: QtCore.QModelIndex\n        \"\"\"\n        try:\n            parent = self._index_to_item(parent_index)\n            return self.createIndex(row, column, parent.children[row])\n        except:\n            return QtCore.QModelIndex()",
  "def parent(self, index=None):\n        \"\"\"Find the index of the parent of the item at a given index.\"\"\"\n        try:\n            parent = self._index_to_item(index).parent\n            return self.createIndex(parent.row, 0, parent)\n        except:\n            # Something went wrong with finding the parent so return an invalid index\n            return QtCore.QModelIndex()",
  "def flags(self, index):\n        \"\"\"Return flags telling Qt what to do with the item\"\"\"\n        return QtCore.Qt.ItemIsSelectable | QtCore.Qt.ItemIsEnabled",
  "def data(self, index, role):\n        \"\"\"The data represented by this item.\"\"\"\n        if role == QtCore.Qt.DisplayRole:\n            return self._index_to_item(index).basename\n        else:\n            return None",
  "def headerData(self, section, orientation, role=None):\n        \"\"\"Return the header names - an empty string here!\"\"\"\n        return [\"\"]",
  "def rowCount(self, index):\n        \"\"\"The number of rows exposed by the model\"\"\"\n        try:\n            item = self._index_to_item(index)\n            assert item.has_children\n            return len(item.children)\n        except:\n            # if it doesn't have keys, assume there are no children.\n            return 0",
  "def hasChildren(self, index):\n        \"\"\"Whether or not this object has children\"\"\"\n        return self._index_to_item(index).has_children",
  "def columnCount(self, index=None, *args, **kwargs):\n        \"\"\"Return the number of columns\"\"\"\n        return 1",
  "def refresh_tree(self):\n        \"\"\"Reload the HDF5 tree, resetting the model\n\n        This causes all cached HDF5 tree information to be deleted, and any views\n        using this model will automatically reload.\n        \"\"\"\n        self.beginResetModel()\n        self.root_item.purge_children()\n        self.endResetModel()",
  "def selected_h5item_from_view(self, treeview):\n        \"\"\"Given a treeview object, return the selection, as an HDF5 object, or a work-alike for multiple selection.\n\n        If one item is selected, we will return the HDF5 group or dataset that is selected.  If multiple items are\n        selected, we will return a dummy HDF5 group containing all selected items.\n        \"\"\"\n        items = [self._index_to_item(index) for index in treeview.selectedIndexes()]\n        if len(items) == 1:\n            return items[0].h5item\n        elif len(items) > 1:\n            return DummyHDF5Group({item.name: item.h5item for item in items})\n        else:\n            return None",
  "def set_up_treeview(self, treeview):\n        \"\"\"Correctly configure a QTreeView to use this model.\n\n        This will set the HDF5ItemModel as the tree's model (data source), and in the future\n        may set up context menus, etc. as appropriate.\"\"\"\n        treeview.setModel(self) # Make the tree view use this object as its model\n        # Set up a callback to allow us to customise the context menu\n        treeview.setContextMenuPolicy(QtCore.Qt.CustomContextMenu)\n        treeview.customContextMenuRequested.connect(functools.partial(self.context_menu, treeview))\n        # Allow multiple objects to be selected\n        treeview.setSelectionMode(QtWidgets.QAbstractItemView.ExtendedSelection)",
  "def context_menu(self, treeview, position):\n        \"\"\"Generate a right-click menu for the items\"\"\"\n        menu = QtWidgets.QMenu()\n        actions = {}\n\n        for operation in ['Refresh tree']:\n            actions[operation] = menu.addAction(operation)\n        action = menu.exec_(treeview.viewport().mapToGlobal(position))\n\n\n        if action == actions['Refresh tree']:\n            self.refresh_tree()",
  "def __init__(self, datafile, **kwargs):\n        \"\"\"Create a TreeView widget that views the contents of an HDF5 tree.\n\n        Arguments:\n            datafile : nplab.datafile.Group\n            the HDF5 tree to show\n\n        Additional keyword arguments are passed to the QTreeView constructor.\n        You may want to include parent, for example.\"\"\"\n        QtWidgets.QTreeView.__init__(self, **kwargs)\n\n        self.model = HDF5ItemModel(datafile)\n        self.model.set_up_treeview(self)\n        self.sizePolicy().setHorizontalStretch(0)",
  "def selected_h5item(self):\n        \"\"\"Return the current selection as an HDF5 item.\"\"\"\n        return self.model.selected_h5item_from_view(self)",
  "def __del__(self):\n        del self.model",
  "def __init__(self, data_file, parent=None):\n        super(HDF5Browser, self).__init__(parent)\n        self.data_file = df.DataFile(data_file)\n        self.treeWidget = HDF5TreeWidget(data_file,\n                                         parent=self)\n        self.selection_model = self.treeWidget.selectionModel() \n        self.selection_model.selectionChanged.connect(self.selection_changed)\n        self.viewer = HDF5ItemViewer(parent=self, \n                                     show_controls=True,\n                                     )\n        self.refresh_tree_button = QtWidgets.QPushButton() #Create a refresh button\n        self.refresh_tree_button.setText(\"Refresh Tree\")\n        \n        #adding the refresh button\n        self.treelayoutwidget = QtWidgets.QWidget()     #construct a widget which can then contain the refresh button and the tree\n        self.treelayoutwidget.setLayout(QtWidgets.QVBoxLayout())\n        self.treelayoutwidget.layout().addWidget(self.treeWidget)\n        self.treelayoutwidget.layout().addWidget(self.refresh_tree_button) \n        \n        self.refresh_tree_button.clicked.connect(self.treeWidget.model.refresh_tree)\n\n        splitter = QtWidgets.QSplitter()\n        splitter.addWidget(self.treelayoutwidget)       #Add newly constructed widget (treeview and button) to the splitter\n        splitter.addWidget(self.viewer)\n        self.setLayout(QtWidgets.QHBoxLayout())\n        self.layout().addWidget(splitter)",
  "def sizeHint(self):\n        return QtCore.QSize(1024,768)",
  "def selection_changed(self, selected, deselected):\n        \"\"\"Callback function to update the displayed item when the tree selection changes.\"\"\"\n        try:\n            self.viewer.data = self.treeWidget.selected_h5item()\n            print(self.viewer.data)\n            if self.data_file.update_current_group:\n                df.set_current_group(self.treeWidget.selected_h5item())\n\n        except Exception as e:\n            \n            print(e, 'That could be corrupted')",
  "def __del__(self):\n        pass",
  "def is_pyqt5():\n        return (QT_API[:5] == 'PyQt5')",
  "def is_pyqt5():\n    return QtCore.qVersion().startswith('5')",
  "class DataRenderer(object):\n    def __init__(self, h5object, parent=None):\n    #    assert self.is_suitable(h5object) >= 0, \"Can't render that object: {0}\".format(h5object)\n        super(DataRenderer, self).__init__()\n        self.parent = parent\n        self.h5object = h5object\n\n    @classmethod\n    def is_suitable(cls, h5object):\n        \"\"\"Return a score of how well suited this renderer is to the object.\n        \n        This should be a quick function, as it's called often (every renderer\n        gives a score each time we look for a suitable renderer).  Return a\n        number < 0 if you can't render the data.\n        \"\"\"\n        return -1",
  "def add_renderer(renderer_class):\n    \"\"\"Add a renderer to the list of available renderers\"\"\"\n    renderers.add(renderer_class)",
  "def add_group_renderer(renderer_class):\n    \"\"\"Add a renderer to the list of available renderers\"\"\"\n    group_renders.add(renderer_class)",
  "def suitable_renderers(h5object, return_scores=False):\n    \"\"\"Find renderers that can render a given object, in order of suitability.\n    If the selected group contains more than 100 elements, consider only the\n    group_renderers and not the rest, which are very time consuming.\n    \"\"\"\n    renderers_and_scores = []\n    if isinstance(h5object, h5py.Group) and len(list(h5object.values()))>100:\n        for r in group_renders:\n            try:\n                renderers_and_scores.append((r.is_suitable(h5object), r))\n            except:\n      #          print \"renderer {0} failed when checking suitability for {1}\".format(r, h5object)\n                pass # renderers that cause exceptions shouldn't be used!\n\n    else:    \n        for r in renderers:\n            try:\n                renderers_and_scores.append((r.is_suitable(h5object), r))\n            except Exception as e:\n                print(\"renderer {0} failed when checking suitability for {1} due to error: {2}\".format(r, h5object,e))\n                pass # renderers that cause exceptions shouldn't be used!\n        \n    renderers_and_scores.sort(key=lambda score_r: score_r[0], reverse=True)\n    if return_scores:\n        return [(score, r) for score, r in renderers_and_scores if score >= 0]\n    else:\n        return [r for score, r in renderers_and_scores if score >= 0]",
  "class HDF5InfoRenderer(DataRenderer, QtWidgets.QWidget):\n    \"\"\" A renderer returning the basic HDF5 info\"\"\"\n    def __init__(self, h5object, parent=None):\n        super(HDF5InfoRenderer, self).__init__(h5object, parent)\n        uic.loadUi(os.path.join(os.path.dirname(__file__), 'hdf5_info_renderer.ui'),self)\n        self.parent = parent\n        self.h5object = h5object\n\n\n        self.lineEdit.setText(self.h5object.name)\n        self.lineEdit2.setText(self.h5object.parent.name)\n        self.lineEdit3.setText(self.h5object.file.filename)\n        \n\n    @classmethod\n    def is_suitable(cls, h5object):\n        # Retrieve the things we're going to display to check that they exist (if an exception occurs, the renderer\n        # will be deemed unsuitable)\n        name = h5object.name\n        parentname = h5object.parent.name\n        filename = h5object.file.filename\n        return 2",
  "class ValueRenderer(DataRenderer, QtWidgets.QWidget):\n    \"\"\"A renderer returning the objects name type and shape if a dataset object\"\"\"\n    def __init__(self, h5object, parent=None):\n        super(ValueRenderer, self).__init__(h5object, parent)\n        \n        #our layout is simple - just a single QLabel\n        self.label = QtWidgets.QLabel()\n        layout = QtWidgets.QVBoxLayout(self)\n        layout.addWidget(self.label)\n        self.setLayout(layout)\n        \n        self.label.setText(self.text(h5object))\n        \n    def text(self, h5object):\n        \"\"\"Return the text that is displayed in the label\"\"\"\n        v = h5object[()]\n        if type(v) is bytes:\n            return v.decode()\n        return str(v)\n\n    @classmethod\n    def is_suitable(cls, h5object):\n        try:\n            if getattr(h5object, 'is_note', False):\n                return 11\n            if len(h5object.shape)==0:\n                return 10\n            else:\n                return -1\n        except:\n            return -1",
  "class TextRenderer(DataRenderer, QtWidgets.QWidget):\n    \"\"\"A renderer returning the objects name type and shape if a dataset object\"\"\"\n    def __init__(self, h5object, parent=None):\n        super(TextRenderer, self).__init__(h5object, parent)\n        \n        #our layout is simple - just a single QLineEdit\n        self.label = QtWidgets.QLineEdit()\n        layout = QtWidgets.QFormLayout(self)\n        layout.addWidget(self.label)\n        self.setLayout(layout)\n        self.label.setText(self.text(h5object))\n        \n    def text(self, h5object):\n        \"\"\"Return the text that is displayed in the label\"\"\"\n        return str(h5object)\n\n    @classmethod\n    def is_suitable(cls, h5object):\n        return 1",
  "class AttrsRenderer(DataRenderer, QtWidgets.QWidget):\n    \"\"\" A renderer displaying a table with the Attributes of the HDF5 object selected\"\"\"\n    \n    def __init__(self, h5object, parent=None):\n        super(AttrsRenderer, self).__init__(h5object)\n        uic.loadUi(os.path.join(os.path.join(os.path.dirname(__file__), 'hdf5_attrs_renderer.ui')),self)\n        \n        self.h5object = h5object\n        \n        if type(h5object)==list:\n            item_info = QtWidgets.QTableWidgetItem(\"Choose a single element to display its attributes!\")\n            self.tableWidget.setItem(0,0,item_info)\n            self.tableWidget.resizeColumnsToContents()\n        else:\n            self.tableWidget.setRowCount(len(self.h5object.attrs))\n            row = 0\n            for key, value in sorted(h5object.attrs.items()):\n                item_key = QtWidgets.QTableWidgetItem(key)\n                item_value = QtWidgets.QTableWidgetItem(str(value))\n                self.tableWidget.setItem(row,0,item_key)\n                self.tableWidget.setItem(row,1,item_value)\n                row = row + 1\n            self.tableWidget.resizeColumnsToContents()\n        \n        \n# PREVIOUS ATTRIBUTES RENDERER\n#class AttrsRenderer(TextRenderer):\n#    \"\"\" A renderer displaying the Attributes of the HDF5 object selected\"\"\"\n#    def text(self, h5object):\n#        text = \"Attributes:\\n\"\n#        for key, value in h5object.attrs.iteritems():\n#            text += \"{0}: {1}\\n\".format(key, str(value))\n#        return text\n        \n    @classmethod\n    def is_suitable(cls, h5object):\n        if isinstance(h5object,h5py.Group):\n            if len(list(h5object.keys())) > 10:\n                return 5000\n        return 1",
  "class FigureRenderer(DataRenderer, QtWidgets.QWidget):\n    \"\"\"A renderer class which sets up a matplotlib figure for use \n    in more complicated renderers\n    \"\"\"\n    def __init__(self, h5object, parent=None):\n        super(FigureRenderer, self).__init__(h5object, parent)\n        self.fig = Figure()\n\n        layout = QtWidgets.QVBoxLayout(self)\n        self.figureWidget = FigureCanvas(self.fig)\n        layout.addWidget(self.figureWidget)\n        self.setLayout(layout)\n\n        self.display_data()\n\n    def display_data(self):\n        self.fig.canvas.draw()",
  "class FigureRendererPG(DataRenderer, QtWidgets.QWidget):\n    \"\"\"A renderer class which sets up a pyqtgraph for use \n    in more complicated renderers\n    \"\"\"\n    def __init__(self, h5object, parent=None):\n        super(FigureRendererPG, self).__init__(h5object, parent)\n        pg.setConfigOption('background', 'w')\n        pg.setConfigOption('foreground', 'k')\n        self.figureWidget =  pg.PlotWidget(name='Plot1') \n        self.layout = QtWidgets.QVBoxLayout(self)\n        self.layout.addWidget(self.figureWidget)\n        self.setLayout(self.layout)\n\n        self.display_data()\n\n    def display_data(self):\n        self.fig.canvas.draw()",
  "class DataRenderer1DPG(FigureRendererPG):\n    \"\"\" A renderer for 1D datasets experessing them in a line graph using\n    pyqt graph. Allowing the user to interact with the graph i.e. zooming into \n    selected region or performing transformations of the axis\n    \"\"\"\n    def display_data(self):\n        if not hasattr(self.h5object, \"values\"):\n            # If we have only one item, treat it as a group containing that item.\n            self.h5object = {self.h5object.name: self.h5object}\n        icolour = 0    \n        self.figureWidget.addLegend(offset = (-1,1))\n        for h5object in list(self.h5object.values()):\n            try:\n                if np.shape(h5object)[0] == 2 or np.shape(h5object)[1] == 2:\n                    Xdata = np.array(h5object)[0]\n                    Ydata = np.array(h5object)[1]\n                else:\n                    Ydata = np.array(h5object)\n                    Xdata = np.arange(len(Ydata))\n            except IndexError:\n                Ydata = np.array(h5object)\n                Xdata = np.arange(len(Ydata))\n            self.figureWidget.plot(x = Xdata, y = Ydata,name = h5object.name, pen =(icolour,len(self.h5object)))\n            icolour = icolour + 1\n            \n        labelStyle = {'font-size': '24pt'}\n        try:\n            self.figureWidget.setLabel('bottom', h5object.attrs['X label'], **labelStyle)\n        except:\n            self.figureWidget.setLabel('bottom', 'An X axis', **labelStyle)\n            \n        try:\n            self.figureWidget.setLabel('left', h5object.attrs['Y label'], **labelStyle)\n        except:\n            self.figureWidget.setLabel('left', 'An Y axis', **labelStyle)\n\n    @classmethod\n    def is_suitable(cls, h5object):\n        if not hasattr(h5object, \"values\"):\n            # If we have only one item, treat it as a group containing that item.\n            h5object = {h5object.name: h5object}\n        try:\n            if not len(list(h5object.values())):\n                return -1\n            for dataset in list(h5object.values()):\n                # Check that all datasets selected are either 1D or Nx2 or 2xN\n                if not (dataset.shape and isinstance(dataset, h5py.Dataset)):\n                    return -1#we can only render datasets\n                try:\n                    assert len(dataset.shape) == 1\n                except:\n                    assert len(dataset.shape) == 2\n                    assert np.any(np.array(dataset.shape) == 2)\n        except:\n            return -1\n        return 14",
  "class Scatter_plot1DPG(FigureRendererPG):\n    \"\"\" A renderer for 1D datasets experessing them in a scatter graph using\n    pyqt graph. Allowing the user to interact with the graph i.e. zooming into \n    selected region or performing transformations of the axis\n    \"\"\"\n\n    def display_data(self):\n        if not hasattr(self.h5object, \"values\"):\n            # If we have only one item, treat it as a group containing that item.\n            self.h5object = {self.h5object.name: self.h5object}\n        icolour = 0    \n        self.figureWidget.addLegend(offset = (-1,1))\n        for h5object in list(self.h5object.values()): \n            try: \n                if np.shape(h5object)[0] == 2 or np.shape(h5object)[1] == 2:\n                    Xdata = np.array(h5object)[0]\n                    Ydata = np.array(h5object)[1]\n                else:\n                    Ydata = np.array(h5object)\n                    Xdata = np.arange(len(Ydata))\n            except IndexError:\n                Ydata = np.array(h5object)\n                Xdata = np.arange(len(Ydata))\n            self.figureWidget.plot(x = Xdata, y = Ydata,name = h5object.name, pen =None, symbol ='o',symbolPen = (icolour,len(self.h5object)),symbolBrush = (icolour,len(self.h5object)))\n            icolour = icolour + 1\n            \n        labelStyle = {'font-size': '24pt'}\n        try:\n            self.figureWidget.setLabel('bottom', h5object.attrs['X label'], **labelStyle)\n        except:\n            self.figureWidget.setLabel('bottom', 'An X axis', **labelStyle)\n            \n        try:\n            self.figureWidget.setLabel('left', h5object.attrs['Y label'], **labelStyle)\n        except:\n            self.figureWidget.setLabel('left', 'An Y axis', **labelStyle)\n          \n    @classmethod\n    def is_suitable(cls, h5object):\n        return DataRenderer1DPG.is_suitable(h5object) - 2",
  "class MultiSpectrum2D(DataRenderer, QtWidgets.QWidget):\n    \"\"\" A renderer for large spectral datasets experessing them in a colour map using\n    pyqt graph. Allowing the user to interact with the graph i.e. zooming into \n    selected region and changing the colour scheme through the use of a histogramLUT \n    widget on the right of the image.\n    \n    If a background and/or reference are within the attributes for the datafile \n    they will also be applied. If this is the case it will be expressed in the \n    title of the colourmap.\n    \n    This renderer is also avaible for users attempting to look at multiple spectra \n    in seperate datasets at the same time through selection while pressing\n    control/shift as used in most windows apps.\n    \n    It should be noted when using this renderer that all infs and NaNs will be shown as 0!!!\n    \"\"\"\n    def __init__(self, h5object, parent=None):\n        super(MultiSpectrum2D, self).__init__(h5object, parent)\n        pg.setConfigOption('background', 'w')\n        pg.setConfigOption('foreground', 'k')\n        self.layout = QtWidgets.QGridLayout()\n        self.setLayout(self.layout)\n        self.layout.setSpacing(0)\n\n        self.display_data()\n\n    def display_data(self):\n        v = pg.GraphicsView()\n        vb = pg.PlotItem()\n        v.setCentralItem(vb)\n        self.layout.addWidget(v, 0, 0)\n    \n        w = pg.HistogramLUTWidget()\n        self.layout.addWidget(w, 0, 1)\n        \n        if isinstance(self.h5object,dict) or isinstance(self.h5object,h5py.Group):\n#            for i in range(len(self.h5object.values())):\n#                if i == 0:    \n#                    data = np.array(self.h5object.values()[i])\n#                else:\n#                    data = np.append(data,np.array(self.h5object.values()[i]),axis = 0)\n #           sorted_values = \n            data = np.array(list(self.h5object.values()))\n            dict_of_times = {}\n            for h5object in list(self.h5object.values()):\n                dict_of_times[h5object.attrs['creation_timestamp']]=h5object\n            data = np.array(list(dict_of_times.values()))\n            for i,h5object_time in enumerate(sorted(dict_of_times.keys())):\n                if i == 0:    \n                    data = np.array([dict_of_times[h5object_time]])\n                else:\n                    data = np.append(data,np.array([dict_of_times[h5object_time]]),axis = 0)\n\n                \n            ListData = True\n            print(np.shape(data),np.shape(list(self.h5object.values())))\n        elif len(self.h5object.shape) == 1 and len(self.h5object.attrs['wavelengths'])<len(self.h5object) and len(self.h5object)%len(self.h5object.attrs['wavelengths']) == 0:\n            RawData = np.array(self.h5object,dtype = float)\n            Xlen = len(np.array(self.h5object.attrs['wavelengths']))\n            Ylen = len(RawData)//Xlen\n            data = [RawData.reshape((Ylen,Xlen))]\n            self.h5object = {self.h5object.name : self.h5object}\n            ListData = False\n            \n        else:\n            data = [np.array(self.h5object)]\n            self.h5object = {self.h5object.name : self.h5object}\n            ListData = False\n\n        background_counter = 0\n        reference_counter = 0\n        i = 0\n        j = 0\n        for h5object in data:\n            Title = \"A\"\n            variable_int = False\n\n            if 'variable_int_enabled' in list(list(self.h5object.values())[i].attrs.keys()):\n                variable_int = list(self.h5object.values())[i].attrs['variable_int_enabled']\n            if ((variable_int == True) and #Check for variable integration time and that the background_int and reference_int are not none\n                        ((list(self.h5object.values())[i].attrs['background_int'] != list(self.h5object.values())[i].attrs['integration_time'] \n                            and (list(self.h5object.values())[i].attrs['background_int'] != None))\n                        or (list(self.h5object.values())[i].attrs['reference_int'] != list(self.h5object.values())[i].attrs['integration_time'] \n                            and (list(self.h5object.values())[i].attrs['reference_int'] != None)))):\n                if list(self.h5object.values())[i].attrs['background_int'] != None:\n                    if list(self.h5object.values())[i].attrs['reference_int'] != None:\n                        data[i] = (((data[i]-(list(self.h5object.values())[i].attrs['background_constant']+list(self.h5object.values())[i].attrs['background_gradient']*list(self.h5object.values())[i].attrs['integration_time']))/\n                                        (((list(self.h5object.values())[i].attrs['reference']-(list(self.h5object.values())[i].attrs['background_constant']+list(self.h5object.values())[i].attrs['background_gradient']*list(self.h5object.values())[i].attrs['reference_int']))\n                                        *list(self.h5object.values())[i].attrs['integration_time']/list(self.h5object.values())[i].attrs['reference_int']))))\n                    else:\n                        data[i] = data[i]-(list(self.h5object.values())[i].attrs['background_constant']+list(self.h5object.values())[i].attrs['background_gradient']*list(self.h5object.values())[i].attrs['integration_time'])\n                        reference_counter = reference_counter +1\n                \n            else:\n                if 'background' in list(list(self.h5object.values())[i].attrs.keys()):\n                    if ListData == True:\n                        if len(np.array(data[i])) == len(np.array(list(self.h5object.values())[i].attrs['reference'])):\n                            data[i] = data[i] - np.array(list(self.h5object.values())[i].attrs['background'])     \n                    else:\n                        if len(np.array(data)) == len(np.array(list(self.h5object.values())[i].attrs['background'])):\n                                data = data - np.array(list(self.h5object.values())[i].attrs['background'])[:,np.newaxis]       \n                        Title = Title + \" background subtracted\"\n                else:\n                    background_counter = background_counter+1\n                if 'reference' in list(list(self.h5object.values())[i].attrs.keys()):\n                    if ListData == True:\n                        if len(np.array(data[i])) == len(np.array(list(self.h5object.values())[i].attrs['reference'])):\n                            data[i] = (data[i]/(np.array(list(self.h5object.values())[i].attrs['reference'])- np.array(list(self.h5object.values())[i].attrs['background'])))   \n                    else:\n                        if len(np.array(data)) == len(np.array(list(self.h5object.values())[i].attrs['reference'])):\n                            data = (data/(np.array(list(self.h5object.values())[i].attrs['reference'])[:,np.newaxis]- np.array(list(self.h5object.values())[i].attrs['background'])[:,np.newaxis]))\n                    Title = Title + \" referenced\"\n                else:\n                    reference_counter = reference_counter +1\n   #         print i,j,np.max(data) ,self.h5object.values()[i].attrs.keys()\n            if len(list(self.h5object.values())) != len(data):\n                i = int((float(len(list(self.h5object.values())))/len(data))*j)\n                j=j+1\n            else:\n                i = i +1\n            \n        if ListData == False:\n            data = data[0]            \n        data = np.transpose(data)\n        \n            \n        if reference_counter == 0 and background_counter == 0:\n            print(\"All spectrum are referenced and background subtracted\")\n        else:\n            print(\"Number of spectrum not referenced \"+str(reference_counter))\n            print(\"Number of spectrum not background subtracted \"+str(background_counter))\n        Title = Title + \" spectrum\"\n         \n        data[np.where(np.isnan(data))] = 0\n        data[np.where(np.isinf(data))] = 0\n\n\n\n      #  plot.plot(x = np.array(self.h5object.attrs['wavelengths']), y = np.array(h5object),name = h5object.name)\n        labelStyle = {'font-size': '24pt'}\n        vb.setLabel('left', 'Spectrum number',**labelStyle)\n        vb.setLabel('bottom', 'Wavelength (nm)',**labelStyle)\n\n        vb.setTitle(Title,**labelStyle)\n        \n\n        img = pg.ImageItem(data)\n\n        ConvertionC= list(self.h5object.values())[0].attrs['wavelengths'][0]\n        ConvertionM = ((list(self.h5object.values())[0].attrs['wavelengths'][-1] - list(self.h5object.values())[0].attrs['wavelengths'][0])/len(list(self.h5object.values())[0].attrs['wavelengths']))\n\n\n\n        img.translate(ConvertionC,0)\n        img.scale(ConvertionM,1)\n        vb.addItem(img)\n        vb.autoRange(False)\n\n\n        w.setImageItem(img)\n\n\n   \n    @classmethod\n    def is_suitable(cls, h5object):\n        suitability = 0\n        if isinstance(h5object,dict) == False and isinstance(h5object,h5py.Group) == False:\n            try:\n                if len(h5object.shape) == 1 and (len(h5object)/len(h5object.attrs['wavelengths'])) == 1:\n                    return -1\n            except:\n                return -1\n            h5object = {h5object.name : h5object}\n        \n        for dataset in list(h5object.values()):\n            if not isinstance(dataset, h5py.Dataset):\n                return -1\n            if len(dataset.shape) == 1:\n                suitability = suitability + 10\n                    \n            if len(dataset.shape) > 2:\n                return -1\n      \n            if 'wavelengths' in list(dataset.attrs.keys()):\n                if len(dataset.shape) == 2:\n                    if len(np.array(dataset)[:,0]) < 100:\n                        suitability = suitability + len(h5object)-20\n                    else:\n                        return 1\n                elif ((len(np.array(dataset))/len(dataset.attrs['wavelengths'])))>1 and (len(np.array(dataset))%len(dataset.attrs['wavelengths'])) == 0 :           \n                    suitability = suitability + 50\n                elif len(dataset.attrs['wavelengths']) != len(np.array(dataset)):\n                    print(\"the number of bins does not equal the number of wavelengths!\")\n                    return -1\n                suitability = suitability + 11\n            else:\n                return -1\n             \n            if 'background' in list(dataset.attrs.keys()):\n                suitability = suitability + 10\n            if 'reference' in list(dataset.attrs.keys()):\n                suitability = suitability + 10\n             \n        return suitability",
  "class DataRenderer2or3DPG(DataRenderer, QtWidgets.QWidget):\n    \"\"\" A renderer for 2D datasets images experessing them in a colour map using\n    pyqt graph. Allowing the user to interact with the graph i.e. zooming into \n    selected region and changing the colour scheme through the use of a histogramLUT \n    widget on the right of the image while also allowing the user to scroll through the\n    frames that make the image 3-d dimensional.\n    \"\"\"\n    def __init__(self, h5object, parent=None):\n        super(DataRenderer2or3DPG, self).__init__(h5object, parent)\n        pg.setConfigOption('background', 'w')\n        pg.setConfigOption('foreground', 'k')\n        self.layout = QtWidgets.QVBoxLayout()\n        self.setLayout(self.layout)\n        \n\n        self.display_data()\n\n    def display_data(self, data=None, lock_aspect=False):\n        if data is None:\n            data = np.array(self.h5object)\n        data[np.where(np.isnan(data))] = 0 \n        img = pg.ImageView()\n        if len(data.shape)==3 and data.shape[2]==3:\n            data = np.transpose(data,axes = (1,0,2))\n        elif len(data.shape)==2:\n            data = np.transpose(data)\n            \n        img.setImage(data)\n        #img.setMinimumSize(950,750) #This seems unhelpful to me - RWB\n        img.view.setAspectLocked(lock_aspect)\n        self.layout.addWidget(img)\n        self.setLayout(self.layout)\n\n   \n    @classmethod\n    def is_suitable(cls, h5object):\n        if not isinstance(h5object, h5py.Dataset):\n            return -1\n        elif len(h5object.shape) == 3:\n            return 31\n        elif len(h5object.shape) == 4 and h5object.shape[3] == 3:\n            return 31\n        elif len(h5object.shape) == 2:\n            return 21\n        elif len(h5object.shape) > 3:\n            return -1\n        else:\n            return -1",
  "class JPEGRenderer(DataRenderer2or3DPG):\n    \"\"\"Renders a 1D array holding JPEG data as a 2D image.\"\"\"\n    def __init__(self, h5object, parent=None):\n        super(JPEGRenderer, self).__init__(h5object, parent)\n\n    def display_data(self):\n        import cv2\n        data = cv2.imdecode(np.array(self.h5object), cv2.CV_LOAD_IMAGE_UNCHANGED)\n        DataRenderer2or3DPG.display_data(self, data=data.transpose((1,0,2)), lock_aspect=True)\n\n    @classmethod\n    def is_suitable(cls, h5object):\n        if h5object.attrs.get('compressed_image_format', None) in ['JPEG', 'PNG', ]:\n            return 50\n        if len(getattr(h5object, 'shape', [])) == 1: \n            # Detect the JPEG header directly.  NB this is a work in progress, I don't think it works currently.\n            if all(np.array(h5object[:4]) == np.array([255,216,255,224],dtype=np.uint8)):\n                return 50\n        return -1",
  "class DataRenderer1D(FigureRenderer):\n    \"\"\" A renderer for 1D datasets experessing them in a line graph using\n    matplotlib. Although this does not allow the user to interact with the\n    figure it is often found to be more stable.\n    \"\"\"\n    def display_data(self):\n        matplotlib.rc('xtick', labelsize=24) \n        matplotlib.rc('ytick', labelsize=24) \n        ax = self.fig.add_subplot(111)\n        ax.plot(self.h5object)\n        ax.set_aspect(\"auto\")\n        ax.relim()\n        ax.autoscale_view()\n        self.fig.canvas.draw()\n\n    @classmethod\n    def is_suitable(cls, h5object):\n        if not isinstance(h5object, h5py.Dataset):\n            return -1\n        if len(h5object.shape) == 1:\n            return 10\n        elif len(h5object.shape) > 1:\n            return -1\n        return -1",
  "class DataRenderer2D(FigureRenderer):\n    \"\"\" A renderer for 2D datasets experessing them in a colourmap graph using\n    matplotlib. Although this does not allow the user to interact with the\n    figure it is often found to be more stable.\n    \"\"\"\n    def display_data(self):\n        ax = self.fig.add_subplot(111)\n        ax.imshow(self.h5object, aspect=\"auto\", cmap=\"cubehelix\")\n        self.fig.canvas.draw()\n\n    @classmethod\n    def is_suitable(cls, h5object):\n        if not isinstance(h5object, h5py.Dataset):\n            return -1\n        if len(h5object.shape) == 2:\n            return 10\n        elif len(h5object.shape) < 2:\n            return -1\n        else:\n            return -1",
  "class DataRendererRGB(FigureRenderer):\n    \"\"\" A renderer for RGB images/datasets experessing them in a colourmap graph using\n    matplotlib. Allow this does not allow the user to interact with the\n    figure it is often found to be more stable.\n    \"\"\"\n    def display_data(self):\n        ax = self.fig.add_subplot(111)\n        ax.imshow(self.h5object)\n        self.fig.canvas.draw()\n\n    @classmethod\n    def is_suitable(cls, h5object):\n        if not isinstance(h5object, h5py.Dataset):\n            return -1\n        if len(h5object.shape) == 3 and h5object.shape[2]==3:\n            return 15\n        elif len(h5object.shape) != 3:\n            return -1\n        else:\n            return -1",
  "class SpectrumRenderer(FigureRendererPG):\n    \"\"\" A renderer for  spectral datasets experessing them in a line graph using\n    pyqt graph. Allowing the user to interact with the graph i.e. zooming into \n    selected region or performing mathematical transfomations on the axis\n    \n    If a background and/or reference are within the attributes for the datafile \n    they will also be applied. If this is the case it will be expressed in the \n    title of the graph.\n    \n    This renderer is also avaible for users attempting to look at multiple spectra \n    in seperate datasets at the same time through selection while pressing\n    control/shift as used in most windows apps.\n    \"\"\"\n    def display_data(self):\n        if type(self.h5object) == h5py.Dataset:\n            self.h5object = {self.h5object.name : self.h5object}\n        #Perform averaging\n        h5list = {}\n        for h5object in list(self.h5object.values()):  \n            if 'averaging_enabled' in list(h5object.attrs.keys()):\n                if h5object.attrs['averaging_enabled']==True:\n                    ldata = np.average(np.array(h5object)[...],axis = 0)\n                    linedata = ArrayWithAttrs(ldata,attrs = h5object.attrs)\n                    linedata.name = h5object.name\n                    h5list[linedata.name] =linedata\n                else:\n                    h5list[h5object.name] = h5object\n            else:\n                h5list[h5object.name] = h5object\n        self.h5object = h5list\n\n\n   #     if isinstance(self.h5object,dict) or isinstance(self.h5object,h5py.Group):\n   #         pass\n        #take 2D or one datasets and combine them\n        h5list = {}\n        for h5object in list(self.h5object.values()):\n            if len(h5object.shape)==2:\n                for line in range(len(h5object[:,0])):\n                    ldata = np.array(h5object)[line]\n                    linedata = ArrayWithAttrs(ldata,attrs = h5object.attrs)\n                    linedata.name = h5object.name+\"_\"+str(line)\n                    h5list[linedata.name] =linedata\n            else:\n                h5list[h5object.name] = h5object\n        self.h5object = h5list\n   #     elif type(self.h5object) != dict or type(self.h5object) != df.Group or type(self.h5object) != h5py.Group:\n  #      elif type(self.h5object) == h5py.Dataset\n #           self.h5object = {self.h5object.name : self.h5object}\n        #Deal with averaging of spectra\n        plot = self.figureWidget\n        plot.addLegend(offset = (-1,1))\n        icolour = 0\n        for h5object in list(self.h5object.values()):\n            icolour = icolour+1\n            Data = np.array(h5object)\n            Title = \"A\"\n            if 'variable_int_enabled' in list(h5object.attrs.keys()):\n                variable_int = h5object.attrs['variable_int_enabled']\n            else:\n                variable_int =False\n            if ((variable_int == True) and #Check for variable integration time and that the background_int and reference_int are not none\n                        ((h5object.attrs['background_int'] != h5object.attrs['integration_time'] \n                            and (h5object.attrs['background_int'] != None))\n                        or (h5object.attrs['reference_int'] != h5object.attrs['integration_time'] \n                            and (h5object.attrs['reference_int'] != None)))):\n                Title = Title + \" variable\"\n                if h5object.attrs['background_int'] != None:\n                    if h5object.attrs['reference_int'] != None:\n                        Data = (((Data-(h5object.attrs['background_constant']+h5object.attrs['background_gradient']*h5object.attrs['integration_time']))/ \n                                        (((h5object.attrs['reference']-(h5object.attrs['background_constant']+h5object.attrs['background_gradient']*h5object.attrs['reference_int']))\n                                        *h5object.attrs['integration_time']/h5object.attrs['reference_int']))))\n                        Title = Title + \" referenced and background subtracted\"\n                    else:\n                        Data = Data-(h5object.attrs['background_constant']+h5object.attrs['background_gradient']*h5object.attrs['integration_time'])\n                        Title = Title + \" background subtracted\"\n            else:\n                if 'background' in list(h5object.attrs.keys()):\n                    if len(np.array(h5object)) == len(np.array(h5object.attrs['background'])):\n                        Data = Data - np.array(h5object.attrs['background'])\n                        Title = Title + \" background subtracted\"\n                    if 'reference' in list(h5object.attrs.keys()):\n                        if len(np.array(h5object)) == len(np.array(h5object.attrs['reference'])):\n                            Data = (Data/(np.array(h5object.attrs['reference'])- np.array(h5object.attrs['background'])))\n                            Title = Title + \" referenced\"\n            if 'absorption_enabled' in list(h5object.attrs.keys()):\n                if h5object.attrs['absorption_enabled']:\n                    Data = np.log10((1/np.array(Data)))\n            plot.plot(x = np.array(h5object.attrs['wavelengths']), y = np.array(Data),name = h5object.name, pen =(icolour,len(self.h5object)) )\n            Title = Title + \" spectrum\"\n                \n            labelStyle = {'font-size': '24pt'}\n            self.figureWidget.setLabel('left', 'Intensity',**labelStyle)\n            self.figureWidget.setLabel('bottom', 'Wavelength (nm)',**labelStyle)\n            self.figureWidget.setTitle(Title,**labelStyle) # displays too small\n            \n        \n   \n    @classmethod\n    def is_suitable(cls, h5object):\n        suitability = 0\n        if isinstance(h5object,dict) == False and isinstance(h5object,h5py.Group) == False:\n            h5object = {h5object.name : h5object}\n        if not len(list(h5object.values())):\n                return -1\n        for dataset in list(h5object.values()):\n            if not isinstance(dataset, h5py.Dataset):\n                return -1\n            if len(dataset.shape) == 1:\n                suitability = suitability + 10\n                    \n            if len(dataset.shape) > 2:\n                return -1\n      \n            if 'wavelengths' in list(dataset.attrs.keys()):\n                if len(dataset.shape) == 2:\n                    if len(np.array(dataset)[:,0])<20:\n                        suitability = suitability + len(h5object)-20\n                    else:\n                        return 1\n                elif len(dataset.attrs['wavelengths']) != len(np.array(dataset)):\n                    print(\"the number of bins does not equal the number of wavelengths!\")\n                    return -1\n                suitability = suitability + 10\n            else:\n                return -1\n             \n            if 'background' in list(dataset.attrs.keys()):\n                suitability = suitability + 10\n            if 'reference' in list(dataset.attrs.keys()):\n                suitability = suitability + 10 \n        suitability = suitability + 10\n        return suitability",
  "class HyperSpec(DataRenderer, QtWidgets.QWidget):\n    \"\"\" A renderer for large hyper spectral datasets experessing them in a colour map using\n    pyqt graph. Allowing the user to interact with the graph i.e. zooming into \n    selected region and changing the colour scheme through the use of a histogramLUT \n    widget on the right of the image. A slider is also available to change the current\n    wavelength shown in the image.\n    \n    X/y/z attributes will be used as axis on the plots if available.\n\n    \"\"\"\n    def __init__(self, h5object, parent=None):\n        super(HyperSpec, self).__init__(h5object, parent)\n        pg.setConfigOption('background', 'w')\n        pg.setConfigOption('foreground', 'k')\n        self.layout = QtWidgets.QGridLayout()\n        self.setLayout(self.layout)\n        self.display_data()\n\n    def display_data(self):\n        data = np.array(self.h5object)\n        data[np.where(np.isnan(data))] = 0 \n        \n        dims = len(np.shape(data))\n        \n        Images = []\n        midpoints = []\n        \n        for dim in range(dims-1):\n            Images.append(pg.ImageView(view=pg.PlotItem()))\n            midpoints.append(int((np.shape(data)[dim]/2)))\n\n     \n        Imagedata = []\n        \n        Imagedata.append(np.transpose(data[:,:,midpoints[2],:]))\n        Imagedata.append(np.transpose(data[:,midpoints[1],:,:]))\n        Imagedata.append(np.transpose(data[midpoints[0],:,:,:]))\n        \n        XConvertionM = 1\n        YConvertionM = 1        \n        ZConvertionM = 1\n        \n        if len(self.h5object.attrs['x']) > 1:\n           XConvertionM = self.h5object.attrs['x'][1] - self.h5object.attrs['x'][0]\n        if len(self.h5object.attrs['y']) > 1:\n            YConvertionM = self.h5object.attrs['y'][1] - self.h5object.attrs['y'][0]                    \n        if len(self.h5object.attrs['z']) > 1:\n            ZConvertionM = self.h5object.attrs['z'][1] - self.h5object.attrs['z'][0]\n            \n        convertionfactors = [[YConvertionM,XConvertionM],[ZConvertionM,XConvertionM],[ZConvertionM,YConvertionM]]\n        \n        labels = [[\"X\",\"Y\"],[\"X\",\"Z\"],[\"Y\",\"Z\"]]\n                \n        for imgNum in range(len(Imagedata)):\n            if len(Imagedata[imgNum][0,0,:]) == 1:\n                Imagedata[imgNum] = np.swapaxes(Imagedata[imgNum],1,2)\n                con = convertionfactors[imgNum][1]\n                convertionfactors[imgNum][1] = convertionfactors[imgNum][0]\n                convertionfactors[imgNum][0] = con\n                \n                conlabel = labels[imgNum][0]\n                labels[imgNum][0] = labels[imgNum][1]\n                labels[imgNum][1] = conlabel\n\n  \n        \n        for imgNom in range(len(Images)):\n            Images[imgNom].setImage(Imagedata[imgNom],xvals = np.array(self.h5object.attrs['wavelengths']),autoHistogramRange = True)\n      \n\n        \n \n       \n    \n        Images[0].getImageItem().scale(convertionfactors[0][0],convertionfactors[0][1])\n\n        \n        Images[1].getImageItem().scale(convertionfactors[1][0],convertionfactors[1][1])\n        \n        Images[2].getImageItem().scale(convertionfactors[2][0], convertionfactors[2][1])\n\n        \n        \n               \n\n\n        for imgNom in range(len(Images)): \n            Images[imgNom].autoLevels()\n            Images[imgNom].autoRange()\n            Images[imgNom].ui.roiBtn.hide()\n            Images[imgNom].ui.menuBtn.hide() \n            Images[imgNom].setMinimumSize(550,350)\n            Images[imgNom].view.setAspectLocked(False)\n            \n            Images[imgNom].getView().setTitle(labels[imgNom][0]+\"(\"+labels[imgNom][1]+\")\")\n            Images[imgNom].getView().setLabel(\"left\" , labels[imgNom][0])\n            Images[imgNom].getView().setLabel(\"bottom\" , labels[imgNom][1])\n      \n        self.layout.addWidget(Images[0],0,0)\n        self.layout.addWidget(Images[1],0,1)\n        self.layout.addWidget(Images[2],1,0)\n        \n        \n        self.setLayout(self.layout)\n\n   \n    @classmethod\n    def is_suitable(cls, h5object):\n        if not isinstance(h5object, h5py.Dataset):\n            return -1\n        elif len(h5object.shape) == 4 and 'z' in list(h5object.attrs.keys()) and 'y' in list(h5object.attrs.keys()) and 'x' in list(h5object.attrs.keys()):\n            return 30\n        elif len(h5object.shape) > 4:\n            return -1\n        else:\n            return -1",
  "class HyperSpec_Alan(DataRenderer, QtWidgets.QWidget):\n    \"\"\" A Renderer similar to HyperSpec however written to match Alan's style of \n    writting hyperspec images with the x,y and wavelengths being in different dataset within one group. \n    Currently only capable of displaying Hyperspec images from two spectromters in two dimensions.\n    \n    If you need to do 3D grid scans feel free to update me!\n\n    \"\"\"\n    def __init__(self, h5object, parent=None):\n        super(HyperSpec_Alan, self).__init__(h5object, parent)\n        pg.setConfigOption('background', 'w')\n        pg.setConfigOption('foreground', 'k')\n        self.layout = QtWidgets.QGridLayout()\n        self.setLayout(self.layout)\n        self.display_data()\n\n    def display_data(self):\n        # A try and except loop to determine the number of hyperspectral image avaible\n        try:\n            original_string = 'hs_image'\n            test_string = original_string\n            num_hyperspec = 1\n            Fail = False\n            while Fail == False:\n                self.h5object[test_string]\n                num_hyperspec = num_hyperspec + 1\n                test_string = original_string+str(num_hyperspec)\n        except KeyError:\n            pass\n        #Creating a list of hyperspec images to put into a the layout\n        Images = []\n        #Calculate the X,Y scales for the images\n        XConvertionM = ((self.h5object['x'][-1] - self.h5object['x'][0])/len(self.h5object['x']))\n        YConvertionM = ((self.h5object['y'][-1] - self.h5object['y'][0])/len(self.h5object['y']))\n        #creating an iterator for the number of hyperspectral images\n        for hyperspec_nom in range(1,num_hyperspec):\n            if hyperspec_nom == 1:\n                hyperspec_nom_str = ''\n            else:\n                hyperspec_nom_str = str(hyperspec_nom)\n                \n            #Grab the correct hyperspec data\n            data = np.transpose(np.array(self.h5object['hs_image'+hyperspec_nom_str]))\n            #Change NaNs to zeros (prevents error)\n            data[0][np.where(np.isnan(data[0]))] = 0 \n        \n            #create image item for current image                 \n            Images.append(pg.ImageView(view=pg.PlotItem()))\n            #Set image\n            Images[hyperspec_nom-1].setImage(data,xvals = np.array(self.h5object['wavelength2']),autoHistogramRange = True)\n            \n     \n            # Formating of the Image\n            Images[hyperspec_nom-1].getImageItem().scale(XConvertionM,YConvertionM)\n            Images[hyperspec_nom-1].autoRange()\n            Images[hyperspec_nom-1].autoLevels()\n            Images[hyperspec_nom-1].ui.roiBtn.hide()\n            Images[hyperspec_nom-1].ui.menuBtn.hide()\n            Images[hyperspec_nom-1].setMinimumSize(550,350)\n        \n       #Image postion within a grid, (with need updating if using mroe than 4 spectrometers)\n        positions = [[0,0],[0,1],[1,0],[1,1]]    \n        #Add Images to layout\n        for hyperspec_nom in range(num_hyperspec-1): \n            self.layout.addWidget(Images[hyperspec_nom],positions[hyperspec_nom][0],positions[hyperspec_nom][1])\n\n        \n        self.setLayout(self.layout)\n\n   \n    @classmethod\n    def is_suitable(cls, h5object):\n        suitability = 0\n        try:\n            h5object['hs_image']\n            suitability = suitability + 10\n        except KeyError:\n            return -1\n            \n        try:\n            h5object['wavelength']\n            suitability = suitability + 10\n        except KeyError:\n            return -1\n            \n        try:\n            h5object['y']\n            suitability = suitability + 10\n        except KeyError:\n            return -1\n            \n        try:\n            h5object['x']\n            suitability = suitability + 10\n        except KeyError:\n            return -1  \n            \n        return suitability",
  "class ScannedParticle(FigureRenderer):\n    \"\"\"A renderer for individual particles from a particle scan.\"\"\"\n    def display_data(self):\n        g = self.h5object\n        zscan = g['z_scan']\n        dz = g['z_scan'].attrs.get('dz', np.arange(zscan.shape[0]))\n        spectrum = np.mean(zscan, axis=0)\n        wavelengths = zscan.attrs.get(\"wavelengths\")\n        spectrum_range = slice(None)\n        try:\n            background = zscan.attrs.get(\"background\")\n            spectrum -= background #we'll fail here if there was no background recorded\n            reference = zscan.attrs.get(\"reference\")\n            spectrum /= (reference - background) #if there's a reference, apply it\n            spectrum_range = reference > (np.max(reference)/10)\n        except:\n            pass # if reference/background are missing, ignore them.\n        import matplotlib.gridspec as gridspec\n        gs = gridspec.GridSpec(2,2)\n        ax0 = self.fig.add_subplot(gs[0,0])  # plot the overview image\n        ax0.imshow(g['camera_image'], extent=(0, 1, 0, 1), aspect=\"equal\")\n        ax0.plot([0.5, 0.5], [0.2, 0.8], \"w-\") #crosshair\n        ax0.plot([0.2, 0.8], [0.5, 0.5], \"w-\")\n        ax0.get_xaxis().set_visible(False)\n        ax0.get_yaxis().set_visible(False)\n        ax0.set_title(\"Particle Image\")\n\n        ax1 = self.fig.add_subplot(gs[0,1])  # plot the z stack\n        ax1.imshow(zscan, extent=(wavelengths.min(), wavelengths.max(), dz.min(), dz.max()), aspect=\"auto\", cmap=\"cubehelix\")\n        ax1.set_xlabel(\"Wavelength/nm\")\n        ax1.set_ylabel(\"Z/um\")\n\n        ax2 = self.fig.add_subplot(gs[1,0:2])  # plot the spectrum\n        ax2.plot(wavelengths[spectrum_range], spectrum[spectrum_range])\n        ax2.set_xlabel(\"Wavelength/nm\")\n        ax2.set_ylabel(\"Z-averaged Spectrum\")\n        self.fig.canvas.draw()\n\n    @classmethod\n    def is_suitable(cls, h5object):\n        # This relies on sensible exception handling: if an exception occurs here, the renderer\n        # will be deemed unsuitable (!)\n\n        # First, make sure we've got the right datasets (NB this also raises an exception if it's not a group)\n        g = h5object\n        keys = getattr(g, 'keys', list)()\n        for k in ['camera_image', 'z_scan']:\n            if k not in keys:\n                # print(\"missing dataset {}, can't be a particle...\".format(k))\n                return -1\n        try:\n            assert g['camera_image'].shape[0] > 10\n            assert g['camera_image'].shape[1] > 10\n            assert len(g['z_scan'].shape) == 2\n        except: return -1\n        return 500",
  "class PumpProbeShifted(DataRenderer, QtWidgets.QWidget):\n    ''' A renderer for Pump probe experiments, leaving the data un changed'''\n    \"\"\" A renderer for 1D datasets experessing them in a line graph using\n    pyqt graph. Allowing the user to interact with the graph i.e. zooming into \n    selected region or performing transformations of the axis\n    \"\"\"\n    def __init__(self, h5object, parent=None):\n        super(PumpProbeShifted, self).__init__(h5object, parent)\n        pg.setConfigOption('background', 'w')\n        pg.setConfigOption('foreground', 'k')\n        self.layout = QtWidgets.QGridLayout()\n        self.setLayout(self.layout)\n        self.display_data()\n        \n    def display_data(self):\n        if isinstance(self.h5object,dict) == False and isinstance(self.h5object,h5py.Group) == False:\n            self.h5object = {self.h5object.name : self.h5object}\n        icolour = 0    \n        Plots = []\n        axes ={0 : 'X',1 : 'Y', 2 : 'R'}\n        \n\n        for axis in axes:\n            Plots.append(pg.PlotWidget())\n       \n        for plot in Plots:\n            plot.addLegend(offset = (-1,1))\n        \n        stepperoffset = -5.0\n        \n        for h5object in list(self.h5object.values()):\n            for axis in list(axes.keys()):\n                data = np.array(h5object)\n                data[np.where(data[:,7]%2 != 0),5] +=  stepperoffset\n                data[:,5] = -1*(data[:,5]-(864.0))\n     \n                Plots[axis].plot(x = data[:,5], y = data[:,axis],name = h5object.name,pen =(icolour,len(self.h5object)))\n                Plots[axis].setLabel('left',axes[axis]+\" (V)\")\n                Plots[axis].setLabel('bottom', 'Time (ps)')\n            icolour = icolour + 1        \n        \n        \n\n        self.layout.addWidget(Plots[0],0,0)\n        self.layout.addWidget(Plots[1],0,1)\n        self.layout.addWidget(Plots[2],1,0)\n\n        \n    def change_in_stepperoffset(self):\n        print(\"HI\")\n        \n        \n    @classmethod\n    def is_suitable(cls, h5object):\n        suitability = 0\n        if isinstance(h5object,dict) == False and isinstance(h5object,h5py.Group) == False:\n            h5object = {h5object.name : h5object}\n            \n        for dataset in list(h5object.values()):\n            if not isinstance(dataset, h5py.Dataset):\n                return -1\n            if len(dataset.shape) == 2:\n                if dataset.shape[1] == 8:\n                    suitability = suitability + 11\n                else:\n                    return -1\n            else:\n                return -1\n            if 'repeats' in list(dataset.attrs.keys()):\n                suitability = suitability + 50\n            if 'start' in list(dataset.attrs.keys()):\n                suitability = suitability + 50\n            if 'finish' in list(dataset.attrs.keys()):\n                suitability = suitability + 50\n            if 'stepsize' in list(dataset.attrs.keys()):\n                suitability = suitability + 20\n            if 'velocity' in list(dataset.attrs.keys()):\n                suitability = suitability + 20      \n            if 'acceleration' in list(dataset.attrs.keys()):\n                suitability = suitability + 20    \n            if 'filter' in list(dataset.attrs.keys()):\n                suitability = suitability + 20      \n            if 'sensitivity' in list(dataset.attrs.keys()):\n                suitability = suitability + 20    \n        return suitability",
  "class PumpProbeRaw(DataRenderer, QtWidgets.QWidget):\n    ''' A renderer for Pump probe experiments, leaving the data un changed'''\n    \"\"\" A renderer for 1D datasets experessing them in a line graph using\n    pyqt graph. Allowing the user to interact with the graph i.e. zooming into \n    selected region or performing transformations of the axis\n    \"\"\"\n    def __init__(self, h5object, parent=None):\n        super(PumpProbeRaw, self).__init__(h5object, parent)\n        pg.setConfigOption('background', 'w')\n        pg.setConfigOption('foreground', 'k')\n        self.layout = QtWidgets.QGridLayout()\n        self.setLayout(self.layout)\n        self.display_data()\n        \n    def display_data(self):\n        if isinstance(self.h5object,dict) == False and isinstance(self.h5object,h5py.Group) == False:\n            self.h5object = {self.h5object.name : self.h5object}\n        icolour = 0    \n        Plots = []\n        axes ={0 : 'X',1 : 'Y', 2 : 'R'}\n        \n\n        for axis in axes:\n            Plots.append(pg.PlotWidget())\n       \n        for plot in Plots:\n            plot.addLegend(offset = (-1,1))\n        \n   #     stepperoffset = -5.0\n        \n        for h5object in list(self.h5object.values()):\n            for axis in list(axes.keys()):\n                data = np.array(h5object)\n          #      data[np.where(data[:,7]%2 != 0),5] +=  stepperoffset\n        #        data[:,5] = -1*(data[:,5]-(864.0))\n\n                Plots[axis].plot(x = data[:,6], y = data[:,axis],name = h5object.name,pen =(icolour,len(self.h5object)))\n                Plots[axis].setLabel('left',axes[axis]+\" (V)\")\n                Plots[axis].setLabel('bottom', 'Time (ps)')\n            icolour = icolour + 1        \n        \n        \n\n        self.layout.addWidget(Plots[0],0,0)\n        self.layout.addWidget(Plots[1],0,1)\n        self.layout.addWidget(Plots[2],1,0)\n             \n                \n    @classmethod\n    def is_suitable(cls, h5object):\n        suitability = 0\n        if isinstance(h5object,dict) == False and isinstance(h5object,h5py.Group) == False:\n            h5object = {h5object.name : h5object}\n           \n        for dataset in list(h5object.values()):\n            if not isinstance(dataset, h5py.Dataset):\n                return -1\n            if len(dataset.shape) == 2:\n                if dataset.shape[1] == 8:\n                    suitability = suitability + 11\n                else:\n                    return -1\n            else:\n                return -1\n            if 'repeats' in list(dataset.attrs.keys()):\n                suitability = suitability + 50\n            if 'start' in list(dataset.attrs.keys()):\n                suitability = suitability + 50\n            if 'finish' in list(dataset.attrs.keys()):\n                suitability = suitability + 50\n            if 'stepsize' in list(dataset.attrs.keys()):\n                suitability = suitability + 20\n            if 'velocity' in list(dataset.attrs.keys()):\n                suitability = suitability + 20      \n            if 'acceleration' in list(dataset.attrs.keys()):\n                suitability = suitability + 20    \n            if 'filter' in list(dataset.attrs.keys()):\n                suitability = suitability + 20      \n            if 'sensitivity' in list(dataset.attrs.keys()):\n                suitability = suitability + 20    \n        return suitability",
  "class PumpProbeRawXOnly(DataRenderer, QtWidgets.QWidget):\n    ''' A renderer for Pump probe experiments, leaving the data un changed'''\n    \"\"\" A renderer for 1D datasets experessing them in a line graph using\n    pyqt graph. Allowing the user to interact with the graph i.e. zooming into \n    selected region or performing transformations of the axis\n    \"\"\"\n    def __init__(self, h5object, parent=None):\n        super(PumpProbeRawXOnly, self).__init__(h5object, parent)\n        pg.setConfigOption('background', 'w')\n        pg.setConfigOption('foreground', 'k')\n        self.layout = QtWidgets.QGridLayout()\n        self.setLayout(self.layout)\n        self.display_data()\n        \n    def display_data(self):\n        if isinstance(self.h5object,dict) == False and isinstance(self.h5object,h5py.Group) == False:\n            self.h5object = {self.h5object.name : self.h5object}\n        icolour = 0    \n        Plots = []\n        axes ={0 : 'X'}\n        \n\n        for axis in axes:\n            Plots.append(pg.PlotWidget())\n       \n        for plot in Plots:\n            plot.addLegend(offset = (-1,1))\n        \n        stepperoffset = -5.0\n        \n        for h5object in list(self.h5object.values()):\n            for axis in list(axes.keys()):\n                data = np.array(h5object)\n                data[np.where(data[:,7]%2 != 0),5] +=  stepperoffset\n                data[:,5] = -1*(data[:,5]-(864.0))\n                data[:,0] = data[:,0]/8.0\n\n                Plots[axis].plot(x = data[:,5], y = data[:,axis],name = h5object.name,pen =(icolour,len(self.h5object)))\n                Plots[axis].setLabel('left',\"dV/V\")\n                Plots[axis].setLabel('bottom', 'Time (ps)')\n            icolour = icolour + 1        \n        \n        \n        self.layout.addWidget(Plots[0],0,0)\n        \n\n        \n        \n    @classmethod\n    def is_suitable(cls, h5object):\n        suitability = 0\n        if isinstance(h5object,dict) == False and isinstance(h5object,h5py.Group) == False:\n            h5object = {h5object.name : h5object}       \n            \n        for dataset in list(h5object.values()):\n            if not isinstance(dataset, h5py.Dataset):\n                return -1\n            if len(dataset.shape) == 2:\n                if dataset.shape[1] == 8:\n                    suitability = suitability + 11\n                else:\n                    return -1\n            else:\n                return -1\n            if 'repeats' in list(dataset.attrs.keys()):\n                suitability = suitability + 50\n            if 'start' in list(dataset.attrs.keys()):\n                suitability = suitability + 50\n            if 'finish' in list(dataset.attrs.keys()):\n                suitability = suitability + 50\n            if 'stepsize' in list(dataset.attrs.keys()):\n                suitability = suitability + 20\n            if 'velocity' in list(dataset.attrs.keys()):\n                suitability = suitability + 20      \n            if 'acceleration' in list(dataset.attrs.keys()):\n                suitability = suitability + 20    \n            if 'filter' in list(dataset.attrs.keys()):\n                suitability = suitability + 20      \n            if 'sensitivity' in list(dataset.attrs.keys()):\n                suitability = suitability + 20    \n        return suitability",
  "class PumpProbeX_loops(DataRenderer, QtWidgets.QWidget):\n    ''' A renderer for Pump probe experiments, leaving the data un changed'''\n    \"\"\" A renderer for 1D datasets experessing them in a line graph using\n    pyqt graph. Allowing the user to interact with the graph i.e. zooming into \n    selected region or performing transformations of the axis\n    \"\"\"\n    def __init__(self, h5object, parent=None):\n        super(PumpProbeX_loops, self).__init__(h5object, parent)\n        pg.setConfigOption('background', 'w')\n        pg.setConfigOption('foreground', 'k')\n        self.layout = QtWidgets.QGridLayout()\n        self.setLayout(self.layout)\n        self.display_data()\n        \n    def display_data(self):\n        if isinstance(self.h5object,dict) == False and isinstance(self.h5object,h5py.Group) == False:\n            self.h5object = {self.h5object.name : self.h5object}\n        icolour = 0    \n        Plots = []\n        axes ={0 : 'X'}\n        \n\n        for axis in axes:\n            Plots.append(pg.PlotWidget())\n       \n        for plot in Plots:\n            plot.addLegend(offset = (-1,1))\n        \n        stepperoffset = -5.0\n        \n        for h5object in list(self.h5object.values()):\n            for axis in list(axes.keys()):\n                data = np.array(h5object)\n                data[np.where(data[:,7]%2 != 0),5] +=  stepperoffset\n                data[:,5] = -1*(data[:,5]-(864.0))\n                data[:,0] = data[:,0]/8.0\n             \n                for icolour in range(int(np.max(data[:,7])+1)):\n                    Plots[axis].plot(x = data[np.where(data[:,7]==icolour)[0],5], y = data[np.where(data[:,7]==icolour)[0],axis],name = h5object.name,pen =(icolour,np.max(data[:,7])+1))\n                Plots[axis].setLabel('left',\"dV/V\")\n                Plots[axis].setLabel('bottom', 'Time (ps)')\n            icolour = icolour + 1        \n        \n        \n\n        self.layout.addWidget(Plots[0],0,0)\n\n    @classmethod\n    def is_suitable(cls, h5object):\n        suitability = 0\n        if isinstance(h5object,dict) == False and isinstance(h5object,h5py.Group) == False:\n            h5object = {h5object.name : h5object}\n            \n        for dataset in list(h5object.values()):\n            if not isinstance(dataset, h5py.Dataset):\n                return -1\n            if len(dataset.shape) == 2:\n                if dataset.shape[1] == 8:\n                    suitability = suitability + 11\n                else:\n                    return -1\n            else:\n                return -1\n            if 'repeats' in list(dataset.attrs.keys()):\n                suitability = suitability + 50\n            if 'start' in list(dataset.attrs.keys()):\n                suitability = suitability + 50\n            if 'finish' in list(dataset.attrs.keys()):\n                suitability = suitability + 50\n            if 'stepsize' in list(dataset.attrs.keys()):\n                suitability = suitability + 20\n            if 'velocity' in list(dataset.attrs.keys()):\n                suitability = suitability + 20      \n            if 'acceleration' in list(dataset.attrs.keys()):\n                suitability = suitability + 20    \n            if 'filter' in list(dataset.attrs.keys()):\n                suitability = suitability + 20      \n            if 'sensitivity' in list(dataset.attrs.keys()):\n                suitability = suitability + 20    \n        return suitability",
  "class AutocorrelationRenderer(FigureRendererPG):\n    \"\"\" A renderer for 1D datasets pushing them through the autocorrelation function prior to plotting. \n    Also looks for metadata annotations in each dataset. In the case when the dataset attributes include field:\n        dt\n        frequency\n    The make_Xdata generates converts the 1D dataset into a 2D dataset by reconstructing the times at which the data was sampled and \n    relabels the X-axis with the time. Lastly, before plotting the data is transformed to an equivalent of \"semilogx\" format in matplotlib\n    \"\"\"\n\n    #Computes autocorrelation of the data using FFT: O(nlogn). Direct computation of correlation is O(n^2) and so is slower\n    @staticmethod\n    def autocorrelation(x,mode=\"fft\"):\n        import scipy.signal\n        x=np.asarray(x)\n        n = len(x)\n        mean = x.mean()\n        if mode == \"fft\":\n            r = scipy.signal.correlate(x,x,mode=\"full\",method=\"fft\")[-n:]\n            outp = np.divide(r,np.multiply(mean**2,np.arange(n,0,-1)))\n            return outp\n        elif mode == \"direct\":\n            r = np.correlate(x, x, mode = 'full')[-n:]\n            outp =  np.divide(r,np.multiply(mean**2,np.arange(n,0,-1)))\n            return outp\n\n    #Tries to convert the array of indices on the X axis into time sample points by checking if dataset contains \"dt\" or \"frequency\" metadata annotations\n    @staticmethod\n    def make_Xdata(dataset,N):\n        #Pulls out metadata from the datasets in the case when the dataset is 1D\n        # reconstructs the sampling times, assuming equidistant - halves space requirements\n        Xdata = np.arange(N)\n        keys = [\"dt\", \"frequency\"]\n        for k in keys:\n            if k in list(dataset.attrs.keys()):\n                if k == \"dt\":\n                    try:\n                        dt = float(dataset.attrs[k])\n                        return dt*Xdata,\"Log10(Time) [s]\"\n                    except: pass\n                elif k == \"frequency\":\n                    try:\n                        dt = 1.0/float(dataset.attrs[k])\n                        return dt*Xdata,\"Log10(Time) [s]\"\n                    except: pass\n            else:\n                return Xdata,\"Log10(ArrayIndex)\"\n        \n    def display_data(self):\n        if not hasattr(self.h5object, \"values\"):\n            # If we have only one item, treat it as a group containing that item.\n            self.h5object = {self.h5object.name: self.h5object}\n        icolour = 0    \n        self.figureWidget.addLegend(offset = (-1,1))\n\n        #Default X and Y labels\n        Xlabel = 'Log10(X axis)'\n        Ylabel = 'ACF(Y axis)'\n        for dataset in list(self.h5object.values()):\n\n            #Try to pull out axes label annotations from metadata + reformat them\n            try:\n                Xlabel = \"Log10({0})\".format(dataset.attrs['X label'])\n            except:\n                pass\n            try:\n                Ylabel = \"ACF({0})\".format(dataset.attrs['Y label'])\n            except:\n                pass\n            #Pull out data\n            try:\n                if np.shape(dataset)[0] == 2 or np.shape(dataset)[1] == 2:\n                    Xdata = np.array(dataset)[0]\n                    Ydata = np.array(dataset)[1] \n                else:\n                    Ydata = np.array(dataset)\n                    #no xdata stores - generate our own\n                    Xdata,Xlabel = AutocorrelationRenderer.make_Xdata(dataset, len(Ydata))\n            except IndexError:\n                #no xdata stores - generate our own\n                Ydata = np.array(dataset)\n                Xdata,Xlabel = AutocorrelationRenderer.make_Xdata(dataset, len(Ydata))\n\n            #Final transform prior to plotting:\n            xs = np.log10(Xdata[1:])\n            ys = AutocorrelationRenderer.autocorrelation(Ydata)[1:]\n            #plot\n            self.figureWidget.plot(x = xs, y = ys,name = dataset.name, pen =(icolour,len(self.h5object)))\n            icolour = icolour + 1\n            \n        labelStyle = {'font-size': '24pt'}\n        #set axes labels\n        self.figureWidget.setLabel('bottom', Xlabel, **labelStyle)\n        self.figureWidget.setLabel('left', Ylabel, **labelStyle)\n       \n\n    @classmethod\n    def is_suitable(cls, h5object):\n        if not hasattr(h5object, \"values\"):\n            # If we have only one item, treat it as a group containing that item.\n            h5object = {h5object.name: h5object}\n        if not len(list(h5object.values())):\n            return -1\n        for dataset in list(h5object.values()):\n            # Check that all datasets selected are either 1D or Nx2 or 2xN\n            assert isinstance(dataset, h5py.Dataset)\n            #autocorrelation functions are only for the adlink9812 card\n            if not (dataset.attrs.get(\"device\", None)==\"adlink9812\"):\n                return -1\n            try:\n                assert len(dataset.shape) == 1\n            except:\n                assert len(dataset.shape) == 2\n                assert np.any(np.array(dataset.shape) == 2)\n\n        return 14",
  "def __init__(self, h5object, parent=None):\n    #    assert self.is_suitable(h5object) >= 0, \"Can't render that object: {0}\".format(h5object)\n        super(DataRenderer, self).__init__()\n        self.parent = parent\n        self.h5object = h5object",
  "def is_suitable(cls, h5object):\n        \"\"\"Return a score of how well suited this renderer is to the object.\n        \n        This should be a quick function, as it's called often (every renderer\n        gives a score each time we look for a suitable renderer).  Return a\n        number < 0 if you can't render the data.\n        \"\"\"\n        return -1",
  "def __init__(self, h5object, parent=None):\n        super(HDF5InfoRenderer, self).__init__(h5object, parent)\n        uic.loadUi(os.path.join(os.path.dirname(__file__), 'hdf5_info_renderer.ui'),self)\n        self.parent = parent\n        self.h5object = h5object\n\n\n        self.lineEdit.setText(self.h5object.name)\n        self.lineEdit2.setText(self.h5object.parent.name)\n        self.lineEdit3.setText(self.h5object.file.filename)",
  "def is_suitable(cls, h5object):\n        # Retrieve the things we're going to display to check that they exist (if an exception occurs, the renderer\n        # will be deemed unsuitable)\n        name = h5object.name\n        parentname = h5object.parent.name\n        filename = h5object.file.filename\n        return 2",
  "def __init__(self, h5object, parent=None):\n        super(ValueRenderer, self).__init__(h5object, parent)\n        \n        #our layout is simple - just a single QLabel\n        self.label = QtWidgets.QLabel()\n        layout = QtWidgets.QVBoxLayout(self)\n        layout.addWidget(self.label)\n        self.setLayout(layout)\n        \n        self.label.setText(self.text(h5object))",
  "def text(self, h5object):\n        \"\"\"Return the text that is displayed in the label\"\"\"\n        v = h5object[()]\n        if type(v) is bytes:\n            return v.decode()\n        return str(v)",
  "def is_suitable(cls, h5object):\n        try:\n            if getattr(h5object, 'is_note', False):\n                return 11\n            if len(h5object.shape)==0:\n                return 10\n            else:\n                return -1\n        except:\n            return -1",
  "def __init__(self, h5object, parent=None):\n        super(TextRenderer, self).__init__(h5object, parent)\n        \n        #our layout is simple - just a single QLineEdit\n        self.label = QtWidgets.QLineEdit()\n        layout = QtWidgets.QFormLayout(self)\n        layout.addWidget(self.label)\n        self.setLayout(layout)\n        self.label.setText(self.text(h5object))",
  "def text(self, h5object):\n        \"\"\"Return the text that is displayed in the label\"\"\"\n        return str(h5object)",
  "def is_suitable(cls, h5object):\n        return 1",
  "def __init__(self, h5object, parent=None):\n        super(AttrsRenderer, self).__init__(h5object)\n        uic.loadUi(os.path.join(os.path.join(os.path.dirname(__file__), 'hdf5_attrs_renderer.ui')),self)\n        \n        self.h5object = h5object\n        \n        if type(h5object)==list:\n            item_info = QtWidgets.QTableWidgetItem(\"Choose a single element to display its attributes!\")\n            self.tableWidget.setItem(0,0,item_info)\n            self.tableWidget.resizeColumnsToContents()\n        else:\n            self.tableWidget.setRowCount(len(self.h5object.attrs))\n            row = 0\n            for key, value in sorted(h5object.attrs.items()):\n                item_key = QtWidgets.QTableWidgetItem(key)\n                item_value = QtWidgets.QTableWidgetItem(str(value))\n                self.tableWidget.setItem(row,0,item_key)\n                self.tableWidget.setItem(row,1,item_value)\n                row = row + 1\n            self.tableWidget.resizeColumnsToContents()",
  "def is_suitable(cls, h5object):\n        if isinstance(h5object,h5py.Group):\n            if len(list(h5object.keys())) > 10:\n                return 5000\n        return 1",
  "def __init__(self, h5object, parent=None):\n        super(FigureRenderer, self).__init__(h5object, parent)\n        self.fig = Figure()\n\n        layout = QtWidgets.QVBoxLayout(self)\n        self.figureWidget = FigureCanvas(self.fig)\n        layout.addWidget(self.figureWidget)\n        self.setLayout(layout)\n\n        self.display_data()",
  "def display_data(self):\n        self.fig.canvas.draw()",
  "def __init__(self, h5object, parent=None):\n        super(FigureRendererPG, self).__init__(h5object, parent)\n        pg.setConfigOption('background', 'w')\n        pg.setConfigOption('foreground', 'k')\n        self.figureWidget =  pg.PlotWidget(name='Plot1') \n        self.layout = QtWidgets.QVBoxLayout(self)\n        self.layout.addWidget(self.figureWidget)\n        self.setLayout(self.layout)\n\n        self.display_data()",
  "def display_data(self):\n        self.fig.canvas.draw()",
  "def display_data(self):\n        if not hasattr(self.h5object, \"values\"):\n            # If we have only one item, treat it as a group containing that item.\n            self.h5object = {self.h5object.name: self.h5object}\n        icolour = 0    \n        self.figureWidget.addLegend(offset = (-1,1))\n        for h5object in list(self.h5object.values()):\n            try:\n                if np.shape(h5object)[0] == 2 or np.shape(h5object)[1] == 2:\n                    Xdata = np.array(h5object)[0]\n                    Ydata = np.array(h5object)[1]\n                else:\n                    Ydata = np.array(h5object)\n                    Xdata = np.arange(len(Ydata))\n            except IndexError:\n                Ydata = np.array(h5object)\n                Xdata = np.arange(len(Ydata))\n            self.figureWidget.plot(x = Xdata, y = Ydata,name = h5object.name, pen =(icolour,len(self.h5object)))\n            icolour = icolour + 1\n            \n        labelStyle = {'font-size': '24pt'}\n        try:\n            self.figureWidget.setLabel('bottom', h5object.attrs['X label'], **labelStyle)\n        except:\n            self.figureWidget.setLabel('bottom', 'An X axis', **labelStyle)\n            \n        try:\n            self.figureWidget.setLabel('left', h5object.attrs['Y label'], **labelStyle)\n        except:\n            self.figureWidget.setLabel('left', 'An Y axis', **labelStyle)",
  "def is_suitable(cls, h5object):\n        if not hasattr(h5object, \"values\"):\n            # If we have only one item, treat it as a group containing that item.\n            h5object = {h5object.name: h5object}\n        try:\n            if not len(list(h5object.values())):\n                return -1\n            for dataset in list(h5object.values()):\n                # Check that all datasets selected are either 1D or Nx2 or 2xN\n                if not (dataset.shape and isinstance(dataset, h5py.Dataset)):\n                    return -1#we can only render datasets\n                try:\n                    assert len(dataset.shape) == 1\n                except:\n                    assert len(dataset.shape) == 2\n                    assert np.any(np.array(dataset.shape) == 2)\n        except:\n            return -1\n        return 14",
  "def display_data(self):\n        if not hasattr(self.h5object, \"values\"):\n            # If we have only one item, treat it as a group containing that item.\n            self.h5object = {self.h5object.name: self.h5object}\n        icolour = 0    \n        self.figureWidget.addLegend(offset = (-1,1))\n        for h5object in list(self.h5object.values()): \n            try: \n                if np.shape(h5object)[0] == 2 or np.shape(h5object)[1] == 2:\n                    Xdata = np.array(h5object)[0]\n                    Ydata = np.array(h5object)[1]\n                else:\n                    Ydata = np.array(h5object)\n                    Xdata = np.arange(len(Ydata))\n            except IndexError:\n                Ydata = np.array(h5object)\n                Xdata = np.arange(len(Ydata))\n            self.figureWidget.plot(x = Xdata, y = Ydata,name = h5object.name, pen =None, symbol ='o',symbolPen = (icolour,len(self.h5object)),symbolBrush = (icolour,len(self.h5object)))\n            icolour = icolour + 1\n            \n        labelStyle = {'font-size': '24pt'}\n        try:\n            self.figureWidget.setLabel('bottom', h5object.attrs['X label'], **labelStyle)\n        except:\n            self.figureWidget.setLabel('bottom', 'An X axis', **labelStyle)\n            \n        try:\n            self.figureWidget.setLabel('left', h5object.attrs['Y label'], **labelStyle)\n        except:\n            self.figureWidget.setLabel('left', 'An Y axis', **labelStyle)",
  "def is_suitable(cls, h5object):\n        return DataRenderer1DPG.is_suitable(h5object) - 2",
  "def __init__(self, h5object, parent=None):\n        super(MultiSpectrum2D, self).__init__(h5object, parent)\n        pg.setConfigOption('background', 'w')\n        pg.setConfigOption('foreground', 'k')\n        self.layout = QtWidgets.QGridLayout()\n        self.setLayout(self.layout)\n        self.layout.setSpacing(0)\n\n        self.display_data()",
  "def display_data(self):\n        v = pg.GraphicsView()\n        vb = pg.PlotItem()\n        v.setCentralItem(vb)\n        self.layout.addWidget(v, 0, 0)\n    \n        w = pg.HistogramLUTWidget()\n        self.layout.addWidget(w, 0, 1)\n        \n        if isinstance(self.h5object,dict) or isinstance(self.h5object,h5py.Group):\n#            for i in range(len(self.h5object.values())):\n#                if i == 0:    \n#                    data = np.array(self.h5object.values()[i])\n#                else:\n#                    data = np.append(data,np.array(self.h5object.values()[i]),axis = 0)\n #           sorted_values = \n            data = np.array(list(self.h5object.values()))\n            dict_of_times = {}\n            for h5object in list(self.h5object.values()):\n                dict_of_times[h5object.attrs['creation_timestamp']]=h5object\n            data = np.array(list(dict_of_times.values()))\n            for i,h5object_time in enumerate(sorted(dict_of_times.keys())):\n                if i == 0:    \n                    data = np.array([dict_of_times[h5object_time]])\n                else:\n                    data = np.append(data,np.array([dict_of_times[h5object_time]]),axis = 0)\n\n                \n            ListData = True\n            print(np.shape(data),np.shape(list(self.h5object.values())))\n        elif len(self.h5object.shape) == 1 and len(self.h5object.attrs['wavelengths'])<len(self.h5object) and len(self.h5object)%len(self.h5object.attrs['wavelengths']) == 0:\n            RawData = np.array(self.h5object,dtype = float)\n            Xlen = len(np.array(self.h5object.attrs['wavelengths']))\n            Ylen = len(RawData)//Xlen\n            data = [RawData.reshape((Ylen,Xlen))]\n            self.h5object = {self.h5object.name : self.h5object}\n            ListData = False\n            \n        else:\n            data = [np.array(self.h5object)]\n            self.h5object = {self.h5object.name : self.h5object}\n            ListData = False\n\n        background_counter = 0\n        reference_counter = 0\n        i = 0\n        j = 0\n        for h5object in data:\n            Title = \"A\"\n            variable_int = False\n\n            if 'variable_int_enabled' in list(list(self.h5object.values())[i].attrs.keys()):\n                variable_int = list(self.h5object.values())[i].attrs['variable_int_enabled']\n            if ((variable_int == True) and #Check for variable integration time and that the background_int and reference_int are not none\n                        ((list(self.h5object.values())[i].attrs['background_int'] != list(self.h5object.values())[i].attrs['integration_time'] \n                            and (list(self.h5object.values())[i].attrs['background_int'] != None))\n                        or (list(self.h5object.values())[i].attrs['reference_int'] != list(self.h5object.values())[i].attrs['integration_time'] \n                            and (list(self.h5object.values())[i].attrs['reference_int'] != None)))):\n                if list(self.h5object.values())[i].attrs['background_int'] != None:\n                    if list(self.h5object.values())[i].attrs['reference_int'] != None:\n                        data[i] = (((data[i]-(list(self.h5object.values())[i].attrs['background_constant']+list(self.h5object.values())[i].attrs['background_gradient']*list(self.h5object.values())[i].attrs['integration_time']))/\n                                        (((list(self.h5object.values())[i].attrs['reference']-(list(self.h5object.values())[i].attrs['background_constant']+list(self.h5object.values())[i].attrs['background_gradient']*list(self.h5object.values())[i].attrs['reference_int']))\n                                        *list(self.h5object.values())[i].attrs['integration_time']/list(self.h5object.values())[i].attrs['reference_int']))))\n                    else:\n                        data[i] = data[i]-(list(self.h5object.values())[i].attrs['background_constant']+list(self.h5object.values())[i].attrs['background_gradient']*list(self.h5object.values())[i].attrs['integration_time'])\n                        reference_counter = reference_counter +1\n                \n            else:\n                if 'background' in list(list(self.h5object.values())[i].attrs.keys()):\n                    if ListData == True:\n                        if len(np.array(data[i])) == len(np.array(list(self.h5object.values())[i].attrs['reference'])):\n                            data[i] = data[i] - np.array(list(self.h5object.values())[i].attrs['background'])     \n                    else:\n                        if len(np.array(data)) == len(np.array(list(self.h5object.values())[i].attrs['background'])):\n                                data = data - np.array(list(self.h5object.values())[i].attrs['background'])[:,np.newaxis]       \n                        Title = Title + \" background subtracted\"\n                else:\n                    background_counter = background_counter+1\n                if 'reference' in list(list(self.h5object.values())[i].attrs.keys()):\n                    if ListData == True:\n                        if len(np.array(data[i])) == len(np.array(list(self.h5object.values())[i].attrs['reference'])):\n                            data[i] = (data[i]/(np.array(list(self.h5object.values())[i].attrs['reference'])- np.array(list(self.h5object.values())[i].attrs['background'])))   \n                    else:\n                        if len(np.array(data)) == len(np.array(list(self.h5object.values())[i].attrs['reference'])):\n                            data = (data/(np.array(list(self.h5object.values())[i].attrs['reference'])[:,np.newaxis]- np.array(list(self.h5object.values())[i].attrs['background'])[:,np.newaxis]))\n                    Title = Title + \" referenced\"\n                else:\n                    reference_counter = reference_counter +1\n   #         print i,j,np.max(data) ,self.h5object.values()[i].attrs.keys()\n            if len(list(self.h5object.values())) != len(data):\n                i = int((float(len(list(self.h5object.values())))/len(data))*j)\n                j=j+1\n            else:\n                i = i +1\n            \n        if ListData == False:\n            data = data[0]            \n        data = np.transpose(data)\n        \n            \n        if reference_counter == 0 and background_counter == 0:\n            print(\"All spectrum are referenced and background subtracted\")\n        else:\n            print(\"Number of spectrum not referenced \"+str(reference_counter))\n            print(\"Number of spectrum not background subtracted \"+str(background_counter))\n        Title = Title + \" spectrum\"\n         \n        data[np.where(np.isnan(data))] = 0\n        data[np.where(np.isinf(data))] = 0\n\n\n\n      #  plot.plot(x = np.array(self.h5object.attrs['wavelengths']), y = np.array(h5object),name = h5object.name)\n        labelStyle = {'font-size': '24pt'}\n        vb.setLabel('left', 'Spectrum number',**labelStyle)\n        vb.setLabel('bottom', 'Wavelength (nm)',**labelStyle)\n\n        vb.setTitle(Title,**labelStyle)\n        \n\n        img = pg.ImageItem(data)\n\n        ConvertionC= list(self.h5object.values())[0].attrs['wavelengths'][0]\n        ConvertionM = ((list(self.h5object.values())[0].attrs['wavelengths'][-1] - list(self.h5object.values())[0].attrs['wavelengths'][0])/len(list(self.h5object.values())[0].attrs['wavelengths']))\n\n\n\n        img.translate(ConvertionC,0)\n        img.scale(ConvertionM,1)\n        vb.addItem(img)\n        vb.autoRange(False)\n\n\n        w.setImageItem(img)",
  "def is_suitable(cls, h5object):\n        suitability = 0\n        if isinstance(h5object,dict) == False and isinstance(h5object,h5py.Group) == False:\n            try:\n                if len(h5object.shape) == 1 and (len(h5object)/len(h5object.attrs['wavelengths'])) == 1:\n                    return -1\n            except:\n                return -1\n            h5object = {h5object.name : h5object}\n        \n        for dataset in list(h5object.values()):\n            if not isinstance(dataset, h5py.Dataset):\n                return -1\n            if len(dataset.shape) == 1:\n                suitability = suitability + 10\n                    \n            if len(dataset.shape) > 2:\n                return -1\n      \n            if 'wavelengths' in list(dataset.attrs.keys()):\n                if len(dataset.shape) == 2:\n                    if len(np.array(dataset)[:,0]) < 100:\n                        suitability = suitability + len(h5object)-20\n                    else:\n                        return 1\n                elif ((len(np.array(dataset))/len(dataset.attrs['wavelengths'])))>1 and (len(np.array(dataset))%len(dataset.attrs['wavelengths'])) == 0 :           \n                    suitability = suitability + 50\n                elif len(dataset.attrs['wavelengths']) != len(np.array(dataset)):\n                    print(\"the number of bins does not equal the number of wavelengths!\")\n                    return -1\n                suitability = suitability + 11\n            else:\n                return -1\n             \n            if 'background' in list(dataset.attrs.keys()):\n                suitability = suitability + 10\n            if 'reference' in list(dataset.attrs.keys()):\n                suitability = suitability + 10\n             \n        return suitability",
  "def __init__(self, h5object, parent=None):\n        super(DataRenderer2or3DPG, self).__init__(h5object, parent)\n        pg.setConfigOption('background', 'w')\n        pg.setConfigOption('foreground', 'k')\n        self.layout = QtWidgets.QVBoxLayout()\n        self.setLayout(self.layout)\n        \n\n        self.display_data()",
  "def display_data(self, data=None, lock_aspect=False):\n        if data is None:\n            data = np.array(self.h5object)\n        data[np.where(np.isnan(data))] = 0 \n        img = pg.ImageView()\n        if len(data.shape)==3 and data.shape[2]==3:\n            data = np.transpose(data,axes = (1,0,2))\n        elif len(data.shape)==2:\n            data = np.transpose(data)\n            \n        img.setImage(data)\n        #img.setMinimumSize(950,750) #This seems unhelpful to me - RWB\n        img.view.setAspectLocked(lock_aspect)\n        self.layout.addWidget(img)\n        self.setLayout(self.layout)",
  "def is_suitable(cls, h5object):\n        if not isinstance(h5object, h5py.Dataset):\n            return -1\n        elif len(h5object.shape) == 3:\n            return 31\n        elif len(h5object.shape) == 4 and h5object.shape[3] == 3:\n            return 31\n        elif len(h5object.shape) == 2:\n            return 21\n        elif len(h5object.shape) > 3:\n            return -1\n        else:\n            return -1",
  "def __init__(self, h5object, parent=None):\n        super(JPEGRenderer, self).__init__(h5object, parent)",
  "def display_data(self):\n        import cv2\n        data = cv2.imdecode(np.array(self.h5object), cv2.CV_LOAD_IMAGE_UNCHANGED)\n        DataRenderer2or3DPG.display_data(self, data=data.transpose((1,0,2)), lock_aspect=True)",
  "def is_suitable(cls, h5object):\n        if h5object.attrs.get('compressed_image_format', None) in ['JPEG', 'PNG', ]:\n            return 50\n        if len(getattr(h5object, 'shape', [])) == 1: \n            # Detect the JPEG header directly.  NB this is a work in progress, I don't think it works currently.\n            if all(np.array(h5object[:4]) == np.array([255,216,255,224],dtype=np.uint8)):\n                return 50\n        return -1",
  "def display_data(self):\n        matplotlib.rc('xtick', labelsize=24) \n        matplotlib.rc('ytick', labelsize=24) \n        ax = self.fig.add_subplot(111)\n        ax.plot(self.h5object)\n        ax.set_aspect(\"auto\")\n        ax.relim()\n        ax.autoscale_view()\n        self.fig.canvas.draw()",
  "def is_suitable(cls, h5object):\n        if not isinstance(h5object, h5py.Dataset):\n            return -1\n        if len(h5object.shape) == 1:\n            return 10\n        elif len(h5object.shape) > 1:\n            return -1\n        return -1",
  "def display_data(self):\n        ax = self.fig.add_subplot(111)\n        ax.imshow(self.h5object, aspect=\"auto\", cmap=\"cubehelix\")\n        self.fig.canvas.draw()",
  "def is_suitable(cls, h5object):\n        if not isinstance(h5object, h5py.Dataset):\n            return -1\n        if len(h5object.shape) == 2:\n            return 10\n        elif len(h5object.shape) < 2:\n            return -1\n        else:\n            return -1",
  "def display_data(self):\n        ax = self.fig.add_subplot(111)\n        ax.imshow(self.h5object)\n        self.fig.canvas.draw()",
  "def is_suitable(cls, h5object):\n        if not isinstance(h5object, h5py.Dataset):\n            return -1\n        if len(h5object.shape) == 3 and h5object.shape[2]==3:\n            return 15\n        elif len(h5object.shape) != 3:\n            return -1\n        else:\n            return -1",
  "def display_data(self):\n        if type(self.h5object) == h5py.Dataset:\n            self.h5object = {self.h5object.name : self.h5object}\n        #Perform averaging\n        h5list = {}\n        for h5object in list(self.h5object.values()):  \n            if 'averaging_enabled' in list(h5object.attrs.keys()):\n                if h5object.attrs['averaging_enabled']==True:\n                    ldata = np.average(np.array(h5object)[...],axis = 0)\n                    linedata = ArrayWithAttrs(ldata,attrs = h5object.attrs)\n                    linedata.name = h5object.name\n                    h5list[linedata.name] =linedata\n                else:\n                    h5list[h5object.name] = h5object\n            else:\n                h5list[h5object.name] = h5object\n        self.h5object = h5list\n\n\n   #     if isinstance(self.h5object,dict) or isinstance(self.h5object,h5py.Group):\n   #         pass\n        #take 2D or one datasets and combine them\n        h5list = {}\n        for h5object in list(self.h5object.values()):\n            if len(h5object.shape)==2:\n                for line in range(len(h5object[:,0])):\n                    ldata = np.array(h5object)[line]\n                    linedata = ArrayWithAttrs(ldata,attrs = h5object.attrs)\n                    linedata.name = h5object.name+\"_\"+str(line)\n                    h5list[linedata.name] =linedata\n            else:\n                h5list[h5object.name] = h5object\n        self.h5object = h5list\n   #     elif type(self.h5object) != dict or type(self.h5object) != df.Group or type(self.h5object) != h5py.Group:\n  #      elif type(self.h5object) == h5py.Dataset\n #           self.h5object = {self.h5object.name : self.h5object}\n        #Deal with averaging of spectra\n        plot = self.figureWidget\n        plot.addLegend(offset = (-1,1))\n        icolour = 0\n        for h5object in list(self.h5object.values()):\n            icolour = icolour+1\n            Data = np.array(h5object)\n            Title = \"A\"\n            if 'variable_int_enabled' in list(h5object.attrs.keys()):\n                variable_int = h5object.attrs['variable_int_enabled']\n            else:\n                variable_int =False\n            if ((variable_int == True) and #Check for variable integration time and that the background_int and reference_int are not none\n                        ((h5object.attrs['background_int'] != h5object.attrs['integration_time'] \n                            and (h5object.attrs['background_int'] != None))\n                        or (h5object.attrs['reference_int'] != h5object.attrs['integration_time'] \n                            and (h5object.attrs['reference_int'] != None)))):\n                Title = Title + \" variable\"\n                if h5object.attrs['background_int'] != None:\n                    if h5object.attrs['reference_int'] != None:\n                        Data = (((Data-(h5object.attrs['background_constant']+h5object.attrs['background_gradient']*h5object.attrs['integration_time']))/ \n                                        (((h5object.attrs['reference']-(h5object.attrs['background_constant']+h5object.attrs['background_gradient']*h5object.attrs['reference_int']))\n                                        *h5object.attrs['integration_time']/h5object.attrs['reference_int']))))\n                        Title = Title + \" referenced and background subtracted\"\n                    else:\n                        Data = Data-(h5object.attrs['background_constant']+h5object.attrs['background_gradient']*h5object.attrs['integration_time'])\n                        Title = Title + \" background subtracted\"\n            else:\n                if 'background' in list(h5object.attrs.keys()):\n                    if len(np.array(h5object)) == len(np.array(h5object.attrs['background'])):\n                        Data = Data - np.array(h5object.attrs['background'])\n                        Title = Title + \" background subtracted\"\n                    if 'reference' in list(h5object.attrs.keys()):\n                        if len(np.array(h5object)) == len(np.array(h5object.attrs['reference'])):\n                            Data = (Data/(np.array(h5object.attrs['reference'])- np.array(h5object.attrs['background'])))\n                            Title = Title + \" referenced\"\n            if 'absorption_enabled' in list(h5object.attrs.keys()):\n                if h5object.attrs['absorption_enabled']:\n                    Data = np.log10((1/np.array(Data)))\n            plot.plot(x = np.array(h5object.attrs['wavelengths']), y = np.array(Data),name = h5object.name, pen =(icolour,len(self.h5object)) )\n            Title = Title + \" spectrum\"\n                \n            labelStyle = {'font-size': '24pt'}\n            self.figureWidget.setLabel('left', 'Intensity',**labelStyle)\n            self.figureWidget.setLabel('bottom', 'Wavelength (nm)',**labelStyle)\n            self.figureWidget.setTitle(Title,**labelStyle)",
  "def is_suitable(cls, h5object):\n        suitability = 0\n        if isinstance(h5object,dict) == False and isinstance(h5object,h5py.Group) == False:\n            h5object = {h5object.name : h5object}\n        if not len(list(h5object.values())):\n                return -1\n        for dataset in list(h5object.values()):\n            if not isinstance(dataset, h5py.Dataset):\n                return -1\n            if len(dataset.shape) == 1:\n                suitability = suitability + 10\n                    \n            if len(dataset.shape) > 2:\n                return -1\n      \n            if 'wavelengths' in list(dataset.attrs.keys()):\n                if len(dataset.shape) == 2:\n                    if len(np.array(dataset)[:,0])<20:\n                        suitability = suitability + len(h5object)-20\n                    else:\n                        return 1\n                elif len(dataset.attrs['wavelengths']) != len(np.array(dataset)):\n                    print(\"the number of bins does not equal the number of wavelengths!\")\n                    return -1\n                suitability = suitability + 10\n            else:\n                return -1\n             \n            if 'background' in list(dataset.attrs.keys()):\n                suitability = suitability + 10\n            if 'reference' in list(dataset.attrs.keys()):\n                suitability = suitability + 10 \n        suitability = suitability + 10\n        return suitability",
  "def __init__(self, h5object, parent=None):\n        super(HyperSpec, self).__init__(h5object, parent)\n        pg.setConfigOption('background', 'w')\n        pg.setConfigOption('foreground', 'k')\n        self.layout = QtWidgets.QGridLayout()\n        self.setLayout(self.layout)\n        self.display_data()",
  "def display_data(self):\n        data = np.array(self.h5object)\n        data[np.where(np.isnan(data))] = 0 \n        \n        dims = len(np.shape(data))\n        \n        Images = []\n        midpoints = []\n        \n        for dim in range(dims-1):\n            Images.append(pg.ImageView(view=pg.PlotItem()))\n            midpoints.append(int((np.shape(data)[dim]/2)))\n\n     \n        Imagedata = []\n        \n        Imagedata.append(np.transpose(data[:,:,midpoints[2],:]))\n        Imagedata.append(np.transpose(data[:,midpoints[1],:,:]))\n        Imagedata.append(np.transpose(data[midpoints[0],:,:,:]))\n        \n        XConvertionM = 1\n        YConvertionM = 1        \n        ZConvertionM = 1\n        \n        if len(self.h5object.attrs['x']) > 1:\n           XConvertionM = self.h5object.attrs['x'][1] - self.h5object.attrs['x'][0]\n        if len(self.h5object.attrs['y']) > 1:\n            YConvertionM = self.h5object.attrs['y'][1] - self.h5object.attrs['y'][0]                    \n        if len(self.h5object.attrs['z']) > 1:\n            ZConvertionM = self.h5object.attrs['z'][1] - self.h5object.attrs['z'][0]\n            \n        convertionfactors = [[YConvertionM,XConvertionM],[ZConvertionM,XConvertionM],[ZConvertionM,YConvertionM]]\n        \n        labels = [[\"X\",\"Y\"],[\"X\",\"Z\"],[\"Y\",\"Z\"]]\n                \n        for imgNum in range(len(Imagedata)):\n            if len(Imagedata[imgNum][0,0,:]) == 1:\n                Imagedata[imgNum] = np.swapaxes(Imagedata[imgNum],1,2)\n                con = convertionfactors[imgNum][1]\n                convertionfactors[imgNum][1] = convertionfactors[imgNum][0]\n                convertionfactors[imgNum][0] = con\n                \n                conlabel = labels[imgNum][0]\n                labels[imgNum][0] = labels[imgNum][1]\n                labels[imgNum][1] = conlabel\n\n  \n        \n        for imgNom in range(len(Images)):\n            Images[imgNom].setImage(Imagedata[imgNom],xvals = np.array(self.h5object.attrs['wavelengths']),autoHistogramRange = True)\n      \n\n        \n \n       \n    \n        Images[0].getImageItem().scale(convertionfactors[0][0],convertionfactors[0][1])\n\n        \n        Images[1].getImageItem().scale(convertionfactors[1][0],convertionfactors[1][1])\n        \n        Images[2].getImageItem().scale(convertionfactors[2][0], convertionfactors[2][1])\n\n        \n        \n               \n\n\n        for imgNom in range(len(Images)): \n            Images[imgNom].autoLevels()\n            Images[imgNom].autoRange()\n            Images[imgNom].ui.roiBtn.hide()\n            Images[imgNom].ui.menuBtn.hide() \n            Images[imgNom].setMinimumSize(550,350)\n            Images[imgNom].view.setAspectLocked(False)\n            \n            Images[imgNom].getView().setTitle(labels[imgNom][0]+\"(\"+labels[imgNom][1]+\")\")\n            Images[imgNom].getView().setLabel(\"left\" , labels[imgNom][0])\n            Images[imgNom].getView().setLabel(\"bottom\" , labels[imgNom][1])\n      \n        self.layout.addWidget(Images[0],0,0)\n        self.layout.addWidget(Images[1],0,1)\n        self.layout.addWidget(Images[2],1,0)\n        \n        \n        self.setLayout(self.layout)",
  "def is_suitable(cls, h5object):\n        if not isinstance(h5object, h5py.Dataset):\n            return -1\n        elif len(h5object.shape) == 4 and 'z' in list(h5object.attrs.keys()) and 'y' in list(h5object.attrs.keys()) and 'x' in list(h5object.attrs.keys()):\n            return 30\n        elif len(h5object.shape) > 4:\n            return -1\n        else:\n            return -1",
  "def __init__(self, h5object, parent=None):\n        super(HyperSpec_Alan, self).__init__(h5object, parent)\n        pg.setConfigOption('background', 'w')\n        pg.setConfigOption('foreground', 'k')\n        self.layout = QtWidgets.QGridLayout()\n        self.setLayout(self.layout)\n        self.display_data()",
  "def display_data(self):\n        # A try and except loop to determine the number of hyperspectral image avaible\n        try:\n            original_string = 'hs_image'\n            test_string = original_string\n            num_hyperspec = 1\n            Fail = False\n            while Fail == False:\n                self.h5object[test_string]\n                num_hyperspec = num_hyperspec + 1\n                test_string = original_string+str(num_hyperspec)\n        except KeyError:\n            pass\n        #Creating a list of hyperspec images to put into a the layout\n        Images = []\n        #Calculate the X,Y scales for the images\n        XConvertionM = ((self.h5object['x'][-1] - self.h5object['x'][0])/len(self.h5object['x']))\n        YConvertionM = ((self.h5object['y'][-1] - self.h5object['y'][0])/len(self.h5object['y']))\n        #creating an iterator for the number of hyperspectral images\n        for hyperspec_nom in range(1,num_hyperspec):\n            if hyperspec_nom == 1:\n                hyperspec_nom_str = ''\n            else:\n                hyperspec_nom_str = str(hyperspec_nom)\n                \n            #Grab the correct hyperspec data\n            data = np.transpose(np.array(self.h5object['hs_image'+hyperspec_nom_str]))\n            #Change NaNs to zeros (prevents error)\n            data[0][np.where(np.isnan(data[0]))] = 0 \n        \n            #create image item for current image                 \n            Images.append(pg.ImageView(view=pg.PlotItem()))\n            #Set image\n            Images[hyperspec_nom-1].setImage(data,xvals = np.array(self.h5object['wavelength2']),autoHistogramRange = True)\n            \n     \n            # Formating of the Image\n            Images[hyperspec_nom-1].getImageItem().scale(XConvertionM,YConvertionM)\n            Images[hyperspec_nom-1].autoRange()\n            Images[hyperspec_nom-1].autoLevels()\n            Images[hyperspec_nom-1].ui.roiBtn.hide()\n            Images[hyperspec_nom-1].ui.menuBtn.hide()\n            Images[hyperspec_nom-1].setMinimumSize(550,350)\n        \n       #Image postion within a grid, (with need updating if using mroe than 4 spectrometers)\n        positions = [[0,0],[0,1],[1,0],[1,1]]    \n        #Add Images to layout\n        for hyperspec_nom in range(num_hyperspec-1): \n            self.layout.addWidget(Images[hyperspec_nom],positions[hyperspec_nom][0],positions[hyperspec_nom][1])\n\n        \n        self.setLayout(self.layout)",
  "def is_suitable(cls, h5object):\n        suitability = 0\n        try:\n            h5object['hs_image']\n            suitability = suitability + 10\n        except KeyError:\n            return -1\n            \n        try:\n            h5object['wavelength']\n            suitability = suitability + 10\n        except KeyError:\n            return -1\n            \n        try:\n            h5object['y']\n            suitability = suitability + 10\n        except KeyError:\n            return -1\n            \n        try:\n            h5object['x']\n            suitability = suitability + 10\n        except KeyError:\n            return -1  \n            \n        return suitability",
  "def display_data(self):\n        g = self.h5object\n        zscan = g['z_scan']\n        dz = g['z_scan'].attrs.get('dz', np.arange(zscan.shape[0]))\n        spectrum = np.mean(zscan, axis=0)\n        wavelengths = zscan.attrs.get(\"wavelengths\")\n        spectrum_range = slice(None)\n        try:\n            background = zscan.attrs.get(\"background\")\n            spectrum -= background #we'll fail here if there was no background recorded\n            reference = zscan.attrs.get(\"reference\")\n            spectrum /= (reference - background) #if there's a reference, apply it\n            spectrum_range = reference > (np.max(reference)/10)\n        except:\n            pass # if reference/background are missing, ignore them.\n        import matplotlib.gridspec as gridspec\n        gs = gridspec.GridSpec(2,2)\n        ax0 = self.fig.add_subplot(gs[0,0])  # plot the overview image\n        ax0.imshow(g['camera_image'], extent=(0, 1, 0, 1), aspect=\"equal\")\n        ax0.plot([0.5, 0.5], [0.2, 0.8], \"w-\") #crosshair\n        ax0.plot([0.2, 0.8], [0.5, 0.5], \"w-\")\n        ax0.get_xaxis().set_visible(False)\n        ax0.get_yaxis().set_visible(False)\n        ax0.set_title(\"Particle Image\")\n\n        ax1 = self.fig.add_subplot(gs[0,1])  # plot the z stack\n        ax1.imshow(zscan, extent=(wavelengths.min(), wavelengths.max(), dz.min(), dz.max()), aspect=\"auto\", cmap=\"cubehelix\")\n        ax1.set_xlabel(\"Wavelength/nm\")\n        ax1.set_ylabel(\"Z/um\")\n\n        ax2 = self.fig.add_subplot(gs[1,0:2])  # plot the spectrum\n        ax2.plot(wavelengths[spectrum_range], spectrum[spectrum_range])\n        ax2.set_xlabel(\"Wavelength/nm\")\n        ax2.set_ylabel(\"Z-averaged Spectrum\")\n        self.fig.canvas.draw()",
  "def is_suitable(cls, h5object):\n        # This relies on sensible exception handling: if an exception occurs here, the renderer\n        # will be deemed unsuitable (!)\n\n        # First, make sure we've got the right datasets (NB this also raises an exception if it's not a group)\n        g = h5object\n        keys = getattr(g, 'keys', list)()\n        for k in ['camera_image', 'z_scan']:\n            if k not in keys:\n                # print(\"missing dataset {}, can't be a particle...\".format(k))\n                return -1\n        try:\n            assert g['camera_image'].shape[0] > 10\n            assert g['camera_image'].shape[1] > 10\n            assert len(g['z_scan'].shape) == 2\n        except: return -1\n        return 500",
  "def __init__(self, h5object, parent=None):\n        super(PumpProbeShifted, self).__init__(h5object, parent)\n        pg.setConfigOption('background', 'w')\n        pg.setConfigOption('foreground', 'k')\n        self.layout = QtWidgets.QGridLayout()\n        self.setLayout(self.layout)\n        self.display_data()",
  "def display_data(self):\n        if isinstance(self.h5object,dict) == False and isinstance(self.h5object,h5py.Group) == False:\n            self.h5object = {self.h5object.name : self.h5object}\n        icolour = 0    \n        Plots = []\n        axes ={0 : 'X',1 : 'Y', 2 : 'R'}\n        \n\n        for axis in axes:\n            Plots.append(pg.PlotWidget())\n       \n        for plot in Plots:\n            plot.addLegend(offset = (-1,1))\n        \n        stepperoffset = -5.0\n        \n        for h5object in list(self.h5object.values()):\n            for axis in list(axes.keys()):\n                data = np.array(h5object)\n                data[np.where(data[:,7]%2 != 0),5] +=  stepperoffset\n                data[:,5] = -1*(data[:,5]-(864.0))\n     \n                Plots[axis].plot(x = data[:,5], y = data[:,axis],name = h5object.name,pen =(icolour,len(self.h5object)))\n                Plots[axis].setLabel('left',axes[axis]+\" (V)\")\n                Plots[axis].setLabel('bottom', 'Time (ps)')\n            icolour = icolour + 1        \n        \n        \n\n        self.layout.addWidget(Plots[0],0,0)\n        self.layout.addWidget(Plots[1],0,1)\n        self.layout.addWidget(Plots[2],1,0)",
  "def change_in_stepperoffset(self):\n        print(\"HI\")",
  "def is_suitable(cls, h5object):\n        suitability = 0\n        if isinstance(h5object,dict) == False and isinstance(h5object,h5py.Group) == False:\n            h5object = {h5object.name : h5object}\n            \n        for dataset in list(h5object.values()):\n            if not isinstance(dataset, h5py.Dataset):\n                return -1\n            if len(dataset.shape) == 2:\n                if dataset.shape[1] == 8:\n                    suitability = suitability + 11\n                else:\n                    return -1\n            else:\n                return -1\n            if 'repeats' in list(dataset.attrs.keys()):\n                suitability = suitability + 50\n            if 'start' in list(dataset.attrs.keys()):\n                suitability = suitability + 50\n            if 'finish' in list(dataset.attrs.keys()):\n                suitability = suitability + 50\n            if 'stepsize' in list(dataset.attrs.keys()):\n                suitability = suitability + 20\n            if 'velocity' in list(dataset.attrs.keys()):\n                suitability = suitability + 20      \n            if 'acceleration' in list(dataset.attrs.keys()):\n                suitability = suitability + 20    \n            if 'filter' in list(dataset.attrs.keys()):\n                suitability = suitability + 20      \n            if 'sensitivity' in list(dataset.attrs.keys()):\n                suitability = suitability + 20    \n        return suitability",
  "def __init__(self, h5object, parent=None):\n        super(PumpProbeRaw, self).__init__(h5object, parent)\n        pg.setConfigOption('background', 'w')\n        pg.setConfigOption('foreground', 'k')\n        self.layout = QtWidgets.QGridLayout()\n        self.setLayout(self.layout)\n        self.display_data()",
  "def display_data(self):\n        if isinstance(self.h5object,dict) == False and isinstance(self.h5object,h5py.Group) == False:\n            self.h5object = {self.h5object.name : self.h5object}\n        icolour = 0    \n        Plots = []\n        axes ={0 : 'X',1 : 'Y', 2 : 'R'}\n        \n\n        for axis in axes:\n            Plots.append(pg.PlotWidget())\n       \n        for plot in Plots:\n            plot.addLegend(offset = (-1,1))\n        \n   #     stepperoffset = -5.0\n        \n        for h5object in list(self.h5object.values()):\n            for axis in list(axes.keys()):\n                data = np.array(h5object)\n          #      data[np.where(data[:,7]%2 != 0),5] +=  stepperoffset\n        #        data[:,5] = -1*(data[:,5]-(864.0))\n\n                Plots[axis].plot(x = data[:,6], y = data[:,axis],name = h5object.name,pen =(icolour,len(self.h5object)))\n                Plots[axis].setLabel('left',axes[axis]+\" (V)\")\n                Plots[axis].setLabel('bottom', 'Time (ps)')\n            icolour = icolour + 1        \n        \n        \n\n        self.layout.addWidget(Plots[0],0,0)\n        self.layout.addWidget(Plots[1],0,1)\n        self.layout.addWidget(Plots[2],1,0)",
  "def is_suitable(cls, h5object):\n        suitability = 0\n        if isinstance(h5object,dict) == False and isinstance(h5object,h5py.Group) == False:\n            h5object = {h5object.name : h5object}\n           \n        for dataset in list(h5object.values()):\n            if not isinstance(dataset, h5py.Dataset):\n                return -1\n            if len(dataset.shape) == 2:\n                if dataset.shape[1] == 8:\n                    suitability = suitability + 11\n                else:\n                    return -1\n            else:\n                return -1\n            if 'repeats' in list(dataset.attrs.keys()):\n                suitability = suitability + 50\n            if 'start' in list(dataset.attrs.keys()):\n                suitability = suitability + 50\n            if 'finish' in list(dataset.attrs.keys()):\n                suitability = suitability + 50\n            if 'stepsize' in list(dataset.attrs.keys()):\n                suitability = suitability + 20\n            if 'velocity' in list(dataset.attrs.keys()):\n                suitability = suitability + 20      \n            if 'acceleration' in list(dataset.attrs.keys()):\n                suitability = suitability + 20    \n            if 'filter' in list(dataset.attrs.keys()):\n                suitability = suitability + 20      \n            if 'sensitivity' in list(dataset.attrs.keys()):\n                suitability = suitability + 20    \n        return suitability",
  "def __init__(self, h5object, parent=None):\n        super(PumpProbeRawXOnly, self).__init__(h5object, parent)\n        pg.setConfigOption('background', 'w')\n        pg.setConfigOption('foreground', 'k')\n        self.layout = QtWidgets.QGridLayout()\n        self.setLayout(self.layout)\n        self.display_data()",
  "def display_data(self):\n        if isinstance(self.h5object,dict) == False and isinstance(self.h5object,h5py.Group) == False:\n            self.h5object = {self.h5object.name : self.h5object}\n        icolour = 0    \n        Plots = []\n        axes ={0 : 'X'}\n        \n\n        for axis in axes:\n            Plots.append(pg.PlotWidget())\n       \n        for plot in Plots:\n            plot.addLegend(offset = (-1,1))\n        \n        stepperoffset = -5.0\n        \n        for h5object in list(self.h5object.values()):\n            for axis in list(axes.keys()):\n                data = np.array(h5object)\n                data[np.where(data[:,7]%2 != 0),5] +=  stepperoffset\n                data[:,5] = -1*(data[:,5]-(864.0))\n                data[:,0] = data[:,0]/8.0\n\n                Plots[axis].plot(x = data[:,5], y = data[:,axis],name = h5object.name,pen =(icolour,len(self.h5object)))\n                Plots[axis].setLabel('left',\"dV/V\")\n                Plots[axis].setLabel('bottom', 'Time (ps)')\n            icolour = icolour + 1        \n        \n        \n        self.layout.addWidget(Plots[0],0,0)",
  "def is_suitable(cls, h5object):\n        suitability = 0\n        if isinstance(h5object,dict) == False and isinstance(h5object,h5py.Group) == False:\n            h5object = {h5object.name : h5object}       \n            \n        for dataset in list(h5object.values()):\n            if not isinstance(dataset, h5py.Dataset):\n                return -1\n            if len(dataset.shape) == 2:\n                if dataset.shape[1] == 8:\n                    suitability = suitability + 11\n                else:\n                    return -1\n            else:\n                return -1\n            if 'repeats' in list(dataset.attrs.keys()):\n                suitability = suitability + 50\n            if 'start' in list(dataset.attrs.keys()):\n                suitability = suitability + 50\n            if 'finish' in list(dataset.attrs.keys()):\n                suitability = suitability + 50\n            if 'stepsize' in list(dataset.attrs.keys()):\n                suitability = suitability + 20\n            if 'velocity' in list(dataset.attrs.keys()):\n                suitability = suitability + 20      \n            if 'acceleration' in list(dataset.attrs.keys()):\n                suitability = suitability + 20    \n            if 'filter' in list(dataset.attrs.keys()):\n                suitability = suitability + 20      \n            if 'sensitivity' in list(dataset.attrs.keys()):\n                suitability = suitability + 20    \n        return suitability",
  "def __init__(self, h5object, parent=None):\n        super(PumpProbeX_loops, self).__init__(h5object, parent)\n        pg.setConfigOption('background', 'w')\n        pg.setConfigOption('foreground', 'k')\n        self.layout = QtWidgets.QGridLayout()\n        self.setLayout(self.layout)\n        self.display_data()",
  "def display_data(self):\n        if isinstance(self.h5object,dict) == False and isinstance(self.h5object,h5py.Group) == False:\n            self.h5object = {self.h5object.name : self.h5object}\n        icolour = 0    \n        Plots = []\n        axes ={0 : 'X'}\n        \n\n        for axis in axes:\n            Plots.append(pg.PlotWidget())\n       \n        for plot in Plots:\n            plot.addLegend(offset = (-1,1))\n        \n        stepperoffset = -5.0\n        \n        for h5object in list(self.h5object.values()):\n            for axis in list(axes.keys()):\n                data = np.array(h5object)\n                data[np.where(data[:,7]%2 != 0),5] +=  stepperoffset\n                data[:,5] = -1*(data[:,5]-(864.0))\n                data[:,0] = data[:,0]/8.0\n             \n                for icolour in range(int(np.max(data[:,7])+1)):\n                    Plots[axis].plot(x = data[np.where(data[:,7]==icolour)[0],5], y = data[np.where(data[:,7]==icolour)[0],axis],name = h5object.name,pen =(icolour,np.max(data[:,7])+1))\n                Plots[axis].setLabel('left',\"dV/V\")\n                Plots[axis].setLabel('bottom', 'Time (ps)')\n            icolour = icolour + 1        \n        \n        \n\n        self.layout.addWidget(Plots[0],0,0)",
  "def is_suitable(cls, h5object):\n        suitability = 0\n        if isinstance(h5object,dict) == False and isinstance(h5object,h5py.Group) == False:\n            h5object = {h5object.name : h5object}\n            \n        for dataset in list(h5object.values()):\n            if not isinstance(dataset, h5py.Dataset):\n                return -1\n            if len(dataset.shape) == 2:\n                if dataset.shape[1] == 8:\n                    suitability = suitability + 11\n                else:\n                    return -1\n            else:\n                return -1\n            if 'repeats' in list(dataset.attrs.keys()):\n                suitability = suitability + 50\n            if 'start' in list(dataset.attrs.keys()):\n                suitability = suitability + 50\n            if 'finish' in list(dataset.attrs.keys()):\n                suitability = suitability + 50\n            if 'stepsize' in list(dataset.attrs.keys()):\n                suitability = suitability + 20\n            if 'velocity' in list(dataset.attrs.keys()):\n                suitability = suitability + 20      \n            if 'acceleration' in list(dataset.attrs.keys()):\n                suitability = suitability + 20    \n            if 'filter' in list(dataset.attrs.keys()):\n                suitability = suitability + 20      \n            if 'sensitivity' in list(dataset.attrs.keys()):\n                suitability = suitability + 20    \n        return suitability",
  "def autocorrelation(x,mode=\"fft\"):\n        import scipy.signal\n        x=np.asarray(x)\n        n = len(x)\n        mean = x.mean()\n        if mode == \"fft\":\n            r = scipy.signal.correlate(x,x,mode=\"full\",method=\"fft\")[-n:]\n            outp = np.divide(r,np.multiply(mean**2,np.arange(n,0,-1)))\n            return outp\n        elif mode == \"direct\":\n            r = np.correlate(x, x, mode = 'full')[-n:]\n            outp =  np.divide(r,np.multiply(mean**2,np.arange(n,0,-1)))\n            return outp",
  "def make_Xdata(dataset,N):\n        #Pulls out metadata from the datasets in the case when the dataset is 1D\n        # reconstructs the sampling times, assuming equidistant - halves space requirements\n        Xdata = np.arange(N)\n        keys = [\"dt\", \"frequency\"]\n        for k in keys:\n            if k in list(dataset.attrs.keys()):\n                if k == \"dt\":\n                    try:\n                        dt = float(dataset.attrs[k])\n                        return dt*Xdata,\"Log10(Time) [s]\"\n                    except: pass\n                elif k == \"frequency\":\n                    try:\n                        dt = 1.0/float(dataset.attrs[k])\n                        return dt*Xdata,\"Log10(Time) [s]\"\n                    except: pass\n            else:\n                return Xdata,\"Log10(ArrayIndex)\"",
  "def display_data(self):\n        if not hasattr(self.h5object, \"values\"):\n            # If we have only one item, treat it as a group containing that item.\n            self.h5object = {self.h5object.name: self.h5object}\n        icolour = 0    \n        self.figureWidget.addLegend(offset = (-1,1))\n\n        #Default X and Y labels\n        Xlabel = 'Log10(X axis)'\n        Ylabel = 'ACF(Y axis)'\n        for dataset in list(self.h5object.values()):\n\n            #Try to pull out axes label annotations from metadata + reformat them\n            try:\n                Xlabel = \"Log10({0})\".format(dataset.attrs['X label'])\n            except:\n                pass\n            try:\n                Ylabel = \"ACF({0})\".format(dataset.attrs['Y label'])\n            except:\n                pass\n            #Pull out data\n            try:\n                if np.shape(dataset)[0] == 2 or np.shape(dataset)[1] == 2:\n                    Xdata = np.array(dataset)[0]\n                    Ydata = np.array(dataset)[1] \n                else:\n                    Ydata = np.array(dataset)\n                    #no xdata stores - generate our own\n                    Xdata,Xlabel = AutocorrelationRenderer.make_Xdata(dataset, len(Ydata))\n            except IndexError:\n                #no xdata stores - generate our own\n                Ydata = np.array(dataset)\n                Xdata,Xlabel = AutocorrelationRenderer.make_Xdata(dataset, len(Ydata))\n\n            #Final transform prior to plotting:\n            xs = np.log10(Xdata[1:])\n            ys = AutocorrelationRenderer.autocorrelation(Ydata)[1:]\n            #plot\n            self.figureWidget.plot(x = xs, y = ys,name = dataset.name, pen =(icolour,len(self.h5object)))\n            icolour = icolour + 1\n            \n        labelStyle = {'font-size': '24pt'}\n        #set axes labels\n        self.figureWidget.setLabel('bottom', Xlabel, **labelStyle)\n        self.figureWidget.setLabel('left', Ylabel, **labelStyle)",
  "def is_suitable(cls, h5object):\n        if not hasattr(h5object, \"values\"):\n            # If we have only one item, treat it as a group containing that item.\n            h5object = {h5object.name: h5object}\n        if not len(list(h5object.values())):\n            return -1\n        for dataset in list(h5object.values()):\n            # Check that all datasets selected are either 1D or Nx2 or 2xN\n            assert isinstance(dataset, h5py.Dataset)\n            #autocorrelation functions are only for the adlink9812 card\n            if not (dataset.attrs.get(\"device\", None)==\"adlink9812\"):\n                return -1\n            try:\n                assert len(dataset.shape) == 1\n            except:\n                assert len(dataset.shape) == 2\n                assert np.any(np.array(dataset.shape) == 2)\n\n        return 14",
  "def qInitResources():\n    QtCore.qRegisterResourceData(0x01, qt_resource_struct, qt_resource_name, qt_resource_data)",
  "def qCleanupResources():\n    QtCore.qUnregisterResourceData(0x01, qt_resource_struct, qt_resource_name, qt_resource_data)",
  "def strip_suffices(name, suffices=[]):\n    \"\"\"strip a string from the end of a name, if it's present.\"\"\"\n    for s in suffices:\n        if name.endswith(s):\n            return name[:-len(s)]\n    return name",
  "def first_object_with_attr(objects, name, raise_exception=True):\n    \"\"\"Return the first object from a list that has the given attribute.\n    \n    Raise an exception if none of them has the object, if raise_exception\n    is True, otherwise return None.\n    \"\"\"\n    for obj in objects:\n        if hasattr(obj, name):\n            return obj\n    if raise_exception:\n        raise AttributeError(\"None of the supplied objects had attribute '{0}'\".format(name))\n    else:\n        return None",
  "class UiTools(object):\n    \"\"\"Methods useful to inherit when creating Qt user interfaces.\"\"\"\n    def load_ui_from_file(self, current_file, filename):\n        \"\"\"Load a form from a Qt Designer file, into the current object.\n        \n        Usually current_file should just be __file__, if the ui file is located\n        in the same directory as the python module you're writing.  Filename\n        is the UI file.\"\"\"\n        uic.loadUi(os.path.join(os.path.dirname(current_file), filename), self)\n        \n    def replace_widget(self, layout, old_widget, new_widget, **kwargs):\n        if isinstance(layout, QtWidgets.QGridLayout):\n            index = layout.indexOf(old_widget)\n            position = layout.getItemPosition(index)\n            layout.removeWidget(old_widget)\n            old_widget.setParent(None)\n            layout.addWidget(new_widget, *position, **kwargs)\n            #new_widget.setParent(self)\n        else:\n            index = layout.indexOf(old_widget)\n            layout.removeWidget(old_widget)\n            old_widget.setParent(None)\n            layout.insertWidget(index, new_widget, **kwargs)\n        return new_widget\n\n    def check_state(self, *args, **kwargs):\n        sender = self.sender()\n        validator = sender.validator()\n        state = validator.validate(sender.text(), 0)[0]\n        if state == QtGui.QValidator.Acceptable:\n            color = '#c4df9b'  # green\n        elif state == QtGui.QValidator.Intermediate:\n            color = '#fff79a'  # yellow\n        else:\n            color = '#f6989d'  # red\n        sender.setStyleSheet('QLineEdit { background-color: %s }' % color)\n        return True if state == QtGui.QValidator.Acceptable else False\n\n    def on_text_change(self, text):\n        \"\"\"This method makes it easy to validate text input.\n        \n        TODO: instructions on how to use it!\"\"\"\n        sender = self.sender()\n        if sender.validator() is not None:\n            state = sender.validator().validate(text, 0)[0]\n            if state != QtGui.QValidator.Acceptable:\n                return False\n        return sender\n    \n    def auto_connect_by_name(self, \n                             controlled_object=None, \n                             controlled_objects=[], \n                             control_self=True, \n                             verbose=False,\n                             ):\n        \"\"\"Try to intelligently connect up widgets to an object's properties.\n        \n        Enumerate widgets of supported types, and connect them to properties\n        of the object with the same name.  The object in question is the\n        `controlled object` parameter, and multiple objects can be searched\n        in order - first `controlled_object`, then `controlled_objects`, then\n        this object (if control_self is True).\n        \n        The exception to this is buttons: they look in `self` first of all, \n        then try the list of controlled objects.\n        \n        e.g. if there's a button called \"save_button\", we'll first try to\n        connect self.save_button.clicked to self.save, then (if a controleld\n        object is specified) to self._controlled_object.save.\n        \n        \"\"\"\n        self.slots_to_update_properties = {} # holds callback functions to \n                                # update properties when their controls change.\n        self.callbacks_to_update_controls = {} # holds callback functions to\n                                # update controls when their properties change.\n        if controlled_object is not None:\n            controlled_objects = [controlled_object] + controlled_objects\n        if control_self:\n            controlled_objects = controlled_objects + [self]\n        \n        # Connect buttons to methods with the same name\n        for button in self.findChildren(QtWidgets.QPushButton):\n            name = strip_suffices(button.objectName(), [\"_button\",\"_pushButton\",\"Button\"])\n            try:\n                # look for the named function first in this object, then in the controlled objects\n                obj = first_object_with_attr([self] + controlled_objects, name)\n                action=getattr(obj, name)\n                assert callable(action), \"To call it from a button, it must be callable!\"\n                button.clicked.connect(action)\n                if verbose:\n                    print(\"connected button '{0}' to {1}\".format(name, action))\n            except:\n                if verbose:\n                    print(\"didn't connect button with name '%s'\" % name)    \n        \n        # Now, we try to connect properties with their controls.  This only\n        # works for the most common controls, defined in \n        # auto_connectable_controls\n        \n        # Connect controls to properties with the same name\n        for control_type, c in list(auto_connectable_controls.items()):\n            for control in self.findChildren(c['qt_type']):\n                # print(control)\n                name = strip_suffices(control.objectName(), c['suffices'])\n                try:\n                    # look for the named property on the controlled objects\n                    obj = first_object_with_attr(controlled_objects, name)\n                    assert getattr(obj, name) is not control, \"Didn't connect\"\\\n                        \" the object, as it would have overwritten itself!\"\n                    \n                    # make a function to update the property, and keep track of it.\n                    control_changed = c['control_change_handler'](obj, name)\n                    getattr(control, c['control_change_slot_name']).connect(control_changed)\n                    self.slots_to_update_properties[name] = control_changed\n                    \n                    # Also try to register for updates in the other direction\n                    # using NotifiedProperties\n                    update_handler = c['property_change_handler'](control)\n                    try:\n                        register_for_property_changes(obj, name, update_handler)\n                        self.callbacks_to_update_controls[name] = update_handler\n                    except:\n                        if verbose:\n                            print(\"Couldn't register for updates on {0}, perhaps \"\\\n                                   \"it's not a NotifiedProperty?\".format(name))\n                    \n                    # whether or not it's a NotifiedProperty, we can at least \n                    # try to ensure we *start* with the same values!\n                    try:\n                        update_handler(getattr(obj, name))\n                        # this should fail if the property doesn't exist...\n                    except:\n                        if verbose:\n                            print(\"Failed to initialise {0}, perhaps there's \"\\\n                                   \"no matching property...\".format(name))\n                            \n                    \n                    if verbose:\n                        print(\"connected {0} '{1}' to {2}\".format(control_type, \n                                 name, \"UI\" if obj is self else \"target\"))\n                except Exception as e:\n                    if verbose:\n                        print(\"didn't connect {0} '{1}'\".format(control_type, name))\n                        print(e)\n\n    def save_settings(self, settings, prefix=''):\n        \"\"\"Following https://stackoverflow.com/questions/23279125/python-pyqt4-functions-to-save-and-restore-ui-widget-values\n        :param ui:\n        :param settings:\n        :return:\n        \"\"\"\n\n        for _, obj in inspect.getmembers(self):\n            if isinstance(obj, QtWidgets.QComboBox):\n                wdgt_name = obj.objectName()\n                try:\n                    index = obj.currentIndex()  # get current index from combobox\n                    value = obj.itemText(index)  # get the text for current index\n                    settings.setValue('/'.join([prefix, wdgt_name]), value)  # save combobox selection to registry\n                except Exception as e:\n                    print('Failed saving %s because: %s' % ('/'.join([prefix, wdgt_name]), e))\n\n            elif isinstance(obj, QtWidgets.QLineEdit):\n                wdgt_name = obj.objectName()\n                try:\n                    value = obj.text()\n                    settings.setValue('/'.join([prefix, wdgt_name]),\n                                      value)  # save ui values, so they can be restored next time\n                except Exception as e:\n                    print('Failed saving %s because: %s' % ('/'.join([prefix, wdgt_name]), e))\n\n            elif isinstance(obj, QtWidgets.QCheckBox):\n                wdgt_name = obj.objectName()\n                try:\n                    value = obj.isChecked()\n                    settings.setValue('/'.join([prefix, wdgt_name]), value)\n                except Exception as e:\n                    print('Failed saving %s because: %s' % ('/'.join([prefix, wdgt_name]), e))\n\n    def load_settings(self, settings, prefix=''):\n\n        for _, obj in inspect.getmembers(self):\n            if isinstance(obj, QtWidgets.QComboBox):\n                wdgt_name = obj.objectName()\n                try:\n                    value = settings.value('/'.join([prefix, wdgt_name]))\n                    if value == \"\":\n                        continue\n                    index = obj.findText(value)  # get the corresponding index for specified string in combobox\n\n                    if index == -1:  # add to list if not found\n                        obj.insertItems(0, [value])\n                        index = obj.findText(value)\n                        obj.setCurrentIndex(index)\n                    else:\n                        obj.setCurrentIndex(index)  # preselect a combobox value by index\n                except Exception as e:\n                    print('Failed saving %s because: %s' % ('/'.join([prefix, wdgt_name]), e))\n\n            elif isinstance(obj, QtWidgets.QLineEdit):\n                wdgt_name = obj.objectName()\n                try:\n                    value = settings.value('/'.join([prefix, wdgt_name]))  # get stored value from registry\n                    obj.setText(value)  # restore lineEditFile\n                except Exception as e:\n                    print('Failed saving %s because: %s' % ('/'.join([prefix, wdgt_name]), e))\n\n            elif isinstance(obj, QtWidgets.QCheckBox):\n                wdgt_name = obj.objectName()\n                try:\n                    value = settings.value('/'.join([prefix, wdgt_name]))  # get stored value from registry\n                    if value is not None:\n                        obj.setCheckState(value)  # restore checkbox\n                except Exception as e:\n                    print('Failed saving %s because: %s' % ('/'.join([prefix, wdgt_name]), e))",
  "class QuickControlBox(QtWidgets.QGroupBox, UiTools):\n    \"A groupbox that can quickly add controls that synchronise with properties.\"\n    def __init__(self, title=\"Quick Settings\", *args, **kwargs):\n        super(QuickControlBox, self).__init__(*args, **kwargs)\n        self.setTitle(title)\n        self.setLayout(QtWidgets.QFormLayout())\n        self.controls = dict()\n    \n    def add_doublespinbox(self, name, vmin=-float(\"inf\"), vmax=float(\"inf\"), singlestep=1.,):\n        \"\"\"Add a floating-point spin box control.\"\"\"\n        sb = QtWidgets.QDoubleSpinBox()\n        self.controls[name] = sb\n        sb.setObjectName(name + \"_spinbox\")\n        sb.setMinimum(vmin)\n        sb.setMaximum(vmax)\n        sb.setSingleStep(singlestep)\n        sb.setKeyboardTracking(False)\n        self.layout().addRow(name.title(), sb)\n    \n    def add_spinbox(self, name, vmin=-2**31, vmax=2**31-1, singlestep=1):\n        \"\"\"Add a floating-point spin box control.\"\"\"\n        sb = QtWidgets.QSpinBox()\n        self.controls[name] = sb\n        sb.setObjectName(name + \"_spinbox\")\n        sb.setMinimum(vmin)\n        sb.setMaximum(vmax)\n        sb.setSingleStep(singlestep)\n        sb.setKeyboardTracking(False)\n        self.layout().addRow(name.title(), sb)\n        \n    def add_lineedit(self, name):\n        \"\"\"Add a single-line text box control.\"\"\"\n        le = QtWidgets.QLineEdit()\n        self.controls[name] = le\n        le.setObjectName(name + \"_lineedit\")\n        self.layout().addRow(name.title(), le)\n        \n    def add_button(self, name, title=None):\n        \"\"\"Add a button.\"\"\"\n        if title is None:\n            title = name.title()\n        button = QtWidgets.QPushButton()\n        self.controls[name] = button\n        button.setObjectName(name + \"_button\")\n        button.setText(title)\n        self.layout().addRow(button)\n        \n    def add_checkbox(self, name, title=None):\n        if title is None:\n            title = name.title()\n        checkbox = QtWidgets.QCheckBox()\n        self.controls[name] = checkbox\n        checkbox.setObjectName(name + \"_checkbox\")\n        checkbox.setText(title)\n        self.layout().addRow(\"\", checkbox)\n        \n    def add_combobox(self, name,options, title=None):\n        if title is None:\n            title = name.title()\n        combobox = QtWidgets.QComboBox()\n        for option in options:\n            combobox.addItem(option)\n\n        self.controls[name] = combobox\n        combobox.setObjectName(name + \"_combobox\")\n        self.layout().addRow(title, combobox)",
  "def control_change_handler(conversion=lambda x: x):\n    \"\"\"Generate a function that produces callback functions.\n    \n    This function returns another function, which makes functions.  Sorry.\n    \n    The function returned by this function will have a docstring (!), it\n    takes in an object and a property name, and returns a callback function\n    that can be used to update a property when a Qt control changes.\n    \n    conversion (optional) specifies a function that converts between the\n    data type returned by Qt and the data type expected by the property.\n    \"\"\"\n    def handler_generator(obj, name):\n        \"\"\"Generate a function to update a property when a Qt control changes.\n        \n        Arguments:\n        obj: object\n            The object to which the property is attached\n        name: string\n            The name of the property to update\n        \"\"\"\n        def update_property(value):\n            try:\n                setattr(obj, name, conversion(value))\n            except AttributeError:\n                print(name,'has no setter?')\n        return update_property\n    return handler_generator",
  "def property_change_handler(value_name, \n                            conversion=lambda x: x, \n                            setter_name=None, \n                            getter_name=None):\n    \"\"\"Generate a function that produces callback functions.\n    \n    These callback functions are for properties changing, and update controls,\n    but otherwise see `control_change_handler`.\n    \n    value_name: string\n        The name of the Qt property representing the control's value\n    conversion: function (optional)\n        A function to convert between the property's value and the control's\n    setter_name: string\n        The name of the setter method called to change the value.  Usually this\n        can be left as the default, which uses ``setName`` where value_name is\n        name.\n    getter_name: string\n        The name of the getter method called to retrieve the value.  Usually\n        this can be omitted as the getter name is the same as the value_name.\n    \"\"\"\n    if setter_name is None:\n        setter_name = \"set\" + value_name[0].upper() + value_name[1:]\n    if getter_name is None:\n        getter_name = value_name\n    def handler_generator(control):\n        \"\"\"Generate a function to update a control when a property changes.\"\"\"\n        # first get hold of functions to get and set the control's value\n        getter = getattr(control, getter_name)\n        setter = getattr(control, setter_name)\n        def update_control(value):\n            if getter() != conversion(value):\n                # If we're syncing in both directions, this is important to\n                # avoid infinite loops.  Qt is reasonably good about doing this\n                # but let's do belt-and-braces for safety.\n                setter(conversion(value))\n        return update_control\n    return handler_generator",
  "def load_ui_from_file(self, current_file, filename):\n        \"\"\"Load a form from a Qt Designer file, into the current object.\n        \n        Usually current_file should just be __file__, if the ui file is located\n        in the same directory as the python module you're writing.  Filename\n        is the UI file.\"\"\"\n        uic.loadUi(os.path.join(os.path.dirname(current_file), filename), self)",
  "def replace_widget(self, layout, old_widget, new_widget, **kwargs):\n        if isinstance(layout, QtWidgets.QGridLayout):\n            index = layout.indexOf(old_widget)\n            position = layout.getItemPosition(index)\n            layout.removeWidget(old_widget)\n            old_widget.setParent(None)\n            layout.addWidget(new_widget, *position, **kwargs)\n            #new_widget.setParent(self)\n        else:\n            index = layout.indexOf(old_widget)\n            layout.removeWidget(old_widget)\n            old_widget.setParent(None)\n            layout.insertWidget(index, new_widget, **kwargs)\n        return new_widget",
  "def check_state(self, *args, **kwargs):\n        sender = self.sender()\n        validator = sender.validator()\n        state = validator.validate(sender.text(), 0)[0]\n        if state == QtGui.QValidator.Acceptable:\n            color = '#c4df9b'  # green\n        elif state == QtGui.QValidator.Intermediate:\n            color = '#fff79a'  # yellow\n        else:\n            color = '#f6989d'  # red\n        sender.setStyleSheet('QLineEdit { background-color: %s }' % color)\n        return True if state == QtGui.QValidator.Acceptable else False",
  "def on_text_change(self, text):\n        \"\"\"This method makes it easy to validate text input.\n        \n        TODO: instructions on how to use it!\"\"\"\n        sender = self.sender()\n        if sender.validator() is not None:\n            state = sender.validator().validate(text, 0)[0]\n            if state != QtGui.QValidator.Acceptable:\n                return False\n        return sender",
  "def auto_connect_by_name(self, \n                             controlled_object=None, \n                             controlled_objects=[], \n                             control_self=True, \n                             verbose=False,\n                             ):\n        \"\"\"Try to intelligently connect up widgets to an object's properties.\n        \n        Enumerate widgets of supported types, and connect them to properties\n        of the object with the same name.  The object in question is the\n        `controlled object` parameter, and multiple objects can be searched\n        in order - first `controlled_object`, then `controlled_objects`, then\n        this object (if control_self is True).\n        \n        The exception to this is buttons: they look in `self` first of all, \n        then try the list of controlled objects.\n        \n        e.g. if there's a button called \"save_button\", we'll first try to\n        connect self.save_button.clicked to self.save, then (if a controleld\n        object is specified) to self._controlled_object.save.\n        \n        \"\"\"\n        self.slots_to_update_properties = {} # holds callback functions to \n                                # update properties when their controls change.\n        self.callbacks_to_update_controls = {} # holds callback functions to\n                                # update controls when their properties change.\n        if controlled_object is not None:\n            controlled_objects = [controlled_object] + controlled_objects\n        if control_self:\n            controlled_objects = controlled_objects + [self]\n        \n        # Connect buttons to methods with the same name\n        for button in self.findChildren(QtWidgets.QPushButton):\n            name = strip_suffices(button.objectName(), [\"_button\",\"_pushButton\",\"Button\"])\n            try:\n                # look for the named function first in this object, then in the controlled objects\n                obj = first_object_with_attr([self] + controlled_objects, name)\n                action=getattr(obj, name)\n                assert callable(action), \"To call it from a button, it must be callable!\"\n                button.clicked.connect(action)\n                if verbose:\n                    print(\"connected button '{0}' to {1}\".format(name, action))\n            except:\n                if verbose:\n                    print(\"didn't connect button with name '%s'\" % name)    \n        \n        # Now, we try to connect properties with their controls.  This only\n        # works for the most common controls, defined in \n        # auto_connectable_controls\n        \n        # Connect controls to properties with the same name\n        for control_type, c in list(auto_connectable_controls.items()):\n            for control in self.findChildren(c['qt_type']):\n                # print(control)\n                name = strip_suffices(control.objectName(), c['suffices'])\n                try:\n                    # look for the named property on the controlled objects\n                    obj = first_object_with_attr(controlled_objects, name)\n                    assert getattr(obj, name) is not control, \"Didn't connect\"\\\n                        \" the object, as it would have overwritten itself!\"\n                    \n                    # make a function to update the property, and keep track of it.\n                    control_changed = c['control_change_handler'](obj, name)\n                    getattr(control, c['control_change_slot_name']).connect(control_changed)\n                    self.slots_to_update_properties[name] = control_changed\n                    \n                    # Also try to register for updates in the other direction\n                    # using NotifiedProperties\n                    update_handler = c['property_change_handler'](control)\n                    try:\n                        register_for_property_changes(obj, name, update_handler)\n                        self.callbacks_to_update_controls[name] = update_handler\n                    except:\n                        if verbose:\n                            print(\"Couldn't register for updates on {0}, perhaps \"\\\n                                   \"it's not a NotifiedProperty?\".format(name))\n                    \n                    # whether or not it's a NotifiedProperty, we can at least \n                    # try to ensure we *start* with the same values!\n                    try:\n                        update_handler(getattr(obj, name))\n                        # this should fail if the property doesn't exist...\n                    except:\n                        if verbose:\n                            print(\"Failed to initialise {0}, perhaps there's \"\\\n                                   \"no matching property...\".format(name))\n                            \n                    \n                    if verbose:\n                        print(\"connected {0} '{1}' to {2}\".format(control_type, \n                                 name, \"UI\" if obj is self else \"target\"))\n                except Exception as e:\n                    if verbose:\n                        print(\"didn't connect {0} '{1}'\".format(control_type, name))\n                        print(e)",
  "def save_settings(self, settings, prefix=''):\n        \"\"\"Following https://stackoverflow.com/questions/23279125/python-pyqt4-functions-to-save-and-restore-ui-widget-values\n        :param ui:\n        :param settings:\n        :return:\n        \"\"\"\n\n        for _, obj in inspect.getmembers(self):\n            if isinstance(obj, QtWidgets.QComboBox):\n                wdgt_name = obj.objectName()\n                try:\n                    index = obj.currentIndex()  # get current index from combobox\n                    value = obj.itemText(index)  # get the text for current index\n                    settings.setValue('/'.join([prefix, wdgt_name]), value)  # save combobox selection to registry\n                except Exception as e:\n                    print('Failed saving %s because: %s' % ('/'.join([prefix, wdgt_name]), e))\n\n            elif isinstance(obj, QtWidgets.QLineEdit):\n                wdgt_name = obj.objectName()\n                try:\n                    value = obj.text()\n                    settings.setValue('/'.join([prefix, wdgt_name]),\n                                      value)  # save ui values, so they can be restored next time\n                except Exception as e:\n                    print('Failed saving %s because: %s' % ('/'.join([prefix, wdgt_name]), e))\n\n            elif isinstance(obj, QtWidgets.QCheckBox):\n                wdgt_name = obj.objectName()\n                try:\n                    value = obj.isChecked()\n                    settings.setValue('/'.join([prefix, wdgt_name]), value)\n                except Exception as e:\n                    print('Failed saving %s because: %s' % ('/'.join([prefix, wdgt_name]), e))",
  "def load_settings(self, settings, prefix=''):\n\n        for _, obj in inspect.getmembers(self):\n            if isinstance(obj, QtWidgets.QComboBox):\n                wdgt_name = obj.objectName()\n                try:\n                    value = settings.value('/'.join([prefix, wdgt_name]))\n                    if value == \"\":\n                        continue\n                    index = obj.findText(value)  # get the corresponding index for specified string in combobox\n\n                    if index == -1:  # add to list if not found\n                        obj.insertItems(0, [value])\n                        index = obj.findText(value)\n                        obj.setCurrentIndex(index)\n                    else:\n                        obj.setCurrentIndex(index)  # preselect a combobox value by index\n                except Exception as e:\n                    print('Failed saving %s because: %s' % ('/'.join([prefix, wdgt_name]), e))\n\n            elif isinstance(obj, QtWidgets.QLineEdit):\n                wdgt_name = obj.objectName()\n                try:\n                    value = settings.value('/'.join([prefix, wdgt_name]))  # get stored value from registry\n                    obj.setText(value)  # restore lineEditFile\n                except Exception as e:\n                    print('Failed saving %s because: %s' % ('/'.join([prefix, wdgt_name]), e))\n\n            elif isinstance(obj, QtWidgets.QCheckBox):\n                wdgt_name = obj.objectName()\n                try:\n                    value = settings.value('/'.join([prefix, wdgt_name]))  # get stored value from registry\n                    if value is not None:\n                        obj.setCheckState(value)  # restore checkbox\n                except Exception as e:\n                    print('Failed saving %s because: %s' % ('/'.join([prefix, wdgt_name]), e))",
  "def __init__(self, title=\"Quick Settings\", *args, **kwargs):\n        super(QuickControlBox, self).__init__(*args, **kwargs)\n        self.setTitle(title)\n        self.setLayout(QtWidgets.QFormLayout())\n        self.controls = dict()",
  "def add_doublespinbox(self, name, vmin=-float(\"inf\"), vmax=float(\"inf\"), singlestep=1.,):\n        \"\"\"Add a floating-point spin box control.\"\"\"\n        sb = QtWidgets.QDoubleSpinBox()\n        self.controls[name] = sb\n        sb.setObjectName(name + \"_spinbox\")\n        sb.setMinimum(vmin)\n        sb.setMaximum(vmax)\n        sb.setSingleStep(singlestep)\n        sb.setKeyboardTracking(False)\n        self.layout().addRow(name.title(), sb)",
  "def add_spinbox(self, name, vmin=-2**31, vmax=2**31-1, singlestep=1):\n        \"\"\"Add a floating-point spin box control.\"\"\"\n        sb = QtWidgets.QSpinBox()\n        self.controls[name] = sb\n        sb.setObjectName(name + \"_spinbox\")\n        sb.setMinimum(vmin)\n        sb.setMaximum(vmax)\n        sb.setSingleStep(singlestep)\n        sb.setKeyboardTracking(False)\n        self.layout().addRow(name.title(), sb)",
  "def add_lineedit(self, name):\n        \"\"\"Add a single-line text box control.\"\"\"\n        le = QtWidgets.QLineEdit()\n        self.controls[name] = le\n        le.setObjectName(name + \"_lineedit\")\n        self.layout().addRow(name.title(), le)",
  "def add_button(self, name, title=None):\n        \"\"\"Add a button.\"\"\"\n        if title is None:\n            title = name.title()\n        button = QtWidgets.QPushButton()\n        self.controls[name] = button\n        button.setObjectName(name + \"_button\")\n        button.setText(title)\n        self.layout().addRow(button)",
  "def add_checkbox(self, name, title=None):\n        if title is None:\n            title = name.title()\n        checkbox = QtWidgets.QCheckBox()\n        self.controls[name] = checkbox\n        checkbox.setObjectName(name + \"_checkbox\")\n        checkbox.setText(title)\n        self.layout().addRow(\"\", checkbox)",
  "def add_combobox(self, name,options, title=None):\n        if title is None:\n            title = name.title()\n        combobox = QtWidgets.QComboBox()\n        for option in options:\n            combobox.addItem(option)\n\n        self.controls[name] = combobox\n        combobox.setObjectName(name + \"_combobox\")\n        self.layout().addRow(title, combobox)",
  "def handler_generator(obj, name):\n        \"\"\"Generate a function to update a property when a Qt control changes.\n        \n        Arguments:\n        obj: object\n            The object to which the property is attached\n        name: string\n            The name of the property to update\n        \"\"\"\n        def update_property(value):\n            try:\n                setattr(obj, name, conversion(value))\n            except AttributeError:\n                print(name,'has no setter?')\n        return update_property",
  "def handler_generator(control):\n        \"\"\"Generate a function to update a control when a property changes.\"\"\"\n        # first get hold of functions to get and set the control's value\n        getter = getattr(control, getter_name)\n        setter = getattr(control, setter_name)\n        def update_control(value):\n            if getter() != conversion(value):\n                # If we're syncing in both directions, this is important to\n                # avoid infinite loops.  Qt is reasonably good about doing this\n                # but let's do belt-and-braces for safety.\n                setter(conversion(value))\n        return update_control",
  "def update_property(value):\n            try:\n                setattr(obj, name, conversion(value))\n            except AttributeError:\n                print(name,'has no setter?')",
  "def update_control(value):\n            if getter() != conversion(value):\n                # If we're syncing in both directions, this is important to\n                # avoid infinite loops.  Qt is reasonably good about doing this\n                # but let's do belt-and-braces for safety.\n                setter(conversion(value))",
  "class DataGroupCreator(QtWidgets.QWidget,UiTools, ShowGUIMixin):\n    \n    group_name = DumbNotifiedProperty('particle_%d')\n    gui_current_group = DumbNotifiedProperty(None)\n    use_created_group = DumbNotifiedProperty(False)\n    \n    def __init__(self, file=None):\n        super().__init__()\n        uic.loadUi(os.path.dirname(__file__)+'\\data_group_creator.ui', self)\n        if file is None:\n            self.file = datafile.current()\n        else:\n            self.file = file\n        self._use_created_group = False\n        self.auto_connect_by_name()        \n        register_for_property_changes(self, 'use_created_group', self.use_created_group_changed)\n        \n    def create_group(self):\n        init_use_cur = datafile._use_current_group\n        datafile._use_current_group = False\n        self.gui_current_group = self.file.create_group(self.group_name)\n        if self.use_created_group_checkBox.checkState(): \n            datafile._current_group = self.gui_current_group\n        datafile._use_current_group = init_use_cur\n        \n    def use_created_group_changed(self, new):\n        datafile._use_current_group = new\n        if new:\n            if hasattr(self, 'gui_current_group'):\n                datafile._current_group = self.gui_current_group\n            else: print('No created group (yet)!')\n            \n    def add_note(self):\n        note = self.note_textEdit.toPlainText()\n        if note:\n            if self.use_created_group:\n                place = self.gui_current_group\n            else:\n                place = self.file\n            place.create_dataset('note_%d', data=note, attrs={'is_note': True})\n            \n    def get_qt_ui(self):\n        return self",
  "def __init__(self, file=None):\n        super().__init__()\n        uic.loadUi(os.path.dirname(__file__)+'\\data_group_creator.ui', self)\n        if file is None:\n            self.file = datafile.current()\n        else:\n            self.file = file\n        self._use_created_group = False\n        self.auto_connect_by_name()        \n        register_for_property_changes(self, 'use_created_group', self.use_created_group_changed)",
  "def create_group(self):\n        init_use_cur = datafile._use_current_group\n        datafile._use_current_group = False\n        self.gui_current_group = self.file.create_group(self.group_name)\n        if self.use_created_group_checkBox.checkState(): \n            datafile._current_group = self.gui_current_group\n        datafile._use_current_group = init_use_cur",
  "def use_created_group_changed(self, new):\n        datafile._use_current_group = new\n        if new:\n            if hasattr(self, 'gui_current_group'):\n                datafile._current_group = self.gui_current_group\n            else: print('No created group (yet)!')",
  "def add_note(self):\n        note = self.note_textEdit.toPlainText()\n        if note:\n            if self.use_created_group:\n                place = self.gui_current_group\n            else:\n                place = self.file\n            place.create_dataset('note_%d', data=note, attrs={'is_note': True})",
  "def get_qt_ui(self):\n        return self",
  "class PositionBarWidget(QWidget):\n\n    def __init__(self, min_value, max_value, margin=0.1):\n        super(PositionBarWidget, self).__init__()\n        self.min_value = min_value\n        self.max_value = max_value\n        self.range = max_value-min_value\n        self.margin = margin\n        self.initUI()\n        self.setValue(old_div(self.range,2))\n\n\n\n    def initUI(self):\n        self.setMinimumSize(15,50)\n\n    def setValue(self, value):\n        self.value = value-self.min_value\n        self.repaint()\n\n    def paintEvent(self, e):\n        qp = QPainter()\n        qp.begin(self)\n        self.drawWidget(qp)\n        qp.end()\n\n    def drawWidget(self, qp):\n        size = self.size()\n        w = size.width()\n        h = size.height()\n\n        lower_threshold = self.margin*self.range\n        upper_threshold = (1-self.margin)*self.range\n\n        till = round(old_div((h * (self.range-self.value)),self.range))\n\n        if self.value <= lower_threshold or self.value >= upper_threshold:\n            qp.setBrush(QColor(255, 100, 100))\n        else:\n            qp.setBrush(QColor(50, 255, 50))\n        qp.setPen(QColor(0,0,0))\n        qp.drawRect(0, h-1, w, till-h)\n\n        pen = QPen(QColor(20, 20, 20), 1, Qt.SolidLine)\n        qp.setPen(pen)\n        qp.setBrush(Qt.NoBrush)\n        qp.drawRect(0, 0, w-1, h-1)\n\n        sepeation_marks = int(round(h / 10.0))\n        for i in range(sepeation_marks, 10*sepeation_marks, sepeation_marks):\n            qp.drawLine(0, i, 5, i)",
  "class XYPositionWidget(pg.PlotWidget):\n\n    def __init__(self, xrange_nm, yrange_nm):\n        super(XYPositionWidget, self).__init__(background=None)\n        self.setXRange(0,xrange_nm)\n        self.setYRange(0,yrange_nm)\n        self.init_plot()\n        self.crosshair = CrossHair('r')\n        self.addItem(self.crosshair)\n        self.crosshair.crosshair_size=0.05*xrange_nm\n#        self.crosshair.CrossHairMoved.connect(self.mouseMoved)\n        self.pos = []\n        self.unit = 'pxl'\n\n    def init_plot(self):\n\n#        self.setGeometry(400, 50, 400, 400)\n#        self.setBackground(background=None)\n#        data = np.zeros((100,100))\n#        img = pg.ImageItem(image=data)\n#        self.addItem(img)\n        self.showAxis('right',show=True)\n        self.showAxis('top',show=True)\n        self.getAxis('left').setPen('k')\n        self.getAxis('bottom').setPen('k')\n        self.getAxis('right').setPen('k')\n        self.getAxis('top').setPen('k')\n        self.getAxis('top').showLabel(show=False)\n        self.getAxis('right').setStyle(showValues=False)\n        self.getAxis('top').setStyle(showValues=False)\n        self.getAxis('left').setStyle(showValues=False)\n        self.getAxis('bottom').setStyle(showValues=False)\n        self.setMouseEnabled(x=False,y=False)\n        self.setMinimumSize(150,100)\n        self.show()\n\n\n    def setValue(self, new_x, new_y):\n        return self.crosshair.setPos(new_x, new_y)\n\n\n    def pxl_to_unit(self, pxl):\n        return pxl\n\n    def mouseMoved(self):\n        self.pos = self.crosshair.pos()\n        x1 = self.crosshair.pos()[0]\n        y1 = self.crosshair.pos()[1]\n#        xu1, yu1 = self.pxl_to_unit((x1, y1))\n        print(\"cursor moved to pixel: [%i,%i]\" % (x1,y1))",
  "class CrossHair(pg.GraphicsObject):\n    CrossHairMoved = QtCore.Signal()\n    Released = QtCore.Signal()\n\n    def __init__(self, color):\n        super(CrossHair, self).__init__()\n        self.color = color\n        self.crosshair_size = 2\n\n    def paint(self, p, *args):\n        p.setPen(pg.mkPen(self.color))\n        p.drawLine(-self.crosshair_size, 0, self.crosshair_size, 0)\n        p.drawLine(0, -self.crosshair_size, 0, self.crosshair_size)\n\n    def boundingRect(self):\n        return QtCore.QRectF(-self.crosshair_size, -self.crosshair_size, 2*self.crosshair_size, 2*self.crosshair_size)\n\n    def mouseDragEvent(self, ev):\n        ev.accept()\n        if ev.isStart():\n            self.startPos = self.pos()\n        elif ev.isFinish():\n            self.setPos(*list(map(int, self.pos())))\n        else:\n            self.setPos(self.startPos + ev.pos() - ev.buttonDownPos())\n        self.CrossHairMoved.emit()",
  "class XYZPositionWidget(QWidget):\n\n    def __init__(self,xrange_nm, yrange_nm, zrange_nm, show_xy_pos=True,\n                 show_z_pos=True):\n        super(XYZPositionWidget, self).__init__()\n        layout = QHBoxLayout()\n        if show_xy_pos:\n            self.xy_widget = XYPositionWidget(xrange_nm, yrange_nm)\n            layout.addWidget(self.xy_widget)\n        if show_z_pos:\n            self.z_bar = PositionBarWidget(0,zrange_nm)\n            layout.addWidget(self.z_bar)\n        self.setLayout(layout)",
  "def __init__(self, min_value, max_value, margin=0.1):\n        super(PositionBarWidget, self).__init__()\n        self.min_value = min_value\n        self.max_value = max_value\n        self.range = max_value-min_value\n        self.margin = margin\n        self.initUI()\n        self.setValue(old_div(self.range,2))",
  "def initUI(self):\n        self.setMinimumSize(15,50)",
  "def setValue(self, value):\n        self.value = value-self.min_value\n        self.repaint()",
  "def paintEvent(self, e):\n        qp = QPainter()\n        qp.begin(self)\n        self.drawWidget(qp)\n        qp.end()",
  "def drawWidget(self, qp):\n        size = self.size()\n        w = size.width()\n        h = size.height()\n\n        lower_threshold = self.margin*self.range\n        upper_threshold = (1-self.margin)*self.range\n\n        till = round(old_div((h * (self.range-self.value)),self.range))\n\n        if self.value <= lower_threshold or self.value >= upper_threshold:\n            qp.setBrush(QColor(255, 100, 100))\n        else:\n            qp.setBrush(QColor(50, 255, 50))\n        qp.setPen(QColor(0,0,0))\n        qp.drawRect(0, h-1, w, till-h)\n\n        pen = QPen(QColor(20, 20, 20), 1, Qt.SolidLine)\n        qp.setPen(pen)\n        qp.setBrush(Qt.NoBrush)\n        qp.drawRect(0, 0, w-1, h-1)\n\n        sepeation_marks = int(round(h / 10.0))\n        for i in range(sepeation_marks, 10*sepeation_marks, sepeation_marks):\n            qp.drawLine(0, i, 5, i)",
  "def __init__(self, xrange_nm, yrange_nm):\n        super(XYPositionWidget, self).__init__(background=None)\n        self.setXRange(0,xrange_nm)\n        self.setYRange(0,yrange_nm)\n        self.init_plot()\n        self.crosshair = CrossHair('r')\n        self.addItem(self.crosshair)\n        self.crosshair.crosshair_size=0.05*xrange_nm\n#        self.crosshair.CrossHairMoved.connect(self.mouseMoved)\n        self.pos = []\n        self.unit = 'pxl'",
  "def init_plot(self):\n\n#        self.setGeometry(400, 50, 400, 400)\n#        self.setBackground(background=None)\n#        data = np.zeros((100,100))\n#        img = pg.ImageItem(image=data)\n#        self.addItem(img)\n        self.showAxis('right',show=True)\n        self.showAxis('top',show=True)\n        self.getAxis('left').setPen('k')\n        self.getAxis('bottom').setPen('k')\n        self.getAxis('right').setPen('k')\n        self.getAxis('top').setPen('k')\n        self.getAxis('top').showLabel(show=False)\n        self.getAxis('right').setStyle(showValues=False)\n        self.getAxis('top').setStyle(showValues=False)\n        self.getAxis('left').setStyle(showValues=False)\n        self.getAxis('bottom').setStyle(showValues=False)\n        self.setMouseEnabled(x=False,y=False)\n        self.setMinimumSize(150,100)\n        self.show()",
  "def setValue(self, new_x, new_y):\n        return self.crosshair.setPos(new_x, new_y)",
  "def pxl_to_unit(self, pxl):\n        return pxl",
  "def mouseMoved(self):\n        self.pos = self.crosshair.pos()\n        x1 = self.crosshair.pos()[0]\n        y1 = self.crosshair.pos()[1]\n#        xu1, yu1 = self.pxl_to_unit((x1, y1))\n        print(\"cursor moved to pixel: [%i,%i]\" % (x1,y1))",
  "def __init__(self, color):\n        super(CrossHair, self).__init__()\n        self.color = color\n        self.crosshair_size = 2",
  "def paint(self, p, *args):\n        p.setPen(pg.mkPen(self.color))\n        p.drawLine(-self.crosshair_size, 0, self.crosshair_size, 0)\n        p.drawLine(0, -self.crosshair_size, 0, self.crosshair_size)",
  "def boundingRect(self):\n        return QtCore.QRectF(-self.crosshair_size, -self.crosshair_size, 2*self.crosshair_size, 2*self.crosshair_size)",
  "def mouseDragEvent(self, ev):\n        ev.accept()\n        if ev.isStart():\n            self.startPos = self.pos()\n        elif ev.isFinish():\n            self.setPos(*list(map(int, self.pos())))\n        else:\n            self.setPos(self.startPos + ev.pos() - ev.buttonDownPos())\n        self.CrossHairMoved.emit()",
  "def __init__(self,xrange_nm, yrange_nm, zrange_nm, show_xy_pos=True,\n                 show_z_pos=True):\n        super(XYZPositionWidget, self).__init__()\n        layout = QHBoxLayout()\n        if show_xy_pos:\n            self.xy_widget = XYPositionWidget(xrange_nm, yrange_nm)\n            layout.addWidget(self.xy_widget)\n        if show_z_pos:\n            self.z_bar = PositionBarWidget(0,zrange_nm)\n            layout.addWidget(self.z_bar)\n        self.setLayout(layout)",
  "class ArbitraryAxis(pg.AxisItem):\n    \"\"\"\n    Axis that retains it's underlying coordinates, while displaying different coordinates as ticks.\n    It allows one to retain the sizes, shapes and location of widgets added on top the same independently of scaling\n    (e.g. CrossHairs)\n    \"\"\"\n\n    def __init__(self, *args, **kwargs):\n        super(ArbitraryAxis, self).__init__(*args, **kwargs)\n        self.axis_values = None\n\n    def pos_to_unit(self, value):\n        def get_value(index):\n            \"\"\"Function that extracts the value from a list (axis_vectors) according to some given position (index),\n            returning NaN if the index is out of range\"\"\"\n            if int(index) < 0 or int(index) > len(self.axis_values):\n                return np.nan\n            else:\n                return self.axis_values[int(index)]\n\n        if self.axis_values is None:\n            func = int\n        else:\n            func = get_value\n\n        if not hasattr(value, '__iter__'):\n            return func(value)\n        else:\n            return list(map(func, value))\n\n    def tickStrings(self, values, scale, spacing):\n        try:\n            values = self.pos_to_unit(values)\n            spacing = np.abs(np.diff(self.pos_to_unit([0, spacing]))[0])\n            spacing += 0.001\n            returnval = super(ArbitraryAxis, self).tickStrings(values, scale, spacing)\n        except Exception as e:\n            # pg throws out a TypeError/RuntimeWarning when there's no ticks. We ignore it\n            returnval = [''] * len(values)\n            # print(e)\n        return returnval",
  "class Crosshair(pg.GraphicsObject):\n    Released = QtCore.Signal()\n\n    def __init__(self, color, size=5, *args):\n        super(Crosshair, self).__init__(*args)\n        self.color = color\n        self._size = size\n        self._origin = [0, 0]\n\n    def paint(self, p, *args):\n        p.setPen(pg.mkPen(self.color))\n        p.drawLine(-self._size, 0, self._size, 0)\n        p.drawLine(0, -self._size, 0, self._size)\n\n    def boundingRect(self):\n        \"\"\"Makes a clickable rectangle around the center, which is half the size of the cross hair\"\"\"\n        return QtCore.QRectF(-self._size, -self._size, 2 * self._size, 2 * self._size)\n\n    def mouseDragEvent(self, ev):\n        # Ensures the Crosshair always remains in the center of a pixel, which makes the ROI selection easier\n        ev.accept()\n        if ev.isStart():\n            self.startPos = self.pos()\n        elif ev.isFinish():\n            rounded_pos = [int(x) + 0.5 for x in self.pos()]\n            self.setPos(*rounded_pos)\n        else:\n            self.setPos(self.startPos + ev.pos() - ev.buttonDownPos())\n        self.Released.emit()\n\n    def referenced_pos(self):\n        pos = self.pos()\n        return [np.abs(pos[x] - self._origin[x]) for x in [0, 1]]",
  "class ExtendedImageView(pg.ImageView):\n    \"\"\"\n    Extension of the pg ImageView so that it's possible to put percentile levels instead of playing around with\n    the histogram. Also adds the possibility of normalising each image when given a 3D array, instead of normalising to\n    the maximum of the whole array.\n\n    # TODO: link the histogram region with the lineedit levels\n    \"\"\"\n\n    def __init__(self, *args, **kwargs):\n        self.axis_values = dict(bottom=None, left=None, top=None, right=None)\n        self.axis_units = dict(bottom=None, left=None, top=None, right=None)\n        kwargs['view'] = pg.PlotItem(axisItems=dict(bottom=ArbitraryAxis(orientation=\"bottom\"),\n                                                    left=ArbitraryAxis(orientation=\"left\"),\n                                                    top=ArbitraryAxis(orientation=\"top\"),\n                                                    right=ArbitraryAxis(orientation=\"right\")))\n        super(ExtendedImageView, self).__init__(*args, **kwargs)\n        self.imageItem.axisOrder = 'row-major'\n\n        # Setting up the autoleveling GUI\n        self.level_percentiles = [0, 100]\n        self.levelGroup = uic.loadUi(os.path.join(os.path.dirname(__file__), 'autolevel.ui'))\n        self.ui.gridLayout_3.addWidget(self.levelGroup, 2, 0, 1, 1)\n        self.levelGroup.setVisible(False)\n\n        self.levelGroup.checkbox_singleimagelevel.stateChanged.connect(self.set_level_percentiles)\n        self.levelGroup.lineEdit_minLevel.returnPressed.connect(self.set_level_percentiles)\n        self.levelGroup.lineEdit_maxLevel.returnPressed.connect(self.set_level_percentiles)\n        self.levelGroup.pushButton_reset.pressed.connect(self.reset)\n\n        # Setting up the additional tools GUI\n        self.tools = uic.loadUi(os.path.join(os.path.dirname(__file__), 'imageview_tools.ui'))\n        self.ui.splitter.addWidget(self.tools)\n        self.tools.checkbox_tools.stateChanged.connect(self.show_tools)\n        self.tools.checkbox_aspectratio.stateChanged.connect(\n            lambda: self.view.setAspectLocked(self.tools.checkbox_aspectratio.isChecked()))\n        self.tools.checkbox_axes.stateChanged.connect(self.hide_axes)\n\n        # Setting up the crosshairs\n        for idx, color in enumerate(['r', 'g']):\n            crosshair = Crosshair(color)\n            self.getView().addItem(crosshair)\n            crosshair.Released.connect(self.crosshair_moved)\n            setattr(self, 'CrossHair%d' % (idx + 1), crosshair)\n        self.label_crosshairpos = QtWidgets.QLabel()\n        self.ui.gridLayout.addWidget(self.label_crosshairpos, 2, 0, 1, 3)\n        self.label_crosshairpos.hide()\n        self.crosshair_moved()\n\n    def show_tools(self):\n        boolean = self.tools.checkbox_tools.isChecked()\n        if boolean:\n            self.getHistogramWidget().show()\n            self.ui.roiBtn.show()\n            self.ui.menuBtn.show()\n        else:\n            self.getHistogramWidget().hide()\n            self.ui.roiBtn.hide()\n            self.ui.menuBtn.hide()\n\n    def roiClicked(self):\n        \"\"\"Ensures that the new widget in the splitter is displayed\"\"\"\n        super(ExtendedImageView, self).roiClicked()\n        if self.hasTimeAxis() and not self.ui.roiBtn.isChecked():\n            self.ui.splitter.setSizes([self.height() - 70, 35, 35])\n\n    def buildMenu(self):\n        \"\"\"Adds an action to the existing pg.ImageView menu to toggle the visibility of the new GUI\"\"\"\n        super(ExtendedImageView, self).buildMenu()\n        # Percentiles\n        self.levelAction = QtWidgets.QAction(\"Autolevel\", self.menu)\n        self.levelAction.setCheckable(True)\n        self.levelAction.toggled.connect(lambda boolean: self.levelGroup.setVisible(boolean))\n        self.menu.addAction(self.levelAction)\n        # Crosshair label\n        self.labelAction = QtWidgets.QAction(\"Crosshair label\", self.menu)\n        self.labelAction.setCheckable(True)\n        self.labelAction.toggled.connect(lambda boolean: self.label_crosshairpos.setVisible(boolean))\n        self.menu.addAction(self.labelAction)\n\n    # Scaled axis functions\n    def get_axes(self):\n        \"\"\"Returns the AxisItems\"\"\"\n        axes_dict = self.getView().axes\n        names = [\"bottom\", \"left\", \"top\", \"right\"]  # Ensures its always in the same order\n        axs = [axes_dict[name]['item'] for name in names]\n        return axs\n\n    def hide_axes(self):\n        boolean = self.tools.checkbox_axes.isChecked()\n        if boolean:\n            for ax in self.get_axes():\n                ax.hide()\n        else:\n            for ax in self.get_axes():\n                ax.show()\n\n    # Percentile functions\n    def set_level_percentiles(self):\n        \"\"\"\n        Reads the GUI lineEdits and sets the level percentiles. If not normalising each image, it also finds the levels\n        and sets them\n        :return:\n        \"\"\"\n        min_level = float(self.levelGroup.lineEdit_minLevel.text())\n        max_level = float(self.levelGroup.lineEdit_maxLevel.text())\n\n        self.level_percentiles = [min_level, max_level]\n        self.imageDisp = None\n        self.updateImage()\n        self.autoLevels()\n\n    def reset(self):\n        self.levelGroup.lineEdit_minLevel.setText('0')\n        self.levelGroup.lineEdit_maxLevel.setText('100')\n        self.set_level_percentiles()\n\n    def getProcessedImage(self):\n        \"\"\"Reimplements the ImageView.getProcessedImage to allow leveling of each image in a time series\"\"\"\n        rtrn = super(ExtendedImageView, self).getProcessedImage()\n        if self.levelGroup.checkbox_singleimagelevel.isChecked() and self.hasTimeAxis():\n            if self.axes['c'] is not None:\n                # axes['c'] keeps track of what dimension is the colour. And since we are taking one dimension out when\n                # doing quickMinMax of each image in the time series:\n                self.axes['c'] -= 1\n            self._imageLevels = self.quickMinMax(self.imageDisp[self.currentIndex])\n            self.levelMin = min([level[0] for level in self._imageLevels])\n            self.levelMax = max([level[1] for level in self._imageLevels])\n            self.autoLevels()\n            if self.axes['c'] is not None:\n                # Now we bring it back to where it was before\n                self.axes['c'] += 1\n        return rtrn\n\n    def quickMinMax(self, data):\n        \"\"\"Reimplements the ImageView.quickMinMax to set level percentiles\"\"\"\n        mm = super(ExtendedImageView, self).quickMinMax(data)\n        return [(np.percentile(x, self.level_percentiles[0]),\n                 np.percentile(x, self.level_percentiles[1])) for x in mm]\n\n    # Crosshairs\n    def pos_to_unit(self, positions):\n        \"\"\"\n        Given an iterable of positions, iterates over them and returns the scaled values along the corresponding axis.\n        Uses the ArbitraryAxis.pos_to_unit method\n\n        :param positions: 2- or 4-tuple of floats. If two values given, assumed it corresponds to the (bottom, left)\n        axis, if four values the order should be (bottom, left, top, right) as given by self.get_axes()\n        :return:\n        \"\"\"\n        axs = self.get_axes()\n        units = ()\n\n        if len(positions) == 2:\n            axs = axs[:2]\n        for ax, pos in zip(axs, positions):\n            if hasattr(ax, 'pos_to_unit'):\n                units += (ax.pos_to_unit(pos),)\n            else:\n                units += (pos,)\n\n        return units\n\n    def crosshair_moved(self):\n        \"\"\"\n        Displays the current position of the two cross-hairs, as well as the distance between them, in pixels and in\n        units (when given)\n        :return:\n        \"\"\"\n        try:\n            # First gets the crosshair positions, and finds the distance between them\n            positions = ()\n            for idx in [1, 2]:\n                xhair = getattr(self, \"CrossHair%d\" % idx)\n                pos = tuple(xhair.referenced_pos())\n                positions += pos\n            diff = np.linalg.norm(np.array(positions[:2]) - np.array(positions[2:]))\n            positions += (diff,)\n\n            display_string = \"Pixels: <span style='color: red'>[%i,%i] </span> \" \\\n                             \"<span style='color: green'> [%i,%i] </span> \" \\\n                             u\"\\u0394px=%g\" % positions\n\n            # If any units are given, get the positions and scale them using pos_to_unit\n            if any([self.axis_units[x] is not None for x in ['bottom', 'left']]):\n                scaled_positions = ()\n                for idx in [1, 2]:\n                    xhair = getattr(self, \"CrossHair%d\" % idx)\n                    pos = tuple(xhair.referenced_pos())\n                    scaled_positions += self.pos_to_unit(pos)\n                units = ()\n                for ax in ['bottom', 'left']:\n                    if self.axis_units[ax] is None:\n                        units += ('px',)\n                    else:\n                        units += (self.axis_units[ax],)\n                display_string += \"\\t(%s, %s):\" \\\n                                  \"<span style='color: red'> (%g, %g)</span> \" \\\n                                  \"<span style='color: green'> (%g, %g)</span> \" % (units + scaled_positions)\n\n                # If the bottom and left axis have the same units, display the distance between the crosshairs\n                if self.axis_units['bottom'] == self.axis_units['left']:\n                    difft = np.linalg.norm(np.array(scaled_positions[:2]) - np.array(scaled_positions[2:]))\n                    unit = self.axis_units['bottom']\n                    display_string += u\"\\u0394%s=%g\" % (unit, difft)\n\n            self.label_crosshairpos.setText(display_string)\n        except Exception as e:\n            print('Failed updating crosshair position: %s' % e)\n\n    def get_roi(self):\n        \"\"\"\n        Pixel positions of the edges of the rectangle bound by the crosshairs\n        :return: 4-tuple of integers. left, right, top, and bottom edges\n        \"\"\"\n        assert hasattr(self, 'CrossHair1')\n        assert hasattr(self, 'CrossHair2')\n\n        pos1 = self.CrossHair1.referenced_pos()\n        pos2 = self.CrossHair2.referenced_pos()\n        if pos1 == pos2:\n            return None\n\n        min_x, max_x = [int(x) for x in (min(pos1[0], pos2[0]), max(pos1[0], pos2[0]))]\n        min_y, max_y = [int(x) for x in (min(pos1[1], pos2[1]), max(pos1[1], pos2[1]))]\n\n        return min_x, max_x, min_y, max_y",
  "def test():\n    from nplab.utils.gui import get_qt_app\n    app = get_qt_app()\n    ui = ExtendedImageView()\n    data = []\n    for ii, dum in enumerate(np.random.random((10, 50, 50))):\n        data += [dum + ii]\n    data = np.array(data)\n    ui.setImage(data)\n    ui.show()\n    app.exec_()",
  "def __init__(self, *args, **kwargs):\n        super(ArbitraryAxis, self).__init__(*args, **kwargs)\n        self.axis_values = None",
  "def pos_to_unit(self, value):\n        def get_value(index):\n            \"\"\"Function that extracts the value from a list (axis_vectors) according to some given position (index),\n            returning NaN if the index is out of range\"\"\"\n            if int(index) < 0 or int(index) > len(self.axis_values):\n                return np.nan\n            else:\n                return self.axis_values[int(index)]\n\n        if self.axis_values is None:\n            func = int\n        else:\n            func = get_value\n\n        if not hasattr(value, '__iter__'):\n            return func(value)\n        else:\n            return list(map(func, value))",
  "def tickStrings(self, values, scale, spacing):\n        try:\n            values = self.pos_to_unit(values)\n            spacing = np.abs(np.diff(self.pos_to_unit([0, spacing]))[0])\n            spacing += 0.001\n            returnval = super(ArbitraryAxis, self).tickStrings(values, scale, spacing)\n        except Exception as e:\n            # pg throws out a TypeError/RuntimeWarning when there's no ticks. We ignore it\n            returnval = [''] * len(values)\n            # print(e)\n        return returnval",
  "def __init__(self, color, size=5, *args):\n        super(Crosshair, self).__init__(*args)\n        self.color = color\n        self._size = size\n        self._origin = [0, 0]",
  "def paint(self, p, *args):\n        p.setPen(pg.mkPen(self.color))\n        p.drawLine(-self._size, 0, self._size, 0)\n        p.drawLine(0, -self._size, 0, self._size)",
  "def boundingRect(self):\n        \"\"\"Makes a clickable rectangle around the center, which is half the size of the cross hair\"\"\"\n        return QtCore.QRectF(-self._size, -self._size, 2 * self._size, 2 * self._size)",
  "def mouseDragEvent(self, ev):\n        # Ensures the Crosshair always remains in the center of a pixel, which makes the ROI selection easier\n        ev.accept()\n        if ev.isStart():\n            self.startPos = self.pos()\n        elif ev.isFinish():\n            rounded_pos = [int(x) + 0.5 for x in self.pos()]\n            self.setPos(*rounded_pos)\n        else:\n            self.setPos(self.startPos + ev.pos() - ev.buttonDownPos())\n        self.Released.emit()",
  "def referenced_pos(self):\n        pos = self.pos()\n        return [np.abs(pos[x] - self._origin[x]) for x in [0, 1]]",
  "def __init__(self, *args, **kwargs):\n        self.axis_values = dict(bottom=None, left=None, top=None, right=None)\n        self.axis_units = dict(bottom=None, left=None, top=None, right=None)\n        kwargs['view'] = pg.PlotItem(axisItems=dict(bottom=ArbitraryAxis(orientation=\"bottom\"),\n                                                    left=ArbitraryAxis(orientation=\"left\"),\n                                                    top=ArbitraryAxis(orientation=\"top\"),\n                                                    right=ArbitraryAxis(orientation=\"right\")))\n        super(ExtendedImageView, self).__init__(*args, **kwargs)\n        self.imageItem.axisOrder = 'row-major'\n\n        # Setting up the autoleveling GUI\n        self.level_percentiles = [0, 100]\n        self.levelGroup = uic.loadUi(os.path.join(os.path.dirname(__file__), 'autolevel.ui'))\n        self.ui.gridLayout_3.addWidget(self.levelGroup, 2, 0, 1, 1)\n        self.levelGroup.setVisible(False)\n\n        self.levelGroup.checkbox_singleimagelevel.stateChanged.connect(self.set_level_percentiles)\n        self.levelGroup.lineEdit_minLevel.returnPressed.connect(self.set_level_percentiles)\n        self.levelGroup.lineEdit_maxLevel.returnPressed.connect(self.set_level_percentiles)\n        self.levelGroup.pushButton_reset.pressed.connect(self.reset)\n\n        # Setting up the additional tools GUI\n        self.tools = uic.loadUi(os.path.join(os.path.dirname(__file__), 'imageview_tools.ui'))\n        self.ui.splitter.addWidget(self.tools)\n        self.tools.checkbox_tools.stateChanged.connect(self.show_tools)\n        self.tools.checkbox_aspectratio.stateChanged.connect(\n            lambda: self.view.setAspectLocked(self.tools.checkbox_aspectratio.isChecked()))\n        self.tools.checkbox_axes.stateChanged.connect(self.hide_axes)\n\n        # Setting up the crosshairs\n        for idx, color in enumerate(['r', 'g']):\n            crosshair = Crosshair(color)\n            self.getView().addItem(crosshair)\n            crosshair.Released.connect(self.crosshair_moved)\n            setattr(self, 'CrossHair%d' % (idx + 1), crosshair)\n        self.label_crosshairpos = QtWidgets.QLabel()\n        self.ui.gridLayout.addWidget(self.label_crosshairpos, 2, 0, 1, 3)\n        self.label_crosshairpos.hide()\n        self.crosshair_moved()",
  "def show_tools(self):\n        boolean = self.tools.checkbox_tools.isChecked()\n        if boolean:\n            self.getHistogramWidget().show()\n            self.ui.roiBtn.show()\n            self.ui.menuBtn.show()\n        else:\n            self.getHistogramWidget().hide()\n            self.ui.roiBtn.hide()\n            self.ui.menuBtn.hide()",
  "def roiClicked(self):\n        \"\"\"Ensures that the new widget in the splitter is displayed\"\"\"\n        super(ExtendedImageView, self).roiClicked()\n        if self.hasTimeAxis() and not self.ui.roiBtn.isChecked():\n            self.ui.splitter.setSizes([self.height() - 70, 35, 35])",
  "def buildMenu(self):\n        \"\"\"Adds an action to the existing pg.ImageView menu to toggle the visibility of the new GUI\"\"\"\n        super(ExtendedImageView, self).buildMenu()\n        # Percentiles\n        self.levelAction = QtWidgets.QAction(\"Autolevel\", self.menu)\n        self.levelAction.setCheckable(True)\n        self.levelAction.toggled.connect(lambda boolean: self.levelGroup.setVisible(boolean))\n        self.menu.addAction(self.levelAction)\n        # Crosshair label\n        self.labelAction = QtWidgets.QAction(\"Crosshair label\", self.menu)\n        self.labelAction.setCheckable(True)\n        self.labelAction.toggled.connect(lambda boolean: self.label_crosshairpos.setVisible(boolean))\n        self.menu.addAction(self.labelAction)",
  "def get_axes(self):\n        \"\"\"Returns the AxisItems\"\"\"\n        axes_dict = self.getView().axes\n        names = [\"bottom\", \"left\", \"top\", \"right\"]  # Ensures its always in the same order\n        axs = [axes_dict[name]['item'] for name in names]\n        return axs",
  "def hide_axes(self):\n        boolean = self.tools.checkbox_axes.isChecked()\n        if boolean:\n            for ax in self.get_axes():\n                ax.hide()\n        else:\n            for ax in self.get_axes():\n                ax.show()",
  "def set_level_percentiles(self):\n        \"\"\"\n        Reads the GUI lineEdits and sets the level percentiles. If not normalising each image, it also finds the levels\n        and sets them\n        :return:\n        \"\"\"\n        min_level = float(self.levelGroup.lineEdit_minLevel.text())\n        max_level = float(self.levelGroup.lineEdit_maxLevel.text())\n\n        self.level_percentiles = [min_level, max_level]\n        self.imageDisp = None\n        self.updateImage()\n        self.autoLevels()",
  "def reset(self):\n        self.levelGroup.lineEdit_minLevel.setText('0')\n        self.levelGroup.lineEdit_maxLevel.setText('100')\n        self.set_level_percentiles()",
  "def getProcessedImage(self):\n        \"\"\"Reimplements the ImageView.getProcessedImage to allow leveling of each image in a time series\"\"\"\n        rtrn = super(ExtendedImageView, self).getProcessedImage()\n        if self.levelGroup.checkbox_singleimagelevel.isChecked() and self.hasTimeAxis():\n            if self.axes['c'] is not None:\n                # axes['c'] keeps track of what dimension is the colour. And since we are taking one dimension out when\n                # doing quickMinMax of each image in the time series:\n                self.axes['c'] -= 1\n            self._imageLevels = self.quickMinMax(self.imageDisp[self.currentIndex])\n            self.levelMin = min([level[0] for level in self._imageLevels])\n            self.levelMax = max([level[1] for level in self._imageLevels])\n            self.autoLevels()\n            if self.axes['c'] is not None:\n                # Now we bring it back to where it was before\n                self.axes['c'] += 1\n        return rtrn",
  "def quickMinMax(self, data):\n        \"\"\"Reimplements the ImageView.quickMinMax to set level percentiles\"\"\"\n        mm = super(ExtendedImageView, self).quickMinMax(data)\n        return [(np.percentile(x, self.level_percentiles[0]),\n                 np.percentile(x, self.level_percentiles[1])) for x in mm]",
  "def pos_to_unit(self, positions):\n        \"\"\"\n        Given an iterable of positions, iterates over them and returns the scaled values along the corresponding axis.\n        Uses the ArbitraryAxis.pos_to_unit method\n\n        :param positions: 2- or 4-tuple of floats. If two values given, assumed it corresponds to the (bottom, left)\n        axis, if four values the order should be (bottom, left, top, right) as given by self.get_axes()\n        :return:\n        \"\"\"\n        axs = self.get_axes()\n        units = ()\n\n        if len(positions) == 2:\n            axs = axs[:2]\n        for ax, pos in zip(axs, positions):\n            if hasattr(ax, 'pos_to_unit'):\n                units += (ax.pos_to_unit(pos),)\n            else:\n                units += (pos,)\n\n        return units",
  "def crosshair_moved(self):\n        \"\"\"\n        Displays the current position of the two cross-hairs, as well as the distance between them, in pixels and in\n        units (when given)\n        :return:\n        \"\"\"\n        try:\n            # First gets the crosshair positions, and finds the distance between them\n            positions = ()\n            for idx in [1, 2]:\n                xhair = getattr(self, \"CrossHair%d\" % idx)\n                pos = tuple(xhair.referenced_pos())\n                positions += pos\n            diff = np.linalg.norm(np.array(positions[:2]) - np.array(positions[2:]))\n            positions += (diff,)\n\n            display_string = \"Pixels: <span style='color: red'>[%i,%i] </span> \" \\\n                             \"<span style='color: green'> [%i,%i] </span> \" \\\n                             u\"\\u0394px=%g\" % positions\n\n            # If any units are given, get the positions and scale them using pos_to_unit\n            if any([self.axis_units[x] is not None for x in ['bottom', 'left']]):\n                scaled_positions = ()\n                for idx in [1, 2]:\n                    xhair = getattr(self, \"CrossHair%d\" % idx)\n                    pos = tuple(xhair.referenced_pos())\n                    scaled_positions += self.pos_to_unit(pos)\n                units = ()\n                for ax in ['bottom', 'left']:\n                    if self.axis_units[ax] is None:\n                        units += ('px',)\n                    else:\n                        units += (self.axis_units[ax],)\n                display_string += \"\\t(%s, %s):\" \\\n                                  \"<span style='color: red'> (%g, %g)</span> \" \\\n                                  \"<span style='color: green'> (%g, %g)</span> \" % (units + scaled_positions)\n\n                # If the bottom and left axis have the same units, display the distance between the crosshairs\n                if self.axis_units['bottom'] == self.axis_units['left']:\n                    difft = np.linalg.norm(np.array(scaled_positions[:2]) - np.array(scaled_positions[2:]))\n                    unit = self.axis_units['bottom']\n                    display_string += u\"\\u0394%s=%g\" % (unit, difft)\n\n            self.label_crosshairpos.setText(display_string)\n        except Exception as e:\n            print('Failed updating crosshair position: %s' % e)",
  "def get_roi(self):\n        \"\"\"\n        Pixel positions of the edges of the rectangle bound by the crosshairs\n        :return: 4-tuple of integers. left, right, top, and bottom edges\n        \"\"\"\n        assert hasattr(self, 'CrossHair1')\n        assert hasattr(self, 'CrossHair2')\n\n        pos1 = self.CrossHair1.referenced_pos()\n        pos2 = self.CrossHair2.referenced_pos()\n        if pos1 == pos2:\n            return None\n\n        min_x, max_x = [int(x) for x in (min(pos1[0], pos2[0]), max(pos1[0], pos2[0]))]\n        min_y, max_y = [int(x) for x in (min(pos1[1], pos2[1]), max(pos1[1], pos2[1]))]\n\n        return min_x, max_x, min_y, max_y",
  "def get_value(index):\n            \"\"\"Function that extracts the value from a list (axis_vectors) according to some given position (index),\n            returning NaN if the index is out of range\"\"\"\n            if int(index) < 0 or int(index) > len(self.axis_values):\n                return np.nan\n            else:\n                return self.axis_values[int(index)]",
  "class SerialInstrument(MessageBusInstrument):\n    \"\"\"\n    An instrument primarily using serial communications\n    \"\"\"\n    port_settings = {}\n    initial_character = ''\n    \"\"\"A dictionary of serial port settings.  It is passed as the keyword\n    arguments to the constructor of the underlying serial port object, so\n    see the documentation for pyserial for full explanations.\n\n    port\n        Device name or port number number or None.\n    baudrate\n        Baud rate such as 9600 or 115200 etc.\n    bytesize\n        Number of data bits. Possible values: FIVEBITS, SIXBITS, SEVENBITS, EIGHTBITS\n    parity\n        Enable parity checking. Possible values: PARITY_NONE, PARITY_EVEN, PARITY_ODD PARITY_MARK, PARITY_SPACE\n    stopbits\n        Number of stop bits. Possible values: STOPBITS_ONE, STOPBITS_ONE_POINT_FIVE, STOPBITS_TWO\n    timeout\n        Set a read timeout value.\n    xonxoff\n        Enable software flow control.\n    rtscts\n        Enable hardware (RTS/CTS) flow control.\n    dsrdtr\n        Enable hardware (DSR/DTR) flow control.\n    writeTimeout\n        Set a write timeout value.\n    interCharTimeout\n        Inter-character timeout, None to disable (default).\n    \"\"\"\n\n    _serial_port_lock = threading.Lock()\n\n    def __init__(self, port=None):\n        \"\"\"\n        Set up the serial port and so on.\n        \"\"\"\n        MessageBusInstrument.__init__(self)  # Using super() here can cause issues with multiple inheritance.\n        # Eventually this shouldn't rely on init...\n        if self.termination_read is None:\n            self.termination_read = self.termination_character\n        self.open(port, False)\n\n    @property\n    def timeout(self):\n        return self._timeout\n\n    @timeout.setter\n    def timeout(self, value):\n        self.ser._timeout = self._timeout = value\n        self.ser._reconfigure_port()\n\n    def open(self, port=None, quiet=True):\n        \"\"\"Open communications with the serial port.\n\n        If no port is specified, it will attempt to autodetect.  If quiet=True\n        then we don't warn when ports are opened multiple times.\n        \"\"\"\n        with self.communications_lock:\n            if hasattr(self, 'ser') and self.ser.isOpen():\n                if not quiet: print(\"Warning: attempted to open an already-open port!\")\n                return\n            if port is None: port = self.find_port()\n            assert port is not None, \"We don't have a serial port to open, meaning you didn't specify a valid port and autodetection failed.  Are you sure the instrument is connected?\"\n            self.ser = serial.Serial(port, **self.port_settings)\n            # self.ser_io = io.TextIOWrapper(io.BufferedRWPair(self.ser, self.ser,1),\n            #                                newline = self.termination_character,\n            #                                line_buffering = True)\n            # the block above wraps the serial IO layer with a text IO layer\n            # this allows us to read/write in neat lines.  NB the buffer size must\n            # be set to 1 byte for maximum responsiveness.\n            assert self.test_communications(), \"The instrument doesn't seem to be responding.  Did you specify the right port?\"\n\n    def close(self):\n        \"\"\"Release the serial port\"\"\"\n        with self.communications_lock:\n            try:\n                self.ser.close()\n            except Exception as e:\n                print(\"The serial port didn't close cleanly:\", e)\n\n    def __del__(self):\n        self.close()\n\n    def _write(self, query_string, ignore_echo=False, timeout=None):\n        \"\"\"Write a string to the serial port\"\"\"\n        assert self.ser.isOpen(), \"Warning: attempted to write to the serial port before it was opened.  Perhaps you need to call the 'open' method first?\"\n        try:\n            if self.ser.outWaiting() > 0: self.ser.flushOutput()  # ensure there's nothing waiting\n        except AttributeError:\n            if self.ser.out_waiting > 0: self.ser.flushOutput()  # ensure there's nothing waiting\n        if ignore_echo: self.flush_input_buffer()\n        self.ser.write(str.encode(self.initial_character + str(query_string) + self.termination_character))\n        if ignore_echo:\n            echo = self.readline(timeout).strip()\n            if query_string != echo:\n                self._logger.warn('This write did not echo: ' + echo)\n\n    def flush_input_buffer(self):\n        \"\"\"Make sure there's nothing waiting to be read, and clear the buffer if there is.\"\"\"\n        with self.communications_lock:\n            self.ser.reset_input_buffer()\n            # if self.ser.inWaiting() > 0: self.ser.flushInput()\n    def flush_output_buffer(self):\n        \"\"\"Make sure there's nothing waiting to be written, and clear the buffer if there is.\"\"\"\n        with self.communications_lock:\n            self.ser.reset_output_buffer()\n\n    def readline(self, timeout=None):\n        with self.communications_lock:\n            if hasattr(self, 'timeout') and timeout is None:\n                timeout = self.timeout\n            elif timeout is None:\n                timeout = 10\n            eol = str.encode(self.termination_character)\n            leneol = len(eol)\n            line = bytearray()\n            start = time.time()\n            while time.time() - start < timeout:\n                c = self.ser.read(1)\n                if c:\n                    line += c\n                    if line[-leneol:] == eol:\n                        break\n                else:\n                    break\n            return line.decode().replace(self.termination_read, '\\n')\n\n    def test_communications(self):\n        \"\"\"Check if the device is available on the current port.\n\n        This should be overridden by subclasses.  Assume the port has been\n        successfully opened and the settings are as defined by self.port_settings.\n        Usually this function sends a command and checks for a known reply.\"\"\"\n        with self.communications_lock:\n            return True\n\n    def find_port(self):\n        \"\"\"Iterate through the available serial ports and query them to see\n        if our instrument is there.\"\"\"\n        with self.communications_lock:\n            success = False\n            for port_name, _, _ in serial.tools.list_ports.comports():  # loop through serial ports, apparently 256 is the limit?!\n                try:\n                    print(\"Trying port\", port_name)\n                    self.open(port_name)\n                    success = True\n                    print(\"Success!\")\n                except:\n                    pass\n                finally:\n                    try:\n                        self.close()\n                    except:\n                        pass  # we don't care if there's an error closing the port...\n                if success:\n                    break  # again, make sure this happens *after* closing the port\n            if success:\n                return port_name\n            else:\n                return None",
  "def __init__(self, port=None):\n        \"\"\"\n        Set up the serial port and so on.\n        \"\"\"\n        MessageBusInstrument.__init__(self)  # Using super() here can cause issues with multiple inheritance.\n        # Eventually this shouldn't rely on init...\n        if self.termination_read is None:\n            self.termination_read = self.termination_character\n        self.open(port, False)",
  "def timeout(self):\n        return self._timeout",
  "def timeout(self, value):\n        self.ser._timeout = self._timeout = value\n        self.ser._reconfigure_port()",
  "def open(self, port=None, quiet=True):\n        \"\"\"Open communications with the serial port.\n\n        If no port is specified, it will attempt to autodetect.  If quiet=True\n        then we don't warn when ports are opened multiple times.\n        \"\"\"\n        with self.communications_lock:\n            if hasattr(self, 'ser') and self.ser.isOpen():\n                if not quiet: print(\"Warning: attempted to open an already-open port!\")\n                return\n            if port is None: port = self.find_port()\n            assert port is not None, \"We don't have a serial port to open, meaning you didn't specify a valid port and autodetection failed.  Are you sure the instrument is connected?\"\n            self.ser = serial.Serial(port, **self.port_settings)\n            # self.ser_io = io.TextIOWrapper(io.BufferedRWPair(self.ser, self.ser,1),\n            #                                newline = self.termination_character,\n            #                                line_buffering = True)\n            # the block above wraps the serial IO layer with a text IO layer\n            # this allows us to read/write in neat lines.  NB the buffer size must\n            # be set to 1 byte for maximum responsiveness.\n            assert self.test_communications(), \"The instrument doesn't seem to be responding.  Did you specify the right port?\"",
  "def close(self):\n        \"\"\"Release the serial port\"\"\"\n        with self.communications_lock:\n            try:\n                self.ser.close()\n            except Exception as e:\n                print(\"The serial port didn't close cleanly:\", e)",
  "def __del__(self):\n        self.close()",
  "def _write(self, query_string, ignore_echo=False, timeout=None):\n        \"\"\"Write a string to the serial port\"\"\"\n        assert self.ser.isOpen(), \"Warning: attempted to write to the serial port before it was opened.  Perhaps you need to call the 'open' method first?\"\n        try:\n            if self.ser.outWaiting() > 0: self.ser.flushOutput()  # ensure there's nothing waiting\n        except AttributeError:\n            if self.ser.out_waiting > 0: self.ser.flushOutput()  # ensure there's nothing waiting\n        if ignore_echo: self.flush_input_buffer()\n        self.ser.write(str.encode(self.initial_character + str(query_string) + self.termination_character))\n        if ignore_echo:\n            echo = self.readline(timeout).strip()\n            if query_string != echo:\n                self._logger.warn('This write did not echo: ' + echo)",
  "def flush_input_buffer(self):\n        \"\"\"Make sure there's nothing waiting to be read, and clear the buffer if there is.\"\"\"\n        with self.communications_lock:\n            self.ser.reset_input_buffer()",
  "def flush_output_buffer(self):\n        \"\"\"Make sure there's nothing waiting to be written, and clear the buffer if there is.\"\"\"\n        with self.communications_lock:\n            self.ser.reset_output_buffer()",
  "def readline(self, timeout=None):\n        with self.communications_lock:\n            if hasattr(self, 'timeout') and timeout is None:\n                timeout = self.timeout\n            elif timeout is None:\n                timeout = 10\n            eol = str.encode(self.termination_character)\n            leneol = len(eol)\n            line = bytearray()\n            start = time.time()\n            while time.time() - start < timeout:\n                c = self.ser.read(1)\n                if c:\n                    line += c\n                    if line[-leneol:] == eol:\n                        break\n                else:\n                    break\n            return line.decode().replace(self.termination_read, '\\n')",
  "def test_communications(self):\n        \"\"\"Check if the device is available on the current port.\n\n        This should be overridden by subclasses.  Assume the port has been\n        successfully opened and the settings are as defined by self.port_settings.\n        Usually this function sends a command and checks for a known reply.\"\"\"\n        with self.communications_lock:\n            return True",
  "def find_port(self):\n        \"\"\"Iterate through the available serial ports and query them to see\n        if our instrument is there.\"\"\"\n        with self.communications_lock:\n            success = False\n            for port_name, _, _ in serial.tools.list_ports.comports():  # loop through serial ports, apparently 256 is the limit?!\n                try:\n                    print(\"Trying port\", port_name)\n                    self.open(port_name)\n                    success = True\n                    print(\"Success!\")\n                except:\n                    pass\n                finally:\n                    try:\n                        self.close()\n                    except:\n                        pass  # we don't care if there's an error closing the port...\n                if success:\n                    break  # again, make sure this happens *after* closing the port\n            if success:\n                return port_name\n            else:\n                return None",
  "def detect_APT_VCP_devices():\n    \"\"\"Function to tell you what devices are connected to what comports \"\"\"\n    possible_destinations = [0x50, 0x11, 0x21, 0x22, 0x23, 0x24, 0x25, 0x26, 0x27, 0x28, 0x29, 0x2A]\n    device_dict = dict()\n    for port_name, _, _ in list_ports.comports():  # loop through serial ports, apparently 256 is the limit?!\n\n        print(\"Trying port\", port_name)\n        try:\n            for destination in possible_destinations:\n                try:\n                    test_device = APT_VCP(port_name, destination=destination)\n                    device_dict[port_name] = {'destination': destination,\n                                              'Serial Number': test_device.serial_number,\n                                              'Model': test_device.model}\n                    break\n                except struct.error:\n                    pass\n        except serial.serialutil.SerialException:\n            pass\n    return device_dict",
  "class APT_VCP(serial_instrument.SerialInstrument):\n    \"\"\"\n    This class handles all the basic communication with APT virtual com ports\n    \"\"\"\n    port_settings = dict(baudrate=115200,\n                         bytesize=8,\n                         parity=serial.PARITY_NONE,\n                         stopbits=1,\n                         xonxoff=0,\n                         rtscts=0,\n                         timeout=1,\n                         writeTimeout=1)\n    termination_character = \"\"  # The APT communicates via fixed length messages therefore this is not required\n    surprise_message_codes = {'MGMSG_HW_RESPONSE': 0x0080,\n                              # The message id codes for messages sent from the hardware to the device.\n                              'MGMSG_HW_RICHRESPONSE': 0x0081,\n                              # One for one line error code and one for longer error codes\n                              'Status update id': None}  # This is the satus update message id that varies for each device and therefore must be set\n\n    channel_number_to_identity = {1: 0x01, 2: 0x02, 3: 0x04, 4: 0x08}  # Sets up the channel numbers to values\n    state_conversion = {True: 0x01,\n                        False: 0x02}  # Sets up the conversion from True and False values to 1's and 2's (godknows why they havnt used 0 and 1)\n    reverse_state_conversion = {0x01: True, 0x02: False}\n    serial_num_to_device_types = {0: ['Filter flipper', 'MFF002'],\n                                  20: ['Legacy Single channel stepper driver', 'BSC001'],\n                                  25: ['Legacy single channel mini stepper driver', 'BMS001'],\n                                  27: ['K - Cube brushed DC servo driver', 'KDCT101'],\n                                  28: ['K - Cube brushless DC servo driver', 'KBD101'],\n                                  30: ['Legacy dual channel stepper driver', 'BSC002'],\n                                  35: ['Legacy dual channel mini stepper driver', 'BMS002'],\n                                  40: ['Single channel stepper driver', 'BSC101'],\n                                  60: ['OptoSTDriver(mini stepper driver)', 'OST001'],\n                                  63: ['OptoDCDriver (mini DC servo driver)', 'ODC001'],\n                                  70: ['Three channel card slot stepper driver', 'BSC103'],\n                                  80: ['Stepper Driver T-Cube', 'TST001'],\n                                  83: ['DC Driver T-Cube', 'TDC001'],\n                                  73: ['Brushless DC motherboard', 'BBD102/BBD103'],\n                                  94: ['Brushless DC motor card', 'BBD102/BBD103']}\n    command_log = deque(maxlen=20)  # stores commands sent to the device\n    timeout = 30\n    def __init__(self, port=None, source=0x01, destination=None, use_si_units=False, stay_alive=False):\n        \"\"\"\n        Set up the serial port, setting source and destinations, verbosity and hardware info.\n        \"\"\"\n        serial_instrument.SerialInstrument.__init__(self, port=port)  # this opens the port\n        self.source = source\n        if destination is None:\n            self._logger.error('destination has not been set!')\n        elif type(destination) != dict:\n            self.destination = {'1': destination}\n        else:\n            self.destination = destination\n        self.stay_alive = stay_alive\n        self.serial_number = None\n        self.model = None\n        self.number_of_channels = None\n        hrdwr_info = self.get_hardware_info()  # sets things like the serial_number, model and number_of_channels\n        self._logger.debug(hrdwr_info)\n\n    @staticmethod\n    def unpack_binary_mask(value, size=13):\n        lst = [bool(value & (1 << size - i - 1)) for i in range(size)]\n        lst.reverse()\n        return lst\n\n    @staticmethod\n    def _bit_mask_array(value, bit_mask):\n        final_mask = []\n        for mask in bit_mask:\n            final_mask += [bool(value & int(mask))]\n        return final_mask\n\n    def read(self):\n        \"\"\"Overwrite the read command with a fixed length read, check\n            for additional data stream and error codes\"\"\"\n        header = bytearray(self.ser.read(6))  # read 6 byte header\n        msgid, length, dest, source = struct.unpack('<HHBB',\n                                                    header)  # unpack the header as described by the format were a second data stream is expected\n        if msgid in list(self.surprise_message_codes.values()):  # Compare the message code to the list of suprise message codes\n            if msgid == self.surprise_message_codes['MGMSG_HW_RESPONSE']:\n                msgid, param1, param2, dest, source = struct.unpack('<HBBBB', header)\n                returned_message = {'message': msgid, 'param1': param1,\n                                    'param2': param2, 'dest': dest,\n                                    'source': source}\n                self._logger.debug(returned_message)\n                self.read()\n            elif msgid == self.surprise_message_codes['MGMSG_HW_RICHRESPONSE']:\n                data = self.ser.read(length)\n                returned_message = {'message': msgid, 'length': length,\n                                    'dest': dest, 'source': source,\n                                    'data': data}\n                self._logger.debug(returned_message)\n                self.read()\n            elif (msgid == self.surprise_message_codes['Status update id']\n                  and self.command_log[-1] == self.surprise_message_codes['Status update id']):\n                data = self.ser.read(length)\n                returned_message = {'message': msgid, 'length': length,\n                                    'dest': dest, 'source': source,\n                                    'data': data}\n                self.update_status(returned_message)\n                self.read()\n        else:\n            if self.source | 0x80 == dest:\n                data = self.ser.read(length)\n                returned_message = {'message': msgid, 'length': length,\n                                    'dest': dest, 'source': source,\n                                    'data': data}\n            elif self.source != dest:\n                if dest <= 0x80:\n                    self.source = dest\n                else:\n                    self.source = dest-128\n                data = self.ser.read(length)\n                returned_message = {'message': msgid, 'length': length,\n                                    'dest': dest, 'source': source,\n                                    'data': data}\n            else:\n                msgid, param1, param2, dest, source = struct.unpack('<HBBBB', header)\n\n                returned_message = {'message': msgid, 'param1': param1,\n                                    'param2': param2, 'dest': dest,\n                                    'source': source}\n            return returned_message\n\n    def _write(self, message_id, param1=0x00, param2=0x00, data=None, destination_id=None):\n        \"\"\"Overwrite the serial write command to combine message_id,\n            two possible parameters (set to 0 if not given)\n            with the source and destinations \"\"\"\n        if destination_id is None:\n            destination = list(self.destination.values())[0]\n        else:\n            destination = self.destination[destination_id]\n        if data is None:\n            formated_message = bytearray(struct.pack('<HBBBB', message_id, param1, param2, destination, self.source))\n        else:\n            param1 = len(data)\n            formated_message = bytearray(struct.pack('<HBBBB', message_id, param1, param2,\n                                                     destination | 0x80, self.source))\n            formated_message += data\n        \n        if len(self.command_log) == self.command_log.maxlen \\\n                and 0x0492 not in self.command_log \\\n                and self.stay_alive:\n            self.command_log.append(0x0492)\n            self.staying_alive()\n        self.command_log.append(message_id)\n        self.ser.write(formated_message)\n    write = _write\n\n    def query(self, message_id, param1=0x00, param2=0x00, data=None, destination_id=None, blocking=False):\n        \"\"\"Overwrite the query command to allow the correct passing of message_ids and parameters\"\"\"\n        with self.communications_lock:\n            self.flush_input_buffer()\n            self._write(message_id, param1, param2, data=data, destination_id=destination_id)\n            time.sleep(0.1)\n            if blocking:\n                reply = self._waitForReply()\n                if reply[0]:\n                    return reply[1]\n                else:\n                    self._logger.error('No reply received for message ' + str(message_id))\n                    return reply[1]\n            else:\n                return self.read()  # question: should we strip the final newline?\n\n    # Listing General control message, not all of these can be used with every piece of equipment\n    def identify(self):\n        \"\"\"Instruct hardware unit to identify itself by flashing its LED\"\"\"\n        self.write(0x0223)\n\n    def set_channel_state(self, channel_number, new_state, destination_id=None):\n        \"\"\"Enable or disable a channel\"\"\"\n        channel_identity = self.channel_number_to_identity[channel_number]\n        new_state = self.state_conversion[new_state]\n        self.write(0x0210, param1=channel_identity, param2=new_state, destination_id=destination_id)\n\n    def get_channel_state(self, channel_number, destination_id=None):\n        \"\"\"Get the current state of a channel\"\"\"\n        message_dict = self.query(0x0211, param1=self.channel_number_to_identity[\n            channel_number], destination_id=destination_id)  # Get the entire message dictionary\n        current_state = self.reverse_state_conversion[\n            message_dict['param2']]  # pull out the current state parameter and convert it to a True/False value\n        return current_state\n\n    def disconnect(self, destination_id=None):\n        \"\"\"Disconnect the controller from the usb bus\"\"\"\n        self.write(0x002, destination_id=destination_id)\n\n    def enable_updates(self, enable_state, update_rate=10, destination_id=None):\n        \"\"\"Enable or disable hardware updates\"\"\"\n        if enable_state:\n            self.write(0x0011, param1=update_rate, destination_id=destination_id)\n        else:\n            self.write(0x0012, destination_id=destination_id)\n\n    def get_hardware_info(self, destination_id=None):\n        \"\"\"Manually get a status update\"\"\"\n        message_dict = self.query(0x0005, destination_id=destination_id)\n        serialnum, model, hwtype, swversion, notes, hwversion, modstate, nchans = struct.unpack('<I8sHI48s12xHHH',\n                                                                                                message_dict['data'])\n        if serialnum != 0 and len(str(serialnum)) != 8:\n            serialnum = int(hex(serialnum)[2:-1])\n\n        hardware_dict = {'serial_number': serialnum, 'model': str(model).replace('\\x00', ''), 'hardware_type': hwtype,\n                         'software_version': swversion, 'notes': str(notes).replace('\\x00', ''),\n                         'hardware_version': hwversion,\n                         'modstate': modstate, 'number_of_channels': nchans}\n        self.serial_number = serialnum\n\n        try:\n            self.model = self.serial_num_to_device_types[int(str(serialnum)[0:2])]\n        except KeyError:\n            self.model = ['Dummy', 'Serial number not recognised in the serial_num_to_device_types']\n            self._logger.warn('Serial number not recognised. Model set to Dummy')\n        self.number_of_channels = nchans\n        return hardware_dict\n\n    def get_status_update(self):\n        \"\"\"This need subclassing and written over as the commands and format\n        varies between devices\"\"\"\n        raise NotImplementedError\n\n    def update_status(self):\n        \"\"\"This  command should update device properties from the update message\n            however this has to be defined for every device as the status update format\n            and commands vary,\n            please implement me\n            Args:\n                The returned message from a status update request           (dict)\"\"\"\n        raise NotImplementedError\n\n    def staying_alive(self, destination_id=None):\n        \"\"\"Keeps the motor controller from thinking the Pc has crashed \"\"\"\n        if destination_id is None:\n            destination_id = list(self.destination.keys())\n        else:\n            if not hasattr(destination_id, '__iter__'):\n                destination_id = tuple(destination_id)\n        for dest in destination_id:\n            self._logger.debug(str(dest))\n            self.write(0x0492, destination_id=dest)\n        self._logger.debug(str(destination_id) + str(dest))\n        \n    def _waitForReply(self):\n        reply = ''\n        t0 = time.time()\n        while len(reply) == 0:\n            try:\n                reply = self.read()\n            except struct.error:\n                reply = ''\n            time.sleep(0.1)\n            if time.time() - t0 > self.timeout:\n                return False, ''\n        return True, reply",
  "def __init__(self, port=None, source=0x01, destination=None, use_si_units=False, stay_alive=False):\n        \"\"\"\n        Set up the serial port, setting source and destinations, verbosity and hardware info.\n        \"\"\"\n        serial_instrument.SerialInstrument.__init__(self, port=port)  # this opens the port\n        self.source = source\n        if destination is None:\n            self._logger.error('destination has not been set!')\n        elif type(destination) != dict:\n            self.destination = {'1': destination}\n        else:\n            self.destination = destination\n        self.stay_alive = stay_alive\n        self.serial_number = None\n        self.model = None\n        self.number_of_channels = None\n        hrdwr_info = self.get_hardware_info()  # sets things like the serial_number, model and number_of_channels\n        self._logger.debug(hrdwr_info)",
  "def unpack_binary_mask(value, size=13):\n        lst = [bool(value & (1 << size - i - 1)) for i in range(size)]\n        lst.reverse()\n        return lst",
  "def _bit_mask_array(value, bit_mask):\n        final_mask = []\n        for mask in bit_mask:\n            final_mask += [bool(value & int(mask))]\n        return final_mask",
  "def read(self):\n        \"\"\"Overwrite the read command with a fixed length read, check\n            for additional data stream and error codes\"\"\"\n        header = bytearray(self.ser.read(6))  # read 6 byte header\n        msgid, length, dest, source = struct.unpack('<HHBB',\n                                                    header)  # unpack the header as described by the format were a second data stream is expected\n        if msgid in list(self.surprise_message_codes.values()):  # Compare the message code to the list of suprise message codes\n            if msgid == self.surprise_message_codes['MGMSG_HW_RESPONSE']:\n                msgid, param1, param2, dest, source = struct.unpack('<HBBBB', header)\n                returned_message = {'message': msgid, 'param1': param1,\n                                    'param2': param2, 'dest': dest,\n                                    'source': source}\n                self._logger.debug(returned_message)\n                self.read()\n            elif msgid == self.surprise_message_codes['MGMSG_HW_RICHRESPONSE']:\n                data = self.ser.read(length)\n                returned_message = {'message': msgid, 'length': length,\n                                    'dest': dest, 'source': source,\n                                    'data': data}\n                self._logger.debug(returned_message)\n                self.read()\n            elif (msgid == self.surprise_message_codes['Status update id']\n                  and self.command_log[-1] == self.surprise_message_codes['Status update id']):\n                data = self.ser.read(length)\n                returned_message = {'message': msgid, 'length': length,\n                                    'dest': dest, 'source': source,\n                                    'data': data}\n                self.update_status(returned_message)\n                self.read()\n        else:\n            if self.source | 0x80 == dest:\n                data = self.ser.read(length)\n                returned_message = {'message': msgid, 'length': length,\n                                    'dest': dest, 'source': source,\n                                    'data': data}\n            elif self.source != dest:\n                if dest <= 0x80:\n                    self.source = dest\n                else:\n                    self.source = dest-128\n                data = self.ser.read(length)\n                returned_message = {'message': msgid, 'length': length,\n                                    'dest': dest, 'source': source,\n                                    'data': data}\n            else:\n                msgid, param1, param2, dest, source = struct.unpack('<HBBBB', header)\n\n                returned_message = {'message': msgid, 'param1': param1,\n                                    'param2': param2, 'dest': dest,\n                                    'source': source}\n            return returned_message",
  "def _write(self, message_id, param1=0x00, param2=0x00, data=None, destination_id=None):\n        \"\"\"Overwrite the serial write command to combine message_id,\n            two possible parameters (set to 0 if not given)\n            with the source and destinations \"\"\"\n        if destination_id is None:\n            destination = list(self.destination.values())[0]\n        else:\n            destination = self.destination[destination_id]\n        if data is None:\n            formated_message = bytearray(struct.pack('<HBBBB', message_id, param1, param2, destination, self.source))\n        else:\n            param1 = len(data)\n            formated_message = bytearray(struct.pack('<HBBBB', message_id, param1, param2,\n                                                     destination | 0x80, self.source))\n            formated_message += data\n        \n        if len(self.command_log) == self.command_log.maxlen \\\n                and 0x0492 not in self.command_log \\\n                and self.stay_alive:\n            self.command_log.append(0x0492)\n            self.staying_alive()\n        self.command_log.append(message_id)\n        self.ser.write(formated_message)",
  "def query(self, message_id, param1=0x00, param2=0x00, data=None, destination_id=None, blocking=False):\n        \"\"\"Overwrite the query command to allow the correct passing of message_ids and parameters\"\"\"\n        with self.communications_lock:\n            self.flush_input_buffer()\n            self._write(message_id, param1, param2, data=data, destination_id=destination_id)\n            time.sleep(0.1)\n            if blocking:\n                reply = self._waitForReply()\n                if reply[0]:\n                    return reply[1]\n                else:\n                    self._logger.error('No reply received for message ' + str(message_id))\n                    return reply[1]\n            else:\n                return self.read()",
  "def identify(self):\n        \"\"\"Instruct hardware unit to identify itself by flashing its LED\"\"\"\n        self.write(0x0223)",
  "def set_channel_state(self, channel_number, new_state, destination_id=None):\n        \"\"\"Enable or disable a channel\"\"\"\n        channel_identity = self.channel_number_to_identity[channel_number]\n        new_state = self.state_conversion[new_state]\n        self.write(0x0210, param1=channel_identity, param2=new_state, destination_id=destination_id)",
  "def get_channel_state(self, channel_number, destination_id=None):\n        \"\"\"Get the current state of a channel\"\"\"\n        message_dict = self.query(0x0211, param1=self.channel_number_to_identity[\n            channel_number], destination_id=destination_id)  # Get the entire message dictionary\n        current_state = self.reverse_state_conversion[\n            message_dict['param2']]  # pull out the current state parameter and convert it to a True/False value\n        return current_state",
  "def disconnect(self, destination_id=None):\n        \"\"\"Disconnect the controller from the usb bus\"\"\"\n        self.write(0x002, destination_id=destination_id)",
  "def enable_updates(self, enable_state, update_rate=10, destination_id=None):\n        \"\"\"Enable or disable hardware updates\"\"\"\n        if enable_state:\n            self.write(0x0011, param1=update_rate, destination_id=destination_id)\n        else:\n            self.write(0x0012, destination_id=destination_id)",
  "def get_hardware_info(self, destination_id=None):\n        \"\"\"Manually get a status update\"\"\"\n        message_dict = self.query(0x0005, destination_id=destination_id)\n        serialnum, model, hwtype, swversion, notes, hwversion, modstate, nchans = struct.unpack('<I8sHI48s12xHHH',\n                                                                                                message_dict['data'])\n        if serialnum != 0 and len(str(serialnum)) != 8:\n            serialnum = int(hex(serialnum)[2:-1])\n\n        hardware_dict = {'serial_number': serialnum, 'model': str(model).replace('\\x00', ''), 'hardware_type': hwtype,\n                         'software_version': swversion, 'notes': str(notes).replace('\\x00', ''),\n                         'hardware_version': hwversion,\n                         'modstate': modstate, 'number_of_channels': nchans}\n        self.serial_number = serialnum\n\n        try:\n            self.model = self.serial_num_to_device_types[int(str(serialnum)[0:2])]\n        except KeyError:\n            self.model = ['Dummy', 'Serial number not recognised in the serial_num_to_device_types']\n            self._logger.warn('Serial number not recognised. Model set to Dummy')\n        self.number_of_channels = nchans\n        return hardware_dict",
  "def get_status_update(self):\n        \"\"\"This need subclassing and written over as the commands and format\n        varies between devices\"\"\"\n        raise NotImplementedError",
  "def update_status(self):\n        \"\"\"This  command should update device properties from the update message\n            however this has to be defined for every device as the status update format\n            and commands vary,\n            please implement me\n            Args:\n                The returned message from a status update request           (dict)\"\"\"\n        raise NotImplementedError",
  "def staying_alive(self, destination_id=None):\n        \"\"\"Keeps the motor controller from thinking the Pc has crashed \"\"\"\n        if destination_id is None:\n            destination_id = list(self.destination.keys())\n        else:\n            if not hasattr(destination_id, '__iter__'):\n                destination_id = tuple(destination_id)\n        for dest in destination_id:\n            self._logger.debug(str(dest))\n            self.write(0x0492, destination_id=dest)\n        self._logger.debug(str(destination_id) + str(dest))",
  "def _waitForReply(self):\n        reply = ''\n        t0 = time.time()\n        while len(reply) == 0:\n            try:\n                reply = self.read()\n            except struct.error:\n                reply = ''\n            time.sleep(0.1)\n            if time.time() - t0 > self.timeout:\n                return False, ''\n        return True, reply",
  "class MessageBusInstrument(nplab.instrument.Instrument):\n    \"\"\"\n    Message Bus Instrument\n    ======================\n\n    An instrument that communicates by sending strings back and forth over a bus.\n\n    This base class provides commonly-used mechanisms that support the use of\n    serial or VISA instruments.  The SerialInstrument and VISAInstrument classes\n    both inherit from this class.  Most interactions with this class involve\n    a call to the `query` method.  This writes a message and returns the reply.\n    \n    \n\n    Subclassing Notes\n    -----------------\n\n    The minimum you need to do to create a working subclass is override the\n    `write()` and `readline()` methods.  You probably also want to provide an\n    open() and close() method to deal with the underlying port, and put\n    something sensible in __init__ to open your port when it's created.\n\n    It's also a very good idea to provide some way to flush the input buffer\n    with `flush_input_buffer()`.\n    \n    Threading Notes\n    ---------------\n    \n    The message bus protocol includes a property, `communications_lock`.  All\n    commands that use the communications bus should be protected by this lock.\n    It's also permissible to use it to protect sequences of calls to the bus \n    that must be atomic (e.g. a multi-part exchange of messages).  However, try\n    not to hold it too long - or odd things might happen if other threads are \n    blocked for a long time.  The lock is reentrant so there's no issue with\n    acquiring it twice.\n    \"\"\"\n    termination_character = \"\\n\"  #: All messages to or from the instrument end with this character.\n    termination_read = None  #: Can be used if the writing and reading termination characters are different. Currently implemented in serial_instrument\n    termination_line = None  #: If multi-line responses are recieved, they must end with this string\n    ignore_echo = False\n\n    _communications_lock = None\n\n    @property\n    def communications_lock(self):\n        \"\"\"A lock object used to protect access to the communications bus\"\"\"\n        # This requires initialisation but our init method won't be called - so\n        # the property initialises it on first use.\n        if self._communications_lock is None:\n            self._communications_lock = threading.RLock()\n        return self._communications_lock\n\n    def write(self, write_string, timeout=None, *args, **kwargs):\n        \"\"\"Write a string to the unerlying communications port\"\"\"\n        with self.communications_lock:\n            self._write(write_string, *args, **kwargs)\n        self._check_echo(write_string, timeout)\n\n    def _write(self, query_string, *args, **kwargs):\n        raise NotImplementedError(\"Subclasses of MessageBusInstrument must override the _write method!\")\n\n    def flush_input_buffer(self):\n        \"\"\"Make sure there's nothing waiting to be read.\n\n        This function should be overridden to make sure nothing's lurking in\n        the input buffer that could confuse a query.\n        \"\"\"\n        with self.communications_lock:\n            pass\n    \n    def readline(self, timeout=None):\n        \"\"\"Read one line from the underlying bus.  Must be overriden.\"\"\"\n        with self.communications_lock:\n            raise NotImplementedError(\"Subclasses of MessageBusInstrument must override the readline method!\")\n            \n    def read_multiline(self, termination_line=None, timeout=None):\n        \"\"\"Read one line from the underlying bus.  Must be overriden.\n\n        This should not need to be reimplemented unless there's a more efficient\n        way of reading multiple lines than multiple calls to readline().\"\"\"\n        with self.communications_lock:\n            if termination_line is None:\n                termination_line = self.termination_line\n\n            try:\n                assert isinstance(termination_line, basestring), \"If you perform a multiline query, you must specify a termination line either through the termination_line keyword argument or the termination_line property of the NPSerialInstrument.\"\n            except NameError:\n                assert isinstance(termination_line, str), \"If you perform a multiline query, you must specify a termination line either through the termination_line keyword argument or the termination_line property of the NPSerialInstrument.\"\n\n            response = \"\"\n            last_line = \"dummy\"\n            while termination_line not in last_line and len(last_line) > 0:  # read until we get the termination line.\n                last_line = self.readline(timeout)\n                response += last_line\n            return response\n\n    def query(self, query_string, multiline=False, termination_line=None, timeout=None):\n        \"\"\"\n        Write a string to the stage controller and return its response.\n\n        It will block until a response is received.  The multiline and termination_line commands\n        will keep reading until a termination phrase is reached.\n        \"\"\"\n        with self.communications_lock:\n            self.flush_input_buffer()\n            self.write(query_string, timeout)\n\n            if termination_line is not None:\n                multiline = True\n            if multiline:\n                return self.read_multiline(termination_line)\n            else:\n                return self.readline(timeout).strip()  # question: should we strip the final newline?\n\n    def _check_echo(self, echo_string, timeout=None):\n        if self.ignore_echo:\n            echo_line = self.readline(timeout).strip()\n            if echo_line != echo_string:\n                self._logger.warn('Command did not echo: %s' % echo_string)\n\n    def parsed_query_old(self, query_string, response_string=r\"(\\d+)\", re_flags=0, parse_function=int, **kwargs):\n        \"\"\"\n        Perform a query, then parse the result.\n\n        By default it looks for an integer and returns one, otherwise it will\n        match a custom regex string and return the subexpressions, parsed through\n        the supplied functions.\n\n        TODO: make this accept friendlier sscanf style arguments, and produce parse functions automatically\n        \"\"\"\n        # NB no need for the lock here - `query` is already an atomic operation.\n        reply = self.query(query_string, **kwargs)\n        res = re.search(response_string, reply, flags=re_flags)\n        if res is None:\n            raise ValueError(\"Stage response to '%s' ('%s') wasn't matched by /%s/\" % (query_string, reply, response_string))\n        try:\n            if len(res.groups()) == 1:\n                return parse_function(res.groups()[0])\n            else:\n                return list(map(parse_function,res.groups()))\n        except ValueError:\n            raise ValueError(\"Stage response to %s ('%s') couldn't be parsed by the supplied function\" % (query_string, reply))\n\n    def parsed_query(self, query_string, response_string=r\"%d\", re_flags=0, parse_function=None, **kwargs):\n        \"\"\"\n        Perform a query, returning a parsed form of the response.\n\n        First query the instrument with the given query string, then compare\n        the response against a template.  The template may contain text and\n        placeholders (e.g. %i and %f for integer and floating point values\n        respectively).  Regular expressions are also allowed - each group is\n        considered as one item to be parsed.  However, currently it's not\n        supported to use both % placeholders and regular expressions at the\n        same time.\n\n        If placeholders %i, %f, etc. are used, the returned values are\n        automatically converted to integer or floating point, otherwise you\n        must specify a parsing function (applied to all groups) or a list of\n        parsing functions (applied to each group in turn).\n        \"\"\"\n\n        response_regex = response_string\n        noop = lambda x: x  # placeholder null parse function\n        placeholders = [  # tuples of (regex matching placeholder, regex to replace it with, parse function)\n            (r\"%c\", r\".\", noop),\n            (r\"%(\\\\d+)c\", r\".{\\1}\", noop),  # TODO support %cn where n is a number of chars\n            (r\"%d\", r\"[-+]?\\\\d+\", int),\n            (r\"%[eEfg]\", r\"[-+]?(?:\\\\d+(?:\\.\\\\d*)?|\\.\\\\d+)(?:[eE][-+]?\\\\d+)?\", float),\n            # (r\"%(\\\\d+)c\",r\".{\\\\1}\", noop), #TODO support %cn where n is a number of chars\n            # (r\"%d\",r\"[-+]?\\\\d+\", int),\n            # (r\"%[eEfg]\",r\"[-+]?(?:\\\\d+(?:\\\\.\\\\d*)?|\\\\.\\\\d+)(?:[eE][-+]?\\\\d+)?\", float),\n            (r\"%i\", r\"[-+]?(?:0[xX][\\\\dA-Fa-f]+|0[0-7]*|\\\\d+)\", lambda x: int(x, 0)),  # 0=autodetect base\n            (r\"%o\", r\"[-+]?[0-7]+\", lambda x: int(x, 8)),  # 8 means octal\n            (r\"%s\", r\"\\\\S+\", noop),\n            (r\"%u\", r\"\\\\d+\", int),\n            (r\"%[xX]\", r\"[-+]?(?:0[xX])?[\\\\dA-Fa-f]+\", lambda x: int(x, 16)),  # 16 forces hexadecimal\n        ]\n        matched_placeholders = []\n        for placeholder, regex, parse_fun in placeholders:\n            response_regex = re.sub(placeholder, '(' + regex + ')', response_regex)  # substitute regex for placeholder\n            matched_placeholders.extend([(parse_fun, m.start()) for m in re.finditer(placeholder, response_string)])  # save the positions of the placeholders\n        if parse_function is None:\n            parse_function = [f for f, s in sorted(matched_placeholders, key=lambda m: m[1])]  # order parse functions by their occurrence in the original string\n        if not hasattr(parse_function, '__iter__'):\n            parse_function = [parse_function]  # make sure it's a list.\n\n        reply = self.query(query_string, **kwargs)  # do the query\n        res = re.search(response_regex, reply, flags=re_flags)\n        if res is None:\n            raise ValueError(\"Stage response to '%s' ('%s') wasn't matched by /%s/ (generated regex /%s/\" % (query_string, reply, response_string, response_regex))\n        try:\n            parsed_result = [f(g) for f, g in zip(parse_function, res.groups())]  # try to apply each parse function to its argument\n            if len(parsed_result) == 1:\n                return parsed_result[0]\n            else:\n                return parsed_result\n        except ValueError:\n            print(\"Parsing Error\")\n            print(\"Matched Groups:\", res.groups())\n            print(\"Parsing Functions:\", parse_function)\n            raise ValueError(\"Stage response to %s ('%s') couldn't be parsed by the supplied function\" % (query_string, reply))\n\n    def int_query(self, query_string, **kwargs):\n        \"\"\"Perform a query and return the result(s) as integer(s) (see parsedQuery)\"\"\"\n        return self.parsed_query(query_string, \"%d\", **kwargs)\n\n    def float_query(self, query_string, **kwargs):\n        \"\"\"Perform a query and return the result(s) as float(s) (see parsedQuery)\"\"\"\n        return self.parsed_query(query_string, \"%f\", **kwargs)",
  "class queried_property(object):\n    \"\"\"A Property interface that reads and writes from the instrument on the bus.\n    \n    This returns a property-like (i.e. a descriptor) object.  You can use it\n    in a class definition just like a property.  The property it creates will\n    interact with the instrument over the communication bus to set and retrieve\n    its value.\n    \"\"\"\n    def __init__(self, get_cmd=None, set_cmd=None, validate=None, valrange=None,\n                 fdel=None, doc=None, dtype='float'):\n        self.dtype = dtype\n        self.get_cmd = get_cmd\n        self.set_cmd = set_cmd\n        self.validate = validate\n        self.valrange = valrange\n        self.fdel = fdel\n        self.__doc__ = doc\n\n    # TODO: standardise the return (single value only vs parsed result), consider bool\n    def __get__(self, obj, objtype=None):\n        #print 'get', obj, objtype\n        if obj is None:\n            return self\n        if self.get_cmd is None:\n            raise AttributeError(\"unreadable attribute\")\n        if self.dtype == 'float':\n            getter = obj.float_query\n        elif self.dtype == 'int':\n            getter = obj.int_query\n        else:\n            getter = obj.query\n        value = getter(self.get_cmd)\n        if self.dtype == 'bool':\n            value = bool(value)\n        return value\n\n    def __set__(self, obj, value):\n        #print 'set', obj, value\n        if self.set_cmd is None:\n            raise AttributeError(\"can't set attribute\")\n        if self.validate is not None:\n            if value not in self.validate:\n                raise ValueError('invalid value supplied - value must be one of {}'.format(self.validate))\n        if self.valrange is not None:\n            if value < min(self.valrange) or value > max(self.valrange):\n                raise ValueError('invalid value supplied - value must be in the range {}-{}'.format(*self.valrange))\n        message = self.set_cmd\n        if '{0' in message:\n            message = message.format(value)\n        elif '%' in message:\n            message = message % value\n        obj.write(message)\n\n    def __delete__(self, obj):\n        if self.fdel is None:\n            raise AttributeError(\"can't delete attribute\")\n        self.fdel(obj)",
  "class queried_channel_property(queried_property):\n    # I'm not sure what this does or who uses it.  I assume it's Alan's? --rwb27\n    def __init__(self, get_cmd=None, set_cmd=None, validate=None, valrange=None,\n                 fdel=None, doc=None, dtype='float'):\n        super(queried_channel_property, self).__init__(get_cmd, set_cmd, validate, valrange,\n                                                       fdel, doc, dtype)\n\n    def __get__(self, obj, objtype=None):\n        assert hasattr(obj, 'ch') and hasattr(obj, 'parent'),\\\n        'object must have a ch attribute and a parent attribute'\n        if obj is None:\n            return self\n        if self.get_cmd is None:\n            raise AttributeError(\"unreadable attribute\")\n        if self.dtype == 'float':\n            getter = obj.parent.float_query\n        elif self.dtype == 'int':\n            getter = obj.parent.int_query\n        else:\n            getter = obj.parent.query\n        message = self.get_cmd\n        if '{0' in message:\n            message = message.format(obj.ch)\n        elif '%' in message:\n            message = message % obj.ch\n        value = getter(message)\n        if self.dtype == 'bool':\n            value = bool(value)\n        return value\n\n    def __set__(self, obj, value):\n        assert hasattr(obj, 'ch') and hasattr(obj, 'parent'),\\\n        'object must have a ch attribute and a parent attribute'\n        if self.set_cmd is None:\n            raise AttributeError(\"can't set attribute\")\n        if self.validate is not None:\n            if value not in self.validate:\n                raise ValueError('invalid value supplied - value must be one of {}'.format(self.validate))\n        if self.valrange is not None:\n            if value < min(self.valrange) or value > max(self.valrange):\n                raise ValueError('invalid value supplied - value must be in the range {}-{}'.format(*self.valrange))\n        message = self.set_cmd\n        if '{0' in message:\n            message = message.format(obj.ch, value)\n        elif '%' in message:\n            message = message % (obj.ch, value)\n        obj.parent.write(message)",
  "class EchoInstrument(MessageBusInstrument):\n    \"\"\"Trivial test instrument, it simply echoes back what we write.\"\"\"\n    def __init__(self):\n        super(EchoInstrument, self).__init__()\n        self._last_write = \"\"\n\n    def _write(self, msg, *args, **kwargs):\n        self._last_write = msg\n\n    def readline(self, timeout=None):\n        return self._last_write",
  "def wrap_with_echo_to_console(obj):\n    \"\"\"Modify an object on-the-fly so all its write and readline calls are echoed to the console\"\"\"\n    import functools\n\n    obj._debug_echo = True\n    obj._original_write = obj.write\n    obj._original_readline = obj.readline\n\n    def write(self, q, *args, **kwargs):\n        print(\"Sent: \"+str(q))\n        return self._original_write(q, *args, **kwargs)\n    obj.write = functools.partial(write, obj)\n\n    def readline(self, *args, **kwargs):\n        ret = self._original_readline(*args, **kwargs)\n        print(\"Recv: \"+str(ret))\n        return ret\n    obj.readline = functools.partial(readline, obj)",
  "def communications_lock(self):\n        \"\"\"A lock object used to protect access to the communications bus\"\"\"\n        # This requires initialisation but our init method won't be called - so\n        # the property initialises it on first use.\n        if self._communications_lock is None:\n            self._communications_lock = threading.RLock()\n        return self._communications_lock",
  "def write(self, write_string, timeout=None, *args, **kwargs):\n        \"\"\"Write a string to the unerlying communications port\"\"\"\n        with self.communications_lock:\n            self._write(write_string, *args, **kwargs)\n        self._check_echo(write_string, timeout)",
  "def _write(self, query_string, *args, **kwargs):\n        raise NotImplementedError(\"Subclasses of MessageBusInstrument must override the _write method!\")",
  "def flush_input_buffer(self):\n        \"\"\"Make sure there's nothing waiting to be read.\n\n        This function should be overridden to make sure nothing's lurking in\n        the input buffer that could confuse a query.\n        \"\"\"\n        with self.communications_lock:\n            pass",
  "def readline(self, timeout=None):\n        \"\"\"Read one line from the underlying bus.  Must be overriden.\"\"\"\n        with self.communications_lock:\n            raise NotImplementedError(\"Subclasses of MessageBusInstrument must override the readline method!\")",
  "def read_multiline(self, termination_line=None, timeout=None):\n        \"\"\"Read one line from the underlying bus.  Must be overriden.\n\n        This should not need to be reimplemented unless there's a more efficient\n        way of reading multiple lines than multiple calls to readline().\"\"\"\n        with self.communications_lock:\n            if termination_line is None:\n                termination_line = self.termination_line\n\n            try:\n                assert isinstance(termination_line, basestring), \"If you perform a multiline query, you must specify a termination line either through the termination_line keyword argument or the termination_line property of the NPSerialInstrument.\"\n            except NameError:\n                assert isinstance(termination_line, str), \"If you perform a multiline query, you must specify a termination line either through the termination_line keyword argument or the termination_line property of the NPSerialInstrument.\"\n\n            response = \"\"\n            last_line = \"dummy\"\n            while termination_line not in last_line and len(last_line) > 0:  # read until we get the termination line.\n                last_line = self.readline(timeout)\n                response += last_line\n            return response",
  "def query(self, query_string, multiline=False, termination_line=None, timeout=None):\n        \"\"\"\n        Write a string to the stage controller and return its response.\n\n        It will block until a response is received.  The multiline and termination_line commands\n        will keep reading until a termination phrase is reached.\n        \"\"\"\n        with self.communications_lock:\n            self.flush_input_buffer()\n            self.write(query_string, timeout)\n\n            if termination_line is not None:\n                multiline = True\n            if multiline:\n                return self.read_multiline(termination_line)\n            else:\n                return self.readline(timeout).strip()",
  "def _check_echo(self, echo_string, timeout=None):\n        if self.ignore_echo:\n            echo_line = self.readline(timeout).strip()\n            if echo_line != echo_string:\n                self._logger.warn('Command did not echo: %s' % echo_string)",
  "def parsed_query_old(self, query_string, response_string=r\"(\\d+)\", re_flags=0, parse_function=int, **kwargs):\n        \"\"\"\n        Perform a query, then parse the result.\n\n        By default it looks for an integer and returns one, otherwise it will\n        match a custom regex string and return the subexpressions, parsed through\n        the supplied functions.\n\n        TODO: make this accept friendlier sscanf style arguments, and produce parse functions automatically\n        \"\"\"\n        # NB no need for the lock here - `query` is already an atomic operation.\n        reply = self.query(query_string, **kwargs)\n        res = re.search(response_string, reply, flags=re_flags)\n        if res is None:\n            raise ValueError(\"Stage response to '%s' ('%s') wasn't matched by /%s/\" % (query_string, reply, response_string))\n        try:\n            if len(res.groups()) == 1:\n                return parse_function(res.groups()[0])\n            else:\n                return list(map(parse_function,res.groups()))\n        except ValueError:\n            raise ValueError(\"Stage response to %s ('%s') couldn't be parsed by the supplied function\" % (query_string, reply))",
  "def parsed_query(self, query_string, response_string=r\"%d\", re_flags=0, parse_function=None, **kwargs):\n        \"\"\"\n        Perform a query, returning a parsed form of the response.\n\n        First query the instrument with the given query string, then compare\n        the response against a template.  The template may contain text and\n        placeholders (e.g. %i and %f for integer and floating point values\n        respectively).  Regular expressions are also allowed - each group is\n        considered as one item to be parsed.  However, currently it's not\n        supported to use both % placeholders and regular expressions at the\n        same time.\n\n        If placeholders %i, %f, etc. are used, the returned values are\n        automatically converted to integer or floating point, otherwise you\n        must specify a parsing function (applied to all groups) or a list of\n        parsing functions (applied to each group in turn).\n        \"\"\"\n\n        response_regex = response_string\n        noop = lambda x: x  # placeholder null parse function\n        placeholders = [  # tuples of (regex matching placeholder, regex to replace it with, parse function)\n            (r\"%c\", r\".\", noop),\n            (r\"%(\\\\d+)c\", r\".{\\1}\", noop),  # TODO support %cn where n is a number of chars\n            (r\"%d\", r\"[-+]?\\\\d+\", int),\n            (r\"%[eEfg]\", r\"[-+]?(?:\\\\d+(?:\\.\\\\d*)?|\\.\\\\d+)(?:[eE][-+]?\\\\d+)?\", float),\n            # (r\"%(\\\\d+)c\",r\".{\\\\1}\", noop), #TODO support %cn where n is a number of chars\n            # (r\"%d\",r\"[-+]?\\\\d+\", int),\n            # (r\"%[eEfg]\",r\"[-+]?(?:\\\\d+(?:\\\\.\\\\d*)?|\\\\.\\\\d+)(?:[eE][-+]?\\\\d+)?\", float),\n            (r\"%i\", r\"[-+]?(?:0[xX][\\\\dA-Fa-f]+|0[0-7]*|\\\\d+)\", lambda x: int(x, 0)),  # 0=autodetect base\n            (r\"%o\", r\"[-+]?[0-7]+\", lambda x: int(x, 8)),  # 8 means octal\n            (r\"%s\", r\"\\\\S+\", noop),\n            (r\"%u\", r\"\\\\d+\", int),\n            (r\"%[xX]\", r\"[-+]?(?:0[xX])?[\\\\dA-Fa-f]+\", lambda x: int(x, 16)),  # 16 forces hexadecimal\n        ]\n        matched_placeholders = []\n        for placeholder, regex, parse_fun in placeholders:\n            response_regex = re.sub(placeholder, '(' + regex + ')', response_regex)  # substitute regex for placeholder\n            matched_placeholders.extend([(parse_fun, m.start()) for m in re.finditer(placeholder, response_string)])  # save the positions of the placeholders\n        if parse_function is None:\n            parse_function = [f for f, s in sorted(matched_placeholders, key=lambda m: m[1])]  # order parse functions by their occurrence in the original string\n        if not hasattr(parse_function, '__iter__'):\n            parse_function = [parse_function]  # make sure it's a list.\n\n        reply = self.query(query_string, **kwargs)  # do the query\n        res = re.search(response_regex, reply, flags=re_flags)\n        if res is None:\n            raise ValueError(\"Stage response to '%s' ('%s') wasn't matched by /%s/ (generated regex /%s/\" % (query_string, reply, response_string, response_regex))\n        try:\n            parsed_result = [f(g) for f, g in zip(parse_function, res.groups())]  # try to apply each parse function to its argument\n            if len(parsed_result) == 1:\n                return parsed_result[0]\n            else:\n                return parsed_result\n        except ValueError:\n            print(\"Parsing Error\")\n            print(\"Matched Groups:\", res.groups())\n            print(\"Parsing Functions:\", parse_function)\n            raise ValueError(\"Stage response to %s ('%s') couldn't be parsed by the supplied function\" % (query_string, reply))",
  "def int_query(self, query_string, **kwargs):\n        \"\"\"Perform a query and return the result(s) as integer(s) (see parsedQuery)\"\"\"\n        return self.parsed_query(query_string, \"%d\", **kwargs)",
  "def float_query(self, query_string, **kwargs):\n        \"\"\"Perform a query and return the result(s) as float(s) (see parsedQuery)\"\"\"\n        return self.parsed_query(query_string, \"%f\", **kwargs)",
  "def __init__(self, get_cmd=None, set_cmd=None, validate=None, valrange=None,\n                 fdel=None, doc=None, dtype='float'):\n        self.dtype = dtype\n        self.get_cmd = get_cmd\n        self.set_cmd = set_cmd\n        self.validate = validate\n        self.valrange = valrange\n        self.fdel = fdel\n        self.__doc__ = doc",
  "def __get__(self, obj, objtype=None):\n        #print 'get', obj, objtype\n        if obj is None:\n            return self\n        if self.get_cmd is None:\n            raise AttributeError(\"unreadable attribute\")\n        if self.dtype == 'float':\n            getter = obj.float_query\n        elif self.dtype == 'int':\n            getter = obj.int_query\n        else:\n            getter = obj.query\n        value = getter(self.get_cmd)\n        if self.dtype == 'bool':\n            value = bool(value)\n        return value",
  "def __set__(self, obj, value):\n        #print 'set', obj, value\n        if self.set_cmd is None:\n            raise AttributeError(\"can't set attribute\")\n        if self.validate is not None:\n            if value not in self.validate:\n                raise ValueError('invalid value supplied - value must be one of {}'.format(self.validate))\n        if self.valrange is not None:\n            if value < min(self.valrange) or value > max(self.valrange):\n                raise ValueError('invalid value supplied - value must be in the range {}-{}'.format(*self.valrange))\n        message = self.set_cmd\n        if '{0' in message:\n            message = message.format(value)\n        elif '%' in message:\n            message = message % value\n        obj.write(message)",
  "def __delete__(self, obj):\n        if self.fdel is None:\n            raise AttributeError(\"can't delete attribute\")\n        self.fdel(obj)",
  "def __init__(self, get_cmd=None, set_cmd=None, validate=None, valrange=None,\n                 fdel=None, doc=None, dtype='float'):\n        super(queried_channel_property, self).__init__(get_cmd, set_cmd, validate, valrange,\n                                                       fdel, doc, dtype)",
  "def __get__(self, obj, objtype=None):\n        assert hasattr(obj, 'ch') and hasattr(obj, 'parent'),\\\n        'object must have a ch attribute and a parent attribute'\n        if obj is None:\n            return self\n        if self.get_cmd is None:\n            raise AttributeError(\"unreadable attribute\")\n        if self.dtype == 'float':\n            getter = obj.parent.float_query\n        elif self.dtype == 'int':\n            getter = obj.parent.int_query\n        else:\n            getter = obj.parent.query\n        message = self.get_cmd\n        if '{0' in message:\n            message = message.format(obj.ch)\n        elif '%' in message:\n            message = message % obj.ch\n        value = getter(message)\n        if self.dtype == 'bool':\n            value = bool(value)\n        return value",
  "def __set__(self, obj, value):\n        assert hasattr(obj, 'ch') and hasattr(obj, 'parent'),\\\n        'object must have a ch attribute and a parent attribute'\n        if self.set_cmd is None:\n            raise AttributeError(\"can't set attribute\")\n        if self.validate is not None:\n            if value not in self.validate:\n                raise ValueError('invalid value supplied - value must be one of {}'.format(self.validate))\n        if self.valrange is not None:\n            if value < min(self.valrange) or value > max(self.valrange):\n                raise ValueError('invalid value supplied - value must be in the range {}-{}'.format(*self.valrange))\n        message = self.set_cmd\n        if '{0' in message:\n            message = message.format(obj.ch, value)\n        elif '%' in message:\n            message = message % (obj.ch, value)\n        obj.parent.write(message)",
  "def __init__(self):\n        super(EchoInstrument, self).__init__()\n        self._last_write = \"\"",
  "def _write(self, msg, *args, **kwargs):\n        self._last_write = msg",
  "def readline(self, timeout=None):\n        return self._last_write",
  "def write(self, q, *args, **kwargs):\n        print(\"Sent: \"+str(q))\n        return self._original_write(q, *args, **kwargs)",
  "def readline(self, *args, **kwargs):\n        ret = self._original_readline(*args, **kwargs)\n        print(\"Recv: \"+str(ret))\n        return ret",
  "class DummyInstrument(EchoInstrument):\n        x = queried_property('gx', 'sx {0}', dtype='str')",
  "class VirtualInstrument_listener(object):\n\n    def __init__(self, memory_size=65536, memory_identifier='VirtualInstMemory'):\n        \"\"\"\n        A class for creating the listening element of the \"virtual\" instrument, when subclassed this\n        essentially creates a memory map and waits for commands. Upon receiving a command the instrument\n        will execute the named command and pass back the results via a second map\n        Args:\n            memory_size(int):       The size of the in command memory map -\n                                    100 times this value is used for the out\n\n            memory_identifier(str): The memory str identifier - this is usually set as the \"VirtualInstMemory_'classname'\"\n        \"\"\"\n        self.memory_map_in = mmap.mmap(0, memory_size, memory_identifier + 'In')\n        self.memory_map_out = mmap.mmap(0, memory_size * 100, memory_identifier + 'Out')\n        self.end_line = 'THE END\\n'\n        self.out_size = memory_size * 100\n        self.memory_identifier = memory_identifier\n        np.set_printoptions(\n            threshold=np.inf)  # Set the prints options so that the arrays are printed as strings with no shortening\n\n    def begin_listening(self):\n        \"\"\" Start the listening loop, this is a never ending loop which looks for \n        commands in the 'In' memory map. The command is run via the 'run_command_str' function.\n        The resulting data is then passed back through the out memory map.\n        \"\"\"\n        running = True\n        while running:\n            time.sleep(0.01)\n            self.memory_map_in.seek(0)\n            command_str = self.memory_map_in.readline()\n            self.memory_map_in.seek(0)\n            self.memory_map_in.write(self.end_line)\n            command_str = re.sub('\\n', '', command_str)\n            if command_str != self.end_line[:-1]:\n                data = self.run_command_str(command_str)\n                if data is not None:\n                    self.memory_map_out.seek(0)\n                    if not hasattr(data, '__iter__'):\n                        data = (data,)\n                    self.memory_map_out.write('data = [];')\n                    for data_i in data:\n                        try:\n                            data_i_str = np.array_str(data_i)  # attempt to convert array's to a str\n                            try:\n                                self.memory_map_out.write('data.append(np.array(' + data_i_str + '));')\n                            except ValueError:\n                                print('Memory map size error, Increase the output map size')\n\n                        except AttributeError:\n                            # If the data is not a numpy array it will be passed at its str representation...This should work for most dtypes?\n                            self.memory_map_out.write('data.append(' + str(data_i) + ');')\n                    self.memory_map_out.write('\\n' + self.end_line)\n\n    def run_command_str(self, input_str):\n        \"\"\"\n        Parse and run the passed in command from the input string which can\n        also contain input arguments\n        \"\"\"\n        command = re.sub(r'\\((.*?)\\)', '', input_str)\n        if hasattr(self, command):\n            #         print 'command' , command\n            function = getattr(self, command)\n            input_list = re.findall(r'\\((.*?)\\)', input_str)[0].split(',')\n            if len(input_list) > 1:\n                input_dict = {}\n                for input_param in input_list:\n                    input_param_split = input_param.split('=')\n                    if len(input_param_split) == 2:\n                        input_dict[input_param.split('=')[0]] = input_param.split('=')[1]\n                    else:\n                        print('Arguments must be named for use through VirtualInstrument')\n                #           print 'input_dict', input_dict\n                return function(**input_dict)\n            else:\n                #           print'got to run'\n                return function()\n            #            return_vals = exec('self.'+input_str)\n\n        else:\n            print(command, 'does not exist')",
  "class VirtualInstrument_speaker(MessageBusInstrument):\n\n    def __init__(self, memory_size=65536, memory_identifier='VirtualInstMemory'):\n        \"\"\"\n        When subclassed creates the speaker half of the virtual instrument.\n        It does this by creating read and write functions pass and parse commands/data to\n        and from the listener instrument\n        Args:\n            memory_size(int):       The size of the in command memory map -\n                                    100 times this value is used for the out\n\n            memory_identifier(str): The memory str identifier - this is usually set as the \"VirtualInstMemory_'classname'\"\n        \"\"\"\n        self.end_line = 'THE END\\n'\n        self.memory_map_in = mmap.mmap(0, memory_size, memory_identifier + 'In')\n        self.memory_map_in.write(self.end_line)\n        self.memory_map_out = mmap.mmap(0, memory_size * 100, memory_identifier + 'Out')\n        self.memory_map_out.write(self.end_line)\n\n        self.out_size = memory_size * 100\n        self.memory_identifier = memory_identifier\n\n    def read(self):\n        \"\"\"Function for reading from the memory map and parsing any data.\n        \"\"\"\n        self.memory_map_out.seek(0)\n        reading = True\n        lines = ''\n        while reading:\n            new_line = self.memory_map_out.readline()\n            #            print new_line\n            if new_line == self.end_line:\n                reading = False\n            else:\n                lines += new_line\n            if new_line == '':\n                return None\n        data = re.sub('\\n', '', lines)\n        data = re.sub(r'\\]  *\\[', '],[', data)\n        data = re.sub(r'([0-9])  *([0-9])', r'\\1,\\2', data)\n        data = re.sub(r'([0-9])  *([0-9])', r'\\1,\\2', data)\n        data = re.sub(' *', '', data)\n        self.memory_map_out.seek(0)\n        self.memory_map_out.write(self.end_line + '\\n')\n        try:\n            exec(data)\n            return data\n        #        return data\n        except:\n            return None\n\n    #     return lines\n    def _write(self, command):\n        \"\"\"\n        Write the command name and arguments to the In memory map\n        \"\"\"\n        self.memory_map_in.seek(0)\n        self.memory_map_in.write(command + '\\n')\n        self.memory_map_in.write(self.end_line)",
  "def function_builder(command_name):\n    \"\"\"A function for generating the write functions for intergrating classes with\n    the speaker instrument class.\n    \"\"\"\n\n    def wrapped_function(*args, **kwargs):\n        input_str = ''\n        obj = args[0]\n        if len(args) > 1:\n            for input_value in args[1:]:\n                input_str += str(input_value) + ','\n\n        for input_name, input_value in list(kwargs.items()):\n            input_str = input_str + input_name + '=' + input_value + ','\n        input_str = input_str[:-1]\n        obj.memory_map_in.seek(0)\n        obj.memory_map_in.write(command_name + '(' + input_str + ')\\n')\n        print(command_name + '(' + input_str + ')\\n')\n        time.sleep(1)\n        return obj.read()\n\n    return wrapped_function",
  "def create_speaker_class(original_class):\n    \"\"\"\n    A function that creates a speaker class by subclassing the original class\n    and replacing any function calls with write commands that pass the functions to the listener\n    \"\"\"\n\n    class original_class_Stripped(original_class):  # copies the class\n        def __init__(self):\n            original_class.__init__(self)\n\n    for command_name in list(original_class.__dict__.keys()):  # replaces any method\n        command = getattr(original_class_Stripped, command_name)\n        if inspect.ismethod(command):\n            setattr(original_class_Stripped, command_name, function_builder(command_name))\n\n    class virtual_speaker_class(original_class_Stripped,\n                                VirtualInstrument_speaker):  # creates the new class by sublcassing the stripped class and the speaker class\n        def __init__(self, memory_size=65536, memory_identifier='VirtualInstMemory_' + original_class.__name__):\n            VirtualInstrument_speaker.__init__(self, memory_size, memory_identifier)\n\n    return virtual_speaker_class()",
  "def create_listener_class(original_class):\n    \"\"\"A function that creates a subclass of the orignal class and the listener class\n    Args:\n        original_class(class):  The instrument class the listener will be a subclass of \n    \"\"\"\n\n    class virtual_listener(original_class, VirtualInstrument_listener):\n        def __init__(self, memory_size=65536, memory_identifier='VirtualInstMemory_' + original_class.__name__):\n            original_class.__init__(self)\n            VirtualInstrument_listener.__init__(self, memory_size, memory_identifier)\n\n    return virtual_listener",
  "def create_listener_by_name(module_name, class_name):\n    \"\"\"A convenceince function for creating the listener class via the name of the module and class\n    \"\"\"\n    exec ('from ' + (module_name + \" import \" + class_name) + ' as ' + class_name)\n    exec ('virtual_listener=create_listener_class(' + class_name + ')')\n    return virtual_listener",
  "def setup_communication(original_class):\n    \"\"\"A function that creates both the speaker and the listener class, the speaker is created like a normal class\n    while the listener is created using subprocess to call a 32-bit python console.\n    Args:\n        original_class(class):  The instrument you wish to create in the 32bit console\n    Returns:\n        speaker_class(class): The instrument used within the 64 bit consle to control the 32 bit instrument\n        listner_console(subprocess.Popen): The subprocess console that the listner instrument exists within\n    \"\"\"\n    speaker_class = create_speaker_class(original_class)\n    import subprocess\n    command_str = \"exec(\\'import qtpy;from nplab.instrument.virtual_instrument import inialise_listenser;inialise_listenser(\" + r\"\\\"\" + original_class.__module__ + r\"\\\",\\\"\" + original_class.__name__ + r\"\\\"\" + \")')\"\n    listner_console = subprocess.Popen([\"python32\",\n                                        \"-c\",\n                                        command_str])\n    return speaker_class, listner_console",
  "def inialise_listenser(module_name, class_name):\n    \"\"\"The functions that is called within the 32bit console to create the listener and begin listening.\n    \"\"\"\n    #   print 'start'\n    listener_class = create_listener_by_name(module_name, class_name)\n    listener = listener_class()\n    listener.begin_listening()",
  "def __init__(self, memory_size=65536, memory_identifier='VirtualInstMemory'):\n        \"\"\"\n        A class for creating the listening element of the \"virtual\" instrument, when subclassed this\n        essentially creates a memory map and waits for commands. Upon receiving a command the instrument\n        will execute the named command and pass back the results via a second map\n        Args:\n            memory_size(int):       The size of the in command memory map -\n                                    100 times this value is used for the out\n\n            memory_identifier(str): The memory str identifier - this is usually set as the \"VirtualInstMemory_'classname'\"\n        \"\"\"\n        self.memory_map_in = mmap.mmap(0, memory_size, memory_identifier + 'In')\n        self.memory_map_out = mmap.mmap(0, memory_size * 100, memory_identifier + 'Out')\n        self.end_line = 'THE END\\n'\n        self.out_size = memory_size * 100\n        self.memory_identifier = memory_identifier\n        np.set_printoptions(\n            threshold=np.inf)",
  "def begin_listening(self):\n        \"\"\" Start the listening loop, this is a never ending loop which looks for \n        commands in the 'In' memory map. The command is run via the 'run_command_str' function.\n        The resulting data is then passed back through the out memory map.\n        \"\"\"\n        running = True\n        while running:\n            time.sleep(0.01)\n            self.memory_map_in.seek(0)\n            command_str = self.memory_map_in.readline()\n            self.memory_map_in.seek(0)\n            self.memory_map_in.write(self.end_line)\n            command_str = re.sub('\\n', '', command_str)\n            if command_str != self.end_line[:-1]:\n                data = self.run_command_str(command_str)\n                if data is not None:\n                    self.memory_map_out.seek(0)\n                    if not hasattr(data, '__iter__'):\n                        data = (data,)\n                    self.memory_map_out.write('data = [];')\n                    for data_i in data:\n                        try:\n                            data_i_str = np.array_str(data_i)  # attempt to convert array's to a str\n                            try:\n                                self.memory_map_out.write('data.append(np.array(' + data_i_str + '));')\n                            except ValueError:\n                                print('Memory map size error, Increase the output map size')\n\n                        except AttributeError:\n                            # If the data is not a numpy array it will be passed at its str representation...This should work for most dtypes?\n                            self.memory_map_out.write('data.append(' + str(data_i) + ');')\n                    self.memory_map_out.write('\\n' + self.end_line)",
  "def run_command_str(self, input_str):\n        \"\"\"\n        Parse and run the passed in command from the input string which can\n        also contain input arguments\n        \"\"\"\n        command = re.sub(r'\\((.*?)\\)', '', input_str)\n        if hasattr(self, command):\n            #         print 'command' , command\n            function = getattr(self, command)\n            input_list = re.findall(r'\\((.*?)\\)', input_str)[0].split(',')\n            if len(input_list) > 1:\n                input_dict = {}\n                for input_param in input_list:\n                    input_param_split = input_param.split('=')\n                    if len(input_param_split) == 2:\n                        input_dict[input_param.split('=')[0]] = input_param.split('=')[1]\n                    else:\n                        print('Arguments must be named for use through VirtualInstrument')\n                #           print 'input_dict', input_dict\n                return function(**input_dict)\n            else:\n                #           print'got to run'\n                return function()\n            #            return_vals = exec('self.'+input_str)\n\n        else:\n            print(command, 'does not exist')",
  "def __init__(self, memory_size=65536, memory_identifier='VirtualInstMemory'):\n        \"\"\"\n        When subclassed creates the speaker half of the virtual instrument.\n        It does this by creating read and write functions pass and parse commands/data to\n        and from the listener instrument\n        Args:\n            memory_size(int):       The size of the in command memory map -\n                                    100 times this value is used for the out\n\n            memory_identifier(str): The memory str identifier - this is usually set as the \"VirtualInstMemory_'classname'\"\n        \"\"\"\n        self.end_line = 'THE END\\n'\n        self.memory_map_in = mmap.mmap(0, memory_size, memory_identifier + 'In')\n        self.memory_map_in.write(self.end_line)\n        self.memory_map_out = mmap.mmap(0, memory_size * 100, memory_identifier + 'Out')\n        self.memory_map_out.write(self.end_line)\n\n        self.out_size = memory_size * 100\n        self.memory_identifier = memory_identifier",
  "def read(self):\n        \"\"\"Function for reading from the memory map and parsing any data.\n        \"\"\"\n        self.memory_map_out.seek(0)\n        reading = True\n        lines = ''\n        while reading:\n            new_line = self.memory_map_out.readline()\n            #            print new_line\n            if new_line == self.end_line:\n                reading = False\n            else:\n                lines += new_line\n            if new_line == '':\n                return None\n        data = re.sub('\\n', '', lines)\n        data = re.sub(r'\\]  *\\[', '],[', data)\n        data = re.sub(r'([0-9])  *([0-9])', r'\\1,\\2', data)\n        data = re.sub(r'([0-9])  *([0-9])', r'\\1,\\2', data)\n        data = re.sub(' *', '', data)\n        self.memory_map_out.seek(0)\n        self.memory_map_out.write(self.end_line + '\\n')\n        try:\n            exec(data)\n            return data\n        #        return data\n        except:\n            return None",
  "def _write(self, command):\n        \"\"\"\n        Write the command name and arguments to the In memory map\n        \"\"\"\n        self.memory_map_in.seek(0)\n        self.memory_map_in.write(command + '\\n')\n        self.memory_map_in.write(self.end_line)",
  "def wrapped_function(*args, **kwargs):\n        input_str = ''\n        obj = args[0]\n        if len(args) > 1:\n            for input_value in args[1:]:\n                input_str += str(input_value) + ','\n\n        for input_name, input_value in list(kwargs.items()):\n            input_str = input_str + input_name + '=' + input_value + ','\n        input_str = input_str[:-1]\n        obj.memory_map_in.seek(0)\n        obj.memory_map_in.write(command_name + '(' + input_str + ')\\n')\n        print(command_name + '(' + input_str + ')\\n')\n        time.sleep(1)\n        return obj.read()",
  "class original_class_Stripped(original_class):  # copies the class\n        def __init__(self):\n            original_class.__init__(self)",
  "class virtual_speaker_class(original_class_Stripped,\n                                VirtualInstrument_speaker):  # creates the new class by sublcassing the stripped class and the speaker class\n        def __init__(self, memory_size=65536, memory_identifier='VirtualInstMemory_' + original_class.__name__):\n            VirtualInstrument_speaker.__init__(self, memory_size, memory_identifier)",
  "class virtual_listener(original_class, VirtualInstrument_listener):\n        def __init__(self, memory_size=65536, memory_identifier='VirtualInstMemory_' + original_class.__name__):\n            original_class.__init__(self)\n            VirtualInstrument_listener.__init__(self, memory_size, memory_identifier)",
  "def __init__(self):\n            original_class.__init__(self)",
  "def __init__(self, memory_size=65536, memory_identifier='VirtualInstMemory_' + original_class.__name__):\n            VirtualInstrument_speaker.__init__(self, memory_size, memory_identifier)",
  "def __init__(self, memory_size=65536, memory_identifier='VirtualInstMemory_' + original_class.__name__):\n            original_class.__init__(self)\n            VirtualInstrument_listener.__init__(self, memory_size, memory_identifier)",
  "class Instrument(ShowGUIMixin):\n    \"\"\"Base class for all instrument-control classes.\n\n    This class takes care of management of instruments, saving data, etc.\n    \"\"\"\n    __instances = None\n    metadata_property_names = () #\"Tuple of names of properties that should be automatically saved as HDF5 metadata\n\n    def __init__(self):\n        \"\"\"Create an instrument object.\"\"\"\n        super(Instrument, self).__init__()\n        Instrument.instances_set().add(self) #keep track of instances (should this be in __new__?)\n        self._logger = logging.getLogger('Instrument.' + str(type(self)).split('.')[-1].split('\\'')[0])\n\n    @classmethod\n    def instances_set(cls):\n        if Instrument.__instances is None:\n            Instrument.__instances = WeakSet()\n        return Instrument.__instances\n\n    @classmethod\n    def get_instances(cls):\n        \"\"\"Return a list of all available instances of this class.\"\"\"\n        return [i for i in Instrument.instances_set() if isinstance(i, cls)]\n\n    @classmethod\n    def get_instance(cls, create=True, exceptions=True, *args, **kwargs):\n        \"\"\"Return an instance of this class, if one exists.\n\n        Usually returns the first available instance.\n        \"\"\"\n        instances = cls.get_instances()\n        if len(instances)>0:\n            return instances[0]\n        else:\n            if create:\n                return cls(*args, **kwargs)\n            else:\n                if exceptions:\n                    raise IndexError(\"There is no available instance!\")\n                else:\n                    return None\n\n    @classmethod\n    def get_root_data_folder(cls):\n        \"\"\"Return a sensibly-named data folder in the default file.\"\"\"\n        if nplab.datafile._use_current_group == True:\n            if nplab.datafile._current_group != None:\n                return nplab.datafile._current_group\n        f = nplab.current_datafile()\n        return f.require_group(cls.__name__)\n\n    @classmethod\n    def create_data_group(cls, name, *args, **kwargs):\n        \"\"\"Return a group to store a reading.\n\n        :param name: should be a noun describing what the reading is (image,\n        spectrum, etc.)\n        :param attrs: may be a dictionary, saved as HDF5 metadata\n        \"\"\"\n        if \"%d\" not in name:\n            name = name + '_%d'\n        df = cls.get_root_data_folder()\n        return df.create_group(name, auto_increment=True, *args, **kwargs)\n\n    @classmethod\n    def create_dataset(cls, name, flush=True, *args, **kwargs):\n        \"\"\"Store a reading in a dataset (or make a new dataset to fill later).\n\n        :param name: should be a noun describing what the reading is (image,\n        spectrum, etc.)\n\n        Other arguments are passed to `nplab.datafile.Group.create_dataset`.\n        \"\"\"\n        if \"%d\" not in name: # is this really necessary?\n            name = name + '_%d'\n        df = cls.get_root_data_folder()\n        dset = df.create_dataset(name, *args, **kwargs)\n        if 'data' in kwargs and flush:\n            dset.file.flush() #make sure it's in the file if we wrote data\n        return dset\n\n    def log(self, message,level = 'info'):\n        \"\"\"Save a log message to the current datafile.\n\n        This is the preferred way to output debug/informational messages.  They\n        will be saved in the current HDF5 file and optionally shown in the\n        nplab console.\n        \"\"\"\n        nplab.utils.log.log(message, from_object=self, level=level)\n\n    def get_metadata(self, \n                     property_names=[], \n                     include_default_names=True,\n                     exclude=None\n                     ):\n        \"\"\"A dictionary of settings, properties, etc. to save along with data.\n\n        This returns the value of each property specified in the arguments or\n        in `self.metadata_property_names`.\n        \n        Arguments:\n        property_names : list of strings, optional\n            A list specifying the names of properties (of this object) to be\n            retrieved and returned in the dictionary.\n        include_default_names : boolean, optional (default True)\n            If True (the default), include the default metadata along with the\n            specified names.  This means that get_metadata can be used with no\n            arguments to retrieve the default metadata.\n        exclude : list of strings, optional\n            A list of properties to exclude (primarily useful when you want to\n            remove some of the default entries).  Nothing is excluded by \n            default.\n        \"\"\"\n        # Convert everything to lists to:\n        # * ensure we don't modify the arguments (it copies list arguments)\n        # * make it all mutable so we can remove items\n        # * prevent errors when adding lists and tuples\n        keys = list(property_names)\n        if include_default_names:\n            keys += list(self.metadata_property_names)\n        if exclude is not None:\n            for p in exclude:\n                try:\n                    keys.remove(p)\n                except ValueError:\n                    pass # Don't worry if we exclude items that are not there!\n        return {name: getattr(self,name) for name in keys}\n\n    metadata = property(get_metadata)\n\n    def bundle_metadata(self, data, enable=True, **kwargs):\n        \"\"\"Add metadata to a dataset, returning an ArrayWithAttrs.\n        \n        Arguments:\n        data : np.ndarray\n            The data with which to bundle the metadata\n        enable : boolean (optional, default to True)\n            Set this argument to False to do nothing, i.e. just return data.\n        **kwargs\n            Addditional arguments are passed to get_metadata (for example, you \n            can specify a list of `property_names` to add to the default\n            metadata, or a list of names to exclude.\n        \"\"\"\n        if enable:\n            return ArrayWithAttrs(data, attrs=self.get_metadata(**kwargs))\n        else:\n            return data\n\n    def open_config_file(self):\n        \"\"\"Open the config file for the current spectrometer and return it, creating if it's not there\"\"\"\n        if not hasattr(self, '_config_file'):\n            try:\n                f = inspect.getfile(self.__class__) # fails in IPython\n            except (TypeError, ValueError):\n                f = inspect.getfile(self.__class__.__init__) # assumes the inst has an init method\n            d = os.path.dirname(f)\n            self._config_file = nplab.datafile.DataFile(os.path.join(d, self.__class__.__name__+'_config.h5'), mode='a')\n            self._config_file.attrs['date'] = datetime.datetime.now().strftime(\"%H:%M %d/%m/%y\")\n        return self._config_file\n\n    config_file = property(open_config_file)\n    \n    def update_config(self, name, data, attrs= None):\n        \"\"\"Update the configuration file for this spectrometer.\n        \n        A file is created in the nplab directory that holds configuration\n        data for the spectrometer, including reference/background.  This\n        function allows values to be stored in that file.\"\"\"\n        f = self.config_file\n        if name in f.keys():\n            try: del f[name]\n            except: \n                f[name][...] = data\n                f.flush()    \n        else:\n            f.create_dataset(name, data=data, attrs=attrs)\n\n    @contextmanager\n    def temporarily_set(self, **kwargs):\n        \"\"\"Utility function for temporarily setting instrument parameters\n\n        :Example:\n        >>> with camera.temporarily_set(exposure=1, backgrounded=False):\n        >>>     image = camera.get_image()\n\n        :param kwargs: dict\n        :return:\n        \"\"\"\n        try:\n            original_settings = dict()\n            for key, value in kwargs.items():\n                original_settings[key] = getattr(self, key)\n                setattr(self, key, value)\n            yield original_settings\n        finally:\n            for key, value in original_settings.items():\n                setattr(self, key, value)",
  "def __init__(self):\n        \"\"\"Create an instrument object.\"\"\"\n        super(Instrument, self).__init__()\n        Instrument.instances_set().add(self) #keep track of instances (should this be in __new__?)\n        self._logger = logging.getLogger('Instrument.' + str(type(self)).split('.')[-1].split('\\'')[0])",
  "def instances_set(cls):\n        if Instrument.__instances is None:\n            Instrument.__instances = WeakSet()\n        return Instrument.__instances",
  "def get_instances(cls):\n        \"\"\"Return a list of all available instances of this class.\"\"\"\n        return [i for i in Instrument.instances_set() if isinstance(i, cls)]",
  "def get_instance(cls, create=True, exceptions=True, *args, **kwargs):\n        \"\"\"Return an instance of this class, if one exists.\n\n        Usually returns the first available instance.\n        \"\"\"\n        instances = cls.get_instances()\n        if len(instances)>0:\n            return instances[0]\n        else:\n            if create:\n                return cls(*args, **kwargs)\n            else:\n                if exceptions:\n                    raise IndexError(\"There is no available instance!\")\n                else:\n                    return None",
  "def get_root_data_folder(cls):\n        \"\"\"Return a sensibly-named data folder in the default file.\"\"\"\n        if nplab.datafile._use_current_group == True:\n            if nplab.datafile._current_group != None:\n                return nplab.datafile._current_group\n        f = nplab.current_datafile()\n        return f.require_group(cls.__name__)",
  "def create_data_group(cls, name, *args, **kwargs):\n        \"\"\"Return a group to store a reading.\n\n        :param name: should be a noun describing what the reading is (image,\n        spectrum, etc.)\n        :param attrs: may be a dictionary, saved as HDF5 metadata\n        \"\"\"\n        if \"%d\" not in name:\n            name = name + '_%d'\n        df = cls.get_root_data_folder()\n        return df.create_group(name, auto_increment=True, *args, **kwargs)",
  "def create_dataset(cls, name, flush=True, *args, **kwargs):\n        \"\"\"Store a reading in a dataset (or make a new dataset to fill later).\n\n        :param name: should be a noun describing what the reading is (image,\n        spectrum, etc.)\n\n        Other arguments are passed to `nplab.datafile.Group.create_dataset`.\n        \"\"\"\n        if \"%d\" not in name: # is this really necessary?\n            name = name + '_%d'\n        df = cls.get_root_data_folder()\n        dset = df.create_dataset(name, *args, **kwargs)\n        if 'data' in kwargs and flush:\n            dset.file.flush() #make sure it's in the file if we wrote data\n        return dset",
  "def log(self, message,level = 'info'):\n        \"\"\"Save a log message to the current datafile.\n\n        This is the preferred way to output debug/informational messages.  They\n        will be saved in the current HDF5 file and optionally shown in the\n        nplab console.\n        \"\"\"\n        nplab.utils.log.log(message, from_object=self, level=level)",
  "def get_metadata(self, \n                     property_names=[], \n                     include_default_names=True,\n                     exclude=None\n                     ):\n        \"\"\"A dictionary of settings, properties, etc. to save along with data.\n\n        This returns the value of each property specified in the arguments or\n        in `self.metadata_property_names`.\n        \n        Arguments:\n        property_names : list of strings, optional\n            A list specifying the names of properties (of this object) to be\n            retrieved and returned in the dictionary.\n        include_default_names : boolean, optional (default True)\n            If True (the default), include the default metadata along with the\n            specified names.  This means that get_metadata can be used with no\n            arguments to retrieve the default metadata.\n        exclude : list of strings, optional\n            A list of properties to exclude (primarily useful when you want to\n            remove some of the default entries).  Nothing is excluded by \n            default.\n        \"\"\"\n        # Convert everything to lists to:\n        # * ensure we don't modify the arguments (it copies list arguments)\n        # * make it all mutable so we can remove items\n        # * prevent errors when adding lists and tuples\n        keys = list(property_names)\n        if include_default_names:\n            keys += list(self.metadata_property_names)\n        if exclude is not None:\n            for p in exclude:\n                try:\n                    keys.remove(p)\n                except ValueError:\n                    pass # Don't worry if we exclude items that are not there!\n        return {name: getattr(self,name) for name in keys}",
  "def bundle_metadata(self, data, enable=True, **kwargs):\n        \"\"\"Add metadata to a dataset, returning an ArrayWithAttrs.\n        \n        Arguments:\n        data : np.ndarray\n            The data with which to bundle the metadata\n        enable : boolean (optional, default to True)\n            Set this argument to False to do nothing, i.e. just return data.\n        **kwargs\n            Addditional arguments are passed to get_metadata (for example, you \n            can specify a list of `property_names` to add to the default\n            metadata, or a list of names to exclude.\n        \"\"\"\n        if enable:\n            return ArrayWithAttrs(data, attrs=self.get_metadata(**kwargs))\n        else:\n            return data",
  "def open_config_file(self):\n        \"\"\"Open the config file for the current spectrometer and return it, creating if it's not there\"\"\"\n        if not hasattr(self, '_config_file'):\n            try:\n                f = inspect.getfile(self.__class__) # fails in IPython\n            except (TypeError, ValueError):\n                f = inspect.getfile(self.__class__.__init__) # assumes the inst has an init method\n            d = os.path.dirname(f)\n            self._config_file = nplab.datafile.DataFile(os.path.join(d, self.__class__.__name__+'_config.h5'), mode='a')\n            self._config_file.attrs['date'] = datetime.datetime.now().strftime(\"%H:%M %d/%m/%y\")\n        return self._config_file",
  "def update_config(self, name, data, attrs= None):\n        \"\"\"Update the configuration file for this spectrometer.\n        \n        A file is created in the nplab directory that holds configuration\n        data for the spectrometer, including reference/background.  This\n        function allows values to be stored in that file.\"\"\"\n        f = self.config_file\n        if name in f.keys():\n            try: del f[name]\n            except: \n                f[name][...] = data\n                f.flush()    \n        else:\n            f.create_dataset(name, data=data, attrs=attrs)",
  "def temporarily_set(self, **kwargs):\n        \"\"\"Utility function for temporarily setting instrument parameters\n\n        :Example:\n        >>> with camera.temporarily_set(exposure=1, backgrounded=False):\n        >>>     image = camera.get_image()\n\n        :param kwargs: dict\n        :return:\n        \"\"\"\n        try:\n            original_settings = dict()\n            for key, value in kwargs.items():\n                original_settings[key] = getattr(self, key)\n                setattr(self, key, value)\n            yield original_settings\n        finally:\n            for key, value in original_settings.items():\n                setattr(self, key, value)",
  "def parse_arrays(value):\n    \"\"\"Utility function to convert arrays to strings to be sent over TCP\n\n    :param value: array to be converted\n    :return:\n    \"\"\"\n    if type(value) == ArrayWithAttrs:\n        reply = repr(dict(array=value.tolist(), attrs=value.attrs))\n    elif type(value) == np.ndarray:\n        reply = repr(dict(array=value.tolist()))\n    else:\n        reply = repr(value)\n    return reply",
  "def parse_strings(value):\n    \"\"\"Utility function to convert strings back into arrays\n\n    :param value: string containing an array\n    :return:\n    \"\"\"\n    if not isinstance(value, dict):\n        value = ast.literal_eval(value)\n    if isinstance(value, dict):\n        if 'array' in value and 'attrs' in value:\n            return ArrayWithAttrs(value['array'], value['attrs'])\n        elif 'array' in value:\n            return np.array(value['array'])\n    else:\n        return value",
  "def subselect(string, size=100):\n    \"\"\"Utility function to create a shortened version of strings for logging\n\n    :param string: string to be shortened\n    :param size: maximum size of string allowed\n    :return:\n    \"\"\"\n    if len(string) > size:\n        return '%s ... %s' % (string[:int(size/2)], string[-int(size/2):])\n    else:\n        return string",
  "class ServerHandler(socketserver.BaseRequestHandler):\n    def handle(self):\n        try:\n            raw_data = self.request.recv(BUFFER_SIZE).strip()\n            while message_end not in raw_data:\n                raw_data += self.request.recv(BUFFER_SIZE).strip()\n            raw_data = re.sub(re.escape(message_end) + b'$', b'', raw_data)\n            self.server._logger.debug(\"Server received: %s\" % subselect(raw_data))\n\n            if raw_data == b\"list_attributes\":\n                instr_reply = list(self.server.instrument.__dict__.keys())\n            else:\n                command_dict = ast.literal_eval(raw_data.decode())\n                if \"command\" in command_dict:\n                    if \"args\" in command_dict and \"kwargs\" in command_dict:\n                        instr_reply = getattr(self.server.instrument,\n                                              command_dict[\"command\"])(*command_dict[\"args\"], **command_dict[\"kwargs\"])\n                    elif \"args\" in command_dict:\n                        instr_reply = getattr(self.server.instrument, command_dict[\"command\"])(*command_dict[\"args\"])\n                    elif \"kwargs\" in command_dict:\n                        instr_reply = getattr(self.server.instrument, command_dict[\"command\"])(**command_dict[\"kwargs\"])\n                    else:\n                        instr_reply = getattr(self.server.instrument, command_dict[\"command\"])()\n                elif \"variable_get\" in command_dict:\n                    instr_reply = getattr(self.server.instrument, command_dict[\"variable_get\"])\n                elif \"variable_set\" in command_dict:\n                    setattr(self.server.instrument, command_dict[\"variable_set\"],\n                            parse_strings(command_dict[\"variable_value\"]))\n                    instr_reply = ''\n                else:\n                    instr_reply = \"Dictionary did not contain a 'command' or 'variable' key\"\n        except Exception as e:\n            self.server._logger.warn(e)\n            instr_reply = dict(error=e)\n        self.server._logger.debug(\"Instrument reply: %s\" % subselect(str(instr_reply)))\n\n        try:\n            if type(instr_reply) == ArrayWithAttrs:\n                reply = repr(dict(array=instr_reply.tolist(), attrs=instr_reply.attrs))\n            elif type(instr_reply) == np.ndarray:\n                reply = repr(dict(array=instr_reply.tolist()))\n            else:\n                reply = repr(instr_reply)\n        except Exception as e:\n            self.server._logger.warn(e)\n            reply = repr(dict(error=str(e)))\n        self.request.sendall(reply.encode() + message_end)\n        self.server._logger.debug(\n            \"Server replied %s %s: %s\" % (len(reply), sys.getsizeof(reply), subselect(reply)))",
  "def create_server_class(original_class):\n    \"\"\"\n    Given an nplab instrument class, returns a class that acts as a TCP server for that instrument.\n\n    :param original_class: an nplab instrument class\n    :return: server class\n    \"\"\"\n\n    class Server(socketserver.TCPServer):\n        def __init__(self, server_address, *args, **kwargs):\n            \"\"\"\n            To instantiate the server class, the TCP address needs to be given first, and then the arguments that would\n            be passed normally to the nplab instrument\n\n            :param server_address: 2-tuple. IP address and port for the server to listen on\n            :param args: arguments to be passed to the nplab instrument\n            :param kwargs: named arguments for the nplab instrument\n            \"\"\"\n            socketserver.TCPServer.__init__(self, server_address, ServerHandler, True)\n            self.instrument = original_class(*args, **kwargs)\n            self._logger = create_logger('TCP server')\n            self.thread = None\n\n        def run(self, with_gui=True, backgrounded=False):\n            \"\"\"\n            Start running the server\n\n            :param with_gui: bool. Runs the server in the background and opens the nplab instrument GUI\n            :param backgrounded: bool. Runs the server in the background\n            :return:\n            \"\"\"\n            if with_gui or backgrounded:\n                if self.thread is not None:\n                    del self.thread\n                self.thread = threading.Thread(target=self.serve_forever)\n                self.thread.setDaemon(True)  # don't hang on exit\n                self.thread.start()\n                if with_gui:\n                    self.instrument.show_gui()\n            else:\n                self.serve_forever()\n    return Server",
  "def create_client_class(original_class,\n                        tcp_methods=None,\n                        excluded_methods=('get_qt_ui', \"get_control_widget\", \"get_preview_widget\"),\n                        tcp_attributes=None,\n                        excluded_attributes=('ui', '_ShowGUIMixin__gui_instance')):\n    \"\"\"\n    Given an nplab instrument, returns a class that overrides a series of class methods, so that instead of running\n    those methods, it sends a string over TCP an instrument server of the same type. It is also able to get and set\n    attributes in the specific class instance of the server.\n\n    :param original_class: an nplab instrument class\n    :param tcp_methods: an iterable of method names that are to be sent over TCP. By default it is the\n                        original_class.__dict__.keys() excluding magic methods\n    :param excluded_methods: methods you do not want to send over TCP. By default the get_qt_ui isn't sent over TCP,\n            since it doesn't return something that can be sent over TCP (a pointer to an instance local to the server)\n    :param tcp_attributes: attributes you do want to read over TCP.\n    :param excluded_attributes: attributes you do not want to read over TCP, e.g. attributes that are inherently local.\n            Hence, by default, the GUI attributes are not read over TCP.\n    :return: new_class\n    \"\"\"\n\n    def method_builder(method_name):\n        \"\"\"\n        Given a method name, return a function that takes in any number of arguments and named arguments, creates a\n        dictionary with at most three keys (command, args, kwargs) and sends it to the server that the instance is\n        connected to\n\n        :param method_name: string\n        :return: method (function)\n        \"\"\"\n\n        def method(*args, **kwargs):\n            obj = args[0]\n            command_dict = dict(command=method_name)\n            if len(args) > 1:\n                command_dict[\"args\"] = args[1:]\n            if len(list(kwargs.keys())) > 0:\n                command_dict[\"kwargs\"] = kwargs\n            reply = obj.send_to_server(repr(command_dict))\n            if type(reply) == dict:\n                if \"array\" in reply:\n                    if \"attrs\" in reply:\n                        reply = ArrayWithAttrs(np.array(reply[\"array\"]), reply[\"attrs\"])\n                    else:\n                        reply = np.array(reply[\"array\"])\n            return reply\n\n        return method\n\n    class NewClass(original_class):\n        def __init__(self, address):\n            \"\"\"\n            The client instantiation also gets a list of attributes present in the server instrument instance\n\n            :param address: 2-tuple of IP and port to connect to\n            \"\"\"\n            self.address = address\n            self._logger = create_logger(original_class.__name__ + '_client')\n            self.instance_attributes = self.send_to_server(\"list_attributes\", address)\n\n        def __setattr__(self, item, value):\n            \"\"\"\n            Overriding the base __setattr__\n\n            :param item:\n            :param value:\n            :return:\n            \"\"\"\n            # print \"Setting: \", item\n            # If the item is a method, pass it to the NewClass so that it can be sent to the server\n            if item in self.method_list:\n                super(NewClass, self).__setattr__(item, value)\n            # If the item is a local attribute, set it locally\n            elif item in ['instance_attributes', 'address', '_logger'] + excluded_attributes:\n                original_class.__setattr__(self, item, value)\n            # If the item is an attribute of the server instrument, send it over TCP. Note this if needs to happen after\n            # the previous one, since it needs to use the self.instance_attributes\n            elif item in self.instance_attributes or item in tcp_attributes:\n                self.send_to_server(repr(dict(variable_set=item, variable_value=parse_arrays(value))))\n            else:\n                original_class.__setattr__(self, item, value)\n\n        def send_to_server(self, tcp_string, address=None):\n            \"\"\"\n            Opens a TCP port, connects it to address, sends the tcp_string, collects the reply, and returns it after\n            literal_eval\n\n            :param tcp_string: string to be sent over TCP\n            :param address: address to send to\n            :return: ast.literal_eval(reply_string)\n            \"\"\"\n            if address is None:\n                address = self.address\n            if isinstance(tcp_string, str):\n                tcp_string = tcp_string.encode()\n            self._logger.debug(\"Client sending: %s\" % subselect(tcp_string))\n            try:\n                sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n                sock.connect(address)\n                sock.sendall(tcp_string + message_end)\n                self._logger.debug(\"Client sent: %s\" % subselect(tcp_string))\n                received = sock.recv(BUFFER_SIZE)\n                while message_end not in received:\n                    received += sock.recv(BUFFER_SIZE)\n                received = re.sub(re.escape(message_end) + b'$', b'', received)\n                self._logger.debug(\"Client received: %s\" % subselect(received))\n                sock.close()\n                if b'error' in received:\n                    raise RuntimeError('Server error: %s' % subselect(received))\n            except Exception as e:\n                raise e\n            return ast.literal_eval(received.decode())\n\n    if tcp_methods is None:\n        tcp_methods = list(original_class.__dict__.keys())\n    excluded_methods = list(excluded_methods)\n    if tcp_attributes is None:\n        tcp_attributes = list()\n    excluded_attributes = list(excluded_attributes)\n\n    methods = []\n    for command_name in tcp_methods:\n        command = getattr(NewClass, command_name)\n        # only replaces methods that are not magic (__xx__) and are not explicitly excluded\n        if (inspect.ismethod(command) or inspect.isfunction(command)) and not command_name.startswith('__') and command_name not in excluded_methods:\n            setattr(NewClass, command_name, method_builder(command_name))\n            methods += [command_name]\n    setattr(NewClass, \"method_list\", methods)\n\n    def my_getattr(self, item):\n        # print(\"Getting: \", item, item in [\"address\", \"instance_attributes\"])\n        if item in [\"address\", \"instance_attributes\", \"method_list\", \"_logger\", \"__init__\"] + excluded_attributes:\n            # print('Excluded attribute: %s' % item)\n            return object.__getattribute__(self, item)\n            # return object.__getattr__(self, item)\n        elif item in self.instance_attributes or item in tcp_attributes:\n            # print('TCP: %s' % item)\n            return self.send_to_server(repr(dict(variable_get=item)))\n        elif item in excluded_methods:\n            # print('Excluded method: %s' % item)\n            # return original_class.__getattribute__(self, item)\n            return original_class.__getattr__(self, item)\n        else:\n            return super(NewClass, self).__getattr__(item)\n\n    setattr(NewClass, \"__getattr__\", my_getattr)\n\n    return NewClass",
  "def handle(self):\n        try:\n            raw_data = self.request.recv(BUFFER_SIZE).strip()\n            while message_end not in raw_data:\n                raw_data += self.request.recv(BUFFER_SIZE).strip()\n            raw_data = re.sub(re.escape(message_end) + b'$', b'', raw_data)\n            self.server._logger.debug(\"Server received: %s\" % subselect(raw_data))\n\n            if raw_data == b\"list_attributes\":\n                instr_reply = list(self.server.instrument.__dict__.keys())\n            else:\n                command_dict = ast.literal_eval(raw_data.decode())\n                if \"command\" in command_dict:\n                    if \"args\" in command_dict and \"kwargs\" in command_dict:\n                        instr_reply = getattr(self.server.instrument,\n                                              command_dict[\"command\"])(*command_dict[\"args\"], **command_dict[\"kwargs\"])\n                    elif \"args\" in command_dict:\n                        instr_reply = getattr(self.server.instrument, command_dict[\"command\"])(*command_dict[\"args\"])\n                    elif \"kwargs\" in command_dict:\n                        instr_reply = getattr(self.server.instrument, command_dict[\"command\"])(**command_dict[\"kwargs\"])\n                    else:\n                        instr_reply = getattr(self.server.instrument, command_dict[\"command\"])()\n                elif \"variable_get\" in command_dict:\n                    instr_reply = getattr(self.server.instrument, command_dict[\"variable_get\"])\n                elif \"variable_set\" in command_dict:\n                    setattr(self.server.instrument, command_dict[\"variable_set\"],\n                            parse_strings(command_dict[\"variable_value\"]))\n                    instr_reply = ''\n                else:\n                    instr_reply = \"Dictionary did not contain a 'command' or 'variable' key\"\n        except Exception as e:\n            self.server._logger.warn(e)\n            instr_reply = dict(error=e)\n        self.server._logger.debug(\"Instrument reply: %s\" % subselect(str(instr_reply)))\n\n        try:\n            if type(instr_reply) == ArrayWithAttrs:\n                reply = repr(dict(array=instr_reply.tolist(), attrs=instr_reply.attrs))\n            elif type(instr_reply) == np.ndarray:\n                reply = repr(dict(array=instr_reply.tolist()))\n            else:\n                reply = repr(instr_reply)\n        except Exception as e:\n            self.server._logger.warn(e)\n            reply = repr(dict(error=str(e)))\n        self.request.sendall(reply.encode() + message_end)\n        self.server._logger.debug(\n            \"Server replied %s %s: %s\" % (len(reply), sys.getsizeof(reply), subselect(reply)))",
  "class Server(socketserver.TCPServer):\n        def __init__(self, server_address, *args, **kwargs):\n            \"\"\"\n            To instantiate the server class, the TCP address needs to be given first, and then the arguments that would\n            be passed normally to the nplab instrument\n\n            :param server_address: 2-tuple. IP address and port for the server to listen on\n            :param args: arguments to be passed to the nplab instrument\n            :param kwargs: named arguments for the nplab instrument\n            \"\"\"\n            socketserver.TCPServer.__init__(self, server_address, ServerHandler, True)\n            self.instrument = original_class(*args, **kwargs)\n            self._logger = create_logger('TCP server')\n            self.thread = None\n\n        def run(self, with_gui=True, backgrounded=False):\n            \"\"\"\n            Start running the server\n\n            :param with_gui: bool. Runs the server in the background and opens the nplab instrument GUI\n            :param backgrounded: bool. Runs the server in the background\n            :return:\n            \"\"\"\n            if with_gui or backgrounded:\n                if self.thread is not None:\n                    del self.thread\n                self.thread = threading.Thread(target=self.serve_forever)\n                self.thread.setDaemon(True)  # don't hang on exit\n                self.thread.start()\n                if with_gui:\n                    self.instrument.show_gui()\n            else:\n                self.serve_forever()",
  "def method_builder(method_name):\n        \"\"\"\n        Given a method name, return a function that takes in any number of arguments and named arguments, creates a\n        dictionary with at most three keys (command, args, kwargs) and sends it to the server that the instance is\n        connected to\n\n        :param method_name: string\n        :return: method (function)\n        \"\"\"\n\n        def method(*args, **kwargs):\n            obj = args[0]\n            command_dict = dict(command=method_name)\n            if len(args) > 1:\n                command_dict[\"args\"] = args[1:]\n            if len(list(kwargs.keys())) > 0:\n                command_dict[\"kwargs\"] = kwargs\n            reply = obj.send_to_server(repr(command_dict))\n            if type(reply) == dict:\n                if \"array\" in reply:\n                    if \"attrs\" in reply:\n                        reply = ArrayWithAttrs(np.array(reply[\"array\"]), reply[\"attrs\"])\n                    else:\n                        reply = np.array(reply[\"array\"])\n            return reply\n\n        return method",
  "class NewClass(original_class):\n        def __init__(self, address):\n            \"\"\"\n            The client instantiation also gets a list of attributes present in the server instrument instance\n\n            :param address: 2-tuple of IP and port to connect to\n            \"\"\"\n            self.address = address\n            self._logger = create_logger(original_class.__name__ + '_client')\n            self.instance_attributes = self.send_to_server(\"list_attributes\", address)\n\n        def __setattr__(self, item, value):\n            \"\"\"\n            Overriding the base __setattr__\n\n            :param item:\n            :param value:\n            :return:\n            \"\"\"\n            # print \"Setting: \", item\n            # If the item is a method, pass it to the NewClass so that it can be sent to the server\n            if item in self.method_list:\n                super(NewClass, self).__setattr__(item, value)\n            # If the item is a local attribute, set it locally\n            elif item in ['instance_attributes', 'address', '_logger'] + excluded_attributes:\n                original_class.__setattr__(self, item, value)\n            # If the item is an attribute of the server instrument, send it over TCP. Note this if needs to happen after\n            # the previous one, since it needs to use the self.instance_attributes\n            elif item in self.instance_attributes or item in tcp_attributes:\n                self.send_to_server(repr(dict(variable_set=item, variable_value=parse_arrays(value))))\n            else:\n                original_class.__setattr__(self, item, value)\n\n        def send_to_server(self, tcp_string, address=None):\n            \"\"\"\n            Opens a TCP port, connects it to address, sends the tcp_string, collects the reply, and returns it after\n            literal_eval\n\n            :param tcp_string: string to be sent over TCP\n            :param address: address to send to\n            :return: ast.literal_eval(reply_string)\n            \"\"\"\n            if address is None:\n                address = self.address\n            if isinstance(tcp_string, str):\n                tcp_string = tcp_string.encode()\n            self._logger.debug(\"Client sending: %s\" % subselect(tcp_string))\n            try:\n                sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n                sock.connect(address)\n                sock.sendall(tcp_string + message_end)\n                self._logger.debug(\"Client sent: %s\" % subselect(tcp_string))\n                received = sock.recv(BUFFER_SIZE)\n                while message_end not in received:\n                    received += sock.recv(BUFFER_SIZE)\n                received = re.sub(re.escape(message_end) + b'$', b'', received)\n                self._logger.debug(\"Client received: %s\" % subselect(received))\n                sock.close()\n                if b'error' in received:\n                    raise RuntimeError('Server error: %s' % subselect(received))\n            except Exception as e:\n                raise e\n            return ast.literal_eval(received.decode())",
  "def my_getattr(self, item):\n        # print(\"Getting: \", item, item in [\"address\", \"instance_attributes\"])\n        if item in [\"address\", \"instance_attributes\", \"method_list\", \"_logger\", \"__init__\"] + excluded_attributes:\n            # print('Excluded attribute: %s' % item)\n            return object.__getattribute__(self, item)\n            # return object.__getattr__(self, item)\n        elif item in self.instance_attributes or item in tcp_attributes:\n            # print('TCP: %s' % item)\n            return self.send_to_server(repr(dict(variable_get=item)))\n        elif item in excluded_methods:\n            # print('Excluded method: %s' % item)\n            # return original_class.__getattribute__(self, item)\n            return original_class.__getattr__(self, item)\n        else:\n            return super(NewClass, self).__getattr__(item)",
  "def __init__(self, server_address, *args, **kwargs):\n            \"\"\"\n            To instantiate the server class, the TCP address needs to be given first, and then the arguments that would\n            be passed normally to the nplab instrument\n\n            :param server_address: 2-tuple. IP address and port for the server to listen on\n            :param args: arguments to be passed to the nplab instrument\n            :param kwargs: named arguments for the nplab instrument\n            \"\"\"\n            socketserver.TCPServer.__init__(self, server_address, ServerHandler, True)\n            self.instrument = original_class(*args, **kwargs)\n            self._logger = create_logger('TCP server')\n            self.thread = None",
  "def run(self, with_gui=True, backgrounded=False):\n            \"\"\"\n            Start running the server\n\n            :param with_gui: bool. Runs the server in the background and opens the nplab instrument GUI\n            :param backgrounded: bool. Runs the server in the background\n            :return:\n            \"\"\"\n            if with_gui or backgrounded:\n                if self.thread is not None:\n                    del self.thread\n                self.thread = threading.Thread(target=self.serve_forever)\n                self.thread.setDaemon(True)  # don't hang on exit\n                self.thread.start()\n                if with_gui:\n                    self.instrument.show_gui()\n            else:\n                self.serve_forever()",
  "def method(*args, **kwargs):\n            obj = args[0]\n            command_dict = dict(command=method_name)\n            if len(args) > 1:\n                command_dict[\"args\"] = args[1:]\n            if len(list(kwargs.keys())) > 0:\n                command_dict[\"kwargs\"] = kwargs\n            reply = obj.send_to_server(repr(command_dict))\n            if type(reply) == dict:\n                if \"array\" in reply:\n                    if \"attrs\" in reply:\n                        reply = ArrayWithAttrs(np.array(reply[\"array\"]), reply[\"attrs\"])\n                    else:\n                        reply = np.array(reply[\"array\"])\n            return reply",
  "def __init__(self, address):\n            \"\"\"\n            The client instantiation also gets a list of attributes present in the server instrument instance\n\n            :param address: 2-tuple of IP and port to connect to\n            \"\"\"\n            self.address = address\n            self._logger = create_logger(original_class.__name__ + '_client')\n            self.instance_attributes = self.send_to_server(\"list_attributes\", address)",
  "def __setattr__(self, item, value):\n            \"\"\"\n            Overriding the base __setattr__\n\n            :param item:\n            :param value:\n            :return:\n            \"\"\"\n            # print \"Setting: \", item\n            # If the item is a method, pass it to the NewClass so that it can be sent to the server\n            if item in self.method_list:\n                super(NewClass, self).__setattr__(item, value)\n            # If the item is a local attribute, set it locally\n            elif item in ['instance_attributes', 'address', '_logger'] + excluded_attributes:\n                original_class.__setattr__(self, item, value)\n            # If the item is an attribute of the server instrument, send it over TCP. Note this if needs to happen after\n            # the previous one, since it needs to use the self.instance_attributes\n            elif item in self.instance_attributes or item in tcp_attributes:\n                self.send_to_server(repr(dict(variable_set=item, variable_value=parse_arrays(value))))\n            else:\n                original_class.__setattr__(self, item, value)",
  "def send_to_server(self, tcp_string, address=None):\n            \"\"\"\n            Opens a TCP port, connects it to address, sends the tcp_string, collects the reply, and returns it after\n            literal_eval\n\n            :param tcp_string: string to be sent over TCP\n            :param address: address to send to\n            :return: ast.literal_eval(reply_string)\n            \"\"\"\n            if address is None:\n                address = self.address\n            if isinstance(tcp_string, str):\n                tcp_string = tcp_string.encode()\n            self._logger.debug(\"Client sending: %s\" % subselect(tcp_string))\n            try:\n                sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n                sock.connect(address)\n                sock.sendall(tcp_string + message_end)\n                self._logger.debug(\"Client sent: %s\" % subselect(tcp_string))\n                received = sock.recv(BUFFER_SIZE)\n                while message_end not in received:\n                    received += sock.recv(BUFFER_SIZE)\n                received = re.sub(re.escape(message_end) + b'$', b'', received)\n                self._logger.debug(\"Client received: %s\" % subselect(received))\n                sock.close()\n                if b'error' in received:\n                    raise RuntimeError('Server error: %s' % subselect(received))\n            except Exception as e:\n                raise e\n            return ast.literal_eval(received.decode())",
  "class VisaInstrument(MessageBusInstrument):\n    \"\"\"\n    An instrument primarily using VISA communications\n    \"\"\"\n\n    def __init__(self, address, settings=None):\n        \"\"\"\n        :param address: VISA address as a string\n        :param settings: dictionary of instrument settings, including:\n            'read_termination', 'write_termination', 'timeout' (0 for inf),\n            'send_end' (not recommended to remove end of line character),\n            delay (time between write and read during query)\n        :type object\n        \"\"\"\n        super(VisaInstrument, self).__init__()\n        rm = visa.ResourceManager()\n        try:\n            assert address in rm.list_resources(), \"The instrument was not found\"\n        except AssertionError:\n            print('Available equipment:', rm.list_resources())\n        if settings is None:\n            settings = dict()\n        self.instr = rm.open_resource(address, **settings)\n        self._address = address\n        self._settings = settings\n\n    def __del__(self):\n        try:\n            self.instr.close()\n        except Exception as e:\n            print(\"The serial port didn't close cleanly:\", e)\n\n    def _write(self, *args, **kwargs):\n        with self.communications_lock:\n            return self.instr.write(*args, **kwargs)\n\n    def read(self, *args, **kwargs):\n        with self.communications_lock:\n            return self.instr.read(*args, **kwargs)\n\n    def query(self, *args, **kwargs):\n        with self.communications_lock:\n            return self.instr.query(*args, **kwargs)\n\n    def clear_read_buffer(self):\n        empty_buffer = False\n        while not empty_buffer:\n            try:\n                self.instr.read()\n            except Exception:\n                print(\"Buffer emptied\")\n                empty_buffer = True\n                \n    idn = queried_property('*idn?', dtype='str')",
  "def __init__(self, address, settings=None):\n        \"\"\"\n        :param address: VISA address as a string\n        :param settings: dictionary of instrument settings, including:\n            'read_termination', 'write_termination', 'timeout' (0 for inf),\n            'send_end' (not recommended to remove end of line character),\n            delay (time between write and read during query)\n        :type object\n        \"\"\"\n        super(VisaInstrument, self).__init__()\n        rm = visa.ResourceManager()\n        try:\n            assert address in rm.list_resources(), \"The instrument was not found\"\n        except AssertionError:\n            print('Available equipment:', rm.list_resources())\n        if settings is None:\n            settings = dict()\n        self.instr = rm.open_resource(address, **settings)\n        self._address = address\n        self._settings = settings",
  "def __del__(self):\n        try:\n            self.instr.close()\n        except Exception as e:\n            print(\"The serial port didn't close cleanly:\", e)",
  "def _write(self, *args, **kwargs):\n        with self.communications_lock:\n            return self.instr.write(*args, **kwargs)",
  "def read(self, *args, **kwargs):\n        with self.communications_lock:\n            return self.instr.read(*args, **kwargs)",
  "def query(self, *args, **kwargs):\n        with self.communications_lock:\n            return self.instr.query(*args, **kwargs)",
  "def clear_read_buffer(self):\n        empty_buffer = False\n        while not empty_buffer:\n            try:\n                self.instr.read()\n            except Exception:\n                print(\"Buffer emptied\")\n                empty_buffer = True",
  "def error_string(error_code):\n    \"\"\"convert an error code into a human-readable string\"\"\"\n    N = 1024  # we need to create a buffer into which we place the returned string\n    s = ctypes.create_string_buffer(N)\n    seabreeze.seabreeze_get_error_string(error_code, byref(s), N)\n    return s.value.decode('utf-8')",
  "def check_error(error_c_int):\n    \"\"\"check the error code returned by a function (as a raw c_int)\n    and raise an exception if it's nonzero.\"\"\"\n    if error_c_int.value != 0:\n        raise OceanOpticsError(error_c_int.value)",
  "def list_spectrometers():\n    \"\"\"List the serial numbers of all spectrometers connected to the computer\"\"\"\n    spectrometers = []\n    n = 0\n    try:\n        while True:  # we stop when we run out of spectrometers, signified by an exception\n            # the line below creates a spectrometer, initialises, gets the serial number, and closes again\n            spectrometers.append(OceanOpticsSpectrometer(n).serial_number)\n            # if the spectrometer does not exist, it raises an exception.\n            n += 1\n    except OceanOpticsError:\n        pass\n    finally:\n        return spectrometers",
  "def shutdown_seabreeze():\n    \"\"\"shut down seabreeze, useful if anything has gone wrong\"\"\"\n    seabreeze.seabreeze_shutdown()",
  "class OceanOpticsError(Exception):\n    def __init__(self, code):\n        self.code = code\n\n    def __str__(self):\n        return \"Code %d: %s.\" % (self.code, error_string(self.code))",
  "class OceanOpticsSpectrometer(Spectrometer, Instrument):\n    \"\"\"Class representing the Ocean Optics spectrometers, via the SeaBreeze library\n\n    The constructor takes a single numeric argument, which is the index of the\n    spectrometer you want, starting at 0.  It has traits, so you can call up a\n    GUI to control the spectrometer with s.configure_traits.\"\"\"\n\n    metadata_property_names = Spectrometer.metadata_property_names+ (\"tec_temperature\",)\n\n    @staticmethod\n    def shutdown_seabreeze():\n        \"\"\"shut down seabreeze, useful if anything has gone wrong\"\"\"\n        shutdown_seabreeze()\n\n    @classmethod\n    def list_spectrometers(cls):\n        \"\"\"List the serial numbers of all spectrometers connected to the computer\"\"\"\n        return list_spectrometers()\n\n    @classmethod\n    def get_spectrometer_instances(cls):\n        \"\"\"return a list of spectrometer instances for all available spectrometers\"\"\"\n        spectrometers = []\n        try:\n            n = 0\n            while True:\n                spectrometers.append(cls(n))\n                n += 1\n        except OceanOpticsError:\n            pass\n        finally:\n            return spectrometers\n\n    @classmethod\n    def get_spectrometers(cls):\n        \"\"\"get a Spectrometers instance containing all available spectrometers\"\"\"\n        return Spectrometers(cls.get_spectrometer_instances())\n\n    @classmethod\n    def get_current_spectrometers(cls):\n        \"\"\"Return the currently-open spectrometers, or all spectrometers.\n\n        If one or more spectrometers are currently open, create a Spectrometers\n        wrapper and include them in it.  If not, attempt to open and wrap all\n        spectrometers connected to the computer.\"\"\"\n        instances = cls.get_instances()\n        print(instances)\n        if instances == []:\n            return cls.get_spectrometers()\n        else:\n            return Spectrometers(instances)\n\n    def __init__(self, index):\n        \"\"\"Initialise the spectrometer\"\"\"\n        self.index = index  # the spectrometer's ID, used by all seabreeze functions\n        self._comms_lock = threading.RLock()\n        self._isOpen = False\n        self._open()\n        super(OceanOpticsSpectrometer, self).__init__()\n        self.get_API_version() \n        self._minimum_integration_time = None\n        self.integration_time = self.minimum_integration_time\n        self._tec_enabled = True\n        self.enable_tec = True\n        \n        self._file = inspect.getfile(self.__class__)\n        \n        # https://bugs.python.org/issue12920 getfile fails when running the script directly,\n        # or when using IPython after script execution\n    \n        \n\n    def __del__(self):\n        self._close()\n        super(OceanOpticsSpectrometer, self).__del__()\n        return self\n\n    def _open(self, force=False):\n        \"\"\"Open communications with the spectrometer (called on initialisation).\"\"\"\n        if (self._isOpen and not force):  # don't cause errors if it's already open\n            return\n        else:\n            e = ctypes.c_int()\n            seabreeze.seabreeze_open_spectrometer(self.index, byref(e))\n            check_error(e)\n            self._isOpen = True\n\n    def _close(self, force=False):\n        \"\"\"Close communication with the spectrometer and release it.\"\"\"\n        if (not self._isOpen and not force):\n            return\n        else:\n            e = ctypes.c_int()\n            seabreeze.seabreeze_close_spectrometer(self.index, byref(e))\n            check_error(e)\n            self._isOpen = False\n\n    def open_config_file(self):\n        if self._config_file is None:\n            \n            d = os.path.dirname(self._file)\n            self._config_file = DataFile(h5py.File(os.path.join(d, self.model_name+'_'+self.serial_number+'_config.h5'), 'a'))\n            self._config_file.attrs['date'] = datetime.datetime.now().strftime(\"%H:%M %d/%m/%y\")\n        return self._config_file\n\n    config_file = property(open_config_file)\n    def get_API_version(self):\n        N = 32  # make a buffer for the DLL to return a string into\n        s = ctypes.create_string_buffer(N)\n        e = ctypes.c_int()\n        try:\n            seabreeze.seabreeze_get_model(self.index, byref(e), byref(s), N)\n            self.API_ver = 2\n        except:\n            self.API_ver = 1\n        check_error(e)        \n\n    def get_model_name(self):\n        if self._model_name is None:\n            N = 32  # make a buffer for the DLL to return a string into\n            s = ctypes.create_string_buffer(N)\n            e = ctypes.c_int()\n            try:\n                seabreeze.seabreeze_get_model(self.index, byref(e), byref(s), N)\n                self.API_ver = 2\n            except:\n                seabreeze.seabreeze_get_spectrometer_type(self.index, byref(e), byref(s), N)\n                self.API_ver = 1\n            check_error(e)\n            self._model_name = s.value.decode('utf-8')\n        return self._model_name\n\n    model_name = property(get_model_name)\n\n    def get_serial_number(self):\n        \"\"\"The spectrometer's serial number.\"\"\"\n        if self._serial_number is None:\n            N = 32  # make a buffer for the DLL to return a string into\n            s = ctypes.create_string_buffer(N)\n            e = ctypes.c_int()\n            seabreeze.seabreeze_get_serial_number(self.index, byref(e), byref(s), N)\n            check_error(e)\n            self._serial_number = s.value.decode('utf-8')\n        return self._serial_number\n\n    serial_number = property(get_serial_number)\n\n    def get_usb_descriptor(self, id):\n        \"\"\"The spectrometer's USB descriptor\"\"\"\n        N = 32  # make a buffer for the DLL to return a string into\n        s = ctypes.create_string_buffer(N)\n        e = ctypes.c_int()\n        seabreeze.seabreeze_get_usb_descriptor_string(self.index, byref(e), c_int(id), byref(s), N)\n        check_error(e)\n        return s.value.decode('utf-8')\n\n    def get_integration_time(self):\n        \"\"\"The current integration time.\n\n        The SeaBreeze API doesn't seem to allow us to get the current integration time, so\n        we work around it by cacheing the last used integration time.  Note that this will\n        return None if you've not set the integration time.\"\"\"\n        if hasattr(self, \"_latest_integration_time\"):\n            return self._latest_integration_time\n        else:\n            return None\n\n    def set_integration_time(self, milliseconds):\n        \"\"\"Set the integration time\"\"\"\n        e = ctypes.c_int()\n        if milliseconds < self.minimum_integration_time:\n            raise ValueError(\"Cannot set integration time below %d microseconds\" % self.minimum_integration_time)\n        if self.API_ver == 1:\n            seabreeze.seabreeze_set_integration_time(self.index, byref(e), c_ulong(int(milliseconds * 1000)))\n        if self.API_ver == 2:\n            seabreeze.seabreeze_set_integration_time_microsec(self.index, byref(e), c_ulong(int(milliseconds * 1000)))\n        \n        check_error(e)\n        self._latest_integration_time = milliseconds\n\n    integration_time = property(get_integration_time, set_integration_time)\n\n    def get_minimum_integration_time(self):\n        \"\"\"Minimum allowable value for integration time\"\"\"\n        if self._minimum_integration_time is None:\n            e = ctypes.c_int()\n            if self.API_ver == 1:\n                min_time = seabreeze.seabreeze_get_minimum_integration_time_micros(self.index, byref(e))\n            if self.API_ver == 2:\n                min_time = seabreeze.seabreeze_get_min_integration_time_microsec(self.index, byref(e))   \n            check_error(e)\n            self._minimum_integration_time = min_time / 1000.\n        return self._minimum_integration_time\n\n    minimum_integration_time = property(get_minimum_integration_time)\n\n    def get_tec_enable(self):\n        \"\"\"Whether or not the thermo-electric cooler is enabled.\"\"\"\n        try:\n            return self._tec_enabled\n        except OceanOpticsError as error:\n            print(error)\n            print('Most likely raised due to the lack of a tec on this device')\n\n    def set_tec_enable(self, state=True):\n        \"\"\"Turn the cooling system on or off.\"\"\"\n        try:\n            e = ctypes.c_int()\n            seabreeze.seabreeze_set_tec_enable(self.index, byref(e), c_int(state))\n            check_error(e)\n            self._tec_enabled = state\n        except OceanOpticsError as error:\n            print(error)\n            print('Most likely raised due to the lack of a tec on this device')\n\n    enable_tec = property(get_tec_enable, set_tec_enable)\n\n    def get_tec_temperature(self):\n        \"\"\"Current temperature.\"\"\"\n        try:\n            e = ctypes.c_int()\n            read_tec_temperature = seabreeze.seabreeze_read_tec_temperature\n            read_tec_temperature.restype = c_double\n            temperature_0 = read_tec_temperature(self.index, byref(e))\n            for i in range(100):\n                temperature = read_tec_temperature(self.index, byref(e))\n                check_error(e)\n                if temperature==temperature_0:\n                    break\n                else:\n                    temperature_0=temperature\n                if i==99:\n                    self.log('Temperature reading inconsitent after 100 attmpets','WARN')\n           \n            return temperature\n        except OceanOpticsError as error:\n            print(error)\n            print('Most likely raised due to the lack of a tec on this device')\n\n    def set_tec_temperature(self, temperature):\n        \"\"\"Enable the cooling system and set the temperature\"\"\"\n        try:\n            if not self.enable_tec:\n                self.enable_tec = True\n            e = ctypes.c_int()\n            seabreeze.seabreeze_set_tec_temperature(self.index, byref(e), c_double(temperature))\n            seabreeze.seabreeze_set_tec_enable(self.index, byref(e), 1)\n            check_error(e)\n        except OceanOpticsError as error:\n            print(error)\n            print('Most likely raised due to the lack of a tec on this device')\n\n    tec_temperature = property(get_tec_temperature, set_tec_temperature)\n\n    def read_wavelengths(self):\n        \"\"\"get an array of the wavelengths in nm\"\"\"\n        self._comms_lock.acquire()\n        e = ctypes.c_int()\n        N = seabreeze.seabreeze_get_formatted_spectrum_length(self.index, byref(e))\n        wavelengths_carray = (c_double * N)()  # this should create a c array of doubles, length N\n        seabreeze.seabreeze_get_wavelengths(self.index, byref(e), byref(wavelengths_carray), N)\n        self._comms_lock.release()\n        check_error(e)\n        return np.array(list(wavelengths_carray))\n\n    def get_wavelengths(self):\n        \"\"\"Wavelength values for each pixel.\n\n        NB this caches the value so it's only retrieved from the spectrometer once.\"\"\"\n        if self._wavelengths is None:\n            self._wavelengths = self.read_wavelengths()\n        return self._wavelengths\n\n    wavelengths = property(get_wavelengths)\n\n    def read_spectrum(self, bundle_metadata=False):\n        \"\"\"Get the current reading from the spectrometer's sensor.\n\n        Acquire a new spectrum and return it.  If bundle_metadata is true, this will be\n        returned as an ArrayWithAttrs, including the current metadata.\"\"\"\n        e = ctypes.c_int()\n        N = seabreeze.seabreeze_get_formatted_spectrum_length(self.index, byref(e))\n        with self._comms_lock:\n            spectrum_carray = (c_double * N)()  # this should create a c array of doubles, length N\n            seabreeze.seabreeze_get_formatted_spectrum(self.index, byref(e), byref(spectrum_carray), N)\n        check_error(e)  # throw an exception if something went wrong\n        new_spectrum = np.array(list(spectrum_carray))\n\n        if bundle_metadata:\n            return ArrayWithAttrs(new_spectrum, attrs=self.metadata)\n        else:\n            return new_spectrum\n\n    def get_qt_ui(self, control_only=False, display_only = False):\n        \"\"\"Return a Qt Widget for controlling the spectrometer.\n\n        If control_only is true, this will not contain a graph of the spectrum.\n        \"\"\"\n        if control_only:\n            return OceanOpticsControlUI(self)\n        elif display_only:\n            return SpectrometerDisplayUI(self)\n        else:\n            return SpectrometerUI(self)\n\n    def get_control_widget(self):\n        \"\"\"Convenience function \"\"\"\n        return self.get_qt_ui(control_only=True)\n        \n    def get_preview_widget(self):\n        \"\"\"Convenience function \"\"\"\n        return self.get_qt_ui(display_only=True)",
  "class OceanOpticsControlUI(SpectrometerControlUI):\n    def __init__(self, spectrometer):\n        assert isinstance(spectrometer, OceanOpticsSpectrometer), 'spectrometer must be an OceanOpticsSpectrometer'\n        super(OceanOpticsControlUI, self).__init__(spectrometer,os.path.join(os.path.dirname(__file__),'ocean_optics_controls.ui'))\n#        self.tec_temperature.setValidator(QtGui.QDoubleValidator())\n        # self.tec_temperature.textChanged.connect(self.check_state)\n        # self.tec_temperature.textChanged.connect(self.update_param)\n        # self.tec_temperature.setText(str(spectrometer.tec_temperature))\n        try: \n            self.spectrometer.get_tec_temperature()\n            tec = True\n        except AttributeError as e:\n            print(e, 'removing cooling functionality')\n            tec = False\n        if tec:\n            \n            self.set_tec_temperature_pushButton.clicked.connect(self.gui_set_tec_temperature)\n            self.read_tec_temperature_pushButton.clicked.connect(self.gui_read_tec_tempeature)\n            self.enable_tec.stateChanged.connect(self.update_enable_tec)\n            self.enable_tec.setChecked(self.spectrometer.enable_tec)\n            initial_temperature = np.round(self.spectrometer.tec_temperature, decimals = 1)\n            self.tec_temperature_lcdNumber.display(float(initial_temperature))\n            self.set_tec_temperature_LineEdit.setText(str(initial_temperature))\n            self.update_enable_tec(0) # sometimes helps enable cooling\n            self.update_enable_tec(1)\n        else:\n            self.set_tec_temperature_pushButton.setVisible(False)\n            self.read_tec_temperature_pushButton.setVisible(False)\n            self.enable_tec.setVisible(False)\n            self.tec_temperature_lcdNumber.setVisible(False)\n            self.set_tec_temperature_LineEdit.setVisible(False)\n            \n    def update_param(self, value):\n        sender = self.sender()\n        if sender.validator() is not None:\n            state = sender.validator().validate(value, 0)[0]\n            if state != QtGui.QValidator.Acceptable:\n                return\n        if sender is self.integration_time:\n            try:\n                self.spectrometer.integration_time = float(value)\n            except ValueError:\n                pass\n        elif sender is self.tec_temperature:\n            try:\n                self.spectrometer.tec_temperature = float(value)\n            except ValueError:\n                pass\n    \n    def gui_set_tec_temperature(self):\n        self.spectrometer.tec_temperature = float(self.set_tec_temperature_LineEdit.text().strip())\n    \n    def gui_read_tec_tempeature(self):\n        self.tec_temperature_lcdNumber.display(float(self.spectrometer.tec_temperature))\n    \n    def update_enable_tec(self, state):\n        if state == QtCore.Qt.Checked:\n            self.spectrometer.enable_tec = True\n        elif state == QtCore.Qt.Unchecked:\n            self.spectrometer.enable_tec = False",
  "def main():\n    from nplab.instrument.spectrometer import Spectrometers\n    import sys\n    from nplab.utils.gui import get_qt_app\n\n    try:\n        N = len(list_spectrometers())\n        print(\"Spectrometers connected:\", list_spectrometers())\n        print(\"%d spectrometers found\" % N)\n        assert N != 0, 'There are no Ocean Optics spectrometers attached (are you using the seabreeze drivers?)'\n\n        spectrometers = OceanOpticsSpectrometer.get_spectrometers()\n        for s in spectrometers.spectrometers:\n            print(\"spectrometer %s is a %s\" % (s.serial_number, s.model_name))\n            if s.model_name in [\"QE65000\", \"QE-PRO\"]:\n                s.set_tec_temperature = -20\n            s.read()\n #       app = get_qt_app()\n #       ui = spectrometers.get_qt_ui()\n #       ui.show()\n #       sys.exit(app.exec_()) #this is the \"long way\" of running a GUI\n        spectrometers.show_gui()  # the \"short way\" of running a GUI\n    except OceanOpticsError as error:\n        print(\"An error occurred with the spectrometer: %s\" % error)\n    finally:\n        try:\n            pass\n            #           del s     #we close the spectrometer afterwards, regardless of what happened.\n        except:  # of course, if there's no spectrometer this will fail, hence the error handling\n            shutdown_seabreeze()  # reset things if we've had errors\n            print(\"The spectrometer did not close cleanly. SeaBreeze has been reset.\")",
  "def __init__(self, code):\n        self.code = code",
  "def __str__(self):\n        return \"Code %d: %s.\" % (self.code, error_string(self.code))",
  "def shutdown_seabreeze():\n        \"\"\"shut down seabreeze, useful if anything has gone wrong\"\"\"\n        shutdown_seabreeze()",
  "def list_spectrometers(cls):\n        \"\"\"List the serial numbers of all spectrometers connected to the computer\"\"\"\n        return list_spectrometers()",
  "def get_spectrometer_instances(cls):\n        \"\"\"return a list of spectrometer instances for all available spectrometers\"\"\"\n        spectrometers = []\n        try:\n            n = 0\n            while True:\n                spectrometers.append(cls(n))\n                n += 1\n        except OceanOpticsError:\n            pass\n        finally:\n            return spectrometers",
  "def get_spectrometers(cls):\n        \"\"\"get a Spectrometers instance containing all available spectrometers\"\"\"\n        return Spectrometers(cls.get_spectrometer_instances())",
  "def get_current_spectrometers(cls):\n        \"\"\"Return the currently-open spectrometers, or all spectrometers.\n\n        If one or more spectrometers are currently open, create a Spectrometers\n        wrapper and include them in it.  If not, attempt to open and wrap all\n        spectrometers connected to the computer.\"\"\"\n        instances = cls.get_instances()\n        print(instances)\n        if instances == []:\n            return cls.get_spectrometers()\n        else:\n            return Spectrometers(instances)",
  "def __init__(self, index):\n        \"\"\"Initialise the spectrometer\"\"\"\n        self.index = index  # the spectrometer's ID, used by all seabreeze functions\n        self._comms_lock = threading.RLock()\n        self._isOpen = False\n        self._open()\n        super(OceanOpticsSpectrometer, self).__init__()\n        self.get_API_version() \n        self._minimum_integration_time = None\n        self.integration_time = self.minimum_integration_time\n        self._tec_enabled = True\n        self.enable_tec = True\n        \n        self._file = inspect.getfile(self.__class__)",
  "def __del__(self):\n        self._close()\n        super(OceanOpticsSpectrometer, self).__del__()\n        return self",
  "def _open(self, force=False):\n        \"\"\"Open communications with the spectrometer (called on initialisation).\"\"\"\n        if (self._isOpen and not force):  # don't cause errors if it's already open\n            return\n        else:\n            e = ctypes.c_int()\n            seabreeze.seabreeze_open_spectrometer(self.index, byref(e))\n            check_error(e)\n            self._isOpen = True",
  "def _close(self, force=False):\n        \"\"\"Close communication with the spectrometer and release it.\"\"\"\n        if (not self._isOpen and not force):\n            return\n        else:\n            e = ctypes.c_int()\n            seabreeze.seabreeze_close_spectrometer(self.index, byref(e))\n            check_error(e)\n            self._isOpen = False",
  "def open_config_file(self):\n        if self._config_file is None:\n            \n            d = os.path.dirname(self._file)\n            self._config_file = DataFile(h5py.File(os.path.join(d, self.model_name+'_'+self.serial_number+'_config.h5'), 'a'))\n            self._config_file.attrs['date'] = datetime.datetime.now().strftime(\"%H:%M %d/%m/%y\")\n        return self._config_file",
  "def get_API_version(self):\n        N = 32  # make a buffer for the DLL to return a string into\n        s = ctypes.create_string_buffer(N)\n        e = ctypes.c_int()\n        try:\n            seabreeze.seabreeze_get_model(self.index, byref(e), byref(s), N)\n            self.API_ver = 2\n        except:\n            self.API_ver = 1\n        check_error(e)",
  "def get_model_name(self):\n        if self._model_name is None:\n            N = 32  # make a buffer for the DLL to return a string into\n            s = ctypes.create_string_buffer(N)\n            e = ctypes.c_int()\n            try:\n                seabreeze.seabreeze_get_model(self.index, byref(e), byref(s), N)\n                self.API_ver = 2\n            except:\n                seabreeze.seabreeze_get_spectrometer_type(self.index, byref(e), byref(s), N)\n                self.API_ver = 1\n            check_error(e)\n            self._model_name = s.value.decode('utf-8')\n        return self._model_name",
  "def get_serial_number(self):\n        \"\"\"The spectrometer's serial number.\"\"\"\n        if self._serial_number is None:\n            N = 32  # make a buffer for the DLL to return a string into\n            s = ctypes.create_string_buffer(N)\n            e = ctypes.c_int()\n            seabreeze.seabreeze_get_serial_number(self.index, byref(e), byref(s), N)\n            check_error(e)\n            self._serial_number = s.value.decode('utf-8')\n        return self._serial_number",
  "def get_usb_descriptor(self, id):\n        \"\"\"The spectrometer's USB descriptor\"\"\"\n        N = 32  # make a buffer for the DLL to return a string into\n        s = ctypes.create_string_buffer(N)\n        e = ctypes.c_int()\n        seabreeze.seabreeze_get_usb_descriptor_string(self.index, byref(e), c_int(id), byref(s), N)\n        check_error(e)\n        return s.value.decode('utf-8')",
  "def get_integration_time(self):\n        \"\"\"The current integration time.\n\n        The SeaBreeze API doesn't seem to allow us to get the current integration time, so\n        we work around it by cacheing the last used integration time.  Note that this will\n        return None if you've not set the integration time.\"\"\"\n        if hasattr(self, \"_latest_integration_time\"):\n            return self._latest_integration_time\n        else:\n            return None",
  "def set_integration_time(self, milliseconds):\n        \"\"\"Set the integration time\"\"\"\n        e = ctypes.c_int()\n        if milliseconds < self.minimum_integration_time:\n            raise ValueError(\"Cannot set integration time below %d microseconds\" % self.minimum_integration_time)\n        if self.API_ver == 1:\n            seabreeze.seabreeze_set_integration_time(self.index, byref(e), c_ulong(int(milliseconds * 1000)))\n        if self.API_ver == 2:\n            seabreeze.seabreeze_set_integration_time_microsec(self.index, byref(e), c_ulong(int(milliseconds * 1000)))\n        \n        check_error(e)\n        self._latest_integration_time = milliseconds",
  "def get_minimum_integration_time(self):\n        \"\"\"Minimum allowable value for integration time\"\"\"\n        if self._minimum_integration_time is None:\n            e = ctypes.c_int()\n            if self.API_ver == 1:\n                min_time = seabreeze.seabreeze_get_minimum_integration_time_micros(self.index, byref(e))\n            if self.API_ver == 2:\n                min_time = seabreeze.seabreeze_get_min_integration_time_microsec(self.index, byref(e))   \n            check_error(e)\n            self._minimum_integration_time = min_time / 1000.\n        return self._minimum_integration_time",
  "def get_tec_enable(self):\n        \"\"\"Whether or not the thermo-electric cooler is enabled.\"\"\"\n        try:\n            return self._tec_enabled\n        except OceanOpticsError as error:\n            print(error)\n            print('Most likely raised due to the lack of a tec on this device')",
  "def set_tec_enable(self, state=True):\n        \"\"\"Turn the cooling system on or off.\"\"\"\n        try:\n            e = ctypes.c_int()\n            seabreeze.seabreeze_set_tec_enable(self.index, byref(e), c_int(state))\n            check_error(e)\n            self._tec_enabled = state\n        except OceanOpticsError as error:\n            print(error)\n            print('Most likely raised due to the lack of a tec on this device')",
  "def get_tec_temperature(self):\n        \"\"\"Current temperature.\"\"\"\n        try:\n            e = ctypes.c_int()\n            read_tec_temperature = seabreeze.seabreeze_read_tec_temperature\n            read_tec_temperature.restype = c_double\n            temperature_0 = read_tec_temperature(self.index, byref(e))\n            for i in range(100):\n                temperature = read_tec_temperature(self.index, byref(e))\n                check_error(e)\n                if temperature==temperature_0:\n                    break\n                else:\n                    temperature_0=temperature\n                if i==99:\n                    self.log('Temperature reading inconsitent after 100 attmpets','WARN')\n           \n            return temperature\n        except OceanOpticsError as error:\n            print(error)\n            print('Most likely raised due to the lack of a tec on this device')",
  "def set_tec_temperature(self, temperature):\n        \"\"\"Enable the cooling system and set the temperature\"\"\"\n        try:\n            if not self.enable_tec:\n                self.enable_tec = True\n            e = ctypes.c_int()\n            seabreeze.seabreeze_set_tec_temperature(self.index, byref(e), c_double(temperature))\n            seabreeze.seabreeze_set_tec_enable(self.index, byref(e), 1)\n            check_error(e)\n        except OceanOpticsError as error:\n            print(error)\n            print('Most likely raised due to the lack of a tec on this device')",
  "def read_wavelengths(self):\n        \"\"\"get an array of the wavelengths in nm\"\"\"\n        self._comms_lock.acquire()\n        e = ctypes.c_int()\n        N = seabreeze.seabreeze_get_formatted_spectrum_length(self.index, byref(e))\n        wavelengths_carray = (c_double * N)()  # this should create a c array of doubles, length N\n        seabreeze.seabreeze_get_wavelengths(self.index, byref(e), byref(wavelengths_carray), N)\n        self._comms_lock.release()\n        check_error(e)\n        return np.array(list(wavelengths_carray))",
  "def get_wavelengths(self):\n        \"\"\"Wavelength values for each pixel.\n\n        NB this caches the value so it's only retrieved from the spectrometer once.\"\"\"\n        if self._wavelengths is None:\n            self._wavelengths = self.read_wavelengths()\n        return self._wavelengths",
  "def read_spectrum(self, bundle_metadata=False):\n        \"\"\"Get the current reading from the spectrometer's sensor.\n\n        Acquire a new spectrum and return it.  If bundle_metadata is true, this will be\n        returned as an ArrayWithAttrs, including the current metadata.\"\"\"\n        e = ctypes.c_int()\n        N = seabreeze.seabreeze_get_formatted_spectrum_length(self.index, byref(e))\n        with self._comms_lock:\n            spectrum_carray = (c_double * N)()  # this should create a c array of doubles, length N\n            seabreeze.seabreeze_get_formatted_spectrum(self.index, byref(e), byref(spectrum_carray), N)\n        check_error(e)  # throw an exception if something went wrong\n        new_spectrum = np.array(list(spectrum_carray))\n\n        if bundle_metadata:\n            return ArrayWithAttrs(new_spectrum, attrs=self.metadata)\n        else:\n            return new_spectrum",
  "def get_qt_ui(self, control_only=False, display_only = False):\n        \"\"\"Return a Qt Widget for controlling the spectrometer.\n\n        If control_only is true, this will not contain a graph of the spectrum.\n        \"\"\"\n        if control_only:\n            return OceanOpticsControlUI(self)\n        elif display_only:\n            return SpectrometerDisplayUI(self)\n        else:\n            return SpectrometerUI(self)",
  "def get_control_widget(self):\n        \"\"\"Convenience function \"\"\"\n        return self.get_qt_ui(control_only=True)",
  "def get_preview_widget(self):\n        \"\"\"Convenience function \"\"\"\n        return self.get_qt_ui(display_only=True)",
  "def __init__(self, spectrometer):\n        assert isinstance(spectrometer, OceanOpticsSpectrometer), 'spectrometer must be an OceanOpticsSpectrometer'\n        super(OceanOpticsControlUI, self).__init__(spectrometer,os.path.join(os.path.dirname(__file__),'ocean_optics_controls.ui'))\n#        self.tec_temperature.setValidator(QtGui.QDoubleValidator())\n        # self.tec_temperature.textChanged.connect(self.check_state)\n        # self.tec_temperature.textChanged.connect(self.update_param)\n        # self.tec_temperature.setText(str(spectrometer.tec_temperature))\n        try: \n            self.spectrometer.get_tec_temperature()\n            tec = True\n        except AttributeError as e:\n            print(e, 'removing cooling functionality')\n            tec = False\n        if tec:\n            \n            self.set_tec_temperature_pushButton.clicked.connect(self.gui_set_tec_temperature)\n            self.read_tec_temperature_pushButton.clicked.connect(self.gui_read_tec_tempeature)\n            self.enable_tec.stateChanged.connect(self.update_enable_tec)\n            self.enable_tec.setChecked(self.spectrometer.enable_tec)\n            initial_temperature = np.round(self.spectrometer.tec_temperature, decimals = 1)\n            self.tec_temperature_lcdNumber.display(float(initial_temperature))\n            self.set_tec_temperature_LineEdit.setText(str(initial_temperature))\n            self.update_enable_tec(0) # sometimes helps enable cooling\n            self.update_enable_tec(1)\n        else:\n            self.set_tec_temperature_pushButton.setVisible(False)\n            self.read_tec_temperature_pushButton.setVisible(False)\n            self.enable_tec.setVisible(False)\n            self.tec_temperature_lcdNumber.setVisible(False)\n            self.set_tec_temperature_LineEdit.setVisible(False)",
  "def update_param(self, value):\n        sender = self.sender()\n        if sender.validator() is not None:\n            state = sender.validator().validate(value, 0)[0]\n            if state != QtGui.QValidator.Acceptable:\n                return\n        if sender is self.integration_time:\n            try:\n                self.spectrometer.integration_time = float(value)\n            except ValueError:\n                pass\n        elif sender is self.tec_temperature:\n            try:\n                self.spectrometer.tec_temperature = float(value)\n            except ValueError:\n                pass",
  "def gui_set_tec_temperature(self):\n        self.spectrometer.tec_temperature = float(self.set_tec_temperature_LineEdit.text().strip())",
  "def gui_read_tec_tempeature(self):\n        self.tec_temperature_lcdNumber.display(float(self.spectrometer.tec_temperature))",
  "def update_enable_tec(self, state):\n        if state == QtCore.Qt.Checked:\n            self.spectrometer.enable_tec = True\n        elif state == QtCore.Qt.Unchecked:\n            self.spectrometer.enable_tec = False",
  "class SpectrometerAligner(Instrument):\n#   \n    def __init__(self,spectrometer,stage):\n        super(SpectrometerAligner,self).__init__()\n        self.spectrometer = spectrometer\n        self.stage = stage\n        self.align_to_raw_spectra=False\n        self.settling_time=0.3\n        self.spectrum_mask = None\n        self._action_lock=threading.RLock() \n    def merit_function(self):\n        \"\"\"this is what we optimise\"\"\"\n        spectrum = self.spectrometer.read_spectrum()\n        if not self.align_to_raw_spectra and self.spectrometer.background.shape == spectrum.shape:\n            spectrum -= self.spectrometer.background\n        if self.spectrum_mask is None:\n            return np.nansum(spectrum)\n        else:\n            return np.nansum(spectrum[self.spectrum_mask])\n    def _do_circle_iteration_fired(self):\n        threading.Thread(target=self.iterate_circle,\n                         kwargs=dict(radius=self.step_size,npoints=self.number_of_points)).start()\n    def iterate_circle(self,radius,npoints=3,print_move=True,**kwargs):\n        \"\"\"Move the stage in a circle, taking spectra.  Refine the position.\"\"\"\n        angles = [2*np.pi/float(npoints) * float(i) for i in range(npoints)]\n        points = [np.array([np.cos(a),np.sin(a),0])*radius for a in angles]\n        return self.iterate_on_points(points, include_here=True, print_move=print_move, **kwargs)\n    def iterate_grid(self,stepsize,**kwargs):\n        \"\"\"Move the stage in a 9-point grid and then find the maximum.\"\"\"\n        points = [np.array([i,j,0])*stepsize for i in [-1,0,1] for j in [-1,0,1] if not (i==0 and j==0)]\n        return self.iterate_on_points(points, include_here=True, fit_method=\"maximum\", **kwargs)\n    def _do_focus_iteration_fired(self):\n        threading.Thread(target=self.iterate_z, args=[self.step_size]).start()\n    def iterate_z(self,dz,print_move=True):\n        \"\"\"Move the stage up and down to optimise focus\"\"\"\n        return self.iterate_on_points([np.array([0,0,z]) for z in [-dz,dz]],print_move=print_move)\n    def iterate_on_points(self,points,include_here=True,print_move=True,plot_args={},fit_method=\"centroid\"):\n        \"\"\"Visit the points supplied, and refine our position.\n        \n        The merit function will be evaluated at each point (given in stage\n        units, relative to the current position) and then the stage moved to\n        the centre of mass.  The minimum reading is subtracted to avoid\n        negative values (which mess things up) and speed up convergence.\n        \n        include_here adds the present position as one of the points.  This can\n        help stability if the points passed in are e.g. a circle.\"\"\"\n        #NB we're not bothering with sample coordinates here...\n        self._action_lock.acquire()\n        here = np.array(self.stage.position)\n        positions = [here]\n        powers = [self.merit_function()]\n        for p in points: #iterate through the points and measure the merit function\n            self.stage.move(here+p)\n            time.sleep(self.settling_time)\n            positions.append(self.stage.position)\n            powers.append(self.merit_function())\n        if fit_method==\"parabola\": #parabolic fit: fit a 2D parabola to the data.  More responsive but less stable than centre of mass.\n            try:\n                pos = np.array(positions) - np.mean(positions,axis=0)\n                powers = np.array(powers)\n                mean_position = np.mean(pos, axis=0) #default to no motion, (as the polyfit will fail if there's no motion in one axis) ??should this be positions (measured) or points (specified)?\n                axes_with_motion = np.where(np.std(np.array(points),axis=0)>0)[0] #don't try to fit axes where there's no motion (nb the [0] is necessary because the return value from np.where is a tuple)\n                #model: power = a +b.x + c.<crossterms>\n                N = len(axes_with_motion) #number of axes\n                quadratic = np.ones((powers.shape[0], 2*N + 1))\n                for i, a in enumerate(axes_with_motion):\n                    quadratic[:,i+1] = pos[:,a] #put linear terms in the matrix\n                for i, a in enumerate(axes_with_motion):\n                    quadratic[:,i+1+N] = pos[:,a] #put quadratic terms in the matrix (ignore cross terms for now...)\n                p = np.linalg.lstsq(quadratic, powers)[0] #use least squares to fast-fit a 2D parabola\n                print(\"quadratic fit: \", p)\n                for i, a in enumerate(axes_with_motion):\n                    if p[i+1+N] > 0:\n                        mean_position[a] = np.Inf * p[i+1] #if the parabola is happy/flat, assume we are moving the maximum step\n                        print(\"warning: there is no maximum on axis %d\" % a)\n                    else:\n                        mean_position[a] = old_div(-p[i+1],(2*p[i+N+1])) #if there's a maximum in the fitted curve, assume that's where we should be\n                        print(\"axis %d has a maximum at %.2f\" % (a, mean_position[a]))\n                for i in range(mean_position.shape[0]):\n                    if mean_position[i] > old_div(np.max(pos[:,i]),2): mean_position[i] = old_div(np.max(pos[:,i]),2) #constrain to lie within the positions supplied\n                    if mean_position[i] < old_div(np.min(pos[:,i]),2): mean_position[i] = old_div(np.min(pos[:,i]),2) #so we don't move too far\n                mean_position += np.mean(positions,axis=0)\n            except:\n                print(\"Quadratic fit failed, falling back to centroid.\")\n                fit_method=\"centroid\"\n        if fit_method==\"gaussian\":\n            try:\n                pos = np.array(positions)\n                powers = np.array(powers)\n                mean_position = np.mean(pos, axis=0) #default to no motion, (as the polyfit will fail if there's no motion in one axis) ??should this be positions (measured) or points (specified)?\n                axes_with_motion = np.where(np.std(np.array(points),axis=0)>0)[0] #don't try to fit axes where there's no motion (nb the [0] is necessary because the return value from np.where is a tuple)\n                N = len(axes_with_motion)\n                def error_from_gaussian(p):\n                    gaussian = p[0] + p[1] * np.exp(-np.sum(old_div((pos-p[2:2+N])**2,(2*p[2+N:2+2*N]**2)),axis=1))\n                    return np.mean((powers-gaussian)**2)\n                ret = scipy.optimize.minimize(error_from_gaussian, [0,np.max(powers)]+list(mean_position)+list(np.ones(N)*0.3))\n                print(ret)\n                assert ret.success\n                for i, a in enumerate(axes_with_motion):\n                    mean_position[a] = ret.x[i+2]\n            except:\n                print(\"Gaussian fit failed, falling back to centroid.\")\n                fit_method=\"centroid\"\n        if fit_method==\"centroid\":\n            powers = np.array(powers) - np.min(powers)*1.1+np.max(powers)*0.1 #make sure no powers are <0\n            mean_position = old_div(np.dot(powers, positions),np.sum(powers))\n        if fit_method==\"maximum\":           #go to the brightest point\n            powers = np.array(powers)\n            mean_position = np.array(positions)[powers.argmax(),:]\n                    \n        if print_move:\n            print(\"moving %.3f, %.3f, %.3f\" % tuple(mean_position - here))\n        try:\n            self.stage.move(mean_position)\n        except:\n            print(\"Positions:\\n\",positions)\n            print(\"Powers: \",powers)\n            print(\"Mean Position: \",mean_position)\n        self._action_lock.release()\n        self.plot_alignment(positions, powers, mean_position, **plot_args)\n        return positions, powers, mean_position\n    def optimise(self,tolerance, max_steps=10, stepsize=0.5, npoints=3, dz=0.5,verbose=False):\n        \"\"\"Repeatedly move and take spectra to find the peak.\n        \n        \n        WARNING: it seems a bit unstable at the moment, best consider this \n        \"experimental\" code! The focus has a tendency to wander!\n        \n        Each iteration, we perform iterate_circle(stepsize, npoints) then\n        iterate_z(dz).  The algorithm stops when the distance moved is less\n        than tolerance.  If tolerance is a 3-element numpy array, then a\n        different tolerance is applied to x, y, z: [1,1,1] is equivalent to a \n        tolerance of 1, as the comparison is sum(dx**2/tolerance**2) < 1.0\n        \"\"\"\n        self._action_lock.acquire()\n        positions = [np.array(self.stage.position)]\n        powers = [self.merit_function()]\n        for i in range(max_steps):\n            pos = self.iterate_circle(stepsize,npoints, print_move=verbose)[2]\n            pos = self.iterate_z(dz, print_move=verbose)[2]\n            positions.append(pos)\n            powers.append(self.merit_function())\n            if np.sum(old_div((positions[-1] - positions[-2])**2, tolerance**2)) <= 1.0:\n                break\n            else:\n                time.sleep(self.settling_time)\n        if verbose: print(\"performed %d iterations\" % (len(positions)-1))\n        self._action_lock.release()\n        self.plot_alignment(positions, powers, [np.NaN,np.NaN])\n        return positions, powers\n    def _do_XY_optimisation_fired(self):\n        threading.Thread(target=self.optimise_2D,args=[self.tolerance], kwargs=dict(stepsize=self.step_size, npoints = self.number_of_points)).start()\n    def optimise_2D(self, tolerance=0.03, max_steps=10, stepsize=0.2, npoints=3, print_move=True,reduce_integration_time = True):\n        \"\"\"repeatedly move and take spectra to find the peak\n        \n        we run iterate_circle until the movement produced is small enough.\"\"\"\n        if reduce_integration_time == True:\n            start_expo =self.spectrometer.integration_time\n            self.spectrometer.integration_time = start_expo/3.0\n        self._action_lock.acquire()\n        positions = [np.array(self.stage.position)]\n        powers = [self.merit_function()]\n        for i in range(max_steps):\n            #pos = self.iterate_circle(stepsize,npoints,print_move,plot_args={'color':\"blue\",'cla':(i==0)})[2]\n            pos = self.iterate_grid(stepsize,print_move=print_move,plot_args={'color':\"blue\",'cla':(i==0)})[2]\n            positions.append(pos)\n            powers.append(self.merit_function())\n            if np.sqrt(np.sum((positions[-1] - positions[-2])**2)) < tolerance:\n                break\n        print(\"performed %d iterations\" % (len(positions)-1))\n        self._action_lock.release()\n        self.plot_alignment(positions, powers, [np.NaN,np.NaN], cla=False, fade=False, color=\"green\")\n        if reduce_integration_time == True:\n            self.spectrometer.integration_time = start_expo\n        return positions, powers\n    def z_scan(self, dz = np.arange(-4,4,0.4)):\n        \"\"\"Take spectra at (relative) z positions dz and return as a 2D array\"\"\"\n        spectra = []\n        here = self.stage.position\n        self.spectrometer.read_spectrum()\n        self.spectrometer.read_spectrum() #reads spectrum trice to clear cached junk before taking measurement\n        for z in dz:\n            self.stage.move(np.array([0,0,z])+here)\n            time.sleep(self.settling_time)\n            spectra.append(self.spectrometer.read_spectrum())\n        self.stage.move(here)\n        return ArrayWithAttrs(spectra, attrs=self.spectrometer.metadata)\n    def plot_alignment(self,positions, powers, mean_position, cla=True, fade=True, **kwargs):\n        \"\"\"plot an alignment so we can see how it went\"\"\"\n        pass",
  "def fit_parabola(positions, powers, *args):\n    positions = np.array(positions)\n    powers = np.array(powers)\n    mean_position = np.mean(positions,axis=0) #default to no motion, (as the polyfit will fail if there's no motion in one axis) ??should this be positions (measured) or points (specified)?\n    axes_with_motion = np.where(np.std(positions,axis=0)>0)[0] #don't try to fit axes where there's no motion (nb the [0] is necessary because the return value from np.where is a tuple)\n    #model: power = a +b.x + c.<crossterms>\n    N = len(axes_with_motion) #number of axes\n    quadratic = np.ones((powers.shape[0], 2*N + 1))\n    for i, a in enumerate(axes_with_motion):\n        quadratic[:,i+1] = positions[:,a] #put linear terms in the matrix\n    for i, a in enumerate(axes_with_motion):\n        quadratic[:,i+1+N] = positions[:,a] #put quadratic terms in the matrix (ignore cross terms for now...)\n    p = np.linalg.lstsq(quadratic, powers)[0] #use least squares to fast-fit a 2D parabola\n    for i, a in enumerate(axes_with_motion):\n        if p[i+1+N] > 0:\n            mean_position[a] = np.Inf * p[i+1] #if the parabola is happy/flat, assume we are moving the maximum step\n        else:\n            mean_position[a] = old_div(-p[i+1],(2*p[i+N+1])) #if there's a maximum in the fitted curve, assume that's where we should be\n    for i in range(mean_position.shape[0]):\n        if mean_position[i] > np.max(positions[:,i]): mean_position[i] = np.max(positions[:,i]) #constrain to lie within the positions supplied\n        if mean_position[i] < np.min(positions[:,i]): mean_position[i] = np.min(positions[:,i]) #so we don't move too far\n    return mean_position - np.mean(positions,axis=0)",
  "def plot_alignment(positions, powers, mean_position):\n    x = [p[0] for p in positions]\n    y = [p[1] for p in positions]\n    powers = np.array(powers)\n    s = old_div(powers,powers.max()) * 20\n    plt.scatter(x,y,s=s)\n    plt.plot([mean_position[0]],[mean_position[1]], 'r+')\n    plt.show(block=False)",
  "def __init__(self,spectrometer,stage):\n        super(SpectrometerAligner,self).__init__()\n        self.spectrometer = spectrometer\n        self.stage = stage\n        self.align_to_raw_spectra=False\n        self.settling_time=0.3\n        self.spectrum_mask = None\n        self._action_lock=threading.RLock()",
  "def merit_function(self):\n        \"\"\"this is what we optimise\"\"\"\n        spectrum = self.spectrometer.read_spectrum()\n        if not self.align_to_raw_spectra and self.spectrometer.background.shape == spectrum.shape:\n            spectrum -= self.spectrometer.background\n        if self.spectrum_mask is None:\n            return np.nansum(spectrum)\n        else:\n            return np.nansum(spectrum[self.spectrum_mask])",
  "def _do_circle_iteration_fired(self):\n        threading.Thread(target=self.iterate_circle,\n                         kwargs=dict(radius=self.step_size,npoints=self.number_of_points)).start()",
  "def iterate_circle(self,radius,npoints=3,print_move=True,**kwargs):\n        \"\"\"Move the stage in a circle, taking spectra.  Refine the position.\"\"\"\n        angles = [2*np.pi/float(npoints) * float(i) for i in range(npoints)]\n        points = [np.array([np.cos(a),np.sin(a),0])*radius for a in angles]\n        return self.iterate_on_points(points, include_here=True, print_move=print_move, **kwargs)",
  "def iterate_grid(self,stepsize,**kwargs):\n        \"\"\"Move the stage in a 9-point grid and then find the maximum.\"\"\"\n        points = [np.array([i,j,0])*stepsize for i in [-1,0,1] for j in [-1,0,1] if not (i==0 and j==0)]\n        return self.iterate_on_points(points, include_here=True, fit_method=\"maximum\", **kwargs)",
  "def _do_focus_iteration_fired(self):\n        threading.Thread(target=self.iterate_z, args=[self.step_size]).start()",
  "def iterate_z(self,dz,print_move=True):\n        \"\"\"Move the stage up and down to optimise focus\"\"\"\n        return self.iterate_on_points([np.array([0,0,z]) for z in [-dz,dz]],print_move=print_move)",
  "def iterate_on_points(self,points,include_here=True,print_move=True,plot_args={},fit_method=\"centroid\"):\n        \"\"\"Visit the points supplied, and refine our position.\n        \n        The merit function will be evaluated at each point (given in stage\n        units, relative to the current position) and then the stage moved to\n        the centre of mass.  The minimum reading is subtracted to avoid\n        negative values (which mess things up) and speed up convergence.\n        \n        include_here adds the present position as one of the points.  This can\n        help stability if the points passed in are e.g. a circle.\"\"\"\n        #NB we're not bothering with sample coordinates here...\n        self._action_lock.acquire()\n        here = np.array(self.stage.position)\n        positions = [here]\n        powers = [self.merit_function()]\n        for p in points: #iterate through the points and measure the merit function\n            self.stage.move(here+p)\n            time.sleep(self.settling_time)\n            positions.append(self.stage.position)\n            powers.append(self.merit_function())\n        if fit_method==\"parabola\": #parabolic fit: fit a 2D parabola to the data.  More responsive but less stable than centre of mass.\n            try:\n                pos = np.array(positions) - np.mean(positions,axis=0)\n                powers = np.array(powers)\n                mean_position = np.mean(pos, axis=0) #default to no motion, (as the polyfit will fail if there's no motion in one axis) ??should this be positions (measured) or points (specified)?\n                axes_with_motion = np.where(np.std(np.array(points),axis=0)>0)[0] #don't try to fit axes where there's no motion (nb the [0] is necessary because the return value from np.where is a tuple)\n                #model: power = a +b.x + c.<crossterms>\n                N = len(axes_with_motion) #number of axes\n                quadratic = np.ones((powers.shape[0], 2*N + 1))\n                for i, a in enumerate(axes_with_motion):\n                    quadratic[:,i+1] = pos[:,a] #put linear terms in the matrix\n                for i, a in enumerate(axes_with_motion):\n                    quadratic[:,i+1+N] = pos[:,a] #put quadratic terms in the matrix (ignore cross terms for now...)\n                p = np.linalg.lstsq(quadratic, powers)[0] #use least squares to fast-fit a 2D parabola\n                print(\"quadratic fit: \", p)\n                for i, a in enumerate(axes_with_motion):\n                    if p[i+1+N] > 0:\n                        mean_position[a] = np.Inf * p[i+1] #if the parabola is happy/flat, assume we are moving the maximum step\n                        print(\"warning: there is no maximum on axis %d\" % a)\n                    else:\n                        mean_position[a] = old_div(-p[i+1],(2*p[i+N+1])) #if there's a maximum in the fitted curve, assume that's where we should be\n                        print(\"axis %d has a maximum at %.2f\" % (a, mean_position[a]))\n                for i in range(mean_position.shape[0]):\n                    if mean_position[i] > old_div(np.max(pos[:,i]),2): mean_position[i] = old_div(np.max(pos[:,i]),2) #constrain to lie within the positions supplied\n                    if mean_position[i] < old_div(np.min(pos[:,i]),2): mean_position[i] = old_div(np.min(pos[:,i]),2) #so we don't move too far\n                mean_position += np.mean(positions,axis=0)\n            except:\n                print(\"Quadratic fit failed, falling back to centroid.\")\n                fit_method=\"centroid\"\n        if fit_method==\"gaussian\":\n            try:\n                pos = np.array(positions)\n                powers = np.array(powers)\n                mean_position = np.mean(pos, axis=0) #default to no motion, (as the polyfit will fail if there's no motion in one axis) ??should this be positions (measured) or points (specified)?\n                axes_with_motion = np.where(np.std(np.array(points),axis=0)>0)[0] #don't try to fit axes where there's no motion (nb the [0] is necessary because the return value from np.where is a tuple)\n                N = len(axes_with_motion)\n                def error_from_gaussian(p):\n                    gaussian = p[0] + p[1] * np.exp(-np.sum(old_div((pos-p[2:2+N])**2,(2*p[2+N:2+2*N]**2)),axis=1))\n                    return np.mean((powers-gaussian)**2)\n                ret = scipy.optimize.minimize(error_from_gaussian, [0,np.max(powers)]+list(mean_position)+list(np.ones(N)*0.3))\n                print(ret)\n                assert ret.success\n                for i, a in enumerate(axes_with_motion):\n                    mean_position[a] = ret.x[i+2]\n            except:\n                print(\"Gaussian fit failed, falling back to centroid.\")\n                fit_method=\"centroid\"\n        if fit_method==\"centroid\":\n            powers = np.array(powers) - np.min(powers)*1.1+np.max(powers)*0.1 #make sure no powers are <0\n            mean_position = old_div(np.dot(powers, positions),np.sum(powers))\n        if fit_method==\"maximum\":           #go to the brightest point\n            powers = np.array(powers)\n            mean_position = np.array(positions)[powers.argmax(),:]\n                    \n        if print_move:\n            print(\"moving %.3f, %.3f, %.3f\" % tuple(mean_position - here))\n        try:\n            self.stage.move(mean_position)\n        except:\n            print(\"Positions:\\n\",positions)\n            print(\"Powers: \",powers)\n            print(\"Mean Position: \",mean_position)\n        self._action_lock.release()\n        self.plot_alignment(positions, powers, mean_position, **plot_args)\n        return positions, powers, mean_position",
  "def optimise(self,tolerance, max_steps=10, stepsize=0.5, npoints=3, dz=0.5,verbose=False):\n        \"\"\"Repeatedly move and take spectra to find the peak.\n        \n        \n        WARNING: it seems a bit unstable at the moment, best consider this \n        \"experimental\" code! The focus has a tendency to wander!\n        \n        Each iteration, we perform iterate_circle(stepsize, npoints) then\n        iterate_z(dz).  The algorithm stops when the distance moved is less\n        than tolerance.  If tolerance is a 3-element numpy array, then a\n        different tolerance is applied to x, y, z: [1,1,1] is equivalent to a \n        tolerance of 1, as the comparison is sum(dx**2/tolerance**2) < 1.0\n        \"\"\"\n        self._action_lock.acquire()\n        positions = [np.array(self.stage.position)]\n        powers = [self.merit_function()]\n        for i in range(max_steps):\n            pos = self.iterate_circle(stepsize,npoints, print_move=verbose)[2]\n            pos = self.iterate_z(dz, print_move=verbose)[2]\n            positions.append(pos)\n            powers.append(self.merit_function())\n            if np.sum(old_div((positions[-1] - positions[-2])**2, tolerance**2)) <= 1.0:\n                break\n            else:\n                time.sleep(self.settling_time)\n        if verbose: print(\"performed %d iterations\" % (len(positions)-1))\n        self._action_lock.release()\n        self.plot_alignment(positions, powers, [np.NaN,np.NaN])\n        return positions, powers",
  "def _do_XY_optimisation_fired(self):\n        threading.Thread(target=self.optimise_2D,args=[self.tolerance], kwargs=dict(stepsize=self.step_size, npoints = self.number_of_points)).start()",
  "def optimise_2D(self, tolerance=0.03, max_steps=10, stepsize=0.2, npoints=3, print_move=True,reduce_integration_time = True):\n        \"\"\"repeatedly move and take spectra to find the peak\n        \n        we run iterate_circle until the movement produced is small enough.\"\"\"\n        if reduce_integration_time == True:\n            start_expo =self.spectrometer.integration_time\n            self.spectrometer.integration_time = start_expo/3.0\n        self._action_lock.acquire()\n        positions = [np.array(self.stage.position)]\n        powers = [self.merit_function()]\n        for i in range(max_steps):\n            #pos = self.iterate_circle(stepsize,npoints,print_move,plot_args={'color':\"blue\",'cla':(i==0)})[2]\n            pos = self.iterate_grid(stepsize,print_move=print_move,plot_args={'color':\"blue\",'cla':(i==0)})[2]\n            positions.append(pos)\n            powers.append(self.merit_function())\n            if np.sqrt(np.sum((positions[-1] - positions[-2])**2)) < tolerance:\n                break\n        print(\"performed %d iterations\" % (len(positions)-1))\n        self._action_lock.release()\n        self.plot_alignment(positions, powers, [np.NaN,np.NaN], cla=False, fade=False, color=\"green\")\n        if reduce_integration_time == True:\n            self.spectrometer.integration_time = start_expo\n        return positions, powers",
  "def z_scan(self, dz = np.arange(-4,4,0.4)):\n        \"\"\"Take spectra at (relative) z positions dz and return as a 2D array\"\"\"\n        spectra = []\n        here = self.stage.position\n        self.spectrometer.read_spectrum()\n        self.spectrometer.read_spectrum() #reads spectrum trice to clear cached junk before taking measurement\n        for z in dz:\n            self.stage.move(np.array([0,0,z])+here)\n            time.sleep(self.settling_time)\n            spectra.append(self.spectrometer.read_spectrum())\n        self.stage.move(here)\n        return ArrayWithAttrs(spectra, attrs=self.spectrometer.metadata)",
  "def plot_alignment(self,positions, powers, mean_position, cla=True, fade=True, **kwargs):\n        \"\"\"plot an alignment so we can see how it went\"\"\"\n        pass",
  "def error_from_gaussian(p):\n                    gaussian = p[0] + p[1] * np.exp(-np.sum(old_div((pos-p[2:2+N])**2,(2*p[2+N:2+2*N]**2)),axis=1))\n                    return np.mean((powers-gaussian)**2)",
  "class SpectrumRenderer(FigureRenderer):\n    def __init__(self, h5group, parent=None):\n        super(SpectrumRenderer, self).__init__(h5group, parent)\n        self.wavelength = h5group['wavelength']\n        self.spectrum = h5group['spectrum']\n\n    def display_data(self):\n        ax = self.fig.add_subplot(111)\n        ax.plot(self.wavelength, self.spectrum)\n        ax.set_xlabel('wavelength (nm)')\n        self.fig.canvas.draw()\n\n    @classmethod\n    def is_suitable(cls, h5object):\n        if not isinstance(h5object, h5py.Group):\n            return -1\n        if 'wavelength' in h5object and 'spectrum' in h5object:\n            if len(h5object['spectrum'].shape == 1):\n                return 3\n            elif len(h5object['spectrum'].shape > 1):\n                return 2",
  "class MultiSpectrumRenderer(FigureRenderer):\n    def __init__(self, h5group, parent=None):\n        super(MultiSpectrumRenderer, self).__init__(h5group, parent)\n        self.wavelength = h5group['wavelength']\n        self.spectrum = h5group['spectrum']\n        self.wavelength2 = h5group['wavelength2']\n        self.spectrum2 = h5group['spectrum2']\n\n    def display_data(self):\n        ax = self.fig.add_subplot(111)\n        ax.plot(self.wavelength, self.spectrum)\n        ax = ax.twinx()\n        ax.plot(self.wavelength2, self.spectrum2)\n        ax.set_xlabel('wavelength (nm)')\n        self.fig.canvas.draw()\n\n    @classmethod\n    def is_suitable(cls, h5object):\n        if not isinstance(h5object, h5py.Group):\n            return -1\n        if 'wavelength2' in h5object and 'spectrum2' in h5object:\n            if len(h5object['spectrum2'].shape == 1):\n                return 5\n            elif len(h5object['spectrum2'].shape > 1):\n                return 4\n        elif 'wavelength' in h5object and 'spectrum' in h5object:\n            if len(h5object['spectrum'].shape == 1):\n                return 3\n            elif len(h5object['spectrum'].shape > 1):\n                return 2",
  "def __init__(self, h5group, parent=None):\n        super(SpectrumRenderer, self).__init__(h5group, parent)\n        self.wavelength = h5group['wavelength']\n        self.spectrum = h5group['spectrum']",
  "def display_data(self):\n        ax = self.fig.add_subplot(111)\n        ax.plot(self.wavelength, self.spectrum)\n        ax.set_xlabel('wavelength (nm)')\n        self.fig.canvas.draw()",
  "def is_suitable(cls, h5object):\n        if not isinstance(h5object, h5py.Group):\n            return -1\n        if 'wavelength' in h5object and 'spectrum' in h5object:\n            if len(h5object['spectrum'].shape == 1):\n                return 3\n            elif len(h5object['spectrum'].shape > 1):\n                return 2",
  "def __init__(self, h5group, parent=None):\n        super(MultiSpectrumRenderer, self).__init__(h5group, parent)\n        self.wavelength = h5group['wavelength']\n        self.spectrum = h5group['spectrum']\n        self.wavelength2 = h5group['wavelength2']\n        self.spectrum2 = h5group['spectrum2']",
  "def display_data(self):\n        ax = self.fig.add_subplot(111)\n        ax.plot(self.wavelength, self.spectrum)\n        ax = ax.twinx()\n        ax.plot(self.wavelength2, self.spectrum2)\n        ax.set_xlabel('wavelength (nm)')\n        self.fig.canvas.draw()",
  "def is_suitable(cls, h5object):\n        if not isinstance(h5object, h5py.Group):\n            return -1\n        if 'wavelength2' in h5object and 'spectrum2' in h5object:\n            if len(h5object['spectrum2'].shape == 1):\n                return 5\n            elif len(h5object['spectrum2'].shape > 1):\n                return 4\n        elif 'wavelength' in h5object and 'spectrum' in h5object:\n            if len(h5object['spectrum'].shape == 1):\n                return 3\n            elif len(h5object['spectrum'].shape > 1):\n                return 2",
  "class Shamdor(Andor):\n    ''' Wrapper class for the shamrock and the andor\n    '''\n\n    def __init__(self, pixel_number=1600,\n                 pixel_width=16,\n                 use_shifts=False, \n                 laser_wl=632.8,\n                 white_shutter=None):\n        self.shamrock = Shamrock()\n        self.shamrock.pixel_number = pixel_number\n        self.shamrock.pixel_width = pixel_width\n        self.use_shifts = use_shifts\n        self.laser_wl = laser_wl\n        self.white_shutter = white_shutter\n        super(Shamdor, self).__init__()\n        self.metadata_property_names += ('slit_width', 'wavelengths')\n    \n    def get_x_axis(self, use_shifts=None):\n        if self.use_shifts and use_shifts in (None, True):\n            \n            wavelengths = np.array(self.shamrock.GetCalibration()[::-1])\n            return ( 1./(self.laser_wl*1e-9)- 1./(wavelengths*1e-9))/100    \n        else:\n            return self.shamrock.GetCalibration()[::-1]\n    x_axis = property(get_x_axis)\n    \n    @property\n    def slit_width(self):\n        return self.shamrock.slit_width\n    \n    @property \n    def wavelengths(self):\n        return self.get_x_axis(use_shifts=False)",
  "def Capture(_AndorUI):\n    if _AndorUI.Andor.white_shutter is not None:\n        isopen = _AndorUI.Andor.white_shutter.is_open()\n       \n        if isopen:\n            _AndorUI.Andor.white_shutter.close_shutter()\n        _AndorUI.Andor.raw_image(update_latest_frame=True)\n        if isopen:\n            _AndorUI.Andor.white_shutter.open_shutter()\n    else:\n        _AndorUI.Andor.raw_image(update_latest_frame=True)",
  "def __init__(self, pixel_number=1600,\n                 pixel_width=16,\n                 use_shifts=False, \n                 laser_wl=632.8,\n                 white_shutter=None):\n        self.shamrock = Shamrock()\n        self.shamrock.pixel_number = pixel_number\n        self.shamrock.pixel_width = pixel_width\n        self.use_shifts = use_shifts\n        self.laser_wl = laser_wl\n        self.white_shutter = white_shutter\n        super(Shamdor, self).__init__()\n        self.metadata_property_names += ('slit_width', 'wavelengths')",
  "def get_x_axis(self, use_shifts=None):\n        if self.use_shifts and use_shifts in (None, True):\n            \n            wavelengths = np.array(self.shamrock.GetCalibration()[::-1])\n            return ( 1./(self.laser_wl*1e-9)- 1./(wavelengths*1e-9))/100    \n        else:\n            return self.shamrock.GetCalibration()[::-1]",
  "def slit_width(self):\n        return self.shamrock.slit_width",
  "def wavelengths(self):\n        return self.get_x_axis(use_shifts=False)",
  "class Kymera(Instrument):\n    def __init__(self):\n        super(Kymera,self).__init__()\n        #for Windows\n        architecture = platform.architecture()\n\n        self.dll = CDLL(r\"C:\\Program Files\\Andor SDK\\ATSpectrograph\\64\\atspectrograph.dll\")\n\n        error = self.dll.ATSpectrographInitialize(\"\")#(byref(tekst))\n        self.current_kymera = 0 #for more than one kymera this has to be varied, see KymeraGetNumberDevices\n        self._logger.setLevel('WARNING')\n        \n    def verbose(self, error, function=''):\n        self.log( \"[%s]: %s\" %(function, error), level='info')\n    \n    #basic Kymera features    \n    def Initialize(self):\n        error = self.dll.ATSpectrographInitialize(\"\")\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n    \n    def GetNumberDevices(self):\n        no_kymeras = c_int()\n        error = self.dll.ATSpectrographGetNumberDevices(byref(no_kymeras))\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n        return no_kymeras.value\n    num_kymeras = property(GetNumberDevices)   \n    \n    def Close(self):\n        error = self.dll.ATSpectrographClose()\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n\n    \n    def GetSerialNumber(self):\n        ATSpectrographSN = c_char()\n        error = self.dll.ATSpectrographGetSerialNumber(self.current_kymera, byref(ATSpectrographSN))\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n        return ATSpectrographSN\n    serial_number = property(GetSerialNumber)\n    \n    \n    def EepromGetOpticalParams(self):\n        self.FocalLength = c_float()\n        self.AngularDeviation = c_float()\n        self.FocalTilt = c_float()\n        error = self.dll.ATSpectrographEepromGetOpticalParams(self.current_kymera, byref(self.FocalLength), byref(self.AngularDeviation), byref(self.FocalTilt))\n        return {'FocalLength':self.FocalLength,'AngularDeviation':self.AngularDeviation,'FocalTilt':self.FocalTilt}\n        \n    #basic Grating features\n    def GratingIsPresent(self):\n        is_present = c_int()\n        error = self.dll.ATSpectrographGratingIsPresent(self.current_kymera,is_present)\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n        return is_present.vlaue\n    grating_present = property(GratingIsPresent)\n    \n    \n    def GetTurret(self):\n        Turret = c_int()\n        error = self.dll.ATSpectrographGetTurret(self.current_kymera,byref(Turret))\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n        return Turret.value\n    def SetTurret(self,turret):\n        error = self.dll.ATSpectrographSetTurret(self.current_kymera,c_int(turret))\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n    \n    turret_position = NotifiedProperty(GetTurret,SetTurret)\n    \n    def GetNumberGratings(self):\n        self.noGratings = c_int()\n        error = self.dll.ATSpectrographGetNumberGratings(self.current_kymera,byref(self.noGratings))\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n        return self.noGratings\n    num_gratings = property(GetNumberGratings)\n\n    \n    def GetGrating(self):\n        grating = c_int()\n        error = self.dll.ATSpectrographGetGrating(self.current_kymera,byref(grating))\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n        return grating.value\n    def SetGrating(self,grating_num):\n        grating_num = int(grating_num)\n        grating = c_int(grating_num)\n        error = self.dll.ATSpectrographSetGrating(self.current_kymera,grating)\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n    current_grating = NotifiedProperty(GetGrating,SetGrating)    \n    def GetGratingInfo(self):    \n        lines = c_float()\n        blaze = c_char()\n        home = c_int()                \n        offset = c_int()        \n        error = self.dll.ATSpectrographGetGratingInfo(self.current_kymera,self.current_grating,byref(lines),byref(blaze),byref(home),byref(offset))\n        CurrGratingInfo = [lines.value,blaze.value,home.value,offset.value]\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n        return CurrGratingInfo\n    GratingInfo = property(GetGratingInfo)\n    \n    def GetGratingOffset(self):\n        GratingOffset = c_int() #not this is in steps, so int\n        error = self.dll.ATSpectrographGetGratingOffset(self.current_kymera,self.current_grating,byref(GratingOffset))\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n        return GratingOffset\n    def SetGratingOffset(self,offset):\n        error = self.dll.ATSpectrographSetGratingOffset(self.current_kymera,self.current_grating,c_int(offset))\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n    Grating_offset = NotifiedProperty(GetGratingOffset,SetGratingOffset)\n    \n    def GetDetectorOffset(self):\n        DetectorOffset = c_int() #note this is in steps, so int\n        #error = self.dll.ShamrockGetDetectorOffset(self.current_kymera,byref(self.DetectorOffset))\n        error = self.dll.ATSpectrographGetDetectorOffset(self.current_kymera,byref(DetectorOffset))\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n        return DetectorOffset.value\n    def SetDetectorOffset(self,offset):\n        error = self.dll.ATSpectrographSetDetectorOffset(self.current_kymera,self.current_grating,c_int(offset))\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n    \n    detector_offset = NotifiedProperty(GetDetectorOffset,SetDetectorOffset)\n        \n\n    \n    #Wavelength features\n    def WavelengthIsPresent(self):\n        ispresent = c_int()\n        error = self.dll.ATSpectrographWavelengthIsPresent(self.current_kymera,byref(ispresent))\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n        return ispresent.value\n    motor_present = property(WavelengthIsPresent)\n        \n    def GetWavelength(self):\n        curr_wave = c_float()\n        error = self.dll.ATSpectrographGetWavelength(self.current_kymera,byref(curr_wave))\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n        return curr_wave.value\n    def SetWavelength(self,centre_wl):\n        error = self.dll.ATSpectrographSetWavelength(self.current_kymera,c_float(centre_wl))\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n        \n    center_wavelength = NotifiedProperty(GetWavelength,SetWavelength)  \n      \n    def AtZeroOrder(self):\n        is_at_zero = c_int()\n        error = self.dll.ATSpectrographAtZeroOrder(self.current_kymera,byref(is_at_zero))\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n        return is_at_zero.value\n    wavelength_is_zero = property(AtZeroOrder)  \n    \n    def GetWavelengthLimits(self):\n        min_wl = c_float()\n        max_wl = c_float()      \n        error = self.dll.ATSpectrographGetWavelengthLimits(self.current_kymera,self.current_grating,byref(min_wl),byref(max_wl))\n        wl_limits = [min_wl.value, max_wl.value]\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n        return wl_limits\n    wavelength_limits = property(GetWavelengthLimits)\n        \n\n    \n    def GotoZeroOrder(self):\n        error = self.dll.ATSpectrographGotoZeroOrder(self.current_kymera)\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n    \n    #Slit functions\n    def AutoSlitIsPresent(self):\n        present = c_int()\n        slits = []        \n    \n        for i in range(1,5):\n            self.dll.ATSpectrographAutoSlitIsPresent(self.current_kymera,i,present)\n            slits.append(present.value)\n        return slits\n    Autoslits = property(AutoSlitIsPresent)\n            \n    #Sets the slit to the default value (10um)\n    def AutoSlitReset(self,slit):\n        error = self.dll.ATSpectrographAutoSlitReset(self.current_kymera,self.current_slit)\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n\n    \n    #finds if input slit is present\n    def SlitIsPresent(self):\n        slit_present = c_int()\n        error = self.dll.ATSpectrographSlitIsPresent(self.current_kymera,byref(slit_present))\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n        return slit_present.value\n    slit_present = property(SlitIsPresent)\n    \n    #Output Slits\n    def GetAutoSlitWidth(self,slit):\n        slitw = c_float()\n        error = self.dll.ATSpectrographGetAutoSlitWidth(self.current_kymera,slit,byref(slitw))\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n        return slitw.value\n        \n    def SetAutoSlitWidth(self,slit,width):\n        slit_w = c_float(width)      \n        error = self.dll.ATSpectrographSetAutoSlitWidth(self.current_kymera,slit_w)\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n        return width\n    \n    #Input Slits\n    def GetSlit(self):\n        slitw = c_float()\n        error = self.dll.ATSpectrographGetSlitWidth(self.current_kymera,c_ulong(1),byref(slitw))\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n        return slitw.value\n    \n    def SetSlit(self,width):\n        slit_w = c_float(width)\n        error = self.dll.ATSpectrographSetSlitWidth(self.current_kymera,c_ulong(1),slit_w)\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n    slit_width = NotifiedProperty(GetSlit,SetSlit)\n    \n    def SlitReset(self):\n        error = self.dll.ATSpectrographSlitReset(self.current_kymera)\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n\n        \n    #Calibration functions\n    def SetPixelWidth(self,width):\n        error = self.dll.ATSpectrographSetPixelWidth(self.current_kymera,c_float(width))\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n    \n    def GetPixelWidth(self):\n        pixelw = c_float()\n        error = self.dll.ATSpectrographGetPixelWidth(self.current_kymera,byref(pixelw))\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n        return pixelw.value\n    pixel_width = NotifiedProperty(GetPixelWidth,SetPixelWidth)\n    \n    def GetNumberPixels(self):\n        numpix = c_int()\n        error = self.dll.ATSpectrographGetNumberPixels(self.current_kymera,byref(numpix))\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n        return numpix.value\n    \n    def SetNumberPixels(self,pixels):\n        error = self.dll.ATSpectrographSetNumberPixels(self.current_kymera,pixels)\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n    pixel_number = NotifiedProperty(GetNumberPixels,SetNumberPixels)\n    \n    def GetCalibration(self):\n        ccalib = c_float*self.pixel_number\n        ccalib_array = ccalib()\n        error = self.dll.ATSpectrographGetCalibration(self.current_kymera, pointer(ccalib_array), self.pixel_number)\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n        calib = []        \n        for i in range(len(ccalib_array)):\n            calib.append(ccalib_array[i])\n        return calib[:]\n    wl_calibration = property(GetCalibration)     \n    \n    def GetPixelCalibrationCoefficients(self):\n        ca = c_float()\n        cb = c_float()\n        cc = c_float()\n        cd = c_float()\n        error = self.dll.ATSpectrographGetPixelCalibrationCoefficients(self.current_kymera,byref(ca),byref(cb),byref(cc),byref(cd))\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n        return [ca,cb,cc,cd]\n    PixelCalibrationCoefficients = property(GetPixelCalibrationCoefficients)\n        \n    def get_qt_ui(self):\n        return KymeraControlUI(self)",
  "class KymeraLegacy(Instrument):\n    '''This is for use with the older shamrock drivers - works with 32bit PCs and windows <10'''\n    def __init__(self):\n        super(Kymera,self).__init__()\n        #for Windows\n        architecture = platform.architecture()\n\n        if architecture[0] == \"64bit\":\n            self.dll2 = CDLL(\"C:\\\\Program Files\\\\Andor SDK\\\\Shamrock64\\\\atshamrock\")#\"C:\\\\Program Files\\\\Andor SOLIS\\\\Drivers\\\\Shamrock64\\\\atshamrock\")\n            self.dll = CDLL(\"C:\\\\Program Files\\\\Andor SDK\\\\Shamrock64\\\\ShamrockCif\")#C:\\\\Program Files\\\\Andor SOLIS\\\\Drivers\\\\Shamrock64\\\\ShamrockCIF\")\n            tekst = c_char()\n            error = self.dll.ShamrockInitialize(byref(tekst))\n\n        elif architecture[0] == \"32bit\":\n            self.dll2 = WinDLL(\"C:\\\\Program Files\\\\Andor SDK\\\\Shamrock\\\\atshamrock.dll\")\n            self.dll = WinDLL(\"C:\\\\Program Files\\\\Andor SDK\\\\Shamrock\\\\ShamrockCIF.dll\")\n            tekst = c_char_p(\"\")     \n            error = self.dll.ShamrockInitialize(tekst)\n            \n        self.current_shamrock = 0 #for more than one Shamrock this has to be varied, see ShamrockGetNumberDevices\n        self.center_wavelength = 0.0\n\n    def verbose(self, error, function=''):\n        self.log( \"[%s]: %s\" %(function, error),level = 'info')\n    \n    #basic Shamrock features    \n    def Initialize(self):\n        error = self.dll.ShamrockInitialize(\"\")\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n    \n    def GetNumberDevices(self):\n        no_shamrocks = c_int()\n        error = self.dll.ShamrockGetNumberDevices(byref(no_shamrocks))\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n        return no_shamrocks.value\n    num_shamrocks = property(GetNumberDevices)   \n    \n    def Close(self):\n        error = self.dll.ShamrockClose()\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n\n    \n    def GetSerialNumber(self):\n        ShamrockSN = c_char()\n        error = self.dll.ShamrockGetSerialNumber(self.current_shamrock, byref(ShamrockSN))\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n        return ShamrockSN\n    serial_number = property(GetSerialNumber)\n    \n    \n    def EepromGetOpticalParams(self):\n        self.FocalLength = c_float()\n        self.AngularDeviation = c_float()\n        self.FocalTilt = c_float()\n        error = self.dll.ShamrockEepromGetOpticalParams(self.current_shamrock, byref(self.FocalLength), byref(self.AngularDeviation), byref(self.FocalTilt))\n        return {'FocalLength':self.FocalLength,'AngularDeviation':self.AngularDeviation,'FocalTilt':self.FocalTilt}\n        \n    #basic Grating features\n    def GratingIsPresent(self):\n        is_present = c_int()\n        error = self.dll.ShamrockGratingIsPresent(self.current_shamrock,is_present)\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n        return is_present.vlaue\n    grating_present = property(GratingIsPresent)\n    \n    \n    def GetTurret(self):\n        Turret = c_int()\n        error = self.dll.ShamrockGetTurret(self.current_shamrock,byref(Turret))\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n        return Turret.value\n    def SetTurret(self,turret):\n        error = self.dll.ShamrockSetTurret(self.current_shamrock,c_int(turret))\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n    \n    turret_position = NotifiedProperty(GetTurret,SetTurret)\n    \n    def GetNumberGratings(self):\n        self.noGratings = c_int()\n        error = self.dll.ShamrockGetNumberGratings(self.current_shamrock,byref(self.noGratings))\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n        return self.noGratings\n    num_gratings = property(GetNumberGratings)\n\n    \n    def GetGrating(self):\n        grating = c_int()\n        error = self.dll.ShamrockGetGrating(self.current_shamrock,byref(grating))\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n        return grating.value\n    def SetGrating(self,grating_num):\n        grating_num = int(grating_num)\n        grating = c_int(grating_num)\n        error = self.dll.ShamrockSetGrating(self.current_shamrock,grating)\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n    current_grating = NotifiedProperty(GetGrating,SetGrating)    \n    def GetGratingInfo(self):    \n        lines = c_float()\n        blaze = c_char()\n        home = c_int()                \n        offset = c_int()        \n        error = self.dll.ShamrockGetGratingInfo(self.current_shamrock,self.current_grating,byref(lines),byref(blaze),byref(home),byref(offset))\n        CurrGratingInfo = [lines.value,blaze.value,home.value,offset.value]\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n        return CurrGratingInfo\n    GratingInfo = property(GetGratingInfo)\n    \n    def GetGratingOffset(self):\n        GratingOffset = c_int() #not this is in steps, so int\n        error = self.dll.ShamrockGetGratingOffset(self.current_shamrock,self.current_grating,byref(GratingOffset))\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n        return GratingOffset\n    def SetGratingOffset(self,offset):\n        error = self.dll.ShamrockSetGratingOffset(self.current_shamrock,self.current_grating,c_int(offset))\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n    Grating_offset = NotifiedProperty(GetGratingOffset,SetGratingOffset)\n    \n    def GetDetectorOffset(self):\n        DetectorOffset = c_int() #note this is in steps, so int\n        #error = self.dll.ShamrockGetDetectorOffset(self.current_shamrock,byref(self.DetectorOffset))\n        error = self.dll.ShamrockGetDetectorOffset(self.current_shamrock,byref(DetectorOffset))\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n        return DetectorOffset.value\n    def SetDetectorOffset(self,offset):\n        error = self.dll.ShamrockSetDetectorOffset(self.current_shamrock,self.current_grating,c_int(offset))\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n    \n    detector_offset = NotifiedProperty(GetDetectorOffset,SetDetectorOffset)\n        \n    #Wavelength features\n    def WavelengthIsPresent(self):\n        ispresent = c_int()\n        error = self.dll.ShamrockWavelengthIsPresent(self.current_shamrock,byref(ispresent))\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n        return ispresent.value\n    motor_present = property(WavelengthIsPresent)\n        \n    def GetWavelength(self):\n        curr_wave = c_float()\n        error = self.dll.ShamrockGetWavelength(self.current_shamrock,byref(curr_wave))\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n        return curr_wave.value\n    def SetWavelength(self,centre_wl):\n        error = self.dll.ShamrockSetWavelength(self.current_shamrock,c_float(centre_wl))\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n\n    center_wavelength = NotifiedProperty(GetWavelength,SetWavelength)  \n      \n    def AtZeroOrder(self):\n        is_at_zero = c_int()\n        error = self.dll.ShamrockAtZeroOrder(self.current_shamrock,byref(is_at_zero))\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n        return is_at_zero.value\n    wavelength_is_zero = property(AtZeroOrder)  \n    \n    def GetWavelengthLimits(self):\n        min_wl = c_float()\n        max_wl = c_float()      \n        error = self.dll.ShamrockGetWavelengthLimits(self.current_shamrock,self.current_grating,byref(min_wl),byref(max_wl))\n        wl_limits = [min_wl.value, max_wl.value]\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n        return wl_limits\n    wavelength_limits = property(GetWavelengthLimits)\n    \n    def GotoZeroOrder(self):\n        error = self.dll.ShamrockGotoZeroOrder(self.current_shamrock)\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n    \n    #Slit functions\n    def AutoSlitIsPresent(self):\n        present = c_int()\n        slits = []        \n    \n        for i in range(1,5):\n            self.dll.ShamrockAutoSlitIsPresent(self.current_shamrock,i,present)\n            slits.append(present.value)\n        return slits\n    Autoslits = property(AutoSlitIsPresent)\n            \n    #Sets the slit to the default value (10um)\n    def AutoSlitReset(self,slit):\n        error = self.dll.ShamrockAutoSlitReset(self.current_shamrock,self.current_slit)\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n\n    \n    #finds if input slit is present\n    def SlitIsPresent(self):\n        slit_present = c_int()\n        error = self.dll.ShamrockSlitIsPresent(self.current_shamrock,byref(slit_present))\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n        return slit_present.value\n    slit_present = property(SlitIsPresent)\n    \n    #Output Slits\n    def GetAutoSlitWidth(self,slit):\n        slitw = c_float()\n        error = self.dll.ShamrockGetAutoSlitWidth(self.current_shamrock,slit,byref(slitw))\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n        return slitw.value\n        \n    def SetAutoSlitWidth(self,slit,width):\n        slit_w = c_float(width)        \n        error = self.dll.ShamrockSetAutoSlitWidth(self.current_shamrock,slit,slit_w)\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n        return width\n    \n    #Input Slits\n    def GetSlit(self):\n        slitw = c_float()\n        error = self.dll.ShamrockGetSlit(self.current_shamrock,byref(slitw))\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n        return slitw.value\n    \n    def SetSlit(self,width):\n        slit_w = c_float(width)\n        error = self.dll.ShamrockSetSlit(self.current_shamrock,slit_w)\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n    slit_width = NotifiedProperty(GetSlit,SetSlit)\n    \n    def SlitReset(self):\n        error = self.dll.ShamrockSlitReset(self.current_shamrock)\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n\n        \n    #Calibration functions\n    def SetPixelWidth(self,width):\n        error = self.dll.ShamrockSetPixelWidth(self.current_shamrock,c_float(width))\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n    \n    def GetPixelWidth(self):\n        pixelw = c_float()\n        error = self.dll.ShamrockGetPixelWidth(self.current_shamrock,byref(pixelw))\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n        return pixelw.value\n    pixel_width = NotifiedProperty(GetPixelWidth,SetPixelWidth)\n    \n    def GetNumberPixels(self):\n        numpix = c_int()\n        error = self.dll.ShamrockGetNumberPixels(self.current_shamrock,byref(numpix))\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n        return numpix.value\n    \n    def SetNumberPixels(self,pixels):\n        error = self.dll.ShamrockSetNumberPixels(self.current_shamrock,pixels)\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n    pixel_number = NotifiedProperty(GetNumberPixels,SetNumberPixels)\n    \n    def GetCalibration(self):\n        ccalib = c_float*self.pixel_number\n        ccalib_array = ccalib()\n        error = self.dll.ShamrockGetCalibration(self.current_shamrock,pointer(ccalib_array),self.pixel_number)\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n        calib = []        \n        for i in range(len(ccalib_array)):\n            calib.append(ccalib_array[i])\n        return calib[:]\n    wl_calibration = property(GetCalibration)     \n    \n    def GetPixelCalibrationCoefficients(self):\n        ca = c_float()\n        cb = c_float()\n        cc = c_float()\n        cd = c_float()\n        error = self.dll.ShamrockGetPixelCalibrationCoefficients(self.current_shamrock,byref(ca),byref(cb),byref(cc),byref(cd))\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n        return [ca,cb,cc,cd]\n    PixelCalibrationCoefficients = property(GetPixelCalibrationCoefficients)\n        \n    def get_qt_ui(self):\n        return KymeraControlUI(self)",
  "class KymeraControlUI(QtWidgets.QWidget,UiTools):\n    def __init__(self, kymera, ui_file =os.path.join(os.path.dirname(__file__),'kymera.ui'),  parent=None):\n        assert isinstance(kymera, Kymera), \"instrument must be a Triax\"\n        super(KymeraControlUI, self).__init__()\n        uic.loadUi(ui_file, self)\n        self.kymera = kymera\n        self.centre_wl_lineEdit.returnPressed.connect(self.set_wl_gui)\n        self.slit_lineEdit.returnPressed.connect(self.set_slit_gui)     \n        self.centre_wl_lineEdit.setText(str(self.kymera.center_wavelength))\n        self.slit_lineEdit.setText(str(self.kymera.slit_width))\n        # eval('self.grating_'+str(self.kymera.current_grating)+'_radioButton.setChecked(True)')\n        for radio_button in [1, 2, 3]:\n            eval('self.grating_'+str(radio_button)+'_radioButton.clicked.connect(self.set_grating_gui)')\n        getattr(self, f'grating_{self.kymera.current_grating}_radioButton').setChecked(True)\n    def set_wl_gui(self):\n        self.kymera.center_wavelength = float(self.centre_wl_lineEdit.text().strip())\n    def set_slit_gui(self):\n        self.kymera.slit_width = float(self.slit_lineEdit.text().strip())\n    def set_grating_gui(self):\n        s = self.sender()\n        if s is self.grating_1_radioButton:\n            self.kymera.current_grating = 1\n        elif s is self.grating_2_radioButton:\n            self.kymera.current_grating = 2\n        elif s is self.grating_3_radioButton:\n            self.kymera.current_grating = 3\n        else:\n            raise ValueError('radio buttons not connected!')",
  "def main():\n    \n    app = get_qt_app()\n    s = Kymera() \n    ui = KymeraControlUI(kymera=s)\n    ui.show()\n    sys.exit(app.exec_())",
  "def __init__(self):\n        super(Kymera,self).__init__()\n        #for Windows\n        architecture = platform.architecture()\n\n        self.dll = CDLL(r\"C:\\Program Files\\Andor SDK\\ATSpectrograph\\64\\atspectrograph.dll\")\n\n        error = self.dll.ATSpectrographInitialize(\"\")#(byref(tekst))\n        self.current_kymera = 0 #for more than one kymera this has to be varied, see KymeraGetNumberDevices\n        self._logger.setLevel('WARNING')",
  "def verbose(self, error, function=''):\n        self.log( \"[%s]: %s\" %(function, error), level='info')",
  "def Initialize(self):\n        error = self.dll.ATSpectrographInitialize(\"\")\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)",
  "def GetNumberDevices(self):\n        no_kymeras = c_int()\n        error = self.dll.ATSpectrographGetNumberDevices(byref(no_kymeras))\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n        return no_kymeras.value",
  "def Close(self):\n        error = self.dll.ATSpectrographClose()\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)",
  "def GetSerialNumber(self):\n        ATSpectrographSN = c_char()\n        error = self.dll.ATSpectrographGetSerialNumber(self.current_kymera, byref(ATSpectrographSN))\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n        return ATSpectrographSN",
  "def EepromGetOpticalParams(self):\n        self.FocalLength = c_float()\n        self.AngularDeviation = c_float()\n        self.FocalTilt = c_float()\n        error = self.dll.ATSpectrographEepromGetOpticalParams(self.current_kymera, byref(self.FocalLength), byref(self.AngularDeviation), byref(self.FocalTilt))\n        return {'FocalLength':self.FocalLength,'AngularDeviation':self.AngularDeviation,'FocalTilt':self.FocalTilt}",
  "def GratingIsPresent(self):\n        is_present = c_int()\n        error = self.dll.ATSpectrographGratingIsPresent(self.current_kymera,is_present)\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n        return is_present.vlaue",
  "def GetTurret(self):\n        Turret = c_int()\n        error = self.dll.ATSpectrographGetTurret(self.current_kymera,byref(Turret))\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n        return Turret.value",
  "def SetTurret(self,turret):\n        error = self.dll.ATSpectrographSetTurret(self.current_kymera,c_int(turret))\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)",
  "def GetNumberGratings(self):\n        self.noGratings = c_int()\n        error = self.dll.ATSpectrographGetNumberGratings(self.current_kymera,byref(self.noGratings))\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n        return self.noGratings",
  "def GetGrating(self):\n        grating = c_int()\n        error = self.dll.ATSpectrographGetGrating(self.current_kymera,byref(grating))\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n        return grating.value",
  "def SetGrating(self,grating_num):\n        grating_num = int(grating_num)\n        grating = c_int(grating_num)\n        error = self.dll.ATSpectrographSetGrating(self.current_kymera,grating)\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)",
  "def GetGratingInfo(self):    \n        lines = c_float()\n        blaze = c_char()\n        home = c_int()                \n        offset = c_int()        \n        error = self.dll.ATSpectrographGetGratingInfo(self.current_kymera,self.current_grating,byref(lines),byref(blaze),byref(home),byref(offset))\n        CurrGratingInfo = [lines.value,blaze.value,home.value,offset.value]\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n        return CurrGratingInfo",
  "def GetGratingOffset(self):\n        GratingOffset = c_int() #not this is in steps, so int\n        error = self.dll.ATSpectrographGetGratingOffset(self.current_kymera,self.current_grating,byref(GratingOffset))\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n        return GratingOffset",
  "def SetGratingOffset(self,offset):\n        error = self.dll.ATSpectrographSetGratingOffset(self.current_kymera,self.current_grating,c_int(offset))\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)",
  "def GetDetectorOffset(self):\n        DetectorOffset = c_int() #note this is in steps, so int\n        #error = self.dll.ShamrockGetDetectorOffset(self.current_kymera,byref(self.DetectorOffset))\n        error = self.dll.ATSpectrographGetDetectorOffset(self.current_kymera,byref(DetectorOffset))\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n        return DetectorOffset.value",
  "def SetDetectorOffset(self,offset):\n        error = self.dll.ATSpectrographSetDetectorOffset(self.current_kymera,self.current_grating,c_int(offset))\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)",
  "def WavelengthIsPresent(self):\n        ispresent = c_int()\n        error = self.dll.ATSpectrographWavelengthIsPresent(self.current_kymera,byref(ispresent))\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n        return ispresent.value",
  "def GetWavelength(self):\n        curr_wave = c_float()\n        error = self.dll.ATSpectrographGetWavelength(self.current_kymera,byref(curr_wave))\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n        return curr_wave.value",
  "def SetWavelength(self,centre_wl):\n        error = self.dll.ATSpectrographSetWavelength(self.current_kymera,c_float(centre_wl))\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)",
  "def AtZeroOrder(self):\n        is_at_zero = c_int()\n        error = self.dll.ATSpectrographAtZeroOrder(self.current_kymera,byref(is_at_zero))\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n        return is_at_zero.value",
  "def GetWavelengthLimits(self):\n        min_wl = c_float()\n        max_wl = c_float()      \n        error = self.dll.ATSpectrographGetWavelengthLimits(self.current_kymera,self.current_grating,byref(min_wl),byref(max_wl))\n        wl_limits = [min_wl.value, max_wl.value]\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n        return wl_limits",
  "def GotoZeroOrder(self):\n        error = self.dll.ATSpectrographGotoZeroOrder(self.current_kymera)\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)",
  "def AutoSlitIsPresent(self):\n        present = c_int()\n        slits = []        \n    \n        for i in range(1,5):\n            self.dll.ATSpectrographAutoSlitIsPresent(self.current_kymera,i,present)\n            slits.append(present.value)\n        return slits",
  "def AutoSlitReset(self,slit):\n        error = self.dll.ATSpectrographAutoSlitReset(self.current_kymera,self.current_slit)\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)",
  "def SlitIsPresent(self):\n        slit_present = c_int()\n        error = self.dll.ATSpectrographSlitIsPresent(self.current_kymera,byref(slit_present))\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n        return slit_present.value",
  "def GetAutoSlitWidth(self,slit):\n        slitw = c_float()\n        error = self.dll.ATSpectrographGetAutoSlitWidth(self.current_kymera,slit,byref(slitw))\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n        return slitw.value",
  "def SetAutoSlitWidth(self,slit,width):\n        slit_w = c_float(width)      \n        error = self.dll.ATSpectrographSetAutoSlitWidth(self.current_kymera,slit_w)\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n        return width",
  "def GetSlit(self):\n        slitw = c_float()\n        error = self.dll.ATSpectrographGetSlitWidth(self.current_kymera,c_ulong(1),byref(slitw))\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n        return slitw.value",
  "def SetSlit(self,width):\n        slit_w = c_float(width)\n        error = self.dll.ATSpectrographSetSlitWidth(self.current_kymera,c_ulong(1),slit_w)\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)",
  "def SlitReset(self):\n        error = self.dll.ATSpectrographSlitReset(self.current_kymera)\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)",
  "def SetPixelWidth(self,width):\n        error = self.dll.ATSpectrographSetPixelWidth(self.current_kymera,c_float(width))\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)",
  "def GetPixelWidth(self):\n        pixelw = c_float()\n        error = self.dll.ATSpectrographGetPixelWidth(self.current_kymera,byref(pixelw))\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n        return pixelw.value",
  "def GetNumberPixels(self):\n        numpix = c_int()\n        error = self.dll.ATSpectrographGetNumberPixels(self.current_kymera,byref(numpix))\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n        return numpix.value",
  "def SetNumberPixels(self,pixels):\n        error = self.dll.ATSpectrographSetNumberPixels(self.current_kymera,pixels)\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)",
  "def GetCalibration(self):\n        ccalib = c_float*self.pixel_number\n        ccalib_array = ccalib()\n        error = self.dll.ATSpectrographGetCalibration(self.current_kymera, pointer(ccalib_array), self.pixel_number)\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n        calib = []        \n        for i in range(len(ccalib_array)):\n            calib.append(ccalib_array[i])\n        return calib[:]",
  "def GetPixelCalibrationCoefficients(self):\n        ca = c_float()\n        cb = c_float()\n        cc = c_float()\n        cd = c_float()\n        error = self.dll.ATSpectrographGetPixelCalibrationCoefficients(self.current_kymera,byref(ca),byref(cb),byref(cc),byref(cd))\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n        return [ca,cb,cc,cd]",
  "def get_qt_ui(self):\n        return KymeraControlUI(self)",
  "def __init__(self):\n        super(Kymera,self).__init__()\n        #for Windows\n        architecture = platform.architecture()\n\n        if architecture[0] == \"64bit\":\n            self.dll2 = CDLL(\"C:\\\\Program Files\\\\Andor SDK\\\\Shamrock64\\\\atshamrock\")#\"C:\\\\Program Files\\\\Andor SOLIS\\\\Drivers\\\\Shamrock64\\\\atshamrock\")\n            self.dll = CDLL(\"C:\\\\Program Files\\\\Andor SDK\\\\Shamrock64\\\\ShamrockCif\")#C:\\\\Program Files\\\\Andor SOLIS\\\\Drivers\\\\Shamrock64\\\\ShamrockCIF\")\n            tekst = c_char()\n            error = self.dll.ShamrockInitialize(byref(tekst))\n\n        elif architecture[0] == \"32bit\":\n            self.dll2 = WinDLL(\"C:\\\\Program Files\\\\Andor SDK\\\\Shamrock\\\\atshamrock.dll\")\n            self.dll = WinDLL(\"C:\\\\Program Files\\\\Andor SDK\\\\Shamrock\\\\ShamrockCIF.dll\")\n            tekst = c_char_p(\"\")     \n            error = self.dll.ShamrockInitialize(tekst)\n            \n        self.current_shamrock = 0 #for more than one Shamrock this has to be varied, see ShamrockGetNumberDevices\n        self.center_wavelength = 0.0",
  "def verbose(self, error, function=''):\n        self.log( \"[%s]: %s\" %(function, error),level = 'info')",
  "def Initialize(self):\n        error = self.dll.ShamrockInitialize(\"\")\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)",
  "def GetNumberDevices(self):\n        no_shamrocks = c_int()\n        error = self.dll.ShamrockGetNumberDevices(byref(no_shamrocks))\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n        return no_shamrocks.value",
  "def Close(self):\n        error = self.dll.ShamrockClose()\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)",
  "def GetSerialNumber(self):\n        ShamrockSN = c_char()\n        error = self.dll.ShamrockGetSerialNumber(self.current_shamrock, byref(ShamrockSN))\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n        return ShamrockSN",
  "def EepromGetOpticalParams(self):\n        self.FocalLength = c_float()\n        self.AngularDeviation = c_float()\n        self.FocalTilt = c_float()\n        error = self.dll.ShamrockEepromGetOpticalParams(self.current_shamrock, byref(self.FocalLength), byref(self.AngularDeviation), byref(self.FocalTilt))\n        return {'FocalLength':self.FocalLength,'AngularDeviation':self.AngularDeviation,'FocalTilt':self.FocalTilt}",
  "def GratingIsPresent(self):\n        is_present = c_int()\n        error = self.dll.ShamrockGratingIsPresent(self.current_shamrock,is_present)\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n        return is_present.vlaue",
  "def GetTurret(self):\n        Turret = c_int()\n        error = self.dll.ShamrockGetTurret(self.current_shamrock,byref(Turret))\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n        return Turret.value",
  "def SetTurret(self,turret):\n        error = self.dll.ShamrockSetTurret(self.current_shamrock,c_int(turret))\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)",
  "def GetNumberGratings(self):\n        self.noGratings = c_int()\n        error = self.dll.ShamrockGetNumberGratings(self.current_shamrock,byref(self.noGratings))\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n        return self.noGratings",
  "def GetGrating(self):\n        grating = c_int()\n        error = self.dll.ShamrockGetGrating(self.current_shamrock,byref(grating))\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n        return grating.value",
  "def SetGrating(self,grating_num):\n        grating_num = int(grating_num)\n        grating = c_int(grating_num)\n        error = self.dll.ShamrockSetGrating(self.current_shamrock,grating)\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)",
  "def GetGratingInfo(self):    \n        lines = c_float()\n        blaze = c_char()\n        home = c_int()                \n        offset = c_int()        \n        error = self.dll.ShamrockGetGratingInfo(self.current_shamrock,self.current_grating,byref(lines),byref(blaze),byref(home),byref(offset))\n        CurrGratingInfo = [lines.value,blaze.value,home.value,offset.value]\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n        return CurrGratingInfo",
  "def GetGratingOffset(self):\n        GratingOffset = c_int() #not this is in steps, so int\n        error = self.dll.ShamrockGetGratingOffset(self.current_shamrock,self.current_grating,byref(GratingOffset))\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n        return GratingOffset",
  "def SetGratingOffset(self,offset):\n        error = self.dll.ShamrockSetGratingOffset(self.current_shamrock,self.current_grating,c_int(offset))\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)",
  "def GetDetectorOffset(self):\n        DetectorOffset = c_int() #note this is in steps, so int\n        #error = self.dll.ShamrockGetDetectorOffset(self.current_shamrock,byref(self.DetectorOffset))\n        error = self.dll.ShamrockGetDetectorOffset(self.current_shamrock,byref(DetectorOffset))\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n        return DetectorOffset.value",
  "def SetDetectorOffset(self,offset):\n        error = self.dll.ShamrockSetDetectorOffset(self.current_shamrock,self.current_grating,c_int(offset))\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)",
  "def WavelengthIsPresent(self):\n        ispresent = c_int()\n        error = self.dll.ShamrockWavelengthIsPresent(self.current_shamrock,byref(ispresent))\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n        return ispresent.value",
  "def GetWavelength(self):\n        curr_wave = c_float()\n        error = self.dll.ShamrockGetWavelength(self.current_shamrock,byref(curr_wave))\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n        return curr_wave.value",
  "def SetWavelength(self,centre_wl):\n        error = self.dll.ShamrockSetWavelength(self.current_shamrock,c_float(centre_wl))\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)",
  "def AtZeroOrder(self):\n        is_at_zero = c_int()\n        error = self.dll.ShamrockAtZeroOrder(self.current_shamrock,byref(is_at_zero))\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n        return is_at_zero.value",
  "def GetWavelengthLimits(self):\n        min_wl = c_float()\n        max_wl = c_float()      \n        error = self.dll.ShamrockGetWavelengthLimits(self.current_shamrock,self.current_grating,byref(min_wl),byref(max_wl))\n        wl_limits = [min_wl.value, max_wl.value]\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n        return wl_limits",
  "def GotoZeroOrder(self):\n        error = self.dll.ShamrockGotoZeroOrder(self.current_shamrock)\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)",
  "def AutoSlitIsPresent(self):\n        present = c_int()\n        slits = []        \n    \n        for i in range(1,5):\n            self.dll.ShamrockAutoSlitIsPresent(self.current_shamrock,i,present)\n            slits.append(present.value)\n        return slits",
  "def AutoSlitReset(self,slit):\n        error = self.dll.ShamrockAutoSlitReset(self.current_shamrock,self.current_slit)\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)",
  "def SlitIsPresent(self):\n        slit_present = c_int()\n        error = self.dll.ShamrockSlitIsPresent(self.current_shamrock,byref(slit_present))\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n        return slit_present.value",
  "def GetAutoSlitWidth(self,slit):\n        slitw = c_float()\n        error = self.dll.ShamrockGetAutoSlitWidth(self.current_shamrock,slit,byref(slitw))\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n        return slitw.value",
  "def SetAutoSlitWidth(self,slit,width):\n        slit_w = c_float(width)        \n        error = self.dll.ShamrockSetAutoSlitWidth(self.current_shamrock,slit,slit_w)\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n        return width",
  "def GetSlit(self):\n        slitw = c_float()\n        error = self.dll.ShamrockGetSlit(self.current_shamrock,byref(slitw))\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n        return slitw.value",
  "def SetSlit(self,width):\n        slit_w = c_float(width)\n        error = self.dll.ShamrockSetSlit(self.current_shamrock,slit_w)\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)",
  "def SlitReset(self):\n        error = self.dll.ShamrockSlitReset(self.current_shamrock)\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)",
  "def SetPixelWidth(self,width):\n        error = self.dll.ShamrockSetPixelWidth(self.current_shamrock,c_float(width))\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)",
  "def GetPixelWidth(self):\n        pixelw = c_float()\n        error = self.dll.ShamrockGetPixelWidth(self.current_shamrock,byref(pixelw))\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n        return pixelw.value",
  "def GetNumberPixels(self):\n        numpix = c_int()\n        error = self.dll.ShamrockGetNumberPixels(self.current_shamrock,byref(numpix))\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n        return numpix.value",
  "def SetNumberPixels(self,pixels):\n        error = self.dll.ShamrockSetNumberPixels(self.current_shamrock,pixels)\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)",
  "def GetCalibration(self):\n        ccalib = c_float*self.pixel_number\n        ccalib_array = ccalib()\n        error = self.dll.ShamrockGetCalibration(self.current_shamrock,pointer(ccalib_array),self.pixel_number)\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n        calib = []        \n        for i in range(len(ccalib_array)):\n            calib.append(ccalib_array[i])\n        return calib[:]",
  "def GetPixelCalibrationCoefficients(self):\n        ca = c_float()\n        cb = c_float()\n        cc = c_float()\n        cd = c_float()\n        error = self.dll.ShamrockGetPixelCalibrationCoefficients(self.current_shamrock,byref(ca),byref(cb),byref(cc),byref(cd))\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n        return [ca,cb,cc,cd]",
  "def get_qt_ui(self):\n        return KymeraControlUI(self)",
  "def __init__(self, kymera, ui_file =os.path.join(os.path.dirname(__file__),'kymera.ui'),  parent=None):\n        assert isinstance(kymera, Kymera), \"instrument must be a Triax\"\n        super(KymeraControlUI, self).__init__()\n        uic.loadUi(ui_file, self)\n        self.kymera = kymera\n        self.centre_wl_lineEdit.returnPressed.connect(self.set_wl_gui)\n        self.slit_lineEdit.returnPressed.connect(self.set_slit_gui)     \n        self.centre_wl_lineEdit.setText(str(self.kymera.center_wavelength))\n        self.slit_lineEdit.setText(str(self.kymera.slit_width))\n        # eval('self.grating_'+str(self.kymera.current_grating)+'_radioButton.setChecked(True)')\n        for radio_button in [1, 2, 3]:\n            eval('self.grating_'+str(radio_button)+'_radioButton.clicked.connect(self.set_grating_gui)')\n        getattr(self, f'grating_{self.kymera.current_grating}_radioButton').setChecked(True)",
  "def set_wl_gui(self):\n        self.kymera.center_wavelength = float(self.centre_wl_lineEdit.text().strip())",
  "def set_slit_gui(self):\n        self.kymera.slit_width = float(self.slit_lineEdit.text().strip())",
  "def set_grating_gui(self):\n        s = self.sender()\n        if s is self.grating_1_radioButton:\n            self.kymera.current_grating = 1\n        elif s is self.grating_2_radioButton:\n            self.kymera.current_grating = 2\n        elif s is self.grating_3_radioButton:\n            self.kymera.current_grating = 3\n        else:\n            raise ValueError('radio buttons not connected!')",
  "class SpectrometerAligner(Instrument):\n#    spectrum_mask=None #a mask to set which pixels to align to\n#    align_to_raw_spectra=False\n#    spectrometer=None\n#    stage=None\n#    settling_time=Float(0.3)\n#    step_size=Range(0.01,100.,0.5)\n#    tolerance=Range(0.01,10.,0.05)\n#    number_of_points = Range(2,20,5)\n#    do_circle_iteration = Button()\n#    do_focus_iteration = Button()\n#    do_XY_optimisation = Button()\n#    figure = Instance(Figure, ())\n#    last_alignment_positions = Array(shape=(3,None),dtype=np.float)\n#    last_alignment_powers = Array(shape=(None,),dtype=np.float)\n#    \n#    traits_view = View(\n#                    Tabbed(\n#                        VGroup(\n#                            Item(name=\"settling_time\"),\n#                            Item(name=\"step_size\"),\n#                            HGroup(\n#                                Item(name=\"do_circle_iteration\",show_label=False),\n#                                Item(name=\"do_focus_iteration\",show_label=False),\n#                            ),\n#                            Item(name=\"tolerance\"),\n#                            Item(name=\"do_XY_optimisation\",show_label=False),\n#                            label=\"Controls\",\n#                        ),\n#                        Item('figure', editor=MPLFigureEditor(),\n#                               show_label=False, label=\"Last Alignment\"),\n#                    ),\n#                    resizable=True, title=\"Spectrometer Aligner\",\n#                )\n    def __init__(self,spectrometer,stage):\n        super(SpectrometerAligner,self).__init__()\n        self.spectrometer = spectrometer\n        self.stage = stage\n        self.align_to_raw_spectra=False\n        self.settling_time=0.3\n        self.spectrum_mask = None\n#        self.step_size=Range(0.01,100.,0.5)\n#        self.tolerance=Range(0.01,10.,0.05)\n#        self.number_of_points = Range(2,20,5)\n#        self.figure = \n#        self.figure.add_subplot(111)\n        self._action_lock=threading.RLock() #reentrant lock, so that it doesn't matter that both optimise, and iterate_points (which it calls) acquire the lock\n#        self._plot_data = ArrayPlotData(xpos=[],ypos=[])\n#        self.plot = Plot(self._plot_data)\n#        self.plot.plot(\"xpos\",\"ypos\",type=\"scatter\",color=\"red\")\n#        self.plot.plot((\"across\",\"middle\"),color=\"yellow\")\n#        self.plot.plot((\"middle\",\"across\"),color=\"yellow\")\n    def merit_function(self):\n        \"\"\"this is what we optimise\"\"\"\n        spectrum = self.spectrometer.read_spectrum()\n        if not self.align_to_raw_spectra and self.spectrometer.background.shape == spectrum.shape:\n            spectrum -= self.spectrometer.background\n        if self.spectrum_mask is None:\n            return np.nansum(spectrum)\n        else:\n            return np.nansum(spectrum[self.spectrum_mask])\n    def _do_circle_iteration_fired(self):\n        threading.Thread(target=self.iterate_circle,\n                         kwargs=dict(radius=self.step_size,npoints=self.number_of_points)).start()\n    def iterate_circle(self,radius,npoints=3,print_move=True,**kwargs):\n        \"\"\"Move the stage in a circle, taking spectra.  Refine the position.\"\"\"\n        angles = [2*np.pi/float(npoints) * float(i) for i in range(npoints)]\n        points = [np.array([np.cos(a),np.sin(a),0])*radius for a in angles]\n        return self.iterate_on_points(points, include_here=True, print_move=print_move, **kwargs)\n    def iterate_grid(self,stepsize,**kwargs):\n        \"\"\"Move the stage in a 9-point grid and then find the maximum.\"\"\"\n        points = [np.array([i,j,0])*stepsize for i in [-1,0,1] for j in [-1,0,1] if not (i==0 and j==0)]\n        return self.iterate_on_points(points, include_here=True, fit_method=\"maximum\", **kwargs)\n    def _do_focus_iteration_fired(self):\n        threading.Thread(target=self.iterate_z, args=[self.step_size]).start()\n    def iterate_z(self,dz,print_move=True):\n        \"\"\"Move the stage up and down to optimise focus\"\"\"\n        return self.iterate_on_points([np.array([0,0,z]) for z in [-dz,dz]],print_move=print_move)\n    def iterate_on_points(self,points,include_here=True,print_move=True,plot_args={},fit_method=\"centroid\"):\n        \"\"\"Visit the points supplied, and refine our position.\n        \n        The merit function will be evaluated at each point (given in stage\n        units, relative to the current position) and then the stage moved to\n        the centre of mass.  The minimum reading is subtracted to avoid\n        negative values (which mess things up) and speed up convergence.\n        \n        include_here adds the present position as one of the points.  This can\n        help stability if the points passed in are e.g. a circle.\"\"\"\n        #NB we're not bothering with sample coordinates here...\n        self._action_lock.acquire()\n        here = np.array(self.stage.position)\n        positions = [here]\n        powers = [self.merit_function()]\n        for p in points: #iterate through the points and measure the merit function\n            self.stage.move(here+p)\n            time.sleep(self.settling_time)\n            positions.append(self.stage.position)\n            powers.append(self.merit_function())\n        if fit_method==\"parabola\": #parabolic fit: fit a 2D parabola to the data.  More responsive but less stable than centre of mass.\n            try:\n                pos = np.array(positions) - np.mean(positions,axis=0)\n                powers = np.array(powers)\n                mean_position = np.mean(pos, axis=0) #default to no motion, (as the polyfit will fail if there's no motion in one axis) ??should this be positions (measured) or points (specified)?\n                axes_with_motion = np.where(np.std(np.array(points),axis=0)>0)[0] #don't try to fit axes where there's no motion (nb the [0] is necessary because the return value from np.where is a tuple)\n                #model: power = a +b.x + c.<crossterms>\n                N = len(axes_with_motion) #number of axes\n                quadratic = np.ones((powers.shape[0], 2*N + 1))\n                for i, a in enumerate(axes_with_motion):\n                    quadratic[:,i+1] = pos[:,a] #put linear terms in the matrix\n                for i, a in enumerate(axes_with_motion):\n                    quadratic[:,i+1+N] = pos[:,a] #put quadratic terms in the matrix (ignore cross terms for now...)\n                p = np.linalg.lstsq(quadratic, powers)[0] #use least squares to fast-fit a 2D parabola\n                print(\"quadratic fit: \", p)\n                for i, a in enumerate(axes_with_motion):\n                    if p[i+1+N] > 0:\n                        mean_position[a] = np.Inf * p[i+1] #if the parabola is happy/flat, assume we are moving the maximum step\n                        print(\"warning: there is no maximum on axis %d\" % a)\n                    else:\n                        mean_position[a] = old_div(-p[i+1],(2*p[i+N+1])) #if there's a maximum in the fitted curve, assume that's where we should be\n                        print(\"axis %d has a maximum at %.2f\" % (a, mean_position[a]))\n                for i in range(mean_position.shape[0]):\n                    if mean_position[i] > old_div(np.max(pos[:,i]),2): mean_position[i] = old_div(np.max(pos[:,i]),2) #constrain to lie within the positions supplied\n                    if mean_position[i] < old_div(np.min(pos[:,i]),2): mean_position[i] = old_div(np.min(pos[:,i]),2) #so we don't move too far\n                mean_position += np.mean(positions,axis=0)\n            except:\n                print(\"Quadratic fit failed, falling back to centroid.\")\n                fit_method=\"centroid\"\n        if fit_method==\"gaussian\":\n            try:\n                pos = np.array(positions)\n                powers = np.array(powers)\n                mean_position = np.mean(pos, axis=0) #default to no motion, (as the polyfit will fail if there's no motion in one axis) ??should this be positions (measured) or points (specified)?\n                axes_with_motion = np.where(np.std(np.array(points),axis=0)>0)[0] #don't try to fit axes where there's no motion (nb the [0] is necessary because the return value from np.where is a tuple)\n                N = len(axes_with_motion)\n                def error_from_gaussian(p):\n                    gaussian = p[0] + p[1] * np.exp(-np.sum(old_div((pos-p[2:2+N])**2,(2*p[2+N:2+2*N]**2)),axis=1))\n                    return np.mean((powers-gaussian)**2)\n                ret = scipy.optimize.minimize(error_from_gaussian, [0,np.max(powers)]+list(mean_position)+list(np.ones(N)*0.3))\n                print(ret)\n                assert ret.success\n                for i, a in enumerate(axes_with_motion):\n                    mean_position[a] = ret.x[i+2]\n            except:\n                print(\"Gaussian fit failed, falling back to centroid.\")\n                fit_method=\"centroid\"\n        if fit_method==\"centroid\":\n            powers = np.array(powers) - np.min(powers)*1.1+np.max(powers)*0.1 #make sure no powers are <0\n            mean_position = old_div(np.dot(powers, positions),np.sum(powers))\n        if fit_method==\"maximum\":           #go to the brightest point\n            powers = np.array(powers)\n            mean_position = np.array(positions)[powers.argmax(),:]\n                    \n        if print_move:\n            print(\"moving %.3f, %.3f, %.3f\" % tuple(mean_position - here))\n        try:\n            self.stage.move(mean_position)\n        except:\n            print(\"Positions:\\n\",positions)\n            print(\"Powers: \",powers)\n            print(\"Mean Position: \",mean_position)\n        self._action_lock.release()\n        self.plot_alignment(positions, powers, mean_position, **plot_args)\n        return positions, powers, mean_position\n    def optimise(self,tolerance, max_steps=10, stepsize=0.5, npoints=3, dz=0.5,verbose=False):\n        \"\"\"Repeatedly move and take spectra to find the peak.\n        \n        \n        WARNING: it seems a bit unstable at the moment, best consider this \n        \"experimental\" code! The focus has a tendency to wander!\n        \n        Each iteration, we perform iterate_circle(stepsize, npoints) then\n        iterate_z(dz).  The algorithm stops when the distance moved is less\n        than tolerance.  If tolerance is a 3-element numpy array, then a\n        different tolerance is applied to x, y, z: [1,1,1] is equivalent to a \n        tolerance of 1, as the comparison is sum(dx**2/tolerance**2) < 1.0\n        \"\"\"\n        self._action_lock.acquire()\n        positions = [np.array(self.stage.position)]\n        powers = [self.merit_function()]\n        for i in range(max_steps):\n            pos = self.iterate_circle(stepsize,npoints, print_move=verbose)[2]\n            pos = self.iterate_z(dz, print_move=verbose)[2]\n            positions.append(pos)\n            powers.append(self.merit_function())\n            if np.sum(old_div((positions[-1] - positions[-2])**2, tolerance**2)) <= 1.0:\n                break\n            else:\n                time.sleep(self.settling_time)\n        if verbose: print(\"performed %d iterations\" % (len(positions)-1))\n        self._action_lock.release()\n        self.plot_alignment(positions, powers, [np.NaN,np.NaN])\n        return positions, powers\n    def _do_XY_optimisation_fired(self):\n        threading.Thread(target=self.optimise_2D,args=[self.tolerance], kwargs=dict(stepsize=self.step_size, npoints = self.number_of_points)).start()\n    def optimise_2D(self, tolerance=0.03, max_steps=10, stepsize=0.2, npoints=3, print_move=True,reduce_integration_time = True):\n        \"\"\"repeatedly move and take spectra to find the peak\n        \n        we run iterate_circle until the movement produced is small enough.\"\"\"\n        if reduce_integration_time == True:\n            start_expo =self.spectrometer.integration_time\n            self.spectrometer.integration_time = start_expo/3.0\n        self._action_lock.acquire()\n        positions = [np.array(self.stage.position)]\n        powers = [self.merit_function()]\n        for i in range(max_steps):\n            #pos = self.iterate_circle(stepsize,npoints,print_move,plot_args={'color':\"blue\",'cla':(i==0)})[2]\n            pos = self.iterate_grid(stepsize,print_move=print_move,plot_args={'color':\"blue\",'cla':(i==0)})[2]\n            positions.append(pos)\n            powers.append(self.merit_function())\n            if np.sqrt(np.sum((positions[-1] - positions[-2])**2)) < tolerance:\n                break\n        print(\"performed %d iterations\" % (len(positions)-1))\n        self._action_lock.release()\n        self.plot_alignment(positions, powers, [np.NaN,np.NaN], cla=False, fade=False, color=\"green\")\n        if reduce_integration_time == True:\n            self.spectrometer.integration_time = start_expo\n        return positions, powers\n    def z_scan(self, dz = np.arange(-4,4,0.4)):\n        \"\"\"Take spectra at (relative) z positions dz and return as a 2D array\"\"\"\n        spectra = []\n        here = self.stage.position\n        for z in dz:\n            self.stage.move(np.array([0,0,z])+here)\n            time.sleep(self.settling_time)\n            spectra.append(self.spectrometer.read_spectrum())\n        self.stage.move(here)\n        return ArrayWithAttrs(spectra, attrs=self.spectrometer.metadata)\n    def plot_alignment(self,positions, powers, mean_position, cla=True, fade=True, **kwargs):\n        \"\"\"plot an alignment so we can see how it went\"\"\"\n        pass",
  "def fit_parabola(positions, powers, *args):\n    positions = np.array(positions)\n    powers = np.array(powers)\n    mean_position = np.mean(positions,axis=0) #default to no motion, (as the polyfit will fail if there's no motion in one axis) ??should this be positions (measured) or points (specified)?\n    axes_with_motion = np.where(np.std(positions,axis=0)>0)[0] #don't try to fit axes where there's no motion (nb the [0] is necessary because the return value from np.where is a tuple)\n    #model: power = a +b.x + c.<crossterms>\n    N = len(axes_with_motion) #number of axes\n    quadratic = np.ones((powers.shape[0], 2*N + 1))\n    for i, a in enumerate(axes_with_motion):\n        quadratic[:,i+1] = positions[:,a] #put linear terms in the matrix\n    for i, a in enumerate(axes_with_motion):\n        quadratic[:,i+1+N] = positions[:,a] #put quadratic terms in the matrix (ignore cross terms for now...)\n    p = np.linalg.lstsq(quadratic, powers)[0] #use least squares to fast-fit a 2D parabola\n    for i, a in enumerate(axes_with_motion):\n        if p[i+1+N] > 0:\n            mean_position[a] = np.Inf * p[i+1] #if the parabola is happy/flat, assume we are moving the maximum step\n        else:\n            mean_position[a] = old_div(-p[i+1],(2*p[i+N+1])) #if there's a maximum in the fitted curve, assume that's where we should be\n    for i in range(mean_position.shape[0]):\n        if mean_position[i] > np.max(positions[:,i]): mean_position[i] = np.max(positions[:,i]) #constrain to lie within the positions supplied\n        if mean_position[i] < np.min(positions[:,i]): mean_position[i] = np.min(positions[:,i]) #so we don't move too far\n    return mean_position - np.mean(positions,axis=0)",
  "def plot_alignment(positions, powers, mean_position):\n    x = [p[0] for p in positions]\n    y = [p[1] for p in positions]\n    powers = np.array(powers)\n    s = old_div(powers,powers.max()) * 20\n    plt.scatter(x,y,s=s)\n    plt.plot([mean_position[0]],[mean_position[1]], 'r+')\n    plt.show(block=False)",
  "def __init__(self,spectrometer,stage):\n        super(SpectrometerAligner,self).__init__()\n        self.spectrometer = spectrometer\n        self.stage = stage\n        self.align_to_raw_spectra=False\n        self.settling_time=0.3\n        self.spectrum_mask = None\n#        self.step_size=Range(0.01,100.,0.5)\n#        self.tolerance=Range(0.01,10.,0.05)\n#        self.number_of_points = Range(2,20,5)\n#        self.figure = \n#        self.figure.add_subplot(111)\n        self._action_lock=threading.RLock()",
  "def merit_function(self):\n        \"\"\"this is what we optimise\"\"\"\n        spectrum = self.spectrometer.read_spectrum()\n        if not self.align_to_raw_spectra and self.spectrometer.background.shape == spectrum.shape:\n            spectrum -= self.spectrometer.background\n        if self.spectrum_mask is None:\n            return np.nansum(spectrum)\n        else:\n            return np.nansum(spectrum[self.spectrum_mask])",
  "def _do_circle_iteration_fired(self):\n        threading.Thread(target=self.iterate_circle,\n                         kwargs=dict(radius=self.step_size,npoints=self.number_of_points)).start()",
  "def iterate_circle(self,radius,npoints=3,print_move=True,**kwargs):\n        \"\"\"Move the stage in a circle, taking spectra.  Refine the position.\"\"\"\n        angles = [2*np.pi/float(npoints) * float(i) for i in range(npoints)]\n        points = [np.array([np.cos(a),np.sin(a),0])*radius for a in angles]\n        return self.iterate_on_points(points, include_here=True, print_move=print_move, **kwargs)",
  "def iterate_grid(self,stepsize,**kwargs):\n        \"\"\"Move the stage in a 9-point grid and then find the maximum.\"\"\"\n        points = [np.array([i,j,0])*stepsize for i in [-1,0,1] for j in [-1,0,1] if not (i==0 and j==0)]\n        return self.iterate_on_points(points, include_here=True, fit_method=\"maximum\", **kwargs)",
  "def _do_focus_iteration_fired(self):\n        threading.Thread(target=self.iterate_z, args=[self.step_size]).start()",
  "def iterate_z(self,dz,print_move=True):\n        \"\"\"Move the stage up and down to optimise focus\"\"\"\n        return self.iterate_on_points([np.array([0,0,z]) for z in [-dz,dz]],print_move=print_move)",
  "def iterate_on_points(self,points,include_here=True,print_move=True,plot_args={},fit_method=\"centroid\"):\n        \"\"\"Visit the points supplied, and refine our position.\n        \n        The merit function will be evaluated at each point (given in stage\n        units, relative to the current position) and then the stage moved to\n        the centre of mass.  The minimum reading is subtracted to avoid\n        negative values (which mess things up) and speed up convergence.\n        \n        include_here adds the present position as one of the points.  This can\n        help stability if the points passed in are e.g. a circle.\"\"\"\n        #NB we're not bothering with sample coordinates here...\n        self._action_lock.acquire()\n        here = np.array(self.stage.position)\n        positions = [here]\n        powers = [self.merit_function()]\n        for p in points: #iterate through the points and measure the merit function\n            self.stage.move(here+p)\n            time.sleep(self.settling_time)\n            positions.append(self.stage.position)\n            powers.append(self.merit_function())\n        if fit_method==\"parabola\": #parabolic fit: fit a 2D parabola to the data.  More responsive but less stable than centre of mass.\n            try:\n                pos = np.array(positions) - np.mean(positions,axis=0)\n                powers = np.array(powers)\n                mean_position = np.mean(pos, axis=0) #default to no motion, (as the polyfit will fail if there's no motion in one axis) ??should this be positions (measured) or points (specified)?\n                axes_with_motion = np.where(np.std(np.array(points),axis=0)>0)[0] #don't try to fit axes where there's no motion (nb the [0] is necessary because the return value from np.where is a tuple)\n                #model: power = a +b.x + c.<crossterms>\n                N = len(axes_with_motion) #number of axes\n                quadratic = np.ones((powers.shape[0], 2*N + 1))\n                for i, a in enumerate(axes_with_motion):\n                    quadratic[:,i+1] = pos[:,a] #put linear terms in the matrix\n                for i, a in enumerate(axes_with_motion):\n                    quadratic[:,i+1+N] = pos[:,a] #put quadratic terms in the matrix (ignore cross terms for now...)\n                p = np.linalg.lstsq(quadratic, powers)[0] #use least squares to fast-fit a 2D parabola\n                print(\"quadratic fit: \", p)\n                for i, a in enumerate(axes_with_motion):\n                    if p[i+1+N] > 0:\n                        mean_position[a] = np.Inf * p[i+1] #if the parabola is happy/flat, assume we are moving the maximum step\n                        print(\"warning: there is no maximum on axis %d\" % a)\n                    else:\n                        mean_position[a] = old_div(-p[i+1],(2*p[i+N+1])) #if there's a maximum in the fitted curve, assume that's where we should be\n                        print(\"axis %d has a maximum at %.2f\" % (a, mean_position[a]))\n                for i in range(mean_position.shape[0]):\n                    if mean_position[i] > old_div(np.max(pos[:,i]),2): mean_position[i] = old_div(np.max(pos[:,i]),2) #constrain to lie within the positions supplied\n                    if mean_position[i] < old_div(np.min(pos[:,i]),2): mean_position[i] = old_div(np.min(pos[:,i]),2) #so we don't move too far\n                mean_position += np.mean(positions,axis=0)\n            except:\n                print(\"Quadratic fit failed, falling back to centroid.\")\n                fit_method=\"centroid\"\n        if fit_method==\"gaussian\":\n            try:\n                pos = np.array(positions)\n                powers = np.array(powers)\n                mean_position = np.mean(pos, axis=0) #default to no motion, (as the polyfit will fail if there's no motion in one axis) ??should this be positions (measured) or points (specified)?\n                axes_with_motion = np.where(np.std(np.array(points),axis=0)>0)[0] #don't try to fit axes where there's no motion (nb the [0] is necessary because the return value from np.where is a tuple)\n                N = len(axes_with_motion)\n                def error_from_gaussian(p):\n                    gaussian = p[0] + p[1] * np.exp(-np.sum(old_div((pos-p[2:2+N])**2,(2*p[2+N:2+2*N]**2)),axis=1))\n                    return np.mean((powers-gaussian)**2)\n                ret = scipy.optimize.minimize(error_from_gaussian, [0,np.max(powers)]+list(mean_position)+list(np.ones(N)*0.3))\n                print(ret)\n                assert ret.success\n                for i, a in enumerate(axes_with_motion):\n                    mean_position[a] = ret.x[i+2]\n            except:\n                print(\"Gaussian fit failed, falling back to centroid.\")\n                fit_method=\"centroid\"\n        if fit_method==\"centroid\":\n            powers = np.array(powers) - np.min(powers)*1.1+np.max(powers)*0.1 #make sure no powers are <0\n            mean_position = old_div(np.dot(powers, positions),np.sum(powers))\n        if fit_method==\"maximum\":           #go to the brightest point\n            powers = np.array(powers)\n            mean_position = np.array(positions)[powers.argmax(),:]\n                    \n        if print_move:\n            print(\"moving %.3f, %.3f, %.3f\" % tuple(mean_position - here))\n        try:\n            self.stage.move(mean_position)\n        except:\n            print(\"Positions:\\n\",positions)\n            print(\"Powers: \",powers)\n            print(\"Mean Position: \",mean_position)\n        self._action_lock.release()\n        self.plot_alignment(positions, powers, mean_position, **plot_args)\n        return positions, powers, mean_position",
  "def optimise(self,tolerance, max_steps=10, stepsize=0.5, npoints=3, dz=0.5,verbose=False):\n        \"\"\"Repeatedly move and take spectra to find the peak.\n        \n        \n        WARNING: it seems a bit unstable at the moment, best consider this \n        \"experimental\" code! The focus has a tendency to wander!\n        \n        Each iteration, we perform iterate_circle(stepsize, npoints) then\n        iterate_z(dz).  The algorithm stops when the distance moved is less\n        than tolerance.  If tolerance is a 3-element numpy array, then a\n        different tolerance is applied to x, y, z: [1,1,1] is equivalent to a \n        tolerance of 1, as the comparison is sum(dx**2/tolerance**2) < 1.0\n        \"\"\"\n        self._action_lock.acquire()\n        positions = [np.array(self.stage.position)]\n        powers = [self.merit_function()]\n        for i in range(max_steps):\n            pos = self.iterate_circle(stepsize,npoints, print_move=verbose)[2]\n            pos = self.iterate_z(dz, print_move=verbose)[2]\n            positions.append(pos)\n            powers.append(self.merit_function())\n            if np.sum(old_div((positions[-1] - positions[-2])**2, tolerance**2)) <= 1.0:\n                break\n            else:\n                time.sleep(self.settling_time)\n        if verbose: print(\"performed %d iterations\" % (len(positions)-1))\n        self._action_lock.release()\n        self.plot_alignment(positions, powers, [np.NaN,np.NaN])\n        return positions, powers",
  "def _do_XY_optimisation_fired(self):\n        threading.Thread(target=self.optimise_2D,args=[self.tolerance], kwargs=dict(stepsize=self.step_size, npoints = self.number_of_points)).start()",
  "def optimise_2D(self, tolerance=0.03, max_steps=10, stepsize=0.2, npoints=3, print_move=True,reduce_integration_time = True):\n        \"\"\"repeatedly move and take spectra to find the peak\n        \n        we run iterate_circle until the movement produced is small enough.\"\"\"\n        if reduce_integration_time == True:\n            start_expo =self.spectrometer.integration_time\n            self.spectrometer.integration_time = start_expo/3.0\n        self._action_lock.acquire()\n        positions = [np.array(self.stage.position)]\n        powers = [self.merit_function()]\n        for i in range(max_steps):\n            #pos = self.iterate_circle(stepsize,npoints,print_move,plot_args={'color':\"blue\",'cla':(i==0)})[2]\n            pos = self.iterate_grid(stepsize,print_move=print_move,plot_args={'color':\"blue\",'cla':(i==0)})[2]\n            positions.append(pos)\n            powers.append(self.merit_function())\n            if np.sqrt(np.sum((positions[-1] - positions[-2])**2)) < tolerance:\n                break\n        print(\"performed %d iterations\" % (len(positions)-1))\n        self._action_lock.release()\n        self.plot_alignment(positions, powers, [np.NaN,np.NaN], cla=False, fade=False, color=\"green\")\n        if reduce_integration_time == True:\n            self.spectrometer.integration_time = start_expo\n        return positions, powers",
  "def z_scan(self, dz = np.arange(-4,4,0.4)):\n        \"\"\"Take spectra at (relative) z positions dz and return as a 2D array\"\"\"\n        spectra = []\n        here = self.stage.position\n        for z in dz:\n            self.stage.move(np.array([0,0,z])+here)\n            time.sleep(self.settling_time)\n            spectra.append(self.spectrometer.read_spectrum())\n        self.stage.move(here)\n        return ArrayWithAttrs(spectra, attrs=self.spectrometer.metadata)",
  "def plot_alignment(self,positions, powers, mean_position, cla=True, fade=True, **kwargs):\n        \"\"\"plot an alignment so we can see how it went\"\"\"\n        pass",
  "def error_from_gaussian(p):\n                    gaussian = p[0] + p[1] * np.exp(-np.sum(old_div((pos-p[2:2+N])**2,(2*p[2+N:2+2*N]**2)),axis=1))\n                    return np.mean((powers-gaussian)**2)",
  "class Kandor(Andor):\n    ''' Wrapper class for the kymera and the andor\n    '''\n    \n    def __init__(self, pixel_number=1600,\n                 pixel_width=16,\n                 use_shifts=False, \n                 laser_wl=632.8,\n                 white_shutter=None):\n        \n        super().__init__()\n        self.kymera = Kymera()\n        self.kymera.pixel_number = pixel_number\n        self.kymera.pixel_width = pixel_width\n        self.use_shifts = use_shifts\n        self.laser_wl = laser_wl\n        self.white_shutter = white_shutter\n        self.metadata_property_names += ('slit_width', 'wavelengths')\n        self.ImageFlip = 0\n    \n    def get_x_axis(self, use_shifts=None):\n        X = self.kymera.GetCalibration()\n        if all([not x for x in X]):# if the list is all 0s\n            X = range(len(X))\n        if self.use_shifts and use_shifts in [None, False]:\n            \n            wavelengths = np.array(X)\n            return ( 1./(self.laser_wl*1e-9)- 1./(wavelengths*1e-9))/100    \n        \n        return X\n    x_axis = property(get_x_axis)\n    \n    @property\n    def slit_width(self):\n        return self.kymera.slit_width\n    \n    @property \n    def wavelengths(self):\n        return self.get_x_axis(use_shifts=False)",
  "def __init__(self, pixel_number=1600,\n                 pixel_width=16,\n                 use_shifts=False, \n                 laser_wl=632.8,\n                 white_shutter=None):\n        \n        super().__init__()\n        self.kymera = Kymera()\n        self.kymera.pixel_number = pixel_number\n        self.kymera.pixel_width = pixel_width\n        self.use_shifts = use_shifts\n        self.laser_wl = laser_wl\n        self.white_shutter = white_shutter\n        self.metadata_property_names += ('slit_width', 'wavelengths')\n        self.ImageFlip = 0",
  "def get_x_axis(self, use_shifts=None):\n        X = self.kymera.GetCalibration()\n        if all([not x for x in X]):# if the list is all 0s\n            X = range(len(X))\n        if self.use_shifts and use_shifts in [None, False]:\n            \n            wavelengths = np.array(X)\n            return ( 1./(self.laser_wl*1e-9)- 1./(wavelengths*1e-9))/100    \n        \n        return X",
  "def slit_width(self):\n        return self.kymera.slit_width",
  "def wavelengths(self):\n        return self.get_x_axis(use_shifts=False)",
  "class Acton(SerialInstrument):\n    port_settings = dict(baudrate=9600,\n                         bytesize=serial.EIGHTBITS,\n                         parity=serial.PARITY_NONE,\n                         stopbits=serial.STOPBITS_ONE,\n                         timeout=5,  # wait at most one second for a response\n                         writeTimeout=1,  # similarly, fail if writing takes >1s\n                         xonxoff=False, rtscts=False, dsrdtr=False,\n                         )\n                         \n    def __init__(self, port, debug=0, echo=True, dummy=False):\n        if debug > 0:\n            print(\"Started: Acton.__init__\")\n        SerialInstrument.__init__(self, port)\n        self.echo=echo\n        \n        # self.ser.flushInput()\n        # self.ser.flushOutput()\n        \n        # model info\n        self.write_command(\"MONO-RESET\")\n        # if debug > 0:\n            # print \"Started [2]: Acton.__init__\"\n        \n        # self.model = self.write_command(\"MODEL\",debug=debug)\n        # self.serial_number = self.write_command(\"SERIAL\",debug=debug)\n        # load grating info\n        # self.read_grating_info(debug=debug)\n    \n\n    def read_done_status(self):\n        resp = self.write_command(\"MONO-?DONE\")  # returns either 1 or 0 for done or not done\n        return bool(int(resp))\n    \n    def read_wl(self):\n        resp = self.write_command(\"?NM\")\n        \"700.000 nm\"\n        self.wl = float(resp.split()[0])\n        return self.wl\n        \n#     def write_wl(self, wl, waittime=1.0):\n#         wl = float(wl)\n#         resp = self.write_command(\"%0.3f NM\" % wl,waittime=waittime)\n# #        if self.debug: logger.debug(\"write_wl wl:{} resp:{}\".format( wl, resp))\n        \n    def write_wl_fast(self, wl, waittime=1.0):\n        wl = float(wl)\n        resp = self.write_command(\"%0.3f GOTO\" % wl,waittime=waittime)\n#        if self.debug: logger.debug(\"write_wl_fast wl:{} resp:{}\".format( wl, resp))\n        \n\n#     def write_wl_nonblock(self, wl):\n#         wl = float(wl)\n#         resp = self.write_command(\"%0.3f >NM\" % wl)\n# #        if self.debug: logger.debug(\"write_wl_nonblock wl:{} resp:{}\".format( wl, resp))\n        \n    def read_grating_info(self,debug=0):\n        grating_string = self.write_command(\"?GRATINGS\", waittime=1.0,debug=debug)\n        \"\"\"\n            \\x1a1  1200 g/mm BLZ=  500NM \n            2  300 g/mm BLZ=  1.0UM \n            3  150 g/mm BLZ=  500NM \n            4  Not Installed     \n            5  Not Installed     \n            6  Not Installed     \n            7  Not Installed     \n            8  Not Installed     \n            9  Not Installed     \n            ok\n        \"\"\"\n        # 0x1A is the arrow char, indicates selected grating\n        \n        if self.echo:\n            gratings = grating_string.splitlines()[1:-1] # needed for echo\n        else:\n            gratings = grating_string.splitlines()[0:-1] # for no echo\n#        if self.debug: print(gratings)\n        \n        print(gratings)\n        self.gratings = []\n        \n        for grating in gratings:\n#            if self.debug: logger.debug(\"grating: {}\".format( grating ))\n            grating_num, name = grating.strip('\\x1a').strip(' ').split(' ', 1)\n            #if self.debug: logger.debug(\"grating stripped: {}\".format( grating ))\n            num = int(grating_num)\n            self.gratings.append( (num, name) )\n        \n        self.gratings_dict = {num: name for num,name in self.gratings}\n        \n        return self.gratings\n    \n    def set_wavelength(self,wavelength,blocking=True,fast=True,debug=0):\n\n\n        if blocking == True:\n\n            if fast == False:\n                query = \"{0:.3f} NM\".format(wavelength)\n            elif fast == True:\n                query = \"{0:.3f} GOTO\".format(wavelength)\n\n        elif blocking == False:\n            query = \"{0:.3f} >NM\".format(wavelength)\n        print(\"set_wavelength:\", query)\n        resp = self.write_command(query,debug=debug)\n        return resp \n\n    def get_wavelength(self):\n        resp = self.write_command(\"?NM\")\n        return resp\n\n    def read_turret(self):\n        resp = self.write_command(\"?TURRET\")\n        self.turret = int(resp)\n        return self.turret\n    \n    def write_turret(self, turret):\n        assert turret in [1,2,3]\n        \"%i TURRET\"\n    \n    def read_grating(self):\n        resp = self.write_command(\"?GRATING\")\n        self.grating = int(resp)\n        return self.grating\n        \n    def read_grating_name(self):\n        self.read_grating()\n        return self.gratings[self.grating-1]\n        \n    def set_grating(self, grating):\n        assert 0 < grating < 10 \n        self.write_command(\"%i GRATING\" % grating)        \n        \n    def read_exit_mirror(self):\n        resp = self.write_command(\"EXIT-MIRROR ?MIRROR\")\n        self.exit_mirror = resp.upper()\n        return self.exit_mirror\n    \n    def write_exit_mirror(self, pos):\n        pos = pos.upper()\n        assert pos in ['FRONT', 'SIDE']\n        self.write_command(\"EXIT-MIRROR %s\" % pos)\n        \n    def read_entrance_slit(self):\n        resp = self.write_command(\"SIDE-ENT-SLIT ?MICRONS\")\n        #\"480 um\" or \"no motor\"\n        print((repr(resp)))\n        if resp == 'no motor':\n            self.entrance_slit = -1\n        else:\n            self.entrance_slit = int(resp.split()[0])\n        return self.entrance_slit\n        \n    def write_entrance_slit(self, pos):\n        assert 5 <= pos <= 3000\n        self.write_command(\"SIDE-ENT-SLIT %i MICRONS\" % pos)\n        # should return new pos\n\n    def home_entrance_slit(self):\n        # TODO\n        \"SIDE-ENT-SLIT SHOME\"\n\n        \n    def read_exit_slit(self):\n        resp = self.write_command(\"SIDE-EXIT-SLIT ?MICRONS\")\n        #\"960 um\" or \"no motor\"\n        if resp == 'no motor':\n            self.exit_slit = -1\n        else:\n            self.exit_slit = int(resp.split()[0])\n        return self.exit_slit\n        \n    def write_exit_slit(self, pos):\n        assert 5 <= pos <= 3000\n        self.write_command(\"SIDE-EXIT-SLIT %i MICRONS\" % pos)\n           \n    def write_command(self, cmd, waittime=0.5, debug = 0):       \n        cmd_bytes = (cmd).encode('ASCII')\n        self.ser.write(cmd_bytes+b\"\\r\")\n        time.sleep(waittime)\n        \n        out = bytearray()\n        char = b\"\"\n        missed_char_count = 0\n        while char != b\"k\":\n            char = self.ser.read()\n            if char == b\"\": #handles a timeout here\n                missed_char_count += 1\n                if missed_char_count > 3:\n                    return 0\n                continue\n            out += char\n\n        \n        out += self.ser.read(2) #Should be \"\\r\\n\"\n        \n        out = out.decode('ascii')\n\n        if debug > 0:\n            print(\"response full:\", out)   \n            print(\"response tail:\",out[-5:])\n        # assert out[-5:] == \" ok\\r\\n\"\n        # out = out[:-5].strip()\n    \n        # When echo is enabled, verify echoed command and strip\n        if self.echo:\n            echo = out[0:len(cmd_bytes)]        \n            rest = out[len(cmd_bytes):]\n            print((\"echo, rest, cmd:\", echo, rest, cmd_bytes))\n            # assert echo == cmd\n            return rest\n        else:\n            return out\n        #self.ser.flushInput()\n        #self.ser.flushOutput()\n        #return out\n    \n    def close(self):\n        self.ser.close()",
  "def __init__(self, port, debug=0, echo=True, dummy=False):\n        if debug > 0:\n            print(\"Started: Acton.__init__\")\n        SerialInstrument.__init__(self, port)\n        self.echo=echo\n        \n        # self.ser.flushInput()\n        # self.ser.flushOutput()\n        \n        # model info\n        self.write_command(\"MONO-RESET\")",
  "def read_done_status(self):\n        resp = self.write_command(\"MONO-?DONE\")  # returns either 1 or 0 for done or not done\n        return bool(int(resp))",
  "def read_wl(self):\n        resp = self.write_command(\"?NM\")\n        \"700.000 nm\"\n        self.wl = float(resp.split()[0])\n        return self.wl",
  "def write_wl_fast(self, wl, waittime=1.0):\n        wl = float(wl)\n        resp = self.write_command(\"%0.3f GOTO\" % wl,waittime=waittime)",
  "def read_grating_info(self,debug=0):\n        grating_string = self.write_command(\"?GRATINGS\", waittime=1.0,debug=debug)\n        \"\"\"\n            \\x1a1  1200 g/mm BLZ=  500NM \n            2  300 g/mm BLZ=  1.0UM \n            3  150 g/mm BLZ=  500NM \n            4  Not Installed     \n            5  Not Installed     \n            6  Not Installed     \n            7  Not Installed     \n            8  Not Installed     \n            9  Not Installed     \n            ok\n        \"\"\"\n        # 0x1A is the arrow char, indicates selected grating\n        \n        if self.echo:\n            gratings = grating_string.splitlines()[1:-1] # needed for echo\n        else:\n            gratings = grating_string.splitlines()[0:-1] # for no echo\n#        if self.debug: print(gratings)\n        \n        print(gratings)\n        self.gratings = []\n        \n        for grating in gratings:\n#            if self.debug: logger.debug(\"grating: {}\".format( grating ))\n            grating_num, name = grating.strip('\\x1a').strip(' ').split(' ', 1)\n            #if self.debug: logger.debug(\"grating stripped: {}\".format( grating ))\n            num = int(grating_num)\n            self.gratings.append( (num, name) )\n        \n        self.gratings_dict = {num: name for num,name in self.gratings}\n        \n        return self.gratings",
  "def set_wavelength(self,wavelength,blocking=True,fast=True,debug=0):\n\n\n        if blocking == True:\n\n            if fast == False:\n                query = \"{0:.3f} NM\".format(wavelength)\n            elif fast == True:\n                query = \"{0:.3f} GOTO\".format(wavelength)\n\n        elif blocking == False:\n            query = \"{0:.3f} >NM\".format(wavelength)\n        print(\"set_wavelength:\", query)\n        resp = self.write_command(query,debug=debug)\n        return resp",
  "def get_wavelength(self):\n        resp = self.write_command(\"?NM\")\n        return resp",
  "def read_turret(self):\n        resp = self.write_command(\"?TURRET\")\n        self.turret = int(resp)\n        return self.turret",
  "def write_turret(self, turret):\n        assert turret in [1,2,3]\n        \"%i TURRET\"",
  "def read_grating(self):\n        resp = self.write_command(\"?GRATING\")\n        self.grating = int(resp)\n        return self.grating",
  "def read_grating_name(self):\n        self.read_grating()\n        return self.gratings[self.grating-1]",
  "def set_grating(self, grating):\n        assert 0 < grating < 10 \n        self.write_command(\"%i GRATING\" % grating)",
  "def read_exit_mirror(self):\n        resp = self.write_command(\"EXIT-MIRROR ?MIRROR\")\n        self.exit_mirror = resp.upper()\n        return self.exit_mirror",
  "def write_exit_mirror(self, pos):\n        pos = pos.upper()\n        assert pos in ['FRONT', 'SIDE']\n        self.write_command(\"EXIT-MIRROR %s\" % pos)",
  "def read_entrance_slit(self):\n        resp = self.write_command(\"SIDE-ENT-SLIT ?MICRONS\")\n        #\"480 um\" or \"no motor\"\n        print((repr(resp)))\n        if resp == 'no motor':\n            self.entrance_slit = -1\n        else:\n            self.entrance_slit = int(resp.split()[0])\n        return self.entrance_slit",
  "def write_entrance_slit(self, pos):\n        assert 5 <= pos <= 3000\n        self.write_command(\"SIDE-ENT-SLIT %i MICRONS\" % pos)",
  "def home_entrance_slit(self):\n        # TODO\n        \"SIDE-ENT-SLIT SHOME\"",
  "def read_exit_slit(self):\n        resp = self.write_command(\"SIDE-EXIT-SLIT ?MICRONS\")\n        #\"960 um\" or \"no motor\"\n        if resp == 'no motor':\n            self.exit_slit = -1\n        else:\n            self.exit_slit = int(resp.split()[0])\n        return self.exit_slit",
  "def write_exit_slit(self, pos):\n        assert 5 <= pos <= 3000\n        self.write_command(\"SIDE-EXIT-SLIT %i MICRONS\" % pos)",
  "def write_command(self, cmd, waittime=0.5, debug = 0):       \n        cmd_bytes = (cmd).encode('ASCII')\n        self.ser.write(cmd_bytes+b\"\\r\")\n        time.sleep(waittime)\n        \n        out = bytearray()\n        char = b\"\"\n        missed_char_count = 0\n        while char != b\"k\":\n            char = self.ser.read()\n            if char == b\"\": #handles a timeout here\n                missed_char_count += 1\n                if missed_char_count > 3:\n                    return 0\n                continue\n            out += char\n\n        \n        out += self.ser.read(2) #Should be \"\\r\\n\"\n        \n        out = out.decode('ascii')\n\n        if debug > 0:\n            print(\"response full:\", out)   \n            print(\"response tail:\",out[-5:])\n        # assert out[-5:] == \" ok\\r\\n\"\n        # out = out[:-5].strip()\n    \n        # When echo is enabled, verify echoed command and strip\n        if self.echo:\n            echo = out[0:len(cmd_bytes)]        \n            rest = out[len(cmd_bytes):]\n            print((\"echo, rest, cmd:\", echo, rest, cmd_bytes))\n            # assert echo == cmd\n            return rest\n        else:\n            return out",
  "def close(self):\n        self.ser.close()",
  "class Spectrometer(Instrument):\n\n    metadata_property_names = ('model_name', 'serial_number', 'integration_time',\n                               'reference', 'background', 'wavelengths',\n                               'background_int', 'reference_int','variable_int_enabled',\n                               'background_gradient','background_constant', 'averaging_enabled'\n                               ,'absorption_enabled')\n   \n    variable_int_enabled = DumbNotifiedProperty(False)\n    filename = DumbNotifiedProperty(\"spectrum\")\n    dark = False\n    def __init__(self):\n        super(Spectrometer, self).__init__()\n        self._model_name = None\n        self._serial_number = None\n        self._wavelengths = None\n        self.reference = None\n        self.background = None\n        self.background_constant =None\n        self.background_gradient = None\n        self.background_int = None\n        self.reference_int = None\n      #  self.variable_int_enabled = DumbNotifiedProperty(False)\n        self.latest_raw_spectrum = None\n        self.latest_spectrum = None\n        self.averaging_enabled = False\n        self.spectra_deque = deque(maxlen = 1)\n        self.absorption_enabled = False\n        self._config_file = None\n\n        self.stored_references = {}\n        self.stored_backgrounds = {}\n        self.reference_ID = 0\n        self.spectra_buffer = np.zeros(0)\n        self.data_file = df.current()\n        self.curr_scan=None\n        self.num_spectra = 1\n        self.delay = 0\n        self.time_series_name = 'time_series_%d'\n\n\n    def __del__(self):\n        try:\n            self._config_file.close()\n        except AttributeError:\n            pass #if it's not present, we get an exception - which doesn't matter.\n\n    def open_config_file(self):\n        \"\"\"Open the config file for the current spectrometer and return it, creating if it's not there\"\"\"\n        if self._config_file is None:\n            f = inspect.getfile(self.__class__)\n            d = os.path.dirname(f)\n            self._config_file = DataFile(h5py.File(os.path.join(d, 'config.h5')))\n            self._config_file.attrs['date'] = datetime.datetime.now().strftime(\"%H:%M %d/%m/%y\")\n        return self._config_file\n\n    config_file = property(open_config_file)\n\n    def update_config(self, name, data, attrs= None):\n        \"\"\"Update the configuration file for this spectrometer.\n        \n        A file is created in the nplab directory that holds configuration\n        data for the spectrometer, including reference/background.  This\n        function allows values to be stored in that file.\"\"\"\n        f = self.config_file\n        if name not in f:\n            f.create_dataset(name, data=data ,attrs = attrs)\n        else:\n            dset = f[name]\n            dset[...] = data\n            f.flush()\n\n    def get_model_name(self):\n        \"\"\"The model name of the spectrometer.\"\"\"\n        if self._model_name is None:\n            self._model_name = 'model_name'\n        return self._model_name\n\n    model_name = property(get_model_name)\n\n    def get_serial_number(self):\n        \"\"\"The spectrometer's serial number (as a string).\"\"\"\n        warnings.warn(\"Using the default implementation for get_serial_number: this should be overridden!\",DeprecationWarning)\n        if self._serial_number is None:\n            self._serial_number = 'serial_number'\n        return self._serial_number\n\n    serial_number = property(get_serial_number)\n\n    def get_integration_time(self):\n        \"\"\"The integration time of the spectrometer (this function is a stub)!\"\"\"\n        warnings.warn(\"Using the default implementation for integration time: this should be overridden!\",DeprecationWarning)\n        return 0\n\n    def set_integration_time(self, value):\n        \"\"\"Set the integration time of the spectrometer (this is a stub)!\"\"\"\n        warnings.warn(\"Using the default implementation for integration time: this should be overridden!\",DeprecationWarning)\n        print('setting 0')\n\n    integration_time = property(get_integration_time, set_integration_time)\n\n    def get_wavelengths(self):\n        \"\"\"An array of wavelengths corresponding to the spectrometer's pixels.\"\"\"\n        warnings.warn(\"Using the default implementation for wavelengths: this should be overridden!\",DeprecationWarning)\n\n        if self._wavelengths is None:\n            self._wavelengths = np.arange(400,1200,1)\n        return self._wavelengths\n\n    wavelengths = property(get_wavelengths)\n\n    def read_spectrum(self, bundle_metadata=False):\n        \"\"\"Take a reading on the spectrometer and return it\"\"\"\n        warnings.warn(\"Using the default implementation for read_spectrum: this should be overridden!\",DeprecationWarning)\n        self.latest_raw_spectrum = np.zeros(0)\n        return self.bundle_metadata(self.latest_raw_spectrum, enable=bundle_metadata)\n\n    def read_background(self):\n        \"\"\"Acquire a new spectrum and use it as a background measurement.\n        This background should be less than 50% of the spectrometer saturation\"\"\"\n        if self.averaging_enabled == True:\n            background_1 = np.average(self.read_averaged_spectrum(True,True),axis=0)\n        else:\n            background_1 = self.read_spectrum()\n        self.integration_time = 2.0*self.integration_time\n        if self.averaging_enabled == True:\n            background_2 = np.average(self.read_averaged_spectrum(True,True),axis=0)\n        else:\n            background_2 = self.read_spectrum()\n        self.integration_time = self.integration_time/2.0\n        self.background_gradient = (background_2-background_1)/self.integration_time\n        self.background_constant = background_1-(self.integration_time*self.background_gradient)\n        self.background = background_1\n        self.background_int = self.integration_time\n        self.stored_backgrounds[self.reference_ID] = {'background_gradient' : self.background_gradient,\n                                                     'background_constant' : self.background_constant,\n                                                     'background' : self.background,\n                                                     'background_int': self.background_int}\n        self.update_config('background_gradient', self.background_gradient)\n        self.update_config('background_constant', self.background_constant)\n        self.update_config('background', self.background)\n        self.update_config('background_int', self.background_int)\n\n    def clear_background(self):\n        \"\"\"Clear the current background reading.\"\"\"\n        self.background = None\n        self.background_gradient = None\n        self.background_constant = None\n        self.background_int = None\n\n    def read_reference(self):\n        \"\"\"Acquire a new spectrum and use it as a reference.\"\"\"\n        if self.averaging_enabled == True:\n            self.reference = np.average(self.read_averaged_spectrum(True,True),axis=0)\n        else:\n            self.reference = self.read_spectrum() \n        self.reference_int = self.integration_time\n        self.update_config('reference', self.reference)\n        self.update_config('reference_int',self.reference_int) \n        self.stored_references[self.reference_ID] = {'reference' : self.reference,\n                                                    'reference_int' : self.reference_int}\n    def load_reference(self,ID):\n        for attr in self.stored_backgrounds[ID]:\n            setattr(self,attr,self.stored_backgrounds[ID][attr])\n        for attr in self.stored_references[ID]:\n            setattr(self,attr,self.stored_references[ID][attr])\n\n    def clear_reference(self):\n        \"\"\"Clear the current reference spectrum\"\"\"\n        self.reference = None\n        self.reference_int = None\n\n    def is_background_compensated(self):\n        \"\"\"Return whether there's currently a valid background spectrum\"\"\"\n        return len(self.background)==len(self.latest_raw_spectrum) and \\\n            sum(self.background)>0\n\n    def is_referenced(self):\n        \"\"\"Check whether there's currently a valid background and reference spectrum\"\"\"\n        try:\n            return self.is_background_compensated and \\\n                len(self.reference)==len(self.latest_raw_spectrum) and \\\n                sum(self.reference)>0\n        except TypeError:\n            return False\n\n    def process_spectrum(self, spectrum):\n        \"\"\"Subtract the background and divide by the reference, if possible\"\"\"\n        if self.background is not None:\n            if self.reference is not None:\n                old_error_settings = np.seterr(all='ignore')\n           #     new_spectrum = (spectrum - (self.background-np.min(self.background))*self.integration_time/self.background_int+np.min(self.background))/(((self.reference-np.min(self.background))*self.integration_time/self.reference_int - (self.background-np.min(self.background))*self.integration_time/self.background_int)+np.min(self.background))\n                if self.variable_int_enabled == True:\n                    new_spectrum = ((spectrum-(self.background_constant+self.background_gradient*self.integration_time))/((self.reference-(self.background_constant+self.background_gradient*self.reference_int))*self.integration_time/self.reference_int))\n                else:\n                    new_spectrum = (spectrum-self.background)/(self.reference-self.background)\n                np.seterr(**old_error_settings)\n                new_spectrum[np.isinf(new_spectrum)] = np.NaN #if the reference is nearly 0, we get infinities - just make them all NaNs.\n            else:\n                if self.variable_int_enabled == True:\n                    new_spectrum = spectrum-(self.background_constant+self.background_gradient*self.integration_time)\n                else:\n                    new_spectrum = spectrum-self.background\n                \n        else:\n            new_spectrum = spectrum\n        if self.absorption_enabled == True:\n            return np.log10(1/new_spectrum)\n        return new_spectrum\n\n    def read_processed_spectrum(self):\n        \"\"\"Acquire a new spectrum and return a processed (referenced/background-subtracted) spectrum.\n        \n        NB if saving data to file, it's best to save raw spectra along with metadata - this is a\n        convenience method for display purposes.\"\"\"\n        if self.averaging_enabled == True:\n            spectrum = np.average(self.read_averaged_spectrum(fresh = True),axis=0)\n        else:\n            spectrum = self.read_spectrum()\n        self.latest_spectrum = self.process_spectrum(spectrum)\n        return self.latest_spectrum\n\n    def read(self):\n        \"\"\"Acquire a new spectrum and return a tuple of wavelengths, spectrum\"\"\"\n        return self.wavelengths, self.read_processed_spectrum()\n\n    def mask_spectrum(self, spectrum, threshold):\n        \"\"\"Return a masked array of the spectrum, showing only points where the reference\n        is bright enough to be useful.\"\"\"\n        if self.reference is not None and self.background is not None:\n            reference = self.reference - self.background\n            mask = reference < reference.max() * threshold\n            if len(spectrum.shape)>1:\n                mask = np.tile(mask, spectrum.shape[:-1]+(1,))\n            return ma.array(spectrum, mask=mask)\n        else:\n            return spectrum\n    _preview_widgets = WeakSet()\n    def get_qt_ui(self, control_only=False,display_only = False):\n        \"\"\"Create a Qt interface for the spectrometer\"\"\"\n        \n        if control_only:\n            \n            newwidget = SpectrometerControlUI(self)\n            self._preview_widgets.add(newwidget)\n            return newwidget\n        elif display_only:\n            return SpectrometerDisplayUI(self)\n        else:\n            return SpectrometerUI(self)\n            \n    def get_control_widget(self):\n        \"\"\"Convenience function \"\"\"\n        return self.get_qt_ui(control_only=True)\n        \n    def get_preview_widget(self):\n        \"\"\"Convenience function \"\"\"\n        return self.get_qt_ui(display_only=True)\n\n    def save_spectrum(self, spectrum=None, attrs={}, new_deque = False):\n        \"\"\"Save a spectrum to the current datafile, creating if necessary.\n        \n        If no spectrum is passed in, a new spectrum is taken.  The convention\n        is to save raw spectra only, along with reference/background to allow\n        later processing.\n        \n        The attrs dictionary allows extra metadata to be saved in the HDF5 file.\"\"\"\n        if self.averaging_enabled == True:\n            spectrum = self.read_averaged_spectrum(new_deque = new_deque)\n        else:\n            spectrum = self.read_spectrum() if spectrum is None else spectrum\n        metadata = self.metadata\n        metadata.update(attrs) #allow extra metadata to be passed in\n        self.create_dataset(self.filename, data=spectrum, attrs=metadata) \n        #save data in the default place (see nplab.instrument.Instrument)\n    def read_averaged_spectrum(self,new_deque = False,fresh = False):\n            if fresh == True:\n                self.spectra_deque.append(self.read_spectrum())\n            if new_deque == True:\n                self.spectra_deque.clear()\n            while len(self.spectra_deque) < self.spectra_deque.maxlen:\n                self.spectra_deque.append(self.read_spectrum())\n            return self.spectra_deque\n        \n    def save_reference_to_file(self):\n        pass\n\n    def load_reference_from_file(self):\n        pass\n    \n    def time_series(self, num_spectra = None, delay = None, update_progress = lambda p:p):# delay in ms\n        if num_spectra is None:\n            num_spectra = self.num_spectra\n        if delay is None:\n            delay = self.delay\n        delay/=1000\n        update_progress(0)\n        metadata = self.metadata\n        extra_metadata = {'number of spectra' : num_spectra,\n                          'spectrum end-to-start delay' : delay\n                           }\n        metadata.update(extra_metadata) \n        to_save = []\n        times = []\n        start = time.time()\n        for spectrum_number in range(num_spectra):\n            times.append(time.time() - start)\n            to_save.append(self.read_spectrum()) # should be a numpy array\n            time.sleep(delay)\n            update_progress(spectrum_number)\n        metadata.update({'start times' : times})\n        self.create_dataset(self.time_series_name, data=to_save, attrs=metadata)\n        to_return = ArrayWithAttrs(to_save, attrs = metadata)\n        return to_return",
  "class Spectrometers(Instrument):\n    def __init__(self, spectrometer_list):\n        assert False not in [isinstance(s, Spectrometer) for s in spectrometer_list],\\\n            'an invalid spectrometer was supplied'\n        super(Spectrometers, self).__init__()\n        self.spectrometers = spectrometer_list\n        self.num_spectrometers = len(spectrometer_list)\n        self._pool = ThreadPool(processes=self.num_spectrometers)\n        self._wavelengths = None\n        filename = DumbNotifiedProperty('spectra')\n\n    def __del__(self):\n        self._pool.close()\n\n    def add_spectrometer(self, spectrometer):\n        assert isinstance(spectrometer, Spectrometer), 'spectrometer must be an instance of Spectrometer'\n        if spectrometer not in self.spectrometers:\n            self.spectrometers.append(spectrometer)\n            self.num_spectrometers = len(self.spectrometers)\n\n    def get_wavelengths(self):\n        if self._wavelengths is None:\n            self._wavelengths = [s.wavelengths for s in self.spectrometers]\n        return self._wavelengths\n\n    wavelengths = property(get_wavelengths)\n\n    def read_spectra(self):\n        \"\"\"Acquire spectra from all spectrometers and return as a list.\"\"\"\n        return self._pool.map(lambda s: s.read_spectrum(), self.spectrometers)\n\n    def read_processed_spectra(self):\n        \"\"\"Acquire a list of processed (referenced, background subtracted) spectra.\"\"\"\n        return self._pool.map(lambda s: s.read_processed_spectrum(), self.spectrometers)\n\n    def process_spectra(self, spectra):\n        pairs = list(zip(self.spectrometers, spectra))\n        return self._pool.map(lambda s_spectrum: s_spectrum[0].process_spectrum(s_spectrum[1]), pairs)\n\n    def get_metadata_list(self):\n        \"\"\"Return a list of metadata for each spectrometer.\"\"\"\n        return self._pool.map(lambda s: s.get_metadata(), self.spectrometers)\n\n    def mask_spectra(self, spectra, threshold):\n        return [spectrometer.mask_spectrum(spectrum, threshold) for (spectrometer, spectrum) in zip(self.spectrometers, spectra)]\n\n    def get_qt_ui(self):\n        return SpectrometersUI(self)\n\n    def save_spectra(self, spectra=None, attrs={}):\n        \"\"\"Save spectra from all the spectrometers, in a folder in the current\n        datafile, creating the file if needed.\n\n        If no spectra are given, new ones are acquired - NB you should pass\n        raw spectra in - metadata will be saved along with the spectra.\n        \"\"\"\n        spectra = self.read_spectra() if spectra is None else spectra\n        metadata_list = self.get_metadata_list()\n        g = self.create_data_group(self.filename,attrs=attrs) # create a uniquely numbered group in the default place\n        for spectrum,metadata in zip(spectra,metadata_list):\n            g.create_dataset('spectrum_%d',data=spectrum,attrs=metadata)\n            \n    def get_metadata(self):\n        \"\"\"\n        Returns a list of dictionaries containing relevant spectrometer properties\n        for each spectrometer.\n        \"\"\"\n        return [spectrometer.metadata for spectrometer in self.spectrometers]\n\n    metadata = property(get_metadata)",
  "class SpectrometerControlUI(QtWidgets.QWidget,UiTools):\n    \n    def __init__(self, spectrometer, ui_file =os.path.join(os.path.dirname(__file__),'spectrometer_controls.ui'),  parent=None):\n        assert isinstance(spectrometer, Spectrometer), \"instrument must be a Spectrometer\"\n        super(SpectrometerControlUI, self).__init__()\n        uic.loadUi(ui_file, self)\n        self.spectrometer = spectrometer\n        \n        self.integration_time.setValidator(QtGui.QDoubleValidator())\n        self.integration_time.textChanged.connect(self.check_state)\n        self.integration_time.textChanged.connect(self.update_param)\n\n        self.read_background_button.clicked.connect(self.button_pressed)\n        self.read_reference_button.clicked.connect(self.button_pressed)\n        self.clear_background_button.clicked.connect(self.button_pressed)\n        self.clear_reference_button.clicked.connect(self.button_pressed)\n        self.load_state_button.clicked.connect(self.button_pressed)\n\n        self.background_subtracted.stateChanged.connect(self.state_changed)\n        self.referenced.stateChanged.connect(self.state_changed)\n        \n        self.Absorption_checkBox.stateChanged.connect(self.state_changed)\n                \n        register_for_property_changes(self.spectrometer,'variable_int_enabled',self.variable_int_state_change)\n#        if self.spectrometer.variable_int_enabled:\n#                self.background_subtracted.blockSignals(True)\n#                self.background_subtracted.setCheckState(QtCore.Qt.Checked)\n#                self.background_subtracted.blockSignals(False)\n        self.Variable_int.stateChanged.connect(self.state_changed)\n        \n#                if self.spectrometer.variable_int_enabled:\n#                self.background_subtracted.blockSignals(True)\n#                self.background_subtracted.setCheckState(QtCore.Qt.Checked)\n#                self.background_subtracted.blockSignals(False)\n        self.average_checkBox.stateChanged.connect(self.state_changed)\n        self.Average_spinBox.valueChanged.connect(self.update_averages)\n        \n        self.referenceID_spinBox.valueChanged.connect(self.update_references)\n\n\n        self.id_string.setText('{0} {1}'.format(self.spectrometer.model_name, self.spectrometer.serial_number))\n        self.id_string.resize(self.id_string.sizeHint())\n\n        self.integration_time.setText(str(spectrometer.integration_time))\n\n        self.num_spectra_spinBox.valueChanged.connect(self.update_time_series_params)\n        self.delay_doubleSpinBox.valueChanged.connect(self.update_time_series_params)\n        self.time_series_name_lineEdit.textChanged.connect(self.update_time_series_name)\n        self.time_series_pushButton.clicked.connect(self.time_series)\n\n    def update_param(self, *args, **kwargs):\n        sender = self.sender()\n        if sender is self.integration_time:\n            try:\n                self.spectrometer.integration_time = float(args[0])\n            except ValueError:\n                pass\n            \n    def update_averages(self,*args,**kwargs):\n        self.spectrometer.spectra_deque = deque(maxlen = args[0])\n\n    def button_pressed(self, *args, **kwargs):\n        sender = self.sender()\n        if sender is self.read_background_button:\n            self.spectrometer.read_background()\n            self.background_subtracted.blockSignals(True)\n            self.background_subtracted.setCheckState(QtCore.Qt.Checked)\n            self.background_subtracted.blockSignals(False)            \n        elif sender is self.clear_background_button:\n            self.spectrometer.clear_background()\n            self.background_subtracted.blockSignals(True)\n            self.background_subtracted.setCheckState(QtCore.Qt.Unchecked)\n            self.background_subtracted.blockSignals(False)\n        elif sender is self.read_reference_button:\n            self.spectrometer.read_reference()\n            self.referenced.blockSignals(True)\n            self.referenced.setCheckState(QtCore.Qt.Checked)\n            self.referenced.blockSignals(False)\n        elif sender is self.clear_reference_button:\n            self.spectrometer.clear_reference()\n            self.referenced.blockSignals(True)\n            self.referenced.setCheckState(QtCore.Qt.Unchecked)\n            self.referenced.blockSignals(False)\n        elif sender is self.load_state_button:\n            if 'background' in self.spectrometer.config_file:\n                self.spectrometer.background = self.spectrometer.config_file['background'][:] #load the background\n                if 'background_constant' in self.spectrometer.config_file:\n                    self.spectrometer.background_constant = self.spectrometer.config_file['background_constant'][:]\n                if 'background_gradient' in self.spectrometer.config_file:\n                    self.spectrometer.background_gradient = self.spectrometer.config_file['background_gradient'][:]\n                if 'background_int' in self.spectrometer.config_file:\n                    self.spectrometer.background_int = self.spectrometer.config_file['background_int'][...]\n                    \n                self.background_subtracted.blockSignals(True)\n                self.background_subtracted.setCheckState(QtCore.Qt.Checked)\n                self.background_subtracted.blockSignals(False)\n            else:\n                print('background not found in config file')\n            if 'reference' in self.spectrometer.config_file:\n                self.spectrometer.reference = self.spectrometer.config_file['reference'][:]\n                if 'reference_int' in self.spectrometer.config_file:\n                    self.spectrometer.reference_int = self.spectrometer.config_file['reference_int'][...]\n                self.referenced.blockSignals(True)\n                self.referenced.setCheckState(QtCore.Qt.Checked)\n                self.referenced.blockSignals(False)\n            else:\n                print('reference not found in config file')\n                \n\n    def state_changed(self, state):\n        sender = self.sender()\n        if sender is self.background_subtracted and state == QtCore.Qt.Checked:\n            self.spectrometer.read_background()\n        elif sender is self.background_subtracted and state == QtCore.Qt.Unchecked:\n            self.spectrometer.clear_background()\n        if sender is self.referenced and state == QtCore.Qt.Checked:\n            self.spectrometer.read_reference()\n        elif sender is self.referenced and state == QtCore.Qt.Unchecked:\n            self.spectrometer.clear_reference()\n            \n        elif sender is self.Variable_int and\\\n        self.Variable_int.isChecked() != self.spectrometer.variable_int_enabled:\n            self.spectrometer.variable_int_enabled = not self.spectrometer.variable_int_enabled\n            \n        elif sender is self.average_checkBox:\n            self.spectrometer.averaging_enabled = not self.spectrometer.averaging_enabled\n            \n        elif sender is self.Absorption_checkBox:\n            self.spectrometer.absorption_enabled = not self.spectrometer.absorption_enabled\n        \n    def variable_int_state_change(self, new):\n        self.Variable_int.setChecked(new)\n            \n    def update_references(self,*args, **kwargs):\n        self.spectrometer.reference_ID = args[0]\n        try:\n            self.spectrometer.load_reference(self.spectrometer.reference_ID )\n        except KeyError:\n            self.spectrometer.clear_reference()\n            self.referenced.blockSignals(True)\n            self.referenced.setCheckState(QtCore.Qt.Unchecked)\n            self.referenced.blockSignals(False)\n            \n            self.spectrometer.clear_background()\n            self.background_subtracted.blockSignals(True)\n            self.background_subtracted.setCheckState(QtCore.Qt.Unchecked)\n            self.background_subtracted.blockSignals(False)\n\n\n            self.spectrometer._logger.info('No refence/background saved in slot %s to load' %args[0])\n            \n    def update_time_series_params(self):\n        self.spectrometer.num_spectra = int(self.num_spectra_spinBox.value())   \n        self.spectrometer.delay = float(self.delay_doubleSpinBox.value()) \n        self.time_total_lcdNumber.display(np.round(self.spectrometer.num_spectra*(self.spectrometer.integration_time + self.spectrometer.delay)/1000, decimals = 0))\n    def update_time_series_name(self):\n        self.spectrometer.time_series_name = self.time_series_name_lineEdit.text().strip()\n    def time_series(self):\n        run_function_modally(self.spectrometer.time_series, progress_maximum = self.spectrometer.num_spectra)",
  "class DisplayThread(QtCore.QThread):\n    spectrum_ready = QtCore.Signal(np.ndarray)\n    spectra_ready = QtCore.Signal(list)\n\n    def __init__(self, parent):\n        super(DisplayThread, self).__init__()\n        self.parent = parent\n        self.single_shot = False\n        self.refresh_rate = 30.\n\n    def run(self):\n        t0 = time.time()\n        while self.parent.live_button.isChecked() or self.single_shot:\n            read_processed_spectrum = self.parent.spectrometer.read_processed_spectra \\\n                if isinstance(self.parent.spectrometer, Spectrometers) \\\n                else self.parent.spectrometer.read_processed_spectrum\n            spectrum = read_processed_spectrum()\n            if time.time()-t0 < 1./self.refresh_rate:\n                continue\n            else:\n                t0 = time.time()\n            if type(spectrum) == np.ndarray:\n                self.spectrum_ready.emit(spectrum)\n            elif type(spectrum) == list:\n                self.spectra_ready.emit(spectrum)\n            if self.single_shot:\n                break\n        self.finished.emit()",
  "class SpectrometerDisplayUI(QtWidgets.QWidget,UiTools):\n    def __init__(self, spectrometer,ui_file = os.path.join(os.path.dirname(__file__),'spectrometer_view.ui'),\n                 parent=None):\n        assert isinstance(spectrometer, Spectrometer) or isinstance(spectrometer, Spectrometers),\\\n            \"instrument must be a Spectrometer or an instance of Spectrometers\"\n        super(SpectrometerDisplayUI, self).__init__()\n        uic.loadUi(ui_file, self)\n        if isinstance(spectrometer, Spectrometers) and spectrometer.num_spectrometers == 1:\n            spectrometer = spectrometer.spectrometers[0]\n        if isinstance(spectrometer,Spectrometer):\n            spectrometer.num_spectrometers = 1\n        self.spectrometer = spectrometer\n        print(self.spectrometer)\n        if spectrometer.dark:\n            pg.setConfigOption('background', (50, 65, 75))\n        else:\n             pg.setConfigOption('background', 'w')\n             pg.setConfigOption('foreground', 'k')\n        self.plotbox = QtWidgets.QGroupBox()\n        self.plotbox.setLayout(QtWidgets.QGridLayout())\n        self.plotlayout = self.plotbox.layout()          \n        self.plots =[]\n\n        for spectrometer_nom in range(self.spectrometer.num_spectrometers):\n            self.plots.append(pg.PlotWidget(labels = {'bottom':'Wavelength (nm)'}))\n            self.plotlayout.addWidget(self.plots[spectrometer_nom])\n\n        self.figure_widget = self.replace_widget(self.display_layout,\n                                                 self.figure_widget, self.plotbox)         \n        self.take_spectrum_button.clicked.connect(self.button_pressed)\n        self.live_button.clicked.connect(self.button_pressed)\n        self.save_button.clicked.connect(self.button_pressed)\n        self.threshold.setValidator(QtGui.QDoubleValidator())\n        self.threshold.textChanged.connect(self.check_state)\n        self._display_thread = DisplayThread(self)\n        self._display_thread.spectrum_ready.connect(self.update_display)\n        self._display_thread.spectra_ready.connect(self.update_display)\n\n        self.period = 0.2\n        self.filename_lineEdit.textChanged.connect(self.filename_changed_ui)\n       \n        register_for_property_changes(self.spectrometer,'filename',self.filename_changed)\n    def button_pressed(self, *args, **kwargs):\n        sender = self.sender()\n        if sender is self.take_spectrum_button:\n            #if self._display_thread.is_alive():\n            if self._display_thread.isRunning():\n                print('already acquiring')\n                return\n            #self._display_thread = Thread(target=self.update_spectrum)\n            self._display_thread.single_shot = True\n            self._display_thread.start()\n            #self.update_spectrum()\n        elif sender is self.save_button:\n            save_spectrum = self.spectrometer.save_spectra \\\n                if isinstance(self.spectrometer, Spectrometers) \\\n                else self.spectrometer.save_spectrum\n            save_spectrum(attrs={'description':str(self.description.text())})\n        elif sender is self.live_button:\n            if self.live_button.isChecked():\n                #if self._display_thread.is_alive():\n                if self._display_thread.isRunning():\n                    print('already acquiring')\n                    return\n                #self._display_thread = Thread(target=self.continuously_update_spectrum)\n                self._display_thread.single_shot = False\n                self._display_thread.start()\n\n    def update_spectrum(self):\n        read_processed_spectrum = self.spectrometer.read_processed_spectra \\\n            if isinstance(self.spectrometer, Spectrometers) \\\n            else self.spectrometer.read_processed_spectrum\n        spectrum = read_processed_spectrum()\n        self.update_display(spectrum)\n\n    def continuously_update_spectrum(self):\n        t0 = time.time()\n        while self.live_button.isChecked():\n            if time.time()-t0 < 1./30.:\n                continue\n            else:\n                t0 = time.time()\n            self.update_spectrum()\n\n    def update_display(self, spectrum):\n        #Update the graphs\n        if len(np.ravel(spectrum))>len(spectrum):# checking if it's 2d\n            spectrum = np.array([[0 if np.isnan(i) else i for i in s] for s in list(spectrum)])\n        else:\n            spectrum= np.array([0 if np.isnan(i) else i for i in spectrum])\n        wavelengths = self.spectrometer.wavelengths\n        if self.enable_threshold.checkState() == QtCore.Qt.Checked:\n            threshold = float(self.threshold.text())\n            if isinstance(self.spectrometer, Spectrometers):\n                spectrum = [spectrometer.mask_spectrum(s, threshold) for (spectrometer, s) in zip(self.spectrometer.spectrometers, spectrum)]\n            else:\n                spectrum = self.spectrometer.mask_spectrum(spectrum, threshold)\n                    \n        if not self.plots[0].getPlotItem().listDataItems():\n            self.plotdata = []\n            if isinstance(self.spectrometer, Spectrometers):\n                for spectrometer_nom in range(self.spectrometer.num_spectrometers):\n                    self.plotdata.append(self.plots[spectrometer_nom].plot(x = wavelengths[spectrometer_nom],y \\\n                    = spectrum[spectrometer_nom],pen =(spectrometer_nom,len(list(range(self.spectrometer.num_spectrometers))))))\n            else:                \n                self.plotdata.append(self.plots[0].plot(x = wavelengths,y = spectrum,pen =(0,len(list(range(self.spectrometer.num_spectrometers))))))\n        else:\n            if isinstance(self.spectrometer, Spectrometers):\n                for spectrometer_nom in range(self.spectrometer.num_spectrometers):\n                    self.plotdata[spectrometer_nom].setData(x = wavelengths[spectrometer_nom],y= spectrum[spectrometer_nom])\n            else:\n                self.plotdata[0].setData(x = wavelengths,y= spectrum)\n\n    def filename_changed_ui(self):\n        self.spectrometer.filename = self.filename_lineEdit.text()\n    def filename_changed(self):\n        self.filename_lineEdit.setText(self.spectrometer.filename)",
  "class SpectrometerUI(QtWidgets.QWidget):\n    \"\"\"\n    Joins together the control and display UIs into a single spectrometer UI.\n    \"\"\"\n\n    def __init__(self, spectrometer):\n        assert isinstance(spectrometer, Spectrometer), \"instrument must be a Spectrometer\"\n        super(SpectrometerUI, self).__init__()\n        self.spectrometer = spectrometer\n        self._init_ui()\n\n    def _init_ui(self):\n        self.setWindowTitle(self.spectrometer.__class__.__name__)\n        self.controls = self.spectrometer.get_qt_ui(control_only=True)\n        self.display = SpectrometerDisplayUI(self.spectrometer)\n        layout = QtWidgets.QVBoxLayout()\n    #    controls_layout = QtWidgets.QVBoxLayout()\n    #    controls_layout.addWidget(self.controls)\n    #    controls_layout.setContentsMargins(0,0,0,0)\n    #    controls_group = QtWidgets.QGroupBox()\n    #    controls_group.setTitle('Spectrometer')\n    #    controls_group.setLayout(controls_layout)\n        layout.addWidget(self.controls)\n        layout.addWidget(self.display)\n        layout.setContentsMargins(5,5,5,5)\n        layout.setSpacing(5)\n        self.setLayout(layout)",
  "class SpectrometersUI(QtWidgets.QWidget):\n    def __init__(self, spectrometers):\n        assert isinstance(spectrometers, Spectrometers), \"instrument must be an instance of Spectrometers\"\n        super(SpectrometersUI, self).__init__()\n        self.spectrometers = spectrometers\n        self._init_ui()\n\n    def _init_ui(self):\n        self.setWindowTitle('Spectrometers')\n        self.controls_layout = QtWidgets.QHBoxLayout()\n        controls_group = QtWidgets.QGroupBox()\n        controls_group.setTitle('Spectrometers')\n        controls_group.setLayout(self.controls_layout)\n        self.controls = []\n        for spectrometer in self.spectrometers.spectrometers:\n            control = spectrometer.get_qt_ui(control_only=True)\n            self.controls_layout.addWidget(control)\n            self.controls.append(control)\n        self.display = SpectrometerDisplayUI(self.spectrometers)\n        layout = QtWidgets.QVBoxLayout()\n        layout.addWidget(controls_group)\n        layout.addWidget(self.display)\n        self.setLayout(layout)",
  "class DummySpectrometer(Spectrometer):\n    \"\"\"A trivial stub spectrometer, for use in development.\"\"\"\n    metadata_property_names = [\"integration_time\", \"wavelengths\"]\n    def __init__(self):\n        super(DummySpectrometer, self).__init__()\n        self._integration_time = 10\n        self.background = np.zeros(len(self.wavelengths))\n        self.reference = np.ones(len(self.wavelengths))\n    def get_integration_time(self):\n        return self._integration_time\n\n    def set_integration_time(self, value):\n        self._integration_time = value\n\n    integration_time = property(get_integration_time, set_integration_time)\n\n    def get_wavelengths(self):\n        return np.arange(400,1200,1)\n\n    wavelengths = property(get_wavelengths)\n    \n    \n    def read_spectrum(self, bundle_metadata=False):\n        from time import sleep\n        sleep(self.integration_time/1000.)\n        if bundle_metadata:\n            return self.bundle_metadata(np.array([np.random.random() for wl in self.wavelengths])*self.integration_time/1000.0,\n                                    enable=bundle_metadata)\n        return np.array([np.random.random() for wl in self.wavelengths])*self.integration_time/1000.0",
  "def __init__(self):\n        super(Spectrometer, self).__init__()\n        self._model_name = None\n        self._serial_number = None\n        self._wavelengths = None\n        self.reference = None\n        self.background = None\n        self.background_constant =None\n        self.background_gradient = None\n        self.background_int = None\n        self.reference_int = None\n      #  self.variable_int_enabled = DumbNotifiedProperty(False)\n        self.latest_raw_spectrum = None\n        self.latest_spectrum = None\n        self.averaging_enabled = False\n        self.spectra_deque = deque(maxlen = 1)\n        self.absorption_enabled = False\n        self._config_file = None\n\n        self.stored_references = {}\n        self.stored_backgrounds = {}\n        self.reference_ID = 0\n        self.spectra_buffer = np.zeros(0)\n        self.data_file = df.current()\n        self.curr_scan=None\n        self.num_spectra = 1\n        self.delay = 0\n        self.time_series_name = 'time_series_%d'",
  "def __del__(self):\n        try:\n            self._config_file.close()\n        except AttributeError:\n            pass",
  "def open_config_file(self):\n        \"\"\"Open the config file for the current spectrometer and return it, creating if it's not there\"\"\"\n        if self._config_file is None:\n            f = inspect.getfile(self.__class__)\n            d = os.path.dirname(f)\n            self._config_file = DataFile(h5py.File(os.path.join(d, 'config.h5')))\n            self._config_file.attrs['date'] = datetime.datetime.now().strftime(\"%H:%M %d/%m/%y\")\n        return self._config_file",
  "def update_config(self, name, data, attrs= None):\n        \"\"\"Update the configuration file for this spectrometer.\n        \n        A file is created in the nplab directory that holds configuration\n        data for the spectrometer, including reference/background.  This\n        function allows values to be stored in that file.\"\"\"\n        f = self.config_file\n        if name not in f:\n            f.create_dataset(name, data=data ,attrs = attrs)\n        else:\n            dset = f[name]\n            dset[...] = data\n            f.flush()",
  "def get_model_name(self):\n        \"\"\"The model name of the spectrometer.\"\"\"\n        if self._model_name is None:\n            self._model_name = 'model_name'\n        return self._model_name",
  "def get_serial_number(self):\n        \"\"\"The spectrometer's serial number (as a string).\"\"\"\n        warnings.warn(\"Using the default implementation for get_serial_number: this should be overridden!\",DeprecationWarning)\n        if self._serial_number is None:\n            self._serial_number = 'serial_number'\n        return self._serial_number",
  "def get_integration_time(self):\n        \"\"\"The integration time of the spectrometer (this function is a stub)!\"\"\"\n        warnings.warn(\"Using the default implementation for integration time: this should be overridden!\",DeprecationWarning)\n        return 0",
  "def set_integration_time(self, value):\n        \"\"\"Set the integration time of the spectrometer (this is a stub)!\"\"\"\n        warnings.warn(\"Using the default implementation for integration time: this should be overridden!\",DeprecationWarning)\n        print('setting 0')",
  "def get_wavelengths(self):\n        \"\"\"An array of wavelengths corresponding to the spectrometer's pixels.\"\"\"\n        warnings.warn(\"Using the default implementation for wavelengths: this should be overridden!\",DeprecationWarning)\n\n        if self._wavelengths is None:\n            self._wavelengths = np.arange(400,1200,1)\n        return self._wavelengths",
  "def read_spectrum(self, bundle_metadata=False):\n        \"\"\"Take a reading on the spectrometer and return it\"\"\"\n        warnings.warn(\"Using the default implementation for read_spectrum: this should be overridden!\",DeprecationWarning)\n        self.latest_raw_spectrum = np.zeros(0)\n        return self.bundle_metadata(self.latest_raw_spectrum, enable=bundle_metadata)",
  "def read_background(self):\n        \"\"\"Acquire a new spectrum and use it as a background measurement.\n        This background should be less than 50% of the spectrometer saturation\"\"\"\n        if self.averaging_enabled == True:\n            background_1 = np.average(self.read_averaged_spectrum(True,True),axis=0)\n        else:\n            background_1 = self.read_spectrum()\n        self.integration_time = 2.0*self.integration_time\n        if self.averaging_enabled == True:\n            background_2 = np.average(self.read_averaged_spectrum(True,True),axis=0)\n        else:\n            background_2 = self.read_spectrum()\n        self.integration_time = self.integration_time/2.0\n        self.background_gradient = (background_2-background_1)/self.integration_time\n        self.background_constant = background_1-(self.integration_time*self.background_gradient)\n        self.background = background_1\n        self.background_int = self.integration_time\n        self.stored_backgrounds[self.reference_ID] = {'background_gradient' : self.background_gradient,\n                                                     'background_constant' : self.background_constant,\n                                                     'background' : self.background,\n                                                     'background_int': self.background_int}\n        self.update_config('background_gradient', self.background_gradient)\n        self.update_config('background_constant', self.background_constant)\n        self.update_config('background', self.background)\n        self.update_config('background_int', self.background_int)",
  "def clear_background(self):\n        \"\"\"Clear the current background reading.\"\"\"\n        self.background = None\n        self.background_gradient = None\n        self.background_constant = None\n        self.background_int = None",
  "def read_reference(self):\n        \"\"\"Acquire a new spectrum and use it as a reference.\"\"\"\n        if self.averaging_enabled == True:\n            self.reference = np.average(self.read_averaged_spectrum(True,True),axis=0)\n        else:\n            self.reference = self.read_spectrum() \n        self.reference_int = self.integration_time\n        self.update_config('reference', self.reference)\n        self.update_config('reference_int',self.reference_int) \n        self.stored_references[self.reference_ID] = {'reference' : self.reference,\n                                                    'reference_int' : self.reference_int}",
  "def load_reference(self,ID):\n        for attr in self.stored_backgrounds[ID]:\n            setattr(self,attr,self.stored_backgrounds[ID][attr])\n        for attr in self.stored_references[ID]:\n            setattr(self,attr,self.stored_references[ID][attr])",
  "def clear_reference(self):\n        \"\"\"Clear the current reference spectrum\"\"\"\n        self.reference = None\n        self.reference_int = None",
  "def is_background_compensated(self):\n        \"\"\"Return whether there's currently a valid background spectrum\"\"\"\n        return len(self.background)==len(self.latest_raw_spectrum) and \\\n            sum(self.background)>0",
  "def is_referenced(self):\n        \"\"\"Check whether there's currently a valid background and reference spectrum\"\"\"\n        try:\n            return self.is_background_compensated and \\\n                len(self.reference)==len(self.latest_raw_spectrum) and \\\n                sum(self.reference)>0\n        except TypeError:\n            return False",
  "def process_spectrum(self, spectrum):\n        \"\"\"Subtract the background and divide by the reference, if possible\"\"\"\n        if self.background is not None:\n            if self.reference is not None:\n                old_error_settings = np.seterr(all='ignore')\n           #     new_spectrum = (spectrum - (self.background-np.min(self.background))*self.integration_time/self.background_int+np.min(self.background))/(((self.reference-np.min(self.background))*self.integration_time/self.reference_int - (self.background-np.min(self.background))*self.integration_time/self.background_int)+np.min(self.background))\n                if self.variable_int_enabled == True:\n                    new_spectrum = ((spectrum-(self.background_constant+self.background_gradient*self.integration_time))/((self.reference-(self.background_constant+self.background_gradient*self.reference_int))*self.integration_time/self.reference_int))\n                else:\n                    new_spectrum = (spectrum-self.background)/(self.reference-self.background)\n                np.seterr(**old_error_settings)\n                new_spectrum[np.isinf(new_spectrum)] = np.NaN #if the reference is nearly 0, we get infinities - just make them all NaNs.\n            else:\n                if self.variable_int_enabled == True:\n                    new_spectrum = spectrum-(self.background_constant+self.background_gradient*self.integration_time)\n                else:\n                    new_spectrum = spectrum-self.background\n                \n        else:\n            new_spectrum = spectrum\n        if self.absorption_enabled == True:\n            return np.log10(1/new_spectrum)\n        return new_spectrum",
  "def read_processed_spectrum(self):\n        \"\"\"Acquire a new spectrum and return a processed (referenced/background-subtracted) spectrum.\n        \n        NB if saving data to file, it's best to save raw spectra along with metadata - this is a\n        convenience method for display purposes.\"\"\"\n        if self.averaging_enabled == True:\n            spectrum = np.average(self.read_averaged_spectrum(fresh = True),axis=0)\n        else:\n            spectrum = self.read_spectrum()\n        self.latest_spectrum = self.process_spectrum(spectrum)\n        return self.latest_spectrum",
  "def read(self):\n        \"\"\"Acquire a new spectrum and return a tuple of wavelengths, spectrum\"\"\"\n        return self.wavelengths, self.read_processed_spectrum()",
  "def mask_spectrum(self, spectrum, threshold):\n        \"\"\"Return a masked array of the spectrum, showing only points where the reference\n        is bright enough to be useful.\"\"\"\n        if self.reference is not None and self.background is not None:\n            reference = self.reference - self.background\n            mask = reference < reference.max() * threshold\n            if len(spectrum.shape)>1:\n                mask = np.tile(mask, spectrum.shape[:-1]+(1,))\n            return ma.array(spectrum, mask=mask)\n        else:\n            return spectrum",
  "def get_qt_ui(self, control_only=False,display_only = False):\n        \"\"\"Create a Qt interface for the spectrometer\"\"\"\n        \n        if control_only:\n            \n            newwidget = SpectrometerControlUI(self)\n            self._preview_widgets.add(newwidget)\n            return newwidget\n        elif display_only:\n            return SpectrometerDisplayUI(self)\n        else:\n            return SpectrometerUI(self)",
  "def get_control_widget(self):\n        \"\"\"Convenience function \"\"\"\n        return self.get_qt_ui(control_only=True)",
  "def get_preview_widget(self):\n        \"\"\"Convenience function \"\"\"\n        return self.get_qt_ui(display_only=True)",
  "def save_spectrum(self, spectrum=None, attrs={}, new_deque = False):\n        \"\"\"Save a spectrum to the current datafile, creating if necessary.\n        \n        If no spectrum is passed in, a new spectrum is taken.  The convention\n        is to save raw spectra only, along with reference/background to allow\n        later processing.\n        \n        The attrs dictionary allows extra metadata to be saved in the HDF5 file.\"\"\"\n        if self.averaging_enabled == True:\n            spectrum = self.read_averaged_spectrum(new_deque = new_deque)\n        else:\n            spectrum = self.read_spectrum() if spectrum is None else spectrum\n        metadata = self.metadata\n        metadata.update(attrs) #allow extra metadata to be passed in\n        self.create_dataset(self.filename, data=spectrum, attrs=metadata)",
  "def read_averaged_spectrum(self,new_deque = False,fresh = False):\n            if fresh == True:\n                self.spectra_deque.append(self.read_spectrum())\n            if new_deque == True:\n                self.spectra_deque.clear()\n            while len(self.spectra_deque) < self.spectra_deque.maxlen:\n                self.spectra_deque.append(self.read_spectrum())\n            return self.spectra_deque",
  "def save_reference_to_file(self):\n        pass",
  "def load_reference_from_file(self):\n        pass",
  "def time_series(self, num_spectra = None, delay = None, update_progress = lambda p:p):# delay in ms\n        if num_spectra is None:\n            num_spectra = self.num_spectra\n        if delay is None:\n            delay = self.delay\n        delay/=1000\n        update_progress(0)\n        metadata = self.metadata\n        extra_metadata = {'number of spectra' : num_spectra,\n                          'spectrum end-to-start delay' : delay\n                           }\n        metadata.update(extra_metadata) \n        to_save = []\n        times = []\n        start = time.time()\n        for spectrum_number in range(num_spectra):\n            times.append(time.time() - start)\n            to_save.append(self.read_spectrum()) # should be a numpy array\n            time.sleep(delay)\n            update_progress(spectrum_number)\n        metadata.update({'start times' : times})\n        self.create_dataset(self.time_series_name, data=to_save, attrs=metadata)\n        to_return = ArrayWithAttrs(to_save, attrs = metadata)\n        return to_return",
  "def __init__(self, spectrometer_list):\n        assert False not in [isinstance(s, Spectrometer) for s in spectrometer_list],\\\n            'an invalid spectrometer was supplied'\n        super(Spectrometers, self).__init__()\n        self.spectrometers = spectrometer_list\n        self.num_spectrometers = len(spectrometer_list)\n        self._pool = ThreadPool(processes=self.num_spectrometers)\n        self._wavelengths = None\n        filename = DumbNotifiedProperty('spectra')",
  "def __del__(self):\n        self._pool.close()",
  "def add_spectrometer(self, spectrometer):\n        assert isinstance(spectrometer, Spectrometer), 'spectrometer must be an instance of Spectrometer'\n        if spectrometer not in self.spectrometers:\n            self.spectrometers.append(spectrometer)\n            self.num_spectrometers = len(self.spectrometers)",
  "def get_wavelengths(self):\n        if self._wavelengths is None:\n            self._wavelengths = [s.wavelengths for s in self.spectrometers]\n        return self._wavelengths",
  "def read_spectra(self):\n        \"\"\"Acquire spectra from all spectrometers and return as a list.\"\"\"\n        return self._pool.map(lambda s: s.read_spectrum(), self.spectrometers)",
  "def read_processed_spectra(self):\n        \"\"\"Acquire a list of processed (referenced, background subtracted) spectra.\"\"\"\n        return self._pool.map(lambda s: s.read_processed_spectrum(), self.spectrometers)",
  "def process_spectra(self, spectra):\n        pairs = list(zip(self.spectrometers, spectra))\n        return self._pool.map(lambda s_spectrum: s_spectrum[0].process_spectrum(s_spectrum[1]), pairs)",
  "def get_metadata_list(self):\n        \"\"\"Return a list of metadata for each spectrometer.\"\"\"\n        return self._pool.map(lambda s: s.get_metadata(), self.spectrometers)",
  "def mask_spectra(self, spectra, threshold):\n        return [spectrometer.mask_spectrum(spectrum, threshold) for (spectrometer, spectrum) in zip(self.spectrometers, spectra)]",
  "def get_qt_ui(self):\n        return SpectrometersUI(self)",
  "def save_spectra(self, spectra=None, attrs={}):\n        \"\"\"Save spectra from all the spectrometers, in a folder in the current\n        datafile, creating the file if needed.\n\n        If no spectra are given, new ones are acquired - NB you should pass\n        raw spectra in - metadata will be saved along with the spectra.\n        \"\"\"\n        spectra = self.read_spectra() if spectra is None else spectra\n        metadata_list = self.get_metadata_list()\n        g = self.create_data_group(self.filename,attrs=attrs) # create a uniquely numbered group in the default place\n        for spectrum,metadata in zip(spectra,metadata_list):\n            g.create_dataset('spectrum_%d',data=spectrum,attrs=metadata)",
  "def get_metadata(self):\n        \"\"\"\n        Returns a list of dictionaries containing relevant spectrometer properties\n        for each spectrometer.\n        \"\"\"\n        return [spectrometer.metadata for spectrometer in self.spectrometers]",
  "def __init__(self, spectrometer, ui_file =os.path.join(os.path.dirname(__file__),'spectrometer_controls.ui'),  parent=None):\n        assert isinstance(spectrometer, Spectrometer), \"instrument must be a Spectrometer\"\n        super(SpectrometerControlUI, self).__init__()\n        uic.loadUi(ui_file, self)\n        self.spectrometer = spectrometer\n        \n        self.integration_time.setValidator(QtGui.QDoubleValidator())\n        self.integration_time.textChanged.connect(self.check_state)\n        self.integration_time.textChanged.connect(self.update_param)\n\n        self.read_background_button.clicked.connect(self.button_pressed)\n        self.read_reference_button.clicked.connect(self.button_pressed)\n        self.clear_background_button.clicked.connect(self.button_pressed)\n        self.clear_reference_button.clicked.connect(self.button_pressed)\n        self.load_state_button.clicked.connect(self.button_pressed)\n\n        self.background_subtracted.stateChanged.connect(self.state_changed)\n        self.referenced.stateChanged.connect(self.state_changed)\n        \n        self.Absorption_checkBox.stateChanged.connect(self.state_changed)\n                \n        register_for_property_changes(self.spectrometer,'variable_int_enabled',self.variable_int_state_change)\n#        if self.spectrometer.variable_int_enabled:\n#                self.background_subtracted.blockSignals(True)\n#                self.background_subtracted.setCheckState(QtCore.Qt.Checked)\n#                self.background_subtracted.blockSignals(False)\n        self.Variable_int.stateChanged.connect(self.state_changed)\n        \n#                if self.spectrometer.variable_int_enabled:\n#                self.background_subtracted.blockSignals(True)\n#                self.background_subtracted.setCheckState(QtCore.Qt.Checked)\n#                self.background_subtracted.blockSignals(False)\n        self.average_checkBox.stateChanged.connect(self.state_changed)\n        self.Average_spinBox.valueChanged.connect(self.update_averages)\n        \n        self.referenceID_spinBox.valueChanged.connect(self.update_references)\n\n\n        self.id_string.setText('{0} {1}'.format(self.spectrometer.model_name, self.spectrometer.serial_number))\n        self.id_string.resize(self.id_string.sizeHint())\n\n        self.integration_time.setText(str(spectrometer.integration_time))\n\n        self.num_spectra_spinBox.valueChanged.connect(self.update_time_series_params)\n        self.delay_doubleSpinBox.valueChanged.connect(self.update_time_series_params)\n        self.time_series_name_lineEdit.textChanged.connect(self.update_time_series_name)\n        self.time_series_pushButton.clicked.connect(self.time_series)",
  "def update_param(self, *args, **kwargs):\n        sender = self.sender()\n        if sender is self.integration_time:\n            try:\n                self.spectrometer.integration_time = float(args[0])\n            except ValueError:\n                pass",
  "def update_averages(self,*args,**kwargs):\n        self.spectrometer.spectra_deque = deque(maxlen = args[0])",
  "def button_pressed(self, *args, **kwargs):\n        sender = self.sender()\n        if sender is self.read_background_button:\n            self.spectrometer.read_background()\n            self.background_subtracted.blockSignals(True)\n            self.background_subtracted.setCheckState(QtCore.Qt.Checked)\n            self.background_subtracted.blockSignals(False)            \n        elif sender is self.clear_background_button:\n            self.spectrometer.clear_background()\n            self.background_subtracted.blockSignals(True)\n            self.background_subtracted.setCheckState(QtCore.Qt.Unchecked)\n            self.background_subtracted.blockSignals(False)\n        elif sender is self.read_reference_button:\n            self.spectrometer.read_reference()\n            self.referenced.blockSignals(True)\n            self.referenced.setCheckState(QtCore.Qt.Checked)\n            self.referenced.blockSignals(False)\n        elif sender is self.clear_reference_button:\n            self.spectrometer.clear_reference()\n            self.referenced.blockSignals(True)\n            self.referenced.setCheckState(QtCore.Qt.Unchecked)\n            self.referenced.blockSignals(False)\n        elif sender is self.load_state_button:\n            if 'background' in self.spectrometer.config_file:\n                self.spectrometer.background = self.spectrometer.config_file['background'][:] #load the background\n                if 'background_constant' in self.spectrometer.config_file:\n                    self.spectrometer.background_constant = self.spectrometer.config_file['background_constant'][:]\n                if 'background_gradient' in self.spectrometer.config_file:\n                    self.spectrometer.background_gradient = self.spectrometer.config_file['background_gradient'][:]\n                if 'background_int' in self.spectrometer.config_file:\n                    self.spectrometer.background_int = self.spectrometer.config_file['background_int'][...]\n                    \n                self.background_subtracted.blockSignals(True)\n                self.background_subtracted.setCheckState(QtCore.Qt.Checked)\n                self.background_subtracted.blockSignals(False)\n            else:\n                print('background not found in config file')\n            if 'reference' in self.spectrometer.config_file:\n                self.spectrometer.reference = self.spectrometer.config_file['reference'][:]\n                if 'reference_int' in self.spectrometer.config_file:\n                    self.spectrometer.reference_int = self.spectrometer.config_file['reference_int'][...]\n                self.referenced.blockSignals(True)\n                self.referenced.setCheckState(QtCore.Qt.Checked)\n                self.referenced.blockSignals(False)\n            else:\n                print('reference not found in config file')",
  "def state_changed(self, state):\n        sender = self.sender()\n        if sender is self.background_subtracted and state == QtCore.Qt.Checked:\n            self.spectrometer.read_background()\n        elif sender is self.background_subtracted and state == QtCore.Qt.Unchecked:\n            self.spectrometer.clear_background()\n        if sender is self.referenced and state == QtCore.Qt.Checked:\n            self.spectrometer.read_reference()\n        elif sender is self.referenced and state == QtCore.Qt.Unchecked:\n            self.spectrometer.clear_reference()\n            \n        elif sender is self.Variable_int and\\\n        self.Variable_int.isChecked() != self.spectrometer.variable_int_enabled:\n            self.spectrometer.variable_int_enabled = not self.spectrometer.variable_int_enabled\n            \n        elif sender is self.average_checkBox:\n            self.spectrometer.averaging_enabled = not self.spectrometer.averaging_enabled\n            \n        elif sender is self.Absorption_checkBox:\n            self.spectrometer.absorption_enabled = not self.spectrometer.absorption_enabled",
  "def variable_int_state_change(self, new):\n        self.Variable_int.setChecked(new)",
  "def update_references(self,*args, **kwargs):\n        self.spectrometer.reference_ID = args[0]\n        try:\n            self.spectrometer.load_reference(self.spectrometer.reference_ID )\n        except KeyError:\n            self.spectrometer.clear_reference()\n            self.referenced.blockSignals(True)\n            self.referenced.setCheckState(QtCore.Qt.Unchecked)\n            self.referenced.blockSignals(False)\n            \n            self.spectrometer.clear_background()\n            self.background_subtracted.blockSignals(True)\n            self.background_subtracted.setCheckState(QtCore.Qt.Unchecked)\n            self.background_subtracted.blockSignals(False)\n\n\n            self.spectrometer._logger.info('No refence/background saved in slot %s to load' %args[0])",
  "def update_time_series_params(self):\n        self.spectrometer.num_spectra = int(self.num_spectra_spinBox.value())   \n        self.spectrometer.delay = float(self.delay_doubleSpinBox.value()) \n        self.time_total_lcdNumber.display(np.round(self.spectrometer.num_spectra*(self.spectrometer.integration_time + self.spectrometer.delay)/1000, decimals = 0))",
  "def update_time_series_name(self):\n        self.spectrometer.time_series_name = self.time_series_name_lineEdit.text().strip()",
  "def time_series(self):\n        run_function_modally(self.spectrometer.time_series, progress_maximum = self.spectrometer.num_spectra)",
  "def __init__(self, parent):\n        super(DisplayThread, self).__init__()\n        self.parent = parent\n        self.single_shot = False\n        self.refresh_rate = 30.",
  "def run(self):\n        t0 = time.time()\n        while self.parent.live_button.isChecked() or self.single_shot:\n            read_processed_spectrum = self.parent.spectrometer.read_processed_spectra \\\n                if isinstance(self.parent.spectrometer, Spectrometers) \\\n                else self.parent.spectrometer.read_processed_spectrum\n            spectrum = read_processed_spectrum()\n            if time.time()-t0 < 1./self.refresh_rate:\n                continue\n            else:\n                t0 = time.time()\n            if type(spectrum) == np.ndarray:\n                self.spectrum_ready.emit(spectrum)\n            elif type(spectrum) == list:\n                self.spectra_ready.emit(spectrum)\n            if self.single_shot:\n                break\n        self.finished.emit()",
  "def __init__(self, spectrometer,ui_file = os.path.join(os.path.dirname(__file__),'spectrometer_view.ui'),\n                 parent=None):\n        assert isinstance(spectrometer, Spectrometer) or isinstance(spectrometer, Spectrometers),\\\n            \"instrument must be a Spectrometer or an instance of Spectrometers\"\n        super(SpectrometerDisplayUI, self).__init__()\n        uic.loadUi(ui_file, self)\n        if isinstance(spectrometer, Spectrometers) and spectrometer.num_spectrometers == 1:\n            spectrometer = spectrometer.spectrometers[0]\n        if isinstance(spectrometer,Spectrometer):\n            spectrometer.num_spectrometers = 1\n        self.spectrometer = spectrometer\n        print(self.spectrometer)\n        if spectrometer.dark:\n            pg.setConfigOption('background', (50, 65, 75))\n        else:\n             pg.setConfigOption('background', 'w')\n             pg.setConfigOption('foreground', 'k')\n        self.plotbox = QtWidgets.QGroupBox()\n        self.plotbox.setLayout(QtWidgets.QGridLayout())\n        self.plotlayout = self.plotbox.layout()          \n        self.plots =[]\n\n        for spectrometer_nom in range(self.spectrometer.num_spectrometers):\n            self.plots.append(pg.PlotWidget(labels = {'bottom':'Wavelength (nm)'}))\n            self.plotlayout.addWidget(self.plots[spectrometer_nom])\n\n        self.figure_widget = self.replace_widget(self.display_layout,\n                                                 self.figure_widget, self.plotbox)         \n        self.take_spectrum_button.clicked.connect(self.button_pressed)\n        self.live_button.clicked.connect(self.button_pressed)\n        self.save_button.clicked.connect(self.button_pressed)\n        self.threshold.setValidator(QtGui.QDoubleValidator())\n        self.threshold.textChanged.connect(self.check_state)\n        self._display_thread = DisplayThread(self)\n        self._display_thread.spectrum_ready.connect(self.update_display)\n        self._display_thread.spectra_ready.connect(self.update_display)\n\n        self.period = 0.2\n        self.filename_lineEdit.textChanged.connect(self.filename_changed_ui)\n       \n        register_for_property_changes(self.spectrometer,'filename',self.filename_changed)",
  "def button_pressed(self, *args, **kwargs):\n        sender = self.sender()\n        if sender is self.take_spectrum_button:\n            #if self._display_thread.is_alive():\n            if self._display_thread.isRunning():\n                print('already acquiring')\n                return\n            #self._display_thread = Thread(target=self.update_spectrum)\n            self._display_thread.single_shot = True\n            self._display_thread.start()\n            #self.update_spectrum()\n        elif sender is self.save_button:\n            save_spectrum = self.spectrometer.save_spectra \\\n                if isinstance(self.spectrometer, Spectrometers) \\\n                else self.spectrometer.save_spectrum\n            save_spectrum(attrs={'description':str(self.description.text())})\n        elif sender is self.live_button:\n            if self.live_button.isChecked():\n                #if self._display_thread.is_alive():\n                if self._display_thread.isRunning():\n                    print('already acquiring')\n                    return\n                #self._display_thread = Thread(target=self.continuously_update_spectrum)\n                self._display_thread.single_shot = False\n                self._display_thread.start()",
  "def update_spectrum(self):\n        read_processed_spectrum = self.spectrometer.read_processed_spectra \\\n            if isinstance(self.spectrometer, Spectrometers) \\\n            else self.spectrometer.read_processed_spectrum\n        spectrum = read_processed_spectrum()\n        self.update_display(spectrum)",
  "def continuously_update_spectrum(self):\n        t0 = time.time()\n        while self.live_button.isChecked():\n            if time.time()-t0 < 1./30.:\n                continue\n            else:\n                t0 = time.time()\n            self.update_spectrum()",
  "def update_display(self, spectrum):\n        #Update the graphs\n        if len(np.ravel(spectrum))>len(spectrum):# checking if it's 2d\n            spectrum = np.array([[0 if np.isnan(i) else i for i in s] for s in list(spectrum)])\n        else:\n            spectrum= np.array([0 if np.isnan(i) else i for i in spectrum])\n        wavelengths = self.spectrometer.wavelengths\n        if self.enable_threshold.checkState() == QtCore.Qt.Checked:\n            threshold = float(self.threshold.text())\n            if isinstance(self.spectrometer, Spectrometers):\n                spectrum = [spectrometer.mask_spectrum(s, threshold) for (spectrometer, s) in zip(self.spectrometer.spectrometers, spectrum)]\n            else:\n                spectrum = self.spectrometer.mask_spectrum(spectrum, threshold)\n                    \n        if not self.plots[0].getPlotItem().listDataItems():\n            self.plotdata = []\n            if isinstance(self.spectrometer, Spectrometers):\n                for spectrometer_nom in range(self.spectrometer.num_spectrometers):\n                    self.plotdata.append(self.plots[spectrometer_nom].plot(x = wavelengths[spectrometer_nom],y \\\n                    = spectrum[spectrometer_nom],pen =(spectrometer_nom,len(list(range(self.spectrometer.num_spectrometers))))))\n            else:                \n                self.plotdata.append(self.plots[0].plot(x = wavelengths,y = spectrum,pen =(0,len(list(range(self.spectrometer.num_spectrometers))))))\n        else:\n            if isinstance(self.spectrometer, Spectrometers):\n                for spectrometer_nom in range(self.spectrometer.num_spectrometers):\n                    self.plotdata[spectrometer_nom].setData(x = wavelengths[spectrometer_nom],y= spectrum[spectrometer_nom])\n            else:\n                self.plotdata[0].setData(x = wavelengths,y= spectrum)",
  "def filename_changed_ui(self):\n        self.spectrometer.filename = self.filename_lineEdit.text()",
  "def filename_changed(self):\n        self.filename_lineEdit.setText(self.spectrometer.filename)",
  "def __init__(self, spectrometer):\n        assert isinstance(spectrometer, Spectrometer), \"instrument must be a Spectrometer\"\n        super(SpectrometerUI, self).__init__()\n        self.spectrometer = spectrometer\n        self._init_ui()",
  "def _init_ui(self):\n        self.setWindowTitle(self.spectrometer.__class__.__name__)\n        self.controls = self.spectrometer.get_qt_ui(control_only=True)\n        self.display = SpectrometerDisplayUI(self.spectrometer)\n        layout = QtWidgets.QVBoxLayout()\n    #    controls_layout = QtWidgets.QVBoxLayout()\n    #    controls_layout.addWidget(self.controls)\n    #    controls_layout.setContentsMargins(0,0,0,0)\n    #    controls_group = QtWidgets.QGroupBox()\n    #    controls_group.setTitle('Spectrometer')\n    #    controls_group.setLayout(controls_layout)\n        layout.addWidget(self.controls)\n        layout.addWidget(self.display)\n        layout.setContentsMargins(5,5,5,5)\n        layout.setSpacing(5)\n        self.setLayout(layout)",
  "def __init__(self, spectrometers):\n        assert isinstance(spectrometers, Spectrometers), \"instrument must be an instance of Spectrometers\"\n        super(SpectrometersUI, self).__init__()\n        self.spectrometers = spectrometers\n        self._init_ui()",
  "def _init_ui(self):\n        self.setWindowTitle('Spectrometers')\n        self.controls_layout = QtWidgets.QHBoxLayout()\n        controls_group = QtWidgets.QGroupBox()\n        controls_group.setTitle('Spectrometers')\n        controls_group.setLayout(self.controls_layout)\n        self.controls = []\n        for spectrometer in self.spectrometers.spectrometers:\n            control = spectrometer.get_qt_ui(control_only=True)\n            self.controls_layout.addWidget(control)\n            self.controls.append(control)\n        self.display = SpectrometerDisplayUI(self.spectrometers)\n        layout = QtWidgets.QVBoxLayout()\n        layout.addWidget(controls_group)\n        layout.addWidget(self.display)\n        self.setLayout(layout)",
  "def __init__(self):\n        super(DummySpectrometer, self).__init__()\n        self._integration_time = 10\n        self.background = np.zeros(len(self.wavelengths))\n        self.reference = np.ones(len(self.wavelengths))",
  "def get_integration_time(self):\n        return self._integration_time",
  "def set_integration_time(self, value):\n        self._integration_time = value",
  "def get_wavelengths(self):\n        return np.arange(400,1200,1)",
  "def read_spectrum(self, bundle_metadata=False):\n        from time import sleep\n        sleep(self.integration_time/1000.)\n        if bundle_metadata:\n            return self.bundle_metadata(np.array([np.random.random() for wl in self.wavelengths])*self.integration_time/1000.0,\n                                    enable=bundle_metadata)\n        return np.array([np.random.random() for wl in self.wavelengths])*self.integration_time/1000.0",
  "class Shamrock(Instrument):\n    def __init__(self):\n        super(Shamrock,self).__init__()\n        #for Windows\n        architecture = platform.architecture()\n        \n        if architecture[0] == \"64bit\":\n            self.dll2 = CDLL(\"C:\\\\Program Files\\\\Andor SOLIS\\\\Drivers\\\\Shamrock64\\\\atshamrock\")\n            self.dll = CDLL(\"C:\\\\Program Files\\\\Andor SOLIS\\\\Drivers\\\\Shamrock64\\\\ShamrockCIF\")\n            tekst = c_char()        \n            error = self.dll.ShamrockInitialize(byref(tekst))\n\n        elif architecture[0] == \"32bit\":\n            self.dll2 = WinDLL(\"C:\\\\Program Files\\\\Andor SDK\\\\Shamrock\\\\atshamrock.dll\")\n            self.dll = WinDLL(\"C:\\\\Program Files\\\\Andor SDK\\\\Shamrock\\\\ShamrockCIF.dll\")\n            tekst = c_char_p(\"\")     \n            error = self.dll.ShamrockInitialize(tekst)\n            \n        self.current_shamrock = 0 #for more than one Shamrock this has to be varied, see ShamrockGetNumberDevices\n        self._logger.setLevel('WARN')\n\n    def verbose(self, error, function=''):\n        self.log( \"[%s]: %s\" %(function, error),level = 'info')\n    \n    #basic Shamrock features    \n    def Initialize(self):\n        error = self.dll.ShamrockInitialize(\"\")\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n    \n    def GetNumberDevices(self):\n        no_shamrocks = c_int()\n        error = self.dll.ShamrockGetNumberDevices(byref(no_shamrocks))\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n        return no_shamrocks.value\n    num_shamrocks = property(GetNumberDevices)   \n    \n    def Close(self):\n        error = self.dll.ShamrockClose()\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n\n    \n    def GetSerialNumber(self):\n        ShamrockSN = c_char()\n        error = self.dll.ShamrockGetSerialNumber(self.current_shamrock, byref(ShamrockSN))\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n        return ShamrockSN\n    serial_number = property(GetSerialNumber)\n    \n    \n    def EepromGetOpticalParams(self):\n        self.FocalLength = c_float()\n        self.AngularDeviation = c_float()\n        self.FocalTilt = c_float()\n        error = self.dll.ShamrockEepromGetOpticalParams(self.current_shamrock, byref(self.FocalLength), byref(self.AngularDeviation), byref(self.FocalTilt))\n        return {'FocalLength':self.FocalLength,'AngularDeviation':self.AngularDeviation,'FocalTilt':self.FocalTilt}\n        \n    #basic Grating features\n    def GratingIsPresent(self):\n        is_present = c_int()\n        error = self.dll.ShamrockGratingIsPresent(self.current_shamrock,is_present)\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n        return is_present.vlaue\n    grating_present = property(GratingIsPresent)\n    \n    \n    def GetTurret(self):\n        Turret = c_int()\n        error = self.dll.ShamrockGetTurret(self.current_shamrock,byref(Turret))\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n        return Turret.value\n    def SetTurret(self,turret):\n        error = self.dll.ShamrockSetTurret(self.current_shamrock,c_int(turret))\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n    \n    turret_position = NotifiedProperty(GetTurret,SetTurret)\n    \n    def GetNumberGratings(self):\n        self.noGratings = c_int()\n        error = self.dll.ShamrockGetNumberGratings(self.current_shamrock,byref(self.noGratings))\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n        return self.noGratings\n    num_gratings = property(GetNumberGratings)\n\n    \n    def GetGrating(self):\n        grating = c_int()\n        error = self.dll.ShamrockGetGrating(self.current_shamrock,byref(grating))\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n        return grating.value\n    def SetGrating(self,grating_num):\n        grating_num = int(grating_num)\n        grating = c_int(grating_num)\n        error = self.dll.ShamrockSetGrating(self.current_shamrock,grating)\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n    current_grating = NotifiedProperty(GetGrating,SetGrating)    \n    def GetGratingInfo(self):    \n        lines = c_float()\n        blaze = c_char()\n        home = c_int()                \n        offset = c_int()        \n        error = self.dll.ShamrockGetGratingInfo(self.current_shamrock,self.current_grating,byref(lines),byref(blaze),byref(home),byref(offset))\n        CurrGratingInfo = [lines.value,blaze.value,home.value,offset.value]\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n        return CurrGratingInfo\n    GratingInfo = property(GetGratingInfo)\n    \n    def GetGratingOffset(self):\n        GratingOffset = c_int() #not this is in steps, so int\n        error = self.dll.ShamrockGetGratingOffset(self.current_shamrock,self.current_grating,byref(GratingOffset))\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n        return GratingOffset\n    def SetGratingOffset(self,offset):\n        error = self.dll.ShamrockSetGratingOffset(self.current_shamrock,self.current_grating,c_int(offset))\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n    Grating_offset = NotifiedProperty(GetGratingOffset,SetGratingOffset)\n    \n    def GetDetectorOffset(self):\n        DetectorOffset = c_int() #note this is in steps, so int\n        #error = self.dll.ShamrockGetDetectorOffset(self.current_shamrock,byref(self.DetectorOffset))\n        error = self.dll.ShamrockGetDetectorOffset(self.current_shamrock,byref(DetectorOffset))\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n        return DetectorOffset.value\n    def SetDetectorOffset(self,offset):\n        error = self.dll.ShamrockSetDetectorOffset(self.current_shamrock,self.current_grating,c_int(offset))\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n    \n    detector_offset = NotifiedProperty(GetDetectorOffset,SetDetectorOffset)\n        \n\n    \n    #Wavelength features\n    def WavelengthIsPresent(self):\n        ispresent = c_int()\n        error = self.dll.ShamrockWavelengthIsPresent(self.current_shamrock,byref(ispresent))\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n        return ispresent.value\n    motor_present = property(WavelengthIsPresent)\n        \n    def GetWavelength(self):\n        curr_wave = c_float()\n        error = self.dll.ShamrockGetWavelength(self.current_shamrock,byref(curr_wave))\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n        return curr_wave.value\n    def SetWavelength(self,centre_wl):\n        error = self.dll.ShamrockSetWavelength(self.current_shamrock,c_float(centre_wl))\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n\n    center_wavelength = NotifiedProperty(GetWavelength,SetWavelength)  \n      \n    def AtZeroOrder(self):\n        is_at_zero = c_int()\n        error = self.dll.ShamrockAtZeroOrder(self.current_shamrock,byref(is_at_zero))\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n        return is_at_zero.value\n    wavelength_is_zero = property(AtZeroOrder)  \n    \n    def GetWavelengthLimits(self):\n        min_wl = c_float()\n        max_wl = c_float()      \n        error = self.dll.ShamrockGetWavelengthLimits(self.current_shamrock,self.current_grating,byref(min_wl),byref(max_wl))\n        wl_limits = [min_wl.value, max_wl.value]\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n        return wl_limits\n    wavelength_limits = property(GetWavelengthLimits)\n        \n\n    \n    def GotoZeroOrder(self):\n        error = self.dll.ShamrockGotoZeroOrder(self.current_shamrock)\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n    \n    #Slit functions\n    def AutoSlitIsPresent(self):\n        present = c_int()\n        slits = []        \n    \n        for i in range(1,5):\n            self.dll.ShamrockAutoSlitIsPresent(self.current_shamrock,i,present)\n            slits.append(present.value)\n        return slits\n    Autoslits = property(AutoSlitIsPresent)\n            \n    #Sets the slit to the default value (10um)\n    def AutoSlitReset(self,slit):\n        error = self.dll.ShamrockAutoSlitReset(self.current_shamrock,self.current_slit)\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n\n    \n    #finds if input slit is present\n    def SlitIsPresent(self):\n        slit_present = c_int()\n        error = self.dll.ShamrockSlitIsPresent(self.current_shamrock,byref(slit_present))\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n        return slit_present.value\n    slit_present = property(SlitIsPresent)\n    \n    #Output Slits\n    def GetAutoSlitWidth(self,slit):\n        slitw = c_float()\n        error = self.dll.ShamrockGetAutoSlitWidth(self.current_shamrock,slit,byref(slitw))\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n        return slitw.value\n        \n    def SetAutoSlitWidth(self,slit,width):\n        slit_w = c_float(width)        \n        error = self.dll.ShamrockSetAutoSlitWidth(self.current_shamrock,slit,slit_w)\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n        return width\n    \n    #Input Slits\n    def GetSlit(self):\n        slitw = c_float()\n        error = self.dll.ShamrockGetSlit(self.current_shamrock,byref(slitw))\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n        return slitw.value\n    \n    def SetSlit(self,width):\n        slit_w = c_float(width)\n        error = self.dll.ShamrockSetSlit(self.current_shamrock,slit_w)\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n    slit_width = NotifiedProperty(GetSlit,SetSlit)\n    \n    def SlitReset(self):\n        error = self.dll.ShamrockSlitReset(self.current_shamrock)\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n\n        \n    #Calibration functions\n    def SetPixelWidth(self,width):\n        error = self.dll.ShamrockSetPixelWidth(self.current_shamrock,c_float(width))\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n    \n    def GetPixelWidth(self):\n        pixelw = c_float()\n        error = self.dll.ShamrockGetPixelWidth(self.current_shamrock,byref(pixelw))\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n        return pixelw.value\n    pixel_width = NotifiedProperty(GetPixelWidth,SetPixelWidth)\n    \n    def GetNumberPixels(self):\n        numpix = c_int()\n        error = self.dll.ShamrockGetNumberPixels(self.current_shamrock,byref(numpix))\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n        return numpix.value\n    \n    def SetNumberPixels(self,pixels):\n        error = self.dll.ShamrockSetNumberPixels(self.current_shamrock,pixels)\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n    pixel_number = NotifiedProperty(GetNumberPixels,SetNumberPixels)\n    \n    def GetCalibration(self):\n        ccalib = c_float*self.pixel_number\n        ccalib_array = ccalib()\n        error = self.dll.ShamrockGetCalibration(self.current_shamrock,pointer(ccalib_array),self.pixel_number)\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n        calib = []        \n        for i in range(len(ccalib_array)):\n            calib.append(ccalib_array[i])\n        return calib[:]\n    wl_calibration = property(GetCalibration)     \n    \n    def GetPixelCalibrationCoefficients(self):\n        ca = c_float()\n        cb = c_float()\n        cc = c_float()\n        cd = c_float()\n        error = self.dll.ShamrockGetPixelCalibrationCoefficients(self.current_shamrock,byref(ca),byref(cb),byref(cc),byref(cd))\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n        return [ca,cb,cc,cd]\n    PixelCalibrationCoefficients = property(GetPixelCalibrationCoefficients)\n        \n    def get_qt_ui(self):\n        return ShamrockControlUI(self)",
  "class ShamrockControlUI(QuickControlBox):\n    '''Control Widget for the Shamrock spectrometer\n    '''\n    def __init__(self,shamrock):\n        super(ShamrockControlUI,self).__init__(title = 'Shamrock')\n        self.shamrock = shamrock\n        self.add_doublespinbox(\"center_wavelength\")\n        self.add_doublespinbox(\"slit_width\")\n        self.add_spinbox(\"current_grating\")\n        self.add_lineedit('GratingInfo')\n        self.controls['GratingInfo'].setReadOnly(True)\n        self.auto_connect_by_name(controlled_object = self.shamrock)",
  "def main():\n    \n    app = get_qt_app()\n    s = Shamrock() \n    ui = ShamrockControlUI(shamrock=s)\n    ui.show()\n    sys.exit(app.exec_())",
  "def __init__(self):\n        super(Shamrock,self).__init__()\n        #for Windows\n        architecture = platform.architecture()\n        \n        if architecture[0] == \"64bit\":\n            self.dll2 = CDLL(\"C:\\\\Program Files\\\\Andor SOLIS\\\\Drivers\\\\Shamrock64\\\\atshamrock\")\n            self.dll = CDLL(\"C:\\\\Program Files\\\\Andor SOLIS\\\\Drivers\\\\Shamrock64\\\\ShamrockCIF\")\n            tekst = c_char()        \n            error = self.dll.ShamrockInitialize(byref(tekst))\n\n        elif architecture[0] == \"32bit\":\n            self.dll2 = WinDLL(\"C:\\\\Program Files\\\\Andor SDK\\\\Shamrock\\\\atshamrock.dll\")\n            self.dll = WinDLL(\"C:\\\\Program Files\\\\Andor SDK\\\\Shamrock\\\\ShamrockCIF.dll\")\n            tekst = c_char_p(\"\")     \n            error = self.dll.ShamrockInitialize(tekst)\n            \n        self.current_shamrock = 0 #for more than one Shamrock this has to be varied, see ShamrockGetNumberDevices\n        self._logger.setLevel('WARN')",
  "def verbose(self, error, function=''):\n        self.log( \"[%s]: %s\" %(function, error),level = 'info')",
  "def Initialize(self):\n        error = self.dll.ShamrockInitialize(\"\")\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)",
  "def GetNumberDevices(self):\n        no_shamrocks = c_int()\n        error = self.dll.ShamrockGetNumberDevices(byref(no_shamrocks))\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n        return no_shamrocks.value",
  "def Close(self):\n        error = self.dll.ShamrockClose()\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)",
  "def GetSerialNumber(self):\n        ShamrockSN = c_char()\n        error = self.dll.ShamrockGetSerialNumber(self.current_shamrock, byref(ShamrockSN))\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n        return ShamrockSN",
  "def EepromGetOpticalParams(self):\n        self.FocalLength = c_float()\n        self.AngularDeviation = c_float()\n        self.FocalTilt = c_float()\n        error = self.dll.ShamrockEepromGetOpticalParams(self.current_shamrock, byref(self.FocalLength), byref(self.AngularDeviation), byref(self.FocalTilt))\n        return {'FocalLength':self.FocalLength,'AngularDeviation':self.AngularDeviation,'FocalTilt':self.FocalTilt}",
  "def GratingIsPresent(self):\n        is_present = c_int()\n        error = self.dll.ShamrockGratingIsPresent(self.current_shamrock,is_present)\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n        return is_present.vlaue",
  "def GetTurret(self):\n        Turret = c_int()\n        error = self.dll.ShamrockGetTurret(self.current_shamrock,byref(Turret))\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n        return Turret.value",
  "def SetTurret(self,turret):\n        error = self.dll.ShamrockSetTurret(self.current_shamrock,c_int(turret))\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)",
  "def GetNumberGratings(self):\n        self.noGratings = c_int()\n        error = self.dll.ShamrockGetNumberGratings(self.current_shamrock,byref(self.noGratings))\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n        return self.noGratings",
  "def GetGrating(self):\n        grating = c_int()\n        error = self.dll.ShamrockGetGrating(self.current_shamrock,byref(grating))\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n        return grating.value",
  "def SetGrating(self,grating_num):\n        grating_num = int(grating_num)\n        grating = c_int(grating_num)\n        error = self.dll.ShamrockSetGrating(self.current_shamrock,grating)\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)",
  "def GetGratingInfo(self):    \n        lines = c_float()\n        blaze = c_char()\n        home = c_int()                \n        offset = c_int()        \n        error = self.dll.ShamrockGetGratingInfo(self.current_shamrock,self.current_grating,byref(lines),byref(blaze),byref(home),byref(offset))\n        CurrGratingInfo = [lines.value,blaze.value,home.value,offset.value]\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n        return CurrGratingInfo",
  "def GetGratingOffset(self):\n        GratingOffset = c_int() #not this is in steps, so int\n        error = self.dll.ShamrockGetGratingOffset(self.current_shamrock,self.current_grating,byref(GratingOffset))\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n        return GratingOffset",
  "def SetGratingOffset(self,offset):\n        error = self.dll.ShamrockSetGratingOffset(self.current_shamrock,self.current_grating,c_int(offset))\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)",
  "def GetDetectorOffset(self):\n        DetectorOffset = c_int() #note this is in steps, so int\n        #error = self.dll.ShamrockGetDetectorOffset(self.current_shamrock,byref(self.DetectorOffset))\n        error = self.dll.ShamrockGetDetectorOffset(self.current_shamrock,byref(DetectorOffset))\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n        return DetectorOffset.value",
  "def SetDetectorOffset(self,offset):\n        error = self.dll.ShamrockSetDetectorOffset(self.current_shamrock,self.current_grating,c_int(offset))\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)",
  "def WavelengthIsPresent(self):\n        ispresent = c_int()\n        error = self.dll.ShamrockWavelengthIsPresent(self.current_shamrock,byref(ispresent))\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n        return ispresent.value",
  "def GetWavelength(self):\n        curr_wave = c_float()\n        error = self.dll.ShamrockGetWavelength(self.current_shamrock,byref(curr_wave))\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n        return curr_wave.value",
  "def SetWavelength(self,centre_wl):\n        error = self.dll.ShamrockSetWavelength(self.current_shamrock,c_float(centre_wl))\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)",
  "def AtZeroOrder(self):\n        is_at_zero = c_int()\n        error = self.dll.ShamrockAtZeroOrder(self.current_shamrock,byref(is_at_zero))\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n        return is_at_zero.value",
  "def GetWavelengthLimits(self):\n        min_wl = c_float()\n        max_wl = c_float()      \n        error = self.dll.ShamrockGetWavelengthLimits(self.current_shamrock,self.current_grating,byref(min_wl),byref(max_wl))\n        wl_limits = [min_wl.value, max_wl.value]\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n        return wl_limits",
  "def GotoZeroOrder(self):\n        error = self.dll.ShamrockGotoZeroOrder(self.current_shamrock)\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)",
  "def AutoSlitIsPresent(self):\n        present = c_int()\n        slits = []        \n    \n        for i in range(1,5):\n            self.dll.ShamrockAutoSlitIsPresent(self.current_shamrock,i,present)\n            slits.append(present.value)\n        return slits",
  "def AutoSlitReset(self,slit):\n        error = self.dll.ShamrockAutoSlitReset(self.current_shamrock,self.current_slit)\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)",
  "def SlitIsPresent(self):\n        slit_present = c_int()\n        error = self.dll.ShamrockSlitIsPresent(self.current_shamrock,byref(slit_present))\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n        return slit_present.value",
  "def GetAutoSlitWidth(self,slit):\n        slitw = c_float()\n        error = self.dll.ShamrockGetAutoSlitWidth(self.current_shamrock,slit,byref(slitw))\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n        return slitw.value",
  "def SetAutoSlitWidth(self,slit,width):\n        slit_w = c_float(width)        \n        error = self.dll.ShamrockSetAutoSlitWidth(self.current_shamrock,slit,slit_w)\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n        return width",
  "def GetSlit(self):\n        slitw = c_float()\n        error = self.dll.ShamrockGetSlit(self.current_shamrock,byref(slitw))\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n        return slitw.value",
  "def SetSlit(self,width):\n        slit_w = c_float(width)\n        error = self.dll.ShamrockSetSlit(self.current_shamrock,slit_w)\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)",
  "def SlitReset(self):\n        error = self.dll.ShamrockSlitReset(self.current_shamrock)\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)",
  "def SetPixelWidth(self,width):\n        error = self.dll.ShamrockSetPixelWidth(self.current_shamrock,c_float(width))\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)",
  "def GetPixelWidth(self):\n        pixelw = c_float()\n        error = self.dll.ShamrockGetPixelWidth(self.current_shamrock,byref(pixelw))\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n        return pixelw.value",
  "def GetNumberPixels(self):\n        numpix = c_int()\n        error = self.dll.ShamrockGetNumberPixels(self.current_shamrock,byref(numpix))\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n        return numpix.value",
  "def SetNumberPixels(self,pixels):\n        error = self.dll.ShamrockSetNumberPixels(self.current_shamrock,pixels)\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)",
  "def GetCalibration(self):\n        ccalib = c_float*self.pixel_number\n        ccalib_array = ccalib()\n        error = self.dll.ShamrockGetCalibration(self.current_shamrock,pointer(ccalib_array),self.pixel_number)\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n        calib = []        \n        for i in range(len(ccalib_array)):\n            calib.append(ccalib_array[i])\n        return calib[:]",
  "def GetPixelCalibrationCoefficients(self):\n        ca = c_float()\n        cb = c_float()\n        cc = c_float()\n        cd = c_float()\n        error = self.dll.ShamrockGetPixelCalibrationCoefficients(self.current_shamrock,byref(ca),byref(cb),byref(cc),byref(cd))\n        self.verbose(ERROR_CODE[error], sys._getframe().f_code.co_name)\n        return [ca,cb,cc,cd]",
  "def get_qt_ui(self):\n        return ShamrockControlUI(self)",
  "def __init__(self,shamrock):\n        super(ShamrockControlUI,self).__init__(title = 'Shamrock')\n        self.shamrock = shamrock\n        self.add_doublespinbox(\"center_wavelength\")\n        self.add_doublespinbox(\"slit_width\")\n        self.add_spinbox(\"current_grating\")\n        self.add_lineedit('GratingInfo')\n        self.controls['GratingInfo'].setReadOnly(True)\n        self.auto_connect_by_name(controlled_object = self.shamrock)",
  "class SP2750(VisaInstrument):\n    \"\"\" Monochromator class\n    ftp://ftp.princetoninstruments.com/public/manuals/Acton/SP-2750.pdf\n    \"\"\"\n\n    @property\n    def wavelength(self):\n        return self.get_wavelength()\n\n    @wavelength.setter\n    def wavelength(self, value):\n        self.set_wavelength_fast(value)\n\n    def __init__(self, address, calibration_file=None):\n        port_settings = dict(baud_rate=9600, read_termination=\"\\r\\n\", write_termination=\"\\r\", timeout=10000)\n        super(SP2750, self).__init__(address, port_settings)\n        self.clear_read_buffer()\n        self._calibration_file = calibration_file\n\n        self.metadata_property_names += ('wavelength', )\n\n    def query(self, *args, **kwargs):\n        \"\"\"\n        Simple query wrapper that checks whether the command was received properly\n        :param args:\n        :param kwargs:\n        :return:\n        \"\"\"\n        full_reply = self.instr.query(*args, **kwargs)\n\n        status = full_reply[-2:]\n        reply = full_reply[:-2]\n\n        if \"?\" in full_reply:\n            self._logger.warn(\"Message  %s\" % full_reply)\n\n        if status == \"ok\":\n            return reply.strip()\n        else:\n            self._logger.info(\"Multiple reads\")\n            read = str(full_reply)\n            idx = 0\n            while \"ok\" not in read:\n                read += \" | \" + self.read()\n                idx += 1\n                if idx > 10:\n                    raise ValueError(\"Too many multiple reads\")\n            return read\n\n    def calibrate(self, wvl, to_device=True):\n        if to_device:\n            calibrated = wvl\n        else:\n            calibrated = wvl\n        return calibrated\n\n    # MOVEMENT COMMANDS\n    def _wait(self):\n        \"\"\"Checks whether movement has finished\"\"\"\n        time.sleep(1)\n        t0 = time.time()\n        while time.time() - t0 < 10 and not self.is_ready():\n            try:\n                if self.is_ready():\n                    break\n            except VisaIOError as e:\n                time.sleep(1)  # This you get from testing\n\n    def set_wavelength_fast(self, wvl):\n        \"\"\"\n        Goes to a destination wavelength at maximum motor speed. Accepts destination wavelength in nm as a floating\n        point number with up to 3 digits after the decimal point or whole number wavelength with no decimal point.\n        :param wvl:\n        :return:\n        \"\"\"\n\n        self.write(\"%0.3f GOTO\" % self.calibrate(wvl))\n        # TODO: wait until the spectrometer replies OK\n        self._wait()\n        return self.read()\n\n    def set_wavelength(self, wvl):\n        \"\"\"\n        Goes to a destination wavelength at constant nm/min rate specified by last NM/MIN\n        command. Accepts destination wavelength in nm as a floating point number with up\n        to 3 digits after the decimal point or whole number wavelength with no decimal point.\n        :param wvl:\n        :return:\n        \"\"\"\n\n        self.write(\"%0.3f NM\" % self.calibrate(wvl))\n\n    def get_wavelength(self):\n        \"\"\"\n        Returns present wavelength in nm to 0.01nm resolution with units nm appended.\n        :return:\n        \"\"\"\n        string = self.query(\"?NM\")\n        wvl = float(re.findall(\"([0-9]+\\.[0-9]+) \", string)[0])\n        return self.calibrate(wvl, False)\n\n    def set_speed(self, rate):\n        \"\"\"\n        Sets the scan rate in nm/min to 0.01 nm/min resolution with units nm/min\n        :param rate:\n        :return:\n        \"\"\"\n        self.query(\"%0.3f NM/MIN\" % rate)\n\n    def is_ready(self):\n        return bool(self.query(\"MONO-?DONE\"))\n\n    # GRATING CONTROL\n    def set_grating(self, index):\n        \"\"\"\n        Places specified grating in position to the wavelength of the wavelength on the\n        present grating. Up to nine (9) gratings are allowed on three (3) turrets. This\n        command takes a grating number from 1 -9. IMPORTANT NOTE: This command\n        assumes that the correct turret is specified by the TURRET command. For example,\n        using grating numbers 1, 4 and 7 will place the first grating on the installed turret into\n        that position and call up the parameters for the grating number specified.\n        :param index:\n        :return:\n        \"\"\"\n\n        self.query(\"%d GRATING\" % index)\n\n    def get_grating(self):\n        \"\"\"\n        Returns the number of gratings presently being used numbered 1 -9.\n        :return:\n        \"\"\"\n        return self.query(\"?GRATING\")\n\n    def get_gratings(self):\n        \"\"\"\n        Returns the list of installed gratings with position groove density and blaze. The\n        present grating is specified with an arrow.\n        :return:\n        \"\"\"\n        return self.query(\"?GRATINGS\")\n\n    # DIVERTER MIRRORS\n    @property\n    def exit_mirror(self):\n        self.query('EXIT-MIRROR')\n        return self.query('?MIRROR')\n\n    @exit_mirror.setter\n    def exit_mirror(self, value):\n        assert value in ['SIDE', 'FRONT']\n        self.query('EXIT-MIRROR')\n        self.query(value)\n\n    @property\n    def entrance_mirror(self):\n        self.query('ENT-MIRROR')\n        return self.query('?MIRROR')\n\n    @entrance_mirror.setter\n    def entrance_mirror(self, value):\n        assert value in ['SIDE', 'FRONT']\n        self.query('ENT-MIRROR')\n        self.query(value)\n\n    # CALIBRATED MEASUREMENT\n    @property\n    def calibration_file(self):\n        \"\"\"Path to the calibration file\"\"\"\n        if self._calibration_file is None:\n            self._calibration_file = os.path.join(os.path.dirname(__file__), 'default_calibration.json')\n        return self._calibration_file\n\n    @calibration_file.setter\n    def calibration_file(self, path):\n        \"\"\"Ensures the path is absolute and points to a .json file\"\"\"\n        if not os.path.isabs(path):\n            default_directory = os.path.dirname(__file__)\n            path, ext = os.path.splitext(path)\n            if ext != 'json':\n                if ext != '':\n                    self._logger.warn('Changing file type to JSON')\n                ext = 'json'\n                path = os.path.join(default_directory, path + '.' + ext)\n        self._calibration_file = path\n\n    def get_wavelengths(self):\n        \"\"\"Returns the current wavelength range being shown on a detector attached to the SP2750\n\n        Reads from a calibration file that contains the detector size being used, and the dispersion. Example JSONs:\n            {\n              \"detector_size\": 100,\n              \"dispersion\": 0.01\n            }\n            {\n              \"detector_size\": 100,\n              \"dispersion\": [0.0001, 0.02]\n            }\n            {\n              \"detector_size\": 2048,\n              \"dispersion\": {\"1\": 0.014, \"2\": [0.0001, 0.02]},\n              \"offset\": {\"1\": [0.00001, 1]}\n            }\n        :return:\n        \"\"\"\n        central_wavelength = self.wavelength\n\n        with open(self.calibration_file, 'r') as dfile:\n            calibration = json.load(dfile)\n        detector_size = calibration['detector_size']\n\n        dispersion = calibration['dispersion']\n        if isinstance(dispersion, dict):\n            current_grating = self.get_grating()\n            dispersion = dispersion[current_grating]\n        poly = np.poly1d(dispersion)  # poly1d handles it whether you give it a number on an iterable\n        dispersion_value = poly(central_wavelength)\n\n        offset_value = 0\n        if 'offset' in calibration:\n            offset = calibration['offset']\n            if isinstance(offset, dict):\n                current_grating = self.get_grating()\n                offset = offset[current_grating]\n\n            poly = np.poly1d(offset)\n            offset_value = poly(central_wavelength)\n\n        pixels = np.arange(detector_size, dtype=np.float)\n        pixels -= np.mean(pixels)\n        delta_wvl = pixels * dispersion_value\n        return central_wavelength + delta_wvl + offset_value",
  "def wavelength(self):\n        return self.get_wavelength()",
  "def wavelength(self, value):\n        self.set_wavelength_fast(value)",
  "def __init__(self, address, calibration_file=None):\n        port_settings = dict(baud_rate=9600, read_termination=\"\\r\\n\", write_termination=\"\\r\", timeout=10000)\n        super(SP2750, self).__init__(address, port_settings)\n        self.clear_read_buffer()\n        self._calibration_file = calibration_file\n\n        self.metadata_property_names += ('wavelength', )",
  "def query(self, *args, **kwargs):\n        \"\"\"\n        Simple query wrapper that checks whether the command was received properly\n        :param args:\n        :param kwargs:\n        :return:\n        \"\"\"\n        full_reply = self.instr.query(*args, **kwargs)\n\n        status = full_reply[-2:]\n        reply = full_reply[:-2]\n\n        if \"?\" in full_reply:\n            self._logger.warn(\"Message  %s\" % full_reply)\n\n        if status == \"ok\":\n            return reply.strip()\n        else:\n            self._logger.info(\"Multiple reads\")\n            read = str(full_reply)\n            idx = 0\n            while \"ok\" not in read:\n                read += \" | \" + self.read()\n                idx += 1\n                if idx > 10:\n                    raise ValueError(\"Too many multiple reads\")\n            return read",
  "def calibrate(self, wvl, to_device=True):\n        if to_device:\n            calibrated = wvl\n        else:\n            calibrated = wvl\n        return calibrated",
  "def _wait(self):\n        \"\"\"Checks whether movement has finished\"\"\"\n        time.sleep(1)\n        t0 = time.time()\n        while time.time() - t0 < 10 and not self.is_ready():\n            try:\n                if self.is_ready():\n                    break\n            except VisaIOError as e:\n                time.sleep(1)",
  "def set_wavelength_fast(self, wvl):\n        \"\"\"\n        Goes to a destination wavelength at maximum motor speed. Accepts destination wavelength in nm as a floating\n        point number with up to 3 digits after the decimal point or whole number wavelength with no decimal point.\n        :param wvl:\n        :return:\n        \"\"\"\n\n        self.write(\"%0.3f GOTO\" % self.calibrate(wvl))\n        # TODO: wait until the spectrometer replies OK\n        self._wait()\n        return self.read()",
  "def set_wavelength(self, wvl):\n        \"\"\"\n        Goes to a destination wavelength at constant nm/min rate specified by last NM/MIN\n        command. Accepts destination wavelength in nm as a floating point number with up\n        to 3 digits after the decimal point or whole number wavelength with no decimal point.\n        :param wvl:\n        :return:\n        \"\"\"\n\n        self.write(\"%0.3f NM\" % self.calibrate(wvl))",
  "def get_wavelength(self):\n        \"\"\"\n        Returns present wavelength in nm to 0.01nm resolution with units nm appended.\n        :return:\n        \"\"\"\n        string = self.query(\"?NM\")\n        wvl = float(re.findall(\"([0-9]+\\.[0-9]+) \", string)[0])\n        return self.calibrate(wvl, False)",
  "def set_speed(self, rate):\n        \"\"\"\n        Sets the scan rate in nm/min to 0.01 nm/min resolution with units nm/min\n        :param rate:\n        :return:\n        \"\"\"\n        self.query(\"%0.3f NM/MIN\" % rate)",
  "def is_ready(self):\n        return bool(self.query(\"MONO-?DONE\"))",
  "def set_grating(self, index):\n        \"\"\"\n        Places specified grating in position to the wavelength of the wavelength on the\n        present grating. Up to nine (9) gratings are allowed on three (3) turrets. This\n        command takes a grating number from 1 -9. IMPORTANT NOTE: This command\n        assumes that the correct turret is specified by the TURRET command. For example,\n        using grating numbers 1, 4 and 7 will place the first grating on the installed turret into\n        that position and call up the parameters for the grating number specified.\n        :param index:\n        :return:\n        \"\"\"\n\n        self.query(\"%d GRATING\" % index)",
  "def get_grating(self):\n        \"\"\"\n        Returns the number of gratings presently being used numbered 1 -9.\n        :return:\n        \"\"\"\n        return self.query(\"?GRATING\")",
  "def get_gratings(self):\n        \"\"\"\n        Returns the list of installed gratings with position groove density and blaze. The\n        present grating is specified with an arrow.\n        :return:\n        \"\"\"\n        return self.query(\"?GRATINGS\")",
  "def exit_mirror(self):\n        self.query('EXIT-MIRROR')\n        return self.query('?MIRROR')",
  "def exit_mirror(self, value):\n        assert value in ['SIDE', 'FRONT']\n        self.query('EXIT-MIRROR')\n        self.query(value)",
  "def entrance_mirror(self):\n        self.query('ENT-MIRROR')\n        return self.query('?MIRROR')",
  "def entrance_mirror(self, value):\n        assert value in ['SIDE', 'FRONT']\n        self.query('ENT-MIRROR')\n        self.query(value)",
  "def calibration_file(self):\n        \"\"\"Path to the calibration file\"\"\"\n        if self._calibration_file is None:\n            self._calibration_file = os.path.join(os.path.dirname(__file__), 'default_calibration.json')\n        return self._calibration_file",
  "def calibration_file(self, path):\n        \"\"\"Ensures the path is absolute and points to a .json file\"\"\"\n        if not os.path.isabs(path):\n            default_directory = os.path.dirname(__file__)\n            path, ext = os.path.splitext(path)\n            if ext != 'json':\n                if ext != '':\n                    self._logger.warn('Changing file type to JSON')\n                ext = 'json'\n                path = os.path.join(default_directory, path + '.' + ext)\n        self._calibration_file = path",
  "def get_wavelengths(self):\n        \"\"\"Returns the current wavelength range being shown on a detector attached to the SP2750\n\n        Reads from a calibration file that contains the detector size being used, and the dispersion. Example JSONs:\n            {\n              \"detector_size\": 100,\n              \"dispersion\": 0.01\n            }\n            {\n              \"detector_size\": 100,\n              \"dispersion\": [0.0001, 0.02]\n            }\n            {\n              \"detector_size\": 2048,\n              \"dispersion\": {\"1\": 0.014, \"2\": [0.0001, 0.02]},\n              \"offset\": {\"1\": [0.00001, 1]}\n            }\n        :return:\n        \"\"\"\n        central_wavelength = self.wavelength\n\n        with open(self.calibration_file, 'r') as dfile:\n            calibration = json.load(dfile)\n        detector_size = calibration['detector_size']\n\n        dispersion = calibration['dispersion']\n        if isinstance(dispersion, dict):\n            current_grating = self.get_grating()\n            dispersion = dispersion[current_grating]\n        poly = np.poly1d(dispersion)  # poly1d handles it whether you give it a number on an iterable\n        dispersion_value = poly(central_wavelength)\n\n        offset_value = 0\n        if 'offset' in calibration:\n            offset = calibration['offset']\n            if isinstance(offset, dict):\n                current_grating = self.get_grating()\n                offset = offset[current_grating]\n\n            poly = np.poly1d(offset)\n            offset_value = poly(central_wavelength)\n\n        pixels = np.arange(detector_size, dtype=np.float)\n        pixels -= np.mean(pixels)\n        delta_wvl = pixels * dispersion_value\n        return central_wavelength + delta_wvl + offset_value",
  "def Quad_Interp(x_Points,y_Points,Input): #x are in order\n\n    Number=np.ones(len(Input)).astype(int)\n    Barrier=[]\n    for i in Number:\n        Barrier.append(x_Points[1])\n    Barrier=np.array(Barrier)\n    while True:\n        Change=(Input>Barrier)\n        Change[Number==(len(x_Points)-1)]=False \n        if np.sum(Change)==0:\n            break \n        else:\n            Number[Change]+=1\n            for i in np.array(range(len(Number)))[Change]:\n                Barrier[i]=x_Points[Number[i]]\n    \n    Min=np.min(Number)\n    Max=np.max(Number)\n    Output=np.empty(len(Input))\n    while Min<=Max:\n        Mask=(Number==Min)\n        if np.sum(Mask)!=0:\n\n            Poly=[]\n            if Min-2>=0:\n                Poly.append(np.polyfit(x_Points[Min-2:Min+1],y_Points[Min-2:Min+1],2))\n            if Min+1<len(y_Points):\n                Poly.append(np.polyfit(x_Points[Min-1:Min+2],y_Points[Min-1:Min+2],2))\n            if len(Poly)==1:\n                Output[Mask]=np.polyval(Poly[0],Input[Mask])\n            else:\n                for i in range(2):\n                    Poly[i]=np.polyval(Poly[i],Input[Mask])\n                Frac=(Input[Mask]-x_Points[Min-1])/(x_Points[Min]-x_Points[Min-1])\n                Output[Mask]=(1.-Frac)*Poly[0]+Frac*Poly[1]\n        Min+=1\n\n    return Output",
  "class Triax(VisaInstrument):\n    metadata_property_names = ('wavelength', )\n\n    def __init__(self, Address, Calibration_Arrays=[],CCD_Horizontal_Resolution=2048):  \n        \"\"\"\n        Initialisation function for the triax class. Address in the port address of the triax connection. Calibration_Arrays is a list of 3x3 numpy arrays\n        containing the calibration coefficents for each grating in the spectrometer.\n        \"\"\"\n    \n        #--------Attempt to open communication------------\n\n        try:\n\n            VisaInstrument.__init__(self, Address, settings=dict(timeout=4000, write_termination='\\n'))\n            Attempts=0\n            End=False\n            while End is False:\n                if self.query(\" \")=='F':\n                    End=True\n                else:\n                    self.instr.write_raw('\\x4f\\x32\\x30\\x30\\x30\\x00') #Move from boot program to main program\n                    time.sleep(2)\n                    Attempts+=1\n                    if Attempts==5:\n                        raise Exception('Triax communication error!')\n\n        except:\n            raise Exception('Triax communication error!')\n\n        self.Calibration_Data=Calibration_Arrays\n\n        self.Wavelength_Array=None #Not intially set. Updated with a change of grating or stepper motor position\n        self.Number_of_Pixels=CCD_Horizontal_Resolution\n\n    def Get_Wavelength_Array(self):\n        \"\"\"\n        Returns the wavelength array in memory. If it is yet to be calculated, it is caluculated here\n        \"\"\"\n        if self.Wavelength_Array is None:\n            Steps=self.Motor_Steps()\n            if False: # Steps<self.Grating_Information[0][0] or Steps>self.Grating_Information[0][-1]:\n                print('WARNING: You are outside of the calibration range')\n            self.Wavelength_Array=self.Convert_Pixels_to_Wavelengths(np.array(range(self.Number_of_Pixels)),Steps)\n        return self.Wavelength_Array\n\n    def Grating(self, Set_To=None):\n        \"\"\"\n        Function for checking or setting the grating number. If Set_To is left as None, current grating number is returned. If 0,1 or 2 is passed as Set_To, the\n        corresponding grating position is rotated to.\n        \"\"\"\n\n   \t\t#-----Check Input-------\n        \n        if Set_To not in [None,0,1,2]:\n            raise ValueError('Invalid input for grating input. Must be None, 0, 1, or 2.')\n\n        #----Return current grating or switch grating---------\n            \n        if Set_To is None:\n            return int(self.query(\"Z452,0,0,0\\r\")[1:])\n\n        else:\n            self.write(\"Z451,0,0,0,%i\\r\" % (Set_To))\n            time.sleep(1)\n            self.waitTillReady()\n            self.Grating_Number = Set_To\n\n    def Motor_Steps(self):\n        \"\"\"\n        Returns the current rotation of the grating in units of steps of the internal stepper motor\n        \"\"\"\n        self.write(\"H0\\r\")\n        return int(self.read()[1:])\n\n\n    def Convert_Pixels_to_Wavelengths(self,Pixel_Array,Steps=None):\n        if Steps is None:\n            Steps=self.Motor_Steps()\n\n        Extremes=[]\n        Calibration_Data=self.Calibration_Data[self.Grating()]\n        Root=Calibration_Data[1]\n        Calibration_Data=Calibration_Data[0]\n\n        Extremes=[]\n        for i in Calibration_Data:\n            a,b,c=i[1:]\n            Extremes.append([(-b+Root*((b**2-(4*a*(c-0)))**0.5))/(2*a),(-b+Root*((b**2-(4*a*(c-self.Number_of_Pixels+1)))**0.5))/(2*a)])\n\n        Start=np.floor(np.min(np.array(Extremes)))\n        End=np.ceil(np.max(np.array(Extremes)))\n\n        if Steps<Start:\n            print('Warning: You are outside of calibrated region')\n            Edge=self.Convert_Pixels_to_Wavelengths(Pixel_Array,Start)\n            In=self.Convert_Pixels_to_Wavelengths(Pixel_Array,Start+1)\n            Step=np.mean(Edge-In)\n            return (Start-Steps)*Step+Edge\n        if Steps>End:\n            print('Warning: You are outside of calibrated region')\n            Edge=self.Convert_Pixels_to_Wavelengths(Pixel_Array,End)\n            In=self.Convert_Pixels_to_Wavelengths(Pixel_Array,End-1)\n            Step=np.mean(Edge-In)\n            return (Steps-End)*Step+Edge\n\n        Known_Pixels=[]\n        Wavelengths=[]\n        for i in Calibration_Data:\n            Known_Pixels.append(np.sum(np.array([Steps**2,Steps,1])*i[1:]))\n            Wavelengths.append(i[0])\n        Output=Quad_Interp(np.array(Known_Pixels),np.array(Wavelengths),np.array(Pixel_Array))\n        return np.array(Output)\n        \n\n    def Find_Required_Step(self,Wavelength,Pixel,Require_Integer=True):\n        Bounds=[]\n        Calibration_Data=self.Calibration_Data[self.Grating()]\n        Root=Calibration_Data[1]\n        Calibration_Data=Calibration_Data[0]\n        for i in Calibration_Data:\n            a,b,c=i[1:]\n            Bounds+=[(-b+Root*((b**2-(4*a*(c-0)))**0.5))/(2*a),(-b+Root*((b**2-(4*a*(c-self.Number_of_Pixels+1)))**0.5))/(2*a)]\n\n        Bounds=[np.min(Bounds),np.max(Bounds)]\n        Values=[]\n        for i in Bounds:\n            Values.append(self.Convert_Pixels_to_Wavelengths([Pixel],Steps=i)[0])\n        if Values[1]<Values[0]:\n            Values=[Values[1],Values[0]]\n            Bounds=[Bounds[1],Bounds[0]]\n\n        if Wavelength<Values[0]:\n            raise Exception('Outside calibrated area! Cannot move below '+str(np.round(Values[0],2))+'nm for this pixel')\n        if Wavelength>Values[1]:\n            raise Exception('Outside calibrated area! Cannot move above '+str(np.round(Values[1],2))+'nm for this pixel')\n\n        while Bounds[1]-Bounds[0]>1:\n            New=np.mean(Bounds)\n            Value=self.Convert_Pixels_to_Wavelengths([Pixel],Steps=New)[0]\n            if Value<=Wavelength:\n                Bounds[0]=New\n                Values[0]=Value\n            else:\n                Bounds[1]=New\n                Values[1]=Value\n       \n        Fraction=(Wavelength-Values[0])/(Values[1]-Values[0])\n        Step=(1-Fraction)*Bounds[0]+Fraction*Bounds[1]\n        if Require_Integer is True:\n            Step=int(round(Step))\n        return Step\n           \n\n    def Move_Steps(self, Steps):\n        \"\"\"\n        Function to move the grating by a number of stepper motor Steps.\n        \"\"\"\n        \n        if (Steps <= 0):  # Taken from original code, assume there is an issue moving backwards that this corrects\n            self.write(\"F0,%i\\r\" % (Steps - 1000))\n            time.sleep(1)\n            self.waitTillReady()\n            self.write(\"F0,1000\\r\")\n            self.waitTillReady()\n        else:\n            self.write(\"F0,%i\\r\" % Steps)\n            time.sleep(1)\n            self.waitTillReady()\n    def Set_Center_Wavelength(self,Wavelength):  \n        if self.ccd_size is None:\n            raise ValueError('ccd_size must be set in child class')\n        Centre_Pixel=int(self.ccd_size/2)\n        Required_Step=self.Find_Required_Step(Wavelength,Centre_Pixel)\n        Current_Step=self.Motor_Steps()\n        self.Move_Steps(Required_Step-Current_Step)\n    \n    def Get_Center_Wavelength(self):\n        wls = self.Get_Wavelength_Array()\n        return wls[len(wls)//2]\n    \n    center_wavelength = property(Get_Center_Wavelength, Set_Center_Wavelength) \n    def Slit(self, Width=None):\n        \"\"\"\n        Function to return or set the triax slit with in units of um. If Width is None, the current width is returned. \n        \"\"\"\n        \n        Current_Width=int(self.query(\"j0,0\\r\")[1:])\n        \n        if Width is None:\n            return Current_Width\n        elif Width > 0:\n           To_Move = Width - Current_Width\n        if To_Move == 0:\n            return\n        elif To_Move > 0:  # backlash correction\n            self.write(\"k0,0,%i\\r\" % (To_Move + 100))\n            self.waitTillReady()\n        \n            self.write(\"k0,0,-100\\r\")\n            self.waitTillReady()\n        else:\n            self.write(\"k0,0,%i\\r\" % To_Move)\n            self.waitTillReady()\n\n    def _isBusy(self):\n        \"\"\"\n        Queries whether the Triax is willing to accept further commands\n        \"\"\"\n        \n        if self.query(\"E\") == 'oz':\n            return False\n        else:\n            return True\n\n    def waitTillReady(self,Timeout=120):\n        \"\"\"\n        When called, this function checks the triax status once per second to check if it is busy. When it is not, the function returns. Also return automatically \n        after Timeout seconds.\n        \"\"\"\n\n        Start_Time = time.time()\n\n        while self._isBusy():\n            time.sleep(1)\n            if (time.time() - Start_Time) > Timeout:\n                self._logger.warn('Timed out')\n                print('Timed out')\n                break\n    def get_qt_ui(self):\n        return TriaxUI(self)\n\n    #-------------------------------------------------------------------------------------------------\n\n    \"\"\"\n\tHeld here are functions from the original code that, at this point in time, I do not wish to touch\n    \"\"\"\n\n    def reset(self):\n        self.instr.write_raw(b'\\xde')\n        time.sleep(5)\n        buff = self.query(\" \")\n        if buff == 'B':\n            self.instr.write_raw('\\x4f\\x32\\x30\\x30\\x30\\x00')  # <O2000>0\n            buff = self.query(\" \")\n        if buff == 'F':\n            self._logger.debug(\"Triax is reset\")\n            self.setup()\n\n    def setup(self):\n        self._logger.info(\"Initiating motor. This will take some time...\")\n        self.write(\"A\")\n        time.sleep(60)\n        self.waitTillReady()\n        self.Grating(2)\n        self.Grating_Number = self.Grating()\n\n    def exitLateral(self):\n        self.write(\"e0\\r\")\n        self.write(\"c0\\r\")  # sets entrance mirror to lateral as well\n\n    def exitAxial(self):\n        self.write(\"f0\\r\")\n        self.write(\"d0\\r\")",
  "class TriaxUI(QtWidgets.QWidget,UiTools):\n    def __init__(self, triax, ui_file =os.path.join(os.path.dirname(__file__),'triax_ui.ui'),  parent=None):\n        assert isinstance(triax, Triax), \"instrument must be a Triax\"\n        super(TriaxUI, self).__init__()\n        uic.loadUi(ui_file, self)\n        self.triax = triax\n        self.centre_wl_lineEdit.returnPressed.connect(self.set_wl_gui)\n        self.slit_lineEdit.returnPressed.connect(self.set_slit_gui)     \n        self.centre_wl_lineEdit.setText(str(np.around(self.triax.center_wavelength)))\n        self.slit_lineEdit.setText(str(self.triax.Slit()))\n        eval('self.grating_'+str(self.triax.Grating())+'_radioButton.setChecked(True)')\n        for radio_button in range(3):\n            eval('self.grating_'+str(radio_button)+'_radioButton.clicked.connect(self.set_grating_gui)')\n    def set_wl_gui(self):\n        self.triax.Set_Center_Wavelength(float(self.centre_wl_lineEdit.text().strip()))\n    def set_slit_gui(self):\n        self.triax.Slit(float(self.slit_lineEdit.text().strip()))\n    def set_grating_gui(self):\n        s = self.sender()\n        if s is self.grating_0_radioButton:\n            self.triax.Grating(0)\n        elif s is self.grating_1_radioButton:\n            self.triax.Grating(1)\n        elif s is self.grating_2_radioButton:\n            self.triax.Grating(2)\n        else:\n            raise ValueError('radio buttons not connected!')",
  "class Trandor(Andor):#Andor\n    ''' Wrapper class for the Triax and the andor\n    ''' \n    # Calibration_Arrays = Calibration_Arrays\n    def __init__(self, white_shutter=None, triax_address='GPIB0::1::INSTR', use_shifts = False, laser_wavelength=632.8):\n        print ('Triax Information:, 2')\n        super(Trandor,self).__init__()\n        self.triax = Triax(triax_address, Calibration_Arrays=Calibration_Arrays, CCD_Horizontal_Resolution=CCD_Size) #Initialise triax\n\n        self.white_shutter = white_shutter\n        self.triax.ccd_size = CCD_Size\n        self.use_shifts = use_shifts\n        self.laser_wavelength = laser_wavelength\n        \n        print ('Current Grating:'+str(self.triax.Grating()))\n        print ('Current Slit Width:'+str(self.triax.Slit())+'um')\n        self.metadata_property_names += ('slit_width', 'wavelengths')\n        # self.triax.Calibration_Arrays = Calibration_Arrays\n    \n    def Grating(self, Set_To=None):\n        return self.triax.Grating(Set_To)\n\n    def Generate_Wavelength_Axis(self, use_shifts=None):\n\n        if use_shifts is None:\n            use_shifts = self.use_shifts\n        if use_shifts:\n            \n            wavelengths = np.array(self.triax.Get_Wavelength_Array())\n            return ( 1./(self.laser_wavelength*1e-9)- 1./(wavelengths*1e-9))/100    \n        else:\n            return self.triax.Get_Wavelength_Array()\n    x_axis = property(Generate_Wavelength_Axis)\n\n    @property\n    def wavelengths(self):\n        return self.Generate_Wavelength_Axis(use_shifts=False)\n    @property\n    def slit_width(self):\n        return self.triax.Slit()\n    @slit_width.setter\n    def slit_width(self, val):\n        self.triax.Slit(val)\n\n    def Test_Notch_Alignment(self):\n        \tAccepted=False\n        \twhile Accepted is False:\n        \t\tInput=input('WARNING! A slight misalignment of the narrow band notch filters could be catastrophic! Has the laser thoughput been tested? [Yes/No]')\n        \t\tif Input.upper() in ['Y','N','YES','NO']:\n        \t\t\tAccepted=True\n        \t\t\tif len(Input)>1:\n        \t\t\t\tInput=Input.upper()[0]\n        \tif Input.upper()=='Y':\n        \t\tprint ('You are now free to capture spectra')\n        \t\tself.Notch_Filters_Tested=True\n        \telse:\n        \t\tprint ('The next spectrum capture will be allowed for you to test this. Please LOWER the laser power and REDUCE the integration time.')\n        \t\tself.Notch_Filters_Tested=None\n    def Set_Center_Wavelength(self, wavelength):\n        ''' backwards compatability with lab codes that use trandor.Set_Center_Wavelength'''\n        self.triax.Set_Center_Wavelength(wavelength)",
  "def Capture(_AndorUI):\n    if _AndorUI.Andor.white_shutter is not None:\n        isopen = _AndorUI.Andor.white_shutter.is_open()\n        if isopen:\n            _AndorUI.Andor.white_shutter.close_shutter()\n        _AndorUI.Andor.raw_image(update_latest_frame = True)\n        if isopen:\n            _AndorUI.Andor.white_shutter.open_shutter()\n    else:\n        _AndorUI.Andor.raw_image(update_latest_frame = True)",
  "def __init__(self, Address, Calibration_Arrays=[],CCD_Horizontal_Resolution=2048):  \n        \"\"\"\n        Initialisation function for the triax class. Address in the port address of the triax connection. Calibration_Arrays is a list of 3x3 numpy arrays\n        containing the calibration coefficents for each grating in the spectrometer.\n        \"\"\"\n    \n        #--------Attempt to open communication------------\n\n        try:\n\n            VisaInstrument.__init__(self, Address, settings=dict(timeout=4000, write_termination='\\n'))\n            Attempts=0\n            End=False\n            while End is False:\n                if self.query(\" \")=='F':\n                    End=True\n                else:\n                    self.instr.write_raw('\\x4f\\x32\\x30\\x30\\x30\\x00') #Move from boot program to main program\n                    time.sleep(2)\n                    Attempts+=1\n                    if Attempts==5:\n                        raise Exception('Triax communication error!')\n\n        except:\n            raise Exception('Triax communication error!')\n\n        self.Calibration_Data=Calibration_Arrays\n\n        self.Wavelength_Array=None #Not intially set. Updated with a change of grating or stepper motor position\n        self.Number_of_Pixels=CCD_Horizontal_Resolution",
  "def Get_Wavelength_Array(self):\n        \"\"\"\n        Returns the wavelength array in memory. If it is yet to be calculated, it is caluculated here\n        \"\"\"\n        if self.Wavelength_Array is None:\n            Steps=self.Motor_Steps()\n            if False: # Steps<self.Grating_Information[0][0] or Steps>self.Grating_Information[0][-1]:\n                print('WARNING: You are outside of the calibration range')\n            self.Wavelength_Array=self.Convert_Pixels_to_Wavelengths(np.array(range(self.Number_of_Pixels)),Steps)\n        return self.Wavelength_Array",
  "def Grating(self, Set_To=None):\n        \"\"\"\n        Function for checking or setting the grating number. If Set_To is left as None, current grating number is returned. If 0,1 or 2 is passed as Set_To, the\n        corresponding grating position is rotated to.\n        \"\"\"\n\n   \t\t#-----Check Input-------\n        \n        if Set_To not in [None,0,1,2]:\n            raise ValueError('Invalid input for grating input. Must be None, 0, 1, or 2.')\n\n        #----Return current grating or switch grating---------\n            \n        if Set_To is None:\n            return int(self.query(\"Z452,0,0,0\\r\")[1:])\n\n        else:\n            self.write(\"Z451,0,0,0,%i\\r\" % (Set_To))\n            time.sleep(1)\n            self.waitTillReady()\n            self.Grating_Number = Set_To",
  "def Motor_Steps(self):\n        \"\"\"\n        Returns the current rotation of the grating in units of steps of the internal stepper motor\n        \"\"\"\n        self.write(\"H0\\r\")\n        return int(self.read()[1:])",
  "def Convert_Pixels_to_Wavelengths(self,Pixel_Array,Steps=None):\n        if Steps is None:\n            Steps=self.Motor_Steps()\n\n        Extremes=[]\n        Calibration_Data=self.Calibration_Data[self.Grating()]\n        Root=Calibration_Data[1]\n        Calibration_Data=Calibration_Data[0]\n\n        Extremes=[]\n        for i in Calibration_Data:\n            a,b,c=i[1:]\n            Extremes.append([(-b+Root*((b**2-(4*a*(c-0)))**0.5))/(2*a),(-b+Root*((b**2-(4*a*(c-self.Number_of_Pixels+1)))**0.5))/(2*a)])\n\n        Start=np.floor(np.min(np.array(Extremes)))\n        End=np.ceil(np.max(np.array(Extremes)))\n\n        if Steps<Start:\n            print('Warning: You are outside of calibrated region')\n            Edge=self.Convert_Pixels_to_Wavelengths(Pixel_Array,Start)\n            In=self.Convert_Pixels_to_Wavelengths(Pixel_Array,Start+1)\n            Step=np.mean(Edge-In)\n            return (Start-Steps)*Step+Edge\n        if Steps>End:\n            print('Warning: You are outside of calibrated region')\n            Edge=self.Convert_Pixels_to_Wavelengths(Pixel_Array,End)\n            In=self.Convert_Pixels_to_Wavelengths(Pixel_Array,End-1)\n            Step=np.mean(Edge-In)\n            return (Steps-End)*Step+Edge\n\n        Known_Pixels=[]\n        Wavelengths=[]\n        for i in Calibration_Data:\n            Known_Pixels.append(np.sum(np.array([Steps**2,Steps,1])*i[1:]))\n            Wavelengths.append(i[0])\n        Output=Quad_Interp(np.array(Known_Pixels),np.array(Wavelengths),np.array(Pixel_Array))\n        return np.array(Output)",
  "def Find_Required_Step(self,Wavelength,Pixel,Require_Integer=True):\n        Bounds=[]\n        Calibration_Data=self.Calibration_Data[self.Grating()]\n        Root=Calibration_Data[1]\n        Calibration_Data=Calibration_Data[0]\n        for i in Calibration_Data:\n            a,b,c=i[1:]\n            Bounds+=[(-b+Root*((b**2-(4*a*(c-0)))**0.5))/(2*a),(-b+Root*((b**2-(4*a*(c-self.Number_of_Pixels+1)))**0.5))/(2*a)]\n\n        Bounds=[np.min(Bounds),np.max(Bounds)]\n        Values=[]\n        for i in Bounds:\n            Values.append(self.Convert_Pixels_to_Wavelengths([Pixel],Steps=i)[0])\n        if Values[1]<Values[0]:\n            Values=[Values[1],Values[0]]\n            Bounds=[Bounds[1],Bounds[0]]\n\n        if Wavelength<Values[0]:\n            raise Exception('Outside calibrated area! Cannot move below '+str(np.round(Values[0],2))+'nm for this pixel')\n        if Wavelength>Values[1]:\n            raise Exception('Outside calibrated area! Cannot move above '+str(np.round(Values[1],2))+'nm for this pixel')\n\n        while Bounds[1]-Bounds[0]>1:\n            New=np.mean(Bounds)\n            Value=self.Convert_Pixels_to_Wavelengths([Pixel],Steps=New)[0]\n            if Value<=Wavelength:\n                Bounds[0]=New\n                Values[0]=Value\n            else:\n                Bounds[1]=New\n                Values[1]=Value\n       \n        Fraction=(Wavelength-Values[0])/(Values[1]-Values[0])\n        Step=(1-Fraction)*Bounds[0]+Fraction*Bounds[1]\n        if Require_Integer is True:\n            Step=int(round(Step))\n        return Step",
  "def Move_Steps(self, Steps):\n        \"\"\"\n        Function to move the grating by a number of stepper motor Steps.\n        \"\"\"\n        \n        if (Steps <= 0):  # Taken from original code, assume there is an issue moving backwards that this corrects\n            self.write(\"F0,%i\\r\" % (Steps - 1000))\n            time.sleep(1)\n            self.waitTillReady()\n            self.write(\"F0,1000\\r\")\n            self.waitTillReady()\n        else:\n            self.write(\"F0,%i\\r\" % Steps)\n            time.sleep(1)\n            self.waitTillReady()",
  "def Set_Center_Wavelength(self,Wavelength):  \n        if self.ccd_size is None:\n            raise ValueError('ccd_size must be set in child class')\n        Centre_Pixel=int(self.ccd_size/2)\n        Required_Step=self.Find_Required_Step(Wavelength,Centre_Pixel)\n        Current_Step=self.Motor_Steps()\n        self.Move_Steps(Required_Step-Current_Step)",
  "def Get_Center_Wavelength(self):\n        wls = self.Get_Wavelength_Array()\n        return wls[len(wls)//2]",
  "def Slit(self, Width=None):\n        \"\"\"\n        Function to return or set the triax slit with in units of um. If Width is None, the current width is returned. \n        \"\"\"\n        \n        Current_Width=int(self.query(\"j0,0\\r\")[1:])\n        \n        if Width is None:\n            return Current_Width\n        elif Width > 0:\n           To_Move = Width - Current_Width\n        if To_Move == 0:\n            return\n        elif To_Move > 0:  # backlash correction\n            self.write(\"k0,0,%i\\r\" % (To_Move + 100))\n            self.waitTillReady()\n        \n            self.write(\"k0,0,-100\\r\")\n            self.waitTillReady()\n        else:\n            self.write(\"k0,0,%i\\r\" % To_Move)\n            self.waitTillReady()",
  "def _isBusy(self):\n        \"\"\"\n        Queries whether the Triax is willing to accept further commands\n        \"\"\"\n        \n        if self.query(\"E\") == 'oz':\n            return False\n        else:\n            return True",
  "def waitTillReady(self,Timeout=120):\n        \"\"\"\n        When called, this function checks the triax status once per second to check if it is busy. When it is not, the function returns. Also return automatically \n        after Timeout seconds.\n        \"\"\"\n\n        Start_Time = time.time()\n\n        while self._isBusy():\n            time.sleep(1)\n            if (time.time() - Start_Time) > Timeout:\n                self._logger.warn('Timed out')\n                print('Timed out')\n                break",
  "def get_qt_ui(self):\n        return TriaxUI(self)",
  "def reset(self):\n        self.instr.write_raw(b'\\xde')\n        time.sleep(5)\n        buff = self.query(\" \")\n        if buff == 'B':\n            self.instr.write_raw('\\x4f\\x32\\x30\\x30\\x30\\x00')  # <O2000>0\n            buff = self.query(\" \")\n        if buff == 'F':\n            self._logger.debug(\"Triax is reset\")\n            self.setup()",
  "def setup(self):\n        self._logger.info(\"Initiating motor. This will take some time...\")\n        self.write(\"A\")\n        time.sleep(60)\n        self.waitTillReady()\n        self.Grating(2)\n        self.Grating_Number = self.Grating()",
  "def exitLateral(self):\n        self.write(\"e0\\r\")\n        self.write(\"c0\\r\")",
  "def exitAxial(self):\n        self.write(\"f0\\r\")\n        self.write(\"d0\\r\")",
  "def __init__(self, triax, ui_file =os.path.join(os.path.dirname(__file__),'triax_ui.ui'),  parent=None):\n        assert isinstance(triax, Triax), \"instrument must be a Triax\"\n        super(TriaxUI, self).__init__()\n        uic.loadUi(ui_file, self)\n        self.triax = triax\n        self.centre_wl_lineEdit.returnPressed.connect(self.set_wl_gui)\n        self.slit_lineEdit.returnPressed.connect(self.set_slit_gui)     \n        self.centre_wl_lineEdit.setText(str(np.around(self.triax.center_wavelength)))\n        self.slit_lineEdit.setText(str(self.triax.Slit()))\n        eval('self.grating_'+str(self.triax.Grating())+'_radioButton.setChecked(True)')\n        for radio_button in range(3):\n            eval('self.grating_'+str(radio_button)+'_radioButton.clicked.connect(self.set_grating_gui)')",
  "def set_wl_gui(self):\n        self.triax.Set_Center_Wavelength(float(self.centre_wl_lineEdit.text().strip()))",
  "def set_slit_gui(self):\n        self.triax.Slit(float(self.slit_lineEdit.text().strip()))",
  "def set_grating_gui(self):\n        s = self.sender()\n        if s is self.grating_0_radioButton:\n            self.triax.Grating(0)\n        elif s is self.grating_1_radioButton:\n            self.triax.Grating(1)\n        elif s is self.grating_2_radioButton:\n            self.triax.Grating(2)\n        else:\n            raise ValueError('radio buttons not connected!')",
  "def __init__(self, white_shutter=None, triax_address='GPIB0::1::INSTR', use_shifts = False, laser_wavelength=632.8):\n        print ('Triax Information:, 2')\n        super(Trandor,self).__init__()\n        self.triax = Triax(triax_address, Calibration_Arrays=Calibration_Arrays, CCD_Horizontal_Resolution=CCD_Size) #Initialise triax\n\n        self.white_shutter = white_shutter\n        self.triax.ccd_size = CCD_Size\n        self.use_shifts = use_shifts\n        self.laser_wavelength = laser_wavelength\n        \n        print ('Current Grating:'+str(self.triax.Grating()))\n        print ('Current Slit Width:'+str(self.triax.Slit())+'um')\n        self.metadata_property_names += ('slit_width', 'wavelengths')",
  "def Grating(self, Set_To=None):\n        return self.triax.Grating(Set_To)",
  "def Generate_Wavelength_Axis(self, use_shifts=None):\n\n        if use_shifts is None:\n            use_shifts = self.use_shifts\n        if use_shifts:\n            \n            wavelengths = np.array(self.triax.Get_Wavelength_Array())\n            return ( 1./(self.laser_wavelength*1e-9)- 1./(wavelengths*1e-9))/100    \n        else:\n            return self.triax.Get_Wavelength_Array()",
  "def wavelengths(self):\n        return self.Generate_Wavelength_Axis(use_shifts=False)",
  "def slit_width(self):\n        return self.triax.Slit()",
  "def slit_width(self, val):\n        self.triax.Slit(val)",
  "def Test_Notch_Alignment(self):\n        \tAccepted=False\n        \twhile Accepted is False:\n        \t\tInput=input('WARNING! A slight misalignment of the narrow band notch filters could be catastrophic! Has the laser thoughput been tested? [Yes/No]')\n        \t\tif Input.upper() in ['Y','N','YES','NO']:\n        \t\t\tAccepted=True\n        \t\t\tif len(Input)>1:\n        \t\t\t\tInput=Input.upper()[0]\n        \tif Input.upper()=='Y':\n        \t\tprint ('You are now free to capture spectra')\n        \t\tself.Notch_Filters_Tested=True\n        \telse:\n        \t\tprint ('The next spectrum capture will be allowed for you to test this. Please LOWER the laser power and REDUCE the integration time.')\n        \t\tself.Notch_Filters_Tested=None",
  "def Set_Center_Wavelength(self, wavelength):\n        ''' backwards compatability with lab codes that use trandor.Set_Center_Wavelength'''\n        self.triax.Set_Center_Wavelength(wavelength)",
  "def Quad_Interp(x_Points,y_Points,Input): #x are in order\n\n    Number=np.ones(len(Input)).astype(int)\n    Barrier=[]\n    for i in Number:\n        Barrier.append(x_Points[1])\n    Barrier=np.array(Barrier)\n    while True:\n        Change=(Input>Barrier)\n        Change[Number==(len(x_Points)-1)]=False \n        if np.sum(Change)==0:\n            break \n        else:\n            Number[Change]+=1\n            for i in np.array(range(len(Number)))[Change]:\n                Barrier[i]=x_Points[Number[i]]\n    \n    Min=np.min(Number)\n    Max=np.max(Number)\n    Output=np.empty(len(Input))\n    while Min<=Max:\n        Mask=(Number==Min)\n        if np.sum(Mask)!=0:\n\n            Poly=[]\n            if Min-2>=0:\n                Poly.append(np.polyfit(x_Points[Min-2:Min+1],y_Points[Min-2:Min+1],2))\n            if Min+1<len(y_Points):\n                Poly.append(np.polyfit(x_Points[Min-1:Min+2],y_Points[Min-1:Min+2],2))\n            if len(Poly)==1:\n                Output[Mask]=np.polyval(Poly[0],Input[Mask])\n            else:\n                for i in range(2):\n                    Poly[i]=np.polyval(Poly[i],Input[Mask])\n                Frac=(Input[Mask]-x_Points[Min-1])/(x_Points[Min]-x_Points[Min-1])\n                Output[Mask]=(1.-Frac)*Poly[0]+Frac*Poly[1]\n        Min+=1\n\n    return Output",
  "class Triax(VisaInstrument):\n    metadata_property_names = ('wavelength', )\n\n    def __init__(self, Address, Calibration_Arrays=[],CCD_Horizontal_Resolution=1600):  \n        \"\"\"\n        Initialisation function for the triax class. Address in the port address of the triax connection. Calibration_Arrays is a list of 3x3 numpy arrays\n        containing the calibration coefficents for each grating in the spectrometer.\n        \"\"\"\n    \n        #--------Attempt to open communication------------\n\n        try:\n\n            VisaInstrument.__init__(self, Address, settings=dict(timeout=4000, write_termination='\\n'))\n            Attempts=0\n            End=False\n            while End is False:\n                if self.query(\" \")=='F':\n                    End=True\n                else:\n                    self.instr.write_raw('\\x4f\\x32\\x30\\x30\\x30\\x00') #Move from boot program to main program\n                    time.sleep(2)\n                    Attempts+=1\n                    if Attempts==5:\n                        raise Exception('Triax communication error!')\n\n        except:\n            raise Exception('Triax communication error!')\n\n        self.Calibration_Data=Calibration_Arrays\n\n        self.Wavelength_Array=None #Not intially set. Updated with a change of grating or stepper motor position\n        self.Number_of_Pixels=CCD_Horizontal_Resolution\n\n    def Get_Wavelength_Array(self):\n        \"\"\"\n        Returns the wavelength array in memory. If it is yet to be calculated, it is caluculated here\n        \"\"\"\n        if self.Wavelength_Array is None:\n            Steps=self.Motor_Steps()\n            if Steps<self.Grating_Information[0][0] or Steps>self.Grating_Information[0][-1]:\n                print('WARNING: You are outside of the calibration range')\n            self.Wavelength_Array=self.Convert_Pixels_to_Wavelengths(np.array(range(self.Number_of_Pixels)),Steps)\n        return self.Wavelength_Array\n\n    def Grating(self, Set_To=None):\n        \"\"\"\n        Function for checking or setting the grating number. If Set_To is left as None, current grating number is returned. If 0,1 or 2 is passed as Set_To, the\n        corresponding grating position is rotated to.\n        \"\"\"\n\n   \t\t#-----Check Input-------\n        \n        if Set_To not in [None,0,1,2]:\n            raise ValueError('Invalid input for grating input. Must be None, 0, 1, or 2.')\n\n        #----Return current grating or switch grating---------\n            \n        if Set_To is None:\n            return int(self.query(\"Z452,0,0,0\\r\")[1:])\n\n        else:\n            self.write(\"Z451,0,0,0,%i\\r\" % (Set_To))\n            time.sleep(1)\n            self.waitTillReady()\n            self.Grating_Number = Set_To\n\n    def Motor_Steps(self):\n        \"\"\"\n        Returns the current rotation of the grating in units of steps of the internal stepper motor\n        \"\"\"\n        self.write(\"H0\\r\")\n        return int(self.read()[1:])\n\n\n    def Convert_Pixels_to_Wavelengths(self,Pixel_Array,Steps=None):\n        if Steps is None:\n            Steps=self.Motor_Steps()\n\n        Extremes=[]\n        Calibration_Data=self.Calibration_Data[self.Grating()]\n        Root=Calibration_Data[1]\n        Calibration_Data=Calibration_Data[0]\n\n        Extremes=[]\n        for i in Calibration_Data:\n            a,b,c=i[1:]\n            Extremes.append([(-b+Root*((b**2-(4*a*(c-0)))**0.5))/(2*a),(-b+Root*((b**2-(4*a*(c-self.Number_of_Pixels+1)))**0.5))/(2*a)])\n\n        Start=np.floor(np.min(np.array(Extremes)))\n        End=np.ceil(np.max(np.array(Extremes)))\n\n        if Steps<Start:\n            print('Warning: You are outside of calibrated region')\n            Edge=self.Convert_Pixels_to_Wavelengths(Pixel_Array,Start)\n            In=self.Convert_Pixels_to_Wavelengths(Pixel_Array,Start+1)\n            Step=np.mean(Edge-In)\n            return (Start-Steps)*Step+Edge\n        if Steps>End:\n            print('Warning: You are outside of calibrated region')\n            Edge=self.Convert_Pixels_to_Wavelengths(Pixel_Array,End)\n            In=self.Convert_Pixels_to_Wavelengths(Pixel_Array,End-1)\n            Step=np.mean(Edge-In)\n            return (Steps-End)*Step+Edge\n\n        Known_Pixels=[]\n        Wavelengths=[]\n        for i in Calibration_Data:\n            Known_Pixels.append(np.sum(np.array([Steps**2,Steps,1])*i[1:]))\n            Wavelengths.append(i[0])\n        Output=Quad_Interp(np.array(Known_Pixels),np.array(Wavelengths),np.array(Pixel_Array))\n        return np.array(Output)\n        \n\n    def Find_Required_Step(self,Wavelength,Pixel,Require_Integer=True):\n        Bounds=[]\n        Calibration_Data=self.Calibration_Data[self.Grating()]\n        Root=Calibration_Data[1]\n        Calibration_Data=Calibration_Data[0]\n        for i in Calibration_Data:\n            a,b,c=i[1:]\n            Bounds+=[(-b+Root*((b**2-(4*a*(c-0)))**0.5))/(2*a),(-b+Root*((b**2-(4*a*(c-self.Number_of_Pixels+1)))**0.5))/(2*a)]\n\n        Bounds=[np.min(Bounds),np.max(Bounds)]\n        Values=[]\n        for i in Bounds:\n            Values.append(self.Convert_Pixels_to_Wavelengths([Pixel],Steps=i)[0])\n        if Values[1]<Values[0]:\n            Values=[Values[1],Values[0]]\n            Bounds=[Bounds[1],Bounds[0]]\n\n        if Wavelength<Values[0]:\n            raise Exception('Outside calibrated area! Cannot move below '+str(np.round(Values[0],2))+'nm for this pixel')\n        if Wavelength>Values[1]:\n            raise Exception('Outside calibrated area! Cannot move above '+str(np.round(Values[1],2))+'nm for this pixel')\n\n        while Bounds[1]-Bounds[0]>1:\n            New=np.mean(Bounds)\n            Value=self.Convert_Pixels_to_Wavelengths([Pixel],Steps=New)[0]\n            if Value<=Wavelength:\n                Bounds[0]=New\n                Values[0]=Value\n            else:\n                Bounds[1]=New\n                Values[1]=Value\n       \n        Fraction=(Wavelength-Values[0])/(Values[1]-Values[0])\n        Step=(1-Fraction)*Bounds[0]+Fraction*Bounds[1]\n        if Require_Integer is True:\n            Step=int(round(Step))\n        return Step\n           \n\n    def Move_Steps(self, Steps):\n        \"\"\"\n        Function to move the grating by a number of stepper motor Steps.\n        \"\"\"\n        \n        if (Steps <= 0):  # Taken from original code, assume there is an issue moving backwards that this corrects\n            self.write(\"F0,%i\\r\" % (Steps - 1000))\n            time.sleep(1)\n            self.waitTillReady()\n            self.write(\"F0,1000\\r\")\n            self.waitTillReady()\n        else:\n            self.write(\"F0,%i\\r\" % Steps)\n            time.sleep(1)\n            self.waitTillReady()\n    def Set_Center_Wavelength(self,Wavelength):  \n        if self.ccd_size is None:\n            raise ValueError('ccd_size must be set in child class')\n        Centre_Pixel=int(self.ccd_size/2)\n        Required_Step=self.Find_Required_Step(Wavelength,Centre_Pixel)\n        Current_Step=self.Motor_Steps()\n        self.Move_Steps(Required_Step-Current_Step)\n    \n    def Get_Center_Wavelength(self):\n        wls = self.Get_Wavelength_Array()\n        return wls[len(wls)//2]\n    \n    center_wavelength = property(Get_Center_Wavelength, Set_Center_Wavelength)\n    def Slit(self, Width=None):\n        \"\"\"\n        Function to return or set the triax slit with in units of um. If Width is None, the current width is returned. \n        \"\"\"\n        \n        Current_Width=int(self.query(\"j0,0\\r\")[1:])\n        \n        if Width is None:\n            return Current_Width\n        elif Width > 0:\n           To_Move = Width - Current_Width\n        if To_Move == 0:\n            return\n        elif To_Move > 0:  # backlash correction\n            self.write(\"k0,0,%i\\r\" % (To_Move + 100))\n            self.waitTillReady()\n        \n            self.write(\"k0,0,-100\\r\")\n            self.waitTillReady()\n        else:\n            self.write(\"k0,0,%i\\r\" % To_Move)\n            self.waitTillReady()\n\n    def _isBusy(self):\n        \"\"\"\n        Queries whether the Triax is willing to accept further commands\n        \"\"\"\n        \n        if self.query(\"E\") == 'oz':\n            return False\n        else:\n            return True\n\n    def waitTillReady(self,Timeout=120):\n        \"\"\"\n        When called, this function checks the triax status once per second to check if it is busy. When it is not, the function returns. Also return automatically \n        after Timeout seconds.\n        \"\"\"\n\n        Start_Time = time.time()\n\n        while self._isBusy():\n            time.sleep(1)\n            if (time.time() - Start_Time) > Timeout:\n                self._logger.warn('Timed out')\n                print('Timed out')\n                break\n\n    #-------------------------------------------------------------------------------------------------\n\n    \"\"\"\n\tHeld here are functions from the original code that, at this point in time, I do not wish to touch\n    \"\"\"\n\n    def reset(self):\n        self.instr.write_raw('\\xde')\n        time.sleep(5)\n        buff = self.query(\" \")\n        if buff == 'B':\n            self.instr.write_raw('\\x4f\\x32\\x30\\x30\\x30\\x00')  # <O2000>0\n            buff = self.query(\" \")\n        if buff == 'F':\n            self._logger.debug(\"Triax is reset\")\n            self.setup()\n\n    def setup(self):\n        self._logger.info(\"Initiating motor. This will take some time...\")\n        self.write(\"A\")\n        time.sleep(60)\n        self.waitTillReady()\n        self.Grating(1)\n        self.Grating_Number = self.Grating()\n\n    def exitLateral(self):\n        self.write(\"e0\\r\")\n        self.write(\"c0\\r\")  # sets entrance mirror to lateral as well\n\n    def exitAxial(self):\n        self.write(\"f0\\r\")\n        self.write(\"d0\\r\")",
  "class TriaxUI(QtWidgets.QWidget,UiTools):\n    def __init__(self, triax, ui_file =os.path.join(os.path.dirname(__file__),'triax_ui.ui'),  parent=None):\n        assert isinstance(triax, Triax), \"instrument must be a Triax\"\n        super(TriaxUI, self).__init__()\n        uic.loadUi(ui_file, self)\n        self.triax = triax\n        self.centre_wl_lineEdit.returnPressed.connect(self.set_wl_gui)\n        self.slit_lineEdit.returnPressed.connect(self.set_slit_gui)     \n        self.centre_wl_lineEdit.setText(str(np.around(self.triax.center_wavelength)))\n        self.slit_lineEdit.setText(str(self.triax.Slit()))\n        eval('self.grating_'+str(self.triax.Grating())+'_radioButton.setChecked(True)')\n        for radio_button in range(3):\n            eval('self.grating_'+str(radio_button)+'_radioButton.clicked.connect(self.set_grating_gui)')\n    def set_wl_gui(self):\n        self.triax.Set_Center_Wavelength(float(self.centre_wl_lineEdit.text().strip()))\n    def set_slit_gui(self):\n        self.triax.Slit(float(self.slit_lineEdit.text().strip()))\n    def set_grating_gui(self):\n        s = self.sender()\n        if s is self.grating_0_radioButton:\n            self.triax.Grating(0)\n        elif s is self.grating_1_radioButton:\n            self.triax.Grating(1)\n        elif s is self.grating_2_radioButton:\n            self.triax.Grating(2)\n        else:\n            raise ValueError('radio buttons not connected!')",
  "def __init__(self, Address, Calibration_Arrays=[],CCD_Horizontal_Resolution=1600):  \n        \"\"\"\n        Initialisation function for the triax class. Address in the port address of the triax connection. Calibration_Arrays is a list of 3x3 numpy arrays\n        containing the calibration coefficents for each grating in the spectrometer.\n        \"\"\"\n    \n        #--------Attempt to open communication------------\n\n        try:\n\n            VisaInstrument.__init__(self, Address, settings=dict(timeout=4000, write_termination='\\n'))\n            Attempts=0\n            End=False\n            while End is False:\n                if self.query(\" \")=='F':\n                    End=True\n                else:\n                    self.instr.write_raw('\\x4f\\x32\\x30\\x30\\x30\\x00') #Move from boot program to main program\n                    time.sleep(2)\n                    Attempts+=1\n                    if Attempts==5:\n                        raise Exception('Triax communication error!')\n\n        except:\n            raise Exception('Triax communication error!')\n\n        self.Calibration_Data=Calibration_Arrays\n\n        self.Wavelength_Array=None #Not intially set. Updated with a change of grating or stepper motor position\n        self.Number_of_Pixels=CCD_Horizontal_Resolution",
  "def Get_Wavelength_Array(self):\n        \"\"\"\n        Returns the wavelength array in memory. If it is yet to be calculated, it is caluculated here\n        \"\"\"\n        if self.Wavelength_Array is None:\n            Steps=self.Motor_Steps()\n            if Steps<self.Grating_Information[0][0] or Steps>self.Grating_Information[0][-1]:\n                print('WARNING: You are outside of the calibration range')\n            self.Wavelength_Array=self.Convert_Pixels_to_Wavelengths(np.array(range(self.Number_of_Pixels)),Steps)\n        return self.Wavelength_Array",
  "def Grating(self, Set_To=None):\n        \"\"\"\n        Function for checking or setting the grating number. If Set_To is left as None, current grating number is returned. If 0,1 or 2 is passed as Set_To, the\n        corresponding grating position is rotated to.\n        \"\"\"\n\n   \t\t#-----Check Input-------\n        \n        if Set_To not in [None,0,1,2]:\n            raise ValueError('Invalid input for grating input. Must be None, 0, 1, or 2.')\n\n        #----Return current grating or switch grating---------\n            \n        if Set_To is None:\n            return int(self.query(\"Z452,0,0,0\\r\")[1:])\n\n        else:\n            self.write(\"Z451,0,0,0,%i\\r\" % (Set_To))\n            time.sleep(1)\n            self.waitTillReady()\n            self.Grating_Number = Set_To",
  "def Motor_Steps(self):\n        \"\"\"\n        Returns the current rotation of the grating in units of steps of the internal stepper motor\n        \"\"\"\n        self.write(\"H0\\r\")\n        return int(self.read()[1:])",
  "def Convert_Pixels_to_Wavelengths(self,Pixel_Array,Steps=None):\n        if Steps is None:\n            Steps=self.Motor_Steps()\n\n        Extremes=[]\n        Calibration_Data=self.Calibration_Data[self.Grating()]\n        Root=Calibration_Data[1]\n        Calibration_Data=Calibration_Data[0]\n\n        Extremes=[]\n        for i in Calibration_Data:\n            a,b,c=i[1:]\n            Extremes.append([(-b+Root*((b**2-(4*a*(c-0)))**0.5))/(2*a),(-b+Root*((b**2-(4*a*(c-self.Number_of_Pixels+1)))**0.5))/(2*a)])\n\n        Start=np.floor(np.min(np.array(Extremes)))\n        End=np.ceil(np.max(np.array(Extremes)))\n\n        if Steps<Start:\n            print('Warning: You are outside of calibrated region')\n            Edge=self.Convert_Pixels_to_Wavelengths(Pixel_Array,Start)\n            In=self.Convert_Pixels_to_Wavelengths(Pixel_Array,Start+1)\n            Step=np.mean(Edge-In)\n            return (Start-Steps)*Step+Edge\n        if Steps>End:\n            print('Warning: You are outside of calibrated region')\n            Edge=self.Convert_Pixels_to_Wavelengths(Pixel_Array,End)\n            In=self.Convert_Pixels_to_Wavelengths(Pixel_Array,End-1)\n            Step=np.mean(Edge-In)\n            return (Steps-End)*Step+Edge\n\n        Known_Pixels=[]\n        Wavelengths=[]\n        for i in Calibration_Data:\n            Known_Pixels.append(np.sum(np.array([Steps**2,Steps,1])*i[1:]))\n            Wavelengths.append(i[0])\n        Output=Quad_Interp(np.array(Known_Pixels),np.array(Wavelengths),np.array(Pixel_Array))\n        return np.array(Output)",
  "def Find_Required_Step(self,Wavelength,Pixel,Require_Integer=True):\n        Bounds=[]\n        Calibration_Data=self.Calibration_Data[self.Grating()]\n        Root=Calibration_Data[1]\n        Calibration_Data=Calibration_Data[0]\n        for i in Calibration_Data:\n            a,b,c=i[1:]\n            Bounds+=[(-b+Root*((b**2-(4*a*(c-0)))**0.5))/(2*a),(-b+Root*((b**2-(4*a*(c-self.Number_of_Pixels+1)))**0.5))/(2*a)]\n\n        Bounds=[np.min(Bounds),np.max(Bounds)]\n        Values=[]\n        for i in Bounds:\n            Values.append(self.Convert_Pixels_to_Wavelengths([Pixel],Steps=i)[0])\n        if Values[1]<Values[0]:\n            Values=[Values[1],Values[0]]\n            Bounds=[Bounds[1],Bounds[0]]\n\n        if Wavelength<Values[0]:\n            raise Exception('Outside calibrated area! Cannot move below '+str(np.round(Values[0],2))+'nm for this pixel')\n        if Wavelength>Values[1]:\n            raise Exception('Outside calibrated area! Cannot move above '+str(np.round(Values[1],2))+'nm for this pixel')\n\n        while Bounds[1]-Bounds[0]>1:\n            New=np.mean(Bounds)\n            Value=self.Convert_Pixels_to_Wavelengths([Pixel],Steps=New)[0]\n            if Value<=Wavelength:\n                Bounds[0]=New\n                Values[0]=Value\n            else:\n                Bounds[1]=New\n                Values[1]=Value\n       \n        Fraction=(Wavelength-Values[0])/(Values[1]-Values[0])\n        Step=(1-Fraction)*Bounds[0]+Fraction*Bounds[1]\n        if Require_Integer is True:\n            Step=int(round(Step))\n        return Step",
  "def Move_Steps(self, Steps):\n        \"\"\"\n        Function to move the grating by a number of stepper motor Steps.\n        \"\"\"\n        \n        if (Steps <= 0):  # Taken from original code, assume there is an issue moving backwards that this corrects\n            self.write(\"F0,%i\\r\" % (Steps - 1000))\n            time.sleep(1)\n            self.waitTillReady()\n            self.write(\"F0,1000\\r\")\n            self.waitTillReady()\n        else:\n            self.write(\"F0,%i\\r\" % Steps)\n            time.sleep(1)\n            self.waitTillReady()",
  "def Set_Center_Wavelength(self,Wavelength):  \n        if self.ccd_size is None:\n            raise ValueError('ccd_size must be set in child class')\n        Centre_Pixel=int(self.ccd_size/2)\n        Required_Step=self.Find_Required_Step(Wavelength,Centre_Pixel)\n        Current_Step=self.Motor_Steps()\n        self.Move_Steps(Required_Step-Current_Step)",
  "def Get_Center_Wavelength(self):\n        wls = self.Get_Wavelength_Array()\n        return wls[len(wls)//2]",
  "def Slit(self, Width=None):\n        \"\"\"\n        Function to return or set the triax slit with in units of um. If Width is None, the current width is returned. \n        \"\"\"\n        \n        Current_Width=int(self.query(\"j0,0\\r\")[1:])\n        \n        if Width is None:\n            return Current_Width\n        elif Width > 0:\n           To_Move = Width - Current_Width\n        if To_Move == 0:\n            return\n        elif To_Move > 0:  # backlash correction\n            self.write(\"k0,0,%i\\r\" % (To_Move + 100))\n            self.waitTillReady()\n        \n            self.write(\"k0,0,-100\\r\")\n            self.waitTillReady()\n        else:\n            self.write(\"k0,0,%i\\r\" % To_Move)\n            self.waitTillReady()",
  "def _isBusy(self):\n        \"\"\"\n        Queries whether the Triax is willing to accept further commands\n        \"\"\"\n        \n        if self.query(\"E\") == 'oz':\n            return False\n        else:\n            return True",
  "def waitTillReady(self,Timeout=120):\n        \"\"\"\n        When called, this function checks the triax status once per second to check if it is busy. When it is not, the function returns. Also return automatically \n        after Timeout seconds.\n        \"\"\"\n\n        Start_Time = time.time()\n\n        while self._isBusy():\n            time.sleep(1)\n            if (time.time() - Start_Time) > Timeout:\n                self._logger.warn('Timed out')\n                print('Timed out')\n                break",
  "def reset(self):\n        self.instr.write_raw('\\xde')\n        time.sleep(5)\n        buff = self.query(\" \")\n        if buff == 'B':\n            self.instr.write_raw('\\x4f\\x32\\x30\\x30\\x30\\x00')  # <O2000>0\n            buff = self.query(\" \")\n        if buff == 'F':\n            self._logger.debug(\"Triax is reset\")\n            self.setup()",
  "def setup(self):\n        self._logger.info(\"Initiating motor. This will take some time...\")\n        self.write(\"A\")\n        time.sleep(60)\n        self.waitTillReady()\n        self.Grating(1)\n        self.Grating_Number = self.Grating()",
  "def exitLateral(self):\n        self.write(\"e0\\r\")\n        self.write(\"c0\\r\")",
  "def exitAxial(self):\n        self.write(\"f0\\r\")\n        self.write(\"d0\\r\")",
  "def __init__(self, triax, ui_file =os.path.join(os.path.dirname(__file__),'triax_ui.ui'),  parent=None):\n        assert isinstance(triax, Triax), \"instrument must be a Triax\"\n        super(TriaxUI, self).__init__()\n        uic.loadUi(ui_file, self)\n        self.triax = triax\n        self.centre_wl_lineEdit.returnPressed.connect(self.set_wl_gui)\n        self.slit_lineEdit.returnPressed.connect(self.set_slit_gui)     \n        self.centre_wl_lineEdit.setText(str(np.around(self.triax.center_wavelength)))\n        self.slit_lineEdit.setText(str(self.triax.Slit()))\n        eval('self.grating_'+str(self.triax.Grating())+'_radioButton.setChecked(True)')\n        for radio_button in range(3):\n            eval('self.grating_'+str(radio_button)+'_radioButton.clicked.connect(self.set_grating_gui)')",
  "def set_wl_gui(self):\n        self.triax.Set_Center_Wavelength(float(self.centre_wl_lineEdit.text().strip()))",
  "def set_slit_gui(self):\n        self.triax.Slit(float(self.slit_lineEdit.text().strip()))",
  "def set_grating_gui(self):\n        s = self.sender()\n        if s is self.grating_0_radioButton:\n            self.triax.Grating(0)\n        elif s is self.grating_1_radioButton:\n            self.triax.Grating(1)\n        elif s is self.grating_2_radioButton:\n            self.triax.Grating(2)\n        else:\n            raise ValueError('radio buttons not connected!')",
  "class Trandor(Andor):#Andor\n    ''' Wrapper class for the Triax and the andor\n    ''' \n    def __init__(self, white_shutter=None, triax_address = 'GPIB0::1::INSTR', use_shifts = False, laser = '_633'):\n        print ('Triax Information:')\n        super(Trandor,self).__init__()\n        self.triax = Triax(triax_address, Calibration_Arrays,CCD_Size) #Initialise triax\n        self.white_shutter = white_shutter\n        self.triax.ccd_size = CCD_Size\n        self.use_shifts = use_shifts\n        self.laser = laser\n        \n        print ('Current Grating:'+str(self.triax.Grating()))\n        print ('Current Slit Width:'+str(self.triax.Slit())+'um')\n        self.metadata_property_names += ('slit_width', 'wavelengths')\n        \n    def Grating(self, Set_To=None):\n        return self.triax.Grating(Set_To)\n\n    def Generate_Wavelength_Axis(self, use_shifts=None):\n\n        if use_shifts is None:\n            use_shifts = self.use_shifts\n        if use_shifts:\n            if self.laser == '_633': centre_wl = 632.8\n            elif self.laser == '_785': centre_wl = 784.81\n            wavelengths = np.array(self.triax.Get_Wavelength_Array()[::-1])\n            return ( 1./(centre_wl*1e-9)- 1./(wavelengths*1e-9))/100    \n        else:\n            return self.triax.Get_Wavelength_Array()[::-1]\n    x_axis = property(Generate_Wavelength_Axis)\n\n    @property\n    def wavelengths(self):\n        return self.Generate_Wavelength_Axis(use_shifts=False)\n    @property\n    def slit_width(self):\n        return self.triax.Slit()\n\n    def Test_Notch_Alignment(self):\n        \tAccepted=False\n        \twhile Accepted is False:\n        \t\tInput=input('WARNING! A slight misalignment of the narrow band notch filters could be catastrophic! Has the laser thoughput been tested? [Yes/No]')\n        \t\tif Input.upper() in ['Y','N','YES','NO']:\n        \t\t\tAccepted=True\n        \t\t\tif len(Input)>1:\n        \t\t\t\tInput=Input.upper()[0]\n        \tif Input.upper()=='Y':\n        \t\tprint ('You are now free to capture spectra')\n        \t\tself.Notch_Filters_Tested=True\n        \telse:\n        \t\tprint ('The next spectrum capture will be allowed for you to test this. Please LOWER the laser power and REDUCE the integration time.')\n        \t\tself.Notch_Filters_Tested=None\n    def Set_Center_Wavelength(self, wavelength):\n        ''' backwards compatability with lab codes that use trandor.Set_Center_Wavelength'''\n        self.triax.Set_Center_Wavelength(wavelength)",
  "def Capture(_AndorUI):\n    if _AndorUI.Andor.white_shutter is not None:\n        isopen = _AndorUI.Andor.white_shutter.is_open()\n        if isopen:\n            _AndorUI.Andor.white_shutter.close_shutter()\n        _AndorUI.Andor.raw_image(update_latest_frame = True)\n        if isopen:\n            _AndorUI.Andor.white_shutter.open_shutter()\n    else:\n        _AndorUI.Andor.raw_image(update_latest_frame = True)",
  "def __init__(self, white_shutter=None, triax_address = 'GPIB0::1::INSTR', use_shifts = False, laser = '_633'):\n        print ('Triax Information:')\n        super(Trandor,self).__init__()\n        self.triax = Triax(triax_address, Calibration_Arrays,CCD_Size) #Initialise triax\n        self.white_shutter = white_shutter\n        self.triax.ccd_size = CCD_Size\n        self.use_shifts = use_shifts\n        self.laser = laser\n        \n        print ('Current Grating:'+str(self.triax.Grating()))\n        print ('Current Slit Width:'+str(self.triax.Slit())+'um')\n        self.metadata_property_names += ('slit_width', 'wavelengths')",
  "def Grating(self, Set_To=None):\n        return self.triax.Grating(Set_To)",
  "def Generate_Wavelength_Axis(self, use_shifts=None):\n\n        if use_shifts is None:\n            use_shifts = self.use_shifts\n        if use_shifts:\n            if self.laser == '_633': centre_wl = 632.8\n            elif self.laser == '_785': centre_wl = 784.81\n            wavelengths = np.array(self.triax.Get_Wavelength_Array()[::-1])\n            return ( 1./(centre_wl*1e-9)- 1./(wavelengths*1e-9))/100    \n        else:\n            return self.triax.Get_Wavelength_Array()[::-1]",
  "def wavelengths(self):\n        return self.Generate_Wavelength_Axis(use_shifts=False)",
  "def slit_width(self):\n        return self.triax.Slit()",
  "def Test_Notch_Alignment(self):\n        \tAccepted=False\n        \twhile Accepted is False:\n        \t\tInput=input('WARNING! A slight misalignment of the narrow band notch filters could be catastrophic! Has the laser thoughput been tested? [Yes/No]')\n        \t\tif Input.upper() in ['Y','N','YES','NO']:\n        \t\t\tAccepted=True\n        \t\t\tif len(Input)>1:\n        \t\t\t\tInput=Input.upper()[0]\n        \tif Input.upper()=='Y':\n        \t\tprint ('You are now free to capture spectra')\n        \t\tself.Notch_Filters_Tested=True\n        \telse:\n        \t\tprint ('The next spectrum capture will be allowed for you to test this. Please LOWER the laser power and REDUCE the integration time.')\n        \t\tself.Notch_Filters_Tested=None",
  "def Set_Center_Wavelength(self, wavelength):\n        ''' backwards compatability with lab codes that use trandor.Set_Center_Wavelength'''\n        self.triax.Set_Center_Wavelength(wavelength)",
  "class Triax(VisaInstrument):\n    metadata_property_names = ('wavelength', )\n\n    def __init__(self, Address, Calibration_Data=[], CCD_Horizontal_Resolution=2000):  \n        \"\"\"\n        Initialisation function for the triax class. Address in the port address of the triax connection.\n\n        For each grating, a list of wavelengths used for calibration (in acending order) is put into Calibration Data, \n        followed by experimental data points for each quadratic coefficient. Pass an empty list to just get the pixel array back for that grating.\n\n        CCD_Horizontal_Resolution is an integer for the horizontal size of the camera used with the triax.\n\n        To calculate the wavelengths hitting each pixel, an inverse process is used. It is possible to find (approximate) the grating stepper motor position \n        required to put a wavelength on a given pixel. To calculate the wavelength array, a quadratic curve is returned such that the motor position required to \n        put each wavelength on each pixel is as close as possible to the real stepper motor position.\n        \"\"\"\n        \n        #--------Attempt to open communication------------\n\n        try:\n\n            VisaInstrument.__init__(self, Address, settings=dict(timeout=4000, write_termination='\\n'))\n            Attempts=0\n            End=False\n            while End is False:\n                if self.query(\" \")=='F':\n                    End=True\n                else:\n                    self.instr.write_raw('\\x4f\\x32\\x30\\x30\\x30\\x00') #Move from boot program to main program\n                    time.sleep(2)\n                    Attempts+=1\n                    if Attempts==5:\n                        raise Exception('Triax communication error!')\n\n        except:\n            raise Exception('Triax communication error!')\n\n        #----Generate initial 3x3 calibration arrays for the gratings used for initial estimate of wavelengths on each CCD pixel--------\n        \n        self.Grating_Number=self.Grating() #Current grating number\n        self.Calibration_Arrays=[]\n        for i in Calibration_Data:\n            self.Calibration_Arrays.append([])\n            if len(i)==4:\n                for j in i[1:]:\n                    self.Calibration_Arrays[-1].append(np.polyfit(i[0],j,2))\n\n\n        #---------Generate the quadratic fit data to create quadratic splines for the 3x3 calibration arrays for the gratings, used to improve wavelength estimation-----------\n\n        self.Spline_Data=[]   \n        for i in Calibration_Data:\n            self.Spline_Data.append([])\n            if len(i)==4:\n                self.Spline_Data[-1].append(i[0])\n                for j in i[1:]:\n                    self.Spline_Data[-1].append([])\n                    for k in range(len(self.Spline_Data[-1][0]))[1:-1]:\n                        self.Spline_Data[-1][-1].append(np.polyfit(self.Spline_Data[-1][0][k-1:k+2],j[k-1:k+2],2))\n\n        #---print regions each grating is calibrated over\n\n        self.Regions=[]\n\n        print('This Triax spectrometer is calibrated for use over the following ranges:')\n        for i in range(len(Calibration_Data)):\n            if len(Calibration_Data[i])==4:\n                print('Grating',i,':',np.min(Calibration_Data[i][0]),'nm - ',np.max(Calibration_Data[i][0]),'nm')\n                self.Regions.append([np.min(Calibration_Data[i][0]),np.max(Calibration_Data[i][0])])\n            else:\n                self.Regions.append(None)\n\n        self.Wavelength_Array = None #Not intially set. Updated with a change of grating or stepper motor position\n        self.Number_of_Pixels=CCD_Horizontal_Resolution\n\n    def Get_Wavelength_Array(self):\n        \"\"\"\n        Returns the wavelength array in memory. If it is yet to be calculated, it is caluculated here\n        \"\"\"\n        if self.Wavelength_Array is None:\n            self.Wavelength_Array=self.Convert_Pixels_to_Wavelengths(np.array(list(range(self.Number_of_Pixels))))\n        return self.Wavelength_Array\n\n    def Grating(self, Set_To=None):\n        \"\"\"\n        Function for checking or setting the grating number. If Set_To is left as None, current grating number is returned. If 0,1 or 2 is passed as Set_To, the\n        corresponding grating position is rotated to.\n        \"\"\"\n\n   \t\t#-----Check Input-------\n        \n        if Set_To not in [None,0,1,2]:\n            raise ValueError('Invalid input for grating input. Must be None, 0, 1, or 2.')\n\n        #----Return current grating or switch grating---------\n            \n        if Set_To is None:\n            return int(self.query(\"Z452,0,0,0\\r\")[1:])\n\n        else:\n            self.write(\"Z451,0,0,0,%i\\r\" % (Set_To))\n            time.sleep(1)\n            self.waitTillReady()\n            self.Grating_Number = Set_To\n            #try:\n            self.Wavelength_Array=self.Convert_Pixels_to_Wavelengths(np.arange(self.Number_of_Pixels)) #Update wavelength array\n            #except:\n                #Dump=1\n\n    def Motor_Steps(self):\n        \"\"\"\n        Returns the current rotation of the grating in units of steps of the internal stepper motor\n        \"\"\"\n\n        self.write(\"H0\\r\")\n        return int(self.read()[1:])\n\n    def Convert_Pixels_to_Wavelengths(self,Pixel_Array):\n        \"\"\"\n        A function to convert a given Pixel Array into a wavelength array depending on the current Grating and Grating Position.\n\n        Achieves this by optimising wavelengths on each pixel that would require the current grating motor stepper position.\n\n        Result is always a quadratic approximation.\n        \"\"\"\n\n        Steps=self.Motor_Steps() #Check grating position\n\n        if self.Grating_Number<=len(self.Calibration_Arrays): #Check calibration exists\n            if len(self.Calibration_Arrays)==0 or len(self.Calibration_Arrays[self.Grating_Number])==0:\n                return Pixel_Array\n\n        Sample_Pixels=np.linspace(np.min(Pixel_Array),np.max(Pixel_Array),10) #Make some estimates to the nearest 0.1nm\n        Sample_Wavelengths=[np.mean(self.Regions[self.Grating_Number])]\n        while len(Sample_Wavelengths)<len(Sample_Pixels):\n            Sample_Wavelengths.append(Sample_Wavelengths[0])\n        Range=0.5*(self.Regions[self.Grating_Number][1]-self.Regions[self.Grating_Number][0])\n        Spacing=[10.,1.,0.1]\n\n        while len(Spacing)>0:\n            for i in range(len(Sample_Pixels)):\n                To_Test=np.arange(Sample_Wavelengths[i]-Range,Sample_Wavelengths[i]+Range,Spacing[0])\n                Results=[]\n                for j in To_Test:\n                    Results.append(self.Find_Required_Step(j,Sample_Pixels[i],False))\n                Sample_Wavelengths[i]=To_Test[np.argmin(np.abs(np.array(Results)-Steps))]\n            Range=Spacing[0]\n            Spacing=Spacing[1:]\n\n        #Use estimates to find a quadratic relation\n\n        Coefficents=np.polyfit(Sample_Pixels,Sample_Wavelengths,2)\n\n        #Optimise this relation over all pixels\n\n        def Loss(Coefficents):\n            Wavelengths = np.polyval(np.polyfit(Sample_Pixels,Sample_Wavelengths,2),Pixel_Array)\n            Diff=[]\n            for i in range(len(Pixel_Array)):\n                Diff.append(self.Find_Required_Step(Wavelengths[i],Pixel_Array[i],False)-Steps)\n            return np.sum(np.abs(Diff))\n\n        Coefficents=spo.minimize(Loss,Coefficents).x\n\n        Wavelengths=np.polyval(np.polyfit(Sample_Pixels,Sample_Wavelengths,2), Pixel_Array)\n\n        return Wavelengths\n           \n    def Find_Required_Step(self,Wavelength,Pixel,Require_Integer=True):\n        \"\"\"\n        Function to return the required motor step value that would place a given Wavelength on a given Pixel of the CCD\n        \"\"\"\n\n        if self.Grating_Number>=len(self.Calibration_Arrays) or len(self.Calibration_Arrays[self.Grating_Number])==0: #Check calibration exists\n            raise ValueError('Current grating is not calibrated! No calibration supplied!')\n\n        Spline_Data=self.Spline_Data[self.Grating_Number]\n\n        Coefficent_Blocks=[]\n        for i in range(len(Spline_Data[1])):\n            Coefficent_Blocks.append(np.array([Spline_Data[1][i],Spline_Data[2][i],Spline_Data[3][i]]))\n\n        #-----Calculate the 3x3 calibration matrix to use-----------    \n\n        Region=0\n        while Region<len(Spline_Data[0]) and Spline_Data[0][Region]<Wavelength:\n            Region+=1\n\n        if Region<=1:\n            Coefficents=Coefficent_Blocks[0]\n        elif Region>=len(Spline_Data)-1:\n            Coefficents=Coefficent_Blocks[-1]\n        else:\n            Frac=(Wavelength-Spline_Data[0][Region-1])/(Spline_Data[0][Region]-Spline_Data[0][Region-1])\n            Coefficents=(1-Frac)*Coefficent_Blocks[Region-2]+Frac*Coefficent_Blocks[Region-1]\n        \n        #Perform Conversion\n        \n        Coefficents=np.sum(Coefficents*np.array([Wavelength**2,Wavelength,1.]),axis=1)\n\n        Output=(-Coefficents[1]-np.sqrt((Coefficents[1]**2)-(4*Coefficents[0]*(Coefficents[2]-Pixel))))/(2*Coefficents[0])\n        if Require_Integer is True:\n            Output=int(Output)\n       \n        return Output\n\n    def Move_Steps(self, Steps):\n        \"\"\"\n        Function to move the grating by a number of stepper motor Steps.\n        \"\"\"\n        \n        if (Steps <= 0):  # Taken from original code, assume there is an issue moving backwards that this corrects\n            self.write(\"F0,%i\\r\" % (Steps - 1000))\n            time.sleep(1)\n            self.waitTillReady()\n            self.write(\"F0,1000\\r\")\n            self.waitTillReady()\n        else:\n            self.write(\"F0,%i\\r\" % Steps)\n            time.sleep(1)\n            self.waitTillReady()\n        self.Wavelength_Array=self.Convert_Pixels_to_Wavelengths(np.array(list(range(self.Number_of_Pixels)))) #Update wavelength array\n\n    def Set_Center_Wavelength(self,Wavelength):  \n        if self.ccd_size is None:\n            raise ValueError('ccd_size must be set in child class')\n        Centre_Pixel=int(self.ccd_size/2)\n        Required_Step=self.Find_Required_Step(Wavelength,Centre_Pixel)\n        Current_Step=self.Motor_Steps()\n        self.Move_Steps(Required_Step-Current_Step)\n    \n    def Get_Center_Wavelength(self):\n        wls = self.Get_Wavelength_Array()\n        return wls[len(wls)//2]\n    \n    center_wavelength = property(Get_Center_Wavelength, Set_Center_Wavelength)    \n\n    def Slit(self, Width=None):\n        \"\"\"\n        Function to return or set the triax slit with in units of um. If Width is None, the current width is returned. \n        \"\"\"\n        \n        Current_Width=int(self.query(\"j0,0\\r\")[1:])\n        \n        if Width is None:\n            return Current_Width\n        elif Width > 0:\n           To_Move = Width - Current_Width\n        if To_Move == 0:\n            return\n        elif To_Move > 0:  # backlash correction\n            self.write(\"k0,0,%i\\r\" % (To_Move + 100))\n            self.waitTillReady()\n        \n            self.write(\"k0,0,-100\\r\")\n            self.waitTillReady()\n        else:\n            self.write(\"k0,0,%i\\r\" % To_Move)\n            self.waitTillReady()\n\n    def _isBusy(self):\n        \"\"\"\n        Queries whether the Triax is willing to accept further commands\n        \"\"\"\n        \n        if self.query(\"E\") == 'oz':\n            return False\n        else:\n            return True\n\n    def waitTillReady(self,Timeout=120):\n        \"\"\"\n        When called, this function checks the triax status once per second to check if it is busy. When it is not, the function returns. Also return automatically \n        after Timeout seconds.\n        \"\"\"\n\n        Start_Time = time.time()\n\n        while self._isBusy():\n            time.sleep(1)\n            if (time.time() - Start_Time) > Timeout:\n                self._logger.warn('Timed out')\n                print('Timed out')\n                break\n    def get_qt_ui(self):\n        return TriaxUI(self)\n    #-------------------------------------------------------------------------------------------------\n\n    \"\"\"\n\tHeld here are functions from old code by Hamid Ohadi that, at this point in time, I do not wish to touch\n    \"\"\"\n\n    def reset(self):\n        self.instr.write_raw(b'\\xde')\n        time.sleep(5)\n        buff = self.query(\" \")\n        if buff == 'B':\n            self.instr.write_raw(b'\\x4f\\x32\\x30\\x30\\x30\\x00')  # <O2000>0\n            buff = self.query(\" \")\n        if buff == 'F':\n            self._logger.debug(\"Triax is reset\")\n            self.setup()\n\n    def setup(self):\n        self._logger.info(\"Initiating motor. This will take some time...\")\n        self.write(\"A\")\n        # time.sleep(60)\n        # self.waitTillReady()\n        # self.Grating(1)\n        # self.Grating_Number = self.Grating()\n\n    def exitLateral(self):\n        self.write(\"e0\\r\")\n        self.write(\"c0\\r\")  # sets entrance mirror to lateral as well\n\n    def exitAxial(self):\n        self.write(\"f0\\r\")\n        self.write(\"d0\\r\")",
  "class TriaxUI(QtWidgets.QWidget,UiTools):\n    def __init__(self, triax, ui_file =os.path.join(os.path.dirname(__file__),'triax_ui.ui'),  parent=None):\n        assert isinstance(triax, Triax), \"instrument must be a Triax\"\n        super(TriaxUI, self).__init__()\n        uic.loadUi(ui_file, self)\n        self.triax = triax\n        self.centre_wl_lineEdit.returnPressed.connect(self.set_wl_gui)\n        self.slit_lineEdit.returnPressed.connect(self.set_slit_gui)     \n        self.centre_wl_lineEdit.setText(str(np.around(self.triax.center_wavelength)))\n        self.slit_lineEdit.setText(str(self.triax.Slit()))\n        eval('self.grating_'+str(self.triax.Grating())+'_radioButton.setChecked(True)')\n        for radio_button in range(3):\n            eval('self.grating_'+str(radio_button)+'_radioButton.clicked.connect(self.set_grating_gui)')\n    def set_wl_gui(self):\n        self.triax.Set_Center_Wavelength(float(self.centre_wl_lineEdit.text().strip()))\n    def set_slit_gui(self):\n        self.triax.Slit(float(self.slit_lineEdit.text().strip()))\n    def set_grating_gui(self):\n        s = self.sender()\n        if s is self.grating_0_radioButton:\n            self.triax.Grating(0)\n        elif s is self.grating_1_radioButton:\n            self.triax.Grating(1)\n        elif s is self.grating_2_radioButton:\n            self.triax.Grating(2)\n        else:\n            raise ValueError('radio buttons not connected!')",
  "def __init__(self, Address, Calibration_Data=[], CCD_Horizontal_Resolution=2000):  \n        \"\"\"\n        Initialisation function for the triax class. Address in the port address of the triax connection.\n\n        For each grating, a list of wavelengths used for calibration (in acending order) is put into Calibration Data, \n        followed by experimental data points for each quadratic coefficient. Pass an empty list to just get the pixel array back for that grating.\n\n        CCD_Horizontal_Resolution is an integer for the horizontal size of the camera used with the triax.\n\n        To calculate the wavelengths hitting each pixel, an inverse process is used. It is possible to find (approximate) the grating stepper motor position \n        required to put a wavelength on a given pixel. To calculate the wavelength array, a quadratic curve is returned such that the motor position required to \n        put each wavelength on each pixel is as close as possible to the real stepper motor position.\n        \"\"\"\n        \n        #--------Attempt to open communication------------\n\n        try:\n\n            VisaInstrument.__init__(self, Address, settings=dict(timeout=4000, write_termination='\\n'))\n            Attempts=0\n            End=False\n            while End is False:\n                if self.query(\" \")=='F':\n                    End=True\n                else:\n                    self.instr.write_raw('\\x4f\\x32\\x30\\x30\\x30\\x00') #Move from boot program to main program\n                    time.sleep(2)\n                    Attempts+=1\n                    if Attempts==5:\n                        raise Exception('Triax communication error!')\n\n        except:\n            raise Exception('Triax communication error!')\n\n        #----Generate initial 3x3 calibration arrays for the gratings used for initial estimate of wavelengths on each CCD pixel--------\n        \n        self.Grating_Number=self.Grating() #Current grating number\n        self.Calibration_Arrays=[]\n        for i in Calibration_Data:\n            self.Calibration_Arrays.append([])\n            if len(i)==4:\n                for j in i[1:]:\n                    self.Calibration_Arrays[-1].append(np.polyfit(i[0],j,2))\n\n\n        #---------Generate the quadratic fit data to create quadratic splines for the 3x3 calibration arrays for the gratings, used to improve wavelength estimation-----------\n\n        self.Spline_Data=[]   \n        for i in Calibration_Data:\n            self.Spline_Data.append([])\n            if len(i)==4:\n                self.Spline_Data[-1].append(i[0])\n                for j in i[1:]:\n                    self.Spline_Data[-1].append([])\n                    for k in range(len(self.Spline_Data[-1][0]))[1:-1]:\n                        self.Spline_Data[-1][-1].append(np.polyfit(self.Spline_Data[-1][0][k-1:k+2],j[k-1:k+2],2))\n\n        #---print regions each grating is calibrated over\n\n        self.Regions=[]\n\n        print('This Triax spectrometer is calibrated for use over the following ranges:')\n        for i in range(len(Calibration_Data)):\n            if len(Calibration_Data[i])==4:\n                print('Grating',i,':',np.min(Calibration_Data[i][0]),'nm - ',np.max(Calibration_Data[i][0]),'nm')\n                self.Regions.append([np.min(Calibration_Data[i][0]),np.max(Calibration_Data[i][0])])\n            else:\n                self.Regions.append(None)\n\n        self.Wavelength_Array = None #Not intially set. Updated with a change of grating or stepper motor position\n        self.Number_of_Pixels=CCD_Horizontal_Resolution",
  "def Get_Wavelength_Array(self):\n        \"\"\"\n        Returns the wavelength array in memory. If it is yet to be calculated, it is caluculated here\n        \"\"\"\n        if self.Wavelength_Array is None:\n            self.Wavelength_Array=self.Convert_Pixels_to_Wavelengths(np.array(list(range(self.Number_of_Pixels))))\n        return self.Wavelength_Array",
  "def Grating(self, Set_To=None):\n        \"\"\"\n        Function for checking or setting the grating number. If Set_To is left as None, current grating number is returned. If 0,1 or 2 is passed as Set_To, the\n        corresponding grating position is rotated to.\n        \"\"\"\n\n   \t\t#-----Check Input-------\n        \n        if Set_To not in [None,0,1,2]:\n            raise ValueError('Invalid input for grating input. Must be None, 0, 1, or 2.')\n\n        #----Return current grating or switch grating---------\n            \n        if Set_To is None:\n            return int(self.query(\"Z452,0,0,0\\r\")[1:])\n\n        else:\n            self.write(\"Z451,0,0,0,%i\\r\" % (Set_To))\n            time.sleep(1)\n            self.waitTillReady()\n            self.Grating_Number = Set_To\n            #try:\n            self.Wavelength_Array=self.Convert_Pixels_to_Wavelengths(np.arange(self.Number_of_Pixels))",
  "def Motor_Steps(self):\n        \"\"\"\n        Returns the current rotation of the grating in units of steps of the internal stepper motor\n        \"\"\"\n\n        self.write(\"H0\\r\")\n        return int(self.read()[1:])",
  "def Convert_Pixels_to_Wavelengths(self,Pixel_Array):\n        \"\"\"\n        A function to convert a given Pixel Array into a wavelength array depending on the current Grating and Grating Position.\n\n        Achieves this by optimising wavelengths on each pixel that would require the current grating motor stepper position.\n\n        Result is always a quadratic approximation.\n        \"\"\"\n\n        Steps=self.Motor_Steps() #Check grating position\n\n        if self.Grating_Number<=len(self.Calibration_Arrays): #Check calibration exists\n            if len(self.Calibration_Arrays)==0 or len(self.Calibration_Arrays[self.Grating_Number])==0:\n                return Pixel_Array\n\n        Sample_Pixels=np.linspace(np.min(Pixel_Array),np.max(Pixel_Array),10) #Make some estimates to the nearest 0.1nm\n        Sample_Wavelengths=[np.mean(self.Regions[self.Grating_Number])]\n        while len(Sample_Wavelengths)<len(Sample_Pixels):\n            Sample_Wavelengths.append(Sample_Wavelengths[0])\n        Range=0.5*(self.Regions[self.Grating_Number][1]-self.Regions[self.Grating_Number][0])\n        Spacing=[10.,1.,0.1]\n\n        while len(Spacing)>0:\n            for i in range(len(Sample_Pixels)):\n                To_Test=np.arange(Sample_Wavelengths[i]-Range,Sample_Wavelengths[i]+Range,Spacing[0])\n                Results=[]\n                for j in To_Test:\n                    Results.append(self.Find_Required_Step(j,Sample_Pixels[i],False))\n                Sample_Wavelengths[i]=To_Test[np.argmin(np.abs(np.array(Results)-Steps))]\n            Range=Spacing[0]\n            Spacing=Spacing[1:]\n\n        #Use estimates to find a quadratic relation\n\n        Coefficents=np.polyfit(Sample_Pixels,Sample_Wavelengths,2)\n\n        #Optimise this relation over all pixels\n\n        def Loss(Coefficents):\n            Wavelengths = np.polyval(np.polyfit(Sample_Pixels,Sample_Wavelengths,2),Pixel_Array)\n            Diff=[]\n            for i in range(len(Pixel_Array)):\n                Diff.append(self.Find_Required_Step(Wavelengths[i],Pixel_Array[i],False)-Steps)\n            return np.sum(np.abs(Diff))\n\n        Coefficents=spo.minimize(Loss,Coefficents).x\n\n        Wavelengths=np.polyval(np.polyfit(Sample_Pixels,Sample_Wavelengths,2), Pixel_Array)\n\n        return Wavelengths",
  "def Find_Required_Step(self,Wavelength,Pixel,Require_Integer=True):\n        \"\"\"\n        Function to return the required motor step value that would place a given Wavelength on a given Pixel of the CCD\n        \"\"\"\n\n        if self.Grating_Number>=len(self.Calibration_Arrays) or len(self.Calibration_Arrays[self.Grating_Number])==0: #Check calibration exists\n            raise ValueError('Current grating is not calibrated! No calibration supplied!')\n\n        Spline_Data=self.Spline_Data[self.Grating_Number]\n\n        Coefficent_Blocks=[]\n        for i in range(len(Spline_Data[1])):\n            Coefficent_Blocks.append(np.array([Spline_Data[1][i],Spline_Data[2][i],Spline_Data[3][i]]))\n\n        #-----Calculate the 3x3 calibration matrix to use-----------    \n\n        Region=0\n        while Region<len(Spline_Data[0]) and Spline_Data[0][Region]<Wavelength:\n            Region+=1\n\n        if Region<=1:\n            Coefficents=Coefficent_Blocks[0]\n        elif Region>=len(Spline_Data)-1:\n            Coefficents=Coefficent_Blocks[-1]\n        else:\n            Frac=(Wavelength-Spline_Data[0][Region-1])/(Spline_Data[0][Region]-Spline_Data[0][Region-1])\n            Coefficents=(1-Frac)*Coefficent_Blocks[Region-2]+Frac*Coefficent_Blocks[Region-1]\n        \n        #Perform Conversion\n        \n        Coefficents=np.sum(Coefficents*np.array([Wavelength**2,Wavelength,1.]),axis=1)\n\n        Output=(-Coefficents[1]-np.sqrt((Coefficents[1]**2)-(4*Coefficents[0]*(Coefficents[2]-Pixel))))/(2*Coefficents[0])\n        if Require_Integer is True:\n            Output=int(Output)\n       \n        return Output",
  "def Move_Steps(self, Steps):\n        \"\"\"\n        Function to move the grating by a number of stepper motor Steps.\n        \"\"\"\n        \n        if (Steps <= 0):  # Taken from original code, assume there is an issue moving backwards that this corrects\n            self.write(\"F0,%i\\r\" % (Steps - 1000))\n            time.sleep(1)\n            self.waitTillReady()\n            self.write(\"F0,1000\\r\")\n            self.waitTillReady()\n        else:\n            self.write(\"F0,%i\\r\" % Steps)\n            time.sleep(1)\n            self.waitTillReady()\n        self.Wavelength_Array=self.Convert_Pixels_to_Wavelengths(np.array(list(range(self.Number_of_Pixels))))",
  "def Set_Center_Wavelength(self,Wavelength):  \n        if self.ccd_size is None:\n            raise ValueError('ccd_size must be set in child class')\n        Centre_Pixel=int(self.ccd_size/2)\n        Required_Step=self.Find_Required_Step(Wavelength,Centre_Pixel)\n        Current_Step=self.Motor_Steps()\n        self.Move_Steps(Required_Step-Current_Step)",
  "def Get_Center_Wavelength(self):\n        wls = self.Get_Wavelength_Array()\n        return wls[len(wls)//2]",
  "def Slit(self, Width=None):\n        \"\"\"\n        Function to return or set the triax slit with in units of um. If Width is None, the current width is returned. \n        \"\"\"\n        \n        Current_Width=int(self.query(\"j0,0\\r\")[1:])\n        \n        if Width is None:\n            return Current_Width\n        elif Width > 0:\n           To_Move = Width - Current_Width\n        if To_Move == 0:\n            return\n        elif To_Move > 0:  # backlash correction\n            self.write(\"k0,0,%i\\r\" % (To_Move + 100))\n            self.waitTillReady()\n        \n            self.write(\"k0,0,-100\\r\")\n            self.waitTillReady()\n        else:\n            self.write(\"k0,0,%i\\r\" % To_Move)\n            self.waitTillReady()",
  "def _isBusy(self):\n        \"\"\"\n        Queries whether the Triax is willing to accept further commands\n        \"\"\"\n        \n        if self.query(\"E\") == 'oz':\n            return False\n        else:\n            return True",
  "def waitTillReady(self,Timeout=120):\n        \"\"\"\n        When called, this function checks the triax status once per second to check if it is busy. When it is not, the function returns. Also return automatically \n        after Timeout seconds.\n        \"\"\"\n\n        Start_Time = time.time()\n\n        while self._isBusy():\n            time.sleep(1)\n            if (time.time() - Start_Time) > Timeout:\n                self._logger.warn('Timed out')\n                print('Timed out')\n                break",
  "def get_qt_ui(self):\n        return TriaxUI(self)",
  "def reset(self):\n        self.instr.write_raw(b'\\xde')\n        time.sleep(5)\n        buff = self.query(\" \")\n        if buff == 'B':\n            self.instr.write_raw(b'\\x4f\\x32\\x30\\x30\\x30\\x00')  # <O2000>0\n            buff = self.query(\" \")\n        if buff == 'F':\n            self._logger.debug(\"Triax is reset\")\n            self.setup()",
  "def setup(self):\n        self._logger.info(\"Initiating motor. This will take some time...\")\n        self.write(\"A\")",
  "def exitLateral(self):\n        self.write(\"e0\\r\")\n        self.write(\"c0\\r\")",
  "def exitAxial(self):\n        self.write(\"f0\\r\")\n        self.write(\"d0\\r\")",
  "def __init__(self, triax, ui_file =os.path.join(os.path.dirname(__file__),'triax_ui.ui'),  parent=None):\n        assert isinstance(triax, Triax), \"instrument must be a Triax\"\n        super(TriaxUI, self).__init__()\n        uic.loadUi(ui_file, self)\n        self.triax = triax\n        self.centre_wl_lineEdit.returnPressed.connect(self.set_wl_gui)\n        self.slit_lineEdit.returnPressed.connect(self.set_slit_gui)     \n        self.centre_wl_lineEdit.setText(str(np.around(self.triax.center_wavelength)))\n        self.slit_lineEdit.setText(str(self.triax.Slit()))\n        eval('self.grating_'+str(self.triax.Grating())+'_radioButton.setChecked(True)')\n        for radio_button in range(3):\n            eval('self.grating_'+str(radio_button)+'_radioButton.clicked.connect(self.set_grating_gui)')",
  "def set_wl_gui(self):\n        self.triax.Set_Center_Wavelength(float(self.centre_wl_lineEdit.text().strip()))",
  "def set_slit_gui(self):\n        self.triax.Slit(float(self.slit_lineEdit.text().strip()))",
  "def set_grating_gui(self):\n        s = self.sender()\n        if s is self.grating_0_radioButton:\n            self.triax.Grating(0)\n        elif s is self.grating_1_radioButton:\n            self.triax.Grating(1)\n        elif s is self.grating_2_radioButton:\n            self.triax.Grating(2)\n        else:\n            raise ValueError('radio buttons not connected!')",
  "def Loss(Coefficents):\n            Wavelengths = np.polyval(np.polyfit(Sample_Pixels,Sample_Wavelengths,2),Pixel_Array)\n            Diff=[]\n            for i in range(len(Pixel_Array)):\n                Diff.append(self.Find_Required_Step(Wavelengths[i],Pixel_Array[i],False)-Steps)\n            return np.sum(np.abs(Diff))",
  "class SuperChromeUIAuto(object):\n    \"\"\" A class for controlling the fianium superchrome filter using UI automation\n    \"\"\"\n    def __init__(self):\n        self.filter_app = Application().connect(path = r\"C:\\Program Files (x86)\\Fianium\\SuperChrome\\SuperChromeTest.exe\")\n        self.filter_diag = self.filter_app.TestDualVariableFilter\n        \n    def select_filter(self, filter_str):\n        \n        if filter_str.lower() == 'filter1':\n            self.filter_diag.Filter1.click()\n            self.filter_diag.InBeamPath.click()\n        else: \n            if filter_str.lower() == 'filter2':\n                self.filter_diag.Filter2.click()\n                self.filter_diag.InBeamPath.click()\n    \n    def move_filter_pos(self, filter_str = 'Filter2', filter_pos = 5800):\n        \n        if filter_str.lower() == 'filter1' or filter_str.lower() == 'filter2':\n            self.select_filter(filter_str)\n            self.filter_diag.Edit6.type_keys(str(filter_pos))\n            self.filter_diag.Apply.click()\n        else:\n            display('Invalid filter name')\n    \n    def move_out_of_beam(self, filter_str = 'Filter2'):\n        \n        if filter_str.lower() == 'filter1':\n            self.filter_diag.Filter1.click()\n            self.filter_diag.OutBeamPath.click()\n            self.filter_diag.Apply.click()\n            \n        else: \n            if filter_str.lower() == 'filter2':\n                self.filter_diag.Filter2.click()\n                self.filter_diag.OutBeamPath.click()\n                self.filter_diag.Apply.click()\n            else: \n                display('Invalid filter name')\n                \n    def move_filter_wavelength(self, filter_str = 'Filter2', cut_off = 650):\n        \n\n        if filter_str.lower() == 'filter2':\n            self.lookup_table = np.loadtxt(r'E:\\OneDrive - University Of Cambridge\\Ultrafast Raman Rig\\fo263\\filter2_lookup_table.txt')\n        if filter_str.lower() == 'filter1':\n            display('Filter1 is not yet calibrated. Sorry!')\n            return\n        \n        filter_pos = old_div(np.abs(self.lookup_table - cut_off).argmin(),2)\n        self.move_filter_pos(filter_str, self.lookup_table[int(filter_pos)][0])",
  "def __init__(self):\n        self.filter_app = Application().connect(path = r\"C:\\Program Files (x86)\\Fianium\\SuperChrome\\SuperChromeTest.exe\")\n        self.filter_diag = self.filter_app.TestDualVariableFilter",
  "def select_filter(self, filter_str):\n        \n        if filter_str.lower() == 'filter1':\n            self.filter_diag.Filter1.click()\n            self.filter_diag.InBeamPath.click()\n        else: \n            if filter_str.lower() == 'filter2':\n                self.filter_diag.Filter2.click()\n                self.filter_diag.InBeamPath.click()",
  "def move_filter_pos(self, filter_str = 'Filter2', filter_pos = 5800):\n        \n        if filter_str.lower() == 'filter1' or filter_str.lower() == 'filter2':\n            self.select_filter(filter_str)\n            self.filter_diag.Edit6.type_keys(str(filter_pos))\n            self.filter_diag.Apply.click()\n        else:\n            display('Invalid filter name')",
  "def move_out_of_beam(self, filter_str = 'Filter2'):\n        \n        if filter_str.lower() == 'filter1':\n            self.filter_diag.Filter1.click()\n            self.filter_diag.OutBeamPath.click()\n            self.filter_diag.Apply.click()\n            \n        else: \n            if filter_str.lower() == 'filter2':\n                self.filter_diag.Filter2.click()\n                self.filter_diag.OutBeamPath.click()\n                self.filter_diag.Apply.click()\n            else: \n                display('Invalid filter name')",
  "def move_filter_wavelength(self, filter_str = 'Filter2', cut_off = 650):\n        \n\n        if filter_str.lower() == 'filter2':\n            self.lookup_table = np.loadtxt(r'E:\\OneDrive - University Of Cambridge\\Ultrafast Raman Rig\\fo263\\filter2_lookup_table.txt')\n        if filter_str.lower() == 'filter1':\n            display('Filter1 is not yet calibrated. Sorry!')\n            return\n        \n        filter_pos = old_div(np.abs(self.lookup_table - cut_off).argmin(),2)\n        self.move_filter_pos(filter_str, self.lookup_table[int(filter_pos)][0])",
  "class VariSpec(SerialInstrument):\n    termination_character = \"\\r\"\n    port_settings = dict(baudrate=9600,bytesize=serial.EIGHTBITS,\n                        parity=serial.PARITY_NONE,\n                        stopbits=serial.STOPBITS_ONE,\n                        timeout=1, #wait at most one second for a response\n                        writeTimeout=1, #similarly, fail if writing takes >1s\n                        xonxoff=False, rtscts=False, dsrdtr=False\n                    )  \n    ignore_echo = True\n    \n    def __init__(self, port):\n        super().__init__(port=port)\n        self._set = False\n        self._logger.info(f'wavelength range = {self.wavelength_range}')\n    \n    def reset_error(self):\n        self.write(\"R 1\")\n    \n    def get_wavelength(self):\n        if self._set:\n            return float(self.query(\"W ?\")[3:])\n        else:\n            self._logger.warning('wavelength has not been set')\n    \n    def set_wavelength(self, wl):\n        self._set = True\n        self.write(f'W {wl:.2f}')\n        e = self.get_error()\n        if e =='0':\n            return \n        if e == '12': \n            self._logger.warning(f'{wl=} out of range')\n        else:\n            self._logger.warning(f'error code {e} raised')\n  \n    wavelength = NotifiedProperty(get_wavelength, set_wavelength) \n    wl = wavelength\n    \n    def get_error(self):\n        e = self.query('R ?')[1:].strip()\n        self.reset_error()\n        return e\n    \n    \n    def get_wavelength_range(self):\n        return tuple(map(float, self.query('V ?').split()[2:4]))\n    wavelength_range = property(get_wavelength_range)\n    wl_range = wavelength_range\n    def get_qt_ui(self):\n        return VariSpecUI(self)",
  "class VariSpecUI(QuickControlBox):\n    def __init__(self, instr):\n        super().__init__()\n        self.instr = instr\n        self.add_doublespinbox('wavelength', *instr.get_wavelength_range())\n        self.add_button('reset_error')\n        self.auto_connect_by_name(controlled_object=instr)",
  "def __init__(self, port):\n        super().__init__(port=port)\n        self._set = False\n        self._logger.info(f'wavelength range = {self.wavelength_range}')",
  "def reset_error(self):\n        self.write(\"R 1\")",
  "def get_wavelength(self):\n        if self._set:\n            return float(self.query(\"W ?\")[3:])\n        else:\n            self._logger.warning('wavelength has not been set')",
  "def set_wavelength(self, wl):\n        self._set = True\n        self.write(f'W {wl:.2f}')\n        e = self.get_error()\n        if e =='0':\n            return \n        if e == '12': \n            self._logger.warning(f'{wl=} out of range')\n        else:\n            self._logger.warning(f'error code {e} raised')",
  "def get_error(self):\n        e = self.query('R ?')[1:].strip()\n        self.reset_error()\n        return e",
  "def get_wavelength_range(self):\n        return tuple(map(float, self.query('V ?').split()[2:4]))",
  "def get_qt_ui(self):\n        return VariSpecUI(self)",
  "def __init__(self, instr):\n        super().__init__()\n        self.instr = instr\n        self.add_doublespinbox('wavelength', *instr.get_wavelength_range())\n        self.add_button('reset_error')\n        self.auto_connect_by_name(controlled_object=instr)",
  "class SuperChrome(Instrument):\n    \"\"\" A class for controlling the fianium superchrome filter\n    \"\"\"\n    def __init__(self):\n#        self.dll = cdll.LoadLibrary(os.path.dirname(__file__) + \"\\\\SuperChromeSDK\")\n#        self.dll.InitialiseDll(windll.kernel32._handle)\n#        self.dll = windll\n\n        self.dll = cdll.LoadLibrary(r'C:\\Users\\hera.NP-BROMINE2\\Documents\\GitHub\\nplab\\nplab\\instrument\\filters' + \"\\\\SuperChromeSDK.dll\")\n        self.init();\n    def init(self):\n        self.dll.InitialiseDll(windll.kernel32._handle)\n        self.dll.Initialise();\n        self.MoveSyncWaveAndBw(633, 10)\n        self.wvl = 633;\n        self.bw = 10;\n    def MoveWvl(self, centWvl, bwWvl):\n        \"\"\" centWvl and bwWvl are in nm\n        \"\"\"\n        print(\"Moving\")\n        self.MoveSyncWaveAndBw(centWvl, bwWvl)\n        self.wvl = centWvl;\n        self.bw = bwWvl;",
  "def __init__(self):\n#        self.dll = cdll.LoadLibrary(os.path.dirname(__file__) + \"\\\\SuperChromeSDK\")\n#        self.dll.InitialiseDll(windll.kernel32._handle)\n#        self.dll = windll\n\n        self.dll = cdll.LoadLibrary(r'C:\\Users\\hera.NP-BROMINE2\\Documents\\GitHub\\nplab\\nplab\\instrument\\filters' + \"\\\\SuperChromeSDK.dll\")\n        self.init();",
  "def init(self):\n        self.dll.InitialiseDll(windll.kernel32._handle)\n        self.dll.Initialise();\n        self.MoveSyncWaveAndBw(633, 10)\n        self.wvl = 633;\n        self.bw = 10;",
  "def MoveWvl(self, centWvl, bwWvl):\n        \"\"\" centWvl and bwWvl are in nm\n        \"\"\"\n        print(\"Moving\")\n        self.MoveSyncWaveAndBw(centWvl, bwWvl)\n        self.wvl = centWvl;\n        self.bw = bwWvl;",
  "class AOTF(serial.SerialInstrument):\n\n\ttermination_character = \"\\n\"\n\ttermination_line = \"\\r\"\n\n\tport_settings = dict(baudrate=38400,bytesize=serial.EIGHTBITS,\n                        parity=serial.PARITY_NONE,\n                        stopbits=serial.STOPBITS_ONE,\n                        timeout=1, #wait at most one second for a response\n                        writeTimeout=1, #similarly, fail if writing takes >1s\n                        xonxoff=False, rtscts=False, dsrdtr=False\n                    )  \n\n\tdef __init__(self,port = None):\n\n\t\t#Open communication port\n\t\tsuper(AOTF,self).__init__(port =port)\n\n\t\t'''\n\t\tFunction AOTF_ModMax()\n\t\tAOTF_Write(\"dau en\") # Enable microcontroller to manipulate the Daughter Board controls\n\t\t'''\n\t\t\n\t\tr = self.query(\"dau en\")\n\t\tprint(\"Daughter Board control enable, response:\",r)\n\t\t\n\t\tself.set_default_calibration()\n\t\t\n\t\t# self.aotf_off()\n\t\tself.query(\"dau dac * 16383\")\n\n\n\t\t# Macro AOTF_setup()\n\t\t# VDT2/P=COM3 baud=38400, stopbits=1, databits=8, parity=0, echo=0\n\t\t# Variable/G AOTFint0=0,AOTFint1=0,AOTFint2=0,AOTFwl0=670,AOTFwl1=570,AOTFwl2=550\n\t\t# AOTF_ModMax()\n\t\t# AOTF_off()\n\n\t\n\t#TODO:\n\t''' \n\tFunction AOTF_chMod(st)\n\tVariable st\n\tif (st==1)\n\t\tAOTF_Write(\"dau dis\")\n\t\tAOTF_Write(dau gain * 72)\n\telse\n\t\tAOTF_Write(\"dau en\")\n\tendif\n\tEnd\n\t'''\n\n\tdef set_amplitude(self, channel, amplitude):\n\t\t'''\n\t\tFunction AOTF_Amp(ch,aa)// Sets AOTF channel ch amplitude to aa\n\t\t\tVariable ch, aa\n\t\t\tNvar AOTFint0,AOTFint1,AOTFint2\n\t\t\tString nm\n\t\t\taa = (aa>3000? 3000 : aa)\n\t\t\tnm = \"dds a \"+num2istr(ch)+\" \"+num2istr(aa)\n\t\t\tif ((ch>=0)&&(ch<8))\n\t\t\t  AOTF_Write(nm)\n\t\t\t  AOTF_Read()\n\t\t\t  if (ch==0)\n\t\t\t    AOTFint0 = aa\n\t\t\t  elseif (ch==1)\n\t\t\t    AOTFint1 = aa\n\t\t\t  elseif (ch==2)\n\t\t\t    AOTFint2 = aa\n\t\t\t  endif\n\t\t\tendif\n\t\t\tEnd\n\t\t'''\n\t\tassert(int(channel) >= 0 and int(channel) <= 7), \"Channel index in range 0-7\"\n\t\tassert(int(amplitude) >= 0 and int(amplitude) <= 16383), \"Channel amplitude in range 0-16383\"\n\t\tcommand = \"dds a {0} {1}\".format(channel,amplitude)\n\t\tresponse = self.query(command)\n\t\tprint(\"AOTF.set_amplitude:\", response)\n\t\treturn\n\n\tdef set_wavelength(self,channel,wavelength):\n\t\t'''\n\t\t\tFunction AOTF_Wav(ch,wl)              // Sets AOTF channel ch wavelength to wl\n\t\t\t\tVariable ch, wl\n\t\t\t\tNvar AOTFwl0,AOTFwl1,AOTFwl2\n\t\t\t\tString nm\n\t\t\t\twl = (wl>690? 690 : wl)\n\t\t\t\twl = (wl<450? 450 : wl)\n\t\t\t\tsprintf nm,\"dds w %u %3.1f\",ch,wl\n\t\t\t\tif ((ch>=0)&&(ch<8))\n\t\t\t\t  AOTF_Write(nm)\n\t\t\t\t  AOTF_Read()\n\n\t\t\t\t  if (ch==0)\n\t\t\t\t    AOTFwl0 = wl\n\t\t\t\t  elseif (ch==1)\n\t\t\t\t    AOTFwl1 = wl\n\t\t\t\t  elseif (ch==2)\n\t\t\t\t    AOTFwl2 = wl\n\t\t\t\t  endif\n\t\t\t\tendif\n\t\t\tEnd\n\t\t'''\n\t\tassert(int(channel) >= 0 and int(channel) <= 7), \"Channel index in range 0-7\"\n\t\tassert(float(wavelength) >= 450.0 and float(wavelength) <= 1100.0), \"Channel wavelength in range 450.0-690.0\"\n\t\tcommand = \"dds w {0} {1:.1f}\".format(channel,wavelength) #Notation: :.1f - show 'wavelength' to 1 float ('f') point places\n\t\tresponse = self.query(command)\n\t\tprint(\"AOTF.set_wavelength:\", response)\n\t\treturn \n\n\tdef set_frequency(self,channel,frequency):\n\t\t#Note: frequency in MHz?\n\t\tassert(int(channel) >= 0 and int(channel) <= 7), \"Channel index in range 0-7\"\n\t\tcommand = \"dds f {0} {1:6f}\".format(int(channel),frequency) #Notation: :.6f - show 'frequency' to 6 float ('f') point places\n\t\tresponse = self.query(command)\n\t\tprint(\"AOTF.set_frequency:\", response)\n\n\n\tdef set_default_calibration(self):\n\t\t'''\n\t\tFunction AOTF_Tune()           // sets up tuning parameters for this AOTF\n\t\t\tAOTF_Write(\"cal tuning 0 397.46\"); AOTF_Read()\n\t\t\tAOTF_Write(\"cal tuning 1 -1.2232\"); AOTF_Read()\n\t\t\tAOTF_Write(\"cal tuning 2 1.46\"); AOTF_Read()\n\t\t\tEnd\n\t\t'''\n\n\t\tr = self.query(\"cal tuning 0 397.46\")\n\t\tprint(\"Calibration step1:\",r)\n\t\tr = self.query(\"cal tuning 1 -1.2232\")\n\t\tprint(\"Calibration step2:\",r)\n\t\tr = self.query(\"cal tuning 2 1.4658e-3\")\n\t\tprint(\"Calibration step3:\",r)\n\t\tr = self.query(\"cal tuning 3 -6.15e-7\")\n\t\tprint(\"Calibration step4:\",r)\n\t\tr = self.query(\"cal save\")\n\t\tprint(\"Calibration step5:\",r)\n\n\t\treturn\n\t\t#LOADING THIS CALIBRATION MAKES THE AOTF STOP WORKING???? \n\t\t\n\n\t\t'''\n\t\t#DEFAULT CALIBRATION FROM AOTF CONTROLLER SOFTWARE\n\t\tcal tuning 0 397.46\n\t\t* cal tuning 1 -1.2232\n\t\t* cal tuning 2 1.4658e-3\n\t\t* cal tuning 3 -6.155E-7\n\t\t* cal save\n\t\t'''\n\t\treturn \n\n\tdef aotf_off(self):\n\t\tfor c in range(0,8):\n\t\t\tself.set_amplitude(channel=c, amplitude=0)\n\t\treturn\n\n\tdef enable_channel_by_frequency(self,channel,frequency,amplitude):\n\t\tself.set_frequency(channel,frequency)\n\t\tself.set_amplitude(channel,amplitude)\n\n\tdef enable_channel_by_wavelength(self,channel,wavelength,amplitude):\n\t\tself.set_wavelength(channel,wavelength)\n\t\tself.set_amplitude(channel,amplitude)\n\n\tdef disable_channel(self,channel):\n\t\t#enabling channel - requires\n\t\tself.set_amplitude(channel,0)",
  "class AOTF_UI(QtWidgets.QWidget, UiTools):\n\tdef __init__(self,device, parent=None,debug = False, verbose = False):\n\t\tif not isinstance(device, AOTF):\n\t\t\traise ValueError(\"Object is not an instance of the AOTF Class\")\n\t\tsuper(AOTF_UI, self).__init__()\n\t\t\n\t\tuic.loadUi(os.path.join(os.path.dirname(__file__), 'aotf.ui'), self)\n\n\t\t#aotf:\n\t\tself.aotf = device \n\t\t\n\t\tself.wavelength_textboxes = [self.chn1_wl,self.chn2_wl,self.chn3_wl,self.chn4_wl,self.chn5_wl,self.chn6_wl,self.chn7_wl,self.chn8_wl]\n\t\tself.power_textboxes = [self.chn1_pwr,self.chn2_pwr,self.chn3_pwr,self.chn4_pwr,self.chn5_pwr,self.chn6_pwr,self.chn7_pwr,self.chn8_pwr]\n\t\tself.active = [self.chn1_toggle,self.chn2_toggle,self.chn3_toggle,self.chn4_toggle,self.chn5_toggle,self.chn6_toggle,self.chn7_toggle,self.chn8_toggle]\n\n\t\tfor wl in self.wavelength_textboxes:\n\t\t\twl.textChanged.connect(self.set_wavelength)\n\n\t\tfor pwr in self.power_textboxes:\n\t\t\tpwr.textChanged.connect(self.set_power)\n\n\t\t\n\t\tself.off_btn.clicked.connect(self.set_off)\n\t\tself.on_btn.clicked.connect(self.set_on)\n\t\tself.settings = [[0,0],[0,0],[0,0],[0,0],[0,0],[0,0],[0,0],[0,0]]\n\n\t\tself.set_wavelength()\n\t\tself.set_power()\n\n\tdef set_wavelength(self):\n\t\ttry:\n\t\t\tfor i in range(len(self.wavelength_textboxes)):\n\t\t\t\twavelength = float(self.wavelength_textboxes[i].text())\n\t\t\t\tself.settings[i][0] = wavelength\n\t\t\tprint(self.settings)\n\t\texcept ValueError as e:\n\t\t\tprint(e)\n\n\t\treturn\n\n\tdef set_power(self):\n\t\ttry:\n\t\t\tfor i in range(len(self.power_textboxes)):\n\t\t\t\tpower = int(self.power_textboxes[i].text())\n\t\t\t\tself.settings[i][1] = power\n\t\texcept ValueError as e:\n\t\t\tprint(e)\n\t\treturn\n\n\tdef set_on(self):\n\t\tprint(self.settings)\n\t\tchannel_is_on = [bool(a.isChecked()) for a in self.active]\n\t\tprint(channel_is_on)\n\t\tfor i,is_on in enumerate(channel_is_on):\n\t\t\tif is_on == True:\n\t\t\t\twl = self.settings[i][0]\n\t\t\t\tpwr = self.settings[i][1]\n\t\t\t\tprint(\"wavelength:\", wl)\n\t\t\t\taotf.enable_channel_by_wavelength(i,wl,pwr)\n\t\t\telse:\n\t\t\t\taotf.disable_channel(i)\n\t\treturn\n\n\tdef set_off(self):\n\t\tself.aotf.aotf_off()\n\t\treturn",
  "def make_gui():\n\tglobal aotf \n\taotf = AOTF(\"/dev/ttyUSB2\")\n\tapp = get_qt_app()\n\tui = AOTF_UI(device=aotf,debug =False)\n\tui.show()\n\tsys.exit(app.exec_())",
  "def flash_wavelengths(wavelengths,t_sec):\n\taotf = AOTF(\"/dev/ttyUSB2\")\n\twhile True:\n\t\tfor i in range(len(wavelengths)):\n\t\t\taotf.enable_channel_by_wavelength(i,wavelengths[i],8000)\n\t\ttime.sleep(t_sec)\n\t\tfor i in range(len(wavelengths)):\n\t\t\taotf.disable_channel(i)\n\t\ttime.sleep(t_sec)\n\treturn",
  "def say(text):\n\timport pyttsx\n\tengine = pyttsx.init()\n\tengine.say(text)\n\tengine.runAndWait()\n\treturn",
  "def flash_frequency(f):\n\taotf = AOTF(\"/dev/ttyUSB2\")\n\twhile True:\n\t\taotf.enable_channel_by_frequency(1,f,8000)\n\t\ttime.sleep(0.4)\n\t\taotf.disable_channel(1)\n\t\ttime.sleep(0.4)",
  "def set_frequency(fs):\n\n\taotf = AOTF(\"/dev/ttyUSB2\")\n\tfor i,f in enumerate(fs):\n\t\t# aotf.disable_channel(i)\n\t\taotf.enable_channel_by_frequency(i,f,8000)",
  "def scan_frequency(freqs,t):\n\taotf = AOTF(\"/dev/ttyUSB2\")\n\tfor f in freqs:\n\t\tprint(\"freq:\",f)\n\t\taotf.enable_channel_by_frequency(1,f,8000)\n\t\tsay(\"{0:.3g} megahertz\".format(f))\n\t\tsay(\"measure\")\n\t\ttime.sleep(t)\n\t\t\n\t\taotf.disable_channel(1)\n\t\ttime.sleep(t)\n\t\n\treturn",
  "def __init__(self,port = None):\n\n\t\t#Open communication port\n\t\tsuper(AOTF,self).__init__(port =port)\n\n\t\t'''\n\t\tFunction AOTF_ModMax()\n\t\tAOTF_Write(\"dau en\") # Enable microcontroller to manipulate the Daughter Board controls\n\t\t'''\n\t\t\n\t\tr = self.query(\"dau en\")\n\t\tprint(\"Daughter Board control enable, response:\",r)\n\t\t\n\t\tself.set_default_calibration()\n\t\t\n\t\t# self.aotf_off()\n\t\tself.query(\"dau dac * 16383\")",
  "def set_amplitude(self, channel, amplitude):\n\t\t'''\n\t\tFunction AOTF_Amp(ch,aa)// Sets AOTF channel ch amplitude to aa\n\t\t\tVariable ch, aa\n\t\t\tNvar AOTFint0,AOTFint1,AOTFint2\n\t\t\tString nm\n\t\t\taa = (aa>3000? 3000 : aa)\n\t\t\tnm = \"dds a \"+num2istr(ch)+\" \"+num2istr(aa)\n\t\t\tif ((ch>=0)&&(ch<8))\n\t\t\t  AOTF_Write(nm)\n\t\t\t  AOTF_Read()\n\t\t\t  if (ch==0)\n\t\t\t    AOTFint0 = aa\n\t\t\t  elseif (ch==1)\n\t\t\t    AOTFint1 = aa\n\t\t\t  elseif (ch==2)\n\t\t\t    AOTFint2 = aa\n\t\t\t  endif\n\t\t\tendif\n\t\t\tEnd\n\t\t'''\n\t\tassert(int(channel) >= 0 and int(channel) <= 7), \"Channel index in range 0-7\"\n\t\tassert(int(amplitude) >= 0 and int(amplitude) <= 16383), \"Channel amplitude in range 0-16383\"\n\t\tcommand = \"dds a {0} {1}\".format(channel,amplitude)\n\t\tresponse = self.query(command)\n\t\tprint(\"AOTF.set_amplitude:\", response)\n\t\treturn",
  "def set_wavelength(self,channel,wavelength):\n\t\t'''\n\t\t\tFunction AOTF_Wav(ch,wl)              // Sets AOTF channel ch wavelength to wl\n\t\t\t\tVariable ch, wl\n\t\t\t\tNvar AOTFwl0,AOTFwl1,AOTFwl2\n\t\t\t\tString nm\n\t\t\t\twl = (wl>690? 690 : wl)\n\t\t\t\twl = (wl<450? 450 : wl)\n\t\t\t\tsprintf nm,\"dds w %u %3.1f\",ch,wl\n\t\t\t\tif ((ch>=0)&&(ch<8))\n\t\t\t\t  AOTF_Write(nm)\n\t\t\t\t  AOTF_Read()\n\n\t\t\t\t  if (ch==0)\n\t\t\t\t    AOTFwl0 = wl\n\t\t\t\t  elseif (ch==1)\n\t\t\t\t    AOTFwl1 = wl\n\t\t\t\t  elseif (ch==2)\n\t\t\t\t    AOTFwl2 = wl\n\t\t\t\t  endif\n\t\t\t\tendif\n\t\t\tEnd\n\t\t'''\n\t\tassert(int(channel) >= 0 and int(channel) <= 7), \"Channel index in range 0-7\"\n\t\tassert(float(wavelength) >= 450.0 and float(wavelength) <= 1100.0), \"Channel wavelength in range 450.0-690.0\"\n\t\tcommand = \"dds w {0} {1:.1f}\".format(channel,wavelength) #Notation: :.1f - show 'wavelength' to 1 float ('f') point places\n\t\tresponse = self.query(command)\n\t\tprint(\"AOTF.set_wavelength:\", response)\n\t\treturn",
  "def set_frequency(self,channel,frequency):\n\t\t#Note: frequency in MHz?\n\t\tassert(int(channel) >= 0 and int(channel) <= 7), \"Channel index in range 0-7\"\n\t\tcommand = \"dds f {0} {1:6f}\".format(int(channel),frequency) #Notation: :.6f - show 'frequency' to 6 float ('f') point places\n\t\tresponse = self.query(command)\n\t\tprint(\"AOTF.set_frequency:\", response)",
  "def set_default_calibration(self):\n\t\t'''\n\t\tFunction AOTF_Tune()           // sets up tuning parameters for this AOTF\n\t\t\tAOTF_Write(\"cal tuning 0 397.46\"); AOTF_Read()\n\t\t\tAOTF_Write(\"cal tuning 1 -1.2232\"); AOTF_Read()\n\t\t\tAOTF_Write(\"cal tuning 2 1.46\"); AOTF_Read()\n\t\t\tEnd\n\t\t'''\n\n\t\tr = self.query(\"cal tuning 0 397.46\")\n\t\tprint(\"Calibration step1:\",r)\n\t\tr = self.query(\"cal tuning 1 -1.2232\")\n\t\tprint(\"Calibration step2:\",r)\n\t\tr = self.query(\"cal tuning 2 1.4658e-3\")\n\t\tprint(\"Calibration step3:\",r)\n\t\tr = self.query(\"cal tuning 3 -6.15e-7\")\n\t\tprint(\"Calibration step4:\",r)\n\t\tr = self.query(\"cal save\")\n\t\tprint(\"Calibration step5:\",r)\n\n\t\treturn\n\t\t#LOADING THIS CALIBRATION MAKES THE AOTF STOP WORKING???? \n\t\t\n\n\t\t'''\n\t\t#DEFAULT CALIBRATION FROM AOTF CONTROLLER SOFTWARE\n\t\tcal tuning 0 397.46\n\t\t* cal tuning 1 -1.2232\n\t\t* cal tuning 2 1.4658e-3\n\t\t* cal tuning 3 -6.155E-7\n\t\t* cal save\n\t\t'''\n\t\treturn",
  "def aotf_off(self):\n\t\tfor c in range(0,8):\n\t\t\tself.set_amplitude(channel=c, amplitude=0)\n\t\treturn",
  "def enable_channel_by_frequency(self,channel,frequency,amplitude):\n\t\tself.set_frequency(channel,frequency)\n\t\tself.set_amplitude(channel,amplitude)",
  "def enable_channel_by_wavelength(self,channel,wavelength,amplitude):\n\t\tself.set_wavelength(channel,wavelength)\n\t\tself.set_amplitude(channel,amplitude)",
  "def disable_channel(self,channel):\n\t\t#enabling channel - requires\n\t\tself.set_amplitude(channel,0)",
  "def __init__(self,device, parent=None,debug = False, verbose = False):\n\t\tif not isinstance(device, AOTF):\n\t\t\traise ValueError(\"Object is not an instance of the AOTF Class\")\n\t\tsuper(AOTF_UI, self).__init__()\n\t\t\n\t\tuic.loadUi(os.path.join(os.path.dirname(__file__), 'aotf.ui'), self)\n\n\t\t#aotf:\n\t\tself.aotf = device \n\t\t\n\t\tself.wavelength_textboxes = [self.chn1_wl,self.chn2_wl,self.chn3_wl,self.chn4_wl,self.chn5_wl,self.chn6_wl,self.chn7_wl,self.chn8_wl]\n\t\tself.power_textboxes = [self.chn1_pwr,self.chn2_pwr,self.chn3_pwr,self.chn4_pwr,self.chn5_pwr,self.chn6_pwr,self.chn7_pwr,self.chn8_pwr]\n\t\tself.active = [self.chn1_toggle,self.chn2_toggle,self.chn3_toggle,self.chn4_toggle,self.chn5_toggle,self.chn6_toggle,self.chn7_toggle,self.chn8_toggle]\n\n\t\tfor wl in self.wavelength_textboxes:\n\t\t\twl.textChanged.connect(self.set_wavelength)\n\n\t\tfor pwr in self.power_textboxes:\n\t\t\tpwr.textChanged.connect(self.set_power)\n\n\t\t\n\t\tself.off_btn.clicked.connect(self.set_off)\n\t\tself.on_btn.clicked.connect(self.set_on)\n\t\tself.settings = [[0,0],[0,0],[0,0],[0,0],[0,0],[0,0],[0,0],[0,0]]\n\n\t\tself.set_wavelength()\n\t\tself.set_power()",
  "def set_wavelength(self):\n\t\ttry:\n\t\t\tfor i in range(len(self.wavelength_textboxes)):\n\t\t\t\twavelength = float(self.wavelength_textboxes[i].text())\n\t\t\t\tself.settings[i][0] = wavelength\n\t\t\tprint(self.settings)\n\t\texcept ValueError as e:\n\t\t\tprint(e)\n\n\t\treturn",
  "def set_power(self):\n\t\ttry:\n\t\t\tfor i in range(len(self.power_textboxes)):\n\t\t\t\tpower = int(self.power_textboxes[i].text())\n\t\t\t\tself.settings[i][1] = power\n\t\texcept ValueError as e:\n\t\t\tprint(e)\n\t\treturn",
  "def set_on(self):\n\t\tprint(self.settings)\n\t\tchannel_is_on = [bool(a.isChecked()) for a in self.active]\n\t\tprint(channel_is_on)\n\t\tfor i,is_on in enumerate(channel_is_on):\n\t\t\tif is_on == True:\n\t\t\t\twl = self.settings[i][0]\n\t\t\t\tpwr = self.settings[i][1]\n\t\t\t\tprint(\"wavelength:\", wl)\n\t\t\t\taotf.enable_channel_by_wavelength(i,wl,pwr)\n\t\t\telse:\n\t\t\t\taotf.disable_channel(i)\n\t\treturn",
  "def set_off(self):\n\t\tself.aotf.aotf_off()\n\t\treturn",
  "class MatchboxLaser(SerialInstrument, LightSource):\n    def __init__(self, port=None):\n        self.port_settings = {'baudrate': 115200,\n                        'bytesize':serial.EIGHTBITS,\n                        'stopbits':serial.STOPBITS_ONE,\n                        'timeout':1, #wait at most one second for a response\n                        'writeTimeout':1, #similarly, fail if writing takes >1s\n                        }\n        self.termination_character = \"\\r\"\n        SerialInstrument.__init__(self, port=port)\n        self.turn_on()\n        \n    def __del__(self):\n        self.turn_off()\n        return \n\n    def close(self):\n        self.turn_off()\n        self.__del__()\n\n    def turn_on(self):\n        \"\"\"change laser status from off to on\"\"\"\n        self.query(\"e 1\")\n        \n    def turn_off(self):\n        \"\"\"change laser status from on to off\"\"\"\n        self.query(\"e 0\")        \n    \n    def get_power(self):\n        \"\"\"read the current power output in mW\"\"\"\n        readings=self.query(\"r r\")\n        readout=np.fromstring(readings[11:], dtype=np.float,sep=' ' ,count=4)\n        return readout[3]\n\n\n    def readpower(self):\n        \"\"\"deprecated: returns get_power()\"\"\"\n        return self.get_power()   \n\n        \n    def read_setParameters(self):\n        \"\"\"read out set Parameters: Set T1 (deg.), set T2  (deg.), set LD current (mA),\n        set Optical power 12bit range, set Optical power (mW),max allowed LD current (mA),\n        Autostart enable (boolean), access leve; (float)\"\"\"\n        readings=self.query(\"r s\")\n        settings=np.fromstring(readings, dtype=np.float,sep=' ' ,count=8)\n        return settings\n        \n    def read_parameters(self):\n        \"\"\"read out Parameters: T1 (deg.), T2  (deg.),T3 (deg.),LD current (mA),\n        TEC1 load%, TEC2 load%, laserstatus\"\"\"\n        readings=self.query(\"r r\")\n        readout=np.fromstring(readings[11:], dtype=np.float,sep=' ' ,count=4)\n        DAC=readout[3]\n        print(\"DAC current:  %.2f mA\" % DAC)\n        return readout\n        \n    def set_power(self, power):\n        \"\"\"Set optical power DAC in 12 bit full range\"\"\"\n        '''Max value: 8191, min value 0\n        Note: this does not turn off the laser\n        '''\n        power = abs(int(power))\n        print(\"Setting power:{} (min:0, max: 8191)\".format(power))\n        self.query(\"c 6 {}\".format(power))\n        return self.get_power()",
  "def __init__(self, port=None):\n        self.port_settings = {'baudrate': 115200,\n                        'bytesize':serial.EIGHTBITS,\n                        'stopbits':serial.STOPBITS_ONE,\n                        'timeout':1, #wait at most one second for a response\n                        'writeTimeout':1, #similarly, fail if writing takes >1s\n                        }\n        self.termination_character = \"\\r\"\n        SerialInstrument.__init__(self, port=port)\n        self.turn_on()",
  "def __del__(self):\n        self.turn_off()\n        return",
  "def close(self):\n        self.turn_off()\n        self.__del__()",
  "def turn_on(self):\n        \"\"\"change laser status from off to on\"\"\"\n        self.query(\"e 1\")",
  "def turn_off(self):\n        \"\"\"change laser status from on to off\"\"\"\n        self.query(\"e 0\")",
  "def get_power(self):\n        \"\"\"read the current power output in mW\"\"\"\n        readings=self.query(\"r r\")\n        readout=np.fromstring(readings[11:], dtype=np.float,sep=' ' ,count=4)\n        return readout[3]",
  "def readpower(self):\n        \"\"\"deprecated: returns get_power()\"\"\"\n        return self.get_power()",
  "def read_setParameters(self):\n        \"\"\"read out set Parameters: Set T1 (deg.), set T2  (deg.), set LD current (mA),\n        set Optical power 12bit range, set Optical power (mW),max allowed LD current (mA),\n        Autostart enable (boolean), access leve; (float)\"\"\"\n        readings=self.query(\"r s\")\n        settings=np.fromstring(readings, dtype=np.float,sep=' ' ,count=8)\n        return settings",
  "def read_parameters(self):\n        \"\"\"read out Parameters: T1 (deg.), T2  (deg.),T3 (deg.),LD current (mA),\n        TEC1 load%, TEC2 load%, laserstatus\"\"\"\n        readings=self.query(\"r r\")\n        readout=np.fromstring(readings[11:], dtype=np.float,sep=' ' ,count=4)\n        DAC=readout[3]\n        print(\"DAC current:  %.2f mA\" % DAC)\n        return readout",
  "def set_power(self, power):\n        \"\"\"Set optical power DAC in 12 bit full range\"\"\"\n        '''Max value: 8191, min value 0\n        Note: this does not turn off the laser\n        '''\n        power = abs(int(power))\n        print(\"Setting power:{} (min:0, max: 8191)\".format(power))\n        self.query(\"c 6 {}\".format(power))\n        return self.get_power()",
  "class Maitai(SerialInstrument):\n    port_settings = dict(baudrate=38400,\n                        bytesize=serial.EIGHTBITS,\n                        parity=serial.PARITY_NONE,\n                        stopbits=serial.STOPBITS_ONE,\n                        timeout=1, #wait at most one second for a response\n                        writeTimeout=1, #similarly, fail if writing takes >1s\n                        xonxoff=True, rtscts=False, dsrdtr=False,\n                    )\n    termination_character = \"\\n\"\n    def __init__(self, port):\n        '''Maitai Ti:saphire laser: just requires port number to inialise '''\n        super(Maitai, self).__init__(port)\n        self.set_watchdog(0)\n    \n    def on(self):\n        '''Turn the Maitai on'''\n        self.write('ON')\n    def off(self):\n        '''Turn the Maitai off'''\n        self.write('OFF')\n    def open_shutter(self):\n        '''Opens the shutter using the shutter state property'''\n        self.shutter_state = True\n    def close_shutter(self):\n        '''Close the shutter using the shutter state property '''\n        self.shutter_state = False\n    def get_shutter_state(self):\n        '''Get shutter state and convert it to a bool\n        returns:\n            bool: True == open and False == close'''\n        return bool(int(self.query('SHUTTER?')))\n    def set_shutter_state(self,state):\n        ''' Sets the shutter from a bool\n        Args:\n            bool True == Open, false == closed\n        '''\n        self.write('SHUTTER '+str(int(state)))\n    shutter_state = NotifiedProperty(get_shutter_state,set_shutter_state)\n        \n    def get_humidity(self):\n        '''Returns the humidity '''\n        return self.query('READ:HUM?')\n    def get_power(self):\n        '''Returns the IR power\n        '''\n        return self.query('READ:POWER?')\n    \n    def get_green_power(self):\n        '''Returns the IR power\n        '''\n        return self.query('READ:PLASER:POWER?')\n    def get_current_wavelength(self):\n        ''' The current real time wavelength - allowing you to check if the maitai ahs moved to the set wavelength yet\n        '''\n        return self.query('READ:WAVELENGTH?')\n    current_wavelength = property(get_current_wavelength)\n    def save(self):\n        '''Save tje current maitai settings for restart '''\n        self.write('SAVE')\n    def get_set_wavelength(self):\n        ''' wavelength(float):  The current set wavelength of the Maitai (in nm)\n                                must between 690 and 1020\n        '''\n        return float(self.query('WAVELENGTH?')[:-2])\n#    def set_wavelength(self,wavelength):\n#        if wavelength>690 and wavelength<1020:\n#            return self.write('WAVELENGTH ')\n#        else:\n#            self.log('Wavelength out of range ('+wavelength+')')\n        \n    def set_wavelength(self,wavelength):\n        if wavelength>690 and wavelength<1020:\n            return self.write('WAVelength ' + str(wavelength))\n        else:\n            self.log('Wavelength out of range ('+wavelength+')')            \n        \n    wavelength = NotifiedProperty(get_set_wavelength,set_wavelength)\n    \n    def set_watchdog(self,n):\n        '''Sets the watchdog timer i.e. the ammount of time the laser will \n        keep itself on without stay alive command. If set to zero this is disabled\n        '''\n        self.write('TIMER:WATCHDOG '+str(n))\n        \n    def get_qt_ui(self):\n        return MaitaiControlUI(self)",
  "class MaitaiControlUI(QuickControlBox):\n    '''Control Widget for the MaiTai laser\n    '''\n    def __init__(self,maitai):\n        super(MaitaiControlUI,self).__init__(title = 'MaiTai')\n        self.maitai = maitai\n        self.add_button('on')\n        self.add_button('off')\n        self.add_button('open_shutter')\n        self.add_button('close_shutter')\n        self.add_doublespinbox(\"wavelength\")\n        self.auto_connect_by_name(controlled_object = self.maitai)",
  "def __init__(self, port):\n        '''Maitai Ti:saphire laser: just requires port number to inialise '''\n        super(Maitai, self).__init__(port)\n        self.set_watchdog(0)",
  "def on(self):\n        '''Turn the Maitai on'''\n        self.write('ON')",
  "def off(self):\n        '''Turn the Maitai off'''\n        self.write('OFF')",
  "def open_shutter(self):\n        '''Opens the shutter using the shutter state property'''\n        self.shutter_state = True",
  "def close_shutter(self):\n        '''Close the shutter using the shutter state property '''\n        self.shutter_state = False",
  "def get_shutter_state(self):\n        '''Get shutter state and convert it to a bool\n        returns:\n            bool: True == open and False == close'''\n        return bool(int(self.query('SHUTTER?')))",
  "def set_shutter_state(self,state):\n        ''' Sets the shutter from a bool\n        Args:\n            bool True == Open, false == closed\n        '''\n        self.write('SHUTTER '+str(int(state)))",
  "def get_humidity(self):\n        '''Returns the humidity '''\n        return self.query('READ:HUM?')",
  "def get_power(self):\n        '''Returns the IR power\n        '''\n        return self.query('READ:POWER?')",
  "def get_green_power(self):\n        '''Returns the IR power\n        '''\n        return self.query('READ:PLASER:POWER?')",
  "def get_current_wavelength(self):\n        ''' The current real time wavelength - allowing you to check if the maitai ahs moved to the set wavelength yet\n        '''\n        return self.query('READ:WAVELENGTH?')",
  "def save(self):\n        '''Save tje current maitai settings for restart '''\n        self.write('SAVE')",
  "def get_set_wavelength(self):\n        ''' wavelength(float):  The current set wavelength of the Maitai (in nm)\n                                must between 690 and 1020\n        '''\n        return float(self.query('WAVELENGTH?')[:-2])",
  "def set_wavelength(self,wavelength):\n        if wavelength>690 and wavelength<1020:\n            return self.write('WAVelength ' + str(wavelength))\n        else:\n            self.log('Wavelength out of range ('+wavelength+')')",
  "def set_watchdog(self,n):\n        '''Sets the watchdog timer i.e. the ammount of time the laser will \n        keep itself on without stay alive command. If set to zero this is disabled\n        '''\n        self.write('TIMER:WATCHDOG '+str(n))",
  "def get_qt_ui(self):\n        return MaitaiControlUI(self)",
  "def __init__(self,maitai):\n        super(MaitaiControlUI,self).__init__(title = 'MaiTai')\n        self.maitai = maitai\n        self.add_button('on')\n        self.add_button('off')\n        self.add_button('open_shutter')\n        self.add_button('close_shutter')\n        self.add_doublespinbox(\"wavelength\")\n        self.auto_connect_by_name(controlled_object = self.maitai)",
  "class CubeLaser(SerialInstrument, LightSource):\n    def __init__(self, port=None):\n        self.port_settings = {'baudrate': 19200,\n                        'bytesize':serial.EIGHTBITS,\n                        'stopbits':serial.STOPBITS_ONE,\n                        'timeout':1, #wait at most one second for a response\n                        'writeTimeout':1, #similarly, fail if writing takes >1s\n                        }\n        self.termination_character = \"\\r\"\n        SerialInstrument.__init__(self, port=port)\n        \n    def get_power(self):\n        \"\"\"read the current power output in mW\"\"\"\n        power = self.float_query(\"?P\") \n        print(\"%.1f mW\" % power)\n        return power  \n        \n    def set_power(self, power):\n        \"\"\"set the power output in mW\"\"\"\n        if 0<=power<=40:\n            self.query(\"P=%.1f\" % power)\n        else:\n            print('Input power must be between 0 an 40 mW')\n\n    def mode_switch(self,pulsed=0): #if pulsed=0, then CW; if 1 then pulsed\n        self.query(\"CW=%.f\" % (1-pulsed))\n        if pulsed == 0:\n            mode = 'CW mode'\n        elif pulsed == 1:\n            mode = 'Pulsed mode'\n        else:\n            mode = 'pulsed must be 0 (CW) or 1 (Pulsed)'           \n        print(mode)",
  "class CubeLaserUI(QtGui.QWidget):\n    def __init__(self):\n        QtGui.QWidget.__init__(self)\n        self.setWindowTitle(\"Cube Laser\")\n        self.resize(300,100)\n        self.move(100,1500)\n        self.power_switch = QtGui.QCheckBox('Power ON',self)\n        self.power_switch.clicked.connect(self.handle_power_switch)\n        self.pulsed_switch = QtGui.QCheckBox('Pulsed Mode',self)\n        self.pulsed_switch.clicked.connect(self.handle_pulsed_switch)\n        self.power_input_label = QtGui.QLabel('Input Power:')\n        self.power_input = QtGui.QDoubleSpinBox()\n        self.power_input.valueChanged.connect(self.handle_power_input)\n        self.power_input.setMinimum(0)\n        self.power_input.setMaximum(40)\n        self.power_input_unit = QtGui.QLabel('mW')\n        self.power_readout_label = QtGui.QLabel('Readout Power:')\n        self.power_readout = QtGui.QLabel('0.0')\n        self.power_readout_unit = QtGui.QLabel('mW')\n\n        layout = QtGui.QGridLayout(self)\n        \n        layout.addWidget(self.power_switch, 1, 0)\n        layout.addWidget(self.power_input_label, 2, 0)\n        layout.addWidget(self.power_input, 2, 1)\n        layout.addWidget(self.power_input_unit, 2, 2)\n        layout.addWidget(self.power_readout_label, 3, 0)\n        layout.addWidget(self.power_readout, 3, 1)\n        layout.addWidget(self.power_readout_unit, 3, 2)\n        layout.addWidget(self.pulsed_switch, 4, 0)\n        \n        \n    def handle_power_switch(self):\n        laser = CubeLaser(\"COM7\")\n        if self.power_switch.isChecked():\n            laser.set_power(self.power_input.value())\n            print('Power ON')\n        else:\n            laser.set_power(0)\n            print('Power OFF')\n            \n        self.power_readout.setText(str(laser.get_power()))    \n        laser.close()\n    \n    def handle_pulsed_switch(self):\n        laser = CubeLaser(\"COM7\")\n        if self.pulsed_switch.isChecked():\n            laser.mode_switch(1)\n        else:\n            laser.mode_switch(0)\n        self.power_readout.setText(str(laser.get_power()))    \n        laser.close()\n    \n    def handle_power_input(self):\n        laser = CubeLaser(\"COM7\")\n        if self.power_switch.isChecked():\n            laser.set_power(self.power_input.value())\n        else:\n            laser.set_power(0)      \n        self.power_readout.setText(str(laser.get_power()))    \n        laser.close()",
  "def __init__(self, port=None):\n        self.port_settings = {'baudrate': 19200,\n                        'bytesize':serial.EIGHTBITS,\n                        'stopbits':serial.STOPBITS_ONE,\n                        'timeout':1, #wait at most one second for a response\n                        'writeTimeout':1, #similarly, fail if writing takes >1s\n                        }\n        self.termination_character = \"\\r\"\n        SerialInstrument.__init__(self, port=port)",
  "def get_power(self):\n        \"\"\"read the current power output in mW\"\"\"\n        power = self.float_query(\"?P\") \n        print(\"%.1f mW\" % power)\n        return power",
  "def set_power(self, power):\n        \"\"\"set the power output in mW\"\"\"\n        if 0<=power<=40:\n            self.query(\"P=%.1f\" % power)\n        else:\n            print('Input power must be between 0 an 40 mW')",
  "def mode_switch(self,pulsed=0): #if pulsed=0, then CW; if 1 then pulsed\n        self.query(\"CW=%.f\" % (1-pulsed))\n        if pulsed == 0:\n            mode = 'CW mode'\n        elif pulsed == 1:\n            mode = 'Pulsed mode'\n        else:\n            mode = 'pulsed must be 0 (CW) or 1 (Pulsed)'           \n        print(mode)",
  "def __init__(self):\n        QtGui.QWidget.__init__(self)\n        self.setWindowTitle(\"Cube Laser\")\n        self.resize(300,100)\n        self.move(100,1500)\n        self.power_switch = QtGui.QCheckBox('Power ON',self)\n        self.power_switch.clicked.connect(self.handle_power_switch)\n        self.pulsed_switch = QtGui.QCheckBox('Pulsed Mode',self)\n        self.pulsed_switch.clicked.connect(self.handle_pulsed_switch)\n        self.power_input_label = QtGui.QLabel('Input Power:')\n        self.power_input = QtGui.QDoubleSpinBox()\n        self.power_input.valueChanged.connect(self.handle_power_input)\n        self.power_input.setMinimum(0)\n        self.power_input.setMaximum(40)\n        self.power_input_unit = QtGui.QLabel('mW')\n        self.power_readout_label = QtGui.QLabel('Readout Power:')\n        self.power_readout = QtGui.QLabel('0.0')\n        self.power_readout_unit = QtGui.QLabel('mW')\n\n        layout = QtGui.QGridLayout(self)\n        \n        layout.addWidget(self.power_switch, 1, 0)\n        layout.addWidget(self.power_input_label, 2, 0)\n        layout.addWidget(self.power_input, 2, 1)\n        layout.addWidget(self.power_input_unit, 2, 2)\n        layout.addWidget(self.power_readout_label, 3, 0)\n        layout.addWidget(self.power_readout, 3, 1)\n        layout.addWidget(self.power_readout_unit, 3, 2)\n        layout.addWidget(self.pulsed_switch, 4, 0)",
  "def handle_power_switch(self):\n        laser = CubeLaser(\"COM7\")\n        if self.power_switch.isChecked():\n            laser.set_power(self.power_input.value())\n            print('Power ON')\n        else:\n            laser.set_power(0)\n            print('Power OFF')\n            \n        self.power_readout.setText(str(laser.get_power()))    \n        laser.close()",
  "def handle_pulsed_switch(self):\n        laser = CubeLaser(\"COM7\")\n        if self.pulsed_switch.isChecked():\n            laser.mode_switch(1)\n        else:\n            laser.mode_switch(0)\n        self.power_readout.setText(str(laser.get_power()))    \n        laser.close()",
  "def handle_power_input(self):\n        laser = CubeLaser(\"COM7\")\n        if self.power_switch.isChecked():\n            laser.set_power(self.power_input.value())\n        else:\n            laser.set_power(0)      \n        self.power_readout.setText(str(laser.get_power()))    \n        laser.close()",
  "class inspire_OPO(SerialInstrument):\n    port_settings = dict(baudrate=9600,\n                         bytesize=serial.EIGHTBITS,\n                         parity=serial.PARITY_NONE,\n                         stopbits=serial.STOPBITS_ONE,\n                         timeout=1,  #wait at most one second for a response\n                         writeTimeout=1,  #similarly, fail if writing takes >1s\n                         xonxoff=False, rtscts=False, dsrdtr=False,\n                         )\n    \n    def __init__(self, port):\n        self.mode = 'power'\n        self.initialise()\n        \n    def initialise(self):\n        self.write('00 550.0')\n    \n    def set_wavelength(self,wavelength):\n        wavelength=str(int(wavelength))+'.0'\n        self.write(self.mode_dict[self.mode]+ wavelength)\n    def get_wavelength(self):\n        wavelength = self.query('50 550.0')\n        return wavelength\n    wavelength = NotifiedProperty(get_wavelength,set_wavelength)\n    def enable_power_mode(self):\n        self.query(mode_dict['power']+' '+self.wavelength)\n    mode_dict = {'tune':'03',\n                 'power':'04'}\n    def SHG_on(self):\n        self.query('08 000.0')\n    def SHG_off(self):\n        self.query('09 000.0')\n    def SHG_find(self):\n        self.query('10 000.0')\n    def SHG_optimise(self):\n        self.query('11 000.0')\n    \n    def auto_cavity(self):\n        self.query('07 '+self.wavelength)",
  "def __init__(self, port):\n        self.mode = 'power'\n        self.initialise()",
  "def initialise(self):\n        self.write('00 550.0')",
  "def set_wavelength(self,wavelength):\n        wavelength=str(int(wavelength))+'.0'\n        self.write(self.mode_dict[self.mode]+ wavelength)",
  "def get_wavelength(self):\n        wavelength = self.query('50 550.0')\n        return wavelength",
  "def enable_power_mode(self):\n        self.query(mode_dict['power']+' '+self.wavelength)",
  "def SHG_on(self):\n        self.query('08 000.0')",
  "def SHG_off(self):\n        self.query('09 000.0')",
  "def SHG_find(self):\n        self.query('10 000.0')",
  "def SHG_optimise(self):\n        self.query('11 000.0')",
  "def auto_cavity(self):\n        self.query('07 '+self.wavelength)",
  "class Fianium(LightSource, serial.SerialInstrument):\n    \"\"\"\n    Interface for the Fianium supercontinuum lasers\n    \"\"\"\n\n    COMMAND_LIST = {\n\n    \"A?\" : {\"description\":\"Get Alarms\", \"type\":\"query\"},\n    \"B?\" : {\"description\":\"Get back reflection photodiode value\",\"type\":\"query\"},\n    \"H?\" : {\"description\":\"Display list of commands\",\"type\":\"query\"},\n    \"I?\" : {\"description\":\"Get status display interval\",\"type\":\"query\"},\n    \"M?\" : {\"description\":\"Get laser control mode\",\"type\":\"query\"},\n    \"P?\" : {\"description\":\"Get preamplifier photodiode value\",\"type\":\"query\"},\n    \"Q?\" : {\"description\":\"Get amplifier control DAC value\",\"type\":\"query\"},\n    \"V?\" : {\"description\":\"Get control software version and release date\",\"type\":\"query\"},\n    \"W?\" : {\"description\":\"Get laser operating time counter\",\"type\":\"query\"},\n    \"X?\" : {\"description\":\"Get status display mode\",\"type\":\"query\"},\n       \n    \"A=\" : {\"description\":\"Clear all alarms\",\"type\":\"setter\"},\n    \"I=\" : {\"description\":\"Set status display interval\",\"type\":\"setter\"},\n    \"M=\" : {\"description\":\"Set status display interval\",\"type\":\"setter\"},\n    \"Q=\" : {\"description\":\"Set amplifier current control DAC value in USB mode\",\"type\":\"setter\"},\n    \"X=\" : {\"description\":\"Set status display mode\",\"type\":\"setter\"}\n    }\n\n    port_settings = dict(baudrate=19200,\n                        bytesize=serial.EIGHTBITS,\n                        parity=serial.PARITY_NONE,\n                        stopbits=serial.STOPBITS_ONE,\n                        timeout=1, #wait at most one second for a response\n                        writeTimeout=1, #similarly, fail if writing takes >1s\n                        xonxoff=False, rtscts=False, dsrdtr=False,\n                    )\n    termination_character = \"\\n\" #: All messages to or from the instrument end with this character.\n\n    def __init__(self, port=None, shutter=None):\n        serial.SerialInstrument.__init__(self, port=port)\n        LightSource.__init__(self, shutter=shutter)\n        self.min_power = 0\n        self.max_power = 2000\n\n\n\n    def get_dac(self):\n        return self.float_query('Q?')\n    def set_dac(self, dac):\n        self.write('Q=%d' % dac)\n    dac = property(get_dac, set_dac)\n\n    def get_power(self):\n        return self.get_dac()\n    def set_power(self, value):\n        self.set_dac(value)\n    power = property(get_power, set_power)\n\n\n    def get_queries(self):\n        for k,v in list(self.COMMAND_LIST.items()):\n            if v[\"type\"]==\"query\":\n                print(\"Query:[{0}], Description:[{1}]\".format(k,v[\"description\"]))\n\n    def get_setters(self):\n        for k,v in list(self.COMMAND_LIST.items()):\n            if v[\"type\"]==\"setter\":\n                print(\"Query:[{0}], Description:[{1}]\".format(k,v[\"description\"]))\n    \n    \n\n\n    def get_alarms(self):\n        response = self.query('A?')\n        print(\"Fianium.get_alarms:\", response)\n        return response\n\n    def get_back_reflection_value(self):\n        response = self.float_query('B?')\n        return response",
  "def __init__(self, port=None, shutter=None):\n        serial.SerialInstrument.__init__(self, port=port)\n        LightSource.__init__(self, shutter=shutter)\n        self.min_power = 0\n        self.max_power = 2000",
  "def get_dac(self):\n        return self.float_query('Q?')",
  "def set_dac(self, dac):\n        self.write('Q=%d' % dac)",
  "def get_power(self):\n        return self.get_dac()",
  "def set_power(self, value):\n        self.set_dac(value)",
  "def get_queries(self):\n        for k,v in list(self.COMMAND_LIST.items()):\n            if v[\"type\"]==\"query\":\n                print(\"Query:[{0}], Description:[{1}]\".format(k,v[\"description\"]))",
  "def get_setters(self):\n        for k,v in list(self.COMMAND_LIST.items()):\n            if v[\"type\"]==\"setter\":\n                print(\"Query:[{0}], Description:[{1}]\".format(k,v[\"description\"]))",
  "def get_alarms(self):\n        response = self.query('A?')\n        print(\"Fianium.get_alarms:\", response)\n        return response",
  "def get_back_reflection_value(self):\n        response = self.float_query('B?')\n        return response",
  "class OndaxLaser(SerialInstrument, LightSource):\n    def __init__(self, port=None):\n        self.port_settings = {'baudrate': 9600,\n                        'bytesize':serial.EIGHTBITS,\n                        'stopbits':serial.STOPBITS_ONE,\n                        'parity':serial.PARITY_NONE,\n                        'timeout':1, #wait at most one second for a response\n                        'writeTimeout':1, #similarly, fail if writing takes >1s\n                        }\n        self.termination_character = \"\\r\\n\"\n        SerialInstrument.__init__(self, port=port)\n        LightSource.__init__(self)\n        self.min_power=12\n        self.max_power=70\n        \n    def get_power(self):\n        \"\"\"read the current power output in mW\"\"\"\n        return self.float_query(\"rli?\")\n\n    def readpower(self):\n        \"\"\"deprecated: returns get_power()\"\"\"\n        return self.get_power()        \n        \n    def set_power(self, power):\n        \"\"\"set the power output in mW\"\"\"\n        power = float(power)\n        assert power <= self.max_power, ValueError(\"Exceeded maximum power\")\n        assert power >= self.min_power, ValueError(\"Below minimum power\")\n        self.query(\"slc:%f\" % power)\n        return self.readpower()",
  "def __init__(self, port=None):\n        self.port_settings = {'baudrate': 9600,\n                        'bytesize':serial.EIGHTBITS,\n                        'stopbits':serial.STOPBITS_ONE,\n                        'parity':serial.PARITY_NONE,\n                        'timeout':1, #wait at most one second for a response\n                        'writeTimeout':1, #similarly, fail if writing takes >1s\n                        }\n        self.termination_character = \"\\r\\n\"\n        SerialInstrument.__init__(self, port=port)\n        LightSource.__init__(self)\n        self.min_power=12\n        self.max_power=70",
  "def get_power(self):\n        \"\"\"read the current power output in mW\"\"\"\n        return self.float_query(\"rli?\")",
  "def readpower(self):\n        \"\"\"deprecated: returns get_power()\"\"\"\n        return self.get_power()",
  "def set_power(self, power):\n        \"\"\"set the power output in mW\"\"\"\n        power = float(power)\n        assert power <= self.max_power, ValueError(\"Exceeded maximum power\")\n        assert power >= self.min_power, ValueError(\"Below minimum power\")\n        self.query(\"slc:%f\" % power)\n        return self.readpower()",
  "class LightSource(Instrument):\n    \"\"\"A generic class representing light sources (including lasers)\n    \n    By default they can just have their power set and read.\n    \"\"\"\n    min_power = 0\n    max_power = 1\n    shutter = None\n    def __init__(self, shutter=None):\n        assert isinstance(shutter, Shutter) or shutter == None, 'invalid shutter supplied'\n        super(LightSource, self).__init__()\n        self.shutter = shutter\n\n    def get_power(self):\n        \"\"\"Get the current power of the light source\"\"\"\n        pass\n\n    def set_power(self, value):\n        \"\"\"Set the current power of the light source\"\"\"\n        print(value)\n\n    def _get_power(self):\n        \"\"\"Wrapper for get_power so we don't need to redefine properties\"\"\"\n        return self.get_power()\n    \n    def _set_power(self, value):\n        \"\"\"Wrapper for get_power so we don't need to redefine properties\"\"\"\n        return self.set_power(value)\n        \n    power = property(_get_power, _set_power)\n\n    def get_qt_ui(self):\n        return LightSourceUI(self)",
  "class LightSourceUI(QtWidgets.QWidget, UiTools):\n    def __init__(self, light_source, parent=None):\n        assert isinstance(light_source, LightSource), 'instrument must be a LightSource'\n        self.light_source = light_source\n        super(LightSourceUI, self).__init__(parent)\n        uic.loadUi(os.path.join(os.path.dirname(__file__), 'light_source.ui'), self)\n        self.control_group.setTitle(self.light_source.__class__.__name__)\n        self.power.setValidator(QtGui.QDoubleValidator())\n        self.power.textChanged.connect(self.check_state)\n        self.power.returnPressed.connect(self.update_param)\n        self.power_slider.setRange(self.light_source.min_power, self.light_source.max_power)\n        self.power_slider.valueChanged[int].connect(self.update_param)\n        self.power_slider.sliderReleased.connect(self.update_param)\n        self.set_power_button.clicked.connect(self.on_click)\n\n        if self.light_source.shutter is not None:\n            self.control_layout.addWidget(self.light_source.shutter.get_qt_ui())\n\n    def on_click(self):\n        sender = self.sender()\n        if sender == self.set_power_button:\n            self.power_slider.blockSignals(True)\n            self.power_slider.setValue(float(self.power.text()))\n            self.power_slider.blockSignals(False)\n            self.light_source.power = float(self.power.text())\n\n    def update_param(self, *args, **kwargs):\n        sender = self.sender()\n        index = self.senderSignalIndex()\n        if sender == self.power:\n            self.power_slider.blockSignals(True)\n            self.power_slider.setValue(float(self.power.text()))\n            self.power_slider.blockSignals(False)\n            self.light_source.power = float(self.power.text())\n        if sender == self.power_slider:\n            if len(args) != 0:  # slider is moving and the value is changing\n                value, = args\n                self.power.setText(str(value))\n            else:  # slider is released and signal has no arguments\n                value = sender.value()\n                self.light_source.power = float(self.power.text())",
  "def __init__(self, shutter=None):\n        assert isinstance(shutter, Shutter) or shutter == None, 'invalid shutter supplied'\n        super(LightSource, self).__init__()\n        self.shutter = shutter",
  "def get_power(self):\n        \"\"\"Get the current power of the light source\"\"\"\n        pass",
  "def set_power(self, value):\n        \"\"\"Set the current power of the light source\"\"\"\n        print(value)",
  "def _get_power(self):\n        \"\"\"Wrapper for get_power so we don't need to redefine properties\"\"\"\n        return self.get_power()",
  "def _set_power(self, value):\n        \"\"\"Wrapper for get_power so we don't need to redefine properties\"\"\"\n        return self.set_power(value)",
  "def get_qt_ui(self):\n        return LightSourceUI(self)",
  "def __init__(self, light_source, parent=None):\n        assert isinstance(light_source, LightSource), 'instrument must be a LightSource'\n        self.light_source = light_source\n        super(LightSourceUI, self).__init__(parent)\n        uic.loadUi(os.path.join(os.path.dirname(__file__), 'light_source.ui'), self)\n        self.control_group.setTitle(self.light_source.__class__.__name__)\n        self.power.setValidator(QtGui.QDoubleValidator())\n        self.power.textChanged.connect(self.check_state)\n        self.power.returnPressed.connect(self.update_param)\n        self.power_slider.setRange(self.light_source.min_power, self.light_source.max_power)\n        self.power_slider.valueChanged[int].connect(self.update_param)\n        self.power_slider.sliderReleased.connect(self.update_param)\n        self.set_power_button.clicked.connect(self.on_click)\n\n        if self.light_source.shutter is not None:\n            self.control_layout.addWidget(self.light_source.shutter.get_qt_ui())",
  "def on_click(self):\n        sender = self.sender()\n        if sender == self.set_power_button:\n            self.power_slider.blockSignals(True)\n            self.power_slider.setValue(float(self.power.text()))\n            self.power_slider.blockSignals(False)\n            self.light_source.power = float(self.power.text())",
  "def update_param(self, *args, **kwargs):\n        sender = self.sender()\n        index = self.senderSignalIndex()\n        if sender == self.power:\n            self.power_slider.blockSignals(True)\n            self.power_slider.setValue(float(self.power.text()))\n            self.power_slider.blockSignals(False)\n            self.light_source.power = float(self.power.text())\n        if sender == self.power_slider:\n            if len(args) != 0:  # slider is moving and the value is changing\n                value, = args\n                self.power.setText(str(value))\n            else:  # slider is released and signal has no arguments\n                value = sender.value()\n                self.light_source.power = float(self.power.text())",
  "class SolsTiSParseFail(Exception):\n    # updateGUI = QtCore.SIGNAL()\n\n    def __init__(self, dicc):\n        exceptionstring = ERROR_CODE[dicc['message']['parameters']['protocol_error'][0]] + \\\n                          '\\n at transmission: ' + str(dicc['message']['transmission_id'][0])\n\n        super(SolsTiSParseFail, self).__init__(exceptionstring)",
  "class SolsTiS(Instrument):\n    metadata_property_names = ('laser_status', )\n\n    def __init__(self, address, **kwargs):\n        \"\"\"\n\n        :param address: tuple of the SolsTiS (TCP_IP,TCP_PORT)\n        \"\"\"\n        Instrument.__init__(self)\n\n        self.socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        self.socket.settimeout(TIMEOUT)\n        self.socket.connect(address)\n       \n        self.computerIP = socket.gethostbyname(socket.gethostname())\n\n        self.laser_status = {}\n        self._transmission_id = 1\n        self.message_out_history = collections.deque(maxlen=MAX_MESSAGE_HISTORY)\n        self.message_in_history = collections.deque(maxlen=MAX_MESSAGE_HISTORY)\n\n        self.start_link()\n        self.system_status()\n\n    def __del__(self):\n        self.socket.close()\n\n    def send_command(self, operation, parameters=None):\n        \"\"\"\n        Implementation of the TCP JSON message structure as provided in the SolsTiS manual.\n        Also reads back the message from the SolsTiS, and, if verbose, prints out the\n        status of the laser after the command.\n\n        :param operation: string containing name of operation\n        :param parameters: dictionary of parameters for operation\n        \"\"\"\n        if parameters is None:\n            self.current_message = {\n                \"message\":\n                    {\n                        \"transmission_id\": [self._transmission_id],\n                        \"op\": operation\n                    }\n            }\n        else:\n            self.current_message = {\n                \"message\":\n                    {\n                        \"transmission_id\": [self._transmission_id],\n                        \"op\": operation,\n                        \"parameters\": parameters\n                    }\n            }\n\n        self.socket.send(json.dumps(self.current_message))\n\n        self.message_out_history.append(self.current_message)\n        self._transmission_id += 1\n\n        self.read_message()\n\n        if 'status' in list(self.message_in_history[-1]['message']['parameters'].keys()):\n            status = self.message_in_history[-1]['message']['parameters']['status']\n\n            if isinstance(status, str):\n                self._logger.debug(operation + ': ' + status)\n            else:\n                self._logger.debug(operation + ': ' + id_dictionary.get(operation, {})['status'][status[0]])\n\n    def read_message(self):\n        \"\"\"\n        Reads BUFFER_SIZE bytes from the laser, and appends the last full message to message_in_history\n\n        \"\"\"\n        self.current_reply = self.socket.recv(BUFFER_SIZE)\n        if len(self.current_reply.split('{')) != len(self.current_reply.split('}')):\n            self._logger.warn('You have not read a full number of messages')\n\n        self.message_in_history.append(json.loads('{' + self.current_reply.lstrip('{').split('}{')[-1]))\n\n        if self.message_in_history[-1]['message']['op'] == 'parse_fail':\n            raise SolsTiSParseFail(self.message_in_history[-1])\n\n    def start_link(self):\n        self.send_command(\"start_link\", {\"ip_address\": self.computerIP})\n\n    def ping(self, text):\n        self.send_command(\"ping\", {\"text_in\": text})\n\n        return self.message_in_history[-1]['message']['parameters']['text_out']\n\n    def change_wavelength(self, l):\n        self.send_command(\"set_wave_m\", {\"wavelength\": [l]})\n\n        time.sleep(1)\n        if self.message_in_history[-1]['message']['parameters']['status'][0] == 0:\n            self.system_status()\n\n    def check_wavelength(self):\n        self.send_command(\"poll_wave_m\")\n\n        if self.message_in_history[-1]['message']['parameters']['status'][0] == 0:\n            self.laser_status['wavelength'] = \\\n                self.message_in_history[-1]['message']['parameters']['current_wavelength'][0]\n\n    def stop_tuning(self):\n        self.send_command(\"stop_move_wave_t\")\n\n    def tune_etalon(self, val):\n        self.send_command(\"tune_etalon\", {\"setting\": [val]})\n\n    def tune_cavity(self, val):\n        self.send_command(\"tune_cavity\", {\"setting\": [val]})\n\n    def fine_tune_cavity(self, val):\n        self.send_command(\"fine_tune_cavity\", {\"setting\": [val]})\n\n    def tune_resonator(self, val):\n        self.send_command(\"tune_resonator\", {\"setting\": [val]})\n\n    def fine_tune_resonator(self, val):\n        self.send_command(\"fine_tune_resonator\", {\"setting\": [val]})\n\n    def etalon_lock(self, val):\n        if val not in ['off', 'on']:\n            raise ValueError('Lock can only be set to \"off\" or \"on\"')\n        else:\n            self.send_command(\"etalon_lock\", {\"operation\": val})\n\n            if self.message_in_history[-1]['message']['parameters']['status'][0] == 0:\n                self.laser_status['etalon_lock'] = val\n\n    def etalon_lock_status(self):\n        self.send_command(\"etalon_lock_status\")\n\n        if self.message_in_history[-1]['message']['parameters']['status'][0] == 0:\n            self.laser_status['etalon_lock'] = self.message_in_history[-1]['message']['parameters']['condition']\n\n    def cavity_lock(self, val):\n        if val not in ['off', 'on']:\n            self._logger.warn('Lock can only be set to \"off\" or \"on\"')\n        else:\n            self.send_command(\"cavity_lock\", {\"operation\": val})\n\n            if self.message_in_history[-1]['message']['parameters']['status'][0] == 0:\n                self.laser_status['ref_cavity_lock'] = val\n\n    def cavity_lock_status(self):\n        self.send_command(\"cavity_lock_status\")\n\n        if self.message_in_history[-1]['message']['parameters']['status'][0] == 0:\n            self.laser_status['ref_cavity_lock'] = self.message_in_history[-1]['message']['parameters']['condition']\n\n    def system_status(self):\n        self.send_command(\"get_status\")\n\n        if self.message_in_history[-1]['message']['parameters']['status'][0] == 0:\n            status = self.message_in_history[-1]['message']['parameters']\n            for ii in status:\n                if type(status[ii]) == list:\n                    self.laser_status[ii] = status[ii][0]\n                else:\n                    self.laser_status[ii] = status[ii]\n\n        # self.updateGUI.emit()\n\n    def get_qt_ui(self):\n        return SolsTiSUI(self)",
  "class SolsTiSUI(QtWidgets.QWidget):\n    def __init__(self, solstis):\n        assert isinstance(solstis, SolsTiS), \"instrument must be a SolsTiS\"\n        super(SolsTiSUI, self).__init__()\n\n        self.SolsTiS = solstis\n        self.signal = QtCore.SIGNAL('SolsTiSGUIupdate')\n        self.SolsTiSMonitorThread = None\n\n        uic.loadUi(os.path.join(os.path.dirname(__file__), 'SolsTiS.ui'), self)\n\n        self.checkBoxSolsTiSLockMonitor.stateChanged.connect(self.SolsTiSLockMonitor)\n        self.checkBoxSolsTiSEtalonLock.stateChanged.connect(self.SolsTiSLockEtalon)\n        self.checkBoxSolsTiSCavityLock.stateChanged.connect(self.SolsTiSLockCavity)\n        self.lineEditSolsTiSWL.returnPressed.connect(self.SolsTiSWL)\n        self.pushButtonSolsTiSstatusMonitor.clicked.connect(self.SolsTiSMonitor)\n        self.pushButtonSolsTiSstopMonitor.clicked.connect(self.SolsTiSMonitorStop)\n\n        # self.SolsTiS.updateGUI.connect(self.updateGUI)\n\n    def SolsTiSLockMonitor(self):\n        # ADD A SEcTION THAT CHECKS THAT THE ETALON VOLTAGE DOESN'T GO TOO FAR AWAY\n        if self.checkBoxSolsTiSEtalonLock.isChecked():\n            self.SolsTisLockThread = SolsTiSLockThread(self.SolsTiS)\n            self.SolsTisLockThread.connect(self.SolsTisLockThread, self.SolsTisLockThread.signal, self.SolsTiSReLock)\n            self.SolsTisLockThread.start()\n\n    def SolsTiSReLock(self):\n        progress = QtWidgets.QProgressDialog(\"Re-locking etalon\", \"Abort\", 0, 5, self)\n        progress.show()\n        i = 0\n        self.SolsTiS.system_status()\n\n        while self.SolsTiS.laser_status['etalon_lock'] != 'on' and i < 5:\n            progress.setValue(i)\n            self.SolsTiS.etalon_lock('on')\n            time.sleep(0.5)\n            self.SolsTiS.system_status()\n            time.sleep(0.1)\n            i += 1\n        progress.close()\n        if i < 5:\n            self.SolsTiSLockMonitor()\n        else:\n            popup = QtWidgets.QMessageBox()\n            popup.setText(\"Re-locking the etalon failed\")\n            popup.exec_()\n\n    def SolsTiSLockEtalon(self):\n        if self.checkBoxSolsTiSEtalonLock.isChecked():\n            self.SolsTiS.etalon_lock(\"on\")\n        else:\n            self.SolsTiS.etalon_lock(\"off\")\n\n    def SolsTiSLockCavity(self):\n        if self.checkBoxSolsTiSCavityLock.isChecked():\n            self.SolsTiS.cavity_lock(\"on\")\n        else:\n            self.SolsTiS.cavity_lock(\"off\")\n\n    def SolsTiSWL(self):\n        wl = float(self.lineEditSolsTiSWL.text())\n        self.SolsTiS.change_wavelength(wl)\n\n    def updateGUI(self):\n        self.lineEditSolsTiSWL.setText(str(self.SolsTiS.laser_status['wavelength']))\n        self.checkBoxSolsTiSCavityLock.setChecked(self.SolsTiS.laser_status['cavity_lock'] in ['on'])\n        self.checkBoxSolsTiSEtalonLock.setChecked(self.SolsTiS.laser_status['etalon_lock'] in ['on'])\n\n    def SolsTiSMonitor(self):\n        '''\n        Starts a monitoring thread that returns the system_status of the laser every 10s\n        :return:\n        '''\n        if self.SolsTiSMonitorThread is None:\n            self.SolsTiSMonitorThread = SolsTiSStatusThread(self.SolsTiS)\n            self.SolsTiSMonitorThread.connect(self.SolsTiSMonitorThread, self.SolsTiSMonitorThread.signal,\n                                              self.SolsTiSupdatestatus)\n            self.SolsTiSMonitorThread.start()\n        elif not self.SolsTiSMonitorThread.isRunning():\n            self.SolsTiSMonitorThread.start()\n\n    def SolsTiSMonitorStop(self):\n        '''\n        Terminates the monitor thread if it exists\n        :return:\n        '''\n        if self.SolsTiSMonitorThread is not None and self.SolsTiSMonitorThread.isRunning():\n            self.SolsTiSMonitorThread.terminate()\n\n    def SolsTiSupdatestatus(self):\n        '''\n        relevant_properties is a dictionary of labels to display (keys) and names of the properties to display as returned\n        by the laser\n        We then create a dictionary with the labels and the values of the properties (display_dicc)\n        And display that dictionary as a table\n        :return:\n        '''\n        relevant_properties = {'C. lock': 'cavity_lock', 'E. lock': 'etalon_lock', 'T': 'temperature',\n                               'R. volt.': 'resonator_voltage', 'E. volt.': 'etalon_voltage',\n                               'wvl': 'wavelength', 'Out': 'output_monitor'}\n        display_dicc = {new_key: self.SolsTiS.laser_status[relevant_properties[new_key]] for new_key in\n                        list(relevant_properties.keys())}\n        self.tableWidget.setRowCount(len(relevant_properties))\n        row = 0\n        for key in list(display_dicc.keys()):\n            item_key = QtWidgets.QTableWidgetItem(key)\n            item_value = QtWidgets.QTableWidgetItem(str(display_dicc[key]))\n            self.tableWidget.setItem(row, 0, item_key)\n            self.tableWidget.setItem(row, 1, item_value)\n            row = row + 1\n        self.tableWidget.resizeColumnsToContents()",
  "class SolsTiSLockThread(QtCore.QThread):\n    def __init__(self, solstis):\n        QtCore.QThread.__init__(self)\n        self.SolsTiS = solstis\n        self.signal = QtCore.SIGNAL(\"laser_unlocked\")\n\n        self.setTerminationEnabled()\n\n        self.SolsTiS.system_status()\n        if self.SolsTiS.laser_status['etalon_lock'] != 'on':\n            self.SolsTiS.etalon_lock('on')\n\n    def run(self):\n        while self.SolsTiS.laser_status['etalon_lock'] == 'on':\n            time.sleep(2)\n            self.SolsTiS.system_status()\n            time.sleep(0.1)\n\n        self.emit(self.signal)",
  "class SolsTiSStatusThread(QtCore.QThread):\n    def __init__(self, solstis):\n        QtCore.QThread.__init__(self)\n        self.SolsTiS = solstis\n        self.signal = QtCore.SIGNAL(\"SolsTiS_status_update\")\n\n        self.setTerminationEnabled()\n\n        self.SolsTiS.system_status()\n\n    def run(self):\n        while 1:\n            self.SolsTiS.system_status()\n\n            self.emit(self.signal, self.SolsTiS.laser_status)\n\n            time.sleep(1)",
  "def download_logs():\n    def perdelta(start, end, delta):\n        return_list = []\n        curr = start\n        while curr < end:\n            # yield curr\n            return_list.append(curr)\n            curr += delta\n        return [(int(x.strftime('%d')), int(x.strftime('%m')), int(x.strftime('%y'))) for x in return_list]\n\n    '''NOT GENERAL\n\n    Script that can be used to download the logs created by automatic logging in the laser\n    '''\n    import urllib.request, urllib.error, urllib.parse\n    # import numpy as np\n    from datetime import date, timedelta\n\n    url_name = 'http://172.24.37.153/FS/FLASH0/M_Squared/Logs/log_%d_%d_%d_%d.txt'\n\n    # nums1 = [153, 222]\n    # days = np.linspace(1, 32) #[1,2,3,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29]\n    # months = np.linspace(1, 13)\n    # years = [15, 16]\n\n    # nums = [(153,18,8,16), (222,24,6,16), (222,23,6,16)]\n\n\n    all_logs = []\n    list_dates = perdelta(date(2016, 7, 12), date(2016, 11, 4), timedelta(days=1))\n    for datum in list_dates:\n        try:\n            data = urllib.request.urlopen(url_name % ((153,) + datum))\n            all_logs.append(data.read())\n            print('Downloaded ', url_name % ((153,) + datum))\n        except Exception as e:\n            print('Failed ', url_name % ((153,) + datum), ' because ', e)\n    list_dates = perdelta(date(2015, 7, 8), date(2016, 7, 11), timedelta(days=1))\n    for datum in list_dates:\n        try:\n            data = urllib.request.urlopen(url_name % ((222,) + datum))\n            all_logs.append(data.read())\n            print('Downloaded ', url_name % ((222,) + datum))\n        except Exception as e:\n            print('Failed ', url_name % ((222,) + datum), ' because ', e)\n\n    # for num in nums:\n    #     try:\n    #         data = urllib2.urlopen(url_name % num)\n    #         all_logs.append(data.read())\n    #         print 'Downloaded ', url_name % num\n    #     except:\n    #         print 'Failed ', url_name % num\n    #     time.sleep(1)\n    # for num1 in nums1:\n    #     for day in days:\n    #         for month in months:\n    #             for year in years:\n    #                 try:\n    #                     data = urllib2.urlopen(url_name % (num1, day, month, year))\n    #                     all_logs.append(data.read())\n    #                     print 'Downloaded ', url_name % (num1, day, month, year)\n    #                 except:\n    #                     print 'Failed ', url_name % (num1, day, month, year)\n    #                 time.sleep(1)\n    import pickle\n    pickle.dump(all_logs, open(r'C:\\Users\\Hera\\Desktop/SolsTiSLogs.p', 'w'))\n    return all_logs",
  "def __init__(self, dicc):\n        exceptionstring = ERROR_CODE[dicc['message']['parameters']['protocol_error'][0]] + \\\n                          '\\n at transmission: ' + str(dicc['message']['transmission_id'][0])\n\n        super(SolsTiSParseFail, self).__init__(exceptionstring)",
  "def __init__(self, address, **kwargs):\n        \"\"\"\n\n        :param address: tuple of the SolsTiS (TCP_IP,TCP_PORT)\n        \"\"\"\n        Instrument.__init__(self)\n\n        self.socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        self.socket.settimeout(TIMEOUT)\n        self.socket.connect(address)\n       \n        self.computerIP = socket.gethostbyname(socket.gethostname())\n\n        self.laser_status = {}\n        self._transmission_id = 1\n        self.message_out_history = collections.deque(maxlen=MAX_MESSAGE_HISTORY)\n        self.message_in_history = collections.deque(maxlen=MAX_MESSAGE_HISTORY)\n\n        self.start_link()\n        self.system_status()",
  "def __del__(self):\n        self.socket.close()",
  "def send_command(self, operation, parameters=None):\n        \"\"\"\n        Implementation of the TCP JSON message structure as provided in the SolsTiS manual.\n        Also reads back the message from the SolsTiS, and, if verbose, prints out the\n        status of the laser after the command.\n\n        :param operation: string containing name of operation\n        :param parameters: dictionary of parameters for operation\n        \"\"\"\n        if parameters is None:\n            self.current_message = {\n                \"message\":\n                    {\n                        \"transmission_id\": [self._transmission_id],\n                        \"op\": operation\n                    }\n            }\n        else:\n            self.current_message = {\n                \"message\":\n                    {\n                        \"transmission_id\": [self._transmission_id],\n                        \"op\": operation,\n                        \"parameters\": parameters\n                    }\n            }\n\n        self.socket.send(json.dumps(self.current_message))\n\n        self.message_out_history.append(self.current_message)\n        self._transmission_id += 1\n\n        self.read_message()\n\n        if 'status' in list(self.message_in_history[-1]['message']['parameters'].keys()):\n            status = self.message_in_history[-1]['message']['parameters']['status']\n\n            if isinstance(status, str):\n                self._logger.debug(operation + ': ' + status)\n            else:\n                self._logger.debug(operation + ': ' + id_dictionary.get(operation, {})['status'][status[0]])",
  "def read_message(self):\n        \"\"\"\n        Reads BUFFER_SIZE bytes from the laser, and appends the last full message to message_in_history\n\n        \"\"\"\n        self.current_reply = self.socket.recv(BUFFER_SIZE)\n        if len(self.current_reply.split('{')) != len(self.current_reply.split('}')):\n            self._logger.warn('You have not read a full number of messages')\n\n        self.message_in_history.append(json.loads('{' + self.current_reply.lstrip('{').split('}{')[-1]))\n\n        if self.message_in_history[-1]['message']['op'] == 'parse_fail':\n            raise SolsTiSParseFail(self.message_in_history[-1])",
  "def start_link(self):\n        self.send_command(\"start_link\", {\"ip_address\": self.computerIP})",
  "def ping(self, text):\n        self.send_command(\"ping\", {\"text_in\": text})\n\n        return self.message_in_history[-1]['message']['parameters']['text_out']",
  "def change_wavelength(self, l):\n        self.send_command(\"set_wave_m\", {\"wavelength\": [l]})\n\n        time.sleep(1)\n        if self.message_in_history[-1]['message']['parameters']['status'][0] == 0:\n            self.system_status()",
  "def check_wavelength(self):\n        self.send_command(\"poll_wave_m\")\n\n        if self.message_in_history[-1]['message']['parameters']['status'][0] == 0:\n            self.laser_status['wavelength'] = \\\n                self.message_in_history[-1]['message']['parameters']['current_wavelength'][0]",
  "def stop_tuning(self):\n        self.send_command(\"stop_move_wave_t\")",
  "def tune_etalon(self, val):\n        self.send_command(\"tune_etalon\", {\"setting\": [val]})",
  "def tune_cavity(self, val):\n        self.send_command(\"tune_cavity\", {\"setting\": [val]})",
  "def fine_tune_cavity(self, val):\n        self.send_command(\"fine_tune_cavity\", {\"setting\": [val]})",
  "def tune_resonator(self, val):\n        self.send_command(\"tune_resonator\", {\"setting\": [val]})",
  "def fine_tune_resonator(self, val):\n        self.send_command(\"fine_tune_resonator\", {\"setting\": [val]})",
  "def etalon_lock(self, val):\n        if val not in ['off', 'on']:\n            raise ValueError('Lock can only be set to \"off\" or \"on\"')\n        else:\n            self.send_command(\"etalon_lock\", {\"operation\": val})\n\n            if self.message_in_history[-1]['message']['parameters']['status'][0] == 0:\n                self.laser_status['etalon_lock'] = val",
  "def etalon_lock_status(self):\n        self.send_command(\"etalon_lock_status\")\n\n        if self.message_in_history[-1]['message']['parameters']['status'][0] == 0:\n            self.laser_status['etalon_lock'] = self.message_in_history[-1]['message']['parameters']['condition']",
  "def cavity_lock(self, val):\n        if val not in ['off', 'on']:\n            self._logger.warn('Lock can only be set to \"off\" or \"on\"')\n        else:\n            self.send_command(\"cavity_lock\", {\"operation\": val})\n\n            if self.message_in_history[-1]['message']['parameters']['status'][0] == 0:\n                self.laser_status['ref_cavity_lock'] = val",
  "def cavity_lock_status(self):\n        self.send_command(\"cavity_lock_status\")\n\n        if self.message_in_history[-1]['message']['parameters']['status'][0] == 0:\n            self.laser_status['ref_cavity_lock'] = self.message_in_history[-1]['message']['parameters']['condition']",
  "def system_status(self):\n        self.send_command(\"get_status\")\n\n        if self.message_in_history[-1]['message']['parameters']['status'][0] == 0:\n            status = self.message_in_history[-1]['message']['parameters']\n            for ii in status:\n                if type(status[ii]) == list:\n                    self.laser_status[ii] = status[ii][0]\n                else:\n                    self.laser_status[ii] = status[ii]",
  "def get_qt_ui(self):\n        return SolsTiSUI(self)",
  "def __init__(self, solstis):\n        assert isinstance(solstis, SolsTiS), \"instrument must be a SolsTiS\"\n        super(SolsTiSUI, self).__init__()\n\n        self.SolsTiS = solstis\n        self.signal = QtCore.SIGNAL('SolsTiSGUIupdate')\n        self.SolsTiSMonitorThread = None\n\n        uic.loadUi(os.path.join(os.path.dirname(__file__), 'SolsTiS.ui'), self)\n\n        self.checkBoxSolsTiSLockMonitor.stateChanged.connect(self.SolsTiSLockMonitor)\n        self.checkBoxSolsTiSEtalonLock.stateChanged.connect(self.SolsTiSLockEtalon)\n        self.checkBoxSolsTiSCavityLock.stateChanged.connect(self.SolsTiSLockCavity)\n        self.lineEditSolsTiSWL.returnPressed.connect(self.SolsTiSWL)\n        self.pushButtonSolsTiSstatusMonitor.clicked.connect(self.SolsTiSMonitor)\n        self.pushButtonSolsTiSstopMonitor.clicked.connect(self.SolsTiSMonitorStop)",
  "def SolsTiSLockMonitor(self):\n        # ADD A SEcTION THAT CHECKS THAT THE ETALON VOLTAGE DOESN'T GO TOO FAR AWAY\n        if self.checkBoxSolsTiSEtalonLock.isChecked():\n            self.SolsTisLockThread = SolsTiSLockThread(self.SolsTiS)\n            self.SolsTisLockThread.connect(self.SolsTisLockThread, self.SolsTisLockThread.signal, self.SolsTiSReLock)\n            self.SolsTisLockThread.start()",
  "def SolsTiSReLock(self):\n        progress = QtWidgets.QProgressDialog(\"Re-locking etalon\", \"Abort\", 0, 5, self)\n        progress.show()\n        i = 0\n        self.SolsTiS.system_status()\n\n        while self.SolsTiS.laser_status['etalon_lock'] != 'on' and i < 5:\n            progress.setValue(i)\n            self.SolsTiS.etalon_lock('on')\n            time.sleep(0.5)\n            self.SolsTiS.system_status()\n            time.sleep(0.1)\n            i += 1\n        progress.close()\n        if i < 5:\n            self.SolsTiSLockMonitor()\n        else:\n            popup = QtWidgets.QMessageBox()\n            popup.setText(\"Re-locking the etalon failed\")\n            popup.exec_()",
  "def SolsTiSLockEtalon(self):\n        if self.checkBoxSolsTiSEtalonLock.isChecked():\n            self.SolsTiS.etalon_lock(\"on\")\n        else:\n            self.SolsTiS.etalon_lock(\"off\")",
  "def SolsTiSLockCavity(self):\n        if self.checkBoxSolsTiSCavityLock.isChecked():\n            self.SolsTiS.cavity_lock(\"on\")\n        else:\n            self.SolsTiS.cavity_lock(\"off\")",
  "def SolsTiSWL(self):\n        wl = float(self.lineEditSolsTiSWL.text())\n        self.SolsTiS.change_wavelength(wl)",
  "def updateGUI(self):\n        self.lineEditSolsTiSWL.setText(str(self.SolsTiS.laser_status['wavelength']))\n        self.checkBoxSolsTiSCavityLock.setChecked(self.SolsTiS.laser_status['cavity_lock'] in ['on'])\n        self.checkBoxSolsTiSEtalonLock.setChecked(self.SolsTiS.laser_status['etalon_lock'] in ['on'])",
  "def SolsTiSMonitor(self):\n        '''\n        Starts a monitoring thread that returns the system_status of the laser every 10s\n        :return:\n        '''\n        if self.SolsTiSMonitorThread is None:\n            self.SolsTiSMonitorThread = SolsTiSStatusThread(self.SolsTiS)\n            self.SolsTiSMonitorThread.connect(self.SolsTiSMonitorThread, self.SolsTiSMonitorThread.signal,\n                                              self.SolsTiSupdatestatus)\n            self.SolsTiSMonitorThread.start()\n        elif not self.SolsTiSMonitorThread.isRunning():\n            self.SolsTiSMonitorThread.start()",
  "def SolsTiSMonitorStop(self):\n        '''\n        Terminates the monitor thread if it exists\n        :return:\n        '''\n        if self.SolsTiSMonitorThread is not None and self.SolsTiSMonitorThread.isRunning():\n            self.SolsTiSMonitorThread.terminate()",
  "def SolsTiSupdatestatus(self):\n        '''\n        relevant_properties is a dictionary of labels to display (keys) and names of the properties to display as returned\n        by the laser\n        We then create a dictionary with the labels and the values of the properties (display_dicc)\n        And display that dictionary as a table\n        :return:\n        '''\n        relevant_properties = {'C. lock': 'cavity_lock', 'E. lock': 'etalon_lock', 'T': 'temperature',\n                               'R. volt.': 'resonator_voltage', 'E. volt.': 'etalon_voltage',\n                               'wvl': 'wavelength', 'Out': 'output_monitor'}\n        display_dicc = {new_key: self.SolsTiS.laser_status[relevant_properties[new_key]] for new_key in\n                        list(relevant_properties.keys())}\n        self.tableWidget.setRowCount(len(relevant_properties))\n        row = 0\n        for key in list(display_dicc.keys()):\n            item_key = QtWidgets.QTableWidgetItem(key)\n            item_value = QtWidgets.QTableWidgetItem(str(display_dicc[key]))\n            self.tableWidget.setItem(row, 0, item_key)\n            self.tableWidget.setItem(row, 1, item_value)\n            row = row + 1\n        self.tableWidget.resizeColumnsToContents()",
  "def __init__(self, solstis):\n        QtCore.QThread.__init__(self)\n        self.SolsTiS = solstis\n        self.signal = QtCore.SIGNAL(\"laser_unlocked\")\n\n        self.setTerminationEnabled()\n\n        self.SolsTiS.system_status()\n        if self.SolsTiS.laser_status['etalon_lock'] != 'on':\n            self.SolsTiS.etalon_lock('on')",
  "def run(self):\n        while self.SolsTiS.laser_status['etalon_lock'] == 'on':\n            time.sleep(2)\n            self.SolsTiS.system_status()\n            time.sleep(0.1)\n\n        self.emit(self.signal)",
  "def __init__(self, solstis):\n        QtCore.QThread.__init__(self)\n        self.SolsTiS = solstis\n        self.signal = QtCore.SIGNAL(\"SolsTiS_status_update\")\n\n        self.setTerminationEnabled()\n\n        self.SolsTiS.system_status()",
  "def run(self):\n        while 1:\n            self.SolsTiS.system_status()\n\n            self.emit(self.signal, self.SolsTiS.laser_status)\n\n            time.sleep(1)",
  "def perdelta(start, end, delta):\n        return_list = []\n        curr = start\n        while curr < end:\n            # yield curr\n            return_list.append(curr)\n            curr += delta\n        return [(int(x.strftime('%d')), int(x.strftime('%m')), int(x.strftime('%y'))) for x in return_list]",
  "class APTMotor(object):\n    def __init__(self, SerialNum=None, HWTYPE=31,blacklash_correction=0.10,minimum_velocity=0.0,acceleration=5.0,max_velocity=10.0):\n        '''\n        HWTYPE_BSC001\t\t11\t// 1 Ch benchtop stepper driver\n        HWTYPE_BSC101\t\t12\t// 1 Ch benchtop stepper driver\n        HWTYPE_BSC002\t\t13\t// 2 Ch benchtop stepper driver\n        HWTYPE_BDC101\t\t14\t// 1 Ch benchtop DC servo driver\n        HWTYPE_SCC001\t\t21\t// 1 Ch stepper driver card (used within BSC102,103 units)\n        HWTYPE_DCC001\t\t22\t// 1 Ch DC servo driver card (used within BDC102,103 units)\n        HWTYPE_ODC001\t\t24\t// 1 Ch DC servo driver cube\n        HWTYPE_OST001\t\t25\t// 1 Ch stepper driver cube\n        HWTYPE_MST601\t\t26\t// 2 Ch modular stepper driver module\n        HWTYPE_TST001\t\t29\t// 1 Ch Stepper driver T-Cube\n        HWTYPE_TDC001\t\t31\t// 1 Ch DC servo driver T-Cube\n        HWTYPE_LTSXXX\t\t42\t// LTS300/LTS150 Long Travel Integrated Driver/Stages\n        HWTYPE_L490MZ\t\t43\t// L490MZ Integrated Driver/Labjack\n        HWTYPE_BBD10X\t\t44\t// 1/2/3 Ch benchtop brushless DC servo driver\n        '''\n        self.Connected = False\n\n        self.aptdll = windll.LoadLibrary(DLL_PATH)\n\n        self.aptdll.EnableEventDlg(True)\n        self.aptdll.APTInit()\n        #print 'APT initialized'\n        self.HWType = c_long(HWTYPE)\n        self.blCorr = blacklash_correction #100um backlash correction\n        if SerialNum is not None:\n            if DEBUG: print((\"Serial is\", SerialNum))\n            self.SerialNum = c_long(SerialNum)\n            self.initializeHardwareDevice()\n        # TODO : Error reporting to know if initialisation went sucessfully or not.\n\n        else:\n            if DEBUG: print(\"No serial, please setSerialNumber\")\n\n        self.setVelocityParameters(minVel=minimum_velocity, acc=acceleration, maxVel=max_velocity)\n\n    def getNumberOfHardwareUnits(self):\n        '''\n        Returns the number of HW units connected that are available to be interfaced\n        '''\n        numUnits = c_long()\n        self.aptdll.GetNumHWUnitsEx(self.HWType, pointer(numUnits))\n        return numUnits.value\n\n\n    def getSerialNumberByIdx(self, index):\n        '''\n        Returns the Serial Number of the specified index\n        '''\n        HWSerialNum = c_long()\n        hardwareIndex = c_long(index)\n        self.aptdll.GetHWSerialNumEx(self.HWType, hardwareIndex, pointer(HWSerialNum))\n        return HWSerialNum\n\n    def setSerialNumber(self, SerialNum):\n        '''\n        Sets the Serial Number of the specified index\n        '''\n        if DEBUG: print((\"Serial is\", SerialNum))\n        self.SerialNum = c_long(SerialNum)\n        return self.SerialNum.value\n\n    def initializeHardwareDevice(self):\n        '''\n        Initialises the motor.\n        You can only get the position of the motor and move the motor after it has been initialised.\n        Once initiallised, it will not respond to other objects trying to control it, until released.\n        '''\n        if DEBUG: print(('initializeHardwareDevice serial', self.SerialNum))\n        result = self.aptdll.InitHWDevice(self.SerialNum)\n\n        if result == 0:\n            self.Connected = True\n            if DEBUG: print('initializeHardwareDevice connection SUCESS')\n        # need some kind of error reporting here\n        else:\n            raise Exception('Connection Failed. Check Serial Number!')\n        return True\n\n        ''' Interfacing with the motor settings '''\n    def getHardwareInformation(self):\n        model = c_buffer(255)\n        softwareVersion = c_buffer(255)\n        hardwareNotes = c_buffer(255)\n        self.aptdll.GetHWInfo(self.SerialNum, model, 255, softwareVersion, 255, hardwareNotes, 255)\n        hwinfo = [model.value, softwareVersion.value, hardwareNotes.value]\n        return hwinfo\n\n    def getStageAxisInformation(self):\n        minimumPosition = c_float()\n        maximumPosition = c_float()\n        units = c_long()\n        pitch = c_float()\n        self.aptdll.MOT_GetStageAxisInfo(self.SerialNum, pointer(minimumPosition), pointer(maximumPosition), pointer(units), pointer(pitch))\n        stageAxisInformation = [minimumPosition.value, maximumPosition.value, units.value, pitch.value]\n        return stageAxisInformation\n\n    def setStageAxisInformation(self, minimumPosition, maximumPosition):\n        minimumPosition = c_float(minimumPosition)\n        maximumPosition = c_float(maximumPosition)\n        units = c_long(1) #units of mm\n        # Get different pitches of lead screw for moving stages for different stages.\n        pitch = c_float(self.config.get_pitch())\n        self.aptdll.MOT_SetStageAxisInfo(self.SerialNum, minimumPosition, maximumPosition, units, pitch)\n        return True\n\n    def getHardwareLimitSwitches(self):\n        reverseLimitSwitch = c_long()\n        forwardLimitSwitch = c_long()\n        self.aptdll.MOT_GetHWLimSwitches(self.SerialNum, pointer(reverseLimitSwitch), pointer(forwardLimitSwitch))\n        hardwareLimitSwitches = [reverseLimitSwitch.value, forwardLimitSwitch.value]\n        return hardwareLimitSwitches\n\n    def getVelocityParameters(self):\n        minimumVelocity = c_float()\n        acceleration = c_float()\n        maximumVelocity = c_float()\n        self.aptdll.MOT_GetVelParams(self.SerialNum, pointer(minimumVelocity), pointer(acceleration), pointer(maximumVelocity))\n        velocityParameters = [minimumVelocity.value, acceleration.value, maximumVelocity.value]\n        return velocityParameters\n\n    def getVel(self):\n        if DEBUG: print('getVel probing...')\n        minVel, acc, maxVel = self.getVelocityParameters()\n        if DEBUG: print('getVel maxVel')\n        return maxVel\n\n\n    def setVelocityParameters(self, minVel, acc, maxVel):\n        minimumVelocity = c_float(minVel)\n        acceleration = c_float(acc)\n        maximumVelocity = c_float(maxVel)\n        self.aptdll.MOT_SetVelParams(self.SerialNum, minimumVelocity, acceleration, maximumVelocity)\n        return True\n\n    def setVel(self, maxVel):\n        if DEBUG: print(('setVel', maxVel))\n        minVel, acc, oldVel = self.getVelocityParameters()\n        self.setVelocityParameters(minVel, acc, maxVel)\n        return True\n\n    def getVelocityParameterLimits(self):\n        maximumAcceleration = c_float()\n        maximumVelocity = c_float()\n        self.aptdll.MOT_GetVelParamLimits(self.SerialNum, pointer(maximumAcceleration), pointer(maximumVelocity))\n        velocityParameterLimits = [maximumAcceleration.value, maximumVelocity.value]\n        return velocityParameterLimits\n\n        '''\n        Controlling the motors\n        m = move\n        c = controlled velocity\n        b = backlash correction\n\n        Rel = relative distance from current position.\n        Abs = absolute position\n        '''\n    def getPos(self):\n        '''\n        Obtain the current absolute position of the stage\n        '''\n        if DEBUG: print('getPos probing...')\n        if not self.Connected:\n            raise Exception('Please connect first! Use initializeHardwareDevice')\n\n        position = c_float()\n        self.aptdll.MOT_GetPosition(self.SerialNum, pointer(position))\n        if DEBUG: print(('getPos ', position.value))\n        return position.value\n\n    def mRel(self, relDistance):\n        '''\n        Moves the motor a relative distance specified\n        relDistance    float     Relative position desired\n        '''\n        if DEBUG: print(('mRel ', relDistance, c_float(relDistance)))\n        if not self.Connected:\n            print('Please connect first! Use initializeHardwareDevice')\n            #raise Exception('Please connect first! Use initializeHardwareDevice')\n        relativeDistance = c_float(relDistance)\n        self.aptdll.MOT_MoveRelativeEx(self.SerialNum, relativeDistance, True)\n        if DEBUG: print('mRel SUCESS')\n        return True\n\n    def mAbs(self, absPosition):\n        '''\n        Moves the motor to the Absolute position specified\n        absPosition    float     Position desired\n        '''\n        if DEBUG: print(('mAbs ', absPosition, c_float(absPosition)))\n        if not self.Connected:\n            raise Exception('Please connect first! Use initializeHardwareDevice')\n        absolutePosition = c_float(absPosition)\n        self.aptdll.MOT_MoveAbsoluteEx(self.SerialNum, absolutePosition, True)\n        if DEBUG: print('mAbs SUCESS')\n        return True\n\n    def mcRel(self, relDistance, moveVel=0.5):\n        '''\n        Moves the motor a relative distance specified at a controlled velocity\n        relDistance    float     Relative position desired\n        moveVel        float     Motor velocity, mm/sec\n        '''\n        if DEBUG: print(('mcRel ', relDistance, c_float(relDistance), 'mVel', moveVel))\n        if not self.Connected:\n            raise Exception('Please connect first! Use initializeHardwareDevice')\n        # Save velocities to reset after move\n        maxVel = self.getVel()\n        # Set new desired max velocity\n        self.setVel(moveVel)\n        self.mRel(relDistance)\n        self.setVel(maxVel)\n        if DEBUG: print('mcRel SUCESS')\n        return True\n\n    def mcAbs(self, absPosition, moveVel=0.5):\n        '''\n        Moves the motor to the Absolute position specified at a controlled velocity\n        absPosition    float     Position desired\n        moveVel        float     Motor velocity, mm/sec\n        '''\n        if DEBUG: print(('mcAbs ', absPosition, c_float(absPosition), 'mVel', moveVel))\n        if not self.Connected:\n            raise Exception('Please connect first! Use initializeHardwareDevice')\n        # Save velocities to reset after move\n        minVel, acc, maxVel = self.getVelocityParameters()\n        # Set new desired max velocity\n        self.setVel(moveVel)\n        self.mAbs(absPosition)\n        self.setVel(maxVel)\n        if DEBUG: print('mcAbs SUCESS')\n        return True\n\n    def mbRel(self, relDistance):\n        '''\n        Moves the motor a relative distance specified\n        relDistance    float     Relative position desired\n        '''\n        if DEBUG: print(('mbRel ', relDistance, c_float(relDistance)))\n        if not self.Connected:\n            print('Please connect first! Use initializeHardwareDevice')\n            #raise Exception('Please connect first! Use initializeHardwareDevice')\n        self.mRel(relDistance-self.blCorr)\n        self.mRel(self.blCorr)\n        if DEBUG: print('mbRel SUCCESS')\n        return True\n\n    def mbAbs(self, absPosition):\n        '''\n        Moves the motor to the Absolute position specified\n        absPosition    float     Position desired\n        '''\n        if DEBUG: print(('mbAbs ', absPosition, c_float(absPosition)))\n        if not self.Connected:\n            raise Exception('Please connect first! Use initializeHardwareDevice')\n        if (absPosition < self.getPos()):\n            if DEBUG: print(('backlash mAbs', absPosition - self.blCorr))\n            self.mAbs(absPosition-self.blCorr)\n        self.mAbs(absPosition)\n        if DEBUG: print('mbAbs SUCCESS')\n        return True\n\n        ''' Miscelaneous '''\n    def identify(self):\n        '''\n        Causes the motor to blink the Active LED\n        '''\n        self.aptdll.MOT_Identify(self.SerialNum)\n        return True\n\n    def cleanUpAPT(self):\n        '''\n        Releases the APT object\n        Use when exiting the program\n        '''\n        self.aptdll.APTCleanUp()\n        if DEBUG: print('APT cleaned up')\n        self.Connected = False\n\n\n    def stopMove(self):\n        if DEBUG: print((\"Stopping stage:{}\".format(self.SerialNum)))\n        if not self.Connected:\n            raise Exception(\"Not connected to the stage\")\n        else:\n            self.aptdll.MOT_StopProfiled(self.SerialNum)\n            if DEBUG: print(\"Stopped\")\n            return",
  "def __init__(self, SerialNum=None, HWTYPE=31,blacklash_correction=0.10,minimum_velocity=0.0,acceleration=5.0,max_velocity=10.0):\n        '''\n        HWTYPE_BSC001\t\t11\t// 1 Ch benchtop stepper driver\n        HWTYPE_BSC101\t\t12\t// 1 Ch benchtop stepper driver\n        HWTYPE_BSC002\t\t13\t// 2 Ch benchtop stepper driver\n        HWTYPE_BDC101\t\t14\t// 1 Ch benchtop DC servo driver\n        HWTYPE_SCC001\t\t21\t// 1 Ch stepper driver card (used within BSC102,103 units)\n        HWTYPE_DCC001\t\t22\t// 1 Ch DC servo driver card (used within BDC102,103 units)\n        HWTYPE_ODC001\t\t24\t// 1 Ch DC servo driver cube\n        HWTYPE_OST001\t\t25\t// 1 Ch stepper driver cube\n        HWTYPE_MST601\t\t26\t// 2 Ch modular stepper driver module\n        HWTYPE_TST001\t\t29\t// 1 Ch Stepper driver T-Cube\n        HWTYPE_TDC001\t\t31\t// 1 Ch DC servo driver T-Cube\n        HWTYPE_LTSXXX\t\t42\t// LTS300/LTS150 Long Travel Integrated Driver/Stages\n        HWTYPE_L490MZ\t\t43\t// L490MZ Integrated Driver/Labjack\n        HWTYPE_BBD10X\t\t44\t// 1/2/3 Ch benchtop brushless DC servo driver\n        '''\n        self.Connected = False\n\n        self.aptdll = windll.LoadLibrary(DLL_PATH)\n\n        self.aptdll.EnableEventDlg(True)\n        self.aptdll.APTInit()\n        #print 'APT initialized'\n        self.HWType = c_long(HWTYPE)\n        self.blCorr = blacklash_correction #100um backlash correction\n        if SerialNum is not None:\n            if DEBUG: print((\"Serial is\", SerialNum))\n            self.SerialNum = c_long(SerialNum)\n            self.initializeHardwareDevice()\n        # TODO : Error reporting to know if initialisation went sucessfully or not.\n\n        else:\n            if DEBUG: print(\"No serial, please setSerialNumber\")\n\n        self.setVelocityParameters(minVel=minimum_velocity, acc=acceleration, maxVel=max_velocity)",
  "def getNumberOfHardwareUnits(self):\n        '''\n        Returns the number of HW units connected that are available to be interfaced\n        '''\n        numUnits = c_long()\n        self.aptdll.GetNumHWUnitsEx(self.HWType, pointer(numUnits))\n        return numUnits.value",
  "def getSerialNumberByIdx(self, index):\n        '''\n        Returns the Serial Number of the specified index\n        '''\n        HWSerialNum = c_long()\n        hardwareIndex = c_long(index)\n        self.aptdll.GetHWSerialNumEx(self.HWType, hardwareIndex, pointer(HWSerialNum))\n        return HWSerialNum",
  "def setSerialNumber(self, SerialNum):\n        '''\n        Sets the Serial Number of the specified index\n        '''\n        if DEBUG: print((\"Serial is\", SerialNum))\n        self.SerialNum = c_long(SerialNum)\n        return self.SerialNum.value",
  "def initializeHardwareDevice(self):\n        '''\n        Initialises the motor.\n        You can only get the position of the motor and move the motor after it has been initialised.\n        Once initiallised, it will not respond to other objects trying to control it, until released.\n        '''\n        if DEBUG: print(('initializeHardwareDevice serial', self.SerialNum))\n        result = self.aptdll.InitHWDevice(self.SerialNum)\n\n        if result == 0:\n            self.Connected = True\n            if DEBUG: print('initializeHardwareDevice connection SUCESS')\n        # need some kind of error reporting here\n        else:\n            raise Exception('Connection Failed. Check Serial Number!')\n        return True\n\n        ''' Interfacing with the motor settings '''",
  "def getHardwareInformation(self):\n        model = c_buffer(255)\n        softwareVersion = c_buffer(255)\n        hardwareNotes = c_buffer(255)\n        self.aptdll.GetHWInfo(self.SerialNum, model, 255, softwareVersion, 255, hardwareNotes, 255)\n        hwinfo = [model.value, softwareVersion.value, hardwareNotes.value]\n        return hwinfo",
  "def getStageAxisInformation(self):\n        minimumPosition = c_float()\n        maximumPosition = c_float()\n        units = c_long()\n        pitch = c_float()\n        self.aptdll.MOT_GetStageAxisInfo(self.SerialNum, pointer(minimumPosition), pointer(maximumPosition), pointer(units), pointer(pitch))\n        stageAxisInformation = [minimumPosition.value, maximumPosition.value, units.value, pitch.value]\n        return stageAxisInformation",
  "def setStageAxisInformation(self, minimumPosition, maximumPosition):\n        minimumPosition = c_float(minimumPosition)\n        maximumPosition = c_float(maximumPosition)\n        units = c_long(1) #units of mm\n        # Get different pitches of lead screw for moving stages for different stages.\n        pitch = c_float(self.config.get_pitch())\n        self.aptdll.MOT_SetStageAxisInfo(self.SerialNum, minimumPosition, maximumPosition, units, pitch)\n        return True",
  "def getHardwareLimitSwitches(self):\n        reverseLimitSwitch = c_long()\n        forwardLimitSwitch = c_long()\n        self.aptdll.MOT_GetHWLimSwitches(self.SerialNum, pointer(reverseLimitSwitch), pointer(forwardLimitSwitch))\n        hardwareLimitSwitches = [reverseLimitSwitch.value, forwardLimitSwitch.value]\n        return hardwareLimitSwitches",
  "def getVelocityParameters(self):\n        minimumVelocity = c_float()\n        acceleration = c_float()\n        maximumVelocity = c_float()\n        self.aptdll.MOT_GetVelParams(self.SerialNum, pointer(minimumVelocity), pointer(acceleration), pointer(maximumVelocity))\n        velocityParameters = [minimumVelocity.value, acceleration.value, maximumVelocity.value]\n        return velocityParameters",
  "def getVel(self):\n        if DEBUG: print('getVel probing...')\n        minVel, acc, maxVel = self.getVelocityParameters()\n        if DEBUG: print('getVel maxVel')\n        return maxVel",
  "def setVelocityParameters(self, minVel, acc, maxVel):\n        minimumVelocity = c_float(minVel)\n        acceleration = c_float(acc)\n        maximumVelocity = c_float(maxVel)\n        self.aptdll.MOT_SetVelParams(self.SerialNum, minimumVelocity, acceleration, maximumVelocity)\n        return True",
  "def setVel(self, maxVel):\n        if DEBUG: print(('setVel', maxVel))\n        minVel, acc, oldVel = self.getVelocityParameters()\n        self.setVelocityParameters(minVel, acc, maxVel)\n        return True",
  "def getVelocityParameterLimits(self):\n        maximumAcceleration = c_float()\n        maximumVelocity = c_float()\n        self.aptdll.MOT_GetVelParamLimits(self.SerialNum, pointer(maximumAcceleration), pointer(maximumVelocity))\n        velocityParameterLimits = [maximumAcceleration.value, maximumVelocity.value]\n        return velocityParameterLimits\n\n        '''\n        Controlling the motors\n        m = move\n        c = controlled velocity\n        b = backlash correction\n\n        Rel = relative distance from current position.\n        Abs = absolute position\n        '''",
  "def getPos(self):\n        '''\n        Obtain the current absolute position of the stage\n        '''\n        if DEBUG: print('getPos probing...')\n        if not self.Connected:\n            raise Exception('Please connect first! Use initializeHardwareDevice')\n\n        position = c_float()\n        self.aptdll.MOT_GetPosition(self.SerialNum, pointer(position))\n        if DEBUG: print(('getPos ', position.value))\n        return position.value",
  "def mRel(self, relDistance):\n        '''\n        Moves the motor a relative distance specified\n        relDistance    float     Relative position desired\n        '''\n        if DEBUG: print(('mRel ', relDistance, c_float(relDistance)))\n        if not self.Connected:\n            print('Please connect first! Use initializeHardwareDevice')\n            #raise Exception('Please connect first! Use initializeHardwareDevice')\n        relativeDistance = c_float(relDistance)\n        self.aptdll.MOT_MoveRelativeEx(self.SerialNum, relativeDistance, True)\n        if DEBUG: print('mRel SUCESS')\n        return True",
  "def mAbs(self, absPosition):\n        '''\n        Moves the motor to the Absolute position specified\n        absPosition    float     Position desired\n        '''\n        if DEBUG: print(('mAbs ', absPosition, c_float(absPosition)))\n        if not self.Connected:\n            raise Exception('Please connect first! Use initializeHardwareDevice')\n        absolutePosition = c_float(absPosition)\n        self.aptdll.MOT_MoveAbsoluteEx(self.SerialNum, absolutePosition, True)\n        if DEBUG: print('mAbs SUCESS')\n        return True",
  "def mcRel(self, relDistance, moveVel=0.5):\n        '''\n        Moves the motor a relative distance specified at a controlled velocity\n        relDistance    float     Relative position desired\n        moveVel        float     Motor velocity, mm/sec\n        '''\n        if DEBUG: print(('mcRel ', relDistance, c_float(relDistance), 'mVel', moveVel))\n        if not self.Connected:\n            raise Exception('Please connect first! Use initializeHardwareDevice')\n        # Save velocities to reset after move\n        maxVel = self.getVel()\n        # Set new desired max velocity\n        self.setVel(moveVel)\n        self.mRel(relDistance)\n        self.setVel(maxVel)\n        if DEBUG: print('mcRel SUCESS')\n        return True",
  "def mcAbs(self, absPosition, moveVel=0.5):\n        '''\n        Moves the motor to the Absolute position specified at a controlled velocity\n        absPosition    float     Position desired\n        moveVel        float     Motor velocity, mm/sec\n        '''\n        if DEBUG: print(('mcAbs ', absPosition, c_float(absPosition), 'mVel', moveVel))\n        if not self.Connected:\n            raise Exception('Please connect first! Use initializeHardwareDevice')\n        # Save velocities to reset after move\n        minVel, acc, maxVel = self.getVelocityParameters()\n        # Set new desired max velocity\n        self.setVel(moveVel)\n        self.mAbs(absPosition)\n        self.setVel(maxVel)\n        if DEBUG: print('mcAbs SUCESS')\n        return True",
  "def mbRel(self, relDistance):\n        '''\n        Moves the motor a relative distance specified\n        relDistance    float     Relative position desired\n        '''\n        if DEBUG: print(('mbRel ', relDistance, c_float(relDistance)))\n        if not self.Connected:\n            print('Please connect first! Use initializeHardwareDevice')\n            #raise Exception('Please connect first! Use initializeHardwareDevice')\n        self.mRel(relDistance-self.blCorr)\n        self.mRel(self.blCorr)\n        if DEBUG: print('mbRel SUCCESS')\n        return True",
  "def mbAbs(self, absPosition):\n        '''\n        Moves the motor to the Absolute position specified\n        absPosition    float     Position desired\n        '''\n        if DEBUG: print(('mbAbs ', absPosition, c_float(absPosition)))\n        if not self.Connected:\n            raise Exception('Please connect first! Use initializeHardwareDevice')\n        if (absPosition < self.getPos()):\n            if DEBUG: print(('backlash mAbs', absPosition - self.blCorr))\n            self.mAbs(absPosition-self.blCorr)\n        self.mAbs(absPosition)\n        if DEBUG: print('mbAbs SUCCESS')\n        return True\n\n        ''' Miscelaneous '''",
  "def identify(self):\n        '''\n        Causes the motor to blink the Active LED\n        '''\n        self.aptdll.MOT_Identify(self.SerialNum)\n        return True",
  "def cleanUpAPT(self):\n        '''\n        Releases the APT object\n        Use when exiting the program\n        '''\n        self.aptdll.APTCleanUp()\n        if DEBUG: print('APT cleaned up')\n        self.Connected = False",
  "def stopMove(self):\n        if DEBUG: print((\"Stopping stage:{}\".format(self.SerialNum)))\n        if not self.Connected:\n            raise Exception(\"Not connected to the stage\")\n        else:\n            self.aptdll.MOT_StopProfiled(self.SerialNum)\n            if DEBUG: print(\"Stopped\")\n            return",
  "class APT_parameter(NotifiedProperty):\n    \"\"\"A quick way of creating a property that alters an apt parameter.\n\n    NB the property will be read immediately after it's written, to ensure\n    that the value we send to any listening controls/indicators is correct\n    (otherwise we'd send them the value that was requested, even if it was\n    not valid).  This behaviour can be disabled by setting read_back to False\n    in the constructor.\n    \"\"\"\n\n    def __init__(self, parameter_name, doc=None, read_back=True):\n        \"\"\"Create a property that reads and writes the given parameter.\n\n        This internally uses the `get_camera_parameter` and\n        `set_camera_parameter` methods, so make sure you override them.\n        \"\"\"\n        if doc is None:\n            doc = \"Adjust the camera parameter '{0}'\".format(parameter_name)\n        super(APT_parameter, self).__init__(fget=self.fget,\n                                            fset=self.fset,\n                                            doc=doc,\n                                            read_back=read_back)\n        self.parameter_name = parameter_name\n\n    def fget(self, obj):\n        return obj.get_APT_parameter(self.parameter_name)\n\n    def fset(self, obj, value):\n        obj.set_APT_parameter(self.parameter_name, value)",
  "class APT_VCP_motor(APT_VCP, Stage):\n    \"\"\"\n    This class handles all the basic communication with APT virtual com for motors\n    \"\"\"\n\n    axis_names = ('x', )\n    def __init__(self, port=None, source=0x01, destination=None,\n                 use_si_units=False, stay_alive = False, unit = 'm',**kwargs):\n        \"\"\"\n        Set up the serial port, setting source and destinations, and hardware info.\n        \"\"\"\n        APT_VCP.__init__(self, port=port, source=source, destination=destination,\n                         use_si_units=use_si_units, stay_alive=stay_alive)  # this opens the port\n        Stage.__init__(self,unit = unit)\n        if self.model[1] in DC_status_motors:\n            # Set the bit mask for DC controllers\n            self.status_bit_mask = np.array([[0x00000001, 'forward hardware limit switch is active'],\n                                             [0x00000002, 'reverse hardware limit switch is active'],\n                                             [0x00000010, 'in motion, moving forward'],\n                                             [0x00000020, 'in motion, moving reverse'],\n                                             [0x00000040, 'in motion, jogging forward'],\n                                             [0x00000080, 'in motion, jogging reverse'],\n                                             [0x00000200, 'in motion, homing'],\n                                             [0x00000400, 'homed (homing has been completed)'],\n                                             [0x00001000, 'tracking'],\n                                             [0x00002000, 'settled'],\n                                             [0x00004000, 'motion error (excessive position error)'],\n                                             [0x01000000, 'motor current limit reached'],\n                                             [0x80000000, 'channel is enabled']])\n            self.velocity_scaling_factor = 204.8  # for converting velocity to mm/sec\n        else:\n            # Set the bit mask for normal motor controllers\n            self.status_bit_mask = np.array([[0x00000001, 'forward (CW) hardware limit switch is active'],\n                                    [0x00000002, 'reverse (CCW) hardware limit switch is active'],\n                                    [0x00000004, 'forward (CW) software limit switch is active'],\n                                    [0x00000008, 'reverse (CCW) software limit switch is active'],\n                                    [0x00000010, 'in motion, moving forward (CW)'],\n                                    [0x00000020, 'in motion, moving reverse (CCW)'],\n                                    [0x00000040, 'in motion, jogging forward (CW)'],\n                                    [0x00000080, 'in motion, jogging reverse (CCW)'],\n                                    [0x00000100, 'motor connected'],\n                                    [0x00000200, 'in motion, homing'],\n                                    [0x00000400, 'homed (homing has been completed)'],\n                                    [0x00001000, 'interlock state (1 = enabled)']])\n\n            # delattr(self, 'get_qt_ui')\n        if type(destination) != dict and len(self.destination)==1:\n            self.destination = {'x': destination}\n        \n        else:\n            self.axis_names = tuple(destination.keys())\n            self.destination = destination\n        \n        self.make_all_parameters()\n        self._recusive_move_num = 0\n\n    '''MOVEMENT'''\n\n#    def _waitForReply(self, msgCode, replysize):\n#        self.write(msgCode)\n#        reply = self.ser.read(replysize)\n#        t0 = time.time()\n#        while len(reply) == replysize:\n#            reply = self.ser.read(replysize)\n#            time.sleep(0.1)\n#            if time.time() - t0 > 30:\n#                return False\n#        return True\n\n    def _waitFinishMove(self,axis = None,debug=False):\n        \"\"\"A simple function to force movement to block the console \"\"\"\n        if axis is None:\n            destination_ids = list(self.destination.keys())\n        else:\n            destination_ids = [axis]\n        for dest in destination_ids:\n            status = self.get_status_update(axis=dest)\n            if debug > 0 or DEBUG:\n                print(status)\n            \n            while any(['in motion' in x[1] for x in status]):\n                time.sleep(0.1)\n                status = self.get_status_update(axis = dest)\n\n    def home(self,axis = None):\n        \"\"\"Rehome the stage with an axis input \"\"\"\n        if axis == None:\n            destination_ids = self.axis_names\n        else:\n            destination_ids = tuple(axis)\n        for dest in destination_ids:\n            self.write(0x0443, destination_id = dest)\n    #        self._waitForReply(0x0444, 6)\n            self._waitFinishMove()\n\n    def move(self, pos, axis=None, relative=False, channel_number=None, block=True):\n        \"\"\" Move command allowing specification of axis, \n        relative, channel and if we want the function to be blocking\"\"\"\n        if channel_number is None:\n            channel_number = 1\n        if not hasattr(pos, '__iter__'):\n            pos = [pos]\n        elif type(pos)==tuple:\n            pos = list(pos)\n        if axis is None:\n            if len(pos)==len(self.axis_names):\n                axes = self.axis_names\n            else:\n                self._logger.warn('What axis shall I move?')\n        else:\n            axes = tuple(axis)\n        #create list of positions for each axis\n        pos_list = [0]*len(self.axis_names)\n        for i,axis  in enumerate(axes):\n            axis_number = np.where(np.array(self.axis_names)==[axis])[0][0]\n            pos_list[axis_number] = pos[i]\n        pos = pos_list\n        for axis in axes:\n            axis_number = np.where(np.array(self.axis_names)==[axis])[0][0]\n            if relative:\n                pos[axis_number] = self.position[axis_number]+pos[axis_number]\n\n            pos_in_counts = int(np.round(self.convert(pos[axis_number],'position','counts'),decimals = 0))\n            data = bytearray(struct.pack('<HL', self.channel_number_to_identity[channel_number], pos_in_counts))\n            try:\n                self.write(0x0453, data=data,destination_id=axis)\n                if block ==True:\n                    self._waitFinishMove()\n            except struct.error as e:\n                self.log('Move failed with '+str(e),'warning')\n                self._recusive_move_num+=1\n                if self._recusive_move_num>10:\n                    self._recusive_move_num = 0\n                    raise Exception('Stage move failed!')\n                self.move(pos[axis_number],axis=axis,channel_number=channel_number,block = block)\n            self._recusive_move_num = 0\n            axis_number += 1\n\n\n    '''PARAMETERS'''\n\n\n    def get_status_update(self, channel_number=1,axis = None):\n        if self.model[1] in DC_status_motors:\n            returned_message = self.query(0x0490, param1=self.channel_number_to_identity[channel_number],destination_id = axis)\n        else:\n            returned_message = self.query(0x0480, param1=self.channel_number_to_identity[channel_number],destination_id = axis)\n        return self.update_status(returned_message['data'])\n\n    def update_status(self, returned_message,debug=False):\n        '''This command should update device properties from the update message\n            however this has to be defined for every device as the status update format\n            and commands vary,\n            please implement me\n            Args:\n                The returned message from a status update request           (dict)\n        '''\n        if debug > 0 or DEBUG == True:\n            N = len(returned_message)\n            print(\"returned_message length:\",N)\n        if self.model[1] in DC_status_motors:\n            channel, position, velocity, Reserved, status_bits = struct.unpack(r'<HLHHI', returned_message)\n            #HLHHI\n            #H - 2, L - 4, I - 4\n            # self.position = position\n            # self.velocity = velocity / self.velocity_scaling_factor\n        else:\n            \n            channel, position, EncCnt,status_bits, ChanIdent2,_,_,_ = struct.unpack(r'<HILIHLLL', returned_message)\n            # print \"Status bits\",status_bits\n            # print \"self.status_bit_mask\",self.status_bit_mask[:, 0]\n        bitmask = self._bit_mask_array(status_bits, [int(i) for i in self.status_bit_mask[:, 0]])\n        self.status = self.status_bit_mask[np.where(bitmask)]\n        if debug > 0 or DEBUG == True:\n            print(self.status)\n        return self.status\n\n\n    def init_no_flash_programming(self):\n        \"\"\" This message must be sent on startup to tell the controller\n        the source and destination address - The manual says this MUST be\n        sent as part of the intialisation process\n\n        Labled as: MGMSG_HW_NO_FLASH_PROGRAMMING\n        \"\"\"\n        self.write(0x0018)\n\n    def get_position(self, axis = None,channel_number=1):\n        '''Sets/Gets the live position count in the controller\n            generally this should not be used to set the position\n            instead the controller should determine its own position\n            by performing a homing manoeuvre\n            Args:\n                postion:    (float) this is the real position value\n                            which is then converted to APT units within the setter\n                channel_number:     (int) This defaults to 1\n        '''\n        if axis is None:\n            return np.array(([self.get_position(axis) for axis in self.axis_names]))\n        else:\n            if axis not in self.axis_names:\n                raise ValueError(\"{0} is not a valid axis, must be one of {1}\".format(axis, self.axis_names))\n                \n            returned_message = self.query(0x0411, param1=self.channel_number_to_identity[channel_number],\n                                          destination_id = axis)\n            data = returned_message['data']\n            channel_id, position = struct.unpack(r'<HL', data)\n        # position = self.convert_to_SI_position(position)\n            return self.convert(position,'counts','position')\n\n    def set_position(self, position, channel_number=1,axis = None):\n        # position = self.convert_to_APT_position(position)\n        data = bytearray(struct.pack('<HL', self.channel_number_to_identity[channel_number], position))\n        self.write(0x0410, data=data,destination_id = axis)\n\n    position = property(get_position, set_position)\n\n\n    def convert(self, value, from_, to_):\n        print('Not doing anything from ', from_, ' to ', to_)\n        return value\n\n    def make_parameter(self, param_dict, destination_id = None):\n        \"\"\"Makes a parameter dictionary and sets it as a property\n\n        All parameters in the Thorlabs APT basically require the same command structure, so this function wraps any\n        parameter creation to simplify the code. It takes a dictionary containing the name of the parameter you want to\n        make, which will be used to create a property attribute by that name and a getter and a setter. The dictionary\n        should also containg the getter and setter command codes, and the structure of the data that is passed in the\n        getter and setter. Finally the dictionary should contain the names of each of the sub_parameters given by the\n        setter and getter, whose values can be converted into normal units by overwriting the self.convert() function\n\n        Examples:\n            Make self.velocity_params property, together with a self.get_velocity_params and self.set_velocity_params\n            functions. self.velocity_params will be a dictionary, containing 'channel_num', 'min_velocity',\n            'acceleration' and 'max_velocity'. The velocities will be converted into velocity through the convert\n            function and the acceleration will be converted into acceleration.\n\n                >>> self.make_parameter(dict(name='velocity_params', set=0x0413, get=0x0414, structure='HLLL',\n                >>>                     param_names=['channel_num', ['min_velocity', 'velocity'],\n                >>>                                 ['acceleration', 'acceleration'], ['max_velocity', 'velocity']]))\n\n\n        Args:\n            param_dict:\n                name        :   internal name that you want the parameter to have\n                set         :   setter function\n                get         :   getter function\n                structure   :   binary structure of the data packets\n                param_names :   names of the parameters in the structure\n\n        Returns:\n\n        \"\"\"\n\n        def getter(selfie, channel_number=1):\n            returned_message = selfie.query(param_dict['get'], param1=selfie.channel_number_to_identity[channel_number],destination_id = destination_id)\n            data = returned_message['data']\n            data = struct.unpack('<' + param_dict['structure'], data)\n            params = {}\n            index = 0\n            for name in param_dict['param_names']:\n                if type(name) == str:\n                    params[name] = data[index]\n                elif type(name) == list:\n                    params[name[0]] = selfie.convert(data[index], 'counts', name[1])\n                index += 1\n            return params\n\n        def setter(selfie, params, channel_number=None):\n            if channel_number is None:\n                channel_number = params['channel_num']\n            unstructured_data = ['<' + param_dict['structure'],\n                                 selfie.channel_number_to_identity[channel_number]]\n            for name in param_dict['param_names']:\n                if name != 'channel_num':\n                    if type(name) == str:\n                        unstructured_data += [params[name]]\n                    elif type(name) == list:\n                        unstructured_data += [selfie.convert(params[name[0]], name[1], 'counts')]\n            data = struct.pack(*unstructured_data)\n            selfie.write(param_dict['set'], data=data, destination_id=destination_id )\n\n        setattr(self, 'get_' + param_dict['name'], types.MethodType(getter, self))\n        setattr(self, 'set_' + param_dict['name'], types.MethodType(setter, self))\n        try:\n            setattr(self, param_dict['name'], property('get_' + param_dict['name'], 'set_' + param_dict['name']))\n        except AttributeError:\n            print(param_dict['name'], ' already exists')\n\n    def make_all_parameters(self):\n        # TODO: add all the documentation for each of these parameters\n        for axis in self.destination:\n            self.make_parameter(dict(name=axis+'_encoder_counts', set=0x0409, get=0x040A, structure='HL', param_names=['channel_num', 'encoder_counts']),destination_id=axis)\n            # self.make_parameter(dict(name='position', set=0x0410, get=0x0411, structure='HL', param_names=['channel_num', ['position', 'distance']]))\n            self.make_parameter(dict(name=axis+'_velocity_params', set=0x0413, get=0x0414, structure='HLLL',\n                                     param_names=['channel_num', ['min_velocity', 'velocity'],\n                                                  ['acceleration', 'acceleration'], ['max_velocity', 'velocity']]),destination_id=axis)\n            self.make_parameter(dict(name=axis+'_jog_params', set=0x0416, get=0x0417, structure='HHLLLLH',\n                                     param_names=['channel_num', ['jog_step_size', 'distance'],\n                                                  ['jog_min_velocity', 'velocity'], ['jog_acceleration', 'acceleration'],\n                                                  ['jog_max_velocity', 'velocity'], 'jog_stop_mode']),destination_id=axis)\n            self.make_parameter(dict(name=axis+'_gen_move_params', set=0x043C, get=0x043B, structure='HL',\n                                     param_names=['channel_num', 'backlash']),destination_id = axis)\n            self.make_parameter(dict(name=axis+'_power_params', set=0x0426, get=0x0427, structure='HHH',\n                                     param_names=['channel_num', 'RestPower', 'MovePower']),destination_id = axis)\n            self.make_parameter(dict(name=axis+'_move_rel_params', set=0x0446, get=0x0447, structure='HL',\n                                     param_names=['channel_num', 'rel_dist']),destination_id = axis)\n            self.make_parameter(dict(name=axis+'_move_abs_params', set=0x0451, get=0x0452, structure='HL',\n                                     param_names=['channel_num', 'abs_dist']),destination_id = axis)\n            self.make_parameter(dict(name=axis+'_home_params', set=0x0441, get=0x0442, structure='HHHLL',\n                                     param_names=['channel_num', 'direction', 'limit_switch', 'velocity', 'offset']),destination_id=axis)",
  "class DC_APT(APT_VCP_motor):\n    #The different EncCnt (calibrations) for the different stage types\n    DC_stages_EncCnt = {'MTS':34304.0,\n             'PRM':1919.64*1E3,\n             'Z8':34304.0,\n             'Z6':24600,\n             'DDSM100':2000,\n             'DDS':20000,\n             'MLS' : 20000\n             }\n    def __init__(self,  port=None, source=0x01, destination=None,use_si_units=True,unit = 'm',\n                 stay_alive=True, stage_type = None):\n        \"\"\"\n        Pass all of the correct arguments to APT_VCP_motor for the DC stages and create converters.\n        \"\"\"\n        APT_VCP_motor.__init__(self, port=port, source=source, destination=destination,\n                         use_si_units=True,unit = unit, stay_alive=stay_alive)  # this opens the port\n        #Setup up conversion factors\n        if self.model[1] == 'BBD102/BBD103': #Once the TBD001 controller is added it needs to be added here\n            self.t_constant = 102.4E-6\n        elif self.model[1] in ['TDC001', 'KDCT101']:\n            self.t_constant = 2048.0/(6.0E6)\n        else:\n            self.t_constant = None\n        \n        if stage_type != None:\n            try:\n                self.EncCnt = float(self.DC_stages_EncCnt[stage_type])\n            except KeyError:\n                self.EncCnt = None\n                self._logger.warn('The stage type suggested is not listed and therefore a calibration cannot be set')\n        else:\n            self.EncCnt = None    \n            \n    def convert(self, value, from_, to_):\n        if None in (self.EncCnt,self.t_constant):\n            self._logger.warn('Conversion impossible: one of the constants has not been implemented')\n            return value\n        if from_ == 'counts':\n            return self.counts_to[to_](self,value)\n        elif to_ == 'counts':\n            return self.si_to[from_](self,value)\n        else:\n            self._logger.warn(('Converting %s to %s is not possible!, returning raw value'%(from_, to_))) \n            return value\n\n    def counts_to_pos(self,counts):\n        return (counts/self.EncCnt)*1E3\n    def pos_to_counts(self,pos):\n        return (pos*self.EncCnt/1E3)\n    \n    def counts_to_vel(self,counts):\n        return (counts/(self.EncCnt*self.t_constant*65536))*1E3\n    def vel_to_counts(self,vel):\n        return (vel*65536*self.t_constant*self.EncCnt/1E3)\n        \n    def counts_to_acc(self,counts):\n        return (counts/(self.EncCnt*self.t_constant**2*65536))*1E3\n    def acc_to_counts(self,acc):\n        return (self.EncCnt*self.t_constant**2*65536*acc/1E3)\n    def move_step(self,axis,direction):\n        self.move_rel(self.stepsize*direction,axis)\n    def _waitFinishMove(self,axis = None,debug=False):\n        \"\"\"A simple function to force movement to block the console \"\"\"\n        if axis == None:\n            destination_ids = list(self.destination.keys())\n        else:\n            destination_ids = [axis]\n        for dest in destination_ids:\n            status = self.get_status_update(axis = dest)# \\ # and all([not x[1].endswith('homing') for x in status])\\\n            while any(['in motion' in x[1] for x in status]):\n \n                time.sleep(0.1)\n                status = self.get_status_update(axis = dest)\n                if debug > 0 or DEBUG:\n                    print(status)\n    def home(self,axis = None):\n        \"\"\"Rehome the stage with an axis input \"\"\"\n        if axis == None:\n            destination_ids = self.axis_names\n        else:\n            destination_ids = tuple(axis)\n        for dest in destination_ids:\n            self.write(0x0443,destination_id = dest)\n            self._waitForReply()\n            self._waitFinishMove()\n    counts_to = {'position' : counts_to_pos,\n                 'velocity' : counts_to_vel,\n                 'acceleration' : counts_to_acc}\n    si_to = {'position' : pos_to_counts,\n             'velocity' : vel_to_counts,\n             'acceleration' : acc_to_counts}",
  "class Stepper_APT_std(APT_VCP_motor):\n    #The different EncCnt (calibrations) for the different stage types is microstep/mm\n    stepper_stages_EncCnt = {'DRV001':51200,\n             'DRV013':25600,\n             'DRV014':25600,\n             'NRT':25600,\n             'LTS':25600,\n             'DRV':20480,\n             'FW' : 71,\n             'NR' : 4693,\n             }\n    def __init__(self,  port=None, source=0x01, destination=None,use_si_units=True, stay_alive=True, stage_type = None):\n        \"\"\"\n        Pass all of the correct arguments to APT_VCP_motor for the standard stepper controllers\n        stages and create converters.\n        \"\"\"\n        APT_VCP_motor.__init__(self, port=port, source=source, destination=destination,\n                         use_si_units=True, stay_alive=stay_alive)  # this opens the port\n        #Setup up conversion factors\n        \n        if stage_type != None:\n            try:\n                self.EncCnt = float(self.stepper_stages_EncCnt[stage_type])\n            except KeyError:\n                self.EncCnt = None\n                self._logger.warn('The stage type suggested is not listed and therefore a calibration cannot be set')\n        else:\n            self.EncCnt = None\n                \n            \n    def convert(self, value, from_, to_):\n        if self.EncCnt==None:\n            self._logger.warn('Conversion impossible: one of the constants has not been implemented')\n            return value\n        if from_ == 'counts':\n            return self.counts_to_si(value)\n        elif to_ == 'counts':\n            return self.si_to_counts(value)\n        else:\n            self._logger.warn(('Converting %s to %s is not possible!, returning raw value'%(from_, to_))) \n            return value\n\n    def counts_to_si(self,counts):\n        return (counts/self.EncCnt)*1E3\n    def si_to_counts(self,pos):\n        return (pos*self.EncCnt/1E3)",
  "class Stepper_APT_trinamics(APT_VCP_motor):\n    #The different EncCnt (calibrations) for the different stage types is microstep/mm\n    stepper_stages_EncCnt = {'DRV001':819200,\n             'DRV013':409600,\n             'DRV014':409600,\n             'NRT':409600,\n             'LTS':409600,\n             'MLJ':409600,\n             'DRV':327680,\n             'FW' : 1138,\n             'NR' : 75091,\n             }\n    def __init__(self,  port=None, source=0x01, destination=None,use_si_units=True, stay_alive=True, stage_type = None):\n        \"\"\"\n        Pass all of the correct arguments to APT_VCP_motor for the Trinamics stepper controllers\n        stages and create converters.\n        \"\"\"\n        APT_VCP_motor.__init__(self, port=port, source=source, destination=destination,\n                         use_si_units=True, stay_alive=stay_alive)  # this opens the port\n        #Setup up conversion factors\n        if stage_type!= None:\n            try:\n                self.EncCnt = float(self.stepper_stages_EncCnt[stage_type])\n            except KeyError:\n                self.EncCnt = None\n                self._logger.warn('The stage type suggested is not listed and therefore a calibration cannot be set')\n        else:\n            self.EncCnt = None\n                \n            \n    def convert(self, value, from_, to_):\n        if None in (self.EncCnt,self.t_constant):\n            self._logger.warn('Conversion impossible: one of the constants has not been implemented')\n            return value\n        if from_ == 'counts':\n            return self.counts_to[to_](self,value)\n        elif to_ == 'counts':\n            return self.si_to[from_](self,value)\n        else:\n            self._logger.warn(('Converting %s to %s is not possible!, returning raw value'%(from_, to_))) \n            return value\n\n    def counts_to_pos(self,counts):\n        return old_div(counts,self.EncCnt)*1E3\n    def pos_to_counts(self,pos):\n        return old_div(pos*self.EncCnt,1E3)\n    \n    def counts_to_vel(self,counts):\n        return old_div(counts,(self.EncCnt*53.68))*1E3\n    def vel_to_counts(self,vel):\n        return old_div(vel*53.68*self.EncCnt,1E3)\n        \n    def counts_to_acc(self,counts):\n        return old_div(counts,(self.EncCnt/90.9))*1E3\n    def acc_to_counts(self,acc):\n        return old_div(self.EncCnt/90.9*acc,1E3)\n        \n    counts_to = {'position' : counts_to_pos,\n                 'velocity' : counts_to_vel,\n                 'acceleration' : counts_to_acc}\n    si_to = {'position' : pos_to_counts,\n             'velocity' : vel_to_counts,\n             'acceleration' : acc_to_counts}",
  "class MFF102(APT_VCP_motor):\n    \n    def jog_forward(self): # 1 -> 0 (blame thorlabs)\n        self._write(0x046A, param2=0x01)\n        self._waitFinishMove()\n        \n    def jog_backward(self): # 0 -> 1\n        self._write(0x046A, param2=0x02)\n        self._waitFinishMove()\n    \n    def get_status_bits(self):\n        data = self.query(0x0429, blocking=True)['data']\n        status_bits = struct.unpack(r'3h', data)\n        return status_bits\n    \n    def get_position(self):\n        return self.get_status_bits()[1] - 1\n        \n    def set_position(self, val):\n        if (pos := self.position) > val:\n            self.jog_forward()\n        elif pos < val:\n            self.jog_backward()\n    position = NotifiedProperty(get_position, set_position)\n    \n    def toggle(self):\n        self.position = not self.position    \n        \n    def home(self):\n        self.set_position(0)\n        \n    def _waitFinishMove(self):\n        pass\n    def get_qt_ui(self):\n        return FlipperUI(self)",
  "class FlipperUI(QuickControlBox):\n    def __init__(self, instr):\n        super().__init__()\n        self.instr = instr\n        self.add_checkbox('position')\n        self.auto_connect_by_name(controlled_object=instr)",
  "def __init__(self, parameter_name, doc=None, read_back=True):\n        \"\"\"Create a property that reads and writes the given parameter.\n\n        This internally uses the `get_camera_parameter` and\n        `set_camera_parameter` methods, so make sure you override them.\n        \"\"\"\n        if doc is None:\n            doc = \"Adjust the camera parameter '{0}'\".format(parameter_name)\n        super(APT_parameter, self).__init__(fget=self.fget,\n                                            fset=self.fset,\n                                            doc=doc,\n                                            read_back=read_back)\n        self.parameter_name = parameter_name",
  "def fget(self, obj):\n        return obj.get_APT_parameter(self.parameter_name)",
  "def fset(self, obj, value):\n        obj.set_APT_parameter(self.parameter_name, value)",
  "def __init__(self, port=None, source=0x01, destination=None,\n                 use_si_units=False, stay_alive = False, unit = 'm',**kwargs):\n        \"\"\"\n        Set up the serial port, setting source and destinations, and hardware info.\n        \"\"\"\n        APT_VCP.__init__(self, port=port, source=source, destination=destination,\n                         use_si_units=use_si_units, stay_alive=stay_alive)  # this opens the port\n        Stage.__init__(self,unit = unit)\n        if self.model[1] in DC_status_motors:\n            # Set the bit mask for DC controllers\n            self.status_bit_mask = np.array([[0x00000001, 'forward hardware limit switch is active'],\n                                             [0x00000002, 'reverse hardware limit switch is active'],\n                                             [0x00000010, 'in motion, moving forward'],\n                                             [0x00000020, 'in motion, moving reverse'],\n                                             [0x00000040, 'in motion, jogging forward'],\n                                             [0x00000080, 'in motion, jogging reverse'],\n                                             [0x00000200, 'in motion, homing'],\n                                             [0x00000400, 'homed (homing has been completed)'],\n                                             [0x00001000, 'tracking'],\n                                             [0x00002000, 'settled'],\n                                             [0x00004000, 'motion error (excessive position error)'],\n                                             [0x01000000, 'motor current limit reached'],\n                                             [0x80000000, 'channel is enabled']])\n            self.velocity_scaling_factor = 204.8  # for converting velocity to mm/sec\n        else:\n            # Set the bit mask for normal motor controllers\n            self.status_bit_mask = np.array([[0x00000001, 'forward (CW) hardware limit switch is active'],\n                                    [0x00000002, 'reverse (CCW) hardware limit switch is active'],\n                                    [0x00000004, 'forward (CW) software limit switch is active'],\n                                    [0x00000008, 'reverse (CCW) software limit switch is active'],\n                                    [0x00000010, 'in motion, moving forward (CW)'],\n                                    [0x00000020, 'in motion, moving reverse (CCW)'],\n                                    [0x00000040, 'in motion, jogging forward (CW)'],\n                                    [0x00000080, 'in motion, jogging reverse (CCW)'],\n                                    [0x00000100, 'motor connected'],\n                                    [0x00000200, 'in motion, homing'],\n                                    [0x00000400, 'homed (homing has been completed)'],\n                                    [0x00001000, 'interlock state (1 = enabled)']])\n\n            # delattr(self, 'get_qt_ui')\n        if type(destination) != dict and len(self.destination)==1:\n            self.destination = {'x': destination}\n        \n        else:\n            self.axis_names = tuple(destination.keys())\n            self.destination = destination\n        \n        self.make_all_parameters()\n        self._recusive_move_num = 0",
  "def _waitFinishMove(self,axis = None,debug=False):\n        \"\"\"A simple function to force movement to block the console \"\"\"\n        if axis is None:\n            destination_ids = list(self.destination.keys())\n        else:\n            destination_ids = [axis]\n        for dest in destination_ids:\n            status = self.get_status_update(axis=dest)\n            if debug > 0 or DEBUG:\n                print(status)\n            \n            while any(['in motion' in x[1] for x in status]):\n                time.sleep(0.1)\n                status = self.get_status_update(axis = dest)",
  "def home(self,axis = None):\n        \"\"\"Rehome the stage with an axis input \"\"\"\n        if axis == None:\n            destination_ids = self.axis_names\n        else:\n            destination_ids = tuple(axis)\n        for dest in destination_ids:\n            self.write(0x0443, destination_id = dest)\n    #        self._waitForReply(0x0444, 6)\n            self._waitFinishMove()",
  "def move(self, pos, axis=None, relative=False, channel_number=None, block=True):\n        \"\"\" Move command allowing specification of axis, \n        relative, channel and if we want the function to be blocking\"\"\"\n        if channel_number is None:\n            channel_number = 1\n        if not hasattr(pos, '__iter__'):\n            pos = [pos]\n        elif type(pos)==tuple:\n            pos = list(pos)\n        if axis is None:\n            if len(pos)==len(self.axis_names):\n                axes = self.axis_names\n            else:\n                self._logger.warn('What axis shall I move?')\n        else:\n            axes = tuple(axis)\n        #create list of positions for each axis\n        pos_list = [0]*len(self.axis_names)\n        for i,axis  in enumerate(axes):\n            axis_number = np.where(np.array(self.axis_names)==[axis])[0][0]\n            pos_list[axis_number] = pos[i]\n        pos = pos_list\n        for axis in axes:\n            axis_number = np.where(np.array(self.axis_names)==[axis])[0][0]\n            if relative:\n                pos[axis_number] = self.position[axis_number]+pos[axis_number]\n\n            pos_in_counts = int(np.round(self.convert(pos[axis_number],'position','counts'),decimals = 0))\n            data = bytearray(struct.pack('<HL', self.channel_number_to_identity[channel_number], pos_in_counts))\n            try:\n                self.write(0x0453, data=data,destination_id=axis)\n                if block ==True:\n                    self._waitFinishMove()\n            except struct.error as e:\n                self.log('Move failed with '+str(e),'warning')\n                self._recusive_move_num+=1\n                if self._recusive_move_num>10:\n                    self._recusive_move_num = 0\n                    raise Exception('Stage move failed!')\n                self.move(pos[axis_number],axis=axis,channel_number=channel_number,block = block)\n            self._recusive_move_num = 0\n            axis_number += 1",
  "def get_status_update(self, channel_number=1,axis = None):\n        if self.model[1] in DC_status_motors:\n            returned_message = self.query(0x0490, param1=self.channel_number_to_identity[channel_number],destination_id = axis)\n        else:\n            returned_message = self.query(0x0480, param1=self.channel_number_to_identity[channel_number],destination_id = axis)\n        return self.update_status(returned_message['data'])",
  "def update_status(self, returned_message,debug=False):\n        '''This command should update device properties from the update message\n            however this has to be defined for every device as the status update format\n            and commands vary,\n            please implement me\n            Args:\n                The returned message from a status update request           (dict)\n        '''\n        if debug > 0 or DEBUG == True:\n            N = len(returned_message)\n            print(\"returned_message length:\",N)\n        if self.model[1] in DC_status_motors:\n            channel, position, velocity, Reserved, status_bits = struct.unpack(r'<HLHHI', returned_message)\n            #HLHHI\n            #H - 2, L - 4, I - 4\n            # self.position = position\n            # self.velocity = velocity / self.velocity_scaling_factor\n        else:\n            \n            channel, position, EncCnt,status_bits, ChanIdent2,_,_,_ = struct.unpack(r'<HILIHLLL', returned_message)\n            # print \"Status bits\",status_bits\n            # print \"self.status_bit_mask\",self.status_bit_mask[:, 0]\n        bitmask = self._bit_mask_array(status_bits, [int(i) for i in self.status_bit_mask[:, 0]])\n        self.status = self.status_bit_mask[np.where(bitmask)]\n        if debug > 0 or DEBUG == True:\n            print(self.status)\n        return self.status",
  "def init_no_flash_programming(self):\n        \"\"\" This message must be sent on startup to tell the controller\n        the source and destination address - The manual says this MUST be\n        sent as part of the intialisation process\n\n        Labled as: MGMSG_HW_NO_FLASH_PROGRAMMING\n        \"\"\"\n        self.write(0x0018)",
  "def get_position(self, axis = None,channel_number=1):\n        '''Sets/Gets the live position count in the controller\n            generally this should not be used to set the position\n            instead the controller should determine its own position\n            by performing a homing manoeuvre\n            Args:\n                postion:    (float) this is the real position value\n                            which is then converted to APT units within the setter\n                channel_number:     (int) This defaults to 1\n        '''\n        if axis is None:\n            return np.array(([self.get_position(axis) for axis in self.axis_names]))\n        else:\n            if axis not in self.axis_names:\n                raise ValueError(\"{0} is not a valid axis, must be one of {1}\".format(axis, self.axis_names))\n                \n            returned_message = self.query(0x0411, param1=self.channel_number_to_identity[channel_number],\n                                          destination_id = axis)\n            data = returned_message['data']\n            channel_id, position = struct.unpack(r'<HL', data)\n        # position = self.convert_to_SI_position(position)\n            return self.convert(position,'counts','position')",
  "def set_position(self, position, channel_number=1,axis = None):\n        # position = self.convert_to_APT_position(position)\n        data = bytearray(struct.pack('<HL', self.channel_number_to_identity[channel_number], position))\n        self.write(0x0410, data=data,destination_id = axis)",
  "def convert(self, value, from_, to_):\n        print('Not doing anything from ', from_, ' to ', to_)\n        return value",
  "def make_parameter(self, param_dict, destination_id = None):\n        \"\"\"Makes a parameter dictionary and sets it as a property\n\n        All parameters in the Thorlabs APT basically require the same command structure, so this function wraps any\n        parameter creation to simplify the code. It takes a dictionary containing the name of the parameter you want to\n        make, which will be used to create a property attribute by that name and a getter and a setter. The dictionary\n        should also containg the getter and setter command codes, and the structure of the data that is passed in the\n        getter and setter. Finally the dictionary should contain the names of each of the sub_parameters given by the\n        setter and getter, whose values can be converted into normal units by overwriting the self.convert() function\n\n        Examples:\n            Make self.velocity_params property, together with a self.get_velocity_params and self.set_velocity_params\n            functions. self.velocity_params will be a dictionary, containing 'channel_num', 'min_velocity',\n            'acceleration' and 'max_velocity'. The velocities will be converted into velocity through the convert\n            function and the acceleration will be converted into acceleration.\n\n                >>> self.make_parameter(dict(name='velocity_params', set=0x0413, get=0x0414, structure='HLLL',\n                >>>                     param_names=['channel_num', ['min_velocity', 'velocity'],\n                >>>                                 ['acceleration', 'acceleration'], ['max_velocity', 'velocity']]))\n\n\n        Args:\n            param_dict:\n                name        :   internal name that you want the parameter to have\n                set         :   setter function\n                get         :   getter function\n                structure   :   binary structure of the data packets\n                param_names :   names of the parameters in the structure\n\n        Returns:\n\n        \"\"\"\n\n        def getter(selfie, channel_number=1):\n            returned_message = selfie.query(param_dict['get'], param1=selfie.channel_number_to_identity[channel_number],destination_id = destination_id)\n            data = returned_message['data']\n            data = struct.unpack('<' + param_dict['structure'], data)\n            params = {}\n            index = 0\n            for name in param_dict['param_names']:\n                if type(name) == str:\n                    params[name] = data[index]\n                elif type(name) == list:\n                    params[name[0]] = selfie.convert(data[index], 'counts', name[1])\n                index += 1\n            return params\n\n        def setter(selfie, params, channel_number=None):\n            if channel_number is None:\n                channel_number = params['channel_num']\n            unstructured_data = ['<' + param_dict['structure'],\n                                 selfie.channel_number_to_identity[channel_number]]\n            for name in param_dict['param_names']:\n                if name != 'channel_num':\n                    if type(name) == str:\n                        unstructured_data += [params[name]]\n                    elif type(name) == list:\n                        unstructured_data += [selfie.convert(params[name[0]], name[1], 'counts')]\n            data = struct.pack(*unstructured_data)\n            selfie.write(param_dict['set'], data=data, destination_id=destination_id )\n\n        setattr(self, 'get_' + param_dict['name'], types.MethodType(getter, self))\n        setattr(self, 'set_' + param_dict['name'], types.MethodType(setter, self))\n        try:\n            setattr(self, param_dict['name'], property('get_' + param_dict['name'], 'set_' + param_dict['name']))\n        except AttributeError:\n            print(param_dict['name'], ' already exists')",
  "def make_all_parameters(self):\n        # TODO: add all the documentation for each of these parameters\n        for axis in self.destination:\n            self.make_parameter(dict(name=axis+'_encoder_counts', set=0x0409, get=0x040A, structure='HL', param_names=['channel_num', 'encoder_counts']),destination_id=axis)\n            # self.make_parameter(dict(name='position', set=0x0410, get=0x0411, structure='HL', param_names=['channel_num', ['position', 'distance']]))\n            self.make_parameter(dict(name=axis+'_velocity_params', set=0x0413, get=0x0414, structure='HLLL',\n                                     param_names=['channel_num', ['min_velocity', 'velocity'],\n                                                  ['acceleration', 'acceleration'], ['max_velocity', 'velocity']]),destination_id=axis)\n            self.make_parameter(dict(name=axis+'_jog_params', set=0x0416, get=0x0417, structure='HHLLLLH',\n                                     param_names=['channel_num', ['jog_step_size', 'distance'],\n                                                  ['jog_min_velocity', 'velocity'], ['jog_acceleration', 'acceleration'],\n                                                  ['jog_max_velocity', 'velocity'], 'jog_stop_mode']),destination_id=axis)\n            self.make_parameter(dict(name=axis+'_gen_move_params', set=0x043C, get=0x043B, structure='HL',\n                                     param_names=['channel_num', 'backlash']),destination_id = axis)\n            self.make_parameter(dict(name=axis+'_power_params', set=0x0426, get=0x0427, structure='HHH',\n                                     param_names=['channel_num', 'RestPower', 'MovePower']),destination_id = axis)\n            self.make_parameter(dict(name=axis+'_move_rel_params', set=0x0446, get=0x0447, structure='HL',\n                                     param_names=['channel_num', 'rel_dist']),destination_id = axis)\n            self.make_parameter(dict(name=axis+'_move_abs_params', set=0x0451, get=0x0452, structure='HL',\n                                     param_names=['channel_num', 'abs_dist']),destination_id = axis)\n            self.make_parameter(dict(name=axis+'_home_params', set=0x0441, get=0x0442, structure='HHHLL',\n                                     param_names=['channel_num', 'direction', 'limit_switch', 'velocity', 'offset']),destination_id=axis)",
  "def __init__(self,  port=None, source=0x01, destination=None,use_si_units=True,unit = 'm',\n                 stay_alive=True, stage_type = None):\n        \"\"\"\n        Pass all of the correct arguments to APT_VCP_motor for the DC stages and create converters.\n        \"\"\"\n        APT_VCP_motor.__init__(self, port=port, source=source, destination=destination,\n                         use_si_units=True,unit = unit, stay_alive=stay_alive)  # this opens the port\n        #Setup up conversion factors\n        if self.model[1] == 'BBD102/BBD103': #Once the TBD001 controller is added it needs to be added here\n            self.t_constant = 102.4E-6\n        elif self.model[1] in ['TDC001', 'KDCT101']:\n            self.t_constant = 2048.0/(6.0E6)\n        else:\n            self.t_constant = None\n        \n        if stage_type != None:\n            try:\n                self.EncCnt = float(self.DC_stages_EncCnt[stage_type])\n            except KeyError:\n                self.EncCnt = None\n                self._logger.warn('The stage type suggested is not listed and therefore a calibration cannot be set')\n        else:\n            self.EncCnt = None",
  "def convert(self, value, from_, to_):\n        if None in (self.EncCnt,self.t_constant):\n            self._logger.warn('Conversion impossible: one of the constants has not been implemented')\n            return value\n        if from_ == 'counts':\n            return self.counts_to[to_](self,value)\n        elif to_ == 'counts':\n            return self.si_to[from_](self,value)\n        else:\n            self._logger.warn(('Converting %s to %s is not possible!, returning raw value'%(from_, to_))) \n            return value",
  "def counts_to_pos(self,counts):\n        return (counts/self.EncCnt)*1E3",
  "def pos_to_counts(self,pos):\n        return (pos*self.EncCnt/1E3)",
  "def counts_to_vel(self,counts):\n        return (counts/(self.EncCnt*self.t_constant*65536))*1E3",
  "def vel_to_counts(self,vel):\n        return (vel*65536*self.t_constant*self.EncCnt/1E3)",
  "def counts_to_acc(self,counts):\n        return (counts/(self.EncCnt*self.t_constant**2*65536))*1E3",
  "def acc_to_counts(self,acc):\n        return (self.EncCnt*self.t_constant**2*65536*acc/1E3)",
  "def move_step(self,axis,direction):\n        self.move_rel(self.stepsize*direction,axis)",
  "def _waitFinishMove(self,axis = None,debug=False):\n        \"\"\"A simple function to force movement to block the console \"\"\"\n        if axis == None:\n            destination_ids = list(self.destination.keys())\n        else:\n            destination_ids = [axis]\n        for dest in destination_ids:\n            status = self.get_status_update(axis = dest)# \\ # and all([not x[1].endswith('homing') for x in status])\\\n            while any(['in motion' in x[1] for x in status]):\n \n                time.sleep(0.1)\n                status = self.get_status_update(axis = dest)\n                if debug > 0 or DEBUG:\n                    print(status)",
  "def home(self,axis = None):\n        \"\"\"Rehome the stage with an axis input \"\"\"\n        if axis == None:\n            destination_ids = self.axis_names\n        else:\n            destination_ids = tuple(axis)\n        for dest in destination_ids:\n            self.write(0x0443,destination_id = dest)\n            self._waitForReply()\n            self._waitFinishMove()",
  "def __init__(self,  port=None, source=0x01, destination=None,use_si_units=True, stay_alive=True, stage_type = None):\n        \"\"\"\n        Pass all of the correct arguments to APT_VCP_motor for the standard stepper controllers\n        stages and create converters.\n        \"\"\"\n        APT_VCP_motor.__init__(self, port=port, source=source, destination=destination,\n                         use_si_units=True, stay_alive=stay_alive)  # this opens the port\n        #Setup up conversion factors\n        \n        if stage_type != None:\n            try:\n                self.EncCnt = float(self.stepper_stages_EncCnt[stage_type])\n            except KeyError:\n                self.EncCnt = None\n                self._logger.warn('The stage type suggested is not listed and therefore a calibration cannot be set')\n        else:\n            self.EncCnt = None",
  "def convert(self, value, from_, to_):\n        if self.EncCnt==None:\n            self._logger.warn('Conversion impossible: one of the constants has not been implemented')\n            return value\n        if from_ == 'counts':\n            return self.counts_to_si(value)\n        elif to_ == 'counts':\n            return self.si_to_counts(value)\n        else:\n            self._logger.warn(('Converting %s to %s is not possible!, returning raw value'%(from_, to_))) \n            return value",
  "def counts_to_si(self,counts):\n        return (counts/self.EncCnt)*1E3",
  "def si_to_counts(self,pos):\n        return (pos*self.EncCnt/1E3)",
  "def __init__(self,  port=None, source=0x01, destination=None,use_si_units=True, stay_alive=True, stage_type = None):\n        \"\"\"\n        Pass all of the correct arguments to APT_VCP_motor for the Trinamics stepper controllers\n        stages and create converters.\n        \"\"\"\n        APT_VCP_motor.__init__(self, port=port, source=source, destination=destination,\n                         use_si_units=True, stay_alive=stay_alive)  # this opens the port\n        #Setup up conversion factors\n        if stage_type!= None:\n            try:\n                self.EncCnt = float(self.stepper_stages_EncCnt[stage_type])\n            except KeyError:\n                self.EncCnt = None\n                self._logger.warn('The stage type suggested is not listed and therefore a calibration cannot be set')\n        else:\n            self.EncCnt = None",
  "def convert(self, value, from_, to_):\n        if None in (self.EncCnt,self.t_constant):\n            self._logger.warn('Conversion impossible: one of the constants has not been implemented')\n            return value\n        if from_ == 'counts':\n            return self.counts_to[to_](self,value)\n        elif to_ == 'counts':\n            return self.si_to[from_](self,value)\n        else:\n            self._logger.warn(('Converting %s to %s is not possible!, returning raw value'%(from_, to_))) \n            return value",
  "def counts_to_pos(self,counts):\n        return old_div(counts,self.EncCnt)*1E3",
  "def pos_to_counts(self,pos):\n        return old_div(pos*self.EncCnt,1E3)",
  "def counts_to_vel(self,counts):\n        return old_div(counts,(self.EncCnt*53.68))*1E3",
  "def vel_to_counts(self,vel):\n        return old_div(vel*53.68*self.EncCnt,1E3)",
  "def counts_to_acc(self,counts):\n        return old_div(counts,(self.EncCnt/90.9))*1E3",
  "def acc_to_counts(self,acc):\n        return old_div(self.EncCnt/90.9*acc,1E3)",
  "def jog_forward(self): # 1 -> 0 (blame thorlabs)\n        self._write(0x046A, param2=0x01)\n        self._waitFinishMove()",
  "def jog_backward(self): # 0 -> 1\n        self._write(0x046A, param2=0x02)\n        self._waitFinishMove()",
  "def get_status_bits(self):\n        data = self.query(0x0429, blocking=True)['data']\n        status_bits = struct.unpack(r'3h', data)\n        return status_bits",
  "def get_position(self):\n        return self.get_status_bits()[1] - 1",
  "def set_position(self, val):\n        if (pos := self.position) > val:\n            self.jog_forward()\n        elif pos < val:\n            self.jog_backward()",
  "def toggle(self):\n        self.position = not self.position",
  "def home(self):\n        self.set_position(0)",
  "def _waitFinishMove(self):\n        pass",
  "def get_qt_ui(self):\n        return FlipperUI(self)",
  "def __init__(self, instr):\n        super().__init__()\n        self.instr = instr\n        self.add_checkbox('position')\n        self.auto_connect_by_name(controlled_object=instr)",
  "def getter(selfie, channel_number=1):\n            returned_message = selfie.query(param_dict['get'], param1=selfie.channel_number_to_identity[channel_number],destination_id = destination_id)\n            data = returned_message['data']\n            data = struct.unpack('<' + param_dict['structure'], data)\n            params = {}\n            index = 0\n            for name in param_dict['param_names']:\n                if type(name) == str:\n                    params[name] = data[index]\n                elif type(name) == list:\n                    params[name[0]] = selfie.convert(data[index], 'counts', name[1])\n                index += 1\n            return params",
  "def setter(selfie, params, channel_number=None):\n            if channel_number is None:\n                channel_number = params['channel_num']\n            unstructured_data = ['<' + param_dict['structure'],\n                                 selfie.channel_number_to_identity[channel_number]]\n            for name in param_dict['param_names']:\n                if name != 'channel_num':\n                    if type(name) == str:\n                        unstructured_data += [params[name]]\n                    elif type(name) == list:\n                        unstructured_data += [selfie.convert(params[name[0]], name[1], 'counts')]\n            data = struct.pack(*unstructured_data)\n            selfie.write(param_dict['set'], data=data, destination_id=destination_id )",
  "class Piezoconcept(SerialInstrument, Stage):\n    '''A class for the Piezoconcept objective collar '''\n    axis_names = ('z',)\n\n    def __init__(self, port=None, unit='u', cmd_axis='Z'):\n        '''Set up baudrate etc and recenters the stage to the center of it's range (50um)\n        \n        Args:\n            port(int/str):  The port the device is connected \n                            to in any of the accepted serial formats\n            \n        '''\n        self.termination_character = '\\n'\n        self.port_settings = {\n            'baudrate': 115200,\n            'bytesize': serial.EIGHTBITS,\n            'parity': serial.PARITY_NONE,\n            'stopbits': serial.STOPBITS_ONE,\n            'timeout': 1,  # wait at most one second for a response\n            #          'writeTimeout':1, #similarly, fail if writing takes >1s\n            #         'xonxoff':False, 'rtscts':False, 'dsrdtr':False,\n        }\n        SerialInstrument.__init__(self, port=port)\n        Stage.__init__(self)\n        self.cmd_axis = cmd_axis.upper()\n        self.unit = unit  # This can be 'u' for micron or 'n' for nano\n        self.distance_scale = 1 if unit == 'n' else 1_000.\n    def move(self, value, axis=None, relative=False):\n        '''Move to an absolute positions between 0 and 100 um \n        \n        Args:\n            value(float):   position to move to\n\n        '''\n        nm = int(self.distance_scale*value)\n        if relative:\n            if 0 <= nm/1_000 + self.position*1_000 < 100_000:\n                self.write(f'MOVR{self.cmd_axis} {nm}n')\n            else:\n                self._logger.warn(\n                    \"The value is out of range! 0-100 um (0-1E8 nm) (Z)\")          \n        else:\n            if 0 <= nm < 100_000:\n            #     if (multiplied-0.2*self.distance_scale) > 0:\n            #         value = value-0.2*self.distance_scale  # why?\n      \n                self.write(f'MOVE{self.cmd_axis} {nm}n')\n                # print(self.readline(), 'reply')\n            else:\n                self._logger.warn(\n                    \"The value is out of range! 0-100 um (0-1E8 nm) (Z)\")\n            \n     \n\n    def get_position(self):\n        return float(self.query(f'GET_{self.cmd_axis}')[:-3])\n\n    def move_step(self, direction):\n        '''Move a predefined step in either direction\n        Args:\n            direction(int):     +1/-1 corresponding to either positive or negative directions\n            \n        Notes:\n            There is no value checking on the directions value therefore \n            it can also be used to perform integer multiples of steps\n        '''\n        self.move_rel(direction*self.stepsize)\n\n    def recenter(self):\n        '''Recenter the stage (50um) and reset software position \n        '''\n        self.move(50)\n\n    def INFO(self):\n        ''' '''\n        return self.query(\"INFOS\", multiline=True, termination_line=\" blah blah\", timeout=.1,)\n\n    def DSIO(self):\n        ''' '''\n        return self.query(\"DSIO 1\", multiline=True, termination_line=\" blah blah\", timeout=.1,)\n\n    def HELP(self):\n        return self.query('HELP_')",
  "def __init__(self, port=None, unit='u', cmd_axis='Z'):\n        '''Set up baudrate etc and recenters the stage to the center of it's range (50um)\n        \n        Args:\n            port(int/str):  The port the device is connected \n                            to in any of the accepted serial formats\n            \n        '''\n        self.termination_character = '\\n'\n        self.port_settings = {\n            'baudrate': 115200,\n            'bytesize': serial.EIGHTBITS,\n            'parity': serial.PARITY_NONE,\n            'stopbits': serial.STOPBITS_ONE,\n            'timeout': 1,  # wait at most one second for a response\n            #          'writeTimeout':1, #similarly, fail if writing takes >1s\n            #         'xonxoff':False, 'rtscts':False, 'dsrdtr':False,\n        }\n        SerialInstrument.__init__(self, port=port)\n        Stage.__init__(self)\n        self.cmd_axis = cmd_axis.upper()\n        self.unit = unit  # This can be 'u' for micron or 'n' for nano\n        self.distance_scale = 1 if unit == 'n' else 1_000.",
  "def move(self, value, axis=None, relative=False):\n        '''Move to an absolute positions between 0 and 100 um \n        \n        Args:\n            value(float):   position to move to\n\n        '''\n        nm = int(self.distance_scale*value)\n        if relative:\n            if 0 <= nm/1_000 + self.position*1_000 < 100_000:\n                self.write(f'MOVR{self.cmd_axis} {nm}n')\n            else:\n                self._logger.warn(\n                    \"The value is out of range! 0-100 um (0-1E8 nm) (Z)\")          \n        else:\n            if 0 <= nm < 100_000:\n            #     if (multiplied-0.2*self.distance_scale) > 0:\n            #         value = value-0.2*self.distance_scale  # why?\n      \n                self.write(f'MOVE{self.cmd_axis} {nm}n')\n                # print(self.readline(), 'reply')\n            else:\n                self._logger.warn(\n                    \"The value is out of range! 0-100 um (0-1E8 nm) (Z)\")",
  "def get_position(self):\n        return float(self.query(f'GET_{self.cmd_axis}')[:-3])",
  "def move_step(self, direction):\n        '''Move a predefined step in either direction\n        Args:\n            direction(int):     +1/-1 corresponding to either positive or negative directions\n            \n        Notes:\n            There is no value checking on the directions value therefore \n            it can also be used to perform integer multiples of steps\n        '''\n        self.move_rel(direction*self.stepsize)",
  "def recenter(self):\n        '''Recenter the stage (50um) and reset software position \n        '''\n        self.move(50)",
  "def INFO(self):\n        ''' '''\n        return self.query(\"INFOS\", multiline=True, termination_line=\" blah blah\", timeout=.1,)",
  "def DSIO(self):\n        ''' '''\n        return self.query(\"DSIO 1\", multiline=True, termination_line=\" blah blah\", timeout=.1,)",
  "def HELP(self):\n        return self.query('HELP_')",
  "class CameraStageMapper(Instrument):\n    \"\"\"\n    This class sits between a camera and a stage, allowing coordinate conversion.\n\n    Coordinate Systems\n    ------------------\n    We consider the centre of the image to be our current position, and give\n    the position of each pixel on the camera such that it would be brought to\n    the centre of the camera image by moving the stage to (-position).\n    \"\"\"\n#    do_calibration = Button()\n#    calibration_distance = Float(7, tooltip=\"Distance to move in each direction when calibrating, in um\")\n#    camera_to_sample = Array(shape=(2,2))\n#    do_autofocus = Button()\n#    autofocus_range = Range(0., 100., 5.)\n#    autofocus_step = Range(0., 10., 0.5)\n#    autofocus_default_ranges = [np.arange(-5,5,0.5),np.arange(-1,1,0.2)]\n#    frames_to_discard = Int(1)\n#    settling_time = Float(0.2)\n#    disable_live_view = True\n#    traits_view = View(\n#                    VGroup(\n#                        Item(name=\"calibration_distance\"),\n#                        Item(name=\"do_calibration\"),\n#                        Item(name=\"autofocus_range\"),\n#                        Item(name=\"autofocus_step\"),\n#                        Item(name=\"do_autofocus\"),\n#                        Item(name=\"camera_to_sample\"),\n#                    ),\n#                    title=\"Camera-Stage Mapper\",\n#                )\n    def __init__(self, camera, stage):\n        super(CameraStageMapper, self).__init__()\n        self.camera = camera\n        self.stage = stage\n        self.autofocus_range = 5.0\n        self.autofocus_step = 0.5\n        self.autofocus_default_ranges = [np.arange(-5,5,0.5),np.arange(-1,1,0.2)]\n        self.camera_to_sample = np.identity(2)\n        self.camera_centre = (0.5,0.5)\n        self.calibration_distance = 7\n        self.settling_time = 0.2\n        self.frames_to_discard = 1\n        self.camera.set_legacy_click_callback(self.move_to_camera_point)\n        self.disable_live_view = True\n        self._action_lock = threading.Lock() #prevent us from doing two things involving motion at once!\n        self.filter_images = False\n    \n    ############ Coordinate Conversion ##################\n    def camera_pixel_to_point(self, p):\n        \"\"\"convert pixel coordinates to point coordinates (normalised 0-1)\"\"\"\n        return (np.array(p,dtype=float)/\n                np.array(self.camera.latest_frame.shape[0:2], dtype=float))\n    def camera_point_to_pixel(self, p):\n        \"\"\"convert point coordinates (normalised 0-1) to pixel\"\"\"\n        return np.array(p)*np.array(self.camera.latest_frame.shape[0:2])\n    def camera_pixel_to_sample(self, p):\n        return self.camera_point_to_sample(self.camera_pixel_to_point(p))\n    def camera_point_to_sample(self, p):\n        displacement = np.dot(np.array(p) - np.array(self.camera_centre),\n                              self.camera_to_sample)\n        return self.camera_centre_position()[0:2] + displacement\n    def camera_point_displacement_to_sample(self, p):\n        \"\"\"Convert a displacement from camera point units to microns\"\"\"\n        return np.dot(np.array(p), self.camera_to_sample)\n    def camera_pixel_displacement_to_sample(self, p):\n        \"\"\"Convert from pixels to microns for relative moves\"\"\"\n        return self.camera_point_displacement_to_sample(self.camera_pixel_to_point(p))\n    \n    ############## Stage Control #####################\n    def move_to_camera_pixel(self, p):\n        \"\"\"bring the object at pixel p=(x,y) on the camera to the centre\"\"\"\n        return self.move_to_camera_point(*tuple(self.camera_pixel_to_point(p)))\n    def move_to_camera_point(self, x, y=None):\n        \"\"\"Move the stage to centre point (x,y) on the camera\n        \n        (x,y) is the position on the camera, where x,y range from 0 to 1\"\"\"\n        if y is None:\n            p=x\n        else:\n            p=(x,y)\n        displacement = np.dot(np.array(p) - np.array(self.camera_centre),\n                              self.camera_to_sample)\n        current_position = displacement +self.camera_centre_position()[0:2]\n        self.move_to_sample_position(current_position)\n\n    def move_to_sample_position(self, p):\n        \"\"\"Move the stage to centre sample position p on the camera\"\"\"\n        self.stage.move(-np.array(p))\n    \n    def camera_centre_position(self):\n        \"\"\"return the position of the centre of the camera view, on the sample\"\"\"\n        return -self.stage.position\n    \n    ################## Closed loop stage control #################\n    def centre_on_feature(self, feature_image, search_size=(50,50), tolerance=0.3, max_iterations=10, **kwargs):\n        \"\"\"Adjust the stage slightly to centre on the given feature.\n        \n        This should be called immediately after moving the stage to centre on a\n        feature in the image: first move the stage to bring that feature to the\n        centre, then call this function to fine-tune.\n        \n        Arguments\n        =========\n        * feature_image: an RGB image of a feature.  Must be\n        significantly smaller than the camera image.\n        * search_size: size of the area around the image centre to search, in\n        pixels.  Should be a tuple of length 2.\n        * tolerance: how accurately we're going to centre (in um)\n        * max_iterations: maximum number of shifts\n        \"\"\"\n        shift=[999.,999.]\n        n=0\n        if self.disable_live_view:\n            camera_live_view = self.camera.live_view\n            self.camera.live_view = False\n        while np.sqrt(np.sum(np.array(shift)**2))>tolerance and n<max_iterations:\n            n+=1\n            try:\n                shift=self.centre_on_feature_iterate(feature_image, \n                                                     search_size=search_size, \n                                                     **kwargs)\n                print(\"Centring on feature: moving by %.2f, %.2f\" % tuple(shift))\n            except:\n                print(\"Something went wrong with auto-centering - trying again.\") #don't worry, we incremented N so this won't go on forever!\n        if np.sqrt(np.sum(np.array(shift)**2))>tolerance:\n            print(\"Performed %d iterations but did not converge on the feature to within %.3fum\" % (n, tolerance))\n        else:\n            print(\"Centered on feature in %d iterations.\" % n)\n        if self.disable_live_view:\n            self.camera.live_view = camera_live_view #reenable live view if necessary\n    def centre_on_feature_iterate(self, feature_image, search_size=(50,50), image_filter=lambda x: x):\n        \"\"\"Measure the displacement of the sample and move to correct it.\n        \n        Arguments:\n        feature_image : numpy.ndarray\n            This is the feature that should be at the centre of the camera.  It\n            must be smaller than the camera image + search size.\n        search_size : (int, int)\n            The distance in pixels to search over.  Defaults to (50,50).\n        image_filter : function (optional)\n            If supplied, run this function on the image before cross-correlating\n            (you can use this to cross-correlate in grayscale, for example).\n        \"\"\"\n        try:\n            self.flush_camera_and_wait()\n            current_image = image_filter(self.camera.color_image()) #get the current image\n            corr = cv2.matchTemplate(current_image,feature_image,cv2.TM_SQDIFF_NORMED) #correlate them: NB the match position is the MINIMUM\n            #restrict to just the search area, and invert so we find the maximum\n            corr = -corr[(corr.shape[0]/2. - search_size[0]/2.):(corr.shape[0]/2. + search_size[0]/2.),\n                         (corr.shape[1]/2. - search_size[1]/2.):(corr.shape[1]/2. + search_size[1]/2.)] #invert the image so we can find a peak\n            corr += (corr.max()-corr.min())*0.1 - corr.max() #background-subtract 90% of maximum\n            corr = cv2.threshold(corr, 0, 0, cv2.THRESH_TOZERO)[1] #zero out any negative pixels - but there should always be > 0 nonzero pixels\n            peak = ndimage.measurements.center_of_mass(corr) #take the centroid (NB this is of grayscale values not just binary)\n            self.move_to_camera_pixel(np.array(peak) - np.array(corr.shape[0:2])/2.+np.array(current_image.shape[0:2])/2.)\n            return self.camera_pixel_displacement_to_sample(np.array(peak) - np.array(corr.shape[0:2])/2.)\n        except Exception as e:\n            print(\"Exception: \", e)\n            print(\"Corr: \", corr)\n            print(\"Feature: \", feature_image)\n            print(\"Feature Size: \", feature_image.shape)\n            print(\"Corr size: \", corr.shape)\n            print(\"Peak: \", peak)\n            print(\"sum(corr): \", np.sum(corr))\n            print(\"max(corr): \", np.max(corr))\n            raise e\n\n########## Calibration ###############\n    def calibrate_in_background(self):\n        threading.Thread(target=self.calibrate).start()\n    def calibrate(self, dx=None):\n        \"\"\"Move the stage in a square and set the transformation matrix.\"\"\"\n        try:\n            with self._action_lock:\n                if dx is None or dx is False: dx=self.calibration_distance #use a sensible default\n                here = self.camera_centre_position()\n                if len(self.stage.axis_names)==2:\n                    pos = [np.array([i,j]) for i in [-dx,dx] for j in [-dx,dx]]\n                elif len(self.stage.axis_names)==3:\n                    pos = [np.array([i,j,0]) for i in [-dx,dx] for j in [-dx,dx]]\n                print(pos, dx)\n                camera_pos = []\n                self.camera.update_latest_frame() # make sure we've got a fresh image\n                if self.filter_images==True and self.camera.filter_function != None:\n                    initial_image = self.camera.filter_function(self.camera.raw_image())\n                else:\n                    initial_image = self.camera.gray_image()\n                w, h, = initial_image.shape\n                template = initial_image[(w//4):(3*w//4),(h//4):(3*h//4)] #.astype(np.float)\n                #template -= cv2.blur(template, (21,21), borderType=cv2.BORDER_REPLICATE)\n        #        self.calibration_template = template\n        #        self.calibration_images = []\n                camera_live_view = self.camera.live_view\n                if self.disable_live_view:\n                    self.camera.live_view = False\n                for p in pos:\n                    self.move_to_sample_position(here + p)\n                    self.flush_camera_and_wait()\n                    if self.filter_images==True and self.camera.filter_function != None:\n                        current_image = self.camera.filter_function(self.camera.raw_image())\n                    else:\n                        current_image = self.camera.gray_image()\n                    corr = cv2.matchTemplate(current_image,template,cv2.TM_SQDIFF_NORMED)\n                    corr *= -1. #invert the image\n                    corr += (corr.max()-corr.min())*0.1 - corr.max() ##\n                    corr = cv2.threshold(corr, 0, 0, cv2.THRESH_TOZERO)[1]\n        #            peak = np.unravel_index(corr.argmin(),corr.shape)\n                    peak = ndimage.measurements.center_of_mass(corr)\n                    camera_pos.append(peak - ((np.array(current_image.shape) - \\\n                                                           np.array(template.shape))/2))\n        #            self.calibration_images.append({\"image\":current_image,\"correlation\":corr,\"pos\":p,\"peak\":peak})\n                self.move_to_sample_position(here)\n                self.flush_camera_and_wait()#otherwise we get a worrying \"jump\" when enabling live view...\n                self.camera.live_view = camera_live_view\n                #camera_pos now contains the displacements in pixels for each move\n                sample_displacement = np.array([-p[0:2] for p in pos]) #nb need to convert to 2D, and the stage positioning is flipped from sample coords\n                camera_displacement = np.array([self.camera_pixel_to_point(p) for p in camera_pos])\n                print(\"sample was moved (in um):\\n\",sample_displacement)\n                print(\"the image shifted (in fractions-of-a-camera):\\n\",camera_displacement)\n                A, res, rank, s = np.linalg.lstsq(camera_displacement, sample_displacement)\n                self.camera_to_sample = A\n        except Exception as e:\n            print('Calibration failed because', e)\n    def flush_camera_and_wait(self):\n        \"\"\"take and discard a number of images from the camera to make sure the image is fresh\n        \n        This functionality should really be in the camera, not the aligner!\"\"\"\n        time.sleep(self.settling_time)\n        for i in range(self.frames_to_discard):\n            self.camera.raw_image() #acquire, then discard, an image from the camera\n\n    ######## Image Tiling ############\n    def acquire_tiled_image(self, n_images=(3,3), dest=None, overlap=0.33,\n                            autofocus_args={},live_plot=False, downsample=8):\n        \"\"\"Raster-scan the stage and take images, which we can later tile.\n\n        Arguments:\n        @param: n_images: A tuple of length 2 specifying the number of images\n        to take in X and Y\n        @param: dest: An HDF5 Group object to store the images in.  Each image\n        will be tagged with metadata to mark where it was taken.  If no dest\n        is specified, a new group will be created in the current datafile.\n        @param: overlap: the fraction of each image to overlap with the \n        adjacent one (it's important this is high enough to match them up)\n        @param: autofocus_args: A dictionary of keyword arguments for the\n        autofocus that occurs before each image is taken.  Set to None to\n        disable autofocusing.\n        \"\"\"\n        reset_interactive_mode = live_plot and not matplotlib.is_interactive()\n        if live_plot:\n            plt.ion()\n            fig = plt.figure()\n            axes = fig.add_subplot(111)\n            axes.set_aspect(1)\n            \n        with self._action_lock:\n            if dest is None:\n                dest = self.create_data_group(\"tiled_image_%d\") #or should this be in RAM??\n            centre_position = self.camera_centre_position()[0:2] #only 2D\n            x_indices = np.arange(n_images[0]) - (n_images[0] - 1)/2.0\n            y_indices = np.arange(n_images[1]) - (n_images[1] - 1)/2.0\n            for y_index in y_indices:\n                for x_index in x_indices:\n                    position = centre_position + self.camera_point_displacement_to_sample(np.array([x_index, y_index]) * (1-overlap))\n                    self.move_to_sample_position(position) #go to the raster point\n                    if autofocus_args is not None:\n                        self.autofocus(**autofocus_args)\n                    self.flush_camera_and_wait() #wait for the camera to be ready/stage to settle\n                    tile = dest.create_dataset(\"tile_%d\", \n                                               data=self.camera.color_image(),\n                                               attrs=self.camera.metadata)\n                    tile.attrs.create(\"stage_position\",self.stage.position)\n                    tile.attrs.create(\"camera_centre_position\",self.camera_centre_position())\n                    if live_plot:\n                        #Plot the image, in sample coordinates\n                        corner_points = np.array([self.camera_point_to_sample((xcorner,ycorner)) \n                                                for ycorner in [0,1] for xcorner in [0,1]]) #positions of corners\n                        plot_skewed_image(tile[::downsample, ::downsample, :],\n                                          corner_points, axes=axes)\n                        fig.canvas.draw()\n                x_indices = x_indices[::-1] #reverse the X positions, so we do a snake-scan\n            dest.attrs.set(\"camera_to_sample\",self.camera_to_sample)\n            dest.attrs.set(\"camera_centre\",self.camera_centre)\n            self.move_to_sample_position(centre_position) #go back to the start point\n        if reset_interactive_mode:\n            plt.ioff()\n        return dest\n        \n    ######## Autofocus Stuff #########\n    def autofocus_merit_function(self): # we maximise this...\n        \"\"\"Take an image and calculate the focus metric, this is what we optimise.\n        \n        Currently, this calculates the sum of the square of the Laplacian of the image\n        which should pick out sharp features quite effectively.  It can, however, be\n        thrown off by very bright objects if the camera is saturated.\"\"\"\n        self.flush_camera_and_wait()\n#        self.camera.update_latest_frame() #take an extra frame to make sure this one is fresh\n        if self.filter_images == True and self.camera.filter_function != None:\n            img = self.camera.filter_function(self.camera.raw_image())\n        else:\n            img = self.camera.raw_image()\n        if np.shape(img)[-1]==3:\n            img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n#        return np.sum((img - cv2.blur(img,(21,21))).astype(np.single)**2)\n        return np.sum(cv2.Laplacian(img, ddepth=cv2.CV_32F)**2)\n\n\n    def autofocus_in_background(self):\n        def work():\n            self.autofocus_iterate(np.arange(old_div(-self.autofocus_range,2), old_div(self.autofocus_range,2), self.autofocus_step))\n        threading.Thread(target=work).start()\n    \n    def autofocus_iterate(self, dz, method=\"centre_of_mass\", noise_floor=0.3):\n        self._action_lock.acquire()\n        \"\"\"Move in z and take images.  Move to the sharpest position.\"\"\"\n        here = self.stage.position\n        positions = [here]                              #positions keeps track of where we sample\n        powers = [self.autofocus_merit_function()]      #powers holds the value of the merit fn at each point\n        camera_live_view = self.camera.live_view\n        if self.disable_live_view:\n            self.camera.live_view = False\n        for z in dz:\n            self.stage.move(np.array([0,0,z])+here)     #visit each point and evaluate merit function\n #           time.sleep(0.5)\n            positions.append(self.stage.position)\n            powers.append(self.autofocus_merit_function())\n        powers = np.array(powers)\n        positions = np.array(positions)\n        z = positions[:,2] \n        if method==\"centre_of_mass\":\n            threshold = powers.min() + (powers.max()-powers.min())*noise_floor #(powers.min() if len(powers)<4 else np.max([powers[z.argmin()],powers[z.argmax()]])) #ensure edges are zero\n            weights = powers - threshold\n            weights[weights<0] = 0. #zero out any negative values\n            if(np.sum(weights)==0): \n                new_position = positions[powers.argmax(),:]\n            else: \n                new_position = old_div(np.dot(weights, positions),np.sum(weights))\n        elif method==\"parabola\":\n            coefficients = np.polyfit(z, powers, deg=2) #fit a parabola\n            root = old_div(-coefficients[1],(2*coefficients[0])) #p = c[0]z**\" + c[1]z + c[2] which has max (or min) at 2c[0]z + c[1]=0 i.e. z=-c[1]/2c[0]\n            if z.min() < root and root < z.max():\n                new_position = [here[0],here[1],root]\n            else:\n                new_position = positions[powers.argmax(),:]\n        else:\n            new_position = positions[powers.argmax(),:]\n        self.stage.move(new_position)\n        self.camera.live_view = camera_live_view\n        self._action_lock.release()\n        return new_position-here, positions, powers\n\n    def autofocus(self, ranges=None, max_steps=10):\n        \"\"\"move the stage to bring the sample into focus\n        \n        Presently, it just does one iteration for each range passed in: usually\n        this would mean a coarse focus then a fine focus.\n        \"\"\" #NEEDS WORK!\n        if ranges is None or ranges is False:\n            ranges = self.autofocus_default_ranges\n        n=0\n        for r in ranges:\n            pos = self.autofocus_iterate(r)[0]\n            print(\"moving Z by %.3f\" % pos[2])\n            n+=1\n        print(\"Autofocus: performed %d iterations\" % n)\n    \n    def get_qt_ui(self):\n        return CameraStageMapperControlWidget(self)",
  "class CameraStageMapperControlWidget(QtWidgets.QWidget, UiTools):\n    \"\"\"Controls for the Camera stage mapper\"\"\"\n    def __init__(self, camerastagemapper):\n        super(CameraStageMapperControlWidget, self).__init__()\n        self.camerastagemapper = camerastagemapper\n        self.load_ui_from_file(__file__,\"camerastagemapper.ui\")\n        self.auto_connect_by_name(controlled_object=self.camerastagemapper, verbose=True)",
  "def __init__(self, camera, stage):\n        super(CameraStageMapper, self).__init__()\n        self.camera = camera\n        self.stage = stage\n        self.autofocus_range = 5.0\n        self.autofocus_step = 0.5\n        self.autofocus_default_ranges = [np.arange(-5,5,0.5),np.arange(-1,1,0.2)]\n        self.camera_to_sample = np.identity(2)\n        self.camera_centre = (0.5,0.5)\n        self.calibration_distance = 7\n        self.settling_time = 0.2\n        self.frames_to_discard = 1\n        self.camera.set_legacy_click_callback(self.move_to_camera_point)\n        self.disable_live_view = True\n        self._action_lock = threading.Lock() #prevent us from doing two things involving motion at once!\n        self.filter_images = False",
  "def camera_pixel_to_point(self, p):\n        \"\"\"convert pixel coordinates to point coordinates (normalised 0-1)\"\"\"\n        return (np.array(p,dtype=float)/\n                np.array(self.camera.latest_frame.shape[0:2], dtype=float))",
  "def camera_point_to_pixel(self, p):\n        \"\"\"convert point coordinates (normalised 0-1) to pixel\"\"\"\n        return np.array(p)*np.array(self.camera.latest_frame.shape[0:2])",
  "def camera_pixel_to_sample(self, p):\n        return self.camera_point_to_sample(self.camera_pixel_to_point(p))",
  "def camera_point_to_sample(self, p):\n        displacement = np.dot(np.array(p) - np.array(self.camera_centre),\n                              self.camera_to_sample)\n        return self.camera_centre_position()[0:2] + displacement",
  "def camera_point_displacement_to_sample(self, p):\n        \"\"\"Convert a displacement from camera point units to microns\"\"\"\n        return np.dot(np.array(p), self.camera_to_sample)",
  "def camera_pixel_displacement_to_sample(self, p):\n        \"\"\"Convert from pixels to microns for relative moves\"\"\"\n        return self.camera_point_displacement_to_sample(self.camera_pixel_to_point(p))",
  "def move_to_camera_pixel(self, p):\n        \"\"\"bring the object at pixel p=(x,y) on the camera to the centre\"\"\"\n        return self.move_to_camera_point(*tuple(self.camera_pixel_to_point(p)))",
  "def move_to_camera_point(self, x, y=None):\n        \"\"\"Move the stage to centre point (x,y) on the camera\n        \n        (x,y) is the position on the camera, where x,y range from 0 to 1\"\"\"\n        if y is None:\n            p=x\n        else:\n            p=(x,y)\n        displacement = np.dot(np.array(p) - np.array(self.camera_centre),\n                              self.camera_to_sample)\n        current_position = displacement +self.camera_centre_position()[0:2]\n        self.move_to_sample_position(current_position)",
  "def move_to_sample_position(self, p):\n        \"\"\"Move the stage to centre sample position p on the camera\"\"\"\n        self.stage.move(-np.array(p))",
  "def camera_centre_position(self):\n        \"\"\"return the position of the centre of the camera view, on the sample\"\"\"\n        return -self.stage.position",
  "def centre_on_feature(self, feature_image, search_size=(50,50), tolerance=0.3, max_iterations=10, **kwargs):\n        \"\"\"Adjust the stage slightly to centre on the given feature.\n        \n        This should be called immediately after moving the stage to centre on a\n        feature in the image: first move the stage to bring that feature to the\n        centre, then call this function to fine-tune.\n        \n        Arguments\n        =========\n        * feature_image: an RGB image of a feature.  Must be\n        significantly smaller than the camera image.\n        * search_size: size of the area around the image centre to search, in\n        pixels.  Should be a tuple of length 2.\n        * tolerance: how accurately we're going to centre (in um)\n        * max_iterations: maximum number of shifts\n        \"\"\"\n        shift=[999.,999.]\n        n=0\n        if self.disable_live_view:\n            camera_live_view = self.camera.live_view\n            self.camera.live_view = False\n        while np.sqrt(np.sum(np.array(shift)**2))>tolerance and n<max_iterations:\n            n+=1\n            try:\n                shift=self.centre_on_feature_iterate(feature_image, \n                                                     search_size=search_size, \n                                                     **kwargs)\n                print(\"Centring on feature: moving by %.2f, %.2f\" % tuple(shift))\n            except:\n                print(\"Something went wrong with auto-centering - trying again.\") #don't worry, we incremented N so this won't go on forever!\n        if np.sqrt(np.sum(np.array(shift)**2))>tolerance:\n            print(\"Performed %d iterations but did not converge on the feature to within %.3fum\" % (n, tolerance))\n        else:\n            print(\"Centered on feature in %d iterations.\" % n)\n        if self.disable_live_view:\n            self.camera.live_view = camera_live_view",
  "def centre_on_feature_iterate(self, feature_image, search_size=(50,50), image_filter=lambda x: x):\n        \"\"\"Measure the displacement of the sample and move to correct it.\n        \n        Arguments:\n        feature_image : numpy.ndarray\n            This is the feature that should be at the centre of the camera.  It\n            must be smaller than the camera image + search size.\n        search_size : (int, int)\n            The distance in pixels to search over.  Defaults to (50,50).\n        image_filter : function (optional)\n            If supplied, run this function on the image before cross-correlating\n            (you can use this to cross-correlate in grayscale, for example).\n        \"\"\"\n        try:\n            self.flush_camera_and_wait()\n            current_image = image_filter(self.camera.color_image()) #get the current image\n            corr = cv2.matchTemplate(current_image,feature_image,cv2.TM_SQDIFF_NORMED) #correlate them: NB the match position is the MINIMUM\n            #restrict to just the search area, and invert so we find the maximum\n            corr = -corr[(corr.shape[0]/2. - search_size[0]/2.):(corr.shape[0]/2. + search_size[0]/2.),\n                         (corr.shape[1]/2. - search_size[1]/2.):(corr.shape[1]/2. + search_size[1]/2.)] #invert the image so we can find a peak\n            corr += (corr.max()-corr.min())*0.1 - corr.max() #background-subtract 90% of maximum\n            corr = cv2.threshold(corr, 0, 0, cv2.THRESH_TOZERO)[1] #zero out any negative pixels - but there should always be > 0 nonzero pixels\n            peak = ndimage.measurements.center_of_mass(corr) #take the centroid (NB this is of grayscale values not just binary)\n            self.move_to_camera_pixel(np.array(peak) - np.array(corr.shape[0:2])/2.+np.array(current_image.shape[0:2])/2.)\n            return self.camera_pixel_displacement_to_sample(np.array(peak) - np.array(corr.shape[0:2])/2.)\n        except Exception as e:\n            print(\"Exception: \", e)\n            print(\"Corr: \", corr)\n            print(\"Feature: \", feature_image)\n            print(\"Feature Size: \", feature_image.shape)\n            print(\"Corr size: \", corr.shape)\n            print(\"Peak: \", peak)\n            print(\"sum(corr): \", np.sum(corr))\n            print(\"max(corr): \", np.max(corr))\n            raise e",
  "def calibrate_in_background(self):\n        threading.Thread(target=self.calibrate).start()",
  "def calibrate(self, dx=None):\n        \"\"\"Move the stage in a square and set the transformation matrix.\"\"\"\n        try:\n            with self._action_lock:\n                if dx is None or dx is False: dx=self.calibration_distance #use a sensible default\n                here = self.camera_centre_position()\n                if len(self.stage.axis_names)==2:\n                    pos = [np.array([i,j]) for i in [-dx,dx] for j in [-dx,dx]]\n                elif len(self.stage.axis_names)==3:\n                    pos = [np.array([i,j,0]) for i in [-dx,dx] for j in [-dx,dx]]\n                print(pos, dx)\n                camera_pos = []\n                self.camera.update_latest_frame() # make sure we've got a fresh image\n                if self.filter_images==True and self.camera.filter_function != None:\n                    initial_image = self.camera.filter_function(self.camera.raw_image())\n                else:\n                    initial_image = self.camera.gray_image()\n                w, h, = initial_image.shape\n                template = initial_image[(w//4):(3*w//4),(h//4):(3*h//4)] #.astype(np.float)\n                #template -= cv2.blur(template, (21,21), borderType=cv2.BORDER_REPLICATE)\n        #        self.calibration_template = template\n        #        self.calibration_images = []\n                camera_live_view = self.camera.live_view\n                if self.disable_live_view:\n                    self.camera.live_view = False\n                for p in pos:\n                    self.move_to_sample_position(here + p)\n                    self.flush_camera_and_wait()\n                    if self.filter_images==True and self.camera.filter_function != None:\n                        current_image = self.camera.filter_function(self.camera.raw_image())\n                    else:\n                        current_image = self.camera.gray_image()\n                    corr = cv2.matchTemplate(current_image,template,cv2.TM_SQDIFF_NORMED)\n                    corr *= -1. #invert the image\n                    corr += (corr.max()-corr.min())*0.1 - corr.max() ##\n                    corr = cv2.threshold(corr, 0, 0, cv2.THRESH_TOZERO)[1]\n        #            peak = np.unravel_index(corr.argmin(),corr.shape)\n                    peak = ndimage.measurements.center_of_mass(corr)\n                    camera_pos.append(peak - ((np.array(current_image.shape) - \\\n                                                           np.array(template.shape))/2))\n        #            self.calibration_images.append({\"image\":current_image,\"correlation\":corr,\"pos\":p,\"peak\":peak})\n                self.move_to_sample_position(here)\n                self.flush_camera_and_wait()#otherwise we get a worrying \"jump\" when enabling live view...\n                self.camera.live_view = camera_live_view\n                #camera_pos now contains the displacements in pixels for each move\n                sample_displacement = np.array([-p[0:2] for p in pos]) #nb need to convert to 2D, and the stage positioning is flipped from sample coords\n                camera_displacement = np.array([self.camera_pixel_to_point(p) for p in camera_pos])\n                print(\"sample was moved (in um):\\n\",sample_displacement)\n                print(\"the image shifted (in fractions-of-a-camera):\\n\",camera_displacement)\n                A, res, rank, s = np.linalg.lstsq(camera_displacement, sample_displacement)\n                self.camera_to_sample = A\n        except Exception as e:\n            print('Calibration failed because', e)",
  "def flush_camera_and_wait(self):\n        \"\"\"take and discard a number of images from the camera to make sure the image is fresh\n        \n        This functionality should really be in the camera, not the aligner!\"\"\"\n        time.sleep(self.settling_time)\n        for i in range(self.frames_to_discard):\n            self.camera.raw_image()",
  "def acquire_tiled_image(self, n_images=(3,3), dest=None, overlap=0.33,\n                            autofocus_args={},live_plot=False, downsample=8):\n        \"\"\"Raster-scan the stage and take images, which we can later tile.\n\n        Arguments:\n        @param: n_images: A tuple of length 2 specifying the number of images\n        to take in X and Y\n        @param: dest: An HDF5 Group object to store the images in.  Each image\n        will be tagged with metadata to mark where it was taken.  If no dest\n        is specified, a new group will be created in the current datafile.\n        @param: overlap: the fraction of each image to overlap with the \n        adjacent one (it's important this is high enough to match them up)\n        @param: autofocus_args: A dictionary of keyword arguments for the\n        autofocus that occurs before each image is taken.  Set to None to\n        disable autofocusing.\n        \"\"\"\n        reset_interactive_mode = live_plot and not matplotlib.is_interactive()\n        if live_plot:\n            plt.ion()\n            fig = plt.figure()\n            axes = fig.add_subplot(111)\n            axes.set_aspect(1)\n            \n        with self._action_lock:\n            if dest is None:\n                dest = self.create_data_group(\"tiled_image_%d\") #or should this be in RAM??\n            centre_position = self.camera_centre_position()[0:2] #only 2D\n            x_indices = np.arange(n_images[0]) - (n_images[0] - 1)/2.0\n            y_indices = np.arange(n_images[1]) - (n_images[1] - 1)/2.0\n            for y_index in y_indices:\n                for x_index in x_indices:\n                    position = centre_position + self.camera_point_displacement_to_sample(np.array([x_index, y_index]) * (1-overlap))\n                    self.move_to_sample_position(position) #go to the raster point\n                    if autofocus_args is not None:\n                        self.autofocus(**autofocus_args)\n                    self.flush_camera_and_wait() #wait for the camera to be ready/stage to settle\n                    tile = dest.create_dataset(\"tile_%d\", \n                                               data=self.camera.color_image(),\n                                               attrs=self.camera.metadata)\n                    tile.attrs.create(\"stage_position\",self.stage.position)\n                    tile.attrs.create(\"camera_centre_position\",self.camera_centre_position())\n                    if live_plot:\n                        #Plot the image, in sample coordinates\n                        corner_points = np.array([self.camera_point_to_sample((xcorner,ycorner)) \n                                                for ycorner in [0,1] for xcorner in [0,1]]) #positions of corners\n                        plot_skewed_image(tile[::downsample, ::downsample, :],\n                                          corner_points, axes=axes)\n                        fig.canvas.draw()\n                x_indices = x_indices[::-1] #reverse the X positions, so we do a snake-scan\n            dest.attrs.set(\"camera_to_sample\",self.camera_to_sample)\n            dest.attrs.set(\"camera_centre\",self.camera_centre)\n            self.move_to_sample_position(centre_position) #go back to the start point\n        if reset_interactive_mode:\n            plt.ioff()\n        return dest",
  "def autofocus_merit_function(self): # we maximise this...\n        \"\"\"Take an image and calculate the focus metric, this is what we optimise.\n        \n        Currently, this calculates the sum of the square of the Laplacian of the image\n        which should pick out sharp features quite effectively.  It can, however, be\n        thrown off by very bright objects if the camera is saturated.\"\"\"\n        self.flush_camera_and_wait()\n#        self.camera.update_latest_frame() #take an extra frame to make sure this one is fresh\n        if self.filter_images == True and self.camera.filter_function != None:\n            img = self.camera.filter_function(self.camera.raw_image())\n        else:\n            img = self.camera.raw_image()\n        if np.shape(img)[-1]==3:\n            img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n#        return np.sum((img - cv2.blur(img,(21,21))).astype(np.single)**2)\n        return np.sum(cv2.Laplacian(img, ddepth=cv2.CV_32F)**2)",
  "def autofocus_in_background(self):\n        def work():\n            self.autofocus_iterate(np.arange(old_div(-self.autofocus_range,2), old_div(self.autofocus_range,2), self.autofocus_step))\n        threading.Thread(target=work).start()",
  "def autofocus_iterate(self, dz, method=\"centre_of_mass\", noise_floor=0.3):\n        self._action_lock.acquire()\n        \"\"\"Move in z and take images.  Move to the sharpest position.\"\"\"\n        here = self.stage.position\n        positions = [here]                              #positions keeps track of where we sample\n        powers = [self.autofocus_merit_function()]      #powers holds the value of the merit fn at each point\n        camera_live_view = self.camera.live_view\n        if self.disable_live_view:\n            self.camera.live_view = False\n        for z in dz:\n            self.stage.move(np.array([0,0,z])+here)     #visit each point and evaluate merit function\n #           time.sleep(0.5)\n            positions.append(self.stage.position)\n            powers.append(self.autofocus_merit_function())\n        powers = np.array(powers)\n        positions = np.array(positions)\n        z = positions[:,2] \n        if method==\"centre_of_mass\":\n            threshold = powers.min() + (powers.max()-powers.min())*noise_floor #(powers.min() if len(powers)<4 else np.max([powers[z.argmin()],powers[z.argmax()]])) #ensure edges are zero\n            weights = powers - threshold\n            weights[weights<0] = 0. #zero out any negative values\n            if(np.sum(weights)==0): \n                new_position = positions[powers.argmax(),:]\n            else: \n                new_position = old_div(np.dot(weights, positions),np.sum(weights))\n        elif method==\"parabola\":\n            coefficients = np.polyfit(z, powers, deg=2) #fit a parabola\n            root = old_div(-coefficients[1],(2*coefficients[0])) #p = c[0]z**\" + c[1]z + c[2] which has max (or min) at 2c[0]z + c[1]=0 i.e. z=-c[1]/2c[0]\n            if z.min() < root and root < z.max():\n                new_position = [here[0],here[1],root]\n            else:\n                new_position = positions[powers.argmax(),:]\n        else:\n            new_position = positions[powers.argmax(),:]\n        self.stage.move(new_position)\n        self.camera.live_view = camera_live_view\n        self._action_lock.release()\n        return new_position-here, positions, powers",
  "def autofocus(self, ranges=None, max_steps=10):\n        \"\"\"move the stage to bring the sample into focus\n        \n        Presently, it just does one iteration for each range passed in: usually\n        this would mean a coarse focus then a fine focus.\n        \"\"\" #NEEDS WORK!\n        if ranges is None or ranges is False:\n            ranges = self.autofocus_default_ranges\n        n=0\n        for r in ranges:\n            pos = self.autofocus_iterate(r)[0]\n            print(\"moving Z by %.3f\" % pos[2])\n            n+=1\n        print(\"Autofocus: performed %d iterations\" % n)",
  "def get_qt_ui(self):\n        return CameraStageMapperControlWidget(self)",
  "def __init__(self, camerastagemapper):\n        super(CameraStageMapperControlWidget, self).__init__()\n        self.camerastagemapper = camerastagemapper\n        self.load_ui_from_file(__file__,\"camerastagemapper.ui\")\n        self.auto_connect_by_name(controlled_object=self.camerastagemapper, verbose=True)",
  "def work():\n            self.autofocus_iterate(np.arange(old_div(-self.autofocus_range,2), old_div(self.autofocus_range,2), self.autofocus_step))",
  "class ProScan(serial.SerialInstrument, stage.Stage):\n    \"\"\"\n    This class handles the Prior stage.\n    \"\"\"\n    port_settings = dict(baudrate=9600,\n                        bytesize=serial.EIGHTBITS,\n                        parity=serial.PARITY_NONE,\n                        stopbits=serial.STOPBITS_TWO,\n                        timeout=1, #wait at most .one second for a response\n                        writeTimeout=1, #similarly, fail if writing takes >1s\n                        xonxoff=False, rtscts=False, dsrdtr=False,\n                    )\n    termination_character = \"\\r\" #: All messages to or from the instrument end with this character.\n    termination_line = \"END\" #: If multi-line responses are recieved, they must end with this string\n\n    def __init__(self, port=None, use_si_units=False, hardware_version=None):\n        \"\"\"\n        Set up the serial port and so on. \n        If the controller is a ProScan II not a ProScan III. \n        The hardware_version must be set to two or the Stopbit value will be incorrect\n        \"\"\"\n        if hardware_version == 2:\n            self.port_settings['stopbits'] = serial.STOPBITS_ONE\n        serial.SerialInstrument.__init__(self, port=port) #this opens the port\n        stage.Stage.__init__(self,unit = 'u') #this opens the port\n        \n        self.query(\"COMP O\") #enable full-featured serial interface\n        \n#        try: #get the set-up parameters\n        self.microstepsPerMicron = self.parsed_query(\"STAGE\",r\"MICROSTEPS/MICRON = %d\",termination_line=\"END\")\n        self.query(\"RES s %f\" % (1/self.microstepsPerMicron)) #set the resolution to 1 microstep\n        self.resolution = self.float_query(\"RES s\")\n#        except:\n#            raise Exception(\"Could not establish stage parameters, maybe the com port is wrong?\")\n        if re.search(\"FOCUS = NONE\", self.query(\"FOCUS\",termination_line=\"END\")) is None:\n            self.zAxisPresent = False\n        else:\n            self.query(\"UPR Z %d\" % 100) #set 100 microns per revolution on the Z drive (for BX51)\n            self.query(\"RES Z %f\" % self.resolution) #make resolution isotropic :)\n        \n        self.query(\"ENCODER 1\") #turn on encoders (if present)\n        self.query(\"SERVO 0\") #turn off servocontrol\n        self.query(\"BLSH 0\") #turn off backlash control for xy\n        \n        self.use_si_units = use_si_units\n        self.axis_names = ('x', 'y', 'z')\n        \n    def move_rel(self, dx, block=True):\n        \"\"\"Make a relative move by dx microns/metres (see move)\"\"\"\n        return self.move(dx, relative=True, block=block)\n\n    def move(self, x, relative=False, axis=None, block=True):\n        \"\"\"\n        Move to coordinate x (a np.array of coordinates) in microns, or metres if use_si_units is true\n        \n        By default we block until the move is over (if possible), if wait==False\n        we return immediately.  relative=True does relative motion, otherwise\n        motion is absolute.\n        \"\"\"\n        querystring = \"G\"\n        if axis is not None and relative:\n            # single-axis emulation is fine for relative moves\n            return self.move_axis(x, axis, relative=relative, block=block)\n        elif axis is not None and not relative:\n            # single-axis absolute move\n            assert axis.lower() in self.axis_names, ValueError(\"{0} is not a valid axis name.\".format(axis))\n            querystring += axis.upper()\n            x = [x]\n        elif axis is None and relative:\n            # relative move\n            querystring += \"R\"\n        if self.use_si_units: x = np.array(x) * 1e6\n        for i in range(len(x)): querystring += \" %d\" % int(x[i]/self.resolution)\n        self.query(querystring)\n        time_0 = time.time()\n        #position_0 = self.position\n        #print position_0\n        try:\n            if(block):\n                while(self.is_moving()):\n                    time.sleep(0.02)\n                    if(time.time()-time_0>20): # Set move timelimit in case stage gets stuck\n                       # new_position = self.position                        \n                        print(x, end=' ')\n                        print(self.position)\n                        #if(new_position == position_0).all(): #Allow moves that take greater than timelimit             \n                        self.emergency_stop()\n                        self.move(x, relative, axis, block)\n        except KeyboardInterrupt:\n            self.emergency_stop()\n\n    def move_axis(self, pos, axis, relative=False, **kwargs):\n        \"\"\"Move along one axis\"\"\"\n        # We use the built-in emulation for relative moves\n        if relative:\n            return stage.Stage.move_axis(self, pos, axis, relative=True, **kwargs)\n        else:\n            return self.move(pos, axis=axis, relative=relative, **kwargs)\n\n    def get_position(self, axis=None):\n        \"\"\"return the current position in microns\"\"\"\n        if axis is not None:\n            return self.select_axis(self.get_position(), axis)\n        else:\n            pos = self.parsed_query('P',r\"%f,%f,%f\")\n            if self.use_si_units:\n                pos = np.array(pos)/1e6\n            return np.array(pos) * self.resolution\n\n    position = property(get_position)\n\n    def is_moving(self):\n        \"\"\"return true if the stage is in motion\"\"\"\n        return self.int_query(\"$,S\")>0\n\n    def emergency_stop(self):\n        return self.query(\"K\")\n\n    def test_communications(self):\n        \"\"\"Check there is a prior stage at the other end of the COM port.\"\"\"\n        response = self.query(\"?\",multiline=True)\n        if response.startswith(\"PROSCAN\"):\n            return True\n        else:\n            return False\n    @property\n    def max_speed_z(self):\n        return self.query('SMZ')\n    \n    @max_speed_z.setter\n    def max_speed_z(self, speed):\n        return self.query(f'SMZ {int(speed)}')\n    \n    def disable_joy(self):\n        self.query('H')\n    def enable_joy(self):\n        self.query('J')",
  "def __init__(self, port=None, use_si_units=False, hardware_version=None):\n        \"\"\"\n        Set up the serial port and so on. \n        If the controller is a ProScan II not a ProScan III. \n        The hardware_version must be set to two or the Stopbit value will be incorrect\n        \"\"\"\n        if hardware_version == 2:\n            self.port_settings['stopbits'] = serial.STOPBITS_ONE\n        serial.SerialInstrument.__init__(self, port=port) #this opens the port\n        stage.Stage.__init__(self,unit = 'u') #this opens the port\n        \n        self.query(\"COMP O\") #enable full-featured serial interface\n        \n#        try: #get the set-up parameters\n        self.microstepsPerMicron = self.parsed_query(\"STAGE\",r\"MICROSTEPS/MICRON = %d\",termination_line=\"END\")\n        self.query(\"RES s %f\" % (1/self.microstepsPerMicron)) #set the resolution to 1 microstep\n        self.resolution = self.float_query(\"RES s\")\n#        except:\n#            raise Exception(\"Could not establish stage parameters, maybe the com port is wrong?\")\n        if re.search(\"FOCUS = NONE\", self.query(\"FOCUS\",termination_line=\"END\")) is None:\n            self.zAxisPresent = False\n        else:\n            self.query(\"UPR Z %d\" % 100) #set 100 microns per revolution on the Z drive (for BX51)\n            self.query(\"RES Z %f\" % self.resolution) #make resolution isotropic :)\n        \n        self.query(\"ENCODER 1\") #turn on encoders (if present)\n        self.query(\"SERVO 0\") #turn off servocontrol\n        self.query(\"BLSH 0\") #turn off backlash control for xy\n        \n        self.use_si_units = use_si_units\n        self.axis_names = ('x', 'y', 'z')",
  "def move_rel(self, dx, block=True):\n        \"\"\"Make a relative move by dx microns/metres (see move)\"\"\"\n        return self.move(dx, relative=True, block=block)",
  "def move(self, x, relative=False, axis=None, block=True):\n        \"\"\"\n        Move to coordinate x (a np.array of coordinates) in microns, or metres if use_si_units is true\n        \n        By default we block until the move is over (if possible), if wait==False\n        we return immediately.  relative=True does relative motion, otherwise\n        motion is absolute.\n        \"\"\"\n        querystring = \"G\"\n        if axis is not None and relative:\n            # single-axis emulation is fine for relative moves\n            return self.move_axis(x, axis, relative=relative, block=block)\n        elif axis is not None and not relative:\n            # single-axis absolute move\n            assert axis.lower() in self.axis_names, ValueError(\"{0} is not a valid axis name.\".format(axis))\n            querystring += axis.upper()\n            x = [x]\n        elif axis is None and relative:\n            # relative move\n            querystring += \"R\"\n        if self.use_si_units: x = np.array(x) * 1e6\n        for i in range(len(x)): querystring += \" %d\" % int(x[i]/self.resolution)\n        self.query(querystring)\n        time_0 = time.time()\n        #position_0 = self.position\n        #print position_0\n        try:\n            if(block):\n                while(self.is_moving()):\n                    time.sleep(0.02)\n                    if(time.time()-time_0>20): # Set move timelimit in case stage gets stuck\n                       # new_position = self.position                        \n                        print(x, end=' ')\n                        print(self.position)\n                        #if(new_position == position_0).all(): #Allow moves that take greater than timelimit             \n                        self.emergency_stop()\n                        self.move(x, relative, axis, block)\n        except KeyboardInterrupt:\n            self.emergency_stop()",
  "def move_axis(self, pos, axis, relative=False, **kwargs):\n        \"\"\"Move along one axis\"\"\"\n        # We use the built-in emulation for relative moves\n        if relative:\n            return stage.Stage.move_axis(self, pos, axis, relative=True, **kwargs)\n        else:\n            return self.move(pos, axis=axis, relative=relative, **kwargs)",
  "def get_position(self, axis=None):\n        \"\"\"return the current position in microns\"\"\"\n        if axis is not None:\n            return self.select_axis(self.get_position(), axis)\n        else:\n            pos = self.parsed_query('P',r\"%f,%f,%f\")\n            if self.use_si_units:\n                pos = np.array(pos)/1e6\n            return np.array(pos) * self.resolution",
  "def is_moving(self):\n        \"\"\"return true if the stage is in motion\"\"\"\n        return self.int_query(\"$,S\")>0",
  "def emergency_stop(self):\n        return self.query(\"K\")",
  "def test_communications(self):\n        \"\"\"Check there is a prior stage at the other end of the COM port.\"\"\"\n        response = self.query(\"?\",multiline=True)\n        if response.startswith(\"PROSCAN\"):\n            return True\n        else:\n            return False",
  "def max_speed_z(self):\n        return self.query('SMZ')",
  "def max_speed_z(self, speed):\n        return self.query(f'SMZ {int(speed)}')",
  "def disable_joy(self):\n        self.query('H')",
  "def enable_joy(self):\n        self.query('J')",
  "class GSC01(SerialInstrument, Stage):\n    \"\"\"\n    Stage controller GSC-01\n    \"\"\"\n\n    counts_per_degree = 400.\n    axis_names = ('1', )\n    metadata_property_names = ('position', )\n\n    def __init__(self, address, **kwargs):\n\n        self.port_settings = dict(baudrate=9600,\n                                  bytesize=8,\n                                  stopbits=1,\n                                  parity='N',\n                                  xonxoff=True,\n                                  timeout=0.5,\n                                  writeTimeout=0.5,\n                                  rtscts=True\n                                  )\n        SerialInstrument.__init__(self, address)\n        self.termination_character = '\\r\\n'\n        Stage.__init__(self)\n\n        if 'offsetOrigin' in kwargs:\n            self.offsetOrigin(kwargs['offsetOrigin'])  # 20000)\n\n        if 'home_on_start' in list(kwargs.keys()):\n            if kwargs['home_on_start']:\n                self.MechanicalHome()\n\n    def __del__(self):\n        try:\n            self.ser.close()\n        except:\n            self._logger.warn(\"Couldn't close GSC01\")\n\n    def wait(self):\n        while self.getACK3() != 'R':\n            time.sleep(0.1)\n            # pass\n\n    def write_cmd(self, command, read=True, wait=False):\n        '''\n        :param command: serial command to send to device\n        :param read: if True, reads out standard 'OK' or 'NG' reply from the GSC-01\n        :param fname: name of calling function, only useful when verbose\n        :return:\n        '''\n\n        self.write(command)\n\n        if read:\n            reply = self.readline()\n            self._logger.debug('[%s]: %s' % (command, reply))\n        else:\n            reply = self.readline()\n            if reply != 'OK\\n':\n                self._logger.warn('%s replied %s' % (command, reply))\n\n        if wait:\n            self.wait()\n\n        return reply\n\n    def MechanicalHome(self):\n        '''\n        This command is used to detect the mechanical origin for a stage and set that position as the origin. The moving\n        speed S: 500pps, F:5000ps, R:200mS. Running a stop command suspends the operation. Any other commands are not\n        acceptable.\n        :return:\n        '''\n        self.write_cmd('H:1', read=False, wait=True)\n\n    def initializeOrigin(self):\n        \"\"\"\n        Sets the origin to the current position.\n        \"\"\"\n        self.write('R:1')\n\n    def offsetOrigin(self, steps):\n        \"\"\"\n        Sets and offset to the homing command, so that the origin is not beside the limit sensors\n        Effective only for the homing operation in MINI system. Value is initialised to zero when turning power off.\n        :param steps: offset steps (integer)\n        :return:\n        \"\"\"\n\n        self.write('S:N%d' % steps)\n\n    @locked_action\n    def move(self, pos, axis=None, relative=False, wait=True):\n        counts = self.counts_per_degree * pos\n        if relative:\n            if not (-16777214 <= counts <= 16777214):\n                raise ValueError('stage1 must be between -16777214 and 16777214.')\n\n            command = 'M:W'\n            if counts >= 0:\n                command += '+P%d' % counts\n            else:\n                command += '-P%d' % -counts\n        else:\n            command = 'A:W'\n            if counts >= 0:\n                command += '+P%d' % counts\n            else:\n                command += '-P%d' % -counts\n        self.write_cmd(command, read=False)\n        self._go()\n\n        if wait:\n            t0 = time.time()\n            curpos = self.get_position()[0]\n            while curpos != pos and time.time()-t0 < 10:\n                curpos = self.get_position()[0]\n                time.sleep(0.1)\n\n    def get_position(self, axis=None):\n        status = self.getStatus()\n        counts = status.split(',')[0]\n        position = float(counts)/self.counts_per_degree\n        self._logger.debug('Status: %s. Counts: %s. Position returned %g' %(status, counts, position))\n        return [position]\n\n    def jog(self, direction, timeout=2):\n        \"\"\"\n        Moves stage continuously at jogging speed for specified length of time.\n        :param direction: either '+' or '-'\n        :param timeout: in seconds\n        :return:\n        \"\"\"\n\n        self.write('J:1%s' % direction)\n        t0 = time.time()\n        self._go()\n        while time.time() - t0 < timeout:\n            time.sleep(0.1)\n        self.decelerate()\n\n    def _go(self):\n        \"\"\"\n        Moves the stages. To be used internally.\n        \"\"\"\n        self.write_cmd('G:', read=False)\n\n    def decelerate(self):\n        \"\"\"\n        Decelerates and stop the stages.\n        \"\"\"\n        self.write('L:1')\n\n    def stop(self):\n        \"\"\"\n        Stops the stages immediately.\n        \"\"\"\n        self.write('L:E')\n\n    def setSpeed(self, minSpeed1, maxSpeed1, accelerationTime1):\n        \"\"\"\n        Set minimum and maximum speeds and acceleration time.\n        :param minSpeed1: between 100 and 20000, in steps of 100 [PPS]\n        :param maxSpeed1: between 100 and 20000, in steps of 100 [PPS]\n        :param accelerationTime1: between 0 and 1000 [ms]\n        :return:\n        \"\"\"\n        if not (100 <= minSpeed1 <= maxSpeed1 <= 20000):\n            raise ValueError('Must be 100 <= minSpeed1 <= maxSpeed1 <= 20000')\n\n        if not (0 <= accelerationTime1 <= 1000):\n            raise ValueError('Must be 00 <= accelerationTime1 <= 1000.')\n\n        self.write('D:1S%dF%dR%d' % (minSpeed1, maxSpeed1, accelerationTime1))\n\n    def setJogSpeed(self, speed):\n        \"\"\"\n        Set jog speed\n        :param speed: between 100 and 20000, in steps of 100 [PPS]\n        :return:\n        \"\"\"\n        if 100 < speed < 20000:\n            raise ValueError('Speed must be in 100-20000 range')\n\n        self.write('S:J%d' % speed)\n\n    def enableMotorExcitation(self, stage1=True):\n        \"\"\"\n        Turn motor on/off\n        :param stage1: True (on) or False (off)\n        :return:\n        \"\"\"\n\n        self.write('C:1%d' % stage1)\n\n    def getStatus(self):\n        \"\"\"\n        Gets the current status, consisting of position, command status, stop status, and motor readiness\n        :return: position, ACK1, ACK2, ACK3\n                ACK1:   X   Command Error\n                        K   Command accepted normally\n                ACK2:   L   Limit Sensor stop\n                        K   Normal stop\n                ACK3:   B   Busy\n                        R   Ready\n        \"\"\"\n        return self.write_cmd('Q:')\n\n    def getACK3(self):\n        \"\"\"\n        :return: 'R' if motor ready, 'B' if motor busy\n        \"\"\"\n        self.write_cmd('!:', read=False)\n        return self.readline()\n\n    def getVersion(self):\n        \"\"\"\n        Returns the ROM version\n        \"\"\"\n        self.write('?:V', read=False)\n        return self.readline()",
  "class SHOT(VisaInstrument, Stage):\n    \"\"\"\n    https://www.global-optosigma.com/en_jp/software/motorize/manual_en/SHOT-102.zip\n    \"\"\"\n    axis_names = ('1', '2')\n\n    def __init__(self, address, **kwargs):\n\n        self.port_settings = dict(baudrate=38400,\n                                  bytesize=8,\n                                  stopbits=1,\n                                  parity='N',\n                                  xonxoff=True,\n                                  timeout=0.5,\n                                  writeTimeout=0.5,\n                                  rtscts=True\n                                  )\n        VisaInstrument.__init__(self, address)\n        self.termination_character = '\\r\\n'\n        Stage.__init__(self, unit=\"step\")\n\n    def _rom_version(self):\n        \"\"\"\n        Request an internal ROM version from the controller.\n        :return: str, ROM version\n        \"\"\"\n        return self.query(\"?:V\")\n\n    def _go(self, wait=True):\n        \"\"\"\n        Moves the stages. To be used internally.\n        \"\"\"\n        self._write_check('G:', wait=wait)\n\n    @locked_action\n    def _write_check(self, command, wait=False):\n        self._logger.debug(\"Writing: %s\" %command)\n        self.write(command)\n        self._logger.debug(\"Writing successful\")\n        reply = self.read()\n        self._logger.debug(\"Read: %s\" %reply)\n\n        if reply == 'NG\\n':\n            self._logger.warn('%s replied %s' % (command, reply))\n        else:\n            if wait:\n                self._wait()\n            return reply\n\n    def _wait(self):\n        \"\"\"\n        Wait until controller is ready\n        \"\"\"\n        while self.is_busy():\n            time.sleep(0.1)\n\n    def home(self, axis=\"W\", direction=\"+\"):\n        \"\"\"\n        Detects the machine zero on the stage, and define the position as the home position\n        :param axis: either 1, 2 or W (for both)\n        :param direction: either + or -\n        :return:\n        \"\"\"\n\n        self._write_check(\"H:%s%s\" % (axis, direction))\n\n    def set_origin(self, axis=\"W\"):\n        \"\"\"\n        Sets the origin to the current position.\n        :param axis: either 1, 2 or W (for both)\n        \"\"\"\n\n        self._write_check('R:' + str(axis))\n\n    def move(self, counts, axis=1, relative=False, wait=True):\n        \"\"\"\n\n        :param counts: either an integer, or a tuple of two integers. Positive or negative\n        :param axis: either 1, 2 or W (for both)\n        :param relative:\n        :param wait:\n        :return:\n        \"\"\"\n        if not hasattr(counts, '__iter__'):\n            counts = (counts, )\n        for count in counts:\n            if not (-16777214 <= count <= 16777214):\n                raise ValueError('stage1 must be between -16777214 and 16777214.')\n\n        if relative:\n            command = \"M:\"\n        else:\n            command = \"A:\"\n\n        if not hasattr(axis, '__iter__'):\n            command += str(axis)\n        else:\n            command += 'W'\n        for count in counts:\n            if count >= 0:\n                command += '+P%d' % count\n            else:\n                command += '-P%d' % -count\n\n        self._write_check(command, wait=wait)\n        self._go(wait=wait)\n\n    def get_position(self, axis=None):\n        status = self.status()\n        counts = list(map(int, status.split(',')[:2]))\n        if axis is None:\n            axis = self.axis_names\n        elif not isinstance(axis, list) and not isinstance(axis, tuple):\n            axis = [axis]\n        return [self.select_axis(counts, ax) for ax in axis]\n\n    def jog(self, axis=\"W\", direction=\"+\", timeout=2):\n        \"\"\"\n        Moves stage continuously at jogging speed for specified length of time.\n\n        :param axis: either 1, 2 or W (for both)\n        :param direction: either + or -\n        :param timeout: amount of seconds to jog for\n        :return:\n        \"\"\"\n\n        self._write_check(\"J:%s%s\" % (axis, direction))\n\n        t0 = time.time()\n        self._go()\n        while time.time() - t0 < timeout:\n            time.sleep(0.1)\n        self.decelerate()\n\n    def decelerate(self, axis=\"W\"):\n        \"\"\"\n        Decelerates and stop the stages.\n        :param axis: either 1, 2 or W (for both)\n        \"\"\"\n\n        self._write_check('L:' + str(axis))\n\n    def emergency_stop(self):\n        \"\"\"\n        Stops the stages immediately.\n        \"\"\"\n        self.write('L:E')\n\n    def set_speed(self, axes, min_speed, max_speed, accel_time):\n        \"\"\"Changing the movement speed\n        On turning ON the power, SHOT-102 will default a minimum speed (S), maximum speed (F), and\n        acceleration/deceleration time (R), all set by switches 9 and 10 on DIP Switch 1 for each speed range.\n        :param axis: either 1, 2 or W (for both)\n        :param min_speed: integer or tuple of two integers\n        :param max_speed: integer or tuple of two integers\n        :param accel_time: integer or tuple of two integers\n        :return:\n        \"\"\"\n\n        if not (1 <= min_speed <= max_speed <= 20000):\n            raise ValueError('Must be 1 <= min_speed <= max_speed <= 20000')\n        if not (0 <= accel_time <= 5000):\n            raise ValueError('Must be 0 <= accel_time <= 5000')\n        if not hasattr(min_speed, \"__iter__\"):\n            min_speed = tuple(min_speed)\n        if not hasattr(max_speed, \"__iter__\"):\n            max_speed = tuple(max_speed)\n        if not hasattr(accel_time, \"__iter__\"):\n            accel_time = tuple(accel_time)\n        if axes == \"W\":\n            if len(min_speed) != 2 or len(min_speed) != 2 or len(min_speed) != 2:\n                raise ValueError('You need to provide speeds and times for both axis')\n\n        command = \"D:%s\" %axes\n        for mn, mx, at in zip(min_speed, max_speed, accel_time):\n            command += \"S\" + str(mn) + \"F\" + str(mx) + \"R\" + str(at)\n        self._write_check(command)\n\n    def on_off(self, axes, state):\n        \"\"\"\n        Deenergizes (motor free) or Energizes (hold) the motor.\n        Execute this command to move (rotate) stages manually. Once executed, the actual stage position does not\n        coincide with the coordinate value being displayed. For proper positioning, perform zero return and make the\n        stage position consistent with the coordinate value being displayed.\n        :param axes: either 1, 2 or W (for both)\n        :param state: 0 (off) or 1 (on)\n        :return:\n        \"\"\"\n        self._write_check(\"C:%s%s\" % (axes, state))\n\n    def status(self):\n        \"\"\"\n        A command to check the validity of an immediately preceding command, and request a controller to return the\n        state of stage operations, coordinates of axes, etc.\n        :return: str coord_1, coord_2, ACK1, ACK2, ACK3\n            coordinates are 10-digit data including sign (positive is space)\n            ACK1:   X - command or parameter error\n                    K - successful command\n            ACK2:   L - axis 1 emergency stop\n                    M - axis 2 emergency stop\n                    W - both axis emergency stop\n                    K - normal stop\n            ACK3:   B - busy\n                    R - ready\n        \"\"\"\n        return self.query(\"Q:\")\n\n    def is_busy(self):\n        \"\"\"\n\n        :return: bool\n        \"\"\"\n        reply = self.query(\"!:\")\n\n        if \"B\" in reply:\n            return True\n        else:\n            return False",
  "class HIT(SerialInstrument, Stage):\n    \"\"\"\n    Stage controller for the many-axis HIT controller.\n\n    https://www.global-optosigma.com/en_jp/software/motorize/manual_en/HIT_En.pdf\n    \"\"\"\n\n    # TODO: interpolation commands. They set a position in the plane of two axes and jog in a curved or straight path\n    # TODO: add units\n\n    axis_names = list(map(str, list(range(8))))\n    axis_LUT = dict(list(zip(list(map(str, list(range(8)))), list(range(8)))))\n\n    def __init__(self, address, **kwargs):\n\n        self.port_settings = dict(baudrate=38400,\n                                  bytesize=8,\n                                  stopbits=1,\n                                  parity='N',\n                                  xonxoff=True,\n                                  timeout=0.5,\n                                  writeTimeout=0.5,\n                                  rtscts=True\n                                  )\n        SerialInstrument.__init__(self, address)\n        self.termination_character = '\\r\\n'\n        Stage.__init__(self, unit=\"step\")\n\n    def _axes_iterable(self, axes=None):\n        \"\"\"Convenience function\n\n        Given a list of axes names or axes numbers (can be mixed), returns an list of the corresponding axes numbers\n        using axis_LUT\n\n        :param axes: list of axes names or number (can be mixed)\n        :return:\n        \"\"\"\n        if axes is None:\n            axes = self.axis_names\n        if not isinstance(axes, list) and not isinstance(axes, tuple):\n            axes = (axes, )\n        axes_iter = []\n        for ax in axes:\n            if ax in list(self.axis_LUT.keys()):\n                axes_iter += [self.axis_LUT[ax]]\n            elif type(ax) == int:\n                axes_iter += [ax]\n            else:\n                raise ValueError(\"Unrecognised axis: %s %s\" % (ax, type(ax)))\n        return axes_iter\n\n    def move(self, counts, axes=None, relative=False, wait=True):\n        \"\"\"\n\n        :param counts: (int) number of motor steps. If iterable, should be same length as axes.\n        :param axes: list of axes\n        :param relative: (bool)\n        :param wait: bool\n        :return:\n        \"\"\"\n        axes = self._axes_iterable(axes)\n        if not hasattr(counts, '__iter__'):\n            counts = [counts] * len(axes)\n        for count in counts:\n            assert -134217728 < count < +134217727\n        counts = list(map(int, counts))\n\n        if relative:\n            command = 'M'\n        else:\n            command = 'A'\n\n        self.multi_axis_cmd(command, axes, counts, wait)\n\n        # TODO: add checking for Stage limits using status +-LS\n\n    def get_position(self, axes=None):\n        axes = self._axes_iterable(axes)\n        all_positions = self.query(\"Q:\").split(\",\")\n        positions = []\n        for ax in axes:\n            try:\n                positions += [int(all_positions[ax])]\n            except ValueError:\n                positions += [None]\n        return positions\n\n    def status(self, axes=None):\n        \"\"\"\n\n        :param axes: list of strings/integers corresponding to the names or indices of the axes, or a single string/integer\n        :return: string corresponding to the overall status, and a dictionary for the individual axes' status\n        \"\"\"\n        bit_list = [\"\", \"DRV alarm\", \"Scale alarm\", \"Z limit\", \"Near\", \"ORG\", \"+LS\", \"-LS\"]\n        raw_statuses = self.query(\"Q:S\").split(\",\")\n        status = []\n        for rs in raw_statuses:\n            try:\n                # Converting to 8-bit hexadecimal. https://stackoverflow.com/questions/1425493/convert-hex-to-binary\n                _bin = bin(int(rs, 16))[2:].zfill(8)\n                _status = []\n                for bit, bit_name in zip(_bin, bit_list):\n                    if bool(int(bit)):\n                        _status += [bit_name]\n                if len(_status) > 0:\n                    status += [_status]\n                else:\n                    status += [\"OK\"]\n            except ValueError:\n                status += [None]\n        overall_status = status[0]\n        axes_status = status[1:]\n\n        axes = self._axes_iterable(axes)\n        reply = dict()\n        for name, indx in zip(self.axis_names, axes):\n            reply[name] = axes_status[indx]\n        return overall_status, reply\n\n    def is_moving(self, axes=None):\n        axes = self._axes_iterable(axes)\n        statuses = self.query(\"!:\").split(\",\")\n        status = []\n        for ax in axes:\n            status += [bool(int(statuses[ax]))]  # converting a '0' or '1' to a False or True\n        return any(status)\n\n    @locked_action\n    def write_check(self, command, wait=False):\n        \"\"\"\n        Light wrapper providing error checking, locking and waiting\n\n        :param command: full serial command to send to device\n        :param wait: bool\n        :return:\n        \"\"\"\n        self.write(command)\n\n        reply = self.readline()[:-1]  # excluding the \\n termination\n        self._logger.debug(\"Reply: %s\" % reply)\n\n        if reply == 'NG':\n            self._logger.warn('%s replied %s' % (command, reply))\n        else:\n            if wait:\n                self.wait_until_stopped()\n            return reply\n\n    def multi_axis_cmd(self, command, axes, parameters, wait=False):\n        \"\"\"Convenience function\n\n        Creates commands with the appropriate parameters in the appropriate places.\n        e.g. by simply giving 'H', None, 1 it creates the command H:,1,,,1,,,1 (assuming the stage has three active axes at positions 1, 4 and 7\n\n        :param command: command code to send to device\n        :param axes: axes name or index (or list of)\n        :param parameters: list of parameters to pass. If iterable, it passes each item to each of the axes. Otherwise it passes the same argument to all axes\n        :param wait: if True, calls self.wait before returning\n        :return:\n        \"\"\"\n        axes_iter = self._axes_iterable(axes)\n\n        if not hasattr(parameters, \"__iter__\"):\n            parameters = [parameters] * len(axes_iter)\n        if len(parameters) != len(axes_iter):\n            raise ValueError(\"Length of axes and parameters must be the same\")\n\n        self._logger.debug(\"Axes: %s axes_iter: %s Parameters: %s\" % (axes, axes_iter, parameters))\n\n        argument_list = ['DUMMY']*8\n        for ax, param in zip(axes_iter, parameters):\n            argument_list[ax] = str(param)\n        argument_string = ','.join(argument_list)\n        argument_string = argument_string.replace('DUMMY', '')\n        command += ':' + argument_string\n        self._logger.debug('Writing: %s' % command)\n\n        self.write_check(command, wait)\n\n    def mechanical_home(self, axes=None):\n        \"\"\"\n        This command is used to detect the mechanical origin for a stage and set that position as the origin. The moving\n        speed S: 500pps, F:5000ps, R:200mS. Running a stop command suspends the operation. Any other commands are not\n        acceptable.\n        :param axes: axes name or index (or list of)\n        :return:\n        \"\"\"\n        self.multi_axis_cmd('H', axes, 1, wait=True)\n\n    def set_home(self, axes=None):\n        \"\"\"\n        Sets the origin to the current position.\n        :param axes: axes name or index (or list of)\n        :return:\n        \"\"\"\n        self.multi_axis_cmd('R', axes, 1)\n\n    def jog(self, directions, axes=None, timeout=2):\n        \"\"\"\n        Moves stage continuously at jogging speed for specified length of time.\n        :param directions: a single value or iterable of either '+' or '-'\n        :param axes:\n        :param timeout: in seconds\n        :return:\n        \"\"\"\n\n        # TODO: make the write_check non-blocking for this to work\n        raise NotImplementedError\n        # self.multi_axis_cmd('J', axes, directions)\n        # t0 = time.time()\n        # while time.time() - t0 < timeout:\n        #     time.sleep(0.1)\n        # self.decelerate(axes)\n\n    def decelerate(self, axes=None):\n        \"\"\"\n        Decelerates and stop the stages.\n\n        :param axes: axes name or index (or list of)\n        :return:\n        \"\"\"\n\n        self.multi_axis_cmd('L', axes, 1)\n\n    def stop_all_stages(self):\n        \"\"\"\n        Stops the stages immediately.\n        \"\"\"\n        self.write_check('L:E')\n\n    def set_speed(self, axis, start_speed, max_speed, acceleration_time):\n        \"\"\"\n\n        :param axis: axes name or index\n        :param start_speed:  between 100 and 20000, in steps of 100 [PPS]\n        :param max_speed: between 100 and 20000, in steps of 100 [PPS]\n        :param acceleration_time: between 0 and 1000 [ms]\n        :return:\n        \"\"\"\n\n        if not (1 <= start_speed <= max_speed <= 999999999):\n            raise ValueError('Must be 1 <= start_speed <= max_speed <= 999999999')\n\n        if not (1 <= acceleration_time <= 1000):\n            raise ValueError('Must be 00 <= acceleration_time <= 1000.')\n\n        axes = self._axes_iterable(axis)\n        for axis in axes:\n            self.write_check('D:%d,%d,%d,%d' % (axis, start_speed, max_speed, acceleration_time))\n\n    def on_off(self, axes=None, on_off=None):\n        \"\"\"\n        Turn motor on/off\n        :param axes: axes name or index (or list of)\n        :param on_off: True (on) or False (off)\n        :return:\n        \"\"\"\n        if on_off is None:\n            on_off = 1\n\n        self.multi_axis_cmd('C', axes, on_off)",
  "def __init__(self, address, **kwargs):\n\n        self.port_settings = dict(baudrate=9600,\n                                  bytesize=8,\n                                  stopbits=1,\n                                  parity='N',\n                                  xonxoff=True,\n                                  timeout=0.5,\n                                  writeTimeout=0.5,\n                                  rtscts=True\n                                  )\n        SerialInstrument.__init__(self, address)\n        self.termination_character = '\\r\\n'\n        Stage.__init__(self)\n\n        if 'offsetOrigin' in kwargs:\n            self.offsetOrigin(kwargs['offsetOrigin'])  # 20000)\n\n        if 'home_on_start' in list(kwargs.keys()):\n            if kwargs['home_on_start']:\n                self.MechanicalHome()",
  "def __del__(self):\n        try:\n            self.ser.close()\n        except:\n            self._logger.warn(\"Couldn't close GSC01\")",
  "def wait(self):\n        while self.getACK3() != 'R':\n            time.sleep(0.1)",
  "def write_cmd(self, command, read=True, wait=False):\n        '''\n        :param command: serial command to send to device\n        :param read: if True, reads out standard 'OK' or 'NG' reply from the GSC-01\n        :param fname: name of calling function, only useful when verbose\n        :return:\n        '''\n\n        self.write(command)\n\n        if read:\n            reply = self.readline()\n            self._logger.debug('[%s]: %s' % (command, reply))\n        else:\n            reply = self.readline()\n            if reply != 'OK\\n':\n                self._logger.warn('%s replied %s' % (command, reply))\n\n        if wait:\n            self.wait()\n\n        return reply",
  "def MechanicalHome(self):\n        '''\n        This command is used to detect the mechanical origin for a stage and set that position as the origin. The moving\n        speed S: 500pps, F:5000ps, R:200mS. Running a stop command suspends the operation. Any other commands are not\n        acceptable.\n        :return:\n        '''\n        self.write_cmd('H:1', read=False, wait=True)",
  "def initializeOrigin(self):\n        \"\"\"\n        Sets the origin to the current position.\n        \"\"\"\n        self.write('R:1')",
  "def offsetOrigin(self, steps):\n        \"\"\"\n        Sets and offset to the homing command, so that the origin is not beside the limit sensors\n        Effective only for the homing operation in MINI system. Value is initialised to zero when turning power off.\n        :param steps: offset steps (integer)\n        :return:\n        \"\"\"\n\n        self.write('S:N%d' % steps)",
  "def move(self, pos, axis=None, relative=False, wait=True):\n        counts = self.counts_per_degree * pos\n        if relative:\n            if not (-16777214 <= counts <= 16777214):\n                raise ValueError('stage1 must be between -16777214 and 16777214.')\n\n            command = 'M:W'\n            if counts >= 0:\n                command += '+P%d' % counts\n            else:\n                command += '-P%d' % -counts\n        else:\n            command = 'A:W'\n            if counts >= 0:\n                command += '+P%d' % counts\n            else:\n                command += '-P%d' % -counts\n        self.write_cmd(command, read=False)\n        self._go()\n\n        if wait:\n            t0 = time.time()\n            curpos = self.get_position()[0]\n            while curpos != pos and time.time()-t0 < 10:\n                curpos = self.get_position()[0]\n                time.sleep(0.1)",
  "def get_position(self, axis=None):\n        status = self.getStatus()\n        counts = status.split(',')[0]\n        position = float(counts)/self.counts_per_degree\n        self._logger.debug('Status: %s. Counts: %s. Position returned %g' %(status, counts, position))\n        return [position]",
  "def jog(self, direction, timeout=2):\n        \"\"\"\n        Moves stage continuously at jogging speed for specified length of time.\n        :param direction: either '+' or '-'\n        :param timeout: in seconds\n        :return:\n        \"\"\"\n\n        self.write('J:1%s' % direction)\n        t0 = time.time()\n        self._go()\n        while time.time() - t0 < timeout:\n            time.sleep(0.1)\n        self.decelerate()",
  "def _go(self):\n        \"\"\"\n        Moves the stages. To be used internally.\n        \"\"\"\n        self.write_cmd('G:', read=False)",
  "def decelerate(self):\n        \"\"\"\n        Decelerates and stop the stages.\n        \"\"\"\n        self.write('L:1')",
  "def stop(self):\n        \"\"\"\n        Stops the stages immediately.\n        \"\"\"\n        self.write('L:E')",
  "def setSpeed(self, minSpeed1, maxSpeed1, accelerationTime1):\n        \"\"\"\n        Set minimum and maximum speeds and acceleration time.\n        :param minSpeed1: between 100 and 20000, in steps of 100 [PPS]\n        :param maxSpeed1: between 100 and 20000, in steps of 100 [PPS]\n        :param accelerationTime1: between 0 and 1000 [ms]\n        :return:\n        \"\"\"\n        if not (100 <= minSpeed1 <= maxSpeed1 <= 20000):\n            raise ValueError('Must be 100 <= minSpeed1 <= maxSpeed1 <= 20000')\n\n        if not (0 <= accelerationTime1 <= 1000):\n            raise ValueError('Must be 00 <= accelerationTime1 <= 1000.')\n\n        self.write('D:1S%dF%dR%d' % (minSpeed1, maxSpeed1, accelerationTime1))",
  "def setJogSpeed(self, speed):\n        \"\"\"\n        Set jog speed\n        :param speed: between 100 and 20000, in steps of 100 [PPS]\n        :return:\n        \"\"\"\n        if 100 < speed < 20000:\n            raise ValueError('Speed must be in 100-20000 range')\n\n        self.write('S:J%d' % speed)",
  "def enableMotorExcitation(self, stage1=True):\n        \"\"\"\n        Turn motor on/off\n        :param stage1: True (on) or False (off)\n        :return:\n        \"\"\"\n\n        self.write('C:1%d' % stage1)",
  "def getStatus(self):\n        \"\"\"\n        Gets the current status, consisting of position, command status, stop status, and motor readiness\n        :return: position, ACK1, ACK2, ACK3\n                ACK1:   X   Command Error\n                        K   Command accepted normally\n                ACK2:   L   Limit Sensor stop\n                        K   Normal stop\n                ACK3:   B   Busy\n                        R   Ready\n        \"\"\"\n        return self.write_cmd('Q:')",
  "def getACK3(self):\n        \"\"\"\n        :return: 'R' if motor ready, 'B' if motor busy\n        \"\"\"\n        self.write_cmd('!:', read=False)\n        return self.readline()",
  "def getVersion(self):\n        \"\"\"\n        Returns the ROM version\n        \"\"\"\n        self.write('?:V', read=False)\n        return self.readline()",
  "def __init__(self, address, **kwargs):\n\n        self.port_settings = dict(baudrate=38400,\n                                  bytesize=8,\n                                  stopbits=1,\n                                  parity='N',\n                                  xonxoff=True,\n                                  timeout=0.5,\n                                  writeTimeout=0.5,\n                                  rtscts=True\n                                  )\n        VisaInstrument.__init__(self, address)\n        self.termination_character = '\\r\\n'\n        Stage.__init__(self, unit=\"step\")",
  "def _rom_version(self):\n        \"\"\"\n        Request an internal ROM version from the controller.\n        :return: str, ROM version\n        \"\"\"\n        return self.query(\"?:V\")",
  "def _go(self, wait=True):\n        \"\"\"\n        Moves the stages. To be used internally.\n        \"\"\"\n        self._write_check('G:', wait=wait)",
  "def _write_check(self, command, wait=False):\n        self._logger.debug(\"Writing: %s\" %command)\n        self.write(command)\n        self._logger.debug(\"Writing successful\")\n        reply = self.read()\n        self._logger.debug(\"Read: %s\" %reply)\n\n        if reply == 'NG\\n':\n            self._logger.warn('%s replied %s' % (command, reply))\n        else:\n            if wait:\n                self._wait()\n            return reply",
  "def _wait(self):\n        \"\"\"\n        Wait until controller is ready\n        \"\"\"\n        while self.is_busy():\n            time.sleep(0.1)",
  "def home(self, axis=\"W\", direction=\"+\"):\n        \"\"\"\n        Detects the machine zero on the stage, and define the position as the home position\n        :param axis: either 1, 2 or W (for both)\n        :param direction: either + or -\n        :return:\n        \"\"\"\n\n        self._write_check(\"H:%s%s\" % (axis, direction))",
  "def set_origin(self, axis=\"W\"):\n        \"\"\"\n        Sets the origin to the current position.\n        :param axis: either 1, 2 or W (for both)\n        \"\"\"\n\n        self._write_check('R:' + str(axis))",
  "def move(self, counts, axis=1, relative=False, wait=True):\n        \"\"\"\n\n        :param counts: either an integer, or a tuple of two integers. Positive or negative\n        :param axis: either 1, 2 or W (for both)\n        :param relative:\n        :param wait:\n        :return:\n        \"\"\"\n        if not hasattr(counts, '__iter__'):\n            counts = (counts, )\n        for count in counts:\n            if not (-16777214 <= count <= 16777214):\n                raise ValueError('stage1 must be between -16777214 and 16777214.')\n\n        if relative:\n            command = \"M:\"\n        else:\n            command = \"A:\"\n\n        if not hasattr(axis, '__iter__'):\n            command += str(axis)\n        else:\n            command += 'W'\n        for count in counts:\n            if count >= 0:\n                command += '+P%d' % count\n            else:\n                command += '-P%d' % -count\n\n        self._write_check(command, wait=wait)\n        self._go(wait=wait)",
  "def get_position(self, axis=None):\n        status = self.status()\n        counts = list(map(int, status.split(',')[:2]))\n        if axis is None:\n            axis = self.axis_names\n        elif not isinstance(axis, list) and not isinstance(axis, tuple):\n            axis = [axis]\n        return [self.select_axis(counts, ax) for ax in axis]",
  "def jog(self, axis=\"W\", direction=\"+\", timeout=2):\n        \"\"\"\n        Moves stage continuously at jogging speed for specified length of time.\n\n        :param axis: either 1, 2 or W (for both)\n        :param direction: either + or -\n        :param timeout: amount of seconds to jog for\n        :return:\n        \"\"\"\n\n        self._write_check(\"J:%s%s\" % (axis, direction))\n\n        t0 = time.time()\n        self._go()\n        while time.time() - t0 < timeout:\n            time.sleep(0.1)\n        self.decelerate()",
  "def decelerate(self, axis=\"W\"):\n        \"\"\"\n        Decelerates and stop the stages.\n        :param axis: either 1, 2 or W (for both)\n        \"\"\"\n\n        self._write_check('L:' + str(axis))",
  "def emergency_stop(self):\n        \"\"\"\n        Stops the stages immediately.\n        \"\"\"\n        self.write('L:E')",
  "def set_speed(self, axes, min_speed, max_speed, accel_time):\n        \"\"\"Changing the movement speed\n        On turning ON the power, SHOT-102 will default a minimum speed (S), maximum speed (F), and\n        acceleration/deceleration time (R), all set by switches 9 and 10 on DIP Switch 1 for each speed range.\n        :param axis: either 1, 2 or W (for both)\n        :param min_speed: integer or tuple of two integers\n        :param max_speed: integer or tuple of two integers\n        :param accel_time: integer or tuple of two integers\n        :return:\n        \"\"\"\n\n        if not (1 <= min_speed <= max_speed <= 20000):\n            raise ValueError('Must be 1 <= min_speed <= max_speed <= 20000')\n        if not (0 <= accel_time <= 5000):\n            raise ValueError('Must be 0 <= accel_time <= 5000')\n        if not hasattr(min_speed, \"__iter__\"):\n            min_speed = tuple(min_speed)\n        if not hasattr(max_speed, \"__iter__\"):\n            max_speed = tuple(max_speed)\n        if not hasattr(accel_time, \"__iter__\"):\n            accel_time = tuple(accel_time)\n        if axes == \"W\":\n            if len(min_speed) != 2 or len(min_speed) != 2 or len(min_speed) != 2:\n                raise ValueError('You need to provide speeds and times for both axis')\n\n        command = \"D:%s\" %axes\n        for mn, mx, at in zip(min_speed, max_speed, accel_time):\n            command += \"S\" + str(mn) + \"F\" + str(mx) + \"R\" + str(at)\n        self._write_check(command)",
  "def on_off(self, axes, state):\n        \"\"\"\n        Deenergizes (motor free) or Energizes (hold) the motor.\n        Execute this command to move (rotate) stages manually. Once executed, the actual stage position does not\n        coincide with the coordinate value being displayed. For proper positioning, perform zero return and make the\n        stage position consistent with the coordinate value being displayed.\n        :param axes: either 1, 2 or W (for both)\n        :param state: 0 (off) or 1 (on)\n        :return:\n        \"\"\"\n        self._write_check(\"C:%s%s\" % (axes, state))",
  "def status(self):\n        \"\"\"\n        A command to check the validity of an immediately preceding command, and request a controller to return the\n        state of stage operations, coordinates of axes, etc.\n        :return: str coord_1, coord_2, ACK1, ACK2, ACK3\n            coordinates are 10-digit data including sign (positive is space)\n            ACK1:   X - command or parameter error\n                    K - successful command\n            ACK2:   L - axis 1 emergency stop\n                    M - axis 2 emergency stop\n                    W - both axis emergency stop\n                    K - normal stop\n            ACK3:   B - busy\n                    R - ready\n        \"\"\"\n        return self.query(\"Q:\")",
  "def is_busy(self):\n        \"\"\"\n\n        :return: bool\n        \"\"\"\n        reply = self.query(\"!:\")\n\n        if \"B\" in reply:\n            return True\n        else:\n            return False",
  "def __init__(self, address, **kwargs):\n\n        self.port_settings = dict(baudrate=38400,\n                                  bytesize=8,\n                                  stopbits=1,\n                                  parity='N',\n                                  xonxoff=True,\n                                  timeout=0.5,\n                                  writeTimeout=0.5,\n                                  rtscts=True\n                                  )\n        SerialInstrument.__init__(self, address)\n        self.termination_character = '\\r\\n'\n        Stage.__init__(self, unit=\"step\")",
  "def _axes_iterable(self, axes=None):\n        \"\"\"Convenience function\n\n        Given a list of axes names or axes numbers (can be mixed), returns an list of the corresponding axes numbers\n        using axis_LUT\n\n        :param axes: list of axes names or number (can be mixed)\n        :return:\n        \"\"\"\n        if axes is None:\n            axes = self.axis_names\n        if not isinstance(axes, list) and not isinstance(axes, tuple):\n            axes = (axes, )\n        axes_iter = []\n        for ax in axes:\n            if ax in list(self.axis_LUT.keys()):\n                axes_iter += [self.axis_LUT[ax]]\n            elif type(ax) == int:\n                axes_iter += [ax]\n            else:\n                raise ValueError(\"Unrecognised axis: %s %s\" % (ax, type(ax)))\n        return axes_iter",
  "def move(self, counts, axes=None, relative=False, wait=True):\n        \"\"\"\n\n        :param counts: (int) number of motor steps. If iterable, should be same length as axes.\n        :param axes: list of axes\n        :param relative: (bool)\n        :param wait: bool\n        :return:\n        \"\"\"\n        axes = self._axes_iterable(axes)\n        if not hasattr(counts, '__iter__'):\n            counts = [counts] * len(axes)\n        for count in counts:\n            assert -134217728 < count < +134217727\n        counts = list(map(int, counts))\n\n        if relative:\n            command = 'M'\n        else:\n            command = 'A'\n\n        self.multi_axis_cmd(command, axes, counts, wait)",
  "def get_position(self, axes=None):\n        axes = self._axes_iterable(axes)\n        all_positions = self.query(\"Q:\").split(\",\")\n        positions = []\n        for ax in axes:\n            try:\n                positions += [int(all_positions[ax])]\n            except ValueError:\n                positions += [None]\n        return positions",
  "def status(self, axes=None):\n        \"\"\"\n\n        :param axes: list of strings/integers corresponding to the names or indices of the axes, or a single string/integer\n        :return: string corresponding to the overall status, and a dictionary for the individual axes' status\n        \"\"\"\n        bit_list = [\"\", \"DRV alarm\", \"Scale alarm\", \"Z limit\", \"Near\", \"ORG\", \"+LS\", \"-LS\"]\n        raw_statuses = self.query(\"Q:S\").split(\",\")\n        status = []\n        for rs in raw_statuses:\n            try:\n                # Converting to 8-bit hexadecimal. https://stackoverflow.com/questions/1425493/convert-hex-to-binary\n                _bin = bin(int(rs, 16))[2:].zfill(8)\n                _status = []\n                for bit, bit_name in zip(_bin, bit_list):\n                    if bool(int(bit)):\n                        _status += [bit_name]\n                if len(_status) > 0:\n                    status += [_status]\n                else:\n                    status += [\"OK\"]\n            except ValueError:\n                status += [None]\n        overall_status = status[0]\n        axes_status = status[1:]\n\n        axes = self._axes_iterable(axes)\n        reply = dict()\n        for name, indx in zip(self.axis_names, axes):\n            reply[name] = axes_status[indx]\n        return overall_status, reply",
  "def is_moving(self, axes=None):\n        axes = self._axes_iterable(axes)\n        statuses = self.query(\"!:\").split(\",\")\n        status = []\n        for ax in axes:\n            status += [bool(int(statuses[ax]))]  # converting a '0' or '1' to a False or True\n        return any(status)",
  "def write_check(self, command, wait=False):\n        \"\"\"\n        Light wrapper providing error checking, locking and waiting\n\n        :param command: full serial command to send to device\n        :param wait: bool\n        :return:\n        \"\"\"\n        self.write(command)\n\n        reply = self.readline()[:-1]  # excluding the \\n termination\n        self._logger.debug(\"Reply: %s\" % reply)\n\n        if reply == 'NG':\n            self._logger.warn('%s replied %s' % (command, reply))\n        else:\n            if wait:\n                self.wait_until_stopped()\n            return reply",
  "def multi_axis_cmd(self, command, axes, parameters, wait=False):\n        \"\"\"Convenience function\n\n        Creates commands with the appropriate parameters in the appropriate places.\n        e.g. by simply giving 'H', None, 1 it creates the command H:,1,,,1,,,1 (assuming the stage has three active axes at positions 1, 4 and 7\n\n        :param command: command code to send to device\n        :param axes: axes name or index (or list of)\n        :param parameters: list of parameters to pass. If iterable, it passes each item to each of the axes. Otherwise it passes the same argument to all axes\n        :param wait: if True, calls self.wait before returning\n        :return:\n        \"\"\"\n        axes_iter = self._axes_iterable(axes)\n\n        if not hasattr(parameters, \"__iter__\"):\n            parameters = [parameters] * len(axes_iter)\n        if len(parameters) != len(axes_iter):\n            raise ValueError(\"Length of axes and parameters must be the same\")\n\n        self._logger.debug(\"Axes: %s axes_iter: %s Parameters: %s\" % (axes, axes_iter, parameters))\n\n        argument_list = ['DUMMY']*8\n        for ax, param in zip(axes_iter, parameters):\n            argument_list[ax] = str(param)\n        argument_string = ','.join(argument_list)\n        argument_string = argument_string.replace('DUMMY', '')\n        command += ':' + argument_string\n        self._logger.debug('Writing: %s' % command)\n\n        self.write_check(command, wait)",
  "def mechanical_home(self, axes=None):\n        \"\"\"\n        This command is used to detect the mechanical origin for a stage and set that position as the origin. The moving\n        speed S: 500pps, F:5000ps, R:200mS. Running a stop command suspends the operation. Any other commands are not\n        acceptable.\n        :param axes: axes name or index (or list of)\n        :return:\n        \"\"\"\n        self.multi_axis_cmd('H', axes, 1, wait=True)",
  "def set_home(self, axes=None):\n        \"\"\"\n        Sets the origin to the current position.\n        :param axes: axes name or index (or list of)\n        :return:\n        \"\"\"\n        self.multi_axis_cmd('R', axes, 1)",
  "def jog(self, directions, axes=None, timeout=2):\n        \"\"\"\n        Moves stage continuously at jogging speed for specified length of time.\n        :param directions: a single value or iterable of either '+' or '-'\n        :param axes:\n        :param timeout: in seconds\n        :return:\n        \"\"\"\n\n        # TODO: make the write_check non-blocking for this to work\n        raise NotImplementedError",
  "def decelerate(self, axes=None):\n        \"\"\"\n        Decelerates and stop the stages.\n\n        :param axes: axes name or index (or list of)\n        :return:\n        \"\"\"\n\n        self.multi_axis_cmd('L', axes, 1)",
  "def stop_all_stages(self):\n        \"\"\"\n        Stops the stages immediately.\n        \"\"\"\n        self.write_check('L:E')",
  "def set_speed(self, axis, start_speed, max_speed, acceleration_time):\n        \"\"\"\n\n        :param axis: axes name or index\n        :param start_speed:  between 100 and 20000, in steps of 100 [PPS]\n        :param max_speed: between 100 and 20000, in steps of 100 [PPS]\n        :param acceleration_time: between 0 and 1000 [ms]\n        :return:\n        \"\"\"\n\n        if not (1 <= start_speed <= max_speed <= 999999999):\n            raise ValueError('Must be 1 <= start_speed <= max_speed <= 999999999')\n\n        if not (1 <= acceleration_time <= 1000):\n            raise ValueError('Must be 00 <= acceleration_time <= 1000.')\n\n        axes = self._axes_iterable(axis)\n        for axis in axes:\n            self.write_check('D:%d,%d,%d,%d' % (axis, start_speed, max_speed, acceleration_time))",
  "def on_off(self, axes=None, on_off=None):\n        \"\"\"\n        Turn motor on/off\n        :param axes: axes name or index (or list of)\n        :param on_off: True (on) or False (off)\n        :return:\n        \"\"\"\n        if on_off is None:\n            on_off = 1\n\n        self.multi_axis_cmd('C', axes, on_off)",
  "class Thorlabs_BSC103(APT_VCP):\n\n\n\tdef __init__(self,port=None,debug=0):\n\t\t\n\t\tself.debug = debug\n\t\tAPT_VCP.__init__(self, port=port,source=0x01,destination={\"motherboard\":0x11})",
  "def __init__(self,port=None,debug=0):\n\t\t\n\t\tself.debug = debug\n\t\tAPT_VCP.__init__(self, port=port,source=0x01,destination={\"motherboard\":0x11})",
  "class WheelOfPower(object):\n    \"\"\"A quick wrapper to add a filter wheel and a powermeter together to create\n    an autocalibrate object which can move to a given power\"\"\"\n\n    def __init__(self, power_meter, rotation_stage):\n        self.power_meter = power_meter\n        self.rotation_stage = rotation_stage\n        self.abort_deque = False\n        self.deque_time = 1.0\n        self.deque_length = 100\n        self.history_deque = deque(maxlen=self.deque_length)\n\n    def calibrate(self, start=0, stop=360, steps=360):\n        stage_positions = np.linspace(start, stop, steps)\n        powers = []\n        for position in stage_positions:\n            self.rotation_stage.move(position)\n            powers.append(self.power_meter.average_power)\n        powers = np.array(powers)\n        interp_function = interp1d(stage_positions, powers)\n        new_stage_positions = np.linspace(start, stop, steps * 100)\n        new_powers = interp_function(new_stage_positions)\n        self.powers = new_powers\n        self.stage_position = new_stage_positions\n\n    def power_to_pos(self, power):\n        \"\"\"Find the closest power by looking up the interpolated table \"\"\"\n        return self.stage_position[self.powers == self.find_nearest(self.powers, power)]\n\n    def find_nearest(self, array, value):\n        \"\"\" find the minimum value of an array\"\"\"\n        return array[np.abs(array - value).argmin()]\n\n    def move_to_power(self, power):\n        pos = self.power_to_pos(power)\n        self.rotation_stage.move(pos)\n\n    def update_deque(self):\n        running = True\n        while running:\n            t0 = time.time()\n            current_powers = []\n            while (time.time() - t0) < self.deque_time:\n                current_powers.append(self.power_meter.average_power)\n            self.history_deque.append(np.average(current_powers))\n            if self.abort_deque == True:\n                running = False\n        self.abort_deque = False\n\n    def start_deque_thread(self):\n        self.deque_thread = threading.Thread(target=self.update_deque)\n        self.deque_thread.start()\n\n    def clear_deque_thread(self):\n        self.history_deque = deque(maxlen=self.deque_length)",
  "class PowerWheelMixin(object):\n    \"\"\"\n    General mixin to add calibration functions to an instrument that controls power. The general calibration is done by\n    providing interpolation functions to the measured power dependency.\n\n    The user must implement the raw_power property.\n    Optionally, the prepare_calibration gives some flexibility in choosing the interpolation region.\n    \"\"\"\n\n    def __init__(self):\n        super(PowerWheelMixin, self).__init__()\n        self.cal_to_raw = lambda x: x\n        self.raw_to_cal = lambda x: x\n        self.calibration = None\n        self._raw_calibration = None\n        self._raw_min = 0\n        self._raw_max = 1\n\n    @property\n    def raw_power(self):\n        raise NotImplementedError\n\n    @raw_power.setter\n    def raw_power(self, value):\n        raise NotImplementedError\n\n    def prepare_calibration(self, calibration):\n        \"\"\"\n        Allows the user to perform some analysis on the raw_calibration before making an interpolation.\n        Useful in a situation where the calibration is not monotonic (making one of the interpolations multivalued)\n        :return:\n        \"\"\"\n        return calibration\n\n    def _calibration_functions(self, calibration=None):\n        if calibration is None:\n            calibration = self.calibration\n        self.cal_to_raw = interp1d(calibration[1], calibration[0])\n        self.raw_to_cal = interp1d(calibration[0], calibration[1])\n\n    def recalibrate(self, power_meter, points=3):\n        \"\"\"\n        Selects a few random points. Finds the factor that would most closely bring the calibration to these\n        points. This assumes that the only possible change is a multiplicative factor\n\n        :param power_meter: instrument instance with a 'power' property\n        :param points: int. Number of points you want to check\n        :return:\n        \"\"\"\n        assert self.calibration is not None\n\n        old_calibration = np.copy(self.calibration)\n\n        rand_indices = np.random.choice(old_calibration.shape[1], points)\n        raw_vals = old_calibration[0, rand_indices]\n        old_cal = old_calibration[1, rand_indices]\n        run_function_modally(self._recalibrate, points, power_meter, raw_vals, old_cal)\n\n    def _recalibrate(self, power_meter, raw_vals, old_cal, update_progress=lambda p: p):\n        new_cal = []\n        for idx, raw in enumerate(raw_vals):\n            update_progress(idx)\n            self.raw_power = raw\n            new_cal += [power_meter.power]\n\n        def minimise(params):\n            return np.sum(np.abs((old_cal * params[0]) - new_cal))\n\n        results = minimize(minimise, np.array([1]))\n\n        self.calibration[1] *= results.x[0]\n        self._calibration_functions()\n\n    def calibrate(self, power_meter, points=51, min_power=None, max_power=None):\n        \"\"\"\n        General calibration procedure. Iterates over 'raw_powers', and measures the actual powers using a powermeter\n\n        :param power_meter: powermeter instrument with 'power' property\n        :param points: int. Number of interpolation points\n        :param min_power: float. minimum value of raw_power\n        :param max_power: float. maximum value of raw_power\n        :return:\n        \"\"\"\n        if min_power is None:\n            min_power = self._raw_min\n        if max_power is None:\n            max_power = self._raw_max\n\n        raw_powers = np.linspace(min_power, max_power, points)\n        run_function_modally(self._calibrate, points, power_meter, raw_powers)\n\n    def _calibrate(self, power_meter, raw_powers, update_progress=lambda p: p):\n        powers = np.array([])\n        for idx, raw in enumerate(raw_powers):\n            update_progress(idx)\n            self.raw_power = raw\n            powers = np.append(powers, power_meter.power)\n        self._raw_calibration = np.array([raw_powers, powers])\n        self.calibration = self.prepare_calibration(self._raw_calibration)\n        self._calibration_functions()\n\n    def save_calibration(self, filename=None):\n        \"\"\"\n        Save calibration to a .txt using numpy\n        :param filename: str\n        :return:\n        \"\"\"\n        if filename is None:\n            filename = os.path.dirname(os.path.abspath(__file__)) + '/powerwheel_calibration.txt'\n        np.savetxt(filename, self.calibration)\n\n    def load_calibration(self, filename=None, power_meter=None):\n        \"\"\"\n        Load a numpy-saved .txt\n\n        :param filename: str\n        :param power_meter: powermeter instrument with a 'power' attribute. If given, PowerWheel will recalibrate\n        :return:\n        \"\"\"\n        if filename is None:\n            filename = os.path.dirname(os.path.abspath(__file__)) + '/powerwheel_calibration.txt'\n        self.calibration = np.loadtxt(filename)\n        if power_meter is not None:\n            self.recalibrate(power_meter)\n        self._calibration_functions()\n\n    @property\n    def power(self):\n        return self.raw_to_cal(self.raw_power)\n\n    @power.setter\n    def power(self, value):\n        self.raw_power = self.cal_to_raw(value)",
  "def __init__(self, power_meter, rotation_stage):\n        self.power_meter = power_meter\n        self.rotation_stage = rotation_stage\n        self.abort_deque = False\n        self.deque_time = 1.0\n        self.deque_length = 100\n        self.history_deque = deque(maxlen=self.deque_length)",
  "def calibrate(self, start=0, stop=360, steps=360):\n        stage_positions = np.linspace(start, stop, steps)\n        powers = []\n        for position in stage_positions:\n            self.rotation_stage.move(position)\n            powers.append(self.power_meter.average_power)\n        powers = np.array(powers)\n        interp_function = interp1d(stage_positions, powers)\n        new_stage_positions = np.linspace(start, stop, steps * 100)\n        new_powers = interp_function(new_stage_positions)\n        self.powers = new_powers\n        self.stage_position = new_stage_positions",
  "def power_to_pos(self, power):\n        \"\"\"Find the closest power by looking up the interpolated table \"\"\"\n        return self.stage_position[self.powers == self.find_nearest(self.powers, power)]",
  "def find_nearest(self, array, value):\n        \"\"\" find the minimum value of an array\"\"\"\n        return array[np.abs(array - value).argmin()]",
  "def move_to_power(self, power):\n        pos = self.power_to_pos(power)\n        self.rotation_stage.move(pos)",
  "def update_deque(self):\n        running = True\n        while running:\n            t0 = time.time()\n            current_powers = []\n            while (time.time() - t0) < self.deque_time:\n                current_powers.append(self.power_meter.average_power)\n            self.history_deque.append(np.average(current_powers))\n            if self.abort_deque == True:\n                running = False\n        self.abort_deque = False",
  "def start_deque_thread(self):\n        self.deque_thread = threading.Thread(target=self.update_deque)\n        self.deque_thread.start()",
  "def clear_deque_thread(self):\n        self.history_deque = deque(maxlen=self.deque_length)",
  "def __init__(self):\n        super(PowerWheelMixin, self).__init__()\n        self.cal_to_raw = lambda x: x\n        self.raw_to_cal = lambda x: x\n        self.calibration = None\n        self._raw_calibration = None\n        self._raw_min = 0\n        self._raw_max = 1",
  "def raw_power(self):\n        raise NotImplementedError",
  "def raw_power(self, value):\n        raise NotImplementedError",
  "def prepare_calibration(self, calibration):\n        \"\"\"\n        Allows the user to perform some analysis on the raw_calibration before making an interpolation.\n        Useful in a situation where the calibration is not monotonic (making one of the interpolations multivalued)\n        :return:\n        \"\"\"\n        return calibration",
  "def _calibration_functions(self, calibration=None):\n        if calibration is None:\n            calibration = self.calibration\n        self.cal_to_raw = interp1d(calibration[1], calibration[0])\n        self.raw_to_cal = interp1d(calibration[0], calibration[1])",
  "def recalibrate(self, power_meter, points=3):\n        \"\"\"\n        Selects a few random points. Finds the factor that would most closely bring the calibration to these\n        points. This assumes that the only possible change is a multiplicative factor\n\n        :param power_meter: instrument instance with a 'power' property\n        :param points: int. Number of points you want to check\n        :return:\n        \"\"\"\n        assert self.calibration is not None\n\n        old_calibration = np.copy(self.calibration)\n\n        rand_indices = np.random.choice(old_calibration.shape[1], points)\n        raw_vals = old_calibration[0, rand_indices]\n        old_cal = old_calibration[1, rand_indices]\n        run_function_modally(self._recalibrate, points, power_meter, raw_vals, old_cal)",
  "def _recalibrate(self, power_meter, raw_vals, old_cal, update_progress=lambda p: p):\n        new_cal = []\n        for idx, raw in enumerate(raw_vals):\n            update_progress(idx)\n            self.raw_power = raw\n            new_cal += [power_meter.power]\n\n        def minimise(params):\n            return np.sum(np.abs((old_cal * params[0]) - new_cal))\n\n        results = minimize(minimise, np.array([1]))\n\n        self.calibration[1] *= results.x[0]\n        self._calibration_functions()",
  "def calibrate(self, power_meter, points=51, min_power=None, max_power=None):\n        \"\"\"\n        General calibration procedure. Iterates over 'raw_powers', and measures the actual powers using a powermeter\n\n        :param power_meter: powermeter instrument with 'power' property\n        :param points: int. Number of interpolation points\n        :param min_power: float. minimum value of raw_power\n        :param max_power: float. maximum value of raw_power\n        :return:\n        \"\"\"\n        if min_power is None:\n            min_power = self._raw_min\n        if max_power is None:\n            max_power = self._raw_max\n\n        raw_powers = np.linspace(min_power, max_power, points)\n        run_function_modally(self._calibrate, points, power_meter, raw_powers)",
  "def _calibrate(self, power_meter, raw_powers, update_progress=lambda p: p):\n        powers = np.array([])\n        for idx, raw in enumerate(raw_powers):\n            update_progress(idx)\n            self.raw_power = raw\n            powers = np.append(powers, power_meter.power)\n        self._raw_calibration = np.array([raw_powers, powers])\n        self.calibration = self.prepare_calibration(self._raw_calibration)\n        self._calibration_functions()",
  "def save_calibration(self, filename=None):\n        \"\"\"\n        Save calibration to a .txt using numpy\n        :param filename: str\n        :return:\n        \"\"\"\n        if filename is None:\n            filename = os.path.dirname(os.path.abspath(__file__)) + '/powerwheel_calibration.txt'\n        np.savetxt(filename, self.calibration)",
  "def load_calibration(self, filename=None, power_meter=None):\n        \"\"\"\n        Load a numpy-saved .txt\n\n        :param filename: str\n        :param power_meter: powermeter instrument with a 'power' attribute. If given, PowerWheel will recalibrate\n        :return:\n        \"\"\"\n        if filename is None:\n            filename = os.path.dirname(os.path.abspath(__file__)) + '/powerwheel_calibration.txt'\n        self.calibration = np.loadtxt(filename)\n        if power_meter is not None:\n            self.recalibrate(power_meter)\n        self._calibration_functions()",
  "def power(self):\n        return self.raw_to_cal(self.raw_power)",
  "def power(self, value):\n        self.raw_power = self.cal_to_raw(value)",
  "def minimise(params):\n            return np.sum(np.abs((old_cal * params[0]) - new_cal))",
  "def bytes_to_binary(bytearr,debug = 0):\n    '''\n    Helper method for converting a bytearray datatype to a binary representation\n    '''\n    if debug > 0: print(bytearr)\n    bytes_as_binary =[ format(int(b,base=16),\"#06b\").replace(\"0b\",\"\") for b in bytearr ]  \n    if debug > 0: print(bytes_as_binary)\n    binary = \"\".join(bytes_as_binary)\n    return binary",
  "def twos_complement_to_int(binary,debug = 0):\n    '''\n    Compute 2s complement of binary number representation\n    '''\n    if debug > 0: print(binary)\n    N = len(binary)\n    a_N = int(binary[0])\n    return float(-a_N*2**(N-1) + int(binary[1:],base=2))",
  "def int_to_hex(integer,padded_length=8,debug=0):\n    '''\n    Convert integer number to hexidecimal. Return value is zero-padded at the beginning\n    until its length matches the value passed in \"padded_length\"\n    '''\n    outp = (format(integer,\"#0{}x\".format(padded_length+2)).replace(\"0x\",\"\")).upper()\n    return outp",
  "def int_to_twos_complement(integer, padded_length=16,debug = 0):\n    '''\n    Two's complement in integer representation. Padded length specifies the padding on the \n    binary representation used to compute the twos complement\n    '''\n    #number is above 0 - return binary representation:\n    if integer >= 0:\n        return integer\n\n    #number is below zero - return twos complement representation:\n    elif integer < 0:\n        if debug > 0: print(\"Below zero - returning twos complement\")\n        integer = -1*integer\n        binary = format(integer,\"0{}b\".format(padded_length+2)).replace(\"0b\",\"\")\n        ones_complement = [str(1-int(b)) for b in str(binary)]\n        ones_complement = int(\"\".join(ones_complement))\n        twos_complement = int(\"0b\"+str(ones_complement),base=2) + 1\n        twos_complement = format(twos_complement,\"034b\").replace(\"0b\",\"\")\n        if debug > 0:\n            print(\"input:\",integer)\n            print(\"binary:\",binary) \n            print(\"ones comp:\", ones_complement)\n            print(\"twos comp (int):\", int(twos_complement,base=2)) \n        return int(\"0b\"+twos_complement,base=2)",
  "class BusDistributor(SerialInstrument):\n    ''' a class to handle the port settings of a thorlabs ELLB distributor bus.\n    Each of these can have several devices attached. They are assigned device\n    indices by the thorlabs Ello software - otherwise they all default to 0 and\n    don't work separately. \n    '''\n    def __init__(self, port):\n        self.termination_character = '\\n'\n        self.port_settings = dict(baudrate=9600,\n                                  bytesize=8,\n                                  stopbits=1,\n                                  parity='N',\n                                  timeout=2,\n                                  writeTimeout=2,\n                                  xonxoff=False)\n        super().__init__(port)",
  "class Thorlabs_ELL20(Stage):\n\n    #default id is 0, but if multiple devices of same type connected may have others\n    VALID_DEVICE_IDs = [str(v) for v in list(range(0,11)) + [\"A\",\"B\",\"C\",\"D\",\"E\",\"F\"]]\n\n    #How much a stage sleeps (in seconds) between successive calls to .get_position.\n    #Used to make blocking calls to move_absolute and move_relative. \n    BLOCK_SLEEPING_TIME = 0.02\n    #Theshold for position accuracy when stage is meant to be stationary\n    #If difference between successive calls to get_position returns value \n    #whose difference is less than jitter - consider stage to have stopped \n    POSITION_JITTER_THRESHOLD = 0.02\n\n    #human readable status codes\n    DEVICE_STATUS_CODES = {\n            0: \"OK, no error\",\n            1: \"Communication Timeout\",\n            2: \"Mechanical time out\",\n            3: \"Command error or not supported\",\n            4: \"Value out of range\",\n            5: \"Module isolated\",\n            6: \"Module out of isolation\",\n            7: \"Initialization error\",\n            8: \"Thermal error\",\n            9: \"Busy\",\n            10: \"Sensor Error\",\n            11: \"Motor Error\",\n            12: \"Out of Range\",\n            13: \"Over current error\",\n            14: \"OK, no error\",\n            \"OutOfBounds\" : \"Reserved\"\n        }\n\n    def __init__(self, serial_device, device_index=0, debug=0):\n        '''can be passed either a BusDistributor instance, or  \"COM5\"  '''\n        if type(serial_device) is str:\n            self.serial_device = BusDistributor(serial_device)\n        else:\n            self.serial_device = serial_device\n        self.debug = debug\n\n        Stage.__init__(self)\n        self.ui = None\n\n        #configure stage parameters\n        if str(device_index) not in self.VALID_DEVICE_IDs:\n            raise ValueError(\"Device ID: {} is not valid!\".format(device_index))\n        self.device_index = device_index\n        \n        configuration = self.get_device_info()\n        self.TRAVEL = configuration[\"travel\"]\n        self.PULSES_PER_MM = configuration[\"pulses\"]\n        \n        if self.debug > 0:\n            print(\"Travel (degrees):\", self.TRAVEL)\n            print(\"Pulses per mm\", self.PULSES_PER_MM)\n            print(\"Device status:\",self.get_device_status())\n\n    def query_device(self,query):\n\n        '''\n        Wrap a generic query with the ID of the device (integer in range: 0-F)\n        so that we dont need to be explicit about this id\n        '''\n        raw_query = \"{0}{1}\".format(self.device_index,query)\n        if self.debug > 0:\n            print(\"raw_query\", raw_query)\n        raw_response = self.serial_device.query(raw_query) \n        if self.debug > 0:\n            print(\"raw_response\",raw_response)\n        return raw_response\n\n    \n    def _position_to_pulse_count(self,position):\n        '''\n        Convert from an position (specified in degrees) into the number of pulses\n        that need to be applied to the motor to turn it. \n\n        pulses_per_revolution - specified by Thorlabs as number of pulses for a revolution (360 deg) of stage\n        travel - the maximum angular motion of stage (==360 for ELL8K)\n\n        Method used when sending instructions to move to stage\n        '''\n        pulses = int(np.rint(position*self.PULSES_PER_MM))\n        if self.debug > 0:\n            print(\"Input position:\", position) \n            print(\"Pulses:\", pulses) \n        return pulses\n\n    def _pulse_count_to_position(self,pulse_count):\n        '''\n        Convert from an pulse count into the degrees. \n\n        pulses_per_revolution - specified by Thorlabs as number of pulses for a revolution (360 deg) of stage\n        travel - the maximum angular motion of stage (==360 for ELL8K)\n\n        Method used when reading data received from stage\n        '''\n        return pulse_count/self.PULSES_PER_MM\n\n    def _position_to_hex_pulses(self, position):\n        '''\n        Convert position in range (-360.0,360.0) (exclusive of edges) into a hex representation of pulse\n        count required for talking to the ELL8K stage\n        \n        '''\n        \n        #convert position to number of pulses used to drive motors:\n        pulses_int = self._position_to_pulse_count(position)    \n        if self.debug > 0 : print(\"Pulses (int)\", pulses_int)\n        #make two's complement to allow for -ve values\n        pulses_int = int_to_twos_complement(pulses_int)\n        if self.debug > 0 : print(\"Pulses (int,2s compl)\", pulses_int)\n        #convert integer to hex\n        pulses_hex = int_to_hex(pulses_int) \n        if self.debug > 0 : print(\"Pulses hex:\", pulses_hex)\n        return pulses_hex\n\n    def _hex_pulses_to_position(self, hex_pulse_position):\n        '''\n        Convert position to position - full method for processing responses from stage\n        '''\n        binary_pulse_position = bytes_to_binary(hex_pulse_position)\n        int_pulse_position = twos_complement_to_int(binary_pulse_position)\n        return self._pulse_count_to_position(int_pulse_position)\n\n\n    def _decode_position_response(self,response):\n        '''\n        Method for decoding positional response from stage for responses from:\n            mode_absolute, mode_relative, move_home\n        '''\n        header = response[0:3]\n        if header == \"{0}GS\".format(self.device_index):\n            #still moving\n            status_code = int(response[3:5],base=16)\n            status = self.DEVICE_STATUS_CODES[status_code]\n            outp = {\"header\": header,\"status\": status}\n            return outp\n        elif header == \"{0}PO\".format(self.device_index):\n            hex_pulse_position = response[3:11]\n            position = self._hex_pulses_to_position(hex_pulse_position)\n            outp = {\"header\": header,\"position\": position}\n            return outp\n\n    def _block_until_stopped(self):\n       '''\n       Method for blocking move_absolute and move_relative and move_home commands until stage has stopped\n       Spins on get_position command comparing returned results. If between two calls position doesn't change\n       Then assume stage has stopped and exit\n       '''\n       stopped = False\n       previous_position = 0.0\n       current_position = 1.0\n        \n       try:    \n           while(stopped == False):\n               time.sleep(self.BLOCK_SLEEPING_TIME)\n               current_position = self.get_position()\n               stopped =(np.absolute(current_position - previous_position) < self.POSITION_JITTER_THRESHOLD)\n               previous_position = current_position\n       except KeyboardInterrupt:\n           return\n       return \n\n\n    def get_position(self,axis=None):\n        '''\n        Query stage for its current position, in degrees\n        This method overrides the Stage class' method\n        '''\n        response = self.query_device(\"gp\")\n        header = response[0:3]\n        if header == \"{0}PO\".format(self.device_index):\n        #position given in twos complement representation\n            byte_position = response[3:11]\n            binary_position = bytes_to_binary(byte_position)\n            pulse_position = twos_complement_to_int(binary_position)\n            position = float(pulse_position)/self.PULSES_PER_MM\n            return position\n        else:\n            raise ValueError(\"Incompatible Header received:{}\".format(header)) \n        \n    def move(self,pos, axis=None, relative=False):\n        '''\n        Send command to move stage.\n        pos:  specified in degrees and can be in range (-360,360)\n        relative: whether motion is relative to current position or relative to global home\n        This method overrides the Stage class' method\n        '''\n        if relative:\n            self.move_relative(pos)\n        else:\n            self.move_absolute(pos)\n\n\n    def get_device_info(self):\n        '''\n        Instruct hardware to identify itself. \n        Give information about model, serial numbner, firmware. \n\n        This MUST be called at initialization of the stage as the key parameters:\n\n        TRAVEL, PULSES are extracted here\n\n        TRAVEL - the range of travel of the stage, specified in units (mm or deg) relevant to the type of stage\n        PULSES - specifieid the number of pulses applied to motors to move stage over entire range of travel\n\n        Hence: ratio of PULSES/TRAVEL gives number of pulses to move 1 mm or 1 deg\n        '''\n             \n        response = self.query_device(\"in\")\n\n        #decode the response\n        header = response[0:3]\n        ell = response[3:5]\n        sn = response[5:13]\n        year = response[13:17]\n        firmware_release = response[17:19]\n        hardware_release = response[19:21]\n        \n        bytes_travel = response[21:25] #units: mm/deg\n        \n        binary_travel = bytes_to_binary(bytes_travel)\n        travel = twos_complement_to_int(binary_travel)\n        \n        bytes_pulses = response[25:33]\n        binary_pulses = bytes_to_binary(bytes_pulses)\n        pulses = twos_complement_to_int(binary_pulses)\n\n        outp = {\n            \"header\" : header,\n            \"ell\" : ell,\n            \"sn\": sn,\n            \"year\": year,\n            \"firmware_release\": firmware_release,\n            \"hardware_release\": hardware_release,\n            \"travel\": travel,\n            \"pulses\": pulses\n        }\n        return outp \n\n    def get_device_status(self):\n        '''\n        Query device to get its status code  - for testing that device is functioning correctly\n        '''\n\n        response = self.query_device(\"gs\")\n        #read response and decode it:\n        header = response[0:3]\n        byte_status = response[3:5]\n        if self.debug > 0: print(\"Byte status:\", byte_status)\n\n        binary_status = bytes_to_binary(byte_status)\n        if self.debug > 0: print(\"Binary status\", binary_status)\n        int_status = int(binary_status,base=2)\n\n        if int_status in list(self.DEVICE_STATUS_CODES.keys()):\n            return {\"header\": header, \"status\": self.DEVICE_STATUS_CODES[int_status]}\n        else:\n            return {\"header\": header, \"status\": self.DEVICE_STATUS_CODES[\"OutOfBounds\"]}\n\n    def move_home(self, blocking=True):\n        '''\n        Move stage to factory default home location. \n        Note: Thorlabs API allows resetting stages home but this not implemented as it isnt' advised \n        '''\n\n        \n        response = self.query_device(\"ho\")\n        if blocking:\n            self._block_until_stopped()\n        return self._decode_position_response(response)\n        \n\n    def move_absolute(self, position, blocking=True):\n        \"\"\"Move to absolute position relative to home setting\n\n        Args:\n            position (float): position to move to, specified in degrees.\n\n        Returns:\n            None\n\n        Raises:\n            None\n\n        \"\"\"\n   \n        pulses_hex = self._position_to_hex_pulses(position)\n        response = self.query_device(\"ma{0}\".format(pulses_hex))\n        \n        header  = response[0:3]\n\n        if blocking:\n            self._block_until_stopped()\n        return self._decode_position_response(response)\n        \n    def move_relative(self,position,blocking=True):\n        \"\"\"Moves relative to current position\n\n        Args:\n            position (float): relative position to move to, specified in degrees.\n            clockwise(bool): specifies whether we are moving in the clockwise direction. \n                    False if moving anticlockwise\n        \n        Returns:\n            None\n\n        Raises:\n            None\n\n        \"\"\"\n        pulses_hex = self._position_to_hex_pulses(position)\n        response = self.query_device(\"mr{0}\".format(pulses_hex))\n        if blocking:\n            self._block_until_stopped()\n        return self._decode_position_response(response)\n    \n    def optimize_motors(self, save_new_params=False):\n        '''Due to load, build tolerances and other mechanical variances, the\n        default resonating frequency of a particular motor may not be that\n        which delivers best performance.\n        This message fine tunes the frequency search performed by the\n        SEARCHFREQ messages. When this message is called, the\n        SEARCHFREQ message is called first automatically to optimize the\n        operating frequency. After completion, another frequency search is\n        performed and the mechanical performance is monitored to further\n        optimize the operating frequencies for backward and forward\n        movement. The values then need to be saved\n        '''\n        reply = self.query_device('om')\n        if save_new_params:\n            self.save_new_parameters()\n        return reply\n    def save_new_parameters(self):\n        return self.query_device('us')\n    \n    position = NotifiedProperty(get_position, move_absolute)\n    def get_qt_ui(self):\n        return ELL20UI(self)",
  "class ELL20UI(QuickControlBox):\n\n    def __init__(self, stage):\n        super().__init__()\n        \n        self.add_doublespinbox('position', 0, stage.TRAVEL)\n        self.auto_connect_by_name(controlled_object=stage)",
  "def __init__(self, port):\n        self.termination_character = '\\n'\n        self.port_settings = dict(baudrate=9600,\n                                  bytesize=8,\n                                  stopbits=1,\n                                  parity='N',\n                                  timeout=2,\n                                  writeTimeout=2,\n                                  xonxoff=False)\n        super().__init__(port)",
  "def __init__(self, serial_device, device_index=0, debug=0):\n        '''can be passed either a BusDistributor instance, or  \"COM5\"  '''\n        if type(serial_device) is str:\n            self.serial_device = BusDistributor(serial_device)\n        else:\n            self.serial_device = serial_device\n        self.debug = debug\n\n        Stage.__init__(self)\n        self.ui = None\n\n        #configure stage parameters\n        if str(device_index) not in self.VALID_DEVICE_IDs:\n            raise ValueError(\"Device ID: {} is not valid!\".format(device_index))\n        self.device_index = device_index\n        \n        configuration = self.get_device_info()\n        self.TRAVEL = configuration[\"travel\"]\n        self.PULSES_PER_MM = configuration[\"pulses\"]\n        \n        if self.debug > 0:\n            print(\"Travel (degrees):\", self.TRAVEL)\n            print(\"Pulses per mm\", self.PULSES_PER_MM)\n            print(\"Device status:\",self.get_device_status())",
  "def query_device(self,query):\n\n        '''\n        Wrap a generic query with the ID of the device (integer in range: 0-F)\n        so that we dont need to be explicit about this id\n        '''\n        raw_query = \"{0}{1}\".format(self.device_index,query)\n        if self.debug > 0:\n            print(\"raw_query\", raw_query)\n        raw_response = self.serial_device.query(raw_query) \n        if self.debug > 0:\n            print(\"raw_response\",raw_response)\n        return raw_response",
  "def _position_to_pulse_count(self,position):\n        '''\n        Convert from an position (specified in degrees) into the number of pulses\n        that need to be applied to the motor to turn it. \n\n        pulses_per_revolution - specified by Thorlabs as number of pulses for a revolution (360 deg) of stage\n        travel - the maximum angular motion of stage (==360 for ELL8K)\n\n        Method used when sending instructions to move to stage\n        '''\n        pulses = int(np.rint(position*self.PULSES_PER_MM))\n        if self.debug > 0:\n            print(\"Input position:\", position) \n            print(\"Pulses:\", pulses) \n        return pulses",
  "def _pulse_count_to_position(self,pulse_count):\n        '''\n        Convert from an pulse count into the degrees. \n\n        pulses_per_revolution - specified by Thorlabs as number of pulses for a revolution (360 deg) of stage\n        travel - the maximum angular motion of stage (==360 for ELL8K)\n\n        Method used when reading data received from stage\n        '''\n        return pulse_count/self.PULSES_PER_MM",
  "def _position_to_hex_pulses(self, position):\n        '''\n        Convert position in range (-360.0,360.0) (exclusive of edges) into a hex representation of pulse\n        count required for talking to the ELL8K stage\n        \n        '''\n        \n        #convert position to number of pulses used to drive motors:\n        pulses_int = self._position_to_pulse_count(position)    \n        if self.debug > 0 : print(\"Pulses (int)\", pulses_int)\n        #make two's complement to allow for -ve values\n        pulses_int = int_to_twos_complement(pulses_int)\n        if self.debug > 0 : print(\"Pulses (int,2s compl)\", pulses_int)\n        #convert integer to hex\n        pulses_hex = int_to_hex(pulses_int) \n        if self.debug > 0 : print(\"Pulses hex:\", pulses_hex)\n        return pulses_hex",
  "def _hex_pulses_to_position(self, hex_pulse_position):\n        '''\n        Convert position to position - full method for processing responses from stage\n        '''\n        binary_pulse_position = bytes_to_binary(hex_pulse_position)\n        int_pulse_position = twos_complement_to_int(binary_pulse_position)\n        return self._pulse_count_to_position(int_pulse_position)",
  "def _decode_position_response(self,response):\n        '''\n        Method for decoding positional response from stage for responses from:\n            mode_absolute, mode_relative, move_home\n        '''\n        header = response[0:3]\n        if header == \"{0}GS\".format(self.device_index):\n            #still moving\n            status_code = int(response[3:5],base=16)\n            status = self.DEVICE_STATUS_CODES[status_code]\n            outp = {\"header\": header,\"status\": status}\n            return outp\n        elif header == \"{0}PO\".format(self.device_index):\n            hex_pulse_position = response[3:11]\n            position = self._hex_pulses_to_position(hex_pulse_position)\n            outp = {\"header\": header,\"position\": position}\n            return outp",
  "def _block_until_stopped(self):\n       '''\n       Method for blocking move_absolute and move_relative and move_home commands until stage has stopped\n       Spins on get_position command comparing returned results. If between two calls position doesn't change\n       Then assume stage has stopped and exit\n       '''\n       stopped = False\n       previous_position = 0.0\n       current_position = 1.0\n        \n       try:    \n           while(stopped == False):\n               time.sleep(self.BLOCK_SLEEPING_TIME)\n               current_position = self.get_position()\n               stopped =(np.absolute(current_position - previous_position) < self.POSITION_JITTER_THRESHOLD)\n               previous_position = current_position\n       except KeyboardInterrupt:\n           return\n       return",
  "def get_position(self,axis=None):\n        '''\n        Query stage for its current position, in degrees\n        This method overrides the Stage class' method\n        '''\n        response = self.query_device(\"gp\")\n        header = response[0:3]\n        if header == \"{0}PO\".format(self.device_index):\n        #position given in twos complement representation\n            byte_position = response[3:11]\n            binary_position = bytes_to_binary(byte_position)\n            pulse_position = twos_complement_to_int(binary_position)\n            position = float(pulse_position)/self.PULSES_PER_MM\n            return position\n        else:\n            raise ValueError(\"Incompatible Header received:{}\".format(header))",
  "def move(self,pos, axis=None, relative=False):\n        '''\n        Send command to move stage.\n        pos:  specified in degrees and can be in range (-360,360)\n        relative: whether motion is relative to current position or relative to global home\n        This method overrides the Stage class' method\n        '''\n        if relative:\n            self.move_relative(pos)\n        else:\n            self.move_absolute(pos)",
  "def get_device_info(self):\n        '''\n        Instruct hardware to identify itself. \n        Give information about model, serial numbner, firmware. \n\n        This MUST be called at initialization of the stage as the key parameters:\n\n        TRAVEL, PULSES are extracted here\n\n        TRAVEL - the range of travel of the stage, specified in units (mm or deg) relevant to the type of stage\n        PULSES - specifieid the number of pulses applied to motors to move stage over entire range of travel\n\n        Hence: ratio of PULSES/TRAVEL gives number of pulses to move 1 mm or 1 deg\n        '''\n             \n        response = self.query_device(\"in\")\n\n        #decode the response\n        header = response[0:3]\n        ell = response[3:5]\n        sn = response[5:13]\n        year = response[13:17]\n        firmware_release = response[17:19]\n        hardware_release = response[19:21]\n        \n        bytes_travel = response[21:25] #units: mm/deg\n        \n        binary_travel = bytes_to_binary(bytes_travel)\n        travel = twos_complement_to_int(binary_travel)\n        \n        bytes_pulses = response[25:33]\n        binary_pulses = bytes_to_binary(bytes_pulses)\n        pulses = twos_complement_to_int(binary_pulses)\n\n        outp = {\n            \"header\" : header,\n            \"ell\" : ell,\n            \"sn\": sn,\n            \"year\": year,\n            \"firmware_release\": firmware_release,\n            \"hardware_release\": hardware_release,\n            \"travel\": travel,\n            \"pulses\": pulses\n        }\n        return outp",
  "def get_device_status(self):\n        '''\n        Query device to get its status code  - for testing that device is functioning correctly\n        '''\n\n        response = self.query_device(\"gs\")\n        #read response and decode it:\n        header = response[0:3]\n        byte_status = response[3:5]\n        if self.debug > 0: print(\"Byte status:\", byte_status)\n\n        binary_status = bytes_to_binary(byte_status)\n        if self.debug > 0: print(\"Binary status\", binary_status)\n        int_status = int(binary_status,base=2)\n\n        if int_status in list(self.DEVICE_STATUS_CODES.keys()):\n            return {\"header\": header, \"status\": self.DEVICE_STATUS_CODES[int_status]}\n        else:\n            return {\"header\": header, \"status\": self.DEVICE_STATUS_CODES[\"OutOfBounds\"]}",
  "def move_home(self, blocking=True):\n        '''\n        Move stage to factory default home location. \n        Note: Thorlabs API allows resetting stages home but this not implemented as it isnt' advised \n        '''\n\n        \n        response = self.query_device(\"ho\")\n        if blocking:\n            self._block_until_stopped()\n        return self._decode_position_response(response)",
  "def move_absolute(self, position, blocking=True):\n        \"\"\"Move to absolute position relative to home setting\n\n        Args:\n            position (float): position to move to, specified in degrees.\n\n        Returns:\n            None\n\n        Raises:\n            None\n\n        \"\"\"\n   \n        pulses_hex = self._position_to_hex_pulses(position)\n        response = self.query_device(\"ma{0}\".format(pulses_hex))\n        \n        header  = response[0:3]\n\n        if blocking:\n            self._block_until_stopped()\n        return self._decode_position_response(response)",
  "def move_relative(self,position,blocking=True):\n        \"\"\"Moves relative to current position\n\n        Args:\n            position (float): relative position to move to, specified in degrees.\n            clockwise(bool): specifies whether we are moving in the clockwise direction. \n                    False if moving anticlockwise\n        \n        Returns:\n            None\n\n        Raises:\n            None\n\n        \"\"\"\n        pulses_hex = self._position_to_hex_pulses(position)\n        response = self.query_device(\"mr{0}\".format(pulses_hex))\n        if blocking:\n            self._block_until_stopped()\n        return self._decode_position_response(response)",
  "def optimize_motors(self, save_new_params=False):\n        '''Due to load, build tolerances and other mechanical variances, the\n        default resonating frequency of a particular motor may not be that\n        which delivers best performance.\n        This message fine tunes the frequency search performed by the\n        SEARCHFREQ messages. When this message is called, the\n        SEARCHFREQ message is called first automatically to optimize the\n        operating frequency. After completion, another frequency search is\n        performed and the mechanical performance is monitored to further\n        optimize the operating frequencies for backward and forward\n        movement. The values then need to be saved\n        '''\n        reply = self.query_device('om')\n        if save_new_params:\n            self.save_new_parameters()\n        return reply",
  "def save_new_parameters(self):\n        return self.query_device('us')",
  "def get_qt_ui(self):\n        return ELL20UI(self)",
  "def __init__(self, stage):\n        super().__init__()\n        \n        self.add_doublespinbox('position', 0, stage.TRAVEL)\n        self.auto_connect_by_name(controlled_object=stage)",
  "def list_devices():\n    \"\"\"Return a list of Kinesis serial numbers\"\"\"\n    DeviceManagerCLI.DeviceManagerCLI.BuildDeviceList()\n    return DeviceManagerCLI.DeviceManagerCLI.GetDeviceList()",
  "class KCube(Stage):\n    axis_names = ('theta', )\n\n    def __init__(self, serial_number):\n        super(Stage, self).__init__()\n\n        DeviceManagerCLI.DeviceManagerCLI.BuildDeviceList()\n        self.device = KcubeDCServoCLI.KCubeDCServo.CreateKCubeDCServo(serial_number)\n        self.device.Connect(serial_number)\n        self.device.WaitForSettingsInitialized(5000)\n        self.device.EnableDevice()\n\n    def move(self, pos, axis=None, relative=False):\n        self.device.MoveTo(Decimal(pos), 60000)\n\n    def get_position(self, axis=None):\n        return float(self.device.Position.ToString())",
  "class TCube(Stage):\n    axis_names = ('theta', )\n\n    def __init__(self, serial_number):\n        super(Stage, self).__init__()\n\n        DeviceManagerCLI.DeviceManagerCLI.BuildDeviceList()\n        self.device = TcubeDCServoCLI.TCubeDCServo.CreateTCubeDCServo(serial_number)\n        self.device.Connect(serial_number)\n        self.device.WaitForSettingsInitialized(5000)\n        self.device.EnableDevice()\n\n    def move(self, pos, axis=None, relative=False):\n        self.device.MoveTo(Decimal(pos), 60000)\n\n    def get_position(self, axis=None):\n        return float(self.device.Position.ToString())",
  "class BenchtopPiezo(Stage):\n    axis_names = None\n    connected = False\n    channels = []\n    device = None\n\n    def __init__(self, serial_number):\n        self._serial_number = serial_number\n        DeviceManagerCLI.DeviceManagerCLI.BuildDeviceList()\n        self.device = BenchtopPiezoCLI.BenchtopPiezo.CreateBenchtopPiezo(serial_number)\n        self.connect()\n        super(Stage, self).__init__()\n    \n    def connect(self):\n        \"\"\"Initialise communications, populate channel list, etc.\"\"\"\n        self.device.Connect(self._serial_number)\n        self.connected = True\n        assert len(self.channels) == 0, \"Error connecting: we've already initialised channels!\"\n        for i in range(self.device.ChannelCount):\n            chan = self.device.GetChannel(i+1) # Kinesis channels are one-indexed\n            chan.WaitForSettingsInitialized(5000)\n            chan.StartPolling(250) # getting the voltage only works if you poll!\n            time.sleep(0.5) # ThorLabs have this in their example...\n            chan.EnableDevice()\n            # I don't know if the lines below are necessary or not - but removing them\n            # may or may not work...\n            time.sleep(0.5)\n            config = chan.GetPiezoConfiguration(chan.DeviceID)\n            info = chan.GetDeviceInfo()\n            max_v = Decimal.ToDouble(chan.GetMaxOutputVoltage())\n            self.channels.append(chan)\n        self.axis_names = tuple(\"channel_{}\".format(i) for i in range(self.device.ChannelCount))\n\n    def close(self):\n        \"\"\"Shut down communications\"\"\"\n        if not self.connected:\n            print(f\"Not closing piezo device {self._serial_number}, it's not open!\")\n            return\n        for chan in self.channels:\n            chan.StopPolling()\n        self.channels = []\n        self.device.Disconnect(True)\n\n    def __del__(self):\n        try:\n            if self.connected:\n                self.close()\n        except:\n            print(f\"Error closing communications on deletion of device {self._serial_number}\")\n\n    def set_output_voltages(self, voltages):\n        \"\"\"Set the output voltage\"\"\"\n        assert len(voltages) == len(self.channels), \"You must specify exactly one voltage per channel\"\n        for chan, v in zip (self.channels, voltages):\n            chan.SetOutputVoltage(Decimal(v))\n    \n    def get_output_voltages(self):\n        \"\"\"Retrieve the output voltages as a list of floating-point numbers\"\"\"\n        return [Decimal.ToDouble(chan.GetOutputVoltage()) for chan in self.channels]\n\n    output_voltages = property(get_output_voltages, set_output_voltages)\n\n    def move(self, pos, axis=None, relative=False):\n        \"\"\"Move the piezo stage.  For now, this is done in volts.\"\"\"\n        if axis is None:\n            for p, ax in zip(pos, self.axis_names):\n                self.move_axis(p, ax, relative=relative)\n        else:\n            self.move_axis(pos, axis, relative=relative)\n    \n    def move_axis(self, pos, axis, relative=False):\n        \"\"\"Move one axis (currently in volts)\"\"\"\n        chan = self.select_axis(self.channels, axis)\n        if relative:\n            # emulate relative moves\n            pos += Decimal.ToDouble(chan.GetOutputVoltage())\n        chan.SetOutputVoltage(Decimal(pos))\n\n    def get_position(self, axis=None):\n        if axis is None:\n            return [self.get_position(ax) for ax in self.axis_names]\n        else:\n            chan = self.select_axis(self.channels, axis)\n            return Decimal.ToDouble(chan.GetOutputVoltage())",
  "def __init__(self, serial_number):\n        super(Stage, self).__init__()\n\n        DeviceManagerCLI.DeviceManagerCLI.BuildDeviceList()\n        self.device = KcubeDCServoCLI.KCubeDCServo.CreateKCubeDCServo(serial_number)\n        self.device.Connect(serial_number)\n        self.device.WaitForSettingsInitialized(5000)\n        self.device.EnableDevice()",
  "def move(self, pos, axis=None, relative=False):\n        self.device.MoveTo(Decimal(pos), 60000)",
  "def get_position(self, axis=None):\n        return float(self.device.Position.ToString())",
  "def __init__(self, serial_number):\n        super(Stage, self).__init__()\n\n        DeviceManagerCLI.DeviceManagerCLI.BuildDeviceList()\n        self.device = TcubeDCServoCLI.TCubeDCServo.CreateTCubeDCServo(serial_number)\n        self.device.Connect(serial_number)\n        self.device.WaitForSettingsInitialized(5000)\n        self.device.EnableDevice()",
  "def move(self, pos, axis=None, relative=False):\n        self.device.MoveTo(Decimal(pos), 60000)",
  "def get_position(self, axis=None):\n        return float(self.device.Position.ToString())",
  "def __init__(self, serial_number):\n        self._serial_number = serial_number\n        DeviceManagerCLI.DeviceManagerCLI.BuildDeviceList()\n        self.device = BenchtopPiezoCLI.BenchtopPiezo.CreateBenchtopPiezo(serial_number)\n        self.connect()\n        super(Stage, self).__init__()",
  "def connect(self):\n        \"\"\"Initialise communications, populate channel list, etc.\"\"\"\n        self.device.Connect(self._serial_number)\n        self.connected = True\n        assert len(self.channels) == 0, \"Error connecting: we've already initialised channels!\"\n        for i in range(self.device.ChannelCount):\n            chan = self.device.GetChannel(i+1) # Kinesis channels are one-indexed\n            chan.WaitForSettingsInitialized(5000)\n            chan.StartPolling(250) # getting the voltage only works if you poll!\n            time.sleep(0.5) # ThorLabs have this in their example...\n            chan.EnableDevice()\n            # I don't know if the lines below are necessary or not - but removing them\n            # may or may not work...\n            time.sleep(0.5)\n            config = chan.GetPiezoConfiguration(chan.DeviceID)\n            info = chan.GetDeviceInfo()\n            max_v = Decimal.ToDouble(chan.GetMaxOutputVoltage())\n            self.channels.append(chan)\n        self.axis_names = tuple(\"channel_{}\".format(i) for i in range(self.device.ChannelCount))",
  "def close(self):\n        \"\"\"Shut down communications\"\"\"\n        if not self.connected:\n            print(f\"Not closing piezo device {self._serial_number}, it's not open!\")\n            return\n        for chan in self.channels:\n            chan.StopPolling()\n        self.channels = []\n        self.device.Disconnect(True)",
  "def __del__(self):\n        try:\n            if self.connected:\n                self.close()\n        except:\n            print(f\"Error closing communications on deletion of device {self._serial_number}\")",
  "def set_output_voltages(self, voltages):\n        \"\"\"Set the output voltage\"\"\"\n        assert len(voltages) == len(self.channels), \"You must specify exactly one voltage per channel\"\n        for chan, v in zip (self.channels, voltages):\n            chan.SetOutputVoltage(Decimal(v))",
  "def get_output_voltages(self):\n        \"\"\"Retrieve the output voltages as a list of floating-point numbers\"\"\"\n        return [Decimal.ToDouble(chan.GetOutputVoltage()) for chan in self.channels]",
  "def move(self, pos, axis=None, relative=False):\n        \"\"\"Move the piezo stage.  For now, this is done in volts.\"\"\"\n        if axis is None:\n            for p, ax in zip(pos, self.axis_names):\n                self.move_axis(p, ax, relative=relative)\n        else:\n            self.move_axis(pos, axis, relative=relative)",
  "def move_axis(self, pos, axis, relative=False):\n        \"\"\"Move one axis (currently in volts)\"\"\"\n        chan = self.select_axis(self.channels, axis)\n        if relative:\n            # emulate relative moves\n            pos += Decimal.ToDouble(chan.GetOutputVoltage())\n        chan.SetOutputVoltage(Decimal(pos))",
  "def get_position(self, axis=None):\n        if axis is None:\n            return [self.get_position(ax) for ax in self.axis_names]\n        else:\n            chan = self.select_axis(self.channels, axis)\n            return Decimal.ToDouble(chan.GetOutputVoltage())",
  "def squawk():\n    for i in range(5):\n        winsound.Beep(random.randrange(37,3500),random.randrange(70,750)) \n    return 'I did a thing'",
  "class Rotators(QtWidgets.QWidget, Instrument):\n    ''' takes a list of rotators (must have a move function, should be a subclass of Stage),\n    and makes a simple gui for them. Enter a list of angles to turn to, and they will be\n    iterated through according to the rules of itertools.zip_longest, and the payload \n    function called, and its results saved. payload should return the data to be saved. \n    allowed formats:\n        A: 0, 10, 20\n        B: 0, 45, 90\n        C: \n            #will not move rotator c\n        A: np.linspace(0, 360, 10)\n        B: np.arange(0, 360, 10)\n        C: 45\n        # will set C to 45 deg, B will continue moving and taking measurements \n        # after A runs out\n        '''\n    def __init__(self, rotators, payload=squawk):\n        QtWidgets.QWidget.__init__(self)\n        Instrument.__init__(self)\n        self.rotators = rotators\n        self.payload = payload\n        \n        self.edits = {r: [] for r in rotators}\n        \n        lines_widget = QtWidgets.QWidget()\n        lines_layout = QtWidgets.QFormLayout()\n        \n        for label, r in rotators.items():\n            l = QtWidgets.QLabel(label)\n            self.edits[label] = (t := QtWidgets.QLineEdit())\n            t.editingFinished.connect(self.textChanged)\n            lines_layout.addRow(l, t)  \n        lines_widget.setLayout(lines_layout)\n        layout = QtWidgets.QHBoxLayout()\n        layout.addWidget(lines_widget)\n        self.run_pushButton = QtWidgets.QPushButton('Run')\n        self.run_pushButton.clicked.connect(self.run)\n        layout.addWidget(self.run_pushButton)\n        self.setLayout(layout)\n\n    def textChanged(self):\n       self.angles = {r: self.parse_edit(self.edits[r]) for r in self.rotators}\n       \n    @staticmethod\n    def parse_edit(edit):\n        text = edit.text()\n        if text:\n            if text.startswith('np.'):\n                return eval(text.strip()).tolist()\n            split = (s for s in re.split(r',| |;', text) if s)\n            return list(map(float, split))\n        else:\n            return []\n        \n    @background_action\n    def run(self, checked):\n        zipped_angles = zip_longest(*self.angles.values(), fillvalue=None)\n        rotators = [self.rotators[key] for key in self.angles]\n        for angles in (zipped_angles):\n            for r, a in zip(rotators, angles):\n                if a is not None:\n                    r.move(a)\n            data = ArrayWithAttrs(self.payload())\n            data.attrs.update({l: r.position for l, r in self.rotators.items()})\n            self.create_dataset('rotator_data_%d', data=data)\n  \n    def get_qt_ui(self):\n         return self",
  "def __init__(self, rotators, payload=squawk):\n        QtWidgets.QWidget.__init__(self)\n        Instrument.__init__(self)\n        self.rotators = rotators\n        self.payload = payload\n        \n        self.edits = {r: [] for r in rotators}\n        \n        lines_widget = QtWidgets.QWidget()\n        lines_layout = QtWidgets.QFormLayout()\n        \n        for label, r in rotators.items():\n            l = QtWidgets.QLabel(label)\n            self.edits[label] = (t := QtWidgets.QLineEdit())\n            t.editingFinished.connect(self.textChanged)\n            lines_layout.addRow(l, t)  \n        lines_widget.setLayout(lines_layout)\n        layout = QtWidgets.QHBoxLayout()\n        layout.addWidget(lines_widget)\n        self.run_pushButton = QtWidgets.QPushButton('Run')\n        self.run_pushButton.clicked.connect(self.run)\n        layout.addWidget(self.run_pushButton)\n        self.setLayout(layout)",
  "def textChanged(self):\n       self.angles = {r: self.parse_edit(self.edits[r]) for r in self.rotators}",
  "def parse_edit(edit):\n        text = edit.text()\n        if text:\n            if text.startswith('np.'):\n                return eval(text.strip()).tolist()\n            split = (s for s in re.split(r',| |;', text) if s)\n            return list(map(float, split))\n        else:\n            return []",
  "def run(self, checked):\n        zipped_angles = zip_longest(*self.angles.values(), fillvalue=None)\n        rotators = [self.rotators[key] for key in self.angles]\n        for angles in (zipped_angles):\n            for r, a in zip(rotators, angles):\n                if a is not None:\n                    r.move(a)\n            data = ArrayWithAttrs(self.payload())\n            data.attrs.update({l: r.position for l, r in self.rotators.items()})\n            self.create_dataset('rotator_data_%d', data=data)",
  "def get_qt_ui(self):\n         return self",
  "def get_enums(): # get status return values from MCSControl.h\n    with open(os.path.join(file_dir, 'MCSControl.h'), 'r') as f:\n        lines = [line.strip().split(' ') for line in f.readlines() if line.startswith('#define')]\n        enums = {}\n        for line in lines:\n            while '' in line: line.remove('')\n            if len(line) == 3:\n                try:\n                    enums[line[1]] = int(line[2])\n                except ValueError:\n                    pass\n    return enums",
  "def set_enums():\n    enums = get_enums()\n    for k, v in zip(list(enums.keys()), list(enums.values())):\n        # print k+' = '+str(v)\n        cmd = k + ' = c_int(' + str(v) + ')'\n        exec(cmd, globals())",
  "class MCSError(Exception):\n    def __init__(self, value):\n        try:\n            self.value = value\n            error_text = ctypes.c_char_p()\n            mcsc.SA_GetStatusInfo(value, byref(error_text))\n            print(\"MCS error {:d}\".format(value))\n            print(ctypes.string_at(error_text))\n        except:\n            print(\"MCS error {:d}\".format(value))",
  "class SmaractMCS(PiezoStage):\n    \"\"\"\n    Smaract MCS controller interface for Smaract stages.\n    Check SmarAct's MCS Progammer's Guide for mor information.\n    \"\"\"\n\n    @staticmethod\n    def check_status(status):\n        \"\"\"\n        Checks the status of the MCS controller. If not 'SA_OK' return the MCSError code\n        \"\"\"\n        if (status != SA_OK.value):\n            raise MCSError(status)\n        else:\n            return True\n\n    @classmethod\n    def find_mcs_systems(cls):\n        \"\"\"\n        Get a list of all MCS devices available on this computer. The list\n        contains MCS IDs which are unique numbers to identify a MCS.\n        \"\"\"\n        outBuffer = ctypes.create_string_buffer(4096)\n        bufferSize = c_int(4096)  # ctypes.sizeof(outBuffer)\n        # outBuffer holds the locator strings, separated by '\\n'\n        # bufferSize holds the number of bytes written to outBuffer\n        if cls.check_status(mcsc.SA_FindSystems(\"\", outBuffer, byref(bufferSize))):\n#            print 'buffer size:', bufferSize\n            print('buffer:', ctypes.string_at(outBuffer))\n        return ctypes.string_at(outBuffer)\n\n    def __init__(self, system_id):\n        super(SmaractMCS, self).__init__()\n        self.mcs_id = system_id\n        self.handle = c_int(0)\n        # self.setup()  #?? why setup() not used anymore?? => sets sensor power modes, low vibration modes, speeds, acceleration, ... => maybe because don't need to be set/changed for every software start??\n        self.is_open = False\n        self._num_ch = None\n        self.axis_names = tuple(i for i in range(self.num_ch))\n        self.positions = [0 for ch in range(self.num_ch)]\n        self.levels = [0 for ch in range(self.num_ch)]\n        self.voltages = [0 for ch in range(self.num_ch)]\n        self.scan_positions = [0 for ch in range(self.num_ch)]\n        self.min_voltage = [0 for ch in range(self.num_ch)]\n        self.max_voltage = [100 for ch in range(self.num_ch)]\n        self.min_voltage_levels = [0 for ch in range(self.num_ch)]\n        self.max_voltage_levels = [4095 for ch in range(self.num_ch)]\n\n\n    ### ====================== ###\n    ### Initialization methods ###\n    ### ====================== ###\n\n    def check_open_status(self):\n        if self.open_mcs():\n            return\n        else:\n            raise SmaractError('Error opening')\n\n    def open_mcs(self):\n        if not self.is_open:\n            mode = ctypes.c_char_p('sync') # use synchronouse communication mode\n            if self.check_status(mcsc.SA_OpenSystem(byref(self.handle), self.mcs_id, mode)):\n                self.is_open = True\n                return True\n            else:\n                return False\n        else:\n            return True\n\n    def close_mcs(self):\n        if self.is_open:\n            if self.check_status(mcsc.SA_CloseSystem(self.handle)):\n                self.is_open = False\n                return True\n            else:\n                return False\n        else:\n            return True\n\n    def get_num_channels(self):\n        if self._num_ch is not None:\n            return self._num_ch\n        num_ch = c_int()\n        self.check_open_status()\n        if self.check_status(mcsc.SA_GetNumberOfChannels(self.handle, byref(num_ch))):\n            self._num_ch = num_ch.value\n            return num_ch.value\n        else:\n            return False\n\n    def setup(self):\n        self.check_open_status()\n        self.set_sensor_power_mode(2)\n        for i in range(self.num_ch):\n            self.set_speed(ch, 0)\n            self.set_acceleration(ch, 0)\n            self.set_low_vibration_mode(ch, 1)\n            ch = c_int(i)\n            self.check_status(mcsc.SA_SetStepWhileScan_S(self.handle, ch, SA_NO_STEP_WHILE_SCAN))\n\n\n\n    def get_sensor_type(self, ch):\n        \"\"\"\n        returns the sensor type for a given channel ch\n        For a list of sensor types see MCS Programmer's Guide\n        \"\"\"\n        ch = c_int(int(ch))\n        sensor_type = c_int()\n        self.check_open_status()\n        mcsc.SA_GetSensorType_S(self.handle, ch, byref(sensor_type))\n        return sensor_type.value\n\n\n\n    def set_sensor_type(self, ch, sensor_type):\n        \"\"\"\n        sets the sensor type for a given channel ch\n        For a list of sensor types see MCS Programmer's Guide\n        \"\"\"\n        ch = c_int(int(ch))\n        sensor_type = c_int(int(sensor_type))\n        self.check_open_status()\n        mcsc.SA_SetSensorType_S(self.handle, ch, sensor_type)\n\n\n    def set_sensor_power_mode(self, mode):\n        modes = {0: SA_SENSOR_DISABLED, 1: SA_SENSOR_ENABLED, 2: SA_SENSOR_POWERSAVE}\n        self.check_open_status()\n        self.check_status(mcsc.SA_SetSensorEnabled_S(self.handle, modes[mode]))\n\n    def set_low_vibration_mode(self, ch, enable):\n        ch = c_int(int(ch))\n        values = {0: SA_DISABLED, 1: SA_ENABLED}\n        self.check_open_status()\n        self.check_status(mcsc.SA_SetChannelProperty_S(self.handle, ch,\n                                                       mcsc.SA_EPK(SA_GENERAL, SA_LOW_VIBRATION, SA_OPERATION_MODE),\n                                                       values[enable]))\n\n    def get_acceleration(self, ch):\n        ch = c_int(int(ch))\n        acceleration = c_int()\n        self.check_open_status()\n        mcsc.SA_GetClosedLoopMoveAcceleration_S(self.handle, ch, byref(acceleration))\n        return acceleration.value\n\n    def set_acceleration(self, ch, acceleration):\n        '''\n        units are um/s/s.\n        '''\n        ch = c_int(int(ch))\n        acceleration = c_int(int(acceleration))\n        self.check_open_status()\n        mcsc.SA_SetClosedLoopMoveAcceleration_S(self.handle, ch, acceleration)\n\n    def get_speed(self, ch):\n        ch = c_int(int(ch))\n        speed = c_int()\n        self.check_open_status()\n        self.check_status(mcsc.SA_GetClosedLoopMoveSpeed_S(self.handle, ch,\n                                                           byref(speed)))\n        return speed.value\n\n    def set_speed(self, ch, speed):\n        '''\n        units are nm/s, max is 1e8. A value of 0 deactivates speed control\n        (defaults to max.).\n        '''\n        ch = c_int(int(ch))\n        speed = c_int(int(speed))\n        self.check_open_status()\n        self.check_status(mcsc.SA_SetClosedLoopMoveSpeed_S(self.handle, ch,\n                                                           speed))\n\n    def get_frequency(self, ch):\n        ch = c_int(int(ch))\n        frequency = c_int()\n        self.check_open_status()\n        self.check_status(mcsc.SA_GetClosedLoopMaxFrequency_S(self.handle, ch,\n                                                              byref(frequency)))\n        return frequency.value\n\n    def set_frequency(self, ch, frequency):\n        '''\n        units are nm/s, min is 50, max is 18,500. A value of 0 deactivates speed control\n        (defaults to max.).\n        '''\n        ch = c_int(int(ch))\n        frequency = c_int(int(frequency))\n        self.check_open_status()\n        self.check_status(mcsc.SA_SetClosedLoopMaxFrequency_S(self.handle, ch,\n                                                              frequency))\n\n    ### Calibration Methods ###\n\n    def wait_until_stopped(self, ch):\n        status = c_int(4)\n        if type(ch) is not c_int:\n            ch = c_int(ch)\n        while status.value != SA_STOPPED_STATUS.value:\n            self.check_status(mcsc.SA_GetStatus_S(self.handle, ch, byref(status)))\n        return\n\n    def get_channel_status(self, ch):\n        ch = c_int(ch)\n        status = c_int(4)\n        self.check_status(mcsc.SA_GetStatus_S(self.handle, ch, byref(status)))\n        return status.value\n\n    def calibrate_system(self):\n        print('calibrating system')\n        self.check_open_status()\n        self.set_sensor_power_mode(1)\n        num_ch = self.get_num_channels()\n        for ch in range(num_ch):\n            self.check_status(mcsc.SA_CalibrateSensor_S(self.handle, ch))\n            self.wait_until_stopped(ch)\n\n    def set_safe_directions(self):\n        \"\"\"\n        Sets the safe directions for all channels to move when referencing.\n        Vertical channels should all move upwards (i.e. SA_FORWARD_DIRECTION).\n        The left channel should move left (SA_BACKWARD_DIRECTION) while the\n        right channel should move right (SA_FORWARD_DIRECTION). The remaining\n        two forward channels should move backwards away from the objective\n        (SA_BACKWARD_DIRECTION).\n\n        Note that this function is currently based on the tip experiment arrangement.\n        \"\"\"\n        self.check_open_status()\n        # self.set_sensor_power_mode(1)\n        num_ch = self.get_num_channels()\n        forward_channels = [3]  # was [0,1,2,5]\n        for i in range(num_ch):\n            value = SA_FORWARD_DIRECTION if (i in forward_channels) \\\n                else SA_BACKWARD_DIRECTION\n            ch = c_int(int(i))\n            self.check_status(mcsc.SA_SetSafeDirection_S(self.handle,\n                                                         ch, value))\n        return forward_channels\n\n    def find_references_ch(self, ch):\n        print('finding reference for ch', ch)\n        ch = c_int(int(ch))\n        self.check_open_status()\n        self.set_sensor_power_mode(1)\n        forward_channels = self.set_safe_directions()\n        value = SA_FORWARD_DIRECTION if (ch.value in forward_channels) else SA_BACKWARD_DIRECTION\n        self.check_status(mcsc.SA_FindReferenceMark_S(self.handle, ch, value, 0, SA_AUTO_ZERO))\n        self.wait_until_stopped(ch)\n\n    def find_references(self):\n        self.check_open_status()\n        num_ch = self.get_num_channels()\n        for i in range(num_ch):\n            self.find_references_ch(i)\n\n\n    \"\"\" =============================\n        position of rotary positioner\n        =============================\n    \"\"\"\n    def move_angle_absolute(self, ch, angle, revolution, holdTime):\n        \"\"\"\n        ch: positioner channel\n        angle: absolute angle to move in micro degrees: 0 .. 359,999,999\n        revolution: absolute revolution to move: -32,768 .. 32,767\n        holdTime: time in milliseconds the angle is actively hold after reaching target: 0 .. 60,000\n        with 0 deactivating feature and 60,000 is infinite/until manually stopped\n        \"\"\"\n        ch = c_uint32(int(ch))\n        angle = c_uint32(int(angle))\n        revolution = c_int32(int(angle))\n        holdTime = c_uint32(int(holdTime))\n        self.check_open_status()\n        mcsc.SA_GoToAngleAbolute_S(self.handle, ch, angle, revolution, holdTime)\n\n\n    def move_angle_relative(self, ch, angle, revolution, holdTime):\n        \"\"\"\n        ch: positioner channel\n        angle: relative angle to move in micro degrees: -359,999,999 .. 359,999,999\n        revolution: relative revolution to move: -32,768 .. 32,767\n        holdTime: time in milliseconds the angle is actively hold after reaching target: 0 .. 60,000\n        with 0 deactivating feature and 60,000 is infinite/until manually stopped\n        \"\"\"\n        ch = c_uint32(int(ch))\n        angle = c_int32(int(angle))\n        revolution = c_int32(int(angle))\n        holdTime = c_uint32(int(holdTime))\n        self.check_open_status()\n        mcsc.SA_GoToAngleRelative_S(self.handle, ch, angle, revolution, holdTime)\n\n    def get_angle(self,ch):\n        \"\"\"\n        returns the absolute angle and revolutions of the given positioner channel ch\n        \"\"\"\n        ch = c_uint32(int(ch))\n        angle = c_uint32()\n        revolution = c_int32()\n        self.check_open_status()\n        mcsc.SA_GetAngle_S(self.handle, byref(angle), byref(revolution))\n        return [angle.value, revolution.value]\n\n\n\n\n    ### ==================================================== ###\n    ### Methods to read-out position and move to a specific  ###\n    ### position via slip-stick motion and piezo movement    ###\n    ## ===================================================== ###\n\n    def get_position(self, axis=None):\n        \"\"\"\n        Get the position of the stage or of a specified axis.\n        :param axis:\n        :return:\n        \"\"\"\n        if axis is None:\n            return [self.get_position(axis) for axis in self.axis_names]\n        else:\n            if axis not in self.axis_names:\n                raise ValueError(\"{0} is not a valid axis, must be one of {1}\".format(axis, self.axis_names))\n            ch = c_int(int(axis))\n            position = c_int()\n            self.check_open_status()\n            mcsc.SA_GetPosition_S(self.handle, ch, byref(position))\n            return 1e-9 * position.value\n\n    def move(self, position, axis, relative=False):\n        \"\"\"\n        Move the stage to the requested position. The function should block all further\n        actions until the stage has finished moving.\n        :param position: units of m (SI units, converted to nm in the method)\n        :param axis: integer channel index\n        :param relative:\n        :return:\n        \"\"\"\n        if axis not in self.axis_names:\n            raise ValueError(\"{0} is not a valid axis, must be one of {1}\".format(axis, self.axis_names))\n        position *= 1e9\n        ch = c_int(int(axis))\n        position = c_int(int(position))\n        self.check_open_status()\n        if relative:\n            self.check_status(mcsc.SA_GotoPositionRelative_S(self.handle, ch, position, c_int(0)))\n        else:\n            self.check_status(mcsc.SA_GotoPositionAbsolute_S(self.handle, ch, position, c_int(0)))\n        self.wait_until_stopped(ch)\n\n    def stop(self, axis=None):\n        \"\"\"\n        stops any ongoing movement of the positioner\n        \"\"\"\n        if axis is None: # stop movement of all positioner\n            axes= [c_int(int(axis)) for axis in self.axis_names]\n            for ch in axes:\n                self.check_status(mcsc.SA_Stop_S(self.handle, ch))\n        elif axis not in self.axis_names: # wrong positioner name\n            raise ValueError(\"{0} is not a valid axis, must be one of {1}\".format(axis, self.axis_names))\n        else:  # just stop movement of specified positioner\n            ch = c_int(int(axis))\n            self.check_status(mcsc.SA_Stop_S(self.handle, ch))\n\n    def set_initial_position(self, ch, position):\n        \"\"\"\n        defines the current position to have a specific value; the measuring\n        scale is shifted accordingly\n        \"\"\"\n        ch = c_int(int(ch))\n        position = c_int(position)\n        self.check_open_status()\n        mcsc.SA_SetPosition_S(self.handle, ch, position)\n\n    def set_position(self, ch, position): # same as set_initial_position() !!!\n        '''\n        units are nm\n        '''\n        position *= 1e9\n        ch = c_int(int(ch))\n        position = c_int(int(position))\n        self.check_open_status()\n        mcsc.SA_SetPosition_S(self.handle, ch, position)\n\n    def physical_position_known(self, ch):\n        ch = c_int(int(ch))\n        known = c_int()\n        self.check_open_status()\n        mcsc.SA_GetPhysicalPositionKnown_S(self.handle, ch, byref(known))\n        if known == SA_PHYSICAL_POSITION_KNOWN:\n            return True\n        elif known == SA_PHYSICAL_POSITION_UNKNOWN:\n            return False\n        else:\n            raise SmaractError('Unknown return value')\n\n    def multi_move(self, positions, axes, relative=False): #?? doesn't this method include the simple move() method??\n        self.check_open_status()\n\n        positions = [c_int(1e9 * p) for p in positions]\n        channels = [c_int(int(axis)) for axis in axes]\n\n        for i in range(len(axes)):\n            if relative:\n                self.check_status(mcsc.SA_GotoPositionRelative_S(self.handle, channels[i], positions[i], c_int(0)))\n            else:\n                self.check_status(mcsc.SA_GotoPositionAbsolute_S(self.handle, channels[i], positions[i], c_int(0)))\n        for axis in axes:\n            self.wait_until_stopped(axis)\n\n    def multi_move_rel(self, step, axes):\n        steps = [1e9 * step for axis in axes]\n        self.multi_move(steps, axes, relative=True)\n\n\n    ### ==================================== ###\n    ### Method to control slip-stick motion ###\n    ### ==================================== ###\n\n    def slip_stick_move(self, axis, steps=1, amplitude=1800, frequency=100):\n        \"\"\"\n        this method perforems a burst of slip-stick coarse motion steps.\n\n        :param axis: chanel index of selected SmarAct stage\n        :param steps: number and direction of steps, ranging between -30,000 .. 30,000\n                      with 0 stopping the positioner and +/-30,000 perfomes unbounded\n                      move, which is strongly riscouraged!\n        :param amplitude: voltage amplitude of the pulse send to the piezo,\n                          ranging from 0 .. 4,095 with 0 corresponding to 0 V\n                          and 4,095 corresponding to 100 V, a value of 2047\n                          roughly leads to a 500 nm step\n        :param frequency: frequency the steps are performed with in Hz, ranging\n                          from 1 .. 18,500\n        \"\"\"\n        if axis not in self.axis_names:\n            raise ValueError(\"{0} is not a valid axis, must be one of {1}\".format(axis, self.axis_names))\n        ch = c_int(int(axis))\n        steps = c_int(int(steps))\n        amplitude = c_uint(int(amplitude))\n        frequency = c_uint(int(frequency))\n        self.check_open_status()\n        self.check_status(mcsc.SA_StepMove_S(self.handle, ch, steps, amplitude, frequency))\n\n\n    ### ===================================== ###\n    ### Methods to control the piezo scanners ###\n    ### ===================================== ###\n\n    ### primary methods that provide diret interface to MCS main controller\n\n    def get_piezo_position(self, axis=None):\n        \"\"\"\n        Get the scanning position of the stage or of a specified axis.\n        :param axis:\n        :return:\n        \"\"\"\n        if axis is None:\n            return [1e-9*10.*self.get_voltage(axis) for axis in self.axis_names]\n        else:\n            if axis not in self.axis_names:\n                raise ValueError(\"{0} is not a valid axis, must be one of {1}\".format(axis, self.axis_names))\n            voltage = self.get_voltage(axis)\n            position = 1e-9*10.*voltage\n            return position\n\n    def get_piezo_level(self, axis=None):\n        \"\"\"\n        Get the voltage levels (0-4095) of the specified piezo axis\n        \"\"\"\n        if axis is None:\n            return [self.get_piezo_level(axis) for axis in self.axis_names]\n        else:\n            if axis not in self.axis_names:\n                raise ValueError(\"{0} is not a valid axis, must be one of {1}\".format(axis, self.axis_names))\n            ch = c_int(int(axis))\n            level = c_int()\n            self.check_open_status()\n            mcsc.SA_GetVoltageLevel_S(self.handle, ch, byref(level))\n            return level.value\n\n    def set_piezo_level(self, level, axis, speed=4095, relative=False):\n        \"\"\"\n        Scan up to 100V\n        level: 0 - 100 V, 0 - 4095\n        speed: 4095 s - 1 us for full 4095 voltage range, 1 - 4,095,000,000\n        \"\"\"\n        if axis not in self.axis_names:\n            raise ValueError(\"{0} is not a valid axis, must be one of {1}\".format(axis, self.axis_names))\n        ch = c_int(int(axis))\n        level = c_int(int(level))\n        speed = c_int(int(speed))\n        self.check_open_status()\n        if relative:\n            self.check_status(mcsc.SA_ScanMoveRelative_S(self.handle, ch, level, speed))\n        else:\n            self.check_status(mcsc.SA_ScanMoveAbsolute_S(self.handle, ch, level, speed))\n        self.wait_until_stopped(ch)\n\n    def multi_set_piezo_level(self, levels, axes, speeds, relative=False):\n        self.check_open_status()\n        levels = [c_int(int(level)) for level in levels]\n        axes = [c_int(int(axis)) for axis in axes]\n        speeds = [c_int(int(speed)) for speed in speeds]\n        for i in range(len(axes)):\n            if relative:\n                pass\n            else:\n                self.check_status(mcsc.SA_ScanMoveAbsolute_S(self.handle, axes[i], levels[i], speeds[i]))\n        for axis in axes:\n            self.wait_until_stopped(axis)\n\n\n    ### additional useful methods to control the piezo scanners\n\n    def set_piezo_level_rel(self, diff, axis, speed=4095):\n        \"\"\"\n        Scan up to 50V\n        diff: -100 - 100 V, -4095 - 4095\n        speed: 4095 s - 1 us for full 4095 voltage range, 1 - 4,095,000,000\n        \"\"\"\n        self.set_piezo_level(diff, axis, speed, relative=True)\n\n    def get_piezo_voltage(self, ch):\n        level = self.get_piezo_level(ch)\n        voltage = self.level_to_voltage(level)\n        return voltage\n\n    def set_piezo_voltage(self, axis, voltage, speed=4095000000, relative=False):\n        \"\"\"\n        Scan to 50V\n        level: 0 - 100 V, 0 - 4095\n        speed: 4095 s - 1 us for full 4095 voltage range, 1 - 4,095,000,000\n        \"\"\"\n        level = self.voltage_to_level(voltage)\n        self.set_piezo_level(level, axis, speed, relative)\n\n    def set_piezo_voltage_rel(self, axis, voltage_diff, speed):\n        \"\"\"\n        Scan to 50V\n        level: 0 - 100 V, 0 - 4095\n        speed: 4095 s - 1 us for full 4095 voltage range, 1 - 4,095,000,000\n        \"\"\"\n        diff = self.voltage_to_level(voltage_diff)\n        self.set_piezo_level(diff, axis, speed, relative=True)\n\n    def set_piezo_position(self, position, axis, speed, relative=False):\n        level = self.position_to_level(1e9*position)\n        self.set_piezo_level(level, axis, speed, relative)\n\n    def set_piezo_position_rel(self, axis, step, speed):\n        diff = self.position_to_level(1e9*step)\n        self.set_piezo_level(diff, axis, speed, relative=True)\n\n    def multi_set_piezo_voltage(self, voltages, axes, speeds, relative=False):\n        levels = [self.voltage_to_level(v) for v in voltages]\n        self.multi_set_piezo_level(levels, axes, speeds, relative)\n\n    def multi_set_piezo_position(self, positions, axes, speeds, relative=False):\n        levels = [self.position_to_level(1e9*p) for p in positions]\n        self.multi_set_piezo_level(levels, axes, speeds, relative)\n\n    def position_to_level(self, position):\n        # 1.5 um per 100 V, position can be between 0 and 1500 nm\n        voltage = position / 15.\n        level = self.voltage_to_level(voltage)\n        return level\n\n    def voltage_to_level(self, voltage):\n        level = voltage * 4095. / 100.\n        level = round(level)\n        return level\n\n    def level_to_voltage(self, level):\n        voltage = 100. * level / 4095.\n        return voltage\n\n    def level_to_position(self, level):\n        voltage = self.level_to_voltage(level)\n        position = voltage * 10.\n        return position\n\n    def get_qt_ui(self):\n        return SmaractMCSUI(self)\n\n    ### Useful Properties ###\n    num_ch = property(get_num_channels)\n    position = property(get_position)\n    piezo_levels = property(get_piezo_level)\n    piezo_position = property(get_piezo_position)",
  "class SmaractStageUI(StageUI):\n    def __init__(self, stage):\n        super(SmaractStageUI, self).__init__(stage, stage_step_min=50e-9)\n\n    def move_axis_relative(self, index, axis, dir=1):\n        if axis in [1,2,4,5]:\n            dir *= -1\n        self.stage.move(dir*self.step_size[index], axis=axis, relative=True)\n        self.update_ui[int].emit(axis)",
  "class MCSSerialError(Exception):\n    def __init__(self, error_msg):\n        self.channel = error_msg[0]\n        self.error_code = error_msg[1]\n        self.error = {}\n        self.error['0'] = 'No Error'\n        self.error['1'] = 'Syntax Error'\n        self.error['2'] = 'Invalid Command Error'\n        self.error['3'] = 'Overflow Error'\n        self.error['4'] = 'Parse Error'\n        self.error['5'] = 'Too Few Parameters Error'\n        self.error['6'] = 'Too Many Parameters Error'\n        self.error['7'] = 'Invalid Parameter Error'\n        self.error['8'] = 'Wrong Mode Error'\n        self.error['129'] = 'No Sensor Present Error'\n        self.error['140'] = 'Sensor Disabled Error'\n        self.error['141'] = 'Command Overridden Error'\n        self.error['142'] = 'End Stop Reached Error'\n        self.error['143'] = 'Wrong Sensor Type Error'\n        self.error['144'] = 'Could Not Find Reference Mark Error'\n        self.error['145'] = 'Wrong End Effector Type Error'\n        self.error['146'] = 'Movement Locked Error'\n        self.error['147'] = 'Range Limit Reached Error'\n        self.error['148'] = 'Physical Position Unknown Error'\n        self.error['150'] = 'Command Not Processable Error'\n        self.error['151'] = 'Waiting For Trigger Error'\n        self.error['152'] = 'Command ot Triggeral Error'\n        self.error['153'] = 'Command Queue Full Error'\n        self.error['154'] = 'Invalid Component Error'\n        self.error['155'] = 'Invalid Sub Component Error'\n        self.error['156'] = 'Invalid Property Error'\n        self.error['157'] = 'Permission Denied Error'\n\n    def __str__(self):\n        if self.channel == '-1':\n            return \"[%s] %s\" % (self.error_code, self.error[self.error_code])\n        else:\n            return \"[%s]: %s for channel %s\" % (self.error_code, self.error[self.error_code], self.channel)",
  "class SmaractMCSSerial(SerialInstrument,PiezoStage):\n    \"\"\"\n    RS232 Smaract MCS controller interface for SmarAct stages.\n\n    Check SmarAct's \"MCS ASCII Programming Interface\" Guide for mor information\n    general command structure: <inital_character><command name>[param][,param]...<termination_character>\n    with command names are a combination of uppercase letters and parameters\n    given as decimal values which can be positive or negative\n\n    \"\"\"\n    port_settings = dict(baudrate=9600,\n                        bytesize=serial.EIGHTBITS,\n                        parity=serial.PARITY_NONE,\n                        stopbits=serial.STOPBITS_ONE,\n                        timeout=1, #wait at most one second for a response\n                        writeTimeout=1, #similarly, fail if writing takes >1s\n                        xonxoff=False, rtscts=False, dsrdtr=False,\n                    )\n    def __init__(self,port):\n        self.initial_character = ':'\n        self.termination_character = '\\n'\n        super(SmaractMCSSerial, self).__init__(port=port)\n        self._num_ch = None\n        self.unit=\"m\"\n        self.axis_names = tuple(i for i in range(self.num_ch))\n        self.positions = [0 for ch in range(self.num_ch)]\n        self.levels = [0 for ch in range(self.num_ch)]\n        self.voltages = [0 for ch in range(self.num_ch)]\n        self.scan_positions = [0 for ch in range(self.num_ch)]\n        self.min_voltage = [0 for ch in range(self.num_ch)]\n        self.max_voltage = [100 for ch in range(self.num_ch)]\n        self.min_voltage_levels = [0 for ch in range(self.num_ch)]\n        self.max_voltage_levels = [4095 for ch in range(self.num_ch)]\n\n        # necessary to open the serial port? Or done automatically during class initialisation?\n\n    \"\"\"\n        overwrite query() from message_bus_instrumennt class to implement error detection\n    \"\"\"\n    def query(self,queryString,multiline=False,termination_line=None,timeout=None):\n        \"\"\"\n        original query() from message_bus_instrumennt class overwritten to\n        implement error detection\n        \"\"\"\n        with self.communications_lock:\n            self.flush_input_buffer()\n            self.write(queryString) # intial and termination character are added in write()\n            if self.ignore_echo == True: # Needs Implementing for a multiline read!\n                first_line = self.readline(timeout).strip()\n                if first_line == queryString:\n                    return self.check_for_error(self.readline(timeout).strip())\n                else:\n                    print('This command did not echo!!!')\n                    return first_line\n\n            if termination_line is not None:\n                multiline = True\n            if multiline:\n                return self.check_for_error(self.read_multiline(termination_line))\n            else:\n                return self.check_for_error(self.readline(timeout).strip())\n\n\n\n    def check_for_error(self,response):\n        if response[1] == \"E\" and not response[-1] == \"0\":\n            print(response)\n            raise MCSSerialError(response[2:].split(','))\n        else:\n            return response\n\n\n    \"\"\" =======================\n        Initialisation commands\n        =======================\n    \"\"\"\n    def get_communication_mode(self):\n        mode = self.query(\"GCM\")\n        if mode[-1] == '0':\n            print(\"synchronous communication mode\")\n        elif mode[-1] == '1':\n            print(\"asynchronous communication mode\")\n        return int(mode[-1])\n\n    def set_communication_mode(self,mode):\n        if mode == \"sync\" or mode == \"synchronous\" or mode == \"0\":\n            self.write(\"SCM0\")\n        elif mode == \"async\" or mode == \"asynchronous\" or mode == \"1\":\n            self.write(\"SCM1\")\n        else:\n            raise ValueError(\"No valid communication mode. Possible modes are: 'sync' or 'async'.\")\n\n    def set_baud_rate(self,baudrate):\n        \"\"\"\n        the baud rate is stored to non-volatile memory and loaded on future power ups\n        valid range for baudrate: 9,600 .. 115,200\n        \"\"\"\n        self.write(\"CB\"+str(baudrate))\n\n    def get_channel_type(self,ch):\n        response = self.query(\"GCT\"+str(ch))\n        return int(response[-1])\n\n    def get_interface_version(self):\n        response = self.query(\"GIV\")[3:].split(',')\n        print(\"versionHigh:\", response[0])\n        print(\"versionLow:\", response[1])\n        print(\"versionUpdate:\", response[2])\n        return response\n\n    def get_num_channels(self):\n        if self._num_ch is not None:\n            return self._num_ch\n        self._num_ch = int(self.query(\"GNC\")[2:])\n        return self._num_ch\n\n    def get_system_id(self):\n        return str(self.query(\"GSI\")[3:])\n\n    def reset(self):\n        acknowledgment = self.query(\"R\")\n        if acknowledgment == \":E-1,0\":\n            print(\"SmarAct MCS reset succesfully\")\n            return True\n        else:\n            print(\"SmarAct MCS reset failled\")\n            return False\n\n    def check_status(self, ch):\n        \"\"\"\n        Checks the status of a given positioner channel\n        \"\"\"\n        response=self.query(\"GS\"+str(ch))\n        return int(response[response.index(\",\")+1:])\n\n    def wait_until_stopped(self, ch):\n        while self.check_status(ch)!=0:\n            print(\"sleep\")\n            time.sleep(1)\n\n    \"\"\" =====================\n        Calibaration methods\n        =====================\n    \"\"\"\n\n    def calibrate_system(self):\n#        print 'calibrating system..'\n        self.set_sensor_power_mode(1)\n        num_ch = self.get_num_channels()\n        for ch in range(num_ch):\n            print(\"calibrating channel\",ch, \"..\")\n            self.write(\"CS\"+str(ch))\n            self.wait_until_stopped(ch)\n\n    def get_safe_direction(self,ch):\n        \"\"\"\n        returns the safe dirction for a given channel ch, with 0 being forward\n        and 1 being backward\n        \"\"\"\n        response = self.query(\"GSD\"+str(ch))\n        return int(response[response.index(\",\")+1:])\n\n\n    def set_safe_directions(self):\n        \"\"\"\n        Vertical channels should all move upwards (i.e. 0).\n        The left channel should move left (i.e. 1) while the\n        right channel should move right (0). The remaining\n        two forward channels should move backwards away from the objective\n        (1).\n\n        Note that this function is currently based on the tip experiment arrangement.\n        \"\"\"\n        safe_directions = [1,1,0,0,1,0]\n        for ch, value in enumerate(safe_directions):\n            self.write(\"SSD\"+str(ch)+\",\"+str(value))\n        return safe_directions\n\n\n    def find_references_ch(self, ch):\n        print('finding reference for ch', ch)\n        self.set_sensor_power_mode(1)\n        safe_directions = self.set_safe_directions()\n        self.write(\"FRM\"+str(ch)+\",\"+str(safe_directions[ch])+\",0,1\")\n        self.wait_until_stopped(ch)\n\n    def find_references(self):\n        num_ch = self.get_num_channels()\n        for i in range(num_ch):\n            self.find_references_ch(i)\n\n\n    def set_position(self, ch, position):\n        \"\"\"\n        defines the current position to have a specific value; the measuring\n        scale is shifted accordingly\n        \"\"\"\n        self.write(\"SP\"+str(ch)+\",\"+str(position))\n\n\n    def physical_position_known(self, ch):\n        response = self.query(\"GPPK\"+str(ch))\n        if response[response.index(\",\")+1:] ==\"1\":\n            return True\n        elif response[response.index(\",\")+1:] ==\"0\":\n            return False\n        else:\n            raise ValueError('Unknown return value')\n\n\n\n    \"\"\" ========================================\n        speed, accelaration and sensor settings\n        ========================================\n    \"\"\"\n    def get_acceleration(self, ch):\n        \"\"\"\n        returns the acceleration of a given channel used for closed-loop\n        commands in um*s^-2 (linear positioner) or mdegree*s^-2 (roatry positioner).\n        A returned value of 0 means that the acceleration control is deactivated\n        \"\"\"\n        response = self.query(\"GCLA\"+str(ch))\n        return int(response[response.index(\",\")+1:])\n\n    def set_acceleration(self, ch, acceleration):\n        \"\"\"\n        sets the acceleration of a given channel used for closed-loop\n        commands in um*s^-2 (linear positioner) or mdegree*s^-2 (roatry positioner).\n        The valid range is 0 .. 10,000,000. A value of 0 deactivates the\n        acceleration control feature.\n        \"\"\"\n        self.write(\"SCLA\"+str(ch)+\",\"+str(acceleration))\n\n    def get_speed(self,ch):\n        \"\"\"\n        returns the speed used for closed-loop commands for a given channel.\n        For linear positioners units are: nm/s, for rotary positioners microdegree/s\n        A value of 0 means the speed control is deactivated.\n        \"\"\"\n        response = self.query(\"GCLS\"+str(ch))\n        return int(response[response.index(\",\")+1:])\n\n    def set_speed(self,ch,speed):\n        \"\"\"\n        sets the speed used for closed-loop commands for a given channel.\n        For linear positioners units are: nm/s, for rotary positioners microdegree/s\n        A value of 0 means the speed control is being deactivated.\n        The valid range is: 0.. 100,000,000\n        \"\"\"\n        self.write(\"SCLS\"+str(ch)+\",\"+str(int(speed)))\n\n    def set_frequency(self, ch,frequency):\n        \"\"\"\n        sets the maximum frequency used for closed-loop commands for a given channel.\n        The valid range is 50.. 18,500 Hz\n        \"\"\"\n        if frequency <50 or frequency > 18500:\n            raise ValueError(\"The valid range for the maximum frequency is 50.. 18,500 Hz\")\n        else:\n            self.write(\"SCLF\"+str(ch)+\",\"+str(int(frequency)))\n\n    def get_sensor_type(self, ch):\n        \"\"\"\n        returns the sensor type for a given channel ch\n        For a list of sensor types see MCS ASCII Programming Interface documentation\n        \"\"\"\n        response = self.query(\"GST\"+str(ch))\n        return int(response[response.index(\",\")+1:])\n\n\n    def set_sensor_type(self, ch, sensor_type):\n        \"\"\"\n        sets the sensor type for a given channel ch\n        For a list of sensor types see MCS ASCII Programming Interface documentation\n        \"\"\"\n        self.write(\"SST\"+str(ch)+\",\"+str(sensor_type))\n\n    def get_sensor_power_mode(self):\n        \"\"\"\n        returns the power mode for all positioner channels. Modes can be:\n        0: sensors disabled\n        1: sensors enabled\n        2: power saving mode\n        \"\"\"\n        response = self.query(\"GSE\")\n        return int(response[3:])\n\n\n    def set_sensor_power_mode(self, mode):\n        \"\"\"\n        sets the power mode for all positioner channels. Modes can be:\n        0: sensors disabled\n        1: sensors enabled\n        2: power saving mode\n        \"\"\"\n        if mode not in [0,1,2]:\n            raise ValueError(\"No valid sensor mode! Valid modes are: 0 (disabled), 1 (enabled), 2 (powersafe)\")\n        else:\n            self.write(\"SSE\"+str(mode))\n\n\n    def set_low_vibration_mode(self, ch, enable):\n        raise ValueError(\"The low vibration mode is not supported by this controller!\")\n        # self.write(\"GCP\"+str(ch)+\",16908289\")\n\n    def get_low_vibration_mode(self,ch):\n        raise ValueError(\"The low vibration mode is not supported by this controller!\")\n#        self.write(\"SCP\"+str(ch)+\",\"+str(sensor_type))\n\n\n\n\n    ### ==================================================== ###\n    ### Methods to read-out position and move to a specific  ###\n    ### position via slip-stick motion and piezo movement    ###\n    ## ===================================================== ###\n\n    def get_position(self, axis=None):\n        \"\"\"\n        Get the position of the stage or of a specified axis.\n        :param axis:\n        :return:\n        \"\"\"\n        if axis is None:\n            return [self.get_position(axis) for axis in self.axis_names]\n        else:\n            if axis not in [0,1,2,3,4,5]:  #self.axis_names:\n                raise ValueError(\"{0} is not a valid axis, must be one of {1}\".format(axis, self.axis_names))\n            else:\n                response = self.query(\"GP\"+str(axis))\n                return 1e-9*float(response[response.index(\",\")+1:])\n\n\n    def move(self, position, axis, relative=False, holdTime=0):\n        \"\"\"\n        Move the stage to the requested position. The function should block all further\n        actions until the stage has finished moving.\n        :param position: units of m (SI units, converted to nm in the method)\n        :param axis: integer channel index\n        :param relative:\n        :return:\n        \"\"\"\n        if axis not in [0,1,2,3,4,5]: #self.axis_names:\n            raise ValueError(\"{0} is not a valid axis, must be one of {1}\".format(axis, self.axis_names))\n        position *= 1e9\n        if relative:\n            send_string = \"MPR\"+str(axis)+\",\"+str(int(position))+\",\"+str(holdTime)\n            return self.query(send_string)\n        else:\n            send_string = \"MPA\"+str(axis)+\",\"+str(int(position))+\",\"+str(holdTime)\n            return self.query(send_string)\n        self.wait_until_stopped(axis)\n\n    def stop(self, axis=None):\n        \"\"\"\n        stops any ongoing movement of the positioner\n        \"\"\"\n        if axis is None: # stop movement of all positioner\n            axes= [0,1,2,3,4,5] #c_int(int(axis)) for axis in self.axis_names]\n            for ch in axes:\n                self.write(\"S\"+str(ch))\n        elif axis not in [0,1,2,3,4,5]: # self.axis_names: # wrong positioner name\n            raise ValueError(\"{0} is not a valid axis, must be one of {1}\".format(axis, self.axis_names))\n        else:  # just stop movement of specified positioner\n            self.write(\"S\"+str(ch))\n\n\n    \"\"\" =============================\n        position of rotary positioner\n        =============================\n    \"\"\"\n    def move_angle_absolute(self, ch, angle, revolution, holdTime):\n        \"\"\"\n        ch: positioner channel\n        angle: absolute angle to move in micro degrees: 0 .. 359,999,999\n        revolution: absolute revolution to move: -32,768 .. 32,767\n        holdTime: time in milliseconds the angle is actively hold after reaching target: 0 .. 60,000\n        with 0 deactivating feature and 60,000 is infinite/until manually stopped\n        \"\"\"\n        self.write(\"MAA\"+str(ch)+\",\"+str(angle)+\",\"+str(revolution)+\",\"+str(holdTime))\n\n    def move_angle_relative(self, ch, angle, revolution, holdTime):\n        \"\"\"\n        ch: positioner channel\n        angle: relative angle to move in micro degrees: -359,999,999 .. 359,999,999\n        revolution: relative revolution to move: -32,768 .. 32,767\n        holdTime: time in milliseconds the angle is actively hold after reaching target: 0 .. 60,000\n        with 0 deactivating feature and 60,000 is infinite/until manually stopped\n        \"\"\"\n        self.write(\"MAR\"+str(ch)+\",\"+str(angle)+\",\"+str(revolution)+\",\"+str(holdTime))\n\n    def get_angle(self,ch):\n        \"\"\"\n        returns the absolute angle and revolutions of the given positioner channel ch\n        \"\"\"\n        response = self.query(\"GA\")[3:].split(',')\n        print(\"angle in microdegree:\", response[0])\n        print(\"revolutions:\", response[1])\n        return response\n\n\n\n    ### ==================================== ###\n    ### Method to control slip-stick motion ###\n    ### ==================================== ###\n\n    def slip_stick_move(self, axis, steps=1, amplitude=1800, frequency=100):\n        \"\"\"\n        this method perforems a burst of slip-stick coarse motion steps.\n\n        :param axis: chanel index of selected SmarAct stage\n        :param steps: number and direction of steps, ranging between -30,000 .. 30,000\n                      with 0 stopping the positioner and +/-30,000 perfomes unbounded\n                      move, which is strongly riscouraged!\n        :param amplitude: voltage amplitude of the pulse send to the piezo,\n                          ranging from 0 .. 4,095 with 0 corresponding to 0 V\n                          and 4,095 corresponding to 100 V, a value of 2047\n                          roughly leads to a 500 nm step\n        :param frequency: frequency the steps are performed with in Hz, ranging\n                          from 1 .. 18,500\n        \"\"\"\n        if axis not in self.axis_names:\n            raise ValueError(\"{0} is not a valid axis, must be one of {1}\".format(axis, self.axis_names))\n        self.write(\"MST\"+str(axis)+\",\"+str(steps)+\",\"+str(amplitude)+\",\"+str(frequency))\n\n\n    ### ===================================== ###\n    ### Methods to control the piezo scanners ###\n    ### ===================================== ###\n\n    def get_piezo_level(self, axis=None):\n        \"\"\"\n        Get the voltage levels (0-4095) of the specified piezo axis\n        \"\"\"\n        if axis is None:\n            return [self.get_piezo_level(axis) for axis in self.axis_names]\n        else:\n            if axis not in self.axis_names:\n                raise ValueError(\"{0} is not a valid axis, must be one of {1}\".format(axis, self.axis_names))\n            response = self.query(\"GVL\"+str(axis))\n            return int(response[response.index(\",\")+1:])\n\n    def set_piezo_level(self, level, axis, speed=4095000000, relative=False):\n        \"\"\"\n        Scan up to 100V\n        level: 0 - 4095 (equals 0 .. 100 V)\n        speed: 0.. 4,095,000,0000 => 12 bit increments per second, for value of 1: full range scan takes 4095 seconds, at full speed scan is done in 1 micro second\n        \"\"\"\n        if axis not in self.axis_names:\n            raise ValueError(\"{0} is not a valid axis, must be one of {1}\".format(axis, self.axis_names))\n        if relative:\n            self.write(\"MSCR\"+str(axis)+\",\"+str(level)+\",\"+str(speed))\n        else:\n            self.write(\"MSCA\"+str(axis)+\",\"+str(level)+\",\"+str(speed))\n        self.wait_until_stopped(axis)\n\n    def multi_set_piezo_level(self, levels, axes, speeds, relative=False):\n        for i in range(len(axes)):\n            self.set_piezo_level(levels[i],axes[i],speed[i],relative)\n\n\n    ### additional useful methods to control the piezo scanners\n    def get_piezo_voltage(self, axis):\n        level = self.get_piezo_level(axis)\n        voltage = self.level_to_voltage(level)\n        return voltage\n\n    def set_piezo_voltage(self, axis, voltage, speed=4095000000, relative=False):\n        \"\"\"\n        level: 0 - 100 V, 0 - 4095\n        speed: 4095 s - 1 us for full 4095 voltage range, 1 - 4,095,000,000\n        \"\"\"\n        level = self.voltage_to_level(voltage)\n        self.set_piezo_level(level, axis, speed, relative)\n\n    def set_piezo_position(self, position, axis, speed, relative=False):\n        level = self.position_to_level(1e9*position)\n        self.set_piezo_level(level, axis, speed, relative)\n\n\n    def multi_set_piezo_voltage(self, voltages, axes, speeds, relative=False):\n        levels = [self.voltage_to_level(v) for v in voltages]\n        self.multi_set_piezo_level(levels, axes, speeds, relative)\n\n    def multi_set_piezo_position(self, positions, axes, speeds, relative=False):\n        levels = [self.position_to_level(1e9*p) for p in positions]\n        self.multi_set_piezo_level(levels, axes, speeds, relative)\n\n    def position_to_level(self, position):\n        # 1.5 um per 100 V, position can be between 0 and 1500 nm\n        voltage = position / 15.\n        level = int(self.voltage_to_level(voltage))\n        return level\n\n    def voltage_to_level(self, voltage):\n        level = voltage * 4095. / 100.\n        level = round(level)\n        return level\n\n    def level_to_voltage(self, level):\n        voltage = 100. * level / 4095.\n        return voltage\n\n    def level_to_position(self, level):\n        voltage = self.level_to_voltage(level)\n        position = voltage * 10.\n        return position\n\n    def get_qt_ui(self):\n        return SmaractMCSUI(self)\n\n\n    ### Useful Properties ###\n    num_ch = property(get_num_channels)\n    position = property(get_position)\n    piezo_levels = property(get_piezo_level)",
  "class SmaractScanStageUI(PiezoStageUI):\n    def __init__(self, stage):\n        super(SmaractScanStageUI, self).__init__(stage)\n\n    def move_axis_relative(self, index, axis, dir=1):\n        if axis in [1,2,4,5]:\n            dir *= -1\n        self.stage.set_piezo_position(dir*self.step_size[index], axis=axis, speed=4095, relative=True)\n        self.update_ui[int].emit(axis)\n\n    @QtCore.Slot(int)\n    @QtCore.Slot(str)\n    def update_positions(self, axis=None):\n        piezo_levels = self.stage.piezo_levels\n        if axis is None:\n            for i in range(len(self.position_widgets)):\n                self.position_widgets[i].xy_widget.setValue(piezo_levels[i*3],self.stage.max_voltage_levels[i*3+1]-piezo_levels[i*3+1])\n                self.position_widgets[i].z_bar.setValue(self.stage.max_voltage_levels[i*3+2]-piezo_levels[i*3+2])\n\n#            current_position = self.stage.scan_position\n#            for i in range(len(self.positions)):\n#                p = engineering_format(current_position[i], base_unit='m', digits_of_precision=3)\n#                self.positions[i].setText(p)\n        else:\n            if axis % 3 == 0:\n                self.position_widgets[old_div(axis,3)].xy_widget.setValue(piezo_levels[axis],self.stage.max_voltage_levels[axis+1]-piezo_levels[axis+1])\n            elif axis % 3 == 1:\n                self.position_widgets[old_div(axis,3)].xy_widget.setValue(piezo_levels[axis-1],self.stage.max_voltage_levels[axis]-piezo_levels[axis])\n            else:\n                self.position_widgets[old_div(axis,3)].z_bar.setValue(self.stage.max_voltage_levels[axis]-piezo_levels[axis])",
  "class SmaractMCSUI(QtWidgets.QWidget, UiTools):\n    def __init__(self, mcs, parent=None):\n        assert isinstance(mcs, SmaractMCS) or isinstance(mcs, SmaractMCSSerial) , \"system must be a Smaract MCS\"\n        super(SmaractMCSUI, self).__init__()\n        self.mcs = mcs\n        uic.loadUi(os.path.join(os.path.dirname(__file__), 'smaract_mcs.ui'), self)\n        self.mcs_id.setText(str(mcs.mcs_id))\n        self.num_ch.setText(str(mcs.num_ch))\n        self.reference_button.clicked.connect(self.mcs.find_references)\n        self.calibrate_button.clicked.connect(self.mcs.calibrate_system)\n        self.step_stage_widget = self.replace_widget(self.step_stage_layout, self.step_stage_widget, SmaractStageUI(self.mcs))\n        self.scan_stage_widget = self.replace_widget(self.scan_stage_layout, self.scan_stage_widget, SmaractScanStageUI(self.mcs))",
  "def __init__(self, value):\n        try:\n            self.value = value\n            error_text = ctypes.c_char_p()\n            mcsc.SA_GetStatusInfo(value, byref(error_text))\n            print(\"MCS error {:d}\".format(value))\n            print(ctypes.string_at(error_text))\n        except:\n            print(\"MCS error {:d}\".format(value))",
  "def check_status(status):\n        \"\"\"\n        Checks the status of the MCS controller. If not 'SA_OK' return the MCSError code\n        \"\"\"\n        if (status != SA_OK.value):\n            raise MCSError(status)\n        else:\n            return True",
  "def find_mcs_systems(cls):\n        \"\"\"\n        Get a list of all MCS devices available on this computer. The list\n        contains MCS IDs which are unique numbers to identify a MCS.\n        \"\"\"\n        outBuffer = ctypes.create_string_buffer(4096)\n        bufferSize = c_int(4096)  # ctypes.sizeof(outBuffer)\n        # outBuffer holds the locator strings, separated by '\\n'\n        # bufferSize holds the number of bytes written to outBuffer\n        if cls.check_status(mcsc.SA_FindSystems(\"\", outBuffer, byref(bufferSize))):\n#            print 'buffer size:', bufferSize\n            print('buffer:', ctypes.string_at(outBuffer))\n        return ctypes.string_at(outBuffer)",
  "def __init__(self, system_id):\n        super(SmaractMCS, self).__init__()\n        self.mcs_id = system_id\n        self.handle = c_int(0)\n        # self.setup()  #?? why setup() not used anymore?? => sets sensor power modes, low vibration modes, speeds, acceleration, ... => maybe because don't need to be set/changed for every software start??\n        self.is_open = False\n        self._num_ch = None\n        self.axis_names = tuple(i for i in range(self.num_ch))\n        self.positions = [0 for ch in range(self.num_ch)]\n        self.levels = [0 for ch in range(self.num_ch)]\n        self.voltages = [0 for ch in range(self.num_ch)]\n        self.scan_positions = [0 for ch in range(self.num_ch)]\n        self.min_voltage = [0 for ch in range(self.num_ch)]\n        self.max_voltage = [100 for ch in range(self.num_ch)]\n        self.min_voltage_levels = [0 for ch in range(self.num_ch)]\n        self.max_voltage_levels = [4095 for ch in range(self.num_ch)]",
  "def check_open_status(self):\n        if self.open_mcs():\n            return\n        else:\n            raise SmaractError('Error opening')",
  "def open_mcs(self):\n        if not self.is_open:\n            mode = ctypes.c_char_p('sync') # use synchronouse communication mode\n            if self.check_status(mcsc.SA_OpenSystem(byref(self.handle), self.mcs_id, mode)):\n                self.is_open = True\n                return True\n            else:\n                return False\n        else:\n            return True",
  "def close_mcs(self):\n        if self.is_open:\n            if self.check_status(mcsc.SA_CloseSystem(self.handle)):\n                self.is_open = False\n                return True\n            else:\n                return False\n        else:\n            return True",
  "def get_num_channels(self):\n        if self._num_ch is not None:\n            return self._num_ch\n        num_ch = c_int()\n        self.check_open_status()\n        if self.check_status(mcsc.SA_GetNumberOfChannels(self.handle, byref(num_ch))):\n            self._num_ch = num_ch.value\n            return num_ch.value\n        else:\n            return False",
  "def setup(self):\n        self.check_open_status()\n        self.set_sensor_power_mode(2)\n        for i in range(self.num_ch):\n            self.set_speed(ch, 0)\n            self.set_acceleration(ch, 0)\n            self.set_low_vibration_mode(ch, 1)\n            ch = c_int(i)\n            self.check_status(mcsc.SA_SetStepWhileScan_S(self.handle, ch, SA_NO_STEP_WHILE_SCAN))",
  "def get_sensor_type(self, ch):\n        \"\"\"\n        returns the sensor type for a given channel ch\n        For a list of sensor types see MCS Programmer's Guide\n        \"\"\"\n        ch = c_int(int(ch))\n        sensor_type = c_int()\n        self.check_open_status()\n        mcsc.SA_GetSensorType_S(self.handle, ch, byref(sensor_type))\n        return sensor_type.value",
  "def set_sensor_type(self, ch, sensor_type):\n        \"\"\"\n        sets the sensor type for a given channel ch\n        For a list of sensor types see MCS Programmer's Guide\n        \"\"\"\n        ch = c_int(int(ch))\n        sensor_type = c_int(int(sensor_type))\n        self.check_open_status()\n        mcsc.SA_SetSensorType_S(self.handle, ch, sensor_type)",
  "def set_sensor_power_mode(self, mode):\n        modes = {0: SA_SENSOR_DISABLED, 1: SA_SENSOR_ENABLED, 2: SA_SENSOR_POWERSAVE}\n        self.check_open_status()\n        self.check_status(mcsc.SA_SetSensorEnabled_S(self.handle, modes[mode]))",
  "def set_low_vibration_mode(self, ch, enable):\n        ch = c_int(int(ch))\n        values = {0: SA_DISABLED, 1: SA_ENABLED}\n        self.check_open_status()\n        self.check_status(mcsc.SA_SetChannelProperty_S(self.handle, ch,\n                                                       mcsc.SA_EPK(SA_GENERAL, SA_LOW_VIBRATION, SA_OPERATION_MODE),\n                                                       values[enable]))",
  "def get_acceleration(self, ch):\n        ch = c_int(int(ch))\n        acceleration = c_int()\n        self.check_open_status()\n        mcsc.SA_GetClosedLoopMoveAcceleration_S(self.handle, ch, byref(acceleration))\n        return acceleration.value",
  "def set_acceleration(self, ch, acceleration):\n        '''\n        units are um/s/s.\n        '''\n        ch = c_int(int(ch))\n        acceleration = c_int(int(acceleration))\n        self.check_open_status()\n        mcsc.SA_SetClosedLoopMoveAcceleration_S(self.handle, ch, acceleration)",
  "def get_speed(self, ch):\n        ch = c_int(int(ch))\n        speed = c_int()\n        self.check_open_status()\n        self.check_status(mcsc.SA_GetClosedLoopMoveSpeed_S(self.handle, ch,\n                                                           byref(speed)))\n        return speed.value",
  "def set_speed(self, ch, speed):\n        '''\n        units are nm/s, max is 1e8. A value of 0 deactivates speed control\n        (defaults to max.).\n        '''\n        ch = c_int(int(ch))\n        speed = c_int(int(speed))\n        self.check_open_status()\n        self.check_status(mcsc.SA_SetClosedLoopMoveSpeed_S(self.handle, ch,\n                                                           speed))",
  "def get_frequency(self, ch):\n        ch = c_int(int(ch))\n        frequency = c_int()\n        self.check_open_status()\n        self.check_status(mcsc.SA_GetClosedLoopMaxFrequency_S(self.handle, ch,\n                                                              byref(frequency)))\n        return frequency.value",
  "def set_frequency(self, ch, frequency):\n        '''\n        units are nm/s, min is 50, max is 18,500. A value of 0 deactivates speed control\n        (defaults to max.).\n        '''\n        ch = c_int(int(ch))\n        frequency = c_int(int(frequency))\n        self.check_open_status()\n        self.check_status(mcsc.SA_SetClosedLoopMaxFrequency_S(self.handle, ch,\n                                                              frequency))",
  "def wait_until_stopped(self, ch):\n        status = c_int(4)\n        if type(ch) is not c_int:\n            ch = c_int(ch)\n        while status.value != SA_STOPPED_STATUS.value:\n            self.check_status(mcsc.SA_GetStatus_S(self.handle, ch, byref(status)))\n        return",
  "def get_channel_status(self, ch):\n        ch = c_int(ch)\n        status = c_int(4)\n        self.check_status(mcsc.SA_GetStatus_S(self.handle, ch, byref(status)))\n        return status.value",
  "def calibrate_system(self):\n        print('calibrating system')\n        self.check_open_status()\n        self.set_sensor_power_mode(1)\n        num_ch = self.get_num_channels()\n        for ch in range(num_ch):\n            self.check_status(mcsc.SA_CalibrateSensor_S(self.handle, ch))\n            self.wait_until_stopped(ch)",
  "def set_safe_directions(self):\n        \"\"\"\n        Sets the safe directions for all channels to move when referencing.\n        Vertical channels should all move upwards (i.e. SA_FORWARD_DIRECTION).\n        The left channel should move left (SA_BACKWARD_DIRECTION) while the\n        right channel should move right (SA_FORWARD_DIRECTION). The remaining\n        two forward channels should move backwards away from the objective\n        (SA_BACKWARD_DIRECTION).\n\n        Note that this function is currently based on the tip experiment arrangement.\n        \"\"\"\n        self.check_open_status()\n        # self.set_sensor_power_mode(1)\n        num_ch = self.get_num_channels()\n        forward_channels = [3]  # was [0,1,2,5]\n        for i in range(num_ch):\n            value = SA_FORWARD_DIRECTION if (i in forward_channels) \\\n                else SA_BACKWARD_DIRECTION\n            ch = c_int(int(i))\n            self.check_status(mcsc.SA_SetSafeDirection_S(self.handle,\n                                                         ch, value))\n        return forward_channels",
  "def find_references_ch(self, ch):\n        print('finding reference for ch', ch)\n        ch = c_int(int(ch))\n        self.check_open_status()\n        self.set_sensor_power_mode(1)\n        forward_channels = self.set_safe_directions()\n        value = SA_FORWARD_DIRECTION if (ch.value in forward_channels) else SA_BACKWARD_DIRECTION\n        self.check_status(mcsc.SA_FindReferenceMark_S(self.handle, ch, value, 0, SA_AUTO_ZERO))\n        self.wait_until_stopped(ch)",
  "def find_references(self):\n        self.check_open_status()\n        num_ch = self.get_num_channels()\n        for i in range(num_ch):\n            self.find_references_ch(i)",
  "def move_angle_absolute(self, ch, angle, revolution, holdTime):\n        \"\"\"\n        ch: positioner channel\n        angle: absolute angle to move in micro degrees: 0 .. 359,999,999\n        revolution: absolute revolution to move: -32,768 .. 32,767\n        holdTime: time in milliseconds the angle is actively hold after reaching target: 0 .. 60,000\n        with 0 deactivating feature and 60,000 is infinite/until manually stopped\n        \"\"\"\n        ch = c_uint32(int(ch))\n        angle = c_uint32(int(angle))\n        revolution = c_int32(int(angle))\n        holdTime = c_uint32(int(holdTime))\n        self.check_open_status()\n        mcsc.SA_GoToAngleAbolute_S(self.handle, ch, angle, revolution, holdTime)",
  "def move_angle_relative(self, ch, angle, revolution, holdTime):\n        \"\"\"\n        ch: positioner channel\n        angle: relative angle to move in micro degrees: -359,999,999 .. 359,999,999\n        revolution: relative revolution to move: -32,768 .. 32,767\n        holdTime: time in milliseconds the angle is actively hold after reaching target: 0 .. 60,000\n        with 0 deactivating feature and 60,000 is infinite/until manually stopped\n        \"\"\"\n        ch = c_uint32(int(ch))\n        angle = c_int32(int(angle))\n        revolution = c_int32(int(angle))\n        holdTime = c_uint32(int(holdTime))\n        self.check_open_status()\n        mcsc.SA_GoToAngleRelative_S(self.handle, ch, angle, revolution, holdTime)",
  "def get_angle(self,ch):\n        \"\"\"\n        returns the absolute angle and revolutions of the given positioner channel ch\n        \"\"\"\n        ch = c_uint32(int(ch))\n        angle = c_uint32()\n        revolution = c_int32()\n        self.check_open_status()\n        mcsc.SA_GetAngle_S(self.handle, byref(angle), byref(revolution))\n        return [angle.value, revolution.value]",
  "def get_position(self, axis=None):\n        \"\"\"\n        Get the position of the stage or of a specified axis.\n        :param axis:\n        :return:\n        \"\"\"\n        if axis is None:\n            return [self.get_position(axis) for axis in self.axis_names]\n        else:\n            if axis not in self.axis_names:\n                raise ValueError(\"{0} is not a valid axis, must be one of {1}\".format(axis, self.axis_names))\n            ch = c_int(int(axis))\n            position = c_int()\n            self.check_open_status()\n            mcsc.SA_GetPosition_S(self.handle, ch, byref(position))\n            return 1e-9 * position.value",
  "def move(self, position, axis, relative=False):\n        \"\"\"\n        Move the stage to the requested position. The function should block all further\n        actions until the stage has finished moving.\n        :param position: units of m (SI units, converted to nm in the method)\n        :param axis: integer channel index\n        :param relative:\n        :return:\n        \"\"\"\n        if axis not in self.axis_names:\n            raise ValueError(\"{0} is not a valid axis, must be one of {1}\".format(axis, self.axis_names))\n        position *= 1e9\n        ch = c_int(int(axis))\n        position = c_int(int(position))\n        self.check_open_status()\n        if relative:\n            self.check_status(mcsc.SA_GotoPositionRelative_S(self.handle, ch, position, c_int(0)))\n        else:\n            self.check_status(mcsc.SA_GotoPositionAbsolute_S(self.handle, ch, position, c_int(0)))\n        self.wait_until_stopped(ch)",
  "def stop(self, axis=None):\n        \"\"\"\n        stops any ongoing movement of the positioner\n        \"\"\"\n        if axis is None: # stop movement of all positioner\n            axes= [c_int(int(axis)) for axis in self.axis_names]\n            for ch in axes:\n                self.check_status(mcsc.SA_Stop_S(self.handle, ch))\n        elif axis not in self.axis_names: # wrong positioner name\n            raise ValueError(\"{0} is not a valid axis, must be one of {1}\".format(axis, self.axis_names))\n        else:  # just stop movement of specified positioner\n            ch = c_int(int(axis))\n            self.check_status(mcsc.SA_Stop_S(self.handle, ch))",
  "def set_initial_position(self, ch, position):\n        \"\"\"\n        defines the current position to have a specific value; the measuring\n        scale is shifted accordingly\n        \"\"\"\n        ch = c_int(int(ch))\n        position = c_int(position)\n        self.check_open_status()\n        mcsc.SA_SetPosition_S(self.handle, ch, position)",
  "def set_position(self, ch, position): # same as set_initial_position() !!!\n        '''\n        units are nm\n        '''\n        position *= 1e9\n        ch = c_int(int(ch))\n        position = c_int(int(position))\n        self.check_open_status()\n        mcsc.SA_SetPosition_S(self.handle, ch, position)",
  "def physical_position_known(self, ch):\n        ch = c_int(int(ch))\n        known = c_int()\n        self.check_open_status()\n        mcsc.SA_GetPhysicalPositionKnown_S(self.handle, ch, byref(known))\n        if known == SA_PHYSICAL_POSITION_KNOWN:\n            return True\n        elif known == SA_PHYSICAL_POSITION_UNKNOWN:\n            return False\n        else:\n            raise SmaractError('Unknown return value')",
  "def multi_move(self, positions, axes, relative=False): #?? doesn't this method include the simple move() method??\n        self.check_open_status()\n\n        positions = [c_int(1e9 * p) for p in positions]\n        channels = [c_int(int(axis)) for axis in axes]\n\n        for i in range(len(axes)):\n            if relative:\n                self.check_status(mcsc.SA_GotoPositionRelative_S(self.handle, channels[i], positions[i], c_int(0)))\n            else:\n                self.check_status(mcsc.SA_GotoPositionAbsolute_S(self.handle, channels[i], positions[i], c_int(0)))\n        for axis in axes:\n            self.wait_until_stopped(axis)",
  "def multi_move_rel(self, step, axes):\n        steps = [1e9 * step for axis in axes]\n        self.multi_move(steps, axes, relative=True)",
  "def slip_stick_move(self, axis, steps=1, amplitude=1800, frequency=100):\n        \"\"\"\n        this method perforems a burst of slip-stick coarse motion steps.\n\n        :param axis: chanel index of selected SmarAct stage\n        :param steps: number and direction of steps, ranging between -30,000 .. 30,000\n                      with 0 stopping the positioner and +/-30,000 perfomes unbounded\n                      move, which is strongly riscouraged!\n        :param amplitude: voltage amplitude of the pulse send to the piezo,\n                          ranging from 0 .. 4,095 with 0 corresponding to 0 V\n                          and 4,095 corresponding to 100 V, a value of 2047\n                          roughly leads to a 500 nm step\n        :param frequency: frequency the steps are performed with in Hz, ranging\n                          from 1 .. 18,500\n        \"\"\"\n        if axis not in self.axis_names:\n            raise ValueError(\"{0} is not a valid axis, must be one of {1}\".format(axis, self.axis_names))\n        ch = c_int(int(axis))\n        steps = c_int(int(steps))\n        amplitude = c_uint(int(amplitude))\n        frequency = c_uint(int(frequency))\n        self.check_open_status()\n        self.check_status(mcsc.SA_StepMove_S(self.handle, ch, steps, amplitude, frequency))",
  "def get_piezo_position(self, axis=None):\n        \"\"\"\n        Get the scanning position of the stage or of a specified axis.\n        :param axis:\n        :return:\n        \"\"\"\n        if axis is None:\n            return [1e-9*10.*self.get_voltage(axis) for axis in self.axis_names]\n        else:\n            if axis not in self.axis_names:\n                raise ValueError(\"{0} is not a valid axis, must be one of {1}\".format(axis, self.axis_names))\n            voltage = self.get_voltage(axis)\n            position = 1e-9*10.*voltage\n            return position",
  "def get_piezo_level(self, axis=None):\n        \"\"\"\n        Get the voltage levels (0-4095) of the specified piezo axis\n        \"\"\"\n        if axis is None:\n            return [self.get_piezo_level(axis) for axis in self.axis_names]\n        else:\n            if axis not in self.axis_names:\n                raise ValueError(\"{0} is not a valid axis, must be one of {1}\".format(axis, self.axis_names))\n            ch = c_int(int(axis))\n            level = c_int()\n            self.check_open_status()\n            mcsc.SA_GetVoltageLevel_S(self.handle, ch, byref(level))\n            return level.value",
  "def set_piezo_level(self, level, axis, speed=4095, relative=False):\n        \"\"\"\n        Scan up to 100V\n        level: 0 - 100 V, 0 - 4095\n        speed: 4095 s - 1 us for full 4095 voltage range, 1 - 4,095,000,000\n        \"\"\"\n        if axis not in self.axis_names:\n            raise ValueError(\"{0} is not a valid axis, must be one of {1}\".format(axis, self.axis_names))\n        ch = c_int(int(axis))\n        level = c_int(int(level))\n        speed = c_int(int(speed))\n        self.check_open_status()\n        if relative:\n            self.check_status(mcsc.SA_ScanMoveRelative_S(self.handle, ch, level, speed))\n        else:\n            self.check_status(mcsc.SA_ScanMoveAbsolute_S(self.handle, ch, level, speed))\n        self.wait_until_stopped(ch)",
  "def multi_set_piezo_level(self, levels, axes, speeds, relative=False):\n        self.check_open_status()\n        levels = [c_int(int(level)) for level in levels]\n        axes = [c_int(int(axis)) for axis in axes]\n        speeds = [c_int(int(speed)) for speed in speeds]\n        for i in range(len(axes)):\n            if relative:\n                pass\n            else:\n                self.check_status(mcsc.SA_ScanMoveAbsolute_S(self.handle, axes[i], levels[i], speeds[i]))\n        for axis in axes:\n            self.wait_until_stopped(axis)",
  "def set_piezo_level_rel(self, diff, axis, speed=4095):\n        \"\"\"\n        Scan up to 50V\n        diff: -100 - 100 V, -4095 - 4095\n        speed: 4095 s - 1 us for full 4095 voltage range, 1 - 4,095,000,000\n        \"\"\"\n        self.set_piezo_level(diff, axis, speed, relative=True)",
  "def get_piezo_voltage(self, ch):\n        level = self.get_piezo_level(ch)\n        voltage = self.level_to_voltage(level)\n        return voltage",
  "def set_piezo_voltage(self, axis, voltage, speed=4095000000, relative=False):\n        \"\"\"\n        Scan to 50V\n        level: 0 - 100 V, 0 - 4095\n        speed: 4095 s - 1 us for full 4095 voltage range, 1 - 4,095,000,000\n        \"\"\"\n        level = self.voltage_to_level(voltage)\n        self.set_piezo_level(level, axis, speed, relative)",
  "def set_piezo_voltage_rel(self, axis, voltage_diff, speed):\n        \"\"\"\n        Scan to 50V\n        level: 0 - 100 V, 0 - 4095\n        speed: 4095 s - 1 us for full 4095 voltage range, 1 - 4,095,000,000\n        \"\"\"\n        diff = self.voltage_to_level(voltage_diff)\n        self.set_piezo_level(diff, axis, speed, relative=True)",
  "def set_piezo_position(self, position, axis, speed, relative=False):\n        level = self.position_to_level(1e9*position)\n        self.set_piezo_level(level, axis, speed, relative)",
  "def set_piezo_position_rel(self, axis, step, speed):\n        diff = self.position_to_level(1e9*step)\n        self.set_piezo_level(diff, axis, speed, relative=True)",
  "def multi_set_piezo_voltage(self, voltages, axes, speeds, relative=False):\n        levels = [self.voltage_to_level(v) for v in voltages]\n        self.multi_set_piezo_level(levels, axes, speeds, relative)",
  "def multi_set_piezo_position(self, positions, axes, speeds, relative=False):\n        levels = [self.position_to_level(1e9*p) for p in positions]\n        self.multi_set_piezo_level(levels, axes, speeds, relative)",
  "def position_to_level(self, position):\n        # 1.5 um per 100 V, position can be between 0 and 1500 nm\n        voltage = position / 15.\n        level = self.voltage_to_level(voltage)\n        return level",
  "def voltage_to_level(self, voltage):\n        level = voltage * 4095. / 100.\n        level = round(level)\n        return level",
  "def level_to_voltage(self, level):\n        voltage = 100. * level / 4095.\n        return voltage",
  "def level_to_position(self, level):\n        voltage = self.level_to_voltage(level)\n        position = voltage * 10.\n        return position",
  "def get_qt_ui(self):\n        return SmaractMCSUI(self)",
  "def __init__(self, stage):\n        super(SmaractStageUI, self).__init__(stage, stage_step_min=50e-9)",
  "def move_axis_relative(self, index, axis, dir=1):\n        if axis in [1,2,4,5]:\n            dir *= -1\n        self.stage.move(dir*self.step_size[index], axis=axis, relative=True)\n        self.update_ui[int].emit(axis)",
  "def __init__(self, error_msg):\n        self.channel = error_msg[0]\n        self.error_code = error_msg[1]\n        self.error = {}\n        self.error['0'] = 'No Error'\n        self.error['1'] = 'Syntax Error'\n        self.error['2'] = 'Invalid Command Error'\n        self.error['3'] = 'Overflow Error'\n        self.error['4'] = 'Parse Error'\n        self.error['5'] = 'Too Few Parameters Error'\n        self.error['6'] = 'Too Many Parameters Error'\n        self.error['7'] = 'Invalid Parameter Error'\n        self.error['8'] = 'Wrong Mode Error'\n        self.error['129'] = 'No Sensor Present Error'\n        self.error['140'] = 'Sensor Disabled Error'\n        self.error['141'] = 'Command Overridden Error'\n        self.error['142'] = 'End Stop Reached Error'\n        self.error['143'] = 'Wrong Sensor Type Error'\n        self.error['144'] = 'Could Not Find Reference Mark Error'\n        self.error['145'] = 'Wrong End Effector Type Error'\n        self.error['146'] = 'Movement Locked Error'\n        self.error['147'] = 'Range Limit Reached Error'\n        self.error['148'] = 'Physical Position Unknown Error'\n        self.error['150'] = 'Command Not Processable Error'\n        self.error['151'] = 'Waiting For Trigger Error'\n        self.error['152'] = 'Command ot Triggeral Error'\n        self.error['153'] = 'Command Queue Full Error'\n        self.error['154'] = 'Invalid Component Error'\n        self.error['155'] = 'Invalid Sub Component Error'\n        self.error['156'] = 'Invalid Property Error'\n        self.error['157'] = 'Permission Denied Error'",
  "def __str__(self):\n        if self.channel == '-1':\n            return \"[%s] %s\" % (self.error_code, self.error[self.error_code])\n        else:\n            return \"[%s]: %s for channel %s\" % (self.error_code, self.error[self.error_code], self.channel)",
  "def __init__(self,port):\n        self.initial_character = ':'\n        self.termination_character = '\\n'\n        super(SmaractMCSSerial, self).__init__(port=port)\n        self._num_ch = None\n        self.unit=\"m\"\n        self.axis_names = tuple(i for i in range(self.num_ch))\n        self.positions = [0 for ch in range(self.num_ch)]\n        self.levels = [0 for ch in range(self.num_ch)]\n        self.voltages = [0 for ch in range(self.num_ch)]\n        self.scan_positions = [0 for ch in range(self.num_ch)]\n        self.min_voltage = [0 for ch in range(self.num_ch)]\n        self.max_voltage = [100 for ch in range(self.num_ch)]\n        self.min_voltage_levels = [0 for ch in range(self.num_ch)]\n        self.max_voltage_levels = [4095 for ch in range(self.num_ch)]",
  "def query(self,queryString,multiline=False,termination_line=None,timeout=None):\n        \"\"\"\n        original query() from message_bus_instrumennt class overwritten to\n        implement error detection\n        \"\"\"\n        with self.communications_lock:\n            self.flush_input_buffer()\n            self.write(queryString) # intial and termination character are added in write()\n            if self.ignore_echo == True: # Needs Implementing for a multiline read!\n                first_line = self.readline(timeout).strip()\n                if first_line == queryString:\n                    return self.check_for_error(self.readline(timeout).strip())\n                else:\n                    print('This command did not echo!!!')\n                    return first_line\n\n            if termination_line is not None:\n                multiline = True\n            if multiline:\n                return self.check_for_error(self.read_multiline(termination_line))\n            else:\n                return self.check_for_error(self.readline(timeout).strip())",
  "def check_for_error(self,response):\n        if response[1] == \"E\" and not response[-1] == \"0\":\n            print(response)\n            raise MCSSerialError(response[2:].split(','))\n        else:\n            return response",
  "def get_communication_mode(self):\n        mode = self.query(\"GCM\")\n        if mode[-1] == '0':\n            print(\"synchronous communication mode\")\n        elif mode[-1] == '1':\n            print(\"asynchronous communication mode\")\n        return int(mode[-1])",
  "def set_communication_mode(self,mode):\n        if mode == \"sync\" or mode == \"synchronous\" or mode == \"0\":\n            self.write(\"SCM0\")\n        elif mode == \"async\" or mode == \"asynchronous\" or mode == \"1\":\n            self.write(\"SCM1\")\n        else:\n            raise ValueError(\"No valid communication mode. Possible modes are: 'sync' or 'async'.\")",
  "def set_baud_rate(self,baudrate):\n        \"\"\"\n        the baud rate is stored to non-volatile memory and loaded on future power ups\n        valid range for baudrate: 9,600 .. 115,200\n        \"\"\"\n        self.write(\"CB\"+str(baudrate))",
  "def get_channel_type(self,ch):\n        response = self.query(\"GCT\"+str(ch))\n        return int(response[-1])",
  "def get_interface_version(self):\n        response = self.query(\"GIV\")[3:].split(',')\n        print(\"versionHigh:\", response[0])\n        print(\"versionLow:\", response[1])\n        print(\"versionUpdate:\", response[2])\n        return response",
  "def get_num_channels(self):\n        if self._num_ch is not None:\n            return self._num_ch\n        self._num_ch = int(self.query(\"GNC\")[2:])\n        return self._num_ch",
  "def get_system_id(self):\n        return str(self.query(\"GSI\")[3:])",
  "def reset(self):\n        acknowledgment = self.query(\"R\")\n        if acknowledgment == \":E-1,0\":\n            print(\"SmarAct MCS reset succesfully\")\n            return True\n        else:\n            print(\"SmarAct MCS reset failled\")\n            return False",
  "def check_status(self, ch):\n        \"\"\"\n        Checks the status of a given positioner channel\n        \"\"\"\n        response=self.query(\"GS\"+str(ch))\n        return int(response[response.index(\",\")+1:])",
  "def wait_until_stopped(self, ch):\n        while self.check_status(ch)!=0:\n            print(\"sleep\")\n            time.sleep(1)",
  "def calibrate_system(self):\n#        print 'calibrating system..'\n        self.set_sensor_power_mode(1)\n        num_ch = self.get_num_channels()\n        for ch in range(num_ch):\n            print(\"calibrating channel\",ch, \"..\")\n            self.write(\"CS\"+str(ch))\n            self.wait_until_stopped(ch)",
  "def get_safe_direction(self,ch):\n        \"\"\"\n        returns the safe dirction for a given channel ch, with 0 being forward\n        and 1 being backward\n        \"\"\"\n        response = self.query(\"GSD\"+str(ch))\n        return int(response[response.index(\",\")+1:])",
  "def set_safe_directions(self):\n        \"\"\"\n        Vertical channels should all move upwards (i.e. 0).\n        The left channel should move left (i.e. 1) while the\n        right channel should move right (0). The remaining\n        two forward channels should move backwards away from the objective\n        (1).\n\n        Note that this function is currently based on the tip experiment arrangement.\n        \"\"\"\n        safe_directions = [1,1,0,0,1,0]\n        for ch, value in enumerate(safe_directions):\n            self.write(\"SSD\"+str(ch)+\",\"+str(value))\n        return safe_directions",
  "def find_references_ch(self, ch):\n        print('finding reference for ch', ch)\n        self.set_sensor_power_mode(1)\n        safe_directions = self.set_safe_directions()\n        self.write(\"FRM\"+str(ch)+\",\"+str(safe_directions[ch])+\",0,1\")\n        self.wait_until_stopped(ch)",
  "def find_references(self):\n        num_ch = self.get_num_channels()\n        for i in range(num_ch):\n            self.find_references_ch(i)",
  "def set_position(self, ch, position):\n        \"\"\"\n        defines the current position to have a specific value; the measuring\n        scale is shifted accordingly\n        \"\"\"\n        self.write(\"SP\"+str(ch)+\",\"+str(position))",
  "def physical_position_known(self, ch):\n        response = self.query(\"GPPK\"+str(ch))\n        if response[response.index(\",\")+1:] ==\"1\":\n            return True\n        elif response[response.index(\",\")+1:] ==\"0\":\n            return False\n        else:\n            raise ValueError('Unknown return value')",
  "def get_acceleration(self, ch):\n        \"\"\"\n        returns the acceleration of a given channel used for closed-loop\n        commands in um*s^-2 (linear positioner) or mdegree*s^-2 (roatry positioner).\n        A returned value of 0 means that the acceleration control is deactivated\n        \"\"\"\n        response = self.query(\"GCLA\"+str(ch))\n        return int(response[response.index(\",\")+1:])",
  "def set_acceleration(self, ch, acceleration):\n        \"\"\"\n        sets the acceleration of a given channel used for closed-loop\n        commands in um*s^-2 (linear positioner) or mdegree*s^-2 (roatry positioner).\n        The valid range is 0 .. 10,000,000. A value of 0 deactivates the\n        acceleration control feature.\n        \"\"\"\n        self.write(\"SCLA\"+str(ch)+\",\"+str(acceleration))",
  "def get_speed(self,ch):\n        \"\"\"\n        returns the speed used for closed-loop commands for a given channel.\n        For linear positioners units are: nm/s, for rotary positioners microdegree/s\n        A value of 0 means the speed control is deactivated.\n        \"\"\"\n        response = self.query(\"GCLS\"+str(ch))\n        return int(response[response.index(\",\")+1:])",
  "def set_speed(self,ch,speed):\n        \"\"\"\n        sets the speed used for closed-loop commands for a given channel.\n        For linear positioners units are: nm/s, for rotary positioners microdegree/s\n        A value of 0 means the speed control is being deactivated.\n        The valid range is: 0.. 100,000,000\n        \"\"\"\n        self.write(\"SCLS\"+str(ch)+\",\"+str(int(speed)))",
  "def set_frequency(self, ch,frequency):\n        \"\"\"\n        sets the maximum frequency used for closed-loop commands for a given channel.\n        The valid range is 50.. 18,500 Hz\n        \"\"\"\n        if frequency <50 or frequency > 18500:\n            raise ValueError(\"The valid range for the maximum frequency is 50.. 18,500 Hz\")\n        else:\n            self.write(\"SCLF\"+str(ch)+\",\"+str(int(frequency)))",
  "def get_sensor_type(self, ch):\n        \"\"\"\n        returns the sensor type for a given channel ch\n        For a list of sensor types see MCS ASCII Programming Interface documentation\n        \"\"\"\n        response = self.query(\"GST\"+str(ch))\n        return int(response[response.index(\",\")+1:])",
  "def set_sensor_type(self, ch, sensor_type):\n        \"\"\"\n        sets the sensor type for a given channel ch\n        For a list of sensor types see MCS ASCII Programming Interface documentation\n        \"\"\"\n        self.write(\"SST\"+str(ch)+\",\"+str(sensor_type))",
  "def get_sensor_power_mode(self):\n        \"\"\"\n        returns the power mode for all positioner channels. Modes can be:\n        0: sensors disabled\n        1: sensors enabled\n        2: power saving mode\n        \"\"\"\n        response = self.query(\"GSE\")\n        return int(response[3:])",
  "def set_sensor_power_mode(self, mode):\n        \"\"\"\n        sets the power mode for all positioner channels. Modes can be:\n        0: sensors disabled\n        1: sensors enabled\n        2: power saving mode\n        \"\"\"\n        if mode not in [0,1,2]:\n            raise ValueError(\"No valid sensor mode! Valid modes are: 0 (disabled), 1 (enabled), 2 (powersafe)\")\n        else:\n            self.write(\"SSE\"+str(mode))",
  "def set_low_vibration_mode(self, ch, enable):\n        raise ValueError(\"The low vibration mode is not supported by this controller!\")",
  "def get_low_vibration_mode(self,ch):\n        raise ValueError(\"The low vibration mode is not supported by this controller!\")",
  "def get_position(self, axis=None):\n        \"\"\"\n        Get the position of the stage or of a specified axis.\n        :param axis:\n        :return:\n        \"\"\"\n        if axis is None:\n            return [self.get_position(axis) for axis in self.axis_names]\n        else:\n            if axis not in [0,1,2,3,4,5]:  #self.axis_names:\n                raise ValueError(\"{0} is not a valid axis, must be one of {1}\".format(axis, self.axis_names))\n            else:\n                response = self.query(\"GP\"+str(axis))\n                return 1e-9*float(response[response.index(\",\")+1:])",
  "def move(self, position, axis, relative=False, holdTime=0):\n        \"\"\"\n        Move the stage to the requested position. The function should block all further\n        actions until the stage has finished moving.\n        :param position: units of m (SI units, converted to nm in the method)\n        :param axis: integer channel index\n        :param relative:\n        :return:\n        \"\"\"\n        if axis not in [0,1,2,3,4,5]: #self.axis_names:\n            raise ValueError(\"{0} is not a valid axis, must be one of {1}\".format(axis, self.axis_names))\n        position *= 1e9\n        if relative:\n            send_string = \"MPR\"+str(axis)+\",\"+str(int(position))+\",\"+str(holdTime)\n            return self.query(send_string)\n        else:\n            send_string = \"MPA\"+str(axis)+\",\"+str(int(position))+\",\"+str(holdTime)\n            return self.query(send_string)\n        self.wait_until_stopped(axis)",
  "def stop(self, axis=None):\n        \"\"\"\n        stops any ongoing movement of the positioner\n        \"\"\"\n        if axis is None: # stop movement of all positioner\n            axes= [0,1,2,3,4,5] #c_int(int(axis)) for axis in self.axis_names]\n            for ch in axes:\n                self.write(\"S\"+str(ch))\n        elif axis not in [0,1,2,3,4,5]: # self.axis_names: # wrong positioner name\n            raise ValueError(\"{0} is not a valid axis, must be one of {1}\".format(axis, self.axis_names))\n        else:  # just stop movement of specified positioner\n            self.write(\"S\"+str(ch))",
  "def move_angle_absolute(self, ch, angle, revolution, holdTime):\n        \"\"\"\n        ch: positioner channel\n        angle: absolute angle to move in micro degrees: 0 .. 359,999,999\n        revolution: absolute revolution to move: -32,768 .. 32,767\n        holdTime: time in milliseconds the angle is actively hold after reaching target: 0 .. 60,000\n        with 0 deactivating feature and 60,000 is infinite/until manually stopped\n        \"\"\"\n        self.write(\"MAA\"+str(ch)+\",\"+str(angle)+\",\"+str(revolution)+\",\"+str(holdTime))",
  "def move_angle_relative(self, ch, angle, revolution, holdTime):\n        \"\"\"\n        ch: positioner channel\n        angle: relative angle to move in micro degrees: -359,999,999 .. 359,999,999\n        revolution: relative revolution to move: -32,768 .. 32,767\n        holdTime: time in milliseconds the angle is actively hold after reaching target: 0 .. 60,000\n        with 0 deactivating feature and 60,000 is infinite/until manually stopped\n        \"\"\"\n        self.write(\"MAR\"+str(ch)+\",\"+str(angle)+\",\"+str(revolution)+\",\"+str(holdTime))",
  "def get_angle(self,ch):\n        \"\"\"\n        returns the absolute angle and revolutions of the given positioner channel ch\n        \"\"\"\n        response = self.query(\"GA\")[3:].split(',')\n        print(\"angle in microdegree:\", response[0])\n        print(\"revolutions:\", response[1])\n        return response",
  "def slip_stick_move(self, axis, steps=1, amplitude=1800, frequency=100):\n        \"\"\"\n        this method perforems a burst of slip-stick coarse motion steps.\n\n        :param axis: chanel index of selected SmarAct stage\n        :param steps: number and direction of steps, ranging between -30,000 .. 30,000\n                      with 0 stopping the positioner and +/-30,000 perfomes unbounded\n                      move, which is strongly riscouraged!\n        :param amplitude: voltage amplitude of the pulse send to the piezo,\n                          ranging from 0 .. 4,095 with 0 corresponding to 0 V\n                          and 4,095 corresponding to 100 V, a value of 2047\n                          roughly leads to a 500 nm step\n        :param frequency: frequency the steps are performed with in Hz, ranging\n                          from 1 .. 18,500\n        \"\"\"\n        if axis not in self.axis_names:\n            raise ValueError(\"{0} is not a valid axis, must be one of {1}\".format(axis, self.axis_names))\n        self.write(\"MST\"+str(axis)+\",\"+str(steps)+\",\"+str(amplitude)+\",\"+str(frequency))",
  "def get_piezo_level(self, axis=None):\n        \"\"\"\n        Get the voltage levels (0-4095) of the specified piezo axis\n        \"\"\"\n        if axis is None:\n            return [self.get_piezo_level(axis) for axis in self.axis_names]\n        else:\n            if axis not in self.axis_names:\n                raise ValueError(\"{0} is not a valid axis, must be one of {1}\".format(axis, self.axis_names))\n            response = self.query(\"GVL\"+str(axis))\n            return int(response[response.index(\",\")+1:])",
  "def set_piezo_level(self, level, axis, speed=4095000000, relative=False):\n        \"\"\"\n        Scan up to 100V\n        level: 0 - 4095 (equals 0 .. 100 V)\n        speed: 0.. 4,095,000,0000 => 12 bit increments per second, for value of 1: full range scan takes 4095 seconds, at full speed scan is done in 1 micro second\n        \"\"\"\n        if axis not in self.axis_names:\n            raise ValueError(\"{0} is not a valid axis, must be one of {1}\".format(axis, self.axis_names))\n        if relative:\n            self.write(\"MSCR\"+str(axis)+\",\"+str(level)+\",\"+str(speed))\n        else:\n            self.write(\"MSCA\"+str(axis)+\",\"+str(level)+\",\"+str(speed))\n        self.wait_until_stopped(axis)",
  "def multi_set_piezo_level(self, levels, axes, speeds, relative=False):\n        for i in range(len(axes)):\n            self.set_piezo_level(levels[i],axes[i],speed[i],relative)",
  "def get_piezo_voltage(self, axis):\n        level = self.get_piezo_level(axis)\n        voltage = self.level_to_voltage(level)\n        return voltage",
  "def set_piezo_voltage(self, axis, voltage, speed=4095000000, relative=False):\n        \"\"\"\n        level: 0 - 100 V, 0 - 4095\n        speed: 4095 s - 1 us for full 4095 voltage range, 1 - 4,095,000,000\n        \"\"\"\n        level = self.voltage_to_level(voltage)\n        self.set_piezo_level(level, axis, speed, relative)",
  "def set_piezo_position(self, position, axis, speed, relative=False):\n        level = self.position_to_level(1e9*position)\n        self.set_piezo_level(level, axis, speed, relative)",
  "def multi_set_piezo_voltage(self, voltages, axes, speeds, relative=False):\n        levels = [self.voltage_to_level(v) for v in voltages]\n        self.multi_set_piezo_level(levels, axes, speeds, relative)",
  "def multi_set_piezo_position(self, positions, axes, speeds, relative=False):\n        levels = [self.position_to_level(1e9*p) for p in positions]\n        self.multi_set_piezo_level(levels, axes, speeds, relative)",
  "def position_to_level(self, position):\n        # 1.5 um per 100 V, position can be between 0 and 1500 nm\n        voltage = position / 15.\n        level = int(self.voltage_to_level(voltage))\n        return level",
  "def voltage_to_level(self, voltage):\n        level = voltage * 4095. / 100.\n        level = round(level)\n        return level",
  "def level_to_voltage(self, level):\n        voltage = 100. * level / 4095.\n        return voltage",
  "def level_to_position(self, level):\n        voltage = self.level_to_voltage(level)\n        position = voltage * 10.\n        return position",
  "def get_qt_ui(self):\n        return SmaractMCSUI(self)",
  "def __init__(self, stage):\n        super(SmaractScanStageUI, self).__init__(stage)",
  "def move_axis_relative(self, index, axis, dir=1):\n        if axis in [1,2,4,5]:\n            dir *= -1\n        self.stage.set_piezo_position(dir*self.step_size[index], axis=axis, speed=4095, relative=True)\n        self.update_ui[int].emit(axis)",
  "def update_positions(self, axis=None):\n        piezo_levels = self.stage.piezo_levels\n        if axis is None:\n            for i in range(len(self.position_widgets)):\n                self.position_widgets[i].xy_widget.setValue(piezo_levels[i*3],self.stage.max_voltage_levels[i*3+1]-piezo_levels[i*3+1])\n                self.position_widgets[i].z_bar.setValue(self.stage.max_voltage_levels[i*3+2]-piezo_levels[i*3+2])\n\n#            current_position = self.stage.scan_position\n#            for i in range(len(self.positions)):\n#                p = engineering_format(current_position[i], base_unit='m', digits_of_precision=3)\n#                self.positions[i].setText(p)\n        else:\n            if axis % 3 == 0:\n                self.position_widgets[old_div(axis,3)].xy_widget.setValue(piezo_levels[axis],self.stage.max_voltage_levels[axis+1]-piezo_levels[axis+1])\n            elif axis % 3 == 1:\n                self.position_widgets[old_div(axis,3)].xy_widget.setValue(piezo_levels[axis-1],self.stage.max_voltage_levels[axis]-piezo_levels[axis])\n            else:\n                self.position_widgets[old_div(axis,3)].z_bar.setValue(self.stage.max_voltage_levels[axis]-piezo_levels[axis])",
  "def __init__(self, mcs, parent=None):\n        assert isinstance(mcs, SmaractMCS) or isinstance(mcs, SmaractMCSSerial) , \"system must be a Smaract MCS\"\n        super(SmaractMCSUI, self).__init__()\n        self.mcs = mcs\n        uic.loadUi(os.path.join(os.path.dirname(__file__), 'smaract_mcs.ui'), self)\n        self.mcs_id.setText(str(mcs.mcs_id))\n        self.num_ch.setText(str(mcs.num_ch))\n        self.reference_button.clicked.connect(self.mcs.find_references)\n        self.calibrate_button.clicked.connect(self.mcs.calibrate_system)\n        self.step_stage_widget = self.replace_widget(self.step_stage_layout, self.step_stage_widget, SmaractStageUI(self.mcs))\n        self.scan_stage_widget = self.replace_widget(self.scan_stage_layout, self.scan_stage_widget, SmaractScanStageUI(self.mcs))",
  "class NanoPZ(si.SerialInstrument,Stage):\n    def __init__(self, port=None,controllerNOM =\"1\"):\n        self.port_settings = {\n                    'baudrate':19200,\n                    'bytesize':serial.EIGHTBITS,\n                    'parity':serial.PARITY_NONE,\n                    'stopbits':serial.STOPBITS_ONE,\n                    'timeout':1, #wait at most one second for a response\n                    'writeTimeout':1, #similarly, fail if writing takes >1s\n                    'xonxoff':True, 'rtscts':False, 'dsrdtr':False,\n                    }\n        si.SerialInstrument.__init__(self,port=port)\n        self.termination_character = '\\r'\n        self.stepsize = 10\n        if controllerNOM<10:\n            controllerNOM = \"0%s\" %controllerNOM\n        self.controllerNOM = controllerNOM\n        self.motor_on()\n\n    def _send_command(self, msg):\n        self.ser.write('{0}{1}'.format(self.controllerNOM, msg))\n\n    def _readerror(self):\n        '''\n        This function returns the current error (if any)\n\n        Could be useful to have it check for errors after every function call\n\n        Returns:\n\n        '''\n        self.ser.write('{0}TE?'.format(self.controllerNOM))\n        a = self.ser.readline()\n        b = a.split(' ')[1]\n        error = b.split('\\r')[0]\n\n        if error != 0:\n            self._logger.warn('%s' % (ERROR_CODE[error]))\n            return ERROR_CODE[error]\n\n    def getHardwareStatus(self):\n        self._send_command('PH?')\n        status = self.ser.readline()\n        return status\n\n    def getControllerStatus(self):\n        self._send_command('TS?')\n        status = self.ser.readline()\n        return status\n\n    def stop_motion(self):\n        self._send_command('ST')\n\n    def move(self, pos, relative=True):\n        if relative:\n            self._send_command(\"PR{0}\".format(pos))\n        else:\n            self._logger.warn('NanoPZ does not have absolute moving')\n        \n    # def move_rel(self,value):\n    #     self.write(\"{0}PR{1}\".format(self.controllerNOM, value))\n    \n    def move_step(self,direction):\n        self.move_rel(direction*self.stepsize)\n        \n    def motor_on(self):\n        self._send_command(\"MO\")\n        \n    def get_position(self, axis=None):\n        return self.query(\"{0}TP?\".format(self.controllerNOM))[len(\"{0}TP?\")-1:]\n        \n    def set_zero(self):\n        self._send_command(\"OR\")\n        \n    def lower_limit(self,value):\n        if value <0:\n            self._send_command(\"SL{0}\".format(value))\n        else:\n            print(\"The lower Limit must be less than 0, current lower limit = \",self.query(\"{0}SL?\".format(self.controllerNOM)))\n            \n    def upper_limit(self,value):\n        if value >0:\n            self._send_command(\"SR{0}\".format(value))\n        else:\n            print(\"The upper Limit must be greater than 0, current upper limit = \",self.query(\"{0}SR?\".format(self.controllerNOM)))",
  "def __init__(self, port=None,controllerNOM =\"1\"):\n        self.port_settings = {\n                    'baudrate':19200,\n                    'bytesize':serial.EIGHTBITS,\n                    'parity':serial.PARITY_NONE,\n                    'stopbits':serial.STOPBITS_ONE,\n                    'timeout':1, #wait at most one second for a response\n                    'writeTimeout':1, #similarly, fail if writing takes >1s\n                    'xonxoff':True, 'rtscts':False, 'dsrdtr':False,\n                    }\n        si.SerialInstrument.__init__(self,port=port)\n        self.termination_character = '\\r'\n        self.stepsize = 10\n        if controllerNOM<10:\n            controllerNOM = \"0%s\" %controllerNOM\n        self.controllerNOM = controllerNOM\n        self.motor_on()",
  "def _send_command(self, msg):\n        self.ser.write('{0}{1}'.format(self.controllerNOM, msg))",
  "def _readerror(self):\n        '''\n        This function returns the current error (if any)\n\n        Could be useful to have it check for errors after every function call\n\n        Returns:\n\n        '''\n        self.ser.write('{0}TE?'.format(self.controllerNOM))\n        a = self.ser.readline()\n        b = a.split(' ')[1]\n        error = b.split('\\r')[0]\n\n        if error != 0:\n            self._logger.warn('%s' % (ERROR_CODE[error]))\n            return ERROR_CODE[error]",
  "def getHardwareStatus(self):\n        self._send_command('PH?')\n        status = self.ser.readline()\n        return status",
  "def getControllerStatus(self):\n        self._send_command('TS?')\n        status = self.ser.readline()\n        return status",
  "def stop_motion(self):\n        self._send_command('ST')",
  "def move(self, pos, relative=True):\n        if relative:\n            self._send_command(\"PR{0}\".format(pos))\n        else:\n            self._logger.warn('NanoPZ does not have absolute moving')",
  "def move_step(self,direction):\n        self.move_rel(direction*self.stepsize)",
  "def motor_on(self):\n        self._send_command(\"MO\")",
  "def get_position(self, axis=None):\n        return self.query(\"{0}TP?\".format(self.controllerNOM))[len(\"{0}TP?\")-1:]",
  "def set_zero(self):\n        self._send_command(\"OR\")",
  "def lower_limit(self,value):\n        if value <0:\n            self._send_command(\"SL{0}\".format(value))\n        else:\n            print(\"The lower Limit must be less than 0, current lower limit = \",self.query(\"{0}SL?\".format(self.controllerNOM)))",
  "def upper_limit(self,value):\n        if value >0:\n            self._send_command(\"SR{0}\".format(value))\n        else:\n            print(\"The upper Limit must be greater than 0, current upper limit = \",self.query(\"{0}SR?\".format(self.controllerNOM)))",
  "class ParkerStepper(si.SerialInstrument):\n    '''Stepper object for controlling timedelay\n    \n    '''\n    def __init__(self, port=None,max_steps = 12000000,calibration = 7500.0):\n        '''Setup baud rate, return charcter and timeout '''\n        self.termination_character = '\\r'\n        self.port_settings = {'baudrate':9600,'timeout':1}\n        si.SerialInstrument.__init__(self,port=port)\n        self.calibration = calibration\n        self.max_steps = float(max_steps)\n        self.initialise()\n    def initialise(self):\n        '''Set Calibration and make stepper ready to run '''\n        self.write(\"SSA1\")\n        self.query(\"CMDDIR1\") #Should be a query?\n        self.write(\"MPI\")\n        self.write(\"A5\")\n        self.write(\"V4\")\n        self.write(\"8ER3200\")\n        self.write(\"8OSB1\")\n        self.write(\"8OSH0\")\n        self.write(\"8OSC0\")\n        self.write(\"8OSD0\")\n        self.write(\"8FSA0\")\n        self.query(\"8OS\")  #SHOULD BE A QUERY?\n        self.query(\"8FS\")\n    \n    def moveto(self,newlocation,blocking = True):\n        '''Moves to the requested stepper position\n        Args:\n            newlocation(int):   The new postion you want the stepper to move to                \n        '''\n        if newlocation>=self.max_steps or newlocation<0:\n            print('Move failed as new postion was out of range')\n            return None\n        self.write(\"MN\")\n        self.write(\"MPA\")\n        self.write(\"8D\"+str(newlocation))\n        self.write(\"G\")\n        if blocking == True:\n            self.location()\n        \n    def step(self,stepsize,blocking = True):\n        '''Perform a signal step of size x\n        Args:\n            stepsize(int): '''\n        self.write(\"MN\")\n        self.write(\"MPI\")\n        self.write(\"8D\"+str(stepsize))\n        self.write(\"G\")\n        if blocking == True:\n            self.location()\n        \n    def loop(self,repeats,start,finish,velocity = 4,acceleration = 5):\n        '''Perform a number of loops using the inbuilt loop function\n        Args:\n            repeats(int):  Number of loops\n            start(int) :    Start location\n            finish(int):    End location\n            velocity(int):  Stepper veolocity\n            acceleration(int):  Stepper acceleration\n            '''\n        self.write(\"A\"+str(acceleration))\n        self.write(\"V\"+str(velocity))\n        self.write(\"L\"+str(repeats))\n        self.moveto(start)\n        self.moveto(finish)\n        self.write(\"N\")\n    def location(self):\n        '''Determine the current stepper position in picoseconds and steps\n        Returns:\n            stepper position picoseconds\n            stepper position steps\n            '''\n        Success = False\n        while Success ==False:\n            try:\n                loc = [old_div(self.int_query(\"8PR\"),(self.calibration)),self.int_query(\"8PR\")]\n                if loc != [old_div(self.int_query(\"8PR\"),(self.calibration)),self.int_query(\"8PR\")]:\n                    raise ValueError\n                Success = True\n            except ValueError:\n                Success = False\n        return loc\n        \n\n    def movepositive(self):\n        '''Move continuesly positive until a stop command is recieved '''\n        self.write(\"MC\")\n        self.write(\"H+\")\n        self.write(\"G\")\n\n    def movenegative(self):\n        '''Move continuesly negative until a stop command is recieved '''\n        self.write(\"MC\")\n        self.write(\"H-\")\n        self.write(\"G\")\n\n    def stop(self):\n        '''Force the stepper to stop in its current position '''\n        self.write(\"S\")\n    \n    def home(self, velocity = -3): \n        '''Move the stepper to its home position\n        Args:\n            velocity(int):  Stepper velocity\n        Notes:\n            The correct sign (+/-) for the velocity for home movement must be \n            given otherwise the stepper will go to the wrong end of the stage'''\n        self.write(\"GH\"+str(velocity))\n    \n    def zero(self): \n        '''Set the current stepper position as zero '''\n        self.write(\"PZ\")\n\n    def get_qt_ui(self):\n        if not hasattr(self,'ui'):\n            self.ui = Stepper_Ui(self)\n        return self.ui",
  "class Stepper_Ui(QtWidgets.QWidget, UiTools):\n    def __init__(self,stepper):\n        super(Stepper_Ui, self).__init__()\n      #  assert(stepper==Stepper) # checking if the object is a stepper\n        self.stepper = stepper\n        ui_file = os.path.join(os.path.dirname(__file__),'stepper_GUI.ui') # GUI path . e.g. look into location of the current file and search for the given name\n        uic.loadUi(ui_file, self) #loading the ui file \n        \n        self.move_spinBox.setMaximum(int(self.stepper.max_steps))\n        self.move_percent_doubleSpinBox.setMaximum(100.0)\n        \n        self.current_button.clicked.connect(self.update_positions)\n        \n        self.setpercent_pushButton.clicked.connect(self.move_to_percent)\n        self.setsteps_pushButton.clicked.connect(self.move_to)\n        self.update_positions()\n    def update_positions(self):\n        current_pos = float(self.stepper.location()[1])\n        self.current_number.setText(str(current_pos))\n        self.current_percent.setText(str(old_div(100.0*current_pos,self.stepper.max_steps))[:4]+'%')\n    \n    def move_to_percent(self):\n        percent=self.move_percent_doubleSpinBox.value()\n        steps=int(old_div((percent*self.stepper.max_steps),100))\n        self.stepper.moveto(steps,blocking = False)\n        \n    def move_to(self):\n        steps= self.move_spinBox.value()\n        self.stepper.moveto(steps)",
  "def __init__(self, port=None,max_steps = 12000000,calibration = 7500.0):\n        '''Setup baud rate, return charcter and timeout '''\n        self.termination_character = '\\r'\n        self.port_settings = {'baudrate':9600,'timeout':1}\n        si.SerialInstrument.__init__(self,port=port)\n        self.calibration = calibration\n        self.max_steps = float(max_steps)\n        self.initialise()",
  "def initialise(self):\n        '''Set Calibration and make stepper ready to run '''\n        self.write(\"SSA1\")\n        self.query(\"CMDDIR1\") #Should be a query?\n        self.write(\"MPI\")\n        self.write(\"A5\")\n        self.write(\"V4\")\n        self.write(\"8ER3200\")\n        self.write(\"8OSB1\")\n        self.write(\"8OSH0\")\n        self.write(\"8OSC0\")\n        self.write(\"8OSD0\")\n        self.write(\"8FSA0\")\n        self.query(\"8OS\")  #SHOULD BE A QUERY?\n        self.query(\"8FS\")",
  "def moveto(self,newlocation,blocking = True):\n        '''Moves to the requested stepper position\n        Args:\n            newlocation(int):   The new postion you want the stepper to move to                \n        '''\n        if newlocation>=self.max_steps or newlocation<0:\n            print('Move failed as new postion was out of range')\n            return None\n        self.write(\"MN\")\n        self.write(\"MPA\")\n        self.write(\"8D\"+str(newlocation))\n        self.write(\"G\")\n        if blocking == True:\n            self.location()",
  "def step(self,stepsize,blocking = True):\n        '''Perform a signal step of size x\n        Args:\n            stepsize(int): '''\n        self.write(\"MN\")\n        self.write(\"MPI\")\n        self.write(\"8D\"+str(stepsize))\n        self.write(\"G\")\n        if blocking == True:\n            self.location()",
  "def loop(self,repeats,start,finish,velocity = 4,acceleration = 5):\n        '''Perform a number of loops using the inbuilt loop function\n        Args:\n            repeats(int):  Number of loops\n            start(int) :    Start location\n            finish(int):    End location\n            velocity(int):  Stepper veolocity\n            acceleration(int):  Stepper acceleration\n            '''\n        self.write(\"A\"+str(acceleration))\n        self.write(\"V\"+str(velocity))\n        self.write(\"L\"+str(repeats))\n        self.moveto(start)\n        self.moveto(finish)\n        self.write(\"N\")",
  "def location(self):\n        '''Determine the current stepper position in picoseconds and steps\n        Returns:\n            stepper position picoseconds\n            stepper position steps\n            '''\n        Success = False\n        while Success ==False:\n            try:\n                loc = [old_div(self.int_query(\"8PR\"),(self.calibration)),self.int_query(\"8PR\")]\n                if loc != [old_div(self.int_query(\"8PR\"),(self.calibration)),self.int_query(\"8PR\")]:\n                    raise ValueError\n                Success = True\n            except ValueError:\n                Success = False\n        return loc",
  "def movepositive(self):\n        '''Move continuesly positive until a stop command is recieved '''\n        self.write(\"MC\")\n        self.write(\"H+\")\n        self.write(\"G\")",
  "def movenegative(self):\n        '''Move continuesly negative until a stop command is recieved '''\n        self.write(\"MC\")\n        self.write(\"H-\")\n        self.write(\"G\")",
  "def stop(self):\n        '''Force the stepper to stop in its current position '''\n        self.write(\"S\")",
  "def home(self, velocity = -3): \n        '''Move the stepper to its home position\n        Args:\n            velocity(int):  Stepper velocity\n        Notes:\n            The correct sign (+/-) for the velocity for home movement must be \n            given otherwise the stepper will go to the wrong end of the stage'''\n        self.write(\"GH\"+str(velocity))",
  "def zero(self): \n        '''Set the current stepper position as zero '''\n        self.write(\"PZ\")",
  "def get_qt_ui(self):\n        if not hasattr(self,'ui'):\n            self.ui = Stepper_Ui(self)\n        return self.ui",
  "def __init__(self,stepper):\n        super(Stepper_Ui, self).__init__()\n      #  assert(stepper==Stepper) # checking if the object is a stepper\n        self.stepper = stepper\n        ui_file = os.path.join(os.path.dirname(__file__),'stepper_GUI.ui') # GUI path . e.g. look into location of the current file and search for the given name\n        uic.loadUi(ui_file, self) #loading the ui file \n        \n        self.move_spinBox.setMaximum(int(self.stepper.max_steps))\n        self.move_percent_doubleSpinBox.setMaximum(100.0)\n        \n        self.current_button.clicked.connect(self.update_positions)\n        \n        self.setpercent_pushButton.clicked.connect(self.move_to_percent)\n        self.setsteps_pushButton.clicked.connect(self.move_to)\n        self.update_positions()",
  "def update_positions(self):\n        current_pos = float(self.stepper.location()[1])\n        self.current_number.setText(str(current_pos))\n        self.current_percent.setText(str(old_div(100.0*current_pos,self.stepper.max_steps))[:4]+'%')",
  "def move_to_percent(self):\n        percent=self.move_percent_doubleSpinBox.value()\n        steps=int(old_div((percent*self.stepper.max_steps),100))\n        self.stepper.moveto(steps,blocking = False)",
  "def move_to(self):\n        steps= self.move_spinBox.value()\n        self.stepper.moveto(steps)",
  "class SMC100ReadTimeOutException(Exception):\n    def __init__(self):\n        super(SMC100ReadTimeOutException, self).__init__('Read timed out')",
  "class SMC100WaitTimedOutException(Exception):\n    def __init__(self):\n        super(SMC100WaitTimedOutException, self).__init__('Wait timed out')",
  "class SMC100DisabledStateException(Exception):\n    def __init__(self, state):\n        super(SMC100DisabledStateException, self).__init__('Disabled state encountered: ' + state)",
  "class SMC100RS232CorruptionException(Exception):\n    def __init__(self, c):\n        super(SMC100RS232CorruptionException, self).__init__('RS232 corruption detected: %s' % (hex(ord(c))))",
  "class SMC100InvalidResponseException(Exception):\n    def __init__(self, cmd, resp):\n        s = 'Invalid response to %s: %s' % (cmd, resp)\n        super(SMC100InvalidResponseException, self).__init__(s)",
  "class SMC100(SerialInstrument, Stage):\n    \"\"\"\n    Class to interface with Newport's SMC100 controller.\n    The SMC100 accepts commands in the form of:\n      <ID><command><arguments><CR><LF>\n    Reply, if any, will be in the form\n      <ID><command><result><CR><LF>\n    There is minimal support for manually setting stage parameter as Newport's\n    ESP stages can supply the SMC100 with the correct configuration parameters.\n    Some effort is made to take up backlash, but this should not be trusted too\n    much.\n    The move commands must be used with care, because they make assumptions\n    about the units which is dependent on the STAGE. I only have TRB25CC, which\n    has native units of mm. A more general implementation will move the move\n    methods into a stage class.\n    \"\"\"\n\n    def __init__(self, port, smcID=(1, ), **kwargs):\n        \"\"\"\n        If backlash_compensation is False, no backlash compensation will be done.\n        If silent is False, then additional output will be emitted to aid in\n        debugging.\n        If sleepfunc is not None, then it will be used instead of time.sleep. It\n        will be given the number of seconds (float) to sleep for, and is provided\n        for ease integration with single threaded GUIs.\n        Note that this method only connects to the controller, it otherwise makes\n        no attempt to home or configure the controller for the attached stage. This\n        delibrate to minimise realworld side effects.\n        If the controller has previously been configured, it will suffice to simply\n        call home() to take the controller out of not referenced mode. For a brand\n        new controller, call reset_and_configure().\n        \"\"\"\n        self.port_settings = dict(baudrate=57600,\n                    bytesize=8,\n                    stopbits=1,\n                    parity='N',\n                    xonxoff=True,\n                    timeout=0.050)\n\n        SerialInstrument.__init__(self, port)\n        Stage.__init__(self)\n        # self._logger.debug('Connecting to SMC100 on %s' % (port))\n\n        self.software_home = None\n        self._last_sendcmd_time = 0\n        if not hasattr(smcID, '__iter__'):\n            smcID = (smcID, )\n        self._smcID = list(smcID)\n        self.axis_names = ()\n        for id in self._smcID:\n            self.axis_names += (str(id), )\n            self._send_cmd('ID', id, '?', True)  # Just testing the connection\n\n    def __del__(self):\n        self.close()\n\n    def _send_cmd(self, command, axes=None, argument=None, expect_response=False, retry=False):\n        \"\"\"\n        Send the specified command along with the argument, if any. The response\n        is checked to ensure it has the correct prefix, and is returned WITHOUT\n        the prefix.\n        It is important that for GET commands, e.g. 1ID?, the ? is specified as an\n        ARGUMENT, not as part of the command. Doing so will result in assertion\n        failure.\n        If expect_response is True, a response is expected from the controller\n        which will be verified and returned without the prefix.\n        If expect_response is True, and retry is True or an integer, then when the\n        response does not pass verification, the command will be sent again for\n        retry number of times, or until success if retry is True.\n        The retry option MUST BE USED CAREFULLY. It should ONLY be used read-only\n        commands, because otherwise REPEATED MOTION MIGHT RESULT. In fact some\n        commands are EXPLICITLY REJECTED to prevent this, such as relative move.\n        \"\"\"\n        if axes is None:\n            axes = self.axis_names #self._smcID[0]\n        elif not hasattr(axes, '__iter__'):\n            axes = (axes, )\n\n        reply = ()\n        for axis in axes:\n            if type(axis) != str:\n                axis = str(axis)\n            assert command[-1] != '?'\n\n            if argument is None:\n                argument = ''\n\n            prefix = axis + command\n            tosend = prefix + str(argument)\n\n            # prevent certain commands from being retried automatically\n            no_retry_commands = ['PR', 'OR']\n            if command in no_retry_commands:\n                retry = False\n\n            done = False\n            while not done:\n                if expect_response:\n                    self.ser.flushInput()\n\n                self.ser.flushOutput()\n\n                self.ser.write(tosend)\n                self.ser.write('\\r\\n')\n\n                self.ser.flush()\n\n                if expect_response:\n                    try:\n                        response = self._readline()\n                        if response.startswith(prefix):\n                            reply += (response[len(prefix):], )\n                            done = True\n                        else:\n                            raise SMC100InvalidResponseException(command, response)\n                    except Exception as ex:\n                        if not retry or retry <= 0:\n                            raise ex\n                        else:\n                            if type(retry) == int:\n                                retry -= 1\n                            continue\n                else:\n                    # we only need to delay when we are not waiting for a response\n                    now = time.time()\n                    dt = now - self._last_sendcmd_time\n                    dt = COMMAND_WAIT_TIME_SEC - dt\n                    # print dt\n                    if dt > 0:\n                        time.sleep(dt)\n                    self._last_sendcmd_time = now\n                    done = True\n                    # return None\n        return reply\n\n    def _readline(self):\n        \"\"\"\n        Returns a line, that is reads until \\r\\n.\n        OK, so you are probably wondering why I wrote this. Why not just use\n        self.ser.readline()?\n        I am glad you asked.\n        With python < 2.6, pySerial uses serial.FileLike, that provides a readline\n        that accepts the max number of chars to read, and the end of line\n        character.\n        With python >= 2.6, pySerial uses io.RawIOBase, whose readline only\n        accepts the max number of chars to read. io.RawIOBase does support the\n        idea of a end of line character, but it is an attribute on the instance,\n        which makes sense... except pySerial doesn't pass the newline= keyword\n        argument along to the underlying class, and so you can't actually change\n        it.\n        \"\"\"\n        done = False\n        line = str()\n        # print 'reading line',\n        while not done:\n            c = self.ser.read()\n            # ignore \\r since it is part of the line terminator\n            if len(c) == 0:\n                raise SMC100ReadTimeOutException()\n            elif c == '\\r':\n                continue\n            elif c == '\\n':\n                done = True\n            elif ord(c) > 32 and ord(c) < 127:\n                line += c\n            else:\n                raise SMC100RS232CorruptionException(c)\n\n        return line\n\n    def _wait_states(self, targetstates, ignore_disabled_states=False):\n        \"\"\"\n        Waits for the controller to enter one of the the specified target state.\n        Controller state is determined via the TS command.\n        If ignore_disabled_states is True, disable states are ignored. The normal\n        behaviour when encountering a disabled state when not looking for one is\n        for an exception to be raised.\n        Note that this method will ignore read timeouts and keep trying until the\n        controller responds.  Because of this it can be used to determine when the\n        controller is ready again after a command like PW0 which can take up to 10\n        seconds to execute.\n        If any disable state is encountered, the method will raise an error,\n        UNLESS you were waiting for that state. This is because if we wait for\n        READY_FROM_MOVING, and the stage gets stuck we transition into\n        DISABLE_FROM_MOVING and then STAY THERE FOREVER.\n        The state encountered is returned.\n        \"\"\"\n        starttime = time.time()\n        done = [False]*len(self.axis_names)\n        self._logger.debug('waiting for states %s' % (str(targetstates)))\n        while not all(done):\n            for axes in range(len(self.axis_names)):\n                waittime = time.time() - starttime\n                if waittime > MAX_WAIT_TIME_SEC:\n                    raise SMC100WaitTimedOutException()\n\n                try:\n                    state = self.get_status()[axes][1]\n                    if state in targetstates:\n                        self._logger.debug('in state %s' % (state))\n                        done[axes] = True\n                        # return state\n                    elif not ignore_disabled_states:\n                        disabledstates = [\n                            STATE_DISABLE_FROM_READY,\n                            STATE_DISABLE_FROM_JOGGING,\n                            STATE_DISABLE_FROM_MOVING]\n                        if state in disabledstates:\n                            raise SMC100DisabledStateException(state)\n\n                except SMC100ReadTimeOutException:\n                    self._logger.info('Read timed out, retrying in 1 second')\n                    time.sleep(1)\n                    continue\n\n    def reset_and_configure(self):\n        \"\"\"\n        Configures the controller by resetting it and then asking it to load\n        stage parameters from an ESP compatible stage. This is then followed\n        by a homing action.\n        \"\"\"\n        self._send_cmd('RS')\n        self._send_cmd('RS')\n\n        self._wait_states(STATE_NOT_REFERENCED_FROM_RESET, ignore_disabled_states=True)\n\n        stage = self._send_cmd('ID', '?', True)\n        self._logger.info('Found stage %s' %stage)\n\n        # enter config mode\n        self._send_cmd('PW', 1)\n        self._wait_states(STATE_CONFIGURATION)\n\n        # load stage parameters\n        self._send_cmd('ZX', 1)\n\n        # enable stage ID check\n        self._send_cmd('ZX', 2)\n\n        # exit configuration mode\n        self._send_cmd('PW', 0)\n\n        # wait for us to get back into NOT REFERENCED state\n        self._wait_states(STATE_NOT_REFERENCED_FROM_CONFIGURATION)\n\n    def get_position(self, axis=None):\n        pos = self._send_cmd('TP', axes=axis, argument='?', expect_response=True, retry=10)\n        pos = list(map(float, pos))\n        return pos\n\n    def home(self, **kwargs):\n        \"\"\"\n        Homes the controller. If waitStop is True, then this method returns when\n        homing is complete.\n        Note that because calling home when the stage is already homed has no\n        effect, and homing is generally expected to place the stage at the\n        origin, an absolute move to 0 um is executed after homing. This ensures\n        that the stage is at origin after calling this method.\n        Calling this method is necessary to take the controller out of not referenced\n        state after a restart.\n        \"\"\"\n        self._send_cmd('OR')\n        if 'waitStop' in kwargs and kwargs['waitStop']:\n            # wait for the controller to be ready\n            st = self._wait_states((STATE_READY_FROM_HOMING, STATE_READY_FROM_MOVING))\n            if st == STATE_READY_FROM_MOVING:\n                self.move([0]*len(self.axis_names), **kwargs)\n        else:\n            self.move([0]*len(self.axis_names), **kwargs)\n\n    def stop(self):\n        self._send_cmd('ST')\n\n    def get_status(self):\n        \"\"\"\n        Executes TS? and returns the the error code as integer and state as string\n        as specified on pages 64 - 65 of the manual.\n        \"\"\"\n\n        resps = self._send_cmd('TS', argument='?', expect_response=True, retry=10)\n        reply = ()\n        for resp in resps:\n            errors = int(resp[0:4], 16)\n            state = resp[4:]\n            assert len(state) == 2\n            reply += ([errors, state], )\n\n        return reply\n\n    def move(self, pos, axis=None, relative=False, waitStop=True):\n        if axis is None:\n            axis = self.axis_names\n        if not hasattr(pos, '__iter__'):\n            pos = [pos]\n        if relative:\n            index = 0\n            for ax in axis:\n                self._send_cmd('PR', axes=ax, argument=pos[index])\n                index += 1\n        else:\n            index = 0\n            for ax in axis:\n                self._send_cmd('PA', axes=ax, argument=pos[index])\n                index += 1\n\n        if waitStop:\n            # If we were previously homed, then something like PR0 will have no\n            # effect and we end up waiting forever for ready from moving because\n            # we never left ready from homing. This is why STATE_READY_FROM_HOMING\n            # is included.\n            self._wait_states((STATE_READY_FROM_MOVING, STATE_READY_FROM_HOMING))\n\n    def move_referenced(self, position_mm, **kwargs):\n        \"\"\"\n        Moves to an absolute position referenced from the software home\n\n        Args:\n            position_mm: position from the software home\n            **kwargs: kwargs to be passed to the move command\n\n        Returns:\n\n        \"\"\"\n\n        if not hasattr(position_mm, '__iter__'):\n            position_mm = (position_mm, )\n\n        final_pos = list(map(lambda x, y: x+y, self.software_home, position_mm))\n\n        self.move(final_pos, **kwargs)\n\n    def set_software_home(self):\n        \"\"\"\n        Sets a software home, so that we can easily go back to similar sample positions\n\n        Returns:\n\n        \"\"\"\n        self.software_home = self.get_position()\n\n    def go_software_home(self):\n        self.move_referenced([0]*len(self.axis_names))\n\n    def set_velocity(self, velocity):\n        self._send_cmd('VA_Set', velocity)",
  "def __init__(self):\n        super(SMC100ReadTimeOutException, self).__init__('Read timed out')",
  "def __init__(self):\n        super(SMC100WaitTimedOutException, self).__init__('Wait timed out')",
  "def __init__(self, state):\n        super(SMC100DisabledStateException, self).__init__('Disabled state encountered: ' + state)",
  "def __init__(self, c):\n        super(SMC100RS232CorruptionException, self).__init__('RS232 corruption detected: %s' % (hex(ord(c))))",
  "def __init__(self, cmd, resp):\n        s = 'Invalid response to %s: %s' % (cmd, resp)\n        super(SMC100InvalidResponseException, self).__init__(s)",
  "def __init__(self, port, smcID=(1, ), **kwargs):\n        \"\"\"\n        If backlash_compensation is False, no backlash compensation will be done.\n        If silent is False, then additional output will be emitted to aid in\n        debugging.\n        If sleepfunc is not None, then it will be used instead of time.sleep. It\n        will be given the number of seconds (float) to sleep for, and is provided\n        for ease integration with single threaded GUIs.\n        Note that this method only connects to the controller, it otherwise makes\n        no attempt to home or configure the controller for the attached stage. This\n        delibrate to minimise realworld side effects.\n        If the controller has previously been configured, it will suffice to simply\n        call home() to take the controller out of not referenced mode. For a brand\n        new controller, call reset_and_configure().\n        \"\"\"\n        self.port_settings = dict(baudrate=57600,\n                    bytesize=8,\n                    stopbits=1,\n                    parity='N',\n                    xonxoff=True,\n                    timeout=0.050)\n\n        SerialInstrument.__init__(self, port)\n        Stage.__init__(self)\n        # self._logger.debug('Connecting to SMC100 on %s' % (port))\n\n        self.software_home = None\n        self._last_sendcmd_time = 0\n        if not hasattr(smcID, '__iter__'):\n            smcID = (smcID, )\n        self._smcID = list(smcID)\n        self.axis_names = ()\n        for id in self._smcID:\n            self.axis_names += (str(id), )\n            self._send_cmd('ID', id, '?', True)",
  "def __del__(self):\n        self.close()",
  "def _send_cmd(self, command, axes=None, argument=None, expect_response=False, retry=False):\n        \"\"\"\n        Send the specified command along with the argument, if any. The response\n        is checked to ensure it has the correct prefix, and is returned WITHOUT\n        the prefix.\n        It is important that for GET commands, e.g. 1ID?, the ? is specified as an\n        ARGUMENT, not as part of the command. Doing so will result in assertion\n        failure.\n        If expect_response is True, a response is expected from the controller\n        which will be verified and returned without the prefix.\n        If expect_response is True, and retry is True or an integer, then when the\n        response does not pass verification, the command will be sent again for\n        retry number of times, or until success if retry is True.\n        The retry option MUST BE USED CAREFULLY. It should ONLY be used read-only\n        commands, because otherwise REPEATED MOTION MIGHT RESULT. In fact some\n        commands are EXPLICITLY REJECTED to prevent this, such as relative move.\n        \"\"\"\n        if axes is None:\n            axes = self.axis_names #self._smcID[0]\n        elif not hasattr(axes, '__iter__'):\n            axes = (axes, )\n\n        reply = ()\n        for axis in axes:\n            if type(axis) != str:\n                axis = str(axis)\n            assert command[-1] != '?'\n\n            if argument is None:\n                argument = ''\n\n            prefix = axis + command\n            tosend = prefix + str(argument)\n\n            # prevent certain commands from being retried automatically\n            no_retry_commands = ['PR', 'OR']\n            if command in no_retry_commands:\n                retry = False\n\n            done = False\n            while not done:\n                if expect_response:\n                    self.ser.flushInput()\n\n                self.ser.flushOutput()\n\n                self.ser.write(tosend)\n                self.ser.write('\\r\\n')\n\n                self.ser.flush()\n\n                if expect_response:\n                    try:\n                        response = self._readline()\n                        if response.startswith(prefix):\n                            reply += (response[len(prefix):], )\n                            done = True\n                        else:\n                            raise SMC100InvalidResponseException(command, response)\n                    except Exception as ex:\n                        if not retry or retry <= 0:\n                            raise ex\n                        else:\n                            if type(retry) == int:\n                                retry -= 1\n                            continue\n                else:\n                    # we only need to delay when we are not waiting for a response\n                    now = time.time()\n                    dt = now - self._last_sendcmd_time\n                    dt = COMMAND_WAIT_TIME_SEC - dt\n                    # print dt\n                    if dt > 0:\n                        time.sleep(dt)\n                    self._last_sendcmd_time = now\n                    done = True\n                    # return None\n        return reply",
  "def _readline(self):\n        \"\"\"\n        Returns a line, that is reads until \\r\\n.\n        OK, so you are probably wondering why I wrote this. Why not just use\n        self.ser.readline()?\n        I am glad you asked.\n        With python < 2.6, pySerial uses serial.FileLike, that provides a readline\n        that accepts the max number of chars to read, and the end of line\n        character.\n        With python >= 2.6, pySerial uses io.RawIOBase, whose readline only\n        accepts the max number of chars to read. io.RawIOBase does support the\n        idea of a end of line character, but it is an attribute on the instance,\n        which makes sense... except pySerial doesn't pass the newline= keyword\n        argument along to the underlying class, and so you can't actually change\n        it.\n        \"\"\"\n        done = False\n        line = str()\n        # print 'reading line',\n        while not done:\n            c = self.ser.read()\n            # ignore \\r since it is part of the line terminator\n            if len(c) == 0:\n                raise SMC100ReadTimeOutException()\n            elif c == '\\r':\n                continue\n            elif c == '\\n':\n                done = True\n            elif ord(c) > 32 and ord(c) < 127:\n                line += c\n            else:\n                raise SMC100RS232CorruptionException(c)\n\n        return line",
  "def _wait_states(self, targetstates, ignore_disabled_states=False):\n        \"\"\"\n        Waits for the controller to enter one of the the specified target state.\n        Controller state is determined via the TS command.\n        If ignore_disabled_states is True, disable states are ignored. The normal\n        behaviour when encountering a disabled state when not looking for one is\n        for an exception to be raised.\n        Note that this method will ignore read timeouts and keep trying until the\n        controller responds.  Because of this it can be used to determine when the\n        controller is ready again after a command like PW0 which can take up to 10\n        seconds to execute.\n        If any disable state is encountered, the method will raise an error,\n        UNLESS you were waiting for that state. This is because if we wait for\n        READY_FROM_MOVING, and the stage gets stuck we transition into\n        DISABLE_FROM_MOVING and then STAY THERE FOREVER.\n        The state encountered is returned.\n        \"\"\"\n        starttime = time.time()\n        done = [False]*len(self.axis_names)\n        self._logger.debug('waiting for states %s' % (str(targetstates)))\n        while not all(done):\n            for axes in range(len(self.axis_names)):\n                waittime = time.time() - starttime\n                if waittime > MAX_WAIT_TIME_SEC:\n                    raise SMC100WaitTimedOutException()\n\n                try:\n                    state = self.get_status()[axes][1]\n                    if state in targetstates:\n                        self._logger.debug('in state %s' % (state))\n                        done[axes] = True\n                        # return state\n                    elif not ignore_disabled_states:\n                        disabledstates = [\n                            STATE_DISABLE_FROM_READY,\n                            STATE_DISABLE_FROM_JOGGING,\n                            STATE_DISABLE_FROM_MOVING]\n                        if state in disabledstates:\n                            raise SMC100DisabledStateException(state)\n\n                except SMC100ReadTimeOutException:\n                    self._logger.info('Read timed out, retrying in 1 second')\n                    time.sleep(1)\n                    continue",
  "def reset_and_configure(self):\n        \"\"\"\n        Configures the controller by resetting it and then asking it to load\n        stage parameters from an ESP compatible stage. This is then followed\n        by a homing action.\n        \"\"\"\n        self._send_cmd('RS')\n        self._send_cmd('RS')\n\n        self._wait_states(STATE_NOT_REFERENCED_FROM_RESET, ignore_disabled_states=True)\n\n        stage = self._send_cmd('ID', '?', True)\n        self._logger.info('Found stage %s' %stage)\n\n        # enter config mode\n        self._send_cmd('PW', 1)\n        self._wait_states(STATE_CONFIGURATION)\n\n        # load stage parameters\n        self._send_cmd('ZX', 1)\n\n        # enable stage ID check\n        self._send_cmd('ZX', 2)\n\n        # exit configuration mode\n        self._send_cmd('PW', 0)\n\n        # wait for us to get back into NOT REFERENCED state\n        self._wait_states(STATE_NOT_REFERENCED_FROM_CONFIGURATION)",
  "def get_position(self, axis=None):\n        pos = self._send_cmd('TP', axes=axis, argument='?', expect_response=True, retry=10)\n        pos = list(map(float, pos))\n        return pos",
  "def home(self, **kwargs):\n        \"\"\"\n        Homes the controller. If waitStop is True, then this method returns when\n        homing is complete.\n        Note that because calling home when the stage is already homed has no\n        effect, and homing is generally expected to place the stage at the\n        origin, an absolute move to 0 um is executed after homing. This ensures\n        that the stage is at origin after calling this method.\n        Calling this method is necessary to take the controller out of not referenced\n        state after a restart.\n        \"\"\"\n        self._send_cmd('OR')\n        if 'waitStop' in kwargs and kwargs['waitStop']:\n            # wait for the controller to be ready\n            st = self._wait_states((STATE_READY_FROM_HOMING, STATE_READY_FROM_MOVING))\n            if st == STATE_READY_FROM_MOVING:\n                self.move([0]*len(self.axis_names), **kwargs)\n        else:\n            self.move([0]*len(self.axis_names), **kwargs)",
  "def stop(self):\n        self._send_cmd('ST')",
  "def get_status(self):\n        \"\"\"\n        Executes TS? and returns the the error code as integer and state as string\n        as specified on pages 64 - 65 of the manual.\n        \"\"\"\n\n        resps = self._send_cmd('TS', argument='?', expect_response=True, retry=10)\n        reply = ()\n        for resp in resps:\n            errors = int(resp[0:4], 16)\n            state = resp[4:]\n            assert len(state) == 2\n            reply += ([errors, state], )\n\n        return reply",
  "def move(self, pos, axis=None, relative=False, waitStop=True):\n        if axis is None:\n            axis = self.axis_names\n        if not hasattr(pos, '__iter__'):\n            pos = [pos]\n        if relative:\n            index = 0\n            for ax in axis:\n                self._send_cmd('PR', axes=ax, argument=pos[index])\n                index += 1\n        else:\n            index = 0\n            for ax in axis:\n                self._send_cmd('PA', axes=ax, argument=pos[index])\n                index += 1\n\n        if waitStop:\n            # If we were previously homed, then something like PR0 will have no\n            # effect and we end up waiting forever for ready from moving because\n            # we never left ready from homing. This is why STATE_READY_FROM_HOMING\n            # is included.\n            self._wait_states((STATE_READY_FROM_MOVING, STATE_READY_FROM_HOMING))",
  "def move_referenced(self, position_mm, **kwargs):\n        \"\"\"\n        Moves to an absolute position referenced from the software home\n\n        Args:\n            position_mm: position from the software home\n            **kwargs: kwargs to be passed to the move command\n\n        Returns:\n\n        \"\"\"\n\n        if not hasattr(position_mm, '__iter__'):\n            position_mm = (position_mm, )\n\n        final_pos = list(map(lambda x, y: x+y, self.software_home, position_mm))\n\n        self.move(final_pos, **kwargs)",
  "def set_software_home(self):\n        \"\"\"\n        Sets a software home, so that we can easily go back to similar sample positions\n\n        Returns:\n\n        \"\"\"\n        self.software_home = self.get_position()",
  "def go_software_home(self):\n        self.move_referenced([0]*len(self.axis_names))",
  "def set_velocity(self, velocity):\n        self._send_cmd('VA_Set', velocity)",
  "class PIStage(VisaInstrument, Stage):\n    \"\"\"\n    Control interface for PI stages.\n    \"\"\"\n    def __init__(self, address='ASRL8::INSTR',timeout = 10,baud_rate = 57600):\n        super(PIStage, self).__init__(address=address)\n        self.instr.read_termination = '\\n'\n        self.instr.write_termination = '\\n'\n        self.instr.baud_rate = 57600\n   #     self.instr.timeout = 10\n        self.axis_names = ('a', 'b')\n        self.positions = [0 for ch in range(3)]\n        self._stage_id = None\n        self.startup()\n\n    def move(self, pos, axis=None, relative=False):\n        if relative:\n            self.set_axis_param(partial(self.move_axis, relative=True), pos, axis)\n        else:\n            self.set_axis_param(self.move_axis, pos, axis)\n\n    def move_axis(self, pos, axis, relative=False):\n        if relative:\n            self.write('mvr {0}{1}'.format(axis, 1e6*pos))\n        else:\n            self.write('mov {0}{1}'.format(axis, 1e6*pos))\n        self.wait_until_stopped(axis)\n\n    def get_position(self, axis=None):\n        return self.get_axis_param(lambda axis: 1e-6*float(self.query('pos? {0}'.format(axis))), axis)\n    position = property(fget=get_position, doc=\"Current position of the stage\")\n\n    def is_moving(self, axes=None):\n        \"\"\"\n        Returns True if any of the specified axes are in motion.\n        In this case the position is polled 3 times and see if the stage stays close to\n        its initial position.\n        \"\"\"\n        positions = np.zeros((3, len(axes)))\n        for i in range(3):\n            positions[i] = [self.get_position(axis) for axis in axes]\n            time.sleep(0.005)\n        sum_of_diffs = np.sum(positions-positions[0], axis=1)\n        if np.any(sum_of_diffs > 0.01):\n            print(sum_of_diffs)\n            return True\n        else:\n            return False\n\n    def wait_until_stopped(self, axes=None):\n        \"\"\"Block until the stage is no longer moving.\"\"\"\n        while self.is_moving(axes=axes):\n            time.sleep(0.01)\n\n    def startup(self):\n        self.online = 1\n        while not self.online:\n            print(self.online)\n        self.loop_mode = 1\n        self.speed_mode = 0\n        self.velocity = 100\n        self.drift_compensation = 0\n        self.instr.write('cto 132')\n        self.instr.write('cto 232')\n        self.instr.write('cto 332')\n\n    def shutdown(self):\n        self.loop_mode = 0\n        self.online = 0\n\n    def get_velocity(self, axis=None):\n        return self.get_axis_param(lambda axis: float(self.query('vel? {0}'.format(axis))), axis)\n    def set_velocity(self, value, axis=None):\n        self.set_axis_param(lambda value, axis: self.write('vel {0}{1}'.format(axis, value)), value, axis)\n    velocity = property(get_velocity, set_velocity)\n\n    def get_drift_compensation(self, axis=None):\n        return self.get_axis_param(lambda axis: bool(self.query('dco? {0}'.format(axis))), axis)\n    def set_drift_compensation(self, value, axis=None):\n        self.set_axis_param(lambda value, axis: self.write('dco {0}{1}'.format(axis, value)), value, axis)\n    drift_compensation = property(get_drift_compensation, set_drift_compensation)\n\n    def get_loop_mode(self, axis=None):\n        return self.get_axis_param(lambda axis: bool(self.query('svo? {0}'.format(axis))), axis)\n    def set_loop_mode(self, value, axis=None):\n        \"\"\"\n        Set the mode of each axis control loop\n        :param value: servo control mode - 1 for closed loop, 0 for open loop\n        :param axis:\n        :return:\n        \"\"\"\n        self.set_axis_param(lambda value, axis: self.write('svo {0}{1}'.format(axis, value)), value, axis)\n    loop_mode = property(get_loop_mode, set_loop_mode)\n\n    def get_speed_mode(self, axis=None):\n        return self.get_axis_param(lambda axis: bool(self.query('vco? {0}'.format(axis))), axis)\n    def set_speed_mode(self, value, axis=None):\n        \"\"\"\n        Set the mode of each axis control loop\n        :param value: speed control mode - 1 for controlled speed, 0 for fastest\n        :param axis:\n        :return:\n        \"\"\"\n        self.set_axis_param(lambda value, axis: self.write('vco {0}{1}'.format(axis, value)), value, axis)\n    speed_mode = property(get_speed_mode, set_speed_mode)\n\n    def get_online(self):\n        return bool(self.query('onl?'))\n    def set_online(self, value):\n        self.write('onl {0}'.format(value))\n    online = property(get_online, set_online)\n\n    def get_on_target(self):\n       return bool(self.query('ont?'))\n    on_target = property(get_on_target)\n\n    def get_id(self):\n        if self._stage_id is None:\n            self._stage_id = self.query('*idn?')\n        return self._stage_id\n    stage_id = property(get_id)\n\n    def get_qt_ui(self):\n        return StageUI(self, stage_step_min=0.1e-9, stage_step_max=100e-6)",
  "def __init__(self, address='ASRL8::INSTR',timeout = 10,baud_rate = 57600):\n        super(PIStage, self).__init__(address=address)\n        self.instr.read_termination = '\\n'\n        self.instr.write_termination = '\\n'\n        self.instr.baud_rate = 57600\n   #     self.instr.timeout = 10\n        self.axis_names = ('a', 'b')\n        self.positions = [0 for ch in range(3)]\n        self._stage_id = None\n        self.startup()",
  "def move(self, pos, axis=None, relative=False):\n        if relative:\n            self.set_axis_param(partial(self.move_axis, relative=True), pos, axis)\n        else:\n            self.set_axis_param(self.move_axis, pos, axis)",
  "def move_axis(self, pos, axis, relative=False):\n        if relative:\n            self.write('mvr {0}{1}'.format(axis, 1e6*pos))\n        else:\n            self.write('mov {0}{1}'.format(axis, 1e6*pos))\n        self.wait_until_stopped(axis)",
  "def get_position(self, axis=None):\n        return self.get_axis_param(lambda axis: 1e-6*float(self.query('pos? {0}'.format(axis))), axis)",
  "def is_moving(self, axes=None):\n        \"\"\"\n        Returns True if any of the specified axes are in motion.\n        In this case the position is polled 3 times and see if the stage stays close to\n        its initial position.\n        \"\"\"\n        positions = np.zeros((3, len(axes)))\n        for i in range(3):\n            positions[i] = [self.get_position(axis) for axis in axes]\n            time.sleep(0.005)\n        sum_of_diffs = np.sum(positions-positions[0], axis=1)\n        if np.any(sum_of_diffs > 0.01):\n            print(sum_of_diffs)\n            return True\n        else:\n            return False",
  "def wait_until_stopped(self, axes=None):\n        \"\"\"Block until the stage is no longer moving.\"\"\"\n        while self.is_moving(axes=axes):\n            time.sleep(0.01)",
  "def startup(self):\n        self.online = 1\n        while not self.online:\n            print(self.online)\n        self.loop_mode = 1\n        self.speed_mode = 0\n        self.velocity = 100\n        self.drift_compensation = 0\n        self.instr.write('cto 132')\n        self.instr.write('cto 232')\n        self.instr.write('cto 332')",
  "def shutdown(self):\n        self.loop_mode = 0\n        self.online = 0",
  "def get_velocity(self, axis=None):\n        return self.get_axis_param(lambda axis: float(self.query('vel? {0}'.format(axis))), axis)",
  "def set_velocity(self, value, axis=None):\n        self.set_axis_param(lambda value, axis: self.write('vel {0}{1}'.format(axis, value)), value, axis)",
  "def get_drift_compensation(self, axis=None):\n        return self.get_axis_param(lambda axis: bool(self.query('dco? {0}'.format(axis))), axis)",
  "def set_drift_compensation(self, value, axis=None):\n        self.set_axis_param(lambda value, axis: self.write('dco {0}{1}'.format(axis, value)), value, axis)",
  "def get_loop_mode(self, axis=None):\n        return self.get_axis_param(lambda axis: bool(self.query('svo? {0}'.format(axis))), axis)",
  "def set_loop_mode(self, value, axis=None):\n        \"\"\"\n        Set the mode of each axis control loop\n        :param value: servo control mode - 1 for closed loop, 0 for open loop\n        :param axis:\n        :return:\n        \"\"\"\n        self.set_axis_param(lambda value, axis: self.write('svo {0}{1}'.format(axis, value)), value, axis)",
  "def get_speed_mode(self, axis=None):\n        return self.get_axis_param(lambda axis: bool(self.query('vco? {0}'.format(axis))), axis)",
  "def set_speed_mode(self, value, axis=None):\n        \"\"\"\n        Set the mode of each axis control loop\n        :param value: speed control mode - 1 for controlled speed, 0 for fastest\n        :param axis:\n        :return:\n        \"\"\"\n        self.set_axis_param(lambda value, axis: self.write('vco {0}{1}'.format(axis, value)), value, axis)",
  "def get_online(self):\n        return bool(self.query('onl?'))",
  "def set_online(self, value):\n        self.write('onl {0}'.format(value))",
  "def get_on_target(self):\n       return bool(self.query('ont?'))",
  "def get_id(self):\n        if self._stage_id is None:\n            self._stage_id = self.query('*idn?')\n        return self._stage_id",
  "def get_qt_ui(self):\n        return StageUI(self, stage_step_min=0.1e-9, stage_step_max=100e-6)",
  "class Piezoconcept(si.SerialInstrument):\n    '''A simple class for the Piezo concept FOC100 nanopositioning system'''\n    \n    def __init__(self, port=None):\n        self.termination_character = '\\n'\n        self.port_settings = {\n                    'baudrate':115200,\n                    'bytesize':serial.EIGHTBITS,\n                    'parity':serial.PARITY_NONE,\n                    'stopbits':serial.STOPBITS_ONE,\n                    'timeout':1, #wait at most one second for a response\n          #          'writeTimeout':1, #similarly, fail if writing takes >1s\n           #         'xonxoff':False, 'rtscts':False, 'dsrdtr':False,\n                    }\n        si.SerialInstrument.__init__(self,port=port)\n        self.recenter()\n        \n    def move_rel(self,value,unit=\"n\"):\n        '''A command for relative movement, where the default units is nm'''\n        if unit == \"n\":\n            multiplier=1\n        if unit == \"u\":\n            multiplier=1E3\n            \n        if (value*multiplier+self.position) > 1E5 or (value*multiplier+self.position) < 0:\n            print(\"The value is out of range! 0-100 um (0-1E8 nm) (Z)\")\n        elif (value*multiplier+self.position) < 1E5 and (value*multiplier+self.position) >= 0:\n            self.write(\"MOVRX \"+str(value)+unit)\n            self.position=(value*multiplier+self.position)\n    \n    def move(self,value,unit=\"n\"):\n        '''An absolute movement command, will print an error to the console \n        if you moveoutside of the range(100um) default unit is nm'''\n        if unit == \"n\":\n            multiplier=1\n        if unit == \"u\":\n            multiplier=1E3\n            \n        if value*multiplier >1E5 or value*multiplier <0:\n            print(\"The value is out of range! 0-100 um (0-1E8 nm) (Z)\")\n            \n        elif value*multiplier < 1E5 and value*multiplier >=0: \n            self.write(\"MOVEX \"+str(value)+unit)\n            self.position = value*multiplier\n            \n    def move_step(self,direction):\n        self.move_rel(direction*self.stepsize)\n        \n    def recenter(self):\n        ''' Moves the stage to the center position'''\n        self.move(50,unit = \"u\")\n        self.position = 50E3\n        \n    def INFO(self):\n        return self.query(\"INFOS\",multiline=True,termination_line= \"\\n \\n \\n \\n\",timeout=.1,)",
  "def __init__(self, port=None):\n        self.termination_character = '\\n'\n        self.port_settings = {\n                    'baudrate':115200,\n                    'bytesize':serial.EIGHTBITS,\n                    'parity':serial.PARITY_NONE,\n                    'stopbits':serial.STOPBITS_ONE,\n                    'timeout':1, #wait at most one second for a response\n          #          'writeTimeout':1, #similarly, fail if writing takes >1s\n           #         'xonxoff':False, 'rtscts':False, 'dsrdtr':False,\n                    }\n        si.SerialInstrument.__init__(self,port=port)\n        self.recenter()",
  "def move_rel(self,value,unit=\"n\"):\n        '''A command for relative movement, where the default units is nm'''\n        if unit == \"n\":\n            multiplier=1\n        if unit == \"u\":\n            multiplier=1E3\n            \n        if (value*multiplier+self.position) > 1E5 or (value*multiplier+self.position) < 0:\n            print(\"The value is out of range! 0-100 um (0-1E8 nm) (Z)\")\n        elif (value*multiplier+self.position) < 1E5 and (value*multiplier+self.position) >= 0:\n            self.write(\"MOVRX \"+str(value)+unit)\n            self.position=(value*multiplier+self.position)",
  "def move(self,value,unit=\"n\"):\n        '''An absolute movement command, will print an error to the console \n        if you moveoutside of the range(100um) default unit is nm'''\n        if unit == \"n\":\n            multiplier=1\n        if unit == \"u\":\n            multiplier=1E3\n            \n        if value*multiplier >1E5 or value*multiplier <0:\n            print(\"The value is out of range! 0-100 um (0-1E8 nm) (Z)\")\n            \n        elif value*multiplier < 1E5 and value*multiplier >=0: \n            self.write(\"MOVEX \"+str(value)+unit)\n            self.position = value*multiplier",
  "def move_step(self,direction):\n        self.move_rel(direction*self.stepsize)",
  "def recenter(self):\n        ''' Moves the stage to the center position'''\n        self.move(50,unit = \"u\")\n        self.position = 50E3",
  "def INFO(self):\n        return self.query(\"INFOS\",multiline=True,termination_line= \"\\n \\n \\n \\n\",timeout=.1,)",
  "class ELL18K(object):\n\n\tdef __init__(self,Port=None,Backlash_Correct=True):\n\t\t\"\"\"\n\t\tClass for Thorlabs Ellipical Motor Rotation Stage.\n\n\t\tInputs:\n\t\tPort = COM Port (String)\n\t\tCounts_per_Rev = Number of intervals a 360 degree is split into.\n\t\t\t\t\t\t This varies between iterations of the device\n\t\tBacklash_Correct = Bool\n\n\t\t\"\"\"\n\n\t\tself.Port=serial.SerialInstrument(Port)\n\t\tself.Port.open()\n\t\tself.Counts_per_Rev=int('0x'+self.Write_Hex('0in')[-9:-2],0) #Cuts off return characters\n\t\tself.Backlash_Correct=Backlash_Correct\n\n\t\tself.Calibrate_Motors() #Calibrates motor resonance frequencies to account for load etc.\n\n\t#------Utility functions----------\n\n\tdef Number_to_Hex(self,Input,Min_Digits=8):\n\t\t\"\"\"\n\t\tTakes an Input integer and returns the corresponding hex as a string.\n\t\tIf resulting string has less than Min_Digits digits, zeros are added to the front\n\t\t\"\"\"\n\t\tHex=str(hex(Input))[2:].upper() #All letters should be upper case\n\n\t\twhile len(Hex)<Min_Digits:\n\t\t\tHex='0'+Hex\n\t\treturn Hex\n\n\n\tdef Convert_Status(self,Code):\n\t\t\"\"\"\n\t\tConverts integer Code into a status string\n\t\t\"\"\"\n\t\tResponses=['No Error', 'Communication time out', 'Mechanical time out', 'Command error', 'Value out of range', 'Module isolated']\n\t\tResponses+=['Module out of isolation', 'Initializing error', 'Thermal error', 'Busy', 'Sensor Error', 'Initializing error', 'Thermal error', 'Busy']\n\t\tResponses+=['Sensor Error', 'Motor Error', 'Out of Range']\n\n\t\tif Code>=14:\n\t\t\treturn 'Reserved Response Code'\n\t\telse:\n\t\t\treturn Responses[Code]\n\n\tdef Write_Hex(self,String):\n\t\t\"\"\"\n\t\tWrites Hex string to port. Reads following line from port and returns string.\n\t\t\"\"\"\n\n\t\tSeperate=[]\n\t\tFormat=''\n\t\tfor i in String:\n\t\t\tSeperate.append(bytes(i, \"utf-8\"))\n\t\t\tFormat+='c'\n\t\tPacker=struct.Struct(format=Format)\n\t\tself.Port.write(Packer.pack(*Seperate))\n\n\t\tResponse=self.Port.readline()\n\t\treturn Response\n\n\tdef Two_Compliment(self,Integer,Bits=32):\n\t\t\"\"\"\n\t\tConverts an integer into its 2s compliment with respect to a certain number of bits\n\t\t\"\"\"\n\t\tString=bin(Integer)[2:]\n\t\twhile len(String)<Bits:\n\t\t\tString='0'+String\n\t\tNew=[]\n\t\tfor i in range(len(String)):\n\t\t\tNew.append((-1*(int(String[i])-1)))\n\t\tn=len(New)-1\n\t\tNew[-1]+=1\n\t\twhile n>=0:\n\t\t\tif New[n]==2:\n\t\t\t\tNew[n]=0\n\t\t\t\tif n>0:\n\t\t\t\t\tNew[n-1]+=1\n\t\t\telse:\n\t\t\t\tn=0\n\t\t\tn-=1\n\t\tString_New='0b'\n\t\tfor i in New:\n\t\t\tString_New+=str(i)\n\t\treturn int(String_New,0)\n\n\t#------Stage Commands----------\n\n\tdef Calibrate_Motors(self):\n\t\t\"\"\"\n\t\tCauses both motors to do a frequency sweep to find optimal resonance frequency\n\t\t\"\"\"\n\t\tself.Write_Hex('0s1')\n\t\tself.Write_Hex('0s2')\n\t\tself.Write_Hex('0us')\n\n\tdef Get_Status(self):\n\t\t\"\"\"\n\t\tRequests a status message\n\t\t\"\"\"\n\t\tStatus=self.Write_Hex('0gs')\n\t\tCode=int('0x'+Status[3:],0)\n\t\treturn self.Convert_Status(Code)\n\n\tdef Read_Position(self,Integer=None):\n\t\t\"\"\"\n\t\tReturns current stage angle. Can also take in a motor step Integer instead of requesting one from the device\n\t\t\"\"\"\n\t\tif Integer is None:\n\t\t\tPos=self.Write_Hex('0gp')\n\t\t\tif Pos[:3]=='0PO': #Position_Returned\n\t\t\t\tInteger=int('0x'+Pos[3:],0)\n\t\t\telse:\n\t\t\t\tCode=int('0x'+Pos[3:],0) #Status returned\n\t\t\t\treturn self.Convert_Status(Code)\n\t\t\n\t\tif Integer>2147483647: #Negative Number\n\t\t\tInteger=-self.Two_Compliment(Integer)\n\t\tInteger=360.*float(Integer)/self.Counts_per_Rev\n\t\treturn Integer\n\n\n\tdef Rotate_To(self,Angle):\n\t\t\"\"\"\n\t\tRotates the stage to a given angle. Returns final angle or status report\n\t\t\"\"\"\n\n\t\tAngle=(Angle%360)\n\n\t\tCurrent_Angle=self.Read_Position()\n\t\tif isinstance(Current_Angle,str)==True: #Check is status returned\n\t\t\treturn Current_Angle\n\n\t\tif abs(Current_Angle-Angle)>=360./self.Counts_per_Rev: #Is it worth rotating?\n\n\t\t\tif self.Backlash_Correct==True:\n\t\t\t\tInitial_Angle=(Angle-5)\n\t\t\telse:\n\t\t\t\tInitial_Angle=Angle\n\n\t\t\tPulses=float(Initial_Angle)*self.Counts_per_Rev/360.\n\t\t\tPulses=int(np.round(Pulses)) #Closest to requested\n\n\t\t\tPos=self.Write_Hex('0ma'+self.Number_to_Hex(Pulses))\n\n\t\t\tif self.Backlash_Correct==True:\n\t\t\t\tPulses=float(Angle)*self.Counts_per_Rev/360.\n\t\t\t\tPulses=int(np.round(Pulses)) #Closest to requested\n\n\t\t\t\tPos=self.Write_Hex('0ma'+self.Number_to_Hex(Pulses))\n\n\t\t\tif Pos[:3]=='0PO': #Position_Returned\n\t\t\t\tPos=int('0x'+Pos[3:],0)\n\t\t\t\treturn self.Read_Position(Pos)\n\t\t\telse:\n\t\t\t\tCode=int('0x'+Pos[3:],0) #Status returned\n\t\t\t\treturn self.Convert_Status(Code)\n\n\t\telse:\n\t\t\treturn Current_Angle\n\n\tdef Rotate(self,Angle):\n\t\tCurrent_Angle=self.Read_Position()\n\t\tif isinstance(Current_Angle,str)==True: #Check is status returned\n\t\t\treturn Current_Angle\n\t\telse:\n\t\t\treturn self.Rotate_To(Current_Angle+Angle)",
  "def __init__(self,Port=None,Backlash_Correct=True):\n\t\t\"\"\"\n\t\tClass for Thorlabs Ellipical Motor Rotation Stage.\n\n\t\tInputs:\n\t\tPort = COM Port (String)\n\t\tCounts_per_Rev = Number of intervals a 360 degree is split into.\n\t\t\t\t\t\t This varies between iterations of the device\n\t\tBacklash_Correct = Bool\n\n\t\t\"\"\"\n\n\t\tself.Port=serial.SerialInstrument(Port)\n\t\tself.Port.open()\n\t\tself.Counts_per_Rev=int('0x'+self.Write_Hex('0in')[-9:-2],0) #Cuts off return characters\n\t\tself.Backlash_Correct=Backlash_Correct\n\n\t\tself.Calibrate_Motors()",
  "def Number_to_Hex(self,Input,Min_Digits=8):\n\t\t\"\"\"\n\t\tTakes an Input integer and returns the corresponding hex as a string.\n\t\tIf resulting string has less than Min_Digits digits, zeros are added to the front\n\t\t\"\"\"\n\t\tHex=str(hex(Input))[2:].upper() #All letters should be upper case\n\n\t\twhile len(Hex)<Min_Digits:\n\t\t\tHex='0'+Hex\n\t\treturn Hex",
  "def Convert_Status(self,Code):\n\t\t\"\"\"\n\t\tConverts integer Code into a status string\n\t\t\"\"\"\n\t\tResponses=['No Error', 'Communication time out', 'Mechanical time out', 'Command error', 'Value out of range', 'Module isolated']\n\t\tResponses+=['Module out of isolation', 'Initializing error', 'Thermal error', 'Busy', 'Sensor Error', 'Initializing error', 'Thermal error', 'Busy']\n\t\tResponses+=['Sensor Error', 'Motor Error', 'Out of Range']\n\n\t\tif Code>=14:\n\t\t\treturn 'Reserved Response Code'\n\t\telse:\n\t\t\treturn Responses[Code]",
  "def Write_Hex(self,String):\n\t\t\"\"\"\n\t\tWrites Hex string to port. Reads following line from port and returns string.\n\t\t\"\"\"\n\n\t\tSeperate=[]\n\t\tFormat=''\n\t\tfor i in String:\n\t\t\tSeperate.append(bytes(i, \"utf-8\"))\n\t\t\tFormat+='c'\n\t\tPacker=struct.Struct(format=Format)\n\t\tself.Port.write(Packer.pack(*Seperate))\n\n\t\tResponse=self.Port.readline()\n\t\treturn Response",
  "def Two_Compliment(self,Integer,Bits=32):\n\t\t\"\"\"\n\t\tConverts an integer into its 2s compliment with respect to a certain number of bits\n\t\t\"\"\"\n\t\tString=bin(Integer)[2:]\n\t\twhile len(String)<Bits:\n\t\t\tString='0'+String\n\t\tNew=[]\n\t\tfor i in range(len(String)):\n\t\t\tNew.append((-1*(int(String[i])-1)))\n\t\tn=len(New)-1\n\t\tNew[-1]+=1\n\t\twhile n>=0:\n\t\t\tif New[n]==2:\n\t\t\t\tNew[n]=0\n\t\t\t\tif n>0:\n\t\t\t\t\tNew[n-1]+=1\n\t\t\telse:\n\t\t\t\tn=0\n\t\t\tn-=1\n\t\tString_New='0b'\n\t\tfor i in New:\n\t\t\tString_New+=str(i)\n\t\treturn int(String_New,0)",
  "def Calibrate_Motors(self):\n\t\t\"\"\"\n\t\tCauses both motors to do a frequency sweep to find optimal resonance frequency\n\t\t\"\"\"\n\t\tself.Write_Hex('0s1')\n\t\tself.Write_Hex('0s2')\n\t\tself.Write_Hex('0us')",
  "def Get_Status(self):\n\t\t\"\"\"\n\t\tRequests a status message\n\t\t\"\"\"\n\t\tStatus=self.Write_Hex('0gs')\n\t\tCode=int('0x'+Status[3:],0)\n\t\treturn self.Convert_Status(Code)",
  "def Read_Position(self,Integer=None):\n\t\t\"\"\"\n\t\tReturns current stage angle. Can also take in a motor step Integer instead of requesting one from the device\n\t\t\"\"\"\n\t\tif Integer is None:\n\t\t\tPos=self.Write_Hex('0gp')\n\t\t\tif Pos[:3]=='0PO': #Position_Returned\n\t\t\t\tInteger=int('0x'+Pos[3:],0)\n\t\t\telse:\n\t\t\t\tCode=int('0x'+Pos[3:],0) #Status returned\n\t\t\t\treturn self.Convert_Status(Code)\n\t\t\n\t\tif Integer>2147483647: #Negative Number\n\t\t\tInteger=-self.Two_Compliment(Integer)\n\t\tInteger=360.*float(Integer)/self.Counts_per_Rev\n\t\treturn Integer",
  "def Rotate_To(self,Angle):\n\t\t\"\"\"\n\t\tRotates the stage to a given angle. Returns final angle or status report\n\t\t\"\"\"\n\n\t\tAngle=(Angle%360)\n\n\t\tCurrent_Angle=self.Read_Position()\n\t\tif isinstance(Current_Angle,str)==True: #Check is status returned\n\t\t\treturn Current_Angle\n\n\t\tif abs(Current_Angle-Angle)>=360./self.Counts_per_Rev: #Is it worth rotating?\n\n\t\t\tif self.Backlash_Correct==True:\n\t\t\t\tInitial_Angle=(Angle-5)\n\t\t\telse:\n\t\t\t\tInitial_Angle=Angle\n\n\t\t\tPulses=float(Initial_Angle)*self.Counts_per_Rev/360.\n\t\t\tPulses=int(np.round(Pulses)) #Closest to requested\n\n\t\t\tPos=self.Write_Hex('0ma'+self.Number_to_Hex(Pulses))\n\n\t\t\tif self.Backlash_Correct==True:\n\t\t\t\tPulses=float(Angle)*self.Counts_per_Rev/360.\n\t\t\t\tPulses=int(np.round(Pulses)) #Closest to requested\n\n\t\t\t\tPos=self.Write_Hex('0ma'+self.Number_to_Hex(Pulses))\n\n\t\t\tif Pos[:3]=='0PO': #Position_Returned\n\t\t\t\tPos=int('0x'+Pos[3:],0)\n\t\t\t\treturn self.Read_Position(Pos)\n\t\t\telse:\n\t\t\t\tCode=int('0x'+Pos[3:],0) #Status returned\n\t\t\t\treturn self.Convert_Status(Code)\n\n\t\telse:\n\t\t\treturn Current_Angle",
  "def Rotate(self,Angle):\n\t\tCurrent_Angle=self.Read_Position()\n\t\tif isinstance(Current_Angle,str)==True: #Check is status returned\n\t\t\treturn Current_Angle\n\t\telse:\n\t\t\treturn self.Rotate_To(Current_Angle+Angle)",
  "class Stage(Instrument):\n    \"\"\"A class representing motion-control stages.\n    \n    This class primarily provides two things: the ability to find the position\n    of the stage (using `Stage.position` or `Stage.get_position(axis=\"a\")`), \n    and the ability to move the stage (see `Stage.move()`).\n    \n    Subclassing Notes\n    -----------------\n    The minimum you need to do in order to subclass this is to override the\n    `move` method and the `get_position` method.  NB you must handle the case\n    where `axis` is specified and where it is not.  For `move`, `move_axis` is\n    provided, which will help emulate single-axis moves on stages that can't \n    make them natively.\n    \n    In the future, a class factory method might be available, that will \n    simplify the emulation of various features.\n    \"\"\"\n    axis_names = ('x', 'y', 'z')\n    def __init__(self, unit='m'):\n        Instrument.__init__(self)\n        self.unit = unit\n\n    def move(self, pos, axis=None, relative=False):\n        raise NotImplementedError(\"You must override move() in a Stage subclass\")\n\n    def move_rel(self, position, axis=None):\n        \"\"\"Make a relative move, see move() with relative=True.\"\"\"\n        self.move(position, axis, relative=True)\n\n    def move_axis(self, pos, axis, relative=False, **kwargs):\n        \"\"\"Move along one axis.\n        \n        This function moves only in one axis, by calling self.move with \n        appropriately generated values (i.e. it supplies all axes with position\n        instructions, but those not moving just get the current position).\n        \n        It's intended for use in stages that don't support single-axis moves.\"\"\"\n        if axis not in self.axis_names:\n            raise ValueError(\"{0} is not a valid axis, must be one of {1}\".format(axis, self.axis_names))\n\n        full_position = np.zeros((len(self.axis_names))) if relative else self.position\n        full_position[self.axis_names.index(axis)] = pos\n        self.move(full_position, relative=relative, **kwargs)\n\n    def get_position(self, axis=None):\n        raise NotImplementedError(\"You must override get_position in a Stage subclass.\")\n\n    def select_axis(self, iterable, axis):\n        \"\"\"Pick an element from a tuple, indexed by axis name.\"\"\"\n        assert axis in self.axis_names, ValueError(\"{0} is not a valid axis name.\".format(axis))\n        return iterable[self.axis_names.index(axis)]\n\n    def _get_position_proxy(self):\n        \"\"\"Return self.get_position() (this is a convenience to avoid having\n        to redefine the position property every time you subclass - don't call\n        it directly)\"\"\"\n        return self.get_position()\n    position = property(fget=_get_position_proxy, doc=\"Current position of the stage (all axes)\")\n\n    def is_moving(self, axes=None):\n        \"\"\"Returns True if any of the specified axes are in motion.\"\"\"\n        raise NotImplementedError(\"The is_moving method must be subclassed and implemented before it's any use!\")\n\n    def wait_until_stopped(self, axes=None):\n        \"\"\"Block until the stage is no longer moving.\"\"\"\n        while self.is_moving(axes=axes):\n            time.sleep(0.01)\n\n    def get_qt_ui(self):\n        if self.unit == 'm':\n            return StageUI(self)\n        elif self.unit == 'u':\n            return StageUI(self, stage_step_min=1E-3, stage_step_max=1000.0, default_step=1.0)\n        elif self.unit == 'step':\n            return StageUI(self, stage_step_min=1, stage_step_max=1000.0, default_step=1.0)\n        elif self.unit == 'deg':\n            return StageUI(self, stage_step_min=0.1, stage_step_max=360, default_step=1.0)\n        else:\n            self._logger.warn('Tried displaying a GUI for an unrecognised unit: %s' % self.unit)\n\n    def get_axis_param(self, get_func, axis=None):\n        if axis is None:\n            return tuple(get_func(axis) for axis in self.axis_names)\n        elif isinstance(axis, collections.Sequence) and not isinstance(axis, str):\n            return tuple(get_func(ax) for ax in axis)\n        else:\n            return get_func(axis)\n\n    def set_axis_param(self, set_func, value, axis=None):\n        if axis is None:\n            if isinstance(value, collections.Sequence):\n                tuple(set_func(v, axis) for v,axis in zip(value, self.axis_names))\n            else:\n                tuple(set_func(value, axis) for axis in self.axis_names)\n        elif isinstance(axis, collections.Sequence) and not isinstance(axis, str):\n            if isinstance(value, collections.Sequence):\n                tuple(set_func(v, ax) for v,ax in zip(value, axis))\n            else:\n                tuple(set_func(value, ax) for ax in axis)\n        else:\n            set_func(value, axis)",
  "class PiezoStage(Stage):\n\n    def __init__(self):\n        super(PiezoStage, self).__init__()\n\n    def get_piezo_level(self, axis=None):\n        \"\"\" Returns the voltage levels of the specified piezo axis. \"\"\"\n        raise NotImplementedError(\"You must override get_piezo_leveln in a Stage subclass.\")\n        if axis is None:\n            return [self.get_scanner_level(axis) for axis in self.axis_names]\n        else:\n            if axis not in self.axis_names:\n                raise ValueError(\"{0} is not a valid axis, must be one of {1}\".format(axis, self.axis_names))\n\n    def set_piezo_level(self, level, axis):\n        \"\"\" Sets the voltage levels of the specified piezo axis. \"\"\"\n        raise NotImplementedError(\"You must override set_piezo_level in a Stage subclass.\")\n        if axis not in self.axis_names:\n            raise ValueError(\"{0} is not a valid axis, must be one of {1}\".format(axis, self.axis_names))\n\n    def get_piezo_voltage(self, axis):\n        \"\"\" Returns the voltage of the specified piezo axis. \"\"\"\n        raise NotImplementedError(\"You must override get_piezo_voltage in a Stage subclass.\")\n\n    def set_piezo_voltage(self, axis, voltage):\n        \"\"\" Sets the voltage of the specified piezo axis. \"\"\"\n        raise NotImplementedError(\"You must override set_piezo_voltage in a Stage subclass.\")\n\n    def get_piezo_position(self, axis=None):\n        \"\"\" Returns the position of the specified piezo axis. \"\"\"\n        raise NotImplementedError(\"You must override get_piezo_position in a Stage subclass.\")\n\n    def set_piezo_position(self, axis=None):\n        \"\"\" Sets the position of the specified piezo axis. \"\"\"\n        raise NotImplementedError(\"You must override set_piezo_position in a Stage subclass.\")",
  "class StageUI(QtWidgets.QWidget, UiTools):\n    update_ui = QtCore.Signal([int], [str])\n\n    def __init__(self, stage, parent=None, stage_step_min=1e-9, stage_step_max=1e-3, default_step=1e-6):\n        assert isinstance(stage, Stage), \"instrument must be a Stage\"\n        super(StageUI, self).__init__()\n        self.stage = stage\n        #self.setupUi(self)\n        self.step_size_values = step_size_dict(stage_step_min, stage_step_max,unit = self.stage.unit)\n        self.step_size = [self.step_size_values[list(self.step_size_values.keys())[0]] for axis in stage.axis_names]\n        self.update_ui[int].connect(self.update_positions)\n        self.update_ui[str].connect(self.update_positions)\n        self.create_axes_layout(default_step)\n        self.update_positions()\n\n    def move_axis_absolute(self, position, axis):\n        self.stage.move(position, axis=axis, relative=False)\n        if type(axis) == str:\n            self.update_ui[str].emit(axis)\n        elif type(axis) == int:\n            self.update_ui[int].emit(axis)\n\n    def move_axis_relative(self, index, axis, dir=1):\n        self.stage.move(dir * self.step_size[index], axis=axis, relative=True)\n        if type(axis) == str:\n            #    axis = QtCore.QString(axis)\n            self.update_ui[str].emit(axis)\n        elif type(axis) == int:\n            self.update_ui[int].emit(axis)\n\n    def zero_all_axes(self, axes):\n        pass\n#        for axis in axes:\n#            self.move_axis_absolute(0, axis)\n\n    def create_axes_layout(self, default_step=1e-6, arrange_buttons='cross', rows=None):\n        \"\"\"Layout of the PyQt widgets for absolute and relative movement of all axis\n\n        :param default_step:\n        :param arrange_buttons: either 'cross' or 'stack'. If 'cross', assumes the stages axes are x,y,z movement,\n        placing the arrows in an intuitive cross pattern\n        :param rows: number of rows per column when distributing the QtWidgets\n        :return:\n        \"\"\"\n        if rows is None:\n            rows = np.ceil(np.sqrt(len(self.stage.axis_names)))\n        rows = int(rows)  # int is needed for the old_div and the modulo operations\n\n        uic.loadUi(os.path.join(os.path.dirname(__file__), 'stage.ui'), self)\n        self.update_pos_button.clicked.connect(partial(self.update_positions, None))\n        path = os.path.dirname(os.path.realpath(nplab.ui.__file__))\n        icon_size = QtCore.QSize(12, 12)\n        self.positions = []\n        self.set_positions = []\n        self.set_position_buttons = []\n        for i, ax in enumerate(self.stage.axis_names):\n            col = 4 * (i// rows)\n            position = QtWidgets.QLineEdit('', self)\n            position.setReadOnly(True)\n            self.positions.append(position)\n            set_position = QtWidgets.QLineEdit('0', self)\n            set_position.setMinimumWidth(40)\n            self.set_positions.append(set_position)\n            set_position_button = QtWidgets.QPushButton('', self)\n            set_position_button.setIcon(QtGui.QIcon(os.path.join(path, 'go.png')))\n            set_position_button.setIconSize(icon_size)\n            set_position_button.resize(icon_size)\n            set_position_button.clicked.connect(self.button_pressed)\n            self.set_position_buttons.append(set_position_button)\n            # for each stage axis add a label, a field for the current position,\n            # a field to set a new position and a button to set a new position ..\n            self.info_layout.addWidget(QtWidgets.QLabel(str(ax), self), i % rows, col)\n            self.info_layout.addWidget(position, i % rows, col + 1)\n            self.info_layout.addWidget(set_position, i % rows, col + 2)\n            self.info_layout.addWidget(set_position_button, i % rows, col + 3)\n\n            if i % rows == 0:\n                if arrange_buttons == 'cross':\n                    group = QtWidgets.QGroupBox('axes {0}'.format(1 + (i// rows)), self)\n                    layout = QtWidgets.QGridLayout()\n                    layout.setSpacing(3)\n                    group.setLayout(layout)\n                    self.axes_layout.addWidget(group, 0, i// rows)\n                    offset = 0\n                elif arrange_buttons == 'stack':\n                    layout = self.axes_layout\n                    offset = 7 * (i// rows)\n                else:\n                    raise ValueError('Unrecognised arrangment: %s' % arrange_buttons)\n\n            step_size_select = QtWidgets.QComboBox(self)\n            step_size_select.addItems(list(self.step_size_values.keys()))\n            step_size_select.activated[str].connect(partial(self.on_activated, i))\n            step_str = engineering_format(default_step, self.stage.unit)\n            step_index = list(self.step_size_values.keys()).index(step_str)\n            step_size_select.setCurrentIndex(step_index)\n            layout.addWidget(QtWidgets.QLabel(str(ax), self), i % rows, 5 + offset)\n            layout.addWidget(step_size_select, i % rows, 6 + offset)\n            if i % 3 == 0 and arrange_buttons == 'cross':\n                layout.addItem(QtWidgets.QSpacerItem(12, 0), 0, 4)\n\n            plus_button = QtWidgets.QPushButton('', self)\n            plus_button.clicked.connect(partial(self.move_axis_relative, i, ax, 1))\n            minus_button = QtWidgets.QPushButton('', self)\n            minus_button.clicked.connect(partial(self.move_axis_relative, i, ax, -1))\n            if arrange_buttons == 'cross':\n                if i % rows == 0:\n                    plus_button.setIcon(QtGui.QIcon(os.path.join(path, 'right.png')))\n                    minus_button.setIcon(QtGui.QIcon(os.path.join(path, 'left.png')))\n                    layout.addWidget(minus_button, 1, 0)\n                    layout.addWidget(plus_button, 1, 2)\n                elif i % rows == 1:\n                    plus_button.setIcon(QtGui.QIcon(os.path.join(path, 'up.png')))\n                    minus_button.setIcon(QtGui.QIcon(os.path.join(path, 'down.png')))\n                    layout.addWidget(plus_button, 0, 1)\n                    layout.addWidget(minus_button, 2, 1)\n                elif i % rows == 2:\n                    plus_button.setIcon(QtGui.QIcon(os.path.join(path, 'up.png')))\n                    minus_button.setIcon(QtGui.QIcon(os.path.join(path, 'down.png')))\n                    layout.addWidget(plus_button, 0, 3)\n                    layout.addWidget(minus_button, 2, 3)\n            elif arrange_buttons == 'stack':\n                plus_button.setIcon(QtGui.QIcon(os.path.join(path, 'right.png')))\n                minus_button.setIcon(QtGui.QIcon(os.path.join(path, 'left.png')))\n                layout.addWidget(minus_button, i % rows, 0 + offset)\n                layout.addWidget(plus_button, i % rows, 1 + offset)\n            else:\n                raise ValueError('Unrecognised arrangment: %s' % arrange_buttons)\n            plus_button.setIconSize(icon_size)\n            plus_button.resize(icon_size)\n            minus_button.setIconSize(icon_size)\n            minus_button.resize(icon_size)\n\n    def button_pressed(self, *args, **kwargs):\n        sender = self.sender()\n        if sender in self.set_position_buttons:\n            index = self.set_position_buttons.index(sender)\n            axis = self.stage.axis_names[index]\n            position = float(self.set_positions[index].text())\n            self.move_axis_absolute(position, axis)\n\n    def on_activated(self, index, value):\n        # print self.sender(), index, value\n        self.step_size[index] = self.step_size_values[value]\n\n    @QtCore.Slot(int)\n    # @QtCore.pyqtSlot('QString')\n    @QtCore.Slot(str)\n    def update_positions(self, axis=None):\n        if axis not in self.stage.axis_names:\n            axis = None\n        if axis is None:\n            for axis in self.stage.axis_names:\n                self.update_positions(axis=axis)\n        else:\n            i = self.stage.axis_names.index(axis)\n            try:\n                p = engineering_format(self.stage.position[i], base_unit=self.stage.unit, digits_of_precision=4)\n            except ValueError:\n                p = '0 m'\n            self.positions[i].setText(p)",
  "def step_size_dict(smallest, largest, mantissas=[1, 2, 5],unit = 'm'):\n    \"\"\"Return a dictionary with nicely-formatted distances as keys and metres as values.\"\"\"\n    log_range = np.arange(np.floor(np.log10(smallest)), np.floor(np.log10(largest)) + 1)\n    steps = [m * 10 ** e for e in log_range for m in mantissas if smallest <= m * 10 ** e <= largest]\n    return OrderedDict((engineering_format(s, unit), s) for s in steps)",
  "class PiezoStageUI(StageUI):\n\n    def __init__(self, stage, parent=None, stage_step_min=1e-9,\n                 stage_step_max=1e-3, default_step=1e-8,show_xy_pos=True,\n                 show_z_pos=True):\n        self.show_xy_pos = show_xy_pos\n        self.show_z_pos = show_z_pos\n        assert isinstance(stage, Stage), \"instrument must be a Stage\"\n        super(PiezoStageUI, self).__init__(stage, parent, stage_step_min, stage_step_max, default_step)\n\n\n    def create_axes_layout(self, default_step=1e-8, stack_multiple_stages='horizontal'):\n        uic.loadUi(os.path.join(os.path.dirname(__file__), 'piezo_stage.ui'), self)\n        path = os.path.dirname(os.path.realpath(nplab.ui.__file__))\n        icon_size = QtCore.QSize(12, 12)\n        self.position_widgets = []\n        self.xy_positions = []\n        self.set_positions = []\n        self.set_position_buttons = []\n        for i, ax in enumerate(self.stage.axis_names):\n            col = 4 * (i// 3)\n            if i % 3 == 0:\n                # absolute position for different stages consisting of 3 axes\n                position_widget = XYZPositionWidget(self.stage.max_voltage_levels[(i//3)],\n                                                    self.stage.max_voltage_levels[(i//3)+1],\n                                                    self.stage.max_voltage_levels[(i//3)+2],\n                                                    show_xy_pos=self.show_xy_pos,\n                                                    show_z_pos=self.show_z_pos)\n                if self.show_xy_pos:\n                    xy_position = position_widget.xy_widget.crosshair\n                    xy_position.CrossHairMoved.connect(self.crosshair_moved)\n                    self.xy_positions.append(xy_position)\n\n                self.position_widgets.append(position_widget)\n\n                self.info_layout.addWidget(position_widget, 0, col,3,1)\n\n                # position control elements for different stages consisting of 3 axes, arranged in a grid layout\n                group = QtWidgets.QGroupBox('stage {0}'.format(1 + ((i// 3))), self)\n                layout = QtWidgets.QGridLayout()\n                layout.setSpacing(3)\n                group.setLayout(layout)\n                self.axes_layout.addWidget(group, 0, (i// 3))\n                zero_button = QtWidgets.QPushButton('', self)\n                zero_button.setIcon(QtGui.QIcon(os.path.join(path, 'zero.png')))\n                zero_button.setIconSize(icon_size)\n                zero_button.resize(icon_size)\n                n = len(self.stage.axis_names) - i if len(self.stage.axis_names) - i < 3 else 3\n                #axes_set = self.stage.axis_names[i:i + n]\n                #zero_button.clicked.connect(partial(self.zero_all_axes, axes_set))\n                layout.addWidget(zero_button, 1, 1)\n\n            set_position = QtWidgets.QLineEdit('0', self)   # text field to set position\n            set_position.setMinimumWidth(40)\n            set_position.setReadOnly(True)\n            self.set_positions.append(set_position)\n            set_position_button = QtWidgets.QPushButton('', self)\n            set_position_button.setIcon(QtGui.QIcon(os.path.join(path, 'go.png')))\n            set_position_button.setIconSize(icon_size)\n            set_position_button.resize(icon_size)\n            set_position_button.clicked.connect(self.button_pressed)\n            self.set_position_buttons.append(set_position_button)\n            # for each stage axis add a label, a field for the current position,\n            # a field to set a new position and a button to set a new position ..\n            self.info_layout.addWidget(QtWidgets.QLabel(str(ax), self), i % 3, col+1)\n            self.info_layout.addWidget(set_position, i % 3, col + 2)\n            self.info_layout.addWidget(set_position_button, i % 3, col + 3)\n\n            step_size_select = QtWidgets.QComboBox(self)\n            step_size_select.addItems(list(self.step_size_values.keys()))\n            step_size_select.activated[str].connect(partial(self.on_activated, i))\n            step_str = engineering_format(default_step, self.stage.unit)\n            step_index = list(self.step_size_values.keys()).index(step_str)\n            step_size_select.setCurrentIndex(step_index)\n            layout.addWidget(QtWidgets.QLabel(str(ax), self), i % 3, 5)\n            layout.addWidget(step_size_select, i % 3, 6)\n            if i % 3 == 0:\n                layout.addItem(QtWidgets.QSpacerItem(12, 0), 0, 4)\n\n            plus_button = QtWidgets.QPushButton('', self)\n            plus_button.clicked.connect(partial(self.move_axis_relative, i, ax, 1))\n            minus_button = QtWidgets.QPushButton('', self)\n            minus_button.clicked.connect(partial(self.move_axis_relative, i, ax, -1))\n            if i % 3 == 0:\n                plus_button.setIcon(QtGui.QIcon(os.path.join(path, 'right.png')))\n                minus_button.setIcon(QtGui.QIcon(os.path.join(path, 'left.png')))\n                layout.addWidget(minus_button, 1, 0)\n                layout.addWidget(plus_button, 1, 2)\n            elif i % 3 == 1:\n                plus_button.setIcon(QtGui.QIcon(os.path.join(path, 'up.png')))\n                minus_button.setIcon(QtGui.QIcon(os.path.join(path, 'down.png')))\n                layout.addWidget(plus_button, 0, 1)\n                layout.addWidget(minus_button, 2, 1)\n            elif i % 3 == 2:\n                plus_button.setIcon(QtGui.QIcon(os.path.join(path, 'up.png')))\n                minus_button.setIcon(QtGui.QIcon(os.path.join(path, 'down.png')))\n                layout.addWidget(plus_button, 0, 3)\n                layout.addWidget(minus_button, 2, 3)\n            plus_button.setIconSize(icon_size)\n            plus_button.resize(icon_size)\n            minus_button.setIconSize(icon_size)\n            minus_button.resize(icon_size)\n\n    def crosshair_moved(self):\n        sender = self.sender()\n        if sender in self.xy_positions:\n            i = self.xy_positions.index(sender)\n            self.stage.set_piezo_level(self.xy_positions[i].pos()[0],i*3)\n            self.stage.set_piezo_level(self.xy_positions[i].pos()[1],i*3+1)\n            # print \"crosshair moved in xy_widget \", i\n            # print self.xy_positions[i].pos()\n\n    @QtCore.Slot(int)\n    @QtCore.Slot(str)\n    def update_positions(self, axis=None):\n        piezo_levels = self.stage.piezo_levels\n        if axis is None:\n            for i in range(len(self.position_widgets)):\n                if self.show_xy_pos:\n                    self.position_widgets[i].xy_widget.setValue(piezo_levels[i*3],piezo_levels[i*3+1])\n                if self.show_z_pos:\n                    self.position_widgets[i].z_bar.setValue(piezo_levels[i*3+2])\n\n        else:\n            if self.show_xy_pos:\n                if axis % 3 == 0:\n                    self.position_widgets[(axis//3)].xy_widget.setValue(piezo_levels[axis],piezo_levels[axis+1])\n                elif axis % 3 == 1:\n                    self.position_widgets[(axis//3)].xy_widget.setValue(piezo_levels[axis-1],piezo_levels[axis])\n            if self.show_z_pos and axis % 3 == 2:\n                self.position_widgets[(axis//3)].z_bar.setValue(piezo_levels[axis])",
  "class DummyStage(Stage):\n    \"\"\"A stub stage for testing purposes, prints moves to the console.\"\"\"\n\n    def __init__(self):\n        super(DummyStage, self).__init__()\n        self.axis_names = ('x1', 'y1', 'z1', 'x2', 'y2', 'z2')\n        self.max_voltage_levels = [4095 for ch in range(len(self.axis_names))]\n        self._position = np.zeros((len(self.axis_names)), dtype=np.float64)\n        self.piezo_levels = [50,50,50,50,50,50]\n\n    def move(self, position, axis=None, relative=False):\n        def move_axis(position, axis):\n            if relative:\n                self._position[self.axis_names.index(axis)] += position\n            else:\n                self._position[self.axis_names.index(axis)] = position\n        self.set_axis_param(move_axis, position, axis)\n        #i = self.axis_names.index(axis)\n        #if relative:\n        #    self._position[i] += position\n        #else:\n        #    self._position[i] = position\n            # print \"stage now at\", self._position\n\n    #def move_rel(self, position, axis=None):\n    #    self.move(position, relative=True)\n\n    def get_position(self, axis=None):\n        return self.get_axis_param(lambda axis: self._position[self.axis_names.index(axis)], axis)\n\n    position = property(get_position)\n\n    def get_qt_ui(self):\n        return PiezoStageUI(self,show_z_pos=False)",
  "def __init__(self, unit='m'):\n        Instrument.__init__(self)\n        self.unit = unit",
  "def move(self, pos, axis=None, relative=False):\n        raise NotImplementedError(\"You must override move() in a Stage subclass\")",
  "def move_rel(self, position, axis=None):\n        \"\"\"Make a relative move, see move() with relative=True.\"\"\"\n        self.move(position, axis, relative=True)",
  "def move_axis(self, pos, axis, relative=False, **kwargs):\n        \"\"\"Move along one axis.\n        \n        This function moves only in one axis, by calling self.move with \n        appropriately generated values (i.e. it supplies all axes with position\n        instructions, but those not moving just get the current position).\n        \n        It's intended for use in stages that don't support single-axis moves.\"\"\"\n        if axis not in self.axis_names:\n            raise ValueError(\"{0} is not a valid axis, must be one of {1}\".format(axis, self.axis_names))\n\n        full_position = np.zeros((len(self.axis_names))) if relative else self.position\n        full_position[self.axis_names.index(axis)] = pos\n        self.move(full_position, relative=relative, **kwargs)",
  "def get_position(self, axis=None):\n        raise NotImplementedError(\"You must override get_position in a Stage subclass.\")",
  "def select_axis(self, iterable, axis):\n        \"\"\"Pick an element from a tuple, indexed by axis name.\"\"\"\n        assert axis in self.axis_names, ValueError(\"{0} is not a valid axis name.\".format(axis))\n        return iterable[self.axis_names.index(axis)]",
  "def _get_position_proxy(self):\n        \"\"\"Return self.get_position() (this is a convenience to avoid having\n        to redefine the position property every time you subclass - don't call\n        it directly)\"\"\"\n        return self.get_position()",
  "def is_moving(self, axes=None):\n        \"\"\"Returns True if any of the specified axes are in motion.\"\"\"\n        raise NotImplementedError(\"The is_moving method must be subclassed and implemented before it's any use!\")",
  "def wait_until_stopped(self, axes=None):\n        \"\"\"Block until the stage is no longer moving.\"\"\"\n        while self.is_moving(axes=axes):\n            time.sleep(0.01)",
  "def get_qt_ui(self):\n        if self.unit == 'm':\n            return StageUI(self)\n        elif self.unit == 'u':\n            return StageUI(self, stage_step_min=1E-3, stage_step_max=1000.0, default_step=1.0)\n        elif self.unit == 'step':\n            return StageUI(self, stage_step_min=1, stage_step_max=1000.0, default_step=1.0)\n        elif self.unit == 'deg':\n            return StageUI(self, stage_step_min=0.1, stage_step_max=360, default_step=1.0)\n        else:\n            self._logger.warn('Tried displaying a GUI for an unrecognised unit: %s' % self.unit)",
  "def get_axis_param(self, get_func, axis=None):\n        if axis is None:\n            return tuple(get_func(axis) for axis in self.axis_names)\n        elif isinstance(axis, collections.Sequence) and not isinstance(axis, str):\n            return tuple(get_func(ax) for ax in axis)\n        else:\n            return get_func(axis)",
  "def set_axis_param(self, set_func, value, axis=None):\n        if axis is None:\n            if isinstance(value, collections.Sequence):\n                tuple(set_func(v, axis) for v,axis in zip(value, self.axis_names))\n            else:\n                tuple(set_func(value, axis) for axis in self.axis_names)\n        elif isinstance(axis, collections.Sequence) and not isinstance(axis, str):\n            if isinstance(value, collections.Sequence):\n                tuple(set_func(v, ax) for v,ax in zip(value, axis))\n            else:\n                tuple(set_func(value, ax) for ax in axis)\n        else:\n            set_func(value, axis)",
  "def __init__(self):\n        super(PiezoStage, self).__init__()",
  "def get_piezo_level(self, axis=None):\n        \"\"\" Returns the voltage levels of the specified piezo axis. \"\"\"\n        raise NotImplementedError(\"You must override get_piezo_leveln in a Stage subclass.\")\n        if axis is None:\n            return [self.get_scanner_level(axis) for axis in self.axis_names]\n        else:\n            if axis not in self.axis_names:\n                raise ValueError(\"{0} is not a valid axis, must be one of {1}\".format(axis, self.axis_names))",
  "def set_piezo_level(self, level, axis):\n        \"\"\" Sets the voltage levels of the specified piezo axis. \"\"\"\n        raise NotImplementedError(\"You must override set_piezo_level in a Stage subclass.\")\n        if axis not in self.axis_names:\n            raise ValueError(\"{0} is not a valid axis, must be one of {1}\".format(axis, self.axis_names))",
  "def get_piezo_voltage(self, axis):\n        \"\"\" Returns the voltage of the specified piezo axis. \"\"\"\n        raise NotImplementedError(\"You must override get_piezo_voltage in a Stage subclass.\")",
  "def set_piezo_voltage(self, axis, voltage):\n        \"\"\" Sets the voltage of the specified piezo axis. \"\"\"\n        raise NotImplementedError(\"You must override set_piezo_voltage in a Stage subclass.\")",
  "def get_piezo_position(self, axis=None):\n        \"\"\" Returns the position of the specified piezo axis. \"\"\"\n        raise NotImplementedError(\"You must override get_piezo_position in a Stage subclass.\")",
  "def set_piezo_position(self, axis=None):\n        \"\"\" Sets the position of the specified piezo axis. \"\"\"\n        raise NotImplementedError(\"You must override set_piezo_position in a Stage subclass.\")",
  "def __init__(self, stage, parent=None, stage_step_min=1e-9, stage_step_max=1e-3, default_step=1e-6):\n        assert isinstance(stage, Stage), \"instrument must be a Stage\"\n        super(StageUI, self).__init__()\n        self.stage = stage\n        #self.setupUi(self)\n        self.step_size_values = step_size_dict(stage_step_min, stage_step_max,unit = self.stage.unit)\n        self.step_size = [self.step_size_values[list(self.step_size_values.keys())[0]] for axis in stage.axis_names]\n        self.update_ui[int].connect(self.update_positions)\n        self.update_ui[str].connect(self.update_positions)\n        self.create_axes_layout(default_step)\n        self.update_positions()",
  "def move_axis_absolute(self, position, axis):\n        self.stage.move(position, axis=axis, relative=False)\n        if type(axis) == str:\n            self.update_ui[str].emit(axis)\n        elif type(axis) == int:\n            self.update_ui[int].emit(axis)",
  "def move_axis_relative(self, index, axis, dir=1):\n        self.stage.move(dir * self.step_size[index], axis=axis, relative=True)\n        if type(axis) == str:\n            #    axis = QtCore.QString(axis)\n            self.update_ui[str].emit(axis)\n        elif type(axis) == int:\n            self.update_ui[int].emit(axis)",
  "def zero_all_axes(self, axes):\n        pass",
  "def create_axes_layout(self, default_step=1e-6, arrange_buttons='cross', rows=None):\n        \"\"\"Layout of the PyQt widgets for absolute and relative movement of all axis\n\n        :param default_step:\n        :param arrange_buttons: either 'cross' or 'stack'. If 'cross', assumes the stages axes are x,y,z movement,\n        placing the arrows in an intuitive cross pattern\n        :param rows: number of rows per column when distributing the QtWidgets\n        :return:\n        \"\"\"\n        if rows is None:\n            rows = np.ceil(np.sqrt(len(self.stage.axis_names)))\n        rows = int(rows)  # int is needed for the old_div and the modulo operations\n\n        uic.loadUi(os.path.join(os.path.dirname(__file__), 'stage.ui'), self)\n        self.update_pos_button.clicked.connect(partial(self.update_positions, None))\n        path = os.path.dirname(os.path.realpath(nplab.ui.__file__))\n        icon_size = QtCore.QSize(12, 12)\n        self.positions = []\n        self.set_positions = []\n        self.set_position_buttons = []\n        for i, ax in enumerate(self.stage.axis_names):\n            col = 4 * (i// rows)\n            position = QtWidgets.QLineEdit('', self)\n            position.setReadOnly(True)\n            self.positions.append(position)\n            set_position = QtWidgets.QLineEdit('0', self)\n            set_position.setMinimumWidth(40)\n            self.set_positions.append(set_position)\n            set_position_button = QtWidgets.QPushButton('', self)\n            set_position_button.setIcon(QtGui.QIcon(os.path.join(path, 'go.png')))\n            set_position_button.setIconSize(icon_size)\n            set_position_button.resize(icon_size)\n            set_position_button.clicked.connect(self.button_pressed)\n            self.set_position_buttons.append(set_position_button)\n            # for each stage axis add a label, a field for the current position,\n            # a field to set a new position and a button to set a new position ..\n            self.info_layout.addWidget(QtWidgets.QLabel(str(ax), self), i % rows, col)\n            self.info_layout.addWidget(position, i % rows, col + 1)\n            self.info_layout.addWidget(set_position, i % rows, col + 2)\n            self.info_layout.addWidget(set_position_button, i % rows, col + 3)\n\n            if i % rows == 0:\n                if arrange_buttons == 'cross':\n                    group = QtWidgets.QGroupBox('axes {0}'.format(1 + (i// rows)), self)\n                    layout = QtWidgets.QGridLayout()\n                    layout.setSpacing(3)\n                    group.setLayout(layout)\n                    self.axes_layout.addWidget(group, 0, i// rows)\n                    offset = 0\n                elif arrange_buttons == 'stack':\n                    layout = self.axes_layout\n                    offset = 7 * (i// rows)\n                else:\n                    raise ValueError('Unrecognised arrangment: %s' % arrange_buttons)\n\n            step_size_select = QtWidgets.QComboBox(self)\n            step_size_select.addItems(list(self.step_size_values.keys()))\n            step_size_select.activated[str].connect(partial(self.on_activated, i))\n            step_str = engineering_format(default_step, self.stage.unit)\n            step_index = list(self.step_size_values.keys()).index(step_str)\n            step_size_select.setCurrentIndex(step_index)\n            layout.addWidget(QtWidgets.QLabel(str(ax), self), i % rows, 5 + offset)\n            layout.addWidget(step_size_select, i % rows, 6 + offset)\n            if i % 3 == 0 and arrange_buttons == 'cross':\n                layout.addItem(QtWidgets.QSpacerItem(12, 0), 0, 4)\n\n            plus_button = QtWidgets.QPushButton('', self)\n            plus_button.clicked.connect(partial(self.move_axis_relative, i, ax, 1))\n            minus_button = QtWidgets.QPushButton('', self)\n            minus_button.clicked.connect(partial(self.move_axis_relative, i, ax, -1))\n            if arrange_buttons == 'cross':\n                if i % rows == 0:\n                    plus_button.setIcon(QtGui.QIcon(os.path.join(path, 'right.png')))\n                    minus_button.setIcon(QtGui.QIcon(os.path.join(path, 'left.png')))\n                    layout.addWidget(minus_button, 1, 0)\n                    layout.addWidget(plus_button, 1, 2)\n                elif i % rows == 1:\n                    plus_button.setIcon(QtGui.QIcon(os.path.join(path, 'up.png')))\n                    minus_button.setIcon(QtGui.QIcon(os.path.join(path, 'down.png')))\n                    layout.addWidget(plus_button, 0, 1)\n                    layout.addWidget(minus_button, 2, 1)\n                elif i % rows == 2:\n                    plus_button.setIcon(QtGui.QIcon(os.path.join(path, 'up.png')))\n                    minus_button.setIcon(QtGui.QIcon(os.path.join(path, 'down.png')))\n                    layout.addWidget(plus_button, 0, 3)\n                    layout.addWidget(minus_button, 2, 3)\n            elif arrange_buttons == 'stack':\n                plus_button.setIcon(QtGui.QIcon(os.path.join(path, 'right.png')))\n                minus_button.setIcon(QtGui.QIcon(os.path.join(path, 'left.png')))\n                layout.addWidget(minus_button, i % rows, 0 + offset)\n                layout.addWidget(plus_button, i % rows, 1 + offset)\n            else:\n                raise ValueError('Unrecognised arrangment: %s' % arrange_buttons)\n            plus_button.setIconSize(icon_size)\n            plus_button.resize(icon_size)\n            minus_button.setIconSize(icon_size)\n            minus_button.resize(icon_size)",
  "def button_pressed(self, *args, **kwargs):\n        sender = self.sender()\n        if sender in self.set_position_buttons:\n            index = self.set_position_buttons.index(sender)\n            axis = self.stage.axis_names[index]\n            position = float(self.set_positions[index].text())\n            self.move_axis_absolute(position, axis)",
  "def on_activated(self, index, value):\n        # print self.sender(), index, value\n        self.step_size[index] = self.step_size_values[value]",
  "def update_positions(self, axis=None):\n        if axis not in self.stage.axis_names:\n            axis = None\n        if axis is None:\n            for axis in self.stage.axis_names:\n                self.update_positions(axis=axis)\n        else:\n            i = self.stage.axis_names.index(axis)\n            try:\n                p = engineering_format(self.stage.position[i], base_unit=self.stage.unit, digits_of_precision=4)\n            except ValueError:\n                p = '0 m'\n            self.positions[i].setText(p)",
  "def __init__(self, stage, parent=None, stage_step_min=1e-9,\n                 stage_step_max=1e-3, default_step=1e-8,show_xy_pos=True,\n                 show_z_pos=True):\n        self.show_xy_pos = show_xy_pos\n        self.show_z_pos = show_z_pos\n        assert isinstance(stage, Stage), \"instrument must be a Stage\"\n        super(PiezoStageUI, self).__init__(stage, parent, stage_step_min, stage_step_max, default_step)",
  "def create_axes_layout(self, default_step=1e-8, stack_multiple_stages='horizontal'):\n        uic.loadUi(os.path.join(os.path.dirname(__file__), 'piezo_stage.ui'), self)\n        path = os.path.dirname(os.path.realpath(nplab.ui.__file__))\n        icon_size = QtCore.QSize(12, 12)\n        self.position_widgets = []\n        self.xy_positions = []\n        self.set_positions = []\n        self.set_position_buttons = []\n        for i, ax in enumerate(self.stage.axis_names):\n            col = 4 * (i// 3)\n            if i % 3 == 0:\n                # absolute position for different stages consisting of 3 axes\n                position_widget = XYZPositionWidget(self.stage.max_voltage_levels[(i//3)],\n                                                    self.stage.max_voltage_levels[(i//3)+1],\n                                                    self.stage.max_voltage_levels[(i//3)+2],\n                                                    show_xy_pos=self.show_xy_pos,\n                                                    show_z_pos=self.show_z_pos)\n                if self.show_xy_pos:\n                    xy_position = position_widget.xy_widget.crosshair\n                    xy_position.CrossHairMoved.connect(self.crosshair_moved)\n                    self.xy_positions.append(xy_position)\n\n                self.position_widgets.append(position_widget)\n\n                self.info_layout.addWidget(position_widget, 0, col,3,1)\n\n                # position control elements for different stages consisting of 3 axes, arranged in a grid layout\n                group = QtWidgets.QGroupBox('stage {0}'.format(1 + ((i// 3))), self)\n                layout = QtWidgets.QGridLayout()\n                layout.setSpacing(3)\n                group.setLayout(layout)\n                self.axes_layout.addWidget(group, 0, (i// 3))\n                zero_button = QtWidgets.QPushButton('', self)\n                zero_button.setIcon(QtGui.QIcon(os.path.join(path, 'zero.png')))\n                zero_button.setIconSize(icon_size)\n                zero_button.resize(icon_size)\n                n = len(self.stage.axis_names) - i if len(self.stage.axis_names) - i < 3 else 3\n                #axes_set = self.stage.axis_names[i:i + n]\n                #zero_button.clicked.connect(partial(self.zero_all_axes, axes_set))\n                layout.addWidget(zero_button, 1, 1)\n\n            set_position = QtWidgets.QLineEdit('0', self)   # text field to set position\n            set_position.setMinimumWidth(40)\n            set_position.setReadOnly(True)\n            self.set_positions.append(set_position)\n            set_position_button = QtWidgets.QPushButton('', self)\n            set_position_button.setIcon(QtGui.QIcon(os.path.join(path, 'go.png')))\n            set_position_button.setIconSize(icon_size)\n            set_position_button.resize(icon_size)\n            set_position_button.clicked.connect(self.button_pressed)\n            self.set_position_buttons.append(set_position_button)\n            # for each stage axis add a label, a field for the current position,\n            # a field to set a new position and a button to set a new position ..\n            self.info_layout.addWidget(QtWidgets.QLabel(str(ax), self), i % 3, col+1)\n            self.info_layout.addWidget(set_position, i % 3, col + 2)\n            self.info_layout.addWidget(set_position_button, i % 3, col + 3)\n\n            step_size_select = QtWidgets.QComboBox(self)\n            step_size_select.addItems(list(self.step_size_values.keys()))\n            step_size_select.activated[str].connect(partial(self.on_activated, i))\n            step_str = engineering_format(default_step, self.stage.unit)\n            step_index = list(self.step_size_values.keys()).index(step_str)\n            step_size_select.setCurrentIndex(step_index)\n            layout.addWidget(QtWidgets.QLabel(str(ax), self), i % 3, 5)\n            layout.addWidget(step_size_select, i % 3, 6)\n            if i % 3 == 0:\n                layout.addItem(QtWidgets.QSpacerItem(12, 0), 0, 4)\n\n            plus_button = QtWidgets.QPushButton('', self)\n            plus_button.clicked.connect(partial(self.move_axis_relative, i, ax, 1))\n            minus_button = QtWidgets.QPushButton('', self)\n            minus_button.clicked.connect(partial(self.move_axis_relative, i, ax, -1))\n            if i % 3 == 0:\n                plus_button.setIcon(QtGui.QIcon(os.path.join(path, 'right.png')))\n                minus_button.setIcon(QtGui.QIcon(os.path.join(path, 'left.png')))\n                layout.addWidget(minus_button, 1, 0)\n                layout.addWidget(plus_button, 1, 2)\n            elif i % 3 == 1:\n                plus_button.setIcon(QtGui.QIcon(os.path.join(path, 'up.png')))\n                minus_button.setIcon(QtGui.QIcon(os.path.join(path, 'down.png')))\n                layout.addWidget(plus_button, 0, 1)\n                layout.addWidget(minus_button, 2, 1)\n            elif i % 3 == 2:\n                plus_button.setIcon(QtGui.QIcon(os.path.join(path, 'up.png')))\n                minus_button.setIcon(QtGui.QIcon(os.path.join(path, 'down.png')))\n                layout.addWidget(plus_button, 0, 3)\n                layout.addWidget(minus_button, 2, 3)\n            plus_button.setIconSize(icon_size)\n            plus_button.resize(icon_size)\n            minus_button.setIconSize(icon_size)\n            minus_button.resize(icon_size)",
  "def crosshair_moved(self):\n        sender = self.sender()\n        if sender in self.xy_positions:\n            i = self.xy_positions.index(sender)\n            self.stage.set_piezo_level(self.xy_positions[i].pos()[0],i*3)\n            self.stage.set_piezo_level(self.xy_positions[i].pos()[1],i*3+1)",
  "def update_positions(self, axis=None):\n        piezo_levels = self.stage.piezo_levels\n        if axis is None:\n            for i in range(len(self.position_widgets)):\n                if self.show_xy_pos:\n                    self.position_widgets[i].xy_widget.setValue(piezo_levels[i*3],piezo_levels[i*3+1])\n                if self.show_z_pos:\n                    self.position_widgets[i].z_bar.setValue(piezo_levels[i*3+2])\n\n        else:\n            if self.show_xy_pos:\n                if axis % 3 == 0:\n                    self.position_widgets[(axis//3)].xy_widget.setValue(piezo_levels[axis],piezo_levels[axis+1])\n                elif axis % 3 == 1:\n                    self.position_widgets[(axis//3)].xy_widget.setValue(piezo_levels[axis-1],piezo_levels[axis])\n            if self.show_z_pos and axis % 3 == 2:\n                self.position_widgets[(axis//3)].z_bar.setValue(piezo_levels[axis])",
  "def __init__(self):\n        super(DummyStage, self).__init__()\n        self.axis_names = ('x1', 'y1', 'z1', 'x2', 'y2', 'z2')\n        self.max_voltage_levels = [4095 for ch in range(len(self.axis_names))]\n        self._position = np.zeros((len(self.axis_names)), dtype=np.float64)\n        self.piezo_levels = [50,50,50,50,50,50]",
  "def move(self, position, axis=None, relative=False):\n        def move_axis(position, axis):\n            if relative:\n                self._position[self.axis_names.index(axis)] += position\n            else:\n                self._position[self.axis_names.index(axis)] = position\n        self.set_axis_param(move_axis, position, axis)",
  "def get_position(self, axis=None):\n        return self.get_axis_param(lambda axis: self._position[self.axis_names.index(axis)], axis)",
  "def get_qt_ui(self):\n        return PiezoStageUI(self,show_z_pos=False)",
  "def move_axis(position, axis):\n            if relative:\n                self._position[self.axis_names.index(axis)] += position\n            else:\n                self._position[self.axis_names.index(axis)] = position",
  "class CameraStageMapper(Instrument, HasTraits):\n    \"\"\"\n    This class sits between a camera and a stage, allowing coordinate conversion.\n\n    Coordinate Systems\n    ------------------\n    We consider the centre of the image to be our current position, and give\n    the position of each pixel on the camera such that it would be brought to\n    the centre of the camera image by moving the stage to (-position).\n    \"\"\"\n    do_calibration = Button()\n    calibration_distance = Float(7, tooltip=\"Distance to move in each direction when calibrating, in um\")\n    camera_to_sample = Array(shape=(2,2))\n    do_autofocus = Button()\n    autofocus_range = Range(0., 100., 5.)\n    autofocus_step = Range(0., 10., 0.5)\n    autofocus_default_ranges = [np.arange(-5,5,0.5),np.arange(-1,1,0.2)]\n    frames_to_discard = Int(1)\n    settling_time = Float(0.2)\n    disable_live_view = True\n    traits_view = View(\n                    VGroup(\n                        Item(name=\"calibration_distance\"),\n                        Item(name=\"do_calibration\"),\n                        Item(name=\"autofocus_range\"),\n                        Item(name=\"autofocus_step\"),\n                        Item(name=\"do_autofocus\"),\n                        Item(name=\"camera_to_sample\"),\n                    ),\n                    title=\"Camera-Stage Mapper\",\n                )\n    def __init__(self, camera, stage):\n        super(CameraStageMapper, self).__init__()\n        self.camera = camera\n        self.stage = stage\n        self.camera_to_sample = np.identity(2)\n        self.camera_centre = (0.5,0.5)\n        self.camera.set_legacy_click_callback(self.move_to_camera_point)\n        self._action_lock = threading.Lock() #prevent us from doing two things involving motion at once!\n    \n    ############ Coordinate Conversion ##################\n    def camera_pixel_to_point(self, p):\n        \"\"\"convert pixel coordinates to point coordinates (normalised 0-1)\"\"\"\n        return old_div(np.array(p,dtype=float), \\\n                np.array(self.camera.latest_frame.shape[0:2], dtype=float))\n    def camera_point_to_pixel(self, p):\n        \"\"\"convert point coordinates (normalised 0-1) to pixel\"\"\"\n        return np.array(p)*np.array(self.camera.latest_frame.shape[0:2])\n    def camera_pixel_to_sample(self, p):\n        return self.camera_point_to_sample(self.camera_pixel_to_point(p))\n    def camera_point_to_sample(self, p):\n        displacement = np.dot(np.array(p) - np.array(self.camera_centre),\n                              self.camera_to_sample)\n        return self.camera_centre_position()[0:2] + displacement\n    def camera_point_displacement_to_sample(self, p):\n        \"\"\"Convert a displacement from camera point units to microns\"\"\"\n        return np.dot(np.array(p), self.camera_to_sample)\n    def camera_pixel_displacement_to_sample(self, p):\n        \"\"\"Convert from pixels to microns for relative moves\"\"\"\n        return self.camera_point_displacement_to_sample(self.camera_pixel_to_point(p))\n    \n    ############## Stage Control #####################\n    def move_to_camera_pixel(self, p):\n        \"\"\"bring the object at pixel p=(x,y) on the camera to the centre\"\"\"\n        return self.move_to_camera_point(*tuple(self.camera_pixel_to_point(p)))\n    def move_to_camera_point(self, x, y=None):\n        \"\"\"Move the stage to centre point (x,y) on the camera\n        \n        (x,y) is the position on the camera, where x,y range from 0 to 1\"\"\"\n        if y is None:\n            p=x\n        else:\n            p=(x,y)\n        displacement = np.dot(np.array(p) - np.array(self.camera_centre),\n                              self.camera_to_sample)\n        current_position = displacement +self.camera_centre_position()[0:2]\n        self.move_to_sample_position(current_position)\n\n    def move_to_sample_position(self, p):\n        \"\"\"Move the stage to centre sample position p on the camera\"\"\"\n        self.stage.move(-np.array(p))\n    \n    def camera_centre_position(self):\n        \"\"\"return the position of the centre of the camera view, on the sample\"\"\"\n        return -self.stage.position\n    \n    ################## Closed loop stage control #################\n    def centre_on_feature(self, feature_image, search_size=(50,50), tolerance=0.3, max_iterations=10, **kwargs):\n        \"\"\"Adjust the stage slightly to centre on the given feature.\n        \n        This should be called immediately after moving the stage to centre on a\n        feature in the image: first move the stage to bring that feature to the\n        centre, then call this function to fine-tune.\n        \n        Arguments\n        =========\n        * feature_image: an RGB image of a feature.  Must be\n        significantly smaller than the camera image.\n        * search_size: size of the area around the image centre to search, in\n        pixels.  Should be a tuple of length 2.\n        * tolerance: how accurately we're going to centre (in um)\n        * max_iterations: maximum number of shifts\n        \"\"\"\n        shift=[999.,999.]\n        n=0\n        if self.disable_live_view:\n            camera_live_view = self.camera.live_view\n            self.camera.live_view = False\n        while np.sqrt(np.sum(np.array(shift)**2))>tolerance and n<max_iterations:\n            n+=1\n            try:\n                shift=self.centre_on_feature_iterate(feature_image, \n                                                     search_size=search_size, \n                                                     **kwargs)\n                print(\"Centring on feature: moving by %.2f, %.2f\" % tuple(shift))\n            except:\n                print(\"Something went wrong with auto-centering - trying again.\") #don't worry, we incremented N so this won't go on forever!\n        if np.sqrt(np.sum(np.array(shift)**2))>tolerance:\n            print(\"Performed %d iterations but did not converge on the feature to within %.3fum\" % (n, tolerance))\n        else:\n            print(\"Centered on feature in %d iterations.\" % n)\n        if self.disable_live_view:\n            self.camera.live_view = camera_live_view #reenable live view if necessary\n    def centre_on_feature_iterate(self, feature_image, search_size=(50,50), image_filter=lambda x: x):\n        \"\"\"Measure the displacement of the sample and move to correct it.\n        \n        Arguments:\n        feature_image : numpy.ndarray\n            This is the feature that should be at the centre of the camera.  It\n            must be smaller than the camera image + search size.\n        search_size : (int, int)\n            The distance in pixels to search over.  Defaults to (50,50).\n        image_filter : function (optional)\n            If supplied, run this function on the image before cross-correlating\n            (you can use this to cross-correlate in grayscale, for example).\n        \"\"\"\n        try:\n            self.flush_camera_and_wait()\n            current_image = image_filter(self.camera.color_image()) #get the current image\n            corr = cv2.matchTemplate(current_image,feature_image,cv2.TM_SQDIFF_NORMED) #correlate them: NB the match position is the MINIMUM\n            #restrict to just the search area, and invert so we find the maximum\n            corr = -corr[(corr.shape[0]/2. - search_size[0]/2.):(corr.shape[0]/2. + search_size[0]/2.),\n                         (corr.shape[1]/2. - search_size[1]/2.):(corr.shape[1]/2. + search_size[1]/2.)] #invert the image so we can find a peak\n            corr += (corr.max()-corr.min())*0.1 - corr.max() #background-subtract 90% of maximum\n            corr = cv2.threshold(corr, 0, 0, cv2.THRESH_TOZERO)[1] #zero out any negative pixels - but there should always be > 0 nonzero pixels\n            peak = ndimage.measurements.center_of_mass(corr) #take the centroid (NB this is of grayscale values not just binary)\n            self.move_to_camera_pixel(np.array(peak) - np.array(corr.shape[0:2])/2.+np.array(current_image.shape[0:2])/2.)\n            return self.camera_pixel_displacement_to_sample(np.array(peak) - np.array(corr.shape[0:2])/2.)\n        except Exception as e:\n            print(\"Exception: \", e)\n            print(\"Corr: \", corr)\n            print(\"Feature: \", feature_image)\n            print(\"Feature Size: \", feature_image.shape)\n            print(\"Corr size: \", corr.shape)\n            print(\"Peak: \", peak)\n            print(\"sum(corr): \", np.sum(corr))\n            print(\"max(corr): \", np.max(corr))\n            raise e\n\n########## Calibration ###############\n    @on_trait_change(\"do_calibration\")\n    def calibrate_in_background(self):\n        threading.Thread(target=self.calibrate).start()\n    def calibrate(self, dx=None):\n        \"\"\"Move the stage in a square and set the transformation matrix.\"\"\"\n        with self._action_lock:\n            if dx is None: dx=self.calibration_distance #use a sensible default\n            here = self.camera_centre_position()\n            pos = [np.array([i,j,0]) for i in [-dx,dx] for j in [-dx,dx]]\n            camera_pos = []\n            self.camera.update_latest_frame() # make sure we've got a fresh image\n            initial_image = self.camera.gray_image()\n            w, h, = initial_image.shape\n            template = initial_image[old_div(w,4):old_div(3*w,4),old_div(h,4):old_div(3*h,4)] #.astype(np.float)\n            #template -= cv2.blur(template, (21,21), borderType=cv2.BORDER_REPLICATE)\n    #        self.calibration_template = template\n    #        self.calibration_images = []\n            camera_live_view = self.camera.live_view\n            if self.disable_live_view:\n                self.camera.live_view = False\n            for p in pos:\n                self.move_to_sample_position(here + p)\n                self.flush_camera_and_wait()\n                current_image = self.camera.gray_image()\n                corr = cv2.matchTemplate(current_image,template,cv2.TM_SQDIFF_NORMED)\n                corr *= -1. #invert the image\n                corr += (corr.max()-corr.min())*0.1 - corr.max() ##\n                corr = cv2.threshold(corr, 0, 0, cv2.THRESH_TOZERO)[1]\n    #            peak = np.unravel_index(corr.argmin(),corr.shape)\n                peak = ndimage.measurements.center_of_mass(corr)\n                camera_pos.append(peak - old_div((np.array(current_image.shape) - \\\n                                                       np.array(template.shape)),2))\n    #            self.calibration_images.append({\"image\":current_image,\"correlation\":corr,\"pos\":p,\"peak\":peak})\n            self.move_to_sample_position(here)\n            self.flush_camera_and_wait()#otherwise we get a worrying \"jump\" when enabling live view...\n            self.camera.live_view = camera_live_view\n            #camera_pos now contains the displacements in pixels for each move\n            sample_displacement = np.array([-p[0:2] for p in pos]) #nb need to convert to 2D, and the stage positioning is flipped from sample coords\n            camera_displacement = np.array([self.camera_pixel_to_point(p) for p in camera_pos])\n            print(\"sample was moved (in um):\\n\",sample_displacement)\n            print(\"the image shifted (in fractions-of-a-camera):\\n\",camera_displacement)\n            A, res, rank, s = np.linalg.lstsq(camera_displacement, sample_displacement)\n            self.camera_to_sample = A\n\n    def flush_camera_and_wait(self):\n        \"\"\"take and discard a number of images from the camera to make sure the image is fresh\n        \n        This functionality should really be in the camera, not the aligner!\"\"\"\n        time.sleep(self.settling_time)\n        for i in range(self.frames_to_discard):\n            self.camera.raw_image() #acquire, then discard, an image from the camera\n\n    ######## Image Tiling ############\n    def acquire_tiled_image(self, n_images=(3,3), dest=None, overlap=0.33,\n                            autofocus_args={},live_plot=False, downsample=8):\n        \"\"\"Raster-scan the stage and take images, which we can later tile.\n\n        Arguments:\n        @param: n_images: A tuple of length 2 specifying the number of images\n        to take in X and Y\n        @param: dest: An HDF5 Group object to store the images in.  Each image\n        will be tagged with metadata to mark where it was taken.  If no dest\n        is specified, a new group will be created in the current datafile.\n        @param: overlap: the fraction of each image to overlap with the \n        adjacent one (it's important this is high enough to match them up)\n        @param: autofocus_args: A dictionary of keyword arguments for the\n        autofocus that occurs before each image is taken.  Set to None to\n        disable autofocusing.\n        \"\"\"\n        reset_interactive_mode = live_plot and not matplotlib.is_interactive()\n        if live_plot:\n            plt.ion()\n            fig = plt.figure()\n            axes = fig.add_subplot(111)\n            axes.set_aspect(1)\n            \n        with self._action_lock:\n            if dest is None:\n                dest = self.create_data_group(\"tiled_image_%d\") #or should this be in RAM??\n            centre_position = self.camera_centre_position()[0:2] #only 2D\n            x_indices = np.arange(n_images[0]) - (n_images[0] - 1)/2.0\n            y_indices = np.arange(n_images[1]) - (n_images[1] - 1)/2.0\n            for y_index in y_indices:\n                for x_index in x_indices:\n                    position = centre_position + self.camera_point_displacement_to_sample(np.array([x_index, y_index]) * (1-overlap))\n                    self.move_to_sample_position(position) #go to the raster point\n                    if autofocus_args is not None:\n                        self.autofocus(**autofocus_args)\n                    self.flush_camera_and_wait() #wait for the camera to be ready/stage to settle\n                    tile = dest.create_dataset(\"tile_%d\", \n                                               data=self.camera.color_image(),\n                                               attrs=self.camera.metadata)\n                    tile.attrs.create(\"stage_position\",self.stage.position)\n                    tile.attrs.create(\"camera_centre_position\",self.camera_centre_position())\n                    if live_plot:\n                        #Plot the image, in sample coordinates\n                        corner_points = np.array([self.camera_point_to_sample((xcorner,ycorner)) \n                                                for ycorner in [0,1] for xcorner in [0,1]]) #positions of corners\n                        plot_skewed_image(tile[::downsample, ::downsample, :],\n                                          corner_points, axes=axes)\n                        fig.canvas.draw()\n                x_indices = x_indices[::-1] #reverse the X positions, so we do a snake-scan\n            dest.attrs.set(\"camera_to_sample\",self.camera_to_sample)\n            dest.attrs.set(\"camera_centre\",self.camera_centre)\n            self.move_to_sample_position(centre_position) #go back to the start point\n        if reset_interactive_mode:\n            plt.ioff()\n        return dest\n        \n    ######## Autofocus Stuff #########\n    def autofocus_merit_function(self): # we maximise this...\n        \"\"\"Take an image and calculate the focus metric, this is what we optimise.\n        \n        Currently, this calculates the sum of the square of the Laplacian of the image\n        which should pick out sharp features quite effectively.  It can, however, be\n        thrown off by very bright objects if the camera is saturated.\"\"\"\n        self.flush_camera_and_wait()\n#        self.camera.update_latest_frame() #take an extra frame to make sure this one is fresh\n        img = self.camera.raw_image()\n#        return np.sum((img - cv2.blur(img,(21,21))).astype(np.single)**2)\n        return np.sum(cv2.Laplacian(cv2.cvtColor(img,cv2.COLOR_BGR2GRAY), ddepth=cv2.CV_32F)**2)\n\n    @on_trait_change(\"do_autofocus\")\n    def autofocus_in_background(self):\n        def work():\n            self.autofocus_iterate(np.arange(old_div(-self.autofocus_range,2), old_div(self.autofocus_range,2), self.autofocus_step))\n        threading.Thread(target=work).start()\n    \n    def autofocus_iterate(self, dz, method=\"centre_of_mass\", noise_floor=0.3):\n        self._action_lock.acquire()\n        \"\"\"Move in z and take images.  Move to the sharpest position.\"\"\"\n        here = self.stage.position\n        positions = [here]                              #positions keeps track of where we sample\n        powers = [self.autofocus_merit_function()]      #powers holds the value of the merit fn at each point\n        camera_live_view = self.camera.live_view\n        if self.disable_live_view:\n            self.camera.live_view = False\n        for z in dz:\n            self.stage.move(np.array([0,0,z])+here)     #visit each point and evaluate merit function\n #           time.sleep(0.5)\n            positions.append(self.stage.position)\n            powers.append(self.autofocus_merit_function())\n        powers = np.array(powers)\n        positions = np.array(positions)\n        z = positions[:,2] \n        if method==\"centre_of_mass\":\n            threshold = powers.min() + (powers.max()-powers.min())*noise_floor #(powers.min() if len(powers)<4 else np.max([powers[z.argmin()],powers[z.argmax()]])) #ensure edges are zero\n            weights = powers - threshold\n            weights[weights<0] = 0. #zero out any negative values\n            if(np.sum(weights)==0): \n                new_position = positions[powers.argmax(),:]\n            else: \n                new_position = old_div(np.dot(weights, positions),np.sum(weights))\n        elif method==\"parabola\":\n            coefficients = np.polyfit(z, powers, deg=2) #fit a parabola\n            root = old_div(-coefficients[1],(2*coefficients[0])) #p = c[0]z**\" + c[1]z + c[2] which has max (or min) at 2c[0]z + c[1]=0 i.e. z=-c[1]/2c[0]\n            if z.min() < root and root < z.max():\n                new_position = [here[0],here[1],root]\n            else:\n                new_position = positions[powers.argmax(),:]\n        else:\n            new_position = positions[powers.argmax(),:]\n        self.stage.move(new_position)\n        self.camera.live_view = camera_live_view\n        self._action_lock.release()\n        return new_position-here, positions, powers\n\n    def autofocus(self, ranges=None, max_steps=10):\n        \"\"\"move the stage to bring the sample into focus\n        \n        Presently, it just does one iteration for each range passed in: usually\n        this would mean a coarse focus then a fine focus.\n        \"\"\" #NEEDS WORK!\n        if ranges is None:\n            ranges = self.autofocus_default_ranges\n        n=0\n        for r in ranges:\n            pos = self.autofocus_iterate(r)[0]\n            print(\"moving Z by %.3f\" % pos[2])\n            n+=1\n        print(\"Autofocus: performed %d iterations\" % n)",
  "def __init__(self, camera, stage):\n        super(CameraStageMapper, self).__init__()\n        self.camera = camera\n        self.stage = stage\n        self.camera_to_sample = np.identity(2)\n        self.camera_centre = (0.5,0.5)\n        self.camera.set_legacy_click_callback(self.move_to_camera_point)\n        self._action_lock = threading.Lock()",
  "def camera_pixel_to_point(self, p):\n        \"\"\"convert pixel coordinates to point coordinates (normalised 0-1)\"\"\"\n        return old_div(np.array(p,dtype=float), \\\n                np.array(self.camera.latest_frame.shape[0:2], dtype=float))",
  "def camera_point_to_pixel(self, p):\n        \"\"\"convert point coordinates (normalised 0-1) to pixel\"\"\"\n        return np.array(p)*np.array(self.camera.latest_frame.shape[0:2])",
  "def camera_pixel_to_sample(self, p):\n        return self.camera_point_to_sample(self.camera_pixel_to_point(p))",
  "def camera_point_to_sample(self, p):\n        displacement = np.dot(np.array(p) - np.array(self.camera_centre),\n                              self.camera_to_sample)\n        return self.camera_centre_position()[0:2] + displacement",
  "def camera_point_displacement_to_sample(self, p):\n        \"\"\"Convert a displacement from camera point units to microns\"\"\"\n        return np.dot(np.array(p), self.camera_to_sample)",
  "def camera_pixel_displacement_to_sample(self, p):\n        \"\"\"Convert from pixels to microns for relative moves\"\"\"\n        return self.camera_point_displacement_to_sample(self.camera_pixel_to_point(p))",
  "def move_to_camera_pixel(self, p):\n        \"\"\"bring the object at pixel p=(x,y) on the camera to the centre\"\"\"\n        return self.move_to_camera_point(*tuple(self.camera_pixel_to_point(p)))",
  "def move_to_camera_point(self, x, y=None):\n        \"\"\"Move the stage to centre point (x,y) on the camera\n        \n        (x,y) is the position on the camera, where x,y range from 0 to 1\"\"\"\n        if y is None:\n            p=x\n        else:\n            p=(x,y)\n        displacement = np.dot(np.array(p) - np.array(self.camera_centre),\n                              self.camera_to_sample)\n        current_position = displacement +self.camera_centre_position()[0:2]\n        self.move_to_sample_position(current_position)",
  "def move_to_sample_position(self, p):\n        \"\"\"Move the stage to centre sample position p on the camera\"\"\"\n        self.stage.move(-np.array(p))",
  "def camera_centre_position(self):\n        \"\"\"return the position of the centre of the camera view, on the sample\"\"\"\n        return -self.stage.position",
  "def centre_on_feature(self, feature_image, search_size=(50,50), tolerance=0.3, max_iterations=10, **kwargs):\n        \"\"\"Adjust the stage slightly to centre on the given feature.\n        \n        This should be called immediately after moving the stage to centre on a\n        feature in the image: first move the stage to bring that feature to the\n        centre, then call this function to fine-tune.\n        \n        Arguments\n        =========\n        * feature_image: an RGB image of a feature.  Must be\n        significantly smaller than the camera image.\n        * search_size: size of the area around the image centre to search, in\n        pixels.  Should be a tuple of length 2.\n        * tolerance: how accurately we're going to centre (in um)\n        * max_iterations: maximum number of shifts\n        \"\"\"\n        shift=[999.,999.]\n        n=0\n        if self.disable_live_view:\n            camera_live_view = self.camera.live_view\n            self.camera.live_view = False\n        while np.sqrt(np.sum(np.array(shift)**2))>tolerance and n<max_iterations:\n            n+=1\n            try:\n                shift=self.centre_on_feature_iterate(feature_image, \n                                                     search_size=search_size, \n                                                     **kwargs)\n                print(\"Centring on feature: moving by %.2f, %.2f\" % tuple(shift))\n            except:\n                print(\"Something went wrong with auto-centering - trying again.\") #don't worry, we incremented N so this won't go on forever!\n        if np.sqrt(np.sum(np.array(shift)**2))>tolerance:\n            print(\"Performed %d iterations but did not converge on the feature to within %.3fum\" % (n, tolerance))\n        else:\n            print(\"Centered on feature in %d iterations.\" % n)\n        if self.disable_live_view:\n            self.camera.live_view = camera_live_view",
  "def centre_on_feature_iterate(self, feature_image, search_size=(50,50), image_filter=lambda x: x):\n        \"\"\"Measure the displacement of the sample and move to correct it.\n        \n        Arguments:\n        feature_image : numpy.ndarray\n            This is the feature that should be at the centre of the camera.  It\n            must be smaller than the camera image + search size.\n        search_size : (int, int)\n            The distance in pixels to search over.  Defaults to (50,50).\n        image_filter : function (optional)\n            If supplied, run this function on the image before cross-correlating\n            (you can use this to cross-correlate in grayscale, for example).\n        \"\"\"\n        try:\n            self.flush_camera_and_wait()\n            current_image = image_filter(self.camera.color_image()) #get the current image\n            corr = cv2.matchTemplate(current_image,feature_image,cv2.TM_SQDIFF_NORMED) #correlate them: NB the match position is the MINIMUM\n            #restrict to just the search area, and invert so we find the maximum\n            corr = -corr[(corr.shape[0]/2. - search_size[0]/2.):(corr.shape[0]/2. + search_size[0]/2.),\n                         (corr.shape[1]/2. - search_size[1]/2.):(corr.shape[1]/2. + search_size[1]/2.)] #invert the image so we can find a peak\n            corr += (corr.max()-corr.min())*0.1 - corr.max() #background-subtract 90% of maximum\n            corr = cv2.threshold(corr, 0, 0, cv2.THRESH_TOZERO)[1] #zero out any negative pixels - but there should always be > 0 nonzero pixels\n            peak = ndimage.measurements.center_of_mass(corr) #take the centroid (NB this is of grayscale values not just binary)\n            self.move_to_camera_pixel(np.array(peak) - np.array(corr.shape[0:2])/2.+np.array(current_image.shape[0:2])/2.)\n            return self.camera_pixel_displacement_to_sample(np.array(peak) - np.array(corr.shape[0:2])/2.)\n        except Exception as e:\n            print(\"Exception: \", e)\n            print(\"Corr: \", corr)\n            print(\"Feature: \", feature_image)\n            print(\"Feature Size: \", feature_image.shape)\n            print(\"Corr size: \", corr.shape)\n            print(\"Peak: \", peak)\n            print(\"sum(corr): \", np.sum(corr))\n            print(\"max(corr): \", np.max(corr))\n            raise e",
  "def calibrate_in_background(self):\n        threading.Thread(target=self.calibrate).start()",
  "def calibrate(self, dx=None):\n        \"\"\"Move the stage in a square and set the transformation matrix.\"\"\"\n        with self._action_lock:\n            if dx is None: dx=self.calibration_distance #use a sensible default\n            here = self.camera_centre_position()\n            pos = [np.array([i,j,0]) for i in [-dx,dx] for j in [-dx,dx]]\n            camera_pos = []\n            self.camera.update_latest_frame() # make sure we've got a fresh image\n            initial_image = self.camera.gray_image()\n            w, h, = initial_image.shape\n            template = initial_image[old_div(w,4):old_div(3*w,4),old_div(h,4):old_div(3*h,4)] #.astype(np.float)\n            #template -= cv2.blur(template, (21,21), borderType=cv2.BORDER_REPLICATE)\n    #        self.calibration_template = template\n    #        self.calibration_images = []\n            camera_live_view = self.camera.live_view\n            if self.disable_live_view:\n                self.camera.live_view = False\n            for p in pos:\n                self.move_to_sample_position(here + p)\n                self.flush_camera_and_wait()\n                current_image = self.camera.gray_image()\n                corr = cv2.matchTemplate(current_image,template,cv2.TM_SQDIFF_NORMED)\n                corr *= -1. #invert the image\n                corr += (corr.max()-corr.min())*0.1 - corr.max() ##\n                corr = cv2.threshold(corr, 0, 0, cv2.THRESH_TOZERO)[1]\n    #            peak = np.unravel_index(corr.argmin(),corr.shape)\n                peak = ndimage.measurements.center_of_mass(corr)\n                camera_pos.append(peak - old_div((np.array(current_image.shape) - \\\n                                                       np.array(template.shape)),2))\n    #            self.calibration_images.append({\"image\":current_image,\"correlation\":corr,\"pos\":p,\"peak\":peak})\n            self.move_to_sample_position(here)\n            self.flush_camera_and_wait()#otherwise we get a worrying \"jump\" when enabling live view...\n            self.camera.live_view = camera_live_view\n            #camera_pos now contains the displacements in pixels for each move\n            sample_displacement = np.array([-p[0:2] for p in pos]) #nb need to convert to 2D, and the stage positioning is flipped from sample coords\n            camera_displacement = np.array([self.camera_pixel_to_point(p) for p in camera_pos])\n            print(\"sample was moved (in um):\\n\",sample_displacement)\n            print(\"the image shifted (in fractions-of-a-camera):\\n\",camera_displacement)\n            A, res, rank, s = np.linalg.lstsq(camera_displacement, sample_displacement)\n            self.camera_to_sample = A",
  "def flush_camera_and_wait(self):\n        \"\"\"take and discard a number of images from the camera to make sure the image is fresh\n        \n        This functionality should really be in the camera, not the aligner!\"\"\"\n        time.sleep(self.settling_time)\n        for i in range(self.frames_to_discard):\n            self.camera.raw_image()",
  "def acquire_tiled_image(self, n_images=(3,3), dest=None, overlap=0.33,\n                            autofocus_args={},live_plot=False, downsample=8):\n        \"\"\"Raster-scan the stage and take images, which we can later tile.\n\n        Arguments:\n        @param: n_images: A tuple of length 2 specifying the number of images\n        to take in X and Y\n        @param: dest: An HDF5 Group object to store the images in.  Each image\n        will be tagged with metadata to mark where it was taken.  If no dest\n        is specified, a new group will be created in the current datafile.\n        @param: overlap: the fraction of each image to overlap with the \n        adjacent one (it's important this is high enough to match them up)\n        @param: autofocus_args: A dictionary of keyword arguments for the\n        autofocus that occurs before each image is taken.  Set to None to\n        disable autofocusing.\n        \"\"\"\n        reset_interactive_mode = live_plot and not matplotlib.is_interactive()\n        if live_plot:\n            plt.ion()\n            fig = plt.figure()\n            axes = fig.add_subplot(111)\n            axes.set_aspect(1)\n            \n        with self._action_lock:\n            if dest is None:\n                dest = self.create_data_group(\"tiled_image_%d\") #or should this be in RAM??\n            centre_position = self.camera_centre_position()[0:2] #only 2D\n            x_indices = np.arange(n_images[0]) - (n_images[0] - 1)/2.0\n            y_indices = np.arange(n_images[1]) - (n_images[1] - 1)/2.0\n            for y_index in y_indices:\n                for x_index in x_indices:\n                    position = centre_position + self.camera_point_displacement_to_sample(np.array([x_index, y_index]) * (1-overlap))\n                    self.move_to_sample_position(position) #go to the raster point\n                    if autofocus_args is not None:\n                        self.autofocus(**autofocus_args)\n                    self.flush_camera_and_wait() #wait for the camera to be ready/stage to settle\n                    tile = dest.create_dataset(\"tile_%d\", \n                                               data=self.camera.color_image(),\n                                               attrs=self.camera.metadata)\n                    tile.attrs.create(\"stage_position\",self.stage.position)\n                    tile.attrs.create(\"camera_centre_position\",self.camera_centre_position())\n                    if live_plot:\n                        #Plot the image, in sample coordinates\n                        corner_points = np.array([self.camera_point_to_sample((xcorner,ycorner)) \n                                                for ycorner in [0,1] for xcorner in [0,1]]) #positions of corners\n                        plot_skewed_image(tile[::downsample, ::downsample, :],\n                                          corner_points, axes=axes)\n                        fig.canvas.draw()\n                x_indices = x_indices[::-1] #reverse the X positions, so we do a snake-scan\n            dest.attrs.set(\"camera_to_sample\",self.camera_to_sample)\n            dest.attrs.set(\"camera_centre\",self.camera_centre)\n            self.move_to_sample_position(centre_position) #go back to the start point\n        if reset_interactive_mode:\n            plt.ioff()\n        return dest",
  "def autofocus_merit_function(self): # we maximise this...\n        \"\"\"Take an image and calculate the focus metric, this is what we optimise.\n        \n        Currently, this calculates the sum of the square of the Laplacian of the image\n        which should pick out sharp features quite effectively.  It can, however, be\n        thrown off by very bright objects if the camera is saturated.\"\"\"\n        self.flush_camera_and_wait()\n#        self.camera.update_latest_frame() #take an extra frame to make sure this one is fresh\n        img = self.camera.raw_image()\n#        return np.sum((img - cv2.blur(img,(21,21))).astype(np.single)**2)\n        return np.sum(cv2.Laplacian(cv2.cvtColor(img,cv2.COLOR_BGR2GRAY), ddepth=cv2.CV_32F)**2)",
  "def autofocus_in_background(self):\n        def work():\n            self.autofocus_iterate(np.arange(old_div(-self.autofocus_range,2), old_div(self.autofocus_range,2), self.autofocus_step))\n        threading.Thread(target=work).start()",
  "def autofocus_iterate(self, dz, method=\"centre_of_mass\", noise_floor=0.3):\n        self._action_lock.acquire()\n        \"\"\"Move in z and take images.  Move to the sharpest position.\"\"\"\n        here = self.stage.position\n        positions = [here]                              #positions keeps track of where we sample\n        powers = [self.autofocus_merit_function()]      #powers holds the value of the merit fn at each point\n        camera_live_view = self.camera.live_view\n        if self.disable_live_view:\n            self.camera.live_view = False\n        for z in dz:\n            self.stage.move(np.array([0,0,z])+here)     #visit each point and evaluate merit function\n #           time.sleep(0.5)\n            positions.append(self.stage.position)\n            powers.append(self.autofocus_merit_function())\n        powers = np.array(powers)\n        positions = np.array(positions)\n        z = positions[:,2] \n        if method==\"centre_of_mass\":\n            threshold = powers.min() + (powers.max()-powers.min())*noise_floor #(powers.min() if len(powers)<4 else np.max([powers[z.argmin()],powers[z.argmax()]])) #ensure edges are zero\n            weights = powers - threshold\n            weights[weights<0] = 0. #zero out any negative values\n            if(np.sum(weights)==0): \n                new_position = positions[powers.argmax(),:]\n            else: \n                new_position = old_div(np.dot(weights, positions),np.sum(weights))\n        elif method==\"parabola\":\n            coefficients = np.polyfit(z, powers, deg=2) #fit a parabola\n            root = old_div(-coefficients[1],(2*coefficients[0])) #p = c[0]z**\" + c[1]z + c[2] which has max (or min) at 2c[0]z + c[1]=0 i.e. z=-c[1]/2c[0]\n            if z.min() < root and root < z.max():\n                new_position = [here[0],here[1],root]\n            else:\n                new_position = positions[powers.argmax(),:]\n        else:\n            new_position = positions[powers.argmax(),:]\n        self.stage.move(new_position)\n        self.camera.live_view = camera_live_view\n        self._action_lock.release()\n        return new_position-here, positions, powers",
  "def autofocus(self, ranges=None, max_steps=10):\n        \"\"\"move the stage to bring the sample into focus\n        \n        Presently, it just does one iteration for each range passed in: usually\n        this would mean a coarse focus then a fine focus.\n        \"\"\" #NEEDS WORK!\n        if ranges is None:\n            ranges = self.autofocus_default_ranges\n        n=0\n        for r in ranges:\n            pos = self.autofocus_iterate(r)[0]\n            print(\"moving Z by %.3f\" % pos[2])\n            n+=1\n        print(\"Autofocus: performed %d iterations\" % n)",
  "def work():\n            self.autofocus_iterate(np.arange(old_div(-self.autofocus_range,2), old_div(self.autofocus_range,2), self.autofocus_step))",
  "class fake_stage(Stage):\n    def move(self,a,axis = 1,relative = False):\n        print(a)\n    def get_position(self):\n        return 0",
  "class piezoconcept_thorlabsMSL02_wrapper(Stage):\n    axis_names = ('x','y','z')\n    def __init__(self,no_z = False):\n        self.xy = DC_APT.get_instance()\n        self.unit = 'u'\n        if no_z:\n            self.z = fake_stage()  \n        else:\n            self.z = Piezoconcept.get_instance()\n        \n    def get_position(self):\n        return np.append(self.xy.position,self.z.position)\n  #  postion = property(get_position)\n    def move(self, x,axis=None, relative=False, block=True):\n        \"\"\" move wrapper\n\n        \"\"\"\n        print('move command' ,x,axis,relative)\n        if axis == None:\n            if len(x)==3:\n                self.z.move(x[2],relative = relative)\n                try:\n                    self.xy.move(x[:2],relative = relative,block = block)\n                except Exception as e:\n                    print(e)\n                    self.xy.move(x[:2],relative = relative,block = block)\n            elif len(x)==2:\n                try:\n                    self.xy.move(x,relative = relative,block = block)\n                except Exception as e:\n                    print(e)\n                    self.xy.move(x[:2],relative = relative,block = block)\n        if axis in self.axis_names:\n            if axis=='x' or axis=='y':\n                self.xy.move(x,axis = axis,relative = relative)\n            if axis == 'z':\n                self.z.move(x,relative = relative)",
  "def move(self,a,axis = 1,relative = False):\n        print(a)",
  "def get_position(self):\n        return 0",
  "def __init__(self,no_z = False):\n        self.xy = DC_APT.get_instance()\n        self.unit = 'u'\n        if no_z:\n            self.z = fake_stage()  \n        else:\n            self.z = Piezoconcept.get_instance()",
  "def get_position(self):\n        return np.append(self.xy.position,self.z.position)",
  "def move(self, x,axis=None, relative=False, block=True):\n        \"\"\" move wrapper\n\n        \"\"\"\n        print('move command' ,x,axis,relative)\n        if axis == None:\n            if len(x)==3:\n                self.z.move(x[2],relative = relative)\n                try:\n                    self.xy.move(x[:2],relative = relative,block = block)\n                except Exception as e:\n                    print(e)\n                    self.xy.move(x[:2],relative = relative,block = block)\n            elif len(x)==2:\n                try:\n                    self.xy.move(x,relative = relative,block = block)\n                except Exception as e:\n                    print(e)\n                    self.xy.move(x[:2],relative = relative,block = block)\n        if axis in self.axis_names:\n            if axis=='x' or axis=='y':\n                self.xy.move(x,axis = axis,relative = relative)\n            if axis == 'z':\n                self.z.move(x,relative = relative)",
  "def bytes_to_binary(bytearr, debug=0):\n    '''\n    Helper method for converting a bytearray datatype to a binary representation\n    '''\n    if debug > 0:\n        print(bytearr)\n    bytes_as_binary = [format(int(b, base=16), \"#06b\").replace(\n        \"0b\", \"\") for b in bytearr]\n    if debug > 0:\n        print(bytes_as_binary)\n    binary = \"\".join(bytes_as_binary)\n    return binary",
  "def twos_complement_to_int(binary, debug=0):\n    '''\n    Compute 2s complement of binary number representation\n    '''\n    if debug > 0:\n        print(binary)\n    N = len(binary)\n    a_N = int(binary[0])\n    return float(-a_N*2**(N-1) + int(binary[1:], base=2))",
  "def int_to_hex(integer, padded_length=8, debug=0):\n    '''\n    Convert integer number to hexidecimal. Return value is zero-padded at the beginning\n    until its length matches the value passed in \"padded_length\"\n    '''\n    outp = (format(integer, \"#0{}x\".format(\n        padded_length+2)).replace(\"0x\", \"\")).upper()\n    return outp",
  "def int_to_twos_complement(integer, padded_length=16, debug=0):\n    '''\n    Two's complement in integer representation. Padded length specifies the padding on the \n    binary representation used to compute the twos complement\n    '''\n    # number is above 0 - return binary representation:\n    if integer >= 0:\n        return integer\n\n    # number is below zero - return twos complement representation:\n    elif integer < 0:\n        if debug > 0:\n            print(\"Below zero - returning twos complement\")\n        integer = -1*integer\n        binary = format(integer, \"0{}b\".format(\n            padded_length+2)).replace(\"0b\", \"\")\n        ones_complement = [str(1-int(b)) for b in str(binary)]\n        ones_complement = int(\"\".join(ones_complement))\n        twos_complement = int(\"0b\"+str(ones_complement), base=2) + 1\n        twos_complement = format(twos_complement, \"034b\").replace(\"0b\", \"\")\n        if debug > 0:\n            print(\"input:\", integer)\n            print(\"binary:\", binary)\n            print(\"ones comp:\", ones_complement)\n            print(\"twos comp (int):\", int(twos_complement, base=2))\n        return int(\"0b\"+twos_complement, base=2)",
  "class Thorlabs_ELL8K(Stage):\n\n    # default id is 0, but if multiple devices of same type connected may have others\n    VALID_DEVICE_IDs = [str(v) for v in list(\n        range(0, 11)) + [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\"]]\n\n    # How much a stage sleeps (in seconds) between successive calls to .get_position.\n    # Used to make blocking calls to move_absolute and move_relative.\n    BLOCK_SLEEPING_TIME = 0.1\n    # Theshold for position accuracy when stage is meant to be stationary\n    # If difference between successive calls to get_position returns value\n    # whose difference is less than jitter - consider stage to have stopped\n    POSITION_JITTER_THRESHOLD = 0.02\n\n    # human readable status codes\n    DEVICE_STATUS_CODES = {\n        0: \"OK, no error\",\n        1: \"Communication Timeout\",\n        2: \"Mechanical time out\",\n        3: \"Command error or not supported\",\n        4: \"Value out of range\",\n        5: \"Module isolated\",\n        6: \"Module out of isolation\",\n        7: \"Initialization error\",\n        8: \"Thermal error\",\n        9: \"Busy\",\n        10: \"Sensor Error\",\n        11: \"Motor Error\",\n        12: \"Out of Range\",\n        13: \"Over current error\",\n        14: \"OK, no error\",\n        \"OutOfBounds\": \"Reserved\"\n    }\n\n    def __init__(self, serial_device, device_index=0, debug=0):\n        '''can be passed either a BusDistributor instance, or  \"COM5\"  '''\n        if type(serial_device) is str:\n            self.serial_device = BusDistributor(serial_device)\n        else:\n            self.serial_device = serial_device\n        self.debug = debug\n\n        Stage.__init__(self)\n        self.ui = None\n\n        # configure stage parameters\n        if str(device_index) not in Thorlabs_ELL8K.VALID_DEVICE_IDs:\n            raise ValueError(\n                \"Device ID: {} is not valid!\".format(device_index))\n        self.device_index = device_index\n\n        configuration = self.get_device_info()\n        self.TRAVEL = configuration[\"travel\"]\n        self.PULSES_PER_REVOLUTION = configuration[\"pulses\"]\n\n        if self.debug > 0:\n            print(\"Travel (degrees):\", self.TRAVEL)\n            print(\"Pulses per revolution\", self.PULSES_PER_REVOLUTION)\n            print(\"Device status:\", self.get_device_status())\n\n    def query_device(self, query):\n        '''\n        Wrap a generic query with the ID of the device (integer in range: 0-F)\n        so that we dont need to be explicit about this id\n        '''\n        raw_query = \"{0}{1}\".format(self.device_index, query)\n        if self.debug > 0:\n            print(\"raw_query\", raw_query)\n        raw_response = self.serial_device.query(raw_query)\n        if self.debug > 0:\n            print(\"raw_response\", raw_response)\n        return raw_response\n\n    def __angle_to_pulse_count(self, angle):\n        '''\n        Convert from an angle (specified in degrees) into the number of pulses\n        that need to be applied to the motor to turn it. \n\n        pulses_per_revolution - specified by Thorlabs as number of pulses for a revolution (360 deg) of stage\n        travel - the maximum angular motion of stage (==360 for ELL8K)\n\n        Method used when sending instructions to move to stage\n        '''\n        pulse_per_deg = self.PULSES_PER_REVOLUTION/float(self.TRAVEL)\n        pulses = int(np.rint(angle*pulse_per_deg))\n        if self.debug > 0:\n            print(\"Input angle:\", angle)\n            print(\"Pulses:\", pulses)\n        return pulses\n\n    def __pulse_count_to_angle(self, pulse_count):\n        '''\n        Convert from an pulse count into the degrees. \n\n        pulses_per_revolution - specified by Thorlabs as number of pulses for a revolution (360 deg) of stage\n        travel - the maximum angular motion of stage (==360 for ELL8K)\n\n        Method used when reading data received from stage\n        '''\n        return float(self.TRAVEL)*pulse_count/self.PULSES_PER_REVOLUTION\n\n    def __angle_to_hex_pulses(self, angle):\n        '''\n        Convert angle in range (-360.0,360.0) (exclusive of edges) into a hex representation of pulse\n        count required for talking to the ELL8K stage\n\n        '''\n        if angle < -360.0 or angle > 360.0:\n            raise ValueError(\"Valid angle bounds are: (-360,360) [exclusive]\")\n\n        # convert angle to number of pulses used to drive motors:\n        pulses_int = self.__angle_to_pulse_count(angle)\n        if self.debug > 0:\n            print(\"Pulses (int)\", pulses_int)\n        # make two's complement to allow for -ve values\n        pulses_int = int_to_twos_complement(pulses_int)\n        if self.debug > 0:\n            print(\"Pulses (int,2s compl)\", pulses_int)\n        # convert integer to hex\n        pulses_hex = int_to_hex(pulses_int)\n        if self.debug > 0:\n            print(\"Pulses hex:\", pulses_hex)\n        return pulses_hex\n\n    def __hex_pulses_to_angle(self, hex_pulse_position):\n        '''\n        Convert position to angle - full method for processing responses from stage\n        '''\n        binary_pulse_position = bytes_to_binary(hex_pulse_position)\n        int_pulse_position = twos_complement_to_int(binary_pulse_position)\n        return self.__pulse_count_to_angle(int_pulse_position)\n\n    def __decode_position_response(self, response):\n        '''\n        Method for decoding positional response from stage for responses from:\n            mode_absolute, mode_relative, move_home\n        '''\n        header = response[0:3]\n        if header == \"{0}GS\".format(self.device_index):\n            # still moving\n            status_code = int(response[3:5], base=16)\n            status = Thorlabs_ELL8K.DEVICE_STATUS_CODES[status_code]\n            outp = {\"header\": header, \"status\": status}\n            return outp\n        elif header == \"{0}PO\".format(self.device_index):\n            hex_pulse_position = response[3:11]\n            position = self.__hex_pulses_to_angle(hex_pulse_position)\n            outp = {\"header\": header, \"position\": position}\n            return outp\n\n    def __block_until_stopped(self):\n        '''\n        Method for blocking move_absolute and move_relative and move_home commands until stage has stopped\n        Spins on get_position command comparing returned results. If between two calls position doesn't change\n        Then assume stage has stopped and exit\n        '''\n        stopped = False\n        previous_angle = 0.0\n        current_angle = 1.0\n\n        try:\n            while(stopped == False):\n                time.sleep(Thorlabs_ELL8K.BLOCK_SLEEPING_TIME)\n                current_angle = self.get_position()\n                stopped = (np.absolute(current_angle - previous_angle)\n                           < Thorlabs_ELL8K.POSITION_JITTER_THRESHOLD)\n                previous_angle = current_angle\n        except KeyboardInterrupt:\n            return\n        return\n\n    def get_position(self, axis=None):\n        '''\n        Query stage for its current position, in degrees\n        This method overrides the Stage class' method\n        '''\n        response = self.query_device(\"gp\")\n        header = response[0:3]\n        if header == \"{0}PO\".format(self.device_index):\n            # position given in twos complement representation\n            byte_position = response[3:11]\n            binary_position = bytes_to_binary(byte_position)\n            pulse_position = twos_complement_to_int(binary_position)\n            degrees_position = self.TRAVEL * \\\n                (float(pulse_position)/self.PULSES_PER_REVOLUTION)\n            return degrees_position\n        else:\n            raise ValueError(\"Incompatible Header received:{}\".format(header))\n\n    def move(self, pos, axis=None, relative=False):\n        '''\n        Send command to move stage.\n        pos:  specified in degrees and can be in range (-360,360)\n        relative: whether motion is relative to current position or relative to global home\n        This method overrides the Stage class' method\n        '''\n        if relative:\n            self.move_relative(pos)\n        else:\n            self.move_absolute(pos)\n\n    def get_qt_ui(self):\n        '''\n        Get UI for stage\n        '''\n        if self.ui is None:\n            self.ui = Thorlabs_ELL8K_UI(stage=self)\n        return self.ui\n\n    def get_device_info(self):\n        '''\n        Instruct hardware to identify itself. \n        Give information about model, serial numbner, firmware. \n\n        This MUST be called at initialization of the stage as the key parameters:\n\n        TRAVEL, PULSES are extracted here\n\n        TRAVEL - the range of travel of the stage, specified in units (mm or deg) relevant to the type of stage\n        PULSES - specifieid the number of pulses applied to motors to move stage over entire range of travel\n\n        Hence: ratio of PULSES/TRAVEL gives number of pulses to move 1 mm or 1 deg\n        '''\n\n        response = self.query_device(\"in\")\n\n        # decode the response\n        header = response[0:3]\n        ell = response[3:5]\n        sn = response[5:13]\n        year = response[13:17]\n        firmware_release = response[17:19]\n        hardware_release = response[19:21]\n\n        bytes_travel = response[21:25]  # units: mm/deg\n\n        binary_travel = bytes_to_binary(bytes_travel)\n        travel = twos_complement_to_int(binary_travel)\n\n        bytes_pulses = response[25:33]\n        binary_pulses = bytes_to_binary(bytes_pulses)\n        pulses = twos_complement_to_int(binary_pulses)\n\n        outp = {\n            \"header\": header,\n            \"ell\": ell,\n            \"sn\": sn,\n            \"year\": year,\n            \"firmware_release\": firmware_release,\n            \"hardware_release\": hardware_release,\n            \"travel\": travel,\n            \"pulses\": pulses\n        }\n        return outp\n\n    def get_device_status(self):\n        '''\n        Query device to get its status code  - for testing that device is functioning correctly\n        '''\n\n        response = self.query_device(\"gs\")\n        # read response and decode it:\n        header = response[0:3]\n        byte_status = response[3:5]\n        if self.debug > 0:\n            print(\"Byte status:\", byte_status)\n\n        binary_status = bytes_to_binary(byte_status)\n        if self.debug > 0:\n            print(\"Binary status\", binary_status)\n        int_status = int(binary_status, base=2)\n\n        if int_status in list(Thorlabs_ELL8K.DEVICE_STATUS_CODES.keys()):\n            return {\"header\": header, \"status\": Thorlabs_ELL8K.DEVICE_STATUS_CODES[int_status]}\n        else:\n            return {\"header\": header, \"status\": Thorlabs_ELL8K.DEVICE_STATUS_CODES[\"OutOfBounds\"]}\n\n    def move_home(self, clockwise=True, blocking=True):\n        '''\n        Move stage to factory default home location. \n        Note: Thorlabs API allows resetting stages home but this not implemented as it isnt' advised \n        '''\n        if clockwise:\n            direction = 0\n        else:\n            direction = 1\n        response = self.query_device(\"ho{0}\".format(direction))\n\n        if blocking:\n            self.__block_until_stopped()\n        return self.__decode_position_response(response)\n\n    def move_absolute(self, angle, blocking=True):\n        \"\"\"Move to absolute position relative to home setting\n\n        Args:\n            angle (float): angle to move to, specified in degrees.\n\n        Returns:\n            None\n\n        Raises:\n            None\n\n        \"\"\"\n        if -360 > angle or angle > 360:\n            angle %= 360\n        if angle < 0:\n            angle = 360+angle\n        pulses_hex = self.__angle_to_hex_pulses(angle)\n        response = self.query_device(\"ma{0}\".format(pulses_hex))\n\n        header = response[0:3]\n\n        if blocking:\n            self.__block_until_stopped()\n        return self.__decode_position_response(response)\n\n    def move_relative(self, angle, blocking=True):\n        \"\"\"Moves relative to current position\n\n        Args:\n            angle (float): relative angle to move to, specified in degrees.\n            clockwise(bool): specifies whether we are moving in the clockwise direction. \n                    False if moving anticlockwise\n\n        Returns:\n            None\n\n        Raises:\n            None\n\n        \"\"\"\n        pulses_hex = self.__angle_to_hex_pulses(angle)\n        response = self.query_device(\"mr{0}\".format(pulses_hex))\n        if blocking:\n            self.__block_until_stopped()\n        return self.__decode_position_response(response)\n\n    def optimize_motors(self, save_new_params=False):\n        '''Due to load, build tolerances and other mechanical variances, the\n        default resonating frequency of a particular motor may not be that\n        which delivers best performance.\n        This message fine tunes the frequency search performed by the\n        SEARCHFREQ messages. When this message is called, the\n        SEARCHFREQ message is called first automatically to optimize the\n        operating frequency. After completion, another frequency search is\n        performed and the mechanical performance is monitored to further\n        optimize the operating frequencies for backward and forward\n        movement. The values then need to be saved\n        '''\n        reply = self.query_device('om')\n        if save_new_params:\n            self.save_new_parameters()\n        return reply\n\n    def save_new_parameters(self):\n        return self.query_device('us')",
  "class Thorlabs_ELL8K_UI(QtWidgets.QWidget, UiTools):\n\n    def __init__(self, stage, parent=None, debug=0):\n        if not isinstance(stage, Thorlabs_ELL8K):\n            raise ValueError(\n                \"Object is not an instance of the Thorlabs_ELL8K Stage\")\n        super(Thorlabs_ELL8K_UI, self).__init__()\n        self.stage = stage  # this is the actual rotation stage\n        self.parent = parent\n        self.debug = debug\n\n        uic.loadUi(os.path.join(os.path.dirname(\n            __file__), 'thorlabs_ell8k.ui'), self)\n\n        self.move_relative_btn.clicked.connect(self.move_relative)\n        self.move_absolute_btn.clicked.connect(self.move_absolute)\n        self.move_home_btn.clicked.connect(self.move_home)\n        self.current_angle_btn.clicked.connect(self.update_current_angle)\n\n    def move_relative(self):\n        try:\n            angle = float(self.move_relative_textbox.text())\n        except ValueError as e:\n            print(e)\n            return\n        self.stage.move(pos=angle, relative=True)\n\n    def move_absolute(self):\n        try:\n            angle = float(self.move_absolute_textbox.text())\n        except ValueError as e:\n            print(e)\n            return\n        self.stage.move(pos=angle, relative=False)\n\n    def move_home(self):\n        self.stage.move_home()\n\n    def update_current_angle(self):\n        angle = self.stage.get_position()\n        self.current_angle_value.setText(str(angle))",
  "def test_stage(s):\n    '''\n    Run from main to test stage\n    '''\n    debug = False\n\n    print(\"Status\", s.get_device_status())\n    print(\"Info\", s.get_device_info())\n    print(\"Homing\", s.move_home())\n    print(\"Home position\", s.get_position())\n    angle = 30\n    s.move(angle, relative=True)\n    print(\"30==\", s.get_position())\n    angle = -30\n    s.move(angle, relative=True)\n    print(\"-30==\", s.get_position())\n\n    angle = 150\n    s.move(angle, relative=False)\n    print(\"150==\", s.get_position())\n\n    angle = -10\n    s.move(angle, relative=False)\n    print(\"350==\", s.get_position())",
  "def test_ui():\n    '''\n    Run from main to test ui + stage\n    '''\n    s = Thorlabs_ELL8K(\"COM1\")\n    app = get_qt_app()\n    ui = Thorlabs_ELL8K_UI(stage=s)\n    ui.show()\n    sys.exit(app.exec_())",
  "def __init__(self, serial_device, device_index=0, debug=0):\n        '''can be passed either a BusDistributor instance, or  \"COM5\"  '''\n        if type(serial_device) is str:\n            self.serial_device = BusDistributor(serial_device)\n        else:\n            self.serial_device = serial_device\n        self.debug = debug\n\n        Stage.__init__(self)\n        self.ui = None\n\n        # configure stage parameters\n        if str(device_index) not in Thorlabs_ELL8K.VALID_DEVICE_IDs:\n            raise ValueError(\n                \"Device ID: {} is not valid!\".format(device_index))\n        self.device_index = device_index\n\n        configuration = self.get_device_info()\n        self.TRAVEL = configuration[\"travel\"]\n        self.PULSES_PER_REVOLUTION = configuration[\"pulses\"]\n\n        if self.debug > 0:\n            print(\"Travel (degrees):\", self.TRAVEL)\n            print(\"Pulses per revolution\", self.PULSES_PER_REVOLUTION)\n            print(\"Device status:\", self.get_device_status())",
  "def query_device(self, query):\n        '''\n        Wrap a generic query with the ID of the device (integer in range: 0-F)\n        so that we dont need to be explicit about this id\n        '''\n        raw_query = \"{0}{1}\".format(self.device_index, query)\n        if self.debug > 0:\n            print(\"raw_query\", raw_query)\n        raw_response = self.serial_device.query(raw_query)\n        if self.debug > 0:\n            print(\"raw_response\", raw_response)\n        return raw_response",
  "def __angle_to_pulse_count(self, angle):\n        '''\n        Convert from an angle (specified in degrees) into the number of pulses\n        that need to be applied to the motor to turn it. \n\n        pulses_per_revolution - specified by Thorlabs as number of pulses for a revolution (360 deg) of stage\n        travel - the maximum angular motion of stage (==360 for ELL8K)\n\n        Method used when sending instructions to move to stage\n        '''\n        pulse_per_deg = self.PULSES_PER_REVOLUTION/float(self.TRAVEL)\n        pulses = int(np.rint(angle*pulse_per_deg))\n        if self.debug > 0:\n            print(\"Input angle:\", angle)\n            print(\"Pulses:\", pulses)\n        return pulses",
  "def __pulse_count_to_angle(self, pulse_count):\n        '''\n        Convert from an pulse count into the degrees. \n\n        pulses_per_revolution - specified by Thorlabs as number of pulses for a revolution (360 deg) of stage\n        travel - the maximum angular motion of stage (==360 for ELL8K)\n\n        Method used when reading data received from stage\n        '''\n        return float(self.TRAVEL)*pulse_count/self.PULSES_PER_REVOLUTION",
  "def __angle_to_hex_pulses(self, angle):\n        '''\n        Convert angle in range (-360.0,360.0) (exclusive of edges) into a hex representation of pulse\n        count required for talking to the ELL8K stage\n\n        '''\n        if angle < -360.0 or angle > 360.0:\n            raise ValueError(\"Valid angle bounds are: (-360,360) [exclusive]\")\n\n        # convert angle to number of pulses used to drive motors:\n        pulses_int = self.__angle_to_pulse_count(angle)\n        if self.debug > 0:\n            print(\"Pulses (int)\", pulses_int)\n        # make two's complement to allow for -ve values\n        pulses_int = int_to_twos_complement(pulses_int)\n        if self.debug > 0:\n            print(\"Pulses (int,2s compl)\", pulses_int)\n        # convert integer to hex\n        pulses_hex = int_to_hex(pulses_int)\n        if self.debug > 0:\n            print(\"Pulses hex:\", pulses_hex)\n        return pulses_hex",
  "def __hex_pulses_to_angle(self, hex_pulse_position):\n        '''\n        Convert position to angle - full method for processing responses from stage\n        '''\n        binary_pulse_position = bytes_to_binary(hex_pulse_position)\n        int_pulse_position = twos_complement_to_int(binary_pulse_position)\n        return self.__pulse_count_to_angle(int_pulse_position)",
  "def __decode_position_response(self, response):\n        '''\n        Method for decoding positional response from stage for responses from:\n            mode_absolute, mode_relative, move_home\n        '''\n        header = response[0:3]\n        if header == \"{0}GS\".format(self.device_index):\n            # still moving\n            status_code = int(response[3:5], base=16)\n            status = Thorlabs_ELL8K.DEVICE_STATUS_CODES[status_code]\n            outp = {\"header\": header, \"status\": status}\n            return outp\n        elif header == \"{0}PO\".format(self.device_index):\n            hex_pulse_position = response[3:11]\n            position = self.__hex_pulses_to_angle(hex_pulse_position)\n            outp = {\"header\": header, \"position\": position}\n            return outp",
  "def __block_until_stopped(self):\n        '''\n        Method for blocking move_absolute and move_relative and move_home commands until stage has stopped\n        Spins on get_position command comparing returned results. If between two calls position doesn't change\n        Then assume stage has stopped and exit\n        '''\n        stopped = False\n        previous_angle = 0.0\n        current_angle = 1.0\n\n        try:\n            while(stopped == False):\n                time.sleep(Thorlabs_ELL8K.BLOCK_SLEEPING_TIME)\n                current_angle = self.get_position()\n                stopped = (np.absolute(current_angle - previous_angle)\n                           < Thorlabs_ELL8K.POSITION_JITTER_THRESHOLD)\n                previous_angle = current_angle\n        except KeyboardInterrupt:\n            return\n        return",
  "def get_position(self, axis=None):\n        '''\n        Query stage for its current position, in degrees\n        This method overrides the Stage class' method\n        '''\n        response = self.query_device(\"gp\")\n        header = response[0:3]\n        if header == \"{0}PO\".format(self.device_index):\n            # position given in twos complement representation\n            byte_position = response[3:11]\n            binary_position = bytes_to_binary(byte_position)\n            pulse_position = twos_complement_to_int(binary_position)\n            degrees_position = self.TRAVEL * \\\n                (float(pulse_position)/self.PULSES_PER_REVOLUTION)\n            return degrees_position\n        else:\n            raise ValueError(\"Incompatible Header received:{}\".format(header))",
  "def move(self, pos, axis=None, relative=False):\n        '''\n        Send command to move stage.\n        pos:  specified in degrees and can be in range (-360,360)\n        relative: whether motion is relative to current position or relative to global home\n        This method overrides the Stage class' method\n        '''\n        if relative:\n            self.move_relative(pos)\n        else:\n            self.move_absolute(pos)",
  "def get_qt_ui(self):\n        '''\n        Get UI for stage\n        '''\n        if self.ui is None:\n            self.ui = Thorlabs_ELL8K_UI(stage=self)\n        return self.ui",
  "def get_device_info(self):\n        '''\n        Instruct hardware to identify itself. \n        Give information about model, serial numbner, firmware. \n\n        This MUST be called at initialization of the stage as the key parameters:\n\n        TRAVEL, PULSES are extracted here\n\n        TRAVEL - the range of travel of the stage, specified in units (mm or deg) relevant to the type of stage\n        PULSES - specifieid the number of pulses applied to motors to move stage over entire range of travel\n\n        Hence: ratio of PULSES/TRAVEL gives number of pulses to move 1 mm or 1 deg\n        '''\n\n        response = self.query_device(\"in\")\n\n        # decode the response\n        header = response[0:3]\n        ell = response[3:5]\n        sn = response[5:13]\n        year = response[13:17]\n        firmware_release = response[17:19]\n        hardware_release = response[19:21]\n\n        bytes_travel = response[21:25]  # units: mm/deg\n\n        binary_travel = bytes_to_binary(bytes_travel)\n        travel = twos_complement_to_int(binary_travel)\n\n        bytes_pulses = response[25:33]\n        binary_pulses = bytes_to_binary(bytes_pulses)\n        pulses = twos_complement_to_int(binary_pulses)\n\n        outp = {\n            \"header\": header,\n            \"ell\": ell,\n            \"sn\": sn,\n            \"year\": year,\n            \"firmware_release\": firmware_release,\n            \"hardware_release\": hardware_release,\n            \"travel\": travel,\n            \"pulses\": pulses\n        }\n        return outp",
  "def get_device_status(self):\n        '''\n        Query device to get its status code  - for testing that device is functioning correctly\n        '''\n\n        response = self.query_device(\"gs\")\n        # read response and decode it:\n        header = response[0:3]\n        byte_status = response[3:5]\n        if self.debug > 0:\n            print(\"Byte status:\", byte_status)\n\n        binary_status = bytes_to_binary(byte_status)\n        if self.debug > 0:\n            print(\"Binary status\", binary_status)\n        int_status = int(binary_status, base=2)\n\n        if int_status in list(Thorlabs_ELL8K.DEVICE_STATUS_CODES.keys()):\n            return {\"header\": header, \"status\": Thorlabs_ELL8K.DEVICE_STATUS_CODES[int_status]}\n        else:\n            return {\"header\": header, \"status\": Thorlabs_ELL8K.DEVICE_STATUS_CODES[\"OutOfBounds\"]}",
  "def move_home(self, clockwise=True, blocking=True):\n        '''\n        Move stage to factory default home location. \n        Note: Thorlabs API allows resetting stages home but this not implemented as it isnt' advised \n        '''\n        if clockwise:\n            direction = 0\n        else:\n            direction = 1\n        response = self.query_device(\"ho{0}\".format(direction))\n\n        if blocking:\n            self.__block_until_stopped()\n        return self.__decode_position_response(response)",
  "def move_absolute(self, angle, blocking=True):\n        \"\"\"Move to absolute position relative to home setting\n\n        Args:\n            angle (float): angle to move to, specified in degrees.\n\n        Returns:\n            None\n\n        Raises:\n            None\n\n        \"\"\"\n        if -360 > angle or angle > 360:\n            angle %= 360\n        if angle < 0:\n            angle = 360+angle\n        pulses_hex = self.__angle_to_hex_pulses(angle)\n        response = self.query_device(\"ma{0}\".format(pulses_hex))\n\n        header = response[0:3]\n\n        if blocking:\n            self.__block_until_stopped()\n        return self.__decode_position_response(response)",
  "def move_relative(self, angle, blocking=True):\n        \"\"\"Moves relative to current position\n\n        Args:\n            angle (float): relative angle to move to, specified in degrees.\n            clockwise(bool): specifies whether we are moving in the clockwise direction. \n                    False if moving anticlockwise\n\n        Returns:\n            None\n\n        Raises:\n            None\n\n        \"\"\"\n        pulses_hex = self.__angle_to_hex_pulses(angle)\n        response = self.query_device(\"mr{0}\".format(pulses_hex))\n        if blocking:\n            self.__block_until_stopped()\n        return self.__decode_position_response(response)",
  "def optimize_motors(self, save_new_params=False):\n        '''Due to load, build tolerances and other mechanical variances, the\n        default resonating frequency of a particular motor may not be that\n        which delivers best performance.\n        This message fine tunes the frequency search performed by the\n        SEARCHFREQ messages. When this message is called, the\n        SEARCHFREQ message is called first automatically to optimize the\n        operating frequency. After completion, another frequency search is\n        performed and the mechanical performance is monitored to further\n        optimize the operating frequencies for backward and forward\n        movement. The values then need to be saved\n        '''\n        reply = self.query_device('om')\n        if save_new_params:\n            self.save_new_parameters()\n        return reply",
  "def save_new_parameters(self):\n        return self.query_device('us')",
  "def __init__(self, stage, parent=None, debug=0):\n        if not isinstance(stage, Thorlabs_ELL8K):\n            raise ValueError(\n                \"Object is not an instance of the Thorlabs_ELL8K Stage\")\n        super(Thorlabs_ELL8K_UI, self).__init__()\n        self.stage = stage  # this is the actual rotation stage\n        self.parent = parent\n        self.debug = debug\n\n        uic.loadUi(os.path.join(os.path.dirname(\n            __file__), 'thorlabs_ell8k.ui'), self)\n\n        self.move_relative_btn.clicked.connect(self.move_relative)\n        self.move_absolute_btn.clicked.connect(self.move_absolute)\n        self.move_home_btn.clicked.connect(self.move_home)\n        self.current_angle_btn.clicked.connect(self.update_current_angle)",
  "def move_relative(self):\n        try:\n            angle = float(self.move_relative_textbox.text())\n        except ValueError as e:\n            print(e)\n            return\n        self.stage.move(pos=angle, relative=True)",
  "def move_absolute(self):\n        try:\n            angle = float(self.move_absolute_textbox.text())\n        except ValueError as e:\n            print(e)\n            return\n        self.stage.move(pos=angle, relative=False)",
  "def move_home(self):\n        self.stage.move_home()",
  "def update_current_angle(self):\n        angle = self.stage.get_position()\n        self.current_angle_value.setText(str(angle))",
  "class FW212C(Instrument):\n    def __init__(self, address = 'ASRLCOM7::INSTR'):\n        self.visa_address = str(address)\n        self.baud_rate=115200\n        self.num_position=12\n        self.sept_str=\"\\r\"\n        self.prompt_str=\">\"\n        rm = visa.ResourceManager()\n        self.device = rm.open_resource(self.visa_address, baud_rate=self.baud_rate, read_termination=self.sept_str,write_termination='', timeout=1000)\n        self.setSpeedMode(1)\n        self.setSensorMode(0)\n        self.setPositionCount(self.num_position)\n    \n    def clear(self):\n        self.device.read()\n\n    def write(self,msg):\n        self.device.write(msg+self.sept_str)\n        self.clear()    \n    \n    def query(self,msg):\n        self.device.query(msg+self.sept_str)\n        return int(self.device.read())    \n    \n    def setPosition(self,position):\n        self.write(\"pos=\"+str(position))    \n    def getPosition(self):\n        pos=self.query(\"pos?\")\n        return int(pos)  \n    position = property(getPosition, setPosition)  \n    \n    def setPositionCount(self,posCount):\n        self.write(\"pcount=\"+str(int(posCount)))\n       \n    def getPositionCount(self):\n        return int(self.query(\"pcount?\"))\n        \n    def setSpeedMode(self,mode):\n        #slow: 0, fast:1\n        self.write(\"speed=\"+str(int(mode)))\n        \n    def getSpeedMode(self):\n        #slow: 0, fast:1\n        return int(self.query(\"speed?\"))\n        \n    def setSensorMode(self,mode):\n        #off when idle: 0, always on: 1\n        self.write(\"sensors=\"+str(int(mode)))\n        \n    def getSensorMode(self):\n        #off when idle: 0, always on: 1\n        return int(self.query(\"sensors?\"))\n        \n    def saveSettings(self):\n        self.write(\"save\")\n        \n    def shutdown(self):\n        self.device.close()\n    def get_qt_ui(self):\n        return FW212C_UI(self)",
  "class FW212C_UI(QtWidgets.QWidget, UiTools):\n    def __init__(self, fw):\n        super(FW212C_UI, self).__init__()\n        self.fw = fw\n        uic.loadUi(os.path.join(os.path.dirname(__file__), 'thorlabs_fw212c.ui'), self)\n        for button in range(1,13):#1-12\n            eval('self.radioButton_'+str(button)+'.clicked.connect(self.button_pressed)')\n    def button_pressed(self):\n        '''buttons are called radioButton_x'''\n        self.fw.position = int(self.sender().objectName().split('_')[-1])",
  "def __init__(self, address = 'ASRLCOM7::INSTR'):\n        self.visa_address = str(address)\n        self.baud_rate=115200\n        self.num_position=12\n        self.sept_str=\"\\r\"\n        self.prompt_str=\">\"\n        rm = visa.ResourceManager()\n        self.device = rm.open_resource(self.visa_address, baud_rate=self.baud_rate, read_termination=self.sept_str,write_termination='', timeout=1000)\n        self.setSpeedMode(1)\n        self.setSensorMode(0)\n        self.setPositionCount(self.num_position)",
  "def clear(self):\n        self.device.read()",
  "def write(self,msg):\n        self.device.write(msg+self.sept_str)\n        self.clear()",
  "def query(self,msg):\n        self.device.query(msg+self.sept_str)\n        return int(self.device.read())",
  "def setPosition(self,position):\n        self.write(\"pos=\"+str(position))",
  "def getPosition(self):\n        pos=self.query(\"pos?\")\n        return int(pos)",
  "def setPositionCount(self,posCount):\n        self.write(\"pcount=\"+str(int(posCount)))",
  "def getPositionCount(self):\n        return int(self.query(\"pcount?\"))",
  "def setSpeedMode(self,mode):\n        #slow: 0, fast:1\n        self.write(\"speed=\"+str(int(mode)))",
  "def getSpeedMode(self):\n        #slow: 0, fast:1\n        return int(self.query(\"speed?\"))",
  "def setSensorMode(self,mode):\n        #off when idle: 0, always on: 1\n        self.write(\"sensors=\"+str(int(mode)))",
  "def getSensorMode(self):\n        #off when idle: 0, always on: 1\n        return int(self.query(\"sensors?\"))",
  "def saveSettings(self):\n        self.write(\"save\")",
  "def shutdown(self):\n        self.device.close()",
  "def get_qt_ui(self):\n        return FW212C_UI(self)",
  "def __init__(self, fw):\n        super(FW212C_UI, self).__init__()\n        self.fw = fw\n        uic.loadUi(os.path.join(os.path.dirname(__file__), 'thorlabs_fw212c.ui'), self)\n        for button in range(1,13):#1-12\n            eval('self.radioButton_'+str(button)+'.clicked.connect(self.button_pressed)')",
  "def button_pressed(self):\n        '''buttons are called radioButton_x'''\n        self.fw.position = int(self.sender().objectName().split('_')[-1])",
  "class XY_ZWrapper(Stage):\n    axis_names = ('x', 'y', 'z')\n    \n    def __init__(self, XY, Z, unit='u'):\n        self.XY = XY\n        self.Z = Z\n        super().__init__(unit=unit)\n        \n    \n    def get_position(self, axis=None):\n       if axis is  None:\n           return np.append(self.XY.position, self.Z.position)\n       elif axis in self.axis_names:\n           if axis in 'xy':\n               return self.XY.get_position(axis=axis)\n           elif axis == 'z':\n               return self.Z.get_position()\n    \n    def move(self, x, axis=None, relative=False):\n        \"\"\" move wrapper \"\"\"\n        if axis is None:\n            self.XY.move(x[:2], relative=relative)\n            if len(x) == 3:\n                self.Z.move(x[2], relative=relative)\n               \n        elif axis in self.axis_names:\n            if axis in 'xy':\n                self.XY.move(x, axis=axis, relative=relative)\n            elif axis == 'z':\n                self.Z.move(x, relative=relative)",
  "def __init__(self, XY, Z, unit='u'):\n        self.XY = XY\n        self.Z = Z\n        super().__init__(unit=unit)",
  "def get_position(self, axis=None):\n       if axis is  None:\n           return np.append(self.XY.position, self.Z.position)\n       elif axis in self.axis_names:\n           if axis in 'xy':\n               return self.XY.get_position(axis=axis)\n           elif axis == 'z':\n               return self.Z.get_position()",
  "def move(self, x, axis=None, relative=False):\n        \"\"\" move wrapper \"\"\"\n        if axis is None:\n            self.XY.move(x[:2], relative=relative)\n            if len(x) == 3:\n                self.Z.move(x[2], relative=relative)\n               \n        elif axis in self.axis_names:\n            if axis in 'xy':\n                self.XY.move(x, axis=axis, relative=relative)\n            elif axis == 'z':\n                self.Z.move(x, relative=relative)",
  "class Rotation_Stage_Backend(serial.SerialInstrument):\n    \n    def __init__(self,port=None):\n        super(Rotation_Stage_Backend, self).__init__()\n        \n    def Number_to_Hex(self,Input,Min_Size=8):\n        Hex=hex(Input)[2:]\n        Output=[]\n        for i in Hex:\n            Output.append(i)\n        while len(Output)<Min_Size:\n            Output=['0']+Output\n        Output = list(map(str.encode, Output))\n        return Output\n\n\n    def Convert_Status(self,Code):\n        Responses=['No Error', 'Communication time out', 'Mechanical time out', 'Command error', 'Value out of range', 'Module isolated']\n        Responses+=['Module out of isolation', 'Initializing error', 'Thermal error', 'Busy', 'Sensor Error', 'Initializing error', 'Thermal error', 'Busy']\n        Responses+=['Sensor Error', 'Motor Error', 'Out of Range']\n        if Code>=14:\n            return 'Reserved Response Code'\n        else:\n            return Responses[Code]\n\n    def Get_Status(self):\n        Packer=struct.Struct(format=b'ccc')\n        Message=Packer.pack(*[b'0',b'g',b's'])\n        self.Port.write(Message)\n        Response=self.Port.readline()\n\n        Code=int(b'0x'+Response[3:],0)\n\n        return self.Convert_Status(Code)\n\n    def Rotate(self,Angle):\n\n        Message=[b'0',b'm',b'r']\n\n        while Angle<0:\n            Angle+=360.\n        Angle=Angle%360\n\n        Angle= 262144.*Angle/360\n\n        Angle=int(Angle)\n        Angle=self.Number_to_Hex(Angle)\n\n        Message+=Angle\n        Packer=struct.Struct(format=b'ccccccccccc')\n        Message=Packer.pack(*Message)\n        \n        self.Port.write(Message)\n        Response=self.Port.readline()\n        \n\n        Code=int(b'0x'+Response[3:],0)\n\n        if Response[:3]==b'0PO':\n            Position=float(Code)/262144\n            return 'Position: '+str(Position*360)\n        else:\n            return self.Convert_Status(Code)\n\n    def Rotate_To(self,Angle):\n\n        Message=[b'0', b'm', b'a']\n\n        while Angle<0:\n            Angle+=360.\n        Angle=Angle%360\n\n        Angle=(262144.*Angle)/360\n\n        Angle=int(Angle)\n        Angle=self.Number_to_Hex(Angle)\n\n        Message+=Angle\n        Packer=struct.Struct(format=b'ccccccccccc')\n        Message=Packer.pack(*Message)\n        \n        self.Port.write(Message)\n        Response=self.Port.readline()\n        \n\n        Code=int(b'0x'+Response[3:],0)\n\n        if Response[:3]==b'0PO':\n            Position=float(Code)/262144\n            return 'Position: '+str(Position*360)\n        else:\n            return self.Convert_Status(Code)\n\n    def Get_Position(self):\n      # This fails for small angles. Also, should return a float\n        Packer=struct.Struct(format=b'ccc') \n        Message=Packer.pack(*[b'0',b'g',b'p'])\n\n        self.Port.write(Message)\n        Response=self.Port.readline()\n        Code=int(b'0x'+Response[3:],0)\n\n        if Response[:3]==b'0PO':\n            Position=float(Code)/262144\n            return 'Position: '+str(Position*360)\n        else:\n            return self.Convert_Status(Code)",
  "class Filter_Wheel(object):\n\n    def __init__(self,Port='COM20',Power_Meter=None,Power_Curve_Directory=os.path):\n            self.Stage=Rotation_Stage_Backend(Port)\n            self.Power_Curve=np.load(Power_Curve_Directory+'Filter_Wheel_Power_Curve.npy')\n            self.Power_Curve_Directory=Power_Curve_Directory\n            self.Power_Meter=Power_Meter\n            self.Angle_Range=[0,360]      #230\n            \n    def Return_Home(self):\n        self.Stage.Rotate_To(180) #100\n\n    def Generate_Power_Curve(self,Number_of_Points=30,Measurements_per_Point=10,Background=0.):\n        if self.Power_Meter is None:\n            print('No Power Meter Defined!')\n            return\n        \n        Input_Angles=np.linspace(self.Angle_Range[0],self.Angle_Range[1],Number_of_Points)\n\n        Output_Angles=[]\n        Output_Powers=[]\n\n        self.Stage.Rotate_To(self.Angle_Range[0]) \n        time.sleep(2)\n\n        for i in Input_Angles:\n            Pos=self.Stage.Rotate_To(i)\n            time.sleep(0.5)\n            Pos=float(Pos[9:])\n#            if Pos>295:\n#                Pos-=360\n            Output_Angles.append(Pos)\n            Power=[]\n            while len(Power)<Measurements_per_Point:\n                Power.append(self.Power_Meter.read)\n            Output_Powers.append(np.mean(Power))\n            time.sleep(0.5)\n            print('Current Angle: '+str(round(Pos,2)))\n\n        self.Stage.Rotate_To(self.Angle_Range[0])#-190\n\n        self.Power_Curve=np.array([Output_Angles,1000.*(np.array(Output_Powers)-Background)])\n\n    def Generate_Power_Curve_v2(self,Number_of_Points=30,Measurements_per_Point=10,Background=0.):\n        if self.Power_Meter is None:\n            print('No Power Meter Defined!')\n            raise Exception('Lacking Power Meter')\n        def Measure():\n            Power=[]\n\n            while len(Power)<Measurements_per_Point:\n                try:\n                    Power.append(self.Power_Meter.read)\n                except:\n                    Dump=1\n            return np.median(Power)\n        def Rotate_Catch(Angle):\n            Pos=None\n            while Pos is None:\n                try:\n                    Pos=self.Stage.Rotate_To(Angle)\n                    time.sleep(0.5)\n                    Pos=float(Pos[9:])\n                except:\n                    Pos=None\n            return Pos%360\n\n        Angles=[]\n        Powers=[]\n        for i in [self.Angle_Range[0],self.Angle_Range[1]]:\n            Pos=Rotate_Catch(i)\n            Angles.append(Pos)\n            Powers.append(Measure())\n\n        while len(Powers)<Number_of_Points:\n            Diff=[]\n            n=1\n            while n<len(Powers):\n                Diff.append(Powers[n-1]-Powers[n])\n                n+=1\n            print('Points:'+str(len(Powers))+'. Average Power Seperation: '+str(round(np.mean(Diff)*1000000,2))+'uW')\n            Next=np.argmax(Diff)\n          #print Next\n            Next_Angle=0.5*(Angles[Next]+Angles[Next+1])\n            Pos=Rotate_Catch(Next_Angle)\n            Angles=Angles[:Next+1]+[Pos]+Angles[Next+1:]\n            Powers=Powers[:Next+1]+[Measure()]+Powers[Next+1:]\n\n        self.Return_Home()\n        self.Power_Curve=np.array([Angles,1000.*(np.array(Powers)-Background)])\n\n        \n    def Save_Power_Curve(self):\n        np.save(self.Power_Curve_Directory+'Filter_Wheel_Power_Curve.npy',self.Power_Curve)\n\n    def Set_To_Power(self,Power):\n        if Power>np.max(self.Power_Curve[1]) or Power<np.min(self.Power_Curve[1]):\n            print('Outside available power limits!')\n            print('Please enter a value between '+str(np.min(self.Power_Curve[1]))+' and '+str(np.max(self.Power_Curve[1])))\n            return\n\n        Lower_Angle=0\n        while self.Power_Curve[1][Lower_Angle]>=Power:\n            Lower_Angle+=1\n        Lower_Angle-=1\n\n        if Lower_Angle==len(self.Power_Curve[1]):\n            Lower_Angle-=1\n\n        Angles=[self.Power_Curve[0][Lower_Angle],self.Power_Curve[0][Lower_Angle+1]]\n        Powers=[self.Power_Curve[1][Lower_Angle],self.Power_Curve[1][Lower_Angle+1]]\n\n        m=(Angles[1]-Angles[0])/(Powers[1]-Powers[0])\n        c=Angles[0]-(m*Powers[0])\n\n        Angle=(m*Power)+c\n\n        print('Rotating To: '+str(round(Angle,2)))\n\n        self.Stage.Rotate_To(Angle)\n        \n        return Angle",
  "def __init__(self,port=None):\n        super(Rotation_Stage_Backend, self).__init__()",
  "def Number_to_Hex(self,Input,Min_Size=8):\n        Hex=hex(Input)[2:]\n        Output=[]\n        for i in Hex:\n            Output.append(i)\n        while len(Output)<Min_Size:\n            Output=['0']+Output\n        Output = list(map(str.encode, Output))\n        return Output",
  "def Convert_Status(self,Code):\n        Responses=['No Error', 'Communication time out', 'Mechanical time out', 'Command error', 'Value out of range', 'Module isolated']\n        Responses+=['Module out of isolation', 'Initializing error', 'Thermal error', 'Busy', 'Sensor Error', 'Initializing error', 'Thermal error', 'Busy']\n        Responses+=['Sensor Error', 'Motor Error', 'Out of Range']\n        if Code>=14:\n            return 'Reserved Response Code'\n        else:\n            return Responses[Code]",
  "def Get_Status(self):\n        Packer=struct.Struct(format=b'ccc')\n        Message=Packer.pack(*[b'0',b'g',b's'])\n        self.Port.write(Message)\n        Response=self.Port.readline()\n\n        Code=int(b'0x'+Response[3:],0)\n\n        return self.Convert_Status(Code)",
  "def Rotate(self,Angle):\n\n        Message=[b'0',b'm',b'r']\n\n        while Angle<0:\n            Angle+=360.\n        Angle=Angle%360\n\n        Angle= 262144.*Angle/360\n\n        Angle=int(Angle)\n        Angle=self.Number_to_Hex(Angle)\n\n        Message+=Angle\n        Packer=struct.Struct(format=b'ccccccccccc')\n        Message=Packer.pack(*Message)\n        \n        self.Port.write(Message)\n        Response=self.Port.readline()\n        \n\n        Code=int(b'0x'+Response[3:],0)\n\n        if Response[:3]==b'0PO':\n            Position=float(Code)/262144\n            return 'Position: '+str(Position*360)\n        else:\n            return self.Convert_Status(Code)",
  "def Rotate_To(self,Angle):\n\n        Message=[b'0', b'm', b'a']\n\n        while Angle<0:\n            Angle+=360.\n        Angle=Angle%360\n\n        Angle=(262144.*Angle)/360\n\n        Angle=int(Angle)\n        Angle=self.Number_to_Hex(Angle)\n\n        Message+=Angle\n        Packer=struct.Struct(format=b'ccccccccccc')\n        Message=Packer.pack(*Message)\n        \n        self.Port.write(Message)\n        Response=self.Port.readline()\n        \n\n        Code=int(b'0x'+Response[3:],0)\n\n        if Response[:3]==b'0PO':\n            Position=float(Code)/262144\n            return 'Position: '+str(Position*360)\n        else:\n            return self.Convert_Status(Code)",
  "def Get_Position(self):\n      # This fails for small angles. Also, should return a float\n        Packer=struct.Struct(format=b'ccc') \n        Message=Packer.pack(*[b'0',b'g',b'p'])\n\n        self.Port.write(Message)\n        Response=self.Port.readline()\n        Code=int(b'0x'+Response[3:],0)\n\n        if Response[:3]==b'0PO':\n            Position=float(Code)/262144\n            return 'Position: '+str(Position*360)\n        else:\n            return self.Convert_Status(Code)",
  "def __init__(self,Port='COM20',Power_Meter=None,Power_Curve_Directory=os.path):\n            self.Stage=Rotation_Stage_Backend(Port)\n            self.Power_Curve=np.load(Power_Curve_Directory+'Filter_Wheel_Power_Curve.npy')\n            self.Power_Curve_Directory=Power_Curve_Directory\n            self.Power_Meter=Power_Meter\n            self.Angle_Range=[0,360]",
  "def Return_Home(self):\n        self.Stage.Rotate_To(180)",
  "def Generate_Power_Curve(self,Number_of_Points=30,Measurements_per_Point=10,Background=0.):\n        if self.Power_Meter is None:\n            print('No Power Meter Defined!')\n            return\n        \n        Input_Angles=np.linspace(self.Angle_Range[0],self.Angle_Range[1],Number_of_Points)\n\n        Output_Angles=[]\n        Output_Powers=[]\n\n        self.Stage.Rotate_To(self.Angle_Range[0]) \n        time.sleep(2)\n\n        for i in Input_Angles:\n            Pos=self.Stage.Rotate_To(i)\n            time.sleep(0.5)\n            Pos=float(Pos[9:])\n#            if Pos>295:\n#                Pos-=360\n            Output_Angles.append(Pos)\n            Power=[]\n            while len(Power)<Measurements_per_Point:\n                Power.append(self.Power_Meter.read)\n            Output_Powers.append(np.mean(Power))\n            time.sleep(0.5)\n            print('Current Angle: '+str(round(Pos,2)))\n\n        self.Stage.Rotate_To(self.Angle_Range[0])#-190\n\n        self.Power_Curve=np.array([Output_Angles,1000.*(np.array(Output_Powers)-Background)])",
  "def Generate_Power_Curve_v2(self,Number_of_Points=30,Measurements_per_Point=10,Background=0.):\n        if self.Power_Meter is None:\n            print('No Power Meter Defined!')\n            raise Exception('Lacking Power Meter')\n        def Measure():\n            Power=[]\n\n            while len(Power)<Measurements_per_Point:\n                try:\n                    Power.append(self.Power_Meter.read)\n                except:\n                    Dump=1\n            return np.median(Power)\n        def Rotate_Catch(Angle):\n            Pos=None\n            while Pos is None:\n                try:\n                    Pos=self.Stage.Rotate_To(Angle)\n                    time.sleep(0.5)\n                    Pos=float(Pos[9:])\n                except:\n                    Pos=None\n            return Pos%360\n\n        Angles=[]\n        Powers=[]\n        for i in [self.Angle_Range[0],self.Angle_Range[1]]:\n            Pos=Rotate_Catch(i)\n            Angles.append(Pos)\n            Powers.append(Measure())\n\n        while len(Powers)<Number_of_Points:\n            Diff=[]\n            n=1\n            while n<len(Powers):\n                Diff.append(Powers[n-1]-Powers[n])\n                n+=1\n            print('Points:'+str(len(Powers))+'. Average Power Seperation: '+str(round(np.mean(Diff)*1000000,2))+'uW')\n            Next=np.argmax(Diff)\n          #print Next\n            Next_Angle=0.5*(Angles[Next]+Angles[Next+1])\n            Pos=Rotate_Catch(Next_Angle)\n            Angles=Angles[:Next+1]+[Pos]+Angles[Next+1:]\n            Powers=Powers[:Next+1]+[Measure()]+Powers[Next+1:]\n\n        self.Return_Home()\n        self.Power_Curve=np.array([Angles,1000.*(np.array(Powers)-Background)])",
  "def Save_Power_Curve(self):\n        np.save(self.Power_Curve_Directory+'Filter_Wheel_Power_Curve.npy',self.Power_Curve)",
  "def Set_To_Power(self,Power):\n        if Power>np.max(self.Power_Curve[1]) or Power<np.min(self.Power_Curve[1]):\n            print('Outside available power limits!')\n            print('Please enter a value between '+str(np.min(self.Power_Curve[1]))+' and '+str(np.max(self.Power_Curve[1])))\n            return\n\n        Lower_Angle=0\n        while self.Power_Curve[1][Lower_Angle]>=Power:\n            Lower_Angle+=1\n        Lower_Angle-=1\n\n        if Lower_Angle==len(self.Power_Curve[1]):\n            Lower_Angle-=1\n\n        Angles=[self.Power_Curve[0][Lower_Angle],self.Power_Curve[0][Lower_Angle+1]]\n        Powers=[self.Power_Curve[1][Lower_Angle],self.Power_Curve[1][Lower_Angle+1]]\n\n        m=(Angles[1]-Angles[0])/(Powers[1]-Powers[0])\n        c=Angles[0]-(m*Powers[0])\n\n        Angle=(m*Power)+c\n\n        print('Rotating To: '+str(round(Angle,2)))\n\n        self.Stage.Rotate_To(Angle)\n        \n        return Angle",
  "def Measure():\n            Power=[]\n\n            while len(Power)<Measurements_per_Point:\n                try:\n                    Power.append(self.Power_Meter.read)\n                except:\n                    Dump=1\n            return np.median(Power)",
  "def Rotate_Catch(Angle):\n            Pos=None\n            while Pos is None:\n                try:\n                    Pos=self.Stage.Rotate_To(Angle)\n                    time.sleep(0.5)\n                    Pos=float(Pos[9:])\n                except:\n                    Pos=None\n            return Pos%360",
  "class Ell20(ElloDevice):\n\n    def __init__(self, serial_device, device_index=0, debug=0):\n        '''can be passed either a BusDistributor instance, or  \"COM5\"  '''\n        super().__init__(serial_device, device_index=0, debug=0)\n        \n        \n        self.configuration = self.get_device_info()\n        self.TRAVEL = self.configuration[\"travel\"]\n        self.PULSES_PER_MM = self.configuration[\"pulses\"]\n        if self.debug > 0:\n            print(\"Travel (degrees):\", self.TRAVEL)\n            print(\"Pulses per revolution\", self.PULSES_PER_MM)\n            print(\"Device status:\", self.get_device_status())\n    \n    \n    def _position_to_pulse_count(self, position):\n        '''\n        Convert from an position (specified in degrees) into the number of pulses\n        that need to be applied to the motor to turn it. \n\n        pulses_per_revolution - specified by Thorlabs as number of pulses for a revolution (360 deg) of stage\n        travel - the maximum angular motion of stage (==360 for ELL8K)\n\n        Method used when sending instructions to move to stage\n        '''\n        pulses = int(np.rint(position*self.PULSES_PER_MM))\n        if self.debug > 0:\n            print(\"Input position:\", position)\n            print(\"Pulses:\", pulses)\n        return pulses\n\n    def _pulse_count_to_position(self, pulse_count):\n        '''\n        Convert from an pulse count into the degrees. \n\n        pulses_per_revolution - specified by Thorlabs as number of pulses for a revolution (360 deg) of stage\n        travel - the maximum angular motion of stage (==360 for ELL8K)\n\n        Method used when reading data received from stage\n        '''\n        return pulse_count/self.PULSES_PER_MM\n\n    def _position_to_hex_pulses(self, position):\n        '''\n        Convert position in range (-360.0,360.0) (exclusive of edges) into a hex representation of pulse\n        count required for talking to the ELL8K stage\n\n        '''\n\n        # convert position to number of pulses used to drive motors:\n        pulses_int = self._position_to_pulse_count(position)\n        if self.debug > 0:\n            print(\"Pulses (int)\", pulses_int)\n        # make two's complement to allow for -ve values\n        pulses_int = int_to_twos_complement(pulses_int)\n        if self.debug > 0:\n            print(\"Pulses (int,2s compl)\", pulses_int)\n        # convert integer to hex\n        pulses_hex = int_to_hex(pulses_int)\n        if self.debug > 0:\n            print(\"Pulses hex:\", pulses_hex)\n        return pulses_hex\n\n    def _hex_pulses_to_position(self, hex_pulse_position):\n        '''\n        Convert position to position - full method for processing responses from stage\n        '''\n        binary_pulse_position = bytes_to_binary(hex_pulse_position)\n        int_pulse_position = twos_complement_to_int(binary_pulse_position)\n        return self._pulse_count_to_position(int_pulse_position)\n    \n    \n    def move_absolute(self, position, blocking=True):\n        \"\"\"Move to absolute position relative to home setting\n\n        Args:\n            position (float): position to move to, specified in degrees.\n\n        Returns:\n            None\n\n        Raises:\n            None\n\n        \"\"\"\n\n        pulses_hex = self._position_to_hex_pulses(position)\n        response = self.query_device(\"ma{0}\".format(pulses_hex))\n\n        header = response[0:3]\n\n        if blocking:\n            self._block_until_stopped()\n        return self._decode_position_response(response)\n    \n    def get_position(self, axis=None):\n        '''\n        Query stage for its current position, in degrees\n        This method overrides the Stage class' method\n        '''\n        response = self.query_device(\"gp\")\n        header = response[0:3]\n        if header == \"{0}PO\".format(self.device_index):\n            # position given in twos complement representation\n            byte_position = response[3:11]\n            binary_position = bytes_to_binary(byte_position)\n            pulse_position = twos_complement_to_int(binary_position)\n            position = float(pulse_position)/self.PULSES_PER_MM\n            return position\n        else:\n            raise ValueError(\"Incompatible Header received:{}\".format(header))\n\n    def move_home(self, blocking=True):\n        '''\n        Move stage to factory default home location. \n        Note: Thorlabs API allows resetting stages home but this not implemented as it isnt' advised \n        '''\n\n        response = self.query_device(\"ho\")\n        if blocking:\n            self._block_until_stopped()\n        return self._decode_position_response(response)\n\n    def get_qt_ui(self):\n        return ELL20UI(self)",
  "class ELL20UI(QuickControlBox):\n\n    def __init__(self, stage):\n        super().__init__()\n        self.add_doublespinbox('position', 0, stage.TRAVEL)\n        self.auto_connect_by_name(controlled_object=stage)",
  "class Ell20BiPositional(Ell20):\n    SLOTS = (0.05, 0.95)  # fractions of travel\n    TOLERANCE = 0.05\n\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        # self.move_home()\n        # self.slot = 0\n\n    def get_slot(self):\n        frac = self.get_position() / self.TRAVEL\n        for i, slot in enumerate(self.SLOTS):\n            if abs(frac - slot) < self.TOLERANCE:\n                return i\n        self.log('not in either position', level='warn')\n\n    def set_slot(self, index):\n        self.move(self.SLOTS[index]*self.TRAVEL)\n    slot = NotifiedProperty(get_slot, set_slot)\n\n    def center(self):\n        slot = min(enumerate(self.SLOTS),\n                   key=lambda i_s: abs(i_s[1] - (self.get_position() / self.TRAVEL)))[0]\n        self.slot = slot\n\n    def get_qt_ui(self):\n        return Ell20BiPositionalUi(self)",
  "class Ell20BiPositionalUi(QuickControlBox):\n\n    def __init__(self, stage):\n        super().__init__()\n\n        self.add_spinbox('slot', 0, len(stage.SLOTS))\n        self.auto_connect_by_name(controlled_object=stage)",
  "def __init__(self, serial_device, device_index=0, debug=0):\n        '''can be passed either a BusDistributor instance, or  \"COM5\"  '''\n        super().__init__(serial_device, device_index=0, debug=0)\n        \n        \n        self.configuration = self.get_device_info()\n        self.TRAVEL = self.configuration[\"travel\"]\n        self.PULSES_PER_MM = self.configuration[\"pulses\"]\n        if self.debug > 0:\n            print(\"Travel (degrees):\", self.TRAVEL)\n            print(\"Pulses per revolution\", self.PULSES_PER_MM)\n            print(\"Device status:\", self.get_device_status())",
  "def _position_to_pulse_count(self, position):\n        '''\n        Convert from an position (specified in degrees) into the number of pulses\n        that need to be applied to the motor to turn it. \n\n        pulses_per_revolution - specified by Thorlabs as number of pulses for a revolution (360 deg) of stage\n        travel - the maximum angular motion of stage (==360 for ELL8K)\n\n        Method used when sending instructions to move to stage\n        '''\n        pulses = int(np.rint(position*self.PULSES_PER_MM))\n        if self.debug > 0:\n            print(\"Input position:\", position)\n            print(\"Pulses:\", pulses)\n        return pulses",
  "def _pulse_count_to_position(self, pulse_count):\n        '''\n        Convert from an pulse count into the degrees. \n\n        pulses_per_revolution - specified by Thorlabs as number of pulses for a revolution (360 deg) of stage\n        travel - the maximum angular motion of stage (==360 for ELL8K)\n\n        Method used when reading data received from stage\n        '''\n        return pulse_count/self.PULSES_PER_MM",
  "def _position_to_hex_pulses(self, position):\n        '''\n        Convert position in range (-360.0,360.0) (exclusive of edges) into a hex representation of pulse\n        count required for talking to the ELL8K stage\n\n        '''\n\n        # convert position to number of pulses used to drive motors:\n        pulses_int = self._position_to_pulse_count(position)\n        if self.debug > 0:\n            print(\"Pulses (int)\", pulses_int)\n        # make two's complement to allow for -ve values\n        pulses_int = int_to_twos_complement(pulses_int)\n        if self.debug > 0:\n            print(\"Pulses (int,2s compl)\", pulses_int)\n        # convert integer to hex\n        pulses_hex = int_to_hex(pulses_int)\n        if self.debug > 0:\n            print(\"Pulses hex:\", pulses_hex)\n        return pulses_hex",
  "def _hex_pulses_to_position(self, hex_pulse_position):\n        '''\n        Convert position to position - full method for processing responses from stage\n        '''\n        binary_pulse_position = bytes_to_binary(hex_pulse_position)\n        int_pulse_position = twos_complement_to_int(binary_pulse_position)\n        return self._pulse_count_to_position(int_pulse_position)",
  "def move_absolute(self, position, blocking=True):\n        \"\"\"Move to absolute position relative to home setting\n\n        Args:\n            position (float): position to move to, specified in degrees.\n\n        Returns:\n            None\n\n        Raises:\n            None\n\n        \"\"\"\n\n        pulses_hex = self._position_to_hex_pulses(position)\n        response = self.query_device(\"ma{0}\".format(pulses_hex))\n\n        header = response[0:3]\n\n        if blocking:\n            self._block_until_stopped()\n        return self._decode_position_response(response)",
  "def get_position(self, axis=None):\n        '''\n        Query stage for its current position, in degrees\n        This method overrides the Stage class' method\n        '''\n        response = self.query_device(\"gp\")\n        header = response[0:3]\n        if header == \"{0}PO\".format(self.device_index):\n            # position given in twos complement representation\n            byte_position = response[3:11]\n            binary_position = bytes_to_binary(byte_position)\n            pulse_position = twos_complement_to_int(binary_position)\n            position = float(pulse_position)/self.PULSES_PER_MM\n            return position\n        else:\n            raise ValueError(\"Incompatible Header received:{}\".format(header))",
  "def move_home(self, blocking=True):\n        '''\n        Move stage to factory default home location. \n        Note: Thorlabs API allows resetting stages home but this not implemented as it isnt' advised \n        '''\n\n        response = self.query_device(\"ho\")\n        if blocking:\n            self._block_until_stopped()\n        return self._decode_position_response(response)",
  "def get_qt_ui(self):\n        return ELL20UI(self)",
  "def __init__(self, stage):\n        super().__init__()\n        self.add_doublespinbox('position', 0, stage.TRAVEL)\n        self.auto_connect_by_name(controlled_object=stage)",
  "def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)",
  "def get_slot(self):\n        frac = self.get_position() / self.TRAVEL\n        for i, slot in enumerate(self.SLOTS):\n            if abs(frac - slot) < self.TOLERANCE:\n                return i\n        self.log('not in either position', level='warn')",
  "def set_slot(self, index):\n        self.move(self.SLOTS[index]*self.TRAVEL)",
  "def center(self):\n        slot = min(enumerate(self.SLOTS),\n                   key=lambda i_s: abs(i_s[1] - (self.get_position() / self.TRAVEL)))[0]\n        self.slot = slot",
  "def get_qt_ui(self):\n        return Ell20BiPositionalUi(self)",
  "def __init__(self, stage):\n        super().__init__()\n\n        self.add_spinbox('slot', 0, len(stage.SLOTS))\n        self.auto_connect_by_name(controlled_object=stage)",
  "class Ell9(Ell6):\n    positions = 4\n\n    def get_qt_ui(self):\n        '''\n        Get UI for stage\n        '''\n\n        return ELL9UI(self)",
  "class ELL6UI(QuickControlBox):\n    def __init__(self, instr):\n        super().__init__('ELL6')\n        self.add_spinbox('position', vmin=0, vmax=1)\n        self.auto_connect_by_name(controlled_object=instr)",
  "class ELL9UI(QuickControlBox):\n    def __init__(self, instr):\n        super().__init__('ELL9')\n        self.add_spinbox('position', vmin=0, vmax=3)\n        self.auto_connect_by_name(controlled_object=instr)",
  "def get_qt_ui(self):\n        '''\n        Get UI for stage\n        '''\n\n        return ELL9UI(self)",
  "def __init__(self, instr):\n        super().__init__('ELL6')\n        self.add_spinbox('position', vmin=0, vmax=1)\n        self.auto_connect_by_name(controlled_object=instr)",
  "def __init__(self, instr):\n        super().__init__('ELL9')\n        self.add_spinbox('position', vmin=0, vmax=3)\n        self.auto_connect_by_name(controlled_object=instr)",
  "def bytes_to_binary(bytearr, debug=0):\n    '''\n    Helper method for converting a bytearray datatype to a binary representation\n    '''\n    if debug > 0: print(bytearr)\n    bytes_as_binary = [format(int(b, base=16), \"#06b\").replace(\n        \"0b\", \"\") for b in bytearr]\n    if debug > 0: print(bytes_as_binary)\n    binary = \"\".join(bytes_as_binary)\n    return binary",
  "def twos_complement_to_int(binary, debug=0):\n    '''\n    Compute 2s complement of binary number representation\n    '''\n    if debug > 0: print(binary)\n    N = len(binary)\n    a_N = int(binary[0])\n    return float(-a_N*2**(N-1) + int(binary[1:], base=2))",
  "def int_to_hex(integer, padded_length=8, debug=0):\n    '''\n    Convert integer number to hexidecimal. Return value is zero-padded at the beginning\n    until its length matches the value passed in \"padded_length\"\n    '''\n    outp = (format(integer, \"#0{}x\".format(\n        padded_length+2)).replace(\"0x\", \"\")).upper()\n    return outp",
  "def int_to_twos_complement(integer, padded_length=16, debug=0):\n    '''\n    Two's complement in integer representation. Padded length specifies the padding on the\n    binary representation used to compute the twos complement\n    '''\n    #number is above 0 - return binary representation:\n    if integer >= 0:\n        return integer\n\n    #number is below zero - return twos complement representation:\n    elif integer < 0:\n        if debug > 0: print(\"Below zero - returning twos complement\")\n        integer = -1*integer\n        binary = format(integer, \"0{}b\".format(\n            padded_length+2)).replace(\"0b\", \"\")\n        ones_complement = [str(1-int(b)) for b in str(binary)]\n        ones_complement = int(\"\".join(ones_complement))\n        twos_complement = int(\"0b\"+str(ones_complement), base=2) + 1\n        twos_complement = format(twos_complement, \"034b\").replace(\"0b\", \"\")\n        if debug > 0:\n            print(\"input:\", integer)\n            print(\"binary:\", binary)\n            print(\"ones comp:\", ones_complement)\n            print(\"twos comp (int):\", int(twos_complement, base=2))\n        return int(\"0b\"+twos_complement, base=2)",
  "class BusDistributor(SerialInstrument):\n    ''' a class to handle the port settings of a thorlabs ELLB distributor bus.\n    Each of these can have several devices attached. They are assigned device\n    indices by the thorlabs Ello software - otherwise they all default to 0 and\n    don't work separately.\n    '''\n\n    def __init__(self, port):\n        self.termination_character = '\\n'\n        self.port_settings = dict(baudrate=9600,\n                                  bytesize=8,\n                                  stopbits=1,\n                                  parity='N',\n                                  timeout=2,\n                                  writeTimeout=2,\n                                  xonxoff=False)\n        super().__init__(port)",
  "def flushed(f):\n    @wraps(f)\n    def inner(self, *args, **kwargs):\n        self.serial_device.flush_input_buffer()\n        retval = f(self, *args, **kwargs)\n        self.serial_device.flush_input_buffer()\n        return retval\n    return inner",
  "class ElloDevice(Stage):\n\n    # default id is 0, but if multiple devices of same type connected may have others\n    VALID_DEVICE_IDs = [str(v) for v in list(\n        range(0, 11)) + [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\"]]\n\n    # How much a stage sleeps (in seconds) between successive calls to .get_position.\n    # Used to make blocking calls to move_absolute and move_relative.\n    BLOCK_SLEEPING_TIME = 0.1\n    # Theshold for position accuracy when stage is meant to be stationary\n    # If difference between successive calls to get_position returns value\n    # whose difference is less than jitter - consider stage to have stopped\n    POSITION_JITTER_THRESHOLD = 0.02\n    BLOCK_TIMEOUT = 4. \n    # human readable status codes\n    DEVICE_STATUS_CODES = {\n        0: \"OK, no error\",\n        1: \"Communication Timeout\",\n        2: \"Mechanical time out\",\n        3: \"Command error or not supported\",\n        4: \"Value out of range\",\n        5: \"Module isolated\",\n        6: \"Module out of isolation\",\n        7: \"Initialization error\",\n        8: \"Thermal error\",\n        9: \"Busy\",\n        10: \"Sensor Error\",\n        11: \"Motor Error\",\n        12: \"Out of Range\",\n        13: \"Over current error\",\n        14: \"OK, no error\",\n        \"OutOfBounds\": \"Reserved\"\n    }\n\n    def __init__(self, serial_device, device_index=0, debug=0):\n        '''can be passed either a BusDistributor instance, or  \"COM5\"  '''\n        if type(serial_device) is str:\n            self.serial_device = BusDistributor(serial_device)\n        elif isinstance(serial_device, BusDistributor):\n            self.serial_device = serial_device\n        else:\n            raise TypeError('ello device is wrong type')\n        self.debug = debug\n        if str(device_index) not in self.VALID_DEVICE_IDs:\n            raise ValueError(\n                \"Device ID: {} is not valid!\".format(device_index))\n        self.device_index = device_index\n        Stage.__init__(self)\n        self.ui = None\n        # self.configuration = self.get_device_info()\n        \n    \n    @flushed\n    def query_device(self, query):\n        '''\n        Wrap a generic query with the ID of the device (integer in range: 0-F)\n        so that we dont need to be explicit about this id\n        '''\n        raw_query = \"{0}{1}\".format(self.device_index, query)\n        if self.debug > 0:\n            print(\"raw_query\", raw_query)\n        raw_response = self.serial_device.query(raw_query)\n        if self.debug > 0:\n            print(\"raw_response\", raw_response)\n        return raw_response\n\n    def _angle_to_pulse_count(self, angle):\n        '''\n        Convert from an angle (specified in degrees) into the number of pulses\n        that need to be applied to the motor to turn it. \n\n        pulses_per_revolution - specified by Thorlabs as number of pulses for a revolution (360 deg) of stage\n        travel - the maximum angular motion of stage (==360 for ELL8K)\n\n        Method used when sending instructions to move to stage\n        '''\n        pulse_per_deg = self.PULSES_PER_REVOLUTION/float(self.TRAVEL)\n        pulses = int(np.rint(angle*pulse_per_deg))\n        if self.debug > 0:\n            print(\"Input angle:\", angle)\n            print(\"Pulses:\", pulses)\n        return pulses\n\n    def _pulse_count_to_angle(self, pulse_count):\n        '''\n        Convert from an pulse count into the degrees. \n\n        pulses_per_revolution - specified by Thorlabs as number of pulses for a revolution (360 deg) of stage\n        travel - the maximum angular motion of stage (==360 for ELL8K)\n\n        Method used when reading data received from stage\n        '''\n        return float(self.TRAVEL)*pulse_count/self.PULSES_PER_REVOLUTION\n\n    def _angle_to_hex_pulses(self, angle):\n        '''\n        Convert angle in range (-360.0,360.0) (exclusive of edges) into a hex representation of pulse\n        count required for talking to the ELL8K stage\n\n        '''\n        if angle < -360.0 or angle > 360.0:\n            raise ValueError(\"Valid angle bounds are: (-360,360) [exclusive]\")\n\n        # convert angle to number of pulses used to drive motors:\n        pulses_int = self._angle_to_pulse_count(angle)\n        if self.debug > 0:\n            print(\"Pulses (int)\", pulses_int)\n        # make two's complement to allow for -ve values\n        pulses_int = int_to_twos_complement(pulses_int)\n        if self.debug > 0:\n            print(\"Pulses (int,2s compl)\", pulses_int)\n        # convert integer to hex\n        pulses_hex = int_to_hex(pulses_int)\n        if self.debug > 0:\n            print(\"Pulses hex:\", pulses_hex)\n        return pulses_hex\n\n    def _hex_pulses_to_angle(self, hex_pulse_position):\n        '''\n        Convert position to angle - full method for processing responses from stage\n        '''\n        binary_pulse_position = bytes_to_binary(hex_pulse_position)\n        int_pulse_position = twos_complement_to_int(binary_pulse_position)\n        return self._pulse_count_to_angle(int_pulse_position)\n\n    def _decode_position_response(self, response):\n        '''\n        Method for decoding positional response from stage for responses from:\n            mode_absolute, mode_relative, move_home\n        '''\n        header = response[0:3]\n        if header == \"{0}GS\".format(self.device_index):\n            # still moving\n            status_code = int(response[3:5], base=16)\n            status = self.DEVICE_STATUS_CODES[status_code]\n            outp = {\"header\": header, \"status\": status}\n            return outp\n        elif header == \"{0}PO\".format(self.device_index):\n            hex_pulse_position = response[3:11]\n            position = self._hex_pulses_to_angle(hex_pulse_position)\n            outp = {\"header\": header, \"position\": position}\n            return outp\n\n    def _block_until_stopped(self):\n        '''\n        Method for blocking move_absolute and move_relative and move_home commands until stage has stopped\n        Spins on get_position command comparing returned results. If between two calls position doesn't change\n        Then assume stage has stopped and exit\n        '''\n        # stopped = False\n        previous_angle = np.inf\n        # current_angle = 1.0\n\n        start = time.time()\n        \n        while time.time() - start < self.BLOCK_TIMEOUT:\n            try:\n                current_angle = self.position\n            except ValueError:\n                continue\n            if (np.absolute(current_angle - previous_angle) < self.POSITION_JITTER_THRESHOLD):\n                break\n            time.sleep(self.BLOCK_SLEEPING_TIME)\n            previous_angle = current_angle\n    \n\n    def get_position(self, axis=None):\n        raise NotImplementedError('must subclass')\n        # '''\n        # Query stage for its current position, in degrees\n        # This method overrides the Stage class' method\n        # '''\n        # response = self.query_device(\"gp\")\n        # header = response[0:3]\n        # if header == \"{0}PO\".format(self.device_index):\n        #     # position given in twos complement representation\n        #     byte_position = response[3:11]\n        #     binary_position = bytes_to_binary(byte_position)\n        #     pulse_position = twos_complement_to_int(binary_position)\n        #     degrees_position = self.TRAVEL * \\\n        #         (float(pulse_position)/self.PULSES_PER_REVOLUTION)\n        #     return degrees_position\n        # else:\n        #     raise ValueError(\"Incompatible Header received:{}\".format(header))\n\n    def move(self, pos, axis=None, relative=False):\n        '''\n        Send command to move stage.\n        pos:  specified in degrees and can be in range (-360,360)\n        relative: whether motion is relative to current position or relative to global home\n        This method overrides the Stage class' method\n        '''\n        if relative:\n            self.move_relative(pos)\n        else:\n            self.move_absolute(pos)\n\n\n    def get_device_info(self):\n        '''\n        Instruct hardware to identify itself. \n        Give information about model, serial numbner, firmware. \n\n        This MUST be called at initialization of the stage as the key parameters:\n\n        TRAVEL, PULSES are extracted here\n\n        TRAVEL - the range of travel of the stage, specified in units (mm or deg) relevant to the type of stage\n        PULSES - specifieid the number of pulses applied to motors to move stage over entire range of travel\n\n        Hence: ratio of PULSES/TRAVEL gives number of pulses to move 1 mm or 1 deg\n        '''\n\n        response = self.query_device(\"in\")\n    \n        # decode the response\n        header = response[0:3]\n        ell = response[3:5]\n        sn = response[5:13]\n        year = response[13:17]\n        firmware_release = response[17:19]\n        hardware_release = response[19:21]\n\n        bytes_travel = response[21:25]  # units: mm/deg\n\n        binary_travel = bytes_to_binary(bytes_travel)\n        travel = twos_complement_to_int(binary_travel)\n\n        bytes_pulses = response[25:33]\n        binary_pulses = bytes_to_binary(bytes_pulses)\n        pulses = twos_complement_to_int(binary_pulses)\n\n        outp = {\n            \"header\": header,\n            \"ell\": ell,\n            \"sn\": sn,\n            \"year\": year,\n            \"firmware_release\": firmware_release,\n            \"hardware_release\": hardware_release,\n            \"travel\": travel,\n            \"pulses\": pulses\n        }\n        return outp\n\n    def get_device_status(self):\n        '''\n        Query device to get its status code  - for testing that device is functioning correctly\n        '''\n\n        response = self.query_device(\"gs\")\n        # read response and decode it:\n        header = response[0:3]\n        byte_status = response[3:5]\n        if self.debug > 0:\n            print(\"Byte status:\", byte_status)\n\n        binary_status = bytes_to_binary(byte_status)\n        if self.debug > 0:\n            print(\"Binary status\", binary_status)\n        int_status = int(binary_status, base=2)\n\n        if int_status in list(Thorlabs_ELL8K.DEVICE_STATUS_CODES.keys()):\n            return {\"header\": header, \"status\": Thorlabs_ELL8K.DEVICE_STATUS_CODES[int_status]}\n        else:\n            return {\"header\": header, \"status\": Thorlabs_ELL8K.DEVICE_STATUS_CODES[\"OutOfBounds\"]}\n\n    def move_home(self, clockwise=True, blocking=True):\n        '''\n        Move stage to factory default home location. \n        Note: Thorlabs API allows resetting stages home but this not implemented as it isnt' advised \n        '''\n        if clockwise:\n            direction = 0\n        else:\n            direction = 1\n        response = self.query_device(\"ho{0}\".format(direction))\n\n        if blocking:\n            self._block_until_stopped()\n        return self._decode_position_response(response)\n\n    def move_absolute(self, angle, blocking=True):\n        \"\"\"Move to absolute position relative to home setting\n\n        Args:\n            angle (float): angle to move to, specified in degrees.\n\n        Returns:\n            None\n\n        Raises:\n            None\n\n        \"\"\"\n        \n        pulses_hex = self._angle_to_hex_pulses(angle)\n        response = self.query_device(\"ma{0}\".format(pulses_hex))\n        header = response[0:3]\n        if blocking:\n            self._block_until_stopped()\n        return self._decode_position_response(response)\n\n    def move_relative(self, angle, blocking=True):\n        \"\"\"Moves relative to current position\n\n        Args:\n            angle (float): relative angle to move to, specified in degrees.\n            clockwise(bool): specifies whether we are moving in the clockwise direction. \n                    False if moving anticlockwise\n\n        Returns:\n            None\n\n        Raises:\n            None\n\n        \"\"\"\n        pulses_hex = self._angle_to_hex_pulses(angle)\n        response = self.query_device(\"mr{0}\".format(pulses_hex))\n        if blocking:\n            self._block_until_stopped()\n        return self._decode_position_response(response)\n\n    def optimize_motors(self, save_new_params=False):\n        '''Due to load, build tolerances and other mechanical variances, the\n        default resonating frequency of a particular motor may not be that\n        which delivers best performance.\n        This message fine tunes the frequency search performed by the\n        SEARCHFREQ messages. When this message is called, the\n        SEARCHFREQ message is called first automatically to optimize the\n        operating frequency. After completion, another frequency search is\n        performed and the mechanical performance is monitored to further\n        optimize the operating frequencies for backward and forward\n        movement. The values then need to be saved\n        '''\n        reply = self.query_device('om')\n        if save_new_params:\n            self.save_new_parameters()\n        return reply\n\n    def save_new_parameters(self):\n        return self.query_device('us')",
  "def __init__(self, port):\n        self.termination_character = '\\n'\n        self.port_settings = dict(baudrate=9600,\n                                  bytesize=8,\n                                  stopbits=1,\n                                  parity='N',\n                                  timeout=2,\n                                  writeTimeout=2,\n                                  xonxoff=False)\n        super().__init__(port)",
  "def inner(self, *args, **kwargs):\n        self.serial_device.flush_input_buffer()\n        retval = f(self, *args, **kwargs)\n        self.serial_device.flush_input_buffer()\n        return retval",
  "def __init__(self, serial_device, device_index=0, debug=0):\n        '''can be passed either a BusDistributor instance, or  \"COM5\"  '''\n        if type(serial_device) is str:\n            self.serial_device = BusDistributor(serial_device)\n        elif isinstance(serial_device, BusDistributor):\n            self.serial_device = serial_device\n        else:\n            raise TypeError('ello device is wrong type')\n        self.debug = debug\n        if str(device_index) not in self.VALID_DEVICE_IDs:\n            raise ValueError(\n                \"Device ID: {} is not valid!\".format(device_index))\n        self.device_index = device_index\n        Stage.__init__(self)\n        self.ui = None",
  "def query_device(self, query):\n        '''\n        Wrap a generic query with the ID of the device (integer in range: 0-F)\n        so that we dont need to be explicit about this id\n        '''\n        raw_query = \"{0}{1}\".format(self.device_index, query)\n        if self.debug > 0:\n            print(\"raw_query\", raw_query)\n        raw_response = self.serial_device.query(raw_query)\n        if self.debug > 0:\n            print(\"raw_response\", raw_response)\n        return raw_response",
  "def _angle_to_pulse_count(self, angle):\n        '''\n        Convert from an angle (specified in degrees) into the number of pulses\n        that need to be applied to the motor to turn it. \n\n        pulses_per_revolution - specified by Thorlabs as number of pulses for a revolution (360 deg) of stage\n        travel - the maximum angular motion of stage (==360 for ELL8K)\n\n        Method used when sending instructions to move to stage\n        '''\n        pulse_per_deg = self.PULSES_PER_REVOLUTION/float(self.TRAVEL)\n        pulses = int(np.rint(angle*pulse_per_deg))\n        if self.debug > 0:\n            print(\"Input angle:\", angle)\n            print(\"Pulses:\", pulses)\n        return pulses",
  "def _pulse_count_to_angle(self, pulse_count):\n        '''\n        Convert from an pulse count into the degrees. \n\n        pulses_per_revolution - specified by Thorlabs as number of pulses for a revolution (360 deg) of stage\n        travel - the maximum angular motion of stage (==360 for ELL8K)\n\n        Method used when reading data received from stage\n        '''\n        return float(self.TRAVEL)*pulse_count/self.PULSES_PER_REVOLUTION",
  "def _angle_to_hex_pulses(self, angle):\n        '''\n        Convert angle in range (-360.0,360.0) (exclusive of edges) into a hex representation of pulse\n        count required for talking to the ELL8K stage\n\n        '''\n        if angle < -360.0 or angle > 360.0:\n            raise ValueError(\"Valid angle bounds are: (-360,360) [exclusive]\")\n\n        # convert angle to number of pulses used to drive motors:\n        pulses_int = self._angle_to_pulse_count(angle)\n        if self.debug > 0:\n            print(\"Pulses (int)\", pulses_int)\n        # make two's complement to allow for -ve values\n        pulses_int = int_to_twos_complement(pulses_int)\n        if self.debug > 0:\n            print(\"Pulses (int,2s compl)\", pulses_int)\n        # convert integer to hex\n        pulses_hex = int_to_hex(pulses_int)\n        if self.debug > 0:\n            print(\"Pulses hex:\", pulses_hex)\n        return pulses_hex",
  "def _hex_pulses_to_angle(self, hex_pulse_position):\n        '''\n        Convert position to angle - full method for processing responses from stage\n        '''\n        binary_pulse_position = bytes_to_binary(hex_pulse_position)\n        int_pulse_position = twos_complement_to_int(binary_pulse_position)\n        return self._pulse_count_to_angle(int_pulse_position)",
  "def _decode_position_response(self, response):\n        '''\n        Method for decoding positional response from stage for responses from:\n            mode_absolute, mode_relative, move_home\n        '''\n        header = response[0:3]\n        if header == \"{0}GS\".format(self.device_index):\n            # still moving\n            status_code = int(response[3:5], base=16)\n            status = self.DEVICE_STATUS_CODES[status_code]\n            outp = {\"header\": header, \"status\": status}\n            return outp\n        elif header == \"{0}PO\".format(self.device_index):\n            hex_pulse_position = response[3:11]\n            position = self._hex_pulses_to_angle(hex_pulse_position)\n            outp = {\"header\": header, \"position\": position}\n            return outp",
  "def _block_until_stopped(self):\n        '''\n        Method for blocking move_absolute and move_relative and move_home commands until stage has stopped\n        Spins on get_position command comparing returned results. If between two calls position doesn't change\n        Then assume stage has stopped and exit\n        '''\n        # stopped = False\n        previous_angle = np.inf\n        # current_angle = 1.0\n\n        start = time.time()\n        \n        while time.time() - start < self.BLOCK_TIMEOUT:\n            try:\n                current_angle = self.position\n            except ValueError:\n                continue\n            if (np.absolute(current_angle - previous_angle) < self.POSITION_JITTER_THRESHOLD):\n                break\n            time.sleep(self.BLOCK_SLEEPING_TIME)\n            previous_angle = current_angle",
  "def get_position(self, axis=None):\n        raise NotImplementedError('must subclass')",
  "def move(self, pos, axis=None, relative=False):\n        '''\n        Send command to move stage.\n        pos:  specified in degrees and can be in range (-360,360)\n        relative: whether motion is relative to current position or relative to global home\n        This method overrides the Stage class' method\n        '''\n        if relative:\n            self.move_relative(pos)\n        else:\n            self.move_absolute(pos)",
  "def get_device_info(self):\n        '''\n        Instruct hardware to identify itself. \n        Give information about model, serial numbner, firmware. \n\n        This MUST be called at initialization of the stage as the key parameters:\n\n        TRAVEL, PULSES are extracted here\n\n        TRAVEL - the range of travel of the stage, specified in units (mm or deg) relevant to the type of stage\n        PULSES - specifieid the number of pulses applied to motors to move stage over entire range of travel\n\n        Hence: ratio of PULSES/TRAVEL gives number of pulses to move 1 mm or 1 deg\n        '''\n\n        response = self.query_device(\"in\")\n    \n        # decode the response\n        header = response[0:3]\n        ell = response[3:5]\n        sn = response[5:13]\n        year = response[13:17]\n        firmware_release = response[17:19]\n        hardware_release = response[19:21]\n\n        bytes_travel = response[21:25]  # units: mm/deg\n\n        binary_travel = bytes_to_binary(bytes_travel)\n        travel = twos_complement_to_int(binary_travel)\n\n        bytes_pulses = response[25:33]\n        binary_pulses = bytes_to_binary(bytes_pulses)\n        pulses = twos_complement_to_int(binary_pulses)\n\n        outp = {\n            \"header\": header,\n            \"ell\": ell,\n            \"sn\": sn,\n            \"year\": year,\n            \"firmware_release\": firmware_release,\n            \"hardware_release\": hardware_release,\n            \"travel\": travel,\n            \"pulses\": pulses\n        }\n        return outp",
  "def get_device_status(self):\n        '''\n        Query device to get its status code  - for testing that device is functioning correctly\n        '''\n\n        response = self.query_device(\"gs\")\n        # read response and decode it:\n        header = response[0:3]\n        byte_status = response[3:5]\n        if self.debug > 0:\n            print(\"Byte status:\", byte_status)\n\n        binary_status = bytes_to_binary(byte_status)\n        if self.debug > 0:\n            print(\"Binary status\", binary_status)\n        int_status = int(binary_status, base=2)\n\n        if int_status in list(Thorlabs_ELL8K.DEVICE_STATUS_CODES.keys()):\n            return {\"header\": header, \"status\": Thorlabs_ELL8K.DEVICE_STATUS_CODES[int_status]}\n        else:\n            return {\"header\": header, \"status\": Thorlabs_ELL8K.DEVICE_STATUS_CODES[\"OutOfBounds\"]}",
  "def move_home(self, clockwise=True, blocking=True):\n        '''\n        Move stage to factory default home location. \n        Note: Thorlabs API allows resetting stages home but this not implemented as it isnt' advised \n        '''\n        if clockwise:\n            direction = 0\n        else:\n            direction = 1\n        response = self.query_device(\"ho{0}\".format(direction))\n\n        if blocking:\n            self._block_until_stopped()\n        return self._decode_position_response(response)",
  "def move_absolute(self, angle, blocking=True):\n        \"\"\"Move to absolute position relative to home setting\n\n        Args:\n            angle (float): angle to move to, specified in degrees.\n\n        Returns:\n            None\n\n        Raises:\n            None\n\n        \"\"\"\n        \n        pulses_hex = self._angle_to_hex_pulses(angle)\n        response = self.query_device(\"ma{0}\".format(pulses_hex))\n        header = response[0:3]\n        if blocking:\n            self._block_until_stopped()\n        return self._decode_position_response(response)",
  "def move_relative(self, angle, blocking=True):\n        \"\"\"Moves relative to current position\n\n        Args:\n            angle (float): relative angle to move to, specified in degrees.\n            clockwise(bool): specifies whether we are moving in the clockwise direction. \n                    False if moving anticlockwise\n\n        Returns:\n            None\n\n        Raises:\n            None\n\n        \"\"\"\n        pulses_hex = self._angle_to_hex_pulses(angle)\n        response = self.query_device(\"mr{0}\".format(pulses_hex))\n        if blocking:\n            self._block_until_stopped()\n        return self._decode_position_response(response)",
  "def optimize_motors(self, save_new_params=False):\n        '''Due to load, build tolerances and other mechanical variances, the\n        default resonating frequency of a particular motor may not be that\n        which delivers best performance.\n        This message fine tunes the frequency search performed by the\n        SEARCHFREQ messages. When this message is called, the\n        SEARCHFREQ message is called first automatically to optimize the\n        operating frequency. After completion, another frequency search is\n        performed and the mechanical performance is monitored to further\n        optimize the operating frequencies for backward and forward\n        movement. The values then need to be saved\n        '''\n        reply = self.query_device('om')\n        if save_new_params:\n            self.save_new_parameters()\n        return reply",
  "def save_new_parameters(self):\n        return self.query_device('us')",
  "class Ell6(ElloDevice):\n    positions = 2\n\n    def __init__(self, serial_device, device_index=0, debug=0):\n        '''can be passed either a BusDistributor instance, or  \"COM5\"  '''\n        super().__init__(serial_device, device_index=0, debug=0)\n        self.home()\n\n    def home(self):\n        self.query_device('ho')\n        self._position = 0\n\n    def set_position(self, pos):\n        assert 0 <= pos < self.positions\n        \n        while pos > self._position:\n            self.move_forward()\n        while pos < self._position:\n            self.move_backward()\n        \n    def get_position(self):\n        return self._position\n   \n    position = NotifiedProperty(get_position, set_position)\n\n    def get_qt_ui(self):\n        '''\n        Get UI for stage\n        '''\n\n        return ELL6UI(self)\n\n    def move_forward(self):\n        self.query_device('fw')\n        self._position += 1\n\n    def move_backward(self):\n        self.query_device('bw')\n        self._position -= 1",
  "class ELL6UI(QuickControlBox):\n    def __init__(self, instr):\n        super().__init__('ELL6')\n        self.add_spinbox('position', vmin=0, vmax=1)\n        self.auto_connect_by_name(controlled_object=instr)",
  "def __init__(self, serial_device, device_index=0, debug=0):\n        '''can be passed either a BusDistributor instance, or  \"COM5\"  '''\n        super().__init__(serial_device, device_index=0, debug=0)\n        self.home()",
  "def home(self):\n        self.query_device('ho')\n        self._position = 0",
  "def set_position(self, pos):\n        assert 0 <= pos < self.positions\n        \n        while pos > self._position:\n            self.move_forward()\n        while pos < self._position:\n            self.move_backward()",
  "def get_position(self):\n        return self._position",
  "def get_qt_ui(self):\n        '''\n        Get UI for stage\n        '''\n\n        return ELL6UI(self)",
  "def move_forward(self):\n        self.query_device('fw')\n        self._position += 1",
  "def move_backward(self):\n        self.query_device('bw')\n        self._position -= 1",
  "def __init__(self, instr):\n        super().__init__('ELL6')\n        self.add_spinbox('position', vmin=0, vmax=1)\n        self.auto_connect_by_name(controlled_object=instr)",
  "class Ell8(ElloDevice):\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.configuration = self.get_device_info()\n        self.TRAVEL = self.configuration[\"travel\"]\n        self.PULSES_PER_REVOLUTION = self.configuration[\"pulses\"]\n        if self.debug > 0:\n            print(\"Travel (degrees):\", self.TRAVEL)\n            print(\"Pulses per revolution\", self.PULSES_PER_REVOLUTION)\n            print(\"Device status:\", self.get_device_status())\n    \n    def get_position(self, axis=None):\n        '''\n        Query stage for its current position, in degrees\n        This method overrides the Stage class' method\n        '''\n        response = self.query_device(\"gp\")\n        header = response[0:3]\n        if header == \"{0}PO\".format(self.device_index):\n            # position given in twos complement representation\n            byte_position = response[3:11]\n            binary_position = bytes_to_binary(byte_position)\n            pulse_position = twos_complement_to_int(binary_position)\n            degrees_position = self.TRAVEL * \\\n                (float(pulse_position)/self.PULSES_PER_REVOLUTION)\n            return degrees_position\n        else:\n            raise ValueError(\"Incompatible Header received:{}\".format(header))\n    def move_absolute(self, angle, blocking=True):\n        \"\"\"Move to absolute position relative to home setting\n\n        Args:\n            angle (float): angle to move to, specified in degrees.\n\n        Returns:\n            None\n\n        Raises:\n            None\n\n        \"\"\"\n        if -360 > angle or angle > 360:\n            angle %= 360\n        if angle < 0:\n            angle = 360+angle\n        return super().move_absolute(angle, blocking=blocking)",
  "class Thorlabs_ELL8K_UI(QtWidgets.QWidget, UiTools):\n\n    def __init__(self, stage, parent=None, debug=0):\n        if not isinstance(stage, Thorlabs_ELL8K):\n            raise ValueError(\n                \"Object is not an instance of the Thorlabs_ELL8K Stage\")\n        super(Thorlabs_ELL8K_UI, self).__init__()\n        \n        self.stage = stage  # this is the actual rotation stage\n        self.parent = parent\n        self.debug = debug\n\n        uic.loadUi(os.path.join(os.path.dirname(\n            __file__), 'thorlabs_ell8k.ui'), self)\n\n        self.move_relative_btn.clicked.connect(self.move_relative)\n        self.move_absolute_btn.clicked.connect(self.move_absolute)\n        self.move_home_btn.clicked.connect(self.move_home)\n        self.current_angle_btn.clicked.connect(self.update_current_angle)\n\n    def move_relative(self):\n        try:\n            angle = float(self.move_relative_textbox.text())\n        except ValueError as e:\n            print(e)\n            return\n        self.stage.move(pos=angle, relative=True)\n\n    def move_absolute(self):\n        try:\n            angle = float(self.move_absolute_textbox.text())\n        except ValueError as e:\n            print(e)\n            return\n        self.stage.move(pos=angle, relative=False)\n\n    def move_home(self):\n        self.stage.move_home()\n\n    def update_current_angle(self):\n        angle = self.stage.get_position()\n        self.current_angle_value.setText(str(angle))",
  "def test_stage(s):\n    '''\n    Run from main to test stage\n    '''\n    debug = False\n\n    print(\"Status\", s.get_device_status())\n    print(\"Info\", s.get_device_info())\n    print(\"Homing\", s.move_home())\n    print(\"Home position\", s.get_position())\n    angle = 30\n    s.move(angle, relative=True)\n    print(\"30==\", s.get_position())\n    angle = -30\n    s.move(angle, relative=True)\n    print(\"-30==\", s.get_position())\n\n    angle = 150\n    s.move(angle, relative=False)\n    print(\"150==\", s.get_position())\n\n    angle = -10\n    s.move(angle, relative=False)\n    print(\"350==\", s.get_position())",
  "def test_ui():\n    '''\n    Run from main to test ui + stage\n    '''\n    s = Thorlabs_ELL8K(\"COM1\")\n    app = get_qt_app()\n    ui = Thorlabs_ELL8K_UI(stage=s)\n    ui.show()\n    sys.exit(app.exec_())",
  "def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.configuration = self.get_device_info()\n        self.TRAVEL = self.configuration[\"travel\"]\n        self.PULSES_PER_REVOLUTION = self.configuration[\"pulses\"]\n        if self.debug > 0:\n            print(\"Travel (degrees):\", self.TRAVEL)\n            print(\"Pulses per revolution\", self.PULSES_PER_REVOLUTION)\n            print(\"Device status:\", self.get_device_status())",
  "def get_position(self, axis=None):\n        '''\n        Query stage for its current position, in degrees\n        This method overrides the Stage class' method\n        '''\n        response = self.query_device(\"gp\")\n        header = response[0:3]\n        if header == \"{0}PO\".format(self.device_index):\n            # position given in twos complement representation\n            byte_position = response[3:11]\n            binary_position = bytes_to_binary(byte_position)\n            pulse_position = twos_complement_to_int(binary_position)\n            degrees_position = self.TRAVEL * \\\n                (float(pulse_position)/self.PULSES_PER_REVOLUTION)\n            return degrees_position\n        else:\n            raise ValueError(\"Incompatible Header received:{}\".format(header))",
  "def move_absolute(self, angle, blocking=True):\n        \"\"\"Move to absolute position relative to home setting\n\n        Args:\n            angle (float): angle to move to, specified in degrees.\n\n        Returns:\n            None\n\n        Raises:\n            None\n\n        \"\"\"\n        if -360 > angle or angle > 360:\n            angle %= 360\n        if angle < 0:\n            angle = 360+angle\n        return super().move_absolute(angle, blocking=blocking)",
  "def __init__(self, stage, parent=None, debug=0):\n        if not isinstance(stage, Thorlabs_ELL8K):\n            raise ValueError(\n                \"Object is not an instance of the Thorlabs_ELL8K Stage\")\n        super(Thorlabs_ELL8K_UI, self).__init__()\n        \n        self.stage = stage  # this is the actual rotation stage\n        self.parent = parent\n        self.debug = debug\n\n        uic.loadUi(os.path.join(os.path.dirname(\n            __file__), 'thorlabs_ell8k.ui'), self)\n\n        self.move_relative_btn.clicked.connect(self.move_relative)\n        self.move_absolute_btn.clicked.connect(self.move_absolute)\n        self.move_home_btn.clicked.connect(self.move_home)\n        self.current_angle_btn.clicked.connect(self.update_current_angle)",
  "def move_relative(self):\n        try:\n            angle = float(self.move_relative_textbox.text())\n        except ValueError as e:\n            print(e)\n            return\n        self.stage.move(pos=angle, relative=True)",
  "def move_absolute(self):\n        try:\n            angle = float(self.move_absolute_textbox.text())\n        except ValueError as e:\n            print(e)\n            return\n        self.stage.move(pos=angle, relative=False)",
  "def move_home(self):\n        self.stage.move_home()",
  "def update_current_angle(self):\n        angle = self.stage.get_position()\n        self.current_angle_value.setText(str(angle))",
  "class StaticTuner(Controller):\n\t#Control the output of one intrument using another instrument\n\n\tdef __init__(self, sensor,actuator, sensor_bounds, actuator_bounds, ac0=None):\n\n\t\t'''\n\t\t@param sensor - the device returning the parameter that we wish to tune\n\t\t\n\t\t\tThis controller will assume that the sensor has method .get_output_state_value() method implemented\n\n\t\t@param actuator - the device, typically a stage whose setting we change to affect the output of the sensor\n\t\n\n\t\n\t\t@param sensor_bounds - specifies lower and upper bound on acceptable values of the sensor output\n\t\t\tuseful for constraining the acutator to prevent damage to the sensor\n\n\t\t@param actuator_bounds - bounds on the actuator parameters.\n\t\t\tExample: linear stage will have a minimum and maximum displacement from zero in either direction\n\n\t\t@param ac0 - initial position of the actuator from which we start the tuning stage\n\t\t\n\n\n\t\t'''\n\n\t\tController.__init__(self,sensor = sensor, actuator = actuator, sensor_bounds = sensor_bounds, actuator_bounds = actuator_bounds)\n\t\t\n\n\n\tdef calibrate(self,ac0):\n\n\t\t#min and max sensor values\n\t\tsensor_min = self.sensor_bounds[0]\n\t\tsensor_max = self.sensor_bounds[1]\n\n\t\tactuator_min = self.actuator_bounds[0]\n\t\tactuator_max = self.actuator_bounds[1]\n\n\n\t\tcalibration_samples = 10\n\n\n\t\tself.calibration = np.zeros((calibration_samples,2))\n\t\tsize_step = (actuator_max-actuator_min)/float(calibration_samples)\n\t\t\n\t\tactuator_positions = [ac0] \n\t\tfor i in range(1,calibration_samples,2):\n\t\t\tactuator_positions = actuator_positions + [ac0+i*size_step, ac0-i*size_step]\n\t\t\tprint(actuator_positions)\n\n\t\tpass\n\n\tdef update_calibration(self,sensor_value, actuator_value):\n\t\tpass\n\n\tdef get_required_actuator_value(self,sensor_value):\n\t\tif self.calibration_data is None:\n\t\t\traise ValueError(\"You need to calibrate the controller before you use it!\")\n\t\telse:\n\t\t\traise NotImplementedError",
  "def __init__(self, sensor,actuator, sensor_bounds, actuator_bounds, ac0=None):\n\n\t\t'''\n\t\t@param sensor - the device returning the parameter that we wish to tune\n\t\t\n\t\t\tThis controller will assume that the sensor has method .get_output_state_value() method implemented\n\n\t\t@param actuator - the device, typically a stage whose setting we change to affect the output of the sensor\n\t\n\n\t\n\t\t@param sensor_bounds - specifies lower and upper bound on acceptable values of the sensor output\n\t\t\tuseful for constraining the acutator to prevent damage to the sensor\n\n\t\t@param actuator_bounds - bounds on the actuator parameters.\n\t\t\tExample: linear stage will have a minimum and maximum displacement from zero in either direction\n\n\t\t@param ac0 - initial position of the actuator from which we start the tuning stage\n\t\t\n\n\n\t\t'''\n\n\t\tController.__init__(self,sensor = sensor, actuator = actuator, sensor_bounds = sensor_bounds, actuator_bounds = actuator_bounds)",
  "def calibrate(self,ac0):\n\n\t\t#min and max sensor values\n\t\tsensor_min = self.sensor_bounds[0]\n\t\tsensor_max = self.sensor_bounds[1]\n\n\t\tactuator_min = self.actuator_bounds[0]\n\t\tactuator_max = self.actuator_bounds[1]\n\n\n\t\tcalibration_samples = 10\n\n\n\t\tself.calibration = np.zeros((calibration_samples,2))\n\t\tsize_step = (actuator_max-actuator_min)/float(calibration_samples)\n\t\t\n\t\tactuator_positions = [ac0] \n\t\tfor i in range(1,calibration_samples,2):\n\t\t\tactuator_positions = actuator_positions + [ac0+i*size_step, ac0-i*size_step]\n\t\t\tprint(actuator_positions)\n\n\t\tpass",
  "def update_calibration(self,sensor_value, actuator_value):\n\t\tpass",
  "def get_required_actuator_value(self,sensor_value):\n\t\tif self.calibration_data is None:\n\t\t\traise ValueError(\"You need to calibrate the controller before you use it!\")\n\t\telse:\n\t\t\traise NotImplementedError",
  "class Sensor(Instrument):\n\n\tdef __init__(self):\n\t\tInstrument.__init__(self)\n\n\n\tdef get_sensor_value():\n\t\traise NotImplementedError",
  "class Actuator(Instrument):\n\n\tdef __init__(self):\n\t\tInstrument.__init__(self)\n\n\tdef set_actuator_value(value):\n\t\traise NotImplementedError",
  "class Controller(Instrument):\n\n\n\tdef __init__(self,sensor,actuator, sensor_bounds, actuator_bounds):\n\n\t\tself.sensor = sensor\n\t\tself.actuator = actuator \n\t\tself.sensor_bounds = sensor_bounds\n\t\tself.actuator_bounds = actuator_bounds\n\n\t\tself.calibration_data = None\n\t'''\n\tGenerate datastructure that can later be queried to get the required actuator coordinates for setting the sensor\n\n\t'''\n\tdef calibrate(ac0):\n\t\t'''\n\t\t@param ac0 - initial position of actuator - around which would would like to control\n\t\t'''\n\t\traise NotImplementedError\n\n\t'''\n\tUsed to update calibration data to incorporate new information at runtime \n\t'''\n\tdef update_calibration(sensor_value, actuator_value):\n\t\tif self.calibration_data is None:\n\t\t\traise ValueError(\"You need to calibrate the controller before you use it!\")\n\t\telse:\n\t\t\traise NotImplementedError\n\n\n\tdef get_required_actuator_value(sensor_value):\n\t\tif self.calibration_data is None:\n\t\t\traise ValueError(\"You need to calibrate the controller before you use it!\")\n\t\telse:\n\t\t\traise NotImplementedError\n\t'''\n\tUse calibration data to set the actuator to level required for desired sensor output value\n\t'''\n\tdef set_sensor_to(value):\n\t\tactuator_value = self.get_required_actuator_value(value)\n\t\tself.actuator.set_actuator_value(actuator_value)\n\t\treturn",
  "def __init__(self):\n\t\tInstrument.__init__(self)",
  "def get_sensor_value():\n\t\traise NotImplementedError",
  "def __init__(self):\n\t\tInstrument.__init__(self)",
  "def set_actuator_value(value):\n\t\traise NotImplementedError",
  "def __init__(self,sensor,actuator, sensor_bounds, actuator_bounds):\n\n\t\tself.sensor = sensor\n\t\tself.actuator = actuator \n\t\tself.sensor_bounds = sensor_bounds\n\t\tself.actuator_bounds = actuator_bounds\n\n\t\tself.calibration_data = None",
  "def calibrate(ac0):\n\t\t'''\n\t\t@param ac0 - initial position of actuator - around which would would like to control\n\t\t'''\n\t\traise NotImplementedError",
  "def update_calibration(sensor_value, actuator_value):\n\t\tif self.calibration_data is None:\n\t\t\traise ValueError(\"You need to calibrate the controller before you use it!\")\n\t\telse:\n\t\t\traise NotImplementedError",
  "def get_required_actuator_value(sensor_value):\n\t\tif self.calibration_data is None:\n\t\t\traise ValueError(\"You need to calibrate the controller before you use it!\")\n\t\telse:\n\t\t\traise NotImplementedError",
  "def set_sensor_to(value):\n\t\tactuator_value = self.get_required_actuator_value(value)\n\t\tself.actuator.set_actuator_value(actuator_value)\n\t\treturn",
  "class Digikrom(SerialInstrument):\n    port_settings = dict(baudrate=9600,\n                        bytesize=serial.EIGHTBITS,\n                        parity=serial.PARITY_NONE,\n                        stopbits=serial.STOPBITS_ONE,\n                        timeout=1, #wait at most one second for a response\n                        writeTimeout=1, #similarly, fail if writing takes >1s\n                        xonxoff=False, rtscts=False, dsrdtr=False,\n                    )\n    def __init__(self,port = None,serial_number = [50, 52, 51, 49, 55]):\n        self.termination_character = ''\n        self.serial_number = serial_number\n        super(Digikrom, self).__init__(port=port)\n    def query(self,message,convert_to_hex = True,return_as_dec = True,\n              max_len_returned = 10,block = True):\n        \"\"\"The digikrom uses fixed length commands and has no termination character\n        therefore the query function from serialinstrument needs to be overwritten.\n        As the digikrom requires input in hex commands must be changed from decimal\n        (as listed in the manual) to hex. The returned messages also need the same treatment\n        The maximum length of the returned str can also be specified to maximise speed\n        as currently it just waits for timeout\"\"\"\n        if convert_to_hex==True:\n            message_hex = self.encode_bytes(message)\n        else:\n            message_hex = message\n        self.write(message_hex)\n        returned_message = self.ser.read(max_len_returned)\n        if return_as_dec == True:\n            returned_message = self.decode_bytes(returned_message)\n\n        if returned_message[-1]==24:\n            block = False\n            self.set_status_byte(returned_message[-2])\n        elif(returned_message!=[message]):\n            self.set_status_byte(returned_message[-1])\n            while block == True:\n                block_message = self.decode_bytes(self.ser.read_all())\n                if len(block_message)==1:\n                    if block_message[0] == 24:\n                        block = False\n        return returned_message\n\n    @staticmethod\n    def decode_bytes(byte_str):\n        \"\"\"The digikrom uses decimal charcters therefore it is helpful to translate\n        hex (returned from the digikrom) into a list of decimal values to prevent\n        asci mishaps\n        \"\"\"\n        decimal_list = []\n        for byte in byte_str:\n            decimal_list.append(ord(byte))\n        return decimal_list\n\n    @staticmethod\n    def encode_bytes(decimal_list):\n        \"\"\"The digikrom uses decimal charcters but recieves hex therefore it is\n        helpful to translate decimal values into hex to send to the digikrom\n        \"\"\"\n        if type(decimal_list)!=list:\n            decimal_list = [decimal_list]\n        byte_str = ''\n        for decimal in decimal_list:\n            byte = chr(decimal)\n            byte_str+=byte\n        return byte_str\n\n    def set_status_byte(self,status_byte):\n        \"\"\"Extract the status from the status byte \"\"\"\n        binary_byte = bin(status_byte)[2:]\n        if len(binary_byte)!=8:\n            binary_byte = (8-len(binary_byte))*'0'+binary_byte\n        if binary_byte[0]==1:\n            motor_movement_order = 'negative'\n        else:\n            motor_movement_order = 'positive'\n        if binary_byte[4]==1:\n            scan_direction = 'positive'\n        else:\n            scan_direction = 'negative'\n        if binary_byte[7]=='0':\n            value_accepted = True\n            value_error = None\n        else:\n            value_accepted=False\n            if binary_byte[6] == '1':\n                value_error = 'repeat set'\n            elif binary_byte[5] == '1':\n                value_error = 'value too large'\n            elif binary_byte[5] == '0':\n                value_error = 'value too small'\n        CSR_mode = bool(int(binary_byte[2]))\n        status_dict = {'value_accepted':value_accepted,\n                       'value_error':value_error,\n                       'motor_movement_order':motor_movement_order,\n                       'scan_direction' :scan_direction,\n                       'CSR_mode':CSR_mode\n                       }\n\n        if value_accepted==True:\n            level = 'debug'\n        else:\n            level = 'warn'\n        self.log(status_dict,level = level)\n        self._status_byte = status_dict\n    def get_wavelength(self):\n        \"\"\"The get wavlength command number is 29 and data is returned as 3 bytes,\n        the high byte, the mid byte and the low bye. These byte correspond to\n        multiples of 65536, 256 and 1. as shown below\"\"\"\n        returned_message = self.query(29)\n        wl = returned_message[1]*65536\n        wl += 256*returned_message[2]\n        wl += returned_message[3]\n        self.set_status_byte(returned_message[-2])\n        return wl/100.0\n    def set_wavelength(self,wl):\n        \"\"\"The set wavlength command number is 16 and data is sent as 3 bytes,\n        the high byte, the mid byte and the low bye. These byte correspond to\n        multiples of 65536, 256 and 1. as shown below\"\"\"\n        self.query(16,block = False)\n        wl = wl*100\n        high_byte = int(old_div(wl,65536))\n        wl = wl-high_byte*65536\n        mid_byte = int(old_div(wl,256))\n        wl = wl-mid_byte*256\n        low_byte = int(wl)\n        self.query([high_byte,mid_byte,low_byte])\n\n    centre_wavlength = NotifiedProperty(get_wavelength,set_wavelength)\n\n\n    def get_grating_id(self):\n        info = self.query(19)\n        info_dict = {'number_of_gratings': info[1],\n                     'current_grating': info[2],\n                     'grating_ruling':info[3]*256+info[4],\n                     'grating_blaze':info[5]*256+info[6]}\n        return info_dict\n    def set_grating(self,grating_number):\n        \"\"\"This command changes gratings , if additional gratings installed..\"\"\"\n        self.query(26)\n        self.query(grating_number)\n    def reset(self):\n        \"\"\"This command returns the grating to home position \"\"\"\n        self.query([255,255,255])\n\n    def clear(self):\n        \"\"\"This command restores factory calibration values for the grating and slits.\n        This command also executes a reset, which returns the grating to home position.\"\"\"\n        self.query(25)\n\n    def CSR(self,bandpass_value):\n        \"\"\" This command sets monochromator to Constant Spectral Resolution mode.\n        The slit width will vary throughout a scan. This is useful, for example,\n        where measurement of a constant interval of frequency is desired\n        (spectral power distribution measurements).\"\"\"\n        self.query(28)\n        high_byte = int(old_div(bandpass_value,256))\n        bandpass_value = bandpass_value-high_byte*256\n        low_byte = int(bandpass_value)\n        self.query([high_byte,low_byte])\n\n    def echo(self):\n        \"\"\"The ECHO command is used to verify communications with the DK240/480.\n        \"\"\"\n        self.log(self.query(27),level = 'info')\n\n    def gval(self,repositioning_wl):\n        \"\"\"This command allows recalibration of the monochromator positioning\n        scale factor and should be used immediately after using the ZERO command\n        (see page 15). The monochromator should be set to the peak of a known spectral line,\n        then the position of that line is input using the CALIBRATE command.\n        \"\"\"\n        self.query(18)\n        repositioning_wl = repositioning_wl*100\n        high_byte = int(old_div(repositioning_wl,65536))\n        repositioning_wl = repositioning_wl-high_byte*65536\n        mid_byte = int(old_div(repositioning_wl,256))\n        repositioning_wl = repositioning_wl-mid_byte*256\n        low_byte = int(repositioning_wl)\n        self.query([high_byte,mid_byte,low_byte])\n    def get_serial(self):\n        \"\"\" Returns the 5 digit serial number of the monochromator.\"\"\"\n        return self.query(33)[1:-2]\n\n    def get_slit_widths(self):\n        \"\"\"Returns the current four byte (six byte for DK242) slit width.\n        First two bytes are high and low byte of the entrance slit width in microns.\n        Second two bytes are the high and low byte of the exit slit width.\n        For DK242, the last two bytes are for middle slit width.\"\"\"\n        slit_info = self.query(30)[1:-2]\n        slit_info = np.array(slit_info)\n        low_byte = slit_info[1::2]\n        high_byte = slit_info[::2]\n        slit_info = 256*high_byte+low_byte\n        return slit_info\n\n    def set_all_slits(self,slit_width):\n        \"\"\" Adjusts all slits to a given width.\n        \"\"\"\n        high_byte = int(old_div(slit_width,256))\n        slit_width = slit_width-high_byte*256\n        low_byte = int(slit_width)\n        self.query(14)\n        self.query([high_byte,low_byte])\n\n    def set_slit_1_width(self,slit_width):\n        \"\"\"Adjusts entrance slit to a given width.\"\"\"\n        high_byte = int(old_div(slit_width,256))\n        slit_width = slit_width-high_byte*256\n        low_byte = int(slit_width)\n        self.query(31)\n        self.query([high_byte,low_byte])\n\n    def set_slit_2_width(self,slit_width):\n        \"\"\"Adjusts exit slit to a given width.\"\"\"\n        \"\"\"Slit 2 (exit) not installed 05042019\"\"\"\n        high_byte = int(old_div(slit_width,256))\n        slit_width = slit_width-high_byte*256\n        low_byte = int(slit_width)\n        self.query(32)\n        self.query([high_byte,low_byte])\n\n    def set_slit_3_width(self,slit_width):\n        \"\"\"Adjusts middle slit to a given width.\"\"\"\n        high_byte = int(old_div(slit_width,256))\n        slit_width = slit_width-high_byte*256\n        low_byte = int(slit_width)\n        self.query(34)\n        self.query([high_byte,low_byte])\n\n\n    def test_communications(self):\n        \"\"\"Check there is the correct digikrom at other end of the COM port.\"\"\"\n        try:\n            serial_num = self.get_serial()\n        except:\n            return False\n        if serial_num == self.serial_number:\n            return True\n        else:\n            return False",
  "def init():\n    spec = Digikrom(port=\"COM9\",serial_number = [50, 52, 51, 49, 55])\n    return spec",
  "def __init__(self,port = None,serial_number = [50, 52, 51, 49, 55]):\n        self.termination_character = ''\n        self.serial_number = serial_number\n        super(Digikrom, self).__init__(port=port)",
  "def query(self,message,convert_to_hex = True,return_as_dec = True,\n              max_len_returned = 10,block = True):\n        \"\"\"The digikrom uses fixed length commands and has no termination character\n        therefore the query function from serialinstrument needs to be overwritten.\n        As the digikrom requires input in hex commands must be changed from decimal\n        (as listed in the manual) to hex. The returned messages also need the same treatment\n        The maximum length of the returned str can also be specified to maximise speed\n        as currently it just waits for timeout\"\"\"\n        if convert_to_hex==True:\n            message_hex = self.encode_bytes(message)\n        else:\n            message_hex = message\n        self.write(message_hex)\n        returned_message = self.ser.read(max_len_returned)\n        if return_as_dec == True:\n            returned_message = self.decode_bytes(returned_message)\n\n        if returned_message[-1]==24:\n            block = False\n            self.set_status_byte(returned_message[-2])\n        elif(returned_message!=[message]):\n            self.set_status_byte(returned_message[-1])\n            while block == True:\n                block_message = self.decode_bytes(self.ser.read_all())\n                if len(block_message)==1:\n                    if block_message[0] == 24:\n                        block = False\n        return returned_message",
  "def decode_bytes(byte_str):\n        \"\"\"The digikrom uses decimal charcters therefore it is helpful to translate\n        hex (returned from the digikrom) into a list of decimal values to prevent\n        asci mishaps\n        \"\"\"\n        decimal_list = []\n        for byte in byte_str:\n            decimal_list.append(ord(byte))\n        return decimal_list",
  "def encode_bytes(decimal_list):\n        \"\"\"The digikrom uses decimal charcters but recieves hex therefore it is\n        helpful to translate decimal values into hex to send to the digikrom\n        \"\"\"\n        if type(decimal_list)!=list:\n            decimal_list = [decimal_list]\n        byte_str = ''\n        for decimal in decimal_list:\n            byte = chr(decimal)\n            byte_str+=byte\n        return byte_str",
  "def set_status_byte(self,status_byte):\n        \"\"\"Extract the status from the status byte \"\"\"\n        binary_byte = bin(status_byte)[2:]\n        if len(binary_byte)!=8:\n            binary_byte = (8-len(binary_byte))*'0'+binary_byte\n        if binary_byte[0]==1:\n            motor_movement_order = 'negative'\n        else:\n            motor_movement_order = 'positive'\n        if binary_byte[4]==1:\n            scan_direction = 'positive'\n        else:\n            scan_direction = 'negative'\n        if binary_byte[7]=='0':\n            value_accepted = True\n            value_error = None\n        else:\n            value_accepted=False\n            if binary_byte[6] == '1':\n                value_error = 'repeat set'\n            elif binary_byte[5] == '1':\n                value_error = 'value too large'\n            elif binary_byte[5] == '0':\n                value_error = 'value too small'\n        CSR_mode = bool(int(binary_byte[2]))\n        status_dict = {'value_accepted':value_accepted,\n                       'value_error':value_error,\n                       'motor_movement_order':motor_movement_order,\n                       'scan_direction' :scan_direction,\n                       'CSR_mode':CSR_mode\n                       }\n\n        if value_accepted==True:\n            level = 'debug'\n        else:\n            level = 'warn'\n        self.log(status_dict,level = level)\n        self._status_byte = status_dict",
  "def get_wavelength(self):\n        \"\"\"The get wavlength command number is 29 and data is returned as 3 bytes,\n        the high byte, the mid byte and the low bye. These byte correspond to\n        multiples of 65536, 256 and 1. as shown below\"\"\"\n        returned_message = self.query(29)\n        wl = returned_message[1]*65536\n        wl += 256*returned_message[2]\n        wl += returned_message[3]\n        self.set_status_byte(returned_message[-2])\n        return wl/100.0",
  "def set_wavelength(self,wl):\n        \"\"\"The set wavlength command number is 16 and data is sent as 3 bytes,\n        the high byte, the mid byte and the low bye. These byte correspond to\n        multiples of 65536, 256 and 1. as shown below\"\"\"\n        self.query(16,block = False)\n        wl = wl*100\n        high_byte = int(old_div(wl,65536))\n        wl = wl-high_byte*65536\n        mid_byte = int(old_div(wl,256))\n        wl = wl-mid_byte*256\n        low_byte = int(wl)\n        self.query([high_byte,mid_byte,low_byte])",
  "def get_grating_id(self):\n        info = self.query(19)\n        info_dict = {'number_of_gratings': info[1],\n                     'current_grating': info[2],\n                     'grating_ruling':info[3]*256+info[4],\n                     'grating_blaze':info[5]*256+info[6]}\n        return info_dict",
  "def set_grating(self,grating_number):\n        \"\"\"This command changes gratings , if additional gratings installed..\"\"\"\n        self.query(26)\n        self.query(grating_number)",
  "def reset(self):\n        \"\"\"This command returns the grating to home position \"\"\"\n        self.query([255,255,255])",
  "def clear(self):\n        \"\"\"This command restores factory calibration values for the grating and slits.\n        This command also executes a reset, which returns the grating to home position.\"\"\"\n        self.query(25)",
  "def CSR(self,bandpass_value):\n        \"\"\" This command sets monochromator to Constant Spectral Resolution mode.\n        The slit width will vary throughout a scan. This is useful, for example,\n        where measurement of a constant interval of frequency is desired\n        (spectral power distribution measurements).\"\"\"\n        self.query(28)\n        high_byte = int(old_div(bandpass_value,256))\n        bandpass_value = bandpass_value-high_byte*256\n        low_byte = int(bandpass_value)\n        self.query([high_byte,low_byte])",
  "def echo(self):\n        \"\"\"The ECHO command is used to verify communications with the DK240/480.\n        \"\"\"\n        self.log(self.query(27),level = 'info')",
  "def gval(self,repositioning_wl):\n        \"\"\"This command allows recalibration of the monochromator positioning\n        scale factor and should be used immediately after using the ZERO command\n        (see page 15). The monochromator should be set to the peak of a known spectral line,\n        then the position of that line is input using the CALIBRATE command.\n        \"\"\"\n        self.query(18)\n        repositioning_wl = repositioning_wl*100\n        high_byte = int(old_div(repositioning_wl,65536))\n        repositioning_wl = repositioning_wl-high_byte*65536\n        mid_byte = int(old_div(repositioning_wl,256))\n        repositioning_wl = repositioning_wl-mid_byte*256\n        low_byte = int(repositioning_wl)\n        self.query([high_byte,mid_byte,low_byte])",
  "def get_serial(self):\n        \"\"\" Returns the 5 digit serial number of the monochromator.\"\"\"\n        return self.query(33)[1:-2]",
  "def get_slit_widths(self):\n        \"\"\"Returns the current four byte (six byte for DK242) slit width.\n        First two bytes are high and low byte of the entrance slit width in microns.\n        Second two bytes are the high and low byte of the exit slit width.\n        For DK242, the last two bytes are for middle slit width.\"\"\"\n        slit_info = self.query(30)[1:-2]\n        slit_info = np.array(slit_info)\n        low_byte = slit_info[1::2]\n        high_byte = slit_info[::2]\n        slit_info = 256*high_byte+low_byte\n        return slit_info",
  "def set_all_slits(self,slit_width):\n        \"\"\" Adjusts all slits to a given width.\n        \"\"\"\n        high_byte = int(old_div(slit_width,256))\n        slit_width = slit_width-high_byte*256\n        low_byte = int(slit_width)\n        self.query(14)\n        self.query([high_byte,low_byte])",
  "def set_slit_1_width(self,slit_width):\n        \"\"\"Adjusts entrance slit to a given width.\"\"\"\n        high_byte = int(old_div(slit_width,256))\n        slit_width = slit_width-high_byte*256\n        low_byte = int(slit_width)\n        self.query(31)\n        self.query([high_byte,low_byte])",
  "def set_slit_2_width(self,slit_width):\n        \"\"\"Adjusts exit slit to a given width.\"\"\"\n        \"\"\"Slit 2 (exit) not installed 05042019\"\"\"\n        high_byte = int(old_div(slit_width,256))\n        slit_width = slit_width-high_byte*256\n        low_byte = int(slit_width)\n        self.query(32)\n        self.query([high_byte,low_byte])",
  "def set_slit_3_width(self,slit_width):\n        \"\"\"Adjusts middle slit to a given width.\"\"\"\n        high_byte = int(old_div(slit_width,256))\n        slit_width = slit_width-high_byte*256\n        low_byte = int(slit_width)\n        self.query(34)\n        self.query([high_byte,low_byte])",
  "def test_communications(self):\n        \"\"\"Check there is the correct digikrom at other end of the COM port.\"\"\"\n        try:\n            serial_num = self.get_serial()\n        except:\n            return False\n        if serial_num == self.serial_number:\n            return True\n        else:\n            return False",
  "def read_tokens():\n\t'''\n\tText tokens are mapped to integers in the bentham_dlltokens.h file\n\tread the file and make the dictionary of tokens \n\t'''\n\ttoken_map = {}\n\timport re\n\tdefinition_pattern = re.compile(\"#define.*\")\n\ttoken_filepath = os.path.normpath(DIRPATH+\"/bentham_dlltokens.h\")\n\twith open(token_filepath,\"r\") as f:\n\t\tfor line in f.readlines():\n\t\t\tline = line.strip(\"\\n\")\n\t\t\tif bool(definition_pattern.match(line))==True:\n\t\t\t\tline_list = line.split(\" \")\n\t\t\t\ttoken_map.update({line_list[1]:int(line_list[2])})\n\n\treturn token_map",
  "class Bentham_DTMc300(Instrument):\n\n\tdef __init__(self):\n\t\tsuper(Bentham_DTMc300,self).__init__()\n\n\t\tself.dll = WinDLL(DLL_PATH)\n\n\t\tself.token_map = read_tokens()\n\t\terror_report = c_char_p(\"\")\n\t\tresponse = self.dll.BI_build_system_model(c_char_p(CONFIG_PATH),error_report)\n\t\tprint(\"Error report\",error_report)\n\t\tprint(\"BI_build_system_model:\",response)\n\t\tresponse = self.dll.BI_load_setup(c_char_p(ATTRS_PATH)) \n\t\tprint(\"BI_load_setup:\",response)\n\t\tresponse = self.dll.BI_initialise(None)\n\t\tprint(\"BI_initialise:\",response)\n\t\tresponse = self.dll.BI_park(None)\n\t\tprint(\"BI_park:\",response)\n\n\t\tself.components = self.get_component_list()\n\n\tdef get_component_list(self):\n\t\tmylist = (ctypes.c_char*100)()\n\t\tresponse = self.dll.BI_get_component_list(ctypes.byref(mylist))\n\t\tcomponents = [k for k in (\"\".join([c for c in mylist if c != '\\x00'])).split(\",\") if k != '']\n\t\tprint(\"BI_get_component_list:\",response, components)\n\t\treturn components\n\n\n\tdef get(self,item_id,token,index):\n\t\tvalue = ctypes.c_double(0.0)\n\t\tprint(\"id:{0}, token:{1}, index:{2}\".format(item_id,token,index))\n\t\tresponse = self.dll.BI_get(c_char_p(item_id),ctypes.c_int32(self.token_map[token]),ctypes.c_int32(index),ctypes.byref(value))\n\t\tprint(\"BI_get\", response)\n\t\treturn value.value\n  \n\tdef get_wavelength(self,token=\"mono\"):\n\t\twavelength = self.get(item_id=\"mono\",token=\"MonochromatorCurrentWL\",index=0)\n\t\treturn wavelength\n\n\tdef set_wavelength(self,wavelength):\n\t\t\n\t\tdelay = ctypes.c_double(0.0)\n\t\tresponse = self.dll.BI_select_wavelength(ctypes.c_double(wavelength), ctypes.byref(delay))\n\t\ttime.sleep(0.3) #sleep for 300ms - ensure everything has moved\n\t\treturn",
  "def __init__(self):\n\t\tsuper(Bentham_DTMc300,self).__init__()\n\n\t\tself.dll = WinDLL(DLL_PATH)\n\n\t\tself.token_map = read_tokens()\n\t\terror_report = c_char_p(\"\")\n\t\tresponse = self.dll.BI_build_system_model(c_char_p(CONFIG_PATH),error_report)\n\t\tprint(\"Error report\",error_report)\n\t\tprint(\"BI_build_system_model:\",response)\n\t\tresponse = self.dll.BI_load_setup(c_char_p(ATTRS_PATH)) \n\t\tprint(\"BI_load_setup:\",response)\n\t\tresponse = self.dll.BI_initialise(None)\n\t\tprint(\"BI_initialise:\",response)\n\t\tresponse = self.dll.BI_park(None)\n\t\tprint(\"BI_park:\",response)\n\n\t\tself.components = self.get_component_list()",
  "def get_component_list(self):\n\t\tmylist = (ctypes.c_char*100)()\n\t\tresponse = self.dll.BI_get_component_list(ctypes.byref(mylist))\n\t\tcomponents = [k for k in (\"\".join([c for c in mylist if c != '\\x00'])).split(\",\") if k != '']\n\t\tprint(\"BI_get_component_list:\",response, components)\n\t\treturn components",
  "def get(self,item_id,token,index):\n\t\tvalue = ctypes.c_double(0.0)\n\t\tprint(\"id:{0}, token:{1}, index:{2}\".format(item_id,token,index))\n\t\tresponse = self.dll.BI_get(c_char_p(item_id),ctypes.c_int32(self.token_map[token]),ctypes.c_int32(index),ctypes.byref(value))\n\t\tprint(\"BI_get\", response)\n\t\treturn value.value",
  "def get_wavelength(self,token=\"mono\"):\n\t\twavelength = self.get(item_id=\"mono\",token=\"MonochromatorCurrentWL\",index=0)\n\t\treturn wavelength",
  "def set_wavelength(self,wavelength):\n\t\t\n\t\tdelay = ctypes.c_double(0.0)\n\t\tresponse = self.dll.BI_select_wavelength(ctypes.c_double(wavelength), ctypes.byref(delay))\n\t\ttime.sleep(0.3) #sleep for 300ms - ensure everything has moved\n\t\treturn",
  "def bool_to_state(Bool):\n    if Bool:\n        return 'Open'\n    if not Bool:\n        return 'Closed'",
  "def state_to_bool(state):\n    if state == 'Open':\n        return True\n    if state == 'Closed':\n        return False",
  "class ThorLabsSC10(Shutter, serial.SerialInstrument):\n    port_settings = dict(baudrate=9600,\n                         bytesize=serial.EIGHTBITS,\n                         parity=serial.PARITY_NONE,\n                         stopbits=serial.STOPBITS_ONE,\n                         timeout=1,  # wait at most one second for a response\n                         writeTimeout=1,  # similarly, fail if writing takes >1s\n                         xonxoff=False, rtscts=False, dsrdtr=False,\n                         )\n    termination_character = \"\\r\"  #: All messages to or from the instrument end with this character.\n    '''\n    self._state trys to keep track of the shutter state. This is because communication quite frequently fails with this shutter for some reason.\n    The toggle function always works, however self.query('ens?') often returns None, along with the message 'Command did not echo!!!'.\n    self._state may be incorrect initially, if the laser shutter is open, and communication fails. \n    In this case, simply specify the shutter state manually with\n    >>> shutter._state = 'Open' # for example\n    \n    The self._state attribute is overwritten if communication with the shutter succeeds at any time, so this should maximise the state being right. \n    using the physical buttons on the shutter will of course mess this all up. \n    -ee306\n    '''\n    def __init__(self, port=None):\n        serial.SerialInstrument.__init__(self, port=port)\n        Shutter.__init__(self)\n        self.ignore_echo = True     \n        self._state = 'Closed'  # usually the case      \n        self.get_state(report_success = True) # overwrites self._state if communication succeeds     \n            \n    def toggle(self):\n        self.write('ens')\n        self._state = bool_to_state(not state_to_bool(self._state))#toggles self._state\n#        \n#    def get_state(self):\n#        if self.query('ens?') == '0':\n#            return 'Closed'\n#        elif self.query('ens?') == '1':\n#            return 'Open'\n    \n    def get_state(self, report_success = False):\n        try:\n            state = bool(int(self.query('ens?')))\n\n            if state:\n                self._state = 'Open'            \n                return self._state\n            if not state:\n                self._state = 'Closed'            \n                return self._state\n            assert False \n        except (ValueError, AssertionError):\n            if report_success: \n                print(\n                        '''Communication with shutter failed; assuming shutter is closed.\\nChange shutter._state if not!'''\n                      )          \n            return self._state\n    \n    def set_state(self, state):\n        if state_to_bool(self.get_state()) != state_to_bool(state):\n            self.toggle()\n        \n    def open_shutter(self):\n        if not state_to_bool(self.get_state()):\n            self.toggle()\n        elif state_to_bool(self._state):\n            print('Shutter is already open!')\n        \n    def close_shutter(self):  \n        if state_to_bool(self._state):\n            self.toggle()\n        elif not state_to_bool(self._state):\n            print('Shutter is already closed!')\n        \n    def set_mode(self,n):\n        \"\"\" Where n equals an associated mode\n            mode=1: Sets the unit to Manual Mode\n            mode=2: Sets the unit to Auto Mode\n            mode=3: Sets the unit to Single Mode\n            mode=4: Sets the unit to Repeat Mode\n            mode=5: Sets the unit to the External Gate Mode\"\"\"\n        self.query('mode='+str(n))\n    def get_mode(self):\n        self.query('mode?')",
  "def __init__(self, port=None):\n        serial.SerialInstrument.__init__(self, port=port)\n        Shutter.__init__(self)\n        self.ignore_echo = True     \n        self._state = 'Closed'  # usually the case      \n        self.get_state(report_success = True)",
  "def toggle(self):\n        self.write('ens')\n        self._state = bool_to_state(not state_to_bool(self._state))",
  "def get_state(self, report_success = False):\n        try:\n            state = bool(int(self.query('ens?')))\n\n            if state:\n                self._state = 'Open'            \n                return self._state\n            if not state:\n                self._state = 'Closed'            \n                return self._state\n            assert False \n        except (ValueError, AssertionError):\n            if report_success: \n                print(\n                        '''Communication with shutter failed; assuming shutter is closed.\\nChange shutter._state if not!'''\n                      )          \n            return self._state",
  "def set_state(self, state):\n        if state_to_bool(self.get_state()) != state_to_bool(state):\n            self.toggle()",
  "def open_shutter(self):\n        if not state_to_bool(self.get_state()):\n            self.toggle()\n        elif state_to_bool(self._state):\n            print('Shutter is already open!')",
  "def close_shutter(self):  \n        if state_to_bool(self._state):\n            self.toggle()\n        elif not state_to_bool(self._state):\n            print('Shutter is already closed!')",
  "def set_mode(self,n):\n        \"\"\" Where n equals an associated mode\n            mode=1: Sets the unit to Manual Mode\n            mode=2: Sets the unit to Auto Mode\n            mode=3: Sets the unit to Single Mode\n            mode=4: Sets the unit to Repeat Mode\n            mode=5: Sets the unit to the External Gate Mode\"\"\"\n        self.query('mode='+str(n))",
  "def get_mode(self):\n        self.query('mode?')",
  "class ILShutter(SerialInstrument, ShutterWithEmulatedRead):\n    def __init__(self, port):\n        self.port_settings = {'baudrate': 19200,\n                        'bytesize':serial.SEVENBITS,\n                        'parity':serial.PARITY_ODD,\n                        'stopbits':serial.STOPBITS_ONE,\n                        'timeout':1, #wait at most one second for a response\n                        'writeTimeout':1, #similarly, fail if writing takes >1s\n                        }\n        self.termination_character = \"\\r\"\n        SerialInstrument.__init__(self, port=port)\n        ShutterWithEmulatedRead.__init__(self)\n        self.query(\"ct\") #enable computer control\n        \n    def set_state(self, value):\n        \"\"\"Set the shutter to be either \"Open\" or \"Closed\" \"\"\"\n        if value.title() == \"Open\":\n            self.query(\"S4U\")\n            self.__state = \"Open\"\n        else:\n            self.query(\"S4D\")\n            self.__state = \"Closed\"",
  "def __init__(self, port):\n        self.port_settings = {'baudrate': 19200,\n                        'bytesize':serial.SEVENBITS,\n                        'parity':serial.PARITY_ODD,\n                        'stopbits':serial.STOPBITS_ONE,\n                        'timeout':1, #wait at most one second for a response\n                        'writeTimeout':1, #similarly, fail if writing takes >1s\n                        }\n        self.termination_character = \"\\r\"\n        SerialInstrument.__init__(self, port=port)\n        ShutterWithEmulatedRead.__init__(self)\n        self.query(\"ct\")",
  "def set_state(self, value):\n        \"\"\"Set the shutter to be either \"Open\" or \"Closed\" \"\"\"\n        if value.title() == \"Open\":\n            self.query(\"S4U\")\n            self.__state = \"Open\"\n        else:\n            self.query(\"S4D\")\n            self.__state = \"Closed\"",
  "class Uniblitz(ShutterWithEmulatedRead, SerialInstrument):\n    \"\"\"\n    Shutter controller from Uniblitz for BX51 white light path\n    \"\"\"\n    def __init__(self, port=None):\n        self.port_settings = {'baudrate': 9600,\n                        'bytesize':serial.EIGHTBITS,\n                        'parity':serial.PARITY_NONE,\n                        'stopbits':serial.STOPBITS_ONE,\n                        'timeout':1, #wait at most one second for a response\n                        'writeTimeout':1, #similarly, fail if writing takes >1s\n                        }\n        self.termination_character = \"\\r\"\n        SerialInstrument.__init__(self, port=port)\n        ShutterWithEmulatedRead.__init__(self)\n        self.shutter_state = 0\n    \n    def set_state(self,state):\n        if state=='Open':\n            self.ser.write(str.encode('@'))\n        elif state == 'Closed': \n            self.ser.write(str.encode('A'))",
  "def __init__(self, port=None):\n        self.port_settings = {'baudrate': 9600,\n                        'bytesize':serial.EIGHTBITS,\n                        'parity':serial.PARITY_NONE,\n                        'stopbits':serial.STOPBITS_ONE,\n                        'timeout':1, #wait at most one second for a response\n                        'writeTimeout':1, #similarly, fail if writing takes >1s\n                        }\n        self.termination_character = \"\\r\"\n        SerialInstrument.__init__(self, port=port)\n        ShutterWithEmulatedRead.__init__(self)\n        self.shutter_state = 0",
  "def set_state(self,state):\n        if state=='Open':\n            self.ser.write(str.encode('@'))\n        elif state == 'Closed': \n            self.ser.write(str.encode('A'))",
  "class Arduino_TTL_shutter(SerialInstrument,Shutter):\n    '''A class for the Piezoconcept objective collar '''\n\n    def __init__(self, port=None):\n        '''Set up baudrate etc and recenters the stage to the center of it's range (50um)\n        \n        Args:\n            port(int/str):  The port the device is connected \n                            to in any of the accepted serial formats\n            \n        '''\n        self.termination_character = '\\n'\n        self.port_settings = {\n                    'baudrate':9600,\n             #       'bytesize':serial.EIGHTBITS,\n                    'timeout':2, #wait at most one second for a response\n                    }\n        self.termination_character = '\\n'\n        SerialInstrument.__init__(self,port=port)\n        Shutter.__init__(self)\n    def get_state(self):\n        return self.query('Read')\n    def set_state(self,state):\n        self.query(state)",
  "class Arduino_tri_shutter(SerialInstrument):\n    '''Control class for tri shutter '''\n\n    def __init__(self, port=None):\n        '''Set up baudrate etc and recenters the stage to the center of it's range (50um)\n        \n        Args:\n            port(int/str):  The port the device is connected \n                            to in any of the accepted serial formats\n            \n        '''\n        self.termination_character = '\\n'\n        self.port_settings = {\n                    'baudrate':9600,\n             #       'bytesize':serial.EIGHTBITS,\n                    'timeout':2, #wait at most one second for a response\n                    }\n        self.termination_character = '\\r\\n'\n        SerialInstrument.__init__(self,port=port)\n    def set_shutter_1_state(self,state):\n        \"\"\"Set State Command for Shutter 1 used by check box \"\"\"\n        if state == True:\n            self._open_shutter_1()\n        elif state == False:\n            self._close_shutter_1()\n            \n    def set_shutter_2_state(self,state):\n        \"\"\"Set State Command for Shutter 2 used by check box \"\"\"\n        if state == True:\n            self._open_shutter_2()\n        elif state == False:\n            self._close_shutter_2()\n            \n    def set_mirror_1_state(self,state):\n        \"\"\"Set State Command for flipper 1 used by check box \"\"\"\n        if state == True:\n            self._flip_mirror_0()\n        elif state == False:\n            self._flip_mirror_1()\n            \n            \n\n    def open_shutter_1(self):\n        \"\"\"Usable open shutter 1 function that updates GUI when used\"\"\"\n        self.Shutter_1_State = True\n    def close_shutter_1(self):\n        \"\"\"Usable close shutter 1 function that updates GUI when used\"\"\"\n        self.Shutter_1_State = False\n    def open_shutter_2(self):\n        \"\"\"Usable open shutter 2 function that updates GUI when used\"\"\"\n        self.Shutter_2_State = True\n    def close_shutter_2(self):\n        \"\"\"Usable close shutter 2 function that updates GUI when used\"\"\"\n        self.Shutter_2_State = False\n        \n    def flip_mirror_0(self):\n        \"\"\"Usable open flip_mirror 1  function that updates GUI when used\"\"\"\n        self.Flipper_1_State = False\n    def flip_mirror_1(self):\n        \"\"\"Usable close flip mirror 1 function that updates GUI when used\"\"\"\n        self.Flipper_1_State = False\n        \n        \n        \n    def _open_shutter_1(self):\n        \"\"\"do not use! Hidden access to open shutter \"\"\"\n        self.query('A')\n    def _close_shutter_1(self):\n        \"\"\"do not use! hidden close shutter function\"\"\"\n        self.query('B')\n    def _open_shutter_2(self):\n        \"\"\"do not use! Hidden access to open shutter \"\"\"\n        self.query('C')\n    def _close_shutter_2(self):\n        \"\"\"do not use! hidden close shutter function\"\"\"\n        self.query('D')\n    def _flip_mirror_0(self):\n        \"\"\"do not use! hidden open flipper function\"\"\"\n        self.query('E')\n    def _flip_mirror_1(self):\n        \"\"\"do not use! hidden open flipper function\"\"\"\n        self.query('F')\n        \n #   def get_state(self):\n #       return self.query('Read')\n #   def set_state(self,state):\n #       self.query(state)\n    def get_qt_ui(self):\n        self.ui = tri_shutter_ui(self)\n        return self.ui\n    def read_state(self):\n        states = self.query('S')\n        states = states.split(',')\n        states = [bool(int(state)) for state in states]\n        return states\n    states = NotifiedProperty(fget= read_state)\n    def get_state_1(self):\n        return self.states[0]\n    def get_state_2(self):\n        return self.states[1]    \n\n    def get_state_3(self):\n        return self.states[2]\n\n    \n    Shutter_1_State = NotifiedProperty(fset = set_shutter_1_state, fget = get_state_1)\n    Shutter_2_State = NotifiedProperty(fset = set_shutter_2_state, fget = get_state_2)\n    Flipper_1_State = NotifiedProperty(fset = set_mirror_1_state, fget = get_state_3)",
  "class tri_shutter_ui(QuickControlBox):\n    '''Control Widget for the Shamrock spectrometer\n    '''\n    def __init__(self,shutter):\n        super(tri_shutter_ui,self).__init__(title = 'Tri_shutter')\n        self.shutter = shutter\n        self.add_checkbox('Shutter_1_State')\n        self.add_checkbox('Shutter_2_State')\n        self.add_checkbox('Flipper_1_State')\n        self.auto_connect_by_name(controlled_object = self.shutter)",
  "def __init__(self, port=None):\n        '''Set up baudrate etc and recenters the stage to the center of it's range (50um)\n        \n        Args:\n            port(int/str):  The port the device is connected \n                            to in any of the accepted serial formats\n            \n        '''\n        self.termination_character = '\\n'\n        self.port_settings = {\n                    'baudrate':9600,\n             #       'bytesize':serial.EIGHTBITS,\n                    'timeout':2, #wait at most one second for a response\n                    }\n        self.termination_character = '\\n'\n        SerialInstrument.__init__(self,port=port)\n        Shutter.__init__(self)",
  "def get_state(self):\n        return self.query('Read')",
  "def set_state(self,state):\n        self.query(state)",
  "def __init__(self, port=None):\n        '''Set up baudrate etc and recenters the stage to the center of it's range (50um)\n        \n        Args:\n            port(int/str):  The port the device is connected \n                            to in any of the accepted serial formats\n            \n        '''\n        self.termination_character = '\\n'\n        self.port_settings = {\n                    'baudrate':9600,\n             #       'bytesize':serial.EIGHTBITS,\n                    'timeout':2, #wait at most one second for a response\n                    }\n        self.termination_character = '\\r\\n'\n        SerialInstrument.__init__(self,port=port)",
  "def set_shutter_1_state(self,state):\n        \"\"\"Set State Command for Shutter 1 used by check box \"\"\"\n        if state == True:\n            self._open_shutter_1()\n        elif state == False:\n            self._close_shutter_1()",
  "def set_shutter_2_state(self,state):\n        \"\"\"Set State Command for Shutter 2 used by check box \"\"\"\n        if state == True:\n            self._open_shutter_2()\n        elif state == False:\n            self._close_shutter_2()",
  "def set_mirror_1_state(self,state):\n        \"\"\"Set State Command for flipper 1 used by check box \"\"\"\n        if state == True:\n            self._flip_mirror_0()\n        elif state == False:\n            self._flip_mirror_1()",
  "def open_shutter_1(self):\n        \"\"\"Usable open shutter 1 function that updates GUI when used\"\"\"\n        self.Shutter_1_State = True",
  "def close_shutter_1(self):\n        \"\"\"Usable close shutter 1 function that updates GUI when used\"\"\"\n        self.Shutter_1_State = False",
  "def open_shutter_2(self):\n        \"\"\"Usable open shutter 2 function that updates GUI when used\"\"\"\n        self.Shutter_2_State = True",
  "def close_shutter_2(self):\n        \"\"\"Usable close shutter 2 function that updates GUI when used\"\"\"\n        self.Shutter_2_State = False",
  "def flip_mirror_0(self):\n        \"\"\"Usable open flip_mirror 1  function that updates GUI when used\"\"\"\n        self.Flipper_1_State = False",
  "def flip_mirror_1(self):\n        \"\"\"Usable close flip mirror 1 function that updates GUI when used\"\"\"\n        self.Flipper_1_State = False",
  "def _open_shutter_1(self):\n        \"\"\"do not use! Hidden access to open shutter \"\"\"\n        self.query('A')",
  "def _close_shutter_1(self):\n        \"\"\"do not use! hidden close shutter function\"\"\"\n        self.query('B')",
  "def _open_shutter_2(self):\n        \"\"\"do not use! Hidden access to open shutter \"\"\"\n        self.query('C')",
  "def _close_shutter_2(self):\n        \"\"\"do not use! hidden close shutter function\"\"\"\n        self.query('D')",
  "def _flip_mirror_0(self):\n        \"\"\"do not use! hidden open flipper function\"\"\"\n        self.query('E')",
  "def _flip_mirror_1(self):\n        \"\"\"do not use! hidden open flipper function\"\"\"\n        self.query('F')",
  "def get_qt_ui(self):\n        self.ui = tri_shutter_ui(self)\n        return self.ui",
  "def read_state(self):\n        states = self.query('S')\n        states = states.split(',')\n        states = [bool(int(state)) for state in states]\n        return states",
  "def get_state_1(self):\n        return self.states[0]",
  "def get_state_2(self):\n        return self.states[1]",
  "def get_state_3(self):\n        return self.states[2]",
  "def __init__(self,shutter):\n        super(tri_shutter_ui,self).__init__(title = 'Tri_shutter')\n        self.shutter = shutter\n        self.add_checkbox('Shutter_1_State')\n        self.add_checkbox('Shutter_2_State')\n        self.add_checkbox('Flipper_1_State')\n        self.auto_connect_by_name(controlled_object = self.shutter)",
  "class Shutter(Instrument):\n    \"\"\"A generic instrument class for optical shutters.\n    \n    An optical shutter can be \"Open\" (allowing light to pass) or \"Closed\" (not\n    allowing light through).  This generic class provides a GUI and some\n    convenience methods.  You can set and (usually) check the state of the\n    shutter using the property `Shutter.state` which is a string that's either\n    \"Open\" or \"Closed\".  If you need a boolean answer, use `Shutter.is_open()`\n    or `Shutter.is_closed`.  There's also `expose()` that opens for a number\n    of seconds, and `toggle()` that changes state.\n    \n    # Subclassing Notes\n    The minimum required subclassing effort is overriding `set_state` to open\n    and close the shutter.  Overriding get_state allows you to read back the\n    state of the shutter.  If you want to emulate that (i.e. keep track of\n    the state of the shutter in software) subclass `ShutterWithEmulatedRead`\n    and make sure you call its `__init__` method in your initialisation code.\n    \"\"\"\n    def __init__(self):\n        super(Shutter, self).__init__()\n\n    def toggle(self):\n        \"\"\"Toggle the state of the shutter.\n        \n        The default behaviour will emulate a toggle command if none exists.\n        \"\"\"\n        try:\n            if self.is_closed():\n                self.state = \"Open\"\n            else:\n                self.state = \"Closed\"\n        except NotImplementedError:\n            raise NotImplementedError(\"This shutter has no way to toggle!\"\"\")\n        \n    @contextlib.contextmanager\n    def hold(self, state=\"Open\", default_state=\"Closed\"):\n        \"\"\"Hold the shutter in a given state (for use in a `with` block).\n        \n        This returns a context manager, so it can be used in a `with` block,\n        so that the shutter is held in the given position (default Open) while\n        something else happens, then returns to its previous state (usually\n        Closed) afterwards, even if exceptions occur.\n        \n        If the shutter can't report it's current state it should raise a\n        `NotImplementedError` (this is the default) in which case we will \n        default to closing the shutter afterwards unless `default_state` has\n        been set in which case we use that.\n        \n        In the future, this might block other threads from touching the \n        shutter - currently it does not.\n        \"\"\"\n        try:\n            oldstate = self.state\n        except NotImplementedError:\n            oldstate = default_state\n        try:\n            self.state = state\n            yield\n        finally:\n            self.state = oldstate\n            \n    def expose(self, time_in_seconds):\n        \"\"\"Open the shutter for a specified time, then close again.\n        \n        This function will block until the exposure is over.  NB if you \n        override this function in a subclass, take care with what happens to\n        reads/writes of the self.state property.  If you are in a subclass\n        of `ShutterWithEmulatedRead` you might need to update\n        `_last_set_state`.\n        \"\"\"\n        with self.hold(\"Open\"):\n            time.sleep(time_in_seconds)\n\n    def get_state(self):\n        \"\"\"Whether the shutter is 'Open' or 'Closed'.\"\"\"\n        raise NotImplementedError(\"This shutter has no way to get its state!\"\"\")\n\n    def set_state(self, value):\n        \"\"\"Set the shutter to be either 'Open' or 'Closed'.\"\"\"\n        raise NotImplementedError(\"This shutter has no way to set its state!\"\"\")\n        \n    def open_shutter(self):\n        \"\"\"Open the shutter.\"\"\"\n        self._set_state_proxy(\"Open\")\n    \n    def close_shutter(self):\n        \"\"\"Close the shutter.\"\"\"\n        self._set_state_proxy(\"Closed\")\n\n    # This slightly ugly hack means it's not necessary to redefine the \n    # state property every time it's subclassed.\n    def _get_state_proxy(self):\n        \"\"\"The state of the shutter - should either be \"Open\" or \"Closed\".\"\"\"\n        return self.get_state()\n        \n    def _set_state_proxy(self, state):\n        self.set_state(state)\n        self._last_set_state = state.title() # Remember what state we're in\n        \n    state = property(_get_state_proxy, _set_state_proxy)\n    \n    def is_open(self):\n        \"\"\"Return `True` if the shutter is open.\"\"\"\n        return self.state.title() == \"Open\"\n        \n    def is_closed(self):\n        \"\"\"Return `True` if the shutter is closed.\"\"\"\n        return self.state.title() == \"Closed\"\n\n    def get_qt_ui(self):\n        \"\"\"Return a graphical interface for the shutter.\"\"\"\n        return ShutterUI(self)",
  "class ShutterWithEmulatedRead(Shutter):\n    \"\"\"A shutter class that keeps track in software of whether it's open.\n    \n    Use this instead of `Shutter` if you don't want to communicate with the\n    shutter to check whether it's open or closed.\n    \n    # Subclassing Notes\n    See the subclassing notes from `Shutter`.  All you need to override is\n    `set_state`, the rest is dealt with.  NB if you have to initialise the\n    hardware, make sure you do that *before* calling \n    `ShutterWithEmulatedRead.__init__()` as it closes the shutter to start\n    with.\n    \"\"\"\n    def __init__(self):\n        \"\"\"Initialise the shutter to the closed position.\"\"\"\n        self._last_set_state = 'Closed'\n        self.state = \"Closed\"\n    \n    def get_state(self):\n        \"\"\"Whether the shutter is Open or Closed.\"\"\"\n        return self._last_set_state",
  "class ShutterUI(QtWidgets.QWidget, UiTools):\n    def __init__(self, shutter, parent=None):\n        assert isinstance(shutter, Shutter), 'instrument must be a Shutter'\n        self.shutter = shutter\n        super(ShutterUI, self).__init__(parent)\n        uic.loadUi(os.path.join(os.path.dirname(__file__), 'shutter.ui'), self)\n        self.auto_connect_by_name(controlled_object = self.shutter,verbose = False)\n    #    self.state.stateChanged.connect(self.on_change)\n\n    def on_change(self):\n        self.shutter.toggle()",
  "class DummyShutter(Shutter):\n    \"\"\"A stub class to simulate a shutter\"\"\"\n    _open = DumbNotifiedProperty(False)\n    def __init__(self):\n        \"\"\"Create a dummy shutter object\"\"\"\n        self._open = False\n        super(DummyShutter, self).__init__()\n        \n    def toggle(self):\n        \"\"\"toggle the state of the shutter\"\"\"\n        self._open = not self._open\n    \n    def get_state(self):\n        \"\"\"Return the state of the shutter, a string reading 'open' or 'closed'\"\"\"\n        return \"Open\" if self._open else \"Closed\"\n        \n    def set_state(self, value):\n        \"\"\"Set the state of the shutter (to open or closed)\"\"\"\n        if isinstance(value, str):\n            self._open = (value.lower() == \"open\")\n        elif isinstance(value, bool):\n            self._open = value",
  "def __init__(self):\n        super(Shutter, self).__init__()",
  "def toggle(self):\n        \"\"\"Toggle the state of the shutter.\n        \n        The default behaviour will emulate a toggle command if none exists.\n        \"\"\"\n        try:\n            if self.is_closed():\n                self.state = \"Open\"\n            else:\n                self.state = \"Closed\"\n        except NotImplementedError:\n            raise NotImplementedError(\"This shutter has no way to toggle!\"\"\")",
  "def hold(self, state=\"Open\", default_state=\"Closed\"):\n        \"\"\"Hold the shutter in a given state (for use in a `with` block).\n        \n        This returns a context manager, so it can be used in a `with` block,\n        so that the shutter is held in the given position (default Open) while\n        something else happens, then returns to its previous state (usually\n        Closed) afterwards, even if exceptions occur.\n        \n        If the shutter can't report it's current state it should raise a\n        `NotImplementedError` (this is the default) in which case we will \n        default to closing the shutter afterwards unless `default_state` has\n        been set in which case we use that.\n        \n        In the future, this might block other threads from touching the \n        shutter - currently it does not.\n        \"\"\"\n        try:\n            oldstate = self.state\n        except NotImplementedError:\n            oldstate = default_state\n        try:\n            self.state = state\n            yield\n        finally:\n            self.state = oldstate",
  "def expose(self, time_in_seconds):\n        \"\"\"Open the shutter for a specified time, then close again.\n        \n        This function will block until the exposure is over.  NB if you \n        override this function in a subclass, take care with what happens to\n        reads/writes of the self.state property.  If you are in a subclass\n        of `ShutterWithEmulatedRead` you might need to update\n        `_last_set_state`.\n        \"\"\"\n        with self.hold(\"Open\"):\n            time.sleep(time_in_seconds)",
  "def get_state(self):\n        \"\"\"Whether the shutter is 'Open' or 'Closed'.\"\"\"\n        raise NotImplementedError(\"This shutter has no way to get its state!\"\"\")",
  "def set_state(self, value):\n        \"\"\"Set the shutter to be either 'Open' or 'Closed'.\"\"\"\n        raise NotImplementedError(\"This shutter has no way to set its state!\"\"\")",
  "def open_shutter(self):\n        \"\"\"Open the shutter.\"\"\"\n        self._set_state_proxy(\"Open\")",
  "def close_shutter(self):\n        \"\"\"Close the shutter.\"\"\"\n        self._set_state_proxy(\"Closed\")",
  "def _get_state_proxy(self):\n        \"\"\"The state of the shutter - should either be \"Open\" or \"Closed\".\"\"\"\n        return self.get_state()",
  "def _set_state_proxy(self, state):\n        self.set_state(state)\n        self._last_set_state = state.title()",
  "def is_open(self):\n        \"\"\"Return `True` if the shutter is open.\"\"\"\n        return self.state.title() == \"Open\"",
  "def is_closed(self):\n        \"\"\"Return `True` if the shutter is closed.\"\"\"\n        return self.state.title() == \"Closed\"",
  "def get_qt_ui(self):\n        \"\"\"Return a graphical interface for the shutter.\"\"\"\n        return ShutterUI(self)",
  "def __init__(self):\n        \"\"\"Initialise the shutter to the closed position.\"\"\"\n        self._last_set_state = 'Closed'\n        self.state = \"Closed\"",
  "def get_state(self):\n        \"\"\"Whether the shutter is Open or Closed.\"\"\"\n        return self._last_set_state",
  "def __init__(self, shutter, parent=None):\n        assert isinstance(shutter, Shutter), 'instrument must be a Shutter'\n        self.shutter = shutter\n        super(ShutterUI, self).__init__(parent)\n        uic.loadUi(os.path.join(os.path.dirname(__file__), 'shutter.ui'), self)\n        self.auto_connect_by_name(controlled_object = self.shutter,verbose = False)",
  "def on_change(self):\n        self.shutter.toggle()",
  "def __init__(self):\n        \"\"\"Create a dummy shutter object\"\"\"\n        self._open = False\n        super(DummyShutter, self).__init__()",
  "def toggle(self):\n        \"\"\"toggle the state of the shutter\"\"\"\n        self._open = not self._open",
  "def get_state(self):\n        \"\"\"Return the state of the shutter, a string reading 'open' or 'closed'\"\"\"\n        return \"Open\" if self._open else \"Closed\"",
  "def set_state(self, value):\n        \"\"\"Set the state of the shutter (to open or closed)\"\"\"\n        if isinstance(value, str):\n            self._open = (value.lower() == \"open\")\n        elif isinstance(value, bool):\n            self._open = value",
  "class ArduinoShutter(ShutterWithEmulatedRead, SerialInstrument):\n    def __init__(self, port):\n        self.termination_character = '\\r'\n        SerialInstrument.__init__(self, port)\n        ShutterWithEmulatedRead.__init__(self)\n        self.flush_input_buffer()\n        self.readline()\n        self.timeout = 1\n    def set_state(self, State):\n        if State == self.get_state(): return print(f'shutter is already {State}')\n        if State == 'Open':\n            if self.query('1')!= '1\\n':\n                print('error opening shutter')\n        if State == 'Closed':\n            if self.query('0')!= '0\\n':\n                print('error opening shutter' )",
  "def __init__(self, port):\n        self.termination_character = '\\r'\n        SerialInstrument.__init__(self, port)\n        ShutterWithEmulatedRead.__init__(self)\n        self.flush_input_buffer()\n        self.readline()\n        self.timeout = 1",
  "def set_state(self, State):\n        if State == self.get_state(): return print(f'shutter is already {State}')\n        if State == 'Open':\n            if self.query('1')!= '1\\n':\n                print('error opening shutter')\n        if State == 'Closed':\n            if self.query('0')!= '0\\n':\n                print('error opening shutter' )",
  "class Keithley2635A(VisaInstrument):\n    \"\"\"Interface to the Keithley 2635A SMU.\"\"\"\n    def __init__(self, address='GPIB0::26::INSTR'):\n        super(Keithley2635A, self).__init__(address)\n        self.instr.read_termination = '\\n'\n        self.instr.write_termination = '\\n'\n        self.reset()\n\n    def reset(self):\n        \"\"\"Reset the SMU to its default state.\"\"\"\n        self.write('reset()')\n\n    output = queried_property('print(smua.source.output)', 'smua.source.output={0}',\n                              validate=['smua.OUTPUT_ON', 'smua.OUTPUT_OFF', 0, 1], dtype='str',\n                              doc='Turn the SMU on or off')\n    source = queried_property('print(smua.source.func)', 'smua.source.func={0}',\n                              validate=['smua.OUTPUT_DCVOLTS', 'smua.OUTPUT_DCAMPS', 0, 1], dtype='str',\n                              doc='Set the source type, either voltage or current')\n\n    # def set_src_voltage(self, voltage):\n    #    self.instr.write('smua.source.levelv=%s' % voltage)\n    #    self.check_voltage_range(voltage)\n\n    src_voltage = queried_property('print(smua.source.levelv)', 'smua.source.levelv={0}',\n                                   doc='Source voltage')\n    src_current = queried_property('print(smua.source.leveli)', 'smua.source.leveli={0}',\n                                   doc='Source current')\n    src_voltage_range = queried_property('print(smua.source.rangev)', 'smua.source.rangev={0}',\n                                         doc='Source voltage range')\n    src_current_range = queried_property('print(smua.source.rangei)', 'smua.source.rangei={0}',\n                                         doc='Source current range')\n    meas_voltage_range = queried_property('print(smua.measure.rangev)', 'smua.measure.rangev={0}',\n                                          doc='Measured voltage range')\n    meas_current_range = queried_property('print(smua.measure.rangei)', 'smua.measure.rangei={0}',\n                                          doc='Measured current range')\n    src_compliance = queried_property('print(smua.source.compliance)', 'smua.source.compliance={0}',\n                                      doc='Source compliance')\n    src_voltage_limit = queried_property('print(smua.source.limitv)', 'smua.source.limitv={0}',\n                                         doc='Source voltage limit')\n    src_current_limit = queried_property('print(smua.source.limiti)', 'smua.source.limiti={0}',\n                                         doc='Source current limit')\n\n    display = queried_property('print(display.smua.measure.func)', 'display.smua.measure.func={0}',\n                               validate=['display.MEASURE_DCAMPS', 'display.MEASURE_DCVOLTS', 'display.MEASURE_OHMS',\n                                         'display.MEASURE_WATTS', 0, 1, 2, 3],\n                               dtype='str', doc='Measurement displayed on the SMU front panel')\n\n    src_voltage_autorange = queried_property('print(smua.source.autorangev)', 'smua.source.autorangev=%s',\n                                             validate=[0, 1, False, True], dtype='int',\n                                             doc='Source voltage autorange')\n    src_current_autorange = queried_property('print(smua.source.autorangei)', 'smua.source.autorangei=%s',\n                                             validate=[0, 1, False, True], dtype='int',\n                                             doc='Source current autorange')\n\n    src_voltage_lowrange = queried_property('print(smua.source.lowrangev)', 'smua.source.lowrangev=%s',\n                                            doc='Minimum range the source voltage autorange will set')\n    src_current_lowrange = queried_property('print(smua.source.lowrangei)', 'smua.source.lowrangei=%s',\n                                            doc='Minimum range the source current autorange will set')\n\n    meas_voltage_autorange = queried_property('print(smua.measure.autorangev)', 'smua.measure.autorangev=%s',\n                                              validate=[0, 1, False, True], dtype='int',\n                                              doc='Measurement voltage autorange')\n    meas_current_autorange = queried_property('print(smua.measure.autorangei)', 'smua.measure.autorangei=%s',\n                                              validate=[0, 1, False, True], dtype='int',\n                                              doc='Measurement current autorange')\n\n    meas_voltage_lowrange = queried_property('print(smua.measure.lowrangev)', 'smua.measure.lowrangev=%s',\n                                             doc='Minimum range the measurement voltage autorange will set')\n    meas_current_lowrange = queried_property('print(smua.measure.lowrangei)', 'smua.measure.lowrangei=%s',\n                                             doc='Minimum range the measurement current autorange will set')\n\n    def read_voltage(self):\n        \"\"\"Measure the voltage.\"\"\"\n        return float(self.instr.query('print(smua.measure.v())'))\n\n    def read_current(self):\n        \"\"\"Measure the current.\"\"\"\n        return float(self.instr.query('print(smua.measure.i())'))\n\n    def read_resistance(self):\n        \"\"\"Measure the resistance.\"\"\"\n        return float(self.instr.query('print(smua.measure.r())'))\n\n    def read_power(self):\n        \"\"\"Measure the power.\"\"\"\n        return float(self.instr.query('print(smua.measure.p())'))\n\n    def read_iv(self):\n        \"\"\"Measure the voltage and the current.\"\"\"\n        self.instr.write('i,v = smua.measure.iv()')\n        return float(self.instr.query('print(i)')), \\\n               float(self.instr.query('print(v)'))\n\n    @property\n    def error(self):\n        \"\"\"Get the next error code from the SMU.\"\"\"\n        self.instr.write('errorCode, message = errorqueue.next()')\n        code = self.instr.query('print(errorCode)')\n        msg = self.instr.query('print(message)')\n        return '{0:s}: {1:s}'.format(code, msg)\n\n    def check_current_range(self, i):\n        i_range = self.get_meas_current_range()\n        while abs(i) >= i_range:\n            i_range = 10 ** (np.ceil(np.log10(i_range) + 1))  # go up one order of magnitude\n            self.set_meas_current_range(i_range)\n            i = self.read_current()\n            # print 'i up', i, i_range\n        if i != 0:\n            minimum = 1e-8\n            while (np.log10(abs(i)) - np.log10(i_range) <= -3) and i_range > minimum:\n                i_range = 10 ** (np.ceil(np.log10(abs(i))))\n                # set a lower limit\n                i_range = i_range if i_range >= minimum else minimum\n                self.set_meas_current_range(i_range)\n                i = self.read_current()\n                # print 'i down', i, i_range\n        return i\n\n    def check_voltage_range(self, v):\n        v_range = self.get_src_voltage_range()\n        while abs(v) >= v_range:  # say v=1.2 and v_range=1, aim for v_range=10\n            v_range = 2 * 10 ** (np.ceil(np.log10(abs(v))))\n            self.set_src_voltage_range(v_range)\n            v = self.get_src_voltage()\n            # print 'v up', v, v_range\n        # autorange to a lower voltage range if the voltage value is 2 orders\n        # of magnitude higher than the measurement\n        if v != 0:\n            minimum = 200e-3\n            while (np.log10(abs(v)) - np.log10(v_range) <= -2) and v_range > minimum:\n                v_range = 2 * 10 ** (np.ceil(np.log10(abs(v))))\n                v_range = v_range if v_range >= minimum else minimum\n                self.set_src_voltage_range(v_range)\n                v = self.get_src_voltage()\n                # print 'v down', v, v_range\n        return v\n\n    def get_qt_ui(self):\n        return SmuUI(self)",
  "class SmuUI(QtWidgets.QWidget):\n    def __init__(self, smu, parent=None):\n        super(SmuUI, self).__init__()\n        self.smu = smu\n        self.parent = parent\n        uic.loadUi(os.path.join(os.path.dirname(__file__), 'smu.ui'), self)\n\n        self.current_button.clicked.connect(self.state_changed)\n        self.voltage_button.clicked.connect(self.state_changed)\n        self.source_value.returnPressed.connect(self.set_parameter)\n        self.source_range.returnPressed.connect(self.set_parameter)\n        self.source_autorange.stateChanged.connect(self.state_changed)\n        self.source_limit.returnPressed.connect(self.set_parameter)\n        self.measurement_range.returnPressed.connect(self.set_parameter)\n        self.measurement_autorange.stateChanged.connect(self.state_changed)\n        self.measurement_limit.returnPressed.connect(self.set_parameter)\n        self.measure_button.clicked.connect(self.measure_button_clicked)\n        self.display_select.activated[str].connect(self.on_activated)\n        self.output.stateChanged.connect(self.state_changed)\n\n        self.voltage_button.setChecked(True)\n        self.source_value.setText(str(self.smu.src_voltage))\n        self.source_range.setText(str(self.smu.src_voltage_range))\n        self.source_autorange.setChecked(bool(self.smu.src_voltage_autorange))\n        self.source_limit.setText(str(self.smu.src_voltage_limit))\n        self.measurement_range.setText(str(self.smu.meas_current_range))\n        self.measurement_autorange.setChecked(bool(self.smu.meas_current_autorange))\n        self.measurement_limit.setText(str(self.smu.src_current_limit))\n        self.output.setChecked(False)\n\n    def set_parameter(self):\n        sender = self.sender()\n        value = sender.text()\n        if sender.validator() is not None:\n            state = sender.validator().validate(value, 0)[0]\n            if state != QtGui.QValidator.Acceptable:\n                return\n        if self.voltage_button.isChecked():\n            if sender == self.source_value:\n                self.smu.src_voltage = float(value)\n            elif sender == self.source_range:\n                self.source_autorange.setChecked(False)\n                self.smu.src_voltage_range = float(value)\n            elif sender == self.source_limit:\n                self.smu.src_voltage_limit = float(value)\n            elif sender == self.measurement_range:\n                self.measurement_autorange.setChecked(False)\n                self.smu.meas_current_range = float(value)\n            elif sender == self.measurement_limit:\n                self.smu.src_current_limit = float(value)\n        elif self.current_button.isChecked():\n            if sender == self.source_value:\n                self.smu.src_current = float(value)\n            elif sender == self.source_range:\n                self.source_autorange.setChecked(False)\n                self.smu.src_current_range = float(value)\n            elif sender == self.source_limit:\n                self.smu.src_current_limit = float(value)\n            elif sender == self.measurement_range:\n                self.maesurement_autorange.setChecked(False)\n                self.smu.meas_voltage_range = float(value)\n            elif sender == self.measurement_limit:\n                self.smu.meas_voltage_limit = float(value)\n\n    def state_changed(self, state):\n        sender = self.sender()\n        value = True if state == QtCore.Qt.Checked else False\n        if sender == self.voltage_button:\n            if value:\n                self.current_button.blockSignals(True)\n                self.current_button.setChecked(False)\n                self.current_button.blockSignals(False)\n                self.smu.source = 0\n        elif sender == self.current_button:\n            if value:\n                self.voltage_button.blockSignals(True)\n                self.voltage_button.setChecked(False)\n                self.voltage_button.blockSignals(False)\n                self.smu.source = 1\n        elif sender == self.source_autorange:\n            if self.voltage_button.isChecked():\n                self.smu.src_voltage_autorange = value\n            elif self.current_button.isChecked():\n                self.smu.src_current_autorange = value\n        elif sender == self.measurement_autorange:\n            if self.voltage_button.isChecked():\n                self.smu.meas_current_autorange = value\n            elif self.current_button.isChecked():\n                self.smu.meas_voltage_autorange = value\n        elif sender == self.output:\n            if value:\n                self.smu.output = 1\n            else:\n                self.smu.output = 0\n\n    def measure_button_clicked(self):\n        voltage = self.smu.read_voltage()\n        current = self.smu.read_current()\n        resistance = self.smu.read_resistance()\n        power = self.smu.read_power()\n        self.measurements.setText(\n            '{0:.2e} V, {1:.2e} A, {2:.2e} Ohms, {3:.2e} W'.format(voltage, current, resistance, power))\n\n    def on_activated(self, value):\n        # print self.sender(), index, value\n        if value == 'voltage':\n            self.smu.display = 1\n        elif value == 'current':\n            self.smu.display = 0\n        elif value == 'resistance':\n            self.smu.display = 2\n        elif value == 'power':\n            self.smu.display = 3",
  "def __init__(self, address='GPIB0::26::INSTR'):\n        super(Keithley2635A, self).__init__(address)\n        self.instr.read_termination = '\\n'\n        self.instr.write_termination = '\\n'\n        self.reset()",
  "def reset(self):\n        \"\"\"Reset the SMU to its default state.\"\"\"\n        self.write('reset()')",
  "def read_voltage(self):\n        \"\"\"Measure the voltage.\"\"\"\n        return float(self.instr.query('print(smua.measure.v())'))",
  "def read_current(self):\n        \"\"\"Measure the current.\"\"\"\n        return float(self.instr.query('print(smua.measure.i())'))",
  "def read_resistance(self):\n        \"\"\"Measure the resistance.\"\"\"\n        return float(self.instr.query('print(smua.measure.r())'))",
  "def read_power(self):\n        \"\"\"Measure the power.\"\"\"\n        return float(self.instr.query('print(smua.measure.p())'))",
  "def read_iv(self):\n        \"\"\"Measure the voltage and the current.\"\"\"\n        self.instr.write('i,v = smua.measure.iv()')\n        return float(self.instr.query('print(i)')), \\\n               float(self.instr.query('print(v)'))",
  "def error(self):\n        \"\"\"Get the next error code from the SMU.\"\"\"\n        self.instr.write('errorCode, message = errorqueue.next()')\n        code = self.instr.query('print(errorCode)')\n        msg = self.instr.query('print(message)')\n        return '{0:s}: {1:s}'.format(code, msg)",
  "def check_current_range(self, i):\n        i_range = self.get_meas_current_range()\n        while abs(i) >= i_range:\n            i_range = 10 ** (np.ceil(np.log10(i_range) + 1))  # go up one order of magnitude\n            self.set_meas_current_range(i_range)\n            i = self.read_current()\n            # print 'i up', i, i_range\n        if i != 0:\n            minimum = 1e-8\n            while (np.log10(abs(i)) - np.log10(i_range) <= -3) and i_range > minimum:\n                i_range = 10 ** (np.ceil(np.log10(abs(i))))\n                # set a lower limit\n                i_range = i_range if i_range >= minimum else minimum\n                self.set_meas_current_range(i_range)\n                i = self.read_current()\n                # print 'i down', i, i_range\n        return i",
  "def check_voltage_range(self, v):\n        v_range = self.get_src_voltage_range()\n        while abs(v) >= v_range:  # say v=1.2 and v_range=1, aim for v_range=10\n            v_range = 2 * 10 ** (np.ceil(np.log10(abs(v))))\n            self.set_src_voltage_range(v_range)\n            v = self.get_src_voltage()\n            # print 'v up', v, v_range\n        # autorange to a lower voltage range if the voltage value is 2 orders\n        # of magnitude higher than the measurement\n        if v != 0:\n            minimum = 200e-3\n            while (np.log10(abs(v)) - np.log10(v_range) <= -2) and v_range > minimum:\n                v_range = 2 * 10 ** (np.ceil(np.log10(abs(v))))\n                v_range = v_range if v_range >= minimum else minimum\n                self.set_src_voltage_range(v_range)\n                v = self.get_src_voltage()\n                # print 'v down', v, v_range\n        return v",
  "def get_qt_ui(self):\n        return SmuUI(self)",
  "def __init__(self, smu, parent=None):\n        super(SmuUI, self).__init__()\n        self.smu = smu\n        self.parent = parent\n        uic.loadUi(os.path.join(os.path.dirname(__file__), 'smu.ui'), self)\n\n        self.current_button.clicked.connect(self.state_changed)\n        self.voltage_button.clicked.connect(self.state_changed)\n        self.source_value.returnPressed.connect(self.set_parameter)\n        self.source_range.returnPressed.connect(self.set_parameter)\n        self.source_autorange.stateChanged.connect(self.state_changed)\n        self.source_limit.returnPressed.connect(self.set_parameter)\n        self.measurement_range.returnPressed.connect(self.set_parameter)\n        self.measurement_autorange.stateChanged.connect(self.state_changed)\n        self.measurement_limit.returnPressed.connect(self.set_parameter)\n        self.measure_button.clicked.connect(self.measure_button_clicked)\n        self.display_select.activated[str].connect(self.on_activated)\n        self.output.stateChanged.connect(self.state_changed)\n\n        self.voltage_button.setChecked(True)\n        self.source_value.setText(str(self.smu.src_voltage))\n        self.source_range.setText(str(self.smu.src_voltage_range))\n        self.source_autorange.setChecked(bool(self.smu.src_voltage_autorange))\n        self.source_limit.setText(str(self.smu.src_voltage_limit))\n        self.measurement_range.setText(str(self.smu.meas_current_range))\n        self.measurement_autorange.setChecked(bool(self.smu.meas_current_autorange))\n        self.measurement_limit.setText(str(self.smu.src_current_limit))\n        self.output.setChecked(False)",
  "def set_parameter(self):\n        sender = self.sender()\n        value = sender.text()\n        if sender.validator() is not None:\n            state = sender.validator().validate(value, 0)[0]\n            if state != QtGui.QValidator.Acceptable:\n                return\n        if self.voltage_button.isChecked():\n            if sender == self.source_value:\n                self.smu.src_voltage = float(value)\n            elif sender == self.source_range:\n                self.source_autorange.setChecked(False)\n                self.smu.src_voltage_range = float(value)\n            elif sender == self.source_limit:\n                self.smu.src_voltage_limit = float(value)\n            elif sender == self.measurement_range:\n                self.measurement_autorange.setChecked(False)\n                self.smu.meas_current_range = float(value)\n            elif sender == self.measurement_limit:\n                self.smu.src_current_limit = float(value)\n        elif self.current_button.isChecked():\n            if sender == self.source_value:\n                self.smu.src_current = float(value)\n            elif sender == self.source_range:\n                self.source_autorange.setChecked(False)\n                self.smu.src_current_range = float(value)\n            elif sender == self.source_limit:\n                self.smu.src_current_limit = float(value)\n            elif sender == self.measurement_range:\n                self.maesurement_autorange.setChecked(False)\n                self.smu.meas_voltage_range = float(value)\n            elif sender == self.measurement_limit:\n                self.smu.meas_voltage_limit = float(value)",
  "def state_changed(self, state):\n        sender = self.sender()\n        value = True if state == QtCore.Qt.Checked else False\n        if sender == self.voltage_button:\n            if value:\n                self.current_button.blockSignals(True)\n                self.current_button.setChecked(False)\n                self.current_button.blockSignals(False)\n                self.smu.source = 0\n        elif sender == self.current_button:\n            if value:\n                self.voltage_button.blockSignals(True)\n                self.voltage_button.setChecked(False)\n                self.voltage_button.blockSignals(False)\n                self.smu.source = 1\n        elif sender == self.source_autorange:\n            if self.voltage_button.isChecked():\n                self.smu.src_voltage_autorange = value\n            elif self.current_button.isChecked():\n                self.smu.src_current_autorange = value\n        elif sender == self.measurement_autorange:\n            if self.voltage_button.isChecked():\n                self.smu.meas_current_autorange = value\n            elif self.current_button.isChecked():\n                self.smu.meas_voltage_autorange = value\n        elif sender == self.output:\n            if value:\n                self.smu.output = 1\n            else:\n                self.smu.output = 0",
  "def measure_button_clicked(self):\n        voltage = self.smu.read_voltage()\n        current = self.smu.read_current()\n        resistance = self.smu.read_resistance()\n        power = self.smu.read_power()\n        self.measurements.setText(\n            '{0:.2e} V, {1:.2e} A, {2:.2e} Ohms, {3:.2e} W'.format(voltage, current, resistance, power))",
  "def on_activated(self, value):\n        # print self.sender(), index, value\n        if value == 'voltage':\n            self.smu.display = 1\n        elif value == 'current':\n            self.smu.display = 0\n        elif value == 'resistance':\n            self.smu.display = 2\n        elif value == 'power':\n            self.smu.display = 3",
  "class NewportPowermeter(Instrument):\n    def __init__(self, product_id, **kwargs):\n        \"\"\"\n\n        :param product_id: go to Device Manager, double click on instrument, go to Details, in the Property drop-down,\n                select Hardware IDs. If the ID is something like PID_ABC1, use product_id = 0xACB1\n        :param kwargs:\n        \"\"\"\n        super(NewportPowermeter, self).__init__()\n        if \"libname\" in kwargs:\n            libname = kwargs[\"libname\"]\n        else:\n            libname = \"usbdll.dll\"\n        self.dll = windll.LoadLibrary(libname)\n\n        self.product_id = product_id\n\n        self.open_device_with_product_id()\n        self.instrument = self.get_instrument_list()\n        self.device_id, self.model_number, self.serial_number = self.instrument\n\n        self.wvl_range = [int(self.query('PM:MIN:Lambda?')), int(self.query('PM:MAX:Lambda?'))]\n\n    # def __del__(self):\n    #     self.close_device()\n\n    def _dllWrapper(self, command, *args):\n        \"\"\"Simple dll wrapper\n        Takes care of the error checking for all dll calls\n        :param command: string with the command name\n        :param args: list of (optional) arguments to pass to the dll function\n        :return:\n        \"\"\"\n        self._logger.debug(\"Calling DLL with: %s %s\" % (command, args))\n        status = getattr(self.dll, command)(*args)\n        if status != 0:\n            raise Exception('%s failed with status %s' % (command, status))\n        else:\n            pass\n\n    def open_device_all_products_all_devices(self):\n        self._dllWrapper(\"newp_usb_init_system\")\n        self._logger.info(\"You have connected to one or more Newport products\")\n\n    def open_device_with_product_id(self):\n        \"\"\"\n        opens a device with a certain product id\n\n        \"\"\"\n        cproductid = c_int(self.product_id)\n        useusbaddress = c_bool(1)  # We will only use deviceids or addresses\n        num_devices = c_int()\n\n        self._dllWrapper(\"newp_usb_open_devices\", cproductid, useusbaddress, byref(num_devices))\n\n    def close_device(self):\n        self._dllWrapper(\"newp_usb_uninit_system\")\n\n    def get_instrument_list(self):\n        arInstruments = c_int()\n        arInstrumentsModel = c_int()\n        arInstrumentsSN = c_int()\n        nArraySize = c_int()\n        self._dllWrapper(\"GetInstrumentList\", byref(arInstruments), byref(arInstrumentsModel), byref(arInstrumentsSN),\n                         byref(nArraySize))\n        instrument_list = [arInstruments.value, arInstrumentsModel.value, arInstrumentsSN.value]\n        return instrument_list\n\n    def query(self, query_string):\n        \"\"\"\n        Write a query and read the response from the device\n        :rtype : String\n        :param query_string: Check Manual for commands, ex '*IDN?'\n        :return:\n        \"\"\"\n        self.write(query_string)\n        return self.read()\n\n    def read(self):\n        cdevice_id = c_long(self.device_id)\n        time.sleep(0.2)\n        response = create_string_buffer(('\\000' * 1024).encode())\n        leng = c_ulong(1024)\n        read_bytes = c_ulong()\n        self._dllWrapper(\"newp_usb_get_ascii\", cdevice_id, byref(response), leng, byref(read_bytes))\n        answer = response.value[0:read_bytes.value].rstrip(b'\\r\\n')\n        return answer\n\n    def write(self, command_string):\n        \"\"\"\n        Write a string to the device\n\n        :param command_string: Name of the string to be sent. Check Manual for commands\n        :raise:\n        \"\"\"\n        command = create_string_buffer(command_string.encode())\n        length = c_ulong(sizeof(command))\n        cdevice_id = c_long(self.device_id)\n\n        self._dllWrapper(\"newp_usb_send_ascii\", cdevice_id, byref(command), length)\n\n    @property\n    def channel(self):\n        return self.query(\"PM:CHANnel?\")\n\n    @channel.setter\n    def channel(self, channel):\n        assert channel in [1, 2]\n\n        self.write(\"PM:CHANnel \" + str(channel))\n\n    @property\n    def wavelength(self):\n        self._logger.debug(\"Reading wavelength\")\n        return self.query('PM:Lambda?')\n\n    @wavelength.setter\n    def wavelength(self, wavelength):\n        \"\"\"\n        Sets the wavelength on the device\n        :param wavelength int: float\n        \"\"\"\n        self._logger.debug(\"Setting wavelength\")\n        if not isinstance(wavelength, int):\n            self._logger.info('Wavelength has to be an integer. Converting to integer')\n            wavelength = int(wavelength)\n        assert self.wvl_range[0] <= wavelength <= self.wvl_range[1]\n\n        self.write('PM:Lambda ' + str(wavelength))\n\n    def set_filtering(self, filter_type=0):\n        \"\"\"\n        Set the filtering on the device\n        :param filter_type:\n        0:No filtering\n        1:Analog filter\n        2:Digital filter\n        3:Analog and Digital filter\n        \"\"\"\n        if filter_type in [0, 1, 2, 3]:\n            self.write(\"PM:FILT %d\" % filter_type)\n        else:\n            raise ValueError(\"filter_type needs to be between 0 and 3\")\n\n    def read_buffer(self, wavelength=700, buff_size=1000, interval_ms=1):\n        \"\"\"\n        Stores the power values at a certain wavelength.\n        :param wavelength: float: Wavelength at which this operation should be done. float.\n        :param buff_size: int: nuber of readings that will be taken\n        :param interval_ms: float: Time between readings in ms.\n        :return: [actualwavelength,mean_power,std_power]\n        \"\"\"\n        self.wavelength = wavelength\n        self.write('PM:DS:Clear')\n        self.write('PM:DS:SIZE ' + str(buff_size))\n        self.write('PM:DS:INT ' + str(\n            interval_ms * 10))  # to set 1 ms rate we have to give int value of 10. This is strange as manual says the INT should be in ms\n        self.write('PM:DS:ENable 1')\n        while int(self.query('PM:DS:COUNT?')) < buff_size:  # Waits for the buffer is full or not.\n            time.sleep(old_div(0.001 * interval_ms * buff_size, 10))\n        actualwavelength = self.query('PM:Lambda?')\n        mean_power = self.query('PM:STAT:MEAN?')\n        std_power = self.query('PM:STAT:SDEV?')\n        self.write('PM:DS:Clear')\n        return [actualwavelength, mean_power, std_power]\n\n    @property\n    def power(self):\n        \"\"\"\n        Reads the instantaneous power\n        \"\"\"\n\n        power = self.query('PM:Power?')\n        return float(power)",
  "def __init__(self, product_id, **kwargs):\n        \"\"\"\n\n        :param product_id: go to Device Manager, double click on instrument, go to Details, in the Property drop-down,\n                select Hardware IDs. If the ID is something like PID_ABC1, use product_id = 0xACB1\n        :param kwargs:\n        \"\"\"\n        super(NewportPowermeter, self).__init__()\n        if \"libname\" in kwargs:\n            libname = kwargs[\"libname\"]\n        else:\n            libname = \"usbdll.dll\"\n        self.dll = windll.LoadLibrary(libname)\n\n        self.product_id = product_id\n\n        self.open_device_with_product_id()\n        self.instrument = self.get_instrument_list()\n        self.device_id, self.model_number, self.serial_number = self.instrument\n\n        self.wvl_range = [int(self.query('PM:MIN:Lambda?')), int(self.query('PM:MAX:Lambda?'))]",
  "def _dllWrapper(self, command, *args):\n        \"\"\"Simple dll wrapper\n        Takes care of the error checking for all dll calls\n        :param command: string with the command name\n        :param args: list of (optional) arguments to pass to the dll function\n        :return:\n        \"\"\"\n        self._logger.debug(\"Calling DLL with: %s %s\" % (command, args))\n        status = getattr(self.dll, command)(*args)\n        if status != 0:\n            raise Exception('%s failed with status %s' % (command, status))\n        else:\n            pass",
  "def open_device_all_products_all_devices(self):\n        self._dllWrapper(\"newp_usb_init_system\")\n        self._logger.info(\"You have connected to one or more Newport products\")",
  "def open_device_with_product_id(self):\n        \"\"\"\n        opens a device with a certain product id\n\n        \"\"\"\n        cproductid = c_int(self.product_id)\n        useusbaddress = c_bool(1)  # We will only use deviceids or addresses\n        num_devices = c_int()\n\n        self._dllWrapper(\"newp_usb_open_devices\", cproductid, useusbaddress, byref(num_devices))",
  "def close_device(self):\n        self._dllWrapper(\"newp_usb_uninit_system\")",
  "def get_instrument_list(self):\n        arInstruments = c_int()\n        arInstrumentsModel = c_int()\n        arInstrumentsSN = c_int()\n        nArraySize = c_int()\n        self._dllWrapper(\"GetInstrumentList\", byref(arInstruments), byref(arInstrumentsModel), byref(arInstrumentsSN),\n                         byref(nArraySize))\n        instrument_list = [arInstruments.value, arInstrumentsModel.value, arInstrumentsSN.value]\n        return instrument_list",
  "def query(self, query_string):\n        \"\"\"\n        Write a query and read the response from the device\n        :rtype : String\n        :param query_string: Check Manual for commands, ex '*IDN?'\n        :return:\n        \"\"\"\n        self.write(query_string)\n        return self.read()",
  "def read(self):\n        cdevice_id = c_long(self.device_id)\n        time.sleep(0.2)\n        response = create_string_buffer(('\\000' * 1024).encode())\n        leng = c_ulong(1024)\n        read_bytes = c_ulong()\n        self._dllWrapper(\"newp_usb_get_ascii\", cdevice_id, byref(response), leng, byref(read_bytes))\n        answer = response.value[0:read_bytes.value].rstrip(b'\\r\\n')\n        return answer",
  "def write(self, command_string):\n        \"\"\"\n        Write a string to the device\n\n        :param command_string: Name of the string to be sent. Check Manual for commands\n        :raise:\n        \"\"\"\n        command = create_string_buffer(command_string.encode())\n        length = c_ulong(sizeof(command))\n        cdevice_id = c_long(self.device_id)\n\n        self._dllWrapper(\"newp_usb_send_ascii\", cdevice_id, byref(command), length)",
  "def channel(self):\n        return self.query(\"PM:CHANnel?\")",
  "def channel(self, channel):\n        assert channel in [1, 2]\n\n        self.write(\"PM:CHANnel \" + str(channel))",
  "def wavelength(self):\n        self._logger.debug(\"Reading wavelength\")\n        return self.query('PM:Lambda?')",
  "def wavelength(self, wavelength):\n        \"\"\"\n        Sets the wavelength on the device\n        :param wavelength int: float\n        \"\"\"\n        self._logger.debug(\"Setting wavelength\")\n        if not isinstance(wavelength, int):\n            self._logger.info('Wavelength has to be an integer. Converting to integer')\n            wavelength = int(wavelength)\n        assert self.wvl_range[0] <= wavelength <= self.wvl_range[1]\n\n        self.write('PM:Lambda ' + str(wavelength))",
  "def set_filtering(self, filter_type=0):\n        \"\"\"\n        Set the filtering on the device\n        :param filter_type:\n        0:No filtering\n        1:Analog filter\n        2:Digital filter\n        3:Analog and Digital filter\n        \"\"\"\n        if filter_type in [0, 1, 2, 3]:\n            self.write(\"PM:FILT %d\" % filter_type)\n        else:\n            raise ValueError(\"filter_type needs to be between 0 and 3\")",
  "def read_buffer(self, wavelength=700, buff_size=1000, interval_ms=1):\n        \"\"\"\n        Stores the power values at a certain wavelength.\n        :param wavelength: float: Wavelength at which this operation should be done. float.\n        :param buff_size: int: nuber of readings that will be taken\n        :param interval_ms: float: Time between readings in ms.\n        :return: [actualwavelength,mean_power,std_power]\n        \"\"\"\n        self.wavelength = wavelength\n        self.write('PM:DS:Clear')\n        self.write('PM:DS:SIZE ' + str(buff_size))\n        self.write('PM:DS:INT ' + str(\n            interval_ms * 10))  # to set 1 ms rate we have to give int value of 10. This is strange as manual says the INT should be in ms\n        self.write('PM:DS:ENable 1')\n        while int(self.query('PM:DS:COUNT?')) < buff_size:  # Waits for the buffer is full or not.\n            time.sleep(old_div(0.001 * interval_ms * buff_size, 10))\n        actualwavelength = self.query('PM:Lambda?')\n        mean_power = self.query('PM:STAT:MEAN?')\n        std_power = self.query('PM:STAT:SDEV?')\n        self.write('PM:DS:Clear')\n        return [actualwavelength, mean_power, std_power]",
  "def power(self):\n        \"\"\"\n        Reads the instantaneous power\n        \"\"\"\n\n        power = self.query('PM:Power?')\n        return float(power)",
  "class SignalGenerator(SerialInstrument):\n    port_settings = dict(baudrate=9600,\n                    bytesize=serial.EIGHTBITS,\n                    parity=serial.PARITY_NONE,\n                    stopbits=serial.STOPBITS_ONE,\n                    timeout=1, #wait at most one second for a response\n                    writeTimeout=1, #similarly, fail if writing takes >1s\n                    xonxoff=False, rtscts=False, dsrdtr=True,\n                )\n    def __init__(self, port=None):\n        SerialInstrument.__init__(self, port=port) #this opens the port\n        self.query(\"SYST:REMOTE\")\n\n    frequency = queried_property('freq?', 'freq {0}')\n    function = queried_property('function:shape?', 'function:shape {0}',\n                                validate=['sinusoid', 'dc', 'square'], dtype='str')\n    voltage = queried_property('voltage?', 'voltage {0}')\n    offset = queried_property('voltage:offset?', 'voltage:offset {0}')\n    output_load = queried_property('output:load?', 'output:load {0}',\n                                   validate=['inf'], dtype='str')\n    volt_high = queried_property('volt:high?', 'volt:high {0}')\n    volt_low = queried_property('volt:low?', 'volt:low {0}')\n\n    def reset(self):\n        self.write('*rst')",
  "def __init__(self, port=None):\n        SerialInstrument.__init__(self, port=port) #this opens the port\n        self.query(\"SYST:REMOTE\")",
  "def reset(self):\n        self.write('*rst')",
  "class PowerMeter(Instrument):\n    '''\n    brings basic nplab functionality, and a gui with live mode to a powermeter.\n    The minimum you need to do to subclass this is overwrite the read_power method\n    '''\n    live = DumbNotifiedProperty(False)\n    beep = DumbNotifiedProperty(False)\n    def __init__(self):\n        Instrument.__init__(self)\n        \n    def read_power(self):\n        raise NotImplementedError\n    @property\n    def power(self):\n        return self.read_power()\n        \n    def get_qt_ui(self):\n        return PowerMeterUI(self)",
  "class PowerMeterUI(QtWidgets.QWidget, UiTools):\n    update_data_signal = QtCore.Signal(np.ndarray)\n    def __init__(self, pm):    \n        super(PowerMeterUI, self).__init__()\n        uic.loadUi(os.path.join(os.path.dirname(__file__), 'power_meter.ui'),self)\n        self.pm = pm        \n        self.update_condition = threading.Condition()        \n        self.display_thread = DisplayThread(self)        \n        self.SetupSignals()\n        register_for_property_changes(self.pm, 'live', self.live_changed)\n        register_for_property_changes(self.pm, 'beep', self.beep_changed)\n    \n    def SetupSignals(self):\n        self.read_pushButton.clicked.connect(self.button_pressed)\n        self.live_button.clicked.connect(self.button_pressed)\n        self.beep_button.clicked.connect(self.beep_pressed)\n        self.display_thread.ready.connect(self.update_display)\n        \n    def button_pressed(self):\n        s = self.sender()\n        if s == self.read_pushButton:\n            self.display_thread.single_shot = True\n        elif s == self.live_button:\n            self.pm.live = self.live_button.isChecked()\n        self.display_thread.start()\n    def beep_pressed(self):\n        self.pm.beep = self.beep_button.isChecked()\n    def update_display(self, power):\n        self.power_lcdNumber.display(float(power))\n    def live_changed(self, new):\n        if self.live_button.isChecked() is not self.pm.live:\n            self.live_button.setChecked(new)\n        self.display_thread.start()\n    def beep_changed(self, new):\n        if self.beep_button.isChecked() is not self.pm.beep:\n            self.beep_button.setChecked(new)",
  "class DisplayThread(QtCore.QThread):\n    ready = QtCore.Signal(float)\n    def __init__(self, parent):\n        super(DisplayThread, self).__init__()\n        self.parent = parent\n        self.single_shot = False\n        self.refresh_rate = 4.\n    def run(self):\n        t0 = time.time()\n        beep_power = self.parent.pm.power\n        while self.parent.pm.live or self.single_shot:\n            p = self.parent.pm.power\n            if time.time()-t0 < 1./self.refresh_rate:\n                continue\n            else:\n                t0 = time.time()\n            \n            if self.parent.pm.beep:\n                beep_freq = 1500*(p/beep_power)\n                if 37<beep_freq<32767:\n                    winsound.Beep(int(beep_freq), 100)\n                    \n            self.ready.emit(p)\n            if self.single_shot:\n                self.single_shot = False               \n                break\n        self.finished.emit()",
  "class dummyPowerMeter(PowerMeter):\n    def __init__(self):\n        super(PowerMeter, self).__init__()\n    def read_power(self):\n        return np.random.rand()*10",
  "def __init__(self):\n        Instrument.__init__(self)",
  "def read_power(self):\n        raise NotImplementedError",
  "def power(self):\n        return self.read_power()",
  "def get_qt_ui(self):\n        return PowerMeterUI(self)",
  "def __init__(self, pm):    \n        super(PowerMeterUI, self).__init__()\n        uic.loadUi(os.path.join(os.path.dirname(__file__), 'power_meter.ui'),self)\n        self.pm = pm        \n        self.update_condition = threading.Condition()        \n        self.display_thread = DisplayThread(self)        \n        self.SetupSignals()\n        register_for_property_changes(self.pm, 'live', self.live_changed)\n        register_for_property_changes(self.pm, 'beep', self.beep_changed)",
  "def SetupSignals(self):\n        self.read_pushButton.clicked.connect(self.button_pressed)\n        self.live_button.clicked.connect(self.button_pressed)\n        self.beep_button.clicked.connect(self.beep_pressed)\n        self.display_thread.ready.connect(self.update_display)",
  "def button_pressed(self):\n        s = self.sender()\n        if s == self.read_pushButton:\n            self.display_thread.single_shot = True\n        elif s == self.live_button:\n            self.pm.live = self.live_button.isChecked()\n        self.display_thread.start()",
  "def beep_pressed(self):\n        self.pm.beep = self.beep_button.isChecked()",
  "def update_display(self, power):\n        self.power_lcdNumber.display(float(power))",
  "def live_changed(self, new):\n        if self.live_button.isChecked() is not self.pm.live:\n            self.live_button.setChecked(new)\n        self.display_thread.start()",
  "def beep_changed(self, new):\n        if self.beep_button.isChecked() is not self.pm.beep:\n            self.beep_button.setChecked(new)",
  "def __init__(self, parent):\n        super(DisplayThread, self).__init__()\n        self.parent = parent\n        self.single_shot = False\n        self.refresh_rate = 4.",
  "def run(self):\n        t0 = time.time()\n        beep_power = self.parent.pm.power\n        while self.parent.pm.live or self.single_shot:\n            p = self.parent.pm.power\n            if time.time()-t0 < 1./self.refresh_rate:\n                continue\n            else:\n                t0 = time.time()\n            \n            if self.parent.pm.beep:\n                beep_freq = 1500*(p/beep_power)\n                if 37<beep_freq<32767:\n                    winsound.Beep(int(beep_freq), 100)\n                    \n            self.ready.emit(p)\n            if self.single_shot:\n                self.single_shot = False               \n                break\n        self.finished.emit()",
  "def __init__(self):\n        super(PowerMeter, self).__init__()",
  "def read_power(self):\n        return np.random.rand()*10",
  "class TBS1032B(VisaInstrument):\n    \"\"\"Visa Interface for TBS1032B Tektronix Digital Oscilloscope\"\"\"\n    def __init__(self, address='GPIB0::3::INSTR'):\n        super(TBS1032B, self).__init__(address)\n    \n    def channel(self, channel):\n        self.write('MEASUrement:IMMed:SOUrce CH' + str(channel))\n    \n    def set_probe(self, channel, probe):\n        self.write('CH'+str(channel)+':PRObe' + str(probe))\n    \n    def autoset(self):\n        self.write('AUTOSet EXECute')\n    \n    def acquisition(self, acq):\n        \"\"\" RUN or STOP\"\"\"\n        self.write('ACQuire:STATE ' + str(acq))\n    \n    def read_par(self, channel, parameter):\n        \"\"\"Reading given parameter value and returning a list of (value type, value)\"\"\"\n        avoid_random_output=False\n        \n        if parameter in ['frequency', 'freq', 'Frequency', 'Freq', 'FREQUENCY', 'FREQ']:\n            par='FREQuency'\n        elif parameter in ['Mean', 'mean', 'MEAN']:\n            par='MEAN'\n        elif parameter in ['period', 'per', 'Period', 'PERIOD', 'PER']:\n            par='PERIod'\n        elif parameter in ['phase','Phase','PHASE']:\n            par='PHAse'\n        elif parameter in ['peak-peak','peak_to_peak','V_pp', 'pk2pk', 'Vpp', 'VPP']:\n            par='PK2pk'\n        elif parameter in ['Vrms','Voltage_rms']:\n            par='CRMs'\n        elif parameter in ['minimum','min','Minimum', 'Min']:\n            par='MINImum'    \n        elif parameter in ['maximum','max','Maximum', 'Max']:\n            par='MAXImum' \n        elif parameter in ['rise','Rise']:\n            par='RISe'      \n        elif parameter in ['Fall','fall']:\n            par='FALL'   \n        elif parameter in ['ampl', 'amplitude', 'Amplitude','Ampl', 'AMPLITUDE', 'AMPL']:\n            par='amplitude' \n        elif parameter in ['attenuation', 'probe', 'att']:\n            par='CH'+ str(channel) + ':PRObe?'\n            return self.output_typo_adjust('probe',self.query(str(par)))\n        else:\n            print('Having problem reading oscilloscope query')\n            avoid_random_output=True\n        \n        if (avoid_random_output==False) and (parameter not in ['attenuation', 'probe', 'att']):\n            self.write('MEASUrement:IMMed:TYPe ' + str(par))\n            a=self.query('MEASUrement:IMMed:TYPe?')\n            b=self.query('MEASUrement:IMMed:VALue?')\n            return self.output_typo_adjust(a,b)\n        else:\n            return ('Nothing', None)\n\n\n    def output_typo_adjust(self, a, b):\n        a=a\n        b=b\n        if a[len(a)-1]=='\\n':\n            a=a[:len(a)-1]\n        if b[len(b)-1]=='\\n':\n            b=float(b[:len(b)-1])\n      \n        return (a,b)",
  "def __init__(self, address='GPIB0::3::INSTR'):\n        super(TBS1032B, self).__init__(address)",
  "def channel(self, channel):\n        self.write('MEASUrement:IMMed:SOUrce CH' + str(channel))",
  "def set_probe(self, channel, probe):\n        self.write('CH'+str(channel)+':PRObe' + str(probe))",
  "def autoset(self):\n        self.write('AUTOSet EXECute')",
  "def acquisition(self, acq):\n        \"\"\" RUN or STOP\"\"\"\n        self.write('ACQuire:STATE ' + str(acq))",
  "def read_par(self, channel, parameter):\n        \"\"\"Reading given parameter value and returning a list of (value type, value)\"\"\"\n        avoid_random_output=False\n        \n        if parameter in ['frequency', 'freq', 'Frequency', 'Freq', 'FREQUENCY', 'FREQ']:\n            par='FREQuency'\n        elif parameter in ['Mean', 'mean', 'MEAN']:\n            par='MEAN'\n        elif parameter in ['period', 'per', 'Period', 'PERIOD', 'PER']:\n            par='PERIod'\n        elif parameter in ['phase','Phase','PHASE']:\n            par='PHAse'\n        elif parameter in ['peak-peak','peak_to_peak','V_pp', 'pk2pk', 'Vpp', 'VPP']:\n            par='PK2pk'\n        elif parameter in ['Vrms','Voltage_rms']:\n            par='CRMs'\n        elif parameter in ['minimum','min','Minimum', 'Min']:\n            par='MINImum'    \n        elif parameter in ['maximum','max','Maximum', 'Max']:\n            par='MAXImum' \n        elif parameter in ['rise','Rise']:\n            par='RISe'      \n        elif parameter in ['Fall','fall']:\n            par='FALL'   \n        elif parameter in ['ampl', 'amplitude', 'Amplitude','Ampl', 'AMPLITUDE', 'AMPL']:\n            par='amplitude' \n        elif parameter in ['attenuation', 'probe', 'att']:\n            par='CH'+ str(channel) + ':PRObe?'\n            return self.output_typo_adjust('probe',self.query(str(par)))\n        else:\n            print('Having problem reading oscilloscope query')\n            avoid_random_output=True\n        \n        if (avoid_random_output==False) and (parameter not in ['attenuation', 'probe', 'att']):\n            self.write('MEASUrement:IMMed:TYPe ' + str(par))\n            a=self.query('MEASUrement:IMMed:TYPe?')\n            b=self.query('MEASUrement:IMMed:VALue?')\n            return self.output_typo_adjust(a,b)\n        else:\n            return ('Nothing', None)",
  "def output_typo_adjust(self, a, b):\n        a=a\n        b=b\n        if a[len(a)-1]=='\\n':\n            a=a[:len(a)-1]\n        if b[len(b)-1]=='\\n':\n            b=float(b[:len(b)-1])\n      \n        return (a,b)",
  "class SignalGenerator(VisaInstrument):\n    def __init__(self, address='GPIB0::3::INSTR'):\n        super(SignalGenerator, self).__init__(address)\n        self.instr.read_termination = '\\n'\n        self.instr.write_termination = '\\n'\n\n    frequency = queried_property('freq?', 'freq {0}')\n    function = queried_property('function:shape?', 'function:shape {0}',\n                                validate=['sinusoid', 'dc'], dtype='str')\n    voltage = queried_property('voltage?', 'voltage {0}')\n    offset = queried_property('voltage:offset?', 'voltage:offset {0}')\n    output_load = queried_property('output:load?', 'output:load {0}',\n                                   validate=['inf'], dtype='str')\n    volt_high = queried_property('volt:high?', 'volt:high {0}')\n    volt_low = queried_property('volt:low?', 'volt:low {0}')\n    output = queried_property('output?', 'output {0}',\n                              validate=['OFF', 'ON'], dtype='str')\n\n    def reset(self):\n        self.write('*rst')",
  "def __init__(self, address='GPIB0::3::INSTR'):\n        super(SignalGenerator, self).__init__(address)\n        self.instr.read_termination = '\\n'\n        self.instr.write_termination = '\\n'",
  "def reset(self):\n        self.write('*rst')",
  "class freq_source(vi.VisaInstrument):\n    \"\"\"Software control for the Wiltron 6769B swept frequency source\n    \"\"\"\n\n    def __init__(self, address='GPIB0::5::INSTR'):\n        \"\"\"Sets up visa communication and class dictionaries\n        \n        The class dictionaries are manully inputed translations between what \n        the source will send/recieve and the real values. \n        \n            \n        Args:\n            address(str):   Visa address\n        \n        \"\"\"\n        super(freq_source, self).__init__(address)\n        self.instr.read_termination = '\\n'\n        self.instr.write_termination = '\\n'\n        self.instr.timeout = None\n        print(self.query('OI'))\n        #print(self.instr.read_termination)\n        \n        \n        # self.filter_list = {}\n        print('source connected successfully')\n        return\n    #def output_on(self):\n        \n    # def RF_on(self):\n    #     return self.query('RF')\n        \n    # def get_power(self):\n    #     return self.query('OPM')\n    \n    # def set_power(self,target_power=-10d):\n    #     return(self.query(''))\n    def set_freq(self,mem_slot=1,target_freq=2.2): # frequency in GHz\n    # mem_slot is pre-set memory slot, from 1 to 9\n        self._write('F'+str(mem_slot)+str(target_freq)+'GH')\n        return\n    \n    def RF_on(self):\n        self._write('RF1')\n    \n    def RF_off(self):\n        self._write('RF0')\n    \n    def set_power(self,power=-10): # power in dBm\n        self._write('L1'+str(power)+'DM')\n        \n    def get_power(self):\n        return self.query('OL1')\n        \n    def close(self):\n        self.instr.close()\n    \n    #sweep between two frequencies\n    def freq_sweep(self,f1=2.1,f2=2.5,T=30):\n        #scan between f1 and f2 with time T\n        self.set_freq(mem_slot=2,target_freq=f2)\n        self.set_freq(mem_slot=1,target_freq=f1)\n        self._write('SWT30SEC') #set scan time to 30sec\n        self._write('SF1')# start scan\n    \n    def set_cw(self,mem_slot=1,freq=2.1):\n        self.set_freq(mem_slot=mem_slot,target_freq=freq)\n        self._write('CF1')",
  "def __init__(self, address='GPIB0::5::INSTR'):\n        \"\"\"Sets up visa communication and class dictionaries\n        \n        The class dictionaries are manully inputed translations between what \n        the source will send/recieve and the real values. \n        \n            \n        Args:\n            address(str):   Visa address\n        \n        \"\"\"\n        super(freq_source, self).__init__(address)\n        self.instr.read_termination = '\\n'\n        self.instr.write_termination = '\\n'\n        self.instr.timeout = None\n        print(self.query('OI'))\n        #print(self.instr.read_termination)\n        \n        \n        # self.filter_list = {}\n        print('source connected successfully')\n        return",
  "def set_freq(self,mem_slot=1,target_freq=2.2): # frequency in GHz\n    # mem_slot is pre-set memory slot, from 1 to 9\n        self._write('F'+str(mem_slot)+str(target_freq)+'GH')\n        return",
  "def RF_on(self):\n        self._write('RF1')",
  "def RF_off(self):\n        self._write('RF0')",
  "def set_power(self,power=-10): # power in dBm\n        self._write('L1'+str(power)+'DM')",
  "def get_power(self):\n        return self.query('OL1')",
  "def close(self):\n        self.instr.close()",
  "def freq_sweep(self,f1=2.1,f2=2.5,T=30):\n        #scan between f1 and f2 with time T\n        self.set_freq(mem_slot=2,target_freq=f2)\n        self.set_freq(mem_slot=1,target_freq=f1)\n        self._write('SWT30SEC') #set scan time to 30sec\n        self._write('SF1')",
  "def set_cw(self,mem_slot=1,freq=2.1):\n        self.set_freq(mem_slot=mem_slot,target_freq=freq)\n        self._write('CF1')",
  "def Sigmoid(x,Shift=0.68207277,Scale=8.49175969):\n    Zero=1./(np.exp(Shift*Scale)+1)\n    One=1./(np.exp(-(1-Shift)*Scale)+1)\n    \n    Output=(x-Shift)*Scale\n    Output=np.exp(-Output)+1\n    Output=1./Output\n    return (Output-Zero)/(One-Zero)",
  "def Inverse_Sigmoid(x,Shift=0.68207277,Scale=8.49175969):\n    Zero=1./(np.exp(Shift*Scale)+1)\n    One=1./(np.exp(-(1-Shift)*Scale)+1)\n    \n    Output=-np.log((1./(((One-Zero)*x)+Zero))-1)\n    Output/=Scale\n    Output+=Shift \n    return Output",
  "class AOM(VisaInstrument): \n    def __init__(self, address='USB0::0x0957::0x0407::MY44037993::0::INSTR', *args, **kwargs):\n        super().__init__(address, *args, **kwargs)\n        self.Power_Supply = self.instr\n        self.mode = 'R'\n       \n        self.Power_Supply.write(\"FUNC DC\")\n        self.Power_Supply.write(\"VOLT:OFFS 1\")\n        \n    def Switch_Mode(self):\n        if self.mode=='R':\n            self.mode = 'L'\n        else:\n            self.mode = 'R'\n    @property\n    def mode(self):\n        return self._mode\n    @mode.setter\n    def mode(self, value):\n        self._mode = value        \n        out = 'SYSTEM:'        \n        if value =='R': out+='REMOTE'\n        else: out+= 'LOCAL'\n        self.Power_Supply.write(out)\n\n        \n    def Power(self,Fraction=None):\n#        if Fraction is None:\n#            Voltage=float(self.Power_Supply.query(\"SOUR:VOLT:OFFS?\"))\n#            return Inverse_Sigmoid(Voltage)\n#        else:\n#            if Fraction<0:\n#                Fraction=0.\n#            if Fraction>1:\n#                Fraction=1.\n#            Voltage=Sigmoid(Fraction)\n#            self.Power_Supply.write(\"VOLT:OFFS \"+str(Voltage))\n#            \n        if Fraction is None:\n            return float(self.Power_Supply.query(\"SOUR:VOLT:OFFS?\"))\n        else:\n            if Fraction<0:\n                Fraction=0.\n            if Fraction>1:\n                Fraction=1.\n            self.Power_Supply.write(\"VOLT:OFFS \"+str(Fraction))  \n        \n    def Get_Power(self):\n        return float(self.Power_Supply.query(\"SOUR:VOLT:OFFS?\"))\n    \n    def Power_Apply(self, shape, frequency, amplitude, offset):\n        self.Power_Supply.write(\"APPL:%s %d Hz, %f VPP, %f V\" % (shape, frequency, amplitude, offset))\n        \n    def Find_Power(self,Power,Power_Meter,Laser_Shutter,Steps=10,Tolerance=1.):\n        Bounds=[0,1]\n        Laser_Shutter.close_shutter()\n        Laser_Shutter.set_mode(1)\n        \n        def Take_Reading():\n            Laser_Shutter.open_shutter()\n            Output=[]\n            Fail=0\n            while len(Output)<20:\n                try:\n                    Output.append(Power_Meter.read)\n                    Fail=0\n                except:\n                    Fail+=1\n                if Fail==10:\n                    raise Exception('Restart power meter')\n            Laser_Shutter.close_shutter()\n            return np.median(Output)*1000000\n            \n        x=[0.,1]\n        y=[]\n        for i in x:\n            self.Power(i)   \n            y.append( Take_Reading())         \n            time.sleep(1 )\n        \n         \n        if y[0]>Power or  y[1]<Power:\n            print( 'Out of Range!')\n            return\n        \n        for i in range(2):\n            Bound=np.mean(x)\n            self.Power(Bound)   \n            Reading=Take_Reading()\n            if Reading>Power:\n                x[1]=Bound\n                y[1]=Reading\n            else:\n                x[0]=Bound\n                y[0]=Reading\n            time.sleep(1)\n            \n        Step=0\n        Error=np.inf\n        while Step<Steps or Error>Tolerance:\n            Step+=1\n            print('Error:',str(round(Error,2)),'uW')\n            if x[1]!=x[0]:\n                m=old_div((y[1]-y[0]),(x[1]-x[0]))\n                c=y[0]-(m*x[0])\n                Guess=old_div((Power-c),m)\n                self.Power(Guess)\n                Reading=Take_Reading()\n                Error=np.abs(Reading-Power)\n                if Power<Reading:\n                    y[1]=Reading\n                    x[1]=Guess\n                else:\n                    y[0]=Reading\n                    x[0]=Guess\n                time.sleep(1)\n            else:\n                Step=np.inf \n                Error=0\n        if x[1]!=x[0]:\n            m=old_div((y[1]-y[0]),(x[1]-x[0]))\n            c=y[0]-(m*x[0])\n            Guess=old_div((Power-c),m)\n        else:\n            Guess=x[0]\n        self.Power(Guess)\n        Reading=Take_Reading()\n        return Guess,Reading",
  "def __init__(self, address='USB0::0x0957::0x0407::MY44037993::0::INSTR', *args, **kwargs):\n        super().__init__(address, *args, **kwargs)\n        self.Power_Supply = self.instr\n        self.mode = 'R'\n       \n        self.Power_Supply.write(\"FUNC DC\")\n        self.Power_Supply.write(\"VOLT:OFFS 1\")",
  "def Switch_Mode(self):\n        if self.mode=='R':\n            self.mode = 'L'\n        else:\n            self.mode = 'R'",
  "def mode(self):\n        return self._mode",
  "def mode(self, value):\n        self._mode = value        \n        out = 'SYSTEM:'        \n        if value =='R': out+='REMOTE'\n        else: out+= 'LOCAL'\n        self.Power_Supply.write(out)",
  "def Power(self,Fraction=None):\n#        if Fraction is None:\n#            Voltage=float(self.Power_Supply.query(\"SOUR:VOLT:OFFS?\"))\n#            return Inverse_Sigmoid(Voltage)\n#        else:\n#            if Fraction<0:\n#                Fraction=0.\n#            if Fraction>1:\n#                Fraction=1.\n#            Voltage=Sigmoid(Fraction)\n#            self.Power_Supply.write(\"VOLT:OFFS \"+str(Voltage))\n#            \n        if Fraction is None:\n            return float(self.Power_Supply.query(\"SOUR:VOLT:OFFS?\"))\n        else:\n            if Fraction<0:\n                Fraction=0.\n            if Fraction>1:\n                Fraction=1.\n            self.Power_Supply.write(\"VOLT:OFFS \"+str(Fraction))",
  "def Get_Power(self):\n        return float(self.Power_Supply.query(\"SOUR:VOLT:OFFS?\"))",
  "def Power_Apply(self, shape, frequency, amplitude, offset):\n        self.Power_Supply.write(\"APPL:%s %d Hz, %f VPP, %f V\" % (shape, frequency, amplitude, offset))",
  "def Find_Power(self,Power,Power_Meter,Laser_Shutter,Steps=10,Tolerance=1.):\n        Bounds=[0,1]\n        Laser_Shutter.close_shutter()\n        Laser_Shutter.set_mode(1)\n        \n        def Take_Reading():\n            Laser_Shutter.open_shutter()\n            Output=[]\n            Fail=0\n            while len(Output)<20:\n                try:\n                    Output.append(Power_Meter.read)\n                    Fail=0\n                except:\n                    Fail+=1\n                if Fail==10:\n                    raise Exception('Restart power meter')\n            Laser_Shutter.close_shutter()\n            return np.median(Output)*1000000\n            \n        x=[0.,1]\n        y=[]\n        for i in x:\n            self.Power(i)   \n            y.append( Take_Reading())         \n            time.sleep(1 )\n        \n         \n        if y[0]>Power or  y[1]<Power:\n            print( 'Out of Range!')\n            return\n        \n        for i in range(2):\n            Bound=np.mean(x)\n            self.Power(Bound)   \n            Reading=Take_Reading()\n            if Reading>Power:\n                x[1]=Bound\n                y[1]=Reading\n            else:\n                x[0]=Bound\n                y[0]=Reading\n            time.sleep(1)\n            \n        Step=0\n        Error=np.inf\n        while Step<Steps or Error>Tolerance:\n            Step+=1\n            print('Error:',str(round(Error,2)),'uW')\n            if x[1]!=x[0]:\n                m=old_div((y[1]-y[0]),(x[1]-x[0]))\n                c=y[0]-(m*x[0])\n                Guess=old_div((Power-c),m)\n                self.Power(Guess)\n                Reading=Take_Reading()\n                Error=np.abs(Reading-Power)\n                if Power<Reading:\n                    y[1]=Reading\n                    x[1]=Guess\n                else:\n                    y[0]=Reading\n                    x[0]=Guess\n                time.sleep(1)\n            else:\n                Step=np.inf \n                Error=0\n        if x[1]!=x[0]:\n            m=old_div((y[1]-y[0]),(x[1]-x[0]))\n            c=y[0]-(m*x[0])\n            Guess=old_div((Power-c),m)\n        else:\n            Guess=x[0]\n        self.Power(Guess)\n        Reading=Take_Reading()\n        return Guess,Reading",
  "def Take_Reading():\n            Laser_Shutter.open_shutter()\n            Output=[]\n            Fail=0\n            while len(Output)<20:\n                try:\n                    Output.append(Power_Meter.read)\n                    Fail=0\n                except:\n                    Fail+=1\n                if Fail==10:\n                    raise Exception('Restart power meter')\n            Laser_Shutter.close_shutter()\n            return np.median(Output)*1000000",
  "class TimeHarp(Instrument):\n    \n    timeharp_mode = 0  #0=standard histogramming, 1=TTTR\n    ctcstatus = 0\n    countrate = 0\n    BLOCKSIZE =  4096;\n\n    def __init__(self):\n        super(TimeHarp,self).__init__()\n        #for Windows\n        #self.TH_dll = cdll.LoadLibrary(r'C:\\Program Files (x86)\\PicoQuant\\TH200-THLibv61\\Thlib_for_x64\\Thlib.dll')\n       # self.TH_dll = cdll.LoadLibrary('C:\\Program Files\\PicoQuant\\TH200-THLibv61\\ThLib.lib')\n        self.TH_dll =windll.LoadLibrary(r'ThLib.dll')\n\n        self.Timeharp_Initialize(self.timeharp_mode)\n        \n    def verbose(self, error, function=''):\n        self.log( \"[%s]: %s\" %(function, error),level = 'info')\n        \n\n    def Timeharp_Initialize(self, timeharp_mode):\n        retint = self.TH_dll.TH_Initialize(timeharp_mode)\n        if retint < 0:\n            self.verbose(self.FindError(retint), sys._getframe().f_code.co_name) \n            self.TH_dll.TH_Shutdown()\n        \n    def TimeHarp_Calibrate(self):\n        retint = self.TH_dll.TH_Calibrate();\n        if retint < 0:\n            self.verbose(self.FindError(retint), sys._getframe().f_code.co_name) \n            self.TH_dll.TH_Shutdown()\n        \n    def TimeHarp_SetCFDDiscrMin(self, CFDLevel = 20):\n        retint = self.TH_dll.TH_SetCFDDiscrMin(CFDLevel)\n        if retint < 0:\n            self.verbose(self.FindError(retint), sys._getframe().f_code.co_name) \n            self.TH_dll.TH_Shutdown()\n        \n    def TimeHarp_SetCFDZeroX(self, CFDZeroX = 20):\n        retint = self.TH_dll.TH_SetCFDZeroCross(CFDZeroX)\n        if retint < 0:\n            self.verbose(self.FindError(retint), sys._getframe().f_code.co_name) \n            self.TH_dll.TH_Shutdown()\n\n    def TimeHarp_SetSyncLevel(self, SyncLevel = -700):\n        retint = self.TH_dll.TH_SetSyncLevel(SyncLevel)\n        if retint < 0:\n            self.verbose(self.FindError(retint), sys._getframe().f_code.co_name) \n            self.TH_dll.TH_Shutdown()\n        \n    def TimeHarp_SetRange(self, Range = 0):\n        # range code 0 = base resolution, 1 = 2 x base resolution and so on.      \n        retint = self.TH_dll.TH_SetRange(Range)\n        if retint < 0:\n            self.verbose(self.FindError(retint), sys._getframe().f_code.co_name) \n            self.TH_dll.TH_Shutdown()\n\n    def TimeHarp_SetOffset(self, Offset = 0):    \n        retint = self.TH_dll.TH_SetOffset(Offset)\n        if retint < 0:\n            self.verbose(self.FindError(retint), sys._getframe().f_code.co_name) \n            self.TH_dll.TH_Shutdown()\n        \n    def TimeHarp_SetStopOverflow(self):    \n        retint = self.TH_dll.TH_SetStopOverflow( 1, 65535)\n        if retint < 0:\n            self.verbose(self.FindError(retint), sys._getframe().f_code.co_name) \n            self.TH_dll.TH_Shutdown()\n        \n    def TimeHarp_GetResolution(self):    \n        retint = self.TH_dll.TH_GetResolution()\n        if retint < 0:\n            self.verbose(self.FindError(retint), sys._getframe().f_code.co_name) \n            self.TH_dll.TH_Shutdown()\n        return retint\n    \n    def TimeHarp_SetSyncMode(self):\n        retint = self.TH_dll.TH_SetSyncMode()\n        if retint < 0:\n            self.verbose(self.FindError(retint), sys._getframe().f_code.co_name) \n            self.TH_dll.TH_Shutdown()        \n        \n    \n    def TimeHarp_GetCountRate(self):\n        retint = self.TH_dll.TH_GetCountRate()\n        if retint < 0:\n            self.verbose(self.FindError(retint), sys._getframe().f_code.co_name) \n            self.TH_dll.TH_Shutdown()\n        return retint    \n       \n    \n    def TimeHarp_ClearHistMem(self, TH_block = 0):\n        retint =self.TH_dll.TH_ClearHistMem(TH_block)\n        if retint < 0:\n            self.verbose(self.FindError(retint), sys._getframe().f_code.co_name) \n            self.TH_dll.TH_Shutdown()\n    \n    def TimeHarp_GetFlags(self):\n        retint =self.TH_dll.TH_GetFlags()\n        if retint < 0:\n            self.verbose(self.FindError(retint), sys._getframe().f_code.co_name) \n            self.TH_dll.TH_Shutdown()\n            \n            \n    def TimeHarp_StartMeas(self):\n        retint =self.TH_dll.TH_StartMeas()\n        if retint < 0:\n            self.verbose(self.FindError(retint), sys._getframe().f_code.co_name) \n            self.TH_dll.TH_Shutdown()\n            \n    def TimeHarp_CTCStatus(self):\n        retint =self.TH_dll.TH_CTCStatus()\n        if retint < 0:\n            self.verbose(self.FindError(retint), sys._getframe().f_code.co_name) \n            self.TH_dll.TH_Shutdown()\n        return retint\n\n    def TimeHarp_SetMMode(self, mmode = 0, tacq = 1000): #acquire for 1s\n        retint =self.TH_dll.TH_SetMMode(mmode, tacq)\n        if retint < 0:\n            self.verbose(self.FindError(retint), sys._getframe().f_code.co_name) \n            self.TH_dll.TH_Shutdown()\n        return retint\n    \n    \n    def TimeHarp_StopMeas(self):\n        retint =self.TH_dll.TH_StopMeas()\n        if retint < 0:\n            self.verbose(self.FindError(retint), sys._getframe().f_code.co_name) \n            self.TH_dll.TH_Shutdown()\n            \n    def TimeHarp_ShutDown(self):\n        self.TH_dll.TH_Shutdown()\n            \n    def TimeHarp_GetBlock(self, block = 0):\n        retarr_p = c_uint32*self.BLOCKSIZE\n        retarr = retarr_p()\n        retint= self.TH_dll.TH_GetBlock(byref(retarr), block)\n        if retint < 0:\n            self.verbose(self.FindError(retint), sys._getframe().f_code.co_name) \n            self.TH_dll.TH_Shutdown()\n        return retarr, retint\n    \n       \n    def ReadErrorFile(self):\n        #mypath = r'C:\\Program Files (x86)\\PicoQuant\\TH200-THLibv61'\n        mypath = r'R:\\fo263\\manuals\\TimeHarp200_SW_and_DLL_v6_1';\n        \n        filename = 'Errcodes_mod_170920.txt'\n        myFile = open(mypath + '\\\\' + filename, 'r')\n        filecontent = myFile.read()\n        err_code = filecontent.split();\n        myFile.close()\n        \n        return err_code\n    \n    ERROR_CODE = property(ReadErrorFile)\n\n                       \n        \n    def FindError(self, thiserror):\n        error_index = self.ERROR_CODE.index(str(thiserror))\n        return self.ERROR_CODE[error_index - 1]",
  "def __init__(self):\n        super(TimeHarp,self).__init__()\n        #for Windows\n        #self.TH_dll = cdll.LoadLibrary(r'C:\\Program Files (x86)\\PicoQuant\\TH200-THLibv61\\Thlib_for_x64\\Thlib.dll')\n       # self.TH_dll = cdll.LoadLibrary('C:\\Program Files\\PicoQuant\\TH200-THLibv61\\ThLib.lib')\n        self.TH_dll =windll.LoadLibrary(r'ThLib.dll')\n\n        self.Timeharp_Initialize(self.timeharp_mode)",
  "def verbose(self, error, function=''):\n        self.log( \"[%s]: %s\" %(function, error),level = 'info')",
  "def Timeharp_Initialize(self, timeharp_mode):\n        retint = self.TH_dll.TH_Initialize(timeharp_mode)\n        if retint < 0:\n            self.verbose(self.FindError(retint), sys._getframe().f_code.co_name) \n            self.TH_dll.TH_Shutdown()",
  "def TimeHarp_Calibrate(self):\n        retint = self.TH_dll.TH_Calibrate();\n        if retint < 0:\n            self.verbose(self.FindError(retint), sys._getframe().f_code.co_name) \n            self.TH_dll.TH_Shutdown()",
  "def TimeHarp_SetCFDDiscrMin(self, CFDLevel = 20):\n        retint = self.TH_dll.TH_SetCFDDiscrMin(CFDLevel)\n        if retint < 0:\n            self.verbose(self.FindError(retint), sys._getframe().f_code.co_name) \n            self.TH_dll.TH_Shutdown()",
  "def TimeHarp_SetCFDZeroX(self, CFDZeroX = 20):\n        retint = self.TH_dll.TH_SetCFDZeroCross(CFDZeroX)\n        if retint < 0:\n            self.verbose(self.FindError(retint), sys._getframe().f_code.co_name) \n            self.TH_dll.TH_Shutdown()",
  "def TimeHarp_SetSyncLevel(self, SyncLevel = -700):\n        retint = self.TH_dll.TH_SetSyncLevel(SyncLevel)\n        if retint < 0:\n            self.verbose(self.FindError(retint), sys._getframe().f_code.co_name) \n            self.TH_dll.TH_Shutdown()",
  "def TimeHarp_SetRange(self, Range = 0):\n        # range code 0 = base resolution, 1 = 2 x base resolution and so on.      \n        retint = self.TH_dll.TH_SetRange(Range)\n        if retint < 0:\n            self.verbose(self.FindError(retint), sys._getframe().f_code.co_name) \n            self.TH_dll.TH_Shutdown()",
  "def TimeHarp_SetOffset(self, Offset = 0):    \n        retint = self.TH_dll.TH_SetOffset(Offset)\n        if retint < 0:\n            self.verbose(self.FindError(retint), sys._getframe().f_code.co_name) \n            self.TH_dll.TH_Shutdown()",
  "def TimeHarp_SetStopOverflow(self):    \n        retint = self.TH_dll.TH_SetStopOverflow( 1, 65535)\n        if retint < 0:\n            self.verbose(self.FindError(retint), sys._getframe().f_code.co_name) \n            self.TH_dll.TH_Shutdown()",
  "def TimeHarp_GetResolution(self):    \n        retint = self.TH_dll.TH_GetResolution()\n        if retint < 0:\n            self.verbose(self.FindError(retint), sys._getframe().f_code.co_name) \n            self.TH_dll.TH_Shutdown()\n        return retint",
  "def TimeHarp_SetSyncMode(self):\n        retint = self.TH_dll.TH_SetSyncMode()\n        if retint < 0:\n            self.verbose(self.FindError(retint), sys._getframe().f_code.co_name) \n            self.TH_dll.TH_Shutdown()",
  "def TimeHarp_GetCountRate(self):\n        retint = self.TH_dll.TH_GetCountRate()\n        if retint < 0:\n            self.verbose(self.FindError(retint), sys._getframe().f_code.co_name) \n            self.TH_dll.TH_Shutdown()\n        return retint",
  "def TimeHarp_ClearHistMem(self, TH_block = 0):\n        retint =self.TH_dll.TH_ClearHistMem(TH_block)\n        if retint < 0:\n            self.verbose(self.FindError(retint), sys._getframe().f_code.co_name) \n            self.TH_dll.TH_Shutdown()",
  "def TimeHarp_GetFlags(self):\n        retint =self.TH_dll.TH_GetFlags()\n        if retint < 0:\n            self.verbose(self.FindError(retint), sys._getframe().f_code.co_name) \n            self.TH_dll.TH_Shutdown()",
  "def TimeHarp_StartMeas(self):\n        retint =self.TH_dll.TH_StartMeas()\n        if retint < 0:\n            self.verbose(self.FindError(retint), sys._getframe().f_code.co_name) \n            self.TH_dll.TH_Shutdown()",
  "def TimeHarp_CTCStatus(self):\n        retint =self.TH_dll.TH_CTCStatus()\n        if retint < 0:\n            self.verbose(self.FindError(retint), sys._getframe().f_code.co_name) \n            self.TH_dll.TH_Shutdown()\n        return retint",
  "def TimeHarp_SetMMode(self, mmode = 0, tacq = 1000): #acquire for 1s\n        retint =self.TH_dll.TH_SetMMode(mmode, tacq)\n        if retint < 0:\n            self.verbose(self.FindError(retint), sys._getframe().f_code.co_name) \n            self.TH_dll.TH_Shutdown()\n        return retint",
  "def TimeHarp_StopMeas(self):\n        retint =self.TH_dll.TH_StopMeas()\n        if retint < 0:\n            self.verbose(self.FindError(retint), sys._getframe().f_code.co_name) \n            self.TH_dll.TH_Shutdown()",
  "def TimeHarp_ShutDown(self):\n        self.TH_dll.TH_Shutdown()",
  "def TimeHarp_GetBlock(self, block = 0):\n        retarr_p = c_uint32*self.BLOCKSIZE\n        retarr = retarr_p()\n        retint= self.TH_dll.TH_GetBlock(byref(retarr), block)\n        if retint < 0:\n            self.verbose(self.FindError(retint), sys._getframe().f_code.co_name) \n            self.TH_dll.TH_Shutdown()\n        return retarr, retint",
  "def ReadErrorFile(self):\n        #mypath = r'C:\\Program Files (x86)\\PicoQuant\\TH200-THLibv61'\n        mypath = r'R:\\fo263\\manuals\\TimeHarp200_SW_and_DLL_v6_1';\n        \n        filename = 'Errcodes_mod_170920.txt'\n        myFile = open(mypath + '\\\\' + filename, 'r')\n        filecontent = myFile.read()\n        err_code = filecontent.split();\n        myFile.close()\n        \n        return err_code",
  "def FindError(self, thiserror):\n        error_index = self.ERROR_CODE.index(str(thiserror))\n        return self.ERROR_CODE[error_index - 1]",
  "class Timetagger(Instrument):\n\n\tdef __init__(self,verbose=0):\n\n\t\tself.pipeline = CapturePipeline()\n\t\tself._out_file_cat = None\n\t\tself._out_file = None\n\t\tself.readout_running = False\n\n\t\t#default pipeline latency\n\t\tself.pipeline.set_send_window(84)\n\n\tdef get_qt_ui(self):\n\t\traise ValueError(\"Timetagger UI - Not implemented!\")\n\n\n\tdef capture(self,integration_time,output_file):\n\n\t\tself.pipeline.start_capture()\n\t\tself.start_writeout(filename=output_file)\n\t\ttime.sleep(integration_time)\n\t\tself.pipeline.stop_capture()\n\t\tself._out_file_cat.terminate()\n\t\tself._out_file.close()\n\t\tself._out_file_cat = None\n\t\tself._out_file = None\n\t\tself.readout_running = False\n\t\treturn\n\n\tdef start_writeout(self, filename):\n\t    if self._out_file_cat is not None:\n\t            self._out_file_cat.terminate()\n\t    filename = os.path.normpath(os.path.expanduser(filename))\n\t    print(\"Writing captured data to:\", filename)\n\t    dirname = os.path.dirname(filename)\n\t    if not os.path.exists(dirname) and len(dirname) > 0:\n\t            os.makedirs(dirname)\n\t    self._out_file = open(filename, 'w')\n\t    self._out_file_cat = subprocess.Popen(['timetag-cat'], stdout=self._out_file)\n\t    return",
  "def __init__(self,verbose=0):\n\n\t\tself.pipeline = CapturePipeline()\n\t\tself._out_file_cat = None\n\t\tself._out_file = None\n\t\tself.readout_running = False\n\n\t\t#default pipeline latency\n\t\tself.pipeline.set_send_window(84)",
  "def get_qt_ui(self):\n\t\traise ValueError(\"Timetagger UI - Not implemented!\")",
  "def capture(self,integration_time,output_file):\n\n\t\tself.pipeline.start_capture()\n\t\tself.start_writeout(filename=output_file)\n\t\ttime.sleep(integration_time)\n\t\tself.pipeline.stop_capture()\n\t\tself._out_file_cat.terminate()\n\t\tself._out_file.close()\n\t\tself._out_file_cat = None\n\t\tself._out_file = None\n\t\tself.readout_running = False\n\t\treturn",
  "def start_writeout(self, filename):\n\t    if self._out_file_cat is not None:\n\t            self._out_file_cat.terminate()\n\t    filename = os.path.normpath(os.path.expanduser(filename))\n\t    print(\"Writing captured data to:\", filename)\n\t    dirname = os.path.dirname(filename)\n\t    if not os.path.exists(dirname) and len(dirname) > 0:\n\t            os.makedirs(dirname)\n\t    self._out_file = open(filename, 'w')\n\t    self._out_file_cat = subprocess.Popen(['timetag-cat'], stdout=self._out_file)\n\t    return",
  "def bytes_to_binary(bytearr, debug=0):\n    '''\n    Helper method for converting a bytearray datatype to a binary representation\n    '''\n    if debug > 0: print(bytearr)\n    bytes_as_binary = [format(int(b, base=16), \"#06b\").replace(\n        \"0b\", \"\") for b in bytearr]\n    if debug > 0: print(bytes_as_binary)\n    binary = \"\".join(bytes_as_binary)\n    return binary",
  "def twos_complement_to_int(binary, debug=0):\n    '''\n    Compute 2s complement of binary number representation\n    '''\n    if debug > 0: print(binary)\n    N = len(binary)\n    a_N = int(binary[0])\n    return float(-a_N*2**(N-1) + int(binary[1:], base=2))",
  "def int_to_hex(integer, padded_length=8, debug=0):\n    '''\n    Convert integer number to hexidecimal. Return value is zero-padded at the beginning\n    until its length matches the value passed in \"padded_length\"\n    '''\n    outp = (format(integer, \"#0{}x\".format(\n        padded_length+2)).replace(\"0x\", \"\")).upper()\n    return outp",
  "def int_to_twos_complement(integer, padded_length=16, debug=0):\n    '''\n    Two's complement in integer representation. Padded length specifies the padding on the\n    binary representation used to compute the twos complement\n    '''\n    #number is above 0 - return binary representation:\n    if integer >= 0:\n        return integer\n\n    #number is below zero - return twos complement representation:\n    elif integer < 0:\n        if debug > 0: print(\"Below zero - returning twos complement\")\n        integer = -1*integer\n        binary = format(integer, \"0{}b\".format(\n            padded_length+2)).replace(\"0b\", \"\")\n        ones_complement = [str(1-int(b)) for b in str(binary)]\n        ones_complement = int(\"\".join(ones_complement))\n        twos_complement = int(\"0b\"+str(ones_complement), base=2) + 1\n        twos_complement = format(twos_complement, \"034b\").replace(\"0b\", \"\")\n        if debug > 0:\n            print(\"input:\", integer)\n            print(\"binary:\", binary)\n            print(\"ones comp:\", ones_complement)\n            print(\"twos comp (int):\", int(twos_complement, base=2))\n        return int(\"0b\"+twos_complement, base=2)",
  "class BusDistributor(SerialInstrument):\n    ''' a class to handle the port settings of a thorlabs ELLB distributor bus.\n    Each of these can have several devices attached. They are assigned device\n    indices by the thorlabs Ello software - otherwise they all default to 0 and\n    don't work separately.\n    '''\n\n    def __init__(self, port):\n        self.termination_character = '\\n'\n        self.port_settings = dict(baudrate=9600,\n                                  bytesize=8,\n                                  stopbits=1,\n                                  parity='N',\n                                  timeout=2,\n                                  writeTimeout=2,\n                                  xonxoff=False)\n        super().__init__(port)",
  "class ThorlabsELL6(Instrument):\n\n    #default id is 0, but if multiple devices of same type connected may have others\n    VALID_DEVICE_IDs = [str(v) for v in list(\n        range(11)) + [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\"]]\n\n    #How much a stage sleeps (in seconds) between successive calls to .get_position.\n    #Used to make blocking calls to move_absolute and move_relative.\n    BLOCK_SLEEPING_TIME = 0.02\n    #Theshold for position accuracy when stage is meant to be stationary\n    #If difference between successive calls to get_position returns value\n    #whose difference is less than jitter - consider stage to have stopped\n    POSITION_JITTER_THRESHOLD = 0.02\n\n    #human readable status codes\n    DEVICE_STATUS_CODES = {\n            0: \"OK, no error\",\n            1: \"Communication Timeout\",\n            2: \"Mechanical time out\",\n            3: \"Command error or not supported\",\n            4: \"Value out of range\",\n            5: \"Module isolated\",\n            6: \"Module out of isolation\",\n            7: \"Initialization error\",\n            8: \"Thermal error\",\n            9: \"Busy\",\n            10: \"Sensor Error\",\n            11: \"Motor Error\",\n            12: \"Out of Range\",\n            13: \"Over current error\",\n            14: \"OK, no error\",\n            \"OutOfBounds\": \"Reserved\"\n        }\n    positions = 2\n\n    def __init__(self, serial_device, device_index=0, debug=0):\n        '''can be passed either a BusDistributor instance, or  \"COM5\"  '''\n        super().__init__()\n        if type(serial_device) is str:\n            self.serial_device = BusDistributor(serial_device)\n        else:\n            self.serial_device = serial_device\n        self.debug = debug\n\n        if str(device_index) not in self.VALID_DEVICE_IDs:\n            raise ValueError(\n                \"Device ID: {} is not valid!\".format(device_index))\n        self.device_index = device_index\n        self.home()\n\n    def home(self):\n        self.query_device('ho')\n        self._position = 0\n\n    def set_position(self, pos):\n        assert 0 <= pos < self.positions\n        \n        while pos > self._position:\n            self.move_forward()\n        while pos < self._position:\n            self.move_backward()\n        \n    def get_position(self):\n        return self._position\n   \n    position = NotifiedProperty(get_position, set_position)\n\n    def query_device(self, query):\n        '''\n        Wrap a generic query with the ID of the device (integer in range: 0-F)\n        so that we dont need to be explicit about this id\n        '''\n        raw_query = \"{0}{1}\".format(self.device_index, query)\n        if self.debug > 0:\n            print(\"raw_query\", raw_query)\n        raw_response = self.serial_device.query(raw_query)\n        if self.debug > 0:\n            print(\"raw_response\", raw_response)\n        return raw_response\n\n    def get_qt_ui(self):\n        '''\n        Get UI for stage\n        '''\n\n        return ELL6UI(self)\n\n    def move_forward(self):\n        self.query_device('fw')\n        self._position += 1\n\n    def move_backward(self):\n        self.query_device('bw')\n        self._position -= 1",
  "class ThorlabsELL9(ThorlabsELL6):\n    positions = 4\n\n    def get_qt_ui(self):\n        '''\n        Get UI for stage\n        '''\n\n        return ELL9UI(self)",
  "class ELL6UI(QuickControlBox):\n    def __init__(self, instr):\n        super().__init__('ELL6')\n        self.add_spinbox('position', vmin=0, vmax=1)\n        self.auto_connect_by_name(controlled_object=instr)",
  "class ELL9UI(QuickControlBox):\n    def __init__(self, instr):\n        super().__init__('ELL9')\n        self.add_spinbox('position', vmin=0, vmax=3)\n        self.auto_connect_by_name(controlled_object=instr)",
  "def __init__(self, port):\n        self.termination_character = '\\n'\n        self.port_settings = dict(baudrate=9600,\n                                  bytesize=8,\n                                  stopbits=1,\n                                  parity='N',\n                                  timeout=2,\n                                  writeTimeout=2,\n                                  xonxoff=False)\n        super().__init__(port)",
  "def __init__(self, serial_device, device_index=0, debug=0):\n        '''can be passed either a BusDistributor instance, or  \"COM5\"  '''\n        super().__init__()\n        if type(serial_device) is str:\n            self.serial_device = BusDistributor(serial_device)\n        else:\n            self.serial_device = serial_device\n        self.debug = debug\n\n        if str(device_index) not in self.VALID_DEVICE_IDs:\n            raise ValueError(\n                \"Device ID: {} is not valid!\".format(device_index))\n        self.device_index = device_index\n        self.home()",
  "def home(self):\n        self.query_device('ho')\n        self._position = 0",
  "def set_position(self, pos):\n        assert 0 <= pos < self.positions\n        \n        while pos > self._position:\n            self.move_forward()\n        while pos < self._position:\n            self.move_backward()",
  "def get_position(self):\n        return self._position",
  "def query_device(self, query):\n        '''\n        Wrap a generic query with the ID of the device (integer in range: 0-F)\n        so that we dont need to be explicit about this id\n        '''\n        raw_query = \"{0}{1}\".format(self.device_index, query)\n        if self.debug > 0:\n            print(\"raw_query\", raw_query)\n        raw_response = self.serial_device.query(raw_query)\n        if self.debug > 0:\n            print(\"raw_response\", raw_response)\n        return raw_response",
  "def get_qt_ui(self):\n        '''\n        Get UI for stage\n        '''\n\n        return ELL6UI(self)",
  "def move_forward(self):\n        self.query_device('fw')\n        self._position += 1",
  "def move_backward(self):\n        self.query_device('bw')\n        self._position -= 1",
  "def get_qt_ui(self):\n        '''\n        Get UI for stage\n        '''\n\n        return ELL9UI(self)",
  "def __init__(self, instr):\n        super().__init__('ELL6')\n        self.add_spinbox('position', vmin=0, vmax=1)\n        self.auto_connect_by_name(controlled_object=instr)",
  "def __init__(self, instr):\n        super().__init__('ELL9')\n        self.add_spinbox('position', vmin=0, vmax=3)\n        self.auto_connect_by_name(controlled_object=instr)",
  "class Talk2Computer(Instrument):\n   \n    def receive(self):\n        host = \"\"\n        port = 65535\n        buf = 1024\n        addr = (host, port)\n        UDPSock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)\n        UDPSock.bind(addr)\n            \n        print(\"Waiting to receive messages...\")\n        while True:\n            #(data, addr) = UDPSock.recvfrom(buf)\n            data = UDPSock.recv(buf)\n            print(\"Received message: \" + data)\n            if data == \"exit\":\n                break\n            if data != \" \":\n                break\n        return data\n        UDPSock.close()\n        #os._exit(0)\n    \n#    def send(self, ipadd = \"172.24.36.227\", displaymsg = \" \"): # set to IP address of target computer\n#        port = 65535\n#        addr = (ipadd, port)\n#        data = \" \"\n#        UDPSock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)\n#        while True:\n#            if displaymsg == \" \":\n#                data = raw_input(\"Enter message to send or type 'exit': \")\n#                UDPSock.sendto(data, addr)\n#            else: \n#                UDPSock.sendto(str(displaymsg), addr)\n#                break\n#            if data == \"exit\":\n#                break\n#        UDPSock.close()\n  \n    def send_particle_number(pretext = \"Particle_\", offset = 0):\n        try:\n            current_particle = wizard.current_particle\n            particle_name = pretext + str(current_particle + offset)\n            send(\"172.24.36.227\",  {'cmd': 'start', 'filename': particle_name} )\n        except exception as e:\n            print(e)      \n        \n        \n    def send(ipadd = \"172.24.36.227\",  dict = {'cmd': 'start', 'filename': 'np1'}): # set to IP address of target computer\n        port = 65535\n        addr = (ipadd, port)\n        data = \" \"\n        UDPSock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)\n        UDPSock.sendto(str(dict), addr)\n        UDPSock.close()\n    \n    \n    def send2(self, ipadd = \"172.24.36.227\",  dict = {'cmd': 'start', 'filename': 'np1'}): # set to IP address of target computer\n        port = 65535\n        addr = (ipadd, port)\n        data = \" \"\n        UDPSock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)\n        while True:\n            UDPSock.sendto(str(dict), addr)\n            break\n            if data == \"exit\":\n                break\n        UDPSock.close()",
  "def receive(self):\n        host = \"\"\n        port = 65535\n        buf = 1024\n        addr = (host, port)\n        UDPSock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)\n        UDPSock.bind(addr)\n            \n        print(\"Waiting to receive messages...\")\n        while True:\n            #(data, addr) = UDPSock.recvfrom(buf)\n            data = UDPSock.recv(buf)\n            print(\"Received message: \" + data)\n            if data == \"exit\":\n                break\n            if data != \" \":\n                break\n        return data\n        UDPSock.close()",
  "def send_particle_number(pretext = \"Particle_\", offset = 0):\n        try:\n            current_particle = wizard.current_particle\n            particle_name = pretext + str(current_particle + offset)\n            send(\"172.24.36.227\",  {'cmd': 'start', 'filename': particle_name} )\n        except exception as e:\n            print(e)",
  "def send(ipadd = \"172.24.36.227\",  dict = {'cmd': 'start', 'filename': 'np1'}): # set to IP address of target computer\n        port = 65535\n        addr = (ipadd, port)\n        data = \" \"\n        UDPSock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)\n        UDPSock.sendto(str(dict), addr)\n        UDPSock.close()",
  "def send2(self, ipadd = \"172.24.36.227\",  dict = {'cmd': 'start', 'filename': 'np1'}): # set to IP address of target computer\n        port = 65535\n        addr = (ipadd, port)\n        data = \" \"\n        UDPSock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)\n        while True:\n            UDPSock.sendto(str(dict), addr)\n            break\n            if data == \"exit\":\n                break\n        UDPSock.close()",
  "class NIDAQ(Instrument):\n    \"\"\"An interface for NIDAQ devices.\"\"\"\n\n    def __init__(self, device_id):\n        \"\"\"\n\n        :param device_id: a string identifier, e.g. 'Dev1'\n        \"\"\"\n        super(NIDAQ, self).__init__()\n        self.device_id = device_id\n        self.current_task = None\n        self.channels = None\n        self.sample_rate = None\n        self.time_interval = None\n        self.num_points = None\n\n    def setup_multi_ai(self, channels, sample_rate, time_interval):\n        \"\"\"\n        Setup the DAQ device for multiple channel analog input. In this implementation the\n        task is not started, only setup with the task committed to improve start speed.\n\n        :rtype : object\n        :param channels: an iterable containing a sequence of channel identifiers, e.g. 0,1,2..\n        :param sample_rate: the sampling frequency\n        :param time_interval: the time interval over which data is sampled\n        \"\"\"\n        num_samples = int(sample_rate * time_interval)  # this is the number of points expected per channel\n        while num_samples % len(channels) != 0:  # the number of samples must be evenly divisable between all channels\n            num_samples += 1  # the number of samples is increased until all channels are equal\n        self.num_samples = num_samples\n        self.time_interval = time_interval\n        analog_input = Task()\n        s = ''\n        for ch in channels:\n            s += '{0}/ai{1},'.format(self.device_id, str(ch))\n        analog_input.CreateAIVoltageChan(s, \"\", DAQmx_Val_Cfg_Default, -10.0, 10.0, DAQmx_Val_Volts, None)\n        analog_input.CfgSampClkTiming(\"\", sample_rate, DAQmx_Val_Rising, DAQmx_Val_FiniteSamps, num_samples)\n        analog_input.TaskControl(DAQmx_Val_Task_Commit)\n        self.current_task = analog_input\n        self.channels = channels\n\n    def read_multi_ai(self):\n        \"\"\"\n        Read from a DAQ device previously setup using setup_multi_ai. The task is started and\n        then stopped once complete. The data is then parsed and returned.\n\n        :rtype : np.ndarray, np.ndarray\n        :return: time, data\n        \"\"\"\n        analog_input = self.current_task\n        read = int32()\n        total_samples = self.num_samples * len(self.channels)\n        data = np.zeros((total_samples,), dtype=np.float64)\n        time = np.linspace(0, self.time_interval, self.num_samples)\n        analog_input.StartTask()\n        analog_input.ReadAnalogF64(self.num_samples,#DAQmx_Val_Auto,\n                                   -1,#DAQmx_Val_WaitInfinitely,\n                                   DAQmx_Val_GroupByChannel,\n                                   data,\n                                   total_samples, byref(read), None)\n        analog_input.StopTask()\n        data = self._parse_data(self.channels, data)\n        return time, data\n\n    def setup_multi_ai_cont(self, channels, sample_rate, time_interval):\n        '''\n        '''\n        analog_input = Task()\n        analog_counter = Task()\n        num_samples = int(sample_rate * time_interval) # this is the number of points expected per channel\n        while num_samples%len(channels) != 0: num_samples += 1\n        self.num_samples = num_samples\n        self.time_interval = time_interval\n        # DAQmx Configure Code\n        s = ''\n        for ch in channels:\n            s += self.device+'/ai'+str(ch)+','\n        # create an analog input channel named aiChannel\n        analog_input.CreateAIVoltageChan(s, \"aiChannel\",\n                                         DAQmx_Val_Cfg_Default,\n                                         -10.0, 10.0, DAQmx_Val_Volts,\n                                         None)\n        # create the clock for my analog input task\n        analog_input.CfgSampClkTiming(\"/%s/Ctr0InternalOutput\"%self.device,\n                                      sample_rate, DAQmx_Val_Rising,\n                                      DAQmx_Val_ContSamps, num_samples)\n        # configure analog input buffer\n        #analog_input.SetBufferAttribute(DAQmx_Buf_Input_BufSize, num_samples+1000)\n        # create a counter output channel named coChannel */\n        analog_counter.CreateCOPulseChanFreq('/%s/ctr0'%self.device,\n                                                  \"coChannel\", DAQmx_Val_Hz,\n                                                  DAQmx_Val_Low, 0, sample_rate, 0.5)\n\n    \t  # create the clock for my counter output task*/\n        analog_counter.CfgImplicitTiming(DAQmx_Val_FiniteSamps, num_samples)\n        analog_counter.CfgDigEdgeStartTrig('/%s/PFI0'%self.device, DAQmx_Val_Rising)\n        analog_counter.SetTrigAttribute(DAQmx_StartTrig_Retriggerable, True);\n        # DAQmx Start Code\n        analog_input.StartTask()\n        analog_counter.StartTask()\n        #analog_input.TaskControl(DAQmx_Val_Task_Commit)\n        self.current_task = analog_input\n        self.current_counter = analog_counter\n        self.channels = channels\n\n    def read_multi_ai_cont(self):\n        analog_input = self.current_task\n        read = int32()\n        total_samples = self.num_samples * len(self.channels)\n        data = np.zeros((total_samples,), dtype=np.float64)\n        time = np.linspace(0, self.time_interval, self.num_samples)\n        analog_input.ReadAnalogF64(self.num_samples,#DAQmx_Val_Auto,\n                                   -1,#DAQmx_Val_WaitInfinitely,\n                                   DAQmx_Val_GroupByChannel,\n                                   data,\n                                   total_samples, byref(read), None)\n        #print \"Acquired %d points\"%read.value\n        data = self._parse_data(self.channels, data)\n        return time, data\n\n    def _parse_data(self, channels, data):\n        \"\"\"\n        The readout data is organised into an array n*m long, where n is the number of channels\n        and m is the number of samples per channel. This method splits the readout data into n\n        segments corresponding to each channel data.\n\n        :param channels:\n        :param data:\n        :return: data\n        \"\"\"\n        data = np.split(data, len(channels))\n        return data\n\n    def clear_multi_ai(self):\n        \"\"\"\n        Clear the previously committed task as set in setup_multi_ai.\n\n        :return:\n        \"\"\"\n        self.current_task.TaskControl(DAQmx_Val_Task_Unreserve)\n\n    def stop_current_task(self):\n        \"\"\"\n        Force the current task to stop.\n\n        :return:\n        \"\"\"\n        self.current_task.StopTask()",
  "class Itask(Task):\n    \"\"\"Essentially a wrapper for the NIDAQ Task object that allows multiple\n    Tasks to be run without initialisation each time the Task needs to be run:\n    \"\"\"\n    def __init__(self):\n        Task.__init__(self)\n        self.mode = None\n\n    \n    def setupmulti_ao(self,device_id,channels,minoutput,maxoutput):\n        \"\"\" The command required to setup a task/channel in the analog output \n            configuration\n        Args:\n            device_id (string): the name of the device setup in NI Max\n                                This should alawys be pulled straight from the \n                                NIDAQ object via self.device_id\n            channels(list): The channel number you wish to control in list format\n            minoutput (float): The minimum voltage the device will apply\n            maxoutput(float): the maximum voltage a device can apply\"\"\"\n        self.device_id = device_id\n        self.minoutput = minoutput\n        self.maxoutput = maxoutput\n        self.channels = channels\n        s = ''\n        for ch in channels:\n            s += '{0}/ao{1},'.format(self.device_id, str(ch))\n            \n        self.CreateAOVoltageChan(s,'',self.minoutput,self.maxoutput,DAQmx_Val_Volts, None)\n        self.mode = \"AO\"\n    \n    def set_ao(self,value):\n        \"\"\" the command for setting analog output voltages, input values are in \n            Volts. self.setupmulti_ao must be called before this method can be used\n        \n        Args:\n            value(float): the new output voltage in Volts\n            \n        Raises:\n            BaseException: The task is not currently in analog output mode i.e. run self.setupmulti_ao()\"\"\"\n            \n        if self.mode != \"AO\":\n            raise BaseException('This Task is not setup for analog output, the current Task is setup for',self.mode)\n        value = np.array(float(value))\n        self.WriteAnalogF64( len(self.channels), True, 10.0, DAQmx_Val_GroupByChannel, value,  byref(int32()), None)",
  "def __init__(self, device_id):\n        \"\"\"\n\n        :param device_id: a string identifier, e.g. 'Dev1'\n        \"\"\"\n        super(NIDAQ, self).__init__()\n        self.device_id = device_id\n        self.current_task = None\n        self.channels = None\n        self.sample_rate = None\n        self.time_interval = None\n        self.num_points = None",
  "def setup_multi_ai(self, channels, sample_rate, time_interval):\n        \"\"\"\n        Setup the DAQ device for multiple channel analog input. In this implementation the\n        task is not started, only setup with the task committed to improve start speed.\n\n        :rtype : object\n        :param channels: an iterable containing a sequence of channel identifiers, e.g. 0,1,2..\n        :param sample_rate: the sampling frequency\n        :param time_interval: the time interval over which data is sampled\n        \"\"\"\n        num_samples = int(sample_rate * time_interval)  # this is the number of points expected per channel\n        while num_samples % len(channels) != 0:  # the number of samples must be evenly divisable between all channels\n            num_samples += 1  # the number of samples is increased until all channels are equal\n        self.num_samples = num_samples\n        self.time_interval = time_interval\n        analog_input = Task()\n        s = ''\n        for ch in channels:\n            s += '{0}/ai{1},'.format(self.device_id, str(ch))\n        analog_input.CreateAIVoltageChan(s, \"\", DAQmx_Val_Cfg_Default, -10.0, 10.0, DAQmx_Val_Volts, None)\n        analog_input.CfgSampClkTiming(\"\", sample_rate, DAQmx_Val_Rising, DAQmx_Val_FiniteSamps, num_samples)\n        analog_input.TaskControl(DAQmx_Val_Task_Commit)\n        self.current_task = analog_input\n        self.channels = channels",
  "def read_multi_ai(self):\n        \"\"\"\n        Read from a DAQ device previously setup using setup_multi_ai. The task is started and\n        then stopped once complete. The data is then parsed and returned.\n\n        :rtype : np.ndarray, np.ndarray\n        :return: time, data\n        \"\"\"\n        analog_input = self.current_task\n        read = int32()\n        total_samples = self.num_samples * len(self.channels)\n        data = np.zeros((total_samples,), dtype=np.float64)\n        time = np.linspace(0, self.time_interval, self.num_samples)\n        analog_input.StartTask()\n        analog_input.ReadAnalogF64(self.num_samples,#DAQmx_Val_Auto,\n                                   -1,#DAQmx_Val_WaitInfinitely,\n                                   DAQmx_Val_GroupByChannel,\n                                   data,\n                                   total_samples, byref(read), None)\n        analog_input.StopTask()\n        data = self._parse_data(self.channels, data)\n        return time, data",
  "def setup_multi_ai_cont(self, channels, sample_rate, time_interval):\n        '''\n        '''\n        analog_input = Task()\n        analog_counter = Task()\n        num_samples = int(sample_rate * time_interval) # this is the number of points expected per channel\n        while num_samples%len(channels) != 0: num_samples += 1\n        self.num_samples = num_samples\n        self.time_interval = time_interval\n        # DAQmx Configure Code\n        s = ''\n        for ch in channels:\n            s += self.device+'/ai'+str(ch)+','\n        # create an analog input channel named aiChannel\n        analog_input.CreateAIVoltageChan(s, \"aiChannel\",\n                                         DAQmx_Val_Cfg_Default,\n                                         -10.0, 10.0, DAQmx_Val_Volts,\n                                         None)\n        # create the clock for my analog input task\n        analog_input.CfgSampClkTiming(\"/%s/Ctr0InternalOutput\"%self.device,\n                                      sample_rate, DAQmx_Val_Rising,\n                                      DAQmx_Val_ContSamps, num_samples)\n        # configure analog input buffer\n        #analog_input.SetBufferAttribute(DAQmx_Buf_Input_BufSize, num_samples+1000)\n        # create a counter output channel named coChannel */\n        analog_counter.CreateCOPulseChanFreq('/%s/ctr0'%self.device,\n                                                  \"coChannel\", DAQmx_Val_Hz,\n                                                  DAQmx_Val_Low, 0, sample_rate, 0.5)\n\n    \t  # create the clock for my counter output task*/\n        analog_counter.CfgImplicitTiming(DAQmx_Val_FiniteSamps, num_samples)\n        analog_counter.CfgDigEdgeStartTrig('/%s/PFI0'%self.device, DAQmx_Val_Rising)\n        analog_counter.SetTrigAttribute(DAQmx_StartTrig_Retriggerable, True);\n        # DAQmx Start Code\n        analog_input.StartTask()\n        analog_counter.StartTask()\n        #analog_input.TaskControl(DAQmx_Val_Task_Commit)\n        self.current_task = analog_input\n        self.current_counter = analog_counter\n        self.channels = channels",
  "def read_multi_ai_cont(self):\n        analog_input = self.current_task\n        read = int32()\n        total_samples = self.num_samples * len(self.channels)\n        data = np.zeros((total_samples,), dtype=np.float64)\n        time = np.linspace(0, self.time_interval, self.num_samples)\n        analog_input.ReadAnalogF64(self.num_samples,#DAQmx_Val_Auto,\n                                   -1,#DAQmx_Val_WaitInfinitely,\n                                   DAQmx_Val_GroupByChannel,\n                                   data,\n                                   total_samples, byref(read), None)\n        #print \"Acquired %d points\"%read.value\n        data = self._parse_data(self.channels, data)\n        return time, data",
  "def _parse_data(self, channels, data):\n        \"\"\"\n        The readout data is organised into an array n*m long, where n is the number of channels\n        and m is the number of samples per channel. This method splits the readout data into n\n        segments corresponding to each channel data.\n\n        :param channels:\n        :param data:\n        :return: data\n        \"\"\"\n        data = np.split(data, len(channels))\n        return data",
  "def clear_multi_ai(self):\n        \"\"\"\n        Clear the previously committed task as set in setup_multi_ai.\n\n        :return:\n        \"\"\"\n        self.current_task.TaskControl(DAQmx_Val_Task_Unreserve)",
  "def stop_current_task(self):\n        \"\"\"\n        Force the current task to stop.\n\n        :return:\n        \"\"\"\n        self.current_task.StopTask()",
  "def __init__(self):\n        Task.__init__(self)\n        self.mode = None",
  "def setupmulti_ao(self,device_id,channels,minoutput,maxoutput):\n        \"\"\" The command required to setup a task/channel in the analog output \n            configuration\n        Args:\n            device_id (string): the name of the device setup in NI Max\n                                This should alawys be pulled straight from the \n                                NIDAQ object via self.device_id\n            channels(list): The channel number you wish to control in list format\n            minoutput (float): The minimum voltage the device will apply\n            maxoutput(float): the maximum voltage a device can apply\"\"\"\n        self.device_id = device_id\n        self.minoutput = minoutput\n        self.maxoutput = maxoutput\n        self.channels = channels\n        s = ''\n        for ch in channels:\n            s += '{0}/ao{1},'.format(self.device_id, str(ch))\n            \n        self.CreateAOVoltageChan(s,'',self.minoutput,self.maxoutput,DAQmx_Val_Volts, None)\n        self.mode = \"AO\"",
  "def set_ao(self,value):\n        \"\"\" the command for setting analog output voltages, input values are in \n            Volts. self.setupmulti_ao must be called before this method can be used\n        \n        Args:\n            value(float): the new output voltage in Volts\n            \n        Raises:\n            BaseException: The task is not currently in analog output mode i.e. run self.setupmulti_ao()\"\"\"\n            \n        if self.mode != \"AO\":\n            raise BaseException('This Task is not setup for analog output, the current Task is setup for',self.mode)\n        value = np.array(float(value))\n        self.WriteAnalogF64( len(self.channels), True, 10.0, DAQmx_Val_GroupByChannel, value,  byref(int32()), None)",
  "def multi_read(d):\n        print(5./6000)\n        d.setup_multi_ai([0,1,2,3,4], 1e6, 0.001)\n        j = 0\n        while j<2:\n            time, data = d.read_multi_ai()\n            ref = data[0]\n            x = old_div(data[1],data[2])\n            y = old_div(data[3],data[4])\n            new_data = [ref, x, y]\n            for i in range(len(new_data)):\n                plot(time, new_data[i])\n            j += 1\n        d.clear_multi_ai()",
  "def cont_multi_read(d):\n        print('should take %s ms' % (1000*5./6000.))\n        d.setup_multi_ai_cont([0,1,2,3,4], 1e6, 5./6000.)\n        i=0\n        while i<10:\n            sleep(1)\n            time, data = d.read_multi_ai_cont()\n            i+=1\n        #print timeit.timeit(d.read_multi_ai_cont, number=1000)\n        d.clear_multi_ai()",
  "class Frequency_counter_F390(SerialInstrument):\n    port_settings = dict(baudrate=115200,\n                         bytesize=serial.EIGHTBITS,\n                         parity=serial.PARITY_NONE,\n                         xonxoff=True,\n                         timeout= 1.0)\n    termination_character = \"\\n\"\n    update_data_signal = QtCore.Signal(np.ndarray)\n    def __init__(self,port = None,integration_time = 1):\n        SerialInstrument.__init__(self, port=port)\n        self.live_window = 100\n        self._live_view = False\n        self.int_time = integration_time\n        self.write('FO') #do not apply low pass filter\n        self.write('Z5') #for 50 Ohms impedance\n        \n    function_dict = {'0' :  'B Input Period',\n                    '1':    'A Input Period',\n                    '2':    'A Input Frequency',\n                    '3':    'B Input Frequency',\n                    '4':    'Frequency Ratio B:A',\n                    '5':    'A Input Width High',\n                    '6':    'A Input Width Low',\n                    '7':    'A Input Count',\n                    '8':    'A Input Ratio H:L',\n                    '9':    'A Input Duty Cycle',\n                    'C':    'C Input Frequency',\n                    'D':    'C Input Period'}\n    def get_function(self):\n        '''A property to set the required function of the frequency counter\n        Args:\n            f: the a string value of the function shown in the table below and in self.function_dict\n            \n            0 B Input Period\n            1 A Input Period\n            2 A Input Frequency\n            3 B Input Frequency\n            4 Frequency Ratio B:A\n            5 A Input Width High\n            6 A Input Width Low\n            7 A Input Count\n            8 A Input Ratio H:L\n            9 A Input Duty Cycle\n            C C Input Frequency\n            D C Input Period\n        returns:\n            the current function\n            '''\n        return self.function_dict(self._function)\n    def set_function(self,f):\n        self._function = str(f)\n        self.write('F'+str(f))\n\n    function = property(fget=get_function,fset=set_function)\n    \n    def get_identity(self):\n        '''Returns the device id (good for testing comms) '''\n        return self.query('*IDN?')\n    \n    def test_communications(self):\n        '''A command to allow autodetection to work '''\n        if self.get_identity().split(',')[0] == 'Thurlby-Thandar':\n            return True\n    def measure_next(self):\n        '''Return the next valid measurement'''\n        try:\n            return float(self.query('N?')[:-2])\n        except:\n            print(self.query('N?')[:-2])\n    def measure_next_fast(self):\n        '''Return the invalid measurement (i.e. refereshs at LCD refresh rate, not the measreument rate)'''\n        try:\n            return float(self.query('?')[:-2])\n        except:\n            print(self.query('?')[:-2])\n#    def start_countinous_fast(self):\n#        '''Starts fast streaming of values at the LCD refresh rate '''\n#        self.write('C?')\n#    def start_countinous_single(self):\n#        '''Starts continuous streaming of values at the rate of the measurement time'''\n#        self.write('E?')\n#    def stop_countinous(self):\n#        self.write('STOP')\n    def get_live_view_window(self):\n        return self._live_window\n    def set_live_view_window(self,window_length):\n        self._live_window = window_length\n        '''Set the number of the stored values in the deque '''\n        self.live_deque = deque(maxlen=window_length)\n        \n    live_window = NotifiedProperty(get_live_view_window,set_live_view_window)\n    \n    int_times = {0.3:'1',\n                 1:'2',\n                 10:'3',\n                 100:'4'}\n    impedances = {'50': 'Z5', \n                  '1M': 'Z1'}\n    def get_int_time(self):\n        '''A property for the integration time possible values are:\n                0.3 s, 1s, 10s,100s '''\n        return self._int_time\n    def set_int_time(self,integration_time):\n        self._int_time = integration_time\n        try:\n            self.write('M'+self.int_times[integration_time])\n        except KeyError:\n            self.log('Invalid integration time', level ='WARN')\n    int_time = NotifiedProperty(get_int_time,set_int_time)\n    \n    def get_qt_ui(self):\n        self.ui = CounterUI(self)\n        self.display_ui = self.ui.preview_widget\n        self.control_ui = self.ui.control_widget\n        return self.ui\n    def get_preview_widget(self):\n        self.display_ui = CounterPreviewWidget(self)\n        return self.display_ui\n    def get_control_widget(self):\n        self.control_ui = CounterControlUI(self)\n        return self.control_ui\n    def _live_view_function(self):\n        '''The function that is run within the live preview thread '''\n        while self._live_view:\n            data = None\n            data = self.measure_next_fast()\n       #     while data == None:\n            time.sleep(self.int_time)\n            self.live_deque.append([data,time.time()])\n            self.display_ui.update_data_signal.emit(np.array(self.live_deque))\n       \n    def get_live_view(self):\n        '''Setting up the notificed property\n        live view to allow live view to be switch on and off ''' \n        return self._live_view\n    def set_live_view(self,enabled):\n        if enabled==True:\n            try:\n                self._live_view = True\n                self._live_view_stop_event = threading.Event()\n                self._live_view_thread = threading.Thread(target=self._live_view_function)\n                self._live_view_thread.start()\n            except AttributeError as e: #if any of the attributes aren't there\n                print(\"Error:\", e)\n        else:\n            if not self._live_view:\n                return # do nothing if it's not running.\n            print(\"stopping live view thread\")\n            try:\n                self._live_view = False\n                self._live_view_stop_event.set()\n                self._live_view_thread.join()\n                del(self._live_view_stop_event, self._live_view_thread)\n            except AttributeError:\n                raise Exception(\"Tried to stop live view but it doesn't appear to be running!\")\n    live_view = NotifiedProperty(get_live_view,set_live_view)",
  "class CounterPreviewWidget(QtWidgets.QWidget):\n    \"\"\"A Qt Widget to display the live feed from a camera.\"\"\"\n    update_data_signal = QtCore.Signal(np.ndarray)\n    \n    def __init__(self,counter):\n        super(CounterPreviewWidget, self).__init__()\n        \n     #   self.plot_item = pg.pl\n\n        self.plot_widget = pg.PlotWidget(labels = {'bottom':'Time'})\n        self.plot = self.plot_widget.getPlotItem()\n        self.setLayout(QtWidgets.QGridLayout())\n        self.layout().addWidget(self.plot_widget)\n        self.counter = counter\n        # We want to make sure we always update the data in the GUI thread.\n        # This is done using the signal/slot mechanism\n        self.update_data_signal.connect(self.update_widget, type=QtCore.Qt.QueuedConnection)\n\n    def update_widget(self, new_data):\n        \"\"\"Set the data to the latest\"\"\"\n    #    print 'update',new_data\n        self.plot.clear()\n        self.plot.plot(new_data[:,1]-new_data[0,1],new_data[:,0])",
  "class CounterControlUI(QuickControlBox):\n    '''A quick control box to allow the user to change simple settings '''\n    def __init__(self,counter):\n        super(CounterControlUI, self).__init__(title = 'Counter_Control')\n        self.counter = counter\n        self.add_checkbox('live_view')\n        self.add_spinbox('live_window')\n        self.add_doublespinbox('int_time')\n        self.auto_connect_by_name(controlled_object = self.counter)",
  "class CounterUI(QtWidgets.QWidget):\n    \"\"\"Generic user interface for a camera.\"\"\"\n    def __init__(self, counter):\n        #TODO: better checking (e.g. assert camera has color_image, gray_image methods)\n        super(CounterUI, self).__init__()\n        self.counter=counter\n        \n        # Set up the UI        \n        self.setWindowTitle(self.counter.__class__.__name__)\n        layout = QtWidgets.QVBoxLayout()\n        # The image display goes at the top of the window\n        self.preview_widget = self.counter.get_preview_widget()\n        layout.addWidget(self.preview_widget)\n        # The controls go in a layout, inside a group box.\n        self.control_widget = self.counter.get_control_widget()\n        layout.addWidget(self.control_widget)\n        #layout.setContentsMargins(5,5,5,5)\n        layout.setSpacing(5)\n        self.setLayout(layout)",
  "def __init__(self,port = None,integration_time = 1):\n        SerialInstrument.__init__(self, port=port)\n        self.live_window = 100\n        self._live_view = False\n        self.int_time = integration_time\n        self.write('FO') #do not apply low pass filter\n        self.write('Z5')",
  "def get_function(self):\n        '''A property to set the required function of the frequency counter\n        Args:\n            f: the a string value of the function shown in the table below and in self.function_dict\n            \n            0 B Input Period\n            1 A Input Period\n            2 A Input Frequency\n            3 B Input Frequency\n            4 Frequency Ratio B:A\n            5 A Input Width High\n            6 A Input Width Low\n            7 A Input Count\n            8 A Input Ratio H:L\n            9 A Input Duty Cycle\n            C C Input Frequency\n            D C Input Period\n        returns:\n            the current function\n            '''\n        return self.function_dict(self._function)",
  "def set_function(self,f):\n        self._function = str(f)\n        self.write('F'+str(f))",
  "def get_identity(self):\n        '''Returns the device id (good for testing comms) '''\n        return self.query('*IDN?')",
  "def test_communications(self):\n        '''A command to allow autodetection to work '''\n        if self.get_identity().split(',')[0] == 'Thurlby-Thandar':\n            return True",
  "def measure_next(self):\n        '''Return the next valid measurement'''\n        try:\n            return float(self.query('N?')[:-2])\n        except:\n            print(self.query('N?')[:-2])",
  "def measure_next_fast(self):\n        '''Return the invalid measurement (i.e. refereshs at LCD refresh rate, not the measreument rate)'''\n        try:\n            return float(self.query('?')[:-2])\n        except:\n            print(self.query('?')[:-2])",
  "def get_live_view_window(self):\n        return self._live_window",
  "def set_live_view_window(self,window_length):\n        self._live_window = window_length\n        '''Set the number of the stored values in the deque '''\n        self.live_deque = deque(maxlen=window_length)",
  "def get_int_time(self):\n        '''A property for the integration time possible values are:\n                0.3 s, 1s, 10s,100s '''\n        return self._int_time",
  "def set_int_time(self,integration_time):\n        self._int_time = integration_time\n        try:\n            self.write('M'+self.int_times[integration_time])\n        except KeyError:\n            self.log('Invalid integration time', level ='WARN')",
  "def get_qt_ui(self):\n        self.ui = CounterUI(self)\n        self.display_ui = self.ui.preview_widget\n        self.control_ui = self.ui.control_widget\n        return self.ui",
  "def get_preview_widget(self):\n        self.display_ui = CounterPreviewWidget(self)\n        return self.display_ui",
  "def get_control_widget(self):\n        self.control_ui = CounterControlUI(self)\n        return self.control_ui",
  "def _live_view_function(self):\n        '''The function that is run within the live preview thread '''\n        while self._live_view:\n            data = None\n            data = self.measure_next_fast()\n       #     while data == None:\n            time.sleep(self.int_time)\n            self.live_deque.append([data,time.time()])\n            self.display_ui.update_data_signal.emit(np.array(self.live_deque))",
  "def get_live_view(self):\n        '''Setting up the notificed property\n        live view to allow live view to be switch on and off ''' \n        return self._live_view",
  "def set_live_view(self,enabled):\n        if enabled==True:\n            try:\n                self._live_view = True\n                self._live_view_stop_event = threading.Event()\n                self._live_view_thread = threading.Thread(target=self._live_view_function)\n                self._live_view_thread.start()\n            except AttributeError as e: #if any of the attributes aren't there\n                print(\"Error:\", e)\n        else:\n            if not self._live_view:\n                return # do nothing if it's not running.\n            print(\"stopping live view thread\")\n            try:\n                self._live_view = False\n                self._live_view_stop_event.set()\n                self._live_view_thread.join()\n                del(self._live_view_stop_event, self._live_view_thread)\n            except AttributeError:\n                raise Exception(\"Tried to stop live view but it doesn't appear to be running!\")",
  "def __init__(self,counter):\n        super(CounterPreviewWidget, self).__init__()\n        \n     #   self.plot_item = pg.pl\n\n        self.plot_widget = pg.PlotWidget(labels = {'bottom':'Time'})\n        self.plot = self.plot_widget.getPlotItem()\n        self.setLayout(QtWidgets.QGridLayout())\n        self.layout().addWidget(self.plot_widget)\n        self.counter = counter\n        # We want to make sure we always update the data in the GUI thread.\n        # This is done using the signal/slot mechanism\n        self.update_data_signal.connect(self.update_widget, type=QtCore.Qt.QueuedConnection)",
  "def update_widget(self, new_data):\n        \"\"\"Set the data to the latest\"\"\"\n    #    print 'update',new_data\n        self.plot.clear()\n        self.plot.plot(new_data[:,1]-new_data[0,1],new_data[:,0])",
  "def __init__(self,counter):\n        super(CounterControlUI, self).__init__(title = 'Counter_Control')\n        self.counter = counter\n        self.add_checkbox('live_view')\n        self.add_spinbox('live_window')\n        self.add_doublespinbox('int_time')\n        self.auto_connect_by_name(controlled_object = self.counter)",
  "def __init__(self, counter):\n        #TODO: better checking (e.g. assert camera has color_image, gray_image methods)\n        super(CounterUI, self).__init__()\n        self.counter=counter\n        \n        # Set up the UI        \n        self.setWindowTitle(self.counter.__class__.__name__)\n        layout = QtWidgets.QVBoxLayout()\n        # The image display goes at the top of the window\n        self.preview_widget = self.counter.get_preview_widget()\n        layout.addWidget(self.preview_widget)\n        # The controls go in a layout, inside a group box.\n        self.control_widget = self.counter.get_control_widget()\n        layout.addWidget(self.control_widget)\n        #layout.setContentsMargins(5,5,5,5)\n        layout.setSpacing(5)\n        self.setLayout(layout)",
  "class TGF4242(SerialInstrument):\n    \n    def __init__(self, port=None):\n        \"\"\"Serial Interface to TGF4242 function generator.\"\"\"\n        SerialInstrument.__init__(self, port=port) #this opens the port\n    \n    def channel(self, channel):\n        \"\"\"Select Channel: 1 or 2\"\"\"\n        self.write('CHN ' + str(channel)) \n        #be carefull needs space between CHN and channel. Same everywhere\n    \n    def output(self, output):\n        \"\"\"Turn ON or OFF the output of selected channel:\n            \n            type 'ON' or 1 to turn on\n            \n            type 'OFF' or 0 to turn off\n        \"\"\"\n        if output==1:\n            self.write('OUTPUT ON')\n        elif output==0:\n            self.write('OUTPUT OFF')\n        else:\n            self.write('OUTPUT ' + output)\n     \n    \n    def freq(self, freq):\n        \"\"\"Set signal frequency in Hz\"\"\"\n        self.write('FREQ ' + str(freq))\n        \n    def ampl(self, ampl):\n        \"\"\"Set signal amplitude (Vpp) in VOLTS\"\"\"\n        self.write('ampl ' + str(ampl))\n        \n    def offset(self, offset):\n        \"\"\"Set the signal DC offset in VOLTS\"\"\"\n        self.write('DCOFFS ' +  str(offset))\n        \n    def phase(self, phase):\n        \"\"\"Set the waveform phase offset in DEGREES\"\"\"\n        self.write('PHASE ' + str(phase))\n        \n    def align(self, align):\n        \"\"\"Align phase for both channels\"\"\"\n        self.write('ALIGN')\n        \n    def waveform(self, wave):\n        \"\"\"Set the waveform: SINE, SQUARE, TRIANG, PULSE, NOISE, ARB\"\"\"\n        if wave=='triangular' or wave=='Triangular' or wave=='TRIANGULAR':\n            self.write('WAVE TRIANG')\n        elif wave=='arbitrary' or wave=='Arbitrary' or wave=='ARBITRARY':\n            self.write('WAVE ARB')\n        else:\n            self.write('WAVE ' + wave)",
  "def __init__(self, port=None):\n        \"\"\"Serial Interface to TGF4242 function generator.\"\"\"\n        SerialInstrument.__init__(self, port=port)",
  "def channel(self, channel):\n        \"\"\"Select Channel: 1 or 2\"\"\"\n        self.write('CHN ' + str(channel))",
  "def output(self, output):\n        \"\"\"Turn ON or OFF the output of selected channel:\n            \n            type 'ON' or 1 to turn on\n            \n            type 'OFF' or 0 to turn off\n        \"\"\"\n        if output==1:\n            self.write('OUTPUT ON')\n        elif output==0:\n            self.write('OUTPUT OFF')\n        else:\n            self.write('OUTPUT ' + output)",
  "def freq(self, freq):\n        \"\"\"Set signal frequency in Hz\"\"\"\n        self.write('FREQ ' + str(freq))",
  "def ampl(self, ampl):\n        \"\"\"Set signal amplitude (Vpp) in VOLTS\"\"\"\n        self.write('ampl ' + str(ampl))",
  "def offset(self, offset):\n        \"\"\"Set the signal DC offset in VOLTS\"\"\"\n        self.write('DCOFFS ' +  str(offset))",
  "def phase(self, phase):\n        \"\"\"Set the waveform phase offset in DEGREES\"\"\"\n        self.write('PHASE ' + str(phase))",
  "def align(self, align):\n        \"\"\"Align phase for both channels\"\"\"\n        self.write('ALIGN')",
  "def waveform(self, wave):\n        \"\"\"Set the waveform: SINE, SQUARE, TRIANG, PULSE, NOISE, ARB\"\"\"\n        if wave=='triangular' or wave=='Triangular' or wave=='TRIANGULAR':\n            self.write('WAVE TRIANG')\n        elif wave=='arbitrary' or wave=='Arbitrary' or wave=='ARBITRARY':\n            self.write('WAVE ARB')\n        else:\n            self.write('WAVE ' + wave)",
  "def isMonotonic(A):\n\n    return (all(A[i] <= A[i + 1] for i in range(len(A) - 1)) or\n            all(A[i] >= A[i + 1] for i in range(len(A) - 1)))",
  "class PowerControl(Instrument):\n    '''\n    Controls the power. power_controller is something with a continuous input parameter like a filter wheel, or an AOM. \n    '''\n    calibrate_points = DumbNotifiedProperty(25)\n    def __init__(self, power_controller,\n                 power_meter,\n                 before_calibration_func=None,\n                 after_calibration_func=None,\n                 calibration_points=25,\n                 title='power control',\n                 move_range=(0, 1)):\n        super().__init__()\n        self.pc = power_controller\n        self.pometer = power_meter\n        self.calibration_points = calibration_points\n        self.title = title\n        self.before_calibration_func = before_calibration_func \n        self.after_calibration_func = after_calibration_func\n        assert isinstance(power_controller, (Aom, Stage)), \\\n            ('power_controller must be AOM or Stage')\n        assert isinstance(power_meter, PowerMeter), \\\n            ('Power meter have power_meter.PowerMeter base class')\n        \n        \n        if isinstance(self.pc, RStage):\n            self.min_param, self.max_param = 0, 360\n     \n        elif isinstance(self.pc, Aom):\n            self.min_param, self.max_param = 0, 1\n        else: \n            self.min_param, self.max_param =  move_range\n        self.maxpower = None\n        self.minpower = None\n        self.update_power_calibration()\n        \n        if isinstance(self.pc, Stage):\n            self.set_param = self.pc.move\n            self.get_param = self.pc.get_position\n        if isinstance(self.pc, Aom):\n            self.set_param = self.pc.Power\n            self.get_param = self.pc.Get_Power\n\n    @property\n    def param(self):\n        return self.get_param()\n\n    @param.setter\n    def param(self, value):\n        self.set_param(value)\n\n    @property\n    def mid_param(self):\n        return (self.max_param - self.min_param)/2\n\n    @property\n    def points(self):\n        if isinstance(self.pc, RStage):\n            if self.min_param < self.max_param:\n                return np.logspace(0, np.log10(self.max_param-self.min_param), self.calibration_points)+self.min_param\n            return self.min_param - np.logspace(0, np.log10(self.min_param-self.max_param), self.calibration_points)\n        else:  # isinstance(self.pc, Aom):\n            return np.linspace(self.min_param, self.max_param, num=self.calibration_points, endpoint=True)\n\n    def calibrate_power(self, update_progress=lambda p: p):\n        '''\n\n        '''\n        if self.before_calibration_func is not None:\n            state = self.before_calibration_func()\n        attrs = {}\n    \n        if isinstance(self.pc, RStage):\n            attrs['Angles'] = self.points\n        if isinstance(self.pc, Aom):\n            attrs['Voltages'] = self.points\n\n        attrs['x_axis'] = self.points\n        attrs['parameters'] = self.points\n        attrs['wavelengths'] = self.points\n\n        powers = []\n        \n        for i, point in enumerate(self.points):\n            self.param = point\n            time.sleep(.2)\n            powers.append(self.pometer.power)\n            update_progress(i)\n\n        group = self.create_data_group(self.title+'_%d')\n        group.create_dataset('powers', data=powers, attrs=attrs)\n        \n        \n        self.param = self.mid_param\n        self.update_power_calibration()\n        if self.after_calibration_func is not None:\n            self.after_calibration_func(*state)\n\n    def update_power_calibration(self, specific_calibration=None, laser=None):\n        '''\n        specific_calibration should be the exact name of the power calibration group, otherwise\n        the most recent calibration for the given laser is used.\n        '''\n\n        \n        initial = datafile._use_current_group\n        datafile._use_current_group = False\n        search_in = self.get_root_data_folder()\n        datafile._use_current_group = initial\n        if specific_calibration is not None:\n            try:\n                power_calibration_group = search_in[specific_calibration]\n            except ValueError:\n                print('This calibration doesn\\'t exist!')\n                return\n        else:\n            \n            candidates = [group for name, group in sort_by_timestamp(search_in) # return key val pairs\n                                       if '_'.join(name.split('_')[:-1]) == self.title]\n            if candidates: \n                power_calibration_group = candidates[-1]\n                pc = power_calibration_group['powers']\n                self.power_calibration = {'powers': pc[()],\n                                          'parameters': pc.attrs['parameters']}\n                if isMonotonic(self.power_calibration['powers']):\n                    self.update_config('parameters_'+self.title,\n                                       pc.attrs['parameters'])\n                    self.update_config('powers_'+self.title, pc[()])\n                else:\n                    print('power curve isn\\'t monotonic, not saving to config file')\n            else:\n                if len(self.config_file) > 0:\n                    self.power_calibration = {'_'.join(n.split(\n                        '_')[:-1]): f for n, f in self.config_file.items() if n.endswith(self.title)}\n                    print(\n                        f'No power calibration in current file, using inaccurate configuration ({self.title})')\n                else:\n                    print(f'No power calibration found ({self.title})')\n\n    @property\n    def power(self):\n        return self.pometer.power\n\n    @power.setter\n    def power(self, value):\n        self._power = value\n        self.param = self.power_to_param(value)\n\n    def power_to_param(self, power):\n        \n        params = self.power_calibration['parameters']\n        powers = np.array(self.power_calibration['powers'])\n        curve = interpolate.interp1d(powers, params, kind='cubic')\n        return curve(power)\n\n    def get_qt_ui(self):\n        return PowerControl_UI(self)",
  "class PowerControl_UI(QtWidgets.QWidget, UiTools):\n    def __init__(self, PC):\n        super(PowerControl_UI, self).__init__()\n        uic.loadUi(os.path.join(os.path.dirname(\n            __file__), 'power_control.ui'), self)\n        self.PC = PC\n        self.auto_connect_by_name(controlled_object=self.PC)\n        self._power_doubleSpinBox.valueChanged.connect(self._power_changed)\n        self.title_label.setText(self.PC.title)\n    \n    def _power_changed(self, new):\n        self.PC.power = new\n        \n    def calibrate_power_gui(self):\n        run_function_modally(self.PC.calibrate_power, \n                             progress_maximum=len(self.PC.points))",
  "def __init__(self, power_controller,\n                 power_meter,\n                 before_calibration_func=None,\n                 after_calibration_func=None,\n                 calibration_points=25,\n                 title='power control',\n                 move_range=(0, 1)):\n        super().__init__()\n        self.pc = power_controller\n        self.pometer = power_meter\n        self.calibration_points = calibration_points\n        self.title = title\n        self.before_calibration_func = before_calibration_func \n        self.after_calibration_func = after_calibration_func\n        assert isinstance(power_controller, (Aom, Stage)), \\\n            ('power_controller must be AOM or Stage')\n        assert isinstance(power_meter, PowerMeter), \\\n            ('Power meter have power_meter.PowerMeter base class')\n        \n        \n        if isinstance(self.pc, RStage):\n            self.min_param, self.max_param = 0, 360\n     \n        elif isinstance(self.pc, Aom):\n            self.min_param, self.max_param = 0, 1\n        else: \n            self.min_param, self.max_param =  move_range\n        self.maxpower = None\n        self.minpower = None\n        self.update_power_calibration()\n        \n        if isinstance(self.pc, Stage):\n            self.set_param = self.pc.move\n            self.get_param = self.pc.get_position\n        if isinstance(self.pc, Aom):\n            self.set_param = self.pc.Power\n            self.get_param = self.pc.Get_Power",
  "def param(self):\n        return self.get_param()",
  "def param(self, value):\n        self.set_param(value)",
  "def mid_param(self):\n        return (self.max_param - self.min_param)/2",
  "def points(self):\n        if isinstance(self.pc, RStage):\n            if self.min_param < self.max_param:\n                return np.logspace(0, np.log10(self.max_param-self.min_param), self.calibration_points)+self.min_param\n            return self.min_param - np.logspace(0, np.log10(self.min_param-self.max_param), self.calibration_points)\n        else:  # isinstance(self.pc, Aom):\n            return np.linspace(self.min_param, self.max_param, num=self.calibration_points, endpoint=True)",
  "def calibrate_power(self, update_progress=lambda p: p):\n        '''\n\n        '''\n        if self.before_calibration_func is not None:\n            state = self.before_calibration_func()\n        attrs = {}\n    \n        if isinstance(self.pc, RStage):\n            attrs['Angles'] = self.points\n        if isinstance(self.pc, Aom):\n            attrs['Voltages'] = self.points\n\n        attrs['x_axis'] = self.points\n        attrs['parameters'] = self.points\n        attrs['wavelengths'] = self.points\n\n        powers = []\n        \n        for i, point in enumerate(self.points):\n            self.param = point\n            time.sleep(.2)\n            powers.append(self.pometer.power)\n            update_progress(i)\n\n        group = self.create_data_group(self.title+'_%d')\n        group.create_dataset('powers', data=powers, attrs=attrs)\n        \n        \n        self.param = self.mid_param\n        self.update_power_calibration()\n        if self.after_calibration_func is not None:\n            self.after_calibration_func(*state)",
  "def update_power_calibration(self, specific_calibration=None, laser=None):\n        '''\n        specific_calibration should be the exact name of the power calibration group, otherwise\n        the most recent calibration for the given laser is used.\n        '''\n\n        \n        initial = datafile._use_current_group\n        datafile._use_current_group = False\n        search_in = self.get_root_data_folder()\n        datafile._use_current_group = initial\n        if specific_calibration is not None:\n            try:\n                power_calibration_group = search_in[specific_calibration]\n            except ValueError:\n                print('This calibration doesn\\'t exist!')\n                return\n        else:\n            \n            candidates = [group for name, group in sort_by_timestamp(search_in) # return key val pairs\n                                       if '_'.join(name.split('_')[:-1]) == self.title]\n            if candidates: \n                power_calibration_group = candidates[-1]\n                pc = power_calibration_group['powers']\n                self.power_calibration = {'powers': pc[()],\n                                          'parameters': pc.attrs['parameters']}\n                if isMonotonic(self.power_calibration['powers']):\n                    self.update_config('parameters_'+self.title,\n                                       pc.attrs['parameters'])\n                    self.update_config('powers_'+self.title, pc[()])\n                else:\n                    print('power curve isn\\'t monotonic, not saving to config file')\n            else:\n                if len(self.config_file) > 0:\n                    self.power_calibration = {'_'.join(n.split(\n                        '_')[:-1]): f for n, f in self.config_file.items() if n.endswith(self.title)}\n                    print(\n                        f'No power calibration in current file, using inaccurate configuration ({self.title})')\n                else:\n                    print(f'No power calibration found ({self.title})')",
  "def power(self):\n        return self.pometer.power",
  "def power(self, value):\n        self._power = value\n        self.param = self.power_to_param(value)",
  "def power_to_param(self, power):\n        \n        params = self.power_calibration['parameters']\n        powers = np.array(self.power_calibration['powers'])\n        curve = interpolate.interp1d(powers, params, kind='cubic')\n        return curve(power)",
  "def get_qt_ui(self):\n        return PowerControl_UI(self)",
  "def __init__(self, PC):\n        super(PowerControl_UI, self).__init__()\n        uic.loadUi(os.path.join(os.path.dirname(\n            __file__), 'power_control.ui'), self)\n        self.PC = PC\n        self.auto_connect_by_name(controlled_object=self.PC)\n        self._power_doubleSpinBox.valueChanged.connect(self._power_changed)\n        self.title_label.setText(self.PC.title)",
  "def _power_changed(self, new):\n        self.PC.power = new",
  "def calibrate_power_gui(self):\n        run_function_modally(self.PC.calibrate_power, \n                             progress_maximum=len(self.PC.points))",
  "class Lockin_SR810(vi.VisaInstrument):\n    \"\"\"Software control for the Stanford Research Systems SR844 Lockin\n    \"\"\"\n\n    def __init__(self, address='GPIB0::8::INSTR'):\n        \"\"\"Sets up visa communication and class dictionaries\n        \n        The class dictionaries are manully inputed translations between what \n        the lockin will send/recieve and the real values. \n        These have been built for:\n            - channel number i.e. X,Y ...   \n            - Sensitivity i.e. Voltage range\n            - time constant i.e. integration time\n            - Filter options i.e. 6 dB etc\n            \n        Args:\n            address(str):   Visa address\n        \n        \"\"\"\n        super(Lockin_SR810, self).__init__(address)\n        self.instr.read_termination = '\\n'\n        self.instr.write_termination = '\\n'\n        self.instr.timeout = None\n        print(self.instr.read_termination)\n        print(self.write('OUTX'))\n        self.write('ICPL 0')\n        self.ch_list = {}\n        self.sens_list = {}\n        self.time_list = {0:10e-6, # time constant given in sec\n                          1:30e-6,\n                          2:100e-6,\n                          3:300e-6, \n                          4:1e-3,\n                          5:3e-3,\n                          6:0.01,\n                          7:0.03,\n                          8:0.1,\n                          9:0.300,\n                          10:1,\n                          11:3,\n                          12:10,\n                          13:30,\n                                     }\n        self.filter_list = {}\n        print('lockin connected successfully')\n        return\n\n    def measure_variables(self, channels='1,2'):\n        \"\"\"Upto six variable read, must be greater than 1 measure via a string\n        Args:\n            channels(str):  A string containing integers seperated by a comma \n                            refering to each of the Variable that you which to \n                            measure (as shown below):\n                            1   X\n                            2   Y\n                            3   R [V]\n                            4   R [dBm]\n                            5   \\xce\\xb8\n                            6   AUX IN 1\n                            7   AUX IN 2\n                            8   Reference Frequency\n                            9   CH1 display\n                            10  CH2 display \n        \"\"\"\n        variables = self.query('SNAP? ' + channels)\n        variables = variables.split(',')\n        variables = [ float(i) for i in variables ]\n        return variables\n\n    def measure_X(self):\n        \"\"\"Measure the current X value\n        Notes :\n            Offsets and Ratio applied\"\"\"\n        return self.float_query('OUTP? 1')\n\n    def measure_Y(self):\n        \"\"\"Measure the current Y value\n        Notes :\n            Offsets and Ratio applied\"\"\"\n        return self.float_query('OUTP? 2')\n\n    def measure_R(self):\n        \"\"\"Measure the current R value\n        Notes :\n            Offsets and Ratio applied\"\"\"\n        output = -1\n        while output > 1 or output < 0:\n            output = self.float_query('OUTP? 3')\n\n        return self.float_query('OUTP? 3')\n\n    def measure_theta(self):\n        \"\"\"Measure the current phase (theta) \n        Notes :\n            Offsets and Ratio applied\"\"\"\n        return self.float_query('OUTP? 4')\n\n    def check_frequency(self):\n        \"\"\" Return current measurement frequesncy\n        Returns:\n            Current measreument frequency\"\"\"\n        return self.float_query('FREQ?')\n\n    def get_sens(self):\n        \"\"\" The sensitivity property \n        \n        Gettr:\n            Gets the Current sensitivity as an integer and a real value\n            \n            Returns:\n                num (int):  The integer returned by the lockin\n                sens_list[num](float):  The real value for sensitivty in Vrms\n                        \n        Settr:\n            Sets the current sensitivity as a integer \n            \n            Args:\n                i(int): Sets the sensitivty of the lockin as shown by the dict \n                        self.sens_list typed out below.\n                        \n                        i               Sensitivity\n                        0               100 nVrms / -127 dBm \n                        1               300 nVrms / -117 dBm \n                        2               1 \\xce\\xbcVrms / -107 dBm \n                        3               3 \\xce\\xbcVrms / -97 dBm \n                        4               10 \\xce\\xbcVrms / -87 dBm \n                        5               30 \\xce\\xbcVrms / -77 dBm \n                        6               100 \\xce\\xbcVrms / -67 dBm \n                        7               300 \\xce\\xbcVrms / -57 dBm\n                        8               1 mVrms / -47 dBm\n                        9               3 mVrms / -37 dBm\n                        10              10 mVrms / -27 dBm\n                        11              30 mVrms / -17 dBm\n                        12              100 mVrms / -7 dBm\n                        13              300 mVrms / +3 dBm\n                        14              1 Vrms / +13 dBm\n        \"\"\"\n        num = self.int_query('SENS?')\n        return (\n         num, self.sens_list[num])\n\n    def set_sens(self, i):\n        self.write('SENS%s' % i)\n\n    sensitivity = property(get_sens, set_sens)\n\n    def get_time_constant(self):\n        \"\"\" The time_constant property \n        \n        Gettr:\n            Gets the Current time constant as an integer and a real value\n            \n            Returns:\n                num (int):  The integer returned by the lockin\n                time_list[num](float):  The real value for sensitivty in Seconds\n                        \n        Settr:\n            Sets the current time constant as an integer \n            \n            Args:\n                i(int): Sets the time constant of the lockin as shown by the dict \n                        self.time_list typed out below.\n                        \n                        i       time constant\n                        0       100 \\xce\\xbcs \n                        1       300 \\xce\\xbcs \n                        2       1 ms \n                        3       3 ms \n                        4       10 ms \n                        5       30 ms\n                        6       100 ms \n                        7       300 ms \n                        8       1 s \n                        9       3 s\n                        10      10 s\n                        11      30 s\n                        12      100 s\n                        13      300 s\n                        14      1 ks\n                        15      3 ks\n                        16      10 ks\n                        17      30 ks\n        \"\"\"\n        num = self.int_query('OFLT?')\n        return (\n         num, self.time_list[num])\n\n    def set_time_constant(self, i):\n        self.write('OFLT' + str(i))\n\n    time_constant = property(get_time_constant, set_time_constant)\n\n    def set_time_constant_from_int(self, integrationtime):\n        \"\"\"Command to reverse read a dictionary and set the time_constant\n        \n        Args:\n            integrationtime(float):     The real value for the time constant in seconds\n                                        for allowed values see self.time_list\n        \"\"\"\n        for i in range(len(list(self.time_list.values())[:])):\n            if list(self.time_list.values())[i] == integrationtime:\n                self.time_constant = list(self.time_list.keys())[i]\n                return True\n\n        print('Setting integration time failed. ' + str(integrationtime) + ' is not in self.time_list')\n        return False\n\n    def get_line_filter(self):\n        \"\"\" Gets filter related to power line, \n            0 - no filter\n            1 - line filter\n            2 - 2xline filter\n            3 - Both \"\"\"\n        num_filter = self.int_query('ILIN?')\n        return num_filter\n\n    def set_line_filter(self, filter_mode):\n        \"\"\" Sets filter related to power line, \n            0 - no filter\n            1 - line filter\n            2 - 2xline filter\n            3 - Both \"\"\"\n        self.write('ILIN' + str(filter_mode))\n\n    linefilter = property(get_line_filter, set_line_filter)\n\n    def set_input_mode(self, mode):\n        \"\"\"Sets the input mode:\n            A (i=0), A-B (i=1), I (1 M\\xce\\xa9) (i=2) or I (100 M\\xce\\xa9) (i=3).\"\"\"\n        self.write('ISRC' + str(mode))\n\n    def get_input_mode(self):\n        return self.int_query('ISRC?')\n\n    inputmode = property(get_input_mode, set_input_mode)\n\n    def get_filter(self):\n        \"\"\" The filterslope property \n        \n        Gettr:\n            Gets the filter as an integer and a real value\n            \n            Returns:\n                num (int):  The integer returned by the lockin\n                time_list[num](str):  The real value for filter \n                        \n        Settr:\n            Sets the current filter as an integer \n            \n            Args:\n                i(int): Sets the filter of the lockin as shown by the dict \n                        self.time_list typed out below.\n                        \n                        i       Filter\n                        0       No filter\n                        1       6 dB\n                        2       12 dB\n                        3       18 dB\n                        4       24 dB \n        \"\"\"\n        num = self.int_query('OFSL?')\n        return (\n         num, self.filter_list[num])\n\n    def set_filter(self, i):\n        self.write('OFSL%s' % i)\n\n    filterslope = property(get_filter, set_filter)\n\n    def get_res(self):\n        \"\"\" Gets the dynamic reserve of the lockin\n         0 = High, 1 = normal, 2 = low noise\n        \"\"\"\n        return self.int_query('RMOD?')\n\n    def set_res(self, i):\n        self.write('RMOD%s' % i)\n\n    reserve = property(get_res, set_res)\n\n    def set_phase(self, phase):\n        self.write('PHAS' + str(phase))\n\n    def get_phase(self):\n        return self.float_query('PHAS?')\n\n    phase = property(get_phase, set_phase)\n    \n    def set_harmonic(self, harmonic):\n        self.write('HARM' + str(harmonic))\n        print('HARM' + str(harmonic))\n    def get_harmonic(self, harmonic):\n        return self.int_query('HARM?')\n    harmonic = property(get_harmonic, set_harmonic)\n\n    def autosens(self):\n        \"\"\"checks measurement is with range and auto changes sensitivty and reserve respectively\n        Returns:\n            sens(i,float):  The new sensitivty in both forms\n            wide_res(int):  The new wide reserve (high = 0, normal = 1, low noise = 2)\n            close_res(int): The new close reserve (high = 0, normal = 1, low noise = 2)\n        \"\"\"\n        testmax = np.max([np.abs(self.measure_R()), np.abs(self.measure_X()), np.abs(self.measure_Y())])\n        try:\n            Lowersense = self.sens_list[(self.sensitivity[0] - 1)]\n        except KeyError:\n            Lowersense = 0.0\n        else:\n            while testmax > self.sensitivity[1] or testmax < Lowersense:\n                testmax = np.max([np.abs(self.measure_R()), np.abs(self.measure_X()), np.abs(self.measure_Y())])\n                try:\n                    Lowersense = self.sens_list[(self.sensitivity[0] - 1)]\n                except KeyError:\n                    Lowersense = 0.0\n                else:\n                    if testmax > self.sensitivity[1]:\n                        if self.sensitivity[0] == 14:\n                            print('OVERLOADED RUNNNNNN')\n                        self.sensitivity = self.sensitivity[0] + 1\n                    elif testmax < Lowersense:\n                        self.sensitivity = self.sensitivity[0] - 1\n                    sleep(1)\n                    self.write('AWRS')\n                    wide_res = self.wide_res\n                    self.write('ACRS')\n                    close_res = self.close_res\n\n        sens = self.sensitivity\n        wide_res = self.wide_res\n        close_res = self.close_res\n        return (\n         sens, wide_res, close_res)\n\n    def get_harmonic(self):\n        num = self.int_query(\"HARM?\");\n        return num\n    def set_harmonic(self,i):\n        self.write(\"HARM%s\" %i)\n        \n    harmonic = property(get_harmonic, set_harmonic)",
  "def __init__(self, address='GPIB0::8::INSTR'):\n        \"\"\"Sets up visa communication and class dictionaries\n        \n        The class dictionaries are manully inputed translations between what \n        the lockin will send/recieve and the real values. \n        These have been built for:\n            - channel number i.e. X,Y ...   \n            - Sensitivity i.e. Voltage range\n            - time constant i.e. integration time\n            - Filter options i.e. 6 dB etc\n            \n        Args:\n            address(str):   Visa address\n        \n        \"\"\"\n        super(Lockin_SR810, self).__init__(address)\n        self.instr.read_termination = '\\n'\n        self.instr.write_termination = '\\n'\n        self.instr.timeout = None\n        print(self.instr.read_termination)\n        print(self.write('OUTX'))\n        self.write('ICPL 0')\n        self.ch_list = {}\n        self.sens_list = {}\n        self.time_list = {0:10e-6, # time constant given in sec\n                          1:30e-6,\n                          2:100e-6,\n                          3:300e-6, \n                          4:1e-3,\n                          5:3e-3,\n                          6:0.01,\n                          7:0.03,\n                          8:0.1,\n                          9:0.300,\n                          10:1,\n                          11:3,\n                          12:10,\n                          13:30,\n                                     }\n        self.filter_list = {}\n        print('lockin connected successfully')\n        return",
  "def measure_variables(self, channels='1,2'):\n        \"\"\"Upto six variable read, must be greater than 1 measure via a string\n        Args:\n            channels(str):  A string containing integers seperated by a comma \n                            refering to each of the Variable that you which to \n                            measure (as shown below):\n                            1   X\n                            2   Y\n                            3   R [V]\n                            4   R [dBm]\n                            5   \\xce\\xb8\n                            6   AUX IN 1\n                            7   AUX IN 2\n                            8   Reference Frequency\n                            9   CH1 display\n                            10  CH2 display \n        \"\"\"\n        variables = self.query('SNAP? ' + channels)\n        variables = variables.split(',')\n        variables = [ float(i) for i in variables ]\n        return variables",
  "def measure_X(self):\n        \"\"\"Measure the current X value\n        Notes :\n            Offsets and Ratio applied\"\"\"\n        return self.float_query('OUTP? 1')",
  "def measure_Y(self):\n        \"\"\"Measure the current Y value\n        Notes :\n            Offsets and Ratio applied\"\"\"\n        return self.float_query('OUTP? 2')",
  "def measure_R(self):\n        \"\"\"Measure the current R value\n        Notes :\n            Offsets and Ratio applied\"\"\"\n        output = -1\n        while output > 1 or output < 0:\n            output = self.float_query('OUTP? 3')\n\n        return self.float_query('OUTP? 3')",
  "def measure_theta(self):\n        \"\"\"Measure the current phase (theta) \n        Notes :\n            Offsets and Ratio applied\"\"\"\n        return self.float_query('OUTP? 4')",
  "def check_frequency(self):\n        \"\"\" Return current measurement frequesncy\n        Returns:\n            Current measreument frequency\"\"\"\n        return self.float_query('FREQ?')",
  "def get_sens(self):\n        \"\"\" The sensitivity property \n        \n        Gettr:\n            Gets the Current sensitivity as an integer and a real value\n            \n            Returns:\n                num (int):  The integer returned by the lockin\n                sens_list[num](float):  The real value for sensitivty in Vrms\n                        \n        Settr:\n            Sets the current sensitivity as a integer \n            \n            Args:\n                i(int): Sets the sensitivty of the lockin as shown by the dict \n                        self.sens_list typed out below.\n                        \n                        i               Sensitivity\n                        0               100 nVrms / -127 dBm \n                        1               300 nVrms / -117 dBm \n                        2               1 \\xce\\xbcVrms / -107 dBm \n                        3               3 \\xce\\xbcVrms / -97 dBm \n                        4               10 \\xce\\xbcVrms / -87 dBm \n                        5               30 \\xce\\xbcVrms / -77 dBm \n                        6               100 \\xce\\xbcVrms / -67 dBm \n                        7               300 \\xce\\xbcVrms / -57 dBm\n                        8               1 mVrms / -47 dBm\n                        9               3 mVrms / -37 dBm\n                        10              10 mVrms / -27 dBm\n                        11              30 mVrms / -17 dBm\n                        12              100 mVrms / -7 dBm\n                        13              300 mVrms / +3 dBm\n                        14              1 Vrms / +13 dBm\n        \"\"\"\n        num = self.int_query('SENS?')\n        return (\n         num, self.sens_list[num])",
  "def set_sens(self, i):\n        self.write('SENS%s' % i)",
  "def get_time_constant(self):\n        \"\"\" The time_constant property \n        \n        Gettr:\n            Gets the Current time constant as an integer and a real value\n            \n            Returns:\n                num (int):  The integer returned by the lockin\n                time_list[num](float):  The real value for sensitivty in Seconds\n                        \n        Settr:\n            Sets the current time constant as an integer \n            \n            Args:\n                i(int): Sets the time constant of the lockin as shown by the dict \n                        self.time_list typed out below.\n                        \n                        i       time constant\n                        0       100 \\xce\\xbcs \n                        1       300 \\xce\\xbcs \n                        2       1 ms \n                        3       3 ms \n                        4       10 ms \n                        5       30 ms\n                        6       100 ms \n                        7       300 ms \n                        8       1 s \n                        9       3 s\n                        10      10 s\n                        11      30 s\n                        12      100 s\n                        13      300 s\n                        14      1 ks\n                        15      3 ks\n                        16      10 ks\n                        17      30 ks\n        \"\"\"\n        num = self.int_query('OFLT?')\n        return (\n         num, self.time_list[num])",
  "def set_time_constant(self, i):\n        self.write('OFLT' + str(i))",
  "def set_time_constant_from_int(self, integrationtime):\n        \"\"\"Command to reverse read a dictionary and set the time_constant\n        \n        Args:\n            integrationtime(float):     The real value for the time constant in seconds\n                                        for allowed values see self.time_list\n        \"\"\"\n        for i in range(len(list(self.time_list.values())[:])):\n            if list(self.time_list.values())[i] == integrationtime:\n                self.time_constant = list(self.time_list.keys())[i]\n                return True\n\n        print('Setting integration time failed. ' + str(integrationtime) + ' is not in self.time_list')\n        return False",
  "def get_line_filter(self):\n        \"\"\" Gets filter related to power line, \n            0 - no filter\n            1 - line filter\n            2 - 2xline filter\n            3 - Both \"\"\"\n        num_filter = self.int_query('ILIN?')\n        return num_filter",
  "def set_line_filter(self, filter_mode):\n        \"\"\" Sets filter related to power line, \n            0 - no filter\n            1 - line filter\n            2 - 2xline filter\n            3 - Both \"\"\"\n        self.write('ILIN' + str(filter_mode))",
  "def set_input_mode(self, mode):\n        \"\"\"Sets the input mode:\n            A (i=0), A-B (i=1), I (1 M\\xce\\xa9) (i=2) or I (100 M\\xce\\xa9) (i=3).\"\"\"\n        self.write('ISRC' + str(mode))",
  "def get_input_mode(self):\n        return self.int_query('ISRC?')",
  "def get_filter(self):\n        \"\"\" The filterslope property \n        \n        Gettr:\n            Gets the filter as an integer and a real value\n            \n            Returns:\n                num (int):  The integer returned by the lockin\n                time_list[num](str):  The real value for filter \n                        \n        Settr:\n            Sets the current filter as an integer \n            \n            Args:\n                i(int): Sets the filter of the lockin as shown by the dict \n                        self.time_list typed out below.\n                        \n                        i       Filter\n                        0       No filter\n                        1       6 dB\n                        2       12 dB\n                        3       18 dB\n                        4       24 dB \n        \"\"\"\n        num = self.int_query('OFSL?')\n        return (\n         num, self.filter_list[num])",
  "def set_filter(self, i):\n        self.write('OFSL%s' % i)",
  "def get_res(self):\n        \"\"\" Gets the dynamic reserve of the lockin\n         0 = High, 1 = normal, 2 = low noise\n        \"\"\"\n        return self.int_query('RMOD?')",
  "def set_res(self, i):\n        self.write('RMOD%s' % i)",
  "def set_phase(self, phase):\n        self.write('PHAS' + str(phase))",
  "def get_phase(self):\n        return self.float_query('PHAS?')",
  "def set_harmonic(self, harmonic):\n        self.write('HARM' + str(harmonic))\n        print('HARM' + str(harmonic))",
  "def get_harmonic(self, harmonic):\n        return self.int_query('HARM?')",
  "def autosens(self):\n        \"\"\"checks measurement is with range and auto changes sensitivty and reserve respectively\n        Returns:\n            sens(i,float):  The new sensitivty in both forms\n            wide_res(int):  The new wide reserve (high = 0, normal = 1, low noise = 2)\n            close_res(int): The new close reserve (high = 0, normal = 1, low noise = 2)\n        \"\"\"\n        testmax = np.max([np.abs(self.measure_R()), np.abs(self.measure_X()), np.abs(self.measure_Y())])\n        try:\n            Lowersense = self.sens_list[(self.sensitivity[0] - 1)]\n        except KeyError:\n            Lowersense = 0.0\n        else:\n            while testmax > self.sensitivity[1] or testmax < Lowersense:\n                testmax = np.max([np.abs(self.measure_R()), np.abs(self.measure_X()), np.abs(self.measure_Y())])\n                try:\n                    Lowersense = self.sens_list[(self.sensitivity[0] - 1)]\n                except KeyError:\n                    Lowersense = 0.0\n                else:\n                    if testmax > self.sensitivity[1]:\n                        if self.sensitivity[0] == 14:\n                            print('OVERLOADED RUNNNNNN')\n                        self.sensitivity = self.sensitivity[0] + 1\n                    elif testmax < Lowersense:\n                        self.sensitivity = self.sensitivity[0] - 1\n                    sleep(1)\n                    self.write('AWRS')\n                    wide_res = self.wide_res\n                    self.write('ACRS')\n                    close_res = self.close_res\n\n        sens = self.sensitivity\n        wide_res = self.wide_res\n        close_res = self.close_res\n        return (\n         sens, wide_res, close_res)",
  "def get_harmonic(self):\n        num = self.int_query(\"HARM?\");\n        return num",
  "def set_harmonic(self,i):\n        self.write(\"HARM%s\" %i)",
  "class Adlink9812(Instrument):\n\n\tdef __init__(self, dll_path=\"C:\\ADLINK\\PCIS-DASK\\Lib\\PCI-Dask64.dll\",verbose=False,debug=False):\n\t\t\"\"\"Initialize DLL and configure card\"\"\"\n\t\tsuper(Adlink9812,self).__init__()\n\t\tself.debug = debug\n\t\tif self.debug:\n\t\t\tself.log(message=\"Instrument.Adlink9812: DEBUG MODE\")\n\t\tif not os.path.exists(dll_path):\n\t\t\tif self.debug != True:\n\t\t\t\tmessage= \"Adlink DLL not found: {}\".format(dll_path)\n\t\t\t\tself.log(message=message)\n\t\t\t\traise ValueError(message)\n\t\telse:\n\t\t\tself.dll = CDLL(dll_path)\n\t\t\tself.card_id = self.register_card()\n\t\t\tself.configure_card()\n\n\t\tself.ui = None\n\n\tdef __del__(self):\n\t\t'''Deregister the card on object deletion'''\n\t\tself.release_card()\n\n\tdef get_qt_ui(self):\n\t\tif self.ui is None:\n\t\t\tself.ui = Adlink9812UI(card=self)\n\t\treturn self.ui\n\n\tdef register_card(self,channel = 0):\n\t\toutp = ctypes.c_int16(self.dll.Register_Card(adlink9812_constants.PCI_9812,c_ushort(channel)))\n\t\tif outp.value < 0:\n\t\t\tself.log(\"Register_Card: nonpositive value -> error code:\"+str(outp))\n\t\treturn outp.value\n\n\tdef release_card(self):\n\t\treleaseErr = ctypes.c_int16(self.dll.Release_Card(self.card_id))\n\t\tif releaseErr.value != 0:\n\t\t\tself.log(message=\"Release_Card: Non-zero status code:\"+str(releaseErr.value))\n\t\treturn\n\n\tdef get_card_sample_rate(self,sampling_freq):\n\t\tactual = c_double()\n\t\tstatusCode = ctypes.c_int16(DLL.GetActualRate(self.card_id,c_double(sampling_freq), byref(actual)))\n\n\t\tif statusCode.value != 0:\n\t\t\tself.log(message=\"GetActualRate: Non-zero status code:\"+str(statusCode.value))\n\t\treturn actual.value\n\n\tdef configure_card(self):\n\t\t#Configure card for recording\n\t\tconfigErr = ctypes.c_int16(self.dll.AI_9812_Config(\n\t\t\tc_ushort(self.card_id),\n\t\t\tc_ushort(adlink9812_constants.P9812_TRGMOD_SOFT), #Software trigger mode\n\t\t\tc_ushort(adlink9812_constants.P9812_TRGSRC_CH0),  #Channel 0 \n\t\t\tc_ushort(adlink9812_constants.P9812_TRGSLP_POS),  #Positive edge trigger\n\t\t\tc_ushort(adlink9812_constants.P9812_CLKSRC_INT),  #Internal clock\n\t\t\tc_ushort(0x80), \t\t\t\t\t\t\t\t  #Trigger threshold = 0.00V\n\t\t\tc_ushort(0),\t\t\t\t\t\t\t\t\t\t#Postcount - setting for Middle/Delay Trigger\n\t\t\t))\n\n\t\tif configErr.value != 0:\n\t\t\tself.log(message=\"AI_9812_Config: Non-zero status code:\"+str(configErr.value))\n\t\treturn\n\n\n\tdef convert_to_volts(self,inputBuffer, outputBuffer, buffer_size):\n\t\tconvertErr = ctypes.c_int16(self.dll.AI_ContVScale(\n\t\t\t\tc_ushort(self.card_id),\t\t\t\t\t\t\t#CardNumber\n\t\t\t\tc_ushort(adlink9812_constants.AD_B_1_V),\t\t#AdRange\n\t\t\t\tinputBuffer, \t\t\t\t\t\t\t\t\t#DataBuffer   - array storing raw 16bit A/D values\n\t\t\t\toutputBuffer, \t\t\t\t\t\t\t\t\t#VoltageArray - reference to array storing voltages\n\t\t\t\tc_uint32(buffer_size) \t\t\t\t\t\t\t#Sample count - number of samples to be converted\n\t\t\t))\n\n\t\tif convertErr.value != 0:\n\t\t\tself.log(message=\"AI_ContVScale: Non-zero status code:\"+str(convertErr.value))\n\t\treturn \n\n\n\tdef synchronous_analog_input_read(self,sample_freq, sample_count,verbose = False,channel=0):\n\t\t#Initialize Buffers\n\t\t#databuffer for holding A/D samples + metadata bits\n\t\tdataBuff = (c_ushort*sample_count)()\n\t\t#voltageArray for holding converted voltage values\n\t\tvoltageOut = (c_double*sample_count)()\n\n\t\t#Sample data, Mode: Synchronous\n\t\treadErr = ctypes.c_int16(self.dll.AI_ContReadChannel(\n\t\t\tc_ushort(self.card_id), \t\t\t\t\t\t\t\t#CardNumber\n\t\t\tc_ushort(channel),       \t\t\t\t\t\t#Channel\n\t\t\tc_ushort(adlink9812_constants.AD_B_1_V),\t\t#AdRange\n\t\t\tdataBuff,\t\t\t\t\t\t\t\t\t\t\t\t#Buffer\n\t\t\tc_uint32(sample_count),\t\t\t\t\t\t\t#ReadCount\n\t\t\tc_double(sample_freq),\t\t\t\t\t\t\t#SampleRate (Hz)\n\t\t\tc_ushort(adlink9812_constants.SYNCH_OP)\t\t\t#SyncMode\n\t\t))\n\n\t\tif readErr.value != 0:\n\t\t\tself.log(message=\"AI_ContReadChannel: Non-zero status code:\"+str(readErr.value))\n\n\t\t#Convert to volts\n\t\tself.convert_to_volts(dataBuff,voltageOut,sample_count)\n\t\treturn np.asarray(voltageOut)\n\n\tdef asynchronous_double_buffered_analog_input_read(self,sample_freq,sample_count,card_buffer_size = 500000,verbose=False, channel = 0):\n\t\t'''\n\t\tNon-Triggered Double-Buffered Asynchronous  Analog Input Continuous Read\n\t\tSteps: [Adlink PCIS-DASK manual,page 47]\n\n\t\t1. AI_XXXX_Config\n\t\t\tConfigure the card for the asynchronous mode\n\n\t\t2. AI_AsyncDblBufferMode \n\t\t\tEnable double buffered mode\n\n\t\t3. AI_ContReadChannel\n\t\t\tRead from a single channel (=0)\n\n\t\t4. while not stop:\n\n\t\t\t4.1 if (AI_AsyncDblBufferHaldReady):   #Check if buffer is half full]\n\t\t\t\t\n\t\t\t\t4.1.1 AI_AsyncDblBufferTransfer\t   #Transfer data from card buffer into user buffer\n\t\t\t\n\t\t5. AI_AsyncClear\n\t\t6. Convert all data to volts and return\n\n\t\t'''\n\t\t\n\t\t#AI_AsyncDblBufferMode - initialize Double Buffer Mode\n\t\tbuffModeErr = ctypes.c_int16(self.dll.AI_AsyncDblBufferMode(c_ushort(self.card_id),ctypes.c_bool(1)))\n\t\tif verbose or buffModeErr.value != 0:\n\t\t\tself.log(message=\"AI_AsyncDblBufferMode: Non-zero status code\"+str(buffModeErr.value))\n\n\t\t#card buffer\n\t\tcardBuffer = (c_ushort*card_buffer_size)()\n\n\t\t#user buffers\n\t\tuser_buffer_size = old_div(card_buffer_size,2) #half due to being full when buffer is read\n\t\tnbuff = int(math.ceil(sample_count/float(user_buffer_size)))\n\t\t\n\t\t# uBs = [(c_double*user_buffer_size)()]*nbuff\n\t\tuBs = []\n\t\tprint(uBs)\n\t\t# oBs = [(c_double*user_buffer_size)()]*nbuff\n\t\toBs = []\n\t\tif verbose:\n\t\t\tself.log(message=\"Number of user buffers:\"+str(nbuff))\n\n\t\t#AI_ContReadChanne\n\n\t\treadErr = ctypes.c_int16(self.dll.AI_ContReadChannel(\n\t\t\tc_ushort(self.card_id), \t\t\t\t\t#CardNumber\n\t\t\tc_ushort(channel),       \t\t\t#Channel\n\t\t\tc_ushort(adlink9812_constants.AD_B_1_V),\t\t#AdRange\n\t\t\tcardBuffer,\t\t\t\t\t\t\t\t\t#Buffer\n\t\t\tc_uint32(card_buffer_size),\t\t\t#ReadCount\n\t\t\tc_double(sample_freq),\t\t\t\t#SampleRate (Hz)\n\t\t\tc_ushort(adlink9812_constants.ASYNCH_OP)\t\t#SyncMode - Asynchronous\n\t\t))\n\n\t\tif verbose or readErr.value != 0:\n\t\t\tself.log(message=\"AI_ContReadChannel: Non-zero status code\"+str(readErr.value))\n\n\t\t#AI_AsyncDblBufferHalfReader\n\t\t#I16 AI_AsyncDblBufferHalfReady (U16 CardNumber, BOOLEAN *HalfReady,BOOLEAN *StopFlag)\n\t\t\n\t\tfor i in range(nbuff):\n\t\t\tcurrentBuffer = (c_double*user_buffer_size)()\n\t\t\thalfReady = c_bool(0)\n\t\t\tstopFlag = c_bool(0)\n\t\t\twhile halfReady.value != True:\n\t\t\t\tbuffReadyErr = ctypes.c_int16(self.dll.AI_AsyncDblBufferHalfReady(\n\t\t\t\t\tc_ushort(self.card_id),\n\t\t\t\t\tctypes.byref(halfReady),\n\t\t\t\t\tctypes.byref(stopFlag))\n\t\t\t\t)\n\t\t\t\tif buffReadyErr.value!=0:\n\t\t\t\t\tself.log(message=\"buffReadErr:\"+str(buffReadyErr.value))\n\t\t\t\t\tself.log(message=\"HalfReady:\"+str(halfReady.value))\n\t\t\n\t\t\t#AI_AsyncDblBufferTransfer\n\t\t\t#I16 AI_AsyncDblBufferTransfer (U16 CardNumber, U16 *Buffer)\n\t\t\tbuffTransferErr = ctypes.c_int16(self.dll.AI_AsyncDblBufferTransfer(c_ushort(self.card_id), ctypes.byref(currentBuffer)))\n\t\t\tuBs.append(currentBuffer)\n\t\t\tif buffTransferErr.value != 0:\n\t\t\t\tself.log(message=\"buffTransferErr:\"+str(buffTransferErr.value))\n\n\t\taccessCnt = ctypes.c_int32(0)\n\t\tclearErr = ctypes.c_int16(self.dll.AI_AsyncClear(self.card_id, ctypes.byref(accessCnt)))\n\t\tif verbose:\n\t\t\tself.log(message=\"AI_AsyncClear,AccessCnt:\"+str(accessCnt.value))\n\t\t\n\t\t#concatenate user buffer onto existing numpy array\n\t\t#reinitialize user buffer\n\n\t\tfor i in range(nbuff):\n\t\t\toB = (c_double*user_buffer_size)()\n\t\t\tconvertErr = ctypes.c_int16(self.dll.AI_ContVScale(\n\t\t\tc_ushort(self.card_id),\t\t\t\t#CardNumber\n\t\t\tc_ushort(adlink9812_constants.AD_B_1_V),\t#AdRange\n\t\t\tuBs[i], \t\t\t\t\t#DataBuffer   - array storing raw 16bit A/D values\n\t\t\toB, \t\t\t\t\t#VoltageArray - reference to array storing voltages\n\t\t\tc_uint32(user_buffer_size) \t\t\t#Sample count - number of samples to be converted\n\t\t\t))\n\t\t\toBs.append(oB)\n\t\t\tif convertErr.value != 0:\n\t\t\t\tself.log(message=\"AI_ContVScale: Non-zero status code:\"+str(convertErr.value))\n\t\treturn np.concatenate(oBs)\n\n\t@staticmethod\n\tdef get_times(dt,nsamples):\n\t\treturn [i*dt for i in range(nsamples)]\n\n\tdef capture(self,sample_freq, sample_count,verbose = False):\n\t\tassert(sample_freq <= int(2e7) and sample_freq > 1)\n\t\tdt = 1.0/sample_freq\n\t\tif self.debug:\n\t\t\t\n\t\t\tdebug_out = (2.0*np.random.rand(sample_count))-1.0 \n\t\t\treturn debug_out,dt\n\n\t\telif sample_count > 100000:\n\t\t\treturn self.asynchronous_double_buffered_analog_input_read(sample_freq= sample_freq,sample_count = sample_count,verbose = verbose),dt\n\t\telse:\n\t\t\treturn self.synchronous_analog_input_read(sample_freq= sample_freq,sample_count = sample_count,verbose = verbose),dt",
  "class Adlink9812UI(QtWidgets.QWidget, UiTools):\n\tdef __init__(self,card, parent=None,debug = False, verbose = False):\n\t\tif not isinstance(card, Adlink9812):\n\t\t\traise ValueError(\"Object is not an instance of the Adlink9812 Daq\")\n\t\tsuper(Adlink9812UI, self).__init__()\n\t\tself.card = card \n\t\tself.parent = parent\n\t\tself.debug = debug\n\t\tself.verbose = verbose\n\t\tself.log = self.card.log\n\n\t\t#Initialize the capture thread handle\n\t\tself.capture_thread = None\n\n\t\tuic.loadUi(os.path.join(os.path.dirname(__file__), 'adlink9812.ui'), self)\n\n\t\t#daq_settings_layout\n\t\tself.sample_freq_textbox.textChanged.connect(self.set_sample_freq)\n\t\tself.sample_count_textbox.textChanged.connect(self.set_sample_count)\n\t\tself.series_name_textbox.textChanged.connect(self.set_series_name)\n\t\t\n\t\t#processing_stages_layout\n\t\t# self.threshold_textbox.textChanged.connect(self.set_threshold)\n\t\tself.binning_textbox.textChanged.connect(self.set_bin_width)\n\t\tself.average_textbox.textChanged.connect(self.set_averaging)\n\n\n\t\t#actions_layout\n\t\tself.capture_button.clicked.connect(self.threaded_capture)\n\t\tself.count_rate_button.clicked.connect(self.current_count_rate)\n\n\t\tself.set_sample_freq()\n\t\tself.set_sample_count()\n\t\tself.set_series_name()\n\t\tself.set_bin_width()\n\t\tself.set_averaging()\n\t\t# self.set_threshold()\n\t\n\tdef set_averaging(self):\n\t\ttry:\n\t\t\tself.averaging_runs = int(self.average_textbox.text())\n\t\texcept:\n\t\t\tself.log(message=\"Failed parsing average_textbox value: {0}\".format(self.average_textbox.text()))\n\t\treturn\n\n\t# def set_threshold(self):\n\t# \ttry:\n\t# \t\tself.difference_threshold = float(self.threshold_textbox.text())\n\t# \texcept Exception, e:\n\t# \t\tprint \"Failed parsing threshold_textbox value: {0}\".format(self.threshold_textbox.text())\n\t# \treturn\n\n\tdef set_bin_width(self):\n\t\ttry:\n\t\t\tself.bin_width = float(self.binning_textbox.text())\n\t\texcept Exception as e:\n\t\t\tself.log(message=\"Failed parsing binning_threshold: {0}\".format(self.binning_textbox.text()))\n\t\treturn\n\n\tdef set_sample_freq(self):\n\t\tMHz = 1e6\n\t\ttry:\n\t\t\tself.sample_freq = int(float(self.sample_freq_textbox.text())*MHz)\n\t\texcept Exception as e:\n\t\t\tself.log(message=\"Failed parsing sample_freq_textbox value to float:\"+str(self.sample_freq_textbox.text()))\n\t\t\treturn\n\t\treturn\n\n\tdef set_sample_count(self):\n\t\ttry:\n\n\n\t\t\tself.sample_count = int(float(self.sample_count_textbox.text()))\n\t\t\tif self.verbose>0:\n\t\t\t\tprint(\"Sample Count: {0} [Counts]\".format(self.sample_count))\n\n\t\t\tself.sample_count = int(float(self.sample_count_textbox.text()))\n\n\t\texcept Exception as e:\n\t\t\tself.log(message=\"Failed parsing sample count to int:\"+self.sample_freq_textbox.text())\n\t\treturn\n\n\tdef set_series_name(self):\n\t\tself.series_group = self.series_name_textbox.text()\n\t\treturn\n\n\tdef save_data(self,data,datatype, group,metadata=None):\n\t\tVALID_DATATYPES = [\"raw_voltage\", \"voltage_difference\", \"photon_counts\", \"autocorrelation\",\"autocorrelation_stdev\",\"autocorrelation_skew\"]\n\n\t\tattrs = {\"device\": \"adlink9812\",\"datatype\":datatype}\n\t\t#push additional metadata\n\t\tif metadata != None:\n\t\t\tattrs.update(metadata) \n\t\tassert(datatype in VALID_DATATYPES)\n\t\tif datatype == \"raw_voltage\":\n\t\t\tattrs.update({\"_units\": \"volts\",\"X label\": \"Sample Index\",\"Y label\": \"Voltage [V]\"})\n\t\telif datatype == \"voltage_difference\":\n\t\t\tattrs.update({\"_units\": \"none\",\"X label\": \"Sample Index\",\"Y label\": \"Normalized Voltage Difference [V]\"\t})\n\t\telif datatype == \"photon_counts\":\n\t\t\tattrs.update({\"_units\": \"count\",\"X label\": \"Time [s]\",\"Y label\": \"Photon Count\"})\n\t\telif datatype == \"autocorrelation\":\n\t\t\tattrs.update({\"_units\": \"none\",\"X label\": \"Time [s]\",\"Y label\": \"Intensity Autocorrelation g2 [no units]\"})\n\t\telif datatype == \"autocorrelation_stdev\":\n\t\t\tattrs.update({\"_units\": \"none\",\"X label\": \"Time [s]\",\"Y label\": \"Autocorrelation Stdev [no units]\"})\n\t\telif datatype == \"autocorrelation_skew\":\n\t\t\tattrs.update({\"_units\": \"none\",\"X label\": \"Time [s]\",\"Y label\": \"Autocorrelation skew [no units]\"})\n\t\t\t\n\t\telse:\n\t\t\traise ValueError(\"adlink9812.save_data - Invalid datatype\")\n\t\tgroup.create_dataset(datatype+\"_%d\",data=data, attrs = attrs)\n\t\tgroup.file.flush()\n\t\treturn \n\n\tdef postprocess(self,voltages,dt,save,group,metadata):\n\n\t\tattributes = dict(metadata)\n\n\n\t\t#initial system parameters\n\t\tsample_count = len(voltages)\n\t\tsample_time = dt*sample_count\n\n\t\t#take difference of voltages\n\t\trounded_diff = dls_signal_postprocessing.signal_diff(voltages)\n\t\t\n\t\t#thresholding\n\t\tthresholded = np.absolute(rounded_diff).astype(int)\n\n\t\t#binning\n\t\ttime_bin_width = self.bin_width\n\t\tindex_bin_width = dls_signal_postprocessing.binwidth_time_to_index(time_bin_width,dt)\n\t\tbinned_counts = dls_signal_postprocessing.binning(thresholded=thresholded,index_bin_width=index_bin_width)\n\t\ttime_bins = time_bin_width*np.arange(0,len(binned_counts))\n\n\t\ttotal_counts = np.sum(binned_counts)\n\t\tcount_rate = float(total_counts)/float(sample_time)\n\t\tself.log(\"\\tCounts: {0:.3g}, Rate:{1:.3g}\".format(total_counts, count_rate))\n\t\t#correlation\n\t\t#note - truncating delay t=0, this is the zero frequency - not interesting\n\t\ttimes = time_bins[1:]\n\t\tautocorrelation = dls_signal_postprocessing.autocorrelation(binned_counts)[1:]\n\n\t\t#save data\n\t\tattributes.update({\"averaged_data\": \"False\"})\n\t\tstages = [\n\t\t(\"raw_voltage\", self.raw_checkbox.isChecked(), voltages,attributes),\n\t\t(\"voltage_difference\", self.difference_checkbox.isChecked(), rounded_diff,attributes),\n\t\t(\"photon_counts\", self.binning_checkbox.isChecked(), np.vstack((time_bins,binned_counts)),attributes),\n\t\t(\"autocorrelation\", self.correlate_checkbox.isChecked(), np.vstack((times, autocorrelation)),attributes)\n\t\t]\n\t\tfor (datatype, checked, data,mdata) in stages:\n\t\t\tif save == True and checked == True:\n\t\t\t\tself.save_data(datatype=datatype,data=data, group=group,metadata=mdata)\n\t\treturn times, autocorrelation\n\n\n\tdef current_count_rate(self):\n\t\t#measure for 0.05s for sampling photon count\n\n\t\t#fixed values of sampling - we want to keep things easy\n\t\tfrequency = 2e7 #20MHz\n\t\tsample_count = int(1e6) #0.05s  \n\t\tvoltages, dt = self.card.capture(sample_freq=frequency, sample_count=sample_count)\n\t\tsample_time = dt*sample_count\n\t\t#convert rounded difference to integers\n\t\tthresholded = np.absolute(dls_signal_postprocessing.signal_diff(voltages)).astype(int)\n\t\ttotal_counts = np.sum(thresholded)\n\t\tcount_rate = old_div(total_counts,sample_time)\n\t\tself.log(\"Total Counts: {0} [counts], Rate: {1} [counts/s]\".format(int(total_counts), count_rate))\n\t\treturn total_counts, count_rate \n\n\n\tdef capture(self,metadata=None):\n\t\t\n\t\tsave = self.save_checkbox.isChecked()\n\t\tplot = self.plot_checkbox.isChecked()\n\t\taverage = self.average_checkbox.isChecked()\n\n\t\tmessage = '''\n Capture started\n SamplingFreq (Hz):{0}\n SampleCount (counts):{1}\n SeriesName:{2}\n Plot trace:{3}\n Save trace:{4}\n Averaging:{5}'''.format(self.sample_freq,self.sample_count, self.series_group, plot,save,average)\n\t\tself.log(message=message,level=\"info\")\n\n\t\tif save:\n\t\t\ttry:\n\t\t\t\tself.datafile\n\t\t\texcept AttributeError:\n\t\t\t\tself.datafile = nplab.datafile.current()\n\t\t\tdg = self.datafile.require_group(self.series_group)\n\t\telse:\n\t\t\tdg = None\n\t\t\n\t\tself.description = self.comment_textbox.document().toPlainText()\n\t\tself.log(message=\"Description:{}\".format(self.description))\n\n\t\tif metadata is not None and type(metadata) == dict:\n\t\t\tself.base_metadata = metadata\n\t\telse:\n\t\t\tself.base_metadata = dict()\n\t\tself.base_metadata.update({\"description\":self.description})\n\n\t\t#Averaging run:\n\t\tif average == False:\n\t\t\tvoltages, dt = self.card.capture(sample_freq=self.sample_freq, sample_count=self.sample_count)\n\t\t\ttimes, autocorrelation = self.postprocess(voltages= voltages,dt=dt, save=save, group = dg,metadata=self.base_metadata)\n\t\t\tacs_array = None  \n\t\telif average == True:\n\t\t\tself.log(\n\t\t\t\tmessage='''Averaging enabled - checkbox options reset:\\n\\traw_checkbox:{0} -> False\\n\\tdifference_checkbox {1} -> False\\n\\tbinning_checkbox {2} -> False'''.format(\n\t\t\t\t\tself.raw_checkbox.isChecked(),\n\t\t\t\t\tself.difference_checkbox.isChecked(),\n\t\t\t\t\tself.binning_checkbox.isChecked()),\n\t\t\t\tlevel=\"warn\")\n\t\t\tself.raw_checkbox.setChecked(False)\n\t\t\tself.difference_checkbox.setChecked(False)\n\t\t\tself.binning_checkbox.setChecked(False)\n\n\t\t\tacs_array = None\n\t\t\tfor i in range(self.averaging_runs):\n\t\t\t\tstart_time = timeit.default_timer()\n\t\n\t\t\t\tself.card.log(message=\"---Iteration:{0}\".format(i))\n\n\t\t\t\tvoltages, dt = self.card.capture(sample_freq=self.sample_freq, sample_count=self.sample_count)\n\t\t\t\ttimes, autocorrelation = self.postprocess(voltages= voltages,dt=dt, save=save, group = dg,metadata=self.base_metadata)\n\t\t\t\t\n\t\t\t\tif acs_array is None:\n\t\t\t\t\tacs_array = np.zeros(shape=(self.averaging_runs, len(autocorrelation)),dtype=np.float32)\n\t\t\t\t\n\t\t\t\tacs_array[i,:] = autocorrelation\n\n\t\t\t\texec_time =timeit.default_timer() - start_time\n\t\t\t\tself.log(message=\"/--Iteration:{0} [T_exec:{1:.3g}]\".format(i,exec_time))\n\t\t\t#compute mean, stdev and skew for all data\n\t\t\tmean_acs = np.mean(acs_array,axis=0)\n\t\t\tassert(len(mean_acs) == len(times))\n\t\t\tstdev_acs = np.std(acs_array,axis=0)\n\t\t\tskew_acs = scipy.stats.skew(acs_array,axis=0)\n\n\n\t\t\taveraged_metadata=dict(self.base_metadata)\n\t\t\taveraged_metadata.update({\"averaged_data\": \"True\"})\n\t\t\tself.save_data(data=np.vstack((times, mean_acs)),datatype=\"autocorrelation\", group=dg,metadata=averaged_metadata)\n\t\t\tself.save_data(data=np.vstack((times, stdev_acs)),datatype=\"autocorrelation_stdev\", group=dg,metadata=averaged_metadata)\n\t\t\tself.save_data(data=np.vstack((times, skew_acs)),datatype=\"autocorrelation_skew\", group=dg,metadata=averaged_metadata)\n\n\t\treturn \n\n\tdef threaded_capture(self,settings=None):\n\t\tif isinstance(self.capture_thread, threading.Thread) and self.capture_thread.is_alive():\n\t\t\tself.card.log(message=\"Capture already running!\", level=\"info\")\n\t\t\treturn\n\t\tself.capture_thread = threading.Thread(target=self.capture,args=(settings,))\n\t\tself.capture_thread.start()",
  "def __init__(self, dll_path=\"C:\\ADLINK\\PCIS-DASK\\Lib\\PCI-Dask64.dll\",verbose=False,debug=False):\n\t\t\"\"\"Initialize DLL and configure card\"\"\"\n\t\tsuper(Adlink9812,self).__init__()\n\t\tself.debug = debug\n\t\tif self.debug:\n\t\t\tself.log(message=\"Instrument.Adlink9812: DEBUG MODE\")\n\t\tif not os.path.exists(dll_path):\n\t\t\tif self.debug != True:\n\t\t\t\tmessage= \"Adlink DLL not found: {}\".format(dll_path)\n\t\t\t\tself.log(message=message)\n\t\t\t\traise ValueError(message)\n\t\telse:\n\t\t\tself.dll = CDLL(dll_path)\n\t\t\tself.card_id = self.register_card()\n\t\t\tself.configure_card()\n\n\t\tself.ui = None",
  "def __del__(self):\n\t\t'''Deregister the card on object deletion'''\n\t\tself.release_card()",
  "def get_qt_ui(self):\n\t\tif self.ui is None:\n\t\t\tself.ui = Adlink9812UI(card=self)\n\t\treturn self.ui",
  "def register_card(self,channel = 0):\n\t\toutp = ctypes.c_int16(self.dll.Register_Card(adlink9812_constants.PCI_9812,c_ushort(channel)))\n\t\tif outp.value < 0:\n\t\t\tself.log(\"Register_Card: nonpositive value -> error code:\"+str(outp))\n\t\treturn outp.value",
  "def release_card(self):\n\t\treleaseErr = ctypes.c_int16(self.dll.Release_Card(self.card_id))\n\t\tif releaseErr.value != 0:\n\t\t\tself.log(message=\"Release_Card: Non-zero status code:\"+str(releaseErr.value))\n\t\treturn",
  "def get_card_sample_rate(self,sampling_freq):\n\t\tactual = c_double()\n\t\tstatusCode = ctypes.c_int16(DLL.GetActualRate(self.card_id,c_double(sampling_freq), byref(actual)))\n\n\t\tif statusCode.value != 0:\n\t\t\tself.log(message=\"GetActualRate: Non-zero status code:\"+str(statusCode.value))\n\t\treturn actual.value",
  "def configure_card(self):\n\t\t#Configure card for recording\n\t\tconfigErr = ctypes.c_int16(self.dll.AI_9812_Config(\n\t\t\tc_ushort(self.card_id),\n\t\t\tc_ushort(adlink9812_constants.P9812_TRGMOD_SOFT), #Software trigger mode\n\t\t\tc_ushort(adlink9812_constants.P9812_TRGSRC_CH0),  #Channel 0 \n\t\t\tc_ushort(adlink9812_constants.P9812_TRGSLP_POS),  #Positive edge trigger\n\t\t\tc_ushort(adlink9812_constants.P9812_CLKSRC_INT),  #Internal clock\n\t\t\tc_ushort(0x80), \t\t\t\t\t\t\t\t  #Trigger threshold = 0.00V\n\t\t\tc_ushort(0),\t\t\t\t\t\t\t\t\t\t#Postcount - setting for Middle/Delay Trigger\n\t\t\t))\n\n\t\tif configErr.value != 0:\n\t\t\tself.log(message=\"AI_9812_Config: Non-zero status code:\"+str(configErr.value))\n\t\treturn",
  "def convert_to_volts(self,inputBuffer, outputBuffer, buffer_size):\n\t\tconvertErr = ctypes.c_int16(self.dll.AI_ContVScale(\n\t\t\t\tc_ushort(self.card_id),\t\t\t\t\t\t\t#CardNumber\n\t\t\t\tc_ushort(adlink9812_constants.AD_B_1_V),\t\t#AdRange\n\t\t\t\tinputBuffer, \t\t\t\t\t\t\t\t\t#DataBuffer   - array storing raw 16bit A/D values\n\t\t\t\toutputBuffer, \t\t\t\t\t\t\t\t\t#VoltageArray - reference to array storing voltages\n\t\t\t\tc_uint32(buffer_size) \t\t\t\t\t\t\t#Sample count - number of samples to be converted\n\t\t\t))\n\n\t\tif convertErr.value != 0:\n\t\t\tself.log(message=\"AI_ContVScale: Non-zero status code:\"+str(convertErr.value))\n\t\treturn",
  "def synchronous_analog_input_read(self,sample_freq, sample_count,verbose = False,channel=0):\n\t\t#Initialize Buffers\n\t\t#databuffer for holding A/D samples + metadata bits\n\t\tdataBuff = (c_ushort*sample_count)()\n\t\t#voltageArray for holding converted voltage values\n\t\tvoltageOut = (c_double*sample_count)()\n\n\t\t#Sample data, Mode: Synchronous\n\t\treadErr = ctypes.c_int16(self.dll.AI_ContReadChannel(\n\t\t\tc_ushort(self.card_id), \t\t\t\t\t\t\t\t#CardNumber\n\t\t\tc_ushort(channel),       \t\t\t\t\t\t#Channel\n\t\t\tc_ushort(adlink9812_constants.AD_B_1_V),\t\t#AdRange\n\t\t\tdataBuff,\t\t\t\t\t\t\t\t\t\t\t\t#Buffer\n\t\t\tc_uint32(sample_count),\t\t\t\t\t\t\t#ReadCount\n\t\t\tc_double(sample_freq),\t\t\t\t\t\t\t#SampleRate (Hz)\n\t\t\tc_ushort(adlink9812_constants.SYNCH_OP)\t\t\t#SyncMode\n\t\t))\n\n\t\tif readErr.value != 0:\n\t\t\tself.log(message=\"AI_ContReadChannel: Non-zero status code:\"+str(readErr.value))\n\n\t\t#Convert to volts\n\t\tself.convert_to_volts(dataBuff,voltageOut,sample_count)\n\t\treturn np.asarray(voltageOut)",
  "def asynchronous_double_buffered_analog_input_read(self,sample_freq,sample_count,card_buffer_size = 500000,verbose=False, channel = 0):\n\t\t'''\n\t\tNon-Triggered Double-Buffered Asynchronous  Analog Input Continuous Read\n\t\tSteps: [Adlink PCIS-DASK manual,page 47]\n\n\t\t1. AI_XXXX_Config\n\t\t\tConfigure the card for the asynchronous mode\n\n\t\t2. AI_AsyncDblBufferMode \n\t\t\tEnable double buffered mode\n\n\t\t3. AI_ContReadChannel\n\t\t\tRead from a single channel (=0)\n\n\t\t4. while not stop:\n\n\t\t\t4.1 if (AI_AsyncDblBufferHaldReady):   #Check if buffer is half full]\n\t\t\t\t\n\t\t\t\t4.1.1 AI_AsyncDblBufferTransfer\t   #Transfer data from card buffer into user buffer\n\t\t\t\n\t\t5. AI_AsyncClear\n\t\t6. Convert all data to volts and return\n\n\t\t'''\n\t\t\n\t\t#AI_AsyncDblBufferMode - initialize Double Buffer Mode\n\t\tbuffModeErr = ctypes.c_int16(self.dll.AI_AsyncDblBufferMode(c_ushort(self.card_id),ctypes.c_bool(1)))\n\t\tif verbose or buffModeErr.value != 0:\n\t\t\tself.log(message=\"AI_AsyncDblBufferMode: Non-zero status code\"+str(buffModeErr.value))\n\n\t\t#card buffer\n\t\tcardBuffer = (c_ushort*card_buffer_size)()\n\n\t\t#user buffers\n\t\tuser_buffer_size = old_div(card_buffer_size,2) #half due to being full when buffer is read\n\t\tnbuff = int(math.ceil(sample_count/float(user_buffer_size)))\n\t\t\n\t\t# uBs = [(c_double*user_buffer_size)()]*nbuff\n\t\tuBs = []\n\t\tprint(uBs)\n\t\t# oBs = [(c_double*user_buffer_size)()]*nbuff\n\t\toBs = []\n\t\tif verbose:\n\t\t\tself.log(message=\"Number of user buffers:\"+str(nbuff))\n\n\t\t#AI_ContReadChanne\n\n\t\treadErr = ctypes.c_int16(self.dll.AI_ContReadChannel(\n\t\t\tc_ushort(self.card_id), \t\t\t\t\t#CardNumber\n\t\t\tc_ushort(channel),       \t\t\t#Channel\n\t\t\tc_ushort(adlink9812_constants.AD_B_1_V),\t\t#AdRange\n\t\t\tcardBuffer,\t\t\t\t\t\t\t\t\t#Buffer\n\t\t\tc_uint32(card_buffer_size),\t\t\t#ReadCount\n\t\t\tc_double(sample_freq),\t\t\t\t#SampleRate (Hz)\n\t\t\tc_ushort(adlink9812_constants.ASYNCH_OP)\t\t#SyncMode - Asynchronous\n\t\t))\n\n\t\tif verbose or readErr.value != 0:\n\t\t\tself.log(message=\"AI_ContReadChannel: Non-zero status code\"+str(readErr.value))\n\n\t\t#AI_AsyncDblBufferHalfReader\n\t\t#I16 AI_AsyncDblBufferHalfReady (U16 CardNumber, BOOLEAN *HalfReady,BOOLEAN *StopFlag)\n\t\t\n\t\tfor i in range(nbuff):\n\t\t\tcurrentBuffer = (c_double*user_buffer_size)()\n\t\t\thalfReady = c_bool(0)\n\t\t\tstopFlag = c_bool(0)\n\t\t\twhile halfReady.value != True:\n\t\t\t\tbuffReadyErr = ctypes.c_int16(self.dll.AI_AsyncDblBufferHalfReady(\n\t\t\t\t\tc_ushort(self.card_id),\n\t\t\t\t\tctypes.byref(halfReady),\n\t\t\t\t\tctypes.byref(stopFlag))\n\t\t\t\t)\n\t\t\t\tif buffReadyErr.value!=0:\n\t\t\t\t\tself.log(message=\"buffReadErr:\"+str(buffReadyErr.value))\n\t\t\t\t\tself.log(message=\"HalfReady:\"+str(halfReady.value))\n\t\t\n\t\t\t#AI_AsyncDblBufferTransfer\n\t\t\t#I16 AI_AsyncDblBufferTransfer (U16 CardNumber, U16 *Buffer)\n\t\t\tbuffTransferErr = ctypes.c_int16(self.dll.AI_AsyncDblBufferTransfer(c_ushort(self.card_id), ctypes.byref(currentBuffer)))\n\t\t\tuBs.append(currentBuffer)\n\t\t\tif buffTransferErr.value != 0:\n\t\t\t\tself.log(message=\"buffTransferErr:\"+str(buffTransferErr.value))\n\n\t\taccessCnt = ctypes.c_int32(0)\n\t\tclearErr = ctypes.c_int16(self.dll.AI_AsyncClear(self.card_id, ctypes.byref(accessCnt)))\n\t\tif verbose:\n\t\t\tself.log(message=\"AI_AsyncClear,AccessCnt:\"+str(accessCnt.value))\n\t\t\n\t\t#concatenate user buffer onto existing numpy array\n\t\t#reinitialize user buffer\n\n\t\tfor i in range(nbuff):\n\t\t\toB = (c_double*user_buffer_size)()\n\t\t\tconvertErr = ctypes.c_int16(self.dll.AI_ContVScale(\n\t\t\tc_ushort(self.card_id),\t\t\t\t#CardNumber\n\t\t\tc_ushort(adlink9812_constants.AD_B_1_V),\t#AdRange\n\t\t\tuBs[i], \t\t\t\t\t#DataBuffer   - array storing raw 16bit A/D values\n\t\t\toB, \t\t\t\t\t#VoltageArray - reference to array storing voltages\n\t\t\tc_uint32(user_buffer_size) \t\t\t#Sample count - number of samples to be converted\n\t\t\t))\n\t\t\toBs.append(oB)\n\t\t\tif convertErr.value != 0:\n\t\t\t\tself.log(message=\"AI_ContVScale: Non-zero status code:\"+str(convertErr.value))\n\t\treturn np.concatenate(oBs)",
  "def get_times(dt,nsamples):\n\t\treturn [i*dt for i in range(nsamples)]",
  "def capture(self,sample_freq, sample_count,verbose = False):\n\t\tassert(sample_freq <= int(2e7) and sample_freq > 1)\n\t\tdt = 1.0/sample_freq\n\t\tif self.debug:\n\t\t\t\n\t\t\tdebug_out = (2.0*np.random.rand(sample_count))-1.0 \n\t\t\treturn debug_out,dt\n\n\t\telif sample_count > 100000:\n\t\t\treturn self.asynchronous_double_buffered_analog_input_read(sample_freq= sample_freq,sample_count = sample_count,verbose = verbose),dt\n\t\telse:\n\t\t\treturn self.synchronous_analog_input_read(sample_freq= sample_freq,sample_count = sample_count,verbose = verbose),dt",
  "def __init__(self,card, parent=None,debug = False, verbose = False):\n\t\tif not isinstance(card, Adlink9812):\n\t\t\traise ValueError(\"Object is not an instance of the Adlink9812 Daq\")\n\t\tsuper(Adlink9812UI, self).__init__()\n\t\tself.card = card \n\t\tself.parent = parent\n\t\tself.debug = debug\n\t\tself.verbose = verbose\n\t\tself.log = self.card.log\n\n\t\t#Initialize the capture thread handle\n\t\tself.capture_thread = None\n\n\t\tuic.loadUi(os.path.join(os.path.dirname(__file__), 'adlink9812.ui'), self)\n\n\t\t#daq_settings_layout\n\t\tself.sample_freq_textbox.textChanged.connect(self.set_sample_freq)\n\t\tself.sample_count_textbox.textChanged.connect(self.set_sample_count)\n\t\tself.series_name_textbox.textChanged.connect(self.set_series_name)\n\t\t\n\t\t#processing_stages_layout\n\t\t# self.threshold_textbox.textChanged.connect(self.set_threshold)\n\t\tself.binning_textbox.textChanged.connect(self.set_bin_width)\n\t\tself.average_textbox.textChanged.connect(self.set_averaging)\n\n\n\t\t#actions_layout\n\t\tself.capture_button.clicked.connect(self.threaded_capture)\n\t\tself.count_rate_button.clicked.connect(self.current_count_rate)\n\n\t\tself.set_sample_freq()\n\t\tself.set_sample_count()\n\t\tself.set_series_name()\n\t\tself.set_bin_width()\n\t\tself.set_averaging()",
  "def set_averaging(self):\n\t\ttry:\n\t\t\tself.averaging_runs = int(self.average_textbox.text())\n\t\texcept:\n\t\t\tself.log(message=\"Failed parsing average_textbox value: {0}\".format(self.average_textbox.text()))\n\t\treturn",
  "def set_bin_width(self):\n\t\ttry:\n\t\t\tself.bin_width = float(self.binning_textbox.text())\n\t\texcept Exception as e:\n\t\t\tself.log(message=\"Failed parsing binning_threshold: {0}\".format(self.binning_textbox.text()))\n\t\treturn",
  "def set_sample_freq(self):\n\t\tMHz = 1e6\n\t\ttry:\n\t\t\tself.sample_freq = int(float(self.sample_freq_textbox.text())*MHz)\n\t\texcept Exception as e:\n\t\t\tself.log(message=\"Failed parsing sample_freq_textbox value to float:\"+str(self.sample_freq_textbox.text()))\n\t\t\treturn\n\t\treturn",
  "def set_sample_count(self):\n\t\ttry:\n\n\n\t\t\tself.sample_count = int(float(self.sample_count_textbox.text()))\n\t\t\tif self.verbose>0:\n\t\t\t\tprint(\"Sample Count: {0} [Counts]\".format(self.sample_count))\n\n\t\t\tself.sample_count = int(float(self.sample_count_textbox.text()))\n\n\t\texcept Exception as e:\n\t\t\tself.log(message=\"Failed parsing sample count to int:\"+self.sample_freq_textbox.text())\n\t\treturn",
  "def set_series_name(self):\n\t\tself.series_group = self.series_name_textbox.text()\n\t\treturn",
  "def save_data(self,data,datatype, group,metadata=None):\n\t\tVALID_DATATYPES = [\"raw_voltage\", \"voltage_difference\", \"photon_counts\", \"autocorrelation\",\"autocorrelation_stdev\",\"autocorrelation_skew\"]\n\n\t\tattrs = {\"device\": \"adlink9812\",\"datatype\":datatype}\n\t\t#push additional metadata\n\t\tif metadata != None:\n\t\t\tattrs.update(metadata) \n\t\tassert(datatype in VALID_DATATYPES)\n\t\tif datatype == \"raw_voltage\":\n\t\t\tattrs.update({\"_units\": \"volts\",\"X label\": \"Sample Index\",\"Y label\": \"Voltage [V]\"})\n\t\telif datatype == \"voltage_difference\":\n\t\t\tattrs.update({\"_units\": \"none\",\"X label\": \"Sample Index\",\"Y label\": \"Normalized Voltage Difference [V]\"\t})\n\t\telif datatype == \"photon_counts\":\n\t\t\tattrs.update({\"_units\": \"count\",\"X label\": \"Time [s]\",\"Y label\": \"Photon Count\"})\n\t\telif datatype == \"autocorrelation\":\n\t\t\tattrs.update({\"_units\": \"none\",\"X label\": \"Time [s]\",\"Y label\": \"Intensity Autocorrelation g2 [no units]\"})\n\t\telif datatype == \"autocorrelation_stdev\":\n\t\t\tattrs.update({\"_units\": \"none\",\"X label\": \"Time [s]\",\"Y label\": \"Autocorrelation Stdev [no units]\"})\n\t\telif datatype == \"autocorrelation_skew\":\n\t\t\tattrs.update({\"_units\": \"none\",\"X label\": \"Time [s]\",\"Y label\": \"Autocorrelation skew [no units]\"})\n\t\t\t\n\t\telse:\n\t\t\traise ValueError(\"adlink9812.save_data - Invalid datatype\")\n\t\tgroup.create_dataset(datatype+\"_%d\",data=data, attrs = attrs)\n\t\tgroup.file.flush()\n\t\treturn",
  "def postprocess(self,voltages,dt,save,group,metadata):\n\n\t\tattributes = dict(metadata)\n\n\n\t\t#initial system parameters\n\t\tsample_count = len(voltages)\n\t\tsample_time = dt*sample_count\n\n\t\t#take difference of voltages\n\t\trounded_diff = dls_signal_postprocessing.signal_diff(voltages)\n\t\t\n\t\t#thresholding\n\t\tthresholded = np.absolute(rounded_diff).astype(int)\n\n\t\t#binning\n\t\ttime_bin_width = self.bin_width\n\t\tindex_bin_width = dls_signal_postprocessing.binwidth_time_to_index(time_bin_width,dt)\n\t\tbinned_counts = dls_signal_postprocessing.binning(thresholded=thresholded,index_bin_width=index_bin_width)\n\t\ttime_bins = time_bin_width*np.arange(0,len(binned_counts))\n\n\t\ttotal_counts = np.sum(binned_counts)\n\t\tcount_rate = float(total_counts)/float(sample_time)\n\t\tself.log(\"\\tCounts: {0:.3g}, Rate:{1:.3g}\".format(total_counts, count_rate))\n\t\t#correlation\n\t\t#note - truncating delay t=0, this is the zero frequency - not interesting\n\t\ttimes = time_bins[1:]\n\t\tautocorrelation = dls_signal_postprocessing.autocorrelation(binned_counts)[1:]\n\n\t\t#save data\n\t\tattributes.update({\"averaged_data\": \"False\"})\n\t\tstages = [\n\t\t(\"raw_voltage\", self.raw_checkbox.isChecked(), voltages,attributes),\n\t\t(\"voltage_difference\", self.difference_checkbox.isChecked(), rounded_diff,attributes),\n\t\t(\"photon_counts\", self.binning_checkbox.isChecked(), np.vstack((time_bins,binned_counts)),attributes),\n\t\t(\"autocorrelation\", self.correlate_checkbox.isChecked(), np.vstack((times, autocorrelation)),attributes)\n\t\t]\n\t\tfor (datatype, checked, data,mdata) in stages:\n\t\t\tif save == True and checked == True:\n\t\t\t\tself.save_data(datatype=datatype,data=data, group=group,metadata=mdata)\n\t\treturn times, autocorrelation",
  "def current_count_rate(self):\n\t\t#measure for 0.05s for sampling photon count\n\n\t\t#fixed values of sampling - we want to keep things easy\n\t\tfrequency = 2e7 #20MHz\n\t\tsample_count = int(1e6) #0.05s  \n\t\tvoltages, dt = self.card.capture(sample_freq=frequency, sample_count=sample_count)\n\t\tsample_time = dt*sample_count\n\t\t#convert rounded difference to integers\n\t\tthresholded = np.absolute(dls_signal_postprocessing.signal_diff(voltages)).astype(int)\n\t\ttotal_counts = np.sum(thresholded)\n\t\tcount_rate = old_div(total_counts,sample_time)\n\t\tself.log(\"Total Counts: {0} [counts], Rate: {1} [counts/s]\".format(int(total_counts), count_rate))\n\t\treturn total_counts, count_rate",
  "def capture(self,metadata=None):\n\t\t\n\t\tsave = self.save_checkbox.isChecked()\n\t\tplot = self.plot_checkbox.isChecked()\n\t\taverage = self.average_checkbox.isChecked()\n\n\t\tmessage = '''\n Capture started\n SamplingFreq (Hz):{0}\n SampleCount (counts):{1}\n SeriesName:{2}\n Plot trace:{3}\n Save trace:{4}\n Averaging:{5}'''.format(self.sample_freq,self.sample_count, self.series_group, plot,save,average)\n\t\tself.log(message=message,level=\"info\")\n\n\t\tif save:\n\t\t\ttry:\n\t\t\t\tself.datafile\n\t\t\texcept AttributeError:\n\t\t\t\tself.datafile = nplab.datafile.current()\n\t\t\tdg = self.datafile.require_group(self.series_group)\n\t\telse:\n\t\t\tdg = None\n\t\t\n\t\tself.description = self.comment_textbox.document().toPlainText()\n\t\tself.log(message=\"Description:{}\".format(self.description))\n\n\t\tif metadata is not None and type(metadata) == dict:\n\t\t\tself.base_metadata = metadata\n\t\telse:\n\t\t\tself.base_metadata = dict()\n\t\tself.base_metadata.update({\"description\":self.description})\n\n\t\t#Averaging run:\n\t\tif average == False:\n\t\t\tvoltages, dt = self.card.capture(sample_freq=self.sample_freq, sample_count=self.sample_count)\n\t\t\ttimes, autocorrelation = self.postprocess(voltages= voltages,dt=dt, save=save, group = dg,metadata=self.base_metadata)\n\t\t\tacs_array = None  \n\t\telif average == True:\n\t\t\tself.log(\n\t\t\t\tmessage='''Averaging enabled - checkbox options reset:\\n\\traw_checkbox:{0} -> False\\n\\tdifference_checkbox {1} -> False\\n\\tbinning_checkbox {2} -> False'''.format(\n\t\t\t\t\tself.raw_checkbox.isChecked(),\n\t\t\t\t\tself.difference_checkbox.isChecked(),\n\t\t\t\t\tself.binning_checkbox.isChecked()),\n\t\t\t\tlevel=\"warn\")\n\t\t\tself.raw_checkbox.setChecked(False)\n\t\t\tself.difference_checkbox.setChecked(False)\n\t\t\tself.binning_checkbox.setChecked(False)\n\n\t\t\tacs_array = None\n\t\t\tfor i in range(self.averaging_runs):\n\t\t\t\tstart_time = timeit.default_timer()\n\t\n\t\t\t\tself.card.log(message=\"---Iteration:{0}\".format(i))\n\n\t\t\t\tvoltages, dt = self.card.capture(sample_freq=self.sample_freq, sample_count=self.sample_count)\n\t\t\t\ttimes, autocorrelation = self.postprocess(voltages= voltages,dt=dt, save=save, group = dg,metadata=self.base_metadata)\n\t\t\t\t\n\t\t\t\tif acs_array is None:\n\t\t\t\t\tacs_array = np.zeros(shape=(self.averaging_runs, len(autocorrelation)),dtype=np.float32)\n\t\t\t\t\n\t\t\t\tacs_array[i,:] = autocorrelation\n\n\t\t\t\texec_time =timeit.default_timer() - start_time\n\t\t\t\tself.log(message=\"/--Iteration:{0} [T_exec:{1:.3g}]\".format(i,exec_time))\n\t\t\t#compute mean, stdev and skew for all data\n\t\t\tmean_acs = np.mean(acs_array,axis=0)\n\t\t\tassert(len(mean_acs) == len(times))\n\t\t\tstdev_acs = np.std(acs_array,axis=0)\n\t\t\tskew_acs = scipy.stats.skew(acs_array,axis=0)\n\n\n\t\t\taveraged_metadata=dict(self.base_metadata)\n\t\t\taveraged_metadata.update({\"averaged_data\": \"True\"})\n\t\t\tself.save_data(data=np.vstack((times, mean_acs)),datatype=\"autocorrelation\", group=dg,metadata=averaged_metadata)\n\t\t\tself.save_data(data=np.vstack((times, stdev_acs)),datatype=\"autocorrelation_stdev\", group=dg,metadata=averaged_metadata)\n\t\t\tself.save_data(data=np.vstack((times, skew_acs)),datatype=\"autocorrelation_skew\", group=dg,metadata=averaged_metadata)\n\n\t\treturn",
  "def threaded_capture(self,settings=None):\n\t\tif isinstance(self.capture_thread, threading.Thread) and self.capture_thread.is_alive():\n\t\t\tself.card.log(message=\"Capture already running!\", level=\"info\")\n\t\t\treturn\n\t\tself.capture_thread = threading.Thread(target=self.capture,args=(settings,))\n\t\tself.capture_thread.start()",
  "class AgilentDSOChannel(object):\n    def __init__(self, dso, channel):\n        self.parent = dso\n        self.ch = channel\n\n    def capture(self):\n        self.parent.write(':digitize channel{0}'.format(self.ch))\n\n    display = queried_channel_property(':channel{0}:display?', ':channel{0}:display {1}',\n                                       validate=[0, 1], dtype='int')\n    range = queried_channel_property(':channel{0}:range?', ':channel{0}:range {1}')\n    scale = queried_channel_property(':channel{0}:scale?', ':channel{0}:scale {1}')\n    offset = queried_channel_property(':channel{0}:offset?', ':channel{0}:offset {1}')\n    coupling = queried_channel_property(':channel{0}:coupling?', ':channel{0}:coupling {1}',\n                                        validate=['ac', 'dc'], dtype='str')\n    units = queried_channel_property(':channel{0}:unit?', ':channel{0}:unit {1}',\n                                     validate=['volt', 'ampere'], dtype='str')\n    label = queried_channel_property(':channel{0}:label?', ':channel{0}:label {1}', dtype='str')\n    probe = queried_channel_property(':channel{0}:probe?', ':channel{0}:probe {1}')",
  "class AgilentDSO(VisaInstrument):\n    \"\"\"\n    Interface to the Agilent digital storage oscilloscopes.\n    \"\"\"\n    def __init__(self, address='USB0::0x0957::0x1799::MY51330673::INSTR'):\n        super(AgilentDSO, self).__init__(address=address)\n        self.instr.read_termination = '\\n'\n        self.instr.write_termination = '\\n'\n        self.channel_names = (1, 2)\n        for ch in self.channel_names:\n            setattr(self, 'channel{0}'.format(ch), AgilentDSOChannel(self, ch))\n        self.channels = tuple(getattr(self, 'channel{0}'.format(ch)) for ch in self.channel_names)\n        # set byte transmission\n        self.waveform_format = 'byte'\n        byteorder = self.waveform_byteorder\n        self.waveform_unsigned = 1\n        byteorder = True if byteorder == 'MSBF' else False\n        self.instr.values_format.use_binary('B', byteorder, np.array)\n\n    def reset(self):\n        self.write('*rst')\n\n    def clear(self):\n        self.write('*cls')\n\n    def autoscale(self):\n        self.write(':autoscale')\n\n    def capture(self, channel=None):\n        if channel is None:\n            self.write(':digitize')\n        else:\n            assert channel in self.channels\n            self.write(':digitize channel{0}'.format(channel))\n\n    def run(self):\n        self.write(':run')\n\n    def single_shot(self):\n        self.write(':single')\n\n    def stop(self):\n        self.write(':stop')\n\n    def force_trigger(self):\n        self.write(':trigger:force')\n\n    acquire_type = queried_property(':acquire:type?', ':acquire:type {0}',\n                                    validate=['normal', 'average', 'hresolution', 'peak'],\n                                    dtype='str'),\n    acquire_complete = queried_property(':acquire:complete?', ':acquire:complete {0}'),\n    acquire_count = queried_property(':acquire:count?', ':acquire:count {0}'),\n    acquire_points = queried_property(':acquire:points?', dtype='int')\n    armed = queried_property(':aer?')\n    opc = queried_property('*opc?')\n    operegister_condition = queried_property(':operegister:condition?', dtype='int')\n    time_mode = queried_property(':timebase:mode?', ':timebase:mode {0}',\n                                 validate=['main', 'window', 'xy', 'roll', 'MAIN'],\n                                 dtype='str')\n    time_range = queried_property(':timebase:range?', ':timebase:range {0}')\n    time_scale = queried_property(':timebase:scale?', ':timebase:scale {0}')\n    time_ref = queried_property(':timebase:reference?', ':timebase:reference {0}',\n                                validate=['left', 'center', 'right', 'LEFT', 'CENT'], dtype='str')\n    time_delay = queried_property(':timebase:delay?', ':timebase:delay {0}')\n    trigger_sweep = queried_property(':trigger:sweep?', ':trigger:sweep {0}',\n                                     validate=['normal', 'auto', 'NORM', 'AUTO'], dtype='str')\n    trigger_mode = queried_property(':trigger:mode?', ':trigger:mode {0}',\n                                    validate=['edge', 'glitch', 'pattern', 'tv', 'EDGE'], dtype='str')\n    trigger_level = queried_property(':trigger:level?', ':trigger:level {0}')\n    trigger_source = queried_property(':trigger:source?', ':trigger:source {0}',\n                                      validate=['channel1', 'channel2', 'external', 'line', 'wgen', 'CHAN1', 'CHAN2'],\n                                      dtype='str')\n    trigger_slope = queried_property(':trigger:slope?', ':trigger:slope {0}',\n                                     validate=['positive', 'negative', 'either', 'alternate', 'POS', 'NEG'],\n                                     dtype='str')\n    trigger_reject_noise = queried_property(':trigger:nreject?', ':trigger:nreject {0}',\n                                            validate=[0, 1], dtype='int')\n    trigger_filter = queried_property(':trigger:hfreject?', ':trigger:hfreject {0}',\n                                      validate=[0, 1], dtype='int')\n    trigger_status = queried_property(':ter?', dtype='int')\n    waveform_format = queried_property(':waveform:format?', ':waveform:format {0}',\n                                       validate=['byte', 'ascii'], dtype='str')\n    waveform_byteorder = queried_property(':waveform:byteorder?', ':waveform:byteorder {0}',\n                                          validate=['lsbfirst', 'msbfirst', 'LSBFirst', 'MSBFirst', 'LSBF', 'MSBF'],\n                                          dtype='str')\n    waveform_unsigned = queried_property(':waveform:unsigned?', ':waveform:unsigned {0}',\n                                         validate=[0, 1], dtype='int')\n    waveform_points = queried_property(':waveform:points?', ':waveform:points {0}', dtype='int')\n    waveform_points_mode = queried_property(':waveform:points:mode?', ':waveform:points:mode {0}',\n                                            validate=['normal', 'maximum', 'raw', 'NORM', 'MAX', 'RAW'],\n                                            dtype='str')\n\n    # read parameters\n    def set_source(self, ch):\n        assert ch in self.channel_names\n        self.write(\":waveform:source channel{0}\".format(ch))\n\n    x_or = queried_property(\":waveform:xorigin?\")\n    x_inc = queried_property(\":waveform:xincrement?\")\n    y_or = queried_property(\":waveform:yorigin?\")\n    y_inc = queried_property(\":waveform:yincrement?\")\n    y_ref = queried_property(\":waveform:yreference?\")\n\n    def set_trace_parameters(self, ch, mode='maximum'):\n        assert ch in self.channel_names\n        self.set_source(ch)\n        self.waveform_points_mode = mode\n        self.waveform_points = self.acquire_points\n\n    def scale_trace(self, trace):\n        trace = self.y_or + (self.y_inc * (trace - self.y_ref))\n        time = np.arange(trace.size)*self.x_inc + self.x_or\n        return time, trace\n\n    def read_trace(self, ch, renew=True):\n        assert ch in self.channel_names\n        if renew:\n            self.set_trace_parameters(ch)\n        self.set_source(ch)\n        trace = self.instr.query_values(':waveform:data?')\n\n        time, trace = self.scale_trace(trace)\n        return time, trace\n\n    def check_trigger(self, force=False):\n        if force:\n            self.force_trigger()\n        return bool(self.trigger_status)\n\n    def is_running(self):\n        if (self.operegister_condition == 4128):\n            return False\n        else:\n            return True\n\n    def get_qt_ui(self):\n        return AgilentDsoUI(self)",
  "class AgilentDsoUI(QtWidgets.QWidget, UiTools):\n    def __init__(self, dso, parent=None):\n        if not isinstance(dso, AgilentDSO):\n            raise ValueError('dso must be an instance of DSO')\n        super(AgilentDsoUI, self).__init__()\n        self.dso = dso\n        self.parent = parent\n        uic.loadUi(os.path.join(os.path.dirname(__file__), 'agilent_dso.ui'), self)",
  "def __init__(self, dso, channel):\n        self.parent = dso\n        self.ch = channel",
  "def capture(self):\n        self.parent.write(':digitize channel{0}'.format(self.ch))",
  "def __init__(self, address='USB0::0x0957::0x1799::MY51330673::INSTR'):\n        super(AgilentDSO, self).__init__(address=address)\n        self.instr.read_termination = '\\n'\n        self.instr.write_termination = '\\n'\n        self.channel_names = (1, 2)\n        for ch in self.channel_names:\n            setattr(self, 'channel{0}'.format(ch), AgilentDSOChannel(self, ch))\n        self.channels = tuple(getattr(self, 'channel{0}'.format(ch)) for ch in self.channel_names)\n        # set byte transmission\n        self.waveform_format = 'byte'\n        byteorder = self.waveform_byteorder\n        self.waveform_unsigned = 1\n        byteorder = True if byteorder == 'MSBF' else False\n        self.instr.values_format.use_binary('B', byteorder, np.array)",
  "def reset(self):\n        self.write('*rst')",
  "def clear(self):\n        self.write('*cls')",
  "def autoscale(self):\n        self.write(':autoscale')",
  "def capture(self, channel=None):\n        if channel is None:\n            self.write(':digitize')\n        else:\n            assert channel in self.channels\n            self.write(':digitize channel{0}'.format(channel))",
  "def run(self):\n        self.write(':run')",
  "def single_shot(self):\n        self.write(':single')",
  "def stop(self):\n        self.write(':stop')",
  "def force_trigger(self):\n        self.write(':trigger:force')",
  "def set_source(self, ch):\n        assert ch in self.channel_names\n        self.write(\":waveform:source channel{0}\".format(ch))",
  "def set_trace_parameters(self, ch, mode='maximum'):\n        assert ch in self.channel_names\n        self.set_source(ch)\n        self.waveform_points_mode = mode\n        self.waveform_points = self.acquire_points",
  "def scale_trace(self, trace):\n        trace = self.y_or + (self.y_inc * (trace - self.y_ref))\n        time = np.arange(trace.size)*self.x_inc + self.x_or\n        return time, trace",
  "def read_trace(self, ch, renew=True):\n        assert ch in self.channel_names\n        if renew:\n            self.set_trace_parameters(ch)\n        self.set_source(ch)\n        trace = self.instr.query_values(':waveform:data?')\n\n        time, trace = self.scale_trace(trace)\n        return time, trace",
  "def check_trigger(self, force=False):\n        if force:\n            self.force_trigger()\n        return bool(self.trigger_status)",
  "def is_running(self):\n        if (self.operegister_condition == 4128):\n            return False\n        else:\n            return True",
  "def get_qt_ui(self):\n        return AgilentDsoUI(self)",
  "def __init__(self, dso, parent=None):\n        if not isinstance(dso, AgilentDSO):\n            raise ValueError('dso must be an instance of DSO')\n        super(AgilentDsoUI, self).__init__()\n        self.dso = dso\n        self.parent = parent\n        uic.loadUi(os.path.join(os.path.dirname(__file__), 'agilent_dso.ui'), self)",
  "class Lockin_SR844(vi.VisaInstrument):\n    '''Software control for the Stanford Research Systems SR844 Lockin\n    '''\n    def __init__(self, address='GPIB0::8::INSTR'):\n        '''Sets up visa communication and class dictionaries\n        \n        The class dictionaries are manully inputed translations between what \n        the lockin will send/recieve and the real values. \n        These have been built for:\n            - channel number i.e. X,Y ...   \n            - Sensitivity i.e. Voltage range\n            - time constant i.e. integration time\n            - Filter options i.e. 6 dB etc\n            \n        Args:\n            address(str):   Visa address\n        \n        '''\n        super(Lockin_SR844, self).__init__(address)\n        self.instr.read_termination = '\\n'\n        self.instr.write_termination = '\\n'\n        self.instr.timeout = None\n        print(self.instr.read_termination)\n \n        print(self.write(\"OUTX\"))\n        \n        self.ch_list = {'X': 1, 'Y': 2,'R[V]' : 3,'R [dBm]' : 4,\"theta\" : 5, \"AUX1\" : 6, \"AUX2\" : 7, \"Ref Freq\" : 8,\n                        \"CH1\" : 9, \"CH2\" :10}\n        self.sens_list = {0 : 100E-9,1 : 300E-9, 2 : 1E-6, 3 : 3E-6, 4 : 10E-6, \n                          5 : 30E-6, 6 : 100E-6, 7 : 300E-6, 8 : 1E-3, 9 : 3E-3, \n                          10 : 10E-3, 11 : 30E-3, 12 : 100E-3,13 : 300E-3, 14 : 1}\n        self.time_list = {0 : 100E-6,1 : 300E-6, 2 : 1E-3, 3 : 3E-3, 4 : 10E-3,\n                          5 : 30E-3, 6 : 100E-3,  7 : 300E-3, 8 : 1, 9 : 3, \n                          10 : 10, 11 : 30, 12 : 100,13 : 300, 14 : 1E3, 15 : 3E3, \n                          16 : 10E3, 17 : 30E3}\n        self.filter_list = {0 : \"No Filter\", 1 : \"6 dB\", 2:\"12 dB\",3:\"24 dB\"}\n        \n    def measure_variables(self,channels = \"1,2\"):\n        \"\"\"Upto six variable read, must be greater than 1 measure via a string\n        Args:\n            channels(str):  A string containing integers seperated by a comma \n                            refering to each of the Variable that you which to \n                            measure (as shown below):\n                            1   X\n                            2   Y\n                            3   R [V]\n                            4   R [dBm]\n                            5   \u03b8\n                            6   AUX IN 1\n                            7   AUX IN 2\n                            8   Reference Frequency\n                            9   CH1 display\n                            10  CH2 display \n        \"\"\"\n        variables = self.query(\"SNAP? \"+channels)\n        variables = variables.split(\",\")  \n        variables = [float(i) for i in variables]\n        return variables\n    \n    def measure_X(self):\n        '''Measure the current X value\n        Notes :\n            Offsets and Ratio applied'''\n        return self.float_query(\"OUTP? 1\")\n        \n    def measure_Y(self):\n        '''Measure the current Y value\n        Notes :\n            Offsets and Ratio applied'''\n        return self.float_query(\"OUTP? 2\")\n        \n                \n    def measure_R(self):\n        '''Measure the current R value\n        Notes :\n            Offsets and Ratio applied'''\n        output=-1\n        while output > 1 or output < 0:\n            output = self.float_query(\"OUTP? 3\")\n        return self.float_query(\"OUTP? 3\")\n        \n    def measure_theta(self):\n        '''Measure the current phase (theta) \n        Notes :\n            Offsets and Ratio applied'''\n        return self.float_query(\"OUTP? 5\")\n        \n    def check_frequency(self):\n        ''' Return current measurement frequesncy\n        Returns:\n            Current measreument frequency'''\n        return self.float_query(\"FREQ?\")\n        \n    def get_sens(self):\n        ''' The sensitivity property \n        \n        Gettr:\n            Gets the Current sensitivity as an integer and a real value\n            \n            Returns:\n                num (int):  The integer returned by the lockin\n                sens_list[num](float):  The real value for sensitivty in Vrms\n                        \n        Settr:\n            Sets the current sensitivity as a integer \n            \n            Args:\n                i(int): Sets the sensitivty of the lockin as shown by the dict \n                        self.sens_list typed out below.\n                        \n                        i               Sensitivity\n                        0               100 nVrms / -127 dBm \n                        1               300 nVrms / -117 dBm \n                        2               1 \u03bcVrms / -107 dBm \n                        3               3 \u03bcVrms / -97 dBm \n                        4               10 \u03bcVrms / -87 dBm \n                        5               30 \u03bcVrms / -77 dBm \n                        6               100 \u03bcVrms / -67 dBm \n                        7               300 \u03bcVrms / -57 dBm\n                        8               1 mVrms / -47 dBm\n                        9               3 mVrms / -37 dBm\n                        10              10 mVrms / -27 dBm\n                        11              30 mVrms / -17 dBm\n                        12              100 mVrms / -7 dBm\n                        13              300 mVrms / +3 dBm\n                        14              1 Vrms / +13 dBm\n        '''\n        num = self.int_query(\"SENS?\")\n        return num,self.sens_list[num]\n        \n    def set_sens(self,i):\n        self.write(\"SENS%s\"%i)\n    \n    sensitivity = property(get_sens, set_sens)\n    \n    def get_time_costant(self):\n        ''' The time_constant property \n        \n        Gettr:\n            Gets the Current time constant as an integer and a real value\n            \n            Returns:\n                num (int):  The integer returned by the lockin\n                time_list[num](float):  The real value for sensitivty in Seconds\n                        \n        Settr:\n            Sets the current time constant as an integer \n            \n            Args:\n                i(int): Sets the time constant of the lockin as shown by the dict \n                        self.time_list typed out below.\n                        \n                        i       time constant\n                        0       100 \u03bcs \n                        1       300 \u03bcs \n                        2       1 ms \n                        3       3 ms \n                        4       10 ms \n                        5       30 ms\n                        6       100 ms \n                        7       300 ms \n                        8       1 s \n                        9       3 s\n                        10      10 s\n                        11      30 s\n                        12      100 s\n                        13      300 s\n                        14      1 ks\n                        15      3 ks\n                        16      10 ks\n                        17      30 ks\n        '''\n\n        num = self.int_query(\"OFLT?\")\n        return num,self.time_list[num]\n\n    def set_time_costant(self,i):\n        self.write(\"OFLT\"+str(i))     \n    \n    time_constant = property(get_time_costant, set_time_costant)\n    \n    def set_time_constant_from_int(self,integrationtime):\n        '''Command to reverse read a dictionary and set the time_constant\n        \n        Args:\n            integrationtime(float):     The real value for the time constant in seconds\n                                        for allowed values see self.time_list\n        '''\n        for i in range(len(list(self.time_list.values())[:])):\n            if list(self.time_list.values())[i] == integrationtime:\n                self.time_constant = list(self.time_list.keys())[i]\n                return True\n        print('Setting integration time failed. '+str(integrationtime)+' is not in self.time_list')\n        return False\n\n    def get_filter(self):\n        ''' The filterslope property \n        \n        Gettr:\n            Gets the filter as an integer and a real value\n            \n            Returns:\n                num (int):  The integer returned by the lockin\n                time_list[num](str):  The real value for filter \n                        \n        Settr:\n            Sets the current filter as an integer \n            \n            Args:\n                i(int): Sets the filter of the lockin as shown by the dict \n                        self.time_list typed out below.\n                        \n                        i       Filter\n                        0       No filter\n                        1       6 dB\n                        2       12 dB\n                        3       18 dB\n                        4       24 dB \n        '''\n        num = self.int_query(\"OFSL?\")\n        return num,self.filter_list[num]\n        \n    def set_filter(self,i):\n        self.write(\"OFSL%s\" %i)\n        \n    filterslope = property(get_filter, set_filter)    \n    \n    def get_close_res(self):\n        ''' The close_res property represents the close reserve of the lockin\n        Gettr:\n            Returns:\n                i(int):     The close reserve of the lockin where\n                            high = 0, normal = 1, low noise = 2\n        Settr:\n            Args:\n                i(int):     Set the close reserve of the lockin where\n                            high = 0, normal = 1, low noise = 2\n        '''\n        return self.int_query(\"CRSV?\")\n        \n    def set_close_res(self,i):\n        self.write(\"CRSV%s\" %i)\n        \n    close_res = property(get_close_res,set_close_res)\n\n    def get_wide_res(self):\n        ''' The wide_res property represents the wide reserve of the lockin\n        Gettr:\n            Returns:\n                i(int):     The close reserve of the lockin where\n                            high = 0, normal = 1, low noise = 2\n        Settr:\n            Args:\n                i(int):     Set the close reserve of the lockin where\n                            high = 0, normal = 1, low noise = 2\n        '''\n        return self.int_query(\"WRSV?\")\n        \n    def set_wide_res(self,i):\n        self.write(\"WRSV%s\" % i)\n        \n    wide_res = property(get_wide_res,set_wide_res)\n        \n    def autosens(self):\n        '''checks measurement is with range and auto changes sensitivty and reserve respectively\n        Returns:\n            sens(i,float):  The new sensitivty in both forms\n            wide_res(int):  The new wide reserve (high = 0, normal = 1, low noise = 2)\n            close_res(int): The new close reserve (high = 0, normal = 1, low noise = 2)\n        '''\n        testmax = np.max([np.abs(self.measure_R()),np.abs(self.measure_X()),np.abs(self.measure_Y())])\n        try:\n            Lowersense = self.sens_list[self.sensitivity[0]-1]\n        except KeyError:\n            Lowersense = 0.0\n        while testmax>self.sensitivity[1] or testmax<Lowersense:\n            testmax = np.max([np.abs(self.measure_R()),np.abs(self.measure_X()),np.abs(self.measure_Y())])\n            try:\n                Lowersense = self.sens_list[self.sensitivity[0]-1]\n            except KeyError:\n                Lowersense = 0.0\n            if testmax>self.sensitivity[1]:\n                if self.sensitivity[0]==14:\n                    print(\"OVERLOADED RUNNNNNN\")\n                self.sensitivity = self.sensitivity[0]+1\n            elif testmax<Lowersense:\n                self.sensitivity = self.sensitivity[0]-1\n            sleep(1)\n            self.write(\"AWRS\")  #wideband reseve\n            wide_res = self.wide_res\n            self.write(\"ACRS\") #close in  reseve\n            close_res = self.close_res\n        sens = self.sensitivity\n        wide_res = self.wide_res\n        close_res = self.close_res\n        return sens, wide_res, close_res",
  "def __init__(self, address='GPIB0::8::INSTR'):\n        '''Sets up visa communication and class dictionaries\n        \n        The class dictionaries are manully inputed translations between what \n        the lockin will send/recieve and the real values. \n        These have been built for:\n            - channel number i.e. X,Y ...   \n            - Sensitivity i.e. Voltage range\n            - time constant i.e. integration time\n            - Filter options i.e. 6 dB etc\n            \n        Args:\n            address(str):   Visa address\n        \n        '''\n        super(Lockin_SR844, self).__init__(address)\n        self.instr.read_termination = '\\n'\n        self.instr.write_termination = '\\n'\n        self.instr.timeout = None\n        print(self.instr.read_termination)\n \n        print(self.write(\"OUTX\"))\n        \n        self.ch_list = {'X': 1, 'Y': 2,'R[V]' : 3,'R [dBm]' : 4,\"theta\" : 5, \"AUX1\" : 6, \"AUX2\" : 7, \"Ref Freq\" : 8,\n                        \"CH1\" : 9, \"CH2\" :10}\n        self.sens_list = {0 : 100E-9,1 : 300E-9, 2 : 1E-6, 3 : 3E-6, 4 : 10E-6, \n                          5 : 30E-6, 6 : 100E-6, 7 : 300E-6, 8 : 1E-3, 9 : 3E-3, \n                          10 : 10E-3, 11 : 30E-3, 12 : 100E-3,13 : 300E-3, 14 : 1}\n        self.time_list = {0 : 100E-6,1 : 300E-6, 2 : 1E-3, 3 : 3E-3, 4 : 10E-3,\n                          5 : 30E-3, 6 : 100E-3,  7 : 300E-3, 8 : 1, 9 : 3, \n                          10 : 10, 11 : 30, 12 : 100,13 : 300, 14 : 1E3, 15 : 3E3, \n                          16 : 10E3, 17 : 30E3}\n        self.filter_list = {0 : \"No Filter\", 1 : \"6 dB\", 2:\"12 dB\",3:\"24 dB\"}",
  "def measure_variables(self,channels = \"1,2\"):\n        \"\"\"Upto six variable read, must be greater than 1 measure via a string\n        Args:\n            channels(str):  A string containing integers seperated by a comma \n                            refering to each of the Variable that you which to \n                            measure (as shown below):\n                            1   X\n                            2   Y\n                            3   R [V]\n                            4   R [dBm]\n                            5   \u03b8\n                            6   AUX IN 1\n                            7   AUX IN 2\n                            8   Reference Frequency\n                            9   CH1 display\n                            10  CH2 display \n        \"\"\"\n        variables = self.query(\"SNAP? \"+channels)\n        variables = variables.split(\",\")  \n        variables = [float(i) for i in variables]\n        return variables",
  "def measure_X(self):\n        '''Measure the current X value\n        Notes :\n            Offsets and Ratio applied'''\n        return self.float_query(\"OUTP? 1\")",
  "def measure_Y(self):\n        '''Measure the current Y value\n        Notes :\n            Offsets and Ratio applied'''\n        return self.float_query(\"OUTP? 2\")",
  "def measure_R(self):\n        '''Measure the current R value\n        Notes :\n            Offsets and Ratio applied'''\n        output=-1\n        while output > 1 or output < 0:\n            output = self.float_query(\"OUTP? 3\")\n        return self.float_query(\"OUTP? 3\")",
  "def measure_theta(self):\n        '''Measure the current phase (theta) \n        Notes :\n            Offsets and Ratio applied'''\n        return self.float_query(\"OUTP? 5\")",
  "def check_frequency(self):\n        ''' Return current measurement frequesncy\n        Returns:\n            Current measreument frequency'''\n        return self.float_query(\"FREQ?\")",
  "def get_sens(self):\n        ''' The sensitivity property \n        \n        Gettr:\n            Gets the Current sensitivity as an integer and a real value\n            \n            Returns:\n                num (int):  The integer returned by the lockin\n                sens_list[num](float):  The real value for sensitivty in Vrms\n                        \n        Settr:\n            Sets the current sensitivity as a integer \n            \n            Args:\n                i(int): Sets the sensitivty of the lockin as shown by the dict \n                        self.sens_list typed out below.\n                        \n                        i               Sensitivity\n                        0               100 nVrms / -127 dBm \n                        1               300 nVrms / -117 dBm \n                        2               1 \u03bcVrms / -107 dBm \n                        3               3 \u03bcVrms / -97 dBm \n                        4               10 \u03bcVrms / -87 dBm \n                        5               30 \u03bcVrms / -77 dBm \n                        6               100 \u03bcVrms / -67 dBm \n                        7               300 \u03bcVrms / -57 dBm\n                        8               1 mVrms / -47 dBm\n                        9               3 mVrms / -37 dBm\n                        10              10 mVrms / -27 dBm\n                        11              30 mVrms / -17 dBm\n                        12              100 mVrms / -7 dBm\n                        13              300 mVrms / +3 dBm\n                        14              1 Vrms / +13 dBm\n        '''\n        num = self.int_query(\"SENS?\")\n        return num,self.sens_list[num]",
  "def set_sens(self,i):\n        self.write(\"SENS%s\"%i)",
  "def get_time_costant(self):\n        ''' The time_constant property \n        \n        Gettr:\n            Gets the Current time constant as an integer and a real value\n            \n            Returns:\n                num (int):  The integer returned by the lockin\n                time_list[num](float):  The real value for sensitivty in Seconds\n                        \n        Settr:\n            Sets the current time constant as an integer \n            \n            Args:\n                i(int): Sets the time constant of the lockin as shown by the dict \n                        self.time_list typed out below.\n                        \n                        i       time constant\n                        0       100 \u03bcs \n                        1       300 \u03bcs \n                        2       1 ms \n                        3       3 ms \n                        4       10 ms \n                        5       30 ms\n                        6       100 ms \n                        7       300 ms \n                        8       1 s \n                        9       3 s\n                        10      10 s\n                        11      30 s\n                        12      100 s\n                        13      300 s\n                        14      1 ks\n                        15      3 ks\n                        16      10 ks\n                        17      30 ks\n        '''\n\n        num = self.int_query(\"OFLT?\")\n        return num,self.time_list[num]",
  "def set_time_costant(self,i):\n        self.write(\"OFLT\"+str(i))",
  "def set_time_constant_from_int(self,integrationtime):\n        '''Command to reverse read a dictionary and set the time_constant\n        \n        Args:\n            integrationtime(float):     The real value for the time constant in seconds\n                                        for allowed values see self.time_list\n        '''\n        for i in range(len(list(self.time_list.values())[:])):\n            if list(self.time_list.values())[i] == integrationtime:\n                self.time_constant = list(self.time_list.keys())[i]\n                return True\n        print('Setting integration time failed. '+str(integrationtime)+' is not in self.time_list')\n        return False",
  "def get_filter(self):\n        ''' The filterslope property \n        \n        Gettr:\n            Gets the filter as an integer and a real value\n            \n            Returns:\n                num (int):  The integer returned by the lockin\n                time_list[num](str):  The real value for filter \n                        \n        Settr:\n            Sets the current filter as an integer \n            \n            Args:\n                i(int): Sets the filter of the lockin as shown by the dict \n                        self.time_list typed out below.\n                        \n                        i       Filter\n                        0       No filter\n                        1       6 dB\n                        2       12 dB\n                        3       18 dB\n                        4       24 dB \n        '''\n        num = self.int_query(\"OFSL?\")\n        return num,self.filter_list[num]",
  "def set_filter(self,i):\n        self.write(\"OFSL%s\" %i)",
  "def get_close_res(self):\n        ''' The close_res property represents the close reserve of the lockin\n        Gettr:\n            Returns:\n                i(int):     The close reserve of the lockin where\n                            high = 0, normal = 1, low noise = 2\n        Settr:\n            Args:\n                i(int):     Set the close reserve of the lockin where\n                            high = 0, normal = 1, low noise = 2\n        '''\n        return self.int_query(\"CRSV?\")",
  "def set_close_res(self,i):\n        self.write(\"CRSV%s\" %i)",
  "def get_wide_res(self):\n        ''' The wide_res property represents the wide reserve of the lockin\n        Gettr:\n            Returns:\n                i(int):     The close reserve of the lockin where\n                            high = 0, normal = 1, low noise = 2\n        Settr:\n            Args:\n                i(int):     Set the close reserve of the lockin where\n                            high = 0, normal = 1, low noise = 2\n        '''\n        return self.int_query(\"WRSV?\")",
  "def set_wide_res(self,i):\n        self.write(\"WRSV%s\" % i)",
  "def autosens(self):\n        '''checks measurement is with range and auto changes sensitivty and reserve respectively\n        Returns:\n            sens(i,float):  The new sensitivty in both forms\n            wide_res(int):  The new wide reserve (high = 0, normal = 1, low noise = 2)\n            close_res(int): The new close reserve (high = 0, normal = 1, low noise = 2)\n        '''\n        testmax = np.max([np.abs(self.measure_R()),np.abs(self.measure_X()),np.abs(self.measure_Y())])\n        try:\n            Lowersense = self.sens_list[self.sensitivity[0]-1]\n        except KeyError:\n            Lowersense = 0.0\n        while testmax>self.sensitivity[1] or testmax<Lowersense:\n            testmax = np.max([np.abs(self.measure_R()),np.abs(self.measure_X()),np.abs(self.measure_Y())])\n            try:\n                Lowersense = self.sens_list[self.sensitivity[0]-1]\n            except KeyError:\n                Lowersense = 0.0\n            if testmax>self.sensitivity[1]:\n                if self.sensitivity[0]==14:\n                    print(\"OVERLOADED RUNNNNNN\")\n                self.sensitivity = self.sensitivity[0]+1\n            elif testmax<Lowersense:\n                self.sensitivity = self.sensitivity[0]-1\n            sleep(1)\n            self.write(\"AWRS\")  #wideband reseve\n            wide_res = self.wide_res\n            self.write(\"ACRS\") #close in  reseve\n            close_res = self.close_res\n        sens = self.sensitivity\n        wide_res = self.wide_res\n        close_res = self.close_res\n        return sens, wide_res, close_res",
  "class ThorlabsPowermeter(PowerMeter, VisaInstrument):\n    def __init__(self, address = 'USB0::0x1313::0x807B::17121118::INSTR',\n                 settings = {\n                              # 'timeout': 0.1,\n                              'read_termination': '\\n',\n                              'write_termination': '\\r\\n',\n                                }):\n     \n        VisaInstrument.__init__(self, address=address, settings=settings)\n        PowerMeter.__init__(self)\n        self.address = address\n        self.settings = settings\n        self.num_averages = 10\n    def _read(self):\n        return float(self.query('READ?'))\n    \n    @property\n    def wavelength(self):\n        return self.query('Sense:Correction:WAVelength?')\n    \n    @wavelength.setter\n    def wavelength(self, wl):\n        self.write('Sense:Correction:WAVelength '+str(wl))\n    \n    def read_average(self, num_averages=None):\n        \"\"\"a quick averaging tool for the pm100 power meter \"\"\"\n        live = self.live\n        self.live = False\n        if num_averages is None:\n            num_averages = self.num_averages\n        powers = []\n        failures = 0\n        while failures<20 and len(powers)<num_averages:\n            try: \n                powers.append(self.power)\n                failures = 0\n            except:\n                failures+=1\n        # average = np.mean([self.power for _ in range(num_averages)])\n        average = np.mean(powers)\n        self.live = live\n        return average\n    \n    def read_power(self):\n        return self._read()*1000\n    \n    def restart(self):\n        self.__init__(self.address)",
  "def __init__(self, address = 'USB0::0x1313::0x807B::17121118::INSTR',\n                 settings = {\n                              # 'timeout': 0.1,\n                              'read_termination': '\\n',\n                              'write_termination': '\\r\\n',\n                                }):\n     \n        VisaInstrument.__init__(self, address=address, settings=settings)\n        PowerMeter.__init__(self)\n        self.address = address\n        self.settings = settings\n        self.num_averages = 10",
  "def _read(self):\n        return float(self.query('READ?'))",
  "def wavelength(self):\n        return self.query('Sense:Correction:WAVelength?')",
  "def wavelength(self, wl):\n        self.write('Sense:Correction:WAVelength '+str(wl))",
  "def read_average(self, num_averages=None):\n        \"\"\"a quick averaging tool for the pm100 power meter \"\"\"\n        live = self.live\n        self.live = False\n        if num_averages is None:\n            num_averages = self.num_averages\n        powers = []\n        failures = 0\n        while failures<20 and len(powers)<num_averages:\n            try: \n                powers.append(self.power)\n                failures = 0\n            except:\n                failures+=1\n        # average = np.mean([self.power for _ in range(num_averages)])\n        average = np.mean(powers)\n        self.live = live\n        return average",
  "def read_power(self):\n        return self._read()*1000",
  "def restart(self):\n        self.__init__(self.address)",
  "class ArduinoRotator(SerialInstrument):\n    STEPS_PER_REV = 16334.982528149094\n    max_int = 32_767 # biggest integer the arduino can hold\n    def __init__(self, port, unidirectional=False):\n        self.termination_character = '\\n'\n        SerialInstrument.__init__(self, port)\n        self.flush_input_buffer()\n        self.ignore_echo = True\n        self.timeout = 0.5\n        time.sleep(2) # for some reason this is necessary to change default speed\n        self.speed = 15\n        self._logger.setLevel('WARN')\n        self._angle = 0\n        self.unidirectional = unidirectional\n        \n    # def query(self, queryString, **args):\n    #     return super().query(queryString, timeout=self.timeout, **args)\n   \n    @property\n    def speed(self):\n        return self._speed\n    \n    @speed.setter\n    def speed(self, value):\n        if value < 1: self._speed = 1\n        if value > 15: self._speed = 15\n        self._speed = int(value)\n        self.write(f'S{self._speed}', ignore_echo=True)\n    \n    @property\n    def angle(self):\n        return self._angle\n    \n    @angle.setter\n    def angle(self, angle):\n        self.move(angle)\n    \n    def move_raw(self, steps):\n        start = time.time()\n        cmd = f'M{int(steps)}'\n        self._logger.info('command: ' + cmd)\n        self.write(cmd, ignore_echo=True)\n        while time.time() - start < 200:\n            reply = self.readline().strip()\n            if reply == '1':\n                break\n            if reply:\n                self._logger.info('ki-> '+ reply)\n            time.sleep(0.1)\n    \n    def move_a_lot(self, steps):\n        if steps == 0:\n            return  \n        \n        sign = (1, -1)[steps<0]\n        steps = abs(steps)\n        \n        movements = 0\n        if steps > self.max_int:\n            movements = steps // self.max_int\n            steps = steps % self.max_int\n            \n        for movement in range(movements):\n            self._logger.info('starting new command, rotation may be discontinuous')\n            self.move_raw(sign*self.max_int)\n        \n        self.move_raw(sign*steps)\n    \n    def move_rel(self, degrees):\n        ''''clockwise'''\n        self._logger.info(f'moving {degrees} degrees')\n        self.move_a_lot(int(-degrees*self.STEPS_PER_REV/360))\n        self._angle += degrees\n    \n    def move(self, degree):\n        if self.angle > degree and self.unidirectional:\n            degree += 360\n        self.move_rel(degree - self.angle)\n        \n    def home(self):\n        if self.angle == 0.:\n            return\n        self.move_rel(360 - self.angle)\n        \n    def calibrate(self, rotations: int = 5):\n        print(f'rotating clockwise {rotations} rotations')\n        self.speed = 15\n        self.move_rel(rotations*360)\n        overshoot = float(input('''How far did it over/undershoot\n                          (in degrees)?'''))\n        \n        self.STEPS_PER_REV = self.STEPS_PER_REV*(rotations)/(rotations+overshoot/360)\n        print(f'steps per rev = {self.STEPS_PER_REV} ')",
  "def __init__(self, port, unidirectional=False):\n        self.termination_character = '\\n'\n        SerialInstrument.__init__(self, port)\n        self.flush_input_buffer()\n        self.ignore_echo = True\n        self.timeout = 0.5\n        time.sleep(2) # for some reason this is necessary to change default speed\n        self.speed = 15\n        self._logger.setLevel('WARN')\n        self._angle = 0\n        self.unidirectional = unidirectional",
  "def speed(self):\n        return self._speed",
  "def speed(self, value):\n        if value < 1: self._speed = 1\n        if value > 15: self._speed = 15\n        self._speed = int(value)\n        self.write(f'S{self._speed}', ignore_echo=True)",
  "def angle(self):\n        return self._angle",
  "def angle(self, angle):\n        self.move(angle)",
  "def move_raw(self, steps):\n        start = time.time()\n        cmd = f'M{int(steps)}'\n        self._logger.info('command: ' + cmd)\n        self.write(cmd, ignore_echo=True)\n        while time.time() - start < 200:\n            reply = self.readline().strip()\n            if reply == '1':\n                break\n            if reply:\n                self._logger.info('ki-> '+ reply)\n            time.sleep(0.1)",
  "def move_a_lot(self, steps):\n        if steps == 0:\n            return  \n        \n        sign = (1, -1)[steps<0]\n        steps = abs(steps)\n        \n        movements = 0\n        if steps > self.max_int:\n            movements = steps // self.max_int\n            steps = steps % self.max_int\n            \n        for movement in range(movements):\n            self._logger.info('starting new command, rotation may be discontinuous')\n            self.move_raw(sign*self.max_int)\n        \n        self.move_raw(sign*steps)",
  "def move_rel(self, degrees):\n        ''''clockwise'''\n        self._logger.info(f'moving {degrees} degrees')\n        self.move_a_lot(int(-degrees*self.STEPS_PER_REV/360))\n        self._angle += degrees",
  "def move(self, degree):\n        if self.angle > degree and self.unidirectional:\n            degree += 360\n        self.move_rel(degree - self.angle)",
  "def home(self):\n        if self.angle == 0.:\n            return\n        self.move_rel(360 - self.angle)",
  "def calibrate(self, rotations: int = 5):\n        print(f'rotating clockwise {rotations} rotations')\n        self.speed = 15\n        self.move_rel(rotations*360)\n        overshoot = float(input('''How far did it over/undershoot\n                          (in degrees)?'''))\n        \n        self.STEPS_PER_REV = self.STEPS_PER_REV*(rotations)/(rotations+overshoot/360)\n        print(f'steps per rev = {self.STEPS_PER_REV} ')",
  "class SpectrumAnalyzer(VisaInstrument):\n    def __init__(self, address='GPIB0::18::INSTR'):\n        super(SpectrumAnalyzer, self).__init__(address)\n        self.instr.read_termination = '\\n'\n        self.instr.write_termination = '\\n'\n        self.freq_points=601\n\n    # frequency = queried_property('freq?', 'freq {0}')\n    # function = queried_property('function:shape?', 'function:shape {0}',\n    #                             validate=['sinusoid', 'dc'], dtype='str')\n    # voltage = queried_property('voltage?', 'voltage {0}')\n    # offset = queried_property('voltage:offset?', 'voltage:offset {0}')\n    # output_load = queried_property('output:load?', 'output:load {0}',\n    #                                validate=['inf'], dtype='str')\n    # volt_high = queried_property('volt:high?', 'volt:high {0}')\n    # volt_low = queried_property('volt:low?', 'volt:low {0}')\n    # output = queried_property('output?', 'output {0}',\n    #                           validate=['OFF', 'ON'], dtype='str')\n\n    def reset(self):\n        self.write('*rst')\n        \n    def get_center_freq(self):\n        return float(self.query('CF?'))/1e6 #return span in MHz\n    \n    def set_center_freq(self,CF): # center frequency in MHz\n        self.write('CF '+str(CF)+' MHZ')\n        return float(self.query('CF?'))/1e6 #return span in MHz\n        \n    def get_span(self):\n        return float(self.query('SP?'))/1e6 #return span in MHz\n    \n    def set_span(self,SP): #span in MHz\n        self.write('SP '+str(SP)+' MHZ')\n        return float(self.query('SP?'))/1e6 #return span in MHz\n    \n    def get_res(self): # get resolution bandwidth\n        return float(self.query('RB?'))/1e3 # returns resolution in MHz\n    \n    def set_res(self,res): # set resolution, res in kHz\n        self.write('RB '+str(res)+' KHZ')\n        return float(self.query('RB?'))/1e3 #return span in MHz\n    \n    def get_sweep_time(self):\n        return float(self.query('ST?')) #return sweep time in sec\n    \n    def set_sweep_time(self,ST): #sweep time in sec\n        self.write('ST '+str(ST)+' S')\n        sleep(1)\n        return float(self.query('ST?')) #return span in MHz\n    \n    def set_single_sweep(self): # set to single sweep\n        self.write('SNGLS')\n        \n    def set_cont_sweep(self):\n        self.write('CONTS')\n    \n    def command_completed(self):\n        done=False\n        while not done:\n            try: \n                done=bool(self.query('DONE?'))\n            except:\n                done=False\n        return done\n    \n    # def take_sweep(self):\n        \n    #     self.write('TS')\n    #     done=False\n    #     while not done:\n    #         try: \n    #             done=bool(self.query('DONE?'))\n    #         except:\n    #             done=False\n    #     print('sweep ended')\n    #     return True\n    \n    def take_sweep(self):\n        \n        self.write('TS')\n        if self.command_completed():\n            print('sweep completed')\n            return True\n    \n    def get_data(self):\n        self.clear_read_buffer()\n        data=self.query('TRA?')\n        data=np.fromstring(data,dtype=float,sep=',')\n        return(data)\n    \n    def get_freq_axis(self):\n        fa=float(self.query('FA?'))/1e6\n        fb=float(self.query('FB?'))/1e6\n        return np.linspace(fa,fb,self.freq_points)",
  "def __init__(self, address='GPIB0::18::INSTR'):\n        super(SpectrumAnalyzer, self).__init__(address)\n        self.instr.read_termination = '\\n'\n        self.instr.write_termination = '\\n'\n        self.freq_points=601",
  "def reset(self):\n        self.write('*rst')",
  "def get_center_freq(self):\n        return float(self.query('CF?'))/1e6",
  "def set_center_freq(self,CF): # center frequency in MHz\n        self.write('CF '+str(CF)+' MHZ')\n        return float(self.query('CF?'))/1e6",
  "def get_span(self):\n        return float(self.query('SP?'))/1e6",
  "def set_span(self,SP): #span in MHz\n        self.write('SP '+str(SP)+' MHZ')\n        return float(self.query('SP?'))/1e6",
  "def get_res(self): # get resolution bandwidth\n        return float(self.query('RB?'))/1e3",
  "def set_res(self,res): # set resolution, res in kHz\n        self.write('RB '+str(res)+' KHZ')\n        return float(self.query('RB?'))/1e3",
  "def get_sweep_time(self):\n        return float(self.query('ST?'))",
  "def set_sweep_time(self,ST): #sweep time in sec\n        self.write('ST '+str(ST)+' S')\n        sleep(1)\n        return float(self.query('ST?'))",
  "def set_single_sweep(self): # set to single sweep\n        self.write('SNGLS')",
  "def set_cont_sweep(self):\n        self.write('CONTS')",
  "def command_completed(self):\n        done=False\n        while not done:\n            try: \n                done=bool(self.query('DONE?'))\n            except:\n                done=False\n        return done",
  "def take_sweep(self):\n        \n        self.write('TS')\n        if self.command_completed():\n            print('sweep completed')\n            return True",
  "def get_data(self):\n        self.clear_read_buffer()\n        data=self.query('TRA?')\n        data=np.fromstring(data,dtype=float,sep=',')\n        return(data)",
  "def get_freq_axis(self):\n        fa=float(self.query('FA?'))/1e6\n        fb=float(self.query('FB?'))/1e6\n        return np.linspace(fa,fb,self.freq_points)",
  "class VariableRetarder(SerialInstrument):\n    \"\"\"\n    Serial control of a 3040. It does NOT provide all the functionality of the CellDrive 3000 Advanced\n    Because it wants commands sent to it ending in \\r, but it returns commands that end in \\r\\n had to rewrite the read write functions\n    \"\"\"\n    port_settings = dict(baudrate=38400, bytesize=EIGHTBITS, parity=PARITY_NONE, stopbits=STOPBITS_ONE,\n                         timeout=2)\n    termination_character = '\\r'\n    termination_read = '\\r\\n'\n    wait_time = 2\n\n    def __init__(self, port=None, channel=1):\n        super(VariableRetarder, self).__init__(port)\n        self._channel = channel\n\n    def query(self, queryString, *args, **kwargs):\n        reply = super(VariableRetarder, self).query(queryString, *args, **kwargs)\n        self._logger.debug('Received: %s' % reply)\n        split_reply = reply.split(':')\n        split_query = queryString.split(':')\n        if split_reply[0] != split_query[0]:\n            self._logger.warn('Error trying to query: %s %s' % (queryString, split_reply))\n        return split_reply[1]\n\n    @property\n    def firmware_version(self):\n        return self.query('ver:?')\n\n    @property\n    def channel(self):\n        \"\"\"\n        Sets the default channel to performs queries on\n        :return:\n        \"\"\"\n        return self._channel\n\n    @channel.setter\n    def channel(self, value):\n        self._channel = value\n\n    @property\n    def voltage(self):\n        \"\"\"\n        Query the voltage setting on the current channel\n        :return:\n        \"\"\"\n        reply = self.query('ld:%d,?' % self.channel)\n        integer = int(reply.split(',')[1])\n        voltage = integer / 6553.5\n        return voltage\n\n    @voltage.setter\n    def voltage(self, value):\n        \"\"\"\n        Sets the modulation voltage on the specified LC channel.\n        Converts integer i to a squarewave amplitude voltage.\n        :param value: float\n        :return:\n        \"\"\"\n        assert 0 <= value <= 10\n        integer = value * 6553.5\n        self.write('ld:%d,%d' % (self.channel, integer))\n        time.sleep(self.wait_time)\n\n    @property\n    def all_voltages(self):\n        \"\"\"\n        Query voltage settings on all four channels.\n        :return:\n        \"\"\"\n        reply = self.query('ldd:?')\n        integers = list(map(int, reply.split(',')))\n        voltages = [x / 6553.5 for x in integers]\n        return voltages\n\n    @all_voltages.setter\n    def all_voltages(self, value):\n        \"\"\"\n        Simultaneously sets the modulation voltages on all four LC channels.\n        Converts each integer i to a square-wave amplitude voltage.\n\n        :param value: 4-tuple of floats\n        :return:\n        \"\"\"\n        for val in value:\n            assert 0 <= val <= 10\n        voltages = tuple(value)\n        integers = [x * 6553.5 for x in voltages]\n        self.write('ldd:%d,%d,%d,%d' % integers)\n\n    @property\n    def temperature(self):\n        \"\"\"\n        Query the current temperature of a temperature-controlled LC.\n        :return:\n        \"\"\"\n        integer = int(self.query('tmp:?'))\n        return (old_div(integer * 500, 65535)) - 273.15\n\n    @property\n    def temperature_setpoint(self):\n        \"\"\"\n        Query the current temperature setpoint.\n        :return:\n        \"\"\"\n        integer = int(self.query('tsp:?'))\n        return (old_div(integer * 500, 16384)) - 273.15\n\n    @temperature_setpoint.setter\n    def temperature_setpoint(self, value):\n        \"\"\"\n        Sets the temperature setpoint for temperature control.\n        :param value:\n        :return:\n        \"\"\"\n        integer = old_div((value + 273.15) * 16384, 500)\n        self.write('tsp:%d' % integer)\n\n    def sync(self):\n        \"\"\"\n        Produces a sync pulse (highlow) on the front panel sync connector.\n        :return:\n        \"\"\"\n        self.write('sout:')\n\n    def extin(self, channels):\n        \"\"\"\n        Enables output channels to be driven by signal applied to front panel external input connector.\n        :param channels: 4-tuple of booleans\n        :return:\n        \"\"\"\n        integer = 0\n        for idx, chn in enumerate(channels):\n            if chn:\n                integer += 2 ** idx\n        self.write('extin:%d' % integer)",
  "def __init__(self, port=None, channel=1):\n        super(VariableRetarder, self).__init__(port)\n        self._channel = channel",
  "def query(self, queryString, *args, **kwargs):\n        reply = super(VariableRetarder, self).query(queryString, *args, **kwargs)\n        self._logger.debug('Received: %s' % reply)\n        split_reply = reply.split(':')\n        split_query = queryString.split(':')\n        if split_reply[0] != split_query[0]:\n            self._logger.warn('Error trying to query: %s %s' % (queryString, split_reply))\n        return split_reply[1]",
  "def firmware_version(self):\n        return self.query('ver:?')",
  "def channel(self):\n        \"\"\"\n        Sets the default channel to performs queries on\n        :return:\n        \"\"\"\n        return self._channel",
  "def channel(self, value):\n        self._channel = value",
  "def voltage(self):\n        \"\"\"\n        Query the voltage setting on the current channel\n        :return:\n        \"\"\"\n        reply = self.query('ld:%d,?' % self.channel)\n        integer = int(reply.split(',')[1])\n        voltage = integer / 6553.5\n        return voltage",
  "def voltage(self, value):\n        \"\"\"\n        Sets the modulation voltage on the specified LC channel.\n        Converts integer i to a squarewave amplitude voltage.\n        :param value: float\n        :return:\n        \"\"\"\n        assert 0 <= value <= 10\n        integer = value * 6553.5\n        self.write('ld:%d,%d' % (self.channel, integer))\n        time.sleep(self.wait_time)",
  "def all_voltages(self):\n        \"\"\"\n        Query voltage settings on all four channels.\n        :return:\n        \"\"\"\n        reply = self.query('ldd:?')\n        integers = list(map(int, reply.split(',')))\n        voltages = [x / 6553.5 for x in integers]\n        return voltages",
  "def all_voltages(self, value):\n        \"\"\"\n        Simultaneously sets the modulation voltages on all four LC channels.\n        Converts each integer i to a square-wave amplitude voltage.\n\n        :param value: 4-tuple of floats\n        :return:\n        \"\"\"\n        for val in value:\n            assert 0 <= val <= 10\n        voltages = tuple(value)\n        integers = [x * 6553.5 for x in voltages]\n        self.write('ldd:%d,%d,%d,%d' % integers)",
  "def temperature(self):\n        \"\"\"\n        Query the current temperature of a temperature-controlled LC.\n        :return:\n        \"\"\"\n        integer = int(self.query('tmp:?'))\n        return (old_div(integer * 500, 65535)) - 273.15",
  "def temperature_setpoint(self):\n        \"\"\"\n        Query the current temperature setpoint.\n        :return:\n        \"\"\"\n        integer = int(self.query('tsp:?'))\n        return (old_div(integer * 500, 16384)) - 273.15",
  "def temperature_setpoint(self, value):\n        \"\"\"\n        Sets the temperature setpoint for temperature control.\n        :param value:\n        :return:\n        \"\"\"\n        integer = old_div((value + 273.15) * 16384, 500)\n        self.write('tsp:%d' % integer)",
  "def sync(self):\n        \"\"\"\n        Produces a sync pulse (highlow) on the front panel sync connector.\n        :return:\n        \"\"\"\n        self.write('sout:')",
  "def extin(self, channels):\n        \"\"\"\n        Enables output channels to be driven by signal applied to front panel external input connector.\n        :param channels: 4-tuple of booleans\n        :return:\n        \"\"\"\n        integer = 0\n        for idx, chn in enumerate(channels):\n            if chn:\n                integer += 2 ** idx\n        self.write('extin:%d' % integer)",
  "def test_info(lib, device_id):\n    print(\"\\nGet device info\")\n    x_device_information = xi.device_information_t()\n    result = xi.lib.get_device_information(\n        device_id, byref(x_device_information))\n    print(\"Result: \" + repr(result))\n    if result == xi.Result.Ok:\n        print(\"Device information:\")\n        print(\" Manufacturer: \" +\n              repr(xi.string_at(x_device_information.Manufacturer).decode()))\n        print(\" ManufacturerId: \" +\n              repr(xi.string_at(x_device_information.ManufacturerId).decode()))\n        print(\" ProductDescription: \" +\n              repr(xi.string_at(x_device_information.ProductDescription).decode()))\n        print(\" Major: \" + repr(x_device_information.Major))\n        print(\" Minor: \" + repr(x_device_information.Minor))\n        print(\" Release: \" + repr(x_device_information.Release))",
  "def test_status(lib, device_id):\n    print(\"\\nGet status\")\n    x_status = xi.status_t()\n    result = xi.lib.get_status(device_id, byref(x_status))\n    print(\"Result: \" + repr(result))\n    if result == xi.Result.Ok:\n        print(\"Status.Ipwr: \" + repr(x_status.Ipwr))\n        print(\"Status.Upwr: \" + repr(x_status.Upwr))\n        print(\"Status.Iusb: \" + repr(x_status.Iusb))\n        print(\"Status.Flags: \" + repr(hex(x_status.Flags)))",
  "def test_get_position(lib, device_id):\n    print(\"\\nRead position\")\n    x_pos = xi.get_position_t()\n    result = xi.lib.get_position(device_id, byref(x_pos))\n    print(\"Result: \" + repr(result))\n    if result == xi.Result.Ok:\n        print(\"Position: {0} steps, {1} microsteps\".format(\n            x_pos.Position, x_pos.uPosition))\n    return x_pos.Position, x_pos.uPosition",
  "def test_left(lib, device_id):\n    print(\"\\nMoving left\")\n    result = lib.command_left(device_id)\n    print(\"Result: \" + repr(result))",
  "def test_move(lib, device_id, distance, udistance):\n    print(\"\\nGoing to {0} steps, {1} microsteps\".format(distance, udistance))\n    result = lib.command_move(device_id, distance, udistance)\n    print(\"Result: \" + repr(result))",
  "def test_wait_for_stop(lib, device_id, interval):\n    print(\"\\nWaiting for stop\")\n    result = lib.command_wait_for_stop(device_id, interval)\n    print(\"Result: \" + repr(result))",
  "def test_serial(lib, device_id):\n    print(\"\\nReading serial\")\n    x_serial = c_uint()\n    result = lib.get_serial_number(device_id, byref(x_serial))\n    if result == xi.Result.Ok:\n        print(\"Serial: \" + repr(x_serial.value))",
  "def test_get_speed(lib, device_id):\n    print(\"\\nGet speed\")\n    # Create move settings structure\n    mvst = xi.move_settings_t()\n    # Get current move settings from controller\n    result = lib.get_move_settings(device_id, byref(mvst))\n    # Print command return status. It will be 0 if all is OK\n    print(\"Read command result: \" + repr(result))\n\n    return mvst.Speed",
  "def test_set_speed(lib, device_id, speed):\n    print(\"\\nSet speed\")\n    # Create move settings structure\n    mvst = xi.move_settings_t()\n    # Get current move settings from controller\n    result = lib.get_move_settings(device_id, byref(mvst))\n    # Print command return status. It will be 0 if all is OK\n    print(\"Read command result: \" + repr(result))\n    print(\"The speed was equal to {0}. We will change it to {1}\".format(\n        mvst.Speed, speed))\n    # Change current speed\n    mvst.Speed = int(speed)\n    # Write new move settings to controller\n    result = lib.set_move_settings(device_id, byref(mvst))\n    # Print command return status. It will be 0 if all is OK\n    print(\"Write command result: \" + repr(result))",
  "def test_set_microstep_mode_256(lib, device_id):\n    print(\"\\nSet microstep mode to 256\")\n    # Create engine settings structure\n    eng = xi.engine_settings_t()\n    # Get current engine settings from controller\n    result = lib.get_engine_settings(device_id, byref(eng))\n    # Print command return status. It will be 0 if all is OK\n    print(\"Read command result: \" + repr(result))\n    # Change MicrostepMode parameter to MICROSTEP_MODE_FRAC_256\n    # (use MICROSTEP_MODE_FRAC_128, MICROSTEP_MODE_FRAC_64 ... for other microstep modes)\n    eng.MicrostepMode = xi.MicrostepMode.MICROSTEP_MODE_FRAC_256\n    # Write new engine settings to controller\n    result = lib.set_engine_settings(device_id, byref(eng))\n    # Print command return status. It will be 0 if all is OK\n    print(\"Write command result: \" + repr(result))",
  "class Iris(Instrument):\n    def __init__(self):\n        super().__init__()\n        self.device_id = xi.lib.open_device(open_name)\n        eng = xi.engine_settings_t()\n        xi.lib.get_engine_settings(self.device_id, byref(eng))\n        eng.MicrostepMode = xi.MicrostepMode.MICROSTEP_MODE_FRAC_256\n        xi.lib.set_engine_settings(self.device_id, byref(eng))\n        self.set_speed(500_000)\n        xi.lib.command_homezero(self.device_id)\n        self._wait()\n        self.close_fully()\n        self.open_fully()\n        \n    def _wait(self):\n        xi.lib.command_wait_for_stop(self.device_id, 100)  \n        # 100 ms refresh rate\n    \n    def get_range(self):\n        sst  = xi.stage_settings_t()\n        xi.lib.get_stage_settings(ir.device_id, byref(sst))\n        rang = sst.TravelRange\n        return rang\n    \n        \n    def _close_fully(self):\n        xi.lib.command_left(self.device_id)\n        \n    def _open_fully(self):\n        xi.lib.command_right(self.device_id)\n        \n    def close_fully(self):\n        self._close_fully()\n        self._wait()\n        self._close_pos = self.get_position() # open, closed    \n        self._close_fraction = 1\n        \n    def open_fully(self):\n        self._open_fully()\n        self._wait()\n        self._close_fraction = 0\n        self._open_pos = self.get_position()\n        \n    \n    def close_partially(self, frac):\n        try:\n            self.set_position(*(int((c - o)*frac + o) for c, o in zip(self._close_pos, self._open_pos)))\n            self._close_fraction = frac\n        except AttributeError:\n            self.log('must close fully before partially to calibrate range', level='warn')\n    def open_partially(self, frac):\n        self.close_partially(1-frac)\n        \n    def get_close_fraction(self):\n        return self._close_fraction\n    \n    def get_open_fraction(self):\n        return 1 - self.get_close_fraction()\n    \n    open_fraction = NotifiedProperty(get_open_fraction, open_partially)\n        \n    \n    def set_position(self, pos, upos):\n        xi.lib.command_move(self.device_id, pos, upos)\n        self._wait()\n\n    def get_position(self):\n        x_pos = xi.get_position_t()\n        xi.lib.get_position(self.device_id, byref(x_pos))\n        return x_pos.Position, x_pos.uPosition\n    position = property(get_position, set_position)\n    \n    def set_speed(self, speed):\n        mvst = xi.move_settings_t()\n        mvst.Speed = int(speed)\n        xi.lib.set_move_settings(self.device_id, byref(mvst))\n\n    def get_speed(self):\n        mvst = xi.move_settings_t()\n        xi.lib.get_move_settings(self.device_id, byref(mvst))\n        return mvst.Speed\n    \n    def get_control_settings(self):\n        cst = xi.control_settings_t()\n        xi.lib.get_control_settings(self.device_id, cst)\n        return cst\n\n    def _test(self):\n        test_info(xi.lib, self.device_id)\n        test_status(xi.lib, self.device_id)\n        test_set_microstep_mode_256(xi.lib, self.device_id)\n        startpos, ustartpos = test_get_position(xi.lib, self.device_id)\n        # first move\n        test_left(xi.lib, self.device_id)\n        time.sleep(3)\n        test_get_position(xi.lib, self.device_id)\n        # second move\n        current_speed = test_get_speed(xi.lib, self.device_id)\n        test_set_speed(xi.lib, self.device_id, current_speed * 2)\n        test_move(xi.lib, self.device_id, startpos, ustartpos)\n        test_wait_for_stop(xi.lib, self.device_id, 100)\n        test_status(xi.lib, self.device_id)\n        test_serial(xi.lib, self.device_id)\n\n    def __del__(self):\n        self._close()\n\n    def _close(self):\n        xi.lib.close_device(byref(xi.cast(self.device_id, POINTER(c_int))))\n        \n    def get_qt_ui(self):\n        return IrisGui(self)",
  "class IrisGui(QuickControlBox):\n    def __init__(self, iris):\n        self.iris = iris\n        super().__init__()\n        self.add_doublespinbox('open_fraction')\n        self.auto_connect_by_name(controlled_object=self.iris)",
  "def __init__(self):\n        super().__init__()\n        self.device_id = xi.lib.open_device(open_name)\n        eng = xi.engine_settings_t()\n        xi.lib.get_engine_settings(self.device_id, byref(eng))\n        eng.MicrostepMode = xi.MicrostepMode.MICROSTEP_MODE_FRAC_256\n        xi.lib.set_engine_settings(self.device_id, byref(eng))\n        self.set_speed(500_000)\n        xi.lib.command_homezero(self.device_id)\n        self._wait()\n        self.close_fully()\n        self.open_fully()",
  "def _wait(self):\n        xi.lib.command_wait_for_stop(self.device_id, 100)",
  "def get_range(self):\n        sst  = xi.stage_settings_t()\n        xi.lib.get_stage_settings(ir.device_id, byref(sst))\n        rang = sst.TravelRange\n        return rang",
  "def _close_fully(self):\n        xi.lib.command_left(self.device_id)",
  "def _open_fully(self):\n        xi.lib.command_right(self.device_id)",
  "def close_fully(self):\n        self._close_fully()\n        self._wait()\n        self._close_pos = self.get_position() # open, closed    \n        self._close_fraction = 1",
  "def open_fully(self):\n        self._open_fully()\n        self._wait()\n        self._close_fraction = 0\n        self._open_pos = self.get_position()",
  "def close_partially(self, frac):\n        try:\n            self.set_position(*(int((c - o)*frac + o) for c, o in zip(self._close_pos, self._open_pos)))\n            self._close_fraction = frac\n        except AttributeError:\n            self.log('must close fully before partially to calibrate range', level='warn')",
  "def open_partially(self, frac):\n        self.close_partially(1-frac)",
  "def get_close_fraction(self):\n        return self._close_fraction",
  "def get_open_fraction(self):\n        return 1 - self.get_close_fraction()",
  "def set_position(self, pos, upos):\n        xi.lib.command_move(self.device_id, pos, upos)\n        self._wait()",
  "def get_position(self):\n        x_pos = xi.get_position_t()\n        xi.lib.get_position(self.device_id, byref(x_pos))\n        return x_pos.Position, x_pos.uPosition",
  "def set_speed(self, speed):\n        mvst = xi.move_settings_t()\n        mvst.Speed = int(speed)\n        xi.lib.set_move_settings(self.device_id, byref(mvst))",
  "def get_speed(self):\n        mvst = xi.move_settings_t()\n        xi.lib.get_move_settings(self.device_id, byref(mvst))\n        return mvst.Speed",
  "def get_control_settings(self):\n        cst = xi.control_settings_t()\n        xi.lib.get_control_settings(self.device_id, cst)\n        return cst",
  "def _test(self):\n        test_info(xi.lib, self.device_id)\n        test_status(xi.lib, self.device_id)\n        test_set_microstep_mode_256(xi.lib, self.device_id)\n        startpos, ustartpos = test_get_position(xi.lib, self.device_id)\n        # first move\n        test_left(xi.lib, self.device_id)\n        time.sleep(3)\n        test_get_position(xi.lib, self.device_id)\n        # second move\n        current_speed = test_get_speed(xi.lib, self.device_id)\n        test_set_speed(xi.lib, self.device_id, current_speed * 2)\n        test_move(xi.lib, self.device_id, startpos, ustartpos)\n        test_wait_for_stop(xi.lib, self.device_id, 100)\n        test_status(xi.lib, self.device_id)\n        test_serial(xi.lib, self.device_id)",
  "def __del__(self):\n        self._close()",
  "def _close(self):\n        xi.lib.close_device(byref(xi.cast(self.device_id, POINTER(c_int))))",
  "def get_qt_ui(self):\n        return IrisGui(self)",
  "def __init__(self, iris):\n        self.iris = iris\n        super().__init__()\n        self.add_doublespinbox('open_fraction')\n        self.auto_connect_by_name(controlled_object=self.iris)",
  "class BaseUi(QtWidgets.QWidget, UiTools):\n    def __init__(self, slm_gui, name):\n        super(BaseUi, self).__init__()\n        uic.loadUi(os.path.join(os.path.dirname(__file__), 'ui_%s.ui' % name), self)\n        self.slm_gui = slm_gui\n        self._connect()\n\n    def _connect(self):\n        return\n\n    def get_params(self):\n        \"\"\"\n        :return: list of parameters to be passed to the pattern_generator of the same name as the class\n        \"\"\"\n        raise NotImplementedError",
  "class constantUi(BaseUi):\n    def __init__(self, slm_gui):\n        super(constantUi, self).__init__(slm_gui, 'constant')\n\n    def _connect(self):\n        self.offset_slider.valueChanged.connect(self.update_offset_lineedit)\n        self.offset_lineEdit.returnPressed.connect(self.update_offset_slider)\n        self.offset_slider.valueChanged.connect(self.slm_gui.make)\n\n    def update_offset_lineedit(self):\n        steps = self.offset_slider.value()\n        value = 2 * steps / 100.\n        self.offset_lineEdit.setText('%g' % value)\n\n    def update_offset_slider(self):\n        value = float(self.offset_lineEdit.text())\n        steps = 100 * value / 2.\n        self.offset_slider.setValue(steps)\n\n    def get_params(self):\n        return np.pi * float(self.offset_lineEdit.text()),",
  "class calibration_responsivenessUi(BaseUi):\n    def __init__(self, slm_gui):\n        super(calibration_responsivenessUi, self).__init__(slm_gui, 'calibration_responsiveness')\n\n    def _connect(self):\n        self.offset_slider.valueChanged.connect(self.update_offset_lineedit)\n        self.offset_lineEdit.returnPressed.connect(self.update_offset_slider)\n\n    def update_offset_lineedit(self):\n        steps = self.offset_slider.value()\n        value = 2 * steps / 100.\n        self.offset_lineEdit.setText('%g' % value)\n\n    def update_offset_slider(self):\n        value = float(self.offset_lineEdit.text())\n        steps = 100 * value / 2.\n        self.offset_slider.setValue(steps)\n\n    def get_params(self):\n        return np.pi * float(self.offset_lineEdit.text()), int(self.spinBox_axis.value())",
  "class gratingsUi(BaseUi):\n    def __init__(self, slm_gui):\n        super(gratingsUi, self).__init__(slm_gui, 'gratings')\n\n    def _connect(self):\n        self.pushButton_center.clicked.connect(lambda: self.update_gratings('center'))\n        self.pushButton_up.clicked.connect(lambda: self.update_gratings('up'))\n        self.pushButton_down.clicked.connect(lambda: self.update_gratings('down'))\n        self.pushButton_left.clicked.connect(lambda: self.update_gratings('left'))\n        self.pushButton_right.clicked.connect(lambda: self.update_gratings('right'))\n        self.gratingx_lineEdit.textChanged.connect(self.slm_gui.make)\n        self.gratingy_lineEdit.textChanged.connect(self.slm_gui.make)\n\n    def update_gratings(self, direction):\n        step = float(self.lineEdit_step.text())\n        grating_x = float(self.gratingx_lineEdit.text())\n        grating_y = float(self.gratingy_lineEdit.text())\n        if direction == 'center':\n            self.gratingx_lineEdit.setText(str(0))\n            self.gratingy_lineEdit.setText(str(0))\n        elif direction == 'up':\n            self.gratingy_lineEdit.setText('%g' % (grating_y + step))\n        elif direction == 'down':\n            self.gratingy_lineEdit.setText('%g' % (grating_y - step))\n        elif direction == 'left':\n            self.gratingx_lineEdit.setText('%g' % (grating_x + step))\n        elif direction == 'right':\n            self.gratingx_lineEdit.setText('%g' % (grating_x - step))\n\n    def get_params(self):\n        grating_x = self.gratingx_lineEdit.text()\n        grating_y = self.gratingy_lineEdit.text()\n        if grating_x == '':\n            grating_x = 0\n        if grating_y == '':\n            grating_y = 0\n        return float(grating_x), float(grating_y)",
  "class astigmatismUi(BaseUi):\n    def __init__(self, slm_gui):\n        super(astigmatismUi, self).__init__(slm_gui, 'astigmatism')\n\n    def _connect(self):\n        self.amplitude_step_lineEdit.returnPressed.connect(self.update_amplitude_lineedit)\n        self.amplitude_offset_lineEdit.returnPressed.connect(self.update_amplitude_lineedit)\n        self.amplitude_slider.valueChanged.connect(self.update_amplitude_lineedit)\n        self.amplitude_lineEdit.returnPressed.connect(self.update_amplitude_slider)\n        self.amplitude_slider.valueChanged.connect(self.slm_gui.make)\n\n        self.angle_step_lineEdit.returnPressed.connect(self.update_angle_lineedit)\n        self.angle_offset_lineEdit.returnPressed.connect(self.update_angle_lineedit)\n        self.angle_slider.valueChanged.connect(self.update_angle_lineedit)\n        self.angle_lineEdit.returnPressed.connect(self.update_angle_slider)\n        self.angle_slider.valueChanged.connect(self.slm_gui.make)\n\n    def update_amplitude_lineedit(self):\n        try:\n            step_size = float(self.amplitude_step_lineEdit.text())\n        except ValueError:\n            amplitude = float(self.amplitude_lineEdit.text())\n            if amplitude != 0:\n                step_size = 0.01 * amplitude\n            else:\n                step_size = 0.0001\n            self.amplitude_step_lineEdit.setText(str(step_size))\n        try:\n            offset = float(self.amplitude_offset_lineEdit.text())\n        except ValueError:\n            offset = float(self.amplitude_lineEdit.text())\n            self.amplitude_offset_lineEdit.setText(str(offset))\n        steps = self.amplitude_slider.value()\n        value = offset + steps * step_size\n\n        self.amplitude_lineEdit.setText('%g' % value)\n\n    def update_amplitude_slider(self):\n        value = float(self.amplitude_lineEdit.text())\n        step_size = float(self.amplitude_step_lineEdit.text())\n        offset = float(self.amplitude_offset_lineEdit.text())\n\n        steps = int(old_div((value - offset), step_size))\n        self.amplitude_slider.setValue(steps)\n\n    def update_angle_lineedit(self):\n        try:\n            step_size = float(self.angle_step_lineEdit.text())\n        except ValueError:\n            step_size = 1\n            self.angle_step_lineEdit.setText(str(step_size))\n        try:\n            offset = float(self.angle_offset_lineEdit.text())\n        except ValueError:\n            offset = float(self.angle_lineEdit.text())\n            self.angle_offset_lineEdit.setText(str(offset))\n        steps = self.angle_slider.value()\n        value = offset + steps * step_size\n\n        self.angle_lineEdit.setText('%g' % value)\n\n    def update_angle_slider(self):\n        value = float(self.angle_lineEdit.text())\n        step_size = float(self.angle_step_lineEdit.text())\n        offset = float(self.angle_offset_lineEdit.text())\n\n        steps = int(old_div((value - offset), step_size))\n        self.angle_slider.setValue(steps)\n\n    def get_params(self):\n        amplitude = float(self.amplitude_lineEdit.text())\n        angle = float(self.angle_lineEdit.text())\n        return amplitude, angle",
  "class focusUi(BaseUi):\n    def __init__(self, slm_gui):\n        super(focusUi, self).__init__(slm_gui, 'focus')\n\n    def _connect(self):\n        # Connects the offset slider to the lineEdits\n        self.lineEdit_step.returnPressed.connect(self.update_lineedit)\n        self.lineEdit_offset.returnPressed.connect(self.update_lineedit)\n        self.slider.valueChanged.connect(self.update_lineedit)\n        self.lineEdit_value.returnPressed.connect(self.update_slider)\n        self.slider.valueChanged.connect(self.slm_gui.make)\n\n    def update_lineedit(self):\n        step_size = float(self.lineEdit_step.text())\n        offset = float(self.lineEdit_offset.text())\n        steps = self.slider.value()\n        value = offset + steps * step_size\n\n        self.lineEdit_value.setText('%g' % value)\n\n    def update_slider(self):\n        value = float(self.lineEdit_value.text())\n        step_size = float(self.lineEdit_step.text())\n        offset = float(self.lineEdit_offset.text())\n\n        steps = int(old_div((value - offset), step_size))\n        self.slider.setValue(steps)\n\n    def get_params(self):\n        curvature = float(self.lineEdit_value.text())\n        return curvature,",
  "class vortexbeamUi(BaseUi):\n    def __init__(self, slm_gui):\n        super(vortexbeamUi, self).__init__(slm_gui, 'vortexbeam')\n\n    def _connect(self):\n        self.pushButton_flip.clicked.connect(self.flip)\n\n        self.slider_angle.valueChanged.connect(lambda: self.lineEdit_angle.setText('%g' % self.slider_angle.value()))\n        self.lineEdit_angle.textChanged.connect(lambda: self.slider_angle.setValue(int(float(self.lineEdit_angle.text()))))\n\n        self.slider_center_x.valueChanged.connect(lambda: self.lineEdit_center_x.setText('%g' % (self.slider_center_x.value()/100)))\n        self.slider_center_y.valueChanged.connect(lambda: self.lineEdit_center_y.setText('%g' % (self.slider_center_y.value()/100)))\n        self.lineEdit_center_x.textChanged.connect(lambda: self.slider_center_x.setValue(int(100*float(self.lineEdit_center_x.text()))))\n        self.lineEdit_center_y.textChanged.connect(lambda: self.slider_center_y.setValue(int(100*float(self.lineEdit_center_y.text()))))\n\n        self.lineEdit_order.textChanged.connect(self.slm_gui.make)\n        self.lineEdit_angle.textChanged.connect(self.slm_gui.make)\n        self.lineEdit_center_x.textChanged.connect(self.slm_gui.make)\n        self.lineEdit_center_y.textChanged.connect(self.slm_gui.make)\n\n    def flip(self):\n        order = int(float(self.lineEdit_order.text()))\n        self.lineEdit_order.setText(str(-order))\n\n    def get_params(self):\n        order = int(float(self.lineEdit_order.text()))\n        angle = float(self.lineEdit_angle.text())\n        center_x = float(self.lineEdit_center_x.text())\n        center_y = float(self.lineEdit_center_y.text())\n        return order, angle, (center_x, center_y)",
  "class multispot_gratingUi(BaseUi):\n    def __init__(self, slm_gui):\n        super(multispot_gratingUi, self).__init__(slm_gui, 'multispot_grating')\n\n    def _connect(self):\n        self.slider_grating.valueChanged.connect(lambda: self.lineEdit_grating.setText('%g' % (self.slider_grating.value()/100)))\n        self.lineEdit_grating.textChanged.connect(lambda: self.slider_grating.setValue(int(100*float(self.lineEdit_grating.text()))))\n\n        self.lineEdit_grating.textChanged.connect(self.slm_gui.make)\n        self.lineEdit_spots.textChanged.connect(self.slm_gui.make)\n\n    def get_params(self):\n        spots = int(float(self.lineEdit_spots.text()))\n        grating = float(self.lineEdit_grating.text())\n        return grating, spots",
  "class linear_lutUi(BaseUi):\n    def __init__(self, slm_gui):\n        super(linear_lutUi, self).__init__(slm_gui, 'linear_lut')\n\n    def _connect(self):\n        # Connects the offset slider to the lineEdits\n        self.offset_lineEdit_step.returnPressed.connect(self.update_offset_lineedit)\n        self.offset_lineEdit_offset.returnPressed.connect(self.update_offset_lineedit)\n        self.offset_slider.valueChanged.connect(self.update_offset_lineedit)\n        self.offset_lineEdit.returnPressed.connect(self.update_offset_slider)\n        self.offset_slider.valueChanged.connect(self.slm_gui.make)\n\n        # Connects the contrast slider to the lineEdits\n        self.contrast_lineEdit_step.returnPressed.connect(self.update_contrast_lineedit)\n        self.contrast_lineEdit_offset.returnPressed.connect(self.update_contrast_lineedit)\n        self.contrast_slider.valueChanged.connect(self.update_contrast_lineedit)\n        self.contrast_lineEdit.returnPressed.connect(self.update_contrast_slider)\n        self.contrast_slider.valueChanged.connect(self.slm_gui.make)\n\n    def update_offset_lineedit(self):\n        step_size = float(self.offset_lineEdit_step.text())\n        offset = float(self.offset_lineEdit_offset.text())\n        steps = self.offset_slider.value()\n        value = offset + steps * step_size\n\n        self.offset_lineEdit.setText('%g' % value)\n\n    def update_offset_slider(self):\n        value = float(self.offset_lineEdit.text())\n        step_size = float(self.offset_lineEdit_step.text())\n        offset = float(self.offset_lineEdit_offset.text())\n\n        steps = int(old_div((value - offset), step_size))\n        self.offset_slider.setValue(steps)\n\n    def update_contrast_lineedit(self):\n        step_size = float(self.contrast_lineEdit_step.text())\n        offset = float(self.contrast_lineEdit_offset.text())\n        steps = self.contrast_slider.value()\n        value = offset + steps * step_size\n\n        self.contrast_lineEdit.setText('%g' % value)\n\n    def update_contrast_slider(self):\n        value = float(self.contrast_lineEdit.text())\n        step_size = float(self.contrast_lineEdit_step.text())\n        offset = float(self.contrast_lineEdit_offset.text())\n\n        steps = int(old_div((value - offset), step_size))\n        self.contrast_slider.setValue(steps)\n\n    def get_params(self):\n        contrast = float(self.contrast_lineEdit.text())\n        offset = float(self.offset_lineEdit.text())\n        return contrast, offset",
  "def __init__(self, slm_gui, name):\n        super(BaseUi, self).__init__()\n        uic.loadUi(os.path.join(os.path.dirname(__file__), 'ui_%s.ui' % name), self)\n        self.slm_gui = slm_gui\n        self._connect()",
  "def _connect(self):\n        return",
  "def get_params(self):\n        \"\"\"\n        :return: list of parameters to be passed to the pattern_generator of the same name as the class\n        \"\"\"\n        raise NotImplementedError",
  "def __init__(self, slm_gui):\n        super(constantUi, self).__init__(slm_gui, 'constant')",
  "def _connect(self):\n        self.offset_slider.valueChanged.connect(self.update_offset_lineedit)\n        self.offset_lineEdit.returnPressed.connect(self.update_offset_slider)\n        self.offset_slider.valueChanged.connect(self.slm_gui.make)",
  "def update_offset_lineedit(self):\n        steps = self.offset_slider.value()\n        value = 2 * steps / 100.\n        self.offset_lineEdit.setText('%g' % value)",
  "def update_offset_slider(self):\n        value = float(self.offset_lineEdit.text())\n        steps = 100 * value / 2.\n        self.offset_slider.setValue(steps)",
  "def get_params(self):\n        return np.pi * float(self.offset_lineEdit.text()),",
  "def __init__(self, slm_gui):\n        super(calibration_responsivenessUi, self).__init__(slm_gui, 'calibration_responsiveness')",
  "def _connect(self):\n        self.offset_slider.valueChanged.connect(self.update_offset_lineedit)\n        self.offset_lineEdit.returnPressed.connect(self.update_offset_slider)",
  "def update_offset_lineedit(self):\n        steps = self.offset_slider.value()\n        value = 2 * steps / 100.\n        self.offset_lineEdit.setText('%g' % value)",
  "def update_offset_slider(self):\n        value = float(self.offset_lineEdit.text())\n        steps = 100 * value / 2.\n        self.offset_slider.setValue(steps)",
  "def get_params(self):\n        return np.pi * float(self.offset_lineEdit.text()), int(self.spinBox_axis.value())",
  "def __init__(self, slm_gui):\n        super(gratingsUi, self).__init__(slm_gui, 'gratings')",
  "def _connect(self):\n        self.pushButton_center.clicked.connect(lambda: self.update_gratings('center'))\n        self.pushButton_up.clicked.connect(lambda: self.update_gratings('up'))\n        self.pushButton_down.clicked.connect(lambda: self.update_gratings('down'))\n        self.pushButton_left.clicked.connect(lambda: self.update_gratings('left'))\n        self.pushButton_right.clicked.connect(lambda: self.update_gratings('right'))\n        self.gratingx_lineEdit.textChanged.connect(self.slm_gui.make)\n        self.gratingy_lineEdit.textChanged.connect(self.slm_gui.make)",
  "def update_gratings(self, direction):\n        step = float(self.lineEdit_step.text())\n        grating_x = float(self.gratingx_lineEdit.text())\n        grating_y = float(self.gratingy_lineEdit.text())\n        if direction == 'center':\n            self.gratingx_lineEdit.setText(str(0))\n            self.gratingy_lineEdit.setText(str(0))\n        elif direction == 'up':\n            self.gratingy_lineEdit.setText('%g' % (grating_y + step))\n        elif direction == 'down':\n            self.gratingy_lineEdit.setText('%g' % (grating_y - step))\n        elif direction == 'left':\n            self.gratingx_lineEdit.setText('%g' % (grating_x + step))\n        elif direction == 'right':\n            self.gratingx_lineEdit.setText('%g' % (grating_x - step))",
  "def get_params(self):\n        grating_x = self.gratingx_lineEdit.text()\n        grating_y = self.gratingy_lineEdit.text()\n        if grating_x == '':\n            grating_x = 0\n        if grating_y == '':\n            grating_y = 0\n        return float(grating_x), float(grating_y)",
  "def __init__(self, slm_gui):\n        super(astigmatismUi, self).__init__(slm_gui, 'astigmatism')",
  "def _connect(self):\n        self.amplitude_step_lineEdit.returnPressed.connect(self.update_amplitude_lineedit)\n        self.amplitude_offset_lineEdit.returnPressed.connect(self.update_amplitude_lineedit)\n        self.amplitude_slider.valueChanged.connect(self.update_amplitude_lineedit)\n        self.amplitude_lineEdit.returnPressed.connect(self.update_amplitude_slider)\n        self.amplitude_slider.valueChanged.connect(self.slm_gui.make)\n\n        self.angle_step_lineEdit.returnPressed.connect(self.update_angle_lineedit)\n        self.angle_offset_lineEdit.returnPressed.connect(self.update_angle_lineedit)\n        self.angle_slider.valueChanged.connect(self.update_angle_lineedit)\n        self.angle_lineEdit.returnPressed.connect(self.update_angle_slider)\n        self.angle_slider.valueChanged.connect(self.slm_gui.make)",
  "def update_amplitude_lineedit(self):\n        try:\n            step_size = float(self.amplitude_step_lineEdit.text())\n        except ValueError:\n            amplitude = float(self.amplitude_lineEdit.text())\n            if amplitude != 0:\n                step_size = 0.01 * amplitude\n            else:\n                step_size = 0.0001\n            self.amplitude_step_lineEdit.setText(str(step_size))\n        try:\n            offset = float(self.amplitude_offset_lineEdit.text())\n        except ValueError:\n            offset = float(self.amplitude_lineEdit.text())\n            self.amplitude_offset_lineEdit.setText(str(offset))\n        steps = self.amplitude_slider.value()\n        value = offset + steps * step_size\n\n        self.amplitude_lineEdit.setText('%g' % value)",
  "def update_amplitude_slider(self):\n        value = float(self.amplitude_lineEdit.text())\n        step_size = float(self.amplitude_step_lineEdit.text())\n        offset = float(self.amplitude_offset_lineEdit.text())\n\n        steps = int(old_div((value - offset), step_size))\n        self.amplitude_slider.setValue(steps)",
  "def update_angle_lineedit(self):\n        try:\n            step_size = float(self.angle_step_lineEdit.text())\n        except ValueError:\n            step_size = 1\n            self.angle_step_lineEdit.setText(str(step_size))\n        try:\n            offset = float(self.angle_offset_lineEdit.text())\n        except ValueError:\n            offset = float(self.angle_lineEdit.text())\n            self.angle_offset_lineEdit.setText(str(offset))\n        steps = self.angle_slider.value()\n        value = offset + steps * step_size\n\n        self.angle_lineEdit.setText('%g' % value)",
  "def update_angle_slider(self):\n        value = float(self.angle_lineEdit.text())\n        step_size = float(self.angle_step_lineEdit.text())\n        offset = float(self.angle_offset_lineEdit.text())\n\n        steps = int(old_div((value - offset), step_size))\n        self.angle_slider.setValue(steps)",
  "def get_params(self):\n        amplitude = float(self.amplitude_lineEdit.text())\n        angle = float(self.angle_lineEdit.text())\n        return amplitude, angle",
  "def __init__(self, slm_gui):\n        super(focusUi, self).__init__(slm_gui, 'focus')",
  "def _connect(self):\n        # Connects the offset slider to the lineEdits\n        self.lineEdit_step.returnPressed.connect(self.update_lineedit)\n        self.lineEdit_offset.returnPressed.connect(self.update_lineedit)\n        self.slider.valueChanged.connect(self.update_lineedit)\n        self.lineEdit_value.returnPressed.connect(self.update_slider)\n        self.slider.valueChanged.connect(self.slm_gui.make)",
  "def update_lineedit(self):\n        step_size = float(self.lineEdit_step.text())\n        offset = float(self.lineEdit_offset.text())\n        steps = self.slider.value()\n        value = offset + steps * step_size\n\n        self.lineEdit_value.setText('%g' % value)",
  "def update_slider(self):\n        value = float(self.lineEdit_value.text())\n        step_size = float(self.lineEdit_step.text())\n        offset = float(self.lineEdit_offset.text())\n\n        steps = int(old_div((value - offset), step_size))\n        self.slider.setValue(steps)",
  "def get_params(self):\n        curvature = float(self.lineEdit_value.text())\n        return curvature,",
  "def __init__(self, slm_gui):\n        super(vortexbeamUi, self).__init__(slm_gui, 'vortexbeam')",
  "def _connect(self):\n        self.pushButton_flip.clicked.connect(self.flip)\n\n        self.slider_angle.valueChanged.connect(lambda: self.lineEdit_angle.setText('%g' % self.slider_angle.value()))\n        self.lineEdit_angle.textChanged.connect(lambda: self.slider_angle.setValue(int(float(self.lineEdit_angle.text()))))\n\n        self.slider_center_x.valueChanged.connect(lambda: self.lineEdit_center_x.setText('%g' % (self.slider_center_x.value()/100)))\n        self.slider_center_y.valueChanged.connect(lambda: self.lineEdit_center_y.setText('%g' % (self.slider_center_y.value()/100)))\n        self.lineEdit_center_x.textChanged.connect(lambda: self.slider_center_x.setValue(int(100*float(self.lineEdit_center_x.text()))))\n        self.lineEdit_center_y.textChanged.connect(lambda: self.slider_center_y.setValue(int(100*float(self.lineEdit_center_y.text()))))\n\n        self.lineEdit_order.textChanged.connect(self.slm_gui.make)\n        self.lineEdit_angle.textChanged.connect(self.slm_gui.make)\n        self.lineEdit_center_x.textChanged.connect(self.slm_gui.make)\n        self.lineEdit_center_y.textChanged.connect(self.slm_gui.make)",
  "def flip(self):\n        order = int(float(self.lineEdit_order.text()))\n        self.lineEdit_order.setText(str(-order))",
  "def get_params(self):\n        order = int(float(self.lineEdit_order.text()))\n        angle = float(self.lineEdit_angle.text())\n        center_x = float(self.lineEdit_center_x.text())\n        center_y = float(self.lineEdit_center_y.text())\n        return order, angle, (center_x, center_y)",
  "def __init__(self, slm_gui):\n        super(multispot_gratingUi, self).__init__(slm_gui, 'multispot_grating')",
  "def _connect(self):\n        self.slider_grating.valueChanged.connect(lambda: self.lineEdit_grating.setText('%g' % (self.slider_grating.value()/100)))\n        self.lineEdit_grating.textChanged.connect(lambda: self.slider_grating.setValue(int(100*float(self.lineEdit_grating.text()))))\n\n        self.lineEdit_grating.textChanged.connect(self.slm_gui.make)\n        self.lineEdit_spots.textChanged.connect(self.slm_gui.make)",
  "def get_params(self):\n        spots = int(float(self.lineEdit_spots.text()))\n        grating = float(self.lineEdit_grating.text())\n        return grating, spots",
  "def __init__(self, slm_gui):\n        super(linear_lutUi, self).__init__(slm_gui, 'linear_lut')",
  "def _connect(self):\n        # Connects the offset slider to the lineEdits\n        self.offset_lineEdit_step.returnPressed.connect(self.update_offset_lineedit)\n        self.offset_lineEdit_offset.returnPressed.connect(self.update_offset_lineedit)\n        self.offset_slider.valueChanged.connect(self.update_offset_lineedit)\n        self.offset_lineEdit.returnPressed.connect(self.update_offset_slider)\n        self.offset_slider.valueChanged.connect(self.slm_gui.make)\n\n        # Connects the contrast slider to the lineEdits\n        self.contrast_lineEdit_step.returnPressed.connect(self.update_contrast_lineedit)\n        self.contrast_lineEdit_offset.returnPressed.connect(self.update_contrast_lineedit)\n        self.contrast_slider.valueChanged.connect(self.update_contrast_lineedit)\n        self.contrast_lineEdit.returnPressed.connect(self.update_contrast_slider)\n        self.contrast_slider.valueChanged.connect(self.slm_gui.make)",
  "def update_offset_lineedit(self):\n        step_size = float(self.offset_lineEdit_step.text())\n        offset = float(self.offset_lineEdit_offset.text())\n        steps = self.offset_slider.value()\n        value = offset + steps * step_size\n\n        self.offset_lineEdit.setText('%g' % value)",
  "def update_offset_slider(self):\n        value = float(self.offset_lineEdit.text())\n        step_size = float(self.offset_lineEdit_step.text())\n        offset = float(self.offset_lineEdit_offset.text())\n\n        steps = int(old_div((value - offset), step_size))\n        self.offset_slider.setValue(steps)",
  "def update_contrast_lineedit(self):\n        step_size = float(self.contrast_lineEdit_step.text())\n        offset = float(self.contrast_lineEdit_offset.text())\n        steps = self.contrast_slider.value()\n        value = offset + steps * step_size\n\n        self.contrast_lineEdit.setText('%g' % value)",
  "def update_contrast_slider(self):\n        value = float(self.contrast_lineEdit.text())\n        step_size = float(self.contrast_lineEdit_step.text())\n        offset = float(self.contrast_lineEdit_offset.text())\n\n        steps = int(old_div((value - offset), step_size))\n        self.contrast_slider.setValue(steps)",
  "def get_params(self):\n        contrast = float(self.contrast_lineEdit.text())\n        offset = float(self.offset_lineEdit.text())\n        return contrast, offset",
  "def _get_coordinate_arrays(image, center=None):\n    \"\"\"Creates coordinate arrays in pixel units\n    :param image: 2D array\n    :param center: two-tuple of floats. If <1, assumes it's a relative center (with the edges of the SLM being at\n                                        [-1, 1]. Otherwise, it should be in pixel units\n    :return: two 2D arrays of coordinates\n    \"\"\"\n    shape = np.shape(image)\n    if center is None:\n        center = [int(old_div(s, 2)) for s in shape]\n    elif any(np.array(center) < 1):\n        center = [int(old_div(s, 2) + c*s) for s, c in zip(shape, center)]\n    yx = [np.arange(shape[idx]) - center[idx] for idx in range(2)[::-1]]\n    x, y = np.meshgrid(*yx)\n    return x, y",
  "def constant(input_phase, offset):\n    return input_phase + offset",
  "def calibration_responsiveness(input_phase, grey_level, axis=0):\n    \"\"\"Function for calibrating the phase retardation as a function of addressing voltage\n    Need to image the reflected beam directly onto a camera, creating fringes. The fringe shift as a function of voltage\n    gives the responsiveness. Note it assumes the retardation is the same across the SLM. If this were not the case, see\n    https://doi.org/10.1364/AO.43.006400 for how to measure it.\n\n    :param input_phase:\n    :param grey_level:\n    :param axis:\n    :return:\n    \"\"\"\n    shape = np.shape(input_phase)\n    centers = [int(old_div(x, 2)) for x in shape]\n    out_phase = np.zeros(shape)\n    if axis == 0:\n        out_phase[centers[0]:] = grey_level\n    elif axis == 1:\n        out_phase[:, centers[1]:] = grey_level\n    else:\n        raise ValueError('Unrecognised axis: %d' % axis)\n    return out_phase",
  "def gratings(input_phase, grating_const_x=0, grating_const_y=0):\n    \"\"\"Linear phase pattern corresponding to a grating/mirror\n\n    :param input_phase:\n    :param grating_const_x: float. Period (in pixels) of the grating along the x direction. Default is no grating\n    :param grating_const_y: float. Period (in pixels) of the grating along the y direction. Default is no grating\n    :return:\n    \"\"\"\n    x, y = _get_coordinate_arrays(input_phase)\n    phase = np.zeros(x.shape)\n    if np.abs(grating_const_x) > 1:\n        phase += (2 * np.pi / grating_const_x) * x\n    if np.abs(grating_const_y) > 1:\n        phase += (2 * np.pi / grating_const_y) * y\n\n    return input_phase + phase",
  "def multispot_grating(input_phase, grating_const, n_spot, center=None):\n    \"\"\"\n\n    :param input_phase:\n    :param grating_const: float. Inverse period (in pixels) of the grating.\n    :param n_spot: int. Number of gratings to divide the SLM in.\n    :param center: two-tuple of floats. To be passed to _get_coordinate_arrays\n    :return:\n    \"\"\"\n    x, y = _get_coordinate_arrays(input_phase, center)\n    theta = np.arctan2(y, x) + np.pi\n\n    phase = np.zeros(x.shape)\n    if n_spot > 1:\n        for i in range(n_spot):\n            gx = np.pi * grating_const * np.cos((i + 0.5) * 2 * np.pi / n_spot)\n            gy = np.pi * grating_const * np.sin((i + 0.5) * 2 * np.pi / n_spot)\n            mask = np.zeros(x.shape)\n            mask[theta <= (i+1) * 2 * np.pi / n_spot] = 1\n            mask[theta <= i * 2 * np.pi / n_spot] = 0\n            phase += (x * gx + y * gy) * mask\n    return input_phase + phase",
  "def focus(input_phase, curvature=0, center=None):\n    \"\"\"Quadratic phase pattern corresponding to a perfect lens\n\n    :param input_phase:\n    :param curvature: float. Inverse focal length of the lens in arbitrary units\n    :param center: two-tuple of floats. To be passed to _get_coordinate_arrays\n    :return:\n    \"\"\"\n    x, y = _get_coordinate_arrays(input_phase, center)\n    phase = curvature * (x ** 2 + y ** 2)\n    return input_phase + phase",
  "def astigmatism(input_phase, amplitude=0, angle=0, center=None):\n    \"\"\"Cylindrical phase pattern corresponding to astigmatism\n\n    :param input_phase:\n    :param amplitude: float. cylindrical curvature\n    :param angle: float. angle between the cylindrical curvature and the input axes\n    :param center: two-tuple of floats. To be passed to _get_coordinate_arrays\n    :return:\n    \"\"\"\n    x, y = _get_coordinate_arrays(input_phase, center)\n    rho = np.sqrt(x ** 2 + y ** 2)\n    phi = np.arctan2(x, y)\n\n    horizontal = amplitude * np.cos(angle * np.pi / 180)\n    diagonal = amplitude * np.sin(angle * np.pi / 180)\n\n    phase = (horizontal * np.cos(2 * phi) + diagonal * np.sin(2 * phi)) * rho ** 2\n\n    return input_phase + phase",
  "def vortexbeam(input_phase, order, angle, center=None):\n    \"\"\"Vortices\n\n    :param input_phase:\n    :param order: int. Vortex order\n    :param angle: float. Orientation of the vortex, in degrees\n    :param center: two-iterable of integers. Location of the center of the vortex on the SLM panel\n    :return:\n    \"\"\"\n    # shape = np.shape(input_phase)\n    # if center is None:\n    #     center = [int(old_div(x, 2)) for x in shape]\n    # elif any(np.array(center) < 1):\n    #     center = [int(old_div(x, 2) + y*x) for x, y in zip(shape, center)]\n    #\n    # x = np.arange(shape[1]) - center[1]\n    # y = np.arange(shape[0]) - center[0]\n    # x, y = np.meshgrid(x, y)\n    x, y = _get_coordinate_arrays(input_phase, center)\n\n    phase = order * (np.angle(x + y * 1j) + angle * np.pi / 180.)\n\n    return input_phase + phase",
  "def linear_lut(input_phase, contrast, offset):\n    \"\"\"\n\n    :param input_phase:\n    :param contrast:\n    :param offset:\n    :return:\n    \"\"\"\n    out_phase = np.copy(input_phase)\n    # out_phase -= out_phase.min()\n    out_phase %= 2 * np.pi - 0.000001\n    out_phase *= contrast\n    out_phase += offset * np.pi\n    return out_phase",
  "def direct_superposition(input_phase, k_vectors, phases=None):\n    if phases is None:\n        phases = np.random.random(len(k_vectors))\n    shape = np.shape(input_phase)\n    x = np.arange(shape[1]) - int(old_div(shape[1], 2))\n    y = np.arange(shape[0]) - int(old_div(shape[0], 2))\n    x, y = np.meshgrid(x, y)\n\n    real_plane = np.zeros(shape)\n    for k_vec, phase in zip(k_vectors, phases):\n        real_plane += np.exp(1j * 2 * np.pi * (k_vec[0] * x + k_vec[1] * y + phase))\n\n    return input_phase + np.angle(np.fft.fftshift(np.fft.fft2(real_plane)))",
  "def mraf(original_phase, target_intensity, input_field=None, mixing_ratio=0.4, signal_region_size=0.5, iterations=30):\n    \"\"\"Mixed-Region Amplitude Freedom algorithm for continuous patterns https://doi.org/10.1364/OE.16.002176\n\n    :param original_phase:\n    :param target_intensity:\n    :param input_field:\n    :param mixing_ratio:\n    :param signal_region_size:\n    :param iterations:\n    :return:\n    \"\"\"\n    shp = target_intensity.shape\n    x, y = np.ogrid[old_div(-shp[1], 2):old_div(shp[1], 2), old_div(-shp[0], 2):old_div(shp[0], 2)]\n    x, y = np.meshgrid(x, y)\n\n    target_intensity = np.asarray(target_intensity, np.float)\n    if input_field is None:\n        # By default, the initial phase focuses a uniform SLM illumination onto the signal region\n        input_phase = ((old_div(x ** 2, (old_div(shp[1], (signal_region_size * 2 * np.sqrt(2)))))) +\n                       (old_div(y ** 2, (old_div(shp[0], (signal_region_size * 2 * np.sqrt(2)))))))\n        input_field = np.exp(1j * input_phase)\n    # Normalising the input field and target intensity to 1 (doesn't have to be 1, but they have to be equal)\n    input_field /= np.sqrt(np.sum(np.abs(input_field)**2))\n    target_intensity /= np.sum(target_intensity)\n\n    # This can leave the center of the SLM one or two pixels\n    mask = (x**2 + y**2) < (signal_region_size * np.min(shp))**2\n    signal_region = np.ones(shp) * mixing_ratio\n    signal_region[~mask] = 0\n    noise_region = np.ones(shp) * (1 - mixing_ratio)\n    noise_region[mask] = 0\n    input_intensity = np.abs(input_field)**2\n\n    for _ in range(iterations):\n        output_field = np.fft.fft2(input_field)\n        # makes sure power out = power in, so that the distribution of power in signal and noise regions makes sense\n        output_field = old_div(output_field, np.sqrt(np.prod(shp)))\n        output_field = np.fft.fftshift(output_field)\n        output_phase = np.angle(output_field)\n\n        mixed_field = signal_region * np.sqrt(target_intensity) * np.exp(1j * output_phase) + noise_region * output_field\n        mixed_field = np.fft.ifftshift(mixed_field)\n\n        input_field = np.fft.ifft2(mixed_field)\n        input_phase = np.angle(input_field)\n        input_field = np.sqrt(input_intensity) * np.exp(1j*input_phase)\n        # print(np.sum(np.abs(input_field)**2), np.sum(target_intensity), np.sum(np.abs(output_field)**2))\n    return original_phase + input_phase",
  "def gerchberg_saxton(original_phase, target_intensity, input_field=None, iterations=30):\n    \"\"\"Gerchberg Saxton algorithm for continuous patterns\n\n    Easiest version, where you don't need to keep track of FFT factors, normalising intensities, or FFT shifts since it\n    all gets discarded anyway.\n\n    :param original_phase:\n    :param target_intensity:\n    :param input_field:\n    :param iterations:\n    :return:\n    \"\"\"\n    assert iterations > 0\n    shp = target_intensity.shape\n    target_intensity = np.fft.fftshift(target_intensity)  # this matrix is only used in the Fourier plane\n    if input_field is None:\n        input_field = np.ones(shp) * np.exp(1j * np.zeros(shp))\n    input_intensity = np.abs(input_field) ** 2\n    for _ in range(iterations):\n        output_field = np.fft.fft2(input_field)  # don't have to normalise since the intensities are replaced\n        output_phase = np.angle(output_field)\n        output_field = np.sqrt(target_intensity) * np.exp(1j * output_phase)\n\n        input_field = np.fft.ifft2(output_field)\n        input_phase = np.angle(input_field)\n        input_field = np.sqrt(input_intensity) * np.exp(1j * input_phase)\n    return original_phase + input_phase",
  "def test_ifft_smoothness(alg_func, *args, **kwargs):\n    \"\"\"Evaluates smoothness of calculated vs target pattern as a function of iteration in an IFFT algorithm\n\n    Smoothness is defined as the sum of absolute difference over the area of interest. For most algorithms the area of\n    interest is the whole plane, while for MRAF the area of interest is only the signal region\n\n    :param alg_func:\n    :param args:\n    :param kwargs:\n    :return:\n    \"\"\"\n    target = np.asarray(misc.face()[:, :, 0], np.float)\n    x, y = _get_coordinate_arrays(target)\n    shp = target.shape\n    # x, y = np.ogrid[old_div(-shp[1], 2):old_div(shp[1], 2), old_div(-shp[0], 2):old_div(shp[0], 2)]\n    # x, y = np.meshgrid(x, y)\n    mask = (x**2 + y**2) > (0.2 * np.min(shp))**2\n    target[mask] = 0\n    target /= np.sum(target)\n\n    iterations = 60\n    if 'iterations' in kwargs:\n        iterations = kwargs['iterations']\n    # The algorithms only return the final phase, so to evaluate the smoothness at each iteration, need to set the\n    # algorithm to only run one step at a time\n    kwargs['iterations'] = 1\n\n    # Defining a mask and a mixing_ratio for calculating the smoothness later\n    if alg_func == gerchberg_saxton:\n        mask = np.ones(shp, dtype=np.bool)\n        mixing_ratio = 1\n    elif alg_func == mraf:\n        x, y = np.ogrid[old_div(-shp[1], 2):old_div(shp[1], 2), old_div(-shp[0], 2):old_div(shp[0], 2)]\n        x, y = np.meshgrid(x, y)\n        signal_region_size = 0.5\n        if 'signal_region_size' in kwargs:\n            signal_region_size = kwargs['signal_region_size']\n        mask = (x**2 + y**2) < (signal_region_size * np.min(shp))**2\n        mixing_ratio = 0.4\n        if 'mixing_ratio' in kwargs:\n            mixing_ratio = kwargs['mixing_ratio']\n    else:\n        raise ValueError('Unrecognised algorithm')\n\n    smth = []\n    outputs = []\n    for indx in range(iterations):\n        init_phase = alg_func(0, target, *args, **kwargs)\n        input_field = np.exp(1j * init_phase)\n        kwargs['input_field'] = input_field\n        output = old_div(np.fft.fftshift(np.fft.fft2(np.exp(1j * init_phase))), (np.prod(shp)))\n        output_int = np.abs(output) ** 2\n        # print(np.sum(np.abs(output_int)), np.sum(np.abs(output_int)[mask]))\n        smth += [old_div(np.sum(np.abs(output_int - mixing_ratio*target)[mask]), np.sum(mask))]\n        outputs += [output]\n\n    fig = plt.figure(figsize=(old_div(8*shp[1],shp[0])*2, 8))\n    gs = gridspec.GridSpec(1, 2)\n    gs2 = gridspec.GridSpecFromSubplotSpec(5, 6, gs[0], 0.001, 0.001)\n    reindex = np.linspace(0, iterations-1, 30)\n    ax = None\n    for indx, _gs in zip(reindex, gs2):\n        indx = int(indx)\n        ax = plt.subplot(_gs, sharex=ax, sharey=ax)\n        ax.imshow(np.abs(outputs[indx]))\n        ax.text(shp[1]/2., 0, '%d=%.3g' % (indx, smth[indx]), ha='center', va='top', color='w')\n        ax.set_xticklabels([])\n        ax.set_yticklabels([])\n    ax2 = plt.subplot(gs[1])\n    ax2.semilogy(smth)\n    return np.array(smth)",
  "def test_ifft_basic(alg_func, *args, **kwargs):\n    \"\"\"Basic testing for IFFT algorithms to see if the final phase truly reproduces an initial target\n\n    Creates an image target (the center of the scipy.misc.face() image), runs the alg_func on it, and plots the results\n    for comparison by eye\n\n    :param alg_func:\n    :param args:\n    :param kwargs:\n    :return:\n    \"\"\"\n    if 'mixing_ratio' in kwargs:\n        intensity_correction = kwargs['mixing_ratio']\n    else:\n        intensity_correction = 1\n    target = np.asarray(misc.face()[:, :, 0], np.float)\n    x, y = _get_coordinate_arrays(target)\n    shp = target.shape\n    # x, y = np.ogrid[old_div(-shp[1], 2):old_div(shp[1], 2), old_div(-shp[0], 2):old_div(shp[0], 2)]\n    # x, y = np.meshgrid(x, y)\n    mask_size = 0.2\n    mask = (x**2 + y**2) > (mask_size * np.min(shp))**2\n    target[mask] = 0\n    target /= np.sum(target)  # the target intensity is normalised to 1\n\n    init_phase = np.zeros(target.shape)\n    # Making an input field that focuses light on the target pattern reduces vortex creation and improves pattern\n    input_field = np.ones(shp) * np.exp(1j * 2*mask_size*np.min(shp) * ((x/np.max(x))**2+(y/np.max(y))**2))\n    kwargs['input_field'] = input_field\n    phase = alg_func(init_phase, target, *args, **kwargs)\n    output = old_div(np.fft.fftshift(np.fft.fft2(np.exp(1j * phase))), (np.prod(shp)))\n    print(np.sum(np.abs(output)**2), np.sum(np.abs(output[~mask])**2), np.sum(np.abs(output[mask])**2))\n    _errors = (target - np.abs(output)**2) / target\n    errors = _errors[np.abs(_errors) != np.inf]\n    avg = np.sqrt(np.mean(errors**2))\n\n    fig, axs = plt.subplots(2, 2, sharey=True, sharex=True, gridspec_kw=dict(wspace=0.01))\n    vmin, vmax = (np.min(target), np.max(target))\n    axs[0, 0].imshow(target, vmin=vmin, vmax=vmax)\n    axs[0, 0].set_title('Target')\n    axs[1, 0].imshow(phase)\n    axs[1, 0].set_title('Input Phase')\n    vmin *= intensity_correction\n    vmax *= intensity_correction\n    axs[0, 1].imshow(np.abs(output)**2, vmin=vmin, vmax=vmax)\n    axs[0, 1].set_title('Output')\n    axs[1, 1].imshow(np.angle(output))\n    axs[1, 1].set_title('Output Phase')\n    fig.suptitle(r'$\\sqrt{\\sum\\left(\\frac{target-output}{target}\\right)^2}=$%g' % avg)\n    plt.show()\n\n    return output, target",
  "def zernike_polynomial(array_size, n, m, beam_size=1, unit_circle=True):\n    \"\"\"\n    Creates an image of a Zernike polynomial of order n,m (https://en.wikipedia.org/wiki/Zernike_polynomials)\n    Keep in mind that they are technically only defined inside the unit circle, but the output of this function is a\n    square, so the corners are wrong.\n\n    :param array_size: int\n    :param n: int\n    :param m: int\n    :param beam_size: float\n    :param unit_circle: bool\n    :return:\n    \"\"\"\n    assert n >= 0\n    if m < 0:\n        odd = True\n        m = np.abs(m)\n    else:\n        odd = False\n    assert n >= m\n\n    if type(array_size) == int:\n        array_size = (array_size, array_size)\n    im_rat = array_size[1]/array_size[0]\n    if im_rat >= 1:\n        _x = np.linspace(-im_rat, im_rat, array_size[1])\n        _y = np.linspace(-1, 1, array_size[0])\n    else:\n        _x = np.linspace(-1, 1, array_size[1])\n        _y = np.linspace(-1/im_rat, 1/im_rat, array_size[0])\n    x, y = np.meshgrid(_x, _y)\n    # By normalising the radius to the beamsize, we can make Zernike polynomials of different sizes\n    rho = old_div(np.sqrt(x**2 + y**2), beam_size)\n    phi = np.arctan2(x, y)\n\n    summ = []\n    for k in range(1 + old_div((n - m), 2)):\n        summ += [old_div(((-1)**k * math.factorial(n - k) * (rho**(n-2*k))),\n                 (math.factorial(k) * math.factorial(old_div((n+m), 2) - k) * math.factorial(old_div((n-m), 2) - k)))]\n    r = np.sum(summ, 0)\n    if (n-m) % 2:\n        r = 0\n\n    # Limiting the polynomial to the unit circle, where it is defined:\n    if unit_circle:\n        r[rho > 1] = 0\n\n    if odd:\n        zernike = r * np.sin(m * phi)\n    else:\n        zernike = r * np.cos(m * phi)\n\n    normalised = zernike / np.sqrt(np.sum(zernike[rho < 1] * zernike[rho < 1]))\n    return normalised",
  "class SlmDisplay(QtWidgets.QWidget):\n    \"\"\"Widget for displaying the greyscale holograms on the SLM\n    It is simply a plain window with a QImage + QLabel.setPixmap combination for displaying phase arrays\n    \"\"\"\n    update_image = QtCore.Signal(np.ndarray)\n\n    def __init__(self, shape=(1000, 1000), resolution=(1, 1), bitness=8, hide_border=True, lut=None):\n        \"\"\"\n        :param shape: 2-tuple of int. Width and height of the SLM panel in pixels\n        :param resolution:\n        :param bitness: int. Number of addressing levels of the SLM\n        :param hide_border: bool. Whether to show the standard window border in your OS. Set to False only for debugging\n        :param lut: tuple. Parameters passed to set_lut. The default LUT assumes that the phase goes from 0 to 2 pi, and\n        we want to display it from 0 to 256\n        \"\"\"\n        super(SlmDisplay, self).__init__()\n\n        self._pixels = [int(old_div(x[0], x[1])) for x in zip(shape, resolution)]\n        self._bitness = bitness\n\n        self._QImage = None\n        self._QLabel = None\n        self._make_gui(hide_border)\n\n        self.LUT = None\n        if lut is None:\n            lut = (2**self._bitness, 0)\n        self.set_lut(lut)\n\n        self.update_image.connect(self._set_image, type=QtCore.Qt.QueuedConnection)\n\n    def _make_gui(self, hide_border=True):\n        \"\"\"Creates and sets the widget layout\n        :param hide_border: bool. See __init__\n        :return:\n        \"\"\"\n        self._QLabel = QtWidgets.QLabel(self)\n\n        layout = QtWidgets.QHBoxLayout(self)\n        layout.setContentsMargins(0, 0, 0, 0)\n        layout.addWidget(self._QLabel)\n        self.setLayout(layout)\n\n        self.setWindowTitle('SLM Phase')\n        if hide_border:\n            self.setWindowFlags(QtCore.Qt.CustomizeWindowHint | QtCore.Qt.FramelessWindowHint | QtCore.Qt.WindowStaysOnTopHint)\n\n    def set_lut(self, lut):\n        if type(lut) == str:\n            lut = np.loadtxt(lut)\n\n        lut = np.array(lut)\n        if len(lut.shape) == 1:\n            # Assumes the lut corresponds to poly1d parameters\n            params = [old_div(x, (2 * np.pi)) for x in lut]\n            self.LUT = np.poly1d(params)\n        elif len(lut.shape) == 2:\n            phase = lut[0]\n            gray_level = lut[1]\n            self.LUT = interp1d(phase, gray_level)\n\n    def set_image(self, phase, slm_monitor=None):\n        # Makes phase go from 0 to 2*pi, and removes floating point errors\n        phase = (phase + 0.1*np.pi / 2 ** self._bitness) % (2 * np.pi) - 0.1*np.pi / 2 ** self._bitness\n        # Makes phase go from -pi to pi\n        phase -= np.pi\n        # Transform into SLM display values\n        phase = self.LUT(phase)\n\n        self.update_image.emit(phase)\n\n        if slm_monitor is not None:\n            app = get_qt_app()\n            desktop = app.desktop()\n            slm_screen = desktop.screen(slm_monitor)\n            assert isinstance(slm_monitor, int)\n            assert desktop.screenCount() > slm_monitor >= 0\n            self.move(slm_screen.x(), slm_screen.y())\n        return phase\n\n    def _set_image(self, phase):\n        \"\"\"Sets an array on the QLabel.Pixmap\n\n        :param phase: np.array from 0 to 2 pi\n        :param slm_monitor: int. Optional. If given, it will move the SLM widget to the specified monitor\n        :return:\n        \"\"\"\n        img = phase.ravel()\n\n        if self._bitness == 8:\n            self._QImage = QtGui.QImage(img.astype(np.uint8), phase.shape[1], phase.shape[0], QtGui.QImage.Format_Grayscale8)\n        else:\n            raise ValueError('Bitness %g is not implemented' % self._bitness)\n\n        self._QLabel.setPixmap(QtGui.QPixmap(self._QImage))",
  "class Slm(Instrument):\n    def __init__(self, options, slm_monitor, correction_phase=None, display_kwargs=None, **kwargs):\n        \"\"\"\n        :param options: list of strings. Names of the functionalities you want your SLM to have:\n            - gratings\n            - vortexbeam\n            - focus\n            - astigmatism\n            - linear_lut\n            The order you give these in is important, as they act on the phase pattern sequentially (see make_phase)\n        :param slm_monitor: int. Monitor index for the SLM. See _get_monitor_size\n        :param correction_phase: array. Some SLMs require a large spatial correction to provide a flat phase\n        :param kwargs:\n        \"\"\"\n        super(Slm, self).__init__()\n\n        self._shape = self._get_monitor_size(slm_monitor)\n        if correction_phase is None:\n            self._correction = np.zeros(self._shape[::-1])\n        elif type(correction_phase) == str:\n            self._correction = np.loadtxt(correction_phase)\n        else:\n            assert correction_phase.shape == self._shape\n            self._correction = correction_phase\n\n        self.phase = None\n        self.Display = None\n        if display_kwargs is None:\n            self.display_kwargs = dict()\n        else:\n            self.display_kwargs = display_kwargs\n        self.options = options\n\n    @staticmethod\n    def _get_monitor_size(monitor_index):\n        \"\"\"Utility function to automatically detect the SLM panel size\n        :param monitor_index: int. Monitor number\n        :return: tuple of two integers, width and height in pixels\n        \"\"\"\n        app = get_qt_app()\n        desktop = app.desktop()\n        assert 0 <= monitor_index < desktop.screenCount(), 'monitor_index must be between 0 and the number of monitors'\n        slm_screen = desktop.screen(monitor_index)\n\n        return [slm_screen.width(), slm_screen.height()]\n\n    def make_phase(self, parameters):\n        \"\"\"Creates and returns the phase pattern\n\n        Iterates over self.options, getting the correct pattern_generator by name and applying them sequentially to an\n        array initially full of zeros.\n\n        :param parameters: dict. Keys correspond to the self.options keys, values are the arguments to be passed to the\n        pattern_generators as unnamed arguments\n        :return:\n        \"\"\"\n        self._logger.debug('Making phases: %s, %s' % (self._shape, parameters))\n        self.phase = np.zeros(self._shape[::-1])\n        for option in self.options:\n            self._logger.debug('Making phase: %s' % option)\n            try:\n                self.phase = getattr(pattern_generators, option)(self.phase, *parameters[option])\n            except Exception as e:\n                self._logger.warn('Failed because: %s' % e)\n        self._logger.debug('Finished making phases')\n        return self.phase\n\n    def display_phase(self, phase, slm_monitor=None):\n        \"\"\"Display a phase array, creating/displaying the appropriate widget if necessary\n\n        :param phase: 2D array of phase values\n        :param slm_monitor: index of the monitor to display the array in\n        :param kwargs: named arguments to be passed to the display widget\n        :return:\n        \"\"\"\n        if self.Display is None:\n            self.Display = SlmDisplay(self._shape, **self.display_kwargs)\n\n        self._logger.debug(\"Setting phase (min, max)=(%g, %g); shape=%s; monitor=%s\" % (np.min(phase), np.max(phase),\n                                                                                        np.shape(phase), slm_monitor))\n        phase = self.Display.set_image(phase + self._correction, slm_monitor=slm_monitor)\n\n        if self.Display.isHidden():\n            self.Display.show()\n        return phase\n\n    def get_qt_ui(self):\n        return SlmUi(self)",
  "class SlmUi(QtWidgets.QWidget, UiTools):\n    def __init__(self, slm):\n        \"\"\"\n        :param slm: instance of Slm\n        \"\"\"\n        super(SlmUi, self).__init__()\n        self.all_widgets = None\n        self.all_docks = None\n        self.PhaseDisplay = None\n        self.dockarea = None\n        self.SLM = slm\n        self.setup_gui()\n\n    def setup_gui(self):\n        \"\"\"Creates a DockArea and fills it with the Slm.options given\n\n        For each option, it extracts the correct ui from gui by name, loads it into a widget and adds it to the DockArea\n\n        :return:\n        \"\"\"\n        uic.loadUi(os.path.join(os.path.dirname(__file__), 'ui_base.ui'), self)\n        self.dockarea = dockarea.DockArea()\n        self.splitter.insertWidget(0, self.dockarea)\n        self.dockarea.show()  # Absolutely no idea why this is needed\n\n        self.all_widgets = dict()\n        self.all_docks = []\n        for option in self.SLM.options:\n            widget = getattr(gui, '%sUi' % option)(self)\n            dock = dockarea.Dock(option)\n            dock.addWidget(widget)\n            self.dockarea.addDock(dock, 'bottom')\n            self.all_widgets[option] = widget\n            self.all_docks += [dock]\n        self.make_pushButton.pressed.connect(self.make)\n        self.save_pushButton.pressed.connect(self.save)\n        self.load_pushButton.pressed.connect(self.load)\n\n    @property\n    def settings_filename(self):\n        filename = self.filename_lineEdit.text()\n        if filename == '':\n            filename = os.path.join(os.path.dirname(__file__), 'settings.ini')\n            self.filename_lineEdit.setText(filename)\n        return filename\n\n    @settings_filename.setter\n    def settings_filename(self, value):\n        self.filename_lineEdit.setText(value)\n\n    def make(self):\n        parameters = self.get_gui_phase_params()\n        self.SLM._logger.debug('SlmUi.make called with args=%s' % (parameters, ))\n        phase = self.SLM.make_phase(parameters)\n\n        slm_monitor = self.slm_monitor_lineEdit.text()\n        if slm_monitor == '':\n            slm_monitor = None\n        else:\n            slm_monitor = int(slm_monitor)\n\n        phase = self.SLM.display_phase(np.copy(phase), slm_monitor=slm_monitor)\n\n        # The data is transposed according to the pyqtgraph documentation for axis ordering\n        # http://www.pyqtgraph.org/documentation/widgets/imageview.html\n        self.PhaseDisplay.setImage(np.copy(phase).transpose())\n\n    def save(self):\n        gui_settings = QtCore.QSettings(self.settings_filename, QtCore.QSettings.IniFormat)\n        self.save_settings(gui_settings, 'base')\n        for name, widget in list(self.all_widgets.items()):\n            widget.save_settings(gui_settings, name)\n        return\n\n    def load(self):\n        gui_settings = QtCore.QSettings(self.settings_filename, QtCore.QSettings.IniFormat)\n        self.load_settings(gui_settings, 'base')\n        for name, widget in list(self.all_widgets.items()):\n            widget.load_settings(gui_settings, name)\n        return\n\n    def get_gui_phase_params(self):\n        \"\"\"Iterates over all widgets, calling get_params, and storing the returns in a dictionary\n\n        :return: dict. Keys are the self.options.keys() and the values are whatever the widgets return from get_params\n        \"\"\"\n        all_params = dict()\n        for name, widget in list(self.all_widgets.items()):\n            all_params[name] = widget.get_params()\n        self.SLM._logger.debug('get_gui_phase_params: %s' % all_params)\n        return all_params\n\n    def closeEvent(self, event):\n        if self.SLM.Display is not None:\n            self.SLM.Display.close()",
  "def __init__(self, shape=(1000, 1000), resolution=(1, 1), bitness=8, hide_border=True, lut=None):\n        \"\"\"\n        :param shape: 2-tuple of int. Width and height of the SLM panel in pixels\n        :param resolution:\n        :param bitness: int. Number of addressing levels of the SLM\n        :param hide_border: bool. Whether to show the standard window border in your OS. Set to False only for debugging\n        :param lut: tuple. Parameters passed to set_lut. The default LUT assumes that the phase goes from 0 to 2 pi, and\n        we want to display it from 0 to 256\n        \"\"\"\n        super(SlmDisplay, self).__init__()\n\n        self._pixels = [int(old_div(x[0], x[1])) for x in zip(shape, resolution)]\n        self._bitness = bitness\n\n        self._QImage = None\n        self._QLabel = None\n        self._make_gui(hide_border)\n\n        self.LUT = None\n        if lut is None:\n            lut = (2**self._bitness, 0)\n        self.set_lut(lut)\n\n        self.update_image.connect(self._set_image, type=QtCore.Qt.QueuedConnection)",
  "def _make_gui(self, hide_border=True):\n        \"\"\"Creates and sets the widget layout\n        :param hide_border: bool. See __init__\n        :return:\n        \"\"\"\n        self._QLabel = QtWidgets.QLabel(self)\n\n        layout = QtWidgets.QHBoxLayout(self)\n        layout.setContentsMargins(0, 0, 0, 0)\n        layout.addWidget(self._QLabel)\n        self.setLayout(layout)\n\n        self.setWindowTitle('SLM Phase')\n        if hide_border:\n            self.setWindowFlags(QtCore.Qt.CustomizeWindowHint | QtCore.Qt.FramelessWindowHint | QtCore.Qt.WindowStaysOnTopHint)",
  "def set_lut(self, lut):\n        if type(lut) == str:\n            lut = np.loadtxt(lut)\n\n        lut = np.array(lut)\n        if len(lut.shape) == 1:\n            # Assumes the lut corresponds to poly1d parameters\n            params = [old_div(x, (2 * np.pi)) for x in lut]\n            self.LUT = np.poly1d(params)\n        elif len(lut.shape) == 2:\n            phase = lut[0]\n            gray_level = lut[1]\n            self.LUT = interp1d(phase, gray_level)",
  "def set_image(self, phase, slm_monitor=None):\n        # Makes phase go from 0 to 2*pi, and removes floating point errors\n        phase = (phase + 0.1*np.pi / 2 ** self._bitness) % (2 * np.pi) - 0.1*np.pi / 2 ** self._bitness\n        # Makes phase go from -pi to pi\n        phase -= np.pi\n        # Transform into SLM display values\n        phase = self.LUT(phase)\n\n        self.update_image.emit(phase)\n\n        if slm_monitor is not None:\n            app = get_qt_app()\n            desktop = app.desktop()\n            slm_screen = desktop.screen(slm_monitor)\n            assert isinstance(slm_monitor, int)\n            assert desktop.screenCount() > slm_monitor >= 0\n            self.move(slm_screen.x(), slm_screen.y())\n        return phase",
  "def _set_image(self, phase):\n        \"\"\"Sets an array on the QLabel.Pixmap\n\n        :param phase: np.array from 0 to 2 pi\n        :param slm_monitor: int. Optional. If given, it will move the SLM widget to the specified monitor\n        :return:\n        \"\"\"\n        img = phase.ravel()\n\n        if self._bitness == 8:\n            self._QImage = QtGui.QImage(img.astype(np.uint8), phase.shape[1], phase.shape[0], QtGui.QImage.Format_Grayscale8)\n        else:\n            raise ValueError('Bitness %g is not implemented' % self._bitness)\n\n        self._QLabel.setPixmap(QtGui.QPixmap(self._QImage))",
  "def __init__(self, options, slm_monitor, correction_phase=None, display_kwargs=None, **kwargs):\n        \"\"\"\n        :param options: list of strings. Names of the functionalities you want your SLM to have:\n            - gratings\n            - vortexbeam\n            - focus\n            - astigmatism\n            - linear_lut\n            The order you give these in is important, as they act on the phase pattern sequentially (see make_phase)\n        :param slm_monitor: int. Monitor index for the SLM. See _get_monitor_size\n        :param correction_phase: array. Some SLMs require a large spatial correction to provide a flat phase\n        :param kwargs:\n        \"\"\"\n        super(Slm, self).__init__()\n\n        self._shape = self._get_monitor_size(slm_monitor)\n        if correction_phase is None:\n            self._correction = np.zeros(self._shape[::-1])\n        elif type(correction_phase) == str:\n            self._correction = np.loadtxt(correction_phase)\n        else:\n            assert correction_phase.shape == self._shape\n            self._correction = correction_phase\n\n        self.phase = None\n        self.Display = None\n        if display_kwargs is None:\n            self.display_kwargs = dict()\n        else:\n            self.display_kwargs = display_kwargs\n        self.options = options",
  "def _get_monitor_size(monitor_index):\n        \"\"\"Utility function to automatically detect the SLM panel size\n        :param monitor_index: int. Monitor number\n        :return: tuple of two integers, width and height in pixels\n        \"\"\"\n        app = get_qt_app()\n        desktop = app.desktop()\n        assert 0 <= monitor_index < desktop.screenCount(), 'monitor_index must be between 0 and the number of monitors'\n        slm_screen = desktop.screen(monitor_index)\n\n        return [slm_screen.width(), slm_screen.height()]",
  "def make_phase(self, parameters):\n        \"\"\"Creates and returns the phase pattern\n\n        Iterates over self.options, getting the correct pattern_generator by name and applying them sequentially to an\n        array initially full of zeros.\n\n        :param parameters: dict. Keys correspond to the self.options keys, values are the arguments to be passed to the\n        pattern_generators as unnamed arguments\n        :return:\n        \"\"\"\n        self._logger.debug('Making phases: %s, %s' % (self._shape, parameters))\n        self.phase = np.zeros(self._shape[::-1])\n        for option in self.options:\n            self._logger.debug('Making phase: %s' % option)\n            try:\n                self.phase = getattr(pattern_generators, option)(self.phase, *parameters[option])\n            except Exception as e:\n                self._logger.warn('Failed because: %s' % e)\n        self._logger.debug('Finished making phases')\n        return self.phase",
  "def display_phase(self, phase, slm_monitor=None):\n        \"\"\"Display a phase array, creating/displaying the appropriate widget if necessary\n\n        :param phase: 2D array of phase values\n        :param slm_monitor: index of the monitor to display the array in\n        :param kwargs: named arguments to be passed to the display widget\n        :return:\n        \"\"\"\n        if self.Display is None:\n            self.Display = SlmDisplay(self._shape, **self.display_kwargs)\n\n        self._logger.debug(\"Setting phase (min, max)=(%g, %g); shape=%s; monitor=%s\" % (np.min(phase), np.max(phase),\n                                                                                        np.shape(phase), slm_monitor))\n        phase = self.Display.set_image(phase + self._correction, slm_monitor=slm_monitor)\n\n        if self.Display.isHidden():\n            self.Display.show()\n        return phase",
  "def get_qt_ui(self):\n        return SlmUi(self)",
  "def __init__(self, slm):\n        \"\"\"\n        :param slm: instance of Slm\n        \"\"\"\n        super(SlmUi, self).__init__()\n        self.all_widgets = None\n        self.all_docks = None\n        self.PhaseDisplay = None\n        self.dockarea = None\n        self.SLM = slm\n        self.setup_gui()",
  "def setup_gui(self):\n        \"\"\"Creates a DockArea and fills it with the Slm.options given\n\n        For each option, it extracts the correct ui from gui by name, loads it into a widget and adds it to the DockArea\n\n        :return:\n        \"\"\"\n        uic.loadUi(os.path.join(os.path.dirname(__file__), 'ui_base.ui'), self)\n        self.dockarea = dockarea.DockArea()\n        self.splitter.insertWidget(0, self.dockarea)\n        self.dockarea.show()  # Absolutely no idea why this is needed\n\n        self.all_widgets = dict()\n        self.all_docks = []\n        for option in self.SLM.options:\n            widget = getattr(gui, '%sUi' % option)(self)\n            dock = dockarea.Dock(option)\n            dock.addWidget(widget)\n            self.dockarea.addDock(dock, 'bottom')\n            self.all_widgets[option] = widget\n            self.all_docks += [dock]\n        self.make_pushButton.pressed.connect(self.make)\n        self.save_pushButton.pressed.connect(self.save)\n        self.load_pushButton.pressed.connect(self.load)",
  "def settings_filename(self):\n        filename = self.filename_lineEdit.text()\n        if filename == '':\n            filename = os.path.join(os.path.dirname(__file__), 'settings.ini')\n            self.filename_lineEdit.setText(filename)\n        return filename",
  "def settings_filename(self, value):\n        self.filename_lineEdit.setText(value)",
  "def make(self):\n        parameters = self.get_gui_phase_params()\n        self.SLM._logger.debug('SlmUi.make called with args=%s' % (parameters, ))\n        phase = self.SLM.make_phase(parameters)\n\n        slm_monitor = self.slm_monitor_lineEdit.text()\n        if slm_monitor == '':\n            slm_monitor = None\n        else:\n            slm_monitor = int(slm_monitor)\n\n        phase = self.SLM.display_phase(np.copy(phase), slm_monitor=slm_monitor)\n\n        # The data is transposed according to the pyqtgraph documentation for axis ordering\n        # http://www.pyqtgraph.org/documentation/widgets/imageview.html\n        self.PhaseDisplay.setImage(np.copy(phase).transpose())",
  "def save(self):\n        gui_settings = QtCore.QSettings(self.settings_filename, QtCore.QSettings.IniFormat)\n        self.save_settings(gui_settings, 'base')\n        for name, widget in list(self.all_widgets.items()):\n            widget.save_settings(gui_settings, name)\n        return",
  "def load(self):\n        gui_settings = QtCore.QSettings(self.settings_filename, QtCore.QSettings.IniFormat)\n        self.load_settings(gui_settings, 'base')\n        for name, widget in list(self.all_widgets.items()):\n            widget.load_settings(gui_settings, name)\n        return",
  "def get_gui_phase_params(self):\n        \"\"\"Iterates over all widgets, calling get_params, and storing the returns in a dictionary\n\n        :return: dict. Keys are the self.options.keys() and the values are whatever the widgets return from get_params\n        \"\"\"\n        all_params = dict()\n        for name, widget in list(self.all_widgets.items()):\n            all_params[name] = widget.get_params()\n        self.SLM._logger.debug('get_gui_phase_params: %s' % all_params)\n        return all_params",
  "def closeEvent(self, event):\n        if self.SLM.Display is not None:\n            self.SLM.Display.close()",
  "class ThorlabsMFF(Flipper):\n    port_settings = dict(baudrate=115200,\n                         bytesize=8,\n                         parity=serial.PARITY_NONE,\n                         stopbits=1,\n                         xonxoff=0,\n                         rtscts=0,\n                         timeout=5,\n                         writeTimeout=1)\n\n    def __init__(self, port, **kwargs):\n        Flipper.__init__(self, port)\n\n    @locked_action\n    def set_state(self, value):\n        if value:\n            self.write(0x046A, param1=0x01, param2=0x01)\n            time.sleep(0.1)\n            t0 = time.time()\n            while self.get_state() != 1:\n                time.sleep(0.1)\n                if time.time() - t0 > self.port_settings['timeout']:\n                    raise RuntimeError('Timed out while waiting for position change')\n        else:\n            self.write(0x046A, param1=0x01, param2=0x02)\n            time.sleep(0.1)\n            t0 = time.time()\n            while self.get_state() != 0:\n                time.sleep(0.1)\n                if time.time() - t0 > self.port_settings['timeout']:\n                    raise RuntimeError('Timed out while waiting for position change')\n\n    def get_state(self):\n        self.write(0x0429, param1=0x01)\n        read = self.read()\n        msg = read['data']\n        unpacked = self.unpack_binary_mask(struct.unpack('<HI', msg)[1])\n        if np.sum(unpacked) != 1:\n            return 'Fuck'\n        elif unpacked[1]:\n            return 0\n        elif unpacked[0]:\n            return 1\n        else:\n            return 'Fuck2'",
  "def __init__(self, port, **kwargs):\n        Flipper.__init__(self, port)",
  "def set_state(self, value):\n        if value:\n            self.write(0x046A, param1=0x01, param2=0x01)\n            time.sleep(0.1)\n            t0 = time.time()\n            while self.get_state() != 1:\n                time.sleep(0.1)\n                if time.time() - t0 > self.port_settings['timeout']:\n                    raise RuntimeError('Timed out while waiting for position change')\n        else:\n            self.write(0x046A, param1=0x01, param2=0x02)\n            time.sleep(0.1)\n            t0 = time.time()\n            while self.get_state() != 0:\n                time.sleep(0.1)\n                if time.time() - t0 > self.port_settings['timeout']:\n                    raise RuntimeError('Timed out while waiting for position change')",
  "def get_state(self):\n        self.write(0x0429, param1=0x01)\n        read = self.read()\n        msg = read['data']\n        unpacked = self.unpack_binary_mask(struct.unpack('<HI', msg)[1])\n        if np.sum(unpacked) != 1:\n            return 'Fuck'\n        elif unpacked[1]:\n            return 0\n        elif unpacked[0]:\n            return 1\n        else:\n            return 'Fuck2'",
  "class Flipper(APT_VCP):\n    \"\"\"A generic instrument class for flippers.\n    \n    # Subclassing Notes\n    The minimum required subclassing effort is overriding `set_state` and `get_state` to open\n    and close the flipper.  Overriding get_state allows you to read back the\n    state of the flipper.  If you want to emulate that (i.e. keep track of\n    the state of the flipper in software) subclass `flipperWithEmulatedRead`\n    and make sure you call its `__init__` method in your initialisation code.\n    \"\"\"\n    def __init__(self, port):\n        # Instrument.__init__(self)\n        APT_VCP.__init__(self, port=port, destination=0x50)\n        # super(Flipper, self).__init__()\n\n    def toggle(self):\n        \"\"\"Toggle the state of the flipper.\n        \n        The default behaviour will emulate a toggle command if none exists.\n        \"\"\"\n        try:\n            if self.state:\n                self.state = 0\n            else:\n                self.state = 1\n        except NotImplementedError:\n            raise NotImplementedError(\"This flipper has no way to toggle!\"\"\")\n\n    def get_state(self):\n        \"\"\"Whether the flipper is 'Open' or 'Closed'.\"\"\"\n        raise NotImplementedError(\"This flipper has no way to get its state!\"\"\")\n\n    def set_state(self, value):\n        \"\"\"Set the flipper to be either 0 or 1'.\"\"\"\n        raise NotImplementedError(\"This flipper has no way to set its state!\"\"\")\n\n    # This slightly ugly hack means it's not necessary to redefine the \n    # state property every time it's subclassed.\n    def _get_state_proxy(self):\n        \"\"\"The state of the flipper - should either be \"Open\" or \"Closed\".\"\"\"\n        return self.get_state()\n        \n    def _set_state_proxy(self, state):\n        self.set_state(state)\n        self._last_set_state = state # Remember what state we're in\n        \n    state = property(_get_state_proxy, _set_state_proxy)\n\n    def get_qt_ui(self):\n        \"\"\"Return a graphical interface for the flipper.\"\"\"\n        return flipperUI(self)",
  "class flipperUI(QtWidgets.QWidget, UiTools):\n    def __init__(self, flipper, parent=None):\n        assert isinstance(flipper, Flipper), 'instrument must be a flipper'\n        self.flipper = flipper\n        super(flipperUI, self).__init__(parent)\n        uic.loadUi(os.path.join(os.path.dirname(__file__), 'flipper.ui'), self)\n        self.auto_connect_by_name(controlled_object = self.flipper,verbose = False)\n    #    self.state.stateChanged.connect(self.on_change)\n\n    def on_change(self):\n        self.flipper.toggle()",
  "class Dummyflipper(Flipper):\n    \"\"\"A stub class to simulate a flipper\"\"\"\n    _open = DumbNotifiedProperty(False)\n    def __init__(self):\n        \"\"\"Create a dummy flipper object\"\"\"\n        self._open = False\n        super(Dummyflipper, self).__init__()\n        \n    def toggle(self):\n        \"\"\"toggle the state of the flipper\"\"\"\n        self._open = not self._open\n    \n    def get_state(self):\n        \"\"\"Return the state of the flipper, a string reading 'open' or 'closed'\"\"\"\n        return \"Open\" if self._open else \"Closed\"\n        \n    def set_state(self, value):\n        \"\"\"Set the state of the flipper (to open or closed)\"\"\"\n        if isinstance(value, str):\n            self._open = (value.lower() == \"open\")\n        elif isinstance(value, bool):\n            self._open = value",
  "def __init__(self, port):\n        # Instrument.__init__(self)\n        APT_VCP.__init__(self, port=port, destination=0x50)",
  "def toggle(self):\n        \"\"\"Toggle the state of the flipper.\n        \n        The default behaviour will emulate a toggle command if none exists.\n        \"\"\"\n        try:\n            if self.state:\n                self.state = 0\n            else:\n                self.state = 1\n        except NotImplementedError:\n            raise NotImplementedError(\"This flipper has no way to toggle!\"\"\")",
  "def get_state(self):\n        \"\"\"Whether the flipper is 'Open' or 'Closed'.\"\"\"\n        raise NotImplementedError(\"This flipper has no way to get its state!\"\"\")",
  "def set_state(self, value):\n        \"\"\"Set the flipper to be either 0 or 1'.\"\"\"\n        raise NotImplementedError(\"This flipper has no way to set its state!\"\"\")",
  "def _get_state_proxy(self):\n        \"\"\"The state of the flipper - should either be \"Open\" or \"Closed\".\"\"\"\n        return self.get_state()",
  "def _set_state_proxy(self, state):\n        self.set_state(state)\n        self._last_set_state = state",
  "def get_qt_ui(self):\n        \"\"\"Return a graphical interface for the flipper.\"\"\"\n        return flipperUI(self)",
  "def __init__(self, flipper, parent=None):\n        assert isinstance(flipper, Flipper), 'instrument must be a flipper'\n        self.flipper = flipper\n        super(flipperUI, self).__init__(parent)\n        uic.loadUi(os.path.join(os.path.dirname(__file__), 'flipper.ui'), self)\n        self.auto_connect_by_name(controlled_object = self.flipper,verbose = False)",
  "def on_change(self):\n        self.flipper.toggle()",
  "def __init__(self):\n        \"\"\"Create a dummy flipper object\"\"\"\n        self._open = False\n        super(Dummyflipper, self).__init__()",
  "def toggle(self):\n        \"\"\"toggle the state of the flipper\"\"\"\n        self._open = not self._open",
  "def get_state(self):\n        \"\"\"Return the state of the flipper, a string reading 'open' or 'closed'\"\"\"\n        return \"Open\" if self._open else \"Closed\"",
  "def set_state(self, value):\n        \"\"\"Set the state of the flipper (to open or closed)\"\"\"\n        if isinstance(value, str):\n            self._open = (value.lower() == \"open\")\n        elif isinstance(value, bool):\n            self._open = value",
  "class LumeneraCamera(Camera):\n    last_frame_time = -1\n    fps = -1\n    \n    \n#    traits_view = View(VGroup(\n#                Item(name=\"image_plot\",editor=ComponentEditor(),show_label=False,springy=True),\n#                HGroup(\n#                    VGroup(\n#                        VGroup(\n#                            Item(name=\"exposure\"),\n#                            Item(name=\"zoom\"),\n#                            Item(name=\"gain\"),\n#                            Item(name=\"live_view\")\n#                            ), #the vgroup is a trick to make the column narrower\n#                        HGroup(\n#                            Item(name=\"edit_properties\",show_label=False),\n#                            Item(name=\"edit_video_properties\",show_label=False),\n#                            Item(name=\"edit_camera_properties\",show_label=False),\n#                        ),\n#                    springy=False),\n#                    VGroup(\n#                        Item(name=\"take_snapshot\",show_label=False),\n#                        HGroup(Item(name=\"description\")),\n#                        Item(name=\"save_snapshot\",show_label=False),\n#                        Item(name=\"save_jpg_snapshot\",show_label=False),\n#                        HGroup(Item(name=\"video_priority\")),\n#                    springy=False),\n#                springy=True),\n#            layout=\"split\"), kind=\"live\",resizable=True,width=500,height=600,title=\"Camera\")\n    def __init__(self,camera_number=1):\n        self.cam = lucam.Lucam(camera_number) #lucam is 1-indexed...\n        self._camera_number = camera_number\n        self._cameraIsStreaming = False\n        \n        #populate metadata - important in case we restart\n        self.auto_restore_metadata = {'exposure':self.exposure, 'gain':self.gain,} #\n        \n        super(LumeneraCamera,self).__init__() #NB this comes after setting up the hardware\n        self.metadata_property_names = ['gain', 'exposure']\n        self.auto_crop_fraction = None\n#        for pname in lucam.Lucam.PROPERTY.keys():\n#            try:\n#                getattr(self, pname)\n#            except:\n#                del lucam.Lucam.PROPERTY[pname]\n#         #       del self.metadata_property_names[pname]\n#                delattr(self.__class__,pname)\n    \n    def restart(self):\n        \"\"\"Close down the Lumenera camera, wait, and re-open.  Useful if it crashes.\"\"\"\n        live_view_setting = self.live_view \n        self.log(\"Attempting to restart camera\")\n        self.live_view = False\n        self.cam.CameraClose()\n        self.log(\"Camera closed\")\n        try:\n            del self.cam\n            self.log(\"Camera deleted\")\n        except Exception as e:\n            print(\"Warning, an exception was raised deleting the old camera:\\n{0}\".format(e))\n        time.sleep(2)\n        self.log(\"Creating new camera object\")\n        self.cam = lucam.Lucam(self._camera_number)\n        self.log(\"New camera object greated\")\n        self.log(\"Setting live view, gain and exposure\")\n        self.live_view = live_view_setting\n        self.gain = self.auto_restore_metadata['gain']\n        self.exposure = self.auto_restore_metadata['exposure']\n        self.log(\"Camera restarted\")\n        \n        \n    def close(self):\n        \"\"\"Stop communication with the camera and allow it to be re-used.\"\"\"\n        self.live_view = False\n        super(LumeneraCamera, self).close()\n        self.cam.CameraClose()\n        \n    def raw_snapshot(self, suppress_errors=False, reset_on_error=True, retrieve_metadata=True,crop_fraction = None):\n        \"\"\"Take a snapshot and return it.  Bypass filters etc.\n        \n        @param: video_priority: If this is set to True, don't interrupt video\n        streaming and just return the latest frame.  If it's set to false,\n        stop the video stream, take a snapshot, and re-start the video stream.\n        @param: suppress_errors: don't raise an exception if we can't get a \n        valid frame.\n        @param: reset_on _error: attempt to turn the camera off and on again\n        if it's not behaving(!)\n        @param: retrieve_metadata: by default, we retrieve certain camera \n        parameters (gain, exposure, etc.) when we take a frame, and store them\n        in self.metadata.  Set this to false to disable the behaviour.\"\"\"\n        #I removed logic for video priority here.  That belongs in raw_image.\n        if self.auto_crop_fraction is not None:\n            crop_fraction = self.auto_crop_fraction\n        with self.acquisition_lock:\n            for i in range(10):\n                try:\n                    # first we must construct the settings object.\n                    # we need to make sure there's enough time in the timeout\n                    # to cope with the exposure.\n                    settings = self.cam.default_snapshot()\n                    settings.timeout = self.cam.GetProperty('exposure')[0] + 500\n                    frame = self.cam.TakeSnapshot(snapshot=settings)\n                    assert frame is not None, \"Failed to capture a frame\"\n                    frame_pointer = frame.ctypes.data_as(\n                                        ctypes.POINTER(ctypes.c_byte))\n                    image = self.convert_frame(frame_pointer,np.product(frame.shape))\n                    if crop_fraction is not None:\n                        x_size = int(image.shape[0]*crop_fraction)//2\n                        x_mid = int(image.shape[0])//2\n                        y_size = int(image.shape[1]*crop_fraction)//2\n                        y_mid = int(image.shape[1])//2\n                        image = image[x_mid-x_size:x_mid+x_size,y_mid-y_size:y_mid+y_size]\n                    return True, image\n                except Exception as e:\n                    print(\"Attempt number {0} failed to capture a frame from the camera: {1}\".format(i,e))\n        print(\"Camera.raw_snapshot() has failed to capture a frame.\")\n        if reset_on_error:\n            print(\"Camera dropped lots of frames.  Turning it off and on again.  Fingers crossed!\")\n            self.restart() #try restarting the camera!\n            return self.raw_snapshot(suppress_errors=suppress_errors, \n                                     reset_on_error=False, #this matters: avoid infinite loop!\n                                     )\n        if not suppress_errors:\n            raise IOError(\"Dropped too many frames from camera :(\")\n        else:\n            return False, None\n        \n    def _streamingCallback(self, context, frame_pointer, frame_size):\n        \"\"\"This function is called on each frame that comes back from the camera when it's streaming.\n        \n        We keep track of the frame rate, and convert each frame to RGB so we \n        can store it in latest_image and thus update the GUI.\n        \"\"\"\n        now = time.time() #clock()\n        self.fps = 1/(now - self.last_frame_time)\n        self.last_frame_time = now\n        try:\n            self.latest_raw_frame = self.convert_frame(frame_pointer, frame_size)\n        except:\n            print(\"invalid frame size\")\n            \n    def convert_frame(self, frame_pointer, frame_size):\n        \"\"\"Convert a frame from the camera to an RGB numpy array.\"\"\"\n        f = self.cam.GetFormat()[0]\n        w, h = f.width // (f.binningX * f.subSampleX), f.height // (f.binningY * f.subSampleY)\n        assert frame_size == w*h, \"The frame size did not match the image format!\"\n        converted_frame = self.cam.ConvertFrameToRgb24(f, frame_pointer) #actually convert the frame\n        return converted_frame[:,:,::-1] #for some reason frames come back BGR - flip them to RGB\n        \n    def start_streaming(self):\n        \"\"\"Start streaming video from the camera as a preview.\n        \n        Don't call this function directly, use the live_view property.\"\"\"\n        self.cam.StreamVideoControl('start_streaming')\n        # time.sleep(0.5)\n        self._callback_id = self.cam.AddStreamingCallback(self._streamingCallback)\n        self._cameraIsStreaming = True\n        \n    def stop_streaming(self):\n        \"\"\"Stop streaming video from the camera.\n        \n        Don't call this function directly, use the live_view function.\"\"\"\n        self.cam.StreamVideoControl('stop_streaming')\n        # time.sleep(0.5)\n        self.cam.RemoveStreamingCallback(self._callback_id)\n        self._cameraIsStreaming = False\n    \n    @NotifiedProperty\n    def live_view(self):\n        \"\"\"Whether the camera is currently streaming and displaying video\"\"\"\n        return self._cameraIsStreaming\n    @live_view.setter\n    def live_view(self, live_view):\n        \"\"\"Turn live view on and off.\n        \n        This is used to start and stop streaming of the camera feed. \"\"\"\n        if live_view == self.live_view:\n            return # Don't execute the start/stop functions twice.\n        if live_view==True:\n            self.start_streaming()\n        else:\n            self.stop_streaming()\n        \n    def get_camera_parameter(self, parameter_name):\n        \"\"\"Get the value of a camera setting.  But you should use the property...\"\"\"\n        return self.cam.GetProperty(parameter_name)[0]\n        \n    def set_camera_parameter(self, parameter_name, value):\n        \"\"\"Get the value of a camera setting.  But you should use the property...\"\"\"\n        self.cam.SetProperty(parameter_name, value)\n        \n    def get_metadata(self):\n        \"\"\"Return a dictionary of camera settings and parameters.\"\"\"\n        ret = super(LumeneraCamera, self).get_metadata()\n        \n        camid=self.cam.GetCameraId()\n        version = self.cam.QueryVersion()\n        interface = self.cam.QueryExternInterface()\n        frame, fps = self.cam.GetFormat()\n        depth = self.cam.GetTruePixelDepth()\n        \n        pixformat = 'raw8 raw16 RGB24 YUV422 Count Filter RGBA32 RGB48'.split()\n        ret['camera_id'] = camid\n        ret['camera_model'] = lucam.CAMERA_MODEL.get(camid, \"Unknown\")\n        ret['serial_number'] = version.serialnumber\n        ret['firmware_version'] = lucam.print_version(version.firmware)\n        ret['FPGA_version'] = lucam.print_version(version.fpga)\n        ret['API_version'] = lucam.print_version(version.api)\n        ret['driver_version'] = lucam.print_version(version.driver)\n        ret['Interface'] = lucam.Lucam.EXTERN_INTERFACE[interface]\n        ret['image_offset'] = (frame.xOffset, frame.yOffset)\n        ret['image_size'] = (frame.width // frame.binningX,\n                                     frame.height // frame.binningY)\n        if frame.flagsX:\n            ret['binning'] = (frame.binningX, frame.binningY)\n        else:\n            ret['subsampling'] = (frame.subSampleX, frame.subSampleY)\n        ret['pixel_format'] = pixformat[frame.pixelFormat]\n        ret['bit_depth'] = (depth if frame.pixelFormat else 8)\n        ret['frame_rate'] = fps\n        return ret\n    \n    def show_camera_properties_dialog(self):\n        \"\"\"Display the camera's built-in properties dialog.\"\"\"\n        self.cam.DisplayPropertyPage(None)\n    def show_video_format_dialog(self):\n        \"\"\"Display the camera's built-in video format dialog.\"\"\"\n        self.cam.DisplayVideoFormatPage(None)\n    def get_control_widget(self):\n        \"Get a Qt widget with the camera's controls (but no image display)\"\n        return LumeneraCameraControlWidget(self)",
  "class LumeneraCameraControlWidget(CameraControlWidget):\n    \"\"\"A control widget for the Lumenera camera, with extra buttons.\"\"\"\n    def __init__(self, camera, auto_connect=True):\n        super(LumeneraCameraControlWidget, self).__init__(camera, auto_connect=False)\n        gb = QuickControlBox()\n        gb.add_doublespinbox(\"exposure\")\n        gb.add_doublespinbox(\"gain\")\n        gb.add_button(\"show_camera_properties_dialog\", title=\"Camera Setup\")\n        gb.add_button(\"show_video_format_dialog\", title=\"Video Format\")\n        self.layout().insertWidget(1, gb) # put the extra settings in the middle\n        self.quick_settings_groupbox = gb        \n        \n        self.auto_connect_by_name(controlled_object=self.camera, verbose=False)",
  "def __init__(self,camera_number=1):\n        self.cam = lucam.Lucam(camera_number) #lucam is 1-indexed...\n        self._camera_number = camera_number\n        self._cameraIsStreaming = False\n        \n        #populate metadata - important in case we restart\n        self.auto_restore_metadata = {'exposure':self.exposure, 'gain':self.gain,} #\n        \n        super(LumeneraCamera,self).__init__() #NB this comes after setting up the hardware\n        self.metadata_property_names = ['gain', 'exposure']\n        self.auto_crop_fraction = None",
  "def restart(self):\n        \"\"\"Close down the Lumenera camera, wait, and re-open.  Useful if it crashes.\"\"\"\n        live_view_setting = self.live_view \n        self.log(\"Attempting to restart camera\")\n        self.live_view = False\n        self.cam.CameraClose()\n        self.log(\"Camera closed\")\n        try:\n            del self.cam\n            self.log(\"Camera deleted\")\n        except Exception as e:\n            print(\"Warning, an exception was raised deleting the old camera:\\n{0}\".format(e))\n        time.sleep(2)\n        self.log(\"Creating new camera object\")\n        self.cam = lucam.Lucam(self._camera_number)\n        self.log(\"New camera object greated\")\n        self.log(\"Setting live view, gain and exposure\")\n        self.live_view = live_view_setting\n        self.gain = self.auto_restore_metadata['gain']\n        self.exposure = self.auto_restore_metadata['exposure']\n        self.log(\"Camera restarted\")",
  "def close(self):\n        \"\"\"Stop communication with the camera and allow it to be re-used.\"\"\"\n        self.live_view = False\n        super(LumeneraCamera, self).close()\n        self.cam.CameraClose()",
  "def raw_snapshot(self, suppress_errors=False, reset_on_error=True, retrieve_metadata=True,crop_fraction = None):\n        \"\"\"Take a snapshot and return it.  Bypass filters etc.\n        \n        @param: video_priority: If this is set to True, don't interrupt video\n        streaming and just return the latest frame.  If it's set to false,\n        stop the video stream, take a snapshot, and re-start the video stream.\n        @param: suppress_errors: don't raise an exception if we can't get a \n        valid frame.\n        @param: reset_on _error: attempt to turn the camera off and on again\n        if it's not behaving(!)\n        @param: retrieve_metadata: by default, we retrieve certain camera \n        parameters (gain, exposure, etc.) when we take a frame, and store them\n        in self.metadata.  Set this to false to disable the behaviour.\"\"\"\n        #I removed logic for video priority here.  That belongs in raw_image.\n        if self.auto_crop_fraction is not None:\n            crop_fraction = self.auto_crop_fraction\n        with self.acquisition_lock:\n            for i in range(10):\n                try:\n                    # first we must construct the settings object.\n                    # we need to make sure there's enough time in the timeout\n                    # to cope with the exposure.\n                    settings = self.cam.default_snapshot()\n                    settings.timeout = self.cam.GetProperty('exposure')[0] + 500\n                    frame = self.cam.TakeSnapshot(snapshot=settings)\n                    assert frame is not None, \"Failed to capture a frame\"\n                    frame_pointer = frame.ctypes.data_as(\n                                        ctypes.POINTER(ctypes.c_byte))\n                    image = self.convert_frame(frame_pointer,np.product(frame.shape))\n                    if crop_fraction is not None:\n                        x_size = int(image.shape[0]*crop_fraction)//2\n                        x_mid = int(image.shape[0])//2\n                        y_size = int(image.shape[1]*crop_fraction)//2\n                        y_mid = int(image.shape[1])//2\n                        image = image[x_mid-x_size:x_mid+x_size,y_mid-y_size:y_mid+y_size]\n                    return True, image\n                except Exception as e:\n                    print(\"Attempt number {0} failed to capture a frame from the camera: {1}\".format(i,e))\n        print(\"Camera.raw_snapshot() has failed to capture a frame.\")\n        if reset_on_error:\n            print(\"Camera dropped lots of frames.  Turning it off and on again.  Fingers crossed!\")\n            self.restart() #try restarting the camera!\n            return self.raw_snapshot(suppress_errors=suppress_errors, \n                                     reset_on_error=False, #this matters: avoid infinite loop!\n                                     )\n        if not suppress_errors:\n            raise IOError(\"Dropped too many frames from camera :(\")\n        else:\n            return False, None",
  "def _streamingCallback(self, context, frame_pointer, frame_size):\n        \"\"\"This function is called on each frame that comes back from the camera when it's streaming.\n        \n        We keep track of the frame rate, and convert each frame to RGB so we \n        can store it in latest_image and thus update the GUI.\n        \"\"\"\n        now = time.time() #clock()\n        self.fps = 1/(now - self.last_frame_time)\n        self.last_frame_time = now\n        try:\n            self.latest_raw_frame = self.convert_frame(frame_pointer, frame_size)\n        except:\n            print(\"invalid frame size\")",
  "def convert_frame(self, frame_pointer, frame_size):\n        \"\"\"Convert a frame from the camera to an RGB numpy array.\"\"\"\n        f = self.cam.GetFormat()[0]\n        w, h = f.width // (f.binningX * f.subSampleX), f.height // (f.binningY * f.subSampleY)\n        assert frame_size == w*h, \"The frame size did not match the image format!\"\n        converted_frame = self.cam.ConvertFrameToRgb24(f, frame_pointer) #actually convert the frame\n        return converted_frame[:,:,::-1]",
  "def start_streaming(self):\n        \"\"\"Start streaming video from the camera as a preview.\n        \n        Don't call this function directly, use the live_view property.\"\"\"\n        self.cam.StreamVideoControl('start_streaming')\n        # time.sleep(0.5)\n        self._callback_id = self.cam.AddStreamingCallback(self._streamingCallback)\n        self._cameraIsStreaming = True",
  "def stop_streaming(self):\n        \"\"\"Stop streaming video from the camera.\n        \n        Don't call this function directly, use the live_view function.\"\"\"\n        self.cam.StreamVideoControl('stop_streaming')\n        # time.sleep(0.5)\n        self.cam.RemoveStreamingCallback(self._callback_id)\n        self._cameraIsStreaming = False",
  "def live_view(self):\n        \"\"\"Whether the camera is currently streaming and displaying video\"\"\"\n        return self._cameraIsStreaming",
  "def live_view(self, live_view):\n        \"\"\"Turn live view on and off.\n        \n        This is used to start and stop streaming of the camera feed. \"\"\"\n        if live_view == self.live_view:\n            return # Don't execute the start/stop functions twice.\n        if live_view==True:\n            self.start_streaming()\n        else:\n            self.stop_streaming()",
  "def get_camera_parameter(self, parameter_name):\n        \"\"\"Get the value of a camera setting.  But you should use the property...\"\"\"\n        return self.cam.GetProperty(parameter_name)[0]",
  "def set_camera_parameter(self, parameter_name, value):\n        \"\"\"Get the value of a camera setting.  But you should use the property...\"\"\"\n        self.cam.SetProperty(parameter_name, value)",
  "def get_metadata(self):\n        \"\"\"Return a dictionary of camera settings and parameters.\"\"\"\n        ret = super(LumeneraCamera, self).get_metadata()\n        \n        camid=self.cam.GetCameraId()\n        version = self.cam.QueryVersion()\n        interface = self.cam.QueryExternInterface()\n        frame, fps = self.cam.GetFormat()\n        depth = self.cam.GetTruePixelDepth()\n        \n        pixformat = 'raw8 raw16 RGB24 YUV422 Count Filter RGBA32 RGB48'.split()\n        ret['camera_id'] = camid\n        ret['camera_model'] = lucam.CAMERA_MODEL.get(camid, \"Unknown\")\n        ret['serial_number'] = version.serialnumber\n        ret['firmware_version'] = lucam.print_version(version.firmware)\n        ret['FPGA_version'] = lucam.print_version(version.fpga)\n        ret['API_version'] = lucam.print_version(version.api)\n        ret['driver_version'] = lucam.print_version(version.driver)\n        ret['Interface'] = lucam.Lucam.EXTERN_INTERFACE[interface]\n        ret['image_offset'] = (frame.xOffset, frame.yOffset)\n        ret['image_size'] = (frame.width // frame.binningX,\n                                     frame.height // frame.binningY)\n        if frame.flagsX:\n            ret['binning'] = (frame.binningX, frame.binningY)\n        else:\n            ret['subsampling'] = (frame.subSampleX, frame.subSampleY)\n        ret['pixel_format'] = pixformat[frame.pixelFormat]\n        ret['bit_depth'] = (depth if frame.pixelFormat else 8)\n        ret['frame_rate'] = fps\n        return ret",
  "def show_camera_properties_dialog(self):\n        \"\"\"Display the camera's built-in properties dialog.\"\"\"\n        self.cam.DisplayPropertyPage(None)",
  "def show_video_format_dialog(self):\n        \"\"\"Display the camera's built-in video format dialog.\"\"\"\n        self.cam.DisplayVideoFormatPage(None)",
  "def get_control_widget(self):\n        \"Get a Qt widget with the camera's controls (but no image display)\"\n        return LumeneraCameraControlWidget(self)",
  "def __init__(self, camera, auto_connect=True):\n        super(LumeneraCameraControlWidget, self).__init__(camera, auto_connect=False)\n        gb = QuickControlBox()\n        gb.add_doublespinbox(\"exposure\")\n        gb.add_doublespinbox(\"gain\")\n        gb.add_button(\"show_camera_properties_dialog\", title=\"Camera Setup\")\n        gb.add_button(\"show_video_format_dialog\", title=\"Video Format\")\n        self.layout().insertWidget(1, gb) # put the extra settings in the middle\n        self.quick_settings_groupbox = gb        \n        \n        self.auto_connect_by_name(controlled_object=self.camera, verbose=False)",
  "class uc480(QtWidgets.QMainWindow, UiTools):\n    \"\"\"\n    GUI which controls a uc480 camera.\n    \"\"\"\n    \n    def __init__(self, serial=False):\n        super(self.__class__, self).__init__()\n        # get the path of this file in case we are calling this class from another location\n        file_path = os.path.dirname(__file__)\n        ui_file = file_path + '\\\\uc480_gui_design.ui'\n        uic.loadUi(ui_file, self)\n        \n        # set initial tabs to display\n        self.SettingsTabWidget.setCurrentIndex(0) \n                \n        # enable / disable push buttons\n        self.reset_gui_without_camera()\n      \n        # connect GUI elements\n        self.AutoExposurePushButton.clicked.connect(self.auto_exposure)\n        self.TakeImagePushButton.clicked.connect(self.take_image)\n        self.SaveImagePushButton.clicked.connect(self.save_image)\n        self.NewFilePushButton.clicked.connect(self.new_hdf5_file)\n        self.LiveViewCheckBox.stateChanged.connect(self.live_view)\n        self.StartVideoPushButton.clicked.connect(self.acquire_video)\n        self.OpenCameraPushButton.clicked.connect(self.open_camera_button)\n        self.CloseCameraPushButton.clicked.connect(self.close_camera)    \n        self.FindCamerasPushButton.clicked.connect(self.find_cameras)\n                        \n        # create the image widget\n        self.image_widget = pg.GraphicsLayoutWidget()\n        view_box = self.image_widget.addViewBox(row=0, col=0, lockAspect=True)        \n        # add image item\n        self.imv = pg.ImageItem(row=0, col=0)\n        self.imv.setOpts(axisOrder='row-major')               \n        view_box.addItem(self.imv)        \n        # add lines\n        pen = pg.mkPen(color='y', width=5)\n        self.vertical_line = pg.InfiniteLine(pos=600, angle=90, movable=True, pen=pen)\n        self.horizontal_line = pg.InfiniteLine(pos=500, angle=0, movable=True, pen=pen)\n        view_box.addItem(self.vertical_line)\n        view_box.addItem(self.horizontal_line)        \n        # add profile plots\n        self.horizontal_profile = self.image_widget.addPlot(row=1, col=0)\n        self.horizontal_profile.showGrid(x=True, y=True)\n        self.vertical_profile = self.image_widget.addPlot(row=0, col=1)\n        self.vertical_profile.showGrid(x=True, y=True)\n        self.vertical_profile.invertX(True)                        \n        # hide axis tick labels\n        for profile in [self.vertical_profile, self.horizontal_profile]:\n            for ax in ['left','right','top','bottom']:\n                profile.showAxis(ax)\n                profile.axes[ax]['item'].setStyle(showValues=False)\n        # set column widths\n        qGraphicsGridLayout = self.image_widget.ci.layout\n        qGraphicsGridLayout.setColumnStretchFactor(0, 3)\n        qGraphicsGridLayout.setRowStretchFactor(0, 3)                          \n        \n        # populate image format combobox\n        self.ImageFormatComboBox.addItem('hdf5',0)\n        self.ImageFormatComboBox.addItem('png',1)\n        self.ImageFormatComboBox.addItem('tiff',2)\n        self.ImageFormatComboBox.addItem('jpg',3)\n        self.ImageFormatComboBox.setCurrentIndex(0)        \n        # populate video format combobox\n        self.VideoFormatComboBox.addItem('hdf5',0)\n        self.VideoFormatComboBox.setCurrentIndex(0)    \n\n        # set df and df_gui to False until the hdf5 file is needed\n        self.df = False\n        self.df_gui = False\n\n        # open camera\n        self.open_camera(serial)\n        \n        # set initial parameters\n        self.file_path = ''\n        self.ExposureTimeNumberBox.setValue(2)\n        self.FramerateNumberBox.setValue(10)\n        self.DisplayFramerateNumberBox.setValue(10)\n        self.GainNumberBox.setValue(0)\n        self.GammaNumberBox.setValue(1)\n        self.BlacklevelNumberBox.setValue(255)       \n        self.ROICheckBox.setChecked(True)\n        self.ROIWidthCheckBox.setChecked(True)\n        self.ROIHeightCheckBox.setChecked(True)\n        self.ROIWidthNumberBox.setValue(self.camera.max_width)\n        self.ROIHeightNumberBox.setValue(self.camera.max_height)\n#        self.ROIWidthNumberBox.setValue(700)\n#        self.ROIHeightNumberBox.setValue(300)\n        \n        # take image with the initial parameters and calculate the best exposure\n        self.auto_exposure()\n    \n    def open_camera_button(self):\n        \"\"\"Read serial number from GUI and connect to the camera.\"\"\"\n        serial = self.SerialComboBox.currentText()\n        self.open_camera(serial=serial)\n    \n    def open_camera(self, serial=False):\n        \"\"\"Connect to a uc480 camera.\"\"\" \n        print('Attempting to connect to the camera...')\n        if serial: \n            print(\"Serial number: %s\" %serial)\n            self.camera = instrument(serial=serial) # specified camera\n        else: \n            print(\"Available instruments:\")\n            print(list_instruments())\n            self.camera = instrument('uc480') # default camera\n        \n        # set the camera gui buttons\n        self.reset_gui_with_camera()\n        print('Camera connection successful.\\n')  \n        self.find_cameras()\n        \n        # set camera window title\n        self.image_widget.setWindowTitle(self.camera.serial + ' = uc480 camera serial no.' )\n        \n        # set camera width and height labels\n        self.CameraWidthLabel.setText(str(self.camera.max_width))\n        self.CameraHeightLabel.setText(str(self.camera.max_height)) \n        \n        # determine which camera parameters can be set        \n        try: \n            self.camera.gamma = int(self.GammaNumberBox.value())\n            self.set_gamma = True\n        except: \n            print(\"WARNING: Can't set gamma.\\n\")\n            self.set_gamma = False              \n        try: \n            self.camera.auto_whitebalance = self.AutoWhitebalanceCheckBox.checkState() \n            self.set_whitebalance = True\n        except: \n            print(\"WARNING: Can't set auto_whitebalance.\\n\")\n            self.set_whitebalance = False    \n        \n        # initialise the attributes dictionary\n        self.attributes = dict()\n\n        # take first image        \n        self.take_image()        \n        \n    def close_camera(self):\n        \"\"\"Close the uc480 camera connection.\"\"\" \n        self.camera.close()\n        self.reset_gui_without_camera()\n        print('Camera connection closed.\\n')  \n        del self.camera\n        self.camera = False\n        \n    def closeEvent(self, event):\n        \"\"\"This will happen when the GUI is closed.\"\"\"\n        # stop live view\n        self.LiveViewCheckBox.setCheckState(False)\n        # close the camera connection\n        if self.camera: self.close_camera()\n        # close the datafile\n        if self.df: self.df.close()\n        # close the databrowser gui\n        if self.df_gui: self.df_gui.close()\n        # close the image widget\n        self.image_widget.close()\n    \n    def find_cameras(self):\n        \"\"\"Find serial numbers of available cameras.\"\"\"\n        drivers = list_instruments()\n        self.SerialComboBox.clear()\n        for driver in drivers:\n            if driver['classname'] == 'UC480_Camera':\n                self.SerialComboBox.addItem(driver['serial'])\n        try:\n            serial = self.camera.serial\n            index = self.SerialComboBox.findText(serial)\n            self.SerialComboBox.setCurrentIndex(index)\n        except:\n            print(\"No camera is currently open.\\n\")\n    \n    def take_image(self):\n        \"\"\"Grab an image and display it.\"\"\"\n        image = self.grab_image()        \n        self.display_image(image)\n        return image\n\n    def get_brightest_pixel(self, image):\n        \"\"\"Get the brightest pixel value from the image.\"\"\"\n        brightest_pixel = np.amax(image)\n        self.CurrentMaxGrayLabel.setText(str(brightest_pixel))\n        return brightest_pixel\n        \n    def auto_exposure(self):\n        \"\"\"Get parameters from the gui and set auto exposure.\"\"\"\n        \n        # get parameters from the gui\n        min_gray = self.MinGrayNumberBox.value()\n        max_gray = self.MaxGrayNumberBox.value()\n        precision = self.ExposureTimePrecisionNumberBox.value()\n        \n        # disable live view\n        live_view_state = self.LiveViewCheckBox.checkState()\n        self.LiveViewCheckBox.setCheckState(False)\n        \n        # set auto exposure\n        self.set_auto_exposure(min_gray=min_gray, max_gray=max_gray, precision=precision)\n    \n        # enable live view\n        self.LiveViewCheckBox.setCheckState(live_view_state)\n    \n    def set_auto_exposure(self, min_gray=200, max_gray=250, precision=1, max_attempts=10):\n        \"\"\"Determine the optimal exposure time.\"\"\"\n        image = self.take_image()\n        brightest_pixel = self.get_brightest_pixel(image)\n        okay = True\n        attempt = 0\n        \n        while (brightest_pixel > max_gray or brightest_pixel < min_gray) and okay:\n            attempt += 1\n            current_exposure = float(self.CurrentExposureLabel.text())\n            \n            # adjust the exposure time\n            if brightest_pixel > max_gray:\n                print(\"REDUCE exposure time...\\n\")\n                new_exposure = current_exposure/2\n            elif brightest_pixel < min_gray:\n                print(\"INCREASE exposure time...\\n\")\n                new_exposure = current_exposure/brightest_pixel*max_gray*0.99\n\n            # try the new exposure time\n            self.ExposureTimeNumberBox.setValue(new_exposure)\n            image = self.take_image()\n            brightest_pixel = self.get_brightest_pixel(image)            \n            previous_exposure = current_exposure\n            current_exposure = float(self.CurrentExposureLabel.text())\n            self.ExposureTimeNumberBox.setValue(current_exposure)\n            \n            # don't keep on trying the same exposure\n            if np.abs(previous_exposure - current_exposure) < precision: okay = False \n            # don't keep on trying forever\n            if attempt > max_attempts: okay = False \n\n            # update the gui\n            QtWidgets.qApp.processEvents()\n\n        \n    def display_image(self, image):\n        \"\"\"Display the latest captured image.\"\"\"\n        # make a copy of the data so it can be accessed when saving an image\n        self.image = image\n        \n        # set levels to [0,255] because otherwise it autoscales when plotting\n        self.imv.setImage(image, autoDownsample=True, levels=[0,255], border='w')   \n        \n        # make sure the line positions are within bounds\n        self.vertical_line.setBounds((0,image.shape[1]-1))\n        self.horizontal_line.setBounds((0,image.shape[0]-1))\n        \n        # get line positions from the gui\n        horizontal_line_position = int(self.horizontal_line.value())\n        vertical_line_position = int(self.vertical_line.value())\n        \n        # clear profile plots\n        self.horizontal_profile.clear()\n        self.vertical_profile.clear()\n        \n        # plot intensity profiles\n        if len(image.shape) == 3: # colour camera\n            c = ['r','g','b']            \n            for i in range(image.shape[2]):\n                pen = pg.mkPen(color=c[i], width=5)\n                self.horizontal_profile.plot(x=list(range(image.shape[1])), y=image[horizontal_line_position,:,i], pen=pen)\n                self.vertical_profile.plot(x=image[:,vertical_line_position,i], y=list(range(image.shape[0])), pen=pen)\n        else: # monochrome camera\n            pen = pg.mkPen(color='w', width=5)\n            self.horizontal_profile.plot(x=list(range(image.shape[1])), y=image[horizontal_line_position,:], pen=pen)\n            self.vertical_profile.plot(x=image[:,vertical_line_position], y=list(range(image.shape[0])), pen=pen)\n        self.horizontal_profile.setYRange(0,255)\n        self.vertical_profile.setXRange(0,255)\n\n        # show the image widget\n        self.image_widget.show()\n    \n    def display_camera_parameters(self, camera_parameters):\n        \"\"\"Display the current camera parameters on the GUI.\"\"\"\n        self.CurrentFramerateLabel.setText(str(camera_parameters['framerate']))\n        self.CurrentExposureLabel.setText(str(camera_parameters['exposure_time']))\n        self.CurrentWidthLabel.setText(str(camera_parameters['width']))\n        self.CurrentHeightLabel.setText(str(camera_parameters['height']))\n        self.MaxWidthLabel.setText(str(camera_parameters['max_width']))\n        self.MaxHeightLabel.setText(str(camera_parameters['max_height']))  \n        self.CurrentMasterGainLabel.setText(str(camera_parameters['master_gain']))\n        self.CurrentGainBoostLabel.setText(str(camera_parameters['gain_boost']))\n        self.CurrentBlacklevelLabel.setText(str(camera_parameters['blacklevel_offset']))\n        self.CurrentAutoBlacklevelLabel.setText(str(camera_parameters['auto_blacklevel']))\n        if self.set_whitebalance: self.CurrentAutoWhitebalanceLabel.setText(str(camera_parameters['auto_whitebalance']))\n        if self.set_gamma: self.CurrentGammaLabel.setText(str(camera_parameters['gamma']))\n    \n    def get_camera_parameters(self):\n        \"\"\"Read parameter values from the camera.\"\"\"\n        camera_parameters = dict()\n        camera_parameters['serial'] = self.camera.serial\n        camera_parameters['framerate'] = self.camera.framerate.magnitude\n        camera_parameters['exposure_time'] = self.camera._get_exposure().magnitude\n        camera_parameters['width'] = self.camera.width\n        camera_parameters['max_width'] = self.camera.max_width\n        camera_parameters['height'] = self.camera.height\n        camera_parameters['max_height'] = self.camera.max_height        \n        camera_parameters['master_gain'] = self.camera.master_gain\n        camera_parameters['gain_boost'] = self.camera.gain_boost\n        camera_parameters['blacklevel_offset'] = self.camera.blacklevel_offset\n        camera_parameters['auto_blacklevel'] = self.camera.auto_blacklevel\n        if self.set_whitebalance: camera_parameters['auto_whitebalance'] = self.camera.auto_whitebalance\n        if self.set_gamma: camera_parameters['gamma'] = self.camera.gamma\n        return camera_parameters\n        \n    def set_video_parameters(self):\n        \"\"\"Read parameters from the GUI and return a dictionary.\"\"\"\n        video_parameters = self.set_capture_parameters()        \n        framerate = \"{} hertz\".format(str(self.FramerateNumberBox.value()))\n        video_parameters['framerate'] = framerate                \n        return video_parameters\n            \n    def set_capture_parameters(self):\n        \"\"\"Read parameters from the GUI and return a dictionary.\"\"\"\n        capture_parameters = dict()\n        exposure_time = \"{} millisecond\".format(str(self.ExposureTimeNumberBox.value()))        \n        capture_parameters['exposure_time'] = exposure_time\n        capture_parameters['gain'] = float(self.GainNumberBox.value())\n        capture_parameters['vbin'] = int(self.VBinNumberBox.value())\n        capture_parameters['hbin'] = int(self.HBinNumberBox.value())\n        capture_parameters['vsub'] = int(self.VSubNumberBox.value())\n        capture_parameters['hsub'] = int(self.HSubNumberBox.value())        \n        capture_parameters = self.set_ROI(capture_parameters)\n        self.set_camera_properties()          \n        return capture_parameters\n    \n    def set_camera_properties(self):\n        \"\"\"Read parameters from the GUI and set the corresponding camera properties.\"\"\"\n        self.camera.auto_blacklevel = self.AutoBlacklevelCheckBox.checkState()\n        self.camera.blacklevel_offset = int(self.BlacklevelNumberBox.value())         \n        self.camera.gain_boost = self.GainBoostCheckBox.checkState()\n        if self.set_gamma: self.camera.gamma = int(self.GammaNumberBox.value())\n        if self.set_whitebalance: self.camera.auto_whitebalance = self.AutoWhitebalanceCheckBox.checkState()            \n    \n    def set_ROI(self, parameters_dict):\n        \"\"\"Read ROI coordinates from the GUI.\"\"\"\n        ROI_dict = {'width':[self.ROIWidthCheckBox, self.ROIWidthNumberBox],\n                    'height':[self.ROIHeightCheckBox, self.ROIHeightNumberBox],\n                    'left':[self.ROILeftEdgeCheckBox, self.ROILeftEdgeNumberBox],\n                    'right':[self.ROIRightEdgeCheckBox, self.ROIRightEdgeNumberBox],\n                    'top':[self.ROITopEdgeCheckBox, self.ROITopEdgeNumberBox],\n                    'bot':[self.ROIBottomEdgeCheckBox, self.ROIBottomEdgeNumberBox],\n                    'cx':[self.ROICentreXCheckBox, self.ROICentreXNumberBox],\n                    'cy':[self.ROICentreYCheckBox, self.ROICentreYNumberBox],\n                    }\n        \n        # clear all of the old ROI parameters\n        for item in list(ROI_dict.keys()):\n            if item in list(parameters_dict.keys()):\n                del parameters_dict[item]\n        \n        # use maximum width and height available\n        parameters_dict['width'] = self.camera.max_width\n        parameters_dict['height'] = self.camera.max_height\n        \n        # repopulate ROI parameters with the selected ones\n        if self.ROICheckBox.checkState():            \n            for item in list(ROI_dict.keys()):\n                if ROI_dict[item][0].checkState():\n                    parameters_dict[item] = int(ROI_dict[item][1].value())\n        \n        return parameters_dict\n\n        \n    def grab_image(self):\n        \"\"\"Grab an image with the camera.\"\"\"\n        # set the desired capture parameters and update the attributes\n        capture_parameters = self.set_capture_parameters()\n        self.attributes.update(capture_parameters)\n        \n        # get the capture_timestamp with millisecond precision\n        # insert a T to match the creation_timestamp formatting\n        self.attributes['capture_timestamp'] = str(datetime.datetime.now()).replace(' ', 'T')\n\n        # grab the image\n        image = self.camera.grab_image(**capture_parameters)\n        self.get_brightest_pixel(image)\n        print('Image grabbed.\\n')\n\n        # get and display the camera parameters and update the attributes\n        camera_parameters = self.get_camera_parameters()\n        self.display_camera_parameters(camera_parameters)    \n        self.attributes.update(camera_parameters)               \n        return image\n        \n    def get_info(self):\n        \"\"\"Get info from the GUI.\"\"\"\n        info = dict()\n        info['description'] = self.DescriptionLineEdit.text()\n        return info\n        \n    def save_image(self, dummy_variable=False, group_name='images'):\n        \"\"\"Save the latest image.\"\"\"\n        # make a copy of the image so the saved image is the one that was on the \n        # screen when the save button was pressed, not when the file name was chosen\n        image = self.image\n        image_format = self.ImageFormatComboBox.currentText()\n        \n        if image_format == 'hdf5':\n            # update the attributes dictionary\n            self.attributes.update(self.get_info())\n            # get the datafile\n            if not self.df: self.new_hdf5_file()\n            # write data in the \"images\" group within the datafile\n            dg = self.df.require_group(name=group_name)\n            # write data to the file\n            dg.create_dataset(\"image_%d\", data=image, attrs=self.attributes)\n            dg.file.flush()\n            print(\"Image saved to the hdf5 file.\\n\")\n            \n        else:\n            # user input to choose file name\n            self.file_path = QtWidgets.QFileDialog.getSaveFileName(self, 'Save image', \n                                                                   self.file_path, \n                                                                   \"(*.\"+self.ImageFormatComboBox.currentText()+\")\")\n            if len(self.file_path):        \n                # save image            \n                imsave(self.file_path, np.flip(image, axis=0))\n                print(\"Image saved: \" + self.file_path + \"\\n\")\n            else:\n                print(\"WARNING: Image wasn't saved.\\n\") \n\n    def new_hdf5_file(self):     \n        \"\"\"Open a new HDF5 file and its databrowser GUI.\"\"\"\n        # close the datafile\n        if self.df: self.df.close() \n        # open new datafile\n        self.df = nplab.current_datafile()\n        # close the databrowser gui\n        if self.df_gui: self.df_gui.close() \n        # open new databrowser gui\n        self.df_gui = self.df.show_gui(blocking=False)                    \n        # update the file name on the camera gui\n        self.FilePathLineEdit.setText(self.df.filename)\n        print()       \n        \n    def live_view(self):\n        \"\"\"Continous image acquisition.\"\"\"\n        if self.LiveViewCheckBox.isChecked():                      \n            # enable/disable gui buttons\n            self.StopVideoPushButton.setEnabled(False)\n            # create thread\n            self.LiveView = LiveViewThread(self.camera)\n            # connect thread\n            self.LiveViewCheckBox.stateChanged.connect(self.LiveView.terminate)\n            self.LiveView.finished.connect(self.terminate_live_view)\n            # live view\n            print(\"Live view...\")\n            max_frames=float('inf')\n            self.start_live_view(save=False, max_frames=max_frames)                      \n            \n    def acquire_video(self):\n        \"\"\"Acquire video frames.\"\"\"            \n        # enable/disable gui buttons          \n        self.LiveViewCheckBox.setEnabled(False)\n        self.StopVideoPushButton.setEnabled(True)\n        self.SaveImagePushButton.setEnabled(False)\n        self.AutoExposurePushButton.setEnabled(False)\n        # create thread\n        self.LiveView = LiveViewThread(self.camera)\n        # connect thread\n        self.StopVideoPushButton.clicked.connect(self.LiveView.terminate)\n        self.LiveView.finished.connect(self.terminate_video_acquisition)\n        # live view\n        max_frames=self.MaxFramesNumberBox.value()\n        self.start_live_view(save=True, max_frames=max_frames)        \n        \n    def start_live_view(self, save=False, max_frames=100):\n        \"\"\"Start continuous image acquisition.\"\"\"     \n        \n        # enable/disable gui buttons\n        self.TakeImagePushButton.setEnabled(False)\n        self.StartVideoPushButton.setEnabled(False)\n        self.OpenCameraPushButton.setEnabled(False)\n        self.CloseCameraPushButton.setEnabled(False)\n        self.NewFilePushButton.setEnabled(False)\n        \n        # connect signals\n        self.LiveView.display_signal.connect(self.display_image)\n        self.LiveView.attributes_signal.connect(self.update_attributes)\n        \n        # set video_parameters and update thread attributes\n        video_parameters = self.set_video_parameters()\n        self.LiveView.attributes.update(video_parameters)\n                \n        # start live view\n        self.LiveView.live_view(video_parameters, \n                                      save=save,\n                                      max_frames=max_frames,\n                                      timeout=self.TimeoutNumberBox.value(),                                      \n                                      display_framerate=self.DisplayFramerateNumberBox.value(),\n                                      )\n        \n        # get and display camera parameters and update thread attributes\n        camera_parameters = self.get_camera_parameters()    \n        self.display_camera_parameters(camera_parameters)\n        self.LiveView.attributes.update(camera_parameters)\n        self.LiveView.attributes.update(self.get_info())\n        \n        # start continuous image acquisition\n        self.LiveView.start()\n    \n    def update_attributes(self, attributes):\n        \"\"\"Update attributes dictionary and display on the GUI.\"\"\"\n        self.attributes.update(attributes)   \n        self.display_camera_parameters(self.attributes)           \n    \n    def terminate_live_view(self):\n        \"\"\"This will run when the live view thread is terminated.\"\"\"\n        print(\"Finished live view.\\n\")\n        self.delete_thread()\n        \n    def terminate_video_acquisition(self):\n        \"\"\"This will run when the video acquisition thread is terminated.\"\"\"\n        print(\"Finished acquiring video.\\n\")\n        self.save_video()        \n        self.delete_thread()\n        \n    def delete_thread(self):    \n        \"\"\"Delete the live view thread and reset the GUI.\"\"\"\n        # stop live video mode\n        self.camera.stop_live_video()\n        # delete the thread to free up memory\n        del self.LiveView        \n        # remove some attribute keys so they don't get recorded in still images\n        attributes_keys_del = ['capture_time_sec', 'max_frames', 'timeout']\n        for key in attributes_keys_del:\n            if attributes_keys_del in list(self.attributes.keys()):\n                del self.attributes[key]\n        # reset the gui buttons\n        self.reset_gui_with_camera()    \n    \n    def save_video(self):\n        \"\"\"Save the acquired video into a file.\"\"\"\n        print(\"Saving video to file, please wait for a while...\")            \n        # TODO: allow saving as different file formats other than hdf5\n        # TODO: write hdf5 data renderer for saved video from the colour camera\n        \n        # disable the GUI whilst the video is being saved\n        self.setEnabled(False)\n        \n        QtWidgets.qApp.processEvents()\n        # get the datafile\n        if not self.df: self.new_hdf5_file()\n        # get the \"videos\" group within the datafile\n        datagroup = self.df.require_group(\"videos\")\n        \n        # save video to the datafile\n        datagroup.create_dataset(\"video_%d\", \n                                 # save only the captured frames even if frame_number < max_frames\n                                 data=self.LiveView.image_array[list(range(self.LiveView.frame_number))],\n                                 attrs=self.LiveView.attributes)\n        \n        # flushing at the end\n        datagroup.file.flush() \n        print(\"Finished saving video.\\n\")\n            \n    def reset_gui_with_camera(self):\n        \"\"\"Enable/disable GUI elements when a camera connection exists.\"\"\"\n        self.setEnabled(True)\n        \n        self.StartVideoPushButton.setEnabled(True)  \n        self.StopVideoPushButton.setEnabled(False)\n\n        self.LiveViewCheckBox.setEnabled(True)\n        self.LiveViewCheckBox.setChecked(False)\n\n        self.TakeImagePushButton.setEnabled(True)\n        self.AutoExposurePushButton.setEnabled(True)\n        self.SaveImagePushButton.setEnabled(True)\n        \n        self.OpenCameraPushButton.setEnabled(False)\n        self.CloseCameraPushButton.setEnabled(True)\n        self.NewFilePushButton.setEnabled(True)\n    \n    def reset_gui_without_camera(self):\n        \"\"\"Enable/disable GUI elements when no camera connection exists.\"\"\"\n        self.setEnabled(True)\n        \n        self.StartVideoPushButton.setEnabled(False)  \n        self.StopVideoPushButton.setEnabled(False)\n\n        self.LiveViewCheckBox.setEnabled(False)\n        self.LiveViewCheckBox.setChecked(False)\n\n        self.TakeImagePushButton.setEnabled(False)\n        self.AutoExposurePushButton.setEnabled(False)\n        self.SaveImagePushButton.setEnabled(False)\n        \n        self.OpenCameraPushButton.setEnabled(True)\n        self.CloseCameraPushButton.setEnabled(False)\n        self.NewFilePushButton.setEnabled(False)",
  "class LiveViewThread(QtCore.QThread):\n    \"\"\"Thread wich allows live view of the camera.\"\"\"\n    display_signal = QtCore.Signal(np.ndarray)\n    attributes_signal = QtCore.Signal(dict)\n    \n    def __init__(self, camera):\n        QtCore.QThread.__init__(self)       \n        self.camera = camera\n        self.attributes = dict()               \n        \n    def __del__(self):\n        self.wait()\n            \n    def live_view(self, video_parameters, save=False, \n                        timeout=1000, max_frames=100,\n                        display_framerate = 10):\n        \"\"\"Start live view with the video parameters received from the main GUI.\"\"\"\n\n        self.timeout = \"{} millisecond\".format(str(timeout))        \n        self.save = save\n        self.max_frames = max_frames\n                       \n        # get the capture_timestamp with millisecond precision\n        # insert a T to match the creation_timestamp formatting\n        self.attributes['capture_timestamp'] = str(datetime.datetime.now()).replace(' ', 'T')\n        self.attributes['max_frames'] = max_frames\n        self.attributes['timeout'] = timeout\n        \n        # start timer with microsecond precision\n        self.high_precision_time = HighPrecisionWallTime()     \n        \n        # start live video\n        self.camera.start_live_video(**video_parameters)       \n        \n        # calculate when we need to emit the image to the gui        \n        capture_framerate = self.camera.framerate.magnitude\n        self.frame_multiple = int(capture_framerate/display_framerate)\n        # if display_framerate > capture_framerate then frame_multiple < 1\n        # since we cannot emit each image more than once, frame_multiple must be >= 1\n        if self.frame_multiple < 1: self.frame_multiple = 1\n        \n        # initialise data arrays\n        if save:\n            print(\"Recording video...\")  \n            \n            image = self.camera.latest_frame()\n            # image_array size is the max_frames by the size of the image taken (works for monochrome and colour)\n            self.array_dim = [self.max_frames] + list(image.shape)\n            print(\"Array dimensions: \" + str(self.array_dim))\n            \n            self.image_array = np.empty(self.array_dim, dtype='uint8') # unit8 for minimum file size\n            self.capture_timestamp_array = np.empty(self.max_frames, dtype='float')\n        \n    def run(self):\n        \"\"\"Continuously acquire frames until the stop button is pressed\n        or the maximum number of frames is reached.\"\"\"\n        self.frame_number = 0\n        while not self.isFinished() and self.frame_number < self.max_frames:\n            # we need to run wait_for_frame so the video framerate is consistent\n            if self.camera.wait_for_frame(timeout=self.timeout):        \n                # get the capture_time with microsecond precision\n                capture_time_sec = self.high_precision_time.sample()                \n                \n                # capture the latest frame\n                image = self.camera.latest_frame()\n                if self.save:\n                    self.save_frame(image, capture_time_sec, self.frame_number)\n                \n                if self.frame_number % self.frame_multiple == 0:\n                    # emit signals to the main gui\n                    self.attributes_signal.emit(self.attributes)\n                    self.display_signal.emit(image) # crashes more often - maybe?               \n                self.frame_number += 1\n                \n        \n    def save_frame(self, image, capture_time_sec, frame_number):\n        \"\"\"Save the frame to RAM.\"\"\"\n        self.image_array[frame_number,:,:] = image\n        self.capture_timestamp_array[frame_number] = capture_time_sec\n        self.attributes['capture_time_sec'] = self.capture_timestamp_array",
  "class HighPrecisionWallTime(object):\n    def __init__(self,):\n        self._wall_time_0 = time.time()\n        self._clock_0 = time.clock()\n\n    def sample(self,):\n        dc = time.clock()-self._clock_0\n        return self._wall_time_0 + dc",
  "def __init__(self, serial=False):\n        super(self.__class__, self).__init__()\n        # get the path of this file in case we are calling this class from another location\n        file_path = os.path.dirname(__file__)\n        ui_file = file_path + '\\\\uc480_gui_design.ui'\n        uic.loadUi(ui_file, self)\n        \n        # set initial tabs to display\n        self.SettingsTabWidget.setCurrentIndex(0) \n                \n        # enable / disable push buttons\n        self.reset_gui_without_camera()\n      \n        # connect GUI elements\n        self.AutoExposurePushButton.clicked.connect(self.auto_exposure)\n        self.TakeImagePushButton.clicked.connect(self.take_image)\n        self.SaveImagePushButton.clicked.connect(self.save_image)\n        self.NewFilePushButton.clicked.connect(self.new_hdf5_file)\n        self.LiveViewCheckBox.stateChanged.connect(self.live_view)\n        self.StartVideoPushButton.clicked.connect(self.acquire_video)\n        self.OpenCameraPushButton.clicked.connect(self.open_camera_button)\n        self.CloseCameraPushButton.clicked.connect(self.close_camera)    \n        self.FindCamerasPushButton.clicked.connect(self.find_cameras)\n                        \n        # create the image widget\n        self.image_widget = pg.GraphicsLayoutWidget()\n        view_box = self.image_widget.addViewBox(row=0, col=0, lockAspect=True)        \n        # add image item\n        self.imv = pg.ImageItem(row=0, col=0)\n        self.imv.setOpts(axisOrder='row-major')               \n        view_box.addItem(self.imv)        \n        # add lines\n        pen = pg.mkPen(color='y', width=5)\n        self.vertical_line = pg.InfiniteLine(pos=600, angle=90, movable=True, pen=pen)\n        self.horizontal_line = pg.InfiniteLine(pos=500, angle=0, movable=True, pen=pen)\n        view_box.addItem(self.vertical_line)\n        view_box.addItem(self.horizontal_line)        \n        # add profile plots\n        self.horizontal_profile = self.image_widget.addPlot(row=1, col=0)\n        self.horizontal_profile.showGrid(x=True, y=True)\n        self.vertical_profile = self.image_widget.addPlot(row=0, col=1)\n        self.vertical_profile.showGrid(x=True, y=True)\n        self.vertical_profile.invertX(True)                        \n        # hide axis tick labels\n        for profile in [self.vertical_profile, self.horizontal_profile]:\n            for ax in ['left','right','top','bottom']:\n                profile.showAxis(ax)\n                profile.axes[ax]['item'].setStyle(showValues=False)\n        # set column widths\n        qGraphicsGridLayout = self.image_widget.ci.layout\n        qGraphicsGridLayout.setColumnStretchFactor(0, 3)\n        qGraphicsGridLayout.setRowStretchFactor(0, 3)                          \n        \n        # populate image format combobox\n        self.ImageFormatComboBox.addItem('hdf5',0)\n        self.ImageFormatComboBox.addItem('png',1)\n        self.ImageFormatComboBox.addItem('tiff',2)\n        self.ImageFormatComboBox.addItem('jpg',3)\n        self.ImageFormatComboBox.setCurrentIndex(0)        \n        # populate video format combobox\n        self.VideoFormatComboBox.addItem('hdf5',0)\n        self.VideoFormatComboBox.setCurrentIndex(0)    \n\n        # set df and df_gui to False until the hdf5 file is needed\n        self.df = False\n        self.df_gui = False\n\n        # open camera\n        self.open_camera(serial)\n        \n        # set initial parameters\n        self.file_path = ''\n        self.ExposureTimeNumberBox.setValue(2)\n        self.FramerateNumberBox.setValue(10)\n        self.DisplayFramerateNumberBox.setValue(10)\n        self.GainNumberBox.setValue(0)\n        self.GammaNumberBox.setValue(1)\n        self.BlacklevelNumberBox.setValue(255)       \n        self.ROICheckBox.setChecked(True)\n        self.ROIWidthCheckBox.setChecked(True)\n        self.ROIHeightCheckBox.setChecked(True)\n        self.ROIWidthNumberBox.setValue(self.camera.max_width)\n        self.ROIHeightNumberBox.setValue(self.camera.max_height)\n#        self.ROIWidthNumberBox.setValue(700)\n#        self.ROIHeightNumberBox.setValue(300)\n        \n        # take image with the initial parameters and calculate the best exposure\n        self.auto_exposure()",
  "def open_camera_button(self):\n        \"\"\"Read serial number from GUI and connect to the camera.\"\"\"\n        serial = self.SerialComboBox.currentText()\n        self.open_camera(serial=serial)",
  "def open_camera(self, serial=False):\n        \"\"\"Connect to a uc480 camera.\"\"\" \n        print('Attempting to connect to the camera...')\n        if serial: \n            print(\"Serial number: %s\" %serial)\n            self.camera = instrument(serial=serial) # specified camera\n        else: \n            print(\"Available instruments:\")\n            print(list_instruments())\n            self.camera = instrument('uc480') # default camera\n        \n        # set the camera gui buttons\n        self.reset_gui_with_camera()\n        print('Camera connection successful.\\n')  \n        self.find_cameras()\n        \n        # set camera window title\n        self.image_widget.setWindowTitle(self.camera.serial + ' = uc480 camera serial no.' )\n        \n        # set camera width and height labels\n        self.CameraWidthLabel.setText(str(self.camera.max_width))\n        self.CameraHeightLabel.setText(str(self.camera.max_height)) \n        \n        # determine which camera parameters can be set        \n        try: \n            self.camera.gamma = int(self.GammaNumberBox.value())\n            self.set_gamma = True\n        except: \n            print(\"WARNING: Can't set gamma.\\n\")\n            self.set_gamma = False              \n        try: \n            self.camera.auto_whitebalance = self.AutoWhitebalanceCheckBox.checkState() \n            self.set_whitebalance = True\n        except: \n            print(\"WARNING: Can't set auto_whitebalance.\\n\")\n            self.set_whitebalance = False    \n        \n        # initialise the attributes dictionary\n        self.attributes = dict()\n\n        # take first image        \n        self.take_image()",
  "def close_camera(self):\n        \"\"\"Close the uc480 camera connection.\"\"\" \n        self.camera.close()\n        self.reset_gui_without_camera()\n        print('Camera connection closed.\\n')  \n        del self.camera\n        self.camera = False",
  "def closeEvent(self, event):\n        \"\"\"This will happen when the GUI is closed.\"\"\"\n        # stop live view\n        self.LiveViewCheckBox.setCheckState(False)\n        # close the camera connection\n        if self.camera: self.close_camera()\n        # close the datafile\n        if self.df: self.df.close()\n        # close the databrowser gui\n        if self.df_gui: self.df_gui.close()\n        # close the image widget\n        self.image_widget.close()",
  "def find_cameras(self):\n        \"\"\"Find serial numbers of available cameras.\"\"\"\n        drivers = list_instruments()\n        self.SerialComboBox.clear()\n        for driver in drivers:\n            if driver['classname'] == 'UC480_Camera':\n                self.SerialComboBox.addItem(driver['serial'])\n        try:\n            serial = self.camera.serial\n            index = self.SerialComboBox.findText(serial)\n            self.SerialComboBox.setCurrentIndex(index)\n        except:\n            print(\"No camera is currently open.\\n\")",
  "def take_image(self):\n        \"\"\"Grab an image and display it.\"\"\"\n        image = self.grab_image()        \n        self.display_image(image)\n        return image",
  "def get_brightest_pixel(self, image):\n        \"\"\"Get the brightest pixel value from the image.\"\"\"\n        brightest_pixel = np.amax(image)\n        self.CurrentMaxGrayLabel.setText(str(brightest_pixel))\n        return brightest_pixel",
  "def auto_exposure(self):\n        \"\"\"Get parameters from the gui and set auto exposure.\"\"\"\n        \n        # get parameters from the gui\n        min_gray = self.MinGrayNumberBox.value()\n        max_gray = self.MaxGrayNumberBox.value()\n        precision = self.ExposureTimePrecisionNumberBox.value()\n        \n        # disable live view\n        live_view_state = self.LiveViewCheckBox.checkState()\n        self.LiveViewCheckBox.setCheckState(False)\n        \n        # set auto exposure\n        self.set_auto_exposure(min_gray=min_gray, max_gray=max_gray, precision=precision)\n    \n        # enable live view\n        self.LiveViewCheckBox.setCheckState(live_view_state)",
  "def set_auto_exposure(self, min_gray=200, max_gray=250, precision=1, max_attempts=10):\n        \"\"\"Determine the optimal exposure time.\"\"\"\n        image = self.take_image()\n        brightest_pixel = self.get_brightest_pixel(image)\n        okay = True\n        attempt = 0\n        \n        while (brightest_pixel > max_gray or brightest_pixel < min_gray) and okay:\n            attempt += 1\n            current_exposure = float(self.CurrentExposureLabel.text())\n            \n            # adjust the exposure time\n            if brightest_pixel > max_gray:\n                print(\"REDUCE exposure time...\\n\")\n                new_exposure = current_exposure/2\n            elif brightest_pixel < min_gray:\n                print(\"INCREASE exposure time...\\n\")\n                new_exposure = current_exposure/brightest_pixel*max_gray*0.99\n\n            # try the new exposure time\n            self.ExposureTimeNumberBox.setValue(new_exposure)\n            image = self.take_image()\n            brightest_pixel = self.get_brightest_pixel(image)            \n            previous_exposure = current_exposure\n            current_exposure = float(self.CurrentExposureLabel.text())\n            self.ExposureTimeNumberBox.setValue(current_exposure)\n            \n            # don't keep on trying the same exposure\n            if np.abs(previous_exposure - current_exposure) < precision: okay = False \n            # don't keep on trying forever\n            if attempt > max_attempts: okay = False \n\n            # update the gui\n            QtWidgets.qApp.processEvents()",
  "def display_image(self, image):\n        \"\"\"Display the latest captured image.\"\"\"\n        # make a copy of the data so it can be accessed when saving an image\n        self.image = image\n        \n        # set levels to [0,255] because otherwise it autoscales when plotting\n        self.imv.setImage(image, autoDownsample=True, levels=[0,255], border='w')   \n        \n        # make sure the line positions are within bounds\n        self.vertical_line.setBounds((0,image.shape[1]-1))\n        self.horizontal_line.setBounds((0,image.shape[0]-1))\n        \n        # get line positions from the gui\n        horizontal_line_position = int(self.horizontal_line.value())\n        vertical_line_position = int(self.vertical_line.value())\n        \n        # clear profile plots\n        self.horizontal_profile.clear()\n        self.vertical_profile.clear()\n        \n        # plot intensity profiles\n        if len(image.shape) == 3: # colour camera\n            c = ['r','g','b']            \n            for i in range(image.shape[2]):\n                pen = pg.mkPen(color=c[i], width=5)\n                self.horizontal_profile.plot(x=list(range(image.shape[1])), y=image[horizontal_line_position,:,i], pen=pen)\n                self.vertical_profile.plot(x=image[:,vertical_line_position,i], y=list(range(image.shape[0])), pen=pen)\n        else: # monochrome camera\n            pen = pg.mkPen(color='w', width=5)\n            self.horizontal_profile.plot(x=list(range(image.shape[1])), y=image[horizontal_line_position,:], pen=pen)\n            self.vertical_profile.plot(x=image[:,vertical_line_position], y=list(range(image.shape[0])), pen=pen)\n        self.horizontal_profile.setYRange(0,255)\n        self.vertical_profile.setXRange(0,255)\n\n        # show the image widget\n        self.image_widget.show()",
  "def display_camera_parameters(self, camera_parameters):\n        \"\"\"Display the current camera parameters on the GUI.\"\"\"\n        self.CurrentFramerateLabel.setText(str(camera_parameters['framerate']))\n        self.CurrentExposureLabel.setText(str(camera_parameters['exposure_time']))\n        self.CurrentWidthLabel.setText(str(camera_parameters['width']))\n        self.CurrentHeightLabel.setText(str(camera_parameters['height']))\n        self.MaxWidthLabel.setText(str(camera_parameters['max_width']))\n        self.MaxHeightLabel.setText(str(camera_parameters['max_height']))  \n        self.CurrentMasterGainLabel.setText(str(camera_parameters['master_gain']))\n        self.CurrentGainBoostLabel.setText(str(camera_parameters['gain_boost']))\n        self.CurrentBlacklevelLabel.setText(str(camera_parameters['blacklevel_offset']))\n        self.CurrentAutoBlacklevelLabel.setText(str(camera_parameters['auto_blacklevel']))\n        if self.set_whitebalance: self.CurrentAutoWhitebalanceLabel.setText(str(camera_parameters['auto_whitebalance']))\n        if self.set_gamma: self.CurrentGammaLabel.setText(str(camera_parameters['gamma']))",
  "def get_camera_parameters(self):\n        \"\"\"Read parameter values from the camera.\"\"\"\n        camera_parameters = dict()\n        camera_parameters['serial'] = self.camera.serial\n        camera_parameters['framerate'] = self.camera.framerate.magnitude\n        camera_parameters['exposure_time'] = self.camera._get_exposure().magnitude\n        camera_parameters['width'] = self.camera.width\n        camera_parameters['max_width'] = self.camera.max_width\n        camera_parameters['height'] = self.camera.height\n        camera_parameters['max_height'] = self.camera.max_height        \n        camera_parameters['master_gain'] = self.camera.master_gain\n        camera_parameters['gain_boost'] = self.camera.gain_boost\n        camera_parameters['blacklevel_offset'] = self.camera.blacklevel_offset\n        camera_parameters['auto_blacklevel'] = self.camera.auto_blacklevel\n        if self.set_whitebalance: camera_parameters['auto_whitebalance'] = self.camera.auto_whitebalance\n        if self.set_gamma: camera_parameters['gamma'] = self.camera.gamma\n        return camera_parameters",
  "def set_video_parameters(self):\n        \"\"\"Read parameters from the GUI and return a dictionary.\"\"\"\n        video_parameters = self.set_capture_parameters()        \n        framerate = \"{} hertz\".format(str(self.FramerateNumberBox.value()))\n        video_parameters['framerate'] = framerate                \n        return video_parameters",
  "def set_capture_parameters(self):\n        \"\"\"Read parameters from the GUI and return a dictionary.\"\"\"\n        capture_parameters = dict()\n        exposure_time = \"{} millisecond\".format(str(self.ExposureTimeNumberBox.value()))        \n        capture_parameters['exposure_time'] = exposure_time\n        capture_parameters['gain'] = float(self.GainNumberBox.value())\n        capture_parameters['vbin'] = int(self.VBinNumberBox.value())\n        capture_parameters['hbin'] = int(self.HBinNumberBox.value())\n        capture_parameters['vsub'] = int(self.VSubNumberBox.value())\n        capture_parameters['hsub'] = int(self.HSubNumberBox.value())        \n        capture_parameters = self.set_ROI(capture_parameters)\n        self.set_camera_properties()          \n        return capture_parameters",
  "def set_camera_properties(self):\n        \"\"\"Read parameters from the GUI and set the corresponding camera properties.\"\"\"\n        self.camera.auto_blacklevel = self.AutoBlacklevelCheckBox.checkState()\n        self.camera.blacklevel_offset = int(self.BlacklevelNumberBox.value())         \n        self.camera.gain_boost = self.GainBoostCheckBox.checkState()\n        if self.set_gamma: self.camera.gamma = int(self.GammaNumberBox.value())\n        if self.set_whitebalance: self.camera.auto_whitebalance = self.AutoWhitebalanceCheckBox.checkState()",
  "def set_ROI(self, parameters_dict):\n        \"\"\"Read ROI coordinates from the GUI.\"\"\"\n        ROI_dict = {'width':[self.ROIWidthCheckBox, self.ROIWidthNumberBox],\n                    'height':[self.ROIHeightCheckBox, self.ROIHeightNumberBox],\n                    'left':[self.ROILeftEdgeCheckBox, self.ROILeftEdgeNumberBox],\n                    'right':[self.ROIRightEdgeCheckBox, self.ROIRightEdgeNumberBox],\n                    'top':[self.ROITopEdgeCheckBox, self.ROITopEdgeNumberBox],\n                    'bot':[self.ROIBottomEdgeCheckBox, self.ROIBottomEdgeNumberBox],\n                    'cx':[self.ROICentreXCheckBox, self.ROICentreXNumberBox],\n                    'cy':[self.ROICentreYCheckBox, self.ROICentreYNumberBox],\n                    }\n        \n        # clear all of the old ROI parameters\n        for item in list(ROI_dict.keys()):\n            if item in list(parameters_dict.keys()):\n                del parameters_dict[item]\n        \n        # use maximum width and height available\n        parameters_dict['width'] = self.camera.max_width\n        parameters_dict['height'] = self.camera.max_height\n        \n        # repopulate ROI parameters with the selected ones\n        if self.ROICheckBox.checkState():            \n            for item in list(ROI_dict.keys()):\n                if ROI_dict[item][0].checkState():\n                    parameters_dict[item] = int(ROI_dict[item][1].value())\n        \n        return parameters_dict",
  "def grab_image(self):\n        \"\"\"Grab an image with the camera.\"\"\"\n        # set the desired capture parameters and update the attributes\n        capture_parameters = self.set_capture_parameters()\n        self.attributes.update(capture_parameters)\n        \n        # get the capture_timestamp with millisecond precision\n        # insert a T to match the creation_timestamp formatting\n        self.attributes['capture_timestamp'] = str(datetime.datetime.now()).replace(' ', 'T')\n\n        # grab the image\n        image = self.camera.grab_image(**capture_parameters)\n        self.get_brightest_pixel(image)\n        print('Image grabbed.\\n')\n\n        # get and display the camera parameters and update the attributes\n        camera_parameters = self.get_camera_parameters()\n        self.display_camera_parameters(camera_parameters)    \n        self.attributes.update(camera_parameters)               \n        return image",
  "def get_info(self):\n        \"\"\"Get info from the GUI.\"\"\"\n        info = dict()\n        info['description'] = self.DescriptionLineEdit.text()\n        return info",
  "def save_image(self, dummy_variable=False, group_name='images'):\n        \"\"\"Save the latest image.\"\"\"\n        # make a copy of the image so the saved image is the one that was on the \n        # screen when the save button was pressed, not when the file name was chosen\n        image = self.image\n        image_format = self.ImageFormatComboBox.currentText()\n        \n        if image_format == 'hdf5':\n            # update the attributes dictionary\n            self.attributes.update(self.get_info())\n            # get the datafile\n            if not self.df: self.new_hdf5_file()\n            # write data in the \"images\" group within the datafile\n            dg = self.df.require_group(name=group_name)\n            # write data to the file\n            dg.create_dataset(\"image_%d\", data=image, attrs=self.attributes)\n            dg.file.flush()\n            print(\"Image saved to the hdf5 file.\\n\")\n            \n        else:\n            # user input to choose file name\n            self.file_path = QtWidgets.QFileDialog.getSaveFileName(self, 'Save image', \n                                                                   self.file_path, \n                                                                   \"(*.\"+self.ImageFormatComboBox.currentText()+\")\")\n            if len(self.file_path):        \n                # save image            \n                imsave(self.file_path, np.flip(image, axis=0))\n                print(\"Image saved: \" + self.file_path + \"\\n\")\n            else:\n                print(\"WARNING: Image wasn't saved.\\n\")",
  "def new_hdf5_file(self):     \n        \"\"\"Open a new HDF5 file and its databrowser GUI.\"\"\"\n        # close the datafile\n        if self.df: self.df.close() \n        # open new datafile\n        self.df = nplab.current_datafile()\n        # close the databrowser gui\n        if self.df_gui: self.df_gui.close() \n        # open new databrowser gui\n        self.df_gui = self.df.show_gui(blocking=False)                    \n        # update the file name on the camera gui\n        self.FilePathLineEdit.setText(self.df.filename)\n        print()",
  "def live_view(self):\n        \"\"\"Continous image acquisition.\"\"\"\n        if self.LiveViewCheckBox.isChecked():                      \n            # enable/disable gui buttons\n            self.StopVideoPushButton.setEnabled(False)\n            # create thread\n            self.LiveView = LiveViewThread(self.camera)\n            # connect thread\n            self.LiveViewCheckBox.stateChanged.connect(self.LiveView.terminate)\n            self.LiveView.finished.connect(self.terminate_live_view)\n            # live view\n            print(\"Live view...\")\n            max_frames=float('inf')\n            self.start_live_view(save=False, max_frames=max_frames)",
  "def acquire_video(self):\n        \"\"\"Acquire video frames.\"\"\"            \n        # enable/disable gui buttons          \n        self.LiveViewCheckBox.setEnabled(False)\n        self.StopVideoPushButton.setEnabled(True)\n        self.SaveImagePushButton.setEnabled(False)\n        self.AutoExposurePushButton.setEnabled(False)\n        # create thread\n        self.LiveView = LiveViewThread(self.camera)\n        # connect thread\n        self.StopVideoPushButton.clicked.connect(self.LiveView.terminate)\n        self.LiveView.finished.connect(self.terminate_video_acquisition)\n        # live view\n        max_frames=self.MaxFramesNumberBox.value()\n        self.start_live_view(save=True, max_frames=max_frames)",
  "def start_live_view(self, save=False, max_frames=100):\n        \"\"\"Start continuous image acquisition.\"\"\"     \n        \n        # enable/disable gui buttons\n        self.TakeImagePushButton.setEnabled(False)\n        self.StartVideoPushButton.setEnabled(False)\n        self.OpenCameraPushButton.setEnabled(False)\n        self.CloseCameraPushButton.setEnabled(False)\n        self.NewFilePushButton.setEnabled(False)\n        \n        # connect signals\n        self.LiveView.display_signal.connect(self.display_image)\n        self.LiveView.attributes_signal.connect(self.update_attributes)\n        \n        # set video_parameters and update thread attributes\n        video_parameters = self.set_video_parameters()\n        self.LiveView.attributes.update(video_parameters)\n                \n        # start live view\n        self.LiveView.live_view(video_parameters, \n                                      save=save,\n                                      max_frames=max_frames,\n                                      timeout=self.TimeoutNumberBox.value(),                                      \n                                      display_framerate=self.DisplayFramerateNumberBox.value(),\n                                      )\n        \n        # get and display camera parameters and update thread attributes\n        camera_parameters = self.get_camera_parameters()    \n        self.display_camera_parameters(camera_parameters)\n        self.LiveView.attributes.update(camera_parameters)\n        self.LiveView.attributes.update(self.get_info())\n        \n        # start continuous image acquisition\n        self.LiveView.start()",
  "def update_attributes(self, attributes):\n        \"\"\"Update attributes dictionary and display on the GUI.\"\"\"\n        self.attributes.update(attributes)   \n        self.display_camera_parameters(self.attributes)",
  "def terminate_live_view(self):\n        \"\"\"This will run when the live view thread is terminated.\"\"\"\n        print(\"Finished live view.\\n\")\n        self.delete_thread()",
  "def terminate_video_acquisition(self):\n        \"\"\"This will run when the video acquisition thread is terminated.\"\"\"\n        print(\"Finished acquiring video.\\n\")\n        self.save_video()        \n        self.delete_thread()",
  "def delete_thread(self):    \n        \"\"\"Delete the live view thread and reset the GUI.\"\"\"\n        # stop live video mode\n        self.camera.stop_live_video()\n        # delete the thread to free up memory\n        del self.LiveView        \n        # remove some attribute keys so they don't get recorded in still images\n        attributes_keys_del = ['capture_time_sec', 'max_frames', 'timeout']\n        for key in attributes_keys_del:\n            if attributes_keys_del in list(self.attributes.keys()):\n                del self.attributes[key]\n        # reset the gui buttons\n        self.reset_gui_with_camera()",
  "def save_video(self):\n        \"\"\"Save the acquired video into a file.\"\"\"\n        print(\"Saving video to file, please wait for a while...\")            \n        # TODO: allow saving as different file formats other than hdf5\n        # TODO: write hdf5 data renderer for saved video from the colour camera\n        \n        # disable the GUI whilst the video is being saved\n        self.setEnabled(False)\n        \n        QtWidgets.qApp.processEvents()\n        # get the datafile\n        if not self.df: self.new_hdf5_file()\n        # get the \"videos\" group within the datafile\n        datagroup = self.df.require_group(\"videos\")\n        \n        # save video to the datafile\n        datagroup.create_dataset(\"video_%d\", \n                                 # save only the captured frames even if frame_number < max_frames\n                                 data=self.LiveView.image_array[list(range(self.LiveView.frame_number))],\n                                 attrs=self.LiveView.attributes)\n        \n        # flushing at the end\n        datagroup.file.flush() \n        print(\"Finished saving video.\\n\")",
  "def reset_gui_with_camera(self):\n        \"\"\"Enable/disable GUI elements when a camera connection exists.\"\"\"\n        self.setEnabled(True)\n        \n        self.StartVideoPushButton.setEnabled(True)  \n        self.StopVideoPushButton.setEnabled(False)\n\n        self.LiveViewCheckBox.setEnabled(True)\n        self.LiveViewCheckBox.setChecked(False)\n\n        self.TakeImagePushButton.setEnabled(True)\n        self.AutoExposurePushButton.setEnabled(True)\n        self.SaveImagePushButton.setEnabled(True)\n        \n        self.OpenCameraPushButton.setEnabled(False)\n        self.CloseCameraPushButton.setEnabled(True)\n        self.NewFilePushButton.setEnabled(True)",
  "def reset_gui_without_camera(self):\n        \"\"\"Enable/disable GUI elements when no camera connection exists.\"\"\"\n        self.setEnabled(True)\n        \n        self.StartVideoPushButton.setEnabled(False)  \n        self.StopVideoPushButton.setEnabled(False)\n\n        self.LiveViewCheckBox.setEnabled(False)\n        self.LiveViewCheckBox.setChecked(False)\n\n        self.TakeImagePushButton.setEnabled(False)\n        self.AutoExposurePushButton.setEnabled(False)\n        self.SaveImagePushButton.setEnabled(False)\n        \n        self.OpenCameraPushButton.setEnabled(True)\n        self.CloseCameraPushButton.setEnabled(False)\n        self.NewFilePushButton.setEnabled(False)",
  "def __init__(self, camera):\n        QtCore.QThread.__init__(self)       \n        self.camera = camera\n        self.attributes = dict()",
  "def __del__(self):\n        self.wait()",
  "def live_view(self, video_parameters, save=False, \n                        timeout=1000, max_frames=100,\n                        display_framerate = 10):\n        \"\"\"Start live view with the video parameters received from the main GUI.\"\"\"\n\n        self.timeout = \"{} millisecond\".format(str(timeout))        \n        self.save = save\n        self.max_frames = max_frames\n                       \n        # get the capture_timestamp with millisecond precision\n        # insert a T to match the creation_timestamp formatting\n        self.attributes['capture_timestamp'] = str(datetime.datetime.now()).replace(' ', 'T')\n        self.attributes['max_frames'] = max_frames\n        self.attributes['timeout'] = timeout\n        \n        # start timer with microsecond precision\n        self.high_precision_time = HighPrecisionWallTime()     \n        \n        # start live video\n        self.camera.start_live_video(**video_parameters)       \n        \n        # calculate when we need to emit the image to the gui        \n        capture_framerate = self.camera.framerate.magnitude\n        self.frame_multiple = int(capture_framerate/display_framerate)\n        # if display_framerate > capture_framerate then frame_multiple < 1\n        # since we cannot emit each image more than once, frame_multiple must be >= 1\n        if self.frame_multiple < 1: self.frame_multiple = 1\n        \n        # initialise data arrays\n        if save:\n            print(\"Recording video...\")  \n            \n            image = self.camera.latest_frame()\n            # image_array size is the max_frames by the size of the image taken (works for monochrome and colour)\n            self.array_dim = [self.max_frames] + list(image.shape)\n            print(\"Array dimensions: \" + str(self.array_dim))\n            \n            self.image_array = np.empty(self.array_dim, dtype='uint8') # unit8 for minimum file size\n            self.capture_timestamp_array = np.empty(self.max_frames, dtype='float')",
  "def run(self):\n        \"\"\"Continuously acquire frames until the stop button is pressed\n        or the maximum number of frames is reached.\"\"\"\n        self.frame_number = 0\n        while not self.isFinished() and self.frame_number < self.max_frames:\n            # we need to run wait_for_frame so the video framerate is consistent\n            if self.camera.wait_for_frame(timeout=self.timeout):        \n                # get the capture_time with microsecond precision\n                capture_time_sec = self.high_precision_time.sample()                \n                \n                # capture the latest frame\n                image = self.camera.latest_frame()\n                if self.save:\n                    self.save_frame(image, capture_time_sec, self.frame_number)\n                \n                if self.frame_number % self.frame_multiple == 0:\n                    # emit signals to the main gui\n                    self.attributes_signal.emit(self.attributes)\n                    self.display_signal.emit(image) # crashes more often - maybe?               \n                self.frame_number += 1",
  "def save_frame(self, image, capture_time_sec, frame_number):\n        \"\"\"Save the frame to RAM.\"\"\"\n        self.image_array[frame_number,:,:] = image\n        self.capture_timestamp_array[frame_number] = capture_time_sec\n        self.attributes['capture_time_sec'] = self.capture_timestamp_array",
  "def __init__(self,):\n        self._wall_time_0 = time.time()\n        self._clock_0 = time.clock()",
  "def sample(self,):\n        dc = time.clock()-self._clock_0\n        return self._wall_time_0 + dc",
  "def disarmer(f):\n    '''pauses live view during the calling of these functions\n    '''\n    @wraps(f)\n    def inner_func(self, *args, **kwargs):\n        if (l := self.live_view):\n            self.live_view = False\n        out = f(self, *args, **kwargs)\n        \n        if l:\n            self.live_view = True\n        return out\n    return inner_func",
  "class PrimeBSI(Camera):\n    notified_properties = ('gain',) # properties that are in the gui\n    disarmed_properties = ('gain', 'exp_time') # properties that break live view if changed\n    metadata_property_names = ('exposure', 'gain')\n    pixel_max = 2047.\n    def __init__(self):  \n        super().__init__()\n        pvc.init_pvcam()\n        self._camera = next(VCamera.detect_camera())\n        if not self._camera.is_open:\n            self._camera.open()\n        self._populate_properties()\n\n    \n    def _populate_properties(self):\n        ''' adds all the properties from TLCamera to Kiralux, for easy access.\n        \n        '''\n        def prop_factory(prime_prop,  notified=False, disarmed=False): # to get around late binding\n            def fget(self):\n                return prime_prop.fget(self._camera)\n            def fset(self, val):\n                return prime_prop.fset(self._camera, val)\n            if disarmed: fset = disarmer(fset)\n            if notified: return NotifiedProperty(*map(locked_action, (fget, fset)))\n            return property(*map(locked_action, (fget, fset)))\n        \n        cls = self.__class__    \n        for prime_attr in dir(prime_cls := self._camera.__class__):\n            if hasattr(prime_prop := getattr(prime_cls, prime_attr), 'fget'): \n                # if it's a property\n                if not hasattr(cls, prime_attr):\n                    # and it's not in Kiralux already\n                    setattr(cls,\n                            prime_attr, # add the property\n                            prop_factory(prime_prop,\n                                         prime_attr in cls.notified_properties,\n                                         prime_attr in cls.disarmed_properties))\n                                         # if it's in disarmed_properties, \n                                         # decorate the setter and return a \n                                         # notified property appropriately.\n    @NotifiedProperty\n    def exposure(self): # always in ms\n        if self.exp_res_index: # us\n            return self.exp_time // 1_000 \n        return self.exp_time\n    \n    @exposure.setter\n    def exposure(self, val): # ms\n        if self.exp_res_index: # us\n            val *= 1_000\n        self.exp_time = int(val)\n            \n    def raw_snapshot(self):\n        if self.live_view:\n            frame = self._camera.poll_frame()[0]['pixel_data']\n        else: \n            frame = self._camera.get_frame()\n        return True, frame\n\n    @Camera.live_view.setter\n    def live_view(self, live_view):\n        if live_view == self._live_view: return # small redundancy with Camera.live_view\n        Camera.live_view.fset(self, live_view)\n        if live_view:\n            self._camera.start_live()\n        else:\n            self._camera.finish()\n    \n    def color_image(self, **kwargs):\n        r = self.raw_image(**kwargs)\n        return np.append(r[:,:, None], np.zeros(r.shape + (2,)), axis=-1)\n    \n    def stack(self, exposures=(10, 100, 1000), **kwargs):\n        live_view = self.live_view\n        self.live_view = False\n        for i, e in enumerate(exposures):\n            self.exposure = e\n            im = self.raw_image(**kwargs)\n            if not i:\n                if isinstance(im, ArrayWithAttrs):\n                    images = ArrayWithAttrs(np.empty((len(exposures),)+im.shape, dtype=im.dtype,), \n                                            attrs=im.attrs | {'exposures': list(exposures)})\n                else:\n                    images = ArrayWithAttrs(np.empty((len(exposures),)+im.shape, dtype=im.dtype),\n                                            attrs={'exposures': list(exposures)})\n            images[i] = im\n        self.live_view = live_view\n        return images  \n    @classmethod\n    def combine(cls, stack):\n        exposures = stack.attrs['exposures']\n        stack[stack >= cls.pixel_max[1]*0.9] = np.nan\n  \n        weighted = np.divide(stack, exposures[:, None, None])\n        combined = np.nanmean(weighted, axis=0)\n        return combined\n        \n    def get_control_widget(self):\n        \"Get a Qt widget with the camera's controls (but no image display)\"\n        return PrimeCameraControlWidget(self)",
  "class PrimeCameraControlWidget(CameraControlWidget):\n    \"\"\"A control widget for the Thorlabs camera, with extra buttons.\"\"\"\n    def __init__(self, camera):\n        super().__init__(camera, auto_connect=False)\n        gb = QuickControlBox()\n        gb.add_spinbox(\"exposure\", 0, 10_000) \n        gb.add_spinbox(\"gain\", 1, 3) # setting range\n        gb.add_button(\"show_camera_properties_dialog\", title=\"Camera Setup\")\n        gb.add_button(\"show_video_format_dialog\", title=\"Video Format\")\n        self.layout().insertWidget(1, gb) # put the extra settings in the middle\n        self.quick_settings_groupbox = gb        \n        self.auto_connect_by_name(controlled_object=self.camera)",
  "def inner_func(self, *args, **kwargs):\n        if (l := self.live_view):\n            self.live_view = False\n        out = f(self, *args, **kwargs)\n        \n        if l:\n            self.live_view = True\n        return out",
  "def __init__(self):  \n        super().__init__()\n        pvc.init_pvcam()\n        self._camera = next(VCamera.detect_camera())\n        if not self._camera.is_open:\n            self._camera.open()\n        self._populate_properties()",
  "def _populate_properties(self):\n        ''' adds all the properties from TLCamera to Kiralux, for easy access.\n        \n        '''\n        def prop_factory(prime_prop,  notified=False, disarmed=False): # to get around late binding\n            def fget(self):\n                return prime_prop.fget(self._camera)\n            def fset(self, val):\n                return prime_prop.fset(self._camera, val)\n            if disarmed: fset = disarmer(fset)\n            if notified: return NotifiedProperty(*map(locked_action, (fget, fset)))\n            return property(*map(locked_action, (fget, fset)))\n        \n        cls = self.__class__    \n        for prime_attr in dir(prime_cls := self._camera.__class__):\n            if hasattr(prime_prop := getattr(prime_cls, prime_attr), 'fget'): \n                # if it's a property\n                if not hasattr(cls, prime_attr):\n                    # and it's not in Kiralux already\n                    setattr(cls,\n                            prime_attr, # add the property\n                            prop_factory(prime_prop,\n                                         prime_attr in cls.notified_properties,\n                                         prime_attr in cls.disarmed_properties))",
  "def exposure(self): # always in ms\n        if self.exp_res_index: # us\n            return self.exp_time // 1_000 \n        return self.exp_time",
  "def exposure(self, val): # ms\n        if self.exp_res_index: # us\n            val *= 1_000\n        self.exp_time = int(val)",
  "def raw_snapshot(self):\n        if self.live_view:\n            frame = self._camera.poll_frame()[0]['pixel_data']\n        else: \n            frame = self._camera.get_frame()\n        return True, frame",
  "def live_view(self, live_view):\n        if live_view == self._live_view: return # small redundancy with Camera.live_view\n        Camera.live_view.fset(self, live_view)\n        if live_view:\n            self._camera.start_live()\n        else:\n            self._camera.finish()",
  "def color_image(self, **kwargs):\n        r = self.raw_image(**kwargs)\n        return np.append(r[:,:, None], np.zeros(r.shape + (2,)), axis=-1)",
  "def stack(self, exposures=(10, 100, 1000), **kwargs):\n        live_view = self.live_view\n        self.live_view = False\n        for i, e in enumerate(exposures):\n            self.exposure = e\n            im = self.raw_image(**kwargs)\n            if not i:\n                if isinstance(im, ArrayWithAttrs):\n                    images = ArrayWithAttrs(np.empty((len(exposures),)+im.shape, dtype=im.dtype,), \n                                            attrs=im.attrs | {'exposures': list(exposures)})\n                else:\n                    images = ArrayWithAttrs(np.empty((len(exposures),)+im.shape, dtype=im.dtype),\n                                            attrs={'exposures': list(exposures)})\n            images[i] = im\n        self.live_view = live_view\n        return images",
  "def combine(cls, stack):\n        exposures = stack.attrs['exposures']\n        stack[stack >= cls.pixel_max[1]*0.9] = np.nan\n  \n        weighted = np.divide(stack, exposures[:, None, None])\n        combined = np.nanmean(weighted, axis=0)\n        return combined",
  "def get_control_widget(self):\n        \"Get a Qt widget with the camera's controls (but no image display)\"\n        return PrimeCameraControlWidget(self)",
  "def __init__(self, camera):\n        super().__init__(camera, auto_connect=False)\n        gb = QuickControlBox()\n        gb.add_spinbox(\"exposure\", 0, 10_000) \n        gb.add_spinbox(\"gain\", 1, 3) # setting range\n        gb.add_button(\"show_camera_properties_dialog\", title=\"Camera Setup\")\n        gb.add_button(\"show_video_format_dialog\", title=\"Video Format\")\n        self.layout().insertWidget(1, gb) # put the extra settings in the middle\n        self.quick_settings_groupbox = gb        \n        self.auto_connect_by_name(controlled_object=self.camera)",
  "def prop_factory(prime_prop,  notified=False, disarmed=False): # to get around late binding\n            def fget(self):\n                return prime_prop.fget(self._camera)\n            def fset(self, val):\n                return prime_prop.fset(self._camera, val)\n            if disarmed: fset = disarmer(fset)\n            if notified: return NotifiedProperty(*map(locked_action, (fget, fset)))\n            return property(*map(locked_action, (fget, fset)))",
  "def fget(self):\n                return prime_prop.fget(self._camera)",
  "def fset(self, val):\n                return prime_prop.fset(self._camera, val)",
  "def distance(p1, p2): # between two ndarrays\n    return  ((p1-p2)**2).sum()",
  "def af_merit_squared_laplacian(image):\n    \"\"\"Return the mean squared Laplacian of an image - a sharpness metric.\n\n    The image will be converted to grayscale if its shape is MxNx3\"\"\"\n    if len(image.shape) == 3:\n        image = np.mean(image, axis=2, dtype=image.dtype)\n    assert len(image.shape) == 2, \"The image is the wrong shape - must be 2D or 3D\"\n    return np.sum(cv2.Laplacian(image, ddepth=cv2.CV_32F) ** 2)",
  "class CameraWithLocation(Instrument):\n    \"\"\"\n    A class wrapping a camera and a stage, allowing them to work together.\n\n    This is designed to handle the low-level stuff like calibration, crosscorrelation, and closed-loop stage control.\n    It also handles autofocus, and has logic for drift correction.  It could compensate for a non-horizontal sample to\n    some extent by adding a tilt to the image plane - but this is as yet unimplemented.\n    \"\"\"\n    pixel_to_sample_displacement = None # A 3x3 matrix that relates displacements in pixels to distance units\n    pixel_to_sample_displacement_shape = None # The shape of the images taken to calibrate the stage\n    drift_estimate = None # Reserved for future use, to compensate for drift\n    datum_pixel = None # The position, in pixels in the image, of the \"datum point\" of the system.\n    settling_time = 0.0 # How long to wait for the stage to stop vibrating.\n    frames_to_discard = 1 # How many frames to discard from the camera after a move.\n    disable_live_view = DumbNotifiedProperty(False) # Whether to disable live view while calibrating/autofocusing/etc.\n    af_step_size = DumbNotifiedProperty(1) # The size of steps to take when autofocusing\n    af_steps = DumbNotifiedProperty(7) # The number of steps to take during autofocus\n    use_thumbnail = DumbNotifiedProperty(False)\n    def __init__(self, camera=None, stage=None):\n        # If no camera or stage is supplied, attempt to retrieve them - but crash with an exception if they don't exist.\n        if camera is None:\n            camera = Camera.get_instance(create=False)\n        if stage is None:\n            stage = Stage.get_instance(create=False)\n        self.camera = camera\n        self.stage = stage\n        self.filter_images = False\n        Instrument.__init__(self)\n\n        shape = self.camera.color_image().shape\n        self.datum_pixel = np.array(shape[:2])/2.0 # Default to using the centre of the image as the datum point\n   #     self.camera.set_legacy_click_callback(self.move_to_feature_pixel)\n        self.camera.set_legacy_click_callback(self.move_to_pixel)\n\n    @property\n    def pixel_to_sample_matrix(self):\n        here = self.datum_location\n        assert self.pixel_to_sample_displacement is not None, \"The CameraWithLocation must be calibrated before use!\"\n        datum_displacement = np.dot(ensure_3d(self.datum_pixel), self.pixel_to_sample_displacement)\n        M = np.zeros((4,4)) # NB M is never a matrix; that would create issues, as then all the vectors must be matrices\n        M[0:3, 0:3] = self.pixel_to_sample_displacement # We calibrate the conversion of displacements and store it\n        M[3, 0:3] = here - datum_displacement # Ensure that the datum pixel transforms to here.\n        return M\n\n    def _add_position_metadata(self, image):\n        \"\"\"Add position metadata to an image, assuming it has just been acquired\"\"\"\n        iwl = ImageWithLocation(image)\n        iwl.attrs['datum_pixel'] = self.datum_pixel\n        iwl.attrs['stage_position'] = self.stage.position\n        if self.pixel_to_sample_displacement is not None:\n  #          assert iwl.shape[:2] == self.pixel_to_sample_displacement.shape[:2], \"Image shape is not the same\" \\\n  #                                                                               \"as when we calibrated!\" #These lines dont make much sense, the iwl has the size of the image while the martix is always only 3x3\n            iwl.attrs['pixel_to_sample_matrix'] = self.pixel_to_sample_matrix\n        else:\n            iwl.attrs['pixel_to_sample_matrix'] = np.identity(4)\n            print('Stage is not yet calbirated')\n        return iwl\n\n\n    ####### Wrapping functions for the camera #######\n    def raw_image(self, *args, **kwargs):\n        \"\"\"Return a raw image from the camera, including position metadata\"\"\"\n        return self._add_position_metadata(self.camera.raw_image(*args, **kwargs))\n\n    def gray_image(self, *args, **kwargs):\n        \"\"\"Return a grayscale image from the camera, including position metadata\"\"\"\n        return self._add_position_metadata(self.camera.gray_image(*args, **kwargs))\n\n    def color_image(self,ignore_filter=False, *args, **kwargs):\n        \"\"\"Return a colour image from the camera, including position metadata\"\"\"\n        image = self.camera.color_image(*args, **kwargs)\n        if (ignore_filter == False and \n            self.filter_images == True and \n            self.camera.filter_function is not None):\n            image = self.camera.filter_function(image)\n        return self._add_position_metadata(image)\n    \n    @staticmethod\n    def crop_centered(image, size=(100,100)):\n        if size is None: return image\n        return image[image.shape[0]//2-size[0]//2:image.shape[0]//2+size[0]//2,\n                     image.shape[1]//2-size[1]//2:image.shape[1]//2+size[1]//2]\n    \n    def thumb_image(self, size=(100,100)):\n        \"\"\"Return a cropped \"thumb\" from the CWL with size  \"\"\"\n        image = self.color_image()\n        return self.crop_centered(image, size=size)\n\n    ###### Wrapping functions for the stage ######\n    def move(self, *args, **kwargs): # TODO: take account of drift\n        \"\"\"Move the stage to a given position\"\"\"\n        self.stage.move(*args, **kwargs)\n\n    def move_rel(self, *args, **kwargs):\n        \"\"\"Move the stage by a given amount\"\"\"\n        self.stage.move_rel(*args, **kwargs)\n    def move_to_pixel(self,x,y):\n        iwl = ImageWithLocation(self.camera.latest_raw_frame)\n        iwl.attrs['datum_pixel'] = self.datum_pixel\n#        self.use_previous_datum_location = True\n        iwl.attrs['pixel_to_sample_matrix'] = self.pixel_to_sample_matrix\n        if (iwl.pixel_to_sample_matrix != np.identity(4)).any():\n            #check if the image has been calibrated\n            #print('move coords', image.pixel_to_location([x,y]))\n            #print('current position', self.stage.position)\n            self.move(iwl.pixel_to_location([x,y]))\n            #print('post move position', self.stage.position)\n#        self.use_previous_datum_location = False\n    @property\n    def datum_location(self):\n        \"\"\"The location in the sample of the datum point (i.e. the current stage position, corrected for drift)\"\"\"\n        if self.drift_estimate == None:\n            return self.stage.position\n        else:\n            return self.stage.position-self.drift_estimate\n        return self.stage.position - self.drift_estimate\n\n    ####### Useful functions for closed-loop stage control #######\n    def settle(self, flush_camera=True, *args, **kwargs):\n        \"\"\"Wait for the stage to stop moving/vibrating, and (unless specified) discard frame(s) from the camera.\n\n        After moving the stage, to get a fresh image from the camera we usually need to both wait for the stage to stop\n        vibrating, and discard one or more frames from the camera, so we have a fresh one.  This function does both of\n        those things (except if flush_camera is False).\n        \"\"\"\n        time.sleep(self.settling_time)\n        for i in range(self.frames_to_discard):\n            self.camera.raw_image(*args, **kwargs)\n\n    def move_to_feature(self, feature,\n                        ignore_position=False,\n                        ignore_z_pos=False,\n                        margin=50,\n                        tolerance=0.5,\n                        max_iterations=10,\n                        max_allowed_movement=4,\n                        autofocus_first=False,\n                        autofocus_args={}):\n        \"\"\"Bring the feature in the supplied image to the centre of the camera\n\n        Strictly, what this aims to do is move the sample such that the datum pixel of the \"feature\" image is on the\n        datum pixel of the camera.  It does this by first (unless instructed not to) moving to the datum point as\n        defined by the image.  It then compares the image from the camera with the feature, and adjusts the position.\n\n        feature : ImageWithLocation or numpy.ndarray\n            The feature that we want to move to.\n        ignore_position : bool (optional, default False)\n            Set this to true to skip the initial move using the image's metadata.\n        margin : int (optional)\n            The maximum error, in pixels, that we can cope with (this sets the size of the search area we use to look\n            for the feature in the camera image, it is (2*range + 1) in both X and Y.  Set to 0 to use the maximum\n            possible search area (given by the difference in size between the feature image and the camera image)\n        tolerance : float (optional)\n            Once the error between our current position and the feature's position is below this threshold, we stop.\n        max_iterations : int (optional)\n            The maximum number of moves we make to fine-tune the position.\n        \"\"\"\n        if (feature.datum_pixel[0]<0 or feature.datum_pixel[0]>np.shape(feature)[0] or \n            feature.datum_pixel[1]<0 or feature.datum_pixel[1]>np.shape(feature)[1]):\n                self.log('The datum picture of the feature is outside of the image!',level = 'WARN')\n            \n        if not ignore_position:\n            try:\n                if ignore_z_pos:\n                    self.move(feature.datum_location[:2]) #ignore original z value\n                else:\n                    self.move(feature.datum_location) #initial move to where we recorded the feature was\n            except:\n                print(\"Warning: no position data in feature image, skipping initial move.\")\n        \n        if autofocus_first: self.autofocus(**autofocus_args)\n        image = self.color_image()\n        assert isinstance(image, ImageWithLocation), \"CameraWithLocation should return an ImageWithLocation...?\"\n\n        last_move = np.infty\n        for i in range(max_iterations):\n            try:\n                self.settle()\n                image = self.color_image(update_latest_frame=True)\n               # , image_size\n                pixel_position = locate_feature_in_image(image,\n                                                         feature,\n                                                         margin=margin,\n                                                         restrict=(margin > 0))\n             #   pixel_position = locate_feature_in_image(image, feature,margin=margin)\n                \n                new_position = image.pixel_to_location(pixel_position)\n                dist = distance(image.datum_location, new_position)\n                if dist > max_allowed_movement:\n                    self.log('feature identified too far away from camera position')\n                    break\n                self.move(new_position)\n                last_move = np.sqrt(np.sum((new_position - image.datum_location)**2)) # calculate the distance moved\n                self.log(\"Centering on feature, iteration {}, moved by {}\".format(i, last_move))\n                if last_move < tolerance:\n                    break\n            except Exception as e:\n                self.log(\"Error centering on feature, iteration {} raised an exception:\\n{}\\n\".format(i, e) +\n                         \"The feature size was {}\\n\".format(feature.shape) +\n                         \"The image size was {}\\n\".format(image.shape))\n\n        if last_move > tolerance:\n            self.log(\"Error centering on feature, final move was too large.\")\n        return last_move < tolerance\n    #\n    def move_to_feature_pixel(self,x,y,image = None):\n        if self.pixel_to_sample_matrix is not None:\n            if image is None:\n                image = self.color_image()\n            feature = image.feature_at((x,y))\n            self.last_feature = feature\n            self.move_to_feature(feature)\n        else:\n            print('CameraWithLocation is not yet calibrated!!')\n        \n\n    def autofocus(self, dz=None, merit_function=af_merit_squared_laplacian,\n                  method=\"centre_of_mass\", noise_floor=0.3,exposure_factor =1.0,\n                  use_thumbnail=None, update_progress=lambda p:p):\n        \"\"\"Move to a range of Z positions and measure focus, then move to the best one.\n\n        Arguments:\n        dz : np.array (optional, defaults to values specified in af_step_size and af_steps\n            Z positions, relative to the current position, to move to and measure focus.\n        merit_function : function, optional\n            A function that takes an image and returns a focus score, which we maximise.\n        update_progress : function, optional\n            This will be called each time we take an image - for use with run_function_modally.\n        \"\"\"\n        self.camera.exposure = self.camera.exposure/exposure_factor\n        if dz is None:\n            dz = (np.arange(self.af_steps) - (self.af_steps - 1)//2) * self.af_step_size # Default value\n        here = self.stage.position\n        positions = []  # positions keeps track of where we sample\n        powers = []  # powers holds the value of the merit fn at each point\n        camera_live_view = self.camera.live_view\n        if self.disable_live_view:\n            self.camera.live_view = False\n\n        for step_num, z in enumerate(dz):\n            self.stage.move(np.array([0, 0, z]) + here)\n            self.settle()\n            positions.append(self.stage.position)\n            if use_thumbnail or (use_thumbnail is None and self.use_thumbnail):\n                image = self.thumb_image()\n            else:\n                image = self.color_image(update_latest_frame=True)\n            powers.append(merit_function(image))\n            update_progress(step_num)\n        powers = np.array(powers)\n        positions = np.array(positions)\n        z = positions[:, 2]\n        if method == \"centre_of_mass\":\n            threshold = powers.min() + (powers.max() - powers.min()) * noise_floor\n            weights = powers - threshold\n            weights[weights < 0] = 0.  # zero out any negative values\n            indices_of_maxima = argrelextrema(np.pad(weights, (1, 1), 'minimum'), np.greater)[0]-1\n            number_of_maxima = indices_of_maxima.size\n            if (np.sum(weights) == 0):\n                print(\"Warning, something went wrong and all the autofocus scores were identical! Returning to initial position.\")\n                new_position = here # Return to initial position if something fails\n            elif (number_of_maxima == 1) and not (indices_of_maxima[0] == 0 or indices_of_maxima[-1] == (weights.size-1)):\n                new_position = np.dot(weights, positions)/ np.sum(weights)\n            else:\n                print(\"Warning, a maximum autofocus score could not be found. Returning to initial position.\")\n                new_position = here\n        elif method == \"parabola\":\n            coefficients = np.polyfit(z, powers, deg=2)  # fit a parabola\n            root = -coefficients[1]/ (2 * coefficients[\n                0])  # p = c[0]z**\" + c[1]z + c[2] which has max (or min) at 2c[0]z + c[1]=0 i.e. z=-c[1]/2c[0]\n            if z.min() < root and root < z.max():\n                new_position = [here[0], here[1], root]\n            else:\n                # The new position would have been outside the scan range - clip it to the outer points.\n                new_position = positions[powers.argmax(), :]\n        else:\n            new_position = positions[powers.argmax(), :]\n        self.stage.move(new_position)\n        self.camera.live_view = camera_live_view\n        update_progress(self.af_steps+1)\n        self.camera.exposure = self.camera.exposure*exposure_factor\n        return new_position - here, positions, powers\n\n    def quick_autofocus(self, dz=0.5, full_dz = None, trigger_full_af=True, update_progress=lambda p:p, **kwargs):\n        \"\"\"Do a quick 3-step autofocus, performing a full autofocus if needed\n\n        dz is a single number - we move this far above and below the current position.\"\"\"\n        shift, pos, powers = self.autofocus(np.array([-dz,0,dz]), method=\"parabola\", update_progress=update_progress)\n        if np.linalg.norm(shift) >= dz and trigger_full_af:\n            return self.autofocus(full_dz, update_progress=update_progress, **kwargs)\n        else:\n            return shift, pos, powers\n\n    def autofocus_gui(self):\n        \"\"\"Run an autofocus using default parameters, with a GUI progress bar.\"\"\"\n        run_function_modally(self.autofocus, progress_maximum=self.af_steps+1)\n\n    def quick_autofocus_gui(self):\n        \"\"\"Run an autofocus using default parameters, with a GUI progress bar.\"\"\"\n        run_function_modally(self.quick_autofocus, progress_maximum=self.af_steps+1)\n\n    def calibrate_xy(self,update_progress=lambda p:p, step = None, min_step = 1e-5, max_step=1000):\n        \"\"\"Make a series of moves in X and Y to determine the XY components of the pixel-to-sample matrix.\n\n        Arguments:\n        step : float, optional (default None)\n            The amount to move the stage by.  This should move the sample by approximately 1/10th of the field of view.\n            If it is left as None, we will attempt to auto-determine the step size (see below).\n        min_step : float, optional\n            If we auto-determine the step size, start with this step size.  It's deliberately tiny.\n        max_step : float, optional\n            If we're auto-determining the step size, fail if it looks like it's more than this.\n\n        This starts by gingerly moving the stage a tiny amount.  That is repeated, increasing the distance exponentially\n        until we see a reasonable movement.  This means we shouldn't need to worry too much about setting the distance\n        we use for calibration.\n\n        NB this currently assumes the stage deals with backlash correction for us.\n        \"\"\"\n        #,bonus_arg = None,\n        # First, acquire a template image:\n        self.settle()\n        starting_image = self.color_image()\n        starting_location = self.datum_location\n        w, h = starting_image.shape[:2]\n        template = starting_image[int(w/4):int(3*w/4),int(h/4):int(3*h/4), ...] # Use the central 50%x50% as template\n        threshold_shift = w*0.02 # Require a shift of at least 2% of the image's width ,changed s[0] to w\n        target_shift = w*0.1 # Aim for a shift of about 10%\n        # Swapping images[-1] for starting_image\n        assert np.sum((locate_feature_in_image(starting_image, template) - self.datum_pixel)**2) < 1, \"Template's not centred!\"\n        update_progress(1)\n        if step is None:\n            # Next, move a small distance until we see a shift, to auto-determine the calibration distance.\n            step = min_step\n            shift = 0\n            while np.linalg.norm(shift) < threshold_shift:\n                assert step < max_step, \"Error, we hit the maximum step before we saw the sample move.\"\n                self.move(starting_location + np.array([step, 0, 0]))\n                image = self.color_image()\n                shift = locate_feature_in_image(image, template) - image.datum_pixel\n                if np.sqrt(np.sum(shift**2)) > threshold_shift:\n                    break\n                else:\n                    step *= 10**(0.5)\n            step *= target_shift / shift # Scale the amount we step the stage by, to get a reasonable image shift.\n            \n        update_progress(2)\n        # Move the stage in a square, recording the displacement from both the stage and the camera\n        pixel_shifts = []\n        images = []\n        for i, p in enumerate([[-step, -step, 0],\n                               [-step,  step, 0],\n                               [step,   step, 0],\n                               [step,  -step, 0]]):\n          #          print 'premove'\n        #        print starting_location,p\n            self.move(starting_location + np.array(p))\n        #        print 'post move'\n            self.settle()\n            image = self.color_image(update_latest_frame=True)\n            pixel_shifts.append(-locate_feature_in_image(image, template) + image.datum_pixel)\n            images.append(image)\n            # NB the minus sign here: we want the position of the image we just took relative to the datum point of\n            # the template, not the other way around.\n            update_progress(3+i)\n        # We then use least-squares to fit the XY part of the matrix relating pixels to distance\n        # location_shifts = np.array([ensure_2d(im.datum_location - starting_location) for im in images])\n        # Does this need to be the datum_location... will this really work for when the stage has not previously been calibrated\n        location_shifts = np.array([ensure_2d(im.attrs['stage_position'] - starting_location) for im in images])\n        pixel_shifts = np.array(pixel_shifts)\n        print(np.shape(pixel_shifts),np.shape(location_shifts))\n        A, res, rank, s = np.linalg.lstsq(pixel_shifts, location_shifts) # we solve pixel_shifts*A = location_shifts\n\n        self.pixel_to_sample_displacement = np.zeros((3,3))\n        self.pixel_to_sample_displacement[2,2] = 1 # just pass Z through unaltered\n        self.pixel_to_sample_displacement[:2,:2] = A # A deals with xy only\n        fractional_error = np.sqrt(np.sum(res)/np.prod(pixel_shifts.shape)) / np.std(pixel_shifts)\n        print(fractional_error)\n        print(np.sum(res),np.prod(pixel_shifts.shape),np.std(pixel_shifts))\n        if fractional_error > 0.02: # Check it was a reasonably good fit\n            print(\"Warning: the error fitting measured displacements was %.1f%%\" % (fractional_error*100))\n        self.log(\"Calibrated the pixel-location matrix.\\nResiduals were {}% of the shift.\\nStage positions:\\n{}\\n\"\n                 \"Pixel shifts:\\n{}\\nResulting matrix:\\n{}\".format(fractional_error*100, location_shifts, pixel_shifts,\n                                                                   self.pixel_to_sample_displacement))\n        update_progress(7)\n        self.update_config('pixel_to_sample_displacement',self.pixel_to_sample_displacement)\n        return self.pixel_to_sample_displacement, location_shifts, pixel_shifts, fractional_error\n    def load_calibration(self):\n        \"\"\"Acquire a new spectrum and use it as a reference.\"\"\"\n        self.pixel_to_sample_displacement = self.config_file['pixel_to_sample_displacement'][:]\n    def get_qt_ui(self):\n        \"\"\"Create a QWidget that controls the camera.\n\n        Specifying control_only=True returns just the controls for the camera.\n        Otherwise, you get both the controls and a preview window.\n        \"\"\"\n        return CameraWithLocationUI(self)\n\n    def get_control_widget(self):\n        \"\"\"Create a QWidget to control the CameraWithLocation\"\"\"\n        return CameraWithLocationControlUI(self)",
  "class CameraWithLocationControlUI(QtWidgets.QWidget):\n    \"\"\"The control box for a CameraWithLocation\"\"\"\n    calibration_distance = DumbNotifiedProperty(0)\n    def __init__(self, cwl):\n        super(CameraWithLocationControlUI, self).__init__()\n        self.cwl = cwl\n        cc = QuickControlBox(\"Settings\")\n        cc.add_doublespinbox(\"calibration_distance\")\n        cc.add_button(\"calibrate_xy_gui\", \"Calibrate XY\")\n        cc.add_button('load_calibration_gui', 'Load Calibration')\n        cc.auto_connect_by_name(self)\n        self.calibration_controls = cc\n\n        fc = QuickControlBox(\"Autofocus\")\n        fc.add_doublespinbox(\"af_step_size\")\n        fc.add_spinbox(\"af_steps\")\n        fc.add_button(\"autofocus_gui\", \"Autofocus\")\n        fc.add_button(\"quick_autofocus_gui\", \"Quick Autofocus\")\n        fc.add_checkbox('use_thumbnail', 'Use Thumbnail')\n        fc.auto_connect_by_name(self.cwl)\n        self.focus_controls = fc\n\n        l = QtWidgets.QHBoxLayout()\n        l.addWidget(cc)\n        l.addWidget(fc)\n        self.setLayout(l)\n\n    def calibrate_xy_gui(self):\n        \"\"\"Run an XY calibration, with a progress bar in the foreground\"\"\"\n        # \n        run_function_modally(self.cwl.calibrate_xy,\n                             progress_maximum=self.cwl.af_steps+1, step = None if self.calibration_distance<= 0 else float(self.calibration_distance))\n    def load_calibration_gui(self):\n        self.cwl.load_calibration()",
  "class CameraWithLocationUI(QtWidgets.QWidget):\n    \"\"\"Generic user interface for a camera.\"\"\"\n\n    def __init__(self, cwl):\n        assert isinstance(cwl, CameraWithLocation), \"instrument must be a CameraWithLocation\"\n        super(CameraWithLocationUI, self).__init__()\n        self.cwl = cwl\n\n        # Set up the UI\n        self.setWindowTitle(self.cwl.camera.__class__.__name__ + \" (location-aware)\")\n        layout = QtWidgets.QVBoxLayout()\n        # We use a tabbed control section below an image.\n        self.tabs = QtWidgets.QTabWidget()\n        self.microscope_controls = self.cwl.get_control_widget()\n        self.camera_controls = self.cwl.camera.get_control_widget()\n        self.tabs.addTab(self.microscope_controls, \"Camera with Location controls\")\n        self.tabs.addTab(self.camera_controls, \"Camera\")\n        # The camera viewer widget is provided by the camera...\n        self.camera_preview = self.cwl.camera.get_preview_widget()\n        # The overall layout puts the image at the top and the controls below\n        l = QtWidgets.QVBoxLayout()\n        l.addWidget(self.camera_preview)\n        l.addWidget(self.tabs)\n        self.setLayout(l)",
  "class AcquireGridOfImages(ExperimentWithProgressBar):\n    \"\"\"Use a CameraWithLocation to acquire a grid of image tiles that can later be stitched together\"\"\"\n    def __init__(self, camera_with_location=None,completion_function= None, **kwargs):\n        super(AcquireGridOfImages, self).__init__(**kwargs)\n        self.cwl = camera_with_location\n        self.completion_function = completion_function\n\n    def prepare_to_run(self, n_tiles=None, overlap_pixels = 250,\n                       data_group=None, autofocus = False, *args, **kwargs):\n        self.autofocus = autofocus\n        self.progress_maximum = n_tiles[0] * n_tiles[1]\n        self.overlap_pixels = overlap_pixels\n        self.dest = self.cwl.create_data_group(\"tiled_image_%d\")  if data_group is None else data_group\n\n    def run(self, n_tiles=(1,1), autofocus_args=None):\n        \"\"\"Acquire a grid of images with the specified overlap.\"\"\"\n        self.update_progress(0)\n        centre_image = self.cwl.color_image()\n        scan_step = np.array(centre_image.shape[:2]) - self.overlap_pixels\n        self.log(\"Starting a {} scan with a step size of {}\".format(n_tiles, scan_step))\n\n        dest = self.dest\n        x_indices = np.arange(n_tiles[0]) - (n_tiles[0] - 1) / 2.0\n        y_indices = np.arange(n_tiles[1]) - (n_tiles[1] - 1) / 2.0\n        images_acquired = 0\n        try:\n            for y_index in y_indices:\n                for x_index in x_indices:\n                    # Go to the grid point\n                    self.cwl.move(centre_image.pixel_to_location(np.array([x_index, y_index]) * scan_step)[:2])\n                    # TODO: make autofocus update drift or something...\n                    if autofocus_args is not None:\n                        self.cwl.autofocus(**autofocus_args)\n                    self.cwl.settle()  # wait for the camera to be ready/stage to settle\n                    dest.create_dataset(\"tile_%d\",data=self.cwl.color_image())\n                    dest.file.flush()\n                    images_acquired += 1 # TODO: work out why I can't just use dest.count_numbered_items(\"tile\")\n                    self.update_progress(images_acquired)\n                x_indices = x_indices[::-1]  # reverse the X positions, so we do a snake-scan\n        except ExperimentStopped:\n            self.log(\"Experiment was aborted.\")\n        finally:\n            self.cwl.move(centre_image.datum_location)  # go back to the start point\n            if self.completion_function is not None:\n                self.completion_function()\n        return dest",
  "def __init__(self, camera=None, stage=None):\n        # If no camera or stage is supplied, attempt to retrieve them - but crash with an exception if they don't exist.\n        if camera is None:\n            camera = Camera.get_instance(create=False)\n        if stage is None:\n            stage = Stage.get_instance(create=False)\n        self.camera = camera\n        self.stage = stage\n        self.filter_images = False\n        Instrument.__init__(self)\n\n        shape = self.camera.color_image().shape\n        self.datum_pixel = np.array(shape[:2])/2.0 # Default to using the centre of the image as the datum point\n   #     self.camera.set_legacy_click_callback(self.move_to_feature_pixel)\n        self.camera.set_legacy_click_callback(self.move_to_pixel)",
  "def pixel_to_sample_matrix(self):\n        here = self.datum_location\n        assert self.pixel_to_sample_displacement is not None, \"The CameraWithLocation must be calibrated before use!\"\n        datum_displacement = np.dot(ensure_3d(self.datum_pixel), self.pixel_to_sample_displacement)\n        M = np.zeros((4,4)) # NB M is never a matrix; that would create issues, as then all the vectors must be matrices\n        M[0:3, 0:3] = self.pixel_to_sample_displacement # We calibrate the conversion of displacements and store it\n        M[3, 0:3] = here - datum_displacement # Ensure that the datum pixel transforms to here.\n        return M",
  "def _add_position_metadata(self, image):\n        \"\"\"Add position metadata to an image, assuming it has just been acquired\"\"\"\n        iwl = ImageWithLocation(image)\n        iwl.attrs['datum_pixel'] = self.datum_pixel\n        iwl.attrs['stage_position'] = self.stage.position\n        if self.pixel_to_sample_displacement is not None:\n  #          assert iwl.shape[:2] == self.pixel_to_sample_displacement.shape[:2], \"Image shape is not the same\" \\\n  #                                                                               \"as when we calibrated!\" #These lines dont make much sense, the iwl has the size of the image while the martix is always only 3x3\n            iwl.attrs['pixel_to_sample_matrix'] = self.pixel_to_sample_matrix\n        else:\n            iwl.attrs['pixel_to_sample_matrix'] = np.identity(4)\n            print('Stage is not yet calbirated')\n        return iwl",
  "def raw_image(self, *args, **kwargs):\n        \"\"\"Return a raw image from the camera, including position metadata\"\"\"\n        return self._add_position_metadata(self.camera.raw_image(*args, **kwargs))",
  "def gray_image(self, *args, **kwargs):\n        \"\"\"Return a grayscale image from the camera, including position metadata\"\"\"\n        return self._add_position_metadata(self.camera.gray_image(*args, **kwargs))",
  "def color_image(self,ignore_filter=False, *args, **kwargs):\n        \"\"\"Return a colour image from the camera, including position metadata\"\"\"\n        image = self.camera.color_image(*args, **kwargs)\n        if (ignore_filter == False and \n            self.filter_images == True and \n            self.camera.filter_function is not None):\n            image = self.camera.filter_function(image)\n        return self._add_position_metadata(image)",
  "def crop_centered(image, size=(100,100)):\n        if size is None: return image\n        return image[image.shape[0]//2-size[0]//2:image.shape[0]//2+size[0]//2,\n                     image.shape[1]//2-size[1]//2:image.shape[1]//2+size[1]//2]",
  "def thumb_image(self, size=(100,100)):\n        \"\"\"Return a cropped \"thumb\" from the CWL with size  \"\"\"\n        image = self.color_image()\n        return self.crop_centered(image, size=size)",
  "def move(self, *args, **kwargs): # TODO: take account of drift\n        \"\"\"Move the stage to a given position\"\"\"\n        self.stage.move(*args, **kwargs)",
  "def move_rel(self, *args, **kwargs):\n        \"\"\"Move the stage by a given amount\"\"\"\n        self.stage.move_rel(*args, **kwargs)",
  "def move_to_pixel(self,x,y):\n        iwl = ImageWithLocation(self.camera.latest_raw_frame)\n        iwl.attrs['datum_pixel'] = self.datum_pixel\n#        self.use_previous_datum_location = True\n        iwl.attrs['pixel_to_sample_matrix'] = self.pixel_to_sample_matrix\n        if (iwl.pixel_to_sample_matrix != np.identity(4)).any():\n            #check if the image has been calibrated\n            #print('move coords', image.pixel_to_location([x,y]))\n            #print('current position', self.stage.position)\n            self.move(iwl.pixel_to_location([x,y]))",
  "def datum_location(self):\n        \"\"\"The location in the sample of the datum point (i.e. the current stage position, corrected for drift)\"\"\"\n        if self.drift_estimate == None:\n            return self.stage.position\n        else:\n            return self.stage.position-self.drift_estimate\n        return self.stage.position - self.drift_estimate",
  "def settle(self, flush_camera=True, *args, **kwargs):\n        \"\"\"Wait for the stage to stop moving/vibrating, and (unless specified) discard frame(s) from the camera.\n\n        After moving the stage, to get a fresh image from the camera we usually need to both wait for the stage to stop\n        vibrating, and discard one or more frames from the camera, so we have a fresh one.  This function does both of\n        those things (except if flush_camera is False).\n        \"\"\"\n        time.sleep(self.settling_time)\n        for i in range(self.frames_to_discard):\n            self.camera.raw_image(*args, **kwargs)",
  "def move_to_feature(self, feature,\n                        ignore_position=False,\n                        ignore_z_pos=False,\n                        margin=50,\n                        tolerance=0.5,\n                        max_iterations=10,\n                        max_allowed_movement=4,\n                        autofocus_first=False,\n                        autofocus_args={}):\n        \"\"\"Bring the feature in the supplied image to the centre of the camera\n\n        Strictly, what this aims to do is move the sample such that the datum pixel of the \"feature\" image is on the\n        datum pixel of the camera.  It does this by first (unless instructed not to) moving to the datum point as\n        defined by the image.  It then compares the image from the camera with the feature, and adjusts the position.\n\n        feature : ImageWithLocation or numpy.ndarray\n            The feature that we want to move to.\n        ignore_position : bool (optional, default False)\n            Set this to true to skip the initial move using the image's metadata.\n        margin : int (optional)\n            The maximum error, in pixels, that we can cope with (this sets the size of the search area we use to look\n            for the feature in the camera image, it is (2*range + 1) in both X and Y.  Set to 0 to use the maximum\n            possible search area (given by the difference in size between the feature image and the camera image)\n        tolerance : float (optional)\n            Once the error between our current position and the feature's position is below this threshold, we stop.\n        max_iterations : int (optional)\n            The maximum number of moves we make to fine-tune the position.\n        \"\"\"\n        if (feature.datum_pixel[0]<0 or feature.datum_pixel[0]>np.shape(feature)[0] or \n            feature.datum_pixel[1]<0 or feature.datum_pixel[1]>np.shape(feature)[1]):\n                self.log('The datum picture of the feature is outside of the image!',level = 'WARN')\n            \n        if not ignore_position:\n            try:\n                if ignore_z_pos:\n                    self.move(feature.datum_location[:2]) #ignore original z value\n                else:\n                    self.move(feature.datum_location) #initial move to where we recorded the feature was\n            except:\n                print(\"Warning: no position data in feature image, skipping initial move.\")\n        \n        if autofocus_first: self.autofocus(**autofocus_args)\n        image = self.color_image()\n        assert isinstance(image, ImageWithLocation), \"CameraWithLocation should return an ImageWithLocation...?\"\n\n        last_move = np.infty\n        for i in range(max_iterations):\n            try:\n                self.settle()\n                image = self.color_image(update_latest_frame=True)\n               # , image_size\n                pixel_position = locate_feature_in_image(image,\n                                                         feature,\n                                                         margin=margin,\n                                                         restrict=(margin > 0))\n             #   pixel_position = locate_feature_in_image(image, feature,margin=margin)\n                \n                new_position = image.pixel_to_location(pixel_position)\n                dist = distance(image.datum_location, new_position)\n                if dist > max_allowed_movement:\n                    self.log('feature identified too far away from camera position')\n                    break\n                self.move(new_position)\n                last_move = np.sqrt(np.sum((new_position - image.datum_location)**2)) # calculate the distance moved\n                self.log(\"Centering on feature, iteration {}, moved by {}\".format(i, last_move))\n                if last_move < tolerance:\n                    break\n            except Exception as e:\n                self.log(\"Error centering on feature, iteration {} raised an exception:\\n{}\\n\".format(i, e) +\n                         \"The feature size was {}\\n\".format(feature.shape) +\n                         \"The image size was {}\\n\".format(image.shape))\n\n        if last_move > tolerance:\n            self.log(\"Error centering on feature, final move was too large.\")\n        return last_move < tolerance",
  "def move_to_feature_pixel(self,x,y,image = None):\n        if self.pixel_to_sample_matrix is not None:\n            if image is None:\n                image = self.color_image()\n            feature = image.feature_at((x,y))\n            self.last_feature = feature\n            self.move_to_feature(feature)\n        else:\n            print('CameraWithLocation is not yet calibrated!!')",
  "def autofocus(self, dz=None, merit_function=af_merit_squared_laplacian,\n                  method=\"centre_of_mass\", noise_floor=0.3,exposure_factor =1.0,\n                  use_thumbnail=None, update_progress=lambda p:p):\n        \"\"\"Move to a range of Z positions and measure focus, then move to the best one.\n\n        Arguments:\n        dz : np.array (optional, defaults to values specified in af_step_size and af_steps\n            Z positions, relative to the current position, to move to and measure focus.\n        merit_function : function, optional\n            A function that takes an image and returns a focus score, which we maximise.\n        update_progress : function, optional\n            This will be called each time we take an image - for use with run_function_modally.\n        \"\"\"\n        self.camera.exposure = self.camera.exposure/exposure_factor\n        if dz is None:\n            dz = (np.arange(self.af_steps) - (self.af_steps - 1)//2) * self.af_step_size # Default value\n        here = self.stage.position\n        positions = []  # positions keeps track of where we sample\n        powers = []  # powers holds the value of the merit fn at each point\n        camera_live_view = self.camera.live_view\n        if self.disable_live_view:\n            self.camera.live_view = False\n\n        for step_num, z in enumerate(dz):\n            self.stage.move(np.array([0, 0, z]) + here)\n            self.settle()\n            positions.append(self.stage.position)\n            if use_thumbnail or (use_thumbnail is None and self.use_thumbnail):\n                image = self.thumb_image()\n            else:\n                image = self.color_image(update_latest_frame=True)\n            powers.append(merit_function(image))\n            update_progress(step_num)\n        powers = np.array(powers)\n        positions = np.array(positions)\n        z = positions[:, 2]\n        if method == \"centre_of_mass\":\n            threshold = powers.min() + (powers.max() - powers.min()) * noise_floor\n            weights = powers - threshold\n            weights[weights < 0] = 0.  # zero out any negative values\n            indices_of_maxima = argrelextrema(np.pad(weights, (1, 1), 'minimum'), np.greater)[0]-1\n            number_of_maxima = indices_of_maxima.size\n            if (np.sum(weights) == 0):\n                print(\"Warning, something went wrong and all the autofocus scores were identical! Returning to initial position.\")\n                new_position = here # Return to initial position if something fails\n            elif (number_of_maxima == 1) and not (indices_of_maxima[0] == 0 or indices_of_maxima[-1] == (weights.size-1)):\n                new_position = np.dot(weights, positions)/ np.sum(weights)\n            else:\n                print(\"Warning, a maximum autofocus score could not be found. Returning to initial position.\")\n                new_position = here\n        elif method == \"parabola\":\n            coefficients = np.polyfit(z, powers, deg=2)  # fit a parabola\n            root = -coefficients[1]/ (2 * coefficients[\n                0])  # p = c[0]z**\" + c[1]z + c[2] which has max (or min) at 2c[0]z + c[1]=0 i.e. z=-c[1]/2c[0]\n            if z.min() < root and root < z.max():\n                new_position = [here[0], here[1], root]\n            else:\n                # The new position would have been outside the scan range - clip it to the outer points.\n                new_position = positions[powers.argmax(), :]\n        else:\n            new_position = positions[powers.argmax(), :]\n        self.stage.move(new_position)\n        self.camera.live_view = camera_live_view\n        update_progress(self.af_steps+1)\n        self.camera.exposure = self.camera.exposure*exposure_factor\n        return new_position - here, positions, powers",
  "def quick_autofocus(self, dz=0.5, full_dz = None, trigger_full_af=True, update_progress=lambda p:p, **kwargs):\n        \"\"\"Do a quick 3-step autofocus, performing a full autofocus if needed\n\n        dz is a single number - we move this far above and below the current position.\"\"\"\n        shift, pos, powers = self.autofocus(np.array([-dz,0,dz]), method=\"parabola\", update_progress=update_progress)\n        if np.linalg.norm(shift) >= dz and trigger_full_af:\n            return self.autofocus(full_dz, update_progress=update_progress, **kwargs)\n        else:\n            return shift, pos, powers",
  "def autofocus_gui(self):\n        \"\"\"Run an autofocus using default parameters, with a GUI progress bar.\"\"\"\n        run_function_modally(self.autofocus, progress_maximum=self.af_steps+1)",
  "def quick_autofocus_gui(self):\n        \"\"\"Run an autofocus using default parameters, with a GUI progress bar.\"\"\"\n        run_function_modally(self.quick_autofocus, progress_maximum=self.af_steps+1)",
  "def calibrate_xy(self,update_progress=lambda p:p, step = None, min_step = 1e-5, max_step=1000):\n        \"\"\"Make a series of moves in X and Y to determine the XY components of the pixel-to-sample matrix.\n\n        Arguments:\n        step : float, optional (default None)\n            The amount to move the stage by.  This should move the sample by approximately 1/10th of the field of view.\n            If it is left as None, we will attempt to auto-determine the step size (see below).\n        min_step : float, optional\n            If we auto-determine the step size, start with this step size.  It's deliberately tiny.\n        max_step : float, optional\n            If we're auto-determining the step size, fail if it looks like it's more than this.\n\n        This starts by gingerly moving the stage a tiny amount.  That is repeated, increasing the distance exponentially\n        until we see a reasonable movement.  This means we shouldn't need to worry too much about setting the distance\n        we use for calibration.\n\n        NB this currently assumes the stage deals with backlash correction for us.\n        \"\"\"\n        #,bonus_arg = None,\n        # First, acquire a template image:\n        self.settle()\n        starting_image = self.color_image()\n        starting_location = self.datum_location\n        w, h = starting_image.shape[:2]\n        template = starting_image[int(w/4):int(3*w/4),int(h/4):int(3*h/4), ...] # Use the central 50%x50% as template\n        threshold_shift = w*0.02 # Require a shift of at least 2% of the image's width ,changed s[0] to w\n        target_shift = w*0.1 # Aim for a shift of about 10%\n        # Swapping images[-1] for starting_image\n        assert np.sum((locate_feature_in_image(starting_image, template) - self.datum_pixel)**2) < 1, \"Template's not centred!\"\n        update_progress(1)\n        if step is None:\n            # Next, move a small distance until we see a shift, to auto-determine the calibration distance.\n            step = min_step\n            shift = 0\n            while np.linalg.norm(shift) < threshold_shift:\n                assert step < max_step, \"Error, we hit the maximum step before we saw the sample move.\"\n                self.move(starting_location + np.array([step, 0, 0]))\n                image = self.color_image()\n                shift = locate_feature_in_image(image, template) - image.datum_pixel\n                if np.sqrt(np.sum(shift**2)) > threshold_shift:\n                    break\n                else:\n                    step *= 10**(0.5)\n            step *= target_shift / shift # Scale the amount we step the stage by, to get a reasonable image shift.\n            \n        update_progress(2)\n        # Move the stage in a square, recording the displacement from both the stage and the camera\n        pixel_shifts = []\n        images = []\n        for i, p in enumerate([[-step, -step, 0],\n                               [-step,  step, 0],\n                               [step,   step, 0],\n                               [step,  -step, 0]]):\n          #          print 'premove'\n        #        print starting_location,p\n            self.move(starting_location + np.array(p))\n        #        print 'post move'\n            self.settle()\n            image = self.color_image(update_latest_frame=True)\n            pixel_shifts.append(-locate_feature_in_image(image, template) + image.datum_pixel)\n            images.append(image)\n            # NB the minus sign here: we want the position of the image we just took relative to the datum point of\n            # the template, not the other way around.\n            update_progress(3+i)\n        # We then use least-squares to fit the XY part of the matrix relating pixels to distance\n        # location_shifts = np.array([ensure_2d(im.datum_location - starting_location) for im in images])\n        # Does this need to be the datum_location... will this really work for when the stage has not previously been calibrated\n        location_shifts = np.array([ensure_2d(im.attrs['stage_position'] - starting_location) for im in images])\n        pixel_shifts = np.array(pixel_shifts)\n        print(np.shape(pixel_shifts),np.shape(location_shifts))\n        A, res, rank, s = np.linalg.lstsq(pixel_shifts, location_shifts) # we solve pixel_shifts*A = location_shifts\n\n        self.pixel_to_sample_displacement = np.zeros((3,3))\n        self.pixel_to_sample_displacement[2,2] = 1 # just pass Z through unaltered\n        self.pixel_to_sample_displacement[:2,:2] = A # A deals with xy only\n        fractional_error = np.sqrt(np.sum(res)/np.prod(pixel_shifts.shape)) / np.std(pixel_shifts)\n        print(fractional_error)\n        print(np.sum(res),np.prod(pixel_shifts.shape),np.std(pixel_shifts))\n        if fractional_error > 0.02: # Check it was a reasonably good fit\n            print(\"Warning: the error fitting measured displacements was %.1f%%\" % (fractional_error*100))\n        self.log(\"Calibrated the pixel-location matrix.\\nResiduals were {}% of the shift.\\nStage positions:\\n{}\\n\"\n                 \"Pixel shifts:\\n{}\\nResulting matrix:\\n{}\".format(fractional_error*100, location_shifts, pixel_shifts,\n                                                                   self.pixel_to_sample_displacement))\n        update_progress(7)\n        self.update_config('pixel_to_sample_displacement',self.pixel_to_sample_displacement)\n        return self.pixel_to_sample_displacement, location_shifts, pixel_shifts, fractional_error",
  "def load_calibration(self):\n        \"\"\"Acquire a new spectrum and use it as a reference.\"\"\"\n        self.pixel_to_sample_displacement = self.config_file['pixel_to_sample_displacement'][:]",
  "def get_qt_ui(self):\n        \"\"\"Create a QWidget that controls the camera.\n\n        Specifying control_only=True returns just the controls for the camera.\n        Otherwise, you get both the controls and a preview window.\n        \"\"\"\n        return CameraWithLocationUI(self)",
  "def get_control_widget(self):\n        \"\"\"Create a QWidget to control the CameraWithLocation\"\"\"\n        return CameraWithLocationControlUI(self)",
  "def __init__(self, cwl):\n        super(CameraWithLocationControlUI, self).__init__()\n        self.cwl = cwl\n        cc = QuickControlBox(\"Settings\")\n        cc.add_doublespinbox(\"calibration_distance\")\n        cc.add_button(\"calibrate_xy_gui\", \"Calibrate XY\")\n        cc.add_button('load_calibration_gui', 'Load Calibration')\n        cc.auto_connect_by_name(self)\n        self.calibration_controls = cc\n\n        fc = QuickControlBox(\"Autofocus\")\n        fc.add_doublespinbox(\"af_step_size\")\n        fc.add_spinbox(\"af_steps\")\n        fc.add_button(\"autofocus_gui\", \"Autofocus\")\n        fc.add_button(\"quick_autofocus_gui\", \"Quick Autofocus\")\n        fc.add_checkbox('use_thumbnail', 'Use Thumbnail')\n        fc.auto_connect_by_name(self.cwl)\n        self.focus_controls = fc\n\n        l = QtWidgets.QHBoxLayout()\n        l.addWidget(cc)\n        l.addWidget(fc)\n        self.setLayout(l)",
  "def calibrate_xy_gui(self):\n        \"\"\"Run an XY calibration, with a progress bar in the foreground\"\"\"\n        # \n        run_function_modally(self.cwl.calibrate_xy,\n                             progress_maximum=self.cwl.af_steps+1, step = None if self.calibration_distance<= 0 else float(self.calibration_distance))",
  "def load_calibration_gui(self):\n        self.cwl.load_calibration()",
  "def __init__(self, cwl):\n        assert isinstance(cwl, CameraWithLocation), \"instrument must be a CameraWithLocation\"\n        super(CameraWithLocationUI, self).__init__()\n        self.cwl = cwl\n\n        # Set up the UI\n        self.setWindowTitle(self.cwl.camera.__class__.__name__ + \" (location-aware)\")\n        layout = QtWidgets.QVBoxLayout()\n        # We use a tabbed control section below an image.\n        self.tabs = QtWidgets.QTabWidget()\n        self.microscope_controls = self.cwl.get_control_widget()\n        self.camera_controls = self.cwl.camera.get_control_widget()\n        self.tabs.addTab(self.microscope_controls, \"Camera with Location controls\")\n        self.tabs.addTab(self.camera_controls, \"Camera\")\n        # The camera viewer widget is provided by the camera...\n        self.camera_preview = self.cwl.camera.get_preview_widget()\n        # The overall layout puts the image at the top and the controls below\n        l = QtWidgets.QVBoxLayout()\n        l.addWidget(self.camera_preview)\n        l.addWidget(self.tabs)\n        self.setLayout(l)",
  "def __init__(self, camera_with_location=None,completion_function= None, **kwargs):\n        super(AcquireGridOfImages, self).__init__(**kwargs)\n        self.cwl = camera_with_location\n        self.completion_function = completion_function",
  "def prepare_to_run(self, n_tiles=None, overlap_pixels = 250,\n                       data_group=None, autofocus = False, *args, **kwargs):\n        self.autofocus = autofocus\n        self.progress_maximum = n_tiles[0] * n_tiles[1]\n        self.overlap_pixels = overlap_pixels\n        self.dest = self.cwl.create_data_group(\"tiled_image_%d\")  if data_group is None else data_group",
  "def run(self, n_tiles=(1,1), autofocus_args=None):\n        \"\"\"Acquire a grid of images with the specified overlap.\"\"\"\n        self.update_progress(0)\n        centre_image = self.cwl.color_image()\n        scan_step = np.array(centre_image.shape[:2]) - self.overlap_pixels\n        self.log(\"Starting a {} scan with a step size of {}\".format(n_tiles, scan_step))\n\n        dest = self.dest\n        x_indices = np.arange(n_tiles[0]) - (n_tiles[0] - 1) / 2.0\n        y_indices = np.arange(n_tiles[1]) - (n_tiles[1] - 1) / 2.0\n        images_acquired = 0\n        try:\n            for y_index in y_indices:\n                for x_index in x_indices:\n                    # Go to the grid point\n                    self.cwl.move(centre_image.pixel_to_location(np.array([x_index, y_index]) * scan_step)[:2])\n                    # TODO: make autofocus update drift or something...\n                    if autofocus_args is not None:\n                        self.cwl.autofocus(**autofocus_args)\n                    self.cwl.settle()  # wait for the camera to be ready/stage to settle\n                    dest.create_dataset(\"tile_%d\",data=self.cwl.color_image())\n                    dest.file.flush()\n                    images_acquired += 1 # TODO: work out why I can't just use dest.count_numbered_items(\"tile\")\n                    self.update_progress(images_acquired)\n                x_indices = x_indices[::-1]  # reverse the X positions, so we do a snake-scan\n        except ExperimentStopped:\n            self.log(\"Experiment was aborted.\")\n        finally:\n            self.cwl.move(centre_image.datum_location)  # go back to the start point\n            if self.completion_function is not None:\n                self.completion_function()\n        return dest",
  "def API():\n    \"\"\"Return ctypes interface to the lucamapi.dll dynamic library.\n\n    Raise WindowsError if the LuCam drivers are not installed.\n\n    \"\"\"\n    from numpy.ctypeslib import ndpointer\n    from ctypes import c_int, c_char_p, c_void_p, POINTER, WINFUNCTYPE\n    from ctypes.wintypes import (BOOL, BYTE, FLOAT, LONG, ULONG, USHORT,\n                                 DWORD, LPCSTR, LPCWSTR, HANDLE, HWND, HMENU)\n\n    pUCHAR_LUT = ndpointer(dtype=numpy.uint8, ndim=1, flags='C_CONTIGUOUS')\n    pUCHAR_RGB = ndpointer(dtype=numpy.uint8, ndim=3, flags='C_CONTIGUOUS')\n    pFLOAT_MATRIX33 = ndpointer(dtype=numpy.float32, ndim=2, shape=(3, 3),\n                                flags='C_CONTIGUOUS')\n\n    UCHAR = ctypes.c_ubyte\n    LONGLONG = ctypes.c_longlong\n    LPCTSTR = LPCSTR\n    pBYTE = POINTER(BYTE)\n    pUCHAR = POINTER(UCHAR)\n    pFLOAT = POINTER(FLOAT)\n    pLONG = POINTER(LONG)\n    pULONG = POINTER(ULONG)\n    pUSHORT = POINTER(USHORT)\n    pHANDLE = POINTER(HANDLE)\n    pLONGLONG = POINTER(LONGLONG)\n\n    class LUCAM_VERSION(ctypes.Structure):\n        \"\"\"Lucam version structure.\"\"\"\n        _fields_ = [\n            ('firmware', ULONG),\n            ('fpga', ULONG),\n            ('api', ULONG),\n            ('driver', ULONG),\n            ('serialnumber', ULONG),\n            ('reserved', ULONG)]\n\n        def __str__(self):\n            return print_structure(self)\n\n    class LUCAM_FRAME_FORMAT(ctypes.Structure):\n        \"\"\"Lucam frame format structure.\"\"\"\n        class X(ctypes.Union):\n            _fields_ = [('subSampleX', USHORT), ('binningX', USHORT)]\n\n        class Y(ctypes.Union):\n            _fields_ = [('subSampleY', USHORT), ('binningY', USHORT)]\n\n        _anonymous_ = ['_x', '_y']\n        _fields_ = [\n            ('xOffset', ULONG),\n            ('yOffset', ULONG),\n            ('width', ULONG),\n            ('height', ULONG),\n            ('pixelFormat', ULONG),\n            ('_x', X),\n            ('flagsX', USHORT),\n            ('_y', Y),\n            ('flagsY', USHORT)]\n\n        def __str__(self):\n            return print_structure(self)\n\n    class LUCAM_SNAPSHOT(ctypes.Structure):\n        \"\"\"Lucam snapshot settings structure.\"\"\"\n        class GAINS(ctypes.Union):\n            class RBGG(ctypes.Structure):\n                _fields_ = [\n                    ('gainRed', FLOAT),\n                    ('gainBlue', FLOAT),\n                    ('gainGrn1', FLOAT),\n                    ('gainGrn2', FLOAT)]\n\n            class MCYY(ctypes.Structure):\n                _fields_ = [\n                    ('gainMag', FLOAT),\n                    ('gainCyan', FLOAT),\n                    ('gainYel1', FLOAT),\n                    ('gainYel2', FLOAT)]\n\n            _anonymous_ = ['_rbgg', '_mcyy']\n            _fields_ = [('_rbgg', RBGG), ('_mcyy', MCYY)]\n\n        class STROBE(ctypes.Union):\n            _fields_ = [('useStrobe', BOOL), ('strobeFlags', ULONG)]\n\n        _anonymous_ = ['_gains', '_strobe']\n        _fields_ = [\n            ('exposure', FLOAT),  # time in ms to expose image before readout\n            ('gain', FLOAT),  # overall gain as a multiplicative factor\n            ('_gains', GAINS),\n            ('_strobe', STROBE),\n            ('strobeDelay', FLOAT),  # delay in ms from exposure to flash\n            ('useHwTrigger', c_int),  # wait for hardware trigger\n            ('timeout', FLOAT),  # max time in ms to wait for trigger\n            ('format', LUCAM_FRAME_FORMAT),\n            ('shutterType', ULONG),\n            ('exposureDelay', FLOAT),  # delay in ms from trigger to exposure\n            ('bufferlastframe', BOOL),\n            ('ulReserved2', ULONG),\n            ('flReserved1', FLOAT),\n            ('flReserved2', FLOAT)]\n\n        def __str__(self):\n            return print_structure(self)\n\n    class LUCAM_CONVERSION(ctypes.Structure):\n        \"\"\"Lucam conversion structure.\"\"\"\n        _fields_ = [\n            ('DemosaicMethod', ULONG),\n            ('CorrectionMatrix', ULONG)]\n\n    class LUCAM_CONVERSION_PARAMS(ctypes.Structure):\n        \"\"\"Structure used for new conversion functions.\"\"\"\n        class GAINS(ctypes.Union):\n            class YUV(ctypes.Structure):\n                _fields_ = [\n                    ('DigitalGain', FLOAT),\n                    ('DigitalWhiteBalanceU', FLOAT),\n                    ('DigitalWhiteBalanceV', FLOAT)]\n\n            class RGB(ctypes.Structure):\n                _fields_ = [\n                    ('DigitalGainRed', FLOAT),\n                    ('DigitalGainGreen', FLOAT),\n                    ('DigitalGainBlue', FLOAT)]\n\n            _anonymous_ = ['_yuv', '_rgb']\n            _fields_ = [('_yuv', YUV), ('_rgb', RGB)]\n\n        _anonymous_ = ['_gains']\n        _fields_ = [\n            ('Size', ULONG),\n            ('DemosaicMethod', ULONG),\n            ('CorrectionMatrix', ULONG),\n            ('FlipX', BOOL),\n            ('FlipY', BOOL),\n            ('Hue', FLOAT),\n            ('Saturation', FLOAT),\n            ('UseColorGainsOverWb', BOOL),\n            ('_gains', GAINS)]\n\n        def __str__(self):\n            return print_structure(self)\n\n    class LUCAM_IMAGE_FORMAT(ctypes.Structure):\n        \"\"\"Image format information.\"\"\"\n        _fields_ = [\n            ('Size', ULONG),\n            ('Width', ULONG),\n            ('Height', ULONG),\n            ('PixelFormat', ULONG),\n            ('ImageSize', ULONG),\n            ('LucamReserved', ULONG * 8)]\n\n        def __str__(self):\n            return print_structure(self)\n\n    pLUCAM_VERSION = POINTER(LUCAM_VERSION)\n    pLUCAM_FRAME_FORMAT = POINTER(LUCAM_FRAME_FORMAT)\n    pLUCAM_SNAPSHOT = POINTER(LUCAM_SNAPSHOT)\n    pLUCAM_CONVERSION = POINTER(LUCAM_CONVERSION)\n    pLUCAM_CONVERSION_PARAMS = POINTER(LUCAM_CONVERSION_PARAMS)\n    pLUCAM_IMAGE_FORMAT = POINTER(LUCAM_IMAGE_FORMAT)\n\n    # Callback function types\n    SnapshotCallback = WINFUNCTYPE(None, c_void_p, pBYTE, ULONG)\n    VideoFilterCallback = WINFUNCTYPE(None, c_void_p, pBYTE, ULONG)\n    RgbVideoFilterCallback = WINFUNCTYPE(None, c_void_p, pBYTE, ULONG, ULONG)\n    ProgressCallback = WINFUNCTYPE(BOOL, c_void_p, FLOAT)\n    Rs232Callback = WINFUNCTYPE(None, c_void_p)\n\n    # Function return and argument types\n    LucamNumCameras = (LONG, )\n    LucamEnumCameras = (LONG, pLUCAM_VERSION, ULONG)\n    LucamCameraOpen = (HANDLE, ULONG)\n    LucamCameraClose = (BOOL, HANDLE)\n    LucamCameraReset = (BOOL, HANDLE)\n    LucamQueryVersion = (BOOL, HANDLE, pLUCAM_VERSION)\n    LucamQueryExternInterface = (BOOL, HANDLE, pULONG)\n    LucamGetCameraId = (BOOL, HANDLE, pULONG)\n    LucamGetProperty = (BOOL, HANDLE, ULONG, pFLOAT, pLONG)\n    LucamSetProperty = (BOOL, HANDLE, ULONG, FLOAT, LONG)\n    LucamPropertyRange = (BOOL, HANDLE, ULONG, pFLOAT, pFLOAT, pFLOAT, pLONG)\n    LucamDisplayPropertyPage = (BOOL, HANDLE, HWND)\n    LucamDisplayVideoFormatPage = (BOOL, HANDLE, HWND)\n    LucamQueryDisplayFrameRate = (BOOL, HANDLE, pFLOAT)\n    LucamCreateDisplayWindow = (\n        BOOL, HANDLE, LPCTSTR, ULONG, c_int, c_int, c_int, c_int, HWND, HMENU)\n    LucamDestroyDisplayWindow = (BOOL, HANDLE)\n    LucamAdjustDisplayWindow = (\n        BOOL, HANDLE, LPCTSTR, c_int, c_int, c_int, c_int)\n    LucamReadRegister = (BOOL, HANDLE, LONG, LONG, pLONG)\n    LucamWriteRegister = (BOOL, HANDLE, LONG, LONG, pLONG)\n    LucamSetFormat = (BOOL, HANDLE, pLUCAM_FRAME_FORMAT, FLOAT)\n    LucamGetFormat = (BOOL, HANDLE, pLUCAM_FRAME_FORMAT, pFLOAT)\n    LucamEnumAvailableFrameRates = (ULONG, HANDLE, ULONG, pFLOAT)\n    LucamStreamVideoControl = (BOOL, HANDLE, ULONG, HWND)\n    LucamStreamVideoControlAVI = (BOOL, HANDLE, ULONG, LPCWSTR, HWND)\n    LucamTakeVideo = (BOOL, HANDLE, LONG, pBYTE)\n    LucamTakeVideoEx = (BOOL, HANDLE, pBYTE, pULONG, ULONG)\n    LucamCancelTakeVideo = (BOOL, HANDLE)\n    LucamTakeSnapshot = (BOOL, HANDLE, pLUCAM_SNAPSHOT, pBYTE)\n    LucamSaveImage = (BOOL, ULONG, ULONG, ULONG, pBYTE, LPCSTR)  # deprecated\n    LucamSaveImageEx = (BOOL, HANDLE, ULONG, ULONG, ULONG, pBYTE, LPCSTR)\n    LucamSaveImageW = (BOOL, ULONG, ULONG, ULONG, pBYTE, LPCWSTR)  # deprecated\n    LucamSaveImageWEx = (BOOL, HANDLE, ULONG, ULONG, ULONG, pBYTE, LPCWSTR)\n    LucamAddStreamingCallback = (LONG, HANDLE, VideoFilterCallback, c_void_p)\n    LucamRemoveStreamingCallback = (BOOL, HANDLE, LONG)\n    LucamAddRgbPreviewCallback = (\n        LONG, HANDLE, RgbVideoFilterCallback, c_void_p, ULONG)\n    LucamRemoveRgbPreviewCallback = (BOOL, HANDLE, LONG)\n    LucamQueryRgbPreviewPixelFormat = (BOOL, HANDLE, pULONG)\n    LucamAddSnapshotCallback = (LONG, HANDLE, SnapshotCallback, c_void_p)\n    LucamRemoveSnapshotCallback = (BOOL, HANDLE, LONG)\n    LucamConvertFrameToRgb24 = (\n        BOOL, HANDLE, pUCHAR_RGB, pBYTE, ULONG, ULONG, ULONG,\n        pLUCAM_CONVERSION)\n    LucamConvertFrameToRgb32 = (\n        BOOL, HANDLE, pBYTE, pBYTE, ULONG, ULONG, ULONG, pLUCAM_CONVERSION)\n    LucamConvertFrameToRgb48 = (\n        BOOL, HANDLE, pUSHORT, pUSHORT, ULONG, ULONG, ULONG, pLUCAM_CONVERSION)\n    LucamConvertFrameToGreyscale8 = (\n        BOOL, HANDLE, pBYTE, pBYTE, ULONG, ULONG, ULONG, pLUCAM_CONVERSION)\n    LucamConvertFrameToGreyscale16 = (\n        BOOL, HANDLE, pUSHORT, pUSHORT, ULONG, ULONG, ULONG, pLUCAM_CONVERSION)\n    LucamConvertBmp24ToRgb24 = (None, pUCHAR_RGB, ULONG, ULONG)\n    LucamConvertRawAVIToStdVideo = (BOOL, HANDLE, LPCWSTR, LPCWSTR, ULONG)\n    LucamPreviewAVIOpen = (HANDLE, LPCWSTR)\n    LucamPreviewAVIClose = (BOOL, HANDLE)\n    LucamPreviewAVIControl = (BOOL, HANDLE, ULONG, HWND)\n    LucamPreviewAVIGetDuration = (\n        BOOL, HANDLE, pLONGLONG, pLONGLONG, pLONGLONG, pLONGLONG)\n    LucamPreviewAVIGetFrameCount = (BOOL, HANDLE, pLONGLONG)\n    LucamPreviewAVIGetFrameRate = (BOOL, HANDLE, pFLOAT)\n    LucamPreviewAVIGetPositionTime = (\n        BOOL, HANDLE, pLONGLONG, pLONGLONG, pLONGLONG, pLONGLONG)\n    LucamPreviewAVIGetPositionFrame = (BOOL, HANDLE, pLONGLONG)\n    LucamPreviewAVISetPositionTime = (\n        BOOL, HANDLE, LONGLONG, LONGLONG, LONGLONG, LONGLONG)\n    LucamPreviewAVISetPositionFrame = (BOOL, HANDLE, LONGLONG)\n    LucamPreviewAVIGetFormat = (BOOL, HANDLE, pLONG, pLONG, pLONG, pLONG)\n    LucamSetupCustomMatrix = (BOOL, HANDLE, pFLOAT_MATRIX33)\n    LucamGetCurrentMatrix = (BOOL, HANDLE, pFLOAT_MATRIX33)\n    LucamEnableFastFrames = (BOOL, HANDLE, pLUCAM_SNAPSHOT)\n    LucamTakeFastFrame = (BOOL, HANDLE, pBYTE)\n    LucamForceTakeFastFrame = (BOOL, HANDLE, pBYTE)\n    LucamTakeFastFrameNoTrigger = (BOOL, HANDLE, pBYTE)\n    LucamDisableFastFrames = (BOOL, HANDLE)\n    LucamSetTriggerMode = (BOOL, HANDLE, BOOL)\n    LucamTriggerFastFrame = (BOOL, HANDLE)\n    LucamCancelTakeFastFrame = (BOOL, HANDLE)\n    LucamEnableSynchronousSnapshots = (\n        HANDLE, ULONG, pHANDLE, POINTER(pLUCAM_SNAPSHOT))\n    LucamTakeSynchronousSnapshots = (BOOL, HANDLE, POINTER(pBYTE))\n    LucamDisableSynchronousSnapshots = (BOOL, HANDLE)\n    LucamGpioRead = (BOOL, HANDLE, pBYTE, pBYTE)\n    LucamGpioWrite = (BOOL, HANDLE, BYTE)\n    LucamGpoSelect = (BOOL, HANDLE, BYTE)\n    LucamGpioConfigure = (BOOL, HANDLE, BYTE)\n    LucamOneShotAutoExposure = (\n        BOOL, HANDLE, UCHAR, ULONG, ULONG, ULONG, ULONG)\n    LucamOneShotAutoWhiteBalance = (BOOL, HANDLE, ULONG, ULONG, ULONG, ULONG)\n    LucamOneShotAutoWhiteBalanceEx = (\n        BOOL, HANDLE, FLOAT, FLOAT, ULONG, ULONG, ULONG, ULONG)\n    LucamDigitalWhiteBalance = (BOOL, HANDLE, ULONG, ULONG, ULONG, ULONG)\n    LucamDigitalWhiteBalanceEx = (\n        BOOL, HANDLE, FLOAT, FLOAT, ULONG, ULONG, ULONG, ULONG)\n    LucamAdjustWhiteBalanceFromSnapshot = (\n        BOOL, HANDLE, pLUCAM_SNAPSHOT, pBYTE, FLOAT, FLOAT, ULONG, ULONG,\n        ULONG, ULONG)\n    LucamOneShotAutoIris = (BOOL, HANDLE, UCHAR, ULONG, ULONG, ULONG, ULONG)\n    LucamContinuousAutoExposureEnable = (\n        BOOL, HANDLE, UCHAR, ULONG, ULONG, ULONG, ULONG, FLOAT)\n    LucamContinuousAutoExposureDisable = (BOOL, HANDLE)\n    LucamAutoFocusStart = (\n        BOOL, HANDLE, ULONG, ULONG, ULONG, ULONG, FLOAT, FLOAT, FLOAT,\n        ProgressCallback, c_void_p)\n    LucamAutoFocusWait = (BOOL, HANDLE, DWORD)\n    LucamAutoFocusStop = (BOOL, HANDLE)\n    LucamAutoFocusQueryProgress = (BOOL, HANDLE, pFLOAT)\n    LucamInitAutoLens = (BOOL, HANDLE, BOOL)\n    LucamSetup8bitsLUT = (BOOL, HANDLE, pUCHAR_LUT, ULONG)\n    LucamSetup8bitsColorLUT = (\n        BOOL, HANDLE, pUCHAR_LUT, ULONG, BOOL, BOOL, BOOL, BOOL)\n    LucamRs232Transmit = (c_int, HANDLE, c_char_p, c_int)\n    LucamRs232Receive = (c_int, HANDLE, c_char_p, c_int)\n    LucamAddRs232Callback = (BOOL, HANDLE, Rs232Callback, c_void_p)\n    LucamRemoveRs232Callback = (None, HANDLE)\n    LucamPermanentBufferRead = (BOOL, HANDLE, pUCHAR, ULONG, ULONG)\n    LucamPermanentBufferWrite = (BOOL, HANDLE, pUCHAR, ULONG, ULONG)\n    LucamGetTruePixelDepth = (BOOL, HANDLE, pULONG)\n    LucamSetTimeout = (BOOL, HANDLE, BOOL, FLOAT)\n    LucamGetLastError = (ULONG, )\n    LucamGetLastErrorForCamera = (ULONG, HANDLE)\n\n    # Pixel format IDs\n    LUCAM_PF_8 = 0  # 8 bit raw or monochrome data\n    LUCAM_PF_16 = 1  # 16 bit raw or monochrome data\n    LUCAM_PF_24 = 2  # 24 bit color data; 8 bits for red, green and blue\n    LUCAM_PF_YUV422 = 3  # 16 bit YUV data\n    LUCAM_PF_COUNT = 4  # count of pixels with intensity above threshold\n    LUCAM_PF_FILTER = 5  # only pixels with intensity above threshold\n    LUCAM_PF_32 = 6  # 32 bit color data; 8 bits for red, green, blue and alpha\n    LUCAM_PF_48 = 7  # 48 bit color data; 16 bits for red, green and blue\n    # Properties uses to access camera settings\n    LUCAM_PROP_BRIGHTNESS = 0\n    LUCAM_PROP_CONTRAST = 1\n    LUCAM_PROP_HUE = 2\n    LUCAM_PROP_SATURATION = 3\n    LUCAM_PROP_SHARPNESS = 4\n    LUCAM_PROP_GAMMA = 5\n    LUCAM_PROP_PAN = 16\n    LUCAM_PROP_TILT = 17\n    LUCAM_PROP_ROLL = 18\n    LUCAM_PROP_ZOOM = 19\n    LUCAM_PROP_EXPOSURE = 20\n    LUCAM_PROP_IRIS = 21\n    LUCAM_PROP_FOCUS = 22\n    LUCAM_PROP_GAIN = 40\n    LUCAM_PROP_GAIN_RED = 41\n    LUCAM_PROP_GAIN_BLUE = 42\n    LUCAM_PROP_GAIN_GREEN1 = 43\n    LUCAM_PROP_GAIN_GREEN2 = 44\n    LUCAM_PROP_GAIN_MAGENTA = 41\n    LUCAM_PROP_GAIN_CYAN = 42\n    LUCAM_PROP_GAIN_YELLOW1 = 43\n    LUCAM_PROP_GAIN_YELLOW2 = 44\n    LUCAM_PROP_DEMOSAICING_METHOD = 64\n    LUCAM_PROP_CORRECTION_MATRIX = 65\n    LUCAM_PROP_FLIPPING = 66\n    LUCAM_PROP_DIGITAL_WHITEBALANCE_U = 69\n    LUCAM_PROP_DIGITAL_WHITEBALANCE_V = 70\n    LUCAM_PROP_DIGITAL_GAIN = 71\n    LUCAM_PROP_DIGITAL_GAIN_RED = 72\n    LUCAM_PROP_DIGITAL_GAIN_GREEN = 73\n    LUCAM_PROP_DIGITAL_GAIN_BLUE = 74\n    LUCAM_PROP_COLOR_FORMAT = 80\n    LUCAM_PROP_MAX_WIDTH = 81\n    LUCAM_PROP_MAX_HEIGHT = 82\n    LUCAM_PROP_ABS_FOCUS = 85\n    LUCAM_PROP_BLACK_LEVEL = 86\n    LUCAM_PROP_KNEE1_EXPOSURE = 96\n    LUCAM_PROP_STILL_KNEE1_EXPOSURE = 96\n    LUCAM_PROP_KNEE2_EXPOSURE = 97\n    LUCAM_PROP_STILL_KNEE2_EXPOSURE = 97\n    LUCAM_PROP_STILL_KNEE3_EXPOSURE = 98\n    LUCAM_PROP_VIDEO_KNEE = 99\n    LUCAM_PROP_KNEE1_LEVEL = 99\n    LUCAM_PROP_THRESHOLD = 101\n    LUCAM_PROP_AUTO_EXP_TARGET = 103\n    LUCAM_PROP_TIMESTAMPS = 105\n    LUCAM_PROP_SNAPSHOT_CLOCK_SPEED = 106  # 0 is fastest\n    LUCAM_PROP_AUTO_EXP_MAXIMUM = 107\n    LUCAM_PROP_TEMPERATURE = 108\n    LUCAM_PROP_TRIGGER = 110\n    LUCAM_PROP_FRAME_GATE = 112\n    LUCAM_PROP_EXPOSURE_INTERVAL = 113\n    LUCAM_PROP_PWM = 114\n    LUCAM_PROP_MEMORY = 115  # value is RO and represent # of frames in memory\n    LUCAM_PROP_STILL_STROBE_DURATION = 116\n    LUCAM_PROP_FAN = 118\n    LUCAM_PROP_SYNC_MODE = 119\n    LUCAM_PROP_SNAPSHOT_COUNT = 120\n    LUCAM_PROP_LSC_X = 121\n    LUCAM_PROP_LSC_Y = 122\n    LUCAM_PROP_AUTO_IRIS_MAX = 123\n    LUCAM_PROP_LENS_STABILIZATION = 124\n    LUCAM_PROP_VIDEO_TRIGGER = 125\n    LUCAM_PROP_KNEE2_LEVEL = 163\n    LUCAM_PROP_THRESHOLD_LOW = 165\n    LUCAM_PROP_THRESHOLD_HIGH = 166\n    LUCAM_PROP_TEMPERATURE2 = 167\n    LUCAM_PROP_LIGHT_FREQUENCY = 168\n    LUCAM_PROP_LUMINANCE = 169\n    LUCAM_PROP_AUTO_GAIN_MAXIMUM = 170\n    LUCAM_PROP_AUTO_SHARPNESS_GAIN_THRESHOLD_LOW = 171\n    LUCAM_PROP_AUTO_SHARPNESS_GAIN_THRESHOLD_HIGH = 172\n    LUCAM_PROP_AUTO_SHARPNESS_LOW = 173\n    LUCAM_PROP_AUTO_SHARPNESS_HIGH = 174\n    LUCAM_PROP_JPEG_QUALITY = 256\n    # Binning will be used instead of subsampling\n    LUCAM_FRAME_FORMAT_FLAGS_BINNING = 0x0001\n    # Property flags\n    LUCAM_PROP_FLAG_USE = 0x80000000  # control use of particular property\n    LUCAM_PROP_FLAG_AUTO = 0x40000000  # control use of property auto function\n    LUCAM_PROP_FLAG_MASTER = 0x40000000  # LUCAM_PROP_SYNC_MODE\n    LUCAM_PROP_FLAG_STROBE_FROM_START_OF_EXPOSURE = 0x20000000\n    LUCAM_PROP_FLAG_BACKLASH_COMPENSATION = 0x20000000\n    LUCAM_PROP_FLAG_USE_FOR_SNAPSHOTS = 0x04000000\n    LUCAM_PROP_FLAG_POLARITY = 0x10000000\n    LUCAM_PROP_FLAG_MEMORY_READBACK = 0x08000000  # LUCAM_PROP_MEMORY\n    LUCAM_PROP_FLAG_BUSY = 0x00040000\n    LUCAM_PROP_FLAG_UNKNOWN_MAXIMUM = 0x00020000\n    LUCAM_PROP_FLAG_UNKNOWN_MINIMUM = 0x00010000\n    LUCAM_PROP_FLAG_LITTLE_ENDIAN = 0x80000000  # for LUCAM_PROP_COLOR_FORMAT\n    LUCAM_PROP_FLAG_ALTERNATE = 0x00080000\n    LUCAM_PROP_FLAG_READONLY = 0x00010000\n    LUCAM_PROP_FLAG_HW_ENABLE = 0x40000000  # VIDEO_TRIGGER\n    LUCAM_PROP_FLAG_SW_TRIGGER = 0x00200000  # VIDEO_TRIGGER\n    # Use with LUCAM_PROP_GAMMA, LUCAM_PROP_BRIGHTNESS, LUCAM_PROP_CONTRAST\n    LUCAM_PROP_FLAG_RED = 0x00000001\n    LUCAM_PROP_FLAG_GREEN1 = 0x00000002\n    LUCAM_PROP_FLAG_GREEN2 = 0x00000004\n    LUCAM_PROP_FLAG_BLUE = 0x00000008\n    # Do not access these properties unless you know what you are doing\n    LUCAM_PROP_STILL_EXPOSURE = 50\n    LUCAM_PROP_STILL_GAIN = 51\n    LUCAM_PROP_STILL_GAIN_RED = 52\n    LUCAM_PROP_STILL_GAIN_GREEN1 = 53\n    LUCAM_PROP_STILL_GAIN_GREEN2 = 54\n    LUCAM_PROP_STILL_GAIN_BLUE = 55\n    LUCAM_PROP_STILL_GAIN_MAGENTA = 52\n    LUCAM_PROP_STILL_GAIN_YELLOW1 = 53\n    LUCAM_PROP_STILL_GAIN_YELLOW2 = 54\n    LUCAM_PROP_STILL_GAIN_CYAN = 55\n    # Color formats for use with LUCAM_PROP_COLOR_FORMAT\n    # Bayer format used by camera sensor\n    LUCAM_CF_MONO = 0\n    LUCAM_CF_BAYER_RGGB = 8\n    LUCAM_CF_BAYER_GRBG = 9\n    LUCAM_CF_BAYER_GBRG = 10\n    LUCAM_CF_BAYER_BGGR = 11\n    LUCAM_CF_BAYER_CYYM = 16\n    LUCAM_CF_BAYER_YCMY = 17\n    LUCAM_CF_BAYER_YMCY = 18\n    LUCAM_CF_BAYER_MYYC = 19\n    # Parameter for LUCAM_PROP_FLIPPING\n    LUCAM_PROP_FLIPPING_NONE = 0\n    LUCAM_PROP_FLIPPING_X = 1\n    LUCAM_PROP_FLIPPING_Y = 2\n    LUCAM_PROP_FLIPPING_XY = 3\n    # Streaming Video Modes\n    STOP_STREAMING = 0\n    START_STREAMING = 1\n    START_DISPLAY = 2\n    PAUSE_STREAM = 3\n    START_RGBSTREAM = 6\n    # Streaming AVI Modes\n    STOP_AVI = 0\n    START_AVI = 1\n    PAUSE_AVI = 2\n    # Parameters for AVI types\n    AVI_RAW_LUMENERA = 0\n    AVI_STANDARD_24 = 1\n    AVI_STANDARD_32 = 2\n    AVI_XVID_24 = 3\n    AVI_STANDARD_8 = 4\n    # Use with LUCAM_CONVERSION.DemosaicMethod\n    LUCAM_DM_NONE = 0\n    LUCAM_DM_FAST = 1\n    LUCAM_DM_HIGH_QUALITY = 2\n    LUCAM_DM_HIGHER_QUALITY = 3\n    LUCAM_DM_SIMPLE = 8\n    # Use with LUCAM_CONVERSION.CorrectionMatrix\n    LUCAM_CM_NONE = 0\n    LUCAM_CM_FLUORESCENT = 1\n    LUCAM_CM_DAYLIGHT = 2\n    LUCAM_CM_INCANDESCENT = 3\n    LUCAM_CM_XENON_FLASH = 4\n    LUCAM_CM_HALOGEN = 5\n    LUCAM_CM_IDENTITY = 14\n    LUCAM_CM_CUSTOM = 15\n    # Shutter types\n    LUCAM_SHUTTER_TYPE_GLOBAL = 0\n    LUCAM_SHUTTER_TYPE_ROLLING = 1\n    # Extern interfaces\n    LUCAM_EXTERN_INTERFACE_USB1 = 1\n    LUCAM_EXTERN_INTERFACE_USB2 = 2\n    # use with LucamRegisterEventNotification\n    LUCAM_EVENT_START_OF_READOUT = 2\n    LUCAM_EVENT_GPI1_CHANGED = 4\n    LUCAM_EVENT_GPI2_CHANGED = 5\n    LUCAM_EVENT_GPI3_CHANGED = 6\n    LUCAM_EVENT_GPI4_CHANGED = 7\n    LUCAM_EVENT_DEVICE_SURPRISE_REMOVAL = 32\n\n    if sys.platform == 'win32':\n        _api = ctypes.windll.LoadLibrary('lucamapi.dll')\n    else:\n        raise NotImplementedError(\"Only Windows is supported\")\n\n    for _name, _value in list(locals().items()):\n        if _name.startswith('Lucam'):\n            _func = getattr(_api, _name)\n            setattr(_func, 'restype', _value[0])\n            setattr(_func, 'argtypes', _value[1:])\n        elif not _name.startswith('_'):\n            setattr(_api, _name, _value)\n    return _api",
  "class Lucam(object):\n    \"\"\"Lumenera camera interface.\n\n    Names of wrapper functions have the 'Lucam' prefix removed from\n    their API counterparts.\n\n    Member functions raise LucamError() if an error occurs in the\n    underlying API function call.\n\n    Camera properties can be accessed in different ways. E.g. the property\n    LUCAM_PROP_BRIGHTNESS of a Lucam instance 'lucam' can is accessible as:\n\n    * lucam.GetProperty(API.LUCAM_PROP_BRIGHTNESS)\n    * lucam.GetProperty('brightness')\n    * lucam.brightness\n\n    \"\"\"\n    Version = API.LUCAM_VERSION\n    FrameFormat = API.LUCAM_FRAME_FORMAT\n    Snapshot = API.LUCAM_SNAPSHOT\n    Conversion = API.LUCAM_CONVERSION\n    ConversionParams = API.LUCAM_CONVERSION_PARAMS\n    ImageFormat = API.LUCAM_IMAGE_FORMAT\n\n    PROPERTY = {}\n    PROP_FLAG = {}\n    PROP_FLIPPING = {}\n    PIXEL_FORMAT = {}\n    COLOR_FORMAT = {}\n    DEMOSAIC_METHOD = {}\n    CORRECT_MATRIX = {}\n    EXTERN_INTERFACE = {}\n    AVI_TYPE = {}\n    EVENT_ID = {}\n\n    for name in dir(API):\n        value = getattr(API, name)\n        if name.startswith('_'):\n            continue\n        elif name.startswith('LUCAM_PROP_FLAG_'):\n            PROP_FLAG[name[16:].lower()] = value\n        elif name.startswith('LUCAM_PROP_FLIPPING_'):\n            PROP_FLIPPING[name[20:].lower()] = value\n        elif name.startswith('LUCAM_PROP_'):\n            PROPERTY[name[11:].lower()] = value\n        elif name.startswith('LUCAM_PF_'):\n            PIXEL_FORMAT[name[9:].lower()] = value\n        elif name.startswith('LUCAM_CF_'):\n            COLOR_FORMAT[name[9:].lower()] = value\n        elif name.startswith('LUCAM_CM_'):\n            CORRECT_MATRIX[name[9:].lower()] = value\n        elif name.startswith('LUCAM_DM_'):\n            DEMOSAIC_METHOD[name[9:].lower()] = value\n        elif name.startswith('LUCAM_EVENT_'):\n            EVENT_ID[name[12:].lower()] = value\n        elif name.startswith('AVI_'):\n            AVI_TYPE[name[4:].lower()] = value\n        elif name.startswith('LUCAM_EXTERN_INTERFACE_'):\n            EXTERN_INTERFACE[value] = name[23:]\n    #del value\n    #del name\n\n    VIDEO_CONTROL = dict(stop_streaming=0, start_streaming=1, start_display=2,\n                         pause_stream=3, start_rgbstream=6)\n\n    def __init__(self, number=1):\n        \"\"\"Open connection to Lumenera camera.\n\n        number : int\n            Camera number. Must be in range 1 through LucamNumCameras().\n\n        \"\"\"\n        self._handle = API.LucamCameraOpen(number)\n        if not self._handle:\n            raise LucamError(API.LucamGetLastError())\n        self._byteorder = '<' if self.is_little_endian() else '>'\n        self._default_frameformat, self._default_framerate = self.GetFormat()\n        self._fastframe = None  # frame format while in fast frame mode\n        self._streaming = None  # frame format while in streaming mode\n        self._callbacks = {}  # references to callback functions\n        self._displaying_window = False\n\n    def __del__(self):\n        \"\"\"Close connection to camera.\"\"\"\n        assert not self._displaying_window\n        assert self._fastframe is None\n        assert self._streaming is None\n        if self._handle:\n            API.LucamCameraClose(self._handle)\n\n    def __str__(self):\n        \"\"\"Return detailed information about camera as string.\"\"\"\n        default = self._default_frameformat\n        camid = self.GetCameraId()\n        version = self.QueryVersion()\n        interface = self.QueryExternInterface()\n        frame, fps = self.GetFormat()\n        allfps = self.EnumAvailableFrameRates()\n        depth = self.GetTruePixelDepth()\n        littleendian = self.is_little_endian()\n        gpo, gpi = self.GpioRead()\n        pixformat = 'raw8 raw16 RGB24 YUV422 Count Filter RGBA32 RGB48'.split()\n\n        result = [\n            \"\",\n            \"Camera handle: %s\" % hex(int(self._handle)),\n            \"Camera ID: %s\" % hex(int(camid)),\n            \"Camera model: %s\" % CAMERA_MODEL.get(camid, \"Unknown\"),\n            \"Serial number: %s\" % version.serialnumber,\n            \"Firmware version: %s\" % print_version(version.firmware),\n            \"FPGA version: %s\" % print_version(version.fpga),\n            \"API version: %s\" % print_version(version.api),\n            \"Driver version: %s\" % print_version(version.driver),\n            \"Interface: %s\" % Lucam.EXTERN_INTERFACE[interface],\n            \"Endianess: %s\" % (\"little\" if littleendian else \"big\"),\n            \"GPIO output registers: 0x%01X\" % gpo,\n            \"GPIO input registers: 0x%01X\" % gpi,\n            \"Default size: %i x %i\" % (default.width, default.height),\n            \"Default pixel format: %s\" % pixformat[default.pixelFormat],\n            \"Default frame rate: %.2f\" % self._default_framerate,\n            \"Image offset: %i, %i\" % (frame.xOffset, frame.yOffset),\n            \"Image size: %i x %i\" % (frame.width // frame.binningX,\n                                     frame.height // frame.binningY),\n            \"Binning: %ix%i\" % (frame.binningX, frame.binningY)\n            if frame.flagsX else\n            \"Subsampling: %ix%i\" % (frame.subSampleX, frame.subSampleY),\n            \"Pixel format: %s\" % pixformat[frame.pixelFormat],\n            \"Pixel depth: %i bit\" % (depth if frame.pixelFormat else 8),\n            \"Frame rate: %.2f\" % fps,\n            \"Available frame rates: %s\" % ', '.join('%.2f' % f\n                                                    for f in allfps)\n        ]\n        #mn = API.FLOAT()\n        #mx = API.FLOAT()\n        value = API.FLOAT()\n        flags = API.LONG()\n        for name in sorted(Lucam.PROPERTY):\n            prop = Lucam.PROPERTY[name]\n            if API.LucamGetProperty(self._handle, prop, value, flags):\n                name = name.capitalize().replace('_', ' ')\n                if flags.value:\n                    result.append(\"%s: %s (%s)\" % (\n                        name, value.value,\n                        \",\".join(list_property_flags(flags.value))))\n                else:\n                    result.append(\"%s: %s\" % (name, value.value))\n            #if API.LucamPropertyRange(self._handle, prop,\n            #                          mn, mx, value, flags):\n            #    result.append(\"%s range: %s\" % (name, print_range(\n            #            mn.value, mx.value, value.value, flags.value)))\n        return \"\\n* \".join(result)\n\n    def __getattr__(self, name):\n        \"\"\"Return value of PROPERTY or PROP_RANGE attribute.\"\"\"\n        if name in Lucam.PROPERTY:\n            return self.GetProperty(name)[0]\n        elif name.endswith(\"_range\"):\n            result = self.PropertyRange(name[:-6])\n            setattr(self, name, result)\n            return result\n        raise AttributeError(\"'Lucam' object has no attribute '%s'\" % name)\n\n    def default_snapshot(self):\n        \"\"\"Return default Snapshot settings.\"\"\"\n        snapshot = API.LUCAM_SNAPSHOT()\n        snapshot.format = self.GetFormat()[0]\n        snapshot.exposure = self.GetProperty('exposure')[0]\n        snapshot.gain = self.GetProperty('gain')[0]\n        snapshot.timeout = 1000.0\n        snapshot.gainRed = 1.0\n        snapshot.gainBlue = 1.0\n        snapshot.gainGrn1 = 1.0\n        snapshot.gainGrn2 = 1.0\n        snapshot.useStrobe = False\n        snapshot.strobeDelay = 0.0\n        snapshot.useHwTrigger = 0\n        snapshot.shutterType = 0\n        snapshot.exposureDelay = 0.0\n        snapshot.bufferlastframe = 0\n        return snapshot\n\n    def default_conversion(self):\n        \"\"\"Return default Conversion settings for ConvertFrameToRgb24().\"\"\"\n        return API.LUCAM_CONVERSION(DemosaicMethod=API.LUCAM_DM_NONE,\n                                    CorrectionMatrix=API.LUCAM_CM_NONE)\n\n    def is_little_endian(self):\n        \"\"\"Return Endianess of camera.\"\"\"\n        value, flags = self.GetProperty(API.LUCAM_PROP_COLOR_FORMAT)\n        return bool(flags & API.LUCAM_PROP_FLAG_LITTLE_ENDIAN)\n\n    def set_properties(self, **kwargs):\n        \"\"\"Set value of mutiple camera properties.\"\"\"\n        for name, value in list(kwargs.items()):\n            if name.endswith('_flag'):\n                continue\n            prop = Lucam.PROPERTY[name]\n            flag = kwargs.get(name + '_flag', 0)\n            if not API.LucamSetProperty(self._handle, prop, value, flag):\n                raise LucamError(self)\n\n    def CameraClose(self):\n        \"\"\"Close connection to camera.\"\"\"\n        if self._displaying_window:\n            self.DestroyDisplayWindow()\n        if not API.LucamCameraClose(self._handle):\n            raise LucamError(self)\n        self._fastframe = None\n        self._streaming = None\n        self._handle = None\n\n    def CameraReset(self):\n        \"\"\"Reset camera to its power-on default state.\"\"\"\n        if not API.LucamCameraReset(self._handle):\n            raise LucamError(self)\n        self._fastframe = None\n        self._streaming = None\n\n    def QueryVersion(self):\n        \"\"\"Return camera version information as API.LUCAM_VERSION.\"\"\"\n        result = API.LUCAM_VERSION()\n        if not API.LucamQueryVersion(self._handle, result):\n            raise LucamError(self)\n        return result\n\n    def QueryExternInterface(self):\n        \"\"\"Return type of interface between camera and computer.\n\n        Return value is one of Lucam.EXTERN_INTERFACE keys.\n\n        \"\"\"\n        result = API.ULONG()\n        if not API.LucamQueryExternInterface(self._handle, result):\n            raise LucamError(self)\n        return result.value\n\n    def GetCameraId(self):\n        \"\"\"Return camera model ID, one of CAMERA_MODEL keys.\"\"\"\n        result = API.ULONG()\n        if not API.LucamGetCameraId(self._handle, result):\n            raise LucamError(self)\n        return result.value\n\n    def EnumAvailableFrameRates(self):\n        \"\"\"Return available frame rates based on camera's clock rates.\"\"\"\n        result = API.FLOAT()\n        size = API.LucamEnumAvailableFrameRates(self._handle, 0, result)\n        result = (API.FLOAT * size)()\n        if not API.LucamEnumAvailableFrameRates(self._handle, size, result):\n            raise LucamError(self)\n        return tuple(result)\n\n    def QueryDisplayFrameRate(self):\n        \"\"\"Return average displayed frame rate since preview started.\"\"\"\n        result = API.FLOAT()\n        if not API.LucamQueryDisplayFrameRate(self._handle, result):\n            raise LucamError(self)\n        return result.value\n\n    def DisplayPropertyPage(self, parent):\n        \"\"\"Open a DirectShow dialog window with camera properties.\"\"\"\n        if not API.LucamDisplayPropertyPage(self._handle, parent):\n            raise LucamError(self)\n\n    def DisplayVideoFormatPage(self, parent):\n        \"\"\"Open a DirectShow dialog window with video properties.\"\"\"\n        if not API.LucamDisplayVideoFormatPage(self._handle, parent):\n            raise LucamError(self)\n\n    def CreateDisplayWindow(self, title=b\"\", style=282001408,\n                            x=0, y=0, width=0, height=0, parent=0, menu=0):\n        \"\"\"Create window, managed by API, for displaying video.\n\n        Parameters\n        ----------\n        title : byte str\n            Title of window that appears in window frame.\n        style : int\n            Window style.\n        x, y : int\n           Coordinates of pixel in video stream that will appear in\n           upper left corner of display window. Default = 0.\n        width, height: int\n            Extent of scaled video stream in pixels.\n\n        The window is not automatically resized to the video frame size.\n\n        \"\"\"\n        if not API.LucamCreateDisplayWindow(\n                self._handle, title, style, x, y, width, height, parent, menu):\n            raise LucamError(self)\n        self._displaying_window = True\n\n    def DestroyDisplayWindow(self):\n        \"\"\"Destroy display window created with CreateDisplayWindow().\"\"\"\n        if not API.LucamDestroyDisplayWindow(self._handle):\n            raise LucamError(self)\n        self._displaying_window = False\n\n    def AdjustDisplayWindow(self, title=b\"\", x=0, y=0, width=0, height=0):\n        \"\"\"Scale video stream into preview window.\n\n        Parameters\n        ----------\n        title : byte str\n            Title of window that appears in window frame.\n        x, y : int\n           Coordinates of pixel in video stream that will appear in\n           upper left corner of display window. Can be used to pan the\n           display windows across the video stream.\n        width, height: int\n            Extent of scaled video stream in pixels. Can be used to zoom.\n\n        \"\"\"\n        if not API.LucamAdjustDisplayWindow(self._handle, title,\n                                            x, y, width, height):\n            raise LucamError(self)\n#        self._displaying_window = True #rwb27 commented this out as it's wrong when used to adjust a window I create...\n\n    def GetTruePixelDepth(self):\n        \"\"\"Return actual pixel depth when running in 16 bit mode.\"\"\"\n        result = API.ULONG()\n        if not API.LucamGetTruePixelDepth(self._handle, result):\n            raise LucamError(self)\n        return result.value\n\n    def GetVideoImageFormat(self):\n        \"\"\"Return video image format used to capture video frame.\n\n        Return type is API.LUCAM_IMAGE_FORMAT.\n\n        The video image format is needed to convert a raw Bayer frame\n        to either color or greyscale using the ConvertFrame***() functions.\n\n        \"\"\"\n        result = API.LUCAM_IMAGE_FORMAT()\n        if not API.LucamGetVideoImageFormat(self._handle, result):\n            raise LucamError(self)\n        return result\n\n    def GetLastErrorForCamera(self):\n        \"\"\"Return code of last error that occurred in a API function.\n\n        Error codes and messages can be found in LucamError.CODES.\n\n        \"\"\"\n        return API.LucamGetLastErrorForCamera(self._handle)\n\n    def SetProperty(self, prop, value, flags=0):\n        \"\"\"Set value of camera property.\n\n        Parameters\n        ----------\n        prop : int or str\n            Camera property. One of Lucam.PROPERTY keys or values.\n        flags : int or sequence of str\n            Capability flags for property. One or combination of\n            Lucam.PROP_FLAG. Default is 0.\n\n        Not all properties are supported by all cameras. If a capability\n        flag is not supported by the property, it is silently ignored.\n\n        \"\"\"\n        prop = Lucam.PROPERTY.get(prop, prop)\n        if isinstance(flags, (list, tuple)):\n            flags, flagseq = 0x0, flags\n            for f in flagseq:\n                flags |= Lucam.PROP_FLAG[f]\n        if not API.LucamSetProperty(self._handle, prop, value, flags):\n            raise LucamError(self)\n\n    def GetProperty(self, prop):\n        \"\"\"Return value and capability flag of camera property.\n\n        Parameters\n        ----------\n        prop : int or str\n            Camera property. One of Lucam.PROPERTY keys or values.\n\n        \"\"\"\n        value = API.FLOAT()\n        flags = API.LONG()\n        prop = Lucam.PROPERTY.get(prop, prop)\n        if not API.LucamGetProperty(self._handle, prop, value, flags):\n            raise LucamError(self)\n        return value.value, flags.value\n\n    def PropertyRange(self, prop):\n        \"\"\"Return range of valid values for property and its default value.\n\n        Return value is tuple of:\n            minimum valid value of camera property,\n            maximum valid value of camera property,\n            default value of camera property,\n            capability flags for property.\n\n        \"\"\"\n        mn = API.FLOAT()\n        mx = API.FLOAT()\n        default = API.FLOAT()\n        flags = API.LONG()\n        prop = Lucam.PROPERTY.get(prop, prop)\n        if not API.LucamPropertyRange(self._handle, prop, mn, mx,\n                                      default, flags):\n            raise LucamError(self)\n        return mn.value, mx.value, default.value, flags.value\n\n    def GetFormat(self):\n        \"\"\"Return frame format and rate of video data.\n\n        Return type is tuple of API.LUCAM_FRAME_FORMAT and framerate.\n\n        \"\"\"\n        frameformat = API.LUCAM_FRAME_FORMAT()\n        framerate = API.FLOAT()\n        if not API.LucamGetFormat(self._handle, frameformat, framerate):\n            raise LucamError(self)\n        return frameformat, framerate.value\n\n    def SetFormat(self, frameformat, framerate):\n        \"\"\"Set frame format and frame rate for video data.\n\n        Parameters\n        ----------\n        frameformat : API.LUCAM_FRAME_FORMAT\n            Video frame format.\n        framerate : float\n            Frame rate for streaming video.\n\n        The origin of the imager is top left. Each dimension of the subwindow\n        must be evenly divisible by 8.\n\n        \"\"\"\n        if not API.LucamSetFormat(self._handle, frameformat, framerate):\n            raise LucamError(self)\n        if self._fastframe:\n            self._fastframe = frameformat\n        if self._streaming:\n            self._streaming = frameformat\n\n    def ReadRegister(self, address, numreg):\n        \"\"\"Return values from contiguous internal camera registers.\n\n        Parameters\n        ----------\n        address : int\n            Starting register address.\n        numreg : int\n            Number of contiguous registers to read.\n\n        \"\"\"\n        result = (API.LONG * numreg)()\n        if not API.LucamReadRegister(self._handle, address, numreg, result):\n            raise LucamError(self)\n        return [v.value for v in result]\n\n    def WriteRegister(self, address, values):\n        \"\"\"Write values to contiguous internal camera registers.\n\n        Parameters\n        ----------\n        address : int\n            Starting register address.\n        values : sequence of int\n            Values to write into registers.\n\n        \"\"\"\n        numreg = len(values)\n        pvalue = (API.LONG * numreg)()\n        for i in range(numreg):\n            pvalue[i] = values[i]\n        if not API.LucamWriteRegister(self._handle, address, numreg, pvalue):\n            raise LucamError(self)\n\n    def SetTimeout(self, still, timeout):\n        \"\"\"Update timeout value set previously with API.LUCAM_SNAPSHOT.timeout.\n\n        Parameters\n        ----------\n        still : bool\n            If True, update timeout for snapshot mode, else for streaming mode.\n        timeout : float\n            Maximum time in ms to wait for trigger before returning from\n            function.\n\n        \"\"\"\n        if not API.LucamSetTimeout(self._handle, still, timeout):\n            raise LucamError(self)\n\n    def SetTriggerMode(self, usehwtrigger):\n        \"\"\"Sets trigger mode used for snapshots while in FastFrames mode.\n\n        Parameters\n        ----------\n        usehwtrigger : bool\n            If True, the camera is set to use the hardware trigger.\n\n        \"\"\"\n        if not API.LucamSetTriggerMode(self._handle, usehwtrigger):\n            raise LucamError(self)\n\n    def TriggerFastFrame(self):\n        \"\"\"Initiate the request to take a snapshot.\n\n        The camera should be in Fast Frames mode using EnableFastFrames().\n        This function will not wait for the return of the snapshot. Use\n        TakeFastFrame() or TakeFastFrameNoTrigger() to take the snapshot.\n\n        \"\"\"\n        if not API.LucamTriggerFastFrame(self._handle):\n            raise LucamError(self)\n\n    def CancelTakeFastFrame(self):\n        \"\"\"Cancel call to TakeFastFrame() and other functions.\n\n        Cancel calls to ForceTakeFastFrame(), TakeFastFrameNoTrigger() or\n        TakeSnapshot() made in another programming thread. The cancelled\n        function will raise LucamError(48).\n\n        \"\"\"\n        if not API.LucamCancelTakeFastFrame(self._handle):\n            raise LucamError(self)\n\n    def EnableFastFrames(self, snapshot=None):\n        \"\"\"Enable fast snapshot capture mode.\n\n        Parameters\n        ----------\n        snapshot : API.LUCAM_SNAPSHOT or None\n            Settings to use for the snapshot. If None (default),\n            settings returned by default_snapshot() will be used.\n\n        If video is streaming when a snapshot is taken, the stream will\n        automatically be stopped (pausing video in the display window if\n        present) before the snapshot is taken. It is not restarted after\n        the snapshot is taken.\n\n        \"\"\"\n        if snapshot is None:\n            snapshot = self.default_snapshot()\n        self._fastframe = snapshot.format\n        if not API.LucamEnableFastFrames(self._handle, snapshot):\n            self._fastframe = None\n            raise LucamError(self)\n\n    def TakeFastFrame(self, out=None, validate=True):\n        \"\"\"Return a single image using still imaging mode.\n\n        Parameters\n        ----------\n        out : numpy array, or None\n            Output buffer. If None, a new numpy.array containing the image\n            data is returned. Else image data will be copied into the\n            output array.\n        validate : bool\n            If True (default), size and dtype of the output array are\n            validated.\n\n        The camera should be in Fast Frames mode using EnableFastFrames().\n\n        \"\"\"\n        data, pdata = ndarray(self._fastframe, self._byteorder, out, validate)\n        if not API.LucamTakeFastFrame(self._handle, pdata):\n            raise LucamError(self)\n        if out is None:\n            return data\n\n    def ForceTakeFastFrame(self, out=None, validate=True):\n        \"\"\"Force a SW triggered snapshot while in HW triggered FastFrames mode.\n\n        Parameters\n        ----------\n        out : numpy array, or None\n            Output buffer. If None, a new numpy.array containing the image\n            data is returned. Else image data will be copied into the\n            output array.\n        validate : bool\n            If True (default), size and dtype of the output array are\n            validated.\n\n        Return a snapshot frame without waiting for the next HW trigger.\n\n        \"\"\"\n        data, pdata = ndarray(self._fastframe, self._byteorder, out, validate)\n        if not API.LucamForceTakeFastFrame(self._handle, pdata):\n            raise LucamError(self)\n        if out is None:\n            return data\n\n    def TakeFastFrameNoTrigger(self, out=None, validate=True):\n        \"\"\"Return previously taken single image using still imaging mode.\n\n        Parameters\n        ----------\n        out : numpy array, or None\n            Output buffer. If None, a new numpy.array containing the image\n            data is returned. Else image data will be copied into the\n            output array.\n        validate : bool\n            If True (default), size and dtype of the output array are\n            validated.\n\n        To use this function, the camera should be in Fast Frames mode\n        using EnableFastFrames().\n        If the camera is in HW triggered mode, this function can retrieve\n        a previously captured image from the API without sending an new\n        snapshot request and waiting for the next snapshot.\n\n        \"\"\"\n        data, pdata = ndarray(self._fastframe, self._byteorder,\n                              out, validate)\n        if not API.LucamTakeFastFrameNoTrigger(self._handle, pdata):\n            raise LucamError(self)\n        if out is None:\n            return data\n\n    def DisableFastFrames(self):\n        \"\"\"Disable fast snapshot capture mode.\n\n        If the camera was streaming when EnableFastFrames() was called,\n        streaming will be restored.\n\n        \"\"\"\n        self._fastframe = None\n        if not API.LucamDisableFastFrames(self._handle):\n            raise LucamError(self)\n\n    def TakeSnapshot(self, snapshot=None, out=None, validate=True):\n        \"\"\"Return single image as numpy array using still imaging.\n\n        Parameters\n        ----------\n        snapshot : API.LUCAM_SNAPSHOT or None\n            Settings to use for the snapshot. If None (default),\n            settings returned by default_snapshot() will be used.\n        out : numpy array, or None\n            Output buffer. If None, a new numpy.array containing the image\n            data is returned. Else image data will be copied into the\n            output array.\n\n        Equivalent to calling EnableFastFrames(), TakeFastFrame(), and\n        DisableFastFrames().\n\n        \"\"\"\n        if snapshot is None:\n            snapshot = self.default_snapshot()\n        data, pdata = ndarray(snapshot.format, self._byteorder, out, validate)\n        if not API.LucamTakeSnapshot(self._handle, snapshot, pdata):\n            raise LucamError(self)\n        if out is None:\n            return data\n\n    def SaveImage(self, data, filename):\n        \"\"\"Save a single image or video frame to disk.\n\n        Parameters\n        ----------\n        data : numpy array\n            Input data.\n        filename : str\n            Name of file. The file extension indicates the file format:\n            .bmp - Windows bitmap\n            .jpg - Joint Photograhic Experts Group\n            .tif - Tagged Image File Format\n            .raw - Raw\n\n        This function accounts for the endianess of the camera output\n        when using 16 bit data.\n\n        \"\"\"\n        pdata = data.ctypes.data_as(API.pBYTE)\n        height, width = data.shape[-2:]\n        pixelformat = {\n            (2, 1): API.LUCAM_PF_8,\n            (3, 1): API.LUCAM_PF_24,\n            (4, 1): API.LUCAM_PF_32,\n            (2, 2): API.LUCAM_PF_16,\n            (3, 2): API.LUCAM_PF_48}[(data.ndim, data.dtype.itemsize)]\n        if not API.LucamSaveImageWEx(self._handle, width, height,\n                                     pixelformat, pdata, filename):\n            raise LucamError(self)\n\n    def StreamVideoControl(self, ctrltype, window=0):\n        \"\"\"Control streaming video.\n\n        Parameters\n        ----------\n        ctrltype : str or int\n            One of Lucam.VIDEO_CONTROL keys or values.\n            'start_display' starts video streaming and displays it in window.\n            'start_streaming' starts video streaming without display.\n            'stop_streaming' stops video streaming.\n            'pause_stream' pauses video streaming.\n        window : int\n            Handle of window to stream video to. Default is the window\n            created by CreateDisplayWindow().\n\n        \"\"\"\n        ctrltype = Lucam.VIDEO_CONTROL.get(ctrltype, ctrltype)\n        if ctrltype in (API.START_STREAMING,\n                        API.START_DISPLAY,\n                        API.START_RGBSTREAM):\n            self._streaming = self.GetFormat()[0]\n        else:\n            self._streaming = None\n        if not API.LucamStreamVideoControl(self._handle, ctrltype, window):\n            self._streaming = None\n            raise LucamError(self)\n\n    def TakeVideo(self, numframes, out=None, validate=True):\n        \"\"\"Take video frames using video mode.\n\n        Parameters\n        ----------\n        numframes : int\n            Number of video frames to take.\n        out : numpy array, or None\n            Output buffer. If None, a new numpy.array containing the image\n            data is returned. Else image data will be copied into the\n            output array.\n        validate : bool\n            If True (default), size and dtype of the output array are\n            validated.\n\n        Start the video stream with StreamVideoControl() before calling\n        this function.\n\n        \"\"\"\n        data, pdata = ndarray(self._streaming, self._byteorder, out,\n                              validate, numframes)\n        if numframes is None:\n            numframes = data.shape[0]\n        if not API.LucamTakeVideo(self._handle, numframes, pdata):\n            raise LucamError(self)\n        if out is None:\n            return data\n\n    def TakeVideoEx(self, out=None, timeout=100.0, validate=True):\n        \"\"\"Return coordinates of video data greater than a specified threshold.\n\n        This function is not implemented yet.\n\n        \"\"\"\n        raise NotImplementedError()\n\n    def CancelTakeVideo(self):\n        \"\"\"Cancel call to TakeVideo() and TakeVideoEx() made in another thread.\n\n        The cancelled function will raise LucamError(48).\n\n        \"\"\"\n        if not API.LucamCancelTakeVideo(self._handle):\n            raise LucamError(self)\n\n    def StreamVideoControlAVI(self, ctrltype, filename='', window=0):\n        \"\"\"Control capture of the video in a raw 8 bit AVI file.\n\n        Parameters\n        ----------\n        ctrltype : str or int\n            One of Lucam.VIDEO_CONTROL keys or values:\n                'start_display'\n                    Starts capture of the video and displays it in window.\n                'start_streaming'\n                    Captures the video without displaying it, which gives an\n                    AVI file with higher quality and frame rate.\n                'stop_streaming'\n                    Stops video streaming.\n                'pause_stream'\n                   Pauses video streaming.\n        filename : str\n            Name of AVI file.\n        window : int\n            Handle of window to stream video to. Default is the window\n            created by CreateDisplayWindow().\n\n        \"\"\"\n        ctrltype = Lucam.VIDEO_CONTROL.get(ctrltype, ctrltype)\n        if not API.LucamStreamVideoControlAVI(self._handle, ctrltype,\n                                              filename, window):\n            raise LucamError(self)\n\n    def ConvertRawAVIToStdVideo(self, outfile, inputfile, outtype=1):\n        \"\"\"Convert raw 8 bit AVI file to 24 or 32 bit standard RGB AVI.\n\n        Parameters\n        ----------\n        outfile : str\n            Name of output AVI file. Must be different from inputfile.\n        inputfile : str\n            Name of input AVI file obtained with StreamVideoControlAVI().\n        outtype : str or int\n            Output AVI type: 'standard_24' (default) or 'standard_32'.\n\n        \"\"\"\n        outtype = Lucam.AVI_TYPE.get(outtype, outtype)\n        if not API.LucamConvertRawAVIToStdVideo(self._handle, outfile,\n                                                inputfile, outtype):\n            raise LucamError(self)\n\n    def ConvertFrameToRgb24(self, frameformat, source_frame_pointer, conversion_params=None):\n        \"\"\"Return RGB24 image from raw Bayer data.\"\"\"\n        \"\"\"\n        LucamConvertFrameToRgb24 = (\n        BOOL, HANDLE, pUCHAR_RGB, pBYTE, ULONG, ULONG, ULONG,\n        pLUCAM_CONVERSION)\n    LucamConvertFrameToRgb32 = (\n        BOOL, HANDLE, pBYTE, pBYTE, ULONG, ULONG, ULONG, pLUCAM_CONVERSION)\n    LucamConvertFrameToRgb48 = (\n        BOOL, HANDLE, pUSHORT, pUSHORT, ULONG, ULONG, ULONG, pLUCAM_CONVERSION)\n    LucamConvertFrameToGreyscale8 = (\n        BOOL, HANDLE, pBYTE, pBYTE, ULONG, ULONG, ULONG, pLUCAM_CONVERSION)\n    LucamConvertFrameToGreyscale16 = (\n        BOOL, HANDLE, pUSHORT, pUSHORT, ULONG, ULONG, ULONG, pLUCAM_CONVERSION)\"\"\"\n        if conversion_params is None:\n                conversion_params = self.default_conversion()\n                conversion_params.DemosaicMethod = API.LUCAM_DM_FAST #need to think about defaults\n        f = frameformat\n        outputformat = copy.copy(frameformat)\n        outputformat.pixelFormat = API.LUCAM_PF_24 #need to modify the frame format for the output\n        dest, pDest = ndarray(outputformat)\n        w, h = f.width // (f.binningX * f.subSampleX), f.height // (f.binningY * f.subSampleY)\n        if not API.LucamConvertFrameToRgb24(self._handle, dest, source_frame_pointer, \n                                            w, h, frameformat.pixelFormat, conversion_params):\n            raise LucamError(self)\n        return dest\n\n    def ConvertFrameToRgb32(self):\n        \"\"\"Return RGB32 image from raw Bayer data.\"\"\"\n        raise NotImplementedError()\n\n    def ConvertFrameToRgb48(self):\n        \"\"\"Return RGB48 image from raw Bayer data.\"\"\"\n        raise NotImplementedError()\n\n    def ConvertFrameToGreyscale8(self, data, out=None, settings=None):\n        \"\"\"Return 8 bit grayscale image from raw Bayer data.\"\"\"\n        raise NotImplementedError()\n\n    def ConvertFrameToGreyscale16(self, data, out=None, settings=None):\n        \"\"\"Return 16 bit grayscale image from raw Bayer data.\"\"\"\n        raise NotImplementedError()\n\n    def Setup8bitsLUT(self, lut):\n        \"\"\"Populate 8 bit LUT inside camera.\n\n        lut : numpy array, or None\n            If None, camera LUT is disabled.\n            Else lut.shape must be (256,) and lut.dtype must be uint8.\n\n        \"\"\"\n        lut = numpy.array(lut if lut else [], numpy.uint8)\n        if not API.LucamSetup8bitsLUT(self._handle, lut, lut.size):\n            raise LucamError(self)\n\n    def Setup8bitsColorLUT(self, lut, red=False, green1=False,\n                           green2=False, blue=False):\n        \"\"\"Populate 8 bit Color LUT inside camera.\n\n        Parameters\n        ----------\n        lut : numpy array, or None\n            If None, camera LUT is disabled.\n            Else lut.shape must be (256,) and lut.dtype must be uint8.\n        red, green1, green2, blue: bool\n            Apply lut to color channel.\n\n        \"\"\"\n        lut = numpy.array(lut if lut else [], numpy.uint8)\n        if not API.LucamSetup8bitsColorLUT(self._handle, lut, lut.size,\n                                           red, green1, green2, blue):\n            raise LucamError(self)\n\n    def SetupCustomMatrix(self, matrix):\n        \"\"\"Defines color correction matrix for converting raw data to RGB24.\n\n        Parameters\n        ----------\n        matrix : numpy array\n            3x3 color correction matrix.\n\n        The ConvertFrameToRgb24() function requires a color correction matrix\n        parameter. The pre-defined ones may be used, but when a specific\n        matrix is required, the LUCAM_CM_CUSTOM parameter can be passed and\n        the values defined using this function will be used.\n\n        \"\"\"\n        matrix = numpy.array(matrix, numpy.float32, copy=False)\n        if not API.LucamSetupCustomMatrix(self._handle, matrix):\n            raise LucamError(self)\n\n    def GetCurrentMatrix(self):\n        \"\"\"Return current color correction matrix.\"\"\"\n        matrix = numpy.empty((3, 3), numpy.float32)\n        if not API.LucamGetCurrentMatrix(self._handle, matrix):\n            raise LucamError(self)\n        return matrix\n\n    def AddStreamingCallback(self, callback, context=None):\n        \"\"\"Add video filter callback function and return callback Id.\n\n        Parameters\n        ----------\n        callback : function\n            API.VideoFilterCallback.\n            The function is called after each frame of streaming video\n            is returned from the camera.\n        context : object\n            Context data to be passed to callback function.\n\n        \"\"\"\n        # asVoidPtr = ctypes.pythonapi.PyCObject_AsVoidPtr #this function converts PyCObject to void *, why is it not in ctypes natively...?\n        # asVoidPtr.restype = ctypes.c_void_p #we need to set the result and argument types of the imported function\n        # asVoidPtr.argtypes = [ctypes.py_object]        \n        callback = API.VideoFilterCallback(callback)\n        if context is not None:\n            context = ctypes.py_object(context)\n        callbackid = API.LucamAddStreamingCallback(self._handle,\n                                                   callback, context)\n        if callbackid == -1:\n            raise LucamError(self)\n        self._callbacks[(API.VideoFilterCallback, callbackid)] = callback\n        return callbackid\n        # callback = API.VideoFilterCallback(callback)\n        # if context is not None:\n        #     context = ctypes.py_object(context)\n        # callbackid = API.LucamAddStreamingCallback(self._handle,\n        #                                            callback, context)\n        # if callbackid == -1:\n        #     raise LucamError(self)\n        # self._callbacks[(API.VideoFilterCallback, callbackid)] = callback\n        # return callbackid\n\n    def RemoveStreamingCallback(self, callbackid):\n        \"\"\"Remove previously registered video filter callback function.\n\n        Parameters\n        ----------\n        callbackid : int\n            Data filter callback function registered with\n            AddStreamingCallback().\n\n        \"\"\"\n        if not API.LucamRemoveStreamingCallback(self._handle, callbackid):\n            raise LucamError(self)\n        del self._callbacks[(API.VideoFilterCallback, callbackid)]\n\n    def AddSnapshotCallback(self, callback, context=None):\n        \"\"\"Add data filter callback function and return callback Id.\n\n        Parameters\n        ----------\n        callback : function\n            API.SnapshotCallback\n            The function is called after each hardware triggered snapshot\n            is returned from the camera but before it is processed.\n        context : object\n            Context data to be passed to callback function.\n\n        \"\"\"\n        callback = API.SnapshotCallback(callback)\n        if context is not None:\n            context = ctypes.py_object(context)\n        callbackid = API.LucamAddSnapshotCallback(self._handle,\n                                                  callback, context)\n        if callbackid == -1:\n            raise LucamError(self)\n        self._callbacks[(API.SnapshotCallback, callbackid)] = callback\n        return callbackid\n\n    def RemoveSnapshotCallback(self, callbackid):\n        \"\"\"Remove previously registered data filter callback function.\n\n        Parameters\n        ----------\n        callbackid : int\n            Data filter callback function registered with\n            AddSnapshotCallback().\n\n        \"\"\"\n        if not API.LucamRemoveSnapshotCallback(self._handle, callbackid):\n            raise LucamError(self)\n        del self._callbacks[(API.SnapshotCallback, callbackid)]\n\n    def AddRgbPreviewCallback(self, callback, pixelformat, context=None):\n        \"\"\"Add video filter callback function and return callback Id.\n\n        Parameters\n        ----------\n        callback : function\n            API.RgbVideoFilterCallback.\n            This function is called after each frame of streaming video is\n            returned from the camera and after it is processed.\n        pixelformat : str or int\n            The pixel format of the data should match the format of the video.\n            Use QueryRgbPreviewPixelFormat().\n            API.LUCAM_PF_24 or API.LUCAM_PF_32.\n        context : object\n            Context data to be passed to callback function.\n\n        \"\"\"\n        callback = API.RgbVideoFilterCallback(callback)\n        pixelformat = Lucam.PIXEL_FORMAT.get(pixelformat, pixelformat)\n        if context is not None:\n            context = ctypes.py_object(context)\n        callbackid = API.LucamAddRgbPreviewCallback(self._handle, callback,\n                                                    context, pixelformat)\n        if callbackid == -1:\n            raise LucamError(self)\n        self._callbacks[(API.RgbVideoFilterCallback, callbackid)] = callback\n        return callbackid\n\n    def RemoveRgbPreviewCallback(self, callbackid):\n        \"\"\"Remove previously registered video filter callback function.\n\n        Parameters\n        ----------\n        callbackid : int\n            Video filter callback function registered with\n            AddRgbPreviewCallback().\n\n        \"\"\"\n        if not API.LucamRemoveRgbPreviewCallback(self._handle, callbackid):\n            raise LucamError(self)\n        del self._callbacks[(API.RgbVideoFilterCallback, callbackid)]\n\n    def QueryRgbPreviewPixelFormat(self):\n        \"\"\"Return pixel format for preview window.\"\"\"\n        pixelformat = API.ULONG()\n        if not API.LucamQueryRgbPreviewPixelFormat(self._handle, pixelformat):\n            raise LucamError(self)\n        return pixelformat.value\n\n    def OneShotAutoExposure(self, target, startx, starty, width, height):\n        \"\"\"Perform one iteration of exposure adjustment to reach target.\n\n        Parameters\n        ----------\n        target : int\n            Target average brightness (0-255).\n        startx, starty, width, height : int\n            Window coordinates after any subsampling or binning.\n\n        \"\"\"\n        if not API.LucamOneShotAutoExposure(self._handle, target,\n                                            startx, starty, width, height):\n            raise LucamError(self)\n\n    def OneShotAutoWhiteBalance(self, startx, starty, width, height):\n        \"\"\"Perform one iteration of analog gain adjustment.\n\n        Parameters\n        ----------\n        startx, starty, width, height : int\n            Window coordinates after any subsampling or binning.\n\n        Perform a single on-chip analog gain adjustment on the video stream\n        in order to color balance the image.\n\n        \"\"\"\n        if not API.LucamOneShotAutoWhiteBalance(self._handle,\n                                                startx, starty, width, height):\n            raise LucamError(self)\n\n    def OneShotAutoWhiteBalanceEx(self, redovergreen, blueovergreen,\n                                  startx, starty, width, height):\n        \"\"\"Perform one iteration of exposure adjustment to reach target color.\n\n        Parameters\n        ----------\n        redovergreen, blueovergreen : float\n            Red pixel value of the desired color divided by green value.\n            Blue pixel value of the desired color divided by green value.\n        startx, starty, width, height : int\n            Window coordinates after any subsampling or binning.\n\n        Perform a single on-chip analog gain adjustment on the video stream\n        in order to color balance the image to a specific target color.\n\n        \"\"\"\n        if not API.LucamOneShotAutoWhiteBalanceEx(\n                self._handle, redovergreen, blueovergreen,\n                startx, starty, width, height):\n            raise LucamError(self)\n\n    def DigitalWhiteBalance(self, startx, starty, width, height):\n        \"\"\"Perform one iteration of digital color gain adjustment.\n\n        Parameters\n        ----------\n        startx, starty, width, height : int\n            Window coordinates after any subsampling or binning.\n\n        Perform a single digital gain adjustment on the video stream\n        in order to color balance the image.\n\n        \"\"\"\n        if not API.LucamDigitalWhiteBalance(self._handle,\n                                            startx, starty, width, height):\n            raise LucamError(self)\n\n    def LucamDigitalWhiteBalanceEx(self, redovergreen, blueovergreen,\n                                   startx, starty, width, height):\n        \"\"\"Perform one iteration of digital color gain adjustment.\n\n        Parameters\n        ----------\n        redovergreen, blueovergreen : float\n            Red pixel value of the desired color divided by green value.\n            Blue pixel value of the desired color divided by green value.\n        startx, starty, width, height : int\n            Window coordinates after any subsampling or binning.\n\n        Perform a single digital gain adjustment on the video stream\n        in order to color balance the image to a specific target color.\n\n        \"\"\"\n        if not API.LucamDigitalWhiteBalanceEx(\n                self._handle, redovergreen, blueovergreen,\n                startx, starty, width, height):\n            raise LucamError(self)\n\n    def AdjustWhiteBalanceFromSnapshot(self, snapshot, data, redovergreen,\n                                       blueovergreen, startx, starty,\n                                       width, height):\n        \"\"\"Adjust digital color gain values of previously taken snapshot.\n\n        Parameters\n        ----------\n        snapshot : API.LUCAM_SNAPSHOT\n            Color gain values of this structure will be changed inplace.\n        data : numpy.array\n            Image data acquired with given snapshot settings using\n            TakeSnapshot() or TakeFastFrames().\n        redovergreen, blueovergreen : float\n            Red pixel value of the desired color divided by green value.\n            Blue pixel value of the desired color divided by green value.\n        startx, starty, width, height : int\n            Window coordinates after any subsampling or binning.\n\n        If the camera is in Fast Frames mode, this function will also update\n        the current color gains used for all subsequent snapshots.\n\n        \"\"\"\n        pdata = data.ctypes.data_as(API.pBYTE)\n        if not API.LucamAdjustWhiteBalanceFromSnapshot(\n                self._handle, snapshot, pdata, redovergreen, blueovergreen,\n                startx, starty, width, height):\n            raise LucamError(self)\n\n    def OneShotAutoIris(self, target, startx, starty, width, height):\n        \"\"\"Perform one iteration of iris adjustment to reach target brightness.\n\n        Parameters\n        ----------\n        target : int\n            Target average brightness (0-255).\n        startx, starty, width, height : int\n            Window coordinates after any subsampling or binning.\n\n        \"\"\"\n        if not API.LucamOneShotAutoIris(self._handle, target,\n                                        startx, starty, width, height):\n            raise LucamError(self)\n\n    def ContinuousAutoExposureEnable(self, target, startx, starty,\n                                     width, height, lightingperiod):\n        \"\"\"Undocumented function.\"\"\"\n        if not API.LucamContinuousAutoExposureEnable(\n                self._handle, target, startx, starty,\n                width, height, lightingperiod):\n            raise LucamError(self)\n\n    def ContinuousAutoExposureDisable(self):\n        \"\"\"Undocumented function.\"\"\"\n        if not API.LucamContinuousAutoExposureDisable(self._handle):\n            raise LucamError(self)\n\n    def LucamAutoFocusStart(self, startx, starty, width, height,\n                            callback=None, context=None):\n        \"\"\"Start auto focus calibration.\n\n        Parameters\n        ----------\n        startx, starty, width, height : int\n            Window coordinates after any subsampling or binning.\n        callback : function or None\n            API.ProgressCallback.\n            If provided, this function will be called periodically with\n            the current progress of the auto focus.\n        context : object\n            Will be passed to callback function.\n\n        \"\"\"\n        callback = API.ProgressCallback(callback if callback else 0)\n        if context is not None:\n            context = ctypes.py_object(context)\n        if not API.LucamAutoFocusStart(self._handle, startx, starty,\n                                       width, height, 0., 0., 0.,\n                                       callback, context):\n            raise LucamError(self)\n        self._callbacks[API.ProgressCallback] = callback\n\n    def LucamAutoFocusWait(self, timeout):\n        \"\"\"Wait for completion of auto focus calibration.\n\n        Parameters\n        ----------\n        timeout : int\n            Duration the auto focus calibration will run before terminating\n            if the proper focus value is not found.\n\n        \"\"\"\n        if not API.LucamAutoFocusWait(self._handle, timeout):\n            raise LucamError(self)\n\n    def LucamAutoFocusStop(self):\n        \"\"\"Stop auto focus calibration prematurely.\"\"\"\n        if not API.LucamAutoFocusStop(self._handle):\n            raise LucamError(self)\n\n    def AutoFocusQueryProgress(self):\n        \"\"\"Return the status in % of the auto focus calibration.\n\n        Only available with cameras that can control a motorized lens.\n\n        \"\"\"\n        percentcomplete = API.FLOAT()\n        if not API.LucamAutoFocusQueryProgress(self._handle, percentcomplete):\n            raise LucamError(self)\n        return percentcomplete.value\n\n    def InitAutoLens(self, force=False):\n        \"\"\"Initialize and calibrate camera lens focus and iris positions.\n\n        Parameters\n        ----------\n        force : bool\n            If True, force a recalibration of lens parameters.\n\n        \"\"\"\n        if not API.LucamInitAutoLens(self._handle):\n            raise LucamError(self)\n\n    def PermanentBufferRead(self, offset=0, size=2048):\n        \"\"\"Return data read from user-defined non-volatile memory.\n\n        The non-volatile memory area is 2048 bytes long.\n\n        \"\"\"\n        assert 0 <= (size - offset) <= 2048\n        data = numpy.zeros((size,), numpy.uint8)\n        pdata = data.ctypes.data_as(API.pUCHAR)\n        if not API.LucamPermanentBufferRead(self._handle, pdata, offset, size):\n            raise LucamError(self)\n        return data\n\n    def PermanentBufferWrite(self, data, offset=0):\n        \"\"\"Write data to user-defined non-volatile memory area.\n\n        The non-volatile memory area is 2048 bytes long and limited to\n        100,000 writes.\n\n        \"\"\"\n        data = numpy.array(data, numpy.uint8, copy=False)\n        pdata = data.ctypes.data_as(API.pUCHAR)\n        size = data.size\n        assert 0 <= (size - offset) <= 2048\n        if not API.LucamPermanentBufferWrite(self._handle, pdata,\n                                             offset, size):\n            raise LucamError(self)\n\n    def GpioRead(self):\n        \"\"\"Return external header status from General Purpose IO register.\n\n        Return value of the output and input bits of the register.\n\n        \"\"\"\n        gpo = API.BYTE()\n        gpi = API.BYTE()\n        if not API.LucamGpioRead(self._handle, gpo, gpi):\n            raise LucamError(self)\n        return gpo.value, gpi.value\n\n    def GpioWrite(self, gpovalues):\n        \"\"\"Write General Purpose IO register to trigger external header output.\n\n        Parameters\n        ----------\n        gpovalues : int\n            Value of the output bits of the register.\n\n        \"\"\"\n        if not API.LucamGpioWrite(self._handle, gpovalues):\n            raise LucamError(self)\n\n    def GpoSelect(self, gpoenable):\n        \"\"\"Enable or disable alternate GPO functionality.\n\n        gpoenable : int\n            Bit flags used to enable/disable alternate functionality.\n\n        \"\"\"\n        if not API.LucamGpoSelect(self._handle, gpoenable):\n            raise LucamError(self)\n\n    def GpioConfigure(self, enableoutput):\n        \"\"\"Configure direction of bi-directional GPIO pin.\n\n        Parameters\n        ----------\n        enableoutput : int\n            Bit flags used to disable or enable the output on a GPIO.\n            Bit values of 1 configure pin as output.\n            Bit values of 0 put the pin into input mode (default).\n\n        This function is only available on Lm-based cameras.\n\n        \"\"\"\n        if not API.LucamGpioConfigure(self._handle, enableoutput):\n            raise LucamError(self)\n\n    def Rs232Transmit(self):\n        \"\"\"Undocumented function.\"\"\"\n        raise NotImplementedError()\n\n    def Rs232Receive(self):\n        \"\"\"Undocumented function.\"\"\"\n        raise NotImplementedError()\n\n    def AddRs232Callback(self):\n        \"\"\"Undocumented function.\"\"\"\n        raise NotImplementedError()\n\n    def RemoveRs232Callback(self):\n        \"\"\"Undocumented function.\"\"\"\n        raise NotImplementedError()",
  "class LucamError(Exception):\n    \"\"\"Exception to report Lucam problems.\"\"\"\n\n    def __init__(self, arg=None):\n        \"\"\"Initialize LucamError instance.\n\n        Parameters\n        ----------\n        arg : int, Lucam instance, or None\n            If arg is None or a Lucam instance, the last error that occured\n            in the API is raised. Else arg is an error code number.\n\n        \"\"\"\n        if arg is None:\n            self.value = API.LucamGetLastError()\n        elif isinstance(arg, Lucam):\n            self.value = arg.GetLastErrorForCamera()\n        else:\n            self.value = int(arg)\n\n    def __str__(self):\n        \"\"\"Return error message.\"\"\"\n        return self.CODES.get(self.value, \"Unknown error: %i\" % self.value)\n\n    CODES = {\n        0: \"\"\"NoError\n            Initialization value in the API.\"\"\",\n        1: \"\"\"NoSuchIndex\n            The index passed to LucamCameraOpen was 0. It must be >= 1.\"\"\",\n        2: \"\"\"SnapshotNotSupported\n            The camera does not support snapshots or fast frames.\"\"\",\n        3: \"\"\"InvalidPixelFormat\n            The pixel format parameter passed to the function is invalid.\"\"\",\n        4: \"\"\"SubsamplingZero\n            A subsampling of zero was passed to a function.\"\"\",\n        5: \"\"\"Busy\n            The function is unavailable because the camera is busy with\n            streaming or capturing fast frames.\"\"\",\n        6: \"\"\"FailedToSetSubsampling\n            The API failed to set the requested subsampling. This can be due\n            to the camera being disconnected. It can also be due to a filter\n            not being there.\"\"\",\n        7: \"\"\"FailedToSetStartPosition\n            The API failed to set the requested subsampling. This can be due\n            to the camera being disconnected.\"\"\",\n        8: \"\"\"PixelFormatNotSupported\n            The camera does not support the pixel format passed to the\n            function.\"\"\",\n        9: \"\"\"InvalidFrameFormat\n            The format passed to the function does not pass the camera\n            requirements. Verify that (xOffset + width) is not greater than\n            the camera's maximum width. Verify that (width / subSamplingX)\n            is a multiple of some 'nice' value. Do the same for the y.\"\"\",\n        10: \"\"\"PreparationFailed\n            The API failed to prepare the camera for streaming or snapshot.\n            This can due to the camera being disconnected. If START_STREAMING\n            succeeds and START_DISPLAY fails with this error, this can be due\n            to a filter not being there or registered.\"\"\",\n        11: \"\"\"CannotRun\n            The API failed to get the camera running. This can be due to\n            a bandwidth problem.\"\"\",\n        12: \"\"\"NoTriggerControl\n            Contact Lumenera.\"\"\",\n        13: \"\"\"NoPin\n            Contact Lumenera.\"\"\",\n        14: \"\"\"NotRunning\n            The function failed because it requires the camera to be running,\n            and it is not.\"\"\",\n        15: \"\"\"TriggerFailed\n            Contact Lumenera.\"\"\",\n        16: \"\"\"CannotSetupFrameFormat\n            The camera does not support that its frame format get setup.\n            This will happen if your camera is plugged to a USB 1 port and\n            it does not support it. LucamCameraOpen will still succeeds,\n            but if a call to LucamGetLastError will return this value.\"\"\",\n        17: \"\"\"DirectShowInitError\n            Direct Show initialization error. This may happen if you run the\n            API before having installed a DS compatible camera ever before.\n            The Lumenera camera is DS compatible.\"\"\",\n        18: \"\"\"CameraNotFound\n            The function LucamCameraOpen did not find the camera # index.\"\"\",\n        19: \"\"\"Timeout\n            The function timed out.\"\"\",\n        20: \"\"\"PropertyUnknown\n            The API does not know the property passed to LucamGetProperty,\n            LucamSetProperty or LucamGetPropertyRange. You may be using an\n            old DLL.\"\"\",\n        21: \"\"\"PropertyUnsupported\n            The camera does not support that property.\"\"\",\n        22: \"\"\"PropertyAccessFailed\n            The API failed to access the property. Most likely, the reason\n            is that the camera does not support that property.\"\"\",\n        23: \"\"\"LucustomNotFound\n            The lucustom.ax filter was not found.\"\"\",\n        24: \"\"\"PreviewNotRunning\n            The function failed because preview is not running.\"\"\",\n        25: \"\"\"LutfNotLoaded\n            The function failed because lutf.ax is not loaded.\"\"\",\n        26: \"\"\"DirectShowError\n            An error related to the operation of DirectShow occured.\"\"\",\n        27: \"\"\"NoMoreCallbacks\n            The function LucamAddStreamingCallback failed because the API\n            cannot support any more callbacks.\"\"\",\n        28: \"\"\"UndeterminedFrameFormat\n            The API does not know what is the frame format of the camera.\"\"\",\n        29: \"\"\"InvalidParameter\n            An parameter has an obviously wrong value.\"\"\",\n        30: \"\"\"NotEnoughResources\n            Resource allocation failed.\"\"\",\n        31: \"\"\"NoSuchConversion\n            One of the members of the LUCAM_CONVERSION structure passed is\n            either unknown or inappropriate.\"\"\",\n        32: \"\"\"ParameterNotWithinBoundaries\n            A parameter representing a quantity is outside the allowed\n            boundaries.\"\"\",\n        33: \"\"\"BadFileIo\n            An error occured creating a file or writing to it. Verify that\n            the path exists.\"\"\",\n        34: \"\"\"GdiplusNotFound\n            gdiplus.dll is needed and was not found.\"\"\",\n        35: \"\"\"GdiplusError\n            gdiplus.dll reported an error. This may happen if there is a file\n            IO error.\"\"\",\n        36: \"\"\"UnknownFormatType\n            Contact Lumenera.\"\"\",\n        37: \"\"\"FailedCreateDisplay\n            The API failed to create the display window. The reason could be\n            unsufficient resources.\"\"\",\n        38: \"\"\"DpLibNotFound\n            deltapolation.dll is needed and was not found.\"\"\",\n        39: \"\"\"DpCmdNotSupported\n            The deltapolation command is not supported by the delta\n            polation library.\"\"\",\n        40: \"\"\"DpCmdUnknown\n            The deltapolation command is unknown or invalid.\"\"\",\n        41: \"\"\"NotWhilePaused\n            The function cannot be performed when the camera is in\n            paused state.\"\"\",\n        42: \"\"\"CaptureFailed\n            Contact Lumenera.\"\"\",\n        43: \"\"\"DpError\n            Contact Lumenera.\"\"\",\n        44: \"\"\"NoSuchFrameRate\n            Contact Lumenera.\"\"\",\n        45: \"\"\"InvalidTarget\n            One of the target parameters is wrong. This error code is used\n            when startX + width > (frameFormat.width / frameFormat.subSampleX)\n            or startY + height > (frameFormat.height / frameFormat.subSampleY)\n            if any of those parameter is odd (not a multiple of 2) or\n            or if width or height is 0.\"\"\",\n        46: \"\"\"FrameTooDark\n            The frame is too dark to perform white balance.\"\"\",\n        47: \"\"\"KsPropertySetNotFound\n            A DirectShow interface necessary to carry out the operation\n            was not found.\"\"\",\n        48: \"\"\"Cancelled\n            The user cancelled the operation.\"\"\",\n        49: \"\"\"KsControlNotSupported\n            The DirectShow IKsControl interface is not supported (did you\n            unplug the camera?).\"\"\",\n        50: \"\"\"EventNotSupported\n            Some module attempted to register an unsupported event.\"\"\",\n        51: \"\"\"NoPreview\n            The function failed because preview was not setup.\"\"\",\n        52: \"\"\"SetPositionFailed\n            A function setting window position failed (invalid parameters).\"\"\",\n        53: \"\"\"NoFrameRateList\n            The frame rate list is not available.\"\"\",\n        54: \"\"\"FrameRateInconsistent\n            There was an error building the frame rate list.\"\"\",\n        55: \"\"\"CameraNotConfiguredForCmd\n            The camera does not support that particular command.\"\"\",\n        56: \"\"\"GraphNotReady\n            The graph is not ready.\"\"\",\n        57: \"\"\"CallbackSetupError\n            Contact Lumenera.\"\"\",\n        58: \"\"\"InvalidTriggerMode\n            You cannot cause a soft trigger when hw trigger is enabled.\"\"\",\n        59: \"\"\"NotFound\n            The API was asked to return soomething that is not there.\"\"\",\n        60: \"\"\"EepromTooSmall\n            The onboard EEPROM is too small.\"\"\",\n        61: \"\"\"EepromWriteFailed\n            The API failed to write to the onboard eeprom.\"\"\",\n        62: \"\"\"UnknownFileType\n            The API failed because it failed to recognize the file type of\n            a file name passed to it.\"\"\",\n        63: \"\"\"EventIdNotSupported\n            LucamRegisterEventNotification failed because the event\n            is not supported.\"\"\",\n        64: \"\"\"EepromCorrupted\n            The API found that the EEPROM was corrupted.\"\"\",\n        65: \"\"\"SectionTooBig\n            The VPD section to write to the eeprom is too big.\"\"\",\n        66: \"\"\"FrameTooBright\n            The frame is too bright to perform white balance.\"\"\",\n        67: \"\"\"NoCorrectionMatrix\n            The camera is configured to have no correction matrix\n            (PROPERTY_CORRECTION_MATRIX is LUCAM_CM_NONE).\"\"\",\n        68: \"\"\"UnknownCameraModel\n            The API failed because it needs to know the camera model and it\n            is not available.\"\"\",\n        69: \"\"\"ApiTooOld\n            The API failed because it needs to be upgraded to access a\n            feature of the camera.\"\"\",\n        70: \"\"\"SaturationZero\n            The API failed because the saturation is currently 0.\"\"\",\n        71: \"\"\"AlreadyInitialised\n            The API failed because the object was already initialised.\"\"\",\n        72: \"\"\"SameInputAndOutputFile\n            The API failed because the object was already initialised.\"\"\",\n        73: \"\"\"FileConversionFailed\n            The API failed because the file conversion was not completed.\"\"\",\n        74: \"\"\"FileAlreadyConverted\n            The API failed because the file is already converted in the\n            desired format.\"\"\",\n        75: \"\"\"PropertyPageNotSupported\n            The API failed to display the property page.\"\"\",\n        76: \"\"\"PropertyPageCreationFailed\n            The API failed to create the property page.\"\"\",\n        77: \"\"\"DirectShowFilterNotInstalled\n            The API did not find the required direct show filter.\"\"\",\n        78: \"\"\"IndividualLutNotAvailable\n            The camera does not support that different LUTs are applied\n            to each color.\"\"\",\n        79: \"\"\"UnexpectedError\n            Contact Lumenera.\"\"\",\n        80: \"\"\"StreamingStopped\n            LucamTakeFastFrame or LucamTakeVideo failed because another thread\n            interrupted the streaming by a call to LucamDisableFastFrames or\n            LucamStreamVideoControl.\"\"\",\n        81: \"\"\"MustBeInSwTriggerMode\n            LucamForceTakeFastFrame was called while the camera is in hardware\n            trigger still mode and the camera does not support taking a sw\n            trigger snapshot while in that state.\"\"\",\n        82: \"\"\"TargetFlaky\n            The target is too flaky to perform auto focus.\"\"\",\n        83: \"\"\"AutoLensUninitialized\n            The auto lens needs to be initialized before the function\n            is used.\"\"\",\n        84: \"\"\"LensNotInstalled\n            The function failed because the lens were not installed correctly.\n            Verify that changing the focus has any effect.\"\"\",\n        85: \"\"\"UnknownError\n            The function failed because of an unknoen error.\n            Contact Lumenera.\"\"\",\n        86: \"\"\"FocusNoFeedbackError\n            There is no feedback available for focus.\"\"\",\n        87: \"\"\"LutfTooOld\n            LuTF.ax is too old for this feature.\"\"\",\n        88: \"\"\"UnknownAviFormat\n            Unknown or invalid AVI format for input file.\"\"\",\n        89: \"\"\"UnknownAviType\n            Unknown AVI type. Verify the AVI type parameter.\"\"\",\n        90: \"\"\"InvalidAviConversion\n            The AVI conversion is invalid.\"\"\",\n        91: \"\"\"SeekFailed\n            The seeking operation failed.\"\"\",\n        92: \"\"\"AviRunning\n            The function cannot be performed while an AVI is being\n            captured.\"\"\",\n        93: \"\"\"CameraAlreadyOpened\n            An attempt was made to open a camera for streaming-related\n            reasons while it is already opened for such.\"\"\",\n        94: \"\"\"NoSubsampledHighRes\n            The API cannot take a high resolution image in subsampled mode\n            or binning mode.\"\"\",\n        95: \"\"\"OnlyOnMonochrome\n            The API function is only available on monochrome cameras.\"\"\",\n        96: \"\"\"No8bppTo48bpp\n            Building a 48 bpp image from an 8 bpp image is invalid.\"\"\",\n        97: \"\"\"Lut8Obsolete\n            Use 12 bits LUT instead.\"\"\",\n        98: \"\"\"FunctionNotSupported\n            That functionnality is not supported.\"\"\",\n        99: \"\"\"RetryLimitReached\n            Property access failed due to a retry limit.\"\"\"}",
  "class LucamSynchronousSnapshots(object):\n    \"\"\"Simultaneous image capture from multiple cameras.\"\"\"\n\n    def __init__(self, cameras=None, settings=None):\n        \"\"\"Enable simultaneous snapshot capture mode.\n\n        Parameters\n        ----------\n        cameras : sequence of Lucam instances, or None.\n            If None (default), snapshots are taken from all connected cameras.\n        settings : sequence of API.LUCAM_SNAPSHOT, or None\n            Settings to use for the snapshot. If None (default), the settings\n            returned by Lucam.default_snapshot() will be used for each camera.\n\n        \"\"\"\n        if cameras is None:\n            cameras = [Lucam(i + 1) for i in range(len(LucamEnumCameras()))]\n        numcams = len(cameras)\n        phcameras = (API.HANDLE * numcams)()\n        ppsettings = (API.pLUCAM_SNAPSHOT * numcams)()\n        if settings is None:\n            settings = [cam.default_snapshot() for cam in cameras]\n        for i in range(numcams):\n            phcameras[i] = cameras[i]._handle\n            ppsettings[i] = ctypes.pointer(settings[i])\n        self._cameras = cameras\n        self._settings = settings\n        self._handle = API.LucamEnableSynchronousSnapshots(numcams, phcameras,\n                                                           ppsettings)\n        if not self._handle:\n            raise LucamError()\n\n    def __del__(self):\n        \"\"\"Disable simultaneous snapshot capture mode.\"\"\"\n        if self._handle:\n            API.LucamDisableSynchronousSnapshots(self._handle)\n\n    def Disable(self):\n        \"\"\"Disable simultaneous snapshot capture mode.\"\"\"\n        if not API.LucamDisableSynchronousSnapshots(self._handle):\n            raise LucamError()\n        self._handle = None\n\n    def Take(self, out=None, validate=True):\n        \"\"\"Simultaneously take single image from several cameras.\n\n        Parameters\n        ----------\n        out : sequence of numpy arrays, or None\n            Output buffer. If None, a list of new numpy.arrays containing\n            the image data is returned. Else image data will be copied into\n            the output arrays.\n\n        \"\"\"\n        result = []\n        ppdata = (API.pBYTE * len(self._cameras))()\n        for i in range(len(self._cameras)):\n            data, pdata = ndarray(self._settings[i].format,\n                                  self._cameras[i]._byteorder,\n                                  out[i] if out else None, validate)\n            result.append(data)\n            ppdata[i] = pdata\n        if not API.LucamTakeSynchronousSnapshots(self._handle, ppdata):\n            raise LucamError()\n        if out is None:\n            return result",
  "class LucamPreviewAVI(object):\n    \"\"\"Preview AVI file.\"\"\"\n\n    CTRLTYPE = {\n        'stop': API.STOP_AVI,\n        'start': API.START_AVI,\n        'pause': API.PAUSE_AVI}\n\n    def __init__(self, filename):\n        \"\"\"Open AVI file for previewing.\"\"\"\n        self._handle = API.LucamPreviewAVIOpen(filename)\n        if not self._handle:\n            raise LucamError()\n        self._filename = filename\n\n    def __del__(self):\n        \"\"\"Close controller to AVI file if still open.\"\"\"\n        if self._handle:\n            API.LucamPreviewAVIClose(self._handle)\n\n    def __str__(self):\n        \"\"\"Return information about AVI as string.\"\"\"\n        info = self.GetFormat()\n        fileformat = ('RAW_LUMENERA', 'STANDARD_24', 'STANDARD_32',\n                      'XVID_24', 'STANDARD_8')[info[2]]\n        return \"\\n* \".join((\n            \"\",\n            \"File name: %s\" % self._filename,\n            \"Type: %s\" % fileformat,\n            \"Width: %s\" % info[0],\n            \"Height: %s\" % info[1],\n            \"Bit depth: %s\" % info[3],\n            \"Frame rate: %s\" % self.GetFrameRate(),\n            \"Frame count: %s\" % self.GetFrameCount(),\n            \"Duration: %s:%s:%s:%s\" % self.GetDuration(),\n            \"Current frame: %s\" % self.GetPositionFrame(),\n            \"Current time: %s:%s:%s:%s\" % self.GetPositionTime()))\n\n    def Close(self):\n        \"\"\"Close controller to AVI file.\"\"\"\n        if not API.LucamPreviewAVIClose(self._handle):\n            raise LucamError()\n        self._handle = None\n\n    def Control(self, ctrltype, window=0):\n        \"\"\"Control previewing of AVI video.\n\n        Parameters\n        ----------\n        ctrltype : str or int\n            Control type. One of LucamPreviewAVI.CTRLTYPE keys or values.\n        window : int\n            Handle to the window to preview video to.\n\n        \"\"\"\n        ctrltype = LucamPreviewAVI.CTRLTYPE.get(ctrltype, ctrltype)\n        if not API.LucamPreviewAVIControl(self._handle, ctrltype, window):\n            raise LucamError()\n\n    def GetDuration(self):\n        \"\"\"Return length of video.\"\"\"\n        minutes = API.LONGLONG()\n        seconds = API.LONGLONG()\n        millisecs = API.LONGLONG()\n        microsecs = API.LONGLONG()\n        if not API.LucamPreviewAVIGetDuration(self._handle, minutes, seconds,\n                                              millisecs, microsecs):\n            raise LucamError()\n        return minutes.value, seconds.value, millisecs.value, microsecs.value\n\n    def GetFrameCount(self):\n        \"\"\"Return total number of frames within AVI file.\"\"\"\n        framecount = API.LONGLONG()\n        if not API.LucamPreviewAVIGetFrameCount(self._handle, framecount):\n            raise LucamError()\n        return framecount.value\n\n    def GetFrameRate(self):\n        \"\"\"Return recorded frame rate of AVI file.\"\"\"\n        framerate = API.FLOAT()\n        if not API.LucamPreviewAVIGetFrameRate(self._handle, framerate):\n            raise LucamError()\n        return framerate.value\n\n    def GetPositionTime(self):\n        \"\"\"Return current time based position within AVI file.\"\"\"\n        minutes = API.LONGLONG()\n        seconds = API.LONGLONG()\n        millisecs = API.LONGLONG()\n        microsecs = API.LONGLONG()\n        if not API.LucamPreviewAVIGetPositionTime(\n                self._handle, minutes, seconds, millisecs, microsecs):\n            raise LucamError()\n        return minutes.value, seconds.value, millisecs.value, microsecs.value\n\n    def GetPositionFrame(self):\n        \"\"\"Return current frame based position within AVI file.\"\"\"\n        curframe = API.LONGLONG()\n        if not API.LucamPreviewAVIGetPositionFrame(self._handle, curframe):\n            raise LucamError()\n        return curframe.value\n\n    def SetPositionTime(self, minutes, seconds, millisecs, microsecs):\n        \"\"\"Set current time based position within AVI file.\"\"\"\n        if not API.LucamPreviewAVISetPositionTime(\n                self._handle, minutes, seconds, millisecs, microsecs):\n            raise LucamError()\n\n    def SetPositionFrame(self, framenumber):\n        \"\"\"Set current frame based position within AVI file.\"\"\"\n        if not API.LucamPreviewAVISetPositionFrame(self._handle, framenumber):\n            raise LucamError()\n\n    def GetFormat(self):\n        \"\"\"Return AVI file information.\"\"\"\n        width = API.LONG()\n        height = API.LONG()\n        filetype = API.LONG()\n        bitdepth = API.LONG()\n        if not API.LucamPreviewAVIGetFormat(self._handle, width, height,\n                                            filetype, bitdepth):\n            raise LucamError()\n        return width.value, height.value, filetype.value, bitdepth.value",
  "def LucamGetLastError():\n    \"\"\"Return code of last error that occurred in a API function.\n\n    Error codes and descriptions can be found in LucamError.CODES.\n\n    \"\"\"\n    return API.LucamGetLastError()",
  "def LucamNumCameras():\n    \"\"\"Return number of cameras attached to system.\"\"\"\n    num = API.LucamNumCameras()\n    if num == -1:\n        raise LucamError()\n    return num",
  "def LucamEnumCameras():\n    \"\"\"Return version information for all cameras attached to computer.\n\n    Return type is a sequence of API.LUCAM_VERSION strutures.\n\n    \"\"\"\n    num = LucamNumCameras()\n    version_array = (API.LUCAM_VERSION * num)()\n    num = API.LucamEnumCameras(version_array, num)\n    if num == -1:\n        raise LucamError()\n    return version_array[:num]",
  "def LucamConvertBmp24ToRgb24(data):\n    \"\"\"Convert Windows bitmap BGR24 data to RGB24.\n\n    Parameters\n    ----------\n    data : numpy array\n        Input data.\n\n    Convert a frame of data from the format returned by\n    Lucam.ConvertFrametoRGB24() (BGR) to standard format (RGB).\n\n    \"\"\"\n    assert data.shape[2] == 3\n    if not API.LucamConvertBmp24ToRgb24(data, data.shape[1], data.shape[0]):\n        raise LucamError()",
  "def ndarray(frameformat, byteorder='=', out=None, validate=True, numframes=1):\n    \"\"\"Return numpy.ndarray and ctypes pointer.\n\n    Parameters\n    ----------\n    frameformat : API.LUCAM_FRAME_FORMAT\n        Frame format.\n    byteorder : char\n        Byte order of 16 bit camera data:\n        '<' - little endian\n        '>' - big endian\n        '=' - native order\n    out : numpy array, or None\n        If None, a new array will be returned. Else the output array\n        size and dtype will be verified.\n    validate : bool\n        If True (default), size and dtype of the output array are\n        validated.\n    numframes : int\n        Number of frames the array must buffer.\n\n    \"\"\"\n    if out is not None and not validate:\n        return out, out.ctypes.data_as(API.pBYTE)\n\n    if (frameformat.width % frameformat.binningX\n            or frameformat.height % frameformat.binningY):\n        raise ValueError('Invalid frame format')\n\n    width = frameformat.width // frameformat.binningX\n    height = frameformat.height // frameformat.binningY\n    pformat = frameformat.pixelFormat\n\n    if pformat in (0, 2, 6):\n        dtype = numpy.dtype('uint8')\n    elif pformat in (1, 3, 7):\n        dtype = numpy.dtype(byteorder + 'u2')\n    else:\n        raise ValueError(\"Pixel format not supported\")\n\n    if pformat in (0, 1, 3, 4, 5):\n        shape = (height, width)\n    elif pformat in (2, 7):\n        shape = (height, width, 3)\n    elif pformat == 6:\n        shape = (height, width, 4)\n    else:\n        raise ValueError(\"Invalid pixel format\")\n\n    if out is None:\n        if int(numframes) > 1:  # numframes must be provided\n            shape = (numframes, ) + shape\n        data = numpy.empty(shape, dtype=dtype)\n    else:\n        # validate size and type of output array\n        if numframes is None:\n            numframes = out.shape[0]\n        if numframes > 1:\n            shape = (numframes, ) + shape\n        if numpy.prod(shape) != out.size or dtype != out.dtype:\n            raise ValueError(\"numpy array does not match image size or type\")\n        data = out\n\n    return data, data.ctypes.data_as(API.pBYTE)",
  "def list_property_flags(flags):\n    \"\"\"Return list of PROPERTY_FLAG strings from flag number.\"\"\"\n    return [k for k, v in list(Lucam.PROP_FLAG.items()) if (v & flags)]",
  "def print_property_range(minval, maxval, default, flags):\n    \"\"\"Return string representation of Lucam.PropertyRange() results.\"\"\"\n    if flags:\n        return \"[%s, %s] default=%s flags=%s\" % (\n            minval, maxval, default,\n            \",\".join(k for k, v in list(Lucam.PROP_FLAG.items()) if (v & flags)))\n    else:\n        return \"[%s, %s] default=%s\" % (minval, maxval, default)",
  "def print_version(version):\n    \"\"\"Return string representation of version number.\"\"\"\n    class Version(ctypes.Union):\n        _fields_ = [('uint', ctypes.c_uint), ('byte', ctypes.c_ubyte * 4)]\n\n    result = []\n    for i in reversed(Version(uint=version).byte):\n        if i or result:\n            result.append('%i' % i)\n    return '.'.join(result)",
  "def print_structure(structure, indent=\"\"):\n    \"\"\"Return string representation of ctypes.Structure.\"\"\"\n    result = [] if indent else ['']\n    for field in structure._fields_:\n        name = field[0]\n        attr = getattr(structure, name)\n        if isinstance(attr, ctypes.Structure):\n            if name in structure._anonymous_:\n                line = \"%s- Struct\\n%s\" % (\n                    indent, print_structure(attr, indent + \"  \"))\n            else:\n                line = \"%s* %s:\\n%s\" % (\n                    indent, name, print_structure(attr, indent + \"  \"))\n        elif isinstance(attr, ctypes.Union):\n            line = \"%s- Union\\n%s\" % (\n                indent, print_structure(attr, indent + \"  \"))\n        else:\n            line = \"%s* %s: %s\" % (indent, name, attr)\n        result.append(line)\n    return \"\\n\".join(result)",
  "def test():\n    \"\"\"Demonstrate use of Lucam object and functions (monochrome only).\"\"\"\n    import time\n\n    # print serial numbers of all connected cameras\n    allcameras = LucamEnumCameras()\n    print((\"Cameras found:\",\n          \", \".join(str(cam.serialnumber) for cam in allcameras)))\n\n    # use first camera\n    lucam = Lucam(1)\n\n    # print detailed information about camera\n    print((\"Camera Properties\", lucam))\n\n    # set camera to 16 bit, 4x4 binning, max framerate\n    lucam.SetFormat(\n        Lucam.FrameFormat(0, 0, 348 * 4, 256 * 4, API.LUCAM_PF_16,\n                          binningX=4, flagsX=1, binningY=4, flagsY=1),\n        framerate=100.0)\n\n    # disable all internal image enhancements\n    lucam.set_properties(brightness=1.0, contrast=1.0, saturation=1.0,\n                         hue=0.0, gamma=1.0, exposure=100.0, gain=1.0)\n\n    # get actual frame format, framerate, and bit depth\n    frameformat, framerate = lucam.GetFormat()\n    pixeldepth = lucam.GetTruePixelDepth()\n    print((\"Pixel Depth:\", pixeldepth))\n    print((\"Framerate:\", framerate))\n    print((\"Frame Format\", frameformat))\n\n    print(\"Color correction matrix:\")\n    print(lucam.GetCurrentMatrix())\n\n    # take snapshot, the easy way\n    image = lucam.TakeSnapshot()\n    import matplotlib.pyplot as plt\n    plt.imshow(image)\n    plt.show()\n\n    # take another snapshot into same image buffer\n    lucam.TakeSnapshot(out=image)\n\n    # take multiple snapshots\n    try:\n        snapshot = Lucam.Snapshot(exposure=lucam.exposure, gain=1.0,\n                                timeout=1000.0, format=frameformat)\n        lucam.EnableFastFrames(snapshot)\n        startsnapshots = time.clock()\n        for _ in range(8):\n            lucam.ForceTakeFastFrame(image, validate=False)\n        endsnapshots = time.clock()\n        print(\"Took 8 snapshots in %f seconds\" % (endsnapshots - startsnapshots))\n    except LucamError:\n        print(\"Warning: ForceTakeFastFrame() failed\")\n    finally:\n        lucam.DisableFastFrames()\n\n    # take multiple snapshots with HW trigger enabled\n    lucam.EnableFastFrames(snapshot)\n    lucam.SetTriggerMode(True)\n    lucam.SetTimeout(True, 100.0)  # timeout after 0.1 s\n    try:\n        # might time out if no HW trigger\n        lucam.TakeFastFrame(image)\n    except LucamError:\n        print('TakeFastFrame() timed out')\n    try:\n        # retrieve previous image\n        lucam.TakeFastFrameNoTrigger(image)\n    except LucamError:\n        print('TakeFastFrameNoTrigger() timed out')\n    try:\n        # request to take snapshot\n        # seems not to work on Infinity 2??\n        lucam.TriggerFastFrame()\n        lucam.TakeFastFrame(image)\n    except LucamError:\n        print('TriggerFastFrame() TakeFastFrame() timed out')\n        # force taking snapshot\n    try:\n        lucam.ForceTakeFastFrame(image)\n    except LucamError:\n        print('ForceTakeFastFrame() timed out')\n    finally:\n        lucam.SetTriggerMode(False)\n        lucam.DisableFastFrames()\n\n    # draw diagonal line into frame buffer\n    numpy.fill_diagonal(image, 255)\n\n    # save last image as TIFF file\n    lucam.SaveImage(image, '_tmp.tif')\n\n    # take video in streaming mode\n    lucam.StreamVideoControl('start_streaming')  # streaming without display\n    video = lucam.TakeVideo(8)  # take a 8 frames video\n    lucam.TakeVideo(None, out=video)  # take another video into same buffer\n    lucam.StreamVideoControl('stop_streaming')\n\n    # save first video frame as RAW file\n    lucam.SaveImage(video, '_tmp.raw')\n\n    # preview video stream in window\n    lucam.CreateDisplayWindow(b\"Test\")\n    lucam.StreamVideoControl('start_display')\n    time.sleep(1.0)\n    lucam.AdjustDisplayWindow(width=frameformat.width * 2,\n                              height=frameformat.height * 2)\n    time.sleep(1.0)\n    print(\"Display rate: %.2f\" % lucam.QueryDisplayFrameRate())\n    lucam.StreamVideoControl('stop_streaming')\n    lucam.DestroyDisplayWindow()\n\n    # reset camera to power-on defaults\n    lucam.CameraReset()\n\n    # set camera to 8 bit VGA mode at low framerate\n    lucam.SetFormat(\n        Lucam.FrameFormat(64, 64, 640, 480, API.LUCAM_PF_8,\n                          binningX=1, flagsX=1, binningY=1, flagsY=1),\n        framerate=10.0)\n    frameformat, framerate = lucam.GetFormat()\n\n    # run a callback function during snapshot\n    def snapshot_callback(context, data, size):\n        data[0] = 42\n        print((\"Snapshot callback function:\", context, data[:2], size))\n    callbackid = lucam.AddSnapshotCallback(snapshot_callback)\n    image = lucam.TakeSnapshot()\n    assert image[0, 0] == 42\n    lucam.RemoveSnapshotCallback(callbackid)\n\n    # run a callback function in streaming mode\n    def streaming_callback(context, data, size):\n        data[0] = 42\n        print((\"Streaming callback function:\", context, data[:2], size))\n    callbackid = lucam.AddStreamingCallback(streaming_callback)\n    lucam.StreamVideoControl('start_streaming')\n    time.sleep(2.0 / framerate)\n    lucam.StreamVideoControl('stop_streaming')\n    lucam.RemoveStreamingCallback(callbackid)\n\n    # set camera look up table to invers\n    lucam.Setup8bitsLUT(list(reversed(list(range(256)))))\n\n    # stream to AVI file\n    lucam.StreamVideoControlAVI('start_streaming', '_tmp.avi')\n    time.sleep(1.0)\n    lucam.StreamVideoControlAVI('stop_streaming')\n\n    # reset camera look up table\n    lucam.Setup8bitsLUT(None)\n\n    # convert 8 bit AVI to 24 bit.\n    lucam.ConvertRawAVIToStdVideo('_tmp24.avi', '_tmp.avi', 'standard_24')\n\n    # Read user-defined non-volatile memory\n    memory = lucam.PermanentBufferRead()\n    print((\"Non-volatile memory:\", memory))\n\n    # close camera connection\n    lucam.CameraClose()\n    del lucam\n\n    # simultaneously take images from all connected cameras\n    allcameras = [Lucam(i + 1) for i in range(len(LucamEnumCameras()))]\n    sync = LucamSynchronousSnapshots(allcameras)\n    data = sync.Take()  # take snapshot\n    sync.Take(data)  # take second snapshot into same buffer\n    sync.Disable()\n\n    # preview AVI files\n    avi = LucamPreviewAVI('_tmp.avi')\n    avi.Control('start')\n    time.sleep(1.0)\n    avi.Control('pause')\n    avi.SetPositionFrame(avi.GetFrameCount() // 2)\n    avi.Control('stop')\n    print((\"AVI Properties\", avi))\n    print(\"Done\")",
  "class LUCAM_VERSION(ctypes.Structure):\n        \"\"\"Lucam version structure.\"\"\"\n        _fields_ = [\n            ('firmware', ULONG),\n            ('fpga', ULONG),\n            ('api', ULONG),\n            ('driver', ULONG),\n            ('serialnumber', ULONG),\n            ('reserved', ULONG)]\n\n        def __str__(self):\n            return print_structure(self)",
  "class LUCAM_FRAME_FORMAT(ctypes.Structure):\n        \"\"\"Lucam frame format structure.\"\"\"\n        class X(ctypes.Union):\n            _fields_ = [('subSampleX', USHORT), ('binningX', USHORT)]\n\n        class Y(ctypes.Union):\n            _fields_ = [('subSampleY', USHORT), ('binningY', USHORT)]\n\n        _anonymous_ = ['_x', '_y']\n        _fields_ = [\n            ('xOffset', ULONG),\n            ('yOffset', ULONG),\n            ('width', ULONG),\n            ('height', ULONG),\n            ('pixelFormat', ULONG),\n            ('_x', X),\n            ('flagsX', USHORT),\n            ('_y', Y),\n            ('flagsY', USHORT)]\n\n        def __str__(self):\n            return print_structure(self)",
  "class LUCAM_SNAPSHOT(ctypes.Structure):\n        \"\"\"Lucam snapshot settings structure.\"\"\"\n        class GAINS(ctypes.Union):\n            class RBGG(ctypes.Structure):\n                _fields_ = [\n                    ('gainRed', FLOAT),\n                    ('gainBlue', FLOAT),\n                    ('gainGrn1', FLOAT),\n                    ('gainGrn2', FLOAT)]\n\n            class MCYY(ctypes.Structure):\n                _fields_ = [\n                    ('gainMag', FLOAT),\n                    ('gainCyan', FLOAT),\n                    ('gainYel1', FLOAT),\n                    ('gainYel2', FLOAT)]\n\n            _anonymous_ = ['_rbgg', '_mcyy']\n            _fields_ = [('_rbgg', RBGG), ('_mcyy', MCYY)]\n\n        class STROBE(ctypes.Union):\n            _fields_ = [('useStrobe', BOOL), ('strobeFlags', ULONG)]\n\n        _anonymous_ = ['_gains', '_strobe']\n        _fields_ = [\n            ('exposure', FLOAT),  # time in ms to expose image before readout\n            ('gain', FLOAT),  # overall gain as a multiplicative factor\n            ('_gains', GAINS),\n            ('_strobe', STROBE),\n            ('strobeDelay', FLOAT),  # delay in ms from exposure to flash\n            ('useHwTrigger', c_int),  # wait for hardware trigger\n            ('timeout', FLOAT),  # max time in ms to wait for trigger\n            ('format', LUCAM_FRAME_FORMAT),\n            ('shutterType', ULONG),\n            ('exposureDelay', FLOAT),  # delay in ms from trigger to exposure\n            ('bufferlastframe', BOOL),\n            ('ulReserved2', ULONG),\n            ('flReserved1', FLOAT),\n            ('flReserved2', FLOAT)]\n\n        def __str__(self):\n            return print_structure(self)",
  "class LUCAM_CONVERSION(ctypes.Structure):\n        \"\"\"Lucam conversion structure.\"\"\"\n        _fields_ = [\n            ('DemosaicMethod', ULONG),\n            ('CorrectionMatrix', ULONG)]",
  "class LUCAM_CONVERSION_PARAMS(ctypes.Structure):\n        \"\"\"Structure used for new conversion functions.\"\"\"\n        class GAINS(ctypes.Union):\n            class YUV(ctypes.Structure):\n                _fields_ = [\n                    ('DigitalGain', FLOAT),\n                    ('DigitalWhiteBalanceU', FLOAT),\n                    ('DigitalWhiteBalanceV', FLOAT)]\n\n            class RGB(ctypes.Structure):\n                _fields_ = [\n                    ('DigitalGainRed', FLOAT),\n                    ('DigitalGainGreen', FLOAT),\n                    ('DigitalGainBlue', FLOAT)]\n\n            _anonymous_ = ['_yuv', '_rgb']\n            _fields_ = [('_yuv', YUV), ('_rgb', RGB)]\n\n        _anonymous_ = ['_gains']\n        _fields_ = [\n            ('Size', ULONG),\n            ('DemosaicMethod', ULONG),\n            ('CorrectionMatrix', ULONG),\n            ('FlipX', BOOL),\n            ('FlipY', BOOL),\n            ('Hue', FLOAT),\n            ('Saturation', FLOAT),\n            ('UseColorGainsOverWb', BOOL),\n            ('_gains', GAINS)]\n\n        def __str__(self):\n            return print_structure(self)",
  "class LUCAM_IMAGE_FORMAT(ctypes.Structure):\n        \"\"\"Image format information.\"\"\"\n        _fields_ = [\n            ('Size', ULONG),\n            ('Width', ULONG),\n            ('Height', ULONG),\n            ('PixelFormat', ULONG),\n            ('ImageSize', ULONG),\n            ('LucamReserved', ULONG * 8)]\n\n        def __str__(self):\n            return print_structure(self)",
  "def __init__(self, number=1):\n        \"\"\"Open connection to Lumenera camera.\n\n        number : int\n            Camera number. Must be in range 1 through LucamNumCameras().\n\n        \"\"\"\n        self._handle = API.LucamCameraOpen(number)\n        if not self._handle:\n            raise LucamError(API.LucamGetLastError())\n        self._byteorder = '<' if self.is_little_endian() else '>'\n        self._default_frameformat, self._default_framerate = self.GetFormat()\n        self._fastframe = None  # frame format while in fast frame mode\n        self._streaming = None  # frame format while in streaming mode\n        self._callbacks = {}  # references to callback functions\n        self._displaying_window = False",
  "def __del__(self):\n        \"\"\"Close connection to camera.\"\"\"\n        assert not self._displaying_window\n        assert self._fastframe is None\n        assert self._streaming is None\n        if self._handle:\n            API.LucamCameraClose(self._handle)",
  "def __str__(self):\n        \"\"\"Return detailed information about camera as string.\"\"\"\n        default = self._default_frameformat\n        camid = self.GetCameraId()\n        version = self.QueryVersion()\n        interface = self.QueryExternInterface()\n        frame, fps = self.GetFormat()\n        allfps = self.EnumAvailableFrameRates()\n        depth = self.GetTruePixelDepth()\n        littleendian = self.is_little_endian()\n        gpo, gpi = self.GpioRead()\n        pixformat = 'raw8 raw16 RGB24 YUV422 Count Filter RGBA32 RGB48'.split()\n\n        result = [\n            \"\",\n            \"Camera handle: %s\" % hex(int(self._handle)),\n            \"Camera ID: %s\" % hex(int(camid)),\n            \"Camera model: %s\" % CAMERA_MODEL.get(camid, \"Unknown\"),\n            \"Serial number: %s\" % version.serialnumber,\n            \"Firmware version: %s\" % print_version(version.firmware),\n            \"FPGA version: %s\" % print_version(version.fpga),\n            \"API version: %s\" % print_version(version.api),\n            \"Driver version: %s\" % print_version(version.driver),\n            \"Interface: %s\" % Lucam.EXTERN_INTERFACE[interface],\n            \"Endianess: %s\" % (\"little\" if littleendian else \"big\"),\n            \"GPIO output registers: 0x%01X\" % gpo,\n            \"GPIO input registers: 0x%01X\" % gpi,\n            \"Default size: %i x %i\" % (default.width, default.height),\n            \"Default pixel format: %s\" % pixformat[default.pixelFormat],\n            \"Default frame rate: %.2f\" % self._default_framerate,\n            \"Image offset: %i, %i\" % (frame.xOffset, frame.yOffset),\n            \"Image size: %i x %i\" % (frame.width // frame.binningX,\n                                     frame.height // frame.binningY),\n            \"Binning: %ix%i\" % (frame.binningX, frame.binningY)\n            if frame.flagsX else\n            \"Subsampling: %ix%i\" % (frame.subSampleX, frame.subSampleY),\n            \"Pixel format: %s\" % pixformat[frame.pixelFormat],\n            \"Pixel depth: %i bit\" % (depth if frame.pixelFormat else 8),\n            \"Frame rate: %.2f\" % fps,\n            \"Available frame rates: %s\" % ', '.join('%.2f' % f\n                                                    for f in allfps)\n        ]\n        #mn = API.FLOAT()\n        #mx = API.FLOAT()\n        value = API.FLOAT()\n        flags = API.LONG()\n        for name in sorted(Lucam.PROPERTY):\n            prop = Lucam.PROPERTY[name]\n            if API.LucamGetProperty(self._handle, prop, value, flags):\n                name = name.capitalize().replace('_', ' ')\n                if flags.value:\n                    result.append(\"%s: %s (%s)\" % (\n                        name, value.value,\n                        \",\".join(list_property_flags(flags.value))))\n                else:\n                    result.append(\"%s: %s\" % (name, value.value))\n            #if API.LucamPropertyRange(self._handle, prop,\n            #                          mn, mx, value, flags):\n            #    result.append(\"%s range: %s\" % (name, print_range(\n            #            mn.value, mx.value, value.value, flags.value)))\n        return \"\\n* \".join(result)",
  "def __getattr__(self, name):\n        \"\"\"Return value of PROPERTY or PROP_RANGE attribute.\"\"\"\n        if name in Lucam.PROPERTY:\n            return self.GetProperty(name)[0]\n        elif name.endswith(\"_range\"):\n            result = self.PropertyRange(name[:-6])\n            setattr(self, name, result)\n            return result\n        raise AttributeError(\"'Lucam' object has no attribute '%s'\" % name)",
  "def default_snapshot(self):\n        \"\"\"Return default Snapshot settings.\"\"\"\n        snapshot = API.LUCAM_SNAPSHOT()\n        snapshot.format = self.GetFormat()[0]\n        snapshot.exposure = self.GetProperty('exposure')[0]\n        snapshot.gain = self.GetProperty('gain')[0]\n        snapshot.timeout = 1000.0\n        snapshot.gainRed = 1.0\n        snapshot.gainBlue = 1.0\n        snapshot.gainGrn1 = 1.0\n        snapshot.gainGrn2 = 1.0\n        snapshot.useStrobe = False\n        snapshot.strobeDelay = 0.0\n        snapshot.useHwTrigger = 0\n        snapshot.shutterType = 0\n        snapshot.exposureDelay = 0.0\n        snapshot.bufferlastframe = 0\n        return snapshot",
  "def default_conversion(self):\n        \"\"\"Return default Conversion settings for ConvertFrameToRgb24().\"\"\"\n        return API.LUCAM_CONVERSION(DemosaicMethod=API.LUCAM_DM_NONE,\n                                    CorrectionMatrix=API.LUCAM_CM_NONE)",
  "def is_little_endian(self):\n        \"\"\"Return Endianess of camera.\"\"\"\n        value, flags = self.GetProperty(API.LUCAM_PROP_COLOR_FORMAT)\n        return bool(flags & API.LUCAM_PROP_FLAG_LITTLE_ENDIAN)",
  "def set_properties(self, **kwargs):\n        \"\"\"Set value of mutiple camera properties.\"\"\"\n        for name, value in list(kwargs.items()):\n            if name.endswith('_flag'):\n                continue\n            prop = Lucam.PROPERTY[name]\n            flag = kwargs.get(name + '_flag', 0)\n            if not API.LucamSetProperty(self._handle, prop, value, flag):\n                raise LucamError(self)",
  "def CameraClose(self):\n        \"\"\"Close connection to camera.\"\"\"\n        if self._displaying_window:\n            self.DestroyDisplayWindow()\n        if not API.LucamCameraClose(self._handle):\n            raise LucamError(self)\n        self._fastframe = None\n        self._streaming = None\n        self._handle = None",
  "def CameraReset(self):\n        \"\"\"Reset camera to its power-on default state.\"\"\"\n        if not API.LucamCameraReset(self._handle):\n            raise LucamError(self)\n        self._fastframe = None\n        self._streaming = None",
  "def QueryVersion(self):\n        \"\"\"Return camera version information as API.LUCAM_VERSION.\"\"\"\n        result = API.LUCAM_VERSION()\n        if not API.LucamQueryVersion(self._handle, result):\n            raise LucamError(self)\n        return result",
  "def QueryExternInterface(self):\n        \"\"\"Return type of interface between camera and computer.\n\n        Return value is one of Lucam.EXTERN_INTERFACE keys.\n\n        \"\"\"\n        result = API.ULONG()\n        if not API.LucamQueryExternInterface(self._handle, result):\n            raise LucamError(self)\n        return result.value",
  "def GetCameraId(self):\n        \"\"\"Return camera model ID, one of CAMERA_MODEL keys.\"\"\"\n        result = API.ULONG()\n        if not API.LucamGetCameraId(self._handle, result):\n            raise LucamError(self)\n        return result.value",
  "def EnumAvailableFrameRates(self):\n        \"\"\"Return available frame rates based on camera's clock rates.\"\"\"\n        result = API.FLOAT()\n        size = API.LucamEnumAvailableFrameRates(self._handle, 0, result)\n        result = (API.FLOAT * size)()\n        if not API.LucamEnumAvailableFrameRates(self._handle, size, result):\n            raise LucamError(self)\n        return tuple(result)",
  "def QueryDisplayFrameRate(self):\n        \"\"\"Return average displayed frame rate since preview started.\"\"\"\n        result = API.FLOAT()\n        if not API.LucamQueryDisplayFrameRate(self._handle, result):\n            raise LucamError(self)\n        return result.value",
  "def DisplayPropertyPage(self, parent):\n        \"\"\"Open a DirectShow dialog window with camera properties.\"\"\"\n        if not API.LucamDisplayPropertyPage(self._handle, parent):\n            raise LucamError(self)",
  "def DisplayVideoFormatPage(self, parent):\n        \"\"\"Open a DirectShow dialog window with video properties.\"\"\"\n        if not API.LucamDisplayVideoFormatPage(self._handle, parent):\n            raise LucamError(self)",
  "def CreateDisplayWindow(self, title=b\"\", style=282001408,\n                            x=0, y=0, width=0, height=0, parent=0, menu=0):\n        \"\"\"Create window, managed by API, for displaying video.\n\n        Parameters\n        ----------\n        title : byte str\n            Title of window that appears in window frame.\n        style : int\n            Window style.\n        x, y : int\n           Coordinates of pixel in video stream that will appear in\n           upper left corner of display window. Default = 0.\n        width, height: int\n            Extent of scaled video stream in pixels.\n\n        The window is not automatically resized to the video frame size.\n\n        \"\"\"\n        if not API.LucamCreateDisplayWindow(\n                self._handle, title, style, x, y, width, height, parent, menu):\n            raise LucamError(self)\n        self._displaying_window = True",
  "def DestroyDisplayWindow(self):\n        \"\"\"Destroy display window created with CreateDisplayWindow().\"\"\"\n        if not API.LucamDestroyDisplayWindow(self._handle):\n            raise LucamError(self)\n        self._displaying_window = False",
  "def AdjustDisplayWindow(self, title=b\"\", x=0, y=0, width=0, height=0):\n        \"\"\"Scale video stream into preview window.\n\n        Parameters\n        ----------\n        title : byte str\n            Title of window that appears in window frame.\n        x, y : int\n           Coordinates of pixel in video stream that will appear in\n           upper left corner of display window. Can be used to pan the\n           display windows across the video stream.\n        width, height: int\n            Extent of scaled video stream in pixels. Can be used to zoom.\n\n        \"\"\"\n        if not API.LucamAdjustDisplayWindow(self._handle, title,\n                                            x, y, width, height):\n            raise LucamError(self)",
  "def GetTruePixelDepth(self):\n        \"\"\"Return actual pixel depth when running in 16 bit mode.\"\"\"\n        result = API.ULONG()\n        if not API.LucamGetTruePixelDepth(self._handle, result):\n            raise LucamError(self)\n        return result.value",
  "def GetVideoImageFormat(self):\n        \"\"\"Return video image format used to capture video frame.\n\n        Return type is API.LUCAM_IMAGE_FORMAT.\n\n        The video image format is needed to convert a raw Bayer frame\n        to either color or greyscale using the ConvertFrame***() functions.\n\n        \"\"\"\n        result = API.LUCAM_IMAGE_FORMAT()\n        if not API.LucamGetVideoImageFormat(self._handle, result):\n            raise LucamError(self)\n        return result",
  "def GetLastErrorForCamera(self):\n        \"\"\"Return code of last error that occurred in a API function.\n\n        Error codes and messages can be found in LucamError.CODES.\n\n        \"\"\"\n        return API.LucamGetLastErrorForCamera(self._handle)",
  "def SetProperty(self, prop, value, flags=0):\n        \"\"\"Set value of camera property.\n\n        Parameters\n        ----------\n        prop : int or str\n            Camera property. One of Lucam.PROPERTY keys or values.\n        flags : int or sequence of str\n            Capability flags for property. One or combination of\n            Lucam.PROP_FLAG. Default is 0.\n\n        Not all properties are supported by all cameras. If a capability\n        flag is not supported by the property, it is silently ignored.\n\n        \"\"\"\n        prop = Lucam.PROPERTY.get(prop, prop)\n        if isinstance(flags, (list, tuple)):\n            flags, flagseq = 0x0, flags\n            for f in flagseq:\n                flags |= Lucam.PROP_FLAG[f]\n        if not API.LucamSetProperty(self._handle, prop, value, flags):\n            raise LucamError(self)",
  "def GetProperty(self, prop):\n        \"\"\"Return value and capability flag of camera property.\n\n        Parameters\n        ----------\n        prop : int or str\n            Camera property. One of Lucam.PROPERTY keys or values.\n\n        \"\"\"\n        value = API.FLOAT()\n        flags = API.LONG()\n        prop = Lucam.PROPERTY.get(prop, prop)\n        if not API.LucamGetProperty(self._handle, prop, value, flags):\n            raise LucamError(self)\n        return value.value, flags.value",
  "def PropertyRange(self, prop):\n        \"\"\"Return range of valid values for property and its default value.\n\n        Return value is tuple of:\n            minimum valid value of camera property,\n            maximum valid value of camera property,\n            default value of camera property,\n            capability flags for property.\n\n        \"\"\"\n        mn = API.FLOAT()\n        mx = API.FLOAT()\n        default = API.FLOAT()\n        flags = API.LONG()\n        prop = Lucam.PROPERTY.get(prop, prop)\n        if not API.LucamPropertyRange(self._handle, prop, mn, mx,\n                                      default, flags):\n            raise LucamError(self)\n        return mn.value, mx.value, default.value, flags.value",
  "def GetFormat(self):\n        \"\"\"Return frame format and rate of video data.\n\n        Return type is tuple of API.LUCAM_FRAME_FORMAT and framerate.\n\n        \"\"\"\n        frameformat = API.LUCAM_FRAME_FORMAT()\n        framerate = API.FLOAT()\n        if not API.LucamGetFormat(self._handle, frameformat, framerate):\n            raise LucamError(self)\n        return frameformat, framerate.value",
  "def SetFormat(self, frameformat, framerate):\n        \"\"\"Set frame format and frame rate for video data.\n\n        Parameters\n        ----------\n        frameformat : API.LUCAM_FRAME_FORMAT\n            Video frame format.\n        framerate : float\n            Frame rate for streaming video.\n\n        The origin of the imager is top left. Each dimension of the subwindow\n        must be evenly divisible by 8.\n\n        \"\"\"\n        if not API.LucamSetFormat(self._handle, frameformat, framerate):\n            raise LucamError(self)\n        if self._fastframe:\n            self._fastframe = frameformat\n        if self._streaming:\n            self._streaming = frameformat",
  "def ReadRegister(self, address, numreg):\n        \"\"\"Return values from contiguous internal camera registers.\n\n        Parameters\n        ----------\n        address : int\n            Starting register address.\n        numreg : int\n            Number of contiguous registers to read.\n\n        \"\"\"\n        result = (API.LONG * numreg)()\n        if not API.LucamReadRegister(self._handle, address, numreg, result):\n            raise LucamError(self)\n        return [v.value for v in result]",
  "def WriteRegister(self, address, values):\n        \"\"\"Write values to contiguous internal camera registers.\n\n        Parameters\n        ----------\n        address : int\n            Starting register address.\n        values : sequence of int\n            Values to write into registers.\n\n        \"\"\"\n        numreg = len(values)\n        pvalue = (API.LONG * numreg)()\n        for i in range(numreg):\n            pvalue[i] = values[i]\n        if not API.LucamWriteRegister(self._handle, address, numreg, pvalue):\n            raise LucamError(self)",
  "def SetTimeout(self, still, timeout):\n        \"\"\"Update timeout value set previously with API.LUCAM_SNAPSHOT.timeout.\n\n        Parameters\n        ----------\n        still : bool\n            If True, update timeout for snapshot mode, else for streaming mode.\n        timeout : float\n            Maximum time in ms to wait for trigger before returning from\n            function.\n\n        \"\"\"\n        if not API.LucamSetTimeout(self._handle, still, timeout):\n            raise LucamError(self)",
  "def SetTriggerMode(self, usehwtrigger):\n        \"\"\"Sets trigger mode used for snapshots while in FastFrames mode.\n\n        Parameters\n        ----------\n        usehwtrigger : bool\n            If True, the camera is set to use the hardware trigger.\n\n        \"\"\"\n        if not API.LucamSetTriggerMode(self._handle, usehwtrigger):\n            raise LucamError(self)",
  "def TriggerFastFrame(self):\n        \"\"\"Initiate the request to take a snapshot.\n\n        The camera should be in Fast Frames mode using EnableFastFrames().\n        This function will not wait for the return of the snapshot. Use\n        TakeFastFrame() or TakeFastFrameNoTrigger() to take the snapshot.\n\n        \"\"\"\n        if not API.LucamTriggerFastFrame(self._handle):\n            raise LucamError(self)",
  "def CancelTakeFastFrame(self):\n        \"\"\"Cancel call to TakeFastFrame() and other functions.\n\n        Cancel calls to ForceTakeFastFrame(), TakeFastFrameNoTrigger() or\n        TakeSnapshot() made in another programming thread. The cancelled\n        function will raise LucamError(48).\n\n        \"\"\"\n        if not API.LucamCancelTakeFastFrame(self._handle):\n            raise LucamError(self)",
  "def EnableFastFrames(self, snapshot=None):\n        \"\"\"Enable fast snapshot capture mode.\n\n        Parameters\n        ----------\n        snapshot : API.LUCAM_SNAPSHOT or None\n            Settings to use for the snapshot. If None (default),\n            settings returned by default_snapshot() will be used.\n\n        If video is streaming when a snapshot is taken, the stream will\n        automatically be stopped (pausing video in the display window if\n        present) before the snapshot is taken. It is not restarted after\n        the snapshot is taken.\n\n        \"\"\"\n        if snapshot is None:\n            snapshot = self.default_snapshot()\n        self._fastframe = snapshot.format\n        if not API.LucamEnableFastFrames(self._handle, snapshot):\n            self._fastframe = None\n            raise LucamError(self)",
  "def TakeFastFrame(self, out=None, validate=True):\n        \"\"\"Return a single image using still imaging mode.\n\n        Parameters\n        ----------\n        out : numpy array, or None\n            Output buffer. If None, a new numpy.array containing the image\n            data is returned. Else image data will be copied into the\n            output array.\n        validate : bool\n            If True (default), size and dtype of the output array are\n            validated.\n\n        The camera should be in Fast Frames mode using EnableFastFrames().\n\n        \"\"\"\n        data, pdata = ndarray(self._fastframe, self._byteorder, out, validate)\n        if not API.LucamTakeFastFrame(self._handle, pdata):\n            raise LucamError(self)\n        if out is None:\n            return data",
  "def ForceTakeFastFrame(self, out=None, validate=True):\n        \"\"\"Force a SW triggered snapshot while in HW triggered FastFrames mode.\n\n        Parameters\n        ----------\n        out : numpy array, or None\n            Output buffer. If None, a new numpy.array containing the image\n            data is returned. Else image data will be copied into the\n            output array.\n        validate : bool\n            If True (default), size and dtype of the output array are\n            validated.\n\n        Return a snapshot frame without waiting for the next HW trigger.\n\n        \"\"\"\n        data, pdata = ndarray(self._fastframe, self._byteorder, out, validate)\n        if not API.LucamForceTakeFastFrame(self._handle, pdata):\n            raise LucamError(self)\n        if out is None:\n            return data",
  "def TakeFastFrameNoTrigger(self, out=None, validate=True):\n        \"\"\"Return previously taken single image using still imaging mode.\n\n        Parameters\n        ----------\n        out : numpy array, or None\n            Output buffer. If None, a new numpy.array containing the image\n            data is returned. Else image data will be copied into the\n            output array.\n        validate : bool\n            If True (default), size and dtype of the output array are\n            validated.\n\n        To use this function, the camera should be in Fast Frames mode\n        using EnableFastFrames().\n        If the camera is in HW triggered mode, this function can retrieve\n        a previously captured image from the API without sending an new\n        snapshot request and waiting for the next snapshot.\n\n        \"\"\"\n        data, pdata = ndarray(self._fastframe, self._byteorder,\n                              out, validate)\n        if not API.LucamTakeFastFrameNoTrigger(self._handle, pdata):\n            raise LucamError(self)\n        if out is None:\n            return data",
  "def DisableFastFrames(self):\n        \"\"\"Disable fast snapshot capture mode.\n\n        If the camera was streaming when EnableFastFrames() was called,\n        streaming will be restored.\n\n        \"\"\"\n        self._fastframe = None\n        if not API.LucamDisableFastFrames(self._handle):\n            raise LucamError(self)",
  "def TakeSnapshot(self, snapshot=None, out=None, validate=True):\n        \"\"\"Return single image as numpy array using still imaging.\n\n        Parameters\n        ----------\n        snapshot : API.LUCAM_SNAPSHOT or None\n            Settings to use for the snapshot. If None (default),\n            settings returned by default_snapshot() will be used.\n        out : numpy array, or None\n            Output buffer. If None, a new numpy.array containing the image\n            data is returned. Else image data will be copied into the\n            output array.\n\n        Equivalent to calling EnableFastFrames(), TakeFastFrame(), and\n        DisableFastFrames().\n\n        \"\"\"\n        if snapshot is None:\n            snapshot = self.default_snapshot()\n        data, pdata = ndarray(snapshot.format, self._byteorder, out, validate)\n        if not API.LucamTakeSnapshot(self._handle, snapshot, pdata):\n            raise LucamError(self)\n        if out is None:\n            return data",
  "def SaveImage(self, data, filename):\n        \"\"\"Save a single image or video frame to disk.\n\n        Parameters\n        ----------\n        data : numpy array\n            Input data.\n        filename : str\n            Name of file. The file extension indicates the file format:\n            .bmp - Windows bitmap\n            .jpg - Joint Photograhic Experts Group\n            .tif - Tagged Image File Format\n            .raw - Raw\n\n        This function accounts for the endianess of the camera output\n        when using 16 bit data.\n\n        \"\"\"\n        pdata = data.ctypes.data_as(API.pBYTE)\n        height, width = data.shape[-2:]\n        pixelformat = {\n            (2, 1): API.LUCAM_PF_8,\n            (3, 1): API.LUCAM_PF_24,\n            (4, 1): API.LUCAM_PF_32,\n            (2, 2): API.LUCAM_PF_16,\n            (3, 2): API.LUCAM_PF_48}[(data.ndim, data.dtype.itemsize)]\n        if not API.LucamSaveImageWEx(self._handle, width, height,\n                                     pixelformat, pdata, filename):\n            raise LucamError(self)",
  "def StreamVideoControl(self, ctrltype, window=0):\n        \"\"\"Control streaming video.\n\n        Parameters\n        ----------\n        ctrltype : str or int\n            One of Lucam.VIDEO_CONTROL keys or values.\n            'start_display' starts video streaming and displays it in window.\n            'start_streaming' starts video streaming without display.\n            'stop_streaming' stops video streaming.\n            'pause_stream' pauses video streaming.\n        window : int\n            Handle of window to stream video to. Default is the window\n            created by CreateDisplayWindow().\n\n        \"\"\"\n        ctrltype = Lucam.VIDEO_CONTROL.get(ctrltype, ctrltype)\n        if ctrltype in (API.START_STREAMING,\n                        API.START_DISPLAY,\n                        API.START_RGBSTREAM):\n            self._streaming = self.GetFormat()[0]\n        else:\n            self._streaming = None\n        if not API.LucamStreamVideoControl(self._handle, ctrltype, window):\n            self._streaming = None\n            raise LucamError(self)",
  "def TakeVideo(self, numframes, out=None, validate=True):\n        \"\"\"Take video frames using video mode.\n\n        Parameters\n        ----------\n        numframes : int\n            Number of video frames to take.\n        out : numpy array, or None\n            Output buffer. If None, a new numpy.array containing the image\n            data is returned. Else image data will be copied into the\n            output array.\n        validate : bool\n            If True (default), size and dtype of the output array are\n            validated.\n\n        Start the video stream with StreamVideoControl() before calling\n        this function.\n\n        \"\"\"\n        data, pdata = ndarray(self._streaming, self._byteorder, out,\n                              validate, numframes)\n        if numframes is None:\n            numframes = data.shape[0]\n        if not API.LucamTakeVideo(self._handle, numframes, pdata):\n            raise LucamError(self)\n        if out is None:\n            return data",
  "def TakeVideoEx(self, out=None, timeout=100.0, validate=True):\n        \"\"\"Return coordinates of video data greater than a specified threshold.\n\n        This function is not implemented yet.\n\n        \"\"\"\n        raise NotImplementedError()",
  "def CancelTakeVideo(self):\n        \"\"\"Cancel call to TakeVideo() and TakeVideoEx() made in another thread.\n\n        The cancelled function will raise LucamError(48).\n\n        \"\"\"\n        if not API.LucamCancelTakeVideo(self._handle):\n            raise LucamError(self)",
  "def StreamVideoControlAVI(self, ctrltype, filename='', window=0):\n        \"\"\"Control capture of the video in a raw 8 bit AVI file.\n\n        Parameters\n        ----------\n        ctrltype : str or int\n            One of Lucam.VIDEO_CONTROL keys or values:\n                'start_display'\n                    Starts capture of the video and displays it in window.\n                'start_streaming'\n                    Captures the video without displaying it, which gives an\n                    AVI file with higher quality and frame rate.\n                'stop_streaming'\n                    Stops video streaming.\n                'pause_stream'\n                   Pauses video streaming.\n        filename : str\n            Name of AVI file.\n        window : int\n            Handle of window to stream video to. Default is the window\n            created by CreateDisplayWindow().\n\n        \"\"\"\n        ctrltype = Lucam.VIDEO_CONTROL.get(ctrltype, ctrltype)\n        if not API.LucamStreamVideoControlAVI(self._handle, ctrltype,\n                                              filename, window):\n            raise LucamError(self)",
  "def ConvertRawAVIToStdVideo(self, outfile, inputfile, outtype=1):\n        \"\"\"Convert raw 8 bit AVI file to 24 or 32 bit standard RGB AVI.\n\n        Parameters\n        ----------\n        outfile : str\n            Name of output AVI file. Must be different from inputfile.\n        inputfile : str\n            Name of input AVI file obtained with StreamVideoControlAVI().\n        outtype : str or int\n            Output AVI type: 'standard_24' (default) or 'standard_32'.\n\n        \"\"\"\n        outtype = Lucam.AVI_TYPE.get(outtype, outtype)\n        if not API.LucamConvertRawAVIToStdVideo(self._handle, outfile,\n                                                inputfile, outtype):\n            raise LucamError(self)",
  "def ConvertFrameToRgb24(self, frameformat, source_frame_pointer, conversion_params=None):\n        \"\"\"Return RGB24 image from raw Bayer data.\"\"\"\n        \"\"\"\n        LucamConvertFrameToRgb24 = (\n        BOOL, HANDLE, pUCHAR_RGB, pBYTE, ULONG, ULONG, ULONG,\n        pLUCAM_CONVERSION)\n    LucamConvertFrameToRgb32 = (\n        BOOL, HANDLE, pBYTE, pBYTE, ULONG, ULONG, ULONG, pLUCAM_CONVERSION)\n    LucamConvertFrameToRgb48 = (\n        BOOL, HANDLE, pUSHORT, pUSHORT, ULONG, ULONG, ULONG, pLUCAM_CONVERSION)\n    LucamConvertFrameToGreyscale8 = (\n        BOOL, HANDLE, pBYTE, pBYTE, ULONG, ULONG, ULONG, pLUCAM_CONVERSION)\n    LucamConvertFrameToGreyscale16 = (\n        BOOL, HANDLE, pUSHORT, pUSHORT, ULONG, ULONG, ULONG, pLUCAM_CONVERSION)\"\"\"\n        if conversion_params is None:\n                conversion_params = self.default_conversion()\n                conversion_params.DemosaicMethod = API.LUCAM_DM_FAST #need to think about defaults\n        f = frameformat\n        outputformat = copy.copy(frameformat)\n        outputformat.pixelFormat = API.LUCAM_PF_24 #need to modify the frame format for the output\n        dest, pDest = ndarray(outputformat)\n        w, h = f.width // (f.binningX * f.subSampleX), f.height // (f.binningY * f.subSampleY)\n        if not API.LucamConvertFrameToRgb24(self._handle, dest, source_frame_pointer, \n                                            w, h, frameformat.pixelFormat, conversion_params):\n            raise LucamError(self)\n        return dest",
  "def ConvertFrameToRgb32(self):\n        \"\"\"Return RGB32 image from raw Bayer data.\"\"\"\n        raise NotImplementedError()",
  "def ConvertFrameToRgb48(self):\n        \"\"\"Return RGB48 image from raw Bayer data.\"\"\"\n        raise NotImplementedError()",
  "def ConvertFrameToGreyscale8(self, data, out=None, settings=None):\n        \"\"\"Return 8 bit grayscale image from raw Bayer data.\"\"\"\n        raise NotImplementedError()",
  "def ConvertFrameToGreyscale16(self, data, out=None, settings=None):\n        \"\"\"Return 16 bit grayscale image from raw Bayer data.\"\"\"\n        raise NotImplementedError()",
  "def Setup8bitsLUT(self, lut):\n        \"\"\"Populate 8 bit LUT inside camera.\n\n        lut : numpy array, or None\n            If None, camera LUT is disabled.\n            Else lut.shape must be (256,) and lut.dtype must be uint8.\n\n        \"\"\"\n        lut = numpy.array(lut if lut else [], numpy.uint8)\n        if not API.LucamSetup8bitsLUT(self._handle, lut, lut.size):\n            raise LucamError(self)",
  "def Setup8bitsColorLUT(self, lut, red=False, green1=False,\n                           green2=False, blue=False):\n        \"\"\"Populate 8 bit Color LUT inside camera.\n\n        Parameters\n        ----------\n        lut : numpy array, or None\n            If None, camera LUT is disabled.\n            Else lut.shape must be (256,) and lut.dtype must be uint8.\n        red, green1, green2, blue: bool\n            Apply lut to color channel.\n\n        \"\"\"\n        lut = numpy.array(lut if lut else [], numpy.uint8)\n        if not API.LucamSetup8bitsColorLUT(self._handle, lut, lut.size,\n                                           red, green1, green2, blue):\n            raise LucamError(self)",
  "def SetupCustomMatrix(self, matrix):\n        \"\"\"Defines color correction matrix for converting raw data to RGB24.\n\n        Parameters\n        ----------\n        matrix : numpy array\n            3x3 color correction matrix.\n\n        The ConvertFrameToRgb24() function requires a color correction matrix\n        parameter. The pre-defined ones may be used, but when a specific\n        matrix is required, the LUCAM_CM_CUSTOM parameter can be passed and\n        the values defined using this function will be used.\n\n        \"\"\"\n        matrix = numpy.array(matrix, numpy.float32, copy=False)\n        if not API.LucamSetupCustomMatrix(self._handle, matrix):\n            raise LucamError(self)",
  "def GetCurrentMatrix(self):\n        \"\"\"Return current color correction matrix.\"\"\"\n        matrix = numpy.empty((3, 3), numpy.float32)\n        if not API.LucamGetCurrentMatrix(self._handle, matrix):\n            raise LucamError(self)\n        return matrix",
  "def AddStreamingCallback(self, callback, context=None):\n        \"\"\"Add video filter callback function and return callback Id.\n\n        Parameters\n        ----------\n        callback : function\n            API.VideoFilterCallback.\n            The function is called after each frame of streaming video\n            is returned from the camera.\n        context : object\n            Context data to be passed to callback function.\n\n        \"\"\"\n        # asVoidPtr = ctypes.pythonapi.PyCObject_AsVoidPtr #this function converts PyCObject to void *, why is it not in ctypes natively...?\n        # asVoidPtr.restype = ctypes.c_void_p #we need to set the result and argument types of the imported function\n        # asVoidPtr.argtypes = [ctypes.py_object]        \n        callback = API.VideoFilterCallback(callback)\n        if context is not None:\n            context = ctypes.py_object(context)\n        callbackid = API.LucamAddStreamingCallback(self._handle,\n                                                   callback, context)\n        if callbackid == -1:\n            raise LucamError(self)\n        self._callbacks[(API.VideoFilterCallback, callbackid)] = callback\n        return callbackid",
  "def RemoveStreamingCallback(self, callbackid):\n        \"\"\"Remove previously registered video filter callback function.\n\n        Parameters\n        ----------\n        callbackid : int\n            Data filter callback function registered with\n            AddStreamingCallback().\n\n        \"\"\"\n        if not API.LucamRemoveStreamingCallback(self._handle, callbackid):\n            raise LucamError(self)\n        del self._callbacks[(API.VideoFilterCallback, callbackid)]",
  "def AddSnapshotCallback(self, callback, context=None):\n        \"\"\"Add data filter callback function and return callback Id.\n\n        Parameters\n        ----------\n        callback : function\n            API.SnapshotCallback\n            The function is called after each hardware triggered snapshot\n            is returned from the camera but before it is processed.\n        context : object\n            Context data to be passed to callback function.\n\n        \"\"\"\n        callback = API.SnapshotCallback(callback)\n        if context is not None:\n            context = ctypes.py_object(context)\n        callbackid = API.LucamAddSnapshotCallback(self._handle,\n                                                  callback, context)\n        if callbackid == -1:\n            raise LucamError(self)\n        self._callbacks[(API.SnapshotCallback, callbackid)] = callback\n        return callbackid",
  "def RemoveSnapshotCallback(self, callbackid):\n        \"\"\"Remove previously registered data filter callback function.\n\n        Parameters\n        ----------\n        callbackid : int\n            Data filter callback function registered with\n            AddSnapshotCallback().\n\n        \"\"\"\n        if not API.LucamRemoveSnapshotCallback(self._handle, callbackid):\n            raise LucamError(self)\n        del self._callbacks[(API.SnapshotCallback, callbackid)]",
  "def AddRgbPreviewCallback(self, callback, pixelformat, context=None):\n        \"\"\"Add video filter callback function and return callback Id.\n\n        Parameters\n        ----------\n        callback : function\n            API.RgbVideoFilterCallback.\n            This function is called after each frame of streaming video is\n            returned from the camera and after it is processed.\n        pixelformat : str or int\n            The pixel format of the data should match the format of the video.\n            Use QueryRgbPreviewPixelFormat().\n            API.LUCAM_PF_24 or API.LUCAM_PF_32.\n        context : object\n            Context data to be passed to callback function.\n\n        \"\"\"\n        callback = API.RgbVideoFilterCallback(callback)\n        pixelformat = Lucam.PIXEL_FORMAT.get(pixelformat, pixelformat)\n        if context is not None:\n            context = ctypes.py_object(context)\n        callbackid = API.LucamAddRgbPreviewCallback(self._handle, callback,\n                                                    context, pixelformat)\n        if callbackid == -1:\n            raise LucamError(self)\n        self._callbacks[(API.RgbVideoFilterCallback, callbackid)] = callback\n        return callbackid",
  "def RemoveRgbPreviewCallback(self, callbackid):\n        \"\"\"Remove previously registered video filter callback function.\n\n        Parameters\n        ----------\n        callbackid : int\n            Video filter callback function registered with\n            AddRgbPreviewCallback().\n\n        \"\"\"\n        if not API.LucamRemoveRgbPreviewCallback(self._handle, callbackid):\n            raise LucamError(self)\n        del self._callbacks[(API.RgbVideoFilterCallback, callbackid)]",
  "def QueryRgbPreviewPixelFormat(self):\n        \"\"\"Return pixel format for preview window.\"\"\"\n        pixelformat = API.ULONG()\n        if not API.LucamQueryRgbPreviewPixelFormat(self._handle, pixelformat):\n            raise LucamError(self)\n        return pixelformat.value",
  "def OneShotAutoExposure(self, target, startx, starty, width, height):\n        \"\"\"Perform one iteration of exposure adjustment to reach target.\n\n        Parameters\n        ----------\n        target : int\n            Target average brightness (0-255).\n        startx, starty, width, height : int\n            Window coordinates after any subsampling or binning.\n\n        \"\"\"\n        if not API.LucamOneShotAutoExposure(self._handle, target,\n                                            startx, starty, width, height):\n            raise LucamError(self)",
  "def OneShotAutoWhiteBalance(self, startx, starty, width, height):\n        \"\"\"Perform one iteration of analog gain adjustment.\n\n        Parameters\n        ----------\n        startx, starty, width, height : int\n            Window coordinates after any subsampling or binning.\n\n        Perform a single on-chip analog gain adjustment on the video stream\n        in order to color balance the image.\n\n        \"\"\"\n        if not API.LucamOneShotAutoWhiteBalance(self._handle,\n                                                startx, starty, width, height):\n            raise LucamError(self)",
  "def OneShotAutoWhiteBalanceEx(self, redovergreen, blueovergreen,\n                                  startx, starty, width, height):\n        \"\"\"Perform one iteration of exposure adjustment to reach target color.\n\n        Parameters\n        ----------\n        redovergreen, blueovergreen : float\n            Red pixel value of the desired color divided by green value.\n            Blue pixel value of the desired color divided by green value.\n        startx, starty, width, height : int\n            Window coordinates after any subsampling or binning.\n\n        Perform a single on-chip analog gain adjustment on the video stream\n        in order to color balance the image to a specific target color.\n\n        \"\"\"\n        if not API.LucamOneShotAutoWhiteBalanceEx(\n                self._handle, redovergreen, blueovergreen,\n                startx, starty, width, height):\n            raise LucamError(self)",
  "def DigitalWhiteBalance(self, startx, starty, width, height):\n        \"\"\"Perform one iteration of digital color gain adjustment.\n\n        Parameters\n        ----------\n        startx, starty, width, height : int\n            Window coordinates after any subsampling or binning.\n\n        Perform a single digital gain adjustment on the video stream\n        in order to color balance the image.\n\n        \"\"\"\n        if not API.LucamDigitalWhiteBalance(self._handle,\n                                            startx, starty, width, height):\n            raise LucamError(self)",
  "def LucamDigitalWhiteBalanceEx(self, redovergreen, blueovergreen,\n                                   startx, starty, width, height):\n        \"\"\"Perform one iteration of digital color gain adjustment.\n\n        Parameters\n        ----------\n        redovergreen, blueovergreen : float\n            Red pixel value of the desired color divided by green value.\n            Blue pixel value of the desired color divided by green value.\n        startx, starty, width, height : int\n            Window coordinates after any subsampling or binning.\n\n        Perform a single digital gain adjustment on the video stream\n        in order to color balance the image to a specific target color.\n\n        \"\"\"\n        if not API.LucamDigitalWhiteBalanceEx(\n                self._handle, redovergreen, blueovergreen,\n                startx, starty, width, height):\n            raise LucamError(self)",
  "def AdjustWhiteBalanceFromSnapshot(self, snapshot, data, redovergreen,\n                                       blueovergreen, startx, starty,\n                                       width, height):\n        \"\"\"Adjust digital color gain values of previously taken snapshot.\n\n        Parameters\n        ----------\n        snapshot : API.LUCAM_SNAPSHOT\n            Color gain values of this structure will be changed inplace.\n        data : numpy.array\n            Image data acquired with given snapshot settings using\n            TakeSnapshot() or TakeFastFrames().\n        redovergreen, blueovergreen : float\n            Red pixel value of the desired color divided by green value.\n            Blue pixel value of the desired color divided by green value.\n        startx, starty, width, height : int\n            Window coordinates after any subsampling or binning.\n\n        If the camera is in Fast Frames mode, this function will also update\n        the current color gains used for all subsequent snapshots.\n\n        \"\"\"\n        pdata = data.ctypes.data_as(API.pBYTE)\n        if not API.LucamAdjustWhiteBalanceFromSnapshot(\n                self._handle, snapshot, pdata, redovergreen, blueovergreen,\n                startx, starty, width, height):\n            raise LucamError(self)",
  "def OneShotAutoIris(self, target, startx, starty, width, height):\n        \"\"\"Perform one iteration of iris adjustment to reach target brightness.\n\n        Parameters\n        ----------\n        target : int\n            Target average brightness (0-255).\n        startx, starty, width, height : int\n            Window coordinates after any subsampling or binning.\n\n        \"\"\"\n        if not API.LucamOneShotAutoIris(self._handle, target,\n                                        startx, starty, width, height):\n            raise LucamError(self)",
  "def ContinuousAutoExposureEnable(self, target, startx, starty,\n                                     width, height, lightingperiod):\n        \"\"\"Undocumented function.\"\"\"\n        if not API.LucamContinuousAutoExposureEnable(\n                self._handle, target, startx, starty,\n                width, height, lightingperiod):\n            raise LucamError(self)",
  "def ContinuousAutoExposureDisable(self):\n        \"\"\"Undocumented function.\"\"\"\n        if not API.LucamContinuousAutoExposureDisable(self._handle):\n            raise LucamError(self)",
  "def LucamAutoFocusStart(self, startx, starty, width, height,\n                            callback=None, context=None):\n        \"\"\"Start auto focus calibration.\n\n        Parameters\n        ----------\n        startx, starty, width, height : int\n            Window coordinates after any subsampling or binning.\n        callback : function or None\n            API.ProgressCallback.\n            If provided, this function will be called periodically with\n            the current progress of the auto focus.\n        context : object\n            Will be passed to callback function.\n\n        \"\"\"\n        callback = API.ProgressCallback(callback if callback else 0)\n        if context is not None:\n            context = ctypes.py_object(context)\n        if not API.LucamAutoFocusStart(self._handle, startx, starty,\n                                       width, height, 0., 0., 0.,\n                                       callback, context):\n            raise LucamError(self)\n        self._callbacks[API.ProgressCallback] = callback",
  "def LucamAutoFocusWait(self, timeout):\n        \"\"\"Wait for completion of auto focus calibration.\n\n        Parameters\n        ----------\n        timeout : int\n            Duration the auto focus calibration will run before terminating\n            if the proper focus value is not found.\n\n        \"\"\"\n        if not API.LucamAutoFocusWait(self._handle, timeout):\n            raise LucamError(self)",
  "def LucamAutoFocusStop(self):\n        \"\"\"Stop auto focus calibration prematurely.\"\"\"\n        if not API.LucamAutoFocusStop(self._handle):\n            raise LucamError(self)",
  "def AutoFocusQueryProgress(self):\n        \"\"\"Return the status in % of the auto focus calibration.\n\n        Only available with cameras that can control a motorized lens.\n\n        \"\"\"\n        percentcomplete = API.FLOAT()\n        if not API.LucamAutoFocusQueryProgress(self._handle, percentcomplete):\n            raise LucamError(self)\n        return percentcomplete.value",
  "def InitAutoLens(self, force=False):\n        \"\"\"Initialize and calibrate camera lens focus and iris positions.\n\n        Parameters\n        ----------\n        force : bool\n            If True, force a recalibration of lens parameters.\n\n        \"\"\"\n        if not API.LucamInitAutoLens(self._handle):\n            raise LucamError(self)",
  "def PermanentBufferRead(self, offset=0, size=2048):\n        \"\"\"Return data read from user-defined non-volatile memory.\n\n        The non-volatile memory area is 2048 bytes long.\n\n        \"\"\"\n        assert 0 <= (size - offset) <= 2048\n        data = numpy.zeros((size,), numpy.uint8)\n        pdata = data.ctypes.data_as(API.pUCHAR)\n        if not API.LucamPermanentBufferRead(self._handle, pdata, offset, size):\n            raise LucamError(self)\n        return data",
  "def PermanentBufferWrite(self, data, offset=0):\n        \"\"\"Write data to user-defined non-volatile memory area.\n\n        The non-volatile memory area is 2048 bytes long and limited to\n        100,000 writes.\n\n        \"\"\"\n        data = numpy.array(data, numpy.uint8, copy=False)\n        pdata = data.ctypes.data_as(API.pUCHAR)\n        size = data.size\n        assert 0 <= (size - offset) <= 2048\n        if not API.LucamPermanentBufferWrite(self._handle, pdata,\n                                             offset, size):\n            raise LucamError(self)",
  "def GpioRead(self):\n        \"\"\"Return external header status from General Purpose IO register.\n\n        Return value of the output and input bits of the register.\n\n        \"\"\"\n        gpo = API.BYTE()\n        gpi = API.BYTE()\n        if not API.LucamGpioRead(self._handle, gpo, gpi):\n            raise LucamError(self)\n        return gpo.value, gpi.value",
  "def GpioWrite(self, gpovalues):\n        \"\"\"Write General Purpose IO register to trigger external header output.\n\n        Parameters\n        ----------\n        gpovalues : int\n            Value of the output bits of the register.\n\n        \"\"\"\n        if not API.LucamGpioWrite(self._handle, gpovalues):\n            raise LucamError(self)",
  "def GpoSelect(self, gpoenable):\n        \"\"\"Enable or disable alternate GPO functionality.\n\n        gpoenable : int\n            Bit flags used to enable/disable alternate functionality.\n\n        \"\"\"\n        if not API.LucamGpoSelect(self._handle, gpoenable):\n            raise LucamError(self)",
  "def GpioConfigure(self, enableoutput):\n        \"\"\"Configure direction of bi-directional GPIO pin.\n\n        Parameters\n        ----------\n        enableoutput : int\n            Bit flags used to disable or enable the output on a GPIO.\n            Bit values of 1 configure pin as output.\n            Bit values of 0 put the pin into input mode (default).\n\n        This function is only available on Lm-based cameras.\n\n        \"\"\"\n        if not API.LucamGpioConfigure(self._handle, enableoutput):\n            raise LucamError(self)",
  "def Rs232Transmit(self):\n        \"\"\"Undocumented function.\"\"\"\n        raise NotImplementedError()",
  "def Rs232Receive(self):\n        \"\"\"Undocumented function.\"\"\"\n        raise NotImplementedError()",
  "def AddRs232Callback(self):\n        \"\"\"Undocumented function.\"\"\"\n        raise NotImplementedError()",
  "def RemoveRs232Callback(self):\n        \"\"\"Undocumented function.\"\"\"\n        raise NotImplementedError()",
  "def __init__(self, arg=None):\n        \"\"\"Initialize LucamError instance.\n\n        Parameters\n        ----------\n        arg : int, Lucam instance, or None\n            If arg is None or a Lucam instance, the last error that occured\n            in the API is raised. Else arg is an error code number.\n\n        \"\"\"\n        if arg is None:\n            self.value = API.LucamGetLastError()\n        elif isinstance(arg, Lucam):\n            self.value = arg.GetLastErrorForCamera()\n        else:\n            self.value = int(arg)",
  "def __str__(self):\n        \"\"\"Return error message.\"\"\"\n        return self.CODES.get(self.value, \"Unknown error: %i\" % self.value)",
  "def __init__(self, cameras=None, settings=None):\n        \"\"\"Enable simultaneous snapshot capture mode.\n\n        Parameters\n        ----------\n        cameras : sequence of Lucam instances, or None.\n            If None (default), snapshots are taken from all connected cameras.\n        settings : sequence of API.LUCAM_SNAPSHOT, or None\n            Settings to use for the snapshot. If None (default), the settings\n            returned by Lucam.default_snapshot() will be used for each camera.\n\n        \"\"\"\n        if cameras is None:\n            cameras = [Lucam(i + 1) for i in range(len(LucamEnumCameras()))]\n        numcams = len(cameras)\n        phcameras = (API.HANDLE * numcams)()\n        ppsettings = (API.pLUCAM_SNAPSHOT * numcams)()\n        if settings is None:\n            settings = [cam.default_snapshot() for cam in cameras]\n        for i in range(numcams):\n            phcameras[i] = cameras[i]._handle\n            ppsettings[i] = ctypes.pointer(settings[i])\n        self._cameras = cameras\n        self._settings = settings\n        self._handle = API.LucamEnableSynchronousSnapshots(numcams, phcameras,\n                                                           ppsettings)\n        if not self._handle:\n            raise LucamError()",
  "def __del__(self):\n        \"\"\"Disable simultaneous snapshot capture mode.\"\"\"\n        if self._handle:\n            API.LucamDisableSynchronousSnapshots(self._handle)",
  "def Disable(self):\n        \"\"\"Disable simultaneous snapshot capture mode.\"\"\"\n        if not API.LucamDisableSynchronousSnapshots(self._handle):\n            raise LucamError()\n        self._handle = None",
  "def Take(self, out=None, validate=True):\n        \"\"\"Simultaneously take single image from several cameras.\n\n        Parameters\n        ----------\n        out : sequence of numpy arrays, or None\n            Output buffer. If None, a list of new numpy.arrays containing\n            the image data is returned. Else image data will be copied into\n            the output arrays.\n\n        \"\"\"\n        result = []\n        ppdata = (API.pBYTE * len(self._cameras))()\n        for i in range(len(self._cameras)):\n            data, pdata = ndarray(self._settings[i].format,\n                                  self._cameras[i]._byteorder,\n                                  out[i] if out else None, validate)\n            result.append(data)\n            ppdata[i] = pdata\n        if not API.LucamTakeSynchronousSnapshots(self._handle, ppdata):\n            raise LucamError()\n        if out is None:\n            return result",
  "def __init__(self, filename):\n        \"\"\"Open AVI file for previewing.\"\"\"\n        self._handle = API.LucamPreviewAVIOpen(filename)\n        if not self._handle:\n            raise LucamError()\n        self._filename = filename",
  "def __del__(self):\n        \"\"\"Close controller to AVI file if still open.\"\"\"\n        if self._handle:\n            API.LucamPreviewAVIClose(self._handle)",
  "def __str__(self):\n        \"\"\"Return information about AVI as string.\"\"\"\n        info = self.GetFormat()\n        fileformat = ('RAW_LUMENERA', 'STANDARD_24', 'STANDARD_32',\n                      'XVID_24', 'STANDARD_8')[info[2]]\n        return \"\\n* \".join((\n            \"\",\n            \"File name: %s\" % self._filename,\n            \"Type: %s\" % fileformat,\n            \"Width: %s\" % info[0],\n            \"Height: %s\" % info[1],\n            \"Bit depth: %s\" % info[3],\n            \"Frame rate: %s\" % self.GetFrameRate(),\n            \"Frame count: %s\" % self.GetFrameCount(),\n            \"Duration: %s:%s:%s:%s\" % self.GetDuration(),\n            \"Current frame: %s\" % self.GetPositionFrame(),\n            \"Current time: %s:%s:%s:%s\" % self.GetPositionTime()))",
  "def Close(self):\n        \"\"\"Close controller to AVI file.\"\"\"\n        if not API.LucamPreviewAVIClose(self._handle):\n            raise LucamError()\n        self._handle = None",
  "def Control(self, ctrltype, window=0):\n        \"\"\"Control previewing of AVI video.\n\n        Parameters\n        ----------\n        ctrltype : str or int\n            Control type. One of LucamPreviewAVI.CTRLTYPE keys or values.\n        window : int\n            Handle to the window to preview video to.\n\n        \"\"\"\n        ctrltype = LucamPreviewAVI.CTRLTYPE.get(ctrltype, ctrltype)\n        if not API.LucamPreviewAVIControl(self._handle, ctrltype, window):\n            raise LucamError()",
  "def GetDuration(self):\n        \"\"\"Return length of video.\"\"\"\n        minutes = API.LONGLONG()\n        seconds = API.LONGLONG()\n        millisecs = API.LONGLONG()\n        microsecs = API.LONGLONG()\n        if not API.LucamPreviewAVIGetDuration(self._handle, minutes, seconds,\n                                              millisecs, microsecs):\n            raise LucamError()\n        return minutes.value, seconds.value, millisecs.value, microsecs.value",
  "def GetFrameCount(self):\n        \"\"\"Return total number of frames within AVI file.\"\"\"\n        framecount = API.LONGLONG()\n        if not API.LucamPreviewAVIGetFrameCount(self._handle, framecount):\n            raise LucamError()\n        return framecount.value",
  "def GetFrameRate(self):\n        \"\"\"Return recorded frame rate of AVI file.\"\"\"\n        framerate = API.FLOAT()\n        if not API.LucamPreviewAVIGetFrameRate(self._handle, framerate):\n            raise LucamError()\n        return framerate.value",
  "def GetPositionTime(self):\n        \"\"\"Return current time based position within AVI file.\"\"\"\n        minutes = API.LONGLONG()\n        seconds = API.LONGLONG()\n        millisecs = API.LONGLONG()\n        microsecs = API.LONGLONG()\n        if not API.LucamPreviewAVIGetPositionTime(\n                self._handle, minutes, seconds, millisecs, microsecs):\n            raise LucamError()\n        return minutes.value, seconds.value, millisecs.value, microsecs.value",
  "def GetPositionFrame(self):\n        \"\"\"Return current frame based position within AVI file.\"\"\"\n        curframe = API.LONGLONG()\n        if not API.LucamPreviewAVIGetPositionFrame(self._handle, curframe):\n            raise LucamError()\n        return curframe.value",
  "def SetPositionTime(self, minutes, seconds, millisecs, microsecs):\n        \"\"\"Set current time based position within AVI file.\"\"\"\n        if not API.LucamPreviewAVISetPositionTime(\n                self._handle, minutes, seconds, millisecs, microsecs):\n            raise LucamError()",
  "def SetPositionFrame(self, framenumber):\n        \"\"\"Set current frame based position within AVI file.\"\"\"\n        if not API.LucamPreviewAVISetPositionFrame(self._handle, framenumber):\n            raise LucamError()",
  "def GetFormat(self):\n        \"\"\"Return AVI file information.\"\"\"\n        width = API.LONG()\n        height = API.LONG()\n        filetype = API.LONG()\n        bitdepth = API.LONG()\n        if not API.LucamPreviewAVIGetFormat(self._handle, width, height,\n                                            filetype, bitdepth):\n            raise LucamError()\n        return width.value, height.value, filetype.value, bitdepth.value",
  "class Version(ctypes.Union):\n        _fields_ = [('uint', ctypes.c_uint), ('byte', ctypes.c_ubyte * 4)]",
  "def snapshot_callback(context, data, size):\n        data[0] = 42\n        print((\"Snapshot callback function:\", context, data[:2], size))",
  "def streaming_callback(context, data, size):\n        data[0] = 42\n        print((\"Streaming callback function:\", context, data[:2], size))",
  "def __str__(self):\n            return print_structure(self)",
  "class X(ctypes.Union):\n            _fields_ = [('subSampleX', USHORT), ('binningX', USHORT)]",
  "class Y(ctypes.Union):\n            _fields_ = [('subSampleY', USHORT), ('binningY', USHORT)]",
  "def __str__(self):\n            return print_structure(self)",
  "class GAINS(ctypes.Union):\n            class RBGG(ctypes.Structure):\n                _fields_ = [\n                    ('gainRed', FLOAT),\n                    ('gainBlue', FLOAT),\n                    ('gainGrn1', FLOAT),\n                    ('gainGrn2', FLOAT)]\n\n            class MCYY(ctypes.Structure):\n                _fields_ = [\n                    ('gainMag', FLOAT),\n                    ('gainCyan', FLOAT),\n                    ('gainYel1', FLOAT),\n                    ('gainYel2', FLOAT)]\n\n            _anonymous_ = ['_rbgg', '_mcyy']\n            _fields_ = [('_rbgg', RBGG), ('_mcyy', MCYY)]",
  "class STROBE(ctypes.Union):\n            _fields_ = [('useStrobe', BOOL), ('strobeFlags', ULONG)]",
  "def __str__(self):\n            return print_structure(self)",
  "class GAINS(ctypes.Union):\n            class YUV(ctypes.Structure):\n                _fields_ = [\n                    ('DigitalGain', FLOAT),\n                    ('DigitalWhiteBalanceU', FLOAT),\n                    ('DigitalWhiteBalanceV', FLOAT)]\n\n            class RGB(ctypes.Structure):\n                _fields_ = [\n                    ('DigitalGainRed', FLOAT),\n                    ('DigitalGainGreen', FLOAT),\n                    ('DigitalGainBlue', FLOAT)]\n\n            _anonymous_ = ['_yuv', '_rgb']\n            _fields_ = [('_yuv', YUV), ('_rgb', RGB)]",
  "def __str__(self):\n            return print_structure(self)",
  "def __str__(self):\n            return print_structure(self)",
  "class RBGG(ctypes.Structure):\n                _fields_ = [\n                    ('gainRed', FLOAT),\n                    ('gainBlue', FLOAT),\n                    ('gainGrn1', FLOAT),\n                    ('gainGrn2', FLOAT)]",
  "class MCYY(ctypes.Structure):\n                _fields_ = [\n                    ('gainMag', FLOAT),\n                    ('gainCyan', FLOAT),\n                    ('gainYel1', FLOAT),\n                    ('gainYel2', FLOAT)]",
  "class YUV(ctypes.Structure):\n                _fields_ = [\n                    ('DigitalGain', FLOAT),\n                    ('DigitalWhiteBalanceU', FLOAT),\n                    ('DigitalWhiteBalanceV', FLOAT)]",
  "class RGB(ctypes.Structure):\n                _fields_ = [\n                    ('DigitalGainRed', FLOAT),\n                    ('DigitalGainGreen', FLOAT),\n                    ('DigitalGainBlue', FLOAT)]",
  "class CameraRoiScale(Camera):\n    \"\"\"\n    Camera with two main features:\n        - Scaled axes with whatever units the user wants. Subclasses may overwrite the pos_to_unit method, or provide\n        an array (x_axis or y_axis) as a lookup table.\n\n        - ROI selection using crosshairs. Subclasses should overwrite the roi method, e.g. to set ROI in the camera hardware\n\n    This class also handles binning, and keeps the scaled axes and ROI selection unaffected by the binning\n    \"\"\"\n    def __init__(self, crosshair_origin='top_left'):\n        super(CameraRoiScale, self).__init__()\n        self.axis_values = dict(bottom=None, left=None, top=None, right=None)\n        self.axis_units = dict(bottom=None, left=None, top=None, right=None)\n        self._roi = (0, 1000, 0, 1000)\n        self.detector_shape = (1000, 1000)\n        self.crosshair_origin = crosshair_origin\n\n    @property\n    def x_axis(self):\n        return self.axis_values['bottom']\n\n    @x_axis.setter\n    def x_axis(self, value):\n        self.axis_values['bottom'] = value\n\n    @property\n    def y_axis(self):\n        return self.axis_values['left']\n\n    @y_axis.setter\n    def y_axis(self, value):\n        self.axis_values['left'] = value\n\n    @property\n    def roi(self):\n        \"\"\"\n        If the camera supports setting a ROI in hardware, the user should overwrite this property\n\n        :return: 4-tuple of integers. Pixel positions xmin, xmax, ymin, ymax\n        \"\"\"\n        return self._roi\n\n    @roi.setter\n    def roi(self, value):\n        \"\"\"\n        By default, setting a ROI will make a filter function that indexes the frame to the given ROI.\n\n        :return: 4-tuple of integers. Pixel positions xmin, xmax, ymin, ymax\n        \"\"\"\n        self._roi = value\n        def fltr(img):\n            return img[self._roi[2]:self._roi[3], self._roi[0]:self._roi[1]]\n        setattr(self, 'filter_function', fltr)\n\n    @property\n    def gui_roi(self):\n        \"\"\"\n\n        :return: 4-tuple of integers. x, y positions of the two crosshairs in the preview widget\n        \"\"\"\n        assert len(self._preview_widgets) == 1\n        for wdg in self._preview_widgets:\n            lims = wdg.get_roi()\n            if lims is None: lims = (0,1,0,1)\n        return lims\n\n    @property\n    def binning(self):\n        \"\"\"\n        The binning property is passed to the display widgets to keep the scaling and units constant, independent of\n        binning.\n\n        By default, it is assumed the camera does not support binning, so the property returns (1, 1) and has no setter.\n        A subclass should overwrite this if the camera supports binnig\n        :return:\n        \"\"\"\n        return 1, 1\n\n    def update_widgets(self):\n        \"\"\"\n        Setting the position, scale, axis values and units, and crosshair sizes of the _preview_widgets\n        :return:\n        \"\"\"\n        if self._preview_widgets is not None:\n            for widgt in self._preview_widgets:\n                if isinstance(widgt, DisplayWidgetRoiScale):\n                    # Set the position of the updated image\n                    roi = self.roi\n                    widgt._pxl_offset = (roi[0], roi[2])\n                    # Set the scaling\n                    widgt._pxl_scale = self.binning\n                    # Set the axes values and units\n                    widgt.axis_values = self.axis_values\n                    widgt.axis_units = self.axis_units\n                    widgt.x_axis = self.x_axis\n                    widgt.y_axis = self.y_axis\n                    if not self.live_view:  # not sure why it doesn't work in live view\n                        widgt.update_axes()\n                    widgt.crosshair_moved()\n\n                    # Resize the crosshairs, so that they are always 1/40th of the total size of the image, but never\n                    # less than 5 pixels\n                    size = max(((roi[1] - roi[0])/40., (roi[3]-roi[2])/40., 5))\n                    for idx in [1, 2]:\n                        xhair = getattr(widgt, 'CrossHair%d' % idx)\n                        xhair._size = size\n                        if self.crosshair_origin == 'top_left':\n                            xhair._origin = [0, 0]\n                        elif self.crosshair_origin == 'top_right':\n                            xhair._origin = [self.detector_shape[0], 0]\n                        elif self.crosshair_origin == 'bottom_left':\n                            xhair._origin = [0, self.detector_shape[1]]\n                        elif self.crosshair_origin == 'top_right':\n                            xhair._origin = [self.detector_shape[0], self.detector_shape[1]]\n                        else:\n                            self._logger.info('Not recognised: crosshair_origin = %s. Needs to be top_left, top_right, '\n                                              'bottom_left or bottom_right' % self.crosshair_origin)\n                        xhair.update()\n\n        super(CameraRoiScale, self).update_widgets()\n\n    def get_preview_widget(self):\n        self._logger.debug('Getting preview widget')\n        if self._preview_widgets is None:\n            self._preview_widgets = WeakSet()\n        new_widget = DisplayWidgetRoiScale()\n        self._preview_widgets.add(new_widget)\n\n        return new_widget",
  "class DisplayWidgetRoiScale(ExtendedImageView):\n    _max_num_line_plots = 4\n    update_data_signal = QtCore.Signal(np.ndarray)\n\n    def __init__(self, scale=(1, 1), offset=(0, 0)):\n        super(DisplayWidgetRoiScale, self).__init__()\n\n        self._pxl_scale = scale\n        self._pxl_offset = offset\n\n        self.LineDisplay = self.ui.roiPlot#creates a PlotWidget instance\n        self.LineDisplay.showGrid(x=True, y=True)\n        self.ui.splitter.setHandleWidth(10)\n        self.getHistogramWidget().gradient.restoreState(list(Gradients.values())[1])\n        self.imageItem.setTransform(QtGui.QTransform())\n        self.LineDisplay.show()\n\n        self.plot = ()\n        for ii in range(self._max_num_line_plots):\n            self.plot += (self.LineDisplay.plot(pen=pyqtgraph.intColor(ii, self._max_num_line_plots)),)\n\n        self.toggle_displays()\n\n        self.checkbox_autorange = QtWidgets.QCheckBox('Autorange')\n        self.tools.gridLayout.addWidget(self.checkbox_autorange, 0, 3, 1, 1)\n\n        self.update_data_signal.connect(self._update_image, type=QtCore.Qt.QueuedConnection)\n\n    @property\n    def x_axis(self):\n        \"\"\"Convenience wrapper for integration with spectrometer code\"\"\"\n        return self.axis_values['bottom']\n\n    @x_axis.setter\n    def x_axis(self, value):\n        self.axis_values['bottom'] = value\n\n    @property\n    def y_axis(self):\n        \"\"\"Convenience wrapper for integration with spectrometer code\"\"\"\n        return self.axis_values['left']\n\n    @y_axis.setter\n    def y_axis(self, value):\n        self.axis_values['left'] = value\n\n    def update_axes(self):\n        gui_axes = self.get_axes()\n        for ax, name in zip(gui_axes, [\"bottom\", \"left\", \"top\", \"right\"]):\n            if self.axis_values[name] is not None:\n                setattr(ax, 'axis_values', self.axis_values[name])\n            if self.axis_units[name] is not None:\n                ax.setLabel(self.axis_units[name])\n\n        # This is kept in case subclasses overwrite the x_axis or y_axis properties\n        for ax, value in zip(gui_axes[:2], [self.x_axis, self.y_axis]):\n            if value is not None:\n                setattr(ax, 'axis_values', value)\n\n    def toggle_displays(self, boolean=False):\n        \"\"\"Toggle between an Image display and a Plot widget for Line displays\n\n        :param boolean: if True, display lines. If False, display images\n        :return:\n        \"\"\"\n        if boolean:\n            self.LineDisplay.show()\n            self.LineDisplay.showAxis('left')\n            self.LineDisplay.setMouseEnabled(True, True)\n            self.ui.splitter.setSizes([0, self.height()-35, 35])\n        else:\n            self.ui.splitter.setSizes([self.height()-35, 0, 35])\n\n    def _update_image(self, newimage):\n        scale = self._pxl_scale\n        offset = self._pxl_offset\n\n        if len(newimage.shape) == 1:\n            self.toggle_displays(True)\n            self.plot[0].setData(x=self.x_axis, y=newimage)\n        elif len(newimage.shape) == 2 and newimage.shape[0] < self._max_num_line_plots:\n            self.toggle_displays(True)\n            for ii, ydata in enumerate(newimage):\n                self.plot[ii].setData(x=self.x_axis, y=ydata)\n        else:\n            self.toggle_displays(False)\n            self.setImage(newimage.astype(float),\n                          pos=offset,\n                          autoRange=self.checkbox_autorange.isChecked(),\n                          scale=scale)\n\n    def update_image(self, newimage):\n        self.update_data_signal.emit(newimage)",
  "class DummyCameraRoiScale(CameraRoiScale):\n    \"\"\"A Dummy CameraRoiScale camera  \"\"\"\n\n    def __init__(self, data='spectrum'):\n        super(DummyCameraRoiScale, self).__init__()\n        self.data_type = data\n\n    def raw_snapshot(self, update_latest_frame=True):\n        \"\"\"Returns a True, stating a succesful snapshot, followed by a (100,100)\n        picture randomly generated image\"\"\"\n        if self.data_type == 'spectrum':\n            ran = 100 * ArrayWithAttrs(np.random.random(1600))\n        elif self.data_type == 'color_time':\n            ran = 100 * np.array([np.random.random((200, 1600, 3)) * x for x in np.arange(1, 11)])\n        elif self.data_type == 'time':\n            ran = 100 * np.array([np.random.random((200, 1600, 3)) * x for x in np.arange(1, 11)])\n        elif self.data_type == 'image':\n            ran = 100 * np.random.random((200, 1600))\n        elif self.data_type == 'color':\n            ran = 100 * np.random.random((200, 1600, 3))\n        else:\n            raise NotImplementedError\n        self._latest_raw_frame = ran\n        return True, ran\n\n    @property\n    def x_axis(self):\n        return np.arange(1600) + 1\n\n    @x_axis.setter\n    def x_axis(self, value):\n        self.axis_values['bottom'] = value",
  "def __init__(self, crosshair_origin='top_left'):\n        super(CameraRoiScale, self).__init__()\n        self.axis_values = dict(bottom=None, left=None, top=None, right=None)\n        self.axis_units = dict(bottom=None, left=None, top=None, right=None)\n        self._roi = (0, 1000, 0, 1000)\n        self.detector_shape = (1000, 1000)\n        self.crosshair_origin = crosshair_origin",
  "def x_axis(self):\n        return self.axis_values['bottom']",
  "def x_axis(self, value):\n        self.axis_values['bottom'] = value",
  "def y_axis(self):\n        return self.axis_values['left']",
  "def y_axis(self, value):\n        self.axis_values['left'] = value",
  "def roi(self):\n        \"\"\"\n        If the camera supports setting a ROI in hardware, the user should overwrite this property\n\n        :return: 4-tuple of integers. Pixel positions xmin, xmax, ymin, ymax\n        \"\"\"\n        return self._roi",
  "def roi(self, value):\n        \"\"\"\n        By default, setting a ROI will make a filter function that indexes the frame to the given ROI.\n\n        :return: 4-tuple of integers. Pixel positions xmin, xmax, ymin, ymax\n        \"\"\"\n        self._roi = value\n        def fltr(img):\n            return img[self._roi[2]:self._roi[3], self._roi[0]:self._roi[1]]\n        setattr(self, 'filter_function', fltr)",
  "def gui_roi(self):\n        \"\"\"\n\n        :return: 4-tuple of integers. x, y positions of the two crosshairs in the preview widget\n        \"\"\"\n        assert len(self._preview_widgets) == 1\n        for wdg in self._preview_widgets:\n            lims = wdg.get_roi()\n            if lims is None: lims = (0,1,0,1)\n        return lims",
  "def binning(self):\n        \"\"\"\n        The binning property is passed to the display widgets to keep the scaling and units constant, independent of\n        binning.\n\n        By default, it is assumed the camera does not support binning, so the property returns (1, 1) and has no setter.\n        A subclass should overwrite this if the camera supports binnig\n        :return:\n        \"\"\"\n        return 1, 1",
  "def update_widgets(self):\n        \"\"\"\n        Setting the position, scale, axis values and units, and crosshair sizes of the _preview_widgets\n        :return:\n        \"\"\"\n        if self._preview_widgets is not None:\n            for widgt in self._preview_widgets:\n                if isinstance(widgt, DisplayWidgetRoiScale):\n                    # Set the position of the updated image\n                    roi = self.roi\n                    widgt._pxl_offset = (roi[0], roi[2])\n                    # Set the scaling\n                    widgt._pxl_scale = self.binning\n                    # Set the axes values and units\n                    widgt.axis_values = self.axis_values\n                    widgt.axis_units = self.axis_units\n                    widgt.x_axis = self.x_axis\n                    widgt.y_axis = self.y_axis\n                    if not self.live_view:  # not sure why it doesn't work in live view\n                        widgt.update_axes()\n                    widgt.crosshair_moved()\n\n                    # Resize the crosshairs, so that they are always 1/40th of the total size of the image, but never\n                    # less than 5 pixels\n                    size = max(((roi[1] - roi[0])/40., (roi[3]-roi[2])/40., 5))\n                    for idx in [1, 2]:\n                        xhair = getattr(widgt, 'CrossHair%d' % idx)\n                        xhair._size = size\n                        if self.crosshair_origin == 'top_left':\n                            xhair._origin = [0, 0]\n                        elif self.crosshair_origin == 'top_right':\n                            xhair._origin = [self.detector_shape[0], 0]\n                        elif self.crosshair_origin == 'bottom_left':\n                            xhair._origin = [0, self.detector_shape[1]]\n                        elif self.crosshair_origin == 'top_right':\n                            xhair._origin = [self.detector_shape[0], self.detector_shape[1]]\n                        else:\n                            self._logger.info('Not recognised: crosshair_origin = %s. Needs to be top_left, top_right, '\n                                              'bottom_left or bottom_right' % self.crosshair_origin)\n                        xhair.update()\n\n        super(CameraRoiScale, self).update_widgets()",
  "def get_preview_widget(self):\n        self._logger.debug('Getting preview widget')\n        if self._preview_widgets is None:\n            self._preview_widgets = WeakSet()\n        new_widget = DisplayWidgetRoiScale()\n        self._preview_widgets.add(new_widget)\n\n        return new_widget",
  "def __init__(self, scale=(1, 1), offset=(0, 0)):\n        super(DisplayWidgetRoiScale, self).__init__()\n\n        self._pxl_scale = scale\n        self._pxl_offset = offset\n\n        self.LineDisplay = self.ui.roiPlot#creates a PlotWidget instance\n        self.LineDisplay.showGrid(x=True, y=True)\n        self.ui.splitter.setHandleWidth(10)\n        self.getHistogramWidget().gradient.restoreState(list(Gradients.values())[1])\n        self.imageItem.setTransform(QtGui.QTransform())\n        self.LineDisplay.show()\n\n        self.plot = ()\n        for ii in range(self._max_num_line_plots):\n            self.plot += (self.LineDisplay.plot(pen=pyqtgraph.intColor(ii, self._max_num_line_plots)),)\n\n        self.toggle_displays()\n\n        self.checkbox_autorange = QtWidgets.QCheckBox('Autorange')\n        self.tools.gridLayout.addWidget(self.checkbox_autorange, 0, 3, 1, 1)\n\n        self.update_data_signal.connect(self._update_image, type=QtCore.Qt.QueuedConnection)",
  "def x_axis(self):\n        \"\"\"Convenience wrapper for integration with spectrometer code\"\"\"\n        return self.axis_values['bottom']",
  "def x_axis(self, value):\n        self.axis_values['bottom'] = value",
  "def y_axis(self):\n        \"\"\"Convenience wrapper for integration with spectrometer code\"\"\"\n        return self.axis_values['left']",
  "def y_axis(self, value):\n        self.axis_values['left'] = value",
  "def update_axes(self):\n        gui_axes = self.get_axes()\n        for ax, name in zip(gui_axes, [\"bottom\", \"left\", \"top\", \"right\"]):\n            if self.axis_values[name] is not None:\n                setattr(ax, 'axis_values', self.axis_values[name])\n            if self.axis_units[name] is not None:\n                ax.setLabel(self.axis_units[name])\n\n        # This is kept in case subclasses overwrite the x_axis or y_axis properties\n        for ax, value in zip(gui_axes[:2], [self.x_axis, self.y_axis]):\n            if value is not None:\n                setattr(ax, 'axis_values', value)",
  "def toggle_displays(self, boolean=False):\n        \"\"\"Toggle between an Image display and a Plot widget for Line displays\n\n        :param boolean: if True, display lines. If False, display images\n        :return:\n        \"\"\"\n        if boolean:\n            self.LineDisplay.show()\n            self.LineDisplay.showAxis('left')\n            self.LineDisplay.setMouseEnabled(True, True)\n            self.ui.splitter.setSizes([0, self.height()-35, 35])\n        else:\n            self.ui.splitter.setSizes([self.height()-35, 0, 35])",
  "def _update_image(self, newimage):\n        scale = self._pxl_scale\n        offset = self._pxl_offset\n\n        if len(newimage.shape) == 1:\n            self.toggle_displays(True)\n            self.plot[0].setData(x=self.x_axis, y=newimage)\n        elif len(newimage.shape) == 2 and newimage.shape[0] < self._max_num_line_plots:\n            self.toggle_displays(True)\n            for ii, ydata in enumerate(newimage):\n                self.plot[ii].setData(x=self.x_axis, y=ydata)\n        else:\n            self.toggle_displays(False)\n            self.setImage(newimage.astype(float),\n                          pos=offset,\n                          autoRange=self.checkbox_autorange.isChecked(),\n                          scale=scale)",
  "def update_image(self, newimage):\n        self.update_data_signal.emit(newimage)",
  "def __init__(self, data='spectrum'):\n        super(DummyCameraRoiScale, self).__init__()\n        self.data_type = data",
  "def raw_snapshot(self, update_latest_frame=True):\n        \"\"\"Returns a True, stating a succesful snapshot, followed by a (100,100)\n        picture randomly generated image\"\"\"\n        if self.data_type == 'spectrum':\n            ran = 100 * ArrayWithAttrs(np.random.random(1600))\n        elif self.data_type == 'color_time':\n            ran = 100 * np.array([np.random.random((200, 1600, 3)) * x for x in np.arange(1, 11)])\n        elif self.data_type == 'time':\n            ran = 100 * np.array([np.random.random((200, 1600, 3)) * x for x in np.arange(1, 11)])\n        elif self.data_type == 'image':\n            ran = 100 * np.random.random((200, 1600))\n        elif self.data_type == 'color':\n            ran = 100 * np.random.random((200, 1600, 3))\n        else:\n            raise NotImplementedError\n        self._latest_raw_frame = ran\n        return True, ran",
  "def x_axis(self):\n        return np.arange(1600) + 1",
  "def x_axis(self, value):\n        self.axis_values['bottom'] = value",
  "def fltr(img):\n            return img[self._roi[2]:self._roi[3], self._roi[0]:self._roi[1]]",
  "class CameraParameter(NotifiedProperty):\n    \"\"\"A quick way of creating a property that alters a camera parameter.\n    \n    The majority of cameras have some sort of mechanism for setting parameters\n    like gain, integration time, etc. etc. that involves calling an API\n    function that takes the property name as an argument.  This is a way\n    of nicely wrapping up the boilerplate code so that these properties map\n    onto properties of the camera object.\n    \n    NB the property will be read immediately after it's written, to ensure\n    that the value we send to any listening controls/indicators is correct\n    (otherwise we'd send them the value that was requested, even if it was\n    not valid).  This behaviour can be disabled by setting read_back to False\n    in the constructor.\n    \"\"\"\n    def __init__(self, parameter_name, doc=None, read_back=True):\n        \"\"\"Create a property that reads and writes the given parameter.\n        \n        This internally uses the `get_camera_parameter` and \n        `set_camera_parameter` methods, so make sure you override them.\n        \"\"\"\n        if doc is None:\n            doc = \"Adjust the camera parameter '{0}'\".format(parameter_name)\n        super(CameraParameter, self).__init__(fget=self.fget, \n                                                      fset=self.fset, \n                                                      doc=doc,\n                                                      read_back=read_back)\n        self.parameter_name = parameter_name\n        \n    def fget(self, obj):\n        return obj.get_camera_parameter(self.parameter_name)\n            \n    def fset(self, obj, value):\n        obj.set_camera_parameter(self.parameter_name, value)",
  "class Camera(Instrument):\n    \"\"\"Generic class for representing cameras.\n    \n    This should always be subclassed in order to make a useful instrument.\n    \n    The minimum you should do is alter raw_snapshot to acquire and return a\n    frame from the camera.  All other acquisition functions can come from that.\n    If your camera also supports video streaming (for live view, for example)\n    you should override     \n    \"\"\"\n    \n    video_priority = DumbNotifiedProperty(False)\n    filename = DumbNotifiedProperty('snapshot_%d')\n    \"\"\"Set video_priority to True to avoid disturbing the video stream when\n    taking images.  raw_snapshot may ignore the setting, but get_image and by\n    extension rgb_image and gray_image will honour it.\"\"\"\n    \n    parameters = None\n    \n    filter_function = None \n    \"\"\"This function is run on the image before it's displayed in live view.  \n    It should accept, and return, an RGB image as its argument.\"\"\"\n    \n    def __init__(self):\n        super(Camera,self).__init__()\n        self.acquisition_lock = threading.Lock()    \n        self._latest_frame_update_condition = threading.Condition()\n        self._live_view = False\n        self._frame_counter = 0\n        # Ensure camera parameters get saved in the metadata.  You may want to override this in subclasses\n        # to remove junk (e.g. if some of the parameters are meaningless)\n#        self.metadata_property_names = self.metadata_property_names + tuple(self.camera_parameter_names())\n        self.metadata_property_names = tuple(self.metadata_property_names) + tuple(self.camera_parameter_names())\n #       self.filename = 'snapshot_%d'\n\n    def __del__(self):\n        self.close()\n#        super(Camera,self).__del__() #apparently not...?\n    def close(self):\n        \"\"\"Stop communication with the camera and allow it to be re-used.\n        \n        override in subclass if you want to shut down hardware.\"\"\"\n        self.live_view = False\n        \n    \n    def get_next_frame(self, timeout=60, discard_frames=0, \n                       assert_live_view=True, raw=True):\n        \"\"\"Wait for the next frame to arrive and return it.\n        \n        This function is mostly intended for acquiring frames from a video\n        stream that's running in live view - it returns a fresh frame without\n        interrupting the video.  If called with timeout=None when live view is\n        false, it may take a very long time to return.\n        \n        @param: timeout: Maximum length of time to wait for a new frame.  None\n        waits forever, but this may be a bad idea (could hang your script).\n        @param: discard_frames: Wait for this many new frames before returning\n        one.  This option is useful if the camera buffers frames, so you must\n        wait for several frames to be acquired before getting a \"fresh\" one.\n        The default setting of 0 means the first new frame that arrives is\n        returned.\n        @param: assert_live_view: If True (default) raise an assertion error if\n        live view is not enabled - this function is intended only to be used\n        when that is the case.\n        @param: raw: The default (True) returns a raw frame - False returns the\n        frame after processing by the filter function if any.\n        \"\"\"\n        if assert_live_view:\n            assert self.live_view, \"\"\"Can't wait for the next frame if live view is not enabled!\"\"\"\n        with self._latest_frame_update_condition:\n            # We use the Condition object to block until a new frame appears\n            # However we need to check that a new frame has actually been taken\n            # so we use the frame counter.\n            # NB the current implementation may be vulnerable to dropped frames\n            # which will probably cause a timeout error.\n            # Checking for frame_counter being >= target_frame is vulnerable to\n            # overflow.\n            target_frame = self._frame_counter + 1 + discard_frames\n            expiry_time = time.time() + timeout\n            while self._frame_counter != target_frame and time.time() < expiry_time:\n                self._latest_frame_update_condition.wait(timeout) #wait for a new frame\n            if time.time() >= expiry_time:\n                raise IOError(\"Timed out waiting for a fresh frame from the video stream.\")\n            if raw:\n                return self.latest_raw_frame\n            else:\n                return self.latest_frame\n        \n    def raw_snapshot(self):\n        \"\"\"Take a snapshot and return it.  No filtering or conversion.\"\"\"\n        raise NotImplementedError(\"Cameras must subclass raw_snapshot!\")\n        return True, np.zeros((640,480,3),dtype=np.uint8)\n        \n    def get_image(self):\n        print(\"Warning: get_image is deprecated, use raw_image() instead.\")\n        return self.raw_image()\n        \n    def raw_image(self, bundle_metadata=False, update_latest_frame=False):\n        \"\"\"Take an image from the camera, respecting video priority.\n        \n        If live view is enabled and video_priority is true, return the next\n        frame in the video stream.  Otherwise, return a specially-acquired\n        image from raw_snapshot.\n        \"\"\"\n        frame = None\n        if self.live_view and self.video_priority:\n            frame = self.get_next_frame(raw=True)\n        else:\n            status, frame = self.raw_snapshot()\n        if update_latest_frame:\n            self.latest_raw_frame = frame\n        # return it as an ArrayWithAttrs including self.metadata, if requested\n        return self.bundle_metadata(frame, bundle_metadata)\n            \n    def color_image(self, **kwargs):\n        \"\"\"Get a colour image (bypass filtering, etc.)\n        \n        Additional keyword arguments are passed to raw_image.\"\"\"\n        frame = self.raw_image(**kwargs)\n        try:\n            assert frame.shape[2]==3\n            return frame\n        except:\n            try:\n                assert len(frame.shape)==2\n                gray_frame = np.vstack((frame,)*3) #turn gray into color by duplicating!\n                if hasattr(frame, \"attrs\"):\n                    return ArrayWithAttrs(gray_frame, attrs=frame.attrs)\n                else:\n                    return gray_frame\n            except:\n                raise Exception(\"Couldn't convert the camera's raw image to colour.\")\n        \n    def gray_image(self, **kwargs):\n        \"\"\"Get a colour image (bypass filtering, etc.)\n        \n        Additional keyword arguments are passed to raw_image.\"\"\"\n        frame = self.raw_image(**kwargs)\n        try:\n            assert len(frame.shape)==2\n            return frame\n        except:\n            try:\n                assert frame.shape[2]==3\n                return np.mean(frame, axis=2, dtype=frame.dtype)\n            except:\n                raise Exception(\"Couldn't convert the camera's raw image to grayscale.\")\n                \n    def save_raw_image(self, update_latest_frame=True, attrs={}):\n        \"\"\"Save an image to the default place in the default HDF5 file.\"\"\"\n        d=self.create_dataset(self.filename, \n                              data=self.raw_image(\n                                  bundle_metadata=True,\n                                  update_latest_frame=update_latest_frame))\n        d.attrs.update(attrs)\n    \n    _latest_raw_frame = None\n    @NotifiedProperty\n    def latest_raw_frame(self):\n        \"\"\"The last frame acquired by the camera.  \n        \n        This property is particularly useful when\n        live_view is enabled.  This is before processing by any filter function\n        that may be in effect.  May be NxMx3 or NxM for monochrome.  To get a\n        fresh frame, use raw_image().  Setting this property will update any\n        preview widgets that are in use.\"\"\"\n        return self._latest_raw_frame\n    @latest_raw_frame.setter\n    def latest_raw_frame(self, frame):\n        \"\"\"Set the latest raw frame, and update the preview widget if any.\"\"\"\n        with self._latest_frame_update_condition:\n            self._latest_raw_frame = frame\n            self._frame_counter += 1\n            self._latest_frame_update_condition.notify_all()\n        \n        # TODO: use the NotifiedProperty to do this with less code?\n        self.update_widgets()\n    \n    def update_widgets(self):\n        \"\"\"Iterates over the preview widgets and updates them. It's a good method to override in subclasses\"\"\"\n        if self._preview_widgets is not None:\n            for w in self._preview_widgets:\n                try:\n                    w.update_image(self.latest_frame)\n                except Exception as e:\n                    print(\"something went wrong updating the preview widget\")\n                    print(e)\n\n    @property\n    def latest_frame(self):\n        \"\"\"The last frame acquired (in live view/from GUI), after filtering.\"\"\"\n        if self.filter_function is not None:\n            return self.filter_function(self.latest_raw_frame)\n        else:\n            return self.latest_raw_frame\n    \n    \n    def update_latest_frame(self, frame=None):\n        \"\"\"Take a new frame and store it as the \"latest frame\"\n        \n        Returns the image as displayed, including filters, etc.\n        This should rarely be used - raw_image, color_image and gray_image are\n        the preferred way of acquiring data.  If you supply an image, it will\n        use that image as if it was the most recent colour image to be \n        acquired.\n        \n        Unless you need the filtered image, you should probably use \n        raw_image, color_image or gray_image.\n        \"\"\"\n        if frame is None: \n            frame = self.color_image()\n        if frame is not None:\n            self.latest_raw_frame = frame\n            \n            return self.latest_frame\n        else:\n            print(\"Failed to get an image from the camera\")    \n    \n    def camera_parameter_names(self):\n        \"\"\"Return a list of names of parameters that may be set/read.\n        \n        This will list the names of all the members of this class that are \n        `CameraParameter`s - you should define one of these for each of the \n        properties of the camera you'd like to expose.\n        \n        If you need to support dynamic properties, I suggest you use a class\n        factory, and add CameraParameters at runtime.  You could do this from\n        within the class, but that's a courageous move.\n        \n        If you need more sophisticated control, I suggest subclassing\n        `CameraParameter`, though I can't currently see how that would help...\n        \"\"\"\n        # first, identify all the CameraParameter properties we've got\n        p_list = []\n        for p in dir(self.__class__):\n            try:\n                if isinstance(getattr(self.__class__, p), CameraParameter):\n                    getattr(self,p)\n                    p_list.append(p)\n            except:\n                try:\n                    delattr(self.__class__,p)\n                except:\n                    pass\n                pass\n        return p_list\n   #     return [p for p in dir(self.__class__)\n    #              if isinstance(getattr(self.__class__, p), CameraParameter)]\n    \n    def get_camera_parameter(self, parameter_name):\n        \"\"\"Return the named property from the camera\"\"\"\n        raise NotImplementedError(\"You must override get_camera_parameter to use it\")\n    def set_camera_parameter(self, parameter_name, value):\n        \"\"\"Return the named property from the camera\"\"\"\n        raise NotImplementedError(\"You must override set_camera_parameter to use it\")\n    \n    _live_view = False\n    @NotifiedProperty\n    def live_view(self):\n        \"\"\"Whether the camera is currently streaming and displaying video\"\"\"\n        return self._live_view\n    @live_view.setter\n    def live_view(self, live_view):\n        \"\"\"Turn live view on and off.\n        \n        This is used to start and stop streaming of the camera feed.  The\n        default implementation just repeatedly takes snapshots, but subclasses\n        are encouraged to override that behaviour by starting/stopping a stream\n        and using a callback function to update self.latest_raw_frame.\"\"\"\n        if live_view==True:\n            if self._live_view:\n                return # do nothing if it's going already.\n            print(\"starting live view thread\")\n            try:\n                self._frame_counter = 0\n                self._live_view_stop_event = threading.Event()\n                self._live_view_thread = threading.Thread(target=self._live_view_function)\n                self._live_view_thread.start()\n                self._live_view = True\n            except AttributeError as e: #if any of the attributes aren't there\n                print(\"Error:\", e)\n        else:\n            if not self._live_view:\n                return # do nothing if it's not running.\n            print(\"stopping live view thread\")\n            try:\n                self._live_view_stop_event.set()\n                self._live_view_thread.join()\n                del(self._live_view_stop_event, self._live_view_thread)\n                self._live_view = False\n            except AttributeError:\n                raise Exception(\"Tried to stop live view but it doesn't appear to be running!\")\n    def _live_view_function(self):\n        \"\"\"This function should only EVER be executed by _live_view_changed.\n        \n        Loop until the event tells us to stop, constantly taking snapshots.\n        Ideally you should override live_view to start and stop streaming\n        from the camera, using a callback function to update latest_raw_frame.\n        \"\"\"\n        while not self._live_view_stop_event.wait(timeout=0.1):\n            success, frame = self.raw_snapshot()\n            if success:\n                self.update_latest_frame(frame)\n            \n    legacy_click_callback = None\n    def set_legacy_click_callback(self, function):\n        \"\"\"Set a function to be called when the image is clicked.\n        \n        Warning: this is only for compatibility with old code and will be removed\n        once camera_stage_mapper is updated!\n        \"\"\"\n        self.legacy_click_callback = function\n        if self._preview_widgets is not None:\n            for w in self._preview_widgets:\n                w.add_legacy_click_callback(self.legacy_click_callback)\n            \n    _preview_widgets = None\n    def get_preview_widget(self):\n        \"\"\"A Qt Widget that can be used as a viewfinder for the camera.\n        \n        In live mode, this is continuously updated.  It's also updated whenever\n        a snapshot is taken using update_latest_frame.  Currently this returns\n        a single widget instance - in future it might be able to generate (and\n        keep updated) multiple widgets.\"\"\"\n        if self._preview_widgets is None:\n            self._preview_widgets = WeakSet()\n        new_widget = CameraPreviewWidget()\n        self._preview_widgets.add(new_widget)\n        if self.legacy_click_callback is not None:\n            new_widget.add_legacy_click_callback(self.legacy_click_callback)\n        return new_widget\n    \n    def get_control_widget(self):\n        \"\"\"Return a widget that contains the camera controls but no image.\"\"\"\n        return CameraControlWidget(self)\n        \n    def get_parameters_widget(self):\n        \"\"\"Return a widget that controls the camera's settings.\"\"\"\n        return CameraParametersWidget(self)\n        \n    def get_qt_ui(self, control_only=False, parameters_only=False):\n        \"\"\"Create a QWidget that controls the camera.\n        \n        Specifying control_only=True returns just the controls for the camera.\n        Otherwise, you get both the controls and a preview window.\n        \"\"\"\n        if control_only:\n            return self.get_control_widget()\n        elif parameters_only:\n            return self.get_parameters_widget(self)\n        else:\n            return CameraUI(self)",
  "class CameraUI(QtWidgets.QWidget):\n    \"\"\"Generic user interface for a camera.\"\"\"\n    def __init__(self, camera):\n        assert isinstance(camera, Camera), \"instrument must be a Camera\"\n        #TODO: better checking (e.g. assert camera has color_image, gray_image methods)\n        super(CameraUI, self).__init__()\n        self.camera=camera\n        \n        # Set up the UI        \n        self.setWindowTitle(self.camera.__class__.__name__)\n        layout = QtWidgets.QVBoxLayout()\n        # The image display goes at the top of the window\n        self.preview_widget = self.camera.get_preview_widget()\n        layout.addWidget(self.preview_widget)\n        # The controls go in a layout, inside a group box.\n        self.controls = self.camera.get_control_widget()\n        layout.addWidget(self.controls)\n        #layout.setContentsMargins(5,5,5,5)\n        layout.setSpacing(5)\n        self.setLayout(layout)",
  "class CameraControlWidget(QtWidgets.QWidget, UiTools):\n    \"\"\"Controls for a camera (these are the really generic ones)\"\"\"\n    def __init__(self, camera, auto_connect=True):\n        assert isinstance(camera, Camera), \"instrument must be a Camera\"\n        #TODO: better checking (e.g. assert camera has color_image, gray_image methods)\n        super(CameraControlWidget, self).__init__()\n        self.camera=camera\n        self.load_ui_from_file(__file__,\"camera_controls_generic.ui\")\n        if auto_connect==True:\n            self.auto_connect_by_name(controlled_object=self.camera, verbose=False)\n        \n    def snapshot(self):\n        \"\"\"Take a new snapshot and display it.\"\"\"\n        self.camera.raw_image(update_latest_frame=True)\n    \n    def save_to_data_file(self):\n        self.camera.save_raw_image(\n            attrs={'description':self.description_lineedit.text()})\n        \n    def save_jpeg(self):\n        cur_img = self.camera.color_image()\n        fname, _ = QtWidgets.QFileDialog.getSaveFileName(\n                                caption = \"Select JPEG filename\",\n                                directory = os.path.join(os.getcwd(),datetime.date.today().strftime(\"%Y-%m-%d.jpg\")),\n                                filter = \"Images (*.jpg *.jpeg)\",\n                            )\n        j = Image.fromarray(cur_img)\n        j.save(fname)\n        \n    def edit_camera_parameters(self):\n        \"\"\"Pop up a camera parameters dialog box.\"\"\"\n        self.camera_parameters_widget = self.camera.get_parameters_widget()\n        self.camera_parameters_widget.show()\n        \n    description = DumbNotifiedProperty(\"Description...\")\n        \n    def __del__(self):\n        pass",
  "class CameraParametersTableModel(QtCore.QAbstractTableModel):\n    \"\"\"Class to manage a Qt table of a camera's parameters.\n    \n    With thanks to http://stackoverflow.com/questions/11736560/edit-table-in-\n    pyqt-using-qabstracttablemodel\"\"\"\n    def __init__(self, camera, parent=None):\n        super(CameraParametersTableModel, self).__init__(parent)\n        self.camera = camera\n        self.parameter_names = self.camera.camera_parameter_names()\n        for parameter_name in self.parameter_names[:]:   #Added to prevent properties the camera does not posses from trying to appear in the list of parameters\n            try:\n                getattr(self.camera, parameter_name)\n            except:\n                self.parameter_names.remove(parameter_name)\n        \n        # Here, we register to get a callback if any of the parameters change\n        # so that we stay in sync with the camera.\n        self._callback_functions = dict()       \n        for i, pn in enumerate(self.parameter_names):\n            callback = self.callback_to_update_row(i)\n            register_for_property_changes(self.camera, pn, callback)\n            self._callback_functions[pn] = callback\n    \n    def callback_to_update_row(self, i):\n        \"\"\"Return a callback function that refreshes the i-th parameter.\"\"\"\n        def callback(value=None):\n            index = self.createIndex(i, 1)\n            self.dataChanged.emit(index, index)\n        return callback\n    \n    def rowCount(self, parent):\n        return len(self.parameter_names)\n    \n    def columnCount(self, parent):\n        return 2\n    \n    def data(self, index, role=QtCore.Qt.DisplayRole):\n        \"Return the data for the table - property names left, values right.\"\n        if not index.isValid() or role != QtCore.Qt.DisplayRole:\n            return None    \n        parameter_name = self.parameter_names[index.row()]\n        if index.column() == 0:\n            return parameter_name\n        else:\n            return getattr(self.camera, parameter_name)\n    \n    def headerData(self, i, orientation, role=QtCore.Qt.DisplayRole):\n        \"Return data for the headers.\"\n        if role == QtCore.Qt.DisplayRole:\n            if orientation == QtCore.Qt.Horizontal:\n                return [\"Parameter Name\", \"Parameter Value\"][i]\n            else:\n                return None\n        return None\n    \n    def setData(self, index, value, role=QtCore.Qt.DisplayRole):\n        \"\"\"If the value is changed, update the corresponding property.\"\"\"\n        assert index.column() == 1, \"Can only edit second column!\"\n        parameter_name = self.parameter_names[index.row()]\n        try:\n            float(value) # make sure the input is valid\n        except:\n            return False\n        setattr(self.camera, parameter_name, float(value))\n        self.dataChanged.emit(index, index) # signal that the data has changed.\n        return True\n        \n    def flags(self, index):\n        \"Return flags to tell Qt that only the second column is editable.\"\n        if index.column() == 1:\n            return (QtCore.Qt.ItemIsEditable | QtCore.Qt.ItemIsEnabled | \n                    QtCore.Qt.ItemIsSelectable)\n        else:\n            return QtCore.Qt.ItemIsEnabled",
  "class CameraParametersWidget(QtWidgets.QWidget, UiTools):\n    \"\"\"An editable table that controls a camera's acquisition parameters.\"\"\"\n    def __init__(self, camera, *args, **kwargs):\n        super(CameraParametersWidget, self).__init__(*args, **kwargs)\n        self.camera = camera\n        self.table_model = CameraParametersTableModel(camera)\n        self.table_view = QtWidgets.QTableView()\n        self.table_view.setModel(self.table_model)\n        self.table_view.setCornerButtonEnabled(False)\n        self.table_view.resizeColumnsToContents()\n        self.table_view.horizontalHeader().setStretchLastSection(True)\n        \n        layout = QtWidgets.QVBoxLayout(self)\n        layout.addWidget(self.table_view)\n        self.setLayout(layout)",
  "class PreviewViewBox(pg.ViewBox):\n    \"\"\"A pyqtgraph ViewBox for use in the preview widget.\"\"\"\n    def suggestPadding(self, axis):\n        \"\"\"Return a value to use for the padding on a given axis.\n        \n        We always return zero so the image, by default, fills the window.\"\"\"\n        return 0",
  "class PreviewImageItem(pg.ImageItem):\n    legacy_click_callback = None\n    click_callback_signal = QtCore.Signal(np.ndarray)\n    def mouseClickEvent(self, ev):\n        \"\"\"Handle a mouse click on the image.\"\"\"\n        if ev.button() == QtCore.Qt.LeftButton:\n            pos = np.array(ev.pos())\n            if self.legacy_click_callback is not None:\n        #        size = np.array(self.image.shape[:2])\n     #           point = pos/size\n      #          self.legacy_click_callback(point[1], point[0])\n                self.legacy_click_callback(int(pos[1]), int(pos[0]))\n                # print(pos)\n                ev.accept()\n            else:\n                pass\n        else:\n            super(PreviewImageItem, self).mouseClickEvent(ev)",
  "class CameraPreviewWidget(pg.GraphicsView):\n    \"\"\"A Qt Widget to display the live feed from a camera.\"\"\"\n    update_data_signal = QtCore.Signal(np.ndarray)\n    \n    def __init__(self):\n        super(CameraPreviewWidget, self).__init__()\n        \n        self.image_item = PreviewImageItem()\n        self.view_box = PreviewViewBox(lockAspect=1.0, invertY=True)\n        self.view_box.addItem(self.image_item)\n        self.view_box.setBackgroundColor([128,128,128,255])\n        self.setCentralWidget(self.view_box)\n        self.crosshair = {'h_line': pg.InfiniteLine(pos=0,angle=0),\n                          'v_line': pg.InfiniteLine(pos=0,angle=90),}\n        for item in list(self.crosshair.values()):\n            self.view_box.addItem(item)\n        self._image_shape = ()\n\n        # We want to make sure we always update the data in the GUI thread.\n        # This is done using the signal/slot mechanism\n        self.update_data_signal.connect(self.update_widget, type=QtCore.Qt.QueuedConnection)\n\n    def update_widget(self, newimage):\n        \"\"\"Set the image, but do so in the Qt main loop to avoid threading nasties.\"\"\"\n        # I've explicitly dealt with the datatype of the source image, to avoid\n        # a bug in the way pyqtgraph interacts with numpy 1.10.  This means\n        # scaling the display values will fail for integer data.  I've thus\n        # forced floating-point for anything that isn't a u8, and assumed u8\n        # wants to be displayed raw.  You can always use filter_function to\n        # tweak the brightness/contrast.\n        if len(newimage.shape)==2:\n            newimage = newimage.transpose()\n        elif len(newimage.shape)==3:\n            newimage = newimage.transpose((1,0,2))\n        if newimage.dtype ==\"uint8\":\n            self.image_item.setImage(newimage, autoLevels=False)\n        else:\n            self.image_item.setImage(newimage.astype(float))\n        if newimage.shape != self._image_shape:\n            self._image_shape = newimage.shape\n            self.set_crosshair_centre((newimage.shape[1]/2.0, newimage.shape[0]/2.0))\n    def update_image(self, newimage):\n        \"\"\"Update the image displayed in the preview widget.\"\"\"\n        # NB compared to previous versions, pyqtgraph flips in y, hence the\n        # funny slice on the next line.\n        self.update_data_signal.emit(newimage)\n        \n    def add_legacy_click_callback(self, function):\n        \"\"\"Add an old-style (coordinates in fractions-of-an-image) callback.\"\"\"\n        self.image_item.legacy_click_callback = function\n    \n    def set_crosshair_centre(self, pos):\n        \"\"\"Move the crosshair to centre on a given pixel coordinate.\"\"\"\n        self.crosshair['h_line'].setValue(pos[0])\n        self.crosshair['v_line'].setValue(pos[1])",
  "class DummyCamera(Camera):\n    \"\"\"A version of the Camera code  \"\"\"\n    exposure = CameraParameter(\"exposure\", \"The exposure time in ms.\")\n    gain = CameraParameter(\"gain\", \"The gain in units of bananas.\")\n    def __init__(self):\n        super(DummyCamera, self).__init__()\n        self._camera_parameters = {'exposure':40, 'gain':1}\n    def raw_snapshot(self):\n        \"\"\"Returns a True, stating a succesful snapshot, followed by a (100,100)\n        picture randomly generated image\"\"\"\n        ran = np.random.random((100,100,3))\n        return True, (ran * 255.9).astype(np.uint8)\n    def get_camera_parameter(self, name):\n        \"\"\"Pull a camera paramter of key \"name\"  from a hidden dictionary\"\"\"\n        return self._camera_parameters[name]\n    def set_camera_parameter(self, name, value):\n        \"\"\"Set a camera paramter of key \"name\"  from a hidden dictionary\"\"\"\n        self._camera_parameters[name] = value\n    def print_numbers(self,a = 5.0,b = 10):\n        \"\"\"A print numbers test function\"\"\"\n        print(a, b)\n    def print_strs(self,a= 'hello'):\n        \"\"\"Print a str test function\"\"\"\n        print(a)\n    def print_array(self,a = np.array([1, 2, 3, 4])):\n        \"\"\"Test Function for printing an array of values\"\"\"\n        print(a)",
  "def __init__(self, parameter_name, doc=None, read_back=True):\n        \"\"\"Create a property that reads and writes the given parameter.\n        \n        This internally uses the `get_camera_parameter` and \n        `set_camera_parameter` methods, so make sure you override them.\n        \"\"\"\n        if doc is None:\n            doc = \"Adjust the camera parameter '{0}'\".format(parameter_name)\n        super(CameraParameter, self).__init__(fget=self.fget, \n                                                      fset=self.fset, \n                                                      doc=doc,\n                                                      read_back=read_back)\n        self.parameter_name = parameter_name",
  "def fget(self, obj):\n        return obj.get_camera_parameter(self.parameter_name)",
  "def fset(self, obj, value):\n        obj.set_camera_parameter(self.parameter_name, value)",
  "def __init__(self):\n        super(Camera,self).__init__()\n        self.acquisition_lock = threading.Lock()    \n        self._latest_frame_update_condition = threading.Condition()\n        self._live_view = False\n        self._frame_counter = 0\n        # Ensure camera parameters get saved in the metadata.  You may want to override this in subclasses\n        # to remove junk (e.g. if some of the parameters are meaningless)\n#        self.metadata_property_names = self.metadata_property_names + tuple(self.camera_parameter_names())\n        self.metadata_property_names = tuple(self.metadata_property_names) + tuple(self.camera_parameter_names())",
  "def __del__(self):\n        self.close()",
  "def close(self):\n        \"\"\"Stop communication with the camera and allow it to be re-used.\n        \n        override in subclass if you want to shut down hardware.\"\"\"\n        self.live_view = False",
  "def get_next_frame(self, timeout=60, discard_frames=0, \n                       assert_live_view=True, raw=True):\n        \"\"\"Wait for the next frame to arrive and return it.\n        \n        This function is mostly intended for acquiring frames from a video\n        stream that's running in live view - it returns a fresh frame without\n        interrupting the video.  If called with timeout=None when live view is\n        false, it may take a very long time to return.\n        \n        @param: timeout: Maximum length of time to wait for a new frame.  None\n        waits forever, but this may be a bad idea (could hang your script).\n        @param: discard_frames: Wait for this many new frames before returning\n        one.  This option is useful if the camera buffers frames, so you must\n        wait for several frames to be acquired before getting a \"fresh\" one.\n        The default setting of 0 means the first new frame that arrives is\n        returned.\n        @param: assert_live_view: If True (default) raise an assertion error if\n        live view is not enabled - this function is intended only to be used\n        when that is the case.\n        @param: raw: The default (True) returns a raw frame - False returns the\n        frame after processing by the filter function if any.\n        \"\"\"\n        if assert_live_view:\n            assert self.live_view, \"\"\"Can't wait for the next frame if live view is not enabled!\"\"\"\n        with self._latest_frame_update_condition:\n            # We use the Condition object to block until a new frame appears\n            # However we need to check that a new frame has actually been taken\n            # so we use the frame counter.\n            # NB the current implementation may be vulnerable to dropped frames\n            # which will probably cause a timeout error.\n            # Checking for frame_counter being >= target_frame is vulnerable to\n            # overflow.\n            target_frame = self._frame_counter + 1 + discard_frames\n            expiry_time = time.time() + timeout\n            while self._frame_counter != target_frame and time.time() < expiry_time:\n                self._latest_frame_update_condition.wait(timeout) #wait for a new frame\n            if time.time() >= expiry_time:\n                raise IOError(\"Timed out waiting for a fresh frame from the video stream.\")\n            if raw:\n                return self.latest_raw_frame\n            else:\n                return self.latest_frame",
  "def raw_snapshot(self):\n        \"\"\"Take a snapshot and return it.  No filtering or conversion.\"\"\"\n        raise NotImplementedError(\"Cameras must subclass raw_snapshot!\")\n        return True, np.zeros((640,480,3),dtype=np.uint8)",
  "def get_image(self):\n        print(\"Warning: get_image is deprecated, use raw_image() instead.\")\n        return self.raw_image()",
  "def raw_image(self, bundle_metadata=False, update_latest_frame=False):\n        \"\"\"Take an image from the camera, respecting video priority.\n        \n        If live view is enabled and video_priority is true, return the next\n        frame in the video stream.  Otherwise, return a specially-acquired\n        image from raw_snapshot.\n        \"\"\"\n        frame = None\n        if self.live_view and self.video_priority:\n            frame = self.get_next_frame(raw=True)\n        else:\n            status, frame = self.raw_snapshot()\n        if update_latest_frame:\n            self.latest_raw_frame = frame\n        # return it as an ArrayWithAttrs including self.metadata, if requested\n        return self.bundle_metadata(frame, bundle_metadata)",
  "def color_image(self, **kwargs):\n        \"\"\"Get a colour image (bypass filtering, etc.)\n        \n        Additional keyword arguments are passed to raw_image.\"\"\"\n        frame = self.raw_image(**kwargs)\n        try:\n            assert frame.shape[2]==3\n            return frame\n        except:\n            try:\n                assert len(frame.shape)==2\n                gray_frame = np.vstack((frame,)*3) #turn gray into color by duplicating!\n                if hasattr(frame, \"attrs\"):\n                    return ArrayWithAttrs(gray_frame, attrs=frame.attrs)\n                else:\n                    return gray_frame\n            except:\n                raise Exception(\"Couldn't convert the camera's raw image to colour.\")",
  "def gray_image(self, **kwargs):\n        \"\"\"Get a colour image (bypass filtering, etc.)\n        \n        Additional keyword arguments are passed to raw_image.\"\"\"\n        frame = self.raw_image(**kwargs)\n        try:\n            assert len(frame.shape)==2\n            return frame\n        except:\n            try:\n                assert frame.shape[2]==3\n                return np.mean(frame, axis=2, dtype=frame.dtype)\n            except:\n                raise Exception(\"Couldn't convert the camera's raw image to grayscale.\")",
  "def save_raw_image(self, update_latest_frame=True, attrs={}):\n        \"\"\"Save an image to the default place in the default HDF5 file.\"\"\"\n        d=self.create_dataset(self.filename, \n                              data=self.raw_image(\n                                  bundle_metadata=True,\n                                  update_latest_frame=update_latest_frame))\n        d.attrs.update(attrs)",
  "def latest_raw_frame(self):\n        \"\"\"The last frame acquired by the camera.  \n        \n        This property is particularly useful when\n        live_view is enabled.  This is before processing by any filter function\n        that may be in effect.  May be NxMx3 or NxM for monochrome.  To get a\n        fresh frame, use raw_image().  Setting this property will update any\n        preview widgets that are in use.\"\"\"\n        return self._latest_raw_frame",
  "def latest_raw_frame(self, frame):\n        \"\"\"Set the latest raw frame, and update the preview widget if any.\"\"\"\n        with self._latest_frame_update_condition:\n            self._latest_raw_frame = frame\n            self._frame_counter += 1\n            self._latest_frame_update_condition.notify_all()\n        \n        # TODO: use the NotifiedProperty to do this with less code?\n        self.update_widgets()",
  "def update_widgets(self):\n        \"\"\"Iterates over the preview widgets and updates them. It's a good method to override in subclasses\"\"\"\n        if self._preview_widgets is not None:\n            for w in self._preview_widgets:\n                try:\n                    w.update_image(self.latest_frame)\n                except Exception as e:\n                    print(\"something went wrong updating the preview widget\")\n                    print(e)",
  "def latest_frame(self):\n        \"\"\"The last frame acquired (in live view/from GUI), after filtering.\"\"\"\n        if self.filter_function is not None:\n            return self.filter_function(self.latest_raw_frame)\n        else:\n            return self.latest_raw_frame",
  "def update_latest_frame(self, frame=None):\n        \"\"\"Take a new frame and store it as the \"latest frame\"\n        \n        Returns the image as displayed, including filters, etc.\n        This should rarely be used - raw_image, color_image and gray_image are\n        the preferred way of acquiring data.  If you supply an image, it will\n        use that image as if it was the most recent colour image to be \n        acquired.\n        \n        Unless you need the filtered image, you should probably use \n        raw_image, color_image or gray_image.\n        \"\"\"\n        if frame is None: \n            frame = self.color_image()\n        if frame is not None:\n            self.latest_raw_frame = frame\n            \n            return self.latest_frame\n        else:\n            print(\"Failed to get an image from the camera\")",
  "def camera_parameter_names(self):\n        \"\"\"Return a list of names of parameters that may be set/read.\n        \n        This will list the names of all the members of this class that are \n        `CameraParameter`s - you should define one of these for each of the \n        properties of the camera you'd like to expose.\n        \n        If you need to support dynamic properties, I suggest you use a class\n        factory, and add CameraParameters at runtime.  You could do this from\n        within the class, but that's a courageous move.\n        \n        If you need more sophisticated control, I suggest subclassing\n        `CameraParameter`, though I can't currently see how that would help...\n        \"\"\"\n        # first, identify all the CameraParameter properties we've got\n        p_list = []\n        for p in dir(self.__class__):\n            try:\n                if isinstance(getattr(self.__class__, p), CameraParameter):\n                    getattr(self,p)\n                    p_list.append(p)\n            except:\n                try:\n                    delattr(self.__class__,p)\n                except:\n                    pass\n                pass\n        return p_list",
  "def get_camera_parameter(self, parameter_name):\n        \"\"\"Return the named property from the camera\"\"\"\n        raise NotImplementedError(\"You must override get_camera_parameter to use it\")",
  "def set_camera_parameter(self, parameter_name, value):\n        \"\"\"Return the named property from the camera\"\"\"\n        raise NotImplementedError(\"You must override set_camera_parameter to use it\")",
  "def live_view(self):\n        \"\"\"Whether the camera is currently streaming and displaying video\"\"\"\n        return self._live_view",
  "def live_view(self, live_view):\n        \"\"\"Turn live view on and off.\n        \n        This is used to start and stop streaming of the camera feed.  The\n        default implementation just repeatedly takes snapshots, but subclasses\n        are encouraged to override that behaviour by starting/stopping a stream\n        and using a callback function to update self.latest_raw_frame.\"\"\"\n        if live_view==True:\n            if self._live_view:\n                return # do nothing if it's going already.\n            print(\"starting live view thread\")\n            try:\n                self._frame_counter = 0\n                self._live_view_stop_event = threading.Event()\n                self._live_view_thread = threading.Thread(target=self._live_view_function)\n                self._live_view_thread.start()\n                self._live_view = True\n            except AttributeError as e: #if any of the attributes aren't there\n                print(\"Error:\", e)\n        else:\n            if not self._live_view:\n                return # do nothing if it's not running.\n            print(\"stopping live view thread\")\n            try:\n                self._live_view_stop_event.set()\n                self._live_view_thread.join()\n                del(self._live_view_stop_event, self._live_view_thread)\n                self._live_view = False\n            except AttributeError:\n                raise Exception(\"Tried to stop live view but it doesn't appear to be running!\")",
  "def _live_view_function(self):\n        \"\"\"This function should only EVER be executed by _live_view_changed.\n        \n        Loop until the event tells us to stop, constantly taking snapshots.\n        Ideally you should override live_view to start and stop streaming\n        from the camera, using a callback function to update latest_raw_frame.\n        \"\"\"\n        while not self._live_view_stop_event.wait(timeout=0.1):\n            success, frame = self.raw_snapshot()\n            if success:\n                self.update_latest_frame(frame)",
  "def set_legacy_click_callback(self, function):\n        \"\"\"Set a function to be called when the image is clicked.\n        \n        Warning: this is only for compatibility with old code and will be removed\n        once camera_stage_mapper is updated!\n        \"\"\"\n        self.legacy_click_callback = function\n        if self._preview_widgets is not None:\n            for w in self._preview_widgets:\n                w.add_legacy_click_callback(self.legacy_click_callback)",
  "def get_preview_widget(self):\n        \"\"\"A Qt Widget that can be used as a viewfinder for the camera.\n        \n        In live mode, this is continuously updated.  It's also updated whenever\n        a snapshot is taken using update_latest_frame.  Currently this returns\n        a single widget instance - in future it might be able to generate (and\n        keep updated) multiple widgets.\"\"\"\n        if self._preview_widgets is None:\n            self._preview_widgets = WeakSet()\n        new_widget = CameraPreviewWidget()\n        self._preview_widgets.add(new_widget)\n        if self.legacy_click_callback is not None:\n            new_widget.add_legacy_click_callback(self.legacy_click_callback)\n        return new_widget",
  "def get_control_widget(self):\n        \"\"\"Return a widget that contains the camera controls but no image.\"\"\"\n        return CameraControlWidget(self)",
  "def get_parameters_widget(self):\n        \"\"\"Return a widget that controls the camera's settings.\"\"\"\n        return CameraParametersWidget(self)",
  "def get_qt_ui(self, control_only=False, parameters_only=False):\n        \"\"\"Create a QWidget that controls the camera.\n        \n        Specifying control_only=True returns just the controls for the camera.\n        Otherwise, you get both the controls and a preview window.\n        \"\"\"\n        if control_only:\n            return self.get_control_widget()\n        elif parameters_only:\n            return self.get_parameters_widget(self)\n        else:\n            return CameraUI(self)",
  "def __init__(self, camera):\n        assert isinstance(camera, Camera), \"instrument must be a Camera\"\n        #TODO: better checking (e.g. assert camera has color_image, gray_image methods)\n        super(CameraUI, self).__init__()\n        self.camera=camera\n        \n        # Set up the UI        \n        self.setWindowTitle(self.camera.__class__.__name__)\n        layout = QtWidgets.QVBoxLayout()\n        # The image display goes at the top of the window\n        self.preview_widget = self.camera.get_preview_widget()\n        layout.addWidget(self.preview_widget)\n        # The controls go in a layout, inside a group box.\n        self.controls = self.camera.get_control_widget()\n        layout.addWidget(self.controls)\n        #layout.setContentsMargins(5,5,5,5)\n        layout.setSpacing(5)\n        self.setLayout(layout)",
  "def __init__(self, camera, auto_connect=True):\n        assert isinstance(camera, Camera), \"instrument must be a Camera\"\n        #TODO: better checking (e.g. assert camera has color_image, gray_image methods)\n        super(CameraControlWidget, self).__init__()\n        self.camera=camera\n        self.load_ui_from_file(__file__,\"camera_controls_generic.ui\")\n        if auto_connect==True:\n            self.auto_connect_by_name(controlled_object=self.camera, verbose=False)",
  "def snapshot(self):\n        \"\"\"Take a new snapshot and display it.\"\"\"\n        self.camera.raw_image(update_latest_frame=True)",
  "def save_to_data_file(self):\n        self.camera.save_raw_image(\n            attrs={'description':self.description_lineedit.text()})",
  "def save_jpeg(self):\n        cur_img = self.camera.color_image()\n        fname, _ = QtWidgets.QFileDialog.getSaveFileName(\n                                caption = \"Select JPEG filename\",\n                                directory = os.path.join(os.getcwd(),datetime.date.today().strftime(\"%Y-%m-%d.jpg\")),\n                                filter = \"Images (*.jpg *.jpeg)\",\n                            )\n        j = Image.fromarray(cur_img)\n        j.save(fname)",
  "def edit_camera_parameters(self):\n        \"\"\"Pop up a camera parameters dialog box.\"\"\"\n        self.camera_parameters_widget = self.camera.get_parameters_widget()\n        self.camera_parameters_widget.show()",
  "def __del__(self):\n        pass",
  "def __init__(self, camera, parent=None):\n        super(CameraParametersTableModel, self).__init__(parent)\n        self.camera = camera\n        self.parameter_names = self.camera.camera_parameter_names()\n        for parameter_name in self.parameter_names[:]:   #Added to prevent properties the camera does not posses from trying to appear in the list of parameters\n            try:\n                getattr(self.camera, parameter_name)\n            except:\n                self.parameter_names.remove(parameter_name)\n        \n        # Here, we register to get a callback if any of the parameters change\n        # so that we stay in sync with the camera.\n        self._callback_functions = dict()       \n        for i, pn in enumerate(self.parameter_names):\n            callback = self.callback_to_update_row(i)\n            register_for_property_changes(self.camera, pn, callback)\n            self._callback_functions[pn] = callback",
  "def callback_to_update_row(self, i):\n        \"\"\"Return a callback function that refreshes the i-th parameter.\"\"\"\n        def callback(value=None):\n            index = self.createIndex(i, 1)\n            self.dataChanged.emit(index, index)\n        return callback",
  "def rowCount(self, parent):\n        return len(self.parameter_names)",
  "def columnCount(self, parent):\n        return 2",
  "def data(self, index, role=QtCore.Qt.DisplayRole):\n        \"Return the data for the table - property names left, values right.\"\n        if not index.isValid() or role != QtCore.Qt.DisplayRole:\n            return None    \n        parameter_name = self.parameter_names[index.row()]\n        if index.column() == 0:\n            return parameter_name\n        else:\n            return getattr(self.camera, parameter_name)",
  "def headerData(self, i, orientation, role=QtCore.Qt.DisplayRole):\n        \"Return data for the headers.\"\n        if role == QtCore.Qt.DisplayRole:\n            if orientation == QtCore.Qt.Horizontal:\n                return [\"Parameter Name\", \"Parameter Value\"][i]\n            else:\n                return None\n        return None",
  "def setData(self, index, value, role=QtCore.Qt.DisplayRole):\n        \"\"\"If the value is changed, update the corresponding property.\"\"\"\n        assert index.column() == 1, \"Can only edit second column!\"\n        parameter_name = self.parameter_names[index.row()]\n        try:\n            float(value) # make sure the input is valid\n        except:\n            return False\n        setattr(self.camera, parameter_name, float(value))\n        self.dataChanged.emit(index, index) # signal that the data has changed.\n        return True",
  "def flags(self, index):\n        \"Return flags to tell Qt that only the second column is editable.\"\n        if index.column() == 1:\n            return (QtCore.Qt.ItemIsEditable | QtCore.Qt.ItemIsEnabled | \n                    QtCore.Qt.ItemIsSelectable)\n        else:\n            return QtCore.Qt.ItemIsEnabled",
  "def __init__(self, camera, *args, **kwargs):\n        super(CameraParametersWidget, self).__init__(*args, **kwargs)\n        self.camera = camera\n        self.table_model = CameraParametersTableModel(camera)\n        self.table_view = QtWidgets.QTableView()\n        self.table_view.setModel(self.table_model)\n        self.table_view.setCornerButtonEnabled(False)\n        self.table_view.resizeColumnsToContents()\n        self.table_view.horizontalHeader().setStretchLastSection(True)\n        \n        layout = QtWidgets.QVBoxLayout(self)\n        layout.addWidget(self.table_view)\n        self.setLayout(layout)",
  "def suggestPadding(self, axis):\n        \"\"\"Return a value to use for the padding on a given axis.\n        \n        We always return zero so the image, by default, fills the window.\"\"\"\n        return 0",
  "def mouseClickEvent(self, ev):\n        \"\"\"Handle a mouse click on the image.\"\"\"\n        if ev.button() == QtCore.Qt.LeftButton:\n            pos = np.array(ev.pos())\n            if self.legacy_click_callback is not None:\n        #        size = np.array(self.image.shape[:2])\n     #           point = pos/size\n      #          self.legacy_click_callback(point[1], point[0])\n                self.legacy_click_callback(int(pos[1]), int(pos[0]))\n                # print(pos)\n                ev.accept()\n            else:\n                pass\n        else:\n            super(PreviewImageItem, self).mouseClickEvent(ev)",
  "def __init__(self):\n        super(CameraPreviewWidget, self).__init__()\n        \n        self.image_item = PreviewImageItem()\n        self.view_box = PreviewViewBox(lockAspect=1.0, invertY=True)\n        self.view_box.addItem(self.image_item)\n        self.view_box.setBackgroundColor([128,128,128,255])\n        self.setCentralWidget(self.view_box)\n        self.crosshair = {'h_line': pg.InfiniteLine(pos=0,angle=0),\n                          'v_line': pg.InfiniteLine(pos=0,angle=90),}\n        for item in list(self.crosshair.values()):\n            self.view_box.addItem(item)\n        self._image_shape = ()\n\n        # We want to make sure we always update the data in the GUI thread.\n        # This is done using the signal/slot mechanism\n        self.update_data_signal.connect(self.update_widget, type=QtCore.Qt.QueuedConnection)",
  "def update_widget(self, newimage):\n        \"\"\"Set the image, but do so in the Qt main loop to avoid threading nasties.\"\"\"\n        # I've explicitly dealt with the datatype of the source image, to avoid\n        # a bug in the way pyqtgraph interacts with numpy 1.10.  This means\n        # scaling the display values will fail for integer data.  I've thus\n        # forced floating-point for anything that isn't a u8, and assumed u8\n        # wants to be displayed raw.  You can always use filter_function to\n        # tweak the brightness/contrast.\n        if len(newimage.shape)==2:\n            newimage = newimage.transpose()\n        elif len(newimage.shape)==3:\n            newimage = newimage.transpose((1,0,2))\n        if newimage.dtype ==\"uint8\":\n            self.image_item.setImage(newimage, autoLevels=False)\n        else:\n            self.image_item.setImage(newimage.astype(float))\n        if newimage.shape != self._image_shape:\n            self._image_shape = newimage.shape\n            self.set_crosshair_centre((newimage.shape[1]/2.0, newimage.shape[0]/2.0))",
  "def update_image(self, newimage):\n        \"\"\"Update the image displayed in the preview widget.\"\"\"\n        # NB compared to previous versions, pyqtgraph flips in y, hence the\n        # funny slice on the next line.\n        self.update_data_signal.emit(newimage)",
  "def add_legacy_click_callback(self, function):\n        \"\"\"Add an old-style (coordinates in fractions-of-an-image) callback.\"\"\"\n        self.image_item.legacy_click_callback = function",
  "def set_crosshair_centre(self, pos):\n        \"\"\"Move the crosshair to centre on a given pixel coordinate.\"\"\"\n        self.crosshair['h_line'].setValue(pos[0])\n        self.crosshair['v_line'].setValue(pos[1])",
  "def __init__(self):\n        super(DummyCamera, self).__init__()\n        self._camera_parameters = {'exposure':40, 'gain':1}",
  "def raw_snapshot(self):\n        \"\"\"Returns a True, stating a succesful snapshot, followed by a (100,100)\n        picture randomly generated image\"\"\"\n        ran = np.random.random((100,100,3))\n        return True, (ran * 255.9).astype(np.uint8)",
  "def get_camera_parameter(self, name):\n        \"\"\"Pull a camera paramter of key \"name\"  from a hidden dictionary\"\"\"\n        return self._camera_parameters[name]",
  "def set_camera_parameter(self, name, value):\n        \"\"\"Set a camera paramter of key \"name\"  from a hidden dictionary\"\"\"\n        self._camera_parameters[name] = value",
  "def print_numbers(self,a = 5.0,b = 10):\n        \"\"\"A print numbers test function\"\"\"\n        print(a, b)",
  "def print_strs(self,a= 'hello'):\n        \"\"\"Print a str test function\"\"\"\n        print(a)",
  "def print_array(self,a = np.array([1, 2, 3, 4])):\n        \"\"\"Test Function for printing an array of values\"\"\"\n        print(a)",
  "def callback(value=None):\n            index = self.createIndex(i, 1)\n            self.dataChanged.emit(index, index)",
  "class OpenCVCamera(Camera):\n    def __init__(self,capturedevice=0):\n        self.cap=cv2.VideoCapture(capturedevice)\n        \n        super(OpenCVCamera,self).__init__() #NB this comes after setting up the hardware\n     \n        \n    def close(self):\n        \"\"\"Stop communication with the camera and allow it to be re-used.\"\"\"\n        super(OpenCVCamera, self).close()\n        self.cap.release()\n        \n    def raw_snapshot(self, suppress_errors = False):\n        \"\"\"Take a snapshot and return it.  Bypass filters etc.\"\"\"\n        with self.acquisition_lock:\n            for i in range(10):\n                try:\n                    ret, frame = self.cap.read()\n                    assert ret, \"OpenCV's capture.read() returned False :(\"\n                    if len(frame.shape) == 3:\n                        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n                    return ret, frame\n                except Exception as e:\n                    print(\"Attempt number {0} failed to capture a frame from the camera!\".format(i))\n                    print(e)\n        print(\"Camera.raw_snapshot() has failed to capture a frame.\")\n        if not suppress_errors:\n            raise IOError(\"Dropped too many frames from camera :(\")\n        else:\n            return False, None\n        \n    def get_camera_parameter(self, parameter_name):\n        \"\"\"Get the value of a camera parameter (though you should really use the property)\"\"\"\n        return self.cap.get(getattr(cv2,parameter_name))\n    def set_camera_parameter(self, parameter_name, value):\n        \"\"\"Set the value of a camera parameter (though you should really use the property)\"\"\"\n        return self.cap.set(getattr(cv2,parameter_name), value)",
  "def __init__(self,capturedevice=0):\n        self.cap=cv2.VideoCapture(capturedevice)\n        \n        super(OpenCVCamera,self).__init__()",
  "def close(self):\n        \"\"\"Stop communication with the camera and allow it to be re-used.\"\"\"\n        super(OpenCVCamera, self).close()\n        self.cap.release()",
  "def raw_snapshot(self, suppress_errors = False):\n        \"\"\"Take a snapshot and return it.  Bypass filters etc.\"\"\"\n        with self.acquisition_lock:\n            for i in range(10):\n                try:\n                    ret, frame = self.cap.read()\n                    assert ret, \"OpenCV's capture.read() returned False :(\"\n                    if len(frame.shape) == 3:\n                        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n                    return ret, frame\n                except Exception as e:\n                    print(\"Attempt number {0} failed to capture a frame from the camera!\".format(i))\n                    print(e)\n        print(\"Camera.raw_snapshot() has failed to capture a frame.\")\n        if not suppress_errors:\n            raise IOError(\"Dropped too many frames from camera :(\")\n        else:\n            return False, None",
  "def get_camera_parameter(self, parameter_name):\n        \"\"\"Get the value of a camera parameter (though you should really use the property)\"\"\"\n        return self.cap.get(getattr(cv2,parameter_name))",
  "def set_camera_parameter(self, parameter_name, value):\n        \"\"\"Set the value of a camera parameter (though you should really use the property)\"\"\"\n        return self.cap.set(getattr(cv2,parameter_name), value)",
  "def ML32_BYTE(four_byte_val): return ((uns8) ((four_byte_val) >> 8))",
  "def LS32_BYTE(four_byte_val): return ((uns8) (four_byte_val))",
  "def MS16_BYTE(two_byte_value): return ((uns8) ((two_byte_value) >> 8))",
  "def LS16_BYTE(two_byte_value): return ((uns8) (two_byte_value))",
  "def VAL_UNS16(ms_byte,ls_byte): return ( (uns16)(((uns16)((uns8)(ms_byte))<<8) | ((uns16)((uns8)(ls_byte)))) )",
  "def VAL_UNS32(ms_byte,mh_byte,ml_byte,ls_byte): return ( ((uns32)((uns8)(ms_byte))<<24) | ((uns32)((uns8)(mh_byte))<<16) | ((uns32)((uns8)(ml_byte))<<8) | ((uns32)((uns8)(ls_byte)) ) )",
  "def MS32_BYTE(four_byte_val): return ((uns8) ((four_byte_val) >> 24))",
  "def MH32_BYTE(four_byte_val): return ((uns8) ((four_byte_val) >> 16))",
  "class rgn_type(Structure):\n    pass",
  "class export_ctrl_type(Structure):\n    pass",
  "def index_closest(val, l):\n    \"\"\"\n    finds in a list the index of the closest existing value from a given value\n    Works also with dict and tuples.\n    \"\"\"\n    if isinstance(l, dict):\n        return min(list(l.items()), key=lambda x: abs(x[1] - val))[0]\n    else:\n        return min(enumerate(l), key=lambda x: abs(x[1] - val))[0]",
  "class PVCamError(Exception):\n    def __init__(self, errno, strerror, *args, **kwargs):\n        super(PVCamError, self).__init__(errno, strerror, *args, **kwargs)\n        self.args = (errno, strerror)\n\n    def __str__(self):\n        return self.args[1]",
  "class CancelledError(Exception):\n    \"\"\"\n    raise to indicate the acquisition is cancelled and must stop\n    \"\"\"\n    pass",
  "class PVCamDLL(ct.WinDLL):\n    \"\"\"\n    Subclass of CDLL specific to PVCam library, which handles error codes for\n    all the functions automatically.\n    It works by setting a default _FuncPtr.errcheck.\n    \"\"\"\n\n    def __init__(self):\n        if os.name == \"nt\":\n            ct.WinDLL.__init__(self, \"pvcam32\")\n            self.pl_pvcam_init()\n        else:\n            raise OSError('Operating system not recognised')\n        #     # Global so that other libraries can access it\n        #     # need to have firewire loaded, even if not used\n        #     try:\n        #         self.raw1394 = ct.CDLL(\"libraw1394.so.11\", RTLD_GLOBAL)\n        #         #self.pthread = CDLL(\"libpthread.so.0\", RTLD_GLOBAL) # python already loads libpthread\n        #         # TODO: shall we use  ctypes.util.find_library(\"pvcam\")?\n        #         CDLL.__init__(self, \"libpvcam.so\", RTLD_GLOBAL)\n        #     except OSError:\n        #         self._logger.exception(\"Failed to find the PVCam driver. You need to \"\n        #                           \"check that libraw1394 and libpvcam are installed.\")\n        #         raise\n        #     try:\n        #         self.pl_pvcam_init()\n        #     except PVCamError:\n        #         pass # if opened several times, initialisation fails but it's all fine\n\n    def pv_errcheck(self, result, func, *args):\n        \"\"\"\n        Analyse the return value of a call and raise an exception in case of\n        error.\n        Follows the ctypes.errcheck callback convention\n        \"\"\"\n        if not result:  # functions return (rs_bool = int) False on error\n            try:\n                err_code = self.pl_error_code()\n            except Exception:\n                raise PVCamError(0, \"Call to %s failed\" % func.__name__)\n            # res = False\n            try:\n                err_mes = ct.create_string_buffer(pv.ERROR_MSG_LEN)\n                res = self.pl_error_message(err_code, err_mes)\n                if res:\n                    raise PVCamError(result, \"Call to %s failed with error code %d: %s\" %\n                                     (func.__name__, err_code, err_mes.value))\n            except Exception:\n                # if not res:\n                raise PVCamError(result, \"call to %s failed with unknown error code %d\" %\n                                     (func.__name__, err_code))\n\n        return result\n\n    def __getitem__(self, name):\n        try:\n            func = super(PVCamDLL, self).__getitem__(name)\n        except Exception:\n            raise AttributeError(\"Failed to find %s\" % (name,))\n        func.__name__ = name\n        if name not in self.err_funcs:\n            func.errcheck = self.pv_errcheck\n        return func\n\n    # names of the functions which are used in case of error (so should not\n    # have their result checked\n    err_funcs = (\"pl_error_code\", \"pl_error_message\", \"pl_exp_check_status\")\n\n    def reinit(self):\n        \"\"\"\n        Does a fast uninit/init cycle\n        \"\"\"\n        try:\n            self.pl_pvcam_uninit()\n        except PVCamError:\n            pass  # whatever\n        try:\n            self.pl_pvcam_init()\n        except PVCamError:\n            pass  # whatever\n\n    def __del__(self):\n        try:\n            self.pl_pvcam_uninit()\n        except:\n            self._logger.exception(\"Failed during PVCam uninitialization\")\n            pass",
  "class PvcamSdk(object):\n    \"\"\"\n    Represents one PVCam camera and provides all the basic interfaces typical of\n    a CCD/CMOS camera.\n    This implementation is for the Roper/PI/Photometrics PVCam library... or at\n    least for the PI version.\n\n    Odemis tested on Linux with SDK 2.7, this was tested on Windows using the documentation found here:\n    ftp://ftp.piacton.com/Public/Manuals/Princeton%20Instruments/PVCAM%202.7%20Software%20User%20Manual.pdf\n\n    Be aware that the library resets almost all the values to their default\n    values after initialisation. The library doesn't call the dimensions\n    horizontal/vertical but serial/parallel (because the camera could be rotated).\n    But we stick to: horizontal = serial (max = width - 1)\n                     vertical = parallel (max = height - 1)\n\n    Here area few more non-obvious requirements given by the PI technical\n    support:\n    * PIXIS, must allocate an even number of frame buffers.\n    * One must not turn off or disconnect the camera with the camera open.\n    * One must not call other PVCAM parameters such as PARAM_TEMP to get the\n     current temperature during data collection. Only functions or parameters\n     designated as 'online' may be called.\n    * Order dependency issue: can't turn on continuous clean before external\n     sync (strobed mode) is enabled.\n    * InGaAs camera cannot do hardware binning\n\n    Provides low-level methods corresponding to the SDK functions.\n    \"\"\"\n\n    def __init__(self, device, *args, **kwargs):\n        \"\"\"\n        Initialises the device\n        device (int or string): number of the device to open, as defined in\n         pvcam, cf scan(), or the name of the device (as in /dev/).\n        Raise an exception if the device cannot be opened.\n        \"\"\"\n        self.pvcam = PVCamDLL()\n        self.current_image = None\n        if \"logger\" in kwargs:\n            self._logger = kwargs[\"logger\"]\n        elif not hasattr(self, \"_logger\"):\n            self._logger = create_logger(\"PvcamSdk\")\n            self._logger.setLevel(\"DEBUG\")\n\n        # so that it's really not possible to use this object in case of error\n        self._handle = None\n        self._temp_timer = None\n        # pick the right selection method depending on the type of \"device\"\n        if isinstance(device, int):\n            try:\n                self._devname = self.cam_get_name(device)  # for reinit\n            except PVCamError:\n                raise Exception(\"Failed to find PI PVCam camera (%d)\"\n                                \"Check the device is turned on and connected to \"\n                                \"the computer. \"\n                                \"You might need to turn it off and on again.\"\n                                % (device))\n        elif isinstance(device, str):\n            # # check the file exists\n            # if not os.path.exists(\"/dev/\" + device):\n            #     raise Exception(\"Failed to find PI PVCam camera %s (at %s). \"\n            #                   \"Check the device is turned on and connected to \"\n            #                   \"the computer. \"\n            #                   \"You might need to turn it off and on again.\"\n            #                   % (name, device))\n            self._devname = device\n        else:\n            raise ValueError(\"Unexpected type for device: %s\" % device)\n\n        try:\n            self._logger.info(\"Initializing camera, can be long (~15 s)...\")\n            self._handle = self.cam_open(self._devname, pv.OPEN_EXCLUSIVE)\n            # raises an error if camera has a problem\n            self.pvcam.pl_cam_get_diags(self._handle)\n        except PVCamError as e:\n            self._logger.info(\"PI camera seems connected but not responding, \"\n                              \"you might want to try turning it off and on again.\")\n            print(e)\n            raise IOError(\"Failed to open PVCam camera %s (%s)\" % (device, self._devname))\n\n        self._logger.info(\"Opened device %s successfully\", device)\n\n        # Describe the camera\n        # up-to-date metadata to be included in dataflow\n        # self._metadata = {MD_HW_NAME: self.getModelName()}\n\n        # drivers\n        self._swVersion = self.get_sw_version()\n        self._hwVersion = self.get_hw_version()\n        self.resolution = self.get_sensor_size()\n\n        # setup everything best (fixed)\n        self._prev_settings = [None, None, None, None, None]  # image, exposure, readout, gain, shutter period\n        # Bit depth is between 6 and 16, but data is _always_ uint16\n        self._shape = self.resolution + (2 ** self.get_param(pv.PARAM_BIT_DEPTH),)\n\n        # put the detector pixelSize\n        self.pixelSize = self.get_pixel_size()\n\n        # to be used to separate acquisition and offline-only parameters (like PARAM_TEMP)\n        # self._online_lock = threading.Lock()\n\n        # Strong cooling for low (image) noise\n        try:\n            self.temperature = self.get_temp()\n        except PVCamError:\n            self._logger.debug(\"Camera doesn't seem to provide temperature information\")\n\n        self._setStaticSettings()\n\n        # gain\n        self._gains = self._get_gains()\n        gain_choices = set(self._gains.values())\n        self._gain = min(gain_choices)  # default to low gain (low noise)\n        # self.gain = CameraParameter('gain')  # model.FloatEnumerated(self._gain, gain_choices, unit=\"\", setter=self._setGain)\n        self._set_gain(self._gain)\n\n        # read out rate\n        self._readout_rates = self._get_readout_rates()  # needed by _setReadoutRate()\n        ror_choices = set(self._readout_rates.values())\n        self._readout_rate = max(ror_choices)  # default to fast acquisition\n        # self.readoutRate = model.FloatEnumerated(self._readout_rate, ror_choices,\n        #                                          unit=\"Hz\", setter=self._setReadoutRate)\n        self._set_readout_rate(self._readout_rate)\n\n        # binning is needed for _setResolution()\n        self._binning = (1, 1)  # px\n        max_bin = self._get_max_bin()\n        self._image_rect = (0, self.resolution[0] - 1, 0, self.resolution[1] - 1)\n        self._number_frames = 1\n\n        self._min_res = self.get_min_resolution()\n        minr = (int(math.ceil(self._min_res[0] / max_bin[0])),\n                int(math.ceil(self._min_res[1] / max_bin[1])))\n        # need to be before binning, as it is modified when changing binning\n        #                   [self._transposeSizeToUser(minr),\n        #                    self._transposeSizeToUser(resolution)],\n        #                                      setter=self._setResolution)\n        self._setResolution(self.resolution)\n        self.background = np.zeros(self.resolution)\n\n        # 2D binning is like a \"small resolution\"\n        self.binning = self._binning  # model.ResolutionVA(self._transposeSizeToUser(self._binning),\n        #                    [self._transposeSizeToUser((1, 1)),\n        #                     self._transposeSizeToUser(max_bin)],\n        #                                   setter=self._setBinning)\n\n        # default values try to get live microscopy imaging more likely to show something\n        try:\n            minexp = self.get_param(pv.PARAM_EXP_MIN_TIME)  # s\n        except PVCamError:\n            # attribute doesn't exist\n            minexp = 0  # same as the resolution\n        minexp = max(1e-3, minexp)  # at least 1 x the exposure resolution (1 ms)\n        # exposure is represented by unsigned int\n        maxexp = (2 ** 32 - 1) * 1e-3  # s\n        range_exp = (minexp, maxexp)  # s\n        self._exposure_time = 0.01  # s\n        # self.exposureTime = model.FloatContinuous(self.exposure, range_exp,\n        #                                           unit=\"s\", setter=self._setexposureTime)\n\n        # To control the shutter: select the maximum frequency, aka minimum\n        # period for the shutter. If it the acquisition time is below, the\n        # shutter stays open all the time. So:\n        # 0 => shutter always active\n        # big value => shutter always opened\n        self._shutter_period = 0.1\n        # self.shutterMinimumPeriod = model.FloatContinuous(self._shutter_period, [0, 10],\n        #                                       unit=\"s\", setter=self._setShutterPeriod)\n        self.acquisition_lock = threading.Lock()\n        self.acquire_must_stop = threading.Event()\n        self.acquire_thread = None\n        # for synchronized acquisition\n        self._cbuffer = None\n        # self._got_event = threading.Event()\n        # self._late_events = collections.deque() # events which haven't been handled yet\n\n        self.data = None  # PVCamDataFlow(self)\n        # Convenience event for the user to connect and fire\n        # self.softwareTrigger = model.Event()\n        self._logger.debug(\"Camera component ready to use.\")\n\n    def __del__(self):\n        if self._temp_timer:\n            self._temp_timer.cancel()\n            self._temp_timer = None\n\n        if self._handle is not None:\n            # don't touch the temperature target/cooling\n\n            # stop the acquisition thread if needed\n            self.acquire_must_stop.set()\n            # self.wait_stopped_flow()\n\n            self._logger.debug(\"Shutting down the camera\")\n            self.pvcam.pl_cam_close(self._handle)\n            self._handle = None\n            del self.pvcam\n\n    # Properties\n    @NotifiedProperty\n    def exposure(self):\n        return self._exposure_time\n\n    @exposure.setter\n    def exposure(self, value):\n        self._exposure_time = value\n\n    @NotifiedProperty\n    def number_frames(self):\n        return self._number_frames\n\n    @number_frames.setter\n    def number_frames(self, value):\n        self._number_frames = value\n\n    def _setStaticSettings(self):\n        \"\"\"\n        Set up all the values that we don't need to change after.\n        Should only be called at initialisation\n        \"\"\"\n        # Set the output amplifier to lowest noise\n        try:\n            # Try to set to low noise, if existing, otherwise: default value\n            aos = self.get_enum_available(pv.PARAM_READOUT_PORT)\n            if pv.READOUT_PORT_LOW_NOISE in aos:\n                self.set_param(pv.PARAM_READOUT_PORT, pv.READOUT_PORT_LOW_NOISE)\n            else:\n                ao = self.get_param(pv.PARAM_READOUT_PORT, pv.ATTR_DEFAULT)\n                self.set_param(pv.PARAM_READOUT_PORT, ao)\n            self._output_amp = self.get_param(pv.PARAM_READOUT_PORT)\n        except PVCamError:\n            self._logger.debug(\"Failed to change readout speed\")\n\n        # Shutter mode (could be an init parameter?)\n        try:\n            # TODO: if the the shutter is in Pre-exposure mode, a short exposure\n            # time can burn it.\n            self.set_param(pv.PARAM_SHTR_OPEN_MODE, pv.OPEN_PRE_SEQUENCE)\n        except PVCamError:\n            self._logger.debug(\"Failed to change shutter mode\")\n\n        # Set to simple acquisition mode\n        self.set_param(pv.PARAM_PMODE, pv.PMODE_NORMAL)\n        # In PI cameras, this is fixed (so read-only)\n        if self.get_param_access(pv.PARAM_CLEAR_MODE) == pv.ACC_READ_WRITE:\n            self._logger.debug(\"Setting clear mode to pre sequence\")\n            # TODO: should be done pre-exposure? As we are not closing the shutter?\n            self.set_param(pv.PARAM_CLEAR_MODE, pv.CLEAR_PRE_EXPOSURE)\n\n        # set the exposure resolution. (choices are us, ms or s) => ms is best\n        # for life imaging (us allows up to 71min)\n        self.set_param(pv.PARAM_EXP_RES_INDEX, pv.EXP_RES_ONE_MILLISEC)\n\n    # low level methods, wrapper to the actual SDK functions\n\n    def Reinitialize(self):\n        \"\"\"\n        Waits for the camera to reappear and reinitialise it. Typically\n        useful in case the user switched off/on the camera.\n        \"\"\"\n        # stop trying to read the temperature while we reinitialize\n        if self._temp_timer is not None:\n            self._temp_timer.cancel()\n            self._temp_timer = None\n\n        try:\n            self.pvcam.pl_cam_close(self._handle)\n        except PVCamError:\n            pass\n        self._handle = None\n\n        # PVCam only update the camera list after uninit()/init()\n        while True:\n            self._logger.info(\"Waiting for the camera to reappear\")\n            self.pvcam.reinit()\n            try:\n                self._handle = self.cam_open(self._devname, pv.OPEN_EXCLUSIVE)\n                break  # succeeded!\n            except PVCamError:\n                time.sleep(1)\n\n        # reinitialise the sdk\n        self._logger.info(\"Trying to reinitialise the camera %s...\", self._devname)\n        try:\n            self.pvcam.pl_cam_get_diags(self._handle)\n        except PVCamError:\n            self._logger.info(\"Reinitialisation failed\")\n            raise\n\n        self._logger.info(\"Reinitialisation successful\")\n\n        # put back the settings\n        self._prev_settings = [None, None, None, None, None]\n        self._setStaticSettings()\n        \n        # self.setTargetTemperature(self.targetTemperature.value)\n        # self._temp_timer = util.RepeatingTimer(10, self.updateTemperatureVA,\n        #                                  \"PVCam temperature update\")\n        # self._temp_timer.start()\n\n    def cam_get_name(self, num):\n        \"\"\"\n        return the name, from the device number\n        num (int >= 0): camera number\n        return (string): name\n        \"\"\"\n        assert (num >= 0)\n        cam_name = ct.create_string_buffer(pv.CAM_NAME_LEN)\n        self.pvcam.pl_cam_get_name(num, cam_name)\n        return cam_name.value\n\n    def cam_open(self, name, mode):\n        \"\"\"\n        Reserve and initializes the camera hardware\n        name (string): camera name\n        mode (int): open mode\n        returns (int): handle\n        \"\"\"\n        handle = ct.c_int16()\n        self.pvcam.pl_cam_open(name, ct.byref(handle), mode)\n        return handle\n\n    pv_type_to_ctype = {\n        pv.TYPE_INT8: ct.c_int8,\n        pv.TYPE_INT16: ct.c_int16,\n        pv.TYPE_INT32: ct.c_int32,\n        pv.TYPE_UNS8: ct.c_uint8,\n        pv.TYPE_UNS16: ct.c_uint16,\n        pv.TYPE_UNS32: ct.c_uint32,\n        pv.TYPE_UNS64: ct.c_uint64,\n        pv.TYPE_FLT64: ct.c_double,  # hopefully true on all platforms?\n        pv.TYPE_BOOLEAN: ct.c_byte,\n        pv.TYPE_ENUM: ct.c_uint32,\n    }\n\n    def get_param(self, param, value=pv.ATTR_CURRENT):\n        \"\"\"\n        Read the current (or other) value of a parameter.\n        Note: for the enumerated parameters, this it the actual value, not the\n        index.\n        param (int): parameter ID (cf pv.PARAM_*)\n        value (int from pv.ATTR_*): which value to read (current, default, min, max, increment)\n        return (value): the value of the parameter, whose type depend on the parameter\n        \"\"\"\n        assert (value in (pv.ATTR_DEFAULT, pv.ATTR_CURRENT, pv.ATTR_MIN,\n                          pv.ATTR_MAX, pv.ATTR_INCREMENT))\n\n        # find out the type of the parameter\n        tp = ct.c_uint16()\n        self.pvcam.pl_get_param(self._handle, param, pv.ATTR_TYPE, ct.byref(tp))\n        if tp.value == pv.TYPE_CHAR_PTR:\n            # a string => need to find out the length\n            count = ct.c_uint32()\n            self.pvcam.pl_get_param(self._handle, param, pv.ATTR_COUNT, ct.byref(count))\n            content = ct.create_string_buffer(count.value)\n        elif tp.value in self.pv_type_to_ctype:\n            # print 'Why?: ', tp.value\n            content = self.pv_type_to_ctype[tp.value]()\n        elif tp.value in (pv.TYPE_VOID_PTR, pv.TYPE_VOID_PTR_PTR):\n            raise ValueError(\"Cannot handle arguments of type pointer\")\n        else:\n            raise NotImplementedError(\"Argument of unknown type %d\" % tp.value)\n\n        # read the parameter\n        self.pvcam.pl_get_param(self._handle, param, value, ct.byref(content))\n        return content.value\n\n    def get_param_access(self, param):\n        \"\"\"\n        gives the access rights for a given parameter.\n        param (int): parameter ID (cf pv.PARAM_*)\n        returns (int): value as in pv.ACC_*\n        \"\"\"\n        rights = ct.c_uint16()\n        self.pvcam.pl_get_param(self._handle, param, pv.ATTR_ACCESS, ct.byref(rights))\n        return rights.value\n\n    def set_param(self, param, value):\n        \"\"\"\n        Write the current value of a parameter.\n        Note: for the enumerated parameter, this is the actual value to set, not\n        the index.\n        param (int): parameter ID (cf pv.PARAM_*)\n        value (should be of the right type): value to write\n        Warning: it seems to not always complain if the value written is incorrect,\n        just using default instead.\n        \"\"\"\n        # find out the type of the parameter\n        tp = ct.c_uint16()\n        self.pvcam.pl_get_param(self._handle, param, pv.ATTR_TYPE, ct.byref(tp))\n        if tp.value == pv.TYPE_CHAR_PTR:\n            content = str(value)\n        elif tp.value in self.pv_type_to_ctype:\n            # print tp.value\n            content = self.pv_type_to_ctype[tp.value](value)\n        elif tp.value in (pv.TYPE_VOID_PTR, pv.TYPE_VOID_PTR_PTR):\n            raise ValueError(\"Cannot handle arguments of type pointer\")\n        else:\n            raise NotImplementedError(\"Argument of unknown type %d\" % tp.value)\n\n        self.pvcam.pl_set_param(self._handle, param, ct.byref(content))\n\n    def get_enum_available(self, param):\n        \"\"\"\n        Get all the available values for a given enumerated parameter.\n        param (int): parameter ID (cf pv.PARAM_*), it must be an enumerated one\n        return (dict (int -> string)): value to description\n        \"\"\"\n        count = ct.c_uint32()\n        self.pvcam.pl_get_param(self._handle, param, pv.ATTR_COUNT, ct.byref(count))\n\n        ret = {}  # int -> str\n        for i in range(count.value):\n            length = ct.c_uint32()\n            content = ct.c_uint32()\n            self.pvcam.pl_enum_str_length(self._handle, param, i, ct.byref(length))\n            desc = ct.create_string_buffer(length.value)\n            self.pvcam.pl_get_enum_param(self._handle, param, i, ct.byref(content),\n                                         desc, length)\n            ret[content.value] = desc.value\n        return ret\n\n    def exp_check_status(self):\n        \"\"\"\n        Checks the status of the current exposure (acquisition)\n        returns (int): status as in pv.* (cf documentation)\n        \"\"\"\n        status = ct.c_int16()\n        byte_cnt = ct.c_uint32()  # number of bytes already acquired: unused\n        self.pvcam.pl_exp_check_status(self._handle, ct.byref(status), ct.byref(byte_cnt))\n        return status.value\n\n    @staticmethod\n    def _int2version(raw):\n        \"\"\"\n        Convert a raw value into version, according to the pvcam convention\n        raw (int)\n        returns (string)\n        \"\"\"\n        ver = []\n        ver.insert(0, raw & 0x0f)  # lowest 4 bits = trivial version\n        raw >>= 4\n        ver.insert(0, raw & 0x0f)  # next 4 bits = minor version\n        raw >>= 4\n        ver.insert(0, raw & 0xff)  # highest 8 bits = major version\n        return '.'.join(str(x) for x in ver)\n\n    def get_sw_version(self):\n        \"\"\"\n        returns a simplified software version information\n        or None if unknown\n        \"\"\"\n        try:\n            ddi_ver = ct.c_uint16()\n            self.pvcam.pl_ddi_get_ver(ct.byref(ddi_ver))\n            interface = self._int2version(ddi_ver.value)\n        except PVCamError:\n            interface = \"unknown\"\n\n        try:\n            pv_ver = ct.c_uint16()\n            self.pvcam.pl_pvcam_get_ver(ct.byref(pv_ver))\n            sdk = self._int2version(pv_ver.value)\n        except PVCamError:\n            sdk = \"unknown\"\n\n        try:\n            driver = self._int2version(self.get_param(pv.PARAM_DD_VERSION))\n        except PVCamError:\n            driver = \"unknown\"\n\n        return \"driver: %s, interface: %s, SDK: %s\" % (driver, interface, sdk)\n\n    def get_hw_version(self):\n        \"\"\"\n        returns a simplified hardware version information\n        \"\"\"\n        versions = {pv.PARAM_CAM_FW_VERSION: \"firmware\",\n                    # Fails on PI pvcam (although PARAM_DD_VERSION manages to\n                    # read the firmware version inside the kernel)\n                    pv.PARAM_PCI_FW_VERSION: \"firmware board\",\n                    pv.PARAM_CAM_FW_FULL_VERSION: \"firmware (full)\",\n                    pv.PARAM_CAMERA_TYPE: \"camera type\",\n                    }\n        ret = \"\"\n        for pid, name in list(versions.items()):\n            try:\n                value = self.get_param(pid)\n                ret += \"%s: %s \" % (name, value)\n            except PVCamError:\n                #                self._logger.exception(\"param %x cannot be accessed\", pid)\n                pass  # skip\n\n        # TODO: if we really want, we can try to look at the product name if it's\n        # USB: from the name, find in in /dev/ -> read major/minor\n        # -> /sys/dev/char/$major:$minor/device\n        # -> read symlink canonically, remove last directory\n        # -> read \"product\" file\n\n        if ret == \"\":\n            ret = \"unknown\"\n        return ret\n\n    def get_model(self):\n        \"\"\"\n        returns (string): name of the camara\n        \"\"\"\n        model_name = \"Princeton Instruments camera\"\n\n        try:\n            model_name += \" with CCD '%s'\" % self.get_param(pv.PARAM_CHIP_NAME)\n        except PVCamError:\n            pass  # unknown\n\n        try:\n            model_name += \" (s/n: %s)\" % self.get_param(pv.PARAM_SERIAL_NUM)\n        except PVCamError:\n            pass  # unknown\n\n        return model_name\n\n    def get_sensor_size(self):\n        \"\"\"\n        return 2-tuple (int, int): width, height of the detector in pixel\n        \"\"\"\n        width = self.get_param(pv.PARAM_SER_SIZE, pv.ATTR_DEFAULT)\n        height = self.get_param(pv.PARAM_PAR_SIZE, pv.ATTR_DEFAULT)\n        return width, height\n\n    def get_min_resolution(self):\n        \"\"\"\n        return 2-tuple (int, int): width, height of the minimum possible resolution\n        \"\"\"\n        width = self.get_param(pv.PARAM_SER_SIZE, pv.ATTR_MIN)\n        height = self.get_param(pv.PARAM_PAR_SIZE, pv.ATTR_MIN)\n        return width, height\n\n    def get_pixel_size(self):\n        \"\"\"\n        return 2-tuple float, float: width, height of one pixel in m\n        \"\"\"\n        # values from the driver are in nm\n        width = self.get_param(pv.PARAM_PIX_SER_DIST, pv.ATTR_DEFAULT) * 1e-9\n        height = self.get_param(pv.PARAM_PIX_PAR_DIST, pv.ATTR_DEFAULT) * 1e-9\n        return width, height\n\n    def get_temp(self):\n        \"\"\"\n        returns (float) the current temperature of the captor in C\n        \"\"\"\n        # it's in 1/100 of C\n        # with self._online_lock:\n        temp = self.get_param(pv.PARAM_TEMP) / 100\n        return temp\n\n    def get_temp_range(self):\n        mint = self.get_param(pv.PARAM_TEMP_SETPOINT, pv.ATTR_MIN) / 100\n        maxt = self.get_param(pv.PARAM_TEMP_SETPOINT, pv.ATTR_MAX) / 100\n        return mint, maxt\n\n    # High level methods\n    def set_temp_target(self, temp):\n        \"\"\"\n        Change the targeted temperature of the CCD. The cooler the less dark noise.\n        temp (-300 < float < 100): temperature in C, should be within the allowed range\n        \"\"\"\n        assert ((-300 <= temp) and (temp <= 100))\n        # TODO: doublebuff_focus.c example code has big warnings to not read/write\n        # the temperature during image acquisition. We might want to avoid it as\n        # well. (as soon as the READOUT_COMPLETE state is reached, it's fine again)\n\n        # it's in 1/100 of C\n        # TODO: use increment? => doesn't seem to matter\n        self.set_param(pv.PARAM_TEMP_SETPOINT, int(round(temp * 100)))\n\n        # Turn off the cooler if above room temperature\n        try:\n            # Note: doesn't seem to have any effect on the PIXIS\n            if temp >= 20:\n                self.set_param(pv.PARAM_HEAD_COOLING_CTRL, pv.HEAD_COOLING_CTRL_OFF)\n                self.set_param(pv.PARAM_COOLING_FAN_CTRL, pv.COOLING_FAN_CTRL_OFF)\n            else:\n                self.set_param(pv.PARAM_HEAD_COOLING_CTRL, pv.HEAD_COOLING_CTRL_ON)\n                self.set_param(pv.PARAM_COOLING_FAN_CTRL, pv.COOLING_FAN_CTRL_ON)\n        except PVCamError:\n            pass\n\n        temp = self.get_param(pv.PARAM_TEMP_SETPOINT) / 100\n        return float(temp)\n\n    def _get_gains(self):\n        \"\"\"\n        Find the gains supported by the device\n        returns (dict of int -> float): index -> multiplier\n        \"\"\"\n        # Gains are special: they do not use a enum type, just min/max\n        ming = self.get_param(pv.PARAM_GAIN_INDEX, pv.ATTR_MIN)\n        maxg = self.get_param(pv.PARAM_GAIN_INDEX, pv.ATTR_MAX)\n        gains = {}\n        for i in range(ming, maxg + 1):\n            # seems to be correct for PIXIS and ST133\n            gains[i] = 2 ** (i - 1)\n        return gains\n\n    def _set_gain(self, value):\n        \"\"\"\n        VA setter for gain (just save)\n        \"\"\"\n        self._gain = value\n        return value\n\n    def _get_readout_rates(self):\n        \"\"\"\n        Find the readout rates supported by the device\n        returns (dict int -> float): for each index: frequency in Hz\n        Note: this is for the current output amplifier and bit depth\n        \"\"\"\n        # It depends on the port (output amplifier), bit depth, which we\n        # consider both fixed.\n        # PARAM_PIX_TIME (ns): the time per pixel\n        # PARAM_SPDTAB_INDEX: the speed index\n        # The only way to find out the rate of a speed, is to set the speed, and\n        # see the new time per pixel.\n        # Note: setting the spdtab idx resets the gain\n\n        mins = self.get_param(pv.PARAM_SPDTAB_INDEX, pv.ATTR_MIN)\n        maxs = self.get_param(pv.PARAM_SPDTAB_INDEX, pv.ATTR_MAX)\n        # save the current value\n        current_spdtab = self.get_param(pv.PARAM_SPDTAB_INDEX)\n        current_gain = self.get_param(pv.PARAM_GAIN_INDEX)\n\n        rates = {}\n        for i in range(mins, maxs + 1):\n            # Try with this given speed tab\n            self.set_param(pv.PARAM_SPDTAB_INDEX, i)\n            pixel_time = self.get_param(pv.PARAM_PIX_TIME)  # ns\n            if pixel_time == 0:\n                self._logger.warning(\"Camera reporting pixel readout time of 0 ns!\")\n                pixel_time = 1\n            rates[i] = 1 / (pixel_time * 1e-9)\n\n        # restore the current values\n        self.set_param(pv.PARAM_SPDTAB_INDEX, current_spdtab)\n        self.set_param(pv.PARAM_GAIN_INDEX, current_gain)\n        return rates\n\n    def _set_readout_rate(self, value):\n        \"\"\"\n        VA setter for readout rate (just save)\n        \"\"\"\n        self._readout_rate = value\n        return value\n\n    def _get_max_bin(self):\n        \"\"\"\n        return the maximum binning in both directions\n        returns (list of int): maximum binning in height, width\n        \"\"\"\n        chip = self.get_param(pv.PARAM_CHIP_NAME)\n        # FIXME: detect more generally if the detector supports binning or not?\n        if \"InGaAs\" in chip:\n            # InGaAs detectors don't support binning (written in the\n            # specification). In practice, it stops sending images if binning > 1.\n            return (1, 1)\n\n        # other cameras seem to support up to the entire sensor resolution\n        return self.get_sensor_size()\n\n    def _set_binning(self, value):\n        \"\"\"\n        Called when \"binning\" VA is modified. It also updates the resolution so\n        that the AOI is approximately the same.\n        value (int): how many pixels horizontally and vertically\n         are combined to create \"super pixels\"\n        \"\"\"\n        value = self._transposeSizeFromUser(value)\n        prev_binning = self._binning\n        self._binning = value\n\n        # adapt resolution so that the AOI stays the same\n        change = (prev_binning[0] / self._binning[0],\n                  prev_binning[1] / self._binning[1])\n        old_resolution = self._transposeSizeFromUser(self.resolution.value)\n        new_resolution = (int(round(old_resolution[0] * change[0])),\n                          int(round(old_resolution[1] * change[1])))\n\n        self.resolution.value = self._transposeSizeToUser(new_resolution)  # will automatically call _storeSize\n        return self._transposeSizeToUser(value)\n\n    def _storeSize(self, size):\n        \"\"\"\n        Check the size is correct (it should) and store it ready for SetImage\n        size (2-tuple int): Width and height of the image. It will be centred\n         on the captor. It depends on the binning, so the same region has a size\n         twice smaller if the binning is 2 instead of 1. It must be a allowed\n         resolution.\n        \"\"\"\n        full_res = self._shape[:2]\n        resolution = (int(full_res[0] // self._binning[0]),\n                      int(full_res[1] // self._binning[1]))\n        assert ((1 <= size[0]) and (size[0] <= resolution[0]) and\n                (1 <= size[1]) and (size[1] <= resolution[1]))\n\n        # Region of interest\n        # center the image\n        lt = ((resolution[0] - size[0]) // 2,\n              (resolution[1] - size[1]) // 2)\n\n        # the rectangle is defined in normal pixels (not super-pixels) from (0,0)\n        self._image_rect = (lt[0] * self._binning[0], (lt[0] + size[0]) * self._binning[0] - 1,\n                            lt[1] * self._binning[1], (lt[1] + size[1]) * self._binning[1] - 1)\n\n    def _setResolution(self, value):\n        # value = self._transposeSizeFromUser(value)\n        new_res = self.resolutionFitter(value)\n        self._storeSize(new_res)\n        # return self._transposeSizeToUser(new_res)\n        return new_res\n\n    def resolutionFitter(self, size_req):\n        \"\"\"\n        Finds a resolution allowed by the camera which fits best the requested\n          resolution.\n        size_req (2-tuple of int): resolution requested\n        returns (2-tuple of int): resolution which fits the camera. It is equal\n         or bigger than the requested resolution\n        \"\"\"\n        # find maximum resolution (with binning)\n        resolution = self._shape[:2]\n        max_size = (int(resolution[0] // self._binning[0]),\n                    int(resolution[1] // self._binning[1]))\n        min_size = (int(math.ceil(self._min_res[0] / self._binning[0])),\n                    int(math.ceil(self._min_res[1] / self._binning[1])))\n\n        # smaller than the whole sensor\n        size = (min(size_req[0], max_size[0]), min(size_req[1], max_size[1]))\n\n        # bigger than the minimum\n        size = (max(min_size[0], size[0]), max(min_size[0], size[1]))\n\n        return size\n\n    # def _setexposureTime(self, value):\n    #     \"\"\"\n    #     Set the exposure time. It's automatically adapted to a working one.\n    #     exp (0<float): exposure time in seconds\n    #     returns the new exposure time\n    #     \"\"\"\n    #     assert (0 < value)\n    # \n    #     # The checks done in the VA should be enough\n    #     # we cache it until just before the next acquisition\n    #     self.exposure = value\n    #     return self.exposure\n\n    # def _setShutterPeriod(self, period):\n    #     self._shutter_period = period\n    #     return period\n\n    def _need_update_settings(self):\n        \"\"\"\n        returns (boolean): True if _update_settings() needs to be called\n        \"\"\"\n        new_image_settings = self._binning + self._image_rect\n        new_settings = [new_image_settings, self._exposure_time,\n                        self._readout_rate, self._gain, self._shutter_period]\n        return new_settings != self._prev_settings\n\n    def _update_settings(self):\n        \"\"\"\n        Commits the settings to the camera. Only the settings which have been\n        modified are updated.\n        Note: acquisition_lock must be taken, and acquisition must _not_ going on.\n        returns (exposure, region, size):\n                exposure: (float) exposure time in second\n                region (pv.rgn_type): the region structure that can be used to set up the acquisition\n                size (2-tuple of int): the size of the data array that will get acquired\n        \"\"\"\n        (prev_image_settings, prev_exp_time,\n         prev_readout_rate, prev_gain, prev_shut) = self._prev_settings\n\n        if prev_readout_rate != self._readout_rate:\n            self._logger.debug(\"Updating readout rate settings to %f Hz\", self._readout_rate)\n            i = index_closest(self._readout_rate, self._readout_rates)\n            self.set_param(pv.PARAM_SPDTAB_INDEX, i)\n\n            # self._metadata[MD_READOUT_TIME] = 1.0 / self._readout_rate  # s\n            # rate might affect the BPP (although on the PIXIS, it's always 16)\n            # self._metadata[MD_BPP] = self.get_param(pv.PARAM_BIT_DEPTH)\n\n            # If readout rate is changed, gain is reset => force update\n            prev_gain = None\n\n        if prev_gain != self._gain:\n            self._logger.debug(\"Updating gain to %f\", self._gain)\n            i = index_closest(self._gain, self._gains)\n            self.set_param(pv.PARAM_GAIN_INDEX, i)\n            # self._metadata[MD_GAIN] = self._gain\n\n        # prepare image (region)\n        region = pv.rgn_type()\n        # region is 0 indexed\n        region.s1, region.s2, region.p1, region.p2 = self._image_rect\n        region.sbin, region.pbin = self._binning\n        # self._metadata[MD_BINNING] = self._binning  # self._transposeSizeToUser(self._binning)\n        new_image_settings = self._binning + self._image_rect\n        # size = ((self._image_rect[1] - self._image_rect[0] + 1) // self._binning[0],\n        #         (self._image_rect[3] - self._image_rect[2] + 1) // self._binning[1],\n        #         self._number_frames)\n        size = (self._number_frames,\n                (self._image_rect[3] - self._image_rect[2] + 1) // self._binning[1],\n                (self._image_rect[1] - self._image_rect[0] + 1) // self._binning[0]\n                )\n\n        # nothing special for the exposure time\n        # self._metadata[MD_EXP_TIME] = self._exposure_time\n\n        # Activate shutter closure whenever needed:\n        # Shutter closes between exposures iif:\n        # * period between exposures is long enough (>0.1s): to ensure we don't burn the mechanism\n        # * readout time > exposure time/100 (when risk of smearing is possible)\n        readout_time = np.prod(size) / self._readout_rate  # s\n        tot_time = readout_time + self._exposure_time  # reality will be slightly longer\n        self._logger.debug(\"exposure = %f s, readout = %f s\", readout_time, self._exposure_time)\n        try:\n            if tot_time < self._shutter_period:\n                self._logger.info(\"Disabling shutter because it would go at %g Hz\",\n                                  1 / tot_time)\n                self.set_param(pv.PARAM_SHTR_OPEN_MODE, pv.OPEN_PRE_SEQUENCE)\n            elif readout_time < (self._exposure_time / 100):\n                self._logger.info(\"Disabling shutter because readout is %g times \"\n                                  \"smaller than exposure\",\n                                  self._exposure_time / readout_time)\n                self.set_param(pv.PARAM_SHTR_OPEN_MODE, pv.OPEN_PRE_SEQUENCE)\n            elif self.get_param(pv.PARAM_SHTR_OPEN_MODE) != 0:\n                self.set_param(pv.PARAM_SHTR_OPEN_MODE, pv.OPEN_PRE_EXPOSURE)\n                self._logger.info(\"Shutter activated\")\n            else:\n                self._logger.info(\"Shutter closed\")\n        except PVCamError:\n            self._logger.debug(\"Failed to change shutter mode\")\n\n        self._prev_settings = [new_image_settings, self._exposure_time,\n                               self._readout_rate, self._gain, self._shutter_period]\n\n        return self._exposure_time, region, size\n\n    def _allocate_buffer(self, length):\n        \"\"\"\n        length (int): number of bytes requested by pl_exp_setup\n        returns a cbuffer of the right type for an image\n        \"\"\"\n        cbuffer = (ct.c_uint16 * (self._number_frames * length // 2))()  # empty array\n        return cbuffer\n    \n    @staticmethod\n    def _buffer_as_array(cbuffer, size):\n        \"\"\"\n        Converts the buffer allocated for the image as an ndarray. zero-copy\n        size (2-tuple of int): width, height\n        return an ndarray\n        \"\"\"\n        p = ct.cast(cbuffer, ct.POINTER(ct.c_uint16))\n        # dataarray = np.ctypeslib.as_array(p, (size[2], size[1], size[0]))  # np shape is H, W\n        dataarray = np.ctypeslib.as_array(p, size)  # np shape is H, W\n        return dataarray  #\n\n    # def start_flow(self, callback):\n    #     \"\"\"\n    #     Set up the camera and acquireOne a flow of images at the best quality for the given\n    #       parameters. Should not be called if already a flow is being acquired.\n    #     callback (callable (DataArray) no return):\n    #      function called for each image acquired\n    #     \"\"\"\n    #     # if there is a very quick unsubscribe(), subscribe(), the previous\n    #     # thread might still be running\n    #     self.wait_stopped_flow() # no-op if the thread is not running\n    #     self.acquisition_lock.acquire()\n    #\n    #     # Set up thread\n    #     self.acquire_thread = threading.Thread(target=self._acquire_thread_run,\n    #             name=\"PVCam acquire flow thread\",\n    #             args=(callback,))\n    #     self.acquire_thread.start()\n\n    def _init_seq(self):\n        \"\"\"Initialise sequence parameters\"\"\"\n\n        exposure, region, size = self._update_settings()\n        self.pvcam.pl_exp_init_seq()\n        blength = ct.c_uint32()\n        exp_ms = int(math.ceil(exposure * 1e3))  # ms\n        # 1 image, with 1 region\n        self.pvcam.pl_exp_setup_seq(self._handle, self._number_frames, 1, ct.byref(region),\n                                    pv.TIMED_MODE, exp_ms, ct.byref(blength))\n        self._logger.debug(\"acquisition setup report buffer size of %d\", blength.value)\n        cbuffer = self._allocate_buffer(blength.value)  # TODO shall allocate a new buffer every time?\n        assert (blength.value / 2) >= (np.prod(size))\n\n        readout_sw = np.prod(size) * 1.0 / self._readout_rate  # s\n        # tends to be very slightly bigger:\n        readout = self.get_param(pv.PARAM_READOUT_TIME) * 1e-3  # s\n        self._logger.debug(\"exposure of %g s, readout %g s (expected %g s)\", exp_ms * 1e-3, readout, readout_sw)\n        duration = exposure + readout  # seems it actually takes +40ms\n        return exposure, region, size, duration, cbuffer\n\n    # def _acquire_thread_run(self, callback):\n    #     \"\"\"\n    #     The core of the acquisition thread. Runs until acquire_must_stop is set.\n    #     \"\"\"\n    #     need_init = True\n    #     retries = 0\n    #     cbuffer = None\n    #     expected_end = 0\n    #     readout = 0  # s\n    #     try:\n    #         while not self.acquire_must_stop.is_set():\n    #             # need to stop acquisition to update settings\n    #             if need_init or self._need_update_settings():\n    #                 if cbuffer:\n    #                     # finish the seq if it was started\n    #                     self.pvcam.pl_exp_finish_seq(self._handle, cbuffer, None)\n    #                     self.pvcam.pl_exp_uninit_seq()\n    #\n    #                 # With circular buffer, we could go about up to 10% faster, but\n    #                 # everything is more complex (eg: odd buffer size will block the\n    #                 # PIXIS), and not all hardware supports it. It would allow\n    #                 # to do memory allocation during the acquisition, but would\n    #                 # require a memcpy afterwards. So we keep it simple.\n    #\n    #                 exposure, region, size, duration, cbuffer = self._init_seq()\n    #                 need_init = False\n    #\n    #             # Acquire the image\n    #             # Note: might be unlocked slightly too early in case of must_stop,\n    #             # but should be very rare and not too much of a problem hopefully.\n    #             with self._online_lock:\n    #                 self._start_acquisition(cbuffer)\n    #                 start = time.time()\n    #                 metadata = dict(self._metadata) # duplicate\n    #                 metadata[MD_ACQ_DATE] = start\n    #                 expected_end = start + duration\n    #                 timeout = expected_end + 1\n    #                 array = self._buffer_as_array(cbuffer, size, metadata)\n    #\n    #                 # wait a bounded time until the image is acquired\n    #                 try:\n    #                     # warning: in seq mode, it will only report once that status is done,\n    #                     # and then automatically go to acquisition again\n    #                     status = self.exp_check_status()\n    #                     while status in STATUS_IN_PROGRESS:\n    #                         now = time.time()\n    #                         if now > timeout:\n    #                             raise IOError(\"Timeout after %g s\" % (now - start))\n    #                         # check if we should stop (sleeping less and less)\n    #                         left = expected_end - now\n    #                         if self.acquire_must_stop.wait(max(0.01, left / 2)):\n    #                             raise CancelledError()\n    #                         status = self.exp_check_status()\n    #\n    #                     if status != pv.READOUT_COMPLETE:\n    #                         raise IOError(\"Acquisition status is unexpected %d\" % status)\n    #                 except (IOError, PVCamError):\n    #                     self.pvcam.pl_exp_abort(self._handle, pv.CCS_NO_CHANGE)\n    #                     if retries > 5:\n    #                         self._logger.error(\"Too many failures to acquire an image\")\n    #                         raise\n    #\n    #                     self._logger.exception(\"trying again to acquire image after error\")\n    #                     try:\n    #                         self.pvcam.pl_exp_abort(self._handle, pv.CCS_HALT_CLOSE_SHTR)\n    #                     except PVCamError:\n    #                         pass\n    #                     self._online_lock.release()\n    #\n    #                     self.pvcam.pl_exp_finish_seq(self._handle, cbuffer, None)\n    #                     self.pvcam.pl_exp_uninit_seq()\n    #\n    #                     # Always assume the \"worse\": the camera has been turned off\n    #                     self.Reinitialize() #returns only once the camera is working again\n    #                     self._online_lock.acquire()\n    #\n    #                     retries += 1\n    #                     cbuffer = None\n    #                     need_init = True\n    #                     continue\n    #\n    #             retries = 0\n    #             self._logger.debug(\"image acquired successfully after %g s\", time.time() - start)\n    #             callback(self._transposeDAToUser(array))\n    #\n    #             # force the GC to non-used buffers, for some reason, without this\n    #             # the GC runs only after we've managed to fill up the memory\n    #             gc.collect()\n    #     except CancelledError:\n    #         # received a must-stop event\n    #         pass\n    #     except Exception:\n    #         self._logger.exception(\"Unexpected failure during image acquisition\")\n    #     else:\n    #         # we know it finished fine, so stop imediately\n    #         # (also stop the pvcam background thread in _seq acquisition)\n    #         self.pvcam.pl_exp_abort(self._handle, pv.CCS_HALT_CLOSE_SHTR)\n    #     finally:\n    #         # ending cleanly\n    #\n    #         # if end is soon, just wait for it (because the camera hates\n    #         # being aborted during the end of acquisition (ie, during readout?)\n    #         left = expected_end - time.time()\n    #         # proportional to readout\n    #         margin = max(readout * 2, 2) # at least 2s\n    #         while left < margin and left > -1: # between margin s ahead up to 1 s late\n    #             if not self.exp_check_status() in STATUS_IN_PROGRESS:\n    #                 self._logger.debug(\"not aborting acquisition as it's already finished\")\n    #                 break\n    #             time.sleep(0.01)\n    #             left = expected_end - time.time()\n    #         else:\n    #             try:\n    #                 if self.exp_check_status() in STATUS_IN_PROGRESS:\n    #                     self._logger.debug(\"aborting acquisition, left = %g s\", left)\n    #                     self.pvcam.pl_exp_abort(self._handle, pv.CCS_HALT_CLOSE_SHTR)\n    #             except PVCamError:\n    #                 self._logger.exception(\"Failed to abort acquisition\")\n    #                 pass # status reported an error\n    #\n    #         # only required with multiple images, but just in case, we do it\n    #         try:\n    #             if cbuffer:\n    #                 self.pvcam.pl_exp_finish_seq(self._handle, cbuffer, None)\n    #         except PVCamError:\n    #             self._logger.exception(\"Failed to finish the acquisition properly\")\n    #\n    #         try:\n    #             if cbuffer:\n    #                 self.pvcam.pl_exp_uninit_seq()\n    #         except PVCamError:\n    #             self._logger.exception(\"Failed to finish the acquisition properly\")\n    #\n    #         self.acquisition_lock.release()\n    #         self._logger.debug(\"Acquisition thread closed\")\n    #         self.acquire_must_stop.clear()\n\n    def capture(self):\n        \"\"\"Modified from odemis, but removing the locking\"\"\"\n        exposure, region, size, duration, cbuffer = self._init_seq()\n        self.pvcam.pl_exp_start_seq(self._handle, cbuffer)\n        start = time.time()\n        # metadata = dict(self._metadata)  # duplicate\n        # metadata[MD_ACQ_DATE] = start\n        expected_end = start + duration\n        timeout = expected_end + 1\n\n        # wait a bounded time until the image is acquired\n        try:\n            # warning: in seq mode, it will only report once that status is done,\n            # and then automatically go to acquisition again\n            status = self.exp_check_status()\n            while status in STATUS_IN_PROGRESS:\n                now = time.time()\n                if now > timeout:\n                    raise IOError(\"Timeout after %g s\" % (now - start))\n                # check if we should stop (sleeping less and less)\n                left = expected_end - now\n                if self.acquire_must_stop.wait(max(0.01, left / 2)):\n                    raise CancelledError()\n                status = self.exp_check_status()\n\n            if status != pv.READOUT_COMPLETE:\n                raise IOError(\"Acquisition status is unexpected %d\" % status)\n        except (IOError, PVCamError):\n            try:\n                self.pvcam.pl_exp_abort(self._handle, pv.CCS_HALT_CLOSE_SHTR)\n            except PVCamError:\n                self._logger.warn(\"Failed aborting\")\n\n        data_array = self._buffer_as_array(cbuffer, size)\n\n        try:\n            if cbuffer:\n                self.pvcam.pl_exp_finish_seq(self._handle, cbuffer, None)\n        except PVCamError:\n            self._logger.exception(\"Failed to finish the acquisition properly\")\n\n        try:\n            if cbuffer:\n                self.pvcam.pl_exp_uninit_seq()\n        except PVCamError:\n            self._logger.exception(\"Failed to finish the acquisition properly\")\n\n        self.current_image = data_array\n\n        return data_array\n\n    def dark_exposure(self):\n        _current_value = self.get_param(pv.PARAM_SHTR_OPEN_MODE)\n        self.set_param(pv.PARAM_SHTR_OPEN_MODE, pv.OPEN_NEVER)\n        array = self.capture()\n        self.background = array\n        self.set_param(pv.PARAM_SHTR_OPEN_MODE, _current_value)\n        return array\n\n    # def _start_acquisition(self, cbuf):\n    #     \"\"\"\n    #     Triggers the start of the acquisition on the camera. If the DataFlow\n    #      is synchronized, wait for the Event to be triggered.\n    #     cbuf (ctype): buffer to contain the data\n    #     raises CancelledError if the acquisition must stop\n    #     \"\"\"\n    #     assert cbuf\n    #\n    #     # catch up late events if we missed the start\n    #     if self._late_events:\n    #         event_time = self._late_events.pop()\n    #         self._logger.warning(\"starting acquisition late by %g s\", time.time() - event_time)\n    #         self.pvcam.pl_exp_start_seq(self._handle, cbuf)\n    #         return\n    #\n    #     self._cbuffer = cbuf\n    #     try:\n    #         # wait until onEvent was called (it will directly start acquisition)\n    #         # or must stop\n    #         while not self.acquire_must_stop.is_set():\n    #             if not self.data._sync_event: # not synchronized (anymore)?\n    #                 self._logger.debug(\"starting acquisition\")\n    #                 self.pvcam.pl_exp_start_seq(self._handle, cbuf)\n    #                 return\n    #             # doesn't need to be very frequent, just not too long to delay\n    #             # cancelling the acquisition, and to check for the event frequently\n    #             # enough\n    #             if self._got_event.wait(0.01):\n    #                 self._got_event.clear()\n    #                 return\n    #     finally:\n    #         self._cbuffer = None\n    #\n    #     raise CancelledError()\n\n    # @oneway\n    # def onEvent(self):\n    #     \"\"\"\n    #     Called by the Event when it is triggered\n    #     \"\"\"\n    #     cbuf = self._cbuffer\n    #     # FIXME: there is a small chance for race conditions:\n    #     # (onEvent) cbuf is None\n    #     # (start acq) no late_events\n    #     # (start acq) set cbuf\n    #     # (start acq) wait\n    #     # (onEvent) add late events & return\n    #     # => need lock (or something else?)\n    #     if not cbuf:\n    #         if self.acquire_thread and self.acquire_thread.isAlive():\n    #             self._logger.warning(\"Received synchronization event but acquisition not ready\")\n    #             # queue the events, it's bad but less bad than skipping it\n    #             self._late_events.append(time.time())\n    #         return\n    #\n    #     self._logger.debug(\"starting sync acquisition\")\n    #     self.pvcam.pl_exp_start_seq(self._handle, cbuf)\n    #     self._got_event.set() # let the acquisition thread know it's starting\n    #\n    # def req_stop_flow(self):\n    #     \"\"\"\n    #     Cancel the acquisition of a flow of images: there will not be any notify() after this function\n    #     Note: the thread should be already running\n    #     Note: the thread might still be running for a little while after!\n    #     \"\"\"\n    #     assert not self.acquire_must_stop.is_set()\n    #     self.acquire_must_stop.set()\n    #\n    # def wait_stopped_flow(self):\n    #     \"\"\"\n    #     Waits until the end acquisition of a flow of images. Calling from the\n    #      acquisition callback is not permitted (it would cause a dead-lock).\n    #     \"\"\"\n    #     if not self.acquire_thread: # no thread ever created\n    #         return\n    #\n    #     # \"if\" is to not wait if it's already finished\n    #     if self.acquire_must_stop.is_set():\n    #         self.acquire_thread.join(20) # 20s timeout for safety\n    #         if self.acquire_thread.isAlive():\n    #             raise OSError(\"Failed to stop the acquisition thread\")\n    #         # ensure it's not set, even if the thread died prematurately\n    #         self.acquire_must_stop.clear()\n\n    @staticmethod\n    def scan():\n        \"\"\"\n        List all the available cameras.\n        Note: it's not recommended to call this method when cameras are being used\n        return (list of 2-tuple: name (strin), device number (int))\n        \"\"\"\n        pvcam = PVCamDLL()\n        num_cam = ct.c_short()\n        pvcam.pl_cam_get_total(ct.byref(num_cam))\n        print(\"Found %d devices.\" % num_cam.value)\n\n        cameras = []\n        for i in range(num_cam.value):\n            cam_name = ct.create_string_buffer(pv.CAM_NAME_LEN)\n            try:\n                pvcam.pl_cam_get_name(i, cam_name)\n            except PVCamError:\n                print(\"Couldn't access camera %d\" % i)\n\n            # TODO: append the resolution to the name of the camera?\n            cameras.append((cam_name.value, {\"device\": i}))\n\n        return cameras",
  "class Pvcam(CameraRoiScale, PvcamSdk):\n    metadata_property_names = ('exposure', 'binning', 'roi')\n\n    def __init__(self, device, **kwargs):\n        # super(Pvcam, self).__init__(device, logger=self._logger)\n        CameraRoiScale.__init__(self)\n        PvcamSdk.__init__(self, device, logger=self._logger)\n        self.background = None\n        self.backgrounded = False\n\n    def raw_snapshot(self):\n        \"\"\"\n        If only one frame, returns a 2D array. If multiple frames, returns a 3D array, where the first dimension is\n        frame number\n        :return: ndarray\n        \"\"\"\n        array = self.capture()\n        if array.shape[0] == 1:\n            array = array[0]\n        return True, array\n\n    def filter_function(self, frame):\n        if self.backgrounded:\n            return np.asarray(frame, float) - np.asarray(self.background, float)\n        else:\n            return frame\n\n    def get_camera_parameter(self, parameter_name):\n        return self.get_param(getattr(pv, parameter_name))\n\n    def set_camera_parameter(self, parameter_name, parameter_value):\n        try:\n            self.set_param(getattr(pv, parameter_name), getattr(pv, parameter_value))\n        except Exception as e:\n            self._logger.warn('paramter ' +parameter_name+' could not be set with the value '+parameter_value+\n                     ' due to error '+str(e))\n\n    def get_control_widget(self):\n        return pvcamUI(self)\n\n    def get_preview_widget(self):\n        self._logger.debug('Getting preview widget')\n        if self._preview_widgets is None:\n            self._preview_widgets = WeakSet()\n        new_widget = DisplayWidgetRoiScale()\n        self._preview_widgets.add(new_widget)\n\n        return new_widget\n\n    @NotifiedProperty\n    def roi(self):\n        return self._image_rect\n\n    @roi.setter\n    def roi(self, value):\n        self._image_rect = value\n\n    @property\n    def binning(self):\n        return self._binning\n\n    @binning.setter\n    def binning(self, value):\n        self._binning = value",
  "class pvcamUI(QtWidgets.QWidget, UiTools):\n\n    def __init__(self, camera):\n        assert isinstance(camera, Pvcam), \"instrument must be an camera\"\n        self._logger = create_logger(\"pvcam.GUI\")\n\n        super(pvcamUI, self).__init__()\n        self.captureThread = None\n        self.camera = camera\n        self.DisplayWidget = None\n\n        self._binning_changed = False\n        self._prev_bin = camera.binning\n\n        uic.loadUi((os.path.dirname(__file__) + '/camera.ui'), self)\n        self._setup_signals()\n        self.data_file = None\n        self.save_all_parameters = False\n        self.backgrounded = False\n\n        self._func_dict = {}\n        for param in self.camera.metadata_property_names:\n            try:\n                func = self.callback_to_update_prop(param)\n                self._func_dict[param] = func\n                register_for_property_changes(self.camera, param, self._func_dict[param])\n            except AssertionError:\n                self._logger.info(\"%s is not a property so cannot be monitored\" % param)\n        # register_for_property_changes(self.camera, \"latest_raw_frame\", self.update_image)\n\n    def __del__(self):\n        self._stopTemperatureThread = True\n        if self.DisplayWidget is not None:\n            self.DisplayWidget.hide()\n            self.DisplayWidget.close()\n\n    def _setup_signals(self):\n        # self.comboBoxAcqMode.activated.connect(self.AcquisitionModeChanged)\n        # self.comboBoxReadMode.activated.connect(self.ReadModeChanged)\n        # self.comboBoxTrigMode.activated.connect(self.TrigChanged)\n        # self.spinBoxNumFrames.valueChanged.connect(self.NumFramesChanged)\n        # self.spinBoxNumFrames.setRange(1, 1000000)\n        # self.spinBoxNumAccum.valueChanged.connect(self.NumAccumChanged)\n        # self.spinBoxNumRows.valueChanged.connect(self.NumRowsChanged)\n        # self.spinBoxCenterRow.valueChanged.connect(self.NumRowsChanged)\n        self.checkBoxROI.stateChanged.connect(self.ROI)\n        # self.checkBoxCrop.stateChanged.connect(self.IsolatedCrop)\n        # self.checkBoxCooler.stateChanged.connect(self.Cooler)\n        # # self.checkBoxAutoExp.stateChanged.connect(self.AutoExpose)\n        # self.checkBoxEMMode.stateChanged.connect(self.OutputAmplifierChanged)\n        # self.spinBoxEMGain.valueChanged.connect(self.EMGainChanged)\n        self.lineEditExpT.editingFinished.connect(self.changed_exposure)\n        # self.lineEditExpT.setValidator(QtGui.QDoubleValidator())\n        self.pushButtonDiv5.clicked.connect(lambda: self.changed_exposure('/'))\n        self.pushButtonTimes5.clicked.connect(lambda: self.changed_exposure('x'))\n        self.spinBox_binx.valueChanged.connect(self.changed_binning)\n        self.spinBox_biny.valueChanged.connect(self.changed_binning)\n\n        self.pushButtonCapture.clicked.connect(self.Capture)\n        self.pushButtonLive.clicked.connect(self.Live)\n        self.pushButtonAbort.clicked.connect(self.Abort)\n        self.save_pushButton.clicked.connect(self.Save)\n        self.pushButtonTakeBG.clicked.connect(self.take_background)\n        self.checkBoxRemoveBG.stateChanged.connect(self.remove_background)\n        # self.referesh_groups_pushButton.clicked.connect(self.update_groups_box)\n\n    def update_exposure(self, value):\n        self.lineEditExpT.setText(str(value))\n\n    def update_binning(self, value):\n        self._binning_changed = True\n        self.spinBox_binx.setValue(value[0])\n        self.spinBox_biny.setValue(value[1])\n\n    def callback_to_update_prop(self, propname):\n        \"\"\"Return a callback function that refreshes the named parameter.\"\"\"\n\n        def callback(value=None):\n            # print 'Callback: ', propname\n            getattr(self, 'update_' + propname)(value)\n\n        return callback\n\n    def changed_binning(self):\n        if not self._binning_changed:\n            self._binning_changed = True\n            self._prev_bin = self.camera.binning\n        xbin = self.spinBox_binx.value()\n        ybin = self.spinBox_biny.value()\n        self.camera.binning = (xbin, ybin)\n\n    def changed_exposure(self, variable=None):\n        if variable is None:\n            exp_time = float(self.lineEditExpT.text())\n        elif variable == 'x':\n            exp_time = float(self.lineEditExpT.text()) * 5\n        elif variable == '/':\n            exp_time = float(self.lineEditExpT.text()) / 5\n        else:\n            raise ValueError(\"Unrecognised exposure time\")\n        self.camera.exposure = exp_time\n        self.update_exposure(exp_time)\n\n    def take_background(self):\n        # self.camera.background = self.camera.dark_exposure()\n        self.camera.dark_exposure()\n        self.backgrounded = True\n        self.checkBoxRemoveBG.setChecked(True)\n\n    def remove_background(self):\n        if self.checkBoxRemoveBG.isChecked():\n            self.camera.backgrounded = True\n        else:\n            self.camera.backgrounded = False\n\n    def Save(self):\n        if self.data_file is None:\n            self.data_file = df.current()\n        data = self.camera.current_image\n\n        if self.lineEdit_groupname.text():\n            group = self.data_file.create_group(self.lineEdit_groupname.text())\n        else:\n            group = self.data_file\n\n        if self.lineEdit_datasetname.text():\n            dataset_name = self.lineEdit_datasetname.text()\n        else:\n            idx = 1\n            while \"pvcam%d\" % idx in list(group.keys()):\n                idx += 1\n            dataset_name = \"pvcam%d\" % idx\n\n        if self.backgrounded:\n            self._logger.info(\"Saving backgrounded image. Remember to save the background separately\")\n            data = np.array(data, np.float)\n            data -= self.camera.background\n\n        try:\n            data_set = group.create_dataset(name=dataset_name, data=data)\n            if self.checkBox_attrs.isChecked():\n                attrs = dict()\n                for param in self.camera.metadata_property_names:\n                    attrs[param] = getattr(self.camera, param)\n                if self.description_plainTextEdit.toPlainText():\n                    attrs['Description'] = self.description_plainTextEdit.toPlainText()\n                df.attributes_from_dict(data_set, attrs)\n        except Exception as e:\n            self._logger.warn(e)\n\n    def ROI(self):\n        if self.checkBoxROI.isChecked():\n            self.camera.roi = self.camera.gui_roi\n        else:\n            shape = self.camera._shape\n            self.camera.roi = (0, shape[0] - 1, 0, shape[1] - 1)\n\n    def Capture(self):\n        self.camera.raw_image(update_latest_frame=True)\n\n    def Live(self):\n        self.camera.live_view = True\n\n    def Abort(self):\n        self.camera.live_view = False",
  "def __init__(self, errno, strerror, *args, **kwargs):\n        super(PVCamError, self).__init__(errno, strerror, *args, **kwargs)\n        self.args = (errno, strerror)",
  "def __str__(self):\n        return self.args[1]",
  "def __init__(self):\n        if os.name == \"nt\":\n            ct.WinDLL.__init__(self, \"pvcam32\")\n            self.pl_pvcam_init()\n        else:\n            raise OSError('Operating system not recognised')",
  "def pv_errcheck(self, result, func, *args):\n        \"\"\"\n        Analyse the return value of a call and raise an exception in case of\n        error.\n        Follows the ctypes.errcheck callback convention\n        \"\"\"\n        if not result:  # functions return (rs_bool = int) False on error\n            try:\n                err_code = self.pl_error_code()\n            except Exception:\n                raise PVCamError(0, \"Call to %s failed\" % func.__name__)\n            # res = False\n            try:\n                err_mes = ct.create_string_buffer(pv.ERROR_MSG_LEN)\n                res = self.pl_error_message(err_code, err_mes)\n                if res:\n                    raise PVCamError(result, \"Call to %s failed with error code %d: %s\" %\n                                     (func.__name__, err_code, err_mes.value))\n            except Exception:\n                # if not res:\n                raise PVCamError(result, \"call to %s failed with unknown error code %d\" %\n                                     (func.__name__, err_code))\n\n        return result",
  "def __getitem__(self, name):\n        try:\n            func = super(PVCamDLL, self).__getitem__(name)\n        except Exception:\n            raise AttributeError(\"Failed to find %s\" % (name,))\n        func.__name__ = name\n        if name not in self.err_funcs:\n            func.errcheck = self.pv_errcheck\n        return func",
  "def reinit(self):\n        \"\"\"\n        Does a fast uninit/init cycle\n        \"\"\"\n        try:\n            self.pl_pvcam_uninit()\n        except PVCamError:\n            pass  # whatever\n        try:\n            self.pl_pvcam_init()\n        except PVCamError:\n            pass",
  "def __del__(self):\n        try:\n            self.pl_pvcam_uninit()\n        except:\n            self._logger.exception(\"Failed during PVCam uninitialization\")\n            pass",
  "def __init__(self, device, *args, **kwargs):\n        \"\"\"\n        Initialises the device\n        device (int or string): number of the device to open, as defined in\n         pvcam, cf scan(), or the name of the device (as in /dev/).\n        Raise an exception if the device cannot be opened.\n        \"\"\"\n        self.pvcam = PVCamDLL()\n        self.current_image = None\n        if \"logger\" in kwargs:\n            self._logger = kwargs[\"logger\"]\n        elif not hasattr(self, \"_logger\"):\n            self._logger = create_logger(\"PvcamSdk\")\n            self._logger.setLevel(\"DEBUG\")\n\n        # so that it's really not possible to use this object in case of error\n        self._handle = None\n        self._temp_timer = None\n        # pick the right selection method depending on the type of \"device\"\n        if isinstance(device, int):\n            try:\n                self._devname = self.cam_get_name(device)  # for reinit\n            except PVCamError:\n                raise Exception(\"Failed to find PI PVCam camera (%d)\"\n                                \"Check the device is turned on and connected to \"\n                                \"the computer. \"\n                                \"You might need to turn it off and on again.\"\n                                % (device))\n        elif isinstance(device, str):\n            # # check the file exists\n            # if not os.path.exists(\"/dev/\" + device):\n            #     raise Exception(\"Failed to find PI PVCam camera %s (at %s). \"\n            #                   \"Check the device is turned on and connected to \"\n            #                   \"the computer. \"\n            #                   \"You might need to turn it off and on again.\"\n            #                   % (name, device))\n            self._devname = device\n        else:\n            raise ValueError(\"Unexpected type for device: %s\" % device)\n\n        try:\n            self._logger.info(\"Initializing camera, can be long (~15 s)...\")\n            self._handle = self.cam_open(self._devname, pv.OPEN_EXCLUSIVE)\n            # raises an error if camera has a problem\n            self.pvcam.pl_cam_get_diags(self._handle)\n        except PVCamError as e:\n            self._logger.info(\"PI camera seems connected but not responding, \"\n                              \"you might want to try turning it off and on again.\")\n            print(e)\n            raise IOError(\"Failed to open PVCam camera %s (%s)\" % (device, self._devname))\n\n        self._logger.info(\"Opened device %s successfully\", device)\n\n        # Describe the camera\n        # up-to-date metadata to be included in dataflow\n        # self._metadata = {MD_HW_NAME: self.getModelName()}\n\n        # drivers\n        self._swVersion = self.get_sw_version()\n        self._hwVersion = self.get_hw_version()\n        self.resolution = self.get_sensor_size()\n\n        # setup everything best (fixed)\n        self._prev_settings = [None, None, None, None, None]  # image, exposure, readout, gain, shutter period\n        # Bit depth is between 6 and 16, but data is _always_ uint16\n        self._shape = self.resolution + (2 ** self.get_param(pv.PARAM_BIT_DEPTH),)\n\n        # put the detector pixelSize\n        self.pixelSize = self.get_pixel_size()\n\n        # to be used to separate acquisition and offline-only parameters (like PARAM_TEMP)\n        # self._online_lock = threading.Lock()\n\n        # Strong cooling for low (image) noise\n        try:\n            self.temperature = self.get_temp()\n        except PVCamError:\n            self._logger.debug(\"Camera doesn't seem to provide temperature information\")\n\n        self._setStaticSettings()\n\n        # gain\n        self._gains = self._get_gains()\n        gain_choices = set(self._gains.values())\n        self._gain = min(gain_choices)  # default to low gain (low noise)\n        # self.gain = CameraParameter('gain')  # model.FloatEnumerated(self._gain, gain_choices, unit=\"\", setter=self._setGain)\n        self._set_gain(self._gain)\n\n        # read out rate\n        self._readout_rates = self._get_readout_rates()  # needed by _setReadoutRate()\n        ror_choices = set(self._readout_rates.values())\n        self._readout_rate = max(ror_choices)  # default to fast acquisition\n        # self.readoutRate = model.FloatEnumerated(self._readout_rate, ror_choices,\n        #                                          unit=\"Hz\", setter=self._setReadoutRate)\n        self._set_readout_rate(self._readout_rate)\n\n        # binning is needed for _setResolution()\n        self._binning = (1, 1)  # px\n        max_bin = self._get_max_bin()\n        self._image_rect = (0, self.resolution[0] - 1, 0, self.resolution[1] - 1)\n        self._number_frames = 1\n\n        self._min_res = self.get_min_resolution()\n        minr = (int(math.ceil(self._min_res[0] / max_bin[0])),\n                int(math.ceil(self._min_res[1] / max_bin[1])))\n        # need to be before binning, as it is modified when changing binning\n        #                   [self._transposeSizeToUser(minr),\n        #                    self._transposeSizeToUser(resolution)],\n        #                                      setter=self._setResolution)\n        self._setResolution(self.resolution)\n        self.background = np.zeros(self.resolution)\n\n        # 2D binning is like a \"small resolution\"\n        self.binning = self._binning  # model.ResolutionVA(self._transposeSizeToUser(self._binning),\n        #                    [self._transposeSizeToUser((1, 1)),\n        #                     self._transposeSizeToUser(max_bin)],\n        #                                   setter=self._setBinning)\n\n        # default values try to get live microscopy imaging more likely to show something\n        try:\n            minexp = self.get_param(pv.PARAM_EXP_MIN_TIME)  # s\n        except PVCamError:\n            # attribute doesn't exist\n            minexp = 0  # same as the resolution\n        minexp = max(1e-3, minexp)  # at least 1 x the exposure resolution (1 ms)\n        # exposure is represented by unsigned int\n        maxexp = (2 ** 32 - 1) * 1e-3  # s\n        range_exp = (minexp, maxexp)  # s\n        self._exposure_time = 0.01  # s\n        # self.exposureTime = model.FloatContinuous(self.exposure, range_exp,\n        #                                           unit=\"s\", setter=self._setexposureTime)\n\n        # To control the shutter: select the maximum frequency, aka minimum\n        # period for the shutter. If it the acquisition time is below, the\n        # shutter stays open all the time. So:\n        # 0 => shutter always active\n        # big value => shutter always opened\n        self._shutter_period = 0.1\n        # self.shutterMinimumPeriod = model.FloatContinuous(self._shutter_period, [0, 10],\n        #                                       unit=\"s\", setter=self._setShutterPeriod)\n        self.acquisition_lock = threading.Lock()\n        self.acquire_must_stop = threading.Event()\n        self.acquire_thread = None\n        # for synchronized acquisition\n        self._cbuffer = None\n        # self._got_event = threading.Event()\n        # self._late_events = collections.deque() # events which haven't been handled yet\n\n        self.data = None  # PVCamDataFlow(self)\n        # Convenience event for the user to connect and fire\n        # self.softwareTrigger = model.Event()\n        self._logger.debug(\"Camera component ready to use.\")",
  "def __del__(self):\n        if self._temp_timer:\n            self._temp_timer.cancel()\n            self._temp_timer = None\n\n        if self._handle is not None:\n            # don't touch the temperature target/cooling\n\n            # stop the acquisition thread if needed\n            self.acquire_must_stop.set()\n            # self.wait_stopped_flow()\n\n            self._logger.debug(\"Shutting down the camera\")\n            self.pvcam.pl_cam_close(self._handle)\n            self._handle = None\n            del self.pvcam",
  "def exposure(self):\n        return self._exposure_time",
  "def exposure(self, value):\n        self._exposure_time = value",
  "def number_frames(self):\n        return self._number_frames",
  "def number_frames(self, value):\n        self._number_frames = value",
  "def _setStaticSettings(self):\n        \"\"\"\n        Set up all the values that we don't need to change after.\n        Should only be called at initialisation\n        \"\"\"\n        # Set the output amplifier to lowest noise\n        try:\n            # Try to set to low noise, if existing, otherwise: default value\n            aos = self.get_enum_available(pv.PARAM_READOUT_PORT)\n            if pv.READOUT_PORT_LOW_NOISE in aos:\n                self.set_param(pv.PARAM_READOUT_PORT, pv.READOUT_PORT_LOW_NOISE)\n            else:\n                ao = self.get_param(pv.PARAM_READOUT_PORT, pv.ATTR_DEFAULT)\n                self.set_param(pv.PARAM_READOUT_PORT, ao)\n            self._output_amp = self.get_param(pv.PARAM_READOUT_PORT)\n        except PVCamError:\n            self._logger.debug(\"Failed to change readout speed\")\n\n        # Shutter mode (could be an init parameter?)\n        try:\n            # TODO: if the the shutter is in Pre-exposure mode, a short exposure\n            # time can burn it.\n            self.set_param(pv.PARAM_SHTR_OPEN_MODE, pv.OPEN_PRE_SEQUENCE)\n        except PVCamError:\n            self._logger.debug(\"Failed to change shutter mode\")\n\n        # Set to simple acquisition mode\n        self.set_param(pv.PARAM_PMODE, pv.PMODE_NORMAL)\n        # In PI cameras, this is fixed (so read-only)\n        if self.get_param_access(pv.PARAM_CLEAR_MODE) == pv.ACC_READ_WRITE:\n            self._logger.debug(\"Setting clear mode to pre sequence\")\n            # TODO: should be done pre-exposure? As we are not closing the shutter?\n            self.set_param(pv.PARAM_CLEAR_MODE, pv.CLEAR_PRE_EXPOSURE)\n\n        # set the exposure resolution. (choices are us, ms or s) => ms is best\n        # for life imaging (us allows up to 71min)\n        self.set_param(pv.PARAM_EXP_RES_INDEX, pv.EXP_RES_ONE_MILLISEC)",
  "def Reinitialize(self):\n        \"\"\"\n        Waits for the camera to reappear and reinitialise it. Typically\n        useful in case the user switched off/on the camera.\n        \"\"\"\n        # stop trying to read the temperature while we reinitialize\n        if self._temp_timer is not None:\n            self._temp_timer.cancel()\n            self._temp_timer = None\n\n        try:\n            self.pvcam.pl_cam_close(self._handle)\n        except PVCamError:\n            pass\n        self._handle = None\n\n        # PVCam only update the camera list after uninit()/init()\n        while True:\n            self._logger.info(\"Waiting for the camera to reappear\")\n            self.pvcam.reinit()\n            try:\n                self._handle = self.cam_open(self._devname, pv.OPEN_EXCLUSIVE)\n                break  # succeeded!\n            except PVCamError:\n                time.sleep(1)\n\n        # reinitialise the sdk\n        self._logger.info(\"Trying to reinitialise the camera %s...\", self._devname)\n        try:\n            self.pvcam.pl_cam_get_diags(self._handle)\n        except PVCamError:\n            self._logger.info(\"Reinitialisation failed\")\n            raise\n\n        self._logger.info(\"Reinitialisation successful\")\n\n        # put back the settings\n        self._prev_settings = [None, None, None, None, None]\n        self._setStaticSettings()",
  "def cam_get_name(self, num):\n        \"\"\"\n        return the name, from the device number\n        num (int >= 0): camera number\n        return (string): name\n        \"\"\"\n        assert (num >= 0)\n        cam_name = ct.create_string_buffer(pv.CAM_NAME_LEN)\n        self.pvcam.pl_cam_get_name(num, cam_name)\n        return cam_name.value",
  "def cam_open(self, name, mode):\n        \"\"\"\n        Reserve and initializes the camera hardware\n        name (string): camera name\n        mode (int): open mode\n        returns (int): handle\n        \"\"\"\n        handle = ct.c_int16()\n        self.pvcam.pl_cam_open(name, ct.byref(handle), mode)\n        return handle",
  "def get_param(self, param, value=pv.ATTR_CURRENT):\n        \"\"\"\n        Read the current (or other) value of a parameter.\n        Note: for the enumerated parameters, this it the actual value, not the\n        index.\n        param (int): parameter ID (cf pv.PARAM_*)\n        value (int from pv.ATTR_*): which value to read (current, default, min, max, increment)\n        return (value): the value of the parameter, whose type depend on the parameter\n        \"\"\"\n        assert (value in (pv.ATTR_DEFAULT, pv.ATTR_CURRENT, pv.ATTR_MIN,\n                          pv.ATTR_MAX, pv.ATTR_INCREMENT))\n\n        # find out the type of the parameter\n        tp = ct.c_uint16()\n        self.pvcam.pl_get_param(self._handle, param, pv.ATTR_TYPE, ct.byref(tp))\n        if tp.value == pv.TYPE_CHAR_PTR:\n            # a string => need to find out the length\n            count = ct.c_uint32()\n            self.pvcam.pl_get_param(self._handle, param, pv.ATTR_COUNT, ct.byref(count))\n            content = ct.create_string_buffer(count.value)\n        elif tp.value in self.pv_type_to_ctype:\n            # print 'Why?: ', tp.value\n            content = self.pv_type_to_ctype[tp.value]()\n        elif tp.value in (pv.TYPE_VOID_PTR, pv.TYPE_VOID_PTR_PTR):\n            raise ValueError(\"Cannot handle arguments of type pointer\")\n        else:\n            raise NotImplementedError(\"Argument of unknown type %d\" % tp.value)\n\n        # read the parameter\n        self.pvcam.pl_get_param(self._handle, param, value, ct.byref(content))\n        return content.value",
  "def get_param_access(self, param):\n        \"\"\"\n        gives the access rights for a given parameter.\n        param (int): parameter ID (cf pv.PARAM_*)\n        returns (int): value as in pv.ACC_*\n        \"\"\"\n        rights = ct.c_uint16()\n        self.pvcam.pl_get_param(self._handle, param, pv.ATTR_ACCESS, ct.byref(rights))\n        return rights.value",
  "def set_param(self, param, value):\n        \"\"\"\n        Write the current value of a parameter.\n        Note: for the enumerated parameter, this is the actual value to set, not\n        the index.\n        param (int): parameter ID (cf pv.PARAM_*)\n        value (should be of the right type): value to write\n        Warning: it seems to not always complain if the value written is incorrect,\n        just using default instead.\n        \"\"\"\n        # find out the type of the parameter\n        tp = ct.c_uint16()\n        self.pvcam.pl_get_param(self._handle, param, pv.ATTR_TYPE, ct.byref(tp))\n        if tp.value == pv.TYPE_CHAR_PTR:\n            content = str(value)\n        elif tp.value in self.pv_type_to_ctype:\n            # print tp.value\n            content = self.pv_type_to_ctype[tp.value](value)\n        elif tp.value in (pv.TYPE_VOID_PTR, pv.TYPE_VOID_PTR_PTR):\n            raise ValueError(\"Cannot handle arguments of type pointer\")\n        else:\n            raise NotImplementedError(\"Argument of unknown type %d\" % tp.value)\n\n        self.pvcam.pl_set_param(self._handle, param, ct.byref(content))",
  "def get_enum_available(self, param):\n        \"\"\"\n        Get all the available values for a given enumerated parameter.\n        param (int): parameter ID (cf pv.PARAM_*), it must be an enumerated one\n        return (dict (int -> string)): value to description\n        \"\"\"\n        count = ct.c_uint32()\n        self.pvcam.pl_get_param(self._handle, param, pv.ATTR_COUNT, ct.byref(count))\n\n        ret = {}  # int -> str\n        for i in range(count.value):\n            length = ct.c_uint32()\n            content = ct.c_uint32()\n            self.pvcam.pl_enum_str_length(self._handle, param, i, ct.byref(length))\n            desc = ct.create_string_buffer(length.value)\n            self.pvcam.pl_get_enum_param(self._handle, param, i, ct.byref(content),\n                                         desc, length)\n            ret[content.value] = desc.value\n        return ret",
  "def exp_check_status(self):\n        \"\"\"\n        Checks the status of the current exposure (acquisition)\n        returns (int): status as in pv.* (cf documentation)\n        \"\"\"\n        status = ct.c_int16()\n        byte_cnt = ct.c_uint32()  # number of bytes already acquired: unused\n        self.pvcam.pl_exp_check_status(self._handle, ct.byref(status), ct.byref(byte_cnt))\n        return status.value",
  "def _int2version(raw):\n        \"\"\"\n        Convert a raw value into version, according to the pvcam convention\n        raw (int)\n        returns (string)\n        \"\"\"\n        ver = []\n        ver.insert(0, raw & 0x0f)  # lowest 4 bits = trivial version\n        raw >>= 4\n        ver.insert(0, raw & 0x0f)  # next 4 bits = minor version\n        raw >>= 4\n        ver.insert(0, raw & 0xff)  # highest 8 bits = major version\n        return '.'.join(str(x) for x in ver)",
  "def get_sw_version(self):\n        \"\"\"\n        returns a simplified software version information\n        or None if unknown\n        \"\"\"\n        try:\n            ddi_ver = ct.c_uint16()\n            self.pvcam.pl_ddi_get_ver(ct.byref(ddi_ver))\n            interface = self._int2version(ddi_ver.value)\n        except PVCamError:\n            interface = \"unknown\"\n\n        try:\n            pv_ver = ct.c_uint16()\n            self.pvcam.pl_pvcam_get_ver(ct.byref(pv_ver))\n            sdk = self._int2version(pv_ver.value)\n        except PVCamError:\n            sdk = \"unknown\"\n\n        try:\n            driver = self._int2version(self.get_param(pv.PARAM_DD_VERSION))\n        except PVCamError:\n            driver = \"unknown\"\n\n        return \"driver: %s, interface: %s, SDK: %s\" % (driver, interface, sdk)",
  "def get_hw_version(self):\n        \"\"\"\n        returns a simplified hardware version information\n        \"\"\"\n        versions = {pv.PARAM_CAM_FW_VERSION: \"firmware\",\n                    # Fails on PI pvcam (although PARAM_DD_VERSION manages to\n                    # read the firmware version inside the kernel)\n                    pv.PARAM_PCI_FW_VERSION: \"firmware board\",\n                    pv.PARAM_CAM_FW_FULL_VERSION: \"firmware (full)\",\n                    pv.PARAM_CAMERA_TYPE: \"camera type\",\n                    }\n        ret = \"\"\n        for pid, name in list(versions.items()):\n            try:\n                value = self.get_param(pid)\n                ret += \"%s: %s \" % (name, value)\n            except PVCamError:\n                #                self._logger.exception(\"param %x cannot be accessed\", pid)\n                pass  # skip\n\n        # TODO: if we really want, we can try to look at the product name if it's\n        # USB: from the name, find in in /dev/ -> read major/minor\n        # -> /sys/dev/char/$major:$minor/device\n        # -> read symlink canonically, remove last directory\n        # -> read \"product\" file\n\n        if ret == \"\":\n            ret = \"unknown\"\n        return ret",
  "def get_model(self):\n        \"\"\"\n        returns (string): name of the camara\n        \"\"\"\n        model_name = \"Princeton Instruments camera\"\n\n        try:\n            model_name += \" with CCD '%s'\" % self.get_param(pv.PARAM_CHIP_NAME)\n        except PVCamError:\n            pass  # unknown\n\n        try:\n            model_name += \" (s/n: %s)\" % self.get_param(pv.PARAM_SERIAL_NUM)\n        except PVCamError:\n            pass  # unknown\n\n        return model_name",
  "def get_sensor_size(self):\n        \"\"\"\n        return 2-tuple (int, int): width, height of the detector in pixel\n        \"\"\"\n        width = self.get_param(pv.PARAM_SER_SIZE, pv.ATTR_DEFAULT)\n        height = self.get_param(pv.PARAM_PAR_SIZE, pv.ATTR_DEFAULT)\n        return width, height",
  "def get_min_resolution(self):\n        \"\"\"\n        return 2-tuple (int, int): width, height of the minimum possible resolution\n        \"\"\"\n        width = self.get_param(pv.PARAM_SER_SIZE, pv.ATTR_MIN)\n        height = self.get_param(pv.PARAM_PAR_SIZE, pv.ATTR_MIN)\n        return width, height",
  "def get_pixel_size(self):\n        \"\"\"\n        return 2-tuple float, float: width, height of one pixel in m\n        \"\"\"\n        # values from the driver are in nm\n        width = self.get_param(pv.PARAM_PIX_SER_DIST, pv.ATTR_DEFAULT) * 1e-9\n        height = self.get_param(pv.PARAM_PIX_PAR_DIST, pv.ATTR_DEFAULT) * 1e-9\n        return width, height",
  "def get_temp(self):\n        \"\"\"\n        returns (float) the current temperature of the captor in C\n        \"\"\"\n        # it's in 1/100 of C\n        # with self._online_lock:\n        temp = self.get_param(pv.PARAM_TEMP) / 100\n        return temp",
  "def get_temp_range(self):\n        mint = self.get_param(pv.PARAM_TEMP_SETPOINT, pv.ATTR_MIN) / 100\n        maxt = self.get_param(pv.PARAM_TEMP_SETPOINT, pv.ATTR_MAX) / 100\n        return mint, maxt",
  "def set_temp_target(self, temp):\n        \"\"\"\n        Change the targeted temperature of the CCD. The cooler the less dark noise.\n        temp (-300 < float < 100): temperature in C, should be within the allowed range\n        \"\"\"\n        assert ((-300 <= temp) and (temp <= 100))\n        # TODO: doublebuff_focus.c example code has big warnings to not read/write\n        # the temperature during image acquisition. We might want to avoid it as\n        # well. (as soon as the READOUT_COMPLETE state is reached, it's fine again)\n\n        # it's in 1/100 of C\n        # TODO: use increment? => doesn't seem to matter\n        self.set_param(pv.PARAM_TEMP_SETPOINT, int(round(temp * 100)))\n\n        # Turn off the cooler if above room temperature\n        try:\n            # Note: doesn't seem to have any effect on the PIXIS\n            if temp >= 20:\n                self.set_param(pv.PARAM_HEAD_COOLING_CTRL, pv.HEAD_COOLING_CTRL_OFF)\n                self.set_param(pv.PARAM_COOLING_FAN_CTRL, pv.COOLING_FAN_CTRL_OFF)\n            else:\n                self.set_param(pv.PARAM_HEAD_COOLING_CTRL, pv.HEAD_COOLING_CTRL_ON)\n                self.set_param(pv.PARAM_COOLING_FAN_CTRL, pv.COOLING_FAN_CTRL_ON)\n        except PVCamError:\n            pass\n\n        temp = self.get_param(pv.PARAM_TEMP_SETPOINT) / 100\n        return float(temp)",
  "def _get_gains(self):\n        \"\"\"\n        Find the gains supported by the device\n        returns (dict of int -> float): index -> multiplier\n        \"\"\"\n        # Gains are special: they do not use a enum type, just min/max\n        ming = self.get_param(pv.PARAM_GAIN_INDEX, pv.ATTR_MIN)\n        maxg = self.get_param(pv.PARAM_GAIN_INDEX, pv.ATTR_MAX)\n        gains = {}\n        for i in range(ming, maxg + 1):\n            # seems to be correct for PIXIS and ST133\n            gains[i] = 2 ** (i - 1)\n        return gains",
  "def _set_gain(self, value):\n        \"\"\"\n        VA setter for gain (just save)\n        \"\"\"\n        self._gain = value\n        return value",
  "def _get_readout_rates(self):\n        \"\"\"\n        Find the readout rates supported by the device\n        returns (dict int -> float): for each index: frequency in Hz\n        Note: this is for the current output amplifier and bit depth\n        \"\"\"\n        # It depends on the port (output amplifier), bit depth, which we\n        # consider both fixed.\n        # PARAM_PIX_TIME (ns): the time per pixel\n        # PARAM_SPDTAB_INDEX: the speed index\n        # The only way to find out the rate of a speed, is to set the speed, and\n        # see the new time per pixel.\n        # Note: setting the spdtab idx resets the gain\n\n        mins = self.get_param(pv.PARAM_SPDTAB_INDEX, pv.ATTR_MIN)\n        maxs = self.get_param(pv.PARAM_SPDTAB_INDEX, pv.ATTR_MAX)\n        # save the current value\n        current_spdtab = self.get_param(pv.PARAM_SPDTAB_INDEX)\n        current_gain = self.get_param(pv.PARAM_GAIN_INDEX)\n\n        rates = {}\n        for i in range(mins, maxs + 1):\n            # Try with this given speed tab\n            self.set_param(pv.PARAM_SPDTAB_INDEX, i)\n            pixel_time = self.get_param(pv.PARAM_PIX_TIME)  # ns\n            if pixel_time == 0:\n                self._logger.warning(\"Camera reporting pixel readout time of 0 ns!\")\n                pixel_time = 1\n            rates[i] = 1 / (pixel_time * 1e-9)\n\n        # restore the current values\n        self.set_param(pv.PARAM_SPDTAB_INDEX, current_spdtab)\n        self.set_param(pv.PARAM_GAIN_INDEX, current_gain)\n        return rates",
  "def _set_readout_rate(self, value):\n        \"\"\"\n        VA setter for readout rate (just save)\n        \"\"\"\n        self._readout_rate = value\n        return value",
  "def _get_max_bin(self):\n        \"\"\"\n        return the maximum binning in both directions\n        returns (list of int): maximum binning in height, width\n        \"\"\"\n        chip = self.get_param(pv.PARAM_CHIP_NAME)\n        # FIXME: detect more generally if the detector supports binning or not?\n        if \"InGaAs\" in chip:\n            # InGaAs detectors don't support binning (written in the\n            # specification). In practice, it stops sending images if binning > 1.\n            return (1, 1)\n\n        # other cameras seem to support up to the entire sensor resolution\n        return self.get_sensor_size()",
  "def _set_binning(self, value):\n        \"\"\"\n        Called when \"binning\" VA is modified. It also updates the resolution so\n        that the AOI is approximately the same.\n        value (int): how many pixels horizontally and vertically\n         are combined to create \"super pixels\"\n        \"\"\"\n        value = self._transposeSizeFromUser(value)\n        prev_binning = self._binning\n        self._binning = value\n\n        # adapt resolution so that the AOI stays the same\n        change = (prev_binning[0] / self._binning[0],\n                  prev_binning[1] / self._binning[1])\n        old_resolution = self._transposeSizeFromUser(self.resolution.value)\n        new_resolution = (int(round(old_resolution[0] * change[0])),\n                          int(round(old_resolution[1] * change[1])))\n\n        self.resolution.value = self._transposeSizeToUser(new_resolution)  # will automatically call _storeSize\n        return self._transposeSizeToUser(value)",
  "def _storeSize(self, size):\n        \"\"\"\n        Check the size is correct (it should) and store it ready for SetImage\n        size (2-tuple int): Width and height of the image. It will be centred\n         on the captor. It depends on the binning, so the same region has a size\n         twice smaller if the binning is 2 instead of 1. It must be a allowed\n         resolution.\n        \"\"\"\n        full_res = self._shape[:2]\n        resolution = (int(full_res[0] // self._binning[0]),\n                      int(full_res[1] // self._binning[1]))\n        assert ((1 <= size[0]) and (size[0] <= resolution[0]) and\n                (1 <= size[1]) and (size[1] <= resolution[1]))\n\n        # Region of interest\n        # center the image\n        lt = ((resolution[0] - size[0]) // 2,\n              (resolution[1] - size[1]) // 2)\n\n        # the rectangle is defined in normal pixels (not super-pixels) from (0,0)\n        self._image_rect = (lt[0] * self._binning[0], (lt[0] + size[0]) * self._binning[0] - 1,\n                            lt[1] * self._binning[1], (lt[1] + size[1]) * self._binning[1] - 1)",
  "def _setResolution(self, value):\n        # value = self._transposeSizeFromUser(value)\n        new_res = self.resolutionFitter(value)\n        self._storeSize(new_res)\n        # return self._transposeSizeToUser(new_res)\n        return new_res",
  "def resolutionFitter(self, size_req):\n        \"\"\"\n        Finds a resolution allowed by the camera which fits best the requested\n          resolution.\n        size_req (2-tuple of int): resolution requested\n        returns (2-tuple of int): resolution which fits the camera. It is equal\n         or bigger than the requested resolution\n        \"\"\"\n        # find maximum resolution (with binning)\n        resolution = self._shape[:2]\n        max_size = (int(resolution[0] // self._binning[0]),\n                    int(resolution[1] // self._binning[1]))\n        min_size = (int(math.ceil(self._min_res[0] / self._binning[0])),\n                    int(math.ceil(self._min_res[1] / self._binning[1])))\n\n        # smaller than the whole sensor\n        size = (min(size_req[0], max_size[0]), min(size_req[1], max_size[1]))\n\n        # bigger than the minimum\n        size = (max(min_size[0], size[0]), max(min_size[0], size[1]))\n\n        return size",
  "def _need_update_settings(self):\n        \"\"\"\n        returns (boolean): True if _update_settings() needs to be called\n        \"\"\"\n        new_image_settings = self._binning + self._image_rect\n        new_settings = [new_image_settings, self._exposure_time,\n                        self._readout_rate, self._gain, self._shutter_period]\n        return new_settings != self._prev_settings",
  "def _update_settings(self):\n        \"\"\"\n        Commits the settings to the camera. Only the settings which have been\n        modified are updated.\n        Note: acquisition_lock must be taken, and acquisition must _not_ going on.\n        returns (exposure, region, size):\n                exposure: (float) exposure time in second\n                region (pv.rgn_type): the region structure that can be used to set up the acquisition\n                size (2-tuple of int): the size of the data array that will get acquired\n        \"\"\"\n        (prev_image_settings, prev_exp_time,\n         prev_readout_rate, prev_gain, prev_shut) = self._prev_settings\n\n        if prev_readout_rate != self._readout_rate:\n            self._logger.debug(\"Updating readout rate settings to %f Hz\", self._readout_rate)\n            i = index_closest(self._readout_rate, self._readout_rates)\n            self.set_param(pv.PARAM_SPDTAB_INDEX, i)\n\n            # self._metadata[MD_READOUT_TIME] = 1.0 / self._readout_rate  # s\n            # rate might affect the BPP (although on the PIXIS, it's always 16)\n            # self._metadata[MD_BPP] = self.get_param(pv.PARAM_BIT_DEPTH)\n\n            # If readout rate is changed, gain is reset => force update\n            prev_gain = None\n\n        if prev_gain != self._gain:\n            self._logger.debug(\"Updating gain to %f\", self._gain)\n            i = index_closest(self._gain, self._gains)\n            self.set_param(pv.PARAM_GAIN_INDEX, i)\n            # self._metadata[MD_GAIN] = self._gain\n\n        # prepare image (region)\n        region = pv.rgn_type()\n        # region is 0 indexed\n        region.s1, region.s2, region.p1, region.p2 = self._image_rect\n        region.sbin, region.pbin = self._binning\n        # self._metadata[MD_BINNING] = self._binning  # self._transposeSizeToUser(self._binning)\n        new_image_settings = self._binning + self._image_rect\n        # size = ((self._image_rect[1] - self._image_rect[0] + 1) // self._binning[0],\n        #         (self._image_rect[3] - self._image_rect[2] + 1) // self._binning[1],\n        #         self._number_frames)\n        size = (self._number_frames,\n                (self._image_rect[3] - self._image_rect[2] + 1) // self._binning[1],\n                (self._image_rect[1] - self._image_rect[0] + 1) // self._binning[0]\n                )\n\n        # nothing special for the exposure time\n        # self._metadata[MD_EXP_TIME] = self._exposure_time\n\n        # Activate shutter closure whenever needed:\n        # Shutter closes between exposures iif:\n        # * period between exposures is long enough (>0.1s): to ensure we don't burn the mechanism\n        # * readout time > exposure time/100 (when risk of smearing is possible)\n        readout_time = np.prod(size) / self._readout_rate  # s\n        tot_time = readout_time + self._exposure_time  # reality will be slightly longer\n        self._logger.debug(\"exposure = %f s, readout = %f s\", readout_time, self._exposure_time)\n        try:\n            if tot_time < self._shutter_period:\n                self._logger.info(\"Disabling shutter because it would go at %g Hz\",\n                                  1 / tot_time)\n                self.set_param(pv.PARAM_SHTR_OPEN_MODE, pv.OPEN_PRE_SEQUENCE)\n            elif readout_time < (self._exposure_time / 100):\n                self._logger.info(\"Disabling shutter because readout is %g times \"\n                                  \"smaller than exposure\",\n                                  self._exposure_time / readout_time)\n                self.set_param(pv.PARAM_SHTR_OPEN_MODE, pv.OPEN_PRE_SEQUENCE)\n            elif self.get_param(pv.PARAM_SHTR_OPEN_MODE) != 0:\n                self.set_param(pv.PARAM_SHTR_OPEN_MODE, pv.OPEN_PRE_EXPOSURE)\n                self._logger.info(\"Shutter activated\")\n            else:\n                self._logger.info(\"Shutter closed\")\n        except PVCamError:\n            self._logger.debug(\"Failed to change shutter mode\")\n\n        self._prev_settings = [new_image_settings, self._exposure_time,\n                               self._readout_rate, self._gain, self._shutter_period]\n\n        return self._exposure_time, region, size",
  "def _allocate_buffer(self, length):\n        \"\"\"\n        length (int): number of bytes requested by pl_exp_setup\n        returns a cbuffer of the right type for an image\n        \"\"\"\n        cbuffer = (ct.c_uint16 * (self._number_frames * length // 2))()  # empty array\n        return cbuffer",
  "def _buffer_as_array(cbuffer, size):\n        \"\"\"\n        Converts the buffer allocated for the image as an ndarray. zero-copy\n        size (2-tuple of int): width, height\n        return an ndarray\n        \"\"\"\n        p = ct.cast(cbuffer, ct.POINTER(ct.c_uint16))\n        # dataarray = np.ctypeslib.as_array(p, (size[2], size[1], size[0]))  # np shape is H, W\n        dataarray = np.ctypeslib.as_array(p, size)  # np shape is H, W\n        return dataarray",
  "def _init_seq(self):\n        \"\"\"Initialise sequence parameters\"\"\"\n\n        exposure, region, size = self._update_settings()\n        self.pvcam.pl_exp_init_seq()\n        blength = ct.c_uint32()\n        exp_ms = int(math.ceil(exposure * 1e3))  # ms\n        # 1 image, with 1 region\n        self.pvcam.pl_exp_setup_seq(self._handle, self._number_frames, 1, ct.byref(region),\n                                    pv.TIMED_MODE, exp_ms, ct.byref(blength))\n        self._logger.debug(\"acquisition setup report buffer size of %d\", blength.value)\n        cbuffer = self._allocate_buffer(blength.value)  # TODO shall allocate a new buffer every time?\n        assert (blength.value / 2) >= (np.prod(size))\n\n        readout_sw = np.prod(size) * 1.0 / self._readout_rate  # s\n        # tends to be very slightly bigger:\n        readout = self.get_param(pv.PARAM_READOUT_TIME) * 1e-3  # s\n        self._logger.debug(\"exposure of %g s, readout %g s (expected %g s)\", exp_ms * 1e-3, readout, readout_sw)\n        duration = exposure + readout  # seems it actually takes +40ms\n        return exposure, region, size, duration, cbuffer",
  "def capture(self):\n        \"\"\"Modified from odemis, but removing the locking\"\"\"\n        exposure, region, size, duration, cbuffer = self._init_seq()\n        self.pvcam.pl_exp_start_seq(self._handle, cbuffer)\n        start = time.time()\n        # metadata = dict(self._metadata)  # duplicate\n        # metadata[MD_ACQ_DATE] = start\n        expected_end = start + duration\n        timeout = expected_end + 1\n\n        # wait a bounded time until the image is acquired\n        try:\n            # warning: in seq mode, it will only report once that status is done,\n            # and then automatically go to acquisition again\n            status = self.exp_check_status()\n            while status in STATUS_IN_PROGRESS:\n                now = time.time()\n                if now > timeout:\n                    raise IOError(\"Timeout after %g s\" % (now - start))\n                # check if we should stop (sleeping less and less)\n                left = expected_end - now\n                if self.acquire_must_stop.wait(max(0.01, left / 2)):\n                    raise CancelledError()\n                status = self.exp_check_status()\n\n            if status != pv.READOUT_COMPLETE:\n                raise IOError(\"Acquisition status is unexpected %d\" % status)\n        except (IOError, PVCamError):\n            try:\n                self.pvcam.pl_exp_abort(self._handle, pv.CCS_HALT_CLOSE_SHTR)\n            except PVCamError:\n                self._logger.warn(\"Failed aborting\")\n\n        data_array = self._buffer_as_array(cbuffer, size)\n\n        try:\n            if cbuffer:\n                self.pvcam.pl_exp_finish_seq(self._handle, cbuffer, None)\n        except PVCamError:\n            self._logger.exception(\"Failed to finish the acquisition properly\")\n\n        try:\n            if cbuffer:\n                self.pvcam.pl_exp_uninit_seq()\n        except PVCamError:\n            self._logger.exception(\"Failed to finish the acquisition properly\")\n\n        self.current_image = data_array\n\n        return data_array",
  "def dark_exposure(self):\n        _current_value = self.get_param(pv.PARAM_SHTR_OPEN_MODE)\n        self.set_param(pv.PARAM_SHTR_OPEN_MODE, pv.OPEN_NEVER)\n        array = self.capture()\n        self.background = array\n        self.set_param(pv.PARAM_SHTR_OPEN_MODE, _current_value)\n        return array",
  "def scan():\n        \"\"\"\n        List all the available cameras.\n        Note: it's not recommended to call this method when cameras are being used\n        return (list of 2-tuple: name (strin), device number (int))\n        \"\"\"\n        pvcam = PVCamDLL()\n        num_cam = ct.c_short()\n        pvcam.pl_cam_get_total(ct.byref(num_cam))\n        print(\"Found %d devices.\" % num_cam.value)\n\n        cameras = []\n        for i in range(num_cam.value):\n            cam_name = ct.create_string_buffer(pv.CAM_NAME_LEN)\n            try:\n                pvcam.pl_cam_get_name(i, cam_name)\n            except PVCamError:\n                print(\"Couldn't access camera %d\" % i)\n\n            # TODO: append the resolution to the name of the camera?\n            cameras.append((cam_name.value, {\"device\": i}))\n\n        return cameras",
  "def __init__(self, device, **kwargs):\n        # super(Pvcam, self).__init__(device, logger=self._logger)\n        CameraRoiScale.__init__(self)\n        PvcamSdk.__init__(self, device, logger=self._logger)\n        self.background = None\n        self.backgrounded = False",
  "def raw_snapshot(self):\n        \"\"\"\n        If only one frame, returns a 2D array. If multiple frames, returns a 3D array, where the first dimension is\n        frame number\n        :return: ndarray\n        \"\"\"\n        array = self.capture()\n        if array.shape[0] == 1:\n            array = array[0]\n        return True, array",
  "def filter_function(self, frame):\n        if self.backgrounded:\n            return np.asarray(frame, float) - np.asarray(self.background, float)\n        else:\n            return frame",
  "def get_camera_parameter(self, parameter_name):\n        return self.get_param(getattr(pv, parameter_name))",
  "def set_camera_parameter(self, parameter_name, parameter_value):\n        try:\n            self.set_param(getattr(pv, parameter_name), getattr(pv, parameter_value))\n        except Exception as e:\n            self._logger.warn('paramter ' +parameter_name+' could not be set with the value '+parameter_value+\n                     ' due to error '+str(e))",
  "def get_control_widget(self):\n        return pvcamUI(self)",
  "def get_preview_widget(self):\n        self._logger.debug('Getting preview widget')\n        if self._preview_widgets is None:\n            self._preview_widgets = WeakSet()\n        new_widget = DisplayWidgetRoiScale()\n        self._preview_widgets.add(new_widget)\n\n        return new_widget",
  "def roi(self):\n        return self._image_rect",
  "def roi(self, value):\n        self._image_rect = value",
  "def binning(self):\n        return self._binning",
  "def binning(self, value):\n        self._binning = value",
  "def __init__(self, camera):\n        assert isinstance(camera, Pvcam), \"instrument must be an camera\"\n        self._logger = create_logger(\"pvcam.GUI\")\n\n        super(pvcamUI, self).__init__()\n        self.captureThread = None\n        self.camera = camera\n        self.DisplayWidget = None\n\n        self._binning_changed = False\n        self._prev_bin = camera.binning\n\n        uic.loadUi((os.path.dirname(__file__) + '/camera.ui'), self)\n        self._setup_signals()\n        self.data_file = None\n        self.save_all_parameters = False\n        self.backgrounded = False\n\n        self._func_dict = {}\n        for param in self.camera.metadata_property_names:\n            try:\n                func = self.callback_to_update_prop(param)\n                self._func_dict[param] = func\n                register_for_property_changes(self.camera, param, self._func_dict[param])\n            except AssertionError:\n                self._logger.info(\"%s is not a property so cannot be monitored\" % param)",
  "def __del__(self):\n        self._stopTemperatureThread = True\n        if self.DisplayWidget is not None:\n            self.DisplayWidget.hide()\n            self.DisplayWidget.close()",
  "def _setup_signals(self):\n        # self.comboBoxAcqMode.activated.connect(self.AcquisitionModeChanged)\n        # self.comboBoxReadMode.activated.connect(self.ReadModeChanged)\n        # self.comboBoxTrigMode.activated.connect(self.TrigChanged)\n        # self.spinBoxNumFrames.valueChanged.connect(self.NumFramesChanged)\n        # self.spinBoxNumFrames.setRange(1, 1000000)\n        # self.spinBoxNumAccum.valueChanged.connect(self.NumAccumChanged)\n        # self.spinBoxNumRows.valueChanged.connect(self.NumRowsChanged)\n        # self.spinBoxCenterRow.valueChanged.connect(self.NumRowsChanged)\n        self.checkBoxROI.stateChanged.connect(self.ROI)\n        # self.checkBoxCrop.stateChanged.connect(self.IsolatedCrop)\n        # self.checkBoxCooler.stateChanged.connect(self.Cooler)\n        # # self.checkBoxAutoExp.stateChanged.connect(self.AutoExpose)\n        # self.checkBoxEMMode.stateChanged.connect(self.OutputAmplifierChanged)\n        # self.spinBoxEMGain.valueChanged.connect(self.EMGainChanged)\n        self.lineEditExpT.editingFinished.connect(self.changed_exposure)\n        # self.lineEditExpT.setValidator(QtGui.QDoubleValidator())\n        self.pushButtonDiv5.clicked.connect(lambda: self.changed_exposure('/'))\n        self.pushButtonTimes5.clicked.connect(lambda: self.changed_exposure('x'))\n        self.spinBox_binx.valueChanged.connect(self.changed_binning)\n        self.spinBox_biny.valueChanged.connect(self.changed_binning)\n\n        self.pushButtonCapture.clicked.connect(self.Capture)\n        self.pushButtonLive.clicked.connect(self.Live)\n        self.pushButtonAbort.clicked.connect(self.Abort)\n        self.save_pushButton.clicked.connect(self.Save)\n        self.pushButtonTakeBG.clicked.connect(self.take_background)\n        self.checkBoxRemoveBG.stateChanged.connect(self.remove_background)",
  "def update_exposure(self, value):\n        self.lineEditExpT.setText(str(value))",
  "def update_binning(self, value):\n        self._binning_changed = True\n        self.spinBox_binx.setValue(value[0])\n        self.spinBox_biny.setValue(value[1])",
  "def callback_to_update_prop(self, propname):\n        \"\"\"Return a callback function that refreshes the named parameter.\"\"\"\n\n        def callback(value=None):\n            # print 'Callback: ', propname\n            getattr(self, 'update_' + propname)(value)\n\n        return callback",
  "def changed_binning(self):\n        if not self._binning_changed:\n            self._binning_changed = True\n            self._prev_bin = self.camera.binning\n        xbin = self.spinBox_binx.value()\n        ybin = self.spinBox_biny.value()\n        self.camera.binning = (xbin, ybin)",
  "def changed_exposure(self, variable=None):\n        if variable is None:\n            exp_time = float(self.lineEditExpT.text())\n        elif variable == 'x':\n            exp_time = float(self.lineEditExpT.text()) * 5\n        elif variable == '/':\n            exp_time = float(self.lineEditExpT.text()) / 5\n        else:\n            raise ValueError(\"Unrecognised exposure time\")\n        self.camera.exposure = exp_time\n        self.update_exposure(exp_time)",
  "def take_background(self):\n        # self.camera.background = self.camera.dark_exposure()\n        self.camera.dark_exposure()\n        self.backgrounded = True\n        self.checkBoxRemoveBG.setChecked(True)",
  "def remove_background(self):\n        if self.checkBoxRemoveBG.isChecked():\n            self.camera.backgrounded = True\n        else:\n            self.camera.backgrounded = False",
  "def Save(self):\n        if self.data_file is None:\n            self.data_file = df.current()\n        data = self.camera.current_image\n\n        if self.lineEdit_groupname.text():\n            group = self.data_file.create_group(self.lineEdit_groupname.text())\n        else:\n            group = self.data_file\n\n        if self.lineEdit_datasetname.text():\n            dataset_name = self.lineEdit_datasetname.text()\n        else:\n            idx = 1\n            while \"pvcam%d\" % idx in list(group.keys()):\n                idx += 1\n            dataset_name = \"pvcam%d\" % idx\n\n        if self.backgrounded:\n            self._logger.info(\"Saving backgrounded image. Remember to save the background separately\")\n            data = np.array(data, np.float)\n            data -= self.camera.background\n\n        try:\n            data_set = group.create_dataset(name=dataset_name, data=data)\n            if self.checkBox_attrs.isChecked():\n                attrs = dict()\n                for param in self.camera.metadata_property_names:\n                    attrs[param] = getattr(self.camera, param)\n                if self.description_plainTextEdit.toPlainText():\n                    attrs['Description'] = self.description_plainTextEdit.toPlainText()\n                df.attributes_from_dict(data_set, attrs)\n        except Exception as e:\n            self._logger.warn(e)",
  "def ROI(self):\n        if self.checkBoxROI.isChecked():\n            self.camera.roi = self.camera.gui_roi\n        else:\n            shape = self.camera._shape\n            self.camera.roi = (0, shape[0] - 1, 0, shape[1] - 1)",
  "def Capture(self):\n        self.camera.raw_image(update_latest_frame=True)",
  "def Live(self):\n        self.camera.live_view = True",
  "def Abort(self):\n        self.camera.live_view = False",
  "def callback(value=None):\n            # print 'Callback: ', propname\n            getattr(self, 'update_' + propname)(value)",
  "def disarmer(f, wait=0.3):\n    '''some properties like roi and binning and frames_per_capture.. need the camera to be \"disarmed\" to\n    be set. This decorator disarms and re-arms the camera before and after the\n    function is called. Particularly for binning, it seems like the camera \n    needs a few secs before it can be changed, hence the time.sleep.\n    '''\n    @wraps(f)\n    def inner_func(self, *args, **kwargs):\n        armed = self._camera.is_armed\n        if armed:\n            self._camera.disarm()\n            time.sleep(wait)\n        out = f(self, *args, **kwargs)\n        self._image_width = self._camera.image_width_pixels\n        self._image_height = self._camera.image_height_pixels  # a compromise\n        # between querying for every capture and wrapping binx and biny setter\n        # methods individually.\n        if armed:\n            self._camera.arm(2)  # 2 frames to buffer\n        if self.live_view:\n            self._camera.issue_software_trigger()\n            time.sleep(wait)\n        return out\n    return inner_func",
  "class Kiralux(Camera):\n    disarmed_properties = ('roi', 'binx', 'biny',\n                           'frames_per_trigger_zero_for_unlimited')\n    # properties that need the camera to be disarmed to set - there may be more.\n    notified_properties = ('gain',)  # properties that are in the gui\n\n    def __init__(self, square_image=False):\n        super().__init__()\n        self._sdk = TLCameraSDK()\n        self._camera = self._sdk.open_camera(\n            self._sdk.discover_available_cameras()[0])\n\n        if self._camera.camera_sensor_type != SENSOR_TYPE.BAYER:\n            # Sensor type is not compatible with the color processing library\n            def process_frame(f): return np.asarray(\n                f)  # no processing for grey images\n        else:\n            self._mono_to_color_sdk = MonoToColorProcessorSDK()\n            self._image_width = self._camera.image_width_pixels\n            self._image_height = self._camera.image_height_pixels\n            self._mono_to_color_processor = self._mono_to_color_sdk.create_mono_to_color_processor(\n                SENSOR_TYPE.BAYER,\n                self._camera.color_filter_array_phase,\n                self._camera.get_color_correction_matrix(),\n                self._camera.get_default_white_balance_matrix(),\n                self._camera.bit_depth\n            )\n            process_frame = self.process_color_frame\n        if square_image:\n            self.process_frame = lambda f: self.make_square(process_frame(f))\n        else:\n            self.process_frame = process_frame\n        self._bit_depth = self._camera.bit_depth\n        self._camera.image_poll_timeout_ms = 0\n        self._populate_properties()\n\n        self._camera.frames_per_trigger_zero_for_unlimited = 1  # snapshot mode\n        self._camera.arm(2)\n\n    def _populate_properties(self):\n        ''' adds all the properties from TLCamera to Kiralux, for easy access.\n\n        '''\n\n        # to get around late binding\n        def prop_factory(thor_prop, disarmed=False, notified=False):\n            def fget(self):\n                return thor_prop.fget(self._camera)\n\n            def fset(self, val):\n                # with self.acquisition_lock: # this leads to infinite locking as raw_snapshot can set frames_per_trigger\n                # it should be possible to simply lock \n                    return thor_prop.fset(self._camera, val)\n\n            # fget = waiter(fget)\n            # fset = waiter(fset)\n            if disarmed:\n                fset = disarmer(fset)\n            # if notified: sreturn NotifiedProperty(fget, fset) \n            ## ^ for some reason this makes acquisition lock unstable\n            ##  It's a bit disappointing but I don't know how to fix - ee306\n            return property(fget, fset)\n\n        cls = self.__class__\n        for thor_attr in dir(thor_cls := self._camera.__class__):\n            if hasattr(thor_prop := getattr(thor_cls, thor_attr), 'fget'):\n                # if it's a property\n                if not hasattr(cls, thor_attr):\n                    # and it's not in Kiralux already\n                    setattr(cls,\n                            thor_attr,  # add the property\n                            prop_factory(thor_prop,\n                                         thor_attr in cls.disarmed_properties,\n                                         thor_attr in cls.notified_properties))\n                    # if it's in disarmed_properties,\n                    # decorate the setter and return a\n                    # notified property appropriately.\n\n    @property\n    def exposure(self):  # in ms by nplab convention\n        return self.exposure_time_us/1000.0\n\n    @exposure.setter\n    def exposure(self, val):\n        self.exposure_time_us = int(val*1000)\n\n    def get_frame(self):  # always gets a frame or dies trying\n        \n        while (f := self._camera.get_pending_frame_or_null()) is None:\n            # pass\n            time.sleep(0.1)\n        return f\n\n    def process_color_frame(self, frame, square_image=False):\n        color_image_data = self._mono_to_color_processor.transform_to_24(frame.image_buffer,\n                                                                         self._image_width,\n                                                                         self._image_height)\n        color_image_data = color_image_data.reshape(\n            self._image_height, self._image_width, 3)\n        # return color_image_data\n        return color_image_data[::-1, ::-1, :]\n\n    def make_square(self, color_image_data):\n        dif = (self._image_width - self._image_height)//2\n        return color_image_data[:, dif:self._image_width-dif, :]\n\n    def raw_snapshot(self):\n\n        if not self.live_view:\n            self._camera.issue_software_trigger()\n        # if it's in live_view, camera should already be triggered\n        with self.acquisition_lock:\n            frame = self.get_frame()\n\n        if frame:\n            return True, self.process_frame(frame)\n\n        return False, None\n\n    @Camera.live_view.setter\n    def live_view(self, live_view):\n        if live_view == self._live_view:\n            return  # small redundancy with Camera.live_view\n        Camera.live_view.fset(self, live_view)\n        if live_view:\n            self.frames_per_trigger_zero_for_unlimited = 0  # unlimited\n            # decorator should trigger as self.live_view == True\n        else:\n            self.frames_per_trigger_zero_for_unlimited = 1  # disarms and rearms\n    # def color_image(self, **kwargs):\n\n    def get_control_widget(self):\n        \"Get a Qt widget with the camera's controls (but no image display)\"\n        return KiraluxCameraControlWidget(self)",
  "class KiraluxCameraControlWidget(CameraControlWidget):\n    \"\"\"A control widget for the Thorlabs camera, with extra buttons.\"\"\"\n\n    def __init__(self, camera):\n        super().__init__(camera, auto_connect=False)\n        gb = QuickControlBox()\n        gb.add_doublespinbox(\"exposure\",\n                             *(e/1000 for e in camera.exposure_time_range_us))\n        gb.add_spinbox(\"gain\", *camera.gain_range)  # setting range\n        gb.add_button(\"show_camera_properties_dialog\", title=\"Camera Setup\")\n        gb.add_button(\"show_video_format_dialog\", title=\"Video Format\")\n        self.layout().insertWidget(1, gb)  # put the extra settings in the middle\n        self.quick_settings_groupbox = gb\n        self.auto_connect_by_name(controlled_object=self.camera)",
  "def inner_func(self, *args, **kwargs):\n        armed = self._camera.is_armed\n        if armed:\n            self._camera.disarm()\n            time.sleep(wait)\n        out = f(self, *args, **kwargs)\n        self._image_width = self._camera.image_width_pixels\n        self._image_height = self._camera.image_height_pixels  # a compromise\n        # between querying for every capture and wrapping binx and biny setter\n        # methods individually.\n        if armed:\n            self._camera.arm(2)  # 2 frames to buffer\n        if self.live_view:\n            self._camera.issue_software_trigger()\n            time.sleep(wait)\n        return out",
  "def __init__(self, square_image=False):\n        super().__init__()\n        self._sdk = TLCameraSDK()\n        self._camera = self._sdk.open_camera(\n            self._sdk.discover_available_cameras()[0])\n\n        if self._camera.camera_sensor_type != SENSOR_TYPE.BAYER:\n            # Sensor type is not compatible with the color processing library\n            def process_frame(f): return np.asarray(\n                f)  # no processing for grey images\n        else:\n            self._mono_to_color_sdk = MonoToColorProcessorSDK()\n            self._image_width = self._camera.image_width_pixels\n            self._image_height = self._camera.image_height_pixels\n            self._mono_to_color_processor = self._mono_to_color_sdk.create_mono_to_color_processor(\n                SENSOR_TYPE.BAYER,\n                self._camera.color_filter_array_phase,\n                self._camera.get_color_correction_matrix(),\n                self._camera.get_default_white_balance_matrix(),\n                self._camera.bit_depth\n            )\n            process_frame = self.process_color_frame\n        if square_image:\n            self.process_frame = lambda f: self.make_square(process_frame(f))\n        else:\n            self.process_frame = process_frame\n        self._bit_depth = self._camera.bit_depth\n        self._camera.image_poll_timeout_ms = 0\n        self._populate_properties()\n\n        self._camera.frames_per_trigger_zero_for_unlimited = 1  # snapshot mode\n        self._camera.arm(2)",
  "def _populate_properties(self):\n        ''' adds all the properties from TLCamera to Kiralux, for easy access.\n\n        '''\n\n        # to get around late binding\n        def prop_factory(thor_prop, disarmed=False, notified=False):\n            def fget(self):\n                return thor_prop.fget(self._camera)\n\n            def fset(self, val):\n                # with self.acquisition_lock: # this leads to infinite locking as raw_snapshot can set frames_per_trigger\n                # it should be possible to simply lock \n                    return thor_prop.fset(self._camera, val)\n\n            # fget = waiter(fget)\n            # fset = waiter(fset)\n            if disarmed:\n                fset = disarmer(fset)\n            # if notified: sreturn NotifiedProperty(fget, fset) \n            ## ^ for some reason this makes acquisition lock unstable\n            ##  It's a bit disappointing but I don't know how to fix - ee306\n            return property(fget, fset)\n\n        cls = self.__class__\n        for thor_attr in dir(thor_cls := self._camera.__class__):\n            if hasattr(thor_prop := getattr(thor_cls, thor_attr), 'fget'):\n                # if it's a property\n                if not hasattr(cls, thor_attr):\n                    # and it's not in Kiralux already\n                    setattr(cls,\n                            thor_attr,  # add the property\n                            prop_factory(thor_prop,\n                                         thor_attr in cls.disarmed_properties,\n                                         thor_attr in cls.notified_properties))",
  "def exposure(self):  # in ms by nplab convention\n        return self.exposure_time_us/1000.0",
  "def exposure(self, val):\n        self.exposure_time_us = int(val*1000)",
  "def get_frame(self):  # always gets a frame or dies trying\n        \n        while (f := self._camera.get_pending_frame_or_null()) is None:\n            # pass\n            time.sleep(0.1)\n        return f",
  "def process_color_frame(self, frame, square_image=False):\n        color_image_data = self._mono_to_color_processor.transform_to_24(frame.image_buffer,\n                                                                         self._image_width,\n                                                                         self._image_height)\n        color_image_data = color_image_data.reshape(\n            self._image_height, self._image_width, 3)\n        # return color_image_data\n        return color_image_data[::-1, ::-1, :]",
  "def make_square(self, color_image_data):\n        dif = (self._image_width - self._image_height)//2\n        return color_image_data[:, dif:self._image_width-dif, :]",
  "def raw_snapshot(self):\n\n        if not self.live_view:\n            self._camera.issue_software_trigger()\n        # if it's in live_view, camera should already be triggered\n        with self.acquisition_lock:\n            frame = self.get_frame()\n\n        if frame:\n            return True, self.process_frame(frame)\n\n        return False, None",
  "def live_view(self, live_view):\n        if live_view == self._live_view:\n            return  # small redundancy with Camera.live_view\n        Camera.live_view.fset(self, live_view)\n        if live_view:\n            self.frames_per_trigger_zero_for_unlimited = 0  # unlimited\n            # decorator should trigger as self.live_view == True\n        else:\n            self.frames_per_trigger_zero_for_unlimited = 1",
  "def get_control_widget(self):\n        \"Get a Qt widget with the camera's controls (but no image display)\"\n        return KiraluxCameraControlWidget(self)",
  "def __init__(self, camera):\n        super().__init__(camera, auto_connect=False)\n        gb = QuickControlBox()\n        gb.add_doublespinbox(\"exposure\",\n                             *(e/1000 for e in camera.exposure_time_range_us))\n        gb.add_spinbox(\"gain\", *camera.gain_range)  # setting range\n        gb.add_button(\"show_camera_properties_dialog\", title=\"Camera Setup\")\n        gb.add_button(\"show_video_format_dialog\", title=\"Video Format\")\n        self.layout().insertWidget(1, gb)  # put the extra settings in the middle\n        self.quick_settings_groupbox = gb\n        self.auto_connect_by_name(controlled_object=self.camera)",
  "def setter():\n        k.gain = 100\n        k.exposure = 50\n        print('broke')",
  "def poller():\n        for _ in range(10):\n            k.raw_image()\n        print('polled')",
  "def work():\n        t = threading.Thread(target=setter)\n        t2 = threading.Thread(target=poller)\n        t2.start()\n        t.start()",
  "def prop_factory(thor_prop, disarmed=False, notified=False):\n            def fget(self):\n                return thor_prop.fget(self._camera)\n\n            def fset(self, val):\n                # with self.acquisition_lock: # this leads to infinite locking as raw_snapshot can set frames_per_trigger\n                # it should be possible to simply lock \n                    return thor_prop.fset(self._camera, val)\n\n            # fget = waiter(fget)\n            # fset = waiter(fset)\n            if disarmed:\n                fset = disarmer(fset)\n            # if notified: sreturn NotifiedProperty(fget, fset) \n            ## ^ for some reason this makes acquisition lock unstable\n            ##  It's a bit disappointing but I don't know how to fix - ee306\n            return property(fget, fset)",
  "def process_frame(f): return np.asarray(\n                f)",
  "def fget(self):\n                return thor_prop.fget(self._camera)",
  "def fset(self, val):\n                # with self.acquisition_lock: # this leads to infinite locking as raw_snapshot can set frames_per_trigger\n                # it should be possible to simply lock \n                    return thor_prop.fset(self._camera, val)",
  "def _get_last_error(sdk):\n    try:\n        error_pointer = sdk.tl_mono_to_color_get_last_error()\n        if error_pointer is None:\n            return None\n        return str(error_pointer.decode(\"utf-8\"))\n    except Exception as exception:\n        _logger.error(\"unable to get last error; \" + str(exception))",
  "def _create_c_failure_message(sdk, function_name, error_code):\n    last_error = _get_last_error(sdk)\n    failure_message = \"{function_name}() returned non-zero error code: {error_code}; \" \\\n                      \"error message: {last_error}\" \\\n        .format(function_name=function_name, error_code=error_code, last_error=last_error)\n    return failure_message",
  "class MonoToColorProcessorSDK(object):\n\n    \"\"\"\n    MonoToColorProcessorSDK\n\n    The SDK object that is used to create MonoToColorProcessor objects. There must be only one instance of this class\n    active at a time. Use the :meth:`dispose()<thorlabs_tsi_sdk.tl_mono_to_color_processor.MonoToColorProcessorSDK.dispose>` method to destroy an SDK instance before\n    creating another instance. *with* statements can also be used with this class to automatically dispose the SDK.\n\n    \"\"\"\n\n    _is_sdk_open = False  # is SDK DLL currently being accessed by a MonoToColorSDK instance\n\n    def __init__(self):\n        # type: (type(None)) -> None\n        self._disposed = True\n\n        if MonoToColorProcessorSDK._is_sdk_open:\n            raise MonoToColorError(\"MonoToColorProcessorSDK is already in use. Please dispose of the current instance \"\n                                   \"before trying to create another instance.\")\n\n        try:\n            if platform.system() == 'Windows':\n                self._sdk = cdll.LoadLibrary(r\"thorlabs_tsi_mono_to_color_processing.dll\")\n            elif platform.system() == 'Linux':\n                self._sdk = cdll.LoadLibrary(r\"libthorlabs_tsi_mono_to_color_processing.so\")\n            else:\n                raise MonoToColorError(\"{system} is not a supported platform.\".format(system=platform.system()))\n            self._disposed = False\n        except OSError as os_error:\n            raise MonoToColorError(str(os_error) +\n                                   \"\\nUnable to load library - are the thorlabs tsi mono to color sdk libraries \"\n                                   \"discoverable from the application directory? Try placing them in the same \"\n                                   \"directory as your program, or adding the directory with the libraries to the \"\n                                   \"PATH. Make sure to use 32-bit libraries when using a 32-bit python interpreter \"\n                                   \"and 64-bit libraries when using a 64-bit interpreter.\\n\")\n\n        error_code = self._sdk.tl_mono_to_color_processing_module_initialize()\n        if error_code != 0:\n            raise MonoToColorError(\"tl_mono_to_color_processing_module_initialize() returned error code: {error_code}\\n\"\n                                   .format(error_code=error_code))\n        MonoToColorProcessorSDK._is_sdk_open = True\n\n        try:\n            \"\"\" set C function argument types \"\"\"\n            self._sdk.tl_mono_to_color_create_mono_to_color_processor.argtypes = [c_int, c_int,\n                                                                                  POINTER(_3x3Matrix_float),\n                                                                                  POINTER(_3x3Matrix_float), c_int,\n                                                                                  POINTER(c_void_p)]\n            self._sdk.tl_mono_to_color_destroy_mono_to_color_processor.argtypes = [c_void_p]\n            self._sdk.tl_mono_to_color_get_color_space.argtypes = [c_void_p, POINTER(c_int)]\n            self._sdk.tl_mono_to_color_set_color_space.argtypes = [c_void_p, c_int]\n            self._sdk.tl_mono_to_color_get_output_format.argtypes = [c_void_p, POINTER(c_int)]\n            self._sdk.tl_mono_to_color_set_output_format.argtypes = [c_void_p, c_int]\n            self._sdk.tl_mono_to_color_get_red_gain.argtypes = [c_void_p, POINTER(c_float)]\n            self._sdk.tl_mono_to_color_set_red_gain.argtypes = [c_void_p, c_float]\n            self._sdk.tl_mono_to_color_get_green_gain.argtypes = [c_void_p, POINTER(c_float)]\n            self._sdk.tl_mono_to_color_set_green_gain.argtypes = [c_void_p, c_float]\n            self._sdk.tl_mono_to_color_get_blue_gain.argtypes = [c_void_p, POINTER(c_float)]\n            self._sdk.tl_mono_to_color_set_blue_gain.argtypes = [c_void_p, c_float]\n            self._sdk.tl_mono_to_color_transform_to_48.argtypes = [c_void_p, POINTER(c_ushort), c_int, c_int,\n                                                                   POINTER(c_ushort)]\n            self._sdk.tl_mono_to_color_transform_to_32.argtypes = [c_void_p, POINTER(c_ushort), c_int, c_int,\n                                                                   POINTER(c_ubyte)]\n            self._sdk.tl_mono_to_color_transform_to_24.argtypes = [c_void_p, POINTER(c_ushort), c_int, c_int,\n                                                                   POINTER(c_ubyte)]\n            self._sdk.tl_mono_to_color_processing_module_terminate.argtypes = []\n            self._sdk.tl_mono_to_color_get_last_error.restype = c_char_p\n            self._sdk.tl_mono_to_color_get_camera_sensor_type.argtypes = [c_void_p, POINTER(c_int)]\n            self._sdk.tl_mono_to_color_get_color_filter_array_phase.argtypes = [c_void_p, POINTER(c_int)]\n            self._sdk.tl_mono_to_color_get_color_correction_matrix.argtypes = [c_void_p,\n                                                                               POINTER(POINTER(_3x3Matrix_float))]\n            self._sdk.tl_mono_to_color_get_default_white_balance_matrix.argtypes = [c_void_p,\n                                                                                    POINTER(POINTER(_3x3Matrix_float))]\n            self._sdk.tl_mono_to_color_get_bit_depth = [c_void_p, POINTER(c_int)]\n        except Exception as exception:\n            _logger.error(\"SDK initialization failed; \" + str(exception))\n            raise exception\n\n    def __del__(self):\n        self.dispose()\n\n    \"\"\" with statement functionality \"\"\"\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, exception_type, exception_value, exception_traceback):\n        if exception_type is not None:\n            _logger.debug(\"\".join(format_exception(exception_type, exception_value, exception_traceback)))\n        self.dispose()\n        return True if exception_type is None else False\n\n    \"\"\" methods \"\"\"\n\n    def dispose(self):\n        # type: (type(None)) -> None\n        \"\"\"\n        Cleans up the MonoToColorProcessorSDK instance - make sure to call this when you are done with the\n        MonoToColorProcessorSDK instance. If using the *with* statement, dispose is called automatically upon exit.\n\n        \"\"\"\n        try:\n            if self._disposed:\n                return\n            error_code = self._sdk.tl_mono_to_color_processing_module_terminate()\n            if error_code != 0:\n                raise MonoToColorError(_create_c_failure_message(\n                    self._sdk, \"tl_mono_to_color_processing_module_terminate\", error_code))\n            MonoToColorProcessorSDK._is_sdk_open = False\n            self._disposed = True\n        except Exception as exception:\n            _logger.error(\"Mono To Color SDK destruction failed; \" + str(exception))\n            raise exception\n\n    def create_mono_to_color_processor(self, camera_sensor_type, color_filter_array_phase, color_correction_matrix,\n                                       default_white_balance_matrix, bit_depth):\n        # type: (SENSOR_TYPE, FILTER_ARRAY_PHASE, np.array, np.array, int) -> MonoToColorProcessor\n        \"\"\"\n        Creates a MonoToColorProcessor object using the given parameters.\n\n        :parameter: - **camera_sensor_type** (:class:`SENSOR_TYPE<thorlabs_tsi_sdk.tl_camera_enums.SENSOR_TYPE>`) - The sensor type used by the camera. Use the property :attr:`TLCamera.camera_sensor_type<thorlabs_tsi_sdk.tl_camera.TLCamera.camera_sensor_type>` to get this information from a camera.\n        :parameter: - **color_filter_array_phase** (:class:`FILTER_ARRAY_PHASE<thorlabs_tsi_sdk.tl_color.FILTER_ARRAY_PHASE>`) - The array phase of the camera's color filter. Use :attr:`TLCamera.color_filter_array_phase<thorlabs_tsi_sdk.tl_camera.TLCamera.color_filter_array_phase>` to get this information from a camera.\n        :parameter: - **color_correction_matrix** (np.array) - A 3x3 correction matrix specific to a camera model that is used during color processing to achieve accurate coloration. use :meth:`TLCamera.get_color_correction_matrix<thorlabs_tsi_sdk.tl_camera.TLCamera.get_color_correction_matrix>` to get this information from a camera.\n        :parameter: - **default_white_balance_matrix** (np.array) - A 3x3 correction matrix specific to a camera model that is used during color processing to white balance images under typical lighting conditions. Use :meth:`TLCamera.get_default_white_balance_matrix<thorlabs_tsi_sdk.tl_camera.TLCamera.get_default_white_balance_matrix>` to get this information from a camera.\n        :parameter: - **bit_depth** (int) - The bit depth that will be used during color processing. To get the bit depth of a camera, use :attr:`TLCamera.bit_depth<thorlabs_tsi_sdk.tl_camera.TLCamera.bit_depth>`\n\n        :returns: :class:`MonoToColorProcessor<thorlabs_tsi_sdk.tl_mono_to_color_processor.MonoToColorProcessor>`\n\n        \"\"\"\n        try:\n            c_mono_to_color_handle = c_void_p()\n            c_camera_sensor_type = c_int(camera_sensor_type)\n            c_color_filter_array_phase = c_int(color_filter_array_phase)\n            c_color_correction_matrix = _3x3Matrix_float(*color_correction_matrix)\n            c_default_white_balance_matrix = _3x3Matrix_float(*default_white_balance_matrix)\n            c_bit_depth = c_int(bit_depth)\n            error_code = self._sdk.tl_mono_to_color_create_mono_to_color_processor(c_camera_sensor_type,\n                                                                                   c_color_filter_array_phase,\n                                                                                   c_color_correction_matrix,\n                                                                                   c_default_white_balance_matrix,\n                                                                                   c_bit_depth,\n                                                                                   c_mono_to_color_handle)\n            if error_code != 0:\n                raise MonoToColorError(_create_c_failure_message(\n                    self._sdk, \"tl_mono_to_color_create_mono_to_color_processor\", error_code))\n            # noinspection PyProtectedMember\n            return MonoToColorProcessor._create(self._sdk, c_mono_to_color_handle)\n        except Exception as exception:\n            _logger.error(\"Failed to create mono to color processor; \" + str(exception))\n            raise exception",
  "class MonoToColorProcessor(object):\n\n    \"\"\"\n    MonoToColorProcessor\n\n    These objects are used to quickly convert monochrome image data to colored image data. When finished with a MonoToColorProcessor,\n    call its :meth:`dispose<thorlabs_tsi_sdk.tl_mono_to_color_processor.MonoToColorProcessor.dispose>` method to clean up any opened resources. These object can\n    be managed using *with* statements for automatic resource clean up. These objects can only be created by calls to\n    :meth:`MonoToColorProcessorSDK.create_mono_to_color_processor()<thorlabs_tsi_sdk.tl_mono_to_color_processor.MonoToColorProcessorSDK.create_mono_to_color_processor>`\n\n    \"\"\"\n\n    __key = object()\n\n    @classmethod\n    def _create(cls, sdk, mono_to_color_processor_handle):\n        # type: (Any, Any) -> MonoToColorProcessor\n        return MonoToColorProcessor(cls.__key, sdk, mono_to_color_processor_handle)\n\n    def __init__(self, key, sdk, mono_to_color_processor_handle):\n        # type: (type(object), Any, Any) -> None\n        try:\n            self._disposed = True\n            assert (key == MonoToColorProcessor.__key), \\\n                \"MonoToColorProcessor objects cannot be created manually. Please use \" \\\n                \"MonoToColorProcessorSDK.create_mono_to_color_processor to acquire new MonoToColorProcessor objects.\"\n            self._sdk = sdk\n            self._mono_to_color_processor_handle = mono_to_color_processor_handle\n            self._disposed = False\n        except Exception as exception:\n            _logger.error(\"MonoToColorProcessor initialization failed; \" + str(exception))\n            raise exception\n\n    def __del__(self):\n        self.dispose()\n\n    \"\"\" with statement functionality \"\"\"\n    def __enter__(self):\n        return self\n\n    def __exit__(self, exception_type, exception_value, exception_traceback):\n        if exception_type is not None:\n            _logger.debug(\"\".join(format_exception(exception_type, exception_value, exception_traceback)))\n        self.dispose()\n        return True if exception_type is None else False\n\n    def dispose(self):\n        # type: (type(None)) -> None\n        \"\"\"\n        Cleans up the MonoToColorProcessor instance - make sure to call this when you are done with the MonoToColor\n        processor. If using the *with* statement, dispose is called automatically upon exit.\n\n        \"\"\"\n        try:\n            if self._disposed:\n                return\n            error_code = self._sdk.tl_mono_to_color_destroy_mono_to_color_processor(\n                self._mono_to_color_processor_handle)\n            if error_code != 0:\n                raise MonoToColorError(_create_c_failure_message(\n                    self._sdk, \"tl_mono_to_color_destroy_mono_to_color_processor\", error_code))\n            self._disposed = True\n        except Exception as exception:\n            _logger.error(\"Could not dispose MonoToColorProcessor instance; \" + str(exception))\n            raise exception\n\n    def transform_to_48(self, input_buffer, image_width_pixels, image_height_pixels):\n        # type: (np.array, int, int) -> np.array\n        \"\"\"\n        Convert monochrome image data into a 3-channel colored image with 16 bits per channel, resulting in 48 bits per\n        pixel. The pixel data will be ordered according to the current value of\n        :attr:`output_format<thorlabs_tsi_sdk.tl_mono_to_color_processor.MonoToColorProcessor.output_format>`.\n\n        :param np.array input_buffer: Single channel monochrome image data. The size of this array should be image_width * image_height. The dtype of the array should be ctypes.c_ushort or a type of equivalent size, the image buffer that comes directly from the camera is compatible (see: :meth:`TLCamera.get_pending_frame_or_null()<thorlabs_tsi_sdk.tl_camera.TLCamera.get_pending_frame_or_null>`).\n        :param int image_width_pixels: The width of the image in the image_buffer.\n        :param int image_height_pixels: The height of the image in the image_buffer.\n        :return np.array: 3-channel colored output image, *dtype* = ctypes.c_ushort.\n        \"\"\"\n        try:\n            output_buffer = np.zeros(shape=(image_width_pixels*image_height_pixels*3,), dtype=c_ushort)\n            output_buffer_pointer = output_buffer.ctypes.data_as(POINTER(c_ushort))\n            input_buffer_pointer = input_buffer.ctypes.data_as(POINTER(c_ushort))\n            c_image_width = c_int(image_width_pixels)\n            c_image_height = c_int(image_height_pixels)\n            error_code = self._sdk.tl_mono_to_color_transform_to_48(self._mono_to_color_processor_handle,\n                                                                    input_buffer_pointer,\n                                                                    c_image_width,\n                                                                    c_image_height,\n                                                                    output_buffer_pointer)\n            if error_code != 0:\n                raise MonoToColorError(_create_c_failure_message(self._sdk, \"tl_mono_to_color_transform_to_48\",\n                                                                 error_code))\n            return output_buffer\n        except Exception as exception:\n            _logger.error(\"Could not transform image to 48bpp; \" + str(exception))\n            raise exception\n\n    def transform_to_32(self, input_buffer, image_width_pixels, image_height_pixels):\n        # type: (np.array, int, int) -> np.array\n        \"\"\"\n        Convert monochrome image data into a 4-channel colored image with 8 bits per channel, resulting in 32 bits per\n        pixel. The pixel data will be ordered according to the current value of\n        :attr:`output_format<thorlabs_tsi_sdk.tl_mono_to_color_processor.MonoToColorProcessor.output_format>`.\n\n        :param np.array input_buffer: Single channel monochrome image data. The size of this array should be image_width * image_height. The dtype of the array should be ctypes.c_ushort or a type of equivalent size, the image buffer that comes directly from the camera is compatible (see: :meth:`TLCamera.get_pending_frame_or_null()<thorlabs_tsi_sdk.tl_camera.TLCamera.get_pending_frame_or_null>`).\n        :param int image_width_pixels: The width of the image in the image_buffer.\n        :param int image_height_pixels: The height of the image in the image_buffer.\n        :return np.array: 4-channel colored output image, *dtype* = ctypes.c_ubyte.\n        \"\"\"\n        try:\n            output_buffer = np.zeros(shape=(image_width_pixels*image_height_pixels*4,), dtype=c_ubyte)\n            output_buffer_pointer = output_buffer.ctypes.data_as(POINTER(c_ubyte))\n            input_buffer_pointer = input_buffer.ctypes.data_as(POINTER(c_ushort))\n            c_image_width = c_int(image_width_pixels)\n            c_image_height = c_int(image_height_pixels)\n            error_code = self._sdk.tl_mono_to_color_transform_to_32(self._mono_to_color_processor_handle,\n                                                                    input_buffer_pointer,\n                                                                    c_image_width,\n                                                                    c_image_height,\n                                                                    output_buffer_pointer)\n            if error_code != 0:\n                raise MonoToColorError(_create_c_failure_message(self._sdk, \"tl_mono_to_color_transform_to_32\",\n                                                                 error_code))\n            return output_buffer\n        except Exception as exception:\n            _logger.error(\"Could not transform image to 32bpp; \" + str(exception))\n            raise exception\n\n    def transform_to_24(self, input_buffer, image_width_pixels, image_height_pixels):\n        # type: (np.array, int, int) -> np.array\n        \"\"\"\n        Convert monochrome image data into a 3-channel colored image with 8 bits per channel, resulting in 24 bits per\n        pixel. The pixel data will be ordered according to the current value of\n        :attr:`output_format<thorlabs_tsi_sdk.tl_mono_to_color_processor.MonoToColorProcessor.output_format>`.\n\n        :param np.array input_buffer: Single channel monochrome image data. The size of this array should be image_width * image_height. The dtype of the array should be ctypes.c_ushort or a type of equivalent size, the image buffer that comes directly from the camera is compatible (see: :meth:`TLCamera.get_pending_frame_or_null()<thorlabs_tsi_sdk.tl_camera.TLCamera.get_pending_frame_or_null>`).\n        :param int image_width_pixels: The width of the image in the input_buffer.\n        :param int image_height_pixels: The height of the image in the input_buffer.\n        :return np.array: 3-channel colored output image, *dtype* = ctypes.c_ubyte.\n        \"\"\"\n        try:\n            output_buffer = np.zeros(shape=(image_width_pixels*image_height_pixels*3,), dtype=c_ubyte)\n            output_buffer_pointer = output_buffer.ctypes.data_as(POINTER(c_ubyte))\n            input_buffer_pointer = input_buffer.ctypes.data_as(POINTER(c_ushort))\n            c_image_width = c_int(image_width_pixels)\n            c_image_height = c_int(image_height_pixels)\n            error_code = self._sdk.tl_mono_to_color_transform_to_24(self._mono_to_color_processor_handle,\n                                                                    input_buffer_pointer,\n                                                                    c_image_width,\n                                                                    c_image_height,\n                                                                    output_buffer_pointer)\n            if error_code != 0:\n                raise MonoToColorError(_create_c_failure_message(self._sdk, \"tl_mono_to_color_transform_to_24\",\n                                                                 error_code))\n            return output_buffer\n        except Exception as exception:\n            _logger.error(\"Could not transform image to 24bpp; \" + str(exception))\n            raise exception\n\n    \"\"\" Properties \"\"\"\n\n    @property\n    def color_space(self):\n        \"\"\"\n        The color space of the mono to color processor. See :class:`COLOR_SPACE<thorlabs_tsi_sdk.tl_mono_to_color_enums.COLOR_SPACE>` for what color spaces\n        are available.\n\n        :type: :class:`COLOR_SPACE<thorlabs_tsi_sdk.tl_mono_to_color_enums.COLOR_SPACE>`\n        \"\"\"\n        try:\n            color_space = c_int()\n            error_code = self._sdk.tl_mono_to_color_get_color_space(self._mono_to_color_processor_handle, color_space)\n            if error_code != 0:\n                raise MonoToColorError(_create_c_failure_message(self._sdk, \"tl_mono_to_color_get_color_space\",\n                                                                 error_code))\n            return COLOR_SPACE(int(color_space.value))\n        except Exception as exception:\n            _logger.error(\"Could not get color space; \" + str(exception))\n            raise exception\n\n    @color_space.setter\n    def color_space(self, color_space):\n        try:\n            c_value = c_int(color_space)\n            error_code = self._sdk.tl_mono_to_color_set_color_space(self._mono_to_color_processor_handle, c_value)\n            if error_code != 0:\n                raise MonoToColorError(_create_c_failure_message(self._sdk, \"tl_mono_to_color_set_color_space\",\n                                                                 error_code))\n        except Exception as exception:\n            _logger.error(\"Could not set color space; \" + str(exception))\n            raise exception\n\n    @property\n    def output_format(self):\n        \"\"\"\n        The format of the colored output image. This describes how the data is ordered in the returned buffer from the\n        transform functions. By default it is RGB_PIXEL. See :class:`FORMAT<thorlabs_tsi_sdk.tl_color_enums.FORMAT>`.\n\n        :type: :class:`FORMAT<thorlabs_tsi_sdk.tl_mono_to_color_enums.FORMAT>`\n        \"\"\"\n        try:\n            output_format = c_int()\n            error_code = self._sdk.tl_mono_to_color_get_output_format(self._mono_to_color_processor_handle,\n                                                                      output_format)\n            if error_code != 0:\n                raise MonoToColorError(_create_c_failure_message(self._sdk, \"tl_mono_to_color_get_output_format\",\n                                                                 error_code))\n            return FORMAT(int(output_format.value))\n        except Exception as exception:\n            _logger.error(\"Could not get output format; \" + str(exception))\n            raise exception\n\n    @output_format.setter\n    def output_format(self, output_format):\n        try:\n            c_value = c_int(output_format)\n            error_code = self._sdk.tl_mono_to_color_set_output_format(self._mono_to_color_processor_handle, c_value)\n            if error_code != 0:\n                raise MonoToColorError(_create_c_failure_message(self._sdk, \"tl_mono_to_color_set_output_format\",\n                                                                 error_code))\n        except Exception as exception:\n            _logger.error(\"Could not set output format; \" + str(exception))\n            raise exception\n\n    @property\n    def red_gain(self):\n        \"\"\"\n        The gain factor that will be applied to the red pixel values in the image. The red intensities will be\n        multiplied by this gain value in the final colored image. The default red gain is\n        taken from the :attr:`default_white_balance_matrix<thorlabs_tsi_sdk.tl_mono_to_color_processor.MonoToColorProcessor.default_white_balance_matrix>` that\n        is passed in when constructing a\n        :meth:`MonoToColorProcessor<thorlabs_tsi_sdk.tl_mono_to_color_processor.MonoToColorProcessorSDK.create_mono_to_color_processor>`.\n\n        :type: float\n        \"\"\"\n        try:\n            red_gain = c_float()\n            error_code = self._sdk.tl_mono_to_color_get_red_gain(self._mono_to_color_processor_handle, red_gain)\n            if error_code != 0:\n                raise MonoToColorError(_create_c_failure_message(self._sdk, \"tl_mono_to_color_get_red_gain\",\n                                                                 error_code))\n            return float(red_gain.value)\n        except Exception as exception:\n            _logger.error(\"Could not get red gain value; \" + str(exception))\n            raise exception\n\n    @red_gain.setter\n    def red_gain(self, red_gain):\n        try:\n            c_value = c_float(red_gain)\n            error_code = self._sdk.tl_mono_to_color_set_red_gain(self._mono_to_color_processor_handle, c_value)\n            if error_code != 0:\n                raise MonoToColorError(_create_c_failure_message(self._sdk, \"tl_mono_to_color_set_red_gain\",\n                                                                 error_code))\n        except Exception as exception:\n            _logger.error(\"Could not set red gain value; \" + str(exception))\n            raise exception\n\n    @property\n    def blue_gain(self):\n        \"\"\"\n        The gain factor that will be applied to the red pixel values in the image. The blue intensities will be\n        multiplied by this gain value in the final colored image. The default blue gain is\n        taken from the :attr:`default_white_balance_matrix<thorlabs_tsi_sdk.tl_mono_to_color_processor.MonoToColorProcessor.default_white_balance_matrix>` that\n        is passed in when constructing a\n        :meth:`MonoToColorProcessor<thorlabs_tsi_sdk.tl_mono_to_color_processor.MonoToColorProcessorSDK.create_mono_to_color_processor>`.\n\n        :type: float\n        \"\"\"\n        try:\n            blue_gain = c_float()\n            error_code = self._sdk.tl_mono_to_color_get_blue_gain(self._mono_to_color_processor_handle, blue_gain)\n            if error_code != 0:\n                raise MonoToColorError(_create_c_failure_message(self._sdk, \"tl_mono_to_color_get_blue_gain\",\n                                                                 error_code))\n            return float(blue_gain.value)\n        except Exception as exception:\n            _logger.error(\"Could not get blue gain value; \" + str(exception))\n            raise exception\n\n    @blue_gain.setter\n    def blue_gain(self, blue_gain):\n        try:\n            c_value = c_float(blue_gain)\n            error_code = self._sdk.tl_mono_to_color_set_blue_gain(self._mono_to_color_processor_handle, c_value)\n            if error_code != 0:\n                raise MonoToColorError(_create_c_failure_message(self._sdk, \"tl_mono_to_color_set_blue_gain\",\n                                                                 error_code))\n        except Exception as exception:\n            _logger.error(\"Could not set blue gain value; \" + str(exception))\n            raise exception\n\n    @property\n    def green_gain(self):\n        \"\"\"\n        The gain factor that will be applied to the red pixel values in the image. The green intensities will be\n        multiplied by this gain value in the final colored image. The default green gain is\n        taken from the :attr:`default_white_balance_matrix<thorlabs_tsi_sdk.tl_mono_to_color_processor.MonoToColorProcessor.default_white_balance_matrix>` that\n        is passed in when constructing a\n        :meth:`MonoToColorProcessor<thorlabs_tsi_sdk.tl_mono_to_color_processor.MonoToColorProcessorSDK.create_mono_to_color_processor>`.\n\n        :type: float\n        \"\"\"\n        try:\n            green_gain = c_float()\n            error_code = self._sdk.tl_mono_to_color_get_green_gain(self._mono_to_color_processor_handle, green_gain)\n            if error_code != 0:\n                raise MonoToColorError(_create_c_failure_message(self._sdk, \"tl_mono_to_color_get_green_gain\",\n                                                                 error_code))\n            return float(green_gain.value)\n        except Exception as exception:\n            _logger.error(\"Could not get green gain value; \" + str(exception))\n            raise exception\n\n    @green_gain.setter\n    def green_gain(self, green_gain):\n        try:\n            c_value = c_float(green_gain)\n            error_code = self._sdk.tl_mono_to_color_set_green_gain(self._mono_to_color_processor_handle, c_value)\n            if error_code != 0:\n                raise MonoToColorError(_create_c_failure_message(self._sdk, \"tl_mono_to_color_set_green_gain\",\n                                                                 error_code))\n        except Exception as exception:\n            _logger.error(\"Could not set green gain value; \" + str(exception))\n            raise exception\n\n    @property\n    def camera_sensor_type(self):\n        \"\"\"\n        The sensor type of the camera (monochrome, bayer, etc...). This value is passed in during construction and may\n        be read back using this property.\n\n        :type: :class:`SENSOR_TYPE<thorlabs_tsi_sdk.tl_camera_enums.SENSOR_TYPE>`\n        \"\"\"\n        try:\n            camera_sensor_type = c_int()\n            error_code = self._sdk.tl_mono_to_color_get_camera_sensor_type(self._mono_to_color_processor_handle,\n                                                                           camera_sensor_type)\n            if error_code != 0:\n                raise MonoToColorError(_create_c_failure_message(self._sdk, \"tl_mono_to_color_get_camera_sensor_type\",\n                                                                 error_code))\n            return SENSOR_TYPE(int(camera_sensor_type.value))\n        except Exception as exception:\n            _logger.error(\"Could not get camera sensor type; \" + str(exception))\n            raise exception\n\n    @property\n    def color_filter_array_phase(self):\n        \"\"\"\n        The color filter array phase used in this mono to color processor. This value is passed in during construction\n        and may be read back using this property.\n\n        :type: :class:`FILTER_ARRAY_PHASE<thorlabs_tsi_sdk.tl_color.FILTER_ARRAY_PHASE>`\n        \"\"\"\n        try:\n            color_filter_array_phase = c_int()\n            error_code = self._sdk.tl_mono_to_color_get_color_filter_array_phase(self._mono_to_color_processor_handle,\n                                                                                 color_filter_array_phase)\n            if error_code != 0:\n                raise MonoToColorError(_create_c_failure_message(\n                    self._sdk, \"tl_mono_to_color_get_color_filter_array_phase\", error_code))\n            return FILTER_ARRAY_PHASE(int(color_filter_array_phase.value))\n        except Exception as exception:\n            _logger.error(\"Could not get color filter array phase; \" + str(exception))\n            raise exception\n\n    @property\n    def color_correction_matrix(self):\n        \"\"\"\n        The default color correction matrix associated with the mono to color processor. This value is passed in during\n        construction and may be read back using this property.\n\n        :type: np.array\n        \"\"\"\n        try:\n            color_correction_matrix = _3x3Matrix_float()\n            error_code = self._sdk.tl_mono_to_color_get_color_correction_matrix(self._mono_to_color_processor_handle,\n                                                                                color_correction_matrix)\n            if error_code != 0:\n                raise MonoToColorError(_create_c_failure_message(\n                    self._sdk, \"tl_mono_to_color_get_color_correction_matrix\", error_code))\n            color_correction_matrix_as_np_array = np.array([float(color_correction_matrix[0]),\n                                                            float(color_correction_matrix[1]),\n                                                            float(color_correction_matrix[2]),\n                                                            float(color_correction_matrix[3]),\n                                                            float(color_correction_matrix[4]),\n                                                            float(color_correction_matrix[5]),\n                                                            float(color_correction_matrix[6]),\n                                                            float(color_correction_matrix[7]),\n                                                            float(color_correction_matrix[8])])\n            return color_correction_matrix_as_np_array\n        except Exception as exception:\n            _logger.error(\"Could not get color correction matrix; \" + str(exception))\n            raise exception\n\n    @property\n    def default_white_balance_matrix(self):\n        \"\"\"\n        The default white balance matrix associated with the mono to color processor. This value is passed in during\n        construction and may be read back using this property.\n\n        :type: np.array\n        \"\"\"\n        try:\n            default_white_balance_matrix = _3x3Matrix_float()\n            error_code = self._sdk.tl_mono_to_color_get_default_white_balance_matrix(\n                self._mono_to_color_processor_handle, default_white_balance_matrix)\n            if error_code != 0:\n                raise MonoToColorError(_create_c_failure_message(\n                    self._sdk, \"tl_mono_to_color_get_default_white_balance_matrix\", error_code))\n            default_white_balance_matrix_as_np_array = np.array([float(default_white_balance_matrix[0]),\n                                                                float(default_white_balance_matrix[1]),\n                                                                float(default_white_balance_matrix[2]),\n                                                                float(default_white_balance_matrix[3]),\n                                                                float(default_white_balance_matrix[4]),\n                                                                float(default_white_balance_matrix[5]),\n                                                                float(default_white_balance_matrix[6]),\n                                                                float(default_white_balance_matrix[7]),\n                                                                float(default_white_balance_matrix[8])])\n            return default_white_balance_matrix_as_np_array\n        except Exception as exception:\n            _logger.error(\"Could not get default white balance matrix; \" + str(exception))\n            raise exception\n\n    @property\n    def bit_depth(self):\n        \"\"\"\n        The bit depth associated with the mono to color processor. This value is passed in during construction and may\n        be read back using this property.\n\n        :type: int\n        \"\"\"\n        try:\n            bit_depth = c_int()\n            error_code = self._sdk.tl_mono_to_color_get_bit_depth(self._mono_to_color_processor_handle, bit_depth)\n            if error_code != 0:\n                raise MonoToColorError(_create_c_failure_message(self._sdk, \"tl_mono_to_color_get_bit_depth\",\n                                                                 error_code))\n            return int(bit_depth.value)\n        except Exception as exception:\n            _logger.error(\"Could not get bit depth; \" + str(exception))\n            raise exception",
  "class MonoToColorError(Exception):\n    def __init__(self, message):\n        _logger.debug(message)\n        super(MonoToColorError, self).__init__(message)",
  "def __init__(self):\n        # type: (type(None)) -> None\n        self._disposed = True\n\n        if MonoToColorProcessorSDK._is_sdk_open:\n            raise MonoToColorError(\"MonoToColorProcessorSDK is already in use. Please dispose of the current instance \"\n                                   \"before trying to create another instance.\")\n\n        try:\n            if platform.system() == 'Windows':\n                self._sdk = cdll.LoadLibrary(r\"thorlabs_tsi_mono_to_color_processing.dll\")\n            elif platform.system() == 'Linux':\n                self._sdk = cdll.LoadLibrary(r\"libthorlabs_tsi_mono_to_color_processing.so\")\n            else:\n                raise MonoToColorError(\"{system} is not a supported platform.\".format(system=platform.system()))\n            self._disposed = False\n        except OSError as os_error:\n            raise MonoToColorError(str(os_error) +\n                                   \"\\nUnable to load library - are the thorlabs tsi mono to color sdk libraries \"\n                                   \"discoverable from the application directory? Try placing them in the same \"\n                                   \"directory as your program, or adding the directory with the libraries to the \"\n                                   \"PATH. Make sure to use 32-bit libraries when using a 32-bit python interpreter \"\n                                   \"and 64-bit libraries when using a 64-bit interpreter.\\n\")\n\n        error_code = self._sdk.tl_mono_to_color_processing_module_initialize()\n        if error_code != 0:\n            raise MonoToColorError(\"tl_mono_to_color_processing_module_initialize() returned error code: {error_code}\\n\"\n                                   .format(error_code=error_code))\n        MonoToColorProcessorSDK._is_sdk_open = True\n\n        try:\n            \"\"\" set C function argument types \"\"\"\n            self._sdk.tl_mono_to_color_create_mono_to_color_processor.argtypes = [c_int, c_int,\n                                                                                  POINTER(_3x3Matrix_float),\n                                                                                  POINTER(_3x3Matrix_float), c_int,\n                                                                                  POINTER(c_void_p)]\n            self._sdk.tl_mono_to_color_destroy_mono_to_color_processor.argtypes = [c_void_p]\n            self._sdk.tl_mono_to_color_get_color_space.argtypes = [c_void_p, POINTER(c_int)]\n            self._sdk.tl_mono_to_color_set_color_space.argtypes = [c_void_p, c_int]\n            self._sdk.tl_mono_to_color_get_output_format.argtypes = [c_void_p, POINTER(c_int)]\n            self._sdk.tl_mono_to_color_set_output_format.argtypes = [c_void_p, c_int]\n            self._sdk.tl_mono_to_color_get_red_gain.argtypes = [c_void_p, POINTER(c_float)]\n            self._sdk.tl_mono_to_color_set_red_gain.argtypes = [c_void_p, c_float]\n            self._sdk.tl_mono_to_color_get_green_gain.argtypes = [c_void_p, POINTER(c_float)]\n            self._sdk.tl_mono_to_color_set_green_gain.argtypes = [c_void_p, c_float]\n            self._sdk.tl_mono_to_color_get_blue_gain.argtypes = [c_void_p, POINTER(c_float)]\n            self._sdk.tl_mono_to_color_set_blue_gain.argtypes = [c_void_p, c_float]\n            self._sdk.tl_mono_to_color_transform_to_48.argtypes = [c_void_p, POINTER(c_ushort), c_int, c_int,\n                                                                   POINTER(c_ushort)]\n            self._sdk.tl_mono_to_color_transform_to_32.argtypes = [c_void_p, POINTER(c_ushort), c_int, c_int,\n                                                                   POINTER(c_ubyte)]\n            self._sdk.tl_mono_to_color_transform_to_24.argtypes = [c_void_p, POINTER(c_ushort), c_int, c_int,\n                                                                   POINTER(c_ubyte)]\n            self._sdk.tl_mono_to_color_processing_module_terminate.argtypes = []\n            self._sdk.tl_mono_to_color_get_last_error.restype = c_char_p\n            self._sdk.tl_mono_to_color_get_camera_sensor_type.argtypes = [c_void_p, POINTER(c_int)]\n            self._sdk.tl_mono_to_color_get_color_filter_array_phase.argtypes = [c_void_p, POINTER(c_int)]\n            self._sdk.tl_mono_to_color_get_color_correction_matrix.argtypes = [c_void_p,\n                                                                               POINTER(POINTER(_3x3Matrix_float))]\n            self._sdk.tl_mono_to_color_get_default_white_balance_matrix.argtypes = [c_void_p,\n                                                                                    POINTER(POINTER(_3x3Matrix_float))]\n            self._sdk.tl_mono_to_color_get_bit_depth = [c_void_p, POINTER(c_int)]\n        except Exception as exception:\n            _logger.error(\"SDK initialization failed; \" + str(exception))\n            raise exception",
  "def __del__(self):\n        self.dispose()",
  "def __enter__(self):\n        return self",
  "def __exit__(self, exception_type, exception_value, exception_traceback):\n        if exception_type is not None:\n            _logger.debug(\"\".join(format_exception(exception_type, exception_value, exception_traceback)))\n        self.dispose()\n        return True if exception_type is None else False",
  "def dispose(self):\n        # type: (type(None)) -> None\n        \"\"\"\n        Cleans up the MonoToColorProcessorSDK instance - make sure to call this when you are done with the\n        MonoToColorProcessorSDK instance. If using the *with* statement, dispose is called automatically upon exit.\n\n        \"\"\"\n        try:\n            if self._disposed:\n                return\n            error_code = self._sdk.tl_mono_to_color_processing_module_terminate()\n            if error_code != 0:\n                raise MonoToColorError(_create_c_failure_message(\n                    self._sdk, \"tl_mono_to_color_processing_module_terminate\", error_code))\n            MonoToColorProcessorSDK._is_sdk_open = False\n            self._disposed = True\n        except Exception as exception:\n            _logger.error(\"Mono To Color SDK destruction failed; \" + str(exception))\n            raise exception",
  "def create_mono_to_color_processor(self, camera_sensor_type, color_filter_array_phase, color_correction_matrix,\n                                       default_white_balance_matrix, bit_depth):\n        # type: (SENSOR_TYPE, FILTER_ARRAY_PHASE, np.array, np.array, int) -> MonoToColorProcessor\n        \"\"\"\n        Creates a MonoToColorProcessor object using the given parameters.\n\n        :parameter: - **camera_sensor_type** (:class:`SENSOR_TYPE<thorlabs_tsi_sdk.tl_camera_enums.SENSOR_TYPE>`) - The sensor type used by the camera. Use the property :attr:`TLCamera.camera_sensor_type<thorlabs_tsi_sdk.tl_camera.TLCamera.camera_sensor_type>` to get this information from a camera.\n        :parameter: - **color_filter_array_phase** (:class:`FILTER_ARRAY_PHASE<thorlabs_tsi_sdk.tl_color.FILTER_ARRAY_PHASE>`) - The array phase of the camera's color filter. Use :attr:`TLCamera.color_filter_array_phase<thorlabs_tsi_sdk.tl_camera.TLCamera.color_filter_array_phase>` to get this information from a camera.\n        :parameter: - **color_correction_matrix** (np.array) - A 3x3 correction matrix specific to a camera model that is used during color processing to achieve accurate coloration. use :meth:`TLCamera.get_color_correction_matrix<thorlabs_tsi_sdk.tl_camera.TLCamera.get_color_correction_matrix>` to get this information from a camera.\n        :parameter: - **default_white_balance_matrix** (np.array) - A 3x3 correction matrix specific to a camera model that is used during color processing to white balance images under typical lighting conditions. Use :meth:`TLCamera.get_default_white_balance_matrix<thorlabs_tsi_sdk.tl_camera.TLCamera.get_default_white_balance_matrix>` to get this information from a camera.\n        :parameter: - **bit_depth** (int) - The bit depth that will be used during color processing. To get the bit depth of a camera, use :attr:`TLCamera.bit_depth<thorlabs_tsi_sdk.tl_camera.TLCamera.bit_depth>`\n\n        :returns: :class:`MonoToColorProcessor<thorlabs_tsi_sdk.tl_mono_to_color_processor.MonoToColorProcessor>`\n\n        \"\"\"\n        try:\n            c_mono_to_color_handle = c_void_p()\n            c_camera_sensor_type = c_int(camera_sensor_type)\n            c_color_filter_array_phase = c_int(color_filter_array_phase)\n            c_color_correction_matrix = _3x3Matrix_float(*color_correction_matrix)\n            c_default_white_balance_matrix = _3x3Matrix_float(*default_white_balance_matrix)\n            c_bit_depth = c_int(bit_depth)\n            error_code = self._sdk.tl_mono_to_color_create_mono_to_color_processor(c_camera_sensor_type,\n                                                                                   c_color_filter_array_phase,\n                                                                                   c_color_correction_matrix,\n                                                                                   c_default_white_balance_matrix,\n                                                                                   c_bit_depth,\n                                                                                   c_mono_to_color_handle)\n            if error_code != 0:\n                raise MonoToColorError(_create_c_failure_message(\n                    self._sdk, \"tl_mono_to_color_create_mono_to_color_processor\", error_code))\n            # noinspection PyProtectedMember\n            return MonoToColorProcessor._create(self._sdk, c_mono_to_color_handle)\n        except Exception as exception:\n            _logger.error(\"Failed to create mono to color processor; \" + str(exception))\n            raise exception",
  "def _create(cls, sdk, mono_to_color_processor_handle):\n        # type: (Any, Any) -> MonoToColorProcessor\n        return MonoToColorProcessor(cls.__key, sdk, mono_to_color_processor_handle)",
  "def __init__(self, key, sdk, mono_to_color_processor_handle):\n        # type: (type(object), Any, Any) -> None\n        try:\n            self._disposed = True\n            assert (key == MonoToColorProcessor.__key), \\\n                \"MonoToColorProcessor objects cannot be created manually. Please use \" \\\n                \"MonoToColorProcessorSDK.create_mono_to_color_processor to acquire new MonoToColorProcessor objects.\"\n            self._sdk = sdk\n            self._mono_to_color_processor_handle = mono_to_color_processor_handle\n            self._disposed = False\n        except Exception as exception:\n            _logger.error(\"MonoToColorProcessor initialization failed; \" + str(exception))\n            raise exception",
  "def __del__(self):\n        self.dispose()",
  "def __enter__(self):\n        return self",
  "def __exit__(self, exception_type, exception_value, exception_traceback):\n        if exception_type is not None:\n            _logger.debug(\"\".join(format_exception(exception_type, exception_value, exception_traceback)))\n        self.dispose()\n        return True if exception_type is None else False",
  "def dispose(self):\n        # type: (type(None)) -> None\n        \"\"\"\n        Cleans up the MonoToColorProcessor instance - make sure to call this when you are done with the MonoToColor\n        processor. If using the *with* statement, dispose is called automatically upon exit.\n\n        \"\"\"\n        try:\n            if self._disposed:\n                return\n            error_code = self._sdk.tl_mono_to_color_destroy_mono_to_color_processor(\n                self._mono_to_color_processor_handle)\n            if error_code != 0:\n                raise MonoToColorError(_create_c_failure_message(\n                    self._sdk, \"tl_mono_to_color_destroy_mono_to_color_processor\", error_code))\n            self._disposed = True\n        except Exception as exception:\n            _logger.error(\"Could not dispose MonoToColorProcessor instance; \" + str(exception))\n            raise exception",
  "def transform_to_48(self, input_buffer, image_width_pixels, image_height_pixels):\n        # type: (np.array, int, int) -> np.array\n        \"\"\"\n        Convert monochrome image data into a 3-channel colored image with 16 bits per channel, resulting in 48 bits per\n        pixel. The pixel data will be ordered according to the current value of\n        :attr:`output_format<thorlabs_tsi_sdk.tl_mono_to_color_processor.MonoToColorProcessor.output_format>`.\n\n        :param np.array input_buffer: Single channel monochrome image data. The size of this array should be image_width * image_height. The dtype of the array should be ctypes.c_ushort or a type of equivalent size, the image buffer that comes directly from the camera is compatible (see: :meth:`TLCamera.get_pending_frame_or_null()<thorlabs_tsi_sdk.tl_camera.TLCamera.get_pending_frame_or_null>`).\n        :param int image_width_pixels: The width of the image in the image_buffer.\n        :param int image_height_pixels: The height of the image in the image_buffer.\n        :return np.array: 3-channel colored output image, *dtype* = ctypes.c_ushort.\n        \"\"\"\n        try:\n            output_buffer = np.zeros(shape=(image_width_pixels*image_height_pixels*3,), dtype=c_ushort)\n            output_buffer_pointer = output_buffer.ctypes.data_as(POINTER(c_ushort))\n            input_buffer_pointer = input_buffer.ctypes.data_as(POINTER(c_ushort))\n            c_image_width = c_int(image_width_pixels)\n            c_image_height = c_int(image_height_pixels)\n            error_code = self._sdk.tl_mono_to_color_transform_to_48(self._mono_to_color_processor_handle,\n                                                                    input_buffer_pointer,\n                                                                    c_image_width,\n                                                                    c_image_height,\n                                                                    output_buffer_pointer)\n            if error_code != 0:\n                raise MonoToColorError(_create_c_failure_message(self._sdk, \"tl_mono_to_color_transform_to_48\",\n                                                                 error_code))\n            return output_buffer\n        except Exception as exception:\n            _logger.error(\"Could not transform image to 48bpp; \" + str(exception))\n            raise exception",
  "def transform_to_32(self, input_buffer, image_width_pixels, image_height_pixels):\n        # type: (np.array, int, int) -> np.array\n        \"\"\"\n        Convert monochrome image data into a 4-channel colored image with 8 bits per channel, resulting in 32 bits per\n        pixel. The pixel data will be ordered according to the current value of\n        :attr:`output_format<thorlabs_tsi_sdk.tl_mono_to_color_processor.MonoToColorProcessor.output_format>`.\n\n        :param np.array input_buffer: Single channel monochrome image data. The size of this array should be image_width * image_height. The dtype of the array should be ctypes.c_ushort or a type of equivalent size, the image buffer that comes directly from the camera is compatible (see: :meth:`TLCamera.get_pending_frame_or_null()<thorlabs_tsi_sdk.tl_camera.TLCamera.get_pending_frame_or_null>`).\n        :param int image_width_pixels: The width of the image in the image_buffer.\n        :param int image_height_pixels: The height of the image in the image_buffer.\n        :return np.array: 4-channel colored output image, *dtype* = ctypes.c_ubyte.\n        \"\"\"\n        try:\n            output_buffer = np.zeros(shape=(image_width_pixels*image_height_pixels*4,), dtype=c_ubyte)\n            output_buffer_pointer = output_buffer.ctypes.data_as(POINTER(c_ubyte))\n            input_buffer_pointer = input_buffer.ctypes.data_as(POINTER(c_ushort))\n            c_image_width = c_int(image_width_pixels)\n            c_image_height = c_int(image_height_pixels)\n            error_code = self._sdk.tl_mono_to_color_transform_to_32(self._mono_to_color_processor_handle,\n                                                                    input_buffer_pointer,\n                                                                    c_image_width,\n                                                                    c_image_height,\n                                                                    output_buffer_pointer)\n            if error_code != 0:\n                raise MonoToColorError(_create_c_failure_message(self._sdk, \"tl_mono_to_color_transform_to_32\",\n                                                                 error_code))\n            return output_buffer\n        except Exception as exception:\n            _logger.error(\"Could not transform image to 32bpp; \" + str(exception))\n            raise exception",
  "def transform_to_24(self, input_buffer, image_width_pixels, image_height_pixels):\n        # type: (np.array, int, int) -> np.array\n        \"\"\"\n        Convert monochrome image data into a 3-channel colored image with 8 bits per channel, resulting in 24 bits per\n        pixel. The pixel data will be ordered according to the current value of\n        :attr:`output_format<thorlabs_tsi_sdk.tl_mono_to_color_processor.MonoToColorProcessor.output_format>`.\n\n        :param np.array input_buffer: Single channel monochrome image data. The size of this array should be image_width * image_height. The dtype of the array should be ctypes.c_ushort or a type of equivalent size, the image buffer that comes directly from the camera is compatible (see: :meth:`TLCamera.get_pending_frame_or_null()<thorlabs_tsi_sdk.tl_camera.TLCamera.get_pending_frame_or_null>`).\n        :param int image_width_pixels: The width of the image in the input_buffer.\n        :param int image_height_pixels: The height of the image in the input_buffer.\n        :return np.array: 3-channel colored output image, *dtype* = ctypes.c_ubyte.\n        \"\"\"\n        try:\n            output_buffer = np.zeros(shape=(image_width_pixels*image_height_pixels*3,), dtype=c_ubyte)\n            output_buffer_pointer = output_buffer.ctypes.data_as(POINTER(c_ubyte))\n            input_buffer_pointer = input_buffer.ctypes.data_as(POINTER(c_ushort))\n            c_image_width = c_int(image_width_pixels)\n            c_image_height = c_int(image_height_pixels)\n            error_code = self._sdk.tl_mono_to_color_transform_to_24(self._mono_to_color_processor_handle,\n                                                                    input_buffer_pointer,\n                                                                    c_image_width,\n                                                                    c_image_height,\n                                                                    output_buffer_pointer)\n            if error_code != 0:\n                raise MonoToColorError(_create_c_failure_message(self._sdk, \"tl_mono_to_color_transform_to_24\",\n                                                                 error_code))\n            return output_buffer\n        except Exception as exception:\n            _logger.error(\"Could not transform image to 24bpp; \" + str(exception))\n            raise exception",
  "def color_space(self):\n        \"\"\"\n        The color space of the mono to color processor. See :class:`COLOR_SPACE<thorlabs_tsi_sdk.tl_mono_to_color_enums.COLOR_SPACE>` for what color spaces\n        are available.\n\n        :type: :class:`COLOR_SPACE<thorlabs_tsi_sdk.tl_mono_to_color_enums.COLOR_SPACE>`\n        \"\"\"\n        try:\n            color_space = c_int()\n            error_code = self._sdk.tl_mono_to_color_get_color_space(self._mono_to_color_processor_handle, color_space)\n            if error_code != 0:\n                raise MonoToColorError(_create_c_failure_message(self._sdk, \"tl_mono_to_color_get_color_space\",\n                                                                 error_code))\n            return COLOR_SPACE(int(color_space.value))\n        except Exception as exception:\n            _logger.error(\"Could not get color space; \" + str(exception))\n            raise exception",
  "def color_space(self, color_space):\n        try:\n            c_value = c_int(color_space)\n            error_code = self._sdk.tl_mono_to_color_set_color_space(self._mono_to_color_processor_handle, c_value)\n            if error_code != 0:\n                raise MonoToColorError(_create_c_failure_message(self._sdk, \"tl_mono_to_color_set_color_space\",\n                                                                 error_code))\n        except Exception as exception:\n            _logger.error(\"Could not set color space; \" + str(exception))\n            raise exception",
  "def output_format(self):\n        \"\"\"\n        The format of the colored output image. This describes how the data is ordered in the returned buffer from the\n        transform functions. By default it is RGB_PIXEL. See :class:`FORMAT<thorlabs_tsi_sdk.tl_color_enums.FORMAT>`.\n\n        :type: :class:`FORMAT<thorlabs_tsi_sdk.tl_mono_to_color_enums.FORMAT>`\n        \"\"\"\n        try:\n            output_format = c_int()\n            error_code = self._sdk.tl_mono_to_color_get_output_format(self._mono_to_color_processor_handle,\n                                                                      output_format)\n            if error_code != 0:\n                raise MonoToColorError(_create_c_failure_message(self._sdk, \"tl_mono_to_color_get_output_format\",\n                                                                 error_code))\n            return FORMAT(int(output_format.value))\n        except Exception as exception:\n            _logger.error(\"Could not get output format; \" + str(exception))\n            raise exception",
  "def output_format(self, output_format):\n        try:\n            c_value = c_int(output_format)\n            error_code = self._sdk.tl_mono_to_color_set_output_format(self._mono_to_color_processor_handle, c_value)\n            if error_code != 0:\n                raise MonoToColorError(_create_c_failure_message(self._sdk, \"tl_mono_to_color_set_output_format\",\n                                                                 error_code))\n        except Exception as exception:\n            _logger.error(\"Could not set output format; \" + str(exception))\n            raise exception",
  "def red_gain(self):\n        \"\"\"\n        The gain factor that will be applied to the red pixel values in the image. The red intensities will be\n        multiplied by this gain value in the final colored image. The default red gain is\n        taken from the :attr:`default_white_balance_matrix<thorlabs_tsi_sdk.tl_mono_to_color_processor.MonoToColorProcessor.default_white_balance_matrix>` that\n        is passed in when constructing a\n        :meth:`MonoToColorProcessor<thorlabs_tsi_sdk.tl_mono_to_color_processor.MonoToColorProcessorSDK.create_mono_to_color_processor>`.\n\n        :type: float\n        \"\"\"\n        try:\n            red_gain = c_float()\n            error_code = self._sdk.tl_mono_to_color_get_red_gain(self._mono_to_color_processor_handle, red_gain)\n            if error_code != 0:\n                raise MonoToColorError(_create_c_failure_message(self._sdk, \"tl_mono_to_color_get_red_gain\",\n                                                                 error_code))\n            return float(red_gain.value)\n        except Exception as exception:\n            _logger.error(\"Could not get red gain value; \" + str(exception))\n            raise exception",
  "def red_gain(self, red_gain):\n        try:\n            c_value = c_float(red_gain)\n            error_code = self._sdk.tl_mono_to_color_set_red_gain(self._mono_to_color_processor_handle, c_value)\n            if error_code != 0:\n                raise MonoToColorError(_create_c_failure_message(self._sdk, \"tl_mono_to_color_set_red_gain\",\n                                                                 error_code))\n        except Exception as exception:\n            _logger.error(\"Could not set red gain value; \" + str(exception))\n            raise exception",
  "def blue_gain(self):\n        \"\"\"\n        The gain factor that will be applied to the red pixel values in the image. The blue intensities will be\n        multiplied by this gain value in the final colored image. The default blue gain is\n        taken from the :attr:`default_white_balance_matrix<thorlabs_tsi_sdk.tl_mono_to_color_processor.MonoToColorProcessor.default_white_balance_matrix>` that\n        is passed in when constructing a\n        :meth:`MonoToColorProcessor<thorlabs_tsi_sdk.tl_mono_to_color_processor.MonoToColorProcessorSDK.create_mono_to_color_processor>`.\n\n        :type: float\n        \"\"\"\n        try:\n            blue_gain = c_float()\n            error_code = self._sdk.tl_mono_to_color_get_blue_gain(self._mono_to_color_processor_handle, blue_gain)\n            if error_code != 0:\n                raise MonoToColorError(_create_c_failure_message(self._sdk, \"tl_mono_to_color_get_blue_gain\",\n                                                                 error_code))\n            return float(blue_gain.value)\n        except Exception as exception:\n            _logger.error(\"Could not get blue gain value; \" + str(exception))\n            raise exception",
  "def blue_gain(self, blue_gain):\n        try:\n            c_value = c_float(blue_gain)\n            error_code = self._sdk.tl_mono_to_color_set_blue_gain(self._mono_to_color_processor_handle, c_value)\n            if error_code != 0:\n                raise MonoToColorError(_create_c_failure_message(self._sdk, \"tl_mono_to_color_set_blue_gain\",\n                                                                 error_code))\n        except Exception as exception:\n            _logger.error(\"Could not set blue gain value; \" + str(exception))\n            raise exception",
  "def green_gain(self):\n        \"\"\"\n        The gain factor that will be applied to the red pixel values in the image. The green intensities will be\n        multiplied by this gain value in the final colored image. The default green gain is\n        taken from the :attr:`default_white_balance_matrix<thorlabs_tsi_sdk.tl_mono_to_color_processor.MonoToColorProcessor.default_white_balance_matrix>` that\n        is passed in when constructing a\n        :meth:`MonoToColorProcessor<thorlabs_tsi_sdk.tl_mono_to_color_processor.MonoToColorProcessorSDK.create_mono_to_color_processor>`.\n\n        :type: float\n        \"\"\"\n        try:\n            green_gain = c_float()\n            error_code = self._sdk.tl_mono_to_color_get_green_gain(self._mono_to_color_processor_handle, green_gain)\n            if error_code != 0:\n                raise MonoToColorError(_create_c_failure_message(self._sdk, \"tl_mono_to_color_get_green_gain\",\n                                                                 error_code))\n            return float(green_gain.value)\n        except Exception as exception:\n            _logger.error(\"Could not get green gain value; \" + str(exception))\n            raise exception",
  "def green_gain(self, green_gain):\n        try:\n            c_value = c_float(green_gain)\n            error_code = self._sdk.tl_mono_to_color_set_green_gain(self._mono_to_color_processor_handle, c_value)\n            if error_code != 0:\n                raise MonoToColorError(_create_c_failure_message(self._sdk, \"tl_mono_to_color_set_green_gain\",\n                                                                 error_code))\n        except Exception as exception:\n            _logger.error(\"Could not set green gain value; \" + str(exception))\n            raise exception",
  "def camera_sensor_type(self):\n        \"\"\"\n        The sensor type of the camera (monochrome, bayer, etc...). This value is passed in during construction and may\n        be read back using this property.\n\n        :type: :class:`SENSOR_TYPE<thorlabs_tsi_sdk.tl_camera_enums.SENSOR_TYPE>`\n        \"\"\"\n        try:\n            camera_sensor_type = c_int()\n            error_code = self._sdk.tl_mono_to_color_get_camera_sensor_type(self._mono_to_color_processor_handle,\n                                                                           camera_sensor_type)\n            if error_code != 0:\n                raise MonoToColorError(_create_c_failure_message(self._sdk, \"tl_mono_to_color_get_camera_sensor_type\",\n                                                                 error_code))\n            return SENSOR_TYPE(int(camera_sensor_type.value))\n        except Exception as exception:\n            _logger.error(\"Could not get camera sensor type; \" + str(exception))\n            raise exception",
  "def color_filter_array_phase(self):\n        \"\"\"\n        The color filter array phase used in this mono to color processor. This value is passed in during construction\n        and may be read back using this property.\n\n        :type: :class:`FILTER_ARRAY_PHASE<thorlabs_tsi_sdk.tl_color.FILTER_ARRAY_PHASE>`\n        \"\"\"\n        try:\n            color_filter_array_phase = c_int()\n            error_code = self._sdk.tl_mono_to_color_get_color_filter_array_phase(self._mono_to_color_processor_handle,\n                                                                                 color_filter_array_phase)\n            if error_code != 0:\n                raise MonoToColorError(_create_c_failure_message(\n                    self._sdk, \"tl_mono_to_color_get_color_filter_array_phase\", error_code))\n            return FILTER_ARRAY_PHASE(int(color_filter_array_phase.value))\n        except Exception as exception:\n            _logger.error(\"Could not get color filter array phase; \" + str(exception))\n            raise exception",
  "def color_correction_matrix(self):\n        \"\"\"\n        The default color correction matrix associated with the mono to color processor. This value is passed in during\n        construction and may be read back using this property.\n\n        :type: np.array\n        \"\"\"\n        try:\n            color_correction_matrix = _3x3Matrix_float()\n            error_code = self._sdk.tl_mono_to_color_get_color_correction_matrix(self._mono_to_color_processor_handle,\n                                                                                color_correction_matrix)\n            if error_code != 0:\n                raise MonoToColorError(_create_c_failure_message(\n                    self._sdk, \"tl_mono_to_color_get_color_correction_matrix\", error_code))\n            color_correction_matrix_as_np_array = np.array([float(color_correction_matrix[0]),\n                                                            float(color_correction_matrix[1]),\n                                                            float(color_correction_matrix[2]),\n                                                            float(color_correction_matrix[3]),\n                                                            float(color_correction_matrix[4]),\n                                                            float(color_correction_matrix[5]),\n                                                            float(color_correction_matrix[6]),\n                                                            float(color_correction_matrix[7]),\n                                                            float(color_correction_matrix[8])])\n            return color_correction_matrix_as_np_array\n        except Exception as exception:\n            _logger.error(\"Could not get color correction matrix; \" + str(exception))\n            raise exception",
  "def default_white_balance_matrix(self):\n        \"\"\"\n        The default white balance matrix associated with the mono to color processor. This value is passed in during\n        construction and may be read back using this property.\n\n        :type: np.array\n        \"\"\"\n        try:\n            default_white_balance_matrix = _3x3Matrix_float()\n            error_code = self._sdk.tl_mono_to_color_get_default_white_balance_matrix(\n                self._mono_to_color_processor_handle, default_white_balance_matrix)\n            if error_code != 0:\n                raise MonoToColorError(_create_c_failure_message(\n                    self._sdk, \"tl_mono_to_color_get_default_white_balance_matrix\", error_code))\n            default_white_balance_matrix_as_np_array = np.array([float(default_white_balance_matrix[0]),\n                                                                float(default_white_balance_matrix[1]),\n                                                                float(default_white_balance_matrix[2]),\n                                                                float(default_white_balance_matrix[3]),\n                                                                float(default_white_balance_matrix[4]),\n                                                                float(default_white_balance_matrix[5]),\n                                                                float(default_white_balance_matrix[6]),\n                                                                float(default_white_balance_matrix[7]),\n                                                                float(default_white_balance_matrix[8])])\n            return default_white_balance_matrix_as_np_array\n        except Exception as exception:\n            _logger.error(\"Could not get default white balance matrix; \" + str(exception))\n            raise exception",
  "def bit_depth(self):\n        \"\"\"\n        The bit depth associated with the mono to color processor. This value is passed in during construction and may\n        be read back using this property.\n\n        :type: int\n        \"\"\"\n        try:\n            bit_depth = c_int()\n            error_code = self._sdk.tl_mono_to_color_get_bit_depth(self._mono_to_color_processor_handle, bit_depth)\n            if error_code != 0:\n                raise MonoToColorError(_create_c_failure_message(self._sdk, \"tl_mono_to_color_get_bit_depth\",\n                                                                 error_code))\n            return int(bit_depth.value)\n        except Exception as exception:\n            _logger.error(\"Could not get bit depth; \" + str(exception))\n            raise exception",
  "def __init__(self, message):\n        _logger.debug(message)\n        super(MonoToColorError, self).__init__(message)",
  "class ColorProcessorSDK(object):\n\n    _is_sdk_open = False  # is SDK DLL currently being accessed by a ColorProcessorSDK instance\n\n    def __init__(self):\n        # type: (type(None)) -> None\n        if ColorProcessorSDK._is_sdk_open:\n            self._disposed = True\n            _logger.error(\"Error: ColorProcessorSDK is already in use. Please dispose of the current instance \"\n                          \"before trying to create another\")\n        try:\n            self._sdk = cdll.LoadLibrary(r\"thorlabs_tsi_color_processing.dll\")\n        except OSError as ose:\n            _logger.error(str(ose) + \"\\n\\nUnable to load library - are the thorlabs_tsi_color_processing DLLs \"\n                                     \"discoverable from the application directory? Try placing them in the same \"\n                                     \"directory as tl_color.py, or adding the directory with the DLLs to the \"\n                                     \"PATH. Make sure to use x86 DLLs when using 32-bit python and x64 DLLs when \"\n                                     \"using 64-bit.\")\n        try:\n            err = self._sdk.tl_color_processing_module_initialize()\n            if err != 0:\n                _logger.error(\"tl_color_processing_initialize failed with error code \" + str(err) + \"\\n\")\n            ColorProcessorSDK._is_sdk_open = True\n            self._disposed = False\n\n            \"\"\" set any C function argument types that need specification \"\"\"\n\n            self._sdk.tl_color_get_blue_input_LUT.argtpyes = [c_void_p]\n            self._sdk.tl_color_get_blue_input_LUT.restype = POINTER(c_int)\n            self._sdk.tl_color_get_red_input_LUT.argtpyes = [c_void_p]\n            self._sdk.tl_color_get_red_input_LUT.restype = POINTER(c_int)\n            self._sdk.tl_color_get_green_input_LUT.argtpyes = [c_void_p]\n            self._sdk.tl_color_get_green_input_LUT.restype = POINTER(c_int)\n            self._sdk.tl_color_enable_input_LUTs.argtypes = [c_int, c_int, c_int]\n            self._sdk.tl_color_get_blue_output_LUT.argtpyes = [c_void_p]\n            self._sdk.tl_color_get_blue_output_LUT.restype = POINTER(c_int)\n            self._sdk.tl_color_get_red_output_LUT.argtpyes = [c_void_p]\n            self._sdk.tl_color_get_red_output_LUT.restype = POINTER(c_int)\n            self._sdk.tl_color_get_green_output_LUT.argtpyes = [c_void_p]\n            self._sdk.tl_color_get_green_output_LUT.restype = POINTER(c_int)\n            self._sdk.tl_color_enable_output_LUTs.argtypes = [c_int, c_int, c_int]\n            self._sdk.tl_color_append_matrix.argtypes = [c_void_p, POINTER(c_float)]\n            self._sdk.tl_color_clear_matrix.argtypes = [c_void_p]\n            self._sdk.tl_color_transform_48_to_48.argtypes = [c_void_p, POINTER(c_ushort), c_int, c_ushort, c_ushort,\n                                                              c_ushort, c_ushort, c_ushort, c_ushort, c_int, c_int,\n                                                              c_int, POINTER(c_ushort), c_int, c_int]\n            self._sdk.tl_color_transform_48_to_32.argtypes = [c_void_p, POINTER(c_ushort), c_int, c_ushort, c_ushort,\n                                                              c_ushort, c_ushort, c_ushort, c_ushort, c_int, c_int,\n                                                              c_int, POINTER(c_ubyte), c_int, c_int]\n            self._sdk.tl_color_transform_48_to_24.argtypes = [c_void_p, POINTER(c_ushort), c_int, c_ushort, c_ushort,\n                                                              c_ushort, c_ushort, c_ushort, c_ushort, c_int, c_int,\n                                                              c_int, POINTER(c_ubyte), c_int, c_int]\n        except Exception as error:\n            _logger.error(\"Error: sdk initialization failed\\n\")\n            raise error\n\n    def __del__(self):\n        self.dispose()\n\n    \"\"\" with statement functionality \"\"\"\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, exc_type, exc_val, exc_tb):\n        if exc_type is not None:\n            _logger.debug(\"\".join(format_exception(exc_type, exc_val, exc_tb)))\n        self.dispose()\n        return True if exc_type is None else False\n\n    \"\"\" public methods \"\"\"\n\n    def dispose(self):\n        # type: (type(None)) -> None\n        try:\n            if self._disposed:\n                return\n            err = self._sdk.tl_color_processing_module_terminate()\n            if err != 0:\n                raise TLColorError(ColorProcessorSDK._create_c_failure_message(\n                    \"tl_color_processing_module_terminate\", err))\n            ColorProcessorSDK._is_sdk_open = False\n            self._disposed = True\n        except Exception as error:\n            _logger.error(\"Error: sdk destruction failed\\n\")\n            raise error\n\n    def create_color_processor(self, input_lut_size_bits, output_lut_size_bits):\n        # type: (int, int) -> ColorProcessor\n        return ColorProcessor(self._sdk, input_lut_size_bits, output_lut_size_bits, self._create_c_failure_message)\n\n    \"\"\" error-handling methods \"\"\"\n\n    _tl_color_error = {\n            'Error code is unknown': -1,\n            'No error': 0,\n            'Color module has not been initialized': 1,\n            'The specified module instance handle is NULL': 2,\n            'The specified input buffer pointer is NULL': 3,\n            'The specified output buffer pointer is NULL': 4,\n            'The same buffer was specified for input and output buffers': 5,\n            'The specified color filter array phase is invalid': 6,\n            'The specified color filter type is unknown': 7,\n            'The specified pixel bit depth is invalid': 8,\n            'The specified input color format is unknown': 9,\n            'The specified output color format is unknown': 10,\n            'The specified bit shift distance is invalid': 11,\n            'The specified pixel clamp value is invalid': 12\n        }\n\n    @staticmethod\n    def _create_c_failure_message(function_name, error_code):\n        error_message = ColorProcessorSDK._tl_color_error.get(error_code, -1)\n        failure_message = \"{function_name}() returned non-zero error code: {error_code}; \" \\\n                          \"error message: {error_message}\\n\"\\\n            .format(function_name=function_name, error_code=error_code, error_message=error_message)\n        return failure_message",
  "class ColorProcessor(object):\n\n    \"\"\" Methods \"\"\"\n\n    def __init__(self, sdk, input_lut_size_bits, output_lut_size_bits, error_string_generator):\n        try:\n            self._sdk = sdk\n            self._input_lut_size_bits = input_lut_size_bits\n            self._output_lut_size_bits = output_lut_size_bits\n            self._create_c_failure_message = error_string_generator\n\n            self._color_processor = self._sdk.tl_color_create_color_processor(self._input_lut_size_bits,\n                                                                              self._output_lut_size_bits)\n            if self._color_processor == 0:\n                raise TLColorError(\"tl_color_create_color_processor() returned a NULL color processor\\n\")\n\n            self._disposed = False\n\n        except Exception as error:\n            _logger.error(\"ColorProcessor initialization failed. \")\n            raise error\n\n    def __del__(self):\n        self.dispose()\n\n    \"\"\" with statement functionality \"\"\"\n    def __enter__(self):\n        return self\n\n    def __exit__(self, exc_type, exc_val, exc_tb):\n        if exc_type is not None:\n            _logger.debug(\"\".join(format_exception(exc_type, exc_val, exc_tb)))\n        self.dispose()\n        return True if exc_type is None else False\n\n    \"\"\" Public Methods \"\"\"\n\n    def dispose(self):\n        # type: (type(None)) -> None\n        try:\n            if self._disposed:\n                return\n            err = self._sdk.tl_color_destroy_color_processor(self._color_processor)\n            if err != 0:\n                raise TLColorError(self._create_c_failure_message(\"tl_color_destroy_color_processor\", err))\n            self._disposed = True\n        except Exception as error:\n            _logger.error(\"Could not cleanly dispose Color Processor instance. \")\n            raise error\n\n#  getters will return a copy of lut. setters will copy values from the given lut to the shared lut.\n\n    def get_blue_input_lut(self):\n        # type: (type(None)) -> np.array\n        try:\n            lut_pointer = self._sdk.tl_color_get_blue_input_LUT(self._color_processor)\n            if not lut_pointer:\n                raise TLColorError(\"tl_color_get_blue_input_lut() returned NULL\\n\")\n            lut_shared = np.ctypeslib.as_array(lut_pointer, shape=(2**self._input_lut_size_bits,))\n            lut_copy = np.empty_like(lut_shared)\n            lut_copy[:] = lut_shared\n            return lut_copy\n        except Exception as error:\n            _logger.error(\"Could not get blue input lut. \")\n            raise error\n\n    def get_green_input_lut(self):\n        # type: (type(None)) -> np.array\n        try:\n            lut_pointer = self._sdk.tl_color_get_green_input_LUT(self._color_processor)\n            if not lut_pointer:\n                raise TLColorError(\"tl_color_get_green_input_lut() returned NULL\\n\")\n            lut_shared = np.ctypeslib.as_array(lut_pointer, shape=(2**self._input_lut_size_bits,))\n            lut_copy = np.empty_like(lut_shared)\n            lut_copy[:] = lut_shared\n            return lut_copy\n        except Exception as error:\n            _logger.error(\"Error: could not get green input lut\\n\")\n            raise error\n\n    def get_red_input_lut(self):\n        # type: (type(None)) -> np.array\n        try:\n            lut_pointer = self._sdk.tl_color_get_red_input_LUT(self._color_processor)\n            if not lut_pointer:\n                raise TLColorError(\"tl_color_get_red_input_lut() returned NULL\\n\")\n            lut_shared = np.ctypeslib.as_array(lut_pointer, shape=(2**self._input_lut_size_bits,))\n            lut_copy = np.empty_like(lut_shared)\n            lut_copy[:] = lut_shared\n            return lut_copy\n        except Exception as error:\n            _logger.error(\"Could not get red input lut. \")\n            raise error\n\n    def set_blue_input_lut(self, blue_lut):\n        # type: (np.array) -> None\n        try:\n            lut_pointer = self._sdk.tl_color_get_blue_input_LUT(self._color_processor)\n            if not lut_pointer:\n                raise TLColorError(\"tl_color_get_blue_input_lut() returned NULL\\n\")\n            lut_shared = np.ctypeslib.as_array(lut_pointer, shape=(2 ** self._input_lut_size_bits,))\n            lut_shared[:] = blue_lut\n        except Exception as error:\n            _logger.error(\"Could not set blue input lut. \")\n            raise error\n\n    def set_green_input_lut(self, green_lut):\n        # type: (np.array) -> None\n        try:\n            lut_pointer = self._sdk.tl_color_get_green_input_LUT(self._color_processor)\n            if not lut_pointer:\n                raise TLColorError(\"tl_color_get_green_input_lut() returned NULL\\n\")\n            lut_shared = np.ctypeslib.as_array(lut_pointer, shape=(2 ** self._input_lut_size_bits,))\n            lut_shared[:] = green_lut\n        except Exception as error:\n            _logger.error(\"Could not set green input lut. \")\n            raise error\n\n    def set_red_input_lut(self, red_lut):\n        # type: (np.array) -> None\n        try:\n            lut_pointer = self._sdk.tl_color_get_red_input_LUT(self._color_processor)\n            if not lut_pointer:\n                raise TLColorError(\"tl_color_get_red_input_lut() returned NULL\\n\")\n            lut_shared = np.ctypeslib.as_array(lut_pointer, shape=(2 ** self._input_lut_size_bits,))\n            lut_shared[:] = red_lut\n        except Exception as error:\n            _logger.error(\"Could not set red input lut. \")\n            raise error\n\n    def enable_input_luts(self, blue_LUT_enable, green_LUT_enable, red_LUT_enable):\n        # type: (int, int, int) -> None\n        try:\n            err = self._sdk.tl_color_enable_input_LUTs(self._color_processor,\n                                                       c_int(blue_LUT_enable),\n                                                       c_int(green_LUT_enable),\n                                                       c_int(red_LUT_enable))\n            if err:\n                raise TLColorError(self._create_c_failure_message(\"tl_color_enable_input_LUTs\", err))\n        except Exception as error:\n            _logger.error(\"Could not enable input luts. \")\n            raise error\n\n    def append_matrix(self, matrix):\n        # type: (np.array) -> None\n        try:\n            arr = _3x3Matrix(*matrix)\n            err = self._sdk.tl_color_append_matrix(self._color_processor, arr)\n            if err:\n                raise TLColorError(self._create_c_failure_message(\"tl_color_append_matrix\", err))\n        except Exception as error:\n            _logger.error(\"Could not append matrix. \")\n            raise error\n\n    def clear_matrix(self):\n        # type: (type(None)) -> None\n        try:\n            err = self._sdk.tl_color_clear_matrix(self._color_processor)\n            if err:\n                raise TLColorError(self._create_c_failure_message(\"tl_color_clear_matrix\", err))\n        except Exception as error:\n            _logger.error(\"Could not clear matrix. \")\n            raise error\n\n    def get_blue_output_lut(self):\n        # type: (type(None)) -> np.array\n        try:\n            lut_pointer = self._sdk.tl_color_get_blue_output_LUT(self._color_processor)\n            if not lut_pointer:\n                raise TLColorError(\"tl_color_get_blue_output_lut() returned NULL\\n\")\n            lut_shared = np.ctypeslib.as_array(lut_pointer, shape=(2**self._output_lut_size_bits,))\n            lut_copy = np.empty_like(lut_shared)\n            lut_copy[:] = lut_shared\n            return lut_copy\n        except Exception as error:\n            _logger.error(\"Could not get blue output lut. \")\n            raise error\n\n    def get_green_output_lut(self):\n        # type: (type(None)) -> np.array\n        try:\n            lut_pointer = self._sdk.tl_color_get_green_output_LUT(self._color_processor)\n            if not lut_pointer:\n                raise TLColorError(\"tl_color_get_green_output_lut() returned NULL\\n\")\n            lut_shared = np.ctypeslib.as_array(lut_pointer, shape=(2**self._output_lut_size_bits,))\n            lut_copy = np.empty_like(lut_shared)\n            lut_copy[:] = lut_shared\n            return lut_copy\n        except Exception as error:\n            _logger.error(\"Could not get green output lut. \")\n            raise error\n\n    def get_red_output_lut(self):\n        # type: (type(None)) -> np.array\n        try:\n            lut_pointer = self._sdk.tl_color_get_red_output_LUT(self._color_processor)\n            if not lut_pointer:\n                raise TLColorError(\"tl_color_get_red_output_lut() returned NULL\\n\")\n            lut_shared = np.ctypeslib.as_array(lut_pointer, shape=(2**self._output_lut_size_bits,))\n            lut_copy = np.empty_like(lut_shared)\n            lut_copy[:] = lut_shared\n            return lut_copy\n        except Exception as error:\n            _logger.error(\"Could not get red output lut. \")\n            raise error\n\n    def set_blue_output_lut(self, blue_lut):\n        # type: (np.array) -> None\n        try:\n            lut_pointer = self._sdk.tl_color_get_blue_output_LUT(self._color_processor)\n            if not lut_pointer:\n                raise TLColorError(\"tl_color_get_blue_output_lut() returned NULL\\n\")\n            lut_shared = np.ctypeslib.as_array(lut_pointer, shape=(2 ** self._output_lut_size_bits,))\n            lut_shared[:] = blue_lut\n        except Exception as error:\n            _logger.error(\"Could not set blue output lut. \")\n            raise error\n\n    def set_green_output_lut(self, green_lut):\n        # type: (np.array) -> None\n        try:\n            lut_pointer = self._sdk.tl_color_get_green_output_LUT(self._color_processor)\n            if not lut_pointer:\n                raise TLColorError(\"tl_color_get_green_output_lut() returned NULL\\n\")\n            lut_shared = np.ctypeslib.as_array(lut_pointer, shape=(2 ** self._output_lut_size_bits,))\n            lut_shared[:] = green_lut\n        except Exception as error:\n            _logger.error(\"Could not set green output lut. \")\n            raise error\n\n    def set_red_output_lut(self, red_lut):\n        # type: (np.array) -> None\n        try:\n            lut_pointer = self._sdk.tl_color_get_red_output_LUT(self._color_processor)\n            if not lut_pointer:\n                raise TLColorError(\"tl_color_get_red_output_lut() returned NULL\\n\")\n            lut_shared = np.ctypeslib.as_array(lut_pointer, shape=(2 ** self._output_lut_size_bits,))\n            lut_shared[:] = red_lut\n        except Exception as error:\n            _logger.error(\"Could not set red output lut. \")\n            raise error\n\n    def enable_output_luts(self, blue_LUT_enable, green_LUT_enable, red_LUT_enable):\n        # type: (int, int, int) -> None\n        try:\n            err = self._sdk.tl_color_enable_output_LUTs(self._color_processor,\n                                                        c_int(blue_LUT_enable),\n                                                        c_int(green_LUT_enable),\n                                                        c_int(red_LUT_enable))\n            if err:\n                raise TLColorError(self._create_c_failure_message(\"tl_color_enable_output_luts\", err))\n        except Exception as error:\n            _logger.error(\"Could not enable output luts. \")\n            raise error\n\n    def transform_48_to_48(self, input_buffer, input_buffer_format, blue_output_min_value, blue_output_max_value,\n                           green_output_min_value, green_output_max_value, red_output_min_value, red_output_max_value,\n                           output_blue_shift_distance, output_green_shift_distance, output_red_shift_distance,\n                           output_buffer_format, number_of_bgr_tuples\n                           ):\n        # type: (np.array, FORMAT, int, int, int, int, int, int, int, int, int, FORMAT, int) -> np.array\n        try:\n            input_buffer_format_value = c_int(input_buffer_format)\n            output_buffer_format_value = c_int(output_buffer_format)\n\n            input_buffer_as_ushort = input_buffer.view(np.ushort)\n            input_pointer = input_buffer_as_ushort.ctypes.data_as(POINTER(c_ushort))\n\n            # number of elements stays the same (RGB -> RGB) size per element stays the same (16-bit -> 16-bit)\n            output_buffer = np.empty(shape=(input_buffer.size,), dtype=np.ushort)\n            output_pointer = output_buffer.ctypes.data_as(POINTER(c_ushort))\n\n            err = self._sdk.tl_color_transform_48_to_48(self._color_processor,\n                                                        input_pointer, input_buffer_format_value,\n                                                        blue_output_min_value, blue_output_max_value,\n                                                        green_output_min_value, green_output_max_value,\n                                                        red_output_min_value, red_output_max_value,\n                                                        output_blue_shift_distance, output_green_shift_distance,\n                                                        output_red_shift_distance, output_pointer,\n                                                        output_buffer_format_value, number_of_bgr_tuples)\n            if err:\n                raise TLColorError(self._create_c_failure_message(\"tl_color_transform_48_to_48\", err))\n            return output_buffer\n        except Exception as error:\n            _logger.error(\"Could not transform image (48 to 48). \")\n            raise error\n\n    def transform_48_to_32(self, input_buffer, input_buffer_format, blue_output_min_value, blue_output_max_value,\n                           green_output_min_value, green_output_max_value, red_output_min_value, red_output_max_value,\n                           output_blue_shift_distance, output_green_shift_distance, output_red_shift_distance,\n                           output_buffer_format, number_of_bgr_tuples\n                           ):\n        # type: (np.array, FORMAT, int, int, int, int, int, int, int, int, int, FORMAT, int) -> np.array\n        try:\n            input_buffer_format_value = c_int(input_buffer_format)\n            output_buffer_format_value = c_int(output_buffer_format)\n\n            input_buffer_as_ushort = input_buffer.view(np.ushort)\n            input_buffer_pointer = input_buffer_as_ushort.ctypes.data_as(POINTER(c_ushort))\n\n            # number of elements goes up (RGB -> RGBA) but size per element goes down (16-bit -> 8-bit)\n            output_buffer = np.empty(shape=(int(input_buffer.size + (input_buffer.size / 4)),), dtype=np.ubyte)\n            output_buffer_pointer = output_buffer.ctypes.data_as(POINTER(c_ubyte))\n\n            err = self._sdk.tl_color_transform_48_to_32(self._color_processor,\n                                                        input_buffer_pointer, input_buffer_format_value,\n                                                        blue_output_min_value, blue_output_max_value,\n                                                        green_output_min_value, green_output_max_value,\n                                                        red_output_min_value, red_output_max_value,\n                                                        output_red_shift_distance, output_green_shift_distance,\n                                                        output_blue_shift_distance, output_buffer_pointer,\n                                                        output_buffer_format_value, number_of_bgr_tuples)\n            if err:\n                raise TLColorError(self._create_c_failure_message(\"tl_color_transform_48_to_32\", err))\n            return output_buffer\n        except Exception as error:\n            _logger.error(\"Could not transform image (48 to 32). \")\n            raise error\n\n    def transform_48_to_24(self, input_buffer, input_buffer_format, blue_output_min_value, blue_output_max_value,\n                           green_output_min_value, green_output_max_value, red_output_min_value, red_output_max_value,\n                           output_blue_shift_distance, output_green_shift_distance, output_red_shift_distance,\n                           output_buffer_format, number_of_bgr_tuples\n                           ):\n        # type: (np.array, FORMAT, int, int, int, int, int, int, int, int, int, FORMAT, int) -> np.array\n        try:\n            input_buffer_format_value = c_int(input_buffer_format)\n            output_buffer_format_value = c_int(output_buffer_format)\n\n            input_buffer_as_ushort = input_buffer.view(np.ushort)\n            input_buffer_pointer = input_buffer_as_ushort.ctypes.data_as(POINTER(c_ushort))\n\n            # number of elements stays the same (RGB -> RGB), size per element goes down (16-bit -> 8-bit)\n            output_buffer = np.empty(shape=(input_buffer.size,), dtype=np.ubyte)\n            output_buffer_pointer = output_buffer.ctypes.data_as(POINTER(c_ubyte))\n\n            err = self._sdk.tl_color_transform_48_to_24(self._color_processor,\n                                                        input_buffer_pointer, input_buffer_format_value,\n                                                        blue_output_min_value, blue_output_max_value,\n                                                        green_output_min_value, green_output_max_value,\n                                                        red_output_min_value, red_output_max_value,\n                                                        output_red_shift_distance, output_green_shift_distance,\n                                                        output_blue_shift_distance, output_buffer_pointer,\n                                                        output_buffer_format_value, number_of_bgr_tuples)\n            if err:\n                raise TLColorError(self._create_c_failure_message(\"tl_color_transform_48_to_24\", err))\n            return output_buffer\n        except Exception as error:\n            _logger.error(\"Could not transform image (48 to 24). \")\n            raise error",
  "class Demosaicker(object):\n\n    _is_sdk_open = False  # is SDK DLL currently being accessed by a Demosaicker instance\n\n    def __init__(self):\n        # type: (type(None)) -> None\n        self._disposed = True\n        if Demosaicker._is_sdk_open:\n            _logger.error(\"Error: Demosaicker is already in use. Please dispose of the current instance before \"\n                          \"trying to create another\")\n        try:\n            self._sdk = cdll.LoadLibrary(r\"thorlabs_tsi_demosaic.dll\")\n        except OSError as ose:\n            _logger.error(str(ose) + \"\\n\\nUnable to load library - are the thorlabs_tsi_demosaic DLLs \"\n                                     \"discoverable from the application directory? Try placing them in the same \"\n                                     \"directory as tl_color.py, or adding the directory with the DLLs to the \"\n                                     \"PATH. Make sure to use x86 DLLs when using 32-bit python and x64 DLLs when \"\n                                     \"using 64-bit.\")\n        try:\n            err = self._sdk.tl_demosaic_module_initialize()\n            if err != 0:\n                raise TLColorError(\"tl_demosaic_module_initialize failed with error code \" + str(err) + \"\\n\")\n            Demosaicker._is_sdk_open = True\n            self._disposed = False\n\n            \"\"\" set C function argument types \"\"\"\n\n            self._sdk.tl_demosaic_transform_16_to_48.argtypes = [c_int, c_int, c_int, c_int, c_int, c_int,\n                                                                 c_int, c_int, POINTER(c_ushort), POINTER(c_ushort)]\n\n        except Exception as error:\n            _logger.error(\"Error: sdk initialization failed\\n\")\n            raise error\n\n    def __del__(self):\n        self.dispose()\n\n    \"\"\" with statement functionality \"\"\"\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, exc_type, exc_val, exc_tb):\n        self.dispose()\n        return isinstance(exc_val, TLColorError)\n\n    \"\"\" public methods \"\"\"\n\n    def dispose(self):\n        # type: (type(None)) -> None\n        try:\n            if self._disposed:\n                return\n            err = self._sdk.tl_demosaic_module_terminate()\n            if err != 0:\n                raise TLColorError(\"tl_demosaic_module_terminate failed with error code \" + str(err) + \"\\n\")\n            Demosaicker._is_sdk_open = False\n            self._disposed = True\n        except Exception as error:\n            _logger.error(\"Error: sdk destruction failed\\n\")\n            raise error\n\n    def transform_16_to_48(self, width, height, x_origin, y_origin, color_phase, output_color_format,\n                           color_filter_type, bit_depth, input_buffer):\n        # type: (int, int, int, int, FILTER_ARRAY_PHASE, FORMAT, FILTER_TYPE, int, np.array) -> np.array\n\n        try:\n            input_buffer_as_ushort = input_buffer.view(np.ushort)\n            input_buffer_pointer = input_buffer_as_ushort.ctypes.data_as(POINTER(c_ushort))\n\n            color_phase_value = c_int(color_phase)\n            output_color_format_value = c_int(output_color_format)\n            color_filter_type_value = c_int(color_filter_type)\n\n            # number of elements goes up (Mono -> RGB), size per element stays the same (16-bit -> 16-bit)\n            output_buffer = np.empty(shape=(input_buffer.size * 3,), dtype=np.ushort)\n            output_buffer_pointer = output_buffer.ctypes.data_as(POINTER(c_ushort))\n\n            err = self._sdk.tl_demosaic_transform_16_to_48(width, height, x_origin, y_origin, color_phase_value,\n                                                           output_color_format_value, color_filter_type_value,\n                                                           bit_depth, input_buffer_pointer, output_buffer_pointer)\n            if err:\n                raise TLColorError(\"tl_color_transform_48_to_24 returned error code \" + str(err) + \"\\n\")\n            return output_buffer\n        except Exception as error:\n            _logger.error(\"Error: could not demosaic the image (16 to 48)\\n\")\n            raise error",
  "class TLColorError(Exception):\n    def __init__(self, message):\n        _logger.debug(message)\n        super(TLColorError, self).__init__(message)",
  "def __init__(self):\n        # type: (type(None)) -> None\n        if ColorProcessorSDK._is_sdk_open:\n            self._disposed = True\n            _logger.error(\"Error: ColorProcessorSDK is already in use. Please dispose of the current instance \"\n                          \"before trying to create another\")\n        try:\n            self._sdk = cdll.LoadLibrary(r\"thorlabs_tsi_color_processing.dll\")\n        except OSError as ose:\n            _logger.error(str(ose) + \"\\n\\nUnable to load library - are the thorlabs_tsi_color_processing DLLs \"\n                                     \"discoverable from the application directory? Try placing them in the same \"\n                                     \"directory as tl_color.py, or adding the directory with the DLLs to the \"\n                                     \"PATH. Make sure to use x86 DLLs when using 32-bit python and x64 DLLs when \"\n                                     \"using 64-bit.\")\n        try:\n            err = self._sdk.tl_color_processing_module_initialize()\n            if err != 0:\n                _logger.error(\"tl_color_processing_initialize failed with error code \" + str(err) + \"\\n\")\n            ColorProcessorSDK._is_sdk_open = True\n            self._disposed = False\n\n            \"\"\" set any C function argument types that need specification \"\"\"\n\n            self._sdk.tl_color_get_blue_input_LUT.argtpyes = [c_void_p]\n            self._sdk.tl_color_get_blue_input_LUT.restype = POINTER(c_int)\n            self._sdk.tl_color_get_red_input_LUT.argtpyes = [c_void_p]\n            self._sdk.tl_color_get_red_input_LUT.restype = POINTER(c_int)\n            self._sdk.tl_color_get_green_input_LUT.argtpyes = [c_void_p]\n            self._sdk.tl_color_get_green_input_LUT.restype = POINTER(c_int)\n            self._sdk.tl_color_enable_input_LUTs.argtypes = [c_int, c_int, c_int]\n            self._sdk.tl_color_get_blue_output_LUT.argtpyes = [c_void_p]\n            self._sdk.tl_color_get_blue_output_LUT.restype = POINTER(c_int)\n            self._sdk.tl_color_get_red_output_LUT.argtpyes = [c_void_p]\n            self._sdk.tl_color_get_red_output_LUT.restype = POINTER(c_int)\n            self._sdk.tl_color_get_green_output_LUT.argtpyes = [c_void_p]\n            self._sdk.tl_color_get_green_output_LUT.restype = POINTER(c_int)\n            self._sdk.tl_color_enable_output_LUTs.argtypes = [c_int, c_int, c_int]\n            self._sdk.tl_color_append_matrix.argtypes = [c_void_p, POINTER(c_float)]\n            self._sdk.tl_color_clear_matrix.argtypes = [c_void_p]\n            self._sdk.tl_color_transform_48_to_48.argtypes = [c_void_p, POINTER(c_ushort), c_int, c_ushort, c_ushort,\n                                                              c_ushort, c_ushort, c_ushort, c_ushort, c_int, c_int,\n                                                              c_int, POINTER(c_ushort), c_int, c_int]\n            self._sdk.tl_color_transform_48_to_32.argtypes = [c_void_p, POINTER(c_ushort), c_int, c_ushort, c_ushort,\n                                                              c_ushort, c_ushort, c_ushort, c_ushort, c_int, c_int,\n                                                              c_int, POINTER(c_ubyte), c_int, c_int]\n            self._sdk.tl_color_transform_48_to_24.argtypes = [c_void_p, POINTER(c_ushort), c_int, c_ushort, c_ushort,\n                                                              c_ushort, c_ushort, c_ushort, c_ushort, c_int, c_int,\n                                                              c_int, POINTER(c_ubyte), c_int, c_int]\n        except Exception as error:\n            _logger.error(\"Error: sdk initialization failed\\n\")\n            raise error",
  "def __del__(self):\n        self.dispose()",
  "def __enter__(self):\n        return self",
  "def __exit__(self, exc_type, exc_val, exc_tb):\n        if exc_type is not None:\n            _logger.debug(\"\".join(format_exception(exc_type, exc_val, exc_tb)))\n        self.dispose()\n        return True if exc_type is None else False",
  "def dispose(self):\n        # type: (type(None)) -> None\n        try:\n            if self._disposed:\n                return\n            err = self._sdk.tl_color_processing_module_terminate()\n            if err != 0:\n                raise TLColorError(ColorProcessorSDK._create_c_failure_message(\n                    \"tl_color_processing_module_terminate\", err))\n            ColorProcessorSDK._is_sdk_open = False\n            self._disposed = True\n        except Exception as error:\n            _logger.error(\"Error: sdk destruction failed\\n\")\n            raise error",
  "def create_color_processor(self, input_lut_size_bits, output_lut_size_bits):\n        # type: (int, int) -> ColorProcessor\n        return ColorProcessor(self._sdk, input_lut_size_bits, output_lut_size_bits, self._create_c_failure_message)",
  "def _create_c_failure_message(function_name, error_code):\n        error_message = ColorProcessorSDK._tl_color_error.get(error_code, -1)\n        failure_message = \"{function_name}() returned non-zero error code: {error_code}; \" \\\n                          \"error message: {error_message}\\n\"\\\n            .format(function_name=function_name, error_code=error_code, error_message=error_message)\n        return failure_message",
  "def __init__(self, sdk, input_lut_size_bits, output_lut_size_bits, error_string_generator):\n        try:\n            self._sdk = sdk\n            self._input_lut_size_bits = input_lut_size_bits\n            self._output_lut_size_bits = output_lut_size_bits\n            self._create_c_failure_message = error_string_generator\n\n            self._color_processor = self._sdk.tl_color_create_color_processor(self._input_lut_size_bits,\n                                                                              self._output_lut_size_bits)\n            if self._color_processor == 0:\n                raise TLColorError(\"tl_color_create_color_processor() returned a NULL color processor\\n\")\n\n            self._disposed = False\n\n        except Exception as error:\n            _logger.error(\"ColorProcessor initialization failed. \")\n            raise error",
  "def __del__(self):\n        self.dispose()",
  "def __enter__(self):\n        return self",
  "def __exit__(self, exc_type, exc_val, exc_tb):\n        if exc_type is not None:\n            _logger.debug(\"\".join(format_exception(exc_type, exc_val, exc_tb)))\n        self.dispose()\n        return True if exc_type is None else False",
  "def dispose(self):\n        # type: (type(None)) -> None\n        try:\n            if self._disposed:\n                return\n            err = self._sdk.tl_color_destroy_color_processor(self._color_processor)\n            if err != 0:\n                raise TLColorError(self._create_c_failure_message(\"tl_color_destroy_color_processor\", err))\n            self._disposed = True\n        except Exception as error:\n            _logger.error(\"Could not cleanly dispose Color Processor instance. \")\n            raise error",
  "def get_blue_input_lut(self):\n        # type: (type(None)) -> np.array\n        try:\n            lut_pointer = self._sdk.tl_color_get_blue_input_LUT(self._color_processor)\n            if not lut_pointer:\n                raise TLColorError(\"tl_color_get_blue_input_lut() returned NULL\\n\")\n            lut_shared = np.ctypeslib.as_array(lut_pointer, shape=(2**self._input_lut_size_bits,))\n            lut_copy = np.empty_like(lut_shared)\n            lut_copy[:] = lut_shared\n            return lut_copy\n        except Exception as error:\n            _logger.error(\"Could not get blue input lut. \")\n            raise error",
  "def get_green_input_lut(self):\n        # type: (type(None)) -> np.array\n        try:\n            lut_pointer = self._sdk.tl_color_get_green_input_LUT(self._color_processor)\n            if not lut_pointer:\n                raise TLColorError(\"tl_color_get_green_input_lut() returned NULL\\n\")\n            lut_shared = np.ctypeslib.as_array(lut_pointer, shape=(2**self._input_lut_size_bits,))\n            lut_copy = np.empty_like(lut_shared)\n            lut_copy[:] = lut_shared\n            return lut_copy\n        except Exception as error:\n            _logger.error(\"Error: could not get green input lut\\n\")\n            raise error",
  "def get_red_input_lut(self):\n        # type: (type(None)) -> np.array\n        try:\n            lut_pointer = self._sdk.tl_color_get_red_input_LUT(self._color_processor)\n            if not lut_pointer:\n                raise TLColorError(\"tl_color_get_red_input_lut() returned NULL\\n\")\n            lut_shared = np.ctypeslib.as_array(lut_pointer, shape=(2**self._input_lut_size_bits,))\n            lut_copy = np.empty_like(lut_shared)\n            lut_copy[:] = lut_shared\n            return lut_copy\n        except Exception as error:\n            _logger.error(\"Could not get red input lut. \")\n            raise error",
  "def set_blue_input_lut(self, blue_lut):\n        # type: (np.array) -> None\n        try:\n            lut_pointer = self._sdk.tl_color_get_blue_input_LUT(self._color_processor)\n            if not lut_pointer:\n                raise TLColorError(\"tl_color_get_blue_input_lut() returned NULL\\n\")\n            lut_shared = np.ctypeslib.as_array(lut_pointer, shape=(2 ** self._input_lut_size_bits,))\n            lut_shared[:] = blue_lut\n        except Exception as error:\n            _logger.error(\"Could not set blue input lut. \")\n            raise error",
  "def set_green_input_lut(self, green_lut):\n        # type: (np.array) -> None\n        try:\n            lut_pointer = self._sdk.tl_color_get_green_input_LUT(self._color_processor)\n            if not lut_pointer:\n                raise TLColorError(\"tl_color_get_green_input_lut() returned NULL\\n\")\n            lut_shared = np.ctypeslib.as_array(lut_pointer, shape=(2 ** self._input_lut_size_bits,))\n            lut_shared[:] = green_lut\n        except Exception as error:\n            _logger.error(\"Could not set green input lut. \")\n            raise error",
  "def set_red_input_lut(self, red_lut):\n        # type: (np.array) -> None\n        try:\n            lut_pointer = self._sdk.tl_color_get_red_input_LUT(self._color_processor)\n            if not lut_pointer:\n                raise TLColorError(\"tl_color_get_red_input_lut() returned NULL\\n\")\n            lut_shared = np.ctypeslib.as_array(lut_pointer, shape=(2 ** self._input_lut_size_bits,))\n            lut_shared[:] = red_lut\n        except Exception as error:\n            _logger.error(\"Could not set red input lut. \")\n            raise error",
  "def enable_input_luts(self, blue_LUT_enable, green_LUT_enable, red_LUT_enable):\n        # type: (int, int, int) -> None\n        try:\n            err = self._sdk.tl_color_enable_input_LUTs(self._color_processor,\n                                                       c_int(blue_LUT_enable),\n                                                       c_int(green_LUT_enable),\n                                                       c_int(red_LUT_enable))\n            if err:\n                raise TLColorError(self._create_c_failure_message(\"tl_color_enable_input_LUTs\", err))\n        except Exception as error:\n            _logger.error(\"Could not enable input luts. \")\n            raise error",
  "def append_matrix(self, matrix):\n        # type: (np.array) -> None\n        try:\n            arr = _3x3Matrix(*matrix)\n            err = self._sdk.tl_color_append_matrix(self._color_processor, arr)\n            if err:\n                raise TLColorError(self._create_c_failure_message(\"tl_color_append_matrix\", err))\n        except Exception as error:\n            _logger.error(\"Could not append matrix. \")\n            raise error",
  "def clear_matrix(self):\n        # type: (type(None)) -> None\n        try:\n            err = self._sdk.tl_color_clear_matrix(self._color_processor)\n            if err:\n                raise TLColorError(self._create_c_failure_message(\"tl_color_clear_matrix\", err))\n        except Exception as error:\n            _logger.error(\"Could not clear matrix. \")\n            raise error",
  "def get_blue_output_lut(self):\n        # type: (type(None)) -> np.array\n        try:\n            lut_pointer = self._sdk.tl_color_get_blue_output_LUT(self._color_processor)\n            if not lut_pointer:\n                raise TLColorError(\"tl_color_get_blue_output_lut() returned NULL\\n\")\n            lut_shared = np.ctypeslib.as_array(lut_pointer, shape=(2**self._output_lut_size_bits,))\n            lut_copy = np.empty_like(lut_shared)\n            lut_copy[:] = lut_shared\n            return lut_copy\n        except Exception as error:\n            _logger.error(\"Could not get blue output lut. \")\n            raise error",
  "def get_green_output_lut(self):\n        # type: (type(None)) -> np.array\n        try:\n            lut_pointer = self._sdk.tl_color_get_green_output_LUT(self._color_processor)\n            if not lut_pointer:\n                raise TLColorError(\"tl_color_get_green_output_lut() returned NULL\\n\")\n            lut_shared = np.ctypeslib.as_array(lut_pointer, shape=(2**self._output_lut_size_bits,))\n            lut_copy = np.empty_like(lut_shared)\n            lut_copy[:] = lut_shared\n            return lut_copy\n        except Exception as error:\n            _logger.error(\"Could not get green output lut. \")\n            raise error",
  "def get_red_output_lut(self):\n        # type: (type(None)) -> np.array\n        try:\n            lut_pointer = self._sdk.tl_color_get_red_output_LUT(self._color_processor)\n            if not lut_pointer:\n                raise TLColorError(\"tl_color_get_red_output_lut() returned NULL\\n\")\n            lut_shared = np.ctypeslib.as_array(lut_pointer, shape=(2**self._output_lut_size_bits,))\n            lut_copy = np.empty_like(lut_shared)\n            lut_copy[:] = lut_shared\n            return lut_copy\n        except Exception as error:\n            _logger.error(\"Could not get red output lut. \")\n            raise error",
  "def set_blue_output_lut(self, blue_lut):\n        # type: (np.array) -> None\n        try:\n            lut_pointer = self._sdk.tl_color_get_blue_output_LUT(self._color_processor)\n            if not lut_pointer:\n                raise TLColorError(\"tl_color_get_blue_output_lut() returned NULL\\n\")\n            lut_shared = np.ctypeslib.as_array(lut_pointer, shape=(2 ** self._output_lut_size_bits,))\n            lut_shared[:] = blue_lut\n        except Exception as error:\n            _logger.error(\"Could not set blue output lut. \")\n            raise error",
  "def set_green_output_lut(self, green_lut):\n        # type: (np.array) -> None\n        try:\n            lut_pointer = self._sdk.tl_color_get_green_output_LUT(self._color_processor)\n            if not lut_pointer:\n                raise TLColorError(\"tl_color_get_green_output_lut() returned NULL\\n\")\n            lut_shared = np.ctypeslib.as_array(lut_pointer, shape=(2 ** self._output_lut_size_bits,))\n            lut_shared[:] = green_lut\n        except Exception as error:\n            _logger.error(\"Could not set green output lut. \")\n            raise error",
  "def set_red_output_lut(self, red_lut):\n        # type: (np.array) -> None\n        try:\n            lut_pointer = self._sdk.tl_color_get_red_output_LUT(self._color_processor)\n            if not lut_pointer:\n                raise TLColorError(\"tl_color_get_red_output_lut() returned NULL\\n\")\n            lut_shared = np.ctypeslib.as_array(lut_pointer, shape=(2 ** self._output_lut_size_bits,))\n            lut_shared[:] = red_lut\n        except Exception as error:\n            _logger.error(\"Could not set red output lut. \")\n            raise error",
  "def enable_output_luts(self, blue_LUT_enable, green_LUT_enable, red_LUT_enable):\n        # type: (int, int, int) -> None\n        try:\n            err = self._sdk.tl_color_enable_output_LUTs(self._color_processor,\n                                                        c_int(blue_LUT_enable),\n                                                        c_int(green_LUT_enable),\n                                                        c_int(red_LUT_enable))\n            if err:\n                raise TLColorError(self._create_c_failure_message(\"tl_color_enable_output_luts\", err))\n        except Exception as error:\n            _logger.error(\"Could not enable output luts. \")\n            raise error",
  "def transform_48_to_48(self, input_buffer, input_buffer_format, blue_output_min_value, blue_output_max_value,\n                           green_output_min_value, green_output_max_value, red_output_min_value, red_output_max_value,\n                           output_blue_shift_distance, output_green_shift_distance, output_red_shift_distance,\n                           output_buffer_format, number_of_bgr_tuples\n                           ):\n        # type: (np.array, FORMAT, int, int, int, int, int, int, int, int, int, FORMAT, int) -> np.array\n        try:\n            input_buffer_format_value = c_int(input_buffer_format)\n            output_buffer_format_value = c_int(output_buffer_format)\n\n            input_buffer_as_ushort = input_buffer.view(np.ushort)\n            input_pointer = input_buffer_as_ushort.ctypes.data_as(POINTER(c_ushort))\n\n            # number of elements stays the same (RGB -> RGB) size per element stays the same (16-bit -> 16-bit)\n            output_buffer = np.empty(shape=(input_buffer.size,), dtype=np.ushort)\n            output_pointer = output_buffer.ctypes.data_as(POINTER(c_ushort))\n\n            err = self._sdk.tl_color_transform_48_to_48(self._color_processor,\n                                                        input_pointer, input_buffer_format_value,\n                                                        blue_output_min_value, blue_output_max_value,\n                                                        green_output_min_value, green_output_max_value,\n                                                        red_output_min_value, red_output_max_value,\n                                                        output_blue_shift_distance, output_green_shift_distance,\n                                                        output_red_shift_distance, output_pointer,\n                                                        output_buffer_format_value, number_of_bgr_tuples)\n            if err:\n                raise TLColorError(self._create_c_failure_message(\"tl_color_transform_48_to_48\", err))\n            return output_buffer\n        except Exception as error:\n            _logger.error(\"Could not transform image (48 to 48). \")\n            raise error",
  "def transform_48_to_32(self, input_buffer, input_buffer_format, blue_output_min_value, blue_output_max_value,\n                           green_output_min_value, green_output_max_value, red_output_min_value, red_output_max_value,\n                           output_blue_shift_distance, output_green_shift_distance, output_red_shift_distance,\n                           output_buffer_format, number_of_bgr_tuples\n                           ):\n        # type: (np.array, FORMAT, int, int, int, int, int, int, int, int, int, FORMAT, int) -> np.array\n        try:\n            input_buffer_format_value = c_int(input_buffer_format)\n            output_buffer_format_value = c_int(output_buffer_format)\n\n            input_buffer_as_ushort = input_buffer.view(np.ushort)\n            input_buffer_pointer = input_buffer_as_ushort.ctypes.data_as(POINTER(c_ushort))\n\n            # number of elements goes up (RGB -> RGBA) but size per element goes down (16-bit -> 8-bit)\n            output_buffer = np.empty(shape=(int(input_buffer.size + (input_buffer.size / 4)),), dtype=np.ubyte)\n            output_buffer_pointer = output_buffer.ctypes.data_as(POINTER(c_ubyte))\n\n            err = self._sdk.tl_color_transform_48_to_32(self._color_processor,\n                                                        input_buffer_pointer, input_buffer_format_value,\n                                                        blue_output_min_value, blue_output_max_value,\n                                                        green_output_min_value, green_output_max_value,\n                                                        red_output_min_value, red_output_max_value,\n                                                        output_red_shift_distance, output_green_shift_distance,\n                                                        output_blue_shift_distance, output_buffer_pointer,\n                                                        output_buffer_format_value, number_of_bgr_tuples)\n            if err:\n                raise TLColorError(self._create_c_failure_message(\"tl_color_transform_48_to_32\", err))\n            return output_buffer\n        except Exception as error:\n            _logger.error(\"Could not transform image (48 to 32). \")\n            raise error",
  "def transform_48_to_24(self, input_buffer, input_buffer_format, blue_output_min_value, blue_output_max_value,\n                           green_output_min_value, green_output_max_value, red_output_min_value, red_output_max_value,\n                           output_blue_shift_distance, output_green_shift_distance, output_red_shift_distance,\n                           output_buffer_format, number_of_bgr_tuples\n                           ):\n        # type: (np.array, FORMAT, int, int, int, int, int, int, int, int, int, FORMAT, int) -> np.array\n        try:\n            input_buffer_format_value = c_int(input_buffer_format)\n            output_buffer_format_value = c_int(output_buffer_format)\n\n            input_buffer_as_ushort = input_buffer.view(np.ushort)\n            input_buffer_pointer = input_buffer_as_ushort.ctypes.data_as(POINTER(c_ushort))\n\n            # number of elements stays the same (RGB -> RGB), size per element goes down (16-bit -> 8-bit)\n            output_buffer = np.empty(shape=(input_buffer.size,), dtype=np.ubyte)\n            output_buffer_pointer = output_buffer.ctypes.data_as(POINTER(c_ubyte))\n\n            err = self._sdk.tl_color_transform_48_to_24(self._color_processor,\n                                                        input_buffer_pointer, input_buffer_format_value,\n                                                        blue_output_min_value, blue_output_max_value,\n                                                        green_output_min_value, green_output_max_value,\n                                                        red_output_min_value, red_output_max_value,\n                                                        output_red_shift_distance, output_green_shift_distance,\n                                                        output_blue_shift_distance, output_buffer_pointer,\n                                                        output_buffer_format_value, number_of_bgr_tuples)\n            if err:\n                raise TLColorError(self._create_c_failure_message(\"tl_color_transform_48_to_24\", err))\n            return output_buffer\n        except Exception as error:\n            _logger.error(\"Could not transform image (48 to 24). \")\n            raise error",
  "def __init__(self):\n        # type: (type(None)) -> None\n        self._disposed = True\n        if Demosaicker._is_sdk_open:\n            _logger.error(\"Error: Demosaicker is already in use. Please dispose of the current instance before \"\n                          \"trying to create another\")\n        try:\n            self._sdk = cdll.LoadLibrary(r\"thorlabs_tsi_demosaic.dll\")\n        except OSError as ose:\n            _logger.error(str(ose) + \"\\n\\nUnable to load library - are the thorlabs_tsi_demosaic DLLs \"\n                                     \"discoverable from the application directory? Try placing them in the same \"\n                                     \"directory as tl_color.py, or adding the directory with the DLLs to the \"\n                                     \"PATH. Make sure to use x86 DLLs when using 32-bit python and x64 DLLs when \"\n                                     \"using 64-bit.\")\n        try:\n            err = self._sdk.tl_demosaic_module_initialize()\n            if err != 0:\n                raise TLColorError(\"tl_demosaic_module_initialize failed with error code \" + str(err) + \"\\n\")\n            Demosaicker._is_sdk_open = True\n            self._disposed = False\n\n            \"\"\" set C function argument types \"\"\"\n\n            self._sdk.tl_demosaic_transform_16_to_48.argtypes = [c_int, c_int, c_int, c_int, c_int, c_int,\n                                                                 c_int, c_int, POINTER(c_ushort), POINTER(c_ushort)]\n\n        except Exception as error:\n            _logger.error(\"Error: sdk initialization failed\\n\")\n            raise error",
  "def __del__(self):\n        self.dispose()",
  "def __enter__(self):\n        return self",
  "def __exit__(self, exc_type, exc_val, exc_tb):\n        self.dispose()\n        return isinstance(exc_val, TLColorError)",
  "def dispose(self):\n        # type: (type(None)) -> None\n        try:\n            if self._disposed:\n                return\n            err = self._sdk.tl_demosaic_module_terminate()\n            if err != 0:\n                raise TLColorError(\"tl_demosaic_module_terminate failed with error code \" + str(err) + \"\\n\")\n            Demosaicker._is_sdk_open = False\n            self._disposed = True\n        except Exception as error:\n            _logger.error(\"Error: sdk destruction failed\\n\")\n            raise error",
  "def transform_16_to_48(self, width, height, x_origin, y_origin, color_phase, output_color_format,\n                           color_filter_type, bit_depth, input_buffer):\n        # type: (int, int, int, int, FILTER_ARRAY_PHASE, FORMAT, FILTER_TYPE, int, np.array) -> np.array\n\n        try:\n            input_buffer_as_ushort = input_buffer.view(np.ushort)\n            input_buffer_pointer = input_buffer_as_ushort.ctypes.data_as(POINTER(c_ushort))\n\n            color_phase_value = c_int(color_phase)\n            output_color_format_value = c_int(output_color_format)\n            color_filter_type_value = c_int(color_filter_type)\n\n            # number of elements goes up (Mono -> RGB), size per element stays the same (16-bit -> 16-bit)\n            output_buffer = np.empty(shape=(input_buffer.size * 3,), dtype=np.ushort)\n            output_buffer_pointer = output_buffer.ctypes.data_as(POINTER(c_ushort))\n\n            err = self._sdk.tl_demosaic_transform_16_to_48(width, height, x_origin, y_origin, color_phase_value,\n                                                           output_color_format_value, color_filter_type_value,\n                                                           bit_depth, input_buffer_pointer, output_buffer_pointer)\n            if err:\n                raise TLColorError(\"tl_color_transform_48_to_24 returned error code \" + str(err) + \"\\n\")\n            return output_buffer\n        except Exception as error:\n            _logger.error(\"Error: could not demosaic the image (16 to 48)\\n\")\n            raise error",
  "def __init__(self, message):\n        _logger.debug(message)\n        super(TLColorError, self).__init__(message)",
  "class _CTypesEnum(IntEnum):\n    @classmethod\n    def from_param(cls, obj):\n        return int(obj)",
  "class POLAR_PHASE(_CTypesEnum):\n    \"\"\"\n    The possible polarization angle values (in degrees) for a pixel in a polarization sensor. The polarization phase\n    pattern of the sensor is::\n\n        -------------\n        | + 0 | -45 |\n        -------------\n        | +45 | +90 |\n        -------------\n\n    The primitive pattern shown above represents the fundamental polarization phase arrangement in a polarization\n    sensor. The basic pattern would extend in the X and Y directions in a real polarization sensor containing millions\n    of pixels. Notice that the phase of the origin (0, 0) pixel logically determines the phase of every other pixel.\n    It is for this reason that the phase of this origin pixel is termed the polarization \"phase\" because it represents\n    the reference point for the phase determination of all other pixels.\n\n\n    \"\"\"\n    PolarPhase0 = 0\n    \"\"\"\n    0 degrees polarization phase \n    \n    \"\"\"\n    PolarPhase45 = 1\n    \"\"\"\n    45 degrees polarization phase \n\n    \"\"\"\n    PolarPhase90 = 2\n    \"\"\"\n    90 degrees polarization phase \n\n    \"\"\"\n    PolarPhase135 = 3\n    \"\"\"\n    135 (-45) degrees polarization phase \n\n    \"\"\"",
  "def from_param(cls, obj):\n        return int(obj)",
  "class __CTypesEnum(IntEnum):\n    @classmethod\n    def from_param(cls, obj):\n        return int(obj)",
  "class FILTER_ARRAY_PHASE(__CTypesEnum):\n    \"\"\"\n    The FILTER_ARRAY_PHASE enumeration lists all the possible values that a pixel in a Bayer pattern color arrangement \n    could assume.\n\n    The classic Bayer pattern is::\n\n        -----------------------\n        |          |          |\n        |    R     |    GR    |\n        |          |          |\n        -----------------------\n        |          |          |\n        |    GB    |    B     |\n        |          |          |\n        -----------------------\n\n    where:\n    \n    - R = a red pixel\n    - GR = a green pixel next to a red pixel\n    - B = a blue pixel\n    - GB = a green pixel next to a blue pixel\n   \n    The primitive pattern shown above represents the fundamental color pixel arrangement in a Bayer pattern\n    color sensor.  The basic pattern would extend in the X and Y directions in a real color sensor containing\n    millions of pixels.\n   \n    Notice that the color of the origin (0, 0) pixel logically determines the color of every other pixel.\n   \n    It is for this reason that the color of this origin pixel is termed the color \"phase\" because it represents\n    the reference point for the color determination of all other pixels.\n   \n    Every TSI color camera provides the sensor specific color phase of the full frame origin pixel as a discoverable\n    parameter.\n\n    \"\"\"\n    BAYER_RED = 0\n    \"\"\"\n    A red pixel.\n    \n    \"\"\"\n    BAYER_BLUE = 1\n    \"\"\"\n    A blue pixel.\n    \n    \"\"\"\n    GREEN_LEFT_OF_RED = 2\n    \"\"\"\n    A green pixel next to a red pixel.\n    \n    \"\"\"\n    GREEN_LEFT_OF_BLUE = 3\n    \"\"\"\n    A green pixel next to a blue pixel.\n    \n    \"\"\"",
  "class FORMAT(__CTypesEnum):\n    \"\"\"\n    The FORMAT enumeration lists all the possible options for specifying the order of\n    color pixels in input and/or output buffers.\n   \n    Depending on the context, it can specify:\n\n    - the desired pixel order that a module must use when writing color pixel data into an output buffer\n    - the pixel order that a module must use to interpret data in an input buffer.\n    \n    \"\"\"\n    BGR_PLANAR = 0\n    \"\"\"\n    The color pixels blue, green, and red are grouped in separate planes in the buffer:\\n\n    BBBBB... GGGGG... RRRRR....\n    \n    \"\"\"\n    BGR_PIXEL = 1\n    \"\"\"\n    The color pixels blue, green, and red are clustered and stored consecutively in the following pattern:\\n \n    BGRBGRBGR...\n    \n    \"\"\"\n    RGB_PIXEL = 2\n    \"\"\"\n    The color pixels blue, green, and red are clustered and stored consecutively in the following pattern:\\n\n    RGBRGBRGB...\n    \n    \"\"\"",
  "class FILTER_TYPE(__CTypesEnum):\n    \"\"\"\n    The FILTER_TYPE enumeration lists all the possible filter options for color cameras\n    \n    \"\"\"\n    BAYER = 0\n    \"\"\"\n    A Bayer pattern color sensor.\n    \n    \"\"\"",
  "def from_param(cls, obj):\n        return int(obj)",
  "class _CTypesEnum(IntEnum):\n    @classmethod\n    def from_param(cls, obj):\n        return int(obj)",
  "class COLOR_SPACE(_CTypesEnum):\n    \"\"\"\n    A color space describes how the colors in an image are going to be specified. Some commonly used color spaces are those derived from the\n    RGB color model, in which each pixel has a Red, Blue, and Green component. This means the amount of color that can expressed in a single\n    pixel is all the possible combinations of Red, Blue, and Green. If we assume the image data is in bytes, each component can take any value\n    from 0 to 255. The total number of colors that a pixel could express can be calculated as 256 * 256 * 256 = 16777216 different colors.\n\n    There are many different color spaces that are used for different purposes. The mono to color processor supports two color spaces that\n    are both derived from the RGB color model: sRGB and Linear sRGB.\n\n    \"\"\"\n    SRGB = 0\n    \"\"\"\n    sRGB or standard RGB is a common color space used for displaying images on computer monitors or for sending images over the internet. \n    In addition to the Red, Blue, and Green components combining to define the color of a pixel, the final RGB values undergo a nonlinear transformation \n    to be put in the sRGB color space. The exact transfer function can be found online by searching for the sRGB specification. The purpose of this \n    transformation is to represent the colors in a way that looks more accurate to humans.\n    \n    \"\"\"\n    LINEAR_SRGB = 1\n    \"\"\"\n    Linear sRGB is very similar to sRGB, but does not perform the non linear transformation. The transformation of the data in sRGB changes the RGB intensities, \n    whereas this color space is much more representative of the raw image data coming off the sensor. Without the transformation, however, images in the Linear \n    sRGB color space do not look as accurate as those in sRGB. When deciding between Linear sRGB and sRGB, use Linear sRGB when the actual intensities of the raw \n    image data are important and use sRGB when the image needs to look accurate to the human eye.\n    \n    \"\"\"",
  "def from_param(cls, obj):\n        return int(obj)",
  "def _get_last_error(sdk):\n    try:\n        error_pointer = sdk.tl_camera_get_last_error()\n        if error_pointer is None:\n            return None\n        return str(error_pointer.decode(\"utf-8\"))\n    except Exception as exception:\n        _logger.error(\"unable to get last error; \" + str(exception))",
  "def _create_c_failure_message(sdk, function_name, error_code):\n    last_error = _get_last_error(sdk)\n    failure_message = \"{function_name}() returned non-zero error code: {error_code}; \" \\\n                      \"error message: {last_error}\" \\\n        .format(function_name=function_name, error_code=error_code, last_error=last_error)\n    return failure_message",
  "class Frame(object):\n    \"\"\"\n\n    Holds the image data and frame count returned by polling the camera for an image.\n\n    \"\"\"\n\n    def __init__(self, image_buffer, frame_count, time_stamp_relative_ns_or_null):\n        #  image_buffer._wrapper = self\n        self._image_buffer = image_buffer\n        self._frame_count = int(frame_count.value)\n        self._time_stamp_relative_ns_or_null = time_stamp_relative_ns_or_null\n\n    @property\n    def image_buffer(self):\n        \"\"\"\n        Numpy array of pixel data. This array is temporary and may be invalidated after\n        :meth:`polling for another image<thorlabs_tsi_sdk.tl_camera.TLCamera.get_pending_frame_or_null>`,\n        :meth:`rearming the camera<thorlabs_tsi_sdk.tl_camera.TLCamera.arm>`, or\n        :meth:`closing the camera<thorlabs_tsi_sdk.tl_camera.TLCamera.dispose>`.\n\n        :type: np.array(dtype=np.ushort)\n        \"\"\"\n        return self._image_buffer\n\n    @property\n    def frame_count(self):\n        \"\"\"\n        Frame number assigned to this image by the camera.\n\n        :type: int\n        \"\"\"\n        return self._frame_count\n\n    @property\n    def time_stamp_relative_ns_or_null(self):\n        \"\"\"\n        Time stamp in nanoseconds relative to an internal counter mechanism. The timestamp is recorded immediately\n        following the exposure time. It is calculated by taking the pixel clock and dividing it by a model-specific\n        clock base frequency.\n        This value can be used to find the time in nanoseconds between frames (Frame_2.time_stamp_relative_ns_or_null -\n        Frame_1.time_stamp_relative_ns_or_null).\n        If the camera does not support time stamps, then this value will be None.\n\n        :type: int\n        \"\"\"\n        return self._time_stamp_relative_ns_or_null",
  "class TLCameraSDK(object):\n    \"\"\"\n    TLCameraSDK\n\n    The SDK object that is used to create TLCamera objects. There must be only one instance of this class active at a\n    time. Use the :meth:`dispose()<thorlabs_tsi_sdk.tl_camera.TLCameraSDK.dispose>` method to destroy an SDK instance before creating\n    another instance. *with* statements can also be used with this class to automatically dispose the SDK.\n\n    \"\"\"\n\n    _is_sdk_open = False  # is SDK DLL currently being accessed by a TLCameraSDK instance\n\n    def __init__(self):\n        # type: (type(None)) -> None\n        self._disposed = True\n\n        if TLCameraSDK._is_sdk_open:\n            raise TLCameraError(\"TLCameraSDK is already in use. Please dispose of the current instance before\"\n                                \" trying to create another\")\n\n        try:\n            if platform.system() == 'Windows':\n                self._sdk = cdll.LoadLibrary(r\"thorlabs_tsi_camera_sdk.dll\")\n            elif platform.system() == 'Linux':\n                self._sdk = cdll.LoadLibrary(r\"libthorlabs_tsi_camera_sdk.so\")\n            else:\n                raise TLCameraError(\"{system} is not a supported platform.\".format(system=platform.system()))\n            self._disposed = False\n        except OSError as os_error:\n            raise TLCameraError(str(os_error) +\n                                \"\\nUnable to load library - are the thorlabs tsi camera sdk libraries \"\n                                \"discoverable from the application directory? Try placing them in the same \"\n                                \"directory as your program, or adding the directory with the libraries to the \"\n                                \"PATH. Make sure to use 32-bit libraries when using a 32-bit python interpreter \"\n                                \"and 64-bit libraries when using a 64-bit interpreter.\\n\")\n\n        error_code = self._sdk.tl_camera_open_sdk()\n        if error_code != 0:\n            raise TLCameraError(\"tl_camera_open_sdk() returned error code: {error_code}\\n\"\n                                .format(error_code=error_code))\n        TLCameraSDK._is_sdk_open = True\n        self._current_camera_connect_callback = None\n        self._current_camera_disconnect_callback = None\n\n        try:\n            \"\"\" set C function argument types \"\"\"\n            self._sdk.tl_camera_discover_available_cameras.argtypes = [c_char_p, c_int]\n            self._sdk.tl_camera_open_camera.argtypes = [c_char_p, POINTER(c_void_p)]\n            self._sdk.tl_camera_set_camera_connect_callback.argtypes = [_camera_connect_callback_type, c_void_p]\n            self._sdk.tl_camera_set_camera_disconnect_callback.argtypes = [_camera_disconnect_callback_type, c_void_p]\n            self._sdk.tl_camera_close_camera.argtypes = [c_void_p]\n            self._sdk.tl_camera_set_frame_available_callback.argtypes = [c_void_p, _frame_available_callback_type,\n                                                                         c_void_p]\n            self._sdk.tl_camera_get_pending_frame_or_null.argtypes = [c_void_p, POINTER(POINTER(c_ushort)),\n                                                                      POINTER(c_int), POINTER(POINTER(c_char)),\n                                                                      POINTER(c_int)]\n            self._sdk.tl_camera_get_measured_frame_rate.argtypes = [c_void_p, POINTER(c_double)]\n            self._sdk.tl_camera_get_is_data_rate_supported.argtypes = [c_void_p, c_int, POINTER(c_bool)]\n            self._sdk.tl_camera_get_is_taps_supported.argtypes = [c_void_p, POINTER(c_bool), c_int]\n            self._sdk.tl_camera_get_color_correction_matrix.argtypes = [c_void_p, POINTER(_3x3Matrix_float)]\n            self._sdk.tl_camera_get_default_white_balance_matrix.argtypes = [c_void_p, POINTER(_3x3Matrix_float)]\n            self._sdk.tl_camera_arm.argtypes = [c_void_p, c_int]\n            self._sdk.tl_camera_issue_software_trigger.argtypes = [c_void_p]\n            self._sdk.tl_camera_disarm.argtypes = [c_void_p]\n            self._sdk.tl_camera_get_exposure_time.argtypes = [c_void_p, POINTER(c_longlong)]\n            self._sdk.tl_camera_set_exposure_time.argtypes = [c_void_p, c_longlong]\n            self._sdk.tl_camera_get_image_poll_timeout.argtypes = [c_void_p, POINTER(c_int)]\n            self._sdk.tl_camera_set_image_poll_timeout.argtypes = [c_void_p, c_int]\n            self._sdk.tl_camera_get_exposure_time_range.argtypes = [c_void_p, POINTER(c_longlong), POINTER(c_longlong)]\n            self._sdk.tl_camera_get_firmware_version.argtypes = [c_void_p, c_char_p, c_int]\n            self._sdk.tl_camera_get_frame_time.argtypes = [c_void_p, POINTER(c_int)]\n            self._sdk.tl_camera_get_trigger_polarity.argtypes = [c_void_p, POINTER(c_int)]\n            self._sdk.tl_camera_set_trigger_polarity.argtypes = [c_void_p, c_int]\n            self._sdk.tl_camera_get_binx.argtypes = [c_void_p, POINTER(c_int)]\n            self._sdk.tl_camera_set_binx.argtypes = [c_void_p, c_int]\n            self._sdk.tl_camera_get_sensor_readout_time.argtypes = [c_void_p, POINTER(c_int)]\n            self._sdk.tl_camera_get_binx_range.argtypes = [c_void_p, POINTER(c_int), POINTER(c_int)]\n            self._sdk.tl_camera_get_is_hot_pixel_correction_enabled.argtypes = [c_void_p, POINTER(c_int)]\n            self._sdk.tl_camera_set_is_hot_pixel_correction_enabled.argtypes = [c_void_p, c_int]\n            self._sdk.tl_camera_get_hot_pixel_correction_threshold.argtypes = [c_void_p, POINTER(c_int)]\n            self._sdk.tl_camera_set_hot_pixel_correction_threshold.argtypes = [c_void_p, c_int]\n            self._sdk.tl_camera_get_hot_pixel_correction_threshold_range.argtypes = [c_void_p, POINTER(c_int),\n                                                                                     POINTER(c_int)]\n            self._sdk.tl_camera_get_sensor_width.argtypes = [c_void_p, POINTER(c_int)]\n            self._sdk.tl_camera_get_gain_range.argtypes = [c_void_p, POINTER(c_int), POINTER(c_int)]\n            self._sdk.tl_camera_get_image_width_range.argtypes = [c_void_p, POINTER(c_int), POINTER(c_int)]\n            self._sdk.tl_camera_get_sensor_height.argtypes = [c_void_p, POINTER(c_int)]\n            self._sdk.tl_camera_get_image_height_range.argtypes = [c_void_p, POINTER(c_int), POINTER(c_int)]\n            self._sdk.tl_camera_get_model.argtypes = [c_void_p, c_char_p, c_int]\n            self._sdk.tl_camera_get_name.argtypes = [c_void_p, c_char_p, c_int]\n            self._sdk.tl_camera_set_name.argtypes = [c_void_p, c_char_p]\n            self._sdk.tl_camera_get_name_string_length_range.argtypes = [c_void_p, POINTER(c_int), POINTER(c_int)]\n            self._sdk.tl_camera_get_frames_per_trigger_zero_for_unlimited.argtypes = [c_void_p, POINTER(c_uint)]\n            self._sdk.tl_camera_set_frames_per_trigger_zero_for_unlimited.argtypes = [c_void_p, c_uint]\n            self._sdk.tl_camera_get_frames_per_trigger_range.argtypes = [c_void_p, POINTER(c_uint), POINTER(c_uint)]\n            self._sdk.tl_camera_get_usb_port_type.argtypes = [c_void_p, POINTER(c_int)]\n            self._sdk.tl_camera_get_communication_interface.argtypes = [c_void_p, POINTER(c_int)]\n            self._sdk.tl_camera_get_operation_mode.argtypes = [c_void_p, POINTER(c_int)]\n            self._sdk.tl_camera_set_operation_mode.argtypes = [c_void_p, c_int]\n            self._sdk.tl_camera_get_is_armed.argtypes = [c_void_p, POINTER(c_bool)]\n            self._sdk.tl_camera_get_is_eep_supported.argtypes = [c_void_p, POINTER(c_bool)]\n            self._sdk.tl_camera_get_is_led_supported.argtypes = [c_void_p, POINTER(c_bool)]\n            self._sdk.tl_camera_get_is_cooling_supported.argtypes = [c_void_p, POINTER(c_bool)]\n            self._sdk.tl_camera_get_cooling_enable.argtypes = [c_void_p, POINTER(c_bool)]\n            self._sdk.tl_camera_get_is_nir_boost_supported.argtypes = [c_void_p, POINTER(c_bool)]\n            self._sdk.tl_camera_get_camera_sensor_type.argtypes = [c_void_p, POINTER(c_int)]\n            self._sdk.tl_camera_get_color_filter_array_phase.argtypes = [c_void_p, POINTER(c_int)]\n            self._sdk.tl_camera_get_camera_color_correction_matrix_output_color_space.argtypes = [c_void_p, c_char_p]\n            self._sdk.tl_camera_get_data_rate.argtypes = [c_void_p, POINTER(c_int)]\n            self._sdk.tl_camera_set_data_rate.argtypes = [c_void_p, c_int]\n            self._sdk.tl_camera_get_sensor_pixel_size_bytes.argtypes = [c_void_p, POINTER(c_int)]\n            self._sdk.tl_camera_get_sensor_pixel_width.argtypes = [c_void_p, POINTER(c_double)]\n            self._sdk.tl_camera_get_sensor_pixel_height.argtypes = [c_void_p, POINTER(c_double)]\n            self._sdk.tl_camera_get_bit_depth.argtypes = [c_void_p, POINTER(c_int)]\n            self._sdk.tl_camera_get_roi.argtypes = [c_void_p, POINTER(c_int), POINTER(c_int), POINTER(c_int),\n                                                    POINTER(c_int)]\n            self._sdk.tl_camera_set_roi.argtypes = [c_void_p, c_int, c_int, c_int, c_int]\n            self._sdk.tl_camera_get_roi_range.argtypes = [c_void_p, POINTER(c_int), POINTER(c_int), POINTER(c_int),\n                                                          POINTER(c_int), POINTER(c_int), POINTER(c_int),\n                                                          POINTER(c_int), POINTER(c_int)]\n            self._sdk.tl_camera_get_serial_number.argtypes = [c_void_p, c_char_p, c_int]\n            self._sdk.tl_camera_get_serial_number_string_length_range.argtypes = [c_void_p, POINTER(c_int),\n                                                                                  POINTER(c_int)]\n            self._sdk.tl_camera_get_is_led_on.argtypes = [c_void_p, POINTER(c_bool)]\n            self._sdk.tl_camera_set_is_led_on.argtypes = [c_void_p, c_bool]\n            self._sdk.tl_camera_get_eep_status.argtypes = [c_void_p, POINTER(c_int)]\n            self._sdk.tl_camera_set_is_eep_enabled.argtypes = [c_void_p, c_bool]\n            self._sdk.tl_camera_get_biny.argtypes = [c_void_p, POINTER(c_int)]\n            self._sdk.tl_camera_set_biny.argtypes = [c_void_p, c_int]\n            self._sdk.tl_camera_get_biny_range.argtypes = [c_void_p, POINTER(c_int), POINTER(c_int)]\n            self._sdk.tl_camera_get_gain.argtypes = [c_void_p, POINTER(c_int)]\n            self._sdk.tl_camera_set_gain.argtypes = [c_void_p, c_int]\n            self._sdk.tl_camera_get_black_level.argtypes = [c_void_p, POINTER(c_int)]\n            self._sdk.tl_camera_set_black_level.argtypes = [c_void_p, c_int]\n            self._sdk.tl_camera_get_black_level_range.argtypes = [c_void_p, POINTER(c_int), POINTER(c_int)]\n            self._sdk.tl_camera_get_frames_per_trigger_zero_for_unlimited.argtypes = [c_void_p, POINTER(c_uint)]\n            self._sdk.tl_camera_set_frames_per_trigger_zero_for_unlimited.argtypes = [c_void_p, c_uint]\n            self._sdk.tl_camera_get_frames_per_trigger_range.argtypes = [c_void_p, POINTER(c_uint), POINTER(c_uint)]\n            self._sdk.tl_camera_get_image_width.argtypes = [c_void_p, POINTER(c_int)]\n            self._sdk.tl_camera_get_image_height.argtypes = [c_void_p, POINTER(c_int)]\n            self._sdk.tl_camera_get_polar_phase.argtypes = [c_void_p, POINTER(c_int)]\n            self._sdk.tl_camera_get_frame_rate_control_value_range.argtypes = [c_void_p, POINTER(c_double), POINTER(c_double)]\n            self._sdk.tl_camera_get_is_frame_rate_control_enabled.argtypes = [c_void_p, POINTER(c_int)]\n            self._sdk.tl_camera_set_is_frame_rate_control_enabled.argtypes = [c_void_p, c_int]\n            self._sdk.tl_camera_get_frame_rate_control_value.argtypes = [c_void_p, POINTER(c_double)]\n            self._sdk.tl_camera_set_frame_rate_control_value.argtypes = [c_void_p, c_double]\n            self._sdk.tl_camera_get_timestamp_clock_frequency.argtypes = [c_void_p, POINTER(c_int)]\n            self._sdk.tl_camera_convert_gain_to_decibels.argtypes = [c_void_p, c_int, POINTER(c_double)]\n            self._sdk.tl_camera_convert_decibels_to_gain.argtypes = [c_void_p, c_double, POINTER(c_int)]\n            self._sdk.tl_camera_get_is_operation_mode_supported.argtypes = [c_void_p, c_int, POINTER(c_bool)]\n\n            self._sdk.tl_camera_get_last_error.restype = c_char_p\n            # noinspection PyProtectedMember\n            self._sdk._internal_command.argtypes = [c_void_p, c_char_p, c_uint, c_char_p, c_uint]\n        except Exception as exception:\n            _logger.error(\"SDK initialization failed; \" + str(exception))\n            raise exception\n\n    def __del__(self):\n        self.dispose()\n\n    \"\"\" with statement functionality \"\"\"\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, exception_type, exception_value, exception_traceback):\n        if exception_type is not None:\n            _logger.debug(\"\".join(format_exception(exception_type, exception_value, exception_traceback)))\n        self.dispose()\n        return True if exception_type is None else False\n\n    \"\"\" methods \"\"\"\n\n    def dispose(self):\n        # type: (type(None)) -> None\n        \"\"\"\n        Cleans up the TLCameraSDK instance - make sure to call this when you are done with the TLCameraSDK instance.\n        If using the *with* statement, dispose is called automatically upon exit.\n\n        \"\"\"\n        try:\n            if self._disposed:\n                return\n            error_code = self._sdk.tl_camera_close_sdk()\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_close_sdk\", error_code))\n            TLCameraSDK._is_sdk_open = False\n            self._disposed = True\n            self._current_camera_connect_callback = None\n            self._current_camera_disconnect_callback = None\n        except Exception as exception:\n            _logger.error(\"Camera SDK destruction failed; \" + str(exception))\n            raise exception\n\n    def discover_available_cameras(self):\n        # type: (type(None)) -> List[str]\n        \"\"\"\n        Returns a list of all open cameras by their serial number string.\n\n        \"\"\"\n        try:\n            string_buffer = create_string_buffer(_STRING_MAX)\n            error_code = self._sdk.tl_camera_discover_available_cameras(string_buffer, _STRING_MAX)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_discover_available_cameras\",\n                                                              error_code))\n            return string_buffer.value.decode(\"utf-8\").split()\n        except Exception as exception:\n            _logger.error(\"discover_available_cameras failed; \" + str(exception))\n            raise exception\n\n    def open_camera(self, camera_serial_number):\n        # type: (str) -> TLCamera\n        \"\"\"\n        Opens the camera with given serial number and returns it as a TLCamera instance.\n\n        :param str camera_serial_number: The serial number of the camera to open.\n        :returns: :class:`TLCamera<thorlabs_tsi_sdk.tl_camera.TLCamera>`\n\n        \"\"\"\n        try:\n            serial_number_bytes = camera_serial_number.encode(\"utf-8\") + b'\\0'\n            c_camera_handle = c_void_p()  # void *\n            error_code = self._sdk.tl_camera_open_camera(serial_number_bytes, c_camera_handle)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_open_camera\", error_code))\n            # noinspection PyProtectedMember\n            return TLCamera._create(self._sdk, c_camera_handle)\n        except Exception as exception:\n            _logger.error(\"Could not open camera '{serial_number}'; {exception}\".format(\n                serial_number=str(camera_serial_number),\n                exception=str(exception)))\n            raise exception\n\n    @staticmethod\n    def _generate_camera_connect_callback(_callback, *args, **kwargs):\n        # warning that context is unused suppressed - it must be in the function signature to match native function call\n        # noinspection PyUnusedLocal\n        def camera_connect_callback(camera_serial_number, usb_port_type, context):\n            _callback(str(camera_serial_number.decode('utf-8')), USB_PORT_TYPE(usb_port_type), *args, **kwargs)\n\n        return _camera_connect_callback_type(camera_connect_callback)\n\n    def set_camera_connect_callback(self,\n                                    handler,\n                                    # type: Callable[[str, USB_PORT_TYPE, Optional[Any], Optional[Any]], type(None)]\n                                    *args,  # type: Optional[Any]\n                                    **kwargs  # type: Optional[Any]\n                                    ):  # type: (...) -> None\n        \"\"\"\n        Sets the callback function for camera connection events. Whenever a USB camera is connected, the provided\n        handler will be called along with any specified arguments and keyword arguments.\n\n        :param handler: Any method with a signature that conforms to this type. It will be called when a USB camera is\n         connected.\n        :type handler: Callable[[str, :class:`USB_PORT_TYPE<thorlabs_tsi_sdk.tl_camera_enums.USB_PORT_TYPE>`, Optional[Any], Optional[Any]], type(None)]\n        :param args: Optional arguments that are forwarded to the handler when it is called.\n        :type args: Optional[Any]\n        :param kwargs: Optional keyword arguments that are forwarded to the handler when it is called.\n        :type kwargs: Optional[Any]\n\n        \"\"\"\n        try:\n            callback = self._generate_camera_connect_callback(handler, *args, **kwargs)\n            error_code = self._sdk.tl_camera_set_camera_connect_callback(callback, None)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_set_camera_connect_callback\",\n                                                              error_code))\n            self._current_camera_connect_callback = callback  # reference the callback so python doesn't delete it\n        except Exception as exception:\n            _logger.error(\"Could not set camera connect callback; \" + str(exception))\n            raise exception\n\n    @staticmethod\n    def _generate_camera_disconnect_callback(_callback, *args, **kwargs):\n        # warning that context is unused suppressed - it must be in the function signature to match native function call\n        # noinspection PyUnusedLocal\n        def camera_disconnect_callback(camera_serial_number, context):\n            _callback(str(camera_serial_number.decode('utf-8')), *args, **kwargs)\n\n        return _camera_disconnect_callback_type(camera_disconnect_callback)\n\n    def set_camera_disconnect_callback(self,\n                                       handler,\n                                       # type: Callable[[str, Optional[Any], Optional[Any]], type(None)]\n                                       *args,  # type: Optional[Any]\n                                       **kwargs  # type: Optional[Any]\n                                       ):  # type: (...) -> None\n        \"\"\"\n        Sets the callback function for camera disconnection events. Whenever a USB camera is disconnected, the\n        provided handler will be called along with any specified arguments and keyword arguments\n\n        :param handler: Any method with a signature that conforms to this type. It will be called when a USB camera is\n         disconnected.\n        :type handler: Callable[[str, Optional[Any], Optional[Any]], type(None)]\n        :param args: Optional arguments that are forwarded to the handler when it is called.\n        :type args: Optional[Any]\n        :param kwargs: Optional keyword arguments that are forwarded to the handler when it is called.\n        :type kwargs: Optional[Any]\n\n        \"\"\"\n        try:\n            callback = self._generate_camera_disconnect_callback(handler, *args, **kwargs)\n            error_code = self._sdk.tl_camera_set_camera_disconnect_callback(callback, None)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_set_camera_disconnect_callback\",\n                                                              error_code))\n            self._current_camera_disconnect_callback = callback  # reference the callback so python doesn't delete it\n        except Exception as exception:\n            _logger.error(\"Could not set camera disconnect callback; \" + str(exception))\n            raise exception",
  "class TLCamera(object):\n    \"\"\"\n    TLCamera\n\n    Used to interface with a Thorlabs camera. These objects can adjust camera settings and retrieve images.\n    When finished with a camera, call its :meth:`dispose<thorlabs_tsi_sdk.tl_camera.TLCamera.dispose>` method to clean\n    up any opened resources. These objects can be managed using *with* statements for automatic resource clean up.\n    These objects can only be created by calls\n    to :meth:`TLCameraSDK.open_camera<thorlabs_tsi_sdk.tl_camera.TLCameraSDK.open_camera>`.\n\n    \"\"\"\n\n    __key = object()\n\n    @classmethod\n    def _create(cls, sdk, camera):\n        # type: (Any, Any) -> TLCamera\n        return TLCamera(cls.__key, sdk, camera)\n\n    def __init__(self, key, sdk, camera):\n        # type: (type(object), Any, Any) -> None\n        try:\n            self._disposed = True\n            assert (key == TLCamera.__key), \"TLCamera objects cannot be created manually. Please use \" \\\n                                            \"TLCameraSDK.open_camera to acquire new TLCamera objects.\"\n            self._sdk = sdk\n            self._camera = camera\n            self._current_frame_available_callback = None\n            self._local_image_height_pixels = 0\n            self._local_image_width_pixels = 0\n            self._local_timestamp_clock_frequency = None\n            self._disposed = False\n        except Exception as exception:\n            _logger.error(\"TLCamera initialization failed; \" + str(exception))\n            raise exception\n\n    def __del__(self):\n        self.dispose()\n\n    \"\"\" with statement functionality \"\"\"\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, exception_type, exception_value, exception_traceback):\n        if exception_type is not None:\n            _logger.debug(\"\".join(format_exception(exception_type, exception_value, exception_traceback)))\n        self.dispose()\n        return True if exception_type is None else False\n\n    def dispose(self):\n        # type: (type(None)) -> None\n        \"\"\"\n        Cleans up the TLCamera instance - make sure to call this when you are done with the camera.\n        If using the *with* statement, dispose is called automatically upon exit.\n\n        \"\"\"\n        try:\n            if self._disposed:\n                return\n            error_code = self._sdk.tl_camera_disarm(self._camera)\n            if error_code != 0:\n                _logger.error(\"Could not disarm camera.\")\n            error_code = self._sdk.tl_camera_close_camera(self._camera)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_close_camera\", error_code))\n            self._disposed = True\n            self._current_frame_available_callback = None\n        except Exception as exception:\n            _logger.error(\"Could not dispose camera; \" + str(exception))\n            raise exception\n\n    def get_pending_frame_or_null(self):\n        # type: (type(None)) -> Optional[Frame]\n        \"\"\"\n        Polls the camera for an image.\n        This method will block for at most :attr:`image_poll_timeout <thorlabs_tsi_sdk.tl_camera.TLCamera.image_poll_timeout_ms>`\n        milliseconds. The Frame that is retrieved will have an image_buffer field to access the pixel data.\n        This image_buffer is only valid until the next call to *get_pending_frame_or_null()* or until disarmed.\n        If image data is needed for a longer period of time, use *np.copy(image_buffer)* to create a deep copy of the\n        data.\n\n        :returns: :class:`Frame<thorlabs_tsi_sdk.tl_camera.Frame>` or None if there is no pending frame\n\n        \"\"\"\n        try:\n            image_buffer = POINTER(c_ushort)()\n            frame_count = c_int()\n            metadata_pointer = POINTER(c_char)()\n            metadata_size_in_bytes = c_int()\n            error_code = self._sdk.tl_camera_get_pending_frame_or_null(self._camera, image_buffer, frame_count,\n                                                                       metadata_pointer, metadata_size_in_bytes)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_get_pending_frame_or_null\",\n                                                              error_code))\n            if not image_buffer:\n                return None\n\n            image_buffer._wrapper = self  # image buffer needs a reference to this instance or it may get deleted\n            image_buffer_as_np_array = np.ctypeslib.as_array(image_buffer, shape=(self._local_image_height_pixels,\n                                                                                  self._local_image_width_pixels))\n            time_stamp_relative_ns = None\n            metadata_size_in_bytes = metadata_size_in_bytes.value\n            if metadata_size_in_bytes > 0 and self._local_timestamp_clock_frequency is not None:\n                metadata = bytes(np.ctypeslib.as_array(metadata_pointer, shape=(metadata_size_in_bytes,)))\n                metadata_chunks = [metadata[i:i+8] for i in range(0, len(metadata), 8)]\n                pixel_clock_high = -1\n                pixel_clock_low = -1\n                for metadata_chunk in metadata_chunks:\n                    tag = metadata_chunk[0:4]\n                    value = struct.unpack('<I', metadata_chunk[4:8])[0]\n                    if tag == b'PCKH':\n                        pixel_clock_high = value\n                    elif tag == b'PCKL':\n                        pixel_clock_low = value\n                    elif tag == b'ENDT':\n                        break\n                # if PCKH or PCKL weren't found, pixel clock is invalid.\n                if pixel_clock_high > -1 and pixel_clock_low > -1:\n                    pixel_clock = (pixel_clock_high << 32) | pixel_clock_low\n                    time_stamp_relative_ns = \\\n                        int((decimal.Decimal(pixel_clock) / decimal.Decimal(self._local_timestamp_clock_frequency))\n                            * 1000000000)\n\n            frame = Frame(image_buffer=image_buffer_as_np_array,\n                          frame_count=frame_count,\n                          time_stamp_relative_ns_or_null=time_stamp_relative_ns)\n\n            return frame\n        except Exception as exception:\n            _logger.error(\"Unable to get pending frame; \" + str(exception))\n            raise exception\n\n    def get_measured_frame_rate_fps(self):\n        # type: (type(None)) -> float\n        \"\"\"\n        Gets the current rate of frames that are delivered to the host computer. The frame rate can be affected by the\n        performance capabilities of the host computer and the communication interface.\n        This method can be polled for updated values as needed.\n\n        :returns: float - The current frame rate as measured by the camera SDK.\n\n        \"\"\"\n        try:\n            frames_per_second = c_double()\n            error_code = self._sdk.tl_camera_get_measured_frame_rate(self._camera, frames_per_second)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_get_measured_frame_rate\",\n                                                              error_code))\n            return float(frames_per_second.value)\n        except Exception as exception:\n            _logger.error(\"Could not get measured frame rate; \" + str(exception))\n            raise exception\n\n    def get_is_data_rate_supported(self, data_rate):\n        # type: (DATA_RATE) -> bool\n        \"\"\"\n        Scientific-CCD cameras and compact-scientific cameras handle sensor- level data-readout speed differently.\n        Use this method to test whether the connected camera supports a particular data rate.\n        For more details about the data rate options, see the :attr:`data_rate<thorlabs_tsi_sdk.tl_camera.TLCamera.data_rate>` property.\n\n        :param: data_rate (:class:`DATA_RATE<thorlabs_tsi_sdk.tl_camera_enums.DATA_RATE>`) - The data rate value to check.\n        :returns: bool - True if the given data rate is supported by the connected camera, false if it is not\n\n        \"\"\"\n        try:\n            c_value = c_int(data_rate)\n            is_supported = c_bool()\n            error_code = self._sdk.tl_camera_get_is_data_rate_supported(self._camera, c_value, is_supported)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"get_is_data_rate_supported\", error_code))\n            return bool(is_supported.value)\n        except Exception as exception:\n            _logger.error(\"Could not get if data rate was supported; \" + str(exception))\n            raise exception\n\n    def get_is_taps_supported(self, tap):\n        # type: (TAPS) -> bool\n        \"\"\"\n        All CCD cameras support a single tap. Some also support dual tap or quad tap. Use this method to test whether a\n        connected camera supports a particular Taps value. For more information on taps and tap balancing, see\n        is_tap_balance_enabled - *Taps not yet supported by Python SDK*.\n\n        :param: tap (:class:`TAPS<thorlabs_tsi_sdk.tl_camera_enums.TAPS>`) - The tap value to check.\n        :returns: bool - True if the connected camera supports the given taps mode, false if not.\n\n        \"\"\"\n        try:\n            c_value = c_int(tap)\n            is_supported = c_bool()\n            error_code = self._sdk.tl_camera_get_is_taps_supported(self._camera, c_value, is_supported)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"get_is_taps_supported\", error_code))\n            return bool(is_supported.value)\n        except Exception as exception:\n            _logger.error(\"Could not get if tap was supported; \" + str(exception))\n            raise exception\n\n    def get_is_operation_mode_supported(self, operation_mode):\n        # type: (OPERATION_MODE) -> bool\n        \"\"\"\n        This method can be used to determine if a camera has the ability to perform hardware triggering. Some cameras,\n        such as the zelux, have both triggered and non-triggered models.\n\n        :param: operation_mode (:class:`OPERATION_MODE<thorlabs_tsi_sdk.tl_camera_enums.OPERATION_MODE>`) - The operation mode to check.\n        :returns: bool - True if the connected camera supports the given operation mode, false if not.\n\n        \"\"\"\n        try:\n            c_value = c_int(operation_mode)\n            is_supported = c_bool()\n            error_code = self._sdk.tl_camera_get_is_operation_mode_supported(self._camera, c_value, is_supported)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"get_is_operation_mode_supported\", error_code))\n            return bool(is_supported.value)\n        except Exception as exception:\n            _logger.error(\"Could not get if operation mode was supported; \" + str(exception))\n            raise exception\n\n    def get_color_correction_matrix(self):\n        # type: (type(None)) -> np.array\n        \"\"\"\n        Each scientific color camera includes a three-by-three matrix that can be used to achieve consistent color for\n        different camera modelsGet the default color correction matrix for this camera. This can be used with the\n        :class:`MonoToColorProcessor<thorlabs_tsi_sdk.tl_mono_to_color_processor.MonoToColorProcessor>` when color processing an image.\n\n        :returns: np.array\n\n        \"\"\"\n        try:\n            color_correction_matrix = _3x3Matrix_float()\n            error_code = self._sdk.tl_camera_get_color_correction_matrix(self._camera, color_correction_matrix)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"get_color_correction_matrix\", error_code))\n            color_correction_matrix_as_np_array = np.array([float(color_correction_matrix[0]),\n                                                            float(color_correction_matrix[1]),\n                                                            float(color_correction_matrix[2]),\n                                                            float(color_correction_matrix[3]),\n                                                            float(color_correction_matrix[4]),\n                                                            float(color_correction_matrix[5]),\n                                                            float(color_correction_matrix[6]),\n                                                            float(color_correction_matrix[7]),\n                                                            float(color_correction_matrix[8])])\n            return color_correction_matrix_as_np_array\n        except Exception as exception:\n            _logger.error(\"Could not get color correction matrix; \" + str(exception))\n            raise exception\n\n    def _get_time_stamp_clock_frequency_or_null(self):\n        # type: (type(None)) -> Optional[int]\n        \"\"\"\n\n        This is the frequency at which the time stamp counter on the camera increments. This is used to calculate\n        clock time from the camera in real-world units.\n\n        :returns: int - time stamp clock base in Hertz.\n\n        \"\"\"\n        try:\n            time_stamp_clock_frequency = c_int()\n            error_code = self._sdk.tl_camera_get_timestamp_clock_frequency(self._camera, time_stamp_clock_frequency)\n            if error_code != 0:\n                return None\n            if time_stamp_clock_frequency.value == 0:\n                return None\n            return int(time_stamp_clock_frequency.value)\n        except Exception as exception:\n            _logger.debug(\"Could not get time stamp clock frequency; \" + str(exception))\n            return None\n\n    def get_default_white_balance_matrix(self):\n        # type: (type(None)) -> np.array\n        \"\"\"\n        Get the default white balance matrix for this camera. Each scientific color camera includes a three-by-three\n        matrix that corrects white balance for the default color temperature. This can be used with the\n        :class:`MonoToColorProcessor<thorlabs_tsi_sdk.tl_mono_to_color_processor.MonoToColorProcessor>` to provide a default white balance to an image.\n\n        :returns: np.array\n\n        \"\"\"\n        try:\n            white_balance_matrix = _3x3Matrix_float()\n            error_code = self._sdk.tl_camera_get_default_white_balance_matrix(self._camera, white_balance_matrix)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"get_default_white_balance_matrix\",\n                                                              error_code))\n            white_balance_matrix_as_np_array = np.array([float(white_balance_matrix[0]),\n                                                         float(white_balance_matrix[1]),\n                                                         float(white_balance_matrix[2]),\n                                                         float(white_balance_matrix[3]),\n                                                         float(white_balance_matrix[4]),\n                                                         float(white_balance_matrix[5]),\n                                                         float(white_balance_matrix[6]),\n                                                         float(white_balance_matrix[7]),\n                                                         float(white_balance_matrix[8])])\n            return white_balance_matrix_as_np_array\n        except Exception as exception:\n            _logger.error(\"Could not get default white balance matrix; \" + str(exception))\n            raise exception\n\n    def arm(self, frames_to_buffer):\n        # type: (int) -> None\n        \"\"\"\n        Before issuing software or hardware triggers to get images from a camera, prepare it for imaging by calling\n        :meth:`arm()<thorlabs_tsi_sdk.tl_camera.TLCamera.arm>`.\n        Depending on the :attr:`operation_mode<thorlabs_tsi_sdk.tl_camera.TLCamera.operation_mode>`, either call\n        :meth:`issue_software_trigger()<thorlabs_tsi_sdk.tl_camera.TLCamera.issue_software_trigger>` or issue a hardware trigger.\n        To start a camera in continuous mode, set the :attr:`operation_mode<thorlabs_tsi_sdk.tl_camera.TLCamera.operation_mode>` to\n        SOFTWARE_TRIGGERED, :attr:`frames per trigger<thorlabs_tsi_sdk.tl_camera.TLCamera.frames_per_trigger_zero_for_unlimited>` to zero, Arm\n        the camera, and then call :meth:`issue_software_trigger()<thorlabs_tsi_sdk.tl_camera.TLCamera.issue_software_trigger>` one time. The\n        camera will then self-trigger frames until :meth:`disarm()<thorlabs_tsi_sdk.tl_camera.TLCamera.disarm>` or\n        :meth:`dispose()<thorlabs_tsi_sdk.tl_camera.TLCamera.dispose>` is called.\n        To start a camera for hardware triggering, set the :attr:`operation_mode<thorlabs_tsi_sdk.tl_camera.TLCamera.operation_mode>` to either\n        HARDWARE_TRIGGERED or BULB, :attr:`frames per trigger<thorlabs_tsi_sdk.tl_camera.TLCamera.frames_per_trigger_zero_for_unlimited>` to\n        one, :attr:`trigger_polarity`<thorlabs_tsi_sdk.tl_camera.TLCamera.trigger_polarity>` to rising-edge or falling-edge triggered, arm the\n        camera, and then issue a triggering signal on the trigger input.\n        If any images are still in the queue when calling :meth:`arm()<thorlabs_tsi_sdk.tl_camera.TLCamera.arm>`, they will be considered stale\n        and cleared from the queue.\n        For more information on the proper procedure for triggering frames and receiving them from the camera, please\n        see the Getting Started section.\n\n        \"\"\"\n        try:\n            error_code = self._sdk.tl_camera_arm(self._camera, c_int(frames_to_buffer))\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_arm\", error_code))\n            self._local_image_height_pixels = self.image_height_pixels\n            self._local_image_width_pixels = self.image_width_pixels\n            self._local_timestamp_clock_frequency = self._get_time_stamp_clock_frequency_or_null()\n        except Exception as exception:\n            _logger.error(\"Could not arm camera; \" + str(exception))\n            raise exception\n\n    def issue_software_trigger(self):\n        # type: (type(None)) -> None\n        \"\"\"\n        If the :attr:`operation_mode<thorlabs_tsi_sdk.tl_camera.TLCamera.operation_mode>` is set to SOFTWARE_TRIGGERED\n        and :meth:`arm()<thorlabs_tsi_sdk.tl_camera.TLCamera.arm>` is called, then calling this method will generate a\n        trigger through the camera SDK rather than through the hardware trigger input.\n\n        The behavior of a software trigger depends on the\n        :attr:`frames_per-trigger_zero_for_unlimited<thorlabs_tsi_sdk.tl_camera.TLCamera.frames_per_trigger_zero_for_unlimited>` property:\n\n        - If :attr:`frames_per-trigger_zero_for_unlimited<thorlabs_tsi_sdk.tl_camera.TLCamera.frames_per_trigger_zero_for_unlimited>` is set to zero, then a single software trigger will start continuous-video mode.\n\n        - If :attr:`frames_per-trigger_zero_for_unlimited<thorlabs_tsi_sdk.tl_camera.TLCamera.frames_per_trigger_zero_for_unlimited>` is set to one or higher, then one software trigger will generate a corresponding number of frames.\n\n        Multiple software triggers can be issued before calling :meth:`disarm()<thorlabs_tsi_sdk.tl_camera.TLCamera.disarm>`.\n\n        IMPORTANT: For scientific-CCD cameras, after issuing a software trigger, it is necessary to wait at least 300ms\n        before adjusting the :attr:`exposure_time_us<thorlabs_tsi_sdk.tl_camera.TLCamera.exposure_time_us>` property.\n\n        \"\"\"\n        try:\n            error_code = self._sdk.tl_camera_issue_software_trigger(self._camera)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_issue_software_trigger\",\n                                                              error_code))\n        except Exception as exception:\n            _logger.error(\"Could not issue software trigger; \" + str(exception))\n            raise exception\n\n    def disarm(self):\n        # type: (type(None)) -> None\n        \"\"\"\n        When finished issuing software or hardware triggers, call :meth:`disarm()<thorlabs_tsi_sdk.tl_camera.TLCamera.disarm>`. This allows\n        setting parameters that are not available in armed mode such as :attr:`roi<thorlabs_tsi_sdk.tl_camera.TLCamera.roi>` or\n        :attr:`operation_mode<thorlabs_tsi_sdk.tl_camera.TLCamera.operation_mode>`.\n        The camera will automatically disarm when :meth:`disarm()<thorlabs_tsi_sdk.tl_camera.TLCamera.disarm>` is called.\n        Disarming the camera does not clear the image queue \u2013 polling can continue until the queue is empty. When\n        calling :meth:`disarm()<thorlabs_tsi_sdk.tl_camera.TLCamera.arm>` again, the queue will be automatically cleared.\n\n        \"\"\"\n        try:\n            error_code = self._sdk.tl_camera_disarm(self._camera)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_disarm\", error_code))\n        except Exception as exception:\n            _logger.error(\"Could not disarm camera; \" + str(exception))\n            raise exception\n\n    def convert_gain_to_decibels(self, gain):\n        # type: (int) -> float\n        \"\"\"\n        Use this method to convert the gain from the :attr:`gain<thorlabs_tsi_sdk.tl_camera.TLCamera.gain>` property into units of Decibels\n        (dB).\n\n        :returns: float\n\n        \"\"\"\n        try:\n            c_decibels = c_double()\n            c_gain = c_int(gain)\n            error_code = self._sdk.tl_camera_convert_gain_to_decibels(self._camera, c_gain, c_decibels)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_convert_gain_to_decibels\",\n                                                              error_code))\n            return float(c_decibels.value)\n        except Exception as exception:\n            _logger.error(\"Could not convert gain to decibels; \" + str(exception))\n            raise exception\n\n    def convert_decibels_to_gain(self, gain_db):\n        # type: (float) -> int\n        \"\"\"\n        Use this method to convert the gain (in decibels) from the\n        :meth:`convert_gain_to_decibels<thorlabs_tsi_sdk.tl_camera.TLCamera.convert_decibels_to_gain>` method back into a gain index.\n        (dB).\n\n        :returns: int\n\n        \"\"\"\n        try:\n            c_gain = c_int()\n            c_decibels = c_double(gain_db)\n            error_code = self._sdk.tl_camera_convert_decibels_to_gain(self._camera, c_decibels, c_gain)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_convert_decibels_to_gain\",\n                                                              error_code))\n            return int(c_gain.value)\n        except Exception as exception:\n            _logger.error(\"Could not convert decibel gain to gain index; \" + str(exception))\n            raise exception\n\n    # internal command intended for TSI software developers\n    def _internal_command(self, command):\n        # type: (str) -> str\n        try:\n            command_data = create_string_buffer(str(command).encode('utf-8') + b'\\0', len(command) + 1)\n            response_data = create_string_buffer(_STRING_MAX)\n            # noinspection PyProtectedMember\n            error_code = self._sdk._internal_command(self._camera, command_data, len(command) + 1, response_data, _STRING_MAX)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"_internal_command\", error_code))\n            return str(response_data.value.decode(\"utf-8\"))\n        except Exception as exception:\n            _logger.error(\"Unable to execute internal command; \" + str(exception))\n            raise exception\n\n    \"\"\" Properties \"\"\"\n\n    @property\n    def exposure_time_us(self):\n        \"\"\"\n        The time, in microseconds (us), that charge is integrated on the image sensor.\n\n        To convert milliseconds to microseconds, multiply the milliseconds by 1,000.\n        To convert microseconds to milliseconds, divide the microseconds by 1,000.\n\n        IMPORTANT: After issuing a software trigger, it is recommended to wait at least 300ms before setting exposure.\n\n        :type: int\n        \"\"\"\n        try:\n            exposure_time_us = c_longlong()\n            error_code = self._sdk.tl_camera_get_exposure_time(self._camera, exposure_time_us)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_get_exposure_time\", error_code))\n            return int(exposure_time_us.value)\n        except Exception as exception:\n            _logger.error(\"Could not get exposure time; \" + str(exception))\n            raise exception\n\n    @exposure_time_us.setter\n    def exposure_time_us(self, exposure_time_us):\n        try:\n            c_value = c_longlong(exposure_time_us)\n            error_code = self._sdk.tl_camera_set_exposure_time(self._camera, c_value)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_set_exposure_time\", error_code))\n        except Exception as exception:\n            _logger.error(\"Could not set exposure time; \" + str(exception))\n            raise exception\n\n    @property\n    def image_poll_timeout_ms(self):\n        \"\"\"\n        :meth:`get_pending_frame_or_null()<thorlabs_tsi_sdk.tl_camera.TLCamera.get_pending_frame_or_null>` will block up to this many\n        milliseconds to get an image. If the SDK could not get an image within the timeout, None will be returned\n        instead.\n\n        :type: int\n        \"\"\"\n        try:\n            image_poll_timeout_ms = c_int()\n            error_code = self._sdk.tl_camera_get_image_poll_timeout(self._camera, image_poll_timeout_ms)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_get_image_poll_timeout\",\n                                                              error_code))\n            return int(image_poll_timeout_ms.value)\n        except Exception as exception:\n            _logger.error(\"Could not get image poll timeout; \" + str(exception))\n            raise exception\n\n    @image_poll_timeout_ms.setter\n    def image_poll_timeout_ms(self, timeout_ms):\n        try:\n            c_value = c_int(timeout_ms)\n            error_code = self._sdk.tl_camera_set_image_poll_timeout(self._camera, c_value)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_set_image_poll_timeout\",\n                                                              error_code))\n        except Exception as exception:\n            _logger.error(\"Could not set image poll timeout; \" + str(exception))\n            raise exception\n\n    @property\n    def exposure_time_range_us(self):\n        \"\"\"\n        Range of possible exposure values in microseconds. This property is Read-Only.\n\n        :type: Range\n        \"\"\"\n        try:\n            exposure_time_us_min = c_longlong()\n            exposure_time_us_max = c_longlong()\n            error_code = self._sdk.tl_camera_get_exposure_time_range(self._camera,\n                                                                     exposure_time_us_min,\n                                                                     exposure_time_us_max)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_get_exposure_time_range\",\n                                                              error_code))\n            return Range(int(exposure_time_us_min.value), int(exposure_time_us_max.value))\n        except Exception as exception:\n            _logger.error(\"Could not get exposure time range; \" + str(exception))\n            raise exception\n\n    @property\n    def firmware_version(self):\n        \"\"\"\n        String containing the version information for all firmware components. This property is Read-Only.\n\n        :type: str\n        \"\"\"\n        try:\n            firmware_version = create_string_buffer(_STRING_MAX)\n            error_code = self._sdk.tl_camera_get_firmware_version(self._camera, firmware_version, _STRING_MAX)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_get_firmware_version\", error_code))\n            return str(firmware_version.value.decode(\"utf-8\"))\n        except Exception as exception:\n            _logger.error(\"Could not get firmware version; \" + str(exception))\n            raise exception\n\n    @property\n    def frame_time_us(self):\n        \"\"\"\n        The time, in microseconds (us), required for a frame to be exposed and read out from the sensor. When\n        triggering frames, this property may be used to determine when the camera is ready to accept another trigger.\n        Other factors such as the communication speed between the camera and the host computer can affect the maximum\n        trigger rate.\n\n        IMPORTANT: Currently, only scientific CCD cameras support this parameter.\n        This property is Read-Only.\n\n        :type: int\n        \"\"\"\n        try:\n            frame_time_us = c_int()\n            error_code = self._sdk.tl_camera_get_frame_time(self._camera, frame_time_us)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_get_frame_time\", error_code))\n            return int(frame_time_us.value)\n        except Exception as exception:\n            _logger.error(\"Could not get frame time; \" + str(exception))\n            raise exception\n\n    @property\n    def trigger_polarity(self):\n        \"\"\"\n        When the :attr:`operation_mode<thorlabs_tsi_sdk.tl_camera.TLCamera.operation_mode>` is set to HARDWARE_TRIGGERED or BULB and then\n        :meth:`arm()<thorlabs_tsi_sdk.tl_camera.TLCamera.arm>` is called, the camera will respond to a trigger input as a signal to begin\n        exposure. Setting trigger polarity tells the camera to begin exposure on either the rising edge or falling\n        edge of the trigger signal.\n\n        :type: :class:`TRIGGER_POLARITY<thorlabs_tsi_sdk.tl_camera_enums.TRIGGER_POLARITY>`\n        \"\"\"\n        try:\n            trigger_polarity = c_int()\n            error_code = self._sdk.tl_camera_get_trigger_polarity(self._camera, trigger_polarity)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_get_trigger_polarity\", error_code))\n            return TRIGGER_POLARITY(int(trigger_polarity.value))\n        except Exception as exception:\n            _logger.error(\"Could not get trigger polarity; \" + str(exception))\n            raise exception\n\n    @trigger_polarity.setter\n    def trigger_polarity(self, trigger_polarity_enum):\n        try:\n            c_value = c_int(int(trigger_polarity_enum))\n            error_code = self._sdk.tl_camera_set_trigger_polarity(self._camera, c_value)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_set_trigger_polarity\", error_code))\n        except Exception as exception:\n            _logger.error(\"Could not set trigger polarity; \" + str(exception))\n            raise exception\n\n    @property\n    def binx(self):\n        \"\"\"\n        The current horizontal binning value.\n\n        :type: int\n        \"\"\"\n        try:\n            binx = c_int()\n            error_code = self._sdk.tl_camera_get_binx(self._camera, binx)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_get_binx\", error_code))\n            return int(binx.value)\n        except Exception as exception:\n            _logger.error(\"Could not get bin x; \" + str(exception))\n            raise exception\n\n    @binx.setter\n    def binx(self, binx):\n        try:\n            c_value = c_int(binx)\n            error_code = self._sdk.tl_camera_set_binx(self._camera, c_value)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_set_binx\", error_code))\n        except Exception as exception:\n            _logger.error(\"Could not set bin x; \" + str(exception))\n            raise exception\n\n    @property\n    def sensor_readout_time_ns(self):\n        \"\"\"\n        The time, in nanoseconds (ns), that readout data from image sensor. This property is Read-Only.\n\n        :type: int\n        \"\"\"\n        try:\n            sensor_readout_time_ns = c_int()\n            error_code = self._sdk.tl_camera_get_sensor_readout_time(self._camera, sensor_readout_time_ns)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_get_sensor_readout_time\",\n                                                              error_code))\n            return int(sensor_readout_time_ns.value)\n        except Exception as exception:\n            _logger.error(\"Could not get sensor readout time; \" + str(exception))\n            raise exception\n\n    @property\n    def binx_range(self):\n        \"\"\"\n        The binning ratio in the X direction can be determined with this property. By default, binning is set to one in\n        both X and Y directions.\n        This property is Read-Only. To set binx, see :attr:`binx<thorlabs_tsi_sdk.tl_camera.TLCamera.binx>`.\n\n        :type: Range\n        \"\"\"\n        try:\n            hbin_min = c_int()\n            hbin_max = c_int()\n            error_code = self._sdk.tl_camera_get_binx_range(self._camera, hbin_min, hbin_max)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_get_binx_range\", error_code))\n            return Range(int(hbin_min.value), int(hbin_max.value))\n        except Exception as exception:\n            _logger.error(\"Could not get bin x range; \" + str(exception))\n            raise exception\n\n    @property\n    def is_hot_pixel_correction_enabled(self):\n        \"\"\"\n        Due to variability in manufacturing, some pixels have inherently higher dark current which manifests as\n        abnormally bright pixels in images, typically visible with longer exposures. Hot-pixel correction identifies\n        hot pixels and then substitutes a calculated value based on the values of neighboring pixels in place of hot\n        pixels.\n        This property enables or disables hot-pixel correction.\n        If the connected camera supports hot-pixel correction, the threshold-range maximum will be greater than zero.\n\n        :type: bool\n        \"\"\"\n        try:\n            is_hot_pixel_correction_enabled = c_int()\n            error_code = self._sdk.tl_camera_get_is_hot_pixel_correction_enabled(self._camera,\n                                                                                 is_hot_pixel_correction_enabled)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk,\n                                                              \"tl_camera_get_is_hot_pixel_correction_enabled\",\n                                                              error_code))\n            return bool(is_hot_pixel_correction_enabled.value)\n        except Exception as exception:\n            _logger.error(\"Could not get is hot pixel correction enabled; \" + str(exception))\n            raise exception\n\n    @is_hot_pixel_correction_enabled.setter\n    def is_hot_pixel_correction_enabled(self, is_hot_pixel_correction_enabled):\n        try:\n            c_value = c_int(is_hot_pixel_correction_enabled)\n            error_code = self._sdk.tl_camera_set_is_hot_pixel_correction_enabled(self._camera, c_value)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk,\n                                                              \"tl_camera_set_is_hot_pixel_correction_enabled\",\n                                                              error_code))\n        except Exception as exception:\n            _logger.error(\"Could not set is hot pixel correction enabled; \" + str(exception))\n            raise exception\n\n    @property\n    def hot_pixel_correction_threshold(self):\n        \"\"\"\n        Due to variability in manufacturing, some pixels have inherently higher dark current which manifests as\n        abnormally bright pixels in images, typically visible with longer exposures. Hot-pixel correction identifies\n        hot pixels and then substitutes a calculated value based on the values of neighboring pixels in place of hot\n        pixels.\n        This property may be used to get or set the hot-pixel correction threshold within the available range.\n        To determine the available range, query the\n        :attr:`hot_pixel_correction_threshold_range<thorlabs_tsi_sdk.tl_camera.TLCamera.hot_pixel_correction_threshold_range>` property.\n        If the threshold range maximum is zero, the connected camera does not support hot-pixel correction.\n        To enable hot-pixel correction, use\n        :attr:`is_hot_pixel_correction_enabled<thorlabs_tsi_sdk.tl_camera.TLCamera.is_hot_pixel_correction_enabled>`.\n\n        :type: int\n        \"\"\"\n        try:\n            hot_pixel_correction_threshold = c_int()\n            error_code = self._sdk.tl_camera_get_hot_pixel_correction_threshold(self._camera,\n                                                                                hot_pixel_correction_threshold)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_get_hot_pixel_correction_threshold\",\n                                                              error_code))\n            return int(hot_pixel_correction_threshold.value)\n        except Exception as exception:\n            _logger.error(\"Could not get hot pixel correction threshold; \" + str(exception))\n            raise exception\n\n    @hot_pixel_correction_threshold.setter\n    def hot_pixel_correction_threshold(self, hot_pixel_correction_threshold):\n        try:\n            c_value = c_int(hot_pixel_correction_threshold)\n            error_code = self._sdk.tl_camera_set_hot_pixel_correction_threshold(self._camera, c_value)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_set_hot_pixel_correction_threshold\",\n                                                              error_code))\n        except Exception as exception:\n            _logger.error(\"Could not set hot pixel correction threshold; \" + str(exception))\n            raise exception\n\n    @property\n    def hot_pixel_correction_threshold_range(self):\n        \"\"\"\n        The range of acceptable hot pixel correction threshold values. If the maximum value is zero, that is an\n        indication that hot pixel correction is not supported by the camera. This property is Read-Only.\n\n        :type: Range\n        \"\"\"\n        try:\n            hot_pixel_correction_threshold_min = c_int()\n            hot_pixel_correction_threshold_max = c_int()\n            error_code = self._sdk.tl_camera_get_hot_pixel_correction_threshold_range(\n                self._camera,\n                hot_pixel_correction_threshold_min,\n                hot_pixel_correction_threshold_max)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk,\n                                                              \"tl_camera_get_hot_pixel_correction_threshold_range\",\n                                                              error_code))\n            return Range(int(hot_pixel_correction_threshold_min.value), int(hot_pixel_correction_threshold_max.value))\n        except Exception as exception:\n            _logger.error(\"Could not get hot pixel correction threshold range; \" + str(exception))\n            raise exception\n\n    @property\n    def sensor_width_pixels(self):\n        \"\"\"\n        This property provides the physical width of the camera sensor in pixels. This is equivalent to the\n        ROI-height-range maximum value. This property is Read-Only.\n\n        :type: int\n        \"\"\"\n        try:\n            sensor_width_pixels = c_int()\n            error_code = self._sdk.tl_camera_get_sensor_width(self._camera, sensor_width_pixels)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_get_sensor_width\", error_code))\n            return int(sensor_width_pixels.value)\n        except Exception as exception:\n            _logger.error(\"Could not get sensor width; \" + str(exception))\n            raise exception\n\n    @property\n    def gain_range(self):\n        \"\"\"\n        The range of possible gain values. This property is Read-Only.\n\n        :type: Range\n        \"\"\"\n        try:\n            gain_min = c_int()\n            gain_max = c_int()\n            error_code = self._sdk.tl_camera_get_gain_range(self._camera, gain_min, gain_max)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_get_gain_range\", error_code))\n            return Range(int(gain_min.value), int(gain_max.value))\n        except Exception as exception:\n            _logger.error(\"Could not get gain range; \" + str(exception))\n            raise exception\n\n    @property\n    def image_width_range_pixels(self):\n        \"\"\"\n        The range of possible image width values. This property is Read-Only.\n\n        :type: Range\n        \"\"\"\n        try:\n            image_width_pixels_min = c_int()\n            image_width_pixels_max = c_int()\n            error_code = self._sdk.tl_camera_get_image_width_range(self._camera,\n                                                                   image_width_pixels_min,\n                                                                   image_width_pixels_max)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_get_image_width_range\", error_code))\n            return Range(int(image_width_pixels_min.value), int(image_width_pixels_max.value))\n        except Exception as exception:\n            _logger.error(\"Could not get image width range; \" + str(exception))\n            raise exception\n\n    @property\n    def sensor_height_pixels(self):\n        \"\"\"\n        This property provides the physical height of the camera sensor in pixels. It is equivalent to the\n        ROI-width-range-maximum value. This property is Read-Only.\n\n        :type: int\n        \"\"\"\n        try:\n            sensor_height_pixels = c_int()\n            error_code = self._sdk.tl_camera_get_sensor_height(self._camera, sensor_height_pixels)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_get_sensor_height\", error_code))\n            return int(sensor_height_pixels.value)\n        except Exception as exception:\n            _logger.error(\"Could not get sensor height; \" + str(exception))\n            raise exception\n\n    @property\n    def image_height_range_pixels(self):\n        \"\"\"\n        The range of possible image height values. This property is Read-Only.\n\n        :type: Range\n        \"\"\"\n        try:\n            image_height_pixels_min = c_int()\n            image_height_pixels_max = c_int()\n            error_code = self._sdk.tl_camera_get_image_height_range(self._camera,\n                                                                    image_height_pixels_min,\n                                                                    image_height_pixels_max)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_get_image_height_range\",\n                                                              error_code))\n            return Range(int(image_height_pixels_min.value), int(image_height_pixels_max.value))\n        except Exception as exception:\n            _logger.error(\"Could not get image height range; \" + str(exception))\n            raise exception\n\n    @property\n    def model(self):\n        \"\"\"\n        Gets the camera model number such as 1501M or 8051C. This property is Read-Only.\n\n        :type: str\n        \"\"\"\n        try:\n            model = create_string_buffer(_STRING_MAX)\n            error_code = self._sdk.tl_camera_get_model(self._camera, model, c_int(_STRING_MAX))\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_get_model\", error_code))\n            return str(model.value.decode(\"utf-8\"))\n        except Exception as exception:\n            _logger.error(\"Could not get camera model; \" + str(exception))\n            raise exception\n\n    @property\n    def name(self):\n        \"\"\"\n        Cameras can always be distinguished from each other by their serial numbers and/or model. A camera can also be\n        named to distinguish between them. For example, if using a two-camera system, cameras may be named \"Left\" and\n        \"Right.\"\n\n        :type: str\n        \"\"\"\n        try:\n            name = create_string_buffer(_STRING_MAX)\n            error_code = self._sdk.tl_camera_get_name(self._camera, name, c_int(_STRING_MAX))\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_get_name\", error_code))\n            return str(name.value.decode(\"utf-8\"))\n        except Exception as exception:\n            _logger.error(\"Could not get camera name; \" + str(exception))\n            raise exception\n\n    @name.setter\n    def name(self, name):\n        try:\n            c_value = create_string_buffer(str(name).encode('utf-8') + b'\\0', len(name) + 1)\n            error_code = self._sdk.tl_camera_set_name(self._camera, c_value)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_set_name\", error_code))\n        except Exception as exception:\n            _logger.error(\"Could not set camera name; \" + str(exception))\n            raise exception\n\n    @property\n    def name_string_length_range(self):\n        \"\"\"\n        The minimum and maximum string lengths allowed for setting the camera's name.\n\n        :type: Range\n        \"\"\"\n        try:\n            name_string_length_min = c_int()\n            name_string_length_max = c_int()\n            error_code = self._sdk.tl_camera_get_name_string_length_range(self._camera,\n                                                                          name_string_length_min,\n                                                                          name_string_length_max)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_get_name_string_length_range\",\n                                                              error_code))\n            return Range(int(name_string_length_min.value), int(name_string_length_max.value))\n        except Exception as exception:\n            _logger.error(\"Could not get name string length range; \" + str(exception))\n            raise exception\n\n    @property\n    def frames_per_trigger_zero_for_unlimited(self):\n        \"\"\"\n        The number of frames generated per software or hardware trigger can be unlimited or finite.\n        If set to zero, the camera will self-trigger indefinitely, allowing a continuous video feed.\n        If set to one or higher, a single software or hardware trigger will generate only the prescribed number of\n        frames and then stop.\n\n        :type: int\n        \"\"\"\n        try:\n            number_of_frames_per_trigger_or_zero_for_unlimited = c_uint()\n            error_code = self._sdk.tl_camera_get_frames_per_trigger_zero_for_unlimited(\n                self._camera, number_of_frames_per_trigger_or_zero_for_unlimited)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk,\n                                                              \"tl_camera_get_frames_per_trigger_zero_for_unlimited\",\n                                                              error_code))\n            return int(number_of_frames_per_trigger_or_zero_for_unlimited.value)\n        except Exception as exception:\n            _logger.error(\"Could not get frames per trigger; \" + str(exception))\n            raise exception\n\n    @frames_per_trigger_zero_for_unlimited.setter\n    def frames_per_trigger_zero_for_unlimited(self, number_of_frames_per_trigger_zero_for_unlimited):\n        try:\n            c_value = c_uint(number_of_frames_per_trigger_zero_for_unlimited)\n            error_code = self._sdk.tl_camera_set_frames_per_trigger_zero_for_unlimited(self._camera, c_value)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk,\n                                                              \"tl_camera_set_frames_per_trigger_zero_for_unlimited\",\n                                                              error_code))\n        except Exception as exception:\n            _logger.error(\"Could not set number of frames per trigger; \" + str(exception))\n            raise exception\n\n    @property\n    def frames_per_trigger_range(self):\n        \"\"\"\n        The number of frames generated per software or hardware trigger can be unlimited or finite.\n        If set to zero, the camera will self-trigger indefinitely, allowing a continuous video feed.\n        If set to one or higher, a single software or hardware trigger will generate only the prescribed number of\n        frames and then stop.\n        This property returns the valid range for\n        :attr:`frames_per_trigger_zero_for_unlimited<thorlabs_tsi_sdk.tl_camera.TLCamera.frames_per_trigger_zero_for_unlimited>`.\n        This property is Read-Only.\n\n        :type: Range\n        \"\"\"\n        try:\n            number_of_frames_per_trigger_min = c_uint()\n            number_of_frames_per_trigger_max = c_uint()\n            error_code = self._sdk.tl_camera_get_frames_per_trigger_range(self._camera,\n                                                                          number_of_frames_per_trigger_min,\n                                                                          number_of_frames_per_trigger_max)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_get_frames_per_trigger_range\",\n                                                              error_code))\n            return Range(int(number_of_frames_per_trigger_min.value), int(number_of_frames_per_trigger_max.value))\n        except Exception as exception:\n            _logger.error(\"Could not get frames per trigger range; \" + str(exception))\n            raise exception\n\n    #    @property\n    #    def calculated_frame_rate_fps(self):\n    #        try:\n    #            calculated_frames_per_second = c_double()\n    #            error_code = self._sdk.tl_camera_get_calculated_frame_rate(self._camera, calculated_frames_per_second)\n    #            if error_code != 0:\n    #                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_\", error_code))\n    #            return float(calculated_frames_per_second.value)\n    #        except Exception as exception:\n    #            _logger.error(\"Could not get calculated frame rate; \" + str(exception))\n\n    @property\n    def usb_port_type(self):\n        \"\"\"\n        The :class:`USB_PORT_TYPE<thorlabs_tsi_sdk.tl_camera_enums.USB_PORT_TYPE>` enumeration defines the values the SDK uses for specifying the USB\n        port type.\n        These values are returned by SDK API functions and callbacks based on the type of physical USB port that the\n        device is connected to.\n        This property is Read-Only.\n\n        :type: :class:`USB_PORT_TYPE<thorlabs_tsi_sdk.tl_camera_enums.USB_PORT_TYPE>`\n        \"\"\"\n        try:\n            usb_port_type = c_int()\n            error_code = self._sdk.tl_camera_get_usb_port_type(self._camera, usb_port_type)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_get_usb_port_type\", error_code))\n            return USB_PORT_TYPE(usb_port_type.value)\n        except Exception as exception:\n            _logger.error(\"Could not get usb port type; \" + str(exception))\n            raise exception\n\n    @property\n    def communication_interface(self):\n        \"\"\"\n        This property describes the computer interface type, such as USB, GigE, or CameraLink. This property is\n        Read-Only.\n\n        :type: :class:`COMMUNICATION_INTERFACE<thorlabs_tsi_sdk.tl_camera_enums.COMMUNICATION_INTERFACE>`\n        \"\"\"\n        try:\n            communication_interface = c_int()\n            error_code = self._sdk.tl_camera_get_communication_interface(self._camera, communication_interface)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_get_communication_interface\",\n                                                              error_code))\n            return COMMUNICATION_INTERFACE(communication_interface.value)\n        except Exception as exception:\n            _logger.error(\"Could not get communication interface; \" + str(exception))\n            raise exception\n\n    @property\n    def operation_mode(self):\n        \"\"\"\n        Thorlabs scientific cameras can be software- or hardware-triggered.\n        To run continuous-video mode, set\n        :attr:`frames_per_trigger_zero_for_unlimited<thorlabs_tsi_sdk.tl_camera.TLCamera.frames_per_trigger_zero_for_unlimited>` to zero and\n        :attr:`operation_mode<thorlabs_tsi_sdk.tl_camera.TLCamera.operation_mode>` to SOFTWARE_TRIGGERED.\n        To issue individual software triggers, set\n        :attr:`frames_per_trigger_zero_for_unlimited<thorlabs_tsi_sdk.tl_camera.TLCamera.frames_per_trigger_zero_for_unlimited>` to a number\n        greater than zero and :attr:`operation_mode<thorlabs_tsi_sdk.tl_camera.TLCamera.operation_mode>` to SOFTWARE_TRIGGERED.\n        To trigger frames using the hardware trigger input, set :attr:`operation_mode<thorlabs_tsi_sdk.tl_camera.TLCamera.operation_mode>` mode\n        to HARDWARE_TRIGGERED. In this mode, the :attr:`exposure_time_us<thorlabs_tsi_sdk.tl_camera.TLCamera.exposure_time_us>` property is\n        used to determine the length of the exposure.\n        To trigger frames using the hardware trigger input and to determine the exposure length with that signal, set\n        :attr:`operation_mode<thorlabs_tsi_sdk.tl_camera.TLCamera.operation_mode>` to BULB.\n\n        :type: :class:`OPERATION_MODE<thorlabs_tsi_sdk.tl_camera_enums.OPERATION_MODE>`\n        \"\"\"\n        try:\n            operation_mode = c_int()\n            error_code = self._sdk.tl_camera_get_operation_mode(self._camera, operation_mode)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_get_operation_mode\", error_code))\n            return OPERATION_MODE(operation_mode.value)\n        except Exception as exception:\n            _logger.error(\"Could not get operation mode; \" + str(exception))\n            raise exception\n\n    @operation_mode.setter\n    def operation_mode(self, operation_mode):\n        try:\n            c_value = c_int(operation_mode)\n            error_code = self._sdk.tl_camera_set_operation_mode(self._camera, c_value)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_set_operation_mode\", error_code))\n        except Exception as exception:\n            _logger.error(\"Could not set operation mode; \" + str(exception))\n            raise exception\n\n    @property\n    def is_armed(self):\n        \"\"\"\n        Prior to issuing software or hardware triggers to get images from a camera, call :meth:`arm()<thorlabs_tsi_sdk.tl_camera.TLCamera.arm>`\n        to prepare it for imaging. This property indicates whether :meth:`arm()<thorlabs_tsi_sdk.tl_camera.TLCamera.arm>` has been called.\n        This property is Read-Only.\n\n        :type: bool\n        \"\"\"\n        try:\n            is_armed = c_bool()\n            error_code = self._sdk.tl_camera_get_is_armed(self._camera, is_armed)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_get_is_armed\", error_code))\n            return bool(is_armed.value)\n        except Exception as exception:\n            _logger.error(\"Could not get is armed; \" + str(exception))\n            raise exception\n\n    @property\n    def is_eep_supported(self):\n        \"\"\"\n        Equal Exposure Pulse (EEP) mode is an LVTTL-level signal that is active between the time when all rows have\n        been reset during rolling reset, and the end of the exposure time (and the beginning of rolling readout). The\n        signal can be used to control an external light source that will be triggered on only during the equal exposure\n        period, providing the same amount of exposure for all pixels in the ROI.\n\n        This property determines whether the connected camera supports EEP mode. This property is Read-Only. To\n        activate EEP mode, see :attr:`is_eep_enabled<thorlabs_tsi_sdk.tl_camera.TLCamera.is_eep_enabled>`\n\n        :type: bool\n        \"\"\"\n        try:\n            is_eep_supported = c_bool()\n            error_code = self._sdk.tl_camera_get_is_eep_supported(self._camera, is_eep_supported)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_get_is_eep_supported\", error_code))\n            return bool(is_eep_supported.value)\n        except Exception as exception:\n            _logger.error(\"Could not get is eep supported; \" + str(exception))\n            raise exception\n\n    @property\n    def is_led_supported(self):\n        \"\"\"\n        Some scientific cameras include an LED indicator light on the back panel.\n        This property is Read-Only. Use :attr:`is_led_supported<thorlabs_tsi_sdk.tl_camera.TLCamera.is_led_supported>` to determine whether the\n        connected camera has an LED indicator.\n\n        :type: bool\n        \"\"\"\n        try:\n            is_led_supported = c_bool()\n            error_code = self._sdk.tl_camera_get_is_led_supported(self._camera, is_led_supported)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_is_led_supported\", error_code))\n            return bool(is_led_supported.value)\n        except Exception as exception:\n            _logger.error(\"Could not get is led supported; \" + str(exception))\n            raise exception\n\n    @property\n    def is_cooling_supported(self):\n        \"\"\"\n        All Thorlabs scientific cameras are designed to efficiently dissipate heat. Some models additionally provide\n        active cooling. Use this property to determine whether the connected camera supports active cooling.\n\n        This property is Read-Only.\n\n        :type: bool\n        \"\"\"\n        try:\n            is_cooling_supported = c_bool()\n            error_code = self._sdk.tl_camera_get_is_cooling_supported(self._camera, is_cooling_supported)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_get_is_cooling_supported\",\n                                                              error_code))\n            return bool(is_cooling_supported.value)\n        except Exception as exception:\n            _logger.error(\"Could not get is cooling supported; \" + str(exception))\n            raise exception\n\n    @property\n    def is_cooling_enabled(self):\n        \"\"\"\n        All Thorlabs scientific cameras are designed to efficiently dissipate heat. Some models additionally provide\n        active cooling via a Thermoelectric Cooler (TEC). Cameras with TECs have an additional power cable to power the\n        cooler. When the cable is plugged in, the TEC will start cooling. When the cable is unplugged, the TEC will stop\n        and the camera will not have active cooling. Use this property to determine via software whether the TEC cable\n        is plugged in or not.\n\n        This property is Read-Only.\n\n        :type: bool\n        \"\"\"\n        try:\n            is_cooling_enabled = c_bool()\n            error_code = self._sdk.tl_camera_get_cooling_enable(self._camera, is_cooling_enabled)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_get_cooling_enable\",\n                                                              error_code))\n            return bool(is_cooling_enabled.value)\n        except Exception as exception:\n            _logger.error(\"Could not get cooling enable; \" + str(exception))\n            raise exception\n\n    @property\n    def is_nir_boost_supported(self):\n        \"\"\"\n        Some scientific-CCD camera models offer an enhanced near-infrared imaging mode for wavelengths in the 500 to\n        1000nm range. The Thorlabs website includes a helpful overview of this camera function on the Camera Basics\n        page: https://www.thorlabs.com/newgrouppage9.cfm?objectgroup_id=8962\n\n        This property enables or disables NIR-boost mode. This property is Read-Only.\n\n        :type: bool\n        \"\"\"\n        try:\n            is_nir_boost_supported = c_bool()\n            error_code = self._sdk.tl_camera_get_is_nir_boost_supported(self._camera, is_nir_boost_supported)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_is_nir_boost_supported\",\n                                                              error_code))\n            return bool(is_nir_boost_supported.value)\n        except Exception as exception:\n            _logger.error(\"Could not get is nir boost supported; \" + str(exception))\n            raise exception\n\n    @property\n    def camera_sensor_type(self):\n        \"\"\"\n        The camera sensor type. This property is Read-Only.\n\n        :type: :class:`SENSOR_TYPE<thorlabs_tsi_sdk.tl_camera_enums.SENSOR_TYPE>`\n        \"\"\"\n        try:\n            camera_sensor_type = c_int()\n            error_code = self._sdk.tl_camera_get_camera_sensor_type(self._camera, camera_sensor_type)\n            if error_code != 0:\n                raise TLCameraError(\n                    _create_c_failure_message(self._sdk, \"tl_camera_get_camera_sensor_type\", error_code))\n            return SENSOR_TYPE(camera_sensor_type.value)\n        except Exception as exception:\n            _logger.error(\"Could not get camera sensor type; \" + str(exception))\n            raise exception\n\n    @property\n    def color_filter_array_phase(self):\n        \"\"\"\n        This describes the :class:`color filter array phase<thorlabs_tsi_sdk.tl_color_enums.FILTER_ARRAY_PHASE>` for the camera.\n        This property is Read-Only.\n\n        :type: :class:`FILTER_ARRAY_PHASE<thorlabs_tsi_sdk.tl_color_enums.FILTER_ARRAY_PHASE>`\n        \"\"\"\n        try:\n            color_filter_array_phase = c_int()\n            error_code = self._sdk.tl_camera_get_color_filter_array_phase(self._camera, color_filter_array_phase)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_get_color_filter_array_phase\",\n                                                              error_code))\n            return FILTER_ARRAY_PHASE(color_filter_array_phase.value)\n        except Exception as exception:\n            _logger.error(\"Could not get color filter array phase; \" + str(exception))\n            raise exception\n\n    @property\n    def camera_color_correction_matrix_output_color_space(self):\n        \"\"\"\n        This describes the camera color correction matrix output color space. This property is Read-Only.\n\n        :type: str\n        \"\"\"\n        try:\n            color_correction_matrix_output_color_space = create_string_buffer(_STRING_MAX)\n            error_code = self._sdk.tl_camera_get_camera_color_correction_matrix_output_color_space(\n                self._camera,\n                color_correction_matrix_output_color_space)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(\n                    self._sdk, \"tl_camera_get_camera_color_correction_matrix_output_color_space\", error_code))\n            return str(color_correction_matrix_output_color_space.value.decode('utf-8'))\n        except Exception as exception:\n            _logger.error(\"Could not get camera color correction matrix output color space; \" + str(exception))\n            raise exception\n\n    @property\n    def data_rate(self):\n        \"\"\"\n        This property sets or gets the sensor-level data rate. Scientific-CCD cameras offer data rates of 20MHz or\n        40MHz. Compact-scientific cameras offer FPS30 or FPS50, which are frame rates supported by the camera when\n        doing full-frame readout. The actual rate can vary if a region of interest (ROI) or binning is set or if the\n        host computer cannot keep up with the camera.\n        To test whether the connected camera supports a particular data rate, use\n        :meth:`get_is_data_rate_supported<thorlabs_tsi_camera.tl_camera.TLCamera.get_is_data_rate_supported>`.\n\n        :type: :class:`DATA_RATE<thorlabs_tsi_sdk.tl_camera_enums.DATA_RATE>`\n        \"\"\"\n        try:\n            data_rate = c_int()\n            error_code = self._sdk.tl_camera_get_data_rate(self._camera, data_rate)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_get_data_rate\", error_code))\n            return DATA_RATE(data_rate.value)\n        except Exception as exception:\n            _logger.error(\"Could not get data rate; \" + str(exception))\n            raise exception\n\n    @data_rate.setter\n    def data_rate(self, data_rate):\n        try:\n            c_value = c_int(data_rate)\n            error_code = self._sdk.tl_camera_set_data_rate(self._camera, c_value)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_set_data_rate\", error_code))\n        except Exception as exception:\n            _logger.error(\"Could not set data rate; \" + str(exception))\n            raise exception\n\n    @property\n    def sensor_pixel_size_bytes(self):\n        \"\"\"\n        The pixel size of the camera's sensor in bytes. This represents the amount of space 1 pixel will occupy in the\n        frame buffer. This property is Read-Only.\n\n        :type: int\n        \"\"\"\n        try:\n            sensor_pixel_size_bytes = c_int()\n            error_code = self._sdk.tl_camera_get_sensor_pixel_size_bytes(self._camera, sensor_pixel_size_bytes)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_get_sensor_pixel_size_bytes\",\n                                                              error_code))\n            return int(sensor_pixel_size_bytes.value)\n        except Exception as exception:\n            _logger.error(\"Could not get sensor pixel size bytes; \" + str(exception))\n            raise exception\n\n    @property\n    def sensor_pixel_width_um(self):\n        \"\"\"\n        This property provides the physical width of a single light-sensitive photo site on the sensor. This property is\n        Read-Only.\n\n        :type: float\n        \"\"\"\n        try:\n            sensor_pixel_width_um = c_double()\n            error_code = self._sdk.tl_camera_get_sensor_pixel_width(self._camera, sensor_pixel_width_um)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_get_sensor_pixel_width\",\n                                                              error_code))\n            return float(sensor_pixel_width_um.value)\n        except Exception as exception:\n            _logger.error(\"Could not get sensor pixel width; \" + str(exception))\n            raise exception\n\n    @property\n    def sensor_pixel_height_um(self):\n        \"\"\"\n        This property provides the physical height of a single light-sensitive photo site on the sensor. This property\n        is Read-Only.\n\n        :type: float\n        \"\"\"\n        try:\n            sensor_pixel_height_um = c_double()\n            error_code = self._sdk.tl_camera_get_sensor_pixel_height(self._camera, sensor_pixel_height_um)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_get_sensor_pixel_height\",\n                                                              error_code))\n            return float(sensor_pixel_height_um.value)\n        except Exception as exception:\n            _logger.error(\"Could not get sensor pixel height; \" + str(exception))\n            raise exception\n\n    @property\n    def bit_depth(self):\n        \"\"\"\n        The number of bits to which a pixel value is digitized on a camera.\n        In the image data that is delivered to the host application, the bit depth indicates how many of the lower bits\n        of each 16-bit ushort value are relevant.\n        While most cameras operate at a fixed bit depth, some are reduced when data bandwidth limitations would\n        otherwise restrict the frame rate. Please consult the camera manual and specification for details about a\n        specific model.\n\n        :type: int\n        \"\"\"\n        try:\n            pixel_bit_depth = c_int()\n            error_code = self._sdk.tl_camera_get_bit_depth(self._camera, pixel_bit_depth)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_get_bit_depth\", error_code))\n            return int(pixel_bit_depth.value)\n        except Exception as exception:\n            _logger.error(\"Could not get bit depth; \" + str(exception))\n            raise exception\n\n    @property\n    def roi(self):\n        \"\"\"\n        By default, the region of interest (ROI) is the same as the sensor resolution. The region of interest can be\n        reduced to a smaller rectangle in order to focus on an area smaller than a full- frame image. In some cases,\n        reducing the ROI can increase the frame rate since less data needs to be transmitted to the host computer.\n        Binning sums adjacent sensor pixels into \"super pixels\". It trades off spatial resolution for sensitivity and\n        speed. For example, if a sensor is 1920 by 1080 pixels and binning is set to two in the X direction and two in\n        the Y direction, the resulting image will be 960 by 540 pixels. Since smaller images require less data to be\n        transmitted to the host computer, binning may increase the frame rate. By default, binning is set to one in\n        both horizontal and vertical directions. binning can be changed by setting :attr:`binx<thorlabs_tsi_sdk.tl_camera.TLCamera.binx>` or\n        :attr:`biny<thorlabs_tsi_sdk.tl_camera.TLCamera.biny>`. It can be different in the X direction than the Y direction, and the available\n        ranges vary by camera model.\n\n        To determine the available ROI ranges, use the :attr:`roi_range<thorlabs_tsi_sdk.tl_camera.TLCamera.roi_range>`.\n\n        :type: ROI\n        \"\"\"\n        try:\n            upper_left_x_pixels = c_int()\n            upper_left_y_pixels = c_int()\n            lower_right_x_pixels = c_int()\n            lower_right_y_pixels = c_int()\n            error_code = self._sdk.tl_camera_get_roi(self._camera,\n                                                     upper_left_x_pixels, upper_left_y_pixels,\n                                                     lower_right_x_pixels, lower_right_y_pixels)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_get_roi\", error_code))\n            return ROI(int(upper_left_x_pixels.value), int(upper_left_y_pixels.value),\n                       int(lower_right_x_pixels.value), int(lower_right_y_pixels.value))\n        except Exception as exception:\n            _logger.error(\"Could not get ROI; \" + str(exception))\n            raise exception\n\n    @roi.setter\n    def roi(self, roi):\n        try:\n            # noinspection PyUnusedLocal\n            error_code = 0\n            try:\n                upper_left_x_pixels, upper_left_y_pixels, lower_right_x_pixels, lower_right_y_pixels = roi\n                c_value_upper_left_x = c_int(upper_left_x_pixels)\n                c_value_upper_left_y = c_int(upper_left_y_pixels)\n                c_value_lower_right_x = c_int(lower_right_x_pixels)\n                c_value_lower_right_y = c_int(lower_right_y_pixels)\n                error_code = self._sdk.tl_camera_set_roi(self._camera,\n                                                         c_value_upper_left_x, c_value_upper_left_y,\n                                                         c_value_lower_right_x, c_value_lower_right_y)\n            except ValueError as value_error:\n                _logger.error(\"To set ROI use an iterable with 4 integers:\\n\"\n                              \"camera.roi = (upper_left_x_pixels, upper_left_y_pixels, \"\n                              \"lower_right_x_pixels, lower_right_y_pixels)\\n\")\n                raise value_error\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_set_roi\", error_code))\n        except Exception as exception:\n            _logger.error(\"Could not set ROI; \" + str(exception))\n            raise exception\n\n    @property\n    def roi_range(self):\n        \"\"\"\n        The rules for rectangular regions of interest (ROIs) vary by camera model. Please consult the camera\n        documentation for more details. The ROI height range indicates the smallest height to which an ROI can be set\n        up to a maximum of the sensor's vertical resolution. The ROI width range indicates the smallest width to which\n        an ROI can be set up to a maximum of the sensor's horizontal resolution.\n\n        This property is Read-Only. For setting the ROI, see :attr:`roi<thorlabs_tsi_sdk.tl_camera.TLCamera.roi>`.\n\n        :type: ROIRange\n        \"\"\"\n        try:\n            upper_left_x_pixels_min = c_int()\n            upper_left_y_pixels_min = c_int()\n            lower_right_x_pixels_min = c_int()\n            lower_right_y_pixels_min = c_int()\n            upper_left_x_pixels_max = c_int()\n            upper_left_y_pixels_max = c_int()\n            lower_right_x_pixels_max = c_int()\n            lower_right_y_pixels_max = c_int()\n            error_code = self._sdk.tl_camera_get_roi_range(self._camera,\n                                                           upper_left_x_pixels_min, upper_left_y_pixels_min,\n                                                           lower_right_x_pixels_min, lower_right_y_pixels_min,\n                                                           upper_left_x_pixels_max, upper_left_y_pixels_max,\n                                                           lower_right_x_pixels_max, lower_right_y_pixels_max)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_get_roi_range\", error_code))\n            return ROIRange(int(upper_left_x_pixels_min.value), int(upper_left_y_pixels_min.value),\n                            int(lower_right_x_pixels_min.value), int(lower_right_y_pixels_min.value),\n                            int(upper_left_x_pixels_max.value), int(upper_left_y_pixels_max.value),\n                            int(lower_right_x_pixels_max.value), int(lower_right_y_pixels_max.value))\n        except Exception as exception:\n            _logger.error(\"Could not get ROI range; \" + str(exception))\n            raise exception\n\n    @property\n    def serial_number(self):\n        \"\"\"\n        This property gets the unique identifier for a camera. This property is Read-Only.\n\n        :type: str\n        \"\"\"\n        try:\n            serial_number = create_string_buffer(_STRING_MAX)\n            error_code = self._sdk.tl_camera_get_serial_number(self._camera, serial_number, _STRING_MAX)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_get_serial_number\", error_code))\n            return str(serial_number.value.decode('utf-8'))\n        except Exception as exception:\n            _logger.error(\"Could not get serial number; \" + str(exception))\n            raise exception\n\n    @property\n    def serial_number_string_length_range(self):\n        \"\"\"\n        The minimum and maximum number of characters allowed in the serial number string. This property is Read-Only.\n\n        :type: Range\n        \"\"\"\n        try:\n            serial_number_string_length_min = c_int()\n            serial_number_string_length_max = c_int()\n            error_code = self._sdk.tl_camera_get_serial_number_string_length_range(self._camera,\n                                                                                   serial_number_string_length_min,\n                                                                                   serial_number_string_length_max)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(\n                    self._sdk, \"tl_camera_get_serial_number_string_length_range\", error_code))\n            return Range(int(serial_number_string_length_min.value), int(serial_number_string_length_max.value))\n        except Exception as exception:\n            _logger.error(\"Could not get serial number string length range; \" + str(exception))\n            raise exception\n\n    @property\n    def is_led_on(self):\n        \"\"\"\n        Some scientific cameras include an LED indicator light on the back panel. This property can be used to turn it\n        on or off.\n\n        :type: bool\n        \"\"\"\n        try:\n            is_led_on = c_bool()\n            error_code = self._sdk.tl_camera_get_is_led_on(self._camera, is_led_on)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_get_is_led_on\", error_code))\n            return bool(is_led_on.value)\n        except Exception as exception:\n            _logger.error(\"Could not get is led on; \" + str(exception))\n            raise exception\n\n    @is_led_on.setter\n    def is_led_on(self, is_led_on):\n        try:\n            c_value = c_bool(is_led_on)\n            error_code = self._sdk.tl_camera_set_is_led_on(self._camera, c_value)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_set_is_led_on\", error_code))\n        except Exception as exception:\n            _logger.error(\"Could not set is led on; \" + str(exception))\n            raise exception\n\n    @property\n    def eep_status(self):\n        \"\"\"\n        Equal Exposure Pulse (EEP) mode is an LVTTL-level signal that is active during the time when all rows have been\n        reset during rolling reset, and the end of the exposure time (and the beginning of rolling readout). The signal\n        can be used to control an external light source that will be on only during the equal exposure period,\n        providing the same amount of exposure for all pixels in the ROI.\n\n        When EEP mode is disabled, the status will always be EEP_STATUS.OFF.\n        EEP mode can be enabled, but, depending on the exposure value, active or inactive.\n        If EEP is enabled in bulb mode, it will always give a status of BULB.\n\n        This property is Read-Only. To activate EEP mode, see :attr:`is_eep_enabled<thorlabs_tsi_sdk.tl_camera.TLCamera.is_eep_enabled>`\n\n        :type: :class:`EEP_STATUS<thorlabs_tsi_sdk.tl_camera_enums.EEP_STATUS>`\n        \"\"\"\n        try:\n            eep_status_enum = c_int()\n            error_code = self._sdk.tl_camera_get_eep_status(self._camera, eep_status_enum)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_get_eep_status\", error_code))\n            return EEP_STATUS(eep_status_enum.value)\n        except Exception as exception:\n            _logger.error(\"Could not get eep status; \" + str(exception))\n            raise exception\n\n    @property\n    def is_eep_enabled(self):\n        \"\"\"\n        Equal Exposure Pulse (EEP) mode is an LVTTL-level signal that is active between the time when all rows have\n        been reset during rolling reset, and the end of the exposure time (and the beginning of rolling readout). The\n        signal can be used to control an external light source that will be triggered on only during the equal exposure\n        period, providing the same amount of exposure for all pixels in the ROI.\n\n        Please see the camera specification for details on EEP mode.\n\n        When enabled, EEP mode will be active or inactive depending on the exposure duration.\n        Use :attr:`is_eep_supported<thorlabs_tsi_sdk.tl_camera.TLCamera.is_eep_supported>` to test whether the connected camera supports this\n        mode.\n        Use :attr:`eep_status<thorlabs_tsi_sdk.tl_camera.TLCamera.eep_status>` to see whether the mode is active, inactive, in bulb mode, or\n        disabled.\n\n        :type: bool\n        \"\"\"\n        try:\n            eep_status = self.eep_status\n            if eep_status == EEP_STATUS.DISABLED:\n                return False\n            else:\n                return True\n        except Exception as exception:\n            _logger.error(\"Could not get is eep enabled; \" + str(exception))\n            raise exception\n\n    @is_eep_enabled.setter\n    def is_eep_enabled(self, is_eep_enabled):\n        try:\n            c_value = c_int(is_eep_enabled)\n            error_code = self._sdk.tl_camera_set_is_eep_enabled(self._camera, c_value)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_set_is_eep_enabled\", error_code))\n        except Exception as exception:\n            _logger.error(\"Could not set is eep enabled; \" + str(exception))\n            raise exception\n\n    @property\n    def biny(self):\n        \"\"\"\n        The current vertical binning value.\n\n        :type: int\n        \"\"\"\n        try:\n            biny = c_int()\n            error_code = self._sdk.tl_camera_get_biny(self._camera, biny)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_get_biny\", error_code))\n            return int(biny.value)\n        except Exception as exception:\n            _logger.error(\"Could not get bin y; \" + str(exception))\n            raise exception\n\n    @biny.setter\n    def biny(self, biny):\n        try:\n            c_value = c_int(biny)\n            error_code = self._sdk.tl_camera_set_biny(self._camera, c_value)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_set_biny\", error_code))\n        except Exception as exception:\n            _logger.error(\"Could not set bin y; \" + str(exception))\n            raise exception\n\n    @property\n    def biny_range(self):\n        \"\"\"\n        The binning ratio in the Y direction can be determined with this property. By default, binning is set to one in\n        both X and Y directions.\n        This property is Read-Only. To set biny, see :attr:`biny<thorlabs_tsi_sdk.tl_camera.TLCamera.biny>`.\n\n        :type: Range\n        \"\"\"\n        try:\n            biny_min = c_int()\n            biny_max = c_int()\n            error_code = self._sdk.tl_camera_get_biny_range(self._camera, biny_min, biny_max)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_biny_range\", error_code))\n            return Range(int(biny_min.value), int(biny_max.value))\n        except Exception as exception:\n            _logger.error(\"Could not get biny range; \" + str(exception))\n            raise exception\n\n    @property\n    def gain(self):\n        \"\"\"\n        Gain refers to the scaling of pixel values up or down for a given amount of light. This scaling is applied\n        prior to digitization.\n        To determine the valid range of values, use the :attr:`gain_range<thorlabs_tsi_sdk.tl_camera.TLCamera.gain_range>` property.\n        If the :attr:`gain_range<thorlabs_tsi_sdk.tl_camera.TLCamera.gain_range>` maximum is zero, then Gain is not supported for the connected\n        camera.\n        The units of measure for Gain can vary by camera. Please consult the data sheet for the specific camera model.\n        Query the :attr:`gain_range<thorlabs_tsi_sdk.tl_camera.TLCamera.gain_range>` property to determine the possible values.\n\n        :type: int\n        \"\"\"\n        try:\n            gain = c_int()\n            error_code = self._sdk.tl_camera_get_gain(self._camera, gain)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_get_gain\", error_code))\n            return int(gain.value)\n        except Exception as exception:\n            _logger.error(\"Could not get gain; \" + str(exception))\n            raise exception\n\n    @gain.setter\n    def gain(self, gain):\n        try:\n            c_value = c_int(gain)\n            error_code = self._sdk.tl_camera_set_gain(self._camera, c_value)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_set_gain\", error_code))\n        except Exception as exception:\n            _logger.error(\"Could not set gain; \" + str(exception))\n            raise exception\n\n    @property\n    def black_level(self):\n        \"\"\"\n        Black level adds an offset to pixel values. If the connected camera supports black level, the\n        :attr:`black_level_range<thorlabs_tsi_sdk.tl_camera.TLCamera.black_level_range>` will have a maximum greater than zero.\n\n        :type: int\n        \"\"\"\n        try:\n            black_level = c_int()\n            error_code = self._sdk.tl_camera_get_black_level(self._camera, black_level)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_get_black_level\", error_code))\n            return int(black_level.value)\n        except Exception as exception:\n            _logger.error(\"Could not get black level; \" + str(exception))\n            raise exception\n\n    @black_level.setter\n    def black_level(self, black_level):\n        try:\n            c_value = c_int(black_level)\n            error_code = self._sdk.tl_camera_set_black_level(self._camera, c_value)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_set_black_level\", error_code))\n        except Exception as exception:\n            _logger.error(\"Could not set black level; \" + str(exception))\n            raise exception\n\n    @property\n    def black_level_range(self):\n        \"\"\"\n        Black level adds an offset to pixel values. If black level is supported by a camera model, then this property\n        will have an upper range higher than zero.\n\n        black_level_range indicates the available values that can be used for the\n        :attr:`black_level<thorlabs_tsi_sdk.tl_camera.TLCamera.black_level>` property.\n\n        :type: Range\n        \"\"\"\n        try:\n            black_level_min = c_int()\n            black_level_max = c_int()\n            error_code = self._sdk.tl_camera_get_black_level_range(self._camera, black_level_min, black_level_max)\n            if error_code == 1002:\n                # Native library issue #\n                _logger.debug(\"Camera does not support black level range\")\n                return Range(0, 0)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_get_black_level_range\", error_code))\n            return Range(int(black_level_min.value), int(black_level_max.value))\n        except Exception as exception:\n            _logger.error(\"Could not get black level range; \" + str(exception))\n            raise exception\n\n    @property\n    def image_width_pixels(self):\n        \"\"\"\n        This property provides the image width in pixels. It is related to ROI width. This property is Read-Only.\n\n        :type: int\n        \"\"\"\n        try:\n            image_width_pixels = c_int()\n            error_code = self._sdk.tl_camera_get_image_width(self._camera, image_width_pixels)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_get_image_width\", error_code))\n            return int(image_width_pixels.value)\n        except Exception as exception:\n            _logger.error(\"Could not get image width; \" + str(exception))\n            raise exception\n\n    @property\n    def image_height_pixels(self):\n        \"\"\"\n        This property provides the image height in pixels. It is related to ROI height. This property is Read-Only.\n\n        :type: int\n        \"\"\"\n        try:\n            image_height_pixels = c_int()\n            error_code = self._sdk.tl_camera_get_image_height(self._camera, image_height_pixels)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_image_height_pixels\", error_code))\n            return int(image_height_pixels.value)\n        except Exception as exception:\n            _logger.error(\"Could not get image height; \" + str(exception))\n            raise exception\n\n    @property\n    def polar_phase(self):\n        \"\"\"\n        This describes how the polarization filter is aligned over the camera sensor. This property is only supported\n        in polarized cameras. In a polarized camera, each pixel is covered with one of four linear polarizers with\n        orientations of -45\u00b0, 0\u00b0, 45\u00b0, or 90\u00b0. The polar phase represents the origin pixel on the sensor. To determine\n        if a camera supports polarization, check the :attr:`camera_sensor_type<thorlabs_tsi_sdk.tl_camera.TLCamera.camera_sensor_type>`\n        property. This property is Read-Only.\n\n        :type: :class:`POLAR_PHASE<thorlabs_tsi_sdk.tl_polarization_enums.POLAR_PHASE>`\n        \"\"\"\n        try:\n            polar_phase_type = c_int()\n            error_code = self._sdk.tl_camera_get_polar_phase(self._camera, polar_phase_type)\n            if error_code != 0:\n                raise TLCameraError(\n                    _create_c_failure_message(self._sdk, \"tl_camera_get_polar_phase\", error_code))\n            return POLAR_PHASE(polar_phase_type.value)\n        except Exception as exception:\n            _logger.error(\"Could not get polar phase; \" + str(exception))\n            raise exception\n\n    @property\n    def frame_rate_control_value_range(self):\n        \"\"\"\n        Frame rate control will set the frames per second of the camera. If frame rate is supported by a camera model,\n        then this property will have an upper range higher than zero.\n\n        frame_rate_control_value_range indicates the available values that can be used for the\n        :attr:`frame_rate_control_value<thorlabs_tsi_sdk.tl_camera.TLCamera.frame_rate_control_value>` property.\n\n        :type: Range\n        \"\"\"\n        try:\n            frame_rate_control_min = c_double()\n            frame_rate_control_max = c_double()\n            error_code = self._sdk.tl_camera_get_frame_rate_control_value_range(self._camera, frame_rate_control_min, frame_rate_control_max)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_get_frame_rate_control_value_range\", error_code))\n            return Range(float(frame_rate_control_min.value), float(frame_rate_control_max.value))\n        except Exception as exception:\n            _logger.error(\"Could not get frame rate control value range; \" + str(exception))\n            raise exception\n\n    @property\n    def is_frame_rate_control_enabled(self):\n        \"\"\"\n        While frame rate control is enabled, the frames per second will be controlled by\n        :attr:`frame_rate_control_value<thorlabs_tsi_sdk.tl_camera.TLCamera.frame_rate_control_value>`.\n\n        The frame rate control adjusts the frame rate of the camera independent of exposure time, within certain\n        constraints. For short exposure times, the maximum frame rate is limited by the readout time of the sensor.\n        For long exposure times, the frame rate is limited by the exposure time.\n\n        This property enables or disables the frame rate control feature.\n        If the connected camera supports frame rate control, the threshold-range maximum will be greater than zero.\n\n        :type: bool\n        \"\"\"\n        try:\n            is_frame_rate_control_enabled = c_int()\n            error_code = self._sdk.tl_camera_get_is_frame_rate_control_enabled(self._camera,\n                                                                               is_frame_rate_control_enabled)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk,\n                                                              \"tl_camera_get_is_frame_rate_control_enabled\",\n                                                              error_code))\n            return bool(is_frame_rate_control_enabled.value)\n        except Exception as exception:\n            _logger.error(\"Could not get is frame rate control enabled; \" + str(exception))\n            raise exception\n\n    @is_frame_rate_control_enabled.setter\n    def is_frame_rate_control_enabled(self, is_frame_rate_control_enabled):\n        try:\n            c_value = c_int(is_frame_rate_control_enabled)\n            error_code = self._sdk.tl_camera_set_is_frame_rate_control_enabled(self._camera, c_value)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk,\n                                                              \"tl_camera_set_is_frame_rate_control_enabled\",\n                                                              error_code))\n        except Exception as exception:\n            _logger.error(\"Could not set is frame rate control enabled; \" + str(exception))\n            raise exception\n\n    @property\n    def frame_rate_control_value(self):\n        \"\"\"\n        The frame rate control adjusts the frame rate of the camera independent of exposure time, within certain\n        constraints. For short exposure times, the maximum frame rate is limited by the readout time of the sensor.\n        For long exposure times, the frame rate is limited by the exposure time.\n\n        :type: float\n        \"\"\"\n        try:\n            frame_rate_control = c_double()\n            error_code = self._sdk.tl_camera_get_frame_rate_control_value(self._camera, frame_rate_control)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_get_frame_rate_control_value\",\n                                                              error_code))\n            return float(frame_rate_control.value)\n        except Exception as exception:\n            _logger.error(\"Could not get frame rate control; \" + str(exception))\n            raise exception\n\n    @frame_rate_control_value.setter\n    def frame_rate_control_value(self, frame_rate_control_value_fps):\n        try:\n            c_value = c_double(frame_rate_control_value_fps)\n            error_code = self._sdk.tl_camera_set_frame_rate_control_value(self._camera, c_value)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_set_frame_rate_control_value\",\n                                                              error_code))\n        except Exception as exception:\n            _logger.error(\"Could not set frame rate control value; \" + str(exception))\n            raise exception",
  "class TLCameraError(Exception):\n    def __init__(self, message):\n        _logger.debug(message)\n        super(TLCameraError, self).__init__(message)",
  "def __init__(self, image_buffer, frame_count, time_stamp_relative_ns_or_null):\n        #  image_buffer._wrapper = self\n        self._image_buffer = image_buffer\n        self._frame_count = int(frame_count.value)\n        self._time_stamp_relative_ns_or_null = time_stamp_relative_ns_or_null",
  "def image_buffer(self):\n        \"\"\"\n        Numpy array of pixel data. This array is temporary and may be invalidated after\n        :meth:`polling for another image<thorlabs_tsi_sdk.tl_camera.TLCamera.get_pending_frame_or_null>`,\n        :meth:`rearming the camera<thorlabs_tsi_sdk.tl_camera.TLCamera.arm>`, or\n        :meth:`closing the camera<thorlabs_tsi_sdk.tl_camera.TLCamera.dispose>`.\n\n        :type: np.array(dtype=np.ushort)\n        \"\"\"\n        return self._image_buffer",
  "def frame_count(self):\n        \"\"\"\n        Frame number assigned to this image by the camera.\n\n        :type: int\n        \"\"\"\n        return self._frame_count",
  "def time_stamp_relative_ns_or_null(self):\n        \"\"\"\n        Time stamp in nanoseconds relative to an internal counter mechanism. The timestamp is recorded immediately\n        following the exposure time. It is calculated by taking the pixel clock and dividing it by a model-specific\n        clock base frequency.\n        This value can be used to find the time in nanoseconds between frames (Frame_2.time_stamp_relative_ns_or_null -\n        Frame_1.time_stamp_relative_ns_or_null).\n        If the camera does not support time stamps, then this value will be None.\n\n        :type: int\n        \"\"\"\n        return self._time_stamp_relative_ns_or_null",
  "def __init__(self):\n        # type: (type(None)) -> None\n        self._disposed = True\n\n        if TLCameraSDK._is_sdk_open:\n            raise TLCameraError(\"TLCameraSDK is already in use. Please dispose of the current instance before\"\n                                \" trying to create another\")\n\n        try:\n            if platform.system() == 'Windows':\n                self._sdk = cdll.LoadLibrary(r\"thorlabs_tsi_camera_sdk.dll\")\n            elif platform.system() == 'Linux':\n                self._sdk = cdll.LoadLibrary(r\"libthorlabs_tsi_camera_sdk.so\")\n            else:\n                raise TLCameraError(\"{system} is not a supported platform.\".format(system=platform.system()))\n            self._disposed = False\n        except OSError as os_error:\n            raise TLCameraError(str(os_error) +\n                                \"\\nUnable to load library - are the thorlabs tsi camera sdk libraries \"\n                                \"discoverable from the application directory? Try placing them in the same \"\n                                \"directory as your program, or adding the directory with the libraries to the \"\n                                \"PATH. Make sure to use 32-bit libraries when using a 32-bit python interpreter \"\n                                \"and 64-bit libraries when using a 64-bit interpreter.\\n\")\n\n        error_code = self._sdk.tl_camera_open_sdk()\n        if error_code != 0:\n            raise TLCameraError(\"tl_camera_open_sdk() returned error code: {error_code}\\n\"\n                                .format(error_code=error_code))\n        TLCameraSDK._is_sdk_open = True\n        self._current_camera_connect_callback = None\n        self._current_camera_disconnect_callback = None\n\n        try:\n            \"\"\" set C function argument types \"\"\"\n            self._sdk.tl_camera_discover_available_cameras.argtypes = [c_char_p, c_int]\n            self._sdk.tl_camera_open_camera.argtypes = [c_char_p, POINTER(c_void_p)]\n            self._sdk.tl_camera_set_camera_connect_callback.argtypes = [_camera_connect_callback_type, c_void_p]\n            self._sdk.tl_camera_set_camera_disconnect_callback.argtypes = [_camera_disconnect_callback_type, c_void_p]\n            self._sdk.tl_camera_close_camera.argtypes = [c_void_p]\n            self._sdk.tl_camera_set_frame_available_callback.argtypes = [c_void_p, _frame_available_callback_type,\n                                                                         c_void_p]\n            self._sdk.tl_camera_get_pending_frame_or_null.argtypes = [c_void_p, POINTER(POINTER(c_ushort)),\n                                                                      POINTER(c_int), POINTER(POINTER(c_char)),\n                                                                      POINTER(c_int)]\n            self._sdk.tl_camera_get_measured_frame_rate.argtypes = [c_void_p, POINTER(c_double)]\n            self._sdk.tl_camera_get_is_data_rate_supported.argtypes = [c_void_p, c_int, POINTER(c_bool)]\n            self._sdk.tl_camera_get_is_taps_supported.argtypes = [c_void_p, POINTER(c_bool), c_int]\n            self._sdk.tl_camera_get_color_correction_matrix.argtypes = [c_void_p, POINTER(_3x3Matrix_float)]\n            self._sdk.tl_camera_get_default_white_balance_matrix.argtypes = [c_void_p, POINTER(_3x3Matrix_float)]\n            self._sdk.tl_camera_arm.argtypes = [c_void_p, c_int]\n            self._sdk.tl_camera_issue_software_trigger.argtypes = [c_void_p]\n            self._sdk.tl_camera_disarm.argtypes = [c_void_p]\n            self._sdk.tl_camera_get_exposure_time.argtypes = [c_void_p, POINTER(c_longlong)]\n            self._sdk.tl_camera_set_exposure_time.argtypes = [c_void_p, c_longlong]\n            self._sdk.tl_camera_get_image_poll_timeout.argtypes = [c_void_p, POINTER(c_int)]\n            self._sdk.tl_camera_set_image_poll_timeout.argtypes = [c_void_p, c_int]\n            self._sdk.tl_camera_get_exposure_time_range.argtypes = [c_void_p, POINTER(c_longlong), POINTER(c_longlong)]\n            self._sdk.tl_camera_get_firmware_version.argtypes = [c_void_p, c_char_p, c_int]\n            self._sdk.tl_camera_get_frame_time.argtypes = [c_void_p, POINTER(c_int)]\n            self._sdk.tl_camera_get_trigger_polarity.argtypes = [c_void_p, POINTER(c_int)]\n            self._sdk.tl_camera_set_trigger_polarity.argtypes = [c_void_p, c_int]\n            self._sdk.tl_camera_get_binx.argtypes = [c_void_p, POINTER(c_int)]\n            self._sdk.tl_camera_set_binx.argtypes = [c_void_p, c_int]\n            self._sdk.tl_camera_get_sensor_readout_time.argtypes = [c_void_p, POINTER(c_int)]\n            self._sdk.tl_camera_get_binx_range.argtypes = [c_void_p, POINTER(c_int), POINTER(c_int)]\n            self._sdk.tl_camera_get_is_hot_pixel_correction_enabled.argtypes = [c_void_p, POINTER(c_int)]\n            self._sdk.tl_camera_set_is_hot_pixel_correction_enabled.argtypes = [c_void_p, c_int]\n            self._sdk.tl_camera_get_hot_pixel_correction_threshold.argtypes = [c_void_p, POINTER(c_int)]\n            self._sdk.tl_camera_set_hot_pixel_correction_threshold.argtypes = [c_void_p, c_int]\n            self._sdk.tl_camera_get_hot_pixel_correction_threshold_range.argtypes = [c_void_p, POINTER(c_int),\n                                                                                     POINTER(c_int)]\n            self._sdk.tl_camera_get_sensor_width.argtypes = [c_void_p, POINTER(c_int)]\n            self._sdk.tl_camera_get_gain_range.argtypes = [c_void_p, POINTER(c_int), POINTER(c_int)]\n            self._sdk.tl_camera_get_image_width_range.argtypes = [c_void_p, POINTER(c_int), POINTER(c_int)]\n            self._sdk.tl_camera_get_sensor_height.argtypes = [c_void_p, POINTER(c_int)]\n            self._sdk.tl_camera_get_image_height_range.argtypes = [c_void_p, POINTER(c_int), POINTER(c_int)]\n            self._sdk.tl_camera_get_model.argtypes = [c_void_p, c_char_p, c_int]\n            self._sdk.tl_camera_get_name.argtypes = [c_void_p, c_char_p, c_int]\n            self._sdk.tl_camera_set_name.argtypes = [c_void_p, c_char_p]\n            self._sdk.tl_camera_get_name_string_length_range.argtypes = [c_void_p, POINTER(c_int), POINTER(c_int)]\n            self._sdk.tl_camera_get_frames_per_trigger_zero_for_unlimited.argtypes = [c_void_p, POINTER(c_uint)]\n            self._sdk.tl_camera_set_frames_per_trigger_zero_for_unlimited.argtypes = [c_void_p, c_uint]\n            self._sdk.tl_camera_get_frames_per_trigger_range.argtypes = [c_void_p, POINTER(c_uint), POINTER(c_uint)]\n            self._sdk.tl_camera_get_usb_port_type.argtypes = [c_void_p, POINTER(c_int)]\n            self._sdk.tl_camera_get_communication_interface.argtypes = [c_void_p, POINTER(c_int)]\n            self._sdk.tl_camera_get_operation_mode.argtypes = [c_void_p, POINTER(c_int)]\n            self._sdk.tl_camera_set_operation_mode.argtypes = [c_void_p, c_int]\n            self._sdk.tl_camera_get_is_armed.argtypes = [c_void_p, POINTER(c_bool)]\n            self._sdk.tl_camera_get_is_eep_supported.argtypes = [c_void_p, POINTER(c_bool)]\n            self._sdk.tl_camera_get_is_led_supported.argtypes = [c_void_p, POINTER(c_bool)]\n            self._sdk.tl_camera_get_is_cooling_supported.argtypes = [c_void_p, POINTER(c_bool)]\n            self._sdk.tl_camera_get_cooling_enable.argtypes = [c_void_p, POINTER(c_bool)]\n            self._sdk.tl_camera_get_is_nir_boost_supported.argtypes = [c_void_p, POINTER(c_bool)]\n            self._sdk.tl_camera_get_camera_sensor_type.argtypes = [c_void_p, POINTER(c_int)]\n            self._sdk.tl_camera_get_color_filter_array_phase.argtypes = [c_void_p, POINTER(c_int)]\n            self._sdk.tl_camera_get_camera_color_correction_matrix_output_color_space.argtypes = [c_void_p, c_char_p]\n            self._sdk.tl_camera_get_data_rate.argtypes = [c_void_p, POINTER(c_int)]\n            self._sdk.tl_camera_set_data_rate.argtypes = [c_void_p, c_int]\n            self._sdk.tl_camera_get_sensor_pixel_size_bytes.argtypes = [c_void_p, POINTER(c_int)]\n            self._sdk.tl_camera_get_sensor_pixel_width.argtypes = [c_void_p, POINTER(c_double)]\n            self._sdk.tl_camera_get_sensor_pixel_height.argtypes = [c_void_p, POINTER(c_double)]\n            self._sdk.tl_camera_get_bit_depth.argtypes = [c_void_p, POINTER(c_int)]\n            self._sdk.tl_camera_get_roi.argtypes = [c_void_p, POINTER(c_int), POINTER(c_int), POINTER(c_int),\n                                                    POINTER(c_int)]\n            self._sdk.tl_camera_set_roi.argtypes = [c_void_p, c_int, c_int, c_int, c_int]\n            self._sdk.tl_camera_get_roi_range.argtypes = [c_void_p, POINTER(c_int), POINTER(c_int), POINTER(c_int),\n                                                          POINTER(c_int), POINTER(c_int), POINTER(c_int),\n                                                          POINTER(c_int), POINTER(c_int)]\n            self._sdk.tl_camera_get_serial_number.argtypes = [c_void_p, c_char_p, c_int]\n            self._sdk.tl_camera_get_serial_number_string_length_range.argtypes = [c_void_p, POINTER(c_int),\n                                                                                  POINTER(c_int)]\n            self._sdk.tl_camera_get_is_led_on.argtypes = [c_void_p, POINTER(c_bool)]\n            self._sdk.tl_camera_set_is_led_on.argtypes = [c_void_p, c_bool]\n            self._sdk.tl_camera_get_eep_status.argtypes = [c_void_p, POINTER(c_int)]\n            self._sdk.tl_camera_set_is_eep_enabled.argtypes = [c_void_p, c_bool]\n            self._sdk.tl_camera_get_biny.argtypes = [c_void_p, POINTER(c_int)]\n            self._sdk.tl_camera_set_biny.argtypes = [c_void_p, c_int]\n            self._sdk.tl_camera_get_biny_range.argtypes = [c_void_p, POINTER(c_int), POINTER(c_int)]\n            self._sdk.tl_camera_get_gain.argtypes = [c_void_p, POINTER(c_int)]\n            self._sdk.tl_camera_set_gain.argtypes = [c_void_p, c_int]\n            self._sdk.tl_camera_get_black_level.argtypes = [c_void_p, POINTER(c_int)]\n            self._sdk.tl_camera_set_black_level.argtypes = [c_void_p, c_int]\n            self._sdk.tl_camera_get_black_level_range.argtypes = [c_void_p, POINTER(c_int), POINTER(c_int)]\n            self._sdk.tl_camera_get_frames_per_trigger_zero_for_unlimited.argtypes = [c_void_p, POINTER(c_uint)]\n            self._sdk.tl_camera_set_frames_per_trigger_zero_for_unlimited.argtypes = [c_void_p, c_uint]\n            self._sdk.tl_camera_get_frames_per_trigger_range.argtypes = [c_void_p, POINTER(c_uint), POINTER(c_uint)]\n            self._sdk.tl_camera_get_image_width.argtypes = [c_void_p, POINTER(c_int)]\n            self._sdk.tl_camera_get_image_height.argtypes = [c_void_p, POINTER(c_int)]\n            self._sdk.tl_camera_get_polar_phase.argtypes = [c_void_p, POINTER(c_int)]\n            self._sdk.tl_camera_get_frame_rate_control_value_range.argtypes = [c_void_p, POINTER(c_double), POINTER(c_double)]\n            self._sdk.tl_camera_get_is_frame_rate_control_enabled.argtypes = [c_void_p, POINTER(c_int)]\n            self._sdk.tl_camera_set_is_frame_rate_control_enabled.argtypes = [c_void_p, c_int]\n            self._sdk.tl_camera_get_frame_rate_control_value.argtypes = [c_void_p, POINTER(c_double)]\n            self._sdk.tl_camera_set_frame_rate_control_value.argtypes = [c_void_p, c_double]\n            self._sdk.tl_camera_get_timestamp_clock_frequency.argtypes = [c_void_p, POINTER(c_int)]\n            self._sdk.tl_camera_convert_gain_to_decibels.argtypes = [c_void_p, c_int, POINTER(c_double)]\n            self._sdk.tl_camera_convert_decibels_to_gain.argtypes = [c_void_p, c_double, POINTER(c_int)]\n            self._sdk.tl_camera_get_is_operation_mode_supported.argtypes = [c_void_p, c_int, POINTER(c_bool)]\n\n            self._sdk.tl_camera_get_last_error.restype = c_char_p\n            # noinspection PyProtectedMember\n            self._sdk._internal_command.argtypes = [c_void_p, c_char_p, c_uint, c_char_p, c_uint]\n        except Exception as exception:\n            _logger.error(\"SDK initialization failed; \" + str(exception))\n            raise exception",
  "def __del__(self):\n        self.dispose()",
  "def __enter__(self):\n        return self",
  "def __exit__(self, exception_type, exception_value, exception_traceback):\n        if exception_type is not None:\n            _logger.debug(\"\".join(format_exception(exception_type, exception_value, exception_traceback)))\n        self.dispose()\n        return True if exception_type is None else False",
  "def dispose(self):\n        # type: (type(None)) -> None\n        \"\"\"\n        Cleans up the TLCameraSDK instance - make sure to call this when you are done with the TLCameraSDK instance.\n        If using the *with* statement, dispose is called automatically upon exit.\n\n        \"\"\"\n        try:\n            if self._disposed:\n                return\n            error_code = self._sdk.tl_camera_close_sdk()\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_close_sdk\", error_code))\n            TLCameraSDK._is_sdk_open = False\n            self._disposed = True\n            self._current_camera_connect_callback = None\n            self._current_camera_disconnect_callback = None\n        except Exception as exception:\n            _logger.error(\"Camera SDK destruction failed; \" + str(exception))\n            raise exception",
  "def discover_available_cameras(self):\n        # type: (type(None)) -> List[str]\n        \"\"\"\n        Returns a list of all open cameras by their serial number string.\n\n        \"\"\"\n        try:\n            string_buffer = create_string_buffer(_STRING_MAX)\n            error_code = self._sdk.tl_camera_discover_available_cameras(string_buffer, _STRING_MAX)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_discover_available_cameras\",\n                                                              error_code))\n            return string_buffer.value.decode(\"utf-8\").split()\n        except Exception as exception:\n            _logger.error(\"discover_available_cameras failed; \" + str(exception))\n            raise exception",
  "def open_camera(self, camera_serial_number):\n        # type: (str) -> TLCamera\n        \"\"\"\n        Opens the camera with given serial number and returns it as a TLCamera instance.\n\n        :param str camera_serial_number: The serial number of the camera to open.\n        :returns: :class:`TLCamera<thorlabs_tsi_sdk.tl_camera.TLCamera>`\n\n        \"\"\"\n        try:\n            serial_number_bytes = camera_serial_number.encode(\"utf-8\") + b'\\0'\n            c_camera_handle = c_void_p()  # void *\n            error_code = self._sdk.tl_camera_open_camera(serial_number_bytes, c_camera_handle)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_open_camera\", error_code))\n            # noinspection PyProtectedMember\n            return TLCamera._create(self._sdk, c_camera_handle)\n        except Exception as exception:\n            _logger.error(\"Could not open camera '{serial_number}'; {exception}\".format(\n                serial_number=str(camera_serial_number),\n                exception=str(exception)))\n            raise exception",
  "def _generate_camera_connect_callback(_callback, *args, **kwargs):\n        # warning that context is unused suppressed - it must be in the function signature to match native function call\n        # noinspection PyUnusedLocal\n        def camera_connect_callback(camera_serial_number, usb_port_type, context):\n            _callback(str(camera_serial_number.decode('utf-8')), USB_PORT_TYPE(usb_port_type), *args, **kwargs)\n\n        return _camera_connect_callback_type(camera_connect_callback)",
  "def set_camera_connect_callback(self,\n                                    handler,\n                                    # type: Callable[[str, USB_PORT_TYPE, Optional[Any], Optional[Any]], type(None)]\n                                    *args,  # type: Optional[Any]\n                                    **kwargs  # type: Optional[Any]\n                                    ):  # type: (...) -> None\n        \"\"\"\n        Sets the callback function for camera connection events. Whenever a USB camera is connected, the provided\n        handler will be called along with any specified arguments and keyword arguments.\n\n        :param handler: Any method with a signature that conforms to this type. It will be called when a USB camera is\n         connected.\n        :type handler: Callable[[str, :class:`USB_PORT_TYPE<thorlabs_tsi_sdk.tl_camera_enums.USB_PORT_TYPE>`, Optional[Any], Optional[Any]], type(None)]\n        :param args: Optional arguments that are forwarded to the handler when it is called.\n        :type args: Optional[Any]\n        :param kwargs: Optional keyword arguments that are forwarded to the handler when it is called.\n        :type kwargs: Optional[Any]\n\n        \"\"\"\n        try:\n            callback = self._generate_camera_connect_callback(handler, *args, **kwargs)\n            error_code = self._sdk.tl_camera_set_camera_connect_callback(callback, None)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_set_camera_connect_callback\",\n                                                              error_code))\n            self._current_camera_connect_callback = callback  # reference the callback so python doesn't delete it\n        except Exception as exception:\n            _logger.error(\"Could not set camera connect callback; \" + str(exception))\n            raise exception",
  "def _generate_camera_disconnect_callback(_callback, *args, **kwargs):\n        # warning that context is unused suppressed - it must be in the function signature to match native function call\n        # noinspection PyUnusedLocal\n        def camera_disconnect_callback(camera_serial_number, context):\n            _callback(str(camera_serial_number.decode('utf-8')), *args, **kwargs)\n\n        return _camera_disconnect_callback_type(camera_disconnect_callback)",
  "def set_camera_disconnect_callback(self,\n                                       handler,\n                                       # type: Callable[[str, Optional[Any], Optional[Any]], type(None)]\n                                       *args,  # type: Optional[Any]\n                                       **kwargs  # type: Optional[Any]\n                                       ):  # type: (...) -> None\n        \"\"\"\n        Sets the callback function for camera disconnection events. Whenever a USB camera is disconnected, the\n        provided handler will be called along with any specified arguments and keyword arguments\n\n        :param handler: Any method with a signature that conforms to this type. It will be called when a USB camera is\n         disconnected.\n        :type handler: Callable[[str, Optional[Any], Optional[Any]], type(None)]\n        :param args: Optional arguments that are forwarded to the handler when it is called.\n        :type args: Optional[Any]\n        :param kwargs: Optional keyword arguments that are forwarded to the handler when it is called.\n        :type kwargs: Optional[Any]\n\n        \"\"\"\n        try:\n            callback = self._generate_camera_disconnect_callback(handler, *args, **kwargs)\n            error_code = self._sdk.tl_camera_set_camera_disconnect_callback(callback, None)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_set_camera_disconnect_callback\",\n                                                              error_code))\n            self._current_camera_disconnect_callback = callback  # reference the callback so python doesn't delete it\n        except Exception as exception:\n            _logger.error(\"Could not set camera disconnect callback; \" + str(exception))\n            raise exception",
  "def _create(cls, sdk, camera):\n        # type: (Any, Any) -> TLCamera\n        return TLCamera(cls.__key, sdk, camera)",
  "def __init__(self, key, sdk, camera):\n        # type: (type(object), Any, Any) -> None\n        try:\n            self._disposed = True\n            assert (key == TLCamera.__key), \"TLCamera objects cannot be created manually. Please use \" \\\n                                            \"TLCameraSDK.open_camera to acquire new TLCamera objects.\"\n            self._sdk = sdk\n            self._camera = camera\n            self._current_frame_available_callback = None\n            self._local_image_height_pixels = 0\n            self._local_image_width_pixels = 0\n            self._local_timestamp_clock_frequency = None\n            self._disposed = False\n        except Exception as exception:\n            _logger.error(\"TLCamera initialization failed; \" + str(exception))\n            raise exception",
  "def __del__(self):\n        self.dispose()",
  "def __enter__(self):\n        return self",
  "def __exit__(self, exception_type, exception_value, exception_traceback):\n        if exception_type is not None:\n            _logger.debug(\"\".join(format_exception(exception_type, exception_value, exception_traceback)))\n        self.dispose()\n        return True if exception_type is None else False",
  "def dispose(self):\n        # type: (type(None)) -> None\n        \"\"\"\n        Cleans up the TLCamera instance - make sure to call this when you are done with the camera.\n        If using the *with* statement, dispose is called automatically upon exit.\n\n        \"\"\"\n        try:\n            if self._disposed:\n                return\n            error_code = self._sdk.tl_camera_disarm(self._camera)\n            if error_code != 0:\n                _logger.error(\"Could not disarm camera.\")\n            error_code = self._sdk.tl_camera_close_camera(self._camera)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_close_camera\", error_code))\n            self._disposed = True\n            self._current_frame_available_callback = None\n        except Exception as exception:\n            _logger.error(\"Could not dispose camera; \" + str(exception))\n            raise exception",
  "def get_pending_frame_or_null(self):\n        # type: (type(None)) -> Optional[Frame]\n        \"\"\"\n        Polls the camera for an image.\n        This method will block for at most :attr:`image_poll_timeout <thorlabs_tsi_sdk.tl_camera.TLCamera.image_poll_timeout_ms>`\n        milliseconds. The Frame that is retrieved will have an image_buffer field to access the pixel data.\n        This image_buffer is only valid until the next call to *get_pending_frame_or_null()* or until disarmed.\n        If image data is needed for a longer period of time, use *np.copy(image_buffer)* to create a deep copy of the\n        data.\n\n        :returns: :class:`Frame<thorlabs_tsi_sdk.tl_camera.Frame>` or None if there is no pending frame\n\n        \"\"\"\n        try:\n            image_buffer = POINTER(c_ushort)()\n            frame_count = c_int()\n            metadata_pointer = POINTER(c_char)()\n            metadata_size_in_bytes = c_int()\n            error_code = self._sdk.tl_camera_get_pending_frame_or_null(self._camera, image_buffer, frame_count,\n                                                                       metadata_pointer, metadata_size_in_bytes)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_get_pending_frame_or_null\",\n                                                              error_code))\n            if not image_buffer:\n                return None\n\n            image_buffer._wrapper = self  # image buffer needs a reference to this instance or it may get deleted\n            image_buffer_as_np_array = np.ctypeslib.as_array(image_buffer, shape=(self._local_image_height_pixels,\n                                                                                  self._local_image_width_pixels))\n            time_stamp_relative_ns = None\n            metadata_size_in_bytes = metadata_size_in_bytes.value\n            if metadata_size_in_bytes > 0 and self._local_timestamp_clock_frequency is not None:\n                metadata = bytes(np.ctypeslib.as_array(metadata_pointer, shape=(metadata_size_in_bytes,)))\n                metadata_chunks = [metadata[i:i+8] for i in range(0, len(metadata), 8)]\n                pixel_clock_high = -1\n                pixel_clock_low = -1\n                for metadata_chunk in metadata_chunks:\n                    tag = metadata_chunk[0:4]\n                    value = struct.unpack('<I', metadata_chunk[4:8])[0]\n                    if tag == b'PCKH':\n                        pixel_clock_high = value\n                    elif tag == b'PCKL':\n                        pixel_clock_low = value\n                    elif tag == b'ENDT':\n                        break\n                # if PCKH or PCKL weren't found, pixel clock is invalid.\n                if pixel_clock_high > -1 and pixel_clock_low > -1:\n                    pixel_clock = (pixel_clock_high << 32) | pixel_clock_low\n                    time_stamp_relative_ns = \\\n                        int((decimal.Decimal(pixel_clock) / decimal.Decimal(self._local_timestamp_clock_frequency))\n                            * 1000000000)\n\n            frame = Frame(image_buffer=image_buffer_as_np_array,\n                          frame_count=frame_count,\n                          time_stamp_relative_ns_or_null=time_stamp_relative_ns)\n\n            return frame\n        except Exception as exception:\n            _logger.error(\"Unable to get pending frame; \" + str(exception))\n            raise exception",
  "def get_measured_frame_rate_fps(self):\n        # type: (type(None)) -> float\n        \"\"\"\n        Gets the current rate of frames that are delivered to the host computer. The frame rate can be affected by the\n        performance capabilities of the host computer and the communication interface.\n        This method can be polled for updated values as needed.\n\n        :returns: float - The current frame rate as measured by the camera SDK.\n\n        \"\"\"\n        try:\n            frames_per_second = c_double()\n            error_code = self._sdk.tl_camera_get_measured_frame_rate(self._camera, frames_per_second)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_get_measured_frame_rate\",\n                                                              error_code))\n            return float(frames_per_second.value)\n        except Exception as exception:\n            _logger.error(\"Could not get measured frame rate; \" + str(exception))\n            raise exception",
  "def get_is_data_rate_supported(self, data_rate):\n        # type: (DATA_RATE) -> bool\n        \"\"\"\n        Scientific-CCD cameras and compact-scientific cameras handle sensor- level data-readout speed differently.\n        Use this method to test whether the connected camera supports a particular data rate.\n        For more details about the data rate options, see the :attr:`data_rate<thorlabs_tsi_sdk.tl_camera.TLCamera.data_rate>` property.\n\n        :param: data_rate (:class:`DATA_RATE<thorlabs_tsi_sdk.tl_camera_enums.DATA_RATE>`) - The data rate value to check.\n        :returns: bool - True if the given data rate is supported by the connected camera, false if it is not\n\n        \"\"\"\n        try:\n            c_value = c_int(data_rate)\n            is_supported = c_bool()\n            error_code = self._sdk.tl_camera_get_is_data_rate_supported(self._camera, c_value, is_supported)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"get_is_data_rate_supported\", error_code))\n            return bool(is_supported.value)\n        except Exception as exception:\n            _logger.error(\"Could not get if data rate was supported; \" + str(exception))\n            raise exception",
  "def get_is_taps_supported(self, tap):\n        # type: (TAPS) -> bool\n        \"\"\"\n        All CCD cameras support a single tap. Some also support dual tap or quad tap. Use this method to test whether a\n        connected camera supports a particular Taps value. For more information on taps and tap balancing, see\n        is_tap_balance_enabled - *Taps not yet supported by Python SDK*.\n\n        :param: tap (:class:`TAPS<thorlabs_tsi_sdk.tl_camera_enums.TAPS>`) - The tap value to check.\n        :returns: bool - True if the connected camera supports the given taps mode, false if not.\n\n        \"\"\"\n        try:\n            c_value = c_int(tap)\n            is_supported = c_bool()\n            error_code = self._sdk.tl_camera_get_is_taps_supported(self._camera, c_value, is_supported)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"get_is_taps_supported\", error_code))\n            return bool(is_supported.value)\n        except Exception as exception:\n            _logger.error(\"Could not get if tap was supported; \" + str(exception))\n            raise exception",
  "def get_is_operation_mode_supported(self, operation_mode):\n        # type: (OPERATION_MODE) -> bool\n        \"\"\"\n        This method can be used to determine if a camera has the ability to perform hardware triggering. Some cameras,\n        such as the zelux, have both triggered and non-triggered models.\n\n        :param: operation_mode (:class:`OPERATION_MODE<thorlabs_tsi_sdk.tl_camera_enums.OPERATION_MODE>`) - The operation mode to check.\n        :returns: bool - True if the connected camera supports the given operation mode, false if not.\n\n        \"\"\"\n        try:\n            c_value = c_int(operation_mode)\n            is_supported = c_bool()\n            error_code = self._sdk.tl_camera_get_is_operation_mode_supported(self._camera, c_value, is_supported)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"get_is_operation_mode_supported\", error_code))\n            return bool(is_supported.value)\n        except Exception as exception:\n            _logger.error(\"Could not get if operation mode was supported; \" + str(exception))\n            raise exception",
  "def get_color_correction_matrix(self):\n        # type: (type(None)) -> np.array\n        \"\"\"\n        Each scientific color camera includes a three-by-three matrix that can be used to achieve consistent color for\n        different camera modelsGet the default color correction matrix for this camera. This can be used with the\n        :class:`MonoToColorProcessor<thorlabs_tsi_sdk.tl_mono_to_color_processor.MonoToColorProcessor>` when color processing an image.\n\n        :returns: np.array\n\n        \"\"\"\n        try:\n            color_correction_matrix = _3x3Matrix_float()\n            error_code = self._sdk.tl_camera_get_color_correction_matrix(self._camera, color_correction_matrix)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"get_color_correction_matrix\", error_code))\n            color_correction_matrix_as_np_array = np.array([float(color_correction_matrix[0]),\n                                                            float(color_correction_matrix[1]),\n                                                            float(color_correction_matrix[2]),\n                                                            float(color_correction_matrix[3]),\n                                                            float(color_correction_matrix[4]),\n                                                            float(color_correction_matrix[5]),\n                                                            float(color_correction_matrix[6]),\n                                                            float(color_correction_matrix[7]),\n                                                            float(color_correction_matrix[8])])\n            return color_correction_matrix_as_np_array\n        except Exception as exception:\n            _logger.error(\"Could not get color correction matrix; \" + str(exception))\n            raise exception",
  "def _get_time_stamp_clock_frequency_or_null(self):\n        # type: (type(None)) -> Optional[int]\n        \"\"\"\n\n        This is the frequency at which the time stamp counter on the camera increments. This is used to calculate\n        clock time from the camera in real-world units.\n\n        :returns: int - time stamp clock base in Hertz.\n\n        \"\"\"\n        try:\n            time_stamp_clock_frequency = c_int()\n            error_code = self._sdk.tl_camera_get_timestamp_clock_frequency(self._camera, time_stamp_clock_frequency)\n            if error_code != 0:\n                return None\n            if time_stamp_clock_frequency.value == 0:\n                return None\n            return int(time_stamp_clock_frequency.value)\n        except Exception as exception:\n            _logger.debug(\"Could not get time stamp clock frequency; \" + str(exception))\n            return None",
  "def get_default_white_balance_matrix(self):\n        # type: (type(None)) -> np.array\n        \"\"\"\n        Get the default white balance matrix for this camera. Each scientific color camera includes a three-by-three\n        matrix that corrects white balance for the default color temperature. This can be used with the\n        :class:`MonoToColorProcessor<thorlabs_tsi_sdk.tl_mono_to_color_processor.MonoToColorProcessor>` to provide a default white balance to an image.\n\n        :returns: np.array\n\n        \"\"\"\n        try:\n            white_balance_matrix = _3x3Matrix_float()\n            error_code = self._sdk.tl_camera_get_default_white_balance_matrix(self._camera, white_balance_matrix)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"get_default_white_balance_matrix\",\n                                                              error_code))\n            white_balance_matrix_as_np_array = np.array([float(white_balance_matrix[0]),\n                                                         float(white_balance_matrix[1]),\n                                                         float(white_balance_matrix[2]),\n                                                         float(white_balance_matrix[3]),\n                                                         float(white_balance_matrix[4]),\n                                                         float(white_balance_matrix[5]),\n                                                         float(white_balance_matrix[6]),\n                                                         float(white_balance_matrix[7]),\n                                                         float(white_balance_matrix[8])])\n            return white_balance_matrix_as_np_array\n        except Exception as exception:\n            _logger.error(\"Could not get default white balance matrix; \" + str(exception))\n            raise exception",
  "def arm(self, frames_to_buffer):\n        # type: (int) -> None\n        \"\"\"\n        Before issuing software or hardware triggers to get images from a camera, prepare it for imaging by calling\n        :meth:`arm()<thorlabs_tsi_sdk.tl_camera.TLCamera.arm>`.\n        Depending on the :attr:`operation_mode<thorlabs_tsi_sdk.tl_camera.TLCamera.operation_mode>`, either call\n        :meth:`issue_software_trigger()<thorlabs_tsi_sdk.tl_camera.TLCamera.issue_software_trigger>` or issue a hardware trigger.\n        To start a camera in continuous mode, set the :attr:`operation_mode<thorlabs_tsi_sdk.tl_camera.TLCamera.operation_mode>` to\n        SOFTWARE_TRIGGERED, :attr:`frames per trigger<thorlabs_tsi_sdk.tl_camera.TLCamera.frames_per_trigger_zero_for_unlimited>` to zero, Arm\n        the camera, and then call :meth:`issue_software_trigger()<thorlabs_tsi_sdk.tl_camera.TLCamera.issue_software_trigger>` one time. The\n        camera will then self-trigger frames until :meth:`disarm()<thorlabs_tsi_sdk.tl_camera.TLCamera.disarm>` or\n        :meth:`dispose()<thorlabs_tsi_sdk.tl_camera.TLCamera.dispose>` is called.\n        To start a camera for hardware triggering, set the :attr:`operation_mode<thorlabs_tsi_sdk.tl_camera.TLCamera.operation_mode>` to either\n        HARDWARE_TRIGGERED or BULB, :attr:`frames per trigger<thorlabs_tsi_sdk.tl_camera.TLCamera.frames_per_trigger_zero_for_unlimited>` to\n        one, :attr:`trigger_polarity`<thorlabs_tsi_sdk.tl_camera.TLCamera.trigger_polarity>` to rising-edge or falling-edge triggered, arm the\n        camera, and then issue a triggering signal on the trigger input.\n        If any images are still in the queue when calling :meth:`arm()<thorlabs_tsi_sdk.tl_camera.TLCamera.arm>`, they will be considered stale\n        and cleared from the queue.\n        For more information on the proper procedure for triggering frames and receiving them from the camera, please\n        see the Getting Started section.\n\n        \"\"\"\n        try:\n            error_code = self._sdk.tl_camera_arm(self._camera, c_int(frames_to_buffer))\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_arm\", error_code))\n            self._local_image_height_pixels = self.image_height_pixels\n            self._local_image_width_pixels = self.image_width_pixels\n            self._local_timestamp_clock_frequency = self._get_time_stamp_clock_frequency_or_null()\n        except Exception as exception:\n            _logger.error(\"Could not arm camera; \" + str(exception))\n            raise exception",
  "def issue_software_trigger(self):\n        # type: (type(None)) -> None\n        \"\"\"\n        If the :attr:`operation_mode<thorlabs_tsi_sdk.tl_camera.TLCamera.operation_mode>` is set to SOFTWARE_TRIGGERED\n        and :meth:`arm()<thorlabs_tsi_sdk.tl_camera.TLCamera.arm>` is called, then calling this method will generate a\n        trigger through the camera SDK rather than through the hardware trigger input.\n\n        The behavior of a software trigger depends on the\n        :attr:`frames_per-trigger_zero_for_unlimited<thorlabs_tsi_sdk.tl_camera.TLCamera.frames_per_trigger_zero_for_unlimited>` property:\n\n        - If :attr:`frames_per-trigger_zero_for_unlimited<thorlabs_tsi_sdk.tl_camera.TLCamera.frames_per_trigger_zero_for_unlimited>` is set to zero, then a single software trigger will start continuous-video mode.\n\n        - If :attr:`frames_per-trigger_zero_for_unlimited<thorlabs_tsi_sdk.tl_camera.TLCamera.frames_per_trigger_zero_for_unlimited>` is set to one or higher, then one software trigger will generate a corresponding number of frames.\n\n        Multiple software triggers can be issued before calling :meth:`disarm()<thorlabs_tsi_sdk.tl_camera.TLCamera.disarm>`.\n\n        IMPORTANT: For scientific-CCD cameras, after issuing a software trigger, it is necessary to wait at least 300ms\n        before adjusting the :attr:`exposure_time_us<thorlabs_tsi_sdk.tl_camera.TLCamera.exposure_time_us>` property.\n\n        \"\"\"\n        try:\n            error_code = self._sdk.tl_camera_issue_software_trigger(self._camera)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_issue_software_trigger\",\n                                                              error_code))\n        except Exception as exception:\n            _logger.error(\"Could not issue software trigger; \" + str(exception))\n            raise exception",
  "def disarm(self):\n        # type: (type(None)) -> None\n        \"\"\"\n        When finished issuing software or hardware triggers, call :meth:`disarm()<thorlabs_tsi_sdk.tl_camera.TLCamera.disarm>`. This allows\n        setting parameters that are not available in armed mode such as :attr:`roi<thorlabs_tsi_sdk.tl_camera.TLCamera.roi>` or\n        :attr:`operation_mode<thorlabs_tsi_sdk.tl_camera.TLCamera.operation_mode>`.\n        The camera will automatically disarm when :meth:`disarm()<thorlabs_tsi_sdk.tl_camera.TLCamera.disarm>` is called.\n        Disarming the camera does not clear the image queue \u2013 polling can continue until the queue is empty. When\n        calling :meth:`disarm()<thorlabs_tsi_sdk.tl_camera.TLCamera.arm>` again, the queue will be automatically cleared.\n\n        \"\"\"\n        try:\n            error_code = self._sdk.tl_camera_disarm(self._camera)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_disarm\", error_code))\n        except Exception as exception:\n            _logger.error(\"Could not disarm camera; \" + str(exception))\n            raise exception",
  "def convert_gain_to_decibels(self, gain):\n        # type: (int) -> float\n        \"\"\"\n        Use this method to convert the gain from the :attr:`gain<thorlabs_tsi_sdk.tl_camera.TLCamera.gain>` property into units of Decibels\n        (dB).\n\n        :returns: float\n\n        \"\"\"\n        try:\n            c_decibels = c_double()\n            c_gain = c_int(gain)\n            error_code = self._sdk.tl_camera_convert_gain_to_decibels(self._camera, c_gain, c_decibels)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_convert_gain_to_decibels\",\n                                                              error_code))\n            return float(c_decibels.value)\n        except Exception as exception:\n            _logger.error(\"Could not convert gain to decibels; \" + str(exception))\n            raise exception",
  "def convert_decibels_to_gain(self, gain_db):\n        # type: (float) -> int\n        \"\"\"\n        Use this method to convert the gain (in decibels) from the\n        :meth:`convert_gain_to_decibels<thorlabs_tsi_sdk.tl_camera.TLCamera.convert_decibels_to_gain>` method back into a gain index.\n        (dB).\n\n        :returns: int\n\n        \"\"\"\n        try:\n            c_gain = c_int()\n            c_decibels = c_double(gain_db)\n            error_code = self._sdk.tl_camera_convert_decibels_to_gain(self._camera, c_decibels, c_gain)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_convert_decibels_to_gain\",\n                                                              error_code))\n            return int(c_gain.value)\n        except Exception as exception:\n            _logger.error(\"Could not convert decibel gain to gain index; \" + str(exception))\n            raise exception",
  "def _internal_command(self, command):\n        # type: (str) -> str\n        try:\n            command_data = create_string_buffer(str(command).encode('utf-8') + b'\\0', len(command) + 1)\n            response_data = create_string_buffer(_STRING_MAX)\n            # noinspection PyProtectedMember\n            error_code = self._sdk._internal_command(self._camera, command_data, len(command) + 1, response_data, _STRING_MAX)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"_internal_command\", error_code))\n            return str(response_data.value.decode(\"utf-8\"))\n        except Exception as exception:\n            _logger.error(\"Unable to execute internal command; \" + str(exception))\n            raise exception",
  "def exposure_time_us(self):\n        \"\"\"\n        The time, in microseconds (us), that charge is integrated on the image sensor.\n\n        To convert milliseconds to microseconds, multiply the milliseconds by 1,000.\n        To convert microseconds to milliseconds, divide the microseconds by 1,000.\n\n        IMPORTANT: After issuing a software trigger, it is recommended to wait at least 300ms before setting exposure.\n\n        :type: int\n        \"\"\"\n        try:\n            exposure_time_us = c_longlong()\n            error_code = self._sdk.tl_camera_get_exposure_time(self._camera, exposure_time_us)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_get_exposure_time\", error_code))\n            return int(exposure_time_us.value)\n        except Exception as exception:\n            _logger.error(\"Could not get exposure time; \" + str(exception))\n            raise exception",
  "def exposure_time_us(self, exposure_time_us):\n        try:\n            c_value = c_longlong(exposure_time_us)\n            error_code = self._sdk.tl_camera_set_exposure_time(self._camera, c_value)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_set_exposure_time\", error_code))\n        except Exception as exception:\n            _logger.error(\"Could not set exposure time; \" + str(exception))\n            raise exception",
  "def image_poll_timeout_ms(self):\n        \"\"\"\n        :meth:`get_pending_frame_or_null()<thorlabs_tsi_sdk.tl_camera.TLCamera.get_pending_frame_or_null>` will block up to this many\n        milliseconds to get an image. If the SDK could not get an image within the timeout, None will be returned\n        instead.\n\n        :type: int\n        \"\"\"\n        try:\n            image_poll_timeout_ms = c_int()\n            error_code = self._sdk.tl_camera_get_image_poll_timeout(self._camera, image_poll_timeout_ms)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_get_image_poll_timeout\",\n                                                              error_code))\n            return int(image_poll_timeout_ms.value)\n        except Exception as exception:\n            _logger.error(\"Could not get image poll timeout; \" + str(exception))\n            raise exception",
  "def image_poll_timeout_ms(self, timeout_ms):\n        try:\n            c_value = c_int(timeout_ms)\n            error_code = self._sdk.tl_camera_set_image_poll_timeout(self._camera, c_value)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_set_image_poll_timeout\",\n                                                              error_code))\n        except Exception as exception:\n            _logger.error(\"Could not set image poll timeout; \" + str(exception))\n            raise exception",
  "def exposure_time_range_us(self):\n        \"\"\"\n        Range of possible exposure values in microseconds. This property is Read-Only.\n\n        :type: Range\n        \"\"\"\n        try:\n            exposure_time_us_min = c_longlong()\n            exposure_time_us_max = c_longlong()\n            error_code = self._sdk.tl_camera_get_exposure_time_range(self._camera,\n                                                                     exposure_time_us_min,\n                                                                     exposure_time_us_max)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_get_exposure_time_range\",\n                                                              error_code))\n            return Range(int(exposure_time_us_min.value), int(exposure_time_us_max.value))\n        except Exception as exception:\n            _logger.error(\"Could not get exposure time range; \" + str(exception))\n            raise exception",
  "def firmware_version(self):\n        \"\"\"\n        String containing the version information for all firmware components. This property is Read-Only.\n\n        :type: str\n        \"\"\"\n        try:\n            firmware_version = create_string_buffer(_STRING_MAX)\n            error_code = self._sdk.tl_camera_get_firmware_version(self._camera, firmware_version, _STRING_MAX)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_get_firmware_version\", error_code))\n            return str(firmware_version.value.decode(\"utf-8\"))\n        except Exception as exception:\n            _logger.error(\"Could not get firmware version; \" + str(exception))\n            raise exception",
  "def frame_time_us(self):\n        \"\"\"\n        The time, in microseconds (us), required for a frame to be exposed and read out from the sensor. When\n        triggering frames, this property may be used to determine when the camera is ready to accept another trigger.\n        Other factors such as the communication speed between the camera and the host computer can affect the maximum\n        trigger rate.\n\n        IMPORTANT: Currently, only scientific CCD cameras support this parameter.\n        This property is Read-Only.\n\n        :type: int\n        \"\"\"\n        try:\n            frame_time_us = c_int()\n            error_code = self._sdk.tl_camera_get_frame_time(self._camera, frame_time_us)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_get_frame_time\", error_code))\n            return int(frame_time_us.value)\n        except Exception as exception:\n            _logger.error(\"Could not get frame time; \" + str(exception))\n            raise exception",
  "def trigger_polarity(self):\n        \"\"\"\n        When the :attr:`operation_mode<thorlabs_tsi_sdk.tl_camera.TLCamera.operation_mode>` is set to HARDWARE_TRIGGERED or BULB and then\n        :meth:`arm()<thorlabs_tsi_sdk.tl_camera.TLCamera.arm>` is called, the camera will respond to a trigger input as a signal to begin\n        exposure. Setting trigger polarity tells the camera to begin exposure on either the rising edge or falling\n        edge of the trigger signal.\n\n        :type: :class:`TRIGGER_POLARITY<thorlabs_tsi_sdk.tl_camera_enums.TRIGGER_POLARITY>`\n        \"\"\"\n        try:\n            trigger_polarity = c_int()\n            error_code = self._sdk.tl_camera_get_trigger_polarity(self._camera, trigger_polarity)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_get_trigger_polarity\", error_code))\n            return TRIGGER_POLARITY(int(trigger_polarity.value))\n        except Exception as exception:\n            _logger.error(\"Could not get trigger polarity; \" + str(exception))\n            raise exception",
  "def trigger_polarity(self, trigger_polarity_enum):\n        try:\n            c_value = c_int(int(trigger_polarity_enum))\n            error_code = self._sdk.tl_camera_set_trigger_polarity(self._camera, c_value)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_set_trigger_polarity\", error_code))\n        except Exception as exception:\n            _logger.error(\"Could not set trigger polarity; \" + str(exception))\n            raise exception",
  "def binx(self):\n        \"\"\"\n        The current horizontal binning value.\n\n        :type: int\n        \"\"\"\n        try:\n            binx = c_int()\n            error_code = self._sdk.tl_camera_get_binx(self._camera, binx)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_get_binx\", error_code))\n            return int(binx.value)\n        except Exception as exception:\n            _logger.error(\"Could not get bin x; \" + str(exception))\n            raise exception",
  "def binx(self, binx):\n        try:\n            c_value = c_int(binx)\n            error_code = self._sdk.tl_camera_set_binx(self._camera, c_value)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_set_binx\", error_code))\n        except Exception as exception:\n            _logger.error(\"Could not set bin x; \" + str(exception))\n            raise exception",
  "def sensor_readout_time_ns(self):\n        \"\"\"\n        The time, in nanoseconds (ns), that readout data from image sensor. This property is Read-Only.\n\n        :type: int\n        \"\"\"\n        try:\n            sensor_readout_time_ns = c_int()\n            error_code = self._sdk.tl_camera_get_sensor_readout_time(self._camera, sensor_readout_time_ns)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_get_sensor_readout_time\",\n                                                              error_code))\n            return int(sensor_readout_time_ns.value)\n        except Exception as exception:\n            _logger.error(\"Could not get sensor readout time; \" + str(exception))\n            raise exception",
  "def binx_range(self):\n        \"\"\"\n        The binning ratio in the X direction can be determined with this property. By default, binning is set to one in\n        both X and Y directions.\n        This property is Read-Only. To set binx, see :attr:`binx<thorlabs_tsi_sdk.tl_camera.TLCamera.binx>`.\n\n        :type: Range\n        \"\"\"\n        try:\n            hbin_min = c_int()\n            hbin_max = c_int()\n            error_code = self._sdk.tl_camera_get_binx_range(self._camera, hbin_min, hbin_max)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_get_binx_range\", error_code))\n            return Range(int(hbin_min.value), int(hbin_max.value))\n        except Exception as exception:\n            _logger.error(\"Could not get bin x range; \" + str(exception))\n            raise exception",
  "def is_hot_pixel_correction_enabled(self):\n        \"\"\"\n        Due to variability in manufacturing, some pixels have inherently higher dark current which manifests as\n        abnormally bright pixels in images, typically visible with longer exposures. Hot-pixel correction identifies\n        hot pixels and then substitutes a calculated value based on the values of neighboring pixels in place of hot\n        pixels.\n        This property enables or disables hot-pixel correction.\n        If the connected camera supports hot-pixel correction, the threshold-range maximum will be greater than zero.\n\n        :type: bool\n        \"\"\"\n        try:\n            is_hot_pixel_correction_enabled = c_int()\n            error_code = self._sdk.tl_camera_get_is_hot_pixel_correction_enabled(self._camera,\n                                                                                 is_hot_pixel_correction_enabled)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk,\n                                                              \"tl_camera_get_is_hot_pixel_correction_enabled\",\n                                                              error_code))\n            return bool(is_hot_pixel_correction_enabled.value)\n        except Exception as exception:\n            _logger.error(\"Could not get is hot pixel correction enabled; \" + str(exception))\n            raise exception",
  "def is_hot_pixel_correction_enabled(self, is_hot_pixel_correction_enabled):\n        try:\n            c_value = c_int(is_hot_pixel_correction_enabled)\n            error_code = self._sdk.tl_camera_set_is_hot_pixel_correction_enabled(self._camera, c_value)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk,\n                                                              \"tl_camera_set_is_hot_pixel_correction_enabled\",\n                                                              error_code))\n        except Exception as exception:\n            _logger.error(\"Could not set is hot pixel correction enabled; \" + str(exception))\n            raise exception",
  "def hot_pixel_correction_threshold(self):\n        \"\"\"\n        Due to variability in manufacturing, some pixels have inherently higher dark current which manifests as\n        abnormally bright pixels in images, typically visible with longer exposures. Hot-pixel correction identifies\n        hot pixels and then substitutes a calculated value based on the values of neighboring pixels in place of hot\n        pixels.\n        This property may be used to get or set the hot-pixel correction threshold within the available range.\n        To determine the available range, query the\n        :attr:`hot_pixel_correction_threshold_range<thorlabs_tsi_sdk.tl_camera.TLCamera.hot_pixel_correction_threshold_range>` property.\n        If the threshold range maximum is zero, the connected camera does not support hot-pixel correction.\n        To enable hot-pixel correction, use\n        :attr:`is_hot_pixel_correction_enabled<thorlabs_tsi_sdk.tl_camera.TLCamera.is_hot_pixel_correction_enabled>`.\n\n        :type: int\n        \"\"\"\n        try:\n            hot_pixel_correction_threshold = c_int()\n            error_code = self._sdk.tl_camera_get_hot_pixel_correction_threshold(self._camera,\n                                                                                hot_pixel_correction_threshold)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_get_hot_pixel_correction_threshold\",\n                                                              error_code))\n            return int(hot_pixel_correction_threshold.value)\n        except Exception as exception:\n            _logger.error(\"Could not get hot pixel correction threshold; \" + str(exception))\n            raise exception",
  "def hot_pixel_correction_threshold(self, hot_pixel_correction_threshold):\n        try:\n            c_value = c_int(hot_pixel_correction_threshold)\n            error_code = self._sdk.tl_camera_set_hot_pixel_correction_threshold(self._camera, c_value)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_set_hot_pixel_correction_threshold\",\n                                                              error_code))\n        except Exception as exception:\n            _logger.error(\"Could not set hot pixel correction threshold; \" + str(exception))\n            raise exception",
  "def hot_pixel_correction_threshold_range(self):\n        \"\"\"\n        The range of acceptable hot pixel correction threshold values. If the maximum value is zero, that is an\n        indication that hot pixel correction is not supported by the camera. This property is Read-Only.\n\n        :type: Range\n        \"\"\"\n        try:\n            hot_pixel_correction_threshold_min = c_int()\n            hot_pixel_correction_threshold_max = c_int()\n            error_code = self._sdk.tl_camera_get_hot_pixel_correction_threshold_range(\n                self._camera,\n                hot_pixel_correction_threshold_min,\n                hot_pixel_correction_threshold_max)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk,\n                                                              \"tl_camera_get_hot_pixel_correction_threshold_range\",\n                                                              error_code))\n            return Range(int(hot_pixel_correction_threshold_min.value), int(hot_pixel_correction_threshold_max.value))\n        except Exception as exception:\n            _logger.error(\"Could not get hot pixel correction threshold range; \" + str(exception))\n            raise exception",
  "def sensor_width_pixels(self):\n        \"\"\"\n        This property provides the physical width of the camera sensor in pixels. This is equivalent to the\n        ROI-height-range maximum value. This property is Read-Only.\n\n        :type: int\n        \"\"\"\n        try:\n            sensor_width_pixels = c_int()\n            error_code = self._sdk.tl_camera_get_sensor_width(self._camera, sensor_width_pixels)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_get_sensor_width\", error_code))\n            return int(sensor_width_pixels.value)\n        except Exception as exception:\n            _logger.error(\"Could not get sensor width; \" + str(exception))\n            raise exception",
  "def gain_range(self):\n        \"\"\"\n        The range of possible gain values. This property is Read-Only.\n\n        :type: Range\n        \"\"\"\n        try:\n            gain_min = c_int()\n            gain_max = c_int()\n            error_code = self._sdk.tl_camera_get_gain_range(self._camera, gain_min, gain_max)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_get_gain_range\", error_code))\n            return Range(int(gain_min.value), int(gain_max.value))\n        except Exception as exception:\n            _logger.error(\"Could not get gain range; \" + str(exception))\n            raise exception",
  "def image_width_range_pixels(self):\n        \"\"\"\n        The range of possible image width values. This property is Read-Only.\n\n        :type: Range\n        \"\"\"\n        try:\n            image_width_pixels_min = c_int()\n            image_width_pixels_max = c_int()\n            error_code = self._sdk.tl_camera_get_image_width_range(self._camera,\n                                                                   image_width_pixels_min,\n                                                                   image_width_pixels_max)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_get_image_width_range\", error_code))\n            return Range(int(image_width_pixels_min.value), int(image_width_pixels_max.value))\n        except Exception as exception:\n            _logger.error(\"Could not get image width range; \" + str(exception))\n            raise exception",
  "def sensor_height_pixels(self):\n        \"\"\"\n        This property provides the physical height of the camera sensor in pixels. It is equivalent to the\n        ROI-width-range-maximum value. This property is Read-Only.\n\n        :type: int\n        \"\"\"\n        try:\n            sensor_height_pixels = c_int()\n            error_code = self._sdk.tl_camera_get_sensor_height(self._camera, sensor_height_pixels)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_get_sensor_height\", error_code))\n            return int(sensor_height_pixels.value)\n        except Exception as exception:\n            _logger.error(\"Could not get sensor height; \" + str(exception))\n            raise exception",
  "def image_height_range_pixels(self):\n        \"\"\"\n        The range of possible image height values. This property is Read-Only.\n\n        :type: Range\n        \"\"\"\n        try:\n            image_height_pixels_min = c_int()\n            image_height_pixels_max = c_int()\n            error_code = self._sdk.tl_camera_get_image_height_range(self._camera,\n                                                                    image_height_pixels_min,\n                                                                    image_height_pixels_max)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_get_image_height_range\",\n                                                              error_code))\n            return Range(int(image_height_pixels_min.value), int(image_height_pixels_max.value))\n        except Exception as exception:\n            _logger.error(\"Could not get image height range; \" + str(exception))\n            raise exception",
  "def model(self):\n        \"\"\"\n        Gets the camera model number such as 1501M or 8051C. This property is Read-Only.\n\n        :type: str\n        \"\"\"\n        try:\n            model = create_string_buffer(_STRING_MAX)\n            error_code = self._sdk.tl_camera_get_model(self._camera, model, c_int(_STRING_MAX))\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_get_model\", error_code))\n            return str(model.value.decode(\"utf-8\"))\n        except Exception as exception:\n            _logger.error(\"Could not get camera model; \" + str(exception))\n            raise exception",
  "def name(self):\n        \"\"\"\n        Cameras can always be distinguished from each other by their serial numbers and/or model. A camera can also be\n        named to distinguish between them. For example, if using a two-camera system, cameras may be named \"Left\" and\n        \"Right.\"\n\n        :type: str\n        \"\"\"\n        try:\n            name = create_string_buffer(_STRING_MAX)\n            error_code = self._sdk.tl_camera_get_name(self._camera, name, c_int(_STRING_MAX))\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_get_name\", error_code))\n            return str(name.value.decode(\"utf-8\"))\n        except Exception as exception:\n            _logger.error(\"Could not get camera name; \" + str(exception))\n            raise exception",
  "def name(self, name):\n        try:\n            c_value = create_string_buffer(str(name).encode('utf-8') + b'\\0', len(name) + 1)\n            error_code = self._sdk.tl_camera_set_name(self._camera, c_value)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_set_name\", error_code))\n        except Exception as exception:\n            _logger.error(\"Could not set camera name; \" + str(exception))\n            raise exception",
  "def name_string_length_range(self):\n        \"\"\"\n        The minimum and maximum string lengths allowed for setting the camera's name.\n\n        :type: Range\n        \"\"\"\n        try:\n            name_string_length_min = c_int()\n            name_string_length_max = c_int()\n            error_code = self._sdk.tl_camera_get_name_string_length_range(self._camera,\n                                                                          name_string_length_min,\n                                                                          name_string_length_max)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_get_name_string_length_range\",\n                                                              error_code))\n            return Range(int(name_string_length_min.value), int(name_string_length_max.value))\n        except Exception as exception:\n            _logger.error(\"Could not get name string length range; \" + str(exception))\n            raise exception",
  "def frames_per_trigger_zero_for_unlimited(self):\n        \"\"\"\n        The number of frames generated per software or hardware trigger can be unlimited or finite.\n        If set to zero, the camera will self-trigger indefinitely, allowing a continuous video feed.\n        If set to one or higher, a single software or hardware trigger will generate only the prescribed number of\n        frames and then stop.\n\n        :type: int\n        \"\"\"\n        try:\n            number_of_frames_per_trigger_or_zero_for_unlimited = c_uint()\n            error_code = self._sdk.tl_camera_get_frames_per_trigger_zero_for_unlimited(\n                self._camera, number_of_frames_per_trigger_or_zero_for_unlimited)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk,\n                                                              \"tl_camera_get_frames_per_trigger_zero_for_unlimited\",\n                                                              error_code))\n            return int(number_of_frames_per_trigger_or_zero_for_unlimited.value)\n        except Exception as exception:\n            _logger.error(\"Could not get frames per trigger; \" + str(exception))\n            raise exception",
  "def frames_per_trigger_zero_for_unlimited(self, number_of_frames_per_trigger_zero_for_unlimited):\n        try:\n            c_value = c_uint(number_of_frames_per_trigger_zero_for_unlimited)\n            error_code = self._sdk.tl_camera_set_frames_per_trigger_zero_for_unlimited(self._camera, c_value)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk,\n                                                              \"tl_camera_set_frames_per_trigger_zero_for_unlimited\",\n                                                              error_code))\n        except Exception as exception:\n            _logger.error(\"Could not set number of frames per trigger; \" + str(exception))\n            raise exception",
  "def frames_per_trigger_range(self):\n        \"\"\"\n        The number of frames generated per software or hardware trigger can be unlimited or finite.\n        If set to zero, the camera will self-trigger indefinitely, allowing a continuous video feed.\n        If set to one or higher, a single software or hardware trigger will generate only the prescribed number of\n        frames and then stop.\n        This property returns the valid range for\n        :attr:`frames_per_trigger_zero_for_unlimited<thorlabs_tsi_sdk.tl_camera.TLCamera.frames_per_trigger_zero_for_unlimited>`.\n        This property is Read-Only.\n\n        :type: Range\n        \"\"\"\n        try:\n            number_of_frames_per_trigger_min = c_uint()\n            number_of_frames_per_trigger_max = c_uint()\n            error_code = self._sdk.tl_camera_get_frames_per_trigger_range(self._camera,\n                                                                          number_of_frames_per_trigger_min,\n                                                                          number_of_frames_per_trigger_max)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_get_frames_per_trigger_range\",\n                                                              error_code))\n            return Range(int(number_of_frames_per_trigger_min.value), int(number_of_frames_per_trigger_max.value))\n        except Exception as exception:\n            _logger.error(\"Could not get frames per trigger range; \" + str(exception))\n            raise exception",
  "def usb_port_type(self):\n        \"\"\"\n        The :class:`USB_PORT_TYPE<thorlabs_tsi_sdk.tl_camera_enums.USB_PORT_TYPE>` enumeration defines the values the SDK uses for specifying the USB\n        port type.\n        These values are returned by SDK API functions and callbacks based on the type of physical USB port that the\n        device is connected to.\n        This property is Read-Only.\n\n        :type: :class:`USB_PORT_TYPE<thorlabs_tsi_sdk.tl_camera_enums.USB_PORT_TYPE>`\n        \"\"\"\n        try:\n            usb_port_type = c_int()\n            error_code = self._sdk.tl_camera_get_usb_port_type(self._camera, usb_port_type)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_get_usb_port_type\", error_code))\n            return USB_PORT_TYPE(usb_port_type.value)\n        except Exception as exception:\n            _logger.error(\"Could not get usb port type; \" + str(exception))\n            raise exception",
  "def communication_interface(self):\n        \"\"\"\n        This property describes the computer interface type, such as USB, GigE, or CameraLink. This property is\n        Read-Only.\n\n        :type: :class:`COMMUNICATION_INTERFACE<thorlabs_tsi_sdk.tl_camera_enums.COMMUNICATION_INTERFACE>`\n        \"\"\"\n        try:\n            communication_interface = c_int()\n            error_code = self._sdk.tl_camera_get_communication_interface(self._camera, communication_interface)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_get_communication_interface\",\n                                                              error_code))\n            return COMMUNICATION_INTERFACE(communication_interface.value)\n        except Exception as exception:\n            _logger.error(\"Could not get communication interface; \" + str(exception))\n            raise exception",
  "def operation_mode(self):\n        \"\"\"\n        Thorlabs scientific cameras can be software- or hardware-triggered.\n        To run continuous-video mode, set\n        :attr:`frames_per_trigger_zero_for_unlimited<thorlabs_tsi_sdk.tl_camera.TLCamera.frames_per_trigger_zero_for_unlimited>` to zero and\n        :attr:`operation_mode<thorlabs_tsi_sdk.tl_camera.TLCamera.operation_mode>` to SOFTWARE_TRIGGERED.\n        To issue individual software triggers, set\n        :attr:`frames_per_trigger_zero_for_unlimited<thorlabs_tsi_sdk.tl_camera.TLCamera.frames_per_trigger_zero_for_unlimited>` to a number\n        greater than zero and :attr:`operation_mode<thorlabs_tsi_sdk.tl_camera.TLCamera.operation_mode>` to SOFTWARE_TRIGGERED.\n        To trigger frames using the hardware trigger input, set :attr:`operation_mode<thorlabs_tsi_sdk.tl_camera.TLCamera.operation_mode>` mode\n        to HARDWARE_TRIGGERED. In this mode, the :attr:`exposure_time_us<thorlabs_tsi_sdk.tl_camera.TLCamera.exposure_time_us>` property is\n        used to determine the length of the exposure.\n        To trigger frames using the hardware trigger input and to determine the exposure length with that signal, set\n        :attr:`operation_mode<thorlabs_tsi_sdk.tl_camera.TLCamera.operation_mode>` to BULB.\n\n        :type: :class:`OPERATION_MODE<thorlabs_tsi_sdk.tl_camera_enums.OPERATION_MODE>`\n        \"\"\"\n        try:\n            operation_mode = c_int()\n            error_code = self._sdk.tl_camera_get_operation_mode(self._camera, operation_mode)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_get_operation_mode\", error_code))\n            return OPERATION_MODE(operation_mode.value)\n        except Exception as exception:\n            _logger.error(\"Could not get operation mode; \" + str(exception))\n            raise exception",
  "def operation_mode(self, operation_mode):\n        try:\n            c_value = c_int(operation_mode)\n            error_code = self._sdk.tl_camera_set_operation_mode(self._camera, c_value)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_set_operation_mode\", error_code))\n        except Exception as exception:\n            _logger.error(\"Could not set operation mode; \" + str(exception))\n            raise exception",
  "def is_armed(self):\n        \"\"\"\n        Prior to issuing software or hardware triggers to get images from a camera, call :meth:`arm()<thorlabs_tsi_sdk.tl_camera.TLCamera.arm>`\n        to prepare it for imaging. This property indicates whether :meth:`arm()<thorlabs_tsi_sdk.tl_camera.TLCamera.arm>` has been called.\n        This property is Read-Only.\n\n        :type: bool\n        \"\"\"\n        try:\n            is_armed = c_bool()\n            error_code = self._sdk.tl_camera_get_is_armed(self._camera, is_armed)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_get_is_armed\", error_code))\n            return bool(is_armed.value)\n        except Exception as exception:\n            _logger.error(\"Could not get is armed; \" + str(exception))\n            raise exception",
  "def is_eep_supported(self):\n        \"\"\"\n        Equal Exposure Pulse (EEP) mode is an LVTTL-level signal that is active between the time when all rows have\n        been reset during rolling reset, and the end of the exposure time (and the beginning of rolling readout). The\n        signal can be used to control an external light source that will be triggered on only during the equal exposure\n        period, providing the same amount of exposure for all pixels in the ROI.\n\n        This property determines whether the connected camera supports EEP mode. This property is Read-Only. To\n        activate EEP mode, see :attr:`is_eep_enabled<thorlabs_tsi_sdk.tl_camera.TLCamera.is_eep_enabled>`\n\n        :type: bool\n        \"\"\"\n        try:\n            is_eep_supported = c_bool()\n            error_code = self._sdk.tl_camera_get_is_eep_supported(self._camera, is_eep_supported)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_get_is_eep_supported\", error_code))\n            return bool(is_eep_supported.value)\n        except Exception as exception:\n            _logger.error(\"Could not get is eep supported; \" + str(exception))\n            raise exception",
  "def is_led_supported(self):\n        \"\"\"\n        Some scientific cameras include an LED indicator light on the back panel.\n        This property is Read-Only. Use :attr:`is_led_supported<thorlabs_tsi_sdk.tl_camera.TLCamera.is_led_supported>` to determine whether the\n        connected camera has an LED indicator.\n\n        :type: bool\n        \"\"\"\n        try:\n            is_led_supported = c_bool()\n            error_code = self._sdk.tl_camera_get_is_led_supported(self._camera, is_led_supported)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_is_led_supported\", error_code))\n            return bool(is_led_supported.value)\n        except Exception as exception:\n            _logger.error(\"Could not get is led supported; \" + str(exception))\n            raise exception",
  "def is_cooling_supported(self):\n        \"\"\"\n        All Thorlabs scientific cameras are designed to efficiently dissipate heat. Some models additionally provide\n        active cooling. Use this property to determine whether the connected camera supports active cooling.\n\n        This property is Read-Only.\n\n        :type: bool\n        \"\"\"\n        try:\n            is_cooling_supported = c_bool()\n            error_code = self._sdk.tl_camera_get_is_cooling_supported(self._camera, is_cooling_supported)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_get_is_cooling_supported\",\n                                                              error_code))\n            return bool(is_cooling_supported.value)\n        except Exception as exception:\n            _logger.error(\"Could not get is cooling supported; \" + str(exception))\n            raise exception",
  "def is_cooling_enabled(self):\n        \"\"\"\n        All Thorlabs scientific cameras are designed to efficiently dissipate heat. Some models additionally provide\n        active cooling via a Thermoelectric Cooler (TEC). Cameras with TECs have an additional power cable to power the\n        cooler. When the cable is plugged in, the TEC will start cooling. When the cable is unplugged, the TEC will stop\n        and the camera will not have active cooling. Use this property to determine via software whether the TEC cable\n        is plugged in or not.\n\n        This property is Read-Only.\n\n        :type: bool\n        \"\"\"\n        try:\n            is_cooling_enabled = c_bool()\n            error_code = self._sdk.tl_camera_get_cooling_enable(self._camera, is_cooling_enabled)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_get_cooling_enable\",\n                                                              error_code))\n            return bool(is_cooling_enabled.value)\n        except Exception as exception:\n            _logger.error(\"Could not get cooling enable; \" + str(exception))\n            raise exception",
  "def is_nir_boost_supported(self):\n        \"\"\"\n        Some scientific-CCD camera models offer an enhanced near-infrared imaging mode for wavelengths in the 500 to\n        1000nm range. The Thorlabs website includes a helpful overview of this camera function on the Camera Basics\n        page: https://www.thorlabs.com/newgrouppage9.cfm?objectgroup_id=8962\n\n        This property enables or disables NIR-boost mode. This property is Read-Only.\n\n        :type: bool\n        \"\"\"\n        try:\n            is_nir_boost_supported = c_bool()\n            error_code = self._sdk.tl_camera_get_is_nir_boost_supported(self._camera, is_nir_boost_supported)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_is_nir_boost_supported\",\n                                                              error_code))\n            return bool(is_nir_boost_supported.value)\n        except Exception as exception:\n            _logger.error(\"Could not get is nir boost supported; \" + str(exception))\n            raise exception",
  "def camera_sensor_type(self):\n        \"\"\"\n        The camera sensor type. This property is Read-Only.\n\n        :type: :class:`SENSOR_TYPE<thorlabs_tsi_sdk.tl_camera_enums.SENSOR_TYPE>`\n        \"\"\"\n        try:\n            camera_sensor_type = c_int()\n            error_code = self._sdk.tl_camera_get_camera_sensor_type(self._camera, camera_sensor_type)\n            if error_code != 0:\n                raise TLCameraError(\n                    _create_c_failure_message(self._sdk, \"tl_camera_get_camera_sensor_type\", error_code))\n            return SENSOR_TYPE(camera_sensor_type.value)\n        except Exception as exception:\n            _logger.error(\"Could not get camera sensor type; \" + str(exception))\n            raise exception",
  "def color_filter_array_phase(self):\n        \"\"\"\n        This describes the :class:`color filter array phase<thorlabs_tsi_sdk.tl_color_enums.FILTER_ARRAY_PHASE>` for the camera.\n        This property is Read-Only.\n\n        :type: :class:`FILTER_ARRAY_PHASE<thorlabs_tsi_sdk.tl_color_enums.FILTER_ARRAY_PHASE>`\n        \"\"\"\n        try:\n            color_filter_array_phase = c_int()\n            error_code = self._sdk.tl_camera_get_color_filter_array_phase(self._camera, color_filter_array_phase)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_get_color_filter_array_phase\",\n                                                              error_code))\n            return FILTER_ARRAY_PHASE(color_filter_array_phase.value)\n        except Exception as exception:\n            _logger.error(\"Could not get color filter array phase; \" + str(exception))\n            raise exception",
  "def camera_color_correction_matrix_output_color_space(self):\n        \"\"\"\n        This describes the camera color correction matrix output color space. This property is Read-Only.\n\n        :type: str\n        \"\"\"\n        try:\n            color_correction_matrix_output_color_space = create_string_buffer(_STRING_MAX)\n            error_code = self._sdk.tl_camera_get_camera_color_correction_matrix_output_color_space(\n                self._camera,\n                color_correction_matrix_output_color_space)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(\n                    self._sdk, \"tl_camera_get_camera_color_correction_matrix_output_color_space\", error_code))\n            return str(color_correction_matrix_output_color_space.value.decode('utf-8'))\n        except Exception as exception:\n            _logger.error(\"Could not get camera color correction matrix output color space; \" + str(exception))\n            raise exception",
  "def data_rate(self):\n        \"\"\"\n        This property sets or gets the sensor-level data rate. Scientific-CCD cameras offer data rates of 20MHz or\n        40MHz. Compact-scientific cameras offer FPS30 or FPS50, which are frame rates supported by the camera when\n        doing full-frame readout. The actual rate can vary if a region of interest (ROI) or binning is set or if the\n        host computer cannot keep up with the camera.\n        To test whether the connected camera supports a particular data rate, use\n        :meth:`get_is_data_rate_supported<thorlabs_tsi_camera.tl_camera.TLCamera.get_is_data_rate_supported>`.\n\n        :type: :class:`DATA_RATE<thorlabs_tsi_sdk.tl_camera_enums.DATA_RATE>`\n        \"\"\"\n        try:\n            data_rate = c_int()\n            error_code = self._sdk.tl_camera_get_data_rate(self._camera, data_rate)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_get_data_rate\", error_code))\n            return DATA_RATE(data_rate.value)\n        except Exception as exception:\n            _logger.error(\"Could not get data rate; \" + str(exception))\n            raise exception",
  "def data_rate(self, data_rate):\n        try:\n            c_value = c_int(data_rate)\n            error_code = self._sdk.tl_camera_set_data_rate(self._camera, c_value)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_set_data_rate\", error_code))\n        except Exception as exception:\n            _logger.error(\"Could not set data rate; \" + str(exception))\n            raise exception",
  "def sensor_pixel_size_bytes(self):\n        \"\"\"\n        The pixel size of the camera's sensor in bytes. This represents the amount of space 1 pixel will occupy in the\n        frame buffer. This property is Read-Only.\n\n        :type: int\n        \"\"\"\n        try:\n            sensor_pixel_size_bytes = c_int()\n            error_code = self._sdk.tl_camera_get_sensor_pixel_size_bytes(self._camera, sensor_pixel_size_bytes)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_get_sensor_pixel_size_bytes\",\n                                                              error_code))\n            return int(sensor_pixel_size_bytes.value)\n        except Exception as exception:\n            _logger.error(\"Could not get sensor pixel size bytes; \" + str(exception))\n            raise exception",
  "def sensor_pixel_width_um(self):\n        \"\"\"\n        This property provides the physical width of a single light-sensitive photo site on the sensor. This property is\n        Read-Only.\n\n        :type: float\n        \"\"\"\n        try:\n            sensor_pixel_width_um = c_double()\n            error_code = self._sdk.tl_camera_get_sensor_pixel_width(self._camera, sensor_pixel_width_um)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_get_sensor_pixel_width\",\n                                                              error_code))\n            return float(sensor_pixel_width_um.value)\n        except Exception as exception:\n            _logger.error(\"Could not get sensor pixel width; \" + str(exception))\n            raise exception",
  "def sensor_pixel_height_um(self):\n        \"\"\"\n        This property provides the physical height of a single light-sensitive photo site on the sensor. This property\n        is Read-Only.\n\n        :type: float\n        \"\"\"\n        try:\n            sensor_pixel_height_um = c_double()\n            error_code = self._sdk.tl_camera_get_sensor_pixel_height(self._camera, sensor_pixel_height_um)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_get_sensor_pixel_height\",\n                                                              error_code))\n            return float(sensor_pixel_height_um.value)\n        except Exception as exception:\n            _logger.error(\"Could not get sensor pixel height; \" + str(exception))\n            raise exception",
  "def bit_depth(self):\n        \"\"\"\n        The number of bits to which a pixel value is digitized on a camera.\n        In the image data that is delivered to the host application, the bit depth indicates how many of the lower bits\n        of each 16-bit ushort value are relevant.\n        While most cameras operate at a fixed bit depth, some are reduced when data bandwidth limitations would\n        otherwise restrict the frame rate. Please consult the camera manual and specification for details about a\n        specific model.\n\n        :type: int\n        \"\"\"\n        try:\n            pixel_bit_depth = c_int()\n            error_code = self._sdk.tl_camera_get_bit_depth(self._camera, pixel_bit_depth)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_get_bit_depth\", error_code))\n            return int(pixel_bit_depth.value)\n        except Exception as exception:\n            _logger.error(\"Could not get bit depth; \" + str(exception))\n            raise exception",
  "def roi(self):\n        \"\"\"\n        By default, the region of interest (ROI) is the same as the sensor resolution. The region of interest can be\n        reduced to a smaller rectangle in order to focus on an area smaller than a full- frame image. In some cases,\n        reducing the ROI can increase the frame rate since less data needs to be transmitted to the host computer.\n        Binning sums adjacent sensor pixels into \"super pixels\". It trades off spatial resolution for sensitivity and\n        speed. For example, if a sensor is 1920 by 1080 pixels and binning is set to two in the X direction and two in\n        the Y direction, the resulting image will be 960 by 540 pixels. Since smaller images require less data to be\n        transmitted to the host computer, binning may increase the frame rate. By default, binning is set to one in\n        both horizontal and vertical directions. binning can be changed by setting :attr:`binx<thorlabs_tsi_sdk.tl_camera.TLCamera.binx>` or\n        :attr:`biny<thorlabs_tsi_sdk.tl_camera.TLCamera.biny>`. It can be different in the X direction than the Y direction, and the available\n        ranges vary by camera model.\n\n        To determine the available ROI ranges, use the :attr:`roi_range<thorlabs_tsi_sdk.tl_camera.TLCamera.roi_range>`.\n\n        :type: ROI\n        \"\"\"\n        try:\n            upper_left_x_pixels = c_int()\n            upper_left_y_pixels = c_int()\n            lower_right_x_pixels = c_int()\n            lower_right_y_pixels = c_int()\n            error_code = self._sdk.tl_camera_get_roi(self._camera,\n                                                     upper_left_x_pixels, upper_left_y_pixels,\n                                                     lower_right_x_pixels, lower_right_y_pixels)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_get_roi\", error_code))\n            return ROI(int(upper_left_x_pixels.value), int(upper_left_y_pixels.value),\n                       int(lower_right_x_pixels.value), int(lower_right_y_pixels.value))\n        except Exception as exception:\n            _logger.error(\"Could not get ROI; \" + str(exception))\n            raise exception",
  "def roi(self, roi):\n        try:\n            # noinspection PyUnusedLocal\n            error_code = 0\n            try:\n                upper_left_x_pixels, upper_left_y_pixels, lower_right_x_pixels, lower_right_y_pixels = roi\n                c_value_upper_left_x = c_int(upper_left_x_pixels)\n                c_value_upper_left_y = c_int(upper_left_y_pixels)\n                c_value_lower_right_x = c_int(lower_right_x_pixels)\n                c_value_lower_right_y = c_int(lower_right_y_pixels)\n                error_code = self._sdk.tl_camera_set_roi(self._camera,\n                                                         c_value_upper_left_x, c_value_upper_left_y,\n                                                         c_value_lower_right_x, c_value_lower_right_y)\n            except ValueError as value_error:\n                _logger.error(\"To set ROI use an iterable with 4 integers:\\n\"\n                              \"camera.roi = (upper_left_x_pixels, upper_left_y_pixels, \"\n                              \"lower_right_x_pixels, lower_right_y_pixels)\\n\")\n                raise value_error\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_set_roi\", error_code))\n        except Exception as exception:\n            _logger.error(\"Could not set ROI; \" + str(exception))\n            raise exception",
  "def roi_range(self):\n        \"\"\"\n        The rules for rectangular regions of interest (ROIs) vary by camera model. Please consult the camera\n        documentation for more details. The ROI height range indicates the smallest height to which an ROI can be set\n        up to a maximum of the sensor's vertical resolution. The ROI width range indicates the smallest width to which\n        an ROI can be set up to a maximum of the sensor's horizontal resolution.\n\n        This property is Read-Only. For setting the ROI, see :attr:`roi<thorlabs_tsi_sdk.tl_camera.TLCamera.roi>`.\n\n        :type: ROIRange\n        \"\"\"\n        try:\n            upper_left_x_pixels_min = c_int()\n            upper_left_y_pixels_min = c_int()\n            lower_right_x_pixels_min = c_int()\n            lower_right_y_pixels_min = c_int()\n            upper_left_x_pixels_max = c_int()\n            upper_left_y_pixels_max = c_int()\n            lower_right_x_pixels_max = c_int()\n            lower_right_y_pixels_max = c_int()\n            error_code = self._sdk.tl_camera_get_roi_range(self._camera,\n                                                           upper_left_x_pixels_min, upper_left_y_pixels_min,\n                                                           lower_right_x_pixels_min, lower_right_y_pixels_min,\n                                                           upper_left_x_pixels_max, upper_left_y_pixels_max,\n                                                           lower_right_x_pixels_max, lower_right_y_pixels_max)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_get_roi_range\", error_code))\n            return ROIRange(int(upper_left_x_pixels_min.value), int(upper_left_y_pixels_min.value),\n                            int(lower_right_x_pixels_min.value), int(lower_right_y_pixels_min.value),\n                            int(upper_left_x_pixels_max.value), int(upper_left_y_pixels_max.value),\n                            int(lower_right_x_pixels_max.value), int(lower_right_y_pixels_max.value))\n        except Exception as exception:\n            _logger.error(\"Could not get ROI range; \" + str(exception))\n            raise exception",
  "def serial_number(self):\n        \"\"\"\n        This property gets the unique identifier for a camera. This property is Read-Only.\n\n        :type: str\n        \"\"\"\n        try:\n            serial_number = create_string_buffer(_STRING_MAX)\n            error_code = self._sdk.tl_camera_get_serial_number(self._camera, serial_number, _STRING_MAX)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_get_serial_number\", error_code))\n            return str(serial_number.value.decode('utf-8'))\n        except Exception as exception:\n            _logger.error(\"Could not get serial number; \" + str(exception))\n            raise exception",
  "def serial_number_string_length_range(self):\n        \"\"\"\n        The minimum and maximum number of characters allowed in the serial number string. This property is Read-Only.\n\n        :type: Range\n        \"\"\"\n        try:\n            serial_number_string_length_min = c_int()\n            serial_number_string_length_max = c_int()\n            error_code = self._sdk.tl_camera_get_serial_number_string_length_range(self._camera,\n                                                                                   serial_number_string_length_min,\n                                                                                   serial_number_string_length_max)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(\n                    self._sdk, \"tl_camera_get_serial_number_string_length_range\", error_code))\n            return Range(int(serial_number_string_length_min.value), int(serial_number_string_length_max.value))\n        except Exception as exception:\n            _logger.error(\"Could not get serial number string length range; \" + str(exception))\n            raise exception",
  "def is_led_on(self):\n        \"\"\"\n        Some scientific cameras include an LED indicator light on the back panel. This property can be used to turn it\n        on or off.\n\n        :type: bool\n        \"\"\"\n        try:\n            is_led_on = c_bool()\n            error_code = self._sdk.tl_camera_get_is_led_on(self._camera, is_led_on)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_get_is_led_on\", error_code))\n            return bool(is_led_on.value)\n        except Exception as exception:\n            _logger.error(\"Could not get is led on; \" + str(exception))\n            raise exception",
  "def is_led_on(self, is_led_on):\n        try:\n            c_value = c_bool(is_led_on)\n            error_code = self._sdk.tl_camera_set_is_led_on(self._camera, c_value)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_set_is_led_on\", error_code))\n        except Exception as exception:\n            _logger.error(\"Could not set is led on; \" + str(exception))\n            raise exception",
  "def eep_status(self):\n        \"\"\"\n        Equal Exposure Pulse (EEP) mode is an LVTTL-level signal that is active during the time when all rows have been\n        reset during rolling reset, and the end of the exposure time (and the beginning of rolling readout). The signal\n        can be used to control an external light source that will be on only during the equal exposure period,\n        providing the same amount of exposure for all pixels in the ROI.\n\n        When EEP mode is disabled, the status will always be EEP_STATUS.OFF.\n        EEP mode can be enabled, but, depending on the exposure value, active or inactive.\n        If EEP is enabled in bulb mode, it will always give a status of BULB.\n\n        This property is Read-Only. To activate EEP mode, see :attr:`is_eep_enabled<thorlabs_tsi_sdk.tl_camera.TLCamera.is_eep_enabled>`\n\n        :type: :class:`EEP_STATUS<thorlabs_tsi_sdk.tl_camera_enums.EEP_STATUS>`\n        \"\"\"\n        try:\n            eep_status_enum = c_int()\n            error_code = self._sdk.tl_camera_get_eep_status(self._camera, eep_status_enum)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_get_eep_status\", error_code))\n            return EEP_STATUS(eep_status_enum.value)\n        except Exception as exception:\n            _logger.error(\"Could not get eep status; \" + str(exception))\n            raise exception",
  "def is_eep_enabled(self):\n        \"\"\"\n        Equal Exposure Pulse (EEP) mode is an LVTTL-level signal that is active between the time when all rows have\n        been reset during rolling reset, and the end of the exposure time (and the beginning of rolling readout). The\n        signal can be used to control an external light source that will be triggered on only during the equal exposure\n        period, providing the same amount of exposure for all pixels in the ROI.\n\n        Please see the camera specification for details on EEP mode.\n\n        When enabled, EEP mode will be active or inactive depending on the exposure duration.\n        Use :attr:`is_eep_supported<thorlabs_tsi_sdk.tl_camera.TLCamera.is_eep_supported>` to test whether the connected camera supports this\n        mode.\n        Use :attr:`eep_status<thorlabs_tsi_sdk.tl_camera.TLCamera.eep_status>` to see whether the mode is active, inactive, in bulb mode, or\n        disabled.\n\n        :type: bool\n        \"\"\"\n        try:\n            eep_status = self.eep_status\n            if eep_status == EEP_STATUS.DISABLED:\n                return False\n            else:\n                return True\n        except Exception as exception:\n            _logger.error(\"Could not get is eep enabled; \" + str(exception))\n            raise exception",
  "def is_eep_enabled(self, is_eep_enabled):\n        try:\n            c_value = c_int(is_eep_enabled)\n            error_code = self._sdk.tl_camera_set_is_eep_enabled(self._camera, c_value)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_set_is_eep_enabled\", error_code))\n        except Exception as exception:\n            _logger.error(\"Could not set is eep enabled; \" + str(exception))\n            raise exception",
  "def biny(self):\n        \"\"\"\n        The current vertical binning value.\n\n        :type: int\n        \"\"\"\n        try:\n            biny = c_int()\n            error_code = self._sdk.tl_camera_get_biny(self._camera, biny)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_get_biny\", error_code))\n            return int(biny.value)\n        except Exception as exception:\n            _logger.error(\"Could not get bin y; \" + str(exception))\n            raise exception",
  "def biny(self, biny):\n        try:\n            c_value = c_int(biny)\n            error_code = self._sdk.tl_camera_set_biny(self._camera, c_value)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_set_biny\", error_code))\n        except Exception as exception:\n            _logger.error(\"Could not set bin y; \" + str(exception))\n            raise exception",
  "def biny_range(self):\n        \"\"\"\n        The binning ratio in the Y direction can be determined with this property. By default, binning is set to one in\n        both X and Y directions.\n        This property is Read-Only. To set biny, see :attr:`biny<thorlabs_tsi_sdk.tl_camera.TLCamera.biny>`.\n\n        :type: Range\n        \"\"\"\n        try:\n            biny_min = c_int()\n            biny_max = c_int()\n            error_code = self._sdk.tl_camera_get_biny_range(self._camera, biny_min, biny_max)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_biny_range\", error_code))\n            return Range(int(biny_min.value), int(biny_max.value))\n        except Exception as exception:\n            _logger.error(\"Could not get biny range; \" + str(exception))\n            raise exception",
  "def gain(self):\n        \"\"\"\n        Gain refers to the scaling of pixel values up or down for a given amount of light. This scaling is applied\n        prior to digitization.\n        To determine the valid range of values, use the :attr:`gain_range<thorlabs_tsi_sdk.tl_camera.TLCamera.gain_range>` property.\n        If the :attr:`gain_range<thorlabs_tsi_sdk.tl_camera.TLCamera.gain_range>` maximum is zero, then Gain is not supported for the connected\n        camera.\n        The units of measure for Gain can vary by camera. Please consult the data sheet for the specific camera model.\n        Query the :attr:`gain_range<thorlabs_tsi_sdk.tl_camera.TLCamera.gain_range>` property to determine the possible values.\n\n        :type: int\n        \"\"\"\n        try:\n            gain = c_int()\n            error_code = self._sdk.tl_camera_get_gain(self._camera, gain)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_get_gain\", error_code))\n            return int(gain.value)\n        except Exception as exception:\n            _logger.error(\"Could not get gain; \" + str(exception))\n            raise exception",
  "def gain(self, gain):\n        try:\n            c_value = c_int(gain)\n            error_code = self._sdk.tl_camera_set_gain(self._camera, c_value)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_set_gain\", error_code))\n        except Exception as exception:\n            _logger.error(\"Could not set gain; \" + str(exception))\n            raise exception",
  "def black_level(self):\n        \"\"\"\n        Black level adds an offset to pixel values. If the connected camera supports black level, the\n        :attr:`black_level_range<thorlabs_tsi_sdk.tl_camera.TLCamera.black_level_range>` will have a maximum greater than zero.\n\n        :type: int\n        \"\"\"\n        try:\n            black_level = c_int()\n            error_code = self._sdk.tl_camera_get_black_level(self._camera, black_level)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_get_black_level\", error_code))\n            return int(black_level.value)\n        except Exception as exception:\n            _logger.error(\"Could not get black level; \" + str(exception))\n            raise exception",
  "def black_level(self, black_level):\n        try:\n            c_value = c_int(black_level)\n            error_code = self._sdk.tl_camera_set_black_level(self._camera, c_value)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_set_black_level\", error_code))\n        except Exception as exception:\n            _logger.error(\"Could not set black level; \" + str(exception))\n            raise exception",
  "def black_level_range(self):\n        \"\"\"\n        Black level adds an offset to pixel values. If black level is supported by a camera model, then this property\n        will have an upper range higher than zero.\n\n        black_level_range indicates the available values that can be used for the\n        :attr:`black_level<thorlabs_tsi_sdk.tl_camera.TLCamera.black_level>` property.\n\n        :type: Range\n        \"\"\"\n        try:\n            black_level_min = c_int()\n            black_level_max = c_int()\n            error_code = self._sdk.tl_camera_get_black_level_range(self._camera, black_level_min, black_level_max)\n            if error_code == 1002:\n                # Native library issue #\n                _logger.debug(\"Camera does not support black level range\")\n                return Range(0, 0)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_get_black_level_range\", error_code))\n            return Range(int(black_level_min.value), int(black_level_max.value))\n        except Exception as exception:\n            _logger.error(\"Could not get black level range; \" + str(exception))\n            raise exception",
  "def image_width_pixels(self):\n        \"\"\"\n        This property provides the image width in pixels. It is related to ROI width. This property is Read-Only.\n\n        :type: int\n        \"\"\"\n        try:\n            image_width_pixels = c_int()\n            error_code = self._sdk.tl_camera_get_image_width(self._camera, image_width_pixels)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_get_image_width\", error_code))\n            return int(image_width_pixels.value)\n        except Exception as exception:\n            _logger.error(\"Could not get image width; \" + str(exception))\n            raise exception",
  "def image_height_pixels(self):\n        \"\"\"\n        This property provides the image height in pixels. It is related to ROI height. This property is Read-Only.\n\n        :type: int\n        \"\"\"\n        try:\n            image_height_pixels = c_int()\n            error_code = self._sdk.tl_camera_get_image_height(self._camera, image_height_pixels)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_image_height_pixels\", error_code))\n            return int(image_height_pixels.value)\n        except Exception as exception:\n            _logger.error(\"Could not get image height; \" + str(exception))\n            raise exception",
  "def polar_phase(self):\n        \"\"\"\n        This describes how the polarization filter is aligned over the camera sensor. This property is only supported\n        in polarized cameras. In a polarized camera, each pixel is covered with one of four linear polarizers with\n        orientations of -45\u00b0, 0\u00b0, 45\u00b0, or 90\u00b0. The polar phase represents the origin pixel on the sensor. To determine\n        if a camera supports polarization, check the :attr:`camera_sensor_type<thorlabs_tsi_sdk.tl_camera.TLCamera.camera_sensor_type>`\n        property. This property is Read-Only.\n\n        :type: :class:`POLAR_PHASE<thorlabs_tsi_sdk.tl_polarization_enums.POLAR_PHASE>`\n        \"\"\"\n        try:\n            polar_phase_type = c_int()\n            error_code = self._sdk.tl_camera_get_polar_phase(self._camera, polar_phase_type)\n            if error_code != 0:\n                raise TLCameraError(\n                    _create_c_failure_message(self._sdk, \"tl_camera_get_polar_phase\", error_code))\n            return POLAR_PHASE(polar_phase_type.value)\n        except Exception as exception:\n            _logger.error(\"Could not get polar phase; \" + str(exception))\n            raise exception",
  "def frame_rate_control_value_range(self):\n        \"\"\"\n        Frame rate control will set the frames per second of the camera. If frame rate is supported by a camera model,\n        then this property will have an upper range higher than zero.\n\n        frame_rate_control_value_range indicates the available values that can be used for the\n        :attr:`frame_rate_control_value<thorlabs_tsi_sdk.tl_camera.TLCamera.frame_rate_control_value>` property.\n\n        :type: Range\n        \"\"\"\n        try:\n            frame_rate_control_min = c_double()\n            frame_rate_control_max = c_double()\n            error_code = self._sdk.tl_camera_get_frame_rate_control_value_range(self._camera, frame_rate_control_min, frame_rate_control_max)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_get_frame_rate_control_value_range\", error_code))\n            return Range(float(frame_rate_control_min.value), float(frame_rate_control_max.value))\n        except Exception as exception:\n            _logger.error(\"Could not get frame rate control value range; \" + str(exception))\n            raise exception",
  "def is_frame_rate_control_enabled(self):\n        \"\"\"\n        While frame rate control is enabled, the frames per second will be controlled by\n        :attr:`frame_rate_control_value<thorlabs_tsi_sdk.tl_camera.TLCamera.frame_rate_control_value>`.\n\n        The frame rate control adjusts the frame rate of the camera independent of exposure time, within certain\n        constraints. For short exposure times, the maximum frame rate is limited by the readout time of the sensor.\n        For long exposure times, the frame rate is limited by the exposure time.\n\n        This property enables or disables the frame rate control feature.\n        If the connected camera supports frame rate control, the threshold-range maximum will be greater than zero.\n\n        :type: bool\n        \"\"\"\n        try:\n            is_frame_rate_control_enabled = c_int()\n            error_code = self._sdk.tl_camera_get_is_frame_rate_control_enabled(self._camera,\n                                                                               is_frame_rate_control_enabled)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk,\n                                                              \"tl_camera_get_is_frame_rate_control_enabled\",\n                                                              error_code))\n            return bool(is_frame_rate_control_enabled.value)\n        except Exception as exception:\n            _logger.error(\"Could not get is frame rate control enabled; \" + str(exception))\n            raise exception",
  "def is_frame_rate_control_enabled(self, is_frame_rate_control_enabled):\n        try:\n            c_value = c_int(is_frame_rate_control_enabled)\n            error_code = self._sdk.tl_camera_set_is_frame_rate_control_enabled(self._camera, c_value)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk,\n                                                              \"tl_camera_set_is_frame_rate_control_enabled\",\n                                                              error_code))\n        except Exception as exception:\n            _logger.error(\"Could not set is frame rate control enabled; \" + str(exception))\n            raise exception",
  "def frame_rate_control_value(self):\n        \"\"\"\n        The frame rate control adjusts the frame rate of the camera independent of exposure time, within certain\n        constraints. For short exposure times, the maximum frame rate is limited by the readout time of the sensor.\n        For long exposure times, the frame rate is limited by the exposure time.\n\n        :type: float\n        \"\"\"\n        try:\n            frame_rate_control = c_double()\n            error_code = self._sdk.tl_camera_get_frame_rate_control_value(self._camera, frame_rate_control)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_get_frame_rate_control_value\",\n                                                              error_code))\n            return float(frame_rate_control.value)\n        except Exception as exception:\n            _logger.error(\"Could not get frame rate control; \" + str(exception))\n            raise exception",
  "def frame_rate_control_value(self, frame_rate_control_value_fps):\n        try:\n            c_value = c_double(frame_rate_control_value_fps)\n            error_code = self._sdk.tl_camera_set_frame_rate_control_value(self._camera, c_value)\n            if error_code != 0:\n                raise TLCameraError(_create_c_failure_message(self._sdk, \"tl_camera_set_frame_rate_control_value\",\n                                                              error_code))\n        except Exception as exception:\n            _logger.error(\"Could not set frame rate control value; \" + str(exception))\n            raise exception",
  "def __init__(self, message):\n        _logger.debug(message)\n        super(TLCameraError, self).__init__(message)",
  "def camera_connect_callback(camera_serial_number, usb_port_type, context):\n            _callback(str(camera_serial_number.decode('utf-8')), USB_PORT_TYPE(usb_port_type), *args, **kwargs)",
  "def camera_disconnect_callback(camera_serial_number, context):\n            _callback(str(camera_serial_number.decode('utf-8')), *args, **kwargs)",
  "class _CTypesEnum(IntEnum):\n    @classmethod\n    def from_param(cls, obj):\n        return int(obj)",
  "class OPERATION_MODE(_CTypesEnum):\n    \"\"\"\n    The OPERATION_MODE enumeration defines the available modes for a camera.\n\n    \"\"\"\n    SOFTWARE_TRIGGERED = 0\n    \"\"\"\n    Use software operation mode to generate one or more frames per trigger or to run continuous video mode.\n    \n    \"\"\"\n    HARDWARE_TRIGGERED = 1\n    \"\"\"\n    Use hardware triggering to generate one or more frames per trigger by issuing hardware signals.\n    \n    \"\"\"\n    BULB = 2\n    \"\"\"\n    Use bulb-mode triggering to generate one or more frames per trigger by issuing hardware signals. Please refer to \n    the camera manual for signaling details.\n    \n    \"\"\"\n    RESERVED1 = 3  # Reserved for internal use.\n    RESERVED2 = 4",
  "class SENSOR_TYPE(_CTypesEnum):\n    \"\"\"\n    This describes the physical capabilities of the camera sensor.\n\n    \"\"\"\n    MONOCHROME = 0\n    \"\"\"\n    Each pixel of the sensor indicates an intensity.\n    \n    \"\"\"\n    BAYER = 1\n    \"\"\"\n    The sensor has a bayer-patterned filter overlaying it, allowing the camera SDK to distinguish red, green, and blue \n    values.\n    \n    \"\"\"\n    MONOCHROME_POLARIZED = 2\n    \"\"\"\n     The sensor has a polarization filter overlaying it allowing the camera to capture polarization information from \n     the incoming light.\n\n    \"\"\"",
  "class TRIGGER_POLARITY(_CTypesEnum):\n    \"\"\"\n    The TRIGGER_POLARITY enumeration defines the options available for specifying the hardware trigger polarity. These\n    values specify which edge of the input trigger pulse that will initiate image acquisition.\n\n    \"\"\"\n    ACTIVE_HIGH = 0\n    \"\"\"\n    Acquire an image on the RISING edge of the trigger pulse.\n    \n    \"\"\"\n    ACTIVE_LOW = 1\n    \"\"\"\n    Acquire an image on the FALLING edge of the trigger pulse.\n\n    \"\"\"",
  "class EEP_STATUS(_CTypesEnum):\n    \"\"\"\n    The EEP_STATUS enumeration defines the options available for specifying the device's EEP mode. Equal Exposure Pulse\n    (EEP) mode is an LVTTL-level signal that is active during the time when all rows have been reset during rolling\n    reset, and the end of the exposure time (and the beginning of rolling readout). The signal can be used to control\n    an external light source that will be on only during the equal exposure period, providing the same amount of\n    exposure for all pixels in the ROI. EEP mode can be enabled, but may be active or inactive depending on the\n    current exposure value. If EEP is enabled in bulb mode, it will always give a status of Bulb.\n\n    \"\"\"\n    DISABLED = 0\n    \"\"\"\n    EEP mode is disabled.\n    \n    \"\"\"\n    ENABLED_ACTIVE = 1\n    \"\"\"\n    EEP mode is enabled and currently active.\n    \n    \"\"\"\n    ENABLED_INACTIVE = 2\n    \"\"\"\n    EEP mode is enabled, but due to an unsupported exposure value, currently inactive.\n    \n    \"\"\"\n    ENABLED_BULB = 3\n    \"\"\"\n    EEP mode is enabled in bulb mode.\n    \n    \"\"\"",
  "class DATA_RATE(_CTypesEnum):\n    \"\"\"\n    The DATA_RATE enumeration defines the options for setting the desired image data delivery rate.\n\n    \"\"\"\n    RESERVED1 = 0  # A RESERVED value (DO NOT USE).\n    RESERVED2 = 1  # A RESERVED value (DO NOT USE).\n    FPS_30 = 2\n    \"\"\"\n    Sets the device to deliver images at 30 frames per second.\n    \n    \"\"\"\n    FPS_50 = 3\n    \"\"\"\n    Sets the device to deliver images at 50 frames per second.\n    \n    \"\"\"",
  "class USB_PORT_TYPE(_CTypesEnum):\n    \"\"\"\n    The USB_PORT_TYPE enumeration defines the values the SDK uses for specifying the USB bus speed. These values are\n    returned by SDK API functions and callbacks based on the type of physical USB port that the device is connected to.\n\n    \"\"\"\n    USB1_0 = 0\n    \"\"\"\n    The device is connected to a USB 1.0/1.1 port (1.5 Mbits/sec or 12 Mbits/sec).\n    \n    \"\"\"\n    USB2_0 = 1\n    \"\"\"\n    The device is connected to a USB 2.0 port (480 Mbits/sec).\n    \n    \"\"\"\n    USB3_0 = 2\n    \"\"\"\n    The device is connected to a USB 3.0 port (5000 Mbits/sec).\n    \n    \"\"\"",
  "class TAPS(_CTypesEnum):\n    \"\"\"\n    Scientific CCD cameras support one or more taps. After exposure is complete, a CCD pixel array holds the charges\n    corresponding to the amount of light collected at beach pixel location. The data is then read out through 1, 2,\n    or 4 channels at a time.\n\n    \"\"\"\n    SINGLE_TAP = 0\n    \"\"\"\n    Charges are read out through a single analog-to-digital converter.\n    \n    \"\"\"\n    DUAL_TAP = 1\n    \"\"\"\n    Charges are read out through two analog-to-digital converters.\n    \n    \"\"\"\n    QUAD_TAP = 2\n    \"\"\"\n    Charges are read out through four analog-to-digital converters.\n    \n    \"\"\"",
  "class COMMUNICATION_INTERFACE(_CTypesEnum):\n    \"\"\"\n    Used to identify what interface the camera is currently using. If using USB, the specific USB version can also be\n    identified using USB_PORT_TYPE.\n\n    \"\"\"\n    GIG_E = 0\n    \"\"\"\n    The camera uses the GigE Vision (GigE) interface standard.\n    \n    \"\"\"\n    LINK = 1\n    \"\"\"\n    The camera uses the CameraLink serial-communication-protocol standard.\n    \n    \"\"\"\n    USB = 2\n    \"\"\"\n    The camera uses a USB interface.\n    \n    \"\"\"",
  "def from_param(cls, obj):\n        return int(obj)",
  "def _get_last_error(sdk):\n    return \"\"",
  "def _create_c_failure_message(sdk, function_name, error_code):\n    last_error = _get_last_error(sdk)\n    failure_message = \"{function_name}() returned non-zero error code: {error_code}; \" \\\n                      \"error message: {last_error}\" \\\n        .format(function_name=function_name, error_code=error_code, last_error=last_error)\n    return failure_message",
  "class PolarizationProcessorSDK(object):\n\n    \"\"\"\n    PolarizationProcessorSDK\n\n    The polarization processor SDK loads DLLs into memory and provides functions to polarization processor instances.\n    Be sure to dispose all PolarizationProcessor objects and then dispose the PolarizationProcessorSDK before exiting\n    the application. *with* statements can also be used with this class to automatically dispose the SDK.\n\n    \"\"\"\n\n    _is_sdk_open = False  # is SDK DLL currently being accessed by a MonoToColorSDK instance\n\n    def __init__(self):\n        # type: (type(None)) -> None\n        self._disposed = True\n\n        if PolarizationProcessorSDK._is_sdk_open:\n            raise PolarizationError(\"PolarizationProcessorSDK is already in use. Please dispose of the current \"\n                                    \"instance before trying to create another instance.\")\n\n        try:\n            if platform.system() == 'Windows':\n                self._sdk = cdll.LoadLibrary(r\"thorlabs_tsi_polarization_processor.dll\")\n            elif platform.system() == 'Linux':\n                self._sdk = cdll.LoadLibrary(r\"libthorlabs_tsi_polarization_processor.so\")\n            else:\n                raise PolarizationError(\"{system} is not a supported platform.\".format(system=platform.system()))\n            self._disposed = False\n        except OSError as os_error:\n            raise PolarizationError(str(os_error) +\n                                    \"\\nUnable to load library - are the thorlabs tsi polarization libraries \"\n                                    \"discoverable from the application directory? Try placing them in the same \"\n                                    \"directory as your program, or adding the directory with the libraries to the \"\n                                    \"PATH. Make sure to use 32-bit libraries when using a 32-bit python interpreter \"\n                                    \"and 64-bit libraries when using a 64-bit interpreter.\\n\")\n\n        error_code = self._sdk.tl_polarization_processor_module_initialize()\n        if error_code != 0:\n            raise PolarizationError(\"tl_polarization_processing_module_initialize() returned error code: {error_code}\\n\"\n                                    .format(error_code=error_code))\n        PolarizationProcessorSDK._is_sdk_open = True\n\n        try:\n            \"\"\" set C function argument types \"\"\"\n            self._sdk.tl_polarization_processor_create_polarization_processor.argtypes = [POINTER(c_void_p)]\n            self._sdk.tl_polarization_processor_destroy_polarization_processor.argtypes = [c_void_p]\n            self._sdk.tl_polarization_processor_set_custom_calibration_coefficients.argtypes = \\\n                [c_void_p,\n                 POINTER(_4x4Matrix_float),\n                 POINTER(_4x4Matrix_float),\n                 POINTER(_4x4Matrix_float),\n                 POINTER(_4x4Matrix_float)]\n            self._sdk.tl_polarization_processor_get_custom_calibration_coefficients.argtypes = \\\n                [c_void_p,\n                 POINTER(_4x4Matrix_float),\n                 POINTER(_4x4Matrix_float),\n                 POINTER(_4x4Matrix_float),\n                 POINTER(_4x4Matrix_float)]\n            self._sdk.tl_polarization_processor_transform.argtypes = [c_void_p,\n                                                                      c_int,\n                                                                      POINTER(c_ushort),\n                                                                      c_int,\n                                                                      c_int,\n                                                                      c_int,\n                                                                      c_int,\n                                                                      c_int,\n                                                                      c_ushort,\n                                                                      POINTER(c_float),\n                                                                      POINTER(c_ushort),\n                                                                      POINTER(c_ushort),\n                                                                      POINTER(c_ushort),\n                                                                      POINTER(c_ushort),\n                                                                      POINTER(c_ushort),\n                                                                      ]\n            self._sdk.tl_polarization_processor_destroy_polarization_processor.argtypes = [c_void_p]\n        except Exception as exception:\n            _logger.error(\"SDK initialization failed; \" + str(exception))\n            raise exception\n\n    def __del__(self):\n        self.dispose()\n\n    \"\"\" with statement functionality \"\"\"\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, exception_type, exception_value, exception_traceback):\n        if exception_type is not None:\n            _logger.debug(\"\".join(format_exception(exception_type, exception_value, exception_traceback)))\n        self.dispose()\n        return True if exception_type is None else False\n\n    \"\"\" methods \"\"\"\n\n    def dispose(self):\n        # type: (type(None)) -> None\n        \"\"\"\n        Cleans up the PolarizationProcessorSDK instance - make sure to call this when you are done with the\n        PolarizationProcessorSDK instance. If using the *with* statement, dispose is called automatically upon exit.\n\n        \"\"\"\n        try:\n            if self._disposed:\n                return\n            error_code = self._sdk.tl_polarization_processor_module_terminate()\n            if error_code != 0:\n                raise PolarizationError(_create_c_failure_message(\n                    self._sdk, \"tl_polarization_processor_module_terminate\", error_code))\n            PolarizationProcessorSDK._is_sdk_open = False\n            self._disposed = True\n        except Exception as exception:\n            _logger.error(\"Polarization SDK destruction failed; \" + str(exception))\n            raise exception\n\n    def create_polarization_processor(self):\n        # type: (type(None)) -> PolarizationProcessor\n        \"\"\"\n        Creates a Polarization Processor object.\n\n        :returns: :class:`PolarizationProcessor<thorlabs_tsi_sdk.tl_polarization_processor.PolarizationProcessor>`\n\n        \"\"\"\n        try:\n            c_polarization_handle = c_void_p()\n            error_code = self._sdk.tl_polarization_processor_create_polarization_processor(c_polarization_handle)\n            if error_code != 0:\n                raise PolarizationError(_create_c_failure_message(\n                    self._sdk, \"tl_polarization_processor_create_polarization_processor\", error_code))\n            # noinspection PyProtectedMember\n            return PolarizationProcessor._create(self._sdk, c_polarization_handle)\n        except Exception as exception:\n            _logger.error(\"Failed to create polarization processor; \" + str(exception))\n            raise exception",
  "class PolarizationProcessor(object):\n\n    \"\"\"\n    PolarizationProcessor\n\n    These objects are used to convert raw sensor data to polarized data. When finished with a PolarizationProcessor,\n    call its :meth:`dispose<thorlabs_tsi_sdk.tl_polarization_processor.PolarizationProcessor.dispose>` method to clean up any opened resources. These object can\n    be managed using *with* statements for automatic resource clean up. These objects can only be created by calls to\n    :meth:`PolarizationProcessorSDK.create_polarization_processor()<thorlabs_tsi_sdk.tl_polarization_processor.PolarizationProcessorSDK.create_polarization_processor>`\n\n    The transform functions return an output image with values from 0 to max value for each pixel. To calculate\n    scaled values for each pixel, you may use the following equation:\n\n    \u2022 polarization_parameter_value = pixel_integer_value * (max_parameter_value / (2^bit_depth - 1)) + min_parameter_value\n\n    The suggested min and max for each type are as follows:\n\n    \u2022 Azimuth: (range from -90\u00b0 to 90\u00b0)\n        \u25e6 min_parameter_value = -90\n        \u25e6 max_parameter_value = 180\n\n    \u2022 DoLP: (range from 0 to 100%)\n        \u25e6 min_parameter_value = 0\n        \u25e6 max_parameter_value = 100\n\n    \u2022 Intensity: (range from 0 to 100)\n        \u25e6 min_parameter_value = 0\n        \u25e6 max_parameter_value = 100\n\n    \"\"\"\n\n    __key = object()\n\n    @classmethod\n    def _create(cls, sdk, polarization_processor_handle):\n        # type: (Any, Any) -> PolarizationProcessor\n        return PolarizationProcessor(cls.__key, sdk, polarization_processor_handle)\n\n    def __init__(self, key, sdk, polarization_processor_handle):\n        # type: (type(object), Any, Any) -> None\n        try:\n            self._disposed = True\n            assert (key == PolarizationProcessor.__key), \\\n                \"PolarizationProcessor objects cannot be created manually. Please use \" \\\n                \"PolarizationProcessorSDK.create_polarization_processor to acquire new PolarizationProcessor objects.\"\n            self._sdk = sdk\n            self._polarization_processor_handle = polarization_processor_handle\n            self._disposed = False\n        except Exception as exception:\n            _logger.error(\"PolarizationProcessor initialization failed; \" + str(exception))\n            raise exception\n\n    def __del__(self):\n        self.dispose()\n\n    \"\"\" with statement functionality \"\"\"\n    def __enter__(self):\n        return self\n\n    def __exit__(self, exception_type, exception_value, exception_traceback):\n        if exception_type is not None:\n            _logger.debug(\"\".join(format_exception(exception_type, exception_value, exception_traceback)))\n        self.dispose()\n        return True if exception_type is None else False\n\n    def dispose(self):\n        # type: (type(None)) -> None\n        \"\"\"\n        Cleans up the PolarizationProcessor instance - make sure to call this when you are done with the polarization\n        processor. If using the *with* statement, dispose is called automatically upon exit.\n\n        \"\"\"\n        try:\n            if self._disposed:\n                return\n            error_code = self._sdk.tl_polarization_processor_destroy_polarization_processor(\n                self._polarization_processor_handle)\n            if error_code != 0:\n                raise PolarizationError(_create_c_failure_message(\n                    self._sdk, \"tl_polarization_processor_destroy_polarization_processor\", error_code))\n            self._disposed = True\n        except Exception as exception:\n            _logger.error(\"Could not dispose PolarizationProcessor instance; \" + str(exception))\n            raise exception\n\n    def transform_to_intensity(self,\n                               sensor_polar_phase,\n                               input_image,\n                               image_origin_x_pixels,\n                               image_origin_y_pixels,\n                               image_width_pixels,\n                               image_height_pixels,\n                               input_image_bit_depth,\n                               output_max_value):\n        # type: (POLAR_PHASE, np.array, int, int, int, int, int, int) -> np.array\n        \"\"\"\n        Transforms raw-image data into the intensity-output buffer, which shows the brightness of the light at each pixel.\n\n        :param sensor_polar_phase: The polar phase (in degrees) of the origin (top-left) pixel of the camera sensor.\n        :param input_image: Unprocessed input image delivered by the camera.\n        :param image_origin_x_pixels: The X position of the origin (top-left) of the input image on the sensor. Warning: Some camera models may nudge input ROI values. Please read values back from camera. See :attr:`TLCamera.roi<thorlabs_tsi_sdk.tl_camera.TLCamera.roi>`.\n        :param image_origin_y_pixels: The Y position of the origin (top-left) of the input image on the sensor. Warning: Some camera models may nudge input ROI values. Please read values back from camera. See :attr:`TLCamera.roi<thorlabs_tsi_sdk.tl_camera.TLCamera.roi>`.\n        :param image_width_pixels: Width of input image in pixels\n        :param image_height_pixels: Height of input image in pixels\n        :param input_image_bit_depth: Bit depth of input image pixels\n        :param output_max_value: The maximum possible pixel value in the output images. Must be between 1 and 65535.\n        :return np.array: Array containing the total optical power (intensity) output, *dtype* = ctypes.c_ushort.\n        \"\"\"\n        try:\n            output_buffer = np.zeros(shape=(image_width_pixels * image_height_pixels,), dtype=c_ushort)\n            output_buffer_pointer = output_buffer.ctypes.data_as(POINTER(c_ushort))\n            input_buffer_pointer = input_image.ctypes.data_as(POINTER(c_ushort))\n            c_image_width = c_int(image_width_pixels)\n            c_image_height = c_int(image_height_pixels)\n            c_image_origin_x_pixels = c_int(image_origin_x_pixels)\n            c_image_origin_y_pixels = c_int(image_origin_y_pixels)\n            c_input_image_bit_depth = c_int(input_image_bit_depth)\n            c_output_max_value = c_ushort(output_max_value)\n            c_sensor_polar_phase = c_int(sensor_polar_phase)\n            error_code = self._sdk.tl_polarization_processor_transform(self._polarization_processor_handle,\n                                                                       c_sensor_polar_phase,\n                                                                       input_buffer_pointer,\n                                                                       c_image_origin_x_pixels,\n                                                                       c_image_origin_y_pixels,\n                                                                       c_image_width,\n                                                                       c_image_height,\n                                                                       c_input_image_bit_depth,\n                                                                       c_output_max_value,\n                                                                       None,  # normalized_stokes_vector_coefficients_x2\n                                                                       output_buffer_pointer,  # total_optical_power\n                                                                       None,  # horizontal_vertical_linear_polarization\n                                                                       None,  # diagonal_linear_polarization\n                                                                       None,  # azimuth\n                                                                       None)  # DOLP\n            if error_code != 0:\n                raise PolarizationError(_create_c_failure_message(self._sdk, \"tl_polarization_processor_transform\",\n                                                                  error_code))\n            return output_buffer\n        except Exception as exception:\n            _logger.error(\"Could not transform to intensity; \" + str(exception))\n            raise exception\n\n    def transform_to_dolp(self,\n                          sensor_polar_phase,\n                          input_image,\n                          image_origin_x_pixels,\n                          image_origin_y_pixels,\n                          image_width_pixels,\n                          image_height_pixels,\n                          input_image_bit_depth,\n                          output_max_value):\n        # type: (POLAR_PHASE, np.array, int, int, int, int, int, int) -> np.array\n        \"\"\"\n        Transforms raw-image data into a DoLP (degree of linear polarization) output buffer, which is a measure of how polarized the light is from none to totally polarized.\n\n        :param sensor_polar_phase: The polar phase (in degrees) of the origin (top-left) pixel of the camera sensor.\n        :param input_image: Unprocessed input image delivered by the camera.\n        :param image_origin_x_pixels: The X position of the origin (top-left) of the input image on the sensor. Warning: Some camera models may nudge input ROI values. Please read values back from camera. See :attr:`TLCamera.roi<thorlabs_tsi_sdk.tl_camera.TLCamera.roi>`.\n        :param image_origin_y_pixels: The Y position of the origin (top-left) of the input image on the sensor. Warning: Some camera models may nudge input ROI values. Please read values back from camera. See :attr:`TLCamera.roi<thorlabs_tsi_sdk.tl_camera.TLCamera.roi>`.\n        :param image_width_pixels: Width of input image in pixels\n        :param image_height_pixels: Height of input image in pixels\n        :param input_image_bit_depth: Bit depth of input image pixels\n        :param output_max_value: The maximum possible pixel value in the output images. Must be between 1 and 65535.\n        :return np.array: Array containing the DoLP (degree of linear polarization) output, *dtype* = ctypes.c_ushort.\n        \"\"\"\n        try:\n            output_buffer = np.zeros(shape=(image_width_pixels * image_height_pixels,), dtype=c_ushort)\n            output_buffer_pointer = output_buffer.ctypes.data_as(POINTER(c_ushort))\n            input_buffer_pointer = input_image.ctypes.data_as(POINTER(c_ushort))\n            c_image_width = c_int(image_width_pixels)\n            c_image_height = c_int(image_height_pixels)\n            c_image_origin_x_pixels = c_int(image_origin_x_pixels)\n            c_image_origin_y_pixels = c_int(image_origin_y_pixels)\n            c_input_image_bit_depth = c_int(input_image_bit_depth)\n            c_output_max_value = c_ushort(output_max_value)\n            c_sensor_polar_phase = c_int(sensor_polar_phase)\n            error_code = self._sdk.tl_polarization_processor_transform(self._polarization_processor_handle,\n                                                                       c_sensor_polar_phase,\n                                                                       input_buffer_pointer,\n                                                                       c_image_origin_x_pixels,\n                                                                       c_image_origin_y_pixels,\n                                                                       c_image_width,\n                                                                       c_image_height,\n                                                                       c_input_image_bit_depth,\n                                                                       c_output_max_value,\n                                                                       None,  # normalized_stokes_vector_coefficients_x2\n                                                                       None,  # total_optical_power\n                                                                       None,  # horizontal_vertical_linear_polarization\n                                                                       None,  # diagonal_linear_polarization\n                                                                       None,  # azimuth\n                                                                       output_buffer_pointer)  # DoLP\n            if error_code != 0:\n                raise PolarizationError(_create_c_failure_message(self._sdk, \"tl_polarization_processor_transform\",\n                                                                  error_code))\n            return output_buffer\n        except Exception as exception:\n            _logger.error(\"Could not transform to DoLP; \" + str(exception))\n            raise exception\n\n    def transform_to_azimuth(self,\n                             sensor_polar_phase,\n                             input_image,\n                             image_origin_x_pixels,\n                             image_origin_y_pixels,\n                             image_width_pixels,\n                             image_height_pixels,\n                             input_image_bit_depth,\n                             output_max_value):\n        # type: (POLAR_PHASE, np.array, int, int, int, int, int, int) -> np.array\n        \"\"\"\n        Transforms raw-image data into an azimuth-output buffer, which shows the angle of polarized light at each pixel.\n\n        :param sensor_polar_phase: The polar phase (in degrees) of the origin (top-left) pixel of the camera sensor.\n        :param input_image: Unprocessed input image delivered by the camera.\n        :param image_origin_x_pixels: The X position of the origin (top-left) of the input image on the sensor. Warning: Some camera models may nudge input ROI values. Please read values back from camera. See :attr:`TLCamera.roi<thorlabs_tsi_sdk.tl_camera.TLCamera.roi>`.\n        :param image_origin_y_pixels: The Y position of the origin (top-left) of the input image on the sensor. Warning: Some camera models may nudge input ROI values. Please read values back from camera. See :attr:`TLCamera.roi<thorlabs_tsi_sdk.tl_camera.TLCamera.roi>`.\n        :param image_width_pixels: Width of input image in pixels\n        :param image_height_pixels: Height of input image in pixels\n        :param input_image_bit_depth: Bit depth of input image pixels\n        :param output_max_value: The maximum possible pixel value in the output images. Must be between 1 and 65535.\n        :return np.array: Array containing the azimuth (polar angle) output, *dtype* = ctypes.c_ushort.\n        \"\"\"\n        try:\n            output_buffer = np.zeros(shape=(image_width_pixels * image_height_pixels,), dtype=c_ushort)\n            output_buffer_pointer = output_buffer.ctypes.data_as(POINTER(c_ushort))\n            input_buffer_pointer = input_image.ctypes.data_as(POINTER(c_ushort))\n            c_image_width = c_int(image_width_pixels)\n            c_image_height = c_int(image_height_pixels)\n            c_image_origin_x_pixels = c_int(image_origin_x_pixels)\n            c_image_origin_y_pixels = c_int(image_origin_y_pixels)\n            c_input_image_bit_depth = c_int(input_image_bit_depth)\n            c_output_max_value = c_ushort(output_max_value)\n            c_sensor_polar_phase = c_int(sensor_polar_phase)\n            error_code = self._sdk.tl_polarization_processor_transform(self._polarization_processor_handle,\n                                                                       c_sensor_polar_phase,\n                                                                       input_buffer_pointer,\n                                                                       c_image_origin_x_pixels,\n                                                                       c_image_origin_y_pixels,\n                                                                       c_image_width,\n                                                                       c_image_height,\n                                                                       c_input_image_bit_depth,\n                                                                       c_output_max_value,\n                                                                       None,  # normalized_stokes_vector_coefficients_x2\n                                                                       None,  # total_optical_power\n                                                                       None,  # horizontal_vertical_linear_polarization\n                                                                       None,  # diagonal_linear_polarization\n                                                                       output_buffer_pointer,  # azimuth\n                                                                       None)  # DoLP\n            if error_code != 0:\n                raise PolarizationError(_create_c_failure_message(self._sdk, \"tl_polarization_processor_transform\",\n                                                                  error_code))\n            return output_buffer\n        except Exception as exception:\n            _logger.error(\"Could not transform to azimuth; \" + str(exception))\n            raise exception\n\n    \"\"\" Properties \"\"\"",
  "class PolarizationError(Exception):\n    def __init__(self, message):\n        _logger.debug(message)\n        super(PolarizationError, self).__init__(message)",
  "def __init__(self):\n        # type: (type(None)) -> None\n        self._disposed = True\n\n        if PolarizationProcessorSDK._is_sdk_open:\n            raise PolarizationError(\"PolarizationProcessorSDK is already in use. Please dispose of the current \"\n                                    \"instance before trying to create another instance.\")\n\n        try:\n            if platform.system() == 'Windows':\n                self._sdk = cdll.LoadLibrary(r\"thorlabs_tsi_polarization_processor.dll\")\n            elif platform.system() == 'Linux':\n                self._sdk = cdll.LoadLibrary(r\"libthorlabs_tsi_polarization_processor.so\")\n            else:\n                raise PolarizationError(\"{system} is not a supported platform.\".format(system=platform.system()))\n            self._disposed = False\n        except OSError as os_error:\n            raise PolarizationError(str(os_error) +\n                                    \"\\nUnable to load library - are the thorlabs tsi polarization libraries \"\n                                    \"discoverable from the application directory? Try placing them in the same \"\n                                    \"directory as your program, or adding the directory with the libraries to the \"\n                                    \"PATH. Make sure to use 32-bit libraries when using a 32-bit python interpreter \"\n                                    \"and 64-bit libraries when using a 64-bit interpreter.\\n\")\n\n        error_code = self._sdk.tl_polarization_processor_module_initialize()\n        if error_code != 0:\n            raise PolarizationError(\"tl_polarization_processing_module_initialize() returned error code: {error_code}\\n\"\n                                    .format(error_code=error_code))\n        PolarizationProcessorSDK._is_sdk_open = True\n\n        try:\n            \"\"\" set C function argument types \"\"\"\n            self._sdk.tl_polarization_processor_create_polarization_processor.argtypes = [POINTER(c_void_p)]\n            self._sdk.tl_polarization_processor_destroy_polarization_processor.argtypes = [c_void_p]\n            self._sdk.tl_polarization_processor_set_custom_calibration_coefficients.argtypes = \\\n                [c_void_p,\n                 POINTER(_4x4Matrix_float),\n                 POINTER(_4x4Matrix_float),\n                 POINTER(_4x4Matrix_float),\n                 POINTER(_4x4Matrix_float)]\n            self._sdk.tl_polarization_processor_get_custom_calibration_coefficients.argtypes = \\\n                [c_void_p,\n                 POINTER(_4x4Matrix_float),\n                 POINTER(_4x4Matrix_float),\n                 POINTER(_4x4Matrix_float),\n                 POINTER(_4x4Matrix_float)]\n            self._sdk.tl_polarization_processor_transform.argtypes = [c_void_p,\n                                                                      c_int,\n                                                                      POINTER(c_ushort),\n                                                                      c_int,\n                                                                      c_int,\n                                                                      c_int,\n                                                                      c_int,\n                                                                      c_int,\n                                                                      c_ushort,\n                                                                      POINTER(c_float),\n                                                                      POINTER(c_ushort),\n                                                                      POINTER(c_ushort),\n                                                                      POINTER(c_ushort),\n                                                                      POINTER(c_ushort),\n                                                                      POINTER(c_ushort),\n                                                                      ]\n            self._sdk.tl_polarization_processor_destroy_polarization_processor.argtypes = [c_void_p]\n        except Exception as exception:\n            _logger.error(\"SDK initialization failed; \" + str(exception))\n            raise exception",
  "def __del__(self):\n        self.dispose()",
  "def __enter__(self):\n        return self",
  "def __exit__(self, exception_type, exception_value, exception_traceback):\n        if exception_type is not None:\n            _logger.debug(\"\".join(format_exception(exception_type, exception_value, exception_traceback)))\n        self.dispose()\n        return True if exception_type is None else False",
  "def dispose(self):\n        # type: (type(None)) -> None\n        \"\"\"\n        Cleans up the PolarizationProcessorSDK instance - make sure to call this when you are done with the\n        PolarizationProcessorSDK instance. If using the *with* statement, dispose is called automatically upon exit.\n\n        \"\"\"\n        try:\n            if self._disposed:\n                return\n            error_code = self._sdk.tl_polarization_processor_module_terminate()\n            if error_code != 0:\n                raise PolarizationError(_create_c_failure_message(\n                    self._sdk, \"tl_polarization_processor_module_terminate\", error_code))\n            PolarizationProcessorSDK._is_sdk_open = False\n            self._disposed = True\n        except Exception as exception:\n            _logger.error(\"Polarization SDK destruction failed; \" + str(exception))\n            raise exception",
  "def create_polarization_processor(self):\n        # type: (type(None)) -> PolarizationProcessor\n        \"\"\"\n        Creates a Polarization Processor object.\n\n        :returns: :class:`PolarizationProcessor<thorlabs_tsi_sdk.tl_polarization_processor.PolarizationProcessor>`\n\n        \"\"\"\n        try:\n            c_polarization_handle = c_void_p()\n            error_code = self._sdk.tl_polarization_processor_create_polarization_processor(c_polarization_handle)\n            if error_code != 0:\n                raise PolarizationError(_create_c_failure_message(\n                    self._sdk, \"tl_polarization_processor_create_polarization_processor\", error_code))\n            # noinspection PyProtectedMember\n            return PolarizationProcessor._create(self._sdk, c_polarization_handle)\n        except Exception as exception:\n            _logger.error(\"Failed to create polarization processor; \" + str(exception))\n            raise exception",
  "def _create(cls, sdk, polarization_processor_handle):\n        # type: (Any, Any) -> PolarizationProcessor\n        return PolarizationProcessor(cls.__key, sdk, polarization_processor_handle)",
  "def __init__(self, key, sdk, polarization_processor_handle):\n        # type: (type(object), Any, Any) -> None\n        try:\n            self._disposed = True\n            assert (key == PolarizationProcessor.__key), \\\n                \"PolarizationProcessor objects cannot be created manually. Please use \" \\\n                \"PolarizationProcessorSDK.create_polarization_processor to acquire new PolarizationProcessor objects.\"\n            self._sdk = sdk\n            self._polarization_processor_handle = polarization_processor_handle\n            self._disposed = False\n        except Exception as exception:\n            _logger.error(\"PolarizationProcessor initialization failed; \" + str(exception))\n            raise exception",
  "def __del__(self):\n        self.dispose()",
  "def __enter__(self):\n        return self",
  "def __exit__(self, exception_type, exception_value, exception_traceback):\n        if exception_type is not None:\n            _logger.debug(\"\".join(format_exception(exception_type, exception_value, exception_traceback)))\n        self.dispose()\n        return True if exception_type is None else False",
  "def dispose(self):\n        # type: (type(None)) -> None\n        \"\"\"\n        Cleans up the PolarizationProcessor instance - make sure to call this when you are done with the polarization\n        processor. If using the *with* statement, dispose is called automatically upon exit.\n\n        \"\"\"\n        try:\n            if self._disposed:\n                return\n            error_code = self._sdk.tl_polarization_processor_destroy_polarization_processor(\n                self._polarization_processor_handle)\n            if error_code != 0:\n                raise PolarizationError(_create_c_failure_message(\n                    self._sdk, \"tl_polarization_processor_destroy_polarization_processor\", error_code))\n            self._disposed = True\n        except Exception as exception:\n            _logger.error(\"Could not dispose PolarizationProcessor instance; \" + str(exception))\n            raise exception",
  "def transform_to_intensity(self,\n                               sensor_polar_phase,\n                               input_image,\n                               image_origin_x_pixels,\n                               image_origin_y_pixels,\n                               image_width_pixels,\n                               image_height_pixels,\n                               input_image_bit_depth,\n                               output_max_value):\n        # type: (POLAR_PHASE, np.array, int, int, int, int, int, int) -> np.array\n        \"\"\"\n        Transforms raw-image data into the intensity-output buffer, which shows the brightness of the light at each pixel.\n\n        :param sensor_polar_phase: The polar phase (in degrees) of the origin (top-left) pixel of the camera sensor.\n        :param input_image: Unprocessed input image delivered by the camera.\n        :param image_origin_x_pixels: The X position of the origin (top-left) of the input image on the sensor. Warning: Some camera models may nudge input ROI values. Please read values back from camera. See :attr:`TLCamera.roi<thorlabs_tsi_sdk.tl_camera.TLCamera.roi>`.\n        :param image_origin_y_pixels: The Y position of the origin (top-left) of the input image on the sensor. Warning: Some camera models may nudge input ROI values. Please read values back from camera. See :attr:`TLCamera.roi<thorlabs_tsi_sdk.tl_camera.TLCamera.roi>`.\n        :param image_width_pixels: Width of input image in pixels\n        :param image_height_pixels: Height of input image in pixels\n        :param input_image_bit_depth: Bit depth of input image pixels\n        :param output_max_value: The maximum possible pixel value in the output images. Must be between 1 and 65535.\n        :return np.array: Array containing the total optical power (intensity) output, *dtype* = ctypes.c_ushort.\n        \"\"\"\n        try:\n            output_buffer = np.zeros(shape=(image_width_pixels * image_height_pixels,), dtype=c_ushort)\n            output_buffer_pointer = output_buffer.ctypes.data_as(POINTER(c_ushort))\n            input_buffer_pointer = input_image.ctypes.data_as(POINTER(c_ushort))\n            c_image_width = c_int(image_width_pixels)\n            c_image_height = c_int(image_height_pixels)\n            c_image_origin_x_pixels = c_int(image_origin_x_pixels)\n            c_image_origin_y_pixels = c_int(image_origin_y_pixels)\n            c_input_image_bit_depth = c_int(input_image_bit_depth)\n            c_output_max_value = c_ushort(output_max_value)\n            c_sensor_polar_phase = c_int(sensor_polar_phase)\n            error_code = self._sdk.tl_polarization_processor_transform(self._polarization_processor_handle,\n                                                                       c_sensor_polar_phase,\n                                                                       input_buffer_pointer,\n                                                                       c_image_origin_x_pixels,\n                                                                       c_image_origin_y_pixels,\n                                                                       c_image_width,\n                                                                       c_image_height,\n                                                                       c_input_image_bit_depth,\n                                                                       c_output_max_value,\n                                                                       None,  # normalized_stokes_vector_coefficients_x2\n                                                                       output_buffer_pointer,  # total_optical_power\n                                                                       None,  # horizontal_vertical_linear_polarization\n                                                                       None,  # diagonal_linear_polarization\n                                                                       None,  # azimuth\n                                                                       None)  # DOLP\n            if error_code != 0:\n                raise PolarizationError(_create_c_failure_message(self._sdk, \"tl_polarization_processor_transform\",\n                                                                  error_code))\n            return output_buffer\n        except Exception as exception:\n            _logger.error(\"Could not transform to intensity; \" + str(exception))\n            raise exception",
  "def transform_to_dolp(self,\n                          sensor_polar_phase,\n                          input_image,\n                          image_origin_x_pixels,\n                          image_origin_y_pixels,\n                          image_width_pixels,\n                          image_height_pixels,\n                          input_image_bit_depth,\n                          output_max_value):\n        # type: (POLAR_PHASE, np.array, int, int, int, int, int, int) -> np.array\n        \"\"\"\n        Transforms raw-image data into a DoLP (degree of linear polarization) output buffer, which is a measure of how polarized the light is from none to totally polarized.\n\n        :param sensor_polar_phase: The polar phase (in degrees) of the origin (top-left) pixel of the camera sensor.\n        :param input_image: Unprocessed input image delivered by the camera.\n        :param image_origin_x_pixels: The X position of the origin (top-left) of the input image on the sensor. Warning: Some camera models may nudge input ROI values. Please read values back from camera. See :attr:`TLCamera.roi<thorlabs_tsi_sdk.tl_camera.TLCamera.roi>`.\n        :param image_origin_y_pixels: The Y position of the origin (top-left) of the input image on the sensor. Warning: Some camera models may nudge input ROI values. Please read values back from camera. See :attr:`TLCamera.roi<thorlabs_tsi_sdk.tl_camera.TLCamera.roi>`.\n        :param image_width_pixels: Width of input image in pixels\n        :param image_height_pixels: Height of input image in pixels\n        :param input_image_bit_depth: Bit depth of input image pixels\n        :param output_max_value: The maximum possible pixel value in the output images. Must be between 1 and 65535.\n        :return np.array: Array containing the DoLP (degree of linear polarization) output, *dtype* = ctypes.c_ushort.\n        \"\"\"\n        try:\n            output_buffer = np.zeros(shape=(image_width_pixels * image_height_pixels,), dtype=c_ushort)\n            output_buffer_pointer = output_buffer.ctypes.data_as(POINTER(c_ushort))\n            input_buffer_pointer = input_image.ctypes.data_as(POINTER(c_ushort))\n            c_image_width = c_int(image_width_pixels)\n            c_image_height = c_int(image_height_pixels)\n            c_image_origin_x_pixels = c_int(image_origin_x_pixels)\n            c_image_origin_y_pixels = c_int(image_origin_y_pixels)\n            c_input_image_bit_depth = c_int(input_image_bit_depth)\n            c_output_max_value = c_ushort(output_max_value)\n            c_sensor_polar_phase = c_int(sensor_polar_phase)\n            error_code = self._sdk.tl_polarization_processor_transform(self._polarization_processor_handle,\n                                                                       c_sensor_polar_phase,\n                                                                       input_buffer_pointer,\n                                                                       c_image_origin_x_pixels,\n                                                                       c_image_origin_y_pixels,\n                                                                       c_image_width,\n                                                                       c_image_height,\n                                                                       c_input_image_bit_depth,\n                                                                       c_output_max_value,\n                                                                       None,  # normalized_stokes_vector_coefficients_x2\n                                                                       None,  # total_optical_power\n                                                                       None,  # horizontal_vertical_linear_polarization\n                                                                       None,  # diagonal_linear_polarization\n                                                                       None,  # azimuth\n                                                                       output_buffer_pointer)  # DoLP\n            if error_code != 0:\n                raise PolarizationError(_create_c_failure_message(self._sdk, \"tl_polarization_processor_transform\",\n                                                                  error_code))\n            return output_buffer\n        except Exception as exception:\n            _logger.error(\"Could not transform to DoLP; \" + str(exception))\n            raise exception",
  "def transform_to_azimuth(self,\n                             sensor_polar_phase,\n                             input_image,\n                             image_origin_x_pixels,\n                             image_origin_y_pixels,\n                             image_width_pixels,\n                             image_height_pixels,\n                             input_image_bit_depth,\n                             output_max_value):\n        # type: (POLAR_PHASE, np.array, int, int, int, int, int, int) -> np.array\n        \"\"\"\n        Transforms raw-image data into an azimuth-output buffer, which shows the angle of polarized light at each pixel.\n\n        :param sensor_polar_phase: The polar phase (in degrees) of the origin (top-left) pixel of the camera sensor.\n        :param input_image: Unprocessed input image delivered by the camera.\n        :param image_origin_x_pixels: The X position of the origin (top-left) of the input image on the sensor. Warning: Some camera models may nudge input ROI values. Please read values back from camera. See :attr:`TLCamera.roi<thorlabs_tsi_sdk.tl_camera.TLCamera.roi>`.\n        :param image_origin_y_pixels: The Y position of the origin (top-left) of the input image on the sensor. Warning: Some camera models may nudge input ROI values. Please read values back from camera. See :attr:`TLCamera.roi<thorlabs_tsi_sdk.tl_camera.TLCamera.roi>`.\n        :param image_width_pixels: Width of input image in pixels\n        :param image_height_pixels: Height of input image in pixels\n        :param input_image_bit_depth: Bit depth of input image pixels\n        :param output_max_value: The maximum possible pixel value in the output images. Must be between 1 and 65535.\n        :return np.array: Array containing the azimuth (polar angle) output, *dtype* = ctypes.c_ushort.\n        \"\"\"\n        try:\n            output_buffer = np.zeros(shape=(image_width_pixels * image_height_pixels,), dtype=c_ushort)\n            output_buffer_pointer = output_buffer.ctypes.data_as(POINTER(c_ushort))\n            input_buffer_pointer = input_image.ctypes.data_as(POINTER(c_ushort))\n            c_image_width = c_int(image_width_pixels)\n            c_image_height = c_int(image_height_pixels)\n            c_image_origin_x_pixels = c_int(image_origin_x_pixels)\n            c_image_origin_y_pixels = c_int(image_origin_y_pixels)\n            c_input_image_bit_depth = c_int(input_image_bit_depth)\n            c_output_max_value = c_ushort(output_max_value)\n            c_sensor_polar_phase = c_int(sensor_polar_phase)\n            error_code = self._sdk.tl_polarization_processor_transform(self._polarization_processor_handle,\n                                                                       c_sensor_polar_phase,\n                                                                       input_buffer_pointer,\n                                                                       c_image_origin_x_pixels,\n                                                                       c_image_origin_y_pixels,\n                                                                       c_image_width,\n                                                                       c_image_height,\n                                                                       c_input_image_bit_depth,\n                                                                       c_output_max_value,\n                                                                       None,  # normalized_stokes_vector_coefficients_x2\n                                                                       None,  # total_optical_power\n                                                                       None,  # horizontal_vertical_linear_polarization\n                                                                       None,  # diagonal_linear_polarization\n                                                                       output_buffer_pointer,  # azimuth\n                                                                       None)  # DoLP\n            if error_code != 0:\n                raise PolarizationError(_create_c_failure_message(self._sdk, \"tl_polarization_processor_transform\",\n                                                                  error_code))\n            return output_buffer\n        except Exception as exception:\n            _logger.error(\"Could not transform to azimuth; \" + str(exception))\n            raise exception",
  "def __init__(self, message):\n        _logger.debug(message)\n        super(PolarizationError, self).__init__(message)",
  "def transpose_dictionary(dictionary):\n\tkeys = list(dictionary.keys())\n\tvalues = list(dictionary.values())\n\tassert(len(set(values))==len(values)) #assert values are unique\n\toutput = {}\n\tfor k,v in list(dictionary.items()):\n\t\toutput.update({v:k})\n\treturn output",
  "def PI_V(value_type,constraint_type,parameter_index):\n\n\t''' Perform bitshift operations for to encode into binary the parameter, it's type info + constraint''' \n\n\tv = transpose_dictionary(PicamValueType)[value_type]\n\tc = transpose_dictionary(PicamConstraintType)[constraint_type]\n\tn = int(parameter_index)\n\treturn (((c)<<24)+((v)<<16)+(n))",
  "class clsPicamReadoutStruct(ct.Structure):\n    _fields_ = [(\"ptr\", ct.c_void_p),\n                (\"intCount\", ct.c_int64)]",
  "class Pixis(Camera):\n    def __init__(self,with_start_up = False,debug=0):\n        self.debug = debug\n        self.bolRunning = False\n        self.y_max = 0\n        self.x_max = 0\n        if with_start_up == True:\n            self.StartUp()\n            self.SetExposureTime(10)\n            \n        self.boundary_cut = 5\n    def __del__(self):\n        if self.bolRunning == True:\n            self.ShutDown()\n\n\n    def raw_snapshot(self, suppress_errors=False):\n        \"\"\"\n            Camera class override\n        \"\"\"\n        try:\n            image  = self.GetCurrentFrame()\n            return True, image\n        except Exception as e:\n            if suppress_errors==True:\n                False, None\n            else:\n                raise e        \n\n    def get_roi(self,x_min=0, x_max = None, y_min=0,y_max = None, suppress_errors=False,debug=0):\n        _,raw_image = self.raw_snapshot(suppress_errors=suppress_errors)\n        if x_max is None:\n            x_max = self.x_max\n        if y_max is None:\n            y_max = self.y_max\n\n        if debug > 0:\n            print(\"Pixis.get_roi region of interest:\",x_min,x_max,y_min,y_max)\n        roi_image = raw_image[max(0,y_min):min(y_max,self.y_max),max(0,x_min):min(self.x_max,x_max)]\n        if debug > 0:\n            print(\"Pixis.roi_image.shape:\",roi_image.shape)\n        return roi_image\n\n    def get_spectrum(self, x_min=0, x_max = None, y_min=0,y_max = None,with_boundary_cut = True, suppress_errors=False):    \n        roi_image = self.get_roi(x_min,x_max,y_min,y_max,suppress_errors)\n        #cut edge values from raw spectrum - remove edge effects\n        raw_spectrum = np.mean(roi_image,axis=0)\n        pixel_offsets = np.array(list(range(0,len(raw_spectrum))))-int(self.FrameWidth/2)\n        if with_boundary_cut == True:\n            return raw_spectrum[self.boundary_cut:-self.boundary_cut], pixel_offsets[self.boundary_cut:-self.boundary_cut]\n\n        else:\n            return raw_spectrum,pixel_offsets\n\n    def get_parameter(self,parameter_name, label=\"unknown\"):\n        \"\"\"\n        Perform GetParameterIntegerValue calls to DLL\n        parameter_name : name of parameter as specified in the picam_constants.py file\n        \"\"\"\n\n        if self.debug > 0:\n            print(\"pixis.get_parameter::parameter_name:{}\".format(parameter_name))\n        self.picam.PicamAdvanced_RefreshParametersFromCameraDevice(self.CameraHandle)\n        assert(parameter_name in list(PicamParameter.keys())) #Check that the passed parameter name is valid (ie. in constants file)\n        param_type, constraint_type, n = PicamParameter[parameter_name]\n        if self.debug > 0:\n            print(\"pixis:get_parameter::param_type: {}\".format(param_type))\n            print(\"pixis:get_parameter::constraint_type: {}\".format(constraint_type))\n            print(\"pixis:get_parameter::n: {}\".format(n))\n\n        param_id = PI_V(value_type=param_type, constraint_type= constraint_type, parameter_index=n)\n\n        #assert returned parameter value type is valid one\n        valid_value_types = list(transpose_dictionary(PicamValueType).keys())\n        assert(param_type in valid_value_types)\n\n        #assert returned parameter constraint type is valid one\n        valid_constraint_types = list(transpose_dictionary(PicamConstraintType).keys())\n        assert(constraint_type in valid_constraint_types)\n        \n        paramtype = param_type.replace(\"PicamValueType_\",\"\")\n\n        if self.debug > 0:\n            print(\"paramtype:\", paramtype)\n\n        if paramtype == \"Enumeration\":\n            paramtype=\"IntegerValue\"\n\n        else:\n            paramtype=paramtype+\"Value\"\n\n        function_name = \"Picam_GetParameter{}\".format(paramtype)\n        if self.debug > 0:\n            print(\"Function name:\",function_name)\n            print(\"Parameter name:\", parameter_name)\n            print(\"Parameter id:\",param_id) \n            # print \"Function object\", f\n        \n        getter = getattr(self.picam,function_name,None)\n        if getter is None:\n            raise ValueError(\"Getter is none!\")\n        else:\n            if self.debug > 0:\n                print(getter)\n        temp =  {\n            \"PicamValueType_Integer\" : ct.c_int(),\n            \"PicamValueType_Boolean\" : ct.c_bool(),\n            \"PicamValueType_LargeInteger\" : ct.c_long(),\n\n            \"PicamValueType_FloatingPoint\" : ct.c_double(),\n\n            \"PicamValueType_Enumeration\": ct.c_int(), #TODO \n            \"PicamValueType_Rois\": None, #TODO\n            \"PicamValueType_Pulse\": None, #TODO\n            \"PicamValueType_Modulations\": None #None       \n        }\n        \n\n\n        value = temp[param_type]\n        if self.debug > 0:\n            print(\"pixis.get_parameter::param_type: {}\".format(param_type))\n            print(\"pixis.get_parameter::value: {}\".format(value))\n        if value is not None:\n            response = getter(self.CameraHandle,param_id, ct.pointer(value))\n\n            if response != 0:\n                print((\"Could not GET value of parameter {0} [label:{1}]\".format(parameter_name,label)))\n                print((\"[Code:{0}] {1}\".format(response, PicamError[response])))\n                return np.nan\n        \n            return value.value\n        else:\n            '''\n            Cases left to implement:\n                PicamValueType_Enumeration,\n                PicamValueType_Rois,\n                PicamValueType_Pulse,\n                PicamValueType_Modulations\n            '''\n            raise NotImplementedError()\n        \n    def set_parameter(self,parameter_name,parameter_value):\n        '''\n        Perform GetParameterIntegerValue calls to DLL\n        parameter_name : name of parameter as specified in the picam_constants.py file\n        '''\n        assert(parameter_name in list(PicamParameter.keys())) #Check that the passed parameter name is valid (ie. in constants file)\n        param_type, constraint_type, n = PicamParameter[parameter_name]\n        param_id = PI_V(value_type=param_type, constraint_type= constraint_type, parameter_index=n)\n\n        #assert returned parameter value type is valid one\n        valid_value_types = list(transpose_dictionary(PicamValueType).keys())\n        assert(param_type in valid_value_types)\n\n        #assert returned parameter constraint type is valid one\n        valid_constraint_types = list(transpose_dictionary(PicamConstraintType).keys())\n        assert(constraint_type in valid_constraint_types)\n        \n\n        function_name = \"Picam_SetParameter{}Value\".format(param_type.replace(\"PicamValueType_\",\"\"))\n        setter = getattr(self.picam,function_name)\n        # setter = self.picam.Picam_SetParameterFloatingPointValue\n        if self.debug > 0:\n            print(\"Function name:\",function_name)\n            print(\"Paramer type, Constraint type, n:\", param_type, constraint_type, n)\n            print(\"Function object\", setter)\n        \n        temp =  {\n            \"PicamValueType_Integer\" : ct.c_int,\n            \"PicamValueType_Boolean\" : ct.c_bool,\n            \"PicamValueType_LargeInteger\" : ct.c_long,\n            \"PicamValueType_FloatingPoint\" : ct.c_double, #WARNING - THIS SHOULD BE A DOUBLE (64bit), NOT FLOAT (32bit) [for 32bit change to float]\n            \"PicamValueType_Enumeration\": ct.c_int, #Maybe an int \n            \"PicamValueType_Rois\": None, #TODO\n            \"PicamValueType_Pulse\": None, #TODO\n            \"PicamValueType_Modulations\": None #None       \n        }\n        \n        #allocate memory for parameter for DLL to populate\n        value = temp[param_type](parameter_value)\n\n        if value is not None:\n            if self.debug > 0:\n                print(\"setting: param_id:  {0}, value:{1}\".format(param_id,value))\n\n            response = setter(self.CameraHandle,param_id, value)\n            if response != 0:\n                print((\"Could not SET value of parameter {0} [label:{1}]\".format(parameter,label)))\n                print((\"[Code:{0}] {1}\".format(response, PicamError[response])))\n                return np.nan\n            #check if commit failed\n            failed_commit = (ct.c_int*10)()\n            failed_count = ct.c_int()\n            response = self.picam.Picam_CommitParameters(self.CameraHandle,ct.byref(failed_commit),ct.byref(failed_count))\n            if self.debug > 0:\n                print(\"Picam_CommitParameters response:\",response, failed_count, list(failed_commit))\n            \n            assert(int(failed_count.value) == 0)\n            #check if commit has passed\n            committed = ct.c_bool(False)\n            response = self.picam.Picam_AreParametersCommitted(self.CameraHandle,ct.byref(committed))\n            if self.debug> 0:\n                    print(\"Picam_CommitParameters response:\",response, committed)\n\n            assert(bool(committed.value) == True)\n            \n            return\n\n        else:\n            '''\n            Cases left to implement:\n                PicamValueType_Enumeration,\n                PicamValueType_Rois,\n                PicamValueType_Pulse,\n                PicamValueType_Modulations\n            '''\n            raise NotImplementedError()\n\n    def StartUp(self):\n        cint_temp = ct.c_int()\n        # Find DLL\n        try:\n            self.picam = ct.WinDLL(os.path.normpath('{}/picam_64bit.dll'.format(PARENT_DIR)))\n        except Exception as e:\n            logging.warning(\"Error:\",e)\n            logging.info(\"Could not find picam dll\")\n            return\n        # Initialise library\n        bolInitialised = ct.c_bool(False)\n        if self.picam.Picam_InitializeLibrary() != 0:\n            print(\"Could not initialise library\")\n            return\n        self.picam.Picam_IsLibraryInitialized(ct.byref(bolInitialised))\n        if bolInitialised == ct.c_bool(False):\n            print(\"Library was not initialised\")\n            return\n        # Get camera handle\n        self.CameraHandle = ct.c_void_p()\n        if self.picam.Picam_OpenFirstCamera(ct.byref(self.CameraHandle)) != 0:\n            print(\"Could not find camera\")\n            return\n\n        self.x_max = self.FrameWidth = self.get_parameter(parameter_name=\"PicamParameter_SensorActiveWidth\", label=\"frame width\")\n        self.y_max = self.FrameHeight = self.get_parameter(parameter_name=\"PicamParameter_SensorActiveHeight\", label=\"frame height\")\n        print(\"Frame size:\", self.x_max, self.y_max)\n        self.bolRunning = True\n        self.SetTemperatureWithLock(-80.0)\n\n    \n    def ShutDown(self):\n        if self.bolRunning == False:\n            return\n        if self.picam.Picam_CloseCamera(self.CameraHandle) != 0:\n            print(\"Could not close camera\")\n            return\n        if self.picam.Picam_UninitializeLibrary() != 0:\n            print(\"Could not shut down library\")\n            return\n        self.bolRunning = False\n        \n    def SetExposureTime(self,time):\n        \n        param_name = \"PicamParameter_ExposureTime\"        \n        param_value = time #in milliseconds\n        self.set_parameter(parameter_name=param_name,parameter_value=param_value)\n\n\n    def SetTemperatureWithLock(self,temperature):\n        self.__SetSensorTemperatureSetPoint(temperature)\n        status_code = p.GetTemperatureStatus()\n        while PicamSensorTemperatureStatus[status_code] != \"PicamSensorTemperatureStatus_Locked\":\n            print(\"TemperatureStatus: {3}[{2}] (current: {0}, target:{1})\".format(p.GetSensorTemperatureReading(), temperature,status_code, PicamSensorTemperatureStatus[status_code]))\n            time.sleep(0.5)\n            status_code = p.GetTemperatureStatus()\n\n        status_code = p.GetTemperatureStatus()\n        print(\"TemperatureStatus: {0} [{1}]\".format(PicamSensorTemperatureStatus[status_code], status_code))\n        return\n\n\n    def GetSensorTemperatureReading(self):\n        param_name = \"PicamParameter_SensorTemperatureReading\"\n        return self.get_parameter(param_name)\n\n    def __SetSensorTemperatureSetPoint(self,temperature):\n        '''\n            Do not use this method if you want to wait for temperature to stabilize, use SetTemperatureWithLock\n        '''\n        param_name = \"PicamParameter_SensorTemperatureSetPoint\"\n        return self.set_parameter(parameter_name=param_name,parameter_value=temperature)\n\n    def GetTemperatureStatus(self):\n        '''\n        See picam_constants.PicamSensorTemperatureStatus for\n            int <-> status mappings\n        '''\n        param_name = \"PicamParameter_SensorTemperatureStatus\"\n        return self.get_parameter(param_name)\n\n\n    def GetExposureTime(self):\n        param_name = \"PicamParameter_ExposureTime\"\n        #function call: PicamEnumeratedType_CoolingFanStatus\n        return self.get_parameter(parameter_name=param_name)\n        \n        # return self.get_parameter(parameter=33685527, label=\"exposure time\")\n    \n\n    def GetSensorType(self):\n        param_name = \"PicamParameter_SensorType\"\n        return self.get_parameter(parameter_name=param_name)\n\n    def GetIntensifierStatus(self):\n        param_name = \"PicamParameter_IntensifierStatus\"\n        return self.get_parameter(parameter_name=param_name)\n\n\n    def GetCurrentFrame(self):\n        \n        if self.bolRunning == False:\n            self.StartUp()\n        \n        structReadout = clsPicamReadoutStruct()\n        intErrorMask = ct.c_int()\n        \n        # Read in pointer to image buffer\n        if self.picam.Picam_Acquire(self.CameraHandle, 1, -1, \n                ct.byref(structReadout), ct.byref(intErrorMask)) != 0:\n            print(\"Image acquisition failed\")\n            return\n        if intErrorMask.value != 0:\n            print(\"Image acquisition returned an error\")\n            return\n        \n        # Get image\n        ctarr = (ct.c_uint16*(self.FrameWidth*self.FrameHeight)) # Create ctypes array\n        ctarr = ctarr.from_address(structReadout.ptr) # Read in array from pointer\n        nparr = np.array(ctarr) # Convert to numpy array\n        nparr = nparr.reshape((self.FrameWidth, self.FrameHeight)) # Reshape numpy array\n        \n        return nparr",
  "def __init__(self,with_start_up = False,debug=0):\n        self.debug = debug\n        self.bolRunning = False\n        self.y_max = 0\n        self.x_max = 0\n        if with_start_up == True:\n            self.StartUp()\n            self.SetExposureTime(10)\n            \n        self.boundary_cut = 5",
  "def __del__(self):\n        if self.bolRunning == True:\n            self.ShutDown()",
  "def raw_snapshot(self, suppress_errors=False):\n        \"\"\"\n            Camera class override\n        \"\"\"\n        try:\n            image  = self.GetCurrentFrame()\n            return True, image\n        except Exception as e:\n            if suppress_errors==True:\n                False, None\n            else:\n                raise e",
  "def get_roi(self,x_min=0, x_max = None, y_min=0,y_max = None, suppress_errors=False,debug=0):\n        _,raw_image = self.raw_snapshot(suppress_errors=suppress_errors)\n        if x_max is None:\n            x_max = self.x_max\n        if y_max is None:\n            y_max = self.y_max\n\n        if debug > 0:\n            print(\"Pixis.get_roi region of interest:\",x_min,x_max,y_min,y_max)\n        roi_image = raw_image[max(0,y_min):min(y_max,self.y_max),max(0,x_min):min(self.x_max,x_max)]\n        if debug > 0:\n            print(\"Pixis.roi_image.shape:\",roi_image.shape)\n        return roi_image",
  "def get_spectrum(self, x_min=0, x_max = None, y_min=0,y_max = None,with_boundary_cut = True, suppress_errors=False):    \n        roi_image = self.get_roi(x_min,x_max,y_min,y_max,suppress_errors)\n        #cut edge values from raw spectrum - remove edge effects\n        raw_spectrum = np.mean(roi_image,axis=0)\n        pixel_offsets = np.array(list(range(0,len(raw_spectrum))))-int(self.FrameWidth/2)\n        if with_boundary_cut == True:\n            return raw_spectrum[self.boundary_cut:-self.boundary_cut], pixel_offsets[self.boundary_cut:-self.boundary_cut]\n\n        else:\n            return raw_spectrum,pixel_offsets",
  "def get_parameter(self,parameter_name, label=\"unknown\"):\n        \"\"\"\n        Perform GetParameterIntegerValue calls to DLL\n        parameter_name : name of parameter as specified in the picam_constants.py file\n        \"\"\"\n\n        if self.debug > 0:\n            print(\"pixis.get_parameter::parameter_name:{}\".format(parameter_name))\n        self.picam.PicamAdvanced_RefreshParametersFromCameraDevice(self.CameraHandle)\n        assert(parameter_name in list(PicamParameter.keys())) #Check that the passed parameter name is valid (ie. in constants file)\n        param_type, constraint_type, n = PicamParameter[parameter_name]\n        if self.debug > 0:\n            print(\"pixis:get_parameter::param_type: {}\".format(param_type))\n            print(\"pixis:get_parameter::constraint_type: {}\".format(constraint_type))\n            print(\"pixis:get_parameter::n: {}\".format(n))\n\n        param_id = PI_V(value_type=param_type, constraint_type= constraint_type, parameter_index=n)\n\n        #assert returned parameter value type is valid one\n        valid_value_types = list(transpose_dictionary(PicamValueType).keys())\n        assert(param_type in valid_value_types)\n\n        #assert returned parameter constraint type is valid one\n        valid_constraint_types = list(transpose_dictionary(PicamConstraintType).keys())\n        assert(constraint_type in valid_constraint_types)\n        \n        paramtype = param_type.replace(\"PicamValueType_\",\"\")\n\n        if self.debug > 0:\n            print(\"paramtype:\", paramtype)\n\n        if paramtype == \"Enumeration\":\n            paramtype=\"IntegerValue\"\n\n        else:\n            paramtype=paramtype+\"Value\"\n\n        function_name = \"Picam_GetParameter{}\".format(paramtype)\n        if self.debug > 0:\n            print(\"Function name:\",function_name)\n            print(\"Parameter name:\", parameter_name)\n            print(\"Parameter id:\",param_id) \n            # print \"Function object\", f\n        \n        getter = getattr(self.picam,function_name,None)\n        if getter is None:\n            raise ValueError(\"Getter is none!\")\n        else:\n            if self.debug > 0:\n                print(getter)\n        temp =  {\n            \"PicamValueType_Integer\" : ct.c_int(),\n            \"PicamValueType_Boolean\" : ct.c_bool(),\n            \"PicamValueType_LargeInteger\" : ct.c_long(),\n\n            \"PicamValueType_FloatingPoint\" : ct.c_double(),\n\n            \"PicamValueType_Enumeration\": ct.c_int(), #TODO \n            \"PicamValueType_Rois\": None, #TODO\n            \"PicamValueType_Pulse\": None, #TODO\n            \"PicamValueType_Modulations\": None #None       \n        }\n        \n\n\n        value = temp[param_type]\n        if self.debug > 0:\n            print(\"pixis.get_parameter::param_type: {}\".format(param_type))\n            print(\"pixis.get_parameter::value: {}\".format(value))\n        if value is not None:\n            response = getter(self.CameraHandle,param_id, ct.pointer(value))\n\n            if response != 0:\n                print((\"Could not GET value of parameter {0} [label:{1}]\".format(parameter_name,label)))\n                print((\"[Code:{0}] {1}\".format(response, PicamError[response])))\n                return np.nan\n        \n            return value.value\n        else:\n            '''\n            Cases left to implement:\n                PicamValueType_Enumeration,\n                PicamValueType_Rois,\n                PicamValueType_Pulse,\n                PicamValueType_Modulations\n            '''\n            raise NotImplementedError()",
  "def set_parameter(self,parameter_name,parameter_value):\n        '''\n        Perform GetParameterIntegerValue calls to DLL\n        parameter_name : name of parameter as specified in the picam_constants.py file\n        '''\n        assert(parameter_name in list(PicamParameter.keys())) #Check that the passed parameter name is valid (ie. in constants file)\n        param_type, constraint_type, n = PicamParameter[parameter_name]\n        param_id = PI_V(value_type=param_type, constraint_type= constraint_type, parameter_index=n)\n\n        #assert returned parameter value type is valid one\n        valid_value_types = list(transpose_dictionary(PicamValueType).keys())\n        assert(param_type in valid_value_types)\n\n        #assert returned parameter constraint type is valid one\n        valid_constraint_types = list(transpose_dictionary(PicamConstraintType).keys())\n        assert(constraint_type in valid_constraint_types)\n        \n\n        function_name = \"Picam_SetParameter{}Value\".format(param_type.replace(\"PicamValueType_\",\"\"))\n        setter = getattr(self.picam,function_name)\n        # setter = self.picam.Picam_SetParameterFloatingPointValue\n        if self.debug > 0:\n            print(\"Function name:\",function_name)\n            print(\"Paramer type, Constraint type, n:\", param_type, constraint_type, n)\n            print(\"Function object\", setter)\n        \n        temp =  {\n            \"PicamValueType_Integer\" : ct.c_int,\n            \"PicamValueType_Boolean\" : ct.c_bool,\n            \"PicamValueType_LargeInteger\" : ct.c_long,\n            \"PicamValueType_FloatingPoint\" : ct.c_double, #WARNING - THIS SHOULD BE A DOUBLE (64bit), NOT FLOAT (32bit) [for 32bit change to float]\n            \"PicamValueType_Enumeration\": ct.c_int, #Maybe an int \n            \"PicamValueType_Rois\": None, #TODO\n            \"PicamValueType_Pulse\": None, #TODO\n            \"PicamValueType_Modulations\": None #None       \n        }\n        \n        #allocate memory for parameter for DLL to populate\n        value = temp[param_type](parameter_value)\n\n        if value is not None:\n            if self.debug > 0:\n                print(\"setting: param_id:  {0}, value:{1}\".format(param_id,value))\n\n            response = setter(self.CameraHandle,param_id, value)\n            if response != 0:\n                print((\"Could not SET value of parameter {0} [label:{1}]\".format(parameter,label)))\n                print((\"[Code:{0}] {1}\".format(response, PicamError[response])))\n                return np.nan\n            #check if commit failed\n            failed_commit = (ct.c_int*10)()\n            failed_count = ct.c_int()\n            response = self.picam.Picam_CommitParameters(self.CameraHandle,ct.byref(failed_commit),ct.byref(failed_count))\n            if self.debug > 0:\n                print(\"Picam_CommitParameters response:\",response, failed_count, list(failed_commit))\n            \n            assert(int(failed_count.value) == 0)\n            #check if commit has passed\n            committed = ct.c_bool(False)\n            response = self.picam.Picam_AreParametersCommitted(self.CameraHandle,ct.byref(committed))\n            if self.debug> 0:\n                    print(\"Picam_CommitParameters response:\",response, committed)\n\n            assert(bool(committed.value) == True)\n            \n            return\n\n        else:\n            '''\n            Cases left to implement:\n                PicamValueType_Enumeration,\n                PicamValueType_Rois,\n                PicamValueType_Pulse,\n                PicamValueType_Modulations\n            '''\n            raise NotImplementedError()",
  "def StartUp(self):\n        cint_temp = ct.c_int()\n        # Find DLL\n        try:\n            self.picam = ct.WinDLL(os.path.normpath('{}/picam_64bit.dll'.format(PARENT_DIR)))\n        except Exception as e:\n            logging.warning(\"Error:\",e)\n            logging.info(\"Could not find picam dll\")\n            return\n        # Initialise library\n        bolInitialised = ct.c_bool(False)\n        if self.picam.Picam_InitializeLibrary() != 0:\n            print(\"Could not initialise library\")\n            return\n        self.picam.Picam_IsLibraryInitialized(ct.byref(bolInitialised))\n        if bolInitialised == ct.c_bool(False):\n            print(\"Library was not initialised\")\n            return\n        # Get camera handle\n        self.CameraHandle = ct.c_void_p()\n        if self.picam.Picam_OpenFirstCamera(ct.byref(self.CameraHandle)) != 0:\n            print(\"Could not find camera\")\n            return\n\n        self.x_max = self.FrameWidth = self.get_parameter(parameter_name=\"PicamParameter_SensorActiveWidth\", label=\"frame width\")\n        self.y_max = self.FrameHeight = self.get_parameter(parameter_name=\"PicamParameter_SensorActiveHeight\", label=\"frame height\")\n        print(\"Frame size:\", self.x_max, self.y_max)\n        self.bolRunning = True\n        self.SetTemperatureWithLock(-80.0)",
  "def ShutDown(self):\n        if self.bolRunning == False:\n            return\n        if self.picam.Picam_CloseCamera(self.CameraHandle) != 0:\n            print(\"Could not close camera\")\n            return\n        if self.picam.Picam_UninitializeLibrary() != 0:\n            print(\"Could not shut down library\")\n            return\n        self.bolRunning = False",
  "def SetExposureTime(self,time):\n        \n        param_name = \"PicamParameter_ExposureTime\"        \n        param_value = time #in milliseconds\n        self.set_parameter(parameter_name=param_name,parameter_value=param_value)",
  "def SetTemperatureWithLock(self,temperature):\n        self.__SetSensorTemperatureSetPoint(temperature)\n        status_code = p.GetTemperatureStatus()\n        while PicamSensorTemperatureStatus[status_code] != \"PicamSensorTemperatureStatus_Locked\":\n            print(\"TemperatureStatus: {3}[{2}] (current: {0}, target:{1})\".format(p.GetSensorTemperatureReading(), temperature,status_code, PicamSensorTemperatureStatus[status_code]))\n            time.sleep(0.5)\n            status_code = p.GetTemperatureStatus()\n\n        status_code = p.GetTemperatureStatus()\n        print(\"TemperatureStatus: {0} [{1}]\".format(PicamSensorTemperatureStatus[status_code], status_code))\n        return",
  "def GetSensorTemperatureReading(self):\n        param_name = \"PicamParameter_SensorTemperatureReading\"\n        return self.get_parameter(param_name)",
  "def __SetSensorTemperatureSetPoint(self,temperature):\n        '''\n            Do not use this method if you want to wait for temperature to stabilize, use SetTemperatureWithLock\n        '''\n        param_name = \"PicamParameter_SensorTemperatureSetPoint\"\n        return self.set_parameter(parameter_name=param_name,parameter_value=temperature)",
  "def GetTemperatureStatus(self):\n        '''\n        See picam_constants.PicamSensorTemperatureStatus for\n            int <-> status mappings\n        '''\n        param_name = \"PicamParameter_SensorTemperatureStatus\"\n        return self.get_parameter(param_name)",
  "def GetExposureTime(self):\n        param_name = \"PicamParameter_ExposureTime\"\n        #function call: PicamEnumeratedType_CoolingFanStatus\n        return self.get_parameter(parameter_name=param_name)",
  "def GetSensorType(self):\n        param_name = \"PicamParameter_SensorType\"\n        return self.get_parameter(parameter_name=param_name)",
  "def GetIntensifierStatus(self):\n        param_name = \"PicamParameter_IntensifierStatus\"\n        return self.get_parameter(parameter_name=param_name)",
  "def GetCurrentFrame(self):\n        \n        if self.bolRunning == False:\n            self.StartUp()\n        \n        structReadout = clsPicamReadoutStruct()\n        intErrorMask = ct.c_int()\n        \n        # Read in pointer to image buffer\n        if self.picam.Picam_Acquire(self.CameraHandle, 1, -1, \n                ct.byref(structReadout), ct.byref(intErrorMask)) != 0:\n            print(\"Image acquisition failed\")\n            return\n        if intErrorMask.value != 0:\n            print(\"Image acquisition returned an error\")\n            return\n        \n        # Get image\n        ctarr = (ct.c_uint16*(self.FrameWidth*self.FrameHeight)) # Create ctypes array\n        ctarr = ctarr.from_address(structReadout.ptr) # Read in array from pointer\n        nparr = np.array(ctarr) # Convert to numpy array\n        nparr = nparr.reshape((self.FrameWidth, self.FrameHeight)) # Reshape numpy array\n        \n        return nparr",
  "def to_bits(integer):\n    \"\"\" Returns a list of bits representing the integer in base 2. Used to parse over the capabilities\n    :param integer:\n    :return: list of 1s and 0s\n    \"\"\"\n    bits = integer.bit_length()\n    return [1 if integer & (1 << (bits-1-n)) else 0 for n in range(bits)]",
  "class AndorCapabilities(Structure):\n    _fields_ = [(\"ulSize\", c_ulong),\n                (\"ulAcqModes\", c_ulong),\n                (\"ulReadModes\", c_ulong),\n                (\"ulTriggerModes\", c_ulong),\n                (\"ulCameraType\", c_ulong),\n                (\"ulPixelMode\", c_ulong),\n                (\"ulSetFunctions\", c_ulong),\n                (\"ulGetFunctions\", c_ulong),\n                (\"ulFeatures\", c_ulong),\n                (\"ulPCICard\", c_ulong),\n                (\"ulEMGainCapability\", c_ulong),\n                (\"ulFTReadModes\", c_ulong)]",
  "class AndorWarning(Warning):\n    def __init__(self, code, msg, reply):\n        super(AndorWarning, self).__init__()\n        self.error_code = code\n        self.error_name = ERROR_CODE[code]\n\n        self.msg = msg\n        self.reply = reply\n\n    def __str__(self):\n        return self.error_name + '\\n Error sent: ' + self.msg + '\\n Error reply: ' + self.reply",
  "class AndorParameter(CameraParameter):\n    \"\"\"Light wrapper of the CameraParameter that ensures the getting and setting of values takes care of possible\n    multiple values\"\"\"\n\n    def __init__(self, parameter_name, doc=None, read_back=True):\n        super(AndorParameter, self).__init__(parameter_name, doc=doc, read_back=read_back)\n\n    def fget(self, obj):\n        value = super(AndorParameter, self).fget(obj)\n        if (type(value) == tuple) and (len(value) == 1):\n            return value[0]\n        else:\n            return value\n\n    def fset(self, obj, value):\n        if type(value) != tuple:\n            value = (value,)\n        super(AndorParameter, self).fset(obj, value)",
  "class AndorBase(object):\n    \"\"\"Base code handling the Andor SDK\n\n    Most of the code for this class is setting up a general way of reading and writing parameters, which are then set up\n    from the parameters dictionary after class definition.\n\n    The self.parameters dictionary contains all the information necessary to deal with the camera parameters. Each\n    entry in the dictionary corresponds to a specific parameter and allows you to specify the Get and/or Set command\n    name and datatype (from the .dll).\n\n    Most parameters are straightforward, since the Andor dll either has inputs (for setting parameters) or outputs\n    (for getting parameters). So you can just intuitively call GetParameter(name) or SetParameter(name, value) with name\n    and value provided by the user.\n    Some parameters, like VSSpeed, HSSpeed..., require inputs to get outputs, so the user must say, e.g.,\n        Andor.GetParameter('VSSpeed', 0)\n    Which does not return the current VSSpeed, but the VSSpeed (in microseconds) of the setting 0.\n    \"\"\"\n    def start(self, camera_index=None):\n        if not hasattr(self, '_logger'):\n            self._logger = LOGGER\n\n        if platform.system() == 'Windows':\n            directory = os.path.dirname(__file__)\n            bitness = platform.architecture()[0][:2]  # either 32 or 64\n            original_file = \"%s/atmcd%sd.dll\" % (directory, bitness)\n\n            if bitness == '32':\n                self.dll = windll.LoadLibrary(original_file)\n            elif bitness == '64':\n                self.dll = CDLL(original_file)\n            else:\n                raise Exception(\"Cannot detect Windows architecture\")\n        elif platform.system() == \"Linux\":\n            original_file = \"usr/local/lib/libandor.so\"\n            self.dll = cdll.LoadLibrary(original_file)\n        else:\n            raise Exception(\"Cannot detect operating system for Andor\")\n        self.parameters = parameters\n        self._parameters = dict()\n        for key, value in list(parameters.items()):\n            if 'value' in value:\n                self._parameters[key] = value['value']\n            else:\n                self._parameters[key] = None\n\n        self._initialized_cameras = []\n        if camera_index is None:\n            if self.get_andor_parameter('AvailableCameras') > 1:\n                self._logger.warn('More than one camera available, but no index provided. Initializing camera 0')\n            self.camera_index = 0\n        else:\n            self.camera_index = camera_index\n\n    def end(self):\n        \"\"\" Safe shutdown procedure \"\"\"\n        for camera in self._initialized_cameras:\n            self.CurrentCamera = camera\n            # If the camera is a Classic or iCCD, wait for the temperature to be higher than -20 before shutting down\n            if self.Capabilities['CameraType'] in [3, 4]:\n                if self.cooler:\n                    self.cooler = 0\n                while self.CurrentTemperature < -20:\n                    print('Waiting')\n                    time.sleep(1)\n            self._logger.info('Shutting down %s' % camera)\n            self._dll_wrapper('ShutDown')\n\n    '''Base functions'''\n\n    @locked_action\n    def _dll_wrapper(self, funcname, inputs=(), outputs=(), reverse=False):\n        \"\"\"Handler for all the .dll calls of the Andor\n\n        :param funcname:    name of the dll function to be called\n        :param inputs:      inputs to be handed in to the dll function\n        :param outputs:     outputs to be expected from the dll\n        :param reverse:     bool. whether to have the inputs first or the outputs first when calling the dll\n        :return:\n        \"\"\"\n        self._logger.debug('DLL call: %s, %s, %s' % (funcname, inputs, outputs))\n        dll_input = ()\n        if reverse:\n            for output in outputs:\n                dll_input += (byref(output),)\n            for inpt in inputs:\n                dll_input += (inpt['type'](inpt['value']),)\n        else:\n            for inpt in inputs:\n                dll_input += (inpt['type'](inpt['value']),)\n            for output in outputs:\n                dll_input += (byref(output),)\n        error = getattr(self.dll, funcname)(*dll_input)\n        self._error_handler(error, funcname, *(inputs + outputs))\n\n        return_values = ()\n        for output in outputs:\n            if hasattr(output, 'value'):\n                return_values += (output.value,)\n            if isinstance(output, AndorCapabilities):\n                dicc = {}\n                for key, value in output._fields_:\n                    dicc[key[2:]] = getattr(output, key)\n                return_values += (dicc,)\n        if len(return_values) == 1:\n            return return_values[0]\n        else:\n            return return_values\n\n    def _error_handler(self, error, funcname='', *args):\n        self._logger.debug(\"[%s]: %s %s\" % (funcname, ERROR_CODE[error], str(args)))\n        if funcname == 'GetTemperature':\n            return\n        if error != 20002:\n            raise AndorWarning(error, funcname, ERROR_CODE[error])\n   \n    def set_andor_parameter(self, param_loc, *inputs):\n        \"\"\"Parameter setter\n\n        Using the information contained in the self.parameters dictionary, send a general parameter set command to the\n        Andor. The command name, and number of inputs and their types are stored in the self.parameters\n\n        :param param_loc: dictionary key of self.parameters\n        :param inputs: inputs required to set the particular parameter. Must be at least one\n        :return:\n        \"\"\"\n        \n        if len(inputs) == 1 and type(inputs[0]) == tuple:\n            if len(np.shape(inputs)) == 2:\n                inputs = inputs[0]\n            elif len(np.shape(inputs)) == 3:\n                inputs = inputs[0][0]\n        if 'not_supported' in self.parameters[param_loc] and self.parameters[param_loc]['not_supported']:\n            return\n        if 'Set' in self.parameters[param_loc]:\n            func = self.parameters[param_loc]['Set']\n\n            form_in = ()\n            if 'Input_params' in func:\n                for input_param in func['Input_params']:\n                    form_in += ({'value': getattr(self, input_param[0]),\n                                  'type': input_param[1]},)\n            for val, typ in zip(inputs, func['Inputs']):\n                form_in += ({'value':val, 'type': typ},)\n\n            form_out = ()\n            if 'Outputs' in func:\n                for val in func['Outputs']:\n                    form_out += (val(), )\n\n            try:\n                self._dll_wrapper(func['cmdName'], inputs=form_in, outputs=form_out)\n\n                if len(inputs) == 1:\n                    self.parameters[param_loc]['value'] = inputs[0]\n                    self._parameters[param_loc] = inputs[0]\n                else:\n                    self.parameters[param_loc]['value'] = inputs\n                    self._parameters[param_loc] = inputs\n\n                if 'Finally' in self.parameters[param_loc]:\n                    self.get_andor_parameter(self.parameters[param_loc]['Finally'])\n            except AndorWarning as andor_warning:\n                if andor_warning.error_name == 'DRV_NOT_SUPPORTED':\n                    if self.parameters[param_loc]['value'] is None:\n                        self._logger.error('Not supported parameter and None value in the parameter dictionary')\n                    else:\n                        self.parameters[param_loc]['not_supported'] = True\n                        inputs = self.parameters[param_loc]['value']\n                        if not isinstance(inputs, tuple):\n                            inputs = (inputs, )\n                else:\n                    self._logger.warn(andor_warning)\n                    raise andor_warning\n\n        if 'Get' not in list(self.parameters[param_loc].keys()):\n            if len(inputs) == 1:\n                setattr(self, '_' + param_loc, inputs[0])\n            else:\n                setattr(self, '_' + param_loc, inputs)\n            self.parameters[param_loc]['value'] = getattr(self, '_' + param_loc)\n            self._parameters[param_loc] = getattr(self, '_' + param_loc)\n\n    def get_andor_parameter(self, param_loc, *inputs):\n        \"\"\"Parameter getter\n\n        Using the information contained in the self.parameters dictionary, send a general parameter get command to the\n        Andor. The command name, and number of inputs and their types are stored in the self.parameters\n\n        :param param_loc: dictionary key of self.parameters\n        :param inputs: optional inputs for getting the specific parameter\n        :return:\n        \"\"\"\n        if 'not_supported' in self.parameters[param_loc]:\n            self._logger.debug('Ignoring get %s because it is not supported' % param_loc)\n            self.parameters[param_loc]['value'] = getattr(self, '_' + param_loc)\n            self._parameters[param_loc] = getattr(self, '_' + param_loc)\n            return getattr(self, '_' + param_loc)\n        if 'Get' in list(self.parameters[param_loc].keys()):\n            func = self.parameters[param_loc]['Get']\n\n            form_out = ()\n            if param_loc == 'Capabilities':\n                form_out += (func['Outputs'][0],)\n            else:\n                for output in func['Outputs']:\n                    form_out += (output(),)\n            form_in = ()\n            if 'Input_params' in func:\n                for input_param in func['Input_params']:\n                    form_in += ({'value': getattr(self, input_param[0]), 'type': input_param[1]},)\n            for ii in range(len(inputs)):\n                form_in += ({'value': inputs[ii], 'type': func['Inputs'][ii]},)\n            if 'Iterator' not in list(func.keys()):\n                vals = self._dll_wrapper(func['cmdName'], inputs=form_in, outputs=form_out)\n            else:\n                vals = ()\n                for i in range(getattr(self, func['Iterator'])):\n                    form_in_iterator = form_in + ({'value': i, 'type': c_int},)\n                    vals += (self._dll_wrapper(func['cmdName'], inputs=form_in_iterator, outputs=form_out),)\n            self.parameters[param_loc]['value'] = vals\n            self._parameters[param_loc] = vals\n            return vals\n        elif 'Get_from_prop' in list(self.parameters[param_loc].keys()) and hasattr(self, '_' + param_loc):\n            vals = getattr(self, self.parameters[param_loc]['Get_from_prop'])[getattr(self, '_' + param_loc)]\n            self.parameters[param_loc]['value'] = vals\n            self._parameters[param_loc] = vals\n            return vals\n        elif 'Get_from_fixed_prop' in list(self.parameters[param_loc].keys()):\n            vals = getattr(self, self.parameters[param_loc]['Get_from_fixed_prop'])[0]\n            self.parameters[param_loc]['value'] = vals\n            self._parameters[param_loc] = vals\n            return vals\n\n        elif hasattr(self, '_' + param_loc):\n            self.parameters[param_loc]['value'] = getattr(self, '_' + param_loc)\n            self._parameters[param_loc] = getattr(self, '_' + param_loc)\n            return getattr(self, '_' + param_loc)\n        else:\n            self._logger.info('The ' + param_loc + ' has not previously been set!')\n            return None\n\n    def get_andor_parameters(self):\n        \"\"\"Gets all the parameters that can be gotten\n\n        :return: an up to date parameters dict containing only values and names\n        \"\"\"\n        param_dict = dict()\n        for param in self.parameters:\n            param_dict[param] = getattr(self, param)\n        return\n\n    def set_andor_parameters(self, parameter_dictionary):\n        \"\"\"Sets all parameters tha can be set\n\n        :param parameter_dictionary: dictionary of parameters to be set\n        :return:\n        \"\"\"\n\n        assert isinstance(parameter_dictionary, dict)\n        for name, value in list(parameter_dictionary.items()):\n            if not hasattr(self, name):\n                self._logger.warn('The parameter ' + name + 'does not exist and therefore cannot be set')\n                continue\n            if value is None:\n                self._logger.info('%s has not been set, as the value provided was \"None\" ' % name)\n                continue\n\n            if 'Get_from_prop' in self.parameters[name]:\n                value = getattr(self, self.parameters[name]['Get_from_prop'])[\n                    np.where(np.array(getattr(self, self.parameters[name]['Get_from_prop'])) == value)[0][0]]\n            try:\n                setattr(self, name, value)\n            except Exception as e:\n                self._logger.warn('Failed to set %s because %s' % (name, e))\n\n    '''Used functions'''\n\n    @property\n    def camera_index(self):\n        return self._camera_index\n\n    @camera_index.setter\n    def camera_index(self, value):\n        \"\"\"Ensures the DLL is changed every time the camera_index is changed.\n        CameraHandle calls the value of camera_index\"\"\"\n        self._camera_index = value\n        self.CurrentCamera = self.CameraHandle\n        self.initialize()\n\n    @property\n    def capabilities(self):\n        \"\"\"Parsing of the Andor capabilities\n\n        Transforming bit values contained in the self.Capabilities attribute into human-understandable parameters, as\n        given by the manual\n\n        :return:\n        \"\"\"\n        capabilities = dict(AcqModes=[], ReadModes=[], FTReadModes=[], TriggerModes=[], CameraType=None, PixelMode=[],\n                            SetFunctions=[], GetFunctions=[], Features=[], PCICard=None, EMGainCapability=[])\n\n        bits = to_bits(self.Capabilities['AcqModes'])\n        keys = ['Single', 'Video', 'Accumulate', 'Kinetic', 'FrameTransfer', 'FastKinetic', 'Overlap']\n        for bit, key in zip(bits, keys):\n            if bit:\n                capabilities['AcqModes'] += [key]\n\n        bits = to_bits(self.Capabilities['ReadModes'])\n        keys = ['FullImage', 'SubImage', 'SingleTrack', 'FVB', 'MultiTrack', 'RandomTrack']\n        for bit, key in zip(bits, keys):\n            if bit:\n                capabilities['ReadModes'] += [key]\n\n        bits = to_bits(self.Capabilities['FTReadModes'])  # Frame transfer read modes\n        keys = ['FullImage', 'SubImage', 'SingleTrack', 'FVB', 'MultiTrack', 'RandomTrack']\n        for bit, key in zip(bits, keys):\n            if bit:\n                capabilities['FTReadModes'] += [key]\n\n        bits = to_bits(self.Capabilities['TriggerModes'])\n        keys = ['Internal', 'External', 'External_FVB_EM', 'Continuous',\n                'ExternalStart', 'Bulb', 'ExternalExposure', 'Inverted']\n        for bit, key in zip(bits, keys):\n            if bit:\n                capabilities['TriggerModes'] += [key]\n\n        keys = ['PDA', 'iXon', 'iCCD', 'EMCCD', 'CCD', 'iStar', 'Video', 'iDus', 'Newton',\n                'Surcam', 'USBiStar', 'Luca', 'Reserved', 'iKon', 'InGaAs', 'iVac', 'Clara']\n        capabilities['CameraType'] = keys[int(self.Capabilities['CameraType'])]\n\n        bits = to_bits(self.Capabilities['PixelMode'])\n        keys = ['8bit', '14bit', '16bit', '32bit', 'mono', 'RGB', 'CMY']\n        for bit, key in zip(bits, keys):\n            if bit:\n                capabilities['PixelMode'] += [key]\n\n        bits = to_bits(self.Capabilities['SetFunctions'])\n        keys = ['VSSpeed', 'HSSpeed', 'Temperature', 'MCPGain', 'EMCCDGain', 'BaselineClamp', 'VSAmplitude',\n                'HighCapacity', 'BaselineOffset', 'PreAmpGain', 'CropMode/IsolatedCropMode', 'DMAParameters',\n                'HorizontalBin', 'MultiTrackHRange', 'RandomTracks', 'EMAdvanced']\n        for bit, key in zip(bits, keys):\n            if bit:\n                capabilities['SetFunctions'] += [key]\n\n        bits = to_bits(self.Capabilities['GetFunctions'])\n        keys = ['Temperature', 'TemperatureRange', 'Detector', 'MCPGain', 'EMCCDGain', 'BaselineClamp']\n        for bit, key in zip(bits, keys):\n            if bit:\n                capabilities['GetFunctions'] += [key]\n\n        bits = to_bits(self.Capabilities['Features'])\n        keys = ['Status', 'DriverEvent', 'Spool', 'Shutter', 'ShutterEx', 'I2C', 'SaturationEvent', 'FanMode',\n                'LowFanMode', 'TemperatureDuringAcquitisition', 'KeepClean', 'Internal', 'FTandExternalExposure',\n                'KineticAndExternalExposure', 'Internal', 'Internal', 'IOcontrol', 'PhotonCounting', 'CountConvert',\n                'DualMode']\n        for bit, key in zip(bits, keys):\n            if bit:\n                capabilities['Features'] += [key]\n\n        capabilities['PCICard'] = int(self.Capabilities['PCICard'])\n\n        bits = to_bits(self.Capabilities['EMGainCapability'])\n        keys = ['8bit', '12bit', 'Linear12', 'Real12']\n        for bit, key in zip(bits, keys):\n            if bit:\n                capabilities['EMGainCapability'] += [key]\n\n        return capabilities\n\n    def abort(self):\n        try:\n            self._dll_wrapper('AbortAcquisition')\n        except AndorWarning:\n            pass\n\n    def initialize(self):\n        \"\"\"Sets the initial parameters for the Andor typical for our experiments\"\"\"\n        if self.CurrentCamera not in self._initialized_cameras:\n            self._initialized_cameras += [self.CurrentCamera]\n            self._dll_wrapper('Initialize', outputs=(c_char(),))\n        self.channel = 0\n        self.set_andor_parameter('ReadMode', 4)\n        self.set_andor_parameter('AcquisitionMode', 1)\n        self.set_andor_parameter('TriggerMode', 0)\n        self.set_andor_parameter('Exposure', 1)\n        detector_shape = self.get_andor_parameter('DetectorShape')\n        self.set_andor_parameter('Image', 1, 1, 1, detector_shape[0], 1, detector_shape[1])\n        self.set_andor_parameter('Shutter', 1, 0, 0, 0)\n        self.set_andor_parameter('SetTemperature', -90)\n        self.set_andor_parameter('CoolerMode', 0)\n        self.set_andor_parameter('FanMode', 0)\n        try:\n            self.set_andor_parameter('OutAmp', 1)  # This means EMCCD off - this is the default mode\n        except AndorWarning:\n            self.set_andor_parameter('OutAmp', 0)\n        self.cooler = 1\n\n    @locked_action\n    def capture(self):\n        \"\"\"Capture an image\n\n        Wraps the three steps required for a camera acquisition: StartAcquisition, WaitForAcquisition and\n        GetAcquiredData. The function also takes care of ensuring that the correct shape of array is passed to the\n        GetAcquiredData call, according to the currently set parameters of the camera.\n\n        :return:\n            np.array    2D or 3D array of the captured image(s)\n            int         number of images taken\n            tuple       shape of the images taken\n        \"\"\"\n        self._dll_wrapper('StartAcquisition')\n        self._dll_wrapper('WaitForAcquisition')\n        self.wait_for_driver()\n        if self._parameters['AcquisitionMode'] == 4:\n            num_of_images = 1  # self.parameters['FastKinetics']['value'][1]\n            image_shape = (self._parameters['FastKinetics'][-1], self._parameters['DetectorShape'][0])\n        else:\n            if self._parameters['AcquisitionMode'] == 1:\n                num_of_images = 1\n            elif self._parameters['AcquisitionMode'] == 2:\n                num_of_images = 1\n            elif self._parameters['AcquisitionMode'] == 3:\n                num_of_images = self._parameters['NKin']\n            else:\n                raise NotImplementedError('Acquisition Mode %g' % self._parameters['AcquisitionMode'])\n\n            if self._parameters['ReadMode'] == 0:\n                if self._parameters['IsolatedCropMode'][0]:\n                    image_shape = (self._parameters['IsolatedCropMode'][2] // self._parameters['IsolatedCropMode'][4], )\n                else:\n                    image_shape = (self._parameters['DetectorShape'][0] // self._parameters['FVBHBin'], )\n            elif self._parameters['ReadMode'] == 1:  # random track\n                image_shape = (self.MultiTrack[0], self._parameters['DetectorShape'][0] // self._parameters['FVBHBin'])\n            elif self._parameters['ReadMode'] == 2:\n                image_shape = ( self.RandomTracks[0], self._parameters['DetectorShape'][0]// self._parameters['FVBHBin'])\n                 \n            elif self._parameters['ReadMode'] == 3:\n                image_shape = (self._parameters['DetectorShape'][0],)\n            elif self._parameters['ReadMode'] == 4:\n                # if self._parameters['IsolatedCropMode'][0]:\n                #     image_shape = (\n                #         self._parameters['IsolatedCropMode'][1] / self._parameters['IsolatedCropMode'][3],\n                #         self._parameters['IsolatedCropMode'][2] / self._parameters['IsolatedCropMode'][4])\n                # else:\n                image_shape = (\n                    (self._parameters['Image'][5] - self._parameters['Image'][4] + 1) // self._parameters['Image'][1],\n                    (self._parameters['Image'][3] - self._parameters['Image'][2] + 1) // self._parameters['Image'][0],)\n            else:\n                raise NotImplementedError('Read Mode %g' % self._parameters['ReadMode'])\n\n        image_shape = tuple([int(x) for x in image_shape])\n        dim = num_of_images * np.prod(image_shape)\n        cimageArray = c_int * dim\n        cimage = cimageArray()\n        self._logger.debug('Getting AcquiredData for %i images with dimension %s' % (num_of_images, image_shape))\n        try:\n            self._dll_wrapper('GetAcquiredData', inputs=({'type': c_int, 'value': dim},), outputs=(cimage,),\n                              reverse=True)\n            imageArray = []\n            for i in range(len(cimage)):\n                imageArray.append(cimage[i])\n        except RuntimeWarning as e:\n            self._logger.warn('Had a RuntimeWarning: %s' % e)\n            imageArray = []\n            for i in range(len(cimage)):\n                imageArray.append(0)\n\n        return imageArray, num_of_images, image_shape\n\n    @property\n    def Image(self):\n        return self.get_andor_parameter('Image')\n\n    @Image.setter\n    def Image(self, value):\n        \"\"\"Ensures a valid image shape is passed\n\n        e.g. if binning is 2x2, and an image with an odd number of pixels along one direction is passed, this function\n        rounds it down to the nearest even number, providing a valid image shape\n\n        :param value:\n        :return:\n        \"\"\"\n        if len(value) == 4:\n            image = self._parameters['Image']\n            value = image[:2] + value\n        # Making sure we pass a valid set of parameters\n        value = list(value)\n        value[3] -= (value[3] - value[2] + 1) % value[0]\n        value[5] -= (value[5] - value[4] + 1) % value[1]\n\n        self.set_andor_parameter('Image', *value)\n\n        crop = self.IsolatedCropMode\n        if crop is not None:\n            crop = [crop[0], value[5], value[3], value[0], value[1]]\n        else:\n            crop = [0, value[5], value[3], value[0], value[1]]\n        self.set_andor_parameter('IsolatedCropMode', *crop)\n\n    @locked_action\n    def set_fast_kinetics(self, n_rows=None):\n        \"\"\"Set the parameters for the Fast Kinetic mode\n\n        Uses the already set parameters of exposure time, ReadMode, and binning as defaults to be passed to the Fast\n        Kinetic parameter setter\n\n        :param n_rows: int. Number of rows to use\n        :return:\n        \"\"\"\n\n        if n_rows is None:\n            n_rows = self._parameters['FastKinetics'][0]\n\n        series_Length = int(self._parameters['DetectorShape'][1] // n_rows) - 1\n        expT = self._parameters['AcquisitionTimings'][0]\n        mode = self._parameters['ReadMode']\n        hbin = self._parameters['Image'][0]\n        vbin = self._parameters['Image'][1]\n        offset = self._parameters['DetectorShape'][1] - n_rows\n\n        self.set_andor_parameter('FastKinetics', n_rows, series_Length, expT, mode, hbin, vbin, offset)\n    \n    \n    @locked_action    \n    def SetRandomTracks(self, number_tracks_and_pixels):\n        number_tracks, pixels = number_tracks_and_pixels\n        assert len(pixels)/number_tracks == 2\n        self._RandomTracks = number_tracks, pixels\n        number_tracks = c_int(number_tracks)\n        arr = c_int * len(pixels)\n        c_pixels = arr(*pixels)\n        return self.dll.SetRandomTracks(number_tracks, byref(c_pixels))\n    \n    def GetRandomTracks(self):\n        return self._RandomTracks\n    RandomTracks = property(GetRandomTracks, SetRandomTracks)\n\n    @property\n    def status(self):\n        error = self._dll_wrapper('GetStatus', outputs=(c_int(),))\n        return ERROR_CODE[error]\n\n    @locked_action\n    def wait_for_driver(self):\n        \"\"\"This function is here because the dll.WaitForAcquisition does not work when in Accumulate mode\"\"\"\n        status = c_int()\n        self.dll.GetStatus(byref(status))\n        while ERROR_CODE[status.value] == 'DRV_ACQUIRING':\n            time.sleep(0.1)\n            self.dll.GetStatus(byref(status))\n\n    @property\n    def cooler(self):\n        return self._dll_wrapper('IsCoolerOn', outputs=(c_int(),))\n\n    @cooler.setter\n    def cooler(self, value):\n        if value:\n            self._dll_wrapper('CoolerON')\n        else:\n            self._dll_wrapper('CoolerOFF')\n\n    def get_series_progress(self):\n        acc = c_long()\n        series = c_long()\n        error = self.dll.GetAcquisitionProgress(byref(acc), byref(series))\n        if ERROR_CODE[error] == \"DRV_SUCCESS\":\n            return series.value\n        else:\n            return None\n\n    def get_accumulation_progress(self):\n        acc = c_long()\n        series = c_long()\n        error = self.dll.GetAcquisitionProgress(byref(acc), byref(series))\n        if ERROR_CODE[error] == \"DRV_SUCCESS\":\n            return acc.value\n        else:\n            return None\n\n    def save_params_to_file(self, filepath=None):\n        if filepath is None:\n            data_file = df.create_file(set_current=False, mode='a')\n        else:\n            data_file = df.DataFile(filepath)\n        data_file.create_dataset(name='AndorSettings', data=[], attrs=self.get_andor_parameters())\n        data_file.close()\n\n    def load_params_from_file(self, filepath=None):\n        if filepath is None:\n            data_file = df.open_file(set_current=False, mode='r')\n        else:\n            data_file = df.DataFile(filepath)\n        if 'AndorSettings' in list(data_file.keys()):\n            self.set_andor_parameters(dict(data_file['AndorSettings'].attrs))\n        else:\n            self._logger.error('Load settings failed as \"AndorSettings\" does not exist')\n        data_file.close()",
  "def __init__(self, code, msg, reply):\n        super(AndorWarning, self).__init__()\n        self.error_code = code\n        self.error_name = ERROR_CODE[code]\n\n        self.msg = msg\n        self.reply = reply",
  "def __str__(self):\n        return self.error_name + '\\n Error sent: ' + self.msg + '\\n Error reply: ' + self.reply",
  "def __init__(self, parameter_name, doc=None, read_back=True):\n        super(AndorParameter, self).__init__(parameter_name, doc=doc, read_back=read_back)",
  "def fget(self, obj):\n        value = super(AndorParameter, self).fget(obj)\n        if (type(value) == tuple) and (len(value) == 1):\n            return value[0]\n        else:\n            return value",
  "def fset(self, obj, value):\n        if type(value) != tuple:\n            value = (value,)\n        super(AndorParameter, self).fset(obj, value)",
  "def start(self, camera_index=None):\n        if not hasattr(self, '_logger'):\n            self._logger = LOGGER\n\n        if platform.system() == 'Windows':\n            directory = os.path.dirname(__file__)\n            bitness = platform.architecture()[0][:2]  # either 32 or 64\n            original_file = \"%s/atmcd%sd.dll\" % (directory, bitness)\n\n            if bitness == '32':\n                self.dll = windll.LoadLibrary(original_file)\n            elif bitness == '64':\n                self.dll = CDLL(original_file)\n            else:\n                raise Exception(\"Cannot detect Windows architecture\")\n        elif platform.system() == \"Linux\":\n            original_file = \"usr/local/lib/libandor.so\"\n            self.dll = cdll.LoadLibrary(original_file)\n        else:\n            raise Exception(\"Cannot detect operating system for Andor\")\n        self.parameters = parameters\n        self._parameters = dict()\n        for key, value in list(parameters.items()):\n            if 'value' in value:\n                self._parameters[key] = value['value']\n            else:\n                self._parameters[key] = None\n\n        self._initialized_cameras = []\n        if camera_index is None:\n            if self.get_andor_parameter('AvailableCameras') > 1:\n                self._logger.warn('More than one camera available, but no index provided. Initializing camera 0')\n            self.camera_index = 0\n        else:\n            self.camera_index = camera_index",
  "def end(self):\n        \"\"\" Safe shutdown procedure \"\"\"\n        for camera in self._initialized_cameras:\n            self.CurrentCamera = camera\n            # If the camera is a Classic or iCCD, wait for the temperature to be higher than -20 before shutting down\n            if self.Capabilities['CameraType'] in [3, 4]:\n                if self.cooler:\n                    self.cooler = 0\n                while self.CurrentTemperature < -20:\n                    print('Waiting')\n                    time.sleep(1)\n            self._logger.info('Shutting down %s' % camera)\n            self._dll_wrapper('ShutDown')",
  "def _dll_wrapper(self, funcname, inputs=(), outputs=(), reverse=False):\n        \"\"\"Handler for all the .dll calls of the Andor\n\n        :param funcname:    name of the dll function to be called\n        :param inputs:      inputs to be handed in to the dll function\n        :param outputs:     outputs to be expected from the dll\n        :param reverse:     bool. whether to have the inputs first or the outputs first when calling the dll\n        :return:\n        \"\"\"\n        self._logger.debug('DLL call: %s, %s, %s' % (funcname, inputs, outputs))\n        dll_input = ()\n        if reverse:\n            for output in outputs:\n                dll_input += (byref(output),)\n            for inpt in inputs:\n                dll_input += (inpt['type'](inpt['value']),)\n        else:\n            for inpt in inputs:\n                dll_input += (inpt['type'](inpt['value']),)\n            for output in outputs:\n                dll_input += (byref(output),)\n        error = getattr(self.dll, funcname)(*dll_input)\n        self._error_handler(error, funcname, *(inputs + outputs))\n\n        return_values = ()\n        for output in outputs:\n            if hasattr(output, 'value'):\n                return_values += (output.value,)\n            if isinstance(output, AndorCapabilities):\n                dicc = {}\n                for key, value in output._fields_:\n                    dicc[key[2:]] = getattr(output, key)\n                return_values += (dicc,)\n        if len(return_values) == 1:\n            return return_values[0]\n        else:\n            return return_values",
  "def _error_handler(self, error, funcname='', *args):\n        self._logger.debug(\"[%s]: %s %s\" % (funcname, ERROR_CODE[error], str(args)))\n        if funcname == 'GetTemperature':\n            return\n        if error != 20002:\n            raise AndorWarning(error, funcname, ERROR_CODE[error])",
  "def set_andor_parameter(self, param_loc, *inputs):\n        \"\"\"Parameter setter\n\n        Using the information contained in the self.parameters dictionary, send a general parameter set command to the\n        Andor. The command name, and number of inputs and their types are stored in the self.parameters\n\n        :param param_loc: dictionary key of self.parameters\n        :param inputs: inputs required to set the particular parameter. Must be at least one\n        :return:\n        \"\"\"\n        \n        if len(inputs) == 1 and type(inputs[0]) == tuple:\n            if len(np.shape(inputs)) == 2:\n                inputs = inputs[0]\n            elif len(np.shape(inputs)) == 3:\n                inputs = inputs[0][0]\n        if 'not_supported' in self.parameters[param_loc] and self.parameters[param_loc]['not_supported']:\n            return\n        if 'Set' in self.parameters[param_loc]:\n            func = self.parameters[param_loc]['Set']\n\n            form_in = ()\n            if 'Input_params' in func:\n                for input_param in func['Input_params']:\n                    form_in += ({'value': getattr(self, input_param[0]),\n                                  'type': input_param[1]},)\n            for val, typ in zip(inputs, func['Inputs']):\n                form_in += ({'value':val, 'type': typ},)\n\n            form_out = ()\n            if 'Outputs' in func:\n                for val in func['Outputs']:\n                    form_out += (val(), )\n\n            try:\n                self._dll_wrapper(func['cmdName'], inputs=form_in, outputs=form_out)\n\n                if len(inputs) == 1:\n                    self.parameters[param_loc]['value'] = inputs[0]\n                    self._parameters[param_loc] = inputs[0]\n                else:\n                    self.parameters[param_loc]['value'] = inputs\n                    self._parameters[param_loc] = inputs\n\n                if 'Finally' in self.parameters[param_loc]:\n                    self.get_andor_parameter(self.parameters[param_loc]['Finally'])\n            except AndorWarning as andor_warning:\n                if andor_warning.error_name == 'DRV_NOT_SUPPORTED':\n                    if self.parameters[param_loc]['value'] is None:\n                        self._logger.error('Not supported parameter and None value in the parameter dictionary')\n                    else:\n                        self.parameters[param_loc]['not_supported'] = True\n                        inputs = self.parameters[param_loc]['value']\n                        if not isinstance(inputs, tuple):\n                            inputs = (inputs, )\n                else:\n                    self._logger.warn(andor_warning)\n                    raise andor_warning\n\n        if 'Get' not in list(self.parameters[param_loc].keys()):\n            if len(inputs) == 1:\n                setattr(self, '_' + param_loc, inputs[0])\n            else:\n                setattr(self, '_' + param_loc, inputs)\n            self.parameters[param_loc]['value'] = getattr(self, '_' + param_loc)\n            self._parameters[param_loc] = getattr(self, '_' + param_loc)",
  "def get_andor_parameter(self, param_loc, *inputs):\n        \"\"\"Parameter getter\n\n        Using the information contained in the self.parameters dictionary, send a general parameter get command to the\n        Andor. The command name, and number of inputs and their types are stored in the self.parameters\n\n        :param param_loc: dictionary key of self.parameters\n        :param inputs: optional inputs for getting the specific parameter\n        :return:\n        \"\"\"\n        if 'not_supported' in self.parameters[param_loc]:\n            self._logger.debug('Ignoring get %s because it is not supported' % param_loc)\n            self.parameters[param_loc]['value'] = getattr(self, '_' + param_loc)\n            self._parameters[param_loc] = getattr(self, '_' + param_loc)\n            return getattr(self, '_' + param_loc)\n        if 'Get' in list(self.parameters[param_loc].keys()):\n            func = self.parameters[param_loc]['Get']\n\n            form_out = ()\n            if param_loc == 'Capabilities':\n                form_out += (func['Outputs'][0],)\n            else:\n                for output in func['Outputs']:\n                    form_out += (output(),)\n            form_in = ()\n            if 'Input_params' in func:\n                for input_param in func['Input_params']:\n                    form_in += ({'value': getattr(self, input_param[0]), 'type': input_param[1]},)\n            for ii in range(len(inputs)):\n                form_in += ({'value': inputs[ii], 'type': func['Inputs'][ii]},)\n            if 'Iterator' not in list(func.keys()):\n                vals = self._dll_wrapper(func['cmdName'], inputs=form_in, outputs=form_out)\n            else:\n                vals = ()\n                for i in range(getattr(self, func['Iterator'])):\n                    form_in_iterator = form_in + ({'value': i, 'type': c_int},)\n                    vals += (self._dll_wrapper(func['cmdName'], inputs=form_in_iterator, outputs=form_out),)\n            self.parameters[param_loc]['value'] = vals\n            self._parameters[param_loc] = vals\n            return vals\n        elif 'Get_from_prop' in list(self.parameters[param_loc].keys()) and hasattr(self, '_' + param_loc):\n            vals = getattr(self, self.parameters[param_loc]['Get_from_prop'])[getattr(self, '_' + param_loc)]\n            self.parameters[param_loc]['value'] = vals\n            self._parameters[param_loc] = vals\n            return vals\n        elif 'Get_from_fixed_prop' in list(self.parameters[param_loc].keys()):\n            vals = getattr(self, self.parameters[param_loc]['Get_from_fixed_prop'])[0]\n            self.parameters[param_loc]['value'] = vals\n            self._parameters[param_loc] = vals\n            return vals\n\n        elif hasattr(self, '_' + param_loc):\n            self.parameters[param_loc]['value'] = getattr(self, '_' + param_loc)\n            self._parameters[param_loc] = getattr(self, '_' + param_loc)\n            return getattr(self, '_' + param_loc)\n        else:\n            self._logger.info('The ' + param_loc + ' has not previously been set!')\n            return None",
  "def get_andor_parameters(self):\n        \"\"\"Gets all the parameters that can be gotten\n\n        :return: an up to date parameters dict containing only values and names\n        \"\"\"\n        param_dict = dict()\n        for param in self.parameters:\n            param_dict[param] = getattr(self, param)\n        return",
  "def set_andor_parameters(self, parameter_dictionary):\n        \"\"\"Sets all parameters tha can be set\n\n        :param parameter_dictionary: dictionary of parameters to be set\n        :return:\n        \"\"\"\n\n        assert isinstance(parameter_dictionary, dict)\n        for name, value in list(parameter_dictionary.items()):\n            if not hasattr(self, name):\n                self._logger.warn('The parameter ' + name + 'does not exist and therefore cannot be set')\n                continue\n            if value is None:\n                self._logger.info('%s has not been set, as the value provided was \"None\" ' % name)\n                continue\n\n            if 'Get_from_prop' in self.parameters[name]:\n                value = getattr(self, self.parameters[name]['Get_from_prop'])[\n                    np.where(np.array(getattr(self, self.parameters[name]['Get_from_prop'])) == value)[0][0]]\n            try:\n                setattr(self, name, value)\n            except Exception as e:\n                self._logger.warn('Failed to set %s because %s' % (name, e))",
  "def camera_index(self):\n        return self._camera_index",
  "def camera_index(self, value):\n        \"\"\"Ensures the DLL is changed every time the camera_index is changed.\n        CameraHandle calls the value of camera_index\"\"\"\n        self._camera_index = value\n        self.CurrentCamera = self.CameraHandle\n        self.initialize()",
  "def capabilities(self):\n        \"\"\"Parsing of the Andor capabilities\n\n        Transforming bit values contained in the self.Capabilities attribute into human-understandable parameters, as\n        given by the manual\n\n        :return:\n        \"\"\"\n        capabilities = dict(AcqModes=[], ReadModes=[], FTReadModes=[], TriggerModes=[], CameraType=None, PixelMode=[],\n                            SetFunctions=[], GetFunctions=[], Features=[], PCICard=None, EMGainCapability=[])\n\n        bits = to_bits(self.Capabilities['AcqModes'])\n        keys = ['Single', 'Video', 'Accumulate', 'Kinetic', 'FrameTransfer', 'FastKinetic', 'Overlap']\n        for bit, key in zip(bits, keys):\n            if bit:\n                capabilities['AcqModes'] += [key]\n\n        bits = to_bits(self.Capabilities['ReadModes'])\n        keys = ['FullImage', 'SubImage', 'SingleTrack', 'FVB', 'MultiTrack', 'RandomTrack']\n        for bit, key in zip(bits, keys):\n            if bit:\n                capabilities['ReadModes'] += [key]\n\n        bits = to_bits(self.Capabilities['FTReadModes'])  # Frame transfer read modes\n        keys = ['FullImage', 'SubImage', 'SingleTrack', 'FVB', 'MultiTrack', 'RandomTrack']\n        for bit, key in zip(bits, keys):\n            if bit:\n                capabilities['FTReadModes'] += [key]\n\n        bits = to_bits(self.Capabilities['TriggerModes'])\n        keys = ['Internal', 'External', 'External_FVB_EM', 'Continuous',\n                'ExternalStart', 'Bulb', 'ExternalExposure', 'Inverted']\n        for bit, key in zip(bits, keys):\n            if bit:\n                capabilities['TriggerModes'] += [key]\n\n        keys = ['PDA', 'iXon', 'iCCD', 'EMCCD', 'CCD', 'iStar', 'Video', 'iDus', 'Newton',\n                'Surcam', 'USBiStar', 'Luca', 'Reserved', 'iKon', 'InGaAs', 'iVac', 'Clara']\n        capabilities['CameraType'] = keys[int(self.Capabilities['CameraType'])]\n\n        bits = to_bits(self.Capabilities['PixelMode'])\n        keys = ['8bit', '14bit', '16bit', '32bit', 'mono', 'RGB', 'CMY']\n        for bit, key in zip(bits, keys):\n            if bit:\n                capabilities['PixelMode'] += [key]\n\n        bits = to_bits(self.Capabilities['SetFunctions'])\n        keys = ['VSSpeed', 'HSSpeed', 'Temperature', 'MCPGain', 'EMCCDGain', 'BaselineClamp', 'VSAmplitude',\n                'HighCapacity', 'BaselineOffset', 'PreAmpGain', 'CropMode/IsolatedCropMode', 'DMAParameters',\n                'HorizontalBin', 'MultiTrackHRange', 'RandomTracks', 'EMAdvanced']\n        for bit, key in zip(bits, keys):\n            if bit:\n                capabilities['SetFunctions'] += [key]\n\n        bits = to_bits(self.Capabilities['GetFunctions'])\n        keys = ['Temperature', 'TemperatureRange', 'Detector', 'MCPGain', 'EMCCDGain', 'BaselineClamp']\n        for bit, key in zip(bits, keys):\n            if bit:\n                capabilities['GetFunctions'] += [key]\n\n        bits = to_bits(self.Capabilities['Features'])\n        keys = ['Status', 'DriverEvent', 'Spool', 'Shutter', 'ShutterEx', 'I2C', 'SaturationEvent', 'FanMode',\n                'LowFanMode', 'TemperatureDuringAcquitisition', 'KeepClean', 'Internal', 'FTandExternalExposure',\n                'KineticAndExternalExposure', 'Internal', 'Internal', 'IOcontrol', 'PhotonCounting', 'CountConvert',\n                'DualMode']\n        for bit, key in zip(bits, keys):\n            if bit:\n                capabilities['Features'] += [key]\n\n        capabilities['PCICard'] = int(self.Capabilities['PCICard'])\n\n        bits = to_bits(self.Capabilities['EMGainCapability'])\n        keys = ['8bit', '12bit', 'Linear12', 'Real12']\n        for bit, key in zip(bits, keys):\n            if bit:\n                capabilities['EMGainCapability'] += [key]\n\n        return capabilities",
  "def abort(self):\n        try:\n            self._dll_wrapper('AbortAcquisition')\n        except AndorWarning:\n            pass",
  "def initialize(self):\n        \"\"\"Sets the initial parameters for the Andor typical for our experiments\"\"\"\n        if self.CurrentCamera not in self._initialized_cameras:\n            self._initialized_cameras += [self.CurrentCamera]\n            self._dll_wrapper('Initialize', outputs=(c_char(),))\n        self.channel = 0\n        self.set_andor_parameter('ReadMode', 4)\n        self.set_andor_parameter('AcquisitionMode', 1)\n        self.set_andor_parameter('TriggerMode', 0)\n        self.set_andor_parameter('Exposure', 1)\n        detector_shape = self.get_andor_parameter('DetectorShape')\n        self.set_andor_parameter('Image', 1, 1, 1, detector_shape[0], 1, detector_shape[1])\n        self.set_andor_parameter('Shutter', 1, 0, 0, 0)\n        self.set_andor_parameter('SetTemperature', -90)\n        self.set_andor_parameter('CoolerMode', 0)\n        self.set_andor_parameter('FanMode', 0)\n        try:\n            self.set_andor_parameter('OutAmp', 1)  # This means EMCCD off - this is the default mode\n        except AndorWarning:\n            self.set_andor_parameter('OutAmp', 0)\n        self.cooler = 1",
  "def capture(self):\n        \"\"\"Capture an image\n\n        Wraps the three steps required for a camera acquisition: StartAcquisition, WaitForAcquisition and\n        GetAcquiredData. The function also takes care of ensuring that the correct shape of array is passed to the\n        GetAcquiredData call, according to the currently set parameters of the camera.\n\n        :return:\n            np.array    2D or 3D array of the captured image(s)\n            int         number of images taken\n            tuple       shape of the images taken\n        \"\"\"\n        self._dll_wrapper('StartAcquisition')\n        self._dll_wrapper('WaitForAcquisition')\n        self.wait_for_driver()\n        if self._parameters['AcquisitionMode'] == 4:\n            num_of_images = 1  # self.parameters['FastKinetics']['value'][1]\n            image_shape = (self._parameters['FastKinetics'][-1], self._parameters['DetectorShape'][0])\n        else:\n            if self._parameters['AcquisitionMode'] == 1:\n                num_of_images = 1\n            elif self._parameters['AcquisitionMode'] == 2:\n                num_of_images = 1\n            elif self._parameters['AcquisitionMode'] == 3:\n                num_of_images = self._parameters['NKin']\n            else:\n                raise NotImplementedError('Acquisition Mode %g' % self._parameters['AcquisitionMode'])\n\n            if self._parameters['ReadMode'] == 0:\n                if self._parameters['IsolatedCropMode'][0]:\n                    image_shape = (self._parameters['IsolatedCropMode'][2] // self._parameters['IsolatedCropMode'][4], )\n                else:\n                    image_shape = (self._parameters['DetectorShape'][0] // self._parameters['FVBHBin'], )\n            elif self._parameters['ReadMode'] == 1:  # random track\n                image_shape = (self.MultiTrack[0], self._parameters['DetectorShape'][0] // self._parameters['FVBHBin'])\n            elif self._parameters['ReadMode'] == 2:\n                image_shape = ( self.RandomTracks[0], self._parameters['DetectorShape'][0]// self._parameters['FVBHBin'])\n                 \n            elif self._parameters['ReadMode'] == 3:\n                image_shape = (self._parameters['DetectorShape'][0],)\n            elif self._parameters['ReadMode'] == 4:\n                # if self._parameters['IsolatedCropMode'][0]:\n                #     image_shape = (\n                #         self._parameters['IsolatedCropMode'][1] / self._parameters['IsolatedCropMode'][3],\n                #         self._parameters['IsolatedCropMode'][2] / self._parameters['IsolatedCropMode'][4])\n                # else:\n                image_shape = (\n                    (self._parameters['Image'][5] - self._parameters['Image'][4] + 1) // self._parameters['Image'][1],\n                    (self._parameters['Image'][3] - self._parameters['Image'][2] + 1) // self._parameters['Image'][0],)\n            else:\n                raise NotImplementedError('Read Mode %g' % self._parameters['ReadMode'])\n\n        image_shape = tuple([int(x) for x in image_shape])\n        dim = num_of_images * np.prod(image_shape)\n        cimageArray = c_int * dim\n        cimage = cimageArray()\n        self._logger.debug('Getting AcquiredData for %i images with dimension %s' % (num_of_images, image_shape))\n        try:\n            self._dll_wrapper('GetAcquiredData', inputs=({'type': c_int, 'value': dim},), outputs=(cimage,),\n                              reverse=True)\n            imageArray = []\n            for i in range(len(cimage)):\n                imageArray.append(cimage[i])\n        except RuntimeWarning as e:\n            self._logger.warn('Had a RuntimeWarning: %s' % e)\n            imageArray = []\n            for i in range(len(cimage)):\n                imageArray.append(0)\n\n        return imageArray, num_of_images, image_shape",
  "def Image(self):\n        return self.get_andor_parameter('Image')",
  "def Image(self, value):\n        \"\"\"Ensures a valid image shape is passed\n\n        e.g. if binning is 2x2, and an image with an odd number of pixels along one direction is passed, this function\n        rounds it down to the nearest even number, providing a valid image shape\n\n        :param value:\n        :return:\n        \"\"\"\n        if len(value) == 4:\n            image = self._parameters['Image']\n            value = image[:2] + value\n        # Making sure we pass a valid set of parameters\n        value = list(value)\n        value[3] -= (value[3] - value[2] + 1) % value[0]\n        value[5] -= (value[5] - value[4] + 1) % value[1]\n\n        self.set_andor_parameter('Image', *value)\n\n        crop = self.IsolatedCropMode\n        if crop is not None:\n            crop = [crop[0], value[5], value[3], value[0], value[1]]\n        else:\n            crop = [0, value[5], value[3], value[0], value[1]]\n        self.set_andor_parameter('IsolatedCropMode', *crop)",
  "def set_fast_kinetics(self, n_rows=None):\n        \"\"\"Set the parameters for the Fast Kinetic mode\n\n        Uses the already set parameters of exposure time, ReadMode, and binning as defaults to be passed to the Fast\n        Kinetic parameter setter\n\n        :param n_rows: int. Number of rows to use\n        :return:\n        \"\"\"\n\n        if n_rows is None:\n            n_rows = self._parameters['FastKinetics'][0]\n\n        series_Length = int(self._parameters['DetectorShape'][1] // n_rows) - 1\n        expT = self._parameters['AcquisitionTimings'][0]\n        mode = self._parameters['ReadMode']\n        hbin = self._parameters['Image'][0]\n        vbin = self._parameters['Image'][1]\n        offset = self._parameters['DetectorShape'][1] - n_rows\n\n        self.set_andor_parameter('FastKinetics', n_rows, series_Length, expT, mode, hbin, vbin, offset)",
  "def SetRandomTracks(self, number_tracks_and_pixels):\n        number_tracks, pixels = number_tracks_and_pixels\n        assert len(pixels)/number_tracks == 2\n        self._RandomTracks = number_tracks, pixels\n        number_tracks = c_int(number_tracks)\n        arr = c_int * len(pixels)\n        c_pixels = arr(*pixels)\n        return self.dll.SetRandomTracks(number_tracks, byref(c_pixels))",
  "def GetRandomTracks(self):\n        return self._RandomTracks",
  "def status(self):\n        error = self._dll_wrapper('GetStatus', outputs=(c_int(),))\n        return ERROR_CODE[error]",
  "def wait_for_driver(self):\n        \"\"\"This function is here because the dll.WaitForAcquisition does not work when in Accumulate mode\"\"\"\n        status = c_int()\n        self.dll.GetStatus(byref(status))\n        while ERROR_CODE[status.value] == 'DRV_ACQUIRING':\n            time.sleep(0.1)\n            self.dll.GetStatus(byref(status))",
  "def cooler(self):\n        return self._dll_wrapper('IsCoolerOn', outputs=(c_int(),))",
  "def cooler(self, value):\n        if value:\n            self._dll_wrapper('CoolerON')\n        else:\n            self._dll_wrapper('CoolerOFF')",
  "def get_series_progress(self):\n        acc = c_long()\n        series = c_long()\n        error = self.dll.GetAcquisitionProgress(byref(acc), byref(series))\n        if ERROR_CODE[error] == \"DRV_SUCCESS\":\n            return series.value\n        else:\n            return None",
  "def get_accumulation_progress(self):\n        acc = c_long()\n        series = c_long()\n        error = self.dll.GetAcquisitionProgress(byref(acc), byref(series))\n        if ERROR_CODE[error] == \"DRV_SUCCESS\":\n            return acc.value\n        else:\n            return None",
  "def save_params_to_file(self, filepath=None):\n        if filepath is None:\n            data_file = df.create_file(set_current=False, mode='a')\n        else:\n            data_file = df.DataFile(filepath)\n        data_file.create_dataset(name='AndorSettings', data=[], attrs=self.get_andor_parameters())\n        data_file.close()",
  "def load_params_from_file(self, filepath=None):\n        if filepath is None:\n            data_file = df.open_file(set_current=False, mode='r')\n        else:\n            data_file = df.DataFile(filepath)\n        if 'AndorSettings' in list(data_file.keys()):\n            self.set_andor_parameters(dict(data_file['AndorSettings'].attrs))\n        else:\n            self._logger.error('Load settings failed as \"AndorSettings\" does not exist')\n        data_file.close()",
  "class Andor(CameraRoiScale, AndorBase):\n    metadata_property_names = ('Exposure', 'x_axis', 'CurrentTemperature',)\n\n    def __init__(self, settings_filepath=None, camera_index=None, **kwargs):\n        super(Andor, self).__init__()\n        self.start(camera_index)\n\n        self.CurImage = None\n        self.background = None\n        self.backgrounded = False\n        self.keep_shutter_open = False\n        if settings_filepath is not None:\n            self.load_params_from_file(settings_filepath)\n        self.isAborted = False\n\n        self.detector_shape = self.DetectorShape  # passing the Andor parameter to the CameraRoiScale class\n\n    def __del__(self):\n        # Need to explicitly call this method so that the shutdown procedure is followed correctly\n        self.end()\n\n    '''Used functions'''\n\n    def get_metadata(self,\n                     property_names=[],\n                     include_default_names=True,\n                     exclude=None\n                     ):\n        \"\"\"\n        Prevents printing a load of statements everytime the metadata is called.\n        TODO: rewrite the AndorProperties so that they are not unnecessarily verbose\n        \"\"\"\n        level = self._logger.level\n        self._logger.setLevel('WARN')\n        diction = super(Andor, self).get_metadata(property_names, include_default_names, exclude)\n        self._logger.setLevel(level)\n        return diction\n\n    metadata = property(get_metadata)\n\n    def raw_snapshot(self):\n        try:\n            if self.keep_shutter_open:\n                i = self.Shutter  # initial shutter settings\n                self.Shutter = (i[0], 1, i[2], i[3])\n            imageArray, num_of_images, image_shape = self.capture()\n            if self.keep_shutter_open:\n                self.Shutter = i\n            # The image is reversed depending on whether you read in the conventional CCD register or the EM register,\n            # so we reverse it back\n            if self._parameters['OutAmp']:\n                reshaped = np.reshape(imageArray, (num_of_images,) + image_shape)[..., ::-1]\n            else:\n                reshaped = np.reshape(imageArray, (num_of_images,) + image_shape)\n            if num_of_images == 1:\n                reshaped = reshaped[0]\n            self.CurImage = self.bundle_metadata(reshaped)\n            return True, self.CurImage\n        except Exception as e:\n            self._logger.warn(\"Couldn't Capture because %s\" % e)\n\n    def Capture(self):\n        \"\"\"takes a spectrum, and displays it\"\"\"\n        return self.raw_image(update_latest_frame=True)\n\n    def filter_function(self, frame):\n        if self.backgrounded:\n            return frame - self.background\n        else:\n            return frame\n\n    def get_camera_parameter(self, parameter_name):\n        return self.get_andor_parameter(parameter_name)\n\n    def set_camera_parameter(self, parameter_name, *parameter_value):\n        try:\n            self.set_andor_parameter(parameter_name, *parameter_value)\n        except Exception as e:\n            self.log(f'parameter {parameter_name} could not be set with the value {parameter_value} due to error {e}')             \n    @property\n    def roi(self):\n        return tuple([x - 1 for x in self.Image[2:]])\n\n    @roi.setter\n    def roi(self, value):\n        image = self._parameters['Image']\n        self.Image = image[:2] + tuple([x + 1 for x in value])\n\n    @property\n    def binning(self):\n        return self.Image[:2]\n\n    @binning.setter\n    def binning(self, value):\n        if not isinstance(value, tuple):\n            value = (value, value)\n        image = self._parameters['Image']\n        self.Image = value + image[2:]\n\n    def get_control_widget(self):\n        return AndorUI(self)",
  "class AndorUI(QtWidgets.QWidget, UiTools):\n    ImageUpdated = QtCore.Signal()\n\n    def __init__(self, andor):\n        assert isinstance(andor, Andor), \"instrument must be an Andor\"\n        super(AndorUI, self).__init__()\n        self.Andor = andor\n        self.DisplayWidget = None\n        self.temperature_display_thread = DisplayThread(self)\n        uic.loadUi((os.path.dirname(__file__) + '/andor.ui'), self)\n\n        self._setup_signals()\n        self.init_gui()\n        self.binning()\n        self.data_file = None\n        self.save_all_parameters = False\n\n        self.gui_params = ['ReadMode', 'Exposure',\n                           'AcquisitionMode', 'OutAmp', 'TriggerMode']\n        self._func_dict = {}\n        for param in self.gui_params:\n            func = self.callback_to_update_prop(param)\n            self._func_dict[param] = func\n            register_for_property_changes(self.Andor, param, self._func_dict[param])\n        if self.Andor.SingleTrack is not None:\n            c_row, n_rows = self.Andor.SingleTrack\n            self.spinBoxCenterRow.setValue(c_row)\n            self.spinBoxNumRows.setValue(n_rows)\n\n    def __del__(self):\n        self._stopTemperatureThread = True\n        if self.DisplayWidget is not None:\n            self.DisplayWidget.hide()\n            self.DisplayWidget.close()\n\n    def _setup_signals(self):\n        self.comboBoxAcqMode.activated.connect(self.acquisition_mode)\n        self.comboBoxBinning.activated.connect(self.binning)\n        self.comboBoxReadMode.activated.connect(self.read_mode)\n        self.comboBoxTrigMode.activated.connect(self.trigger)\n        self.spinBoxNumFrames.valueChanged.connect(self.number_frames)\n        self.spinBoxNumFrames.setRange(1, 1000000)\n        self.spinBoxNumAccum.valueChanged.connect(self.number_accumulations)\n        self.spinBoxNumRows.valueChanged.connect(self.number_rows)\n        self.spinBoxCenterRow.valueChanged.connect(self.number_rows)\n        self.randomtrack_pixels_lineEdit.editingFinished.connect(self.randomtrack_pixels)\n        for box in ['Tracks', 'Height', 'Offset']:\n            eval(f'self.spinBox{box}.valueChanged.connect(self.set_multitrack)')\n        self.checkBoxROI.stateChanged.connect(self.ROI)\n        self.checkBoxCrop.stateChanged.connect(self.isolated_crop)\n        self.checkBoxCooler.stateChanged.connect(self.cooler)\n        self.checkBoxEMMode.stateChanged.connect(self.output_amplifier)\n        self.spinBoxEMGain.valueChanged.connect(self.em_gain)\n        self.lineEditExpT.editingFinished.connect(self.exposure)\n        self.lineEditExpT.setValidator(QtGui.QDoubleValidator())\n        self.pushButtonDiv5.clicked.connect(lambda: self.exposure('/'))\n        self.pushButtonTimes5.clicked.connect(lambda: self.exposure('x'))\n\n        self.pushButtonCapture.clicked.connect(self.Capture)\n        self.pushButtonLive.clicked.connect(self.Live)\n        self.pushButtonAbort.clicked.connect(self.Abort)\n        self.save_pushButton.clicked.connect(self.Save)\n        self.pushButtonTakeBG.clicked.connect(self.take_background)\n        self.checkBoxRemoveBG.stateChanged.connect(self.remove_background)\n        self.referesh_groups_pushButton.clicked.connect(self.update_groups_box)\n        self.keep_shutter_open_checkBox.stateChanged.connect(self.update_shutter_mode)\n        self.read_temperature_pushButton.clicked.connect(self.temperature_gui)\n        self.live_temperature_checkBox.clicked.connect(self.temperature_gui)\n        self.temperature_display_thread.ready.connect(self.update_temperature_display)\n    \n    def set_multitrack(self):\n        self.Andor.MultiTrack = self.spinBoxTracks.value(), self.spinBoxHeight.value(), self.spinBoxOffset.value()\n    def randomtrack_pixels(self):\n        numbers = [i  for i in re.split(r',| ', self.randomtrack_pixels_lineEdit.text()) if i]\n        pixels = list(map(int, numbers))\n        assert not len(pixels) % 2, 'must be even number of inputs'\n        tracks = len(pixels)//2\n        self.Andor.RandomTracks = tracks, pixels\n\n        \n    def init_gui(self):\n        trig_modes = {0: 0, 1: 1, 6: 2}\n        self.comboBoxAcqMode.setCurrentIndex(self.Andor._parameters['AcquisitionMode'] - 1)\n        self.acquisition_mode()\n        self.comboBoxReadMode.setCurrentIndex(self.Andor._parameters['ReadMode'])\n        self.read_mode()\n        self.comboBoxTrigMode.setCurrentIndex(trig_modes[self.Andor._parameters['TriggerMode']])\n        self.trigger()\n        self.comboBoxBinning.setCurrentIndex(np.log2(self.Andor._parameters['Image'][0]))\n        self.binning()\n        self.spinBoxNumFrames.setValue(self.Andor._parameters['NKin'])\n        self.checkBoxEMMode.setChecked(not bool(self.Andor.OutAmp))\n        if len(self.Andor.capabilities['EMGainCapability']) == 0:\n            self.checkBoxEMMode.hide()\n            self.spinBoxEMGain.hide()\n\n        self.Andor.get_camera_parameter('AcquisitionTimings')\n        self.lineEditExpT.setText(\n            str(float('%#e' % self.Andor._parameters['AcquisitionTimings'][0])).rstrip('0'))\n\n    def cooler(self):\n        self.Andor.cooler = self.checkBoxCooler.isChecked()\n\n    def temperature_gui(self):\n        if self.sender() == self.read_temperature_pushButton:\n                self.temperature_display_thread.single_shot = True\n        self.temperature_display_thread.start()\n\n    def update_temperature_display(self, temperature):\n        self.temperature_lcdNumber.display(float(temperature))\n    \n    def get_temperature(self):\n        return self.Andor.CurrentTemperature\n    \n    def update_shutter_mode(self):\n        self.Andor.keep_shutter_open = self.keep_shutter_open_checkBox.isChecked()\n    \n    def acquisition_mode(self):\n        available_modes = ['Single', 'Accumulate', 'Kinetic', 'Fast Kinetic']\n        currentMode = self.comboBoxAcqMode.currentText()\n        self.Andor.set_camera_parameter('AcquisitionMode', available_modes.index(currentMode) + 1)\n\n        if currentMode == 'Single':\n            self.keep_shutter_open_checkBox.hide()\n        else:\n            self.keep_shutter_open_checkBox.show()\n            \n        if currentMode == 'Accumulate':\n            self.spinBoxNumAccum.show()\n            self.labelNumAccum.show()\n            self.doubleSpinBoxCycleTime.show()\n            self.labelCycleTime.show()\n        else:\n            self.spinBoxNumAccum.hide()\n            self.labelNumAccum.hide()  \n            self.doubleSpinBoxCycleTime.hide()\n            self.labelCycleTime.hide()\n            \n        if currentMode == 'Kinetic':\n            self.spinBoxNumFrames.show()\n            self.labelNumFrames.show()\n        else:\n            self.spinBoxNumFrames.hide()\n            self.labelNumFrames.hide()\n            \n        if currentMode == 'Fast Kinetic':\n            self.spinBoxNumRows.show()\n            self.labelNumRows.show()\n            self.spinBoxNumFrames.show()\n            self.labelNumFrames.show()\n        elif self.comboBoxReadMode.currentText() != 'Single track':\n            self.spinBoxNumRows.hide()\n            self.labelNumRows.hide()\n\n    def read_mode(self):\n        available_modes = ['Full Vert Bin', 'Multi-track', 'Random track', 'Single track', 'Image']\n        #TODO implement multi and random track - need extra parameters so removed from GUI\n        currentMode = self.comboBoxReadMode.currentText()\n        self.Andor.set_camera_parameter('ReadMode', available_modes.index(currentMode))\n        if currentMode == 'Single track':\n            self.spinBoxNumRows.show()\n            self.labelNumRows.show()\n            self.spinBoxCenterRow.show()\n            self.labelCenterRow.show()\n        else:\n            self.spinBoxCenterRow.hide()\n            self.labelCenterRow.hide()\n            if self.comboBoxAcqMode.currentText() != 'Fast Kinetic':\n                self.spinBoxNumRows.hide()\n                self.labelNumRows.hide()         \n        if currentMode == 'Multi-track':\n            for box in ['Tracks', 'Height', 'Offset']:\n                eval(f'self.label{box}.show()')\n                eval(f'self.spinBox{box}.show()')\n        else:\n            for box in ['Tracks', 'Height', 'Offset']:\n                eval(f'self.label{box}.hide()')\n                eval(f'self.spinBox{box}.hide()')\n        if currentMode == 'Random track':\n            self.randomtrack_pixels_lineEdit.show()\n        else:\n            self.randomtrack_pixels_lineEdit.hide()\n\n    def update_ReadMode(self, index):\n        self.comboBoxReadMode.setCurrentIndex(index)\n\n    def update_TriggerMode(self, value):\n        available_modes = {0: 0, 1: 1, 6: 2}\n        index = available_modes[value]\n        self.comboBoxTrigMode.setCurrentIndex(index)\n\n    def update_Exposure(self, value):\n        self.lineEditExpT.setText(str(value))\n\n    def callback_to_update_prop(self, propname):\n        \"\"\"Return a callback function that refreshes the named parameter.\"\"\"\n\n        def callback(value=None):\n            getattr(self, 'update_' + propname)(value)\n\n        return callback\n\n    def trigger(self):\n        available_modes = {'Internal': 0, 'External': 1, 'ExternalStart': 6}\n        currentMode = self.comboBoxTrigMode.currentText()\n        self.Andor.set_camera_parameter('TriggerMode', available_modes[currentMode])\n\n    def output_amplifier(self):\n        self.Andor.OutAmp = int(not self.checkBoxEMMode.isChecked())\n        self.checkBoxCrop.setChecked(False)\n\n    def binning(self):\n        current_binning = int(self.comboBoxBinning.currentText()[0])\n        self.Andor.binning = current_binning\n        self.Andor.FVBHBin = current_binning\n\n    def number_frames(self):\n        num_frames = self.spinBoxNumFrames.value()\n        self.Andor.set_camera_parameter('NKin', num_frames)\n\n    def number_accumulations(self):\n        num_frames = self.spinBoxNumAccum.value()\n        self.Andor.set_camera_parameter('NAccum', num_frames)\n\n    def number_rows(self):\n        num_rows = self.spinBoxNumRows.value()\n        if self.Andor._parameters['AcquisitionMode'] == 4:\n            self.Andor.set_fast_kinetics(num_rows)\n        elif self.Andor._parameters['ReadMode'] == 3:\n            center_row = self.spinBoxCenterRow.value()\n            if center_row - num_rows < 0:\n                self.Andor._logger.info(\n                    'Too many rows provided for Single Track mode. Using %g rows instead' % center_row)\n                num_rows = center_row\n            self.Andor.set_camera_parameter('SingleTrack', center_row, num_rows)\n        else:\n            self.Andor._logger.info('Changing the rows only works in Fast Kinetic or in Single Track mode')\n\n    def exposure(self, input=None):\n        if input is None:\n            expT = float(self.lineEditExpT.text())\n        elif input == 'x':\n            expT = float(self.lineEditExpT.text()) * 5\n        elif input == '/':\n            expT = float(self.lineEditExpT.text()) / 5\n        self.Andor.Exposure = expT\n\n    def em_gain(self):\n        gain = self.spinBoxEMGain.value()\n        self.Andor.set_camera_parameter('EMGain', gain)\n\n    def isolated_crop(self):\n        current_binning = self.Andor.binning\n        gui_roi = self.Andor.gui_roi\n        maxy = gui_roi[3]\n        if self.checkBoxEMMode.isChecked():\n            maxx = gui_roi[1]\n        else:\n            shape = self.Andor.DetectorShape\n            maxx = shape[0] - gui_roi[1]\n\n        if self.checkBoxCrop.isChecked():\n            self.checkBoxROI.setEnabled(False)\n            self.Andor.IsolatedCropMode = (1, maxy, maxx, current_binning[0], current_binning[1])\n            self.Andor.Image = (current_binning[0], current_binning[1], 1, maxx, 1, maxy)\n        else:\n            self.checkBoxROI.setEnabled(True)\n            self.Andor.IsolatedCropMode = (0, maxy, maxx, current_binning[0], current_binning[1])\n            shape = self.Andor.DetectorShape\n            self.Andor.Image = (current_binning[0], current_binning[1], 1, shape[0], 1, shape[1])\n\n    def take_background(self):\n        self.Andor.background = self.Andor.raw_snapshot()[1]\n        self.Andor.backgrounded = True\n        self.checkBoxRemoveBG.setChecked(True)\n\n    def remove_background(self):\n        if self.checkBoxRemoveBG.isChecked():\n            self.Andor.backgrounded = True\n        else:\n            self.Andor.backgrounded = False\n\n    def Save(self):\n        if self.data_file is None:\n            self.data_file = df.current()\n        data = self.Andor.CurImage\n        if self.filename_lineEdit.text() != 'Filename....':\n            filename = self.filename_lineEdit.text()\n        else:\n            filename = 'Andor_data'\n        if self.group_comboBox.currentText() == 'AndorData':\n            if df._use_current_group == True and df._current_group is not None:\n                group = df._current_group\n            elif 'AndorData' in list(self.data_file.keys()):\n                group = self.data_file['AndorData']\n            else:\n                group = self.data_file.create_group('AndorData')\n        else:\n            group = self.data_file[self.group_comboBox.currentText()]\n        if np.shape(data)[0] == 1:\n            data = data[0]\n        if self.save_all_parameters:\n            attrs = self.Andor.get_andor_parameters()\n        else:\n            attrs = dict()\n        attrs['Description'] = self.description_plainTextEdit.toPlainText()\n        if hasattr(self.Andor, 'x_axis'):\n            attrs['wavelengths'] = self.Andor.x_axis\n        try:\n            data_set = group.create_dataset(name=filename, data=data)\n        except Exception as e:\n            self.Andor._logger.info(e)\n        df.attributes_from_dict(data_set, attrs)\n        if self.Andor.backgrounded == False and 'background' in list(data_set.attrs.keys()):\n            del data_set.attrs['background']\n\n    def update_groups_box(self):\n        if self.data_file is None:\n            self.data_file = df.current()\n        self.group_comboBox.clear()\n        if 'AndorData' not in list(self.data_file.values()):\n            self.group_comboBox.addItem('AndorData')\n        for group in list(self.data_file.values()):\n            if type(group) == df.Group:\n                self.group_comboBox.addItem(group.name[1:], group)\n\n    def ROI(self):\n        if self.checkBoxROI.isChecked():\n            self.checkBoxCrop.setEnabled(False)\n            self.Andor.roi = self.Andor.gui_roi  # binning + params\n        else:\n            self.checkBoxCrop.setEnabled(True)\n            self.Andor.roi = (0, self.Andor._parameters['DetectorShape'][0]-1,\n                              0, self.Andor._parameters['DetectorShape'][1]-1)\n\n    def Capture(self):\n        self.Andor.raw_image(update_latest_frame=True)\n\n    def Live(self):\n        self.Andor.live_view = True\n\n    def Abort(self):\n        self.Andor.live_view = False",
  "class DisplayThread(QtCore.QThread):\n    \"\"\"for displaying the temperature\"\"\"\n    ready = QtCore.Signal(float)\n\n    def __init__(self, parent):\n        super(DisplayThread, self).__init__()\n        self.parent = parent\n        self.single_shot = False\n        self.refresh_rate = 1.  # every second\n\n    def run(self):\n        t0 = time.time()\n        while self.parent.live_temperature_checkBox.isChecked() or self.single_shot:\n            T = self.parent.get_temperature()\n            if time.time()-t0 < 1./self.refresh_rate:\n                continue\n            else:\n                t0 = time.time()\n            self.ready.emit(T)\n            if self.single_shot:\n                self.single_shot = False               \n                break\n        self.finished.emit()",
  "def __init__(self, settings_filepath=None, camera_index=None, **kwargs):\n        super(Andor, self).__init__()\n        self.start(camera_index)\n\n        self.CurImage = None\n        self.background = None\n        self.backgrounded = False\n        self.keep_shutter_open = False\n        if settings_filepath is not None:\n            self.load_params_from_file(settings_filepath)\n        self.isAborted = False\n\n        self.detector_shape = self.DetectorShape",
  "def __del__(self):\n        # Need to explicitly call this method so that the shutdown procedure is followed correctly\n        self.end()",
  "def get_metadata(self,\n                     property_names=[],\n                     include_default_names=True,\n                     exclude=None\n                     ):\n        \"\"\"\n        Prevents printing a load of statements everytime the metadata is called.\n        TODO: rewrite the AndorProperties so that they are not unnecessarily verbose\n        \"\"\"\n        level = self._logger.level\n        self._logger.setLevel('WARN')\n        diction = super(Andor, self).get_metadata(property_names, include_default_names, exclude)\n        self._logger.setLevel(level)\n        return diction",
  "def raw_snapshot(self):\n        try:\n            if self.keep_shutter_open:\n                i = self.Shutter  # initial shutter settings\n                self.Shutter = (i[0], 1, i[2], i[3])\n            imageArray, num_of_images, image_shape = self.capture()\n            if self.keep_shutter_open:\n                self.Shutter = i\n            # The image is reversed depending on whether you read in the conventional CCD register or the EM register,\n            # so we reverse it back\n            if self._parameters['OutAmp']:\n                reshaped = np.reshape(imageArray, (num_of_images,) + image_shape)[..., ::-1]\n            else:\n                reshaped = np.reshape(imageArray, (num_of_images,) + image_shape)\n            if num_of_images == 1:\n                reshaped = reshaped[0]\n            self.CurImage = self.bundle_metadata(reshaped)\n            return True, self.CurImage\n        except Exception as e:\n            self._logger.warn(\"Couldn't Capture because %s\" % e)",
  "def Capture(self):\n        \"\"\"takes a spectrum, and displays it\"\"\"\n        return self.raw_image(update_latest_frame=True)",
  "def filter_function(self, frame):\n        if self.backgrounded:\n            return frame - self.background\n        else:\n            return frame",
  "def get_camera_parameter(self, parameter_name):\n        return self.get_andor_parameter(parameter_name)",
  "def set_camera_parameter(self, parameter_name, *parameter_value):\n        try:\n            self.set_andor_parameter(parameter_name, *parameter_value)\n        except Exception as e:\n            self.log(f'parameter {parameter_name} could not be set with the value {parameter_value} due to error {e}')",
  "def roi(self):\n        return tuple([x - 1 for x in self.Image[2:]])",
  "def roi(self, value):\n        image = self._parameters['Image']\n        self.Image = image[:2] + tuple([x + 1 for x in value])",
  "def binning(self):\n        return self.Image[:2]",
  "def binning(self, value):\n        if not isinstance(value, tuple):\n            value = (value, value)\n        image = self._parameters['Image']\n        self.Image = value + image[2:]",
  "def get_control_widget(self):\n        return AndorUI(self)",
  "def __init__(self, andor):\n        assert isinstance(andor, Andor), \"instrument must be an Andor\"\n        super(AndorUI, self).__init__()\n        self.Andor = andor\n        self.DisplayWidget = None\n        self.temperature_display_thread = DisplayThread(self)\n        uic.loadUi((os.path.dirname(__file__) + '/andor.ui'), self)\n\n        self._setup_signals()\n        self.init_gui()\n        self.binning()\n        self.data_file = None\n        self.save_all_parameters = False\n\n        self.gui_params = ['ReadMode', 'Exposure',\n                           'AcquisitionMode', 'OutAmp', 'TriggerMode']\n        self._func_dict = {}\n        for param in self.gui_params:\n            func = self.callback_to_update_prop(param)\n            self._func_dict[param] = func\n            register_for_property_changes(self.Andor, param, self._func_dict[param])\n        if self.Andor.SingleTrack is not None:\n            c_row, n_rows = self.Andor.SingleTrack\n            self.spinBoxCenterRow.setValue(c_row)\n            self.spinBoxNumRows.setValue(n_rows)",
  "def __del__(self):\n        self._stopTemperatureThread = True\n        if self.DisplayWidget is not None:\n            self.DisplayWidget.hide()\n            self.DisplayWidget.close()",
  "def _setup_signals(self):\n        self.comboBoxAcqMode.activated.connect(self.acquisition_mode)\n        self.comboBoxBinning.activated.connect(self.binning)\n        self.comboBoxReadMode.activated.connect(self.read_mode)\n        self.comboBoxTrigMode.activated.connect(self.trigger)\n        self.spinBoxNumFrames.valueChanged.connect(self.number_frames)\n        self.spinBoxNumFrames.setRange(1, 1000000)\n        self.spinBoxNumAccum.valueChanged.connect(self.number_accumulations)\n        self.spinBoxNumRows.valueChanged.connect(self.number_rows)\n        self.spinBoxCenterRow.valueChanged.connect(self.number_rows)\n        self.randomtrack_pixels_lineEdit.editingFinished.connect(self.randomtrack_pixels)\n        for box in ['Tracks', 'Height', 'Offset']:\n            eval(f'self.spinBox{box}.valueChanged.connect(self.set_multitrack)')\n        self.checkBoxROI.stateChanged.connect(self.ROI)\n        self.checkBoxCrop.stateChanged.connect(self.isolated_crop)\n        self.checkBoxCooler.stateChanged.connect(self.cooler)\n        self.checkBoxEMMode.stateChanged.connect(self.output_amplifier)\n        self.spinBoxEMGain.valueChanged.connect(self.em_gain)\n        self.lineEditExpT.editingFinished.connect(self.exposure)\n        self.lineEditExpT.setValidator(QtGui.QDoubleValidator())\n        self.pushButtonDiv5.clicked.connect(lambda: self.exposure('/'))\n        self.pushButtonTimes5.clicked.connect(lambda: self.exposure('x'))\n\n        self.pushButtonCapture.clicked.connect(self.Capture)\n        self.pushButtonLive.clicked.connect(self.Live)\n        self.pushButtonAbort.clicked.connect(self.Abort)\n        self.save_pushButton.clicked.connect(self.Save)\n        self.pushButtonTakeBG.clicked.connect(self.take_background)\n        self.checkBoxRemoveBG.stateChanged.connect(self.remove_background)\n        self.referesh_groups_pushButton.clicked.connect(self.update_groups_box)\n        self.keep_shutter_open_checkBox.stateChanged.connect(self.update_shutter_mode)\n        self.read_temperature_pushButton.clicked.connect(self.temperature_gui)\n        self.live_temperature_checkBox.clicked.connect(self.temperature_gui)\n        self.temperature_display_thread.ready.connect(self.update_temperature_display)",
  "def set_multitrack(self):\n        self.Andor.MultiTrack = self.spinBoxTracks.value(), self.spinBoxHeight.value(), self.spinBoxOffset.value()",
  "def randomtrack_pixels(self):\n        numbers = [i  for i in re.split(r',| ', self.randomtrack_pixels_lineEdit.text()) if i]\n        pixels = list(map(int, numbers))\n        assert not len(pixels) % 2, 'must be even number of inputs'\n        tracks = len(pixels)//2\n        self.Andor.RandomTracks = tracks, pixels",
  "def init_gui(self):\n        trig_modes = {0: 0, 1: 1, 6: 2}\n        self.comboBoxAcqMode.setCurrentIndex(self.Andor._parameters['AcquisitionMode'] - 1)\n        self.acquisition_mode()\n        self.comboBoxReadMode.setCurrentIndex(self.Andor._parameters['ReadMode'])\n        self.read_mode()\n        self.comboBoxTrigMode.setCurrentIndex(trig_modes[self.Andor._parameters['TriggerMode']])\n        self.trigger()\n        self.comboBoxBinning.setCurrentIndex(np.log2(self.Andor._parameters['Image'][0]))\n        self.binning()\n        self.spinBoxNumFrames.setValue(self.Andor._parameters['NKin'])\n        self.checkBoxEMMode.setChecked(not bool(self.Andor.OutAmp))\n        if len(self.Andor.capabilities['EMGainCapability']) == 0:\n            self.checkBoxEMMode.hide()\n            self.spinBoxEMGain.hide()\n\n        self.Andor.get_camera_parameter('AcquisitionTimings')\n        self.lineEditExpT.setText(\n            str(float('%#e' % self.Andor._parameters['AcquisitionTimings'][0])).rstrip('0'))",
  "def cooler(self):\n        self.Andor.cooler = self.checkBoxCooler.isChecked()",
  "def temperature_gui(self):\n        if self.sender() == self.read_temperature_pushButton:\n                self.temperature_display_thread.single_shot = True\n        self.temperature_display_thread.start()",
  "def update_temperature_display(self, temperature):\n        self.temperature_lcdNumber.display(float(temperature))",
  "def get_temperature(self):\n        return self.Andor.CurrentTemperature",
  "def update_shutter_mode(self):\n        self.Andor.keep_shutter_open = self.keep_shutter_open_checkBox.isChecked()",
  "def acquisition_mode(self):\n        available_modes = ['Single', 'Accumulate', 'Kinetic', 'Fast Kinetic']\n        currentMode = self.comboBoxAcqMode.currentText()\n        self.Andor.set_camera_parameter('AcquisitionMode', available_modes.index(currentMode) + 1)\n\n        if currentMode == 'Single':\n            self.keep_shutter_open_checkBox.hide()\n        else:\n            self.keep_shutter_open_checkBox.show()\n            \n        if currentMode == 'Accumulate':\n            self.spinBoxNumAccum.show()\n            self.labelNumAccum.show()\n            self.doubleSpinBoxCycleTime.show()\n            self.labelCycleTime.show()\n        else:\n            self.spinBoxNumAccum.hide()\n            self.labelNumAccum.hide()  \n            self.doubleSpinBoxCycleTime.hide()\n            self.labelCycleTime.hide()\n            \n        if currentMode == 'Kinetic':\n            self.spinBoxNumFrames.show()\n            self.labelNumFrames.show()\n        else:\n            self.spinBoxNumFrames.hide()\n            self.labelNumFrames.hide()\n            \n        if currentMode == 'Fast Kinetic':\n            self.spinBoxNumRows.show()\n            self.labelNumRows.show()\n            self.spinBoxNumFrames.show()\n            self.labelNumFrames.show()\n        elif self.comboBoxReadMode.currentText() != 'Single track':\n            self.spinBoxNumRows.hide()\n            self.labelNumRows.hide()",
  "def read_mode(self):\n        available_modes = ['Full Vert Bin', 'Multi-track', 'Random track', 'Single track', 'Image']\n        #TODO implement multi and random track - need extra parameters so removed from GUI\n        currentMode = self.comboBoxReadMode.currentText()\n        self.Andor.set_camera_parameter('ReadMode', available_modes.index(currentMode))\n        if currentMode == 'Single track':\n            self.spinBoxNumRows.show()\n            self.labelNumRows.show()\n            self.spinBoxCenterRow.show()\n            self.labelCenterRow.show()\n        else:\n            self.spinBoxCenterRow.hide()\n            self.labelCenterRow.hide()\n            if self.comboBoxAcqMode.currentText() != 'Fast Kinetic':\n                self.spinBoxNumRows.hide()\n                self.labelNumRows.hide()         \n        if currentMode == 'Multi-track':\n            for box in ['Tracks', 'Height', 'Offset']:\n                eval(f'self.label{box}.show()')\n                eval(f'self.spinBox{box}.show()')\n        else:\n            for box in ['Tracks', 'Height', 'Offset']:\n                eval(f'self.label{box}.hide()')\n                eval(f'self.spinBox{box}.hide()')\n        if currentMode == 'Random track':\n            self.randomtrack_pixels_lineEdit.show()\n        else:\n            self.randomtrack_pixels_lineEdit.hide()",
  "def update_ReadMode(self, index):\n        self.comboBoxReadMode.setCurrentIndex(index)",
  "def update_TriggerMode(self, value):\n        available_modes = {0: 0, 1: 1, 6: 2}\n        index = available_modes[value]\n        self.comboBoxTrigMode.setCurrentIndex(index)",
  "def update_Exposure(self, value):\n        self.lineEditExpT.setText(str(value))",
  "def callback_to_update_prop(self, propname):\n        \"\"\"Return a callback function that refreshes the named parameter.\"\"\"\n\n        def callback(value=None):\n            getattr(self, 'update_' + propname)(value)\n\n        return callback",
  "def trigger(self):\n        available_modes = {'Internal': 0, 'External': 1, 'ExternalStart': 6}\n        currentMode = self.comboBoxTrigMode.currentText()\n        self.Andor.set_camera_parameter('TriggerMode', available_modes[currentMode])",
  "def output_amplifier(self):\n        self.Andor.OutAmp = int(not self.checkBoxEMMode.isChecked())\n        self.checkBoxCrop.setChecked(False)",
  "def binning(self):\n        current_binning = int(self.comboBoxBinning.currentText()[0])\n        self.Andor.binning = current_binning\n        self.Andor.FVBHBin = current_binning",
  "def number_frames(self):\n        num_frames = self.spinBoxNumFrames.value()\n        self.Andor.set_camera_parameter('NKin', num_frames)",
  "def number_accumulations(self):\n        num_frames = self.spinBoxNumAccum.value()\n        self.Andor.set_camera_parameter('NAccum', num_frames)",
  "def number_rows(self):\n        num_rows = self.spinBoxNumRows.value()\n        if self.Andor._parameters['AcquisitionMode'] == 4:\n            self.Andor.set_fast_kinetics(num_rows)\n        elif self.Andor._parameters['ReadMode'] == 3:\n            center_row = self.spinBoxCenterRow.value()\n            if center_row - num_rows < 0:\n                self.Andor._logger.info(\n                    'Too many rows provided for Single Track mode. Using %g rows instead' % center_row)\n                num_rows = center_row\n            self.Andor.set_camera_parameter('SingleTrack', center_row, num_rows)\n        else:\n            self.Andor._logger.info('Changing the rows only works in Fast Kinetic or in Single Track mode')",
  "def exposure(self, input=None):\n        if input is None:\n            expT = float(self.lineEditExpT.text())\n        elif input == 'x':\n            expT = float(self.lineEditExpT.text()) * 5\n        elif input == '/':\n            expT = float(self.lineEditExpT.text()) / 5\n        self.Andor.Exposure = expT",
  "def em_gain(self):\n        gain = self.spinBoxEMGain.value()\n        self.Andor.set_camera_parameter('EMGain', gain)",
  "def isolated_crop(self):\n        current_binning = self.Andor.binning\n        gui_roi = self.Andor.gui_roi\n        maxy = gui_roi[3]\n        if self.checkBoxEMMode.isChecked():\n            maxx = gui_roi[1]\n        else:\n            shape = self.Andor.DetectorShape\n            maxx = shape[0] - gui_roi[1]\n\n        if self.checkBoxCrop.isChecked():\n            self.checkBoxROI.setEnabled(False)\n            self.Andor.IsolatedCropMode = (1, maxy, maxx, current_binning[0], current_binning[1])\n            self.Andor.Image = (current_binning[0], current_binning[1], 1, maxx, 1, maxy)\n        else:\n            self.checkBoxROI.setEnabled(True)\n            self.Andor.IsolatedCropMode = (0, maxy, maxx, current_binning[0], current_binning[1])\n            shape = self.Andor.DetectorShape\n            self.Andor.Image = (current_binning[0], current_binning[1], 1, shape[0], 1, shape[1])",
  "def take_background(self):\n        self.Andor.background = self.Andor.raw_snapshot()[1]\n        self.Andor.backgrounded = True\n        self.checkBoxRemoveBG.setChecked(True)",
  "def remove_background(self):\n        if self.checkBoxRemoveBG.isChecked():\n            self.Andor.backgrounded = True\n        else:\n            self.Andor.backgrounded = False",
  "def Save(self):\n        if self.data_file is None:\n            self.data_file = df.current()\n        data = self.Andor.CurImage\n        if self.filename_lineEdit.text() != 'Filename....':\n            filename = self.filename_lineEdit.text()\n        else:\n            filename = 'Andor_data'\n        if self.group_comboBox.currentText() == 'AndorData':\n            if df._use_current_group == True and df._current_group is not None:\n                group = df._current_group\n            elif 'AndorData' in list(self.data_file.keys()):\n                group = self.data_file['AndorData']\n            else:\n                group = self.data_file.create_group('AndorData')\n        else:\n            group = self.data_file[self.group_comboBox.currentText()]\n        if np.shape(data)[0] == 1:\n            data = data[0]\n        if self.save_all_parameters:\n            attrs = self.Andor.get_andor_parameters()\n        else:\n            attrs = dict()\n        attrs['Description'] = self.description_plainTextEdit.toPlainText()\n        if hasattr(self.Andor, 'x_axis'):\n            attrs['wavelengths'] = self.Andor.x_axis\n        try:\n            data_set = group.create_dataset(name=filename, data=data)\n        except Exception as e:\n            self.Andor._logger.info(e)\n        df.attributes_from_dict(data_set, attrs)\n        if self.Andor.backgrounded == False and 'background' in list(data_set.attrs.keys()):\n            del data_set.attrs['background']",
  "def update_groups_box(self):\n        if self.data_file is None:\n            self.data_file = df.current()\n        self.group_comboBox.clear()\n        if 'AndorData' not in list(self.data_file.values()):\n            self.group_comboBox.addItem('AndorData')\n        for group in list(self.data_file.values()):\n            if type(group) == df.Group:\n                self.group_comboBox.addItem(group.name[1:], group)",
  "def ROI(self):\n        if self.checkBoxROI.isChecked():\n            self.checkBoxCrop.setEnabled(False)\n            self.Andor.roi = self.Andor.gui_roi  # binning + params\n        else:\n            self.checkBoxCrop.setEnabled(True)\n            self.Andor.roi = (0, self.Andor._parameters['DetectorShape'][0]-1,\n                              0, self.Andor._parameters['DetectorShape'][1]-1)",
  "def Capture(self):\n        self.Andor.raw_image(update_latest_frame=True)",
  "def Live(self):\n        self.Andor.live_view = True",
  "def Abort(self):\n        self.Andor.live_view = False",
  "def __init__(self, parent):\n        super(DisplayThread, self).__init__()\n        self.parent = parent\n        self.single_shot = False\n        self.refresh_rate = 1.",
  "def run(self):\n        t0 = time.time()\n        while self.parent.live_temperature_checkBox.isChecked() or self.single_shot:\n            T = self.parent.get_temperature()\n            if time.time()-t0 < 1./self.refresh_rate:\n                continue\n            else:\n                t0 = time.time()\n            self.ready.emit(T)\n            if self.single_shot:\n                self.single_shot = False               \n                break\n        self.finished.emit()",
  "def callback(value=None):\n            getattr(self, 'update_' + propname)(value)",
  "class StreakError(Exception):\n    def __init__(self, code, msg, reply):\n        if isinstance(code, str):\n            code = int(code)\n        super(StreakError, self).__init__()\n        self.msg = msg\n        self.reply = reply\n        self.error_code = code\n        self.error_name = ERROR_CODES[code]\n\n    def __str__(self):\n        return '%s Sent: %s Reply: %s' % (self.error_name, self.msg, self.reply)",
  "class StreakSdk(VisaInstrument):\n    \"\"\"\n    Implements the RemoteExProgrammersHandbook91\n\n    Not Implemented Functions:\n        'MainParamInfo', 'MainParamInfoEx', 'GenParamInfo', 'GenParamInfoEx', 'AcqLiveMonitor', 'AcqLiveMonitorTSInfo',\n        'acqLiveMonitorTSFormat', 'CamSetupSendSerial', 'ImgStatusSet', 'ImgRingBufferGet', 'ImgAnalyze', 'ImgRoiGet',\n        'ImgRoiSet', 'ImgRoiSelectedRoiGet', 'ImgRoiSelectedRoiSet', 'SeqCopyToSeparateImg', 'SeqImgIndexGet', '\n        All of the auxiliary devices, processing, defect pixel tools\n    \"\"\"\n\n    def __init__(self, address, start_app=False, get_all_parameters=False, **kwargs):\n        \"\"\"\n\n        :param address: tuple of the streak TCP address (TCP_IP,TCP_PORT)\n        :param kwargs: optional dictionary keys, also passed to nplab.Instrument\n            CloseAppWhenDone:  closes the streak GUI when you delete the Python class instance\n            get_all_parameters:  gets the values of all the parameters on startup\n        \"\"\"\n        visa_address = 'TCPIP::%s::%d::SOCKET' % address\n        settings = dict(read_termination='\\r', write_termination='\\r', timeout=TIMEOUT, query_delay=SLEEPING_TIME)\n        super(StreakSdk, self).__init__(visa_address, settings)\n\n        message = self.read()  # reads the default message that gets sent from RemoteEx\n        if message != 'RemoteEx Ready':\n            self._logger.warn('Not ready: %s' % message)\n\n        self.data_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        self.data_socket.connect((address[0], address[1] + 1))\n        self.data_socket.settimeout(10)\n        message = self.data_socket.recv(100).decode().rstrip()\n        if message != 'RemoteEx Data Ready':\n            self._logger.warn('Data socket not ready: %s' % message)\n        self.clear_read_buffer()\n\n        self.close_app_when_done = False\n        if \"CloseAppWhenDone\" in kwargs:\n            self.close_app_when_done = kwargs['CloseAppWhenDone']\n\n        # Starting the HPDTA GUI\n        if start_app:\n            self.start_app()\n\n        self._setup_parameter_dictionaries()\n\n        # Getting all the parameters\n        if get_all_parameters:\n            self.get_parameter()\n\n    def __del__(self):\n        if self.close_app_when_done:\n            self.send_command('AppEnd')\n        super(StreakSdk, self).__del__()\n\n    def reopen_connection(self):\n        \"\"\"For some reason, sometimes the remote app crashes, and it's useful to restart the connection without\n        restarting the local python app\n\n        :return:\n        \"\"\"\n        if hasattr(self, 'instr'):\n            del self.instr\n        if hasattr(self, 'data_socket'):\n            self.data_socket.close()\n            del self.data_socket\n\n        settings = dict(read_termination='\\r', write_termination='\\r', timeout=TIMEOUT, query_delay=SLEEPING_TIME)\n\n        rm = visa.ResourceManager()\n        self.instr = rm.open_resource(self._address, **settings)\n\n        message = self.read()  # reads the default message that gets sent from RemoteEx\n        if message != 'RemoteEx Ready':\n            self._logger.warn('Not ready: %s' % message)\n\n        address = self._address.split('::')[1:3]\n        self.data_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        self.data_socket.connect((address[0], int(address[1]) + 1))\n        self.data_socket.settimeout(10)\n        message = self.data_socket.recv(100).decode().rstrip()\n        if message != 'RemoteEx Data Ready':\n            self._logger.warn('Data socket not ready: %s' % message)\n        self.clear_read_buffer()\n\n    def query(self, msg, *args, **kwargs):\n        \"\"\"Light wrapper to add logging and handshaking\n\n        :param msg:\n        :param args:\n        :param kwargs:\n        :return:\n        \"\"\"\n        self._logger.debug(\"write: %s\" % msg)\n        full_reply = super(StreakSdk, self).query(msg, *args, **kwargs)\n        self._logger.debug(\"read: %s\" % full_reply)\n        reply = self._handshake(msg, full_reply, *args, **kwargs)\n        return reply\n\n    def _handshake(self, message, full_reply, *args, **kwargs):\n        \"\"\"Checks command was executed without errors\n\n        Most times a command is sent to the streak, it replies with a message containing an error code (see ERROR_CODES)\n        and the command name. This method returns the error message if there's been an error, or tries to handshake\n        again if there was no handshake message.\n\n        :return:\n        \"\"\"\n        try:\n            split_reply = full_reply.split(',', 2)\n\n            # Some commands have a response (len = 3), others simply have a handshake (len = 2)\n            if len(split_reply) == 2:\n                split_reply += ('', )\n            error_code, command, reply = split_reply\n\n            if error_code in ['4', '5']:\n                # Some messages in the buffer simply state the streak status\n                self._logger.debug('Useless reply:\\t%s\\t%s\\t%s' % (error_code, command, reply))\n                # They are generally not useful, so we handshake again\n                full_reply = self.read(*args, **kwargs)\n                return self._handshake(message, full_reply, *args, **kwargs)\n            elif message.split('(')[0] != command:\n                self._logger.error('Comparing this: %s \\t to this: %s' % (message.split('(')[0], command))\n                raise RuntimeError('Replied command does not match')\n            elif error_code == '0':\n                self._logger.debug('Handshake worked\\t%s\\t%s' % (command, reply))\n                return reply\n            else:\n                raise StreakError(error_code, message, full_reply)\n        except Exception as e:\n            self._logger.warn('Handshake failed: %s' % e)\n\n    def send_command(self, operation, *parameters, **kwargs):\n        \"\"\"Simply parses a command and parameters into the expected TCPIP string command structure:\n            operation(parameter1, parameter2, parameter3...)\n\n        :param operation: str\n        :param parameters: list of parameters to be passed to operation\n        :return:\n        \"\"\"\n\n        self._logger.debug(\"send_command: %s, %s, %s\" % (operation, parameters, kwargs))\n        msg = '%s(%s)' % (operation, ','.join(map(str, parameters)))\n        return self.query(msg, **kwargs)\n\n    def _setup_parameter_dictionaries(self):\n        \"\"\"Setting up a dictionary (self.parameters) that contains all the information for calling parameters, as well\n        as their values (once called)\n\n        Streak parameters are hierarchical (e.g. there are 7 parameters related to the Application). Some have one level\n        (like Application) but others have two levels (e.g. Camera has Binning inside Setup, but Exposure inside one of\n        Live/Acquire/AI/PC).\n\n        TODO: make parameters into CameraParameters that can then be bundled into metadata\n            Problem: some parameters do not have names amenable to being attributes (with spaces, stops, slashes)\n        TODO: handle unavailable parameters and devices\n\n        :return:\n        \"\"\"\n        self.parameters = dict()\n\n        # APPLICATION\n        app_params = ['Date', 'Version', 'Directory', 'Title', 'Titlelong', 'ProgDataDir', 'type']\n        self.parameters['Application'] = {'get': 'AppInfo',\n                                          'set': None,\n                                          'info': None,\n                                          'value': {key: None for key in app_params}}\n\n        # MAIN\n        main_params = ['ImageSize', 'Message', 'Temperature', 'GateMode', 'MCPGain', 'Mode', 'Plugin', 'Shutter',\n                       'StreakCamera', 'TimeRange']\n        self.parameters['Main'] = {'get': 'MainParamGet',\n                                   'set': None,\n                                   'info': 'MainParamInfo',\n                                   'value': {key: None for key in main_params}}\n\n        # GENERAL\n        gen_params = ['RestoreWindowPos', 'UserFunctions', 'ShowStreakControl', 'ShowDelay1Control',\n                      'ShowDelay2Control', 'ShowSpectrControl']\n        self.parameters['General'] = {'get': 'GenParamGet',\n                                      'set': 'GenParamSet',\n                                      'info': 'GenParamInfo',\n                                      'value': {key: None for key in gen_params}}\n\n        # ACQUISITION\n        acquisition_params = ['DisplayInterval', '32BitInAI', 'WriteDPCFile', 'AdditionalTimeout',\n                              'DeactivateGrbNotInUse', 'CCDGainForPC', '32BitInPC', 'MoireeReduction']\n        self.parameters['Acquisition'] = {'get': 'AcqParamGet',\n                                          'set': 'AcqParamSet',\n                                          'info': 'AcqParamInfoEx',\n                                          'value': {key: None for key in acquisition_params}}\n\n        # CAMERA\n        setup_param = ['TimingMode', 'TriggerMode', 'TriggerSource', 'TriggerPolarity', 'ScanMode', 'Binning',\n                       'CCDArea', 'LightMode', 'Hoffs', 'HWidth', 'VOffs', 'VWidth', 'ShowGainOffset', 'NoLines',\n                       'LinesPerImage', 'ScrollingLiveDisplay', 'FrameTrigger', 'VerticalBinning', 'TapNo',\n                       'ShutterAction', 'Cooler', 'TargetTemperature', 'ContrastEnhancement', 'Offset', 'Gain',\n                       'XDirection', 'ScanSpeed', 'MechanicalShutter', 'Subtype', 'AutoDetect', 'Wait2ndFrame', 'DX',\n                       'DY', 'XOffset', 'YOffset', 'BPP', 'CameraName', 'ExposureTime', 'ReadoutTime', 'OnChipAmp',\n                       'CoolingFan', 'Cooler', 'ExtOutputPolarity', 'ExtOutputDelay', 'ExtOutputWidth',\n                       'LowLightSensitivity', 'AutomaticBundleHeight', 'CameraInfo']\n        # Two parameters called Offset and Width were not included (name shadowing, must be a bug in the program or a\n        # typo in the manual). Additionally, all the sensor specific parameters were not included\n        tab_param = ['Exposure', 'Gain', 'Offset', 'NrTrigger', 'Threshold', 'Threshold2', 'DoRTBackSub',\n                     'DoRTShading', 'NrExposures', 'ClearFrameBuffer', 'AmpGain', 'SMD', 'RecurNumber', 'HVoltage',\n                     'AMD', 'ASH', 'ATP', 'SOP', 'SPX', 'MCP', 'TDY', 'IntegrAfterTrig', 'SensitivityValue', 'EMG',\n                     'BGSub', 'RecurFilter', 'HightVoltage', 'StreakTrigger', 'FGTrigger', 'SensitivitySwitch',\n                     'BGOffset', 'ATN', 'SMDExtended', 'LightMode', 'ScanSpeed', 'BGDataMemory', 'SHDataMemory',\n                     'SensitivityMode', 'Sensitivity', 'Sensitivity2Mode', 'Sensitivity2', 'ContrastControl',\n                     'ContrastGain', 'ContrastOffset', 'PhotonImagingMode', 'HighDynamicRangeMode', 'RecurNumber2',\n                     'RecurFilter2', 'FrameAvgNumber', 'FrameAvg']\n        cam_params = dict(Setup={key: None for key in setup_param},\n                          Live={key: None for key in tab_param},\n                          Acquire={key: None for key in tab_param},\n                          AI={key: None for key in tab_param},\n                          PC={key: None for key in tab_param})\n        self.parameters['Camera'] = {'get': 'CamParamGet',\n                                     'set': 'CamParamSet',\n                                     'info': 'CamParamInfoEx',\n                                     'value': cam_params}\n\n        # CORRECTIONS\n        bkg_param = ['BackgroundSource', 'BackFilesForAcqModes', 'GeneralFile', 'LiveFile', 'AcquireFile', 'AIFile',\n                     'Constant', 'ClipZero', 'AutoBacksub']\n        curv_param = ['CorrectionFile', 'AutoCurvature']\n        defect_pixel_param = ['DefectCorrection', 'DefectPixelFile']\n        shading_param = ['ShadingFile', 'ShadingConstant', 'AutoShading', 'SensitivityCorrection', 'LampFile']\n        correction_params = dict(Background={key: None for key in bkg_param},\n                                 Shading={key: None for key in curv_param},\n                                 Curvature={key: None for key in defect_pixel_param},\n                                 DefectPixel={key: None for key in shading_param})\n        self.parameters['Corrections'] = {'get': 'CorParamGet',\n                                          'set': 'CorParamSet',\n                                          'info': 'CorParamInfoEx',\n                                          'value': correction_params}\n\n        # IMAGES\n        img_params = ['AcquireToSameWindow', 'DefaultZoomFactor', 'WarnWhenUnsaved', 'Calibrated', 'LowerLUTIsZero',\n                      'AutoLUT', 'AutoLUTInLive', 'AutoLUTInROI', 'HorizontalRuler', 'VerticalRuler', 'FixedITEXHeader']\n        self.parameters['Images'] = {'get': 'ImgParamGet',\n                                     'set': 'ImgParamSet',\n                                     'info': 'ImgParamGet',\n                                     'value': {key: None for key in img_params}}\n\n        # QUICK PROFILE\n        quick_profile_params = ['UseMinAsZero', 'DisplayQPOutOfImage', 'QPRelativeSpace', 'DisplayDirectionForRect',\n                                'AdjustQPHeight', 'DisplayFWHM', 'DoGaussFit', 'FWHMColor', 'FWHMSize', 'FWHMNoOfDigis']\n        self.parameters['QuickProfile'] = {'get': 'QprParamGet',\n                                           'set': 'QprParamSet',\n                                           'info': 'QprParamInfo',\n                                           'value': {key: None for key in quick_profile_params}}\n\n        # LUT\n        LUT_params = ['Limits', 'Cursors', 'Color', 'Inverted', 'Gamma', 'Linearity', 'Overflowcolors']\n        self.parameters['LUT'] = {'get': 'LutParamGet',\n                                  'set': 'LutParamSet',\n                                  'info': 'LutParamInfo',\n                                  'value': {key: None for key in LUT_params}}\n\n        # SEQUENCE\n        sequence_params = ['AutoCorrectAfterSeq', 'DisplayImgDuringSequence', 'PromptBeforeStart', 'EnableStop',\n                           'Warning', 'EnableAcquireWrap', 'LoadHISSequence', 'PackHisFiles', 'NeverLoadToRam',\n                           'LiveStreamingBuffers', 'WrapPlay', 'PlayInterval', 'ProfileNo', 'CorrectionDirection',\n                           'AcquisitionMode', 'NoOfLoops', 'AcquisitionSpeed', 'AcquireInterval', 'DoAcquireWrap',\n                           'AcquireImages', 'ROIOnly', 'StoreTo', 'FirstImgToStore', 'DisplayDataOnly',\n                           'UsedHDSpaceForCheck', 'AcquireProfiles', 'FirstPrfToStore',\n                           'AutoFixpoint', 'ExcludeSample',\n                           'SampleType', 'CurrentSample', 'NumberOfSamples']\n        self.parameters['Sequence'] = {'get': 'SeqParamGet',\n                                       'set': 'SeqParamSet',\n                                       'info': 'SeqParamInfo',\n                                       'value': {key: None for key in sequence_params}}\n\n        # DEVICES\n        dev_params = ['TD', 'Streak', 'Streakcamera', 'Spec', 'Spectrograph',\n                      'Del', 'Delay', 'Delaybox', 'Del1',\n                      'Del2', 'Delay2', 'DelayBox2']\n        self.parameters['Devices'] = {'get': 'DevParamGet',\n                                      'set': 'DevParamSet',\n                                      'info': 'DevParamInfoEx',\n                                      'value': {key: None for key in dev_params}}\n        self.list_dev_params()\n\n    def get_parameter(self, base_name=None, sub_level=None, sub_sub_level=None):\n        \"\"\"Gets and returns streak parameter(s)\n\n        If either sub_level or sub_sub_level are None, returns all the values at that hierarchy\n\n        >>>> streak.get_parameter()  # returns ALL the streak parameters\n\n        >>>> streak.get_parameter('Devices', 'TD')\n        >>>> {'Time Range': '2', 'Mode': 'Operate', 'Gate Mode': 'Normal', 'MCP Gain': '11', 'Shutter': 'Open',\n              'Blanking Amp.': 'off', 'H Trig. mode': 'Cont', 'H Trig. status': 'Reset', 'H Trig. level': '0.5',\n              'H Trig. slope': 'Rising', 'FocusTimeOver': '5', 'Delay': '0'}\n\n        TODO: handle unrecognised/unavailable parameters/devices\n\n        :param base_name: str\n        :param sub_level: str\n        :param sub_sub_level: str\n        :return:\n        \"\"\"\n        self._logger.debug('Getting parameter: %s %s %s' % (base_name, sub_level, sub_sub_level))\n        if base_name is None:\n            return_dict = dict()\n            for base_name in self.parameters:\n                return_dict[base_name] = self.get_parameter(base_name)\n            return return_dict\n\n        command = self.parameters[base_name]['get']\n        base_dictionary = self.parameters[base_name]['value']\n\n        if sub_level is not None and sub_sub_level is not None:\n            return self.send_command(command, sub_level, sub_sub_level)\n        elif sub_sub_level is None:\n            sub_dictionary = base_dictionary[sub_level]\n            if isinstance(sub_dictionary, dict):\n                return_dict = dict()\n                for subsublevel in list(sub_dictionary.keys()):\n                    return_dict[subsublevel] = self.get_parameter(base_name, sub_level, subsublevel)\n                return return_dict\n            else:\n                return self.send_command(command, sub_level, sub_sub_level)\n        else:\n            return_dict = dict()\n            for sublevel in list(base_dictionary.keys()):\n                return_dict[sublevel] = self.get_parameter(base_name, sublevel)\n            return return_dict\n\n    def set_parameter(self, base_name, sub_level=None, sub_sub_level=None, value=None):\n        \"\"\"Sets streak parameter(s)\n\n        >>>> streak.set_parameter('General', 'ShowStreakControl', None, 1)\n        >>>> streak.set_parameter('General', value=dict(ShowStreakControl=1, ShowDelay1Control=0))\n        >>>> streak.set_parameter('Camera', 'Acquire', 'Exposure', '1 s')\n\n        TODO: handle unrecognised/unavailable parameters/devices\n\n        :param base_name: str\n        :param sub_level: str\n        :param sub_sub_level: str\n        :param value: str/int/float or a dictionary of values. If a single value is given, it should correspond to the\n        parameter located by combining base_name, sublevel and subsublevel. If a dictionary, all key/value pairs should\n        be the same as those in base_name+sublevel\n        :return:\n        \"\"\"\n        self._logger.debug('Setting parameter: %s %s %s %s' % (base_name, sub_level, sub_sub_level, value))\n        assert base_name in self.parameters\n        assert value is not None  # always need a value\n        command = self.parameters[base_name]['set']\n        if command is None:\n            self._logger.warn('Cannot set %s' % base_name)\n            return\n        base_dictionary = self.parameters[base_name]['value']\n\n        if sub_level is not None and sub_sub_level is not None:\n            self.send_command(command, sub_level, sub_sub_level, value)\n        elif sub_sub_level is None:\n            sub_dictionary = base_dictionary[sub_level]\n            if isinstance(sub_dictionary, dict):\n                for sub_sub_level, subsub_value in list(value.items()):\n                    assert sub_sub_level in sub_dictionary\n                    self.set_parameter(base_name, sub_level, sub_sub_level, subsub_value)\n            else:\n                self.send_command(command, sub_level, value)\n        else:\n            for sub_level, values in list(value.items()):\n                self.set_parameter(base_name, sub_level, sub_sub_level, values)\n\n    def get_parameter_info(self, base_name, sub_level=None, sub_sub_level=None):\n        \"\"\"\n\n        >>>> streak.get_parameter_info('Devices', 'TD', 'Time Range')\n        >>>> '-1,-1,Time Range,2,2,5,1,2,3,4,5'\n\n        # TODO: parse reply into more useful strings (need to read through the manual for this)\n\n        :param base_name: str\n        :param sub_level: str\n        :param sub_sub_level: str\n        :return:\n        \"\"\"\n        self._logger.debug('Getting parameter info: %s %s %s' % (base_name, sub_level, sub_sub_level))\n        assert base_name in self.parameters\n        command = self.parameters[base_name]['info']\n        if command is None:\n            self._logger.warn('Cannot get info %s' % base_name)\n        base_values = self.parameters[base_name]['value']\n\n        if sub_level is not None and sub_sub_level is not None:\n            return self.send_command(command, sub_level, sub_sub_level)\n        elif sub_sub_level is None:\n            sub_values = base_values[sub_level]\n            if isinstance(sub_values, dict):\n                return_vals = dict()\n                for sub_sub_level in list(sub_values.keys()):\n                    return_vals[sub_sub_level] = self.get_parameter_info(base_name, sub_level, sub_sub_level)\n                return return_vals\n            else:\n                return self.send_command(command, sub_level, sub_sub_level)\n        else:\n            return_vals = dict()\n            for sub_level in list(base_values.keys()):\n                return_vals[sub_level] = self.get_parameter_info(base_name, sub_level)\n            return return_vals\n\n    '''General commands'''\n    def stop(self):\n        \"\"\"\n        Stops the command currently executed. Not currently available due to the VISA communication being locked\n        :return:\n        \"\"\"\n        self.send_command('Stop')\n\n    def shutdown(self):\n        \"\"\"\n        This command shuts down the application and the RemoteEx program. Response is sent before shutdown.\n        The usefulness of this command is limited because it cannot be sent once the application has hung. Restarting of\n        the remote application if an error has occurred should be done by other means (example: Power off and on the\n        computer from remote and starting the RemoteEx from the autostart).\n\n        :return:\n        \"\"\"\n        self.send_command('Shutdown')\n\n    '''Application commands'''\n\n    def start_app(self, visible=1, ini_file=None):\n        \"\"\"Starts the application on the remote computer\n\n        If the application has already been started this command returns immediately, otherwise it waits until it has\n        been started completely. This can take a while, so the timeout is increased to 2 minutes.\n\n        :param visible: int or bool. If 0/False, initiates an invisible application (no window in remote computer). If\n            ommitted or any other value, initiates a visible application. Ignored if application is already running\n        :param ini_file: str. File location. If given, the application starts with the INI-File (new from version 8.3.0).\n            This parameter is also ignored if the application is already running.\n        :return:\n        \"\"\"\n        timeout = self.instr.timeout\n        self.instr.timeout = 120000\n\n        if ini_file is not None:\n            self.send_command('AppStart', visible, ini_file)\n        else:\n            self.send_command('AppStart', visible)\n\n        self.instr.timeout = timeout\n\n    '''Acquisition commands'''\n\n    def start_acquisition(self, mode='Acquire', wait=True):\n        \"\"\"\n        This command starts an acquisition.\n        :param mode: one of the following:\n                'Live'      Live mode\n                'Acquire'   Acquire mode\n                'AI'        Analog integration\n                'PC'        Photon counting\n        :param wait: bool. Whether to wait until the acquisition is done\n        :return:\n        \"\"\"\n        self.send_command('AcqStart', mode)\n        if wait:\n            while self.is_acquisition_busy():\n                time.sleep(0.1)\n\n    def is_acquisition_busy(self):\n        \"\"\"\n        This command returns the status of an acquisition.\n        :return:\n        \"\"\"\n        reply = self.send_command('AcqStatus').split(',')\n        if reply[0] == 'idle':\n            return False\n        elif reply[0] == 'busy':\n            return True\n        else:\n            raise ValueError('Unrecognised status: %s' % reply)\n\n    def stop_acquisition(self, timeout=1000):\n        \"\"\"\n        This command stops the currently running acquisition. It can have an optional parameter (available\n        from 8.2.0 pf5) indicating the timeout value (in ms) until this command should wait for an\n        acquisition to end. The range of this timeout value is [1...60000] and the default value is 1000 (if\n        not specified)\n        # TODO: somehow get the AcquisitionStop/SequenceStop functionality working. Threads in the background?\n        :param timeout:\n        :return: 0,AcqStop (Successfully stopped)\n                or\n                7,AcqStop,timeout (Timeout while waiting for stop)\n        \"\"\"\n        self.send_command('AcqStop', timeout)\n\n    '''Camera commands'''\n\n    def get_live_bkg(self):\n        \"\"\"\n        This command gets a new background image which is used for real time background subtraction (RTBS). It is only\n        available of LIVE mode is running.\n        :return:\n        \"\"\"\n        self.send_command('CamGetLiveBG')\n\n    '''External device commands (HPD-TA only)'''\n\n    def list_dev_params(self, devices=None):\n        \"\"\"Find list of device parameters\n\n        Queries the streak camera devices to find their parameters, and saves them into self.parameters\n\n        :param devices: iterable with one or more of\n                ['TD', 'Streak', 'Streakcamera', 'Spec', 'Spectrograph', 'Del', 'Delay', 'Delaybox',\n                    'Del1', 'Del2', 'Delay2', 'DelayBox2']\n        :return:\n        \"\"\"\n\n        if devices is None:\n            devices = list(self.parameters['Devices']['value'].keys())\n        for device in devices:\n            if device not in list(self.parameters['Devices']['value'].keys()):\n                raise ValueError('Device %s not recognised' % device)\n            try:\n                reply = self.send_command('DevParamsList', device)\n                param_list = reply.split(',')[1:]\n\n                self.parameters['Devices']['value'][device] = {key: None for key in param_list}\n            except StreakError as e:\n                if e.error_code == 7:\n                    self.parameters['Devices']['value'][device] = 'NotAvailable'\n                else:\n                    raise e\n\n    '''Auxiliary devices commands'''\n\n    '''Correction commands'''\n\n    def do_correction(self, destination='Current', type='BacksubShadingCurvature'):\n        \"\"\"\n\n        :param destination: either 'Current' or a number between 0 and 19\n        :param type: one of:\n         ['Backsub', 'Background', 'Shading', 'Curvature', 'BacksubShading', 'BacksubCurvature',\n         'BacksubShadingCurvature', 'DefectCorrect']\n        :return:\n        \"\"\"\n        if type == 'DefectCorrect':\n            raise NotImplementedError\n        self.send_command('CorDoCorrection', destination, type)\n\n    '''Processing commands'''\n\n    '''Defect pixel tool commands'''\n\n    '''Image commands'''\n\n    def save_image(self, image_index='Current', image_type='TIF', filename='DefaultImage.tif', overwrite=False,\n                   directory=None):\n        \"\"\"\n\n        :param image_index: image to be saved, either 'Current' or a number between 0 and 19\n        :param image_type: one of 'IMG' (ITEX file), 'TIF', 'TIFF', 'ASCII',\n                                'data2tiff', 'data2tif', 'display2tiff', 'display2tif'\n        :param filename: file path\n        :param overwrite: whether to overwrite existing files\n        :param directory:\n        :return:\n        \"\"\"\n        if directory is None:\n            directory = os.getcwd()\n        if not os.path.isabs(filename):\n            filename = os.path.join(directory, filename)\n        self.send_command('ImgSave', image_index, image_type, filename, int(overwrite))\n\n    def load_image(self, filename='DefaultImage.txt', image_type='ASCII'):\n        \"\"\"\n        Not that not all file types which can be saved can also be loaded. Some file types are intended for export only.\n        Note: This load functions loads the image always into a new window independently of the setting of\n        the option AcquireToSameWindow. If the maximum number of windows is reached an error is\n        returned.\n        :param filename: path\n        :param image_type: one of 'IMG' (ITEX file), 'TIF', 'TIFF', 'ASCII',\n                                'data2tiff', 'data2tif', 'display2tiff', 'display2tif'\n        :return:\n        \"\"\"\n        if not os.path.isabs(filename):\n            filename = os.path.join(os.getcwd(), filename)\n        self.send_command('ImgLoad', image_type, filename)\n\n    def delete_image(self, image_index='Current'):\n        \"\"\"\n        Note1: This function deletes the specified images independent whether their content has been saved\n        or not. If you want to keep the content of the image please save the image before executing this\n        command.\n        Note2: This function does not delete images on hard disk.\n        :param image_index: 'Current', 'All' or a number between 0-19\n        :return:\n        \"\"\"\n        self.send_command('ImgDelete', image_index)\n\n    def get_image_status(self, image_index='Current', *identifiers):\n        \"\"\"\n\n        :param image_index: 'Current' or a number between 0-19\n        :param identifiers: section identifier and (optional) token identifier\n        :return:\n        \"\"\"\n        if len(identifiers) == 0:\n            reply = self.send_command('ImgStatusGet', image_index, 'All')\n        elif len(identifiers) == 1:\n            reply = self.send_command('ImgStatusGet', image_index, 'Section', identifiers[0])\n        elif len(identifiers) == 2:\n            reply = self.send_command('ImgStatusGet', image_index, 'Token', identifiers[0], identifiers[1])\n        else:\n            raise ValueError('Too many parameters')\n\n        # Split the large string into sections that start with a word within square parenthesis followed by a comma, and\n        # then a bunch of other things until the next square parenthesis\n        sections = re.findall('\\[(.+?)\\],([^\\[]+)', reply)\n        parsed_reply = dict()\n        for section_title, section in sections:\n            parsed_reply[section_title] = dict()\n            # Divide the section into substrings of \"something=something\", separated by commas or the end of the line\n            subsections = re.findall('(.+?)=\"?(.+?)\"?[,\"$]', section)\n            for subsection, value in subsections:\n                parsed_reply[section_title][subsection] = value\n\n        return parsed_reply\n\n    @property\n    def current_index(self):\n        return int(self.send_command('ImgIndexGet'))\n\n    @current_index.setter\n    def current_index(self, index):\n        self.send_command('ImgIndexSet', index)\n\n    @property\n    def default_directory(self):\n        return self.send_command('ImgDefaultDirGet')\n\n    @default_directory.setter\n    def default_directory(self, path):\n        self.send_command('ImgDefaultDirSet', path)\n\n    def get_img_info(self, image_index='Current'):\n        \"\"\"\n        This command returns the image size in pixels and the Bytes per pixel of a single pixel.\n        :param image_index:\n        :return:\n        \"\"\"\n        response = self.send_command('ImgDataInfo', image_index, 'Size')\n        response = [int(x) for x in response.split(',')]\n        shape = response[:4]\n        bytes_per_pixel = response[-1]\n        return shape, bytes_per_pixel\n\n    def get_image_data(self, image_index='Current', type='Data', *profile_params):\n        \"\"\"\n        This command gets image, display or profile data of the select image.\n        The image data is transferred by the optional second TCP-IP channel. If this channel is not available\n        an error is issued.\n        :param image_index: 'Current' or number between 1-19\n        :param type:\n                - 'Data': raw image data (1,2 or 4 BPP)\n                - 'Display': display data (1 BPP)\n                - 'Profile': profile (4 bytes floating point values)\n        :param profile_params: five numbers:\n                - Profile type: 1 (line profile), 2 (horizontal bin), 3 (vertical bin)\n                - Coordinates: iX, iY, iDX, iDY\n        :return:\n        \"\"\"\n        if type != 'Profile':\n            self.send_command('ImgDataGet', image_index, type)\n        else:\n            self.send_command('ImgDataGet', image_index, type, *profile_params)\n\n    def dump_image_data(self, path, image_index='Current', type='Data', *profile_params):\n        \"\"\"\n        This command gets image or display data of the select image and writes it to file (only binary data,\n        no header). It can be used to get image or profile data alternatively to using the second TCP-IP port.\n        :param path:\n        :param image_index:\n        :param type:\n                - 'Data': raw image data (1,2 or 4 BPP)\n                - 'Display': display data (1 BPP)\n                - 'Profile': profile (4 bytes floating point values)\n        :param profile_params: five numbers:\n                - Profile type: 1 (line profile), 2 (horizontal bin), 3 (vertical bin)\n                - Coordinates: iX, iY, iDX, iDY\n        :return:\n        \"\"\"\n        if type != 'Profile':\n            self.send_command('ImgDataDump', image_index, type, path)\n        else:\n            profile_type = profile_params[0]\n            iX = profile_params[1]\n            iY = profile_params[2]\n            iDX = profile_params[3]\n            iDY = profile_params[4]\n            self.send_command('ImgDataDump', image_index, type, profile_type, iX, iY, iDX, iDY, path)\n\n    '''Quick profile commands'''\n\n    '''LUT commands'''\n\n    def auto_lut(self):\n        \"\"\"Automatically sets the LUT of the current image\"\"\"\n        return self.send_command('LutSetAuto')\n\n    '''Sequence commands'''\n\n    def start_sequence(self, directory=None, wait=False):\n        \"\"\"Starts a streak sequence\n\n        :param directory: str or None. If not None, the images in the sequence will be automatically saved to the given\n            directory in the remote computer\n        :param wait: bool. If True, waits until the acquisition is finished before returning\n        :return:\n        \"\"\"\n        if directory is not None:\n            self.set_parameter('Sequence', 'StoreTo', 'HD <individual files - all modes>')\n            self.set_parameter('Sequence', 'FirstImgToStore', directory)\n        self.send_command('SeqStart')\n\n        if wait:\n            while self.is_sequence_busy():\n                time.sleep(0.5)\n\n    def stop_sequence(self):\n        self.send_command('SeqStop')\n\n    def is_sequence_busy(self):\n        reply = self.send_command('SeqStatus')\n        split_reply = reply.split(',')\n        if split_reply[0] == 'idle':\n            return False\n        elif split_reply[0] == 'busy':\n            return True\n        else:\n            raise ValueError('Unrecognised sequence status: %s' % reply)\n\n    def delete_sequence(self):\n        \"\"\"\n        Deletes the current sequence from memory.\n        Note: This function does not delete a sequence on the hard disk.\n        :return:\n        \"\"\"\n        self.send_command('SeqDelete')\n\n    def save_sequence(self, image_type='ASCII', filename='DefaultSequence.txt', overwrite=0):\n        if not os.path.isabs(filename):\n            filename = os.path.join(os.getcwd(), filename)\n        self.send_command('SeqSave', image_type, filename, overwrite)\n\n    def load_sequence(self, image_type='ASCII', filename='DefaultSequence.txt'):\n        if not os.path.isabs(filename):\n            filename = os.path.join(os.getcwd(), filename)\n        self.send_command('SeqLoad', image_type, filename)\n\n    '''My commands'''\n\n    def capture(self, mode='Acquire', save=False, delete=False, save_kwargs=None):\n        \"\"\"Utility function that takes an image and returns the data array\n\n        # TODO: test capturing and returning a sequence\n\n        :param mode:\n        :param save:\n        :param delete:\n        :param save_kwargs:\n        :return:\n        \"\"\"\n        if mode == 'Acquire':\n            self.start_acquisition(mode)\n\n            if save:\n                self.save_image(**save_kwargs)\n                if delete:\n                    self.delete_image()\n            else:\n                shape, pixel_size = self.get_img_info()\n                n_pixels = (shape[2] - shape[0]) * (shape[3] - shape[1])\n\n                self.get_image_data()\n                self._logger.debug('Receiving: %s pixels of size %g' % (n_pixels, pixel_size))\n\n                image = []\n                for pxl_num in range(n_pixels):\n                    pixel = self.data_socket.recv(pixel_size)\n                    pixel_value = struct.unpack('h', pixel)[0]\n                    image += [pixel_value]\n                image = np.array(image).reshape((shape[3] - shape[1], shape[2] - shape[0]))\n                if delete:\n                    self.delete_image()\n                return image\n        elif mode == 'Sequence':\n            self.start_sequence(wait=True)\n\n            if delete:\n                self.delete_sequence()\n        else:\n            raise ValueError('Capture mode not recognised')",
  "def __init__(self, code, msg, reply):\n        if isinstance(code, str):\n            code = int(code)\n        super(StreakError, self).__init__()\n        self.msg = msg\n        self.reply = reply\n        self.error_code = code\n        self.error_name = ERROR_CODES[code]",
  "def __str__(self):\n        return '%s Sent: %s Reply: %s' % (self.error_name, self.msg, self.reply)",
  "def __init__(self, address, start_app=False, get_all_parameters=False, **kwargs):\n        \"\"\"\n\n        :param address: tuple of the streak TCP address (TCP_IP,TCP_PORT)\n        :param kwargs: optional dictionary keys, also passed to nplab.Instrument\n            CloseAppWhenDone:  closes the streak GUI when you delete the Python class instance\n            get_all_parameters:  gets the values of all the parameters on startup\n        \"\"\"\n        visa_address = 'TCPIP::%s::%d::SOCKET' % address\n        settings = dict(read_termination='\\r', write_termination='\\r', timeout=TIMEOUT, query_delay=SLEEPING_TIME)\n        super(StreakSdk, self).__init__(visa_address, settings)\n\n        message = self.read()  # reads the default message that gets sent from RemoteEx\n        if message != 'RemoteEx Ready':\n            self._logger.warn('Not ready: %s' % message)\n\n        self.data_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        self.data_socket.connect((address[0], address[1] + 1))\n        self.data_socket.settimeout(10)\n        message = self.data_socket.recv(100).decode().rstrip()\n        if message != 'RemoteEx Data Ready':\n            self._logger.warn('Data socket not ready: %s' % message)\n        self.clear_read_buffer()\n\n        self.close_app_when_done = False\n        if \"CloseAppWhenDone\" in kwargs:\n            self.close_app_when_done = kwargs['CloseAppWhenDone']\n\n        # Starting the HPDTA GUI\n        if start_app:\n            self.start_app()\n\n        self._setup_parameter_dictionaries()\n\n        # Getting all the parameters\n        if get_all_parameters:\n            self.get_parameter()",
  "def __del__(self):\n        if self.close_app_when_done:\n            self.send_command('AppEnd')\n        super(StreakSdk, self).__del__()",
  "def reopen_connection(self):\n        \"\"\"For some reason, sometimes the remote app crashes, and it's useful to restart the connection without\n        restarting the local python app\n\n        :return:\n        \"\"\"\n        if hasattr(self, 'instr'):\n            del self.instr\n        if hasattr(self, 'data_socket'):\n            self.data_socket.close()\n            del self.data_socket\n\n        settings = dict(read_termination='\\r', write_termination='\\r', timeout=TIMEOUT, query_delay=SLEEPING_TIME)\n\n        rm = visa.ResourceManager()\n        self.instr = rm.open_resource(self._address, **settings)\n\n        message = self.read()  # reads the default message that gets sent from RemoteEx\n        if message != 'RemoteEx Ready':\n            self._logger.warn('Not ready: %s' % message)\n\n        address = self._address.split('::')[1:3]\n        self.data_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        self.data_socket.connect((address[0], int(address[1]) + 1))\n        self.data_socket.settimeout(10)\n        message = self.data_socket.recv(100).decode().rstrip()\n        if message != 'RemoteEx Data Ready':\n            self._logger.warn('Data socket not ready: %s' % message)\n        self.clear_read_buffer()",
  "def query(self, msg, *args, **kwargs):\n        \"\"\"Light wrapper to add logging and handshaking\n\n        :param msg:\n        :param args:\n        :param kwargs:\n        :return:\n        \"\"\"\n        self._logger.debug(\"write: %s\" % msg)\n        full_reply = super(StreakSdk, self).query(msg, *args, **kwargs)\n        self._logger.debug(\"read: %s\" % full_reply)\n        reply = self._handshake(msg, full_reply, *args, **kwargs)\n        return reply",
  "def _handshake(self, message, full_reply, *args, **kwargs):\n        \"\"\"Checks command was executed without errors\n\n        Most times a command is sent to the streak, it replies with a message containing an error code (see ERROR_CODES)\n        and the command name. This method returns the error message if there's been an error, or tries to handshake\n        again if there was no handshake message.\n\n        :return:\n        \"\"\"\n        try:\n            split_reply = full_reply.split(',', 2)\n\n            # Some commands have a response (len = 3), others simply have a handshake (len = 2)\n            if len(split_reply) == 2:\n                split_reply += ('', )\n            error_code, command, reply = split_reply\n\n            if error_code in ['4', '5']:\n                # Some messages in the buffer simply state the streak status\n                self._logger.debug('Useless reply:\\t%s\\t%s\\t%s' % (error_code, command, reply))\n                # They are generally not useful, so we handshake again\n                full_reply = self.read(*args, **kwargs)\n                return self._handshake(message, full_reply, *args, **kwargs)\n            elif message.split('(')[0] != command:\n                self._logger.error('Comparing this: %s \\t to this: %s' % (message.split('(')[0], command))\n                raise RuntimeError('Replied command does not match')\n            elif error_code == '0':\n                self._logger.debug('Handshake worked\\t%s\\t%s' % (command, reply))\n                return reply\n            else:\n                raise StreakError(error_code, message, full_reply)\n        except Exception as e:\n            self._logger.warn('Handshake failed: %s' % e)",
  "def send_command(self, operation, *parameters, **kwargs):\n        \"\"\"Simply parses a command and parameters into the expected TCPIP string command structure:\n            operation(parameter1, parameter2, parameter3...)\n\n        :param operation: str\n        :param parameters: list of parameters to be passed to operation\n        :return:\n        \"\"\"\n\n        self._logger.debug(\"send_command: %s, %s, %s\" % (operation, parameters, kwargs))\n        msg = '%s(%s)' % (operation, ','.join(map(str, parameters)))\n        return self.query(msg, **kwargs)",
  "def _setup_parameter_dictionaries(self):\n        \"\"\"Setting up a dictionary (self.parameters) that contains all the information for calling parameters, as well\n        as their values (once called)\n\n        Streak parameters are hierarchical (e.g. there are 7 parameters related to the Application). Some have one level\n        (like Application) but others have two levels (e.g. Camera has Binning inside Setup, but Exposure inside one of\n        Live/Acquire/AI/PC).\n\n        TODO: make parameters into CameraParameters that can then be bundled into metadata\n            Problem: some parameters do not have names amenable to being attributes (with spaces, stops, slashes)\n        TODO: handle unavailable parameters and devices\n\n        :return:\n        \"\"\"\n        self.parameters = dict()\n\n        # APPLICATION\n        app_params = ['Date', 'Version', 'Directory', 'Title', 'Titlelong', 'ProgDataDir', 'type']\n        self.parameters['Application'] = {'get': 'AppInfo',\n                                          'set': None,\n                                          'info': None,\n                                          'value': {key: None for key in app_params}}\n\n        # MAIN\n        main_params = ['ImageSize', 'Message', 'Temperature', 'GateMode', 'MCPGain', 'Mode', 'Plugin', 'Shutter',\n                       'StreakCamera', 'TimeRange']\n        self.parameters['Main'] = {'get': 'MainParamGet',\n                                   'set': None,\n                                   'info': 'MainParamInfo',\n                                   'value': {key: None for key in main_params}}\n\n        # GENERAL\n        gen_params = ['RestoreWindowPos', 'UserFunctions', 'ShowStreakControl', 'ShowDelay1Control',\n                      'ShowDelay2Control', 'ShowSpectrControl']\n        self.parameters['General'] = {'get': 'GenParamGet',\n                                      'set': 'GenParamSet',\n                                      'info': 'GenParamInfo',\n                                      'value': {key: None for key in gen_params}}\n\n        # ACQUISITION\n        acquisition_params = ['DisplayInterval', '32BitInAI', 'WriteDPCFile', 'AdditionalTimeout',\n                              'DeactivateGrbNotInUse', 'CCDGainForPC', '32BitInPC', 'MoireeReduction']\n        self.parameters['Acquisition'] = {'get': 'AcqParamGet',\n                                          'set': 'AcqParamSet',\n                                          'info': 'AcqParamInfoEx',\n                                          'value': {key: None for key in acquisition_params}}\n\n        # CAMERA\n        setup_param = ['TimingMode', 'TriggerMode', 'TriggerSource', 'TriggerPolarity', 'ScanMode', 'Binning',\n                       'CCDArea', 'LightMode', 'Hoffs', 'HWidth', 'VOffs', 'VWidth', 'ShowGainOffset', 'NoLines',\n                       'LinesPerImage', 'ScrollingLiveDisplay', 'FrameTrigger', 'VerticalBinning', 'TapNo',\n                       'ShutterAction', 'Cooler', 'TargetTemperature', 'ContrastEnhancement', 'Offset', 'Gain',\n                       'XDirection', 'ScanSpeed', 'MechanicalShutter', 'Subtype', 'AutoDetect', 'Wait2ndFrame', 'DX',\n                       'DY', 'XOffset', 'YOffset', 'BPP', 'CameraName', 'ExposureTime', 'ReadoutTime', 'OnChipAmp',\n                       'CoolingFan', 'Cooler', 'ExtOutputPolarity', 'ExtOutputDelay', 'ExtOutputWidth',\n                       'LowLightSensitivity', 'AutomaticBundleHeight', 'CameraInfo']\n        # Two parameters called Offset and Width were not included (name shadowing, must be a bug in the program or a\n        # typo in the manual). Additionally, all the sensor specific parameters were not included\n        tab_param = ['Exposure', 'Gain', 'Offset', 'NrTrigger', 'Threshold', 'Threshold2', 'DoRTBackSub',\n                     'DoRTShading', 'NrExposures', 'ClearFrameBuffer', 'AmpGain', 'SMD', 'RecurNumber', 'HVoltage',\n                     'AMD', 'ASH', 'ATP', 'SOP', 'SPX', 'MCP', 'TDY', 'IntegrAfterTrig', 'SensitivityValue', 'EMG',\n                     'BGSub', 'RecurFilter', 'HightVoltage', 'StreakTrigger', 'FGTrigger', 'SensitivitySwitch',\n                     'BGOffset', 'ATN', 'SMDExtended', 'LightMode', 'ScanSpeed', 'BGDataMemory', 'SHDataMemory',\n                     'SensitivityMode', 'Sensitivity', 'Sensitivity2Mode', 'Sensitivity2', 'ContrastControl',\n                     'ContrastGain', 'ContrastOffset', 'PhotonImagingMode', 'HighDynamicRangeMode', 'RecurNumber2',\n                     'RecurFilter2', 'FrameAvgNumber', 'FrameAvg']\n        cam_params = dict(Setup={key: None for key in setup_param},\n                          Live={key: None for key in tab_param},\n                          Acquire={key: None for key in tab_param},\n                          AI={key: None for key in tab_param},\n                          PC={key: None for key in tab_param})\n        self.parameters['Camera'] = {'get': 'CamParamGet',\n                                     'set': 'CamParamSet',\n                                     'info': 'CamParamInfoEx',\n                                     'value': cam_params}\n\n        # CORRECTIONS\n        bkg_param = ['BackgroundSource', 'BackFilesForAcqModes', 'GeneralFile', 'LiveFile', 'AcquireFile', 'AIFile',\n                     'Constant', 'ClipZero', 'AutoBacksub']\n        curv_param = ['CorrectionFile', 'AutoCurvature']\n        defect_pixel_param = ['DefectCorrection', 'DefectPixelFile']\n        shading_param = ['ShadingFile', 'ShadingConstant', 'AutoShading', 'SensitivityCorrection', 'LampFile']\n        correction_params = dict(Background={key: None for key in bkg_param},\n                                 Shading={key: None for key in curv_param},\n                                 Curvature={key: None for key in defect_pixel_param},\n                                 DefectPixel={key: None for key in shading_param})\n        self.parameters['Corrections'] = {'get': 'CorParamGet',\n                                          'set': 'CorParamSet',\n                                          'info': 'CorParamInfoEx',\n                                          'value': correction_params}\n\n        # IMAGES\n        img_params = ['AcquireToSameWindow', 'DefaultZoomFactor', 'WarnWhenUnsaved', 'Calibrated', 'LowerLUTIsZero',\n                      'AutoLUT', 'AutoLUTInLive', 'AutoLUTInROI', 'HorizontalRuler', 'VerticalRuler', 'FixedITEXHeader']\n        self.parameters['Images'] = {'get': 'ImgParamGet',\n                                     'set': 'ImgParamSet',\n                                     'info': 'ImgParamGet',\n                                     'value': {key: None for key in img_params}}\n\n        # QUICK PROFILE\n        quick_profile_params = ['UseMinAsZero', 'DisplayQPOutOfImage', 'QPRelativeSpace', 'DisplayDirectionForRect',\n                                'AdjustQPHeight', 'DisplayFWHM', 'DoGaussFit', 'FWHMColor', 'FWHMSize', 'FWHMNoOfDigis']\n        self.parameters['QuickProfile'] = {'get': 'QprParamGet',\n                                           'set': 'QprParamSet',\n                                           'info': 'QprParamInfo',\n                                           'value': {key: None for key in quick_profile_params}}\n\n        # LUT\n        LUT_params = ['Limits', 'Cursors', 'Color', 'Inverted', 'Gamma', 'Linearity', 'Overflowcolors']\n        self.parameters['LUT'] = {'get': 'LutParamGet',\n                                  'set': 'LutParamSet',\n                                  'info': 'LutParamInfo',\n                                  'value': {key: None for key in LUT_params}}\n\n        # SEQUENCE\n        sequence_params = ['AutoCorrectAfterSeq', 'DisplayImgDuringSequence', 'PromptBeforeStart', 'EnableStop',\n                           'Warning', 'EnableAcquireWrap', 'LoadHISSequence', 'PackHisFiles', 'NeverLoadToRam',\n                           'LiveStreamingBuffers', 'WrapPlay', 'PlayInterval', 'ProfileNo', 'CorrectionDirection',\n                           'AcquisitionMode', 'NoOfLoops', 'AcquisitionSpeed', 'AcquireInterval', 'DoAcquireWrap',\n                           'AcquireImages', 'ROIOnly', 'StoreTo', 'FirstImgToStore', 'DisplayDataOnly',\n                           'UsedHDSpaceForCheck', 'AcquireProfiles', 'FirstPrfToStore',\n                           'AutoFixpoint', 'ExcludeSample',\n                           'SampleType', 'CurrentSample', 'NumberOfSamples']\n        self.parameters['Sequence'] = {'get': 'SeqParamGet',\n                                       'set': 'SeqParamSet',\n                                       'info': 'SeqParamInfo',\n                                       'value': {key: None for key in sequence_params}}\n\n        # DEVICES\n        dev_params = ['TD', 'Streak', 'Streakcamera', 'Spec', 'Spectrograph',\n                      'Del', 'Delay', 'Delaybox', 'Del1',\n                      'Del2', 'Delay2', 'DelayBox2']\n        self.parameters['Devices'] = {'get': 'DevParamGet',\n                                      'set': 'DevParamSet',\n                                      'info': 'DevParamInfoEx',\n                                      'value': {key: None for key in dev_params}}\n        self.list_dev_params()",
  "def get_parameter(self, base_name=None, sub_level=None, sub_sub_level=None):\n        \"\"\"Gets and returns streak parameter(s)\n\n        If either sub_level or sub_sub_level are None, returns all the values at that hierarchy\n\n        >>>> streak.get_parameter()  # returns ALL the streak parameters\n\n        >>>> streak.get_parameter('Devices', 'TD')\n        >>>> {'Time Range': '2', 'Mode': 'Operate', 'Gate Mode': 'Normal', 'MCP Gain': '11', 'Shutter': 'Open',\n              'Blanking Amp.': 'off', 'H Trig. mode': 'Cont', 'H Trig. status': 'Reset', 'H Trig. level': '0.5',\n              'H Trig. slope': 'Rising', 'FocusTimeOver': '5', 'Delay': '0'}\n\n        TODO: handle unrecognised/unavailable parameters/devices\n\n        :param base_name: str\n        :param sub_level: str\n        :param sub_sub_level: str\n        :return:\n        \"\"\"\n        self._logger.debug('Getting parameter: %s %s %s' % (base_name, sub_level, sub_sub_level))\n        if base_name is None:\n            return_dict = dict()\n            for base_name in self.parameters:\n                return_dict[base_name] = self.get_parameter(base_name)\n            return return_dict\n\n        command = self.parameters[base_name]['get']\n        base_dictionary = self.parameters[base_name]['value']\n\n        if sub_level is not None and sub_sub_level is not None:\n            return self.send_command(command, sub_level, sub_sub_level)\n        elif sub_sub_level is None:\n            sub_dictionary = base_dictionary[sub_level]\n            if isinstance(sub_dictionary, dict):\n                return_dict = dict()\n                for subsublevel in list(sub_dictionary.keys()):\n                    return_dict[subsublevel] = self.get_parameter(base_name, sub_level, subsublevel)\n                return return_dict\n            else:\n                return self.send_command(command, sub_level, sub_sub_level)\n        else:\n            return_dict = dict()\n            for sublevel in list(base_dictionary.keys()):\n                return_dict[sublevel] = self.get_parameter(base_name, sublevel)\n            return return_dict",
  "def set_parameter(self, base_name, sub_level=None, sub_sub_level=None, value=None):\n        \"\"\"Sets streak parameter(s)\n\n        >>>> streak.set_parameter('General', 'ShowStreakControl', None, 1)\n        >>>> streak.set_parameter('General', value=dict(ShowStreakControl=1, ShowDelay1Control=0))\n        >>>> streak.set_parameter('Camera', 'Acquire', 'Exposure', '1 s')\n\n        TODO: handle unrecognised/unavailable parameters/devices\n\n        :param base_name: str\n        :param sub_level: str\n        :param sub_sub_level: str\n        :param value: str/int/float or a dictionary of values. If a single value is given, it should correspond to the\n        parameter located by combining base_name, sublevel and subsublevel. If a dictionary, all key/value pairs should\n        be the same as those in base_name+sublevel\n        :return:\n        \"\"\"\n        self._logger.debug('Setting parameter: %s %s %s %s' % (base_name, sub_level, sub_sub_level, value))\n        assert base_name in self.parameters\n        assert value is not None  # always need a value\n        command = self.parameters[base_name]['set']\n        if command is None:\n            self._logger.warn('Cannot set %s' % base_name)\n            return\n        base_dictionary = self.parameters[base_name]['value']\n\n        if sub_level is not None and sub_sub_level is not None:\n            self.send_command(command, sub_level, sub_sub_level, value)\n        elif sub_sub_level is None:\n            sub_dictionary = base_dictionary[sub_level]\n            if isinstance(sub_dictionary, dict):\n                for sub_sub_level, subsub_value in list(value.items()):\n                    assert sub_sub_level in sub_dictionary\n                    self.set_parameter(base_name, sub_level, sub_sub_level, subsub_value)\n            else:\n                self.send_command(command, sub_level, value)\n        else:\n            for sub_level, values in list(value.items()):\n                self.set_parameter(base_name, sub_level, sub_sub_level, values)",
  "def get_parameter_info(self, base_name, sub_level=None, sub_sub_level=None):\n        \"\"\"\n\n        >>>> streak.get_parameter_info('Devices', 'TD', 'Time Range')\n        >>>> '-1,-1,Time Range,2,2,5,1,2,3,4,5'\n\n        # TODO: parse reply into more useful strings (need to read through the manual for this)\n\n        :param base_name: str\n        :param sub_level: str\n        :param sub_sub_level: str\n        :return:\n        \"\"\"\n        self._logger.debug('Getting parameter info: %s %s %s' % (base_name, sub_level, sub_sub_level))\n        assert base_name in self.parameters\n        command = self.parameters[base_name]['info']\n        if command is None:\n            self._logger.warn('Cannot get info %s' % base_name)\n        base_values = self.parameters[base_name]['value']\n\n        if sub_level is not None and sub_sub_level is not None:\n            return self.send_command(command, sub_level, sub_sub_level)\n        elif sub_sub_level is None:\n            sub_values = base_values[sub_level]\n            if isinstance(sub_values, dict):\n                return_vals = dict()\n                for sub_sub_level in list(sub_values.keys()):\n                    return_vals[sub_sub_level] = self.get_parameter_info(base_name, sub_level, sub_sub_level)\n                return return_vals\n            else:\n                return self.send_command(command, sub_level, sub_sub_level)\n        else:\n            return_vals = dict()\n            for sub_level in list(base_values.keys()):\n                return_vals[sub_level] = self.get_parameter_info(base_name, sub_level)\n            return return_vals",
  "def stop(self):\n        \"\"\"\n        Stops the command currently executed. Not currently available due to the VISA communication being locked\n        :return:\n        \"\"\"\n        self.send_command('Stop')",
  "def shutdown(self):\n        \"\"\"\n        This command shuts down the application and the RemoteEx program. Response is sent before shutdown.\n        The usefulness of this command is limited because it cannot be sent once the application has hung. Restarting of\n        the remote application if an error has occurred should be done by other means (example: Power off and on the\n        computer from remote and starting the RemoteEx from the autostart).\n\n        :return:\n        \"\"\"\n        self.send_command('Shutdown')",
  "def start_app(self, visible=1, ini_file=None):\n        \"\"\"Starts the application on the remote computer\n\n        If the application has already been started this command returns immediately, otherwise it waits until it has\n        been started completely. This can take a while, so the timeout is increased to 2 minutes.\n\n        :param visible: int or bool. If 0/False, initiates an invisible application (no window in remote computer). If\n            ommitted or any other value, initiates a visible application. Ignored if application is already running\n        :param ini_file: str. File location. If given, the application starts with the INI-File (new from version 8.3.0).\n            This parameter is also ignored if the application is already running.\n        :return:\n        \"\"\"\n        timeout = self.instr.timeout\n        self.instr.timeout = 120000\n\n        if ini_file is not None:\n            self.send_command('AppStart', visible, ini_file)\n        else:\n            self.send_command('AppStart', visible)\n\n        self.instr.timeout = timeout",
  "def start_acquisition(self, mode='Acquire', wait=True):\n        \"\"\"\n        This command starts an acquisition.\n        :param mode: one of the following:\n                'Live'      Live mode\n                'Acquire'   Acquire mode\n                'AI'        Analog integration\n                'PC'        Photon counting\n        :param wait: bool. Whether to wait until the acquisition is done\n        :return:\n        \"\"\"\n        self.send_command('AcqStart', mode)\n        if wait:\n            while self.is_acquisition_busy():\n                time.sleep(0.1)",
  "def is_acquisition_busy(self):\n        \"\"\"\n        This command returns the status of an acquisition.\n        :return:\n        \"\"\"\n        reply = self.send_command('AcqStatus').split(',')\n        if reply[0] == 'idle':\n            return False\n        elif reply[0] == 'busy':\n            return True\n        else:\n            raise ValueError('Unrecognised status: %s' % reply)",
  "def stop_acquisition(self, timeout=1000):\n        \"\"\"\n        This command stops the currently running acquisition. It can have an optional parameter (available\n        from 8.2.0 pf5) indicating the timeout value (in ms) until this command should wait for an\n        acquisition to end. The range of this timeout value is [1...60000] and the default value is 1000 (if\n        not specified)\n        # TODO: somehow get the AcquisitionStop/SequenceStop functionality working. Threads in the background?\n        :param timeout:\n        :return: 0,AcqStop (Successfully stopped)\n                or\n                7,AcqStop,timeout (Timeout while waiting for stop)\n        \"\"\"\n        self.send_command('AcqStop', timeout)",
  "def get_live_bkg(self):\n        \"\"\"\n        This command gets a new background image which is used for real time background subtraction (RTBS). It is only\n        available of LIVE mode is running.\n        :return:\n        \"\"\"\n        self.send_command('CamGetLiveBG')",
  "def list_dev_params(self, devices=None):\n        \"\"\"Find list of device parameters\n\n        Queries the streak camera devices to find their parameters, and saves them into self.parameters\n\n        :param devices: iterable with one or more of\n                ['TD', 'Streak', 'Streakcamera', 'Spec', 'Spectrograph', 'Del', 'Delay', 'Delaybox',\n                    'Del1', 'Del2', 'Delay2', 'DelayBox2']\n        :return:\n        \"\"\"\n\n        if devices is None:\n            devices = list(self.parameters['Devices']['value'].keys())\n        for device in devices:\n            if device not in list(self.parameters['Devices']['value'].keys()):\n                raise ValueError('Device %s not recognised' % device)\n            try:\n                reply = self.send_command('DevParamsList', device)\n                param_list = reply.split(',')[1:]\n\n                self.parameters['Devices']['value'][device] = {key: None for key in param_list}\n            except StreakError as e:\n                if e.error_code == 7:\n                    self.parameters['Devices']['value'][device] = 'NotAvailable'\n                else:\n                    raise e",
  "def do_correction(self, destination='Current', type='BacksubShadingCurvature'):\n        \"\"\"\n\n        :param destination: either 'Current' or a number between 0 and 19\n        :param type: one of:\n         ['Backsub', 'Background', 'Shading', 'Curvature', 'BacksubShading', 'BacksubCurvature',\n         'BacksubShadingCurvature', 'DefectCorrect']\n        :return:\n        \"\"\"\n        if type == 'DefectCorrect':\n            raise NotImplementedError\n        self.send_command('CorDoCorrection', destination, type)",
  "def save_image(self, image_index='Current', image_type='TIF', filename='DefaultImage.tif', overwrite=False,\n                   directory=None):\n        \"\"\"\n\n        :param image_index: image to be saved, either 'Current' or a number between 0 and 19\n        :param image_type: one of 'IMG' (ITEX file), 'TIF', 'TIFF', 'ASCII',\n                                'data2tiff', 'data2tif', 'display2tiff', 'display2tif'\n        :param filename: file path\n        :param overwrite: whether to overwrite existing files\n        :param directory:\n        :return:\n        \"\"\"\n        if directory is None:\n            directory = os.getcwd()\n        if not os.path.isabs(filename):\n            filename = os.path.join(directory, filename)\n        self.send_command('ImgSave', image_index, image_type, filename, int(overwrite))",
  "def load_image(self, filename='DefaultImage.txt', image_type='ASCII'):\n        \"\"\"\n        Not that not all file types which can be saved can also be loaded. Some file types are intended for export only.\n        Note: This load functions loads the image always into a new window independently of the setting of\n        the option AcquireToSameWindow. If the maximum number of windows is reached an error is\n        returned.\n        :param filename: path\n        :param image_type: one of 'IMG' (ITEX file), 'TIF', 'TIFF', 'ASCII',\n                                'data2tiff', 'data2tif', 'display2tiff', 'display2tif'\n        :return:\n        \"\"\"\n        if not os.path.isabs(filename):\n            filename = os.path.join(os.getcwd(), filename)\n        self.send_command('ImgLoad', image_type, filename)",
  "def delete_image(self, image_index='Current'):\n        \"\"\"\n        Note1: This function deletes the specified images independent whether their content has been saved\n        or not. If you want to keep the content of the image please save the image before executing this\n        command.\n        Note2: This function does not delete images on hard disk.\n        :param image_index: 'Current', 'All' or a number between 0-19\n        :return:\n        \"\"\"\n        self.send_command('ImgDelete', image_index)",
  "def get_image_status(self, image_index='Current', *identifiers):\n        \"\"\"\n\n        :param image_index: 'Current' or a number between 0-19\n        :param identifiers: section identifier and (optional) token identifier\n        :return:\n        \"\"\"\n        if len(identifiers) == 0:\n            reply = self.send_command('ImgStatusGet', image_index, 'All')\n        elif len(identifiers) == 1:\n            reply = self.send_command('ImgStatusGet', image_index, 'Section', identifiers[0])\n        elif len(identifiers) == 2:\n            reply = self.send_command('ImgStatusGet', image_index, 'Token', identifiers[0], identifiers[1])\n        else:\n            raise ValueError('Too many parameters')\n\n        # Split the large string into sections that start with a word within square parenthesis followed by a comma, and\n        # then a bunch of other things until the next square parenthesis\n        sections = re.findall('\\[(.+?)\\],([^\\[]+)', reply)\n        parsed_reply = dict()\n        for section_title, section in sections:\n            parsed_reply[section_title] = dict()\n            # Divide the section into substrings of \"something=something\", separated by commas or the end of the line\n            subsections = re.findall('(.+?)=\"?(.+?)\"?[,\"$]', section)\n            for subsection, value in subsections:\n                parsed_reply[section_title][subsection] = value\n\n        return parsed_reply",
  "def current_index(self):\n        return int(self.send_command('ImgIndexGet'))",
  "def current_index(self, index):\n        self.send_command('ImgIndexSet', index)",
  "def default_directory(self):\n        return self.send_command('ImgDefaultDirGet')",
  "def default_directory(self, path):\n        self.send_command('ImgDefaultDirSet', path)",
  "def get_img_info(self, image_index='Current'):\n        \"\"\"\n        This command returns the image size in pixels and the Bytes per pixel of a single pixel.\n        :param image_index:\n        :return:\n        \"\"\"\n        response = self.send_command('ImgDataInfo', image_index, 'Size')\n        response = [int(x) for x in response.split(',')]\n        shape = response[:4]\n        bytes_per_pixel = response[-1]\n        return shape, bytes_per_pixel",
  "def get_image_data(self, image_index='Current', type='Data', *profile_params):\n        \"\"\"\n        This command gets image, display or profile data of the select image.\n        The image data is transferred by the optional second TCP-IP channel. If this channel is not available\n        an error is issued.\n        :param image_index: 'Current' or number between 1-19\n        :param type:\n                - 'Data': raw image data (1,2 or 4 BPP)\n                - 'Display': display data (1 BPP)\n                - 'Profile': profile (4 bytes floating point values)\n        :param profile_params: five numbers:\n                - Profile type: 1 (line profile), 2 (horizontal bin), 3 (vertical bin)\n                - Coordinates: iX, iY, iDX, iDY\n        :return:\n        \"\"\"\n        if type != 'Profile':\n            self.send_command('ImgDataGet', image_index, type)\n        else:\n            self.send_command('ImgDataGet', image_index, type, *profile_params)",
  "def dump_image_data(self, path, image_index='Current', type='Data', *profile_params):\n        \"\"\"\n        This command gets image or display data of the select image and writes it to file (only binary data,\n        no header). It can be used to get image or profile data alternatively to using the second TCP-IP port.\n        :param path:\n        :param image_index:\n        :param type:\n                - 'Data': raw image data (1,2 or 4 BPP)\n                - 'Display': display data (1 BPP)\n                - 'Profile': profile (4 bytes floating point values)\n        :param profile_params: five numbers:\n                - Profile type: 1 (line profile), 2 (horizontal bin), 3 (vertical bin)\n                - Coordinates: iX, iY, iDX, iDY\n        :return:\n        \"\"\"\n        if type != 'Profile':\n            self.send_command('ImgDataDump', image_index, type, path)\n        else:\n            profile_type = profile_params[0]\n            iX = profile_params[1]\n            iY = profile_params[2]\n            iDX = profile_params[3]\n            iDY = profile_params[4]\n            self.send_command('ImgDataDump', image_index, type, profile_type, iX, iY, iDX, iDY, path)",
  "def auto_lut(self):\n        \"\"\"Automatically sets the LUT of the current image\"\"\"\n        return self.send_command('LutSetAuto')",
  "def start_sequence(self, directory=None, wait=False):\n        \"\"\"Starts a streak sequence\n\n        :param directory: str or None. If not None, the images in the sequence will be automatically saved to the given\n            directory in the remote computer\n        :param wait: bool. If True, waits until the acquisition is finished before returning\n        :return:\n        \"\"\"\n        if directory is not None:\n            self.set_parameter('Sequence', 'StoreTo', 'HD <individual files - all modes>')\n            self.set_parameter('Sequence', 'FirstImgToStore', directory)\n        self.send_command('SeqStart')\n\n        if wait:\n            while self.is_sequence_busy():\n                time.sleep(0.5)",
  "def stop_sequence(self):\n        self.send_command('SeqStop')",
  "def is_sequence_busy(self):\n        reply = self.send_command('SeqStatus')\n        split_reply = reply.split(',')\n        if split_reply[0] == 'idle':\n            return False\n        elif split_reply[0] == 'busy':\n            return True\n        else:\n            raise ValueError('Unrecognised sequence status: %s' % reply)",
  "def delete_sequence(self):\n        \"\"\"\n        Deletes the current sequence from memory.\n        Note: This function does not delete a sequence on the hard disk.\n        :return:\n        \"\"\"\n        self.send_command('SeqDelete')",
  "def save_sequence(self, image_type='ASCII', filename='DefaultSequence.txt', overwrite=0):\n        if not os.path.isabs(filename):\n            filename = os.path.join(os.getcwd(), filename)\n        self.send_command('SeqSave', image_type, filename, overwrite)",
  "def load_sequence(self, image_type='ASCII', filename='DefaultSequence.txt'):\n        if not os.path.isabs(filename):\n            filename = os.path.join(os.getcwd(), filename)\n        self.send_command('SeqLoad', image_type, filename)",
  "def capture(self, mode='Acquire', save=False, delete=False, save_kwargs=None):\n        \"\"\"Utility function that takes an image and returns the data array\n\n        # TODO: test capturing and returning a sequence\n\n        :param mode:\n        :param save:\n        :param delete:\n        :param save_kwargs:\n        :return:\n        \"\"\"\n        if mode == 'Acquire':\n            self.start_acquisition(mode)\n\n            if save:\n                self.save_image(**save_kwargs)\n                if delete:\n                    self.delete_image()\n            else:\n                shape, pixel_size = self.get_img_info()\n                n_pixels = (shape[2] - shape[0]) * (shape[3] - shape[1])\n\n                self.get_image_data()\n                self._logger.debug('Receiving: %s pixels of size %g' % (n_pixels, pixel_size))\n\n                image = []\n                for pxl_num in range(n_pixels):\n                    pixel = self.data_socket.recv(pixel_size)\n                    pixel_value = struct.unpack('h', pixel)[0]\n                    image += [pixel_value]\n                image = np.array(image).reshape((shape[3] - shape[1], shape[2] - shape[0]))\n                if delete:\n                    self.delete_image()\n                return image\n        elif mode == 'Sequence':\n            self.start_sequence(wait=True)\n\n            if delete:\n                self.delete_sequence()\n        else:\n            raise ValueError('Capture mode not recognised')",
  "class Streak(StreakSdk, CameraRoiScale):\n    def __init__(self, *args, **kwargs):\n        super(Streak, self).__init__(*args, **kwargs)\n\n    def get_control_widget(self):\n        return StreakUI(self)\n\n    def get_preview_widget(self):\n        self._logger.debug('Getting preview widget')\n        if self._preview_widgets is None:\n            self._preview_widgets = WeakSet()\n        new_widget = DisplayWidgetRoiScale()\n        self._preview_widgets.add(new_widget)\n        return new_widget\n\n    def raw_snapshot(self):\n        try:\n            image = self.capture()\n            return True, self.bundle_metadata(image)\n        except Exception as e:\n            self._logger.warn(\"Couldn't Capture because %s\" % e)",
  "class StreakUI(QtWidgets.QWidget):\n    ImageUpdated = QtCore.Signal()\n\n    def __init__(self, streak):\n        super(StreakUI, self).__init__()\n\n        self.Streak = streak\n        uic.loadUi((os.path.dirname(__file__) + '/Streak.ui'), self)\n\n        self.comboBoxGateMode.activated.connect(self.gate_mode)\n        self.comboBoxReadMode.activated.connect(self.read_mode)\n        self.comboBoxShutter.activated.connect(self.shutter)\n        self.comboBoxTrigMode.activated.connect(self.trigger)\n        self.spinBox_MCPGain.valueChanged.connect(self.mcp_gain)\n        self.lineEditTimeRange.returnPressed.connect(self.time_range)\n        self.comboBoxTimeUnit.activated.connect(self.time_range)\n        self.pushButtonLess.clicked.connect(lambda: self.time_range('-'))\n        self.pushButtonMore.clicked.connect(lambda: self.time_range('+'))\n\n        self.pushButtonCapture.clicked.connect(lambda: self.Streak.raw_image(update_latest_frame=True))\n\n    def gate_mode(self):\n        mode = str(self.comboBoxGateMode.currentText())\n        self.Streak.set_parameter('Devices', 'TD', 'Gate Mode', mode)\n\n    def read_mode(self):\n        mode = str(self.comboBoxReadMode.currentText())\n        self.Streak.set_parameter('Devices', 'TD', 'Mode', mode)\n\n    def shutter(self):\n        mode = str(self.comboBoxShutter.currentText())\n        self.Streak.set_parameter('Devices', 'TD', 'Shutter', mode)\n\n    def trigger(self):\n        mode = str(self.comboBoxTrigMode.currentText())\n        self.Streak.set_parameter('Devices', 'TD', 'Trig. Mode', mode)\n\n    def mcp_gain(self):\n        gain = int(self.spinBox_MCPGain.value())\n        self.Streak.set_parameter('Devices', 'TD', 'MCP Gain', gain)\n\n    def time_range(self, direction=None):\n        allowed_times = {'ns': [5, 10, 20, 50, 100, 200, 500],\n                         'us': [1, 2, 5, 10, 20, 50, 100, 200, 500],\n                         'ms': [1]}\n        unit = str(self.comboBoxTimeUnit.currentText())\n        given_number = int(self.lineEditTimeRange.text())\n\n        if direction is '+':\n            if not (unit == 'ms' and given_number == 1):\n                next_unit = str(unit)\n                if given_number != 500:\n                    next_number = allowed_times[unit][allowed_times[unit].index(given_number) + 1]\n                else:\n                    next_number = 1\n                    if unit == 'ns':\n                        self.comboBoxTimeUnit.setCurrentIndex(1)\n                        next_unit = 'us'\n                    elif unit == 'us':\n                        self.comboBoxTimeUnit.setCurrentIndex(2)\n                        next_unit = 'ms'\n                self.lineEditTimeRange.setText(str(next_number))\n                unit = str(next_unit)\n            else:\n                self.Streak._logger.info('Tried increasing the maximum time range')\n                return\n        elif direction is '-':\n            if not (unit == 'ns' and given_number == 5):\n                next_unit = str(unit)\n                if given_number != 1:\n                    next_number = allowed_times[unit][allowed_times[unit].index(given_number) - 1]\n                else:\n                    next_number = 500\n                    if unit == 'ms':\n                        self.comboBoxTimeUnit.setCurrentIndex(1)\n                        next_unit = 'us'\n                    elif unit == 'us':\n                        self.comboBoxTimeUnit.setCurrentIndex(0)\n                        next_unit = 'ns'\n                self.lineEditTimeRange.setText(str(next_number))\n                unit = str(next_unit)\n            else:\n                self.Streak._logger.info('Tried decreasing the minimum time range')\n                return\n        else:\n            next_number = min(allowed_times[unit], key=lambda x: abs(x - given_number))\n            self.lineEditTimeRange.setText(str(next_number))\n\n        # Some camera models don't give you direct access to the time range, but rather you preset a finite number of\n        # settings that you then switch between\n        try:\n            self.Streak.set_parameter('Devices', 'TD', 'Time Range', str(next_number) + ' ' + unit)\n        except StreakError:\n            self.Streak.set_parameter('Devices', 'TD', 'Time Range', str(next_number))",
  "def __init__(self, *args, **kwargs):\n        super(Streak, self).__init__(*args, **kwargs)",
  "def get_control_widget(self):\n        return StreakUI(self)",
  "def get_preview_widget(self):\n        self._logger.debug('Getting preview widget')\n        if self._preview_widgets is None:\n            self._preview_widgets = WeakSet()\n        new_widget = DisplayWidgetRoiScale()\n        self._preview_widgets.add(new_widget)\n        return new_widget",
  "def raw_snapshot(self):\n        try:\n            image = self.capture()\n            return True, self.bundle_metadata(image)\n        except Exception as e:\n            self._logger.warn(\"Couldn't Capture because %s\" % e)",
  "def __init__(self, streak):\n        super(StreakUI, self).__init__()\n\n        self.Streak = streak\n        uic.loadUi((os.path.dirname(__file__) + '/Streak.ui'), self)\n\n        self.comboBoxGateMode.activated.connect(self.gate_mode)\n        self.comboBoxReadMode.activated.connect(self.read_mode)\n        self.comboBoxShutter.activated.connect(self.shutter)\n        self.comboBoxTrigMode.activated.connect(self.trigger)\n        self.spinBox_MCPGain.valueChanged.connect(self.mcp_gain)\n        self.lineEditTimeRange.returnPressed.connect(self.time_range)\n        self.comboBoxTimeUnit.activated.connect(self.time_range)\n        self.pushButtonLess.clicked.connect(lambda: self.time_range('-'))\n        self.pushButtonMore.clicked.connect(lambda: self.time_range('+'))\n\n        self.pushButtonCapture.clicked.connect(lambda: self.Streak.raw_image(update_latest_frame=True))",
  "def gate_mode(self):\n        mode = str(self.comboBoxGateMode.currentText())\n        self.Streak.set_parameter('Devices', 'TD', 'Gate Mode', mode)",
  "def read_mode(self):\n        mode = str(self.comboBoxReadMode.currentText())\n        self.Streak.set_parameter('Devices', 'TD', 'Mode', mode)",
  "def shutter(self):\n        mode = str(self.comboBoxShutter.currentText())\n        self.Streak.set_parameter('Devices', 'TD', 'Shutter', mode)",
  "def trigger(self):\n        mode = str(self.comboBoxTrigMode.currentText())\n        self.Streak.set_parameter('Devices', 'TD', 'Trig. Mode', mode)",
  "def mcp_gain(self):\n        gain = int(self.spinBox_MCPGain.value())\n        self.Streak.set_parameter('Devices', 'TD', 'MCP Gain', gain)",
  "def time_range(self, direction=None):\n        allowed_times = {'ns': [5, 10, 20, 50, 100, 200, 500],\n                         'us': [1, 2, 5, 10, 20, 50, 100, 200, 500],\n                         'ms': [1]}\n        unit = str(self.comboBoxTimeUnit.currentText())\n        given_number = int(self.lineEditTimeRange.text())\n\n        if direction is '+':\n            if not (unit == 'ms' and given_number == 1):\n                next_unit = str(unit)\n                if given_number != 500:\n                    next_number = allowed_times[unit][allowed_times[unit].index(given_number) + 1]\n                else:\n                    next_number = 1\n                    if unit == 'ns':\n                        self.comboBoxTimeUnit.setCurrentIndex(1)\n                        next_unit = 'us'\n                    elif unit == 'us':\n                        self.comboBoxTimeUnit.setCurrentIndex(2)\n                        next_unit = 'ms'\n                self.lineEditTimeRange.setText(str(next_number))\n                unit = str(next_unit)\n            else:\n                self.Streak._logger.info('Tried increasing the maximum time range')\n                return\n        elif direction is '-':\n            if not (unit == 'ns' and given_number == 5):\n                next_unit = str(unit)\n                if given_number != 1:\n                    next_number = allowed_times[unit][allowed_times[unit].index(given_number) - 1]\n                else:\n                    next_number = 500\n                    if unit == 'ms':\n                        self.comboBoxTimeUnit.setCurrentIndex(1)\n                        next_unit = 'us'\n                    elif unit == 'us':\n                        self.comboBoxTimeUnit.setCurrentIndex(0)\n                        next_unit = 'ns'\n                self.lineEditTimeRange.setText(str(next_number))\n                unit = str(next_unit)\n            else:\n                self.Streak._logger.info('Tried decreasing the minimum time range')\n                return\n        else:\n            next_number = min(allowed_times[unit], key=lambda x: abs(x - given_number))\n            self.lineEditTimeRange.setText(str(next_number))\n\n        # Some camera models don't give you direct access to the time range, but rather you preset a finite number of\n        # settings that you then switch between\n        try:\n            self.Streak.set_parameter('Devices', 'TD', 'Time Range', str(next_number) + ' ' + unit)\n        except StreakError:\n            self.Streak.set_parameter('Devices', 'TD', 'Time Range', str(next_number))",
  "class Magnet(SerialInstrument):\n    termination_character = '\\n'\n    legal_input='NSZs' # there are the allowed inputs: N sets North, S-South, Z-zero,s-query device for it's state\n    port_settings = {'baudrate': 9600,\n                     'timeout': 0.05}\n    def __init__(self, port=None): # initialize communication and set device to zero\n        SerialInstrument.__init__(self, port)\n        self._state = None\n        self.set_state('Z')\n        \n    \n    def correct_input(self, letter): # check legal input\n        if (len(letter)==1) and (letter in self.legal_input): \n            return True\n        else:\n            return False\n       \n    def get_state(self, report_success=False): # query current state\n        return self.query('s')\n\n    def set_state(self, state): # set state\n        if self.correct_input(state):\n            if state != self._state:\n                self._state = self.query(state)\n    \n    def flush_buffer(self, *args, **kwargs):\n        out = super().query(*args, **kwargs)\n        self.log(out, 'info')\n        while self.readline() != '':\n            pass\n        print('finished flushing buffer' + str(self.readline()))\n        return out            \n    \n    def North(self):\n         self.set_state('N')\n\n    def Zero(self):\n        self.set_state('Z')\n    \n    def South(self):\n        self.set_state('S')\n     \n    def get_qt_ui(self):\n        \"\"\"Return a graphical interface for the lamp slider.\"\"\"\n        return MagnetUI(self)",
  "class MagnetUI(QuickControlBox):\n    def __init__(self, Magnet):\n        super().__init__(title='Magnet')\n        self.Magnet = Magnet\n        self.add_button('North')  # or function to connect\n        self.add_button('South')  # or function to connect\n        self.add_button('Zero')  # or function to connect\n        self.auto_connect_by_name(controlled_object=Magnet)",
  "def __init__(self, port=None): # initialize communication and set device to zero\n        SerialInstrument.__init__(self, port)\n        self._state = None\n        self.set_state('Z')",
  "def correct_input(self, letter): # check legal input\n        if (len(letter)==1) and (letter in self.legal_input): \n            return True\n        else:\n            return False",
  "def get_state(self, report_success=False): # query current state\n        return self.query('s')",
  "def set_state(self, state): # set state\n        if self.correct_input(state):\n            if state != self._state:\n                self._state = self.query(state)",
  "def flush_buffer(self, *args, **kwargs):\n        out = super().query(*args, **kwargs)\n        self.log(out, 'info')\n        while self.readline() != '':\n            pass\n        print('finished flushing buffer' + str(self.readline()))\n        return out",
  "def North(self):\n         self.set_state('N')",
  "def Zero(self):\n        self.set_state('Z')",
  "def South(self):\n        self.set_state('S')",
  "def get_qt_ui(self):\n        \"\"\"Return a graphical interface for the lamp slider.\"\"\"\n        return MagnetUI(self)",
  "def __init__(self, Magnet):\n        super().__init__(title='Magnet')\n        self.Magnet = Magnet\n        self.add_button('North')  # or function to connect\n        self.add_button('South')  # or function to connect\n        self.add_button('Zero')  # or function to connect\n        self.auto_connect_by_name(controlled_object=Magnet)",
  "def ML32_BYTE(four_byte_val): return ((uns8) ((four_byte_val) >> 8))",
  "def LS32_BYTE(four_byte_val): return ((uns8) (four_byte_val))",
  "def MS16_BYTE(two_byte_value): return ((uns8) ((two_byte_value) >> 8))",
  "def LS16_BYTE(two_byte_value): return ((uns8) (two_byte_value))",
  "def VAL_UNS16(ms_byte,ls_byte): return ( (uns16)(((uns16)((uns8)(ms_byte))<<8) | ((uns16)((uns8)(ls_byte)))) )",
  "def VAL_UNS32(ms_byte,mh_byte,ml_byte,ls_byte): return ( ((uns32)((uns8)(ms_byte))<<24) | ((uns32)((uns8)(mh_byte))<<16) | ((uns32)((uns8)(ml_byte))<<8) | ((uns32)((uns8)(ls_byte)) ) )",
  "def MS32_BYTE(four_byte_val): return ((uns8) ((four_byte_val) >> 24))",
  "def MH32_BYTE(four_byte_val): return ((uns8) ((four_byte_val) >> 16))",
  "class rgn_type(Structure):\n    pass",
  "class export_ctrl_type(Structure):\n    pass",
  "def initialize_measurement():\n\tp = Pixis256EQt()\n\tp.exposure = EXPOSURE\n\treturn p",
  "def make_app(pixis, refresh_time):\n\tprint(\"one\")\n\tapp = QtGui.QApplication([])\n\tprint(\"two\")\n\n\tw = QtGui.QWidget()\n\tplot = pg.ImageView()\n\n\tlayout = QtGui.QGridLayout() \n\tw.setLayout(layout) \n\tlayout.addWidget(plot, 0, 0) \n\tw.show()\n\t\n\ttimer = pg.QtCore.QTimer() \n\tdef update(): \n\n\t\timg = pixis.read_image(pixis.exposure, timing='timed', mode='kinetics', new=False, end= True, k_size=1)\n\t\t# img = np.random.uniform(0,1,(500,500))\n\t\tplot.setImage(img.T)\n\n\ttimer.timeout.connect(update)\n\ttimer.start(refresh_time)\n\tapp.exec_()",
  "def update(): \n\n\t\timg = pixis.read_image(pixis.exposure, timing='timed', mode='kinetics', new=False, end= True, k_size=1)\n\t\t# img = np.random.uniform(0,1,(500,500))\n\t\tplot.setImage(img.T)",
  "class CCD(Instrument):\n    def __init__(self):\n        super(CCD, self).__init__()\n        self._wavelengths = None\n        self.reference = None\n        self.background = None\n        self._config_file = None\n        self.latest_image = None\n\n    def __del__(self):\n        try:\n            self._config_file.close()\n        except AttributeError:\n            pass  # if it's not present, we get an exception - which doesn't matter.\n\n    def read_image(self):\n        raise NotImplementedError\n\n    @property\n    def config_file(self):\n        \"\"\"\n        Open the config file for the current spectrometer and return it, creating if it's not\n        there.\n        \"\"\"\n        if self._config_file is None:\n            f = inspect.getfile(self.__class__)\n            d = os.path.dirname(f)\n            self._config_file = h5py.File(os.path.join(d, 'config.h5'))\n            self._config_file.attrs['date'] = datetime.datetime.now().strftime(\"%H:%M %d/%m/%y\")\n        return self._config_file\n\n    def update_config(self, name, data):\n        f = self.config_file\n        if name not in f:\n            f.create_dataset(name, data=data)\n        else:\n            dset = f[name]\n            dset[:] = data\n            f.flush()\n\n    def read_background(self):\n        \"\"\"Acquire a new spectrum and use it as a background measurement.\"\"\"\n        self.background = self.read_image()\n        self.update_config('background', self.background)\n\n    def clear_background(self):\n        \"\"\"Clear the current background reading.\"\"\"\n        self.background = None\n\n    def read_reference(self):\n        \"\"\"Acquire a new spectrum and use it as a reference.\"\"\"\n        self.reference = self.read_image()\n        self.update_config('reference', self.reference)\n\n    def clear_reference(self):\n        \"\"\"Clear the current reference spectrum\"\"\"\n        self.reference = None\n\n    def process_image(self, image):\n        \"\"\"Subtract the background and divide by the reference, if possible\"\"\"\n        if self.background is not None:\n            if self.reference is not None:\n                old_error_settings = np.seterr(all='ignore')\n                new_image = (image - self.background)/(self.reference - self.background)\n                np.seterr(**old_error_settings)\n                # if the reference is nearly 0, we get infinities - just make them all NaNs.\n                new_image[np.isinf(new_image)] = np.nan\n            else:\n                new_image = image - self.background\n        else:\n            new_image = image\n        return new_image\n\n    def read_processed_image(self):\n        \"\"\"\n        Acquire a new image and return a processed (referenced/background-subtracted) image.\n\n        NB if saving data to file, it's best to save raw images along with metadata - this is a\n        convenience method for display purposes.\n        \"\"\"\n        image = self.read_image()\n        self.latest_image = self.process_image(image)\n        return self.latest_image\n\n    def mask_image(self, image, threshold=0.05):\n        \"\"\"\n        Return a masked array of the image, showing only points where the reference\n        is bright enough to be useful.\n        \"\"\"\n        if self.reference is not None and self.background is not None:\n            reference = self.reference - self.background\n            mask = reference < reference.max() * threshold\n            return ma.array(image, mask=mask)\n        else:\n            return image",
  "def __init__(self):\n        super(CCD, self).__init__()\n        self._wavelengths = None\n        self.reference = None\n        self.background = None\n        self._config_file = None\n        self.latest_image = None",
  "def __del__(self):\n        try:\n            self._config_file.close()\n        except AttributeError:\n            pass",
  "def read_image(self):\n        raise NotImplementedError",
  "def config_file(self):\n        \"\"\"\n        Open the config file for the current spectrometer and return it, creating if it's not\n        there.\n        \"\"\"\n        if self._config_file is None:\n            f = inspect.getfile(self.__class__)\n            d = os.path.dirname(f)\n            self._config_file = h5py.File(os.path.join(d, 'config.h5'))\n            self._config_file.attrs['date'] = datetime.datetime.now().strftime(\"%H:%M %d/%m/%y\")\n        return self._config_file",
  "def update_config(self, name, data):\n        f = self.config_file\n        if name not in f:\n            f.create_dataset(name, data=data)\n        else:\n            dset = f[name]\n            dset[:] = data\n            f.flush()",
  "def read_background(self):\n        \"\"\"Acquire a new spectrum and use it as a background measurement.\"\"\"\n        self.background = self.read_image()\n        self.update_config('background', self.background)",
  "def clear_background(self):\n        \"\"\"Clear the current background reading.\"\"\"\n        self.background = None",
  "def read_reference(self):\n        \"\"\"Acquire a new spectrum and use it as a reference.\"\"\"\n        self.reference = self.read_image()\n        self.update_config('reference', self.reference)",
  "def clear_reference(self):\n        \"\"\"Clear the current reference spectrum\"\"\"\n        self.reference = None",
  "def process_image(self, image):\n        \"\"\"Subtract the background and divide by the reference, if possible\"\"\"\n        if self.background is not None:\n            if self.reference is not None:\n                old_error_settings = np.seterr(all='ignore')\n                new_image = (image - self.background)/(self.reference - self.background)\n                np.seterr(**old_error_settings)\n                # if the reference is nearly 0, we get infinities - just make them all NaNs.\n                new_image[np.isinf(new_image)] = np.nan\n            else:\n                new_image = image - self.background\n        else:\n            new_image = image\n        return new_image",
  "def read_processed_image(self):\n        \"\"\"\n        Acquire a new image and return a processed (referenced/background-subtracted) image.\n\n        NB if saving data to file, it's best to save raw images along with metadata - this is a\n        convenience method for display purposes.\n        \"\"\"\n        image = self.read_image()\n        self.latest_image = self.process_image(image)\n        return self.latest_image",
  "def mask_image(self, image, threshold=0.05):\n        \"\"\"\n        Return a masked array of the image, showing only points where the reference\n        is bright enough to be useful.\n        \"\"\"\n        if self.reference is not None and self.background is not None:\n            reference = self.reference - self.background\n            mask = reference < reference.max() * threshold\n            return ma.array(image, mask=mask)\n        else:\n            return image",
  "class PixisError(Exception):\n    def __init__(self, msg):\n        print(msg)\n        i = pvcam.pl_error_code()\n        msg = ct.create_string_buffer(20)\n        pvcam.pl_error_message(i, msg)\n        print('self.pvcam Error:', i, msg)\n        pvcam.pl_self.pvcam_uninit()",
  "class Pixis256E(CCD,Camera):\n    def __init__(self):\n        super(Pixis256E, self).__init__()\n        try:\n            self.pvcam = PVCAM #ct.windll.pvcam32\n        except WindowsError as e:\n            print('pvcam not found')\n        cam_selection = ct.c_int16()\n        # Initialize the self.pvcam library and open the camera #\n        self.open_lib()\n        self.open_cam(cam_selection)\n        self._sequence_set = False\n        self._current_frame = None\n\n        self.exposure = 50\n        self.timing_mode = 'timed'  # also 'trigger'\n        self.cont_clears = True\n        self.latest_image = None\n        self.latest_raw_image = None\n        self.masked_image = None\n\n        #print 'trying to allocate0', (ct.c_int16 * 10)()\n\n    def __del__(self):\n        print('deleting')\n        if self.cam_open:\n            self.close_cam()\n        self.close_lib()\n\n    def read_image(self, exposure, timing='timed', mode='kinetics', new=True, end=True, *args,\n                   **kwargs):\n        \"\"\"\n        Read an image.\n\n        :param exposure: Exposure time\n        :param timing: 'timed' or 'trigger'\n        :param mode: 'kinetics'\n        :param new: If it is the first sequence in a set then new (True) sets up the sequence\n        :param end: If it is the last sequence in a set then end (True) finishes the sequence\n        :param kwargs: k_size=1\n\n        :return:\n        \"\"\"\n        if new:  # only setup the first time in a set of sequences\n            # setup sequence\n            if mode == 'kinetics':\n                k_size = kwargs['k_size'] if 'k_size' in kwargs else 1\n                self.setup_kinetics(exposure, k_size, timing)\n        self.start_sequence()  # start acquisition\n        while not self.check_readout():  # wait for image\n            continue\n        image = self.readout_image()  # readout\n        if end:  # shutdown sequence if it is the last one\n            self.finish_sequence()\n        return image\n\n    def open_lib(self):\n        if not self.pvcam.pl_pvcam_init():\n            raise PixisError(\"failed to init self.pvcam\")\n        else:\n            print('init self.pvcam complete')\n\n    def close_lib(self):\n        self.pvcam.pl_pvcam_uninit()\n        print(\"pvcam closed\")\n\n    def open_cam(self, cam_selection):\n        cam_name = ct.create_string_buffer(20)\n        self._handle = ct.c_int16()\n        if not self.pvcam.pl_cam_get_name(cam_selection, cam_name):\n            raise PixisError(\"didn't get cam name\")\n        if not self.pvcam.pl_cam_open(cam_name, ct.byref(self._handle), pv.OPEN_EXCLUSIVE):\n            raise PixisError(\"camera didn't open\")\n        self.cam_open = True\n\n    def close_cam(self):\n        if self._sequence_set:\n            self.finish_sequence()\n        self.pvcam.pl_cam_close(self._handle)\n        self.cam_open = False\n        print('cam closed')\n\n    def set_any_param(self, param_id, param_value):\n        b_status = ct.c_bool()\n        b_param = ct.c_bool()\n        param_access = ct.c_uint16()\n        param_id = ct.c_uint32(param_id)\n\n        if not isinstance(param_value, ct._SimpleCData):\n            raise TypeError(\"The parameter value must be passed as a ctypes instance, not a python value.\")\n\n        b_status = self.pvcam.pl_get_param(self._handle, param_id,\n                                      pv.ATTR_AVAIL, ct.cast(ct.byref(b_param), ct.c_void_p))\n        if b_param:\n            b_status = self.pvcam.pl_get_param(self._handle, param_id,\n                                          pv.ATTR_ACCESS,\n                                          ct.cast(ct.byref(param_access), ct.c_void_p))\n\n            if param_access.value == pv.ACC_READ_WRITE or param_access.value == pv.ACC_WRITE_ONLY:\n                if not self.pvcam.pl_set_param(self._handle, param_id,\n                                          ct.cast(ct.byref(param_value), ct.c_void_p)):\n                    print(\"error: param %d (value = %d) did not get set\" % (\n                    param_id.value, param_value.value))\n                    return False\n            else:\n                print(\"error: param %d is not writable: %s\" % (param_id.value, param_access.value))\n                return False\n        else:\n            print(\"error: param %d is not available\" % param_id.value)\n            return False\n        return True\n\n    def get_any_param(self, param_id):\n        pass\n\n    def set_full_frame(self, region):\n        ser_size = ct.c_uint16()\n        self.pvcam.pl_get_param(self._handle, pv.PARAM_SER_SIZE,\n                           pv.ATTR_DEFAULT, ct.cast(ct.byref(ser_size), ct.c_void_p))\n        par_size = ct.c_uint16()\n        self.pvcam.pl_get_param(self._handle, pv.PARAM_PAR_SIZE,\n                           pv.ATTR_DEFAULT, ct.cast(ct.byref(par_size), ct.c_void_p))\n        region.s1, region.s2, region.p1, region.p2 = (0, ser_size.value - 1,\n                                                      0, par_size.value - 1)\n        region.sbin, region.pbin = (1, 1)\n\n    def setup_kinetics(self, exposure, k_size, timing='trigger'):\n        if self._sequence_set:  # uninitialise all previous sequences\n            self.finish_sequence()\n\n        params = {\n            pv.PARAM_PMODE: (ct.c_uint32(pv.PMODE_KINETICS), 'pmode'),\n            pv.PARAM_KIN_WIN_SIZE: (ct.c_uint16(k_size), 'kinetics window size'),\n            pv.PARAM_PAR_SHIFT_TIME: (ct.c_uint32(9200), 'parallel shift time'),\n            # pv.PARAM_SER_SHIFT_TIME : (ct.c_uint32(9200), 'serial shift time'),\n            pv.PARAM_EXP_RES_INDEX: (ct.c_uint16(pv.EXP_RES_ONE_MICROSEC), 'exposure resolution'),\n            pv.PARAM_CLEAR_CYCLES: (ct.c_uint16(1), 'clear cycles'),\n            pv.PARAM_NUM_OF_STRIPS_PER_CLR: (ct.c_uint16(1), 'number of clear strips'),\n            pv.PARAM_SHTR_OPEN_MODE: (ct.c_uint16(pv.OPEN_PRE_SEQUENCE), 'shutter open mode'),\n            pv.PARAM_EDGE_TRIGGER: (ct.c_uint32(pv.EDGE_TRIG_POS), 'edge trigger'),\n            pv.PARAM_GAIN_INDEX: (ct.c_uint16(3), 'gain index'),\n            # pv.PARAM_CONT_CLEARS : (ct.c_bool(True), 'continuous clears 1'),\n        }\n        for p in params:\n            status = self.set_any_param(p, params[p][0])\n            if not status: print('problem with %s' % params[p][1])\n\n        read_params = [\n            pv.PARAM_PIX_TIME,\n        ]\n        for p in read_params:\n            self.get_any_param(p)\n\n        if not self.pvcam.pl_exp_init_seq():\n            raise PixisError(\"init_seq failed!\")\n\n        exp_time = ct.c_uint32(exposure)\n        size = ct.c_uint32()\n        region = pv.rgn_type()\n        self.set_full_frame(region)\n\n        if timing == 'trigger':\n            timing_mode = pv.TRIGGER_FIRST_MODE\n        elif timing == 'timed':\n            timing_mode = pv.TIMED_MODE\n        if self.pvcam.pl_exp_setup_seq(self._handle, 1, 1, ct.byref(region),\n                                  timing_mode, exp_time, ct.byref(size)):\n            # print \"frame size = %d\" % size.value\n            pass\n        else:\n            raise PixisError(\"experiment setup failed!\")\n        self._sequence_set = True\n        self.exposure = exposure\n        self.size = size\n        self.timing = timing\n\n        if timing == 'trigger':\n            # status = self.set_any_param(pv.PARAM_CLEAR_MODE, ct.c_uint16(pv.CLEAR_PRE_SEQUENCE))\n            # if not status: print 'problem with clear mode'\n            status = self.set_any_param(pv.PARAM_CONT_CLEARS, ct.c_bool(self.cont_clears))\n            if not status:\n                print('problem with continuous cleans 2')\n            # status = self.set_any_param(pv.PARAM_CLN_WHILE_EXPO, ct.c_uint16(1))\n            # if not status: print 'problem with clear while exposing'\n\n            # frame = (ct.c_uint16 * (self.size.value//2))()\n            # self.pvcam.pl_exp_start_seq(self._handle, frame)\n            # self._current_frame = frame\n\n    def start_sequence(self):\n        \"\"\"\n        Create a frame and start the kinetics exposure sequence. Call this method\n        after setting up the trigger and then wait until check_kinetics confirms\n        readout.\n        \"\"\"\n        frame = (ct.c_uint16 * (self.size.value // 2))()\n        self.pvcam.pl_exp_start_seq(self._handle, frame)\n        self._current_frame = frame\n\n    def check_readout(self):\n        \"\"\"\n        Poll the readout status and return if the readout is complete or if it\n        fails.\n        \"\"\"\n        status = ct.c_int16()\n        self.pvcam.pl_exp_check_status(self._handle, ct.byref(status),\n                                  ct.byref(ct.c_int32()))\n        if status.value == pv.READOUT_FAILED:\n            raise PixisError(\"Data collection error\")\n        elif status.value == pv.READOUT_COMPLETE:\n            return True\n        else:\n            return False\n\n    def readout_image(self):\n        \"\"\"If the readout is complete a valid frame is returned.\"\"\"\n        return np.array(list(self._current_frame)).reshape((256, 1024))\n\n    def finish_sequence(self):\n        self.pvcam.pl_exp_finish_seq(self._handle, self._current_frame, 0)\n        self.pvcam.pl_exp_uninit_seq()\n        self._sequence_set = False\n\n    metadata_property_names = ('exposure',)\n\n    def read_background(self):\n        \"\"\"Acquire a new spectrum and use it as a background measurement.\"\"\"\n        self.background = self.read_image(self.exposure, self.timing, self.mode,\n                                          new=True, end=True)\n        self.update_config('background', self.background)\n\n    def read_reference(self):\n        \"\"\"Acquire a new spectrum and use it as a reference.\"\"\"\n        self.reference = self.read_image(self.exposure, self.timing, self.mode,\n                                         new=True, end=True)\n        self.update_config('reference', self.reference)\n    \n    def raw_snapshot(self):\n        try:\n            image = self.read_image(self.exposure, timing='timed', mode='kinetics', new=False, end= True, k_size=1)\n            return 1, image\n        except Exception as e:\n            self._logger.warn(\"Couldn't Capture because %s\" % e)",
  "class Pixis256EQt(Pixis256E, QtCore.QObject):\n    \"\"\"Pixis256E subclass with Qt signals for GUI interaction.\"\"\"\n\n    image_taken = QtCore.Signal(np.ndarray)\n\n    @inherit_docstring(Pixis256E.__init__)\n    def __init__(self):\n        super(Pixis256EQt, self).__init__()\n\n    @inherit_docstring(Pixis256E.read_image)\n    def read_image(self, exposure, timing='timed', mode='kinetics', new=True, end=True, *args,\n                   **kwargs):\n        image = super(Pixis256EQt, self).read_image(exposure, timing='timed', mode='kinetics',\n                                                    new=True, end=True, *args, **kwargs)\n        self.image_taken.emit(image)\n        return image",
  "class Pixis256EUI(QtWidgets.QWidget, UiTools):\n    def __init__(self, pixis):\n        if not isinstance(pixis, Pixis256EQt):\n            raise TypeError('pixis is not an instance of Pixis256EQt')\n        super(Pixis256EUI, self).__init__()\n        self.pixis = pixis\n\n        # self.exposure.setValidator(QtWidgets.QIntValidator())\n        # self.exposure.textChanged.connect(self.check_state)\n        # self.exposure.textChanged.connect(self.on_text_change)\n        # self.mode.activated.connect(self.on_activated)\n        # self.timing.activated.connect(self.on_activated)\n        # self.cont_clears.stateChanged.connect(self.on_state_change)\n        # self.take_image_button.clicked.connect(self.on_click)\n        # self.take_bkgd_button.clicked.connect(self.on_click)\n        # self.clear_bkgd_button.clicked.connect(self.on_click)\n        # self.take_ref_button.clicked.connect(self.on_click)\n        # self.clear_ref_button.clicked.connect(self.on_click)\n\n        # self.pixis.image_taken.connect()\n\n    def on_text_change(self, text):\n        sender = super(Pixis256EUI, self).on_text_change(text)\n        if sender == False:\n            return\n        elif sender == self.exposure:\n            self.pixis.exposure = float(sender)\n\n    def on_click(self):\n        sender = self.sender()\n        if sender == self.take_image_button:\n            self.pixis.read_image(self.pixis.exposure, self.pixis.timing, self.pixis.mode,\n                                  new=True, end=True)\n        elif sender == self.take_bkgd_button:\n            self.pixis.read_background()\n        elif sender == self.clear_bkgd_button:\n            self.pixis.clear_background()\n        elif sender == self.take_ref_button:\n            self.pixis.read_reference()\n        elif sender == self.clear_ref_button:\n            self.pixis.clear_reference()\n\n    def on_activated(self, item):\n        sender = self.sender()\n        if sender == self.mode:\n            self.pixis.mode = item\n        elif sender == self.timing:\n            self.pixis.timing = item\n\n    def on_state_change(self, state):\n        sender = self.sender()\n        if sender == self.cont_clears:\n            if state == QtCore.Qt.Checked:\n                self.pixis.cont_clears = True\n            elif state == QtCore.Qt.Unchecked:\n                self.pixis.cont_clears = False",
  "def __init__(self, msg):\n        print(msg)\n        i = pvcam.pl_error_code()\n        msg = ct.create_string_buffer(20)\n        pvcam.pl_error_message(i, msg)\n        print('self.pvcam Error:', i, msg)\n        pvcam.pl_self.pvcam_uninit()",
  "def __init__(self):\n        super(Pixis256E, self).__init__()\n        try:\n            self.pvcam = PVCAM #ct.windll.pvcam32\n        except WindowsError as e:\n            print('pvcam not found')\n        cam_selection = ct.c_int16()\n        # Initialize the self.pvcam library and open the camera #\n        self.open_lib()\n        self.open_cam(cam_selection)\n        self._sequence_set = False\n        self._current_frame = None\n\n        self.exposure = 50\n        self.timing_mode = 'timed'  # also 'trigger'\n        self.cont_clears = True\n        self.latest_image = None\n        self.latest_raw_image = None\n        self.masked_image = None",
  "def __del__(self):\n        print('deleting')\n        if self.cam_open:\n            self.close_cam()\n        self.close_lib()",
  "def read_image(self, exposure, timing='timed', mode='kinetics', new=True, end=True, *args,\n                   **kwargs):\n        \"\"\"\n        Read an image.\n\n        :param exposure: Exposure time\n        :param timing: 'timed' or 'trigger'\n        :param mode: 'kinetics'\n        :param new: If it is the first sequence in a set then new (True) sets up the sequence\n        :param end: If it is the last sequence in a set then end (True) finishes the sequence\n        :param kwargs: k_size=1\n\n        :return:\n        \"\"\"\n        if new:  # only setup the first time in a set of sequences\n            # setup sequence\n            if mode == 'kinetics':\n                k_size = kwargs['k_size'] if 'k_size' in kwargs else 1\n                self.setup_kinetics(exposure, k_size, timing)\n        self.start_sequence()  # start acquisition\n        while not self.check_readout():  # wait for image\n            continue\n        image = self.readout_image()  # readout\n        if end:  # shutdown sequence if it is the last one\n            self.finish_sequence()\n        return image",
  "def open_lib(self):\n        if not self.pvcam.pl_pvcam_init():\n            raise PixisError(\"failed to init self.pvcam\")\n        else:\n            print('init self.pvcam complete')",
  "def close_lib(self):\n        self.pvcam.pl_pvcam_uninit()\n        print(\"pvcam closed\")",
  "def open_cam(self, cam_selection):\n        cam_name = ct.create_string_buffer(20)\n        self._handle = ct.c_int16()\n        if not self.pvcam.pl_cam_get_name(cam_selection, cam_name):\n            raise PixisError(\"didn't get cam name\")\n        if not self.pvcam.pl_cam_open(cam_name, ct.byref(self._handle), pv.OPEN_EXCLUSIVE):\n            raise PixisError(\"camera didn't open\")\n        self.cam_open = True",
  "def close_cam(self):\n        if self._sequence_set:\n            self.finish_sequence()\n        self.pvcam.pl_cam_close(self._handle)\n        self.cam_open = False\n        print('cam closed')",
  "def set_any_param(self, param_id, param_value):\n        b_status = ct.c_bool()\n        b_param = ct.c_bool()\n        param_access = ct.c_uint16()\n        param_id = ct.c_uint32(param_id)\n\n        if not isinstance(param_value, ct._SimpleCData):\n            raise TypeError(\"The parameter value must be passed as a ctypes instance, not a python value.\")\n\n        b_status = self.pvcam.pl_get_param(self._handle, param_id,\n                                      pv.ATTR_AVAIL, ct.cast(ct.byref(b_param), ct.c_void_p))\n        if b_param:\n            b_status = self.pvcam.pl_get_param(self._handle, param_id,\n                                          pv.ATTR_ACCESS,\n                                          ct.cast(ct.byref(param_access), ct.c_void_p))\n\n            if param_access.value == pv.ACC_READ_WRITE or param_access.value == pv.ACC_WRITE_ONLY:\n                if not self.pvcam.pl_set_param(self._handle, param_id,\n                                          ct.cast(ct.byref(param_value), ct.c_void_p)):\n                    print(\"error: param %d (value = %d) did not get set\" % (\n                    param_id.value, param_value.value))\n                    return False\n            else:\n                print(\"error: param %d is not writable: %s\" % (param_id.value, param_access.value))\n                return False\n        else:\n            print(\"error: param %d is not available\" % param_id.value)\n            return False\n        return True",
  "def get_any_param(self, param_id):\n        pass",
  "def set_full_frame(self, region):\n        ser_size = ct.c_uint16()\n        self.pvcam.pl_get_param(self._handle, pv.PARAM_SER_SIZE,\n                           pv.ATTR_DEFAULT, ct.cast(ct.byref(ser_size), ct.c_void_p))\n        par_size = ct.c_uint16()\n        self.pvcam.pl_get_param(self._handle, pv.PARAM_PAR_SIZE,\n                           pv.ATTR_DEFAULT, ct.cast(ct.byref(par_size), ct.c_void_p))\n        region.s1, region.s2, region.p1, region.p2 = (0, ser_size.value - 1,\n                                                      0, par_size.value - 1)\n        region.sbin, region.pbin = (1, 1)",
  "def setup_kinetics(self, exposure, k_size, timing='trigger'):\n        if self._sequence_set:  # uninitialise all previous sequences\n            self.finish_sequence()\n\n        params = {\n            pv.PARAM_PMODE: (ct.c_uint32(pv.PMODE_KINETICS), 'pmode'),\n            pv.PARAM_KIN_WIN_SIZE: (ct.c_uint16(k_size), 'kinetics window size'),\n            pv.PARAM_PAR_SHIFT_TIME: (ct.c_uint32(9200), 'parallel shift time'),\n            # pv.PARAM_SER_SHIFT_TIME : (ct.c_uint32(9200), 'serial shift time'),\n            pv.PARAM_EXP_RES_INDEX: (ct.c_uint16(pv.EXP_RES_ONE_MICROSEC), 'exposure resolution'),\n            pv.PARAM_CLEAR_CYCLES: (ct.c_uint16(1), 'clear cycles'),\n            pv.PARAM_NUM_OF_STRIPS_PER_CLR: (ct.c_uint16(1), 'number of clear strips'),\n            pv.PARAM_SHTR_OPEN_MODE: (ct.c_uint16(pv.OPEN_PRE_SEQUENCE), 'shutter open mode'),\n            pv.PARAM_EDGE_TRIGGER: (ct.c_uint32(pv.EDGE_TRIG_POS), 'edge trigger'),\n            pv.PARAM_GAIN_INDEX: (ct.c_uint16(3), 'gain index'),\n            # pv.PARAM_CONT_CLEARS : (ct.c_bool(True), 'continuous clears 1'),\n        }\n        for p in params:\n            status = self.set_any_param(p, params[p][0])\n            if not status: print('problem with %s' % params[p][1])\n\n        read_params = [\n            pv.PARAM_PIX_TIME,\n        ]\n        for p in read_params:\n            self.get_any_param(p)\n\n        if not self.pvcam.pl_exp_init_seq():\n            raise PixisError(\"init_seq failed!\")\n\n        exp_time = ct.c_uint32(exposure)\n        size = ct.c_uint32()\n        region = pv.rgn_type()\n        self.set_full_frame(region)\n\n        if timing == 'trigger':\n            timing_mode = pv.TRIGGER_FIRST_MODE\n        elif timing == 'timed':\n            timing_mode = pv.TIMED_MODE\n        if self.pvcam.pl_exp_setup_seq(self._handle, 1, 1, ct.byref(region),\n                                  timing_mode, exp_time, ct.byref(size)):\n            # print \"frame size = %d\" % size.value\n            pass\n        else:\n            raise PixisError(\"experiment setup failed!\")\n        self._sequence_set = True\n        self.exposure = exposure\n        self.size = size\n        self.timing = timing\n\n        if timing == 'trigger':\n            # status = self.set_any_param(pv.PARAM_CLEAR_MODE, ct.c_uint16(pv.CLEAR_PRE_SEQUENCE))\n            # if not status: print 'problem with clear mode'\n            status = self.set_any_param(pv.PARAM_CONT_CLEARS, ct.c_bool(self.cont_clears))\n            if not status:\n                print('problem with continuous cleans 2')",
  "def start_sequence(self):\n        \"\"\"\n        Create a frame and start the kinetics exposure sequence. Call this method\n        after setting up the trigger and then wait until check_kinetics confirms\n        readout.\n        \"\"\"\n        frame = (ct.c_uint16 * (self.size.value // 2))()\n        self.pvcam.pl_exp_start_seq(self._handle, frame)\n        self._current_frame = frame",
  "def check_readout(self):\n        \"\"\"\n        Poll the readout status and return if the readout is complete or if it\n        fails.\n        \"\"\"\n        status = ct.c_int16()\n        self.pvcam.pl_exp_check_status(self._handle, ct.byref(status),\n                                  ct.byref(ct.c_int32()))\n        if status.value == pv.READOUT_FAILED:\n            raise PixisError(\"Data collection error\")\n        elif status.value == pv.READOUT_COMPLETE:\n            return True\n        else:\n            return False",
  "def readout_image(self):\n        \"\"\"If the readout is complete a valid frame is returned.\"\"\"\n        return np.array(list(self._current_frame)).reshape((256, 1024))",
  "def finish_sequence(self):\n        self.pvcam.pl_exp_finish_seq(self._handle, self._current_frame, 0)\n        self.pvcam.pl_exp_uninit_seq()\n        self._sequence_set = False",
  "def read_background(self):\n        \"\"\"Acquire a new spectrum and use it as a background measurement.\"\"\"\n        self.background = self.read_image(self.exposure, self.timing, self.mode,\n                                          new=True, end=True)\n        self.update_config('background', self.background)",
  "def read_reference(self):\n        \"\"\"Acquire a new spectrum and use it as a reference.\"\"\"\n        self.reference = self.read_image(self.exposure, self.timing, self.mode,\n                                         new=True, end=True)\n        self.update_config('reference', self.reference)",
  "def raw_snapshot(self):\n        try:\n            image = self.read_image(self.exposure, timing='timed', mode='kinetics', new=False, end= True, k_size=1)\n            return 1, image\n        except Exception as e:\n            self._logger.warn(\"Couldn't Capture because %s\" % e)",
  "def __init__(self):\n        super(Pixis256EQt, self).__init__()",
  "def read_image(self, exposure, timing='timed', mode='kinetics', new=True, end=True, *args,\n                   **kwargs):\n        image = super(Pixis256EQt, self).read_image(exposure, timing='timed', mode='kinetics',\n                                                    new=True, end=True, *args, **kwargs)\n        self.image_taken.emit(image)\n        return image",
  "def __init__(self, pixis):\n        if not isinstance(pixis, Pixis256EQt):\n            raise TypeError('pixis is not an instance of Pixis256EQt')\n        super(Pixis256EUI, self).__init__()\n        self.pixis = pixis",
  "def on_text_change(self, text):\n        sender = super(Pixis256EUI, self).on_text_change(text)\n        if sender == False:\n            return\n        elif sender == self.exposure:\n            self.pixis.exposure = float(sender)",
  "def on_click(self):\n        sender = self.sender()\n        if sender == self.take_image_button:\n            self.pixis.read_image(self.pixis.exposure, self.pixis.timing, self.pixis.mode,\n                                  new=True, end=True)\n        elif sender == self.take_bkgd_button:\n            self.pixis.read_background()\n        elif sender == self.clear_bkgd_button:\n            self.pixis.clear_background()\n        elif sender == self.take_ref_button:\n            self.pixis.read_reference()\n        elif sender == self.clear_ref_button:\n            self.pixis.clear_reference()",
  "def on_activated(self, item):\n        sender = self.sender()\n        if sender == self.mode:\n            self.pixis.mode = item\n        elif sender == self.timing:\n            self.pixis.timing = item",
  "def on_state_change(self, state):\n        sender = self.sender()\n        if sender == self.cont_clears:\n            if state == QtCore.Qt.Checked:\n                self.pixis.cont_clears = True\n            elif state == QtCore.Qt.Unchecked:\n                self.pixis.cont_clears = False",
  "def test():\n        p.setup_kinetics(p.exposure, 1)\n        print(p.check_readout())\n        imgs = []\n        print('ready')\n        shots = 3\n        for i in range(shots):\n            print('shot {0}'.format(i+1))\n            p.start_sequence()\n            time.sleep(0.1)\n            while not (p.check_readout()): continue\n            print(\"triggered\")\n            img = p.readout_image()\n            imgs.append(img)\n        p.finish_sequence()\n        time.sleep(0.1)\n        img = p.read_image(p.exposure, timing='timed', mode='kinetics', k_size=1)\n        imgs.append(img)\n        #p.close_cam()\n        print('finished')\n\n        print('plotting data')\n        fig, axes = plt.subplots(shots+1, sharex=True)\n        for i, ax in enumerate(axes):\n            img = ax.imshow(imgs[i])\n        print('done')\n        plt.show()",
  "class OxfordITC(VisaInstrument, TemperatureControlMixin):\n    def __init__(self, address, **kwargs):\n        TemperatureControlMixin.__init__(self)\n        if 'GPIB' in address:\n            VisaInstrument.__init__(self, address, settings=dict(timeout=10000, read_termination='\\r',\n                                                                 write_termination='\\r'))\n        else:\n            VisaInstrument.__init__(self, address, settings=dict(baud_rate=9600, read_termination='\\r',\n                                                                 write_termination='\\r', timeout=1000))\n\n        self.setControlMode(3)\n\n        self.params = {'T': 0, 'SetT': 0, 'PID': [0, 0, 0]}\n        self.flush_input_buffer()\n        self.clear_read_buffer()\n        self.get_temperature()\n        self.get_target_temperature()\n\n    def __del__(self):\n        try:\n            self.heaterOff()\n            self.setControlMode(0)\n            self.instr.close()\n        except:\n            self._logger.warn(\"Couldn't close %s on port %s\" %(self.__name__, self._address))\n\n    def get_temperature(self):\n        temp = self.query('R1', delay=1)\n        temp = float(temp[1:len(temp)])  # Remove the first character ('R')\n\n        self.params['T'] = temp\n\n        return temp\n\n    def setControlMode(self, mode):\n        \"\"\"\n        Sets the operation mode (local or remote)\n        :param mode:\n            0 LOCAL & LOCKED (Default State),\n            1 REMOTE & LOCKED (Front Panel Disabled),\n            2 LOCAL & UNLOCKED,\n            3 REMOTE & UNLOCKED (Front Panel Active)\n        :return:\n        \"\"\"\n        if (mode not in [0, 1, 2, 3]):\n            raise Exception('valid modes are 0-3, see documentation')\n        self.write('C' + str(mode))\n\n    def get_target_temperature(self):\n        temp = self.query('R0')\n        temp = float(temp[1:len(temp)])  # Remove the first character ('R')\n\n        self.params['SetT'] = temp\n\n        return temp\n\n    def set_target_temperature(self, temp):\n        \"\"\"\n        Sets the set temperature\n        :param temp: Temperature in Kelvin (int)\n        :return:\n        \"\"\"\n        self.params['SetT'] = temp\n\n        self.write('T' + str(int(temp)))\n\n    def setHeaterMode(self, mode):\n        \"\"\"\n        Sets the heater mode (auto, manual)\n        :param mode:\n            0 HEATER MANUAL - GAS MANUAL,\n            1 HEATER AUTO - GAS MANUAL,\n            2 HEATER MANUAL - GAS AUTO,\n            3 HEATER AUTO - GAS AUTO\n        :return:\n        \"\"\"\n        if (mode not in [0, 1, 2, 3]):\n            raise Exception('valid modes are 0-3, see documentation')\n        self.write('A' + str(mode))\n\n        self.params['Heater'] = mode\n\n    def setHeaterPower(self, power):\n        self.params['HeaterPower'] = power\n        self.write('O' + str(int(power)))\n\n    def heaterOff(self):\n        self.setHeaterMode(0)\n        self.setHeaterPower(0)\n\n    def setAutoPID(self, mode):\n        \"\"\"\n        Sets the PID mode (auto or manual)\n        :param mode:\n            0 disable auto-PID,\n            1 enable auto-PID\n        :return:\n        \"\"\"\n        if (mode not in [0, 1]):\n            raise Exception('valid modes are 0 (off) or 1 (on)')\n        self.write('L' + str(mode))\n\n        self.params['autoPID'] = mode\n\n    def setPID(self, P, I, D):\n        \"\"\"\n        Sets the PID parameters for manual PID control\n        :param P: PROPORTIONAL BAND in Kelvin (resolution 0.001K, ideally 5 to 50K)\n        :param I: INTEGRAL ACTION TIME in minutes (0 to 140, ideally 1 to 10)\n        :param D: DERIVATIVE ACTION TIME in minutes (0 to 273, can be left at 0)\n        :return:\n        \"\"\"\n        self.write('P' + str(P))\n        self.write('I' + str(I))\n        self.write('D' + str(D))\n\n        self.params['PID'] = [P, I, D]\n\n\n    def get_qt_ui(self):\n        return OxfordITCUI(self)",
  "class OxfordITCUI(QtWidgets.QWidget):\n    updateGUI = QtCore.Signal()\n\n    def __init__(self, itc):\n        assert isinstance(itc, OxfordITC), \"instrument must be an Oxford ITC\"\n        super(OxfordITCUI, self).__init__()\n\n        self.ITC = itc\n\n        uic.loadUi(os.path.join(os.path.dirname(__file__), 'OxfordITC.ui'), self)\n\n        self.lineEditSetT.returnPressed.connect(self.setT)\n\n        self.updateGUI.connect(self.SentUpdateGUI)\n        self.SentUpdateGUI()\n\n    def SentUpdateGUI(self):\n        self.textEditT.setText(str(self.ITC.params['T']))\n        self.lineEditSetT.setText(str(self.ITC.params['SetT']))\n        self.lineEditP.setText(str(self.ITC.params['PID'][0]))\n        self.lineEditI.setText(str(self.ITC.params['PID'][1]))\n        self.lineEditD.setText(str(self.ITC.params['PID'][2]))\n        return\n\n    def setT(self):\n        temp = float(self.lineEditSetT.text())\n        self.ITC.setSetTemperature(temp)",
  "def __init__(self, address, **kwargs):\n        TemperatureControlMixin.__init__(self)\n        if 'GPIB' in address:\n            VisaInstrument.__init__(self, address, settings=dict(timeout=10000, read_termination='\\r',\n                                                                 write_termination='\\r'))\n        else:\n            VisaInstrument.__init__(self, address, settings=dict(baud_rate=9600, read_termination='\\r',\n                                                                 write_termination='\\r', timeout=1000))\n\n        self.setControlMode(3)\n\n        self.params = {'T': 0, 'SetT': 0, 'PID': [0, 0, 0]}\n        self.flush_input_buffer()\n        self.clear_read_buffer()\n        self.get_temperature()\n        self.get_target_temperature()",
  "def __del__(self):\n        try:\n            self.heaterOff()\n            self.setControlMode(0)\n            self.instr.close()\n        except:\n            self._logger.warn(\"Couldn't close %s on port %s\" %(self.__name__, self._address))",
  "def get_temperature(self):\n        temp = self.query('R1', delay=1)\n        temp = float(temp[1:len(temp)])  # Remove the first character ('R')\n\n        self.params['T'] = temp\n\n        return temp",
  "def setControlMode(self, mode):\n        \"\"\"\n        Sets the operation mode (local or remote)\n        :param mode:\n            0 LOCAL & LOCKED (Default State),\n            1 REMOTE & LOCKED (Front Panel Disabled),\n            2 LOCAL & UNLOCKED,\n            3 REMOTE & UNLOCKED (Front Panel Active)\n        :return:\n        \"\"\"\n        if (mode not in [0, 1, 2, 3]):\n            raise Exception('valid modes are 0-3, see documentation')\n        self.write('C' + str(mode))",
  "def get_target_temperature(self):\n        temp = self.query('R0')\n        temp = float(temp[1:len(temp)])  # Remove the first character ('R')\n\n        self.params['SetT'] = temp\n\n        return temp",
  "def set_target_temperature(self, temp):\n        \"\"\"\n        Sets the set temperature\n        :param temp: Temperature in Kelvin (int)\n        :return:\n        \"\"\"\n        self.params['SetT'] = temp\n\n        self.write('T' + str(int(temp)))",
  "def setHeaterMode(self, mode):\n        \"\"\"\n        Sets the heater mode (auto, manual)\n        :param mode:\n            0 HEATER MANUAL - GAS MANUAL,\n            1 HEATER AUTO - GAS MANUAL,\n            2 HEATER MANUAL - GAS AUTO,\n            3 HEATER AUTO - GAS AUTO\n        :return:\n        \"\"\"\n        if (mode not in [0, 1, 2, 3]):\n            raise Exception('valid modes are 0-3, see documentation')\n        self.write('A' + str(mode))\n\n        self.params['Heater'] = mode",
  "def setHeaterPower(self, power):\n        self.params['HeaterPower'] = power\n        self.write('O' + str(int(power)))",
  "def heaterOff(self):\n        self.setHeaterMode(0)\n        self.setHeaterPower(0)",
  "def setAutoPID(self, mode):\n        \"\"\"\n        Sets the PID mode (auto or manual)\n        :param mode:\n            0 disable auto-PID,\n            1 enable auto-PID\n        :return:\n        \"\"\"\n        if (mode not in [0, 1]):\n            raise Exception('valid modes are 0 (off) or 1 (on)')\n        self.write('L' + str(mode))\n\n        self.params['autoPID'] = mode",
  "def setPID(self, P, I, D):\n        \"\"\"\n        Sets the PID parameters for manual PID control\n        :param P: PROPORTIONAL BAND in Kelvin (resolution 0.001K, ideally 5 to 50K)\n        :param I: INTEGRAL ACTION TIME in minutes (0 to 140, ideally 1 to 10)\n        :param D: DERIVATIVE ACTION TIME in minutes (0 to 273, can be left at 0)\n        :return:\n        \"\"\"\n        self.write('P' + str(P))\n        self.write('I' + str(I))\n        self.write('D' + str(D))\n\n        self.params['PID'] = [P, I, D]",
  "def get_qt_ui(self):\n        return OxfordITCUI(self)",
  "def __init__(self, itc):\n        assert isinstance(itc, OxfordITC), \"instrument must be an Oxford ITC\"\n        super(OxfordITCUI, self).__init__()\n\n        self.ITC = itc\n\n        uic.loadUi(os.path.join(os.path.dirname(__file__), 'OxfordITC.ui'), self)\n\n        self.lineEditSetT.returnPressed.connect(self.setT)\n\n        self.updateGUI.connect(self.SentUpdateGUI)\n        self.SentUpdateGUI()",
  "def SentUpdateGUI(self):\n        self.textEditT.setText(str(self.ITC.params['T']))\n        self.lineEditSetT.setText(str(self.ITC.params['SetT']))\n        self.lineEditP.setText(str(self.ITC.params['PID'][0]))\n        self.lineEditI.setText(str(self.ITC.params['PID'][1]))\n        self.lineEditD.setText(str(self.ITC.params['PID'][2]))\n        return",
  "def setT(self):\n        temp = float(self.lineEditSetT.text())\n        self.ITC.setSetTemperature(temp)",
  "class LS331(VisaInstrument, TemperatureControlMixin):\n    \"\"\"https://www.lakeshore.com/ObsoleteAndResearchDocs/331_Manual.pdf\"\"\"\n    def __init__(self, address, **kwargs):\n        super(LS331, self).__init__(address, **kwargs)\n\n    def get_temperature(self):\n        reply = self.query(\"KRDG?\")\n        return float(reply[:-2])\n    temperature = property(fget=get_temperature)",
  "def __init__(self, address, **kwargs):\n        super(LS331, self).__init__(address, **kwargs)",
  "def get_temperature(self):\n        reply = self.query(\"KRDG?\")\n        return float(reply[:-2])",
  "class TemperatureControlMixin():\n    \"\"\"A class representing temperature-control stages.\n\n    This class provides two threads: a temperature control thread that monitors the temperature every second and sends a\n    warning when the temperature is out of range, and a temperature monitoring thread that saves the temperature every\n    second and stores the latest temperatures\n\n    Subclassing Notes\n    -----------------\n    The minimum you need to do in order to subclass this is to override the\n    `get_temperature` method\n    \"\"\"\n    def __init__(self):\n        super(TemperatureControlMixin, self).__init__()\n\n        self._control_thread = None\n        self._controlling = False\n\n    def get_temperature(self):\n        raise NotImplementedError\n    temperature = property(fget=get_temperature)\n\n    def set_target_temperature(self, value):\n        raise NotImplementedError\n\n    def get_target_temperature(self):\n        return\n    target_temperature = property(fset=set_target_temperature, fget=get_target_temperature)\n\n    def monitor_temperature(self, how_long=5, how_often=10, warn_limits=None):\n        \"\"\"Sets a thread to monitor the temperature\n\n        :param int how_long: how long a history to keep, in minutes\n        :param int how_often: how often to add a value to the history, in seconds\n        :param 2-tuple warn_limits: min/max temperature below/above which a warning is raised\n        :return:\n        \"\"\"\n        monitor_property(self, 'temperature', how_long * 60, how_often, warn_limits)\n\n    def control_temperature(self, upper_target=None, lower_target=None):\n        \"\"\"\n        Starts a background thread that checks the temperature is within the stated range. If both range limits are\n        None, and the target_temperature property has not been set, we assume an upper limit of 1000\n\n        :param upper_target: float\n        :param lower_target: float\n        :return:\n        \"\"\"\n        if upper_target is None and lower_target is None:\n            if self.target_temperature is not None:\n                upper_target = self.target_temperature\n            else:\n                upper_target = 1000\n        if self._control_thread is not None:\n            self._controlling = False\n            self._control_thread.join()\n            del self._control_thread\n        self._control_thread = threading.Thread(target=self._control_temperature, args=(upper_target, lower_target))\n        self._controlling = True\n        self._control_thread.start()\n\n    def _control_temperature(self, upper_temp=None, lower_temp=None):\n        while upper_temp > self.temperature > lower_temp:\n            time.sleep(1)\n            if not self._controlling:\n                break\n        self._logger.warn('Temperature out of range')",
  "def __init__(self):\n        super(TemperatureControlMixin, self).__init__()\n\n        self._control_thread = None\n        self._controlling = False",
  "def get_temperature(self):\n        raise NotImplementedError",
  "def set_target_temperature(self, value):\n        raise NotImplementedError",
  "def get_target_temperature(self):\n        return",
  "def monitor_temperature(self, how_long=5, how_often=10, warn_limits=None):\n        \"\"\"Sets a thread to monitor the temperature\n\n        :param int how_long: how long a history to keep, in minutes\n        :param int how_often: how often to add a value to the history, in seconds\n        :param 2-tuple warn_limits: min/max temperature below/above which a warning is raised\n        :return:\n        \"\"\"\n        monitor_property(self, 'temperature', how_long * 60, how_often, warn_limits)",
  "def control_temperature(self, upper_target=None, lower_target=None):\n        \"\"\"\n        Starts a background thread that checks the temperature is within the stated range. If both range limits are\n        None, and the target_temperature property has not been set, we assume an upper limit of 1000\n\n        :param upper_target: float\n        :param lower_target: float\n        :return:\n        \"\"\"\n        if upper_target is None and lower_target is None:\n            if self.target_temperature is not None:\n                upper_target = self.target_temperature\n            else:\n                upper_target = 1000\n        if self._control_thread is not None:\n            self._controlling = False\n            self._control_thread.join()\n            del self._control_thread\n        self._control_thread = threading.Thread(target=self._control_temperature, args=(upper_target, lower_target))\n        self._controlling = True\n        self._control_thread.start()",
  "def _control_temperature(self, upper_temp=None, lower_temp=None):\n        while upper_temp > self.temperature > lower_temp:\n            time.sleep(1)\n            if not self._controlling:\n                break\n        self._logger.warn('Temperature out of range')",
  "def wavelength_to_rgb(wavelength, gamma=0.8):\n\n    '''This converts a given wavelength of light to an \n    approximate RGB color value. The wavelength must be given\n    in nanometers in the range from 380 nm through 750 nm\n    (789 THz through 400 THz).\n\n    Based on code by Dan Bruton\n    http://www.physics.sfasu.edu/astro/color/spectra.html\n    \n    Copied from: http://www.noah.org/wiki/Wavelength_to_RGB_in_Python\n    '''\n\n    wavelength = float(wavelength)\n    if wavelength >= 380 and wavelength <= 440:\n        attenuation = 0.3 + old_div(0.7 * (wavelength - 380), (440 - 380))\n        R = ((old_div(-(wavelength - 440), (440 - 380))) * attenuation) ** gamma\n        G = 0.0\n        B = (1.0 * attenuation) ** gamma\n    elif wavelength >= 440 and wavelength <= 490:\n        R = 0.0\n        G = (old_div((wavelength - 440), (490 - 440))) ** gamma\n        B = 1.0\n    elif wavelength >= 490 and wavelength <= 510:\n        R = 0.0\n        G = 1.0\n        B = (old_div(-(wavelength - 510), (510 - 490))) ** gamma\n    elif wavelength >= 510 and wavelength <= 580:\n        R = (old_div((wavelength - 510), (580 - 510))) ** gamma\n        G = 1.0\n        B = 0.0\n    elif wavelength >= 580 and wavelength <= 645:\n        R = 1.0\n        G = (old_div(-(wavelength - 645), (645 - 580))) ** gamma\n        B = 0.0\n    elif wavelength >= 645 and wavelength <= 750:\n        attenuation = 0.3 + old_div(0.7 * (750 - wavelength), (750 - 645))\n        R = (1.0 * attenuation) ** gamma\n        G = 0.0\n        B = 0.0\n    else:\n        R = 0.0\n        G = 0.0\n        B = 0.0\n    R *= 255\n    G *= 255\n    B *= 255\n    return (int(R), int(G), int(B))",
  "def Lentz_Dn(z, N):\n    \"\"\" Compute the logarithmic derivative of the Ricatti-Bessel function\n        This returns the Ricatti-Bessel function of order N with argument z\n        using the continued fraction technique of Lentz, Appl. Opt., 15,\n        668-671, (1976).\n    \"\"\"\n    zinv     =  2.0/z\n    alpha    =  (N+0.5) * zinv\n    aj       = -(N+1.5) * zinv\n    alpha_j1 = aj+1/alpha\n    alpha_j2 = aj\n    ratio    = alpha_j1/alpha_j2\n    runratio = alpha*ratio\n\n    while abs(abs(ratio)-1.0) > 1e-12:\n        aj = zinv - aj\n        alpha_j1 = 1.0/alpha_j1 + aj\n        alpha_j2 = 1.0/alpha_j2 + aj\n        ratio = alpha_j1/alpha_j2\n        zinv  *= -1\n        runratio = ratio*runratio\n\n    return -N/z+runratio",
  "def D_downwards(z, N):\n    \"\"\" Compute the logarithmic derivative of all Ricatti-Bessel functions\n        This returns the Ricatti-Bessel function of orders 0 to N for an\n        argument z using the downwards recurrence relations.\n    \"\"\"\n    D = np.zeros(N, dtype=complex)\n    last_D = Lentz_Dn(z, N)\n    for n in range(N, 0, -1):\n        last_D =  n/z - 1.0/(last_D+n/z)\n        D[n-1] = last_D\n    return D",
  "def D_upwards(z, N):\n    \"\"\" Compute the logarithmic derivative of all Ricatti-Bessel functions\n        This returns the Ricatti-Bessel function of orders 0 to N for an\n        argument z using the upwards recurrence relations.\n    \"\"\"\n    D = np.zeros(N, dtype=complex)\n    exp = np.exp(-2j*z)\n    D[1] = -1/z + (1-exp)/((1-exp)/z-1j*(1+exp))\n    for n in range(2, N):\n        D[n] = 1/(n/z-D[n-1])-n/z\n    return D",
  "def D_calc(m, x, N):\n    \"\"\" Compute the logarithmic derivative of the Ricatti-Bessel function at all\n        orders (from 0 to N) with argument z\n    \"\"\"\n    z = m * x\n    if abs(z.imag) > 13.78*m.real**2 - 10.8*m.real + 3.9:\n        return D_upwards(z, N)\n    else:\n        return D_downwards(z, N)",
  "def calculate_a_b_coefficients(m,x,n_max):\n    n = 2*n_max\n\n    def psi(rho):\n        outp, _ =riccati_jn(n,rho) \n        return outp \n    def dpsi(rho):\n        _,outp = riccati_jn(n,rho)\n        return outp\n    #Definition:\n    #Hankel function of first kind: \n    # Hn = Jn + iYn\n    # Jn - bessel function of first kind\n    # Yn - bessel function of second kind\n    def eps(rho):\n        jn = riccati_jn(n,rho)[0]\n        yn = riccati_yn(n,rho)[0] \n        hn = jn + 1j*yn\n        return hn\n\n    def deps(rho):\n        d_jn = riccati_jn(n,rho)[1]\n        d_yn = riccati_yn(n,rho)[1] \n        d_hn = d_jn + 1j*d_yn\n        return d_hn\n\n    rho = m*x\n          \n    def a():\n        num = m*psi(m*x)*dpsi(x) - psi(x)*dpsi(m*x)\n        denom = m*psi(m*x)*deps(x) - eps(x)*dpsi(m*x)\n        return (num/denom)[0:n]\n\n    def b():\n        num = psi(m*x)*dpsi(x) - m*psi(x)*dpsi(m*x)\n        denom = psi(m*x)*deps(x) - m*eps(x)*dpsi(m*x)\n        return (num/denom)[0:n]\n    return a(), b()",
  "def Mie_ab(m,x,n_max):\n    #  http://pymiescatt.readthedocs.io/en/latest/forward.html#Mie_ab\n    mx = m*x\n    nmax = np.real(np.round(2+x+4*(x**(1/3))))\n    nmx = np.round(max(nmax,np.abs(mx))+16)\n    # print \"NMAX:\", nmax\n    n = np.arange(1,np.real(nmax)+1)\n    nu = n + 0.5\n\n    sx = np.sqrt(0.5*np.pi*x)\n    px = sx*jv(nu,x)\n\n    p1x = np.append(np.sin(x), px[0:int(nmax)-1])\n    chx = -sx*yv(nu,x)\n\n    ch1x = np.append(np.cos(x), chx[0:int(nmax)-1])\n    gsx = px-(0+1j)*chx\n    gs1x = p1x-(0+1j)*ch1x\n\n    # B&H Equation 4.89\n    Dn = np.zeros(int(nmx),dtype=complex)\n    for i in range(int(nmx)-1,1,-1):\n        Dn[i-1] = (i/mx)-(1/(Dn[i]+i/mx))\n\n    D = Dn[1:int(nmax)+1] # Dn(mx), drop terms beyond nMax\n    da = D/m+n/x\n    db = m*D+n/x\n\n    an = (da*px-p1x)/(da*gsx-gs1x)\n    bn = (db*px-p1x)/(db*gsx-gs1x)\n\n    return an, bn",
  "def make_rescaled_parameters(n_med,n_particle,r,wavelength):\n #    :param r: radius of the sphere\n #    :param wavelength: wavelength of illumination\n #    :param n_sph: complex refractive index of the sphere\n #    :param n_med: real refractive index of the dielectric medium\n    x=  n_med * (2*np.pi/wavelength) * r\n    m = n_particle/n_med\n    return x,m",
  "def calculate_pi_tau(mu,n_max):\n    #calculates angle-dependent functions\n    #see Absorption and scattering by small particles, Bohren & Huffman, page 94\n    pi_n = np.zeros(n_max+1)\n    tau_n = np.zeros(n_max+1)\n    pi_n[1] = 1.0\n    tau_n[1] = mu*pi_n[1]\n\n    for n in range(2,n_max):\n        pi_n[n] = ((2.0*n-1)/(n-1))*mu*pi_n[n-1] - ((n)/(n-1))*pi_n[n-2]\n        tau_n[n] = n*mu*pi_n[n] - (n+1)*pi_n[n-1]\n\n    pi_n = np.asarray(pi_n[1:])\n    tau_n =  np.asarray(tau_n[1:])\n\n    return pi_n, tau_n",
  "def mie_S1_S2(m,x,mus,n_max):\n    a,b = Mie_ab(m, x,n_max)\n    S1s = []\n    S2s = []\n    for mu in mus:\n        S1 = 0.0\n        S2 = 0.0\n        pi,tau = calculate_pi_tau(mu,n_max)\n        for n in range(n_max):\n            N = n+1\n            # print len(a),len(pi), len(b), len(tau)\n            S1 = S1+(float(2.0*N+1)/(N**2+N))*(a[n]*pi[n] + b[n]*tau[n])\n            S2 = S2+(float(2.0*N+1)/(N**2+N))*(b[n]*pi[n] + a[n]*tau[n])\n\n        S1s.append(S1)\n        S2s.append(S2)\n    return [S1s,S2s]",
  "def get_refractive_index(target_wavelength, url):\n    #pull in globals\n    global WAVELENGTHS\n    global REFRACTIVE_INDEX\n    if WAVELENGTHS == None or REFRACTIVE_INDEX == None:\n\n        import csv\n        response = requests.get(url)\n        reader = csv.reader(response._content)\n        # for row in reader:\n        #     print row\n        print(response._content)\n        # content = ((response._content).replace('\\r','\\n')).replace('\\n\\n\\n',\"\\n\").replace('\\t',\",\").replace(\"\\n\\n\",\"\\n\")\n        print(content)\n        R = [v.split(\",\") for v in (content.split(\"\\n\"))]\n        R=R[1:]\n\n        wavelengths = []\n        ns = []\n        for row in R:\n            try:\n                w = float(row[0])\n                n = float(row[1])+1j*float(row[2])\n                wavelengths.append(w)\n                ns.append(n)\n            except:\n                pass\n            WAVELENGTHS = wavelengths\n            REFRACTIVE_INDEX = ns\n    print(target_wavelength)\n    print(WAVELENGTHS)\n    print(REFRACTIVE_INDEX)\n    return np.interp(target_wavelength,WAVELENGTHS,REFRACTIVE_INDEX)",
  "def get_refractive_index_Au(target_wavelength):\n    url = \"https://refractiveindex.info/data_csv.php?datafile=data/main/Au/Johnson.yml\"\n    return get_refractive_index(target_wavelength,url=url)",
  "def get_refractive_index_Ag(target_wavelength):\n    url = \"https://refractiveindex.info/data_csv.php?datafile=data/main/Ag/Johnson.yml\"\n    return get_refractive_index(target_wavelength,url=url)",
  "def get_refractive_index_water(target_wavelength):\n    url = \"https://refractiveindex.info/data_csv.php?datafile=data/main/H2O/Hale.yml\"\n    return get_refractive_index(target_wavelength,url=url)",
  "def calculate_scattering_cross_section(m,x,r,n_max):\n    k = x/r\n    a,b = Mie_ab(m, x,n_max)\n    a2 = np.abs(a)**2\n    b2 = np.abs(b)**2\n   \n    # n = np.arange(1,n_max+1)\n    # 2n1 = 2.0*n+1.0\n\n    total = 0.0\n    for n in range(len(a2)):\n        N = n+1\n        total = total + (2*N+1)*(a2[n]+b2[n])\n    return ((2*np.pi)/k**2)*total",
  "def calculate_extinction_cross_section(m,x,r,n_max):\n    k = x/r\n    a,b = Mie_ab(m, x, n_max)\n    \n\n    a2,b2 = np.absolute(a)**2,np.absolute(b)**2\n    \n    total = 0.0\n    for n in range(len(a)):\n        N = n+1\n        real_ab = a[n].real+b[n].real\n        # if real_ab < 0:\n        #     print \"a\",a\n        #     print \"b\",b\n        total = total + (2*N+1)*real_ab\n    return ((2*np.pi)/k**2)*total",
  "def main3():\n    n_medium = 1.3325\n    theta = np.pi/2.0\n   \n    rs = np.linspace(1e-9,500e-9,50)\n    rs = [20e-9,40e-9,]\n    wavelengths = np.linspace(400e-9,1000e-9,600)\n    for r in rs:\n        print(\"r\",r)\n        Xs_sca = []\n        Xs_ext = []\n        for wavelength in wavelengths:\n            n_particle = get_refractive_index_Au(wavelength/1e-9)\n            print(\"N:\",n_particle)\n            x,m = make_rescaled_parameters(n_med=n_medium,n_particle=n_particle,r=r,wavelength=wavelength)\n            \n            print(\"X:{0},M:{1}\".format(x,m))\n            n_max = 20\n            scatteringXc = calculate_scattering_cross_section(m,x,r,n_max)\n            extinctionXc = calculate_extinction_cross_section(m,x,r,n_max)\n\n            # [scatteringXc,extinctionXc,_,_] = small_mie(m,x)\n            Xs_sca.append(scatteringXc)\n            Xs_ext.append(extinctionXc)\n          \n        fig, ax1 = plt.subplots(1,figsize=(8,8))\n\n        Xs_sca = np.asarray(Xs_sca)/(np.pi*r**2)\n        Xs_ext = np.asarray(Xs_ext)/(np.pi*r**2)\n        Xs_abs = Xs_ext - Xs_sca\n\n        # wavelengths = wavelengths/1e-9\n        ax1.plot(wavelengths/1e-9,Xs_sca, label=\"Scattering efficiency $Q_{sca} = \\sigma_{sca}/\\pi r^2$\")\n        ax1.plot(wavelengths/1e-9,Xs_ext, label=\"Extinction efficiency $Q_{ext} = \\sigma_{ext}/\\pi r^2$\")\n        ax1.plot(wavelengths/1e-9,Xs_abs, label=\"Absorption efficiency $Q_{abs} = \\sigma_{abs}/\\pi r^2$\")\n        \n        ext_max =np.max(Xs_ext)\n        lambda_max = wavelengths[np.where(np.abs(Xs_ext==ext_max))][0] \n        ax1.set_xlabel(\"Size[nm]\")\n        ax1.set_ylabel(\"Amplitude\")\n        ax1.legend()\n        plt.title(\"Radius [nm]: {0}, $\\lambda$: {1}\".format(r/1e-9, lambda_max/1e-9))\n        # plt.savefig(\"C:\\Users\\im354\\Pictures\\Mie\\SEA\\particle_{0}.png\".format(r/1e-9))\n        \n        plt.show()",
  "def main2():\n    wavelength = 633.0e-9\n    n_particle = get_refractive_index_Au(wavelength/1e-9)\n    n_medium = 1.3325\n    theta = np.pi/2.0\n    rs = np.linspace(1e-9,5e-7,1000)\n    \n    Is = []\n    Xs_sca = []\n    Xs_ext = []\n    Qext = []\n    Qsca = []\n    Qback = []\n    G = []\n    for r in rs:\n        x,m = make_rescaled_parameters(n_med=n_medium,n_particle=n_particle,r=r,wavelength=wavelength)\n        n_max = 100 #int(x + 4.05 * x**0.33333 + 2.0)+1\n        scatteringXc = calculate_scattering_cross_section(m,x,r,n_max)\n        extinctionXc = calculate_extinction_cross_section(m,x,r,n_max)\n        i = I(r,np.asarray([theta]),n_medium,n_particle,wavelength)\n        Xs_sca.append(scatteringXc)\n        Xs_ext.append(extinctionXc)\n        Is.append(i)\n\n        [qext, qsca, qback, g] = mie_scalar(m, x,n_max)\n\n        Qext.append(qext)\n        Qsca.append(qsca)\n        Qback.append(qback)\n        G.append(g)\n      \n    fig, [ax1,ax2] = plt.subplots(2)\n    ax1.plot(rs/1e-9,Xs_sca/(np.pi*rs**2), label=\"Scattering efficiency $Q_{sca} = \\sigma_{sca}/\\pi r^2$\")\n    ax1.plot(rs/1e-9,Xs_ext/(np.pi*rs**2), label=\"Extinction efficiency $Q_{ext} = \\sigma_{ext}/\\pi r^2$\")\n    \n    ax1.set_xlabel(\"Size[nm]\")\n    ax1.set_ylabel(\"Amplitude\")\n\n\n    ax2.plot(rs/1e-9,Qsca,label=\"Scattering\")\n    ax2.plot(rs/1e-9,Qext,label=\"Extinction\")\n    # ax2.plot(rs/1e-9,Is, label=\"Scattering intensity\")\n    \n    ax2.set_xlabel(\"Size[nm]\")\n    ax2.set_ylabel(\"Amplitude\")\n\n    ax1.legend()\n    ax2.legend()\n    plt.show()",
  "def main():\n    wavelength = 633.0e-9\n    n_particle = get_refractive_index_Au(wavelength/1e-9)\n    n_medium = 1.3325\n\n    for r in np.linspace(1e-9,4e-7,50):\n        fig = plt.figure(figsize=(16,8))\n        ax1 = fig.add_subplot(121,projection=\"polar\")\n        ax2 = fig.add_subplot(122)\n\n        x,m = make_rescaled_parameters(n_med=n_medium,n_particle=n_particle,r=r,wavelength=wavelength)\n        n_max = int(x + 4.05 * x**0.33333 + 2.0)+1\n\n        print(\"x:\",x)\n        print(\"m:\",m)\n        print(\"n_max\", n_max)\n        theta = np.linspace(-np.pi,np.pi, 360)\n        mu = np.cos(theta)\n        [S1,S2] = mie_S1_S2(m,x,mu,n_max)\n\n        S11 = np.abs(S1)**2 + np.abs(S2)**2\n        S12 = np.abs(S1)**2 - np.abs(S2)**2\n\n        i_para = S11+S12\n        i_perp = S11-S12\n        i_total = i_para + i_perp\n        ax1.plot(theta,i_para,label=\"parallel\")\n        ax1.plot(theta,i_perp,label=\"perp\")\n        ax1.plot(theta,i_total,label=\"total\")\n\n        ax2.plot(theta,i_para,label=\"parallel\")\n        ax2.plot(theta,i_perp,label=\"perp\")\n        ax2.plot(theta,i_total, label=\"total\")\n\n        ax1.set_xlabel(\"Angle $\\\\theta$ [rad]\")\n        ax1.set_ylabel(\"Amplitude\")\n\n        ax2.set_xlabel(\"Angle $\\\\theta$ [rad]\")\n        ax2.set_ylabel(\"Amplitude\")\n\n\n        ax1.legend()\n        ax2.legend()\n        plt.title(\"Particle radius [nm]:{0},x:{1},\\nm:{2}, n_max:{3}\".format(r/1e-9,x,m,n_max))\n        # plt.show()\n        plt.savefig(\"C:\\\\Users\\im354\\Pictures\\Mie\\particle_{}.png\".format(r/1e-9))",
  "def scattering_cross_section(radius,wavelength):\n\n    n_particle = gold_refractive_index(required_wavelength=wavelength)\n    n_med = water_refractive_index(required_wavelength=wavelength)\n    x,m = make_rescaled_parameters(n_med=n_med,n_particle=n_particle,r=radius,wavelength=wavelength)\n    output = calculate_scattering_cross_section(m=np.asarray([m]),x=np.asarray([x]),r=np.asarray([radius]),n_max=40) \n    return output",
  "def main4():\n    wavelength_range = np.asarray([1e-9*wl for wl in np.linspace(450,1000,550)])\n    radius_range = np.asarray([r*1e-9 for r in np.linspace(50,250,200)])\n    x,y= np.meshgrid(radius_range,wavelength_range,indexing=\"xy\")\n    f = np.vectorize(scattering_cross_section)\n    z = f(x,y)\n    fig = plt.figure()\n    ax = fig.gca(projection='3d')\n    zmin = np.min(z)\n    surf = ax.plot_surface(x/1e-9, y/1e-9, z/zmin,cmap=cm.coolwarm)\n    plt.xlabel(\"Radius [nm]\")\n    plt.ylabel(\"Wavelength [nm]\")\n    plt.title(\"Normalized scattering cross section\\n Normalization: z/z_min, z_min = {}\".format(zmin))\n\n    ratio_low = scattering_cross_section(radius = 120e-9,wavelength=450e-9)/scattering_cross_section(radius = 100e-9,wavelength=450e-9)\n    ratio_high = scattering_cross_section(radius = 120e-9,wavelength=580e-9)/scattering_cross_section(radius = 100e-9,wavelength=580e-9)\n    print(\"RATIO LOW: \", ratio_low)\n    print(\"RATIO High: \", ratio_high)\n    plt.show()",
  "def psi(rho):\n        outp, _ =riccati_jn(n,rho) \n        return outp",
  "def dpsi(rho):\n        _,outp = riccati_jn(n,rho)\n        return outp",
  "def eps(rho):\n        jn = riccati_jn(n,rho)[0]\n        yn = riccati_yn(n,rho)[0] \n        hn = jn + 1j*yn\n        return hn",
  "def deps(rho):\n        d_jn = riccati_jn(n,rho)[1]\n        d_yn = riccati_yn(n,rho)[1] \n        d_hn = d_jn + 1j*d_yn\n        return d_hn",
  "def a():\n        num = m*psi(m*x)*dpsi(x) - psi(x)*dpsi(m*x)\n        denom = m*psi(m*x)*deps(x) - eps(x)*dpsi(m*x)\n        return (num/denom)[0:n]",
  "def b():\n        num = psi(m*x)*dpsi(x) - m*psi(x)*dpsi(m*x)\n        denom = psi(m*x)*deps(x) - m*eps(x)*dpsi(m*x)\n        return (num/denom)[0:n]",
  "class DoubleSlider(QtWidgets.QSlider):\n    '''' A Qt slider that works with floats (doubles) - taken from\n    https://stackoverflow.com/questions/42820380/use-float-for-qslider'''\n    # create our our signal that we can connect to if necessary\n    doubleValueChanged = QtCore.pyqtSignal(float)\n\n    def __init__(self, *args, decimals=3, **kwargs):\n        super().__init__(*args, **kwargs)\n        self._multi = 10**decimals\n\n        self.valueChanged.connect(self.emitDoubleValueChanged)\n\n    def emitDoubleValueChanged(self):\n        value = float(super().value()) / self._multi\n        self.doubleValueChanged.emit(value)\n\n    def value(self):\n        return float(super().value()) / self._multi\n\n    def setMinimum(self, value):\n        return super().setMinimum(int(value * self._multi))\n\n    def setMaximum(self, value):\n        return super().setMaximum(int(value * self._multi))\n\n    def setSingleStep(self, value):\n        return super().setSingleStep(int(value * self._multi))\n\n    def singleStep(self):\n        return float(super().singleStep()) / self._multi\n\n    def setValue(self, value):\n        super().setValue(int(value * self._multi))",
  "class LorentzGraphWidget(pg.PlotWidget):\n    '''\n    template for an interactive Lorentian graph\n    \n    Input: \n        modes: a dict with two functions, a Lorentzian and 'annotate',\n            which returns the spectral position and efficiency of the mode.\n            \n       xlim_func: when called provides an appropriate xlim. \n        \n    '''\n    def __init__(self,\n                 modes,\n                 xlim_func,\n                 resolution=100,\n                 title='Efficiencies',\n                 xlabel='wavelength (nm)',\n                 ylabel='radiative efficiency',):\n        super().__init__(title=title)\n        self.modes = modes\n        self.xlim_func = xlim_func\n        self.resolution = resolution\n        self.setTitle(title)\n        self.setLabel('bottom', xlabel)\n        self.setLabel('left', ylabel)\n        self.hasLegend = False\n        self.addLegend()\n        self.plot_item = self.getPlotItem()\n        self.plots_to_remove = []\n\n    def _plot(self, *args, remove=True, **kwargs):\n        p = self.plot(*args, **kwargs)  # pyqtgraph\n        if remove:  # keep track of it if we want to remove it every update\n            self.plots_to_remove.append(p)\n    \n    def update(self, remove=True):\n        while self.plots_to_remove:  # remove all the stored plots\n            self.plot_item.removeItem(self.plots_to_remove.pop())\n\n        xs = np.linspace(*self.xlim_func(), self.resolution)  # x axis changes\n        ys = np.zeros((len(self.modes), self.resolution))\n        for i, (name, mode) in enumerate(self.modes.items()):\n            y = mode['Lorentz'](xs)\n            \n            ys[i] = y\n            wl, eff = mode['annotate']()\n            label = f'{name}, wl={round(wl)}nm, efficiency={np.around(eff, 2)}'\n            self._plot(xs,\n                       y,\n                       pen=pg.mkPen(pg.intColor(i,\n                                                len(self.modes),\n                                                alpha=100 + 155 * remove),\n                                    width=5),\n                       name=label,\n                       remove=remove)\n        self._plot(xs, (ys**2 / ys.sum(axis=0)).sum(axis=0),\n                   pen=pg.mkPen(color=pg.mkColor(\n                       (0, 0, 0, 100 + 155 * remove)),\n                                width=5,\n                                style=QtCore.Qt.DotLine),\n                   name='sum',\n                   remove=remove)\n\n    def pin_plot(self):\n        self.update(False)\n\n    def _clear(self):\n        self.clear()\n        self.update()",
  "class PinAndClearButtons(QtWidgets.QGroupBox):\n    def __init__(self, graph):\n        super().__init__('graph pinning buttons')\n        self.setLayout(QtWidgets.QHBoxLayout())\n        pin = QtWidgets.QPushButton('pin')\n        pin.clicked.connect(graph.pin_plot)\n        self.layout().addWidget(pin)\n        clear = QtWidgets.QPushButton('clear')\n        clear.clicked.connect(graph._clear)\n        self.layout().addWidget(clear)",
  "class GraphWithPinAndClearButtons(QtWidgets.QGroupBox):\n    def __init__(self, *args, layout='V', **kwargs):\n        super().__init__(kwargs.get('title', ''))\n        self.graph = LorentzGraphWidget(*args, **kwargs)\n        layout = QtWidgets.QHBoxLayout(\n        ) if layout == 'H' else QtWidgets.QVBoxLayout()\n        layout.addWidget(self.graph)\n        buttons = PinAndClearButtons(self.graph)\n        layout.addWidget(buttons)\n        self.setLayout(layout)\n\n    def update(self):\n        self.graph.update()",
  "class GraphGroup(QtWidgets.QGroupBox):\n    '''\n    feed me GraphWidget objects and \n    I'll lay them out horizontally\n    '''\n    def __init__(self, graphs, layout='H'):\n        super().__init__('Graphs')\n        layout = QtWidgets.QHBoxLayout(\n        ) if layout == 'H' else QtWidgets.QVBoxLayout()\n        self.setLayout(layout)\n        self.graphs = graphs\n        for i, g in enumerate(graphs):\n            self.layout().addWidget(g)\n\n    def update_graphs(self):\n        for g in self.graphs:\n            g.update()\n            g.hasLegend = True\n\n    def export(self):\n        for g in self.graphs:\n            print('Graph:', g._title)\n            g.export()",
  "class FloatMathMixin():\n    '''allows any class to be used like a float,\n    assuming it has a __float__ method.\n    '''\n    def __add__(self, other):\n        return float(self) + np.asarray(other)\n\n    def __sub__(self, other):\n        return float(self) - np.asarray(other)\n\n    def __mul__(self, other):\n        return float(self) * np.asarray(other)\n\n    def __truediv__(self, other):\n        return float(self) / np.asarray(other)\n\n    def __pow__(self, other):\n        return float(self)**np.asarray(other)\n\n    def __radd__(self, other):\n        return self.__add__(other)\n\n    def __rsub__(self, other):\n        return self.__sub__(other)\n\n    def __rmul__(self, other):\n        return self.__mul__(other)\n\n    def __rtruediv__(self, other):\n        return self.__truediv__(other)\n\n    def __rpow__(self, other):\n        return self.__pow__(other)",
  "class Parameter(QtWidgets.QWidget, FloatMathMixin):\n    '''\n    Representation of a parameter to be varied in an equation.\n    Takes its value from the Gui.\n    Supports basic array math.\n    \n    Inputs:\n        name: the label the parameter will have in the gui\n        Default: its initial value\n        Min: minimum value allowed to be entered in the gui\n        Max: maximum...\n        \n    '''\n\n    param_changed = QtCore.pyqtSignal()\n\n    def __init__(self,\n                 name,\n                 default=1.,\n                 Min=-100_000.,\n                 Max=100_000.,\n                 units=None,\n                 slider=True):\n\n        super().__init__()\n        self.name = name\n        self.slider = slider\n        self.units = f' ({units})' if units is not None else ''\n        self.setLayout(QtWidgets.QFormLayout())\n        if slider:\n            self.box = DoubleSlider(QtCore.Qt.Horizontal)\n        else:\n            self.box = QtWidgets.QDoubleSpinBox()\n        self.box.setSingleStep((Max - Min) / 20.)\n        self.label = QtWidgets.QLabel(self.name + self.units)\n        self.layout().addWidget(self.label)\n        self.box.setMinimum(float(Min))\n        self.box.setMaximum(float(Max))\n        self.layout().addWidget(self.box)\n        self.box.setValue(float(default))\n        self.box.doubleValueChanged.connect(self.changed)\n        self.changed(float(default))\n\n    def changed(self, value):\n        self.param_changed.emit()\n        self._float = value\n        if self.slider:\n            self.label.setText(str(self))\n\n    def __float__(self):\n        return self._float\n\n    def __repr__(self):\n        return str(float(self))\n\n    def __str__(self):\n        return f'{self.name}: {float(self)}{self.units}'",
  "class ParameterGroupBox(QtWidgets.QGroupBox):\n    '''\n    feed me parameters and i'll add spinBoxes for them, and \n    emit a signal when they're changed to update the graphs. \n    '''\n    param_changed = QtCore.pyqtSignal()\n\n    def __init__(self, parameters):\n        super().__init__('Parameter controls')\n        self.parameters = parameters\n        self.setLayout(QtWidgets.QHBoxLayout())\n        for p in self.parameters:\n            self.layout().addWidget(p)\n            p.param_changed.connect(self.param_changed.emit)",
  "class LivePlotWindow(QtWidgets.QMainWindow):\n    '''Puts the graphing and parameter widgets together'''\n    def __init__(self, graphs, parameters, style='Fusion'):\n\n        super().__init__()\n        layout = QtWidgets.QVBoxLayout()\n        self.resize(2500, 1500)\n        self.graphing_group = GraphGroup(graphs)  # graphing_group\n        self.parameter_widget = ParameterGroupBox(parameters)\n        layout.addWidget(self.graphing_group)\n        layout.addWidget(self.parameter_widget)\n        self.setWindowTitle('Live Plotting')\n        self.setWindowIcon(QtGui.QIcon('maxwell.png'))\n        self.widget = QtWidgets.QWidget()\n        self.widget.setLayout(layout)\n        self.setCentralWidget(self.widget)\n        self.parameter_widget.param_changed.connect(self.update_graphs)\n        self.update_graphs()\n        self.show()\n\n    def update_graphs(self):\n        self.graphing_group.update_graphs()",
  "def __init__(self, *args, decimals=3, **kwargs):\n        super().__init__(*args, **kwargs)\n        self._multi = 10**decimals\n\n        self.valueChanged.connect(self.emitDoubleValueChanged)",
  "def emitDoubleValueChanged(self):\n        value = float(super().value()) / self._multi\n        self.doubleValueChanged.emit(value)",
  "def value(self):\n        return float(super().value()) / self._multi",
  "def setMinimum(self, value):\n        return super().setMinimum(int(value * self._multi))",
  "def setMaximum(self, value):\n        return super().setMaximum(int(value * self._multi))",
  "def setSingleStep(self, value):\n        return super().setSingleStep(int(value * self._multi))",
  "def singleStep(self):\n        return float(super().singleStep()) / self._multi",
  "def setValue(self, value):\n        super().setValue(int(value * self._multi))",
  "def __init__(self,\n                 modes,\n                 xlim_func,\n                 resolution=100,\n                 title='Efficiencies',\n                 xlabel='wavelength (nm)',\n                 ylabel='radiative efficiency',):\n        super().__init__(title=title)\n        self.modes = modes\n        self.xlim_func = xlim_func\n        self.resolution = resolution\n        self.setTitle(title)\n        self.setLabel('bottom', xlabel)\n        self.setLabel('left', ylabel)\n        self.hasLegend = False\n        self.addLegend()\n        self.plot_item = self.getPlotItem()\n        self.plots_to_remove = []",
  "def _plot(self, *args, remove=True, **kwargs):\n        p = self.plot(*args, **kwargs)  # pyqtgraph\n        if remove:  # keep track of it if we want to remove it every update\n            self.plots_to_remove.append(p)",
  "def update(self, remove=True):\n        while self.plots_to_remove:  # remove all the stored plots\n            self.plot_item.removeItem(self.plots_to_remove.pop())\n\n        xs = np.linspace(*self.xlim_func(), self.resolution)  # x axis changes\n        ys = np.zeros((len(self.modes), self.resolution))\n        for i, (name, mode) in enumerate(self.modes.items()):\n            y = mode['Lorentz'](xs)\n            \n            ys[i] = y\n            wl, eff = mode['annotate']()\n            label = f'{name}, wl={round(wl)}nm, efficiency={np.around(eff, 2)}'\n            self._plot(xs,\n                       y,\n                       pen=pg.mkPen(pg.intColor(i,\n                                                len(self.modes),\n                                                alpha=100 + 155 * remove),\n                                    width=5),\n                       name=label,\n                       remove=remove)\n        self._plot(xs, (ys**2 / ys.sum(axis=0)).sum(axis=0),\n                   pen=pg.mkPen(color=pg.mkColor(\n                       (0, 0, 0, 100 + 155 * remove)),\n                                width=5,\n                                style=QtCore.Qt.DotLine),\n                   name='sum',\n                   remove=remove)",
  "def pin_plot(self):\n        self.update(False)",
  "def _clear(self):\n        self.clear()\n        self.update()",
  "def __init__(self, graph):\n        super().__init__('graph pinning buttons')\n        self.setLayout(QtWidgets.QHBoxLayout())\n        pin = QtWidgets.QPushButton('pin')\n        pin.clicked.connect(graph.pin_plot)\n        self.layout().addWidget(pin)\n        clear = QtWidgets.QPushButton('clear')\n        clear.clicked.connect(graph._clear)\n        self.layout().addWidget(clear)",
  "def __init__(self, *args, layout='V', **kwargs):\n        super().__init__(kwargs.get('title', ''))\n        self.graph = LorentzGraphWidget(*args, **kwargs)\n        layout = QtWidgets.QHBoxLayout(\n        ) if layout == 'H' else QtWidgets.QVBoxLayout()\n        layout.addWidget(self.graph)\n        buttons = PinAndClearButtons(self.graph)\n        layout.addWidget(buttons)\n        self.setLayout(layout)",
  "def update(self):\n        self.graph.update()",
  "def __init__(self, graphs, layout='H'):\n        super().__init__('Graphs')\n        layout = QtWidgets.QHBoxLayout(\n        ) if layout == 'H' else QtWidgets.QVBoxLayout()\n        self.setLayout(layout)\n        self.graphs = graphs\n        for i, g in enumerate(graphs):\n            self.layout().addWidget(g)",
  "def update_graphs(self):\n        for g in self.graphs:\n            g.update()\n            g.hasLegend = True",
  "def export(self):\n        for g in self.graphs:\n            print('Graph:', g._title)\n            g.export()",
  "def __add__(self, other):\n        return float(self) + np.asarray(other)",
  "def __sub__(self, other):\n        return float(self) - np.asarray(other)",
  "def __mul__(self, other):\n        return float(self) * np.asarray(other)",
  "def __truediv__(self, other):\n        return float(self) / np.asarray(other)",
  "def __pow__(self, other):\n        return float(self)**np.asarray(other)",
  "def __radd__(self, other):\n        return self.__add__(other)",
  "def __rsub__(self, other):\n        return self.__sub__(other)",
  "def __rmul__(self, other):\n        return self.__mul__(other)",
  "def __rtruediv__(self, other):\n        return self.__truediv__(other)",
  "def __rpow__(self, other):\n        return self.__pow__(other)",
  "def __init__(self,\n                 name,\n                 default=1.,\n                 Min=-100_000.,\n                 Max=100_000.,\n                 units=None,\n                 slider=True):\n\n        super().__init__()\n        self.name = name\n        self.slider = slider\n        self.units = f' ({units})' if units is not None else ''\n        self.setLayout(QtWidgets.QFormLayout())\n        if slider:\n            self.box = DoubleSlider(QtCore.Qt.Horizontal)\n        else:\n            self.box = QtWidgets.QDoubleSpinBox()\n        self.box.setSingleStep((Max - Min) / 20.)\n        self.label = QtWidgets.QLabel(self.name + self.units)\n        self.layout().addWidget(self.label)\n        self.box.setMinimum(float(Min))\n        self.box.setMaximum(float(Max))\n        self.layout().addWidget(self.box)\n        self.box.setValue(float(default))\n        self.box.doubleValueChanged.connect(self.changed)\n        self.changed(float(default))",
  "def changed(self, value):\n        self.param_changed.emit()\n        self._float = value\n        if self.slider:\n            self.label.setText(str(self))",
  "def __float__(self):\n        return self._float",
  "def __repr__(self):\n        return str(float(self))",
  "def __str__(self):\n        return f'{self.name}: {float(self)}{self.units}'",
  "def __init__(self, parameters):\n        super().__init__('Parameter controls')\n        self.parameters = parameters\n        self.setLayout(QtWidgets.QHBoxLayout())\n        for p in self.parameters:\n            self.layout().addWidget(p)\n            p.param_changed.connect(self.param_changed.emit)",
  "def __init__(self, graphs, parameters, style='Fusion'):\n\n        super().__init__()\n        layout = QtWidgets.QVBoxLayout()\n        self.resize(2500, 1500)\n        self.graphing_group = GraphGroup(graphs)  # graphing_group\n        self.parameter_widget = ParameterGroupBox(parameters)\n        layout.addWidget(self.graphing_group)\n        layout.addWidget(self.parameter_widget)\n        self.setWindowTitle('Live Plotting')\n        self.setWindowIcon(QtGui.QIcon('maxwell.png'))\n        self.widget = QtWidgets.QWidget()\n        self.widget.setLayout(layout)\n        self.setCentralWidget(self.widget)\n        self.parameter_widget.param_changed.connect(self.update_graphs)\n        self.update_graphs()\n        self.show()",
  "def update_graphs(self):\n        self.graphing_group.update_graphs()",
  "def Lorentz(wls, center_wl, eff):\n        eVs, center_eV = map(wl_to_ev, (wls, center_wl))\n        width_2 = MIM(center_eV, n, t) / (1 - eff)  # eV - = Gamma/2\n        lor = (width_2 / (width_2**2 + ((eVs - center_eV))**2)) / (2 * pi**2)\n        # 2pi times all eVs for angular frequency, then divide by pi for normalizing\n        return lor * eff",
  "def real_eq(f, D, t, n):\n        s = n * t**-0.46\n\n        return (395.5 + 0.0 + 179.6 * f + 0.3522 * D + 85.75 * s -\n                567.0 * f**2 + 1.823 * f * D + 93.01 * f * s + 0.00548 * D**2 +\n                1.438 * D * s + 0.836 * s**2)",
  "def imag_eq(real, D):\n        return (1.05\n        +0.0\n        -0.1229*D\n        +0.7649*real\n        +0.001026*D**2\n        +0.08007*D*real\n        -1.159*real**2\n        -2.85e-06*D**3\n        -0.0002686*D**2*real\n        -0.0126*D*real**2\n        +0.2632*real**3)",
  "def Lorentz_eq(wl):\n        real = real_eq(f, D, t, n)\n        efficiency = imag_eq(real, D)\n        return Lorentz(wl, real, efficiency)",
  "def annotate():\n        real = real_eq(f, D, t, n)\n        efficiency = imag_eq(real, D)\n        return real, efficiency",
  "def xlim():\n        wl = real_eq(f, D, t, n) \n        return wl * 0.8, wl * 1.1",
  "def ev_to_wl(eV):\n    return 1239.8419300923943 / eV",
  "def wl_to_omega(wl):\n    return 2 * pi * 1239.8419300923943 / wl",
  "def Lorentz(wls, center_wl, eff):\n    eVs, center_eV = map(wl_to_ev, (wls, center_wl))\n    width_2 = MIM(center_eV, n, t) / (1 - eff)  # eV - = Gamma/2\n    lor = (width_2 / (width_2**2 + ((eVs - center_eV))**2)) / (2 * pi**2)\n    # 2pi times all eVs for angular frequency, then divide by pi for normalizing\n    return lor * eff",
  "def file_to_mode_name(file):\n    return file.stem.replace('=', '_').split('_')[1]",
  "def func_maker(args, body_lines, return_value):\n    ldict = {}\n    defline = f\"def func({', '.join(args)}):\\n\\t\"\n    body = '\\n\\t'.join(body_lines)\n    returnline = '\\treturn ' + return_value\n    exec(''.join((defline, body, returnline)), globals(), ldict)\n    return ldict['func']",
  "def real_factory(s_expression, parsed_txt):\n    return func_maker(('f', 'D', 't', 'n'), [s_expression], parsed_txt)",
  "def imag_factory(parsed_txt):\n    func = func_maker(('real', 'D'), [], parsed_txt)\n\n    def inner_func(real, D):\n        real = wl_to_ev(real)\n        out = func(real, D)\n        return 0.00001 if out <= 0 else out  # prevent /0 in Lorentz\n\n    return inner_func",
  "def lorentz_factory(real_eq, imag_eq):\n    def inner_func(wl):\n        real = real_eq(f, D, t, n)\n        efficiency = imag_eq(real, D)\n        return Lorentz(wl, real, efficiency)\n\n    return inner_func",
  "def annotate_factory(real_eq, imag_eq):\n    def inner_func():\n        real = real_eq(f, D, t, n)\n        efficiency = imag_eq(real, D)\n        return real, efficiency\n\n    return inner_func",
  "def make_graph_widget(folder):\n    modes = defaultdict(dict)\n\n    for file in (folder / 'real equations').iterdir():\n        mode = file_to_mode_name(file)\n\n        with open(file, 'r') as eq_file:\n            s_expression = eq_file.readline()\n            parsed_txt = ''.join(eq_file.read().splitlines())\n            modes[f'{mode} mode']['real'] = real_factory(\n                s_expression, parsed_txt)\n\n    for file in (folder / 'imag equations').iterdir():\n        mode = file_to_mode_name(file)\n        with open(file, 'r') as eq_file:\n            parsed_txt = ''.join(eq_file.read().splitlines())\n            modes[f'{mode} mode']['imag'] = imag_factory(parsed_txt)\n\n    for mode in modes.values():\n        mode['Lorentz'] = lorentz_factory(mode['real'], mode['imag'])\n        mode['annotate'] = annotate_factory(mode['real'], mode['imag'])\n\n    def xlim_func():\n        reals = [mode['real'](f, D, t, n) for mode in modes.values()]\n        return min(reals) * 0.8, max(reals) * 1.1\n\n\n    return GraphWithPinAndClearButtons(modes,\n                                       xlim_func,\n                                       resolution=100,\n                                       title=folder.stem,                                      \n                                       )",
  "def inner_func(real, D):\n        real = wl_to_ev(real)\n        out = func(real, D)\n        return 0.00001 if out <= 0 else out",
  "def inner_func(wl):\n        real = real_eq(f, D, t, n)\n        efficiency = imag_eq(real, D)\n        return Lorentz(wl, real, efficiency)",
  "def inner_func():\n        real = real_eq(f, D, t, n)\n        efficiency = imag_eq(real, D)\n        return real, efficiency",
  "def xlim_func():\n        reals = [mode['real'](f, D, t, n) for mode in modes.values()]\n        return min(reals) * 0.8, max(reals) * 1.1",
  "def MIM(real, n, t):    \n    return np.sum(coef*(np.product(np.array([real, n, t])**powers, axis=1))) + intercept",
  "class AttributeDict(dict):\n    \"\"\"This class extends a dictionary to have a \"create\" method for\n    compatibility with h5py attrs objects.\"\"\"\n    \n    def create(self, name, data):\n        self[name] = data\n        \n    def modify(self, name, data):\n        self[name] = data\n\n    def copy_arrays(self):\n        \"\"\"Replace any numpy.ndarray in the dict with a copy, to break any unintentional links.\"\"\"\n        for k in list(self.keys()):\n            if isinstance(self[k], np.ndarray):\n                self[k] = np.copy(self[k])",
  "def ensure_attribute_dict(obj, copy=False):\n    \"\"\"Given a mapping that may or not be an AttributeDict, return an\n    AttributeDict object that either is, or copies the data of, the input.\"\"\"\n    if isinstance(obj, AttributeDict) and not copy:\n        return obj\n    else:\n        out = AttributeDict(obj)\n        if copy:\n            out.copy_arrays()\n        return out",
  "def ensure_attrs(obj):\n    \"\"\"Return an ArrayWithAttrs version of an array-like object, may be the\n    original object if it already has attrs.\"\"\"\n    if hasattr(obj, 'attrs'):\n        return obj #if it has attrs, do nothing\n    else:\n        return ArrayWithAttrs(obj)",
  "class ArrayWithAttrs(np.ndarray):\n    \"\"\"A numpy ndarray, with an AttributeDict accessible as array.attrs.\n    \n    This class is intended as a temporary version of an h5py dataset to allow\n    the easy passing of metadata/attributes around nplab functions.  It owes\n    a lot to the ``InfoArray`` example in `numpy` documentation on subclassing\n    `numpy.ndarray`.\n    \"\"\"\n    \n    def __new__(cls, input_array, attrs={}):\n        \"\"\"Make a new ndarray, based on an existing one, with an attrs dict.\n        \n        This function adds an attributes dictionary to a numpy array, to make\n        it work like an h5py dataset.  It doesn't copy data if it can be \n        avoided.\"\"\"\n        # the input array should be a numpy array, then we cast it to this type\n        obj = np.asarray(input_array).view(cls)\n        # next, add the dict\n        # ensure_attribute_dict always returns an AttributeDict\n        obj.attrs = ensure_attribute_dict(attrs)\n        # return the new object\n        return obj\n        \n    def __array_finalize__(self, obj):\n        # this is called by numpy when the object is created (__new__ may or\n        # may not get called)\n        if obj is None: return # if obj is None, __new__ was called - do nothing\n        # if we didn't create the object with __new__,  we must add the attrs\n        # dictionary.  We copy this from the source object if possible (while\n        # ensuring it's the right type) or create a new, empty one if not.\n        # NB we don't use ensure_attribute_dict because we want to make sure the\n        # dict object is *copied* not merely referenced.\n        self.attrs = ensure_attribute_dict(getattr(obj, 'attrs', {}), copy=True)",
  "def attribute_bundler(attrs):\n    \"\"\"Return a function that bundles the supplied attributes with an array.\"\"\"\n    def bundle_attrs(array):\n        return ArrayWithAttrs(array, attrs=attrs)",
  "class DummyHDF5Group(dict):\n    def __init__(self,dictionary, attrs ={}, name=\"DummyHDF5Group\"):\n        super(DummyHDF5Group, self).__init__()\n        self.attrs = attrs\n        for key in dictionary:\n            self[key] = dictionary[key]\n        self.name = name\n        self.basename = name\n\n    file = None\n    parent = None",
  "def create(self, name, data):\n        self[name] = data",
  "def modify(self, name, data):\n        self[name] = data",
  "def copy_arrays(self):\n        \"\"\"Replace any numpy.ndarray in the dict with a copy, to break any unintentional links.\"\"\"\n        for k in list(self.keys()):\n            if isinstance(self[k], np.ndarray):\n                self[k] = np.copy(self[k])",
  "def __new__(cls, input_array, attrs={}):\n        \"\"\"Make a new ndarray, based on an existing one, with an attrs dict.\n        \n        This function adds an attributes dictionary to a numpy array, to make\n        it work like an h5py dataset.  It doesn't copy data if it can be \n        avoided.\"\"\"\n        # the input array should be a numpy array, then we cast it to this type\n        obj = np.asarray(input_array).view(cls)\n        # next, add the dict\n        # ensure_attribute_dict always returns an AttributeDict\n        obj.attrs = ensure_attribute_dict(attrs)\n        # return the new object\n        return obj",
  "def __array_finalize__(self, obj):\n        # this is called by numpy when the object is created (__new__ may or\n        # may not get called)\n        if obj is None: return # if obj is None, __new__ was called - do nothing\n        # if we didn't create the object with __new__,  we must add the attrs\n        # dictionary.  We copy this from the source object if possible (while\n        # ensuring it's the right type) or create a new, empty one if not.\n        # NB we don't use ensure_attribute_dict because we want to make sure the\n        # dict object is *copied* not merely referenced.\n        self.attrs = ensure_attribute_dict(getattr(obj, 'attrs', {}), copy=True)",
  "def bundle_attrs(array):\n        return ArrayWithAttrs(array, attrs=attrs)",
  "def __init__(self,dictionary, attrs ={}, name=\"DummyHDF5Group\"):\n        super(DummyHDF5Group, self).__init__()\n        self.attrs = attrs\n        for key in dictionary:\n            self[key] = dictionary[key]\n        self.name = name\n        self.basename = name",
  "class ImageWithLocation(ArrayWithAttrs):\n    \"\"\"An image, as a numpy array, with attributes to provide location information\"\"\"\n#    def __array_finalize__(self, obj):\n#        \"\"\"Ensure that the object is a properly set-up ImageWithLocation\"\"\"\n#        ArrayWithAttrs.__array_finalize__(self, obj) # Ensure we have self.attrs\n    def __getitem__(self, item):\n        \"\"\"Update the metadata when we extract a slice\"\"\"\n        try:\n            # Handle specially the case where we are extracting a 2D region of the image, i.e. the first and second\n            # indices are slices.  We test for that here - and do it in a try: except block so that if, for example,\n            # item is not indexable,\n            assert isinstance(item[0], slice), \"First index was not a slice\"\n            assert isinstance(item[1], slice), \"Second index was not a slice\"\n            start = np.array([item[i].start for i in range(2)])\n            start = np.where(start == np.array(None), 0, start) # missing start points are equivalent to zero\n            step = np.array([item[i].step for i in range(2)])\n            step = np.where(step == np.array(None), 1, step) # missing step is equivalent to step==1\n        except:\n            # If the above doesn't work, assume we're not dealing with a 2D slice and give up.\n            return super(ImageWithLocation, self).__getitem__(item) # pass it on up\n\n        out = super(ImageWithLocation, self).__getitem__(item) # retrieve the slice\n        out.datum_pixel -= start # adjust the datum pixel so it refers to the same part of the image\n        # Next, we adjust the constant part of the pixel-sample matrix so pixels stay in the same place\n        location_shift = np.dot(ensure_3d(start), self.pixel_to_sample_matrix[:3,:3])\n        out.pixel_to_sample_matrix[3,:3] += location_shift\n        if not np.all(step == 1):\n            # if we're downsampling, remember to scale datum_pixel accordingly\n            out.datum_pixel = out.datum_pixel// step\n            # Scale the pixel-to-sample matrix if we've got a non-unity step in the slice\n            # I don't understand why I can't do this with slicing, but it all goes wrong...\n            for i in range(2):\n                out.pixel_to_sample_matrix[i, :3] *= step[i]\n        return out\n\n    def pixel_to_location(self, pixel):\n        \"\"\"Return the location in the sample of the given pixel.\n\n        NB this returns a 3D location, including Z.\"\"\"\n        p = ensure_2d(pixel)\n        l = np.dot(np.array([p[0], p[1], 0, 1]), self.pixel_to_sample_matrix)\n        return l[:3]\n\n    def location_to_pixel(self, location, check_bounds=False, z_tolerance=np.infty):\n        \"\"\"Return the pixel coordinates of a given location in the sample.\n\n        location : numpy.ndarray\n            A 2- or 3- element numpy array representing sample position, in units of distance.\n        check_bounds : bool, optional (default False)\n            If this is True, raise an exception if the pixel is not in the image.\n        z_tolerance : float, optional (defaults to infinity)\n            If we are checking the bounds, make sure the sample location is within this distance of the image's Z\n            position.  The default is to allow any distance.\n\n        Returns : numpy.ndarray\n        A 2- or 3- element position, to match the size of location passed in.\n        \"\"\"\n        l = ensure_2d(location)\n        l = l[:2]-self.pixel_to_sample_matrix[3,:2]\n        p = np.dot(l, np.linalg.inv(self.pixel_to_sample_matrix[:2,:2]))\n        if check_bounds:\n            assert np.all(0 <= p[0:2]), \"The location was not within the image\"\n            assert np.all(p[0:2] <= self.shape[0:2]), \"The location was not within the image\"\n            assert np.abs(p[2]) < z_tolerance, \"The location was too far away from the plane of the image\"\n        if len(location) == 2:\n            return p[:2]\n        else:\n            return p[:3]\n\n    def feature_at(self, centre_position, size=(100,100), set_datum_to_centre=True):\n        \"\"\"Return a thumbnail cropped out of this image, centred on a particular pixel position.\n\n        This is simply a convenience method that saves typing over the usual slice syntax.  Below are two equivalent\n        ways of extracting a thumbnail:\n            pos = (240,320)\n            size = (100,100)\n            thumbnail = image[pos[0] - size[0]/2:pos[0] + size[0]/2, pos[1] - size[1]/2:pos[1] + size[1]/2, ...]\n            thumbnail2 = image.feature_at(pos, size)\n            thumbnail3 = image[190:290 270:370]\n\n        ``centre_position`` and ``size`` should be two-element tuples, but the intention is that this code will cope\n        gracefully with floating-point values.\n\n        NB the datum pixel of the returned image will be set to its centre, not the datum position of the original image\n        by default.  Give the argument ``set_datum_to_centre=False`` to disable this behaviour.\n        \"\"\"\n        try:\n            float(centre_position[0])\n            float(centre_position[1])\n            float(size[0])\n            float(size[1])\n        except:\n            raise IndexError(\"Error: arguments of feature_at were invalid: {}, {}\".format(centre_position, size))\n        pos = centre_position\n\n        # For now, rely on numpy to complain if the feature is outside the image.  May do bound-checking at some point.\n        # If so, we might need to think carefully about the datum pixel of the resulting image.\n        thumb = self[pos[0] - size[0]//2:pos[0] + size[0]//2, pos[1] - size[1]//2:pos[1] + size[1]//2, ...]\n        if set_datum_to_centre:\n            thumb.datum_pixel = (size[0]//2, size[1]//2) # Make the datum point of the new image its centre.\n        return thumb\n\n    def downsample(self, n):\n        \"\"\"Return a view of the image, downsampled (sliced with a non-unity step).\n\n        In the future, an optional argument to this function may take means of blocks of the images to improve signal\n        to noise.  Currently it just decimates (i.e. throws away rows and columns).\n        \"\"\"\n        assert n > 0, \"The downsampling factor must be an integer greater than 0\"\n        return self[::int(n), ::int(n), ...] # The slicing code handles updating metadata\n\n    @property\n    def datum_pixel(self):\n        \"\"\"The pixel that nominally corresponds to where the image \"is\".  Usually the central pixel.\"\"\"\n        datum = self.attrs.get('datum_pixel', (np.array(self.shape[:2]) - 1)//2)\n        assert len(datum) == 2, \"The datum pixel didn't have length 2!\"\n        return datum\n\n    @datum_pixel.setter\n    def datum_pixel(self, datum):\n        assert len(datum) == 2, \"The datum pixel didn't have length 2!\"\n        self.attrs['datum_pixel'] = datum\n\n    @property\n    def datum_location(self):\n        \"\"\"The location in the sample of the datum pixel\"\"\"\n        return self.pixel_to_location(self.datum_pixel)\n\n    @property\n    def pixel_to_sample_matrix(self):\n        \"\"\"The matrix that maps from pixel coordinates to sample coordinates.\n\n        np.dot(p, M) yields a location for the given pixel, where p is [x,y,0,1] and M is this matrix.  The location\n        given will be 4 elements long, and will have 1 as the final element.\n        \"\"\"\n        M = self.attrs['pixel_to_sample_matrix']\n        assert M.shape == (4, 4), \"The pixel-to-sample matrix is the wrong shape!\"\n        assert M.dtype.kind == \"f\", \"The pixel-to-sample matrix is not floating point!\"\n        return M\n\n    @pixel_to_sample_matrix.setter\n    def pixel_to_sample_matrix(self, M):\n        M = np.asanyarray(M) #ensure it's an ndarray subclass\n        assert M.shape == (4, 4), \"The pixel-to-sample matrix must be 4x4!\"\n        assert M.dtype.kind == \"f\", \"The pixel-to-sample matrix must be floating point!\"\n        self.attrs['pixel_to_sample_matrix'] = M",
  "def datum_pixel(image):\n    \"\"\"Get the datum pixel of an image - if no property is present, assume the central pixel.\"\"\"\n    try:\n        return np.array(image.datum_pixel)\n    except:\n        return (np.array(image.shape[:2]) - 1)//2",
  "def ensure_3d(vector):\n    \"\"\"Make sure a vector has 3 elements, appending a zero if needed.\"\"\"\n    if len(vector) == 3:\n        return np.array(vector)\n    elif len(vector) == 2:\n        return np.array([vector[0], vector[1], 0])\n    else:\n        raise ValueError(\"Tried to ensure a vector was 3D, but it had neither 2 nor 3 elements!\")",
  "def ensure_2d(vector):\n    \"\"\"Make sure a vector has 3 elements, appending a zero if needed.\"\"\"\n    if len(vector) == 2:\n        return np.array(vector)\n    elif len(vector) == 3:\n        return np.array(vector[:2])\n    else:\n        raise ValueError(\"Tried to ensure a vector was 2D, but it had neither 2 nor 3 elements!\")",
  "def locate_feature_in_image(image, feature, margin=0, restrict=False):\n    \"\"\"Find the given feature (small image) and return the position of its datum (or centre) in the image's pixels.\n\n    image : numpy.array\n        The image in which to look.\n    feature : numpy.array\n        The feature to look for.  Ideally should be an `ImageWithLocation`.\n    margin : int (optional)\n        Make sure the feature image is at least this much smaller than the big image.  NB this will take account of the\n        image datum points - if the datum points are superimposed, there must be at least margin pixels on each side of\n        the feature image.\n    restrict : bool (optional, default False)\n        If set to true, restrict the search area to a square of (margin * 2 + 1) pixels centred on the pixel that most\n        closely overlaps the datum points of the two images.\n\n    The `image` must be larger than `feature` by a margin big enough to produce a meaningful search area.  We use the\n    OpenCV `matchTemplate` method to find the feature.  The returned position is the position, relative to the corner of\n    the first image, of the \"datum pixel\" of the feature image.  If no datum pixel is specified, we assume it's the\n    centre of the image.  The output of this function can be passed into the pixel_to_location() method of the larger\n    image to yield the position in the sample of the feature you're looking for.\n    \"\"\"\n    # The line below is superfluous if we keep the datum-aware code below it.\n    assert image.shape[0] > feature.shape[0] and image.shape[1] > feature.shape[1], \"Image must be larger than feature!\"\n    # Check that there's enough space around the feature image\n    image, feature = image.astype(np.float32), feature.astype(np.float32)\n    \n    lower_margin = datum_pixel(image) - datum_pixel(feature)\n    upper_margin = (image.shape[:2] - datum_pixel(image)) - (feature.shape[:2] - datum_pixel(feature))\n    assert np.all(np.array([lower_margin, upper_margin]) >= margin), \"The feature image is too large.\"\n    #TODO: sensible auto-crop of the template if it's too large?\n    image_shift = np.array((0,0))\n    if restrict:\n        # if requested, crop the larger image so that our search area is (2*margin + 1) square.\n        image_shift = np.array(lower_margin - margin,dtype = int)\n        image = image[image_shift[0]:image_shift[0] + feature.shape[0] + 2 * margin + 1,\n                      image_shift[1]:image_shift[1] + feature.shape[1] + 2 * margin + 1, ...]\n    corr = cv2.matchTemplate(image, feature,\n                             cv2.TM_SQDIFF_NORMED)  # correlate them: NB the match position is the MINIMUM\n    \n    corr = -corr # invert the image so we can find a peak\n    corr += (corr.max() - corr.min()) * 0.1 - corr.max()  # background-subtract 90% of maximum\n    \n    corr = cv2.threshold(corr, 0, 0, cv2.THRESH_TOZERO)[\n        1]  # zero out any negative pixels - but there should always be > 0 nonzero pixels\n   \n    assert np.sum(corr) > 0, \"Error: the correlation image doesn't have any nonzero pixels.\"\n    peak = ndimage.measurements.center_of_mass(corr)  # take the centroid (NB this is of grayscale values, not binary)\n    pos = np.array(peak) + image_shift + datum_pixel(feature) # return the position of the feature's datum point.\n    return pos",
  "def __getitem__(self, item):\n        \"\"\"Update the metadata when we extract a slice\"\"\"\n        try:\n            # Handle specially the case where we are extracting a 2D region of the image, i.e. the first and second\n            # indices are slices.  We test for that here - and do it in a try: except block so that if, for example,\n            # item is not indexable,\n            assert isinstance(item[0], slice), \"First index was not a slice\"\n            assert isinstance(item[1], slice), \"Second index was not a slice\"\n            start = np.array([item[i].start for i in range(2)])\n            start = np.where(start == np.array(None), 0, start) # missing start points are equivalent to zero\n            step = np.array([item[i].step for i in range(2)])\n            step = np.where(step == np.array(None), 1, step) # missing step is equivalent to step==1\n        except:\n            # If the above doesn't work, assume we're not dealing with a 2D slice and give up.\n            return super(ImageWithLocation, self).__getitem__(item) # pass it on up\n\n        out = super(ImageWithLocation, self).__getitem__(item) # retrieve the slice\n        out.datum_pixel -= start # adjust the datum pixel so it refers to the same part of the image\n        # Next, we adjust the constant part of the pixel-sample matrix so pixels stay in the same place\n        location_shift = np.dot(ensure_3d(start), self.pixel_to_sample_matrix[:3,:3])\n        out.pixel_to_sample_matrix[3,:3] += location_shift\n        if not np.all(step == 1):\n            # if we're downsampling, remember to scale datum_pixel accordingly\n            out.datum_pixel = out.datum_pixel// step\n            # Scale the pixel-to-sample matrix if we've got a non-unity step in the slice\n            # I don't understand why I can't do this with slicing, but it all goes wrong...\n            for i in range(2):\n                out.pixel_to_sample_matrix[i, :3] *= step[i]\n        return out",
  "def pixel_to_location(self, pixel):\n        \"\"\"Return the location in the sample of the given pixel.\n\n        NB this returns a 3D location, including Z.\"\"\"\n        p = ensure_2d(pixel)\n        l = np.dot(np.array([p[0], p[1], 0, 1]), self.pixel_to_sample_matrix)\n        return l[:3]",
  "def location_to_pixel(self, location, check_bounds=False, z_tolerance=np.infty):\n        \"\"\"Return the pixel coordinates of a given location in the sample.\n\n        location : numpy.ndarray\n            A 2- or 3- element numpy array representing sample position, in units of distance.\n        check_bounds : bool, optional (default False)\n            If this is True, raise an exception if the pixel is not in the image.\n        z_tolerance : float, optional (defaults to infinity)\n            If we are checking the bounds, make sure the sample location is within this distance of the image's Z\n            position.  The default is to allow any distance.\n\n        Returns : numpy.ndarray\n        A 2- or 3- element position, to match the size of location passed in.\n        \"\"\"\n        l = ensure_2d(location)\n        l = l[:2]-self.pixel_to_sample_matrix[3,:2]\n        p = np.dot(l, np.linalg.inv(self.pixel_to_sample_matrix[:2,:2]))\n        if check_bounds:\n            assert np.all(0 <= p[0:2]), \"The location was not within the image\"\n            assert np.all(p[0:2] <= self.shape[0:2]), \"The location was not within the image\"\n            assert np.abs(p[2]) < z_tolerance, \"The location was too far away from the plane of the image\"\n        if len(location) == 2:\n            return p[:2]\n        else:\n            return p[:3]",
  "def feature_at(self, centre_position, size=(100,100), set_datum_to_centre=True):\n        \"\"\"Return a thumbnail cropped out of this image, centred on a particular pixel position.\n\n        This is simply a convenience method that saves typing over the usual slice syntax.  Below are two equivalent\n        ways of extracting a thumbnail:\n            pos = (240,320)\n            size = (100,100)\n            thumbnail = image[pos[0] - size[0]/2:pos[0] + size[0]/2, pos[1] - size[1]/2:pos[1] + size[1]/2, ...]\n            thumbnail2 = image.feature_at(pos, size)\n            thumbnail3 = image[190:290 270:370]\n\n        ``centre_position`` and ``size`` should be two-element tuples, but the intention is that this code will cope\n        gracefully with floating-point values.\n\n        NB the datum pixel of the returned image will be set to its centre, not the datum position of the original image\n        by default.  Give the argument ``set_datum_to_centre=False`` to disable this behaviour.\n        \"\"\"\n        try:\n            float(centre_position[0])\n            float(centre_position[1])\n            float(size[0])\n            float(size[1])\n        except:\n            raise IndexError(\"Error: arguments of feature_at were invalid: {}, {}\".format(centre_position, size))\n        pos = centre_position\n\n        # For now, rely on numpy to complain if the feature is outside the image.  May do bound-checking at some point.\n        # If so, we might need to think carefully about the datum pixel of the resulting image.\n        thumb = self[pos[0] - size[0]//2:pos[0] + size[0]//2, pos[1] - size[1]//2:pos[1] + size[1]//2, ...]\n        if set_datum_to_centre:\n            thumb.datum_pixel = (size[0]//2, size[1]//2) # Make the datum point of the new image its centre.\n        return thumb",
  "def downsample(self, n):\n        \"\"\"Return a view of the image, downsampled (sliced with a non-unity step).\n\n        In the future, an optional argument to this function may take means of blocks of the images to improve signal\n        to noise.  Currently it just decimates (i.e. throws away rows and columns).\n        \"\"\"\n        assert n > 0, \"The downsampling factor must be an integer greater than 0\"\n        return self[::int(n), ::int(n), ...]",
  "def datum_pixel(self):\n        \"\"\"The pixel that nominally corresponds to where the image \"is\".  Usually the central pixel.\"\"\"\n        datum = self.attrs.get('datum_pixel', (np.array(self.shape[:2]) - 1)//2)\n        assert len(datum) == 2, \"The datum pixel didn't have length 2!\"\n        return datum",
  "def datum_pixel(self, datum):\n        assert len(datum) == 2, \"The datum pixel didn't have length 2!\"\n        self.attrs['datum_pixel'] = datum",
  "def datum_location(self):\n        \"\"\"The location in the sample of the datum pixel\"\"\"\n        return self.pixel_to_location(self.datum_pixel)",
  "def pixel_to_sample_matrix(self):\n        \"\"\"The matrix that maps from pixel coordinates to sample coordinates.\n\n        np.dot(p, M) yields a location for the given pixel, where p is [x,y,0,1] and M is this matrix.  The location\n        given will be 4 elements long, and will have 1 as the final element.\n        \"\"\"\n        M = self.attrs['pixel_to_sample_matrix']\n        assert M.shape == (4, 4), \"The pixel-to-sample matrix is the wrong shape!\"\n        assert M.dtype.kind == \"f\", \"The pixel-to-sample matrix is not floating point!\"\n        return M",
  "def pixel_to_sample_matrix(self, M):\n        M = np.asanyarray(M) #ensure it's an ndarray subclass\n        assert M.shape == (4, 4), \"The pixel-to-sample matrix must be 4x4!\"\n        assert M.dtype.kind == \"f\", \"The pixel-to-sample matrix must be floating point!\"\n        self.attrs['pixel_to_sample_matrix'] = M",
  "def jpeg_encode(image, quality=90):\n    \"\"\"Encode an image from a numpy array to a JPEG.\n    \n    This function allows compressed JPEG images to be stored in an HDF5 file.\n    You can pass in an OpenCV style image (i.e. an NxMx3 numpy array) and it\n    will return a 1d array of uint8 that is smaller, depending on the\n    quality factor specified.  It is returned as an array_with_attrs so that\n    we can set attributes (that will be saved to HDF5 automatically) to say\n    it was saved as a JPEG.\n    \"\"\"\n    ret, encoded_array = cv2.imencode('.jpeg',image, \n                                      (cv2.cv.CV_IMWRITE_JPEG_QUALITY, quality))\n    assert ret, \"Error encoding image\"\n    jpeg = ArrayWithAttrs(encoded_array)\n    jpeg.attrs.create(\"image_format\", \"jpeg\")\n    jpeg.attrs.create(\"jpeg_quality\", quality)\n    return jpeg",
  "def jpeg_decode(image):\n    \"\"\"Unpack a compressed jpeg image into an uncompressed numpy array.\"\"\"\n    return cv2.imdecode(image, cv2.cv.CV_LOAD_IMAGE_COLOR)",
  "def png_decode(image):\n    \"\"\"Unpack a compressed image into an uncompressed numpy array.\"\"\"\n    return cv2.imdecode(image, cv2.cv.CV_LOAD_IMAGE_COLOR)",
  "def png_encode(image, compression=3):\n    \"\"\"Encode an image from a numpy array to a JPEG.\n    \n    This function allows compressed PNG images to be stored in an HDF5 file.\n    You can pass in an OpenCV style image (i.e. an NxMx3 numpy array) and it\n    will return a 1d array of uint8 that is smaller, depending on the\n    quality factor specified.  It is returned as an array_with_attrs so that\n    we can set attributes (that will be saved to HDF5 automatically) to say\n    it was saved as a PNG.\n    \"\"\"\n    ret, encoded_array = cv2.imencode('.png',image, \n                                      (cv2.cv.CV_IMWRITE_PNG_COMPRESSION, compression))\n    assert ret, \"Error encoding image\"\n    png = ArrayWithAttrs(encoded_array)\n    png.attrs.create(\"image_format\", \"png\")\n    png.attrs.create(\"png_compression\", compression)\n    return png",
  "def test_image_codecs():\n    \"\"\"Unit test for the image encoding/decoding functions\"\"\"\n    noise = np.random.random((1000,1000,3))\n    noise[300:700,300:700,:] *= 4\n    noise *= 255.0/4\n    img = noise.astype(np.uint8)\n    \n    print(\"image size is %d\" % img.size)\n    \n    png = png_encode(img)\n    print(\"PNG size is %d (%.d%%)\" % (png.size, old_div((100*png.size),img.size)))\n    assert png.size < img.size, \"The PNG was bigger than the image!\"\n    \n    jpeg = jpeg_encode(img)\n    print(\"JPEG size is %d (%d%%)\" % (jpeg.size, old_div((100*jpeg.size),img.size)))\n\n    assert jpeg.size < img.size, \"The JPEG was bigger than the image!\"\n    \n    assert np.all(png_decode(png) == img), \"The PNG did not uncompress losslessly.\"\n    assert np.any(jpeg_decode(jpeg) != img), \"The JPEG uncompressed losslessly - wtf?\"\n    \n    jpeg_noise = jpeg_decode(jpeg).astype(np.float) - img\n    print(\"JPEG differed from source image by %.2f RMS\" % np.std(jpeg_noise))",
  "def Convert_Pyqt_to_qtpy(path,avoid_files = None):\n    '''A function for converting pyqt based python scripts to use qtpy \n    ( a wrapper that allows any qt version to be used)\n    \n    Be very careful when using this functions, Always Create backups!!!!!\n    \n    N.B. The fileinput modulue forces the print function to write to file (Very annoying), so do not use any print statements  \n    '''\n    \n    if avoid_files == None:\n        avoid_files = ['PyQtToQtpy.py','utils\\\\gui.py']\n        \n        \n    file_locations = [os.path.join(dirpath, f) #Create a list of file paths from the top level path\n    for dirpath, dirnames, files in os.walk(path)\n        for f in fnmatch.filter(files, '*.py')]\n\n    \n    \n    for filename in file_locations:\n        found_bad_file = False\n        for avoid_file in avoid_files: # skip requested files\n            if avoid_file in filename:\n                found_bad_file = True\n                continue\n        if found_bad_file == True:\n            continue\n        i=0\n        for line in fileinput.input(filename):\n            i+=1\n        if i == 1:\n            f = open(filename,mode = 'r')\n            text = f.read()\n            f.close()\n            text = text.replace('\\r','\\n')\n            f = open(filename,mode='w')\n            f.write(text)\n            f.close()\n                \n        for line in fileinput.input(filename, inplace=True):\n            if ('import ' in line) and (('QtCore' in line) or ('QtGui' in line) or ('uic' in line)):\n                if '*' in line:\n                    nplab_import_line = line.replace('PyQt4','nplab.utils.gui')\n                if ('QtWidgets' not in line) and ('QtGui' in line):\n                    nplab_import_line = 'from nplab.utils.gui import QtWidgets, '\n                else:\n                    nplab_import_line = 'from nplab.utils.gui import '                    \n                for attribute in dir(nplab.utils.gui): \n                    if attribute in line.replace(',',' ').split('\\n')[0].split(' '):               \n                        nplab_import_line = nplab_import_line +attribute+', '\n                if nplab_import_line == 'from nplab.utils.gui import ':\n                    sys.stdout.write(line) \n                    continue\n                else:\n                    nplab_import_line = nplab_import_line[:-2] + '\\n'\n                    sys.stdout.write(line.split('import')[0].split('from')[0]+nplab_import_line) # added line split on import and from to correct for white space for indented imports\n                    continue\n            for command in line.split(' '):\n                if 'QtGui.' in command:\n                    func = re.search(r\"QtGui\\.([0-9a-zA-Z_]+)\", command).group(1)\n                    if hasattr(QtGui,func):\n                        continue\n                    else:\n                        if hasattr(QtWidgets,func):\n                            line = line.replace(\"QtGui\", \"QtWidgets\")\n                        else:\n                            continue\n\n                if 'QtCore.' in command:\n                    \n                    try:\n                        func = re.search(r\"QtCore\\.([0-9a-zA-Z_]+)\", command).group(1)\n                    except IndexError: \n                        continue\n                    if func == 'pyqtSignal':\n                        line = line.replace('pyqtSignal','Signal')\n                        continue\n                            \n            sys.stdout.write(line)\n            \n        fileinput.close()",
  "def timed_execution(f,*args,**kwargs):\n\n\t'''\n\tTimed execution of function 'f' taking arguments\n\n\t@param: f: the function whose execution you want to time\n\t@param: *args: the non-keyword arguments of the function\n\t@param: *kwargs: the keyword arguments of the function\n\n\t@return: output of function (out), execution time (dt) [in seconds]\n\t'''\n\n\tfull_name = str(inspect.getmodule(f))+\".\"+f.__name__\n\tstart_time = timeit.default_timer()\n\tprint((\"-\"*5+\"Start timing\"+\"-\"*5+\"\\n\"+full_name+\"\\n\"+\"-\"*20))\n\t\n\tout = f(*args,**kwargs)\n\t\n\tdt =timeit.default_timer() - start_time\n\tprint((\"-\"*20))\n\tprint((\"Executed in: {1}\\n[{0}]\".format(full_name,dt)))\n\tprint((\"-\"*20))\n\treturn out,dt",
  "class Ipython():\n    def __init__(self, scripts_path=''):\n        self.kernel_manager = QtInProcessKernelManager()\n        self.kernel_manager.start_kernel()\n        self.kernel = self.kernel_manager.kernel\n        sys.stdout = self.kernel.stdout\n        sys.stderr = self.kernel.stderr\n\n        self.scripts_path = scripts_path\n        self.kernel.gui = 'qt4'\n\n        self.kernel_client = self.kernel_manager.client()\n        self.kernel_client.start_channels()\n\n        self.control = RichJupyterWidget()\n        self.control.kernel_manager = self.kernel_manager\n        self.control.kernel_client = self.kernel_client\n        self.control.exit_requested.connect(self.stop)\n\n        self.control.setWindowTitle(\"IPython shell\")\n\n        self.execute('import numpy as np')\n        self.execute('from matplotlib import pyplot as plt')\n        self.execute('%matplotlib')\n        self.execute('')\n\n    def __del__(self):\n        self.stop()\n        self.close()\n\n    def show(self):\n        self.control.show()\n\n        self.control.setWindowState(\n            self.control.windowState() & ~QtCore.Qt.WindowMinimized | QtCore.Qt.WindowActive)\n        self.control.activateWindow()\n\n    def stop(self):\n        self.kernel_client.stop_channels()\n        self.kernel_manager.shutdown_kernel()\n\n    def close(self):\n        self.control.close()\n\n    def push(self, vardic):\n        self.kernel.shell.push(vardic)\n\n    def execute(self, cmd):\n        self.control.execute(cmd)\n\n    def run_script(self, scriptname):\n        scriptpath = os.path.join(self.scripts_path, scriptname)\n        return self.control.execute('run -i %s' % scriptpath)",
  "class QIPythonWidget(RichJupyterWidget):\n    \"\"\"\n    Convenience class for a live IPython console widget. We can replace the standard banner using the customBanner\n    argument. Modified from https://stackoverflow.com/questions/11513132/embedding-ipython-qt-console-in-a-pyqt-application\n    \"\"\"\n\n    def __init__(self, custom_banner=None, scripts_path='', *args, **kwargs):\n        if custom_banner is not None:\n            self.banner = custom_banner\n        self.scripts_path = scripts_path\n        super(QIPythonWidget, self).__init__(*args, **kwargs)\n        self.kernel_manager = kernel_manager = QtInProcessKernelManager()\n        kernel_manager.start_kernel()\n        kernel_manager.kernel.gui = 'qt'\n        self.kernel_client = kernel_client = self._kernel_manager.client()\n        kernel_client.start_channels()\n        self.kernel = self.kernel_manager.kernel\n        sys.stdout = self.kernel.stdout\n        sys.stderr = self.kernel.stderr\n\n        def stop():\n            kernel_client.stop_channels()\n            kernel_manager.shutdown_kernel()\n            guisupport.get_app_qt4().exit()\n\n        self.exit_requested.connect(stop)\n\n        self.execute_command(\"import numpy as np\")\n        self.execute_command(\"from matplotlib import pyplot as plt\")\n        self.execute_command(\"%matplotlib\")\n\n    def push_vars(self, variable_dict):\n        \"\"\" Given a dictionary containing name / value pairs, push those variables to the IPython console widget \"\"\"\n        self.kernel_manager.kernel.shell.push(variable_dict)\n\n    def clear(self):\n        \"\"\" Clears the terminal \"\"\"\n        self._control.clear()\n\n    def print_text(self, text):\n        \"\"\" Prints some plain text to the console \"\"\"\n        self._append_plain_text(text)\n\n    def execute_command(self, command):\n        \"\"\" Execute a command in the frame of the console widget \"\"\"\n        self._execute(command, False)\n\n    def run_script(self, scriptname):\n        try:\n            scriptpath = os.path.join(self.scripts_path, scriptname)\n            self._execute('run -i %s' % scriptpath, False)\n        except Exception as e:\n            print('Failed because ', e)",
  "def __init__(self, scripts_path=''):\n        self.kernel_manager = QtInProcessKernelManager()\n        self.kernel_manager.start_kernel()\n        self.kernel = self.kernel_manager.kernel\n        sys.stdout = self.kernel.stdout\n        sys.stderr = self.kernel.stderr\n\n        self.scripts_path = scripts_path\n        self.kernel.gui = 'qt4'\n\n        self.kernel_client = self.kernel_manager.client()\n        self.kernel_client.start_channels()\n\n        self.control = RichJupyterWidget()\n        self.control.kernel_manager = self.kernel_manager\n        self.control.kernel_client = self.kernel_client\n        self.control.exit_requested.connect(self.stop)\n\n        self.control.setWindowTitle(\"IPython shell\")\n\n        self.execute('import numpy as np')\n        self.execute('from matplotlib import pyplot as plt')\n        self.execute('%matplotlib')\n        self.execute('')",
  "def __del__(self):\n        self.stop()\n        self.close()",
  "def show(self):\n        self.control.show()\n\n        self.control.setWindowState(\n            self.control.windowState() & ~QtCore.Qt.WindowMinimized | QtCore.Qt.WindowActive)\n        self.control.activateWindow()",
  "def stop(self):\n        self.kernel_client.stop_channels()\n        self.kernel_manager.shutdown_kernel()",
  "def close(self):\n        self.control.close()",
  "def push(self, vardic):\n        self.kernel.shell.push(vardic)",
  "def execute(self, cmd):\n        self.control.execute(cmd)",
  "def run_script(self, scriptname):\n        scriptpath = os.path.join(self.scripts_path, scriptname)\n        return self.control.execute('run -i %s' % scriptpath)",
  "def __init__(self, custom_banner=None, scripts_path='', *args, **kwargs):\n        if custom_banner is not None:\n            self.banner = custom_banner\n        self.scripts_path = scripts_path\n        super(QIPythonWidget, self).__init__(*args, **kwargs)\n        self.kernel_manager = kernel_manager = QtInProcessKernelManager()\n        kernel_manager.start_kernel()\n        kernel_manager.kernel.gui = 'qt'\n        self.kernel_client = kernel_client = self._kernel_manager.client()\n        kernel_client.start_channels()\n        self.kernel = self.kernel_manager.kernel\n        sys.stdout = self.kernel.stdout\n        sys.stderr = self.kernel.stderr\n\n        def stop():\n            kernel_client.stop_channels()\n            kernel_manager.shutdown_kernel()\n            guisupport.get_app_qt4().exit()\n\n        self.exit_requested.connect(stop)\n\n        self.execute_command(\"import numpy as np\")\n        self.execute_command(\"from matplotlib import pyplot as plt\")\n        self.execute_command(\"%matplotlib\")",
  "def push_vars(self, variable_dict):\n        \"\"\" Given a dictionary containing name / value pairs, push those variables to the IPython console widget \"\"\"\n        self.kernel_manager.kernel.shell.push(variable_dict)",
  "def clear(self):\n        \"\"\" Clears the terminal \"\"\"\n        self._control.clear()",
  "def print_text(self, text):\n        \"\"\" Prints some plain text to the console \"\"\"\n        self._append_plain_text(text)",
  "def execute_command(self, command):\n        \"\"\" Execute a command in the frame of the console widget \"\"\"\n        self._execute(command, False)",
  "def run_script(self, scriptname):\n        try:\n            scriptpath = os.path.join(self.scripts_path, scriptname)\n            self._execute('run -i %s' % scriptpath, False)\n        except Exception as e:\n            print('Failed because ', e)",
  "def stop():\n            kernel_client.stop_channels()\n            kernel_manager.shutdown_kernel()\n            guisupport.get_app_qt4().exit()",
  "class FigureCanvasWithDeferredDraw(FigureCanvas):\n    # This class allows us to use Qt's event loop to draw the canvas from\n    # the GUI thread, even if the call comes from outside the GUI thread.\n    # this is necessary if you want to plot from a background thread.\n    ask_for_redraw = QtCore.Signal()\n    \n    def __init__(self, figure):\n        FigureCanvas.__init__(self, figure)\n        # We connect the ask_for_redraw signal to the FigureCanvas's draw() method.\n        # using a QueuedConnection ensures that draw() is correctly called in the\n        # application's main GUI thread.\n        self.ask_for_redraw.connect(self.draw, type=QtCore.Qt.QueuedConnection)\n\n    def draw_in_main_loop(self):\n        \"\"\"Draw the canvas, but do so in the Qt main loop to avoid threading nasties.\"\"\"\n        self.ask_for_redraw.emit()",
  "class _MPLFigureEditor(Editor):\n\n    scrollable = True\n\n    def init(self, parent):\n        self.control = self._create_canvas(parent)\n        self.set_tooltip()\n\n    def update_editor(self):\n        pass\n\n    def _create_canvas(self, parent):\n        \"\"\" Create the MPL canvas. \"\"\"\n        # matplotlib commands to create a canvas\n        mpl_canvas = FigureCanvasWithDeferredDraw(self.value)\n        return mpl_canvas",
  "class MPLFigureEditor(BasicEditorFactory):\n    klass = _MPLFigureEditor",
  "def __init__(self, figure):\n        FigureCanvas.__init__(self, figure)\n        # We connect the ask_for_redraw signal to the FigureCanvas's draw() method.\n        # using a QueuedConnection ensures that draw() is correctly called in the\n        # application's main GUI thread.\n        self.ask_for_redraw.connect(self.draw, type=QtCore.Qt.QueuedConnection)",
  "def draw_in_main_loop(self):\n        \"\"\"Draw the canvas, but do so in the Qt main loop to avoid threading nasties.\"\"\"\n        self.ask_for_redraw.emit()",
  "def init(self, parent):\n        self.control = self._create_canvas(parent)\n        self.set_tooltip()",
  "def update_editor(self):\n        pass",
  "def _create_canvas(self, parent):\n        \"\"\" Create the MPL canvas. \"\"\"\n        # matplotlib commands to create a canvas\n        mpl_canvas = FigureCanvasWithDeferredDraw(self.value)\n        return mpl_canvas",
  "class Test(HasTraits):\n\n        figure = Instance(Figure, ())\n        n = Int(11)\n        a = Float(0.5)\n\n        view = View(Item('figure', editor=MPLFigureEditor(),\n                         show_label=False),\n                    Item('n'),\n                    Item('a'),\n                    width=400,\n                    height=300,\n                    resizable=True)\n\n        def __init__(self):\n            super(Test, self).__init__()\n            axes = self.figure.add_subplot(111)\n            self._t = linspace(0, 2 * pi, 200)\n            self.plot()\n\n        @on_trait_change('n,a')\n        def plot(self):\n            t = self._t\n            a = self.a\n            n = self.n\n            axes = self.figure.axes[0]\n            if not axes.lines:\n                axes.plot(sin(t) * (1 + a * cos(n * t)), cos(t) * (1 + a * cos(n * t)))\n            else:\n                l = axes.lines[0]\n                l.set_xdata(sin(t) * (1 + a * cos(n * t)))\n                l.set_ydata(cos(t) * (1 + a * cos(n * t)))\n            canvas = self.figure.canvas\n            if canvas is not None:\n                canvas.draw()",
  "def __init__(self):\n            super(Test, self).__init__()\n            axes = self.figure.add_subplot(111)\n            self._t = linspace(0, 2 * pi, 200)\n            self.plot()",
  "def plot(self):\n            t = self._t\n            a = self.a\n            n = self.n\n            axes = self.figure.axes[0]\n            if not axes.lines:\n                axes.plot(sin(t) * (1 + a * cos(n * t)), cos(t) * (1 + a * cos(n * t)))\n            else:\n                l = axes.lines[0]\n                l.set_xdata(sin(t) * (1 + a * cos(n * t)))\n                l.set_ydata(cos(t) * (1 + a * cos(n * t)))\n            canvas = self.figure.canvas\n            if canvas is not None:\n                canvas.draw()",
  "def plot_skewed_image(image, corners, axes=None, *args, **kwargs):\n    \"\"\"Plot an image in a quadrilateral that has the given corners.\n    \n    Unfortunately, images plotted with the (very fast) imshow method must be\n    bounded by a rectangle with sides parallel to the axes.  This method allows\n    images to be plotted in an arbitrary quadrilateral, useful (for example) if\n    we want to plot images in units of stage displacement.\n    \n    @param: ax: A matplotlib axes object in which to plot the image\n    @param: image: An image, stored as an NxM or NxMx3 array\n    @param: corners: Coordinates of the corners of the array in the order\n    [bottom left, top left, bottom right, top right] as a list of tuples or a\n    4x2 array.\n    \n    Extra arguments/keyword arguments are passed to axes.pcolormesh\n    \"\"\"\n    shape = image.shape\n    assert len(shape) == 2 or (len(shape) == 3 and (shape[2] == 3 or shape[2] == 4)), \"the image argument must have shape (N*M) or (N*M*3) or (N*M*4).\"                   \n    \n    if axes is None:\n        axes = plt.gca()\n    #First, we need to generate the coordinates of the vertices.  Start by\n    #putting the corner coordinates in a 2x2x2 array\n    assert np.array(corners).shape == (4,2), \"The 'corners' argument must be four two-element positions, i.e. have shape (4, 2)\"\n    corner_coordinate_array = np.array(corners).reshape((2,2,2))\n    #now, we \"zoom\" this array using bilinear interpolation (order=1) so that\n    #it has the correct dimensions - one greater than the size of the image.\n    coordinate_array = ndimage.zoom(corner_coordinate_array,\n                                    (old_div((shape[0]+1),2),old_div((shape[1]+1),2),1),\n                                    order=1)\n    if len(shape)==2: #grayscale image\n        mesh = ax.pcolormesh(coordinate_array[:,:,0],\n                             coordinate_array[:,:,1],\n                             image,\n                             *args\n                             **kwargs)\n    else:\n        #Sadly, pcolormesh doesn't seem to do RGB.  The work-around is to first\n        #plot a monochrome image, then set the color for each pixel later.\n        mesh = ax.pcolormesh(coordinate_array[:,:,0],\n                      coordinate_array[:,:,1],\n                      image[:,:,0],\n                      *args,\n                      **kwargs)\n        #we need to pass the colors as a flattened array of (R,G,B).  Worse,\n        #these need to be floating point values between 0 and 1!\n        if image.dtype == np.dtype('uint8'):\n            divisor = 255.0\n        elif image.dtype == np.dtype('uint16'):\n            divisor = 65535.0\n        elif image.max() <= 1.0:\n            divisor = 1.0\n        else:\n            divisor = image.max()\n            \n        mesh.set_color(old_div(image.reshape((shape[0]*shape[1],shape[2])),divisor))",
  "class RefractiveIndexInfoDatabase(object):\n\n\tdef __init__(self):\n\t\t#load library:\n\t\tdirpath =  os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n\t\tlibrary_path = os.path.normpath(dirpath+\"/refractive_index_db_lib.yml\")\n\t\t#print library_path\n\t\twith open(library_path,\"r\") as file:\n\t\t\tlibrary = yaml.load(file.read())\n\t\t\t#loading library file from online location:\n\t\t\t# library_url = \"https://raw.githubusercontent.com/imanyakin/refractiveindex.info-database/master/database/library.yml\"\n\t\t\t# response = requests.get(library_url)\n\t\t\t# library = yaml.load(response._content)\n\t\t\tcls = self.__class__\n\t\t\tdata = cls.get_data(library)\n\t\t\tdata_dict = cls.make_dict(data)\n\n\t\t\t#self test on start\n\t\t\tcls.test_converse_reversibility(data)\n\t\t\tdataset = cls.fetch_dataset_yaml(data[0])\n#\t\t\tprint cls.extract_refractive_indices(dataset)\n\n\t@classmethod\n\tdef get_data(cls,it):\n\t\t'''\n\t\tExtract \"data\" labels from the library.yml file.\n\t\tEach item labelled as \"data\" is a path that can be accessed through internet\n\t\t:param it - iterable (list/dict) of the yaml file\n\t\t'''\n\t\t\n\t\tif type(it) == list:\n\t\t\toutp = []\n\t\t\tfor i in it:\n\t\t\t\toutp = outp + cls.get_data(i)\n\t\t\treturn outp\n\t\t\t# return [get_data(i) for i in it]\n\t\telif type(it) == dict:\n\t\t\toutp = []\n\t\t\tif \"content\" in list(it.keys()):\n\t\t\t\toutp = outp + cls.get_data(it[\"content\"])\n\t\t\tif \"data\" in list(it.keys()):\n\t\t\t\toutp = outp + [it[\"data\"]]\n\t\treturn outp\n\n\t@classmethod\n\tdef make_dict(cls,data):\n\t\t'''\n\t\tConvert list of labels in A/B/C into a tree structured dict\n\t\tLeaf nodes in tree are either lists of labels or are terminated in an empty dict\n\n\t\t'''\n\n\t\t#set up output dict\n\t\toutp = dict()\n\t\t#leys\n\t\tkeys = set([d.split(\"/\")[0] for d in data])\n\t\t\n\n\t\tfor k in keys:\n\t\t\tvalues = []\n\t\t\tfor d in data:\n\t\t\t\tif k == d.split(\"/\")[0]:\n\t\t\t\t\tvalue = \"/\".join(d.split(\"/\")[1:])\n\t\t\t\t\tif len(value)>0:\n\t\t\t\t\t\tvalues.append(value)\n\t\t\toutp.update({k:RefractiveIndexInfoDatabase.make_dict(values)})\n\n\t\t#if all values of output dict are empty lists - collapse dict\n\t\tif all(len(v)==0 for v in list(outp.values())):\n\t\t\treturn list(outp.keys())\n\t\telse:\n\t\t\treturn outp\n\n\t@classmethod\n\tdef make_data(cls,iterable):\n\t\t'''\n\t\tInverse of make_dict, converts from a tree structured dictionary to a list of labels in A/B/C format\n\t\t'''\n\n\t\tif type(iterable) == list:\n\t\t\tif len(iterable) > 0:\n\t\t\t\treturn iterable\n\t\t\telse:\n\t\t\t\treturn ''\n\t\telif type(iterable) == dict:\n\t\t\toutp = []\n\t\t\tfor k in list(iterable.keys()):\n\t\t\t\tvalues = RefractiveIndexInfoDatabase.make_data(iterable[k])\n\t\t\t\tif len(values) > 0:\n\t\t\t\t\tfor v in values:\n\t\t\t\t\t\toutp = outp + [\"/\".join([k,v])]\n\t\t\t\telse:\n\t\t\t\t\toutp = outp + [k]\n\t\t\treturn outp\n\n\t#for testing correct conversion of data --> dict --> data, must preserve all labels\n\t@classmethod\n\tdef test_converse_reversibility(cls,data):\n\n\t\t'''\n\t\tTest code for correct implementation if inverse transformation make_data, make_dict\n\n\t\tperforms: data --> make_dict(data) --> make_data(make_dict(data)) --> data2\n\t\tif operations are inverse then for all elements d1 in data there is a element d2 in data2 \n\t\t'''\n\n\t\titerable = RefractiveIndexInfoDatabase.make_dict(data)\n\t\tdata2 = RefractiveIndexInfoDatabase.make_data(iterable)\n\n\t\tfor d in data:\n\t\t\tassert (d in data2)\n\t\tfor d in data2:\n\t\t\tassert(d in data)\n\n\t\n\t@classmethod\n\tdef fetch_dataset_yaml(cls,label):\n\t\t'''\n\t\tGets, via HTTP, the yaml file containg hte dataset from the website\n\t\tReturns a yaml structured list (yaml is superset of JSON)\n\t\t'''\n\t\tquery_base_url = \"https://refractiveindex.info/database/data/{0}\"\n\t\turl = query_base_url.format(label)\n\t\tresp =  requests.get(url)\n\n\t\tresponse_yaml = yaml.load(resp._content)\n\t\treturn response_yaml\n\n\t@classmethod\n\tdef extract_refractive_indices(cls,response_yaml):\n\t\t'''\n\t\tExtract the wavelengths and refractive indices from a yaml response\n\t\t'''\n\t\tdata = (response_yaml[\"DATA\"][0][\"data\"]).split(\"\\n\")\n\t\twavelengths = []\n\t\trefractive_index = []\n\t\tfor d in data:\n\t\t\ttry:\n\t\t\t\t[w,n,k] = d.split(\" \")\n\t\t\t\twavelengths.append(float(w))\n\t\t\t\trefractive_index.append(float(n) + 1j*float(k))\n\t\t\texcept:\n\t\t\t\ttry:\n\t\t\t\t\t[w,n] = d.split(\" \")\n\t\t\t\t\twavelengths.append(float(w))\n\t\t\t\t\trefractive_index.append(float(n))\n\t\t\t\texcept:\n\t\t\t\t\tprint(\"failed on: ({})\".format(d))\n\t\treturn {\"wavelength\":wavelengths, \"n\": refractive_index}\n\n\t@classmethod\n\tdef refractive_index_generator(cls,label):\n\t\t'''\n\t\tMain method for use. Pulls data from website, transforms it into a dataset\n\t\tReturns function that can be queried.\n\t\tFunction will interpolate between data within a certain range of wavelengths and will crash if required wavelength is outside of this range\n\t\t'''\n\n\t\tdataset_yaml = cls.fetch_dataset_yaml(label)\n\t\tdataset = cls.extract_refractive_indices(dataset_yaml)\n\n\t\twavelengths = dataset[\"wavelength\"]\n\t\tmin_wl = 1e-6*np.min(wavelengths) \n\t\tmax_wl = 1e-6*np.max(wavelengths) \n\t\t\n#\t\tprint \"Min Wavelength in dataset:\", min_wl\n#\t\tprint \"Max Wavelength in dataset:\", max_wl\n\t\tdef generator(required_wavelength,scale=\"nm\",debug=0):\n\n\t\t\tassert(scale==\"nm\") #scale must be in nm - other values may be supported later if required\n\t\t\t#Performs linear interpolation between values in dataset to generate refractive indices over wavelength range spanned by dataset\n\t\t\tif required_wavelength < min_wl:\n\t\t\t\traise ValueError(\"Required wavelength: {0} below minimum in dataset: {1}\".format(required_wavelength,min_wl))\n\n\t\t\telif required_wavelength > max_wl:\n\t\t\t\traise ValueError(\"Required wavelength: {0} above maximum in dataset: {1}\".format(required_wavelength,max_wl))\n\n\t\t\telse:\n\t\t\t\toutput_n = np.interp(required_wavelength*1e6,xp=dataset[\"wavelength\"],fp=dataset[\"n\"])\n\t\t\t\tif debug > 0:\n\t\t\t\t\tprint(\"--- DEBUG Interpolation---\")\n\t\t\t\t\tprint(\"Wavelen: {0}, Refractive_index: {1}\".format(required_wavelength,output_n))\n\t\t\t\treturn output_n\n\n\t\treturn generator",
  "def __init__(self):\n\t\t#load library:\n\t\tdirpath =  os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n\t\tlibrary_path = os.path.normpath(dirpath+\"/refractive_index_db_lib.yml\")\n\t\t#print library_path\n\t\twith open(library_path,\"r\") as file:\n\t\t\tlibrary = yaml.load(file.read())\n\t\t\t#loading library file from online location:\n\t\t\t# library_url = \"https://raw.githubusercontent.com/imanyakin/refractiveindex.info-database/master/database/library.yml\"\n\t\t\t# response = requests.get(library_url)\n\t\t\t# library = yaml.load(response._content)\n\t\t\tcls = self.__class__\n\t\t\tdata = cls.get_data(library)\n\t\t\tdata_dict = cls.make_dict(data)\n\n\t\t\t#self test on start\n\t\t\tcls.test_converse_reversibility(data)\n\t\t\tdataset = cls.fetch_dataset_yaml(data[0])",
  "def get_data(cls,it):\n\t\t'''\n\t\tExtract \"data\" labels from the library.yml file.\n\t\tEach item labelled as \"data\" is a path that can be accessed through internet\n\t\t:param it - iterable (list/dict) of the yaml file\n\t\t'''\n\t\t\n\t\tif type(it) == list:\n\t\t\toutp = []\n\t\t\tfor i in it:\n\t\t\t\toutp = outp + cls.get_data(i)\n\t\t\treturn outp\n\t\t\t# return [get_data(i) for i in it]\n\t\telif type(it) == dict:\n\t\t\toutp = []\n\t\t\tif \"content\" in list(it.keys()):\n\t\t\t\toutp = outp + cls.get_data(it[\"content\"])\n\t\t\tif \"data\" in list(it.keys()):\n\t\t\t\toutp = outp + [it[\"data\"]]\n\t\treturn outp",
  "def make_dict(cls,data):\n\t\t'''\n\t\tConvert list of labels in A/B/C into a tree structured dict\n\t\tLeaf nodes in tree are either lists of labels or are terminated in an empty dict\n\n\t\t'''\n\n\t\t#set up output dict\n\t\toutp = dict()\n\t\t#leys\n\t\tkeys = set([d.split(\"/\")[0] for d in data])\n\t\t\n\n\t\tfor k in keys:\n\t\t\tvalues = []\n\t\t\tfor d in data:\n\t\t\t\tif k == d.split(\"/\")[0]:\n\t\t\t\t\tvalue = \"/\".join(d.split(\"/\")[1:])\n\t\t\t\t\tif len(value)>0:\n\t\t\t\t\t\tvalues.append(value)\n\t\t\toutp.update({k:RefractiveIndexInfoDatabase.make_dict(values)})\n\n\t\t#if all values of output dict are empty lists - collapse dict\n\t\tif all(len(v)==0 for v in list(outp.values())):\n\t\t\treturn list(outp.keys())\n\t\telse:\n\t\t\treturn outp",
  "def make_data(cls,iterable):\n\t\t'''\n\t\tInverse of make_dict, converts from a tree structured dictionary to a list of labels in A/B/C format\n\t\t'''\n\n\t\tif type(iterable) == list:\n\t\t\tif len(iterable) > 0:\n\t\t\t\treturn iterable\n\t\t\telse:\n\t\t\t\treturn ''\n\t\telif type(iterable) == dict:\n\t\t\toutp = []\n\t\t\tfor k in list(iterable.keys()):\n\t\t\t\tvalues = RefractiveIndexInfoDatabase.make_data(iterable[k])\n\t\t\t\tif len(values) > 0:\n\t\t\t\t\tfor v in values:\n\t\t\t\t\t\toutp = outp + [\"/\".join([k,v])]\n\t\t\t\telse:\n\t\t\t\t\toutp = outp + [k]\n\t\t\treturn outp",
  "def test_converse_reversibility(cls,data):\n\n\t\t'''\n\t\tTest code for correct implementation if inverse transformation make_data, make_dict\n\n\t\tperforms: data --> make_dict(data) --> make_data(make_dict(data)) --> data2\n\t\tif operations are inverse then for all elements d1 in data there is a element d2 in data2 \n\t\t'''\n\n\t\titerable = RefractiveIndexInfoDatabase.make_dict(data)\n\t\tdata2 = RefractiveIndexInfoDatabase.make_data(iterable)\n\n\t\tfor d in data:\n\t\t\tassert (d in data2)\n\t\tfor d in data2:\n\t\t\tassert(d in data)",
  "def fetch_dataset_yaml(cls,label):\n\t\t'''\n\t\tGets, via HTTP, the yaml file containg hte dataset from the website\n\t\tReturns a yaml structured list (yaml is superset of JSON)\n\t\t'''\n\t\tquery_base_url = \"https://refractiveindex.info/database/data/{0}\"\n\t\turl = query_base_url.format(label)\n\t\tresp =  requests.get(url)\n\n\t\tresponse_yaml = yaml.load(resp._content)\n\t\treturn response_yaml",
  "def extract_refractive_indices(cls,response_yaml):\n\t\t'''\n\t\tExtract the wavelengths and refractive indices from a yaml response\n\t\t'''\n\t\tdata = (response_yaml[\"DATA\"][0][\"data\"]).split(\"\\n\")\n\t\twavelengths = []\n\t\trefractive_index = []\n\t\tfor d in data:\n\t\t\ttry:\n\t\t\t\t[w,n,k] = d.split(\" \")\n\t\t\t\twavelengths.append(float(w))\n\t\t\t\trefractive_index.append(float(n) + 1j*float(k))\n\t\t\texcept:\n\t\t\t\ttry:\n\t\t\t\t\t[w,n] = d.split(\" \")\n\t\t\t\t\twavelengths.append(float(w))\n\t\t\t\t\trefractive_index.append(float(n))\n\t\t\t\texcept:\n\t\t\t\t\tprint(\"failed on: ({})\".format(d))\n\t\treturn {\"wavelength\":wavelengths, \"n\": refractive_index}",
  "def refractive_index_generator(cls,label):\n\t\t'''\n\t\tMain method for use. Pulls data from website, transforms it into a dataset\n\t\tReturns function that can be queried.\n\t\tFunction will interpolate between data within a certain range of wavelengths and will crash if required wavelength is outside of this range\n\t\t'''\n\n\t\tdataset_yaml = cls.fetch_dataset_yaml(label)\n\t\tdataset = cls.extract_refractive_indices(dataset_yaml)\n\n\t\twavelengths = dataset[\"wavelength\"]\n\t\tmin_wl = 1e-6*np.min(wavelengths) \n\t\tmax_wl = 1e-6*np.max(wavelengths) \n\t\t\n#\t\tprint \"Min Wavelength in dataset:\", min_wl\n#\t\tprint \"Max Wavelength in dataset:\", max_wl\n\t\tdef generator(required_wavelength,scale=\"nm\",debug=0):\n\n\t\t\tassert(scale==\"nm\") #scale must be in nm - other values may be supported later if required\n\t\t\t#Performs linear interpolation between values in dataset to generate refractive indices over wavelength range spanned by dataset\n\t\t\tif required_wavelength < min_wl:\n\t\t\t\traise ValueError(\"Required wavelength: {0} below minimum in dataset: {1}\".format(required_wavelength,min_wl))\n\n\t\t\telif required_wavelength > max_wl:\n\t\t\t\traise ValueError(\"Required wavelength: {0} above maximum in dataset: {1}\".format(required_wavelength,max_wl))\n\n\t\t\telse:\n\t\t\t\toutput_n = np.interp(required_wavelength*1e6,xp=dataset[\"wavelength\"],fp=dataset[\"n\"])\n\t\t\t\tif debug > 0:\n\t\t\t\t\tprint(\"--- DEBUG Interpolation---\")\n\t\t\t\t\tprint(\"Wavelen: {0}, Refractive_index: {1}\".format(required_wavelength,output_n))\n\t\t\t\treturn output_n\n\n\t\treturn generator",
  "def generator(required_wavelength,scale=\"nm\",debug=0):\n\n\t\t\tassert(scale==\"nm\") #scale must be in nm - other values may be supported later if required\n\t\t\t#Performs linear interpolation between values in dataset to generate refractive indices over wavelength range spanned by dataset\n\t\t\tif required_wavelength < min_wl:\n\t\t\t\traise ValueError(\"Required wavelength: {0} below minimum in dataset: {1}\".format(required_wavelength,min_wl))\n\n\t\t\telif required_wavelength > max_wl:\n\t\t\t\traise ValueError(\"Required wavelength: {0} above maximum in dataset: {1}\".format(required_wavelength,max_wl))\n\n\t\t\telse:\n\t\t\t\toutput_n = np.interp(required_wavelength*1e6,xp=dataset[\"wavelength\"],fp=dataset[\"n\"])\n\t\t\t\tif debug > 0:\n\t\t\t\t\tprint(\"--- DEBUG Interpolation---\")\n\t\t\t\t\tprint(\"Wavelen: {0}, Refractive_index: {1}\".format(required_wavelength,output_n))\n\t\t\t\treturn output_n",
  "def f_ratio(f,d):\n\treturn float(f)/d",
  "def numerical_aperture(alpha,n=1.0):\n\treturn n*np.sin(alpha)",
  "def numerical_aperture(r,x,n=1.0):\n\treturn n*(float(r)/x)",
  "def x_from_radius(f,r):\n\treturn np.sqrt(r**2 + f**2)",
  "def x_from_diameter(f,d):\n\treturn \tx_from_radius(f,d/2.0)",
  "def alpha_from_radius(f,r):\n\tx = x_from_radius(f,r)\n\treturn cmath.asin(np.float(r)/x)%(2*np.pi)",
  "def alpha_from_diameter(f,d):\n\tr = d/2.0\n\treturn alpha_from_radius(f,r)",
  "def get_unit_string(obj, default=None, warn=False, fail=False):\n    \"\"\"Return a string representation of an object's units.\n    \n    This function returns obj.attrs.get('units') with no processing, or it\n    converts the units of a Quantity object to a string and returns that.  The\n    output should be suitable for saving to an HDF5 file.\"\"\"\n    try:\n        return obj.attrs.get('units') #this works for things with attrs\n    except AttributeError:\n        try:\n            return str(obj.units) #this works for Quantities\n        except:\n            if warn:\n                print(\"Warning: no unit string found on \" + str(obj))\n            if fail:\n                raise ValueError(\"No unit information was found on \" + str(obj))\n            return default",
  "def unit_to_string(quantity):\n    \"\"\"Converts a quantity (used for units) to a string for saving or display.\n    \n    The only thing this does over and above str(quantity) is stripping the\n    initial \"1 \" where the magnitude is unity.\n    \"\"\"\n    if quantity.magnitude == 1:\n        return str(quantity.units)\n    else:\n        return str(quantity)",
  "def get_units(obj, default=None, warn=False):\n    \"\"\"Return the units from an object as a pint Quantity.\n    \n    The object can be either an ArrayWithAttrs (i.e. obj.attrs.get('units') is\n    a string with the units) or a pint Quantity object.  In both cases, we\n    return a pint Quantity object.  If the input was a Quantity, the object\n    will have a magnitude of one, while if the input is an array it's possible\n    for the magnitude not to be one (this allows arrays to be saved in odd\n    units, like \"100 nm\" which can be useful if it's in camera pixels, for\n    example.\"\"\"\n\n    try:\n        if isinstance(obj, ureg.Quantity):\n            return ureg.Quantity(1, obj.units) #if we have a Quantity, return its units\n        else:\n            unit_string = get_unit_string(obj, fail=True) #look for a units attribute\n            return ureg(unit_string) #convert to a pint unit\n    except:\n        if warn:\n            print(\"Warning: no units found on \" + str(obj))\n        if default is not None:\n            return ensure_unit(default)\n        else:\n            raise ValueError(\"No unit information could be found on \" + str(obj) + \" (it should either have an attrs dict with a 'units' attribute, or be a Quantity).\")",
  "def array_with_units(obj, units):\n    \"\"\"Bundle an object as an ArrayWithAttrs having a \"units\" attribute.\"\"\"\n    ret = ensure_attrs(obj)\n    ret.attrs.create('units', str(units))\n    return ret",
  "def ensure_unit(obj):\n    \"\"\"Ensure an object is a unit (i.e. a pint quantity).\n    \n    Strings will be converted to units if possible, and UnitsContainers will be\n    turned back into Quantities.\"\"\"\n    if isinstance(obj, ureg.Quantity):\n        return obj #if it's a quantity, we're good.\n    else:\n        return ureg(str(obj))",
  "def convert_quantity(obj, dest_units, default=None, warn=True, return_quantity=False):\n    \"\"\"Return a copy of obj in the required units.\"\"\"\n    if ensure_unit(dest_units)==get_units(obj, default=default, warn=False):\n        return obj #make sure objects are returned unchanged if units match\n    if isinstance(obj, ureg.Quantity):\n        q = obj\n    else:\n        #convert the object to a Quantity\n        fu = get_units(obj, default=default, warn=warn)\n        q = old_div(ureg.Quantity(obj, fu.units),fu.magnitude)\n    du = ensure_unit(dest_units)\n    rq = old_div(q.to(du.units), du.magnitude)\n    if return_quantity:\n        return rq\n    else:\n        return rq.magnitude",
  "def engineering_format(number, base_unit='', significant_figures=None, digits_of_precision=None,\n                       print_errors=False):\n    \"\"\"Format a number into a string using SI prefixes.\"\"\"\n    assert not (significant_figures is not None and digits_of_precision is not None), \"You may not specify both the number of digits of precision and the number of significant digits.\"\n    if significant_figures is None and digits_of_precision is None:\n        digits_of_precision = 3 #default to 3 significant figures\n    \n    incPrefixes = ['', 'k', 'M', 'G', 'T', 'P', 'E', 'Z', 'Y']\n    decPrefixes = ['', 'm', 'u', 'n', 'p', 'f', 'a', 'z', 'y']\n    \n    if number == 0:\n        return \"0 \"+base_unit\n    else:\n        exponent = int(np.floor(old_div(np.log10(np.abs(number)),3)))*3 #first power-of-three exponent smaller than number\n        mantissa = float(number) / 10**exponent\n        try:\n            if exponent >= 0:\n                prefix = incPrefixes[old_div(exponent,3)]\n            else:\n                prefix = decPrefixes[old_div(-exponent,3)]\n        except IndexError:\n            if print_errors:\n                print(\"mantissa\",mantissa,\"exponent\",exponent)\n            raise ValueError(\"The number provided was too big (or too small) to convert to an SI prefix!\")\n    return \"%.{0}g %s%s\".format(digits_of_precision) % (mantissa,prefix,base_unit)",
  "class inherit_docstring():\n    \"\"\"Appends the current functions docstring with that of the specified base function\"\"\"\n    def __init__(self, base_f):\n        self.base_f = base_f\n\n    def __call__(self, f):\n        # if the base function has no docstring then do nothing\n        if self.base_f.__doc__ is None:\n            return f\n        # using new lines is not necessary if there is no current docstring to separate\n        if f.__doc__ is None:\n            f.__doc__ = self.base_f.__doc__\n        elif f.__doc__ == '':\n            f.__doc__ += self.base_f.__doc__\n        # if there is a docstring in both the current function and the base function\n        # then the new docstring will include both docstrings separated by an empty line\n        else:\n            f.__doc__ += '\\n\\n'+self.base_f.__doc__\n        return f",
  "def __init__(self, base_f):\n        self.base_f = base_f",
  "def __call__(self, f):\n        # if the base function has no docstring then do nothing\n        if self.base_f.__doc__ is None:\n            return f\n        # using new lines is not necessary if there is no current docstring to separate\n        if f.__doc__ is None:\n            f.__doc__ = self.base_f.__doc__\n        elif f.__doc__ == '':\n            f.__doc__ += self.base_f.__doc__\n        # if there is a docstring in both the current function and the base function\n        # then the new docstring will include both docstrings separated by an empty line\n        else:\n            f.__doc__ += '\\n\\n'+self.base_f.__doc__\n        return f",
  "class A(object):\n        def foo(self, x):\n            \"\"\"Docstring for A\"\"\"\n            return x+1",
  "class B(A):\n        @inherit_docstring(A.foo)\n        def foo(self, x):\n            return x+2",
  "class C(B):\n        @inherit_docstring(B.foo)\n        def foo(self, x):\n            \"\"\"Docstring for C\"\"\"\n            return x+3",
  "def foo(self, x):\n            \"\"\"Docstring for A\"\"\"\n            return x+1",
  "def foo(self, x):\n            return x+2",
  "def foo(self, x):\n            \"\"\"Docstring for C\"\"\"\n            return x+3",
  "class GuiGenerator(QtWidgets.QMainWindow, UiTools):\n    \"\"\"A object for generating a main gui through stitching together multiple guis \n    by the generation of dock widgets, this allow the user to create a save a custom\n    gui without all of the hard work\n    \"\"\"\n\n    def __init__(self, instrument_dict, parent=None, dock_settings_path=None,\n                 scripts_path=None, working_directory=None, file_path=None,\n                 terminal=False, dark=False):  \n        \"\"\"Args:\n            instrument_dict(dict) :     This is a dictionary containing the\n                                        instruments objects where the key is the \n                                        objects new name in the generated new Ipython \n                                        console\n            dock_settings_path(str):    A path for loading a previous dock widget\n                                        configuration\n            scripts_path(str):          The path of any scripts the user may want to\n                                        run using the drop down menu at the top\n                                        of the gui\n            working_directory(str):     A path to the requested working directory - \n                                        handy if you always wish to save data to \n                                        the same directories\n            file_path(str):             A path to the file for saving data. If None,\n                                        a dialog will ask for one. Can be a relative\n                                        path (from working_directory) or an absolute path\n            terminal(bool):             Specifies whether the generated gui has an ipython \n                                        console. Sripts ran in an ipython console cannot \n                                        generate another one.\n                                \"\"\"\n        super(GuiGenerator, self).__init__(parent)\n        self._logger = LOGGER\n        self.instr_dict = instrument_dict\n        if working_directory is None:\n            self.working_directory = os.path.join(os.getcwd())\n        else:\n            self.working_directory = working_directory\n        if file_path is None:\n            self.data_file = df.current(working_directory=working_directory)\n        elif os.path.isabs(file_path):\n            df.set_current(file_path)\n            self.data_file = df.current()\n        else:\n            df.set_current(self.working_directory + '/' + file_path)\n            self.data_file = df.current()\n\n        if dark:\n            app = get_qt_app()\n            app.setStyleSheet(qdarkstyle.load_stylesheet())\n        self.instr_dict[\"HDF5\"] = self.data_file\n        self.setDockNestingEnabled(1)\n\n        self.load_ui_from_file(__file__, 'guigenerator.ui')\n\n        self.allDocks = {}\n        self.allWidgets = {}\n        self.actions = dict(Views={}, Instruments={})\n\n        self.dockwidgetArea = pyqtgraph.dockarea.DockArea()\n        self.dockWidgetArea = self.replace_widget(self.verticalLayout, self.centralWidget(), self.dockwidgetArea)\n        self.dockWidgetAllInstruments.setWidget(self.dockwidgetArea)\n        self.dockWidgetAllInstruments.setTitleBarWidget(QtWidgets.QWidget())  # This trick makes the title bar disappear\n\n        # Iterate over all the opened instruments. If the instrument has a GUI (i.e. if they have the get_qt_ui function\n        # defined inside them), then create a pyqtgraph.Dock for it and add its widget to the Dock. Also prints out any\n        # instruments that do not have GUIs\n        self._logger.info('Opening all GUIs')\n\n        for instr in self.instr_dict:\n            self._open_one_gui(instr)\n            \n        self.script_menu = None\n        if scripts_path is not None:\n            self.scripts_path = scripts_path\n        else:\n            self.scripts_path = 'scripts'\n        sys.path.append(self.scripts_path)\n        self.terminalWindow = None\n        self.terminal = terminal\n        if terminal:\n            self.menuTerminal()\n            self._addActionViewMenu('Terminal')\n        self.terminal = terminal\n        self.makeScriptMenu()\n\n        self.NightMode = 1\n\n        # address of h5 file\n        self.filename = df.current().filename\n\n        self._setupSignals()\n        if dock_settings_path is not None:\n            self.dock_settings_path = dock_settings_path\n            self.menuLoadSettings()\n        else:\n            self.dock_settings_path = None\n        self.showMaximized()\n\n    def __getattribute__(self, name):  # All instruments log function and method calls at debugging level\n\n        returned = QtCore.QObject.__getattribute__(self, name)\n        if inspect.isfunction(returned) or inspect.ismethod(returned):\n            codeline = inspect.getsourcelines(returned)[1]\n            filename = inspect.getfile(returned)\n            self._logger.debug('Called %s on line %g of %s' % (returned.__name__, codeline, filename))\n        return returned\n\n    def _open_one_gui(self, instrument_name):\n        \"\"\"A command for opening a single Instruemnt guiand creating a dock through acquiring the \n        get_qt_ui function for a single panel or if invidual control and preview widgets\n        are possible then the get_control_widget and get_preview_widgets will be sed\n        \"\"\"\n        if hasattr(self.instr_dict[instrument_name], 'get_control_widget') or hasattr(self.instr_dict[instrument_name],\n                                                                                      'get_preview_widget'):\n            if hasattr(self.instr_dict[instrument_name], 'get_control_widget'):\n                self.allWidgets[instrument_name + ' controls'] = self.instr_dict[instrument_name].get_control_widget()\n                self.allDocks[instrument_name + ' controls'] = pyqtgraph.dockarea.Dock(instrument_name + ' controls')\n                self.dockwidgetArea.addDock(self.allDocks[instrument_name + ' controls'], 'left')\n                self.allDocks[instrument_name + ' controls'].addWidget(self.allWidgets[instrument_name + ' controls'])\n                self._addActionViewMenu(instrument_name + ' controls')\n            if hasattr(self.instr_dict[instrument_name], 'get_preview_widget'):\n                self.allWidgets[instrument_name + ' display'] = self.instr_dict[instrument_name].get_preview_widget()\n                self.allDocks[instrument_name + ' display'] = pyqtgraph.dockarea.Dock(instrument_name + ' display')\n                self.dockwidgetArea.addDock(self.allDocks[instrument_name + ' display'], 'left')\n                self.allDocks[instrument_name + ' display'].addWidget(self.allWidgets[instrument_name + ' display'])\n                self._addActionViewMenu(instrument_name + ' display')\n        elif hasattr(self.instr_dict[instrument_name], 'get_qt_ui'):\n            self.allWidgets[instrument_name] = self.instr_dict[instrument_name].get_qt_ui()\n            self.allDocks[instrument_name] = pyqtgraph.dockarea.Dock(instrument_name)\n            self.dockwidgetArea.addDock(self.allDocks[instrument_name], 'left')\n            self.allDocks[instrument_name].addWidget(self.allWidgets[instrument_name])\n            self._addActionViewMenu(instrument_name)\n        else:\n            self._logger.warn('%s does not have a get_qt_ui' % instrument_name)\n\n    def _addActionViewMenu(self, instr):\n        \"\"\"Create the actions menu - such as enabled and disabling gui's on the fly \"\"\"\n        if instr not in self.actions['Views']:\n            action = QtWidgets.QAction(instr, self)\n            self.menuView.addAction(action)\n            action.setCheckable(True)\n            action.setChecked(True)\n            action.triggered.connect(lambda: self._toggleView(instr))\n            self.actions['Views'][instr] = action\n\n    def _toggleView(self, instr):\n        \"\"\"A function for toggling a single gui \"\"\"\n        dock = self.allDocks[instr]\n        if self.actions['Views'][instr].isChecked():\n            self.dockwidgetArea.addDock(dock, 'left')\n            dock.show()\n            dock.showTitleBar()\n        else:\n            dock.close()\n\n    def _setupSignals(self):\n        \"\"\"Connect signals for the different general gui buttons/menu's \"\"\"\n        self.actionExit.triggered.connect(self.close)\n        self.actionNightMode.triggered.connect(self.toggleNightMode)\n        self.actionTerminal.triggered.connect(self.menuTerminal)\n        self.actionShowBrowser.triggered.connect(self.toggle_browser)\n        self.actionNewExperiment.triggered.connect(self.menuNewExperiment)\n        self.actionCloseExperiment.triggered.connect(self.menuCloseExperiment)\n        self.actionSaveExperiment.triggered.connect(self.menuSaveExperiment)\n        self.actionSaveSettings.triggered.connect(self.menuSaveSettings)\n        self.actionRecallSettings.triggered.connect(self.menuLoadSettings)\n        # For some reason the following does not work if put in a loop\n        actions = self.menuVerbose.actions()\n        actions[0].triggered.connect(lambda: self.VerboseChanged(actions[0]))\n        actions[1].triggered.connect(lambda: self.VerboseChanged(actions[1]))\n        actions[2].triggered.connect(lambda: self.VerboseChanged(actions[2]))\n\n    def toggle_browser(self):\n        \"\"\"enable or disable the file browser \"\"\"\n        self.actions['Views']['HDF5'].toggle()\n        self._toggleView('HDF5')\n\n    def toggleNightMode(self):\n        \"\"\"A function to switch all the colors to night mode - handy when working in an optics lab \"\"\"\n        try:\n            if self.actionNightMode.isChecked():\n                import qdarkstyle\n                self.setStyleSheet(qdarkstyle.load_stylesheet(pyside=False))\n            else:\n                self.setStyleSheet('')\n        except Exception as e:\n            print(e)\n            print('trying Qt 5')\n            try:\n                if self.actionNightMode.isChecked():\n                    import qdarkstyle\n                    self.setStyleSheet(qdarkstyle.load_stylesheet_pyqt5())\n                else:\n                    self.setStyleSheet('')\n            except Exception as ee:\n                print(ee)\n                print('Qt 5 style sheet failed')\n\n    def menuSaveSettings(self):\n        \"\"\"A function for saving the current dock layout and settings to a numpy\n        binary array file\"\"\"\n        dock_state = self.dockWidgetArea.saveState()\n        if self.dock_settings_path == None:\n            import nplab.utils.gui\n            from nplab.utils.gui import QtGui, QtWidgets\n            #     app = nplab.utils.gui.get_qt_app()  # ensure Qt is running\n            self.dock_settings_path = QtWidgets.QFileDialog.getSaveFileName(\n                caption=\"Create new dock settings file\",\n                directory=self.working_directory,\n                #            options=qtgui.QFileDialog.DontConfirmOverwrite,\n            )[0]\n\n        np.save(self.dock_settings_path, dock_state)\n\n    def menuLoadSettings(self):\n        \"\"\"A function for loading the current dock layout and settings to a numpy\n        binary array file\"\"\"\n        if self.dock_settings_path == None:\n            import nplab.utils.gui\n            from nplab.utils.gui import QtGui, QtWidgets\n            #          app = nplab.utils.gui.get_qt_app()  # ensure Qt is running\n            self.dock_settings_path = QtWidgets.QFileDialog.getOpenFileName(\n                caption=\"Select Existing Data File\",\n                directory=self.working_directory,\n            )[0]\n        try:\n            loaded_state = np.load(self.dock_settings_path, allow_pickle=True)\n            loaded_state = loaded_state[()]\n            self.dockWidgetArea.restoreState(loaded_state)\n        except Exception as e:\n            self._logger.debug(e)\n            self._logger.warn(\n                'The dock_settings file does not exist! or it is for the wrong docks!')\n\n    def menuNewExperiment(self):\n        \"\"\"A start new experiment button causing the gui to close ask for a new file and reopen\"\"\"\n        dock_state = self.dockWidgetArea.saveState()\n        self.toggle_browser()\n        self.data_file.flush()\n        self.data_file.close()\n        self.data_file = df.current(working_directory=self.working_directory)\n        self.instr_dict['HDF5'] = self.data_file\n        self._open_one_gui('HDF5')\n        self.dockWidgetArea.restoreState(dock_state)\n\n    def menuSaveExperiment(self):\n        \"\"\"push to data to hard drive \"\"\"\n        self.data_file.flush()\n\n    def menuCloseExperiment(self):\n        \"\"\"Close the current data_file\"\"\"\n        try:\n            self.data_file.flush()\n            self.data_file.close()\n            self.allWidgets['HDF5'].treeWidget.model.refresh_tree()\n        except Exception as e:\n            self._logger.info(\"You likely tried closing a closed file: %s\" % e)\n\n    def menuTerminal(self):\n        \"\"\" Create an ipython console for use within the experiment and push\n        all the equipment to it with the requested names\n        \"\"\"\n        from nplab.utils import terminal\n        if self.terminalWindow is None:\n            if os.environ[\"QT_API\"] == \"pyqt5\":\n                self.terminalWindow = terminal.QIPythonWidget(scripts_path=self.scripts_path)\n                self.terminalWindow.push_vars({'gui': self, 'exper': self.instr_dict})\n                self.terminalWindow.push_vars(self.instr_dict)\n                self.terminalWindow.execute_command('import nplab.datafile as df')\n                self.terminalWindow.execute_command('')\n                handle = logging.StreamHandler(self.terminalWindow.kernel_manager.kernel.stdout)\n            else:\n                self.terminalWindow = terminal.Ipython()\n                self.terminalWindow.push({'gui': self, 'exper': self.instr_dict})\n                self.terminalWindow.push(self.instr_dict)\n                self.terminalWindow.execute('import nplab.datafile as df')\n                self.terminalWindow.execute('data_file = df.current()')\n                self.terminalWindow.execute('')\n                handle = logging.StreamHandler(self.terminalWindow.kernel.stdout)\n            formatter = ColoredFormatter('[%(name)s] - %(levelname)s: %(message)s - %(asctime)s ', '%H:%M')\n            handle.setFormatter(formatter)\n            self._logger.addHandler(handle)\n            instr_logger = logging.getLogger('Instrument')\n            instr_logger.addHandler(handle)\n\n            self.allDocks['Terminal'] = pyqtgraph.dockarea.Dock('Terminal')\n            if os.environ[\"QT_API\"] == \"pyqt5\":\n                self.allWidgets['Terminal'] = self.terminalWindow\n            else:\n                self.allWidgets['Terminal'] = self.terminalWindow.control\n            self.dockwidgetArea.addDock(self.allDocks['Terminal'], 'left')\n            self.allDocks['Terminal'].addWidget(self.allWidgets['Terminal'])\n        else:\n            self.actions['Views']['Terminal'].toggle()\n            self._toggleView('Terminal')\n\n    '''Script menu'''\n\n    def makeScriptMenu(self):\n        \"\"\"Generate a menu for running the scripts found in the scripts path locationlocation \"\"\"\n        from functools import partial\n\n        if self.script_menu is None:\n            script_menu = self.menuBar().addMenu('&Scripts')\n        else:\n            script_menu = self.script_menu\n\n        menus = {self.scripts_path: script_menu}\n\n        for dirpath, dirnames, filenames in os.walk(self.scripts_path):\n            # print filenames\n            current = menus[dirpath]\n            for dn in dirnames:\n                menus[os.path.join(dirpath, dn)] = current.addMenu(dn)\n            for fn in filenames:\n                if fn != '__init__.py':\n                    menuitem = current.addAction(fn)\n                    menuitem.triggered.connect(partial(self.menuScriptClicked, '\\\\'.join((dirpath,fn))))\n\n        script_menu.addSeparator()\n        refreshScripts = script_menu.addAction('Refresh')\n        refreshScripts.triggered.connect(self.refreshScriptMenu)\n        self.script_menu = script_menu\n\n    def refreshScriptMenu(self):\n        \"\"\"clear and recompile the scripts menu \"\"\"\n        self._logger.debug('Refreshing script menu')\n        self.script_menu.clear()\n        self.makeScriptMenu()\n\n    def menuScriptClicked(self, scriptname):\n        \"\"\"Runs the selected script \"\"\"\n        self._logger.debug('Script menu clicked: %s' % scriptname)\n        if self.terminal:\n            if self.terminalWindow is None:\n                self.menuTerminal()\n            self.terminalWindow.run_script(scriptname)\n        else:\n            self._logger.debug('Running %s' % os.path.join(self.scripts_path, scriptname))\n            try:\n                runfile(scriptname, current_namespace=True)\n            except Exception as e:\n                print(e)\n            # exec(open(os.path.join(self.scripts_path, scriptname)).read())\n            \n    def VerboseChanged(self, action):\n        \"\"\"Automatically change the loggers \n        verbosity level across all instruments upon \n        request  \"\"\"\n        instr_logger = logging.getLogger('Instrument')\n        if action.isChecked():\n            self._logger.setLevel(action.text().upper())\n            instr_logger.setLevel(action.text().upper())\n            for action2 in self.menuVerbose.actions():\n                if action2.text() != action.text():\n                    action2.setChecked(False)\n        else:\n            self.menuVerbose.actions()[1].setChecked(True)\n            instr_logger.setLevel('INFO')\n            self._logger.setLevel('INFO')\n\n    def closeEvent(self, event):\n        \"\"\"A quick are you sure you want to quit function \"\"\"\n        quit_msg = \"Are you sure you want to exit the program?\"\n        self._logger.info(quit_msg)\n        try:\n            if os.environ[\"QT_API\"] == \"pyqt5\":\n                reply = QtWidgets.QMessageBox.question(self, 'Message', quit_msg,\n                                                       QtWidgets.QMessageBox.Yes | QtWidgets.QMessageBox.Save | QtWidgets.QMessageBox.No)\n\n            else:\n                reply = QtWidgets.QMessageBox.question(self, 'Message', quit_msg,\n                                                       QtWidgets.QMessageBox.Yes, QtWidgets.QMessageBox.Save,\n                                                       QtWidgets.QMessageBox.No)\n\n            if reply != QtWidgets.QMessageBox.No:\n                if reply == QtWidgets.QMessageBox.Save:\n                    self.menuSaveSettings()\n                    # self.experiment.save_load_all_settings()\n                #            self.experiment.isLive = 0\n\n                #            if self.experiment.ExpFile is not None:\n                #                self.experiment.ExpFile.flush()\n                #                self.experiment.ExpFile.close()\n                #            self.experiment.__del__()\n                for wdgt in self.allWidgets.values():\n                    # Explicitly calling QtWidget.close(), so that individual instruments GUIs can follow their own\n                    # closing procedures\n                    wdgt.close()\n                event.accept()\n            else:\n                event.ignore()\n        except Exception as e:\n            event.ignore()\n            print(e)",
  "def __init__(self, instrument_dict, parent=None, dock_settings_path=None,\n                 scripts_path=None, working_directory=None, file_path=None,\n                 terminal=False, dark=False):  \n        \"\"\"Args:\n            instrument_dict(dict) :     This is a dictionary containing the\n                                        instruments objects where the key is the \n                                        objects new name in the generated new Ipython \n                                        console\n            dock_settings_path(str):    A path for loading a previous dock widget\n                                        configuration\n            scripts_path(str):          The path of any scripts the user may want to\n                                        run using the drop down menu at the top\n                                        of the gui\n            working_directory(str):     A path to the requested working directory - \n                                        handy if you always wish to save data to \n                                        the same directories\n            file_path(str):             A path to the file for saving data. If None,\n                                        a dialog will ask for one. Can be a relative\n                                        path (from working_directory) or an absolute path\n            terminal(bool):             Specifies whether the generated gui has an ipython \n                                        console. Sripts ran in an ipython console cannot \n                                        generate another one.\n                                \"\"\"\n        super(GuiGenerator, self).__init__(parent)\n        self._logger = LOGGER\n        self.instr_dict = instrument_dict\n        if working_directory is None:\n            self.working_directory = os.path.join(os.getcwd())\n        else:\n            self.working_directory = working_directory\n        if file_path is None:\n            self.data_file = df.current(working_directory=working_directory)\n        elif os.path.isabs(file_path):\n            df.set_current(file_path)\n            self.data_file = df.current()\n        else:\n            df.set_current(self.working_directory + '/' + file_path)\n            self.data_file = df.current()\n\n        if dark:\n            app = get_qt_app()\n            app.setStyleSheet(qdarkstyle.load_stylesheet())\n        self.instr_dict[\"HDF5\"] = self.data_file\n        self.setDockNestingEnabled(1)\n\n        self.load_ui_from_file(__file__, 'guigenerator.ui')\n\n        self.allDocks = {}\n        self.allWidgets = {}\n        self.actions = dict(Views={}, Instruments={})\n\n        self.dockwidgetArea = pyqtgraph.dockarea.DockArea()\n        self.dockWidgetArea = self.replace_widget(self.verticalLayout, self.centralWidget(), self.dockwidgetArea)\n        self.dockWidgetAllInstruments.setWidget(self.dockwidgetArea)\n        self.dockWidgetAllInstruments.setTitleBarWidget(QtWidgets.QWidget())  # This trick makes the title bar disappear\n\n        # Iterate over all the opened instruments. If the instrument has a GUI (i.e. if they have the get_qt_ui function\n        # defined inside them), then create a pyqtgraph.Dock for it and add its widget to the Dock. Also prints out any\n        # instruments that do not have GUIs\n        self._logger.info('Opening all GUIs')\n\n        for instr in self.instr_dict:\n            self._open_one_gui(instr)\n            \n        self.script_menu = None\n        if scripts_path is not None:\n            self.scripts_path = scripts_path\n        else:\n            self.scripts_path = 'scripts'\n        sys.path.append(self.scripts_path)\n        self.terminalWindow = None\n        self.terminal = terminal\n        if terminal:\n            self.menuTerminal()\n            self._addActionViewMenu('Terminal')\n        self.terminal = terminal\n        self.makeScriptMenu()\n\n        self.NightMode = 1\n\n        # address of h5 file\n        self.filename = df.current().filename\n\n        self._setupSignals()\n        if dock_settings_path is not None:\n            self.dock_settings_path = dock_settings_path\n            self.menuLoadSettings()\n        else:\n            self.dock_settings_path = None\n        self.showMaximized()",
  "def __getattribute__(self, name):  # All instruments log function and method calls at debugging level\n\n        returned = QtCore.QObject.__getattribute__(self, name)\n        if inspect.isfunction(returned) or inspect.ismethod(returned):\n            codeline = inspect.getsourcelines(returned)[1]\n            filename = inspect.getfile(returned)\n            self._logger.debug('Called %s on line %g of %s' % (returned.__name__, codeline, filename))\n        return returned",
  "def _open_one_gui(self, instrument_name):\n        \"\"\"A command for opening a single Instruemnt guiand creating a dock through acquiring the \n        get_qt_ui function for a single panel or if invidual control and preview widgets\n        are possible then the get_control_widget and get_preview_widgets will be sed\n        \"\"\"\n        if hasattr(self.instr_dict[instrument_name], 'get_control_widget') or hasattr(self.instr_dict[instrument_name],\n                                                                                      'get_preview_widget'):\n            if hasattr(self.instr_dict[instrument_name], 'get_control_widget'):\n                self.allWidgets[instrument_name + ' controls'] = self.instr_dict[instrument_name].get_control_widget()\n                self.allDocks[instrument_name + ' controls'] = pyqtgraph.dockarea.Dock(instrument_name + ' controls')\n                self.dockwidgetArea.addDock(self.allDocks[instrument_name + ' controls'], 'left')\n                self.allDocks[instrument_name + ' controls'].addWidget(self.allWidgets[instrument_name + ' controls'])\n                self._addActionViewMenu(instrument_name + ' controls')\n            if hasattr(self.instr_dict[instrument_name], 'get_preview_widget'):\n                self.allWidgets[instrument_name + ' display'] = self.instr_dict[instrument_name].get_preview_widget()\n                self.allDocks[instrument_name + ' display'] = pyqtgraph.dockarea.Dock(instrument_name + ' display')\n                self.dockwidgetArea.addDock(self.allDocks[instrument_name + ' display'], 'left')\n                self.allDocks[instrument_name + ' display'].addWidget(self.allWidgets[instrument_name + ' display'])\n                self._addActionViewMenu(instrument_name + ' display')\n        elif hasattr(self.instr_dict[instrument_name], 'get_qt_ui'):\n            self.allWidgets[instrument_name] = self.instr_dict[instrument_name].get_qt_ui()\n            self.allDocks[instrument_name] = pyqtgraph.dockarea.Dock(instrument_name)\n            self.dockwidgetArea.addDock(self.allDocks[instrument_name], 'left')\n            self.allDocks[instrument_name].addWidget(self.allWidgets[instrument_name])\n            self._addActionViewMenu(instrument_name)\n        else:\n            self._logger.warn('%s does not have a get_qt_ui' % instrument_name)",
  "def _addActionViewMenu(self, instr):\n        \"\"\"Create the actions menu - such as enabled and disabling gui's on the fly \"\"\"\n        if instr not in self.actions['Views']:\n            action = QtWidgets.QAction(instr, self)\n            self.menuView.addAction(action)\n            action.setCheckable(True)\n            action.setChecked(True)\n            action.triggered.connect(lambda: self._toggleView(instr))\n            self.actions['Views'][instr] = action",
  "def _toggleView(self, instr):\n        \"\"\"A function for toggling a single gui \"\"\"\n        dock = self.allDocks[instr]\n        if self.actions['Views'][instr].isChecked():\n            self.dockwidgetArea.addDock(dock, 'left')\n            dock.show()\n            dock.showTitleBar()\n        else:\n            dock.close()",
  "def _setupSignals(self):\n        \"\"\"Connect signals for the different general gui buttons/menu's \"\"\"\n        self.actionExit.triggered.connect(self.close)\n        self.actionNightMode.triggered.connect(self.toggleNightMode)\n        self.actionTerminal.triggered.connect(self.menuTerminal)\n        self.actionShowBrowser.triggered.connect(self.toggle_browser)\n        self.actionNewExperiment.triggered.connect(self.menuNewExperiment)\n        self.actionCloseExperiment.triggered.connect(self.menuCloseExperiment)\n        self.actionSaveExperiment.triggered.connect(self.menuSaveExperiment)\n        self.actionSaveSettings.triggered.connect(self.menuSaveSettings)\n        self.actionRecallSettings.triggered.connect(self.menuLoadSettings)\n        # For some reason the following does not work if put in a loop\n        actions = self.menuVerbose.actions()\n        actions[0].triggered.connect(lambda: self.VerboseChanged(actions[0]))\n        actions[1].triggered.connect(lambda: self.VerboseChanged(actions[1]))\n        actions[2].triggered.connect(lambda: self.VerboseChanged(actions[2]))",
  "def toggle_browser(self):\n        \"\"\"enable or disable the file browser \"\"\"\n        self.actions['Views']['HDF5'].toggle()\n        self._toggleView('HDF5')",
  "def toggleNightMode(self):\n        \"\"\"A function to switch all the colors to night mode - handy when working in an optics lab \"\"\"\n        try:\n            if self.actionNightMode.isChecked():\n                import qdarkstyle\n                self.setStyleSheet(qdarkstyle.load_stylesheet(pyside=False))\n            else:\n                self.setStyleSheet('')\n        except Exception as e:\n            print(e)\n            print('trying Qt 5')\n            try:\n                if self.actionNightMode.isChecked():\n                    import qdarkstyle\n                    self.setStyleSheet(qdarkstyle.load_stylesheet_pyqt5())\n                else:\n                    self.setStyleSheet('')\n            except Exception as ee:\n                print(ee)\n                print('Qt 5 style sheet failed')",
  "def menuSaveSettings(self):\n        \"\"\"A function for saving the current dock layout and settings to a numpy\n        binary array file\"\"\"\n        dock_state = self.dockWidgetArea.saveState()\n        if self.dock_settings_path == None:\n            import nplab.utils.gui\n            from nplab.utils.gui import QtGui, QtWidgets\n            #     app = nplab.utils.gui.get_qt_app()  # ensure Qt is running\n            self.dock_settings_path = QtWidgets.QFileDialog.getSaveFileName(\n                caption=\"Create new dock settings file\",\n                directory=self.working_directory,\n                #            options=qtgui.QFileDialog.DontConfirmOverwrite,\n            )[0]\n\n        np.save(self.dock_settings_path, dock_state)",
  "def menuLoadSettings(self):\n        \"\"\"A function for loading the current dock layout and settings to a numpy\n        binary array file\"\"\"\n        if self.dock_settings_path == None:\n            import nplab.utils.gui\n            from nplab.utils.gui import QtGui, QtWidgets\n            #          app = nplab.utils.gui.get_qt_app()  # ensure Qt is running\n            self.dock_settings_path = QtWidgets.QFileDialog.getOpenFileName(\n                caption=\"Select Existing Data File\",\n                directory=self.working_directory,\n            )[0]\n        try:\n            loaded_state = np.load(self.dock_settings_path, allow_pickle=True)\n            loaded_state = loaded_state[()]\n            self.dockWidgetArea.restoreState(loaded_state)\n        except Exception as e:\n            self._logger.debug(e)\n            self._logger.warn(\n                'The dock_settings file does not exist! or it is for the wrong docks!')",
  "def menuNewExperiment(self):\n        \"\"\"A start new experiment button causing the gui to close ask for a new file and reopen\"\"\"\n        dock_state = self.dockWidgetArea.saveState()\n        self.toggle_browser()\n        self.data_file.flush()\n        self.data_file.close()\n        self.data_file = df.current(working_directory=self.working_directory)\n        self.instr_dict['HDF5'] = self.data_file\n        self._open_one_gui('HDF5')\n        self.dockWidgetArea.restoreState(dock_state)",
  "def menuSaveExperiment(self):\n        \"\"\"push to data to hard drive \"\"\"\n        self.data_file.flush()",
  "def menuCloseExperiment(self):\n        \"\"\"Close the current data_file\"\"\"\n        try:\n            self.data_file.flush()\n            self.data_file.close()\n            self.allWidgets['HDF5'].treeWidget.model.refresh_tree()\n        except Exception as e:\n            self._logger.info(\"You likely tried closing a closed file: %s\" % e)",
  "def menuTerminal(self):\n        \"\"\" Create an ipython console for use within the experiment and push\n        all the equipment to it with the requested names\n        \"\"\"\n        from nplab.utils import terminal\n        if self.terminalWindow is None:\n            if os.environ[\"QT_API\"] == \"pyqt5\":\n                self.terminalWindow = terminal.QIPythonWidget(scripts_path=self.scripts_path)\n                self.terminalWindow.push_vars({'gui': self, 'exper': self.instr_dict})\n                self.terminalWindow.push_vars(self.instr_dict)\n                self.terminalWindow.execute_command('import nplab.datafile as df')\n                self.terminalWindow.execute_command('')\n                handle = logging.StreamHandler(self.terminalWindow.kernel_manager.kernel.stdout)\n            else:\n                self.terminalWindow = terminal.Ipython()\n                self.terminalWindow.push({'gui': self, 'exper': self.instr_dict})\n                self.terminalWindow.push(self.instr_dict)\n                self.terminalWindow.execute('import nplab.datafile as df')\n                self.terminalWindow.execute('data_file = df.current()')\n                self.terminalWindow.execute('')\n                handle = logging.StreamHandler(self.terminalWindow.kernel.stdout)\n            formatter = ColoredFormatter('[%(name)s] - %(levelname)s: %(message)s - %(asctime)s ', '%H:%M')\n            handle.setFormatter(formatter)\n            self._logger.addHandler(handle)\n            instr_logger = logging.getLogger('Instrument')\n            instr_logger.addHandler(handle)\n\n            self.allDocks['Terminal'] = pyqtgraph.dockarea.Dock('Terminal')\n            if os.environ[\"QT_API\"] == \"pyqt5\":\n                self.allWidgets['Terminal'] = self.terminalWindow\n            else:\n                self.allWidgets['Terminal'] = self.terminalWindow.control\n            self.dockwidgetArea.addDock(self.allDocks['Terminal'], 'left')\n            self.allDocks['Terminal'].addWidget(self.allWidgets['Terminal'])\n        else:\n            self.actions['Views']['Terminal'].toggle()\n            self._toggleView('Terminal')",
  "def makeScriptMenu(self):\n        \"\"\"Generate a menu for running the scripts found in the scripts path locationlocation \"\"\"\n        from functools import partial\n\n        if self.script_menu is None:\n            script_menu = self.menuBar().addMenu('&Scripts')\n        else:\n            script_menu = self.script_menu\n\n        menus = {self.scripts_path: script_menu}\n\n        for dirpath, dirnames, filenames in os.walk(self.scripts_path):\n            # print filenames\n            current = menus[dirpath]\n            for dn in dirnames:\n                menus[os.path.join(dirpath, dn)] = current.addMenu(dn)\n            for fn in filenames:\n                if fn != '__init__.py':\n                    menuitem = current.addAction(fn)\n                    menuitem.triggered.connect(partial(self.menuScriptClicked, '\\\\'.join((dirpath,fn))))\n\n        script_menu.addSeparator()\n        refreshScripts = script_menu.addAction('Refresh')\n        refreshScripts.triggered.connect(self.refreshScriptMenu)\n        self.script_menu = script_menu",
  "def refreshScriptMenu(self):\n        \"\"\"clear and recompile the scripts menu \"\"\"\n        self._logger.debug('Refreshing script menu')\n        self.script_menu.clear()\n        self.makeScriptMenu()",
  "def menuScriptClicked(self, scriptname):\n        \"\"\"Runs the selected script \"\"\"\n        self._logger.debug('Script menu clicked: %s' % scriptname)\n        if self.terminal:\n            if self.terminalWindow is None:\n                self.menuTerminal()\n            self.terminalWindow.run_script(scriptname)\n        else:\n            self._logger.debug('Running %s' % os.path.join(self.scripts_path, scriptname))\n            try:\n                runfile(scriptname, current_namespace=True)\n            except Exception as e:\n                print(e)",
  "def VerboseChanged(self, action):\n        \"\"\"Automatically change the loggers \n        verbosity level across all instruments upon \n        request  \"\"\"\n        instr_logger = logging.getLogger('Instrument')\n        if action.isChecked():\n            self._logger.setLevel(action.text().upper())\n            instr_logger.setLevel(action.text().upper())\n            for action2 in self.menuVerbose.actions():\n                if action2.text() != action.text():\n                    action2.setChecked(False)\n        else:\n            self.menuVerbose.actions()[1].setChecked(True)\n            instr_logger.setLevel('INFO')\n            self._logger.setLevel('INFO')",
  "def closeEvent(self, event):\n        \"\"\"A quick are you sure you want to quit function \"\"\"\n        quit_msg = \"Are you sure you want to exit the program?\"\n        self._logger.info(quit_msg)\n        try:\n            if os.environ[\"QT_API\"] == \"pyqt5\":\n                reply = QtWidgets.QMessageBox.question(self, 'Message', quit_msg,\n                                                       QtWidgets.QMessageBox.Yes | QtWidgets.QMessageBox.Save | QtWidgets.QMessageBox.No)\n\n            else:\n                reply = QtWidgets.QMessageBox.question(self, 'Message', quit_msg,\n                                                       QtWidgets.QMessageBox.Yes, QtWidgets.QMessageBox.Save,\n                                                       QtWidgets.QMessageBox.No)\n\n            if reply != QtWidgets.QMessageBox.No:\n                if reply == QtWidgets.QMessageBox.Save:\n                    self.menuSaveSettings()\n                    # self.experiment.save_load_all_settings()\n                #            self.experiment.isLive = 0\n\n                #            if self.experiment.ExpFile is not None:\n                #                self.experiment.ExpFile.flush()\n                #                self.experiment.ExpFile.close()\n                #            self.experiment.__del__()\n                for wdgt in self.allWidgets.values():\n                    # Explicitly calling QtWidget.close(), so that individual instruments GUIs can follow their own\n                    # closing procedures\n                    wdgt.close()\n                event.accept()\n            else:\n                event.ignore()\n        except Exception as e:\n            event.ignore()\n            print(e)",
  "def SendMessage(address,msg,subject):    \n        \"get the username and password from a file\"        \n        f = open(\"R:\\\\0-SHARED\\\\Computing\\\\NP_mailing.txt\")\n        global credentials\n        credentials = imp.load_source('data', '', f)\n        f.close()\n        \n        FROM = 'np.lab.messenger@gmail.com '\n        TO = [address] #must be a list\n        SUBJECT = subject\n        TEXT = msg\n        \n        # Prepare actual message\n        message = \"\"\"\\From: %s\\nTo: %s\\nSubject: %s\\n\\n%s\n        \"\"\" % (FROM, \", \".join(TO), SUBJECT, TEXT)\n        try:\n            server = smtplib.SMTP(\"smtp.gmail.com\", 587) #or port 465 doesn't seem to work!\n            server.ehlo()\n            server.starttls()\n            server.login(credentials.user, credentials.pw)\n            server.sendmail(FROM, TO, message)\n            server.close()\n            print('successfully sent the mail')\n        except:\n            print(\"failed to send mail\")",
  "def send_email(to_address, message, subject=\"[nplab] Notification\", raise_exceptions=False):\n    \"\"\"Send an email (only works for PCs on the Physics network).\n    \n    Uses the np-lab-notifications email address as the \"from\" address and\n    sends unencrypted through ppsw.cam.ac.uk, so this will only work for PCs\n    on the University network.\"\"\"\n    try:\n        header = \"From: {0}\\r\\nTo: {1}\\r\\nSubject: {2}\\r\\n\\r\\n\".format(NPLAB_FROM_ADDRESS, to_address, subject)\n        server = smtplib.SMTP(NPLAB_SMTP_SERVER, 25)\n        server.sendmail(NPLAB_FROM_ADDRESS, to_address, header + message)\n        server.quit()\n    except Exception as e:\n        if raise_exceptions:\n            raise e\n        else:\n            print(\"Warning: errror while sending email to {0}: {1}\".format(to_address, e))",
  "class Property():\n    \"\"\"Emulate PyProperty_Type() in Objects/descrobject.c\n    \n    This is copied from \n    https://docs.python.org/2/howto/descriptor.html#properties\n    as I'd otherwise be reimplementing.  Plus, having this here makes it\n    clearer how my properties differ.\"\"\"\n\n    def __init__(self, fget=None, fset=None, fdel=None, doc=None):\n        self.fget = fget\n        self.fset = fset\n        self.fdel = fdel\n        if doc is None and fget is not None:\n            doc = fget.__doc__\n        self.__doc__ = doc\n\n    def __get__(self, obj, objtype=None):\n        if obj is None:\n            return self\n        if self.fget is None:\n            raise AttributeError(\"unreadable attribute\")\n        return self.fget(obj)\n\n    def __set__(self, obj, value):\n        if self.fset is None:\n            raise AttributeError(\"can't set attribute\")\n        self.fset(obj, value)\n\n    def __delete__(self, obj):\n        if self.fdel is None:\n            raise AttributeError(\"can't delete attribute\")\n        self.fdel(obj)\n\n    def getter(self, fget):\n        return type(self)(fget, self.fset, self.fdel, self.__doc__)\n\n    def setter(self, fset):\n        return type(self)(self.fget, fset, self.fdel, self.__doc__)\n\n    def deleter(self, fdel):\n        return type(self)(self.fget, self.fset, fdel, self.__doc__)",
  "class NotifiedProperty(Property):\n    \"\"\"A property that notifies when it's changed.\"\"\"        \n    def __init__(self, fget=None, fset=None, fdel=None, doc=None, read_back=False, single_update = True):\n        \"\"\"Return a property that notifies when it's changed.\n        \n        This subclasses the pure Python implementation of properties, adding\n        support for notifying objects when it's changed.\n        \n        If read_back is True, the property is read immediately after it is\n        written, so that the value that's notified to any listening functions\n        is the correct one (this allows for validation of the new value, and\n        will make sure controls display what was actually done, rather than \n        the value that was requested).  It's False by default, in case the\n        property that's connected to it is expensive to read.\n        \"\"\"\n        super(NotifiedProperty, self).__init__(fget=fget, fset=fset, fdel=fdel, doc=doc)\n        # We store a set of callbacks for each object (NB there's one property\n        # per *class* not per object, so we have to keep track of instances)\n        # This is weakly-referenced so if the objects die, we don't stop\n        # Python garbage-collecting them.\n        self.callbacks_by_object = WeakKeyDictionary()\n        self.read_back = read_back\n        self.single_update = single_update\n        self.last_value=None\n    \n    def __set__(self, obj, value):\n        \"\"\"Update the property's value, and notify listeners of the change.\"\"\"\n        super(NotifiedProperty, self).__set__(obj, value)\n        if self.read_back:\n            # This ensures the notified value is correct, at the expense of a read\n            if self.single_update:\n                if value!=self.last_value:\n                    if len(str(value).split('.'))==1:\n                        self.last_value=self.__get__(obj)\n                    else:\n                        self.last_value = np.round(self.__get__(obj),len(str(value).split('.')[-1]))\n                    self.send_notification(obj, self.__get__(obj))\n                    \n         #   \n            else:\n                self.send_notification(obj, self.__get__(obj))\n        else:\n            # This is faster, but notifies the requested value, not the actual one\n            self.send_notification(obj, value)\n        \n    def register_callback(self, obj, callback):\n        \"\"\"Add a function to be called whenever the value changes.\n        \n        The function should accept one argument, which is the new value.\n        \n        NB if the function raises an exception, it will not be called again.\n        \"\"\"\n        if obj not in list(self.callbacks_by_object.keys()):\n            self.callbacks_by_object[obj] = set()\n        self.callbacks_by_object[obj].add(callback)\n        \n    def deregister_callback(self, obj, callback):\n        \"\"\"Remove a function from the list of callbacks.\"\"\"\n        try:\n            callbacks = self.callbacks_by_object[obj]\n        except KeyError:\n            raise KeyError(\"There don't appear to be any callbacks defined on this object!\")\n        try:\n            callbacks.remove(callback)\n        except KeyError:\n            pass # Don't worry if callbacks are removed pointlessly!\n        \n        \n    def send_notification(self, obj, value):\n        \"\"\"Notify anyone that's interested that the value changed.\"\"\"\n        if obj in self.callbacks_by_object:\n            for callback in self.callbacks_by_object[obj].copy():\n                try:\n                    callback(value)\n                except:\n                    # Get rid of failed/deleted callbacks\n                    # Sometimes Qt objects don't delete cleanly, hence this bodge.\n                    self.deregister_callback(obj, callback)",
  "class DumbNotifiedProperty(NotifiedProperty):\n    \"A property that acts as a variable, except it notifies when it changes.\"\n    \n    def __init__(self, default=None, fdel=None, doc=None):\n        \"A property that acts as a variable, except it notifies when it changes.\"\n        \n        super(DumbNotifiedProperty, self).__init__(fget=self.fget, \n                                               fset=self.fset, \n                                               fdel=fdel, \n                                               doc=doc)\n        self._value = default\n        self.values_by_object = WeakKeyDictionary() # we store callbacks here\n\n    # Emulate a variable with the functions below:\n    def fget(self, obj):\n        try:\n            # First, try tp return the stored value for that object\n            return self.values_by_object[obj]\n        except KeyError:\n            # Fall back on the default if not.\n            return self._value\n            \n    def fset(self, obj, value):\n        self.values_by_object[obj] = value",
  "def register_for_property_changes(obj, property_name, callback):\n    \"\"\"Register a function to be called when the property changes.\n    \n    Whenever the value of the named property changes, the callback\n    function will be called, with the new value as the only argument.\n    Note that it's the value that was passed as input to the setter, so\n    if you have cunning logic in there, it may be wrong and you might\n    want to consider retrieving the property at the start of this function\n    (at which point the setter has run, so any changes it makes are done)\n    \"\"\"\n    prop = getattr(obj.__class__, property_name, None)\n    assert isinstance(prop, NotifiedProperty), \"The specified property isn't available\"\n    \n    # register the callback.  Note we need to pass the current object in so\n    # the property knows which object we're talking about.\n    prop.register_callback(obj, callback)",
  "class NotifiedPropertiesMixin(object):\n    \"\"\"A mixin class that adds support for notified properties.\n    \n    Notified proprties are a very, very lightweight alternative to Traits.\n    They don't (currently) do any data validation, though nothing in principle\n    stops you extending them to do that.  Essentially, you decorate the setter\n    of a property with @add_notification, and add this mixin to the class.\n    \n    It's then possible to register to find out whenever that property changes.\n    \"\"\"\n    @functools.wraps(register_for_property_changes)\n    def register_for_property_changes(self, property_name, callback):\n        return register_for_property_changes(self, property_name, callback)",
  "def __init__(self, fget=None, fset=None, fdel=None, doc=None):\n        self.fget = fget\n        self.fset = fset\n        self.fdel = fdel\n        if doc is None and fget is not None:\n            doc = fget.__doc__\n        self.__doc__ = doc",
  "def __get__(self, obj, objtype=None):\n        if obj is None:\n            return self\n        if self.fget is None:\n            raise AttributeError(\"unreadable attribute\")\n        return self.fget(obj)",
  "def __set__(self, obj, value):\n        if self.fset is None:\n            raise AttributeError(\"can't set attribute\")\n        self.fset(obj, value)",
  "def __delete__(self, obj):\n        if self.fdel is None:\n            raise AttributeError(\"can't delete attribute\")\n        self.fdel(obj)",
  "def getter(self, fget):\n        return type(self)(fget, self.fset, self.fdel, self.__doc__)",
  "def setter(self, fset):\n        return type(self)(self.fget, fset, self.fdel, self.__doc__)",
  "def deleter(self, fdel):\n        return type(self)(self.fget, self.fset, fdel, self.__doc__)",
  "def __init__(self, fget=None, fset=None, fdel=None, doc=None, read_back=False, single_update = True):\n        \"\"\"Return a property that notifies when it's changed.\n        \n        This subclasses the pure Python implementation of properties, adding\n        support for notifying objects when it's changed.\n        \n        If read_back is True, the property is read immediately after it is\n        written, so that the value that's notified to any listening functions\n        is the correct one (this allows for validation of the new value, and\n        will make sure controls display what was actually done, rather than \n        the value that was requested).  It's False by default, in case the\n        property that's connected to it is expensive to read.\n        \"\"\"\n        super(NotifiedProperty, self).__init__(fget=fget, fset=fset, fdel=fdel, doc=doc)\n        # We store a set of callbacks for each object (NB there's one property\n        # per *class* not per object, so we have to keep track of instances)\n        # This is weakly-referenced so if the objects die, we don't stop\n        # Python garbage-collecting them.\n        self.callbacks_by_object = WeakKeyDictionary()\n        self.read_back = read_back\n        self.single_update = single_update\n        self.last_value=None",
  "def __set__(self, obj, value):\n        \"\"\"Update the property's value, and notify listeners of the change.\"\"\"\n        super(NotifiedProperty, self).__set__(obj, value)\n        if self.read_back:\n            # This ensures the notified value is correct, at the expense of a read\n            if self.single_update:\n                if value!=self.last_value:\n                    if len(str(value).split('.'))==1:\n                        self.last_value=self.__get__(obj)\n                    else:\n                        self.last_value = np.round(self.__get__(obj),len(str(value).split('.')[-1]))\n                    self.send_notification(obj, self.__get__(obj))\n                    \n         #   \n            else:\n                self.send_notification(obj, self.__get__(obj))\n        else:\n            # This is faster, but notifies the requested value, not the actual one\n            self.send_notification(obj, value)",
  "def register_callback(self, obj, callback):\n        \"\"\"Add a function to be called whenever the value changes.\n        \n        The function should accept one argument, which is the new value.\n        \n        NB if the function raises an exception, it will not be called again.\n        \"\"\"\n        if obj not in list(self.callbacks_by_object.keys()):\n            self.callbacks_by_object[obj] = set()\n        self.callbacks_by_object[obj].add(callback)",
  "def deregister_callback(self, obj, callback):\n        \"\"\"Remove a function from the list of callbacks.\"\"\"\n        try:\n            callbacks = self.callbacks_by_object[obj]\n        except KeyError:\n            raise KeyError(\"There don't appear to be any callbacks defined on this object!\")\n        try:\n            callbacks.remove(callback)\n        except KeyError:\n            pass",
  "def send_notification(self, obj, value):\n        \"\"\"Notify anyone that's interested that the value changed.\"\"\"\n        if obj in self.callbacks_by_object:\n            for callback in self.callbacks_by_object[obj].copy():\n                try:\n                    callback(value)\n                except:\n                    # Get rid of failed/deleted callbacks\n                    # Sometimes Qt objects don't delete cleanly, hence this bodge.\n                    self.deregister_callback(obj, callback)",
  "def __init__(self, default=None, fdel=None, doc=None):\n        \"A property that acts as a variable, except it notifies when it changes.\"\n        \n        super(DumbNotifiedProperty, self).__init__(fget=self.fget, \n                                               fset=self.fset, \n                                               fdel=fdel, \n                                               doc=doc)\n        self._value = default\n        self.values_by_object = WeakKeyDictionary()",
  "def fget(self, obj):\n        try:\n            # First, try tp return the stored value for that object\n            return self.values_by_object[obj]\n        except KeyError:\n            # Fall back on the default if not.\n            return self._value",
  "def fset(self, obj, value):\n        self.values_by_object[obj] = value",
  "def register_for_property_changes(self, property_name, callback):\n        return register_for_property_changes(self, property_name, callback)",
  "class foo():\n        a = DumbNotifiedProperty(10)",
  "def a_changed(new):\n        print('a changed to ' + str(new))",
  "class GitFolderMissing(Exception):\n    \"\"\"Exception to be raised if the git folder is not found.\"\"\"\n    pass",
  "def git_folder():\n    \"\"\"Find the git folder for the repo that contains nplab.\"\"\"\n    project_dir = os.path.dirname(os.path.dirname(nplab.__file__))\n    git_folder = os.path.join(project_dir,'.git')\n    if os.path.isdir(git_folder):\n        return git_folder\n    else:\n        raise GitFolderMissing(\"Could not find the git folder - are you in develop mode?\")",
  "def current_branch():\n    \"\"\"Return the name of the current branch we're using\"\"\"\n    f = open(os.path.join(git_folder(),'HEAD'), 'r')\n    current_branch = f.read()[5:].strip()\n    f.close()\n    return current_branch",
  "def latest_commit():\n    \"\"\"Find the SHA1 hash of the most recent commit.\"\"\"\n    #first, open the file with the SHA1 in it\n    f = open(os.path.join(git_folder(), *(current_branch().split('/'))), 'r')\n    sha1 = f.read().strip() #the file only contains the SHA1\n    f.close()\n    return sha1",
  "def all_module_versions_string():\n    \"\"\"A string containing the version of all loaded modules with accessible version info.\"\"\"\n    modulestring = \"\"\n    for m in list(sys.modules.values()):\n        try:\n            modulestring += m.__name__ + \": \" + m.__version__ + \"\\n\"\n        except:\n            pass\n    return modulestring",
  "def platform_string():\n    \"\"\"A string identifying the platform (OS, Python version, etc.)\"\"\"\n    platform_info = \"\"\n    for f in dir(platform):\n        try:\n            platform_info += f + \": \" + str(getattr(platform, f)()) + \"\\n\"\n        except:\n            pass\n    return platform_info",
  "def version_info_string():\n    \"\"\"Construct a big string with all avaliable version info.\"\"\"\n    version_string = \"NPLab %s\\n\" % nplab.__version__\n    try:\n        version_string += \"Branch: %s\\n\" % current_branch()\n        version_string += \"Commit: %s\\n\" % latest_commit()\n    except GitFolderMissing:\n        version_string += \"Release version (not in a Git repository)\\n\"\n    version_string += \"\\n\"\n    version_string += \"Module versions:\\n\"\n    version_string += all_module_versions_string()\n    version_string += \"\\n\"\n    version_string += \"Platform information:\\n\"\n    version_string += platform_string()\n    return version_string",
  "def locked_action_decorator(wait_for_lock=True):\n    \"\"\"This decorates a function, to prevent it being called simultaneously from\n    multiple threads.  Only one locked action can happen at any given time on a\n    given object.\n    \n    We use a Reentrant Lock, which means that a single thread can acquire() it\n    multiple times.  This is helpful (for example if locked functions call\n    other locked functions, this is OK).\n    \n    If wait_for_lock is false and an action is running, it returns immediately.\n    This can be given as an argument to locked_action_decorator (which sets the\n    default) or to the function when called (which overrides it).\n    \"\"\"\n    def decorator(function):\n        #the decorator is meant to be called as @locked_action_decorator()\n        #so we need to return a function, which is what actually gets used\n        #to modify the function we're decorating.\n        @functools.wraps(function)\n        def locked_action(self, *args, **kwargs):\n            \"\"\"Perform an action, but use a lock so only one locked action can\n            happen at any time\"\"\"\n            #First: make sure the lock object exists\n            if not hasattr(self, \"_nplab_action_lock\"):\n                self._nplab_action_lock = threading.RLock()\n            try:\n                if wait_for_lock:\n                    self._nplab_action_lock.acquire() #this will wait until we can lock the device\n                else:    #if \"wait for lock\" is false, just return false if it's busy\n                    if not self._nplab_action_lock.acquire(block=False):\n                        print(\"Could not acquire action lock, giving up.\")\n                        return False\n                return function(self, *args, **kwargs)\n            except Exception as e:\n                raise e #don't attempt to handle errors, just pass them on\n            finally:\n                self._nplab_action_lock.release() #don't leave the thing locked\n        return locked_action\n    return decorator",
  "def background_action_decorator(background_by_default=True, ):\n    \"\"\"This decorates a function to run it in a background thread.  NB it does\n    not lock the function: use @locked_action to do this (the two are compatible\n    but you must place background_action *before* locked function, so that the\n    lock is acquired by the background thread.).\n    \n    Arguments:\n    * background_by_default sets whether the function runs in the\n    background by default or whether it only backgrounds itself when asked.  In\n    either case the non-default behaviour can be requested with keyword argument\n    run_in_background_thread.\n    * \n    \"\"\"\n    def decorator(function):\n        @functools.wraps(function)\n        def background_action(self, *args, **kwargs):\n            if background_by_default:\n                if not hasattr(self, \"_nplab_background_action_threads\"):\n                    self._nplab_background_action_threads = set([])\n                t = threading.Thread()\n                def worker_function():\n                    t.returned_value = function(self, *args, **kwargs)\n                    self._nplab_background_action_threads.remove(t)\n                t.run=worker_function\n                t.host_object = self\n                self._nplab_background_action_threads.add(t)\n                t.start()\n                def join_and_return_result(self): #this gets added to a thread so we can extract the return value\n                    self.join()\n                    return self.returned_value\n                t.join_and_return_result = functools.partial(join_and_return_result, t) #add method to the thread\n                return t\n            else:\n                return function(self, *args, **kwargs)\n        return background_action #this is the one that replaces the function: same signature but with added kwarg run_in_background_thread\n    return decorator",
  "def background_actions_running(obj):\n    \"\"\"Determine whether an object has any currently-active background actions.\"\"\"\n    if not hasattr(obj, \"_nplab_background_action_threads\"):\n        return False\n    for t in obj._nplab_background_action_threads:\n        if t.is_alive():\n            return True\n    return False",
  "def decorator(function):\n        #the decorator is meant to be called as @locked_action_decorator()\n        #so we need to return a function, which is what actually gets used\n        #to modify the function we're decorating.\n        @functools.wraps(function)\n        def locked_action(self, *args, **kwargs):\n            \"\"\"Perform an action, but use a lock so only one locked action can\n            happen at any time\"\"\"\n            #First: make sure the lock object exists\n            if not hasattr(self, \"_nplab_action_lock\"):\n                self._nplab_action_lock = threading.RLock()\n            try:\n                if wait_for_lock:\n                    self._nplab_action_lock.acquire() #this will wait until we can lock the device\n                else:    #if \"wait for lock\" is false, just return false if it's busy\n                    if not self._nplab_action_lock.acquire(block=False):\n                        print(\"Could not acquire action lock, giving up.\")\n                        return False\n                return function(self, *args, **kwargs)\n            except Exception as e:\n                raise e #don't attempt to handle errors, just pass them on\n            finally:\n                self._nplab_action_lock.release() #don't leave the thing locked\n        return locked_action",
  "def decorator(function):\n        @functools.wraps(function)\n        def background_action(self, *args, **kwargs):\n            if background_by_default:\n                if not hasattr(self, \"_nplab_background_action_threads\"):\n                    self._nplab_background_action_threads = set([])\n                t = threading.Thread()\n                def worker_function():\n                    t.returned_value = function(self, *args, **kwargs)\n                    self._nplab_background_action_threads.remove(t)\n                t.run=worker_function\n                t.host_object = self\n                self._nplab_background_action_threads.add(t)\n                t.start()\n                def join_and_return_result(self): #this gets added to a thread so we can extract the return value\n                    self.join()\n                    return self.returned_value\n                t.join_and_return_result = functools.partial(join_and_return_result, t) #add method to the thread\n                return t\n            else:\n                return function(self, *args, **kwargs)\n        return background_action",
  "class Foo(object):\n        @background_action\n        @locked_action\n        def sayhello(self):\n            time.sleep(1)\n            for c in \"Hello World!\\n\":\n                time.sleep(0.1)\n                print((c), end=' ')\n            return \"Return Value\"\n        @background_action\n        def say(self, message):\n            time.sleep(1)\n            for c in message+\"\\n\":\n                time.sleep(0.1)\n                print((c), end=' ')\n            return len(message)",
  "class Bar(object):\n        def sayhello(self):\n            time.sleep(1)\n            for c in \"Hello World!\\n\":\n                time.sleep(0.1)\n                print((c), end=' ')\n        def say(self, message):\n            time.sleep(1)\n            for c in message+\"\\n\":\n                time.sleep(0.1)\n                print((c), end=' ')",
  "def locked_action(self, *args, **kwargs):\n            \"\"\"Perform an action, but use a lock so only one locked action can\n            happen at any time\"\"\"\n            #First: make sure the lock object exists\n            if not hasattr(self, \"_nplab_action_lock\"):\n                self._nplab_action_lock = threading.RLock()\n            try:\n                if wait_for_lock:\n                    self._nplab_action_lock.acquire() #this will wait until we can lock the device\n                else:    #if \"wait for lock\" is false, just return false if it's busy\n                    if not self._nplab_action_lock.acquire(block=False):\n                        print(\"Could not acquire action lock, giving up.\")\n                        return False\n                return function(self, *args, **kwargs)\n            except Exception as e:\n                raise e #don't attempt to handle errors, just pass them on\n            finally:\n                self._nplab_action_lock.release()",
  "def background_action(self, *args, **kwargs):\n            if background_by_default:\n                if not hasattr(self, \"_nplab_background_action_threads\"):\n                    self._nplab_background_action_threads = set([])\n                t = threading.Thread()\n                def worker_function():\n                    t.returned_value = function(self, *args, **kwargs)\n                    self._nplab_background_action_threads.remove(t)\n                t.run=worker_function\n                t.host_object = self\n                self._nplab_background_action_threads.add(t)\n                t.start()\n                def join_and_return_result(self): #this gets added to a thread so we can extract the return value\n                    self.join()\n                    return self.returned_value\n                t.join_and_return_result = functools.partial(join_and_return_result, t) #add method to the thread\n                return t\n            else:\n                return function(self, *args, **kwargs)",
  "def sayhello(self):\n            time.sleep(1)\n            for c in \"Hello World!\\n\":\n                time.sleep(0.1)\n                print((c), end=' ')\n            return \"Return Value\"",
  "def say(self, message):\n            time.sleep(1)\n            for c in message+\"\\n\":\n                time.sleep(0.1)\n                print((c), end=' ')\n            return len(message)",
  "def sayhello(self):\n            time.sleep(1)\n            for c in \"Hello World!\\n\":\n                time.sleep(0.1)\n                print((c), end=' ')",
  "def say(self, message):\n            time.sleep(1)\n            for c in message+\"\\n\":\n                time.sleep(0.1)\n                print((c), end=' ')",
  "def worker_function():\n                    t.returned_value = function(self, *args, **kwargs)\n                    self._nplab_background_action_threads.remove(t)",
  "def join_and_return_result(self): #this gets added to a thread so we can extract the return value\n                    self.join()\n                    return self.returned_value",
  "def get_qt_app(prevent_garbage_collection=True):\n    \"\"\"Retrieve or create the QApplication instance.\n\n    If running inside Spyder, or if you've used TraitsUI, the application\n    will already exist so you can't create another.  However, if you are\n    running from the command line you need to create an instance before\n    you can do anything.  This function takes care of it - it should always\n    return a valid QApplication, unless something goes wrong!\n    \"\"\"\n    app = QtWidgets.QApplication.instance()\n    if app is None:\n        app = QtWidgets.QApplication([])\n    assert app is not None, \"Problem creating the QApplication.\"\n    if prevent_garbage_collection:\n        # Keep a reference to the application if appropriate, to stop\n        # it disappearing due to garbage collection.\n        global _retained_qt_app\n        _retained_qt_app = app\n    return app",
  "def popup_widget(widget): # TODO: what is \"widget\"?\n    if widget.isVisible():  # doesn't need to be created and shown just brought to the front\n        pass\n    else:\n        ui = widget()\n        ui.show()",
  "def show_widget(Widget, *args, **kwargs):\n    \"\"\"Show the specified widget GUI in a QT application.  \n    \n    NB Widget is a class.\"\"\"\n    app = get_qt_app()\n    ui = Widget(*args, **kwargs)\n    ui.show()\n    sys.exit(app.exec_())",
  "def show_guis(instruments, block=True):\n    \"\"\"Display the Qt user interfaces of a list of instruments.\"\"\"\n    app = get_qt_app()\n    uis = [i.show_gui(blocking=False) for i in instruments if hasattr(i, \"get_qt_ui\")]\n    # DataBrowserImprovements swapped get_qt_ui for show_gui(block=False)\n    traits = [i.edit_traits() for i in instruments if hasattr(i, \"edit_traits\")]\n    for ui in uis:\n        ui.show()\n    if block:\n        return app.exec_()\n    else:\n        return uis, traits",
  "class Widget(QtGui.QWidget):\n        def __init__(self):\n            super(Widget, self).__init__()\n            self.setWindowTitle(self.__class__.__name__)\n            # a figure instance to plot on\n            self.figure = Figure()\n            self.ax = self.figure.add_subplot(111)\n            # this is the Canvas Widget that displays the `figure`\n            # it takes the `figure` instance as a parameter to __init__\n            self.canvas = FigureCanvas(self.figure)\n            # Just some button connected to `plot` method\n            self.button = QtGui.QPushButton('Plot')\n            self.button.clicked.connect(self.plot)\n            self.button.setToolTip('This is a <b>QPushButton</b> widget')\n            self.button.resize(self.button.sizeHint())\n            # set the layout\n            layout = QtGui.QVBoxLayout()\n            layout.addWidget(self.canvas)\n            layout.addWidget(self.button)\n            self.setLayout(layout)\n\n        def plot(self):\n            ''' plot some random stuff '''\n            # random data\n            print('plot')\n            data = [np.random.random() for i in range(1000)]\n            # create an axis\n            #ax = self.figure.add_subplot(111)\n            ax = self.figure.axes[0]\n            # discards the old graph\n            ax.hold(False)\n            # plot data\n            ax.plot(data, '*-')\n            # refresh canvas\n            self.canvas.draw()",
  "def __init__(self):\n            super(Widget, self).__init__()\n            self.setWindowTitle(self.__class__.__name__)\n            # a figure instance to plot on\n            self.figure = Figure()\n            self.ax = self.figure.add_subplot(111)\n            # this is the Canvas Widget that displays the `figure`\n            # it takes the `figure` instance as a parameter to __init__\n            self.canvas = FigureCanvas(self.figure)\n            # Just some button connected to `plot` method\n            self.button = QtGui.QPushButton('Plot')\n            self.button.clicked.connect(self.plot)\n            self.button.setToolTip('This is a <b>QPushButton</b> widget')\n            self.button.resize(self.button.sizeHint())\n            # set the layout\n            layout = QtGui.QVBoxLayout()\n            layout.addWidget(self.canvas)\n            layout.addWidget(self.button)\n            self.setLayout(layout)",
  "def plot(self):\n            ''' plot some random stuff '''\n            # random data\n            print('plot')\n            data = [np.random.random() for i in range(1000)]\n            # create an axis\n            #ax = self.figure.add_subplot(111)\n            ax = self.figure.axes[0]\n            # discards the old graph\n            ax.hold(False)\n            # plot data\n            ax.plot(data, '*-')\n            # refresh canvas\n            self.canvas.draw()",
  "class Image_Filter_box(Instrument):\n    threshold = DumbNotifiedProperty()\n    bin_fac = DumbNotifiedProperty()\n    min_size = DumbNotifiedProperty()\n    max_size = DumbNotifiedProperty()\n    bilat_height = DumbNotifiedProperty()\n    bilat_size = DumbNotifiedProperty()\n    morph_kernel_size = DumbNotifiedProperty()\n    show_particles = DumbNotifiedProperty()\n    return_original_with_particles = DumbNotifiedProperty()\n    def __init__(self,threshold = 40, bin_fac = 4,min_size = 2,max_size = 6,\n                 bilat_size = 3, bilat_height = 40, morph_kernel_size = 3):\n        self.threshold = threshold\n        self.bin_fac = bin_fac\n        self.min_size = min_size\n        self.max_size = max_size\n        self.bilat_size = bilat_size\n        self.bilat_height = bilat_height\n        self.morph_kernel_size = morph_kernel_size\n        self.filter_options = ['None','STBOC_with_size_filter','strided_rescale','StrBiThresOpen']\n        self.show_particles = False\n        self.return_original_with_particles = False\n        self.current_filter_index = 0\n        self.update_functions = []\n    \n    def current_filter(self,image):\n        if self.current_filter_proxy is None:\n            return image\n        else:\n            return self.current_filter_proxy(image)\n\n    def set_current_filter_index(self,filter_index):\n        filter_name = self.filter_options[filter_index]\n        self._filter_index = filter_index\n        if filter_name =='None':\n              self.current_filter_proxy = None\n        else:\n            self.current_filter_proxy = getattr(self,filter_name)\n        self._current_filter_str = filter_name\n\n    def get_current_filter_index(self):\n        return self._filter_index\n    current_filter_index = NotifiedProperty(fget=get_current_filter_index,fset=set_current_filter_index)\n\n    def STBOC_with_size_filter(self, g,\n                               return_centers=False,\n                               return_centers_and_radii=False,\n                               return_original_with_particles=False):\n        try:\n            if return_original_with_particles:\n                return STBOC_with_size_filter(g,\n                                          bin_fac= self.bin_fac,\n                                          bilat_size = self.bilat_size, bilat_height = self.bilat_height,\n                                          threshold =self.threshold,min_size = self.min_size,max_size = self.max_size,\n                                          morph_kernel_size = self.morph_kernel_size, show_particles = self.show_particles,\n                                          return_original_with_particles=True, return_centers=False)\n        \n            return STBOC_with_size_filter(g,\n                                          bin_fac=self.bin_fac,\n                                          bilat_size=self.bilat_size,\n                                          bilat_height=self.bilat_height,\n                                          threshold=self.threshold,\n                                          min_size=self.min_size,\n                                          max_size=self.max_size,\n                                          morph_kernel_size=self.morph_kernel_size,\n                                          show_particles=self.show_particles,\n                                          return_original_with_particles=self.return_original_with_particles,\n                                          return_centers=return_centers,\n                                          return_centers_and_radii=return_centers_and_radii)\n            \n                \n        except Exception as e:\n            self.log('Image processing has failed due to: '+str(e),level = 'WARN')\n            print(e, 'Image processsing exception')\n    def strided_rescale(self,g):\n        try:\n            return strided_rescale(g, bin_fac= self.bin_fac)\n        except Exception as e:\n            self.log('Image processing has failed due to: '+str(e),level = 'WARN')\n    \n    def StrBiThresOpen(self,g):\n        try:\n            return StrBiThresOpen(g, bin_fac= self.bin_fac,\n                                           bilat_size = self.bilat_size, bilat_height = self.bilat_height,\n                                           threshold =self.threshold,\n                                           morph_kernel_size = self.morph_kernel_size)\n        except Exception as e:\n            self.log('Image processing has failed due to: '+str(e),level = 'WARN')\n    def connect_function_to_property_changes(self,function):\n    #    print function\n        for variable_name in vars(self.__class__):\n            self.update_functions.append(function)\n            if (type(getattr(self.__class__,variable_name)) == DumbNotifiedProperty or\n                type(getattr(self.__class__,variable_name)) == NotifiedProperty):\n                \n                register_for_property_changes(self,variable_name,self.update_functions[-1])\n        \n    def get_qt_ui(self):\n        return Camera_filter_Control_ui(self)",
  "class Camera_filter_Control_ui(QuickControlBox):\n\n    '''Control Widget for the Shamrock spectrometer\n    '''\n    def __init__(self,filter_box):\n        super(Camera_filter_Control_ui,self).__init__(title = 'Camera_filter_Controls')\n        self.filter_box = filter_box\n        self.add_spinbox('threshold',vmin=-255,vmax=255)\n        self.add_spinbox('bin_fac' , vmin=1)\n        self.add_spinbox('bilat_size')\n        self.add_spinbox('bilat_height')\n        self.add_spinbox('min_size')\n        self.add_spinbox('max_size')\n        self.add_spinbox('morph_kernel_size')\n        self.add_checkbox('show_particles')\n        self.add_checkbox('return_original_with_particles')\n        self.add_combobox('current_filter_index',options = self.filter_box.filter_options)\n        self.auto_connect_by_name(controlled_object = self.filter_box)",
  "def strided_rescale(g, bin_fac=4):\n    try:\n        attrs = g.attrs\n        return_image_with_loc = True\n    except:\n        return_image_with_loc = False\n    g = g.sum(axis=2)\n    try:\n        strided = as_strided(g,\n            shape=(g.shape[0]//bin_fac, g.shape[1]//bin_fac, bin_fac, bin_fac),\n            strides=((g.strides[0]*bin_fac, g.strides[1]*bin_fac)+g.strides))\n        strided = strided.sum(axis=-1).sum(axis=-1)\n        strided = np.uint8((strided-np.min(strided))*254.0/(np.max(strided)-np.min(strided)))\n        strided = strided.repeat(bin_fac,0)\n        strided = strided.repeat(bin_fac,1)\n        if return_image_with_loc==True:\n            return ImageWithLocation(np.copy(strided),attrs = attrs)\n        else:\n            return np.copy(strided)\n    except Exception as e:\n        print(e)",
  "def StrBiThresOpen(g, \n                   bin_fac=4,\n                   threshold=40,\n                   bilat_size=3,\n                   bilat_height=40,\n                   morph_kernel_size=3):\n    try:\n        strided = strided_rescale(g, bin_fac=bin_fac)\n        strided = cv2.bilateralFilter(np.uint8(strided), bilat_size, bilat_size, 50) # noise reduction\n    #    strided[strided<threshold]=1\n      #  strided = cv2.adaptiveThreshold(strided,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\\\n     #       cv2.THRESH_BINARY,3,2)\n        strided = cv2.adaptiveThreshold(strided,255,cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_BINARY,101,-1*threshold)\n        \n        strided = cv2.bilateralFilter(np.uint8(strided),bilat_size,bilat_height/4,50)\n      #  strided[strided>threshold]-=threshold\n        kernel = np.ones((morph_kernel_size,morph_kernel_size),np.uint8)\n        strided = cv2.morphologyEx(strided, cv2.MORPH_OPEN, kernel)\n        strided = cv2.morphologyEx(strided, cv2.MORPH_CLOSE, kernel)\n        strided[strided!=0]=255\n        return np.copy(strided)\n    except Exception as e:\n        print('StrBiThresOpen error:' ,e)",
  "def STBOC_with_size_filter(g, \n                           bin_fac=4,\n                           bilat_size=3,\n                           bilat_height=40,\n                           threshold=20,\n                           min_size=2,\n                           max_size=6,\n                           morph_kernel_size=3,\n                           show_particles=False, \n                           return_original_with_particles=False,\n                           return_centers=False, \n                           return_centers_and_radii=False):\n   g = np.copy(g)\n   strided = StrBiThresOpen(g, bin_fac,threshold,bilat_size,bilat_height,morph_kernel_size)\n   contours, hierarchy = cv2.findContours(strided,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)[-2:]\n   centers = []\n   radii = []\n   for cnt in contours:\n       (x,y),radius = cv2.minEnclosingCircle(cnt)\n   #    center = (int(x),int(y))\n       center = (int(x),int(y))\n #      radius = int(radius)+2\n       if radius>max_size or radius<min_size: # set the binary image to 0\n           radius = int(radius)+2\n           strided[center[1]-radius:center[1]+radius,center[0]-radius:center[0]+radius] = 0\n       else:\n           M = cv2.moments(cnt, binaryImage = True) #find center of mass\n           center = (int(M['m10']/M['m00']),int(M['m01']/M['m00']))\n           centers.append(center)\n           radii.append(radius)\n   if return_centers:\n       if centers:\n           return np.array(centers)[:,::-1] # in numpy indexing\n       return None\n   if return_centers_and_radii:\n       if centers:\n           return np.array(centers)[:,::-1], np.array(radii)\n       return None\n   elif return_original_with_particles:\n #      g = cv2.cvtColor(g,cv2.COLOR_GRAY2RGB)\n  #     g = g#/255.0\n       for cnt,radius in zip(centers,radii):\n           cv2.circle(g, cnt, int(radius*2), (255, 0, 0), 2) # image with a red circle\n       return g\n   elif show_particles:\n\n  #         strided =  cv2.cvtColor(strided,cv2.COLOR_GRAY2RGB)\n #      strided_copy = np.copy(strided)\n       strided = strided[:,:,np.newaxis]\n       strided = strided.repeat(3,axis = 2)\n   #    strided=strided/255.0\n       for cnt,radius in zip(centers,radii):\n     #      print np.shape(strided_copy),  center\n           cv2.circle(strided, cnt, int(radius*2), (255,0,0), 2)\n   strided[strided!=0]=255\n   return strided",
  "def find_particles(self,img=None, border_pixels=50):\n    \"\"\"find particles in the supplied image, or in the camera image\"\"\"\n    self.threshold_image(self.denoise_image(\n            cv2.cvtColor(frame,cv2.COLOR_RGB2GRAY)))[self.border_pixels:-self.border_pixels,self.border_pixels:-self.border_pixels] #ignore the edges\n    labels, nlabels = ndimage.measurements.label(img)\n    return [np.array(p)+15 for p in ndimage.measurements.center_of_mass(img, labels, list(range(1,nlabels+1)))]",
  "def build_strided_filter(func):\n    def filter_func(image):\n        return func(strided_rescale(image))\n    return filter_func",
  "def __init__(self,threshold = 40, bin_fac = 4,min_size = 2,max_size = 6,\n                 bilat_size = 3, bilat_height = 40, morph_kernel_size = 3):\n        self.threshold = threshold\n        self.bin_fac = bin_fac\n        self.min_size = min_size\n        self.max_size = max_size\n        self.bilat_size = bilat_size\n        self.bilat_height = bilat_height\n        self.morph_kernel_size = morph_kernel_size\n        self.filter_options = ['None','STBOC_with_size_filter','strided_rescale','StrBiThresOpen']\n        self.show_particles = False\n        self.return_original_with_particles = False\n        self.current_filter_index = 0\n        self.update_functions = []",
  "def current_filter(self,image):\n        if self.current_filter_proxy is None:\n            return image\n        else:\n            return self.current_filter_proxy(image)",
  "def set_current_filter_index(self,filter_index):\n        filter_name = self.filter_options[filter_index]\n        self._filter_index = filter_index\n        if filter_name =='None':\n              self.current_filter_proxy = None\n        else:\n            self.current_filter_proxy = getattr(self,filter_name)\n        self._current_filter_str = filter_name",
  "def get_current_filter_index(self):\n        return self._filter_index",
  "def STBOC_with_size_filter(self, g,\n                               return_centers=False,\n                               return_centers_and_radii=False,\n                               return_original_with_particles=False):\n        try:\n            if return_original_with_particles:\n                return STBOC_with_size_filter(g,\n                                          bin_fac= self.bin_fac,\n                                          bilat_size = self.bilat_size, bilat_height = self.bilat_height,\n                                          threshold =self.threshold,min_size = self.min_size,max_size = self.max_size,\n                                          morph_kernel_size = self.morph_kernel_size, show_particles = self.show_particles,\n                                          return_original_with_particles=True, return_centers=False)\n        \n            return STBOC_with_size_filter(g,\n                                          bin_fac=self.bin_fac,\n                                          bilat_size=self.bilat_size,\n                                          bilat_height=self.bilat_height,\n                                          threshold=self.threshold,\n                                          min_size=self.min_size,\n                                          max_size=self.max_size,\n                                          morph_kernel_size=self.morph_kernel_size,\n                                          show_particles=self.show_particles,\n                                          return_original_with_particles=self.return_original_with_particles,\n                                          return_centers=return_centers,\n                                          return_centers_and_radii=return_centers_and_radii)\n            \n                \n        except Exception as e:\n            self.log('Image processing has failed due to: '+str(e),level = 'WARN')\n            print(e, 'Image processsing exception')",
  "def strided_rescale(self,g):\n        try:\n            return strided_rescale(g, bin_fac= self.bin_fac)\n        except Exception as e:\n            self.log('Image processing has failed due to: '+str(e),level = 'WARN')",
  "def StrBiThresOpen(self,g):\n        try:\n            return StrBiThresOpen(g, bin_fac= self.bin_fac,\n                                           bilat_size = self.bilat_size, bilat_height = self.bilat_height,\n                                           threshold =self.threshold,\n                                           morph_kernel_size = self.morph_kernel_size)\n        except Exception as e:\n            self.log('Image processing has failed due to: '+str(e),level = 'WARN')",
  "def connect_function_to_property_changes(self,function):\n    #    print function\n        for variable_name in vars(self.__class__):\n            self.update_functions.append(function)\n            if (type(getattr(self.__class__,variable_name)) == DumbNotifiedProperty or\n                type(getattr(self.__class__,variable_name)) == NotifiedProperty):\n                \n                register_for_property_changes(self,variable_name,self.update_functions[-1])",
  "def get_qt_ui(self):\n        return Camera_filter_Control_ui(self)",
  "def __init__(self,filter_box):\n        super(Camera_filter_Control_ui,self).__init__(title = 'Camera_filter_Controls')\n        self.filter_box = filter_box\n        self.add_spinbox('threshold',vmin=-255,vmax=255)\n        self.add_spinbox('bin_fac' , vmin=1)\n        self.add_spinbox('bilat_size')\n        self.add_spinbox('bilat_height')\n        self.add_spinbox('min_size')\n        self.add_spinbox('max_size')\n        self.add_spinbox('morph_kernel_size')\n        self.add_checkbox('show_particles')\n        self.add_checkbox('return_original_with_particles')\n        self.add_combobox('current_filter_index',options = self.filter_box.filter_options)\n        self.auto_connect_by_name(controlled_object = self.filter_box)",
  "def filter_func(image):\n        return func(strided_rescale(image))",
  "def log(message, from_class=None, from_object=None,\n        create_datafile=False, assert_datafile=False, level= 'info'):\n        \"\"\"Add a message to the NPLab log, stored in the current datafile.\n\n        This function will put a message in the nplab_log group in the root of\n        the current datafile (i.e. the HDF5 file returned by\n        `nplab.current_datafile()`).  It is automatically timestamped and named.\n\n        @param: from_class: The class (or a string containing it) relating to\n        the message.  Automatically filled in if from_object is supplied.\n        @param: from_object: The object originating the log message.  We save a\n        string representing the object's ID (allows us to distinguish between\n        concurrent instances).\n        @param: create_datafile: By default, log messages are discarded before\n        the datafile exists - specifying True here will attempt to create a\n        new datafile (which may involve popping up a GUI).\n        @param: assert_datafile: Set to true to raise an exception if there is\n        no current datafile.\n        @param: level: This can either be used to add a value of 'importance' \n        to the log, the default is 'info'. The other options are 'debug',\n        'warn'(as in warning) and 'error', and 'critical'.\n\n        Note that if you are calling this from an `Instrument` subclass you\n        should consider using `self.log()` which automatically fills in the\n        object and class fields.\n        \"\"\"\n        try:\n            if hasattr(from_object,'_logger'):\n                getattr(from_object._logger,level)(message)\n            df = nplab.current_datafile(create_if_none=create_datafile,\n                                        create_if_closed=create_datafile)\n            logs = df.require_group(\"nplab_log\")\n            logs.attrs['log_group'] = True \n            dset = logs.create_dataset(\"entry_%d\",\n                                       data=np.string_(message),\n                                       timestamp=True)\n            #save the object and class if supplied.\n            if from_object is not None:\n                dset.attrs.create(\"object\",np.string_(\"%x\" % id(from_object)))\n                dset.attrs['log_dset'] = True\n                dset.attrs['level'] = level\n                if from_class is None:\n                    #extract the class of the object if it's not specified\n                    try:\n                        from_class = from_object.__class__\n                    except:\n                        pass\n            if from_class is not None:\n                dset.attrs.create(\"class\",np.string_(from_class))\n\n        except Exception as e:\n#            print \"Couldn't log to file: \" + message\n#            print 'due to error', e\n            if assert_datafile:\n                print(\"Error saving log message - raising exception.\")\n                raise e",
  "def formatter_message(message, use_color = True):\n    if use_color:\n        message = message.replace(\"$RESET\", RESET_SEQ).replace(\"$BOLD\", BOLD_SEQ)\n    else:\n        message = message.replace(\"$RESET\", \"\").replace(\"$BOLD\", \"\")\n    return message",
  "class ColoredFormatter(logging.Formatter):\n    def format(self, record):\n        levelname = record.levelname\n        if levelname in COLORS:\n            levelname_color = COLOR_SEQ % (30 + COLORS[levelname]) + levelname + RESET_SEQ\n            record.levelname = levelname_color\n        return logging.Formatter.format(self, record)",
  "def create_logger(name='Experiment', **kwargs):\n    '''This functions defines the Logger called Experiment, with the relevant colored formatting'''\n    if 'level' in kwargs:\n        LOGGER_LEVEL = kwargs['level']\n    else:\n        LOGGER_LEVEL = 'INFO'\n    if 'filename' in kwargs:\n        LOGGER_FILE = kwargs['filename']\n    else:\n        LOGGER_FILE = None\n\n    test = logging.getLogger(name)\n    test.propagate = False\n    test.setLevel(LOGGER_LEVEL)\n\n    if any([isinstance(x, logging.StreamHandler) for x in test.handlers]):\n        test.warn('Logger already has a StreamHandler!')\n    else:\n        fh = logging.StreamHandler(sys.stdout)\n        f = ColoredFormatter('[%(name)s] - %(levelname)s: %(message)s - %(asctime)s ', '%H:%M')\n        fh.setFormatter(f)\n        test.addHandler(fh)\n\n    if LOGGER_FILE is not None:\n        if any([isinstance(x, logging.FileHandler) for x in test.handlers]):\n            test.warn('Logger already has a FileHandler!')\n        else:\n            fh = logging.FileHandler(LOGGER_FILE)\n            fh.setFormatter(logging.Formatter('[%(name)s] - %(levelname)s: %(message)s - %(asctime)s ', datefmt='%H:%M'))\n            fh.setLevel(LOGGER_LEVEL)\n            test.addHandler(fh)\n\n    return test",
  "def format(self, record):\n        levelname = record.levelname\n        if levelname in COLORS:\n            levelname_color = COLOR_SEQ % (30 + COLORS[levelname]) + levelname + RESET_SEQ\n            record.levelname = levelname_color\n        return logging.Formatter.format(self, record)",
  "def monitor_property(instance, property_name, how_long, how_often, warn_limits=None):\n    \"\"\"\n    Given an nplab instrument instance and one of it's properties, it creates a deque containing the property's value\n    over time. The deque gets updated in a background thread.\n\n    :param instance: nplab.Instrument\n    :param property_name: str\n    :param how_long: float. Length of time you want to monitor for. In seconds\n    :param how_often: float. Interval between measurements. In seconds\n    :param warn_limits: None or 2-tuple. If the monitored value goes outside these limits, throws out a warning.\n    :return:\n    \"\"\"\n    setattr(instance, property_name + '_history', collections.deque(maxlen=int(how_long / how_often)))\n    setattr(instance, '_monitoring_' + property_name, True)\n\n    def monitor():\n        while getattr(instance, '_monitoring_' + property_name):\n            value = getattr(instance, property_name)\n            if warn_limits is not None:\n                if value < warn_limits[0] or value > warn_limits[1]:\n                    setattr(instance, '_monitoring_' + property_name, False)\n                    raise ValueError('%s=%g is outside of range' % (property_name, value))\n            getattr(instance, property_name + '_history').append([time.time(), value])\n            time.sleep(how_often)\n\n    monitor_thread = threading.Thread(target=monitor)\n    monitor_thread.setDaemon(True)  # a daemon thread will not prevent the program from exiting\n    monitor_thread.start()",
  "def monitor():\n        while getattr(instance, '_monitoring_' + property_name):\n            value = getattr(instance, property_name)\n            if warn_limits is not None:\n                if value < warn_limits[0] or value > warn_limits[1]:\n                    setattr(instance, '_monitoring_' + property_name, False)\n                    raise ValueError('%s=%g is outside of range' % (property_name, value))\n            getattr(instance, property_name + '_history').append([time.time(), value])\n            time.sleep(how_often)",
  "class ThreadBox3000(QuickControlBox):\n    '''A gui/threading utility for running a function in a thread with a simple control window '''\n    def __init__(self,function= None):\n        super(ThreadBox3000,self).__init__('ThreadBox3000')\n        self.function = function\n    def add_controls(self,function):\n        '''Inspect the inputted function and automatically generate controls by looking the defaults '''\n        full_args = inspect.getargspec(function)\n        self.add_checkbox('save_returned')\n        self.add_lineedit('function name')\n        self.controls['function name'].setText(str(function))\n        self.controls['function name'].setReadOnly(True)\n        if 'self' in full_args.args:\n            full_args.args.remove('self')\n        if (full_args.defaults != None \n                and len(full_args.args)==len(full_args.defaults)):\n            for arg, default in zip(full_args.args, full_args.defaults):\n                if type(default) == int:\n                    self.add_spinbox(arg)\n                    self.controls[arg].setValue(default)\n                elif type(default) == float:\n                    self.add_doublespinbox(arg)\n                    self.controls[arg].setValue(default)\n                elif type(default) == bool:\n                    self.add_checkbox(arg)\n                    self.controls[arg].setChecked(default)\n                elif hasattr(default,'__call__'):\n                    self.add_lineedit(arg)\n                    try:\n                        self.controls[arg].setText(default.__name__)\n                    except Exception as e:\n                        print(e)\n                        self.controls[arg].setText(default.__name__)\n                    self.controls[arg].setReadOnly(True)\n                        \n                else:\n                    self.add_lineedit(arg)\n                    if type(default)==np.ndarray:\n                        \n                        temp_txt = np.array2string(default).replace('   ',',') # danger - might need to check formatter\n                        temp_txt = temp_txt.replace('  ',',')\n                        temp_txt = temp_txt.replace(' ',',')\n                        temp_txt = temp_txt.replace('[,','[')\n                        temp_txt = temp_txt.replace(',]',']')\n                        txt ='np.array('+temp_txt+')'\n                    elif type(default)==str:\n                        txt= \"'\"+default+\"'\"\n                    else:\n                        txt = str(default)\n                    self.controls[arg].setText(txt)\n        self.add_button('start')\n        self.controls['start'].pressed.connect(self.start)                \n    def construct_payload(self):\n        '''Construct the function with the arguments set in the control window '''\n        def payload(save_group=df._current_group):\n            import numpy as np\n            input_variables= {}\n            for variable in list(self.controls.keys()):\n                if variable == 'save_returned' or variable == 'start' or variable == 'function name':\n                    continue\n                \n                variable_control = self.controls[variable]\n                if type(variable_control) == type(QtWidgets.QLineEdit()) and variable_control.isReadOnly()==True:\n                    fullargs = inspect.getargspec(self.function)\n                    args = fullargs.args\n                    try:\n                        args.remove('self')\n                    except ValueError:\n                        pass\n                    args = np.array(args)\n                    defaults = np.array(fullargs.defaults)\n                    default_value = defaults[args==variable]\n                    input_variables[variable]=default_value[0]\n                    print(variable, default_value)\n                elif (type(variable_control) == QtWidgets.QSpinBox or \n                    type(variable_control) == QtWidgets.QDoubleSpinBox):\n                    input_variables[variable]=variable_control.value()\n                elif type(variable_control) == QtWidgets.QLineEdit:\n                    try:\n                        exec('temp_var = '+variable_control.text(), locals())   \n                        input_variables[variable]=temp_var\n\n                    except Exception as e:\n                        print(e)\n                        print('Qlineedit input error for ',variable)\n                elif type(variable_control) == QtWidgets.QCheckBox:\n                    input_variables[variable]=variable_control.isChecked()\n            try:\n                function_returns = self.function(**input_variables)\n            except TypeError:\n                print(input_variables)\n                print('function: ',task)\n                print('Did not recieve the correct inputs!')\n                print('did you make an error in your lineedit inputs?')\n            if self.controls['save_returned'].isChecked()==True:\n                save_group.create_dataset(task,\n                                          data = function_returns,\n                                          attrs = input_variables)\n        return payload\n    def clean_box(self):\n        '''Remove all of the controls from the box '''\n        if len(self.children())>1: #check if the box contains any controls\n            for child in self.children()[1:]:\n                child.deleteLater()\n            self.controls = dict()\n    def set_function(self,function):\n        '''Sets the function, by clearing the old function with 'clean_box' \n            and adding the controls for he new function '''\n        self._function = function\n        self.clean_box()\n        if function is not None:\n            self.add_controls(function)\n    def get_function(self):\n        '''The getter for the current function '''\n        return self._function\n    function = NotifiedProperty(fget = get_function,fset = set_function)\n    @background_action\n    @locked_action\n    def start(self):\n        '''Construct and start the function '''\n        self.construct_payload()()\n    def get_qt_ui(self):\n        return self",
  "def __init__(self,function= None):\n        super(ThreadBox3000,self).__init__('ThreadBox3000')\n        self.function = function",
  "def add_controls(self,function):\n        '''Inspect the inputted function and automatically generate controls by looking the defaults '''\n        full_args = inspect.getargspec(function)\n        self.add_checkbox('save_returned')\n        self.add_lineedit('function name')\n        self.controls['function name'].setText(str(function))\n        self.controls['function name'].setReadOnly(True)\n        if 'self' in full_args.args:\n            full_args.args.remove('self')\n        if (full_args.defaults != None \n                and len(full_args.args)==len(full_args.defaults)):\n            for arg, default in zip(full_args.args, full_args.defaults):\n                if type(default) == int:\n                    self.add_spinbox(arg)\n                    self.controls[arg].setValue(default)\n                elif type(default) == float:\n                    self.add_doublespinbox(arg)\n                    self.controls[arg].setValue(default)\n                elif type(default) == bool:\n                    self.add_checkbox(arg)\n                    self.controls[arg].setChecked(default)\n                elif hasattr(default,'__call__'):\n                    self.add_lineedit(arg)\n                    try:\n                        self.controls[arg].setText(default.__name__)\n                    except Exception as e:\n                        print(e)\n                        self.controls[arg].setText(default.__name__)\n                    self.controls[arg].setReadOnly(True)\n                        \n                else:\n                    self.add_lineedit(arg)\n                    if type(default)==np.ndarray:\n                        \n                        temp_txt = np.array2string(default).replace('   ',',') # danger - might need to check formatter\n                        temp_txt = temp_txt.replace('  ',',')\n                        temp_txt = temp_txt.replace(' ',',')\n                        temp_txt = temp_txt.replace('[,','[')\n                        temp_txt = temp_txt.replace(',]',']')\n                        txt ='np.array('+temp_txt+')'\n                    elif type(default)==str:\n                        txt= \"'\"+default+\"'\"\n                    else:\n                        txt = str(default)\n                    self.controls[arg].setText(txt)\n        self.add_button('start')\n        self.controls['start'].pressed.connect(self.start)",
  "def construct_payload(self):\n        '''Construct the function with the arguments set in the control window '''\n        def payload(save_group=df._current_group):\n            import numpy as np\n            input_variables= {}\n            for variable in list(self.controls.keys()):\n                if variable == 'save_returned' or variable == 'start' or variable == 'function name':\n                    continue\n                \n                variable_control = self.controls[variable]\n                if type(variable_control) == type(QtWidgets.QLineEdit()) and variable_control.isReadOnly()==True:\n                    fullargs = inspect.getargspec(self.function)\n                    args = fullargs.args\n                    try:\n                        args.remove('self')\n                    except ValueError:\n                        pass\n                    args = np.array(args)\n                    defaults = np.array(fullargs.defaults)\n                    default_value = defaults[args==variable]\n                    input_variables[variable]=default_value[0]\n                    print(variable, default_value)\n                elif (type(variable_control) == QtWidgets.QSpinBox or \n                    type(variable_control) == QtWidgets.QDoubleSpinBox):\n                    input_variables[variable]=variable_control.value()\n                elif type(variable_control) == QtWidgets.QLineEdit:\n                    try:\n                        exec('temp_var = '+variable_control.text(), locals())   \n                        input_variables[variable]=temp_var\n\n                    except Exception as e:\n                        print(e)\n                        print('Qlineedit input error for ',variable)\n                elif type(variable_control) == QtWidgets.QCheckBox:\n                    input_variables[variable]=variable_control.isChecked()\n            try:\n                function_returns = self.function(**input_variables)\n            except TypeError:\n                print(input_variables)\n                print('function: ',task)\n                print('Did not recieve the correct inputs!')\n                print('did you make an error in your lineedit inputs?')\n            if self.controls['save_returned'].isChecked()==True:\n                save_group.create_dataset(task,\n                                          data = function_returns,\n                                          attrs = input_variables)\n        return payload",
  "def clean_box(self):\n        '''Remove all of the controls from the box '''\n        if len(self.children())>1: #check if the box contains any controls\n            for child in self.children()[1:]:\n                child.deleteLater()\n            self.controls = dict()",
  "def set_function(self,function):\n        '''Sets the function, by clearing the old function with 'clean_box' \n            and adding the controls for he new function '''\n        self._function = function\n        self.clean_box()\n        if function is not None:\n            self.add_controls(function)",
  "def get_function(self):\n        '''The getter for the current function '''\n        return self._function",
  "def start(self):\n        '''Construct and start the function '''\n        self.construct_payload()()",
  "def get_qt_ui(self):\n        return self",
  "def print_hello(spade = '1'):\n        print(spade)",
  "def payload(save_group=df._current_group):\n            import numpy as np\n            input_variables= {}\n            for variable in list(self.controls.keys()):\n                if variable == 'save_returned' or variable == 'start' or variable == 'function name':\n                    continue\n                \n                variable_control = self.controls[variable]\n                if type(variable_control) == type(QtWidgets.QLineEdit()) and variable_control.isReadOnly()==True:\n                    fullargs = inspect.getargspec(self.function)\n                    args = fullargs.args\n                    try:\n                        args.remove('self')\n                    except ValueError:\n                        pass\n                    args = np.array(args)\n                    defaults = np.array(fullargs.defaults)\n                    default_value = defaults[args==variable]\n                    input_variables[variable]=default_value[0]\n                    print(variable, default_value)\n                elif (type(variable_control) == QtWidgets.QSpinBox or \n                    type(variable_control) == QtWidgets.QDoubleSpinBox):\n                    input_variables[variable]=variable_control.value()\n                elif type(variable_control) == QtWidgets.QLineEdit:\n                    try:\n                        exec('temp_var = '+variable_control.text(), locals())   \n                        input_variables[variable]=temp_var\n\n                    except Exception as e:\n                        print(e)\n                        print('Qlineedit input error for ',variable)\n                elif type(variable_control) == QtWidgets.QCheckBox:\n                    input_variables[variable]=variable_control.isChecked()\n            try:\n                function_returns = self.function(**input_variables)\n            except TypeError:\n                print(input_variables)\n                print('function: ',task)\n                print('Did not recieve the correct inputs!')\n                print('did you make an error in your lineedit inputs?')\n            if self.controls['save_returned'].isChecked()==True:\n                save_group.create_dataset(task,\n                                          data = function_returns,\n                                          attrs = input_variables)",
  "class ShowGUIMixin():\n    \"\"\"A mixin class to provide standard GUI functionality.\n\n    This class provides one method, which pops up a GUI window using \n    either a supplied Qt widget or using TraitsUI.\n    \"\"\"\n    __gui_instance = None\n    def show_gui(self, blocking=None, block=None, force_new_window=False, dark=False):\n        \"\"\"Display a GUI window for the class.\n\n        You may override this method to display a window to control the\n        object.  However, it's better (and less work) to provide a\n        method `get_qt_ui()`.  This shoudl return a QWidget subclass that\n        is the GUI for the object.  This method will take care of ensuring\n        there's a Qt application object and displaying the GUI.\n        \n        If you are using traitsui, then edit_traits/configure_traits \n        methods exist, and this method will simply pop up a traits window\n        for the object.\n\n        If you use blocking=False, it will return immediately - this allows\n        you to continue using the console, assuming there's already a Qt\n        application running (usually the case if you're running from \n        Spyder).  NB you may want to retain the return value if using this\n        mode, as otherwise the GUI may be garbage-collected and disappear.\n        For compatibility, this function accepts either ``block`` or\n        ``blocking`` as a keyword argument - if either is not None it will\n        use that value, otherwise it defaults to ``True``.\n\n        In the future, blocking=False may spawn a Qt application object in\n        a background thread - but that's not currently done so we rely on\n        a Qt application running already (e.g. via the \"input hook\").\n        \n        When using Qt, we default to only creating one UI, and return a\n        handle to it each time this is called.  If ``force_new_window`` is \n        set to `True`, a new widget will be created regardless.  This may\n        cause issues if the retained reference to the GUI in the object is\n        the only one existing - the previous window may disappear.\n        \"\"\"\n        if blocking is None and block is not None:\n            blocking = block # Allow the use of either argument name\n        if blocking is None:\n            blocking = True # We default to True.\n        if hasattr(self,'get_qt_ui'):\n            # NB this dynamic import is important to avoid saddling all of\n            # nplab with dependencies on Qt.\n            from nplab.utils.gui import QtCore, QtGui, QtWidgets, get_qt_app\n            app = get_qt_app()\n            if dark: app.setStyleSheet(qdarkstyle.load_stylesheet())\n            if force_new_window or not isinstance(self.__gui_instance, QtWidgets.QWidget):\n                # create the widget if it doesn't exist already, or if we've been\n                # told to make a new one\n                self.__gui_instance = self.get_qt_ui()\n            ui = self.__gui_instance\n            ui.show()\n            ui.activateWindow() #flash the taskbar entry to make it obvious\n            if blocking:\n                print(\"Running GUI, this will block the command line until the window is closed.\")\n                ui.windowModality = QtCore.Qt.ApplicationModal\n\n                try:\n                    return app.exec_()\n                except:\n                    print(\"Could not run the Qt application: perhaps it is already running?\")\n                    return\n            else:\n                return ui\n        else:\n            try:\n                if blocking:\n                    self.configure_traits()\n                else:\n                    self.edit_traits()\n            except AttributeError:\n                raise NotImplementedError(\"It looks like the show_gui \\\n                          method hasn't been subclassed, there isn't a \\\n                          get_qt_ui() method, and the instrument is not \\\n                          using traitsui.\")",
  "def show_gui(self, blocking=None, block=None, force_new_window=False, dark=False):\n        \"\"\"Display a GUI window for the class.\n\n        You may override this method to display a window to control the\n        object.  However, it's better (and less work) to provide a\n        method `get_qt_ui()`.  This shoudl return a QWidget subclass that\n        is the GUI for the object.  This method will take care of ensuring\n        there's a Qt application object and displaying the GUI.\n        \n        If you are using traitsui, then edit_traits/configure_traits \n        methods exist, and this method will simply pop up a traits window\n        for the object.\n\n        If you use blocking=False, it will return immediately - this allows\n        you to continue using the console, assuming there's already a Qt\n        application running (usually the case if you're running from \n        Spyder).  NB you may want to retain the return value if using this\n        mode, as otherwise the GUI may be garbage-collected and disappear.\n        For compatibility, this function accepts either ``block`` or\n        ``blocking`` as a keyword argument - if either is not None it will\n        use that value, otherwise it defaults to ``True``.\n\n        In the future, blocking=False may spawn a Qt application object in\n        a background thread - but that's not currently done so we rely on\n        a Qt application running already (e.g. via the \"input hook\").\n        \n        When using Qt, we default to only creating one UI, and return a\n        handle to it each time this is called.  If ``force_new_window`` is \n        set to `True`, a new widget will be created regardless.  This may\n        cause issues if the retained reference to the GUI in the object is\n        the only one existing - the previous window may disappear.\n        \"\"\"\n        if blocking is None and block is not None:\n            blocking = block # Allow the use of either argument name\n        if blocking is None:\n            blocking = True # We default to True.\n        if hasattr(self,'get_qt_ui'):\n            # NB this dynamic import is important to avoid saddling all of\n            # nplab with dependencies on Qt.\n            from nplab.utils.gui import QtCore, QtGui, QtWidgets, get_qt_app\n            app = get_qt_app()\n            if dark: app.setStyleSheet(qdarkstyle.load_stylesheet())\n            if force_new_window or not isinstance(self.__gui_instance, QtWidgets.QWidget):\n                # create the widget if it doesn't exist already, or if we've been\n                # told to make a new one\n                self.__gui_instance = self.get_qt_ui()\n            ui = self.__gui_instance\n            ui.show()\n            ui.activateWindow() #flash the taskbar entry to make it obvious\n            if blocking:\n                print(\"Running GUI, this will block the command line until the window is closed.\")\n                ui.windowModality = QtCore.Qt.ApplicationModal\n\n                try:\n                    return app.exec_()\n                except:\n                    print(\"Could not run the Qt application: perhaps it is already running?\")\n                    return\n            else:\n                return ui\n        else:\n            try:\n                if blocking:\n                    self.configure_traits()\n                else:\n                    self.edit_traits()\n            except AttributeError:\n                raise NotImplementedError(\"It looks like the show_gui \\\n                          method hasn't been subclassed, there isn't a \\\n                          get_qt_ui() method, and the instrument is not \\\n                          using traitsui.\")",
  "def nm_to_hz(nm, laser):\n    return (c / (laser * 1e-9) - c / (nm * 1e-9))",
  "def hz_to_nm(hz, laser):\n    return 1e9 / (1 / (laser * 1e-9) - hz / c)",
  "def ev_to_joules(ev, *args, **kwargs):\n    return e * ev",
  "def joules_to_ev(joules, *args, **kwargs):\n    return joules / e",
  "def joules_to_hz(joules, *args, **kwargs):\n    return joules / h",
  "def hz_to_joules(hz, *args, **kwargs):\n    return hz * h",
  "def ev_to_hz(ev, *args, **kwargs):\n    return joules_to_hz(ev_to_joules(ev))",
  "def hz_to_ev(hz, *args, **kwargs):\n    return joules_to_ev(hz_to_joules(hz))",
  "def nm_to_hz(nm, *args, **kwargs):\n    return c / (nm * 1e-9)",
  "def hz_to_nm(hz, *args, **kwargs):\n    return 1e9 / (hz / c)",
  "def cm_to_hz(cm, *args, **kwargs):\n    return cm * c * 100",
  "def hz_to_cm(hz, *args, **kwargs):\n    return 0.01 * hz / c",
  "def thz_to_hz(thz, *args, **kwargs):\n    return thz * 1e12",
  "def hz_to_thz(hz, *args, **kwargs):\n    return hz * 1e-12",
  "def hz_to_rads(hz, *args, **kargs):\n    return 2 * pi * hz",
  "def rads_to_hz(rads, *args, **kargs):\n    return rads / (2 * pi)",
  "class _to:\n    pass",
  "def _conversion_factory(conversions_dict, start_unit, end_unit):\n    f = conversions_dict[\"to_hz\"][start_unit]\n    \n    @wraps(f)\n    @np.vectorize\n    def conv(value, *args, **kwargs):\n        return conversions_dict[\"hz_to\"][end_unit](\n            f(value, *args, **kwargs), *args, **kwargs\n        )\n\n    conv.__doc__ = f\"{full_unit_names[start_unit]} to {full_unit_names[end_unit]}\"\n    return conv",
  "class Convert:\n    def __init__(self, conversions):\n        for start_unit in conversions[\"to_hz\"]:\n            setattr(\n                self,\n                start_unit,\n                To(start_unit, end_units=conversions[\"hz_to\"], conversions=conversions),\n            )",
  "class To:\n    def __init__(self, start_unit, end_units, conversions):\n        self.to = _to()\n        for end_unit in end_units:\n            setattr(\n                self.to,\n                end_unit,\n                _conversion_factory(\n                    conversions,\n                    start_unit,\n                    end_unit,\n                ),\n            )",
  "def conv(value, *args, **kwargs):\n        return conversions_dict[\"hz_to\"][end_unit](\n            f(value, *args, **kwargs), *args, **kwargs\n        )",
  "def __init__(self, conversions):\n        for start_unit in conversions[\"to_hz\"]:\n            setattr(\n                self,\n                start_unit,\n                To(start_unit, end_units=conversions[\"hz_to\"], conversions=conversions),\n            )",
  "def __init__(self, start_unit, end_units, conversions):\n        self.to = _to()\n        for end_unit in end_units:\n            setattr(\n                self.to,\n                end_unit,\n                _conversion_factory(\n                    conversions,\n                    start_unit,\n                    end_unit,\n                ),\n            )",
  "class ExperimentStopped(Exception):\n    \"\"\"An exception raised to stop an experiment running in a background thread.\"\"\"\n    pass",
  "class Experiment(Instrument):\n    \"\"\"A class representing an experimental protocol.\n    \n    This base class is a subclass of Instrument, so it provides all the GUI\n    code and data management that instruments have.  It's also got an\n    improved logging mechanism, designed for use as a status display, and some\n    template methods for running a long experiment in the background.\n    \"\"\"\n    \n    latest_data = DumbNotifiedProperty(doc=\"The last dataset/group we acquired\")\n    log_messages = DumbNotifiedProperty(doc=\"Log messages from the latest run\")\n    log_to_console = False\n    experiment_can_be_safely_aborted = False # set to true if you want to suppress warnings about ExperimentStopped\n    \n    def __init__(self):\n        \"\"\"Create an instance of the Experiment class\"\"\"\n        super(Experiment, self).__init__()\n        self._stop_event = threading.Event()\n        self._finished_event = threading.Event()\n        self._experiment_thread = None\n        self.log_messages = \"\"\n\n    def prepare_to_run(self, *args, **kwargs):\n        \"\"\"This method is always run in the foreground thread before run()\n\n        Use this method if you might need to pop up a GUI, for example.  The\n        most common use of this would be to create a data group or to ensure\n        the current data file exists - doing that in run() could give rise\n        to nasty threading problems.  By default, it does nothing.\n\n        The arguments are passed through from start() to here, so you should\n        either use or ignore them as appropriate.  These are the same args\n        as are passed to run(), so if one of the two functions requires an\n        argument you should make sure the other won't fail if the same\n        argument is passed to it (simple rule: accept *args, **kwargs in\n        both, in addition to any arguments you might have).\n        \"\"\"\n        pass\n\n    def run(self, *args, **kwargs):\n        \"\"\"This method should be the meat of the experiment (needs overriden).\n        \n        This is where your experiment code goes.  Note that you should use\n        `self.wait_or_stop()` to pause your experiment between readings, to\n        allow the background thread to be stopped if necessary.\n        \n        If you set `self.latest_data`, this may be used to display your\n        results in real time.  You can also use `self.log()` to output text\n        describing the experiment's progress; this may be picked up and \n        displayed graphically or in the console.\n\n        The arguments are passed through from start() to here, so you should\n        either use or ignore them as appropriate.  These are the same args\n        as are passed to run(), so if one of the two functions requires an\n        argument you should make sure the other won't fail if the same\n        argument is passed to it (simple rule: accept *args, **kwargs in\n        both, in addition to any arguments you might have).\n        \"\"\"\n        NotImplementedError(\"The run() method of an Experiment must be overridden!\")\n        \n    def wait_or_stop(self, timeout, raise_exception=True):\n        \"\"\"Wait for the specified time in seconds.  Stop if requested.\n        \n        This waits for a given time, unless the experiment has been manually \n        stopped, in which case it will terminate the thread by raising an\n        ExperimentStopped exception.  You should call this whenever your\n        experiment is in a state that would be OK to stop, such as between\n        readings.\n        \n        If raise_exception is False, it will simply return False when the\n        experiment should stop.  This is appropriate if you want to use it in a\n        while loop, e.g. ``while self.wait_or_stop(10,raise_exception=False):``\n        \n        You may want to explicitly handle the ExperimentStopped exception to\n        close down cleanly.\n        \"\"\"\n        if self._stop_event.wait(timeout):\n            if raise_exception:\n                raise ExperimentStopped()\n        return True\n\n    @background_action\n    @locked_action\n    def run_in_background(self, *args, **kwargs):\n        \"\"\"Run the experiment in a background thread.\n        \n        This is important in order to keep the GUI responsive.\n        \"\"\"\n        self.log_messages = \"\"\n        self._stop_event.clear()\n        self._finished_event.clear()\n        self.run(*args, **kwargs)\n        self._finished_event.set()\n        \n    def start(self, *args, **kwargs):\n        \"\"\"Start the experiment running in a background thread.  See run_in_background.\"\"\"\n        assert self.running == False, \"Can't start the experiment when it is already running!\"\n        self.prepare_to_run(*args, **kwargs)\n        self._experiment_thread = self.run_in_background(*args, **kwargs)\n        \n    def stop(self, join=False):\n        \"\"\"Stop the experiment running, if supported.  May take a little while.\"\"\"\n        self._stop_event.set()\n        if join:\n            try:\n                self._experiment_thread.join()\n            except ExperimentStopped as e:\n                if not self.experiment_can_be_safely_aborted:\n                    raise e\n\n    @property\n    def running(self):\n        \"\"\"Whether the experiment is currently running in the background.\"\"\"\n        return background_actions_running(self)\n    \n    def log(self, message):\n        \"\"\"Log a message to the current HDF5 file and to the experiment's history\"\"\"\n        self.log_messages += message + \"\\n\"\n        if self.log_to_console:\n            print(message)\n        super(Experiment, self).log(message)",
  "class ExperimentWithDataDeque(Experiment):\n    \"\"\"Alan's Experiment class, using a deque for data management.\"\"\"\n\n    latest_data = None    \n    \n    def __init__(self):\n        super(Experiment, self).__init__()\n        #self.queue = Queue()\n        self.latest_data = deque([], maxlen=1)\n        self.lock = threading.Lock()  # useful in threaded experiments\n        self.acquiring = threading.Event()\n        self.data_requested = False\n        self.request_complete = False\n\n    def run(self, *args, **kwargs):\n        raise NotImplementedError()\n\n    @background_action\n    @locked_action\n    def run_in_background(self, *args, **kwargs):\n        self.run(*args, **kwargs)\n\n    def set_latest_data(self, *data):\n        self.latest_data.append(data)\n\n    def check_for_data(self):\n        #self.notifier.wait()\n        if len(self.latest_data):\n            return self.latest_data.pop()\n        else:\n            return False\n\n    def request_data(self):\n        if not self.request_complete:\n            self.data_requested = True\n            return False\n        self.request_complete = False\n        data = self.check_for_data()\n        return data\n\n    def check_for_data_request(self, *data):\n        \"\"\"\n        Be careful when giving sequences/iterables e.g. lists, arrays as these are passed\n        by reference and can cause threading issues. Be sure to send a copy.\n        :param data:\n        :return:\n        \"\"\"\n        if self.data_requested:\n            data = tuple(d.copy() if hasattr(d, 'copy') else np.array(d) for d in data)\n            self.set_latest_data(*data)\n            self.data_requested = False\n            self.request_complete = True\n\n    @staticmethod\n    def queue_data(queue, *data):\n        with queue.mutex:\n            queue.queue.clear()\n            queue.all_tasks_done.notify_all()\n            queue.unfinished_tasks = 0\n        queue.put(data)\n        queue.task_done()\n\n    @staticmethod\n    def check_queue(queue):\n        queue.join()\n        if not queue.empty():\n            while not queue.empty():\n                #print queue.qsize()\n                item = queue.get()\n            return item\n        else:\n            return False\n\n    @staticmethod\n    def append_dataset(h5object, name, value, shape=(0,)):\n        if name not in h5object:\n            dset = h5object.require_dataset(name, shape, dtype=np.float64, maxshape=(None,), chunks=True)\n        else:\n            dset = h5object[name]\n        index = dset.shape[0]\n        dset.resize(index+1,0)\n        dset[index,...] = value",
  "def __init__(self):\n        \"\"\"Create an instance of the Experiment class\"\"\"\n        super(Experiment, self).__init__()\n        self._stop_event = threading.Event()\n        self._finished_event = threading.Event()\n        self._experiment_thread = None\n        self.log_messages = \"\"",
  "def prepare_to_run(self, *args, **kwargs):\n        \"\"\"This method is always run in the foreground thread before run()\n\n        Use this method if you might need to pop up a GUI, for example.  The\n        most common use of this would be to create a data group or to ensure\n        the current data file exists - doing that in run() could give rise\n        to nasty threading problems.  By default, it does nothing.\n\n        The arguments are passed through from start() to here, so you should\n        either use or ignore them as appropriate.  These are the same args\n        as are passed to run(), so if one of the two functions requires an\n        argument you should make sure the other won't fail if the same\n        argument is passed to it (simple rule: accept *args, **kwargs in\n        both, in addition to any arguments you might have).\n        \"\"\"\n        pass",
  "def run(self, *args, **kwargs):\n        \"\"\"This method should be the meat of the experiment (needs overriden).\n        \n        This is where your experiment code goes.  Note that you should use\n        `self.wait_or_stop()` to pause your experiment between readings, to\n        allow the background thread to be stopped if necessary.\n        \n        If you set `self.latest_data`, this may be used to display your\n        results in real time.  You can also use `self.log()` to output text\n        describing the experiment's progress; this may be picked up and \n        displayed graphically or in the console.\n\n        The arguments are passed through from start() to here, so you should\n        either use or ignore them as appropriate.  These are the same args\n        as are passed to run(), so if one of the two functions requires an\n        argument you should make sure the other won't fail if the same\n        argument is passed to it (simple rule: accept *args, **kwargs in\n        both, in addition to any arguments you might have).\n        \"\"\"\n        NotImplementedError(\"The run() method of an Experiment must be overridden!\")",
  "def wait_or_stop(self, timeout, raise_exception=True):\n        \"\"\"Wait for the specified time in seconds.  Stop if requested.\n        \n        This waits for a given time, unless the experiment has been manually \n        stopped, in which case it will terminate the thread by raising an\n        ExperimentStopped exception.  You should call this whenever your\n        experiment is in a state that would be OK to stop, such as between\n        readings.\n        \n        If raise_exception is False, it will simply return False when the\n        experiment should stop.  This is appropriate if you want to use it in a\n        while loop, e.g. ``while self.wait_or_stop(10,raise_exception=False):``\n        \n        You may want to explicitly handle the ExperimentStopped exception to\n        close down cleanly.\n        \"\"\"\n        if self._stop_event.wait(timeout):\n            if raise_exception:\n                raise ExperimentStopped()\n        return True",
  "def run_in_background(self, *args, **kwargs):\n        \"\"\"Run the experiment in a background thread.\n        \n        This is important in order to keep the GUI responsive.\n        \"\"\"\n        self.log_messages = \"\"\n        self._stop_event.clear()\n        self._finished_event.clear()\n        self.run(*args, **kwargs)\n        self._finished_event.set()",
  "def start(self, *args, **kwargs):\n        \"\"\"Start the experiment running in a background thread.  See run_in_background.\"\"\"\n        assert self.running == False, \"Can't start the experiment when it is already running!\"\n        self.prepare_to_run(*args, **kwargs)\n        self._experiment_thread = self.run_in_background(*args, **kwargs)",
  "def stop(self, join=False):\n        \"\"\"Stop the experiment running, if supported.  May take a little while.\"\"\"\n        self._stop_event.set()\n        if join:\n            try:\n                self._experiment_thread.join()\n            except ExperimentStopped as e:\n                if not self.experiment_can_be_safely_aborted:\n                    raise e",
  "def running(self):\n        \"\"\"Whether the experiment is currently running in the background.\"\"\"\n        return background_actions_running(self)",
  "def log(self, message):\n        \"\"\"Log a message to the current HDF5 file and to the experiment's history\"\"\"\n        self.log_messages += message + \"\\n\"\n        if self.log_to_console:\n            print(message)\n        super(Experiment, self).log(message)",
  "def __init__(self):\n        super(Experiment, self).__init__()\n        #self.queue = Queue()\n        self.latest_data = deque([], maxlen=1)\n        self.lock = threading.Lock()  # useful in threaded experiments\n        self.acquiring = threading.Event()\n        self.data_requested = False\n        self.request_complete = False",
  "def run(self, *args, **kwargs):\n        raise NotImplementedError()",
  "def run_in_background(self, *args, **kwargs):\n        self.run(*args, **kwargs)",
  "def set_latest_data(self, *data):\n        self.latest_data.append(data)",
  "def check_for_data(self):\n        #self.notifier.wait()\n        if len(self.latest_data):\n            return self.latest_data.pop()\n        else:\n            return False",
  "def request_data(self):\n        if not self.request_complete:\n            self.data_requested = True\n            return False\n        self.request_complete = False\n        data = self.check_for_data()\n        return data",
  "def check_for_data_request(self, *data):\n        \"\"\"\n        Be careful when giving sequences/iterables e.g. lists, arrays as these are passed\n        by reference and can cause threading issues. Be sure to send a copy.\n        :param data:\n        :return:\n        \"\"\"\n        if self.data_requested:\n            data = tuple(d.copy() if hasattr(d, 'copy') else np.array(d) for d in data)\n            self.set_latest_data(*data)\n            self.data_requested = False\n            self.request_complete = True",
  "def queue_data(queue, *data):\n        with queue.mutex:\n            queue.queue.clear()\n            queue.all_tasks_done.notify_all()\n            queue.unfinished_tasks = 0\n        queue.put(data)\n        queue.task_done()",
  "def check_queue(queue):\n        queue.join()\n        if not queue.empty():\n            while not queue.empty():\n                #print queue.qsize()\n                item = queue.get()\n            return item\n        else:\n            return False",
  "def append_dataset(h5object, name, value, shape=(0,)):\n        if name not in h5object:\n            dset = h5object.require_dataset(name, shape, dtype=np.float64, maxshape=(None,), chunks=True)\n        else:\n            dset = h5object[name]\n        index = dset.shape[0]\n        dset.resize(index+1,0)\n        dset[index,...] = value",
  "class ExperimentGuiMixin(object):\n    \"\"\"This class will add a basic GUI to an experiment, showing logs & data.\n    \n    The `get_control_widget()` method is essentially empty, and is intended\n    to be overridden with useful settings for the experiment, for example \n    using a QuickControlBox.\n    \"\"\"\n    def get_qt_ui(self):\n        \"\"\"Create a Qt Widget representing the experiment.\"\"\"\n        return ExperimentWidget(self)\n    \n    def get_data_widget(self):\n        \"\"\"Create a QWidget that shows the latest data\"\"\"\n        return DataWidget(self)\n    \n    def get_log_widget(self):\n        \"\"\"A widget that displays logs in a scrolling display.\"\"\"\n        return LogWidget(self)\n        \n    def get_control_widget(self):\n        \"\"\"Return a widget that controls the experiment's settings.\"\"\"\n        return QuickControlBox()",
  "class ExperimentWithGui(Experiment, ExperimentGuiMixin):\n    \"\"\"Experiment class, extended to have a basic GUI including logs & data.\"\"\"\n    pass",
  "class LogWidget(QuickControlBox):\n    \"\"\"A widget for displaying the logs from an Experiment.\"\"\"\n    def __init__(self, experiment):\n        \"\"\"Create a widget to display an experiment's logs.\"\"\"\n        self.experiment = experiment\n        super(LogWidget, self).__init__()\n        \n        self.text_edit = QtWidgets.QPlainTextEdit()\n        self.text_edit.setReadOnly(True)\n        self.layout().addRow(self.text_edit)\n        self.add_button(\"clear\", title=\"Clear Logs\")\n        self.auto_connect_by_name()\n        \n    def clear(self):\n        \"\"\"Clear the text box, and the logs of the experiment.\"\"\"\n        self.experiment.log_messages = \"\"",
  "class QProgressDialogWithDeferredUpdate(QtWidgets.QProgressDialog):\n    \"\"\"A QProcessDialog that can have its value updated from a background thread.\"\"\"\n    set_new_value = QtCore.Signal(int)\n\n    def __init__(self, *args, **kwargs):\n        QtWidgets.QProgressDialog.__init__(self, *args, **kwargs)\n        self.set_new_value.connect(self.setValue, type=QtCore.Qt.QueuedConnection)\n\n    def setValueLater(self, progress):\n        \"\"\"Update the progress bar - but do it in a thread-safe way.\"\"\"\n        self.set_new_value.emit(progress)",
  "class ExperimentWithProgressBar(Experiment):\n    \"\"\"A class that extends an Experiment by adding a modal Qt progress bar for basic feedback.\n\n    Use it exactly like Experiment, but with a couple of extra steps:\n    * make sure you override ``prepare_to_run()`` and:\n      - set self.progress_maximum (and minimum, if desired)\n    * in your ``run()`` method, call ``self.update_progress(i)`` periodically.\n    The progress bar will disappear once you have called update_progress(n) where n is the\n    value you specified in self.progress_maximum earlier.  NB changing progress_maximum from\n    within run() has no effect currently.\n\n    If the user clicks abort on the progress bar, or stops the experiment by some other means,\n    an exception will be raised from calls to ``update_progress`` that stops the experiment.\n    \"\"\"\n    progress_maximum = None\n    progress_minimum = 0\n    def prepare_to_run(self, *args, **kwargs):\n        \"\"\"Set up the experiment.  Must be overridden to set self.progress_maximum\"\"\"\n        if self.progress_maximum is not None:\n            return # If progress_maximum has been set elsewhere, that's ok...\n        raise NotImplementedError(\"Experiments with progress bars must set self.progress_maximum\"\n                                  \"in the prepare_to_run method.\")\n\n    def run_modally(self, *args, **kwargs):\n        \"\"\"Run the experiment in the background.\n\n        This method replaces `Experiment.start()` and is blocking; it can safely be called\n        from a Qt signal from a button.\n        \"\"\"\n     #   self.prepare_to_run(*args, **kwargs)\n        if self.progress_maximum is None:\n            raise NotImplementedError(\"self.progress_maximum was not set - this is necessary.\")\n        self._progress_bar = QProgressDialogWithDeferredUpdate(\n                                                   self.__class__.__name__,\n                                                   \"Abort\",\n                                                   self.progress_minimum,\n                                                   self.progress_maximum)\n        self._progress_bar.show()\n        self._progress_bar.setAutoClose(True)\n        self._progress_bar.canceled.disconnect()\n        self._progress_bar.canceled.connect(self.stop_and_cancel_dialog)\n        self._experiment_thread = self.run_in_background(*args, **kwargs)\n   #     self._progress_bar.exec_()\n\n    def stop_and_cancel_dialog(self):\n        \"\"\"Abort the experiment and cancel the dialog once done.\"\"\"\n        try:\n            self.stop(True)\n        finally:\n            self._progress_bar.cancel()\n\n    def update_progress(self, progress):\n        \"\"\"Update the progress bar (NB should only be called from within run()\"\"\"\n        if not self.running:\n            # if run was called directly, fail gracefully\n            print(\"Progress: {}\".format(progress))\n            return\n        try:\n            self._progress_bar.setValueLater(progress)\n        except AttributeError:\n            print(\"Error setting progress bar to {} (are you running via run_modally()?)\".format(progress))\n        if self._stop_event.is_set():\n            raise ExperimentStopped()",
  "class RunFunctionWithProgressBar(ExperimentWithProgressBar):\n    \"\"\"An Experiment object that simply runs a function modally\"\"\"\n    def __init__(self, target, progress_maximum=None, *args, **kwargs):\n        super(RunFunctionWithProgressBar, self).__init__(*args, **kwargs)\n        self.target = target\n        assert callable(target), ValueError(\"The target function is not callable!\")\n        self.progress_maximum = progress_maximum\n\n    def run(self, *args, **kwargs):\n        print(\"running function {}\".format(self.target))\n        #, update_progress=self.update_progress,\n        self.target(update_progress=self.update_progress,*args, **kwargs)\n        self.update_progress(self.progress_maximum)",
  "def run_function_modally(function, progress_maximum, *args, **kwargs):\n    \"\"\"Create a temporary ExperimentWithProgressBar and run it modally.\n\n    This convenience function allows a function to be run with a nice progress bar, without the hassle\n    of setting up an Experiment object.  The function must accept a keyword argument, update_progress,\n    which is a function - it should be called periodically, with a numeric argument that starts at zero\n    and increments up to a final value of progress_maximum.  A sensible default for this argument would\n    be ``lambda p: p``, which is a function that does nothing.\n\n    Positional and keyword arguments are passed through, the only other argument needed is\n    progress_maximum, which sets the final value of progress.\n    \"\"\"\n #   function(*args, **kwargs)\n    e = RunFunctionWithProgressBar(function, progress_maximum=progress_maximum)\n    e.run_modally(*args, **kwargs)",
  "def get_qt_ui(self):\n        \"\"\"Create a Qt Widget representing the experiment.\"\"\"\n        return ExperimentWidget(self)",
  "def get_data_widget(self):\n        \"\"\"Create a QWidget that shows the latest data\"\"\"\n        return DataWidget(self)",
  "def get_log_widget(self):\n        \"\"\"A widget that displays logs in a scrolling display.\"\"\"\n        return LogWidget(self)",
  "def get_control_widget(self):\n        \"\"\"Return a widget that controls the experiment's settings.\"\"\"\n        return QuickControlBox()",
  "def __init__(self, experiment):\n        \"\"\"Create a widget to display an experiment's logs.\"\"\"\n        self.experiment = experiment\n        super(LogWidget, self).__init__()\n        \n        self.text_edit = QtWidgets.QPlainTextEdit()\n        self.text_edit.setReadOnly(True)\n        self.layout().addRow(self.text_edit)\n        self.add_button(\"clear\", title=\"Clear Logs\")\n        self.auto_connect_by_name()",
  "def clear(self):\n        \"\"\"Clear the text box, and the logs of the experiment.\"\"\"\n        self.experiment.log_messages = \"\"",
  "def __init__(self, *args, **kwargs):\n        QtWidgets.QProgressDialog.__init__(self, *args, **kwargs)\n        self.set_new_value.connect(self.setValue, type=QtCore.Qt.QueuedConnection)",
  "def setValueLater(self, progress):\n        \"\"\"Update the progress bar - but do it in a thread-safe way.\"\"\"\n        self.set_new_value.emit(progress)",
  "def prepare_to_run(self, *args, **kwargs):\n        \"\"\"Set up the experiment.  Must be overridden to set self.progress_maximum\"\"\"\n        if self.progress_maximum is not None:\n            return # If progress_maximum has been set elsewhere, that's ok...\n        raise NotImplementedError(\"Experiments with progress bars must set self.progress_maximum\"\n                                  \"in the prepare_to_run method.\")",
  "def run_modally(self, *args, **kwargs):\n        \"\"\"Run the experiment in the background.\n\n        This method replaces `Experiment.start()` and is blocking; it can safely be called\n        from a Qt signal from a button.\n        \"\"\"\n     #   self.prepare_to_run(*args, **kwargs)\n        if self.progress_maximum is None:\n            raise NotImplementedError(\"self.progress_maximum was not set - this is necessary.\")\n        self._progress_bar = QProgressDialogWithDeferredUpdate(\n                                                   self.__class__.__name__,\n                                                   \"Abort\",\n                                                   self.progress_minimum,\n                                                   self.progress_maximum)\n        self._progress_bar.show()\n        self._progress_bar.setAutoClose(True)\n        self._progress_bar.canceled.disconnect()\n        self._progress_bar.canceled.connect(self.stop_and_cancel_dialog)\n        self._experiment_thread = self.run_in_background(*args, **kwargs)",
  "def stop_and_cancel_dialog(self):\n        \"\"\"Abort the experiment and cancel the dialog once done.\"\"\"\n        try:\n            self.stop(True)\n        finally:\n            self._progress_bar.cancel()",
  "def update_progress(self, progress):\n        \"\"\"Update the progress bar (NB should only be called from within run()\"\"\"\n        if not self.running:\n            # if run was called directly, fail gracefully\n            print(\"Progress: {}\".format(progress))\n            return\n        try:\n            self._progress_bar.setValueLater(progress)\n        except AttributeError:\n            print(\"Error setting progress bar to {} (are you running via run_modally()?)\".format(progress))\n        if self._stop_event.is_set():\n            raise ExperimentStopped()",
  "def __init__(self, target, progress_maximum=None, *args, **kwargs):\n        super(RunFunctionWithProgressBar, self).__init__(*args, **kwargs)\n        self.target = target\n        assert callable(target), ValueError(\"The target function is not callable!\")\n        self.progress_maximum = progress_maximum",
  "def run(self, *args, **kwargs):\n        print(\"running function {}\".format(self.target))\n        #, update_progress=self.update_progress,\n        self.target(update_progress=self.update_progress,*args, **kwargs)\n        self.update_progress(self.progress_maximum)",
  "def qInitResources():\n    QtCore.qRegisterResourceData(0x01, qt_resource_struct, qt_resource_name, qt_resource_data)",
  "def qCleanupResources():\n    QtCore.qUnregisterResourceData(0x01, qt_resource_struct, qt_resource_name, qt_resource_data)",
  "def diff(voltage):\n\td_voltage = voltage[0:-1] - voltage[1:]\n\treturn d_voltage",
  "def signal_diff(voltages):\n\t#Work with normalized voltages:\n\tvmin = np.min(voltages)\n\trounded_voltages = (voltages-vmin) #subtract min\n\tvmax = np.max(rounded_voltages)\n\trounded_voltages = old_div(rounded_voltages,vmax) #divide by max\n\n\t#NOW: voltages are on scale: [0,1]\n\t#Round to nearest integer - lift/lower intermediate values\n\t#\tWe want digital values, not intermediates for edges\n\trounded_voltages = np.rint(rounded_voltages)\n\t#compute differences and return:\n\td_voltage = rounded_voltages[0:-1] - rounded_voltages[1:]\n\treturn d_voltage",
  "def threshold(voltages, count_threshold = 0.5):\n\traise ValueError(\"Deactivated\")\n\tcount_threshold = 0.4\n\tvmin = np.min(voltages)\n\tvmax = np.max(voltages)\n\tvspan = abs(vmax-vmin)\n\t#Piecewise difference between voltage measurements\n\t#\t+ve if rise edge\n\t#\t-ve if falling edge\n\t#Assertions:\n\t#\tNo consequtive +ve,+ve or -ve,-ve edges\n\t#\t+ve followed by -ve and -ve followed by +ve\n\n\n\t\n\tdiff = signal_diff(voltages)\n\n\t#threshold the absolute values of the pulses, relative to the fraction of the Vpp value\n\t\n\t#Get signs of the pulses\n\t#Expected outputs\n\t# +1 - rising edge\n\t# -1 - falling edge\n\t#  0 - no edge\n\tpulses = np.sign(diff)\n\n\t# assert(pulses.shape==diff.shape)\n\t# for i in xrange(len(pulses)): #DELETE LOOP\n\t# \tassert(pulses[i] in [-1,0,1])\n\n\t#Get indices of the pulse positions\n\tnonzero_indices = np.flatnonzero(pulses)\n \n\tassert(len(nonzero_indices) == int(np.sum(np.absolute(pulses)))),\"NONZERO LENGTH:{0},ABS SUM PULSES:{1}\".format(len(nonzero_indices),np.sum(np.absolute(pulses)))\n\tfor i in range(len(nonzero_indices)): #DELETE LOOP\n\t\tassert(pulses[nonzero_indices[i]] != 0)\n\n\t#Clean up consecutive pulses that are +ve,+ve or -ve,-ve:\n\t# Example:\n\t# 0 1 -1 1 1 1 -1 1 -1 -1 \n\t#          | |  \t    |\n\t# 0 1 -1 1 0 0 -1 1 -1  0\n\n\n\t# assert()\n\t# for i in xrange(1,len(nonzero_indices)):\n\t\t# if pulses[nonzero_indices[i]]== pulses[nonzero_indices[i-1]]:\n\t\t\t# pulses[nonzero_indices[i]] == 0\n\n\t#return absolute values of the pulses\n\treturn np.absolute(pulses)",
  "def binwidth_time_to_index(time_bin_width, dt):\n\treturn int(math.ceil((float(time_bin_width)/float(dt))))",
  "def binned_data_len(input_length, bin_width):\n\t#return length of binned array of original length: input_length and bin_width (as array index)\n\treturn int(math.ceil(float(input_length)/float(bin_width)))",
  "def binning(thresholded, index_bin_width):\n\t#length of input thresholded array of 0s and 1s\n\n\tthresholded_len = len(thresholded)\n\n\t# for i in xrange(thresholded_len): #DELETE LOOP\n\t# \tassert(thresholded[i] in [0,1]), \"Threasholded:\" thresholded[i]\n\n\t#length of output [int]\n\toutp_len = binned_data_len(thresholded_len, index_bin_width)\n\toutput = np.zeros(outp_len)\n\tfor i in range(outp_len):\n\t\toutput[i] = np.sum(np.absolute(thresholded[i*index_bin_width:min(thresholded_len,(i+1)*index_bin_width)]))\n\n\treturn output",
  "def autocorrelation(x,mode=\"fft\"):\n\tx=np.asarray(x)\n\tn = len(x)\n\tmean = x.mean()\n\tif mode == \"fft\":\n\t\tr = scipy.signal.correlate(x,x,mode=\"full\",method=\"fft\")[-n:]\n\t\toutp = np.divide(r,np.multiply(mean**2,np.arange(n,0,-1)))\n\t\treturn outp\n\telif mode == \"direct\":\n\t\tr = np.correlate(x, x, mode = 'full')[-n:]\n\t\toutp =  np.divide(r,np.multiply(mean**2,np.arange(n,0,-1)))\n\t\treturn outp",
  "class DynamicLightScattering(Instrument):\n\n\tDEVICE_KEYS = [\"adc\", \"sample_rotation_stage\"]\n\n\tdef __init__(self, instruments):\n\t\tself.instruments = instruments\n\t\tInstrument.__init__(self,)\n\t\tself.ui = None\n\t\tfor k in list(instruments.keys()):\n\t\t\tassert(k in DynamicLightScattering.DEVICE_KEYS)\n\n\t\tself.adc = instruments[\"adc\"]\n\t\tself.adc_ui = instruments[\"adc\"].get_qt_ui()\n\t\tself.sample_rotation_stage = None\n\t\tself.sample_rotation_stage_ui = None\n\n\t\t#check boxes for the settings\n\t\tself.checkboxes = {\n\t\t\"raw\":self.adc_ui.raw_checkbox,\n\t\t\"difference\":self.adc_ui.difference_checkbox,\n\t\t\"binning\":self.adc_ui.binning_checkbox,\n\t\t\"correlate\":self.adc_ui.correlate_checkbox,\n\t\t\"average\":self.adc_ui.average_checkbox,\n\t\t\"save\":self.adc_ui.save_checkbox,\n\t\t\"plot\":self.adc_ui.plot_checkbox,\n\t\t}\n\n\t\tself.textboxes = {\n\t\t\"sample_count\": self.adc_ui.sample_count_textbox,\n\t\t\"series_name\": self.adc_ui.series_name_textbox,\n\t\t\"binning_size\": self.adc_ui.binning_textbox,\n\t\t\"average_count\": self.adc_ui.average_textbox\n\t\t}\n\t\tself.fields = dict()\n\n\t\tif \"sample_rotation_stage\" in list(instruments.keys()):\n\t\t\tself.sample_rotation_stage = instruments[\"sample_rotation_stage\"]\n\t\t\tself.sample_rotation_stage_ui = self.sample_rotation_stage.get_qt_ui()\n\n\t\t\tself.textboxes.update({\"new_angle\" : self.sample_rotation_stage_ui.new_angle_textbox})\n\t\t\tself.textboxes.update({\"rotation_speed\": self.sample_rotation_stage_ui.rotation_speed_textbox})\n\t\t\tself.fields.update({\"zero_angle\":self.sample_rotation_stage.zero_pos})\n\n\t\tcheckbox_keys = list(self.checkboxes.keys())\n\t\ttextbox_keys = list(self.textboxes.keys())\n\t\tfield_keys = list(self.fields.keys())\n\n\t\t#assert the keys in dict are UNIQUE - otherwise we can't guarantee same parameters are set\n\t\tassert(len(list(set(checkbox_keys).intersection(set(textbox_keys))))==0)\n\t\tassert(len(list(set(checkbox_keys).intersection(set(field_keys))))==0)\n\t\tassert(len(list(set(field_keys).intersection(set(textbox_keys))))==0)\n\t\tprint(\"KEYS\", checkbox_keys+textbox_keys+field_keys)\n\n\t#WHY DOES THIS WORK ONLY HERE - ELSEWHERE THIS ISNT NEEDED???\n\tdef get_qt_ui(self):\n\t\tif self.ui is None:\n\t\t\tself.ui = DynamicLightScatteringUI(experiment=self)\n\t\treturn self.ui\n\n\t#setters for checkboxes, textboxes, and fields\n\tdef set_checkboxes(self,settings):\n\t\tfor s in list(settings.keys()):\n\t\t\tif s in list(self.checkboxes.keys()):\n\t\t\t\ton = bool(settings[s])\n\t\t\t\tself.checkboxes[s].setChecked(on)\n\t\t\t\t\n\tdef set_textboxes(self,settings):\n\t\tfor s in list(settings.keys()):\n\t\t\tif s in list(self.textboxes.keys()):\n\t\t\t\tself.textboxes[s].setText(settings[s])\n\t\treturn\n\n\tdef set_fields(self,settings):\n\t\tfor s in list(settings.keys()):\n\t\t\tif s in list(self.fields.keys()):\n\t\t\t\tself.fields[s] = settings[s]\n\n\tdef run_experiment(self,path,debug=False):\n\t\tself.log(\"PATH\"+ str(path))\n\t\tf = file(path,'r')\n\t\tsteps = json.loads(f.read())\n\t\tself.log(\"STAGES:\"+str(len(steps)))\n\t\tfor i,settings in enumerate(steps):\n\t\t\tself.log(\"Settings {0}:\\n{1}\".format(i,settings))\n\t\t\tself.set_checkboxes(settings)\n\t\t\tself.set_textboxes(settings)\n\t\t\tself.set_fields(settings)\n\n\t\t\tif self.sample_rotation_stage_ui is not None:\n\t\t\t\tself.sample_rotation_stage_ui.move_stage(blocking=True)\n\t\t\tself.adc_ui.threaded_capture(settings={\"experiment_settings\":settings})\n\t\t\tself.adc_ui.capture_thread.join()",
  "class DynamicLightScatteringUI(QtWidgets.QWidget, UiTools):\n\tdef __init__(self,experiment, parent=None,debug = False,verbose=False):\n\t\tif not isinstance(experiment, DynamicLightScattering):\n\t\t\traise ValueError(\"Object is not an instance of the DynamicLightScattering\")\n\t\tsuper(DynamicLightScatteringUI, self).__init__()\n\t\tself.experiment = experiment\n\t\tuic.loadUi(os.path.join(os.path.dirname(__file__), 'dynamic_light_scattering_experiment.ui'), self)\n\n\t\tself.run_config_textbox.textChanged.connect(self.set_run_config_path)\n\t\tself.run_config_button.clicked.connect(self.run_experiment)\n\n\n\tdef run_experiment(self):\n\t\ttry:\n\t\t\tt = threading.Thread(target=self.experiment.run_experiment, args=(self.run_path,))\n\t\t\tt.start()\n\t\texcept Exception as e:\n\t\t\tself.experiment.log(\"Error when running experiment - have you written the path?\",level=\"error\")\n\t\t\tself.experiment.log(e)\n\t\treturn\n\n\tdef set_run_config_path(self):\n\t\tself.run_path = self.run_config_textbox.text()",
  "def __init__(self, instruments):\n\t\tself.instruments = instruments\n\t\tInstrument.__init__(self,)\n\t\tself.ui = None\n\t\tfor k in list(instruments.keys()):\n\t\t\tassert(k in DynamicLightScattering.DEVICE_KEYS)\n\n\t\tself.adc = instruments[\"adc\"]\n\t\tself.adc_ui = instruments[\"adc\"].get_qt_ui()\n\t\tself.sample_rotation_stage = None\n\t\tself.sample_rotation_stage_ui = None\n\n\t\t#check boxes for the settings\n\t\tself.checkboxes = {\n\t\t\"raw\":self.adc_ui.raw_checkbox,\n\t\t\"difference\":self.adc_ui.difference_checkbox,\n\t\t\"binning\":self.adc_ui.binning_checkbox,\n\t\t\"correlate\":self.adc_ui.correlate_checkbox,\n\t\t\"average\":self.adc_ui.average_checkbox,\n\t\t\"save\":self.adc_ui.save_checkbox,\n\t\t\"plot\":self.adc_ui.plot_checkbox,\n\t\t}\n\n\t\tself.textboxes = {\n\t\t\"sample_count\": self.adc_ui.sample_count_textbox,\n\t\t\"series_name\": self.adc_ui.series_name_textbox,\n\t\t\"binning_size\": self.adc_ui.binning_textbox,\n\t\t\"average_count\": self.adc_ui.average_textbox\n\t\t}\n\t\tself.fields = dict()\n\n\t\tif \"sample_rotation_stage\" in list(instruments.keys()):\n\t\t\tself.sample_rotation_stage = instruments[\"sample_rotation_stage\"]\n\t\t\tself.sample_rotation_stage_ui = self.sample_rotation_stage.get_qt_ui()\n\n\t\t\tself.textboxes.update({\"new_angle\" : self.sample_rotation_stage_ui.new_angle_textbox})\n\t\t\tself.textboxes.update({\"rotation_speed\": self.sample_rotation_stage_ui.rotation_speed_textbox})\n\t\t\tself.fields.update({\"zero_angle\":self.sample_rotation_stage.zero_pos})\n\n\t\tcheckbox_keys = list(self.checkboxes.keys())\n\t\ttextbox_keys = list(self.textboxes.keys())\n\t\tfield_keys = list(self.fields.keys())\n\n\t\t#assert the keys in dict are UNIQUE - otherwise we can't guarantee same parameters are set\n\t\tassert(len(list(set(checkbox_keys).intersection(set(textbox_keys))))==0)\n\t\tassert(len(list(set(checkbox_keys).intersection(set(field_keys))))==0)\n\t\tassert(len(list(set(field_keys).intersection(set(textbox_keys))))==0)\n\t\tprint(\"KEYS\", checkbox_keys+textbox_keys+field_keys)",
  "def get_qt_ui(self):\n\t\tif self.ui is None:\n\t\t\tself.ui = DynamicLightScatteringUI(experiment=self)\n\t\treturn self.ui",
  "def set_checkboxes(self,settings):\n\t\tfor s in list(settings.keys()):\n\t\t\tif s in list(self.checkboxes.keys()):\n\t\t\t\ton = bool(settings[s])\n\t\t\t\tself.checkboxes[s].setChecked(on)",
  "def set_textboxes(self,settings):\n\t\tfor s in list(settings.keys()):\n\t\t\tif s in list(self.textboxes.keys()):\n\t\t\t\tself.textboxes[s].setText(settings[s])\n\t\treturn",
  "def set_fields(self,settings):\n\t\tfor s in list(settings.keys()):\n\t\t\tif s in list(self.fields.keys()):\n\t\t\t\tself.fields[s] = settings[s]",
  "def run_experiment(self,path,debug=False):\n\t\tself.log(\"PATH\"+ str(path))\n\t\tf = file(path,'r')\n\t\tsteps = json.loads(f.read())\n\t\tself.log(\"STAGES:\"+str(len(steps)))\n\t\tfor i,settings in enumerate(steps):\n\t\t\tself.log(\"Settings {0}:\\n{1}\".format(i,settings))\n\t\t\tself.set_checkboxes(settings)\n\t\t\tself.set_textboxes(settings)\n\t\t\tself.set_fields(settings)\n\n\t\t\tif self.sample_rotation_stage_ui is not None:\n\t\t\t\tself.sample_rotation_stage_ui.move_stage(blocking=True)\n\t\t\tself.adc_ui.threaded_capture(settings={\"experiment_settings\":settings})\n\t\t\tself.adc_ui.capture_thread.join()",
  "def __init__(self,experiment, parent=None,debug = False,verbose=False):\n\t\tif not isinstance(experiment, DynamicLightScattering):\n\t\t\traise ValueError(\"Object is not an instance of the DynamicLightScattering\")\n\t\tsuper(DynamicLightScatteringUI, self).__init__()\n\t\tself.experiment = experiment\n\t\tuic.loadUi(os.path.join(os.path.dirname(__file__), 'dynamic_light_scattering_experiment.ui'), self)\n\n\t\tself.run_config_textbox.textChanged.connect(self.set_run_config_path)\n\t\tself.run_config_button.clicked.connect(self.run_experiment)",
  "def run_experiment(self):\n\t\ttry:\n\t\t\tt = threading.Thread(target=self.experiment.run_experiment, args=(self.run_path,))\n\t\t\tt.start()\n\t\texcept Exception as e:\n\t\t\tself.experiment.log(\"Error when running experiment - have you written the path?\",level=\"error\")\n\t\t\tself.experiment.log(e)\n\t\treturn",
  "def set_run_config_path(self):\n\t\tself.run_path = self.run_config_textbox.text()",
  "class HyperspectralScan(GridScanQt, ScanningExperimentHDF5):\n    view_layer_updated = QtCore.Signal(int)\n\n    def __init__(self):\n        GridScanQt.__init__(self)\n        ScanningExperimentHDF5.__init__(self)\n        self.spectrometer = None\n        self.light_source = None\n        self.num_spectrometers = 1\n        self.safe_exit = False\n        self.delay = 0.\n\n        self.fig = None#Figure()\n        self._created = False\n        self.view_wavelength = 600\n        self.view_layer = 0\n        self.override_view_layer = False  # used to manually show a specific layer instead of current one scanning\n\n    @property\n    def view_layer(self):\n        return self._view_layer\n\n    @view_layer.setter\n    def view_layer(self, value):\n        self._view_layer = value\n        self.view_layer_updated.emit(value)\n\n    def set_spectrometers(self, spectrometers):\n        if not isinstance(spectrometers, (Spectrometer, Spectrometers)):\n            raise ValueError('spectrometer must be an instance of either Spectrometer or '\n                             'Spectrometers')\n        self.spectrometer = spectrometers\n        if isinstance(spectrometers, Spectrometers):\n            self.num_spectrometers = len(spectrometers.spectrometers)\n        else:\n            self.num_spectrometers = 1\n\n    def set_light_source(self, light_source):\n        assert isinstance(light_source, LightSource), 'light_source must be an instance of LightSource'\n        self.light_source = light_source\n\n    @staticmethod\n    def _suffix(i):\n        return '{}'.format(i+1) if i != 0 else ''\n\n    def init_scan(self):\n        # these checks are performed in case equipment is set without using the set_ method\n        if not isinstance(self.stage, Stage):\n            raise ValueError('stage must be a Stage')\n        if not isinstance(self.spectrometer, (Spectrometer, Spectrometers)):\n            raise ValueError('spectrometer must be a Spectrometer or Spectrometers')\n        # if not self._created:\n        #     self.init_figure()\n\n    def open_scan(self):\n        super(HyperspectralScan, self).open_scan()\n        group = self.f.require_group('hyperspectral_images')\n        self.data = group.create_group('scan_%d', attrs=dict(description=self.description))\n        print('Saving scan to: {}'.format(self.f.file.filename), self.data)\n        raw_group = self.data.create_group('raw_data')\n        for axis_name, axis_values in zip(self.axes_names, self.scan_axes):\n            self.data.create_dataset(axis_name, data=axis_values)\n        for i in range(self.num_spectrometers):\n            suffix = self._suffix(i)\n            spectrometer = self.spectrometer.spectrometers[i]\\\n                if isinstance(self.spectrometer, Spectrometers) else self.spectrometer\n            self.data.create_dataset('wavelength'+suffix, data=spectrometer.wavelengths)\n            self.data.create_dataset('hs_image'+suffix,\n                                     shape=self.grid_shape + (spectrometer.wavelengths.size,),\n                                     dtype=np.float64,\n                                     attrs=spectrometer.metadata)\n            self.data.create_dataset('raw_data/hs_image'+suffix,\n                                     shape=self.grid_shape + (spectrometer.wavelengths.size,),\n                                     dtype=np.float64,\n                                     attrs=spectrometer.metadata)\n        if isinstance(self.spectrometer, Spectrometer):\n            self.read_spectra = self.spectrometer.read_spectrum\n            self.process_spectra = self.spectrometer.process_spectrum\n        elif isinstance(self.spectrometer, Spectrometers):\n            self.read_spectra = self.spectrometer.read_spectra\n            self.process_spectra = self.spectrometer.process_spectra\n        self.init_figure()\n\n    def close_scan(self):\n        super(HyperspectralScan, self).close_scan()\n        self.data.file.flush()\n        time.sleep(0.1)\n        if self.safe_exit:\n            if isinstance(self.light_source.shutter, Shutter):\n                self.light_source.shutter.toggle()\n            else:\n                self.light_source.power = 0\n\n    def scan_function(self, *indices):\n        time.sleep(self.delay)\n        raw_spectra = self.read_spectra()\n        spectra = self.process_spectra(raw_spectra)\n        self.data['raw_data/hs_image'+self._suffix(0)][indices] = raw_spectra\n        self.data['hs_image'+self._suffix(0)][indices] = spectra\n#        for i, (spectrum, raw_spectrum) in enumerate(zip(spectra, raw_spectra)):\n#            try:\n#                suffix = self._suffix(i)\n#                self.data['raw_data/hs_image'+suffix][indices] = raw_spectrum\n#                self.data['hs_image'+suffix][indices] = spectrum\n#            except Exception as e:\n#                print e\n        self.check_for_data_request(*self.set_latest_view(*indices))\n\n    def set_latest_view(self, *indices):\n        view_data = []\n        for i in range(self.num_spectrometers):\n            suffix = self._suffix(i)\n            spectrometer = self.spectrometer.spectrometers[i]\\\n                if isinstance(self.spectrometer, Spectrometers) else self.spectrometer\n            w = abs(spectrometer.wavelengths - self.view_wavelength).argmin()\n            data = self.data['hs_image'+suffix]\n            if self.num_axes == 2:\n                latest_view = data[:, :, w]\n                spectrum = self.data['hs_image'+suffix][indices[-2], indices[-1], :]\n            elif self.num_axes == 3:\n                if self.override_view_layer:\n                    k = self.view_layer\n                else:\n                    k = self.indices[0]\n                    if self.view_layer != k:\n                        self.view_layer = k\n                latest_view = data[k, :, :, w]\n                spectrum = self.data['hs_image'+suffix][k, indices[-2], indices[-1], :]\n            spectrum = spectrometer.mask_spectrum(spectrum, 0.05)\n            view_data += [latest_view, spectrometer.wavelengths, spectrum]\n        return tuple(view_data)\n\n    def init_figure(self):\n        if self.fig is None:\n            return\n        self.fig.clear()\n        gs = gridspec.GridSpec(2, 2, hspace=0.5, wspace=0.5)\n        ax1 = self.fig.add_subplot(gs[0,0])\n        ax2 = self.fig.add_subplot(gs[0,1])\n        for ax in (ax1, ax2):\n            ax.set_xlabel('$x$')\n            ax.set_ylabel('$y$')\n            ax.set_aspect('equal')\n            mult = 1./self._unit_conversion[self.step_unit]\n            x, y = (mult*self.scan_axes[-1], mult*self.scan_axes[-2])\n            ax.set_xlim(x.min(), x.max())\n            ax.set_ylim(y.min(), y.max())\n        ax3 = self.fig.add_subplot(gs[1,:])\n        ax3.set_xlabel('wavelength (nm)')\n        ax3.set_ylabel('intensity (a.u.)')\n        ax4 = ax3.twinx()\n        ax4.set_ylabel('intensity (a.u.)')\n        gs.tight_layout(self.fig)\n        cid = self.fig.canvas.mpl_connect('button_press_event', self.on_mouse_click)\n        # pos = np.array([0.0, 0.2, 0.5, 1.0])\n        # color = np.array([[0,0,0,255], [255,0,0,255], [255,255,0,255], [255,255,255,255]], dtype=np.ubyte)\n        # map = pg.ColorMap(pos, color)\n        # lut = map.getLookupTable(0.0, 1.0, 256)\n        #\n        # self.spectrum_plots = [pg.PlotCurveItem() for i in xrange(self.num_spectrometers)]\n        # self.image_plots = [pg.ImageItem(lut=lut) for i in xrange(self.num_spectrometers)]\n        # for item in self.image_plots:\n        #     plot = self.fig.addPlot()\n        #     plot.addItem(item)\n        #     plot.setAspectLocked(True)\n        #     rect=np.array([-self.size[0]/2.,-self.size[1]/2.,\n        #                    self.size[0], self.size[1]])\n        #     rect /= (self._unit_conversion[self.step_unit]/self._unit_conversion[self.size_unit])\n        #     item.setImage(np.zeros((self.si_size[1]/self.si_step[1],\n        #                             self.si_size[0]/self.si_step[0])))\n        #     item.setRect(QtCore.QRectF(*rect))\n        # self.fig.nextRow()\n        # plot = self.fig.addPlot()\n        # for item in self.spectrum_plots:\n        #     plot.addItem(item)\n        # self._created = True\n\n    def update(self, force=False):\n        super(HyperspectralScan, self).update(force)\n        if not self.fig:\n            return\n        if force:\n            data = self.set_latest_view(*self.indices)\n        else:\n            data = self.request_data()\n        if data is not False:\n            grouped_data = [data[i:i+3] for i in range(0,len(data),3)]\n            colours = ['r', 'b', 'g']\n            for i, data_group in enumerate(grouped_data):\n                img, wavelengths, spectrum = data_group\n                if not np.any(np.isfinite(img)):\n                    return\n                # self.image_plots[i].setImage(img)\n                # self.spectrum_plots[i].setData(x=wavelengths, y=spectrum, pen=colours[i])\n\n                ax = self.fig.axes[i]\n                if not ax.collections:\n                    mult = 1. / self._unit_conversion[self.step_unit]\n                    ax.pcolormesh(mult * self.scan_axes[-1], mult * self.scan_axes[-2], img,\n                                  cmap=matplotlib.cm.afmhot)\n                else:\n                    plot, = ax.collections\n                    plot.set_array(img[:-1, :-1].ravel())\n                    img_min = img[np.isfinite(img)].min()\n                    img_max = img[np.isfinite(img)].max()\n                    plot.set_clim(img_min, img_max)\n                    ax.relim()\n                    #ax.draw_artist(ax.patch)\n                    #ax.draw_artist(plot)\n                ax = self.fig.axes[i+2]\n                c = 'r' if i == 0 else 'b'\n                if not ax.lines:\n                    ax.plot(wavelengths, spectrum, c=c)\n                else:\n                    plot, = ax.lines\n                    plot.set_data(wavelengths, spectrum)\n                    ax.relim()\n                    ax.autoscale_view()\n            #self.fig.canvas.update()\n            #self.fig.canvas.flush_events()\n            self.fig.canvas.draw()\n\n    @property\n    def estimated_step_time(self):\n        if isinstance(self.spectrometer, Spectrometer):\n            max_exposure = self.spectrometer.integration_time\n        elif isinstance(self.spectrometer, Spectrometers):\n            max_exposure = 1e-3 * max([s.integration_time for s in self.spectrometer.spectrometers])\n        else:\n            max_exposure = 0\n            warnings.warn('No integration time as spectrometer is not a valid instance of Spectrometer or Spectrometers.')\n        max_travel = 100e-3\n        #self.estimated_step_time = max_exposure + max_travel\n        return max_exposure + max_travel\n\n    @estimated_step_time.setter\n    def estimated_step_time(self, value):\n        print(value)\n\n    def get_qt_ui(self):\n        return HyperspectralScanUI(self)\n\n    def on_mouse_click(self, event):\n        init_scale = old_div(self._unit_conversion[self.step_unit], self._unit_conversion[self.init_unit])\n        self.init[:2] = (event.xdata * init_scale, event.ydata * init_scale)\n        self.init_updated.emit(self.init)",
  "class HyperspectralScanUI(QtWidgets.QWidget, UiTools):\n    def __init__(self, grid_scanner, parent=None):\n        assert isinstance(grid_scanner, HyperspectralScan), \\\n            'scanner must be an instance of HyperspectralScan'\n        super(HyperspectralScanUI, self).__init__()\n        self.grid_scanner = grid_scanner\n        uic.loadUi(os.path.join(os.path.dirname(__file__), 'hyperspectral_imaging.ui'), self)\n        self.gridscanner_widget = self.replace_widget(self.main_layout, self.gridscanner_widget,\n                                                      GridScanQt.get_qt_ui_cls()(self.grid_scanner))\n        self.gridscanner_widget.rate = 1./20.\n\n        self.grid_scanner.fig = Figure()  # pg.GraphicsLayoutWidget()\n        # self.grid_scanner.fig.scene().sigMouseClicked.connect(self.grid_scanner.on_mouse_click)\n        self.figure_widget = self.replace_widget(self.main_layout, self.figure_widget,\n                                                 FigureCanvas(self.grid_scanner.fig))\n\n        self.init_stage_select()\n        self.init_view_wavelength_controls()\n        self.init_view_select()\n\n        self.scan_description.textChanged.connect(self.update_param)\n        self.safe_exit.stateChanged.connect(self.on_state_change)\n\n        self.config_stage.clicked.connect(self.on_click)\n        self.config_spectrometers.clicked.connect(self.on_click)\n        self.config_light_source.clicked.connect(self.on_click)\n        self.open_browser.clicked.connect(self.on_click)\n\n    def init_stage_select(self):\n        self.stage_select.addItems(['PI', 'SmarAct'])\n        self.stage_select.activated[str].connect(self.select_stage)\n\n    def init_view_wavelength_controls(self):\n        self.view_wavelength.setValidator(QtGui.QIntValidator())\n        # self.view_wavelength.textChanged.connect(self.check_state)\n        self.view_wavelength.returnPressed.connect(self.on_view_wavelength_change)\n\n        min_wl = np.min(self.grid_scanner.spectrometer.wavelengths)\n        max_wl = np.max(self.grid_scanner.spectrometer.wavelengths)\n        self.wavelength_range.setRange(min_wl, max_wl)\n        self.wavelength_range.setFocusPolicy(QtCore.Qt.NoFocus)\n        self.wavelength_range.valueChanged[int].connect(self.on_wavelength_range_change)\n\n        self.view_wavelength.setText(str(self.grid_scanner.view_wavelength))\n        self.wavelength_range.setValue(self.grid_scanner.view_wavelength)\n\n    def init_view_select(self):\n        self.view_layer.setValidator(QtGui.QIntValidator())\n        self.view_layer.textChanged.connect(\n            self.on_view_layer_change)  # (partial(setattr, self.grid_scanner, 'view_layer'))\n        self.grid_scanner.view_layer_updated.connect(self.on_gs_view_layer_change)\n\n        self.override_view_layer.stateChanged.connect(self.on_override_view_layer)\n\n    def update_param(self, *args, **kwargs):\n        sender = self.sender()\n        if sender == self.scan_description:\n            self.grid_scanner.description = self.scan_description.toPlainText().encode('utf8')\n\n    def select_stage(self, name):\n        print(name)\n\n    def on_click(self):\n        sender = self.sender()\n        if sender == self.config_stage:\n            self.stage_ui = self.grid_scanner.stage.get_qt_ui()\n            self.stage_ui.show()\n        elif sender == self.config_spectrometers:\n            self.spectrometers_ui = self.grid_scanner.spectrometer.get_qt_ui()\n            self.spectrometers_ui.show()\n        elif sender == self.config_light_source:\n            self.light_source_ui = self.grid_scanner.light_source.get_qt_ui()\n            self.light_source_ui.show()\n            pass\n        elif sender == self.open_browser:\n            if self.grid_scanner.f is not None:\n                print(self.grid_scanner.f)\n                self.browser = HDF5Browser(self.grid_scanner.f)\n                self.browser.show()\n\n    def on_state_change(self, state):\n        sender = self.sender()\n        if sender is self.safe_exit:\n            if state == QtCore.Qt.Checked:\n                self.grid_scanner.safe_exit = True\n            elif state == QtCore.Qt.Unchecked:\n                self.grid_scanner.safe_exit = False\n\n    def on_view_wavelength_change(self, *args, **kwargs):\n        \"\"\"\n        This function is called by the power text box.\n\n        :param args:\n        :param kwargs:\n        :return:\n        \"\"\"\n        print(self.view_wavelength.text())\n        value = int(self.view_wavelength.text())\n        # self.wavelength_range.valueChanged[int].emit(value)\n        self.wavelength_range.setValue(value)\n\n    def on_wavelength_range_change(self, value):\n        \"\"\"\n        This function is called by the power slider.\n\n        :param value:\n        :return:\n        \"\"\"\n        self.grid_scanner.view_wavelength = value\n        self.view_wavelength.setText('%d' % value)\n\n    def on_view_layer_change(self, *args, **kwargs):\n        self.grid_scanner.view_layer = int(self.view_layer.text())\n\n    def on_gs_view_layer_change(self, value):\n        self.view_layer.setText(str(value))\n\n    def on_override_view_layer(self, state):\n        if state == QtCore.Qt.Checked:\n            self.grid_scanner.override_view_layer = True\n        else:\n            self.grid_scanner.override_view_layer = False",
  "def __init__(self):\n        GridScanQt.__init__(self)\n        ScanningExperimentHDF5.__init__(self)\n        self.spectrometer = None\n        self.light_source = None\n        self.num_spectrometers = 1\n        self.safe_exit = False\n        self.delay = 0.\n\n        self.fig = None#Figure()\n        self._created = False\n        self.view_wavelength = 600\n        self.view_layer = 0\n        self.override_view_layer = False",
  "def view_layer(self):\n        return self._view_layer",
  "def view_layer(self, value):\n        self._view_layer = value\n        self.view_layer_updated.emit(value)",
  "def set_spectrometers(self, spectrometers):\n        if not isinstance(spectrometers, (Spectrometer, Spectrometers)):\n            raise ValueError('spectrometer must be an instance of either Spectrometer or '\n                             'Spectrometers')\n        self.spectrometer = spectrometers\n        if isinstance(spectrometers, Spectrometers):\n            self.num_spectrometers = len(spectrometers.spectrometers)\n        else:\n            self.num_spectrometers = 1",
  "def set_light_source(self, light_source):\n        assert isinstance(light_source, LightSource), 'light_source must be an instance of LightSource'\n        self.light_source = light_source",
  "def _suffix(i):\n        return '{}'.format(i+1) if i != 0 else ''",
  "def init_scan(self):\n        # these checks are performed in case equipment is set without using the set_ method\n        if not isinstance(self.stage, Stage):\n            raise ValueError('stage must be a Stage')\n        if not isinstance(self.spectrometer, (Spectrometer, Spectrometers)):\n            raise ValueError('spectrometer must be a Spectrometer or Spectrometers')",
  "def open_scan(self):\n        super(HyperspectralScan, self).open_scan()\n        group = self.f.require_group('hyperspectral_images')\n        self.data = group.create_group('scan_%d', attrs=dict(description=self.description))\n        print('Saving scan to: {}'.format(self.f.file.filename), self.data)\n        raw_group = self.data.create_group('raw_data')\n        for axis_name, axis_values in zip(self.axes_names, self.scan_axes):\n            self.data.create_dataset(axis_name, data=axis_values)\n        for i in range(self.num_spectrometers):\n            suffix = self._suffix(i)\n            spectrometer = self.spectrometer.spectrometers[i]\\\n                if isinstance(self.spectrometer, Spectrometers) else self.spectrometer\n            self.data.create_dataset('wavelength'+suffix, data=spectrometer.wavelengths)\n            self.data.create_dataset('hs_image'+suffix,\n                                     shape=self.grid_shape + (spectrometer.wavelengths.size,),\n                                     dtype=np.float64,\n                                     attrs=spectrometer.metadata)\n            self.data.create_dataset('raw_data/hs_image'+suffix,\n                                     shape=self.grid_shape + (spectrometer.wavelengths.size,),\n                                     dtype=np.float64,\n                                     attrs=spectrometer.metadata)\n        if isinstance(self.spectrometer, Spectrometer):\n            self.read_spectra = self.spectrometer.read_spectrum\n            self.process_spectra = self.spectrometer.process_spectrum\n        elif isinstance(self.spectrometer, Spectrometers):\n            self.read_spectra = self.spectrometer.read_spectra\n            self.process_spectra = self.spectrometer.process_spectra\n        self.init_figure()",
  "def close_scan(self):\n        super(HyperspectralScan, self).close_scan()\n        self.data.file.flush()\n        time.sleep(0.1)\n        if self.safe_exit:\n            if isinstance(self.light_source.shutter, Shutter):\n                self.light_source.shutter.toggle()\n            else:\n                self.light_source.power = 0",
  "def scan_function(self, *indices):\n        time.sleep(self.delay)\n        raw_spectra = self.read_spectra()\n        spectra = self.process_spectra(raw_spectra)\n        self.data['raw_data/hs_image'+self._suffix(0)][indices] = raw_spectra\n        self.data['hs_image'+self._suffix(0)][indices] = spectra\n#        for i, (spectrum, raw_spectrum) in enumerate(zip(spectra, raw_spectra)):\n#            try:\n#                suffix = self._suffix(i)\n#                self.data['raw_data/hs_image'+suffix][indices] = raw_spectrum\n#                self.data['hs_image'+suffix][indices] = spectrum\n#            except Exception as e:\n#                print e\n        self.check_for_data_request(*self.set_latest_view(*indices))",
  "def set_latest_view(self, *indices):\n        view_data = []\n        for i in range(self.num_spectrometers):\n            suffix = self._suffix(i)\n            spectrometer = self.spectrometer.spectrometers[i]\\\n                if isinstance(self.spectrometer, Spectrometers) else self.spectrometer\n            w = abs(spectrometer.wavelengths - self.view_wavelength).argmin()\n            data = self.data['hs_image'+suffix]\n            if self.num_axes == 2:\n                latest_view = data[:, :, w]\n                spectrum = self.data['hs_image'+suffix][indices[-2], indices[-1], :]\n            elif self.num_axes == 3:\n                if self.override_view_layer:\n                    k = self.view_layer\n                else:\n                    k = self.indices[0]\n                    if self.view_layer != k:\n                        self.view_layer = k\n                latest_view = data[k, :, :, w]\n                spectrum = self.data['hs_image'+suffix][k, indices[-2], indices[-1], :]\n            spectrum = spectrometer.mask_spectrum(spectrum, 0.05)\n            view_data += [latest_view, spectrometer.wavelengths, spectrum]\n        return tuple(view_data)",
  "def init_figure(self):\n        if self.fig is None:\n            return\n        self.fig.clear()\n        gs = gridspec.GridSpec(2, 2, hspace=0.5, wspace=0.5)\n        ax1 = self.fig.add_subplot(gs[0,0])\n        ax2 = self.fig.add_subplot(gs[0,1])\n        for ax in (ax1, ax2):\n            ax.set_xlabel('$x$')\n            ax.set_ylabel('$y$')\n            ax.set_aspect('equal')\n            mult = 1./self._unit_conversion[self.step_unit]\n            x, y = (mult*self.scan_axes[-1], mult*self.scan_axes[-2])\n            ax.set_xlim(x.min(), x.max())\n            ax.set_ylim(y.min(), y.max())\n        ax3 = self.fig.add_subplot(gs[1,:])\n        ax3.set_xlabel('wavelength (nm)')\n        ax3.set_ylabel('intensity (a.u.)')\n        ax4 = ax3.twinx()\n        ax4.set_ylabel('intensity (a.u.)')\n        gs.tight_layout(self.fig)\n        cid = self.fig.canvas.mpl_connect('button_press_event', self.on_mouse_click)",
  "def update(self, force=False):\n        super(HyperspectralScan, self).update(force)\n        if not self.fig:\n            return\n        if force:\n            data = self.set_latest_view(*self.indices)\n        else:\n            data = self.request_data()\n        if data is not False:\n            grouped_data = [data[i:i+3] for i in range(0,len(data),3)]\n            colours = ['r', 'b', 'g']\n            for i, data_group in enumerate(grouped_data):\n                img, wavelengths, spectrum = data_group\n                if not np.any(np.isfinite(img)):\n                    return\n                # self.image_plots[i].setImage(img)\n                # self.spectrum_plots[i].setData(x=wavelengths, y=spectrum, pen=colours[i])\n\n                ax = self.fig.axes[i]\n                if not ax.collections:\n                    mult = 1. / self._unit_conversion[self.step_unit]\n                    ax.pcolormesh(mult * self.scan_axes[-1], mult * self.scan_axes[-2], img,\n                                  cmap=matplotlib.cm.afmhot)\n                else:\n                    plot, = ax.collections\n                    plot.set_array(img[:-1, :-1].ravel())\n                    img_min = img[np.isfinite(img)].min()\n                    img_max = img[np.isfinite(img)].max()\n                    plot.set_clim(img_min, img_max)\n                    ax.relim()\n                    #ax.draw_artist(ax.patch)\n                    #ax.draw_artist(plot)\n                ax = self.fig.axes[i+2]\n                c = 'r' if i == 0 else 'b'\n                if not ax.lines:\n                    ax.plot(wavelengths, spectrum, c=c)\n                else:\n                    plot, = ax.lines\n                    plot.set_data(wavelengths, spectrum)\n                    ax.relim()\n                    ax.autoscale_view()\n            #self.fig.canvas.update()\n            #self.fig.canvas.flush_events()\n            self.fig.canvas.draw()",
  "def estimated_step_time(self):\n        if isinstance(self.spectrometer, Spectrometer):\n            max_exposure = self.spectrometer.integration_time\n        elif isinstance(self.spectrometer, Spectrometers):\n            max_exposure = 1e-3 * max([s.integration_time for s in self.spectrometer.spectrometers])\n        else:\n            max_exposure = 0\n            warnings.warn('No integration time as spectrometer is not a valid instance of Spectrometer or Spectrometers.')\n        max_travel = 100e-3\n        #self.estimated_step_time = max_exposure + max_travel\n        return max_exposure + max_travel",
  "def estimated_step_time(self, value):\n        print(value)",
  "def get_qt_ui(self):\n        return HyperspectralScanUI(self)",
  "def on_mouse_click(self, event):\n        init_scale = old_div(self._unit_conversion[self.step_unit], self._unit_conversion[self.init_unit])\n        self.init[:2] = (event.xdata * init_scale, event.ydata * init_scale)\n        self.init_updated.emit(self.init)",
  "def __init__(self, grid_scanner, parent=None):\n        assert isinstance(grid_scanner, HyperspectralScan), \\\n            'scanner must be an instance of HyperspectralScan'\n        super(HyperspectralScanUI, self).__init__()\n        self.grid_scanner = grid_scanner\n        uic.loadUi(os.path.join(os.path.dirname(__file__), 'hyperspectral_imaging.ui'), self)\n        self.gridscanner_widget = self.replace_widget(self.main_layout, self.gridscanner_widget,\n                                                      GridScanQt.get_qt_ui_cls()(self.grid_scanner))\n        self.gridscanner_widget.rate = 1./20.\n\n        self.grid_scanner.fig = Figure()  # pg.GraphicsLayoutWidget()\n        # self.grid_scanner.fig.scene().sigMouseClicked.connect(self.grid_scanner.on_mouse_click)\n        self.figure_widget = self.replace_widget(self.main_layout, self.figure_widget,\n                                                 FigureCanvas(self.grid_scanner.fig))\n\n        self.init_stage_select()\n        self.init_view_wavelength_controls()\n        self.init_view_select()\n\n        self.scan_description.textChanged.connect(self.update_param)\n        self.safe_exit.stateChanged.connect(self.on_state_change)\n\n        self.config_stage.clicked.connect(self.on_click)\n        self.config_spectrometers.clicked.connect(self.on_click)\n        self.config_light_source.clicked.connect(self.on_click)\n        self.open_browser.clicked.connect(self.on_click)",
  "def init_stage_select(self):\n        self.stage_select.addItems(['PI', 'SmarAct'])\n        self.stage_select.activated[str].connect(self.select_stage)",
  "def init_view_wavelength_controls(self):\n        self.view_wavelength.setValidator(QtGui.QIntValidator())\n        # self.view_wavelength.textChanged.connect(self.check_state)\n        self.view_wavelength.returnPressed.connect(self.on_view_wavelength_change)\n\n        min_wl = np.min(self.grid_scanner.spectrometer.wavelengths)\n        max_wl = np.max(self.grid_scanner.spectrometer.wavelengths)\n        self.wavelength_range.setRange(min_wl, max_wl)\n        self.wavelength_range.setFocusPolicy(QtCore.Qt.NoFocus)\n        self.wavelength_range.valueChanged[int].connect(self.on_wavelength_range_change)\n\n        self.view_wavelength.setText(str(self.grid_scanner.view_wavelength))\n        self.wavelength_range.setValue(self.grid_scanner.view_wavelength)",
  "def init_view_select(self):\n        self.view_layer.setValidator(QtGui.QIntValidator())\n        self.view_layer.textChanged.connect(\n            self.on_view_layer_change)  # (partial(setattr, self.grid_scanner, 'view_layer'))\n        self.grid_scanner.view_layer_updated.connect(self.on_gs_view_layer_change)\n\n        self.override_view_layer.stateChanged.connect(self.on_override_view_layer)",
  "def update_param(self, *args, **kwargs):\n        sender = self.sender()\n        if sender == self.scan_description:\n            self.grid_scanner.description = self.scan_description.toPlainText().encode('utf8')",
  "def select_stage(self, name):\n        print(name)",
  "def on_click(self):\n        sender = self.sender()\n        if sender == self.config_stage:\n            self.stage_ui = self.grid_scanner.stage.get_qt_ui()\n            self.stage_ui.show()\n        elif sender == self.config_spectrometers:\n            self.spectrometers_ui = self.grid_scanner.spectrometer.get_qt_ui()\n            self.spectrometers_ui.show()\n        elif sender == self.config_light_source:\n            self.light_source_ui = self.grid_scanner.light_source.get_qt_ui()\n            self.light_source_ui.show()\n            pass\n        elif sender == self.open_browser:\n            if self.grid_scanner.f is not None:\n                print(self.grid_scanner.f)\n                self.browser = HDF5Browser(self.grid_scanner.f)\n                self.browser.show()",
  "def on_state_change(self, state):\n        sender = self.sender()\n        if sender is self.safe_exit:\n            if state == QtCore.Qt.Checked:\n                self.grid_scanner.safe_exit = True\n            elif state == QtCore.Qt.Unchecked:\n                self.grid_scanner.safe_exit = False",
  "def on_view_wavelength_change(self, *args, **kwargs):\n        \"\"\"\n        This function is called by the power text box.\n\n        :param args:\n        :param kwargs:\n        :return:\n        \"\"\"\n        print(self.view_wavelength.text())\n        value = int(self.view_wavelength.text())\n        # self.wavelength_range.valueChanged[int].emit(value)\n        self.wavelength_range.setValue(value)",
  "def on_wavelength_range_change(self, value):\n        \"\"\"\n        This function is called by the power slider.\n\n        :param value:\n        :return:\n        \"\"\"\n        self.grid_scanner.view_wavelength = value\n        self.view_wavelength.setText('%d' % value)",
  "def on_view_layer_change(self, *args, **kwargs):\n        self.grid_scanner.view_layer = int(self.view_layer.text())",
  "def on_gs_view_layer_change(self, value):\n        self.view_layer.setText(str(value))",
  "def on_override_view_layer(self, state):\n        if state == QtCore.Qt.Checked:\n            self.grid_scanner.override_view_layer = True\n        else:\n            self.grid_scanner.override_view_layer = False",
  "def plot_wavelength_images(hsimg, axslice, roi, fig, ax, subplot_spec, amp=5):\n    wavelengths = [500,600,700,800,900]\n    n_axes = len(wavelengths) + 1  # add 1 axis for colour reconstruction\n\n    #gs1 = gridspec.GridSpecFromSubplotSpec(int(np.ceil(n_axes/3)), 3, subplot_spec,\n    #                                       hspace=0.05, wspace=0.05)\n    grid = ImageGrid(fig, subplot_spec, # similar to subplot(111)\n                nrows_ncols = (int(np.ceil(old_div(n_axes,3))), 3), # creates 2x3 grid of axes\n                axes_pad=0.05, # pad between axes in inch.\n                )\n\n    ax = make_dummy_subplot(ax)\n    ax.set_ylabel('$y$ (nm)', labelpad=23)\n    ax.set_xlabel('$x$ (nm)', labelpad=15)\n\n    for i,wl in enumerate(wavelengths):\n        ax = grid[i]  #fig.add_subplot(gs1[i])\n        if i>2: xlabels=True\n        else: xlabels = False\n        if i%3==0: ylabels = True\n        else: ylabels = False\n        plot_wavelength(hsimg, ax, wl, axslice=axslice, xlabels=xlabels, ylabels=ylabels,\n                        wlnorm=False, threshold=0.5, smoothing=(0, 1),\n                        img_kwargs={'cmap': mpl.cm.afmhot, 'vmin': 0.0})\n        ax.set_xlabel('')\n        ax.set_ylabel('')\n        #if i==3:\n        #    ax.set_xlabel('')\n        #    ax.set_ylabel('')\n        #if i==0:\n        #    ax.set_ylabel('')\n    ax = fig.add_subplot(grid[i+1])\n    img = plot_colour(hsimg, ax, amp=amp, axslice=axslice, smoothing=(0,1,0), norm=True, ylabels=False)\n    ax.set_xlabel('')\n    ax.add_patch(Rectangle((1e9*roi[0],1e9*roi[2]), 1e9*(roi[1]-roi[0]), 1e9*(roi[3]-roi[2]), ec='w', fc='w', alpha=0.1, linewidth=1.5))",
  "def plot_scan(hsimg, axslice, roi, amp=5):\n    axial_wavelength, axial_spectrum = hsimg.integrate_spectra(xlims=(roi[0],roi[1]), ylims=(roi[2],roi[3]), axslice=axslice)\n    transverse_wavelength, transverse_spectrum = hsimg.integrate_spectra(xlims=(roi[0],roi[1]), ylims=(roi[2],roi[3]), axslice=axslice, polarisation=2)\n\n    wavelengths = [500,600,700,800,900]\n    n_axes = len(wavelengths) + 1  # add 1 axis for colour reconstruction\n    aspect = 0.75 + 0.6\n\n    fig = setup_figure(width='column', aspect=aspect, tex=False)\n    gs0 = gridspec.GridSpec(2, 1, height_ratios=[0.75,0.6], hspace=0.34)\n    gs1 = gridspec.GridSpecFromSubplotSpec(int(np.ceil(old_div(n_axes,3))), 3, gs0[0], hspace=0.05, wspace=0.05)\n\n    # make dummy axes from gridspec gs0[0]\n    ax = fig.add_subplot(gs0[0])\n    ax = make_dummy_subplot(ax)\n    ax.set_ylabel('$y$ (nm)', labelpad=23)\n    ax.text(-0.12,1.05,'(a)', ha='right', va='top', transform=ax.transAxes)\n\n    for i,wl in enumerate(wavelengths):\n        ax = fig.add_subplot(gs1[i])\n        if i>2: xlabels=True\n        else: xlabels = False\n        if i%3==0: ylabels = True\n        else: ylabels = False\n        plot_wavelength(hsimg, ax, wl, axslice=axslice, xlabels=xlabels, ylabels=ylabels,\n                        wlnorm=False, threshold=0.5, smoothing=(0,1),\n                        img_kwargs={'cmap':mpl.cm.afmhot, 'vmin':0.0})\n        if i==3:\n            ax.set_xlabel('')\n            ax.set_ylabel('')\n        if i==0:\n            ax.set_ylabel('')\n    ax = fig.add_subplot(gs1[i+1])\n    img = plot_colour(hsimg, ax, amp=amp, axslice=axslice, smoothing=(0,1,0), norm=True, ylabels=False)\n    ax.set_xlabel('')\n    #img = plot_colour_map(hsimg, ax, axslice=5, img_kwargs={'cmap':mpl.cm.spectral})\n    #plt.setp(ax.get_yticklabels(), visible=False)\n    ax.add_patch(Rectangle((1e9*roi[0],1e9*roi[2]), 1e9*(roi[1]-roi[0]), 1e9*(roi[3]-roi[2]), ec='w', fc='w', alpha=0.1, linewidth=1.5))\n\n    ax = fig.add_subplot(gs0[1])\n    ax.text(-0.12,1.05,'(b)', ha='right', va='top', transform=ax.transAxes)\n\n    plot_spectrum(axial_wavelength, axial_spectrum, color='r', label='axial')\n    plot_spectrum(transverse_wavelength, transverse_spectrum, color='b', label='transverse')\n    format_spectrum(ax)\n    ax.set_ylabel('optical\\nresponse (a.u.)')\n    ax.legend(loc='best', fontsize='small')\n    ax.set_ylim(ymin=0.)\n    ax.set_xlim(450,1150)\n    ax.yaxis.set_major_locator(mpl.ticker.MultipleLocator(0.1))\n    ax.yaxis.set_minor_locator(mpl.ticker.AutoMinorLocator(4))\n\n    #gs.tight_layout(fig, w_pad=0.2, h_pad=0.2)\n    #plt.tight_layout()\n    return fig",
  "def _plot_image(x, y, z, ax, **kwargs):\n    img_kwargs = {'vmin': z.min(), 'vmax': z.max(), 'cmap': cm.afmhot,\n                  'rasterized': True, 'shading': 'gouraud'}\n    for k in kwargs:\n        img_kwargs[k] = kwargs[k]\n    x, y = np.meshgrid(x, y, indexing='ij')\n    img = ax.pcolormesh(x, y, z, **img_kwargs)\n    ax.set_xlim(x.min(), x.max())\n    ax.set_ylim(y.min(), y.max())\n    return img",
  "def _format_image_plot(ax, xlabel=None, ylabel=None, invert=False):\n    ax.minorticks_on()\n    ax.set_aspect('equal')\n    ax.tick_params(axis='both', which='major', labelsize='small')\n    for axis in [ax.xaxis, ax.yaxis]:\n        axis.set_major_locator(MaxNLocator(5))\n        axis.set_minor_locator(AutoMinorLocator(4))\n        axis.set_major_formatter(FormatStrFormatter('%d'))\n    if invert:\n        [i.set_color('white') for i in ax.xaxis.get_ticklines()]\n        [i.set_color('white') for i in ax.yaxis.get_ticklines()]\n        [ax.spines[s].set_color('white') for s in ax.spines]\n    if xlabel is not None:\n        ax.set_xlabel(xlabel)\n    else:\n        plt.setp(ax.get_xticklabels(), visible=False)\n    if ylabel is not None:\n        ax.set_ylabel(ylabel)\n    else:\n        plt.setp(ax.get_yticklabels(), visible=False)",
  "def plot_wavelength(hs_image, ax, wl, polarisation=1, wlnorm=True, rescale_axes=False,\n                    smoothing=None, contour_lines=None, mult=1.,\n                    loc='upper right', xlabels=True, ylabels=True, threshold=None,\n                    img_kwargs={}, contour_kwargs={'colors':'k'}, **kwargs):\n    \"\"\"Plots the hyperspectral image at the selected wavelength on a given axis.\"\"\"\n\n    image = hs_image.get_image(wl, polarisation, **kwargs)\n    if wlnorm:\n        minimum, maximum = (image.min(), image.max())\n    else:\n        wavelength, spectra = hs_image.get_spectra(polarisation)\n        minimum, maximum = (spectra.min(), spectra.max())\n    if threshold is not None:\n        maximum = threshold*maximum + (1-threshold)*minimum\n\n    x, unit = scale_axes(hs_image.x)\n    y, unit = scale_axes(hs_image.y)\n    if rescale_axes:\n        x -= x.mean()\n        y -= y.mean()\n    image *= mult\n    if smoothing is not None:\n        image = gaussian_filter(image, smoothing)\n    img = _plot_image(x, y, image, ax, **img_kwargs)\n    if contour_lines is not None:\n        ax.contour(x, y, image, contour_lines, **contour_kwargs)\n    if xlabels: xlabel = '$x$ (%s)'%unit\n    else: xlabel = None\n    if ylabels: ylabel = '$y$ (%s)'%unit\n    else: ylabel = None\n    _format_image_plot(ax, xlabel=xlabel, ylabel=ylabel)\n    tx, ty = locs[loc]\n    ax.text(tx, ty, str(wl)+' nm', va='top', ha='right',\n            transform=ax.transAxes, color='white', fontsize='small', fontweight='bold')\n    return img",
  "def plot_colour_map(hs_image, ax, polarisation=1, norm=True,\n                    smoothing=None,\n                    loc='upper right', xlabels=True, ylabels=True,\n                    img_kwargs={}, **kwargs):\n    \"\"\"Plots the hyperspectral image at the selected wavelength on a given axis.\"\"\"\n\n    image = hs_image.construct_colour_map(polarisation, norm, **kwargs)\n    x, unit = scale_axes(hs_image.x)\n    y, unit = scale_axes(hs_image.y)\n    if smoothing is not None:\n        image = gaussian_filter(image, smoothing)\n    img = _plot_image(x, y, image, ax, **img_kwargs)\n    if xlabels: xlabel = '$x$ (%s)'%unit\n    else: xlabel = None\n    if ylabels: ylabel = '$y$ (%s)'%unit\n    else: ylabel = None\n    _format_image_plot(ax, xlabel=xlabel, ylabel=ylabel)\n    #tx, ty = locs[loc]\n    #ax.text(tx, ty, 'false colour', va='top', ha='right',\n    #        transform=ax.transAxes, color='white', fontsize='small')\n    return img",
  "def plot_colour(hs_image, ax, amp=1, smoothing=None, loc='upper right',\n                xlabels=True, ylabels=True,\n                **kwargs):\n    ax.set_axis_bgcolor('black')\n    image = hs_image.reconstruct_colour_image(**kwargs)\n    if smoothing is not None:\n        image = gaussian_filter(image, smoothing)\n    image[:,:,3] = amp*image[:,:,3]\n    image[:,:,3] = np.where(image[:,:,3] > 1, 1, image[:,:,3])\n    x, unit = scale_axes(hs_image.x)\n    y, unit = scale_axes(hs_image.y)\n    limits = np.array([x.min(), x.max(),\n                       y.min(), y.max()])\n    ax.imshow(image, origin='lower', extent=limits)\n    ax.set_xlim(limits[0], limits[1])\n    ax.set_ylim(limits[2], limits[3])\n    if xlabels: xlabel = '$x$ (%s)'%unit\n    else: xlabel = None\n    if ylabels: ylabel = '$y$ (%s)'%unit\n    else: ylabel = None\n    _format_image_plot(ax, xlabel=xlabel, ylabel=ylabel)\n    tx, ty = locs[loc]\n    ax.text(tx, ty, 'colour', va='top', ha='right',\n            transform=ax.transAxes, color='white', fontsize='small')\n    return image",
  "def plot_line_scan(hs_image, ax, axis, line, imnorm=False, linenorm=False, dat='', smooth=None):\n    if dat=='':\n        spectra = hs_image.spectra\n        wavelength = hs_image.wavelength\n    elif dat=='trans':\n        data = hs_image.data_t\n        wavelength = hs_image.wavelength_t\n    line_spectra = hs_image.get_line_spectra(axis, line, dat)\n\n    if smooth != None: line_spectra = gaussian_filter(line_spectra, smooth)\n\n    if linenorm == True:\n        for i in range(line_spectra.shape[0]):\n            line_spectra[i] = old_div(line_spectra[i], line_spectra[i].max())\n\n    if imnorm == True:\n        minimum = line_spectra.min()\n        maximum = line_spectra.max()\n    else:\n        minimum = data.min() * (data.min()>=0.0)\n        maximum = data.max() * (data.max()>=0.0)\n\n    #lev_exp = np.linspace(np.log10(minimum), np.log10(maximum), 200)\n    #levs = np.power(10, lev_exp)\n    #norm = LogNorm(minimum, maximum)\n    levs = np.linspace(minimum, maximum, 200)\n    norm = cm.colors.Normalize(vmax=maximum, vmin=minimum)\n\n    X, Y = np.meshgrid(hs_image.x, wavelength, indexing='ij')\n    ax.contourf(X, Y, line_spectra, levs, norm=norm, cmap=cm.CMRmap)\n\n    if axis=='x': label = 'y={0:.2f} nm'.format(hs_image.x[line])\n    if axis=='y': label = 'x={0:.2f} nm'.format(hs_image.y[line])\n    ax.text(0.95, 0.95, label, va='top', ha='right',\n            transform=ax.transAxes, color='white', fontsize='small')\n    ax.tick_params(axis='both', which='major', labelsize='small')\n    ax.set_xlim(hs_image.x.min(), hs_image.x.max())\n    ax.set_ylim(wavelength.min(), wavelength.max())\n    _format_image_plot(ax)\n    return line_spectra",
  "class HyperspectralImage(object):\n    '''Applies to both 2D and 3D hyperspectral images, however some methods\n    are limited to specific cases and will raise assertion errors when\n    miscalled.'''\n\n    def __init__(self, file_location,\n                 data_location='hyperspectral_images',\n                 scan_id=None):\n        super(HyperspectralImage, self).__init__()\n        self.f, self.scan = load_data(file_location, data_location, scan_id)\n        self._load_data(self.scan)\n        self._load_calibrations()\n\n    def __del__(self):\n        if self.f is not None:\n            self.f.close()\n\n    def _load_data(self, scan):\n        # ROI data\n        self._rescale = False\n        self._x_lims = (-np.inf, np.inf)\n        self._x_roi = np.s_[:]\n        self._y_lims = (-np.inf, np.inf)\n        self._y_roi = np.s_[:]\n        self._z_lims = (-np.inf, np.inf)\n        self._z_roi = np.s_[:]\n        self._wavelength_lims = (-np.inf, np.inf)\n        self._wavelength_roi = np.s_[:]\n        self._wavelength2_lims = (-np.inf, np.inf)\n        self._wavelength2_roi = np.s_[:]\n        # Other attributes\n        self.attrs = dict(scan.attrs)\n        if 'num_spectrometers' not in self.attrs:\n            self.attrs['num_spectrometers'] = len([s for s in list(scan.keys()) if 'spectra' in s])\n\n    # ROI properties\n    @property\n    def x_lims(self):\n        return self._x_lims\n    @x_lims.setter\n    def x_lims(self, value):\n        assert len(value) == 2, 'Value must have 2 elements'\n        self._x_lims = value\n        a = self.scan['x'][()]\n        a = (a - (a.min()+a.max())/2.0)\n        self._x_roi = get_roi(a, value[0], value[1])\n    @property\n    def y_lims(self):\n        return self._y_lims\n    @y_lims.setter\n    def y_lims(self, value):\n        assert len(value) == 2, 'Value must have 2 elements'\n        self._y_lims = value\n        a = self.scan['y'][()]\n        a = (a - (a.min()+a.max())/2.0)\n        self._y_roi = get_roi(a, value[0], value[1])\n    @property\n    def z_lims(self):\n        return self._z_lims\n    @z_lims.setter\n    def z_lims(self, value):\n        assert len(value) == 2, 'Value must have 2 elements'\n        if 'z' in self.scan:\n            self._z_lims = value\n            a = self.scan['z'][()]\n            a = (a - (a.min()+a.max())/2.0)\n            self._z_roi = get_roi(a, value[0], value[1])\n        else:\n            print('There is no z dataset')\n    @property\n    def wavelength_lims(self):\n        return self._wavelength_lims\n    @wavelength_lims.setter\n    def wavelength_lims(self, value):\n        assert len(value) == 2, 'Value must have 2 elements'\n        self._wavelength_lims = value\n        self._wavelength_roi = get_roi(self.scan['wavelength'][()], value[0], value[1])\n    @property\n    def wavelength2_lims(self):\n        return self._wavelength2_lims\n    @wavelength2_lims.setter\n    def wavelength2_lims(self, value):\n        assert len(value) == 2, 'Value must have 2 elements'\n        if 'wavelength2' in self.scan:\n            self._wavelength2_lims = value\n            self._wavelength2_roi = get_roi(self.scan['wavelength2'][()], value[0], value[1])\n        else:\n            print('There is no wavelength2 dataset')\n    # Axes data properties\n    @property\n    def x(self):\n        a = self.scan['x'][()]\n        a = (a - (a.min()+a.max())/2.0)\n        a = a[self._x_roi]\n        if self._rescale:\n            a = (a - (a.min()+a.max())/2.0)\n        return a\n    @property\n    def y(self):\n        a = self.scan['y'][()]\n        a = (a - (a.min()+a.max())/2.0)\n        a = a[self._y_roi]\n        if self._rescale:\n            a = (a - (a.min()+a.max())/2.0)\n        return a\n    @property\n    def z(self):\n        if 'z' in self.scan:\n            a = self.scan['z'][()]\n            a = (a - (a.min()+a.max())/2.0)\n            a = a[self._z_roi]\n            if self._rescale:\n                a = (a - (a.min()+a.max())/2.0)\n            return a\n        else:\n            print('There is no z dataset')\n    @property\n    def wavelength(self): return self.scan['wavelength'][self._wavelength_roi]\n    @property\n    def energy(self): return old_div(1e9*(old_div(h*c,self.wavelength)),e)\n    @property\n    def wavelength2(self):\n        if 'wavelength2' in self.scan:\n            return self.scan['wavelength2'][self._wavelength2_roi]\n        else:\n            print('There is no wavelength2 dataset')\n    @property\n    def energy2(self):\n        if 'wavelength2' in self.scan:\n            return old_div(1e9*(old_div(h*c,self.wavelength2)),e)\n        else:\n            print('There is no wavelength2 dataset so cannot return energy2')\n    # Data properties\n    @property\n    def spectra(self):\n        ndim = len(self.scan['hs_image'].shape)-1\n        if ndim == 2:\n            roi = np.s_[self._y_roi, self._x_roi, self._wavelength_roi]\n        elif ndim == 3:\n            roi = np.s_[self._z_roi, self._y_roi, self._x_roi, self._wavelength_roi]\n        a = self.scan['hs_image'][roi]\n        a = np.where(np.isfinite(a), a, 0.0)\n        return a\n    @property\n    def spectra2(self):\n        if 'wavelength2' in self.scan and 'hs_image2' in self.scan:\n            ndim = len(self.scan['hs_image2'].shape)-1\n            if ndim == 2:\n                roi = np.s_[self._y_roi, self._x_roi, self._wavelength2_roi]\n            elif ndim == 3:\n                roi = np.s_[self._z_roi, self._y_roi, self._x_roi, self._wavelength2_roi]\n            a = self.scan['hs_image2'][roi]\n            a = np.where(np.isfinite(a), a, 0.0)\n            return a\n        else:\n            print('There is no hs_image2 dataset')\n\n    def _load_calibrations(self):\n        self.fitfunc = lambda x,a,b,c: a*x**2 + b*x + c\n        self._px1 = (4.30671055e-13, -1.64351619e-10, -1.45004691e-09)\n        self._py1 = (-4.41782891e-13, 8.89024179e-10, -3.43640870e-07)\n        self._px2 = (4.39995226e-13, -1.77391339e-10, 2.86613916e-09)\n        self._py2 = (-4.46213678e-13, 8.94792646e-10, -3.45533004e-07)\n        self._dx1, self._dy1 = self._get_offset(self.wavelength, polarisation=1)\n        self._dx2, self._dy2 = self._get_offset(self.wavelength, polarisation=2)\n\n    def apply_corrections(self, a, dataset):\n        name = dataset.name.rsplit('/', 1)[1]\n        if name in ['x', 'y', 'z']:\n            a = (a - (a.min()+a.max())/2.0)\n        elif 'hs_image' in name:\n            a = np.where(np.isfinite(a), a, 0.0)\n        return a\n\n    def get_spectra(self, polarisation=1):\n        if polarisation == 2:\n            assert self.attrs['num_spectrometers'] == 2, 'polarisation does not exist'\n        data = self.spectra2 if polarisation == 2 else self.spectra\n        wavelength = self.wavelength2 if polarisation == 2 else self.wavelength\n        return wavelength, data\n\n    def get_image(self, wl, polarisation=1, axis=0, axslice=None):\n        \"\"\"Returns an image at a given wavelength (layer slice).\"\"\"\n        wavelength, spectra = self.get_spectra(polarisation)\n        if spectra.ndim == 3:\n            return spectra[:,:, get_nearest(wavelength, wl)]\n        elif spectra.ndim > 3:\n            assert axslice is not None, 'slice argument required for 3d images'\n            return spectra[axslice, :, :, get_nearest(wavelength, wl)]\n        else:\n            return None\n\n    def integrate_spectra(self, xlims=None, ylims=None, polarisation=1, axslice=None, return_patch=False):\n        wavelength, spectra = self.get_spectra(polarisation)\n        if spectra.ndim > 3:\n            assert axslice is not None, 'slice argument required for 3d images'\n        if xlims is None:\n            x_roi = np.s_[:]\n        else:\n            x_roi = get_roi(self.x, xlims[0], xlims[1])\n        if ylims is None:\n            y_roi = np.s_[:]\n        else:\n            y_roi = get_roi(self.y, ylims[0], ylims[1])\n        spectra = spectra[axslice, y_roi, x_roi, :] if spectra.ndim > 3 else spectra[y_roi,\n                                                                             x_roi, :]\n        spectrum = np.mean(spectra, axis=(0,1))\n        if return_patch:\n            x, y = (self.x[x_roi], self.y[y_roi])\n            print('averaged over a %dx%d grid' % (len(x), len(y)))\n            patch = np.array([x.min(), y.min(), x.max()-x.min(), y.max()-y.min()])\n            return wavelength, spectrum, patch\n        else:\n            return wavelength, spectrum\n\n    def get_line_spectra(self, axis, line, polarisation=1):\n        wavelength, spectra = self.get_spectra(polarisation)\n        if axis=='x': line_spectra = np.array(spectra[:,line,:])\n        elif axis=='y': line_spectra = np.array(spectra[line,:,:])\n        return line_spectra\n\n    def reconstruct_colour_image(self, polarisation=1, norm=True, axslice=None):\n        \"\"\"Take a hyperspectral image and convert it to an rgb image.\"\"\"\n        wavelength, spectra = self.get_spectra(polarisation)\n        if spectra.ndim > 3:\n            assert axslice is not None, 'slice argument required for 3d images'\n            spectra = spectra[axslice,:,:,:]\n        img = cr.reconstruct_colour_image(spectra, wavelength, norm)\n        return img\n\n    def construct_colour_map(self, polarisation=1, norm=True, axslice=None):\n        \"\"\"Take a hyperspectral image and convert it to an colour map of\n        average wavelength.\"\"\"\n        wavelength, spectra = self.get_spectra(polarisation)\n        if spectra.ndim > 3:\n            assert axslice is not None, 'slice argument required for 3d images'\n            spectra = spectra[axslice,:,:,:]\n        h, w, s = spectra.shape\n        img = np.zeros((h,w))\n        for pos in product(list(range(h)), list(range(w))):\n            i,j = pos\n            spectrum = spectra[i,j,:]\n            threshold = spectrum < 0.01*spectrum.max()\n            spectrum = np.ma.array(spectrum, mask=threshold)\n            wl = np.ma.array(wavelength, mask=threshold)\n            img[i,j] = np.ma.average(wl, axis=-1, weights=spectrum)\n        return img\n\n    def create_calibration(self, unit='SI', polarisation=1, wl_step=5, axslice=None):\n        wavelength, spectra = self.get_spectra(polarisation)\n        wavelength = wavelength[::wl_step]\n        if unit=='pixel':\n            x = np.arange(self.x.size)\n            y = np.arange(self.y.size)\n        elif unit=='SI':\n            x = self.x\n            y = self.y\n        # for all wavelengths fit a centroid to create an array of x0s, y0s\n        x0s = np.zeros_like(wavelength)\n        y0s = np.zeros_like(wavelength)\n        for i,wl in enumerate(wavelength):\n            img = self.get_image(wl, polarisation=1, axslice=axslice)\n            x0, y0 = fit_centroid(img, x, y)\n            x0s[i] = x0\n            y0s[i] = y0\n        roi = slice(np.min(np.where(500 < wavelength)), np.max(np.where(wavelength < 1000)))\n        # fit the functions wavelength vs x0, y0 for wl to offset correction\n        self._fit_calibration(wavelength, x0s, 'x%d'%polarisation, mask=roi)\n        self._fit_calibration(wavelength, y0s, 'y%d'%polarisation, mask=roi)\n        return wavelength, x0s, y0s\n\n    def _fit_calibration(self, x, y, label, mask=None):\n        '''This is an arbitrary quadratic fit function with no dependencies on\n        the data supplied, i.e. it is indepdent of the units, pixels or SI.'''\n        if mask is not None:\n            x = x[mask]\n            y = y[mask]\n        p, cov = curve_fit(self.fitfunc, x, y)\n        setattr(self, '_p'+label, p)\n        return p, cov\n\n    def save_calibration(self):\n        with open('/Users/alansanders/Desktop/calibration.txt', 'w') as f:\n            f.write('p{0:s}: {1}\\n'.format('px1', self.px1))\n            f.write('p{0:s}: {1}\\n'.format('py1', self.py1))\n            f.write('p{0:s}: {1}\\n'.format('px2', self.px2))\n            f.write('p{0:s}: {1}\\n'.format('py2', self.py2))\n\n    def load_calibration(self):\n        with open('/Users/alansanders/Desktop/calibration.txt', 'w') as f:\n            lines = [l.strip() for l in f.readlines()]\n            ps = [s.split(': ')[1] for s in lines]\n            self._px1 = (ps[0])\n            self._py1 = (ps[1])\n            self._px2 = (ps[2])\n            self._py2 = (ps[3])\n\n    def _get_offset(self, wavelength, polarisation=1, unit='SI'):\n        '''Reference wavelength is 500 nm. The function returns how much\n        an image should be shifted by in the (dx,dy) direction for each\n        wavelength. The units of (dx,dy) can be specified but are based upon\n        the assumption that the calibration was done in SI units for\n        standardisation between different sized grids.'''\n        xr = self.fitfunc(500, *getattr(self, '_px%d'%polarisation))\n        yr = self.fitfunc(500, *getattr(self, '_py%d'%polarisation))\n        #wavelength, data = self.get_data(polarisation)\n        xo = self.fitfunc(wavelength, *getattr(self, '_px%d'%polarisation))\n        yo = self.fitfunc(wavelength, *getattr(self, '_py%d'%polarisation))\n\n        if unit=='SI':\n            dx = xo-xr\n            dy = yo-yr\n            return dx, dy\n        elif unit=='pixel':\n            # now require SI to pixel conversions\n            # find out which pixel is closest to xo, yo\n            dpx = [abs(self.x - i).argmin() for i in xo] - abs(self.x - xr).argmin()\n            dpy = [abs(self.y - i).argmin() for i in yo] - abs(self.y - yr).argmin()\n            return dpx, dpy\n\n    def correct_aberrations(self, axslice=None):\n        self._correct_chromatic_aberration(polarisation=1, axslice=axslice)\n        if self.num_spectrometers==2:\n            self._correct_chromatic_aberration(polarisation=2, axslice=axslice)\n\n    def _correct_chromatic_aberration(self, polarisation=1, axslice=None):\n        wavelength, spectra = self.get_spectra(polarisation)\n        xo, yo = self._get_offset(wavelength, unit='pixel')\n        s = spectra.shape\n        #print 'starting data shape:', s\n        s11 = old_div(s[0],2)\n        s12 = s11 + s[0]\n        s21 = old_div(s[1],2)\n        s22 = s21 + s[1]\n        # a 1.6 factor is used to go just beyond the physical maximum shift of\n        # 50% of the current view\n        if spectra.ndim > 3:\n            big_img = np.zeros((1.6*s[-4], 1.6*s[-3], s[-2], s[-1]))\n        else:\n            big_img = np.zeros((1.6*s[-3], 1.6*s[-2], s[-1]))\n        big_img[:] = np.nan\n        x_step = self.x[1] - self.x[0]\n        x = x_step * np.arange(big_img.shape[0])\n        x -= x[old_div(x.size,2)]\n        y_step = self.y[1] - self.y[0]\n        y = y_step * np.arange(big_img.shape[1])\n        y -= y[old_div(y.size,2)]\n        for i in range(s[-1]): # for each wavelength (last dimension)\n            dx = int(round(xo[i]))\n            dy = int(round(yo[i]))\n            #print 'shifts:', dx, dy\n            #print 'central region:', s12-s11, s22-s21\n            #print big_img[s11-dx:s12-dx, s21-dy:s22-dy, i].shape, data[:,:,i].shape\n            if spectra.ndim > 3:\n                big_img[s11-dx:s12-dx, s21-dy:s22-dy, :, i] = spectra[:,:,:,i]\n            else:\n                big_img[s11-dx:s12-dx, s21-dy:s22-dy, i] = spectra[:,:,i]\n        data = np.nan_to_num(big_img)\n        # update data - note that this will invalidate the other polarisation data\n        # and that this data is temporary and will be overwritten if ROI changes\n        # are called\n        setattr(self, 'spectra2' if polarisation==2 else 'spectra', spectra)\n        self.x = x\n        self.y = y",
  "def __init__(self, file_location,\n                 data_location='hyperspectral_images',\n                 scan_id=None):\n        super(HyperspectralImage, self).__init__()\n        self.f, self.scan = load_data(file_location, data_location, scan_id)\n        self._load_data(self.scan)\n        self._load_calibrations()",
  "def __del__(self):\n        if self.f is not None:\n            self.f.close()",
  "def _load_data(self, scan):\n        # ROI data\n        self._rescale = False\n        self._x_lims = (-np.inf, np.inf)\n        self._x_roi = np.s_[:]\n        self._y_lims = (-np.inf, np.inf)\n        self._y_roi = np.s_[:]\n        self._z_lims = (-np.inf, np.inf)\n        self._z_roi = np.s_[:]\n        self._wavelength_lims = (-np.inf, np.inf)\n        self._wavelength_roi = np.s_[:]\n        self._wavelength2_lims = (-np.inf, np.inf)\n        self._wavelength2_roi = np.s_[:]\n        # Other attributes\n        self.attrs = dict(scan.attrs)\n        if 'num_spectrometers' not in self.attrs:\n            self.attrs['num_spectrometers'] = len([s for s in list(scan.keys()) if 'spectra' in s])",
  "def x_lims(self):\n        return self._x_lims",
  "def x_lims(self, value):\n        assert len(value) == 2, 'Value must have 2 elements'\n        self._x_lims = value\n        a = self.scan['x'][()]\n        a = (a - (a.min()+a.max())/2.0)\n        self._x_roi = get_roi(a, value[0], value[1])",
  "def y_lims(self):\n        return self._y_lims",
  "def y_lims(self, value):\n        assert len(value) == 2, 'Value must have 2 elements'\n        self._y_lims = value\n        a = self.scan['y'][()]\n        a = (a - (a.min()+a.max())/2.0)\n        self._y_roi = get_roi(a, value[0], value[1])",
  "def z_lims(self):\n        return self._z_lims",
  "def z_lims(self, value):\n        assert len(value) == 2, 'Value must have 2 elements'\n        if 'z' in self.scan:\n            self._z_lims = value\n            a = self.scan['z'][()]\n            a = (a - (a.min()+a.max())/2.0)\n            self._z_roi = get_roi(a, value[0], value[1])\n        else:\n            print('There is no z dataset')",
  "def wavelength_lims(self):\n        return self._wavelength_lims",
  "def wavelength_lims(self, value):\n        assert len(value) == 2, 'Value must have 2 elements'\n        self._wavelength_lims = value\n        self._wavelength_roi = get_roi(self.scan['wavelength'][()], value[0], value[1])",
  "def wavelength2_lims(self):\n        return self._wavelength2_lims",
  "def wavelength2_lims(self, value):\n        assert len(value) == 2, 'Value must have 2 elements'\n        if 'wavelength2' in self.scan:\n            self._wavelength2_lims = value\n            self._wavelength2_roi = get_roi(self.scan['wavelength2'][()], value[0], value[1])\n        else:\n            print('There is no wavelength2 dataset')",
  "def x(self):\n        a = self.scan['x'][()]\n        a = (a - (a.min()+a.max())/2.0)\n        a = a[self._x_roi]\n        if self._rescale:\n            a = (a - (a.min()+a.max())/2.0)\n        return a",
  "def y(self):\n        a = self.scan['y'][()]\n        a = (a - (a.min()+a.max())/2.0)\n        a = a[self._y_roi]\n        if self._rescale:\n            a = (a - (a.min()+a.max())/2.0)\n        return a",
  "def z(self):\n        if 'z' in self.scan:\n            a = self.scan['z'][()]\n            a = (a - (a.min()+a.max())/2.0)\n            a = a[self._z_roi]\n            if self._rescale:\n                a = (a - (a.min()+a.max())/2.0)\n            return a\n        else:\n            print('There is no z dataset')",
  "def wavelength(self): return self.scan['wavelength'][self._wavelength_roi]",
  "def energy(self): return old_div(1e9*(old_div(h*c,self.wavelength)),e)",
  "def wavelength2(self):\n        if 'wavelength2' in self.scan:\n            return self.scan['wavelength2'][self._wavelength2_roi]\n        else:\n            print('There is no wavelength2 dataset')",
  "def energy2(self):\n        if 'wavelength2' in self.scan:\n            return old_div(1e9*(old_div(h*c,self.wavelength2)),e)\n        else:\n            print('There is no wavelength2 dataset so cannot return energy2')",
  "def spectra(self):\n        ndim = len(self.scan['hs_image'].shape)-1\n        if ndim == 2:\n            roi = np.s_[self._y_roi, self._x_roi, self._wavelength_roi]\n        elif ndim == 3:\n            roi = np.s_[self._z_roi, self._y_roi, self._x_roi, self._wavelength_roi]\n        a = self.scan['hs_image'][roi]\n        a = np.where(np.isfinite(a), a, 0.0)\n        return a",
  "def spectra2(self):\n        if 'wavelength2' in self.scan and 'hs_image2' in self.scan:\n            ndim = len(self.scan['hs_image2'].shape)-1\n            if ndim == 2:\n                roi = np.s_[self._y_roi, self._x_roi, self._wavelength2_roi]\n            elif ndim == 3:\n                roi = np.s_[self._z_roi, self._y_roi, self._x_roi, self._wavelength2_roi]\n            a = self.scan['hs_image2'][roi]\n            a = np.where(np.isfinite(a), a, 0.0)\n            return a\n        else:\n            print('There is no hs_image2 dataset')",
  "def _load_calibrations(self):\n        self.fitfunc = lambda x,a,b,c: a*x**2 + b*x + c\n        self._px1 = (4.30671055e-13, -1.64351619e-10, -1.45004691e-09)\n        self._py1 = (-4.41782891e-13, 8.89024179e-10, -3.43640870e-07)\n        self._px2 = (4.39995226e-13, -1.77391339e-10, 2.86613916e-09)\n        self._py2 = (-4.46213678e-13, 8.94792646e-10, -3.45533004e-07)\n        self._dx1, self._dy1 = self._get_offset(self.wavelength, polarisation=1)\n        self._dx2, self._dy2 = self._get_offset(self.wavelength, polarisation=2)",
  "def apply_corrections(self, a, dataset):\n        name = dataset.name.rsplit('/', 1)[1]\n        if name in ['x', 'y', 'z']:\n            a = (a - (a.min()+a.max())/2.0)\n        elif 'hs_image' in name:\n            a = np.where(np.isfinite(a), a, 0.0)\n        return a",
  "def get_spectra(self, polarisation=1):\n        if polarisation == 2:\n            assert self.attrs['num_spectrometers'] == 2, 'polarisation does not exist'\n        data = self.spectra2 if polarisation == 2 else self.spectra\n        wavelength = self.wavelength2 if polarisation == 2 else self.wavelength\n        return wavelength, data",
  "def get_image(self, wl, polarisation=1, axis=0, axslice=None):\n        \"\"\"Returns an image at a given wavelength (layer slice).\"\"\"\n        wavelength, spectra = self.get_spectra(polarisation)\n        if spectra.ndim == 3:\n            return spectra[:,:, get_nearest(wavelength, wl)]\n        elif spectra.ndim > 3:\n            assert axslice is not None, 'slice argument required for 3d images'\n            return spectra[axslice, :, :, get_nearest(wavelength, wl)]\n        else:\n            return None",
  "def integrate_spectra(self, xlims=None, ylims=None, polarisation=1, axslice=None, return_patch=False):\n        wavelength, spectra = self.get_spectra(polarisation)\n        if spectra.ndim > 3:\n            assert axslice is not None, 'slice argument required for 3d images'\n        if xlims is None:\n            x_roi = np.s_[:]\n        else:\n            x_roi = get_roi(self.x, xlims[0], xlims[1])\n        if ylims is None:\n            y_roi = np.s_[:]\n        else:\n            y_roi = get_roi(self.y, ylims[0], ylims[1])\n        spectra = spectra[axslice, y_roi, x_roi, :] if spectra.ndim > 3 else spectra[y_roi,\n                                                                             x_roi, :]\n        spectrum = np.mean(spectra, axis=(0,1))\n        if return_patch:\n            x, y = (self.x[x_roi], self.y[y_roi])\n            print('averaged over a %dx%d grid' % (len(x), len(y)))\n            patch = np.array([x.min(), y.min(), x.max()-x.min(), y.max()-y.min()])\n            return wavelength, spectrum, patch\n        else:\n            return wavelength, spectrum",
  "def get_line_spectra(self, axis, line, polarisation=1):\n        wavelength, spectra = self.get_spectra(polarisation)\n        if axis=='x': line_spectra = np.array(spectra[:,line,:])\n        elif axis=='y': line_spectra = np.array(spectra[line,:,:])\n        return line_spectra",
  "def reconstruct_colour_image(self, polarisation=1, norm=True, axslice=None):\n        \"\"\"Take a hyperspectral image and convert it to an rgb image.\"\"\"\n        wavelength, spectra = self.get_spectra(polarisation)\n        if spectra.ndim > 3:\n            assert axslice is not None, 'slice argument required for 3d images'\n            spectra = spectra[axslice,:,:,:]\n        img = cr.reconstruct_colour_image(spectra, wavelength, norm)\n        return img",
  "def construct_colour_map(self, polarisation=1, norm=True, axslice=None):\n        \"\"\"Take a hyperspectral image and convert it to an colour map of\n        average wavelength.\"\"\"\n        wavelength, spectra = self.get_spectra(polarisation)\n        if spectra.ndim > 3:\n            assert axslice is not None, 'slice argument required for 3d images'\n            spectra = spectra[axslice,:,:,:]\n        h, w, s = spectra.shape\n        img = np.zeros((h,w))\n        for pos in product(list(range(h)), list(range(w))):\n            i,j = pos\n            spectrum = spectra[i,j,:]\n            threshold = spectrum < 0.01*spectrum.max()\n            spectrum = np.ma.array(spectrum, mask=threshold)\n            wl = np.ma.array(wavelength, mask=threshold)\n            img[i,j] = np.ma.average(wl, axis=-1, weights=spectrum)\n        return img",
  "def create_calibration(self, unit='SI', polarisation=1, wl_step=5, axslice=None):\n        wavelength, spectra = self.get_spectra(polarisation)\n        wavelength = wavelength[::wl_step]\n        if unit=='pixel':\n            x = np.arange(self.x.size)\n            y = np.arange(self.y.size)\n        elif unit=='SI':\n            x = self.x\n            y = self.y\n        # for all wavelengths fit a centroid to create an array of x0s, y0s\n        x0s = np.zeros_like(wavelength)\n        y0s = np.zeros_like(wavelength)\n        for i,wl in enumerate(wavelength):\n            img = self.get_image(wl, polarisation=1, axslice=axslice)\n            x0, y0 = fit_centroid(img, x, y)\n            x0s[i] = x0\n            y0s[i] = y0\n        roi = slice(np.min(np.where(500 < wavelength)), np.max(np.where(wavelength < 1000)))\n        # fit the functions wavelength vs x0, y0 for wl to offset correction\n        self._fit_calibration(wavelength, x0s, 'x%d'%polarisation, mask=roi)\n        self._fit_calibration(wavelength, y0s, 'y%d'%polarisation, mask=roi)\n        return wavelength, x0s, y0s",
  "def _fit_calibration(self, x, y, label, mask=None):\n        '''This is an arbitrary quadratic fit function with no dependencies on\n        the data supplied, i.e. it is indepdent of the units, pixels or SI.'''\n        if mask is not None:\n            x = x[mask]\n            y = y[mask]\n        p, cov = curve_fit(self.fitfunc, x, y)\n        setattr(self, '_p'+label, p)\n        return p, cov",
  "def save_calibration(self):\n        with open('/Users/alansanders/Desktop/calibration.txt', 'w') as f:\n            f.write('p{0:s}: {1}\\n'.format('px1', self.px1))\n            f.write('p{0:s}: {1}\\n'.format('py1', self.py1))\n            f.write('p{0:s}: {1}\\n'.format('px2', self.px2))\n            f.write('p{0:s}: {1}\\n'.format('py2', self.py2))",
  "def load_calibration(self):\n        with open('/Users/alansanders/Desktop/calibration.txt', 'w') as f:\n            lines = [l.strip() for l in f.readlines()]\n            ps = [s.split(': ')[1] for s in lines]\n            self._px1 = (ps[0])\n            self._py1 = (ps[1])\n            self._px2 = (ps[2])\n            self._py2 = (ps[3])",
  "def _get_offset(self, wavelength, polarisation=1, unit='SI'):\n        '''Reference wavelength is 500 nm. The function returns how much\n        an image should be shifted by in the (dx,dy) direction for each\n        wavelength. The units of (dx,dy) can be specified but are based upon\n        the assumption that the calibration was done in SI units for\n        standardisation between different sized grids.'''\n        xr = self.fitfunc(500, *getattr(self, '_px%d'%polarisation))\n        yr = self.fitfunc(500, *getattr(self, '_py%d'%polarisation))\n        #wavelength, data = self.get_data(polarisation)\n        xo = self.fitfunc(wavelength, *getattr(self, '_px%d'%polarisation))\n        yo = self.fitfunc(wavelength, *getattr(self, '_py%d'%polarisation))\n\n        if unit=='SI':\n            dx = xo-xr\n            dy = yo-yr\n            return dx, dy\n        elif unit=='pixel':\n            # now require SI to pixel conversions\n            # find out which pixel is closest to xo, yo\n            dpx = [abs(self.x - i).argmin() for i in xo] - abs(self.x - xr).argmin()\n            dpy = [abs(self.y - i).argmin() for i in yo] - abs(self.y - yr).argmin()\n            return dpx, dpy",
  "def correct_aberrations(self, axslice=None):\n        self._correct_chromatic_aberration(polarisation=1, axslice=axslice)\n        if self.num_spectrometers==2:\n            self._correct_chromatic_aberration(polarisation=2, axslice=axslice)",
  "def _correct_chromatic_aberration(self, polarisation=1, axslice=None):\n        wavelength, spectra = self.get_spectra(polarisation)\n        xo, yo = self._get_offset(wavelength, unit='pixel')\n        s = spectra.shape\n        #print 'starting data shape:', s\n        s11 = old_div(s[0],2)\n        s12 = s11 + s[0]\n        s21 = old_div(s[1],2)\n        s22 = s21 + s[1]\n        # a 1.6 factor is used to go just beyond the physical maximum shift of\n        # 50% of the current view\n        if spectra.ndim > 3:\n            big_img = np.zeros((1.6*s[-4], 1.6*s[-3], s[-2], s[-1]))\n        else:\n            big_img = np.zeros((1.6*s[-3], 1.6*s[-2], s[-1]))\n        big_img[:] = np.nan\n        x_step = self.x[1] - self.x[0]\n        x = x_step * np.arange(big_img.shape[0])\n        x -= x[old_div(x.size,2)]\n        y_step = self.y[1] - self.y[0]\n        y = y_step * np.arange(big_img.shape[1])\n        y -= y[old_div(y.size,2)]\n        for i in range(s[-1]): # for each wavelength (last dimension)\n            dx = int(round(xo[i]))\n            dy = int(round(yo[i]))\n            #print 'shifts:', dx, dy\n            #print 'central region:', s12-s11, s22-s21\n            #print big_img[s11-dx:s12-dx, s21-dy:s22-dy, i].shape, data[:,:,i].shape\n            if spectra.ndim > 3:\n                big_img[s11-dx:s12-dx, s21-dy:s22-dy, :, i] = spectra[:,:,:,i]\n            else:\n                big_img[s11-dx:s12-dx, s21-dy:s22-dy, i] = spectra[:,:,i]\n        data = np.nan_to_num(big_img)\n        # update data - note that this will invalidate the other polarisation data\n        # and that this data is temporary and will be overwritten if ROI changes\n        # are called\n        setattr(self, 'spectra2' if polarisation==2 else 'spectra', spectra)\n        self.x = x\n        self.y = y",
  "class HyperspectralImage(object):\n    '''Applies to both 2D and 3D hyperspectral images, however some methods\n    are limited to specific cases and will raise assertion errors when\n    miscalled.'''\n\n    def __init__(self, file_location,\n                 data_location='hyperspectral scans',\n                 scan_id=None):\n        super(HyperspectralImage, self).__init__()\n        self.f, self.scan = load_data(file_location, data_location, scan_id)\n        self._load_data(self.scan)\n        self._load_calibrations()\n\n    def __del__(self):\n        if self.f is not None:\n            self.f.close()\n\n    def _load_data(self, scan):\n        # ROI data\n        self._rescale = False\n        self._x_lims = (-np.inf, np.inf)\n        self._x_roi = np.s_[:]\n        self._y_lims = (-np.inf, np.inf)\n        self._y_roi = np.s_[:]\n        self._z_lims = (-np.inf, np.inf)\n        self._z_roi = np.s_[:]\n        self._wavelength_lims = (-np.inf, np.inf)\n        self._wavelength_roi = np.s_[:]\n        self._wavelength2_lims = (-np.inf, np.inf)\n        self._wavelength2_roi = np.s_[:]\n        # Other attributes\n        self.attrs = dict(scan.attrs)\n        if 'num_spectrometers' not in self.attrs:\n            self.attrs['num_spectrometers'] = len([s for s in list(scan.keys()) if 'spectra' in s])\n\n    # ROI properties\n    @property\n    def x_lims(self):\n        return self._x_lims\n    @x_lims.setter\n    def x_lims(self, value):\n        assert len(value) == 2, 'Value must have 2 elements'\n        self._x_lims = value\n        a = self.scan['x'][()]\n        a = (a - (a.min()+a.max())/2.0)\n        self._x_roi = get_roi(a, value[0], value[1])\n    @property\n    def y_lims(self):\n        return self._y_lims\n    @y_lims.setter\n    def y_lims(self, value):\n        assert len(value) == 2, 'Value must have 2 elements'\n        self._y_lims = value\n        a = self.scan['y'][()]\n        a = (a - (a.min()+a.max())/2.0)\n        self._y_roi = get_roi(a, value[0], value[1])\n    @property\n    def z_lims(self):\n        return self._z_lims\n    @z_lims.setter\n    def z_lims(self, value):\n        assert len(value) == 2, 'Value must have 2 elements'\n        if 'z' in self.scan:\n            self._z_lims = value\n            a = self.scan['z'][()]\n            a = (a - (a.min()+a.max())/2.0)\n            self._z_roi = get_roi(a, value[0], value[1])\n        else:\n            print('There is no z dataset')\n    @property\n    def wavelength_lims(self):\n        return self._wavelength_lims\n    @wavelength_lims.setter\n    def wavelength_lims(self, value):\n        assert len(value) == 2, 'Value must have 2 elements'\n        self._wavelength_lims = value\n        self._wavelength_roi = get_roi(self.scan['wavelength'][()], value[0], value[1])\n    @property\n    def wavelength2_lims(self):\n        return self._wavelength2_lims\n    @wavelength2_lims.setter\n    def wavelength2_lims(self, value):\n        assert len(value) == 2, 'Value must have 2 elements'\n        if 'wavelength2' in self.scan:\n            self._wavelength2_lims = value\n            self._wavelength2_roi = get_roi(self.scan['wavelength2'][()], value[0], value[1])\n        else:\n            print('There is no wavelength2 dataset')\n    # Axes data properties\n    @property\n    def x(self):\n        a = self.scan['x'][()]\n        a = (a - (a.min()+a.max())/2.0)\n        a = a[self._x_roi]\n        if self._rescale:\n            a = (a - (a.min()+a.max())/2.0)\n        return a\n    @property\n    def y(self):\n        a = self.scan['y'][()]\n        a = (a - (a.min()+a.max())/2.0)\n        a = a[self._y_roi]\n        if self._rescale:\n            a = (a - (a.min()+a.max())/2.0)\n        return a\n    @property\n    def z(self):\n        if 'z' in self.scan:\n            a = self.scan['z'][()]\n            a = (a - (a.min()+a.max())/2.0)\n            a = a[self._z_roi]\n            if self._rescale:\n                a = (a - (a.min()+a.max())/2.0)\n            return a\n        else:\n            print('There is no z dataset')\n    @property\n    def wavelength(self): return self.scan['wavelength'][self._wavelength_roi]\n    @property\n    def energy(self): return old_div(1e9*(old_div(h*c,self.wavelength)),e)\n    @property\n    def wavelength2(self):\n        if 'wavelength2' in self.scan:\n            return self.scan['wavelength2'][self._wavelength2_roi]\n        else:\n            print('There is no wavelength2 dataset')\n    @property\n    def energy2(self):\n        if 'wavelength2' in self.scan:\n            return old_div(1e9*(old_div(h*c,self.wavelength2)),e)\n        else:\n            print('There is no wavelength2 dataset so cannot return energy2')\n    # Data properties\n    @property\n    def spectra(self):\n        ndim = len(self.scan['spectra'].shape)-1\n        if ndim == 2:\n            roi = np.s_[self._x_roi, self._y_roi, self._wavelength_roi]\n        elif ndim == 3:\n            roi = np.s_[self._x_roi, self._y_roi, self._z_roi, self._wavelength_roi]\n        a = self.scan['spectra'][roi]\n        a = np.where(np.isfinite(a), a, 0.0)\n        return a\n    @property\n    def spectra2(self):\n        if 'wavelength2' in self.scan and 'spectra2' in self.scan:\n            ndim = len(self.scan['spectra2'].shape)-1\n            if ndim == 2:\n                roi = np.s_[self._x_roi, self._y_roi, self._wavelength2_roi]\n            elif ndim == 3:\n                roi = np.s_[self._x_roi, self._y_roi, self._z_roi, self._wavelength2_roi]\n            a = self.scan['spectra2'][roi]\n            a = np.where(np.isfinite(a), a, 0.0)\n            return a\n        else:\n            print('There is no spectra2 dataset')\n\n    def _load_calibrations(self):\n        self.fitfunc = lambda x,a,b,c: a*x**2 + b*x + c\n        self._px1 = (4.30671055e-13, -1.64351619e-10, -1.45004691e-09)\n        self._py1 = (-4.41782891e-13, 8.89024179e-10, -3.43640870e-07)\n        self._px2 = (4.39995226e-13, -1.77391339e-10, 2.86613916e-09)\n        self._py2 = (-4.46213678e-13, 8.94792646e-10, -3.45533004e-07)\n        self._dx1, self._dy1 = self._get_offset(self.wavelength, polarisation=1)\n        self._dx2, self._dy2 = self._get_offset(self.wavelength, polarisation=2)\n\n    def apply_corrections(self, a, dataset):\n        name = dataset.name.rsplit('/', 1)[1]\n        if name in ['x', 'y', 'z']:\n            a = (a - (a.min()+a.max())/2.0)\n        elif 'spectra' in name:\n            a = np.where(np.isfinite(a), a, 0.0)\n        return a\n\n    def get_spectra(self, polarisation=1):\n        if polarisation == 2:\n            assert self.attrs['num_spectrometers'] == 2, 'polarisation does not exist'\n        data = self.spectra2 if polarisation == 2 else self.spectra\n        wavelength = self.wavelength2 if polarisation == 2 else self.wavelength\n        return wavelength, data\n\n    def get_image(self, wl, polarisation=1, axis=2, axslice=None):\n        \"\"\"Returns an image at a given wavelength (layer slice).\"\"\"\n        wavelength, spectra = self.get_spectra(polarisation)\n        if spectra.ndim == 3:\n            return spectra[:,:, get_nearest(wavelength, wl)]\n        elif spectra.ndim > 3:\n            assert axslice is not None, 'slice argument required for 3d images'\n            return spectra[:,:, axslice, get_nearest(wavelength, wl)]\n        else:\n            return None\n\n    def integrate_spectra(self, xlims=None, ylims=None, polarisation=1, axslice=None, return_patch=False):\n        wavelength, spectra = self.get_spectra(polarisation)\n        if spectra.ndim > 3:\n            assert axslice is not None, 'slice argument required for 3d images'\n        if xlims is None:\n            x_roi = np.s_[:]\n        else:\n            x_roi = get_roi(self.x, xlims[0], xlims[1])\n        if ylims is None:\n            y_roi = np.s_[:]\n        else:\n            y_roi = get_roi(self.y, ylims[0], ylims[1])\n        spectra = spectra[x_roi,y_roi,axslice,:] if spectra.ndim > 3 else spectra[x_roi,y_roi,:]\n        spectrum = np.mean(spectra, axis=(0,1))\n        if return_patch:\n            x, y = (self.x[x_roi], self.y[y_roi])\n            print('averaged over a %dx%d grid' % (len(x), len(y)))\n            patch = np.array([x.min(), y.min(), x.max()-x.min(), y.max()-y.min()])\n            return wavelength, spectrum, patch\n        else:\n            return wavelength, spectrum\n\n    def get_line_spectra(self, axis, line, polarisation=1):\n        wavelength, spectra = self.get_spectra(polarisation)\n        if axis=='x': line_spectra = np.array(spectra[:,line,:])\n        elif axis=='y': line_spectra = np.array(spectra[line,:,:])\n        return line_spectra\n\n    def reconstruct_colour_image(self, polarisation=1, norm=True, axslice=None):\n        \"\"\"Take a hyperspectral image and convert it to an rgb image.\"\"\"\n        wavelength, spectra = self.get_spectra(polarisation)\n        if spectra.ndim > 3:\n            assert axslice is not None, 'slice argument required for 3d images'\n            spectra = spectra[:,:,axslice,:]\n        img = cr.reconstruct_colour_image(spectra, wavelength, norm)\n        return img\n\n    def construct_colour_map(self, polarisation=1, norm=True, axslice=None):\n        \"\"\"Take a hyperspectral image and convert it to an colour map of\n        average wavelength.\"\"\"\n        wavelength, spectra = self.get_spectra(polarisation)\n        if spectra.ndim > 3:\n            assert axslice is not None, 'slice argument required for 3d images'\n            spectra = spectra[:,:,axslice,:]\n        h, w, s = spectra.shape\n        img = np.zeros((h,w))\n        for pos in product(list(range(h)), list(range(w))):\n            i,j = pos\n            spectrum = spectra[i,j,:]\n            threshold = spectrum < 0.01*spectrum.max()\n            spectrum = np.ma.array(spectrum, mask=threshold)\n            wl = np.ma.array(wavelength, mask=threshold)\n            img[i,j] = np.ma.average(wl, axis=-1, weights=spectrum)\n        return img\n\n    def create_calibration(self, unit='SI', polarisation=1, wl_step=5, axslice=None):\n        wavelength, spectra = self.get_spectra(polarisation)\n        wavelength = wavelength[::wl_step]\n        if unit=='pixel':\n            x = np.arange(self.x.size)\n            y = np.arange(self.y.size)\n        elif unit=='SI':\n            x = self.x\n            y = self.y\n        # for all wavelengths fit a centroid to create an array of x0s, y0s\n        x0s = np.zeros_like(wavelength)\n        y0s = np.zeros_like(wavelength)\n        for i,wl in enumerate(wavelength):\n            img = self.get_image(wl, polarisation=1, axslice=axslice)\n            x0, y0 = fit_centroid(img, x, y)\n            x0s[i] = x0\n            y0s[i] = y0\n        roi = slice(np.min(np.where(500 < wavelength)), np.max(np.where(wavelength < 1000)))\n        # fit the functions wavelength vs x0, y0 for wl to offset correction\n        self._fit_calibration(wavelength, x0s, 'x%d'%polarisation, mask=roi)\n        self._fit_calibration(wavelength, y0s, 'y%d'%polarisation, mask=roi)\n        return wavelength, x0s, y0s\n\n    def _fit_calibration(self, x, y, label, mask=None):\n        '''This is an arbitrary quadratic fit function with no dependencies on\n        the data supplied, i.e. it is indepdent of the units, pixels or SI.'''\n        if mask is not None:\n            x = x[mask]\n            y = y[mask]\n        p, cov = curve_fit(self.fitfunc, x, y)\n        setattr(self, '_p'+label, p)\n        return p, cov\n\n    def save_calibration(self):\n        with open('/Users/alansanders/Desktop/calibration.txt', 'w') as f:\n            f.write('p{0:s}: {1}\\n'.format('px1', self.px1))\n            f.write('p{0:s}: {1}\\n'.format('py1', self.py1))\n            f.write('p{0:s}: {1}\\n'.format('px2', self.px2))\n            f.write('p{0:s}: {1}\\n'.format('py2', self.py2))\n\n    def load_calibration(self):\n        with open('/Users/alansanders/Desktop/calibration.txt', 'w') as f:\n            lines = [l.strip() for l in f.readlines()]\n            ps = [s.split(': ')[1] for s in lines]\n            self._px1 = (ps[0])\n            self._py1 = (ps[1])\n            self._px2 = (ps[2])\n            self._py2 = (ps[3])\n\n    def _get_offset(self, wavelength, polarisation=1, unit='SI'):\n        '''Reference wavelength is 500 nm. The function returns how much\n        an image should be shifted by in the (dx,dy) direction for each\n        wavelength. The units of (dx,dy) can be specified but are based upon\n        the assumption that the calibration was done in SI units for\n        standardisation between different sized grids.'''\n        xr = self.fitfunc(500, *getattr(self, '_px%d'%polarisation))\n        yr = self.fitfunc(500, *getattr(self, '_py%d'%polarisation))\n        #wavelength, data = self.get_data(polarisation)\n        xo = self.fitfunc(wavelength, *getattr(self, '_px%d'%polarisation))\n        yo = self.fitfunc(wavelength, *getattr(self, '_py%d'%polarisation))\n\n        if unit=='SI':\n            dx = xo-xr\n            dy = yo-yr\n            return dx, dy\n        elif unit=='pixel':\n            # now require SI to pixel conversions\n            # find out which pixel is closest to xo, yo\n            dpx = [abs(self.x - i).argmin() for i in xo] - abs(self.x - xr).argmin()\n            dpy = [abs(self.y - i).argmin() for i in yo] - abs(self.y - yr).argmin()\n            return dpx, dpy\n\n    def correct_aberrations(self, axslice=None):\n        self._correct_chromatic_aberration(polarisation=1, axslice=axslice)\n        if self.num_spectrometers==2:\n            self._correct_chromatic_aberration(polarisation=2, axslice=axslice)\n\n    def _correct_chromatic_aberration(self, polarisation=1, axslice=None):\n        wavelength, spectra = self.get_spectra(polarisation)\n        xo, yo = self._get_offset(wavelength, unit='pixel')\n        s = spectra.shape\n        #print 'starting data shape:', s\n        s11 = old_div(s[0],2)\n        s12 = s11 + s[0]\n        s21 = old_div(s[1],2)\n        s22 = s21 + s[1]\n        # a 1.6 factor is used to go just beyond the physical maximum shift of\n        # 50% of the current view\n        if spectra.ndim > 3:\n            big_img = np.zeros((1.6*s[-4], 1.6*s[-3], s[-2], s[-1]))\n        else:\n            big_img = np.zeros((1.6*s[-3], 1.6*s[-2], s[-1]))\n        big_img[:] = np.nan\n        x_step = self.x[1] - self.x[0]\n        x = x_step * np.arange(big_img.shape[0])\n        x -= x[old_div(x.size,2)]\n        y_step = self.y[1] - self.y[0]\n        y = y_step * np.arange(big_img.shape[1])\n        y -= y[old_div(y.size,2)]\n        for i in range(s[-1]): # for each wavelength (last dimension)\n            dx = int(round(xo[i]))\n            dy = int(round(yo[i]))\n            #print 'shifts:', dx, dy\n            #print 'central region:', s12-s11, s22-s21\n            #print big_img[s11-dx:s12-dx, s21-dy:s22-dy, i].shape, data[:,:,i].shape\n            if spectra.ndim > 3:\n                big_img[s11-dx:s12-dx, s21-dy:s22-dy, :, i] = spectra[:,:,:,i]\n            else:\n                big_img[s11-dx:s12-dx, s21-dy:s22-dy, i] = spectra[:,:,i]\n        data = np.nan_to_num(big_img)\n        # update data - note that this will invalidate the other polarisation data\n        # and that this data is temporary and will be overwritten if ROI changes\n        # are called\n        setattr(self, 'spectra2' if polarisation==2 else 'spectra', spectra)\n        self.x = x\n        self.y = y",
  "def __init__(self, file_location,\n                 data_location='hyperspectral scans',\n                 scan_id=None):\n        super(HyperspectralImage, self).__init__()\n        self.f, self.scan = load_data(file_location, data_location, scan_id)\n        self._load_data(self.scan)\n        self._load_calibrations()",
  "def __del__(self):\n        if self.f is not None:\n            self.f.close()",
  "def _load_data(self, scan):\n        # ROI data\n        self._rescale = False\n        self._x_lims = (-np.inf, np.inf)\n        self._x_roi = np.s_[:]\n        self._y_lims = (-np.inf, np.inf)\n        self._y_roi = np.s_[:]\n        self._z_lims = (-np.inf, np.inf)\n        self._z_roi = np.s_[:]\n        self._wavelength_lims = (-np.inf, np.inf)\n        self._wavelength_roi = np.s_[:]\n        self._wavelength2_lims = (-np.inf, np.inf)\n        self._wavelength2_roi = np.s_[:]\n        # Other attributes\n        self.attrs = dict(scan.attrs)\n        if 'num_spectrometers' not in self.attrs:\n            self.attrs['num_spectrometers'] = len([s for s in list(scan.keys()) if 'spectra' in s])",
  "def x_lims(self):\n        return self._x_lims",
  "def x_lims(self, value):\n        assert len(value) == 2, 'Value must have 2 elements'\n        self._x_lims = value\n        a = self.scan['x'][()]\n        a = (a - (a.min()+a.max())/2.0)\n        self._x_roi = get_roi(a, value[0], value[1])",
  "def y_lims(self):\n        return self._y_lims",
  "def y_lims(self, value):\n        assert len(value) == 2, 'Value must have 2 elements'\n        self._y_lims = value\n        a = self.scan['y'][()]\n        a = (a - (a.min()+a.max())/2.0)\n        self._y_roi = get_roi(a, value[0], value[1])",
  "def z_lims(self):\n        return self._z_lims",
  "def z_lims(self, value):\n        assert len(value) == 2, 'Value must have 2 elements'\n        if 'z' in self.scan:\n            self._z_lims = value\n            a = self.scan['z'][()]\n            a = (a - (a.min()+a.max())/2.0)\n            self._z_roi = get_roi(a, value[0], value[1])\n        else:\n            print('There is no z dataset')",
  "def wavelength_lims(self):\n        return self._wavelength_lims",
  "def wavelength_lims(self, value):\n        assert len(value) == 2, 'Value must have 2 elements'\n        self._wavelength_lims = value\n        self._wavelength_roi = get_roi(self.scan['wavelength'][()], value[0], value[1])",
  "def wavelength2_lims(self):\n        return self._wavelength2_lims",
  "def wavelength2_lims(self, value):\n        assert len(value) == 2, 'Value must have 2 elements'\n        if 'wavelength2' in self.scan:\n            self._wavelength2_lims = value\n            self._wavelength2_roi = get_roi(self.scan['wavelength2'][()], value[0], value[1])\n        else:\n            print('There is no wavelength2 dataset')",
  "def x(self):\n        a = self.scan['x'][()]\n        a = (a - (a.min()+a.max())/2.0)\n        a = a[self._x_roi]\n        if self._rescale:\n            a = (a - (a.min()+a.max())/2.0)\n        return a",
  "def y(self):\n        a = self.scan['y'][()]\n        a = (a - (a.min()+a.max())/2.0)\n        a = a[self._y_roi]\n        if self._rescale:\n            a = (a - (a.min()+a.max())/2.0)\n        return a",
  "def z(self):\n        if 'z' in self.scan:\n            a = self.scan['z'][()]\n            a = (a - (a.min()+a.max())/2.0)\n            a = a[self._z_roi]\n            if self._rescale:\n                a = (a - (a.min()+a.max())/2.0)\n            return a\n        else:\n            print('There is no z dataset')",
  "def wavelength(self): return self.scan['wavelength'][self._wavelength_roi]",
  "def energy(self): return old_div(1e9*(old_div(h*c,self.wavelength)),e)",
  "def wavelength2(self):\n        if 'wavelength2' in self.scan:\n            return self.scan['wavelength2'][self._wavelength2_roi]\n        else:\n            print('There is no wavelength2 dataset')",
  "def energy2(self):\n        if 'wavelength2' in self.scan:\n            return old_div(1e9*(old_div(h*c,self.wavelength2)),e)\n        else:\n            print('There is no wavelength2 dataset so cannot return energy2')",
  "def spectra(self):\n        ndim = len(self.scan['spectra'].shape)-1\n        if ndim == 2:\n            roi = np.s_[self._x_roi, self._y_roi, self._wavelength_roi]\n        elif ndim == 3:\n            roi = np.s_[self._x_roi, self._y_roi, self._z_roi, self._wavelength_roi]\n        a = self.scan['spectra'][roi]\n        a = np.where(np.isfinite(a), a, 0.0)\n        return a",
  "def spectra2(self):\n        if 'wavelength2' in self.scan and 'spectra2' in self.scan:\n            ndim = len(self.scan['spectra2'].shape)-1\n            if ndim == 2:\n                roi = np.s_[self._x_roi, self._y_roi, self._wavelength2_roi]\n            elif ndim == 3:\n                roi = np.s_[self._x_roi, self._y_roi, self._z_roi, self._wavelength2_roi]\n            a = self.scan['spectra2'][roi]\n            a = np.where(np.isfinite(a), a, 0.0)\n            return a\n        else:\n            print('There is no spectra2 dataset')",
  "def _load_calibrations(self):\n        self.fitfunc = lambda x,a,b,c: a*x**2 + b*x + c\n        self._px1 = (4.30671055e-13, -1.64351619e-10, -1.45004691e-09)\n        self._py1 = (-4.41782891e-13, 8.89024179e-10, -3.43640870e-07)\n        self._px2 = (4.39995226e-13, -1.77391339e-10, 2.86613916e-09)\n        self._py2 = (-4.46213678e-13, 8.94792646e-10, -3.45533004e-07)\n        self._dx1, self._dy1 = self._get_offset(self.wavelength, polarisation=1)\n        self._dx2, self._dy2 = self._get_offset(self.wavelength, polarisation=2)",
  "def apply_corrections(self, a, dataset):\n        name = dataset.name.rsplit('/', 1)[1]\n        if name in ['x', 'y', 'z']:\n            a = (a - (a.min()+a.max())/2.0)\n        elif 'spectra' in name:\n            a = np.where(np.isfinite(a), a, 0.0)\n        return a",
  "def get_spectra(self, polarisation=1):\n        if polarisation == 2:\n            assert self.attrs['num_spectrometers'] == 2, 'polarisation does not exist'\n        data = self.spectra2 if polarisation == 2 else self.spectra\n        wavelength = self.wavelength2 if polarisation == 2 else self.wavelength\n        return wavelength, data",
  "def get_image(self, wl, polarisation=1, axis=2, axslice=None):\n        \"\"\"Returns an image at a given wavelength (layer slice).\"\"\"\n        wavelength, spectra = self.get_spectra(polarisation)\n        if spectra.ndim == 3:\n            return spectra[:,:, get_nearest(wavelength, wl)]\n        elif spectra.ndim > 3:\n            assert axslice is not None, 'slice argument required for 3d images'\n            return spectra[:,:, axslice, get_nearest(wavelength, wl)]\n        else:\n            return None",
  "def integrate_spectra(self, xlims=None, ylims=None, polarisation=1, axslice=None, return_patch=False):\n        wavelength, spectra = self.get_spectra(polarisation)\n        if spectra.ndim > 3:\n            assert axslice is not None, 'slice argument required for 3d images'\n        if xlims is None:\n            x_roi = np.s_[:]\n        else:\n            x_roi = get_roi(self.x, xlims[0], xlims[1])\n        if ylims is None:\n            y_roi = np.s_[:]\n        else:\n            y_roi = get_roi(self.y, ylims[0], ylims[1])\n        spectra = spectra[x_roi,y_roi,axslice,:] if spectra.ndim > 3 else spectra[x_roi,y_roi,:]\n        spectrum = np.mean(spectra, axis=(0,1))\n        if return_patch:\n            x, y = (self.x[x_roi], self.y[y_roi])\n            print('averaged over a %dx%d grid' % (len(x), len(y)))\n            patch = np.array([x.min(), y.min(), x.max()-x.min(), y.max()-y.min()])\n            return wavelength, spectrum, patch\n        else:\n            return wavelength, spectrum",
  "def get_line_spectra(self, axis, line, polarisation=1):\n        wavelength, spectra = self.get_spectra(polarisation)\n        if axis=='x': line_spectra = np.array(spectra[:,line,:])\n        elif axis=='y': line_spectra = np.array(spectra[line,:,:])\n        return line_spectra",
  "def reconstruct_colour_image(self, polarisation=1, norm=True, axslice=None):\n        \"\"\"Take a hyperspectral image and convert it to an rgb image.\"\"\"\n        wavelength, spectra = self.get_spectra(polarisation)\n        if spectra.ndim > 3:\n            assert axslice is not None, 'slice argument required for 3d images'\n            spectra = spectra[:,:,axslice,:]\n        img = cr.reconstruct_colour_image(spectra, wavelength, norm)\n        return img",
  "def construct_colour_map(self, polarisation=1, norm=True, axslice=None):\n        \"\"\"Take a hyperspectral image and convert it to an colour map of\n        average wavelength.\"\"\"\n        wavelength, spectra = self.get_spectra(polarisation)\n        if spectra.ndim > 3:\n            assert axslice is not None, 'slice argument required for 3d images'\n            spectra = spectra[:,:,axslice,:]\n        h, w, s = spectra.shape\n        img = np.zeros((h,w))\n        for pos in product(list(range(h)), list(range(w))):\n            i,j = pos\n            spectrum = spectra[i,j,:]\n            threshold = spectrum < 0.01*spectrum.max()\n            spectrum = np.ma.array(spectrum, mask=threshold)\n            wl = np.ma.array(wavelength, mask=threshold)\n            img[i,j] = np.ma.average(wl, axis=-1, weights=spectrum)\n        return img",
  "def create_calibration(self, unit='SI', polarisation=1, wl_step=5, axslice=None):\n        wavelength, spectra = self.get_spectra(polarisation)\n        wavelength = wavelength[::wl_step]\n        if unit=='pixel':\n            x = np.arange(self.x.size)\n            y = np.arange(self.y.size)\n        elif unit=='SI':\n            x = self.x\n            y = self.y\n        # for all wavelengths fit a centroid to create an array of x0s, y0s\n        x0s = np.zeros_like(wavelength)\n        y0s = np.zeros_like(wavelength)\n        for i,wl in enumerate(wavelength):\n            img = self.get_image(wl, polarisation=1, axslice=axslice)\n            x0, y0 = fit_centroid(img, x, y)\n            x0s[i] = x0\n            y0s[i] = y0\n        roi = slice(np.min(np.where(500 < wavelength)), np.max(np.where(wavelength < 1000)))\n        # fit the functions wavelength vs x0, y0 for wl to offset correction\n        self._fit_calibration(wavelength, x0s, 'x%d'%polarisation, mask=roi)\n        self._fit_calibration(wavelength, y0s, 'y%d'%polarisation, mask=roi)\n        return wavelength, x0s, y0s",
  "def _fit_calibration(self, x, y, label, mask=None):\n        '''This is an arbitrary quadratic fit function with no dependencies on\n        the data supplied, i.e. it is indepdent of the units, pixels or SI.'''\n        if mask is not None:\n            x = x[mask]\n            y = y[mask]\n        p, cov = curve_fit(self.fitfunc, x, y)\n        setattr(self, '_p'+label, p)\n        return p, cov",
  "def save_calibration(self):\n        with open('/Users/alansanders/Desktop/calibration.txt', 'w') as f:\n            f.write('p{0:s}: {1}\\n'.format('px1', self.px1))\n            f.write('p{0:s}: {1}\\n'.format('py1', self.py1))\n            f.write('p{0:s}: {1}\\n'.format('px2', self.px2))\n            f.write('p{0:s}: {1}\\n'.format('py2', self.py2))",
  "def load_calibration(self):\n        with open('/Users/alansanders/Desktop/calibration.txt', 'w') as f:\n            lines = [l.strip() for l in f.readlines()]\n            ps = [s.split(': ')[1] for s in lines]\n            self._px1 = (ps[0])\n            self._py1 = (ps[1])\n            self._px2 = (ps[2])\n            self._py2 = (ps[3])",
  "def _get_offset(self, wavelength, polarisation=1, unit='SI'):\n        '''Reference wavelength is 500 nm. The function returns how much\n        an image should be shifted by in the (dx,dy) direction for each\n        wavelength. The units of (dx,dy) can be specified but are based upon\n        the assumption that the calibration was done in SI units for\n        standardisation between different sized grids.'''\n        xr = self.fitfunc(500, *getattr(self, '_px%d'%polarisation))\n        yr = self.fitfunc(500, *getattr(self, '_py%d'%polarisation))\n        #wavelength, data = self.get_data(polarisation)\n        xo = self.fitfunc(wavelength, *getattr(self, '_px%d'%polarisation))\n        yo = self.fitfunc(wavelength, *getattr(self, '_py%d'%polarisation))\n\n        if unit=='SI':\n            dx = xo-xr\n            dy = yo-yr\n            return dx, dy\n        elif unit=='pixel':\n            # now require SI to pixel conversions\n            # find out which pixel is closest to xo, yo\n            dpx = [abs(self.x - i).argmin() for i in xo] - abs(self.x - xr).argmin()\n            dpy = [abs(self.y - i).argmin() for i in yo] - abs(self.y - yr).argmin()\n            return dpx, dpy",
  "def correct_aberrations(self, axslice=None):\n        self._correct_chromatic_aberration(polarisation=1, axslice=axslice)\n        if self.num_spectrometers==2:\n            self._correct_chromatic_aberration(polarisation=2, axslice=axslice)",
  "def _correct_chromatic_aberration(self, polarisation=1, axslice=None):\n        wavelength, spectra = self.get_spectra(polarisation)\n        xo, yo = self._get_offset(wavelength, unit='pixel')\n        s = spectra.shape\n        #print 'starting data shape:', s\n        s11 = old_div(s[0],2)\n        s12 = s11 + s[0]\n        s21 = old_div(s[1],2)\n        s22 = s21 + s[1]\n        # a 1.6 factor is used to go just beyond the physical maximum shift of\n        # 50% of the current view\n        if spectra.ndim > 3:\n            big_img = np.zeros((1.6*s[-4], 1.6*s[-3], s[-2], s[-1]))\n        else:\n            big_img = np.zeros((1.6*s[-3], 1.6*s[-2], s[-1]))\n        big_img[:] = np.nan\n        x_step = self.x[1] - self.x[0]\n        x = x_step * np.arange(big_img.shape[0])\n        x -= x[old_div(x.size,2)]\n        y_step = self.y[1] - self.y[0]\n        y = y_step * np.arange(big_img.shape[1])\n        y -= y[old_div(y.size,2)]\n        for i in range(s[-1]): # for each wavelength (last dimension)\n            dx = int(round(xo[i]))\n            dy = int(round(yo[i]))\n            #print 'shifts:', dx, dy\n            #print 'central region:', s12-s11, s22-s21\n            #print big_img[s11-dx:s12-dx, s21-dy:s22-dy, i].shape, data[:,:,i].shape\n            if spectra.ndim > 3:\n                big_img[s11-dx:s12-dx, s21-dy:s22-dy, :, i] = spectra[:,:,:,i]\n            else:\n                big_img[s11-dx:s12-dx, s21-dy:s22-dy, i] = spectra[:,:,i]\n        data = np.nan_to_num(big_img)\n        # update data - note that this will invalidate the other polarisation data\n        # and that this data is temporary and will be overwritten if ROI changes\n        # are called\n        setattr(self, 'spectra2' if polarisation==2 else 'spectra', spectra)\n        self.x = x\n        self.y = y",
  "def least_squares(xs,ys):\n\txs_augmented = np.transpose([xs,np.ones(len(xs))])\n\tm,_,_,_ = np.linalg.lstsq(xs_augmented,ys)\n\treturn m",
  "def single_position_fit(spectra,calibration_wavelengths,center_wavelength = None,debug =0):\n\t'''\n\tspectra: spectra taken at same position (center wavelength) but with different incident laser wavelengths\n\tcalibration_wavelengths - the wavelengths of the laser\n\t'''\n\t\n\txs = peak_positions = [np.argmax(s) for s in spectra]\n\tys = calibration_wavelengths\n\n\t#assuming that this is linear in the give pixel range\n\t[gradient, offset] = least_squares(xs,ys)\n\tif debug > 0:\n\t\tfig, ax = plt.subplots(1)\n\t\tax.plot(xs,ys,'x',label=\"data\")\n\t\tax.plot(xs,gradient*np.array(xs) + offset,label=\"linear fit\")\n\t\tax.set_xlabel(\"Pixel index\")\n\t\tax.set_ylabel(\"Wavelength [nm]\")\n\t\tax.set_title(\"Pixel position vs Wavelength\\n Center wavelength: {0}\".format(center_wavelength))\n\n\t\tplt.show()\n\treturn gradient, offset",
  "def scan_fit(dataset,debug = 0):\n\n\tcenter_wls = []\n\toffsets = []\n\tgradients = []\n\n\tif debug > 0:\n\t\tprint(\"-=\"*10)\n\t\tprint(\"scan_fit dataset debug\")\n\t\tprint(\"-=\"*10)\n\t\tfor d in dataset:\n\t\t\tprint(d)\n\tfor (center_wavelength,spectra,calibration_wavelengths) in dataset:\n\n\t\tif len(spectra) > 1:\n\n\t\t\tprint(center_wavelength,len(spectra),len(calibration_wavelengths))\n\t\t\tgradient, offset = single_position_fit(spectra,calibration_wavelengths,debug=debug,center_wavelength=center_wavelength)\n\n\t\t\tcenter_wls = center_wls + [center_wavelength]\n\t\t\toffsets = offsets + [offset]\n\t\t\tgradients = gradients + [gradient]\n\n\tif debug > 0:\n\t\tprint(\"len(offsets)\", len(offsets))\n\t\tprint(\"len(gradients)\", len(gradients))\n\t\tfig, [ax1,ax2] = plt.subplots(2)\n\t\tax1.plot(center_wls,offsets,'x-')\n\t\tax1.set_title(\"scan_fit: center wavelength vs wavelength offset (=$\\lambda$ at pixel_index=0)\")\n\t\tax2.plot(center_wls,gradients,'x-')\n\t\tax1.set_xlabel(\"Center wavelength [nm]\")\n\t\tax1.set_ylabel(\"Pixel 0 wavelength (offset) [nm]\")\n\t\tax2.set_title(\"scan_fit: center wavelength vs wavelength gradient (for determining wavelength for pixel_index > 0)\")\n\t\tax2.set_xlabel(\"Center wavelength [nm]\")\n\t\tax2.set_ylabel(\"Wavelength increment (gradient) [nm/pixel]\")\n\t\t\n\t\tplt.show()\n\n\tprint(\"center_wls:\",np.max(center_wls),np.min(center_wls))\n\tdef mapper(cw,pixel_index):\n\t\twavelength_offset = interp1d(center_wls,offsets,kind='linear')\n\t\twavelength_gradient = interp1d(center_wls,gradients,kind='linear')\n\n\t\treturn wavelength_offset(cw) + wavelength_gradient(cw)*pixel_index\n\n\treturn mapper",
  "def test(debug):\n\tif debug:\n\t\tprint(\"---TESTING---\")\n\n\tpixels = np.arange(0,1014)\n\tdef make_test_spectrum(mu,sigma=30.0):\n\t\treturn np.exp(-(pixels-mu)**2/float(2*sigma**2))\n\t\n\tcenter_wavelengths=700\n\tcalibration_wavelengths=[704,726,744]\n\tcenters = [300,600,800]\n\tspectra = [make_test_spectrum(p) for p in centers]\n\tdset0 = [center_wavelengths,spectra,calibration_wavelengths]\n\n\tcenter_wavelengths=740\n\tcalibration_wavelengths=[744,766,784]\n\tcenters = [200,500,900]\n\tspectra = [make_test_spectrum(p) for p in centers]\n\tdset1 = [center_wavelengths,spectra,calibration_wavelengths]\n\n\n\tfig, ax = plt.subplots(1)\n\tfor s in spectra:\n\t\tplt.plot(pixels,s)\n\tplt.show()\n\n\tdataset = [dset0,dset1]\n\tscan_fit(dataset,debug=1)",
  "def main(filepath,debug=0):\n\tf =df.DataFile(filepath,\"r\")\n\tg = f[\"calibration\"]\n\tkeys = list(g.keys())\n\n\tcenter_wavelengths = []\n\tfor k in keys:\n\t\tcenter_wavelengths = center_wavelengths + [g[k].attrs[\"center_wavelength\"]]\n\t\t\n\tcenter_wavelengths = sorted(np.unique(center_wavelengths))\n\tprint(\"main:max center wavelength:\",np.max(center_wavelengths))\n\n\tdataset = []\n\tfor cw in center_wavelengths:\n\n\t\tentry = (cw,[],[])\n\t\tfor k in keys:\n\t\t\tif g[k].attrs[\"center_wavelength\"] == cw:\n\t\t\t\tentry[2].append(g[k].attrs[\"laser_wavelength\"])\n\t\t\t\tentry[1].append(np.array(g[k]))\n\t\tdataset.append(entry)\n\n\t# print \"-=\"*10\n\t# for d in dataset:\n\t# \tprint d\n\t# print \"-=\"*10\n\tmapper = scan_fit(dataset,debug=debug)\n\n\treturn mapper",
  "def grating_1200gmm(debug=0):\n\treturn main(DIRPATH+\"\\\\\"+\"ir_calibration_1200gmm.hdf5\",debug=debug)",
  "def grating_300gmm(debug=0):\n\treturn main(DIRPATH+\"\\\\\"+\"ir_calibration_300gmm.hdf5\",debug=debug)",
  "def mapper_tester_300gmm(mapper):\n\n\tcenter_wavelengths = np.linspace(760,910,10)\n\tpixels = np.arange(0,1014,1)\n\t# print pixels\n\t# print mapper\n\t# print center_wavelengths\n\tfor cw in center_wavelengths:\n\t\tprint(\"cW:\",cw)\n\t\twls = [mapper(cw,p) for p in pixels]\n\t\tplt.plot(pixels,wls,label=\"center wavelength:{}\".format(cw))\n\tplt.xlabel(\"Pixel index\")\n\tplt.ylabel(\"Wavelength [nm]\")\n\tplt.legend()\n\tplt.show()",
  "def mapper_tester_1200gmm(mapper):\n\n\tcenter_wavelengths = np.linspace(750,885,10)\n\tpixels = np.arange(0,1014,1)\n\t# print pixels\n\t# print mapper\n\t# print center_wavelengths\n\tfor cw in center_wavelengths:\n\t\tprint(cw)\n\t\twls = []\n\t\tfor p in pixels:\n\t\t\t# print cw,p\n\t\t\twls.append(mapper(cw,p))\n\t\t# wls = [mapper(cw,p) for p in pixels]\n\t\tplt.plot(pixels,wls,label=\"center wavelength:{}\".format(cw))\n\tplt.xlabel(\"Pixel index\")\n\tplt.ylabel(\"Wavelength [nm]\")\n\tplt.legend()\n\tplt.show()",
  "def mapper(cw,pixel_index):\n\t\twavelength_offset = interp1d(center_wls,offsets,kind='linear')\n\t\twavelength_gradient = interp1d(center_wls,gradients,kind='linear')\n\n\t\treturn wavelength_offset(cw) + wavelength_gradient(cw)*pixel_index",
  "def make_test_spectrum(mu,sigma=30.0):\n\t\treturn np.exp(-(pixels-mu)**2/float(2*sigma**2))",
  "def spectrum_pixel_offset(spectrum_1,spectrum_2):\n\tsp1 = spectrum_1\n\tsp2 = spectrum_2\n\n\tsp1 = sp1 - np.mean(sp1)\n\tsp2 = sp2 - np.mean(sp2)\n\n\t#compute cross correlation to match\n\txcs = np.correlate(sp1,sp2,mode=\"same\")\n\t#perform fftshift to center zero offset on 0th position\n\txcs = np.fft.fftshift(xcs)\n\n\t#return peak position of xcs\n\treturn np.argmax(xcs),np.array(xcs)",
  "def pixel_wavelength_conversion(pixel_offset,wavelength_offset):\n\treturn wavelength_offset/float(pixel_offset)",
  "class Pacton(Instrument):\n\n\tdef __init__(self,pixis,acton,boundary_cut=5,debug =0):\n\n\t\tself.debug = debug\n\t\tself.pixis = pixis\n\t\tself.acton = acton \n\n\t\t#####\n\t\t# Wavelength bounds\n\t\t#####\n\t\tself.min_wavelength = 0.000 #[nm]\n\t\tself.max_wavelength = 1200.000 #[nm]\n\t\t\n\t\tself.boundary_cut = boundary_cut\n\n\n\t\t#Used to background subtract when stitching together spectra\n\t\t#To initialize run: get_pixel_response_calibration_spectrum\n\t\tself.pixel_response = None\n\t\tself.raw_pixel_response = None\n\n\t\t#conversion factor from pixels to nm [units: nm/pixel]\n\t\t#default obtained from calibration\n\t\tself.pixel_to_wl_sf = 0.0289082 \n\n\tdef get_image(self,center_wavelength,roi = None,debug=0):\n\t\tself.acton.set_wavelength(center_wavelength,blocking=True,debug=debug)\n\t\tif roi is not None:\n\n\t\t\tif debug>0: print(\"starting try-catch\")\n\t\t\ttry:\n\t\t\t\t[x_min,x_max,y_min,y_max] = roi\n\t\t\t\tif debug > 0:\n\t\t\t\t\tprint(\"Pacton.get_image: region of interest:\", roi)\n\t\t\t\treturn self.pixis.get_roi(x_min=x_min, x_max = x_max, y_min=y_min,y_max = y_max,debug=debug)\n\n\t\t\texcept: \n\t\t\t\traise ValueError(\"Unable to unpack region of interest\")\n\t\telse:\n\t\t\treturn self.pixis.get_roi()\n\t\t\n\tdef pixel_to_wavelength(self,pixels,center_wavelength, intensity):\n\t\tcenter_pixel = np.round(self.pixis.x_max)/2.0\n\t\tif self.pixel_to_wl_sf is None:\n\t\t\traise ValueError(\"No conversion factor set, please run Pacton.calibrate routine\")\n\t\telse:\n\t\t\t#intensity - the counts on each pixel\n\t\t\twavelengths = center_wavelength + self.pixel_to_wl_sf*np.array(pixels)\n\t\t\tmin_wl = np.min(wavelengths)\n\t\t\tmax_wl = np.max(wavelengths)\n\n\t\t\tindices = np.logical_and(CALIBRATION_WAVELENGTHS >= min_wl,CALIBRATION_WAVELENGTHS < max_wl)\n\n\t\t\tcalibration_intensity = CALIBRATION_COUNTS[indices]\n\t\t\tcalibration_wavelengths =CALIBRATION_WAVELENGTHS[indices]\n\n\t\t\tcalibration_intensity = calibration_intensity - np.min(calibration_intensity)\n\t\t\tcalibration_intensity = old_div(calibration_intensity,np.max(calibration_intensity))\n\n\t\t\tintensity = intensity - np.min(intensity)\n\t\t\tintensity = old_div(intensity,np.max(intensity))\n\n\t\t\tupsampled_calibration_intensity = scipy.signal.resample(calibration_intensity, len(wavelengths), t=None, axis=0, window=None)\n\t\t\tupsampled_calibration_wavelengths= scipy.signal.resample(calibration_wavelengths, len(wavelengths), t=None, axis=0, window=None)\n\n\n\n\t\t\tmax_xcs, xcs = spectrum_pixel_offset(upsampled_calibration_intensity,intensity)\n\t\t\txcs = np.fft.fftshift(xcs)\n\t\t\tmax_xcs = np.argmax(xcs)\n\t\t\toffset = max_xcs - old_div(len(wavelengths),2)\n\t\t\t# if self.debug > 0:\n\t\t\t# \tprint \"Calibration wavelength range:\", np.min(upsampled_calibration_wavelengths),np.max(upsampled_calibration_wavelengths)\n\t\t\t# \tprint \"Measured wavelength range:\", np.min(wavelengths),np.max(wavelengths)\n\t\t\t\t\n\t\t\t# \tprint \"Calibration curve length:\", len(calibration_intensity)\n\t\t\t# \tprint \"Measurement curve length:\", len(intensity)\n\t\t\t# \tprint \"Upsampled calibration curve length:\", len(upsampled_calibration_intensity)\n\t\t\t# \tprint \"Offset:\", offset\n\t\t\t# \timport matplotlib.pyplot as plt \n\n\t\t\t# \tfig,[ax1,ax2] = plt.subplots(2,figsize=(3*2*4,3*3))\n\t\t\t# \tax1.plot(wavelengths,intensity,label=\"intensity\")\n\t\t\t# \tax1.plot(calibration_wavelengths,calibration_intensity,label=\"upsampled calibration_intensity\")\n\t\t\t# \tshifted_wavelengths = center_wavelength + self.pixel_to_wl_sf*(np.array(pixels)+offset)\n\t\t\t# \tax1.plot(shifted_wavelengths,intensity,label=\"shifted intensity\")\n\t\t\t\t\n\t\t\t# \tax2.plot(xcs)\n\t\t\t# \tax1.legend()\n\t\t\t# \tplt.show()\n\t\t\twavelengths = center_wavelength + self.pixel_to_wl_sf*(np.array(pixels)+offset)\n\t\t\t\n\n\n\t\treturn wavelengths\n\n\tdef get_pixel_response_calibration_spectrum(self,debug=0):\n\t\t'''\n\t\tScan over spectrum in the region where you don't expect to see anyting (ie. UV)\n\t\tTake spectra at each position and average. This then gives you the pixel response (strange I know).\n\t\tSmooth the average using cvx and use this in furthre processing for background subtraction on the LHS\n\t\tto make it easier to stitch together spectra\n\t\t'''\n\t\twavelengths = list(range(50,80,10))\n\t\tspectra = []\n\t\tfor wl in wavelengths:\n\t\t\tself.acton.set_wavelength(wl,blocking=True,fast=True,debug=debug)\n\t\t\tspectrum,_= self.pixis.get_spectrum()\n\t\t\tspectra.append(spectrum)\n\n\t\tspectra = np.array(spectra)\n\t\tcalibration_spectrum = np.mean(spectra,axis=0)\n\t\t#subtract minimum value to remove edge effects\n\t\tys = np.array(calibration_spectrum)\n\t\t\n\t\tymin = np.min(ys)\n\t\tys = ys - ymin\n\t\t#smooth to get less fluctuations in background\n\t\tsmoothed,_,_ = convex_smooth(ys,2)\n\t\tsmoothed = np.array(smoothed) + ymin\n\t\t#replace first 3 pixel values with \n\t\tsmoothed[0:3] = np.mean(calibration_spectrum[0:3])\n\t\t\n\t\tself.pixel_response = smoothed\n\t\tself.raw_pixel_response = calibration_spectrum\n\t\treturn smoothed, calibration_spectrum\n\n\tdef get_spectrum(self,center_wavelength,subtract_background=True, roi = None,debug=0):\n\n\t\tself.acton.set_wavelength(center_wavelength,blocking=True,debug=debug)\n\t\tif subtract_background == True and self.pixel_response is None:\n\t\t\traise ValueError(\"Error getting spectrum with background subtraction - no background to subtract, please run: Pacton.get_pixel_response_calibration_spectrum \") \n\t\tif roi is not None:\n\t\t\ttry:\n\t\t\t\t[x_min,x_max,y_min,y_max] = roi\n\t\t\t\tspectrum,pixel_offsets = self.pixis.get_spectrum(x_min=x_min, x_max = x_max, y_min=y_min,y_max = y_max)\n\n\t\t\texcept: \n\t\t\t\traise ValueError(\"Unable to unpack region of interest\")\n\t\telse:\n\t\t\tspectrum,pixel_offsets = self.pixis.get_spectrum()\n\t\t\n\t\tif subtract_background == True:\n\t\t\tspectrum = np.array(spectrum) - self.pixel_response\n\t\twavelengths = self.pixel_to_wavelength(pixel_offsets,center_wavelength,spectrum)\n\t\treturn spectrum,wavelengths\n\n\t\n\tdef calibrate(self,wavelengths,with_background_subtraction= False,plot=False,debug = 0):\n\t\tif with_background_subtraction == True:\n\t\t\tsmoothed,_ = self.get_pixel_response_calibration_spectrum()\n\n\t\tif plot == True:\n\t\t\tfig, axarr = plt.subplots(2,figsize=(8,16))\n\t\t\n\t\t#grab calibration spectra\n\t\tspectra = []\n\t\tfor wl in wavelengths:\n\t\t\tself.acton.set_wavelength(wl,fast=True,debug=debug)  \n\t\t\tsp = np.array(self.pixis.get_spectrum()[0])\n\t\t\tif with_background_subtraction == True:\n\n\t\t\t\tsp_bgsub = sp - smoothed\n\t\t\telse:\n\t\t\t\tsp_bgsub = sp\n\t\t\tspectra.append(sp_bgsub)\n\n\t\t\tif plot == True:\n\t\t\t\taxarr[0].plot(sp_bgsub,label=\"WL: {} nm\".format(wl))\n\t\t\t\t\n\t\t#compute correlations to match positions\n\t\tscale_factors =  []\n\t\tfor i in range(0,len(spectra)-1):\n\t\t\tfor j in range(i+1,len(spectra)):\n\t\t\t\tsp1 = spectra[i]\n\t\t\t\tsp2 = spectra[j]\n\t\t\t\tpeak,xcs = spectrum_pixel_offset(sp1,sp2)\n\t\t\t\tif debug > 0:\n\t\t\t\t\tprint(\"Correlation peak (=pixel offset): {0}\".format(peak))\n\t\t\t\td_wl = wavelengths[j] - wavelengths[i]\n\t\t\t\td_pixel = peak\n\t\t\t\tsf = pixel_wavelength_conversion(d_pixel,d_wl)\n\t\t\t\tscale_factors.append(sf)\n\n\t\t\t\tif plot == True:\n\t\t\t\t\tp  =axarr[1].plot(xcs,\"-\",label=\"spectra: {0}nm vs {1}nm [offset: {2:.3g}, scale factor: {3:.3g}]\".format(wavelengths[i],wavelengths[j],peak,sf))\n\t\t\t\t\taxarr[1].plot(peak,xcs[peak],\"o\",color=p[0].get_color())\n\n\t\t\t\tif debug > 0:\n\t\t\t\t\tprint(\"Scale factor [{0} nm] vs [{1} nm]:\".format(wavelengths[i],wavelengths[j]), sf)\n\n\t\t#compute mean of scaling factor\n\t\tsf_mean = np.mean(scale_factors)\n\t\tsf_std = np.std(scale_factors)\n\t\tif debug > 0:\n\t\t\tprint(\"Final pixel to wavelength conversion  factor: {0:4g} +/- {1:4g} [nm/pixel]\".format(sf_mean,sf_std))\n\t\t\n\t\tif plot == True:\n\t\t\taxarr[0].legend()\n\t\t\taxarr[0].set_xlabel(\"Pixel index\")\n\t\t\taxarr[0].set_ylabel(\"Counts\")\n\n\t\t\taxarr[1].legend()\n\n\t\t\taxarr[1].set_xlabel(\"Pixel offset\")\n\t\t\taxarr[1].set_ylabel(\"Crosscorrelation [unnormalized]\")\n\n\t\t\tplt.show()\n\n\t\t#set the device pixel to wavelength scale factor\n\t\tself.pixel_to_wl_sf = sf_mean \n\t\treturn sf_mean,sf_std\n\n\n\tdef scan_spectrum(self,start_wavelength, stop_wavelength,step_size = 10):\n\t\t\n\t\tassert(start_wavelength >= self.min_wavelength)\n\t\tassert(stop_wavelength <= self.max_wavelength)\n\t\tassert(step_size > 0)\n\n\t\t\t\n\t\tpass",
  "def __init__(self,pixis,acton,boundary_cut=5,debug =0):\n\n\t\tself.debug = debug\n\t\tself.pixis = pixis\n\t\tself.acton = acton \n\n\t\t#####\n\t\t# Wavelength bounds\n\t\t#####\n\t\tself.min_wavelength = 0.000 #[nm]\n\t\tself.max_wavelength = 1200.000 #[nm]\n\t\t\n\t\tself.boundary_cut = boundary_cut\n\n\n\t\t#Used to background subtract when stitching together spectra\n\t\t#To initialize run: get_pixel_response_calibration_spectrum\n\t\tself.pixel_response = None\n\t\tself.raw_pixel_response = None\n\n\t\t#conversion factor from pixels to nm [units: nm/pixel]\n\t\t#default obtained from calibration\n\t\tself.pixel_to_wl_sf = 0.0289082",
  "def get_image(self,center_wavelength,roi = None,debug=0):\n\t\tself.acton.set_wavelength(center_wavelength,blocking=True,debug=debug)\n\t\tif roi is not None:\n\n\t\t\tif debug>0: print(\"starting try-catch\")\n\t\t\ttry:\n\t\t\t\t[x_min,x_max,y_min,y_max] = roi\n\t\t\t\tif debug > 0:\n\t\t\t\t\tprint(\"Pacton.get_image: region of interest:\", roi)\n\t\t\t\treturn self.pixis.get_roi(x_min=x_min, x_max = x_max, y_min=y_min,y_max = y_max,debug=debug)\n\n\t\t\texcept: \n\t\t\t\traise ValueError(\"Unable to unpack region of interest\")\n\t\telse:\n\t\t\treturn self.pixis.get_roi()",
  "def pixel_to_wavelength(self,pixels,center_wavelength, intensity):\n\t\tcenter_pixel = np.round(self.pixis.x_max)/2.0\n\t\tif self.pixel_to_wl_sf is None:\n\t\t\traise ValueError(\"No conversion factor set, please run Pacton.calibrate routine\")\n\t\telse:\n\t\t\t#intensity - the counts on each pixel\n\t\t\twavelengths = center_wavelength + self.pixel_to_wl_sf*np.array(pixels)\n\t\t\tmin_wl = np.min(wavelengths)\n\t\t\tmax_wl = np.max(wavelengths)\n\n\t\t\tindices = np.logical_and(CALIBRATION_WAVELENGTHS >= min_wl,CALIBRATION_WAVELENGTHS < max_wl)\n\n\t\t\tcalibration_intensity = CALIBRATION_COUNTS[indices]\n\t\t\tcalibration_wavelengths =CALIBRATION_WAVELENGTHS[indices]\n\n\t\t\tcalibration_intensity = calibration_intensity - np.min(calibration_intensity)\n\t\t\tcalibration_intensity = old_div(calibration_intensity,np.max(calibration_intensity))\n\n\t\t\tintensity = intensity - np.min(intensity)\n\t\t\tintensity = old_div(intensity,np.max(intensity))\n\n\t\t\tupsampled_calibration_intensity = scipy.signal.resample(calibration_intensity, len(wavelengths), t=None, axis=0, window=None)\n\t\t\tupsampled_calibration_wavelengths= scipy.signal.resample(calibration_wavelengths, len(wavelengths), t=None, axis=0, window=None)\n\n\n\n\t\t\tmax_xcs, xcs = spectrum_pixel_offset(upsampled_calibration_intensity,intensity)\n\t\t\txcs = np.fft.fftshift(xcs)\n\t\t\tmax_xcs = np.argmax(xcs)\n\t\t\toffset = max_xcs - old_div(len(wavelengths),2)\n\t\t\t# if self.debug > 0:\n\t\t\t# \tprint \"Calibration wavelength range:\", np.min(upsampled_calibration_wavelengths),np.max(upsampled_calibration_wavelengths)\n\t\t\t# \tprint \"Measured wavelength range:\", np.min(wavelengths),np.max(wavelengths)\n\t\t\t\t\n\t\t\t# \tprint \"Calibration curve length:\", len(calibration_intensity)\n\t\t\t# \tprint \"Measurement curve length:\", len(intensity)\n\t\t\t# \tprint \"Upsampled calibration curve length:\", len(upsampled_calibration_intensity)\n\t\t\t# \tprint \"Offset:\", offset\n\t\t\t# \timport matplotlib.pyplot as plt \n\n\t\t\t# \tfig,[ax1,ax2] = plt.subplots(2,figsize=(3*2*4,3*3))\n\t\t\t# \tax1.plot(wavelengths,intensity,label=\"intensity\")\n\t\t\t# \tax1.plot(calibration_wavelengths,calibration_intensity,label=\"upsampled calibration_intensity\")\n\t\t\t# \tshifted_wavelengths = center_wavelength + self.pixel_to_wl_sf*(np.array(pixels)+offset)\n\t\t\t# \tax1.plot(shifted_wavelengths,intensity,label=\"shifted intensity\")\n\t\t\t\t\n\t\t\t# \tax2.plot(xcs)\n\t\t\t# \tax1.legend()\n\t\t\t# \tplt.show()\n\t\t\twavelengths = center_wavelength + self.pixel_to_wl_sf*(np.array(pixels)+offset)\n\t\t\t\n\n\n\t\treturn wavelengths",
  "def get_pixel_response_calibration_spectrum(self,debug=0):\n\t\t'''\n\t\tScan over spectrum in the region where you don't expect to see anyting (ie. UV)\n\t\tTake spectra at each position and average. This then gives you the pixel response (strange I know).\n\t\tSmooth the average using cvx and use this in furthre processing for background subtraction on the LHS\n\t\tto make it easier to stitch together spectra\n\t\t'''\n\t\twavelengths = list(range(50,80,10))\n\t\tspectra = []\n\t\tfor wl in wavelengths:\n\t\t\tself.acton.set_wavelength(wl,blocking=True,fast=True,debug=debug)\n\t\t\tspectrum,_= self.pixis.get_spectrum()\n\t\t\tspectra.append(spectrum)\n\n\t\tspectra = np.array(spectra)\n\t\tcalibration_spectrum = np.mean(spectra,axis=0)\n\t\t#subtract minimum value to remove edge effects\n\t\tys = np.array(calibration_spectrum)\n\t\t\n\t\tymin = np.min(ys)\n\t\tys = ys - ymin\n\t\t#smooth to get less fluctuations in background\n\t\tsmoothed,_,_ = convex_smooth(ys,2)\n\t\tsmoothed = np.array(smoothed) + ymin\n\t\t#replace first 3 pixel values with \n\t\tsmoothed[0:3] = np.mean(calibration_spectrum[0:3])\n\t\t\n\t\tself.pixel_response = smoothed\n\t\tself.raw_pixel_response = calibration_spectrum\n\t\treturn smoothed, calibration_spectrum",
  "def get_spectrum(self,center_wavelength,subtract_background=True, roi = None,debug=0):\n\n\t\tself.acton.set_wavelength(center_wavelength,blocking=True,debug=debug)\n\t\tif subtract_background == True and self.pixel_response is None:\n\t\t\traise ValueError(\"Error getting spectrum with background subtraction - no background to subtract, please run: Pacton.get_pixel_response_calibration_spectrum \") \n\t\tif roi is not None:\n\t\t\ttry:\n\t\t\t\t[x_min,x_max,y_min,y_max] = roi\n\t\t\t\tspectrum,pixel_offsets = self.pixis.get_spectrum(x_min=x_min, x_max = x_max, y_min=y_min,y_max = y_max)\n\n\t\t\texcept: \n\t\t\t\traise ValueError(\"Unable to unpack region of interest\")\n\t\telse:\n\t\t\tspectrum,pixel_offsets = self.pixis.get_spectrum()\n\t\t\n\t\tif subtract_background == True:\n\t\t\tspectrum = np.array(spectrum) - self.pixel_response\n\t\twavelengths = self.pixel_to_wavelength(pixel_offsets,center_wavelength,spectrum)\n\t\treturn spectrum,wavelengths",
  "def calibrate(self,wavelengths,with_background_subtraction= False,plot=False,debug = 0):\n\t\tif with_background_subtraction == True:\n\t\t\tsmoothed,_ = self.get_pixel_response_calibration_spectrum()\n\n\t\tif plot == True:\n\t\t\tfig, axarr = plt.subplots(2,figsize=(8,16))\n\t\t\n\t\t#grab calibration spectra\n\t\tspectra = []\n\t\tfor wl in wavelengths:\n\t\t\tself.acton.set_wavelength(wl,fast=True,debug=debug)  \n\t\t\tsp = np.array(self.pixis.get_spectrum()[0])\n\t\t\tif with_background_subtraction == True:\n\n\t\t\t\tsp_bgsub = sp - smoothed\n\t\t\telse:\n\t\t\t\tsp_bgsub = sp\n\t\t\tspectra.append(sp_bgsub)\n\n\t\t\tif plot == True:\n\t\t\t\taxarr[0].plot(sp_bgsub,label=\"WL: {} nm\".format(wl))\n\t\t\t\t\n\t\t#compute correlations to match positions\n\t\tscale_factors =  []\n\t\tfor i in range(0,len(spectra)-1):\n\t\t\tfor j in range(i+1,len(spectra)):\n\t\t\t\tsp1 = spectra[i]\n\t\t\t\tsp2 = spectra[j]\n\t\t\t\tpeak,xcs = spectrum_pixel_offset(sp1,sp2)\n\t\t\t\tif debug > 0:\n\t\t\t\t\tprint(\"Correlation peak (=pixel offset): {0}\".format(peak))\n\t\t\t\td_wl = wavelengths[j] - wavelengths[i]\n\t\t\t\td_pixel = peak\n\t\t\t\tsf = pixel_wavelength_conversion(d_pixel,d_wl)\n\t\t\t\tscale_factors.append(sf)\n\n\t\t\t\tif plot == True:\n\t\t\t\t\tp  =axarr[1].plot(xcs,\"-\",label=\"spectra: {0}nm vs {1}nm [offset: {2:.3g}, scale factor: {3:.3g}]\".format(wavelengths[i],wavelengths[j],peak,sf))\n\t\t\t\t\taxarr[1].plot(peak,xcs[peak],\"o\",color=p[0].get_color())\n\n\t\t\t\tif debug > 0:\n\t\t\t\t\tprint(\"Scale factor [{0} nm] vs [{1} nm]:\".format(wavelengths[i],wavelengths[j]), sf)\n\n\t\t#compute mean of scaling factor\n\t\tsf_mean = np.mean(scale_factors)\n\t\tsf_std = np.std(scale_factors)\n\t\tif debug > 0:\n\t\t\tprint(\"Final pixel to wavelength conversion  factor: {0:4g} +/- {1:4g} [nm/pixel]\".format(sf_mean,sf_std))\n\t\t\n\t\tif plot == True:\n\t\t\taxarr[0].legend()\n\t\t\taxarr[0].set_xlabel(\"Pixel index\")\n\t\t\taxarr[0].set_ylabel(\"Counts\")\n\n\t\t\taxarr[1].legend()\n\n\t\t\taxarr[1].set_xlabel(\"Pixel offset\")\n\t\t\taxarr[1].set_ylabel(\"Crosscorrelation [unnormalized]\")\n\n\t\t\tplt.show()\n\n\t\t#set the device pixel to wavelength scale factor\n\t\tself.pixel_to_wl_sf = sf_mean \n\t\treturn sf_mean,sf_std",
  "def scan_spectrum(self,start_wavelength, stop_wavelength,step_size = 10):\n\t\t\n\t\tassert(start_wavelength >= self.min_wavelength)\n\t\tassert(stop_wavelength <= self.max_wavelength)\n\t\tassert(step_size > 0)\n\n\t\t\t\n\t\tpass",
  "def SetSensorTemperatureSetPoint(self,temperature):\n        param_name = \"PicamParameter_SensorTemperatureSetPoint\"\n        return self.set_parameter(parameter_name=param_name,parameter_value=temperature)",
  "def nm_to_raman_shift(laser_wavelength,wavelength):\n\traman_shift = 1e7*(1.0/laser_wavelength - 1.0/wavelength)\n\treturn raman_shift",
  "def initialize_datafile(path):\n\t\"\"\"\n\tThis function defines the format of the group structure\n\n\tParameters are path on filesystem \n\t\n\t\"\"\"\n\tf = df.DataFile(path, 'a')\n\n\treturn f",
  "def initialize_measurement(acton_port, exposure_time = 100):\n\tprint(\"Starting..\")\n\n\tprint(\"Pixis...\")\n\tp = Pixis(debug=1)\n\n\tp.StartUp()\n\tprint(\"Acton...\")\n\tact = Acton(port=acton_port, debug=1)\n\tprint(\"Done...\")\n\tpacton = Pacton(pixis=p,acton=act)\n\tprint(\"Measuring...\")\n\tp.SetExposureTime(exposure_time)\n\t# print pacton.acton.read_grating()\n\tpacton.acton.set_grating(1)\n\t# print \"New grating\",pacton.acton.read_grating_name()  \n\treturn pacton",
  "def single_shot(pacton, file, center_wavelength = 0, show_ = True):\n\tdata_group = file.require_group(\"zero_wavelength_images\")\n\timg = pacton.get_image(center_wavelength,debug=0)\n\texptime = pacton.pixis.GetExposureTime()\n\tattrs = {\"exposure_time\":exptime,\"center_wavelength\":center_wavelength}\n\n\tdata_group.create_dataset(\"image_%d\",data=img, attrs = attrs)\n\tdata_group.file.flush()\n\tif show_ == True:\n\t\t#exercise: put in if statement, only run when suitable flag (ie. input parameter is set to true)\n\t\tfig, ax = plt.subplots(1)\n\t\tax.imshow(img, cmap='gray')\n\t\tplt.show()",
  "def get_spectrum(pacton,file,y_roi,center_wavelength,exposure_time,show_= False, debug = 0, laser_wavelength = None):\n\n\tif debug > 0:\n\t\tprint(\"y_roi\",y_roi)\n\t\tprint(\"center_wavelength\",center_wavelength)\n\t\tprint(\"exposure_time\",exposure_time)\n\tspectrum_group = file.require_group(\"spectrum\")\n\n\t#run calibration to get rid of low pixel value high intensity peaks due to camera response\n\t\n\t#get spectrum, drop interpolated wavelengths - they are wrong!\n\t[ymin,ymax] = y_roi\n\txmin,xmax = [0,1024] #default to be over entire range!\n\troi = [xmin,xmax,ymin,ymax]\n\t\n\tif debug > 0: print(\"Fiddling with exposure...\")\n\tprevious_exposure_time = pacton.pixis.GetExposureTime()\n\tpacton.pixis.SetExposureTime(exposure_time)\n\tif debug > 0: print(\"Getting spectrum...\")\n\tspectrum,_ = pacton.get_spectrum(center_wavelength=center_wavelength,roi=roi)\n\t\n\tpacton.pixis.SetExposureTime(previous_exposure_time)\n\t\n\tpixel_indices = np.arange(0,1014)\n\t\n\tif debug > 0: print(\"Starting wavelength map...\") \n\twavelengths = [mapper(center_wavelength,i) for i in pixel_indices]\n\tif laser_wavelength is not None:\n\t\traman_shifts = [nm_to_raman_shift(laser_wavelength=laser_wavelength,wavelength=wl) for wl in wavelengths]\n\tattrs = {\n\t\t\"wavelengths\":wavelengths,\n\t\t\"raman_shift\": raman_shifts,\n\t\t\"center_wavelength\":center_wavelength,\n\t\t\"roi\":roi,\n\t\t\"exposure_time[ms]\": exposure_time\n\t}\n\tif debug > 0: print(\"writing data...\")\n\tspectrum_group.create_dataset(\"series_%d\",data=spectrum,attrs=attrs)\n\n\tif show_ == True:\n\t\tif laser_wavelength is None:\n\t\t\tfig, ax =plt.subplots(1)\n\t\t\tax.plot(wavelengths,spectrum)\n\t\t\tax.set_xlabel(\"wavelength [nm]\")\n\t\t\tax.set_ylabel(\"intensity [a.u.]\")\n\t\telif laser_wavelength is not None:\n\t\t\tfig, [ax1,ax2] = plt.subplots(2)\n\t\t\tax1.plot(wavelengths,spectrum)\n\t\t\tax2.plot(raman_shifts,spectrum)\n\n\t\t\tax1.set_xlabel(\"wavelength [nm]\")\n\t\t\tax1.set_ylabel(\"intensity [a.u.]\")\n\t\t\tax2.set_xlabel(\"raman shift [$cm^{-1}$]\")\n\t\t\tax2.set_ylabel(\"intensity [a.u.]\")\n\t\tplt.show()",
  "def experiment(pacton, file, functions,argss,kwargss):\n\tfor f, args,kwargs in zip(functions,argss,kwargss):\n\t\tf(pacton,file,*args,**kwargs)\n\n\treturn 0",
  "def get_wavelength(laser):\n\tlaser.system_status()\n\twl = laser.message_in_history[-1][\"message\"][\"parameters\"][\"wavelength\"]\n\treturn wl[0]",
  "def tune(wl,laser):\n\tlaser.change_wavelength(wl)\n\tmax_tries = 20\n\twhile (np.absolute(wl - get_wavelength(laser)) > 0.05) and max_tries > 0:\n\t\ttime.sleep(0.5)\n\t\tmax_tries = max_tries - 1\n\treturn",
  "def get_wavelength(laser):\n\tlaser.system_status()\n\twl = laser.message_in_history[-1][\"message\"][\"parameters\"][\"wavelength\"]\n\treturn wl[0]",
  "def tune(wl,laser):\n\tlaser.change_wavelength(wl)\n\tmax_tries = 20\n\twhile (np.absolute(wl - get_wavelength(laser)) > 0.05) and max_tries > 0:\n\t\ttime.sleep(0.5)\n\t\tmax_tries = max_tries - 1\n\treturn",
  "def get_wavelength(laser):\n\tlaser.system_status()\n\twl = laser.message_in_history[-1][\"message\"][\"parameters\"][\"wavelength\"]\n\treturn wl[0]",
  "def tune(wl,laser):\n\tlaser.change_wavelength(wl)\n\tmax_tries = 10\n\twhile (np.absolute(wl - get_wavelength(laser)) > 0.05) and max_tries > 0:\n\t\ttime.sleep(0.5)\n\t\tmax_tries = max_tries - 1\n\treturn",
  "def make_measurement(data_group,laser_wavelength,center_wavelength,reruns=0):\n\tspectrum,_ = pacton.get_spectrum(center_wavelength,subtract_background=True,roi=[0,1024,600,800],debug=1)\n\tif reruns > 0:\n\t\tN = spectrum.shape[0]\n\t\tspectra = np.zeros((reruns,N))\n\t\tspectra[0,:] = spectrum\n\t\tfor i in range(1,reruns):\n\t\t\tspectrum,_ = pacton.get_spectrum(center_wavelength,subtract_background=True,roi=[0,1024,600,800],debug=1)\n\t\t\tspectra[i,:] = spectrum\n\t\tspectrum = np.mean(spectra,axis=0)\n\n\tdata_group.create_dataset(\"spectrum\"+\"_%d\",data=spectrum, attrs = {\"center_wavelength\":center_wavelength,\"laser_wavelength\":laser_wavelength})\n\tdata_group.file.flush()\n\treturn",
  "def initialize_measurement():\n\tf = df.DataFile(\"ir_calibration.hdf5\",\"a\")\n\tg = f.require_group(\"calibration\")\n\tprint(\"Starting..\")\n\n\tprint(\"Pixis...\")\n\tp = Pixis(debug=1)\n\n\tp.StartUp()\n\tprint(\"Acton...\")\n\tact = Acton(\"COM7\",debug=1)\n\tprint(\"Done...\")\n\tpacton = Pacton(pixis=p,acton=act)\n\tprint(\"Measuring...\")\n\tfig,ax = plt.subplots(1)\n\tp.SetExposureTime(500)\n\tpacton.get_pixel_response_calibration_spectrum()\n\treturn pacton, g",
  "def plot_measurement(pacton, center_wavelength):\n\tfig,ax = plt.subplots(1)\n\tspectrum,_ = pacton.get_spectrum(center_wavelength,subtract_background=True,roi=[0,1024,600,800],debug=1)\n\tax.plot(spectrum)\n\tplt.show()",
  "def list_datafile_content(filepath, folderpath):\n    \"\"\"\n    Lists datasets from hdf5 file written by fiber raman rig in 'folderpath' inside file\n    \n    Parameters\n    ----------\n    filepath : string\n        Path to HDF5 file containing data. \n        \n    folderpath : string\n        Path to group containing spectra inside HDF5 file\n    \n    Returns\n    -------\n    list of string keys of datasets\n    \n    \"\"\"\n    f = df.DataFile(os.path.normpath(filepath), 'r')\n    return list(f[folderpath].keys())",
  "def extractor(filepath, folderpath):\n    \"\"\"\n    Extracts spectral data from hdf5 file written by fiber raman rig.\n    \n    Parameters\n    ----------\n    filepath : string\n        Path to HDF5 file containing data. \n        \n    folderpath : string\n        Path to group containing spectra inside HDF5 file\n    \n    Returns\n    -------\n    data : list of 3-tuples\n        tuple: (dt,center_wavelength, intensity)\n            dt : datetime tuple\n            center_wavelength: float (center wavelength of Acton spectrometer, units: nm)\n            intenisty: numpy.array (integers), .shape: (1014,) \n                CCD size is 1024 but leftmost 10 pixels cut to remove edge effects\n    TODOs\n    -------\n    None\n    \"\"\"\n    f = df.DataFile(os.path.normpath(filepath), 'r')\n    ks = list_datafile_content(filepath, folderpath)\n    def unix_timestamp(dt):\n        return time.mktime(dt.timetuple())\n\n    def dataset_extractor(dset):\n        intensity = np.array(dset)\n        assert intensity.shape[0] == 1014, 'number of datapoints in spctra should be 1014, =1024-10 truncating the left side'\n        center_wl = dset.attrs[\"center_wavelength\"]\n        dt = datetime.strptime(str(dset.attrs[\"creation_timestamp\"]),\"%Y-%m-%dT%H:%M:%S.%f\")\n        return (dt, center_wl, intensity)\n    \n    data = [dataset_extractor(dset=f[folderpath][k]) for k in ks]\n    data = sorted(data, key = lambda x: unix_timestamp(x[0]),reverse = False)\n    assert unix_timestamp(data[0][0]) < unix_timestamp(data[1][0]),\"timestamp of first element is less than timestamp of second element\"\n    return data",
  "def mapped_extractor(filepath, folderpath, mapper):\n    \"\"\"\n    Extracts spectral data from hdf5 file written by fiber raman rig, uses 'mapper' to convert from Acton center wavelength, pixel position to a \n    wavelength.\n    \n    Parameters\n    ----------\n    filepath : string\n        Path to HDF5 file containing data. \n        \n    folderpath : string\n        Path to group containing spectra inside HDF5 file\n    \n    mapper: function\n        function signature: (float, int) -> float\n        a function generated by a calibration file, mapping Acton center wavelength (float) and pixel offset on CCD (int) to a absolute wavelength (float)\n    Returns\n    -------\n    data : list of 3-tuples\n        tuple: (dt,wavelengths, intensity)\n            dt : datetime tuple\n            wavelengths: numpy.array [type:float], .shape: (1014,)\n            intensity: numpy.array [type:integer], .shape: (1014,) \n                CCD size is 1024 but leftmost 10 pixels cut to remove edge effects\n    \"\"\"\n    raw_data = extractor(filepath, folderpath)\n    pixel_offsets = np.arange(0,1014) #pixel offsets in image\n    def array_mapper(center_wavelength,pixel_offsets,mapper):\n        wavelengths =  np.array([mapper(center_wavelength, offset) for offset in pixel_offsets])\n        assert wavelengths.shape[0] == 1014, \"wavelength list should contain 1014 values - one for every pixel/intensity value\"\n\n    mapped_data = [ (dt,array_mapper(center_wl, pixel_offsets, mapper),intensity) for (dt, center_wl, intensity) in raw_data]\n    return mapped_data\n\n    return mapped_data",
  "def unix_timestamp(dt):\n        return time.mktime(dt.timetuple())",
  "def dataset_extractor(dset):\n        intensity = np.array(dset)\n        assert intensity.shape[0] == 1014, 'number of datapoints in spctra should be 1014, =1024-10 truncating the left side'\n        center_wl = dset.attrs[\"center_wavelength\"]\n        dt = datetime.strptime(str(dset.attrs[\"creation_timestamp\"]),\"%Y-%m-%dT%H:%M:%S.%f\")\n        return (dt, center_wl, intensity)",
  "def array_mapper(center_wavelength,pixel_offsets,mapper):\n        wavelengths =  np.array([mapper(center_wavelength, offset) for offset in pixel_offsets])\n        assert wavelengths.shape[0] == 1014, \"wavelength list should contain 1014 values - one for every pixel/intensity value\"",
  "def initialize_measurement(acton_port, exposure_time = 50):\n\tprint(\"Starting..\")\n\n\tprint(\"Pixis...\")\n\tp = Pixis(debug=1)\n\n\tp.StartUp()\n\tprint(\"Acton...\")\n\tact = Acton(port=acton_port, debug=1)\n\tprint(\"Done...\")\n\tpacton = Pacton(pixis=p,acton=act)\n\tprint(\"Measuring...\")\n\tp.SetExposureTime(exposure_time)\n\treturn pacton",
  "def make_app(pacton, refresh_time):\n\n\tapp = QtGui.QApplication([])\n\n\tw = QtGui.QWidget()\n\n\tplot = pg.ImageView()\n\n\tlayout = QtGui.QGridLayout() \n\tw.setLayout(layout) \n\n\tlayout.addWidget(plot, 0, 0) \n\n\tw.show()\n\n\ttimer = pg.QtCore.QTimer() \n\tdef update(): \n\t\t_,img = pacton.pixis.raw_snapshot()\n\t\tplot.setImage(img.T)\n\n\ttimer.timeout.connect(update)\n\ttimer.start(refresh_time)\n\tapp.exec_()",
  "def update(): \n\t\t_,img = pacton.pixis.raw_snapshot()\n\t\tplot.setImage(img.T)",
  "def initialize_measurement(acton_port, exposure_time = 100):\n\tprint(\"Starting..\")\n\n\tprint(\"Pixis...\")\n\tp = Pixis(debug=1)\n\n\tp.StartUp()\n\tprint(\"Acton...\")\n\tact = Acton(port=acton_port, debug=1)\n\tprint(\"Done...\")\n\tpacton = Pacton(pixis=p,acton=act)\n\tprint(\"Measuring...\")\n\tp.SetExposureTime(exposure_time)\n\treturn pacton",
  "def single_shot(acton_port=\"COM5\",center_wavelength = 840, exposure_time =10000):\n\tpacton = initialize_measurement(acton_port=acton_port,exposure_time=exposure_time)\n\tfi = [0,1024,514,600]\n\timg = pacton.get_image(center_wavelength,roi = fi ,debug=0)\n\tfig, ax = plt.subplots(1)\n\tax.imshow(img, cmap='viridis')\n\tplt.show()",
  "def make_measurement(data_group,laser_wavelength,center_wavelength):\n\tspectrum,_ = pacton.get_spectrum(center_wavelength,subtract_background=True,roi=[0,1024,600,800],debug=1)\n\tdata_group.create_dataset(\"spectrum\"+\"_%d\",data=spectrum, attrs = {\"center_wavelength\":center_wavelength,\"laser_wavelength\":laser_wavelength})\n\tdata_group.file.flush()\n\treturn",
  "def initialize_measurement():\n\tf = df.DataFile(\"ir_calibration.hdf5\",\"a\")\n\tg = f.require_group(\"calibration\")\n\tprint(\"Starting..\")\n\n\tprint(\"Pixis...\")\n\tp = Pixis(debug=1)\n\n\tp.StartUp()\n\tprint(\"Acton...\")\n\tact = Acton(\"COM7\",debug=1)\n\tprint(\"Done...\")\n\tpacton = Pacton(pixis=p,acton=act)\n\tprint(\"Measuring...\")\n\tfig,ax = plt.subplots(1)\n\tp.SetExposureTime(500)\n\tpacton.get_pixel_response_calibration_spectrum()\n\treturn pacton, g",
  "def plot_measurement(pacton, center_wavelength):\n\tfig,ax = plt.subplots(1)\n\tspectrum,_ = pacton.get_spectrum(center_wavelength,subtract_background=True,roi=[0,1024,600,800],debug=1)\n\tax.plot(spectrum)\n\tplt.show()",
  "class LinearScan(ScanningExperiment, TimedScan):\n    \"\"\"\n\n    \"\"\"\n\n    def __init__(self, start=None, stop=None, step=None):\n        ScanningExperiment.__init__(self)\n        TimedScan.__init__(self)\n        self.scanner = None\n        self.start, self.stop, self.step = (start, stop, step)\n        self.parameter = None\n        # underscored attributes are made into properties\n        self.status = 'inactive'\n        self.abort_requested = False\n        self.estimated_step_time = 0.001\n        self.acquisition_thread = None\n\n    def run(self):\n        \"\"\"\n        Starts the grid scan in its own thread and runs the update function at the specified\n        rate whilst acquiring the data.\n\n        :param rate: the update period in seconds\n        :return:\n        \"\"\"\n        if isinstance(self.acquisition_thread, threading.Thread) and self.acquisition_thread.is_alive():\n            print('scan already running')\n            return\n        self.init_scan()\n        self.acquisition_thread = threading.Thread(target=self.scan,\n                                                   args=(self.start, self.stop, self.step))\n        self.acquisition_thread.start()\n\n    def init_parameter(self, start, stop, step):\n        \"\"\"Create an parameter array to scan.\"\"\"\n        x = np.arange(start, stop, step)\n        self.total_points = x.size\n        self.parameter = x\n        return x\n\n    def init_current_parameter(self):\n        \"\"\"Convenience method that initialises a grid based on current parameters.\"\"\"\n        self.init_parameter(self.start, self.stop, self.step)\n\n    def set_parameter(self, value):\n        \"\"\"Vary the independent parameter.\"\"\"\n        raise NotImplementedError\n\n    def scan(self, start, stop, step):\n        \"\"\"Scans a grid, applying a function at each position.\"\"\"\n        self.abort_requested = False\n        p = self.init_parameter(start, stop, step)\n        self.open_scan()\n        # get the indices of points along each of the scan axes for use with snaking over array\n        pnts = list(range(p.size))\n\n        self.index = -1\n        self._index = -1\n        self._step_times = np.zeros_like(p)\n        self._step_times.fill(np.nan)\n        self.status = 'acquiring data'\n        self.acquiring.set()\n        scan_start_time = time.time()\n\n        for i in pnts:\n            if self.abort_requested:\n                break\n            self.index = i\n            self.set_parameter(p[i])\n            self.scan_function(i)\n            self._index += 1\n        self.print_scan_time(time.time() - scan_start_time)\n        self.acquiring.clear()\n        # move back to initial positions\n        #self.set_parameter(p[0])\n        # finish the scan\n        self.analyse_scan()\n        self.close_scan()\n        self.status = 'scan complete'",
  "class LinearScanQt(LinearScan, QtCore.QObject):\n    \"\"\"\n    A GridScanner subclass containing additional or redefined functions related to GUI operation.\n    \"\"\"\n\n    total_points_updated = QtCore.Signal(int)\n    status_updated = QtCore.Signal(str)\n    timing_updated = QtCore.Signal(str)\n\n    def __init__(self, start=None, stop=None, step=None):\n        LinearScan.__init__(self, start, stop, step)\n        QtCore.QObject.__init__(self)\n        self.timer = QtCore.QTimer()\n        self.timer.timeout.connect(self.update)\n\n    def run(self, rate=0.1):\n        super(LinearScanQt, self).run()\n        self.acquiring.wait()\n        self.timer.start(1000.*rate)\n\n    def get_qt_ui(self):\n        return LinearScanUI(self)\n\n    @staticmethod\n    def get_qt_ui_cls():\n        return LinearScanUI\n\n    def init_parameter(self, start, stop, step):\n        parameter = super(LinearScanQt, self).init_parameter(start, stop, step)\n        self.total_points_updated.emit(self.total_points)\n        return parameter\n\n    def update(self, force=False):\n        \"\"\"\n        This is the function that is called in the event loop and at the end of the scan\n        and should be reimplemented when subclassing to deal with data updates and GUIs.\n        \"\"\"\n        if not self.acquisition_thread.is_alive():\n            self.timer.stop()\n        self.timing_updated.emit(self.get_formatted_estimated_time_remaining())\n        self.status_updated.emit('')",
  "class LinearScanUI(QtWidgets.QWidget, UiTools):\n    def __init__(self, linear_scanner):\n        assert isinstance(linear_scanner, LinearScanQt), \"A valid LinearScanQt subclass must be supplied\"\n        super(LinearScanUI, self).__init__()\n        self.linear_scanner = linear_scanner\n        uic.loadUi(os.path.join(os.path.dirname(__file__), 'linear_scanner.ui'), self)\n        self.rate = 1./30.\n\n        self.setWindowTitle(self.linear_scanner.__class__.__name__)\n\n        for widget in [self.start, self.stop, self.step]:\n            widget.setValidator(QtGui.QDoubleValidator())\n            widget.textChanged.connect(self.on_text_change)\n        self.update_button.clicked.connect(self.linear_scanner.init_current_parameter)\n        self.start_button.clicked.connect(self.on_click)\n        self.abort_button.clicked.connect(self.linear_scanner.abort)\n        self.step_up.clicked.connect(self.on_click)\n        self.step_down.clicked.connect(self.on_click)\n        self.linear_scanner.status_updated.connect(self.update_status)\n        self.linear_scanner.timing_updated.connect(self.update_timing)\n        self.linear_scanner.total_points_updated.connect(self.update_parameters)\n\n        self.start.setText(str(self.linear_scanner.start))\n        self.stop.setText(str(self.linear_scanner.stop))\n        self.step.setText(str(self.linear_scanner.step))\n        self.status.setText(self.linear_scanner.status)\n\n    def on_click(self):\n        sender = self.sender()\n        if sender == self.start_button:\n            self.linear_scanner.run(self.rate)\n        elif sender == self.step_up:\n            self.linear_scanner.step *= 2\n            self.step.setText(str(self.linear_scanner.step))\n        elif sender == self.step_down:\n            self.linear_scanner.step /= 2\n            self.step.setText(str(self.linear_scanner.step))\n\n    def on_text_change(self, value):\n        sender = self.sender()\n        if sender.validator() is not None:\n            state = sender.validator().validate(value, 0)[0]\n            if state != QtGui.QValidator.Acceptable:\n                return\n        if sender == self.start:\n            self.linear_scanner.start = float(value)\n        elif sender == self.stop:\n            self.linear_scanner.stop = float(value)\n        elif sender == self.step:\n            self.linear_scanner.step = float(value)\n\n    def update_parameters(self):\n        self.total_points.setText(str(self.linear_scanner.total_points))\n        self.total_points.resize(self.total_points.sizeHint())\n        self.est_scan_time.setText(str(self.linear_scanner.estimate_scan_duration()))\n        self.est_scan_time.resize(self.est_scan_time.sizeHint())\n\n    def update_status(self):\n        self.status.setText(self.linear_scanner.status)\n\n    def update_timing(self, time):\n        self.est_time_remain.setText(time)",
  "def __init__(self, start=None, stop=None, step=None):\n        ScanningExperiment.__init__(self)\n        TimedScan.__init__(self)\n        self.scanner = None\n        self.start, self.stop, self.step = (start, stop, step)\n        self.parameter = None\n        # underscored attributes are made into properties\n        self.status = 'inactive'\n        self.abort_requested = False\n        self.estimated_step_time = 0.001\n        self.acquisition_thread = None",
  "def run(self):\n        \"\"\"\n        Starts the grid scan in its own thread and runs the update function at the specified\n        rate whilst acquiring the data.\n\n        :param rate: the update period in seconds\n        :return:\n        \"\"\"\n        if isinstance(self.acquisition_thread, threading.Thread) and self.acquisition_thread.is_alive():\n            print('scan already running')\n            return\n        self.init_scan()\n        self.acquisition_thread = threading.Thread(target=self.scan,\n                                                   args=(self.start, self.stop, self.step))\n        self.acquisition_thread.start()",
  "def init_parameter(self, start, stop, step):\n        \"\"\"Create an parameter array to scan.\"\"\"\n        x = np.arange(start, stop, step)\n        self.total_points = x.size\n        self.parameter = x\n        return x",
  "def init_current_parameter(self):\n        \"\"\"Convenience method that initialises a grid based on current parameters.\"\"\"\n        self.init_parameter(self.start, self.stop, self.step)",
  "def set_parameter(self, value):\n        \"\"\"Vary the independent parameter.\"\"\"\n        raise NotImplementedError",
  "def scan(self, start, stop, step):\n        \"\"\"Scans a grid, applying a function at each position.\"\"\"\n        self.abort_requested = False\n        p = self.init_parameter(start, stop, step)\n        self.open_scan()\n        # get the indices of points along each of the scan axes for use with snaking over array\n        pnts = list(range(p.size))\n\n        self.index = -1\n        self._index = -1\n        self._step_times = np.zeros_like(p)\n        self._step_times.fill(np.nan)\n        self.status = 'acquiring data'\n        self.acquiring.set()\n        scan_start_time = time.time()\n\n        for i in pnts:\n            if self.abort_requested:\n                break\n            self.index = i\n            self.set_parameter(p[i])\n            self.scan_function(i)\n            self._index += 1\n        self.print_scan_time(time.time() - scan_start_time)\n        self.acquiring.clear()\n        # move back to initial positions\n        #self.set_parameter(p[0])\n        # finish the scan\n        self.analyse_scan()\n        self.close_scan()\n        self.status = 'scan complete'",
  "def __init__(self, start=None, stop=None, step=None):\n        LinearScan.__init__(self, start, stop, step)\n        QtCore.QObject.__init__(self)\n        self.timer = QtCore.QTimer()\n        self.timer.timeout.connect(self.update)",
  "def run(self, rate=0.1):\n        super(LinearScanQt, self).run()\n        self.acquiring.wait()\n        self.timer.start(1000.*rate)",
  "def get_qt_ui(self):\n        return LinearScanUI(self)",
  "def get_qt_ui_cls():\n        return LinearScanUI",
  "def init_parameter(self, start, stop, step):\n        parameter = super(LinearScanQt, self).init_parameter(start, stop, step)\n        self.total_points_updated.emit(self.total_points)\n        return parameter",
  "def update(self, force=False):\n        \"\"\"\n        This is the function that is called in the event loop and at the end of the scan\n        and should be reimplemented when subclassing to deal with data updates and GUIs.\n        \"\"\"\n        if not self.acquisition_thread.is_alive():\n            self.timer.stop()\n        self.timing_updated.emit(self.get_formatted_estimated_time_remaining())\n        self.status_updated.emit('')",
  "def __init__(self, linear_scanner):\n        assert isinstance(linear_scanner, LinearScanQt), \"A valid LinearScanQt subclass must be supplied\"\n        super(LinearScanUI, self).__init__()\n        self.linear_scanner = linear_scanner\n        uic.loadUi(os.path.join(os.path.dirname(__file__), 'linear_scanner.ui'), self)\n        self.rate = 1./30.\n\n        self.setWindowTitle(self.linear_scanner.__class__.__name__)\n\n        for widget in [self.start, self.stop, self.step]:\n            widget.setValidator(QtGui.QDoubleValidator())\n            widget.textChanged.connect(self.on_text_change)\n        self.update_button.clicked.connect(self.linear_scanner.init_current_parameter)\n        self.start_button.clicked.connect(self.on_click)\n        self.abort_button.clicked.connect(self.linear_scanner.abort)\n        self.step_up.clicked.connect(self.on_click)\n        self.step_down.clicked.connect(self.on_click)\n        self.linear_scanner.status_updated.connect(self.update_status)\n        self.linear_scanner.timing_updated.connect(self.update_timing)\n        self.linear_scanner.total_points_updated.connect(self.update_parameters)\n\n        self.start.setText(str(self.linear_scanner.start))\n        self.stop.setText(str(self.linear_scanner.stop))\n        self.step.setText(str(self.linear_scanner.step))\n        self.status.setText(self.linear_scanner.status)",
  "def on_click(self):\n        sender = self.sender()\n        if sender == self.start_button:\n            self.linear_scanner.run(self.rate)\n        elif sender == self.step_up:\n            self.linear_scanner.step *= 2\n            self.step.setText(str(self.linear_scanner.step))\n        elif sender == self.step_down:\n            self.linear_scanner.step /= 2\n            self.step.setText(str(self.linear_scanner.step))",
  "def on_text_change(self, value):\n        sender = self.sender()\n        if sender.validator() is not None:\n            state = sender.validator().validate(value, 0)[0]\n            if state != QtGui.QValidator.Acceptable:\n                return\n        if sender == self.start:\n            self.linear_scanner.start = float(value)\n        elif sender == self.stop:\n            self.linear_scanner.stop = float(value)\n        elif sender == self.step:\n            self.linear_scanner.step = float(value)",
  "def update_parameters(self):\n        self.total_points.setText(str(self.linear_scanner.total_points))\n        self.total_points.resize(self.total_points.sizeHint())\n        self.est_scan_time.setText(str(self.linear_scanner.estimate_scan_duration()))\n        self.est_scan_time.resize(self.est_scan_time.sizeHint())",
  "def update_status(self):\n        self.status.setText(self.linear_scanner.status)",
  "def update_timing(self, time):\n        self.est_time_remain.setText(time)",
  "class DummyLinearScan(template):\n        def __init__(self):\n            super(DummyLinearScan, self).__init__()\n            self.start, self.stop, self.step = (0, 1, 0.01)\n            self.estimated_step_time = 0.0005\n            self.fig = Figure()\n            self.data = None\n        def open_scan(self):\n            self.fig.clear()\n            self.data = np.zeros_like(self.parameter, dtype=np.float64)\n            self.data.fill(np.nan)\n            self.ax = self.fig.add_subplot(111)\n            #self.ax.set_xlim(self.parameter.min(), self.parameter.max())\n        def set_parameter(self, value):\n            pass\n        def scan_function(self, index):\n            time.sleep(0.0005)\n            x = self.parameter[index]\n            self.data[index] = np.sin(2*np.pi*5*x)\n            self.check_for_data_request(self.parameter[:self.index+1], self.data[:self.index+1])\n        def run(self, rate=0.1):\n            fname = 'profiling.stats'\n            cProfile.runctx('super(DummyLinearScan, self).run(%.2f)'%rate, globals(), locals(), filename=fname)\n            stats = pstats.Stats(fname)\n            stats.strip_dirs()\n            stats.sort_stats('cumulative')\n            stats.print_stats()\n        def update(self, force=False):\n            super(DummyLinearScan, self).update(force)\n            if self.data is None or self.fig.canvas is None:\n                print('no canvas or data')\n                return\n            if force:\n                data = (self.parameter, self.data)\n            else:\n                data = self.request_data()\n            if data is not False:\n                sweep, data = data\n                if not np.any(np.isfinite(data)):\n                    return\n                if not self.ax.lines:\n                    self.ax.plot(sweep, data)\n                else:\n                    l, = self.ax.lines\n                    l.set_data(sweep, data)\n                    self.ax.relim()\n                    self.ax.autoscale_view()\n                self.fig.canvas.draw()\n        def get_qt_ui(self):\n            return DummyLinearScanUI(self)",
  "class DummyLinearScanUI(LinearScanUI):\n        def __init__(self, linear_scanner):\n            super(DummyLinearScanUI, self).__init__(linear_scanner)\n            self.canvas = FigureCanvas(self.linear_scanner.fig)\n            self.canvas.setMaximumSize(300,300)\n            self.layout.addWidget(self.canvas)\n            self.resize(self.sizeHint())",
  "def __init__(self):\n            super(DummyLinearScan, self).__init__()\n            self.start, self.stop, self.step = (0, 1, 0.01)\n            self.estimated_step_time = 0.0005\n            self.fig = Figure()\n            self.data = None",
  "def open_scan(self):\n            self.fig.clear()\n            self.data = np.zeros_like(self.parameter, dtype=np.float64)\n            self.data.fill(np.nan)\n            self.ax = self.fig.add_subplot(111)",
  "def set_parameter(self, value):\n            pass",
  "def scan_function(self, index):\n            time.sleep(0.0005)\n            x = self.parameter[index]\n            self.data[index] = np.sin(2*np.pi*5*x)\n            self.check_for_data_request(self.parameter[:self.index+1], self.data[:self.index+1])",
  "def run(self, rate=0.1):\n            fname = 'profiling.stats'\n            cProfile.runctx('super(DummyLinearScan, self).run(%.2f)'%rate, globals(), locals(), filename=fname)\n            stats = pstats.Stats(fname)\n            stats.strip_dirs()\n            stats.sort_stats('cumulative')\n            stats.print_stats()",
  "def update(self, force=False):\n            super(DummyLinearScan, self).update(force)\n            if self.data is None or self.fig.canvas is None:\n                print('no canvas or data')\n                return\n            if force:\n                data = (self.parameter, self.data)\n            else:\n                data = self.request_data()\n            if data is not False:\n                sweep, data = data\n                if not np.any(np.isfinite(data)):\n                    return\n                if not self.ax.lines:\n                    self.ax.plot(sweep, data)\n                else:\n                    l, = self.ax.lines\n                    l.set_data(sweep, data)\n                    self.ax.relim()\n                    self.ax.autoscale_view()\n                self.fig.canvas.draw()",
  "def get_qt_ui(self):\n            return DummyLinearScanUI(self)",
  "def __init__(self, linear_scanner):\n            super(DummyLinearScanUI, self).__init__(linear_scanner)\n            self.canvas = FigureCanvas(self.linear_scanner.fig)\n            self.canvas.setMaximumSize(300,300)\n            self.layout.addWidget(self.canvas)\n            self.resize(self.sizeHint())",
  "class ContinuousLinearScan(ScanningExperiment, TimedScan):\n\n    @inherit_docstring(TimedScan)\n    @inherit_docstring(ScanningExperiment)\n    def __init__(self):\n        super(ContinuousLinearScan, self).__init__()\n        self.step = None\n        self.direction = 1\n        # Repeat capabilities\n        self._num_measurements = 0  # the number of measurements made and incremented to num_repeats\n        self.num_repeats = 1  # user sets this in subclass\n        self.hold = False  # setting this to true prevents movement commands\n        self._last_step = 0.  # this is useful when incrementing a displacement array\n        # Feedback attributes\n        self.engage_feedback = False\n        self.feedback_on = 'Force'\n        self.set_point = 0\n        self.feedback_gain = 1\n        self.feedback_min = -1\n        self.feedback_max = 1\n\n    @inherit_docstring(ScanningExperiment.run)\n    def run(self, new=True):\n        if isinstance(self.acquisition_thread, Thread) and self.acquisition_thread.is_alive():\n            print('scan already running')\n            return\n        self.init_scan()\n        self.acquisition_thread = Thread(target=self.scan, args=(new,))\n        self.acquisition_thread.start()\n\n    def set_parameter(self, value):\n        \"\"\"Vary the independent parameter.\"\"\"\n        raise NotImplementedError\n\n    @inherit_docstring(ScanningExperiment.scan_function)\n    def scan_function(self, index):\n        raise NotImplementedError\n\n    def update_parameter(self, value):\n        \"\"\"Vary the independent parameter.\"\"\"\n        raise NotImplementedError\n\n    @inherit_docstring(ScanningExperiment.run)\n    def scan(self, new=True):\n        self.abort_requested = False\n        self.open_scan()\n        self.status = 'acquiring data'\n        self.acquiring.set()\n        scan_start_time = time.time()\n        index = 0 if new else 1\n        while not self.abort_requested:\n            if self.hold or self._num_measurements < self.num_repeats:\n                self._last_step = 0.  # used to prevent the incrementing of the displacement\n            else:\n                self.set_parameter(self.direction*self.step)\n                self._num_measurements = 0  # reset the number of measurements made after move\n                self._last_step = self.direction*self.step\n            self._num_measurements += 1\n            self.scan_function(index)\n            index += 1\n            if self.engage_feedback:\n                feedback_input = self.calculate_feedback_input()\n                direction, step = self.feedback_loop(feedback_input, self.set_point)\n                self.update_from_feedback(direction, step)\n            try:\n                self.update_parameter(self.direction*self.step)\n            except NotImplementedError:\n                pass\n        self.print_scan_time(time.time() - scan_start_time)\n        self.acquiring.clear()\n        # finish the scan\n        self.analyse_scan()\n        self.close_scan()\n        self.status = 'scan complete'\n\n    def calculate_feedback_input(self):\n        \"\"\"\n        Return the input to the feedback loop.\n\n        :return value: the value of the variable to feed back on\n        \"\"\"\n        raise NotImplementedError\n\n    def feedback_loop(self, feedback_input, set_point):\n        \"\"\"\n        Returns the direction and step size that should be used in the next loop iteration.\n        :param feedback_input: the current value of the target variable\n        :param set_point: the target value that should held\n        :returns direction, step_size:\n        :rtype : object\n        \"\"\"\n        e = feedback_input - set_point\n        output = -self.feedback_gain*e  # if e>0 i.e. input > set_point for d=1 then d goes to -1\n        output = np.clip(output, self.feedback_min, self.feedback_max)\n        step_size = abs(output)\n        direction = np.sign(output)\n        return direction, step_size\n\n    def update_from_feedback(self, direction, step):\n        \"\"\"This function is created simply to be subclass GUI updates.\"\"\"\n        self.direction = direction\n        self.step = step",
  "class ContinuousLinearScanQt(ContinuousLinearScan, QtCore.QObject):\n    direction_updated = QtCore.Signal(int)\n    step_updated = QtCore.Signal(float)\n\n    @inherit_docstring(ContinuousLinearScan.__init__)\n    def __init__(self):\n        ContinuousLinearScan.__init__(self)\n        QtCore.QObject.__init__(self)\n        self.timer = QtCore.QTimer()\n        self.timer.timeout.connect(self.update)\n\n    @inherit_docstring(ContinuousLinearScan.run)\n    def run(self, rate=0.1):\n        super(ContinuousLinearScanQt, self).run()\n        self.acquiring.wait()\n        self.timer.start(1000.*rate)\n\n    def get_qt_ui(self):\n        return ContinuousLinearScanUI(self)\n\n    @staticmethod\n    def get_qt_ui_cls():\n        return ContinuousLinearScanUI\n\n    @inherit_docstring(ContinuousLinearScan.update)\n    def update(self, force=False):\n        if not self.acquisition_thread.is_alive():\n            self.timer.stop()\n\n    @inherit_docstring(ContinuousLinearScan.update_from_feedback)\n    def update_from_feedback(self, direction, step):\n        super(ContinuousLinearScanQt, self).update_from_feedback(direction, step)\n        self.direction_updated.emit(self.direction)\n        self.step_updated.emit(self.step)",
  "class ContinuousLinearScanUI(QtWidgets.QWidget, UiTools):\n    def __init__(self, cont_linear_scan):\n        assert isinstance(cont_linear_scan, ContinuousLinearScanQt), 'An instance of ContinuousLinearScanQt must be supplied'\n        super(ContinuousLinearScanUI, self).__init__()\n\n        self.linear_scan = cont_linear_scan\n        uic.loadUi(os.path.join(os.path.dirname(__file__), 'continuous_linear_scanner.ui'), self)\n        self.rate = 1./30.\n\n        self.setWindowTitle(self.linear_scan.__class__.__name__)\n\n        self.step.setValidator(QtGui.QDoubleValidator())\n        self.step.textChanged.connect(self.check_state)\n        self.step.textChanged.connect(self.on_text_change)\n        self.start_button.clicked.connect(self.on_click)\n        self.abort_button.clicked.connect(self.linear_scan.abort)\n        self.change_direction_button.clicked.connect(self.on_click)\n        self.step_up.clicked.connect(self.on_click)\n        self.step_down.clicked.connect(self.on_click)\n        self.step.setText(str(self.linear_scan.step))\n        self.direction.setText(str(self.linear_scan.direction))\n\n        self.num_repeats.setValidator(QtGui.QDoubleValidator())\n        self.num_repeats.textChanged.connect(self.check_state)\n        self.num_repeats.textChanged.connect(self.on_text_change)\n        self.hold.stateChanged.connect(self.on_state_change)\n        self.set_point.setValidator(QtGui.QDoubleValidator())\n        self.set_point.textChanged.connect(self.check_state)\n        self.set_point.textChanged.connect(self.on_text_change)\n        self.engage_feedback.stateChanged.connect(self.on_state_change)\n\n        self.linear_scan.direction_updated.connect(partial(self.update_param, 'direction'))\n        self.linear_scan.step_updated.connect(partial(self.update_param, 'step'))\n\n    def on_click(self):\n        sender = self.sender()\n        if sender == self.start_button:\n            self.linear_scan.run(self.rate)\n        elif sender == self.change_direction_button:\n            self.linear_scan.direction *= -1\n            self.direction.setText(str(self.linear_scan.direction))\n        elif sender == self.step_up:\n            self.step.blockSignals(True)\n            self.linear_scan.step *= 2\n            self.step.setText(str(self.linear_scan.step))\n            self.step.blockSignals(False)\n        elif sender == self.step_down:\n            self.step.blockSignals(True)\n            self.linear_scan.step /= 2\n            self.step.setText(str(self.linear_scan.step))\n            self.step.blockSignals(False)\n\n    def on_text_change(self, value):\n        sender = self.sender()\n        if sender.validator() is not None:\n            state = sender.validator().validate(value, 0)[0]\n            if state != QtGui.QValidator.Acceptable:\n                return\n        if sender == self.step:\n            self.linear_scan.step = float(value)\n        elif sender == self.num_repeats:\n            self.linear_scan.num_repeats = int(value)\n        elif sender == self.set_point:\n            self.linear_scan.set_point = float(value)\n\n    def on_state_change(self, state):\n        sender = self.sender()\n        if sender == self.hold:\n            if state == QtCore.Qt.Checked:\n                self.linear_scan.hold = True\n            elif state == QtCore.Qt.Unchecked:\n                self.linear_scan.hold = False\n        elif sender == self.engage_feedback:\n            if state == QtCore.Qt.Checked:\n                self.linear_scan.engage_feedback = True\n            elif state == QtCore.Qt.Unchecked:\n                self.linear_scan.engage_feedback = False\n\n    def update_param(self, param, value):\n        if param == 'direction':\n            self.direction.setText(str(value))\n        elif param == 'step':\n            self.step.setText(str(value))",
  "def __init__(self):\n        super(ContinuousLinearScan, self).__init__()\n        self.step = None\n        self.direction = 1\n        # Repeat capabilities\n        self._num_measurements = 0  # the number of measurements made and incremented to num_repeats\n        self.num_repeats = 1  # user sets this in subclass\n        self.hold = False  # setting this to true prevents movement commands\n        self._last_step = 0.  # this is useful when incrementing a displacement array\n        # Feedback attributes\n        self.engage_feedback = False\n        self.feedback_on = 'Force'\n        self.set_point = 0\n        self.feedback_gain = 1\n        self.feedback_min = -1\n        self.feedback_max = 1",
  "def run(self, new=True):\n        if isinstance(self.acquisition_thread, Thread) and self.acquisition_thread.is_alive():\n            print('scan already running')\n            return\n        self.init_scan()\n        self.acquisition_thread = Thread(target=self.scan, args=(new,))\n        self.acquisition_thread.start()",
  "def set_parameter(self, value):\n        \"\"\"Vary the independent parameter.\"\"\"\n        raise NotImplementedError",
  "def scan_function(self, index):\n        raise NotImplementedError",
  "def update_parameter(self, value):\n        \"\"\"Vary the independent parameter.\"\"\"\n        raise NotImplementedError",
  "def scan(self, new=True):\n        self.abort_requested = False\n        self.open_scan()\n        self.status = 'acquiring data'\n        self.acquiring.set()\n        scan_start_time = time.time()\n        index = 0 if new else 1\n        while not self.abort_requested:\n            if self.hold or self._num_measurements < self.num_repeats:\n                self._last_step = 0.  # used to prevent the incrementing of the displacement\n            else:\n                self.set_parameter(self.direction*self.step)\n                self._num_measurements = 0  # reset the number of measurements made after move\n                self._last_step = self.direction*self.step\n            self._num_measurements += 1\n            self.scan_function(index)\n            index += 1\n            if self.engage_feedback:\n                feedback_input = self.calculate_feedback_input()\n                direction, step = self.feedback_loop(feedback_input, self.set_point)\n                self.update_from_feedback(direction, step)\n            try:\n                self.update_parameter(self.direction*self.step)\n            except NotImplementedError:\n                pass\n        self.print_scan_time(time.time() - scan_start_time)\n        self.acquiring.clear()\n        # finish the scan\n        self.analyse_scan()\n        self.close_scan()\n        self.status = 'scan complete'",
  "def calculate_feedback_input(self):\n        \"\"\"\n        Return the input to the feedback loop.\n\n        :return value: the value of the variable to feed back on\n        \"\"\"\n        raise NotImplementedError",
  "def feedback_loop(self, feedback_input, set_point):\n        \"\"\"\n        Returns the direction and step size that should be used in the next loop iteration.\n        :param feedback_input: the current value of the target variable\n        :param set_point: the target value that should held\n        :returns direction, step_size:\n        :rtype : object\n        \"\"\"\n        e = feedback_input - set_point\n        output = -self.feedback_gain*e  # if e>0 i.e. input > set_point for d=1 then d goes to -1\n        output = np.clip(output, self.feedback_min, self.feedback_max)\n        step_size = abs(output)\n        direction = np.sign(output)\n        return direction, step_size",
  "def update_from_feedback(self, direction, step):\n        \"\"\"This function is created simply to be subclass GUI updates.\"\"\"\n        self.direction = direction\n        self.step = step",
  "def __init__(self):\n        ContinuousLinearScan.__init__(self)\n        QtCore.QObject.__init__(self)\n        self.timer = QtCore.QTimer()\n        self.timer.timeout.connect(self.update)",
  "def run(self, rate=0.1):\n        super(ContinuousLinearScanQt, self).run()\n        self.acquiring.wait()\n        self.timer.start(1000.*rate)",
  "def get_qt_ui(self):\n        return ContinuousLinearScanUI(self)",
  "def get_qt_ui_cls():\n        return ContinuousLinearScanUI",
  "def update(self, force=False):\n        if not self.acquisition_thread.is_alive():\n            self.timer.stop()",
  "def update_from_feedback(self, direction, step):\n        super(ContinuousLinearScanQt, self).update_from_feedback(direction, step)\n        self.direction_updated.emit(self.direction)\n        self.step_updated.emit(self.step)",
  "def __init__(self, cont_linear_scan):\n        assert isinstance(cont_linear_scan, ContinuousLinearScanQt), 'An instance of ContinuousLinearScanQt must be supplied'\n        super(ContinuousLinearScanUI, self).__init__()\n\n        self.linear_scan = cont_linear_scan\n        uic.loadUi(os.path.join(os.path.dirname(__file__), 'continuous_linear_scanner.ui'), self)\n        self.rate = 1./30.\n\n        self.setWindowTitle(self.linear_scan.__class__.__name__)\n\n        self.step.setValidator(QtGui.QDoubleValidator())\n        self.step.textChanged.connect(self.check_state)\n        self.step.textChanged.connect(self.on_text_change)\n        self.start_button.clicked.connect(self.on_click)\n        self.abort_button.clicked.connect(self.linear_scan.abort)\n        self.change_direction_button.clicked.connect(self.on_click)\n        self.step_up.clicked.connect(self.on_click)\n        self.step_down.clicked.connect(self.on_click)\n        self.step.setText(str(self.linear_scan.step))\n        self.direction.setText(str(self.linear_scan.direction))\n\n        self.num_repeats.setValidator(QtGui.QDoubleValidator())\n        self.num_repeats.textChanged.connect(self.check_state)\n        self.num_repeats.textChanged.connect(self.on_text_change)\n        self.hold.stateChanged.connect(self.on_state_change)\n        self.set_point.setValidator(QtGui.QDoubleValidator())\n        self.set_point.textChanged.connect(self.check_state)\n        self.set_point.textChanged.connect(self.on_text_change)\n        self.engage_feedback.stateChanged.connect(self.on_state_change)\n\n        self.linear_scan.direction_updated.connect(partial(self.update_param, 'direction'))\n        self.linear_scan.step_updated.connect(partial(self.update_param, 'step'))",
  "def on_click(self):\n        sender = self.sender()\n        if sender == self.start_button:\n            self.linear_scan.run(self.rate)\n        elif sender == self.change_direction_button:\n            self.linear_scan.direction *= -1\n            self.direction.setText(str(self.linear_scan.direction))\n        elif sender == self.step_up:\n            self.step.blockSignals(True)\n            self.linear_scan.step *= 2\n            self.step.setText(str(self.linear_scan.step))\n            self.step.blockSignals(False)\n        elif sender == self.step_down:\n            self.step.blockSignals(True)\n            self.linear_scan.step /= 2\n            self.step.setText(str(self.linear_scan.step))\n            self.step.blockSignals(False)",
  "def on_text_change(self, value):\n        sender = self.sender()\n        if sender.validator() is not None:\n            state = sender.validator().validate(value, 0)[0]\n            if state != QtGui.QValidator.Acceptable:\n                return\n        if sender == self.step:\n            self.linear_scan.step = float(value)\n        elif sender == self.num_repeats:\n            self.linear_scan.num_repeats = int(value)\n        elif sender == self.set_point:\n            self.linear_scan.set_point = float(value)",
  "def on_state_change(self, state):\n        sender = self.sender()\n        if sender == self.hold:\n            if state == QtCore.Qt.Checked:\n                self.linear_scan.hold = True\n            elif state == QtCore.Qt.Unchecked:\n                self.linear_scan.hold = False\n        elif sender == self.engage_feedback:\n            if state == QtCore.Qt.Checked:\n                self.linear_scan.engage_feedback = True\n            elif state == QtCore.Qt.Unchecked:\n                self.linear_scan.engage_feedback = False",
  "def update_param(self, param, value):\n        if param == 'direction':\n            self.direction.setText(str(value))\n        elif param == 'step':\n            self.step.setText(str(value))",
  "class DummyLinearScan(ContinuousLinearScanQt):\n        def __init__(self):\n            super(DummyLinearScan, self).__init__()\n            self.step = 1.\n            self.direction = 1.\n            self.fig = Figure()\n            self.p = None\n            self.x = None\n            self.y = None\n        def open_scan(self):\n            self.fig.clear()\n            self.p = 0\n            self.d = []\n            self.x = []\n            self.y = []\n            self.ax = self.fig.add_subplot(111)\n        def set_parameter(self, value):\n            self.p += value\n        #def update_parameter(self, value):\n        #    self.p += value\n        def scan_function(self, index):\n            time.sleep(0.01)\n            self.d.append(index)\n            self.x.append(self.p)\n            self.y.append(np.sin(2*np.pi*0.01*self.p))\n            self.check_for_data_request(self.d, self.x, self.y)\n        def update(self, force=False):\n            super(DummyLinearScan, self).update(force)\n            if self.y == [] or self.fig.canvas is None:\n                return\n            if force:\n                data = (self.d, self.x, self.y)\n            else:\n                data = self.request_data()\n            if data is not False:\n                d, x, y = data\n                if not np.any(np.isfinite(y)):\n                    return\n                if not self.ax.lines:\n                    self.ax.plot(d, y)\n                else:\n                    l, = self.ax.lines\n                    l.set_data(d, y)\n                    self.ax.relim()\n                    self.ax.autoscale_view()\n                self.fig.canvas.draw()\n        def get_qt_ui(self):\n            return DummyLinearScanUI(self)\n        def calculate_feedback_input(self):\n            return self.y[-1]",
  "class DummyLinearScanUI(ContinuousLinearScanUI):\n        def __init__(self, linear_scan):\n            super(DummyLinearScanUI, self).__init__(linear_scan)\n            self.canvas = FigureCanvas(self.linear_scan.fig)\n            self.canvas.setMaximumSize(300,300)\n            self.layout.addWidget(self.canvas)\n            self.resize(self.sizeHint())",
  "def __init__(self):\n            super(DummyLinearScan, self).__init__()\n            self.step = 1.\n            self.direction = 1.\n            self.fig = Figure()\n            self.p = None\n            self.x = None\n            self.y = None",
  "def open_scan(self):\n            self.fig.clear()\n            self.p = 0\n            self.d = []\n            self.x = []\n            self.y = []\n            self.ax = self.fig.add_subplot(111)",
  "def set_parameter(self, value):\n            self.p += value",
  "def scan_function(self, index):\n            time.sleep(0.01)\n            self.d.append(index)\n            self.x.append(self.p)\n            self.y.append(np.sin(2*np.pi*0.01*self.p))\n            self.check_for_data_request(self.d, self.x, self.y)",
  "def update(self, force=False):\n            super(DummyLinearScan, self).update(force)\n            if self.y == [] or self.fig.canvas is None:\n                return\n            if force:\n                data = (self.d, self.x, self.y)\n            else:\n                data = self.request_data()\n            if data is not False:\n                d, x, y = data\n                if not np.any(np.isfinite(y)):\n                    return\n                if not self.ax.lines:\n                    self.ax.plot(d, y)\n                else:\n                    l, = self.ax.lines\n                    l.set_data(d, y)\n                    self.ax.relim()\n                    self.ax.autoscale_view()\n                self.fig.canvas.draw()",
  "def get_qt_ui(self):\n            return DummyLinearScanUI(self)",
  "def calculate_feedback_input(self):\n            return self.y[-1]",
  "def __init__(self, linear_scan):\n            super(DummyLinearScanUI, self).__init__(linear_scan)\n            self.canvas = FigureCanvas(self.linear_scan.fig)\n            self.canvas.setMaximumSize(300,300)\n            self.layout.addWidget(self.canvas)\n            self.resize(self.sizeHint())",
  "class TimedScan(object):\n    def __init__(self):\n        self._estimated_step_time = 0\n        self.total_points = 0\n\n    @property\n    def estimated_step_time(self):\n        return self._estimated_step_time\n\n    @estimated_step_time.setter\n    def estimated_step_time(self, value):\n        self._estimated_step_time = value\n\n    def estimate_scan_duration(self):\n        \"\"\"Estimate the duration of a grid scan.\"\"\"\n        estimated_time = self.total_points * self.estimated_step_time\n        return self.format_time(estimated_time)\n\n    def get_estimated_time_remaining(self):\n        \"\"\"Estimate the time remaining of the current scan.\"\"\"\n        if not hasattr(self, '_step_times'):\n            return np.inf\n        mask = np.isfinite(self._step_times)\n        if not np.any(mask):\n            return 0\n        times = self._step_times[mask].flatten()\n        average_step_time = np.mean(np.diff(times))\n        etr = (self.total_points - self._index) * average_step_time  # remaining steps = self.total_points - index\n        return etr\n\n    def format_time(self, t):\n        \"\"\"Formats the time in seconds into a string with convenient units.\"\"\"\n        if t < 120:\n            return '{0:.1f} s'.format(t)\n        elif (t >= 120) and (t < 3600):\n            return '{0:.1f} mins'.format(t / 60.)\n        elif t >= 3600:\n            return '{0:.1f} hours'.format(t / 3600.)\n        else:\n            return 'You should probably not be running this scan!'\n\n    def get_formatted_estimated_time_remaining(self):\n        \"\"\"Returns a string of convenient units for the estimated time remaining.\"\"\"\n        if self.acquisition_thread.is_alive():\n            etr = self.get_estimated_time_remaining()\n            return self.format_time(etr)\n        else:\n            return 'inactive'\n\n    def print_scan_time(self, t):\n        \"\"\"Prints the duration of the scan.\"\"\"\n        print('Scan took', self.format_time(t))",
  "def __init__(self):\n        self._estimated_step_time = 0\n        self.total_points = 0",
  "def estimated_step_time(self):\n        return self._estimated_step_time",
  "def estimated_step_time(self, value):\n        self._estimated_step_time = value",
  "def estimate_scan_duration(self):\n        \"\"\"Estimate the duration of a grid scan.\"\"\"\n        estimated_time = self.total_points * self.estimated_step_time\n        return self.format_time(estimated_time)",
  "def get_estimated_time_remaining(self):\n        \"\"\"Estimate the time remaining of the current scan.\"\"\"\n        if not hasattr(self, '_step_times'):\n            return np.inf\n        mask = np.isfinite(self._step_times)\n        if not np.any(mask):\n            return 0\n        times = self._step_times[mask].flatten()\n        average_step_time = np.mean(np.diff(times))\n        etr = (self.total_points - self._index) * average_step_time  # remaining steps = self.total_points - index\n        return etr",
  "def format_time(self, t):\n        \"\"\"Formats the time in seconds into a string with convenient units.\"\"\"\n        if t < 120:\n            return '{0:.1f} s'.format(t)\n        elif (t >= 120) and (t < 3600):\n            return '{0:.1f} mins'.format(t / 60.)\n        elif t >= 3600:\n            return '{0:.1f} hours'.format(t / 3600.)\n        else:\n            return 'You should probably not be running this scan!'",
  "def get_formatted_estimated_time_remaining(self):\n        \"\"\"Returns a string of convenient units for the estimated time remaining.\"\"\"\n        if self.acquisition_thread.is_alive():\n            etr = self.get_estimated_time_remaining()\n            return self.format_time(etr)\n        else:\n            return 'inactive'",
  "def print_scan_time(self, t):\n        \"\"\"Prints the duration of the scan.\"\"\"\n        print('Scan took', self.format_time(t))",
  "class ScanningExperiment(ExperimentWithDataDeque):\n    \"\"\"\n    This class defines the core methods required for a threaded scanning experiment.\n    \"\"\"\n    def __init__(self):\n        super(ScanningExperiment, self).__init__()\n        self.status = 'inactive'\n        self.abort_requested = False\n        self.acquisition_thread = None\n\n    def run(self):\n        \"\"\"\n        Starts the scan in its own thread.\n\n        :return:\n        \"\"\"\n        if isinstance(self.acquisition_thread, Thread) and self.acquisition_thread.is_alive():\n            print('scan already running')\n            return\n        self.init_scan()\n        self.acquisition_thread = Thread(target=self.scan, args=())\n        self.acquisition_thread.start()\n        \n    def abort(self):\n        \"\"\"Requests an abort of the currently running grid scan.\"\"\"\n        if not hasattr(self, 'acquisition_thread'):\n            return\n        if self.acquisition_thread.is_alive():\n            print('aborting')\n            self.abort_requested = True\n            self.acquisition_thread.join()\n            \n    def init_scan(self):\n        \"\"\"\n        This is called before the experiment enters its own thread. Methods that should be\n        executed in the main thread should be called here (e.g. graphing).\n\n        :return:\n        \"\"\"\n        pass\n\n    def open_scan(self):\n        \"\"\"\n        This is called after the experiment enters its own thread to setup the scan. Methods\n        that should be executed in line with the experiment should be called here (e.g. data\n        storage).\n\n        :return:\n        \"\"\"\n        pass\n\n    def scan_function(self, index):\n        \"\"\"Applied at each position in the grid scan.\"\"\"\n        raise NotImplementedError\n    \n    def _timed_scan_function(self, index):\n        \"\"\"\n        Supplementary function that can be used\n\n        :param indices:\n        :return:\n        \"\"\"\n        t0 = time.time()\n        self.scan_function(index)\n        dt = time.time() - t0\n        self._step_times[index] = dt  # TODO: check initialisation of this\n        \n    def scan(self):\n        raise NotImplementedError\n        \n    def analyse_scan(self):\n        \"\"\"\n        This is called before the scan is closed to perform any final calculations.\n        :return:\n        \"\"\"\n        pass\n\n    def close_scan(self):\n        \"\"\"\n        Closes the scan whilst still in the experiment thread.\n\n        :return:\n        \"\"\"\n        self.update(force=True)\n        \n    def update(self, force=False):\n        \"\"\"\n        This is the function that is called in the event loop and at the end of the scan\n        and should be reimplemented when subclassing to deal with data updates and GUIs.\n        \"\"\"\n        pass",
  "class ScanningExperimentHDF5(ScanningExperiment):\n    \"\"\"\n    This class adds HDF5 file functionality for recording scans in a standardised manner.\n    \"\"\"\n    def __init__(self):\n        super(ScanningExperimentHDF5, self).__init__()\n        self.f = datafile.current()\n        self.data = None\n        self.description = ''\n\n    def __del__(self):\n        if isinstance(self.f, datafile.DataFile):\n            self.f.close()",
  "def __init__(self):\n        super(ScanningExperiment, self).__init__()\n        self.status = 'inactive'\n        self.abort_requested = False\n        self.acquisition_thread = None",
  "def run(self):\n        \"\"\"\n        Starts the scan in its own thread.\n\n        :return:\n        \"\"\"\n        if isinstance(self.acquisition_thread, Thread) and self.acquisition_thread.is_alive():\n            print('scan already running')\n            return\n        self.init_scan()\n        self.acquisition_thread = Thread(target=self.scan, args=())\n        self.acquisition_thread.start()",
  "def abort(self):\n        \"\"\"Requests an abort of the currently running grid scan.\"\"\"\n        if not hasattr(self, 'acquisition_thread'):\n            return\n        if self.acquisition_thread.is_alive():\n            print('aborting')\n            self.abort_requested = True\n            self.acquisition_thread.join()",
  "def init_scan(self):\n        \"\"\"\n        This is called before the experiment enters its own thread. Methods that should be\n        executed in the main thread should be called here (e.g. graphing).\n\n        :return:\n        \"\"\"\n        pass",
  "def open_scan(self):\n        \"\"\"\n        This is called after the experiment enters its own thread to setup the scan. Methods\n        that should be executed in line with the experiment should be called here (e.g. data\n        storage).\n\n        :return:\n        \"\"\"\n        pass",
  "def scan_function(self, index):\n        \"\"\"Applied at each position in the grid scan.\"\"\"\n        raise NotImplementedError",
  "def _timed_scan_function(self, index):\n        \"\"\"\n        Supplementary function that can be used\n\n        :param indices:\n        :return:\n        \"\"\"\n        t0 = time.time()\n        self.scan_function(index)\n        dt = time.time() - t0\n        self._step_times[index] = dt",
  "def scan(self):\n        raise NotImplementedError",
  "def analyse_scan(self):\n        \"\"\"\n        This is called before the scan is closed to perform any final calculations.\n        :return:\n        \"\"\"\n        pass",
  "def close_scan(self):\n        \"\"\"\n        Closes the scan whilst still in the experiment thread.\n\n        :return:\n        \"\"\"\n        self.update(force=True)",
  "def update(self, force=False):\n        \"\"\"\n        This is the function that is called in the event loop and at the end of the scan\n        and should be reimplemented when subclassing to deal with data updates and GUIs.\n        \"\"\"\n        pass",
  "def __init__(self):\n        super(ScanningExperimentHDF5, self).__init__()\n        self.f = datafile.current()\n        self.data = None\n        self.description = ''",
  "def __del__(self):\n        if isinstance(self.f, datafile.DataFile):\n            self.f.close()",
  "class ContinuousLinearStageScan(ContinuousLinearScan):\n    \"\"\"Continuous linear scan that specifically spatially scans using a stage.\"\"\"\n\n    @inherit_docstring(ContinuousLinearScan.__init__)\n    def __init__(self):\n        super(ContinuousLinearStageScan, self).__init__()\n        self.stage = None\n        self.axis = None\n\n    @inherit_docstring(ContinuousLinearScan.init_scan)\n    def init_scan(self):\n        if not isinstance(self.stage, Stage):\n            raise AttributeError(\"No stage has been set.\")\n\n    def set_stage(self, stage):\n        if not isinstance(stage, Stage):\n            raise ValueError(\"stage must be an instance of Stage.\")\n        self.stage = stage\n\n    @inherit_docstring(ContinuousLinearScan.set_parameter)\n    def set_parameter(self, value):\n        \"\"\"In this subclass the set parameter is the relative position. \"\"\"\n        self.stage.move(value, self.axis, relative=True)",
  "class ContinuousLinearStageScanQt(ContinuousLinearStageScan, ContinuousLinearScanQt):\n\n    @inherit_docstring(ContinuousLinearStageScan)\n    def __init__(self):\n        ContinuousLinearStageScan.__init__(self)\n        ContinuousLinearScanQt.__init__(self)\n\n    @inherit_docstring(ContinuousLinearScanQt.run)\n    def run(self, rate=0.1):\n        # explicitly inherit the method from ContinuousLinearScanQt\n        # otherwise method from ContinuousLinearScan may be called\n        ContinuousLinearScanQt.run(self, rate)\n\n    @inherit_docstring(ContinuousLinearScanQt.get_qt_ui)\n    def get_qt_ui(self):\n        # explicitly inherit the method from ContinuousLinearScanQt\n        # otherwise method from ContinuousLinearScan may be called\n        return ContinuousLinearScanQt.get_qt_ui(self)\n\n    @inherit_docstring(ContinuousLinearScanQt.get_qt_ui_cls)\n    @staticmethod\n    def get_qt_ui_cls():\n        # explicitly inherit the method from ContinuousLinearScanQt\n        # otherwise method from ContinuousLinearScan may be called\n        return ContinuousLinearScanQt.get_qt_ui_cls()\n\n    @inherit_docstring(ContinuousLinearScanQt.update)\n    def update(self, force=False):\n        # explicitly inherit the method from ContinuousLinearScanQt\n        # otherwise method from ContinuousLinearScan may be called\n        ContinuousLinearScanQt.update(self, force)",
  "def __init__(self):\n        super(ContinuousLinearStageScan, self).__init__()\n        self.stage = None\n        self.axis = None",
  "def init_scan(self):\n        if not isinstance(self.stage, Stage):\n            raise AttributeError(\"No stage has been set.\")",
  "def set_stage(self, stage):\n        if not isinstance(stage, Stage):\n            raise ValueError(\"stage must be an instance of Stage.\")\n        self.stage = stage",
  "def set_parameter(self, value):\n        \"\"\"In this subclass the set parameter is the relative position. \"\"\"\n        self.stage.move(value, self.axis, relative=True)",
  "def __init__(self):\n        ContinuousLinearStageScan.__init__(self)\n        ContinuousLinearScanQt.__init__(self)",
  "def run(self, rate=0.1):\n        # explicitly inherit the method from ContinuousLinearScanQt\n        # otherwise method from ContinuousLinearScan may be called\n        ContinuousLinearScanQt.run(self, rate)",
  "def get_qt_ui(self):\n        # explicitly inherit the method from ContinuousLinearScanQt\n        # otherwise method from ContinuousLinearScan may be called\n        return ContinuousLinearScanQt.get_qt_ui(self)",
  "def get_qt_ui_cls():\n        # explicitly inherit the method from ContinuousLinearScanQt\n        # otherwise method from ContinuousLinearScan may be called\n        return ContinuousLinearScanQt.get_qt_ui_cls()",
  "def update(self, force=False):\n        # explicitly inherit the method from ContinuousLinearScanQt\n        # otherwise method from ContinuousLinearScan may be called\n        ContinuousLinearScanQt.update(self, force)",
  "class DummyLinearStageScan(ContinuousLinearStageScanQt):\n        def __init__(self):\n            super(DummyLinearStageScan, self).__init__()\n            self.stage = None\n            self.axis = 'x'\n            self.step = 1.\n            self.direction = 1.\n            self.fig = Figure()\n            self.p = None\n            self.x = None\n            self.y = None\n        def open_scan(self):\n            self.fig.clear()\n            self.p = 0\n            self.d = []\n            self.x = []\n            self.y = []\n            self.ax = self.fig.add_subplot(111)\n        def scan_function(self, index):\n            time.sleep(0.01)\n            p = self.stage.get_position(self.axis)\n            self.d.append(index)\n            self.x.append(p)\n            self.y.append(np.sin(2*np.pi*0.01*p))\n            self.check_for_data_request(self.d, self.x, self.y)\n        def update(self, force=False):\n            super(DummyLinearStageScan, self).update(force)\n            if self.y == [] or self.fig.canvas is None:\n                return\n            if force:\n                data = (self.d, self.x, self.y)\n            else:\n                data = self.request_data()\n            if data is not False:\n                d, x, y = data\n                if not np.any(np.isfinite(y)):\n                    return\n                if not self.ax.lines:\n                    self.ax.plot(d, y)\n                else:\n                    l, = self.ax.lines\n                    l.set_data(d, y)\n                    self.ax.relim()\n                    self.ax.autoscale_view()\n                self.fig.canvas.draw()\n        def get_qt_ui(self):\n            return DummyLinearStageScanUI(self)\n        def calculate_feedback_input(self):\n            return self.y[-1]",
  "class DummyLinearStageScanUI(ContinuousLinearStageScanQt.get_qt_ui_cls()):\n        def __init__(self, linear_scan):\n            super(DummyLinearStageScanUI, self).__init__(linear_scan)\n            self.canvas = FigureCanvas(self.linear_scan.fig)\n            self.canvas.setMaximumSize(300,300)\n            self.layout.addWidget(self.canvas)\n            self.resize(self.sizeHint())",
  "def __init__(self):\n            super(DummyLinearStageScan, self).__init__()\n            self.stage = None\n            self.axis = 'x'\n            self.step = 1.\n            self.direction = 1.\n            self.fig = Figure()\n            self.p = None\n            self.x = None\n            self.y = None",
  "def open_scan(self):\n            self.fig.clear()\n            self.p = 0\n            self.d = []\n            self.x = []\n            self.y = []\n            self.ax = self.fig.add_subplot(111)",
  "def scan_function(self, index):\n            time.sleep(0.01)\n            p = self.stage.get_position(self.axis)\n            self.d.append(index)\n            self.x.append(p)\n            self.y.append(np.sin(2*np.pi*0.01*p))\n            self.check_for_data_request(self.d, self.x, self.y)",
  "def update(self, force=False):\n            super(DummyLinearStageScan, self).update(force)\n            if self.y == [] or self.fig.canvas is None:\n                return\n            if force:\n                data = (self.d, self.x, self.y)\n            else:\n                data = self.request_data()\n            if data is not False:\n                d, x, y = data\n                if not np.any(np.isfinite(y)):\n                    return\n                if not self.ax.lines:\n                    self.ax.plot(d, y)\n                else:\n                    l, = self.ax.lines\n                    l.set_data(d, y)\n                    self.ax.relim()\n                    self.ax.autoscale_view()\n                self.fig.canvas.draw()",
  "def get_qt_ui(self):\n            return DummyLinearStageScanUI(self)",
  "def calculate_feedback_input(self):\n            return self.y[-1]",
  "def __init__(self, linear_scan):\n            super(DummyLinearStageScanUI, self).__init__(linear_scan)\n            self.canvas = FigureCanvas(self.linear_scan.fig)\n            self.canvas.setMaximumSize(300,300)\n            self.layout.addWidget(self.canvas)\n            self.resize(self.sizeHint())",
  "class GridScan(ScanningExperiment, TimedScan):\n    \"\"\"\n    Note that the axes (x,y,z) will relate to the indices (z,y,x) as per array standards.\n    \"\"\"\n\n    def __init__(self):\n        ScanningExperiment.__init__(self)\n        TimedScan.__init__(self)\n        self.stage = Stage()\n        self.stage_units = 1\n        self.axes = list(self.stage.axis_names)\n        self.axes_names = list(str(ax) for ax in self.stage.axis_names)\n        self.size = 1. * np.ones(len(self.axes), dtype=np.float64)\n        self.step = 0.05 * np.ones(len(self.axes), dtype=np.float64)\n        self.init = np.zeros(len(self.axes), dtype=np.float64)\n        self.scan_axes = None\n        # underscored attributes are made into properties\n        self._num_axes = len(self.axes)\n        self._unit_conversion = {'nm': 1e-9, 'um': 1e-6, 'mm': 1e-3}\n        self._size_unit, self._step_unit, self._init_unit = ('um', 'um', 'um')\n        self.grid_shape = (0,0)\n        #self.init_grid(self.axes, self.size, self.step, self.init)\n\n    def _update_axes(self, num_axes):\n        \"\"\"\n        Updates all axes related objects (and sequence lengths) when the number of axes is changed.\n\n        :param num_axes: the new number of axes to scan\n        :return:\n        \"\"\"\n        self._num_axes = num_axes\n        # lists can be reassigned to copy\n        current_axes = self.axes\n        current_axes_names = self.axes_names\n        # numpy arrays must be explicitly copied\n        current_size, current_step, current_init = (self.size.copy(), self.step.copy(), self.init.copy())\n        if self.num_axes > len(current_axes):\n            self.axes = ['']*self.num_axes\n            self.axes_names = ['']*self.num_axes\n            self.size, self.step, self.init = (np.zeros(self.num_axes), np.zeros(self.num_axes), np.zeros(self.num_axes))\n            self.axes[:len(current_axes)] = current_axes\n            self.axes_names[:len(current_axes)] = current_axes_names\n            self.size[:len(current_axes)] = current_size\n            self.step[:len(current_axes)] = current_step\n            self.init[:len(current_axes)] = current_init\n        else:\n            self.axes = current_axes[:self.num_axes]\n            self.axes_names = current_axes_names[:self.num_axes]\n            self.size = current_size[:self.num_axes]\n            self.step = current_step[:self.num_axes]\n            self.init = current_init[:self.num_axes]\n\n    def rescale_parameter(self, param, value):\n        \"\"\"\n        Rescales the parameter (size, step or init) if its units are changed.\n\n        :param param:\n        :param value:\n        :return:\n        \"\"\"\n        if value not in self._unit_conversion:\n            raise ValueError('a valid unit must be supplied')\n        unit_param = '_%s_unit' % param\n        old_value = getattr(self, unit_param) if hasattr(self, unit_param) else value\n        setattr(self, unit_param, value)\n        a = getattr(self, param)\n        a *= old_div(self._unit_conversion[old_value], self._unit_conversion[value])\n\n    num_axes = property(fget=lambda self: self._num_axes, fset=_update_axes)\n    size_unit = property(fget=lambda self: self._size_unit,\n                         fset=lambda self, value: self.rescale_parameter('size', value))\n    step_unit = property(fget=lambda self: self._step_unit,\n                         fset=lambda self, value: self.rescale_parameter('step', value))\n    init_unit = property(fget=lambda self: self._init_unit,\n                         fset=lambda self, value: self.rescale_parameter('init', value))\n    si_size = property(fget=lambda self: self.size*self._unit_conversion[self.size_unit])\n    si_step = property(fget=lambda self: self.step*self._unit_conversion[self.step_unit])\n    si_init = property(fget=lambda self: self.init*self._unit_conversion[self.init_unit])\n\n    def run(self):\n        \"\"\"\n        Starts the grid scan in its own thread and runs the update function at the specified\n        rate whilst acquiring the data.\n\n        :param rate: the update period in seconds\n        :return:\n        \"\"\"\n        if isinstance(self.acquisition_thread, threading.Thread) and self.acquisition_thread.is_alive():\n            print('scan already running')\n            return\n        self.init_scan()\n        self.acquisition_thread = threading.Thread(target=self.scan,\n                                                   args=(self.axes, self.size, self.step, self.init))\n        self.acquisition_thread.start()\n\n    def init_grid(self, axes, size, step, init):\n        \"\"\"Create a grid on which to scan.\"\"\"\n        scan_axes = []\n        for i in range(len(axes)):\n            s = size[i] * self._unit_conversion[self.size_unit]\n            st = step[i] * self._unit_conversion[self.step_unit]\n            s0 = init[i] * self._unit_conversion[self.init_unit]\n            ax = np.arange(0, s+st/2., st) - s/2. + s0\n            scan_axes.append(ax)\n        self.grid_shape = tuple(ax.size for ax in scan_axes)\n        self.total_points = reduce(operator.mul, self.grid_shape, 1)\n        self.scan_axes = scan_axes\n        return scan_axes\n\n    def init_current_grid(self):\n        \"\"\"Convenience method that initialises a grid based on current parameters.\"\"\"\n        axes, size, step, init = (self.axes[::-1], self.size[::-1], self.step[::-1], self.init[::-1])\n        self.init_grid(axes, size, step, init)\n\n    def set_stage(self, stage, axes=None):\n        \"\"\"\n        Sets the stage and move methods.\n\n        :param axes: sequence of axes\n        \"\"\"\n        assert isinstance(stage, Stage), \"stage must be an instance of Stage.\"\n        self.stage = stage\n        #self.move = self.stage.move\n        if axes is None:\n            self.axes = list(self.stage.axis_names[:self.num_axes])\n        else:\n            for ax in axes:\n                if ax not in self.stage.axis_names:\n                    raise ValueError('one of the supplied axes are invalid (not found in the stage axis names)')\n            self.num_axes = len(axes)\n            self.axes = list(axes)\n        self.set_init_to_current_position()\n\n    def move(self, position, axis):\n        \"\"\"Move to a position along a given axis.\"\"\"\n        self.stage.move(old_div(position,self.stage_units), axis=axis)\n\n    def get_position(self, axis):\n        return self.stage.get_position(axis=axis) * self.stage_units\n    \n    def outer_loop_start(self):\n        \"\"\"This function is called before the scan happens, for each value of the outermost variable (usually Z)\"\"\"\n        pass\n    def middle_loop_start(self):\n        \"\"\"This function is called before the scan happens, for each value of the second-outermost variable (usually Y)\"\"\"\n        pass\n    def outer_loop_end(self):\n        \"\"\"This function is called after the scan happens, for each value of the outermost variable (usually Z)\"\"\"\n        pass\n    def middle_loop_end(self):\n        \"\"\"This function is called after the scan happens, for each value of the second-outermost variable (usually Y)\"\"\"\n        pass\n    def scan(self, axes, size, step, init):\n        \"\"\"Scans a grid, applying a function at each position.\"\"\"\n        self.abort_requested = False\n        axes, size, step, init = (axes[::-1], size[::-1], step[::-1], init[::-1])\n        scan_axes = self.init_grid(axes, size, step, init)\n        print(scan_axes)\n        self.open_scan()\n        # get the indices of points along each of the scan axes for use with snaking over array\n        pnts = [list(range(axis.size)) for axis in scan_axes]\n\n        self.indices = [-1,] * len(axes)\n        self._index = 0\n        self._step_times = np.zeros(self.grid_shape)\n        self._step_times.fill(np.nan)\n        self.status = 'acquiring data'\n        self.acquiring.set()\n        scan_start_time = time.time()\n        for k in pnts[0]:  # outer most axis\n            self.indices = list(self.indices)\n            self.indices[0] = k # Make sure indices is always up-to-date, for the drift compensation\n            if self.abort_requested:\n                break\n            self.outer_loop_start()\n            self.status = 'Scanning layer {0:d}/{1:d}'.format(k + 1, len(pnts[0]))\n            self.move(scan_axes[0][k], axes[0])\n            pnts[1] = pnts[1][::-1]  # reverse which way is iterated over each time\n            for j in pnts[1]:\n                if self.abort_requested:\n                    break\n                self.move(scan_axes[1][j], axes[1])\n                self.indices = list(self.indices)\n                self.indices[1] = j\n                if len(axes) == 3:  # for 3d grid (volume) scans\n                    self.middle_loop_start()\n                    pnts[2] = pnts[2][::-1]  # reverse which way is iterated over each time\n                    for i in pnts[2]:\n                        if self.abort_requested:\n                            break\n                        self.move(scan_axes[2][i], axes[2])\n                        self.indices[2] = i # These two lines are redundant.  TODO: pick one...\n                        #self.indices = (k, j, i) # keeping it as a list allows index assignment\n                        self.scan_function(k, j, i)\n                        self._step_times[k,j,i] = time.time()\n                        self._index += 1\n                    self.middle_loop_end()\n                elif len(axes) == 2:  # for regular 2d grid scans ignore third axis i\n                    self.indices = (k, j)\n                    self.scan_function(k, j)\n                    self._step_times[k,j] = time.time()\n                    self._index += 1\n            self.outer_loop_end()\n\n        self.print_scan_time(time.time() - scan_start_time)\n        self.acquiring.clear()\n        # move back to initial positions\n        for i in range(len(axes)):\n            self.move(init[i]*self._unit_conversion[self._init_unit], axes[i])\n        # finish the scan\n        self.analyse_scan()\n        self.close_scan()\n        self.status = 'scan complete'\n\n    def vary_axes(self, name, multiplier=2.):\n        if 'increase_size' in name:\n            self.size *= multiplier\n        elif 'decrease_size' in name:\n            self.size /= multiplier\n        elif 'increase_step' in name:\n            self.step *= multiplier\n        elif 'decrease_step' in name:\n            self.step /= multiplier\n\n    def set_init_to_current_position(self):\n        for i, ax in enumerate(self.axes):\n            self.init[i] = old_div(self.get_position(ax), self._unit_conversion[self.init_unit])",
  "class GridScanQt(GridScan, QtCore.QObject):\n    \"\"\"\n    A GridScanner subclass containing additional or redefined functions related to GUI operation.\n    \"\"\"\n\n    axes_updated = QtCore.Signal(list)\n    axes_names_updated = QtCore.Signal(list)\n    size_updated = QtCore.Signal(np.ndarray)\n    step_updated = QtCore.Signal(np.ndarray)\n    init_updated = QtCore.Signal(np.ndarray)\n    grid_shape_updated = QtCore.Signal(tuple)\n    total_points_updated = QtCore.Signal(int)\n    status_updated = QtCore.Signal(str)\n    timing_updated = QtCore.Signal(str)\n\n    def __init__(self):\n        GridScan.__init__(self)\n        QtCore.QObject.__init__(self)\n        self.timer = QtCore.QTimer()\n        self.timer.timeout.connect(self.update)\n\n    def run(self, rate=0.1):\n        super(GridScanQt, self).run()\n        self.acquiring.wait()\n        self.timer.start(1000*rate)\n\n    def get_qt_ui(self):\n        return GridScanUI(self)\n\n    @staticmethod\n    def get_qt_ui_cls():\n        return GridScanUI\n\n    def _update_axes(self, num_axes):\n        \"\"\"\n        This is called to emit a signal when the axes list is changed and update all dependencies.\n\n        :return:\n        \"\"\"\n        super(GridScanQt, self)._update_axes(num_axes)\n        self.axes_updated.emit(self.axes)\n\n    def init_grid(self, axes, size, step, init):\n        scan_axes = super(GridScanQt, self).init_grid(axes, size, step, init)\n        self.grid_shape_updated.emit(self.grid_shape)\n        self.total_points_updated.emit(self.total_points)\n        return scan_axes\n\n    def update(self, force=False):\n        \"\"\"\n        This is the function that is called in the event loop and at the end of the scan\n        and should be reimplemented when subclassing to deal with data updates and GUIs.\n        \"\"\"\n        if not self.acquisition_thread.is_alive():\n            self.timer.stop()\n        self.timing_updated.emit(self.get_formatted_estimated_time_remaining())\n        self.status_updated.emit('')\n\n    def rescale_parameter(self, param, value):\n        \"\"\"\n        Rescales the list or array-type axes grid parameters and emits the new values\n        to update the variables in the grid scanner.\n        \"\"\"\n        super(GridScanQt, self).rescale_parameter(param, value)\n        a = getattr(self, param)\n        updater = getattr(self, '%s_updated' % param)\n        updater.emit(a)\n\n    def vary_axes(self, name, multiplier=2.):\n        \"\"\"\n\n        :param name:\n        :param multiplier:\n        :return:\n        \"\"\"\n        param = name.split('_',1)[1]\n        super(GridScanQt, self).vary_axes(name, multiplier=2.)\n        getattr(self, '%s_updated' % param).emit(getattr(self, param))\n\n    def set_init_to_current_position(self):\n        super(GridScanQt, self).set_init_to_current_position()\n        self.init_updated.emit(self.init)\n\n    num_axes = property(fget=lambda self: getattr(self, '_num_axes'), fset=_update_axes)\n    size_unit = property(fget=lambda self: getattr(self, '_size_unit'),\n                         fset=lambda self, value: self.rescale_parameter('size', value))\n    step_unit = property(fget=lambda self: getattr(self, '_step_unit'),\n                         fset=lambda self, value: self.rescale_parameter('step', value))\n    init_unit = property(fget=lambda self: getattr(self, '_init_unit'),\n                         fset=lambda self, value: self.rescale_parameter('init', value))",
  "class GridScanUI(QtWidgets.QWidget, UiTools):\n    def __init__(self, grid_scanner):\n        assert isinstance(grid_scanner, GridScanQt), \"A valid GridScannerQT subclass must be supplied\"\n        super(GridScanUI, self).__init__()\n        self.grid_scanner = grid_scanner\n        #self.setupUi(self)\n        uic.loadUi(os.path.join(os.path.dirname(__file__), 'grid_scanner.ui'), self)\n\n        self.rate = 0.1\n\n        self.setWindowTitle(self.grid_scanner.__class__.__name__)\n\n        self.num_axes.setValidator(QtGui.QIntValidator())\n        self.num_axes.textChanged.connect(self.check_state)\n        self.num_axes.returnPressed.connect(self.renew_axes_ui)\n\n        # setting the lists in the GUI list views\n        # note that axes are always set as string so if a stage requires an integer as an\n        # axis identifier then it must be wrapped in an int() in the move function\n        for widget, list, param in zip([self.axes_view, self.axes_names_view, self.size_view, self.step_view, self.init_view],\n                                       [self.grid_scanner.axes, self.grid_scanner.axes_names, self.grid_scanner.size, self.grid_scanner.step, self.grid_scanner.init],\n                                       ['axes', 'axes_names', 'size', 'step', 'init']):\n            model = QtCore.QStringListModel([str(x) for x in list])\n            dtype = str if param in ['axes', 'axes_names'] else float\n            convert = False if param in ['axes', 'axes_names'] else True\n            model.dataChanged.connect(partial(self.set_param, param, dtype=dtype, convert=convert))\n            widget.setModel(model)\n\n        self.grid_scanner.axes_updated.connect(partial(self.update_param, 'axes'))\n        self.grid_scanner.axes_names_updated.connect(partial(self.update_param, 'axes_names'))\n        self.grid_scanner.size_updated.connect(partial(self.update_param, 'size'))\n        self.grid_scanner.step_updated.connect(partial(self.update_param, 'step'))\n        self.grid_scanner.init_updated.connect(partial(self.update_param, 'init'))\n\n        self.size_unit.activated[str].connect(partial(self.grid_scanner.rescale_parameter, 'size'))\n        self.step_unit.activated[str].connect(partial(self.grid_scanner.rescale_parameter, 'step'))\n        self.init_unit.activated[str].connect(partial(self.grid_scanner.rescale_parameter, 'init'))\n\n        self.size_up.clicked.connect(partial(self.grid_scanner.vary_axes, 'increase_size', 2.))\n        self.size_down.clicked.connect(partial(self.grid_scanner.vary_axes, 'decrease_size', 2.))\n        self.step_up.clicked.connect(partial(self.grid_scanner.vary_axes, 'increase_step', 2.))\n        self.step_down.clicked.connect(partial(self.grid_scanner.vary_axes, 'decrease_step', 2.))\n\n        self.grid_scanner.grid_shape_updated.connect(self.update_grid)\n        self.update_button.clicked.connect(self.grid_scanner.init_current_grid)\n        self.start_button.clicked.connect(self.on_click)\n        self.abort_button.clicked.connect(self.grid_scanner.abort)\n        self.grid_scanner.status_updated.connect(self.update_status)\n        self.grid_scanner.timing_updated.connect(self.update_timing)\n\n        self.num_axes.setText(str(self.grid_scanner.num_axes))\n        self.status.setText(self.grid_scanner.status)\n        self.size_unit.setCurrentIndex(self.size_unit.findText(self.grid_scanner.size_unit))\n        self.step_unit.setCurrentIndex(self.size_unit.findText(self.grid_scanner.step_unit))\n        self.init_unit.setCurrentIndex(self.size_unit.findText(self.grid_scanner.init_unit))\n\n        self.set_init_button.clicked.connect(self.on_click)\n\n        self.resize(self.sizeHint())\n\n    def on_click(self):\n        sender = self.sender()\n        if sender == self.start_button:\n            self.grid_scanner.run(self.rate)\n        elif sender == self.set_init_button:\n            self.grid_scanner.set_init_to_current_position()\n\n    def update_axes(self):\n        print(self.axes_view.model().stringList(), self.grid_scanner.axes,\\\n            self.size_view.model().stringList(), self.grid_scanner.size)\n\n    def update_grid(self):\n        self.gridshape.setText(str(self.grid_scanner.grid_shape))\n        self.gridshape.resize(self.gridshape.sizeHint())\n        self.total_points.setText(str(self.grid_scanner.total_points))\n        self.total_points.resize(self.total_points.sizeHint())\n        self.est_scan_time.setText(str(self.grid_scanner.estimate_scan_duration()))\n        self.est_scan_time.resize(self.est_scan_time.sizeHint())\n\n    def update_status(self):\n        self.status.setText(self.grid_scanner.status)\n\n    def update_timing(self, time):\n        self.est_time_remain.setText(time)\n\n    def set_param(self, param, dtype=float, convert=True):\n        \"\"\"\n        Apply changes made in the UI lists to the underlying GridScanner.\n        \"\"\"\n        uia = getattr(self, param+'_view')\n        a = [dtype(x) for x in uia.model().stringList()]\n        if convert:\n            a = np.array(a)\n        setattr(self.grid_scanner, param, a)\n\n    def update_param(self, param):\n        \"\"\"Update the UI list with changes from the underlying GridScanner.\"\"\"\n        gsa = getattr(self.grid_scanner, param)\n        uia = getattr(self, param+'_view')\n        uia.model().setStringList([str(x) for x in gsa])\n\n    def renew_axes_ui(self):\n        n = int(self.num_axes.text())\n        self.grid_scanner.num_axes = n\n        for param in ['axes', 'axes_names', 'size', 'step', 'init']:\n            self.update_param(param)",
  "def __init__(self):\n        ScanningExperiment.__init__(self)\n        TimedScan.__init__(self)\n        self.stage = Stage()\n        self.stage_units = 1\n        self.axes = list(self.stage.axis_names)\n        self.axes_names = list(str(ax) for ax in self.stage.axis_names)\n        self.size = 1. * np.ones(len(self.axes), dtype=np.float64)\n        self.step = 0.05 * np.ones(len(self.axes), dtype=np.float64)\n        self.init = np.zeros(len(self.axes), dtype=np.float64)\n        self.scan_axes = None\n        # underscored attributes are made into properties\n        self._num_axes = len(self.axes)\n        self._unit_conversion = {'nm': 1e-9, 'um': 1e-6, 'mm': 1e-3}\n        self._size_unit, self._step_unit, self._init_unit = ('um', 'um', 'um')\n        self.grid_shape = (0,0)",
  "def _update_axes(self, num_axes):\n        \"\"\"\n        Updates all axes related objects (and sequence lengths) when the number of axes is changed.\n\n        :param num_axes: the new number of axes to scan\n        :return:\n        \"\"\"\n        self._num_axes = num_axes\n        # lists can be reassigned to copy\n        current_axes = self.axes\n        current_axes_names = self.axes_names\n        # numpy arrays must be explicitly copied\n        current_size, current_step, current_init = (self.size.copy(), self.step.copy(), self.init.copy())\n        if self.num_axes > len(current_axes):\n            self.axes = ['']*self.num_axes\n            self.axes_names = ['']*self.num_axes\n            self.size, self.step, self.init = (np.zeros(self.num_axes), np.zeros(self.num_axes), np.zeros(self.num_axes))\n            self.axes[:len(current_axes)] = current_axes\n            self.axes_names[:len(current_axes)] = current_axes_names\n            self.size[:len(current_axes)] = current_size\n            self.step[:len(current_axes)] = current_step\n            self.init[:len(current_axes)] = current_init\n        else:\n            self.axes = current_axes[:self.num_axes]\n            self.axes_names = current_axes_names[:self.num_axes]\n            self.size = current_size[:self.num_axes]\n            self.step = current_step[:self.num_axes]\n            self.init = current_init[:self.num_axes]",
  "def rescale_parameter(self, param, value):\n        \"\"\"\n        Rescales the parameter (size, step or init) if its units are changed.\n\n        :param param:\n        :param value:\n        :return:\n        \"\"\"\n        if value not in self._unit_conversion:\n            raise ValueError('a valid unit must be supplied')\n        unit_param = '_%s_unit' % param\n        old_value = getattr(self, unit_param) if hasattr(self, unit_param) else value\n        setattr(self, unit_param, value)\n        a = getattr(self, param)\n        a *= old_div(self._unit_conversion[old_value], self._unit_conversion[value])",
  "def run(self):\n        \"\"\"\n        Starts the grid scan in its own thread and runs the update function at the specified\n        rate whilst acquiring the data.\n\n        :param rate: the update period in seconds\n        :return:\n        \"\"\"\n        if isinstance(self.acquisition_thread, threading.Thread) and self.acquisition_thread.is_alive():\n            print('scan already running')\n            return\n        self.init_scan()\n        self.acquisition_thread = threading.Thread(target=self.scan,\n                                                   args=(self.axes, self.size, self.step, self.init))\n        self.acquisition_thread.start()",
  "def init_grid(self, axes, size, step, init):\n        \"\"\"Create a grid on which to scan.\"\"\"\n        scan_axes = []\n        for i in range(len(axes)):\n            s = size[i] * self._unit_conversion[self.size_unit]\n            st = step[i] * self._unit_conversion[self.step_unit]\n            s0 = init[i] * self._unit_conversion[self.init_unit]\n            ax = np.arange(0, s+st/2., st) - s/2. + s0\n            scan_axes.append(ax)\n        self.grid_shape = tuple(ax.size for ax in scan_axes)\n        self.total_points = reduce(operator.mul, self.grid_shape, 1)\n        self.scan_axes = scan_axes\n        return scan_axes",
  "def init_current_grid(self):\n        \"\"\"Convenience method that initialises a grid based on current parameters.\"\"\"\n        axes, size, step, init = (self.axes[::-1], self.size[::-1], self.step[::-1], self.init[::-1])\n        self.init_grid(axes, size, step, init)",
  "def set_stage(self, stage, axes=None):\n        \"\"\"\n        Sets the stage and move methods.\n\n        :param axes: sequence of axes\n        \"\"\"\n        assert isinstance(stage, Stage), \"stage must be an instance of Stage.\"\n        self.stage = stage\n        #self.move = self.stage.move\n        if axes is None:\n            self.axes = list(self.stage.axis_names[:self.num_axes])\n        else:\n            for ax in axes:\n                if ax not in self.stage.axis_names:\n                    raise ValueError('one of the supplied axes are invalid (not found in the stage axis names)')\n            self.num_axes = len(axes)\n            self.axes = list(axes)\n        self.set_init_to_current_position()",
  "def move(self, position, axis):\n        \"\"\"Move to a position along a given axis.\"\"\"\n        self.stage.move(old_div(position,self.stage_units), axis=axis)",
  "def get_position(self, axis):\n        return self.stage.get_position(axis=axis) * self.stage_units",
  "def outer_loop_start(self):\n        \"\"\"This function is called before the scan happens, for each value of the outermost variable (usually Z)\"\"\"\n        pass",
  "def middle_loop_start(self):\n        \"\"\"This function is called before the scan happens, for each value of the second-outermost variable (usually Y)\"\"\"\n        pass",
  "def outer_loop_end(self):\n        \"\"\"This function is called after the scan happens, for each value of the outermost variable (usually Z)\"\"\"\n        pass",
  "def middle_loop_end(self):\n        \"\"\"This function is called after the scan happens, for each value of the second-outermost variable (usually Y)\"\"\"\n        pass",
  "def scan(self, axes, size, step, init):\n        \"\"\"Scans a grid, applying a function at each position.\"\"\"\n        self.abort_requested = False\n        axes, size, step, init = (axes[::-1], size[::-1], step[::-1], init[::-1])\n        scan_axes = self.init_grid(axes, size, step, init)\n        print(scan_axes)\n        self.open_scan()\n        # get the indices of points along each of the scan axes for use with snaking over array\n        pnts = [list(range(axis.size)) for axis in scan_axes]\n\n        self.indices = [-1,] * len(axes)\n        self._index = 0\n        self._step_times = np.zeros(self.grid_shape)\n        self._step_times.fill(np.nan)\n        self.status = 'acquiring data'\n        self.acquiring.set()\n        scan_start_time = time.time()\n        for k in pnts[0]:  # outer most axis\n            self.indices = list(self.indices)\n            self.indices[0] = k # Make sure indices is always up-to-date, for the drift compensation\n            if self.abort_requested:\n                break\n            self.outer_loop_start()\n            self.status = 'Scanning layer {0:d}/{1:d}'.format(k + 1, len(pnts[0]))\n            self.move(scan_axes[0][k], axes[0])\n            pnts[1] = pnts[1][::-1]  # reverse which way is iterated over each time\n            for j in pnts[1]:\n                if self.abort_requested:\n                    break\n                self.move(scan_axes[1][j], axes[1])\n                self.indices = list(self.indices)\n                self.indices[1] = j\n                if len(axes) == 3:  # for 3d grid (volume) scans\n                    self.middle_loop_start()\n                    pnts[2] = pnts[2][::-1]  # reverse which way is iterated over each time\n                    for i in pnts[2]:\n                        if self.abort_requested:\n                            break\n                        self.move(scan_axes[2][i], axes[2])\n                        self.indices[2] = i # These two lines are redundant.  TODO: pick one...\n                        #self.indices = (k, j, i) # keeping it as a list allows index assignment\n                        self.scan_function(k, j, i)\n                        self._step_times[k,j,i] = time.time()\n                        self._index += 1\n                    self.middle_loop_end()\n                elif len(axes) == 2:  # for regular 2d grid scans ignore third axis i\n                    self.indices = (k, j)\n                    self.scan_function(k, j)\n                    self._step_times[k,j] = time.time()\n                    self._index += 1\n            self.outer_loop_end()\n\n        self.print_scan_time(time.time() - scan_start_time)\n        self.acquiring.clear()\n        # move back to initial positions\n        for i in range(len(axes)):\n            self.move(init[i]*self._unit_conversion[self._init_unit], axes[i])\n        # finish the scan\n        self.analyse_scan()\n        self.close_scan()\n        self.status = 'scan complete'",
  "def vary_axes(self, name, multiplier=2.):\n        if 'increase_size' in name:\n            self.size *= multiplier\n        elif 'decrease_size' in name:\n            self.size /= multiplier\n        elif 'increase_step' in name:\n            self.step *= multiplier\n        elif 'decrease_step' in name:\n            self.step /= multiplier",
  "def set_init_to_current_position(self):\n        for i, ax in enumerate(self.axes):\n            self.init[i] = old_div(self.get_position(ax), self._unit_conversion[self.init_unit])",
  "def __init__(self):\n        GridScan.__init__(self)\n        QtCore.QObject.__init__(self)\n        self.timer = QtCore.QTimer()\n        self.timer.timeout.connect(self.update)",
  "def run(self, rate=0.1):\n        super(GridScanQt, self).run()\n        self.acquiring.wait()\n        self.timer.start(1000*rate)",
  "def get_qt_ui(self):\n        return GridScanUI(self)",
  "def get_qt_ui_cls():\n        return GridScanUI",
  "def _update_axes(self, num_axes):\n        \"\"\"\n        This is called to emit a signal when the axes list is changed and update all dependencies.\n\n        :return:\n        \"\"\"\n        super(GridScanQt, self)._update_axes(num_axes)\n        self.axes_updated.emit(self.axes)",
  "def init_grid(self, axes, size, step, init):\n        scan_axes = super(GridScanQt, self).init_grid(axes, size, step, init)\n        self.grid_shape_updated.emit(self.grid_shape)\n        self.total_points_updated.emit(self.total_points)\n        return scan_axes",
  "def update(self, force=False):\n        \"\"\"\n        This is the function that is called in the event loop and at the end of the scan\n        and should be reimplemented when subclassing to deal with data updates and GUIs.\n        \"\"\"\n        if not self.acquisition_thread.is_alive():\n            self.timer.stop()\n        self.timing_updated.emit(self.get_formatted_estimated_time_remaining())\n        self.status_updated.emit('')",
  "def rescale_parameter(self, param, value):\n        \"\"\"\n        Rescales the list or array-type axes grid parameters and emits the new values\n        to update the variables in the grid scanner.\n        \"\"\"\n        super(GridScanQt, self).rescale_parameter(param, value)\n        a = getattr(self, param)\n        updater = getattr(self, '%s_updated' % param)\n        updater.emit(a)",
  "def vary_axes(self, name, multiplier=2.):\n        \"\"\"\n\n        :param name:\n        :param multiplier:\n        :return:\n        \"\"\"\n        param = name.split('_',1)[1]\n        super(GridScanQt, self).vary_axes(name, multiplier=2.)\n        getattr(self, '%s_updated' % param).emit(getattr(self, param))",
  "def set_init_to_current_position(self):\n        super(GridScanQt, self).set_init_to_current_position()\n        self.init_updated.emit(self.init)",
  "def __init__(self, grid_scanner):\n        assert isinstance(grid_scanner, GridScanQt), \"A valid GridScannerQT subclass must be supplied\"\n        super(GridScanUI, self).__init__()\n        self.grid_scanner = grid_scanner\n        #self.setupUi(self)\n        uic.loadUi(os.path.join(os.path.dirname(__file__), 'grid_scanner.ui'), self)\n\n        self.rate = 0.1\n\n        self.setWindowTitle(self.grid_scanner.__class__.__name__)\n\n        self.num_axes.setValidator(QtGui.QIntValidator())\n        self.num_axes.textChanged.connect(self.check_state)\n        self.num_axes.returnPressed.connect(self.renew_axes_ui)\n\n        # setting the lists in the GUI list views\n        # note that axes are always set as string so if a stage requires an integer as an\n        # axis identifier then it must be wrapped in an int() in the move function\n        for widget, list, param in zip([self.axes_view, self.axes_names_view, self.size_view, self.step_view, self.init_view],\n                                       [self.grid_scanner.axes, self.grid_scanner.axes_names, self.grid_scanner.size, self.grid_scanner.step, self.grid_scanner.init],\n                                       ['axes', 'axes_names', 'size', 'step', 'init']):\n            model = QtCore.QStringListModel([str(x) for x in list])\n            dtype = str if param in ['axes', 'axes_names'] else float\n            convert = False if param in ['axes', 'axes_names'] else True\n            model.dataChanged.connect(partial(self.set_param, param, dtype=dtype, convert=convert))\n            widget.setModel(model)\n\n        self.grid_scanner.axes_updated.connect(partial(self.update_param, 'axes'))\n        self.grid_scanner.axes_names_updated.connect(partial(self.update_param, 'axes_names'))\n        self.grid_scanner.size_updated.connect(partial(self.update_param, 'size'))\n        self.grid_scanner.step_updated.connect(partial(self.update_param, 'step'))\n        self.grid_scanner.init_updated.connect(partial(self.update_param, 'init'))\n\n        self.size_unit.activated[str].connect(partial(self.grid_scanner.rescale_parameter, 'size'))\n        self.step_unit.activated[str].connect(partial(self.grid_scanner.rescale_parameter, 'step'))\n        self.init_unit.activated[str].connect(partial(self.grid_scanner.rescale_parameter, 'init'))\n\n        self.size_up.clicked.connect(partial(self.grid_scanner.vary_axes, 'increase_size', 2.))\n        self.size_down.clicked.connect(partial(self.grid_scanner.vary_axes, 'decrease_size', 2.))\n        self.step_up.clicked.connect(partial(self.grid_scanner.vary_axes, 'increase_step', 2.))\n        self.step_down.clicked.connect(partial(self.grid_scanner.vary_axes, 'decrease_step', 2.))\n\n        self.grid_scanner.grid_shape_updated.connect(self.update_grid)\n        self.update_button.clicked.connect(self.grid_scanner.init_current_grid)\n        self.start_button.clicked.connect(self.on_click)\n        self.abort_button.clicked.connect(self.grid_scanner.abort)\n        self.grid_scanner.status_updated.connect(self.update_status)\n        self.grid_scanner.timing_updated.connect(self.update_timing)\n\n        self.num_axes.setText(str(self.grid_scanner.num_axes))\n        self.status.setText(self.grid_scanner.status)\n        self.size_unit.setCurrentIndex(self.size_unit.findText(self.grid_scanner.size_unit))\n        self.step_unit.setCurrentIndex(self.size_unit.findText(self.grid_scanner.step_unit))\n        self.init_unit.setCurrentIndex(self.size_unit.findText(self.grid_scanner.init_unit))\n\n        self.set_init_button.clicked.connect(self.on_click)\n\n        self.resize(self.sizeHint())",
  "def on_click(self):\n        sender = self.sender()\n        if sender == self.start_button:\n            self.grid_scanner.run(self.rate)\n        elif sender == self.set_init_button:\n            self.grid_scanner.set_init_to_current_position()",
  "def update_axes(self):\n        print(self.axes_view.model().stringList(), self.grid_scanner.axes,\\\n            self.size_view.model().stringList(), self.grid_scanner.size)",
  "def update_grid(self):\n        self.gridshape.setText(str(self.grid_scanner.grid_shape))\n        self.gridshape.resize(self.gridshape.sizeHint())\n        self.total_points.setText(str(self.grid_scanner.total_points))\n        self.total_points.resize(self.total_points.sizeHint())\n        self.est_scan_time.setText(str(self.grid_scanner.estimate_scan_duration()))\n        self.est_scan_time.resize(self.est_scan_time.sizeHint())",
  "def update_status(self):\n        self.status.setText(self.grid_scanner.status)",
  "def update_timing(self, time):\n        self.est_time_remain.setText(time)",
  "def set_param(self, param, dtype=float, convert=True):\n        \"\"\"\n        Apply changes made in the UI lists to the underlying GridScanner.\n        \"\"\"\n        uia = getattr(self, param+'_view')\n        a = [dtype(x) for x in uia.model().stringList()]\n        if convert:\n            a = np.array(a)\n        setattr(self.grid_scanner, param, a)",
  "def update_param(self, param):\n        \"\"\"Update the UI list with changes from the underlying GridScanner.\"\"\"\n        gsa = getattr(self.grid_scanner, param)\n        uia = getattr(self, param+'_view')\n        uia.model().setStringList([str(x) for x in gsa])",
  "def renew_axes_ui(self):\n        n = int(self.num_axes.text())\n        self.grid_scanner.num_axes = n\n        for param in ['axes', 'axes_names', 'size', 'step', 'init']:\n            self.update_param(param)",
  "class DummyGridScan(template):\n        def __init__(self):\n            super(DummyGridScan, self).__init__()\n            self.estimated_step_time = 0.0005\n            self.fig = Figure()\n            self.data = None\n        def open_scan(self):\n            self.fig.clear()\n            self.data = np.zeros(self.grid_shape, dtype=np.float64)\n            self.data.fill(np.nan)\n            self.ax = self.fig.add_subplot(111)\n            self.ax.set_aspect('equal')\n            mult = 1./self._unit_conversion[self.size_unit]\n            x, y = (mult*self.scan_axes[-1], mult*self.scan_axes[-2])\n            self.ax.set_xlim(x.min(), x.max())\n            self.ax.set_ylim(y.min(), y.max())\n        def scan_function(self, *indices):\n            time.sleep(0.0005)\n            x,y = (self.scan_axes[-1][indices[-1]], self.scan_axes[-2][indices[-2]])\n            self.data[indices] = np.sin(2*np.pi*2e6*x) * np.cos(2*np.pi*2e6*y)\n            if self.num_axes == 2:\n                self.check_for_data_request(self.data)\n            elif self.num_axes == 3:\n                self.check_for_data_request(self.data[indices[0],:,:])\n        #@profile\n        #def start(self, rate=0.1):\n        #    super(DummyGridScanner, self).start(0.1)\n        def run(self, rate=0.1):\n            fname = 'profiling.stats'\n            cProfile.runctx('super(DummyGridScan, self).run(%.2f)'%rate, globals(), locals(), filename=fname)\n            stats = pstats.Stats(fname)\n            stats.strip_dirs()\n            stats.sort_stats('cumulative')\n            stats.print_stats()\n        def update(self, force=False):\n            super(DummyGridScan, self).update(force)\n            if self.data is None or self.fig.canvas is None:\n                print('no canvas or data')\n                return\n            if force:\n                data = (self.data,)\n            else:\n                data = self.request_data()\n            if data is not False:\n                data, = data\n                if not np.any(np.isfinite(data)):\n                    return\n                if not self.ax.collections:\n                    mult = 1./self._unit_conversion[self.size_unit]\n                    self.ax.pcolormesh(mult*self.scan_axes[-1], mult*self.scan_axes[-2], data)\n                    cid = self.fig.canvas.mpl_connect('button_press_event', self.onclick)\n                    cid = self.fig.canvas.mpl_connect('pick_event', self.onpick4)\n                else:\n                    img, = self.ax.collections\n                    img.set_array(data[:-1,:-1].ravel())\n                    try:\n                        img_min = data[np.isfinite(data)].min()\n                        img_max = data[np.isfinite(data)].max()\n                    except ValueError:\n                        print('There may have been a NaN error')\n                        img_min=0\n                        img_max=1\n                    img.set_clim(img_min, img_max)\n                    self.ax.relim()\n                self.fig.canvas.draw()\n        def get_qt_ui(self):\n            return DummyGridScanUI(self)\n        def onclick(self, event):\n            print('button=%d, x=%d, y=%d, xdata=%f, ydata=%f'%(\n            event.button, event.x, event.y, event.xdata, event.ydata))\n            init_scale = old_div(self._unit_conversion[self.size_unit], self._unit_conversion[self.init_unit])\n            self.init[:2] = (event.xdata * init_scale, event.ydata * init_scale)\n            self.init_updated.emit(self.init)\n        def onpick4(self, event):\n            artist = event.artist\n            if isinstance(artist, matplotlib.image.AxesImage):\n                im = artist\n                A = im.get_array()\n                print(('onpick4 image', A.shape))",
  "class DummyGridScanUI(GridScanUI):\n        def __init__(self, grid_scanner):\n            super(DummyGridScanUI, self).__init__(grid_scanner)\n            self.canvas = FigureCanvas(self.grid_scanner.fig)\n            self.canvas.setMaximumSize(300,300)\n            self.layout.addWidget(self.canvas)\n            self.resize(self.sizeHint())",
  "def __init__(self):\n            super(DummyGridScan, self).__init__()\n            self.estimated_step_time = 0.0005\n            self.fig = Figure()\n            self.data = None",
  "def open_scan(self):\n            self.fig.clear()\n            self.data = np.zeros(self.grid_shape, dtype=np.float64)\n            self.data.fill(np.nan)\n            self.ax = self.fig.add_subplot(111)\n            self.ax.set_aspect('equal')\n            mult = 1./self._unit_conversion[self.size_unit]\n            x, y = (mult*self.scan_axes[-1], mult*self.scan_axes[-2])\n            self.ax.set_xlim(x.min(), x.max())\n            self.ax.set_ylim(y.min(), y.max())",
  "def scan_function(self, *indices):\n            time.sleep(0.0005)\n            x,y = (self.scan_axes[-1][indices[-1]], self.scan_axes[-2][indices[-2]])\n            self.data[indices] = np.sin(2*np.pi*2e6*x) * np.cos(2*np.pi*2e6*y)\n            if self.num_axes == 2:\n                self.check_for_data_request(self.data)\n            elif self.num_axes == 3:\n                self.check_for_data_request(self.data[indices[0],:,:])",
  "def run(self, rate=0.1):\n            fname = 'profiling.stats'\n            cProfile.runctx('super(DummyGridScan, self).run(%.2f)'%rate, globals(), locals(), filename=fname)\n            stats = pstats.Stats(fname)\n            stats.strip_dirs()\n            stats.sort_stats('cumulative')\n            stats.print_stats()",
  "def update(self, force=False):\n            super(DummyGridScan, self).update(force)\n            if self.data is None or self.fig.canvas is None:\n                print('no canvas or data')\n                return\n            if force:\n                data = (self.data,)\n            else:\n                data = self.request_data()\n            if data is not False:\n                data, = data\n                if not np.any(np.isfinite(data)):\n                    return\n                if not self.ax.collections:\n                    mult = 1./self._unit_conversion[self.size_unit]\n                    self.ax.pcolormesh(mult*self.scan_axes[-1], mult*self.scan_axes[-2], data)\n                    cid = self.fig.canvas.mpl_connect('button_press_event', self.onclick)\n                    cid = self.fig.canvas.mpl_connect('pick_event', self.onpick4)\n                else:\n                    img, = self.ax.collections\n                    img.set_array(data[:-1,:-1].ravel())\n                    try:\n                        img_min = data[np.isfinite(data)].min()\n                        img_max = data[np.isfinite(data)].max()\n                    except ValueError:\n                        print('There may have been a NaN error')\n                        img_min=0\n                        img_max=1\n                    img.set_clim(img_min, img_max)\n                    self.ax.relim()\n                self.fig.canvas.draw()",
  "def get_qt_ui(self):\n            return DummyGridScanUI(self)",
  "def onclick(self, event):\n            print('button=%d, x=%d, y=%d, xdata=%f, ydata=%f'%(\n            event.button, event.x, event.y, event.xdata, event.ydata))\n            init_scale = old_div(self._unit_conversion[self.size_unit], self._unit_conversion[self.init_unit])\n            self.init[:2] = (event.xdata * init_scale, event.ydata * init_scale)\n            self.init_updated.emit(self.init)",
  "def onpick4(self, event):\n            artist = event.artist\n            if isinstance(artist, matplotlib.image.AxesImage):\n                im = artist\n                A = im.get_array()\n                print(('onpick4 image', A.shape))",
  "def __init__(self, grid_scanner):\n            super(DummyGridScanUI, self).__init__(grid_scanner)\n            self.canvas = FigureCanvas(self.grid_scanner.fig)\n            self.canvas.setMaximumSize(300,300)\n            self.layout.addWidget(self.canvas)\n            self.resize(self.sizeHint())"
]