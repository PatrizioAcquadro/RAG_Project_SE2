[
  "def _python_cmd(*args):\n    \"\"\"\n    Execute a command.\n\n    Return True if the command succeeded.\n    \"\"\"\n    args = (sys.executable,) + args\n    return subprocess.call(args) == 0",
  "def _install(archive_filename, install_args=()):\n    \"\"\"Install Setuptools.\"\"\"\n    with archive_context(archive_filename):\n        # installing\n        log.warn('Installing Setuptools')\n        if not _python_cmd('setup.py', 'install', *install_args):\n            log.warn('Something went wrong during the installation.')\n            log.warn('See the error message above.')\n            # exitcode will be 2\n            return 2",
  "def _build_egg(egg, archive_filename, to_dir):\n    \"\"\"Build Setuptools egg.\"\"\"\n    with archive_context(archive_filename):\n        # building an egg\n        log.warn('Building a Setuptools egg in %s', to_dir)\n        _python_cmd('setup.py', '-q', 'bdist_egg', '--dist-dir', to_dir)\n    # returning the result\n    log.warn(egg)\n    if not os.path.exists(egg):\n        raise IOError('Could not build the egg.')",
  "class ContextualZipFile(zipfile.ZipFile):\n\n    \"\"\"Supplement ZipFile class to support context manager for Python 2.6.\"\"\"\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, type, value, traceback):\n        self.close()\n\n    def __new__(cls, *args, **kwargs):\n        \"\"\"Construct a ZipFile or ContextualZipFile as appropriate.\"\"\"\n        if hasattr(zipfile.ZipFile, '__exit__'):\n            return zipfile.ZipFile(*args, **kwargs)\n        return super(ContextualZipFile, cls).__new__(cls)",
  "def archive_context(filename):\n    \"\"\"\n    Unzip filename to a temporary directory, set to the cwd.\n\n    The unzipped target is cleaned up after.\n    \"\"\"\n    tmpdir = tempfile.mkdtemp()\n    log.warn('Extracting in %s', tmpdir)\n    old_wd = os.getcwd()\n    try:\n        os.chdir(tmpdir)\n        with ContextualZipFile(filename) as archive:\n            archive.extractall()\n\n        # going in the directory\n        subdir = os.path.join(tmpdir, os.listdir(tmpdir)[0])\n        os.chdir(subdir)\n        log.warn('Now working in %s', subdir)\n        yield\n\n    finally:\n        os.chdir(old_wd)\n        shutil.rmtree(tmpdir)",
  "def _do_download(version, download_base, to_dir, download_delay):\n    \"\"\"Download Setuptools.\"\"\"\n    egg = os.path.join(to_dir, 'setuptools-%s-py%d.%d.egg'\n                       % (version, sys.version_info[0], sys.version_info[1]))\n    if not os.path.exists(egg):\n        archive = download_setuptools(version, download_base,\n                                      to_dir, download_delay)\n        _build_egg(egg, archive, to_dir)\n    sys.path.insert(0, egg)\n\n    # Remove previously-imported pkg_resources if present (see\n    # https://bitbucket.org/pypa/setuptools/pull-request/7/ for details).\n    if 'pkg_resources' in sys.modules:\n        del sys.modules['pkg_resources']\n\n    import setuptools\n    setuptools.bootstrap_install_from = egg",
  "def use_setuptools(\n        version=DEFAULT_VERSION, download_base=DEFAULT_URL,\n        to_dir=DEFAULT_SAVE_DIR, download_delay=15):\n    \"\"\"\n    Ensure that a setuptools version is installed.\n\n    Return None. Raise SystemExit if the requested version\n    or later cannot be installed.\n    \"\"\"\n    to_dir = os.path.abspath(to_dir)\n\n    # prior to importing, capture the module state for\n    # representative modules.\n    rep_modules = 'pkg_resources', 'setuptools'\n    imported = set(sys.modules).intersection(rep_modules)\n\n    try:\n        import pkg_resources\n        pkg_resources.require(\"setuptools>=\" + version)\n        # a suitable version is already installed\n        return\n    except ImportError:\n        # pkg_resources not available; setuptools is not installed; download\n        pass\n    except pkg_resources.DistributionNotFound:\n        # no version of setuptools was found; allow download\n        pass\n    except pkg_resources.VersionConflict as VC_err:\n        if imported:\n            _conflict_bail(VC_err, version)\n\n        # otherwise, unload pkg_resources to allow the downloaded version to\n        #  take precedence.\n        del pkg_resources\n        _unload_pkg_resources()\n\n    return _do_download(version, download_base, to_dir, download_delay)",
  "def _conflict_bail(VC_err, version):\n    \"\"\"\n    Setuptools was imported prior to invocation, so it is\n    unsafe to unload it. Bail out.\n    \"\"\"\n    conflict_tmpl = textwrap.dedent(\"\"\"\n        The required version of setuptools (>={version}) is not available,\n        and can't be installed while this script is running. Please\n        install a more recent version first, using\n        'easy_install -U setuptools'.\n\n        (Currently using {VC_err.args[0]!r})\n        \"\"\")\n    msg = conflict_tmpl.format(**locals())\n    sys.stderr.write(msg)\n    sys.exit(2)",
  "def _unload_pkg_resources():\n    del_modules = [\n        name for name in sys.modules\n        if name.startswith('pkg_resources')\n    ]\n    for mod_name in del_modules:\n        del sys.modules[mod_name]",
  "def _clean_check(cmd, target):\n    \"\"\"\n    Run the command to download target.\n\n    If the command fails, clean up before re-raising the error.\n    \"\"\"\n    try:\n        subprocess.check_call(cmd)\n    except subprocess.CalledProcessError:\n        if os.access(target, os.F_OK):\n            os.unlink(target)\n        raise",
  "def download_file_powershell(url, target):\n    \"\"\"\n    Download the file at url to target using Powershell.\n\n    Powershell will validate trust.\n    Raise an exception if the command cannot complete.\n    \"\"\"\n    target = os.path.abspath(target)\n    ps_cmd = (\n        \"[System.Net.WebRequest]::DefaultWebProxy.Credentials = \"\n        \"[System.Net.CredentialCache]::DefaultCredentials; \"\n        \"(new-object System.Net.WebClient).DownloadFile(%(url)r, %(target)r)\"\n        % vars()\n    )\n    cmd = [\n        'powershell',\n        '-Command',\n        ps_cmd,\n    ]\n    _clean_check(cmd, target)",
  "def has_powershell():\n    \"\"\"Determine if Powershell is available.\"\"\"\n    if platform.system() != 'Windows':\n        return False\n    cmd = ['powershell', '-Command', 'echo test']\n    with open(os.path.devnull, 'wb') as devnull:\n        try:\n            subprocess.check_call(cmd, stdout=devnull, stderr=devnull)\n        except Exception:\n            return False\n    return True",
  "def download_file_curl(url, target):\n    cmd = ['curl', url, '--silent', '--output', target]\n    _clean_check(cmd, target)",
  "def has_curl():\n    cmd = ['curl', '--version']\n    with open(os.path.devnull, 'wb') as devnull:\n        try:\n            subprocess.check_call(cmd, stdout=devnull, stderr=devnull)\n        except Exception:\n            return False\n    return True",
  "def download_file_wget(url, target):\n    cmd = ['wget', url, '--quiet', '--output-document', target]\n    _clean_check(cmd, target)",
  "def has_wget():\n    cmd = ['wget', '--version']\n    with open(os.path.devnull, 'wb') as devnull:\n        try:\n            subprocess.check_call(cmd, stdout=devnull, stderr=devnull)\n        except Exception:\n            return False\n    return True",
  "def download_file_insecure(url, target):\n    \"\"\"Use Python to download the file, without connection authentication.\"\"\"\n    src = urlopen(url)\n    try:\n        # Read all the data in one block.\n        data = src.read()\n    finally:\n        src.close()\n\n    # Write all the data in one block to avoid creating a partial file.\n    with open(target, \"wb\") as dst:\n        dst.write(data)",
  "def get_best_downloader():\n    downloaders = (\n        download_file_powershell,\n        download_file_curl,\n        download_file_wget,\n        download_file_insecure,\n    )\n    viable_downloaders = (dl for dl in downloaders if dl.viable())\n    return next(viable_downloaders, None)",
  "def download_setuptools(\n        version=DEFAULT_VERSION, download_base=DEFAULT_URL,\n        to_dir=DEFAULT_SAVE_DIR, delay=15,\n        downloader_factory=get_best_downloader):\n    \"\"\"\n    Download setuptools from a specified location and return its filename.\n\n    `version` should be a valid setuptools version number that is available\n    as an sdist for download under the `download_base` URL (which should end\n    with a '/'). `to_dir` is the directory where the egg will be downloaded.\n    `delay` is the number of seconds to pause before an actual download\n    attempt.\n\n    ``downloader_factory`` should be a function taking no arguments and\n    returning a function for downloading a URL to a target.\n    \"\"\"\n    # making sure we use the absolute path\n    to_dir = os.path.abspath(to_dir)\n    zip_name = \"setuptools-%s.zip\" % version\n    url = download_base + zip_name\n    saveto = os.path.join(to_dir, zip_name)\n    if not os.path.exists(saveto):  # Avoid repeated downloads\n        log.warn(\"Downloading %s\", url)\n        downloader = downloader_factory()\n        downloader(url, saveto)\n    return os.path.realpath(saveto)",
  "def _build_install_args(options):\n    \"\"\"\n    Build the arguments to 'python setup.py install' on the setuptools package.\n\n    Returns list of command line arguments.\n    \"\"\"\n    return ['--user'] if options.user_install else []",
  "def _parse_args():\n    \"\"\"Parse the command line for options.\"\"\"\n    parser = optparse.OptionParser()\n    parser.add_option(\n        '--user', dest='user_install', action='store_true', default=False,\n        help='install in user site package (requires Python 2.6 or later)')\n    parser.add_option(\n        '--download-base', dest='download_base', metavar=\"URL\",\n        default=DEFAULT_URL,\n        help='alternative URL from where to download the setuptools package')\n    parser.add_option(\n        '--insecure', dest='downloader_factory', action='store_const',\n        const=lambda: download_file_insecure, default=get_best_downloader,\n        help='Use internal, non-validating downloader'\n    )\n    parser.add_option(\n        '--version', help=\"Specify which version to download\",\n        default=DEFAULT_VERSION,\n    )\n    parser.add_option(\n    \t'--to-dir',\n    \thelp=\"Directory to save (and re-use) package\",\n    \tdefault=DEFAULT_SAVE_DIR,\n    )\n    options, args = parser.parse_args()\n    # positional arguments are ignored\n    return options",
  "def _download_args(options):\n\t\"\"\"Return args for download_setuptools function from cmdline args.\"\"\"\n\treturn dict(\n\t\tversion=options.version,\n\t\tdownload_base=options.download_base,\n\t\tdownloader_factory=options.downloader_factory,\n\t\tto_dir=options.to_dir,\n\t)",
  "def main():\n    \"\"\"Install or upgrade setuptools and EasyInstall.\"\"\"\n    options = _parse_args()\n    archive = download_setuptools(**_download_args(options))\n    return _install(archive, _build_install_args(options))",
  "def __enter__(self):\n        return self",
  "def __exit__(self, type, value, traceback):\n        self.close()",
  "def __new__(cls, *args, **kwargs):\n        \"\"\"Construct a ZipFile or ContextualZipFile as appropriate.\"\"\"\n        if hasattr(zipfile.ZipFile, '__exit__'):\n            return zipfile.ZipFile(*args, **kwargs)\n        return super(ContextualZipFile, cls).__new__(cls)",
  "class dirTree(dict) :\n    \"\"\" An object to hold list of all files and directories in a directory\n        with option to read sub-directory contents into dirTree objects.\n        Iterates through readSub levels of subfolders\n        Flags to keep track of changes to files etc\"\"\"\n    def __init__(self,dirn,readSub = 9999) :\n        self.removedfiles = {} # List of files that have been renamed or deleted since reading from disk\n        for name in os.listdir(dirn) :\n            if name[-1:] == \"~\" : continue\n            item=dirTreeItem()\n            if os.path.isdir(os.path.join(dirn, name)) :\n                item.type = \"d\"\n                if readSub :\n                    item.dirtree = dirTree(os.path.join(dirn,name),readSub-1)\n            self[name] = item\n\n    def subTree(self,path) : # Returns dirTree object for a subtree based on subfolder name(s)\n        # 'path' can be supplied as either a relative path (eg \"subf/subsubf\") or array (eg ['subf','subsubf']\n        if type(path) in (bytes, str): path = self._split(path)\n        subf=path[0]\n        if subf in self:\n            dtree =  self[subf].dirtree\n        else : return None\n\n        if len(path) == 1 :\n            return dtree\n        else :\n            path.pop(0)\n            return dtree.subTree(path)\n\n    def _split(self,path) : # Turn a relative path into an array of subfolders\n        npath = [os.path.split(path)[1]]\n        while os.path.split(path)[0] :\n            path = os.path.split(path)[0]\n            npath.insert(0,os.path.split(path)[1])\n        return npath",
  "class dirTreeItem(object) :\n\n    def __init__(self, type = \"f\", dirtree = None, read = False, added = False, changed = False, towrite = False, written = False, fileObject = None, fileType = None, flags = {}) :\n        self.type = type                # \"d\" or \"f\"\n        self.dirtree = dirtree          # dirtree for a sub-directory\n        # Remaining properties are for calling scripts to use as they choose to track actions etc\n        self.read = read                # Item has been read by the script\n        self.added = added              # Item has been added to dirtree, so does not exist on disk\n        self.changed = changed          # Item has been changed, so may need updating on disk\n        self.towrite = towrite          # Item should be written out to disk\n        self.written = written          # Item has been written to disk\n        self.fileObject = fileObject    # An object representing the file\n        self.fileType = fileType        # The type of the file object\n        self.flags = {}                 # Any other flags a script might need\n\n    def setinfo(self, read = None, added = None, changed = None, towrite = None, written = None, fileObject = None, fileType = None, flags = None) :\n        pass\n        if read : self.read = read\n        if added : self.added = added\n        if changed : self.changed = changed\n        if towrite: self.towrite = towrite\n        if written : self.written = written\n        if fileObject is not None : self.fileObject = fileObject\n        if fileType : self.fileType = fileType\n        if flags : self.flags = flags",
  "class ufo_diff(object): # For diffing 2 ufos as part of testing\n    # returncodes:\n    #   0 - ufos are the same\n    #   1 - Differences were found\n    #   2 - Errors running the difference (eg can't open file)\n    # diff - text of the differences\n    # errors - text of the errors\n\n    def __init__(self, ufo1, ufo2, ignoreOHCtime=True):\n\n        diffcommand = [\"diff\", \"-r\", \"-c1\", ufo1, ufo2]\n\n        # By default, if only difference in fontinfo is the openTypeHeadCreated timestamp ignore that\n\n        if ignoreOHCtime: # Exclude fontinfo if only diff is openTypeHeadCreated\n                          # Otherwise leave it in so differences are reported by main diff\n            fi1 = os.path.join(ufo1,\"fontinfo.plist\")\n            fi2 = os.path.join(ufo2, \"fontinfo.plist\")\n            fitest = subprocess.Popen([\"diff\", fi1, fi2, \"-c1\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n            text = fitest.communicate()\n            if fitest.returncode == 1:\n                difftext = text[0].decode(\"utf-8\").split(\"\\n\")\n                if difftext[4].strip() == \"<key>openTypeHeadCreated</key>\" and len(difftext) == 12:\n                    diffcommand.append(\"--exclude=fontinfo.plist\")\n\n        # Now do the main diff\n        test = subprocess.Popen(diffcommand, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n        text = test.communicate()\n        self.returncode = test.returncode\n        self.diff = text[0].decode(\"utf-8\")\n        self.errors = text[1]\n\n    def print_text(self): # Print diff info or errors from the diffcommand\n        if self.returncode == 0:\n            print(\"UFOs are the same\")\n        elif self.returncode == 1:\n            print(\"UFOs are different\")\n            print(self.diff)\n        elif self.returncode == 2:\n            print(\"Failed to compare UFOs\")\n            print(self.errors)",
  "class text_diff(object): # For diffing 2 text files with option to ignore common timestamps\n    # See ufo_diff for class attribute details\n\n    def __init__(self, file1, file2, ignore_chars=0, ignore_firstlinechars = 0):\n        # ignore_chars - characters to ignore from left of each line; typically 20 for timestamps\n        # ignore_firstlinechars - as above, but just for first line, eg for initial comment in csv files, typically 22\n        errors = []\n        try:\n            f1 = [x[ignore_chars:-1].replace('\\\\','/') for x in io.open(file1, \"r\", encoding=\"utf-8\").readlines()]\n        except IOError:\n            errors.append(\"Can't open \" + file1)\n        try:\n            f2 = [x[ignore_chars:-1].replace('\\\\','/') for x in io.open(file2, \"r\", encoding=\"utf-8\").readlines()]\n        except IOError:\n            errors.append(\"Can't open \" + file2)\n        if errors == []: # Indicates both files were opened OK\n            if ignore_firstlinechars:  # Ignore first line for files with first line comment with timestamp\n                f1[0] = f1[0][ignore_firstlinechars:-1]\n                f2[0] = f2[0][ignore_firstlinechars:-1]\n            self.errors = \"\"\n            self.diff = \"\\n\".join([x for x in difflib.unified_diff(f1, f2, file1, file2, n=0)])\n            self.returncode = 0 if self.diff == \"\" else 1\n        else:\n            self.diff = \"\"\n            self.errors = \"\\n\".join(errors)\n            self.returncode = 2\n\n    def print_text(self): # Print diff info or errors the unified_diff command\n        if self.returncode == 0:\n            print(\"Files are the same\")\n        elif self.returncode == 1:\n            print(\"Files are different\")\n            print(self.diff)\n        elif self.returncode == 2:\n            print(\"Failed to compare Files\")\n            print(self.errors)",
  "class ttf_diff(object): # For diffing 2 ttf files.  Differences are not listed\n    # See ufo_diff for class attribute details\n\n    def __init__(self, file1, file2):\n        errors=[]\n        if TTFont is None:\n            self.diff=\"\"\n            self.errors=\"Testing failed - class ttf_diff requires fontTools to be installed\"\n            self.returncode = 2\n            return\n\n        # Open the ttf files\n        try:\n            font1 = TTFont(file1)\n        except Exception as e:\n            errors.append(\"Can't open \" + file1)\n            errors.append(e.__str__())\n        try:\n            font2 = TTFont(file2)\n        except Exception as e:\n            errors.append(\"Can't open \" + file2)\n            errors.append(e.__str__())\n        if errors:\n            self.diff = \"\"\n            self.errors = \"\\n\".join(errors)\n            self.returncode = 2\n            return\n\n        # Create ttx xml strings from each font\n        ttx1 = _ttx()\n        ttx2 = _ttx()\n        font1.saveXML(ttx1)\n        font2.saveXML(ttx2)\n\n        if ttx1.txt() == ttx2.txt():\n            self.diff = \"\"\n            self.errors = \"\"\n            self.returncode = 0\n        else:\n            self.diff = file1 + \" and \" + file2 + \" are different - compare with external tools\"\n            self.errors = \"\"\n            self.returncode = 1\n\n    def print_text(self): # Print diff info or errors the unified_diff command\n        if self.returncode == 0:\n            print(\"Files are the same\")\n        elif self.returncode == 1:\n            print(\"Files are different\")\n            print(self.diff)\n        elif self.returncode == 2:\n            print(\"Failed to compare Files\")\n            print(self.errors)",
  "def test_run(tool, commandline, testcommand, outfont, exp_errors, exp_warnings): # Used by tests to run commands\n    sys.argv = commandline.split(\" \")\n    (args, font) = execute(tool, testcommand.doit, testcommand.argspec, chain=\"first\")\n    if outfont:\n        if tool in (\"FT\", \"FP\"):\n            font.save(outfont)\n        else:  # Must be Pyslifont Ufont\n            font.write(outfont)\n    args.logger.logfile.close() # Need to close the log so that the diff test can be run\n    exp_counts = (exp_errors, exp_warnings)\n    actual_counts = (args.logger.errorcount, args.logger.warningcount)\n    result = exp_counts == actual_counts\n    if not result: print(\"Mis-match of logger errors/warnings: \" + str(exp_counts) + \" vs \" + str(actual_counts))\n    return result",
  "def test_diffs(dirname, testname, extensions): # Used by test to run diffs on results files based on extensions\n    result = True\n    for ext in extensions:\n        resultfile = os.path.join(\"local/testresults\", dirname, testname + ext)\n        referencefile = os.path.join(\"tests/reference\", dirname, testname + ext)\n        if ext == \".ufo\":\n            diff = ufo_diff(resultfile, referencefile)\n        elif ext == \".csv\":\n            diff = text_diff(resultfile, referencefile, ignore_firstlinechars=22)\n        elif ext in (\".log\", \".lg\"):\n            diff = text_diff(resultfile, referencefile, ignore_chars=20)\n        elif ext == \".ttf\":\n            diff = ttf_diff(resultfile, referencefile)\n        else:\n            diff = text_diff(resultfile, referencefile)\n\n        if diff.returncode:\n                    diff.print_text()\n                    result = False\n    return result",
  "class _ttx(object): # Used by ttf_diff()\n\n    def __init__(self):\n        self.lines = []\n\n    def write(self, line):\n        if not(\"<checkSumAdjustment value=\" in line or \"<modified value=\" in line) :\n            self.lines.append(line)\n\n    def txt(self):\n        return \"\".join(self.lines)",
  "def nametocolor(color, default=None):\n    global namestocolorslist\n    if default is not None:\n        return namestocolorslist.get(color,default)\n    else:\n        return namestocolorslist.get(color)",
  "def colortoname(color, default=None):\n    global colorstonameslist\n    if default:\n        return colorstonameslist.get(color,default)\n    else:\n        return colorstonameslist.get(color)",
  "def parsecolors(colors, single = False, allowspecial = False): # Process a list of colors - designed for handling command-line input\n    # Colors can be in RBGA format (eg (0.25,0.25,0.25,1)) or text name (eg g_dark_grey), spearated by commas.\n    # Function returns a list of tuples, one per color, (RGBA, name, logcolor, original color after splitting)\n    # If the color can't be parsed, RGBA will be None and logocolor contain an error message\n    # If single is set, just return one tuple rather than a list of tuples\n    # Also can allow for special values of 'none' and 'leave' if allowspecial set\n\n    # First tidy up the input string\n    cols = colors.lower().replace(\" \", \"\")\n\n    if single: # If just one color, don't need to split the string and can allow for RGBA without brackets\n        splitcols = [\"(\" + cols + \")\"] if cols[0] in (\"0\", \"1\") else [cols]\n    else:\n        # Since RGBA colors which have parentheses and then commas within them, so can't just split on commas so add @ signs for first split\n        cols = cols.replace(\",(\", \"@(\").replace(\"),\", \")@\").split(\"@\")\n        splitcols = []\n        for color in cols:\n            if color[0] == \"(\":\n                splitcols.append(color)\n            else:\n                splitcols = splitcols + color.split(',')\n    parsed = []\n    for splitcol in splitcols:\n        if allowspecial and splitcol in (\"none\", \"leave\"):\n            RGBA = \"\"\n            name = splitcol\n            logcolor = splitcol\n        else:\n            errormess = \"\"\n            name = \"\"\n            RGBA = \"\"\n            if splitcol[0] == '(':\n                values = splitcol[1:-1].split(',') # Remove parentheses then split on commas\n                if len(values) != 4:\n                    errormess = \"RGBA colours must have 4 values\"\n                else:\n                    for i in (0, 1, 2, 3):\n                        values[i] = float(values[i])\n                        if values[i] < 0 or values[i] > 1: errormess = \"RGBA values must be between 0 and 1\"\n                    if values[0] + values[1] + values[2] == 0: errormess = \"At lease one RGB value must be non-zero\"\n                    if values[3] == 0: errormess = \"With RGBA, A must not be zero\"\n                if errormess == \"\":\n                    for i in (0, 1, 2, 3):\n                        v = values[i]\n                        if v == int(v): v = int(v)  # Convert integers to int type for correct formatting with str()\n                        RGBA += str(v) + \",\"\n                    RGBA = RGBA[0:-1]  # Strip trialing comma\n                    name = colortoname(RGBA, \"\")\n            else:\n                name = splitcol\n                RGBA = nametocolor(name)\n                if RGBA is None: errormess = \"Invalid color name\"\n            if errormess:\n                logcolor = \"Invalid color: \" + splitcol + \" - \" + errormess\n                RGBA = None\n                name = None\n            else:\n                logcolor = RGBA\n                if name: logcolor += \" (\" + name + \")\"\n        parsed.append((RGBA, name, logcolor,splitcol))\n    if single: parsed = parsed[0]\n\n    return parsed",
  "def required_chars(sets=\"basic\"):\n    if type(sets) == str: sets = (sets,) # Convert single string to a tuple\n    rcfile = open(resource_filename('silfont','data/required_chars.csv'))\n    rcreader = csvreader(rcfile)\n    next(rcreader) # Read fist line which is headers\n    rcdict = {}\n    for line in rcreader:\n        unicode = line[0][2:]\n        item = {\n            \"ps_name\": line[1],\n            \"glyph_name\": line[2],\n            \"sil_set\": line[3],\n            \"rationale\": line[4],\n            \"notes\": line[5]\n        }\n        if item[\"sil_set\"] in sets: rcdict[unicode] = item\n    return rcdict",
  "def prettyjson(data, oneliners=None, indent=\"\", inkey=None, oneline=False):\n    # data - json data to format\n    # oneliners - lists of keys for which data should be output on a single line\n    # indent, inkey & oneline - used when prettyjson calls itself interactively for sub-values that are dicts\n    res = [\"{\"]\n    thisoneline = oneline and (oneliners is None or inkey not in oneliners)\n    for key, value in sorted(data.items()):\n        line = (\"\" if thisoneline else indent) + '\"{}\": '.format(key)\n        if isinstance(value, dict):\n            val = prettyjson(value, oneliners=oneliners,\n                             indent = indent + \"    \", inkey = key,\n                             oneline=(oneline if oneliners is None or key not in oneliners else True))\n        else:\n            val = json.dumps(value, ensure_ascii=False)\n        res.append(line + val + \",\")\n    res[-1] = res[-1][:-1]\n    res.append((\"\" if thisoneline else indent[:-4]) + \"}\")\n    return (\" \" if thisoneline else \"\\n\").join(res)",
  "def __init__(self,dirn,readSub = 9999) :\n        self.removedfiles = {} # List of files that have been renamed or deleted since reading from disk\n        for name in os.listdir(dirn) :\n            if name[-1:] == \"~\" : continue\n            item=dirTreeItem()\n            if os.path.isdir(os.path.join(dirn, name)) :\n                item.type = \"d\"\n                if readSub :\n                    item.dirtree = dirTree(os.path.join(dirn,name),readSub-1)\n            self[name] = item",
  "def subTree(self,path) : # Returns dirTree object for a subtree based on subfolder name(s)\n        # 'path' can be supplied as either a relative path (eg \"subf/subsubf\") or array (eg ['subf','subsubf']\n        if type(path) in (bytes, str): path = self._split(path)\n        subf=path[0]\n        if subf in self:\n            dtree =  self[subf].dirtree\n        else : return None\n\n        if len(path) == 1 :\n            return dtree\n        else :\n            path.pop(0)\n            return dtree.subTree(path)",
  "def _split(self,path) : # Turn a relative path into an array of subfolders\n        npath = [os.path.split(path)[1]]\n        while os.path.split(path)[0] :\n            path = os.path.split(path)[0]\n            npath.insert(0,os.path.split(path)[1])\n        return npath",
  "def __init__(self, type = \"f\", dirtree = None, read = False, added = False, changed = False, towrite = False, written = False, fileObject = None, fileType = None, flags = {}) :\n        self.type = type                # \"d\" or \"f\"\n        self.dirtree = dirtree          # dirtree for a sub-directory\n        # Remaining properties are for calling scripts to use as they choose to track actions etc\n        self.read = read                # Item has been read by the script\n        self.added = added              # Item has been added to dirtree, so does not exist on disk\n        self.changed = changed          # Item has been changed, so may need updating on disk\n        self.towrite = towrite          # Item should be written out to disk\n        self.written = written          # Item has been written to disk\n        self.fileObject = fileObject    # An object representing the file\n        self.fileType = fileType        # The type of the file object\n        self.flags = {}",
  "def setinfo(self, read = None, added = None, changed = None, towrite = None, written = None, fileObject = None, fileType = None, flags = None) :\n        pass\n        if read : self.read = read\n        if added : self.added = added\n        if changed : self.changed = changed\n        if towrite: self.towrite = towrite\n        if written : self.written = written\n        if fileObject is not None : self.fileObject = fileObject\n        if fileType : self.fileType = fileType\n        if flags : self.flags = flags",
  "def __init__(self, ufo1, ufo2, ignoreOHCtime=True):\n\n        diffcommand = [\"diff\", \"-r\", \"-c1\", ufo1, ufo2]\n\n        # By default, if only difference in fontinfo is the openTypeHeadCreated timestamp ignore that\n\n        if ignoreOHCtime: # Exclude fontinfo if only diff is openTypeHeadCreated\n                          # Otherwise leave it in so differences are reported by main diff\n            fi1 = os.path.join(ufo1,\"fontinfo.plist\")\n            fi2 = os.path.join(ufo2, \"fontinfo.plist\")\n            fitest = subprocess.Popen([\"diff\", fi1, fi2, \"-c1\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n            text = fitest.communicate()\n            if fitest.returncode == 1:\n                difftext = text[0].decode(\"utf-8\").split(\"\\n\")\n                if difftext[4].strip() == \"<key>openTypeHeadCreated</key>\" and len(difftext) == 12:\n                    diffcommand.append(\"--exclude=fontinfo.plist\")\n\n        # Now do the main diff\n        test = subprocess.Popen(diffcommand, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n        text = test.communicate()\n        self.returncode = test.returncode\n        self.diff = text[0].decode(\"utf-8\")\n        self.errors = text[1]",
  "def print_text(self): # Print diff info or errors from the diffcommand\n        if self.returncode == 0:\n            print(\"UFOs are the same\")\n        elif self.returncode == 1:\n            print(\"UFOs are different\")\n            print(self.diff)\n        elif self.returncode == 2:\n            print(\"Failed to compare UFOs\")\n            print(self.errors)",
  "def __init__(self, file1, file2, ignore_chars=0, ignore_firstlinechars = 0):\n        # ignore_chars - characters to ignore from left of each line; typically 20 for timestamps\n        # ignore_firstlinechars - as above, but just for first line, eg for initial comment in csv files, typically 22\n        errors = []\n        try:\n            f1 = [x[ignore_chars:-1].replace('\\\\','/') for x in io.open(file1, \"r\", encoding=\"utf-8\").readlines()]\n        except IOError:\n            errors.append(\"Can't open \" + file1)\n        try:\n            f2 = [x[ignore_chars:-1].replace('\\\\','/') for x in io.open(file2, \"r\", encoding=\"utf-8\").readlines()]\n        except IOError:\n            errors.append(\"Can't open \" + file2)\n        if errors == []: # Indicates both files were opened OK\n            if ignore_firstlinechars:  # Ignore first line for files with first line comment with timestamp\n                f1[0] = f1[0][ignore_firstlinechars:-1]\n                f2[0] = f2[0][ignore_firstlinechars:-1]\n            self.errors = \"\"\n            self.diff = \"\\n\".join([x for x in difflib.unified_diff(f1, f2, file1, file2, n=0)])\n            self.returncode = 0 if self.diff == \"\" else 1\n        else:\n            self.diff = \"\"\n            self.errors = \"\\n\".join(errors)\n            self.returncode = 2",
  "def print_text(self): # Print diff info or errors the unified_diff command\n        if self.returncode == 0:\n            print(\"Files are the same\")\n        elif self.returncode == 1:\n            print(\"Files are different\")\n            print(self.diff)\n        elif self.returncode == 2:\n            print(\"Failed to compare Files\")\n            print(self.errors)",
  "def __init__(self, file1, file2):\n        errors=[]\n        if TTFont is None:\n            self.diff=\"\"\n            self.errors=\"Testing failed - class ttf_diff requires fontTools to be installed\"\n            self.returncode = 2\n            return\n\n        # Open the ttf files\n        try:\n            font1 = TTFont(file1)\n        except Exception as e:\n            errors.append(\"Can't open \" + file1)\n            errors.append(e.__str__())\n        try:\n            font2 = TTFont(file2)\n        except Exception as e:\n            errors.append(\"Can't open \" + file2)\n            errors.append(e.__str__())\n        if errors:\n            self.diff = \"\"\n            self.errors = \"\\n\".join(errors)\n            self.returncode = 2\n            return\n\n        # Create ttx xml strings from each font\n        ttx1 = _ttx()\n        ttx2 = _ttx()\n        font1.saveXML(ttx1)\n        font2.saveXML(ttx2)\n\n        if ttx1.txt() == ttx2.txt():\n            self.diff = \"\"\n            self.errors = \"\"\n            self.returncode = 0\n        else:\n            self.diff = file1 + \" and \" + file2 + \" are different - compare with external tools\"\n            self.errors = \"\"\n            self.returncode = 1",
  "def print_text(self): # Print diff info or errors the unified_diff command\n        if self.returncode == 0:\n            print(\"Files are the same\")\n        elif self.returncode == 1:\n            print(\"Files are different\")\n            print(self.diff)\n        elif self.returncode == 2:\n            print(\"Failed to compare Files\")\n            print(self.errors)",
  "def __init__(self):\n        self.lines = []",
  "def write(self, line):\n        if not(\"<checkSumAdjustment value=\" in line or \"<modified value=\" in line) :\n            self.lines.append(line)",
  "def txt(self):\n        return \"\".join(self.lines)",
  "def asFea(g):\n    if hasattr(g, 'asClassFea'):\n        return g.asClassFea()\n    elif hasattr(g, 'asFea'):\n        return g.asFea()\n    elif isinstance(g, tuple) and len(g) == 2:\n        return asFea(g[0]) + \"-\" + asFea(g[1])   # a range\n    elif g.lower() in ast.fea_keywords:\n        return \"\\\\\" + g\n    else:\n        return g",
  "def asLiteralFea(self, indent=\"\"):\n    Element.mode = 'literal'\n    return self.asFea(indent=indent)\n    Element.mode = 'flat'",
  "class ast_Comment(ast.Comment):\n    def __init__(self, text, location=None):\n        super(ast_Comment, self).__init__(text, location=location)\n        self.pretext = \"\"\n        self.posttext = \"\"\n\n    def asFea(self, indent=\"\"):\n        return self.pretext + self.text + self.posttext",
  "class ast_MarkClass(ast.MarkClass):\n    # This is better fixed upstream in parser.parse_glyphclass_ to handle MarkClasses\n    def asClassFea(self, indent=\"\"):\n        return \"[\" + \" \".join(map(asFea, self.glyphs)) + \"]\"",
  "class ast_BaseClass(ast_MarkClass) :\n    def asFea(self, indent=\"\") :\n        return \"@\" + self.name + \" = [\" + \" \".join(map(asFea, self.glyphs.keys())) + \"];\"",
  "class ast_BaseClassDefinition(ast.MarkClassDefinition):\n    def asFea(self, indent=\"\") :\n        # like base class asFea\n        return (\"# \" if self.mode != 'literal' else \"\") + \\\n                \"{}baseClass {} {} @{};\".format(indent, self.glyphs.asFea(),\n                                               self.anchor.asFea(), self.markClass.name)",
  "class ast_MarkBasePosStatement(ast.MarkBasePosStatement):\n    def asFea(self, indent=\"\"):\n        # handles members added by parse_position_base_ with feax syntax\n        if isinstance(self.base, ast.MarkClassName): # flattens pos @BASECLASS mark @MARKCLASS\n            res = \"\"\n            if self.mode == 'literal':\n                res += \"pos base @{} \".format(self.base.markClass.name)\n                res += \" \".join(\"mark @{}\".format(m.name) for m in self.marks)\n                res += \";\"\n            else:\n                for bcd in self.base.markClass.definitions:\n                    if res != \"\":\n                        res += \"\\n{}\".format(indent)\n                    res += \"pos base {} {}\".format(bcd.glyphs.asFea(), bcd.anchor.asFea())\n                    res += \"\".join(\" mark @{}\".format(m.name) for m in self.marks)\n                    res += \";\"\n        else: # like base class method\n            res = \"pos base {}\".format(self.base.asFea())\n            res += \"\".join(\" {} mark @{}\".format(a.asFea(), m.name) for a, m in self.marks)\n            res += \";\"\n        return res\n\n    def build(self, builder) :\n        #TODO: do the right thing here (write to ttf?)\n        pass",
  "class ast_MarkMarkPosStatement(ast.MarkMarkPosStatement):\n    # super class __init__() for reference\n    # def __init__(self, location, baseMarks, marks):\n    #     Statement.__init__(self, location)\n    #     self.baseMarks, self.marks = baseMarks, marks\n\n    def asFea(self, indent=\"\"):\n        # handles members added by parse_position_base_ with feax syntax\n        if isinstance(self.baseMarks, ast.MarkClassName): # flattens pos @MARKCLASS mark @MARKCLASS\n            res = \"\"\n            if self.mode == 'literal':\n                res += \"pos mark @{} \".format(self.base.markClass.name)\n                res += \" \".join(\"mark @{}\".format(m.name) for m in self.marks)\n                res += \";\"\n            else:\n                for mcd in self.baseMarks.markClass.definitions:\n                    if res != \"\":\n                        res += \"\\n{}\".format(indent)\n                    res += \"pos mark {} {}\".format(mcd.glyphs.asFea(), mcd.anchor.asFea())\n                    for m in self.marks:\n                        res += \" mark @{}\".format(m.name)\n                    res += \";\"\n        else: # like base class method\n            res = \"pos mark {}\".format(self.baseMarks.asFea())\n            for a, m in self.marks:\n                res += \" {} mark @{}\".format(a.asFea() if a else \"<anchor NULL>\", m.name)\n            res += \";\"\n        return res\n\n    def build(self, builder):\n        # builder.add_mark_mark_pos(self.location, self.baseMarks.glyphSet(), self.marks)\n        #TODO: do the right thing\n        pass",
  "class ast_CursivePosStatement(ast.CursivePosStatement):\n    # super class __init__() for reference\n    # def __init__(self, location, glyphclass, entryAnchor, exitAnchor):\n    #     Statement.__init__(self, location)\n    #     self.glyphclass = glyphclass\n    #     self.entryAnchor, self.exitAnchor = entryAnchor, exitAnchor\n\n    def asFea(self, indent=\"\"):\n        if isinstance(self.exitAnchor, ast.MarkClass): # pos cursive @BASE1 @BASE2\n            res = \"\"\n            if self.mode == 'literal':\n                res += \"pos cursive @{} @{};\".format(self.glyphclass.name, self.exitAnchor.name)\n            else:\n                allglyphs = set(self.glyphclass.glyphSet())\n                allglyphs.update(self.exitAnchor.glyphSet())\n                for g in sorted(allglyphs):\n                    entry = self.glyphclass.glyphs.get(g, None)\n                    exit = self.exitAnchor.glyphs.get(g, None)\n                    if res != \"\":\n                        res += \"\\n{}\".format(indent)\n                    res += \"pos cursive {} {} {};\".format(g,\n                                (entry.anchor.asFea() if entry else \"<anchor NULL>\"),\n                                (exit.anchor.asFea() if exit else \"<anchor NULL>\"))\n        else:\n            res = super(ast_CursivePosStatement, self).asFea(indent)\n        return res\n\n    def build(self, builder) :\n        #TODO: do the right thing here (write to ttf?)\n        pass",
  "class ast_MarkLigPosStatement(ast.MarkLigPosStatement):\n    def __init__(self, ligatures, marks, location=None):\n        ast.MarkLigPosStatement.__init__(self, ligatures, marks, location)\n        self.classBased = False\n        for l in marks:\n            if l is not None:\n                for m in l:\n                    if m is not None and not isinstance(m[0], ast.Anchor):\n                        self.classBased = True\n                        break\n\n    def build(self, builder):\n        builder.add_mark_lig_pos(self.location, self.ligatures.glyphSet(), self.marks)\n\n    def asFea(self, indent=\"\"):\n        if not self.classBased or self.mode == \"literal\":\n            return super(ast_MarkLigPosStatement, self).asFea(indent)\n\n        res = []\n        for g in self.ligatures.glyphSet():\n            comps = []\n            for l in self.marks:\n                onecomp = []\n                if l is not None and len(l):\n                    for a, m in l:\n                        if not isinstance(a, ast.Anchor):\n                            if g not in a.markClass.glyphs:\n                                continue\n                            left = a.markClass.glyphs[g].anchor.asFea()\n                        else:\n                            left = a.asFea()\n                        onecomp.append(\"{} mark @{}\".format(left, m.name))\n                if not len(onecomp):\n                    onecomp = [\"<anchor NULL>\"]\n                comps.append(\" \".join(onecomp))\n            res.append(\"pos ligature {} \".format(asFea(g)) + (\"\\n\"+indent+SHIFT+\"ligComponent \").join(comps))\n        return (\";\\n\"+indent).join(res) + \";\"",
  "class ast_MultipleSubstStatement(ast.Statement):\n    def __init__(self, prefix, glyph, suffix, replacement, forceChain, location=None):\n        ast.Statement.__init__(self, location)\n        self.prefix, self.glyph, self.suffix = prefix, glyph, suffix\n        self.replacement = replacement\n        self.forceChain = forceChain\n        lenglyphs = len(self.glyph.glyphSet())\n        for i, r in enumerate(self.replacement) :\n            if len(r.glyphSet()) == lenglyphs:\n                self.multindex = i #first RHS slot with a glyph class\n                break\n        else:\n            if lenglyphs > 1:\n                raise FeatureLibError(\"No replacement class is of the same length as the matching class\",\n                                        location)\n            else:\n                self.multindex = 0;\n\n    def build(self, builder):\n        prefix = [p.glyphSet() for p in self.prefix]\n        suffix = [s.glyphSet() for s in self.suffix]\n        glyphs = self.glyph.glyphSet()\n        replacements = self.replacement[self.multindex].glyphSet()\n        lenglyphs = len(glyphs)\n        for i in range(max(lenglyphs, len(replacements))) :\n            builder.add_multiple_subst(\n                self.location, prefix, glyphs[i if lenglyphs > 1 else 0], suffix,\n                self.replacement[0:self.multindex] + [replacements[i]] + self.replacement[self.multindex+1:],\n                self.forceChain)\n\n    def asFea(self, indent=\"\"):\n        res = \"\"\n        pres = (\" \".join(map(asFea, self.prefix)) + \" \") if len(self.prefix) else \"\"\n        sufs = (\" \" + \" \".join(map(asFea, self.suffix))) if len(self.suffix) else \"\"\n        mark = \"'\" if len(self.prefix) or len(self.suffix) or self.forceChain else \"\"\n        if self.mode == 'literal':\n            res += \"sub \" + pres + self.glyph.asFea() + mark + sufs + \" by \"\n            res += \" \".join(asFea(g) for g in self.replacement) + \";\"\n            return res\n        glyphs = self.glyph.glyphSet()\n        replacements = self.replacement[self.multindex].glyphSet()\n        lenglyphs = len(glyphs)\n        count = max(lenglyphs, len(replacements))\n        for i in range(count) :\n            res += (\"\\n\" + indent if i > 0 else \"\") + \"sub \" + pres\n            res += asFea(glyphs[i if lenglyphs > 1 else 0]) + mark + sufs\n            res += \" by \"\n            res += \" \".join(asFea(g) for g in self.replacement[0:self.multindex] + [replacements[i]] + self.replacement[self.multindex+1:])\n            res += \";\" \n        return res",
  "class ast_LigatureSubstStatement(ast.Statement):\n    def __init__(self, prefix, glyphs, suffix, replacement,\n                 forceChain, location=None):\n        ast.Statement.__init__(self, location)\n        self.prefix, self.glyphs, self.suffix = (prefix, glyphs, suffix)\n        self.replacement, self.forceChain = replacement, forceChain\n        lenreplace = len(self.replacement.glyphSet())\n        for i, g in enumerate(self.glyphs):\n            if len(g.glyphSet()) == lenreplace:\n                self.multindex = i #first LHS slot with a glyph class\n                break\n        else:\n            if lenreplace > 1:\n                raise FeatureLibError(\"No class matches replacement class length\", location)\n            else:\n                self.multindex = 0\n\n    def build(self, builder):\n        prefix = [p.glyphSet() for p in self.prefix]\n        glyphs = [g.glyphSet() for g in self.glyphs]\n        suffix = [s.glyphSet() for s in self.suffix]\n        replacements = self.replacement.glyphSet()\n        lenreplace = len(replacements.glyphSet())\n        glyphs = self.glyphs[self.multindex].glyphSet()\n        for i in range(max(len(glyphs), len(replacements))):\n            builder.add_ligature_subst(\n                self.location, prefix,\n                self.glyphs[:self.multindex] + glyphs[i] + self.glyphs[self.multindex+1:],\n                suffix, replacements[i if lenreplace > 1 else 0], self.forceChain)\n\n    def asFea(self, indent=\"\"):\n        res = \"\"\n        pres = (\" \".join(map(asFea, self.prefix)) + \" \") if len(self.prefix) else \"\"\n        sufs = (\" \" + \" \".join(map(asFea, self.suffix))) if len(self.suffix) else \"\"\n        mark = \"'\" if len(self.prefix) or len(self.suffix) or self.forceChain else \"\"\n        if self.mode == 'literal':\n            res += \"sub \" + pres + \" \".join(asFea(g)+mark for g in self.glyphs) + sufs + \" by \"\n            res += self.replacements.asFea() + \";\"\n            return res\n        glyphs = self.glyphs[self.multindex].glyphSet()\n        replacements = self.replacement.glyphSet()\n        lenreplace = len(replacements)\n        count = max(len(glyphs), len(replacements))\n        for i in range(count) :\n            res += (\"\\n\" + indent if i > 0 else \"\") + \"sub \" + pres\n            res += \" \".join(asFea(g)+mark for g in self.glyphs[:self.multindex] + [glyphs[i]] + self.glyphs[self.multindex+1:])\n            res += sufs + \" by \"\n            res += asFea(replacements[i if lenreplace > 1 else 0])\n            res += \";\"\n        return res",
  "class ast_AlternateSubstStatement(ast.Statement):\n    def __init__(self, prefix, glyphs, suffix, replacements, location=None):\n        ast.Statement.__init__(self, location)\n        self.prefix, self.glyphs, self.suffix = (prefix, glyphs, suffix)\n        self.replacements = replacements\n\n    def build(self, builder):\n        prefix = [p.glyphSet() for p in self.prefix]\n        suffix = [s.glyphSet() for s in self.suffix]\n        l = len(self.glyphs.glyphSet())\n        for i, glyph in enumerate(self.glyphs.glyphSet()):\n            replacement = self.replacements.glyphSet()[i::l]\n            builder.add_alternate_subst(self.location, prefix, glyph, suffix,\n                                    replacement)\n\n    def asFea(self, indent=\"\"):\n        res = \"\"\n        l = len(self.glyphs.glyphSet())\n        for i, glyph in enumerate(self.glyphs.glyphSet()):\n            if i > 0:\n                res += \"\\n\" + indent\n            res += \"sub \"\n            if len(self.prefix) or len(self.suffix):\n                if len(self.prefix):\n                    res += \" \".join(map(asFea, self.prefix)) + \" \"\n                res += asFea(glyph) + \"'\"    # even though we really only use 1\n                if len(self.suffix):\n                    res += \" \" + \" \".join(map(asFea, self.suffix))\n            else:\n                res += asFea(glyph)\n            res += \" from \"\n            replacements = ast.GlyphClass(glyphs=self.replacements.glyphSet()[i::l], location=self.location)\n            res += asFea(replacements)\n            res += \";\"\n        return res",
  "class ast_IfBlock(ast.Block):\n    def __init__(self, testfn, name, cond, location=None):\n        ast.Block.__init__(self, location=location)\n        self.testfn = testfn\n        self.name = name\n\n    def asFea(self, indent=\"\"):\n        if self.mode == 'literal':\n            res = \"{}if{}({}) {{\".format(indent, name, cond)\n            res += ast.Block.asFea(self, indent=indent)\n            res += indent + \"}\\n\"\n            return res\n        elif self.testfn():\n            return ast.Block.asFea(self, indent=indent)\n        else:\n            return \"\"",
  "class ast_DoSubStatement(ast.Statement):\n    def __init__(self, varnames, location=None):\n        ast.Statement.__init__(self, location=location)\n        self.names = varnames\n\n    def items(self, variables):\n        yield ((None, None),)",
  "class ast_DoForSubStatement(ast_DoSubStatement):\n    def __init__(self, varname, glyphs, location=None):\n        ast_DoSubStatement.__init__(self, [varname], location=location)\n        self.glyphs = glyphs.glyphSet()\n\n    def items(self, variables):\n        for g in self.glyphs:\n            yield((self.names[0], g),)",
  "def safeeval(exp):\n    # no dunders in attribute names\n    for n in pyast.walk(pyast.parse(exp)):\n        v = getattr(n, 'id', \"\")\n        # if v in ('_getiter_', '__next__'):\n        #     continue\n        if \"__\" in v:\n            return False\n    return True",
  "class ast_DoLetSubStatement(ast_DoSubStatement):\n    def __init__(self, varnames, expression, parser, location=None):\n        ast_DoSubStatement.__init__(self, varnames, location=location)\n        self.parser = parser\n        if not safeeval(expression):\n            expression='\"Unsafe Expression\"'\n        self.expr = expression\n\n    def items(self, variables):\n        gbls = dict(self.parser.fns, **variables)\n        try:\n            v = eval(self.expr, gbls)\n        except Exception as e:\n            raise FeatureLibError(str(e) + \" in \" + self.expr, self.location)\n        if self.names is None:      # in an if\n            yield((None, v),)\n        elif len(self.names) == 1:\n            yield((self.names[0], v),)\n        else:\n            yield(zip(self.names, list(v) + [None] * (len(self.names) - len(v))))",
  "class ast_DoIfSubStatement(ast_DoLetSubStatement):\n    def __init__(self, expression, parser, block, location=None):\n        ast_DoLetSubStatement.__init__(self, None, expression, parser, location=None)\n        self.block = block\n\n    def items(self, variables):\n        (_, v) = list(ast_DoLetSubStatement.items(self, variables))[0][0]\n        yield (None, (v if v else None),)",
  "class ast_KernPairsStatement(ast.Statement):\n    def __init__(self, kerninfo, location=None):\n        super(ast_KernPairsStatement, self).__init__(location)\n        self.kerninfo = kerninfo\n\n    def asFea(self, indent=\"\"):\n        # return (\"\\n\"+indent).join(\"pos {} {} {};\".format(k1, round(v), k2) \\\n        #           for k1, x in self.kerninfo.items() for k2, v in x.items())\n        coverage = set()\n        rules = dict()\n\n        # first sort into lists by type of rule\n        for k1, x in self.kerninfo.items():\n            for k2, v in x.items():\n                # Determine pair kern type, where:\n                #   'gg' = glyph-glyph, 'gc' = glyph-class', 'cg' = class-glyph, 'cc' = class-class\n                ruleType = 'gc'[k1[0]=='@'] + 'gc'[k2[0]=='@']\n                rules.setdefault(ruleType, list()).append([k1, round(v), k2])\n                # for glyph-glyph rules, make list of first glyphs:\n                if ruleType == 'gg':\n                    coverage.add(k1)\n\n        # Now assemble lines in order and convert gc rules to gg where possible:\n        res = []\n        for ruleType in filter(lambda x: x in rules, ('gg', 'gc', 'cg', 'cc')):\n            if ruleType != 'gc':\n                res.extend(['pos {} {} {};'.format(k1, v, k2) for k1,v,k2 in rules[ruleType]])\n            else:\n                res.extend(['enum pos {} {} {};'.format(k1, v, k2) for k1, v, k2 in rules[ruleType] if k1 not in coverage])\n                res.extend(['pos {} {} {};'.format(k1, v, k2) for k1, v, k2 in rules[ruleType] if k1 in coverage])\n\n        return (\"\\n\"+indent).join(res)",
  "def __init__(self, text, location=None):\n        super(ast_Comment, self).__init__(text, location=location)\n        self.pretext = \"\"\n        self.posttext = \"\"",
  "def asFea(self, indent=\"\"):\n        return self.pretext + self.text + self.posttext",
  "def asClassFea(self, indent=\"\"):\n        return \"[\" + \" \".join(map(asFea, self.glyphs)) + \"]\"",
  "def asFea(self, indent=\"\") :\n        return \"@\" + self.name + \" = [\" + \" \".join(map(asFea, self.glyphs.keys())) + \"];\"",
  "def asFea(self, indent=\"\") :\n        # like base class asFea\n        return (\"# \" if self.mode != 'literal' else \"\") + \\\n                \"{}baseClass {} {} @{};\".format(indent, self.glyphs.asFea(),\n                                               self.anchor.asFea(), self.markClass.name)",
  "def asFea(self, indent=\"\"):\n        # handles members added by parse_position_base_ with feax syntax\n        if isinstance(self.base, ast.MarkClassName): # flattens pos @BASECLASS mark @MARKCLASS\n            res = \"\"\n            if self.mode == 'literal':\n                res += \"pos base @{} \".format(self.base.markClass.name)\n                res += \" \".join(\"mark @{}\".format(m.name) for m in self.marks)\n                res += \";\"\n            else:\n                for bcd in self.base.markClass.definitions:\n                    if res != \"\":\n                        res += \"\\n{}\".format(indent)\n                    res += \"pos base {} {}\".format(bcd.glyphs.asFea(), bcd.anchor.asFea())\n                    res += \"\".join(\" mark @{}\".format(m.name) for m in self.marks)\n                    res += \";\"\n        else: # like base class method\n            res = \"pos base {}\".format(self.base.asFea())\n            res += \"\".join(\" {} mark @{}\".format(a.asFea(), m.name) for a, m in self.marks)\n            res += \";\"\n        return res",
  "def build(self, builder) :\n        #TODO: do the right thing here (write to ttf?)\n        pass",
  "def asFea(self, indent=\"\"):\n        # handles members added by parse_position_base_ with feax syntax\n        if isinstance(self.baseMarks, ast.MarkClassName): # flattens pos @MARKCLASS mark @MARKCLASS\n            res = \"\"\n            if self.mode == 'literal':\n                res += \"pos mark @{} \".format(self.base.markClass.name)\n                res += \" \".join(\"mark @{}\".format(m.name) for m in self.marks)\n                res += \";\"\n            else:\n                for mcd in self.baseMarks.markClass.definitions:\n                    if res != \"\":\n                        res += \"\\n{}\".format(indent)\n                    res += \"pos mark {} {}\".format(mcd.glyphs.asFea(), mcd.anchor.asFea())\n                    for m in self.marks:\n                        res += \" mark @{}\".format(m.name)\n                    res += \";\"\n        else: # like base class method\n            res = \"pos mark {}\".format(self.baseMarks.asFea())\n            for a, m in self.marks:\n                res += \" {} mark @{}\".format(a.asFea() if a else \"<anchor NULL>\", m.name)\n            res += \";\"\n        return res",
  "def build(self, builder):\n        # builder.add_mark_mark_pos(self.location, self.baseMarks.glyphSet(), self.marks)\n        #TODO: do the right thing\n        pass",
  "def asFea(self, indent=\"\"):\n        if isinstance(self.exitAnchor, ast.MarkClass): # pos cursive @BASE1 @BASE2\n            res = \"\"\n            if self.mode == 'literal':\n                res += \"pos cursive @{} @{};\".format(self.glyphclass.name, self.exitAnchor.name)\n            else:\n                allglyphs = set(self.glyphclass.glyphSet())\n                allglyphs.update(self.exitAnchor.glyphSet())\n                for g in sorted(allglyphs):\n                    entry = self.glyphclass.glyphs.get(g, None)\n                    exit = self.exitAnchor.glyphs.get(g, None)\n                    if res != \"\":\n                        res += \"\\n{}\".format(indent)\n                    res += \"pos cursive {} {} {};\".format(g,\n                                (entry.anchor.asFea() if entry else \"<anchor NULL>\"),\n                                (exit.anchor.asFea() if exit else \"<anchor NULL>\"))\n        else:\n            res = super(ast_CursivePosStatement, self).asFea(indent)\n        return res",
  "def build(self, builder) :\n        #TODO: do the right thing here (write to ttf?)\n        pass",
  "def __init__(self, ligatures, marks, location=None):\n        ast.MarkLigPosStatement.__init__(self, ligatures, marks, location)\n        self.classBased = False\n        for l in marks:\n            if l is not None:\n                for m in l:\n                    if m is not None and not isinstance(m[0], ast.Anchor):\n                        self.classBased = True\n                        break",
  "def build(self, builder):\n        builder.add_mark_lig_pos(self.location, self.ligatures.glyphSet(), self.marks)",
  "def asFea(self, indent=\"\"):\n        if not self.classBased or self.mode == \"literal\":\n            return super(ast_MarkLigPosStatement, self).asFea(indent)\n\n        res = []\n        for g in self.ligatures.glyphSet():\n            comps = []\n            for l in self.marks:\n                onecomp = []\n                if l is not None and len(l):\n                    for a, m in l:\n                        if not isinstance(a, ast.Anchor):\n                            if g not in a.markClass.glyphs:\n                                continue\n                            left = a.markClass.glyphs[g].anchor.asFea()\n                        else:\n                            left = a.asFea()\n                        onecomp.append(\"{} mark @{}\".format(left, m.name))\n                if not len(onecomp):\n                    onecomp = [\"<anchor NULL>\"]\n                comps.append(\" \".join(onecomp))\n            res.append(\"pos ligature {} \".format(asFea(g)) + (\"\\n\"+indent+SHIFT+\"ligComponent \").join(comps))\n        return (\";\\n\"+indent).join(res) + \";\"",
  "def __init__(self, prefix, glyph, suffix, replacement, forceChain, location=None):\n        ast.Statement.__init__(self, location)\n        self.prefix, self.glyph, self.suffix = prefix, glyph, suffix\n        self.replacement = replacement\n        self.forceChain = forceChain\n        lenglyphs = len(self.glyph.glyphSet())\n        for i, r in enumerate(self.replacement) :\n            if len(r.glyphSet()) == lenglyphs:\n                self.multindex = i #first RHS slot with a glyph class\n                break\n        else:\n            if lenglyphs > 1:\n                raise FeatureLibError(\"No replacement class is of the same length as the matching class\",\n                                        location)\n            else:\n                self.multindex = 0;",
  "def build(self, builder):\n        prefix = [p.glyphSet() for p in self.prefix]\n        suffix = [s.glyphSet() for s in self.suffix]\n        glyphs = self.glyph.glyphSet()\n        replacements = self.replacement[self.multindex].glyphSet()\n        lenglyphs = len(glyphs)\n        for i in range(max(lenglyphs, len(replacements))) :\n            builder.add_multiple_subst(\n                self.location, prefix, glyphs[i if lenglyphs > 1 else 0], suffix,\n                self.replacement[0:self.multindex] + [replacements[i]] + self.replacement[self.multindex+1:],\n                self.forceChain)",
  "def asFea(self, indent=\"\"):\n        res = \"\"\n        pres = (\" \".join(map(asFea, self.prefix)) + \" \") if len(self.prefix) else \"\"\n        sufs = (\" \" + \" \".join(map(asFea, self.suffix))) if len(self.suffix) else \"\"\n        mark = \"'\" if len(self.prefix) or len(self.suffix) or self.forceChain else \"\"\n        if self.mode == 'literal':\n            res += \"sub \" + pres + self.glyph.asFea() + mark + sufs + \" by \"\n            res += \" \".join(asFea(g) for g in self.replacement) + \";\"\n            return res\n        glyphs = self.glyph.glyphSet()\n        replacements = self.replacement[self.multindex].glyphSet()\n        lenglyphs = len(glyphs)\n        count = max(lenglyphs, len(replacements))\n        for i in range(count) :\n            res += (\"\\n\" + indent if i > 0 else \"\") + \"sub \" + pres\n            res += asFea(glyphs[i if lenglyphs > 1 else 0]) + mark + sufs\n            res += \" by \"\n            res += \" \".join(asFea(g) for g in self.replacement[0:self.multindex] + [replacements[i]] + self.replacement[self.multindex+1:])\n            res += \";\" \n        return res",
  "def __init__(self, prefix, glyphs, suffix, replacement,\n                 forceChain, location=None):\n        ast.Statement.__init__(self, location)\n        self.prefix, self.glyphs, self.suffix = (prefix, glyphs, suffix)\n        self.replacement, self.forceChain = replacement, forceChain\n        lenreplace = len(self.replacement.glyphSet())\n        for i, g in enumerate(self.glyphs):\n            if len(g.glyphSet()) == lenreplace:\n                self.multindex = i #first LHS slot with a glyph class\n                break\n        else:\n            if lenreplace > 1:\n                raise FeatureLibError(\"No class matches replacement class length\", location)\n            else:\n                self.multindex = 0",
  "def build(self, builder):\n        prefix = [p.glyphSet() for p in self.prefix]\n        glyphs = [g.glyphSet() for g in self.glyphs]\n        suffix = [s.glyphSet() for s in self.suffix]\n        replacements = self.replacement.glyphSet()\n        lenreplace = len(replacements.glyphSet())\n        glyphs = self.glyphs[self.multindex].glyphSet()\n        for i in range(max(len(glyphs), len(replacements))):\n            builder.add_ligature_subst(\n                self.location, prefix,\n                self.glyphs[:self.multindex] + glyphs[i] + self.glyphs[self.multindex+1:],\n                suffix, replacements[i if lenreplace > 1 else 0], self.forceChain)",
  "def asFea(self, indent=\"\"):\n        res = \"\"\n        pres = (\" \".join(map(asFea, self.prefix)) + \" \") if len(self.prefix) else \"\"\n        sufs = (\" \" + \" \".join(map(asFea, self.suffix))) if len(self.suffix) else \"\"\n        mark = \"'\" if len(self.prefix) or len(self.suffix) or self.forceChain else \"\"\n        if self.mode == 'literal':\n            res += \"sub \" + pres + \" \".join(asFea(g)+mark for g in self.glyphs) + sufs + \" by \"\n            res += self.replacements.asFea() + \";\"\n            return res\n        glyphs = self.glyphs[self.multindex].glyphSet()\n        replacements = self.replacement.glyphSet()\n        lenreplace = len(replacements)\n        count = max(len(glyphs), len(replacements))\n        for i in range(count) :\n            res += (\"\\n\" + indent if i > 0 else \"\") + \"sub \" + pres\n            res += \" \".join(asFea(g)+mark for g in self.glyphs[:self.multindex] + [glyphs[i]] + self.glyphs[self.multindex+1:])\n            res += sufs + \" by \"\n            res += asFea(replacements[i if lenreplace > 1 else 0])\n            res += \";\"\n        return res",
  "def __init__(self, prefix, glyphs, suffix, replacements, location=None):\n        ast.Statement.__init__(self, location)\n        self.prefix, self.glyphs, self.suffix = (prefix, glyphs, suffix)\n        self.replacements = replacements",
  "def build(self, builder):\n        prefix = [p.glyphSet() for p in self.prefix]\n        suffix = [s.glyphSet() for s in self.suffix]\n        l = len(self.glyphs.glyphSet())\n        for i, glyph in enumerate(self.glyphs.glyphSet()):\n            replacement = self.replacements.glyphSet()[i::l]\n            builder.add_alternate_subst(self.location, prefix, glyph, suffix,\n                                    replacement)",
  "def asFea(self, indent=\"\"):\n        res = \"\"\n        l = len(self.glyphs.glyphSet())\n        for i, glyph in enumerate(self.glyphs.glyphSet()):\n            if i > 0:\n                res += \"\\n\" + indent\n            res += \"sub \"\n            if len(self.prefix) or len(self.suffix):\n                if len(self.prefix):\n                    res += \" \".join(map(asFea, self.prefix)) + \" \"\n                res += asFea(glyph) + \"'\"    # even though we really only use 1\n                if len(self.suffix):\n                    res += \" \" + \" \".join(map(asFea, self.suffix))\n            else:\n                res += asFea(glyph)\n            res += \" from \"\n            replacements = ast.GlyphClass(glyphs=self.replacements.glyphSet()[i::l], location=self.location)\n            res += asFea(replacements)\n            res += \";\"\n        return res",
  "def __init__(self, testfn, name, cond, location=None):\n        ast.Block.__init__(self, location=location)\n        self.testfn = testfn\n        self.name = name",
  "def asFea(self, indent=\"\"):\n        if self.mode == 'literal':\n            res = \"{}if{}({}) {{\".format(indent, name, cond)\n            res += ast.Block.asFea(self, indent=indent)\n            res += indent + \"}\\n\"\n            return res\n        elif self.testfn():\n            return ast.Block.asFea(self, indent=indent)\n        else:\n            return \"\"",
  "def __init__(self, varnames, location=None):\n        ast.Statement.__init__(self, location=location)\n        self.names = varnames",
  "def items(self, variables):\n        yield ((None, None),)",
  "def __init__(self, varname, glyphs, location=None):\n        ast_DoSubStatement.__init__(self, [varname], location=location)\n        self.glyphs = glyphs.glyphSet()",
  "def items(self, variables):\n        for g in self.glyphs:\n            yield((self.names[0], g),)",
  "def __init__(self, varnames, expression, parser, location=None):\n        ast_DoSubStatement.__init__(self, varnames, location=location)\n        self.parser = parser\n        if not safeeval(expression):\n            expression='\"Unsafe Expression\"'\n        self.expr = expression",
  "def items(self, variables):\n        gbls = dict(self.parser.fns, **variables)\n        try:\n            v = eval(self.expr, gbls)\n        except Exception as e:\n            raise FeatureLibError(str(e) + \" in \" + self.expr, self.location)\n        if self.names is None:      # in an if\n            yield((None, v),)\n        elif len(self.names) == 1:\n            yield((self.names[0], v),)\n        else:\n            yield(zip(self.names, list(v) + [None] * (len(self.names) - len(v))))",
  "def __init__(self, expression, parser, block, location=None):\n        ast_DoLetSubStatement.__init__(self, None, expression, parser, location=None)\n        self.block = block",
  "def items(self, variables):\n        (_, v) = list(ast_DoLetSubStatement.items(self, variables))[0][0]\n        yield (None, (v if v else None),)",
  "def __init__(self, kerninfo, location=None):\n        super(ast_KernPairsStatement, self).__init__(location)\n        self.kerninfo = kerninfo",
  "def asFea(self, indent=\"\"):\n        # return (\"\\n\"+indent).join(\"pos {} {} {};\".format(k1, round(v), k2) \\\n        #           for k1, x in self.kerninfo.items() for k2, v in x.items())\n        coverage = set()\n        rules = dict()\n\n        # first sort into lists by type of rule\n        for k1, x in self.kerninfo.items():\n            for k2, v in x.items():\n                # Determine pair kern type, where:\n                #   'gg' = glyph-glyph, 'gc' = glyph-class', 'cg' = class-glyph, 'cc' = class-class\n                ruleType = 'gc'[k1[0]=='@'] + 'gc'[k2[0]=='@']\n                rules.setdefault(ruleType, list()).append([k1, round(v), k2])\n                # for glyph-glyph rules, make list of first glyphs:\n                if ruleType == 'gg':\n                    coverage.add(k1)\n\n        # Now assemble lines in order and convert gc rules to gg where possible:\n        res = []\n        for ruleType in filter(lambda x: x in rules, ('gg', 'gc', 'cg', 'cc')):\n            if ruleType != 'gc':\n                res.extend(['pos {} {} {};'.format(k1, v, k2) for k1,v,k2 in rules[ruleType]])\n            else:\n                res.extend(['enum pos {} {} {};'.format(k1, v, k2) for k1, v, k2 in rules[ruleType] if k1 not in coverage])\n                res.extend(['pos {} {} {};'.format(k1, v, k2) for k1, v, k2 in rules[ruleType] if k1 in coverage])\n\n        return (\"\\n\"+indent).join(res)",
  "class _Ucontainer(object):\n    # Parent class for other objects (eg Ulayer)\n    def __init__(self):\n        self._contents = {}\n\n    # Define methods so it acts like an immutable container\n    # (changes should be made via object functions etc)\n    def __len__(self):\n        return len(self._contents)\n\n    def __getitem__(self, key):\n        return self._contents[key]\n\n    def __iter__(self):\n        return iter(self._contents)\n\n    def get(self, key, default=None):\n        return self._contents.get(key, default=default)\n\n    def keys(self):\n        return self._contents.keys()",
  "class _plist(object):\n    # Used for common plist methods inherited by Uplist and Ulib classes\n\n    def addval(self, key, valuetype, value):  # For simple single-value elements - use addelem for dicts or arrays\n        if valuetype not in (\"integer\", \"real\", \"string\"):\n            self.font.logger.log(\"addval() can only be used with simple elements\", \"X\")\n        if key in self._contents: self.font.logger.log(\"Attempt to add duplicate key \" + key + \" to plist\", \"X\")\n        dict = self.etree[0]\n\n        keyelem = ET.Element(\"key\")\n        keyelem.text = key\n        dict.append(keyelem)\n\n        valelem = ET.Element(valuetype)\n        valelem.text = str(value)\n        dict.append(valelem)\n\n        self._contents[key] = [keyelem, valelem]\n\n    def setval(self, key, valuetype, value):  # For simple single-value elements - use setelem for dicts or arrays\n        if valuetype not in (\"integer\", \"real\", \"string\"):\n            self.font.logger.log(\"setval() can only be used with simple elements\", \"X\")\n        if key in self._contents:\n            self._contents[key][1].text = str(value)\n        else:\n            self.addval(key, valuetype, value)\n\n    def getval(self, key, default=None):  # Returns a value for integer, real, string, true, false, dict or array keys or None for other keys\n        elem = self._contents.get(key, [None, None])[1]\n        if elem is None:\n            return default\n        return self._valelem(elem)\n\n    def _valelem(self, elem):  # Used by getval to recursively process dict and array elements\n        if elem.tag == \"integer\": return int(elem.text)\n        elif elem.tag == \"real\": return float(elem.text)\n        elif elem.tag == \"string\": return elem.text\n        elif elem.tag == \"true\": return True\n        elif elem.tag == \"false\": return False\n        elif elem.tag == \"array\":\n            array = []\n            for subelem in elem: array.append(self._valelem(subelem))\n            return array\n        elif elem.tag == \"dict\":\n            dict = {}\n            for i in range(0, len(elem), 2): dict[elem[i].text] = self._valelem(elem[i + 1])\n            return dict\n        else:\n            return None\n\n    def remove(self, key):\n        item = self._contents[key]\n        self.etree[0].remove(item[0])\n        self.etree[0].remove(item[1])\n        del self._contents[key]\n\n    def addelem(self, key, element):  # For non-simple elements (eg arrays) the calling script needs to build the etree element\n        if key in self._contents: self.font.logger.log(\"Attempt to add duplicate key \" + key + \" to plist\", \"X\")\n        dict = self.etree[0]\n\n        keyelem = ET.Element(\"key\")\n        keyelem.text = key\n        dict.append(keyelem)\n        dict.append(element)\n\n        self._contents[key] = [keyelem, element]\n\n    def setelem(self, key, element):\n        if key in self._contents: self.remove(key)\n        self.addelem(key, element)",
  "class Uelement(_Ucontainer):\n    # Class for an etree element. Mainly used as a parent class\n    # For each tag in the element, returns list of sub-elements with that tag\n    def __init__(self, element):\n        self.element = element\n        self.reindex()\n\n    def reindex(self):\n        self._contents = collections.defaultdict(list)\n        for e in self.element:\n            self._contents[e.tag].append(e)\n\n    def remove(self, subelement):\n        self._contents[subelement.tag].remove(subelement)\n        self.element.remove(subelement)\n\n    def append(self, subelement):\n        self._contents[subelement.tag].append(subelement)\n        self.element.append(subelement)\n\n    def insert(self, index, subelement):\n        self._contents[subelement.tag].insert(index, subelement)\n        self.element.insert(index, subelement)\n\n    def replace(self, index, subelement):\n        oldsubelement = self.element[index]\n        cindex = self._contents[subelement.tag].index(oldsubelement)\n        self._contents[subelement.tag][cindex] = subelement\n        self.element[index] = subelement",
  "class UtextFile(object):\n    # Generic object for handling non-xml text files\n    def __init__(self, font, dirn, filen):\n        self.type = \"textfile\"\n        self.font = font\n        self.filen = filen\n        self.dirn = dirn\n        if dirn == font.ufodir:\n            dtree = font.dtree\n        else:\n            dtree = font.dtree.subtree(dirn)\n            if not dtree: font.logger.log(\"Missing directory \" + dirn, \"X\")\n        if filen not in dtree:\n            dtree[filen] = UT.dirTreeItem(added=True)\n        dtree[filen].setinfo(read=True)\n        dtree[filen].fileObject = self\n        dtree[filen].fileType = \"text\"\n\n    def write(self, dtreeitem, dir, ofilen, exists):\n        # For now just copies source to destination if changed\n        inpath = os.path.join(self.dirn, self.filen)\n        changed = True\n        if exists: changed = not (filecmp.cmp(inpath, os.path.join(dir, self.filen)))\n        if changed:\n            try:\n                shutil.copy2(inpath, dir)\n            except Exception as e:\n                print(e)\n                sys.exit(1)\n        dtreeitem.written = True",
  "class Udirectory(object):\n    # Generic object for handling directories - used for data and images\n    def __init__(self, font, parentdir, dirn):\n        self.type = \"directory\"\n        self.font = font\n        self.parentdir = parentdir\n        self.dirn = dirn\n        if parentdir != font.ufodir:\n            self.font.logger.log(\"Currently Udir only supports top-level directories\", \"X\")\n        dtree = font.dtree\n        if dirn not in dtree:\n            self.font.logger.log(\"Udir directory \" + dirn + \" does not exist\", \"X\")\n        dtree[dirn].setinfo(read=True)\n        dtree[dirn].fileObject = self\n        dtree[dirn].fileType = \"directory\"\n\n    def write(self, dtreeitem, oparentdir):\n        # For now just copies source to destination\n        if self.parentdir == oparentdir: return # No action needed\n        inpath = os.path.join(self.parentdir, self.dirn)\n        outpath = os.path.join(oparentdir, self.dirn)\n        try:\n            if os.path.isdir(outpath):\n                shutil.rmtree(outpath)\n            shutil.copytree(inpath, outpath)\n        except Exception as e:\n            print(e)\n            sys.exit(1)\n        dtreeitem.written = True",
  "class Ufont(object):\n    \"\"\" Object to hold all the data from a UFO\"\"\"\n\n    def __init__(self, ufodir, logger=None, params=None):\n        if logger is not None and params is not None:\n            params.logger.log(\"Only supply a logger if params not set (since that has one)\", \"X\")\n        if params is None:\n            params = silfont.core.parameters()\n            if logger is not None: params.logger = logger\n        self.params = params\n        self.logger = params.logger\n        logger = self.logger\n        self.ufodir = ufodir\n        logger.log('Reading UFO: ' + ufodir, 'P')\n        if not os.path.isdir(ufodir):\n            logger.log(ufodir + \" is not a directory\", \"S\")\n        # Read list of files and folders\n        self.dtree = UT.dirTree(ufodir)\n        # Read metainfo (which must exist)\n        self.metainfo = self._readPlist(\"metainfo.plist\")\n        self.UFOversion = self.metainfo[\"formatVersion\"][1].text\n        # Read lib.plist then process pysilfont parameters if present\n        libparams = {}\n        if \"lib.plist\" in self.dtree:\n            self.lib = self._readPlist(\"lib.plist\")\n            if \"org.sil.pysilfontparams\" in self.lib:\n                elem = self.lib[\"org.sil.pysilfontparams\"][1]\n                if elem.tag != \"array\":\n                    logger.log(\"Invalid parameter XML lib.plist - org.sil.pysilfontparams must be an array\", \"S\")\n                for param in elem:\n                    parn = param.tag\n                    if not (parn in params.paramclass) or params.paramclass[parn] not in (\"outparams\", \"ufometadata\"):\n                        logger.log(\"lib.plist org.sil.pysilfontparams must only contain outparams or ufometadata values: \" + parn + \" invalid\", \"S\")\n                    libparams[parn] = param.text\n        # Create font-specific parameter set (with updates from lib.plist)  Prepend names with ufodir to ensure uniqueness if multiple fonts open\n        params.addset(ufodir + \"lib\", \"lib.plist in \" + ufodir, inputdict=libparams)\n        if \"command line\" in params.sets:\n            params.sets[ufodir + \"lib\"].updatewith(\"command line\", log=False)  # Command line parameters override lib.plist ones\n        copyset = \"main\" if \"main\" in params.sets else \"default\"\n        params.addset(ufodir, copyset=copyset)\n        params.sets[ufodir].updatewith(ufodir + \"lib\", sourcedesc=\"lib.plist\")\n        self.paramset = params.sets[ufodir]\n        # Validate specific parameters\n        if self.paramset[\"UFOversion\"] not in (\"\", \"2\", \"3\"): logger.log(\"UFO version must be 2 or 3\", \"S\")\n        if sorted(self.paramset[\"glifElemOrder\"]) != sorted(self.params.sets[\"default\"][\"glifElemOrder\"]):\n            logger.log(\"Invalid values for glifElemOrder\", \"S\")\n\n        # Create outparams based on values in paramset, building attriborders from separate attriborders.<type> parameters.\n        self.outparams = {\"attribOrders\": {}}\n        for parn in params.classes[\"outparams\"]:\n            value = self.paramset[parn]\n            if parn[0:12] == 'attribOrders':\n                elemname = parn.split(\".\")[1]\n                self.outparams[\"attribOrders\"][elemname] = ETU.makeAttribOrder(value)\n            else:\n                self.outparams[parn] = value\n        if self.outparams[\"UFOversion\"] == \"\": self.outparams[\"UFOversion\"] = self.UFOversion\n\n        # Set flags for checking and fixing metadata\n        cf = self.paramset[\"checkfix\"].lower()\n        if cf not in (\"check\", \"fix\", \"none\", \"\"): logger.log(\"Invalid value '\" + cf + \"' for checkfix parameter\", \"S\")\n\n        self.metacheck = True if cf in (\"check\", \"fix\") else False\n        self.metafix = True if cf == \"fix\" else False\n        if \"fontinfo.plist\" not in self.dtree:\n            logger.log(\"fontinfo.plist missing so checkfix routines can't be run\", \"E\")\n            self.metacheck = False\n            self.metafix = False\n\n        # Read other top-level plists\n        if \"fontinfo.plist\" in self.dtree: self.fontinfo = self._readPlist(\"fontinfo.plist\")\n        if \"groups.plist\" in self.dtree: self.groups = self._readPlist(\"groups.plist\")\n        if \"kerning.plist\" in self.dtree: self.kerning = self._readPlist(\"kerning.plist\")\n        createlayercontents = False\n        if self.UFOversion == \"2\":  # Create a dummy layer contents so 2 & 3 can be handled the same\n            createlayercontents = True\n        else:\n            if \"layercontents.plist\" in self.dtree:\n                self.layercontents = self._readPlist(\"layercontents.plist\")\n            else:\n                logger.log(\"layercontents.plist missing - one will be created\", \"W\")\n                createlayercontents = True\n        if createlayercontents:\n            if \"glyphs\" not in self.dtree: logger.log('No glyphs directory in font', \"S\")\n            self.layercontents = Uplist(font=self)\n            self.dtree['layercontents.plist'] = UT.dirTreeItem(read=True, added=True, fileObject=self.layercontents,\n                                                               fileType=\"xml\")\n            dummylc = \"<plist>\\n<array>\\n<array>\\n<string>public.default</string>\\n<string>glyphs</string>\\n</array>\\n</array>\\n</plist>\"\n            self.layercontents.etree = ET.fromstring(dummylc)\n            self.layercontents.populate_dict()\n\n        # Process features.fea\n        if \"features.fea\" in self.dtree:\n            self.features = UfeatureFile(self, ufodir, \"features.fea\")\n        # Process the glyphs directories)\n        self.layers = []\n        self.deflayer = None\n        for i in sorted(self.layercontents.keys()):\n            layername = self.layercontents[i][0].text\n            layerdir = self.layercontents[i][1].text\n            logger.log(\"Processing Glyph Layer \" + str(i) + \": \" + layername + layerdir, \"I\")\n            layer = Ulayer(layername, layerdir, self)\n            if layer:\n                self.layers.append(layer)\n                if layername == \"public.default\": self.deflayer = layer\n            else:\n                logger.log(\"Glyph directory \" + layerdir + \" missing\", \"S\")\n        if self.deflayer is None: logger.log(\"No public.default layer\", \"S\")\n        # Process other directories\n        if \"images\" in self.dtree:\n            self.images = Udirectory(self,ufodir, \"images\")\n        if \"data\" in self.dtree:\n            self.data = Udirectory(self, ufodir, \"data\")\n\n        # Run best practices check and fix routines\n        if self.metacheck:\n            initwarnings = logger.warningcount\n            initerrors = logger.errorcount\n\n            fireq = (\"ascender\", \"copyright\", \"descender\", \"familyName\", \"openTypeNameManufacturer\",\n                        \"styleName\", \"unitsPerEm\", \"versionMajor\", \"versionMinor\")\n            fiwarnifmiss = (\"capHeight\", \"copyright\", \"openTypeNameDescription\", \"openTypeNameDesigner\",\n                        \"openTypeNameDesignerURL\", \"openTypeNameLicense\", \"openTypeNameLicenseURL\",\n                        \"openTypeNameManufacturerURL\", \"openTypeOS2CodePageRanges\",\n                        \"openTypeOS2UnicodeRanges\", \"openTypeOS2VendorID\",\n                        \"openTypeOS2WeightClass\", \"openTypeOS2WinAscent\", \"openTypeOS2WinDescent\")\n            fiwarnifnot = {\"unitsPerEm\": (1000, 2048),\n                           \"styleMapStyleName\": (\"regular\", \"bold\", \"italic\", \"bold italic\")},\n            fiwarnifpresent = (\"note\",)\n            fidel = (\"macintoshFONDFamilyID\", \"macintoshFONDName\", \"openTypeNameCompatibleFullName\",\n                     \"openTypeGaspRangeRecords\", \"openTypeHheaCaretOffset\",\n                     \"openTypeOS2FamilyClass\", \"postscriptForceBold\", \"postscriptIsFixedPitch\",\n                     \"postscriptBlueFuzz\", \"postscriptBlueScale\", \"postscriptBlueShift\", \"postscriptWeightName\",\n                     \"year\")\n            fidelifempty = (\"guidelines\", \"postscriptBlueValues\", \"postscriptFamilyBlues\", \"postscriptFamilyOtherBlues\",\n                            \"postscriptOtherBlues\")\n            fiint = (\"ascender\", \"capHeight\", \"descender\", \"postscriptUnderlinePosition\",\n                     \"postscriptUnderlineThickness\", \"unitsPerEm\", \"xHeight\")\n            ficapitalize = (\"styleMapFamilyName\", \"styleName\")\n            fisetifmissing = {}\n            fisettoother = {\"openTypeHheaAscender\": \"ascender\", \"openTypeHheaDescender\": \"descender\",\n                            \"openTypeNamePreferredFamilyName\": \"familyName\",\n                            \"openTypeNamePreferredSubfamilyName\": \"styleName\", \"openTypeOS2TypoAscender\": \"ascender\",\n                            \"openTypeOS2TypoDescender\": \"descender\"}\n            fisetto = {\"openTypeHheaLineGap\": 0, \"openTypeOS2TypoLineGap\": 0, \"openTypeOS2WidthClass\": 5,\n                       \"openTypeOS2Selection\": [7], \"openTypeOS2Type\": []} # Other values are added below\n\n            libdel = (\"com.fontlab.v2.tth\", \"com.typemytype.robofont.italicSlantOffset\")\n            libsetto = {\"com.schriftgestaltung.customParameter.GSFont.disablesAutomaticAlignment\": True,\n                            \"com.schriftgestaltung.customParameter.GSFont.disablesLastChange\": True}\n            libwarnifnot = {\"com.schriftgestaltung.customParameter.GSFont.useNiceNames\": False}\n            libwarnifmissing = (\"public.glyphOrder\",)\n\n            # fontinfo.plist checks\n            logger.log(\"Checking fontinfo.plist metadata\", \"P\")\n\n            # Check required fields, some of which are needed for remaining checks\n            missing = []\n            for key in fireq:\n                if key not in self.fontinfo or self.fontinfo.getval(key) is None: missing.append(key)\n            # Collect values for constructing other fields, setting dummy values when missing and in check-only mode\n            dummies = False\n            storedvals = {}\n            for key in (\"ascender\", \"copyright\", \"descender\", \"familyName\", \"styleName\", \"openTypeNameManufacturer\", \"versionMajor\", \"versionMinor\"):\n                if key in self.fontinfo and self.fontinfo.getval(key) is not None:\n                    storedvals[key] = self.fontinfo.getval(key)\n                    if key == \"styleName\":\n                        sn = storedvals[key]\n                        sn = re.sub(r\"(\\w)(Italic)\", r\"\\1 \\2\", sn)  # Add a space before Italic if missing\n                        # Capitalise first letter of words\n                        sep = b' ' if type(sn) is bytes else ' '\n                        sn = sep.join(s[:1].upper() + s[1:] for s in sn.split(sep))\n                        if sn != storedvals[key]:\n                            if self.metafix:\n                                self.fontinfo.setval(key, \"string\", sn)\n                                logmess = \" updated \"\n                            else:\n                                logmess = \" would be updated \"\n                            self.logchange(logmess, key, storedvals[key], sn)\n                            storedvals[key] = sn\n                    if key in (\"ascender\", \"descender\"):\n                        storedvals[key] = int(storedvals[key])\n                else:\n                    dummies = True\n                    if key in (\"ascender\", \"descender\", \"versionMajor\", \"versionMinor\"):\n                        storedvals[key] = 999\n                    else:\n                        storedvals[key] = \"Dummy\"\n            if missing:\n                logtype = \"S\" if self.metafix else \"W\"\n                logger.log(\"Required fields missing from fontinfo.plist: \" + str(missing), logtype)\n            if dummies:\n                logger.log(\"Checking will continue with values of 'Dummy' or 999 for missing fields\", \"W\")\n            # Construct values for certain fields\n            value = storedvals[\"openTypeNameManufacturer\"] + \": \" + storedvals[\"familyName\"] + \" \"\n            value = value + storedvals[\"styleName\"] + \": \" + datetime.datetime.now().strftime(\"%Y\")\n            fisetto[\"openTypeNameUniqueID\"] = value\n#            fisetto[\"openTypeOS2WinDescent\"] = -storedvals[\"descender\"]\n            if \"openTypeNameVersion\" not in self.fontinfo:\n                fisetto[\"openTypeNameVersion\"] = \"Version \" + str(storedvals[\"versionMajor\"]) + \".\"\\\n                                                 + str(storedvals[\"versionMinor\"])\n            if \"openTypeOS2WeightClass\" not in self.fontinfo:\n                sn = storedvals[\"styleName\"]\n                sn2wc = {\"Regular\": 400, \"Italic\": 400, \"Bold\": 700, \"BoldItalic\": 700}\n                if sn in sn2wc: fisetto[\"openTypeOS2WeightClass\"] = sn2wc[sn]\n            if \"xHeight\" not in self.fontinfo:\n                fisetto[\"xHeight\"] = int(storedvals[\"ascender\"] * 0.6)\n            if \"openTypeOS2Selection\" in self.fontinfo: # If already present, need to ensure bit 7 is set\n                fisetto[\"openTypeOS2Selection\"] = sorted(list(set(self.fontinfo.getval(\"openTypeOS2Selection\") + [7])))\n\n            for key in fisetifmissing:\n                if key not in self.fontinfo:\n                    fisetto[key] = fisetifmissing[key]\n\n            changes = 0\n            # Warn about missing fields\n            for key in fiwarnifmiss:\n                if key not in self.fontinfo:\n                    logmess = key + \" is missing from fontinfo.plist\"\n                    logger.log(logmess, \"W\")\n            # Warn about bad values\n            for key in fiwarnifnot:\n                if key in self.fontinfo:\n                    value = self.fontinfo.getval(key)\n                    if value not in fiwarnifnot[key]:\n                        logger.log(key + \" should be one of \" + str(fiwarnifnot[key]), \"W\")\n            # Warn about keys where use of discouraged\n            for key in fiwarnifpresent:\n                if key in self.fontinfo:\n                    logger.log(key + \" is present - it's use is discouraged\")\n\n            # Now do all remaining checks - which will lead to values being changed\n            for key in fidel + fidelifempty:\n                if key in self.fontinfo:\n                    old = self.fontinfo.getval(key)\n                    if not(key in fidelifempty and old != []): # Delete except for non-empty fidelifempty\n                        if self.metafix:\n                            self.fontinfo.remove(key)\n                            logmess = \" removed from fontinfo. \"\n                        else:\n                            logmess = \" would be removed from fontinfo \"\n                        self.logchange(logmess, key, old, None)\n                        changes += 1\n\n            # Set to integer values\n            for key in fiint:\n                if key in self.fontinfo:\n                    old = self.fontinfo.getval(key)\n                    if old != int(old):\n                        new = int(old)\n                        if self.metafix:\n                            self.fontinfo.setval(key, \"integer\", new)\n                            logmess = \" updated \"\n                        else:\n                            logmess = \" would be updated \"\n                        self.logchange(logmess, key, old, new)\n                        changes += 1\n            # Capitalize words\n            for key in ficapitalize:\n                if key in self.fontinfo:\n                    old = self.fontinfo.getval(key)\n                    sep = b' ' if type(old) is bytes else ' '\n                    new = sep.join(s[:1].upper() + s[1:] for s in old.split(sep))  # Capitalise words\n                    if new != old:\n                        if self.metafix:\n                            self.fontinfo.setval(key, \"string\", new)\n                            logmess = \" uppdated \"\n                        else:\n                            logmess = \" would be uppdated \"\n                        self.logchange(logmess, key, old, new)\n                        changes += 1\n            # Set to specific values\n            for key in list(fisetto.keys()) + list(fisettoother.keys()):\n                if key in self.fontinfo:\n                    old = self.fontinfo.getval(key)\n                    logmess = \" updated \"\n                else:\n                    old = None\n                    logmess = \" added \"\n                if key in fisetto:\n                    new = fisetto[key]\n                else:\n                    new = storedvals[fisettoother[key]]\n                if new != old:\n                    if self.metafix:\n                        if isinstance(new, list): # Currently only integer arrays\n                            array = ET.Element(\"array\")\n                            for val in new: # Only covers integer at present for openTypeOS2Selection\n                                ET.SubElement(array, \"integer\").text = val\n                                self.fontinfo.setelem(key, array)\n                        else: # Does not cover real at present\n                            valtype = \"integer\" if isinstance(new, int) else \"string\"\n                            self.fontinfo.setval(key, valtype, new)\n                    else:\n                        logmess = \" would be\" + logmess\n                    self.logchange(logmess, key, old, new)\n                    changes += 1\n            # Specific checks\n            if \"italicAngle\" in self.fontinfo:\n                old = self.fontinfo.getval(\"italicAngle\")\n                if old == 0: # Should be deleted if 0\n                    logmess = \" removed since it is 0 \"\n                    if self.metafix:\n                        self.fontinfo.remove(\"italicAngle\")\n                    else:\n                        logmess = \" would be\" + logmess\n                    self.logchange(logmess, \"italicAngle\", old, None)\n                    changes += 1\n            if \"versionMajor\" in self.fontinfo: # If missing, an error will already have been reported...\n                vm = self.fontinfo.getval(\"versionMajor\")\n                if vm == 0: logger.log(\"versionMajor is 0\", \"W\")\n\n            # lib.plist checks\n            if \"lib\" not in self.__dict__:\n                logger.log(\"lib.plist missing so not checked by check & fix routines\", \"E\")\n            else:\n                logger.log(\"Checking lib.plist metadata\", \"P\")\n\n                for key in libdel:\n                    if key in self.lib:\n                        old = self.lib.getval(key)\n                        if self.metafix:\n                            self.lib.remove(key)\n                            logmess = \" removed from lib.plist. \"\n                        else:\n                            logmess = \" would be removed from lib.plist \"\n                        self.logchange(logmess, key, old, None)\n                        changes += 1\n\n                for key in libsetto:\n                    if key in self.lib:\n                        old = self.lib.getval(key)\n                        logmess = \" updated \"\n                    else:\n                        old = None\n                        logmess = \" added \"\n                    new = libsetto[key]\n                    if new != old:\n                        if self.metafix:\n                            # Currently just supports True.  See fisetto for adding other types\n                            if new == True:\n                                self.lib.setelem(key, ET.fromstring(\"<true/>\"))\n                            else:  # Does not cover real at present\n                                logger.log(\"Invalid value type for libsetto\", \"X\")\n                        else:\n                            logmess = \" would be\" + logmess\n                        self.logchange(logmess, key, old, new)\n                        changes += 1\n                for key in libwarnifnot:\n                    value = self.lib.getval(key) if key in self.lib else None\n                    if value != libwarnifnot[key]:\n                        addmess = \"; currently missing\" if value is None else \"; currently set to \" + str(value)\n                        logger.log(key + \" should normally be \" + str(libwarnifnot[key]) + addmess, \"W\")\n\n                for key in libwarnifmissing:\n                    if key not in self.lib:\n                        logger.log(key + \" is missing from lib.plist\", \"W\")\n\n                logmess = \" deleted - obsolete key\" if self.metafix else \" would be deleted - obsolete key\"\n                for key in obsoleteLibKeys: # For obsolete keys that have been added historically by some tools\n                    if key in self.lib:\n                        old = self.lib.getval(key)\n                        if self.metafix: self.lib.remove(key)\n                        self.logchange(logmess,key,old,None)\n                        changes += 1\n\n            # Show check&fix summary\n            warnings = logger.warningcount - initwarnings - changes\n            errors = logger.errorcount - initerrors\n            if errors or warnings or changes:\n                changemess = \", Changes made: \" if self.metafix else \", Changes to make: \"\n                logger.log(\"Check & fix results:- Errors: \" + str(errors) + changemess + str(changes) +\n                           \", Other warnings: \" + str(warnings), \"P\")\n                if logger.scrlevel not in \"WIV\": logger.log(\"See log file for details\", \"P\")\n                if missing and not self.metafix:\n                    logger.log(\"**** Since some required fields were missing, checkfix=fix would fail\", \"P\")\n            else:\n                logger.log(\"Check & Fix ran cleanly\", \"P\")\n\n    def _readPlist(self, filen):\n        if filen in self.dtree:\n            plist = Uplist(font=self, filen=filen)\n            self.dtree[filen].setinfo(read=True, fileObject=plist, fileType=\"xml\")\n            return plist\n        else:\n            self.logger.log(filen + \" does not exist\", \"S\")\n\n    def write(self, outdir):\n        # Write UFO out to disk, based on values set in self.outparams\n        self.logger.log(\"Processing font for output\", \"P\")\n        if not os.path.exists(outdir):\n            try:\n                os.mkdir(outdir)\n            except Exception as e:\n                print(e)\n                sys.exit(1)\n        if not os.path.isdir(outdir):\n            self.logger.log(outdir + \" not a directory\", \"S\")\n\n        # If output UFO already exists, need to open so only changed files are updated and redundant files deleted\n        if outdir == self.ufodir:  # In special case of output and input being the same, simply copy the input font\n            odtree = UT.dirTree(outdir)\n        else:\n            if not os.path.exists(outdir):  # If outdir does not exist, create it\n                try:\n                    os.mkdir(outdir)\n                except Exception as e:\n                    print(e)\n                    sys.exit(1)\n                odtree = {}\n            else:\n                if not os.path.isdir(outdir): self.logger.log(outdir + \" not a directory\", \"S\")\n                dirlist = os.listdir(outdir)\n                if dirlist == []:  # Outdir is empty\n                    odtree = {}\n                else:\n                    self.logger.log(\"Output UFO already exists - reading for comparison\", \"P\")\n                    odtree = UT.dirTree(outdir)\n        # Update version info etc\n        UFOversion = self.outparams[\"UFOversion\"]\n        self.metainfo[\"formatVersion\"][1].text = str(UFOversion)\n        self.metainfo[\"creator\"][1].text = \"org.sil.scripts.pysilfont\"\n\n        # Set standard UFO files for output\n        dtree = self.dtree\n        setFileForOutput(dtree, \"metainfo.plist\", self.metainfo, \"xml\")\n        if \"fontinfo\" in self.__dict__: setFileForOutput(dtree, \"fontinfo.plist\", self.fontinfo, \"xml\")\n        if \"groups\" in self.__dict__: # With groups, sort by glyph name\n            for gname in list(self.groups):\n                group = self.groups.getval(gname)\n                elem = ET.Element(\"array\")\n                for glyph in sorted(group):\n                    ET.SubElement(elem, \"string\").text = glyph\n                self.groups.setelem(gname, elem)\n            setFileForOutput(dtree, \"groups.plist\", self.groups, \"xml\")\n        if \"kerning\" in self.__dict__: setFileForOutput(dtree, \"kerning.plist\", self.kerning, \"xml\")\n        if \"lib\" in self.__dict__: setFileForOutput(dtree, \"lib.plist\", self.lib, \"xml\")\n        if UFOversion == \"3\":\n            # Sort layer contents by layer name\n            lc = self.layercontents\n            lcindex = {lc[x][0].text: lc[x] for x in lc}  # index on layer name\n            for (x, name) in enumerate(sorted(lcindex)):\n                lc.etree[0][x] = lcindex[name]  # Replace array elements in new order\n            setFileForOutput(dtree, \"layercontents.plist\", self.layercontents, \"xml\")\n        if \"features\" in self.__dict__: setFileForOutput(dtree, \"features.fea\", self.features, \"text\")\n        # Set glyph layers for output\n        for layer in self.layers: layer.setForOutput()\n\n        # Write files to disk\n\n        self.logger.log(\"Writing font to \" + outdir, \"P\")\n\n        changes = writeToDisk(dtree, outdir, self, odtree)\n        if changes: # Need to update openTypeHeadCreated if there have been any changes to the font\n            if \"fontinfo\" in self.__dict__:\n                self.fontinfo.setval(\"openTypeHeadCreated\", \"string\",\n                                     datetime.datetime.now().strftime(\"%Y/%m/%d %H:%M:%S\"))\n                self.fontinfo.outxmlstr=\"\" # Need to reset since writeXMLobject has already run once\n                writeXMLobject(self.fontinfo, self.outparams, outdir, \"fontinfo.plist\", True, fobject=True)\n\n    def addfile(self, filetype):  # Add empty plist file for optional files\n        if filetype not in (\"fontinfo\", \"groups\", \"kerning\", \"lib\"): self.logger.log(\"Invalid file type to add\", \"X\")\n        if filetype in self.__dict__: self.logger.log(\"File already in font\", \"X\")\n        obj = Uplist(font=self)\n        setattr(self, filetype, obj)\n        self.dtree[filetype + '.plist'] = UT.dirTreeItem(read=True, added=True, fileObject=obj, fileType=\"xml\")\n        obj.etree = ET.fromstring(\"<plist>\\n<dict/>\\n</plist>\")\n\n    def logchange(self, logmess, key, old, new):\n        oldstr = str(old) if len(str(old)) < 22 else str(old)[0:20] + \"...\"\n        newstr = str(new) if len(str(new)) < 22 else str(new)[0:20] + \"...\"\n        logmess = key + logmess\n        if old is None:\n            logmess = logmess + \" New value: \" + newstr\n        else:\n            if new is None:\n                logmess = logmess + \" Old value: \" + oldstr\n            else:\n                logmess = logmess + \" Old value: \" + oldstr + \", new value: \" + newstr\n        self.logger.log(logmess, \"W\")\n        # Extra verbose logging\n        if len(str(old)) > 21:\n            self.logger.log(\"Full old value: \" + str(old), \"I\")\n        if len(str(new)) > 21:\n            self.logger.log(\"Full new value: \" + str(new), \"I\")\n        otype = \"string\" if isinstance(old, (bytes, str)) else type(old).__name__ # To produce consistent reporting\n        ntype = \"string\" if isinstance(new, (bytes, str)) else type(new).__name__ # with Python 2 & 3\n        self.logger.log(\"Types: Old - \" + otype + \", New - \" + ntype, \"I\")",
  "class Ulayer(_Ucontainer):\n    def __init__(self, layername, layerdir, font):\n        self._contents = collections.OrderedDict()\n        self.dtree = font.dtree.subTree(layerdir)\n        font.dtree[layerdir].read = True\n        self.layername = layername\n        self.layerdir = layerdir\n        self.font = font\n        fulldir = os.path.join(font.ufodir, layerdir)\n        self.contents = Uplist(font=font, dirn=fulldir, filen=\"contents.plist\")\n        self.dtree[\"contents.plist\"].setinfo(read=True, fileObject=self.contents, fileType=\"xml\")\n\n        if font.UFOversion == \"3\":\n            if 'layerinfo.plist' in self.dtree:\n                self.layerinfo = Uplist(font=font, dirn=fulldir, filen=\"layerinfo.plist\")\n                self.dtree[\"layerinfo.plist\"].setinfo(read=True, fileObject=self.layerinfo, fileType=\"xml\")\n\n        for glyphn in sorted(self.contents.keys()):\n            glifn = self.contents[glyphn][1].text\n            if glifn in self.dtree:\n                glyph = Uglif(layer=self, filen=glifn)\n                self._contents[glyphn] = glyph\n                self.dtree[glifn].setinfo(read=True, fileObject=glyph, fileType=\"xml\")\n                if glyph.name != glyphn:\n                    super(Uglif, glyph).__setattr__(\"name\", glyphn)  # Need to use super to bypass normal glyph renaming logic\n                    self.font.logger.log(\"Glyph names in glif and contents.plist did not match for \" + glyphn + \"; corrected\", \"W\")\n            else:\n                self.font.logger.log(\"Missing glif \" + glifn + \" in \" + fulldir, \"S\")\n\n    def setForOutput(self):\n\n        UFOversion = self.font.outparams[\"UFOversion\"]\n        convertg2f1 = True if UFOversion == \"2\" or self.font.outparams[\"format1Glifs\"] else False\n        dtree = self.font.dtree.subTree(self.layerdir)\n        if self.font.outparams[\"renameGlifs\"]: self.renameGlifs()\n\n        setFileForOutput(dtree, \"contents.plist\", self.contents, \"xml\")\n        if \"layerinfo\" in self.__dict__ and UFOversion == \"3\":\n            setFileForOutput(dtree, \"layerinfo.plist\", self.layerinfo, \"xml\")\n\n        for glyphn in self:\n            glyph = self._contents[glyphn]\n            if convertg2f1: glyph.convertToFormat1()\n            if glyph[\"advance\"] is not None:\n                if glyph[\"advance\"].width is None and glyph[\"advance\"].height is None: glyph.remove(\"advance\")\n            # Normalize so that, when both exist, components come before contour\n            outline = glyph[\"outline\"]\n            if len(outline.components) > 0 and list(outline)[0] == \"contour\":\n                # Need to move components to the front...\n                contours = outline.contours\n                components = outline.components\n                oldcontours = list(contours)  # Easiest way to 'move' components is to delete contours then append back at the end\n                for contour in oldcontours: outline.removeobject(contour, \"contour\")\n                for contour in oldcontours: outline.appendobject(contour, \"contour\")\n\n            setFileForOutput(dtree, glyph.filen, glyph, \"xml\")\n\n    def renameGlifs(self):\n        namelist = []\n        for glyphn in sorted(self.keys()):\n            glyph = self._contents[glyphn]\n            filename = makeFileName(glyphn, namelist)\n            namelist.append(filename.lower())\n            filename += \".glif\"\n            if filename != glyph.filen:\n                self.renameGlif(glyphn, glyph, filename)\n\n    def renameGlif(self, glyphn, glyph, newname):\n        self.font.logger.log(\"Renaming glif for \" + glyphn + \" from \" + glyph.filen + \" to \" + newname, \"I\")\n        self.dtree.removedfiles[glyph.filen] = newname  # Track so original glif does not get reported as invalid\n        glyph.filen = newname\n        self.contents[glyphn][1].text = newname\n\n    def addGlyph(self, glyph):\n        glyphn = glyph.name\n        if glyphn in self._contents: self.font.logger.log(glyphn + \" already in font\", \"X\")\n        self._contents[glyphn] = glyph\n        # Set glif name\n        glifn = makeFileName(glyphn)\n        names = []\n        while glifn in self.contents:  # need to check for duplicate glif names\n            names.append(glifn)\n            glifn = makeFileName(glyphn, names)\n        glifn += \".glif\"\n        glyph.filen = glifn\n        # Add to contents.plist and dtree\n        self.contents.addval(glyphn, \"string\", glifn)\n        self.dtree[glifn] = UT.dirTreeItem(read=False, added=True, fileObject=glyph, fileType=\"xml\")\n\n    def delGlyph(self, glyphn):\n        self.dtree.removedfiles[self[glyphn].filen] = \"deleted\"  # Track so original glif does not get reported as invalid\n        del self._contents[glyphn]\n        self.contents.remove(glyphn)",
  "class Uplist(ETU.xmlitem, _plist):\n    def __init__(self, font=None, dirn=None, filen=None, parse=True):\n        if dirn is None and font: dirn = font.ufodir\n        logger = font.logger if font else silfont.core.loggerobj()\n        ETU.xmlitem.__init__(self, dirn, filen, parse, logger)\n        self.type = \"plist\"\n        self.font = font\n        self.outparams = None\n        if filen and dirn: self.populate_dict()\n\n    def populate_dict(self):\n        self._contents.clear()  # Clear existing contents, if any\n        pl = self.etree[0]\n        if pl.tag == \"dict\":\n            for i in range(0, len(pl), 2):\n                key = pl[i].text\n                self._contents[key] = [pl[i], pl[i + 1]]  # The two elements for the item\n        else:  # Assume array of 2 element arrays (eg layercontents.plist)\n            for i in range(len(pl)):\n                self._contents[i] = pl[i]",
  "class Uglif(ETU.xmlitem):\n    # Unlike plists, glifs can have multiples of some sub-elements (eg anchors) so create lists for those\n\n    def __init__(self, layer, filen=None, parse=True, name=None, format=None):\n        dirn = os.path.join(layer.font.ufodir, layer.layerdir)\n        ETU.xmlitem.__init__(self, dirn, filen, parse, layer.font.logger)  # Will read item from file if dirn and filen both present\n        self.type = \"glif\"\n        self.layer = layer\n        self.format = format if format else '2'\n        self.name = name\n        self.outparams = None\n        self.glifElemOrder = self.layer.font.outparams[\"glifElemOrder\"]\n        # Set initial values for sub-objects\n        for elem in self.glifElemOrder:\n            if elem in _glifElemMulti:\n                self._contents[elem] = []\n            else:\n                self._contents[elem] = None\n        if self.etree is not None: self.process_etree()\n\n    def __setattr__(self, name, value):\n        if name == \"name\" and getattr(self, \"name\", None):  # Existing glyph name is being changed\n            oname = self.name\n            if value in self.layer._contents: self.layer.font.logger.log(name + \" already in font\", \"X\")\n            # Update the _contents dictionary\n            del self.layer._contents[oname]\n            self.layer._contents[value] = self\n            # Set glif name\n            glifn = makeFileName(value)\n            names = []\n            while glifn in self.layer.contents:  # need to check for duplicate glif names\n                names.append(glifn)\n                glifn = makeFileName(value, names)\n            glifn += \".glif\"\n\n            # Update to contents.plist, filen and dtree\n            self.layer.contents.remove(oname)\n            self.layer.contents.addval(value, \"string\", glifn)\n            self.layer.dtree.removedfiles[self.filen] = glifn  # Track so original glif does not get reported as invalid\n            self.filen = glifn\n            self.layer.dtree[glifn] = UT.dirTreeItem(read=False, added=True, fileObject=self, fileType=\"xml\")\n        super(Uglif, self).__setattr__(name, value)\n\n    def process_etree(self):\n        et = self.etree\n        self.name = getattrib(et, \"name\")\n        self.format = getattrib(et, \"format\")\n        if self.format is None:\n            if self.layer.font.UFOversion == \"3\":\n                self.format = '2'\n            else:\n                self.format = '1'\n        for i in range(len(et)):\n            element = et[i]\n            tag = element.tag\n            if not tag in self.glifElemOrder: self.layer.font.logger.log(\n                \"Invalid element \" + tag + \" in glif \" + self.name, \"E\")\n            if tag in _glifElemF1 or self.format == '2':\n                if tag in _glifElemMulti:\n                    self._contents[tag].append(self.makeObject(tag, element))\n                else:\n                    self._contents[tag] = self.makeObject(tag, element)\n\n        # Convert UFO2 style anchors to UFO3 anchors\n        if self._contents['outline'] is not None and self.format == \"1\":\n            for contour in self._contents['outline'].contours[:]:\n                if contour.UFO2anchor:\n                    del contour.UFO2anchor[\"type\"]  # remove type=\"move\"\n                    self.add('anchor', contour.UFO2anchor)\n                    self._contents['outline'].removeobject(contour, \"contour\")\n        if self._contents['outline'] is None: self.add('outline')\n\n        self.format = \"2\"\n\n    def rebuildET(self):\n        self.etree = ET.Element(\"glyph\")\n        et = self.etree\n        et.attrib[\"name\"] = self.name\n        et.attrib[\"format\"] = self.format\n        # Insert sub-elements\n        for elem in self.glifElemOrder:\n            if elem in _glifElemF1 or self.format == \"2\":  # Check element is valid for glif format\n                item = self._contents[elem]\n                if item is not None:\n                    if elem in _glifElemMulti:\n                        for object in item:\n                            et.append(object.element)\n                    else:\n                        et.append(item.element)\n\n    def add(self, ename, attrib=None):\n        # Add an element and corresponding object to a glif\n        element = ET.Element(ename)\n        if attrib: element.attrib = attrib\n        if ename == \"lib\": ET.SubElement(element, \"dict\")\n        multi = True if ename in _glifElemMulti else False\n\n        if multi and ename not in self._contents:\n            self._contents[ename] = []\n\n        # Check element does not already exist for single elements\n        if ename in self._contents and not multi:\n            if self._contents[ename] is not None: self.layer.font.logger.log(\"Already an \" + ename + \" in glif\", \"X\")\n\n        # Add new object\n        if multi:\n            self._contents[ename].append(self.makeObject(ename, element))\n        else:\n            self._contents[ename] = self.makeObject(ename, element)\n\n    def remove(self, ename, index=None, object=None):\n        # Remove object from a glif\n        # For multi objects, an index or object must be supplied to identify which\n        # to delete\n        if ename in _glifElemMulti:\n            item = self._contents[ename]\n            if index is None: index = item.index(object)\n            del item[index]\n        else:\n            self._contents[ename] = None\n\n    def convertToFormat1(self):\n        # Convert to a glif format of 1 (for UFO2) prior to writing out\n        self.format = \"1\"\n        # Change anchors to UFO2 style anchors.  Sort anchors by anchor name first\n        anchororder = sorted(self._contents['anchor'], key=lambda x: x.element.attrib['name'])\n        for anchor in anchororder:\n            element = anchor.element\n            for attrn in ('colour', 'indentifier'):  # Remove format 2 attributes\n                if attrn in element.attrib: del element.attrib[attrn]\n            element.attrib['type'] = 'move'\n            contelement = ET.Element(\"contour\")\n            contelement.append(ET.Element(\"point\", element.attrib))\n            self._contents['outline'].appendobject(Ucontour(self._contents['outline'], contelement), \"contour\")\n            self.remove('anchor', object=anchor)\n\n    def makeObject(self, type, element):\n        if type == 'advance': return Uadvance(self, element)\n        if type == 'unicode': return Uunicode(self, element)\n        if type == 'outline': return Uoutline(self, element)\n        if type == 'lib': return Ulib(self, element)\n        if type == 'note': return Unote(self, element)\n        if type == 'image': return Uimage(self, element)\n        if type == 'guideline': return Uguideline(self, element)\n        if type == 'anchor': return Uanchor(self, element)",
  "class Uadvance(Uelement):\n    def __init__(self, glif, element):\n        super(Uadvance, self).__init__(element)\n        self.glif = glif\n        if 'width' in element.attrib:\n            self.width = element.attrib[str('width')]\n        else:\n            self.width = None\n        if 'height' in element.attrib:\n            self.height = element.attrib[str('height')]\n        else:\n            self.height = None\n\n    def __setattr__(self, name, value):\n        if name in ('width', 'height'):\n            if value == \"0\" : value = None\n            if value is None:\n                if name in self.element.attrib: del self.element.attrib[name]\n            else:\n                value = str(value)\n                self.element.attrib[name] = value\n        super(Uadvance, self).__setattr__(name, value)",
  "class Uunicode(Uelement):\n    def __init__(self, glif, element):\n        super(Uunicode, self).__init__(element)\n        self.glif = glif\n        if 'hex' in element.attrib:\n            self.hex = element.attrib['hex']\n        else:\n            self.hex = \"\"\n            self.glif.logger.log(\"No unicode hex attribute for \" + glif.name, \"E\")\n\n    def __setattr__(self, name, value):\n        if name == \"hex\": self.element.attrib['hex'] = value\n        super(Uunicode, self).__setattr__(name, value)",
  "class Unote(Uelement):\n    def __init__(self, glif, element):\n        self.glif = glif\n        super(Unote, self).__init__(element)",
  "class Uimage(Uelement):\n    def __init__(self, glif, element):\n        self.glif = glif\n        super(Uimage, self).__init__(element)",
  "class Uguideline(Uelement):\n    def __init__(self, glif, element):\n        self.glif = glif\n        super(Uguideline, self).__init__(element)",
  "class Uanchor(Uelement):\n    def __init__(self, glif, element):\n        self.glif = glif\n        super(Uanchor, self).__init__(element)",
  "class Uoutline(Uelement):\n    def __init__(self, glif, element):\n        super(Uoutline, self).__init__(element)\n        self.glif = glif\n        self.components = []\n        self.contours = []\n        for tag in self._contents:\n            if tag == \"component\":\n                for component in self._contents[tag]:\n                    self.components.append(Ucomponent(self, component))\n            if tag == \"contour\":\n                for contour in self._contents[tag]:\n                    self.contours.append(Ucontour(self, contour))\n\n    def removeobject(self, obj, typ):\n        super(Uoutline, self).remove(obj.element)\n        if typ == \"component\": self.components.remove(obj)\n        if typ == \"contour\": self.contours.remove(obj)\n\n    def replaceobject(self, oldobj, newobj, typ):\n        eindex = list(self.element).index(oldobj.element)\n        super(Uoutline, self).replace(eindex, newobj.element)\n        if typ == \"component\":\n            cindex = self.components.index(oldobj)\n            self.components[cindex]= newobj\n        if typ == \"contour\":\n            cindex = self.contours.index(oldobj)\n            self.contours[cindex]= newobj\n\n    def appendobject(self, item, typ): # Item can be an contour/component object, element or attribute list\n        if isinstance(item, (Ucontour, Ucomponent)):\n            obj = item\n        else:\n            if isinstance(item, dict):\n                elem = ET.Element(typ)\n                elem.attrib = item\n            elif isinstance(item, ET.Element):\n                elem = item\n            else:\n                self.glif.logger.log(\"item should be dict, element, Ucontour or Ucomponent\", \"S\")\n            if typ == 'component':\n                obj = Ucomponent(self,elem)\n            else:\n                obj = Ucontour(self,elem)\n        super(Uoutline, self).append(obj.element)\n        if typ == \"component\": self.components.append(obj)\n        if typ == \"contour\": self.contours.append(obj)\n\n    def insertobject(self, index, item, typ): # Needs updating to match appendobject\n        self.glif.logger.log(\"insertobject currently buggy so don't use!\", \"X\")",
  "class Ucomponent(Uelement):\n    def __init__(self, outline, element):\n        super(Ucomponent, self).__init__(element)\n        self.outline = outline",
  "class Ucontour(Uelement):\n    def __init__(self, outline, element):\n        super(Ucontour, self).__init__(element)\n        self.outline = outline\n        self.UFO2anchor = None\n        points = self._contents['point']\n        # Identify UFO2-style anchor points\n        if len(points) == 1 and \"type\" in points[0].attrib:\n            if points[0].attrib[\"type\"] == \"move\":\n                if \"name\" in points[0].attrib:\n                    self.UFO2anchor = points[0].attrib\n                else:\n                    self.outline.glif.layer.font.logger.log(\n                        \"Glyph \" + self.outline.glif.name + \" contains a single-point contour with no anchor name\", \"E\")",
  "class Ulib(_Ucontainer, _plist):\n    # For glif lib elements; top-level lib files use Uplist\n    def __init__(self, glif, element):\n        self.glif = glif\n        self.element = element  # needs both element and etree for compatibility\n        self.etree = element    # with other glif components and _plist methods\n        self._contents = {}\n        self.reindex()\n\n    def reindex(self):\n        self._contents.clear()  # Clear existing contents, if any\n        pl = self.element[0]\n        if pl.tag == \"dict\":\n            for i in range(0, len(pl), 2):\n                key = pl[i].text\n                self._contents[key] = [pl[i], pl[i + 1]]",
  "class UfeatureFile(UtextFile):\n    def __init__(self, font, dirn, filen):\n        super(UfeatureFile, self).__init__(font, dirn, filen)",
  "def writeXMLobject(dtreeitem, params, dirn, filen, exists, fobject=False):\n    object = dtreeitem if fobject else dtreeitem.fileObject  # Set fobject to True if a file object is passed ratehr than dtreeitem\n    if object.outparams: params = object.outparams  # override default params with object-specific ones\n    indentFirst = params[\"indentFirst\"]\n    attribOrder = {}\n    if object.type in params['attribOrders']: attribOrder = params['attribOrders'][object.type]\n    if object.type == \"plist\":\n        indentFirst = params[\"plistIndentFirst\"]\n        object.etree.attrib[\".doctype\"] = 'plist PUBLIC \"-//Apple Computer//DTD PLIST 1.0//EN\" \"http://www.apple.com/DTDs/PropertyList-1.0.dtd\"'\n\n    # Format ET data if any data parameters are set\n    if params[\"sortDicts\"] or params[\"precision\"] is not None: normETdata(object.etree, params, type=object.type)\n\n    etw = ETU.ETWriter(object.etree, attributeOrder=attribOrder, indentIncr=params[\"indentIncr\"],\n                       indentFirst=indentFirst, indentML=params[\"indentML\"], precision=params[\"precision\"],\n                       floatAttribs=params[\"floatAttribs\"], intAttribs=params[\"intAttribs\"])\n    object.outxmlstr=etw.serialize_xml()\n    # Now we have the output xml, need to compare with existing item's xml, if present\n    changed = True\n\n    if exists:  # File already on disk\n        if exists == \"same\":  # Output and input locations the same\n            oxmlstr = object.inxmlstr\n        else:  # Read existing XML from disk\n            oxmlstr = \"\"\n            try:\n                oxml = io.open(os.path.join(dirn, filen), \"r\", encoding=\"utf-8\")\n            except Exception as e:\n                print(e)\n                sys.exit(1)\n            for line in oxml.readlines():\n                oxmlstr += line\n            oxml.close()\n        with warnings.catch_warnings():\n            warnings.simplefilter(\"ignore\", UnicodeWarning)\n            if oxmlstr == object.outxmlstr: changed = False\n\n    if changed: object.write_to_file(dirn, filen)\n    if not fobject: dtreeitem.written = True  # Mark as True, even if not changed - the file should still be there!\n    return changed",
  "def setFileForOutput(dtree, filen, fileObject, fileType):  # Put details in dtree, creating item if needed\n    if filen not in dtree:\n        dtree[filen] = UT.dirTreeItem()\n        dtree[filen].added = True\n    dtree[filen].setinfo(fileObject=fileObject, fileType=fileType, towrite=True)",
  "def writeToDisk(dtree, outdir, font, odtree=None, logindent=\"\", changes = False):\n    if odtree is None: odtree = {}\n    # Make lists of items in dtree and odtree with type prepended for sorting and comparison purposes\n    dtreelist = []\n    for filen in dtree: dtreelist.append(dtree[filen].type + filen)\n    dtreelist.sort()\n    odtreelist = []\n    if odtree == {}:\n        locationtype = \"Empty\"\n    else:\n        if outdir == font.ufodir:\n            locationtype = \"Same\"\n        else:\n            locationtype = \"Different\"\n        for filen in odtree: odtreelist.append(odtree[filen].type + filen)\n        odtreelist.sort()\n\n    okey = odtreelist.pop(0) if odtreelist != [] else None\n\n    for key in dtreelist:\n        type = key[0:1]\n        filen = key[1:]\n        dtreeitem = dtree[filen]\n\n        while okey and okey < key:  # Item in output UFO no longer needed\n            ofilen = okey[1:]\n            if okey[0:1] == \"f\":\n                logmess = 'Deleting ' + ofilen + ' from existing output UFO'\n                os.remove(os.path.join(outdir, ofilen))\n            else:\n                logmess = 'Deleting directory ' + ofilen + ' from existing output UFO'\n                shutil.rmtree(os.path.join(outdir, ofilen))\n            if ofilen not in dtree.removedfiles: font.logger.log(logmess, \"W\")  # No need to log for remaned files\n            okey = odtreelist.pop(0) if odtreelist != [] else None\n\n        if key == okey:\n            exists = locationtype\n            okey = odtreelist.pop(0) if odtreelist != [] else None  # Ready for next loop\n        else:\n            exists = False\n\n        if dtreeitem.type == \"f\":\n            if dtreeitem.towrite:\n                font.logger.log(logindent + filen, \"V\")\n                if dtreeitem.fileType == \"xml\":\n                    if dtreeitem.fileObject:  # Only write if object has items\n                        if dtreeitem.fileObject.type == \"glif\":\n                            glif = dtreeitem.fileObject\n                            if glif[\"lib\"] is not None: # Delete lib if no items in it\n                                if glif[\"lib\"].__len__() == 0:\n                                    glif.remove(\"lib\")\n                            # Sort UFO3 anchors by name (UFO2 anchors will have been sorted on conversion)\n                            glif[\"anchor\"].sort(key=lambda anchor: anchor.element.get(\"name\"))\n                            glif.rebuildET()\n                        result = writeXMLobject(dtreeitem, font.outparams, outdir, filen, exists)\n                        if result: changes = True\n                    else:  # Delete existing item if the current object is empty\n                        if exists:\n                            font.logger.log('Deleting empty item ' + filen + ' from existing output UFO', \"I\")\n                            os.remove(os.path.join(outdir, filen))\n                            changes = True\n                elif dtreeitem.fileType == \"text\":\n                    dtreeitem.fileObject.write(dtreeitem, outdir, filen, exists)\n                    ## Need to add code for other file types\n            else:\n                if filen in dtree.removedfiles:\n                    if exists:\n                        os.remove(os.path.join(outdir, filen))  # Silently remove old file for renamed files\n                        changes = True\n                        exists = False\n                else:  # File should not have been in original UFO\n                    if exists == \"same\":\n                        font.logger.log('Deleting ' + filen + ' from existing UFO', \"W\")\n                        os.remove(os.path.join(outdir, filen))\n                        changes = True\n                        exists = False\n                    else:\n                        if not dtreeitem.added:\n                            font.logger.log('Skipping invalid file ' + filen + ' from input UFO', \"W\")\n                if exists:\n                    font.logger.log('Deleting ' + filen + ' from existing output UFO', \"W\")\n                    os.remove(os.path.join(outdir, filen))\n                    changes = True\n\n        else:  # Must be directory\n            if not dtreeitem.read:\n                font.logger.log(logindent + \"Skipping invalid input directory \" + filen, \"W\")\n                if exists:\n                    font.logger.log('Deleting directory ' + filen + ' from existing output UFO', \"W\")\n                    shutil.rmtree(os.path.join(outdir, filen))\n                    changes = True\n                continue\n            font.logger.log(logindent + \"Processing \" + filen + \" directory\", \"I\")\n            subdir = os.path.join(outdir, filen)\n            if isinstance(dtreeitem.fileObject, Udirectory):\n                dtreeitem.fileObject.write(dtreeitem, outdir)\n            else:\n                if not os.path.exists(subdir):  # If outdir does not exist, create it\n                    try:\n                        os.mkdir(subdir)\n                    except Exception as e:\n                        print(e)\n                        sys.exit(1)\n                    changes = True\n\n                if exists:\n                    subodtree = odtree[filen].dirtree\n                else:\n                    subodtree = {}\n                subindent = logindent + \"  \"\n                changes = writeToDisk(dtreeitem.dirtree, subdir, font, subodtree, subindent, changes)\n                if os.listdir(subdir) == []:\n                    os.rmdir(subdir)  # Delete directory if empty\n                    changes = True\n\n    while okey:  # Any remaining items in odree list are no longer needed\n        ofilen = okey[1:]\n        if okey[0:1] == \"f\":\n            logmess = 'Deleting ' + ofilen + ' from existing output UFO'\n            os.remove(os.path.join(outdir, ofilen))\n            changes = True\n        else:\n            logmess = 'Deleting directory ' + ofilen + ' from existing output UFO', \"W\"\n            shutil.rmtree(os.path.join(outdir, ofilen))\n            changes = True\n        if ofilen not in dtree.removedfiles: font.logger.log(logmess, \"W\")  # No need to log warning for removed files\n        okey = odtreelist.pop(0) if odtreelist != [] else None\n    return changes",
  "def normETdata(element, params, type):\n    # Recursively normalise the data an an ElementTree element\n    for subelem in element:\n        normETdata(subelem, params, type)\n\n    precision = params[\"precision\"]\n    if precision is not None:\n        if element.tag in (\"integer\", \"real\"):\n            num = round(float(element.text), precision)\n            if num == int(num):\n                element.tag = \"integer\"\n                element.text = \"{}\".format(int(num))\n            else:\n                element.tag = \"real\"\n                element.text = \"{}\".format(num)\n\n    if params[\"sortDicts\"] and element.tag == \"dict\":\n        edict = {}\n        elist = []\n        for i in range(0, len(element), 2):\n            edict[element[i].text] = [element[i], element[i + 1]]\n            elist.append(element[i].text)\n        keylist = sorted(edict.keys())\n        if elist != keylist:\n            i = 0\n            for key in keylist:\n                element[i] = edict[key][0]\n                element[i + 1] = edict[key][1]\n                i = i + 2",
  "def getattrib(element, attrib): return element.attrib[attrib] if attrib in element.attrib else None",
  "def makeFileName(name, namelist=None):\n    if namelist is None: namelist = []\n    # Replace illegal characters and add _ after UC letters\n    newname = \"\"\n    for x in name:\n        if x in _illegalChars:\n            x = \"_\"\n        else:\n            if x != x.lower(): x += \"_\"\n        newname += x\n    # Replace initial . if present\n    if newname[0] == \".\": newname = \"_\" + newname[1:]\n    parts = []\n    for part in newname.split(\".\"):\n        if part in _reservedNames:\n            part = \"_\" + part\n        parts.append(part)\n    name = \".\".join(parts)\n    if name.lower() in namelist:  # case-insensitive name already used, so add a suffix\n        newname = None\n        i = 1\n        while newname is None:\n            test = name + '{0:015d}'.format(i)\n            if not (test.lower() in namelist): newname = test\n            i += 1\n        name = newname\n    return name",
  "def __init__(self):\n        self._contents = {}",
  "def __len__(self):\n        return len(self._contents)",
  "def __getitem__(self, key):\n        return self._contents[key]",
  "def __iter__(self):\n        return iter(self._contents)",
  "def get(self, key, default=None):\n        return self._contents.get(key, default=default)",
  "def keys(self):\n        return self._contents.keys()",
  "def addval(self, key, valuetype, value):  # For simple single-value elements - use addelem for dicts or arrays\n        if valuetype not in (\"integer\", \"real\", \"string\"):\n            self.font.logger.log(\"addval() can only be used with simple elements\", \"X\")\n        if key in self._contents: self.font.logger.log(\"Attempt to add duplicate key \" + key + \" to plist\", \"X\")\n        dict = self.etree[0]\n\n        keyelem = ET.Element(\"key\")\n        keyelem.text = key\n        dict.append(keyelem)\n\n        valelem = ET.Element(valuetype)\n        valelem.text = str(value)\n        dict.append(valelem)\n\n        self._contents[key] = [keyelem, valelem]",
  "def setval(self, key, valuetype, value):  # For simple single-value elements - use setelem for dicts or arrays\n        if valuetype not in (\"integer\", \"real\", \"string\"):\n            self.font.logger.log(\"setval() can only be used with simple elements\", \"X\")\n        if key in self._contents:\n            self._contents[key][1].text = str(value)\n        else:\n            self.addval(key, valuetype, value)",
  "def getval(self, key, default=None):  # Returns a value for integer, real, string, true, false, dict or array keys or None for other keys\n        elem = self._contents.get(key, [None, None])[1]\n        if elem is None:\n            return default\n        return self._valelem(elem)",
  "def _valelem(self, elem):  # Used by getval to recursively process dict and array elements\n        if elem.tag == \"integer\": return int(elem.text)\n        elif elem.tag == \"real\": return float(elem.text)\n        elif elem.tag == \"string\": return elem.text\n        elif elem.tag == \"true\": return True\n        elif elem.tag == \"false\": return False\n        elif elem.tag == \"array\":\n            array = []\n            for subelem in elem: array.append(self._valelem(subelem))\n            return array\n        elif elem.tag == \"dict\":\n            dict = {}\n            for i in range(0, len(elem), 2): dict[elem[i].text] = self._valelem(elem[i + 1])\n            return dict\n        else:\n            return None",
  "def remove(self, key):\n        item = self._contents[key]\n        self.etree[0].remove(item[0])\n        self.etree[0].remove(item[1])\n        del self._contents[key]",
  "def addelem(self, key, element):  # For non-simple elements (eg arrays) the calling script needs to build the etree element\n        if key in self._contents: self.font.logger.log(\"Attempt to add duplicate key \" + key + \" to plist\", \"X\")\n        dict = self.etree[0]\n\n        keyelem = ET.Element(\"key\")\n        keyelem.text = key\n        dict.append(keyelem)\n        dict.append(element)\n\n        self._contents[key] = [keyelem, element]",
  "def setelem(self, key, element):\n        if key in self._contents: self.remove(key)\n        self.addelem(key, element)",
  "def __init__(self, element):\n        self.element = element\n        self.reindex()",
  "def reindex(self):\n        self._contents = collections.defaultdict(list)\n        for e in self.element:\n            self._contents[e.tag].append(e)",
  "def remove(self, subelement):\n        self._contents[subelement.tag].remove(subelement)\n        self.element.remove(subelement)",
  "def append(self, subelement):\n        self._contents[subelement.tag].append(subelement)\n        self.element.append(subelement)",
  "def insert(self, index, subelement):\n        self._contents[subelement.tag].insert(index, subelement)\n        self.element.insert(index, subelement)",
  "def replace(self, index, subelement):\n        oldsubelement = self.element[index]\n        cindex = self._contents[subelement.tag].index(oldsubelement)\n        self._contents[subelement.tag][cindex] = subelement\n        self.element[index] = subelement",
  "def __init__(self, font, dirn, filen):\n        self.type = \"textfile\"\n        self.font = font\n        self.filen = filen\n        self.dirn = dirn\n        if dirn == font.ufodir:\n            dtree = font.dtree\n        else:\n            dtree = font.dtree.subtree(dirn)\n            if not dtree: font.logger.log(\"Missing directory \" + dirn, \"X\")\n        if filen not in dtree:\n            dtree[filen] = UT.dirTreeItem(added=True)\n        dtree[filen].setinfo(read=True)\n        dtree[filen].fileObject = self\n        dtree[filen].fileType = \"text\"",
  "def write(self, dtreeitem, dir, ofilen, exists):\n        # For now just copies source to destination if changed\n        inpath = os.path.join(self.dirn, self.filen)\n        changed = True\n        if exists: changed = not (filecmp.cmp(inpath, os.path.join(dir, self.filen)))\n        if changed:\n            try:\n                shutil.copy2(inpath, dir)\n            except Exception as e:\n                print(e)\n                sys.exit(1)\n        dtreeitem.written = True",
  "def __init__(self, font, parentdir, dirn):\n        self.type = \"directory\"\n        self.font = font\n        self.parentdir = parentdir\n        self.dirn = dirn\n        if parentdir != font.ufodir:\n            self.font.logger.log(\"Currently Udir only supports top-level directories\", \"X\")\n        dtree = font.dtree\n        if dirn not in dtree:\n            self.font.logger.log(\"Udir directory \" + dirn + \" does not exist\", \"X\")\n        dtree[dirn].setinfo(read=True)\n        dtree[dirn].fileObject = self\n        dtree[dirn].fileType = \"directory\"",
  "def write(self, dtreeitem, oparentdir):\n        # For now just copies source to destination\n        if self.parentdir == oparentdir: return # No action needed\n        inpath = os.path.join(self.parentdir, self.dirn)\n        outpath = os.path.join(oparentdir, self.dirn)\n        try:\n            if os.path.isdir(outpath):\n                shutil.rmtree(outpath)\n            shutil.copytree(inpath, outpath)\n        except Exception as e:\n            print(e)\n            sys.exit(1)\n        dtreeitem.written = True",
  "def __init__(self, ufodir, logger=None, params=None):\n        if logger is not None and params is not None:\n            params.logger.log(\"Only supply a logger if params not set (since that has one)\", \"X\")\n        if params is None:\n            params = silfont.core.parameters()\n            if logger is not None: params.logger = logger\n        self.params = params\n        self.logger = params.logger\n        logger = self.logger\n        self.ufodir = ufodir\n        logger.log('Reading UFO: ' + ufodir, 'P')\n        if not os.path.isdir(ufodir):\n            logger.log(ufodir + \" is not a directory\", \"S\")\n        # Read list of files and folders\n        self.dtree = UT.dirTree(ufodir)\n        # Read metainfo (which must exist)\n        self.metainfo = self._readPlist(\"metainfo.plist\")\n        self.UFOversion = self.metainfo[\"formatVersion\"][1].text\n        # Read lib.plist then process pysilfont parameters if present\n        libparams = {}\n        if \"lib.plist\" in self.dtree:\n            self.lib = self._readPlist(\"lib.plist\")\n            if \"org.sil.pysilfontparams\" in self.lib:\n                elem = self.lib[\"org.sil.pysilfontparams\"][1]\n                if elem.tag != \"array\":\n                    logger.log(\"Invalid parameter XML lib.plist - org.sil.pysilfontparams must be an array\", \"S\")\n                for param in elem:\n                    parn = param.tag\n                    if not (parn in params.paramclass) or params.paramclass[parn] not in (\"outparams\", \"ufometadata\"):\n                        logger.log(\"lib.plist org.sil.pysilfontparams must only contain outparams or ufometadata values: \" + parn + \" invalid\", \"S\")\n                    libparams[parn] = param.text\n        # Create font-specific parameter set (with updates from lib.plist)  Prepend names with ufodir to ensure uniqueness if multiple fonts open\n        params.addset(ufodir + \"lib\", \"lib.plist in \" + ufodir, inputdict=libparams)\n        if \"command line\" in params.sets:\n            params.sets[ufodir + \"lib\"].updatewith(\"command line\", log=False)  # Command line parameters override lib.plist ones\n        copyset = \"main\" if \"main\" in params.sets else \"default\"\n        params.addset(ufodir, copyset=copyset)\n        params.sets[ufodir].updatewith(ufodir + \"lib\", sourcedesc=\"lib.plist\")\n        self.paramset = params.sets[ufodir]\n        # Validate specific parameters\n        if self.paramset[\"UFOversion\"] not in (\"\", \"2\", \"3\"): logger.log(\"UFO version must be 2 or 3\", \"S\")\n        if sorted(self.paramset[\"glifElemOrder\"]) != sorted(self.params.sets[\"default\"][\"glifElemOrder\"]):\n            logger.log(\"Invalid values for glifElemOrder\", \"S\")\n\n        # Create outparams based on values in paramset, building attriborders from separate attriborders.<type> parameters.\n        self.outparams = {\"attribOrders\": {}}\n        for parn in params.classes[\"outparams\"]:\n            value = self.paramset[parn]\n            if parn[0:12] == 'attribOrders':\n                elemname = parn.split(\".\")[1]\n                self.outparams[\"attribOrders\"][elemname] = ETU.makeAttribOrder(value)\n            else:\n                self.outparams[parn] = value\n        if self.outparams[\"UFOversion\"] == \"\": self.outparams[\"UFOversion\"] = self.UFOversion\n\n        # Set flags for checking and fixing metadata\n        cf = self.paramset[\"checkfix\"].lower()\n        if cf not in (\"check\", \"fix\", \"none\", \"\"): logger.log(\"Invalid value '\" + cf + \"' for checkfix parameter\", \"S\")\n\n        self.metacheck = True if cf in (\"check\", \"fix\") else False\n        self.metafix = True if cf == \"fix\" else False\n        if \"fontinfo.plist\" not in self.dtree:\n            logger.log(\"fontinfo.plist missing so checkfix routines can't be run\", \"E\")\n            self.metacheck = False\n            self.metafix = False\n\n        # Read other top-level plists\n        if \"fontinfo.plist\" in self.dtree: self.fontinfo = self._readPlist(\"fontinfo.plist\")\n        if \"groups.plist\" in self.dtree: self.groups = self._readPlist(\"groups.plist\")\n        if \"kerning.plist\" in self.dtree: self.kerning = self._readPlist(\"kerning.plist\")\n        createlayercontents = False\n        if self.UFOversion == \"2\":  # Create a dummy layer contents so 2 & 3 can be handled the same\n            createlayercontents = True\n        else:\n            if \"layercontents.plist\" in self.dtree:\n                self.layercontents = self._readPlist(\"layercontents.plist\")\n            else:\n                logger.log(\"layercontents.plist missing - one will be created\", \"W\")\n                createlayercontents = True\n        if createlayercontents:\n            if \"glyphs\" not in self.dtree: logger.log('No glyphs directory in font', \"S\")\n            self.layercontents = Uplist(font=self)\n            self.dtree['layercontents.plist'] = UT.dirTreeItem(read=True, added=True, fileObject=self.layercontents,\n                                                               fileType=\"xml\")\n            dummylc = \"<plist>\\n<array>\\n<array>\\n<string>public.default</string>\\n<string>glyphs</string>\\n</array>\\n</array>\\n</plist>\"\n            self.layercontents.etree = ET.fromstring(dummylc)\n            self.layercontents.populate_dict()\n\n        # Process features.fea\n        if \"features.fea\" in self.dtree:\n            self.features = UfeatureFile(self, ufodir, \"features.fea\")\n        # Process the glyphs directories)\n        self.layers = []\n        self.deflayer = None\n        for i in sorted(self.layercontents.keys()):\n            layername = self.layercontents[i][0].text\n            layerdir = self.layercontents[i][1].text\n            logger.log(\"Processing Glyph Layer \" + str(i) + \": \" + layername + layerdir, \"I\")\n            layer = Ulayer(layername, layerdir, self)\n            if layer:\n                self.layers.append(layer)\n                if layername == \"public.default\": self.deflayer = layer\n            else:\n                logger.log(\"Glyph directory \" + layerdir + \" missing\", \"S\")\n        if self.deflayer is None: logger.log(\"No public.default layer\", \"S\")\n        # Process other directories\n        if \"images\" in self.dtree:\n            self.images = Udirectory(self,ufodir, \"images\")\n        if \"data\" in self.dtree:\n            self.data = Udirectory(self, ufodir, \"data\")\n\n        # Run best practices check and fix routines\n        if self.metacheck:\n            initwarnings = logger.warningcount\n            initerrors = logger.errorcount\n\n            fireq = (\"ascender\", \"copyright\", \"descender\", \"familyName\", \"openTypeNameManufacturer\",\n                        \"styleName\", \"unitsPerEm\", \"versionMajor\", \"versionMinor\")\n            fiwarnifmiss = (\"capHeight\", \"copyright\", \"openTypeNameDescription\", \"openTypeNameDesigner\",\n                        \"openTypeNameDesignerURL\", \"openTypeNameLicense\", \"openTypeNameLicenseURL\",\n                        \"openTypeNameManufacturerURL\", \"openTypeOS2CodePageRanges\",\n                        \"openTypeOS2UnicodeRanges\", \"openTypeOS2VendorID\",\n                        \"openTypeOS2WeightClass\", \"openTypeOS2WinAscent\", \"openTypeOS2WinDescent\")\n            fiwarnifnot = {\"unitsPerEm\": (1000, 2048),\n                           \"styleMapStyleName\": (\"regular\", \"bold\", \"italic\", \"bold italic\")},\n            fiwarnifpresent = (\"note\",)\n            fidel = (\"macintoshFONDFamilyID\", \"macintoshFONDName\", \"openTypeNameCompatibleFullName\",\n                     \"openTypeGaspRangeRecords\", \"openTypeHheaCaretOffset\",\n                     \"openTypeOS2FamilyClass\", \"postscriptForceBold\", \"postscriptIsFixedPitch\",\n                     \"postscriptBlueFuzz\", \"postscriptBlueScale\", \"postscriptBlueShift\", \"postscriptWeightName\",\n                     \"year\")\n            fidelifempty = (\"guidelines\", \"postscriptBlueValues\", \"postscriptFamilyBlues\", \"postscriptFamilyOtherBlues\",\n                            \"postscriptOtherBlues\")\n            fiint = (\"ascender\", \"capHeight\", \"descender\", \"postscriptUnderlinePosition\",\n                     \"postscriptUnderlineThickness\", \"unitsPerEm\", \"xHeight\")\n            ficapitalize = (\"styleMapFamilyName\", \"styleName\")\n            fisetifmissing = {}\n            fisettoother = {\"openTypeHheaAscender\": \"ascender\", \"openTypeHheaDescender\": \"descender\",\n                            \"openTypeNamePreferredFamilyName\": \"familyName\",\n                            \"openTypeNamePreferredSubfamilyName\": \"styleName\", \"openTypeOS2TypoAscender\": \"ascender\",\n                            \"openTypeOS2TypoDescender\": \"descender\"}\n            fisetto = {\"openTypeHheaLineGap\": 0, \"openTypeOS2TypoLineGap\": 0, \"openTypeOS2WidthClass\": 5,\n                       \"openTypeOS2Selection\": [7], \"openTypeOS2Type\": []} # Other values are added below\n\n            libdel = (\"com.fontlab.v2.tth\", \"com.typemytype.robofont.italicSlantOffset\")\n            libsetto = {\"com.schriftgestaltung.customParameter.GSFont.disablesAutomaticAlignment\": True,\n                            \"com.schriftgestaltung.customParameter.GSFont.disablesLastChange\": True}\n            libwarnifnot = {\"com.schriftgestaltung.customParameter.GSFont.useNiceNames\": False}\n            libwarnifmissing = (\"public.glyphOrder\",)\n\n            # fontinfo.plist checks\n            logger.log(\"Checking fontinfo.plist metadata\", \"P\")\n\n            # Check required fields, some of which are needed for remaining checks\n            missing = []\n            for key in fireq:\n                if key not in self.fontinfo or self.fontinfo.getval(key) is None: missing.append(key)\n            # Collect values for constructing other fields, setting dummy values when missing and in check-only mode\n            dummies = False\n            storedvals = {}\n            for key in (\"ascender\", \"copyright\", \"descender\", \"familyName\", \"styleName\", \"openTypeNameManufacturer\", \"versionMajor\", \"versionMinor\"):\n                if key in self.fontinfo and self.fontinfo.getval(key) is not None:\n                    storedvals[key] = self.fontinfo.getval(key)\n                    if key == \"styleName\":\n                        sn = storedvals[key]\n                        sn = re.sub(r\"(\\w)(Italic)\", r\"\\1 \\2\", sn)  # Add a space before Italic if missing\n                        # Capitalise first letter of words\n                        sep = b' ' if type(sn) is bytes else ' '\n                        sn = sep.join(s[:1].upper() + s[1:] for s in sn.split(sep))\n                        if sn != storedvals[key]:\n                            if self.metafix:\n                                self.fontinfo.setval(key, \"string\", sn)\n                                logmess = \" updated \"\n                            else:\n                                logmess = \" would be updated \"\n                            self.logchange(logmess, key, storedvals[key], sn)\n                            storedvals[key] = sn\n                    if key in (\"ascender\", \"descender\"):\n                        storedvals[key] = int(storedvals[key])\n                else:\n                    dummies = True\n                    if key in (\"ascender\", \"descender\", \"versionMajor\", \"versionMinor\"):\n                        storedvals[key] = 999\n                    else:\n                        storedvals[key] = \"Dummy\"\n            if missing:\n                logtype = \"S\" if self.metafix else \"W\"\n                logger.log(\"Required fields missing from fontinfo.plist: \" + str(missing), logtype)\n            if dummies:\n                logger.log(\"Checking will continue with values of 'Dummy' or 999 for missing fields\", \"W\")\n            # Construct values for certain fields\n            value = storedvals[\"openTypeNameManufacturer\"] + \": \" + storedvals[\"familyName\"] + \" \"\n            value = value + storedvals[\"styleName\"] + \": \" + datetime.datetime.now().strftime(\"%Y\")\n            fisetto[\"openTypeNameUniqueID\"] = value\n#            fisetto[\"openTypeOS2WinDescent\"] = -storedvals[\"descender\"]\n            if \"openTypeNameVersion\" not in self.fontinfo:\n                fisetto[\"openTypeNameVersion\"] = \"Version \" + str(storedvals[\"versionMajor\"]) + \".\"\\\n                                                 + str(storedvals[\"versionMinor\"])\n            if \"openTypeOS2WeightClass\" not in self.fontinfo:\n                sn = storedvals[\"styleName\"]\n                sn2wc = {\"Regular\": 400, \"Italic\": 400, \"Bold\": 700, \"BoldItalic\": 700}\n                if sn in sn2wc: fisetto[\"openTypeOS2WeightClass\"] = sn2wc[sn]\n            if \"xHeight\" not in self.fontinfo:\n                fisetto[\"xHeight\"] = int(storedvals[\"ascender\"] * 0.6)\n            if \"openTypeOS2Selection\" in self.fontinfo: # If already present, need to ensure bit 7 is set\n                fisetto[\"openTypeOS2Selection\"] = sorted(list(set(self.fontinfo.getval(\"openTypeOS2Selection\") + [7])))\n\n            for key in fisetifmissing:\n                if key not in self.fontinfo:\n                    fisetto[key] = fisetifmissing[key]\n\n            changes = 0\n            # Warn about missing fields\n            for key in fiwarnifmiss:\n                if key not in self.fontinfo:\n                    logmess = key + \" is missing from fontinfo.plist\"\n                    logger.log(logmess, \"W\")\n            # Warn about bad values\n            for key in fiwarnifnot:\n                if key in self.fontinfo:\n                    value = self.fontinfo.getval(key)\n                    if value not in fiwarnifnot[key]:\n                        logger.log(key + \" should be one of \" + str(fiwarnifnot[key]), \"W\")\n            # Warn about keys where use of discouraged\n            for key in fiwarnifpresent:\n                if key in self.fontinfo:\n                    logger.log(key + \" is present - it's use is discouraged\")\n\n            # Now do all remaining checks - which will lead to values being changed\n            for key in fidel + fidelifempty:\n                if key in self.fontinfo:\n                    old = self.fontinfo.getval(key)\n                    if not(key in fidelifempty and old != []): # Delete except for non-empty fidelifempty\n                        if self.metafix:\n                            self.fontinfo.remove(key)\n                            logmess = \" removed from fontinfo. \"\n                        else:\n                            logmess = \" would be removed from fontinfo \"\n                        self.logchange(logmess, key, old, None)\n                        changes += 1\n\n            # Set to integer values\n            for key in fiint:\n                if key in self.fontinfo:\n                    old = self.fontinfo.getval(key)\n                    if old != int(old):\n                        new = int(old)\n                        if self.metafix:\n                            self.fontinfo.setval(key, \"integer\", new)\n                            logmess = \" updated \"\n                        else:\n                            logmess = \" would be updated \"\n                        self.logchange(logmess, key, old, new)\n                        changes += 1\n            # Capitalize words\n            for key in ficapitalize:\n                if key in self.fontinfo:\n                    old = self.fontinfo.getval(key)\n                    sep = b' ' if type(old) is bytes else ' '\n                    new = sep.join(s[:1].upper() + s[1:] for s in old.split(sep))  # Capitalise words\n                    if new != old:\n                        if self.metafix:\n                            self.fontinfo.setval(key, \"string\", new)\n                            logmess = \" uppdated \"\n                        else:\n                            logmess = \" would be uppdated \"\n                        self.logchange(logmess, key, old, new)\n                        changes += 1\n            # Set to specific values\n            for key in list(fisetto.keys()) + list(fisettoother.keys()):\n                if key in self.fontinfo:\n                    old = self.fontinfo.getval(key)\n                    logmess = \" updated \"\n                else:\n                    old = None\n                    logmess = \" added \"\n                if key in fisetto:\n                    new = fisetto[key]\n                else:\n                    new = storedvals[fisettoother[key]]\n                if new != old:\n                    if self.metafix:\n                        if isinstance(new, list): # Currently only integer arrays\n                            array = ET.Element(\"array\")\n                            for val in new: # Only covers integer at present for openTypeOS2Selection\n                                ET.SubElement(array, \"integer\").text = val\n                                self.fontinfo.setelem(key, array)\n                        else: # Does not cover real at present\n                            valtype = \"integer\" if isinstance(new, int) else \"string\"\n                            self.fontinfo.setval(key, valtype, new)\n                    else:\n                        logmess = \" would be\" + logmess\n                    self.logchange(logmess, key, old, new)\n                    changes += 1\n            # Specific checks\n            if \"italicAngle\" in self.fontinfo:\n                old = self.fontinfo.getval(\"italicAngle\")\n                if old == 0: # Should be deleted if 0\n                    logmess = \" removed since it is 0 \"\n                    if self.metafix:\n                        self.fontinfo.remove(\"italicAngle\")\n                    else:\n                        logmess = \" would be\" + logmess\n                    self.logchange(logmess, \"italicAngle\", old, None)\n                    changes += 1\n            if \"versionMajor\" in self.fontinfo: # If missing, an error will already have been reported...\n                vm = self.fontinfo.getval(\"versionMajor\")\n                if vm == 0: logger.log(\"versionMajor is 0\", \"W\")\n\n            # lib.plist checks\n            if \"lib\" not in self.__dict__:\n                logger.log(\"lib.plist missing so not checked by check & fix routines\", \"E\")\n            else:\n                logger.log(\"Checking lib.plist metadata\", \"P\")\n\n                for key in libdel:\n                    if key in self.lib:\n                        old = self.lib.getval(key)\n                        if self.metafix:\n                            self.lib.remove(key)\n                            logmess = \" removed from lib.plist. \"\n                        else:\n                            logmess = \" would be removed from lib.plist \"\n                        self.logchange(logmess, key, old, None)\n                        changes += 1\n\n                for key in libsetto:\n                    if key in self.lib:\n                        old = self.lib.getval(key)\n                        logmess = \" updated \"\n                    else:\n                        old = None\n                        logmess = \" added \"\n                    new = libsetto[key]\n                    if new != old:\n                        if self.metafix:\n                            # Currently just supports True.  See fisetto for adding other types\n                            if new == True:\n                                self.lib.setelem(key, ET.fromstring(\"<true/>\"))\n                            else:  # Does not cover real at present\n                                logger.log(\"Invalid value type for libsetto\", \"X\")\n                        else:\n                            logmess = \" would be\" + logmess\n                        self.logchange(logmess, key, old, new)\n                        changes += 1\n                for key in libwarnifnot:\n                    value = self.lib.getval(key) if key in self.lib else None\n                    if value != libwarnifnot[key]:\n                        addmess = \"; currently missing\" if value is None else \"; currently set to \" + str(value)\n                        logger.log(key + \" should normally be \" + str(libwarnifnot[key]) + addmess, \"W\")\n\n                for key in libwarnifmissing:\n                    if key not in self.lib:\n                        logger.log(key + \" is missing from lib.plist\", \"W\")\n\n                logmess = \" deleted - obsolete key\" if self.metafix else \" would be deleted - obsolete key\"\n                for key in obsoleteLibKeys: # For obsolete keys that have been added historically by some tools\n                    if key in self.lib:\n                        old = self.lib.getval(key)\n                        if self.metafix: self.lib.remove(key)\n                        self.logchange(logmess,key,old,None)\n                        changes += 1\n\n            # Show check&fix summary\n            warnings = logger.warningcount - initwarnings - changes\n            errors = logger.errorcount - initerrors\n            if errors or warnings or changes:\n                changemess = \", Changes made: \" if self.metafix else \", Changes to make: \"\n                logger.log(\"Check & fix results:- Errors: \" + str(errors) + changemess + str(changes) +\n                           \", Other warnings: \" + str(warnings), \"P\")\n                if logger.scrlevel not in \"WIV\": logger.log(\"See log file for details\", \"P\")\n                if missing and not self.metafix:\n                    logger.log(\"**** Since some required fields were missing, checkfix=fix would fail\", \"P\")\n            else:\n                logger.log(\"Check & Fix ran cleanly\", \"P\")",
  "def _readPlist(self, filen):\n        if filen in self.dtree:\n            plist = Uplist(font=self, filen=filen)\n            self.dtree[filen].setinfo(read=True, fileObject=plist, fileType=\"xml\")\n            return plist\n        else:\n            self.logger.log(filen + \" does not exist\", \"S\")",
  "def write(self, outdir):\n        # Write UFO out to disk, based on values set in self.outparams\n        self.logger.log(\"Processing font for output\", \"P\")\n        if not os.path.exists(outdir):\n            try:\n                os.mkdir(outdir)\n            except Exception as e:\n                print(e)\n                sys.exit(1)\n        if not os.path.isdir(outdir):\n            self.logger.log(outdir + \" not a directory\", \"S\")\n\n        # If output UFO already exists, need to open so only changed files are updated and redundant files deleted\n        if outdir == self.ufodir:  # In special case of output and input being the same, simply copy the input font\n            odtree = UT.dirTree(outdir)\n        else:\n            if not os.path.exists(outdir):  # If outdir does not exist, create it\n                try:\n                    os.mkdir(outdir)\n                except Exception as e:\n                    print(e)\n                    sys.exit(1)\n                odtree = {}\n            else:\n                if not os.path.isdir(outdir): self.logger.log(outdir + \" not a directory\", \"S\")\n                dirlist = os.listdir(outdir)\n                if dirlist == []:  # Outdir is empty\n                    odtree = {}\n                else:\n                    self.logger.log(\"Output UFO already exists - reading for comparison\", \"P\")\n                    odtree = UT.dirTree(outdir)\n        # Update version info etc\n        UFOversion = self.outparams[\"UFOversion\"]\n        self.metainfo[\"formatVersion\"][1].text = str(UFOversion)\n        self.metainfo[\"creator\"][1].text = \"org.sil.scripts.pysilfont\"\n\n        # Set standard UFO files for output\n        dtree = self.dtree\n        setFileForOutput(dtree, \"metainfo.plist\", self.metainfo, \"xml\")\n        if \"fontinfo\" in self.__dict__: setFileForOutput(dtree, \"fontinfo.plist\", self.fontinfo, \"xml\")\n        if \"groups\" in self.__dict__: # With groups, sort by glyph name\n            for gname in list(self.groups):\n                group = self.groups.getval(gname)\n                elem = ET.Element(\"array\")\n                for glyph in sorted(group):\n                    ET.SubElement(elem, \"string\").text = glyph\n                self.groups.setelem(gname, elem)\n            setFileForOutput(dtree, \"groups.plist\", self.groups, \"xml\")\n        if \"kerning\" in self.__dict__: setFileForOutput(dtree, \"kerning.plist\", self.kerning, \"xml\")\n        if \"lib\" in self.__dict__: setFileForOutput(dtree, \"lib.plist\", self.lib, \"xml\")\n        if UFOversion == \"3\":\n            # Sort layer contents by layer name\n            lc = self.layercontents\n            lcindex = {lc[x][0].text: lc[x] for x in lc}  # index on layer name\n            for (x, name) in enumerate(sorted(lcindex)):\n                lc.etree[0][x] = lcindex[name]  # Replace array elements in new order\n            setFileForOutput(dtree, \"layercontents.plist\", self.layercontents, \"xml\")\n        if \"features\" in self.__dict__: setFileForOutput(dtree, \"features.fea\", self.features, \"text\")\n        # Set glyph layers for output\n        for layer in self.layers: layer.setForOutput()\n\n        # Write files to disk\n\n        self.logger.log(\"Writing font to \" + outdir, \"P\")\n\n        changes = writeToDisk(dtree, outdir, self, odtree)\n        if changes: # Need to update openTypeHeadCreated if there have been any changes to the font\n            if \"fontinfo\" in self.__dict__:\n                self.fontinfo.setval(\"openTypeHeadCreated\", \"string\",\n                                     datetime.datetime.now().strftime(\"%Y/%m/%d %H:%M:%S\"))\n                self.fontinfo.outxmlstr=\"\" # Need to reset since writeXMLobject has already run once\n                writeXMLobject(self.fontinfo, self.outparams, outdir, \"fontinfo.plist\", True, fobject=True)",
  "def addfile(self, filetype):  # Add empty plist file for optional files\n        if filetype not in (\"fontinfo\", \"groups\", \"kerning\", \"lib\"): self.logger.log(\"Invalid file type to add\", \"X\")\n        if filetype in self.__dict__: self.logger.log(\"File already in font\", \"X\")\n        obj = Uplist(font=self)\n        setattr(self, filetype, obj)\n        self.dtree[filetype + '.plist'] = UT.dirTreeItem(read=True, added=True, fileObject=obj, fileType=\"xml\")\n        obj.etree = ET.fromstring(\"<plist>\\n<dict/>\\n</plist>\")",
  "def logchange(self, logmess, key, old, new):\n        oldstr = str(old) if len(str(old)) < 22 else str(old)[0:20] + \"...\"\n        newstr = str(new) if len(str(new)) < 22 else str(new)[0:20] + \"...\"\n        logmess = key + logmess\n        if old is None:\n            logmess = logmess + \" New value: \" + newstr\n        else:\n            if new is None:\n                logmess = logmess + \" Old value: \" + oldstr\n            else:\n                logmess = logmess + \" Old value: \" + oldstr + \", new value: \" + newstr\n        self.logger.log(logmess, \"W\")\n        # Extra verbose logging\n        if len(str(old)) > 21:\n            self.logger.log(\"Full old value: \" + str(old), \"I\")\n        if len(str(new)) > 21:\n            self.logger.log(\"Full new value: \" + str(new), \"I\")\n        otype = \"string\" if isinstance(old, (bytes, str)) else type(old).__name__ # To produce consistent reporting\n        ntype = \"string\" if isinstance(new, (bytes, str)) else type(new).__name__ # with Python 2 & 3\n        self.logger.log(\"Types: Old - \" + otype + \", New - \" + ntype, \"I\")",
  "def __init__(self, layername, layerdir, font):\n        self._contents = collections.OrderedDict()\n        self.dtree = font.dtree.subTree(layerdir)\n        font.dtree[layerdir].read = True\n        self.layername = layername\n        self.layerdir = layerdir\n        self.font = font\n        fulldir = os.path.join(font.ufodir, layerdir)\n        self.contents = Uplist(font=font, dirn=fulldir, filen=\"contents.plist\")\n        self.dtree[\"contents.plist\"].setinfo(read=True, fileObject=self.contents, fileType=\"xml\")\n\n        if font.UFOversion == \"3\":\n            if 'layerinfo.plist' in self.dtree:\n                self.layerinfo = Uplist(font=font, dirn=fulldir, filen=\"layerinfo.plist\")\n                self.dtree[\"layerinfo.plist\"].setinfo(read=True, fileObject=self.layerinfo, fileType=\"xml\")\n\n        for glyphn in sorted(self.contents.keys()):\n            glifn = self.contents[glyphn][1].text\n            if glifn in self.dtree:\n                glyph = Uglif(layer=self, filen=glifn)\n                self._contents[glyphn] = glyph\n                self.dtree[glifn].setinfo(read=True, fileObject=glyph, fileType=\"xml\")\n                if glyph.name != glyphn:\n                    super(Uglif, glyph).__setattr__(\"name\", glyphn)  # Need to use super to bypass normal glyph renaming logic\n                    self.font.logger.log(\"Glyph names in glif and contents.plist did not match for \" + glyphn + \"; corrected\", \"W\")\n            else:\n                self.font.logger.log(\"Missing glif \" + glifn + \" in \" + fulldir, \"S\")",
  "def setForOutput(self):\n\n        UFOversion = self.font.outparams[\"UFOversion\"]\n        convertg2f1 = True if UFOversion == \"2\" or self.font.outparams[\"format1Glifs\"] else False\n        dtree = self.font.dtree.subTree(self.layerdir)\n        if self.font.outparams[\"renameGlifs\"]: self.renameGlifs()\n\n        setFileForOutput(dtree, \"contents.plist\", self.contents, \"xml\")\n        if \"layerinfo\" in self.__dict__ and UFOversion == \"3\":\n            setFileForOutput(dtree, \"layerinfo.plist\", self.layerinfo, \"xml\")\n\n        for glyphn in self:\n            glyph = self._contents[glyphn]\n            if convertg2f1: glyph.convertToFormat1()\n            if glyph[\"advance\"] is not None:\n                if glyph[\"advance\"].width is None and glyph[\"advance\"].height is None: glyph.remove(\"advance\")\n            # Normalize so that, when both exist, components come before contour\n            outline = glyph[\"outline\"]\n            if len(outline.components) > 0 and list(outline)[0] == \"contour\":\n                # Need to move components to the front...\n                contours = outline.contours\n                components = outline.components\n                oldcontours = list(contours)  # Easiest way to 'move' components is to delete contours then append back at the end\n                for contour in oldcontours: outline.removeobject(contour, \"contour\")\n                for contour in oldcontours: outline.appendobject(contour, \"contour\")\n\n            setFileForOutput(dtree, glyph.filen, glyph, \"xml\")",
  "def renameGlifs(self):\n        namelist = []\n        for glyphn in sorted(self.keys()):\n            glyph = self._contents[glyphn]\n            filename = makeFileName(glyphn, namelist)\n            namelist.append(filename.lower())\n            filename += \".glif\"\n            if filename != glyph.filen:\n                self.renameGlif(glyphn, glyph, filename)",
  "def renameGlif(self, glyphn, glyph, newname):\n        self.font.logger.log(\"Renaming glif for \" + glyphn + \" from \" + glyph.filen + \" to \" + newname, \"I\")\n        self.dtree.removedfiles[glyph.filen] = newname  # Track so original glif does not get reported as invalid\n        glyph.filen = newname\n        self.contents[glyphn][1].text = newname",
  "def addGlyph(self, glyph):\n        glyphn = glyph.name\n        if glyphn in self._contents: self.font.logger.log(glyphn + \" already in font\", \"X\")\n        self._contents[glyphn] = glyph\n        # Set glif name\n        glifn = makeFileName(glyphn)\n        names = []\n        while glifn in self.contents:  # need to check for duplicate glif names\n            names.append(glifn)\n            glifn = makeFileName(glyphn, names)\n        glifn += \".glif\"\n        glyph.filen = glifn\n        # Add to contents.plist and dtree\n        self.contents.addval(glyphn, \"string\", glifn)\n        self.dtree[glifn] = UT.dirTreeItem(read=False, added=True, fileObject=glyph, fileType=\"xml\")",
  "def delGlyph(self, glyphn):\n        self.dtree.removedfiles[self[glyphn].filen] = \"deleted\"  # Track so original glif does not get reported as invalid\n        del self._contents[glyphn]\n        self.contents.remove(glyphn)",
  "def __init__(self, font=None, dirn=None, filen=None, parse=True):\n        if dirn is None and font: dirn = font.ufodir\n        logger = font.logger if font else silfont.core.loggerobj()\n        ETU.xmlitem.__init__(self, dirn, filen, parse, logger)\n        self.type = \"plist\"\n        self.font = font\n        self.outparams = None\n        if filen and dirn: self.populate_dict()",
  "def populate_dict(self):\n        self._contents.clear()  # Clear existing contents, if any\n        pl = self.etree[0]\n        if pl.tag == \"dict\":\n            for i in range(0, len(pl), 2):\n                key = pl[i].text\n                self._contents[key] = [pl[i], pl[i + 1]]  # The two elements for the item\n        else:  # Assume array of 2 element arrays (eg layercontents.plist)\n            for i in range(len(pl)):\n                self._contents[i] = pl[i]",
  "def __init__(self, layer, filen=None, parse=True, name=None, format=None):\n        dirn = os.path.join(layer.font.ufodir, layer.layerdir)\n        ETU.xmlitem.__init__(self, dirn, filen, parse, layer.font.logger)  # Will read item from file if dirn and filen both present\n        self.type = \"glif\"\n        self.layer = layer\n        self.format = format if format else '2'\n        self.name = name\n        self.outparams = None\n        self.glifElemOrder = self.layer.font.outparams[\"glifElemOrder\"]\n        # Set initial values for sub-objects\n        for elem in self.glifElemOrder:\n            if elem in _glifElemMulti:\n                self._contents[elem] = []\n            else:\n                self._contents[elem] = None\n        if self.etree is not None: self.process_etree()",
  "def __setattr__(self, name, value):\n        if name == \"name\" and getattr(self, \"name\", None):  # Existing glyph name is being changed\n            oname = self.name\n            if value in self.layer._contents: self.layer.font.logger.log(name + \" already in font\", \"X\")\n            # Update the _contents dictionary\n            del self.layer._contents[oname]\n            self.layer._contents[value] = self\n            # Set glif name\n            glifn = makeFileName(value)\n            names = []\n            while glifn in self.layer.contents:  # need to check for duplicate glif names\n                names.append(glifn)\n                glifn = makeFileName(value, names)\n            glifn += \".glif\"\n\n            # Update to contents.plist, filen and dtree\n            self.layer.contents.remove(oname)\n            self.layer.contents.addval(value, \"string\", glifn)\n            self.layer.dtree.removedfiles[self.filen] = glifn  # Track so original glif does not get reported as invalid\n            self.filen = glifn\n            self.layer.dtree[glifn] = UT.dirTreeItem(read=False, added=True, fileObject=self, fileType=\"xml\")\n        super(Uglif, self).__setattr__(name, value)",
  "def process_etree(self):\n        et = self.etree\n        self.name = getattrib(et, \"name\")\n        self.format = getattrib(et, \"format\")\n        if self.format is None:\n            if self.layer.font.UFOversion == \"3\":\n                self.format = '2'\n            else:\n                self.format = '1'\n        for i in range(len(et)):\n            element = et[i]\n            tag = element.tag\n            if not tag in self.glifElemOrder: self.layer.font.logger.log(\n                \"Invalid element \" + tag + \" in glif \" + self.name, \"E\")\n            if tag in _glifElemF1 or self.format == '2':\n                if tag in _glifElemMulti:\n                    self._contents[tag].append(self.makeObject(tag, element))\n                else:\n                    self._contents[tag] = self.makeObject(tag, element)\n\n        # Convert UFO2 style anchors to UFO3 anchors\n        if self._contents['outline'] is not None and self.format == \"1\":\n            for contour in self._contents['outline'].contours[:]:\n                if contour.UFO2anchor:\n                    del contour.UFO2anchor[\"type\"]  # remove type=\"move\"\n                    self.add('anchor', contour.UFO2anchor)\n                    self._contents['outline'].removeobject(contour, \"contour\")\n        if self._contents['outline'] is None: self.add('outline')\n\n        self.format = \"2\"",
  "def rebuildET(self):\n        self.etree = ET.Element(\"glyph\")\n        et = self.etree\n        et.attrib[\"name\"] = self.name\n        et.attrib[\"format\"] = self.format\n        # Insert sub-elements\n        for elem in self.glifElemOrder:\n            if elem in _glifElemF1 or self.format == \"2\":  # Check element is valid for glif format\n                item = self._contents[elem]\n                if item is not None:\n                    if elem in _glifElemMulti:\n                        for object in item:\n                            et.append(object.element)\n                    else:\n                        et.append(item.element)",
  "def add(self, ename, attrib=None):\n        # Add an element and corresponding object to a glif\n        element = ET.Element(ename)\n        if attrib: element.attrib = attrib\n        if ename == \"lib\": ET.SubElement(element, \"dict\")\n        multi = True if ename in _glifElemMulti else False\n\n        if multi and ename not in self._contents:\n            self._contents[ename] = []\n\n        # Check element does not already exist for single elements\n        if ename in self._contents and not multi:\n            if self._contents[ename] is not None: self.layer.font.logger.log(\"Already an \" + ename + \" in glif\", \"X\")\n\n        # Add new object\n        if multi:\n            self._contents[ename].append(self.makeObject(ename, element))\n        else:\n            self._contents[ename] = self.makeObject(ename, element)",
  "def remove(self, ename, index=None, object=None):\n        # Remove object from a glif\n        # For multi objects, an index or object must be supplied to identify which\n        # to delete\n        if ename in _glifElemMulti:\n            item = self._contents[ename]\n            if index is None: index = item.index(object)\n            del item[index]\n        else:\n            self._contents[ename] = None",
  "def convertToFormat1(self):\n        # Convert to a glif format of 1 (for UFO2) prior to writing out\n        self.format = \"1\"\n        # Change anchors to UFO2 style anchors.  Sort anchors by anchor name first\n        anchororder = sorted(self._contents['anchor'], key=lambda x: x.element.attrib['name'])\n        for anchor in anchororder:\n            element = anchor.element\n            for attrn in ('colour', 'indentifier'):  # Remove format 2 attributes\n                if attrn in element.attrib: del element.attrib[attrn]\n            element.attrib['type'] = 'move'\n            contelement = ET.Element(\"contour\")\n            contelement.append(ET.Element(\"point\", element.attrib))\n            self._contents['outline'].appendobject(Ucontour(self._contents['outline'], contelement), \"contour\")\n            self.remove('anchor', object=anchor)",
  "def makeObject(self, type, element):\n        if type == 'advance': return Uadvance(self, element)\n        if type == 'unicode': return Uunicode(self, element)\n        if type == 'outline': return Uoutline(self, element)\n        if type == 'lib': return Ulib(self, element)\n        if type == 'note': return Unote(self, element)\n        if type == 'image': return Uimage(self, element)\n        if type == 'guideline': return Uguideline(self, element)\n        if type == 'anchor': return Uanchor(self, element)",
  "def __init__(self, glif, element):\n        super(Uadvance, self).__init__(element)\n        self.glif = glif\n        if 'width' in element.attrib:\n            self.width = element.attrib[str('width')]\n        else:\n            self.width = None\n        if 'height' in element.attrib:\n            self.height = element.attrib[str('height')]\n        else:\n            self.height = None",
  "def __setattr__(self, name, value):\n        if name in ('width', 'height'):\n            if value == \"0\" : value = None\n            if value is None:\n                if name in self.element.attrib: del self.element.attrib[name]\n            else:\n                value = str(value)\n                self.element.attrib[name] = value\n        super(Uadvance, self).__setattr__(name, value)",
  "def __init__(self, glif, element):\n        super(Uunicode, self).__init__(element)\n        self.glif = glif\n        if 'hex' in element.attrib:\n            self.hex = element.attrib['hex']\n        else:\n            self.hex = \"\"\n            self.glif.logger.log(\"No unicode hex attribute for \" + glif.name, \"E\")",
  "def __setattr__(self, name, value):\n        if name == \"hex\": self.element.attrib['hex'] = value\n        super(Uunicode, self).__setattr__(name, value)",
  "def __init__(self, glif, element):\n        self.glif = glif\n        super(Unote, self).__init__(element)",
  "def __init__(self, glif, element):\n        self.glif = glif\n        super(Uimage, self).__init__(element)",
  "def __init__(self, glif, element):\n        self.glif = glif\n        super(Uguideline, self).__init__(element)",
  "def __init__(self, glif, element):\n        self.glif = glif\n        super(Uanchor, self).__init__(element)",
  "def __init__(self, glif, element):\n        super(Uoutline, self).__init__(element)\n        self.glif = glif\n        self.components = []\n        self.contours = []\n        for tag in self._contents:\n            if tag == \"component\":\n                for component in self._contents[tag]:\n                    self.components.append(Ucomponent(self, component))\n            if tag == \"contour\":\n                for contour in self._contents[tag]:\n                    self.contours.append(Ucontour(self, contour))",
  "def removeobject(self, obj, typ):\n        super(Uoutline, self).remove(obj.element)\n        if typ == \"component\": self.components.remove(obj)\n        if typ == \"contour\": self.contours.remove(obj)",
  "def replaceobject(self, oldobj, newobj, typ):\n        eindex = list(self.element).index(oldobj.element)\n        super(Uoutline, self).replace(eindex, newobj.element)\n        if typ == \"component\":\n            cindex = self.components.index(oldobj)\n            self.components[cindex]= newobj\n        if typ == \"contour\":\n            cindex = self.contours.index(oldobj)\n            self.contours[cindex]= newobj",
  "def appendobject(self, item, typ): # Item can be an contour/component object, element or attribute list\n        if isinstance(item, (Ucontour, Ucomponent)):\n            obj = item\n        else:\n            if isinstance(item, dict):\n                elem = ET.Element(typ)\n                elem.attrib = item\n            elif isinstance(item, ET.Element):\n                elem = item\n            else:\n                self.glif.logger.log(\"item should be dict, element, Ucontour or Ucomponent\", \"S\")\n            if typ == 'component':\n                obj = Ucomponent(self,elem)\n            else:\n                obj = Ucontour(self,elem)\n        super(Uoutline, self).append(obj.element)\n        if typ == \"component\": self.components.append(obj)\n        if typ == \"contour\": self.contours.append(obj)",
  "def insertobject(self, index, item, typ): # Needs updating to match appendobject\n        self.glif.logger.log(\"insertobject currently buggy so don't use!\", \"X\")",
  "def __init__(self, outline, element):\n        super(Ucomponent, self).__init__(element)\n        self.outline = outline",
  "def __init__(self, outline, element):\n        super(Ucontour, self).__init__(element)\n        self.outline = outline\n        self.UFO2anchor = None\n        points = self._contents['point']\n        # Identify UFO2-style anchor points\n        if len(points) == 1 and \"type\" in points[0].attrib:\n            if points[0].attrib[\"type\"] == \"move\":\n                if \"name\" in points[0].attrib:\n                    self.UFO2anchor = points[0].attrib\n                else:\n                    self.outline.glif.layer.font.logger.log(\n                        \"Glyph \" + self.outline.glif.name + \" contains a single-point contour with no anchor name\", \"E\")",
  "def __init__(self, glif, element):\n        self.glif = glif\n        self.element = element  # needs both element and etree for compatibility\n        self.etree = element    # with other glif components and _plist methods\n        self._contents = {}\n        self.reindex()",
  "def reindex(self):\n        self._contents.clear()  # Clear existing contents, if any\n        pl = self.element[0]\n        if pl.tag == \"dict\":\n            for i in range(0, len(pl), 2):\n                key = pl[i].text\n                self._contents[key] = [pl[i], pl[i + 1]]",
  "def __init__(self, font, dirn, filen):\n        super(UfeatureFile, self).__init__(font, dirn, filen)",
  "class CompGlyph(object):\n\n    def __init__(self, CDelement=None, CDline=None):\n        self.CDelement = CDelement\n        self.CDline = CDline\n\n    def _parseparams(self, rest):\n        \"\"\"Parse a parameter line such as:\n        key1=value1;key2=value2\n        and return a dictionary with key:value pairs.\n        \"\"\"\n        params = {}\n        while rest:\n            matchparam=re.match(paramdef,rest)\n            if matchparam == None:\n                raise ValueError(\"Parameter error: \" + rest)\n            params[matchparam.group('paramname')] = matchparam.group('paramval')\n            rest = matchparam.group('rest')\n        return(params)\n\n    def parsefromCDline(self):\n        \"\"\"Parse the composite glyph information (in self.CDline) such as:\n        LtnCapADiear = LtnCapA + CombDiaer@U |00C4 ! 1, 0, 0, 1 # comment\n        and return a <glyph> element (in self.CDelement)\n        <glyph PSName=\"LtnCapADiear\" UID=\"00C4\">\n          <note>comment</note>\n          <property name=\"mark\" value=\"1, 0, 0, 1\"/>\n          <base PSName=\"LtnCapA\">\n            <attach PSName=\"CombDiaer\" with=\"_U\" at=\"U\"/>\n          </base>\n        </glyph>\n        Position info after @ can include optional base glyph name followed by colon.\n        \"\"\"\n        line = self.CDline\n        results = {}\n        for parseinfo in initialtokens:\n            if len(line) > 0:\n                regex, groupname, errormsg = parseinfo\n                matchresults = re.match(regex,line)\n                if matchresults == None:\n                    raise ValueError(errormsg)\n                line = matchresults.group('remainder')\n                resultsval = matchresults.group(groupname)\n                if resultsval != None:\n                    results[groupname] = resultsval.strip()\n                    if groupname == 'paraminfo': # paraminfo match needs to be removed from remainder\n                        line = line.rstrip('['+resultsval+']')\n                if 'remainder2' in matchresults.groupdict().keys(): line += ' ' + matchresults.group('remainder2')\n# At this point results optionally may contain entries for any of 'commenttext', 'paraminfo', 'markinfo', 'UID', or 'metrics', \n# but it must have 'PSName' if any of 'paraminfo', 'markinfo', 'UID', or 'metrics' present\n        note = results.pop('commenttext', None)\n        if 'PSName' not in results:\n            if len(results) > 0:\n                raise ValueError(\"Missing glyph name\")\n            else: # comment only, or blank line\n                return None\n        dic = {}\n        UIDpresent = 'UID' in results\n        if UIDpresent and results['UID'] == '':\n            results.pop('UID')\n        if 'paraminfo' in results:\n            paramdata = results.pop('paraminfo')\n            if UIDpresent:\n                dic = self._parseparams(paramdata)\n            else:\n                line += \" [\" + paramdata + \"]\"\n        mark = results.pop('markinfo', None)\n        if 'metrics' in results:\n            m = results.pop('metrics')\n            matchmetrics = re.match(lsb_rsb,m)\n            if matchmetrics == None:\n                raise ValueError(\"Error in parameters: \" + m)\n            elif matchmetrics.group('rsb'):\n                metricdic = {'lsb': matchmetrics.group('lsb'), 'rsb': matchmetrics.group('rsb')}\n            else:\n                metricdic = {'advance': matchmetrics.group('lsb')}\n        else:\n            metricdic = None\n\n        # Create <glyph> element and assign attributes\n        g = ET.Element('glyph',attrib=results)\n        if note:                # note from commenttext becomes <note> subelement\n            n = ET.SubElement(g,'note')\n            n.text = note.rstrip()\n        # markinfo becomes <property> subelement\n        if mark:\n            p = ET.SubElement(g, 'property', name = 'mark', value = mark)\n        # paraminfo parameters (now in dic) become <property> subelements\n        if dic:\n            for key in dic:\n                p = ET.SubElement(g, 'property', name = key, value = dic[key])\n        # metrics parameters (now in metricdic) become subelements\n        if metricdic:\n            for key in metricdic:\n                k = ET.SubElement(g, key, width=metricdic[key])\n\n        # Prepare to parse remainder of line\n        prevbase = None\n        prevdiac = None\n        remainder = line\n        expectingdiac = False\n\n        # top of loop to process remainder of line, breaking off base or diacritics from left to right\n        while remainder != \"\":\n            matchresults=re.match(compdef,remainder)\n            if matchresults == None or matchresults.group('compname') == \"\" :\n                raise ValueError(\"Error parsing glyph name: \" + remainder)\n            propdic = {}\n            if matchresults.group('params'):\n                propdic = self._parseparams(matchresults.group('params'))\n            base = matchresults.group('base')\n            position = matchresults.group('position')\n            if expectingdiac:\n                # Determine parent element, based on previous base and diacritic glyphs and optional\n                # matchresults.group('base'), indicating diacritic attaches to a different glyph\n                if base == None:\n                    if prevdiac != None:\n                        parent = prevdiac\n                    else:\n                        parent = prevbase\n                elif base != prevbase.attrib['PSName']:\n                    raise ValueError(\"Error in diacritic alternate base glyph: \" + base)\n                else:\n                    parent = prevbase\n                    if prevdiac == None:\n                        raise ValueError(\"Unnecessary diacritic alternate base glyph: \" + base)\n                # Because 'with' is Python reserved word, passing it directly as a parameter\n                # causes Python syntax error, so build dictionary to pass to SubElement\n                att = {'PSName': matchresults.group('compname')}\n                if position:\n                    if 'with' in propdic:\n                        withval = propdic.pop('with')\n                    else:\n                        withval = \"_\" + position\n                    att['at'] = position\n                    att['with'] = withval\n                # Create <attach> subelement\n                e = ET.SubElement(parent, 'attach', attrib=att)\n                prevdiac = e\n            elif (base or position):\n                raise ValueError(\"Position information on base glyph not supported\")\n            else:\n                # Create <base> subelement\n                e = ET.SubElement(g, 'base', PSName=matchresults.group('compname'))\n                prevbase = e\n                prevdiac = None\n            if 'shift' in propdic:\n                xval, yval = propdic.pop('shift').split(',')\n                s = ET.SubElement(e, 'shift', x=xval, y=yval)\n            # whatever parameters are left in propdic become <property> subelements\n            for key, val in propdic.items():\n                p = ET.SubElement(e, 'property', name=key, value=val)\n\n            remainder = matchresults.group('remainder').lstrip()\n            nextchar = remainder[:1]\n            remainder = remainder[1:].lstrip()\n            expectingdiac = nextchar == '+'\n            if nextchar == '&' or nextchar == '+':\n                if len(remainder) == 0:\n                    raise ValueError(\"Expecting glyph name after & or +\")\n            elif len(nextchar) > 0:\n                raise ValueError(\"Expecting & or + and found \" + nextchar)\n        self.CDelement = g\n\n    def _diacinfo(self, node, parent, lastglyph):\n        \"\"\"receives attach element, PSName of its parent, PSName of most recent glyph\n        returns a string equivalent of this node (and all its descendants)\n        and a string with the name of the most recent glyph\n        \"\"\"\n        diacname = node.get('PSName')\n        atstring = node.get('at')\n        withstring = node.get('with')\n        propdic = {}\n        if withstring != \"_\" + atstring:\n            propdic['with'] = withstring\n        subattachlist = []\n        attachglyph = \"\"\n        if parent != lastglyph:\n            attachglyph = parent + \":\"\n        for subelement in node:\n            if subelement.tag == 'property':\n                propdic[subelement.get('name')] = subelement.get('value')\n            elif subelement.tag == 'attach':\n                subattachlist.append(subelement)\n            elif subelement.tag == 'shift':\n                propdic['shift'] = subelement.get('x') + \",\" + subelement.get('y') \n            # else flag error/warning?\n        propstring = \"\"\n        if propdic:\n            propstring += \" [\" + \";\".join( [k + \"=\" + v for k,v in propdic.items()] ) + \"]\"\n        returnstring = \" + \" + diacname + \"@\" + attachglyph + atstring + propstring\n        prevglyph = diacname\n        for s in subattachlist:\n            string, prevglyph = self._diacinfo(s, diacname, prevglyph)\n            returnstring += string\n        return returnstring, prevglyph\n\n    def _basediacinfo(self, baseelement):\n        \"\"\"receives base element and returns a string equivalent of this node (and all its desendants)\"\"\"\n        basename = baseelement.get('PSName')\n        returnstring = basename\n        prevglyph = basename\n        bpropdic = {}\n        for child in baseelement:\n            if child.tag == 'attach':\n                string, prevglyph = self._diacinfo(child, basename, prevglyph)\n                returnstring += string\n            elif child.tag == 'shift':\n                bpropdic['shift'] = child.get('x') + \",\" + child.get('y') \n        if bpropdic:\n            returnstring += \" [\" + \";\".join( [k + \"=\" + v for k,v in bpropdic.items()] ) + \"]\"\n        return returnstring\n\n    def parsefromCDelement(self):\n        \"\"\"Parse a glyph element such as:\n        <glyph PSName=\"LtnSmITildeGraveDotBlw\" UID=\"E000\">\n          <note>i tilde grave dot-below</note>\n          <base PSName=\"LtnSmDotlessI\">\n            <attach PSName=\"CombDotBlw\" at=\"L\" with=\"_L\" />\n            <attach PSName=\"CombTilde\" at=\"U\" with=\"_U\">\n              <attach PSName=\"CombGrave\" at=\"U\" with=\"_U\" />\n            </attach>\n          </base>\n        </glyph>\n        and produce the equivalent CDline in format:\n        LtnSmITildeGraveDotBlw = LtnSmDotlessI + CombDotBlw@L + CombTilde@LtnSmDotlessI:U + CombGrave@U | E000 # i tilde grave dot-below\n        \"\"\"\n        g = self.CDelement\n        lsb = None\n        rsb = None\n        adv = None\n        markinfo = None\n        note = None\n        paramdic = {}\n        outputline = [g.get('PSName')]\n        resultUID = g.get('UID')\n        basesep = \" = \"\n\n        for child in g:\n            if child.tag == 'note':             note = child.text\n            elif child.tag == 'property':\n                if child.get('name') == 'mark': markinfo = child.get('value')\n                else:                           paramdic[child.get('name')] = child.get('value')\n            elif child.tag == 'lsb':            lsb = child.get('width')\n            elif child.tag == 'rsb':            rsb = child.get('width')\n            elif child.tag == 'advance':        adv = child.get('width')\n            elif child.tag == 'base':\n                outputline.extend([basesep, self._basediacinfo(child)])\n                basesep = \" & \"\n\n        if paramdic and resultUID == None:\n            resultUID = \" \" # to force output of |\n        if adv:             outputline.extend([' ^', adv])\n        if lsb and rsb:     outputline.extend([' ^', lsb, ',', rsb])\n        if resultUID:       outputline.extend([' |', resultUID])\n        if markinfo:        outputline.extend([' !', markinfo])\n        if paramdic:\n            paramsep = \" [\"\n            for k in paramdic:\n                outputline.extend([paramsep, k, \"=\", paramdic[k]])\n                paramsep = \";\"\n            outputline.append(\"]\")\n        if note:\n            outputline.extend([\" # \", note])\n        self.CDline = \"\".join(outputline)",
  "def __init__(self, CDelement=None, CDline=None):\n        self.CDelement = CDelement\n        self.CDline = CDline",
  "def _parseparams(self, rest):\n        \"\"\"Parse a parameter line such as:\n        key1=value1;key2=value2\n        and return a dictionary with key:value pairs.\n        \"\"\"\n        params = {}\n        while rest:\n            matchparam=re.match(paramdef,rest)\n            if matchparam == None:\n                raise ValueError(\"Parameter error: \" + rest)\n            params[matchparam.group('paramname')] = matchparam.group('paramval')\n            rest = matchparam.group('rest')\n        return(params)",
  "def parsefromCDline(self):\n        \"\"\"Parse the composite glyph information (in self.CDline) such as:\n        LtnCapADiear = LtnCapA + CombDiaer@U |00C4 ! 1, 0, 0, 1 # comment\n        and return a <glyph> element (in self.CDelement)\n        <glyph PSName=\"LtnCapADiear\" UID=\"00C4\">\n          <note>comment</note>\n          <property name=\"mark\" value=\"1, 0, 0, 1\"/>\n          <base PSName=\"LtnCapA\">\n            <attach PSName=\"CombDiaer\" with=\"_U\" at=\"U\"/>\n          </base>\n        </glyph>\n        Position info after @ can include optional base glyph name followed by colon.\n        \"\"\"\n        line = self.CDline\n        results = {}\n        for parseinfo in initialtokens:\n            if len(line) > 0:\n                regex, groupname, errormsg = parseinfo\n                matchresults = re.match(regex,line)\n                if matchresults == None:\n                    raise ValueError(errormsg)\n                line = matchresults.group('remainder')\n                resultsval = matchresults.group(groupname)\n                if resultsval != None:\n                    results[groupname] = resultsval.strip()\n                    if groupname == 'paraminfo': # paraminfo match needs to be removed from remainder\n                        line = line.rstrip('['+resultsval+']')\n                if 'remainder2' in matchresults.groupdict().keys(): line += ' ' + matchresults.group('remainder2')\n# At this point results optionally may contain entries for any of 'commenttext', 'paraminfo', 'markinfo', 'UID', or 'metrics', \n# but it must have 'PSName' if any of 'paraminfo', 'markinfo', 'UID', or 'metrics' present\n        note = results.pop('commenttext', None)\n        if 'PSName' not in results:\n            if len(results) > 0:\n                raise ValueError(\"Missing glyph name\")\n            else: # comment only, or blank line\n                return None\n        dic = {}\n        UIDpresent = 'UID' in results\n        if UIDpresent and results['UID'] == '':\n            results.pop('UID')\n        if 'paraminfo' in results:\n            paramdata = results.pop('paraminfo')\n            if UIDpresent:\n                dic = self._parseparams(paramdata)\n            else:\n                line += \" [\" + paramdata + \"]\"\n        mark = results.pop('markinfo', None)\n        if 'metrics' in results:\n            m = results.pop('metrics')\n            matchmetrics = re.match(lsb_rsb,m)\n            if matchmetrics == None:\n                raise ValueError(\"Error in parameters: \" + m)\n            elif matchmetrics.group('rsb'):\n                metricdic = {'lsb': matchmetrics.group('lsb'), 'rsb': matchmetrics.group('rsb')}\n            else:\n                metricdic = {'advance': matchmetrics.group('lsb')}\n        else:\n            metricdic = None\n\n        # Create <glyph> element and assign attributes\n        g = ET.Element('glyph',attrib=results)\n        if note:                # note from commenttext becomes <note> subelement\n            n = ET.SubElement(g,'note')\n            n.text = note.rstrip()\n        # markinfo becomes <property> subelement\n        if mark:\n            p = ET.SubElement(g, 'property', name = 'mark', value = mark)\n        # paraminfo parameters (now in dic) become <property> subelements\n        if dic:\n            for key in dic:\n                p = ET.SubElement(g, 'property', name = key, value = dic[key])\n        # metrics parameters (now in metricdic) become subelements\n        if metricdic:\n            for key in metricdic:\n                k = ET.SubElement(g, key, width=metricdic[key])\n\n        # Prepare to parse remainder of line\n        prevbase = None\n        prevdiac = None\n        remainder = line\n        expectingdiac = False\n\n        # top of loop to process remainder of line, breaking off base or diacritics from left to right\n        while remainder != \"\":\n            matchresults=re.match(compdef,remainder)\n            if matchresults == None or matchresults.group('compname') == \"\" :\n                raise ValueError(\"Error parsing glyph name: \" + remainder)\n            propdic = {}\n            if matchresults.group('params'):\n                propdic = self._parseparams(matchresults.group('params'))\n            base = matchresults.group('base')\n            position = matchresults.group('position')\n            if expectingdiac:\n                # Determine parent element, based on previous base and diacritic glyphs and optional\n                # matchresults.group('base'), indicating diacritic attaches to a different glyph\n                if base == None:\n                    if prevdiac != None:\n                        parent = prevdiac\n                    else:\n                        parent = prevbase\n                elif base != prevbase.attrib['PSName']:\n                    raise ValueError(\"Error in diacritic alternate base glyph: \" + base)\n                else:\n                    parent = prevbase\n                    if prevdiac == None:\n                        raise ValueError(\"Unnecessary diacritic alternate base glyph: \" + base)\n                # Because 'with' is Python reserved word, passing it directly as a parameter\n                # causes Python syntax error, so build dictionary to pass to SubElement\n                att = {'PSName': matchresults.group('compname')}\n                if position:\n                    if 'with' in propdic:\n                        withval = propdic.pop('with')\n                    else:\n                        withval = \"_\" + position\n                    att['at'] = position\n                    att['with'] = withval\n                # Create <attach> subelement\n                e = ET.SubElement(parent, 'attach', attrib=att)\n                prevdiac = e\n            elif (base or position):\n                raise ValueError(\"Position information on base glyph not supported\")\n            else:\n                # Create <base> subelement\n                e = ET.SubElement(g, 'base', PSName=matchresults.group('compname'))\n                prevbase = e\n                prevdiac = None\n            if 'shift' in propdic:\n                xval, yval = propdic.pop('shift').split(',')\n                s = ET.SubElement(e, 'shift', x=xval, y=yval)\n            # whatever parameters are left in propdic become <property> subelements\n            for key, val in propdic.items():\n                p = ET.SubElement(e, 'property', name=key, value=val)\n\n            remainder = matchresults.group('remainder').lstrip()\n            nextchar = remainder[:1]\n            remainder = remainder[1:].lstrip()\n            expectingdiac = nextchar == '+'\n            if nextchar == '&' or nextchar == '+':\n                if len(remainder) == 0:\n                    raise ValueError(\"Expecting glyph name after & or +\")\n            elif len(nextchar) > 0:\n                raise ValueError(\"Expecting & or + and found \" + nextchar)\n        self.CDelement = g",
  "def _diacinfo(self, node, parent, lastglyph):\n        \"\"\"receives attach element, PSName of its parent, PSName of most recent glyph\n        returns a string equivalent of this node (and all its descendants)\n        and a string with the name of the most recent glyph\n        \"\"\"\n        diacname = node.get('PSName')\n        atstring = node.get('at')\n        withstring = node.get('with')\n        propdic = {}\n        if withstring != \"_\" + atstring:\n            propdic['with'] = withstring\n        subattachlist = []\n        attachglyph = \"\"\n        if parent != lastglyph:\n            attachglyph = parent + \":\"\n        for subelement in node:\n            if subelement.tag == 'property':\n                propdic[subelement.get('name')] = subelement.get('value')\n            elif subelement.tag == 'attach':\n                subattachlist.append(subelement)\n            elif subelement.tag == 'shift':\n                propdic['shift'] = subelement.get('x') + \",\" + subelement.get('y') \n            # else flag error/warning?\n        propstring = \"\"\n        if propdic:\n            propstring += \" [\" + \";\".join( [k + \"=\" + v for k,v in propdic.items()] ) + \"]\"\n        returnstring = \" + \" + diacname + \"@\" + attachglyph + atstring + propstring\n        prevglyph = diacname\n        for s in subattachlist:\n            string, prevglyph = self._diacinfo(s, diacname, prevglyph)\n            returnstring += string\n        return returnstring, prevglyph",
  "def _basediacinfo(self, baseelement):\n        \"\"\"receives base element and returns a string equivalent of this node (and all its desendants)\"\"\"\n        basename = baseelement.get('PSName')\n        returnstring = basename\n        prevglyph = basename\n        bpropdic = {}\n        for child in baseelement:\n            if child.tag == 'attach':\n                string, prevglyph = self._diacinfo(child, basename, prevglyph)\n                returnstring += string\n            elif child.tag == 'shift':\n                bpropdic['shift'] = child.get('x') + \",\" + child.get('y') \n        if bpropdic:\n            returnstring += \" [\" + \";\".join( [k + \"=\" + v for k,v in bpropdic.items()] ) + \"]\"\n        return returnstring",
  "def parsefromCDelement(self):\n        \"\"\"Parse a glyph element such as:\n        <glyph PSName=\"LtnSmITildeGraveDotBlw\" UID=\"E000\">\n          <note>i tilde grave dot-below</note>\n          <base PSName=\"LtnSmDotlessI\">\n            <attach PSName=\"CombDotBlw\" at=\"L\" with=\"_L\" />\n            <attach PSName=\"CombTilde\" at=\"U\" with=\"_U\">\n              <attach PSName=\"CombGrave\" at=\"U\" with=\"_U\" />\n            </attach>\n          </base>\n        </glyph>\n        and produce the equivalent CDline in format:\n        LtnSmITildeGraveDotBlw = LtnSmDotlessI + CombDotBlw@L + CombTilde@LtnSmDotlessI:U + CombGrave@U | E000 # i tilde grave dot-below\n        \"\"\"\n        g = self.CDelement\n        lsb = None\n        rsb = None\n        adv = None\n        markinfo = None\n        note = None\n        paramdic = {}\n        outputline = [g.get('PSName')]\n        resultUID = g.get('UID')\n        basesep = \" = \"\n\n        for child in g:\n            if child.tag == 'note':             note = child.text\n            elif child.tag == 'property':\n                if child.get('name') == 'mark': markinfo = child.get('value')\n                else:                           paramdic[child.get('name')] = child.get('value')\n            elif child.tag == 'lsb':            lsb = child.get('width')\n            elif child.tag == 'rsb':            rsb = child.get('width')\n            elif child.tag == 'advance':        adv = child.get('width')\n            elif child.tag == 'base':\n                outputline.extend([basesep, self._basediacinfo(child)])\n                basesep = \" & \"\n\n        if paramdic and resultUID == None:\n            resultUID = \" \" # to force output of |\n        if adv:             outputline.extend([' ^', adv])\n        if lsb and rsb:     outputline.extend([' ^', lsb, ',', rsb])\n        if resultUID:       outputline.extend([' |', resultUID])\n        if markinfo:        outputline.extend([' !', markinfo])\n        if paramdic:\n            paramsep = \" [\"\n            for k in paramdic:\n                outputline.extend([paramsep, k, \"=\", paramdic[k]])\n                paramsep = \";\"\n            outputline.append(\"]\")\n        if note:\n            outputline.extend([\" # \", note])\n        self.CDline = \"\".join(outputline)",
  "class feaplus_ast(object) :\n    MarkBasePosStatement = astx.ast_MarkBasePosStatement\n    MarkMarkPosStatement = astx.ast_MarkMarkPosStatement\n    MarkLigPosStatement = astx.ast_MarkLigPosStatement\n    CursivePosStatement = astx.ast_CursivePosStatement\n    BaseClass = astx.ast_BaseClass\n    MarkClass = astx.ast_MarkClass\n    BaseClassDefinition = astx.ast_BaseClassDefinition\n    MultipleSubstStatement = astx.ast_MultipleSubstStatement\n    LigatureSubstStatement = astx.ast_LigatureSubstStatement\n    IfBlock = astx.ast_IfBlock\n    DoForSubStatement = astx.ast_DoForSubStatement\n    DoLetSubStatement = astx.ast_DoLetSubStatement\n    DoIfSubStatement = astx.ast_DoIfSubStatement\n    AlternateSubstStatement = astx.ast_AlternateSubstStatement\n    Comment = astx.ast_Comment\n    KernPairsStatement = astx.ast_KernPairsStatement\n\n    def __getattr__(self, name):\n        return getattr(ast, name)",
  "class feaplus_parser(Parser) :\n    extensions = {\n        'baseClass': lambda s: s.parseBaseClass(),\n        'ifclass': lambda s: s.parseIfClass(),\n        'ifinfo': lambda s: s.parseIfInfo(),\n        'do': lambda s: s.parseDoStatement_(),\n        'def': lambda s: s.parseDefStatement_(),\n        'kernpairs': lambda s: s.parseKernPairsStatement_()\n    }\n    ast = feaplus_ast()\n\n    def __init__(self, filename, glyphmap, fontinfo, kerninfo, defines) :\n        if filename is None :\n            empty_file = io.StringIO(\"\")\n            super(feaplus_parser, self).__init__(empty_file, glyphmap)\n        else :\n            super(feaplus_parser, self).__init__(filename, glyphmap)\n        self.fontinfo = fontinfo\n        self.kerninfo = kerninfo\n        self.glyphs = glyphmap\n        self.defines = defines\n        self.fns = {\n            '__builtins__': None,\n            're' : re,\n            'math' : math,\n            'APx': lambda g, a, d=0: int(self.glyphs[g].anchors.get(a, [d])[0]),\n            'APy': lambda g, a, d=0: int(self.glyphs[g].anchors.get(a, [0,d])[1]),\n            'ADVx': lambda g: int(self.glyphs[g].advance),\n            'MINx': lambda g: int(self.glyphs[g].bbox[0]),\n            'MINy': lambda g: int(self.glyphs[g].bbox[1]),\n            'MAXx': lambda g: int(self.glyphs[g].bbox[2]),\n            'MAXy': lambda g: int(self.glyphs[g].bbox[3]),\n            'feaclass': lambda c: self.resolve_glyphclass(c).glyphSet(),\n            'allglyphs': lambda : self.glyphs.keys(),\n            'lf': lambda : \"\\n\",\n            'info': lambda s: self.fontinfo.get(s, \"\"),\n            'fileexists': lambda s: os.path.exists(s),\n            'kerninfo': lambda s:[(k1, k2, v) for k1, x in self.kerninfo.items() for k2, v in x.items()],\n            'opt': lambda s: self.defines.get(s, \"\")\n        }\n        # Document which builtins we really need. Of course still insecure.\n        for x in ('True', 'False', 'None', 'int', 'float', 'str', 'abs', 'all', 'any', 'bool',\n                    'dict', 'enumerate', 'filter', 'hasattr', 'hex', 'len', 'list', 'map', 'print',\n                    'max', 'min', 'ord', 'range', 'set', 'sorted', 'sum', 'tuple', 'zip'):\n            self.fns[x] = __builtins__[x]\n\n    def parse(self, filename=None) :\n        if filename is not None :\n            self.lexer_ = feax_lexer.feax_IncludingLexer(filename)\n            self.advance_lexer_(comments=True)\n        return super(feaplus_parser, self).parse()\n\n    def back_lexer_(self):\n        self.lexer_.lexers_[-1].pushback(self.next_token_type_, self.next_token_)\n        self.next_token_type_ = self.cur_token_type_\n        self.next_token_ = self.cur_token_\n        self.next_token_location_ = self.cur_token_location_\n\n    # methods to limit layer violations\n    def define_glyphclass(self, ap_nm, gc) :\n        self.glyphclasses_.define(ap_nm, gc)\n\n    def resolve_glyphclass(self, ap_nm):\n        try:\n            return self.glyphclasses_.resolve(ap_nm)\n        except KeyError:\n            raise FeatureLibError(\"Glyphclass '{}' missing\".format(ap_nm), self.lexer_.location_())\n        return None\n\n    def add_statement(self, val) :\n        self.doc_.statements.append(val)\n\n    def set_baseclass(self, ap_nm) :\n        gc = self.ast.BaseClass(ap_nm)\n        if not hasattr(self.doc_, 'baseClasses') :\n            self.doc_.baseClasses = {}\n        self.doc_.baseClasses[ap_nm] = gc\n        self.define_glyphclass(ap_nm, gc)\n        return gc\n\n    def set_markclass(self, ap_nm) :\n        gc = self.ast.MarkClass(ap_nm)\n        if not hasattr(self.doc_, 'markClasses') :\n            self.doc_.markClasses = {}\n        self.doc_.markClasses[ap_nm] = gc\n        self.define_glyphclass(ap_nm, gc)\n        return gc\n\n\n    # like base class parse_position_base_ & overrides it\n    def parse_position_base_(self, enumerated, vertical):\n        location = self.cur_token_location_\n        self.expect_keyword_(\"base\")\n        if enumerated:\n            raise FeatureLibError(\n                '\"enumerate\" is not allowed with '\n                'mark-to-base attachment positioning',\n                location)\n        base = self.parse_glyphclass_(accept_glyphname=True)\n        if self.next_token_ == \"<\": # handle pos base [glyphs] <anchor> mark @MARKCLASS\n            marks = self.parse_anchor_marks_()\n        else: # handle pos base @BASECLASS mark @MARKCLASS; like base class parse_anchor_marks_\n            marks = []\n            while self.next_token_ == \"mark\": #TODO: is more than one 'mark' meaningful?\n                self.expect_keyword_(\"mark\")\n                m = self.expect_markClass_reference_()\n                marks.append(m)\n        self.expect_symbol_(\";\")\n        return self.ast.MarkBasePosStatement(base, marks, location=location)\n\n    # like base class parse_position_mark_ & overrides it\n    def parse_position_mark_(self, enumerated, vertical):\n        location = self.cur_token_location_\n        self.expect_keyword_(\"mark\")\n        if enumerated:\n            raise FeatureLibError(\n                '\"enumerate\" is not allowed with '\n                'mark-to-mark attachment positioning',\n                location)\n        baseMarks = self.parse_glyphclass_(accept_glyphname=True)\n        if self.next_token_ == \"<\": # handle pos mark [glyphs] <anchor> mark @MARKCLASS\n            marks = self.parse_anchor_marks_()\n        else: # handle pos mark @MARKCLASS mark @MARKCLASS; like base class parse_anchor_marks_\n            marks = []\n            while self.next_token_ == \"mark\": #TODO: is more than one 'mark' meaningful?\n                self.expect_keyword_(\"mark\")\n                m = self.expect_markClass_reference_()\n                marks.append(m)\n        self.expect_symbol_(\";\")\n        return self.ast.MarkMarkPosStatement(baseMarks, marks, location=location)\n\n    def parse_position_cursive_(self, enumerated, vertical):\n        location = self.cur_token_location_\n        self.expect_keyword_(\"cursive\")\n        if enumerated:\n            raise FeatureLibError(\n                '\"enumerate\" is not allowed with '\n                'cursive attachment positioning',\n                location)\n        glyphclass = self.parse_glyphclass_(accept_glyphname=True)\n        if self.next_token_ == \"<\": # handle pos cursive @glyphClass <anchor entry> <anchor exit>\n            entryAnchor = self.parse_anchor_()\n            exitAnchor = self.parse_anchor_()\n            self.expect_symbol_(\";\")\n            return self.ast.CursivePosStatement(\n                glyphclass, entryAnchor, exitAnchor, location=location)\n        else: # handle pos cursive @baseClass @baseClass;\n            mc = self.expect_markClass_reference_()\n            return self.ast.CursivePosStatement(glyphclass.markClass, None, mc, location=location)\n\n    def parse_position_ligature_(self, enumerated, vertical):\n        location = self.cur_token_location_\n        self.expect_keyword_(\"ligature\")\n        if enumerated:\n            raise FeatureLibError(\n                '\"enumerate\" is not allowed with '\n                'mark-to-ligature attachment positioning',\n                location)\n        ligatures = self.parse_glyphclass_(accept_glyphname=True)\n        marks = [self._parse_anchorclass_marks_()]\n        while self.next_token_ == \"ligComponent\":\n            self.expect_keyword_(\"ligComponent\")\n            marks.append(self._parse_anchorclass_marks_())\n        self.expect_symbol_(\";\")\n        return self.ast.MarkLigPosStatement(ligatures, marks, location=location)\n\n    def _parse_anchorclass_marks_(self):\n        \"\"\"Parses a sequence of [<anchor> | @BASECLASS mark @MARKCLASS]*.\"\"\"\n        anchorMarks = []  # [(self.ast.Anchor, markClassName)*]\n        while True:\n            if self.next_token_ == \"<\":\n                anchor = self.parse_anchor_()\n            else:\n                anchor = self.parse_glyphclass_(accept_glyphname=False)\n            if anchor is not None:\n                self.expect_keyword_(\"mark\")\n                markClass = self.expect_markClass_reference_()\n                anchorMarks.append((anchor, markClass))\n            if self.next_token_ == \"ligComponent\" or self.next_token_ == \";\":\n                break\n        return anchorMarks\n\n    # like base class parseMarkClass\n    # but uses BaseClass and BaseClassDefinition which subclass Mark counterparts\n    def parseBaseClass(self):\n        if not hasattr(self.doc_, 'baseClasses'):\n            self.doc_.baseClasses = {}\n        location = self.cur_token_location_\n        glyphs = self.parse_glyphclass_(accept_glyphname=True)\n        anchor = self.parse_anchor_()\n        name = self.expect_class_name_()\n        self.expect_symbol_(\";\")\n        baseClass = self.doc_.baseClasses.get(name)\n        if baseClass is None:\n            baseClass = self.ast.BaseClass(name)\n            self.doc_.baseClasses[name] = baseClass\n            self.glyphclasses_.define(name, baseClass)\n        bcdef = self.ast.BaseClassDefinition(baseClass, anchor, glyphs, location=location)\n        baseClass.addDefinition(bcdef)\n        return bcdef\n\n    #similar to and overrides parser.parse_substitute_\n    def parse_substitute_(self):\n        assert self.cur_token_ in {\"substitute\", \"sub\", \"reversesub\", \"rsub\"}\n        location = self.cur_token_location_\n        reverse = self.cur_token_ in {\"reversesub\", \"rsub\"}\n        old_prefix, old, lookups, values, old_suffix, hasMarks = \\\n            self.parse_glyph_pattern_(vertical=False)\n        if any(values):\n            raise FeatureLibError(\n                \"Substitution statements cannot contain values\", location)\n        new = []\n        if self.next_token_ == \"by\":\n            keyword = self.expect_keyword_(\"by\")\n            while self.next_token_ != \";\":\n                gc = self.parse_glyphclass_(accept_glyphname=True)\n                new.append(gc)\n        elif self.next_token_ == \"from\":\n            keyword = self.expect_keyword_(\"from\")\n            new = [self.parse_glyphclass_(accept_glyphname=False)]\n        else:\n            keyword = None\n        self.expect_symbol_(\";\")\n        if len(new) == 0 and not any(lookups):\n            raise FeatureLibError(\n                'Expected \"by\", \"from\" or explicit lookup references',\n                self.cur_token_location_)\n\n        # GSUB lookup type 3: Alternate substitution.\n        # Format: \"substitute a from [a.1 a.2 a.3];\"\n        if keyword == \"from\":\n            if reverse:\n                raise FeatureLibError(\n                    'Reverse chaining substitutions do not support \"from\"',\n                    location)\n            # allow classes on lhs\n            if len(old) != 1:\n                raise FeatureLibError(\n                    'Expected single glyph or glyph class before \"from\"',\n                    location)\n            if len(new) != 1:\n                raise FeatureLibError(\n                    'Expected a single glyphclass after \"from\"',\n                    location)\n            if len(old[0].glyphSet()) == 0 or len(new[0].glyphSet()) % len(old[0].glyphSet()) != 0:\n                raise FeatureLibError(\n                    'The glyphclass after \"from\" must be a multiple of length of the glyphclass on before',\n                    location)\n            return self.ast.AlternateSubstStatement(\n                old_prefix, old[0], old_suffix, new[0], location=location)\n\n        num_lookups = len([l for l in lookups if l is not None])\n\n        # GSUB lookup type 1: Single substitution.\n        # Format A: \"substitute a by a.sc;\"\n        # Format B: \"substitute [one.fitted one.oldstyle] by one;\"\n        # Format C: \"substitute [a-d] by [A.sc-D.sc];\"\n        if (not reverse and len(old) == 1 and len(new) == 1 and\n                num_lookups == 0):\n            glyphs = list(old[0].glyphSet())\n            replacements = list(new[0].glyphSet())\n            if len(replacements) == 1:\n                replacements = replacements * len(glyphs)\n            if len(glyphs) != len(replacements):\n                raise FeatureLibError(\n                    'Expected a glyph class with %d elements after \"by\", '\n                    'but found a glyph class with %d elements' %\n                    (len(glyphs), len(replacements)), location)\n            return self.ast.SingleSubstStatement(\n                old, new,\n                old_prefix, old_suffix,\n                forceChain=hasMarks, location=location\n            )\n\n        # GSUB lookup type 2: Multiple substitution.\n        # Format: \"substitute f_f_i by f f i;\"\n        if (not reverse and\n                len(old) == 1 and len(new) > 1 and num_lookups == 0):\n            return self.ast.MultipleSubstStatement(old_prefix, old[0], old_suffix, new,\n                                                    hasMarks, location=location)\n\n        # GSUB lookup type 4: Ligature substitution.\n        # Format: \"substitute f f i by f_f_i;\"\n        if (not reverse and\n                len(old) > 1 and len(new) == 1 and num_lookups == 0):\n            return self.ast.LigatureSubstStatement(old_prefix, old, old_suffix, new[0],\n                                                    forceChain=hasMarks, location=location)\n\n        # GSUB lookup type 8: Reverse chaining substitution.\n        if reverse:\n            if len(old) != 1:\n                raise FeatureLibError(\n                    \"In reverse chaining single substitutions, \"\n                    \"only a single glyph or glyph class can be replaced\",\n                    location)\n            if len(new) != 1:\n                raise FeatureLibError(\n                    'In reverse chaining single substitutions, '\n                    'the replacement (after \"by\") must be a single glyph '\n                    'or glyph class', location)\n            if num_lookups != 0:\n                raise FeatureLibError(\n                    \"Reverse chaining substitutions cannot call named lookups\",\n                    location)\n            glyphs = sorted(list(old[0].glyphSet()))\n            replacements = sorted(list(new[0].glyphSet()))\n            if len(replacements) == 1:\n                replacements = replacements * len(glyphs)\n            if len(glyphs) != len(replacements):\n                raise FeatureLibError(\n                    'Expected a glyph class with %d elements after \"by\", '\n                    'but found a glyph class with %d elements' %\n                    (len(glyphs), len(replacements)), location)\n            return self.ast.ReverseChainSingleSubstStatement(\n                old_prefix, old_suffix, old, new, location=location)\n\n        # GSUB lookup type 6: Chaining contextual substitution.\n        assert len(new) == 0, new\n        rule = self.ast.ChainContextSubstStatement(\n            old_prefix, old, old_suffix, lookups, location=location)\n        return rule\n\n    def parse_glyphclass_(self, accept_glyphname):\n        if (accept_glyphname and\n                self.next_token_type_ in (Lexer.NAME, Lexer.CID)):\n            glyph = self.expect_glyph_()\n            return self.ast.GlyphName(glyph, location=self.cur_token_location_)\n        if self.next_token_type_ is Lexer.GLYPHCLASS:\n            self.advance_lexer_()\n            gc = self.glyphclasses_.resolve(self.cur_token_)\n            if gc is None:\n                raise FeatureLibError(\n                    \"Unknown glyph class @%s\" % self.cur_token_,\n                    self.cur_token_location_)\n            if isinstance(gc, self.ast.MarkClass):\n                return self.ast.MarkClassName(gc, location=self.cur_token_location_)\n            else:\n                return self.ast.GlyphClassName(gc, location=self.cur_token_location_)\n\n        self.expect_symbol_(\"[\")\n        location = self.cur_token_location_\n        glyphs = self.ast.GlyphClass(location=location)\n        while self.next_token_ != \"]\":\n            if self.next_token_type_ is Lexer.NAME:\n                glyph = self.expect_glyph_()\n                location = self.cur_token_location_\n                if '-' in glyph and glyph not in self.glyphNames_:\n                    start, limit = self.split_glyph_range_(glyph, location)\n                    glyphs.add_range(\n                        start, limit,\n                        self.make_glyph_range_(location, start, limit))\n                elif self.next_token_ == \"-\":\n                    start = glyph\n                    self.expect_symbol_(\"-\")\n                    limit = self.expect_glyph_()\n                    glyphs.add_range(\n                        start, limit,\n                        self.make_glyph_range_(location, start, limit))\n                else:\n                    glyphs.append(glyph)\n            elif self.next_token_type_ is Lexer.CID:\n                glyph = self.expect_glyph_()\n                if self.next_token_ == \"-\":\n                    range_location = self.cur_token_location_\n                    range_start = self.cur_token_\n                    self.expect_symbol_(\"-\")\n                    range_end = self.expect_cid_()\n                    glyphs.add_cid_range(range_start, range_end,\n                                         self.make_cid_range_(range_location,\n                                                              range_start, range_end))\n                else:\n                    glyphs.append(\"cid%05d\" % self.cur_token_)\n            elif self.next_token_type_ is Lexer.GLYPHCLASS:\n                self.advance_lexer_()\n                gc = self.glyphclasses_.resolve(self.cur_token_)\n                if gc is None:\n                    raise FeatureLibError(\n                        \"Unknown glyph class @%s\" % self.cur_token_,\n                        self.cur_token_location_)\n                # fix bug don't output class definition, just the name.\n                if isinstance(gc, self.ast.MarkClass):\n                    gcn = self.ast.MarkClassName(gc, location=self.cur_token_location_)\n                else:\n                    gcn = self.ast.GlyphClassName(gc, location=self.cur_token_location_)\n                glyphs.add_class(gcn)\n            else:\n                raise FeatureLibError(\n                    \"Expected glyph name, glyph range, \"\n                    \"or glyph class reference. Found %s\" % self.next_token_,\n                    self.next_token_location_)\n        self.expect_symbol_(\"]\")\n        return glyphs\n\n    def parseIfClass(self):\n        location = self.cur_token_location_\n        self.expect_symbol_(\"(\")\n        if self.next_token_type_ is Lexer.GLYPHCLASS:\n            self.advance_lexer_()\n            def ifClassTest():\n                gc = self.glyphclasses_.resolve(self.cur_token_)\n                return gc is not None and len(gc.glyphSet())\n            block = self.ast.IfBlock(ifClassTest, 'ifclass', '@'+self.cur_token_, location=location)\n            self.expect_symbol_(\")\")\n            import inspect      # oh this is so ugly!\n            calledby = inspect.stack()[2][3]    # called through lambda since extension\n            if calledby == 'parse_block_':\n                self.parse_subblock_(block, False)\n            else:\n                self.parse_statements_block_(block)\n            return block\n        else:\n            raise FeatureLibError(\"Syntax error missing glyphclass\", location)\n\n    def parseIfInfo(self):\n        location = self.cur_token_location_\n        self.expect_symbol_(\"(\")\n        name = self.expect_name_()\n        self.expect_symbol_(\",\")\n        reg = self.expect_string_()\n        self.expect_symbol_(\")\")\n        def ifInfoTest():\n            s = self.fontinfo.get(name, \"\")\n            return re.search(reg, s)\n        block = self.ast.IfBlock(ifInfoTest, 'ifinfo', '{}, \"{}\"'.format(name, reg), location=location)\n        import inspect      # oh this is so ugly! Instead caller should pass in context\n        calledby = inspect.stack()[2][3]        # called through a lambda since extension\n        if calledby == 'parse_block_':\n            self.parse_subblock_(block, False)\n        else:\n            self.parse_statements_block_(block)\n        return block\n\n    def parseKernPairsStatement_(self):\n        location = self.cur_token_location_\n        res = self.ast.KernPairsStatement(self.kerninfo, location)\n        return res\n\n    def parse_statements_block_(self, block):\n        self.expect_symbol_(\"{\")\n        statements = block.statements\n        while self.next_token_ != \"}\" or self.cur_comments_:\n            self.advance_lexer_(comments=True)\n            if self.cur_token_type_ is Lexer.COMMENT:\n                statements.append(\n                    self.ast.Comment(self.cur_token_,\n                                     location=self.cur_token_location_))\n            elif self.is_cur_keyword_(\"include\"):\n                statements.append(self.parse_include_())\n            elif self.cur_token_type_ is Lexer.GLYPHCLASS:\n                statements.append(self.parse_glyphclass_definition_())\n            elif self.is_cur_keyword_((\"anon\", \"anonymous\")):\n                statements.append(self.parse_anonymous_())\n            elif self.is_cur_keyword_(\"anchorDef\"):\n                statements.append(self.parse_anchordef_())\n            elif self.is_cur_keyword_(\"languagesystem\"):\n                statements.append(self.parse_languagesystem_())\n            elif self.is_cur_keyword_(\"lookup\"):\n                statements.append(self.parse_lookup_(vertical=False))\n            elif self.is_cur_keyword_(\"markClass\"):\n                statements.append(self.parse_markClass_())\n            elif self.is_cur_keyword_(\"feature\"):\n                statements.append(self.parse_feature_block_())\n            elif self.is_cur_keyword_(\"table\"):\n                statements.append(self.parse_table_())\n            elif self.is_cur_keyword_(\"valueRecordDef\"):\n                statements.append(\n                    self.parse_valuerecord_definition_(vertical=False))\n            elif self.cur_token_type_ is Lexer.NAME and self.cur_token_ in self.extensions:\n                statements.append(self.extensions[self.cur_token_](self))\n            elif self.cur_token_type_ is Lexer.SYMBOL and self.cur_token_ == \";\":\n                continue\n            else:\n                raise FeatureLibError(\n                    \"Expected feature, languagesystem, lookup, markClass, \"\n                    \"table, or glyph class definition, got {} \\\"{}\\\"\".format(self.cur_token_type_, self.cur_token_),\n                    self.cur_token_location_)\n\n        self.expect_symbol_(\"}\")\n        # self.expect_symbol_(\";\")  # can't have }; since tokens are space separated\n\n    def parse_subblock_(self, block, vertical, stylisticset=False,\n                            size_feature=None, cv_feature=None):\n        self.expect_symbol_(\"{\")\n        for symtab in self.symbol_tables_:\n            symtab.enter_scope()\n\n        statements = block.statements\n        while self.next_token_ != \"}\" or self.cur_comments_:\n            self.advance_lexer_(comments=True)\n            if self.cur_token_type_ is Lexer.COMMENT:\n                statements.append(self.ast.Comment(\n                    self.cur_token_, location=self.cur_token_location_))\n            elif self.cur_token_type_ is Lexer.GLYPHCLASS:\n                statements.append(self.parse_glyphclass_definition_())\n            elif self.is_cur_keyword_(\"anchorDef\"):\n                statements.append(self.parse_anchordef_())\n            elif self.is_cur_keyword_({\"enum\", \"enumerate\"}):\n                statements.append(self.parse_enumerate_(vertical=vertical))\n            elif self.is_cur_keyword_(\"feature\"):\n                statements.append(self.parse_feature_reference_())\n            elif self.is_cur_keyword_(\"ignore\"):\n                statements.append(self.parse_ignore_())\n            elif self.is_cur_keyword_(\"language\"):\n                statements.append(self.parse_language_())\n            elif self.is_cur_keyword_(\"lookup\"):\n                statements.append(self.parse_lookup_(vertical))\n            elif self.is_cur_keyword_(\"lookupflag\"):\n                statements.append(self.parse_lookupflag_())\n            elif self.is_cur_keyword_(\"markClass\"):\n                statements.append(self.parse_markClass_())\n            elif self.is_cur_keyword_({\"pos\", \"position\"}):\n                statements.append(\n                    self.parse_position_(enumerated=False, vertical=vertical))\n            elif self.is_cur_keyword_(\"script\"):\n                statements.append(self.parse_script_())\n            elif (self.is_cur_keyword_({\"sub\", \"substitute\",\n                                        \"rsub\", \"reversesub\"})):\n                statements.append(self.parse_substitute_())\n            elif self.is_cur_keyword_(\"subtable\"):\n                statements.append(self.parse_subtable_())\n            elif self.is_cur_keyword_(\"valueRecordDef\"):\n                statements.append(self.parse_valuerecord_definition_(vertical))\n            elif stylisticset and self.is_cur_keyword_(\"featureNames\"):\n                statements.append(self.parse_featureNames_(stylisticset))\n            elif cv_feature and self.is_cur_keyword_(\"cvParameters\"):\n                statements.append(self.parse_cvParameters_(cv_feature))\n            elif size_feature and self.is_cur_keyword_(\"parameters\"):\n                statements.append(self.parse_size_parameters_())\n            elif size_feature and self.is_cur_keyword_(\"sizemenuname\"):\n                statements.append(self.parse_size_menuname_())\n            elif self.cur_token_type_ is Lexer.NAME and self.cur_token_ in self.extensions:\n                statements.append(self.extensions[self.cur_token_](self))\n            elif self.cur_token_ == \";\":\n                continue\n            else:\n                raise FeatureLibError(\n                    \"Expected glyph class definition or statement: got {} {}\".format(self.cur_token_type_, self.cur_token_),\n                    self.cur_token_location_)\n\n        self.expect_symbol_(\"}\")\n        for symtab in self.symbol_tables_:\n            symtab.exit_scope()\n\n    def collect_block_(self):\n        self.expect_symbol_(\"{\")\n        tokens = [(self.cur_token_type_, self.cur_token_)]\n        count = 1\n        while count > 0:\n            self.advance_lexer_()\n            if self.cur_token_ == \"{\":\n                count += 1\n            elif self.cur_token_ == \"}\":\n                count -= 1\n            tokens.append((self.cur_token_type_, self.cur_token_))\n        return tokens\n\n    def parseDoStatement_(self):\n        location = self.cur_token_location_\n        substatements = []\n        ifs = []\n        while True:\n            self.advance_lexer_()\n            if self.is_cur_keyword_(\"for\"):\n                substatements.append(self.parseDoFor_())\n            elif self.is_cur_keyword_(\"let\"):\n                substatements.append(self.parseDoLet_())\n            elif self.is_cur_keyword_(\"if\"):\n                ifs.append(self.parseDoIf_())\n            elif self.cur_token_ == '{':\n                self.back_lexer_()\n                ifs.append(self.parseEmptyIf_())\n                break\n            elif self.cur_token_type_ == Lexer.COMMENT:\n                continue\n            else:\n                self.back_lexer_()\n                break\n        res = self.ast.Block()\n        lex = self.lexer_.lexers_[-1]\n        for s in self.DoIterateValues_(substatements):\n            for i in ifs:\n                (_, v) = next(i.items(s))\n                if v:\n                    lex.scope = s\n                    #import pdb; pdb.set_trace()\n                    lex.pushstack(('tokens', i.block[:]))\n                    self.advance_lexer_()\n                    self.advance_lexer_()\n                    try:\n                        import inspect  # oh this is so ugly!\n                        calledby = inspect.stack()[2][3]  # called through lambda since extension\n                        if calledby == 'parse_block_':\n                            self.parse_subblock_(res, False)\n                        else:\n                            self.parse_statements_block_(res)\n                    except Exception as e:\n                        logging.warning(\"In do context: \" + str(s) + \" lexer: \" + repr(lex) + \" at: \" + str((self.cur_token_, self.next_token_)))\n                        raise\n        return res\n\n    def DoIterateValues_(self, substatements):\n        def updated(d, *a, **kw):\n            d.update(*a, **kw)\n            return d\n        results = [{}]\n        #import pdb; pdb.set_trace()\n        for s in substatements:\n            newresults = []\n            for x in results:\n                for r in s.items(x):\n                    c = x.copy()\n                    c.update(r)\n                    newresults.append(c)\n            results = newresults\n        for r in results:\n            yield r\n\n    def parseDoFor_(self):\n        location = self.cur_token_location_\n        self.advance_lexer_()\n        if self.cur_token_type_ is Lexer.NAME:\n            name = self.cur_token_\n        else:\n            raise FeatureLibError(\"Bad name in do for statement\", location)\n        self.expect_symbol_(\"=\")\n        glyphs = self.parse_glyphclass_(True)\n        self.expect_symbol_(\";\")\n        res = self.ast.DoForSubStatement(name, glyphs, location=location)\n        return res\n\n    def parseDoLet_(self):\n        # import pdb; pdb.set_trace()\n        location = self.cur_token_location_\n        self.advance_lexer_()\n        names = []\n        while self.cur_token_type_ == Lexer.NAME:\n            names.append(self.cur_token_)\n            if self.next_token_type_ is Lexer.SYMBOL:\n                if self.next_token_ == \",\":\n                    self.advance_lexer_()\n                elif self.next_token_ == \"=\":\n                    break\n            self.advance_lexer_()\n        else:\n            raise FeatureLibError(\"Expected '=', found '%s'\" % self.cur_token_,\n                                  self.cur_token_location_)\n        lex = self.lexer_.lexers_[-1]\n        lex.scan_over_(Lexer.CHAR_WHITESPACE_)\n        start = lex.pos_\n        lex.scan_until_(\";\")\n        expr = lex.text_[start:lex.pos_]\n        self.advance_lexer_()\n        self.expect_symbol_(\";\")\n        return self.ast.DoLetSubStatement(names, expr, self, location=location)\n\n    def parseDoIf_(self):\n        location = self.cur_token_location_\n        lex = self.lexer_.lexers_[-1]\n        start = lex.pos_\n        lex.scan_until_(\";\")\n        expr = self.next_token_ + \" \" + lex.text_[start:lex.pos_]\n        self.advance_lexer_()\n        self.expect_symbol_(\";\")\n        block = self.collect_block_()\n        keep = (self.next_token_type_, self.next_token_)\n        block = [keep] + block + [keep]\n        return self.ast.DoIfSubStatement(expr, self, block, location=location)\n\n    def parseEmptyIf_(self):\n        location = self.cur_token_location_\n        lex = self.lexer_.lexers_[-1]\n        start = lex.pos_\n        expr = \"True\"\n        block = self.collect_block_()\n        keep = (self.next_token_type_, self.next_token_)\n        block = [keep] + block + [keep]\n        return self.ast.DoIfSubStatement(expr, self, block, location=location)\n\n    def parseDefStatement_(self):\n        lex = self.lexer_.lexers_[-1]\n        start = lex.pos_\n        lex.scan_until_(\"{\")\n        fname = self.next_token_\n        fsig = fname + lex.text_[start:lex.pos_].strip()\n        tag = re.escape(fname)\n        _, content, location = lex.scan_anonymous_block(tag)\n        self.advance_lexer_()\n        start = lex.pos_\n        lex.scan_until_(\";\")\n        endtag = lex.text_[start:lex.pos_].strip()\n        assert(fname == endtag)\n        self.advance_lexer_()\n        self.advance_lexer_()\n        funcstr = \"def \" + fsig + \":\\n\" + content\n        if astx.safeeval(funcstr):\n            exec(funcstr, self.fns)\n        return self.ast.Comment(\"# def \" + fname)",
  "def __getattr__(self, name):\n        return getattr(ast, name)",
  "def __init__(self, filename, glyphmap, fontinfo, kerninfo, defines) :\n        if filename is None :\n            empty_file = io.StringIO(\"\")\n            super(feaplus_parser, self).__init__(empty_file, glyphmap)\n        else :\n            super(feaplus_parser, self).__init__(filename, glyphmap)\n        self.fontinfo = fontinfo\n        self.kerninfo = kerninfo\n        self.glyphs = glyphmap\n        self.defines = defines\n        self.fns = {\n            '__builtins__': None,\n            're' : re,\n            'math' : math,\n            'APx': lambda g, a, d=0: int(self.glyphs[g].anchors.get(a, [d])[0]),\n            'APy': lambda g, a, d=0: int(self.glyphs[g].anchors.get(a, [0,d])[1]),\n            'ADVx': lambda g: int(self.glyphs[g].advance),\n            'MINx': lambda g: int(self.glyphs[g].bbox[0]),\n            'MINy': lambda g: int(self.glyphs[g].bbox[1]),\n            'MAXx': lambda g: int(self.glyphs[g].bbox[2]),\n            'MAXy': lambda g: int(self.glyphs[g].bbox[3]),\n            'feaclass': lambda c: self.resolve_glyphclass(c).glyphSet(),\n            'allglyphs': lambda : self.glyphs.keys(),\n            'lf': lambda : \"\\n\",\n            'info': lambda s: self.fontinfo.get(s, \"\"),\n            'fileexists': lambda s: os.path.exists(s),\n            'kerninfo': lambda s:[(k1, k2, v) for k1, x in self.kerninfo.items() for k2, v in x.items()],\n            'opt': lambda s: self.defines.get(s, \"\")\n        }\n        # Document which builtins we really need. Of course still insecure.\n        for x in ('True', 'False', 'None', 'int', 'float', 'str', 'abs', 'all', 'any', 'bool',\n                    'dict', 'enumerate', 'filter', 'hasattr', 'hex', 'len', 'list', 'map', 'print',\n                    'max', 'min', 'ord', 'range', 'set', 'sorted', 'sum', 'tuple', 'zip'):\n            self.fns[x] = __builtins__[x]",
  "def parse(self, filename=None) :\n        if filename is not None :\n            self.lexer_ = feax_lexer.feax_IncludingLexer(filename)\n            self.advance_lexer_(comments=True)\n        return super(feaplus_parser, self).parse()",
  "def back_lexer_(self):\n        self.lexer_.lexers_[-1].pushback(self.next_token_type_, self.next_token_)\n        self.next_token_type_ = self.cur_token_type_\n        self.next_token_ = self.cur_token_\n        self.next_token_location_ = self.cur_token_location_",
  "def define_glyphclass(self, ap_nm, gc) :\n        self.glyphclasses_.define(ap_nm, gc)",
  "def resolve_glyphclass(self, ap_nm):\n        try:\n            return self.glyphclasses_.resolve(ap_nm)\n        except KeyError:\n            raise FeatureLibError(\"Glyphclass '{}' missing\".format(ap_nm), self.lexer_.location_())\n        return None",
  "def add_statement(self, val) :\n        self.doc_.statements.append(val)",
  "def set_baseclass(self, ap_nm) :\n        gc = self.ast.BaseClass(ap_nm)\n        if not hasattr(self.doc_, 'baseClasses') :\n            self.doc_.baseClasses = {}\n        self.doc_.baseClasses[ap_nm] = gc\n        self.define_glyphclass(ap_nm, gc)\n        return gc",
  "def set_markclass(self, ap_nm) :\n        gc = self.ast.MarkClass(ap_nm)\n        if not hasattr(self.doc_, 'markClasses') :\n            self.doc_.markClasses = {}\n        self.doc_.markClasses[ap_nm] = gc\n        self.define_glyphclass(ap_nm, gc)\n        return gc",
  "def parse_position_base_(self, enumerated, vertical):\n        location = self.cur_token_location_\n        self.expect_keyword_(\"base\")\n        if enumerated:\n            raise FeatureLibError(\n                '\"enumerate\" is not allowed with '\n                'mark-to-base attachment positioning',\n                location)\n        base = self.parse_glyphclass_(accept_glyphname=True)\n        if self.next_token_ == \"<\": # handle pos base [glyphs] <anchor> mark @MARKCLASS\n            marks = self.parse_anchor_marks_()\n        else: # handle pos base @BASECLASS mark @MARKCLASS; like base class parse_anchor_marks_\n            marks = []\n            while self.next_token_ == \"mark\": #TODO: is more than one 'mark' meaningful?\n                self.expect_keyword_(\"mark\")\n                m = self.expect_markClass_reference_()\n                marks.append(m)\n        self.expect_symbol_(\";\")\n        return self.ast.MarkBasePosStatement(base, marks, location=location)",
  "def parse_position_mark_(self, enumerated, vertical):\n        location = self.cur_token_location_\n        self.expect_keyword_(\"mark\")\n        if enumerated:\n            raise FeatureLibError(\n                '\"enumerate\" is not allowed with '\n                'mark-to-mark attachment positioning',\n                location)\n        baseMarks = self.parse_glyphclass_(accept_glyphname=True)\n        if self.next_token_ == \"<\": # handle pos mark [glyphs] <anchor> mark @MARKCLASS\n            marks = self.parse_anchor_marks_()\n        else: # handle pos mark @MARKCLASS mark @MARKCLASS; like base class parse_anchor_marks_\n            marks = []\n            while self.next_token_ == \"mark\": #TODO: is more than one 'mark' meaningful?\n                self.expect_keyword_(\"mark\")\n                m = self.expect_markClass_reference_()\n                marks.append(m)\n        self.expect_symbol_(\";\")\n        return self.ast.MarkMarkPosStatement(baseMarks, marks, location=location)",
  "def parse_position_cursive_(self, enumerated, vertical):\n        location = self.cur_token_location_\n        self.expect_keyword_(\"cursive\")\n        if enumerated:\n            raise FeatureLibError(\n                '\"enumerate\" is not allowed with '\n                'cursive attachment positioning',\n                location)\n        glyphclass = self.parse_glyphclass_(accept_glyphname=True)\n        if self.next_token_ == \"<\": # handle pos cursive @glyphClass <anchor entry> <anchor exit>\n            entryAnchor = self.parse_anchor_()\n            exitAnchor = self.parse_anchor_()\n            self.expect_symbol_(\";\")\n            return self.ast.CursivePosStatement(\n                glyphclass, entryAnchor, exitAnchor, location=location)\n        else: # handle pos cursive @baseClass @baseClass;\n            mc = self.expect_markClass_reference_()\n            return self.ast.CursivePosStatement(glyphclass.markClass, None, mc, location=location)",
  "def parse_position_ligature_(self, enumerated, vertical):\n        location = self.cur_token_location_\n        self.expect_keyword_(\"ligature\")\n        if enumerated:\n            raise FeatureLibError(\n                '\"enumerate\" is not allowed with '\n                'mark-to-ligature attachment positioning',\n                location)\n        ligatures = self.parse_glyphclass_(accept_glyphname=True)\n        marks = [self._parse_anchorclass_marks_()]\n        while self.next_token_ == \"ligComponent\":\n            self.expect_keyword_(\"ligComponent\")\n            marks.append(self._parse_anchorclass_marks_())\n        self.expect_symbol_(\";\")\n        return self.ast.MarkLigPosStatement(ligatures, marks, location=location)",
  "def _parse_anchorclass_marks_(self):\n        \"\"\"Parses a sequence of [<anchor> | @BASECLASS mark @MARKCLASS]*.\"\"\"\n        anchorMarks = []  # [(self.ast.Anchor, markClassName)*]\n        while True:\n            if self.next_token_ == \"<\":\n                anchor = self.parse_anchor_()\n            else:\n                anchor = self.parse_glyphclass_(accept_glyphname=False)\n            if anchor is not None:\n                self.expect_keyword_(\"mark\")\n                markClass = self.expect_markClass_reference_()\n                anchorMarks.append((anchor, markClass))\n            if self.next_token_ == \"ligComponent\" or self.next_token_ == \";\":\n                break\n        return anchorMarks",
  "def parseBaseClass(self):\n        if not hasattr(self.doc_, 'baseClasses'):\n            self.doc_.baseClasses = {}\n        location = self.cur_token_location_\n        glyphs = self.parse_glyphclass_(accept_glyphname=True)\n        anchor = self.parse_anchor_()\n        name = self.expect_class_name_()\n        self.expect_symbol_(\";\")\n        baseClass = self.doc_.baseClasses.get(name)\n        if baseClass is None:\n            baseClass = self.ast.BaseClass(name)\n            self.doc_.baseClasses[name] = baseClass\n            self.glyphclasses_.define(name, baseClass)\n        bcdef = self.ast.BaseClassDefinition(baseClass, anchor, glyphs, location=location)\n        baseClass.addDefinition(bcdef)\n        return bcdef",
  "def parse_substitute_(self):\n        assert self.cur_token_ in {\"substitute\", \"sub\", \"reversesub\", \"rsub\"}\n        location = self.cur_token_location_\n        reverse = self.cur_token_ in {\"reversesub\", \"rsub\"}\n        old_prefix, old, lookups, values, old_suffix, hasMarks = \\\n            self.parse_glyph_pattern_(vertical=False)\n        if any(values):\n            raise FeatureLibError(\n                \"Substitution statements cannot contain values\", location)\n        new = []\n        if self.next_token_ == \"by\":\n            keyword = self.expect_keyword_(\"by\")\n            while self.next_token_ != \";\":\n                gc = self.parse_glyphclass_(accept_glyphname=True)\n                new.append(gc)\n        elif self.next_token_ == \"from\":\n            keyword = self.expect_keyword_(\"from\")\n            new = [self.parse_glyphclass_(accept_glyphname=False)]\n        else:\n            keyword = None\n        self.expect_symbol_(\";\")\n        if len(new) == 0 and not any(lookups):\n            raise FeatureLibError(\n                'Expected \"by\", \"from\" or explicit lookup references',\n                self.cur_token_location_)\n\n        # GSUB lookup type 3: Alternate substitution.\n        # Format: \"substitute a from [a.1 a.2 a.3];\"\n        if keyword == \"from\":\n            if reverse:\n                raise FeatureLibError(\n                    'Reverse chaining substitutions do not support \"from\"',\n                    location)\n            # allow classes on lhs\n            if len(old) != 1:\n                raise FeatureLibError(\n                    'Expected single glyph or glyph class before \"from\"',\n                    location)\n            if len(new) != 1:\n                raise FeatureLibError(\n                    'Expected a single glyphclass after \"from\"',\n                    location)\n            if len(old[0].glyphSet()) == 0 or len(new[0].glyphSet()) % len(old[0].glyphSet()) != 0:\n                raise FeatureLibError(\n                    'The glyphclass after \"from\" must be a multiple of length of the glyphclass on before',\n                    location)\n            return self.ast.AlternateSubstStatement(\n                old_prefix, old[0], old_suffix, new[0], location=location)\n\n        num_lookups = len([l for l in lookups if l is not None])\n\n        # GSUB lookup type 1: Single substitution.\n        # Format A: \"substitute a by a.sc;\"\n        # Format B: \"substitute [one.fitted one.oldstyle] by one;\"\n        # Format C: \"substitute [a-d] by [A.sc-D.sc];\"\n        if (not reverse and len(old) == 1 and len(new) == 1 and\n                num_lookups == 0):\n            glyphs = list(old[0].glyphSet())\n            replacements = list(new[0].glyphSet())\n            if len(replacements) == 1:\n                replacements = replacements * len(glyphs)\n            if len(glyphs) != len(replacements):\n                raise FeatureLibError(\n                    'Expected a glyph class with %d elements after \"by\", '\n                    'but found a glyph class with %d elements' %\n                    (len(glyphs), len(replacements)), location)\n            return self.ast.SingleSubstStatement(\n                old, new,\n                old_prefix, old_suffix,\n                forceChain=hasMarks, location=location\n            )\n\n        # GSUB lookup type 2: Multiple substitution.\n        # Format: \"substitute f_f_i by f f i;\"\n        if (not reverse and\n                len(old) == 1 and len(new) > 1 and num_lookups == 0):\n            return self.ast.MultipleSubstStatement(old_prefix, old[0], old_suffix, new,\n                                                    hasMarks, location=location)\n\n        # GSUB lookup type 4: Ligature substitution.\n        # Format: \"substitute f f i by f_f_i;\"\n        if (not reverse and\n                len(old) > 1 and len(new) == 1 and num_lookups == 0):\n            return self.ast.LigatureSubstStatement(old_prefix, old, old_suffix, new[0],\n                                                    forceChain=hasMarks, location=location)\n\n        # GSUB lookup type 8: Reverse chaining substitution.\n        if reverse:\n            if len(old) != 1:\n                raise FeatureLibError(\n                    \"In reverse chaining single substitutions, \"\n                    \"only a single glyph or glyph class can be replaced\",\n                    location)\n            if len(new) != 1:\n                raise FeatureLibError(\n                    'In reverse chaining single substitutions, '\n                    'the replacement (after \"by\") must be a single glyph '\n                    'or glyph class', location)\n            if num_lookups != 0:\n                raise FeatureLibError(\n                    \"Reverse chaining substitutions cannot call named lookups\",\n                    location)\n            glyphs = sorted(list(old[0].glyphSet()))\n            replacements = sorted(list(new[0].glyphSet()))\n            if len(replacements) == 1:\n                replacements = replacements * len(glyphs)\n            if len(glyphs) != len(replacements):\n                raise FeatureLibError(\n                    'Expected a glyph class with %d elements after \"by\", '\n                    'but found a glyph class with %d elements' %\n                    (len(glyphs), len(replacements)), location)\n            return self.ast.ReverseChainSingleSubstStatement(\n                old_prefix, old_suffix, old, new, location=location)\n\n        # GSUB lookup type 6: Chaining contextual substitution.\n        assert len(new) == 0, new\n        rule = self.ast.ChainContextSubstStatement(\n            old_prefix, old, old_suffix, lookups, location=location)\n        return rule",
  "def parse_glyphclass_(self, accept_glyphname):\n        if (accept_glyphname and\n                self.next_token_type_ in (Lexer.NAME, Lexer.CID)):\n            glyph = self.expect_glyph_()\n            return self.ast.GlyphName(glyph, location=self.cur_token_location_)\n        if self.next_token_type_ is Lexer.GLYPHCLASS:\n            self.advance_lexer_()\n            gc = self.glyphclasses_.resolve(self.cur_token_)\n            if gc is None:\n                raise FeatureLibError(\n                    \"Unknown glyph class @%s\" % self.cur_token_,\n                    self.cur_token_location_)\n            if isinstance(gc, self.ast.MarkClass):\n                return self.ast.MarkClassName(gc, location=self.cur_token_location_)\n            else:\n                return self.ast.GlyphClassName(gc, location=self.cur_token_location_)\n\n        self.expect_symbol_(\"[\")\n        location = self.cur_token_location_\n        glyphs = self.ast.GlyphClass(location=location)\n        while self.next_token_ != \"]\":\n            if self.next_token_type_ is Lexer.NAME:\n                glyph = self.expect_glyph_()\n                location = self.cur_token_location_\n                if '-' in glyph and glyph not in self.glyphNames_:\n                    start, limit = self.split_glyph_range_(glyph, location)\n                    glyphs.add_range(\n                        start, limit,\n                        self.make_glyph_range_(location, start, limit))\n                elif self.next_token_ == \"-\":\n                    start = glyph\n                    self.expect_symbol_(\"-\")\n                    limit = self.expect_glyph_()\n                    glyphs.add_range(\n                        start, limit,\n                        self.make_glyph_range_(location, start, limit))\n                else:\n                    glyphs.append(glyph)\n            elif self.next_token_type_ is Lexer.CID:\n                glyph = self.expect_glyph_()\n                if self.next_token_ == \"-\":\n                    range_location = self.cur_token_location_\n                    range_start = self.cur_token_\n                    self.expect_symbol_(\"-\")\n                    range_end = self.expect_cid_()\n                    glyphs.add_cid_range(range_start, range_end,\n                                         self.make_cid_range_(range_location,\n                                                              range_start, range_end))\n                else:\n                    glyphs.append(\"cid%05d\" % self.cur_token_)\n            elif self.next_token_type_ is Lexer.GLYPHCLASS:\n                self.advance_lexer_()\n                gc = self.glyphclasses_.resolve(self.cur_token_)\n                if gc is None:\n                    raise FeatureLibError(\n                        \"Unknown glyph class @%s\" % self.cur_token_,\n                        self.cur_token_location_)\n                # fix bug don't output class definition, just the name.\n                if isinstance(gc, self.ast.MarkClass):\n                    gcn = self.ast.MarkClassName(gc, location=self.cur_token_location_)\n                else:\n                    gcn = self.ast.GlyphClassName(gc, location=self.cur_token_location_)\n                glyphs.add_class(gcn)\n            else:\n                raise FeatureLibError(\n                    \"Expected glyph name, glyph range, \"\n                    \"or glyph class reference. Found %s\" % self.next_token_,\n                    self.next_token_location_)\n        self.expect_symbol_(\"]\")\n        return glyphs",
  "def parseIfClass(self):\n        location = self.cur_token_location_\n        self.expect_symbol_(\"(\")\n        if self.next_token_type_ is Lexer.GLYPHCLASS:\n            self.advance_lexer_()\n            def ifClassTest():\n                gc = self.glyphclasses_.resolve(self.cur_token_)\n                return gc is not None and len(gc.glyphSet())\n            block = self.ast.IfBlock(ifClassTest, 'ifclass', '@'+self.cur_token_, location=location)\n            self.expect_symbol_(\")\")\n            import inspect      # oh this is so ugly!\n            calledby = inspect.stack()[2][3]    # called through lambda since extension\n            if calledby == 'parse_block_':\n                self.parse_subblock_(block, False)\n            else:\n                self.parse_statements_block_(block)\n            return block\n        else:\n            raise FeatureLibError(\"Syntax error missing glyphclass\", location)",
  "def parseIfInfo(self):\n        location = self.cur_token_location_\n        self.expect_symbol_(\"(\")\n        name = self.expect_name_()\n        self.expect_symbol_(\",\")\n        reg = self.expect_string_()\n        self.expect_symbol_(\")\")\n        def ifInfoTest():\n            s = self.fontinfo.get(name, \"\")\n            return re.search(reg, s)\n        block = self.ast.IfBlock(ifInfoTest, 'ifinfo', '{}, \"{}\"'.format(name, reg), location=location)\n        import inspect      # oh this is so ugly! Instead caller should pass in context\n        calledby = inspect.stack()[2][3]        # called through a lambda since extension\n        if calledby == 'parse_block_':\n            self.parse_subblock_(block, False)\n        else:\n            self.parse_statements_block_(block)\n        return block",
  "def parseKernPairsStatement_(self):\n        location = self.cur_token_location_\n        res = self.ast.KernPairsStatement(self.kerninfo, location)\n        return res",
  "def parse_statements_block_(self, block):\n        self.expect_symbol_(\"{\")\n        statements = block.statements\n        while self.next_token_ != \"}\" or self.cur_comments_:\n            self.advance_lexer_(comments=True)\n            if self.cur_token_type_ is Lexer.COMMENT:\n                statements.append(\n                    self.ast.Comment(self.cur_token_,\n                                     location=self.cur_token_location_))\n            elif self.is_cur_keyword_(\"include\"):\n                statements.append(self.parse_include_())\n            elif self.cur_token_type_ is Lexer.GLYPHCLASS:\n                statements.append(self.parse_glyphclass_definition_())\n            elif self.is_cur_keyword_((\"anon\", \"anonymous\")):\n                statements.append(self.parse_anonymous_())\n            elif self.is_cur_keyword_(\"anchorDef\"):\n                statements.append(self.parse_anchordef_())\n            elif self.is_cur_keyword_(\"languagesystem\"):\n                statements.append(self.parse_languagesystem_())\n            elif self.is_cur_keyword_(\"lookup\"):\n                statements.append(self.parse_lookup_(vertical=False))\n            elif self.is_cur_keyword_(\"markClass\"):\n                statements.append(self.parse_markClass_())\n            elif self.is_cur_keyword_(\"feature\"):\n                statements.append(self.parse_feature_block_())\n            elif self.is_cur_keyword_(\"table\"):\n                statements.append(self.parse_table_())\n            elif self.is_cur_keyword_(\"valueRecordDef\"):\n                statements.append(\n                    self.parse_valuerecord_definition_(vertical=False))\n            elif self.cur_token_type_ is Lexer.NAME and self.cur_token_ in self.extensions:\n                statements.append(self.extensions[self.cur_token_](self))\n            elif self.cur_token_type_ is Lexer.SYMBOL and self.cur_token_ == \";\":\n                continue\n            else:\n                raise FeatureLibError(\n                    \"Expected feature, languagesystem, lookup, markClass, \"\n                    \"table, or glyph class definition, got {} \\\"{}\\\"\".format(self.cur_token_type_, self.cur_token_),\n                    self.cur_token_location_)\n\n        self.expect_symbol_(\"}\")",
  "def parse_subblock_(self, block, vertical, stylisticset=False,\n                            size_feature=None, cv_feature=None):\n        self.expect_symbol_(\"{\")\n        for symtab in self.symbol_tables_:\n            symtab.enter_scope()\n\n        statements = block.statements\n        while self.next_token_ != \"}\" or self.cur_comments_:\n            self.advance_lexer_(comments=True)\n            if self.cur_token_type_ is Lexer.COMMENT:\n                statements.append(self.ast.Comment(\n                    self.cur_token_, location=self.cur_token_location_))\n            elif self.cur_token_type_ is Lexer.GLYPHCLASS:\n                statements.append(self.parse_glyphclass_definition_())\n            elif self.is_cur_keyword_(\"anchorDef\"):\n                statements.append(self.parse_anchordef_())\n            elif self.is_cur_keyword_({\"enum\", \"enumerate\"}):\n                statements.append(self.parse_enumerate_(vertical=vertical))\n            elif self.is_cur_keyword_(\"feature\"):\n                statements.append(self.parse_feature_reference_())\n            elif self.is_cur_keyword_(\"ignore\"):\n                statements.append(self.parse_ignore_())\n            elif self.is_cur_keyword_(\"language\"):\n                statements.append(self.parse_language_())\n            elif self.is_cur_keyword_(\"lookup\"):\n                statements.append(self.parse_lookup_(vertical))\n            elif self.is_cur_keyword_(\"lookupflag\"):\n                statements.append(self.parse_lookupflag_())\n            elif self.is_cur_keyword_(\"markClass\"):\n                statements.append(self.parse_markClass_())\n            elif self.is_cur_keyword_({\"pos\", \"position\"}):\n                statements.append(\n                    self.parse_position_(enumerated=False, vertical=vertical))\n            elif self.is_cur_keyword_(\"script\"):\n                statements.append(self.parse_script_())\n            elif (self.is_cur_keyword_({\"sub\", \"substitute\",\n                                        \"rsub\", \"reversesub\"})):\n                statements.append(self.parse_substitute_())\n            elif self.is_cur_keyword_(\"subtable\"):\n                statements.append(self.parse_subtable_())\n            elif self.is_cur_keyword_(\"valueRecordDef\"):\n                statements.append(self.parse_valuerecord_definition_(vertical))\n            elif stylisticset and self.is_cur_keyword_(\"featureNames\"):\n                statements.append(self.parse_featureNames_(stylisticset))\n            elif cv_feature and self.is_cur_keyword_(\"cvParameters\"):\n                statements.append(self.parse_cvParameters_(cv_feature))\n            elif size_feature and self.is_cur_keyword_(\"parameters\"):\n                statements.append(self.parse_size_parameters_())\n            elif size_feature and self.is_cur_keyword_(\"sizemenuname\"):\n                statements.append(self.parse_size_menuname_())\n            elif self.cur_token_type_ is Lexer.NAME and self.cur_token_ in self.extensions:\n                statements.append(self.extensions[self.cur_token_](self))\n            elif self.cur_token_ == \";\":\n                continue\n            else:\n                raise FeatureLibError(\n                    \"Expected glyph class definition or statement: got {} {}\".format(self.cur_token_type_, self.cur_token_),\n                    self.cur_token_location_)\n\n        self.expect_symbol_(\"}\")\n        for symtab in self.symbol_tables_:\n            symtab.exit_scope()",
  "def collect_block_(self):\n        self.expect_symbol_(\"{\")\n        tokens = [(self.cur_token_type_, self.cur_token_)]\n        count = 1\n        while count > 0:\n            self.advance_lexer_()\n            if self.cur_token_ == \"{\":\n                count += 1\n            elif self.cur_token_ == \"}\":\n                count -= 1\n            tokens.append((self.cur_token_type_, self.cur_token_))\n        return tokens",
  "def parseDoStatement_(self):\n        location = self.cur_token_location_\n        substatements = []\n        ifs = []\n        while True:\n            self.advance_lexer_()\n            if self.is_cur_keyword_(\"for\"):\n                substatements.append(self.parseDoFor_())\n            elif self.is_cur_keyword_(\"let\"):\n                substatements.append(self.parseDoLet_())\n            elif self.is_cur_keyword_(\"if\"):\n                ifs.append(self.parseDoIf_())\n            elif self.cur_token_ == '{':\n                self.back_lexer_()\n                ifs.append(self.parseEmptyIf_())\n                break\n            elif self.cur_token_type_ == Lexer.COMMENT:\n                continue\n            else:\n                self.back_lexer_()\n                break\n        res = self.ast.Block()\n        lex = self.lexer_.lexers_[-1]\n        for s in self.DoIterateValues_(substatements):\n            for i in ifs:\n                (_, v) = next(i.items(s))\n                if v:\n                    lex.scope = s\n                    #import pdb; pdb.set_trace()\n                    lex.pushstack(('tokens', i.block[:]))\n                    self.advance_lexer_()\n                    self.advance_lexer_()\n                    try:\n                        import inspect  # oh this is so ugly!\n                        calledby = inspect.stack()[2][3]  # called through lambda since extension\n                        if calledby == 'parse_block_':\n                            self.parse_subblock_(res, False)\n                        else:\n                            self.parse_statements_block_(res)\n                    except Exception as e:\n                        logging.warning(\"In do context: \" + str(s) + \" lexer: \" + repr(lex) + \" at: \" + str((self.cur_token_, self.next_token_)))\n                        raise\n        return res",
  "def DoIterateValues_(self, substatements):\n        def updated(d, *a, **kw):\n            d.update(*a, **kw)\n            return d\n        results = [{}]\n        #import pdb; pdb.set_trace()\n        for s in substatements:\n            newresults = []\n            for x in results:\n                for r in s.items(x):\n                    c = x.copy()\n                    c.update(r)\n                    newresults.append(c)\n            results = newresults\n        for r in results:\n            yield r",
  "def parseDoFor_(self):\n        location = self.cur_token_location_\n        self.advance_lexer_()\n        if self.cur_token_type_ is Lexer.NAME:\n            name = self.cur_token_\n        else:\n            raise FeatureLibError(\"Bad name in do for statement\", location)\n        self.expect_symbol_(\"=\")\n        glyphs = self.parse_glyphclass_(True)\n        self.expect_symbol_(\";\")\n        res = self.ast.DoForSubStatement(name, glyphs, location=location)\n        return res",
  "def parseDoLet_(self):\n        # import pdb; pdb.set_trace()\n        location = self.cur_token_location_\n        self.advance_lexer_()\n        names = []\n        while self.cur_token_type_ == Lexer.NAME:\n            names.append(self.cur_token_)\n            if self.next_token_type_ is Lexer.SYMBOL:\n                if self.next_token_ == \",\":\n                    self.advance_lexer_()\n                elif self.next_token_ == \"=\":\n                    break\n            self.advance_lexer_()\n        else:\n            raise FeatureLibError(\"Expected '=', found '%s'\" % self.cur_token_,\n                                  self.cur_token_location_)\n        lex = self.lexer_.lexers_[-1]\n        lex.scan_over_(Lexer.CHAR_WHITESPACE_)\n        start = lex.pos_\n        lex.scan_until_(\";\")\n        expr = lex.text_[start:lex.pos_]\n        self.advance_lexer_()\n        self.expect_symbol_(\";\")\n        return self.ast.DoLetSubStatement(names, expr, self, location=location)",
  "def parseDoIf_(self):\n        location = self.cur_token_location_\n        lex = self.lexer_.lexers_[-1]\n        start = lex.pos_\n        lex.scan_until_(\";\")\n        expr = self.next_token_ + \" \" + lex.text_[start:lex.pos_]\n        self.advance_lexer_()\n        self.expect_symbol_(\";\")\n        block = self.collect_block_()\n        keep = (self.next_token_type_, self.next_token_)\n        block = [keep] + block + [keep]\n        return self.ast.DoIfSubStatement(expr, self, block, location=location)",
  "def parseEmptyIf_(self):\n        location = self.cur_token_location_\n        lex = self.lexer_.lexers_[-1]\n        start = lex.pos_\n        expr = \"True\"\n        block = self.collect_block_()\n        keep = (self.next_token_type_, self.next_token_)\n        block = [keep] + block + [keep]\n        return self.ast.DoIfSubStatement(expr, self, block, location=location)",
  "def parseDefStatement_(self):\n        lex = self.lexer_.lexers_[-1]\n        start = lex.pos_\n        lex.scan_until_(\"{\")\n        fname = self.next_token_\n        fsig = fname + lex.text_[start:lex.pos_].strip()\n        tag = re.escape(fname)\n        _, content, location = lex.scan_anonymous_block(tag)\n        self.advance_lexer_()\n        start = lex.pos_\n        lex.scan_until_(\";\")\n        endtag = lex.text_[start:lex.pos_].strip()\n        assert(fname == endtag)\n        self.advance_lexer_()\n        self.advance_lexer_()\n        funcstr = \"def \" + fsig + \":\\n\" + content\n        if astx.safeeval(funcstr):\n            exec(funcstr, self.fns)\n        return self.ast.Comment(\"# def \" + fname)",
  "def ifInfoTest():\n            s = self.fontinfo.get(name, \"\")\n            return re.search(reg, s)",
  "def updated(d, *a, **kw):\n            d.update(*a, **kw)\n            return d",
  "def ifClassTest():\n                gc = self.glyphclasses_.resolve(self.cur_token_)\n                return gc is not None and len(gc.glyphSet())",
  "class ETWriter(object) :\n    \"\"\" General purpose ElementTree pretty printer complete with options for attribute order\n        beyond simple sorting, and which elements should use cdata\n\n        Note there is no support for namespaces.  Originally there was, and if it is needed in the future look at\n        commits from 10th May 2018 or earlier.  The code there would need reworking!\"\"\"\n\n    def __init__(self, etree, attributeOrder = {}, takesCData = set(),\n            indentIncr = \"  \", indentFirst = \"  \", indentML = False, inlineelem=[], precision = None, floatAttribs = [], intAttribs = []):\n        self.root = etree\n        self.attributeOrder = attributeOrder    # Sort order for attributes - just one list for all elements\n        self.takesCData = takesCData\n        self.indentIncr = indentIncr            # Incremental increase in indent\n        self.indentFirst = indentFirst          # Indent for first level\n        self.indentML = indentML                # Add indent to multi-line strings\n        self.inlineelem = inlineelem            # For supporting in-line elements.  Does not work with mix of inline and other subelements in same element\n        self.precision = precision              # Precision to use outputting numeric attribute values\n        self.floatAttribs = floatAttribs        # List of float/real attributes used with precision\n        self.intAttribs = intAttribs\n\n    def _protect(self, txt, base=_attribprotect) :\n        return re.sub(r'['+r\"\".join(base.keys())+r\"]\", lambda m: base[m.group(0)], txt)\n\n    def serialize_xml(self, base = None, indent = '') :\n        # Create the xml and return as a string\n        outstrings = []\n        outstr=\"\"\n        if base is None :\n            base = self.root\n            outstr += '<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n'\n            if '.pi' in base.attrib : # Processing instructions\n                for pi in base.attrib['.pi'].split(\",\") : outstr += '<?{}?>\\n'.format(pi)\n\n            if '.doctype' in base.attrib : outstr += '<!DOCTYPE {}>\\n'.format(base.attrib['.doctype'])\n\n        tag = base.tag\n        attribs = base.attrib\n\n        if '.comments' in attribs :\n            for c in attribs['.comments'].split(\",\") : outstr += '{}<!--{}-->\\n'.format(indent, c)\n\n        i = indent if tag not in self.inlineelem else \"\"\n        outstr += '{}<{}'.format(i, tag)\n\n        for k in sorted(list(attribs.keys()), key=lambda x: self.attributeOrder.get(x, x)):\n            if k[0] != '.' :\n                att = attribs[k]\n                if self.precision is not None and k in self.floatAttribs :\n                    if \".\" in att:\n                        num = round(float(att), self.precision)\n                        att = int(num) if num == int(num) else num\n                elif k in self.intAttribs :\n                        att = int(round(float(att)))\n                else:\n                    att = self._protect(att)\n                outstr += ' {}=\"{}\"'.format(k, att)\n\n        if len(base) or (base.text and base.text.strip()) :\n            outstr += '>'\n            if base.text and base.text.strip() :\n                if tag not in self.takesCData :\n                    t = base.text\n                    if self.indentML : t = t.replace('\\n', '\\n' + indent)\n                    t = self._protect(t, base=_elementprotect)\n                else :\n                    t = \"<![CDATA[\\n\\t\" + indent + base.text.replace('\\n', '\\n\\t' + indent) + \"\\n\" + indent + \"]]>\"\n                outstr += t\n            if len(base) :\n                if base[0].tag not in self.inlineelem : outstr += '\\n'\n                if base == self.root:\n                    incr = self.indentFirst\n                else:\n                    incr = self.indentIncr\n                outstrings.append(outstr); outstr=\"\"\n                for b in base : outstrings.append(self.serialize_xml(base=b, indent=indent + incr))\n                if base[-1].tag not in self.inlineelem : outstr += indent\n            outstr += '</{}>'.format(tag)\n        else :\n            outstr += '/>'\n        if base.tail and base.tail.strip() :\n            outstr += self._protect(base.tail, base=_elementprotect)\n        if tag not in self.inlineelem : outstr += \"\\n\"\n\n        if '.commentsafter' in base.attrib :\n            for c in base.attrib['.commentsafter'].split(\",\") : outstr += '{}<!--{}-->\\n'.format(indent, c)\n\n        outstrings.append(outstr)\n        return \"\".join(outstrings)",
  "class _container(object) :\n    # Parent class for other objects\n    def __init_(self) :\n        self._contents = {}\n    # Define methods so it acts like an imutable container\n    # (changes should be made via object functions etc)\n    def __len__(self):\n        return len(self._contents)\n    def __getitem__(self, key):\n        return self._contents[key]\n    def __iter__(self):\n        return iter(self._contents)\n    def keys(self) :\n        return self._contents.keys()",
  "class xmlitem(_container):\n    \"\"\" The xml data item for an xml file\"\"\"\n\n    def __init__(self, dirn = None, filen = None, parse = True, logger=None) :\n        self.logger = logger if logger else silfont.core.loggerobj()\n        self._contents = {}\n        self.dirn = dirn\n        self.filen = filen\n        self.inxmlstr = \"\"\n        self.outxmlstr = \"\"\n        self.etree = None\n        self.type = None\n        if filen and dirn :\n            fulln = os.path.join( dirn, filen)\n            self.inxmlstr = io.open(fulln, \"rt\", encoding=\"utf-8\").read()\n            if parse :\n                try:\n                    self.etree = ET.fromstring(self.inxmlstr)\n                except:\n                    try:\n                        self.etree = ET.fromstring(self.inxmlstr.encode(\"utf-8\"))\n                    except Exception as e:\n                        self.logger.log(\"Failed to parse xml for \" + fulln, \"E\")\n                        self.logger.log(str(e), \"S\")\n\n    def write_to_file(self,dirn,filen) :\n        outfile = io.open(os.path.join(dirn,filen),'w', encoding=\"utf-8\")\n        outfile.write(self.outxmlstr)",
  "class ETelement(_container):\n    # Class for an etree element. Mainly used as a parent class\n    # For each tag in the element, ETelement[tag] returns a list of sub-elements with that tag\n    # process_subelements can set attributes for each tag based on a supplied spec\n    def __init__(self,element) :\n        self.element = element\n        self._contents = {}\n        self.reindex()\n\n    def reindex(self) :\n        self._contents = collections.defaultdict(list)\n        for e in self.element :\n            self._contents[e.tag].append(e)\n\n    def remove(self,subelement) :\n        self._contents[subelement.tag].remove(subelement)\n        self.element.remove(subelement)\n\n    def append(self,subelement) :\n        self._contents[subelement.tag].append(subelement)\n        self.element.append(subelement)\n\n    def insert(self,index,subelement) :\n        self._contents[subelement.tag].insert(index,subelement)\n        self.element.insert(index,subelement)\n\n    def replace(self,index,subelement) :\n        self._contents[subelement.tag][index] = subelement\n        self.element[index] = subelement\n\n    def process_attributes(self, attrspec, others = False) :\n        # Process attributes based on list of attributes in the format:\n        #   (element attr name, object attr name, required)\n        # If attr does not exist and is not required, set to None\n        # If others is True, attributes not in the list are allowed\n        # Attributes should be listed in the order they should be output if writing xml out\n\n        if not hasattr(self,\"parseerrors\") or self.parseerrors is None: self.parseerrors=[]\n\n        speclist = {}\n        for (i,spec) in enumerate(attrspec) : speclist[spec[0]] = attrspec[i]\n\n        for eaname in speclist :\n            (eaname,oaname,req) = speclist[eaname]\n            setattr(self, oaname, getattrib(self.element,eaname))\n            if req and getattr(self, oaname) is None : self.parseerrors.append(\"Required attribute \" + eaname + \" missing\")\n\n        # check for any other attributes\n        for att in self.element.attrib :\n            if att not in speclist :\n                if others:\n                    setattr(self, att, getattrib(self.element,att))\n                else :\n                    self.parseerrors.append(\"Invalid attribute \" + att)\n\n    def process_subelements(self,subspec, offspec = False) :\n        # Process all subelements based on spec of expected elements\n        # subspec is a list of elements, with each list in the format:\n        #    (element name, attribute name, class name, required, multiple valeus allowed)\n        # If cl is set, attribute is set to an object made with that class; otherwise just text of the element\n\n        if not hasattr(self,\"parseerrors\")  or self.parseerrors is None : self.parseerrors=[]\n\n        def make_obj(self,cl,element) : # Create object from element and cascade parse errors down\n            if cl is None : return element.text\n            if cl is ETelement :\n                obj = cl(element) # ETelement does not require parent object, ie self\n            else :\n                obj = cl(self,element)\n            if hasattr(obj,\"parseerrors\") and obj.parseerrors != [] :\n                if hasattr(obj,\"name\") and obj.name is not None : # Try to find a name for error reporting\n                    name = obj.name\n                elif hasattr(obj,\"label\") and obj.label is not None  :\n                    name = obj.label\n                else :\n                    name = \"\"\n\n                self.parseerrors.append(\"Errors parsing \" + element.tag + \" element: \" + name)\n                for error in obj.parseerrors :\n                    self.parseerrors.append(\"  \" + error)\n            return obj\n\n        speclist = {}\n        for (i,spec) in enumerate(subspec) : speclist[spec[0]] = subspec[i]\n\n        for ename in speclist :\n            (ename,aname,cl,req,multi) = speclist[ename]\n            initval = [] if multi else None\n            setattr(self,aname,initval)\n\n        for ename in self : # Process all elements\n            if ename in speclist :\n                (ename,aname,cl,req,multi) = speclist[ename]\n                elements = self[ename]\n                if multi :\n                    for elem in elements : getattr(self,aname).append(make_obj(self,cl,elem))\n                else :\n                    setattr(self,aname,make_obj(self,cl,elements[0]))\n                    if len(elements) > 1 : self.parseerrors.append(\"Multiple \" + ename + \" elements not allowed\")\n            else:\n                if offspec: # Elements not in spec are allowed so create list of sub-elemente.\n                    setattr(self,ename,[])\n                    for elem in elements : getattr(self,ename).append(ETelement(elem))\n                else :\n                    self.parseerrors.append(\"Invalid element: \" + ename)\n\n        for ename in speclist : # Check values exist for required elements etc\n            (ename,aname,cl,req,multi) = speclist[ename]\n\n            val = getattr(self,aname)\n            if req :\n                if multi and val == [] : self.parseerrors.append(\"No \" + ename + \" elements \")\n                if not multi and val == None : self.parseerrors.append(\"No \" + ename + \" element\")",
  "def makeAttribOrder(attriblist) : # Turn a list of attrib names into an attributeOrder dict for ETWriter\n        return dict(map(lambda x:(x[1], x[0]), enumerate(attriblist)))",
  "def getattrib(element,attrib) : return element.attrib[attrib] if attrib in element.attrib else None",
  "def __init__(self, etree, attributeOrder = {}, takesCData = set(),\n            indentIncr = \"  \", indentFirst = \"  \", indentML = False, inlineelem=[], precision = None, floatAttribs = [], intAttribs = []):\n        self.root = etree\n        self.attributeOrder = attributeOrder    # Sort order for attributes - just one list for all elements\n        self.takesCData = takesCData\n        self.indentIncr = indentIncr            # Incremental increase in indent\n        self.indentFirst = indentFirst          # Indent for first level\n        self.indentML = indentML                # Add indent to multi-line strings\n        self.inlineelem = inlineelem            # For supporting in-line elements.  Does not work with mix of inline and other subelements in same element\n        self.precision = precision              # Precision to use outputting numeric attribute values\n        self.floatAttribs = floatAttribs        # List of float/real attributes used with precision\n        self.intAttribs = intAttribs",
  "def _protect(self, txt, base=_attribprotect) :\n        return re.sub(r'['+r\"\".join(base.keys())+r\"]\", lambda m: base[m.group(0)], txt)",
  "def serialize_xml(self, base = None, indent = '') :\n        # Create the xml and return as a string\n        outstrings = []\n        outstr=\"\"\n        if base is None :\n            base = self.root\n            outstr += '<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n'\n            if '.pi' in base.attrib : # Processing instructions\n                for pi in base.attrib['.pi'].split(\",\") : outstr += '<?{}?>\\n'.format(pi)\n\n            if '.doctype' in base.attrib : outstr += '<!DOCTYPE {}>\\n'.format(base.attrib['.doctype'])\n\n        tag = base.tag\n        attribs = base.attrib\n\n        if '.comments' in attribs :\n            for c in attribs['.comments'].split(\",\") : outstr += '{}<!--{}-->\\n'.format(indent, c)\n\n        i = indent if tag not in self.inlineelem else \"\"\n        outstr += '{}<{}'.format(i, tag)\n\n        for k in sorted(list(attribs.keys()), key=lambda x: self.attributeOrder.get(x, x)):\n            if k[0] != '.' :\n                att = attribs[k]\n                if self.precision is not None and k in self.floatAttribs :\n                    if \".\" in att:\n                        num = round(float(att), self.precision)\n                        att = int(num) if num == int(num) else num\n                elif k in self.intAttribs :\n                        att = int(round(float(att)))\n                else:\n                    att = self._protect(att)\n                outstr += ' {}=\"{}\"'.format(k, att)\n\n        if len(base) or (base.text and base.text.strip()) :\n            outstr += '>'\n            if base.text and base.text.strip() :\n                if tag not in self.takesCData :\n                    t = base.text\n                    if self.indentML : t = t.replace('\\n', '\\n' + indent)\n                    t = self._protect(t, base=_elementprotect)\n                else :\n                    t = \"<![CDATA[\\n\\t\" + indent + base.text.replace('\\n', '\\n\\t' + indent) + \"\\n\" + indent + \"]]>\"\n                outstr += t\n            if len(base) :\n                if base[0].tag not in self.inlineelem : outstr += '\\n'\n                if base == self.root:\n                    incr = self.indentFirst\n                else:\n                    incr = self.indentIncr\n                outstrings.append(outstr); outstr=\"\"\n                for b in base : outstrings.append(self.serialize_xml(base=b, indent=indent + incr))\n                if base[-1].tag not in self.inlineelem : outstr += indent\n            outstr += '</{}>'.format(tag)\n        else :\n            outstr += '/>'\n        if base.tail and base.tail.strip() :\n            outstr += self._protect(base.tail, base=_elementprotect)\n        if tag not in self.inlineelem : outstr += \"\\n\"\n\n        if '.commentsafter' in base.attrib :\n            for c in base.attrib['.commentsafter'].split(\",\") : outstr += '{}<!--{}-->\\n'.format(indent, c)\n\n        outstrings.append(outstr)\n        return \"\".join(outstrings)",
  "def __init_(self) :\n        self._contents = {}",
  "def __len__(self):\n        return len(self._contents)",
  "def __getitem__(self, key):\n        return self._contents[key]",
  "def __iter__(self):\n        return iter(self._contents)",
  "def keys(self) :\n        return self._contents.keys()",
  "def __init__(self, dirn = None, filen = None, parse = True, logger=None) :\n        self.logger = logger if logger else silfont.core.loggerobj()\n        self._contents = {}\n        self.dirn = dirn\n        self.filen = filen\n        self.inxmlstr = \"\"\n        self.outxmlstr = \"\"\n        self.etree = None\n        self.type = None\n        if filen and dirn :\n            fulln = os.path.join( dirn, filen)\n            self.inxmlstr = io.open(fulln, \"rt\", encoding=\"utf-8\").read()\n            if parse :\n                try:\n                    self.etree = ET.fromstring(self.inxmlstr)\n                except:\n                    try:\n                        self.etree = ET.fromstring(self.inxmlstr.encode(\"utf-8\"))\n                    except Exception as e:\n                        self.logger.log(\"Failed to parse xml for \" + fulln, \"E\")\n                        self.logger.log(str(e), \"S\")",
  "def write_to_file(self,dirn,filen) :\n        outfile = io.open(os.path.join(dirn,filen),'w', encoding=\"utf-8\")\n        outfile.write(self.outxmlstr)",
  "def __init__(self,element) :\n        self.element = element\n        self._contents = {}\n        self.reindex()",
  "def reindex(self) :\n        self._contents = collections.defaultdict(list)\n        for e in self.element :\n            self._contents[e.tag].append(e)",
  "def remove(self,subelement) :\n        self._contents[subelement.tag].remove(subelement)\n        self.element.remove(subelement)",
  "def append(self,subelement) :\n        self._contents[subelement.tag].append(subelement)\n        self.element.append(subelement)",
  "def insert(self,index,subelement) :\n        self._contents[subelement.tag].insert(index,subelement)\n        self.element.insert(index,subelement)",
  "def replace(self,index,subelement) :\n        self._contents[subelement.tag][index] = subelement\n        self.element[index] = subelement",
  "def process_attributes(self, attrspec, others = False) :\n        # Process attributes based on list of attributes in the format:\n        #   (element attr name, object attr name, required)\n        # If attr does not exist and is not required, set to None\n        # If others is True, attributes not in the list are allowed\n        # Attributes should be listed in the order they should be output if writing xml out\n\n        if not hasattr(self,\"parseerrors\") or self.parseerrors is None: self.parseerrors=[]\n\n        speclist = {}\n        for (i,spec) in enumerate(attrspec) : speclist[spec[0]] = attrspec[i]\n\n        for eaname in speclist :\n            (eaname,oaname,req) = speclist[eaname]\n            setattr(self, oaname, getattrib(self.element,eaname))\n            if req and getattr(self, oaname) is None : self.parseerrors.append(\"Required attribute \" + eaname + \" missing\")\n\n        # check for any other attributes\n        for att in self.element.attrib :\n            if att not in speclist :\n                if others:\n                    setattr(self, att, getattrib(self.element,att))\n                else :\n                    self.parseerrors.append(\"Invalid attribute \" + att)",
  "def process_subelements(self,subspec, offspec = False) :\n        # Process all subelements based on spec of expected elements\n        # subspec is a list of elements, with each list in the format:\n        #    (element name, attribute name, class name, required, multiple valeus allowed)\n        # If cl is set, attribute is set to an object made with that class; otherwise just text of the element\n\n        if not hasattr(self,\"parseerrors\")  or self.parseerrors is None : self.parseerrors=[]\n\n        def make_obj(self,cl,element) : # Create object from element and cascade parse errors down\n            if cl is None : return element.text\n            if cl is ETelement :\n                obj = cl(element) # ETelement does not require parent object, ie self\n            else :\n                obj = cl(self,element)\n            if hasattr(obj,\"parseerrors\") and obj.parseerrors != [] :\n                if hasattr(obj,\"name\") and obj.name is not None : # Try to find a name for error reporting\n                    name = obj.name\n                elif hasattr(obj,\"label\") and obj.label is not None  :\n                    name = obj.label\n                else :\n                    name = \"\"\n\n                self.parseerrors.append(\"Errors parsing \" + element.tag + \" element: \" + name)\n                for error in obj.parseerrors :\n                    self.parseerrors.append(\"  \" + error)\n            return obj\n\n        speclist = {}\n        for (i,spec) in enumerate(subspec) : speclist[spec[0]] = subspec[i]\n\n        for ename in speclist :\n            (ename,aname,cl,req,multi) = speclist[ename]\n            initval = [] if multi else None\n            setattr(self,aname,initval)\n\n        for ename in self : # Process all elements\n            if ename in speclist :\n                (ename,aname,cl,req,multi) = speclist[ename]\n                elements = self[ename]\n                if multi :\n                    for elem in elements : getattr(self,aname).append(make_obj(self,cl,elem))\n                else :\n                    setattr(self,aname,make_obj(self,cl,elements[0]))\n                    if len(elements) > 1 : self.parseerrors.append(\"Multiple \" + ename + \" elements not allowed\")\n            else:\n                if offspec: # Elements not in spec are allowed so create list of sub-elemente.\n                    setattr(self,ename,[])\n                    for elem in elements : getattr(self,ename).append(ETelement(elem))\n                else :\n                    self.parseerrors.append(\"Invalid element: \" + ename)\n\n        for ename in speclist : # Check values exist for required elements etc\n            (ename,aname,cl,req,multi) = speclist[ename]\n\n            val = getattr(self,aname)\n            if req :\n                if multi and val == [] : self.parseerrors.append(\"No \" + ename + \" elements \")\n                if not multi and val == None : self.parseerrors.append(\"No \" + ename + \" element\")",
  "def make_obj(self,cl,element) : # Create object from element and cascade parse errors down\n            if cl is None : return element.text\n            if cl is ETelement :\n                obj = cl(element) # ETelement does not require parent object, ie self\n            else :\n                obj = cl(self,element)\n            if hasattr(obj,\"parseerrors\") and obj.parseerrors != [] :\n                if hasattr(obj,\"name\") and obj.name is not None : # Try to find a name for error reporting\n                    name = obj.name\n                elif hasattr(obj,\"label\") and obj.label is not None  :\n                    name = obj.label\n                else :\n                    name = \"\"\n\n                self.parseerrors.append(\"Errors parsing \" + element.tag + \" element: \" + name)\n                for error in obj.parseerrors :\n                    self.parseerrors.append(\"  \" + error)\n            return obj",
  "class _familydata(object):\n    \"\"\"Family data key for use with families.json, font manifests and base files\n    \"\"\"\n    def __init__(self, id=None, data=None, filename = None, type=\"f\", logger=None):\n        # Initial input can be a dictionary (data) in which case id nneds to be set\n        # or it can be read from a file (containing just one family record), in which case id is taken from the file\n        # Type can be f, b or m for families, base or manifest\n        # With f, this would be for just a single entry from a families.json file\n        self.id = id\n        self.data = data if data else {}\n        self.filename = filename\n        self.type = type\n        self.logger = logger if logger else loggerobj()\n\n    def fieldscheck(self, data, validfields, reqfields, logprefix, valid, logs):\n        for key in data: # Check all keys have valid names\n            if key not in validfields:\n                logs.append((f'{logprefix}: Invalid field \"{key}\"', 'W'))\n                valid = False\n                continue\n        # Are required fields present\n        for key in reqfields:\n            if key not in data:\n                logs.append((f'{logprefix}: Required field \"{key}\" missing', 'W'))\n                valid = False\n                continue\n        return (valid, logs)\n\n    def validate(self):\n        global familyfields, filefields, defaultsfields\n        logs = []\n        valid = True\n        if self.type == \"m\":\n            validfields = reqfields = [key for key in familyfields if familyfields[key][\"manifest\"]]\n        else:\n            validfields = list(familyfields)\n            reqfields = [key for key in familyfields if not familyfields[key][\"opt\"]]\n        if self.type == \"f\":\n            reqfields = reqfields + [\"familyid\"]\n        else:  # Must be b\n            validfields = validfields + [\"hosturl\", \"filesroot\"]\n\n        (valid, logs) = self.fieldscheck(self.data, validfields, reqfields, \"Main\", valid, logs)\n        # Now check sub-fields\n        if \"files\" in self.data:\n            fdata = self.data[\"files\"]\n            if self.type == \"m\":\n                validfields = [key for key in filefields if filefields[key][\"manifest\"]]\n                reqfields = [key for key in filefields if filefields[key][\"manifest\"] and not (\"mopt\" in filefields[key] and filefields[key][\"mopt\"])]\n            else:\n                validfields = list(filefields)\n                reqfields = [key for key in filefields if not filefields[key][\"opt\"]]\n            # Now need to check values for each record in files\n            for filen in fdata:\n                frecord = fdata[filen]\n                (valid, logs) = self.fieldscheck(frecord, validfields, reqfields, \"Files: \" + filen, valid, logs)\n                if \"axes\" in frecord: # (Will already have been reported above if axes is missing!)\n                    adata = frecord[\"axes\"]\n                    avalidfields = [key for key in adata if len(key) == 4]\n                    areqfields = [\"wght\", \"ital\"] if self.type == \"m\" else []\n                    (valid, logs) = self.fieldscheck(adata, avalidfields, areqfields, \"Files, axes: \" + filen, valid, logs)\n        if \"defaults\" in self.data:\n            ddata = self.data[\"defaults\"]\n            if self.type == \"m\":\n                validfields = [key for key in defaultsfields if defaultsfields[key][\"manifest\"]]\n                reqfields = [key for key in defaultsfields if defaultsfields[key][\"manifest\"] and not (\"mopt\" in defaultsfields[key] and defaultsfields[key][\"mopt\"])]\n            else:\n                validfields = list(defaultsfields)\n                reqfields = [key for key in defaultsfields if not defaultsfields[key][\"opt\"]]\n            (valid, logs) = self.fieldscheck(ddata, validfields, reqfields, \"Defaults:\", valid, logs)\n        return (valid, logs)\n\n    def read(self, filename=None): # Read data from file (not for families.json)\n        if filename: self.filename = filename\n        with open(self.filename) as infile:\n            try:\n                filedata = json.load(infile)\n            except Exception as e:\n                self.logger.log(f'Error opening {infile}: {e}', 'S')\n            if len(filedata) != 1:\n                self.logger.log(f'Files must contain just one record; {self.filename} has {len(filedata)}')\n            self.id = list(filedata.keys())[0]\n            self.data = filedata[self.id]\n\n    def write(self, filename=None): # Write data to a file (not for families.json)\n        if filename is None: filename = self.filename\n        self.logger.log(f'Writing to {filename}', 'P')\n        filedata = {self.id: self.data}\n        with open(filename, \"w\", encoding=\"utf-8\") as outf:\n            outf.write(prettyjson(filedata, oneliners=[\"files\"]))",
  "class gfr_manifest(_familydata):\n    #\n    def __init__(self, id=None, data=None, filename = None, logger=None):\n        super(gfr_manifest, self).__init__(id=id, data=data, filename=filename, type=\"m\", logger=logger)\n\n    def validate(self, version=None, filename=None, checkfiles=True):\n        # Validate the manifest.\n        # If version is supplied, check that that matches the version in the manifest\n        # If self.filename not already set, the filename of the manifest must be supplied\n        (valid, logs) = super(gfr_manifest, self).validate() # Field name validation based on _familydata validation\n\n        if filename is None: filename = self.filename\n        data = self.data\n\n        if \"files\" in data and checkfiles:\n            files = data[\"files\"]\n            mfilelist = {x: files[x][\"packagepath\"] for x in files}\n\n            # Check files that are on disk match the manifest files\n            (path, base, ext) = splitfn(filename)\n            fontexts = ['.ttf', '.woff', '.woff2']\n            dfilelist = {}\n            for dirname, subdirs, filenames in os.walk(path):\n                for filen in filenames:\n                    (base, ext) = os.path.splitext(filen)\n                    if ext in fontexts:\n                        dfilelist[filen] = (os.path.relpath(os.path.join(dirname, filen), start=path).replace('\\\\', '/'))\n\n            if mfilelist == dfilelist:\n                logs.append(('Files OK', 'I'))\n            else:\n                valid = False\n                logs.append(('Files on disk and in manifest do not match.', 'W'))\n                logs.append(('Files on disk:', 'I'))\n                for filen in sorted(dfilelist):\n                    logs.append((f'     {dfilelist[filen]}', 'I'))\n                logs.append(('Files in manifest:', 'I'))\n                for filen in sorted(mfilelist):\n                    logs.append((f'     {mfilelist[filen]}', 'I'))\n\n            if \"defaults\" in data:\n                defaults = data[\"defaults\"]\n                # Check defaults exist\n                allthere = True\n                for default in defaults:\n                    if defaults[default] not in mfilelist: allthere = False\n\n                if allthere:\n                    logs.append(('Defaults OK', 'I'))\n                else:\n                    valid = False\n                    logs.append(('At least one default missing', 'W'))\n\n        if version:\n            if \"version\" in data:\n                mversion = data[\"version\"]\n                if version == mversion:\n                    logs.append(('Versions OK', 'I'))\n                else:\n                    valid = False\n                    logs.append((f'Version mismatch: {version} supplied and {mversion} in manifest', \"W\"))\n\n        return (valid, logs)",
  "class gfr_base(_familydata):\n    #\n    def __init__(self, id=None, data=None, filename = None, logger=None):\n        super(gfr_base, self).__init__(id=id, data=data, filename=filename, type=\"b\", logger=logger)",
  "class gfr_family(object): # For families.json.\n    #\n    def __init__(self, data=None, filename=None, logger=None):\n        self.filename = filename\n        self.logger = logger if logger else loggerobj()\n        self.familyrecords = {}\n        if data is not None: self.familyrecords = data\n\n    def validate(self, familyid=None):\n        allvalid = True\n        alllogs = []\n        if familyid:\n            record = self.familyrecords[familyid]\n            (allvalid, alllogs) = record.validate()\n        else:\n            for familyid in self.familyrecords:\n                record = self.familyrecords[familyid]\n                (valid, logs) = record.validate()\n            if not valid:\n                allvalid = False\n                alllogs.append(logs)\n        return allvalid, alllogs\n\n    def write(self, filename=None): # Write data to a file\n        if filename is None: filename = self.filename\n        self.logger.log(f'Writing to {filename}', \"P\")\n        with open(filename, \"w\", encoding=\"utf-8\") as outf:\n            outf.write(prettyjson(self.familyrecords, oneliners=[\"files\"]))",
  "def setpaths(logger): # Check that the script is being run from the root of the repository and set standard paths\n    repopath = os.path.abspath(os.path.curdir)\n    # Do cursory checks that this is the root of the fonts repo\n    if repopath[-5:] != \"fonts\" or not os.path.isdir(os.path.join(repopath, \"fonts/sil\")):\n        logger.log(\"GFR scripts must be run from the root of the fonts repo\", \"S\")\n    # Set up standars paths for scripts to use\n    silpath = os.path.join(repopath, \"fonts/sil\")\n    otherpath = os.path.join(repopath, \"fonts/other\")\n    basespath = os.path.join(repopath, \"basefiles\")\n    if not os.path.isdir(basespath): os.makedirs(basespath)\n    return repopath, silpath, otherpath, basespath",
  "def getttfdata(ttf, logger): # Extract data from a ttf\n\n    try:\n        font = TTFont(ttf)\n    except Exception as e:\n        logger.log(f'Error opening {ttf}: {e}', 'S')\n\n    name = font['name']\n    os2 = font['OS/2']\n    post = font['post']\n\n    values = {}\n\n    name16 = name.getName(nameID=16, platformID=3, platEncID=1, langID=0x409)\n\n    values[\"family\"] = str(name16) if name16 else str(name.getName(nameID=1, platformID=3, platEncID=1, langID=0x409))\n    values[\"subfamily\"] = str(name.getName(nameID=2, platformID=3, platEncID=1, langID=0x409))\n    values[\"version\"] =   str(name.getName(nameID=5, platformID=3, platEncID=1, langID=0x409))[8:] # Remove \"Version \" from the front\n    values[\"wght\"] = os2.usWeightClass\n    values[\"ital\"] = 0 if getattr(post, \"italicAngle\") == 0 else 1\n\n    return values",
  "def getziproot(url, ttfpath):\n    req = urllib2.Request(url=url, headers={'User-Agent': 'Mozilla/4.0 (compatible; httpget)'})\n    try:\n        reqdat = urllib2.urlopen(req)\n    except Exception as e:\n        return (None, f'{url} not valid: {str(e)}')\n    zipdat = reqdat.read()\n    zipinfile = io.BytesIO(initial_bytes=zipdat)\n    try:\n        zipf = ZipFile(zipinfile)\n    except Exception as e:\n        return (None, f'{url} is not a valid zip file')\n    for zf in zipf.namelist():\n        if zf.endswith(ttfpath):  # found a font, assume we want it\n            ziproot = zf[:-len(ttfpath) - 1]  # strip trailing /\n            return (ziproot, \"\")\n    else:\n        return (None, f\"Can't find {ttfpath} in {url}\")",
  "def __init__(self, id=None, data=None, filename = None, type=\"f\", logger=None):\n        # Initial input can be a dictionary (data) in which case id nneds to be set\n        # or it can be read from a file (containing just one family record), in which case id is taken from the file\n        # Type can be f, b or m for families, base or manifest\n        # With f, this would be for just a single entry from a families.json file\n        self.id = id\n        self.data = data if data else {}\n        self.filename = filename\n        self.type = type\n        self.logger = logger if logger else loggerobj()",
  "def fieldscheck(self, data, validfields, reqfields, logprefix, valid, logs):\n        for key in data: # Check all keys have valid names\n            if key not in validfields:\n                logs.append((f'{logprefix}: Invalid field \"{key}\"', 'W'))\n                valid = False\n                continue\n        # Are required fields present\n        for key in reqfields:\n            if key not in data:\n                logs.append((f'{logprefix}: Required field \"{key}\" missing', 'W'))\n                valid = False\n                continue\n        return (valid, logs)",
  "def validate(self):\n        global familyfields, filefields, defaultsfields\n        logs = []\n        valid = True\n        if self.type == \"m\":\n            validfields = reqfields = [key for key in familyfields if familyfields[key][\"manifest\"]]\n        else:\n            validfields = list(familyfields)\n            reqfields = [key for key in familyfields if not familyfields[key][\"opt\"]]\n        if self.type == \"f\":\n            reqfields = reqfields + [\"familyid\"]\n        else:  # Must be b\n            validfields = validfields + [\"hosturl\", \"filesroot\"]\n\n        (valid, logs) = self.fieldscheck(self.data, validfields, reqfields, \"Main\", valid, logs)\n        # Now check sub-fields\n        if \"files\" in self.data:\n            fdata = self.data[\"files\"]\n            if self.type == \"m\":\n                validfields = [key for key in filefields if filefields[key][\"manifest\"]]\n                reqfields = [key for key in filefields if filefields[key][\"manifest\"] and not (\"mopt\" in filefields[key] and filefields[key][\"mopt\"])]\n            else:\n                validfields = list(filefields)\n                reqfields = [key for key in filefields if not filefields[key][\"opt\"]]\n            # Now need to check values for each record in files\n            for filen in fdata:\n                frecord = fdata[filen]\n                (valid, logs) = self.fieldscheck(frecord, validfields, reqfields, \"Files: \" + filen, valid, logs)\n                if \"axes\" in frecord: # (Will already have been reported above if axes is missing!)\n                    adata = frecord[\"axes\"]\n                    avalidfields = [key for key in adata if len(key) == 4]\n                    areqfields = [\"wght\", \"ital\"] if self.type == \"m\" else []\n                    (valid, logs) = self.fieldscheck(adata, avalidfields, areqfields, \"Files, axes: \" + filen, valid, logs)\n        if \"defaults\" in self.data:\n            ddata = self.data[\"defaults\"]\n            if self.type == \"m\":\n                validfields = [key for key in defaultsfields if defaultsfields[key][\"manifest\"]]\n                reqfields = [key for key in defaultsfields if defaultsfields[key][\"manifest\"] and not (\"mopt\" in defaultsfields[key] and defaultsfields[key][\"mopt\"])]\n            else:\n                validfields = list(defaultsfields)\n                reqfields = [key for key in defaultsfields if not defaultsfields[key][\"opt\"]]\n            (valid, logs) = self.fieldscheck(ddata, validfields, reqfields, \"Defaults:\", valid, logs)\n        return (valid, logs)",
  "def read(self, filename=None): # Read data from file (not for families.json)\n        if filename: self.filename = filename\n        with open(self.filename) as infile:\n            try:\n                filedata = json.load(infile)\n            except Exception as e:\n                self.logger.log(f'Error opening {infile}: {e}', 'S')\n            if len(filedata) != 1:\n                self.logger.log(f'Files must contain just one record; {self.filename} has {len(filedata)}')\n            self.id = list(filedata.keys())[0]\n            self.data = filedata[self.id]",
  "def write(self, filename=None): # Write data to a file (not for families.json)\n        if filename is None: filename = self.filename\n        self.logger.log(f'Writing to {filename}', 'P')\n        filedata = {self.id: self.data}\n        with open(filename, \"w\", encoding=\"utf-8\") as outf:\n            outf.write(prettyjson(filedata, oneliners=[\"files\"]))",
  "def __init__(self, id=None, data=None, filename = None, logger=None):\n        super(gfr_manifest, self).__init__(id=id, data=data, filename=filename, type=\"m\", logger=logger)",
  "def validate(self, version=None, filename=None, checkfiles=True):\n        # Validate the manifest.\n        # If version is supplied, check that that matches the version in the manifest\n        # If self.filename not already set, the filename of the manifest must be supplied\n        (valid, logs) = super(gfr_manifest, self).validate() # Field name validation based on _familydata validation\n\n        if filename is None: filename = self.filename\n        data = self.data\n\n        if \"files\" in data and checkfiles:\n            files = data[\"files\"]\n            mfilelist = {x: files[x][\"packagepath\"] for x in files}\n\n            # Check files that are on disk match the manifest files\n            (path, base, ext) = splitfn(filename)\n            fontexts = ['.ttf', '.woff', '.woff2']\n            dfilelist = {}\n            for dirname, subdirs, filenames in os.walk(path):\n                for filen in filenames:\n                    (base, ext) = os.path.splitext(filen)\n                    if ext in fontexts:\n                        dfilelist[filen] = (os.path.relpath(os.path.join(dirname, filen), start=path).replace('\\\\', '/'))\n\n            if mfilelist == dfilelist:\n                logs.append(('Files OK', 'I'))\n            else:\n                valid = False\n                logs.append(('Files on disk and in manifest do not match.', 'W'))\n                logs.append(('Files on disk:', 'I'))\n                for filen in sorted(dfilelist):\n                    logs.append((f'     {dfilelist[filen]}', 'I'))\n                logs.append(('Files in manifest:', 'I'))\n                for filen in sorted(mfilelist):\n                    logs.append((f'     {mfilelist[filen]}', 'I'))\n\n            if \"defaults\" in data:\n                defaults = data[\"defaults\"]\n                # Check defaults exist\n                allthere = True\n                for default in defaults:\n                    if defaults[default] not in mfilelist: allthere = False\n\n                if allthere:\n                    logs.append(('Defaults OK', 'I'))\n                else:\n                    valid = False\n                    logs.append(('At least one default missing', 'W'))\n\n        if version:\n            if \"version\" in data:\n                mversion = data[\"version\"]\n                if version == mversion:\n                    logs.append(('Versions OK', 'I'))\n                else:\n                    valid = False\n                    logs.append((f'Version mismatch: {version} supplied and {mversion} in manifest', \"W\"))\n\n        return (valid, logs)",
  "def __init__(self, id=None, data=None, filename = None, logger=None):\n        super(gfr_base, self).__init__(id=id, data=data, filename=filename, type=\"b\", logger=logger)",
  "def __init__(self, data=None, filename=None, logger=None):\n        self.filename = filename\n        self.logger = logger if logger else loggerobj()\n        self.familyrecords = {}\n        if data is not None: self.familyrecords = data",
  "def validate(self, familyid=None):\n        allvalid = True\n        alllogs = []\n        if familyid:\n            record = self.familyrecords[familyid]\n            (allvalid, alllogs) = record.validate()\n        else:\n            for familyid in self.familyrecords:\n                record = self.familyrecords[familyid]\n                (valid, logs) = record.validate()\n            if not valid:\n                allvalid = False\n                alllogs.append(logs)\n        return allvalid, alllogs",
  "def write(self, filename=None): # Write data to a file\n        if filename is None: filename = self.filename\n        self.logger.log(f'Writing to {filename}', \"P\")\n        with open(filename, \"w\", encoding=\"utf-8\") as outf:\n            outf.write(prettyjson(self.familyrecords, oneliners=[\"files\"]))",
  "class Fxml(ETU.ETelement) :\n    def __init__(self, file = None, xmlstring = None, testgrouplabel = None, logger = None, params = None) :\n        self.logger = logger if logger is not None else silfont.core.loggerobj()\n        self.params = params if params is not None else silfont.core.parameters()\n        self.parseerrors=None\n        if not exactlyoneof(file, xmlstring, testgrouplabel) : self.logger.log(\"Must supply exactly one of file, xmlstring and testgrouplabel\",\"X\")\n\n        if testgrouplabel : # Create minimal valid ftml\n            xmlstring = '<ftml version=\"1.0\"><head></head><testgroup label=' + quoteattr(testgrouplabel) +'></testgroup></ftml>'\n\n        if file and not hasattr(file, 'read') : self.logger.log(\"'file' is not a file object\", \"X\") # ET.parse would also work on file name, but other code assumes file object\n\n        try :\n            if file :\n                self.element = ET.parse(file).getroot()\n            else :\n                self.element = ET.fromstring(xmlstring)\n        except Exception as e :\n            self.logger.log(\"Error parsing FTML input: \" + str(e), \"S\")\n\n        super(Fxml,self).__init__(self.element)\n\n        self.version = getattrib(self.element,\"version\")\n        if self.version != \"1.0\" : self.logger.log(\"ftml items must have a version of 1.0\", \"S\")\n\n        self.process_subelements((\n            (\"head\",      \"head\"      , Fhead,     True, False),\n            (\"testgroup\", \"testgroups\", Ftestgroup, True, True )),\n            offspec = False)\n\n        self.stylesheet = {}\n        if file : # If reading from file, look to see if a stylesheet is present in xml processing instructions\n            file.seek(0) # Have to re-read file since ElementTree does not support processing instructions\n            for line in file :\n                if line[0:2] == \"<?\" :\n                    line = line.strip()[:-2] # Strip white space and removing training ?>\n                    parts = line.split(\" \")\n                    if parts[0] == \"<?xml-stylesheet\" :\n                        for part in parts[1:] :\n                            (name,value) = part.split(\"=\")\n                            self.stylesheet[name] = value[1:-1] # Strip quotes\n                        break\n                else :\n                    break\n\n        self.filename = file if file else None\n\n        if self.parseerrors:\n            self.logger.log(\"Errors parsing ftml element:\",\"E\")\n            for error in self.parseerrors : self.logger.log(\"  \" + error,\"E\")\n            self.logger.log(\"Invalid FTML\", \"S\")\n\n    def save(self, file) :\n        self.outxmlstr=\"\"\n        element = self.create_element()\n        etw = ETU.ETWriter(element, inlineelem = [\"em\"])\n        self.outxmlstr = etw.serialize_xml()\n        file.write(self.outxmlstr)\n\n    def create_element(self) : # Create a new Elementtree element based on current object contents\n        element = ET.Element('ftml', version = str(self.version))\n        if self.stylesheet : # Create dummy .pi attribute for style sheet processing instruction\n            pi = \"xml-stylesheet\"\n            for attrib in sorted(self.stylesheet) : pi = pi + ' ' + attrib + '=\"' + self.stylesheet[attrib] + '\"' ## Spec is not clear about what order attributes should be in\n            element.attrib['.pi'] = pi\n        element.append(self.head.create_element())\n        for testgroup in self.testgroups : element.append(testgroup.create_element())\n        return element",
  "class Fhead(ETU.ETelement) :\n    def __init__(self, parent, element) :\n        self.parent = parent\n        self.logger = parent.logger\n        super(Fhead,self).__init__(element)\n\n        self.process_subelements((\n            (\"comment\",    \"comment\",    None,          False, False),\n            (\"fontscale\",  \"fontscale\",  None,          False, False),\n            (\"fontsrc\",    \"fontsrc\",    Ffontsrc,      False, True),\n            (\"styles\",     \"styles\",     ETU.ETelement, False, False ), # Initially just basic elements; Fstyles created below\n            (\"title\",      \"title\",      None,          False, False),\n            (\"widths\",     \"widths\",     _Fwidth,       False, False)),\n            offspec = True)\n\n        if self.fontscale is not None : self.fontscale = int(self.fontscale)\n        if self.styles is not None :\n            styles = {}\n            for styleelem in self.styles[\"style\"] :\n                style = Fstyle(self, element = styleelem)\n                styles[style.name] = style\n                if style.parseerrors:\n                    name = \"\" if style.name is None else style.name\n                    self.parseerrors.append(\"Errors parsing style element: \" + name)\n                    for error in style.parseerrors : self.parseerrors.append(\"  \" + error)\n            self.styles = styles\n        if self.widths is not None : self.widths = self.widths.widthsdict # Convert _Fwidths object into dict\n\n        self.elements = dict(self._contents) # Dictionary of all elements, particularly for handling non-standard elements\n\n    def findstyle(self, name = None, feats = None, lang = None) :\n        if self.styles is not None:\n            for s in self.styles :\n                style = self.styles[s]\n                if style.feats == feats and style.lang == lang :\n                    if name is None or name == style.name : return style # if name is supplied it must match\n        return None\n\n    def addstyle(self, name, feats = None, lang = None) : # Return style if it exists otherwise create new style with newname\n        s = self.findstyle(name, feats, lang)\n        if s is None :\n            if self.styles is None:\n                self.styles = {}\n            if name in self.styles : self.logger.log(\"Adding duplicate style name \" + name, \"X\")\n            s = Fstyle(self, name = name, feats = feats, lang = lang)\n            self.styles[name] = s\n        return s\n\n    def create_element(self) :\n        element = ET.Element('head')\n        # Add in-spec sub-elements in alphabetic order\n        if self.comment   : x = ET.SubElement(element, 'comment') ; x.text = self.comment\n        if self.fontscale : x = ET.SubElement(element, 'fontscale') ; x.text = str(self.fontscale)\n        if isinstance(self.fontsrc, list):\n            # Allow multiple fontsrc\n            for fontsrc in self.fontsrc:\n                element.append(fontsrc.create_element())\n        elif self.fontsrc is not None:\n            element.append(self.fontsrc.create_element())\n        if self.styles :\n            x = ET.SubElement(element, 'styles')\n            for style in sorted(self.styles) : x.append(self.styles[style].create_element())\n        if self.title     : y = ET.SubElement(element, 'title') ; y.text = self.title\n        if not self.widths is None :\n            x = ET.SubElement(element, 'widths')\n            for width in sorted(self.widths) :\n                if self.widths[width] is not None: x.set(width, self.widths[width])\n\n        # Add any non-spec elements\n        for el in sorted(self.elements) :\n            if el not in (\"comment\", \"fontscale\", \"fontsrc\", \"styles\", \"title\", \"widths\") :\n                for elem in self.elements[el] : element.append(elem)\n\n        return element",
  "class Ffontsrc(ETU.ETelement) :\n    # This library only supports a single font in the fontsrc as recommended by the FTML spec\n    # Currently it only supports simple url() and local() values\n\n    def __init__(self, parent, element = None, text = None, label=None) :\n        self.parent = parent\n        self.logger = parent.logger\n        self.parseerrors = []\n\n        if not exactlyoneof(element, text) : self.logger.log(\"Must supply exactly one of element and text\",\"X\")\n\n        try:\n            (txt, url, local) = parsefontsrc(text, allowplain=True) if text else parsefontsrc(element.text)\n        except ValueError as e :\n            txt = text if text else element.text\n            self.parseerrors.append(str(e) + \": \" + txt)\n        else :\n            if text : element = ET.Element(\"fontsrc\") ; element.text = txt\n            if label : element.set('label', label)\n            super(Ffontsrc,self).__init__(element)\n            self.process_attributes((\n                (\"label\", \"label\", False),),\n                others=False)\n            self.text = txt\n            self.url = url\n            self.local = local\n            if self.local : # Parse font name to find if bold, italic etc\n                results = re.match(fontspec, self.local) ## Does not cope with -, eg Gentium-Bold. Should it?\"\n                self.fontfamily = results.group('rest')\n                self.bold = results.group('bold') != None\n                self.italic = results.group('italic') != None\n            else :\n                self.fontfamily = None # If details are needed call getweights()\n\n    def addfontinfo(self) : # set fontfamily, bold and italic by looking inside font\n        (ff, bold, italic) = getfontinfo(self.url)\n        self.fontfamily = ff\n        self.bold = bold\n        self.italic = italic\n\n    def create_element(self) :\n        element = ET.Element(\"fontsrc\")\n        element.text = self.text\n        if self.label  : element.set(\"label\", self.label)\n        return element",
  "class Fstyle(ETU.ETelement) :\n    def __init__(self, parent, element = None, name = None, feats = None, lang = None) :\n        self.parent = parent\n        self.logger = parent.logger\n        if element is not None :\n            if name or feats or lang : parent.logger(\"Can't supply element and other parameters\", \"X\")\n        else :\n            if name is None : self.logger.log(\"Must supply element or name to Fstyle\", \"X\")\n            element = self.element = ET.Element(\"style\", name = name)\n            if feats is not None :\n                if type(feats) is dict : feats = self.dict_to_string(feats)\n                element.set('feats',feats)\n            if lang is not None : element.set('lang', lang)\n        super(Fstyle,self).__init__(element)\n\n        self.process_attributes((\n            (\"feats\", \"feats\", False),\n            (\"lang\",  \"lang\",  False),\n            (\"name\",  \"name\",  True)),\n            others = False)\n\n        if type(self.feats) is str : self.feats = self.string_to_dict(self.feats)\n\n    def string_to_dict(self, string) : # Split string on ',', then add to dict splitting on \" \" and removing quotes\n        dict={}\n        for f in string.split(','):\n            f = f.strip()\n            m = re.match(r'''(?P<quote>['\"])(\\w{4})(?P=quote)\\s+(\\d+|on|off)$''', f)\n            if m:\n                dict[m.group(2)] = m.group(3)\n            else:\n                self.logger.log(f'Invalid feature syntax \"{f}\"', 'E')\n        return dict\n\n    def dict_to_string(self, dict) :\n        str=\"\"\n        for name in sorted(dict) :\n            if dict[name] is not None : str += \"'\" + name + \"' \" + dict[name] + \", \"\n        str = str[0:-2] # remove final \", \"\n        return str\n\n    def create_element(self) :\n        element = ET.Element(\"style\", name = self.name)\n        if self.feats : element.set(\"feats\", self.dict_to_string(self.feats))\n        if self.lang  : element.set(\"lang\", self.lang)\n        return element",
  "class _Fwidth(ETU.ETelement) : # Only used temporarily whilst parsing xml\n    def __init__(self, parent, element) :\n        super(_Fwidth,self).__init__(element)\n        self.parent = parent\n        self.logger = parent.logger\n\n        self.process_attributes((\n            (\"comment\", \"comment\", False),\n            (\"label\", \"label\", False),\n            (\"string\", \"string\", False),\n            (\"stylename\", \"stylename\", False),\n            (\"table\",  \"table\",  False)),\n            others = False)\n        self.widthsdict = {\n            \"comment\": self.comment,\n            \"label\": self.label,\n            \"string\": self.string,\n            \"stylename\": self.stylename,\n            \"table\": self.table}",
  "class Ftestgroup(ETU.ETelement) :\n    def __init__(self, parent, element = None, label = None) :\n        self.parent = parent\n        self.logger = parent.logger\n        if not exactlyoneof(element, label) : self.logger.log(\"Must supply exactly one of element and label\",\"X\")\n\n        if label : element = ET.Element(\"testgroup\", label = label)\n\n        super(Ftestgroup,self).__init__(element)\n\n        self.subgroup = True if type(parent) is Ftestgroup else False\n        self.process_attributes((\n            (\"background\", \"background\", False),\n            (\"label\",      \"label\",      True)),\n            others = False)\n        self.process_subelements((\n            (\"comment\",    \"comment\",    None,       False, False),\n            (\"test\",       \"tests\",      Ftest,      False, True),\n            (\"testgroup\",  \"testgroups\", Ftestgroup, False, True)),\n            offspec = False)\n        if self.subgroup and self.testgroups != [] : parent.parseerrors.append(\"Only one level of testgroup nesting permitted\")\n\n        # Merge any sub-testgroups into tests\n        if self.testgroups != [] :\n            tests = []\n            tg = list(self.testgroups) # Want to preserve original list\n            for elem in self.element :\n                if elem.tag == \"test\":\n                    tests.append(self.tests.pop(0))\n                elif elem.tag == \"testgroup\" :\n                    tests.append(tg.pop(0))\n            self.tests = tests\n\n    def create_element(self) :\n        element = ET.Element(\"testgroup\")\n        if self.background : element.set(\"background\", self.background)\n        element.set(\"label\", self.label)\n        if self.comment : x = ET.SubElement(element, 'comment') ; x.text = self.comment\n        for test in self.tests : element.append(test.create_element())\n        return element",
  "class Ftest(ETU.ETelement) :\n    def __init__(self, parent, element = None, label = None, string = None) :\n        self.parent = parent\n        self.logger = parent.logger\n        if not exactlyoneof(element, (label, string)) : self.logger.log(\"Must supply exactly one of element and label/string\",\"X\")\n\n        if label :\n            element = ET.Element(\"test\", label = label)\n            x = ET.SubElement(element,\"string\") ; x.text = string\n\n        super(Ftest,self).__init__(element)\n\n        self.process_attributes((\n            (\"background\", \"background\", False),\n            (\"label\",      \"label\",      True),\n            (\"rtl\",        \"rtl\",        False),\n            (\"stylename\",  \"stylename\",  False)),\n            others = False)\n\n        self.process_subelements((\n            (\"comment\",    \"comment\",    None,       False, False),\n            (\"string\",     \"string\",     _Fstring,    True,  False)),\n            offspec = False)\n\n        self.string = self.string.string # self.string initially a temporary _Fstring element\n\n    def str(self, noems = False) : # Return formatted version of string\n        string = self.string\n        if noems :\n            string = string.replace(\"<em>\",\"\")\n            string = string.replace(\"</em>\",\"\")\n        return string ## Other formatting options to be added as needed cf ftml2odt\n\n    def create_element(self) :\n        element = ET.Element(\"test\")\n        if self.background : element.set(\"background\", self.background)\n        element.set(\"label\", self.label)\n        if self.rtl :        element.set(\"rtl\",        self.rtl)\n        if self.stylename :  element.set(\"stylename\",  self.stylename)\n        if self.comment : x = ET.SubElement(element, \"comment\") ; x.text = self.comment\n        x = ET.SubElement(element, \"string\") ; x.text = self.string\n\n        return element",
  "class _Fstring(ETU.ETelement) : # Only used temporarily whilst parsing xml\n    def __init__(self, parent, element = None) :\n        self.parent = parent\n        self.logger = parent.logger\n        super(_Fstring,self).__init__(element)\n        self.process_subelements(((\"em\", \"em\", ETU.ETelement,False, True),), offspec = False)\n        # Need to build text of string to include <em> subelements\n        self.string = element.text if element.text else \"\"\n        for em in self.em :\n            self.string += \"<em>{}</em>{}\".format(em.element.text, em.element.tail)",
  "def getattrib(element,attrib) :\n    return element.attrib[attrib] if attrib in element.attrib else None",
  "def exactlyoneof( *args ) : # Check one and only one of args is not None\n\n    last = args[-1]           # Check if last argument is a tuple - in which case\n    if type(last) is tuple :  # either all or none of list must be None\n        for test in last[1:] :\n            if (test is None) != (last[0] == None) : return False\n        args = list(args)  # Convert to list so last val can be changed\n        args[-1] = last[0] # Now valid to test on any item in tuple\n\n    one = False\n    for test in args :\n        if test is not None :\n            if one : return False # already have found one not None\n            one = True\n    if one : return True\n    return False",
  "def parsefontsrc(text, allowplain = False) : # Check fontsrc text is valid and return normalised text, url and local values\n    ''' - if multiple (fallback) fonts are specified, just process the first one\n        - just handles simple url() or local() formats\n        - if allowplain is set, allows text without url() or local() and decides which based on \".\" in text '''\n    text = text.split(\",\")[0] # If multiple (fallback) fonts are specified, just process the first one\n    #if allowplain and not re.match(r\"^(url|local)[(][^)]+[)]\",text) : # Allow for text without url() or local() form\n    if allowplain and not \"(\" in text : # Allow for text without url() or local() form\n        plain = True\n        if \".\" in text :\n            type = \"url\"\n        else :\n            type = \"local\"\n    else :\n        type = text.split(\"(\")[0]\n        if type == \"url\" :\n            text = text.split(\"(\")[1][:-1].strip()\n        elif type == \"local\" :\n            text = text.split(\"(\")[1][:-1].strip()\n        else : raise ValueError(\"Invalid fontsrc string\")\n    if type == \"url\" :\n        return (\"url(\"+text+\")\", text, None)\n    else :\n        return (\"local(\"+text+\")\", None , text)\n\n    return (text,url,local)",
  "def getfontinfo(filename) : # peek inside the font for the name, weight, style\n        f = ttLib.TTFont(filename)\n        # take name from name table, NameID 1, platform ID 3, Encoding ID 1 (possible fallback platformID 1, EncodingID =0)\n        n = f['name'] # name table from font\n        fontname = n.getName(1,3,1).toUnicode() # nameID 1 = Font Family name\n        # take bold and italic info from OS/2 table, fsSelection bits 0 and 5\n        o = f['OS/2'] # OS/2 table\n        italic = (o.fsSelection & 1) > 0\n        bold = (o.fsSelection & 32) > 0\n        return (fontname, bold, italic)",
  "def __init__(self, file = None, xmlstring = None, testgrouplabel = None, logger = None, params = None) :\n        self.logger = logger if logger is not None else silfont.core.loggerobj()\n        self.params = params if params is not None else silfont.core.parameters()\n        self.parseerrors=None\n        if not exactlyoneof(file, xmlstring, testgrouplabel) : self.logger.log(\"Must supply exactly one of file, xmlstring and testgrouplabel\",\"X\")\n\n        if testgrouplabel : # Create minimal valid ftml\n            xmlstring = '<ftml version=\"1.0\"><head></head><testgroup label=' + quoteattr(testgrouplabel) +'></testgroup></ftml>'\n\n        if file and not hasattr(file, 'read') : self.logger.log(\"'file' is not a file object\", \"X\") # ET.parse would also work on file name, but other code assumes file object\n\n        try :\n            if file :\n                self.element = ET.parse(file).getroot()\n            else :\n                self.element = ET.fromstring(xmlstring)\n        except Exception as e :\n            self.logger.log(\"Error parsing FTML input: \" + str(e), \"S\")\n\n        super(Fxml,self).__init__(self.element)\n\n        self.version = getattrib(self.element,\"version\")\n        if self.version != \"1.0\" : self.logger.log(\"ftml items must have a version of 1.0\", \"S\")\n\n        self.process_subelements((\n            (\"head\",      \"head\"      , Fhead,     True, False),\n            (\"testgroup\", \"testgroups\", Ftestgroup, True, True )),\n            offspec = False)\n\n        self.stylesheet = {}\n        if file : # If reading from file, look to see if a stylesheet is present in xml processing instructions\n            file.seek(0) # Have to re-read file since ElementTree does not support processing instructions\n            for line in file :\n                if line[0:2] == \"<?\" :\n                    line = line.strip()[:-2] # Strip white space and removing training ?>\n                    parts = line.split(\" \")\n                    if parts[0] == \"<?xml-stylesheet\" :\n                        for part in parts[1:] :\n                            (name,value) = part.split(\"=\")\n                            self.stylesheet[name] = value[1:-1] # Strip quotes\n                        break\n                else :\n                    break\n\n        self.filename = file if file else None\n\n        if self.parseerrors:\n            self.logger.log(\"Errors parsing ftml element:\",\"E\")\n            for error in self.parseerrors : self.logger.log(\"  \" + error,\"E\")\n            self.logger.log(\"Invalid FTML\", \"S\")",
  "def save(self, file) :\n        self.outxmlstr=\"\"\n        element = self.create_element()\n        etw = ETU.ETWriter(element, inlineelem = [\"em\"])\n        self.outxmlstr = etw.serialize_xml()\n        file.write(self.outxmlstr)",
  "def create_element(self) : # Create a new Elementtree element based on current object contents\n        element = ET.Element('ftml', version = str(self.version))\n        if self.stylesheet : # Create dummy .pi attribute for style sheet processing instruction\n            pi = \"xml-stylesheet\"\n            for attrib in sorted(self.stylesheet) : pi = pi + ' ' + attrib + '=\"' + self.stylesheet[attrib] + '\"' ## Spec is not clear about what order attributes should be in\n            element.attrib['.pi'] = pi\n        element.append(self.head.create_element())\n        for testgroup in self.testgroups : element.append(testgroup.create_element())\n        return element",
  "def __init__(self, parent, element) :\n        self.parent = parent\n        self.logger = parent.logger\n        super(Fhead,self).__init__(element)\n\n        self.process_subelements((\n            (\"comment\",    \"comment\",    None,          False, False),\n            (\"fontscale\",  \"fontscale\",  None,          False, False),\n            (\"fontsrc\",    \"fontsrc\",    Ffontsrc,      False, True),\n            (\"styles\",     \"styles\",     ETU.ETelement, False, False ), # Initially just basic elements; Fstyles created below\n            (\"title\",      \"title\",      None,          False, False),\n            (\"widths\",     \"widths\",     _Fwidth,       False, False)),\n            offspec = True)\n\n        if self.fontscale is not None : self.fontscale = int(self.fontscale)\n        if self.styles is not None :\n            styles = {}\n            for styleelem in self.styles[\"style\"] :\n                style = Fstyle(self, element = styleelem)\n                styles[style.name] = style\n                if style.parseerrors:\n                    name = \"\" if style.name is None else style.name\n                    self.parseerrors.append(\"Errors parsing style element: \" + name)\n                    for error in style.parseerrors : self.parseerrors.append(\"  \" + error)\n            self.styles = styles\n        if self.widths is not None : self.widths = self.widths.widthsdict # Convert _Fwidths object into dict\n\n        self.elements = dict(self._contents)",
  "def findstyle(self, name = None, feats = None, lang = None) :\n        if self.styles is not None:\n            for s in self.styles :\n                style = self.styles[s]\n                if style.feats == feats and style.lang == lang :\n                    if name is None or name == style.name : return style # if name is supplied it must match\n        return None",
  "def addstyle(self, name, feats = None, lang = None) : # Return style if it exists otherwise create new style with newname\n        s = self.findstyle(name, feats, lang)\n        if s is None :\n            if self.styles is None:\n                self.styles = {}\n            if name in self.styles : self.logger.log(\"Adding duplicate style name \" + name, \"X\")\n            s = Fstyle(self, name = name, feats = feats, lang = lang)\n            self.styles[name] = s\n        return s",
  "def create_element(self) :\n        element = ET.Element('head')\n        # Add in-spec sub-elements in alphabetic order\n        if self.comment   : x = ET.SubElement(element, 'comment') ; x.text = self.comment\n        if self.fontscale : x = ET.SubElement(element, 'fontscale') ; x.text = str(self.fontscale)\n        if isinstance(self.fontsrc, list):\n            # Allow multiple fontsrc\n            for fontsrc in self.fontsrc:\n                element.append(fontsrc.create_element())\n        elif self.fontsrc is not None:\n            element.append(self.fontsrc.create_element())\n        if self.styles :\n            x = ET.SubElement(element, 'styles')\n            for style in sorted(self.styles) : x.append(self.styles[style].create_element())\n        if self.title     : y = ET.SubElement(element, 'title') ; y.text = self.title\n        if not self.widths is None :\n            x = ET.SubElement(element, 'widths')\n            for width in sorted(self.widths) :\n                if self.widths[width] is not None: x.set(width, self.widths[width])\n\n        # Add any non-spec elements\n        for el in sorted(self.elements) :\n            if el not in (\"comment\", \"fontscale\", \"fontsrc\", \"styles\", \"title\", \"widths\") :\n                for elem in self.elements[el] : element.append(elem)\n\n        return element",
  "def __init__(self, parent, element = None, text = None, label=None) :\n        self.parent = parent\n        self.logger = parent.logger\n        self.parseerrors = []\n\n        if not exactlyoneof(element, text) : self.logger.log(\"Must supply exactly one of element and text\",\"X\")\n\n        try:\n            (txt, url, local) = parsefontsrc(text, allowplain=True) if text else parsefontsrc(element.text)\n        except ValueError as e :\n            txt = text if text else element.text\n            self.parseerrors.append(str(e) + \": \" + txt)\n        else :\n            if text : element = ET.Element(\"fontsrc\") ; element.text = txt\n            if label : element.set('label', label)\n            super(Ffontsrc,self).__init__(element)\n            self.process_attributes((\n                (\"label\", \"label\", False),),\n                others=False)\n            self.text = txt\n            self.url = url\n            self.local = local\n            if self.local : # Parse font name to find if bold, italic etc\n                results = re.match(fontspec, self.local) ## Does not cope with -, eg Gentium-Bold. Should it?\"\n                self.fontfamily = results.group('rest')\n                self.bold = results.group('bold') != None\n                self.italic = results.group('italic') != None\n            else :\n                self.fontfamily = None",
  "def addfontinfo(self) : # set fontfamily, bold and italic by looking inside font\n        (ff, bold, italic) = getfontinfo(self.url)\n        self.fontfamily = ff\n        self.bold = bold\n        self.italic = italic",
  "def create_element(self) :\n        element = ET.Element(\"fontsrc\")\n        element.text = self.text\n        if self.label  : element.set(\"label\", self.label)\n        return element",
  "def __init__(self, parent, element = None, name = None, feats = None, lang = None) :\n        self.parent = parent\n        self.logger = parent.logger\n        if element is not None :\n            if name or feats or lang : parent.logger(\"Can't supply element and other parameters\", \"X\")\n        else :\n            if name is None : self.logger.log(\"Must supply element or name to Fstyle\", \"X\")\n            element = self.element = ET.Element(\"style\", name = name)\n            if feats is not None :\n                if type(feats) is dict : feats = self.dict_to_string(feats)\n                element.set('feats',feats)\n            if lang is not None : element.set('lang', lang)\n        super(Fstyle,self).__init__(element)\n\n        self.process_attributes((\n            (\"feats\", \"feats\", False),\n            (\"lang\",  \"lang\",  False),\n            (\"name\",  \"name\",  True)),\n            others = False)\n\n        if type(self.feats) is str : self.feats = self.string_to_dict(self.feats)",
  "def string_to_dict(self, string) : # Split string on ',', then add to dict splitting on \" \" and removing quotes\n        dict={}\n        for f in string.split(','):\n            f = f.strip()\n            m = re.match(r'''(?P<quote>['\"])(\\w{4})(?P=quote)\\s+(\\d+|on|off)$''', f)\n            if m:\n                dict[m.group(2)] = m.group(3)\n            else:\n                self.logger.log(f'Invalid feature syntax \"{f}\"', 'E')\n        return dict",
  "def dict_to_string(self, dict) :\n        str=\"\"\n        for name in sorted(dict) :\n            if dict[name] is not None : str += \"'\" + name + \"' \" + dict[name] + \", \"\n        str = str[0:-2] # remove final \", \"\n        return str",
  "def create_element(self) :\n        element = ET.Element(\"style\", name = self.name)\n        if self.feats : element.set(\"feats\", self.dict_to_string(self.feats))\n        if self.lang  : element.set(\"lang\", self.lang)\n        return element",
  "def __init__(self, parent, element) :\n        super(_Fwidth,self).__init__(element)\n        self.parent = parent\n        self.logger = parent.logger\n\n        self.process_attributes((\n            (\"comment\", \"comment\", False),\n            (\"label\", \"label\", False),\n            (\"string\", \"string\", False),\n            (\"stylename\", \"stylename\", False),\n            (\"table\",  \"table\",  False)),\n            others = False)\n        self.widthsdict = {\n            \"comment\": self.comment,\n            \"label\": self.label,\n            \"string\": self.string,\n            \"stylename\": self.stylename,\n            \"table\": self.table}",
  "def __init__(self, parent, element = None, label = None) :\n        self.parent = parent\n        self.logger = parent.logger\n        if not exactlyoneof(element, label) : self.logger.log(\"Must supply exactly one of element and label\",\"X\")\n\n        if label : element = ET.Element(\"testgroup\", label = label)\n\n        super(Ftestgroup,self).__init__(element)\n\n        self.subgroup = True if type(parent) is Ftestgroup else False\n        self.process_attributes((\n            (\"background\", \"background\", False),\n            (\"label\",      \"label\",      True)),\n            others = False)\n        self.process_subelements((\n            (\"comment\",    \"comment\",    None,       False, False),\n            (\"test\",       \"tests\",      Ftest,      False, True),\n            (\"testgroup\",  \"testgroups\", Ftestgroup, False, True)),\n            offspec = False)\n        if self.subgroup and self.testgroups != [] : parent.parseerrors.append(\"Only one level of testgroup nesting permitted\")\n\n        # Merge any sub-testgroups into tests\n        if self.testgroups != [] :\n            tests = []\n            tg = list(self.testgroups) # Want to preserve original list\n            for elem in self.element :\n                if elem.tag == \"test\":\n                    tests.append(self.tests.pop(0))\n                elif elem.tag == \"testgroup\" :\n                    tests.append(tg.pop(0))\n            self.tests = tests",
  "def create_element(self) :\n        element = ET.Element(\"testgroup\")\n        if self.background : element.set(\"background\", self.background)\n        element.set(\"label\", self.label)\n        if self.comment : x = ET.SubElement(element, 'comment') ; x.text = self.comment\n        for test in self.tests : element.append(test.create_element())\n        return element",
  "def __init__(self, parent, element = None, label = None, string = None) :\n        self.parent = parent\n        self.logger = parent.logger\n        if not exactlyoneof(element, (label, string)) : self.logger.log(\"Must supply exactly one of element and label/string\",\"X\")\n\n        if label :\n            element = ET.Element(\"test\", label = label)\n            x = ET.SubElement(element,\"string\") ; x.text = string\n\n        super(Ftest,self).__init__(element)\n\n        self.process_attributes((\n            (\"background\", \"background\", False),\n            (\"label\",      \"label\",      True),\n            (\"rtl\",        \"rtl\",        False),\n            (\"stylename\",  \"stylename\",  False)),\n            others = False)\n\n        self.process_subelements((\n            (\"comment\",    \"comment\",    None,       False, False),\n            (\"string\",     \"string\",     _Fstring,    True,  False)),\n            offspec = False)\n\n        self.string = self.string.string",
  "def str(self, noems = False) : # Return formatted version of string\n        string = self.string\n        if noems :\n            string = string.replace(\"<em>\",\"\")\n            string = string.replace(\"</em>\",\"\")\n        return string",
  "def create_element(self) :\n        element = ET.Element(\"test\")\n        if self.background : element.set(\"background\", self.background)\n        element.set(\"label\", self.label)\n        if self.rtl :        element.set(\"rtl\",        self.rtl)\n        if self.stylename :  element.set(\"stylename\",  self.stylename)\n        if self.comment : x = ET.SubElement(element, \"comment\") ; x.text = self.comment\n        x = ET.SubElement(element, \"string\") ; x.text = self.string\n\n        return element",
  "def __init__(self, parent, element = None) :\n        self.parent = parent\n        self.logger = parent.logger\n        super(_Fstring,self).__init__(element)\n        self.process_subelements(((\"em\", \"em\", ETU.ETelement,False, True),), offspec = False)\n        # Need to build text of string to include <em> subelements\n        self.string = element.text if element.text else \"\"\n        for em in self.em :\n            self.string += \"<em>{}</em>{}\".format(em.element.text, em.element.tail)",
  "class loggerobj(object):\n    # For handling log messages.\n    # Use S for severe errors caused by data, parameters supplied by user etc\n    # Use X for severe errors caused by bad code to get traceback exception\n\n    def __init__(self, logfile=None, loglevels=\"\", leveltext=\"\",  loglevel=\"W\", scrlevel=\"P\"):\n        self.logfile = logfile\n        self.loglevels = loglevels\n        self.leveltext = leveltext\n        self.errorcount = 0\n        self.warningcount = 0\n        if not self.loglevels: self.loglevels = {'X': 0,       'S': 1,       'E': 2,       'P': 3,       'W': 4,       'I': 5,       'V': 6}\n        if not self.leveltext: self.leveltext = ('Exception ', 'Severe:   ', 'Error:    ', 'Progress: ', 'Warning:  ', 'Info:     ', 'Verbose:  ')\n        super(loggerobj, self).__setattr__(\"loglevel\", \"E\") # Temp values so invalid log levels can be reported\n        super(loggerobj, self).__setattr__(\"scrlevel\", \"E\") #\n        self.loglevel = loglevel\n        self.scrlevel = scrlevel\n\n    def __setattr__(self, name, value):\n        if name in (\"loglevel\", \"scrlevel\"):\n            if value in self.loglevels:\n                (minlevel, minnum) = (\"E\",2) if name == \"loglevel\" else (\"S\", 1)\n                if self.loglevels[value] < minnum:\n                    value = minlevel\n                    self.log(name + \" increased to minimum level of \" + minlevel, \"E\")\n            else:\n                self.log(\"Invalid \" + name + \" value: \" + value, \"S\")\n        super(loggerobj, self).__setattr__(name, value)\n        if name == \"scrlevel\" : self._basescrlevel = value # Used by resetscrlevel\n\n    def log(self, logmessage, msglevel=\"W\"):\n        levelval = self.loglevels[msglevel]\n        message = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S \") + self.leveltext[levelval] + str(logmessage)\n        #message = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S.%f\")[0:22] +\" \"+ self.leveltext[levelval] + logmessage  ## added milliseconds for timing tests\n        if levelval <= self.loglevels[self.scrlevel]: print(message)\n        if self.logfile and levelval <= self.loglevels[self.loglevel]: self.logfile.write(message + \"\\n\")\n        if msglevel == \"S\":\n            print(\"\\n **** Fatal error - exiting ****\")\n            sys.exit(1)\n        if msglevel == \"X\": assert False, message\n        if msglevel == \"E\": self.errorcount += 1\n        if msglevel == \"W\": self.warningcount += 1\n\n    def raisescrlevel(self, level): # Temporarily increase screen logging\n        if level not in self.loglevels or level == \"X\" : self.log(\"Invalid scrlevel: \" + level, \"X\")\n        if self.loglevels[level] > self.loglevels[self.scrlevel]:\n            current = self.scrlevel\n            self.scrlevel = level\n            self._basescrlevel = current\n            self.log(\"scrlevel raised to \" + level, \"I\")\n\n    def resetscrlevel(self):\n        self.scrlevel = self._basescrlevel",
  "class parameters(object):\n    # Object for holding parameters information, organised by class (eg logging)\n\n    # Default parameters for use in pysilfont modules\n    #   Names must be case-insensitively unique across all parameter classes\n    #   Parameter types are deduced from the default values\n\n    def __init__(self):\n        # Default parameters for all modules\n        defparams = {}\n        defparams['system'] = {'version': silfont.__version__, 'copyright': silfont.__copyright__}  # Code treats these as read-only\n        defparams['logging'] = {'scrlevel': 'P', 'loglevel': 'W'}\n        defparams['backups'] = {'backup': True, 'backupdir': 'backups', 'backupkeep': 5}\n        # Default parameters for UFO module\n        defparams['outparams'] = OrderedDict([ # Use ordered dict so parameters show in logical order with -h p\n            (\"UFOversion\", \"\"),  # UFOversion - defaults to existing unless a value is supplied\n            (\"indentIncr\",       \"  \"),   # XML Indent increment\n            (\"indentFirst\",      \"  \"),   # First XML indent\n            (\"indentML\",         False),  # Should multi-line string values be indented?\n            (\"plistIndentFirst\", \"\"),     # First indent amount for plists\n            ('precision', 6),             # Decimal precision to use in XML output - both for real values and for attributes if float\n            (\"floatAttribs\", ['xScale', 'xyScale', 'yxScale', 'yScale', 'angle']),  # Used with precision above\n            (\"intAttribs\", ['pos', 'width', 'height', 'xOffset', 'yOffset', 'x', 'y']),\n            (\"sortDicts\",        True),   # Should dict elements be sorted alphabetically?\n            (\"renameGlifs\",      True),   # Rename glifs based on UFO3 suggested algorithm\n            (\"format1Glifs\",     False),  # Force output format 1 glifs including UFO2-style anchors (for use with FontForge\n            (\"glifElemOrder\",    ['advance', 'unicode', 'note',   'image',  'guideline', 'anchor', 'outline', 'lib']),  # Order to output glif elements\n            (\"attribOrders.glif\",['pos', 'width', 'height', 'fileName', 'base', 'xScale', 'xyScale', 'yxScale', 'yScale', 'xOffset', 'yOffset',\n                                  'x', 'y', 'angle', 'type', 'smooth', 'name', 'format', 'color', 'identifier'])\n            ])\n        defparams['ufometadata'] = {\"checkfix\": \"check\"}   # Apply metadata fixes when reading UFOs\n\n        self.paramshelp = {} # Info used when outputting help about parame options\n        self.paramshelp[\"classdesc\"] = {\n            \"logging\": \"controls the level of log messages go to screen or log files.\",\n            \"backups\": \"controls backup settings for scripts that output fonts - by default backups are made if the output font is overwriting the input font\",\n            \"outparams\": \"Output options for UFOs - cover UFO version and normalization\",\n            \"ufometadata\": \"controls if UFO metadata be checked, or checked and fixed\"\n        }\n        self.paramshelp[\"paramsdesc\"] = {\n            \"scrlevel\": \"Logging level for screen messages - one of S,E,P.W,I or V\",\n            \"loglevel\": \"Logging level for log file messages - one of E,P.W,I or V\",\n            \"backup\": \"Should font backups be made\",\n            \"backupdir\": \"Directory to use for font backups\",\n            \"backupkeep\": \"How many backups to keep\",\n            \"indentIncr\": \"XML Indent increment\",\n            \"indentFirst\": \"First XML indent\",\n            \"indentML\": \"Should multi-line string values be indented?\",\n            \"plistIndentFirst\": \"First indent amount for plists\",\n            \"sortDicts\": \"Should dict elements be sorted alphabetically?\",\n            \"precision\": \"Decimal precision to use in XML output - both for real values and for attributes if numeric\",\n            \"renameGlifs\": \"Rename glifs based on UFO3 suggested algorithm\",\n            \"UFOversion\": \"UFOversion to output - defaults to version of the input UFO\",\n            \"format1Glifs\": \"Force output format 1 glifs including UFO2-style anchors (was used with FontForge; no longer needed)\",\n            \"glifElemOrder\": \"Order to output glif elements\",\n            \"floatAttribs\": \"List of float attributes - used when setting decimal precision\",\n            \"intAttribs\": \"List of attributes that should be integers\",\n            \"attribOrders.glif\": \"Order in which to output glif attributes\",\n            \"checkfix\": \"Should check & fix tests be done - one of None, Check or Fix\"\n        }\n        self.paramshelp[\"defaultsdesc\"] = { # For use where default needs clarifying with text\n            \"indentIncr\" : \"<two spaces>\",\n            \"indentFirst\": \"<two spaces>\",\n            \"plistIndentFirst\": \"<No indent>\",\n            \"UFOversion\": \"<Existing version>\"\n        }\n\n        self.classes = {}  # Dictionary containing a list of parameters in each class\n        self.paramclass = {}  # Dictionary of class name for each parameter name\n        self.types = {}  # Python type for each parameter deduced from initial values supplied\n        self.listtypes = {}  # If type is dict, the type of values in the dict\n        self.logger = loggerobj()\n        defset = _paramset(self, \"default\", \"defaults\")\n        self.sets = {\"default\": defset}\n        self.lcase = {}  # Lower case index of parameters names\n        for classn in defparams:\n            self.classes[classn] = []\n            for parn in defparams[classn]:\n                value = defparams[classn][parn]\n                self.classes[classn].append(parn)\n                self.paramclass[parn] = classn\n                self.types[parn] = type(value)\n                if type(value) is list: self.listtypes[parn] = type(value[0])\n                super(_paramset, defset).__setitem__(parn, value)  # __setitem__ in paramset does not allow new values!\n                self.lcase[parn.lower()] = parn\n\n    def addset(self, name, sourcedesc=None, inputdict=None, configfile=None, copyset=None):\n        # Create a subset from one of a dict, config file or existing set\n        # Only one option should used per call\n        # sourcedesc should be added for user-supplied data (eg config file) for reporting purposes\n        dict = {}\n        if configfile:\n            config = configparser.ConfigParser()\n            config.read_file(open(configfile, encoding=\"utf-8\"))\n            if sourcedesc is None: sourcedesc = configfile\n            for classn in config.sections():\n                for item in config.items(classn):\n                    parn = item[0]\n                    if self.paramclass[parn] == \"system\":\n                        self.logger.log(\"Can't change \" + parn + \" parameter via config file\", \"S\")\n                    val = item[1].strip('\"').strip(\"'\")\n                    dict[parn] = val\n        elif copyset:\n            if sourcedesc is None: sourcedesc = \"Copy of \" + copyset\n            for parn in self.sets[copyset]:\n                dict[parn] = self.sets[copyset][parn]\n        elif inputdict:\n            dict = inputdict\n        if sourcedesc is None: sourcedesc = \"unspecified source\"\n        self.sets[name] = _paramset(self, name, sourcedesc, dict)\n\n    def printhelp(self):\n        phelp = self.paramshelp\n        print(\"\\nMost pysilfont scripts have -p, --params options which can be used to change default behaviour of scripts.  For example '-p scrlevel=w' will log warning messages to screen \\n\")\n        print(\"Listed below are all such parameters, grouped by purpose.  Not all apply to all scripts - \"\n              \"in partucular outparams and ufometadata only apply to scripts using pysilfont's own UFO code\")\n        for classn in (\"logging\", \"backups\", \"ufometadata\", \"outparams\"):\n            print(\"\\n\" + classn[0].upper() + classn[1:] + \" - \" + phelp[\"classdesc\"][classn])\n            for param in self.classes[classn]:\n                if param == \"format1Glifs\": continue # Param due to be phased out\n                paramdesc = phelp[\"paramsdesc\"][param]\n                paramtype = self.types[param].__name__\n                defaultdesc = phelp[\"defaultsdesc\"][param] if param in phelp[\"defaultsdesc\"] else self.sets[\"default\"][param]\n                print('    {:<20}: {}'.format(param, paramdesc))\n                print('       (Type: {:<6} Default: {})'.format(paramtype + \",\", defaultdesc))\n        print(\"\\nNote parameter names are case-insensitive\\n\")\n        print(\"For more help see https://github.com/silnrsi/pysilfont/blob/master/docs/parameters.md\\n\")",
  "class _paramset(dict):\n    # Set of parameter values\n    def __init__(self, params, name, sourcedesc, inputdict=None):\n        if inputdict is None: inputdict = {}\n        self.name = name\n        self.sourcedesc = sourcedesc  # Description of source for reporting\n        self.params = params  # Parent parameters object\n        for parn in inputdict:\n            if params.paramclass[parn] == \"system\": # system values can't be changed\n                if inputdict[parn] != params.sets[\"default\"][parn]:\n                    self.params.logger.log(\"Can't change \" + parn + \" - system parameters can't be changed\", \"X\")\n                else:\n                    super(_paramset, self).__setitem__(parn, inputdict[parn])\n            else:\n                self[parn] = inputdict[parn]\n\n    def __setitem__(self, parn, value):\n        origvalue = value\n        origparn = parn\n        parn = parn.lower()\n        if self.params.paramclass[origparn] == \"system\":\n            self.params.logger.log(\"Can't change \" + parn + \" - system parameters are read-only\", \"X\")\n        if parn not in self.params.lcase:\n            self.params.logger.log(\"Invalid parameter \" + origparn + \" from \" + self.sourcedesc, \"S\")\n        else:\n            parn = self.params.lcase[parn]\n        ptyp = self.params.types[parn]\n        if ptyp is bool:\n            value = str2bool(value)\n            if value is None: self.params.logger.log(self.sourcedesc+\" parameter \"+origparn+\" must be boolean: \" + origvalue, \"S\")\n        if ptyp is list:\n            if type(value) is not list: value = value.split(\",\")  # Convert csv string into list\n            if len(value) < 2: self.params.logger.log(self.sourcedesc+\" parameter \"+origparn+\" must have a list of values: \" + origvalue, \"S\")\n            valuesOK = True\n            listtype = self.params.listtypes[parn]\n            for i, val in enumerate(value):\n                if listtype is bool:\n                    val = str2bool(val)\n                    if val is None: self.params.logger.log (self.sourcedesc+\" parameter \"+origparn+\" must contain boolean values: \" + origvalue, \"S\")\n                    value[i] = val\n                if type(val) != listtype:\n                    valuesOK = False\n                    badtype = str(type(val))\n            if not valuesOK: self.params.logger.log(\"Invalid \"+badtype+\" parameter type for \"+origparn+\": \"+self.params.types[parn], \"S\")\n        if parn in (\"loglevel\", \"scrlevel\"):  # Need to check log level is valid before setting it since otherwise logging will fail\n            value = value.upper()\n            if value not in self.params.logger.loglevels: self.params.logger.log (self.sourcedesc+\" parameter \"+parn+\" invalid\", \"S\")\n        super(_paramset, self).__setitem__(parn, value)\n\n    def updatewith(self, update, sourcedesc=None, log=True):\n        # Update a set with values from another set\n        if sourcedesc is None: sourcedesc = self.params.sets[update].sourcedesc\n        for parn in self.params.sets[update]:\n            oldval = self[parn] if parn in self else \"\"\n            self[parn] = self.params.sets[update][parn]\n            if log and oldval != \"\" and self[parn] != oldval:\n                old = str(oldval)\n                new = str(self[parn])\n                if old != old.strip() or new != new.strip():   # Add quotes if there are leading or trailing spaces\n                    old = '\"'+old+'\"'\n                    new = '\"'+new+'\"'\n                self.params.logger.log(sourcedesc + \" parameters: changing \"+parn+\" from \" + old + \" to \" + new, \"I\")",
  "class csvreader(object):    # Iterator for csv files, skipping comments and checking number of fields\n    def __init__(self, filename, minfields=0, maxfields=999, numfields=None, logger=None):\n        self.filename = filename\n        self.minfields = minfields\n        self.maxfields = maxfields\n        self.numfields = numfields\n        self.logger = logger if logger else loggerobj()   # If no logger supplied, will just log to screen\n        # Open the file and create reader\n        try:\n            file = open(filename, \"rt\", encoding=\"utf-8\")\n        except Exception as e:\n            print(e)\n            sys.exit(1)\n        self.file = file\n        self.reader = csv.reader(file)\n        # Find the first non-comment line then reset so __iter__ still returns the first line\n        # This is so scripts can analyse first line (eg to look for headers) before starting iterating\n        self.firstline = None\n        self._commentsbeforefirstline = -1\n        while not self.firstline:\n            row = next(self.reader, None)\n            if row is None: logger.log(\"Input csv is empty or all lines are comments or blank\", \"S\")\n            self._commentsbeforefirstline += 1\n            if row == []: continue  # Skip blank lines\n            if row[0].lstrip().startswith(\"#\"): continue  # Skip comments - ie lines starting with  #\n            self.firstline = row\n        file.seek(0) # Reset the csv and skip comments\n        for i in range(self._commentsbeforefirstline): next(self.reader, None)\n\n    def __setattr__(self, name, value):\n        if name == \"numfields\" and value is not None:  # If numfields is changed, reset min and max fields\n            self.minfields = value\n            self.maxfields = value\n        super(csvreader, self).__setattr__(name, value)\n\n    def __iter__(self):\n        for row in self.reader:\n            self.line_num = self.reader.line_num - 1 - self._commentsbeforefirstline # Count is out due to reading first line in __init__\n            if row == []: continue  # Skip blank lines\n            if row[0].lstrip().startswith(\"#\"): continue  # Skip comments - ie lines starting with  #\n            if len(row) < self.minfields or len(row) > self.maxfields:\n                self.logger.log(\"Invalid number of fields on line \" + str(self.line_num) + \" in \"+self.filename, \"E\" )\n                continue\n            yield row",
  "def execute(tool, fn, scriptargspec, chain = None):\n    # Function to handle parameter parsing, font and file opening etc in command-line scripts\n    # Supports opening (and saving) fonts using PysilFont UFO (UFO), fontParts (FP) or fontTools (FT)\n    # Special handling for:\n    #   -d  variation on -h to print extra info about defaults\n    #   -q  quiet mode - only output a single line with count of errors (if there are any)\n    #   -l  opens log file and also creates a logger function to write to the log file\n    #   -p  other parameters. Includes backup settings and loglevel/scrlevel settings for logger\n    #       for UFOlib scripts, also includes all outparams keys and ufometadata settings\n\n    argspec = list(scriptargspec)\n\n    chainfirst = False\n    if chain == \"first\": # If first call to execute has this set, only do the final return part of chaining\n        chainfirst = True\n        chain = None\n\n    params = chain[\"params\"] if chain else parameters()\n    logger = chain[\"logger\"] if chain else params.logger  # paramset has already created a basic logger\n    argv   = chain[\"argv\"]   if chain else sys.argv\n\n    if tool == \"UFO\":\n        from silfont.ufo import Ufont\n    elif tool == \"FT\":\n        from fontTools import ttLib\n    elif tool == \"FP\":\n        from fontParts.world import OpenFont\n    elif tool == \"\" or tool is None:\n        tool = None\n    else:\n        logger.log(\"Invalid tool in call to execute()\", \"X\")\n        return\n    basemodule = sys.modules[fn.__module__]\n    poptions = {}\n    poptions['prog'] = splitfn(argv[0])[1]\n    poptions['description'] = basemodule.__doc__\n    poptions['formatter_class'] = argparse.RawDescriptionHelpFormatter\n    epilog = \"For more help options use -h ?.  For more documentation see https://github.com/silnrsi/pysilfont/blob/master/docs/scripts.md#\" + poptions['prog'] + \"\\n\\n\"\n    poptions['epilog'] = epilog + \"Version: \" + params.sets['default']['version'] + \"\\n\" + params.sets['default']['copyright']\n\n    parser = argparse.ArgumentParser(**poptions)\n    parser._optionals.title = \"other arguments\"\n\n\n    # Add standard arguments\n    standardargs = {\n            'quiet': ('-q', '--quiet', {'help': 'Quiet mode - only display severe errors', 'action': 'store_true'}, {}),\n            'log': ('-l', '--log', {'help': 'Log file'}, {'type': 'outfile'}),\n            'params': ('-p', '--params', {'help': 'Other parameters - see parameters.md for details', 'action': 'append'}, {'type': 'optiondict'}),\n            'nq': ('--nq', {'help': argparse.SUPPRESS, 'action': 'store_true'}, {})}\n\n    suppliedargs = []\n    for a in argspec:\n        argn = a[:-2][-1]  # [:-2] will give either 1 or 2, the last of which is the full argument name\n        if argn[0:2] == \"--\": argn = argn[2:]  # Will start with -- for options\n        suppliedargs.append(argn)\n    for arg in sorted(standardargs):\n        if arg not in suppliedargs: argspec.append(standardargs[arg])\n\n    defhelp = False\n    if \"-h\" in argv: # Look for help option supplied\n        pos = argv.index(\"-h\")\n        if pos < len(argv)-1: # There is something following -h!\n            opt = argv[pos+1]\n            if opt in (\"d\", \"defaults\"):\n                defhelp = True # Normal help will be displayed with default info displayed by the epilog\n                deffiles = []\n                defother = []\n            elif opt in (\"p\", \"params\"):\n                params.printhelp()\n                sys.exit(0)\n            else:\n                if opt != \"?\":\n                    print(\"Invalid -h value\")\n                    print(\"-h ? displays help options\")\n                print(\"-h d (or -h defaults) lists details of default values for arguments and parameters\")\n                print(\"-h p (or -h params) gives help on parameters that can be set with -p or --params\")\n                sys.exit(0)\n\n    quiet = True if \"-q\" in argv and '--nq' not in argv else False\n    if quiet: logger.scrlevel = \"S\"\n\n    # Process the supplied argument specs, add args to parser, store other info in arginfo\n    arginfo = []\n    logdef = None\n    for a in argspec:\n        # Process all but last tuple entry as argparse arguments\n        nonkwds = a[:-2]\n        kwds = a[-2]\n        try:\n            parser.add_argument(*nonkwds, **kwds)\n        except Exception as e:\n            print(f'nonkwds: {nonkwds}, kwds: {kwds}')\n            print(e)\n            sys.exit(1)\n\n        # Create ainfo, a dict of framework keywords using argument name\n        argn = nonkwds[-1]  # Find the argument name from first 1 or 2 tuple entries\n        if argn[0:2] == \"--\": # Will start with -- for options\n            argn = argn[2:].replace(\"-\", \"_\") # Strip the -- and replace any - in name with _\n        ainfo=dict(a[-1]) #Make a copy so original argspec is not changed\n        for key in ainfo: # Check all keys are valid\n            if key not in (\"def\", \"type\", \"optlog\") : logger.log(\"Invalid argspec framework key: \" + key, \"X\")\n        ainfo['name']=argn\n        if argn == 'log':\n            logdef = ainfo['def'] if 'def' in ainfo else None\n            optlog = ainfo['optlog'] if 'optlog' in ainfo else False\n        arginfo.append(ainfo)\n        if defhelp:\n            arg = nonkwds[0]\n            if 'def' in ainfo:\n                defval = ainfo['def']\n                if argn == 'log' and logdef: defval += \" in logs subdirectory\"\n                deffiles.append([arg, defval])\n            elif 'default' in kwds:\n                defother.append([arg, kwds['default']])\n\n    # if -h d specified, change the help epilog to info about argument defaults\n    if defhelp:\n        if not (deffiles or defother):\n            deftext = \"No defaults for parameters/options\"\n        else:\n            deftext = \"Defaults for parameters/options - see user docs for details\\n\"\n        if deffiles:\n            deftext = deftext + \"\\n  Font/file names\\n\"\n            for (param, defv) in deffiles:\n                deftext = deftext + '    {:<20}{}\\n'.format(param, defv)\n        if defother:\n            deftext = deftext + \"\\n  Other parameters\\n\"\n            for (param, defv) in defother:\n                deftext = deftext + '    {:<20}{}\\n'.format(param, defv)\n        parser.epilog = deftext + \"\\n\\n\" + parser.epilog\n\n    # Parse the command-line arguments. If errors or -h used, procedure will exit here\n    args = parser.parse_args(argv[1:])\n\n    # Process the first positional parameter to get defaults for file names\n    fppval = getattr(args, arginfo[0]['name'])\n    if isinstance(fppval, list): # When nargs=\"+\" or nargs=\"*\" is used a list is returned\n        (fppath, fpbase, fpext) = splitfn(fppval[0])\n        if len(fppval) > 1 : fpbase = \"wildcard\"\n    else:\n        if fppval is None: fppval = \"\"  # For scripts that can be run with no positional parameters\n        (fppath, fpbase, fpext) = splitfn(fppval)  # First pos param use for defaulting\n\n    # Process parameters\n    if chain:\n        execparams = params.sets[\"main\"]\n        args.params = {}  # clparams not used when chaining\n    else:\n        # Read config file from disk if it exists\n        configname = os.path.join(fppath, \"pysilfont.cfg\")\n        if os.path.exists(configname):\n            params.addset(\"config file\", configname, configfile=configname)\n        else:\n            params.addset(\"config file\")  # Create empty set\n        if not quiet and \"scrlevel\" in params.sets[\"config file\"]: logger.scrlevel = params.sets[\"config file\"][\"scrlevel\"]\n\n        # Process command-line parameters\n        clparams = {}\n        if 'params' in args.__dict__:\n            if args.params is not None:\n                for param in args.params:\n                    x = param.split(\"=\", 1)\n                    if len(x) != 2:\n                        logger.log(\"params must be of the form 'param=value'\", \"S\")\n                    if x[1] == \"\\\\t\": x[1] = \"\\t\"  # Special handling for tab characters\n                    clparams[x[0]] = x[1]\n\n        args.params = clparams\n        params.addset(\"command line\", \"command line\", inputdict=clparams)\n        if not quiet and \"scrlevel\" in params.sets[\"command line\"]: logger.scrlevel = params.sets[\"command line\"][\"scrlevel\"]\n\n        # Create main set of parameters based on defaults then update with config file values and command line values\n        params.addset(\"main\", copyset=\"default\")\n        params.sets[\"main\"].updatewith(\"config file\")\n        params.sets[\"main\"].updatewith(\"command line\")\n        execparams = params.sets[\"main\"]\n\n    # Set up logging\n    if chain:\n        setattr(args, 'logger', logger)\n        args.logfile = logger.logfile\n    else:\n        logfile = None\n        logname = args.log if 'log' in args.__dict__ and args.log is not None else \"\"\n        if 'log' in args.__dict__:\n            if logdef is not None and (logname != \"\" or optlog == False):\n                (path, base, ext) = splitfn(logname)\n                (dpath, dbase, dext) = splitfn(logdef)\n                if not path:\n                    if base and ext:  # If both specified then use cwd, ie no path\n                        path = \"\"\n                    else:\n                        path = (fppath if dpath == \"\" else os.path.join(fppath, dpath))\n                        path = os.path.join(path, \"logs\")\n                if not base:\n                    if dbase == \"\":\n                        base = fpbase\n                    elif dbase[0] == \"_\":  # Append to font name if starts with _\n                        base = fpbase + dbase\n                    else:\n                        base = dbase\n                if not ext and dext: ext = dext\n                logname = os.path.join(path, base+ext)\n            if logname == \"\":\n                logfile = None\n            else:\n                (logname, logpath, exists) = fullpath(logname)\n                if not exists:\n                    (parent,subd) = os.path.split(logpath)\n                    if subd == \"logs\" and os.path.isdir(parent): # Create directory if just logs subdir missing\n                        logger.log(\"Creating logs subdirectory in \" + parent, \"P\")\n                        os.makedirs(logpath, exist_ok=True)\n                    else: # Fails, since missing dir is probably a typo!\n                        logger.log(\"Directory \" + parent + \" does not exist\", \"S\")\n                logger.log('Opening log file for output: ' + logname, \"P\")\n                try:\n                    logfile = open(logname, \"w\", encoding=\"utf-8\")\n                except Exception as e:\n                    print(e)\n                    sys.exit(1)\n                args.log = logfile\n        # Set up logger details\n        logger.loglevel = execparams['loglevel'].upper()\n        logger.logfile = logfile\n        if not quiet: logger.scrlevel = \"E\"  # suppress next log message from screen\n        logger.log(\"Running:  \" + \" \".join(argv), \"P\")\n        if not quiet: logger.scrlevel = execparams['scrlevel'].upper()\n        setattr(args, 'logger', logger)\n\n# Process the argument values returned from argparse\n\n    outfont = None\n    infontlist = []\n    for c, ainfo in enumerate(arginfo):\n        aval = getattr(args, ainfo['name'])\n        if ainfo['name'] in ('params', 'log'): continue  # params and log already processed\n        atype = None\n        adef = None\n        if 'type' in ainfo:\n            atype = ainfo['type']\n            if atype not in ('infont', 'outfont', 'infile', 'outfile', 'incsv', 'filename', 'optiondict'):\n                logger.log(\"Invalid type of \" + atype + \" supplied in argspec\", \"X\")\n            if atype != 'optiondict':  # All other types are file types, so adef must be set, even if just to \"\"\n                adef = ainfo['def'] if 'def' in ainfo else \"\"\n            if adef is None and aval is None:  # If def explicitly set to None then this is optional\n                setattr(args, ainfo['name'], None)\n                continue\n\n        if c == 0:\n            if aval is None : logger.log(\"Invalid first positional parameter spec\", \"X\")\n            if aval[-1] in (\"\\\\\",\"/\"): aval = aval[0:-1]  # Remove trailing slashes\n        else:  #Handle defaults for all but first positional parameter\n            if adef is not None:\n                if not aval: aval = \"\"\n#                if aval == \"\" and adef == \"\":  # Only valid for output font parameter\n#                    if atype != \"outfont\":\n#                        logger.log(\"No value suppiled for \" + ainfo['name'], \"S\")\n#                        ## Not sure why this needs to fail - we need to cope with other optional file or filename parameters\n                (apath, abase, aext) = splitfn(aval)\n                (dpath, dbase, dext) = splitfn(adef)  # dpath should be None\n                if not apath:\n                    if abase and aext:  # If both specified then use cwd, ie no path\n                        apath = \"\"\n                    else:\n                        apath = fppath\n                if not abase:\n                    if dbase == \"\":\n                        abase = fpbase\n                    elif dbase[0] == \"_\":  # Append to font name if starts with _\n                        abase = fpbase + dbase\n                    else:\n                        abase = dbase\n                if not aext:\n                    if dext:\n                        aext = dext\n                    elif (atype == 'outfont' or atype == 'infont'): aext = fpext\n                aval = os.path.join(apath, abase+aext)\n\n        # Open files/fonts\n        if atype == 'infont':\n            if tool is None:\n                logger.log(\"Can't specify a font without a font tool\", \"X\")\n            infontlist.append((ainfo['name'], aval))  # Build list of fonts to open when other args processed\n        elif atype == 'infile':\n            logger.log('Opening file for input: '+aval, \"P\")\n            try:\n                aval = open(aval, \"r\", encoding=\"utf-8\")\n            except Exception as e:\n                print(e)\n                sys.exit(1)\n        elif atype == 'incsv':\n            logger.log('Opening file for input: '+aval, \"P\")\n            aval = csvreader(aval, logger=logger)\n        elif atype == 'outfile':\n            (aval, path, exists) = fullpath(aval)\n            if not exists:\n                logger.log(\"Output file directory \" + path + \" does not exist\", \"S\")\n            logger.log('Opening file for output: ' + aval, \"P\")\n            try:\n                aval = open(aval, 'w', encoding=\"utf-8\")\n            except Exception as e:\n                print(e)\n                sys.exit(1)\n        elif atype == 'outfont':\n            if tool is None:\n                logger.log(\"Can't specify a font without a font tool\", \"X\")\n            outfont = aval\n            outfontpath = apath\n            outfontbase = abase\n            outfontext = aext\n\n        elif atype == 'optiondict':  # Turn multiple options in the form ['opt1=a', 'opt2=b'] into a dictionary\n            avaldict={}\n            if aval is not None:\n                for option in aval:\n                    x = option.split(\"=\", 1)\n                    if len(x) != 2:\n                        logger.log(\"options must be of the form 'param=value'\", \"S\")\n                    if x[1] == \"\\\\t\": x[1] = \"\\t\"  # Special handling for tab characters\n                    avaldict[x[0]] = x[1]\n            aval = avaldict\n\n        setattr(args, ainfo['name'], aval)\n\n# Open fonts - needs to be done after processing other arguments so logger and params are defined\n\n    for name, aval in infontlist:\n        if chain and name == 'ifont':\n            aval = chain[\"font\"]\n        else:\n            if tool == \"UFO\": aval = Ufont(aval, params=params)\n            if tool == \"FT\" : aval = ttLib.TTFont(aval)\n            if tool == \"FP\" : aval = OpenFont(aval)\n        setattr(args, name, aval)  # Assign the font object to args attribute\n\n# All arguments processed, now call the main function\n    setattr(args, \"paramsobj\", params)\n    setattr(args, \"cmdlineargs\", argv)\n    newfont = fn(args)\n# If an output font is expected and one is returned, output the font\n    if chainfirst: chain = True # Special handling for first call of chaining\n    if newfont:\n        if chain:  # return font to be handled by chain()\n            return (args, newfont)\n        else:\n            if outfont:\n                # Backup the font if output is overwriting original input font\n                if outfont == infontlist[0][1]:\n                    backupdir = os.path.join(outfontpath, execparams['backupdir'])\n                    backupmax = int(execparams['backupkeep'])\n                    backup = str2bool(execparams['backup'])\n\n                    if backup:\n                        if not os.path.isdir(backupdir):  # Create backup directory if not present\n                            try:\n                                os.mkdir(backupdir)\n                            except Exception as e:\n                                print(e)\n                                sys.exit(1)\n                        backupbase = os.path.join(backupdir, outfontbase+outfontext)\n                        # Work out backup name based on existing backups\n                        nums = sorted([int(i[len(backupbase)+1-len(i):-1]) for i in glob(backupbase+\".*~\")])  # Extract list of backup numbers from existing backups\n                        newnum = max(nums)+1 if nums else 1\n                        backupname = backupbase+\".\"+str(newnum)+\"~\"\n                        # Backup the font\n                        logger.log(\"Backing up input font to \"+backupname, \"P\")\n                        shutil.copytree(outfont, backupname)\n                        # Purge old backups\n                        for i in range(0, len(nums) - backupmax + 1):\n                            backupname = backupbase+\".\"+str(nums[i])+\"~\"\n                            logger.log(\"Purging old backup \"+backupname, \"I\")\n                            shutil.rmtree(backupname)\n                    else:\n                        logger.log(\"No font backup done due to backup parameter setting\", \"I\")\n                # Output the font\n                if tool in (\"FT\", \"FP\"):\n                    logger.log(\"Saving font to \" + outfont, \"P\")\n                    newfont.save(outfont)\n                else:  # Must be Pyslifont Ufont\n                    newfont.write(outfont)\n            else:\n                logger.log(\"Font returned to execute() but no output font is specified in arg spec\", \"X\")\n    elif chain:             # ) When chaining return just args - the font can be accessed by args.ifont\n        return (args, None) # ) assuming that the script has not changed the input font\n\n    if logger.errorcount or logger.warningcount:\n        message = \"Command completed with \" + str(logger.errorcount) + \" errors and \" + str(logger.warningcount) + \" warnings\"\n        if logger.scrlevel in (\"S\", \"E\") and logname != \"\":\n            if logger.scrlevel == \"S\" or logger.warningcount: message = message + \" - see \" + logname\n        if logger.errorcount:\n            if quiet: logger.raisescrlevel(\"E\")\n            logger.log(message, \"E\")\n            logger.resetscrlevel()\n        else:\n            logger.log(message, \"P\")\n        if logger.scrlevel == \"P\" and logger.warningcount: logger.log(\"See log file for warning messages or rerun with '-p scrlevel=w'\", \"P\")\n    else:\n        logger.log(\"Command completed with no warnings\", \"P\")\n\n    return (args, newfont)",
  "def chain(argv, function, argspec, font, params, logger, quiet):  # Chain multiple command-line scripts using UFO module together without writing font to disk\n    ''' argv is a command-line call to a script in sys.argv format.  function and argspec are from the script being called.\n    Although input font name must be supplied for the command line to be parsed correctly by execute() it is not used - instead the supplied\n    font object is used. Similarly -params, logfile and quiet settings in argv are not used by execute() when chaining is used'''\n    if quiet and \"-q\" not in argv: argv.append(\"-q\")\n    logger.log(\"Chaining to \" + argv[0], \"P\")\n    font = execute(\"UFO\", function, argspec, \n        {'argv' : argv, \n            'font'  : font,\n            'params': params,\n            'logger': logger,\n            'quiet' : quiet})\n    logger.log(\"Returning from \" + argv[0], \"P\")\n    return font",
  "def splitfn(fn):  # Split filename into path, base and extension\n    if fn:  # Remove trailing slashes\n        if fn[-1] in (\"\\\\\",\"/\"): fn = fn[0:-1]\n    (path, base) = os.path.split(fn)\n    (base, ext) = os.path.splitext(base)\n    # Handle special case where just a directory is supplied\n    if ext == \"\":  # If there's an extension, treat as file name, eg a ufo directory\n        if os.path.isdir(fn):\n            path = fn\n            base = \"\"\n    return (path, base, ext)",
  "def str2bool(v):  # If v is not a boolean, convert from string to boolean\n    if type(v) == bool: return v\n    v = v.lower()\n    if v in (\"yes\", \"y\", \"true\", \"t\", \"1\"):\n        v = True\n    elif v in (\"no\", \"n\", \"false\", \"f\", \"0\"):\n        v = False\n    else:\n        v = None\n    return v",
  "def fullpath(filen): # Changes file name to one with full path and checks directory exists\n    fullname = os.path.abspath(filen)\n    (fpath,dummy) = os.path.split(fullname)\n    return fullname, fpath, os.path.isdir(fpath)",
  "def __init__(self, logfile=None, loglevels=\"\", leveltext=\"\",  loglevel=\"W\", scrlevel=\"P\"):\n        self.logfile = logfile\n        self.loglevels = loglevels\n        self.leveltext = leveltext\n        self.errorcount = 0\n        self.warningcount = 0\n        if not self.loglevels: self.loglevels = {'X': 0,       'S': 1,       'E': 2,       'P': 3,       'W': 4,       'I': 5,       'V': 6}\n        if not self.leveltext: self.leveltext = ('Exception ', 'Severe:   ', 'Error:    ', 'Progress: ', 'Warning:  ', 'Info:     ', 'Verbose:  ')\n        super(loggerobj, self).__setattr__(\"loglevel\", \"E\") # Temp values so invalid log levels can be reported\n        super(loggerobj, self).__setattr__(\"scrlevel\", \"E\") #\n        self.loglevel = loglevel\n        self.scrlevel = scrlevel",
  "def __setattr__(self, name, value):\n        if name in (\"loglevel\", \"scrlevel\"):\n            if value in self.loglevels:\n                (minlevel, minnum) = (\"E\",2) if name == \"loglevel\" else (\"S\", 1)\n                if self.loglevels[value] < minnum:\n                    value = minlevel\n                    self.log(name + \" increased to minimum level of \" + minlevel, \"E\")\n            else:\n                self.log(\"Invalid \" + name + \" value: \" + value, \"S\")\n        super(loggerobj, self).__setattr__(name, value)\n        if name == \"scrlevel\" : self._basescrlevel = value",
  "def log(self, logmessage, msglevel=\"W\"):\n        levelval = self.loglevels[msglevel]\n        message = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S \") + self.leveltext[levelval] + str(logmessage)\n        #message = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S.%f\")[0:22] +\" \"+ self.leveltext[levelval] + logmessage  ## added milliseconds for timing tests\n        if levelval <= self.loglevels[self.scrlevel]: print(message)\n        if self.logfile and levelval <= self.loglevels[self.loglevel]: self.logfile.write(message + \"\\n\")\n        if msglevel == \"S\":\n            print(\"\\n **** Fatal error - exiting ****\")\n            sys.exit(1)\n        if msglevel == \"X\": assert False, message\n        if msglevel == \"E\": self.errorcount += 1\n        if msglevel == \"W\": self.warningcount += 1",
  "def raisescrlevel(self, level): # Temporarily increase screen logging\n        if level not in self.loglevels or level == \"X\" : self.log(\"Invalid scrlevel: \" + level, \"X\")\n        if self.loglevels[level] > self.loglevels[self.scrlevel]:\n            current = self.scrlevel\n            self.scrlevel = level\n            self._basescrlevel = current\n            self.log(\"scrlevel raised to \" + level, \"I\")",
  "def resetscrlevel(self):\n        self.scrlevel = self._basescrlevel",
  "def __init__(self):\n        # Default parameters for all modules\n        defparams = {}\n        defparams['system'] = {'version': silfont.__version__, 'copyright': silfont.__copyright__}  # Code treats these as read-only\n        defparams['logging'] = {'scrlevel': 'P', 'loglevel': 'W'}\n        defparams['backups'] = {'backup': True, 'backupdir': 'backups', 'backupkeep': 5}\n        # Default parameters for UFO module\n        defparams['outparams'] = OrderedDict([ # Use ordered dict so parameters show in logical order with -h p\n            (\"UFOversion\", \"\"),  # UFOversion - defaults to existing unless a value is supplied\n            (\"indentIncr\",       \"  \"),   # XML Indent increment\n            (\"indentFirst\",      \"  \"),   # First XML indent\n            (\"indentML\",         False),  # Should multi-line string values be indented?\n            (\"plistIndentFirst\", \"\"),     # First indent amount for plists\n            ('precision', 6),             # Decimal precision to use in XML output - both for real values and for attributes if float\n            (\"floatAttribs\", ['xScale', 'xyScale', 'yxScale', 'yScale', 'angle']),  # Used with precision above\n            (\"intAttribs\", ['pos', 'width', 'height', 'xOffset', 'yOffset', 'x', 'y']),\n            (\"sortDicts\",        True),   # Should dict elements be sorted alphabetically?\n            (\"renameGlifs\",      True),   # Rename glifs based on UFO3 suggested algorithm\n            (\"format1Glifs\",     False),  # Force output format 1 glifs including UFO2-style anchors (for use with FontForge\n            (\"glifElemOrder\",    ['advance', 'unicode', 'note',   'image',  'guideline', 'anchor', 'outline', 'lib']),  # Order to output glif elements\n            (\"attribOrders.glif\",['pos', 'width', 'height', 'fileName', 'base', 'xScale', 'xyScale', 'yxScale', 'yScale', 'xOffset', 'yOffset',\n                                  'x', 'y', 'angle', 'type', 'smooth', 'name', 'format', 'color', 'identifier'])\n            ])\n        defparams['ufometadata'] = {\"checkfix\": \"check\"}   # Apply metadata fixes when reading UFOs\n\n        self.paramshelp = {} # Info used when outputting help about parame options\n        self.paramshelp[\"classdesc\"] = {\n            \"logging\": \"controls the level of log messages go to screen or log files.\",\n            \"backups\": \"controls backup settings for scripts that output fonts - by default backups are made if the output font is overwriting the input font\",\n            \"outparams\": \"Output options for UFOs - cover UFO version and normalization\",\n            \"ufometadata\": \"controls if UFO metadata be checked, or checked and fixed\"\n        }\n        self.paramshelp[\"paramsdesc\"] = {\n            \"scrlevel\": \"Logging level for screen messages - one of S,E,P.W,I or V\",\n            \"loglevel\": \"Logging level for log file messages - one of E,P.W,I or V\",\n            \"backup\": \"Should font backups be made\",\n            \"backupdir\": \"Directory to use for font backups\",\n            \"backupkeep\": \"How many backups to keep\",\n            \"indentIncr\": \"XML Indent increment\",\n            \"indentFirst\": \"First XML indent\",\n            \"indentML\": \"Should multi-line string values be indented?\",\n            \"plistIndentFirst\": \"First indent amount for plists\",\n            \"sortDicts\": \"Should dict elements be sorted alphabetically?\",\n            \"precision\": \"Decimal precision to use in XML output - both for real values and for attributes if numeric\",\n            \"renameGlifs\": \"Rename glifs based on UFO3 suggested algorithm\",\n            \"UFOversion\": \"UFOversion to output - defaults to version of the input UFO\",\n            \"format1Glifs\": \"Force output format 1 glifs including UFO2-style anchors (was used with FontForge; no longer needed)\",\n            \"glifElemOrder\": \"Order to output glif elements\",\n            \"floatAttribs\": \"List of float attributes - used when setting decimal precision\",\n            \"intAttribs\": \"List of attributes that should be integers\",\n            \"attribOrders.glif\": \"Order in which to output glif attributes\",\n            \"checkfix\": \"Should check & fix tests be done - one of None, Check or Fix\"\n        }\n        self.paramshelp[\"defaultsdesc\"] = { # For use where default needs clarifying with text\n            \"indentIncr\" : \"<two spaces>\",\n            \"indentFirst\": \"<two spaces>\",\n            \"plistIndentFirst\": \"<No indent>\",\n            \"UFOversion\": \"<Existing version>\"\n        }\n\n        self.classes = {}  # Dictionary containing a list of parameters in each class\n        self.paramclass = {}  # Dictionary of class name for each parameter name\n        self.types = {}  # Python type for each parameter deduced from initial values supplied\n        self.listtypes = {}  # If type is dict, the type of values in the dict\n        self.logger = loggerobj()\n        defset = _paramset(self, \"default\", \"defaults\")\n        self.sets = {\"default\": defset}\n        self.lcase = {}  # Lower case index of parameters names\n        for classn in defparams:\n            self.classes[classn] = []\n            for parn in defparams[classn]:\n                value = defparams[classn][parn]\n                self.classes[classn].append(parn)\n                self.paramclass[parn] = classn\n                self.types[parn] = type(value)\n                if type(value) is list: self.listtypes[parn] = type(value[0])\n                super(_paramset, defset).__setitem__(parn, value)  # __setitem__ in paramset does not allow new values!\n                self.lcase[parn.lower()] = parn",
  "def addset(self, name, sourcedesc=None, inputdict=None, configfile=None, copyset=None):\n        # Create a subset from one of a dict, config file or existing set\n        # Only one option should used per call\n        # sourcedesc should be added for user-supplied data (eg config file) for reporting purposes\n        dict = {}\n        if configfile:\n            config = configparser.ConfigParser()\n            config.read_file(open(configfile, encoding=\"utf-8\"))\n            if sourcedesc is None: sourcedesc = configfile\n            for classn in config.sections():\n                for item in config.items(classn):\n                    parn = item[0]\n                    if self.paramclass[parn] == \"system\":\n                        self.logger.log(\"Can't change \" + parn + \" parameter via config file\", \"S\")\n                    val = item[1].strip('\"').strip(\"'\")\n                    dict[parn] = val\n        elif copyset:\n            if sourcedesc is None: sourcedesc = \"Copy of \" + copyset\n            for parn in self.sets[copyset]:\n                dict[parn] = self.sets[copyset][parn]\n        elif inputdict:\n            dict = inputdict\n        if sourcedesc is None: sourcedesc = \"unspecified source\"\n        self.sets[name] = _paramset(self, name, sourcedesc, dict)",
  "def printhelp(self):\n        phelp = self.paramshelp\n        print(\"\\nMost pysilfont scripts have -p, --params options which can be used to change default behaviour of scripts.  For example '-p scrlevel=w' will log warning messages to screen \\n\")\n        print(\"Listed below are all such parameters, grouped by purpose.  Not all apply to all scripts - \"\n              \"in partucular outparams and ufometadata only apply to scripts using pysilfont's own UFO code\")\n        for classn in (\"logging\", \"backups\", \"ufometadata\", \"outparams\"):\n            print(\"\\n\" + classn[0].upper() + classn[1:] + \" - \" + phelp[\"classdesc\"][classn])\n            for param in self.classes[classn]:\n                if param == \"format1Glifs\": continue # Param due to be phased out\n                paramdesc = phelp[\"paramsdesc\"][param]\n                paramtype = self.types[param].__name__\n                defaultdesc = phelp[\"defaultsdesc\"][param] if param in phelp[\"defaultsdesc\"] else self.sets[\"default\"][param]\n                print('    {:<20}: {}'.format(param, paramdesc))\n                print('       (Type: {:<6} Default: {})'.format(paramtype + \",\", defaultdesc))\n        print(\"\\nNote parameter names are case-insensitive\\n\")\n        print(\"For more help see https://github.com/silnrsi/pysilfont/blob/master/docs/parameters.md\\n\")",
  "def __init__(self, params, name, sourcedesc, inputdict=None):\n        if inputdict is None: inputdict = {}\n        self.name = name\n        self.sourcedesc = sourcedesc  # Description of source for reporting\n        self.params = params  # Parent parameters object\n        for parn in inputdict:\n            if params.paramclass[parn] == \"system\": # system values can't be changed\n                if inputdict[parn] != params.sets[\"default\"][parn]:\n                    self.params.logger.log(\"Can't change \" + parn + \" - system parameters can't be changed\", \"X\")\n                else:\n                    super(_paramset, self).__setitem__(parn, inputdict[parn])\n            else:\n                self[parn] = inputdict[parn]",
  "def __setitem__(self, parn, value):\n        origvalue = value\n        origparn = parn\n        parn = parn.lower()\n        if self.params.paramclass[origparn] == \"system\":\n            self.params.logger.log(\"Can't change \" + parn + \" - system parameters are read-only\", \"X\")\n        if parn not in self.params.lcase:\n            self.params.logger.log(\"Invalid parameter \" + origparn + \" from \" + self.sourcedesc, \"S\")\n        else:\n            parn = self.params.lcase[parn]\n        ptyp = self.params.types[parn]\n        if ptyp is bool:\n            value = str2bool(value)\n            if value is None: self.params.logger.log(self.sourcedesc+\" parameter \"+origparn+\" must be boolean: \" + origvalue, \"S\")\n        if ptyp is list:\n            if type(value) is not list: value = value.split(\",\")  # Convert csv string into list\n            if len(value) < 2: self.params.logger.log(self.sourcedesc+\" parameter \"+origparn+\" must have a list of values: \" + origvalue, \"S\")\n            valuesOK = True\n            listtype = self.params.listtypes[parn]\n            for i, val in enumerate(value):\n                if listtype is bool:\n                    val = str2bool(val)\n                    if val is None: self.params.logger.log (self.sourcedesc+\" parameter \"+origparn+\" must contain boolean values: \" + origvalue, \"S\")\n                    value[i] = val\n                if type(val) != listtype:\n                    valuesOK = False\n                    badtype = str(type(val))\n            if not valuesOK: self.params.logger.log(\"Invalid \"+badtype+\" parameter type for \"+origparn+\": \"+self.params.types[parn], \"S\")\n        if parn in (\"loglevel\", \"scrlevel\"):  # Need to check log level is valid before setting it since otherwise logging will fail\n            value = value.upper()\n            if value not in self.params.logger.loglevels: self.params.logger.log (self.sourcedesc+\" parameter \"+parn+\" invalid\", \"S\")\n        super(_paramset, self).__setitem__(parn, value)",
  "def updatewith(self, update, sourcedesc=None, log=True):\n        # Update a set with values from another set\n        if sourcedesc is None: sourcedesc = self.params.sets[update].sourcedesc\n        for parn in self.params.sets[update]:\n            oldval = self[parn] if parn in self else \"\"\n            self[parn] = self.params.sets[update][parn]\n            if log and oldval != \"\" and self[parn] != oldval:\n                old = str(oldval)\n                new = str(self[parn])\n                if old != old.strip() or new != new.strip():   # Add quotes if there are leading or trailing spaces\n                    old = '\"'+old+'\"'\n                    new = '\"'+new+'\"'\n                self.params.logger.log(sourcedesc + \" parameters: changing \"+parn+\" from \" + old + \" to \" + new, \"I\")",
  "def __init__(self, filename, minfields=0, maxfields=999, numfields=None, logger=None):\n        self.filename = filename\n        self.minfields = minfields\n        self.maxfields = maxfields\n        self.numfields = numfields\n        self.logger = logger if logger else loggerobj()   # If no logger supplied, will just log to screen\n        # Open the file and create reader\n        try:\n            file = open(filename, \"rt\", encoding=\"utf-8\")\n        except Exception as e:\n            print(e)\n            sys.exit(1)\n        self.file = file\n        self.reader = csv.reader(file)\n        # Find the first non-comment line then reset so __iter__ still returns the first line\n        # This is so scripts can analyse first line (eg to look for headers) before starting iterating\n        self.firstline = None\n        self._commentsbeforefirstline = -1\n        while not self.firstline:\n            row = next(self.reader, None)\n            if row is None: logger.log(\"Input csv is empty or all lines are comments or blank\", \"S\")\n            self._commentsbeforefirstline += 1\n            if row == []: continue  # Skip blank lines\n            if row[0].lstrip().startswith(\"#\"): continue  # Skip comments - ie lines starting with  #\n            self.firstline = row\n        file.seek(0) # Reset the csv and skip comments\n        for i in range(self._commentsbeforefirstline): next(self.reader, None)",
  "def __setattr__(self, name, value):\n        if name == \"numfields\" and value is not None:  # If numfields is changed, reset min and max fields\n            self.minfields = value\n            self.maxfields = value\n        super(csvreader, self).__setattr__(name, value)",
  "def __iter__(self):\n        for row in self.reader:\n            self.line_num = self.reader.line_num - 1 - self._commentsbeforefirstline # Count is out due to reading first line in __init__\n            if row == []: continue  # Skip blank lines\n            if row[0].lstrip().startswith(\"#\"): continue  # Skip comments - ie lines starting with  #\n            if len(row) < self.minfields or len(row) > self.maxfields:\n                self.logger.log(\"Invalid number of fields on line \" + str(self.line_num) + \" in \"+self.filename, \"E\" )\n                continue\n            yield row",
  "class SVGPen(BasePen) :\n\n    def __init__(self, glyphSet, scale=1.0) :\n        super(SVGPen, self).__init__(glyphSet);\n        self.__commands = []\n        self.__scale = scale\n\n    def __str__(self) :\n        return \" \".join(self.__commands)\n\n    def scale(self, pt) :\n        return ((pt[0] or 0) * self.__scale, (pt[1] or 0) * self.__scale)\n\n    def _moveTo(self, pt):\n        self.__commands.append(\"M {0[0]} {0[1]}\".format(self.scale(pt)))\n\n    def _lineTo(self, pt):\n        self.__commands.append(\"L {0[0]} {0[1]}\".format(self.scale(pt)))\n\n    def _curveToOne(self, pt1, pt2, pt3) :\n        self.__commands.append(\"C {0[0]} {0[1]} {1[0]} {1[1]} {2[0]} {2[1]}\".format(self.scale(pt1), self.scale(pt2), self.scale(pt3)))\n\n    def _closePath(self) :\n        self.__commands.append(\"Z\")\n\n    def clear(self) :\n        self.__commands = []",
  "def _svgheader():\n    return '''<?xml version=\"1.0\"?>\n<svg xmlns=\"https://www.w3.org/2000/svg\" xmlns:xlink=\"https://www.w3.org/1999/xlink\" version=\"1.1\">\n'''",
  "def _bbox(f, gnames, points, scale=1):\n    gset = f.glyphSet\n    bbox = (0, 0, 0, 0)\n    for i, gname in enumerate(gnames):\n        if hasattr(points, '__len__') and i == len(points):\n            points.append((bbox[2] / scale, 0))\n        pt = points[i] if i < len(points) else (0, 0)\n        g = gset[gname]._glyph\n        if g is None or not hasattr(g, 'xMin') :\n            gbox = (0, 0, 0, 0)\n        else :\n            gbox = (g.xMin * scale, g.yMin * scale, g.xMax * scale, g.yMax * scale)\n        bbox = arrayTools.unionRect(bbox, arrayTools.offsetRect(gbox, pt[0] * scale, pt[1] * scale))\n    return bbox",
  "def _defglyphs(f, gnames, scale=1):\n    global glyphsetcount\n    glyphsetcount += 1\n    gset = f.glyphSet\n    p = SVGPen(gset, scale)\n    res = \"<defs><g>\\n\"\n    for gname in sorted(set(gnames)):\n        res += '<symbol overflow=\"visible\" id=\"{}_{}\">\\n'.format(gname, glyphsetcount)\n        g = gset[gname]\n        p.clear()\n        g.draw(p)\n        res += '<path style=\"stroke:none;\" d=\"' + str(p) + '\"/>\\n</symbol>\\n'\n    res += \"</g></defs>\\n\"\n    return res",
  "def loadFont(fname):\n    if fname.lower().endswith(\".ufo\"):\n        ufo = Font(fname)\n        f = compileTTF(ufo)\n    else:\n        f = ttLib.TTFont(fname)\n    return f",
  "def displayGlyphs(f, gnames, points=None, scale=None):\n    if not hasattr(gnames, '__len__') or isinstance(gnames, basestring):\n        gnames = [gnames]\n    if not hasattr(points, '__len__'):\n        points = []\n    if not hasattr(f, 'glyphSet'):\n        f.glyphSet = f.getGlyphSet()\n    res = _svgheader()\n    if points is None:\n        points = []\n    bbox = _bbox(f, gnames, points, scale or 1)\n    maxh = 100.\n    height = bbox[3] - (bbox[1] if bbox[1] < 0 else 0)\n    if scale is None and height > maxh:\n        scale = maxh / height\n        bbox = [x  * scale for x in bbox]\n    res += _defglyphs(f, gnames, scale)\n    res += '<g id=\"surface1\" transform=\"matrix(1,0,0,-1,{},{})\">\\n'.format(-bbox[0], bbox[3])\n    res += '  <rect x=\"{}\" y=\"{}\" width=\"{}\" height=\"{}\" style=\"fill:white;stroke:none\"/>\\n'.format(\n        bbox[0], bbox[1], bbox[2]-bbox[0], bbox[3])\n    res += '  <g style=\"fill:black\">\\n'\n    for i, gname in enumerate(gnames):\n        pt = points[i] if i < len(points) else (0, 0)\n        res += '    <use xlink:href=\"#{0}_{3}\" x=\"{1}\" y=\"{2}\"/>\\n'.format(gname, pt[0] * scale, pt[1] * scale, glyphsetcount)\n    res += '  </g></g>\\n</svg>\\n'\n    return SVG(data=res)",
  "def displayText(f, text, features = [], lang=None, dir=\"\", script=\"\", shapers=\"\", size=0):\n    import harfbuzz\n    glyphs = harfbuzz.shape_text(f, text, features, lang, dir, script, shapers)\n    gnames = []\n    points = []\n    x = 0\n    y = 0\n    for g in glyphs:\n        gnames.append(f.getGlyphName(g.gid))\n        points.append((x+g.offset[0], y+g.offset[1]))\n        x += g.advance[0]\n        y += g.advance[1]\n    if size == 0:\n        scale = None\n    else:\n        upem = f['head'].unitsPerEm\n        scale = 4. * size / (upem * 3.)\n    return displayGlyphs(f, gnames, points, scale=scale)",
  "def displayRaw(text):\n    # res = \"<html><body>\"+text.encode('utf-8')+\"</body></html>\"\n    res = u\"<html><body><p>\"+text+u\"</p></body></html>\"\n    return HTML(data=res)",
  "def __init__(self, glyphSet, scale=1.0) :\n        super(SVGPen, self).__init__(glyphSet);\n        self.__commands = []\n        self.__scale = scale",
  "def __str__(self) :\n        return \" \".join(self.__commands)",
  "def scale(self, pt) :\n        return ((pt[0] or 0) * self.__scale, (pt[1] or 0) * self.__scale)",
  "def _moveTo(self, pt):\n        self.__commands.append(\"M {0[0]} {0[1]}\".format(self.scale(pt)))",
  "def _lineTo(self, pt):\n        self.__commands.append(\"L {0[0]} {0[1]}\".format(self.scale(pt)))",
  "def _curveToOne(self, pt1, pt2, pt3) :\n        self.__commands.append(\"C {0[0]} {0[1]} {1[0]} {1[1]} {2[0]} {2[1]}\".format(self.scale(pt1), self.scale(pt2), self.scale(pt3)))",
  "def _closePath(self) :\n        self.__commands.append(\"Z\")",
  "def clear(self) :\n        self.__commands = []",
  "class FTML(object):\n    \"\"\"a staging class for collecting ftml content and finally writing the xml\"\"\"\n\n    # Assumes no nesting of test groups\n\n    def __init__(self, title, logger, comment = None, fontsrc = None, fontlabel = None, fontscale = None,\n                 widths = None, rendercheck = True, xslfn = None, defaultrtl = False):\n        self.logger = logger\n        # Initialize an Fxml object\n        fxml = Fxml(testgrouplabel = \"dummy\")\n        fxml.stylesheet = {'type': 'text/xsl', 'href': xslfn if xslfn is not None else 'ftml.xsl'}\n        fxml.head.title = title\n        fxml.head.comment = comment\n        if isinstance(fontsrc, (tuple, list)):\n            # Allow multiple fontsrc\n            fxml.head.fontsrc = [Ffontsrc(fxml.head, text=fontsrc,\n                                          label=fontlabel[i] if fontlabel is not None and i < len(fontlabel) else None)\n                                 for i, fontsrc in enumerate(fontsrc)]\n        elif fontsrc:\n            fxml.head.fontsrc = Ffontsrc(fxml.head, text=fontsrc, label=fontlabel)\n\n        if fontscale: fxml.head.fontscale = int(fontscale)\n        if widths: fxml.head.widths = widths\n        fxml.testgroups.pop() # Remove dummy test group\n        # Save object\n        self._fxml = fxml\n        # Initialize state\n        self._curTest = None\n        self.closeTestGroup()\n        self.defaultRTL = defaultrtl\n        # Add first testgroup if requested\n        if rendercheck:\n            self.startTestGroup(\"Rendering Check\", background=\"#F0F0F0\")\n            self.addToTest(None, \"RenderingUnknown\", \"check\", rtl = False)\n            self.closeTest()\n            self.closeTestGroup()\n\n    _colorMap = {\n        'aqua':    '#00ffff',\n        'black':   '#000000',\n        'blue':    '#0000ff',\n        'fuchsia': '#ff00ff',\n        'green':   '#008000',\n        'grey':    '#808080',\n        'lime':    '#00ff00',\n        'maroon':  '#800000',\n        'navy':    '#000080',\n        'olive':   '#808000',\n        'purple':  '#800080',\n        'red':     '#ff0000',\n        'silver':  '#c0c0c0',\n        'teal':    '#008080',\n        'white':   '#ffffff',\n        'yellow':  '#ffff00',\n        'orange':  '#ffa500'\n    }\n\n    @staticmethod\n    def _getColor(color):\n        if color is None or len(color) == 0:\n            return None\n        color = color.lower()\n        if color in FTML._colorMap:\n            return FTML._colorMap[color]\n        if re.match(r'#[0-9a-f]{6}$', color):\n            return color\n        self.logger.log(f'Color \"{color}\" not understood; ignored', 'W')\n        return None\n\n    def closeTest(self, comment = None):\n        if self._curTest:\n            if comment is not None:\n                self._curTest.comment = comment\n            if self._curColor:\n                self._curTest.background = self._curColor\n        self._curTest = None\n        self._lastUID = None\n        self._lastRTL = None\n\n    def addToTest(self, uid, s = \"\", label = None, comment = None, rtl = None):\n        if rtl is None: rtl = self.defaultRTL\n        if (self._lastUID and uid and uid not in range(self._lastUID, self._lastUID + 2))\\\n                or (self._lastRTL is not None and rtl != self._lastRTL):\n            self.closeTest()\n        self._lastUID = uid\n        self._lastRTL = rtl\n        if self._curTestGroup is None:\n            # Create a new Ftestgroup\n            self.startTestGroup(\"Group\")\n        if self._curTest is None:\n            # Create a new Ftest\n            if label is None:\n                label = \"U+{0:04X}\".format(uid) if uid is not None else \"test\"\n            test = Ftest(self._curTestGroup, label = label, string = '')\n            if comment:\n                test.comment = comment\n            if rtl: test.rtl = \"True\"\n            # Construct stylename and add style if needed:\n            x = ['{}_{}'.format(t,v) for t,v in self._curFeatures.items()] if self._curFeatures else []\n            if self._curLang:\n                x.insert(0,self._curLang)\n            if len(x):\n                test.stylename = '_'.join(x)\n                self._fxml.head.addstyle(test.stylename, feats = self._curFeatures, lang = self._curLang)\n            # Append to current test group\n            self._curTestGroup.tests.append(test)\n            self._curTest = test\n        if len(self._curTest.string): self._curTest.string += ' '\n        # Special hack until we get to python3 with full unicode support\n        self._curTest.string += ''.join([ c if ord(c) < 128 else '\\\\u{0:06X}'.format(ord(c)) for c in s ])\n        # self._curTest.string += s\n\n    def setFeatures(self, features):\n        # features can be None or a list; list elements can be:\n        #   None\n        #   a feature setting in the form [tag,value]\n        if features is None:\n            return self.clearFeatures()\n        features = [x for x in features if x]\n        if len(features) == 0:\n            return self.clearFeatures()\n        features = dict(features)   # Convert to a dictionary -- this is what we'll keep.\n        if features != self._curFeatures:\n            self.closeTest()\n        self._curFeatures = features\n\n    def clearFeatures(self):\n        if self._curFeatures is not None:\n            self.closeTest()\n        self._curFeatures = None\n\n    def setLang(self, langID):\n        if langID != self._curLang:\n            self.closeTest();\n        self._curLang = langID\n\n    def clearLang(self):\n        if self._curLang:\n            self.closeTest()\n        self._curLang = None\n\n    def setBackground(self, color):\n        color = self._getColor(color)\n        if color != self._curColor:\n            self.closeTest()\n        self._curColor = color\n\n    def clearBackground(self):\n        if self._curColor is not None:\n            self.closeTest()\n        self._curColor = None\n\n    def closeTestGroup(self):\n        self.closeTest()\n        self._curTestGroup = None\n        self._curFeatures = None\n        self._curLang = None\n        self._curColor = None\n\n    def startTestGroup(self, label, background = None):\n        if self._curTestGroup is not None:\n            if label == self._curTestGroup.label:\n                return\n            self.closeTestGroup()\n        # Add new test group\n        self._curTestGroup = Ftestgroup(self._fxml, label = label)\n        background = self._getColor(background)\n        if background is not None:\n            self._curTestGroup.background = background\n\n        # append to root test groups\n        self._fxml.testgroups.append(self._curTestGroup)\n\n    def writeFile(self, output):\n        self.closeTestGroup()\n        self._fxml.save(output)",
  "class Feature(object):\n    \"\"\"abstraction of a feature\"\"\"\n\n    def __init__(self, tag):\n        self.tag = tag\n        self.default = 0\n        self.maxval = 1\n        self._tvlist = None\n\n    def __getattr__(self,name):\n        if name == \"tvlist\":\n            # tvlist is a list of all possible tag,value pairs (except the default but including None) for this feature\n            # This attribute shouldn't be needed until all the possible feature value are known,\n            # therefore we'll generate this the first time we need it and save it\n            if self._tvlist is None:\n                self._tvlist = [ None ]\n                for v in range (0, self.maxval+1):\n                    if v != self.default:\n                        self._tvlist.append( [self.tag, str(v)])\n            return self._tvlist",
  "class FChar(object):\n    \"\"\"abstraction of an encoded glyph in the font\"\"\"\n\n    def __init__(self, uids, basename, logger):\n        self.logger = logger\n        # uids can be a singleton integer or, for multiple-encoded glyphs, some kind of sequence of integers\n        if isinstance(uids,collections.abc.Sequence):\n            uids1 = uids\n        else:\n            uids1 = (uids,)\n        # test each uid to make sure valid; remove if not.\n        uids2=[]\n        self.general = \"unknown\"\n        for uid in uids1:\n            try:\n                gc = get_ucd(uid,'gc')\n                if self.general == \"unknown\":\n                    self.general = gc\n                uids2.append(uid)\n            except (TypeError, IndexError):\n                self.logger.log(f'Invalid USV \"{uid}\" -- ignored.', 'E')\n                continue\n            except KeyError:\n                self.logger.log('USV %04X not defined; no properties known' % uid, 'W')\n        # make sure there's at least one left\n        assert len(uids2) > 0, f'No valid USVs found in {repr(uids)}'\n        self._uids = tuple(uids2)\n        self.basename = basename\n        self.feats = set()  # feat tags that affect this char\n        self.langs = set()  # lang tags that affect this char\n        self.aps = set()\n        self.altnames = {}  # alternate glyph names.\n            # the above is a dict keyed by either:\n            #   lang tag e.g., 'ur', or\n            #   feat tag and value, e.g., 'cv24=3'\n            # and returns a the glyphname for that alternate.\n        # Additional info from UFO:\n        self.takesMarks = self.isMark = self.isBase = self.notInUFO = False\n\n    # Most callers don't need to support or or care about multiple-encoded glyphs, so we\n    # support the old .uid attribute by returning the first (I guess we consider it primary) uid.\n    def __getattr__(self,name):\n        if name == 'uids':\n            return self._uids\n        elif name == 'uid':\n            return self._uids[0]\n        else:\n            raise AttributeError\n\n    # the static method FTMLBuilder.checkGlyph is likely preferred\n    #   but leave this instance method for backwards compatibility\n    def checkGlyph(self, gname, font, apRE):\n        # glean info from UFO if glyph is present\n        if gname in font.deflayer:\n            self.notInUFO = False\n            for a in font.deflayer[gname]['anchor'] :\n                name = a.element.get('name')\n                if apRE.match(name) is None:\n                    continue\n                self.aps.add(name)\n                if name.startswith(\"_\") :\n                    self.isMark = True\n                else:\n                    self.takesMarks = True\n            self.isBase = self.takesMarks and not self.isMark\n        else:\n            self.notInUFO = True",
  "class FSpecial(object):\n    \"\"\"abstraction of a ligature or other interesting sequence\"\"\"\n\n    # Similar to FChar but takes a uid list rather than a single uid\n    def __init__(self, uids, basename, logger):\n        self.logger = logger\n        self.uids = uids\n        self.basename = basename\n        # a couple of properties based on the first uid:\n        try:\n            self.general = get_ucd(uids[0],'gc')\n        except KeyError:\n            self.logger.log('USV %04X not defined; no properties known' % uids[0], 'W')\n        self.feats = set()  # feat tags that affect this char\n        self.aps = set()\n        self.langs = set()  # lang tags that affect this char\n        self.altnames = {}  # alternate glyph names.\n        self.takesMarks = self.isMark = self.isBase = self.notInUFO = False",
  "class FTMLBuilder(object):\n    \"\"\"glyph_data and UFO processing for building FTML\"\"\"\n\n    def __init__(self, logger, incsv = None, fontcode = None, font = None, langs = None, rtlenable = False, ap = None ):\n        self.logger = logger\n        self.rtlEnable = rtlenable\n\n        # Default diacritic base:\n        self.diacBase = 0x25CC\n\n        # Default joinBefore and joinAfter sequence\n        self.joinBefore = '\\u200D'  # put before a sequence to force joining shape; def = zwj\n        self.joinAfter = '\\u200D'   # put after a sequence to force joining shape; def = zwj\n\n        # Dict mapping tag to Feature\n        self.features = {}\n\n        # Set of all languages seen\n        if langs is not None:\n            # Use a list so we keep the order (assuming caller wouldn't give us dups\n            self.allLangs = list(re.split(r'\\s*[\\s,]\\s*', langs)) # Allow comma- or space-separated tags\n            self._langsComplete = True  # We have all the lang tags desired\n        else:\n            # use a set because the langtags are going to dribble in and be repeated.\n            self.allLangs = set()\n            self._langsComplete = False # Add lang_tags from glyph_data\n\n        # Be able to find chars and specials:\n        self._charFromUID = {}\n        self._charFromBasename = {}\n        self._specialFromUIDs = {}\n        self._specialFromBasename = {}\n\n        # list of USVs that are in the CSV but whose glyphs are not in the UFO\n        self.uidsMissingFromUFO = set()\n\n        # DummyUSV  (see charAuto())\n        self.curDummyUSV = 0x100000 # Supplemental Private Use Area B\n\n        # Compile --ap parameter\n        if ap is None:\n            ap = \".\"\n        try:\n            self.apRE = re.compile(ap)\n        except re.error as e:\n            logger.log(\"--ap parameter '{}' doesn't compile as regular expression: {}\".format(ap, e), \"S\")\n\n        if incsv is not None:\n            self.readGlyphData(incsv, fontcode, font)\n\n    def addChar(self, uids, basename):\n        # Add an FChar\n        # assume parameters are OK:\n        c = FChar(uids, basename, self.logger)\n        # fatal error if the basename or any of uids have already been seen\n        fatal = False\n        for uid in c.uids:\n            if uid in self._charFromUID:\n                self.logger.log('Attempt to add duplicate USV %04X' % uid, 'E')\n                fatal = True\n            self._charFromUID[uid] = c\n        if basename in self._charFromBasename:\n            self.logger.log('Attempt to add duplicate basename %s' % basename, 'E')\n            fatal = True\n        self._charFromBasename[basename] = c\n        if fatal:\n            self.logger.log('Cannot continue due to previous errors', 'S')\n        return c\n\n    def uids(self):\n        \"\"\" returns list of uids in glyph_data \"\"\"\n        return self._charFromUID.keys()\n\n    def char(self, x):\n        \"\"\" finds an FChar based either basename or uid;\n            generates KeyError if not found.\"\"\"\n        return self._charFromBasename[x] if isinstance(x, str) else self._charFromUID[x]\n\n    def charAuto(self, x):\n        \"\"\" Like char() but will issue a warning and add a dummy \"\"\"\n        try:\n            return self._charFromBasename[x] if isinstance(x, str) else self._charFromUID[x]\n        except KeyError:\n            # Issue error message and create dummy Char object for this character\n            if isinstance(x, str):\n                self.logger.log(f'Glyph \"{x}\" isn\\'t in glyph_data.csv - adding dummy', 'E')\n                while self.curDummyUSV in self._charFromUID:\n                    self.curDummyUSV += 1\n                c = self.addChar(self.curDummyUSV, x)\n            else:\n                self.logger.log(f'Char U+{x:04x} isn\\'t in glyph_data.csv - adding dummy', 'E')\n                c = self.addChar(x, f'U+{x:04x}')\n            return c\n\n    def addSpecial(self, uids, basename):\n        # Add an FSpecial:\n        # fatal error if basename has already been seen:\n        if basename in self._specialFromBasename:\n            self.logger.log('Attempt to add duplicate basename %s' % basename, 'S')\n        c = FSpecial(uids, basename, self.logger)\n        # remember it:\n        self._specialFromUIDs[tuple(uids)] = c\n        self._specialFromBasename[basename] = c\n        return c\n\n    def specials(self):\n        \"\"\"returns a list of the basenames of specials\"\"\"\n        return self._specialFromBasename.keys()\n\n    def special(self, x):\n        \"\"\" finds an FSpecial based either basename or uid sequence;\n            generates KeyError if not found.\"\"\"\n        return self._specialFromBasename[x] if isinstance(x, str) else self._specialFromUIDs[tuple(x)]\n\n    def _csvWarning(self, msg, exception = None):\n        m = \"glyph_data line {1}: {0}\".format(msg, self.incsv.line_num)\n        if exception is not None:\n            m += '; ' + str(exception)\n        self.logger.log(m, 'W')\n\n    def readGlyphData(self, incsv, fontcode = None, font = None):\n        # Remember csv file for other methods:\n        self.incsv = incsv\n\n        # Validate fontcode, if provided\n        if fontcode is not None:\n            whichfont = fontcode.strip().lower()\n            if len(whichfont) != 1:\n                self.logger.log('fontcode must be a single letter', 'S')\n        else:\n            whichfont = None\n\n        # Get headings from csvfile:\n        fl = incsv.firstline\n        if fl is None: self.logger.log(\"Empty input file\", \"S\")\n        # required columns:\n        try:\n            nameCol = fl.index('glyph_name');\n            usvCol = fl.index('USV')\n        except ValueError as e:\n            self.logger.log('Missing csv input field: ' + str(e), 'S')\n        except Exception as e:\n            self.logger.log('Error reading csv input field: ' + str(e), 'S')\n        # optional columns:\n        # If -f specified, make sure we have the fonts column\n        if whichfont is not None:\n            if 'Fonts' not in fl: self.logger.log('-f requires \"Fonts\" column in glyph_data', 'S')\n            fontsCol = fl.index('Fonts')\n        # Allow for projects that use only production glyph names (ps_name same as glyph_name)\n        psCol = fl.index('ps_name') if 'ps_name' in fl else nameCol\n        # Allow for projects that have no feature and/or lang-specific behaviors\n        featCol = fl.index('Feat') if 'Feat' in fl else None\n        bcp47Col = fl.index('bcp47tags') if 'bcp47tags' in fl else None\n\n        next(incsv.reader, None)  # Skip first line with headers\n\n        # RE that matches names of glyphs we don't care about\n        namesToSkipRE = re.compile('^(?:[._].*|null|cr|nonmarkingreturn|tab|glyph_name)$',re.IGNORECASE)\n\n        # RE that matches things like 'cv23' or 'cv23=4' or 'cv23=2,3'\n        featRE = re.compile('^(\\w{2,4})(?:=([\\d,]+))?$')\n\n        # RE that matches USV sequences for ligatures\n        ligatureRE = re.compile('^[0-9A-Fa-f]{4,6}(?:_[0-9A-Fa-f]{4,6})+$')\n        \n        # RE that matches space-separated USV sequences\n        USVsRE = re.compile('^[0-9A-Fa-f]{4,6}(?:\\s+[0-9A-Fa-f]{4,6})*$')\n\n        # keep track of glyph names we've seen to detect duplicates\n        namesSeen = set()\n        psnamesSeen = set()\n\n        # OK, process all records in glyph_data\n        for line in incsv:\n            gname = line[nameCol].strip()\n\n            # things to ignore:\n            if namesToSkipRE.match(gname):\n                continue\n            if whichfont is not None and line[fontsCol] != '*' and line[fontsCol].lower().find(whichfont) < 0:\n                continue\n            if len(gname) == 0:\n                self._csvWarning('empty glyph name in glyph_data; ignored')\n                continue\n            if gname.startswith('#'):\n                continue\n            if gname in namesSeen:\n                self._csvWarning('glyph name %s previously seen in glyph_data; ignored' % gname)\n                continue\n\n            psname = line[psCol].strip() or gname   # If psname absent, working name will be production name\n            if psname in psnamesSeen:\n                self._csvWarning('psname %s previously seen; ignored' % psname)\n                continue\n            namesSeen.add(gname)\n            psnamesSeen.add(psname)\n\n            # compute basename-- the glyph name without extensions:\n            basename = gname.split('.',1)[0]\n\n            # Process USV(s)\n            # could be empty string, a single USV, space-separated list of USVs for multiple encoding,\n            # or underscore-connected USVs indicating ligatures.\n\n            usvs = line[usvCol].strip()\n            if len(usvs) == 0:\n                # Empty USV field, unencoded glyph\n                usvs = ()\n            elif USVsRE.match(usvs):\n                # space-separated hex values:\n                usvs = usvs.split()\n                isLigature = False\n            elif ligatureRE.match(usvs):\n                # '_' separated hex values (ligatures)\n                usvs = usvs.split('_')\n                isLigature = True\n            else:\n                self._csvWarning(f\"invalid USV field '{usvs}'; ignored\")\n                usvs = ()\n            uids = [int(x, 16) for x in usvs]\n\n            if len(uids) == 0:\n                # Handle unencoded glyphs\n                uids = None # Prevents using this record to set default feature values\n                if basename in self._charFromBasename:\n                    c = self._charFromBasename[basename]\n                    # Check for additional AP info\n                    c.checkGlyph(gname, font, self.apRE)\n                elif basename in self._specialFromBasename:\n                    c = self._specialFromBasename[basename]\n                else:\n                    self._csvWarning('unencoded variant %s found before encoded glyph' % gname)\n                    c = None\n            elif isLigature:\n                # Handle ligatures\n                c = self.addSpecial(uids, basename)\n                uids = None  # Prevents using this record to set default feature values  (TODO: Research this)\n            else:\n                # Handle simple encoded glyphs (could be multiple uids!)\n                # Create character object\n                c = self.addChar(uids, basename)\n                if font is not None:\n                    # Examine APs to determine if this character takes marks:\n                    c.checkGlyph(gname, font, self.apRE)\n                    if c.notInUFO:\n                        self.uidsMissingFromUFO.update(uids)\n\n            if featCol is not None:\n                feats = line[featCol].strip()\n                if len(feats) > 0 and not(feats.startswith('#')):\n                    feats = feats.split(';')\n                    for feat in feats:\n                        m = featRE.match(feat)\n                        if m is None:\n                            self._csvWarning('incorrectly formed feature specification \"%s\"; ignored' % feat)\n                        else:\n                            # find/create structure for this feature:\n                            tag = m.group(1)\n                            try:\n                                feature = self.features[tag]\n                            except KeyError:\n                                feature = Feature(tag)\n                                self.features[tag] = feature\n                            # if values supplied, collect default and maximum values for this feature:\n                            if m.group(2) is not None:\n                                vals = [int(i) for i in m.group(2).split(',')]\n                                if len(vals) > 0:\n                                    if uids is not None:\n                                        feature.default = vals[0]\n                                    elif len(feats) == 1:  # TODO: This seems like wrong test.\n                                        for v in vals:\n                                            # remember the glyph name for this feature/value combination:\n                                            feat = '{}={}'.format(tag,v)\n                                            if c is not None and feat not in c.altnames:\n                                                c.altnames[feat] = gname\n                                    vals.append(feature.maxval)\n                                    feature.maxval = max(vals)\n                            if c is not None:\n                                # Record that this feature affects this character:\n                                c.feats.add(tag)\n                            else:\n                                self._csvWarning('untestable feature \"%s\" : no known USV' % tag)\n\n            if bcp47Col is not None:\n                bcp47 = line[bcp47Col].strip()\n                if len(bcp47) > 0 and not(bcp47.startswith('#')):\n                    if c is not None:\n                        for tag in re.split(r'\\s*[\\s,]\\s*', bcp47): # Allow comma- or space-separated tags\n                            c.langs.add(tag)        # lang-tags mentioned for this character\n                            if not self._langsComplete:\n                                self.allLangs.add(tag)  # keep track of all possible lang-tags\n                    else:\n                        self._csvWarning('untestable langs: no known USV')\n\n        # We're finally done, but if allLangs is a set, let's order it (for lack of anything better) and make a list:\n        if not self._langsComplete:\n            self.allLangs = list(sorted(self.allLangs))\n\n    def permuteFeatures(self, uids = None, feats = None):\n        \"\"\" returns an iterator that provides all combinations of feature/value pairs, for a list of uids and/or a specific list of feature tags\"\"\"\n        feats = set(feats) if feats is not None else set()\n        if uids is not None:\n            for uid in uids:\n                if uid in self._charFromUID:\n                    feats.update(self._charFromUID[uid].feats)\n        l = [self.features[tag].tvlist for tag in sorted(feats)]\n        return product(*l)\n\n    @staticmethod\n    def checkGlyph(obj, gname, font, apRE):\n        # glean info from UFO if glyph is present\n        if gname in font.deflayer:\n            obj.notInUFO = False\n            for a in font.deflayer[gname]['anchor']:\n                name = a.element.get('name')\n                if apRE.match(name) is None:\n                    continue\n                obj.aps.add(name)\n                if name.startswith(\"_\"):\n                    obj.isMark = True\n                else:\n                    obj.takesMarks = True\n            obj.isBase = obj.takesMarks and not obj.isMark\n        else:\n            obj.notInUFO = True\n\n    @staticmethod\n    def matchMarkBase(c_mark, c_base):\n        \"\"\" test whether an _AP on c_mark matches an AP on c_base \"\"\"\n        for apM in c_mark.aps:\n            if apM.startswith(\"_\"):\n                ap = apM[1:]\n                for apB in c_base.aps:\n                    if apB == ap:\n                        return True\n        return False\n\n    def render(self, uids, ftml, keyUID = 0, addBreaks = True, rtl = None, dualJoinMode = 3, label = None, comment = None):\n        \"\"\" general purpose (but not required) function to generate ftml for a character sequence \"\"\"\n        if len(uids) == 0:\n            return\n        # Make a copy so we don't affect caller\n        uids = list(uids)\n        # Remember first uid and original length for later\n        startUID = uids[0]\n        uidLen = len(uids)\n        # if keyUID wasn't supplied, use startUID\n        if keyUID == 0: keyUID = startUID\n        if label is None:\n            # Construct label from uids:\n            label = '\\n'.join(['U+{0:04X}'.format(u) for u in uids])\n        if comment is None:\n            # Construct comment from glyph names:\n            comment = ' '.join([self._charFromUID[u].basename for u in uids])\n        # see if uid list includes a mirrored char\n        hasMirrored = bool(len([x for x in uids if get_ucd(x,'Bidi_M')]))\n        # Analyze first and last joining char\n        joiningChars = [x for x in uids if get_ucd(x, 'jt') != 'T']\n        if len(joiningChars):\n            # If first or last non-TRANSPARENT char is a joining char, then we need to emit examples with zwj\n            # Assumes any non-TRANSPARENT char that is bc != L must be a rtl character of some sort\n            uid = joiningChars[0]\n            zwjBefore = (get_ucd(uid,'jt') == 'D'\n                         or (get_ucd(uid,'bc') == 'L' and get_ucd(uid,'jt') == 'L')\n                         or (get_ucd(uid,'bc') != 'L' and get_ucd(uid,'jt') == 'R'))\n            uid = joiningChars[-1]\n            zwjAfter = (get_ucd(uid,'jt') == 'D'\n                         or (get_ucd(uid,'bc') == 'L' and get_ucd(uid,'jt') == 'R')\n                         or (get_ucd(uid,'bc') != 'L' and get_ucd(uid,'jt') == 'L'))\n        else:\n            zwjBefore = zwjAfter = False\n        if get_ucd(startUID,'gc') == 'Mn':\n            # First char is a NSM... prefix a suitable base\n            uids.insert(0, self.diacBase)\n            zwjBefore = False   # No longer any need to put zwj before\n        elif get_ucd(startUID, 'WSpace'):\n            # First char is whitespace -- prefix with baseline brackets:\n            uids.insert(0, 0xF130)\n        lastNonMark = [x for x in uids if get_ucd(x,'gc') != 'Mn'][-1]\n        if get_ucd(lastNonMark, 'WSpace'):\n            # Last non-mark is whitespace -- append baseline brackets:\n            uids.append(0xF131)\n        s = ''.join([chr(uid) for uid in uids])\n        if zwjBefore or zwjAfter:\n            # Show contextual forms:\n            # Start with isolate\n            t = u'{0} '.format(s)\n            if zwjBefore and zwjAfter:\n                # For sequences that show dual-joining behavior, what we show depends on dualJoinMode:\n                if dualJoinMode & 1:\n                    # show initial, medial, final separated by space:\n                    t += u'{0}{2} {1}{0}{2} {1}{0} '.format(s, self.joinBefore, self.joinAfter)\n                if dualJoinMode & 2:\n                    # show 3 joined forms in sequence:\n                    t += u'{0}{0}{0} '.format(s)\n            elif zwjAfter:\n                t += u'{0}{1} '.format(s, self.joinAfter)\n            elif zwjBefore:\n                t += u'{1}{0} '.format(s, self.joinBefore)\n            if addBreaks: ftml.closeTest()\n            ftml.addToTest(keyUID, t, label = label, comment = comment, rtl = rtl)\n            if addBreaks: ftml.closeTest()\n        elif hasMirrored and self.rtlEnable:\n            # Contains mirrored and rtl enabled:\n            if addBreaks: ftml.closeTest()\n            ftml.addToTest(keyUID, u'{0} LTR: \\u202A{0}\\u202C RTL: \\u202B{0}\\u202C'.format(s), label = label, comment = comment, rtl = rtl)\n            if addBreaks: ftml.closeTest()\n        # elif is LRE, RLE, PDF\n        # elif is LRI, RLI, FSI, PDI\n        elif uidLen > 1:\n            ftml.addToTest(keyUID, s , label = label, comment = comment, rtl = rtl)\n        else:\n            ftml.addToTest(keyUID, s , comment = comment, rtl = rtl)",
  "def __init__(self, title, logger, comment = None, fontsrc = None, fontlabel = None, fontscale = None,\n                 widths = None, rendercheck = True, xslfn = None, defaultrtl = False):\n        self.logger = logger\n        # Initialize an Fxml object\n        fxml = Fxml(testgrouplabel = \"dummy\")\n        fxml.stylesheet = {'type': 'text/xsl', 'href': xslfn if xslfn is not None else 'ftml.xsl'}\n        fxml.head.title = title\n        fxml.head.comment = comment\n        if isinstance(fontsrc, (tuple, list)):\n            # Allow multiple fontsrc\n            fxml.head.fontsrc = [Ffontsrc(fxml.head, text=fontsrc,\n                                          label=fontlabel[i] if fontlabel is not None and i < len(fontlabel) else None)\n                                 for i, fontsrc in enumerate(fontsrc)]\n        elif fontsrc:\n            fxml.head.fontsrc = Ffontsrc(fxml.head, text=fontsrc, label=fontlabel)\n\n        if fontscale: fxml.head.fontscale = int(fontscale)\n        if widths: fxml.head.widths = widths\n        fxml.testgroups.pop() # Remove dummy test group\n        # Save object\n        self._fxml = fxml\n        # Initialize state\n        self._curTest = None\n        self.closeTestGroup()\n        self.defaultRTL = defaultrtl\n        # Add first testgroup if requested\n        if rendercheck:\n            self.startTestGroup(\"Rendering Check\", background=\"#F0F0F0\")\n            self.addToTest(None, \"RenderingUnknown\", \"check\", rtl = False)\n            self.closeTest()\n            self.closeTestGroup()",
  "def _getColor(color):\n        if color is None or len(color) == 0:\n            return None\n        color = color.lower()\n        if color in FTML._colorMap:\n            return FTML._colorMap[color]\n        if re.match(r'#[0-9a-f]{6}$', color):\n            return color\n        self.logger.log(f'Color \"{color}\" not understood; ignored', 'W')\n        return None",
  "def closeTest(self, comment = None):\n        if self._curTest:\n            if comment is not None:\n                self._curTest.comment = comment\n            if self._curColor:\n                self._curTest.background = self._curColor\n        self._curTest = None\n        self._lastUID = None\n        self._lastRTL = None",
  "def addToTest(self, uid, s = \"\", label = None, comment = None, rtl = None):\n        if rtl is None: rtl = self.defaultRTL\n        if (self._lastUID and uid and uid not in range(self._lastUID, self._lastUID + 2))\\\n                or (self._lastRTL is not None and rtl != self._lastRTL):\n            self.closeTest()\n        self._lastUID = uid\n        self._lastRTL = rtl\n        if self._curTestGroup is None:\n            # Create a new Ftestgroup\n            self.startTestGroup(\"Group\")\n        if self._curTest is None:\n            # Create a new Ftest\n            if label is None:\n                label = \"U+{0:04X}\".format(uid) if uid is not None else \"test\"\n            test = Ftest(self._curTestGroup, label = label, string = '')\n            if comment:\n                test.comment = comment\n            if rtl: test.rtl = \"True\"\n            # Construct stylename and add style if needed:\n            x = ['{}_{}'.format(t,v) for t,v in self._curFeatures.items()] if self._curFeatures else []\n            if self._curLang:\n                x.insert(0,self._curLang)\n            if len(x):\n                test.stylename = '_'.join(x)\n                self._fxml.head.addstyle(test.stylename, feats = self._curFeatures, lang = self._curLang)\n            # Append to current test group\n            self._curTestGroup.tests.append(test)\n            self._curTest = test\n        if len(self._curTest.string): self._curTest.string += ' '\n        # Special hack until we get to python3 with full unicode support\n        self._curTest.string += ''.join([ c if ord(c) < 128 else '\\\\u{0:06X}'.format(ord(c)) for c in s ])",
  "def setFeatures(self, features):\n        # features can be None or a list; list elements can be:\n        #   None\n        #   a feature setting in the form [tag,value]\n        if features is None:\n            return self.clearFeatures()\n        features = [x for x in features if x]\n        if len(features) == 0:\n            return self.clearFeatures()\n        features = dict(features)   # Convert to a dictionary -- this is what we'll keep.\n        if features != self._curFeatures:\n            self.closeTest()\n        self._curFeatures = features",
  "def clearFeatures(self):\n        if self._curFeatures is not None:\n            self.closeTest()\n        self._curFeatures = None",
  "def setLang(self, langID):\n        if langID != self._curLang:\n            self.closeTest();\n        self._curLang = langID",
  "def clearLang(self):\n        if self._curLang:\n            self.closeTest()\n        self._curLang = None",
  "def setBackground(self, color):\n        color = self._getColor(color)\n        if color != self._curColor:\n            self.closeTest()\n        self._curColor = color",
  "def clearBackground(self):\n        if self._curColor is not None:\n            self.closeTest()\n        self._curColor = None",
  "def closeTestGroup(self):\n        self.closeTest()\n        self._curTestGroup = None\n        self._curFeatures = None\n        self._curLang = None\n        self._curColor = None",
  "def startTestGroup(self, label, background = None):\n        if self._curTestGroup is not None:\n            if label == self._curTestGroup.label:\n                return\n            self.closeTestGroup()\n        # Add new test group\n        self._curTestGroup = Ftestgroup(self._fxml, label = label)\n        background = self._getColor(background)\n        if background is not None:\n            self._curTestGroup.background = background\n\n        # append to root test groups\n        self._fxml.testgroups.append(self._curTestGroup)",
  "def writeFile(self, output):\n        self.closeTestGroup()\n        self._fxml.save(output)",
  "def __init__(self, tag):\n        self.tag = tag\n        self.default = 0\n        self.maxval = 1\n        self._tvlist = None",
  "def __getattr__(self,name):\n        if name == \"tvlist\":\n            # tvlist is a list of all possible tag,value pairs (except the default but including None) for this feature\n            # This attribute shouldn't be needed until all the possible feature value are known,\n            # therefore we'll generate this the first time we need it and save it\n            if self._tvlist is None:\n                self._tvlist = [ None ]\n                for v in range (0, self.maxval+1):\n                    if v != self.default:\n                        self._tvlist.append( [self.tag, str(v)])\n            return self._tvlist",
  "def __init__(self, uids, basename, logger):\n        self.logger = logger\n        # uids can be a singleton integer or, for multiple-encoded glyphs, some kind of sequence of integers\n        if isinstance(uids,collections.abc.Sequence):\n            uids1 = uids\n        else:\n            uids1 = (uids,)\n        # test each uid to make sure valid; remove if not.\n        uids2=[]\n        self.general = \"unknown\"\n        for uid in uids1:\n            try:\n                gc = get_ucd(uid,'gc')\n                if self.general == \"unknown\":\n                    self.general = gc\n                uids2.append(uid)\n            except (TypeError, IndexError):\n                self.logger.log(f'Invalid USV \"{uid}\" -- ignored.', 'E')\n                continue\n            except KeyError:\n                self.logger.log('USV %04X not defined; no properties known' % uid, 'W')\n        # make sure there's at least one left\n        assert len(uids2) > 0, f'No valid USVs found in {repr(uids)}'\n        self._uids = tuple(uids2)\n        self.basename = basename\n        self.feats = set()  # feat tags that affect this char\n        self.langs = set()  # lang tags that affect this char\n        self.aps = set()\n        self.altnames = {}  # alternate glyph names.\n            # the above is a dict keyed by either:\n            #   lang tag e.g., 'ur', or\n            #   feat tag and value, e.g., 'cv24=3'\n            # and returns a the glyphname for that alternate.\n        # Additional info from UFO:\n        self.takesMarks = self.isMark = self.isBase = self.notInUFO = False",
  "def __getattr__(self,name):\n        if name == 'uids':\n            return self._uids\n        elif name == 'uid':\n            return self._uids[0]\n        else:\n            raise AttributeError",
  "def checkGlyph(self, gname, font, apRE):\n        # glean info from UFO if glyph is present\n        if gname in font.deflayer:\n            self.notInUFO = False\n            for a in font.deflayer[gname]['anchor'] :\n                name = a.element.get('name')\n                if apRE.match(name) is None:\n                    continue\n                self.aps.add(name)\n                if name.startswith(\"_\") :\n                    self.isMark = True\n                else:\n                    self.takesMarks = True\n            self.isBase = self.takesMarks and not self.isMark\n        else:\n            self.notInUFO = True",
  "def __init__(self, uids, basename, logger):\n        self.logger = logger\n        self.uids = uids\n        self.basename = basename\n        # a couple of properties based on the first uid:\n        try:\n            self.general = get_ucd(uids[0],'gc')\n        except KeyError:\n            self.logger.log('USV %04X not defined; no properties known' % uids[0], 'W')\n        self.feats = set()  # feat tags that affect this char\n        self.aps = set()\n        self.langs = set()  # lang tags that affect this char\n        self.altnames = {}  # alternate glyph names.\n        self.takesMarks = self.isMark = self.isBase = self.notInUFO = False",
  "def __init__(self, logger, incsv = None, fontcode = None, font = None, langs = None, rtlenable = False, ap = None ):\n        self.logger = logger\n        self.rtlEnable = rtlenable\n\n        # Default diacritic base:\n        self.diacBase = 0x25CC\n\n        # Default joinBefore and joinAfter sequence\n        self.joinBefore = '\\u200D'  # put before a sequence to force joining shape; def = zwj\n        self.joinAfter = '\\u200D'   # put after a sequence to force joining shape; def = zwj\n\n        # Dict mapping tag to Feature\n        self.features = {}\n\n        # Set of all languages seen\n        if langs is not None:\n            # Use a list so we keep the order (assuming caller wouldn't give us dups\n            self.allLangs = list(re.split(r'\\s*[\\s,]\\s*', langs)) # Allow comma- or space-separated tags\n            self._langsComplete = True  # We have all the lang tags desired\n        else:\n            # use a set because the langtags are going to dribble in and be repeated.\n            self.allLangs = set()\n            self._langsComplete = False # Add lang_tags from glyph_data\n\n        # Be able to find chars and specials:\n        self._charFromUID = {}\n        self._charFromBasename = {}\n        self._specialFromUIDs = {}\n        self._specialFromBasename = {}\n\n        # list of USVs that are in the CSV but whose glyphs are not in the UFO\n        self.uidsMissingFromUFO = set()\n\n        # DummyUSV  (see charAuto())\n        self.curDummyUSV = 0x100000 # Supplemental Private Use Area B\n\n        # Compile --ap parameter\n        if ap is None:\n            ap = \".\"\n        try:\n            self.apRE = re.compile(ap)\n        except re.error as e:\n            logger.log(\"--ap parameter '{}' doesn't compile as regular expression: {}\".format(ap, e), \"S\")\n\n        if incsv is not None:\n            self.readGlyphData(incsv, fontcode, font)",
  "def addChar(self, uids, basename):\n        # Add an FChar\n        # assume parameters are OK:\n        c = FChar(uids, basename, self.logger)\n        # fatal error if the basename or any of uids have already been seen\n        fatal = False\n        for uid in c.uids:\n            if uid in self._charFromUID:\n                self.logger.log('Attempt to add duplicate USV %04X' % uid, 'E')\n                fatal = True\n            self._charFromUID[uid] = c\n        if basename in self._charFromBasename:\n            self.logger.log('Attempt to add duplicate basename %s' % basename, 'E')\n            fatal = True\n        self._charFromBasename[basename] = c\n        if fatal:\n            self.logger.log('Cannot continue due to previous errors', 'S')\n        return c",
  "def uids(self):\n        \"\"\" returns list of uids in glyph_data \"\"\"\n        return self._charFromUID.keys()",
  "def char(self, x):\n        \"\"\" finds an FChar based either basename or uid;\n            generates KeyError if not found.\"\"\"\n        return self._charFromBasename[x] if isinstance(x, str) else self._charFromUID[x]",
  "def charAuto(self, x):\n        \"\"\" Like char() but will issue a warning and add a dummy \"\"\"\n        try:\n            return self._charFromBasename[x] if isinstance(x, str) else self._charFromUID[x]\n        except KeyError:\n            # Issue error message and create dummy Char object for this character\n            if isinstance(x, str):\n                self.logger.log(f'Glyph \"{x}\" isn\\'t in glyph_data.csv - adding dummy', 'E')\n                while self.curDummyUSV in self._charFromUID:\n                    self.curDummyUSV += 1\n                c = self.addChar(self.curDummyUSV, x)\n            else:\n                self.logger.log(f'Char U+{x:04x} isn\\'t in glyph_data.csv - adding dummy', 'E')\n                c = self.addChar(x, f'U+{x:04x}')\n            return c",
  "def addSpecial(self, uids, basename):\n        # Add an FSpecial:\n        # fatal error if basename has already been seen:\n        if basename in self._specialFromBasename:\n            self.logger.log('Attempt to add duplicate basename %s' % basename, 'S')\n        c = FSpecial(uids, basename, self.logger)\n        # remember it:\n        self._specialFromUIDs[tuple(uids)] = c\n        self._specialFromBasename[basename] = c\n        return c",
  "def specials(self):\n        \"\"\"returns a list of the basenames of specials\"\"\"\n        return self._specialFromBasename.keys()",
  "def special(self, x):\n        \"\"\" finds an FSpecial based either basename or uid sequence;\n            generates KeyError if not found.\"\"\"\n        return self._specialFromBasename[x] if isinstance(x, str) else self._specialFromUIDs[tuple(x)]",
  "def _csvWarning(self, msg, exception = None):\n        m = \"glyph_data line {1}: {0}\".format(msg, self.incsv.line_num)\n        if exception is not None:\n            m += '; ' + str(exception)\n        self.logger.log(m, 'W')",
  "def readGlyphData(self, incsv, fontcode = None, font = None):\n        # Remember csv file for other methods:\n        self.incsv = incsv\n\n        # Validate fontcode, if provided\n        if fontcode is not None:\n            whichfont = fontcode.strip().lower()\n            if len(whichfont) != 1:\n                self.logger.log('fontcode must be a single letter', 'S')\n        else:\n            whichfont = None\n\n        # Get headings from csvfile:\n        fl = incsv.firstline\n        if fl is None: self.logger.log(\"Empty input file\", \"S\")\n        # required columns:\n        try:\n            nameCol = fl.index('glyph_name');\n            usvCol = fl.index('USV')\n        except ValueError as e:\n            self.logger.log('Missing csv input field: ' + str(e), 'S')\n        except Exception as e:\n            self.logger.log('Error reading csv input field: ' + str(e), 'S')\n        # optional columns:\n        # If -f specified, make sure we have the fonts column\n        if whichfont is not None:\n            if 'Fonts' not in fl: self.logger.log('-f requires \"Fonts\" column in glyph_data', 'S')\n            fontsCol = fl.index('Fonts')\n        # Allow for projects that use only production glyph names (ps_name same as glyph_name)\n        psCol = fl.index('ps_name') if 'ps_name' in fl else nameCol\n        # Allow for projects that have no feature and/or lang-specific behaviors\n        featCol = fl.index('Feat') if 'Feat' in fl else None\n        bcp47Col = fl.index('bcp47tags') if 'bcp47tags' in fl else None\n\n        next(incsv.reader, None)  # Skip first line with headers\n\n        # RE that matches names of glyphs we don't care about\n        namesToSkipRE = re.compile('^(?:[._].*|null|cr|nonmarkingreturn|tab|glyph_name)$',re.IGNORECASE)\n\n        # RE that matches things like 'cv23' or 'cv23=4' or 'cv23=2,3'\n        featRE = re.compile('^(\\w{2,4})(?:=([\\d,]+))?$')\n\n        # RE that matches USV sequences for ligatures\n        ligatureRE = re.compile('^[0-9A-Fa-f]{4,6}(?:_[0-9A-Fa-f]{4,6})+$')\n        \n        # RE that matches space-separated USV sequences\n        USVsRE = re.compile('^[0-9A-Fa-f]{4,6}(?:\\s+[0-9A-Fa-f]{4,6})*$')\n\n        # keep track of glyph names we've seen to detect duplicates\n        namesSeen = set()\n        psnamesSeen = set()\n\n        # OK, process all records in glyph_data\n        for line in incsv:\n            gname = line[nameCol].strip()\n\n            # things to ignore:\n            if namesToSkipRE.match(gname):\n                continue\n            if whichfont is not None and line[fontsCol] != '*' and line[fontsCol].lower().find(whichfont) < 0:\n                continue\n            if len(gname) == 0:\n                self._csvWarning('empty glyph name in glyph_data; ignored')\n                continue\n            if gname.startswith('#'):\n                continue\n            if gname in namesSeen:\n                self._csvWarning('glyph name %s previously seen in glyph_data; ignored' % gname)\n                continue\n\n            psname = line[psCol].strip() or gname   # If psname absent, working name will be production name\n            if psname in psnamesSeen:\n                self._csvWarning('psname %s previously seen; ignored' % psname)\n                continue\n            namesSeen.add(gname)\n            psnamesSeen.add(psname)\n\n            # compute basename-- the glyph name without extensions:\n            basename = gname.split('.',1)[0]\n\n            # Process USV(s)\n            # could be empty string, a single USV, space-separated list of USVs for multiple encoding,\n            # or underscore-connected USVs indicating ligatures.\n\n            usvs = line[usvCol].strip()\n            if len(usvs) == 0:\n                # Empty USV field, unencoded glyph\n                usvs = ()\n            elif USVsRE.match(usvs):\n                # space-separated hex values:\n                usvs = usvs.split()\n                isLigature = False\n            elif ligatureRE.match(usvs):\n                # '_' separated hex values (ligatures)\n                usvs = usvs.split('_')\n                isLigature = True\n            else:\n                self._csvWarning(f\"invalid USV field '{usvs}'; ignored\")\n                usvs = ()\n            uids = [int(x, 16) for x in usvs]\n\n            if len(uids) == 0:\n                # Handle unencoded glyphs\n                uids = None # Prevents using this record to set default feature values\n                if basename in self._charFromBasename:\n                    c = self._charFromBasename[basename]\n                    # Check for additional AP info\n                    c.checkGlyph(gname, font, self.apRE)\n                elif basename in self._specialFromBasename:\n                    c = self._specialFromBasename[basename]\n                else:\n                    self._csvWarning('unencoded variant %s found before encoded glyph' % gname)\n                    c = None\n            elif isLigature:\n                # Handle ligatures\n                c = self.addSpecial(uids, basename)\n                uids = None  # Prevents using this record to set default feature values  (TODO: Research this)\n            else:\n                # Handle simple encoded glyphs (could be multiple uids!)\n                # Create character object\n                c = self.addChar(uids, basename)\n                if font is not None:\n                    # Examine APs to determine if this character takes marks:\n                    c.checkGlyph(gname, font, self.apRE)\n                    if c.notInUFO:\n                        self.uidsMissingFromUFO.update(uids)\n\n            if featCol is not None:\n                feats = line[featCol].strip()\n                if len(feats) > 0 and not(feats.startswith('#')):\n                    feats = feats.split(';')\n                    for feat in feats:\n                        m = featRE.match(feat)\n                        if m is None:\n                            self._csvWarning('incorrectly formed feature specification \"%s\"; ignored' % feat)\n                        else:\n                            # find/create structure for this feature:\n                            tag = m.group(1)\n                            try:\n                                feature = self.features[tag]\n                            except KeyError:\n                                feature = Feature(tag)\n                                self.features[tag] = feature\n                            # if values supplied, collect default and maximum values for this feature:\n                            if m.group(2) is not None:\n                                vals = [int(i) for i in m.group(2).split(',')]\n                                if len(vals) > 0:\n                                    if uids is not None:\n                                        feature.default = vals[0]\n                                    elif len(feats) == 1:  # TODO: This seems like wrong test.\n                                        for v in vals:\n                                            # remember the glyph name for this feature/value combination:\n                                            feat = '{}={}'.format(tag,v)\n                                            if c is not None and feat not in c.altnames:\n                                                c.altnames[feat] = gname\n                                    vals.append(feature.maxval)\n                                    feature.maxval = max(vals)\n                            if c is not None:\n                                # Record that this feature affects this character:\n                                c.feats.add(tag)\n                            else:\n                                self._csvWarning('untestable feature \"%s\" : no known USV' % tag)\n\n            if bcp47Col is not None:\n                bcp47 = line[bcp47Col].strip()\n                if len(bcp47) > 0 and not(bcp47.startswith('#')):\n                    if c is not None:\n                        for tag in re.split(r'\\s*[\\s,]\\s*', bcp47): # Allow comma- or space-separated tags\n                            c.langs.add(tag)        # lang-tags mentioned for this character\n                            if not self._langsComplete:\n                                self.allLangs.add(tag)  # keep track of all possible lang-tags\n                    else:\n                        self._csvWarning('untestable langs: no known USV')\n\n        # We're finally done, but if allLangs is a set, let's order it (for lack of anything better) and make a list:\n        if not self._langsComplete:\n            self.allLangs = list(sorted(self.allLangs))",
  "def permuteFeatures(self, uids = None, feats = None):\n        \"\"\" returns an iterator that provides all combinations of feature/value pairs, for a list of uids and/or a specific list of feature tags\"\"\"\n        feats = set(feats) if feats is not None else set()\n        if uids is not None:\n            for uid in uids:\n                if uid in self._charFromUID:\n                    feats.update(self._charFromUID[uid].feats)\n        l = [self.features[tag].tvlist for tag in sorted(feats)]\n        return product(*l)",
  "def checkGlyph(obj, gname, font, apRE):\n        # glean info from UFO if glyph is present\n        if gname in font.deflayer:\n            obj.notInUFO = False\n            for a in font.deflayer[gname]['anchor']:\n                name = a.element.get('name')\n                if apRE.match(name) is None:\n                    continue\n                obj.aps.add(name)\n                if name.startswith(\"_\"):\n                    obj.isMark = True\n                else:\n                    obj.takesMarks = True\n            obj.isBase = obj.takesMarks and not obj.isMark\n        else:\n            obj.notInUFO = True",
  "def matchMarkBase(c_mark, c_base):\n        \"\"\" test whether an _AP on c_mark matches an AP on c_base \"\"\"\n        for apM in c_mark.aps:\n            if apM.startswith(\"_\"):\n                ap = apM[1:]\n                for apB in c_base.aps:\n                    if apB == ap:\n                        return True\n        return False",
  "def render(self, uids, ftml, keyUID = 0, addBreaks = True, rtl = None, dualJoinMode = 3, label = None, comment = None):\n        \"\"\" general purpose (but not required) function to generate ftml for a character sequence \"\"\"\n        if len(uids) == 0:\n            return\n        # Make a copy so we don't affect caller\n        uids = list(uids)\n        # Remember first uid and original length for later\n        startUID = uids[0]\n        uidLen = len(uids)\n        # if keyUID wasn't supplied, use startUID\n        if keyUID == 0: keyUID = startUID\n        if label is None:\n            # Construct label from uids:\n            label = '\\n'.join(['U+{0:04X}'.format(u) for u in uids])\n        if comment is None:\n            # Construct comment from glyph names:\n            comment = ' '.join([self._charFromUID[u].basename for u in uids])\n        # see if uid list includes a mirrored char\n        hasMirrored = bool(len([x for x in uids if get_ucd(x,'Bidi_M')]))\n        # Analyze first and last joining char\n        joiningChars = [x for x in uids if get_ucd(x, 'jt') != 'T']\n        if len(joiningChars):\n            # If first or last non-TRANSPARENT char is a joining char, then we need to emit examples with zwj\n            # Assumes any non-TRANSPARENT char that is bc != L must be a rtl character of some sort\n            uid = joiningChars[0]\n            zwjBefore = (get_ucd(uid,'jt') == 'D'\n                         or (get_ucd(uid,'bc') == 'L' and get_ucd(uid,'jt') == 'L')\n                         or (get_ucd(uid,'bc') != 'L' and get_ucd(uid,'jt') == 'R'))\n            uid = joiningChars[-1]\n            zwjAfter = (get_ucd(uid,'jt') == 'D'\n                         or (get_ucd(uid,'bc') == 'L' and get_ucd(uid,'jt') == 'R')\n                         or (get_ucd(uid,'bc') != 'L' and get_ucd(uid,'jt') == 'L'))\n        else:\n            zwjBefore = zwjAfter = False\n        if get_ucd(startUID,'gc') == 'Mn':\n            # First char is a NSM... prefix a suitable base\n            uids.insert(0, self.diacBase)\n            zwjBefore = False   # No longer any need to put zwj before\n        elif get_ucd(startUID, 'WSpace'):\n            # First char is whitespace -- prefix with baseline brackets:\n            uids.insert(0, 0xF130)\n        lastNonMark = [x for x in uids if get_ucd(x,'gc') != 'Mn'][-1]\n        if get_ucd(lastNonMark, 'WSpace'):\n            # Last non-mark is whitespace -- append baseline brackets:\n            uids.append(0xF131)\n        s = ''.join([chr(uid) for uid in uids])\n        if zwjBefore or zwjAfter:\n            # Show contextual forms:\n            # Start with isolate\n            t = u'{0} '.format(s)\n            if zwjBefore and zwjAfter:\n                # For sequences that show dual-joining behavior, what we show depends on dualJoinMode:\n                if dualJoinMode & 1:\n                    # show initial, medial, final separated by space:\n                    t += u'{0}{2} {1}{0}{2} {1}{0} '.format(s, self.joinBefore, self.joinAfter)\n                if dualJoinMode & 2:\n                    # show 3 joined forms in sequence:\n                    t += u'{0}{0}{0} '.format(s)\n            elif zwjAfter:\n                t += u'{0}{1} '.format(s, self.joinAfter)\n            elif zwjBefore:\n                t += u'{1}{0} '.format(s, self.joinBefore)\n            if addBreaks: ftml.closeTest()\n            ftml.addToTest(keyUID, t, label = label, comment = comment, rtl = rtl)\n            if addBreaks: ftml.closeTest()\n        elif hasMirrored and self.rtlEnable:\n            # Contains mirrored and rtl enabled:\n            if addBreaks: ftml.closeTest()\n            ftml.addToTest(keyUID, u'{0} LTR: \\u202A{0}\\u202C RTL: \\u202B{0}\\u202C'.format(s), label = label, comment = comment, rtl = rtl)\n            if addBreaks: ftml.closeTest()\n        # elif is LRE, RLE, PDF\n        # elif is LRI, RLI, FSI, PDI\n        elif uidLen > 1:\n            ftml.addToTest(keyUID, s , label = label, comment = comment, rtl = rtl)\n        else:\n            ftml.addToTest(keyUID, s , comment = comment, rtl = rtl)",
  "class feax_Lexer(Lexer):\n\n    def __init__(self, *a):\n        Lexer.__init__(self, *a)\n        self.tokens_ = None\n        self.stack_ = []\n        self.empty_ = False\n\n    def next_(self, recurse=False):\n        while (not self.empty_):\n            if self.tokens_ is not None:\n                res = self.tokens_.pop(0)\n                if not len(self.tokens_):\n                    self.popstack()\n                if res[0] != VARIABLE:\n                    return (res[0], res[1], self.location_())\n                return self.parse_variable(res[1])\n\n            try:\n                res = Lexer.next_(self)\n            except IndexError as e:\n                self.popstack()\n                continue\n            except StopIteration as e:\n                self.popstack()\n                continue\n            except FeatureLibError as e:\n                if u\"Unexpected character\" not in str(e):\n                    raise e\n\n                # only executes if exception occurred\n                location = self.location_()\n                text = self.text_\n                start = self.pos_\n                cur_char = text[start]\n                if cur_char == '$':\n                    self.pos_ += 1\n                    self.scan_over_(Lexer.CHAR_NAME_CONTINUATION_)\n                    varname = text[start+1:self.pos_]\n                    if len(varname) < 1 or len(varname) > 63:\n                        raise FeatureLibError(\"Bad variable name length\", location)\n                    res = (VARIABLE, varname, location)\n                else:\n                    raise FeatureLibError(\"Unexpected character: %r\" % cur_char, location)\n            return res\n        raise StopIteration\n\n    def __repr__(self):\n        if self.tokens_ is not None:\n            return str(self.tokens_)\n        else:\n            return str((self.text_[self.pos_:self.pos_+20], self.pos_, self.text_length_))\n\n    def popstack(self):\n        if len(self.stack_) == 0:\n            self.empty_ = True\n            return\n        t = self.stack_.pop()\n        if t[0] == 'tokens':\n            self.tokens_ = t[1]\n        else:\n            self.text_, self.pos_, self.text_length_ = t[1]\n            self.tokens_ = None\n\n    def pushstack(self, v):\n        if self.tokens_ is None:\n            self.stack_.append(('text', (self.text_, self.pos_, self.text_length_)))\n        else:\n            self.stack_.append(('tokens', self.tokens_))\n        self.stack_.append(v)\n        self.popstack()\n\n    def pushback(self, token_type, token):\n        if self.tokens_ is not None:\n            self.tokens_.append((token_type, token))\n        else:\n            self.pushstack(('tokens', [(token_type, token)]))\n        \n    def parse_variable(self, vname):\n        t = str(self.scope.get(vname, ''))\n        if t != '':\n            self.pushstack(['text', (t + \" \", 0, len(t)+1)])\n        return self.next_()",
  "class feax_IncludingLexer(IncludingLexer):\n\n    @staticmethod\n    def make_lexer_(file_or_path):\n        if hasattr(file_or_path, \"read\"):\n            fileobj, closing = file_or_path, False\n        else:\n            filename, closing = file_or_path, True\n            fileobj = io.open(filename, mode=\"r\", encoding=\"utf-8\")\n        data = fileobj.read()\n        filename = getattr(fileobj, \"name\", None)\n        if closing:\n            fileobj.close()\n        return feax_Lexer(data, filename)",
  "def __init__(self, *a):\n        Lexer.__init__(self, *a)\n        self.tokens_ = None\n        self.stack_ = []\n        self.empty_ = False",
  "def next_(self, recurse=False):\n        while (not self.empty_):\n            if self.tokens_ is not None:\n                res = self.tokens_.pop(0)\n                if not len(self.tokens_):\n                    self.popstack()\n                if res[0] != VARIABLE:\n                    return (res[0], res[1], self.location_())\n                return self.parse_variable(res[1])\n\n            try:\n                res = Lexer.next_(self)\n            except IndexError as e:\n                self.popstack()\n                continue\n            except StopIteration as e:\n                self.popstack()\n                continue\n            except FeatureLibError as e:\n                if u\"Unexpected character\" not in str(e):\n                    raise e\n\n                # only executes if exception occurred\n                location = self.location_()\n                text = self.text_\n                start = self.pos_\n                cur_char = text[start]\n                if cur_char == '$':\n                    self.pos_ += 1\n                    self.scan_over_(Lexer.CHAR_NAME_CONTINUATION_)\n                    varname = text[start+1:self.pos_]\n                    if len(varname) < 1 or len(varname) > 63:\n                        raise FeatureLibError(\"Bad variable name length\", location)\n                    res = (VARIABLE, varname, location)\n                else:\n                    raise FeatureLibError(\"Unexpected character: %r\" % cur_char, location)\n            return res\n        raise StopIteration",
  "def __repr__(self):\n        if self.tokens_ is not None:\n            return str(self.tokens_)\n        else:\n            return str((self.text_[self.pos_:self.pos_+20], self.pos_, self.text_length_))",
  "def popstack(self):\n        if len(self.stack_) == 0:\n            self.empty_ = True\n            return\n        t = self.stack_.pop()\n        if t[0] == 'tokens':\n            self.tokens_ = t[1]\n        else:\n            self.text_, self.pos_, self.text_length_ = t[1]\n            self.tokens_ = None",
  "def pushstack(self, v):\n        if self.tokens_ is None:\n            self.stack_.append(('text', (self.text_, self.pos_, self.text_length_)))\n        else:\n            self.stack_.append(('tokens', self.tokens_))\n        self.stack_.append(v)\n        self.popstack()",
  "def pushback(self, token_type, token):\n        if self.tokens_ is not None:\n            self.tokens_.append((token_type, token))\n        else:\n            self.pushstack(('tokens', [(token_type, token)]))",
  "def parse_variable(self, vname):\n        t = str(self.scope.get(vname, ''))\n        if t != '':\n            self.pushstack(['text', (t + \" \", 0, len(t)+1)])\n        return self.next_()",
  "def make_lexer_(file_or_path):\n        if hasattr(file_or_path, \"read\"):\n            fileobj, closing = file_or_path, False\n        else:\n            filename, closing = file_or_path, True\n            fileobj = io.open(filename, mode=\"r\", encoding=\"utf-8\")\n        data = fileobj.read()\n        filename = getattr(fileobj, \"name\", None)\n        if closing:\n            fileobj.close()\n        return feax_Lexer(data, filename)",
  "class Glyph(object):\n    def __init__(self, gid, **kw):\n        self.gid = gid\n        for k,v in kw.items():\n            setattr(self, k, v)\n\n    def __repr__(self):\n        return \"[{gid}@({offset[0]},{offset[1]})+({advance[0]},{advance[1]})]\".format(**self.__dict__)",
  "def shape_text(f, text, features = [], lang=None, dir=\"\", script=\"\", shapers=\"\"):\n    fontfile = f.reader.file\n    fontfile.seek(0, 0)\n    fontdata = fontfile.read()\n    blob = hb.glib_blob_create(GLib.Bytes.new(fontdata))\n    face = hb.face_create(blob, 0)\n    del blob\n    font = hb.font_create(face)\n    upem = hb.face_get_upem(face)\n    del face\n    hb.font_set_scale(font, upem, upem)\n    hb.ot_font_set_funcs(font)\n\n    buf = hb.buffer_create()\n    t = text.encode('utf-8')\n    hb.buffer_add_utf8(buf, t, 0, -1)\n    hb.buffer_guess_segment_properties(buf)\n    if dir:\n        hb.buffer_set_direction(buf, hb.direction_from_string(dir))\n    if script:\n        hb.buffer_set_script(buf, hb.script_from_string(script))\n    if lang:\n        hb.buffer_set_language(buf, hb.language_from_string(lang))\n    \n    feats = []\n    if len(features):\n        for feat_string in features:\n            if hb.feature_from_string(feat_string, -1, aFeats):\n                feats.append(aFeats)\n    if shapers:\n        hb.shape_full(font, buf, feats, shapers)\n    else:\n        hb.shape(font, buf, feats)\n\n    num_glyphs = hb.buffer_get_length(buf)\n    info = hb.buffer_get_glyph_infos(buf)\n    pos = hb.buffer_get_glyph_positions(buf)\n\n    glyphs = []\n    for i in range(num_glyphs):\n        glyphs.append(Glyph(info[i].codepoint, cluster = info[i].cluster,\n                        offset = (pos[i].x_offset, pos[i].y_offset),\n                        advance = (pos[i].x_advance, pos[i].y_advance),\n                        flags = info[i].mask))\n    return glyphs",
  "def __init__(self, gid, **kw):\n        self.gid = gid\n        for k,v in kw.items():\n            setattr(self, k, v)",
  "def __repr__(self):\n        return \"[{gid}@({offset[0]},{offset[1]})+({advance[0]},{advance[1]})]\".format(**self.__dict__)",
  "def doit(args):\n    font = args.font\n    pfn = args.primaryname\n    orgid = args.orgid\n    logger = args.logger\n    ofn = args.output\n\n    # Find & process info required in the UFO\n\n    fi = font.fontinfo\n\n    ufofields = {}\n    missing = None\n    for field in (\"versionMajor\", \"versionMinor\", \"openTypeNameManufacturer\", \"openTypeNameManufacturerURL\",\n                  \"openTypeNameLicense\", \"copyright\", \"trademark\"):\n        if field in fi:\n            ufofields[field] = fi[field][1].text\n        elif field != 'trademark':      # trademark is no longer required\n            missing = field if missing is None else missing + \", \" + field\n    if missing is not None: logger.log(\"Field(s) missing from fontinfo.plist: \" + missing, \"S\")\n\n    version = ufofields[\"versionMajor\"] + \".\" + ufofields[\"versionMinor\"].zfill(3)\n\n    # Find & process WOFF fields if present in the UFO\n\n    missing = None\n    ufofields[\"woffMetadataDescriptionurl\"] =  None\n    ufowoff = {\"woffMetadataCredits\": \"credits\", \"woffMetadataDescription\": \"text\"} # Field, dict name\n    for field in ufowoff:\n        fival = fi.getval(field) if field in fi else None\n        if fival is None:\n            missing = field if missing is None else missing + \", \" + field\n            ufofields[field] = None\n        else:\n            ufofields[field] = fival[ufowoff[field]]\n            if field == \"woffMetadataDescription\" and \"url\" in fival:\n                ufofields[\"woffMetadataDescriptionurl\"] = fival[\"url\"]\n\n    # Process --populateufowoff setting, if present\n    if args.populateufowoff:\n        if missing != \"woffMetadataCredits, woffMetadataDescription\":\n            logger.log(\"Data exists in the UFO for woffMetadata - remove manually to reuse --populateufowoff\", \"S\")\n\n    if args.populateufowoff or missing is not None:\n        if missing: logger.log(\"WOFF field(s) missing from fontinfo.plist will be generated from FONTLOG.txt: \" + missing, \"W\")\n        # Open the fontlog file\n        try:\n            fontlog = open(args.fontlog)\n        except Exception as e:\n            logger.log(f\"Unable to open {args.fontlog}: {str(e)}\", \"S\")\n        # Parse the fontlog file\n        (section, match) = readuntil(fontlog, (\"Basic Font Information\",))  # Skip until start of \"Basic Font Information\" section\n        if match is None: logger.log(\"No 'Basic Font Information' section in fontlog\", \"S\")\n        (fldescription, match) = readuntil(fontlog, (\"Information for C\", \"Acknowledgements\"))  # Description ends when first of these sections is found\n        fldescription = [{\"text\": fldescription}]\n        if match == \"Information for C\": (section, match) = readuntil(fontlog, (\"Acknowledgements\",))  # If Info... section present then skip on to Acknowledgements\n        if match is None: logger.log(\"No 'Acknowledgements' section in fontlog\", \"S\")\n        (acksection, match) = readuntil(fontlog, (\"No match needed!!\",))\n\n        flcredits = []\n        credit = {}\n        acktype = \"\"\n        flog2woff = {\"N\": \"name\", \"E\": \"Not used\", \"W\": \"url\", \"D\": \"role\"}\n        for line in acksection.splitlines():\n            if line == \"\":\n                if acktype != \"\":  # Must be at the end of a credit section\n                    if \"name\" in credit:\n                        flcredits.append(credit)\n                    else:\n                        logger.log(\"Credit section found with no N: entry\", \"E\")\n                credit = {}\n                acktype = \"\"\n            else:\n                match = re.match(\"^([NEWD]): (.*)\", line)\n                if match is None:\n                    if acktype == \"N\": credit[\"name\"] = credit[\"name\"] + line  # Name entries can be multiple lines\n                else:\n                    acktype = match.group(1)\n                    if acktype in credit:\n                        logger.log(\"Multiple \" + acktype + \" entries found in a credit section\", \"E\")\n                    else:\n                        credit[flog2woff[acktype]] = match.group(2)\n        if flcredits == []: logger.log(\"No credits found in fontlog\", \"S\")\n        if args.populateufowoff:\n            ufofields[\"woffMetadataDescription\"] = fldescription # Force fontlog values to be used writing metadata.xml later\n            ufofields[\"woffMetadataCredits\"] = flcredits\n            # Create xml strings and update fontinfo\n            xmlstring = \"<dict>\" + \\\n                        \"<key>text</key><array><dict>\" + \\\n                        \"<key>text</key><string>\" + textprotect(fldescription[0][\"text\"]) + \"</string>\" + \\\n                        \"</dict></array>\" + \\\n                        \"<key>url</key><string>https://software.sil.org/</string>\"\\\n                        \"</dict>\"\n            fi.setelem(\"woffMetadataDescription\", ET.fromstring(xmlstring))\n\n            xmlstring = \"<dict><key>credits</key><array>\"\n            for credit in flcredits:\n                xmlstring += '<dict><key>name</key><string>' + textprotect(credit[\"name\"]) + '</string>'\n                if \"url\" in credit: xmlstring += '<key>url</key><string>' + textprotect(credit[\"url\"]) + '</string>'\n                if \"role\" in credit: xmlstring += '<key>role</key><string>' + textprotect(credit[\"role\"]) + '</string>'\n                xmlstring += '</dict>'\n            xmlstring += '</array></dict>'\n            fi.setelem(\"woffMetadataCredits\", ET.fromstring(xmlstring))\n\n            fi.setval(\"openTypeHeadCreated\", \"string\", datetime.datetime.now().strftime(\"%Y/%m/%d %H:%M:%S\"))\n            logger.log(\"Writing updated fontinfo.plist with values from FONTLOG.txt\", \"P\")\n            exists = True if os.path.isfile(os.path.join(font.ufodir, \"fontinfo.plist\")) else False\n            UFO.writeXMLobject(fi, font.outparams, font.ufodir, \"fontinfo.plist\", exists, fobject=True)\n\n    description = ufofields[\"woffMetadataDescription\"]\n    if description == None: description = fldescription\n    credits = ufofields[\"woffMetadataCredits\"]\n    if credits == None : credits = flcredits\n\n    # Construct output file name\n    (folder, ufoname) = os.path.split(font.ufodir)\n    filename = os.path.join(folder, pfn + \"-WOFF-metadata.xml\") if ofn is None else ofn\n    try:\n        file = open(filename, \"w\")\n    except Exception as e:\n        logger.log(\"Unable to open \" + filename + \" for writing:\\n\" + str(e), \"S\")\n    logger.log(\"Writing to : \" + filename, \"P\")\n\n    file.write('<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n')\n    file.write('<metadata version=\"1.0\">\\n')\n    file.write('  <uniqueid id=\"' + orgid + '.' + pfn + '.' + version + '\" />\\n')\n    file.write('  <vendor name=\"' + attrprotect(ufofields[\"openTypeNameManufacturer\"]) + '\" url=\"'\n               + attrprotect(ufofields[\"openTypeNameManufacturerURL\"]) + '\" />\\n')\n    file.write('  <credits>\\n')\n    for credit in credits:\n        file.write('    <credit\\n')\n        file.write('      name=\"' + attrprotect(credit[\"name\"]) + '\"\\n')\n        if \"url\" in credit: file.write('      url=\"' + attrprotect(credit[\"url\"]) + '\"\\n')\n        if \"role\" in credit: file.write('      role=\"' + attrprotect(credit[\"role\"]) + '\"\\n')\n        file.write('    />\\n')\n    file.write('  </credits>\\n')\n\n    if ufofields[\"woffMetadataDescriptionurl\"]:\n        file.write(f'  <description url=\"{ufofields[\"woffMetadataDescriptionurl\"]}\">\\n')\n    else:\n        file.write('  <description>\\n')\n    file.write('    <text lang=\"en\">\\n')\n    for entry in description:\n        for line in entry[\"text\"].splitlines():\n            file.write('      ' + textprotect(line) + '\\n')\n    file.write('    </text>\\n')\n    file.write('  </description>\\n')\n\n    file.write('  <license url=\"https://scripts.sil.org/OFL\" id=\"org.sil.ofl.1.1\">\\n')\n    file.write('    <text lang=\"en\">\\n')\n    for line in ufofields[\"openTypeNameLicense\"].splitlines(): file.write('      ' + textprotect(line) + '\\n')\n    file.write('    </text>\\n')\n    file.write('  </license>\\n')\n\n    file.write('  <copyright>\\n')\n    file.write('    <text lang=\"en\">\\n')\n    for line in ufofields[\"copyright\"].splitlines(): file.write('      ' + textprotect(line) + '\\n')\n    file.write('    </text>\\n')\n    file.write('  </copyright>\\n')\n\n    if 'trademark' in ufofields:\n        file.write('  <trademark>\\n')\n        file.write('    <text lang=\"en\">' + textprotect(ufofields[\"trademark\"]) + '</text>\\n')\n        file.write('  </trademark>\\n')\n\n    file.write('</metadata>')\n\n    file.close()",
  "def readuntil(file, texts):  # Read through file until line is in texts.  Return section up to there and the text matched\n    skip = True\n    match = None\n    for line in file:\n        line = line.strip()\n        if skip:  # Skip underlines and blank lines at start of section\n            if line == \"\" or line[0:5] == \"-----\":\n                pass\n            else:\n                section = line\n                skip = False\n        else:\n            for text in texts:\n                if line[0:len(text)] == text: match = text\n            if match: break\n            section = section + \"\\n\" + line\n    while section[-1] == \"\\n\": section = section[:-1]  # Strip blank lines at end\n    return (section, match)",
  "def textprotect(txt):  # Switch special characters in text to use &...; format\n    txt = re.sub(r'&', '&amp;', txt)\n    txt = re.sub(r'<', '&lt;', txt)\n    txt = re.sub(r'>', '&gt;', txt)\n    return txt",
  "def attrprotect(txt):  # Switch special characters in text to use &...; format\n    txt = re.sub(r'&', '&amp;', txt)\n    txt = re.sub(r'<', '&lt;', txt)\n    txt = re.sub(r'>', '&gt;', txt)\n    txt = re.sub(r'\"', '&quot;', txt)\n    return txt",
  "def cmd(): execute(\"UFO\", doit, argspec)",
  "def doit(args) :\n    logger = args.paramsobj.logger\n\n    exceptions = (\"glyph\", \"gamma\", \"greek_circ\")\n\n    # Process input which may be a single file or a directory\n    input = args.input\n    gdlfiles = []\n\n    if os.path.isdir(input) :\n        inputisdir = True\n        indir = input\n        for name in os.listdir(input) :\n            ext = os.path.splitext(name)[1]\n            if ext in  ('.gdl','.gdh') :\n                gdlfiles.append(name)\n    else :\n        inputisdir = False\n        indir,inname = os.path.split(input)\n        gdlfiles = [inname]\n\n    # Process output file name - execute() will not have processed file/dir name at all\n    output = \"\" if args.output is None else args.output\n    outdir,outfile = os.path.split(output)\n    if outfile != \"\" and os.path.splitext(outfile)[1] == \"\" : # if no extension on outfile, assume a dir was meant\n        outdir = os.path.join(outdir,outfile)\n        outfile = None\n    if outfile == \"\" : outfile = None\n    if outfile and inputisdir : logger.log(\"Can't specify an output file when input is a directory\", \"S\")\n    outappend = None\n    if outdir == \"\" :\n        if outfile is None :\n            outappend = \"_out\"\n        else :\n            if outfile == gdlfiles[0] : logger.log(\"Specify a different output file\", \"S\")\n        outdir = indir\n    else:\n        if indir == outdir :\n            if outfile :\n                if outfile == gdlfiles[0] : logger.log(\"Specify a different output file\", \"S\")\n            else:\n                logger.log(\"Specify a different output dir\", \"S\")\n        if not os.path.isdir(outdir) : logger.log(\"Output directory does not exist\", \"S\")\n\n    # Process names csv file\n    args.names.numfields = 2\n    names = {}\n    for line in args.names : names[line[0]] = line[1]\n\n    # Process names2 csv if present\n    names2 = args.names2\n    if names2 is not None :\n        names2.numfields = 2\n        for line in names2 :\n            n1 = line[0]\n            n2 = line[1]\n            if n1 in names and n2 != names[n1] :\n                logger.log(n1 + \" in both names and names2 with different values\",\"E\")\n            else :\n                names[n1] = n2\n\n    # Process psnames csv file\n    args.psnames.numfields = 2\n    psnames = {}\n    for line in args.psnames : psnames[line[1]] = line[0]\n\n    missed = []\n    psmissed = []\n    for filen in gdlfiles:\n        dbg = True if filen == 'main.gdh' else False ##\n        file = open(os.path.join(indir,filen),\"r\")\n        if outappend :\n            base,ext = os.path.splitext(filen)\n            outfilen = base+outappend+ext\n        else :\n            outfilen = filen\n        outfile = open(os.path.join(outdir,outfilen),\"w\")\n        commentblock = False\n        cnt = 0 ##\n        for line in file:\n            cnt += 1 ##\n            #if cnt > 150 : break ##\n            line = line.rstrip()\n            # Skip comment blocks\n            if line[0:2] == \"/*\" :\n                outfile.write(line + \"\\n\")\n                if line.find(\"*/\") == -1 : commentblock = True\n                continue\n            if commentblock :\n                outfile.write(line + \"\\n\")\n                if line.find(\"*/\") != -1 : commentblock = False\n                continue\n            # Scan for graphite names\n            cpos = line.find(\"//\")\n            if cpos == -1 :\n                scan = line\n                comment = \"\"\n            else :\n                scan = line[0:cpos]\n                comment = line[cpos:]\n            tmpline = \"\"\n            while re.search('[\\s(\\[,]g\\w+?[\\s)\\],?:;=]',\" \"+scan+\" \") :\n                m = re.search('[\\s(\\[,]g\\w+?[\\s)\\],?:;=]',\" \"+scan+\" \")\n                gname = m.group(0)[1:-1]\n                if gname in names :\n                    gname = names[gname]\n                else :\n                    if gname not in missed and gname not in exceptions :\n                        logger.log(gname + \" from '\" + line.strip() + \"' in \" + filen + \" missing from csv\", \"W\")\n                        missed.append(gname) # only log each missed name once\n                tmpline = tmpline + scan[lastend:m.start()] + gname\n                scan = scan[m.end()-2:]\n            tmpline = tmpline + scan + comment\n\n            # Scan for postscript statements\n            scan = tmpline[0:tmpline.find(\"//\")] if tmpline.find(\"//\") != -1 else tmpline\n            newline = \"\"\n            lastend = 0\n\n            for m in re.finditer('postscript\\(.+?\\)',scan) :\n                psname = m.group(0)[12:-2]\n                if psname in psnames :\n                    psname = psnames[psname]\n                else :\n                    if psname not in psmissed :\n                        logger.log(psname + \" from '\" + line.strip() + \"' in \" + filen + \" missing from ps csv\", \"W\")\n                        psmissed.append(psname) # only log each missed name once\n                newline = newline + scan[lastend:m.start()+12] + psname\n                lastend = m.end()-2\n\n            newline = newline + tmpline[lastend:]\n            outfile.write(newline + \"\\n\")\n    file.close()\n    outfile.close()\n    if missed != [] : logger.log(\"Names were missed from the csv file - see log file for details\",\"E\")\n    return",
  "def cmd() : execute(None,doit,argspec)",
  "def doit(args):\n    logger = args.logger\n\n    # Open all the supplied DS files and ufos within them\n    dsinfos = []\n    failures = False\n    for pattern in args.ds:\n        cnt = 0\n        for fullpath in glob.glob(pattern):\n            cnt += 1\n            logger.log(f'Opening {fullpath}', 'P')\n            try:\n                ds = DSD.DesignSpaceDocument.fromfile(fullpath)\n            except Exception as e:\n                logger.log(f'Error opening {fullpath}: {e}', 'E')\n                failures = True\n                break\n            dsinfos.append({'dspath': fullpath, 'ds': ds})\n        if not cnt: logger.log(f'No files matched {pattern}', \"S\")\n    if failures: logger.log(\"Failed to open all the designspace files\", \"S\")\n\n    # Find the project root based on first ds assuming the project root is one level above a source directory containing the DS files\n    path = dsinfos[0]['dspath']\n    (path, base, ext) = splitfn(path)\n    (parent,dir) = os.path.split(path)\n    projectroot = parent if dir == \"source\" else None\n    logger.log(f'Project root: {projectroot}', \"V\")\n\n    # Find and open all the unique UFO sources in the DSs\n    ufos = {}\n    refufo = None\n    for dsinfo in dsinfos:\n        logger.log(f'Processing {dsinfo[\"dspath\"]}', \"V\")\n        ds = dsinfo['ds']\n        for source in ds.sources:\n            if source.path not in ufos:\n                ufos[source.path] = Ufo(source, logger)\n                if not refufo: refufo = source.path # For now use the first found.  Need to work out how to choose the best one\n\n    refunicodes = ufos[refufo].unicodes\n    refglyphlist = set(refunicodes)\n    (path,refname) = os.path.split(refufo)\n\n    # Now compare with other UFOs\n    logger.log(f'Comparing glyph inventory and unicode values with those in {refname}', \"P\")\n    for ufopath in ufos:\n        if ufopath == refufo: continue\n        ufo = ufos[ufopath]\n        logger.log(f'Checking {ufo.name}', \"I\")\n        unicodes = ufo.unicodes\n        glyphlist = set(unicodes)\n        missing = refglyphlist - glyphlist\n        extras = glyphlist - refglyphlist\n        both = glyphlist - extras\n        if missing: logger.log(f'These glyphs are missing from {ufo.name}: {str(list(missing))}', 'E')\n        if extras: logger.log(f'These extra glyphs are in {ufo.name}: {\", \".join(extras)}', 'E')\n        valdiff = [f'{g}: {str(unicodes[g])}/{str(refunicodes[g])}'\n                  for g in both if refunicodes[g] != unicodes[g]]\n        if valdiff:\n            valdiff = \"\\n\".join(valdiff)\n            logger.log(f'These glyphs in {ufo.name} have different unicode values to those in {refname}:\\n'\n                       f'{valdiff}', 'E')",
  "class Ufo(object): # Read just the bits for UFO needed for current checks for efficientcy reasons\n    def __init__(self, source, logger):\n        self.source = source\n        (path, self.name) = os.path.split(source.path)\n        self.logger = logger\n        self.ufodir = source.path\n        self.unicodes =  {}\n        if not os.path.isdir(self.ufodir): logger.log(self.ufodir + \" in designspace doc does not exist\", \"S\")\n        try:\n            self.layercontents = UFO.Uplist(font=None, dirn=self.ufodir, filen=\"layercontents.plist\")\n        except Exception as e:\n            logger.log(\"Unable to open layercontents.plist in \" + self.ufodir, \"S\")\n        for i in sorted(self.layercontents.keys()):\n            layername = self.layercontents[i][0].text\n            if layername != 'public.default': continue\n            layerdir = self.layercontents[i][1].text\n            fulldir = os.path.join(self.ufodir, layerdir)\n            self.contents = UFO.Uplist(font=None, dirn=fulldir, filen=\"contents.plist\")\n            for glyphn in sorted(self.contents.keys()):\n                glifn = self.contents[glyphn][1].text\n                glyph = ETU.xmlitem(os.path.join(self.ufodir,layerdir), glifn, logger=logger)\n                unicode = None\n                for x in glyph.etree:\n                    if x.tag == 'unicode':\n                        unicode = x.attrib['hex']\n                        break\n                self.unicodes[glyphn] = unicode",
  "def cmd(): execute('', doit, argspec)",
  "def __init__(self, source, logger):\n        self.source = source\n        (path, self.name) = os.path.split(source.path)\n        self.logger = logger\n        self.ufodir = source.path\n        self.unicodes =  {}\n        if not os.path.isdir(self.ufodir): logger.log(self.ufodir + \" in designspace doc does not exist\", \"S\")\n        try:\n            self.layercontents = UFO.Uplist(font=None, dirn=self.ufodir, filen=\"layercontents.plist\")\n        except Exception as e:\n            logger.log(\"Unable to open layercontents.plist in \" + self.ufodir, \"S\")\n        for i in sorted(self.layercontents.keys()):\n            layername = self.layercontents[i][0].text\n            if layername != 'public.default': continue\n            layerdir = self.layercontents[i][1].text\n            fulldir = os.path.join(self.ufodir, layerdir)\n            self.contents = UFO.Uplist(font=None, dirn=fulldir, filen=\"contents.plist\")\n            for glyphn in sorted(self.contents.keys()):\n                glifn = self.contents[glyphn][1].text\n                glyph = ETU.xmlitem(os.path.join(self.ufodir,layerdir), glifn, logger=logger)\n                unicode = None\n                for x in glyph.etree:\n                    if x.tag == 'unicode':\n                        unicode = x.attrib['hex']\n                        break\n                self.unicodes[glyphn] = unicode",
  "def doit(args) :\n    font = args.ifont\n    incsv = args.input\n    logger = args.logger\n    # Allow for up to 3 unicode values per glyph\n    incsv.minfields = 2\n    incsv.maxfields = 4\n\n    # List of glyphnames actually in the font:\n    glyphlist = list(font.deflayer.keys())\n\n    # Create mapping to find glyph name from decimal usv:\n    dusv2gname = {int(unicode.hex, 16): gname for gname in glyphlist for unicode in font.deflayer[gname]['unicode']}\n\n    # Remember what glyphnames we've processed:\n    processed = set()\n\n    for line in incsv :\n        glyphn = line[0]\n        # Allow for up to 3 unicode values\n        dusvs = []\n        for col in range(1,len(line)):\n            try:\n                dusv = int(line[col],16)  # sanity check and convert to decimal\n            except ValueError:\n                logger.log(\"Invalid USV '%s'; line %d ignored.\" % (line[col], incsv.line_num), \"W\")\n                continue\n            dusvs.append(dusv)\n\n        if glyphn in glyphlist :\n\n            if glyphn in processed:\n                logger.log(f\"Glyph {glyphn} in csv more than once; line {incsv.line_num} ignored.\", \"W\")\n\n            glyph = font.deflayer[glyphn]\n            # Remove existing unicodes\n            for unicode in list(glyph[\"unicode\"]):\n                del dusv2gname[int(unicode.hex, 16)]\n                glyph.remove(\"unicode\",index = 0)\n\n            # Add the new unicode(s) in\n            for dusv in dusvs:\n                # See if any glyph already encodes this unicode value:\n                if dusv in dusv2gname:\n                    # Remove this encoding from the other glyph:\n                    oglyph = font.deflayer[dusv2gname[dusv]]\n                    for unicode in oglyph[\"unicode\"]:\n                        if int(unicode.hex,16) == dusv:\n                            oglyph.remove(\"unicode\", object=unicode)\n                            break\n                # Add this unicode value and update dusv2gname\n                dusv2gname[dusv] = glyphn\n                glyph.add(\"unicode\",{\"hex\": (\"%04X\" % dusv)})  # Standardize to 4 (or more) digits and caps\n            # Record that we processed this glyphname,\n            processed.add(glyphn)\n        else :\n            logger.log(\"Glyph '%s' not in font; line %d ignored.\" % (glyphn, incsv.line_num), \"I\")\n\n    return font",
  "def cmd() : execute(\"UFO\",doit,argspec)",
  "def doit(args) :\n\n    font = args.ifont\n\n    aglfn = dict()\n    if args.aglfn:\n        # Load Adobe Glyph List For New Fonts (AGLFN)\n        incsv = args.aglfn\n        incsv.numfields = 3\n\n        for line in incsv:\n            usv = line[0]\n            aglfn_name = line[1]\n\n            codepoint = int(usv, 16)\n            aglfn[codepoint] = aglfn_name\n\n    # Gather data from the UFO\n    cmap = dict()\n    for glyph in font:\n        for codepoint in glyph.unicodes:\n            cmap[codepoint] = glyph.name\n\n    # Determine list of glyphs that need to be copied\n    header = ('glyph_name', 'rename', 'usv')\n    glyphs = args.glyphs\n    row = ','.join(header)\n    glyphs.write(row + '\\n')\n\n    for line in args.input:\n\n        # Ignore comments\n        line = line.partition('#')[0]\n        line = line.strip()\n\n        # Ignore blank lines\n        if line == '':\n            continue\n\n        # Specify the glyph to copy\n        codepoint = int(line, 16)\n        usv = f'{codepoint:04X}'\n\n        # Specify how to construct default AGLFN name\n        # if codepoint is not listed in the AGLFN file\n        glyph_prefix = 'uni'\n        if codepoint > 0xFFFF:\n            glyph_prefix = 'u'\n\n        if codepoint in cmap:\n            # By default codepoints not listed in the AGLFN file\n            # will be imported with the glyph name of the source UFO\n            default_aglfn = ''\n            if args.uni:\n                # Provide AGLFN compatible names if requested\n                default_aglfn = f'{glyph_prefix}{usv}'\n\n            # Create control file for use with psfcopyglyphs\n            aglfn_name = aglfn.get(codepoint, default_aglfn)\n            glyph_name = cmap[codepoint]\n            if '_' in glyph_name and aglfn_name == '':\n                aglfn_name = glyph_name.replace('_', '')\n            row = ','.join((glyph_name, aglfn_name, usv))\n            glyphs.write(row + '\\n')",
  "def cmd() : execute(\"FP\",doit, argspec)",
  "def doit(args) :\n    font = args.ifont\n    logger = args.logger\n\n    # Process duplicates csv file into a dictionary structure\n    args.input.numfields = 2\n    duplicates = {}\n    for line in args.input :\n        duplicates[line[0]] = line[1]\n\n    # Iterate through dictionary (unsorted)\n    for source, target in duplicates.items() :\n        # Check if source glyph is in font\n        if source in font.keys() :\n            # Give warning if target is already in font, but overwrite anyway\n            if target in font.keys() :\n                logger.log(\"Warning: \" + target + \" already in font and will be replaced\")\n            sourceglyph = font[source]\n            # Make a copy of source into a new glyph object\n            newglyph = sourceglyph.copy()\n            # Modify that glyph object\n            newglyph.unicodes = []\n            # Add the new glyph object to the font with name target\n            font.__setitem__(target,newglyph)\n            logger.log(source + \" duplicated to \" + target)\n        else :\n            logger.log(\"Warning: \" + source + \" not in font\")\n\n    return font",
  "def cmd() : execute(\"FP\",doit,argspec)",
  "def doit(args) :\n\n    font = args.ifont\n    logger = args.logger\n    plist = args.plist\n    if plist is None: plist = \"fontinfo\"\n    if plist not in (\"lib\", \"fontinfo\"):\n        logger.log(\"--plist must be either fontinfo or lib\", \"S\")\n    else:\n        if plist not in font.__dict__: font.addfile(plist)\n    logger.log(\"Adding keys to \" + plist, \"I\")\n    font_plist = getattr(font, plist)\n\n    # Ensure enough options were specified\n    value = args.value or args.file or args.filepart\n    if args.key and not value:\n        logger.log('Value needs to be specified', \"S\")\n    if not args.key and value:\n        logger.log('Key needs to be specified', \"S\")\n\n    # Use a one line string to set the key\n    if args.key and args.value:\n        set_key_value(font_plist, args.key, args.value)\n\n    # Use entire file contents to set the key\n    if args.key and args.file:\n        fh = codecs.open(args.file, 'r', 'utf-8')\n        contents = ''.join(fh.readlines())\n        set_key_value(font_plist, args.key, contents)\n        fh.close()\n\n    # Use some of the file contents to set the key\n    if args.key and args.filepart:\n        fh = codecs.open(args.filepart, 'r', 'utf-8')\n        lines = list()\n        for line in fh:\n            if line == '\\n':\n                break\n            lines.append(line)\n        contents = ''.join(lines)\n        set_key_value(font_plist, args.key, contents)\n        fh.close()\n\n    # Set many keys\n    if args.input:\n        incsv = args.input\n        incsv.numfields = 2\n\n        for line in incsv:\n            key = line[0]\n            value = line[1]\n            set_key_value(font_plist, key, value)\n\n    return font",
  "def set_key_value(font_plist, key, value):\n    \"\"\"Set key to value in font.\"\"\"\n\n    # Currently setval() only works for integer, real or string.\n    # For other items you need to construct an elementtree element and use setelem()\n\n    if value == 'true' or value == 'false':\n        # Handle boolean values\n        font_plist.setelem(key, ET.Element(value))\n    else:\n        try:\n            # Handle integers values\n            number = int(value)\n            font_plist.setval(key, 'integer', number)\n        except ValueError:\n            # Handle string (including multi-line strings) values\n            font_plist.setval(key, 'string', value)\n    font_plist.font.logger.log(key + \" added, value: \" + str(value), \"I\")",
  "def cmd() : execute(\"UFO\",doit, argspec)",
  "def doit(args) :\n    cgobj = CompGlyph()\n    glyphcount = 0\n    for g in ET.parse(args.input).getroot().findall('glyph'):\n        glyphcount += 1\n        cgobj.CDelement = g\n        cgobj.CDline = None\n        cgobj.parsefromCDelement()\n        if cgobj.CDline != None:\n            args.output.write(cgobj.CDline+'\\n')\n        else:\n            pass # error in glyph number glyphcount message\n    return",
  "def cmd() : execute(None,doit,argspec)",
  "def InstanceWriterCF(output_path_prefix, calc_glyphs, fix_weight):\n\n    class LocalInstanceWriter(InstanceWriter):\n        fixWeight = fix_weight\n\n        def __init__(self, path, *args, **kw):\n            if output_path_prefix:\n                path = os.path.join(output_path_prefix, path)\n            return super(LocalInstanceWriter, self).__init__(path, *args, **kw)\n\n        # Override the method used to calculate glyph geometry\n        # If copy_glyphs is true and the glyph being processed is in the same location\n        # (has all the same axes values) as a master UFO,\n        # then extract the glyph geometry directly into the target glyph.\n        # FYI, in the superclass method, m = buildMutator(); m.makeInstance() returns a MathGlyph\n        def _calculateGlyph(self, targetGlyphObject, instanceLocationObject, glyphMasters):\n            # Search for a glyphMaster with the same location as instanceLocationObject\n            found = False\n            if not calc_glyphs: # i.e. if copying glyphs\n                for item in glyphMasters:\n                    locationObject = item['location'] # mutatorMath Location\n                    if locationObject.sameAs(instanceLocationObject) == 0:\n                        found = True\n                        fontObject = item['font'] # defcon Font\n                        glyphName = item['glyphName'] # string\n                        glyphObject = MathGlyph(fontObject[glyphName])\n                        glyphObject.extractGlyph(targetGlyphObject, onlyGeometry=True)\n                        break\n\n            if not found: # includes case of calc_glyphs == True\n                super(LocalInstanceWriter, self)._calculateGlyph(targetGlyphObject,\n                                                                 instanceLocationObject,\n                                                                 glyphMasters)\n\n        def _copyFontInfo(self, targetInfo, sourceInfo):\n            super(LocalInstanceWriter, self)._copyFontInfo(targetInfo, sourceInfo)\n\n            if getattr(self, 'fixWeight', False):\n                # fixWeight is True since the --weightfix (or -W) option was specified\n\n                # This mode is used for RIBBI font builds,\n                # therefore the weight class can be determined\n                # by the style name\n                if self.font.info.styleMapStyleName.lower().startswith(\"bold\"):\n                    weight_class = 700\n                else:\n                    weight_class = 400\n            else:\n                # fixWeight is False (or None)\n\n                # This mode is used for non-RIBBI font builds,\n                # therefore the weight class can be determined\n                # by the weight axis map in the Designspace file\n                foundmap = False\n                weight = int(self.locationObject[\"weight\"])\n                for map_space in self.axes[\"weight\"][\"map\"]:\n                    userspace = int(map_space[0])  # called input in the Designspace file\n                    designspace = int(map_space[1])  # called output in the Designspace file\n                    if designspace == weight:\n                        weight_class = userspace\n                        foundmap = True\n                if not foundmap:\n                    weight_class = 399 # Dummy value designed to look non-standard\n                    logger.log(f'No entry in designspace axis mapping for {weight}; set to 399', 'W')\n            setattr(targetInfo, 'openTypeOS2WeightClass', weight_class)\n\n            localinfo = {}\n            for k in (('openTypeNameManufacturer', None),\n                      ('styleMapFamilyName', 'familyName'),\n                      ('styleMapStyleName', 'styleName')):\n                localinfo[k[0]] = getattr(targetInfo, k[0], (getattr(targetInfo, k[1]) if k[1] is not None else \"\"))\n            localinfo['styleMapStyleName'] = localinfo['styleMapStyleName'].title()\n            localinfo['year'] = re.sub(r'^.*?([0-9]+)\\s*$', r'\\1', getattr(targetInfo, 'openTypeNameUniqueID')) \n            uniqueID = \"{openTypeNameManufacturer}: {styleMapFamilyName} {styleMapStyleName} {year}\".format(**localinfo)\n            setattr(targetInfo, 'openTypeNameUniqueID', uniqueID)\n\n    return LocalInstanceWriter",
  "def progress_func(state=\"update\", action=None, text=None, tick=0):\n    global severe_error\n    if logger:\n        if state == 'error':\n            if str(action) == 'unicodes':\n                logger.log(\"%s: %s\\n%s\" % (state, str(action), str(text)), 'W')\n            else:\n                logger.log(\"%s: %s\\n%s\" % (state, str(action), str(text)), 'E')\n                severe_error = True\n        else:\n            logger.log(\"%s: %s\\n%s\" % (state, str(action), str(text)), 'I')",
  "def doit(args):\n    global logger\n    logger = args.logger\n\n    designspace_path = args.designspace_path\n    instance_font_name = args.instanceName\n    instance_attr = args.instanceAttr\n    instance_val = args.instanceVal\n    output_path_prefix = args.output\n    calc_glyphs = args.forceInterpolation\n    build_folder = args.folder\n    round_instances = args.roundInstances\n\n    if instance_font_name and (instance_attr or instance_val):\n        args.logger.log('--instanceName is mutually exclusive with --instanceAttr or --instanceVal','S')\n    if (instance_attr and not instance_val) or (instance_val and not instance_attr):\n        args.logger.log('--instanceAttr and --instanceVal must be used together', 'S')\n    if (build_folder and (instance_font_name or instance_attr or instance_val\n                          or output_path_prefix or calc_glyphs)):\n        args.logger.log('--folder cannot be used with options: -i, -a, -v, -o, --forceInterpolation', 'S')\n\n    args.logger.log('Interpolating master UFOs from designspace', 'P')\n    if not build_folder:\n        if not os.path.isfile(designspace_path):\n            args.logger.log('A designspace file (not a folder) is required', 'S')\n        reader = DesignSpaceDocumentReader(designspace_path, ufoVersion=3,\n                                           roundGeometry=round_instances,\n                                           progressFunc=progress_func)\n        # assignment to an internal object variable is a kludge, probably should use subclassing instead\n        reader._instanceWriterClass = InstanceWriterCF(output_path_prefix, calc_glyphs, args.weightfix)\n        if calc_glyphs:\n            args.logger.log('Interpolating glyphs where an instance font location matches a master', 'P')\n        if instance_font_name or instance_attr:\n            key_attr = instance_attr if instance_val else 'name'\n            key_val = instance_val if instance_attr else instance_font_name\n            reader.readInstance((key_attr, key_val))\n        else:\n            reader.readInstances()\n    else:\n        # The below uses a utility function that's part of mutatorMath\n        #  It will accept a folder and processes all designspace files there\n        args.logger.log('Interpolating glyphs where an instance font location matches a master', 'P')\n        build_designspace(designspace_path,\n                          outputUFOFormatVersion=3, roundGeometry=round_instances,\n                          progressFunc=progress_func)\n\n    if not severe_error:\n        args.logger.log('Done', 'P')\n    else:\n        args.logger.log('Done with severe error', 'S')",
  "def cmd(): execute(None, doit, argspec)",
  "class LocalInstanceWriter(InstanceWriter):\n        fixWeight = fix_weight\n\n        def __init__(self, path, *args, **kw):\n            if output_path_prefix:\n                path = os.path.join(output_path_prefix, path)\n            return super(LocalInstanceWriter, self).__init__(path, *args, **kw)\n\n        # Override the method used to calculate glyph geometry\n        # If copy_glyphs is true and the glyph being processed is in the same location\n        # (has all the same axes values) as a master UFO,\n        # then extract the glyph geometry directly into the target glyph.\n        # FYI, in the superclass method, m = buildMutator(); m.makeInstance() returns a MathGlyph\n        def _calculateGlyph(self, targetGlyphObject, instanceLocationObject, glyphMasters):\n            # Search for a glyphMaster with the same location as instanceLocationObject\n            found = False\n            if not calc_glyphs: # i.e. if copying glyphs\n                for item in glyphMasters:\n                    locationObject = item['location'] # mutatorMath Location\n                    if locationObject.sameAs(instanceLocationObject) == 0:\n                        found = True\n                        fontObject = item['font'] # defcon Font\n                        glyphName = item['glyphName'] # string\n                        glyphObject = MathGlyph(fontObject[glyphName])\n                        glyphObject.extractGlyph(targetGlyphObject, onlyGeometry=True)\n                        break\n\n            if not found: # includes case of calc_glyphs == True\n                super(LocalInstanceWriter, self)._calculateGlyph(targetGlyphObject,\n                                                                 instanceLocationObject,\n                                                                 glyphMasters)\n\n        def _copyFontInfo(self, targetInfo, sourceInfo):\n            super(LocalInstanceWriter, self)._copyFontInfo(targetInfo, sourceInfo)\n\n            if getattr(self, 'fixWeight', False):\n                # fixWeight is True since the --weightfix (or -W) option was specified\n\n                # This mode is used for RIBBI font builds,\n                # therefore the weight class can be determined\n                # by the style name\n                if self.font.info.styleMapStyleName.lower().startswith(\"bold\"):\n                    weight_class = 700\n                else:\n                    weight_class = 400\n            else:\n                # fixWeight is False (or None)\n\n                # This mode is used for non-RIBBI font builds,\n                # therefore the weight class can be determined\n                # by the weight axis map in the Designspace file\n                foundmap = False\n                weight = int(self.locationObject[\"weight\"])\n                for map_space in self.axes[\"weight\"][\"map\"]:\n                    userspace = int(map_space[0])  # called input in the Designspace file\n                    designspace = int(map_space[1])  # called output in the Designspace file\n                    if designspace == weight:\n                        weight_class = userspace\n                        foundmap = True\n                if not foundmap:\n                    weight_class = 399 # Dummy value designed to look non-standard\n                    logger.log(f'No entry in designspace axis mapping for {weight}; set to 399', 'W')\n            setattr(targetInfo, 'openTypeOS2WeightClass', weight_class)\n\n            localinfo = {}\n            for k in (('openTypeNameManufacturer', None),\n                      ('styleMapFamilyName', 'familyName'),\n                      ('styleMapStyleName', 'styleName')):\n                localinfo[k[0]] = getattr(targetInfo, k[0], (getattr(targetInfo, k[1]) if k[1] is not None else \"\"))\n            localinfo['styleMapStyleName'] = localinfo['styleMapStyleName'].title()\n            localinfo['year'] = re.sub(r'^.*?([0-9]+)\\s*$', r'\\1', getattr(targetInfo, 'openTypeNameUniqueID')) \n            uniqueID = \"{openTypeNameManufacturer}: {styleMapFamilyName} {styleMapStyleName} {year}\".format(**localinfo)\n            setattr(targetInfo, 'openTypeNameUniqueID', uniqueID)",
  "def __init__(self, path, *args, **kw):\n            if output_path_prefix:\n                path = os.path.join(output_path_prefix, path)\n            return super(LocalInstanceWriter, self).__init__(path, *args, **kw)",
  "def _calculateGlyph(self, targetGlyphObject, instanceLocationObject, glyphMasters):\n            # Search for a glyphMaster with the same location as instanceLocationObject\n            found = False\n            if not calc_glyphs: # i.e. if copying glyphs\n                for item in glyphMasters:\n                    locationObject = item['location'] # mutatorMath Location\n                    if locationObject.sameAs(instanceLocationObject) == 0:\n                        found = True\n                        fontObject = item['font'] # defcon Font\n                        glyphName = item['glyphName'] # string\n                        glyphObject = MathGlyph(fontObject[glyphName])\n                        glyphObject.extractGlyph(targetGlyphObject, onlyGeometry=True)\n                        break\n\n            if not found: # includes case of calc_glyphs == True\n                super(LocalInstanceWriter, self)._calculateGlyph(targetGlyphObject,\n                                                                 instanceLocationObject,\n                                                                 glyphMasters)",
  "def _copyFontInfo(self, targetInfo, sourceInfo):\n            super(LocalInstanceWriter, self)._copyFontInfo(targetInfo, sourceInfo)\n\n            if getattr(self, 'fixWeight', False):\n                # fixWeight is True since the --weightfix (or -W) option was specified\n\n                # This mode is used for RIBBI font builds,\n                # therefore the weight class can be determined\n                # by the style name\n                if self.font.info.styleMapStyleName.lower().startswith(\"bold\"):\n                    weight_class = 700\n                else:\n                    weight_class = 400\n            else:\n                # fixWeight is False (or None)\n\n                # This mode is used for non-RIBBI font builds,\n                # therefore the weight class can be determined\n                # by the weight axis map in the Designspace file\n                foundmap = False\n                weight = int(self.locationObject[\"weight\"])\n                for map_space in self.axes[\"weight\"][\"map\"]:\n                    userspace = int(map_space[0])  # called input in the Designspace file\n                    designspace = int(map_space[1])  # called output in the Designspace file\n                    if designspace == weight:\n                        weight_class = userspace\n                        foundmap = True\n                if not foundmap:\n                    weight_class = 399 # Dummy value designed to look non-standard\n                    logger.log(f'No entry in designspace axis mapping for {weight}; set to 399', 'W')\n            setattr(targetInfo, 'openTypeOS2WeightClass', weight_class)\n\n            localinfo = {}\n            for k in (('openTypeNameManufacturer', None),\n                      ('styleMapFamilyName', 'familyName'),\n                      ('styleMapStyleName', 'styleName')):\n                localinfo[k[0]] = getattr(targetInfo, k[0], (getattr(targetInfo, k[1]) if k[1] is not None else \"\"))\n            localinfo['styleMapStyleName'] = localinfo['styleMapStyleName'].title()\n            localinfo['year'] = re.sub(r'^.*?([0-9]+)\\s*$', r'\\1', getattr(targetInfo, 'openTypeNameUniqueID')) \n            uniqueID = \"{openTypeNameManufacturer}: {styleMapFamilyName} {styleMapStyleName} {year}\".format(**localinfo)\n            setattr(targetInfo, 'openTypeNameUniqueID', uniqueID)",
  "def doit(args) :\n\n    if args.version is not None :\n        v = args.version.lower()\n        if v in (\"2\",\"3\",\"3ff\") :\n            if v == \"3ff\": # Special action for testing with FontForge import\n                v = \"3\"\n                args.ifont.outparams['format1Glifs'] = True\n            args.ifont.outparams['UFOversion'] = v\n        else:\n            args.logger.log(\"-v, --version must be one of 2,3 or 3ff\", \"S\")\n\n    return args.ifont",
  "def cmd() : execute(\"UFO\",doit, argspec)",
  "class MyBuilder(Builder):\n\n    def __init__(self, font, featurefile, lateSortLookups=False, fronts=None):\n        super(MyBuilder, self).__init__(font, featurefile)\n        self.lateSortLookups = lateSortLookups\n        self.fronts = fronts if fronts is not None else []\n\n    def buildLookups_(self, tag):\n        assert tag in ('GPOS', 'GSUB'), tag\n        countFeatureLookups = 0\n        fronts = set([l for k, l in self.named_lookups_.items() if k in self.fronts])\n        for bldr in self.lookups_:\n            bldr.lookup_index = None\n            if bldr.table == tag and getattr(bldr, '_feature', \"\") != \"\":\n                countFeatureLookups += 1\n        lookups = []\n        latelookups = []\n        for bldr in self.lookups_:\n            if bldr.table != tag:\n                continue\n            if self.lateSortLookups and getattr(bldr, '_feature', \"\") == \"\":\n                if bldr in fronts:\n                    latelookups.insert(0, bldr)\n                else:\n                    latelookups.append(bldr)\n            else:\n                bldr.lookup_index = len(lookups)\n                lookups.append(bldr)\n                bldr.map_index = bldr.lookup_index\n        numl = len(lookups)\n        for i, l in enumerate(latelookups):\n            l.lookup_index = numl + i\n            l.map_index = l.lookup_index\n        for l in lookups + latelookups:\n            self.lookup_locations[tag][str(l.lookup_index)] = LookupDebugInfo(\n                    location=str(l.location),\n                    name=self.get_lookup_name_(l),\n                    feature=None)\n        return [b.build() for b in lookups + latelookups]\n\n    def add_lookup_to_feature_(self, lookup, feature_name):\n        super(MyBuilder, self).add_lookup_to_feature_(lookup, feature_name)\n        lookup._feature = feature_name",
  "def doit(args) :\n    levels = [\"WARNING\", \"INFO\", \"DEBUG\"]\n    configLogger(level=levels[min(len(levels) - 1, args.verbose)])\n\n    font = TTFont(args.input_font)\n    builder = MyBuilder(font, args.input_fea, lateSortLookups=args.end, fronts=args.front)\n    builder.build()\n    if args.lookupmap:\n        with open(args.lookupmap, \"w\") as outf:\n            for n, l in sorted(builder.named_lookups_.items()):\n                if l is not None:\n                    outf.write(\"{},{},{}\\n\".format(n, l.table, l.map_index))\n    font.save(args.output)",
  "def cmd(): execute(None, doit, argspec)",
  "def __init__(self, font, featurefile, lateSortLookups=False, fronts=None):\n        super(MyBuilder, self).__init__(font, featurefile)\n        self.lateSortLookups = lateSortLookups\n        self.fronts = fronts if fronts is not None else []",
  "def buildLookups_(self, tag):\n        assert tag in ('GPOS', 'GSUB'), tag\n        countFeatureLookups = 0\n        fronts = set([l for k, l in self.named_lookups_.items() if k in self.fronts])\n        for bldr in self.lookups_:\n            bldr.lookup_index = None\n            if bldr.table == tag and getattr(bldr, '_feature', \"\") != \"\":\n                countFeatureLookups += 1\n        lookups = []\n        latelookups = []\n        for bldr in self.lookups_:\n            if bldr.table != tag:\n                continue\n            if self.lateSortLookups and getattr(bldr, '_feature', \"\") == \"\":\n                if bldr in fronts:\n                    latelookups.insert(0, bldr)\n                else:\n                    latelookups.append(bldr)\n            else:\n                bldr.lookup_index = len(lookups)\n                lookups.append(bldr)\n                bldr.map_index = bldr.lookup_index\n        numl = len(lookups)\n        for i, l in enumerate(latelookups):\n            l.lookup_index = numl + i\n            l.map_index = l.lookup_index\n        for l in lookups + latelookups:\n            self.lookup_locations[tag][str(l.lookup_index)] = LookupDebugInfo(\n                    location=str(l.location),\n                    name=self.get_lookup_name_(l),\n                    feature=None)\n        return [b.build() for b in lookups + latelookups]",
  "def add_lookup_to_feature_(self, lookup, feature_name):\n        super(MyBuilder, self).add_lookup_to_feature_(lookup, feature_name)\n        lookup._feature = feature_name",
  "def doit(args):\n    logger = args.logger\n\n    # Read input csv to get glyph sort order\n    incsv = args.glyphdata\n    fl = incsv.firstline\n    if fl is None: logger.log(\"Empty input file\", \"S\")\n    if args.gname in fl:\n        glyphnpos = fl.index(args.gname)\n    else:\n        logger.log(\"No\" + args.gname + \"field in csv headers\", \"S\")\n    if args.sort in fl:\n        sortpos = fl.index(args.sort)\n    else:\n        logger.log('No \"' + args.sort + '\" heading in csv headers\"', \"S\")\n    next(incsv.reader, None)  # Skip first line with containing headers\n    for line in incsv:\n        glyphn = line[glyphnpos]\n        if len(glyphn) == 0:\n            continue\t# No need to include cases where name is blank\n        sorts[glyphn] = float(line[sortpos])\n\n    # RegEx we are looking for in comments\n    matchCountRE = re.compile(\"\\*NEXT ([1-9]\\d*) CLASSES MUST MATCH\\*\")\n\n    # parse classes.xml but include comments\n    class MyTreeBuilder(ET.TreeBuilder):\n        def comment(self, data):\n            res = matchCountRE.search(data)\n            if res:\n                # record the count of classes that must match\n                self.start(ET.Comment, {})\n                self.data(res.group(1))\n                self.end(ET.Comment)\n    doc = ET.parse(args.classes, parser=ET.XMLParser(target=MyTreeBuilder())).getroot()\n\n    # process results looking for both class elements and specially formatted comments\n    matchCount = 0\n    refClassList = None\n    refClassName = None\n\n    for child in doc:\n        if isinstance(child.tag, types.FunctionType):\n            # Special type used for comments\n            if matchCount > 0:\n                logger.log(\"Unexpected match request '{}': matching {} is not yet complete\".format(child.text, refClassName), \"E\")\n                ref = None\n            matchCount = int(child.text)\n            # print \"Match count = {}\".format(matchCount)\n\n        elif child.tag == 'class':\n            l = orderClass(child, logger)  # Do this so we record classes whether we match them or not.\n            if matchCount > 0:\n                matchCount -= 1\n                className = child.attrib['name']\n                if refClassName is None:\n                    refClassList = l\n                    refLen = len(refClassList)\n                    refClassName = className\n                else:\n                    # compare ref list and l\n                    if len(l) != refLen:\n                        logger.log(\"Class {} (length {}) and {} (length {}) have unequal length\".format(refClassName, refLen, className, len(l)), \"E\")\n                    else:\n                        errCount = 0\n                        for i in range(refLen):\n                            if l[i][0] != refClassList[i][0]:\n                                logger.log (\"Class {} and {} inconsistent order glyphs {} and {}\".format(refClassName, className, refClassList[i][2], l[i][2]), \"E\")\n                                errCount += 1\n                                if errCount > 5:\n                                    logger.log (\"Abandoning compare between Classes {} and {}\".format(refClassName, className), \"E\")\n                                    break\n                if matchCount == 0:\n                    refClassName = None\n\n    # List glyphs mentioned in classes.xml but not present in glyph_data:\n    if len(missingGlyphs):\n        logger.log('Glyphs mentioned in classes.xml but not present in glyph_data: ' + ', '.join(sorted(missingGlyphs)), 'W')",
  "def orderClass(classElement, logger):\n    # returns a list of tuples, each containing (indexWithinClass, sortOrder, glyphName)\n    # list is sorted by sortOrder\n    glyphList = classElement.text.split()\n    res = []\n    for i in range(len(glyphList)):\n        token = glyphList[i]\n        if token.startswith('@'):\n            # Nested class\n            cname = token[1:]\n            if cname in classes:\n                res.extend(classes[cname])\n            else:\n                logger.log(\"Invalid fea: class {} referenced before being defined\".format(cname),\"S\")\n        else:\n            # simple glyph name -- make sure it is in glyph_data:\n            if token in sorts:\n                res.append((i, sorts[token], token))\n            else:\n                missingGlyphs.add(token)\n\n    classes[classElement.attrib['name']] = res\n    return sorted(res, key=lambda x: x[1])",
  "def cmd() : execute(None,doit,argspec)",
  "class MyTreeBuilder(ET.TreeBuilder):\n        def comment(self, data):\n            res = matchCountRE.search(data)\n            if res:\n                # record the count of classes that must match\n                self.start(ET.Comment, {})\n                self.data(res.group(1))\n                self.end(ET.Comment)",
  "def comment(self, data):\n            res = matchCountRE.search(data)\n            if res:\n                # record the count of classes that must match\n                self.start(ET.Comment, {})\n                self.data(res.group(1))\n                self.end(ET.Comment)",
  "def cmd():\n    \"\"\"gather the deps\"\"\"\n\n    deps = (  # (module, used by, min recommended version)\n        ('defcon', '?', ''),\n        ('fontMath', '?', ''),\n        ('fontParts', '?', ''),\n        ('fontTools', '?', ''),\n        ('glyphConstruction', '?', ''),\n        ('glyphsLib', '?', ''),\n        ('lxml','?', ''),\n        ('mutatorMath', '?', ''),\n        ('palaso', '?', ''),\n        ('ufoLib2', '?', ''),\n        )\n\n    # Pysilfont info\n    print(\"Pysilfont \" + silfont.__copyright__ + \"\\n\")\n    print(\"   Version:           \" + silfont.__version__)\n    print(\"   Commands in:       \" + sys.argv[0][:-10])\n    print(\"   Code running from: \" + silfont.__file__[:-12])\n    print(\"   using:             Python \" + sys.version.split(' \\n', maxsplit=1)[0])\n\n    for dep in deps:\n        name = dep[0]\n\n        try:\n            module = importlib.import_module(name)\n            path = module.__file__\n            # Remove .py file name from end\n            pyname = path.split(\"/\")[-1]\n            path = path[:-len(pyname)-1]\n            version = \"No version info\"\n            for attr in (\"__version__\", \"version\", \"VERSION\"):\n                if hasattr(module, attr):\n                    version = getattr(module, attr)\n                    break\n        except Exception as e:\n            etext = str(e)\n            if etext == \"No module named '\" + name + \"'\":\n                version = \"Module is not installed\"\n            else:\n                version = \"Module import failed with \" + etext\n            path = \"\"\n\n        print('{:20} {:15} {}'.format(name + \":\", version, path))",
  "def doit(args) :\n    font = args.ifont\n    logger = args.logger\n\n    rationales = {\n        \"A\": \"in Codepage 1252\",\n        \"B\": \"in MacRoman\",\n        \"C\": \"for publishing\",\n        \"D\": \"for Non-Roman fonts and publishing\",\n        \"E\": \"by Google Fonts\",\n        \"F\": \"by TeX for visible space\",\n        \"G\": \"for encoding conversion utilities\",\n        \"H\": \"in case Variation Sequences are defined in future\",\n        \"I\": \"to detect byte order\",\n        \"J\": \"to render combining marks in isolation\",\n        \"K\": \"to view sidebearings for every glyph using these characters\"}\n\n    charsets = [\"basic\"]\n    if args.rtl: charsets.append(\"rtl\")\n    if args.silpua: charsets.append(\"sil\")\n\n    req_chars = required_chars(charsets)\n\n    glyphlist = font.deflayer.keys()\n\n    for glyphn in glyphlist :\n        glyph = font.deflayer[glyphn]\n        if len(glyph[\"unicode\"]) == 1 :\n            unival = glyph[\"unicode\"][0].hex\n            if unival in req_chars:\n                del req_chars[unival]\n\n    cnt = len(req_chars)\n    if cnt > 0:\n        for usv in sorted(req_chars.keys()):\n            item = req_chars[usv]\n            psname = item[\"ps_name\"]\n            gname = item[\"glyph_name\"]\n            name = psname if psname == gname else psname + \", \" + gname\n            logger.log(\"U+\" + usv + \" from the \" + item[\"sil_set\"] +\n                       \" set has no representative glyph (\" + name + \")\", \"W\")\n            logger.log(\"Rationale: This character is needed \" + rationales[item[\"rationale\"]], \"I\")\n            if item[\"notes\"]:\n                logger.log(item[\"notes\"], \"I\")\n        logger.log(\"There are \" + str(cnt) + \" required characters missing\", \"E\")\n\n    return",
  "def cmd() : execute(\"UFO\",doit,argspec)",
  "def doit(args):\n    logger = args.logger\n    gdcsv = args.glyphdata\n    addcsv = args.addcsv\n    dellist = args.deletions\n    sortheader = args.sortheader\n    force = args.force\n\n    # Check arguments are valid\n    if not(addcsv or dellist or sortheader): logger.log(\"At least one of -a, -d or -s must be specified\", \"S\")\n    if force and not addcsv: logger.log(\"-f should only be used with -a\", \"S\")\n\n    #\n    # Process the glyph_data.csv\n    #\n\n    # Process the headers line\n    gdheaders = gdcsv.firstline\n    if 'glyph_name' not in gdheaders: logger.log(\"No glyph_name header in glyph data csv\", \"S\")\n    gdcsv.numfields = len(gdheaders)\n    gdheaders = {header: col for col, header in enumerate(gdheaders)} # Turn into dict of form header: column\n    gdnamecol = gdheaders[\"glyph_name\"]\n    if sortheader and sortheader not in gdheaders:\n        logger.log(sortheader + \" not in glyph data headers\", \"S\")\n    next(gdcsv.reader, None)  # Skip first line with headers in\n\n    # Read the data in\n    logger.log(\"Reading in existing glyph data file\", \"P\")\n    gddata = {}\n    gdorder = []\n    for line in gdcsv:\n        gname = line[gdnamecol]\n        gddata[gname] = line\n        gdorder.append(gname)\n\n    # Delete records from dellist\n\n    if dellist:\n        logger.log(\"Deleting items from glyph data based on deletions file\", \"P\")\n        dellist.numfields = 1\n        for line in dellist:\n            gname = line[0]\n            if gname in gdorder:\n                del gddata[gname]\n                gdorder.remove(gname)\n                logger.log(gname + \" deleted from glyph data\", \"I\")\n            else:\n                logger.log(gname + \"not in glyph data\", \"W\")\n\n    #\n    # Process the addcsv, if present\n    #\n\n    if addcsv:\n        # Check if addcsv has headers; if not use gdheaders\n        addheaders = addcsv.firstline\n        headerssame = True\n        if 'glyph_name' in addheaders:\n            if addheaders != gdcsv.firstline: headerssame = False\n            next(addcsv.reader)\n        else:\n            addheaders = gdheaders\n\n        addcsv.numfields = len(addheaders)\n        addheaders = {header: col for col, header in enumerate(addheaders)}  # Turn into dict of form header: column\n        addnamecol = addheaders[\"glyph_name\"]\n\n        logger.log(\"Adding new records from add csv file\", \"P\")\n        for line in addcsv:\n            gname = line[addnamecol]\n            logtype = \"added to\"\n            if gname in gdorder:\n                if force: # Remove existing line\n                    logtype = \"replaced in\"\n                    del gddata[gname]\n                    gdorder.remove(gname)\n                else:\n                    logger.log(gname + \" already in glyphdata so new data not added\", \"W\")\n                    continue\n            logger.log(f'{gname} {logtype} glyphdata', \"I\")\n\n            if not headerssame: # need to construct new line based on addheaders\n                newline = []\n                for header in gdheaders:\n                    val = line[addheaders[header]] if header in addheaders else \"\"\n                    newline.append(val)\n                line = newline\n\n            gddata[gname] = line\n            gdorder.append(gname)\n\n    # Finally sort the data if sortheader supplied\n    def numeric(x):\n        try:\n            numx = float(x)\n        except ValueError:\n            logger.log(f'Non-numeric value \"{x}\" in sort column; 0 used for sorting', \"E\")\n            numx = 0\n        return numx\n\n    if sortheader:\n        sortheaderpos = gdheaders[sortheader]\n        if args.sortalpha:\n            gdorder = sorted(gdorder, key=lambda x: gddata[x][sortheaderpos])\n        else:\n            gdorder = sorted(gdorder, key=lambda x: numeric(gddata[x][sortheaderpos]))\n\n    # Now write the data out\n    outfile = args.outglyphdata\n    if not outfile:\n        gdcsv.file.close()\n        outfile = gdcsv.filename\n    logger.log(f'Writing glyph data out to {outfile}', \"P\")\n    with open(outfile, \"w\", newline=\"\") as f:\n        writer = csv.writer(f)\n        writer.writerow(gdcsv.firstline)\n        for glyphn in gdorder:\n            writer.writerow(gddata[glyphn])",
  "def cmd() : execute(\"\",doit,argspec)",
  "def numeric(x):\n        try:\n            numx = float(x)\n        except ValueError:\n            logger.log(f'Non-numeric value \"{x}\" in sort column; 0 used for sorting', \"E\")\n            numx = 0\n        return numx",
  "def doit(args) :\n    font = args.ifont\n    outfile = args.output\n\n    # Add initial comments to outfile\n    if not args.nocomments :\n        outfile.write(\"# \" + datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S \") + args.cmdlineargs[0] + \"\\n\")\n        outfile.write(\"# \"+\" \".join(args.cmdlineargs[1:])+\"\\n\\n\")\n\n    glyphlist = sorted(font.deflayer.keys())\n\n    for glyphn in glyphlist :\n        glyph = font.deflayer[glyphn]\n        if len(glyph[\"unicode\"]) == 1 :\n            unival = glyph[\"unicode\"][0].hex\n            outfile.write(glyphn + \",\" + unival + \"\\n\")\n        else :\n            if args.allglyphs :\n                outfile.write(glyphn + \",\" + \"\\n\")\n            \n    return",
  "def cmd() : execute(\"UFO\",doit,argspec)",
  "def doit(args) :\n    global csvmap, ksetsbymember\n    font = args.ifont\n    incsv = args.input\n    incsv.numfields = 2\n    logger = args.logger\n    mergemode = args.mergecomps\n\n    failerrors = 0 # Keep count of errors that should cause the script to fail\n    csvmap = {}    # List of all real maps in incsv, so excluding headers, blank lines, comments and identity maps\n    nameMap = {}   # remember all glyphs actually renamed\n    kerngroupsrenamed = {} # List of all kern groups actually renamed\n\n    # List of secondary layers (ie layers other than the default)\n    secondarylayers = [x for x in font.layers if x.layername != \"public.default\"]\n\n    # Obtain lib.plist glyph order(s) and psnames if they exist:\n    publicGlyphOrder = csGlyphOrder = psnames = displayStrings = None\n    if hasattr(font, 'lib'):\n        if 'public.glyphOrder' in font.lib:\n            publicGlyphOrder = font.lib.getval('public.glyphOrder')     # This is an array\n        if 'com.schriftgestaltung.glyphOrder' in font.lib:\n            csGlyphOrder = font.lib.getval('com.schriftgestaltung.glyphOrder') # This is an array\n        if 'public.postscriptNames' in font.lib:\n            psnames = font.lib.getval('public.postscriptNames')   # This is a dict keyed by glyphnames\n        if 'com.schriftgestaltung.customParameter.GSFont.DisplayStrings' in font.lib:\n            displayStrings = font.lib.getval('com.schriftgestaltung.customParameter.GSFont.DisplayStrings')\n    else:\n        logger.log(\"no lib.plist found in font\", \"W\")\n\n    # Renaming within the UFO is done in two passes to make sure we can handle circular renames such as:\n    #    someglyph.alt = someglyph\n    #    someglyph = someglyph.alt\n\n    # Note that the various objects with glyph names are all done independently since\n    # the same glyph names are not necessarily in all structures.\n\n    # First pass: process all records of csv, and for each glyph that is to be renamed:\n    #   If the new glyphname is not already present, go ahead and rename it now.\n    #   If the new glyph name already exists, rename the glyph to a temporary name\n    #      and put relevant details in saveforlater[]\n\n    saveforlaterFont = []   # For the font itself\n    saveforlaterPGO = []    # For public.GlyphOrder\n    saveforlaterCSGO = []   # For GlyphsApp GlyphOrder (com.schriftgestaltung.glyphOrder)\n    saveforlaterPSN = []    # For public.postscriptNames\n    deletelater = []        # Glyphs we'll delete after merging\n\n    for r in incsv:\n        oldname = r[0].strip()\n        newname = r[1].strip()\n        # ignore header row and rows where the newname is blank or a comment marker\n        if oldname == \"Name\" or oldname.startswith('#') or newname == \"\" or oldname == newname:\n            continue\n        if len(oldname)==0:\n            logger.log('empty glyph oldname in glyph_data; ignored (newname: %s)' % newname, 'W')\n            continue\n        csvmap[oldname]=newname\n\n        # Handle font first:\n        if oldname not in font.deflayer:\n            logger.log(\"glyph name not in font: \" + oldname , \"I\")\n        elif newname not in font.deflayer:\n            inseclayers = False\n            for layer in secondarylayers:\n                if newname in layer:\n                    logger.log(\"Glyph %s is already in non-default layers; can't rename %s\" % (newname, oldname), \"E\")\n                    failerrors += 1\n                    inseclayers = True\n                    continue\n            if not inseclayers:\n                # Ok, this case is easy: just rename the glyph in all layers\n                for layer in font.layers:\n                    if oldname in layer: layer[oldname].name = newname\n                nameMap[oldname] = newname\n                logger.log(\"Pass 1 (Font): Renamed %s to %s\" % (oldname, newname), \"I\")\n        elif mergemode:\n            mergeglyphs(font.deflayer[oldname], font.deflayer[newname])\n            for layer in secondarylayers:\n                if oldname in layer:\n                    if newname in layer:\n                        mergeglyphs(layer[oldname], layer[newname])\n                    else:\n                        layer[oldname].name = newname\n\n            nameMap[oldname] = newname\n            deletelater.append(oldname)\n            logger.log(\"Pass 1 (Font): merged %s to %s\" % (oldname, newname), \"I\")\n        else:\n            # newname already in font -- but it might get renamed later in which case this isn't actually a problem.\n            # For now, then, rename glyph to a temporary name and remember it for second pass\n            tempname = gettempname(lambda n : n not in font.deflayer)\n            for layer in font.layers:\n                if oldname in layer:\n                    layer[oldname].name = tempname\n            saveforlaterFont.append( (tempname, oldname, newname) )\n\n        # Similar algorithm for public.glyphOrder, if present:\n        if publicGlyphOrder:\n            if oldname not in publicGlyphOrder:\n                logger.log(\"glyph name not in publicGlyphorder: \" + oldname , \"I\")\n            else:\n                x = publicGlyphOrder.index(oldname)\n                if newname not in publicGlyphOrder:\n                    publicGlyphOrder[x] = newname\n                    nameMap[oldname] = newname\n                    logger.log(\"Pass 1 (PGO): Renamed %s to %s\" % (oldname, newname), \"I\")\n                elif mergemode:\n                    del publicGlyphOrder[x]\n                    nameMap[oldname] = newname\n                    logger.log(\"Pass 1 (PGO): Removed %s (now using %s)\" % (oldname, newname), \"I\")\n                else:\n                    tempname = gettempname(lambda n : n not in publicGlyphOrder)\n                    publicGlyphOrder[x] = tempname\n                    saveforlaterPGO.append( (x, oldname, newname) )\n\n        # And for GlyphsApp glyph order, if present:\n        if csGlyphOrder:\n            if oldname not in csGlyphOrder:\n                logger.log(\"glyph name not in csGlyphorder: \" + oldname , \"I\")\n            else:\n                x = csGlyphOrder.index(oldname)\n                if newname not in csGlyphOrder:\n                    csGlyphOrder[x] = newname\n                    nameMap[oldname] = newname\n                    logger.log(\"Pass 1 (csGO): Renamed %s to %s\" % (oldname, newname), \"I\")\n                elif mergemode:\n                    del csGlyphOrder[x]\n                    nameMap[oldname] = newname\n                    logger.log(\"Pass 1 (csGO): Removed %s (now using %s)\" % (oldname, newname), \"I\")\n                else:\n                    tempname = gettempname(lambda n : n not in csGlyphOrder)\n                    csGlyphOrder[x] = tempname\n                    saveforlaterCSGO.append( (x, oldname, newname) )\n\n        # And for psnames\n        if psnames:\n            if oldname not in psnames:\n                logger.log(\"glyph name not in psnames: \" + oldname , \"I\")\n            elif newname not in psnames:\n                psnames[newname] = psnames.pop(oldname)\n                nameMap[oldname] = newname\n                logger.log(\"Pass 1 (psn): Renamed %s to %s\" % (oldname, newname), \"I\")\n            elif mergemode:\n                del psnames[oldname]\n                nameMap[oldname] = newname\n                logger.log(\"Pass 1 (psn): Removed %s (now using %s)\" % (oldname, newname), \"I\")\n            else:\n                tempname = gettempname(lambda n: n not in psnames)\n                psnames[tempname] = psnames.pop(oldname)\n                saveforlaterPSN.append( (tempname, oldname, newname))\n\n    # Second pass: now we can reprocess those things we saved for later:\n    #    If the new glyphname is no longer present, we can complete the renaming\n    #    Otherwise we've got a fatal error\n\n    for j in saveforlaterFont:\n        tempname, oldname, newname = j\n        if newname in font.deflayer: # Only need to check deflayer, since (if present) it would have been renamed in all\n            # Ok, this really is a problem\n            logger.log(\"Glyph %s already in font; can't rename %s\" % (newname, oldname), \"E\")\n            failerrors += 1\n        else:\n            for layer in font.layers:\n                if tempname in layer:\n                    layer[tempname].name = newname\n            nameMap[oldname] = newname\n            logger.log(\"Pass 2 (Font): Renamed %s to %s\" % (oldname, newname), \"I\")\n\n    for j in saveforlaterPGO:\n        x, oldname, newname = j\n        if newname in publicGlyphOrder:\n            # Ok, this really is a problem\n            logger.log(\"Glyph %s already in public.GlyphOrder; can't rename %s\" % (newname, oldname), \"E\")\n            failerrors += 1\n        else:\n            publicGlyphOrder[x] = newname\n            nameMap[oldname] = newname\n            logger.log(\"Pass 2 (PGO): Renamed %s to %s\" % (oldname, newname), \"I\")\n\n    for j in saveforlaterCSGO:\n        x, oldname, newname = j\n        if newname in csGlyphOrder:\n            # Ok, this really is a problem\n            logger.log(\"Glyph %s already in com.schriftgestaltung.glyphOrder; can't rename %s\" % (newname, oldname), \"E\")\n            failerrors += 1\n        else:\n            csGlyphOrder[x] = newname\n            nameMap[oldname] = newname\n            logger.log(\"Pass 2 (csGO): Renamed %s to %s\" % (oldname, newname), \"I\")\n\n    for tempname, oldname, newname in saveforlaterPSN:\n        if newname in psnames:\n            # Ok, this really is a problem\n            logger.log(\"Glyph %s already in public.postscriptNames; can't rename %s\" % (newname, oldname), \"E\")\n            failerrors += 1\n        else:\n            psnames[newname] = psnames.pop(tempname)\n            nameMap[oldname] = newname\n            logger.log(\"Pass 2 (psn): Renamed %s to %s\" % (oldname, newname), \"I\")\n\n    # Rebuild font structures from the modified lists we have:\n\n    # Rebuild glyph order elements:\n    if publicGlyphOrder:\n        array = ET.Element(\"array\")\n        for name in publicGlyphOrder:\n            ET.SubElement(array, \"string\").text = name\n        font.lib.setelem(\"public.glyphOrder\", array)\n\n    if csGlyphOrder:\n        array = ET.Element(\"array\")\n        for name in csGlyphOrder:\n            ET.SubElement(array, \"string\").text = name\n        font.lib.setelem(\"com.schriftgestaltung.glyphOrder\", array)\n\n    # Rebuild postscriptNames:\n    if psnames:\n        dict = ET.Element(\"dict\")\n        for n in psnames:\n            ET.SubElement(dict, \"key\").text = n\n            ET.SubElement(dict, \"string\").text = psnames[n]\n        font.lib.setelem(\"public.postscriptNames\", dict)\n\n    # Iterate over all glyphs, and fix up any components that reference renamed glyphs\n    for layer in font.layers:\n        for name in layer:\n            glyph = layer[name]\n            for component in glyph.etree.findall('./outline/component[@base]'):\n                oldname = component.get('base')\n                if oldname in nameMap:\n                    component.set('base', nameMap[oldname])\n                    logger.log(f'renamed component base {oldname} to {component.get(\"base\")} in glyph {name} layer {layer.layername}', 'I')\n            lib = glyph['lib']\n            if lib:\n                if 'com.schriftgestaltung.Glyphs.ComponentInfo' in lib:\n                    cielem = lib['com.schriftgestaltung.Glyphs.ComponentInfo'][1]\n                    for component in cielem:\n                        for i in range(0,len(component),2):\n                            if component[i].text == 'name':\n                                oldname = component[i+1].text\n                                if oldname in nameMap:\n                                    component[i+1].text = nameMap[oldname]\n                                    logger.log(f'renamed component info {oldname} to {nameMap[oldname]} in glyph {name} layer {layer.layername}', 'I')\n\n    # Delete anything we no longer need:\n    for name in deletelater:\n        for layer in font.layers:\n            if name in layer: layer.delGlyph(name)\n        logger.log(\"glyph %s removed\" % name, \"I\")\n\n    # Other structures with glyphs in are handled by looping round the structures replacing glyphs rather than\n    # looping round incsv\n\n    # Update Display Strings\n\n    if displayStrings:\n        changed = False\n        glyphRE = re.compile(r'/([a-zA-Z0-9_.-]+)') # regex to match / followed by a glyph name\n        for i, dispstr in enumerate(displayStrings):            # Passing the glyphSub function to .sub() causes it to\n            displayStrings[i] = glyphRE.sub(glyphsub, dispstr)  # every non-overlapping occurrence of pattern\n            if displayStrings[i] != dispstr:\n                changed = True\n        if changed:\n            array = ET.Element(\"array\")\n            for dispstr in displayStrings:\n                ET.SubElement(array, \"string\").text = dispstr\n            font.lib.setelem('com.schriftgestaltung.customParameter.GSFont.DisplayStrings', array)\n            logger.log(\"com.schriftgestaltung.customParameter.GSFont.DisplayStrings updated\", \"I\")\n\n    # Process groups.plist and kerning.plist\n    #   group names in the form public.kern[1|2].<glyph name> will automatically be renamed if the glyph name is in the csvmap\n    #\n    groups = kerning = None\n    kgroupprefixes = {\"public.kern1.\": 1, \"public.kern2.\": 2}\n\n    if \"groups\" in font.__dict__: groups = font.groups\n    if \"kerning\" in font.__dict__: kerning = font.kerning\n\n    if (groups or kerning) and mergemode:\n        logger.log(\"Note - Kerning and group data not processed when using mergecomps\", \"P\")\n    elif groups or kerning:\n\n        kgroupsmap = [\"\", {}, {}]  # Dicts of kern1/kern2 group renames.  Outside the groups if statement, since also used with kerning.plist\n        if groups:\n            # Analyse existing data, building dict from existing data and building some indexes\n            gdict = {}\n            kgroupsbyglyph =   [\"\", {}, {}]  # First entry dummy, so index is 1 or 2 for kern1 and kern2\n            kgroupduplicates = [\"\", [], []]  #\n            for gname in groups:\n                group = groups.getval(gname)\n                gdict[gname] = group\n                kprefix = gname[0:13]\n                if kprefix in kgroupprefixes:\n                    ktype = kgroupprefixes[kprefix]\n                    for glyph in group:\n                        if glyph in kgroupsbyglyph[ktype]:\n                            kgroupduplicates[ktype].append(glyph)\n                            logger.log(\"In existing kern groups, %s is in more than one kern%s group\" % (glyph, str(ktype)), \"E\")\n                            failerrors += 1\n                        else:\n                            kgroupsbyglyph[ktype][glyph] = gname\n            # Now process the group data\n            glyphsrenamed = []\n            saveforlaterKgroups = []\n            for gname in list(gdict): # Loop round groups renaming glyphs within groups and  kern group names\n                group = gdict[gname]\n\n                # Rename group if kern1 or kern2 group\n                kprefix = gname[:13]\n                if kprefix in kgroupprefixes:\n                    ktype = kgroupprefixes[kprefix]\n                    ksuffix = gname[13:]\n                    if ksuffix in csvmap: # This is a kern group that we should rename\n                        newgname = kprefix + csvmap[ksuffix]\n                        if newgname in gdict: # Will need to be renamed in second pass\n                            tempname = gettempname(lambda n : n not in gdict)\n                            gdict[tempname] = gdict.pop(gname)\n                            saveforlaterKgroups.append((tempname, gname, newgname))\n                        else:\n                            gdict[newgname] = gdict.pop(gname)\n                            kerngroupsrenamed[gname] = newgname\n                            logger.log(\"Pass 1 (Kern groups): Renamed %s to %s\" % (gname, newgname), \"I\")\n                        kgroupsmap[ktype][gname] = newgname\n\n                # Now rename glyphs within the group\n                # - This could lead to duplicate names, but that might be valid for arbitrary groups so not checked\n                # - kern group validity will be checked after all renaming is done\n\n                for (i, glyph) in enumerate(group):\n                    if glyph in csvmap:\n                        group[i] = csvmap[glyph]\n                        if glyph not in glyphsrenamed: glyphsrenamed.append(glyph)\n\n            # Need to report glyphs renamed after the loop, since otherwise could report multiple times\n            for oldname in glyphsrenamed:\n                nameMap[oldname] = csvmap[oldname]\n                logger.log(\"Glyphs in groups: Renamed %s to %s\" % (oldname, csvmap[oldname]), \"I\")\n\n            # Second pass for renaming kern groups. (All glyph renaming is done in first pass)\n\n            for (tempname, oldgname, newgname) in saveforlaterKgroups:\n                if newgname in gdict: # Can't rename\n                    logger.log(\"Kern group %s already in groups.plist; can't rename %s\" % (newgname, oldgname), \"E\")\n                    failerrors += 1\n                else:\n                    gdict[newgname] = gdict.pop(tempname)\n                    kerngroupsrenamed[oldgname] = newgname\n                    logger.log(\"Pass 2 (Kern groups): Renamed %s to %s\" % (oldgname, newgname), \"I\")\n\n            # Finally check kern groups follow the UFO rules!\n            kgroupsbyglyph = [\"\", {}, {}] # Reset for new analysis\n            for gname in gdict:\n                group = gdict[gname]\n                kprefix = gname[:13]\n                if kprefix in kgroupprefixes:\n                    ktype = kgroupprefixes[kprefix]\n                    for glyph in group:\n                        if glyph in kgroupsbyglyph[ktype]: # Glyph already in a kern group so we have a duplicate\n                            if glyph not in kgroupduplicates[ktype]: # This is a newly-created duplicate so report\n                                logger.log(\"After renaming, %s is in more than one kern%s group\" % (glyph, str(ktype)), \"E\")\n                                failerrors += 1\n                                kgroupduplicates[ktype].append(glyph)\n                        else:\n                            kgroupsbyglyph[ktype][glyph] = gname\n\n        # Now need to recreate groups.plist from gdict\n\n            for group in list(groups): groups.remove(group) # Empty existing contents\n            for gname in gdict:\n                elem = ET.Element(\"array\")\n                for glyph in gdict[gname]:\n                    ET.SubElement(elem, \"string\").text = glyph\n                groups.setelem(gname, elem)\n\n        # Now process kerning data\n        if kerning:\n            k1map = kgroupsmap[1]\n            k2map = kgroupsmap[2]\n            kdict = {}\n            for setname in kerning: kdict[setname] = kerning.getval(setname) # Create a working dict from plist\n            saveforlaterKsets = []\n            # First pass on set names\n            for setname in list(kdict): # setname could be a glyph in csvmap or a kern1 group name in k1map\n                if setname in csvmap or setname in k1map:\n                    newname = csvmap[setname] if setname in csvmap else k1map[setname]\n                    if newname in kdict:\n                        tempname = gettempname(lambda n : n not in kdict)\n                        kdict[tempname] = kdict.pop(setname)\n                        saveforlaterKsets.append((tempname, setname, newname))\n                    else:\n                        kdict[newname] = kdict.pop(setname)\n                        if setname in csvmap: nameMap[setname] = newname # Change to kern set name will have been logged previously\n                        logger.log(\"Pass 1 (Kern sets): Renamed %s to %s\" % (setname, newname), \"I\")\n\n            # Now do second pass for set names\n            for (tempname, oldname, newname) in saveforlaterKsets:\n                if newname in kdict:  # Can't rename\n                    logger.log(\"Kern set %s already in kerning.plist; can't rename %s\" % (newname, oldname), \"E\")\n                    failerrors += 1\n                else:\n                    kdict[newname] = kdict.pop(tempname)\n                    if oldname in csvmap: nameMap[oldname] = newname\n                    logger.log(\"Pass 1 (Kern sets): Renamed %s to %s\" % (oldname, newname), \"I\")\n\n            # Rename kern set members next.\n\n            # Here, since a member could be in more than one set, take different approach to two passes.\n            # - In first pass, rename to a temp (and invalid) name so duplicates are not possible.  Name to include\n            #   old name for reporting purposes\n            # - In second pass, set to correct new name after checking for duplicates\n\n            # Do first pass for set names\n            tempnames = []\n            for setname in list(kdict):\n                kset = kdict[setname]\n\n                for mname in list(kset): # mname could be a glyph in csvmap or a kern2 group name in k2map\n                    if mname in csvmap or mname in k2map:\n                        newname = csvmap[mname] if mname in csvmap else k2map[mname]\n                        newname = \"^\" + newname + \"^\" + mname\n                        if newname not in tempnames: tempnames.append(newname)\n                        kset[newname] = kset.pop(mname)\n\n            # Second pass to change temp names to correct final names\n            # We need an index of which sets each member is in\n            ksetsbymember = {}\n            for setname in kdict:\n                kset = kdict[setname]\n                for member in kset:\n                    if member not in ksetsbymember:\n                        ksetsbymember[member] = [setname]\n                    else:\n                        ksetsbymember[member].append(setname)\n            # Now do the renaming\n            for tname in tempnames:\n                (newname, oldname) = tname[1:].split(\"^\")\n                if newname in ksetsbymember:  # Can't rename\n                    logger.log(\"Kern set %s already in kerning.plist; can't rename %s\" % (newname, oldname), \"E\")\n                    failerrors += 1\n                else:\n                    for ksetname in ksetsbymember[tname]:\n                        kset = kdict[ksetname]\n                        kset[newname] = kset.pop(tname)\n                    ksetsbymember[newname] = ksetsbymember.pop(tname)\n                    if tname in csvmap: nameMap[oldname] = newname\n                    logger.log(\"Kern set members: Renamed %s to %s\" % (oldname, newname), \"I\")\n\n            # Now need to recreate kerning.plist from kdict\n            for kset in list(kerning): kerning.remove(kset)  # Empty existing contents\n            for kset in kdict:\n                elem = ET.Element(\"dict\")\n                for member in kdict[kset]:\n                    ET.SubElement(elem, \"key\").text = member\n                    ET.SubElement(elem, \"integer\").text = str(kdict[kset][member])\n                kerning.setelem(kset, elem)\n\n    if failerrors:\n        logger.log(str(failerrors) + \" issues detected - see errors reported above\", \"S\")\n\n    logger.log(\"%d glyphs renamed in UFO\" % (len(nameMap)), \"P\")\n    if kerngroupsrenamed: logger.log(\"%d kern groups renamed in UFO\" % (len(kerngroupsrenamed)), \"P\")\n\n    # If a classfile was provided, change names within it also\n    #\n    if args.classfile:\n\n        logger.log(\"Processing classfile {}\".format(args.classfile), \"P\")\n\n        # In order to preserve comments we use our own TreeBuilder\n        class MyTreeBuilder(ET.TreeBuilder):\n            def comment(self, data):\n                self.start(ET.Comment, {})\n                self.data(data)\n                self.end(ET.Comment)\n\n        # RE to match separators between glyph names (whitespace):\n        notGlyphnameRE = re.compile(r'(\\s+)')\n\n        # Keep a list of glyphnames that were / were not changed\n        changed = set()\n        notChanged = set()\n\n        # Process one token (might be whitespace separator, glyph name, or embedded classname starting with @):\n        def dochange(gname, logErrors = True):\n            if len(gname) == 0 or gname.isspace() or gname not in csvmap or gname.startswith('@'):\n                # No change\n                return gname\n            try:\n                newgname = csvmap[gname]\n                changed.add(gname)\n                return newgname\n            except KeyError:\n                if logErrors: notChanged.add(gname)\n                return gname\n\n        doc = ET.parse(args.classfile, parser=ET.XMLParser(target=MyTreeBuilder()))\n        for e in doc.iter(None):\n            if e.tag in ('class', 'property'):\n                if 'exts' in e.attrib:\n                    logger.log(\"{} '{}' has 'exts' attribute which may need editing\".format(e.tag.title(), e.get('name')), \"W\")\n                # Rather than just split() the text, we'll use re and thus try to preserve whitespace\n                e.text = ''.join([dochange(x) for x in notGlyphnameRE.split(e.text)])\n            elif e.tag is ET.Comment:\n                # Go ahead and look for glyph names in comment text but don't flag as error\n                e.text = ''.join([dochange(x, False) for x in notGlyphnameRE.split(e.text)])\n                # and process the tail as this might be valid part of class or property\n                e.tail = ''.join([dochange(x) for x in notGlyphnameRE.split(e.tail)])\n\n\n        if len(changed):\n            # Something in classes changed so rewrite it... saving  backup\n            (dn,fn) = os.path.split(args.classfile)\n            dn = os.path.join(dn, args.paramsobj.sets['main']['backupdir'])\n            if not os.path.isdir(dn):\n                os.makedirs(dn)\n            # Work out backup name based on existing backups\n            backupname = os.path.join(dn,fn)\n            nums = [int(re.search(r'\\.(\\d+)~$',n).group(1)) for n in glob(backupname + \".*~\")]\n            backupname += \".{}~\".format(max(nums) + 1 if nums else 1)\n            logger.log(\"Backing up input classfile to {}\".format(backupname), \"P\")\n            # Move the original file to backupname\n            os.rename(args.classfile, backupname)\n            # Write the output file\n            doc.write(args.classfile)\n\n            if len(notChanged):\n                logger.log(\"{} glyphs renamed, {} NOT renamed in {}: {}\".format(len(changed), len(notChanged), args.classfile, ' '.join(notChanged)), \"W\")\n            else:\n                logger.log(\"All {} glyphs renamed in {}\".format(len(changed), args.classfile), \"P\")\n\n    return font",
  "def mergeglyphs(mergefrom, mergeto): # Merge any \"moving\" anchors (i.e., those starting with '_') into the glyph we're keeping\n    # Assumption: we are merging one or more component references to just one component; deleting the others\n    for a in mergefrom['anchor']:\n        aname = a.element.get('name')\n        if aname.startswith('_'):\n            # We want to copy this anchor to the glyph being kept:\n            for i, a2 in enumerate(mergeto['anchor']):\n                if a2.element.get('name') == aname:\n                    # Overwrite existing anchor of same name\n                    mergeto['anchor'][i] = a\n                    break\n            else:\n                # Append anchor to glyph\n                mergeto['anchor'].append(a)",
  "def gettempname(f):\n    ''' return a temporary glyph name that, when passed to function f(), returns true'''\n    # Initialize function attribute for use as counter\n    if not hasattr(gettempname, \"counter\"): gettempname.counter = 0\n    while True:\n        name = \"tempglyph%d\" % gettempname.counter\n        gettempname.counter += 1\n        if f(name): return name",
  "def glyphsub(m): # Function passed to re.sub() when updating display strings\n    global csvmap\n    gname = m.group(1)\n    return '/' + csvmap[gname] if gname in csvmap else m.group(0)",
  "def cmd() : execute(\"UFO\",doit,argspec)",
  "class MyTreeBuilder(ET.TreeBuilder):\n            def comment(self, data):\n                self.start(ET.Comment, {})\n                self.data(data)\n                self.end(ET.Comment)",
  "def dochange(gname, logErrors = True):\n            if len(gname) == 0 or gname.isspace() or gname not in csvmap or gname.startswith('@'):\n                # No change\n                return gname\n            try:\n                newgname = csvmap[gname]\n                changed.add(gname)\n                return newgname\n            except KeyError:\n                if logErrors: notChanged.add(gname)\n                return gname",
  "def comment(self, data):\n                self.start(ET.Comment, {})\n                self.data(data)\n                self.end(ET.Comment)",
  "def doit(args) :\n    font = args.ifont\n    logger = args.logger\n\n    # Process csv list into a dictionary structure\n    args.input.numfields = 3\n    deps = {}\n    for line in args.input :\n        deps[line[0]] = {\"newname\": line[1], \"newuni\": line[2]}\n\n    # Iterate through dictionary (unsorted)\n    for source, target in deps.items() :\n        # Check if source glyph is in font\n        if source in font.keys() :\n            # Give warning if target is already in font, but overwrite anyway\n            targetname = target[\"newname\"]\n            targetuni = int(target[\"newuni\"], 16)\n            if targetname in font.keys() :\n                logger.log(\"Warning: \" + targetname + \" already in font and will be replaced\")\n\n            # Make a copy of source into a new glyph object\n            sourceglyph = font[source]            \n            newglyph = sourceglyph.copy()\n            \n            # Draw box around it\n            xmin, ymin, xmax, ymax = sourceglyph.bounds\n            pen = newglyph.getPen()\n            pen.moveTo((xmax + offset, ymin - offset))\n            pen.lineTo((xmax + offset, ymax + offset))\n            pen.lineTo((xmin - offset, ymax + offset))\n            pen.lineTo((xmin - offset, ymin - offset))\n            pen.closePath()\n\n            # Set unicode\n            newglyph.unicodes = []\n            newglyph.unicode = targetuni\n\n            # Add the new glyph object to the font with name target\n            font.__setitem__(targetname,newglyph)\n\n            # Decompose glyph in case there may be components\n            # It seems you can't decompose a glyph has hasn't yet been added to a font\n            font[targetname].decompose()\n            # Correct path direction            \n            font[targetname].correctDirection()            \n\n            logger.log(source + \" duplicated to \" + targetname)\n        else :\n            logger.log(\"Warning: \" + source + \" not in font\")\n\n    return font",
  "def cmd() : execute(\"FP\",doit,argspec)",
  "def hextounichr(match):\n    return chr(int(match.group(1),16))",
  "def BoldItalic(bold, italic):\n    rs = \"\"\n    if bold:\n        rs += \" Bold\"\n    if italic:\n        rs += \" Italic\"\n    return rs",
  "def parsefeats(inputline):\n    featdic = {}\n    while inputline != \"\":\n        results = re.match(onefeat, inputline)\n        if results:\n            featdic[results.group('featname')] = results.group('featval')\n            inputline = results.group('remainder')\n        else:\n            break ### warning about unrecognized feature string: inputline\n    return \":\" + \"&\".join( [f + '=' + featdic[f] for f in sorted(featdic)])",
  "def getfonts(fontsourcestrings, logfile, fromcommandline=True):\n    fontlist = []\n    checkfontfamily = []\n    checkembeddedfont = []\n    for fs in fontsourcestrings:\n        if not fromcommandline: # from FTML <fontsrc> either local() or url()\n            installed = True    # Assume locally installed font\n            results = re.match(findfontnamelocal, fs)\n            fontstring = results.group('fontstring') if results else None\n            if fontstring == None:\n                installed = False\n                results = re.match(findfontnameurl, fs)\n                fontstring = results.group('fontstring') if results else None\n            if fontstring == None:\n                logfile.log(\"Invalid font specification: \" + fs, \"S\")\n        else:                   # from command line\n            fontstring = fs\n            if \".\" in fs:       # must be a filename\n                installed = False\n            else:               # must be an installed font\n                installed = True\n        if installed:\n            # get name, bold and italic info from string\n            results = re.match(fontspec, fontstring.strip())\n            if results:\n                fontname = results.group('rest')\n                bold = results.group('bold') != None\n                italic = results.group('italic') != None\n                fontlist.append( (fontname, bold, italic, None) )\n                if (fontname, bold, italic) in checkfontfamily:\n                    logfile.log(\"Duplicate font specification: \" + fs, \"W\") ### or more severe?\n                else:\n                    checkfontfamily.append( (fontname, bold, italic) )\n            else:\n                logfile.log(\"Invalid font specification: \" + fontstring.strip(), \"E\")\n        else:\n            try:\n                # peek inside the font for the name, weight, style\n                f = ttLib.TTFont(fontstring)\n                # take name from name table, NameID 1, platform ID 3, Encoding ID 1 (possible fallback platformID 1, EncodingID =0)\n                n = f['name'] # name table from font\n                fontname = n.getName(1,3,1).toUnicode() # nameID 1 = Font Family name\n                # take bold and italic info from OS/2 table, fsSelection bits 0 and 5\n                o = f['OS/2'] # OS/2 table\n                italic = (o.fsSelection & 1) > 0\n                bold = (o.fsSelection & 32) > 0\n                fontlist.append( (fontname, bold, italic, fontstring) )\n                if (fontname, bold, italic) in checkfontfamily:\n                    logfile.log(\"Duplicate font specification: \" + fs + BoldItalic(bold, italic), \"W\") ### or more severe?\n                else:\n                    checkfontfamily.append( (fontname, bold, italic) )\n                if (os.path.basename(fontstring)) in checkembeddedfont:\n                    logfile.log(\"Duplicate embedded font: \" + fontstring, \"W\") ### or more severe?\n                else:\n                    checkembeddedfont.append(os.path.basename(fontstring))\n            except IOError:\n                logfile.log(\"Unable to find font file to embed: \" + fontstring, \"E\")\n            except fontTools.ttLib.TTLibError:\n                logfile.log(\"File is not a valid font: \" + fontstring, \"E\")\n            except:\n                logfile.log(\"Error occurred while checking font: \" + fontstring, \"E\") # some other error\n    return fontlist",
  "def init(LOdoc, numfonts=1):\n    totalwid = 6800 #6.8inches\n\n    #compute column widths\n    f = min(numfonts,4)\n    ashare = 4*(6-f)\n    dshare = 2*(6-f)\n    bshare = 100 - 2*ashare - dshare\n    awid = totalwid * ashare // 100\n    dwid = totalwid * dshare // 100\n    bwid = totalwid * bshare // (numfonts * 100)\n\n    # create styles for table, for columns (one style for each column width)\n    # and for one cell (used for everywhere except where background changed)\n    tstyle = Style(name=\"Table1\", family=\"table\")\n    tstyle.addElement(TableProperties(attributes={'width':str(totalwid/1000.)+\"in\", 'align':\"left\"}))\n    LOdoc.automaticstyles.addElement(tstyle)\n    tastyle = Style(name=\"Table1.A\", family=\"table-column\")\n    tastyle.addElement(TableColumnProperties(attributes={'columnwidth':str(awid/1000.)+\"in\"}))\n    LOdoc.automaticstyles.addElement(tastyle)\n    tbstyle = Style(name=\"Table1.B\", family=\"table-column\")\n    tbstyle.addElement(TableColumnProperties(attributes={'columnwidth':str(bwid/1000.)+\"in\"}))\n    LOdoc.automaticstyles.addElement(tbstyle)\n    tdstyle = Style(name=\"Table1.D\", family=\"table-column\")\n    tdstyle.addElement(TableColumnProperties(attributes={'columnwidth':str(dwid/1000.)+\"in\"}))\n    LOdoc.automaticstyles.addElement(tdstyle)\n    ta1style = Style(name=\"Table1.A1\", family=\"table-cell\")\n    ta1style.addElement(TableCellProperties(attributes={'padding':\"0.035in\", 'border':\"0.05pt solid #000000\"}))\n    LOdoc.automaticstyles.addElement(ta1style)\n    # text style used with non-<em> text\n    t1style = Style(name=\"T1\", family=\"text\")\n    t1style.addElement(TextProperties(attributes={'color':\"#999999\" }))\n    LOdoc.automaticstyles.addElement(t1style)\n    # create styles for Title, Subtitle\n    tstyle = Style(name=\"Title\", family=\"paragraph\")\n    tstyle.addElement(TextProperties(attributes={'fontfamily':\"Arial\",'fontsize':\"24pt\",'fontweight':\"bold\" }))\n    LOdoc.styles.addElement(tstyle)\n    ststyle = Style(name=\"Subtitle\", family=\"paragraph\")\n    ststyle.addElement(TextProperties(attributes={'fontfamily':\"Arial\",'fontsize':\"18pt\",'fontweight':\"bold\" }))\n    LOdoc.styles.addElement(ststyle)",
  "def doit(args) :\n    logfile = args.logger\n    if args.report: logfile.loglevel = args.report\n\n    try:\n        root = ET.parse(args.input).getroot()\n    except:\n        logfile.log(\"Error parsing FTML input\", \"S\")\n\n    if args.font:                   # font(s) specified on command line\n        fontlist = getfonts( args.font, logfile )\n    else:                           # get font spec from FTML fontsrc element\n        fontlist = getfonts( [root.find(\"./head/fontsrc\").text], logfile, False )\n        #fontlist = getfonts( [fs.text for fs in root.findall(\"./head/fontsrc\")], False ) ### would allow multiple fontsrc elements\n    numfonts = len(fontlist)\n    if numfonts == 0:\n        logfile.log(\"No font(s) specified\", \"S\")\n    if numfonts > 1:\n        formattedfontnum = [\"{0:02d}\".format(n) for n in range(numfonts)]\n    else:\n        formattedfontnum = [\"\"]\n    logfile.log(\"Font(s) specified:\", \"V\")\n    for n, (fontname, bold, italic, embeddedfont) in enumerate(fontlist):\n        logfile.log(\" \" + formattedfontnum[n] + \" \" + fontname + BoldItalic(bold, italic) + \" \" + str(embeddedfont), \"V\")\n\n    # get optional fontscale; compute pointsize as int(12*fontscale/100). If result xx is not 12, then add \"fo:font-size=xxpt\" in Px styles\n    pointsize = 12\n    fontscaleel = root.find(\"./head/fontscale\")\n    if fontscaleel != None:\n        fontscale = fontscaleel.text\n        try:\n            pointsize = int(int(fontscale)*12/100)\n        except ValueError:\n            # any problem leaves pointsize 12\n            logfile.log(\"Problem with fontscale value; defaulting to 12 point\", \"W\")\n\n    # Get FTML styles and generate LO writer styles\n    # P2 is paragraph style for string element when no features specified\n    # each Px (for P3...) corresponds to an FTML style, which specifies lang or feats or both\n    # if numfonts > 1, two-digit font number is appended to make an LO writer style for each FTML style + font combo\n    # When LO writer style is used with attribute rtl=\"True\", \"R\" appended to style name\n    LOstyles = {}\n    ftmlstyles = {}\n    Pstylenum = 2\n    LOstyles[\"P2\"] = (\"\", None, None)\n    ftmlstyles[0] = \"P2\"\n    for s in root.findall(\"./head/styles/style\"):\n        Pstylenum += 1\n        Pnum = \"P\" + str(Pstylenum)\n        featstring = \"\"\n        if s.get('feats'):\n            featstring = parsefeats(s.get('feats'))\n        langname = None\n        countryname = None\n        lang = s.get('lang')\n        if lang != None:\n            x = re.match(langcode, lang)\n            langname = x.group('langname')\n            countryname = x.group('countryname')\n        # FTML <test> element @stylename attribute references this <style> element @name attribute\n        ftmlstyles[s.get('name')] = Pnum\n        LOstyles[Pnum] = (featstring, langname, countryname)\n\n    # create LOwriter file and construct styles for tables, column widths, etc.\n    LOdoc = OpenDocumentText()\n    init(LOdoc, numfonts)\n    # Initialize sequence counters\n    sds = SequenceDecls()\n    sd = sds.addElement(SequenceDecl(displayoutlinelevel = '0', name = 'Illustration'))\n    sd = sds.addElement(SequenceDecl(displayoutlinelevel = '0', name = 'Table'))\n    sd = sds.addElement(SequenceDecl(displayoutlinelevel = '0', name = 'Text'))\n    sd = sds.addElement(SequenceDecl(displayoutlinelevel = '0', name = 'Drawing'))\n    LOdoc.text.addElement(sds)\n\n    # Create Px style for each (featstring, langname, countryname) tuple in LOstyles\n    # and for each font (if >1 font, append to Px style name a two-digit number corresponding to the font in fontlist)\n    # and (if at least one rtl attribute) suffix of nothing or \"R\"\n    # At the same time, collect info for creating FontFace elements (and any embedded fonts)\n    suffixlist = [\"\", \"R\"] if root.find(\".//test/[@rtl='True']\") != None else [\"\"]\n    fontfaces = {}\n    for p in sorted(LOstyles, key = lambda x : int(x[1:])):  # key = lambda x : int(x[1:]) corrects sort order\n        featstring, langname, countryname = LOstyles[p]\n        for n, (fontname, bold, italic, embeddedfont) in enumerate(fontlist): # embeddedfont = None if no embedding needed\n            fontnum = formattedfontnum[n]\n            # Collect fontface info: need one for each font family + feature combination\n            # Put embedded font in list only under fontname with empty featstring\n            if (fontname, featstring) not in fontfaces:\n                fontfaces[ (fontname, featstring) ] = []\n            if embeddedfont:\n                if (fontname, \"\") not in fontfaces:\n                    fontfaces[ (fontname, \"\") ] = []\n                if embeddedfont not in fontfaces[ (fontname, \"\") ]:\n                    fontfaces[ (fontname, \"\") ].append(embeddedfont)\n            # Generate paragraph styles\n            for s in suffixlist:\n                pstyle = Style(name=p+fontnum+s, family=\"paragraph\")\n                if s == \"R\":\n                    pstyle.addElement(ParagraphProperties(textalign=\"end\", justifysingleword=\"false\", writingmode=\"rl-tb\"))\n                pstyledic = {}\n                pstyledic['fontnamecomplex'] = \\\n                pstyledic['fontnameasian'] =\\\n                pstyledic['fontname'] = fontname + featstring\n                pstyledic['fontsizecomplex'] = \\\n                pstyledic['fontsizeasian'] = \\\n                pstyledic['fontsize'] = str(pointsize) + \"pt\"\n                if bold:\n                    pstyledic['fontweightcomplex'] = \\\n                    pstyledic['fontweightasian'] = \\\n                    pstyledic['fontweight'] = 'bold'\n                if italic:\n                    pstyledic['fontstylecomplex'] = \\\n                    pstyledic['fontstyleasian'] = \\\n                    pstyledic['fontstyle'] = 'italic'\n                if langname != None:\n                    pstyledic['languagecomplex'] = \\\n                    pstyledic['languageasian'] = \\\n                    pstyledic['language'] = langname\n                if countryname != None:\n                    pstyledic['countrycomplex'] = \\\n                    pstyledic['countryasian'] = \\\n                    pstyledic['country'] = countryname\n                pstyle.addElement(TextProperties(attributes=pstyledic))\n#                LOdoc.styles.addElement(pstyle)    ### tried this, but when saving the generated odt, LO changed them to automatic styles\n                LOdoc.automaticstyles.addElement(pstyle)\n\n    fontstoembed = []\n    for fontname, featstring in sorted(fontfaces):  ### Or find a way to keep order of <style> elements from original FTML?\n        ff = FontFace(name=fontname + featstring, fontfamily=fontname + featstring, fontpitch=\"variable\")\n        LOdoc.fontfacedecls.addElement(ff)\n        if fontfaces[ (fontname, featstring) ]:     # embedding needed for this combination\n            for fontfile in fontfaces[ (fontname, featstring) ]:\n                fontstoembed.append(fontfile)       # make list for embedding\n                ffsrc = FontFaceSrc()\n                ffuri = FontFaceUri( **{'href': \"Fonts/\" + os.path.basename(fontfile), 'type': \"simple\"} )\n                ffformat = FontFaceFormat( **{'string': 'truetype'} )\n                ff.addElement(ffsrc)\n                ffsrc.addElement(ffuri)\n                ffuri.addElement(ffformat)\n\n    basename = \"Table1.B\"\n    colorcount = 0\n    colordic = {} # record color #rrggbb as key and \"Table1.Bx\" as stylename (where x is current color count)\n    tablenum = 0\n\n    # get title and comment and use as title and subtitle\n    titleel = root.find(\"./head/title\")\n    if titleel != None:\n        LOdoc.text.addElement(H(outlinelevel=1, stylename=\"Title\", text=titleel.text))\n    commentel = root.find(\"./head/comment\")\n    if commentel != None:\n        LOdoc.text.addElement(P(stylename=\"Subtitle\", text=commentel.text))\n\n    # Each testgroup element begins a new table\n    for tg in root.findall(\"./testgroup\"):\n        # insert label attribute of testgroup element as subtitle\n        tglabel = tg.get('label')\n        if tglabel != None:\n            LOdoc.text.addElement(H(outlinelevel=1, stylename=\"Subtitle\", text=tglabel))\n\n        # insert text from comment subelement of testgroup element\n        tgcommentel = tg.find(\"./comment\")\n        if tgcommentel != None:\n            #print(\"commentel found\")\n            LOdoc.text.addElement(P(text=tgcommentel.text))\n\n        tgbg = tg.get('background') # background attribute of testgroup element\n        tablenum += 1\n        table = Table(name=\"Table\" + str(tablenum), stylename=\"Table1\")\n        table.addElement(TableColumn(stylename=\"Table1.A\"))\n        for n in range(numfonts):\n            table.addElement(TableColumn(stylename=\"Table1.B\"))\n        table.addElement(TableColumn(stylename=\"Table1.A\"))\n        table.addElement(TableColumn(stylename=\"Table1.D\"))\n        for t in tg.findall(\"./test\"):                # Each test element begins a new row\n            # stuff to start the row\n            labeltext = t.get('label')\n            stylename = t.get('stylename')\n            stringel = t.find('./string')\n            commentel = t.find('./comment')\n            rtlsuffix = \"R\" if t.get('rtl') == 'True' else \"\"\n            comment = commentel.text if commentel != None else None\n            colBstyle = \"Table1.A1\"\n            tbg = t.get('background')   # get background attribute of test group (if one exists)\n            if tbg == None: tbg = tgbg\n            if tbg != None:             # if background attribute for test element (or background attribute for testgroup element)\n                if tbg not in colordic: # if color not found in color dic, create new style\n                    colorcount += 1\n                    newname = basename + str(colorcount)\n                    colordic[tbg] = newname\n                    tb1style = Style(name=newname, family=\"table-cell\")\n                    tb1style.addElement(TableCellProperties(attributes={'padding':\"0.0382in\", 'border':\"0.05pt solid #000000\", 'backgroundcolor':tbg}))\n                    LOdoc.automaticstyles.addElement(tb1style)\n                colBstyle = colordic[tbg]\n\n            row = TableRow()\n            table.addElement(row)\n            # fill cells\n            # column A (label)\n            cell = TableCell(stylename=\"Table1.A1\", valuetype=\"string\")\n            if labeltext:\n                cell.addElement(P(stylename=\"Table_20_Contents\", text = labeltext))\n            row.addElement(cell)\n\n            # column B (string)\n            for n in range(numfonts):\n                Pnum = ftmlstyles[stylename] if stylename != None else \"P2\"\n                Pnum = Pnum + formattedfontnum[n] + rtlsuffix\n                ### not clear if any of the following can be moved outside loop and reused\n                cell = TableCell(stylename=colBstyle, valuetype=\"string\")\n                par = P(stylename=Pnum)\n                if len(stringel) == 0: # no <em> subelements\n                    par.addText(re.sub(backu, hextounichr, stringel.text))\n                else:   # handle <em> subelement(s)\n                    if stringel.text != None:\n                        par.addElement(Span(stylename=\"T1\", text = re.sub(backu, hextounichr, stringel.text)))\n                    for e in stringel.findall(\"em\"):\n                        if e.text != None:\n                            par.addText(re.sub(backu, hextounichr, e.text))\n                        if e.tail != None:\n                            par.addElement(Span(stylename=\"T1\", text = re.sub(backu, hextounichr, e.tail)))\n                cell.addElement(par)\n                row.addElement(cell)\n\n            # column C (comment)\n            cell = TableCell(stylename=\"Table1.A1\", valuetype=\"string\")\n            if comment:\n                cell.addElement(P(stylename=\"Table_20_Contents\", text = comment))\n            row.addElement(cell)\n\n            # column D (stylename)\n            cell = TableCell(stylename=\"Table1.A1\", valuetype=\"string\")\n            if comment:\n                cell.addElement(P(stylename=\"Table_20_Contents\", text = stylename))\n            row.addElement(cell)\n        LOdoc.text.addElement(table)\n\n    LOdoc.text.addElement(P(stylename=\"Subtitle\", text=\"\")) # Empty paragraph to end ### necessary?\n\n    try:\n        if fontstoembed: logfile.log(\"Embedding fonts in document\", \"V\")\n        for f in fontstoembed:\n            LOdoc._extra.append(\n                OpaqueObject(filename = \"Fonts/\" + os.path.basename(f),\n                    mediatype = \"application/x-font-ttf\",      ### should be \"application/font-woff\" or \"/font-woff2\" for WOFF fonts, \"/font-opentype\" for ttf\n                    content = io.open(f, \"rb\").read() ))\n        ci = ConfigItem(**{'name':'EmbedFonts', 'type': 'boolean'}) ### (name = 'EmbedFonts', type = 'boolean')\n        ci.addText('true')\n        cis=ConfigItemSet(**{'name':'ooo:configuration-settings'})  ### (name = 'ooo:configuration-settings')\n        cis.addElement(ci)\n        LOdoc.settings.addElement(cis)\n    except:\n        logfile.log(\"Error embedding fonts in document\", \"E\")\n    logfile.log(\"Writing output file: \" + args.output, \"P\")\n    LOdoc.save(args.output)\n    return",
  "def cmd() : execute(\"\",doit, argspec)",
  "def doit(args) :\n    font = args.ifont\n    incsv = args.input\n    incsv.minfields = 2\n    incsv.maxfields = 3\n    incsv.logger = font.logger\n    glyphlist = list(font.deflayer.keys()) # Identify which glifs have not got an AssocFeat set\n\n    for line in incsv :\n        glyphn = line[0]\n        feature = line[1]\n        value = line[2] if len(line) == 3 else \"\"\n\n        if glyphn in glyphlist :\n            glyph = font.deflayer[glyphn]\n            if glyph[\"lib\"] is None : glyph.add(\"lib\")\n            glyph[\"lib\"].setval(\"org.sil.assocFeature\",\"string\",feature)\n            if value != \"\" :\n                glyph[\"lib\"].setval(\"org.sil.assocFeatureValue\",\"integer\",value)\n            else :\n                if \"org.sil.assocFeatureValue\" in glyph[\"lib\"] : glyph[\"lib\"].remove(\"org.sil.assocFeatureValue\")\n            glyphlist.remove(glyphn)\n        else :\n            font.logger.log(\"No glyph in font for \" + glyphn + \" on line \" + str(incsv.line_num),\"E\")\n\n    for glyphn in glyphlist : # Remove any values from remaining glyphs\n        glyph = font.deflayer[glyphn]\n        if glyph[\"lib\"] :\n            if \"org.sil.assocFeatureValue\" in glyph[\"lib\"] : glyph[\"lib\"].remove(\"org.sil.assocFeatureValue\")\n            if \"org.sil.assocFeature\" in glyph[\"lib\"] :\n                glyph[\"lib\"].remove(\"org.sil.assocFeature\")\n                font.logger.log(\"Feature info removed for \" + glyphn,\"I\")\n\n    return font",
  "def cmd() : execute(\"UFO\",doit,argspec)",
  "def doit(args):\n    font = args.ifont\n    incsv = args.input\n    logger = args.logger\n    removemissing = args.removemissing\n\n    fields = args.field.split(\",\")\n    fieldcount = len(fields)\n    headers = args.header.split(\",\")\n    if fieldcount != len(headers): logger.log(\"Must specify same number of values in --field and --header\", \"S\")\n    gname = args.gname\n\n    # Identify file format from first line then create glyphdata[] with glyph name then one column per header\n    glyphdata = {}\n    fl = incsv.firstline\n    if fl is None: logger.log(\"Empty input file\", \"S\")\n    numfields = len(fl)\n    incsv.numfields = numfields\n    fieldpos = []\n    if numfields > 1:  # More than 1 column, so must have headers\n        if gname in fl:\n            glyphnpos = fl.index(gname)\n        else:\n            logger.log(\"No\" + gname + \"field in csv headers\", \"S\")\n        for header in headers:\n            if header in fl:\n                pos = fl.index(header)\n                fieldpos.append(pos)\n            else:\n                logger.log('No \"' + header + '\" heading in csv headers\"', \"S\")\n        next(incsv.reader, None)  # Skip first line with headers in\n        for line in incsv:\n            glyphn = line[glyphnpos]\n            if len(glyphn) == 0:\n                continue\t# No need to include cases where name is blank\n            glyphdata[glyphn]=[]\n            for pos in fieldpos: glyphdata[glyphn].append(float(line[pos]))\n    elif numfields == 1:   # Simple text file.  Create glyphdata in same format as for csv files\n        for i, line in enumerate(incsv): glyphdata[line[0]]=(i,)\n    else:\n        logger.log(\"Invalid csv file\", \"S\")\n\n    # Now process the data\n    if \"lib\" not in font.__dict__: font.addfile(\"lib\")\n    glyphlist = list(font.deflayer.keys())\n\n    for i in range(0,fieldcount):\n        array = ET.Element(\"array\")\n        for glyphn, vals in sorted(glyphdata.items(), key=lambda item: item[1][i]):\n            if glyphn in glyphlist:\n                sub = ET.SubElement(array, \"string\")\n                sub.text = glyphn\n            else:\n                font.logger.log(\"No glyph in font for \" + glyphn, \"I\")\n                if not removemissing:\n                    sub = ET.SubElement(array, \"string\")\n                    sub.text = glyphn\n        font.lib.setelem(fields[i-1],array)\n\n    for glyphn in sorted(glyphlist):  # Remaining glyphs were not in the input file\n        if glyphn not in glyphdata: font.logger.log(\"No entry in input file for font glyph \" + glyphn, \"I\")\n\n    return font",
  "def cmd(): execute(\"UFO\", doit, argspec)",
  "class Glyph:\n    \"\"\"details about a glyph we have, or need to, copy; mostly just for syntactic sugar\"\"\"\n\n    # Glyphs that are used *only* as component glyphs may have to be renamed if there already exists a glyph\n    # by the same name in the target font. we compute a new name by appending .copy1, .copy2, etc until we get a\n    # unique name. We keep track of the mapping from source font glyphname to target font glyphname using a dictionary.\n    # For ease of use, glyphs named by the input file (which won't have their names changed, see --force) will also\n    # be added to this dictionary because they can also be used as components.\n    nameMap = dict()\n\n    def __init__(self, oldname, newname=\"\", psname=\"\", dusv=None):\n        self.oldname = oldname\n        self.newname = newname or oldname\n        self.psname = psname or None\n        self.dusv = dusv or None\n        # Keep track of old-to-new name mapping\n        Glyph.nameMap[oldname] = self.newname",
  "def copyglyph(sfont, tfont, g, args):\n    \"\"\"copy glyph from source font to target font\"\"\"\n    # Generally, 't' variables are target, 's' are source. E.g., tfont is target font.\n\n    global dusv2gname\n    if not dusv2gname:\n        # Create mappings to find exsting glyph name from decimal usv:\n        dusv2gname = {int(unicode.hex, 16): gname for gname in tfont.deflayer for unicode in tfont.deflayer[gname]['unicode']}\n        # NB: Assumes font is well-formed and has at most one glyph with any particular Unicode value.\n\n    # The layer where we want the copied glyph:\n    tlayer = tfont.deflayer\n\n    # if new name present in target layer, delete it.\n    if g.newname in tlayer:\n        # New name is already in font:\n        tfont.logger.log(\"Replacing glyph '{0}' with new glyph\".format(g.newname), \"V\")\n        glyph = tlayer[g.newname]\n        # While here, remove from our mapping any Unicodes from the old glyph:\n        for unicode in glyph[\"unicode\"]:\n            dusv = int(unicode.hex, 16)\n            if dusv in dusv2gname:\n                del dusv2gname[dusv]\n        # Ok, remove old glyph from the layer\n        tlayer.delGlyph(g.newname)\n    else:\n        # New name is not in the font:\n        tfont.logger.log(\"Adding glyph '{0}'\".format(g.newname), \"V\")\n\n    # Create new glyph\n    glyph = Uglif(layer = tlayer)\n    # Set etree from source glyph\n    glyph.etree = ET.fromstring(sfont.deflayer[g.oldname].inxmlstr)\n    glyph.process_etree()\n    # Rename the glyph if needed\n    if glyph.name != g.newname:\n        # Use super to bypass normal glyph renaming logic since it isn't yet in the layer\n        super(Uglif, glyph).__setattr__(\"name\", g.newname)\n    # add new glyph to layer:\n    tlayer.addGlyph(glyph)\n    tfont.logger.log(\"Added glyph '{0}'\".format(g.newname), \"V\")\n\n    # todo: set psname if requested; adjusting any other glyphs in the font as needed.\n\n    # Adjust encoding of new glyph\n    if args.unicode:\n        # First remove any encodings the copied glyph had in the source font:\n        for i in range(len(glyph['unicode']) - 1, -1, -1):\n            glyph.remove('unicode', index=i)\n        if g.dusv:\n            # we want this glyph to be encoded.\n            # First remove this Unicode from any other glyph in the target font\n            if g.dusv in dusv2gname:\n                oglyph = tlayer[dusv2gname[g.dusv]]\n                for unicode in oglyph[\"unicode\"]:\n                    if int(unicode.hex,16) == g.dusv:\n                        oglyph.remove(\"unicode\", object=unicode)\n                        tfont.logger.log(\"Removed USV {0:04X} from existing glyph '{1}'\".format(g.dusv,dusv2gname[g.dusv]), \"V\")\n                        break\n            # Now add and record it:\n            glyph.add(\"unicode\", {\"hex\": '{:04X}'.format(g.dusv)})\n            dusv2gname[g.dusv] = g.newname\n            tfont.logger.log(\"Added USV {0:04X} to glyph '{1}'\".format(g.dusv, g.newname), \"V\")\n\n    # Scale glyph if desired\n    if args.scale:\n        for e in glyph.etree.iter():\n            for attr in ('width', 'height', 'x', 'y', 'xOffset', 'yOffset'):\n                if attr in e.attrib: e.set(attr, str(int(float(e.get(attr))* args.scale)))\n\n    # Look through components, adjusting names and finding out if we need to copy some.\n    for component in glyph.etree.findall('./outline/component[@base]'):\n        oldname = component.get('base')\n        # Note: the following will cause recursion:\n        component.set('base', copyComponent(sfont, tfont, oldname ,args))",
  "def copyComponent(sfont, tfont, oldname, args):\n    \"\"\"copy component glyph if not already copied; make sure name and psname are unique; return its new name\"\"\"\n    if oldname in Glyph.nameMap:\n        # already copied\n        return Glyph.nameMap[oldname]\n\n    # if oldname is already in the target font, make up a new name by adding \".copy1\", incrementing as necessary\n    if oldname not in tfont.deflayer:\n        newname = oldname\n        tfont.logger.log(\"Copying component '{0}' with existing name\".format(oldname), \"V\")\n    else:\n        x = gcopyRE.match(oldname)\n        base = x.group(1)\n        try: i = int(x.group(2))\n        except: i = 1\n        while \"{0}.copy{1}\".format(base,i) in tfont.deflayer:\n            i += 1\n        newname = \"{0}.copy{1}\".format(base,i)\n        tfont.logger.log(\"Copying component '{0}' with new name '{1}'\".format(oldname, newname), \"V\")\n\n    # todo: something similar to above but for psname\n\n    # Now copy the glyph, giving it new name if needed.\n    copyglyph(sfont, tfont, Glyph(oldname, newname), args)\n\n    return newname",
  "def doit(args) :\n    sfont = args.source  # source UFO\n    tfont = args.ifont   # target UFO\n    incsv = args.input\n    logger = args.logger\n\n    # Get headings from csvfile:\n    fl = incsv.firstline\n    if fl is None: logger.log(\"Empty input file\", \"S\")\n    numfields = len(fl)\n    incsv.numfields = numfields\n    # defaults for single column csv (no headers):\n    nameCol = 0\n    renameCol = None\n    psCol = None\n    usvCol = None\n    if numfields > 1 or args.rename or args.unicode:\n        # required columns:\n        try:\n            nameCol = fl.index('glyph_name');\n            if args.rename:\n                renameCol = fl.index(args.rename);\n            if args.unicode:\n                usvCol = fl.index(args.unicode);\n        except ValueError as e:\n            logger.log('Missing csv input field: ' + e.message, 'S')\n        except Exception as e:\n            logger.log('Error reading csv input field: ' + e.message, 'S')\n        # optional columns\n        psCol  = fl.index('ps_name') if 'ps_name' in fl else None\n    if 'glyph_name' in fl:\n        next(incsv.reader, None)  # Skip first line with headers in\n\n    # list of glyphs to copy\n    glist = list()\n\n    def checkname(oldname, newname = None):\n        if not newname: newname = oldname\n        if oldname in Glyph.nameMap:\n            logger.log(\"Line {0}: Glyph '{1}' specified more than once; only the first kept\".format(incsv.line_num, oldname), 'W')\n        elif oldname not in sfont.deflayer:\n            logger.log(\"Line {0}: Glyph '{1}' is not in source font; skipping\".format(incsv.line_num, oldname),\"W\")\n        elif newname in tfont.deflayer and not args.force:\n            logger.log(\"Line {0}: Glyph '{1}' already present; skipping\".format(incsv.line_num, newname), \"W\")\n        else:\n            return True\n        return False\n\n    # glyphs specified in csv file\n    for r in incsv:\n        oldname = r[nameCol]\n        newname = r[renameCol] if args.rename else oldname\n        psname = r[psCol] if psCol is not None else None\n        if args.unicode and r[usvCol]:\n            # validate USV:\n            try:\n                dusv = int(r[usvCol],16)\n            except ValueError:\n                logger.log(\"Line {0}: Invalid USV '{1}'; ignored.\".format(incsv.line_num, r[usvCol]), \"W\")\n                dusv = None\n        else:\n            dusv = None\n\n        if checkname(oldname, newname):\n            glist.append(Glyph(oldname, newname, psname, dusv))\n\n    # glyphs specified on the command line\n    if args.name:\n        for gname in args.name:\n            if checkname(gname):\n                glist.append(Glyph(gname))\n\n    # Ok, now process them:\n    if len(glist) == 0:\n        logger.log(\"No glyphs to copy\", \"S\")\n\n    # copy glyphs by name\n    while len(glist) :\n        g = glist.pop(0)\n        tfont.logger.log(\"Copying source glyph '{0}' as '{1}'{2}\".format(g.oldname, g.newname,\n                         \" (U+{0:04X})\".format(g.dusv) if g.dusv else \"\"), \"I\")\n        copyglyph(sfont, tfont, g, args)\n\n    return tfont",
  "def cmd() : execute(\"UFO\",doit,argspec)",
  "def __init__(self, oldname, newname=\"\", psname=\"\", dusv=None):\n        self.oldname = oldname\n        self.newname = newname or oldname\n        self.psname = psname or None\n        self.dusv = dusv or None\n        # Keep track of old-to-new name mapping\n        Glyph.nameMap[oldname] = self.newname",
  "def checkname(oldname, newname = None):\n        if not newname: newname = oldname\n        if oldname in Glyph.nameMap:\n            logger.log(\"Line {0}: Glyph '{1}' specified more than once; only the first kept\".format(incsv.line_num, oldname), 'W')\n        elif oldname not in sfont.deflayer:\n            logger.log(\"Line {0}: Glyph '{1}' is not in source font; skipping\".format(incsv.line_num, oldname),\"W\")\n        elif newname in tfont.deflayer and not args.force:\n            logger.log(\"Line {0}: Glyph '{1}' already present; skipping\".format(incsv.line_num, newname), \"W\")\n        else:\n            return True\n        return False",
  "def doit(args) :\n\n    fields = [\"copyright\", \"openTypeNameDescription\", \"openTypeNameDesigner\", \"openTypeNameDesignerURL\", \"openTypeNameLicense\", # General feilds\n                \"openTypeNameLicenseURL\", \"openTypeNameManufacturer\", \"openTypeNameManufacturerURL\", \"openTypeOS2CodePageRanges\",\n                \"openTypeOS2UnicodeRanges\", \"openTypeOS2VendorID\", \"trademark\",\n                \"openTypeNameVersion\", \"versionMajor\", \"versionMinor\", # Version fields\n                \"ascender\", \"descender\", \"openTypeHheaAscender\", \"openTypeHheaDescender\", \"openTypeHheaLineGap\", # Design fields\n                \"openTypeOS2TypoAscender\", \"openTypeOS2TypoDescender\", \"openTypeOS2TypoLineGap\", \"openTypeOS2WinAscent\", \"openTypeOS2WinDescent\"]\n    libfields = [\"public.postscriptNames\", \"public.glyphOrder\", \"com.schriftgestaltung.glyphOrder\"]\n\n    fromfont = args.fromfont\n    tofont = args.tofont\n    logger = args.logger\n    reportonly = args.reportonly\n\n    updatemessage = \" to be updated: \" if reportonly else \" updated: \"\n    precision = fromfont.paramset[\"precision\"]\n    # Increase screen logging level to W unless specific level supplied on command-line\n    if not(args.quiet or \"scrlevel\" in args.paramsobj.sets[\"command line\"]) : logger.scrlevel = \"W\"\n\n    # Process fontinfo.plist\n    ffi = fromfont.fontinfo\n    tfi = tofont.fontinfo\n    fupdated = False\n    for field in fields:\n        if field in ffi :\n            felem = ffi[field][1]\n            ftag = felem.tag\n            ftext = felem.text\n            if ftag == 'real' : ftext = processnum(ftext,precision)\n            message = field + updatemessage\n\n            if field in tfi : # Need to compare values to see if update is needed\n                telem = tfi[field][1]\n                ttag = telem.tag\n                ttext = telem.text\n                if ttag == 'real' : ttext = processnum(ttext,precision)\n\n                if ftag in (\"real\", \"integer\", \"string\") :\n                    if ftext != ttext :\n                        if field == \"openTypeNameLicense\" : # Too long to display all\n                            addmess = \" Old: '\" + ttext[0:80] + \"...' New: '\" + ftext[0:80] + \"...'\"\n                        else: addmess = \" Old: '\" + ttext + \"' New: '\" + str(ftext) + \"'\"\n                        telem.text = ftext\n                        logger.log(message + addmess, \"W\")\n                        fupdated = True\n                elif ftag in (\"true, false\") :\n                    if ftag != ttag :\n                        fti.setelem(field, ET.fromstring(\"<\" + ftag + \"/>\"))\n                        logger.log(message + \" Old: '\" + ttag + \"' New: '\" + str(ftag) + \"'\", \"W\")\n                        fupdated = True\n                elif ftag == \"array\" : # Assume simple array with just values to compare\n                    farray = []\n                    for subelem in felem : farray.append(subelem.text)\n                    tarray = []\n                    for subelem in telem : tarray.append(subelem.text)\n                    if farray != tarray :\n                        tfi.setelem(field, ET.fromstring(ET.tostring(felem)))\n                        logger.log(message + \"Some values different Old: \" + str(tarray) + \" New: \" + str(farray), \"W\")\n                        fupdated = True\n                else : logger.log(\"Non-standard fontinfo field type: \"+ ftag + \" in \" + fontname, \"S\")\n            else :\n                tfi.addelem(field, ET.fromstring(ET.tostring(felem)))\n                logger.log(message + \"is missing from destination font so will be copied from source font\", \"W\")\n                fupdated = True\n        else: # Field not in from font\n            if field in tfi :\n                logger.log( field +  \" is missing from source font but present in destination font\", \"E\")\n            else :\n                logger.log( field +  \" is in neither font\", \"W\")\n\n    # Process lib.plist - currently just public.postscriptNames and glyph order fields which are all simple dicts or arrays\n    flib = fromfont.lib\n    tlib = tofont.lib\n    lupdated = False\n    for field in libfields:\n        action = None\n        if field in flib:\n            if field in tlib:  # Need to compare values to see if update is needed\n                if flib.getval(field) != tlib.getval(field):\n                    action = \"Updatefield\"\n            else:\n                action = \"Copyfield\"\n        else:\n            action = \"Error\" if field == (\"public.GlyphOrder\", \"public.postscriptNames\") else \"Warn\"\n            issue = field + \" not in source font lib.plist\"\n\n        # Process the actions, create log messages etc\n        if action is None or action == \"Ignore\":\n            pass\n        elif action == \"Warn\":\n            logger.log(field + \" needs manual correction: \" + issue, \"W\")\n        elif action == \"Error\":\n            logger.log(field + \" needs manual correction: \" + issue, \"E\")\n        elif action in (\"Updatefield\", \"Copyfield\"):  # Updating actions\n            lupdated = True\n            message = field + updatemessage\n            if action == \"Copyfield\":\n                message = message + \"is missing so will be copied from source font\"\n                tlib.addelem(field, ET.fromstring(ET.tostring(flib[field][1])))\n            elif action == \"Updatefield\":\n                message = message + \"Some values different\"\n                tlib.setelem(field, ET.fromstring(ET.tostring(flib[field][1])))\n            logger.log(message, \"W\")\n        else:\n            logger.log(\"Uncoded action: \" + action + \" - oops\", \"X\")\n\n    # Now update on disk\n    if not reportonly:\n        if fupdated:\n            logger.log(\"Writing updated fontinfo.plist\", \"P\")\n            UFO.writeXMLobject(tfi, tofont.outparams, tofont.ufodir, \"fontinfo.plist\", True, fobject=True)\n        if lupdated:\n            logger.log(\"Writing updated lib.plist\", \"P\")\n            UFO.writeXMLobject(tlib, tofont.outparams, tofont.ufodir, \"lib.plist\", True, fobject=True)\n\n    return",
  "def processnum(text, precision) : # Apply same processing to real numbers that normalization will\n    if precision is not None:\n        val = round(float(text), precision)\n        if val == int(val) : val = int(val) # Removed trailing decimal .0\n        text = str(val)\n    return text",
  "def cmd(): execute(\"UFO\",doit, argspec)",
  "def doit(args):\n    font = args.ifont\n    incsv = args.input\n    logger = args.logger\n    indent = ' '*args.indent\n\n    if not (args.quiet or 'scrlevel' in args.paramsobj.sets['command line']):\n        logger.raisescrlevel('W')  # Raise level to W if not already W or higher\n\n    def csvWarning(msg, exception=None):\n        m = f'glyph_data line {incsv.line_num}: {msg}'\n        if exception is not None:\n            m += '; ' + exception.message\n        logger.log(m, 'W')\n\n    # Get glyph names and encoding from input file\n    glyphFromCSVuid = {}\n    uidsFromCSVglyph = {}\n\n    # Identify file format (plain text or csv) from first line\n    # If csv file, it must have headers for \"glyph_name\" and \"USV\"\n    fl = incsv.firstline\n    if fl is None: logger.log('Empty input file', 'S')\n    numfields = len(fl)\n    incsv.numfields = numfields\n    usvCol = None  # Use this as a flag later to determine whether to check USV inventory\n    if numfields > 1:  # More than 1 column, so must have headers\n        # Required columns:\n        try:\n            nameCol = fl.index('glyph_name');\n        except ValueError as e:\n            logger.log('Missing csv input field: ' + e.message, 'S')\n        except Exception as e:\n            logger.log('Error reading csv input field: ' + e.message, 'S')\n        # Optional columns:\n        usvCol = fl.index('USV') if 'USV' in fl else None\n\n        next(incsv.reader, None)  # Skip first line with headers in\n\n        glyphList = set()\n        for line in incsv:\n            gname = line[nameCol]\n            if len(gname) == 0 or line[0].strip().startswith('#'):\n                continue    # No need to include cases where name is blank or comment\n            if gname in glyphList:\n                csvWarning(f'glyph name {gname} previously seen; ignored')\n                continue\n            glyphList.add(gname)\n\n            if usvCol:\n                # Process USV field, which can be:\n                #   empty string -- unencoded glyph\n                #   single USV -- encoded glyph\n                #   USVs connected by '_' -- ligature (in glyph_data for test generation, not glyph encoding)\n                #   space-separated list of the above, where presence of multiple USVs indicates multiply-encoded glyph\n                for usv in line[usvCol].split():\n                    if '_' in usv:\n                        # ignore ligatures -- these are for test generation, not encoding\n                        continue\n                    try:\n                        uid = int(usv, 16)\n                    except Exception as e:\n                        csvWarning(\"invalid USV '%s' (%s); ignored: \" % (usv, e.message))\n\n                    if uid in glyphFromCSVuid:\n                        csvWarning('USV %04X previously seen; ignored' % uid)\n                    else:\n                        # Remember this glyph encoding\n                        glyphFromCSVuid[uid] = gname\n                        uidsFromCSVglyph.setdefault(gname, set()).add(uid)\n    elif numfields == 1:   # Simple text file.\n        glyphList = set(line[0] for line in incsv)\n    else:\n        logger.log('Invalid csv file', 'S')\n\n    # Get the list of glyphs in the UFO\n    ufoList = set(font.deflayer.keys())\n\n    notInUFO = glyphList - ufoList\n    notInGlyphData = ufoList - glyphList\n\n    if len(notInUFO):\n        logger.log('Glyphs present in glyph_data but missing from UFO:\\n' + '\\n'.join(indent + g for g in sorted(notInUFO)), 'W')\n\n    if len(notInGlyphData):\n        logger.log('Glyphs present in UFO but missing from glyph_data:\\n' + '\\n'.join(indent + g for g in sorted(notInGlyphData)), 'W')\n\n    if len(notInUFO) == 0 and len(notInGlyphData) == 0:\n        logger.log('No glyph inventory differences found', 'P')\n\n    if usvCol:\n        # We can check encoding of glyphs in common\n        inBoth = glyphList & ufoList   # Glyphs we want to examine\n\n        csvEncodings = set(f'{gname}|{uid:04X}' for gname in filter(lambda x: x in uidsFromCSVglyph, inBoth) for uid in uidsFromCSVglyph[gname] )\n        ufoEncodings = set(f'{gname}|{int(u.hex, 16):04X}' for gname in inBoth for u in font.deflayer[gname]['unicode'])\n\n        notInUFO = csvEncodings - ufoEncodings\n        notInGlyphData = ufoEncodings - csvEncodings\n\n        if len(notInUFO):\n            logger.log('Encodings present in glyph_data but missing from UFO:\\n' + '\\n'.join(indent + g for g in sorted(notInUFO)), 'W')\n\n        if len(notInGlyphData):\n            logger.log('Encodings present in UFO but missing from glyph_data:\\n' + '\\n'.join(indent + g for g in sorted(notInGlyphData)), 'W')\n\n        if len(notInUFO) == 0 and len(notInGlyphData) == 0:\n            logger.log('No glyph encoding differences found', 'P')\n\n    else:\n        logger.log('Glyph encodings not compared', 'P')",
  "def cmd(): execute('UFO', doit, argspec)",
  "def csvWarning(msg, exception=None):\n        m = f'glyph_data line {incsv.line_num}: {msg}'\n        if exception is not None:\n            m += '; ' + exception.message\n        logger.log(m, 'W')",
  "def doit(args) :\n    font = args.ifont\n    outfile = args.output\n    logger = args.logger\n    color = args.color\n\n    # Add initial comments to outfile\n    if not args.nocomments :\n        outfile.write(\"# \" + datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S \") + args.cmdlineargs[0] + \"\\n\")\n        outfile.write(\"# \"+\" \".join(args.cmdlineargs[1:])+\"\\n\\n\")\n\n    if color :\n        (colorfilter, colorname, logcolor, splitcolor) = parsecolors(color, single=True)\n        if colorfilter is None : logger.log(logcolor, \"S\") # If color not parsed, parsecolors() puts error in logcolor\n\n    glyphlist = font.deflayer.keys()\n\n    for glyphn in sorted(glyphlist) :\n        glyph = font.deflayer[glyphn]\n        colordefraw = \"\"\n        colordef = \"\"\n        if glyph[\"lib\"] :\n            lib = glyph[\"lib\"]\n            if \"public.markColor\" in lib :\n                colordefraw = lib[\"public.markColor\"][1].text\n                colordef = '\"' + colordefraw + '\"'\n                if args.names : colordef = colortoname(colordefraw, colordef)\n            if color :\n                if colorfilter == colordefraw : outfile.write(glyphn + \"\\n\")\n        if not color : outfile.write(glyphn + \",\" + colordef + \"\\n\")\n    return",
  "def cmd() : execute(\"UFO\",doit,argspec)",
  "def doit(args) :\n    logger = args.logger\n\n    ds = DSD.DesignSpaceDocument()\n    ds.read(args.designspace)\n    if len(ds.sources) == 1: logger.log(\"The design space file has only one source UFO\", \"S\")\n\n    # Find all the UFOs from the DS Sources.  Where there are more than 2, the primary one will be considered to be\n    # the one where info copy=\"1\" is set (as per psfsyncmasters).  If not set for any, use the first ufo.\n    pufo = None\n    otherfonts = {}\n    for source in ds.sources:\n        ufo = source.path\n        try:\n            font = OpenFont(ufo)\n        except Exception as e:\n            logger.log(\"Unable to open \" + ufo, \"S\")\n        if source.copyInfo:\n            if pufo: logger.log('Multiple fonts with <info copy=\"1\" />', \"S\")\n            pufo = ufo\n            pfont = font\n        else:\n            otherfonts[ufo] = font\n    if pufo is None: # If we can't identify the primary font by conyInfo, just use the first one\n        pufo = ds.sources[0].path\n        pfont = otherfonts[pufo]\n        del otherfonts[pufo]\n\n    pinventory = set(glyph.name for glyph in pfont)\n    \n    for oufo in otherfonts:      \n        logger.log(f'Comparing {pufo} with {oufo}', 'P')\n        ofont = otherfonts[oufo]\n        oinventory = set(glyph.name for glyph in ofont)\n    \n        if pinventory != oinventory:\n            logger.log(\"The glyph inventories in the two UFOs differ\", \"E\")\n            for glyphn in sorted(pinventory - oinventory):\n                logger.log(f'{glyphn} is only in {pufo}', \"W\")\n            for glyphn in sorted(oinventory - pinventory):\n                logger.log(f'{glyphn} is only in {oufo}', \"W\")\n        else:\n            logger.log(\"The UFOs have the same glyph inventories\", \"P\")\n        # Are glyphs compatible for interpolation\n        incompatibles = {}\n        for glyphn in pinventory & oinventory:\n            compatible, report = pfont[glyphn].isCompatible(ofont[glyphn])\n            if not compatible: incompatibles[glyphn] = report\n        if incompatibles:\n            logger.log(f'{len(incompatibles)} glyphs are not interpolatable', 'E')\n            for glyphn in sorted(incompatibles):\n                logger.log(f'{glyphn} is not interpolatable', 'W')\n                logger.log(incompatibles[glyphn], \"I\")\n            if logger.scrlevel == \"W\": logger.log(\"To see detailed reports run with scrlevel and/or loglevel set to I\")\n        else:\n            logger.log(\"All the glyphs are interpolatable\", \"P\")",
  "def cmd() : execute(None,doit, argspec)",
  "def doit(args):\n    logger = args.logger\n    infont = args.infont\n    font = TTFont(args.infont)\n    defaultpath = os.path.splitext(infont)[0]\n    inFlavor = font.flavor or 'ttf'\n    logger.log(f'input font {infont} is a {inFlavor}', 'I')\n\n    # Read & parse version, if provided\n    flavorData = WOFFFlavorData()  # Initializes all fields to None\n\n    if args.version:\n        try:\n            version = float(args.version)\n            if version < 0:\n                raise ValueError('version cannot be negative')\n            flavorData.majorVersion, flavorData.minorVersion = map(int, format(version, '.3f').split('.'))\n        except:\n            logger.log(f'invalid version syntax \"{args.version}\": should be MM.mmm', 'S')\n    else:\n        try:\n            flavorData.majorVersion = font.flavorData.majorVersion\n            flavorData.minorVersion = font.flavorData.minorVersion\n        except:\n            # Pull version from head table\n            head = font['head']\n            flavorData.majorVersion, flavorData.minorVersion =map(int, format(head.fontRevision, '.3f').split('.'))\n\n    # Read metadata if provided, else get value from input font\n    if args.metadata:\n        try:\n            with open(args.metadata, 'rb') as f:\n                flavorData.metaData = f.read()\n        except:\n            logger.log(f'Unable to read file \"{args.metadata}\"', 'S')\n    elif inFlavor != 'ttf':\n        flavorData.metaData = font.flavorData.metaData\n\n    # Same process for private data\n    if args.privatedata:\n        try:\n            with open(args.privatedata, 'rb') as f:\n                flavorData.privData = f.read()\n        except:\n            logger.log(f'Unable to read file \"{args.privatedata}\"', 'S')\n    elif inFlavor != 'ttf':\n        flavorData.privData = font.flavorData.privData\n\n    if args.woff:\n        font.flavor = 'woff'\n        font.flavorData = flavorData\n        fname =  f'{defaultpath}.{font.flavor}' if args.woff2 == '-' else args.woff\n        logger.log(f'Writing {font.flavor} font to \"{fname}\"', 'P')\n        font.save(fname)\n\n    if args.woff2:\n        font.flavor = 'woff2'\n        font.flavorData = WOFF2FlavorData(data=flavorData)\n        fname =  f'{defaultpath}.{font.flavor}' if args.woff2 == '-' else args.woff2\n        logger.log(f'Writing {font.flavor} font to \"{fname}\"', 'P')\n        font.save(fname)\n\n    if args.ttf:\n        font.flavor = None\n        font.flavorData = None\n        fname =  f'{defaultpath}.ttf' if args.ttf == '-' else args.ttf\n        logger.log(f'Writing ttf font to \"{fname}\"', 'P')\n        font.save(fname)\n\n    font.close()",
  "def cmd() : execute('FT',doit, argspec)",
  "def doit(args) :\n    font = args.ifont\n    logger = args.logger\n    keys = args.key\n    bkeys=args.begins if args.begins is not None else []\n    keycounts = {}\n    bkeycounts = {}\n    for key in keys : keycounts[key] = 0\n    for key in bkeys:\n        if key in keycounts: logger.log(\"--begins key can't be the same as a standard key\", \"S\")\n        bkeycounts[key] = 0\n\n    for glyphn in font.deflayer :\n        glyph = font.deflayer[glyphn]\n        if glyph[\"lib\"] :\n            for key in keys :\n                if key in glyph[\"lib\"] :\n                    val = str( glyph[\"lib\"].getval(key))\n                    glyph[\"lib\"].remove(key)\n                    keycounts[key] += 1\n                    logger.log(key + \" removed from \" + glyphn + \". Value was \" + val, \"I\" )\n                    if key == \"com.schriftgestaltung.Glyphs.originalWidth\": # Special fix re glyphLib bug\n                        if glyph[\"advance\"] is None: glyph.add(\"advance\")\n                        adv = (glyph[\"advance\"])\n                        if adv.width is None:\n                            adv.width = int(float(val))\n                            logger.log(\"Advance width for \" + glyphn + \" set to \" + val, \"I\")\n                        else:\n                            logger.log(\"Advance width for \" + glyphn + \" is already set to \" + str(adv.width) + \" so originalWidth not copied\", \"E\")\n            for key in bkeys:\n                gkeys = list(glyph[\"lib\"])\n                for gkey in gkeys:\n                    if gkey[:len(key)] == key:\n                        val = str(glyph[\"lib\"].getval(gkey))\n                        glyph[\"lib\"].remove(gkey)\n                        if gkey in keycounts:\n                            keycounts[gkey] += 1\n                        else:\n                            keycounts[gkey] = 1\n                        bkeycounts[key] += 1\n                        logger.log(gkey + \" removed from \" + glyphn + \". Value was \" + val, \"I\")\n\n    for key in keycounts :\n        count = keycounts[key]\n        if count > 0 :\n            logger.log(key + \" removed from \" + str(count) +  \" glyphs\", \"P\")\n        else :\n            logger.log(\"No lib entries found for \" + key, \"E\")\n    for key in bkeycounts:\n        if bkeycounts[key] == 0: logger.log(\"No lib entries found for beginning with \" + key, \"E\")\n\n    return font",
  "def cmd() : execute(\"UFO\",doit,argspec)",
  "def doit(args) :\n\n    fontname = args.ifont\n    logger = args.logger\n    params = args.paramsobj\n\n    # Locate the oldest backup\n    (path, base, ext) = splitfn(fontname)\n    backuppath = os.path.join(path, base + \".*-*\" + ext) # Backup has date/time added in format .yymmdd-hhmm\n    backups = glob.glob(backuppath)\n    if len(backups) == 0:\n        logger.log(\"No backups found matching %s so no changes made to the font\" % backuppath, \"P\")\n        return\n    backupname = sorted(backups)[0] # Choose the oldest backup - date/time format sorts alphabetically\n\n    # Reset groups.plist, kerning.plist and any layerinfo.plist(s) from backup ufo\n    for filename in [\"groups.plist\", \"kerning.plist\"]:\n        bufullname = os.path.join(backupname, filename)\n        ufofullname = os.path.join(fontname, filename)\n        if os.path.exists(bufullname):\n            try:\n                shutil.copy(bufullname, fontname)\n                logger.log(filename + \" restored from backup\", \"P\")\n            except Exception as e:\n                logger.log(\"Failed to copy %s to %s: %s\" % (bufullname, fontname, str(e)), \"S\")\n        elif os.path.exists(ufofullname):\n            os.remove(ufofullname)\n            logger.log(filename + \" removed from ufo\", \"P\")\n    lifolders = []\n    for ufoname in (fontname, backupname): # Find any layerinfo files in either ufo\n        lis = glob.glob(os.path.join(ufoname, \"*/layerinfo.plist\"))\n        for li in lis:\n            (lifolder, dummy) = os.path.split(li)       # Get full path name for folder\n            (dummy, lifolder) = os.path.split(lifolder) # Now take ufo name off the front\n            if lifolder not in lifolders: lifolders.append(lifolder)\n    for folder in lifolders:\n        filename = os.path.join(folder, \"layerinfo.plist\")\n        bufullname = os.path.join(backupname, filename)\n        ufofullname = os.path.join(fontname, filename)\n        if os.path.exists(bufullname):\n            try:\n                shutil.copy(bufullname, os.path.join(fontname, folder))\n                logger.log(filename + \" restored from backup\", \"P\")\n            except Exception as e:\n                logger.log(\"Failed to copy %s to %s: %s\" % (bufullname, fontname, str(e)), \"S\")\n        elif os.path.exists(ufofullname):\n            os.remove(ufofullname)\n            logger.log(filename + \" removed from ufo\", \"P\")\n\n    # Now open the fonts\n    font = Ufont(fontname, params = params)\n    backupfont = Ufont(backupname, params = params)\n\n    fidel = (\"openTypeGaspRangeRecords\", \"openTypeHheaCaretOffset\",\n             \"postscriptBlueFuzz\", \"postscriptBlueScale\", \"postscriptBlueShift\", \"postscriptForceBold\",\n             \"postscriptIsFixedPitch\", \"postscriptWeightName\")\n    libdel = (\"com.fontlab.v2.tth\", \"com.typemytype.robofont.italicSlantOffset\")\n    fontinfo = font.fontinfo\n    libplist = font.lib\n    backupfi = backupfont.fontinfo\n    backuplib = backupfont.lib\n\n    # Delete keys that are not needed\n    for key in fidel:\n        if key in fontinfo:\n            old = fontinfo.getval(key)\n            fontinfo.remove(key)\n            logchange(logger, \" removed from fontinfo.plist. \", key, old, None)\n    for key in libdel:\n        if key in libplist:\n            old = libplist.getval(key)\n            libplist.remove(key)\n            logchange(logger, \" removed from lib.plist. \", key, old, None)\n\n    # Correct other metadata:\n    if \"guidelines\" in backupfi:\n        fontinfo.setelem(\"guidelines\",backupfi[\"guidelines\"][1])\n        logger.log(\"fontinfo guidelines copied from backup ufo\", \"I\")\n    elif \"guidelines\" in fontinfo:\n        fontinfo.remove(\"guidelines\")\n        logger.log(\"fontinfo guidelines deleted - not in backup ufo\", \"I\")\n    if \"italicAngle\" in fontinfo and fontinfo.getval(\"italicAngle\") == 0:\n        fontinfo.remove(\"italicAngle\")\n        logger.log(\"fontinfo italicAngle removed since it was 0\", \"I\")\n    if \"openTypeOS2VendorID\" in fontinfo:\n        old = fontinfo.getval(\"openTypeOS2VendorID\")\n        if len(old) < 4:\n            new = \"%-4s\" % (old,)\n            fontinfo.setval(\"openTypeOS2VendorID\", \"string\", new)\n            logchange(logger, \" padded to 4 characters \", \"openTypeOS2VendorID\", \"'%s'\" % (old,) , \"'%s'\" % (new,))\n    if \"woffMetadataCredits\" in backupfi:\n        fontinfo.setelem(\"woffMetadataCredits\",backupfi[\"woffMetadataCredits\"][1])\n        logger.log(\"fontinfo woffMetadataCredits copied from backup ufo\", \"I\")\n    elif \"woffMetadataCredits\" in fontinfo:\n        fontinfo.remove(\"woffMetadataCredits\")\n        logger.log(\"fontinfo woffMetadataCredits deleted - not in backup ufo\", \"I\")\n    if \"woffMetadataDescription\" in backupfi:\n        fontinfo.setelem(\"woffMetadataDescription\",backupfi[\"woffMetadataDescription\"][1])\n        logger.log(\"fontinfo woffMetadataDescription copied from backup ufo\", \"I\")\n    elif \"woffMetadataDescription\" in fontinfo:\n        fontinfo.remove(\"woffMetadataDescription\")\n        logger.log(\"fontinfo woffMetadataDescription deleted - not in backup ufo\", \"I\")\n    if \"public.glyphOrder\" in backuplib:\n        libplist.setelem(\"public.glyphOrder\",backuplib[\"public.glyphOrder\"][1])\n        logger.log(\"lib.plist public.glyphOrder copied from backup ufo\", \"I\")\n    elif \"public.glyphOrder\" in libplist:\n        libplist.remove(\"public.glyphOrder\")\n        logger.log(\"libplist public.glyphOrder deleted - not in backup ufo\", \"I\")\n\n\n\n    # Now process glif level data\n    updates = False\n    for gname in font.deflayer:\n        glyph = font.deflayer[gname]\n        glines = glyph[\"guideline\"]\n        if glines:\n            for gl in list(glines): glines.remove(gl) # Remove any existing glines\n            updates = True\n        buglines = backupfont.deflayer[gname][\"guideline\"] if gname in backupfont.deflayer else []\n        if buglines:\n            for gl in buglines: glines.append(gl) # Add in those from backup\n            updates = True\n    if updates:\n        logger.log(\"Some updates to glif guidelines may have been made\", \"I\")\n        updates = False\n    for layer in font.layers:\n        if layer.layername == \"public.background\":\n            for gname in layer:\n                glyph = layer[gname]\n                if glyph[\"advance\"] is not None:\n                    glyph.remove(\"advance\")\n                    updates = True\n    if updates: logger.log(\"Some advance elements removed from public.background glifs\", \"I\")\n    font.write(fontname)\n    return",
  "def logchange(logger, logmess, key, old, new):\n    oldstr = str(old) if len(str(old)) < 22 else str(old)[0:20] + \"...\"\n    newstr = str(new) if len(str(new)) < 22 else str(new)[0:20] + \"...\"\n    logmess = key + logmess\n    if old is None:\n        logmess = logmess + \" New value: \" + newstr\n    else:\n        if new is None:\n            logmess = logmess + \" Old value: \" + oldstr\n        else:\n            logmess = logmess + \" Old value: \" + oldstr + \", new value: \" + newstr\n    logger.log(logmess, \"I\")",
  "def cmd() : execute(None,doit, argspec)",
  "class feat(object):\n    'TypeTuner feature'\n    def __init__(self, elem, sortkey):\n        self.name = elem.attrib.get('name')\n        self.tag = elem.attrib.get('tag')\n        self.default = elem.attrib.get('value')\n        self.values = OrderedDict()\n        self.sortkey = sortkey\n        for v in elem.findall('value'):\n            # Only add those values which aren't importing line metrics\n            if v.find(\"./cmd[@name='line_metrics_scaled']\") is None:\n                self.values[v.attrib.get('name')] = v.attrib.get('tag')",
  "class feat_map(object):\n    'mapping from OpenType feature tag to TypeTuner feature name, default value, and all values'\n    def __init__(self, r):\n        self.ottag, self.ttfeature, self.default = r[0:3]\n        self.ttvalues = r[3:]",
  "class lang_map(object):\n    'mapping from OpenType language tag to TypeTuner language feature name and value'\n    def __init__(self,r):\n        self.ottag, self.ttfeature, self.ttvalue = r",
  "class font(object):\n    'Cache of tuned font information'\n\n    def __init__(self, font_tag, feats, lang, fontface):\n        self.font_tag = font_tag\n        self.feats = feats\n        self.lang = lang\n        self.fontface = fontface",
  "def cache_font(feats, lang, norebuild):\n    'Create (and cache) a TypeTuned font and @fontface for this combination of features and lang'\n\n    # feats is either None or a css font-feature-settings string using single quotes (according to ftml spec), e.g. \"'cv02' 1, 'cv60' 1\"\n    # lang is either None or bcp47 langtag\n    # norebuild is a debugging aid that causes the code to skip building a .ttf if it is already present thus making the\n    #     program run faster but with the risk that the built TTFs don't match the current build.\n\n    # First step is to construct a name for this set of languages and features, something we'll call the \"font tag\"\n\n    parts = []\n    ttsettings = dict() # place to save TT setting name and value in case we need to build the font\n    fatal_errors = False\n\n    if feats:\n        # Need to split the font-feature-settings around commas and parse each part, mapping css tag and value to\n        # typetuner tag and value\n        for setting in features_splitRE.split(feats):\n            m = feature_settingRE.match(setting)\n            if m is None:\n                logger.log('Invalid CSS feature setting in ftml: {}'.format(setting), 'E')\n                fatal_errors = True\n                continue\n            f,v = m.groups()  # Feature tag and value\n            if v in ['normal','off']:\n                v = '0'\n            elif v == 'on':\n                v = '1'\n            try:\n                v = int(v)\n                assert v >= 0\n            except:\n                logger.log('Invalid feature value {} found in map file'.format(setting), 'E')\n                fatal_errors = True\n                continue\n            if not v:\n                continue    # No need to include 0/off values\n\n            # we need this one... so translate to TypeTuner feature & value using the map file\n            try:\n                fmap = feat_maps[f]\n            except KeyError:\n                logger.log('Font feature \"{}\" not found in map file'.format(f), 'E')\n                fatal_errors = True\n                continue\n\n            f = fmap.ttfeature\n\n            try:\n                v = fmap.ttvalues[v - 1]\n            except IndexError:\n                logger.log('TypeTuner feature \"{}\" doesn\\'t have a value index {}'.format(f, v), 'E')\n                fatal_errors = True\n                continue\n\n            # Now translate to TypeTuner tags using feat_all info\n            if f not in feat_all:\n                logger.log('Tunable font doesn\\'t contain a feature \"{}\"'.format(f), 'E')\n                fatal_errors = True\n            elif v not in feat_all[f].values:\n                logger.log('Tunable font feature \"{}\" doesn\\'t have a value {}'.format(f, v), 'E')\n                fatal_errors = True\n            else:\n                ttsettings[f] = v   # Save TT setting name and value name in case we need to build the font\n                ttfeat = feat_all[f]\n                f = ttfeat.tag\n                v = ttfeat.values[v]\n                # Finally!\n                parts.append(f+v)\n    if lang:\n            if lang not in lang_maps:\n                logger.log('Language tag \"{}\" not found in map file'.format(lang), 'E')\n                fatal_errors = True\n            else:\n                # Translate to TypeTuner feature & value using the map file\n                lmap = lang_maps[lang]\n                f = lmap.ttfeature\n                v = lmap.ttvalue\n                # Translate to TypeTuner tags using feat_all info\n                if f not in feat_all:\n                    logger.log('Tunable font doesn\\'t contain a feature \"{}\"'.format(f), 'E')\n                    fatal_errors = True\n                elif v not in feat_all[f].values:\n                    logger.log('Tunable font feature \"{}\" doesn\\'t have a value {}'.format(f, v), 'E')\n                    fatal_errors = True\n                else:\n                    ttsettings[f] = v  # Save TT setting name and value in case we need to build the font\n                    ttfeat = feat_all[f]\n                    f = ttfeat.tag\n                    v = ttfeat.values[v]\n                    # Finally!\n                    parts.append(f+v)\n    if fatal_errors:\n        return None\n\n    if len(parts) == 0:\n        logger.log('No features or languages found'.format(f), 'E')\n        return None\n\n    # the Font Tag is how we name everything (the ttf, the xml, etc)\n    font_tag = '_'.join(sorted(parts))\n\n    # See if we've had this combination before:\n    if font_tag in font_tag2font:\n        logger.log('Found cached font {}'.format(font_tag), 'I')\n        return font_tag\n\n    # Path to font, which may already exist, and @fontface\n    ttfname = os.path.join(fontdir, font_tag + '.ttf')\n    fontface = '@font-face { font-family: {}; src: url(fonts/{}.ttf); } .{} {font-family: {}; }'.replace('{}',font_tag)\n\n    # Create new font object and remember how to find it:\n    thisfont = font(font_tag, feats, lang, fontface)\n    font_tag2font[font_tag] = thisfont\n    if lang and not feats:\n        lang2font[lang] = thisfont\n\n    # Debugging shortcut: use the existing fonts without rebuilding\n    if norebuild and os.path.isfile(ttfname):\n        logger.log('Blindly using existing font {}'.format(font_tag), 'I')\n        return font_tag\n\n    # Ok, need to build the font\n    logger.log('Building font {}'.format(font_tag), 'I')\n\n    # Create and save the TypeTuner feature settings file\n    sfname = os.path.join(fontdir, font_tag + '.xml')\n    root = ET.XML('''\\\n<?xml version = \"1.0\"?>\n<!DOCTYPE features_set SYSTEM \"feat_set.dtd\">\n<features_set version = \"1.0\"/>\n''')\n    # Note: Order of elements in settings file should be same as order in feat_all\n    # (because this is the way TypeTuner does it and some fonts may expect this)\n    for name, ttfeat in sorted(feat_all.items(), key=lambda x: x[1].sortkey):\n        if name in ttsettings:\n            # Output the non-default value for this one:\n            ET.SubElement(root, 'feature',{'name': name, 'value': ttsettings[name]})\n        else:\n            ET.SubElement(root, 'feature', {'name': name, 'value': ttfeat.default})\n    xml = ET.tostring(root,pretty_print = True, encoding='UTF-8', xml_declaration=True)\n    with open(sfname, '+wb')as f:\n        f.write(xml)\n\n    # Now invoke TypeTuner to create the tuned font\n    try:\n        cmd = ['typetuner', '-o', ttfname, '-n', font_tag, sfname, sourcettf]\n        res = check_output(cmd)\n        if len(res):\n            print('\\n', res)\n    except CalledProcessError as err:\n        logger.log(\"couldn't tune font: {}\".format(err.output), 'S')\n\n    return font_tag",
  "def doit(args) :\n\n    global logger, sourcettf, outputdir, fontdir\n\n    logger = args.logger\n    sourcettf = args.ttfont\n\n    # Create output directory, including fonts subdirectory, if not present\n    outputdir = args.outputdir\n    os.makedirs(outputdir, exist_ok = True)\n    fontdir = os.path.join(outputdir, 'fonts')\n    os.makedirs(fontdir, exist_ok = True)\n\n    # Read and save feature mapping\n    for r in args.map:\n        # remove empty cells from the end\n        while len(r) and len(r[-1]) == 0:\n            r.pop()\n        if len(r) == 0 or r[0].startswith('#'):\n            continue\n        elif r[0].startswith('lang='):\n            if len(r[0]) < 7 or len(r) != 3:\n                logger.log(\"Invalid lang mapping: '\" + ','.join(r) + \"' ignored\", \"W\")\n            else:\n                r[0] = r[0][5:]\n                lang_maps[r[0]] = lang_map(r)\n        else:\n            if len(r) < 4:\n                logger.log(\"Invalid feature mapping: '\" + ','.join(r) + \"' ignored\", \"W\")\n            else:\n                feat_maps[r[0]] = feat_map(r)\n\n    # Open and verify input file is a tunable font; extract and parse feat_all from font.\n    font = ttLib.TTFont(sourcettf)\n    raw_data = font.getTableData('Silt')\n    feat_xml = gzip.decompress(raw_data) # .decode('utf-8')\n    root = ET.fromstring(feat_xml)\n    if root.tag != 'all_features':\n        logger.log(\"Invalid TypeTuner feature file: missing root element\", \"S\")\n    for i, f in enumerate(root.findall('.//feature')):\n        # add to dictionary\n        ttfeat = feat(f,i)\n        feat_all[ttfeat.name] = ttfeat\n\n    # Open and prepare the xslt file to transform the ftml:\n    xslt = ET.parse(args.xsl)\n    xslt_transform = ET.XSLT(xslt)\n\n\n    # Process all ftml files:\n\n    for arg in args.ftml:\n        for infname in glob(arg):\n            # based on input filename, construct output name\n            # find filename and change extension to html:\n            outfname = os.path.join(outputdir, os.path.splitext(os.path.basename(infname))[0] + '.html')\n            logger.log('Processing: {} -> {}'.format(infname, outfname), 'P')\n\n            # Each named style in the FTML ultimately maps to a TypeTuned font that will be added via @fontface.\n            # We need to remember the names of the styles and their associated fonts so we can hack the html.\n            sname2font = dict() # Indexed by ftml stylename; result is a font object\n\n            # Parse the FTML\n            ftml_doc = ET.parse(infname)\n\n            # Adjust <title> to show this is from TypeTuner\n            head = ftml_doc.find('head')\n            title = head.find('title')\n            title.text += \" - TypeTuner\"\n            # Replace all <fontsrc> elements with two identical from the input font:\n            #   One will remain unchanged, the other will eventually be changed to a typetuned font.\n            ET.strip_elements(head, 'fontsrc')\n            fpathname = os.path.relpath(sourcettf, outputdir).replace('\\\\','/')  # for css make sure all slashes are forward!\n            head.append(ET.fromstring('<fontsrc>url({})</fontsrc>'.format(fpathname)))    # First font\n            head.append(ET.fromstring('<fontsrc>url({})</fontsrc>'.format(fpathname)))    # Second font, same as the first\n\n            # iterate over all the styles in this ftml file, building tuned fonts to match if not already done.\n            for style in head.iter('style'):\n                sname = style.get('name')    # e.g. \"some_style\"\n                feats = style.get('feats')  # e.g \"'cv02' 1, 'cv60' 1\"  -- this we'll parse to get need tt features\n                lang = style.get('lang')    # e.g., \"sd\"\n                font_tag = cache_font(feats, lang, args.norebuild)\n                # font_tag could be None due to errors, but messages should already have been logged\n                # If it is valid, remember how to find this font from the ftml stylename\n                if font_tag:\n                    sname2font[sname] = font_tag2font[font_tag]\n\n            # convert to html via supplied xslt\n            html_doc = xslt_transform(ftml_doc)\n\n            # Two modifications to make in the html:\n            # 1) add all @fontface specs to the <style> element\n            # 2) Fix up all occurrences of <td> elements referencing font2\n\n            # Add @fontface to <style>\n            style = html_doc.find('//style')\n            style.text = style.text + '\\n' + '\\n'.join([x.fontface for x in sname2font.values()])\n\n            # Iterate over all <td> elements looking for font2 and a style or lang indicating feature settings\n\n            classRE = re.compile(r'string\\s+(?:(\\w+)\\s+)?font2$')\n\n            for td in html_doc.findall('//td'):\n                tdclass = td.get('class')\n                tdlang = td.get('lang')\n                m = classRE.match(tdclass)\n                if m:\n                    sname = m.group(1)\n                    if sname:\n                        # stylename will get us directly to the font\n                        try:\n                            td.set('class', 'string {}'.format(sname2font[sname].font_tag))\n                            if tdlang:  # If there is also a lang attribute, we no longer need it.\n                                del td.attrib['lang']\n                        except KeyError:\n                            logger.log(\"Style name {} not available.\".format(sname), \"W\")\n                    elif tdlang:\n                        # Otherwise we'll assume there is only the lang attribute\n                        try:\n                            td.set('class', 'string {}'.format(lang2font[tdlang].font_tag))\n                            del td.attrib['lang'] # lang attribute no longer needed.\n                        except KeyError:\n                            logger.log(\"Style for langtag {} not available.\".format(tdlang), \"W\")\n\n\n            # Ok -- write the html out!\n            html = ET.tostring(html_doc, pretty_print=True, method='html', encoding='UTF-8')\n            with open(outfname, '+wb')as f:\n                f.write(html)",
  "def cmd() : execute(None,doit,argspec)",
  "def __init__(self, elem, sortkey):\n        self.name = elem.attrib.get('name')\n        self.tag = elem.attrib.get('tag')\n        self.default = elem.attrib.get('value')\n        self.values = OrderedDict()\n        self.sortkey = sortkey\n        for v in elem.findall('value'):\n            # Only add those values which aren't importing line metrics\n            if v.find(\"./cmd[@name='line_metrics_scaled']\") is None:\n                self.values[v.attrib.get('name')] = v.attrib.get('tag')",
  "def __init__(self, r):\n        self.ottag, self.ttfeature, self.default = r[0:3]\n        self.ttvalues = r[3:]",
  "def __init__(self,r):\n        self.ottag, self.ttfeature, self.ttvalue = r",
  "def __init__(self, font_tag, feats, lang, fontface):\n        self.font_tag = font_tag\n        self.feats = feats\n        self.lang = lang\n        self.fontface = fontface",
  "def doit(args):\n    logger = args.logger\n    fnames = glob.glob(args.inftml)\n    if len(fnames) == 0:\n        logger.log(f'No files matching \"{args.inftml}\" found.','E')\n    for fname in glob.glob(args.inftml):\n        logger.log(f'checking {fname}', 'P')\n        unknownStyles = set()\n        usedStyles = set()\n\n        # recursively find and check all <test> elements in a <testsgroup>\n        def checktestgroup(testgroup):\n            for test in testgroup.tests:\n                # Not sure why, but sub-testgroups are also included in tests, so filter those out for now\n                if isinstance(test, Ftest) and test.stylename:\n                    sname = test.stylename\n                    usedStyles.add(sname)\n                    if sname is not None and sname not in unknownStyles and \\\n                            not (hasStyles and sname in ftml.head.styles):\n                        logger.log(f'  stylename \"{sname}\" not defined in head/styles', 'E')\n                        unknownStyles.add(sname)\n            # recurse to nested testgroups if any:\n            if testgroup.testgroups is not None:\n               for subgroup in testgroup.testgroups:\n                   checktestgroup(subgroup)\n\n        with open(fname,encoding='utf8') as f:\n            # Attempt to parse the ftml file\n            ftml = Fxml(f)\n            hasStyles = ftml.head.styles is not None  # Whether or not any styles are defined in head element\n\n            # Look through all tests for undefined styles:\n            for testgroup in ftml.testgroups:\n                checktestgroup(testgroup)\n\n            if hasStyles:\n                # look for unused styles:\n                for style in ftml.head.styles:\n                    if style not in usedStyles:\n                        logger.log(f'  defined style \"{style}\" not used in any test', 'W')",
  "def cmd() : execute(None,doit, argspec)",
  "def checktestgroup(testgroup):\n            for test in testgroup.tests:\n                # Not sure why, but sub-testgroups are also included in tests, so filter those out for now\n                if isinstance(test, Ftest) and test.stylename:\n                    sname = test.stylename\n                    usedStyles.add(sname)\n                    if sname is not None and sname not in unknownStyles and \\\n                            not (hasStyles and sname in ftml.head.styles):\n                        logger.log(f'  stylename \"{sname}\" not defined in head/styles', 'E')\n                        unknownStyles.add(sname)\n            # recurse to nested testgroups if any:\n            if testgroup.testgroups is not None:\n               for subgroup in testgroup.testgroups:\n                   checktestgroup(subgroup)",
  "def doit(args):\n    font = args.ifont\n    logger = args.logger\n    incsv = args.input\n    gname = args.gname\n    removemissing = args.removemissing\n\n    glyphlist = list(font.deflayer.keys())  # List to check every glyph has a psname supplied\n\n    # Identify file format from first line\n    fl = incsv.firstline\n    if fl is None: logger.log(\"Empty input file\", \"S\")\n    numfields = len(fl)\n    incsv.numfields = numfields\n    if numfields == 2:\n        glyphnpos = 0\n        psnamepos = 1    # Default for plain csv\n    elif numfields > 2:  # More than 2 columns, so must have standard headers\n        if gname in fl:\n            glyphnpos = fl.index(gname)\n        else:\n            logger.log(\"No \" + gname + \" field in csv headers\", \"S\")\n        if \"ps_name\" in fl:\n            psnamepos = fl.index(\"ps_name\")\n        else:\n            logger.log(\"No ps_name field in csv headers\", \"S\")\n        next(incsv.reader, None)  # Skip first line with headers in\n    else:\n        logger.log(\"Invalid csv file\", \"S\")\n\n    # Now process the data\n    dict = ET.Element(\"dict\")\n    for line in incsv:\n        glyphn = line[glyphnpos]\n        psname = line[psnamepos]\n        if len(psname) == 0 or glyphn == psname:\n            continue\t# No need to include cases where production name is blank or same as working name\n        # Check if in font\n        infont = False\n        if glyphn in glyphlist:\n            glyphlist.remove(glyphn)\n            infont = True\n        else:\n            if not removemissing: logger.log(\"No glyph in font for \" + glyphn + \" on line \" + str(incsv.line_num), \"I\")\n        if not removemissing or infont:\n            # Add to dict\n            sub = ET.SubElement(dict, \"key\")\n            sub.text = glyphn\n            sub = ET.SubElement(dict, \"string\")\n            sub.text = psname\n    # Add to lib.plist\n    if len(dict) > 0:\n        if \"lib\" not in font.__dict__: font.addfile(\"lib\")\n        font.lib.setelem(\"public.postscriptNames\", dict)\n    else:\n        if \"lib\" in font.__dict__ and \"public.postscriptNames\" in font.lib:\n            font.lib.remove(\"public.postscriptNames\")\n\n    for glyphn in sorted(glyphlist): logger.log(\"No PS name in input file for font glyph \" + glyphn, \"I\")\n\n    return font",
  "def cmd(): execute(\"UFO\", doit, argspec)",
  "def doit(args) :\n    font = args.ifont\n    logger = args.logger\n\n    constructions = ParseGlyphConstructionListFromString(args.cdfile)\n\n    for construction in constructions :\n        # Create a new constructed glyph object\n        try:\n            constructionGlyph = GlyphConstructionBuilder(construction, font)\n        except ValueError as e:\n            logger.log(\"Invalid CD line '\" + construction + \"' - \" + str(e), \"E\")\n        else:\n            # Make a new glyph in target font with the new glyph name\n            glyph = font.newGlyph(constructionGlyph.name)\n            # Draw the constructed object onto the new glyph\n            # This is rather odd in how it works\n            constructionGlyph.draw(glyph.getPen())\n            # Copy glyph metadata from constructed object\n            glyph.name = constructionGlyph.name\n            glyph.unicode = constructionGlyph.unicode\n            glyph.note = constructionGlyph.note\n            #glyph.markColor = constructionGlyph.mark\n            glyph.width = constructionGlyph.width\n\n    return font",
  "def cmd() : execute(\"FP\",doit,argspec)",
  "def doit(args) :\n    font = args.ifont\n    logger = args.logger\n    infile = args.input\n    color = args.color\n    unicodes = args.unicodes\n    deletecolors = args.deletecolors\n\n    if not ((color is not None) ^ deletecolors): logger.log(\"Must specify one and only one of -c and -x\", \"S\")\n\n    if color is not None:\n        (color, colorname, logcolor, splitcolor) = parsecolors(color, single=True)\n        if color is None: logger.log(logcolor, \"S\") # If color not parsed, parsecolors() puts error in logcolor\n\n    # Process the input file.  It needs to be done in script rather than by execute() since, if -x is used, there might not be one\n    (ibase, iname, iext) = splitfn(infile)\n    if iname == \"nodefault\": # Indicates no file was specified\n        infile = None\n        if (color is not None) or unicodes or (not deletecolors): logger.log(\"If no input file, -x must be used and neither -c or -u can be used\", \"S\")\n    else:\n        logger.log('Opening file for input: ' + infile, \"P\")\n        try:\n            infile = io.open(infile, \"r\", encoding=\"utf-8\")\n        except Exception as e:\n            logger.log(\"Failed to open file: \" + str(e), \"S\")\n\n    # Create list of glyphs to process\n    if deletecolors and infile is None: # Need to delete colors from all glyphs\n        glyphlist = sorted(font.deflayer.keys())\n    else:\n        inlist = [x.strip() for x in infile.readlines()]\n        glyphlist = []\n        if unicodes:\n            unicodesfound = []\n            for glyphn in sorted(font.deflayer.keys()):\n                glyph = font.deflayer[glyphn]\n                for unicode in [x.hex for x in glyph[\"unicode\"]]:\n                    if unicode in inlist:\n                        glyphlist.append(glyphn)\n                        unicodesfound.append(unicode)\n            for unicode in inlist:\n                if unicode not in unicodesfound: logger.log(\"No gylphs with unicode '\" + unicode + \"' in the font\", \"I\")\n        else:\n            for glyphn in inlist:\n                if glyphn in font.deflayer:\n                    glyphlist.append(glyphn)\n                else:\n                    logger.log(glyphn + \" is not in the font\", \"I\")\n\n    changecnt = 0\n    for glyphn in glyphlist:\n        glyph = font.deflayer[glyphn]\n        oldcolor = None\n        lib = glyph[\"lib\"]\n        if lib:\n            if \"public.markColor\" in lib: oldcolor = str(glyph[\"lib\"].getval(\"public.markColor\"))\n        if oldcolor != color:\n            if oldcolor is not None:\n                (temp, oldname, oldlogcolor, splitcolor) = parsecolors(oldcolor, single=True)\n                if temp is None: oldlogcolor = oldcolor # Failed to parse old color, so just report what is was\n\n            changecnt += 1\n            if deletecolors:\n                glyph[\"lib\"].remove(\"public.markColor\")\n                logger.log(glyphn + \": \" + oldlogcolor + \" removed\", \"I\")\n            else:\n                if oldcolor is None:\n                    if lib is None: glyph.add(\"lib\")\n                    glyph[\"lib\"].setval(\"public.markColor\",\"string\",color)\n                    logger.log(glyphn+ \": \" + logcolor + \" added\", \"I\")\n                else:\n                    glyph[\"lib\"].setval(\"public.markColor\", \"string\", color)\n                    logger.log(glyphn + \": \" + oldlogcolor + \" changed to \" + logcolor, \"I\")\n\n    if deletecolors:\n        logger.log(str(changecnt) + \" colors removed\", \"P\")\n    else:\n        logger.log(str(changecnt) + \" colors changed or added\", \"P\")\n\n    return font",
  "def cmd() : execute(\"UFO\",doit,argspec)",
  "def doit(args) :\n    font = args.ifont\n    incsv = args.input\n    incsv.minfields = 2\n    incsv.logger = font.logger\n    glyphlist = list(font.deflayer.keys()) # Identify which glifs have not got AssocUIDs set\n\n    for line in incsv :\n        glyphn = line.pop(0)\n        if glyphn in glyphlist :\n            glyph = font.deflayer[glyphn]\n            if glyph[\"lib\"] is None : glyph.add(\"lib\")\n            # Create an array element for the UID value(s)\n            array = ET.Element(\"array\")\n            for UID in line:\n                sub = ET.SubElement(array,\"string\")\n                sub.text = UID\n            glyph[\"lib\"].setelem(\"org.sil.assocUIDs\",array)\n            glyphlist.remove(glyphn)\n        else :\n            font.logger.log(\"No glyph in font for \" + glyphn + \" on line \" + str(incsv.line_num),\"E\")\n\n    for glyphn in glyphlist : # Remove any values from remaining glyphs\n        glyph = font.deflayer[glyphn]\n        if glyph[\"lib\"] :\n            if \"org.sil.assocUIDs\" in glyph[\"lib\"] :\n                glyph[\"lib\"].remove(\"org.sil.assocUIDs\")\n                font.logger.log(\"UID info removed for \" + glyphn,\"I\")\n\n    return font",
  "def cmd() : execute(\"UFO\",doit,argspec)",
  "def doit(args):\n\n    ttf = ttLib.TTFont(args.ifont)\n\n    newDSIG = ttLib.newTable(\"DSIG\")\n    newDSIG.ulVersion = 1\n    newDSIG.usFlag = 0\n    newDSIG.usNumSigs = 0\n    newDSIG.signatureRecords = []\n    ttf.tables[\"DSIG\"] = newDSIG\n\n    args.logger.log('Saving the output ttf file with dummy DSIG table', 'P')\n    ttf.save(args.ofont)\n\n    args.logger.log('Done', 'P')",
  "def cmd(): execute(\"FT\", doit, argspec)",
  "def doit(args):\n    logger = args.logger\n    masterdir = args.masterdir\n    logger.log(\"Creating UFO objects from GlyphsApp file\", \"I\")\n    with open(args.glyphsfont, 'r', encoding='utf-8') as gfile:\n        gfont = glyphsLib.parser.load(gfile)\n    ufos = glyphsLib.to_ufos(gfont, include_instances=False, family_name=None, propagate_anchors=False, generate_GDEF=False)\n\n    keylists = {\n\n        \"librestorekeys\": [\"org.sil.pysilfontparams\", \"org.sil.altLineMetrics\", \"org.sil.lcg.toneLetters\",\n                   \"org.sil.lcg.transforms\", \"public.glyphOrder\", \"public.postscriptNames\",\n                   \"com.schriftgestaltung.disablesLastChange\", \"com.schriftgestaltung.disablesAutomaticAlignment\",\n                   \"public.skipExportGlyphs\"],\n        \"libdeletekeys\": (\"com.schriftgestaltung.customParameter.GSFont.copyright\",\n                          \"com.schriftgestaltung.customParameter.GSFont.designer\",\n                          \"com.schriftgestaltung.customParameter.GSFont.manufacturer\",\n                          \"com.schriftgestaltung.customParameter.GSFont.note\",\n                          \"com.schriftgestaltung.customParameter.GSFont.Axes\",\n                          \"com.schriftgestaltung.customParameter.GSFont.Axis Mappings\",\n                          \"com.schriftgestaltung.customParameter.GSFontMaster.Master Name\"),\n        \"libdeleteempty\": (\"com.schriftgestaltung.DisplayStrings\",),\n        \"inforestorekeys\": [\"openTypeHeadCreated\", \"openTypeHeadFlags\", \"openTypeNamePreferredFamilyName\", \"openTypeNamePreferredSubfamilyName\",\n                       \"openTypeNameUniqueID\", \"openTypeOS2WeightClass\", \"openTypeOS2WidthClass\", \"postscriptFontName\",\n                       \"postscriptFullName\", \"styleMapFamilyName\", \"styleMapStyleName\", \"note\",\n                       \"woffMetadataCredits\", \"woffMetadataDescription\"],\n        \"integerkeys\": (\"openTypeOS2WeightClass\", \"openTypeOS2WidthClass\"),\n        \"infodeletekeys\": (\"openTypeVheaVertTypoAscender\", \"openTypeVheaVertTypoDescender\", \"openTypeVheaVertTypoLineGap\"),\n #       \"infodeleteempty\": (\"openTypeOS2Selection\",)\n    }\n\n    if args.restore: # Extra keys to restore.  Add to both lists, since should never be duplicated names\n        keylist = args.restore.split(\",\")\n        keylists[\"librestorekeys\"] += keylist\n        keylists[\"inforestorekeys\"].append(keylist)\n\n    loglists = []\n    obskeysfound={}\n    for ufo in ufos:\n        loglists.append(process_ufo(ufo, keylists, masterdir, args, obskeysfound))\n    for loglist in loglists:\n        for logitem in loglist: logger.log(logitem[0], logitem[1])\n    if obskeysfound:\n        logmess = \"The following obsolete keys were found. They may have been in the original UFO or you may have an old version of glyphsLib installed\\n\"\n        for fontname in obskeysfound:\n            keys = obskeysfound[fontname]\n            logmess += \"                    \" + fontname + \": \"\n            for key in keys:\n                logmess += key + \", \"\n            logmess += \"\\n\"\n        logger.log(logmess, \"E\")",
  "def process_ufo(ufo, keylists, masterdir, args, obskeysfound):\n    loglist=[]\n#    sn = ufo.info.styleName  # )\n#    sn = sn.replace(\"Italic Italic\", \"Italic\")  # ) Temp fixes due to glyphLib incorrectly\n#    sn = sn.replace(\"Italic Bold Italic\", \"Bold Italic\")  # ) forming styleName\n#    sn = sn.replace(\"Extra Italic Light Italic\", \"Extra Light Italic\")  # )\n#    ufo.info.styleName = sn  # )\n    fontname = ufo.info.familyName.replace(\" \", \"\") + \"-\" + ufo.info.styleName.replace(\" \", \"\")\n\n    # Fixes to the data\n    if not args.nofixes:\n        loglist.append((\"Fixing data in \" + fontname, \"P\"))\n        # lib.plist processing\n        loglist.append((\"Checking lib.plist\", \"P\"))\n\n        # Restore values from original UFOs, assuming named as <fontname>.ufo in the masterdir\n\n        ufodir = os.path.join(masterdir, fontname + \".ufo\")\n        try:\n            origlibplist = silfont.ufo.Uplist(font=None, dirn=ufodir, filen=\"lib.plist\")\n        except Exception as e:\n            loglist.append((\"Unable to open lib.plist in \" + ufodir + \"; values will not be restored\", \"E\"))\n            origlibplist = None\n\n        if origlibplist is not None:\n\n            for key in keylists[\"librestorekeys\"]:\n                current = None if key not in ufo.lib else ufo.lib[key]\n                if key in origlibplist:\n                    new = origlibplist.getval(key)\n                    if current == new:\n                        continue\n                    else:\n                        ufo.lib[key] = new\n                        logchange(loglist, \" restored from backup ufo. \", key, current, new)\n                elif current:\n                    ufo.lib[key] = None\n                    logchange(loglist, \" removed since not in backup ufo. \", key, current, None)\n\n        # Delete unneeded keys\n\n        for key in keylists[\"libdeletekeys\"]:\n            if key in ufo.lib:\n                current = ufo.lib[key]\n                del ufo.lib[key]\n                logchange(loglist, \" deleted. \", key, current, None)\n\n        for key in keylists[\"libdeleteempty\"]:\n            if key in ufo.lib and (ufo.lib[key] == \"\" or ufo.lib[key] == []):\n                current = ufo.lib[key]\n                del ufo.lib[key]\n                logchange(loglist, \" empty field deleted. \", key, current, None)\n\n        # Check for obsolete keys\n        for key in obsoleteLibKeys:\n            if key in ufo.lib:\n                if fontname not in obskeysfound: obskeysfound[fontname] = []\n                obskeysfound[fontname].append(key)\n\n        # Special processing for Axis Mappings\n        #key = \"com.schriftgestaltung.customParameter.GSFont.Axis Mappings\"\n        #if key in ufo.lib:\n        #    current =ufo.lib[key]\n        #    new = dict(current)\n        #    for x in current:\n        #        val = current[x]\n        #        k = list(val.keys())[0]\n        #        if k[-2:] == \".0\": new[x] = {k[0:-2]: val[k]}\n        #    if current != new:\n        #        ufo.lib[key] = new\n        #        logchange(loglist, \" key names set to integers. \", key, current, new)\n\n        # Special processing for ufo2ft filters\n        key = \"com.github.googlei18n.ufo2ft.filters\"\n        if key in ufo.lib:\n            current = ufo.lib[key]\n            new = list(current)\n            for x in current:\n                if x[\"name\"] == \"eraseOpenCorners\":\n                    new.remove(x)\n\n            if current != new:\n                if new == []:\n                    del ufo.lib[key]\n                else:\n                    ufo.lib[key] = new\n                logchange(loglist, \" eraseOpenCorners filter removed \", key, current, new)\n\n        # fontinfo.plist processing\n\n        loglist.append((\"Checking fontinfo.plist\", \"P\"))\n\n        try:\n            origfontinfo = silfont.ufo.Uplist(font=None, dirn=ufodir, filen=\"fontinfo.plist\")\n        except Exception as e:\n            loglist.append((\"Unable to open fontinfo.plist in \" + ufodir + \"; values will not be restored\", \"E\"))\n            origfontinfo = None\n\n        if origfontinfo is not None:\n            for key in keylists[\"inforestorekeys\"]:\n                current = None if not hasattr(ufo.info, key) else getattr(ufo.info, key)\n                if key in origfontinfo:\n                    new = origfontinfo.getval(key)\n                    if key in keylists[\"integerkeys\"]: new = int(new)\n                    if current == new:\n                        continue\n                    else:\n                        setattr(ufo.info, key, new)\n                        logchange(loglist, \" restored from backup ufo. \", key, current, new)\n                elif current:\n                    setattr(ufo.info, key, None)\n                    logchange(loglist, \" removed since not in backup ufo. \", key, current, None)\n\n        if getattr(ufo.info, \"italicAngle\") == 0:  # Remove italicAngle if 0\n            setattr(ufo.info, \"italicAngle\", None)\n            logchange(loglist, \" removed\", \"italicAngle\", 0, None)\n\n        # Delete unneeded keys\n\n        for key in keylists[\"infodeletekeys\"]:\n            if hasattr(ufo.info, key):\n               current = getattr(ufo.info, key)\n               setattr(ufo.info, key, None)\n               logchange(loglist, \" deleted. \", key, current, None)\n\n#        for key in keylists[\"infodeleteempty\"]:\n#            if hasattr(ufo.info, key) and getattr(ufo.info, key) == \"\":\n#                setattr(ufo.info, key, None)\n#                logchange(loglist, \" empty field deleted. \", key, current, None)\n    if args.nofea or args.preservefea: ufo.features.text = \"\"  # Suppress output of features.fea\n\n    # Now check for glyph level changes needed\n    heightchanges = 0\n    vertorichanges = 0\n    for layer in ufo.layers:\n        for glyph in layer:\n            if glyph.height != 0:\n                loglist.append((f'Advance height of {str(glyph.height)} removed for {glyph.name}', \"V\"))\n                glyph.height = 0\n                heightchanges += 1\n            lib = glyph.lib\n            if \"public.verticalOrigin\" in lib:\n                del lib[\"public.verticalOrigin\"]\n                vertorichanges += 1\n    if heightchanges: loglist.append((f\"{str(heightchanges)} advance heights removed from glyphs\", \"I\"))\n    if vertorichanges: loglist.append((f\"{str(vertorichanges)} public.verticalOrigins removed from lib in glyphs\", \"I\"))\n\n    # Write ufo out\n    ufopath = os.path.join(masterdir, fontname + \".ufo\")\n    if args.preservefea:  # Move features.fea out of the ufo so that it can be restored afterward\n        origfea = os.path.join(ufopath, \"features.fea\")\n        hiddenfea = os.path.join(masterdir, fontname + \"features.tmp\")\n        if os.path.exists(origfea):\n            loglist.append((f'Renaming {origfea} to {hiddenfea}', \"I\"))\n            os.rename(origfea, hiddenfea)\n        else:\n            loglist.append((f\"{origfea} does not exists so can't be restored\", \"E\"))\n            origfea = None\n    loglist.append((\"Writing out \" + ufopath, \"P\"))\n    if os.path.exists(ufopath): shutil.rmtree(ufopath)\n    ufo.save(ufopath)\n    if args.preservefea and origfea:\n        loglist.append((f'Renaming {hiddenfea} back to {origfea}', \"I\"))\n        os.rename(hiddenfea, origfea)\n\n    # Now correct the newly-written fontinfo.plist with changes that can't be made via glyphsLib\n    if not args.nofixes:\n        fontinfo = silfont.ufo.Uplist(font=None, dirn=ufopath, filen=\"fontinfo.plist\")\n        changes = False\n        for key in (\"guidelines\", \"postscriptBlueValues\", \"postscriptFamilyBlues\", \"postscriptFamilyOtherBlues\",\n                    \"postscriptOtherBlues\"):\n            if key in fontinfo and fontinfo.getval(key) == []:\n                fontinfo.remove(key)\n                changes = True\n                logchange(loglist, \" empty list deleted\", key, None, [])\n        if changes:\n            # Create outparams.  Just need any valid values, since font will need normalizing later\n            params = args.paramsobj\n            paramset = params.sets[\"main\"]\n            outparams = {\"attribOrders\": {}}\n            for parn in params.classes[\"outparams\"]: outparams[parn] = paramset[parn]\n            loglist.append((\"Writing updated fontinfo.plist\", \"I\"))\n            silfont.ufo.writeXMLobject(fontinfo, params=outparams, dirn=ufopath, filen=\"fontinfo.plist\", exists=True,\n                                       fobject=True)\n    return loglist",
  "def logchange(loglist, logmess, key, old, new):\n    oldstr = str(old) if len(str(old)) < 22 else str(old)[0:20] + \"...\"\n    newstr = str(new) if len(str(new)) < 22 else str(new)[0:20] + \"...\"\n    logmess = key + logmess\n    if old is None:\n        logmess = logmess + \" New value: \" + newstr\n    else:\n        if new is None:\n            logmess = logmess + \" Old value: \" + oldstr\n        else:\n            logmess = logmess + \" Old value: \" + oldstr + \", new value: \" + newstr\n    loglist.append((logmess, \"I\"))\n    # Extra verbose logging\n    if len(str(old)) > 21 :\n        loglist.append((\"Full old value: \" + str(old), \"V\"))\n    if len(str(new)) > 21 :\n        loglist.append((\"Full new value: \" + str(new), \"V\"))\n    loglist.append((\"Types: Old - \" + str(type(old)) + \", New - \" + str(type(new)), \"V\"))",
  "def cmd(): execute(None, doit, argspec)",
  "def doit(args) :\n    ficopyreq = (\"ascender\", \"copyright\", \"descender\", \"familyName\", \"openTypeHheaAscender\",\n                  \"openTypeHheaDescender\", \"openTypeHheaLineGap\", \"openTypeNameDescription\", \"openTypeNameDesigner\",\n                  \"openTypeNameDesignerURL\", \"openTypeNameLicense\", \"openTypeNameLicenseURL\",\n                  \"openTypeNameManufacturer\", \"openTypeNameManufacturerURL\", \"openTypeNamePreferredFamilyName\",\n                  \"openTypeNameVersion\", \"openTypeOS2CodePageRanges\", \"openTypeOS2TypoAscender\",\n                  \"openTypeOS2TypoDescender\", \"openTypeOS2TypoLineGap\", \"openTypeOS2UnicodeRanges\",\n                  \"openTypeOS2VendorID\", \"openTypeOS2WinAscent\", \"openTypeOS2WinDescent\", \"versionMajor\",\n                  \"versionMinor\")\n    ficopyopt = (\"openTypeNameSampleText\", \"postscriptFamilyBlues\", \"postscriptFamilyOtherBlues\", \"styleMapFamilyName\",\n                  \"trademark\", \"woffMetadataCredits\", \"woffMetadataDescription\")\n    fispecial = (\"italicAngle\", \"openTypeOS2WeightClass\", \"openTypeNamePreferredSubfamilyName\", \"openTypeNameUniqueID\",\n                 \"styleName\", \"unitsPerEm\")\n    fiall = sorted(set(ficopyreq) | set(ficopyopt) | set(fispecial))\n    firequired = ficopyreq + (\"openTypeOS2WeightClass\", \"styleName\", \"unitsPerEm\")\n    libcopyreq = (\"com.schriftgestaltung.glyphOrder\", \"public.glyphOrder\", \"public.postscriptNames\")\n    libcopyopt = (\"public.skipExportGlyphs\",)\n    liball = sorted(set(libcopyreq) | set(libcopyopt))\n    logger = args.logger\n\n    pds = DSD.DesignSpaceDocument()\n    pds.read(args.primaryds)\n    if args.secondds is not None:\n        sds = DSD.DesignSpaceDocument()\n        sds.read(args.secondds)\n    else:\n        sds = None\n    # Extract weight mappings from axes\n    pwmap = swmap = {}\n    for (ds, wmap, name) in ((pds, pwmap, \"primary\"),(sds, swmap, \"secondary\")):\n        if ds:\n            rawmap = None\n            for descriptor in ds.axes:\n                if descriptor.name == \"weight\":\n                    rawmap = descriptor.map\n                    break\n            if rawmap:\n                for (cssw, xvalue) in rawmap:\n                    wmap[int(xvalue)] = int(cssw)\n            else:\n                logger.log(f\"No weight axes mapping in {name} design space\", \"W\")\n\n    # Process all the sources\n    psource = None\n    dsources = []\n    for source in pds.sources:\n        if source.copyInfo:\n            if psource: logger.log('Multiple fonts with <info copy=\"1\" />', \"S\")\n            psource = Dsource(pds, source, logger, frompds=True, psource = True, args = args)\n        else:\n            dsources.append(Dsource(pds, source, logger, frompds=True, psource = False, args = args))\n    if sds is not None:\n        for source in sds.sources:\n            dsources.append(Dsource(sds, source, logger, frompds=False,  psource = False, args=args))\n\n    # Process values in psource\n    fipval = {}\n    libpval = {}\n    changes = False\n    reqmissing = False\n\n    for field in fiall:\n        pval = psource.fontinfo.getval(field) if field in psource.fontinfo else None\n        oval = pval\n        # Set values or do other checks for special cases\n        if field == \"italicAngle\":\n            if \"italic\" in psource.source.filename.lower():\n                if pval is None or pval == 0 :\n                    logger.log(f\"{psource.source.filename}: Italic angle must be non-zero for italic fonts\", \"E\")\n            else:\n                if pval is not None and pval != 0 :\n                    logger.log(f\"{psource.source.filename}: Italic angle must be zero for non-italic fonts\", \"E\")\n                pval = None\n        elif field == \"openTypeOS2WeightClass\":\n            desweight = int(psource.source.location[\"weight\"])\n            if desweight in pwmap:\n                pval = pwmap[desweight]\n            else:\n                logger.log(f\"Design weight {desweight} not in axes mapping so openTypeOS2WeightClass not updated\", \"I\")\n        elif field in (\"styleName\", \"openTypeNamePreferredSubfamilyName\"):\n            pval = psource.source.styleName\n        elif field == \"openTypeNameUniqueID\":\n            nm = str(fipval[\"openTypeNameManufacturer\"]) # Need to wrap with str() just in case missing from\n            fn = str(fipval[\"familyName\"]) # fontinfo so would have been set to None\n            sn = psource.source.styleName\n            pval = nm + \": \" + fn + \" \" + sn + \": \" + datetime.datetime.now().strftime(\"%Y\")\n        elif field == \"unitsperem\":\n            if pval is None or pval <= 0: logger.log(\"unitsperem must be non-zero\", \"S\")\n        # After processing special cases, all required fields should have values\n        if pval is None and field in firequired:\n            reqmissing = True\n            logger.log(\"Required fontinfo field \" + field + \" missing from \" + psource.source.filename, \"E\")\n        elif oval != pval:\n            changes = True\n            if pval is None:\n                if field in psource.fontinfo: psource.fontinfo.remove(field)\n            else:\n                psource.fontinfo[field][1].text = str(pval)\n            logchange(logger, f\"{psource.source.filename}: {field} updated:\", oval, pval)\n        fipval[field] = pval\n    if reqmissing: logger.log(\"Required fontinfo fields missing from \" + psource.source.filename, \"S\")\n    if changes:\n        psource.fontinfo.setval(\"openTypeHeadCreated\", \"string\",\n                             datetime.datetime.now().strftime(\"%Y/%m/%d %H:%M:%S\"))\n        psource.write(\"fontinfo\")\n\n    for field in liball:\n        pval = psource.lib.getval(field) if field in psource.lib else None\n        if pval is None:\n            if field in libcopyreq:\n                logtype = \"W\" if field[0:7] == \"public.\" else \"I\"\n                logger.log(\"lib.plist field \" + field + \" missing from \" + psource.source.filename, logtype)\n        libpval[field] = pval\n\n    # Now update values in other source fonts\n\n    for dsource in dsources:\n        logger.log(\"Processing \" + dsource.ufodir, \"I\")\n        fchanges = False\n        for field in fiall:\n            sval = dsource.fontinfo.getval(field) if field in dsource.fontinfo else None\n            oval = sval\n            pval = fipval[field]\n            # Set values or do other checks for special cases\n            if field == \"italicAngle\":\n                if \"italic\" in dsource.source.filename.lower():\n                    if sval is None or sval == 0:\n                        logger.log(dsource.source.filename + \": Italic angle must be non-zero for italic fonts\", \"E\")\n                else:\n                    if sval is not None and sval != 0:\n                        logger.log(dsource.source.filename + \": Italic angle must be zero for non-italic fonts\", \"E\")\n                    sval = None\n            elif field == \"openTypeOS2WeightClass\":\n                desweight = int(dsource.source.location[\"weight\"])\n                if desweight in swmap:\n                    sval = swmap[desweight]\n                else:\n                    logger.log(f\"Design weight {desweight} not in axes mapping so openTypeOS2WeightClass not updated\", \"I\")\n            elif field in (\"styleName\", \"openTypeNamePreferredSubfamilyName\"):\n                sval = dsource.source.styleName\n            elif field == \"openTypeNameUniqueID\":\n                sn = dsource.source.styleName\n                sval = nm + \": \" + fn + \" \" + sn + \": \" + datetime.datetime.now().strftime(\"%Y\")\n            else:\n                sval = pval\n            if oval != sval:\n                if field == \"unitsPerEm\": logger.log(\"unitsPerEm inconsistent across fonts\", \"S\")\n                fchanges = True\n                if sval is None:\n                    dsource.fontinfo.remove(field)\n                    logmess = \" removed: \"\n                else:\n                    logmess = \" added: \" if oval is None else \" updated: \"\n                    # Copy value from primary.  This will add if missing.\n                    dsource.fontinfo.setelem(field, ET.fromstring(ET.tostring(psource.fontinfo[field][1])))\n                    # For fields where it is not a copy from primary...\n                    if field in (\"italicAngle\", \"openTypeNamePreferredSubfamilyName\", \"openTypeNameUniqueID\",\n                                 \"openTypeOS2WeightClass\", \"styleName\"):\n                        dsource.fontinfo[field][1].text = str(sval)\n\n                logchange(logger, dsource.source.filename + \" \" + field + logmess, oval, sval)\n\n        lchanges = False\n        for field in liball:\n            oval = dsource.lib.getval(field) if field in dsource.lib else None\n            pval = libpval[field]\n            if oval != pval:\n                lchanges = True\n                if pval is None:\n                    dsource.lib.remove(field)\n                    logmess = \" removed: \"\n                else:\n                    dsource.lib.setelem(field, ET.fromstring(ET.tostring(psource.lib[field][1])))\n                    logmess = \" updated: \"\n                logchange(logger, dsource.source.filename + \" \" + field + logmess, oval, pval)\n\n        if lchanges:\n            dsource.write(\"lib\")\n            fchanges = True # Force fontinfo to update so openTypeHeadCreated is set\n        if fchanges:\n            dsource.fontinfo.setval(\"openTypeHeadCreated\", \"string\",\n                                    datetime.datetime.now().strftime(\"%Y/%m/%d %H:%M:%S\"))\n            dsource.write(\"fontinfo\")\n\n    logger.log(\"psfsyncmasters completed\", \"P\")",
  "class Dsource(object):\n    def __init__(self, ds, source, logger, frompds, psource, args):\n        self.ds = ds\n        self.source = source\n        self.logger = logger\n        self.frompds = frompds # Boolean to say if came from pds\n        self.newfile = \"_new\" if args.new else \"\"\n        self.ufodir = source.path\n        if not os.path.isdir(self.ufodir): logger.log(self.ufodir + \" in designspace doc does not exist\", \"S\")\n        try:\n            self.fontinfo = UFO.Uplist(font=None, dirn=self.ufodir, filen=\"fontinfo.plist\")\n        except Exception as e:\n            logger.log(\"Unable to open fontinfo.plist in \" + self.ufodir, \"S\")\n        try:\n            self.lib = UFO.Uplist(font=None, dirn=self.ufodir, filen=\"lib.plist\")\n        except Exception as e:\n            if psource:\n                logger.log(\"Unable to open lib.plist in \" + self.ufodir, \"E\")\n                self.lib = {} # Just need empty dict, so all vals will be set to None\n            else:\n                logger.log(\"Unable to open lib.plist in \" + self.ufodir + \"; creating empty one\", \"E\")\n                self.lib = UFO.Uplist()\n                self.lib.logger=logger\n                self.lib.etree = ET.fromstring(\"<plist>\\n<dict/>\\n</plist>\")\n                self.lib.populate_dict()\n                self.lib.dirn = self.ufodir\n                self.lib.filen = \"lib.plist\"\n\n        # Process parameters with similar logic to that in ufo.py. primarily to create outparams for writeXMLobject\n        libparams = {}\n        params = args.paramsobj\n        if \"org.sil.pysilfontparams\" in self.lib:\n            elem = self.lib[\"org.sil.pysilfontparams\"][1]\n            if elem.tag != \"array\":\n                logger.log(\"Invalid parameter XML lib.plist - org.sil.pysilfontparams must be an array\", \"S\")\n            for param in elem:\n                parn = param.tag\n                if not (parn in params.paramclass) or params.paramclass[parn] not in (\"outparams\", \"ufometadata\"):\n                    logger.log(\n                        \"lib.plist org.sil.pysilfontparams must only contain outparams or ufometadata values: \" + parn + \" invalid\",\n                        \"S\")\n                libparams[parn] = param.text\n        # Create font-specific parameter set (with updates from lib.plist)  Prepend names with ufodir to ensure uniqueness if multiple fonts open\n        params.addset(self.ufodir + \"lib\", \"lib.plist in \" + self.ufodir, inputdict=libparams)\n        if \"command line\" in params.sets:\n            params.sets[self.ufodir + \"lib\"].updatewith(\"command line\", log=False)  # Command line parameters override lib.plist ones\n        copyset = \"main\" if \"main\" in params.sets else \"default\"\n        params.addset(self.ufodir, copyset=copyset)\n        params.sets[self.ufodir].updatewith(self.ufodir + \"lib\", sourcedesc=\"lib.plist\")\n        self.paramset = params.sets[self.ufodir]\n        # Validate specific parameters\n        if sorted(self.paramset[\"glifElemOrder\"]) != sorted(params.sets[\"default\"][\"glifElemOrder\"]):\n            logger.log(\"Invalid values for glifElemOrder\", \"S\")\n        # Create outparams based on values in paramset, building attriborders from separate attriborders.<type> parameters.\n        self.outparams = {\"attribOrders\": {}}\n        for parn in params.classes[\"outparams\"]:\n            value = self.paramset[parn]\n            if parn[0:12] == 'attribOrders':\n                elemname = parn.split(\".\")[1]\n                self.outparams[\"attribOrders\"][elemname] = ETU.makeAttribOrder(value)\n            else:\n                self.outparams[parn] = value\n        self.outparams[\"UFOversion\"] = 9 # Dummy value since not currently needed\n\n    def write(self, plistn):\n        filen = plistn + self.newfile + \".plist\"\n        self.logger.log(\"Writing updated \" + plistn + \".plist to \" + filen, \"P\")\n        exists = True if os.path.isfile(os.path.join(self.ufodir, filen)) else False\n        plist = getattr(self, plistn)\n        UFO.writeXMLobject(plist, self.outparams, self.ufodir, filen, exists, fobject=True)",
  "def logchange(logger, logmess, old, new):\n    oldstr = str(old) if len(str(old)) < 22 else str(old)[0:20] + \"...\"\n    newstr = str(new) if len(str(new)) < 22 else str(new)[0:20] + \"...\"\n    if old is None:\n        logmess = logmess + \" New value: \" + newstr\n    else:\n        if new is None:\n            logmess = logmess + \" Old value: \" + oldstr\n        else:\n            logmess = logmess + \" Old value: \" + oldstr + \", new value: \" + newstr\n    logger.log(logmess, \"W\")\n    # Extra verbose logging\n    if len(str(old)) > 21 :\n        logger.log(\"Full old value: \" + str(old), \"V\")\n    if len(str(new)) > 21 :\n        logger.log(\"Full new value: \" + str(new), \"V\")\n    logger.log(\"Types: Old - \" + str(type(old)) + \", New - \" + str(type(new)), \"V\")",
  "def cmd() : execute(None,doit, argspec)",
  "def __init__(self, ds, source, logger, frompds, psource, args):\n        self.ds = ds\n        self.source = source\n        self.logger = logger\n        self.frompds = frompds # Boolean to say if came from pds\n        self.newfile = \"_new\" if args.new else \"\"\n        self.ufodir = source.path\n        if not os.path.isdir(self.ufodir): logger.log(self.ufodir + \" in designspace doc does not exist\", \"S\")\n        try:\n            self.fontinfo = UFO.Uplist(font=None, dirn=self.ufodir, filen=\"fontinfo.plist\")\n        except Exception as e:\n            logger.log(\"Unable to open fontinfo.plist in \" + self.ufodir, \"S\")\n        try:\n            self.lib = UFO.Uplist(font=None, dirn=self.ufodir, filen=\"lib.plist\")\n        except Exception as e:\n            if psource:\n                logger.log(\"Unable to open lib.plist in \" + self.ufodir, \"E\")\n                self.lib = {} # Just need empty dict, so all vals will be set to None\n            else:\n                logger.log(\"Unable to open lib.plist in \" + self.ufodir + \"; creating empty one\", \"E\")\n                self.lib = UFO.Uplist()\n                self.lib.logger=logger\n                self.lib.etree = ET.fromstring(\"<plist>\\n<dict/>\\n</plist>\")\n                self.lib.populate_dict()\n                self.lib.dirn = self.ufodir\n                self.lib.filen = \"lib.plist\"\n\n        # Process parameters with similar logic to that in ufo.py. primarily to create outparams for writeXMLobject\n        libparams = {}\n        params = args.paramsobj\n        if \"org.sil.pysilfontparams\" in self.lib:\n            elem = self.lib[\"org.sil.pysilfontparams\"][1]\n            if elem.tag != \"array\":\n                logger.log(\"Invalid parameter XML lib.plist - org.sil.pysilfontparams must be an array\", \"S\")\n            for param in elem:\n                parn = param.tag\n                if not (parn in params.paramclass) or params.paramclass[parn] not in (\"outparams\", \"ufometadata\"):\n                    logger.log(\n                        \"lib.plist org.sil.pysilfontparams must only contain outparams or ufometadata values: \" + parn + \" invalid\",\n                        \"S\")\n                libparams[parn] = param.text\n        # Create font-specific parameter set (with updates from lib.plist)  Prepend names with ufodir to ensure uniqueness if multiple fonts open\n        params.addset(self.ufodir + \"lib\", \"lib.plist in \" + self.ufodir, inputdict=libparams)\n        if \"command line\" in params.sets:\n            params.sets[self.ufodir + \"lib\"].updatewith(\"command line\", log=False)  # Command line parameters override lib.plist ones\n        copyset = \"main\" if \"main\" in params.sets else \"default\"\n        params.addset(self.ufodir, copyset=copyset)\n        params.sets[self.ufodir].updatewith(self.ufodir + \"lib\", sourcedesc=\"lib.plist\")\n        self.paramset = params.sets[self.ufodir]\n        # Validate specific parameters\n        if sorted(self.paramset[\"glifElemOrder\"]) != sorted(params.sets[\"default\"][\"glifElemOrder\"]):\n            logger.log(\"Invalid values for glifElemOrder\", \"S\")\n        # Create outparams based on values in paramset, building attriborders from separate attriborders.<type> parameters.\n        self.outparams = {\"attribOrders\": {}}\n        for parn in params.classes[\"outparams\"]:\n            value = self.paramset[parn]\n            if parn[0:12] == 'attribOrders':\n                elemname = parn.split(\".\")[1]\n                self.outparams[\"attribOrders\"][elemname] = ETU.makeAttribOrder(value)\n            else:\n                self.outparams[parn] = value\n        self.outparams[\"UFOversion\"] = 9",
  "def write(self, plistn):\n        filen = plistn + self.newfile + \".plist\"\n        self.logger.log(\"Writing updated \" + plistn + \".plist to \" + filen, \"P\")\n        exists = True if os.path.isfile(os.path.join(self.ufodir, filen)) else False\n        plist = getattr(self, plistn)\n        UFO.writeXMLobject(plist, self.outparams, self.ufodir, filen, exists, fobject=True)",
  "def doit(args):\n    glyphsfile = args.glyphsfile\n    logger = args.logger\n    gformat = args.glyphsformat\n    if gformat in (\"2\",\"3\"):\n        gformat = int(gformat)\n    else:\n        logger.log(\"--glyphsformat must be 2 or 3\", 'S')\n    if glyphsfile is None:\n        (path,base,ext) = splitfn(args.designspace)\n        glyphsfile = os.path.join(path, base + \".glyphs\" )\n    else:\n        (path, base, ext) = splitfn(glyphsfile)\n    backupname = os.path.join(path, base + \"-backup.glyphs\" )\n    logger.log(\"Opening designSpace file\", \"I\")\n    ds = DesignSpaceDocument()\n    ds.read(args.designspace)\n    if args.nofea: # Need to rename the features.fea files so they are not processed\n        origfeas = []; hiddenfeas = []\n        for source in ds.sources:\n            origfea = os.path.join(source.path, \"features.fea\")\n            hiddenfea = os.path.join(source.path, \"features.tmp\")\n            if os.path.exists(origfea):\n                logger.log(f'Renaming {origfea} to {hiddenfea}', \"I\")\n                os.rename(origfea, hiddenfea)\n                origfeas.append(origfea)\n                hiddenfeas.append(hiddenfea)\n            else:\n                logger.log(f'No features.fea found in {source.path}')\n    logger.log(\"Now creating glyphs object\", \"I\")\n    glyphsfont = to_glyphs(ds)\n    if args.nofea: # Now need to reverse renamimg of features.fea files\n        for i, origfea in enumerate(origfeas):\n            logger.log(f'Renaming {hiddenfeas[i]} back to {origfea}', \"I\")\n            os.rename(hiddenfeas[i], origfea)\n    glyphsfont.format_version = gformat\n\n    if os.path.exists(glyphsfile): # Create a backup\n        logger.log(\"Renaming existing glyphs file to \" + backupname, \"I\")\n        os.renames(glyphsfile, backupname)\n    logger.log(\"Writing glyphs file: \" + glyphsfile, \"I\")\n    glyphsfont.save(glyphsfile)",
  "def cmd(): execute(None, doit, argspec)",
  "def doit(args) :\n    ofile = args.output\n    lfile = args.log\n    filelinecount = 0\n    linecount = 0\n    elementcount = 0\n    cgobj = CompGlyph()\n    f = ET.Element('font')\n    for line in args.input.readlines():\n        filelinecount += 1\n        testline = line.strip()\n        if len(testline) > 0 and testline[0:1] != '#':  # not whitespace or comment\n            linecount += 1\n            cgobj.CDline=line\n            cgobj.CDelement=None\n            try:\n                cgobj.parsefromCDline()\n                if cgobj.CDelement != None:\n                    f.append(cgobj.CDelement)\n                    elementcount += 1\n            except ValueError as e:\n                lfile.write(\"Line \"+str(filelinecount)+\": \"+str(e)+'\\n')\n    if linecount != elementcount:\n        lfile.write(\"Lines read from input file: \" + str(filelinecount)+'\\n')\n        lfile.write(\"Lines parsed (excluding blank and comment lines): \" + str(linecount)+'\\n')\n        lfile.write(\"Valid glyphs found: \" + str(elementcount)+'\\n')\n#   instead of simple serialization with: ofile.write(ET.tostring(f))\n#   create ETWriter object and specify indentation and attribute order to get normalized output\n    indentFirst = \"   \"\n    indentIncr = \"   \"\n    attOrder = \"PSName,UID,with,at,x,y\"\n    for k in args.params:\n        if k == 'indentIncr': indentIncr = args.params['indentIncr']\n        elif k == 'indentFirst': indentFirst = args.params['indentFirst']\n        elif k == 'attOrder': attOrder = args.params['attOrder']\n    x = attOrder.split(',')\n    attributeOrder = dict(zip(x,range(len(x))))\n    etwobj=ETWriter(f, indentFirst=indentFirst, indentIncr=indentIncr, attributeOrder=attributeOrder)\n    ofile.write(etwobj.serialize_xml())\n    \n    return",
  "def cmd() : execute(None,doit,argspec)",
  "def doit(args) :\n\n    font = args.font\n    logger = args.logger\n    newversion = args.newversion\n\n\n    fi = font.fontinfo\n    otelem = fi[\"openTypeNameVersion\"][1] if \"openTypeNameVersion\" in fi else None\n    majelem = fi[\"versionMajor\"][1] if \"versionMajor\" in fi else None\n    minelem = fi[\"versionMinor\"][1] if \"versionMinor\" in fi else None\n    otnv = None if otelem is None else otelem.text\n    vmaj = None if majelem is None else majelem.text\n    vmin = None if minelem is None else minelem.text\n\n    if otnv is None or vmaj is None or vmin is None : logger.log(\"At least one of openTypeNameVersion, versionMajor or versionMinor missing from fontinfo.plist\", \"S\")\n\n    if newversion is None:\n        if otnvre.match(otnv) is None:\n            logger.log(\"Current version is '\" + otnv + \"' which is non-standard\", \"E\")\n        else :\n            logger.log(\"Current version is '\" + otnv + \"'\", \"P\")\n            (otmaj,otmin,otextrainfo) = parseotnv(otnv)\n            if (otmaj, int(otmin)) != (vmaj,int(vmin)) :\n                logger.log(\"openTypeNameVersion values don't match versionMajor (\" + vmaj + \") and versionMinor (\" + vmin + \")\", \"E\")\n    else:\n        if newversion[0:1] == \"+\" :\n            if otnvre.match(otnv) is None:\n                logger.log(\"Current openTypeNameVersion is non-standard so can't be incremented: \" + otnv , \"S\")\n            else :\n                (otmaj,otmin,otextrainfo) = parseotnv(otnv)\n                if (otmaj, int(otmin)) != (vmaj,int(vmin)) :\n                    logger.log(\"openTypeNameVersion (\" + otnv + \") doesn't match versionMajor (\" + vmaj + \") and versionMinor (\" + vmin + \")\", \"S\")\n            # Process increment to versionMinor.  Note vmin is treated as 3 digit mpp where m and pp are minor and patch versions respectively\n            increment = newversion[1:]\n            if increment not in (\"1\", \"0.001\", \".001\", \"0.1\", \".1\") :\n                logger.log(\"Invalid increment value - must be one of 1, 0.001, .001, 0.1 or .1\", \"S\")\n            increment = 100 if increment in (\"0.1\", \".1\") else 1\n            if (increment == 100 and vmin[0:1] == \"9\") or (increment == 1 and vmin[1:2] == \"99\") :\n                logger.log(\"Version already at maximum so can't be incremented\", \"S\")\n            otmin = str(int(otmin) + increment).zfill(3)\n        else :\n            newversion = \"Version \" + newversion\n            if otnvre.match(newversion) is None:\n                logger.log(\"newversion format invalid - should be 'M.mpp' or 'M.mpp extrainfo'\", \"S\")\n            else :\n                (otmaj,otmin,otextrainfo) = parseotnv(newversion)\n        newotnv = \"Version \" + otmaj + \".\" + otmin + otextrainfo # Extrainfo already as leading space\n        logger.log(\"Updating version from '\" + otnv + \"' to '\" + newotnv + \"'\",\"P\")\n\n        # Update and write to disk\n        otelem.text = newotnv\n        majelem.text = otmaj\n        minelem.text = otmin\n        UFO.writeXMLobject(fi,font.outparams,font.ufodir, \"fontinfo.plist\" , True, fobject = True)\n\n    return",
  "def parseotnv(string) : # Returns maj, min and extrainfo\n    m = otnvre.match(string) # Assumes string has already been tested for a match\n    extrainfo = \"\" if m.group(3) is None else m.group(3)\n    return (m.group(1), m.group(2), extrainfo)",
  "def cmd() : execute(\"UFO\",doit, argspec)",
  "def cmd() :\n\n    deps = (  # (module, used by, min recommended version)\n        ('defcon', '?', ''),\n        ('fontbakery', '?', ''),\n        ('fontMath', '?', ''),\n        ('fontParts', '?', ''),\n        ('fontTools', '?', ''),\n        ('glyphConstruction', '?', ''),\n        ('glyphsLib', '?', ''),\n        ('lxml','?', ''),\n        ('lz4', '?', ''),\n        ('mutatorMath', '?', ''),\n        ('odf', '?', ''),\n        ('palaso', '?', ''),\n        ('tabulate', '?', ''),\n        ('ufo2ft', '?', ''),\n        ('ufoLib2', '?', ''),\n        )\n\n    # Pysilfont info\n    print(\"Pysilfont \" + silfont.__copyright__ + \"\\n\")\n    print(\"   Version:           \" + silfont.__version__)\n    print(\"   Commands in:       \" + sys.argv[0][:-10])\n    print(\"   Code running from: \" + silfont.__file__[:-12])\n    print(\"   using:             Python \" + sys.version.split(\" \\n\")[0] + \"\\n\")\n\n    for dep in deps:\n        name = dep[0]\n\n        try:\n            module = importlib.import_module(name)\n            path = module.__file__\n            # Remove .py file name from end\n            pyname = path.split(\"/\")[-1]\n            path = path[:-len(pyname)-1]\n            version = \"No version info\"\n            for attr in (\"__version__\", \"version\", \"VERSION\"):\n                if hasattr(module, attr):\n                    version = getattr(module, attr)\n                    break\n        except Exception as e:\n            etext = str(e)\n            if etext == \"No module named '\" + name + \"'\":\n                version = \"Module is not installed\"\n            else:\n                version = \"Module import failed with \" + etext\n            path = \"\"\n\n        print('{:20} {:15} {}'.format(name + \":\", version, path))\n\n    return",
  "class FontInfo:\n    def __init__(self):\n        self.filename = ''\n        self.name_table = dict()\n        self.weight_class = 0\n        self.regular = ''\n        self.bold = ''\n        self.italic = ''\n        self.width = ''\n        self.width_name = ''\n        self.width_class = 0\n        self.wws = ''\n\n    def sort_fullname(self):\n        return self.name_table[4]",
  "def doit(args):\n    logger = args.logger\n\n    font_infos = []\n    for pattern in args.font:\n        for fullpath in glob.glob(pattern):\n            logger.log(f'Processing {fullpath}', 'P')\n            try:\n                font = TTFont(fullpath)\n            except Exception as e:\n                logger.log(f'Error opening {fullpath}: {e}', 'E')\n                break\n\n            font_info = FontInfo()\n            font_info.filename = fullpath\n            get_names(font, font_info)\n            get_bits(font, font_info)\n            font_infos.append(font_info)\n\n    if not font_infos:\n        logger.log(\"No files match the filespec provided for fonts: \" + str(args.font), \"S\")\n\n    font_infos.sort(key=methodcaller('sort_fullname'))\n    font_infos.sort(key=attrgetter('width_class'), reverse=True)\n    font_infos.sort(key=attrgetter('weight_class'))\n\n    rows = list()\n    if args.multiline:\n        # Multi-line mode\n        for font_info in font_infos:\n            for line in multiline_names(font_info):\n                rows.append(line)\n            if args.bits:\n                for line in multiline_bits(font_info):\n                    rows.append(line)\n        align = ['left', 'right']\n        if len(font_infos) == 1:\n            del align[0]\n            for row in rows:\n                del row[0]\n        output = tabulate.tabulate(rows, tablefmt='plain', colalign=align)\n        output = output.replace(': ', ':')\n        output = output.replace('#', '')\n    else:\n        # Table mode\n\n        # Record information for headers\n        headers = table_headers(args.bits)\n\n        # Record information for each instance.\n        for font_info in font_infos:\n            record = table_records(font_info, args.bits)\n            rows.append(record)\n\n        # Not all fonts in a family with have the same name ids present,\n        # for instance 16: Typographic/Preferred family is only needed in\n        # non-RIBBI families, and even then only for the non-RIBBI instances.\n        # Also, not all the bit fields are present in each instance.\n        # Therefore, columns with no data in any instance are removed.\n        indices = list(range(len(headers)))\n        indices.reverse()\n        for index in indices:\n            empty = True\n            for row in rows:\n                data = row[index]\n                if data:\n                    empty = False\n            if empty:\n                for row in rows + [headers]:\n                    del row[index]\n\n        # Format 'pipe' is nicer for GitHub, but is wider on a command line\n        output = tabulate.tabulate(rows, headers, tablefmt='simple')\n\n    # Print output from either mode\n    if args.quiet:\n        print(output)\n    else:\n        logger.log('The following family-related values were found in the name, head, and OS/2 tables\\n' + output, 'P')",
  "def get_names(font, font_info):\n    table = font['name']\n    (platform_id, encoding_id, language_id) = WINDOWS_ENGLISH_IDS\n\n    for name_id in FAMILY_RELATED_IDS:\n        record = table.getName(\n            nameID=name_id,\n            platformID=platform_id,\n            platEncID=encoding_id,\n            langID=language_id\n        )\n        if record:\n            font_info.name_table[name_id] = str(record)",
  "def get_bits(font, font_info):\n    os2 = font['OS/2']\n    head = font['head']\n    font_info.weight_class = os2.usWeightClass\n    font_info.regular = bit2code(os2.fsSelection, 6, 'W-')\n    font_info.bold = bit2code(os2.fsSelection, 5, 'W')\n    font_info.bold += bit2code(head.macStyle, 0, 'M')\n    font_info.italic = bit2code(os2.fsSelection, 0, 'W')\n    font_info.italic += bit2code(head.macStyle, 1, 'M')\n    font_info.width_class = os2.usWidthClass\n    font_info.width = str(font_info.width_class)\n    if font_info.width_class == 5:\n        font_info.width_name = 'Width-Normal'\n    if font_info.width_class < 5:\n        font_info.width_name = 'Width-Condensed'\n        font_info.width += bit2code(head.macStyle, 5, 'M')\n    if font_info.width_class > 5:\n        font_info.width_name = 'Width-Extended'\n        font_info.width += bit2code(head.macStyle, 6, 'M')\n    font_info.wws = bit2code(os2.fsSelection, 8, '8')",
  "def bit2code(bit_field, bit, code_letter):\n    code = ''\n    if bit_field & 1 << bit:\n        code = code_letter\n    return code",
  "def multiline_names(font_info):\n    for name_id in sorted(font_info.name_table):\n        line = [font_info.filename + ':',\n                str(name_id) + ':',\n                FAMILY_RELATED_IDS[name_id] + ':',\n                font_info.name_table[name_id]\n                ]\n        yield line",
  "def multiline_bits(font_info):\n    labels = ('usWeightClass', 'Regular', 'Bold', 'Italic', font_info.width_name, 'WWS')\n    values = (font_info.weight_class, font_info.regular, font_info.bold, font_info.italic, font_info.width, font_info.wws)\n    for label, value in zip(labels, values):\n        if not value:\n            continue\n        line = [font_info.filename + ':',\n                '#',\n                str(label) + ':',\n                value\n                ]\n        yield line",
  "def table_headers(bits):\n    headers = ['filename']\n    for name_id in sorted(FAMILY_RELATED_IDS):\n        name_id_key = FAMILY_RELATED_IDS[name_id]\n        header = f'{name_id}: {name_id_key}'\n        if len(header) > 20:\n            header = header.replace(' ', '\\n')\n            header = header.replace('/', '\\n')\n        headers.append(header)\n    if bits:\n        headers.extend(['wght', 'R', 'B', 'I', 'wdth', 'WWS'])\n    return headers",
  "def table_records(font_info, bits):\n    record = [font_info.filename]\n    for name_id in sorted(FAMILY_RELATED_IDS):\n        name_id_value = font_info.name_table.get(name_id, '')\n        record.append(name_id_value)\n    if bits:\n        record.append(font_info.weight_class)\n        record.append(font_info.regular)\n        record.append(font_info.bold)\n        record.append(font_info.italic)\n        record.append(font_info.width)\n        record.append(font_info.wws)\n    return record",
  "def cmd(): execute('FT', doit, argspec)",
  "def __init__(self):\n        self.filename = ''\n        self.name_table = dict()\n        self.weight_class = 0\n        self.regular = ''\n        self.bold = ''\n        self.italic = ''\n        self.width = ''\n        self.width_name = ''\n        self.width_class = 0\n        self.wws = ''",
  "def sort_fullname(self):\n        return self.name_table[4]",
  "def doit(args):\n    logger = args.logger\n    if args.report: logger.loglevel = args.report\n    # infont = args.ifont\n    incsv = args.input\n    output = args.output\n\n    def csvWarning(msg, exception = None):\n        m = \"glyph_data warning: %s at line %d\" % (msg, incsv.line_num)\n        if exception is not None:\n            m += '; ' + exception.message\n        logger.log(m, 'W')\n\n    if args.fontcode is not None:\n        whichfont = args.fontcode.strip().lower()\n        if len(whichfont) != 1:\n            logger.log('-f parameter must be a single letter', 'S')\n    else:\n        whichfont = None\n\n    # Which headers represent APs to use:\n    apList = args.anchors.split(',')\n    if len(apList) == 0:\n        logger.log('--anchors option value \"%s\" is invalid' % args.anchors, 'S')\n\n    # Get headings from csvfile:\n    fl = incsv.firstline\n    if fl is None: logger.log(\"Empty input file\", \"S\")\n    # required columns:\n    try:\n        nameCol = fl.index(args.gname)\n        baseCol = fl.index(args.base)\n        apCols = [fl.index(ap) for ap in apList]\n        if args.usv is not None:\n            usvCol =  fl.index(args.usv)\n        else:\n            usvCol = None\n    except ValueError as e:\n        logger.log('Missing csv input field: ' + e.message, 'S')\n    except Exception as e:\n        logger.log('Error reading csv input field: ' + e.message, 'S')\n\n    # Now make strip AP names; pair up with columns so easy to iterate:\n    apInfo = list(zip(apCols, [x.strip() for x in apList]))\n\n    # If -f specified, make sure we have the fonts column\n    if whichfont is not None:\n        if 'fonts' not in fl: logger.log('-f requires \"fonts\" column in glyph_data', 'S')\n        fontsCol = fl.index('fonts')\n\n    # RE that matches names of glyphs we don't care about\n    namesToSkipRE = re.compile('^(?:[._].*|null|cr|nonmarkingreturn|tab|glyph_name)$',re.IGNORECASE)\n\n    # keep track of glyph names we've seen to detect duplicates\n    namesSeen = set()\n\n    # OK, process all records in glyph_data\n    for line in incsv:\n        base = line[baseCol].strip()\n        if len(base) == 0:\n            # No composites specified\n            continue\n\n        gname = line[nameCol].strip()\n        # things to ignore:\n        if namesToSkipRE.match(gname): continue\n        if whichfont is not None and line[fontsCol] != '*' and line[fontsCol].lower().find(whichfont) < 0:\n            continue\n\n        if len(gname) == 0:\n            csvWarning('empty glyph name in glyph_data; ignored')\n            continue\n        if gname.startswith('#'): continue\n        if gname in namesSeen:\n            csvWarning('glyph name %s previously seen in glyph_data; ignored' % gname)\n            continue\n        namesSeen.add(gname)\n\n        # Ok, start building the composite\n        composite = '%s = %s' %(gname, base)\n\n        # The first component must *not* reference the base; all others *must*:\n        seenfirst = False\n        for apCol, apName in apInfo:\n            component = line[apCol].strip()\n            if len(component):\n                if not seenfirst:\n                    composite += ' + %s@%s' % (component, apName)\n                    seenfirst = True\n                else:\n                    composite += ' + %s@%s:%s' % (component, base, apName)\n\n        # Add USV if present\n        if usvCol is not None:\n            usv = line[usvCol].strip()\n            if len(usv):\n                composite += ' | %s' % usv\n\n        # Output this one\n        output.write(composite + '\\n')\n\n    output.close()",
  "def cmd() : execute(\"\",doit,argspec)",
  "def csvWarning(msg, exception = None):\n        m = \"glyph_data warning: %s at line %d\" % (msg, incsv.line_num)\n        if exception is not None:\n            m += '; ' + exception.message\n        logger.log(m, 'W')",
  "def doit(args):\n    global version\n    v = version.split(\".\")\n    version = f'{v[0]}.{v[1]}.{v[2]}' # Set version to just the number part - ie without .dev...\n\n    logger = args.logger\n    htmlfile = args.html\n\n    if args.ttfaudit: # Special action to compare checks in profile against check_list values\n        audit(args.fonts, logger) # args.fonts used as output file name for audit\n        return\n\n    if args.csv:\n        try:\n            csvfile = open(args.csv, 'w')\n            csvwriter = csv.writer(csvfile)\n            csvlines = []\n        except Exception as e:\n            logger.log(\"Failed to open \" + args.csv + \": \" + str(e), \"S\")\n    else:\n        csvfile = None\n\n    # Process list of fonts supplied, expanding wildcards using glob if needed\n    fonts = []\n    fontstype = None\n    for pattern in args.fonts:\n        for fullpath in glob.glob(pattern):\n            ftype = fullpath.lower().rsplit(\".\", 1)[-1]\n            if ftype == \"otf\": ftype = \"ttf\"\n            if ftype not in (\"ttf\", \"ufo\"):\n                logger.log(\"Fonts must be OpenType or UFO - \" + fullpath + \" invalid\", \"S\")\n            if fontstype is None:\n                fontstype = ftype\n            else:\n                if ftype != fontstype:\n                    logger.log(\"All fonts must be of the same type - both UFO and ttf/otf fonts supplied\", \"S\")\n            fonts.append(fullpath)\n\n    if fonts == [] : logger.log(\"No files match the filespec provided for fonts: \" + str(args.fonts), \"S\")\n\n    # Find the main folder name for ttf files - strips \"results\" if present\n    (path, ttfdir) = os.path.split(os.path.dirname(fonts[0]))\n    if ttfdir == (\"results\"): ttfdir = os.path.basename(path)\n\n    # Create the profile object\n    if args.profile:\n        proname = args.profile\n    else:\n        if fontstype == \"ttf\":\n            proname = \"silfont.fbtests.ttfchecks\"\n        else:\n            logger.log(\"UFO fonts not yet supported\", \"S\")\n\n    try:\n        module = get_module(proname)\n    except Exception as e:\n        logger.log(\"Failed to import profile: \" + proname + \"\\n\" + str(e), \"S\")\n\n    profile = get_module_profile(module)\n    profile.configuration_defaults = {\n        \"com.google.fonts/check/file_size\": {\n            \"WARN_SIZE\": 1 * 1024 * 1024,\n            \"FAIL_SIZE\": 9 * 1024 * 1024\n        }\n    }\n\n    psfcheck_list = module.psfcheck_list\n\n    # Create the runner and reporter objects, then run the tests\n    configuration = Configuration(full_lists = args.full_lists)\n    runner = CheckRunner(profile, values={\n        \"fonts\": fonts, 'ufos': [], 'designspaces': [], 'glyphs_files': [], 'readme_md': [], 'metadata_pb': []}\n                         , config=configuration)\n\n    if version == \"0.8.6\":\n        sr = SerializeReporter(runner=runner) # This produces results from all the tests in sr.getdoc for later analysis\n    else:\n        sr = SerializeReporter(runner=runner, loglevels = [INFO]) # loglevels was added with 0.8.7\n    reporters = [sr.receive]\n\n    if htmlfile:\n        hr = HTMLReporter(runner=runner, loglevels = [SKIP])\n        reporters.append(hr.receive)\n\n    distribute_generator(runner.run(), reporters)\n\n    # Process the results\n    results = sr.getdoc()\n    sections = results[\"sections\"]\n\n    checks = {}\n    maxname = 11\n    somedebug = False\n    overrides = {}\n    tempoverrides = False\n\n    for section in sections:\n        secchecks = section[\"checks\"]\n        for check in secchecks:\n            checkid = check[\"key\"][1][17:-1]\n            fontfile = check[\"filename\"] if \"filename\" in check else \"Family-wide\"\n            path, fontname = os.path.split(fontfile)\n            if fontname not in checks:\n                checks[fontname] = {\"ERROR\": [], \"FAIL\": [], \"WARN\": [], \"INFO\": [], \"SKIP\": [], \"PASS\": [], \"DEBUG\": []}\n                if len(fontname) > maxname: maxname = len(fontname)\n            status = check[\"result\"]\n            if checkid in psfcheck_list:\n                # Look for status overrides\n                (changetype, temp) = (\"temp_change_status\", True) if \"temp_change_status\" in psfcheck_list[checkid]\\\n                    else (\"change_status\", False)\n                if changetype in psfcheck_list[checkid]:\n                    change_status = psfcheck_list[checkid][changetype]\n                    if status in change_status:\n                        reason = change_status[\"reason\"] if \"reason\" in change_status else None\n                        overrides[fontname + \", \" + checkid] = (status + \" to \" + change_status[status], temp, reason)\n                        if temp: tempoverrides = True\n                        status = change_status[status] ## Should validate new status is one of FAIL, WARN or PASS\n            checks[fontname][status].append(check)\n            if status == \"DEBUG\": somedebug = True\n\n    if htmlfile:\n        logger.log(\"Writing results to \" + htmlfile, \"P\")\n        with open(htmlfile, 'w') as hfile:\n            hfile.write(hr.get_html())\n\n    fbstats   = [\"ERROR\", \"FAIL\", \"WARN\", \"INFO\", \"SKIP\", \"PASS\"]\n    psflevels = [\"E\",     \"E\",    \"W\",    \"I\",    \"I\",    \"V\"]\n    if somedebug: # Only have debug column if some debug statuses are present\n        fbstats.append(\"DEBUG\")\n        psflevels.append(\"W\")\n    wrapper = TextWrapper(width=120, initial_indent=\"   \", subsequent_indent=\"   \")\n    errorcnt = 0\n    failcnt = 0\n    summarymess = \"Check status summary:\\n\"\n    summarymess += \"{:{pad}}ERROR  FAIL  WARN  INFO  SKIP  PASS\".format(\"\", pad=maxname+4)\n    if somedebug: summarymess += \"  DEBUG\"\n    fontlist = list(sorted(x for x in checks if x != \"Family-wide\")) # Alphabetic list of fonts\n    if \"Family-wide\" in checks: fontlist.append(\"Family-wide\") # Add Family-wide last\n    for fontname in fontlist:\n        summarymess += \"\\n  {:{pad}}\".format(fontname, pad=maxname)\n        for i, status in enumerate(fbstats):\n            psflevel = psflevels[i]\n            checklist = checks[fontname][status]\n            cnt = len(checklist)\n            if cnt > 0 or status != \"DEBUG\": summarymess += \"{:6d}\".format(cnt) # Suppress 0 for DEBUG\n            if cnt:\n                if status == \"ERROR\": errorcnt += cnt\n                if status == \"FAIL\": failcnt += cnt\n                messparts = [\"Checks with status {} for {}\".format(status, fontname)]\n                for check in checklist:\n                    checkid = check[\"key\"][1][17:-1]\n                    csvline = [ttfdir, fontname, check[\"key\"][1][17:-1], status, check[\"description\"]]\n                    messparts.append(\" > {}\".format(checkid))\n                    for record in check[\"logs\"]:\n                        message = record[\"message\"]\n                        if record[\"status\"] != status: message = record[\"status\"] + \" \" + message\n                        messparts += wrapper.wrap(message)\n                        csvline.append(message)\n                    if csvfile: csvlines.append(csvline)\n                logger.log(\"\\n\".join(messparts) , psflevel)\n    if csvfile: # Output to csv file, worted by font then checkID\n        for line in sorted(csvlines, key = lambda x: (x[1],x[2])): csvwriter.writerow(line)\n    if overrides != {}:\n        summarymess += \"\\n  Note: \" + str(len(overrides)) + \" Fontbakery statuses were overridden - see log file for details\"\n        if tempoverrides: summarymess += \"\\n        ******** Some of the overrides were temporary overrides ********\"\n    logger.log(summarymess, \"P\")\n\n    if overrides != {}:\n        for oname in overrides:\n            override = overrides[oname]\n            mess = \"Status override for \" + oname + \": \" + override[0]\n            if override[1]: mess += \" (Temporary override)\"\n            logger.log(mess, \"W\")\n            if override[2] is not None: logger.log(\"Override reason: \" + override[2], \"I\")\n\n    if errorcnt + failcnt > 0:\n        mess = str(failcnt) + \" test(s) gave a status of FAIL\" if failcnt > 0 else \"\"\n        if errorcnt > 0:\n            if failcnt > 0: mess += \"\\n                              \"\n            mess += str(errorcnt) + \" test(s) gave a status of ERROR which means they failed to execute properly.\" \\\n                                    \"\\n                              \" \\\n                                    \"   ERROR probably indicates a software issue rather than font issue\"\n        logger.log(mess, \"E\")",
  "def audit(fonts, logger):\n    if len(fonts) != 1: logger.log(\"For audit, specify output csv file instead of list of fonts\", \"S\")\n    csvname = fonts[0]\n    from silfont.fbtests.ttfchecks import all_checks_dict\n    missingfromprofile=[]\n    missingfromchecklist=[]\n    checks = all_checks_dict()\n    logger.log(\"Opening \" + csvname + \" for audit output csv\", \"P\")\n    with open(csvname, 'w', newline='') as csvfile:\n        csvwriter = csv.writer(csvfile, dialect='excel')\n        fields = [\"id\", \"psfaction\", \"section\", \"description\", \"rationale\", \"conditions\"]\n        csvwriter.writerow(fields)\n\n        for checkid in checks:\n            check = checks[checkid]\n            row = [checkid]\n            for field in fields:\n                if field != \"id\": row.append(check[field])\n            if check[\"section\"] == \"Missing\": missingfromprofile.append(checkid)\n            if check[\"psfaction\"] == \"Not in psfcheck_list\": missingfromchecklist.append(checkid)\n            csvwriter.writerow(row)\n    if missingfromprofile != []:\n        mess = \"The following checks are in psfcheck_list but not in the ttfchecks.py profile:\"\n        for checkid in missingfromprofile: mess += \"\\n                                \" + checkid\n        logger.log(mess, \"E\")\n    if missingfromchecklist != []:\n        mess = \"The following checks are in the ttfchecks.py profile but not in psfcheck_list:\"\n        for checkid in missingfromchecklist: mess += \"\\n                                \" + checkid\n        logger.log(mess, \"E\")\n\n    return",
  "def cmd(): execute(None, doit, argspec)",
  "def doit(args) :\n\n    font = args.ifont\n    logger = args.logger\n\n    advances_removed = 0\n    unicodes_removed = 0\n    for layer in font.layers:\n        if layer.layername == \"public.background\":\n            for g in layer:\n                glyph = layer[g]\n                # Remove advance and unicode fields from background layer\n                # (FF currently copies some from default layer)\n                if \"advance\" in glyph:\n                    glyph.remove(\"advance\")\n                    advances_removed += 1\n                    logger.log(\"Removed <advance> from \" + g, \"I\")\n                uc = glyph[\"unicode\"]\n                if uc != []:\n                    while glyph[\"unicode\"] != []: glyph.remove(\"unicode\",0)\n                    unicodes_removed += 1\n                    logger.log(\"Removed unicode value(s) from \" + g, \"I\")\n\n    if advances_removed + unicodes_removed > 0 :\n        logger.log(\"Advance removed from \" + str(advances_removed) + \" glyphs and unicode values(s) removed from \"\n                   + str(unicodes_removed) + \" glyphs\", \"P\")\n    else:\n        logger.log(\"No advances or unicodes removed from glyphs\", \"P\")\n\n    return args.ifont",
  "def cmd() : execute(\"UFO\",doit, argspec)",
  "def doit(args) :\n    font = args.ifont\n    incsv = args.input\n    logger = args.logger\n    deflayer = font.deflayer\n\n    # Create mappings to find glyph name from decimal usv:\n    dusv2gname = {int(ucode.hex, 16): gname for gname in deflayer for ucode in deflayer[gname]['unicode']}\n\n    # check for headers in the csv\n    fl = incsv.firstline\n    if fl is None: logger.log(\"Empty input file\", \"S\")\n    numfields = len(fl)\n    if numfields == 1 and args.header not in fl:\n        dataCol = 0       # Default for plain csv\n    elif numfields >= 1:  # Must have headers\n        try:\n            dataCol = fl.index(args.header)\n        except ValueError as e:\n            logger.log(f'Missing csv header field: {e}', 'S')\n        except Exception as e:\n            logger.log(f'Error reading csv header field: {e}', 'S')\n        if args.filter:\n            try:\n                filterCol = fl.index(args.filter)\n            except ValueError as e:\n                logger.log(f'Missing csv filter field: {e}', 'S')\n            except Exception as e:\n                logger.log(f'Error reading csv filter field: {e}', 'S')\n        next(incsv.reader, None)  # Skip first line with headers in\n    else:\n        logger.log(\"Invalid csv file\", \"S\")\n\n    # From the csv, assemble a list of glyphs to process:\n    toProcess = set()\n    usvRE = re.compile('[0-9a-f]{4,6}$',re.IGNORECASE)   # matches 4-6 digit hex\n    for r in incsv:\n        if args.filter:\n            filterstatus = r[filterCol].strip()\n            if filterstatus != \"Y\":\n                continue\n        gname = r[dataCol].strip()\n        if usvRE.match(gname):\n            # data is USV, not glyph name\n            dusv = int(gname,16)\n            if dusv in dusv2gname:\n                toProcess.add(dusv2gname[dusv])\n                continue\n            # The USV wasn't in the font... try it as a glyph name\n        if gname not in deflayer:\n            logger.log(\"Glyph '%s' not in font; line %d ignored\" % (gname, incsv.line_num), 'W')\n            continue\n        toProcess.add(gname)\n\n    # Generate a complete list of glyphs to keep:\n    toKeep = set()\n    while len(toProcess):\n        gname = toProcess.pop()   # retrieves a random item from the set\n        if gname in toKeep:\n            continue    # Already processed this one\n        toKeep.add(gname)\n        \n        # If it has any components we haven't already processed, add them to the toProcess list\n        for component in deflayer[gname].etree.findall('./outline/component[@base]'):\n            cname = component.get('base')\n            if cname not in toKeep:\n                toProcess.add(cname)\n\n    # Generate a complete list of glyphs to delete:\n    toDelete = set(deflayer).difference(toKeep)\n\n    # Remove any glyphs not in the toKeep set\n    for gname in toDelete:\n        logger.log(\"Deleting \" + gname, \"V\")\n        deflayer.delGlyph(gname)\n    assert len(deflayer) == len(toKeep), \"len(deflayer) != len(toKeep)\"\n    logger.log(\"Retained %d glyphs, deleted %d glyphs.\" % (len(toKeep), len(toDelete)), \"P\")\n\n    # Clean up and rebuild sort orders\n    libexists = True if \"lib\" in font.__dict__ else False\n    for orderName in ('public.glyphOrder', 'com.schriftgestaltung.glyphOrder'):\n        if libexists and orderName in font.lib:\n            glyphOrder = font.lib.getval(orderName)  # This is an array\n            array = ET.Element(\"array\")\n            for gname in glyphOrder:\n                if gname in toKeep:\n                    ET.SubElement(array, \"string\").text = gname\n            font.lib.setelem(orderName, array)\n\n    # Clean up and rebuild psnames\n    if libexists and 'public.postscriptNames' in font.lib:\n        psnames = font.lib.getval('public.postscriptNames')  # This is a dict keyed by glyphnames\n        dict = ET.Element(\"dict\")\n        for gname in psnames:\n            if gname in toKeep:\n                ET.SubElement(dict, \"key\").text = gname\n                ET.SubElement(dict, \"string\").text = psnames[gname]\n        font.lib.setelem(\"public.postscriptNames\", dict)\n\n    return font",
  "def cmd() : execute(\"UFO\",doit,argspec)",
  "def doit(args) :\n    logfile = args.logger\n    if args.report: logfile.loglevel = args.report\n    infont = args.ifont\n    prefix = \"U+\" if args.Uprefix else \"\"\n\n    if hasattr(infont, 'lib') and 'public.glyphOrder' in infont.lib:\n        glyphorderlist = [s.text for s in infont.lib['public.glyphOrder'][1].findall('string')]\n    else:\n        glyphorderlist = []\n        if args.gid:\n            logfile.log(\"public.glyphOrder is absent; ignoring --gid option\", \"E\")\n            args.gid = False\n    glyphorderset = set(glyphorderlist)\n    if len(glyphorderlist) != len(glyphorderset):\n        logfile.log(\"At least one duplicate name in public.glyphOrder\", \"W\")\n        # count of duplicate names is len(glyphorderlist) - len(glyphorderset)\n    actualglyphlist = [g for g in infont.deflayer.keys()]\n    actualglyphset = set(actualglyphlist)\n    listorder = []\n    gid = 0\n    for g in glyphorderlist:\n        if g in actualglyphset:\n            listorder.append( (g, gid) )\n            gid += 1\n            actualglyphset.remove(g)\n            glyphorderset.remove(g)\n        else:\n            logfile.log(g + \" in public.glyphOrder list but absent from UFO\", \"W\")\n    if args.sort: listorder.sort()\n    for g in sorted(actualglyphset):    # if any glyphs remaining\n        listorder.append( (g, None) )\n        logfile.log(g + \" in UFO but not in public.glyphOrder list\", \"W\")\n\n    if 'postscriptFontName' in infont.fontinfo:\n        postscriptFontName = infont.fontinfo['postscriptFontName'][1].text\n    else:\n        if 'styleMapFamilyName' in infont.fontinfo:\n            family = infont.fontinfo['styleMapFamilyName'][1].text\n        elif 'familyName' in infont.fontinfo:\n            family = infont.fontinfo['familyName'][1].text\n        else:\n            family = \"UnknownFamily\"\n        if 'styleMapStyleName' in infont.fontinfo:\n            style = infont.fontinfo['styleMapStyleName'][1].text.capitalize()\n        elif 'styleName' in infont.fontinfo:\n            style = infont.fontinfo['styleName'][1].text\n        else:\n            style = \"UnknownStyle\"\n\n        postscriptFontName = '-'.join((family,style)).replace(' ','')\n    fontElement= ET.Element('font', upem=infont.fontinfo['unitsPerEm'][1].text, name=postscriptFontName)\n    for g, i in listorder:\n        attrib = {'PSName': g}\n        if args.gid and i != None: attrib['GID'] = str(i)\n        u = infont.deflayer[g]['unicode']\n        if len(u)>0: attrib['UID'] = prefix + u[0].element.get('hex')\n        glyphElement = ET.SubElement(fontElement, 'glyph', attrib)\n        anchorlist = []\n        for a in infont.deflayer[g]['anchor']:\n            anchorlist.append( (a.element.get('name'), int(float(a.element.get('x'))), int(float(a.element.get('y'))) ) )\n        anchorlist.sort()\n        for a, x, y in anchorlist:\n            anchorElement = ET.SubElement(glyphElement, 'point', attrib = {'type': a})\n            locationElement = ET.SubElement(anchorElement, 'location', attrib = {'x': str(x), 'y': str(y)})\n\n#   instead of simple serialization with: ofile.write(ET.tostring(fontElement))\n#   create ETWriter object and specify indentation and attribute order to get normalized output\n    ofile = args.output\n    indentFirst = args.params.get('indentFirst', \"\")\n    indentIncr = args.params.get('indentIncr', \"  \")\n    attOrder = args.params.get('attOrder', \"name,upem,PSName,GID,UID,type,x,y\")\n    x = attOrder.split(',')\n    attributeOrder = dict(zip(x,range(len(x))))\n    etwobj=ETWriter(fontElement, indentFirst=indentFirst, indentIncr=indentIncr, attributeOrder=attributeOrder)\n    ofile.write(etwobj.serialize_xml())",
  "def cmd() : execute(\"UFO\",doit,argspec)",
  "def doit(args) :\n    standardstyles = [\"Regular\", \"Italic\", \"Bold\", \"BoldItalic\"]\n    finfoignore = [\"openTypeHeadCreated\", \"openTypeOS2Panose\", \"postscriptBlueScale\", \"postscriptBlueShift\",\n                   \"postscriptBlueValues\", \"postscriptOtherBlues\", \"postscriptStemSnapH\", \"postscriptStemSnapV\", \"postscriptForceBold\"]\n    libfields = [\"public.postscriptNames\", \"public.glyphOrder\", \"com.schriftgestaltung.glyphOrder\"]\n\n    font = args.ifont\n    logger = args.logger\n    singlefont = args.single\n    mfont = args.master\n    newfile = \"_new\" if args.new else \"\"\n    reportonly = args.reportonly\n    updatemessage = \" to be updated: \" if reportonly else \" updated: \"\n    params = args.paramsobj\n    precision = font.paramset[\"precision\"]\n\n    # Increase screen logging level to W unless specific level supplied on command-line\n    if not(args.quiet or \"scrlevel\" in params.sets[\"command line\"]) : logger.scrlevel = \"W\"\n\n    # Process UFO name\n    (path,base) = os.path.split(font.ufodir)\n    (base,ext) = os.path.splitext(base)\n    if '-' not in base : logger.log(\"Non-standard UFO name - must be <family>-<style>\", \"S\")\n    (family,style) = base.split('-')\n\n    styles = [style]\n    fonts = {}\n    fonts[style] = font\n\n    # Process single and master settings\n    if singlefont :\n        if mfont :\n            mastertext = \"Master\" # Used in log messages\n        else : # Check against Regular font from same family\n            mfont = openfont(params, path, family, \"Regular\")\n            if mfont is None : logger.log(\"No regular font to check against - use -m to specify master font\", \"S\")\n            mastertext = \"Regular\"\n            fonts[\"Regular\"] =mfont\n    else : # Supplied font must be Regular\n        if mfont : logger.log(\"-m --master must only be used with -s --single\", \"S\")\n        if style != \"Regular\" : logger.log(\"Must specify a Regular font unless -s is used\", \"S\")\n        mastertext = \"Regular\"\n        mfont = font\n\n    # Check for required fields in master font\n    mfinfo = mfont.fontinfo\n    if \"familyName\" in mfinfo :\n        spacedfamily = mfinfo[\"familyName\"][1].text\n    else:\n        logger.log(\"No familyName field in \" + mastertext, \"S\")\n    if \"openTypeNameManufacturer\" in mfinfo :\n        manufacturer = mfinfo[\"openTypeNameManufacturer\"][1].text\n    else:\n        logger.log(\"No openTypeNameManufacturer field in \" + mastertext, \"S\")\n    mlib = mfont.lib\n\n    # Open the remaining fonts in the family\n    if not singlefont :\n        for style in standardstyles :\n            if not style in fonts :\n                fonts[style] = openfont(params, path, family, style) # Will return None if font does not exist\n                if fonts[style] is not None : styles.append(style)\n\n    # Process fonts\n    psuniqueidlist = []\n    fieldscopied = False\n    for style in styles :\n        font = fonts[style]\n        if font.UFOversion != \"2\" : logger.log(\"This script only works with UFO 2 format fonts\",\"S\")\n\n        fontname = family + \"-\" + style\n        spacedstyle = \"Bold Italic\" if style == \"BoldItalic\" else style\n        spacedname = spacedfamily + \" \" + spacedstyle\n        logger.log(\"************ Processing \" + fontname, \"P\")\n\n        ital = True if \"Italic\" in style else False\n        bold = True if \"Bold\" in style else False\n\n        # Process fontinfo.plist\n        finfo=font.fontinfo\n        fieldlist = list(set(finfo) | set(mfinfo)) # Need all fields from both to detect missing fields\n        fchanged = False\n\n        for field in fieldlist:\n            action = None; issue = \"\"; newval = \"\"\n            if field in finfo :\n                elem = finfo[field][1]\n                tag = elem.tag\n                text = elem.text\n                if text is None : text = \"\"\n                if tag == \"real\" : text = processnum(text,precision)\n            # Field-specific actions\n\n            if field not in finfo :\n                if field not in finfoignore : action = \"Copyfield\"\n            elif field == \"italicAngle\" :\n                if ital and text == \"0\" :\n                    issue = \"is zero\"\n                    action = \"Warn\"\n                if not ital and text != \"0\" :\n                    issue = \"is non-zero\"\n                    newval = 0\n                    action = \"Update\"\n            elif field == \"openTypeNameUniqueID\" :\n                newval = manufacturer + \": \" + spacedname + \": \" + datetime.now().strftime(\"%Y\")\n                if text != newval :\n                    issue = \"Incorrect value\"\n                    action = \"Update\"\n            elif field == \"openTypeOS2WeightClass\" :\n                if bold and text != \"700\" :\n                    issue = \"is not 700\"\n                    newval = 700\n                    action = \"Update\"\n                if not bold and text != \"400\" :\n                    issue = \"is not 400\"\n                    newval = 400\n                    action = \"Update\"\n            elif field == \"postscriptFontName\" :\n                if text != fontname :\n                    newval = fontname\n                    issue = \"Incorrect value\"\n                    action = \"Update\"\n            elif field == \"postscriptFullName\" :\n                if text != spacedname :\n                    newval = spacedname\n                    issue = \"Incorrect value\"\n                    action = \"Update\"\n            elif field == \"postscriptUniqueID\" :\n                if text in psuniqueidlist :\n                    issue = \"has same value as another font: \" + text\n                    action = \"Warn\"\n                else :\n                    psuniqueidlist.append(text)\n            elif field == \"postscriptWeightName\" :\n                newval = 'bold' if bold else 'regular'\n                if text != newval :\n                    issue = \"Incorrect value\"\n                    action = 'Update'\n            elif field == \"styleMapStyleName\" :\n                if text != spacedstyle.lower() :\n                    newval = spacedstyle.lower()\n                    issue = \"Incorrect value\"\n                    action = \"Update\"\n            elif field in (\"styleName\", \"openTypeNamePreferredSubfamilyName\") :\n                if text != spacedstyle :\n                    newval = spacedstyle\n                    issue = \"Incorrect value\"\n                    action = \"Update\"\n            elif field in finfoignore :\n                action = \"Ignore\"\n            # Warn for fields in this font but not master\n            elif field not in mfinfo :\n                issue = \"is in \" + spacedstyle + \" but not in \" + mastertext\n                action = \"Warn\"\n            # for all other fields, sync values from master\n            else :\n                melem = mfinfo[field][1]\n                mtag = melem.tag\n                mtext = melem.text\n                if mtext is None : mtext = \"\"\n                if mtag == 'real' : mtext = processnum(mtext,precision)\n                if tag in (\"real\", \"integer\", \"string\") :\n                    if mtext != text :\n                        issue = \"does not match \" + mastertext + \" value\"\n                        newval = mtext\n                        action = \"Update\"\n                elif tag in (\"true, false\") :\n                    if tag != mtag :\n                        issue = \"does not match \" + mastertext + \" value\"\n                        action = \"FlipBoolean\"\n                elif tag == \"array\" : # Assume simple array with just values to compare\n                    marray = mfinfo.getval(field)\n                    array = finfo.getval(field)\n                    if array != marray: action = \"CopyArray\"\n                else : logger.log(\"Non-standard fontinfo field type in \" + fontname, \"X\")\n\n            # Now process the actions, create log messages etc\n            if action is None or action == \"Ignore\" :\n                pass\n            elif action == \"Warn\" :\n                logger.log(field + \" needs manual correction: \" + issue, \"W\")\n            elif action == \"Error\" :\n                logger.log(field + \" needs manual correction: \" + issue, \"E\")\n            elif action in (\"Update\", \"FlipBoolean\", \"Copyfield\", \"CopyArray\") : # Updating actions\n                fchanged = True\n                message = field + updatemessage\n                if action == \"Update\" :\n                    message = message + issue + \" Old: '\" + text + \"' New: '\" + str(newval) + \"'\"\n                    elem.text = newval\n                elif action == \"FlipBoolean\" :\n                    newval = \"true\" if tag == \"false\" else \"false\"\n                    message = message + issue + \" Old: '\" + tag + \"' New: '\" + newval + \"'\"\n                    finfo.setelem(field, ET.fromstring(\"<\" + newval + \"/>\"))\n                elif action == \"Copyfield\" :\n                    message = message + \"is missing so will be copied from \" + mastertext\n                    fieldscopied = True\n                    finfo.addelem(field, ET.fromstring(ET.tostring(mfinfo[field][1])))\n                elif action == \"CopyArray\" :\n                    message = message + \"Some values different Old: \" + str(array) + \" New: \" + str(marray)\n                    finfo.setelem(field, ET.fromstring(ET.tostring(melem)))\n                logger.log(message, \"W\")\n            else:\n                logger.log(\"Uncoded action: \" + action + \" - oops\", \"X\")\n\n        # Process lib.plist - currently just public.postscriptNames and glyph order fields which are all simple dicts or arrays\n        lib = font.lib\n        lchanged = False\n\n        for field in libfields:\n            # Check the values\n            action = None; issue = \"\"; newval = \"\"\n            if field in mlib:\n                if field in lib:\n                    if lib.getval(field) != mlib.getval(field):  # will only work for arrays or dicts with simple values\n                        action = \"Updatefield\"\n                else:\n                    action = \"Copyfield\"\n            else:\n                action = \"Error\" if field == (\"public.GlyphOrder\", \"public.postscriptNames\") else \"Warn\"\n                issue = field + \" not in \" + mastertext + \" lib.plist\"\n\n            # Process the actions, create log messages etc\n            if action is None or action == \"Ignore\":\n                pass\n            elif action == \"Warn\":\n                logger.log(field + \" needs manual correction: \" + issue, \"W\")\n            elif action == \"Error\":\n                logger.log(field + \" needs manual correction: \" + issue, \"E\")\n            elif action in (\"Updatefield\", \"Copyfield\"):  # Updating actions\n                lchanged = True\n                message = field + updatemessage\n                if action == \"Copyfield\":\n                    message = message + \"is missing so will be copied from \" + mastertext\n                    lib.addelem(field, ET.fromstring(ET.tostring(mlib[field][1])))\n                elif action == \"Updatefield\":\n                    message = message + \"Some values different\"\n                    lib.setelem(field, ET.fromstring(ET.tostring(mlib[field][1])))\n                logger.log(message, \"W\")\n            else:\n                logger.log(\"Uncoded action: \" + action + \" - oops\", \"X\")\n\n        # Now update on disk\n        if not reportonly:\n            if args.normalize:\n                font.write(os.path.join(path, family + \"-\" + style + newfile + \".ufo\"))\n            else:  # Just update fontinfo and lib\n                if fchanged:\n                    filen = \"fontinfo\" + newfile + \".plist\"\n                    logger.log(\"Writing updated fontinfo to \" + filen, \"P\")\n                    exists = True if os.path.isfile(os.path.join(font.ufodir, filen)) else False\n                    UFO.writeXMLobject(finfo, font.outparams, font.ufodir, filen, exists, fobject=True)\n                if lchanged:\n                    filen = \"lib\" + newfile + \".plist\"\n                    logger.log(\"Writing updated lib.plist to \" + filen, \"P\")\n                    exists = True if os.path.isfile(os.path.join(font.ufodir, filen)) else False\n                    UFO.writeXMLobject(lib, font.outparams, font.ufodir, filen, exists, fobject=True)\n\n    if fieldscopied :\n        message = \"After updating, UFOsyncMeta will need to be re-run to validate these fields\" if reportonly else \"Re-run UFOsyncMeta to validate these fields\"\n        logger.log(\"*** Some fields were missing and so copied from \" + mastertext + \". \" + message, \"P\")\n\n    return",
  "def openfont(params, path, family, style) : # Only try if directory exists\n    ufodir = os.path.join(path,family+\"-\"+style+\".ufo\")\n    font = UFO.Ufont(ufodir, params=params) if os.path.isdir(ufodir) else None\n    return font",
  "def processnum(text, precision) : # Apply same processing to numbers that normalization will\n    if precision is not None:\n        val = round(float(text), precision)\n        if val == int(val) : val = int(val) # Removed trailing decimal .0\n        text = str(val)\n    return text",
  "def cmd() : execute(\"UFO\",doit, argspec)",
  "def doit(args):\n    global glyphlist\n    infont = args.ifont\n    logger = args.logger\n    params = infont.outparams\n\n    removeRE = re.compile(args.remove) if args.remove else None\n    preserveRE = re.compile(args.preserve) if args.preserve else None\n\n    colors = None\n    if args.color or args.colors:\n        colors = args.colors if args.colors else \"g_blue,g_purple\"\n        colors = parsecolors(colors, allowspecial=True)\n        invalid = False\n        for color in colors:\n            if color[0] is None:\n                invalid = True\n                logger.log(color[2], \"E\")\n        if len(colors) > 3:\n            logger.log(\"A maximum of three colors can be supplied: \" + str(len(colors)) + \" supplied\", \"E\")\n            invalid = True\n        if invalid: logger.log(\"Re-run with valid colors\", \"S\")\n        if len(colors) == 1: colors.append(colors[0])\n        if len(colors) == 2: colors.append(colors[1])\n        logstatuses = (\"Glyph unchanged\", \"Glyph changed\", \"New glyph\")\n\n    ### temp section (these may someday be passed as optional parameters)\n    RemoveUsedAnchors = True\n    ### end of temp section\n\n    cgobj = CompGlyph()\n\n    for linenum, rawCDline in enumerate(args.cdfile):\n        CDline=rawCDline.strip()\n        if len(CDline) == 0 or CDline[0] == \"#\": continue\n        logger.log(\"Processing line \" + str(linenum+1) + \": \" + CDline,\"I\")\n        cgobj.CDline=CDline\n        try:\n            cgobj.parsefromCDline()\n        except ValueError as mess:\n            logger.log(\"Parsing error: \" + str(mess), \"E\")\n            continue\n        g = cgobj.CDelement\n\n        # Collect target glyph information and construct list of component glyphs\n        targetglyphname = g.get(\"PSName\")\n        targetglyphunicode = g.get(\"UID\")\n        glyphlist = []\t# list of component glyphs\n        lsb = rsb = 0\n        adv = None\n        for e in g:\n            if e.tag == 'note': pass\n            elif e.tag == 'property': pass\t# ignore mark info\n            elif e.tag == 'lsb': lsb = int(e.get('width'))\n            elif e.tag == 'rsb': rsb = int(e.get('width'))\n            elif e.tag == 'advance': adv = int(e.get('width'))\n            elif e.tag == 'base':\n                addtolist(e,None)\n        logger.log(str(glyphlist),\"V\")\n\n        # find each component glyph and compute x,y position\n        xadvance = lsb\n        componentlist = []\n        targetglyphanchors = {} # dictionary of {name: (xOffset,yOffset)}\n        for currglyph, prevglyph, baseAP, diacAP, shiftx, shifty in glyphlist:\n            # get current glyph and its anchor names from font\n            if currglyph not in infont.deflayer:\n                logger.log(currglyph + \" not found in font\", \"E\")\n                continue\n            cg = infont.deflayer[currglyph]\n            cganc = [x.element.get('name') for x in cg['anchor']]\n            diacAPx = diacAPy = 0\n            baseAPx = baseAPy = 0\n            if prevglyph is None:   # this is new 'base'\n                xOffset = xadvance\n                yOffset = 0\n                # Find advance width of currglyph and add to xadvance\n                if 'advance' in cg:\n                    cgadvance = cg['advance']\n                    if cgadvance is not None and cgadvance.element.get('width') is not None:\n                        xadvance += int(float(cgadvance.element.get('width')))\n            else:                 \t# this is 'attach'\n                if diacAP is not None: # find diacritic Attachment Point in currglyph\n                    if diacAP not in cganc:\n                        logger.log(\"The AP '\" + diacAP + \"' does not exist on diacritic glyph \" + currglyph, \"E\")\n                    else:\n                        i = cganc.index(diacAP)\n                        diacAPx = int(float(cg['anchor'][i].element.get('x')))\n                        diacAPy = int(float(cg['anchor'][i].element.get('y')))\n                else:\n                    logger.log(\"No AP specified for diacritic \" + currglyph, \"E\")\n                if baseAP is not None: # find base character Attachment Point in targetglyph\n                    if baseAP not in targetglyphanchors.keys():\n                        logger.log(\"The AP '\" + baseAP + \"' does not exist on base glyph when building \" + targetglyphname, \"E\")\n                    else:\n                        baseAPx = targetglyphanchors[baseAP][0]\n                        baseAPy = targetglyphanchors[baseAP][1]\n                        if RemoveUsedAnchors:\n                            logger.log(\"Removing used anchor \" + baseAP, \"V\")\n                            del targetglyphanchors[baseAP]\n                xOffset = baseAPx - diacAPx\n                yOffset = baseAPy - diacAPy\n\n            if shiftx is not None: xOffset += int(shiftx)\n            if shifty is not None: yOffset += int(shifty)\n\n            componentdic = {'base': currglyph}\n            if xOffset != 0: componentdic['xOffset'] = str(xOffset)\n            if yOffset != 0: componentdic['yOffset'] = str(yOffset)\n            componentlist.append( componentdic )\n\n            # Move anchor information to targetglyphanchors\n            for a in cg['anchor']:\n                dic = a.element.attrib\n                thisanchorname = dic['name']\n                if RemoveUsedAnchors and thisanchorname == diacAP:\n                    logger.log(\"Skipping used anchor \" + diacAP, \"V\")\n                    continue # skip this anchor\n                # add anchor (adjusted for position in targetglyph)\n                targetglyphanchors[thisanchorname] = ( int( dic['x'] ) + xOffset, int( dic['y'] ) + yOffset )\n                logger.log(\"Adding anchor \" + thisanchorname + \": \" + str(targetglyphanchors[thisanchorname]), \"V\")\n            logger.log(str(targetglyphanchors),\"V\")\n\n        if adv is not None:\n            xadvance = adv  ### if adv specified, then this advance value overrides calculated value\n        else:\n            xadvance += rsb ### adjust with rsb\n\n        logger.log(\"Glyph: \" + targetglyphname + \", \" + str(targetglyphunicode) + \", \" + str(xadvance), \"V\")\n        for c in componentlist:\n            logger.log(str(c), \"V\")\n\n        # Flatten components unless -n set\n        if not args.noflatten:\n            newcomponentlist = []\n            for compdic in componentlist:\n                c = compdic['base']\n                x = compdic.get('xOffset')\n                y = compdic.get('yOffset')\n                # look up component glyph\n                g=infont.deflayer[c]\n                # check if it has only components (that is, no contours) in outline\n                if g['outline'] and g['outline'].components and not g['outline'].contours:\n                    # for each component, get base, x1, y1 and create new entry with base, x+x1, y+y1\n                    for subcomp in g['outline'].components:\n                        componentdic = subcomp.element.attrib.copy()\n                        x1 = componentdic.pop('xOffset', 0)\n                        y1 = componentdic.pop('yOffset', 0)\n                        xOffset = addtwo(x, x1)\n                        yOffset = addtwo(y, y1)\n                        if xOffset != 0: componentdic['xOffset'] = str(xOffset)\n                        if yOffset != 0: componentdic['yOffset'] = str(yOffset)\n                        newcomponentlist.append( componentdic )\n                else:\n                    newcomponentlist.append( compdic )\n            if componentlist == newcomponentlist:\n                logger.log(\"No changes to flatten components\", \"V\")\n            else:\n                componentlist = newcomponentlist\n                logger.log(\"Components flattened\", \"V\")\n                for c in componentlist:\n                    logger.log(str(c), \"V\")\n\n        # Check if this new glyph exists in the font already; if so, decide whether to replace, or issue warning\n        preservedAPs = set()\n        if  targetglyphname in infont.deflayer.keys():\n            logger.log(\"Target glyph, \" + targetglyphname + \", already exists in font.\", \"V\")\n            targetglyph = infont.deflayer[targetglyphname]\n            if targetglyph['outline'] and targetglyph['outline'].contours and not args.force: # don't replace glyph with contours, unless -f set\n                logger.log(\"Not replacing existing glyph, \" + targetglyphname + \", because it has contours.\", \"W\")\n                continue\n            else:\n                logger.log(\"Replacing information in existing glyph, \" + targetglyphname, \"I\")\n                glyphstatus = \"Replace\"\n                # delete information from existing glyph\n                targetglyph.remove('outline')\n                targetglyph.remove('advance')\n                for i in xrange(len(targetglyph['anchor'])-1,-1,-1):\n                    aname = targetglyph['anchor'][i].element.attrib['name']\n                    if preserveRE is not None and preserveRE.match(aname):\n                        preservedAPs.add(aname)\n                        logger.log(\"Preserving anchor \" + aname, \"V\")\n                    else:\n                        targetglyph.remove('anchor',index=i)\n        else:\n            logger.log(\"Adding new glyph, \" + targetglyphname, \"I\")\n            glyphstatus = \"New\"\n            # create glyph, using targetglyphname, targetglyphunicode\n            targetglyph = ufo.Uglif(layer=infont.deflayer, name=targetglyphname)\n            # actually add the glyph to the font\n            infont.deflayer.addGlyph(targetglyph)\n\n        if xadvance != 0: targetglyph.add('advance',{'width': str(xadvance)} )\n        if targetglyphunicode: # remove any existing unicode value(s) before adding unicode value\n            for i in xrange(len(targetglyph['unicode'])-1,-1,-1):\n                targetglyph.remove('unicode',index=i)\n            targetglyph.add('unicode',{'hex': targetglyphunicode} )\n        targetglyph.add('outline')\n        # to the outline element, add a component element for every entry in componentlist\n        for compdic in componentlist:\n            comp = ufo.Ucomponent(targetglyph['outline'],ET.Element('component',compdic))\n            targetglyph['outline'].appendobject(comp,'component')\n        # copy anchors to new glyph from targetglyphanchors which has format {'U': (500,1000), 'L': (500,0)}\n        for a in sorted(targetglyphanchors):\n            if removeRE is not None and removeRE.match(a):\n                logger.log(\"Skipping unwanted anchor \" + a, \"V\")\n                continue  # skip this anchor\n            if a not in preservedAPs:\n                targetglyph.add('anchor', {'name': a, 'x': str(targetglyphanchors[a][0]), 'y': str(targetglyphanchors[a][1])} )\n        # mark glyphs as being generated by setting cell mark color if -c or --colors set\n        if colors:\n            # Need to see if the target glyph has changed.\n            if glyphstatus == \"Replace\":\n                # Need to recreate the xml element then normalize it for comparison with original\n                targetglyph[\"anchor\"].sort(key=lambda anchor: anchor.element.get(\"name\"))\n                targetglyph.rebuildET()\n                attribOrder = params['attribOrders']['glif'] if 'glif' in params['attribOrders'] else {}\n                if params[\"sortDicts\"] or params[\"precision\"] is not None: ufo.normETdata(targetglyph.etree, params, 'glif')\n                etw = ETWriter(targetglyph.etree, attributeOrder=attribOrder, indentIncr=params[\"indentIncr\"],\n                                   indentFirst=params[\"indentFirst\"], indentML=params[\"indentML\"], precision=params[\"precision\"],\n                                   floatAttribs=params[\"floatAttribs\"], intAttribs=params[\"intAttribs\"])\n                newxml = etw.serialize_xml()\n                if newxml == targetglyph.inxmlstr: glyphstatus = 'Unchanged'\n\n            x = 0 if glyphstatus == \"Unchanged\" else 1 if glyphstatus == \"Replace\" else 2\n\n            color = colors[x]\n            lib = targetglyph[\"lib\"]\n            if color[0]: # Need to set actual color\n                if lib is None: targetglyph.add(\"lib\")\n                targetglyph[\"lib\"].setval(\"public.markColor\", \"string\", color[0])\n                logger.log(logstatuses[x] + \" - setting markColor to \" + color[2], \"I\")\n            elif x < 2: # No need to log for new glyphs\n                if color[1] == \"none\": # Remove existing color\n                    if lib is not None and \"public.markColor\" in lib: lib.remove(\"public.markColor\")\n                    logger.log(logstatuses[x] + \" - Removing existing markColor\", \"I\")\n                else:\n                    logger.log(logstatuses[x] + \" - Leaving existing markColor (if any)\", \"I\")\n\n    # If analysis only, return without writing output font\n    if args.analysis: return\n    # Return changed font and let execute() write it out\n    return infont",
  "def addtolist(e, prevglyph):\n    \"\"\"Given an element ('base' or 'attach') and the name of previous glyph,\n    add a tuple to the list of glyphs in this composite, including\n    \"at\" and \"with\" attachment point information, and x and y shift values\n    \"\"\"\n    global glyphlist\n    subelementlist = []\n    thisglyphname = e.get('PSName')\n    atvalue = e.get(\"at\")\n    withvalue = e.get(\"with\")\n    shiftx = shifty = None\n    for se in e:\n        if se.tag == 'property': pass\n        elif se.tag == 'shift':\n            shiftx = se.get('x')\n            shifty = se.get('y')\n        elif se.tag == 'attach':\n            subelementlist.append( se )\n    glyphlist.append( ( thisglyphname, prevglyph, atvalue, withvalue, shiftx, shifty ) )\n    for se in subelementlist:\n        addtolist(se, thisglyphname)",
  "def addtwo(a1, a2):\n    \"\"\"Take two items (string, number or None), convert to integer and return sum\"\"\"\n    b1 = int(a1) if a1 is not None else 0\n    b2 = int(a2) if a2 is not None else 0\n    return b1 + b2",
  "def cmd() : execute(\"UFO\",doit,argspec)",
  "def doit(args) :\n    font = args.ifont\n    logger = args.logger\n    transform = args.transform\n\n    if transform[1] == \"(\":\n        # Set transform from matrix - example: \"(0.72, 0, 0, 0.6, 10, 806)\"\n        # (xx, xy, yx, yy, x, y)\n        trans = make_tuple(args.transform)\n    else:\n        # Set transformation specs from UFO lib.plist org.sil.lcg.transforms\n        # Will need to be enhanced to support adjustMetrics, boldX, boldY parameters for smallcaps\n        try:\n            trns = font.lib[\"org.sil.lcg.transforms\"][transform]\n        except KeyError:\n            logger.log(\"Error: transform type not found in lib.plist org.sil.lcg.transforms\", \"S\")\n        else:\n            try:\n                adjM = trns[\"adjustMetrics\"]\n            except KeyError:\n                adjM = 0\n            try:\n                skew = trns[\"skew\"]\n            except KeyError:\n                skew = 0\n            try:\n                shiftX = trns[\"shiftX\"]\n            except KeyError:\n                shiftX = 0\n            try:\n                shiftY = trns[\"shiftY\"]\n            except KeyError:\n                shiftY = 0\n            trans = (trns[\"scaleX\"], 0, skew, trns[\"scaleY\"], shiftX+adjM, shiftY)\n\n\n    # Process csv list into a dictionary structure\n    args.input.numfields = 3\n    deps = {}\n    for (source, newname, newuni) in args.input :\n        if source in deps:\n            deps[source].append({\"newname\": newname, \"newuni\": newuni})\n        else:\n            deps[source] = [({\"newname\": newname, \"newuni\": newuni})]\n\n    # Iterate through dictionary (unsorted)\n    for source in deps:\n        # Check if source glyph is in font\n        if source in font.keys() :\n            for target in deps[source]:\n                # Give warning if target is already in font, but overwrite anyway\n                targetname = target[\"newname\"]\n                if targetname in font.keys() :\n                    logger.log(\"Warning: \" + targetname + \" already in font and will be replaced\")\n\n                # Make a copy of source into a new glyph object\n                sourceglyph = font[source]\n                newglyph = sourceglyph.copy()\n\n                newglyph.transformBy(trans)\n                # Set width because transformBy does not seems to properly adjust width\n                newglyph.width = (int(newglyph.width * trans[0])) + (adjM * 2)\n\n                # Set unicode\n                newglyph.unicodes = []\n                if target[\"newuni\"]:\n                    newglyph.unicode = int(target[\"newuni\"], 16)\n\n                # mark glyphs as being generated by setting cell mark color (defaults to blue if args.color not set)\n                if args.colorcells or args.color:\n                    if args.color:\n                        (color, name, logcolor, splitcolor) = parsecolors(args.color, single=True)\n                        if color is None: logger.log(logcolor, \"S\")  # If color not parsed, parsecolors() puts error in logcolor\n                        color = color.split(\",\") # Need to convert string to tuple\n                        color = (float(color[0]), float(color[1]), float(color[2]), float(color[3]))\n                    else:\n                        color = (0.18, 0.16, 0.78, 1)\n                    newglyph.markColor = color\n\n                # Add the new glyph object to the font with name target\n                font.__setitem__(targetname, newglyph)\n\n                # Decompose glyph in case there may be components\n                # It seems you can't decompose a glyph has hasn't yet been added to a font\n                font[targetname].decompose()\n                # Correct path direction\n                font[targetname].correctDirection()\n\n                logger.log(source + \" duplicated to \" + targetname)\n        else :\n            logger.log(\"Warning: \" + source + \" not in font\")\n\n    return font",
  "def cmd() : execute(\"FP\",doit,argspec)",
  "def long2tag(x):\n    res = []\n    while x:\n        res.append(chr(x & 0xFF))\n        x >>= 8\n    return \"\".join(reversed(res))",
  "def doit(args):\n    infont = args.ifont\n    ltag = args.lang.lower()\n    if 'Sill' in infont and 'Feat' in infont:\n        if ltag in infont['Sill'].langs:\n            changes = dict((long2tag(x[0]), x[1]) for x in infont['Sill'].langs[ltag])\n            for g, f in infont['Feat'].features.items():\n                if g in changes:\n                    f.default = changes[g]\n    otltag = ltag + (\" \" * (4 - len(ltag)))\n    for k in ('GSUB', 'GPOS'):\n        try:\n            t = infont[k].table\n        except KeyError:\n            continue\n        for srec in t.ScriptList.ScriptRecord:\n            for lrec in srec.Script.LangSysRecord:\n                if lrec.LangSysTag.lower() == otltag:\n                    srec.Script.DefaultLangSys = lrec.LangSys\n    return infont",
  "def cmd() : execute('FT', doit, argspec)",
  "def getbbox(g):\n    res = (65536, 65536, -65536, -65536)\n    if g['outline'] is None:\n        return (0, 0, 0, 0)\n    for c in g['outline'].contours:\n        for p in c['point']:\n            if 'type' in p.attrib:      # any actual point counts\n                x = float(p.get('x', '0'))\n                y = float(p.get('y', '0'))\n                res = (min(x, res[0]), min(y, res[1]), max(x, res[2]), max(y, res[3]))\n    return res",
  "class Glyph(object) :\n    def __init__(self, name, advance=0, bbox=None) :\n        self.name = name\n        self.anchors = {}\n        self.is_mark = False\n        self.advance = int(float(advance))\n        self.bbox = bbox or (0, 0, 0, 0)\n\n    def add_anchor(self, info) :\n        self.anchors[info['name']] = (int(float(info['x'])), int(float(info['y'])))\n\n    def decide_if_mark(self) :\n        for a in self.anchors.keys() :\n            if a.startswith(\"_\") :\n                self.is_mark = True\n                break",
  "def decode_element(e):\n    '''Convert plist element into python structures'''\n    res = None\n    if e.tag == 'string':\n        return e.text\n    elif e.tag == 'integer':\n        return int(e.text)\n    elif e.tag== 'real':\n        return float(e.text)\n    elif e.tag == 'array':\n        res = [decode_element(x) for x in e]\n    elif e.tag == 'dict':\n        res = {}\n        for p in zip(e[::2], e[1::2]):\n            res[p[0].text] = decode_element(p[1])\n    return res",
  "class Font(object) :\n    def __init__(self, defines = None):\n        self.glyphs = OrderedDict()\n        self.classes = OrderedDict()\n        self.all_aps = OrderedDict()\n        self.fontinfo = {}\n        self.kerns = {}\n        self.defines = {} if defines is None else defines\n\n    def readaps(self, filename, omitaps='', params = None) :\n        omittedaps = set(omitaps.replace(',',' ').split())  # allow comma- and/or space-separated list\n        if filename.endswith('.ufo') :\n            f = ufo.Ufont(filename, params = params)\n            self.fontinfo = {}\n            for k, v in f.fontinfo._contents.items():\n                self.fontinfo[k] = decode_element(v[1])\n            skipglyphs = set(f.lib.getval('public.skipExportGlyphs', []))\n            for g in f.deflayer :\n                if g in skipglyphs:\n                    continue\n                ufo_g = f.deflayer[g]\n                advb = ufo_g['advance']\n                adv = advb.width if advb is not None and advb.width is not None else 0\n                bbox = getbbox(ufo_g)\n                glyph = Glyph(g, advance=adv, bbox=bbox)\n                self.glyphs[g] = glyph\n                if 'anchor' in ufo_g._contents :\n                    for a in ufo_g._contents['anchor'] :\n                        if a.element.attrib['name'] not in omittedaps:\n                            glyph.add_anchor(a.element.attrib)\n                            self.all_aps.setdefault(a.element.attrib['name'], []).append(glyph)\n            if hasattr(f, 'groups'):\n                for k, v in f.groups._contents.items():\n                    self.classes[k.lstrip('@')] = decode_element(v[1])\n            if hasattr(f, 'kerning'):\n                for k, v in f.kerning._contents.items():\n                    key = k.lstrip('@')\n                    if key in self.classes:\n                        key = \"@\" + key\n                    subelements = decode_element(v[1])\n                    kerndict = {}\n                    for s, n in subelements.items():\n                        skey = s.lstrip('@')\n                        if skey in self.classes:\n                            skey = \"@\" + skey\n                        kerndict[skey] = n\n                    self.kerns[key] = kerndict\n        elif filename.endswith('.xml') :\n            currGlyph = None\n            currPoint = None\n            self.fontinfo = {}\n            for event, elem in et.iterparse(filename, events=('start', 'end')):\n                if event == 'start':\n                    if elem.tag == 'glyph':\n                        name = elem.get('PSName', '')\n                        if name:\n                            currGlyph = Glyph(name)\n                            self.glyphs[name] = currGlyph\n                        currPoint = None\n                    elif elem.tag == 'point':\n                        currPoint = {'name' : elem.get('type', '')}\n                    elif elem.tag == 'location' and currPoint is not None:\n                        currPoint['x'] = int(elem.get('x', 0))\n                        currPoint['y'] = int(elem.get('y', 0))\n                    elif elem.tag == 'font':\n                        n = elem.get('name', '')\n                        x = n.split('-')\n                        if len(x) == 2:\n                            self.fontinfo['familyName'] = x[0]\n                            self.fontinfo['openTypeNamePreferredFamilyName'] = x[0]\n                            self.fontinfo['styleMapFamilyName'] = x[0]\n                            self.fontinfo['styleName'] = x[1]\n                            self.fontinfo['openTypeNamePreferredSubfamilyName'] = x[1]\n                            self.fontinfo['postscriptFullName'] = \"{0} {1}\".format(*x)\n                        self.fontinfo['postscriptFontName'] = n\n                elif event == 'end':\n                    if elem.tag == 'point':\n                        if currGlyph and currPoint['name'] not in omittedaps:\n                            currGlyph.add_anchor(currPoint)\n                            self.all_aps.setdefault(currPoint['name'], []).append(currGlyph)\n                        currPoint = None\n                    elif elem.tag == 'glyph':\n                        currGlyph = None\n\n    def read_classes(self, fname, classproperties=False):\n        doc = et.parse(fname)\n        for c in doc.findall('.//class'):\n            class_name = c.get('name')\n            m = re.search('\\[(\\d+)\\]$', class_name)\n            # support fixedclasses like make_gdl.pl via AP.pm\n            if m:\n                class_nm = class_name[0:m.start()]\n                ix = int(m.group(1))\n            else:\n                class_nm = class_name\n                ix = None\n            cl = self.classes.setdefault(class_nm, [])\n            for e in c.get('exts', '').split() + [\"\"]:\n                for g in c.text.split():\n                    if g+e in self.glyphs or (e == '' and g.startswith('@')):\n                        if ix:\n                            cl.insert(ix, g+e)\n                        else:\n                            cl.append(g+e)\n        if not classproperties:\n            return\n        for c in doc.findall('.//property'):\n            for e in c.get('exts', '').split() + [\"\"]:\n                for g in c.text.split():\n                    if g+e in self.glyphs:\n                        cname = c.get('name') + \"_\" + c.get('value')\n                        self.classes.setdefault(cname, []).append(g+e)\n                    \n    def make_classes(self, ligmode) :\n        for name, g in self.glyphs.items() :\n            # pull off suffix and make classes\n            # TODO: handle ligatures\n            base = name\n            if ligmode is None or 'comp' not in ligmode or \"_\" not in name:\n                pos = base.rfind('.')\n                while pos > 0 :\n                    old_base = base\n                    ext = base[pos+1:]\n                    base = base[:pos]\n                    ext_class_nm = \"c_\" + ext\n                    if base in self.glyphs and old_base in self.glyphs:\n                        glyph_lst = self.classes.setdefault(ext_class_nm, [])\n                        if not old_base in glyph_lst:\n                            glyph_lst.append(old_base)\n                            self.classes.setdefault(\"cno_\" + ext, []).append(base)\n                    pos = base.rfind('.')\n            if ligmode is not None and \"_\" in name:\n                comps = name.split(\"_\")\n                if \"comp\" in ligmode or \".\" not in comps[-1]:\n                    base = comps.pop(-1 if \"last\" in ligmode else 0)\n                    cname = base.replace(\".\", \"_\")\n                    noname = \"_\".join(comps)\n                    if base in self.glyphs and noname in self.glyphs:\n                        glyph_lst = self.classes.setdefault(\"clig_\"+cname, [])\n                        if name not in glyph_lst:\n                            glyph_lst.append(name)\n                            self.classes.setdefault(\"cligno_\"+cname, []).append(noname)\n            if g.is_mark :\n                self.classes.setdefault('GDEF_marks', []).append(name)\n            else :\n                self.classes.setdefault('GDEF_bases', []).append(name)\n\n    def make_marks(self) :\n        for name, g in self.glyphs.items() :\n            g.decide_if_mark()\n\n    def order_classes(self):\n        # return ordered list of classnames as desired for FEA\n\n        # Start with alphabetical then correct:\n        #   1. Put classes like \"cno_whatever\" adjacent to \"c_whatever\"\n        #   2. Classes can be defined in terms of other classes but FEA requires that\n        #      classes be defined before they can be referenced.\n\n        def sortkey(x):\n            key1 = 'c_' + x[4:] if x.startswith('cno_') else x\n            return (key1, x)\n\n        classes = sorted(self.classes.keys(), key=sortkey)\n        links = {}  # key = classname; value = list of other classes that include this one\n        counts = {} # key = classname; value = count of un-output classes that this class includes\n        for name in classes:\n            y = [c[1:] for c in self.classes[name] if c.startswith('@')]  #list of included classes\n            counts[name] = len(y)\n            for c in y:\n                links.setdefault(c, []).append(name)\n\n        outclasses = []\n        while len(classes) > 0:\n            foundone = False\n            for name in classes:\n                if counts[name] == 0:\n                    foundone = True\n                    # output this class\n                    outclasses.append(name)\n                    classes.remove(name)\n                    # adjust counts of classes that include this one\n                    if name in links:\n                        for n in links[name]:\n                            counts[n] -= 1\n                    # It may now be possible to output some we skipped earlier,\n                    # so start over from the beginning of the list\n                    break\n            if not foundone:\n                # all remaining classes include un-output classes and thus there is a loop somewhere\n                raise ValueError(\"Class reference loop(s) found: \" + \", \".join(classes))\n        return outclasses\n\n    def addComment(self, parser, text):\n        cmt = parser.ast.Comment(\"# \" + text, location=None)\n        cmt.pretext = \"\\n\"\n        parser.add_statement(cmt)\n\n    def append_classes(self, parser) :\n        # normal glyph classes\n        self.addComment(parser, \"Main Classes\")\n        for name in self.order_classes():\n            gc = parser.ast.GlyphClass(None, location=None)\n            for g in self.classes[name] :\n                gc.append(g)\n            gcd = parser.ast.GlyphClassDefinition(name, gc, location=None)\n            parser.add_statement(gcd)\n            parser.define_glyphclass(name, gcd)\n\n    def _addGlyphsToClass(self, parser, glyphs, gc, anchor, definer):\n        if len(glyphs) > 1 :\n            val = parser.ast.GlyphClass(glyphs, location=None)\n        else :\n            val = parser.ast.GlyphName(glyphs[0], location=None)\n        classdef = definer(gc, anchor, val, location=None)\n        gc.addDefinition(classdef)\n        parser.add_statement(classdef)\n\n    def append_positions(self, parser):\n        # create base and mark classes, add to fea file dicts and parser symbol table\n        bclassdef_lst = []\n        mclassdef_lst = []\n        self.addComment(parser, \"Positioning classes and statements\")\n        for ap_nm, glyphs_w_ap in self.all_aps.items() :\n            self.addComment(parser, \"AP: \" + ap_nm)\n            # e.g. all glyphs with U AP\n            if not ap_nm.startswith(\"_\"):\n                if any(not x.is_mark for x in glyphs_w_ap):\n                    gcb = parser.set_baseclass(ap_nm)\n                    parser.add_statement(gcb)\n                if any(x.is_mark for x in glyphs_w_ap):\n                    gcm = parser.set_baseclass(ap_nm + \"_MarkBase\")\n                    parser.add_statement(gcm)\n            else:\n                gc = parser.set_markclass(ap_nm)\n\n            # create lists of glyphs that use the same point (name and coordinates)\n            # that can share a class definition\n            anchor_cache = OrderedDict()\n            markanchor_cache = OrderedDict()\n            for g in glyphs_w_ap :\n                p = g.anchors[ap_nm]\n                if g.is_mark and not ap_nm.startswith(\"_\"):\n                    markanchor_cache.setdefault(p, []).append(g.name)\n                else:\n                    anchor_cache.setdefault(p, []).append(g.name)\n\n            if ap_nm.startswith(\"_\"):\n                for p, glyphs_w_pt in anchor_cache.items():\n                    anchor = parser.ast.Anchor(p[0], p[1], location=None)\n                    self._addGlyphsToClass(parser, glyphs_w_pt, gc, anchor, parser.ast.MarkClassDefinition)\n            else:\n                for p, glyphs_w_pt in anchor_cache.items():\n                    anchor = parser.ast.Anchor(p[0], p[1], location=None)\n                    self._addGlyphsToClass(parser, glyphs_w_pt, gcb, anchor, parser.ast.BaseClassDefinition)\n                for p, glyphs_w_pt in markanchor_cache.items():\n                    anchor = parser.ast.Anchor(p[0], p[1], location=None)\n                    self._addGlyphsToClass(parser, glyphs_w_pt, gcm, anchor, parser.ast.BaseClassDefinition)",
  "def doit(args) :\n    defines = dict(x.split('=') for x in args.define) if args.define else {}\n    font = Font(defines)\n    # if args.debug:\n    #     import pdb; pdb.set_trace()\n    if \"checkfix\" not in args.params:\n        args.paramsobj.sets[\"main\"][\"checkfix\"] = \"None\"\n    if args.infile is not None:\n        font.readaps(args.infile, args.omitaps, args.paramsobj)\n\n    font.make_marks()\n    font.make_classes(args.ligmode)\n    if args.classfile:\n        font.read_classes(args.classfile, classproperties = args.classprops)\n\n    p = feaplus_parser(None, font.glyphs, font.fontinfo, font.kerns, font.defines)\n    doc_ufo = p.parse() # returns an empty ast.FeatureFile\n\n    # Add goodies from the font\n    font.append_classes(p)\n    font.append_positions(p)\n\n    # parse the input fea file\n    if args.input :\n        doc_fea = p.parse(args.input)\n    else:\n        doc_fea = doc_ufo\n\n    # output as doc.asFea()\n    if args.output :\n        with open(args.output, \"w\") as of :\n            of.write(doc_fea.asFea())",
  "def cmd(): execute(None, doit, argspec)",
  "def __init__(self, name, advance=0, bbox=None) :\n        self.name = name\n        self.anchors = {}\n        self.is_mark = False\n        self.advance = int(float(advance))\n        self.bbox = bbox or (0, 0, 0, 0)",
  "def add_anchor(self, info) :\n        self.anchors[info['name']] = (int(float(info['x'])), int(float(info['y'])))",
  "def decide_if_mark(self) :\n        for a in self.anchors.keys() :\n            if a.startswith(\"_\") :\n                self.is_mark = True\n                break",
  "def __init__(self, defines = None):\n        self.glyphs = OrderedDict()\n        self.classes = OrderedDict()\n        self.all_aps = OrderedDict()\n        self.fontinfo = {}\n        self.kerns = {}\n        self.defines = {} if defines is None else defines",
  "def readaps(self, filename, omitaps='', params = None) :\n        omittedaps = set(omitaps.replace(',',' ').split())  # allow comma- and/or space-separated list\n        if filename.endswith('.ufo') :\n            f = ufo.Ufont(filename, params = params)\n            self.fontinfo = {}\n            for k, v in f.fontinfo._contents.items():\n                self.fontinfo[k] = decode_element(v[1])\n            skipglyphs = set(f.lib.getval('public.skipExportGlyphs', []))\n            for g in f.deflayer :\n                if g in skipglyphs:\n                    continue\n                ufo_g = f.deflayer[g]\n                advb = ufo_g['advance']\n                adv = advb.width if advb is not None and advb.width is not None else 0\n                bbox = getbbox(ufo_g)\n                glyph = Glyph(g, advance=adv, bbox=bbox)\n                self.glyphs[g] = glyph\n                if 'anchor' in ufo_g._contents :\n                    for a in ufo_g._contents['anchor'] :\n                        if a.element.attrib['name'] not in omittedaps:\n                            glyph.add_anchor(a.element.attrib)\n                            self.all_aps.setdefault(a.element.attrib['name'], []).append(glyph)\n            if hasattr(f, 'groups'):\n                for k, v in f.groups._contents.items():\n                    self.classes[k.lstrip('@')] = decode_element(v[1])\n            if hasattr(f, 'kerning'):\n                for k, v in f.kerning._contents.items():\n                    key = k.lstrip('@')\n                    if key in self.classes:\n                        key = \"@\" + key\n                    subelements = decode_element(v[1])\n                    kerndict = {}\n                    for s, n in subelements.items():\n                        skey = s.lstrip('@')\n                        if skey in self.classes:\n                            skey = \"@\" + skey\n                        kerndict[skey] = n\n                    self.kerns[key] = kerndict\n        elif filename.endswith('.xml') :\n            currGlyph = None\n            currPoint = None\n            self.fontinfo = {}\n            for event, elem in et.iterparse(filename, events=('start', 'end')):\n                if event == 'start':\n                    if elem.tag == 'glyph':\n                        name = elem.get('PSName', '')\n                        if name:\n                            currGlyph = Glyph(name)\n                            self.glyphs[name] = currGlyph\n                        currPoint = None\n                    elif elem.tag == 'point':\n                        currPoint = {'name' : elem.get('type', '')}\n                    elif elem.tag == 'location' and currPoint is not None:\n                        currPoint['x'] = int(elem.get('x', 0))\n                        currPoint['y'] = int(elem.get('y', 0))\n                    elif elem.tag == 'font':\n                        n = elem.get('name', '')\n                        x = n.split('-')\n                        if len(x) == 2:\n                            self.fontinfo['familyName'] = x[0]\n                            self.fontinfo['openTypeNamePreferredFamilyName'] = x[0]\n                            self.fontinfo['styleMapFamilyName'] = x[0]\n                            self.fontinfo['styleName'] = x[1]\n                            self.fontinfo['openTypeNamePreferredSubfamilyName'] = x[1]\n                            self.fontinfo['postscriptFullName'] = \"{0} {1}\".format(*x)\n                        self.fontinfo['postscriptFontName'] = n\n                elif event == 'end':\n                    if elem.tag == 'point':\n                        if currGlyph and currPoint['name'] not in omittedaps:\n                            currGlyph.add_anchor(currPoint)\n                            self.all_aps.setdefault(currPoint['name'], []).append(currGlyph)\n                        currPoint = None\n                    elif elem.tag == 'glyph':\n                        currGlyph = None",
  "def read_classes(self, fname, classproperties=False):\n        doc = et.parse(fname)\n        for c in doc.findall('.//class'):\n            class_name = c.get('name')\n            m = re.search('\\[(\\d+)\\]$', class_name)\n            # support fixedclasses like make_gdl.pl via AP.pm\n            if m:\n                class_nm = class_name[0:m.start()]\n                ix = int(m.group(1))\n            else:\n                class_nm = class_name\n                ix = None\n            cl = self.classes.setdefault(class_nm, [])\n            for e in c.get('exts', '').split() + [\"\"]:\n                for g in c.text.split():\n                    if g+e in self.glyphs or (e == '' and g.startswith('@')):\n                        if ix:\n                            cl.insert(ix, g+e)\n                        else:\n                            cl.append(g+e)\n        if not classproperties:\n            return\n        for c in doc.findall('.//property'):\n            for e in c.get('exts', '').split() + [\"\"]:\n                for g in c.text.split():\n                    if g+e in self.glyphs:\n                        cname = c.get('name') + \"_\" + c.get('value')\n                        self.classes.setdefault(cname, []).append(g+e)",
  "def make_classes(self, ligmode) :\n        for name, g in self.glyphs.items() :\n            # pull off suffix and make classes\n            # TODO: handle ligatures\n            base = name\n            if ligmode is None or 'comp' not in ligmode or \"_\" not in name:\n                pos = base.rfind('.')\n                while pos > 0 :\n                    old_base = base\n                    ext = base[pos+1:]\n                    base = base[:pos]\n                    ext_class_nm = \"c_\" + ext\n                    if base in self.glyphs and old_base in self.glyphs:\n                        glyph_lst = self.classes.setdefault(ext_class_nm, [])\n                        if not old_base in glyph_lst:\n                            glyph_lst.append(old_base)\n                            self.classes.setdefault(\"cno_\" + ext, []).append(base)\n                    pos = base.rfind('.')\n            if ligmode is not None and \"_\" in name:\n                comps = name.split(\"_\")\n                if \"comp\" in ligmode or \".\" not in comps[-1]:\n                    base = comps.pop(-1 if \"last\" in ligmode else 0)\n                    cname = base.replace(\".\", \"_\")\n                    noname = \"_\".join(comps)\n                    if base in self.glyphs and noname in self.glyphs:\n                        glyph_lst = self.classes.setdefault(\"clig_\"+cname, [])\n                        if name not in glyph_lst:\n                            glyph_lst.append(name)\n                            self.classes.setdefault(\"cligno_\"+cname, []).append(noname)\n            if g.is_mark :\n                self.classes.setdefault('GDEF_marks', []).append(name)\n            else :\n                self.classes.setdefault('GDEF_bases', []).append(name)",
  "def make_marks(self) :\n        for name, g in self.glyphs.items() :\n            g.decide_if_mark()",
  "def order_classes(self):\n        # return ordered list of classnames as desired for FEA\n\n        # Start with alphabetical then correct:\n        #   1. Put classes like \"cno_whatever\" adjacent to \"c_whatever\"\n        #   2. Classes can be defined in terms of other classes but FEA requires that\n        #      classes be defined before they can be referenced.\n\n        def sortkey(x):\n            key1 = 'c_' + x[4:] if x.startswith('cno_') else x\n            return (key1, x)\n\n        classes = sorted(self.classes.keys(), key=sortkey)\n        links = {}  # key = classname; value = list of other classes that include this one\n        counts = {} # key = classname; value = count of un-output classes that this class includes\n        for name in classes:\n            y = [c[1:] for c in self.classes[name] if c.startswith('@')]  #list of included classes\n            counts[name] = len(y)\n            for c in y:\n                links.setdefault(c, []).append(name)\n\n        outclasses = []\n        while len(classes) > 0:\n            foundone = False\n            for name in classes:\n                if counts[name] == 0:\n                    foundone = True\n                    # output this class\n                    outclasses.append(name)\n                    classes.remove(name)\n                    # adjust counts of classes that include this one\n                    if name in links:\n                        for n in links[name]:\n                            counts[n] -= 1\n                    # It may now be possible to output some we skipped earlier,\n                    # so start over from the beginning of the list\n                    break\n            if not foundone:\n                # all remaining classes include un-output classes and thus there is a loop somewhere\n                raise ValueError(\"Class reference loop(s) found: \" + \", \".join(classes))\n        return outclasses",
  "def addComment(self, parser, text):\n        cmt = parser.ast.Comment(\"# \" + text, location=None)\n        cmt.pretext = \"\\n\"\n        parser.add_statement(cmt)",
  "def append_classes(self, parser) :\n        # normal glyph classes\n        self.addComment(parser, \"Main Classes\")\n        for name in self.order_classes():\n            gc = parser.ast.GlyphClass(None, location=None)\n            for g in self.classes[name] :\n                gc.append(g)\n            gcd = parser.ast.GlyphClassDefinition(name, gc, location=None)\n            parser.add_statement(gcd)\n            parser.define_glyphclass(name, gcd)",
  "def _addGlyphsToClass(self, parser, glyphs, gc, anchor, definer):\n        if len(glyphs) > 1 :\n            val = parser.ast.GlyphClass(glyphs, location=None)\n        else :\n            val = parser.ast.GlyphName(glyphs[0], location=None)\n        classdef = definer(gc, anchor, val, location=None)\n        gc.addDefinition(classdef)\n        parser.add_statement(classdef)",
  "def append_positions(self, parser):\n        # create base and mark classes, add to fea file dicts and parser symbol table\n        bclassdef_lst = []\n        mclassdef_lst = []\n        self.addComment(parser, \"Positioning classes and statements\")\n        for ap_nm, glyphs_w_ap in self.all_aps.items() :\n            self.addComment(parser, \"AP: \" + ap_nm)\n            # e.g. all glyphs with U AP\n            if not ap_nm.startswith(\"_\"):\n                if any(not x.is_mark for x in glyphs_w_ap):\n                    gcb = parser.set_baseclass(ap_nm)\n                    parser.add_statement(gcb)\n                if any(x.is_mark for x in glyphs_w_ap):\n                    gcm = parser.set_baseclass(ap_nm + \"_MarkBase\")\n                    parser.add_statement(gcm)\n            else:\n                gc = parser.set_markclass(ap_nm)\n\n            # create lists of glyphs that use the same point (name and coordinates)\n            # that can share a class definition\n            anchor_cache = OrderedDict()\n            markanchor_cache = OrderedDict()\n            for g in glyphs_w_ap :\n                p = g.anchors[ap_nm]\n                if g.is_mark and not ap_nm.startswith(\"_\"):\n                    markanchor_cache.setdefault(p, []).append(g.name)\n                else:\n                    anchor_cache.setdefault(p, []).append(g.name)\n\n            if ap_nm.startswith(\"_\"):\n                for p, glyphs_w_pt in anchor_cache.items():\n                    anchor = parser.ast.Anchor(p[0], p[1], location=None)\n                    self._addGlyphsToClass(parser, glyphs_w_pt, gc, anchor, parser.ast.MarkClassDefinition)\n            else:\n                for p, glyphs_w_pt in anchor_cache.items():\n                    anchor = parser.ast.Anchor(p[0], p[1], location=None)\n                    self._addGlyphsToClass(parser, glyphs_w_pt, gcb, anchor, parser.ast.BaseClassDefinition)\n                for p, glyphs_w_pt in markanchor_cache.items():\n                    anchor = parser.ast.Anchor(p[0], p[1], location=None)\n                    self._addGlyphsToClass(parser, glyphs_w_pt, gcm, anchor, parser.ast.BaseClassDefinition)",
  "def sortkey(x):\n            key1 = 'c_' + x[4:] if x.startswith('cno_') else x\n            return (key1, x)",
  "def doit(args) :\n    logger = args.logger\n\n    if args.mapping is None and args.ttf is None:\n        logger.log(\"One or both of -m and -f must be provided\", \"S\")\n    featdoc = ET.parse(args.input)\n    root = featdoc.getroot()\n    if root.tag != 'all_features':\n        logger.log(\"Invalid TypeTuner feature file: missing root element\", \"S\")\n\n    # Whitespace to add after each new alias:\n    tail = '\\n\\t\\t'\n\n    # Find or add alliaes element\n    aliases = root.find('aliases')\n    if aliases is None:\n        aliases = ET.SubElement(root,'aliases')\n        aliases.tail = '\\n'\n\n    added = set()\n    duplicates = set()\n    def setalias(name, value):\n        # detect duplicate names in input\n        if name in added:\n            duplicates.add(name)\n        else:\n            added.add(name)\n        # modify existing or add new alias\n        alias = aliases.find('alias[@name=\"{}\"]'.format(name))\n        if alias is None:\n            alias = ET.SubElement(aliases, 'alias', {'name': name, 'value': value})\n            alias.tail = tail\n        else:\n            alias.set('value', value)\n\n    # Process mapping file if present:\n    if args.mapping:\n        # Mapping file is assumed to come from psfbuildfea, and should look like:\n        #      lookupname,table,index\n        # e.g. DigitAlternates,GSUB,51\n        for (name,table,value) in args.mapping:\n            setalias(name, value)\n\n    # Process the ttf file if present\n    if args.ttf:\n        # Generate aliases for features.\n        # In this code featureID means the key used in FontUtils for finding the feature, e.g., \"calt _2\"\n        def dotable(t):     # Common routine for GPOS and GSUB\n            currtag = None\n            currtagindex = None\n            flist = []     # list, in order, of (featureTag, featureID), per Font::TTF\n            for i in range(0,t.FeatureList.FeatureCount):\n                newtag = str(t.FeatureList.FeatureRecord[i].FeatureTag)\n                if currtag is None or currtag != newtag:\n                    flist.append((newtag, newtag))\n                    currtag = newtag\n                    currtagindex = 0\n                else:\n                    flist.append( (currtag, '{} _{}'.format(currtag, currtagindex)))\n                    currtagindex += 1\n            fslList = {}     # dictionary keyed by feature_script_lang values returning featureID\n            for s in t.ScriptList.ScriptRecord:\n                currtag = str(s.ScriptTag)\n                # At present only looking at the dflt lang entries\n                for findex in s.Script.DefaultLangSys.FeatureIndex:\n                    fslList['{}_{}_dflt'.format(flist[findex][0],currtag)] = flist[findex][1]\n            # Now that we have them all, add them in sorted order.\n            for name, value in sorted(fslList.items()):\n                setalias(name,value)\n\n        # Open the TTF for processing\n        try:\n            f = ttLib.TTFont(args.ttf)\n        except Exception as e:\n            logger.log(\"Couldn't open font '{}' for reading : {}\".format(args.ttf, str(e)),\"S\")\n        # Grab features from GSUB and GPOS\n        for tag in ('GSUB', 'GPOS'):\n            try:\n                dotable(f[tag].table)\n            except Exception as e:\n                logger.log(\"Failed to process {} table: {}\".format(tag, str(e)), \"W\")\n        # Grab features from Graphite:\n        try:\n            for tag in sorted(f['Feat'].features.keys()):\n                if tag == '1':\n                    continue\n                name = 'gr_' + tag\n                value = str(struct.unpack('>L', tag.encode())[0])\n                setalias(name,value)\n        except Exception as e:\n            logger.log(\"Failed to process Feat table: {}\".format(str(e)), \"W\")\n\n    if len(duplicates):\n        logger.log(\"The following aliases defined more than once in input: {}\".format(\", \".join(sorted(duplicates))), \"S\")\n\n    # Success. Write the result\n    featdoc.write(args.output, encoding='UTF-8', xml_declaration=True)",
  "def cmd() : execute(None,doit,argspec)",
  "def setalias(name, value):\n        # detect duplicate names in input\n        if name in added:\n            duplicates.add(name)\n        else:\n            added.add(name)\n        # modify existing or add new alias\n        alias = aliases.find('alias[@name=\"{}\"]'.format(name))\n        if alias is None:\n            alias = ET.SubElement(aliases, 'alias', {'name': name, 'value': value})\n            alias.tail = tail\n        else:\n            alias.set('value', value)",
  "def dotable(t):     # Common routine for GPOS and GSUB\n            currtag = None\n            currtagindex = None\n            flist = []     # list, in order, of (featureTag, featureID), per Font::TTF\n            for i in range(0,t.FeatureList.FeatureCount):\n                newtag = str(t.FeatureList.FeatureRecord[i].FeatureTag)\n                if currtag is None or currtag != newtag:\n                    flist.append((newtag, newtag))\n                    currtag = newtag\n                    currtagindex = 0\n                else:\n                    flist.append( (currtag, '{} _{}'.format(currtag, currtagindex)))\n                    currtagindex += 1\n            fslList = {}     # dictionary keyed by feature_script_lang values returning featureID\n            for s in t.ScriptList.ScriptRecord:\n                currtag = str(s.ScriptTag)\n                # At present only looking at the dflt lang entries\n                for findex in s.Script.DefaultLangSys.FeatureIndex:\n                    fslList['{}_{}_dflt'.format(flist[findex][0],currtag)] = flist[findex][1]\n            # Now that we have them all, add them in sorted order.\n            for name, value in sorted(fslList.items()):\n                setalias(name,value)",
  "def doit(args) :\n    font = args.ifont\n    outfile = args.output\n\n    # Add initial comments to outfile\n    if not args.nocomments :\n        outfile.write(\"# \" + datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S \") + args.cmdlineargs[0] + \"\\n\")\n        outfile.write(\"# \"+\" \".join(args.cmdlineargs[1:])+\"\\n\\n\")\n\n    glyphlist = font.deflayer.keys()\n    missingnames = False\n\n    for glyphn in glyphlist :\n        glyph = font.deflayer[glyphn]\n        # Find PSname if present\n        PSname = None\n        if \"lib\" in glyph :\n            lib = glyph[\"lib\"]\n            if \"public.postscriptname\" in lib : PSname = lib[\"public.postscriptname\"][1].text\n        if PSname:\n            outfile.write(glyphn + \",\" + PSname + \"\\n\")\n        else :\n            font.logger(\"No psname for \" + glyphn, \"W\")\n            missingnames = True\n    if missingnames : font.logger(\"Some glyphs had no psnames - see log file\",\"E\")\n    return",
  "def cmd() : execute(\"UFO\",doit,argspec)",
  "def doit(args) :\n    infont = args.ifont\n    if args.report: infont.logger.loglevel = args.report\n    glyphcount = 0\n\n    try:\n        for g in ET.parse(args.anchorinfo).getroot().findall('glyph'): ###\n            glyphcount += 1\n            gname = g.get('PSName')\n            if gname not in infont.deflayer.keys():\n                infont.logger.log(\"glyph element number \" + str(glyphcount) + \": \" + gname + \" not in font, so skipping anchor data\", \"W\")\n                continue\n            # anchors currently in font for this glyph\n            glyph = infont.deflayer[gname]\n            if args.delete:\n                glyph['anchor'].clear()\n            anchorsinfont = set([ ( a.element.get('name'), a.element.get('x'), a.element.get('y') ) for a in glyph['anchor']])\n            # anchors in XML file to be added\n            anchorstoadd = set()\n            for p in g.findall('point'):\n                name = p.get('type')\n                x = p[0].get('x')               # assume subelement location is first child\n                y = p[0].get('y')\n                if name and x and y:\n                    anchorstoadd.add( (name, x, y) )\n                else:\n                    infont.logger.log(\"Incomplete information for anchor '\" + name + \"' for glyph \" + gname, \"E\")\n            # compare sets\n            if anchorstoadd == anchorsinfont:\n                if len(anchorstoadd) > 0:\n                    infont.logger.log(\"Anchors in file already in font for glyph \" + gname + \": \" + str(anchorstoadd), \"V\")\n                else:\n                    infont.logger.log(\"No anchors in file or in font for glyph \" + gname, \"V\")\n            else:\n                infont.logger.log(\"Anchors in file for glyph \" + gname + \": \" + str(anchorstoadd), \"I\")\n                infont.logger.log(\"Anchors in font for glyph \" + gname + \": \" + str(anchorsinfont), \"I\")\n                for name,x,y in anchorstoadd:\n                    # if anchor being added exists in font already, delete it first\n                    ancnames = [a.element.get('name') for a in glyph['anchor']]\n                    infont.logger.log(str(ancnames), \"V\") ###\n                    if name in ancnames:\n                        infont.logger.log(\"removing anchor \" + name + \", index \" + str(ancnames.index(name)), \"V\") ###\n                        glyph.remove('anchor', ancnames.index(name))\n                    infont.logger.log(\"adding anchor \" + name + \": (\" + x + \", \" + y + \")\", \"V\") ###\n                    glyph.add('anchor', {'name': name, 'x': x, 'y': y})\n        # If analysis only, return without writing output font\n        if args.analysis: return\n        # Return changed font and let execute() write it out\n        return infont\n    except ET.ParseError as mess:\n        infont.logger.log(\"Error parsing XML input file: \" + str(mess), \"S\")\n        return",
  "def cmd() : execute(\"UFO\",doit,argspec)",
  "class lz4tuple(object) :\n    def __init__(self, start) :\n        self.start = start\n        self.literal = start\n        self.literal_len = 0\n        self.match_dist = 0\n        self.match_len = 0\n        self.end = 0\n\n    def __str__(self) :\n        return \"lz4tuple(@{},{}+{},-{}+{})={}\".format(self.start, self.literal, self.literal_len, self.match_dist, self.match_len, self.end)",
  "def read_literal(t, dat, start, datlen) :\n    if t == 15 and start < datlen :\n        v = ord(dat[start:start+1])\n        t += v\n        while v == 0xFF and start < datlen :\n            start += 1\n            v = ord(dat[start:start+1])\n            t += v\n        start += 1\n    return (t, start)",
  "def write_literal(num, shift) :\n    res = []\n    if num > 14 :\n        res.append(15 << shift)\n        num -= 15\n        while num > 255 :\n            res.append(255)\n            num -= 255\n        res.append(num)\n    else :\n        res.append(num << shift)\n    return bytearray(res)",
  "def parseTuple(dat, start, datlen) :\n    res = lz4tuple(start)\n    token = ord(dat[start:start+1])\n    (res.literal_len, start) = read_literal(token >> 4, dat, start+1, datlen)\n    res.literal = start\n    start += res.literal_len\n    res.end = start\n    if start > datlen - 2 : \n        return res\n    res.match_dist = ord(dat[start:start+1]) + (ord(dat[start+1:start+2]) << 8)\n    start += 2\n    (res.match_len, start) = read_literal(token & 0xF, dat, start, datlen)\n    res.end = start\n    return res",
  "def compressGr(dat, version) :\n    if ord(dat[1:2]) < version :\n        vstr = bytes([version]) if sys.version_info.major > 2 else chr(version)\n        dat = dat[0:1] + vstr + dat[2:]\n    datc = lz4.block.compress(dat[:-4], mode='high_compression', compression=16, store_size=False)\n    # now find the final tuple\n    end = len(datc)\n    start = 0\n    curr = lz4tuple(start)\n    while curr.end < end :\n        start = curr.end\n        curr = parseTuple(datc, start, end)\n    if curr.end > end :\n        print(\"Sync error: {!s}\".format(curr))\n    newend = write_literal(curr.literal_len + 4, 4) + datc[curr.literal:curr.literal+curr.literal_len+1] + dat[-4:]\n    lz4hdr = struct.pack(\">L\", (1 << 27) + (len(dat) & 0x7FFFFFF))\n    return dat[0:4] + lz4hdr + datc[0:curr.start] + newend",
  "def doit(args) :\n    infont = args.ifont\n    for tag, version in (('Silf', 5), ('Glat', 3)) :\n        dat = infont.getTableData(tag)\n        newdat = bytes(compressGr(dat, version))\n        table = DefaultTable(tag)\n        table.decompile(newdat, infont)\n        infont[tag] = table\n    return infont",
  "def cmd() : execute('FT', doit, argspec)",
  "def __init__(self, start) :\n        self.start = start\n        self.literal = start\n        self.literal_len = 0\n        self.match_dist = 0\n        self.match_len = 0\n        self.end = 0",
  "def __str__(self) :\n        return \"lz4tuple(@{},{}+{},-{}+{})={}\".format(self.start, self.literal, self.literal_len, self.match_dist, self.match_len, self.end)",
  "class FlattenErrFilter(logging.Filter):\n    def filter(self, record):\n        return not record.getMessage().startswith(\"Number of components differ between UFO and TTF\")",
  "def doit(args):\n    ufo = defcon.Font(args.iufo)\n\n    # if style is Regular and there are no openTypeNameRecords defining the full name (ID=4), then\n    # add one so that \"Regular\" is omitted from the fullname\n    if ufo.info.styleName == 'Regular':\n        if ufo.info.openTypeNameRecords is None:\n            ufo.info.openTypeNameRecords = []\n        fullNameRecords = [ nr for nr in ufo.info.openTypeNameRecords if nr['nameID'] == 4]\n        if not len(fullNameRecords):\n            ufo.info.openTypeNameRecords.append( { 'nameID': 4, 'platformID': 3, 'encodingID': 1, 'languageID': 1033, 'string': ufo.info.familyName } )\n\n#    args.logger.log('Converting UFO to ttf and compiling fea')\n#    font = ufo2ft.compileTTF(ufo,\n#        glyphOrder = ufo.lib.get(PUBLIC_PREFIX + 'glyphOrder'),\n#        useProductionNames = False)\n\n    args.logger.log('Converting UFO to ttf without OT', 'P')\n\n    # default arg value for TTFPreProcessor class: removeOverlaps = False, convertCubics = True\n    preProcessor = ufo2ft.preProcessor.TTFPreProcessor(ufo, removeOverlaps = args.removeOverlaps, convertCubics=True,\n                                                       flattenComponents = True,\n                                                       skipExportGlyphs = ufo.lib.get(\"public.skipExportGlyphs\", []))\n\n    # Need to handle cases if filters that are used are set in com.github.googlei18n.ufo2ft.filters with lib.plist\n    dc = dtc = ftpos = None\n    for (i,filter) in enumerate(preProcessor.preFilters):\n        if isinstance(filter, ufo2ft.filters.decomposeComponents.DecomposeComponentsFilter):\n            dc = True\n        if isinstance(filter, ufo2ft.filters.decomposeTransformedComponents.DecomposeTransformedComponentsFilter):\n            dtc = True\n        if isinstance(filter, ufo2ft.filters.flattenComponents.FlattenComponentsFilter):\n            ftpos = i\n    # Add decomposeComponents if --decomposeComponents is used\n    if args.decomposeComponents and not dc: preProcessor.preFilters.append(\n        ufo2ft.filters.decomposeComponents.DecomposeComponentsFilter())\n    # Add decomposeTransformedComponents if not already set via lib.plist\n    if not dtc: preProcessor.preFilters.append(ufo2ft.filters.decomposeTransformedComponents.DecomposeTransformedComponentsFilter())\n    # Remove flattenComponents if set via lib.plist since we set it via flattenComponents = True when setting up the preprocessor\n    if ftpos: preProcessor.preFilters.pop(ftpos)\n\n    glyphSet = preProcessor.process()\n    outlineCompiler = ufo2ft.outlineCompiler.OutlineTTFCompiler(ufo,\n        glyphSet=glyphSet,\n        glyphOrder=ufo.lib.get(PUBLIC_PREFIX + 'glyphOrder'))\n    font = outlineCompiler.compile()\n\n    # handle uvs glyphs until ufo2ft does it for us.\n    if 'public.unicodeVariationSequences' not in ufo.lib:\n        uvsdict = getuvss(ufo)\n        if len(uvsdict):\n            from fontTools.ttLib.tables._c_m_a_p import cmap_format_14\n            cmap_uvs = cmap_format_14(14)\n            cmap_uvs.platformID = 0\n            cmap_uvs.platEncID = 5\n            cmap_uvs.cmap = {}\n            cmap_uvs.uvsDict = uvsdict\n            font['cmap'].tables.append(cmap_uvs)\n\n    args.logger.log('Saving ttf file', 'P')\n    font.save(args.ottf)\n\n    args.logger.log('Done', 'P')",
  "def getuvss(ufo):\n    uvsdict = {}\n    uvs = ufo.lib.get('org.sil.variationSequences', None)\n    if uvs is not None:\n        for usv, dat in uvs.items():\n            usvc = int(usv, 16)\n            pairs = []\n            uvsdict[usvc] = pairs\n            for k, v in dat.items():\n                pairs.append((int(k, 16), v))\n        return uvsdict\n    for g in ufo:\n        uvs = getattr(g, 'lib', {}).get(\"org.sil.uvs\", None)\n        if uvs is None:\n            continue\n        codes = [int(x, 16) for x in uvs.split()]\n        if codes[1] not in uvsdict:\n            uvsdict[codes[1]] = []\n        uvsdict[codes[1]].append((codes[0], (g.name if codes[0] not in g.unicodes else None)))\n    return uvsdict",
  "def cmd(): execute(None, doit, argspec)",
  "def filter(self, record):\n        return not record.getMessage().startswith(\"Number of components differ between UFO and TTF\")",
  "def doit(args):\n    ufo = defcon.Font(args.iufo)\n    ttf = fontTools.ttLib.TTFont(args.ittf)\n    \n    args.logger.log('Renaming the input ttf glyphs based on production names in the UFO', 'P')\n    postProcessor = ufo2ft.PostProcessor(ttf, ufo)\n    ttf = postProcessor.process(useProductionNames=True, optimizeCFF=False)\n    \n    args.logger.log('Saving the output ttf file', 'P')\n    ttf.save(args.ottf)\n    \n    args.logger.log('Done', 'P')",
  "def cmd(): execute(None, doit, argspec)",
  "def doit(args) :\n    font = args.ifont\n    listinput = args.input\n    logger = args.logger\n\n    glyphlist = []\n    for line in listinput.readlines():\n        glyphlist.append(line.strip())\n\n    deletelist = []\n\n    if args.reverse:\n        for glyphname in font.deflayer:\n            if glyphname not in glyphlist:\n                deletelist.append(glyphname)\n    else:\n        for glyphname in font.deflayer:\n            if glyphname in glyphlist:\n                deletelist.append(glyphname)\n\n    secondarylayers = [x for x in font.layers if x.layername != \"public.default\"]\n\n    liststocheck = ('public.glyphOrder', 'public.postscriptNames', 'com.schriftgestaltung.glyphOrder')\n    liblists = [[],[],[]]; inliblists = [[],[],[]]\n    if hasattr(font, 'lib'):\n        for (i,listn) in enumerate(liststocheck):\n            if listn in font.lib:\n                liblists[i] = font.lib.getval(listn)\n    else:\n        logger.log(\"No lib.plist found in font\", \"W\")\n\n    # Now loop round deleting the glyphs etc\n    logger.log(\"Deleted glyphs:\", \"I\")\n\n    # With groups and kerning, create dicts representing then plists (to make deletion of members easier) and indexes by glyph/member name\n    kgroupprefixes = {\"public.kern1.\": 1, \"public.kern2.\": 2}\n    gdict = {}\n    kdict = {}\n    groupsbyglyph = {}\n    ksetsbymember = {}\n\n    groups = font.groups if hasattr(font, \"groups\") else []\n    kerning = font.kerning if hasattr(font, \"kerning\") else []\n    if groups:\n        for gname in groups:\n            group = groups.getval(gname)\n            gdict[gname] = group\n            for glyph in group:\n                if glyph in groupsbyglyph:\n                    groupsbyglyph[glyph].append(gname)\n                else:\n                    groupsbyglyph[glyph] = [gname]\n    if kerning:\n        for setname in kerning:\n            kset = kerning.getval(setname)\n            kdict[setname] = kset\n            for member in kset:\n                if member in ksetsbymember:\n                    ksetsbymember[member].append(setname)\n                else:\n                    ksetsbymember[member] = [setname]\n\n    # Loop round doing the deleting\n    for glyphn in sorted(deletelist):\n        # Delete from all layers\n        font.deflayer.delGlyph(glyphn)\n        deletedfrom = \"Default layer\"\n        for layer in secondarylayers:\n            if glyphn in layer:\n                deletedfrom += \", \" + layer.layername\n                layer.delGlyph(glyphn)\n        # Check to see if the deleted glyph is in any of liststocheck\n        stillin = None\n        for (i, liblist) in enumerate(liblists):\n            if glyphn in liblist:\n                inliblists[i].append(glyphn)\n                stillin = stillin + \", \" + liststocheck[i] if stillin else liststocheck[i]\n\n        logger.log(\"  \" + glyphn + \" deleted from: \" + deletedfrom, \"I\")\n        if stillin: logger.log(\"  \" + glyphn + \" is still in \" + stillin, \"I\")\n\n        # Process groups.plist and kerning.plist\n\n        tocheck = (glyphn, \"public.kern1.\" + glyphn, \"public.kern2.\" + glyphn)\n        # First delete whole groups and kern pair sets\n        for kerngroup in tocheck[1:]: # Don't check glyphn when deleting groups:\n            if kerngroup in gdict: gdict.pop(kerngroup)\n        for setn in tocheck:\n            if setn in kdict: kdict.pop(setn)\n        # Now delete members within groups and kern pair sets\n        if glyphn in groupsbyglyph:\n            for groupn in groupsbyglyph[glyphn]:\n                if groupn in gdict: # Need to check still there, since whole group may have been deleted above\n                    group = gdict[groupn]\n                    del group[group.index(glyphn)]\n        for member in tocheck:\n            if member in ksetsbymember:\n                for setn in ksetsbymember[member]:\n                    if setn in kdict: del kdict[setn][member]\n        # Now need to recreate groups.plist and kerning.plist\n        if groups:\n            for group in list(groups): groups.remove(group)  # Empty existing contents\n            for gname in gdict:\n                elem = ET.Element(\"array\")\n                if gdict[gname]: # Only create if group is not empty\n                    for glyph in gdict[gname]:\n                        ET.SubElement(elem, \"string\").text = glyph\n                    groups.setelem(gname, elem)\n        if kerning:\n            for kset in list(kerning): kerning.remove(kset)  # Empty existing contents\n            for kset in kdict:\n                elem = ET.Element(\"dict\")\n                if kdict[kset]:\n                    for member in kdict[kset]:\n                        ET.SubElement(elem, \"key\").text = member\n                        ET.SubElement(elem, \"integer\").text = str(kdict[kset][member])\n                    kerning.setelem(kset, elem)\n\n    logger.log(str(len(deletelist)) + \" glyphs deleted. Set logging to I to see details\", \"P\")\n    inalist = set(inliblists[0] + inliblists[1] + inliblists[2])\n    if inalist: logger.log(str(len(inalist)) + \" of the deleted glyphs are still in some lib.plist entries.\", \"W\")\n\n    return font",
  "def cmd() : execute(\"UFO\",doit,argspec)"
]