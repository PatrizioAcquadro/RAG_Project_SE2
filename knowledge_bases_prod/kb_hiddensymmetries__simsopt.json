[
  "class CMakeExtension(Extension):\n    def __init__(self, name, sourcedir=\"\"):\n        Extension.__init__(self, name, sources=[])\n        self.sourcedir = os.path.abspath(sourcedir)",
  "class CMakeBuild(build_ext):\n    # debug: bool = True\n    def build_extension(self, ext):\n        extdir = os.path.abspath(os.path.dirname(self.get_ext_fullpath(ext.name)))\n\n        # required for auto-detection of auxiliary \"native\" libs\n        if not extdir.endswith(os.path.sep):\n            extdir += os.path.sep\n\n        cfg = \"Debug\" if self.debug else \"Release\"\n        cfg = os.getenv(\"CMAKE_BUILD_TYPE\", cfg)\n        print(f\"Choose CMAKE_BUILD_TYPE={cfg}\", flush=True)\n\n        # CMake lets you override the generator - we need to check this.\n        # Can be set with Conda-Build, for example.\n        cmake_generator = os.environ.get(\"CMAKE_GENERATOR\", \"\")\n\n        # Set Python_EXECUTABLE instead if you use PYBIND11_FINDPYTHON\n        # EXAMPLE_VERSION_INFO shows you how to pass a value into the C++ code\n        # from Python.\n\n        PYTHON_ROOT = str((Path(sys.executable).parent / \"..\").resolve())\n        cmake_args = [\n            \"-DCMAKE_LIBRARY_OUTPUT_DIRECTORY={}\".format(extdir),\n            \"-DPYTHON_EXECUTABLE={}\".format(sys.executable),\n            \"-DEXAMPLE_VERSION_INFO={}\".format(self.distribution.get_version()),\n            \"-DCMAKE_BUILD_TYPE={}\".format(cfg),  # not used on MSVC, but no harm\n            \"-DPython_ROOT_DIR={}\".format(PYTHON_ROOT),\n        ]\n        build_args = []\n\n        if self.compiler.compiler_type != \"msvc\":\n            # Using Ninja-build since it a) is available as a wheel and b)\n            # multithreads automatically. MSVC would require all variables be\n            # exported for Ninja to pick it up, which is a little tricky to do.\n            # Users can override the generator with CMAKE_GENERATOR in CMake\n            # 3.15+.\n            if not cmake_generator:\n                cmake_args += [\"-GNinja\"]\n\n        else:\n\n            # Single config generators are handled \"normally\"\n            single_config = any(x in cmake_generator for x in {\"NMake\", \"Ninja\"})\n\n            # CMake allows an arch-in-generator style for backward compatibility\n            contains_arch = any(x in cmake_generator for x in {\"ARM\", \"Win64\"})\n\n            # Specify the arch if using MSVC generator, but only if it doesn't\n            # contain a backward-compatibility arch spec already in the\n            # generator name.\n            if not single_config and not contains_arch:\n                cmake_args += [\"-A\", PLAT_TO_CMAKE[self.plat_name]]\n\n            # Multi-config generators have a different way to specify configs\n            if not single_config:\n                cmake_args += [\n                    \"-DCMAKE_LIBRARY_OUTPUT_DIRECTORY_{}={}\".format(cfg.upper(), extdir)\n                ]\n                build_args += [\"--config\", cfg]\n\n        # Set CMAKE_BUILD_PARALLEL_LEVEL to control the parallel build level\n        # across all generators.\n        if \"CMAKE_BUILD_PARALLEL_LEVEL\" not in os.environ:\n            # self.parallel is a Python 3 only way to set parallel jobs by hand\n            # using -j in the build_ext call, not supported by pip or PyPA-build.\n            if hasattr(self, \"parallel\") and self.parallel:\n                # CMake 3.12+ only.\n                build_args += [\"-j{}\".format(self.parallel)]\n\n        if not os.path.exists(self.build_temp):\n            os.makedirs(self.build_temp)\n\n        subprocess.check_call(\n            [\"cmake\", ext.sourcedir] + cmake_args, cwd=self.build_temp\n        )\n        subprocess.check_call(\n            [\"cmake\", \"--build\", \".\", \"--target\", \"simsoptpp\"] + build_args, cwd=self.build_temp\n        )",
  "def my_local_scheme(version: setuptools_scm.version.ScmVersion) -> str:\n    \"\"\"My local node and date version.\"\"\"\n    node_and_date = setuptools_scm.version.get_local_node_and_date(version)\n    dirty = \".dirty\" if version.dirty else \"\"\n    return str(node_and_date) + dirty",
  "def __init__(self, name, sourcedir=\"\"):\n        Extension.__init__(self, name, sources=[])\n        self.sourcedir = os.path.abspath(sourcedir)",
  "def build_extension(self, ext):\n        extdir = os.path.abspath(os.path.dirname(self.get_ext_fullpath(ext.name)))\n\n        # required for auto-detection of auxiliary \"native\" libs\n        if not extdir.endswith(os.path.sep):\n            extdir += os.path.sep\n\n        cfg = \"Debug\" if self.debug else \"Release\"\n        cfg = os.getenv(\"CMAKE_BUILD_TYPE\", cfg)\n        print(f\"Choose CMAKE_BUILD_TYPE={cfg}\", flush=True)\n\n        # CMake lets you override the generator - we need to check this.\n        # Can be set with Conda-Build, for example.\n        cmake_generator = os.environ.get(\"CMAKE_GENERATOR\", \"\")\n\n        # Set Python_EXECUTABLE instead if you use PYBIND11_FINDPYTHON\n        # EXAMPLE_VERSION_INFO shows you how to pass a value into the C++ code\n        # from Python.\n\n        PYTHON_ROOT = str((Path(sys.executable).parent / \"..\").resolve())\n        cmake_args = [\n            \"-DCMAKE_LIBRARY_OUTPUT_DIRECTORY={}\".format(extdir),\n            \"-DPYTHON_EXECUTABLE={}\".format(sys.executable),\n            \"-DEXAMPLE_VERSION_INFO={}\".format(self.distribution.get_version()),\n            \"-DCMAKE_BUILD_TYPE={}\".format(cfg),  # not used on MSVC, but no harm\n            \"-DPython_ROOT_DIR={}\".format(PYTHON_ROOT),\n        ]\n        build_args = []\n\n        if self.compiler.compiler_type != \"msvc\":\n            # Using Ninja-build since it a) is available as a wheel and b)\n            # multithreads automatically. MSVC would require all variables be\n            # exported for Ninja to pick it up, which is a little tricky to do.\n            # Users can override the generator with CMAKE_GENERATOR in CMake\n            # 3.15+.\n            if not cmake_generator:\n                cmake_args += [\"-GNinja\"]\n\n        else:\n\n            # Single config generators are handled \"normally\"\n            single_config = any(x in cmake_generator for x in {\"NMake\", \"Ninja\"})\n\n            # CMake allows an arch-in-generator style for backward compatibility\n            contains_arch = any(x in cmake_generator for x in {\"ARM\", \"Win64\"})\n\n            # Specify the arch if using MSVC generator, but only if it doesn't\n            # contain a backward-compatibility arch spec already in the\n            # generator name.\n            if not single_config and not contains_arch:\n                cmake_args += [\"-A\", PLAT_TO_CMAKE[self.plat_name]]\n\n            # Multi-config generators have a different way to specify configs\n            if not single_config:\n                cmake_args += [\n                    \"-DCMAKE_LIBRARY_OUTPUT_DIRECTORY_{}={}\".format(cfg.upper(), extdir)\n                ]\n                build_args += [\"--config\", cfg]\n\n        # Set CMAKE_BUILD_PARALLEL_LEVEL to control the parallel build level\n        # across all generators.\n        if \"CMAKE_BUILD_PARALLEL_LEVEL\" not in os.environ:\n            # self.parallel is a Python 3 only way to set parallel jobs by hand\n            # using -j in the build_ext call, not supported by pip or PyPA-build.\n            if hasattr(self, \"parallel\") and self.parallel:\n                # CMake 3.12+ only.\n                build_args += [\"-j{}\".format(self.parallel)]\n\n        if not os.path.exists(self.build_temp):\n            os.makedirs(self.build_temp)\n\n        subprocess.check_call(\n            [\"cmake\", ext.sourcedir] + cmake_args, cwd=self.build_temp\n        )\n        subprocess.check_call(\n            [\"cmake\", \"--build\", \".\", \"--target\", \"simsoptpp\"] + build_args, cwd=self.build_temp\n        )",
  "class CurveRZFourier(sopp.CurveRZFourier, Curve):\n    r\"\"\"\n    ``CurveRZFourier`` is a curve that is represented in cylindrical\n    coordinates using the following Fourier series:\n\n    .. math::\n       r(\\phi) &= \\sum_{m=0}^{\\text{order}} r_{c,m}\\cos(n_{\\text{fp}} m \\phi) + \\sum_{m=1}^{\\text{order}} r_{s,m}\\sin(n_{\\text{fp}} m \\phi) \\\\\n       z(\\phi) &= \\sum_{m=0}^{\\text{order}} z_{c,m}\\cos(n_{\\text{fp}} m \\phi) + \\sum_{m=1}^{\\text{order}} z_{s,m}\\sin(n_{\\text{fp}} m \\phi)\n\n    If ``stellsym = True``, then the :math:`\\sin` terms for :math:`r` and the :math:`\\cos` terms for :math:`z` are zero.\n\n    For the ``stellsym = False`` case, the dofs are stored in the order\n\n    .. math::\n       [r_{c,0}, \\cdots, r_{c,\\text{order}}, r_{s,1}, \\cdots, r_{s,\\text{order}}, z_{c,0},....]\n\n    or in the ``stellsym = True`` case they are stored\n\n    .. math::\n       [r_{c,0},...,r_{c,order},z_{s,1},...,z_{s,order}]\n    \"\"\"\n\n    def __init__(self, quadpoints, order, nfp, stellsym, dofs=None):\n        if isinstance(quadpoints, int):\n            quadpoints = list(np.linspace(0, 1./nfp, quadpoints, endpoint=False))\n        elif isinstance(quadpoints, np.ndarray):\n            quadpoints = list(quadpoints)\n        sopp.CurveRZFourier.__init__(self, quadpoints, order, nfp, stellsym)\n        if dofs is None:\n            Curve.__init__(self, external_dof_setter=CurveRZFourier.set_dofs_impl,\n                           x0=self.get_dofs())\n        else:\n            Curve.__init__(self, external_dof_setter=CurveRZFourier.set_dofs_impl,\n                           dofs=dofs)\n\n    def get_dofs(self):\n        \"\"\"\n        This function returns the dofs associated to this object.\n        \"\"\"\n        return np.asarray(sopp.CurveRZFourier.get_dofs(self))\n\n    def set_dofs(self, dofs):\n        \"\"\"\n        This function sets the dofs associated to this object.\n        \"\"\"\n        self.local_x = dofs\n        sopp.CurveRZFourier.set_dofs(self, dofs)",
  "def __init__(self, quadpoints, order, nfp, stellsym, dofs=None):\n        if isinstance(quadpoints, int):\n            quadpoints = list(np.linspace(0, 1./nfp, quadpoints, endpoint=False))\n        elif isinstance(quadpoints, np.ndarray):\n            quadpoints = list(quadpoints)\n        sopp.CurveRZFourier.__init__(self, quadpoints, order, nfp, stellsym)\n        if dofs is None:\n            Curve.__init__(self, external_dof_setter=CurveRZFourier.set_dofs_impl,\n                           x0=self.get_dofs())\n        else:\n            Curve.__init__(self, external_dof_setter=CurveRZFourier.set_dofs_impl,\n                           dofs=dofs)",
  "def get_dofs(self):\n        \"\"\"\n        This function returns the dofs associated to this object.\n        \"\"\"\n        return np.asarray(sopp.CurveRZFourier.get_dofs(self))",
  "def set_dofs(self, dofs):\n        \"\"\"\n        This function sets the dofs associated to this object.\n        \"\"\"\n        self.local_x = dofs\n        sopp.CurveRZFourier.set_dofs(self, dofs)",
  "def jaxHelicalfouriercurve_pure(dofs, quadpoints, order, n0, l0, R0, r0):\n    A = dofs[:order]\n    B = dofs[order:]\n    phi = quadpoints*2*pi*l0\n    m, phiV = jnp.meshgrid(jnp.arange(order), phi)\n    AcosArray = jnp.sum(A*jnp.cos(m*phiV*n0/l0), axis=1)\n    BsinArray = jnp.sum(B*jnp.sin(m*phiV*n0/l0), axis=1)\n    eta = n0*phi/l0+AcosArray+BsinArray\n    gamma = jnp.zeros((len(quadpoints), 3))\n    gamma = gamma.at[:, 0].add((R0 + r0 * jnp.cos(eta)) * jnp.cos(phi))\n    gamma = gamma.at[:, 1].add((R0 + r0 * jnp.cos(eta)) * jnp.sin(phi))\n    gamma = gamma.at[:, 2].add(-r0 * jnp.sin(eta))\n    return gamma",
  "class CurveHelical(JaxCurve):\n    r'''Curve representation of a helical coil.\n    The helical coil positions are specified by a poloidal angle eta that is a function of the toroidal angle phi with Fourier coefficients :math:`A_k` and :math:`B_k`.\n    The poloidal angle is represented as \n\n    .. math:: \n        \\eta = m_0 \\phi/l_0 + \\sum_k A_k \\cos(n_0 \\phi k/l_0) + B_k \\sin(n_0 \\phi k/l_0)\n\n    Args:\n        quadpoints: number of grid points/resolution along the curve;\n        order:  number of fourier coefficients, i.e., the length of the array A (or B);\n        n0:  toroidal periodicity/number of field periods\n        l0:  number of :math:`2\\pi` turns in :math:`\\phi`\n        R0:  major radius\n        r0:  minor radius\n    '''\n\n    def __init__(self, quadpoints, order, n0, l0, R0, r0, **kwargs):\n        if isinstance(quadpoints, int):\n            quadpoints = np.linspace(0, 1, quadpoints, endpoint=False)\n        pure = lambda dofs, points: jaxHelicalfouriercurve_pure(\n            dofs, points, order, n0, l0, R0, r0)\n        self.order = order\n        self.n0 = n0\n        self.l0 = l0\n        self.R0 = R0\n        self.r0 = r0\n        self.coefficients = [np.zeros((order,)), np.zeros((order,))]\n        if \"dofs\" not in kwargs:\n            if \"x0\" not in kwargs:\n                kwargs[\"x0\"] = np.concatenate(self.coefficients)\n            else:\n                self.set_dofs_impl(kwargs[\"x0\"])\n\n        super().__init__(quadpoints, pure, **kwargs)\n\n    def num_dofs(self):\n        return 2*self.order\n\n    def get_dofs(self):\n        return np.concatenate(self.coefficients)\n\n    def set_dofs_impl(self, dofs):\n        order = int(len(dofs)/2)\n        for i in range(2):\n            self.coefficients[i] = dofs[i*order:(i+1)*order]",
  "def __init__(self, quadpoints, order, n0, l0, R0, r0, **kwargs):\n        if isinstance(quadpoints, int):\n            quadpoints = np.linspace(0, 1, quadpoints, endpoint=False)\n        pure = lambda dofs, points: jaxHelicalfouriercurve_pure(\n            dofs, points, order, n0, l0, R0, r0)\n        self.order = order\n        self.n0 = n0\n        self.l0 = l0\n        self.R0 = R0\n        self.r0 = r0\n        self.coefficients = [np.zeros((order,)), np.zeros((order,))]\n        if \"dofs\" not in kwargs:\n            if \"x0\" not in kwargs:\n                kwargs[\"x0\"] = np.concatenate(self.coefficients)\n            else:\n                self.set_dofs_impl(kwargs[\"x0\"])\n\n        super().__init__(quadpoints, pure, **kwargs)",
  "def num_dofs(self):\n        return 2*self.order",
  "def get_dofs(self):\n        return np.concatenate(self.coefficients)",
  "def set_dofs_impl(self, dofs):\n        order = int(len(dofs)/2)\n        for i in range(2):\n            self.coefficients[i] = dofs[i*order:(i+1)*order]",
  "class SurfaceHenneberg(sopp.Surface, Surface):\n    r\"\"\"\n    This class represents a toroidal surface using the\n    parameterization in Henneberg, Helander, and Drevlak, Journal of\n    Plasma Physics 87, 905870503 (2021). The main benefit of this\n    representation is that there is no freedom in the poloidal angle,\n    i.e. :math:`\\theta` is uniquely defined, in contrast to other\n    parameterizations like\n    :obj:`~.surfacerzfourier.SurfaceRZFourier`. Stellarator symmetry\n    is assumed.\n\n    In this representation by Henneberg et al, the cylindrical\n    coordinates :math:`(R,\\phi,Z)` are written in terms of a unique\n    poloidal angle :math:`\\theta` as follows:\n\n    .. math::\n        R(\\theta,\\phi) = R_0^H(\\phi) + \\rho(\\theta,\\phi) \\cos(\\alpha\\phi) - \\zeta(\\theta,\\phi) \\sin(\\alpha\\phi), \\\\\n        Z(\\theta,\\phi) = Z_0^H(\\phi) + \\rho(\\theta,\\phi) \\sin(\\alpha\\phi) + \\zeta(\\theta,\\phi) \\cos(\\alpha\\phi),\n\n    where\n\n    .. math::\n        R_0^H(\\phi) &=& \\sum_{n=0}^{nmax} R_{0,n}^H \\cos(n_{fp} n \\phi), \\\\\n        Z_0^H(\\phi) &=& \\sum_{n=1}^{nmax} Z_{0,n}^H \\sin(n_{fp} n \\phi), \\\\\n        \\zeta(\\theta,\\phi) &=& \\sum_{n=0}^{nmax} b_n \\cos(n_{fp} n \\phi) \\sin(\\theta - \\alpha \\phi), \\\\\n        \\rho(\\theta,\\phi) &=& \\sum_{n,m} \\rho_{n,m} \\cos(m \\theta - n_{fp} n \\phi - \\alpha \\phi).\n\n    The continuous degrees of freedom are :math:`\\{\\rho_{m,n}, b_n,\n    R_{0,n}^H, Z_{0,n}^H\\}`.  These variables correspond to the\n    attributes ``rhomn``, ``bn``, ``R0nH``, and ``Z0nH`` respectively,\n    which are all numpy arrays.  There is also a discrete degree of\n    freedom :math:`\\alpha` which should be :math:`\\pm n_{fp}/2` where\n    :math:`n_{fp}` is the number of field periods. The attribute\n    ``alpha_fac`` corresponds to :math:`2\\alpha/n_{fp}`, so\n    ``alpha_fac`` is either 1, 0, or -1. Using ``alpha_fac = 0`` is\n    appropriate for axisymmetry, while values of 1 or -1 are\n    appropriate for a stellarator, depending on the handedness of the\n    rotating elongation.\n\n    For :math:`R_{0,n}^H` and :math:`b_n`, :math:`n` is 0 or any\n    positive integer up through ``nmax`` (inclusive).  For\n    :math:`Z_{0,n}^H`, :math:`n` is any positive integer up through\n    ``nmax``.  For :math:`\\rho_{m,n}`, :math:`m` is an integer from 0\n    through ``mmax`` (inclusive). For positive values of :math:`m`,\n    :math:`n` can be any integer from ``-nmax`` through ``nmax``.  For\n    :math:`m=0`, :math:`n` is restricted to integers from 1 through\n    ``nmax``.  Note that we exclude the element of :math:`\\rho_{m,n}`\n    with :math:`m=n=0`, because this degree of freedom is already\n    represented in :math:`R_{0,0}^H`.\n\n    For the 2D array ``rhomn``, functions :func:`set_rhomn()` and\n    :func:`get_rhomn()` are provided for convenience so you can specify\n    ``n``, since the corresponding array index is shifted by\n    ``nmax``. There are no corresponding functions for the 1D arrays\n    ``R0nH``, ``Z0nH``, and ``bn`` since these arrays all have a first\n    index corresponding to ``n=0``.\n\n    For more information about the arguments ``quadpoints_phi``, and\n    ``quadpoints_theta``, see the general documentation on :ref:`surfaces`.\n    Instead of supplying the quadrature point arrays along :math:`\\phi` and\n    :math:`\\theta` directions, one could also specify the number of\n    quadrature points for :math:`\\phi` and :math:`\\theta` using the\n    class method :py:meth:`~simsopt.geo.surface.Surface.from_nphi_ntheta`.\n\n    Args:\n        nfp: The number of field periods.\n        alpha_fac: Should be +1 or -1 for a stellarator, depending on the handedness\n          by which the elongation rotates, or 0 for axisymmetry.\n        mmax: Maximum poloidal mode number included.\n        nmax: Maximum toroidal mode number included, divided by ``nfp``.\n        quadpoints_phi: Set this to a list or 1D array to set the :math:`\\phi_j` grid points directly.\n        quadpoints_theta: Set this to a list or 1D array to set the :math:`\\theta_j` grid points directly.\n    \"\"\"\n    nfp = Integer(min_value=1)\n    alpha_fac = OneofIntegers(-1, 0, 1)\n    mmax = Integer(min_value=1)\n    nmax = PositiveInteger()\n\n    def __init__(self,\n                 nfp: int = 1,\n                 alpha_fac: int = 1,\n                 mmax: int = 1,\n                 nmax: int = 0,\n                 quadpoints_phi: RealArray = None,\n                 quadpoints_theta: RealArray = None,\n                 dofs: DOFs = None):\n\n        self.nfp = nfp\n        self.alpha_fac = alpha_fac\n        self.mmax = mmax\n        self.nmax = nmax\n        self.stellsym = True\n        self.allocate()\n\n        if quadpoints_theta is None:\n            quadpoints_theta = Surface.get_theta_quadpoints()\n        if quadpoints_phi is None:\n            quadpoints_phi = Surface.get_phi_quadpoints(nfp=nfp)\n\n        sopp.Surface.__init__(self, quadpoints_phi, quadpoints_theta)\n        # Initialize to an axisymmetric torus with major radius 1m and\n        # minor radius 0.1m\n        self.R0nH[0] = 1.0\n        self.bn[0] = 0.1\n        self.set_rhomn(1, 0, 0.1)\n\n        if dofs is None:\n            Surface.__init__(self, x0=self.get_dofs(), names=self._make_names(),\n                             external_dof_setter=SurfaceHenneberg.set_dofs_impl)\n        else:\n            Surface.__init__(self, dofs=dofs,\n                             external_dof_setter=SurfaceHenneberg.set_dofs_impl)\n\n    def __repr__(self):\n        return f\"{self.name} (nfp={self.nfp}, alpha_fac={self.alpha_fac}, \" \\\n            + f\"mmax={self.mmax}, nmax={self.nmax})\"\n\n    def allocate(self):\n        \"\"\"\n        Create the arrays for the continuous degrees of freedom. Also set\n        the names of the dofs.\n        \"\"\"\n        logger.debug(\"Allocating SurfaceHenneberg\")\n        # Note that for simpicity, the Z0nH array contains an element\n        # for n=0 even though this element is always 0. Similarly, the\n        # rhomn array has some elements for (m=0, n<0) even though\n        # these elements are always zero.\n\n        self.R0nH = np.zeros(self.nmax + 1)\n        self.Z0nH = np.zeros(self.nmax + 1)\n        self.bn = np.zeros(self.nmax + 1)\n\n        self.ndim = 2 * self.nmax + 1\n        myshape = (self.mmax + 1, self.ndim)\n        self.rhomn = np.zeros(myshape)\n\n    def _make_names(self):\n        names = []\n        for n in range(self.nmax + 1):\n            names.append(f'R0nH({n})')\n        for n in range(1, self.nmax + 1):\n            names.append(f'Z0nH({n})')\n        for n in range(self.nmax + 1):\n            names.append(f'bn({n})')\n        # Handle m = 0 modes in rho_mn:\n        for n in range(1, self.nmax + 1):\n            names.append(f'rhomn(0,{n})')\n        # Handle m > 0 modes in rho_mn:\n        for m in range(1, self.mmax + 1):\n            for n in range(-self.nmax, self.nmax + 1):\n                names.append(f'rhomn({m},{n})')\n        return names\n\n    def _validate_mn(self, m, n):\n        r\"\"\"\n        Check whether given (m, n) values are allowed for :math:`\\rho_{m,n}`.\n        \"\"\"\n        if m < 0:\n            raise ValueError(f'm must be >= 0, but m = {m}')\n        if m > self.mmax:\n            raise ValueError(f'm must be <= mmax, but m = {m}')\n        if m == 0 and n < 1:\n            raise ValueError(f'For m=0, n must be >= 1, but n = {n}')\n        if n > self.nmax:\n            raise ValueError(f'n must be <= nmax, but n = {n}')\n        if n < -self.nmax:\n            raise ValueError(f'n must be >= -nmax, but n = {n}')\n\n    def get_rhomn(self, m, n):\n        r\"\"\"\n        Return a particular :math:`\\rho_{m,n}` coefficient.\n        \"\"\"\n        self._validate_mn(m, n)\n        return self.rhomn[m, n + self.nmax]\n\n    def set_rhomn(self, m, n, val):\n        r\"\"\"\n        Set a particular :math:`\\rho_{m,n}` coefficient.\n        \"\"\"\n        self._validate_mn(m, n)\n        self.rhomn[m, n + self.nmax] = val\n        self.invalidate_cache()\n\n    def get_dofs(self):\n        \"\"\"\n        Return a 1D numpy array with all the degrees of freedom.\n        \"\"\"\n        return np.concatenate((self.R0nH, self.Z0nH[1:], self.bn,\n                               self.rhomn[0, self.nmax + 1:],\n                               np.reshape(self.rhomn[1:, :], (self.mmax * (2 * self.nmax + 1),), order='C')))\n\n    def set_dofs(self, dofs):\n        self.local_x = dofs\n\n    def num_dofs(self):\n        \"\"\"\n        Return the number of degrees of freedom.\n        \"\"\"\n        ndofs = self.nmax + 1  # R0nH\n        ndofs += self.nmax  # Z0nH\n        ndofs += self.nmax + 1  # b0n\n        ndofs += self.nmax  # rhomn for m = 0\n        ndofs += self.mmax * (2 * self.nmax + 1)  # rhomn for m > 0\n\n        return ndofs\n\n    def set_dofs_impl(self, v):\n        \"\"\"\n        Set the shape coefficients from a 1D list/array\n        \"\"\"\n\n        n = self.num_dofs()\n        if len(v) != n:\n            raise ValueError('Input vector should have ' + str(n) + \\\n                             ' elements but instead has ' + str(len(v)))\n\n        index = 0\n        nvals = self.nmax + 1\n        self.R0nH = v[index: index + nvals]\n        index += nvals\n\n        nvals = self.nmax\n        self.Z0nH[1:] = v[index: index + nvals]\n        index += nvals\n\n        nvals = self.nmax + 1\n        self.bn = v[index: index + nvals]\n        index += nvals\n\n        nvals = self.nmax\n        self.rhomn[0, self.nmax + 1:] = v[index: index + nvals]\n        index += nvals\n\n        self.rhomn[1:, :] = np.reshape(v[index:], (self.mmax, 2 * self.nmax + 1), order='C')\n\n    def fixed_range(self, mmax, nmax, fixed=True):\n        \"\"\"\n        Set the ``fixed`` property for a range of ``m`` and ``n`` values.\n\n        All modes with ``m <= mmax`` and ``|n| <= nmax`` will have\n        their fixed property set to the value of the ``fixed``\n        parameter. Note that ``mmax`` and ``nmax`` are included.\n\n        Both ``mmax`` and ``nmax`` must be >= 0.\n\n        For any value of ``mmax``, the ``fixed`` properties of\n        ``R0nH``, ``Z0nH``, and ``rhomn`` are set. The ``fixed``\n        properties of ``bn`` are set only if ``mmax > 0``. In other\n        words, the ``bn`` modes are treated as having ``m=1``.\n        \"\"\"\n        if mmax < 0:\n            raise ValueError('mmax must be >= 0')\n        mmax = min(self.mmax, mmax)\n        if nmax < 0:\n            raise ValueError('nmax must be >= 0')\n        nmax = min(self.nmax, nmax)\n\n        fn = self.fix if fixed else self.unfix\n\n        for n in range(nmax + 1):\n            fn(f'R0nH({n})')\n        for n in range(1, nmax + 1):\n            fn(f'Z0nH({n})')\n        if mmax > 0:\n            for n in range(nmax + 1):\n                fn(f'bn({n})')\n\n        for m in range(mmax + 1):\n            nmin_to_use = -nmax\n            if m == 0:\n                nmin_to_use = 1\n            for n in range(nmin_to_use, nmax + 1):\n                fn(f'rhomn({m},{n})')\n\n    def to_RZFourier(self):\n        \"\"\"\n        Return a :obj:`~.surfacerzfourier.SurfaceRZFourier` object with the identical shape. This\n        routine implements eq (4.5)-(4.6) in the Henneberg paper, plus\n        m=0 terms for R0 and Z0.\n        \"\"\"\n        mpol = self.mmax\n        ntor = self.nmax + 1  # More modes are needed in the SurfaceRZFourier because some indices are shifted by +/- 2*alpha.\n        s = SurfaceRZFourier(nfp=self.nfp, stellsym=True, mpol=mpol, ntor=ntor)\n        s.rc[:] = 0.0\n        s.zs[:] = 0.0\n\n        # Set Rmn.\n        # Handle the 1d arrays (R0nH, bn):\n        for nprime in range(self.nmax + 1):\n            n = nprime\n            # Handle the R0nH term:\n            s.set_rc(0, n, s.get_rc(0, n) + self.R0nH[n])\n            # Handle the b_n term:\n            s.set_rc(1, n, s.get_rc(1, n) + 0.25 * self.bn[nprime])\n            # Handle the b_{-n} term:\n            n = -nprime\n            s.set_rc(1, n, s.get_rc(1, n) + 0.25 * self.bn[nprime])\n            # Handle the b_{n-2alpha} term:\n            n = nprime + self.alpha_fac\n            s.set_rc(1, n, s.get_rc(1, n) - 0.25 * self.bn[nprime])\n            # Handle the b_{-n+2alpha} term:\n            n = -nprime + self.alpha_fac\n            s.set_rc(1, n, s.get_rc(1, n) - 0.25 * self.bn[nprime])\n        # Handle the 2D rho terms:\n        for m in range(self.mmax + 1):\n            nmin = -self.nmax\n            if m == 0:\n                nmin = 1\n            for nprime in range(nmin, self.nmax + 1):\n                # Handle the rho_{m, -n} term:\n                n = -nprime\n                s.set_rc(m, n, s.get_rc(m, n) + 0.5 * self.get_rhomn(m, nprime))\n                # Handle the rho_{m, -n+2alpha} term:\n                n = -nprime + self.alpha_fac\n                s.set_rc(m, n, s.get_rc(m, n) + 0.5 * self.get_rhomn(m, nprime))\n\n        # Set Zmn.\n        # Handle the 1d arrays (Z0nH, bn):\n        for nprime in range(self.nmax + 1):\n            n = nprime\n            # Handle the Z0nH term:\n            s.set_zs(0, n, s.get_zs(0, n) - self.Z0nH[n])\n            # Handle the b_n term:\n            s.set_zs(1, n, s.get_zs(1, n) + 0.25 * self.bn[nprime])\n            # Handle the b_{-n} term:\n            n = -nprime\n            s.set_zs(1, n, s.get_zs(1, n) + 0.25 * self.bn[nprime])\n            # Handle the b_{n-2alpha} term:\n            n = nprime + self.alpha_fac\n            s.set_zs(1, n, s.get_zs(1, n) + 0.25 * self.bn[nprime])\n            # Handle the b_{-n+2alpha} term:\n            n = -nprime + self.alpha_fac\n            s.set_zs(1, n, s.get_zs(1, n) + 0.25 * self.bn[nprime])\n        # Handle the 2D rho terms:\n        for m in range(self.mmax + 1):\n            nmin = -self.nmax\n            if m == 0:\n                nmin = 1\n            for nprime in range(nmin, self.nmax + 1):\n                # Handle the rho_{m, -n} term:\n                n = -nprime\n                s.set_zs(m, n, s.get_zs(m, n) + 0.5 * self.get_rhomn(m, nprime))\n                # Handle the rho_{m, -n+2alpha} term:\n                n = -nprime + self.alpha_fac\n                s.set_zs(m, n, s.get_zs(m, n) - 0.5 * self.get_rhomn(m, nprime))\n\n        return s\n\n    @classmethod\n    def from_RZFourier(cls,\n                       surf,\n                       alpha_fac: int,\n                       mmax: Union[int, None] = None,\n                       nmax: Union[int, None] = None,\n                       ntheta: Union[int, None] = None,\n                       nphi: Union[int, None] = None):\n        \"\"\"\n        Convert a :obj:`~.surfacerzfourier.SurfaceRZFourier` surface to a\n        :obj:`SurfaceHenneberg` surface.\n\n        Args:\n            surf: The :obj:`~.surfacerzfourier.SurfaceRZFourier` object to convert.\n            mmax: Maximum poloidal mode number to include in the new surface. If ``None``,\n              the value ``mpol`` from the old surface will be used.\n            nmax: Maximum toroidal mode number to include in the new surface. If ``None``,\n              the value ``ntor`` from the old surface will be used.\n            ntheta: Number of grid points in the poloidal angle used for the transformation.\n              If ``None``, the value ``3 * ntheta`` will be used.\n            nphi: Number of grid points in the toroidal angle used for the transformation.\n              If ``None``, the value ``3 * nphi`` will be used.\n        \"\"\"\n        if not surf.stellsym:\n            raise RuntimeError('SurfaceHenneberg.from_RZFourier method only '\n                               'works for stellarator symmetric surfaces')\n        if mmax is None:\n            mmax = surf.mpol\n        if nmax is None:\n            nmax = surf.ntor\n        if ntheta is None:\n            ntheta = mmax * 3\n        if nphi is None:\n            nphi = nmax * 3\n        logger.info(f'Beginning conversion with mmax={mmax}, nmax={nmax}, ntheta={ntheta}, nphi={nphi}')\n        nfp = surf.nfp\n        theta = np.linspace(0, 2 * np.pi, ntheta, endpoint=False)\n        phi = np.linspace(0, 2 * np.pi / nfp, nphi, endpoint=False)\n        alpha = 0.5 * nfp * alpha_fac\n\n        # Initialize arrays to store quantities in real-space:\n        R0_realsp = np.zeros(nphi)\n        Z0_realsp = np.zeros(nphi)\n        b_realsp = np.zeros(nphi)\n        rho_realsp = np.zeros((ntheta, nphi))\n\n        def b_min(theta, phi0, cosaphi, sinaphi):\n            \"\"\"\n            This function is minimized as part of finding b.\n            \"\"\"\n            R = 0\n            Z = 0\n            for m in range(surf.mpol + 1):\n                for n in range(-surf.ntor, surf.ntor + 1):\n                    angle = m * theta - n * nfp * phi0\n                    R += surf.get_rc(m, n) * np.cos(angle)\n                    Z += surf.get_zs(m, n) * np.sin(angle)\n            return Z * cosaphi - R * sinaphi\n\n        def b_max(theta, phi0, cosaphi, sinaphi):\n            return -b_min(theta, phi0, cosaphi, sinaphi)\n\n        # An independent transformation is performed at each grid point in phi:\n        for jphi, phi0 in enumerate(phi):\n            logger.debug(f'Transforming jphi={jphi} of {nphi}')\n            cosaphi = np.cos(alpha * phi0)\n            sinaphi = np.sin(alpha * phi0)\n\n            # Find the max and min of the surface in the zeta direction:\n            opt_result = minimize_scalar(b_min, args=(phi0, cosaphi, sinaphi), tol=1e-12)\n            min_for_b = opt_result.fun\n\n            opt_result = minimize_scalar(b_max, args=(phi0, cosaphi, sinaphi), tol=1e-12)\n            max_for_b = -opt_result.fun\n\n            b = 0.5 * (max_for_b - min_for_b)\n            Q = 0.5 * (max_for_b + min_for_b)\n\n            R = np.zeros(ntheta)\n            Z = np.zeros(ntheta)\n            d_Z_d_theta = np.zeros(ntheta)\n            d_R_d_theta = np.zeros(ntheta)\n            for m in range(surf.mpol + 1):\n                for n in range(-surf.ntor, surf.ntor + 1):\n                    angle = m * theta - n * nfp * phi0\n                    R += surf.get_rc(m, n) * np.cos(angle)\n                    Z += surf.get_zs(m, n) * np.sin(angle)\n                    d_Z_d_theta += surf.get_zs(m, n) * m * np.cos(angle)\n                    d_R_d_theta += surf.get_rc(m, n) * m * (-np.sin(angle))\n\n            # Now compute the new theta for each grid point in the old\n            # theta.  This mostly amount to taking an arcsin, but we\n            # must be careful to assign points to the proper half of\n            # [0, 2pi], since arcsin by itself only returns values in\n            # the range [-pi/2, pi/2].\n            d_Z_rot_d_theta = d_Z_d_theta * cosaphi - d_R_d_theta * sinaphi\n            # Copy the first element to the end, for periodicity:\n            d_Z_rot_d_theta_circ = np.concatenate((d_Z_rot_d_theta, [d_Z_rot_d_theta[0]]))\n            sign_flips = d_Z_rot_d_theta_circ[1:] * d_Z_rot_d_theta_circ[:-1]\n            sign_flip_indices = [j for j in range(ntheta) if sign_flips[j] < 0]\n            if len(sign_flip_indices) != 2:\n                logger.warning(f'A number of sign flips other than 2 detected for jphi={jphi}: sign_flip_indices={sign_flip_indices}.' \\\n                               ' This may mean the surface cannot be represented in Henneberg form.' \\\n                               f' sign_flips={sign_flips}')\n\n            temp = (Z * cosaphi - R * sinaphi - Q) / b\n            if np.any(temp > 1):\n                # Going outside [-1, 1] by ~ roundoff is okay, but\n                # warn if we are much farther than that.\n                if np.any(temp > 1 + 1.0e-12):\n                    logger.warning(f'Argument of arcsin exceeds 1: {temp[temp > 1] - 1}')\n                temp[temp > 1] = 1.0\n            if np.any(temp < -1):\n                if np.any(temp < -1 - 1.0e-12):\n                    logger.warning(f'Argument of arcsin is below -1: {temp[temp < -1] + 1}')\n                temp[temp < -1] = -1.0\n\n            arcsin_term = np.arcsin(temp)\n            mask = d_Z_rot_d_theta < 0\n            arcsin_term[mask] = np.pi - arcsin_term[mask]\n            mask = arcsin_term < 0\n            arcsin_term[mask] = arcsin_term[mask] + 2 * np.pi\n            theta_H = arcsin_term + alpha * phi0\n\n            # Copy arrays 3 times, so endpoints are interpolated correctly:\n            theta_H_3 = np.concatenate((theta_H - 2 * np.pi, theta_H, theta_H + 2 * np.pi))\n            R_3 = np.concatenate((R, R, R))\n            Z_3 = np.concatenate((Z, Z, Z))\n            R_interp = interp1d(theta_H_3, R_3, kind='cubic')\n            Z_interp = interp1d(theta_H_3, Z_3, kind='cubic')\n\n            R_H = R_interp(theta)\n            Z_H = Z_interp(theta)\n\n            avg_R = np.mean(R_H)\n            avg_Z = np.mean(Z_H)\n\n            R0H = avg_R * cosaphi * cosaphi + avg_Z * sinaphi * cosaphi - Q * sinaphi\n            Z0H = avg_R * cosaphi * sinaphi + avg_Z * sinaphi * sinaphi + Q * cosaphi\n\n            R0_realsp[jphi] = R0H\n            Z0_realsp[jphi] = Z0H\n            b_realsp[jphi] = b\n            rho_realsp[:, jphi] = (R_H - R0H) * cosaphi + (Z_H - Z0H) * sinaphi\n\n        surf_H = cls(nfp=nfp, alpha_fac=alpha_fac, mmax=mmax, nmax=nmax)\n        # Now convert from real-space to Fourier space.\n        # Start with the 0-frequency terms:\n        surf_H.R0nH[0] = np.mean(R0_realsp)\n        surf_H.bn[0] = np.mean(b_realsp)\n        Z00H = np.mean(Z0_realsp)\n        logger.info(f'n=0 term of Z0nH: {Z00H} (should be ~ 0)')\n        assert np.abs(Z00H) < 1.0e-6\n        rho00 = np.mean(rho_realsp)\n        logger.info(f'm=n=0 term of rho_mn: {rho00} (should be ~ 0)')\n        assert np.abs(rho00) < 1.0e-6\n\n        # Now handle 1D arrays:\n        for n in range(1, nmax + 1):\n            cosnphi_fac = np.cos(n * nfp * phi) / nphi\n            sinnphi_fac = np.sin(n * nfp * phi) / nphi\n            surf_H.R0nH[n] = 2 * np.sum(R0_realsp * cosnphi_fac)\n            surf_H.Z0nH[n] = 2 * np.sum(Z0_realsp * sinnphi_fac)\n            surf_H.bn[n] = 2 * np.sum(b_realsp * cosnphi_fac)\n\n        # Transform rho:\n        phi2d, theta2d = np.meshgrid(phi, theta)\n        #print('phi2d.shape:', phi2d.shape)\n        for m in range(mmax + 1):\n            nmin = -nmax\n            if m == 0:\n                nmin = 1\n            for n in range(nmin, nmax + 1):\n                # Eq above (4.5):\n                angle = m * theta2d + (n * nfp - alpha) * phi2d\n                surf_H.set_rhomn(m, n, 2 * np.sum(rho_realsp * np.cos(angle)) / (ntheta * nphi))\n\n        \"\"\"\n        plt.figure()\n        plt.contourf(phi2d, theta2d, rho_realsp, 25)\n        plt.colorbar()\n        plt.xlabel('phi')\n        plt.ylabel('theta')\n        plt.title('rho_realsp')\n        plt.show()\n        \"\"\"\n\n        # Check that the inverse-transform of the transform gives back\n        # the original arrays, approximately:\n        b_alt = np.zeros(nphi)\n        R0_alt = np.zeros(nphi)\n        Z0_alt = np.zeros(nphi)\n        for n in range(nmax + 1):\n            b_alt += surf_H.bn[n] * np.cos(n * nfp * phi)\n            R0_alt += surf_H.R0nH[n] * np.cos(n * nfp * phi)\n            Z0_alt += surf_H.Z0nH[n] * np.sin(n * nfp * phi)\n\n        print('b_realsp:', b_realsp)\n        print('b_alt:   ', b_alt)\n        print('bn:', surf_H.bn)\n        print('Diff in b:', np.max(np.abs(b_alt - b_realsp)))\n        print('Diff in R0:', np.max(np.abs(R0_alt - R0_realsp)))\n        print('Diff in Z0:', np.max(np.abs(Z0_alt - Z0_realsp)))\n\n        rho_alt = np.zeros((ntheta, nphi))\n        for m in range(mmax + 1):\n            nmin = -nmax\n            if m == 0:\n                nmin = 1\n            for n in range(nmin, nmax + 1):\n                angle = m * theta2d + (n * nfp - alpha) * phi2d\n                rho_alt += surf_H.get_rhomn(m, n) * np.cos(angle)\n        #print('rho_realsp:', rho_realsp)\n        #print('rho_alt:   ', rho_alt)\n        print('Diff in rho:', np.max(np.abs(rho_realsp - rho_alt)))\n\n        surf_H.local_full_x = surf_H.get_dofs()\n        return surf_H\n\n    def gamma_lin(self, data, quadpoints_phi, quadpoints_theta):\n        \"\"\"\n        Evaluate the position vector on the surface in Cartesian\n        coordinates, for a list of (phi, theta) points.\n        \"\"\"\n        # I prefer to work with angles that go up to 2pi rather than 1.\n        theta = quadpoints_theta * 2 * np.pi\n        phi = quadpoints_phi * 2 * np.pi\n        nfp = self.nfp\n        shape = phi.shape\n        R0H = np.zeros(shape)\n        Z0H = np.zeros(shape)\n        b = np.zeros(shape)\n        rho = np.zeros(shape)\n        alpha = 0.5 * nfp * self.alpha_fac\n        for n in range(self.nmax + 1):\n            cosangle = np.cos(nfp * n * phi)\n            R0H += self.R0nH[n] * cosangle\n            b += self.bn[n] * cosangle\n        for n in range(1, self.nmax + 1):\n            sinangle = np.sin(nfp * n * phi)\n            Z0H += self.Z0nH[n] * sinangle\n        for m in range(self.mmax + 1):\n            nmin = -self.nmax\n            if m == 0:\n                nmin = 1\n            for n in range(nmin, self.nmax + 1):\n                cosangle = np.cos(m * theta + nfp * n * phi - alpha * phi)\n                rho += self.get_rhomn(m, n) * cosangle\n        zeta = b * np.sin(theta - alpha * phi)\n        sinaphi = np.sin(alpha * phi)\n        cosaphi = np.cos(alpha * phi)\n        R = R0H + rho * cosaphi - zeta * sinaphi\n        Z = Z0H + rho * sinaphi + zeta * cosaphi\n        data[:, 0] = R * np.cos(phi)\n        data[:, 1] = R * np.sin(phi)\n        data[:, 2] = Z\n\n    def gamma_impl(self, data, quadpoints_phi, quadpoints_theta):\n        \"\"\"\n        Evaluate the position vector on the surface in Cartesian\n        coordinates, for a tensor product grid of points in theta and\n        phi.\n        \"\"\"\n        nphi = len(quadpoints_phi)\n        ntheta = len(quadpoints_theta)\n        phi2d, theta2d = np.meshgrid(quadpoints_phi, quadpoints_theta)\n        data1d = np.zeros((nphi * ntheta, 3))\n        self.gamma_lin(data1d,\n                       np.reshape(phi2d, (nphi * ntheta,)),\n                       np.reshape(theta2d, (nphi * ntheta,)))\n        for xyz in range(3):\n            data[:, :, xyz] = np.reshape(data1d[:, xyz], (ntheta, nphi)).T\n\n    def gammadash1_impl(self, data):\n        \"\"\"\n        Evaluate the derivative of the position vector with respect to the\n        toroidal angle phi.\n        \"\"\"\n        # I prefer to work with angles that go up to 2pi rather than 1.\n        theta1D = self.quadpoints_theta * 2 * np.pi\n        phi1D = self.quadpoints_phi * 2 * np.pi\n        nphi = len(phi1D)\n        ntheta = len(theta1D)\n        nfp = self.nfp\n        R0H = np.zeros(nphi)\n        Z0H = np.zeros(nphi)\n        b = np.zeros(nphi)\n        rho = np.zeros((ntheta, nphi))\n        d_R0H_d_phi = np.zeros(nphi)\n        d_Z0H_d_phi = np.zeros(nphi)\n        d_b_d_phi = np.zeros(nphi)\n        d_rho_d_phi = np.zeros((ntheta, nphi))\n        phi, theta = np.meshgrid(phi1D, theta1D)\n        alpha = 0.5 * nfp * self.alpha_fac\n        for n in range(self.nmax + 1):\n            angle = nfp * n * phi1D\n            cosangle = np.cos(angle)\n            sinangle = np.sin(angle)\n            R0H += self.R0nH[n] * cosangle\n            b += self.bn[n] * cosangle\n            d_R0H_d_phi -= self.R0nH[n] * sinangle * nfp * n\n            d_b_d_phi -= self.bn[n] * sinangle * nfp * n\n            if n > 0:\n                Z0H += self.Z0nH[n] * sinangle\n                d_Z0H_d_phi += self.Z0nH[n] * cosangle * nfp * n\n        for m in range(self.mmax + 1):\n            nmin = -self.nmax\n            if m == 0:\n                nmin = 1\n            for n in range(nmin, self.nmax + 1):\n                angle = m * theta + nfp * n * phi - alpha * phi\n                cosangle = np.cos(angle)\n                sinangle = np.sin(angle)\n                rho += self.get_rhomn(m, n) * cosangle\n                d_rho_d_phi -= self.get_rhomn(m, n) * sinangle * (nfp * n - alpha)\n        R0H2D = np.kron(R0H, np.ones((ntheta, 1)))\n        Z0H2D = np.kron(Z0H, np.ones((ntheta, 1)))\n        b2D = np.kron(b, np.ones((ntheta, 1)))\n        zeta = b2D * np.sin(theta - alpha * phi)\n        d_R0H2D_d_phi = np.kron(d_R0H_d_phi, np.ones((ntheta, 1)))\n        d_Z0H2D_d_phi = np.kron(d_Z0H_d_phi, np.ones((ntheta, 1)))\n        d_b2D_d_phi = np.kron(d_b_d_phi, np.ones((ntheta, 1)))\n        d_zeta_d_phi = d_b2D_d_phi * np.sin(theta - alpha * phi) \\\n            + b2D * np.cos(theta - alpha * phi) * (-alpha)\n        sinaphi = np.sin(alpha * phi)\n        cosaphi = np.cos(alpha * phi)\n        R = R0H2D + rho * cosaphi - zeta * sinaphi\n        Z = Z0H2D + rho * sinaphi + zeta * cosaphi\n        d_R_d_phi = d_R0H2D_d_phi + d_rho_d_phi * cosaphi + rho * (-alpha * sinaphi) \\\n            - d_zeta_d_phi * sinaphi - zeta * (alpha * cosaphi)\n        d_Z_d_phi = d_Z0H2D_d_phi + d_rho_d_phi * sinaphi + rho * (alpha * cosaphi) \\\n            + d_zeta_d_phi * cosaphi + zeta * (-alpha * sinaphi)\n        # Insert factors of 2pi since theta here is 2pi times the theta used for d/dtheta\n        data[:, :, 0] = 2 * np.pi * (d_R_d_phi * np.cos(phi) - R * np.sin(phi)).T\n        data[:, :, 1] = 2 * np.pi * (d_R_d_phi * np.sin(phi) + R * np.cos(phi)).T\n        data[:, :, 2] = 2 * np.pi * d_Z_d_phi.T\n\n    def gammadash2_impl(self, data):\n        \"\"\"\n        Evaluate the derivative of the position vector with respect to\n        theta.\n        \"\"\"\n        # I prefer to work with angles that go up to 2pi rather than 1.\n        theta1D = self.quadpoints_theta * 2 * np.pi\n        phi1D = self.quadpoints_phi * 2 * np.pi\n        nphi = len(phi1D)\n        ntheta = len(theta1D)\n        b = np.zeros(nphi)\n        d_rho_d_theta = np.zeros((ntheta, nphi))\n        phi, theta = np.meshgrid(phi1D, theta1D)\n        alpha = 0.5 * self.nfp * self.alpha_fac\n        for n in range(self.nmax + 1):\n            cosangle = np.cos(self.nfp * n * phi1D)\n            b += self.bn[n] * cosangle\n        for m in range(self.mmax + 1):\n            nmin = -self.nmax\n            if m == 0:\n                nmin = 1\n            for n in range(nmin, self.nmax + 1):\n                sinangle = np.sin(m * theta + self.nfp * n * phi - alpha * phi)\n                d_rho_d_theta -= self.get_rhomn(m, n) * m * sinangle\n        b2D = np.kron(b, np.ones((ntheta, 1)))\n        d_zeta_d_theta = b2D * np.cos(theta - alpha * phi)\n        sinaphi = np.sin(alpha * phi)\n        cosaphi = np.cos(alpha * phi)\n        d_R_d_theta = d_rho_d_theta * cosaphi - d_zeta_d_theta * sinaphi\n        d_Z_d_theta = d_rho_d_theta * sinaphi + d_zeta_d_theta * cosaphi\n        # Insert factors of 2pi since theta here is 2pi times the theta used for d/dtheta\n        data[:, :, 0] = (2 * np.pi * d_R_d_theta * np.cos(phi)).T\n        data[:, :, 1] = (2 * np.pi * d_R_d_theta * np.sin(phi)).T\n        data[:, :, 2] = 2 * np.pi * d_Z_d_theta.T",
  "def __init__(self,\n                 nfp: int = 1,\n                 alpha_fac: int = 1,\n                 mmax: int = 1,\n                 nmax: int = 0,\n                 quadpoints_phi: RealArray = None,\n                 quadpoints_theta: RealArray = None,\n                 dofs: DOFs = None):\n\n        self.nfp = nfp\n        self.alpha_fac = alpha_fac\n        self.mmax = mmax\n        self.nmax = nmax\n        self.stellsym = True\n        self.allocate()\n\n        if quadpoints_theta is None:\n            quadpoints_theta = Surface.get_theta_quadpoints()\n        if quadpoints_phi is None:\n            quadpoints_phi = Surface.get_phi_quadpoints(nfp=nfp)\n\n        sopp.Surface.__init__(self, quadpoints_phi, quadpoints_theta)\n        # Initialize to an axisymmetric torus with major radius 1m and\n        # minor radius 0.1m\n        self.R0nH[0] = 1.0\n        self.bn[0] = 0.1\n        self.set_rhomn(1, 0, 0.1)\n\n        if dofs is None:\n            Surface.__init__(self, x0=self.get_dofs(), names=self._make_names(),\n                             external_dof_setter=SurfaceHenneberg.set_dofs_impl)\n        else:\n            Surface.__init__(self, dofs=dofs,\n                             external_dof_setter=SurfaceHenneberg.set_dofs_impl)",
  "def __repr__(self):\n        return f\"{self.name} (nfp={self.nfp}, alpha_fac={self.alpha_fac}, \" \\\n            + f\"mmax={self.mmax}, nmax={self.nmax})\"",
  "def allocate(self):\n        \"\"\"\n        Create the arrays for the continuous degrees of freedom. Also set\n        the names of the dofs.\n        \"\"\"\n        logger.debug(\"Allocating SurfaceHenneberg\")\n        # Note that for simpicity, the Z0nH array contains an element\n        # for n=0 even though this element is always 0. Similarly, the\n        # rhomn array has some elements for (m=0, n<0) even though\n        # these elements are always zero.\n\n        self.R0nH = np.zeros(self.nmax + 1)\n        self.Z0nH = np.zeros(self.nmax + 1)\n        self.bn = np.zeros(self.nmax + 1)\n\n        self.ndim = 2 * self.nmax + 1\n        myshape = (self.mmax + 1, self.ndim)\n        self.rhomn = np.zeros(myshape)",
  "def _make_names(self):\n        names = []\n        for n in range(self.nmax + 1):\n            names.append(f'R0nH({n})')\n        for n in range(1, self.nmax + 1):\n            names.append(f'Z0nH({n})')\n        for n in range(self.nmax + 1):\n            names.append(f'bn({n})')\n        # Handle m = 0 modes in rho_mn:\n        for n in range(1, self.nmax + 1):\n            names.append(f'rhomn(0,{n})')\n        # Handle m > 0 modes in rho_mn:\n        for m in range(1, self.mmax + 1):\n            for n in range(-self.nmax, self.nmax + 1):\n                names.append(f'rhomn({m},{n})')\n        return names",
  "def _validate_mn(self, m, n):\n        r\"\"\"\n        Check whether given (m, n) values are allowed for :math:`\\rho_{m,n}`.\n        \"\"\"\n        if m < 0:\n            raise ValueError(f'm must be >= 0, but m = {m}')\n        if m > self.mmax:\n            raise ValueError(f'm must be <= mmax, but m = {m}')\n        if m == 0 and n < 1:\n            raise ValueError(f'For m=0, n must be >= 1, but n = {n}')\n        if n > self.nmax:\n            raise ValueError(f'n must be <= nmax, but n = {n}')\n        if n < -self.nmax:\n            raise ValueError(f'n must be >= -nmax, but n = {n}')",
  "def get_rhomn(self, m, n):\n        r\"\"\"\n        Return a particular :math:`\\rho_{m,n}` coefficient.\n        \"\"\"\n        self._validate_mn(m, n)\n        return self.rhomn[m, n + self.nmax]",
  "def set_rhomn(self, m, n, val):\n        r\"\"\"\n        Set a particular :math:`\\rho_{m,n}` coefficient.\n        \"\"\"\n        self._validate_mn(m, n)\n        self.rhomn[m, n + self.nmax] = val\n        self.invalidate_cache()",
  "def get_dofs(self):\n        \"\"\"\n        Return a 1D numpy array with all the degrees of freedom.\n        \"\"\"\n        return np.concatenate((self.R0nH, self.Z0nH[1:], self.bn,\n                               self.rhomn[0, self.nmax + 1:],\n                               np.reshape(self.rhomn[1:, :], (self.mmax * (2 * self.nmax + 1),), order='C')))",
  "def set_dofs(self, dofs):\n        self.local_x = dofs",
  "def num_dofs(self):\n        \"\"\"\n        Return the number of degrees of freedom.\n        \"\"\"\n        ndofs = self.nmax + 1  # R0nH\n        ndofs += self.nmax  # Z0nH\n        ndofs += self.nmax + 1  # b0n\n        ndofs += self.nmax  # rhomn for m = 0\n        ndofs += self.mmax * (2 * self.nmax + 1)  # rhomn for m > 0\n\n        return ndofs",
  "def set_dofs_impl(self, v):\n        \"\"\"\n        Set the shape coefficients from a 1D list/array\n        \"\"\"\n\n        n = self.num_dofs()\n        if len(v) != n:\n            raise ValueError('Input vector should have ' + str(n) + \\\n                             ' elements but instead has ' + str(len(v)))\n\n        index = 0\n        nvals = self.nmax + 1\n        self.R0nH = v[index: index + nvals]\n        index += nvals\n\n        nvals = self.nmax\n        self.Z0nH[1:] = v[index: index + nvals]\n        index += nvals\n\n        nvals = self.nmax + 1\n        self.bn = v[index: index + nvals]\n        index += nvals\n\n        nvals = self.nmax\n        self.rhomn[0, self.nmax + 1:] = v[index: index + nvals]\n        index += nvals\n\n        self.rhomn[1:, :] = np.reshape(v[index:], (self.mmax, 2 * self.nmax + 1), order='C')",
  "def fixed_range(self, mmax, nmax, fixed=True):\n        \"\"\"\n        Set the ``fixed`` property for a range of ``m`` and ``n`` values.\n\n        All modes with ``m <= mmax`` and ``|n| <= nmax`` will have\n        their fixed property set to the value of the ``fixed``\n        parameter. Note that ``mmax`` and ``nmax`` are included.\n\n        Both ``mmax`` and ``nmax`` must be >= 0.\n\n        For any value of ``mmax``, the ``fixed`` properties of\n        ``R0nH``, ``Z0nH``, and ``rhomn`` are set. The ``fixed``\n        properties of ``bn`` are set only if ``mmax > 0``. In other\n        words, the ``bn`` modes are treated as having ``m=1``.\n        \"\"\"\n        if mmax < 0:\n            raise ValueError('mmax must be >= 0')\n        mmax = min(self.mmax, mmax)\n        if nmax < 0:\n            raise ValueError('nmax must be >= 0')\n        nmax = min(self.nmax, nmax)\n\n        fn = self.fix if fixed else self.unfix\n\n        for n in range(nmax + 1):\n            fn(f'R0nH({n})')\n        for n in range(1, nmax + 1):\n            fn(f'Z0nH({n})')\n        if mmax > 0:\n            for n in range(nmax + 1):\n                fn(f'bn({n})')\n\n        for m in range(mmax + 1):\n            nmin_to_use = -nmax\n            if m == 0:\n                nmin_to_use = 1\n            for n in range(nmin_to_use, nmax + 1):\n                fn(f'rhomn({m},{n})')",
  "def to_RZFourier(self):\n        \"\"\"\n        Return a :obj:`~.surfacerzfourier.SurfaceRZFourier` object with the identical shape. This\n        routine implements eq (4.5)-(4.6) in the Henneberg paper, plus\n        m=0 terms for R0 and Z0.\n        \"\"\"\n        mpol = self.mmax\n        ntor = self.nmax + 1  # More modes are needed in the SurfaceRZFourier because some indices are shifted by +/- 2*alpha.\n        s = SurfaceRZFourier(nfp=self.nfp, stellsym=True, mpol=mpol, ntor=ntor)\n        s.rc[:] = 0.0\n        s.zs[:] = 0.0\n\n        # Set Rmn.\n        # Handle the 1d arrays (R0nH, bn):\n        for nprime in range(self.nmax + 1):\n            n = nprime\n            # Handle the R0nH term:\n            s.set_rc(0, n, s.get_rc(0, n) + self.R0nH[n])\n            # Handle the b_n term:\n            s.set_rc(1, n, s.get_rc(1, n) + 0.25 * self.bn[nprime])\n            # Handle the b_{-n} term:\n            n = -nprime\n            s.set_rc(1, n, s.get_rc(1, n) + 0.25 * self.bn[nprime])\n            # Handle the b_{n-2alpha} term:\n            n = nprime + self.alpha_fac\n            s.set_rc(1, n, s.get_rc(1, n) - 0.25 * self.bn[nprime])\n            # Handle the b_{-n+2alpha} term:\n            n = -nprime + self.alpha_fac\n            s.set_rc(1, n, s.get_rc(1, n) - 0.25 * self.bn[nprime])\n        # Handle the 2D rho terms:\n        for m in range(self.mmax + 1):\n            nmin = -self.nmax\n            if m == 0:\n                nmin = 1\n            for nprime in range(nmin, self.nmax + 1):\n                # Handle the rho_{m, -n} term:\n                n = -nprime\n                s.set_rc(m, n, s.get_rc(m, n) + 0.5 * self.get_rhomn(m, nprime))\n                # Handle the rho_{m, -n+2alpha} term:\n                n = -nprime + self.alpha_fac\n                s.set_rc(m, n, s.get_rc(m, n) + 0.5 * self.get_rhomn(m, nprime))\n\n        # Set Zmn.\n        # Handle the 1d arrays (Z0nH, bn):\n        for nprime in range(self.nmax + 1):\n            n = nprime\n            # Handle the Z0nH term:\n            s.set_zs(0, n, s.get_zs(0, n) - self.Z0nH[n])\n            # Handle the b_n term:\n            s.set_zs(1, n, s.get_zs(1, n) + 0.25 * self.bn[nprime])\n            # Handle the b_{-n} term:\n            n = -nprime\n            s.set_zs(1, n, s.get_zs(1, n) + 0.25 * self.bn[nprime])\n            # Handle the b_{n-2alpha} term:\n            n = nprime + self.alpha_fac\n            s.set_zs(1, n, s.get_zs(1, n) + 0.25 * self.bn[nprime])\n            # Handle the b_{-n+2alpha} term:\n            n = -nprime + self.alpha_fac\n            s.set_zs(1, n, s.get_zs(1, n) + 0.25 * self.bn[nprime])\n        # Handle the 2D rho terms:\n        for m in range(self.mmax + 1):\n            nmin = -self.nmax\n            if m == 0:\n                nmin = 1\n            for nprime in range(nmin, self.nmax + 1):\n                # Handle the rho_{m, -n} term:\n                n = -nprime\n                s.set_zs(m, n, s.get_zs(m, n) + 0.5 * self.get_rhomn(m, nprime))\n                # Handle the rho_{m, -n+2alpha} term:\n                n = -nprime + self.alpha_fac\n                s.set_zs(m, n, s.get_zs(m, n) - 0.5 * self.get_rhomn(m, nprime))\n\n        return s",
  "def from_RZFourier(cls,\n                       surf,\n                       alpha_fac: int,\n                       mmax: Union[int, None] = None,\n                       nmax: Union[int, None] = None,\n                       ntheta: Union[int, None] = None,\n                       nphi: Union[int, None] = None):\n        \"\"\"\n        Convert a :obj:`~.surfacerzfourier.SurfaceRZFourier` surface to a\n        :obj:`SurfaceHenneberg` surface.\n\n        Args:\n            surf: The :obj:`~.surfacerzfourier.SurfaceRZFourier` object to convert.\n            mmax: Maximum poloidal mode number to include in the new surface. If ``None``,\n              the value ``mpol`` from the old surface will be used.\n            nmax: Maximum toroidal mode number to include in the new surface. If ``None``,\n              the value ``ntor`` from the old surface will be used.\n            ntheta: Number of grid points in the poloidal angle used for the transformation.\n              If ``None``, the value ``3 * ntheta`` will be used.\n            nphi: Number of grid points in the toroidal angle used for the transformation.\n              If ``None``, the value ``3 * nphi`` will be used.\n        \"\"\"\n        if not surf.stellsym:\n            raise RuntimeError('SurfaceHenneberg.from_RZFourier method only '\n                               'works for stellarator symmetric surfaces')\n        if mmax is None:\n            mmax = surf.mpol\n        if nmax is None:\n            nmax = surf.ntor\n        if ntheta is None:\n            ntheta = mmax * 3\n        if nphi is None:\n            nphi = nmax * 3\n        logger.info(f'Beginning conversion with mmax={mmax}, nmax={nmax}, ntheta={ntheta}, nphi={nphi}')\n        nfp = surf.nfp\n        theta = np.linspace(0, 2 * np.pi, ntheta, endpoint=False)\n        phi = np.linspace(0, 2 * np.pi / nfp, nphi, endpoint=False)\n        alpha = 0.5 * nfp * alpha_fac\n\n        # Initialize arrays to store quantities in real-space:\n        R0_realsp = np.zeros(nphi)\n        Z0_realsp = np.zeros(nphi)\n        b_realsp = np.zeros(nphi)\n        rho_realsp = np.zeros((ntheta, nphi))\n\n        def b_min(theta, phi0, cosaphi, sinaphi):\n            \"\"\"\n            This function is minimized as part of finding b.\n            \"\"\"\n            R = 0\n            Z = 0\n            for m in range(surf.mpol + 1):\n                for n in range(-surf.ntor, surf.ntor + 1):\n                    angle = m * theta - n * nfp * phi0\n                    R += surf.get_rc(m, n) * np.cos(angle)\n                    Z += surf.get_zs(m, n) * np.sin(angle)\n            return Z * cosaphi - R * sinaphi\n\n        def b_max(theta, phi0, cosaphi, sinaphi):\n            return -b_min(theta, phi0, cosaphi, sinaphi)\n\n        # An independent transformation is performed at each grid point in phi:\n        for jphi, phi0 in enumerate(phi):\n            logger.debug(f'Transforming jphi={jphi} of {nphi}')\n            cosaphi = np.cos(alpha * phi0)\n            sinaphi = np.sin(alpha * phi0)\n\n            # Find the max and min of the surface in the zeta direction:\n            opt_result = minimize_scalar(b_min, args=(phi0, cosaphi, sinaphi), tol=1e-12)\n            min_for_b = opt_result.fun\n\n            opt_result = minimize_scalar(b_max, args=(phi0, cosaphi, sinaphi), tol=1e-12)\n            max_for_b = -opt_result.fun\n\n            b = 0.5 * (max_for_b - min_for_b)\n            Q = 0.5 * (max_for_b + min_for_b)\n\n            R = np.zeros(ntheta)\n            Z = np.zeros(ntheta)\n            d_Z_d_theta = np.zeros(ntheta)\n            d_R_d_theta = np.zeros(ntheta)\n            for m in range(surf.mpol + 1):\n                for n in range(-surf.ntor, surf.ntor + 1):\n                    angle = m * theta - n * nfp * phi0\n                    R += surf.get_rc(m, n) * np.cos(angle)\n                    Z += surf.get_zs(m, n) * np.sin(angle)\n                    d_Z_d_theta += surf.get_zs(m, n) * m * np.cos(angle)\n                    d_R_d_theta += surf.get_rc(m, n) * m * (-np.sin(angle))\n\n            # Now compute the new theta for each grid point in the old\n            # theta.  This mostly amount to taking an arcsin, but we\n            # must be careful to assign points to the proper half of\n            # [0, 2pi], since arcsin by itself only returns values in\n            # the range [-pi/2, pi/2].\n            d_Z_rot_d_theta = d_Z_d_theta * cosaphi - d_R_d_theta * sinaphi\n            # Copy the first element to the end, for periodicity:\n            d_Z_rot_d_theta_circ = np.concatenate((d_Z_rot_d_theta, [d_Z_rot_d_theta[0]]))\n            sign_flips = d_Z_rot_d_theta_circ[1:] * d_Z_rot_d_theta_circ[:-1]\n            sign_flip_indices = [j for j in range(ntheta) if sign_flips[j] < 0]\n            if len(sign_flip_indices) != 2:\n                logger.warning(f'A number of sign flips other than 2 detected for jphi={jphi}: sign_flip_indices={sign_flip_indices}.' \\\n                               ' This may mean the surface cannot be represented in Henneberg form.' \\\n                               f' sign_flips={sign_flips}')\n\n            temp = (Z * cosaphi - R * sinaphi - Q) / b\n            if np.any(temp > 1):\n                # Going outside [-1, 1] by ~ roundoff is okay, but\n                # warn if we are much farther than that.\n                if np.any(temp > 1 + 1.0e-12):\n                    logger.warning(f'Argument of arcsin exceeds 1: {temp[temp > 1] - 1}')\n                temp[temp > 1] = 1.0\n            if np.any(temp < -1):\n                if np.any(temp < -1 - 1.0e-12):\n                    logger.warning(f'Argument of arcsin is below -1: {temp[temp < -1] + 1}')\n                temp[temp < -1] = -1.0\n\n            arcsin_term = np.arcsin(temp)\n            mask = d_Z_rot_d_theta < 0\n            arcsin_term[mask] = np.pi - arcsin_term[mask]\n            mask = arcsin_term < 0\n            arcsin_term[mask] = arcsin_term[mask] + 2 * np.pi\n            theta_H = arcsin_term + alpha * phi0\n\n            # Copy arrays 3 times, so endpoints are interpolated correctly:\n            theta_H_3 = np.concatenate((theta_H - 2 * np.pi, theta_H, theta_H + 2 * np.pi))\n            R_3 = np.concatenate((R, R, R))\n            Z_3 = np.concatenate((Z, Z, Z))\n            R_interp = interp1d(theta_H_3, R_3, kind='cubic')\n            Z_interp = interp1d(theta_H_3, Z_3, kind='cubic')\n\n            R_H = R_interp(theta)\n            Z_H = Z_interp(theta)\n\n            avg_R = np.mean(R_H)\n            avg_Z = np.mean(Z_H)\n\n            R0H = avg_R * cosaphi * cosaphi + avg_Z * sinaphi * cosaphi - Q * sinaphi\n            Z0H = avg_R * cosaphi * sinaphi + avg_Z * sinaphi * sinaphi + Q * cosaphi\n\n            R0_realsp[jphi] = R0H\n            Z0_realsp[jphi] = Z0H\n            b_realsp[jphi] = b\n            rho_realsp[:, jphi] = (R_H - R0H) * cosaphi + (Z_H - Z0H) * sinaphi\n\n        surf_H = cls(nfp=nfp, alpha_fac=alpha_fac, mmax=mmax, nmax=nmax)\n        # Now convert from real-space to Fourier space.\n        # Start with the 0-frequency terms:\n        surf_H.R0nH[0] = np.mean(R0_realsp)\n        surf_H.bn[0] = np.mean(b_realsp)\n        Z00H = np.mean(Z0_realsp)\n        logger.info(f'n=0 term of Z0nH: {Z00H} (should be ~ 0)')\n        assert np.abs(Z00H) < 1.0e-6\n        rho00 = np.mean(rho_realsp)\n        logger.info(f'm=n=0 term of rho_mn: {rho00} (should be ~ 0)')\n        assert np.abs(rho00) < 1.0e-6\n\n        # Now handle 1D arrays:\n        for n in range(1, nmax + 1):\n            cosnphi_fac = np.cos(n * nfp * phi) / nphi\n            sinnphi_fac = np.sin(n * nfp * phi) / nphi\n            surf_H.R0nH[n] = 2 * np.sum(R0_realsp * cosnphi_fac)\n            surf_H.Z0nH[n] = 2 * np.sum(Z0_realsp * sinnphi_fac)\n            surf_H.bn[n] = 2 * np.sum(b_realsp * cosnphi_fac)\n\n        # Transform rho:\n        phi2d, theta2d = np.meshgrid(phi, theta)\n        #print('phi2d.shape:', phi2d.shape)\n        for m in range(mmax + 1):\n            nmin = -nmax\n            if m == 0:\n                nmin = 1\n            for n in range(nmin, nmax + 1):\n                # Eq above (4.5):\n                angle = m * theta2d + (n * nfp - alpha) * phi2d\n                surf_H.set_rhomn(m, n, 2 * np.sum(rho_realsp * np.cos(angle)) / (ntheta * nphi))\n\n        \"\"\"\n        plt.figure()\n        plt.contourf(phi2d, theta2d, rho_realsp, 25)\n        plt.colorbar()\n        plt.xlabel('phi')\n        plt.ylabel('theta')\n        plt.title('rho_realsp')\n        plt.show()\n        \"\"\"\n\n        # Check that the inverse-transform of the transform gives back\n        # the original arrays, approximately:\n        b_alt = np.zeros(nphi)\n        R0_alt = np.zeros(nphi)\n        Z0_alt = np.zeros(nphi)\n        for n in range(nmax + 1):\n            b_alt += surf_H.bn[n] * np.cos(n * nfp * phi)\n            R0_alt += surf_H.R0nH[n] * np.cos(n * nfp * phi)\n            Z0_alt += surf_H.Z0nH[n] * np.sin(n * nfp * phi)\n\n        print('b_realsp:', b_realsp)\n        print('b_alt:   ', b_alt)\n        print('bn:', surf_H.bn)\n        print('Diff in b:', np.max(np.abs(b_alt - b_realsp)))\n        print('Diff in R0:', np.max(np.abs(R0_alt - R0_realsp)))\n        print('Diff in Z0:', np.max(np.abs(Z0_alt - Z0_realsp)))\n\n        rho_alt = np.zeros((ntheta, nphi))\n        for m in range(mmax + 1):\n            nmin = -nmax\n            if m == 0:\n                nmin = 1\n            for n in range(nmin, nmax + 1):\n                angle = m * theta2d + (n * nfp - alpha) * phi2d\n                rho_alt += surf_H.get_rhomn(m, n) * np.cos(angle)\n        #print('rho_realsp:', rho_realsp)\n        #print('rho_alt:   ', rho_alt)\n        print('Diff in rho:', np.max(np.abs(rho_realsp - rho_alt)))\n\n        surf_H.local_full_x = surf_H.get_dofs()\n        return surf_H",
  "def gamma_lin(self, data, quadpoints_phi, quadpoints_theta):\n        \"\"\"\n        Evaluate the position vector on the surface in Cartesian\n        coordinates, for a list of (phi, theta) points.\n        \"\"\"\n        # I prefer to work with angles that go up to 2pi rather than 1.\n        theta = quadpoints_theta * 2 * np.pi\n        phi = quadpoints_phi * 2 * np.pi\n        nfp = self.nfp\n        shape = phi.shape\n        R0H = np.zeros(shape)\n        Z0H = np.zeros(shape)\n        b = np.zeros(shape)\n        rho = np.zeros(shape)\n        alpha = 0.5 * nfp * self.alpha_fac\n        for n in range(self.nmax + 1):\n            cosangle = np.cos(nfp * n * phi)\n            R0H += self.R0nH[n] * cosangle\n            b += self.bn[n] * cosangle\n        for n in range(1, self.nmax + 1):\n            sinangle = np.sin(nfp * n * phi)\n            Z0H += self.Z0nH[n] * sinangle\n        for m in range(self.mmax + 1):\n            nmin = -self.nmax\n            if m == 0:\n                nmin = 1\n            for n in range(nmin, self.nmax + 1):\n                cosangle = np.cos(m * theta + nfp * n * phi - alpha * phi)\n                rho += self.get_rhomn(m, n) * cosangle\n        zeta = b * np.sin(theta - alpha * phi)\n        sinaphi = np.sin(alpha * phi)\n        cosaphi = np.cos(alpha * phi)\n        R = R0H + rho * cosaphi - zeta * sinaphi\n        Z = Z0H + rho * sinaphi + zeta * cosaphi\n        data[:, 0] = R * np.cos(phi)\n        data[:, 1] = R * np.sin(phi)\n        data[:, 2] = Z",
  "def gamma_impl(self, data, quadpoints_phi, quadpoints_theta):\n        \"\"\"\n        Evaluate the position vector on the surface in Cartesian\n        coordinates, for a tensor product grid of points in theta and\n        phi.\n        \"\"\"\n        nphi = len(quadpoints_phi)\n        ntheta = len(quadpoints_theta)\n        phi2d, theta2d = np.meshgrid(quadpoints_phi, quadpoints_theta)\n        data1d = np.zeros((nphi * ntheta, 3))\n        self.gamma_lin(data1d,\n                       np.reshape(phi2d, (nphi * ntheta,)),\n                       np.reshape(theta2d, (nphi * ntheta,)))\n        for xyz in range(3):\n            data[:, :, xyz] = np.reshape(data1d[:, xyz], (ntheta, nphi)).T",
  "def gammadash1_impl(self, data):\n        \"\"\"\n        Evaluate the derivative of the position vector with respect to the\n        toroidal angle phi.\n        \"\"\"\n        # I prefer to work with angles that go up to 2pi rather than 1.\n        theta1D = self.quadpoints_theta * 2 * np.pi\n        phi1D = self.quadpoints_phi * 2 * np.pi\n        nphi = len(phi1D)\n        ntheta = len(theta1D)\n        nfp = self.nfp\n        R0H = np.zeros(nphi)\n        Z0H = np.zeros(nphi)\n        b = np.zeros(nphi)\n        rho = np.zeros((ntheta, nphi))\n        d_R0H_d_phi = np.zeros(nphi)\n        d_Z0H_d_phi = np.zeros(nphi)\n        d_b_d_phi = np.zeros(nphi)\n        d_rho_d_phi = np.zeros((ntheta, nphi))\n        phi, theta = np.meshgrid(phi1D, theta1D)\n        alpha = 0.5 * nfp * self.alpha_fac\n        for n in range(self.nmax + 1):\n            angle = nfp * n * phi1D\n            cosangle = np.cos(angle)\n            sinangle = np.sin(angle)\n            R0H += self.R0nH[n] * cosangle\n            b += self.bn[n] * cosangle\n            d_R0H_d_phi -= self.R0nH[n] * sinangle * nfp * n\n            d_b_d_phi -= self.bn[n] * sinangle * nfp * n\n            if n > 0:\n                Z0H += self.Z0nH[n] * sinangle\n                d_Z0H_d_phi += self.Z0nH[n] * cosangle * nfp * n\n        for m in range(self.mmax + 1):\n            nmin = -self.nmax\n            if m == 0:\n                nmin = 1\n            for n in range(nmin, self.nmax + 1):\n                angle = m * theta + nfp * n * phi - alpha * phi\n                cosangle = np.cos(angle)\n                sinangle = np.sin(angle)\n                rho += self.get_rhomn(m, n) * cosangle\n                d_rho_d_phi -= self.get_rhomn(m, n) * sinangle * (nfp * n - alpha)\n        R0H2D = np.kron(R0H, np.ones((ntheta, 1)))\n        Z0H2D = np.kron(Z0H, np.ones((ntheta, 1)))\n        b2D = np.kron(b, np.ones((ntheta, 1)))\n        zeta = b2D * np.sin(theta - alpha * phi)\n        d_R0H2D_d_phi = np.kron(d_R0H_d_phi, np.ones((ntheta, 1)))\n        d_Z0H2D_d_phi = np.kron(d_Z0H_d_phi, np.ones((ntheta, 1)))\n        d_b2D_d_phi = np.kron(d_b_d_phi, np.ones((ntheta, 1)))\n        d_zeta_d_phi = d_b2D_d_phi * np.sin(theta - alpha * phi) \\\n            + b2D * np.cos(theta - alpha * phi) * (-alpha)\n        sinaphi = np.sin(alpha * phi)\n        cosaphi = np.cos(alpha * phi)\n        R = R0H2D + rho * cosaphi - zeta * sinaphi\n        Z = Z0H2D + rho * sinaphi + zeta * cosaphi\n        d_R_d_phi = d_R0H2D_d_phi + d_rho_d_phi * cosaphi + rho * (-alpha * sinaphi) \\\n            - d_zeta_d_phi * sinaphi - zeta * (alpha * cosaphi)\n        d_Z_d_phi = d_Z0H2D_d_phi + d_rho_d_phi * sinaphi + rho * (alpha * cosaphi) \\\n            + d_zeta_d_phi * cosaphi + zeta * (-alpha * sinaphi)\n        # Insert factors of 2pi since theta here is 2pi times the theta used for d/dtheta\n        data[:, :, 0] = 2 * np.pi * (d_R_d_phi * np.cos(phi) - R * np.sin(phi)).T\n        data[:, :, 1] = 2 * np.pi * (d_R_d_phi * np.sin(phi) + R * np.cos(phi)).T\n        data[:, :, 2] = 2 * np.pi * d_Z_d_phi.T",
  "def gammadash2_impl(self, data):\n        \"\"\"\n        Evaluate the derivative of the position vector with respect to\n        theta.\n        \"\"\"\n        # I prefer to work with angles that go up to 2pi rather than 1.\n        theta1D = self.quadpoints_theta * 2 * np.pi\n        phi1D = self.quadpoints_phi * 2 * np.pi\n        nphi = len(phi1D)\n        ntheta = len(theta1D)\n        b = np.zeros(nphi)\n        d_rho_d_theta = np.zeros((ntheta, nphi))\n        phi, theta = np.meshgrid(phi1D, theta1D)\n        alpha = 0.5 * self.nfp * self.alpha_fac\n        for n in range(self.nmax + 1):\n            cosangle = np.cos(self.nfp * n * phi1D)\n            b += self.bn[n] * cosangle\n        for m in range(self.mmax + 1):\n            nmin = -self.nmax\n            if m == 0:\n                nmin = 1\n            for n in range(nmin, self.nmax + 1):\n                sinangle = np.sin(m * theta + self.nfp * n * phi - alpha * phi)\n                d_rho_d_theta -= self.get_rhomn(m, n) * m * sinangle\n        b2D = np.kron(b, np.ones((ntheta, 1)))\n        d_zeta_d_theta = b2D * np.cos(theta - alpha * phi)\n        sinaphi = np.sin(alpha * phi)\n        cosaphi = np.cos(alpha * phi)\n        d_R_d_theta = d_rho_d_theta * cosaphi - d_zeta_d_theta * sinaphi\n        d_Z_d_theta = d_rho_d_theta * sinaphi + d_zeta_d_theta * cosaphi\n        # Insert factors of 2pi since theta here is 2pi times the theta used for d/dtheta\n        data[:, :, 0] = (2 * np.pi * d_R_d_theta * np.cos(phi)).T\n        data[:, :, 1] = (2 * np.pi * d_R_d_theta * np.sin(phi)).T\n        data[:, :, 2] = 2 * np.pi * d_Z_d_theta.T",
  "def b_min(theta, phi0, cosaphi, sinaphi):\n            \"\"\"\n            This function is minimized as part of finding b.\n            \"\"\"\n            R = 0\n            Z = 0\n            for m in range(surf.mpol + 1):\n                for n in range(-surf.ntor, surf.ntor + 1):\n                    angle = m * theta - n * nfp * phi0\n                    R += surf.get_rc(m, n) * np.cos(angle)\n                    Z += surf.get_zs(m, n) * np.sin(angle)\n            return Z * cosaphi - R * sinaphi",
  "def b_max(theta, phi0, cosaphi, sinaphi):\n            return -b_min(theta, phi0, cosaphi, sinaphi)",
  "class SurfaceXYZFourier(sopp.SurfaceXYZFourier, Surface):\n    r\"\"\"`SurfaceXYZFourier` is a surface that is represented in Cartesian\n    coordinates using the following Fourier series:\n\n    .. math::\n        \\hat x(\\phi,\\theta) &= \\sum_{m=0}^{m_\\text{pol}} \\sum_{n=-n_{\\text{tor}}}^{n_{tor}} [\n              x_{c,m,n} \\cos(m \\theta - n_\\text{ fp } n \\phi)\n            + x_{s,m,n} \\sin(m \\theta - n_\\text{ fp } n \\phi)]\\\\\n        \\hat y(\\phi,\\theta) &= \\sum_{m=0}^{m_\\text{pol}} \\sum_{n=-n_\\text{tor}}^{n_\\text{tor}} [\n              y_{c,m,n} \\cos(m \\theta - n_\\text{fp} n \\phi)\n            + y_{s,m,n} \\sin(m \\theta - n_\\text{fp} n \\phi)]\\\\\n        z(\\phi,\\theta) &= \\sum_{m=0}^{m_\\text{pol}} \\sum_{n=-n_\\text{tor}}^{n_\\text{tor}} [\n              z_{c,m,n} \\cos(m \\theta - n_\\text{fp}n \\phi)\n            + z_{s,m,n} \\sin(m \\theta - n_\\text{fp}n \\phi)]\n\n    where\n\n    .. math::\n        x &= \\hat x \\cos(\\phi) - \\hat y \\sin(\\phi)\\\\\n        y &= \\hat x \\sin(\\phi) + \\hat y \\cos(\\phi)\n\n    Note that for :math:`m=0` we skip the :math:`n<0` term for the cos\n    terms, and the :math:`n \\leq 0` for the sin terms.\n\n    When enforcing stellarator symmetry, we set the\n\n    .. math::\n        x_{s,*,*}, ~y_{c,*,*}, \\text{and} ~z_{c,*,*}\n\n    terms to zero.\n\n    For more information about the arguments `quadpoints_phi``, and\n    ``quadpoints_theta``, see the general documentation on :ref:`surfaces`.\n    Instead of supplying the quadrature point arrays along :math:`\\phi` and\n    :math:`\\theta` directions, one could also specify the number of\n    quadrature points for :math:`\\phi` and :math:`\\theta` using the\n    class method :py:meth:`~simsopt.geo.surface.Surface.from_nphi_ntheta`.\n\n    Args:\n        nfp: The number of field periods.\n        stellsym: Whether the surface is stellarator-symmetric, i.e.\n          symmetry under rotation by :math:`\\pi` about the x-axis.\n        mpol: Maximum poloidal mode number included.\n        ntor: Maximum toroidal mode number included, divided by ``nfp``.\n        quadpoints_phi: Set this to a list or 1D array to set the :math:`\\phi_j` grid points directly.\n        quadpoints_theta: Set this to a list or 1D array to set the :math:`\\theta_j` grid points directly.\n    \"\"\"\n\n    def __init__(self, nfp=1, stellsym=True, mpol=1, ntor=0,\n                 quadpoints_phi=None, quadpoints_theta=None,\n                 dofs=None):\n\n        if quadpoints_theta is None:\n            quadpoints_theta = Surface.get_theta_quadpoints()\n        if quadpoints_phi is None:\n            quadpoints_phi = Surface.get_phi_quadpoints(nfp=nfp)\n\n        sopp.SurfaceXYZFourier.__init__(self, mpol, ntor, nfp, stellsym,\n                                        quadpoints_phi, quadpoints_theta)\n        self.xc[0, ntor] = 1.0\n        self.xc[1, ntor] = 0.1\n        self.zs[1, ntor] = 0.1\n        if dofs is None:\n            Surface.__init__(self, x0=self.get_dofs(),\n                             external_dof_setter=SurfaceXYZFourier.set_dofs_impl)\n        else:\n            Surface.__init__(self, dofs=dofs,\n                             external_dof_setter=SurfaceXYZFourier.set_dofs_impl)\n\n    def get_dofs(self):\n        \"\"\"\n        Return the dofs associated to this surface.\n        \"\"\"\n        return np.asarray(sopp.SurfaceXYZFourier.get_dofs(self))\n\n    def set_dofs(self, dofs):\n        \"\"\"\n        Set the dofs associated to this surface.\n        \"\"\"\n        self.local_full_x = dofs\n\n    def recompute_bell(self, parent=None):\n        self.invalidate_cache()\n\n    def to_RZFourier(self):\n        \"\"\"\n        Return a SurfaceRZFourier instance corresponding to the shape of this\n        surface.\n        \"\"\"\n        ntor = self.ntor\n        mpol = self.mpol \n        surf = SurfaceRZFourier(nfp=self.nfp, \n                                stellsym=self.stellsym, \n                                mpol=mpol, \n                                ntor=ntor, \n                                quadpoints_phi=self.quadpoints_phi, \n                                quadpoints_theta=self.quadpoints_theta)\n\n        gamma = np.zeros((surf.quadpoints_phi.size, surf.quadpoints_theta.size, 3))\n        for idx in range(gamma.shape[0]):\n            gamma[idx, :, :] = self.cross_section(surf.quadpoints_phi[idx]*2*np.pi)\n\n        surf.least_squares_fit(gamma)\n        return surf\n\n    return_fn_map = {'area': sopp.SurfaceXYZFourier.area,\n                     'volume': sopp.SurfaceXYZFourier.volume,\n                     'aspect-ratio': Surface.aspect_ratio}",
  "def __init__(self, nfp=1, stellsym=True, mpol=1, ntor=0,\n                 quadpoints_phi=None, quadpoints_theta=None,\n                 dofs=None):\n\n        if quadpoints_theta is None:\n            quadpoints_theta = Surface.get_theta_quadpoints()\n        if quadpoints_phi is None:\n            quadpoints_phi = Surface.get_phi_quadpoints(nfp=nfp)\n\n        sopp.SurfaceXYZFourier.__init__(self, mpol, ntor, nfp, stellsym,\n                                        quadpoints_phi, quadpoints_theta)\n        self.xc[0, ntor] = 1.0\n        self.xc[1, ntor] = 0.1\n        self.zs[1, ntor] = 0.1\n        if dofs is None:\n            Surface.__init__(self, x0=self.get_dofs(),\n                             external_dof_setter=SurfaceXYZFourier.set_dofs_impl)\n        else:\n            Surface.__init__(self, dofs=dofs,\n                             external_dof_setter=SurfaceXYZFourier.set_dofs_impl)",
  "def get_dofs(self):\n        \"\"\"\n        Return the dofs associated to this surface.\n        \"\"\"\n        return np.asarray(sopp.SurfaceXYZFourier.get_dofs(self))",
  "def set_dofs(self, dofs):\n        \"\"\"\n        Set the dofs associated to this surface.\n        \"\"\"\n        self.local_full_x = dofs",
  "def recompute_bell(self, parent=None):\n        self.invalidate_cache()",
  "def to_RZFourier(self):\n        \"\"\"\n        Return a SurfaceRZFourier instance corresponding to the shape of this\n        surface.\n        \"\"\"\n        ntor = self.ntor\n        mpol = self.mpol \n        surf = SurfaceRZFourier(nfp=self.nfp, \n                                stellsym=self.stellsym, \n                                mpol=mpol, \n                                ntor=ntor, \n                                quadpoints_phi=self.quadpoints_phi, \n                                quadpoints_theta=self.quadpoints_theta)\n\n        gamma = np.zeros((surf.quadpoints_phi.size, surf.quadpoints_theta.size, 3))\n        for idx in range(gamma.shape[0]):\n            gamma[idx, :, :] = self.cross_section(surf.quadpoints_phi[idx]*2*np.pi)\n\n        surf.least_squares_fit(gamma)\n        return surf",
  "class PermanentMagnetGrid:\n    r\"\"\"\n    ``PermanentMagnetGrid`` is a class for setting up the grid,\n    plasma surface, and other objects needed to perform permanent\n    magnet optimization for stellarators. The class\n    takes as input two toroidal surfaces specified as SurfaceRZFourier\n    objects, and initializes a set of points (in cylindrical coordinates)\n    between these surfaces. If an existing FAMUS grid file called\n    from FAMUS is desired, use from_famus() instead.\n    It finishes initialization by pre-computing\n    a number of quantities required for the optimization such as the\n    geometric factor in the dipole part of the magnetic field and the\n    target Bfield that is a sum of the coil and plasma magnetic fields.\n\n    Args:\n        plasma_boundary: Surface class object \n            Representing the plasma boundary surface. Gets converted\n            into SurfaceRZFourier object for ease of use.\n        Bn: 2D numpy array, shape (ntheta_quadpoints, nphi_quadpoints)\n            Magnetic field (coils and plasma) at the plasma\n            boundary. Typically this will be the optimized plasma\n            magnetic field from a stage-1 optimization, and the\n            optimized coils from a basic stage-2 optimization.\n            This variable must be specified to run the permanent\n            magnet optimization.\n        coordinate_flag: string\n            Flag to specify the coordinate system used for the grid and optimization.\n            This is primarily used to tell the optimizer which coordinate directions\n            should be considered, \"grid-aligned\". Therefore, you can do weird stuff\n            like cartesian grid-alignment on a simple toroidal grid, which might\n            be self-defeating. However, if coordinate_flag='cartesian' a rectangular\n            Cartesian grid is initialized using the Nx, Ny, and Nz parameters. If\n            the coordinate_flag='cylindrical', a uniform cylindrical grid is initialized\n            using the dr and dz parameters.\n    \"\"\"\n    coordinate_flag = OneofStrings(\"cartesian\", \"cylindrical\", \"toroidal\")\n\n    def __init__(self, plasma_boundary: Surface, Bn, coordinate_flag='cartesian'):\n        Bn = np.array(Bn)\n        if len(Bn.shape) != 2: \n            raise ValueError('Normal magnetic field surface data is incorrect shape.')\n        self.Bn = Bn\n\n        if coordinate_flag == 'cartesian':\n            warnings.warn('Cartesian grid of rectangular cubes will be built, since '\n                          'coordinate_flag = \"cartesian\". However, such a grid can be '\n                          'appropriately reflected only for nfp = 2 and nfp = 4, '\n                          'unlike the uniform cylindrical grid, which has continuous '\n                          'rotational symmetry.')\n        self.coordinate_flag = coordinate_flag\n        self.plasma_boundary = plasma_boundary.to_RZFourier()\n        self.R0 = self.plasma_boundary.get_rc(0, 0)\n        self.nphi = len(self.plasma_boundary.quadpoints_phi)\n        self.ntheta = len(self.plasma_boundary.quadpoints_theta)\n\n    def _setup_uniform_grid(self):\n        \"\"\"\n        Initializes a uniform grid in cartesian coordinates and sets\n        some important grid variables for later.\n        \"\"\"\n        # Get (X, Y, Z) coordinates of the two boundaries\n        self.xyz_inner = self.inner_toroidal_surface.gamma().reshape(-1, 3)\n        self.xyz_outer = self.outer_toroidal_surface.gamma().reshape(-1, 3)\n        if self.coordinate_flag != 'cylindrical':\n            x_outer = self.xyz_outer[:, 0]\n            y_outer = self.xyz_outer[:, 1]\n            z_outer = self.xyz_outer[:, 2]\n\n            x_max = np.max(x_outer)\n            x_min = np.min(x_outer)\n            y_max = np.max(y_outer)\n            y_min = np.min(y_outer)\n            z_max = np.max(z_outer)\n            z_min = np.min(z_outer)\n            z_max = max(z_max, abs(z_min))\n            print(x_min, x_max, y_min, y_max, z_min, z_max)\n\n            # Initialize uniform grid\n            Nx = self.Nx\n            Ny = self.Ny\n            Nz = self.Nz\n            self.dx = (x_max - x_min) / (Nx - 1)\n            self.dy = (y_max - y_min) / (Ny - 1)\n            self.dz = 2 * z_max / (Nz - 1)\n            print(Nx, Ny, Nz, self.dx, self.dy, self.dz)\n\n            # Extra work below so that the stitching with the symmetries is done in\n            # such a way that the reflected cells are still dx and dy away from\n            # the old cells.\n            #### Note that Cartesian cells can only do nfp = 2, 4, 6, ... \n            #### and correctly be rotated to have the right symmetries\n            if (self.plasma_boundary.nfp % 2) == 0:\n                X = np.linspace(self.dx / 2.0, (x_max - x_min) + self.dx / 2.0, Nx, endpoint=True)\n                Y = np.linspace(self.dy / 2.0, (y_max - y_min) + self.dy / 2.0, Ny, endpoint=True)\n            else:\n                X = np.linspace(x_min, x_max, Nx, endpoint=True)\n                Y = np.linspace(y_min, y_max, Ny, endpoint=True)\n            Z = np.linspace(-z_max, z_max, Nz, endpoint=True)\n\n            # Make 3D mesh\n            X, Y, Z = np.meshgrid(X, Y, Z, indexing='ij')\n            self.xyz_uniform = np.transpose(np.array([X, Y, Z]), [1, 2, 3, 0]).reshape(Nx * Ny * Nz, 3)\n\n            # Extra work for nfp = 4 to chop off half of the originally nfp = 2 uniform grid\n            if self.plasma_boundary.nfp == 4:\n                inds = []\n                for i in range(Nx):\n                    for j in range(Ny):\n                        for k in range(Nz):\n                            if X[i, j, k] < Y[i, j, k]:\n                                inds.append(int(i * Ny * Nz + j * Nz + k))\n                good_inds = np.setdiff1d(np.arange(Nx * Ny * Nz), inds)\n                self.xyz_uniform = self.xyz_uniform[good_inds, :]\n        else:\n            # Get (R, Z) coordinates of the outer boundary\n            rphiz_outer = np.array(\n                [np.sqrt(self.xyz_outer[:, 0] ** 2 + self.xyz_outer[:, 1] ** 2), \n                 np.arctan2(self.xyz_outer[:, 1], self.xyz_outer[:, 0]),\n                 self.xyz_outer[:, 2]]\n            ).T\n\n            r_max = np.max(rphiz_outer[:, 0])\n            r_min = np.min(rphiz_outer[:, 0])\n            z_max = np.max(rphiz_outer[:, 2])\n            z_min = np.min(rphiz_outer[:, 2])\n\n            # Initialize uniform grid of curved, square bricks\n            Nr = int((r_max - r_min) / self.dr)\n            self.Nr = Nr\n            self.dz = self.dr\n            Nz = int((z_max - z_min) / self.dz)\n            self.Nz = Nz\n            phi = 2 * np.pi * np.copy(self.plasma_boundary.quadpoints_phi)\n            R = np.linspace(r_min, r_max, Nr)\n            Z = np.linspace(z_min, z_max, Nz)\n\n            # Make 3D mesh\n            R, Phi, Z = np.meshgrid(R, phi, Z, indexing='ij')\n            X = R * np.cos(Phi)\n            Y = R * np.sin(Phi)\n            self.xyz_uniform = np.transpose(np.array([X, Y, Z]), [1, 2, 3, 0]).reshape(-1, 3)\n\n        # Save uniform grid before we start chopping off parts.\n        contig = np.ascontiguousarray\n        pointsToVTK('uniform_grid', contig(self.xyz_uniform[:, 0]),\n                    contig(self.xyz_uniform[:, 1]), contig(self.xyz_uniform[:, 2]))\n\n    @classmethod\n    def geo_setup_from_famus(cls, plasma_boundary, Bn, famus_filename, **kwargs):\n        \"\"\"\n        Function to initialize a SIMSOPT PermanentMagnetGrid from a \n        pre-existing FAMUS file defining a grid of magnets. For\n        example, this function is used for the\n        half-Tesla NCSX configuration (c09r000) and MUSE grids.\n\n        Args\n        ----------\n        famus_filename : string\n            Filename of a FAMUS grid file (a pre-made dipole grid).\n        kwargs: The following are valid keyword arguments.\n            m_maxima: float or 1D numpy array, shape (Ndipoles)\n                Optional array of maximal dipole magnitudes for the permanent\n                magnets. If not provided, defaults to the common magnets\n                used in the MUSE design, with strengths ~ 1 Tesla.\n            pol_vectors: 3D numpy array, shape (Ndipoles, Ncoords, 3)\n                Optional set of local coordinate systems for each dipole, \n                which specifies which directions should be considered grid-aligned.\n                Ncoords can be > 3, as in the PM4Stell design.\n            coordinate_flag: string\n                Flag to specify the coordinate system used for the grid and optimization.\n                This is primarily used to tell the optimizer which coordinate directions\n                should be considered, \"grid-aligned\". Therefore, you can do weird stuff\n                like cartesian grid-alignment on a simple toroidal grid, which might\n                be self-defeating. However, if coordinate_flag='cartesian' a rectangular\n                Cartesian grid is initialized using the Nx, Ny, and Nz parameters. If\n                the coordinate_flag='cylindrical', a uniform cylindrical grid is initialized\n                using the dr and dz parameters.\n            downsample: int\n                Optional integer for downsampling the FAMUS grid, since\n                the MUSE and other grids can be very high resolution\n                and this makes CI take a long while.\n        Returns\n        -------\n        pm_grid: An initialized PermanentMagnetGrid class object.\n\n        \"\"\"\n        coordinate_flag = kwargs.pop(\"coordinate_flag\", \"cartesian\")\n        downsample = kwargs.pop(\"downsample\", 1)\n        pol_vectors = kwargs.pop(\"pol_vectors\", None)\n        m_maxima = kwargs.pop(\"m_maxima\", None)\n        if str(famus_filename)[-6:] != '.focus':\n            raise ValueError('Famus filename must end in .focus')\n\n        pm_grid = cls(plasma_boundary, Bn, coordinate_flag)\n        pm_grid.famus_filename = famus_filename\n        ox, oy, oz, Ic, M0s = np.loadtxt(famus_filename, skiprows=3, usecols=[3, 4, 5, 6, 7],\n                                         delimiter=',', unpack=True)\n\n        # Downsample the resolution as needed \n        inds_total = np.arange(len(ox))\n        inds_downsampled = inds_total[::downsample]\n\n        # also remove any dipoles where the diagnostic ports should be\n        nonzero_inds = np.intersect1d(np.ravel(np.where(Ic == 1.0)), inds_downsampled) \n        pm_grid.Ic_inds = nonzero_inds\n        ox = ox[nonzero_inds]\n        oy = oy[nonzero_inds]\n        oz = oz[nonzero_inds]\n        premade_dipole_grid = np.array([ox, oy, oz]).T\n        pm_grid.ndipoles = premade_dipole_grid.shape[0]\n\n        # Not normalized to 1 like quadpoints_phi!\n        pm_grid.pm_phi = np.arctan2(premade_dipole_grid[:, 1], premade_dipole_grid[:, 0])\n        uniq_phi, counts_phi = np.unique(pm_grid.pm_phi.round(decimals=6), return_counts=True)\n        pm_grid.pm_nphi = len(uniq_phi)\n        pm_grid.pm_uniq_phi = uniq_phi\n        pm_grid.inds = counts_phi\n        for i in reversed(range(1, pm_grid.pm_nphi)):\n            for j in range(0, i):\n                pm_grid.inds[i] += pm_grid.inds[j]\n        pm_grid.dipole_grid_xyz = premade_dipole_grid\n\n        if m_maxima is None:\n            B_max = 1.465  # value used in FAMUS runs for MUSE\n            mu0 = 4 * np.pi * 1e-7\n            cell_vol = M0s * mu0 / B_max\n            pm_grid.m_maxima = B_max * cell_vol[nonzero_inds] / mu0\n        else:\n            if isinstance(m_maxima, float):\n                pm_grid.m_maxima = m_maxima * np.ones(pm_grid.ndipoles)\n            else:\n                pm_grid.m_maxima = m_maxima\n            if len(pm_grid.m_maxima) != pm_grid.ndipoles:\n                raise ValueError('m_maxima passed to geo_setup_from_famus but with '\n                                 'the wrong shape, i.e. != number of dipoles.')\n\n        if pol_vectors is not None:\n            pol_vectors = np.array(pol_vectors)\n            if len(pol_vectors.shape) != 3:\n                raise ValueError('pol vectors must be a 3D array.')\n            elif pol_vectors.shape[2] != 3:\n                raise ValueError('Third dimension of `pol_vectors` array '\n                                 'must be 3')\n            elif pm_grid.coordinate_flag != 'cartesian':\n                raise ValueError('pol_vectors argument can only be used with coordinate_flag = cartesian currently')\n            elif pol_vectors.shape[0] != pm_grid.ndipoles:\n                raise ValueError('First dimension of `pol_vectors` array '\n                                 'must equal the number of dipoles')\n\n        pm_grid.pol_vectors = pol_vectors\n        pm_grid._optimization_setup()\n        return pm_grid\n\n    @classmethod\n    def geo_setup_between_toroidal_surfaces(\n        cls, \n        plasma_boundary,\n        Bn,\n        inner_toroidal_surface: Surface, \n        outer_toroidal_surface: Surface,\n        **kwargs,\n    ):\n        \"\"\"\n        Function to initialize a SIMSOPT PermanentMagnetGrid from a \n        volume defined by two toroidal surfaces. These must be specified\n        directly. Often a good choice is made by extending the plasma \n        boundary by its normal vectors.\n\n        Args\n        ----------\n        inner_toroidal_surface: Surface class object \n            Representing the inner toroidal surface of the volume.\n            Gets converted into SurfaceRZFourier object for \n            ease of use.\n        outer_toroidal_surface: Surface object representing\n            the outer toroidal surface of the volume. Typically \n            want this to have same quadrature points as the inner\n            surface for a functional grid setup. \n            Gets converted into SurfaceRZFourier object for \n            ease of use.\n        kwargs: The following are valid keyword arguments.\n            m_maxima: float or 1D numpy array, shape (Ndipoles)\n                Optional array of maximal dipole magnitudes for the permanent\n                magnets. If not provided, defaults to the common magnets\n                used in the MUSE design, with strengths ~ 1 Tesla.\n            pol_vectors: 3D numpy array, shape (Ndipoles, Ncoords, 3)\n                Optional set of local coordinate systems for each dipole, \n                which specifies which directions should be considered grid-aligned.\n                Ncoords can be > 3, as in the PM4Stell design.\n            dr: double\n                Radial grid spacing in the permanent magnet manifold. Used only if \n                coordinate_flag = cylindrical, then dr is the radial size of the\n                cylindrical bricks in the grid.\n            dz: double\n                Axial grid spacing in the permanent magnet manifold. Used only if\n                coordinate_flag = cylindrical, then dz is the axial size of the\n                cylindrical bricks in the grid.\n            Nx: int\n                Number of points in x to use in a cartesian grid, taken between the \n                inner and outer toroidal surfaces. Used only if the\n                coordinate_flag = cartesian, then Nx is the x-size of the\n                rectangular cubes in the grid.\n            Ny: int\n                Number of points in y to use in a cartesian grid, taken between the \n                inner and outer toroidal surfaces. Used only if the\n                coordinate_flag = cartesian, then Ny is the y-size of the\n                rectangular cubes in the grid.\n            Nz: int\n                Number of points in z to use in a cartesian grid, taken between the \n                inner and outer toroidal surfaces. Used only if the\n                coordinate_flag = cartesian, then Nz is the z-size of the\n                rectangular cubes in the grid.\n            coordinate_flag: string\n                Flag to specify the coordinate system used for the grid and optimization.\n                This is primarily used to tell the optimizer which coordinate directions\n                should be considered, \"grid-aligned\". Therefore, you can do weird stuff\n                like cartesian grid-alignment on a simple toroidal grid, which might\n                be self-defeating. However, if coordinate_flag='cartesian' a rectangular\n                Cartesian grid is initialized using the Nx, Ny, and Nz parameters. If\n                the coordinate_flag='cylindrical', a uniform cylindrical grid is initialized\n                using the dr and dz parameters.\n        Returns\n        -------\n        pm_grid: An initialized PermanentMagnetGrid class object.\n\n        \"\"\"\n        coordinate_flag = kwargs.pop(\"coordinate_flag\", \"cartesian\")\n        pol_vectors = kwargs.pop(\"pol_vectors\", None)\n        m_maxima = kwargs.pop(\"m_maxima\", None)\n        pm_grid = cls(plasma_boundary, Bn, coordinate_flag) \n        Nx = kwargs.pop(\"Nx\", 10)\n        Ny = kwargs.pop(\"Ny\", 10)\n        Nz = kwargs.pop(\"Nz\", 10)\n        dr = kwargs.pop(\"dr\", 0.1)\n        dz = kwargs.pop(\"dz\", 0.1)\n        if Nx <= 0 or Ny <= 0 or Nz <= 0:\n            raise ValueError('Nx, Ny, and Nz should be positive integers')\n        if dr <= 0 or dz <= 0:\n            raise ValueError('dr and dz should be positive floats')\n        pm_grid.dr = dr\n        pm_grid.dz = dz\n        pm_grid.Nx = Nx\n        pm_grid.Ny = Ny\n        pm_grid.Nz = Nz\n        pm_grid.inner_toroidal_surface = inner_toroidal_surface.to_RZFourier()\n        pm_grid.outer_toroidal_surface = outer_toroidal_surface.to_RZFourier()    \n        warnings.warn(\n            'Plasma boundary and inner and outer toroidal surfaces should '\n            'all have the same \"range\" parameter in order for a permanent'\n            ' magnet grid to be correctly initialized.'\n        )        \n\n        # Have the uniform grid, now need to loop through and eliminate cells.\n        contig = np.ascontiguousarray\n        normal_inner = inner_toroidal_surface.unitnormal().reshape(-1, 3)   \n        normal_outer = outer_toroidal_surface.unitnormal().reshape(-1, 3)   \n        pm_grid._setup_uniform_grid()\n        pm_grid.dipole_grid_xyz = sopp.define_a_uniform_cartesian_grid_between_two_toroidal_surfaces(\n            contig(normal_inner), \n            contig(normal_outer), \n            contig(pm_grid.xyz_uniform), \n            contig(pm_grid.xyz_inner), \n            contig(pm_grid.xyz_outer))\n        inds = np.ravel(np.logical_not(np.all(pm_grid.dipole_grid_xyz == 0.0, axis=-1)))\n        pm_grid.dipole_grid_xyz = pm_grid.dipole_grid_xyz[inds, :]\n        pm_grid.ndipoles = pm_grid.dipole_grid_xyz.shape[0]\n        pm_grid.pm_phi = np.arctan2(pm_grid.dipole_grid_xyz[:, 1], pm_grid.dipole_grid_xyz[:, 0])\n        if coordinate_flag == 'cylindrical':\n            cell_vol = np.sqrt(pm_grid.dipole_grid_xyz[:, 0] ** 2 + pm_grid.dipole_grid_xyz[:, 1] ** 2) * pm_grid.dr * pm_grid.dz * 2 * np.pi / (pm_grid.nphi * pm_grid.plasma_boundary.nfp * 2)\n        else:\n            cell_vol = pm_grid.dx * pm_grid.dy * pm_grid.dz * np.ones(pm_grid.ndipoles)     \n        pointsToVTK('dipole_grid',\n                    contig(pm_grid.dipole_grid_xyz[:, 0]),\n                    contig(pm_grid.dipole_grid_xyz[:, 1]),\n                    contig(pm_grid.dipole_grid_xyz[:, 2]))\n        if m_maxima is None:\n            B_max = 1.465  # value used in FAMUS runs for MUSE\n            mu0 = 4 * np.pi * 1e-7\n            pm_grid.m_maxima = B_max * cell_vol / mu0\n        else:\n            if isinstance(m_maxima, float):\n                pm_grid.m_maxima = m_maxima * np.ones(pm_grid.ndipoles)\n            else:\n                pm_grid.m_maxima = m_maxima\n            if len(pm_grid.m_maxima) != pm_grid.ndipoles:\n                raise ValueError(\n                    'm_maxima passed to geo_setup_from_famus but with '\n                    'the wrong shape, i.e. != number of dipoles.')\n        if pol_vectors is not None:\n            pol_vectors = np.array(pol_vectors)\n            if len(pol_vectors.shape) != 3:\n                raise ValueError('pol vectors must be a 3D array.')\n            elif pol_vectors.shape[2] != 3:\n                raise ValueError('Third dimension of `pol_vectors` array must be 3')\n            elif pm_grid.coordinate_flag != 'cartesian':\n                raise ValueError('pol_vectors argument can only be used with coordinate_flag = cartesian currently')\n            elif pol_vectors.shape[0] != pm_grid.ndipoles:\n                raise ValueError('First dimension of `pol_vectors` array '\n                                 'must equal the number of dipoles')\n\n        pm_grid.pol_vectors = pol_vectors\n        pm_grid._optimization_setup()\n        return pm_grid\n\n    def _optimization_setup(self):\n\n        if self.Bn.shape != (self.nphi, self.ntheta):\n            raise ValueError('Normal magnetic field surface data is incorrect shape.')\n\n        # minus sign below because ||Ax - b||^2 term but original\n        # term is integral(B_P + B_C + B_M)^2\n        self.b_obj = - self.Bn.reshape(self.nphi * self.ntheta)\n\n        # Compute geometric factor with the C++ routine\n        self.A_obj = sopp.dipole_field_Bn(\n            np.ascontiguousarray(self.plasma_boundary.gamma().reshape(-1, 3)),\n            np.ascontiguousarray(self.dipole_grid_xyz),\n            np.ascontiguousarray(self.plasma_boundary.unitnormal().reshape(-1, 3)),\n            self.plasma_boundary.nfp, int(self.plasma_boundary.stellsym),\n            np.ascontiguousarray(self.b_obj),\n            self.coordinate_flag,  # cartesian, cylindrical, or simple toroidal\n            self.R0\n        )\n\n        # Rescale the A matrix so that 0.5 * ||Am - b||^2 = f_b,\n        # where f_b is the metric for Bnormal on the plasma surface\n        Ngrid = self.nphi * self.ntheta\n        self.A_obj = self.A_obj.reshape(self.nphi * self.ntheta, self.ndipoles * 3)\n        Nnorms = np.ravel(np.sqrt(np.sum(self.plasma_boundary.normal() ** 2, axis=-1)))\n        for i in range(self.A_obj.shape[0]):\n            self.A_obj[i, :] = self.A_obj[i, :] * np.sqrt(Nnorms[i] / Ngrid)\n        self.b_obj = self.b_obj * np.sqrt(Nnorms / Ngrid)\n        self.ATb = self.A_obj.T @ self.b_obj\n\n        # Compute singular values of A, use this to determine optimal step size\n        # for the MwPGP algorithm, with alpha ~ 2 / ATA_scale\n        S = np.linalg.svd(self.A_obj, full_matrices=False, compute_uv=False)\n        self.ATA_scale = S[0] ** 2\n\n        # Set initial condition for the dipoles to default IC\n        self.m0 = np.zeros(self.ndipoles * 3)\n\n        # Set m to zeros\n        self.m = self.m0\n\n        # Print initial f_B metric using the initial guess\n        total_error = np.linalg.norm((self.A_obj.dot(self.m0) - self.b_obj), ord=2) ** 2 / 2.0\n        print('f_B (total with initial SIMSOPT guess) = ', total_error)\n\n    def _print_initial_opt(self):\n        \"\"\"\n        Print out initial errors and the bulk optimization parameters\n        before the permanent magnets are optimized.\n        \"\"\"\n        ave_Bn = np.mean(np.abs(self.b_obj))\n        total_Bn = np.sum(np.abs(self.b_obj) ** 2)\n        dipole_error = np.linalg.norm(self.A_obj.dot(self.m0), ord=2) ** 2\n        total_error = np.linalg.norm(self.A_obj.dot(self.m0) - self.b_obj, ord=2) ** 2\n        print('Number of phi quadrature points on plasma surface = ', self.nphi)\n        print('Number of theta quadrature points on plasma surface = ', self.ntheta)\n        print('<B * n> without the permanent magnets = {0:.4e}'.format(ave_Bn))\n        print(r'$|b|_2^2 = |B * n|_2^2$ without the permanent magnets = {0:.4e}'.format(total_Bn))\n        print(r'Initial $|Am_0|_2^2 = |B_M * n|_2^2$ without the coils/plasma = {0:.4e}'.format(dipole_error))\n        print('Number of dipoles = ', self.ndipoles)\n        print('Maximum dipole moment = ', np.max(self.m_maxima))\n        print('Shape of A matrix = ', self.A_obj.shape)\n        print('Shape of b vector = ', self.b_obj.shape)\n        print('Initial error on plasma surface = {0:.4e}'.format(total_error))\n\n    def write_to_famus(self, out_dir=''):\n        \"\"\"\n        Takes a PermanentMagnetGrid object and saves the geometry\n        and optimization solution into a FAMUS input file.\n\n        Args:\n            out_dir: Path object for the output directory for saved files.\n        \"\"\"\n        ndipoles = self.ndipoles\n        m = self.m.reshape(ndipoles, 3)\n        ox = self.dipole_grid_xyz[:, 0]\n        oy = self.dipole_grid_xyz[:, 1]\n        oz = self.dipole_grid_xyz[:, 2]\n\n        # Transform the solution vector to the Cartesian basis if necessary\n        if self.coordinate_flag == 'cartesian':\n            mx = m[:, 0]\n            my = m[:, 1]\n            mz = m[:, 2]\n        elif self.coordinate_flag == 'cylindrical':\n            cos_ophi = np.cos(self.pm_phi)\n            sin_ophi = np.sin(self.pm_phi)\n            mx = m[:, 0] * cos_ophi - m[:, 1] * sin_ophi\n            my = m[:, 0] * sin_ophi + m[:, 1] * cos_ophi\n            mz = m[:, 2]\n        elif self.coordinate_flag == 'toroidal':\n            ormajor = np.sqrt(ox**2 + oy**2)\n            otheta = np.arctan2(oz, ormajor - self.R0)\n            cos_ophi = np.cos(self.pm_phi)\n            sin_ophi = np.sin(self.pm_phi)\n            cos_otheta = np.cos(otheta)\n            sin_otheta = np.sin(otheta)\n            mx = m[:, 0] * cos_ophi * cos_otheta \\\n                - m[:, 1] * sin_ophi              \\\n                - m[:, 2] * cos_ophi * sin_otheta\n            my = m[:, 0] * sin_ophi * cos_otheta \\\n                + m[:, 1] * cos_ophi              \\\n                - m[:, 2] * sin_ophi * sin_otheta\n            mz = m[:, 0] * sin_otheta \\\n                + m[:, 2] * cos_otheta\n\n        m0 = self.m_maxima\n        pho = np.sqrt(np.sum(m ** 2, axis=-1)) / m0\n        Lc = 0\n\n        mp = np.arctan2(my, mx)\n        mt = np.arctan2(np.sqrt(mx ** 2 + my ** 2), mz)\n        coilname = [\"pm_{:010d}\".format(i) for i in range(1, ndipoles + 1)]\n        Ic = 1\n        # symmetry = 2 for stellarator symmetry\n        symmetry = int(self.plasma_boundary.stellsym) + 1\n        filename = Path(out_dir) / 'SIMSOPT_dipole_solution.focus'\n\n        with open(filename, \"w\") as wfile:\n            wfile.write(\" # Total number of dipoles,  momentq \\n\")\n            wfile.write(f\"{ndipoles:6d}  {1:4d}\\n\")     # .format(ndipoles, 1))\n            wfile.write(\"#coiltype, symmetry,  coilname,  ox,  oy,  oz,  Ic,  M_0,  pho,  Lc,  mp,  mt \\n\")\n            for i in range(ndipoles):\n                wfile.write(f\" 2, {symmetry:1d}, {coilname[i]}, {ox[i]:15.8E}, {oy[i]:15.8E}, \"\n                            f\"{oz[i]:15.8E}, {Ic:2d}, {m0[i]:15.8E}, {pho[i]:15.8E}, {Lc:2d}, \"\n                            f\"{mp[i]:15.8E}, {mt[i]:15.8E} \\n\")\n\n    def rescale_for_opt(self, reg_l0, reg_l1, reg_l2, nu):\n        \"\"\"\n        Scale regularizers to the largest scale of ATA (~1e-6)\n        to avoid regularization >> ||Am - b|| ** 2 term in the optimization.\n        The prox operator uses reg_l0 * nu for the threshold so normalization\n        below allows reg_l0 and reg_l1 values to be exactly the thresholds\n        used in calculation of the prox. Then add contributions to ATA and\n        ATb coming from extra loss terms such as L2 regularization and\n        relax-and-split. Currently does not rescale the L2 and nu\n        hyperparameters, but users may want to play around with this.\n\n        Args:\n            reg_l0: L0 regularization.\n            reg_l1: L1 regularization.\n            reg_l2: L2 regularization.\n            nu: nu hyperparameter in relax-and-split optimization.\n\n        Returns:\n            reg_l0: Rescaled L0 regularization.\n            reg_l1: Rescaled L1 regularization.\n            reg_l2: Rescaled L2 regularization.\n            nu: Rescaled nu hyperparameter in relax-and-split optimization.\n        \"\"\"\n\n        print('L2 regularization being used with coefficient = {0:.2e}'.format(reg_l2))\n\n        if reg_l0 < 0 or reg_l0 > 1:\n            raise ValueError(\n                'L0 regularization must be between 0 and 1. This '\n                'value is automatically scaled to the largest of the '\n                'dipole maximum values, so reg_l0 = 1 should basically '\n                'truncate all the dipoles to zero. ')\n\n        # Rescale L0 and L1 so that the values used for thresholding\n        # are only parametrized by the values of reg_l0 and reg_l1\n        reg_l0 = reg_l0 / (2 * nu)\n        reg_l1 = reg_l1 / nu\n\n        # may want to rescale nu, otherwise just scan this value\n        # nu = nu / self.ATA_scale\n\n        # Do not rescale L2 term for now.\n        reg_l2 = reg_l2\n\n        # Update algorithm step size if we have extra smooth, convex loss terms\n        self.ATA_scale += 2 * reg_l2 + 1.0 / nu\n\n        return reg_l0, reg_l1, reg_l2, nu",
  "def __init__(self, plasma_boundary: Surface, Bn, coordinate_flag='cartesian'):\n        Bn = np.array(Bn)\n        if len(Bn.shape) != 2: \n            raise ValueError('Normal magnetic field surface data is incorrect shape.')\n        self.Bn = Bn\n\n        if coordinate_flag == 'cartesian':\n            warnings.warn('Cartesian grid of rectangular cubes will be built, since '\n                          'coordinate_flag = \"cartesian\". However, such a grid can be '\n                          'appropriately reflected only for nfp = 2 and nfp = 4, '\n                          'unlike the uniform cylindrical grid, which has continuous '\n                          'rotational symmetry.')\n        self.coordinate_flag = coordinate_flag\n        self.plasma_boundary = plasma_boundary.to_RZFourier()\n        self.R0 = self.plasma_boundary.get_rc(0, 0)\n        self.nphi = len(self.plasma_boundary.quadpoints_phi)\n        self.ntheta = len(self.plasma_boundary.quadpoints_theta)",
  "def _setup_uniform_grid(self):\n        \"\"\"\n        Initializes a uniform grid in cartesian coordinates and sets\n        some important grid variables for later.\n        \"\"\"\n        # Get (X, Y, Z) coordinates of the two boundaries\n        self.xyz_inner = self.inner_toroidal_surface.gamma().reshape(-1, 3)\n        self.xyz_outer = self.outer_toroidal_surface.gamma().reshape(-1, 3)\n        if self.coordinate_flag != 'cylindrical':\n            x_outer = self.xyz_outer[:, 0]\n            y_outer = self.xyz_outer[:, 1]\n            z_outer = self.xyz_outer[:, 2]\n\n            x_max = np.max(x_outer)\n            x_min = np.min(x_outer)\n            y_max = np.max(y_outer)\n            y_min = np.min(y_outer)\n            z_max = np.max(z_outer)\n            z_min = np.min(z_outer)\n            z_max = max(z_max, abs(z_min))\n            print(x_min, x_max, y_min, y_max, z_min, z_max)\n\n            # Initialize uniform grid\n            Nx = self.Nx\n            Ny = self.Ny\n            Nz = self.Nz\n            self.dx = (x_max - x_min) / (Nx - 1)\n            self.dy = (y_max - y_min) / (Ny - 1)\n            self.dz = 2 * z_max / (Nz - 1)\n            print(Nx, Ny, Nz, self.dx, self.dy, self.dz)\n\n            # Extra work below so that the stitching with the symmetries is done in\n            # such a way that the reflected cells are still dx and dy away from\n            # the old cells.\n            #### Note that Cartesian cells can only do nfp = 2, 4, 6, ... \n            #### and correctly be rotated to have the right symmetries\n            if (self.plasma_boundary.nfp % 2) == 0:\n                X = np.linspace(self.dx / 2.0, (x_max - x_min) + self.dx / 2.0, Nx, endpoint=True)\n                Y = np.linspace(self.dy / 2.0, (y_max - y_min) + self.dy / 2.0, Ny, endpoint=True)\n            else:\n                X = np.linspace(x_min, x_max, Nx, endpoint=True)\n                Y = np.linspace(y_min, y_max, Ny, endpoint=True)\n            Z = np.linspace(-z_max, z_max, Nz, endpoint=True)\n\n            # Make 3D mesh\n            X, Y, Z = np.meshgrid(X, Y, Z, indexing='ij')\n            self.xyz_uniform = np.transpose(np.array([X, Y, Z]), [1, 2, 3, 0]).reshape(Nx * Ny * Nz, 3)\n\n            # Extra work for nfp = 4 to chop off half of the originally nfp = 2 uniform grid\n            if self.plasma_boundary.nfp == 4:\n                inds = []\n                for i in range(Nx):\n                    for j in range(Ny):\n                        for k in range(Nz):\n                            if X[i, j, k] < Y[i, j, k]:\n                                inds.append(int(i * Ny * Nz + j * Nz + k))\n                good_inds = np.setdiff1d(np.arange(Nx * Ny * Nz), inds)\n                self.xyz_uniform = self.xyz_uniform[good_inds, :]\n        else:\n            # Get (R, Z) coordinates of the outer boundary\n            rphiz_outer = np.array(\n                [np.sqrt(self.xyz_outer[:, 0] ** 2 + self.xyz_outer[:, 1] ** 2), \n                 np.arctan2(self.xyz_outer[:, 1], self.xyz_outer[:, 0]),\n                 self.xyz_outer[:, 2]]\n            ).T\n\n            r_max = np.max(rphiz_outer[:, 0])\n            r_min = np.min(rphiz_outer[:, 0])\n            z_max = np.max(rphiz_outer[:, 2])\n            z_min = np.min(rphiz_outer[:, 2])\n\n            # Initialize uniform grid of curved, square bricks\n            Nr = int((r_max - r_min) / self.dr)\n            self.Nr = Nr\n            self.dz = self.dr\n            Nz = int((z_max - z_min) / self.dz)\n            self.Nz = Nz\n            phi = 2 * np.pi * np.copy(self.plasma_boundary.quadpoints_phi)\n            R = np.linspace(r_min, r_max, Nr)\n            Z = np.linspace(z_min, z_max, Nz)\n\n            # Make 3D mesh\n            R, Phi, Z = np.meshgrid(R, phi, Z, indexing='ij')\n            X = R * np.cos(Phi)\n            Y = R * np.sin(Phi)\n            self.xyz_uniform = np.transpose(np.array([X, Y, Z]), [1, 2, 3, 0]).reshape(-1, 3)\n\n        # Save uniform grid before we start chopping off parts.\n        contig = np.ascontiguousarray\n        pointsToVTK('uniform_grid', contig(self.xyz_uniform[:, 0]),\n                    contig(self.xyz_uniform[:, 1]), contig(self.xyz_uniform[:, 2]))",
  "def geo_setup_from_famus(cls, plasma_boundary, Bn, famus_filename, **kwargs):\n        \"\"\"\n        Function to initialize a SIMSOPT PermanentMagnetGrid from a \n        pre-existing FAMUS file defining a grid of magnets. For\n        example, this function is used for the\n        half-Tesla NCSX configuration (c09r000) and MUSE grids.\n\n        Args\n        ----------\n        famus_filename : string\n            Filename of a FAMUS grid file (a pre-made dipole grid).\n        kwargs: The following are valid keyword arguments.\n            m_maxima: float or 1D numpy array, shape (Ndipoles)\n                Optional array of maximal dipole magnitudes for the permanent\n                magnets. If not provided, defaults to the common magnets\n                used in the MUSE design, with strengths ~ 1 Tesla.\n            pol_vectors: 3D numpy array, shape (Ndipoles, Ncoords, 3)\n                Optional set of local coordinate systems for each dipole, \n                which specifies which directions should be considered grid-aligned.\n                Ncoords can be > 3, as in the PM4Stell design.\n            coordinate_flag: string\n                Flag to specify the coordinate system used for the grid and optimization.\n                This is primarily used to tell the optimizer which coordinate directions\n                should be considered, \"grid-aligned\". Therefore, you can do weird stuff\n                like cartesian grid-alignment on a simple toroidal grid, which might\n                be self-defeating. However, if coordinate_flag='cartesian' a rectangular\n                Cartesian grid is initialized using the Nx, Ny, and Nz parameters. If\n                the coordinate_flag='cylindrical', a uniform cylindrical grid is initialized\n                using the dr and dz parameters.\n            downsample: int\n                Optional integer for downsampling the FAMUS grid, since\n                the MUSE and other grids can be very high resolution\n                and this makes CI take a long while.\n        Returns\n        -------\n        pm_grid: An initialized PermanentMagnetGrid class object.\n\n        \"\"\"\n        coordinate_flag = kwargs.pop(\"coordinate_flag\", \"cartesian\")\n        downsample = kwargs.pop(\"downsample\", 1)\n        pol_vectors = kwargs.pop(\"pol_vectors\", None)\n        m_maxima = kwargs.pop(\"m_maxima\", None)\n        if str(famus_filename)[-6:] != '.focus':\n            raise ValueError('Famus filename must end in .focus')\n\n        pm_grid = cls(plasma_boundary, Bn, coordinate_flag)\n        pm_grid.famus_filename = famus_filename\n        ox, oy, oz, Ic, M0s = np.loadtxt(famus_filename, skiprows=3, usecols=[3, 4, 5, 6, 7],\n                                         delimiter=',', unpack=True)\n\n        # Downsample the resolution as needed \n        inds_total = np.arange(len(ox))\n        inds_downsampled = inds_total[::downsample]\n\n        # also remove any dipoles where the diagnostic ports should be\n        nonzero_inds = np.intersect1d(np.ravel(np.where(Ic == 1.0)), inds_downsampled) \n        pm_grid.Ic_inds = nonzero_inds\n        ox = ox[nonzero_inds]\n        oy = oy[nonzero_inds]\n        oz = oz[nonzero_inds]\n        premade_dipole_grid = np.array([ox, oy, oz]).T\n        pm_grid.ndipoles = premade_dipole_grid.shape[0]\n\n        # Not normalized to 1 like quadpoints_phi!\n        pm_grid.pm_phi = np.arctan2(premade_dipole_grid[:, 1], premade_dipole_grid[:, 0])\n        uniq_phi, counts_phi = np.unique(pm_grid.pm_phi.round(decimals=6), return_counts=True)\n        pm_grid.pm_nphi = len(uniq_phi)\n        pm_grid.pm_uniq_phi = uniq_phi\n        pm_grid.inds = counts_phi\n        for i in reversed(range(1, pm_grid.pm_nphi)):\n            for j in range(0, i):\n                pm_grid.inds[i] += pm_grid.inds[j]\n        pm_grid.dipole_grid_xyz = premade_dipole_grid\n\n        if m_maxima is None:\n            B_max = 1.465  # value used in FAMUS runs for MUSE\n            mu0 = 4 * np.pi * 1e-7\n            cell_vol = M0s * mu0 / B_max\n            pm_grid.m_maxima = B_max * cell_vol[nonzero_inds] / mu0\n        else:\n            if isinstance(m_maxima, float):\n                pm_grid.m_maxima = m_maxima * np.ones(pm_grid.ndipoles)\n            else:\n                pm_grid.m_maxima = m_maxima\n            if len(pm_grid.m_maxima) != pm_grid.ndipoles:\n                raise ValueError('m_maxima passed to geo_setup_from_famus but with '\n                                 'the wrong shape, i.e. != number of dipoles.')\n\n        if pol_vectors is not None:\n            pol_vectors = np.array(pol_vectors)\n            if len(pol_vectors.shape) != 3:\n                raise ValueError('pol vectors must be a 3D array.')\n            elif pol_vectors.shape[2] != 3:\n                raise ValueError('Third dimension of `pol_vectors` array '\n                                 'must be 3')\n            elif pm_grid.coordinate_flag != 'cartesian':\n                raise ValueError('pol_vectors argument can only be used with coordinate_flag = cartesian currently')\n            elif pol_vectors.shape[0] != pm_grid.ndipoles:\n                raise ValueError('First dimension of `pol_vectors` array '\n                                 'must equal the number of dipoles')\n\n        pm_grid.pol_vectors = pol_vectors\n        pm_grid._optimization_setup()\n        return pm_grid",
  "def geo_setup_between_toroidal_surfaces(\n        cls, \n        plasma_boundary,\n        Bn,\n        inner_toroidal_surface: Surface, \n        outer_toroidal_surface: Surface,\n        **kwargs,\n    ):\n        \"\"\"\n        Function to initialize a SIMSOPT PermanentMagnetGrid from a \n        volume defined by two toroidal surfaces. These must be specified\n        directly. Often a good choice is made by extending the plasma \n        boundary by its normal vectors.\n\n        Args\n        ----------\n        inner_toroidal_surface: Surface class object \n            Representing the inner toroidal surface of the volume.\n            Gets converted into SurfaceRZFourier object for \n            ease of use.\n        outer_toroidal_surface: Surface object representing\n            the outer toroidal surface of the volume. Typically \n            want this to have same quadrature points as the inner\n            surface for a functional grid setup. \n            Gets converted into SurfaceRZFourier object for \n            ease of use.\n        kwargs: The following are valid keyword arguments.\n            m_maxima: float or 1D numpy array, shape (Ndipoles)\n                Optional array of maximal dipole magnitudes for the permanent\n                magnets. If not provided, defaults to the common magnets\n                used in the MUSE design, with strengths ~ 1 Tesla.\n            pol_vectors: 3D numpy array, shape (Ndipoles, Ncoords, 3)\n                Optional set of local coordinate systems for each dipole, \n                which specifies which directions should be considered grid-aligned.\n                Ncoords can be > 3, as in the PM4Stell design.\n            dr: double\n                Radial grid spacing in the permanent magnet manifold. Used only if \n                coordinate_flag = cylindrical, then dr is the radial size of the\n                cylindrical bricks in the grid.\n            dz: double\n                Axial grid spacing in the permanent magnet manifold. Used only if\n                coordinate_flag = cylindrical, then dz is the axial size of the\n                cylindrical bricks in the grid.\n            Nx: int\n                Number of points in x to use in a cartesian grid, taken between the \n                inner and outer toroidal surfaces. Used only if the\n                coordinate_flag = cartesian, then Nx is the x-size of the\n                rectangular cubes in the grid.\n            Ny: int\n                Number of points in y to use in a cartesian grid, taken between the \n                inner and outer toroidal surfaces. Used only if the\n                coordinate_flag = cartesian, then Ny is the y-size of the\n                rectangular cubes in the grid.\n            Nz: int\n                Number of points in z to use in a cartesian grid, taken between the \n                inner and outer toroidal surfaces. Used only if the\n                coordinate_flag = cartesian, then Nz is the z-size of the\n                rectangular cubes in the grid.\n            coordinate_flag: string\n                Flag to specify the coordinate system used for the grid and optimization.\n                This is primarily used to tell the optimizer which coordinate directions\n                should be considered, \"grid-aligned\". Therefore, you can do weird stuff\n                like cartesian grid-alignment on a simple toroidal grid, which might\n                be self-defeating. However, if coordinate_flag='cartesian' a rectangular\n                Cartesian grid is initialized using the Nx, Ny, and Nz parameters. If\n                the coordinate_flag='cylindrical', a uniform cylindrical grid is initialized\n                using the dr and dz parameters.\n        Returns\n        -------\n        pm_grid: An initialized PermanentMagnetGrid class object.\n\n        \"\"\"\n        coordinate_flag = kwargs.pop(\"coordinate_flag\", \"cartesian\")\n        pol_vectors = kwargs.pop(\"pol_vectors\", None)\n        m_maxima = kwargs.pop(\"m_maxima\", None)\n        pm_grid = cls(plasma_boundary, Bn, coordinate_flag) \n        Nx = kwargs.pop(\"Nx\", 10)\n        Ny = kwargs.pop(\"Ny\", 10)\n        Nz = kwargs.pop(\"Nz\", 10)\n        dr = kwargs.pop(\"dr\", 0.1)\n        dz = kwargs.pop(\"dz\", 0.1)\n        if Nx <= 0 or Ny <= 0 or Nz <= 0:\n            raise ValueError('Nx, Ny, and Nz should be positive integers')\n        if dr <= 0 or dz <= 0:\n            raise ValueError('dr and dz should be positive floats')\n        pm_grid.dr = dr\n        pm_grid.dz = dz\n        pm_grid.Nx = Nx\n        pm_grid.Ny = Ny\n        pm_grid.Nz = Nz\n        pm_grid.inner_toroidal_surface = inner_toroidal_surface.to_RZFourier()\n        pm_grid.outer_toroidal_surface = outer_toroidal_surface.to_RZFourier()    \n        warnings.warn(\n            'Plasma boundary and inner and outer toroidal surfaces should '\n            'all have the same \"range\" parameter in order for a permanent'\n            ' magnet grid to be correctly initialized.'\n        )        \n\n        # Have the uniform grid, now need to loop through and eliminate cells.\n        contig = np.ascontiguousarray\n        normal_inner = inner_toroidal_surface.unitnormal().reshape(-1, 3)   \n        normal_outer = outer_toroidal_surface.unitnormal().reshape(-1, 3)   \n        pm_grid._setup_uniform_grid()\n        pm_grid.dipole_grid_xyz = sopp.define_a_uniform_cartesian_grid_between_two_toroidal_surfaces(\n            contig(normal_inner), \n            contig(normal_outer), \n            contig(pm_grid.xyz_uniform), \n            contig(pm_grid.xyz_inner), \n            contig(pm_grid.xyz_outer))\n        inds = np.ravel(np.logical_not(np.all(pm_grid.dipole_grid_xyz == 0.0, axis=-1)))\n        pm_grid.dipole_grid_xyz = pm_grid.dipole_grid_xyz[inds, :]\n        pm_grid.ndipoles = pm_grid.dipole_grid_xyz.shape[0]\n        pm_grid.pm_phi = np.arctan2(pm_grid.dipole_grid_xyz[:, 1], pm_grid.dipole_grid_xyz[:, 0])\n        if coordinate_flag == 'cylindrical':\n            cell_vol = np.sqrt(pm_grid.dipole_grid_xyz[:, 0] ** 2 + pm_grid.dipole_grid_xyz[:, 1] ** 2) * pm_grid.dr * pm_grid.dz * 2 * np.pi / (pm_grid.nphi * pm_grid.plasma_boundary.nfp * 2)\n        else:\n            cell_vol = pm_grid.dx * pm_grid.dy * pm_grid.dz * np.ones(pm_grid.ndipoles)     \n        pointsToVTK('dipole_grid',\n                    contig(pm_grid.dipole_grid_xyz[:, 0]),\n                    contig(pm_grid.dipole_grid_xyz[:, 1]),\n                    contig(pm_grid.dipole_grid_xyz[:, 2]))\n        if m_maxima is None:\n            B_max = 1.465  # value used in FAMUS runs for MUSE\n            mu0 = 4 * np.pi * 1e-7\n            pm_grid.m_maxima = B_max * cell_vol / mu0\n        else:\n            if isinstance(m_maxima, float):\n                pm_grid.m_maxima = m_maxima * np.ones(pm_grid.ndipoles)\n            else:\n                pm_grid.m_maxima = m_maxima\n            if len(pm_grid.m_maxima) != pm_grid.ndipoles:\n                raise ValueError(\n                    'm_maxima passed to geo_setup_from_famus but with '\n                    'the wrong shape, i.e. != number of dipoles.')\n        if pol_vectors is not None:\n            pol_vectors = np.array(pol_vectors)\n            if len(pol_vectors.shape) != 3:\n                raise ValueError('pol vectors must be a 3D array.')\n            elif pol_vectors.shape[2] != 3:\n                raise ValueError('Third dimension of `pol_vectors` array must be 3')\n            elif pm_grid.coordinate_flag != 'cartesian':\n                raise ValueError('pol_vectors argument can only be used with coordinate_flag = cartesian currently')\n            elif pol_vectors.shape[0] != pm_grid.ndipoles:\n                raise ValueError('First dimension of `pol_vectors` array '\n                                 'must equal the number of dipoles')\n\n        pm_grid.pol_vectors = pol_vectors\n        pm_grid._optimization_setup()\n        return pm_grid",
  "def _optimization_setup(self):\n\n        if self.Bn.shape != (self.nphi, self.ntheta):\n            raise ValueError('Normal magnetic field surface data is incorrect shape.')\n\n        # minus sign below because ||Ax - b||^2 term but original\n        # term is integral(B_P + B_C + B_M)^2\n        self.b_obj = - self.Bn.reshape(self.nphi * self.ntheta)\n\n        # Compute geometric factor with the C++ routine\n        self.A_obj = sopp.dipole_field_Bn(\n            np.ascontiguousarray(self.plasma_boundary.gamma().reshape(-1, 3)),\n            np.ascontiguousarray(self.dipole_grid_xyz),\n            np.ascontiguousarray(self.plasma_boundary.unitnormal().reshape(-1, 3)),\n            self.plasma_boundary.nfp, int(self.plasma_boundary.stellsym),\n            np.ascontiguousarray(self.b_obj),\n            self.coordinate_flag,  # cartesian, cylindrical, or simple toroidal\n            self.R0\n        )\n\n        # Rescale the A matrix so that 0.5 * ||Am - b||^2 = f_b,\n        # where f_b is the metric for Bnormal on the plasma surface\n        Ngrid = self.nphi * self.ntheta\n        self.A_obj = self.A_obj.reshape(self.nphi * self.ntheta, self.ndipoles * 3)\n        Nnorms = np.ravel(np.sqrt(np.sum(self.plasma_boundary.normal() ** 2, axis=-1)))\n        for i in range(self.A_obj.shape[0]):\n            self.A_obj[i, :] = self.A_obj[i, :] * np.sqrt(Nnorms[i] / Ngrid)\n        self.b_obj = self.b_obj * np.sqrt(Nnorms / Ngrid)\n        self.ATb = self.A_obj.T @ self.b_obj\n\n        # Compute singular values of A, use this to determine optimal step size\n        # for the MwPGP algorithm, with alpha ~ 2 / ATA_scale\n        S = np.linalg.svd(self.A_obj, full_matrices=False, compute_uv=False)\n        self.ATA_scale = S[0] ** 2\n\n        # Set initial condition for the dipoles to default IC\n        self.m0 = np.zeros(self.ndipoles * 3)\n\n        # Set m to zeros\n        self.m = self.m0\n\n        # Print initial f_B metric using the initial guess\n        total_error = np.linalg.norm((self.A_obj.dot(self.m0) - self.b_obj), ord=2) ** 2 / 2.0\n        print('f_B (total with initial SIMSOPT guess) = ', total_error)",
  "def _print_initial_opt(self):\n        \"\"\"\n        Print out initial errors and the bulk optimization parameters\n        before the permanent magnets are optimized.\n        \"\"\"\n        ave_Bn = np.mean(np.abs(self.b_obj))\n        total_Bn = np.sum(np.abs(self.b_obj) ** 2)\n        dipole_error = np.linalg.norm(self.A_obj.dot(self.m0), ord=2) ** 2\n        total_error = np.linalg.norm(self.A_obj.dot(self.m0) - self.b_obj, ord=2) ** 2\n        print('Number of phi quadrature points on plasma surface = ', self.nphi)\n        print('Number of theta quadrature points on plasma surface = ', self.ntheta)\n        print('<B * n> without the permanent magnets = {0:.4e}'.format(ave_Bn))\n        print(r'$|b|_2^2 = |B * n|_2^2$ without the permanent magnets = {0:.4e}'.format(total_Bn))\n        print(r'Initial $|Am_0|_2^2 = |B_M * n|_2^2$ without the coils/plasma = {0:.4e}'.format(dipole_error))\n        print('Number of dipoles = ', self.ndipoles)\n        print('Maximum dipole moment = ', np.max(self.m_maxima))\n        print('Shape of A matrix = ', self.A_obj.shape)\n        print('Shape of b vector = ', self.b_obj.shape)\n        print('Initial error on plasma surface = {0:.4e}'.format(total_error))",
  "def write_to_famus(self, out_dir=''):\n        \"\"\"\n        Takes a PermanentMagnetGrid object and saves the geometry\n        and optimization solution into a FAMUS input file.\n\n        Args:\n            out_dir: Path object for the output directory for saved files.\n        \"\"\"\n        ndipoles = self.ndipoles\n        m = self.m.reshape(ndipoles, 3)\n        ox = self.dipole_grid_xyz[:, 0]\n        oy = self.dipole_grid_xyz[:, 1]\n        oz = self.dipole_grid_xyz[:, 2]\n\n        # Transform the solution vector to the Cartesian basis if necessary\n        if self.coordinate_flag == 'cartesian':\n            mx = m[:, 0]\n            my = m[:, 1]\n            mz = m[:, 2]\n        elif self.coordinate_flag == 'cylindrical':\n            cos_ophi = np.cos(self.pm_phi)\n            sin_ophi = np.sin(self.pm_phi)\n            mx = m[:, 0] * cos_ophi - m[:, 1] * sin_ophi\n            my = m[:, 0] * sin_ophi + m[:, 1] * cos_ophi\n            mz = m[:, 2]\n        elif self.coordinate_flag == 'toroidal':\n            ormajor = np.sqrt(ox**2 + oy**2)\n            otheta = np.arctan2(oz, ormajor - self.R0)\n            cos_ophi = np.cos(self.pm_phi)\n            sin_ophi = np.sin(self.pm_phi)\n            cos_otheta = np.cos(otheta)\n            sin_otheta = np.sin(otheta)\n            mx = m[:, 0] * cos_ophi * cos_otheta \\\n                - m[:, 1] * sin_ophi              \\\n                - m[:, 2] * cos_ophi * sin_otheta\n            my = m[:, 0] * sin_ophi * cos_otheta \\\n                + m[:, 1] * cos_ophi              \\\n                - m[:, 2] * sin_ophi * sin_otheta\n            mz = m[:, 0] * sin_otheta \\\n                + m[:, 2] * cos_otheta\n\n        m0 = self.m_maxima\n        pho = np.sqrt(np.sum(m ** 2, axis=-1)) / m0\n        Lc = 0\n\n        mp = np.arctan2(my, mx)\n        mt = np.arctan2(np.sqrt(mx ** 2 + my ** 2), mz)\n        coilname = [\"pm_{:010d}\".format(i) for i in range(1, ndipoles + 1)]\n        Ic = 1\n        # symmetry = 2 for stellarator symmetry\n        symmetry = int(self.plasma_boundary.stellsym) + 1\n        filename = Path(out_dir) / 'SIMSOPT_dipole_solution.focus'\n\n        with open(filename, \"w\") as wfile:\n            wfile.write(\" # Total number of dipoles,  momentq \\n\")\n            wfile.write(f\"{ndipoles:6d}  {1:4d}\\n\")     # .format(ndipoles, 1))\n            wfile.write(\"#coiltype, symmetry,  coilname,  ox,  oy,  oz,  Ic,  M_0,  pho,  Lc,  mp,  mt \\n\")\n            for i in range(ndipoles):\n                wfile.write(f\" 2, {symmetry:1d}, {coilname[i]}, {ox[i]:15.8E}, {oy[i]:15.8E}, \"\n                            f\"{oz[i]:15.8E}, {Ic:2d}, {m0[i]:15.8E}, {pho[i]:15.8E}, {Lc:2d}, \"\n                            f\"{mp[i]:15.8E}, {mt[i]:15.8E} \\n\")",
  "def rescale_for_opt(self, reg_l0, reg_l1, reg_l2, nu):\n        \"\"\"\n        Scale regularizers to the largest scale of ATA (~1e-6)\n        to avoid regularization >> ||Am - b|| ** 2 term in the optimization.\n        The prox operator uses reg_l0 * nu for the threshold so normalization\n        below allows reg_l0 and reg_l1 values to be exactly the thresholds\n        used in calculation of the prox. Then add contributions to ATA and\n        ATb coming from extra loss terms such as L2 regularization and\n        relax-and-split. Currently does not rescale the L2 and nu\n        hyperparameters, but users may want to play around with this.\n\n        Args:\n            reg_l0: L0 regularization.\n            reg_l1: L1 regularization.\n            reg_l2: L2 regularization.\n            nu: nu hyperparameter in relax-and-split optimization.\n\n        Returns:\n            reg_l0: Rescaled L0 regularization.\n            reg_l1: Rescaled L1 regularization.\n            reg_l2: Rescaled L2 regularization.\n            nu: Rescaled nu hyperparameter in relax-and-split optimization.\n        \"\"\"\n\n        print('L2 regularization being used with coefficient = {0:.2e}'.format(reg_l2))\n\n        if reg_l0 < 0 or reg_l0 > 1:\n            raise ValueError(\n                'L0 regularization must be between 0 and 1. This '\n                'value is automatically scaled to the largest of the '\n                'dipole maximum values, so reg_l0 = 1 should basically '\n                'truncate all the dipoles to zero. ')\n\n        # Rescale L0 and L1 so that the values used for thresholding\n        # are only parametrized by the values of reg_l0 and reg_l1\n        reg_l0 = reg_l0 / (2 * nu)\n        reg_l1 = reg_l1 / nu\n\n        # may want to rescale nu, otherwise just scan this value\n        # nu = nu / self.ATA_scale\n\n        # Do not rescale L2 term for now.\n        reg_l2 = reg_l2\n\n        # Update algorithm step size if we have extra smooth, convex loss terms\n        self.ATA_scale += 2 * reg_l2 + 1.0 / nu\n\n        return reg_l0, reg_l1, reg_l2, nu",
  "class Area(Optimizable):\n    \"\"\"\n    Wrapper class for surface area label.\n    \"\"\"\n\n    def __init__(self, surface, range=None, nphi=None, ntheta=None):\n\n        if range is not None or nphi is not None or ntheta is not None:\n            if range is None:\n                if surface.stellsym:\n                    range = Surface.RANGE_HALF_PERIOD\n                else:\n                    range = Surface.RANGE_FIELD_PERIOD\n            if nphi is None:\n                nphi = len(surface.quadpoints_phi)\n            if ntheta is None:\n                ntheta = len(surface.quadpoints_theta)\n            self.surface = surface.__class__.from_nphi_ntheta(nphi=nphi, ntheta=ntheta, range=range, nfp=surface.nfp, stellsym=surface.stellsym, \\\n                                                              mpol=surface.mpol, ntor=surface.ntor, dofs=surface.dofs)\n        else:\n            self.surface = surface\n\n        self.range = range\n        self.nphi = nphi\n        self.ntheta = ntheta\n\n        super().__init__(depends_on=[self.surface])\n\n    def J(self):\n        \"\"\"\n        Compute the area of a surface.\n        \"\"\"\n        return self.surface.area()\n\n    @derivative_dec\n    def dJ(self):\n        return Derivative({self.surface: self.dJ_by_dsurfacecoefficients()})\n\n    def dJ_by_dsurfacecoefficients(self):\n        \"\"\"\n        Calculate the partial derivatives with respect to the surface coefficients.\n        \"\"\"\n        return self.surface.darea_by_dcoeff()\n\n    def d2J_by_dsurfacecoefficientsdsurfacecoefficients(self):\n        \"\"\"\n        Calculate the second partial derivatives with respect to the surface coefficients.\n        \"\"\"\n        return self.surface.d2area_by_dcoeffdcoeff()",
  "class Volume(Optimizable):\n    \"\"\"\n    Wrapper class for volume label.\n    \"\"\"\n\n    def __init__(self, surface, range=None, nphi=None, ntheta=None):\n\n        if range is not None or nphi is not None or ntheta is not None:\n            if range is None:\n                if surface.stellsym:\n                    range = Surface.RANGE_HALF_PERIOD\n                else:\n                    range = Surface.RANGE_FIELD_PERIOD\n            if nphi is None:\n                nphi = len(surface.quadpoints_phi)\n            if ntheta is None:\n                ntheta = len(surface.quadpoints_theta)\n            self.surface = surface.__class__.from_nphi_ntheta(nphi=nphi, ntheta=ntheta, range=range, nfp=surface.nfp, stellsym=surface.stellsym, \\\n                                                              mpol=surface.mpol, ntor=surface.ntor, dofs=surface.dofs)\n        else:\n            self.surface = surface\n\n        self.range = range\n        self.nphi = nphi\n        self.ntheta = ntheta\n\n        super().__init__(depends_on=[self.surface])\n\n    def J(self):\n        \"\"\"\n        Compute the volume enclosed by the surface.\n        \"\"\"\n        return self.surface.volume()\n\n    @derivative_dec\n    def dJ(self):\n        return Derivative({self.surface: self.dJ_by_dsurfacecoefficients()})\n\n    def dJ_by_dsurfacecoefficients(self):\n        \"\"\"\n        Calculate the derivatives with respect to the surface coefficients.\n        \"\"\"\n        return self.surface.dvolume_by_dcoeff()\n\n    def d2J_by_dsurfacecoefficientsdsurfacecoefficients(self):\n        \"\"\"\n        Calculate the second derivatives with respect to the surface coefficients.\n        \"\"\"\n        return self.surface.d2volume_by_dcoeffdcoeff()",
  "class ToroidalFlux(Optimizable):\n    r\"\"\"\n    Given a surface and Biot Savart kernel, this objective calculates\n\n    .. math::\n       J &= \\int_{S_{\\varphi}} \\mathbf{B} \\cdot \\mathbf{n} ~ds, \\\\\n       &= \\int_{S_{\\varphi}} \\text{curl} \\mathbf{A} \\cdot \\mathbf{n} ~ds, \\\\\n       &= \\int_{\\partial S_{\\varphi}} \\mathbf{A} \\cdot \\mathbf{t}~dl,\n\n    where :math:`S_{\\varphi}` is a surface of constant :math:`\\varphi`, and :math:`\\mathbf A`\n    is the magnetic vector potential.\n    \"\"\"\n\n    def __init__(self, surface, biotsavart, idx=0, range=None, nphi=None, ntheta=None):\n\n        if range is not None or nphi is not None or ntheta is not None:\n            if range is None:\n                if surface.stellsym:\n                    range = Surface.RANGE_HALF_PERIOD\n                else:\n                    range = Surface.RANGE_FIELD_PERIOD\n            if nphi is None:\n                nphi = len(surface.quadpoints_phi)\n            if ntheta is None:\n                ntheta = len(surface.quadpoints_theta)\n            self.surface = surface.__class__.from_nphi_ntheta(nphi=nphi, ntheta=ntheta, range=range, nfp=surface.nfp, stellsym=surface.stellsym, \\\n                                                              mpol=surface.mpol, ntor=surface.ntor, dofs=surface.dofs)\n        else:\n            self.surface = surface\n\n        self.biotsavart = biotsavart\n        self.idx = idx\n\n        self.range = range\n        self.nphi = nphi\n        self.ntheta = ntheta\n\n        super().__init__(depends_on=[self.surface, biotsavart])\n\n    def recompute_bell(self, parent=None):\n        self.invalidate_cache()\n\n    def invalidate_cache(self):\n        x = self.surface.gamma()[self.idx]\n        self.biotsavart.set_points(x)\n\n    def J(self):\n        r\"\"\"\n        Compute the toroidal flux on the surface where\n        :math:`\\varphi = \\texttt{quadpoints_varphi}[\\texttt{idx}]`.\n        \"\"\"\n        xtheta = self.surface.gammadash2()[self.idx]\n        ntheta = self.surface.gamma().shape[1]\n        A = self.biotsavart.A()\n        tf = np.sum(A * xtheta)/ntheta\n        return tf\n\n    @derivative_dec\n    def dJ(self):\n        d_s = Derivative({self.surface: self.dJ_by_dsurfacecoefficients()})\n        d_c = self.dJ_by_dcoils()\n        return d_s + d_c\n\n    def dJ_by_dsurfacecoefficients(self):\n        \"\"\"\n        Calculate the partial derivatives with respect to the surface coefficients.\n        \"\"\"\n        ntheta = self.surface.gamma().shape[1]\n        dA_by_dX = self.biotsavart.dA_by_dX()\n        A = self.biotsavart.A()\n        dgammadash2 = self.surface.gammadash2()[self.idx, :]\n        dgammadash2_by_dc = self.surface.dgammadash2_by_dcoeff()[self.idx, :]\n\n        dx_dc = self.surface.dgamma_by_dcoeff()[self.idx]\n        dA_dc = np.sum(dA_by_dX[..., :, None] * dx_dc[..., None, :], axis=1)\n        term1 = np.sum(dA_dc * dgammadash2[..., None], axis=(0, 1))\n        term2 = np.sum(A[..., None] * dgammadash2_by_dc, axis=(0, 1))\n\n        out = (term1+term2)/ntheta\n        return out\n\n    def d2J_by_dsurfacecoefficientsdsurfacecoefficients(self):\n        \"\"\"\n        Calculate the second partial derivatives with respect to the surface coefficients.\n        \"\"\"\n        ntheta = self.surface.gamma().shape[1]\n        dx_dc = self.surface.dgamma_by_dcoeff()[self.idx]\n        d2A_by_dXdX = self.biotsavart.d2A_by_dXdX().reshape((ntheta, 3, 3, 3))\n        dA_by_dX = self.biotsavart.dA_by_dX()\n        dA_dc = np.sum(dA_by_dX[..., :, None] * dx_dc[..., None, :], axis=1)\n        d2A_dcdc = np.einsum('jkpl,jpn,jkm->jlmn', d2A_by_dXdX, dx_dc, dx_dc)\n\n        dgammadash2 = self.surface.gammadash2()[self.idx]\n        dgammadash2_by_dc = self.surface.dgammadash2_by_dcoeff()[self.idx]\n\n        term1 = np.sum(d2A_dcdc * dgammadash2[..., None, None], axis=-3)\n        term2 = np.sum(dA_dc[..., :, None] * dgammadash2_by_dc[..., None, :], axis=-3)\n        term3 = np.sum(dA_dc[..., None, :] * dgammadash2_by_dc[..., :, None], axis=-3)\n\n        out = (1/ntheta) * np.sum(term1+term2+term3, axis=0)\n        return out\n\n    def dJ_by_dcoils(self):\n        \"\"\"\n        Calculate the partial derivatives with respect to the coil coefficients.\n        \"\"\"\n        xtheta = self.surface.gammadash2()[self.idx]\n        ntheta = self.surface.gamma().shape[1]\n        dJ_by_dA = xtheta/ntheta\n        dJ_by_dcoils = self.biotsavart.A_vjp(dJ_by_dA)\n        return dJ_by_dcoils",
  "class PrincipalCurvature(Optimizable):\n    r\"\"\"\n\n    Given a Surface, evaluates a metric based on the principal curvatures,\n    :math:`\\kappa_1` and :math:`\\kappa_2`, where :math:`\\kappa_1>\\kappa_2`.\n    This metric is designed to penalize :math:`\\kappa_1 > \\kappa_{\\max,1}` and\n    :math:`-\\kappa_2 > \\kappa_{\\max,2}`.\n\n    .. math::\n       J &= \\int d^2 x \\exp \\left(- ( \\kappa_1 - \\kappa_{\\max,1})/w_1) \\right) \\\\\n         &+ \\int d^2 x \\exp \\left(- (-\\kappa_2 - \\kappa_{\\max,2})/w_2) \\right).\n\n    This metric can be used as a regularization within fixed-boundary optimization\n    to prevent, for example, surfaces with concave regions\n    (large values of :math:`|\\kappa_2|`) or surfaces with large elongation\n    (large values of :math:`\\kappa_1`).\n\n    \"\"\"\n\n    def __init__(self, surface, kappamax1=1, kappamax2=1, weight1=0.05, weight2=0.05):\n        super().__init__(depends_on=[surface])\n        self.surface = surface\n        self.kappamax1 = kappamax1\n        self.kappamax2 = kappamax2\n        self.weight1 = weight1\n        self.weight2 = weight2\n\n    def J(self):\n        curvature = self.surface.surface_curvatures()\n        k1 = curvature[:, :, 2]  # larger\n        k2 = curvature[:, :, 3]  # smaller\n        normal = self.surface.normal()\n        norm_normal = np.sqrt(normal[:, :, 0]**2 + normal[:, :, 1]**2 + normal[:, :, 2]**2)\n        return np.sum(norm_normal * np.exp(-(k1 - self.kappamax1)/self.weight1)) + \\\n            np.sum(norm_normal * np.exp(-(-k2 - self.kappamax2)/self.weight2))\n\n    @derivative_dec\n    def dJ(self):\n        curvature = self.surface.surface_curvatures()\n        k1 = curvature[:, :, 2]  # larger\n        k2 = curvature[:, :, 3]  # smaller\n        normal = self.surface.normal()\n        norm_normal = np.sqrt(normal[:, :, 0]**2 + normal[:, :, 1]**2 + normal[:, :, 2]**2)\n        dcurvature_dc = self.surface.dsurface_curvatures_by_dcoeff()\n        dk1_dc = dcurvature_dc[:, :, 2, :]\n        dk2_dc = dcurvature_dc[:, :, 3, :]\n        dnormal_dc = self.surface.dnormal_by_dcoeff()\n        dnorm_normal_dc = normal[:, :, 0, None]*dnormal_dc[:, :, 0, :]/norm_normal[:, :, None] + \\\n            normal[:, :, 1, None]*dnormal_dc[:, :, 1, :]/norm_normal[:, :, None] + \\\n            normal[:, :, 2, None]*dnormal_dc[:, :, 2, :]/norm_normal[:, :, None]\n        deriv = np.sum(dnorm_normal_dc * np.exp(-(k1[:, :, None] - self.kappamax1)/self.weight1), axis=(0, 1)) + \\\n            np.sum(norm_normal[:, :, None] * np.exp(-(k1[:, :, None] - self.kappamax1)/self.weight1) * (- dk1_dc/self.weight1), axis=(0, 1)) + \\\n            np.sum(dnorm_normal_dc * np.exp(-(-k2[:, :, None] - self.kappamax2)/self.weight2), axis=(0, 1)) + \\\n            np.sum(norm_normal[:, :, None] * np.exp(-(-k2[:, :, None] - self.kappamax2)/self.weight2) * (dk2_dc/self.weight2), axis=(0, 1))\n        return Derivative({self.surface: deriv})",
  "def boozer_surface_residual(surface, iota, G, biotsavart, derivatives=0):\n    r\"\"\"\n    For a given surface, this function computes the\n    residual\n\n    .. math::\n        G\\mathbf B(\\mathbf x) - \\|\\mathbf B(\\mathbf x)\\|^2  (\\mathbf x_\\varphi + \\iota  \\mathbf x_\\theta)\n\n    as well as the derivatives of this residual with respect to surface dofs,\n    iota, and G.  In the above, :math:`\\mathbf x` are points on the surface, :math:`\\iota` is the\n    rotational transform on that surface, and :math:`\\mathbf B` is the magnetic field.\n\n    :math:`G` is known for exact boozer surfaces, so if ``G=None`` is passed, then that\n    value is used instead.\n    \"\"\"\n\n    user_provided_G = G is not None\n    if not user_provided_G:\n        G = 2. * np.pi * np.sum([np.abs(c.current.get_value()) for c in biotsavart.coils]) * (4 * np.pi * 10**(-7) / (2 * np.pi))\n\n    x = surface.gamma()\n    xphi = surface.gammadash1()\n    xtheta = surface.gammadash2()\n    nphi = x.shape[0]\n    ntheta = x.shape[1]\n\n    xsemiflat = x.reshape((x.size//3, 3)).copy()\n\n    biotsavart.set_points(xsemiflat)\n\n    biotsavart.compute(derivatives)\n    B = biotsavart.B().reshape((nphi, ntheta, 3))\n\n    tang = xphi + iota * xtheta\n    B2 = np.sum(B**2, axis=2)\n    residual = G*B - B2[..., None] * tang\n\n    residual_flattened = residual.reshape((nphi*ntheta*3, ))\n    r = residual_flattened\n    if derivatives == 0:\n        return r,\n\n    dx_dc = surface.dgamma_by_dcoeff()\n    dxphi_dc = surface.dgammadash1_by_dcoeff()\n    dxtheta_dc = surface.dgammadash2_by_dcoeff()\n    nsurfdofs = dx_dc.shape[-1]\n\n    dB_by_dX = biotsavart.dB_by_dX().reshape((nphi, ntheta, 3, 3))\n    dB_dc = np.einsum('ijkl,ijkm->ijlm', dB_by_dX, dx_dc)\n\n    # dresidual_dc = G*dB_dc - 2*np.sum(B[..., None]*dB_dc, axis=2)[:, :, None, :] * tang[..., None] - B2[..., None, None] * (dxphi_dc + iota * dxtheta_dc)\n    dresidual_dc = sopp.boozer_dresidual_dc(G, dB_dc, B, tang, B2, dxphi_dc, iota, dxtheta_dc)\n    dresidual_diota = -B2[..., None] * xtheta\n\n    dresidual_dc_flattened = dresidual_dc.reshape((nphi*ntheta*3, nsurfdofs))\n    dresidual_diota_flattened = dresidual_diota.reshape((nphi*ntheta*3, 1))\n\n    if user_provided_G:\n        dresidual_dG = B\n        dresidual_dG_flattened = dresidual_dG.reshape((nphi*ntheta*3, 1))\n        J = np.concatenate((dresidual_dc_flattened, dresidual_diota_flattened, dresidual_dG_flattened), axis=1)\n    else:\n        J = np.concatenate((dresidual_dc_flattened, dresidual_diota_flattened), axis=1)\n    if derivatives == 1:\n        return r, J\n\n    d2B_by_dXdX = biotsavart.d2B_by_dXdX().reshape((nphi, ntheta, 3, 3, 3))\n    d2B_dcdc = np.einsum('ijkpl,ijpn,ijkm->ijlmn', d2B_by_dXdX, dx_dc, dx_dc)\n    dB2_dc = 2. * np.einsum('ijl,ijlm->ijm', B, dB_dc)\n\n    term1 = np.einsum('ijlm,ijln->ijmn', dB_dc, dB_dc)\n    term2 = np.einsum('ijlmn,ijl->ijmn', d2B_dcdc, B)\n    d2B2_dcdc = 2*(term1 + term2)\n\n    term1 = -(dxphi_dc[..., None, :] + iota * dxtheta_dc[..., None, :]) * dB2_dc[..., None, :, None]\n    term2 = -(dxphi_dc[..., :, None] + iota * dxtheta_dc[..., :, None]) * dB2_dc[..., None, None, :]\n    term3 = -(xphi[..., None, None] + iota * xtheta[..., None, None]) * d2B2_dcdc[..., None, :, :]\n    d2residual_by_dcdc = G * d2B_dcdc + term1 + term2 + term3\n    d2residual_by_dcdiota = -(dB2_dc[..., None, :] * xtheta[..., :, None] + B2[..., None, None] * dxtheta_dc)\n    d2residual_by_diotadiota = np.zeros(dresidual_diota.shape)\n\n    d2residual_by_dcdc_flattened = d2residual_by_dcdc.reshape((nphi*ntheta*3, nsurfdofs, nsurfdofs))\n    d2residual_by_dcdiota_flattened = d2residual_by_dcdiota.reshape((nphi*ntheta*3, nsurfdofs))\n    d2residual_by_diotadiota_flattened = d2residual_by_diotadiota.reshape((nphi*ntheta*3,))\n\n    if user_provided_G:\n        d2residual_by_dcdG = dB_dc\n        d2residual_by_diotadG = np.zeros(dresidual_diota.shape)\n        d2residual_by_dGdG = np.zeros(dresidual_dG.shape)\n        d2residual_by_dcdG_flattened = d2residual_by_dcdG.reshape((nphi*ntheta*3, nsurfdofs))\n        d2residual_by_diotadG_flattened = d2residual_by_diotadG.reshape((nphi*ntheta*3,))\n        d2residual_by_dGdG_flattened = d2residual_by_dGdG.reshape((nphi*ntheta*3,))\n        H = np.zeros((nphi*ntheta*3, nsurfdofs + 2, nsurfdofs + 2))\n        # noqa turns out linting so that we can align everything neatly\n        H[:, :nsurfdofs, :nsurfdofs] = d2residual_by_dcdc_flattened        # noqa (0, 0) dcdc\n        H[:, :nsurfdofs, nsurfdofs] = d2residual_by_dcdiota_flattened     # noqa (0, 1) dcdiota\n        H[:, :nsurfdofs, nsurfdofs+1] = d2residual_by_dcdG_flattened        # noqa (0, 2) dcdG\n        H[:, nsurfdofs, :nsurfdofs] = d2residual_by_dcdiota_flattened     # noqa (1, 0) diotadc\n        H[:, nsurfdofs, nsurfdofs] = d2residual_by_diotadiota_flattened  # noqa (1, 1) diotadiota\n        H[:, nsurfdofs, nsurfdofs+1] = d2residual_by_diotadiota_flattened  # noqa (1, 2) diotadG\n        H[:, nsurfdofs+1, :nsurfdofs] = d2residual_by_dcdG_flattened        # noqa (2, 0) dGdc\n        H[:, nsurfdofs+1, nsurfdofs] = d2residual_by_diotadG_flattened     # noqa (2, 1) dGdiota\n        H[:, nsurfdofs+1, nsurfdofs+1] = d2residual_by_dGdG_flattened        # noqa (2, 2) dGdG\n    else:\n        H = np.zeros((nphi*ntheta*3, nsurfdofs + 1, nsurfdofs + 1))\n\n        H[:, :nsurfdofs, :nsurfdofs] = d2residual_by_dcdc_flattened        # noqa (0, 0) dcdc\n        H[:, :nsurfdofs, nsurfdofs] = d2residual_by_dcdiota_flattened     # noqa (0, 1) dcdiota\n        H[:, nsurfdofs, :nsurfdofs] = d2residual_by_dcdiota_flattened     # noqa (1, 0) diotadc\n        H[:, nsurfdofs, nsurfdofs] = d2residual_by_diotadiota_flattened  # noqa (1, 1) diotadiota\n\n    return r, J, H",
  "def parameter_derivatives(surface: Surface,\n                          shape_gradient: NDArray[Any, Float]\n                          ) -> NDArray[Any, Float]:\n    r\"\"\"\n    Converts the shape gradient of a given figure of merit, :math:`f`,\n    to derivatives with respect to parameters defining a surface.  For\n    a perturbation to the surface :math:`\\delta \\vec{x}`, the\n    resulting perturbation to the objective function is\n\n    .. math::\n      \\delta f(\\delta \\vec{x}) = \\int d^2 x \\, G \\delta \\vec{x} \\cdot \\vec{n}\n\n    where :math:`G` is the shape gradient and :math:`\\vec{n}` is the\n    unit normal. Given :math:`G`, the parameter derivatives are then\n    computed as\n\n    .. math::\n      \\frac{\\partial f}{\\partial \\Omega} = \\int d^2 x \\, G \\frac{\\partial\\vec{x}}{\\partial \\Omega} \\cdot \\vec{n},\n\n    where :math:`\\Omega` is any parameter of the surface.\n\n    Args:\n        surface: The surface to use for the computation\n        shape_gradient: 2d array of size (numquadpoints_phi,numquadpoints_theta)\n\n    Returns:\n        1d array of size (ndofs)\n    \"\"\"\n    N = surface.normal()\n    norm_N = np.linalg.norm(N, axis=2)\n    dx_by_dc = surface.dgamma_by_dcoeff()\n    N_dot_dx_by_dc = np.einsum('ijk,ijkl->ijl', N, dx_by_dc)\n    nphi = surface.gamma().shape[0]\n    ntheta = surface.gamma().shape[1]\n    return np.einsum('ijk,ij->k', N_dot_dx_by_dc, shape_gradient) / (ntheta * nphi)",
  "class QfmResidual(Optimizable):\n    r\"\"\"\n    For a given surface :math:`S`, this class computes the residual\n\n    .. math::\n        f(S) = \\frac{\\int_{S} d^2 x \\, (\\textbf{B} \\cdot \\hat{\\textbf{n}})^2}{\\int_{S} d^2 x \\, B^2}\n\n    where :math:`\\textbf{B}` is the magnetic field from :mod:`biotsavart`,\n    :math:`\\hat{\\textbf{n}}` is the unit normal on a given surface, and the\n    integration is performed over the surface. Derivatives are computed wrt the\n    surface dofs.\n    \"\"\"\n\n    def __init__(self, surface, biotsavart):\n        self.surface = surface\n        self.biotsavart = biotsavart\n        self.biotsavart.append_parent(self.surface)\n        super().__init__(depends_on=[surface, biotsavart])\n\n    def recompute_bell(self, parent=None):\n        self.invalidate_cache()\n\n    def invalidate_cache(self):\n        x = self.surface.gamma()\n        xsemiflat = x.reshape((-1, 3))\n        self.biotsavart.set_points(xsemiflat)\n\n    def J(self):\n        N = self.surface.normal()\n        norm_N = np.linalg.norm(N, axis=2)\n        n = N/norm_N[:, :, None]\n        x = self.surface.gamma()\n        nphi = x.shape[0]\n        ntheta = x.shape[1]\n        B = self.biotsavart.B().reshape((nphi, ntheta, 3))\n        B_n = np.sum(B * n, axis=2)\n        norm_B = np.linalg.norm(B, axis=2)\n        return np.sum(B_n**2 * norm_N)/np.sum(norm_B**2 * norm_N)\n\n    def dJ_by_dsurfacecoefficients(self):\n        \"\"\"\n        Calculate the derivatives with respect to the surface coefficients\n        \"\"\"\n\n        # we write the objective as J = J1/J2, then we compute the partial derivatives\n        # dJ1_by_dgamma, dJ1_by_dN, dJ2_by_dgamma, dJ2_by_dN and then use the vjp functions\n        # to get the derivatives wrt to the surface dofs\n        x = self.surface.gamma()\n        nphi = x.shape[0]\n        ntheta = x.shape[1]\n        dB_by_dX = self.biotsavart.dB_by_dX().reshape((nphi, ntheta, 3, 3))\n        B = self.biotsavart.B().reshape((nphi, ntheta, 3))\n        N = self.surface.normal()\n        norm_N = np.linalg.norm(N, axis=2)\n\n        B_N = np.sum(B * N, axis=2)\n        dJ1dx = (2*B_N/norm_N)[:, :, None] * (np.sum(dB_by_dX*N[:, :, None, :], axis=3))\n        dJ1dN = (2*B_N/norm_N)[:, :, None] * B - (B_N**2/norm_N**3)[:, :, None] * N\n\n        dJ2dx = 2 * np.sum(dB_by_dX*B[:, :, None, :], axis=3) * norm_N[:, :, None]\n        dJ2dN = (np.sum(B*B, axis=2)/norm_N)[:, :, None] * N\n\n        J1 = np.sum(B_N**2 / norm_N)  # same as np.sum(B_n**2 * norm_N)\n        J2 = np.sum(B**2 * norm_N[:, :, None])\n\n        # d_J1 = self.surface.dnormal_by_dcoeff_vjp(dJ1dN) + self.surface.dgamma_by_dcoeff_vjp(dJ1dx)\n        # d_J2 = self.surface.dnormal_by_dcoeff_vjp(dJ2dN) + self.surface.dgamma_by_dcoeff_vjp(dJ2dx)\n        # deriv = d_J1/J2 - d_J2*J1/(J2*J2)\n\n        deriv = self.surface.dnormal_by_dcoeff_vjp(dJ1dN/J2 - dJ2dN*J1/(J2*J2)) \\\n            + self.surface.dgamma_by_dcoeff_vjp(dJ1dx/J2 - dJ2dx*J1/(J2*J2))\n        return deriv",
  "class MajorRadius(Optimizable): \n    r\"\"\"\n    This wrapper objective computes the major radius of a toroidal Boozer surface and supplies\n    its derivative with respect to coils\n\n    Args:\n        boozer_surface: The surface to use for the computation\n    \"\"\"\n\n    def __init__(self, boozer_surface):\n        super().__init__(depends_on=[boozer_surface])\n        self.boozer_surface = boozer_surface\n        self.surface = boozer_surface.surface\n        self.recompute_bell()\n\n    def J(self):\n        if self._J is None:\n            self.compute()\n        return self._J\n\n    @derivative_dec\n    def dJ(self):\n        if self._dJ is None:\n            self.compute()\n        return self._dJ\n\n    def recompute_bell(self, parent=None):\n        self._J = None\n        self._dJ = None\n\n    def compute(self):\n        if self.boozer_surface.need_to_run_code:\n            res = self.boozer_surface.res\n            res = self.boozer_surface.solve_residual_equation_exactly_newton(tol=1e-13, maxiter=20, iota=res['iota'], G=res['G'])\n\n        surface = self.surface\n        self._J = surface.major_radius()\n\n        booz_surf = self.boozer_surface\n        iota = booz_surf.res['iota']\n        G = booz_surf.res['G']\n        P, L, U = booz_surf.res['PLU']\n        dconstraint_dcoils_vjp = boozer_surface_dexactresidual_dcoils_dcurrents_vjp\n\n        # tack on dJ_diota = dJ_dG = 0 to the end of dJ_ds\n        dJ_ds = np.zeros(L.shape[0])\n        dj_ds = surface.dmajor_radius_by_dcoeff()\n        dJ_ds[:dj_ds.size] = dj_ds\n        adj = forward_backward(P, L, U, dJ_ds)\n\n        adj_times_dg_dcoil = dconstraint_dcoils_vjp(adj, booz_surf, iota, G)\n        self._dJ = -1 * adj_times_dg_dcoil",
  "class NonQuasiSymmetricRatio(Optimizable):\n    r\"\"\"\n    This objective decomposes the field magnitude :math:`B(\\varphi,\\theta)` into quasisymmetric and\n    non-quasisymmetric components.  For quasi-axisymmetry, we compute\n\n    .. math::\n        B_{\\text{QS}} &= \\frac{\\int_0^1 B \\|\\mathbf n\\| ~d\\varphi}{\\int_0^1 \\|\\mathbf n\\| ~d\\varphi} \\\\\n        B_{\\text{non-QS}} &= B - B_{\\text{QS}}\n\n    where :math:`B = \\| \\mathbf B(\\varphi,\\theta) \\|_2`.  \n    For quasi-poloidal symmetry, an analagous formula is used, but the integral is computed in the :math:`\\theta` direction.\n    The objective computed by this penalty is\n\n    .. math::\n        J &= \\frac{\\int_{\\Gamma_{s}} B_{\\text{non-QS}}^2~dS}{\\int_{\\Gamma_{s}} B_{\\text{QS}}^2~dS} \\\\\n\n    When :math:`J` is zero, then there is perfect QS on the given boozer surface. The ratio of the QS and non-QS components\n    of the field is returned to avoid dependence on the magnitude of the field strength.  Note that this penalty is computed\n    on an auxilliary surface with quadrature points that are different from those on the input Boozer surface.  This is to allow\n    for a spectrally accurate evaluation of the above integrals. Note that if boozer_surface.surface.stellsym == True, \n    computing this term on the half-period with shifted quadrature points is ~not~ equivalent to computing on the full-period \n    with unshifted points.  This is why we compute on an auxilliary surface with quadrature points on the full period.\n\n    Args:\n        boozer_surface: input boozer surface on which the penalty term is evaluated,\n        biotsavart: biotsavart object (not necessarily the same as the one used on the Boozer surface). \n        sDIM: integer that determines the resolution of the quadrature points placed on the auxilliary surface.  \n        quasi_poloidal: `False` for quasiaxisymmetry and `True` for quasipoloidal symmetry\n    \"\"\"\n\n    def __init__(self, boozer_surface, bs, sDIM=20, quasi_poloidal=False):\n        # only BoozerExact surfaces work for now\n        assert boozer_surface.res['type'] == 'exact'\n        # only SurfaceXYZTensorFourier for now\n        assert type(boozer_surface.surface) is SurfaceXYZTensorFourier \n\n        Optimizable.__init__(self, depends_on=[boozer_surface])\n        in_surface = boozer_surface.surface\n        self.boozer_surface = boozer_surface\n\n        surface = in_surface\n        phis = np.linspace(0, 1/in_surface.nfp, 2*sDIM, endpoint=False)\n        thetas = np.linspace(0, 1., 2*sDIM, endpoint=False)\n        surface = SurfaceXYZTensorFourier(mpol=in_surface.mpol, ntor=in_surface.ntor, stellsym=in_surface.stellsym, nfp=in_surface.nfp, quadpoints_phi=phis, quadpoints_theta=thetas, dofs=in_surface.dofs)\n\n        self.axis = 1 if quasi_poloidal else 0\n        self.in_surface = in_surface\n        self.surface = surface\n        self.biotsavart = bs\n        self.recompute_bell()\n\n    def recompute_bell(self, parent=None):\n        self._J = None\n        self._dJ = None\n\n    def J(self):\n        if self._J is None:\n            self.compute()\n        return self._J\n\n    @derivative_dec\n    def dJ(self):\n        if self._dJ is None:\n            self.compute()\n        return self._dJ\n\n    def compute(self):\n        if self.boozer_surface.need_to_run_code:\n            res = self.boozer_surface.res\n            res = self.boozer_surface.solve_residual_equation_exactly_newton(tol=1e-13, maxiter=20, iota=res['iota'], G=res['G'])\n\n        self.biotsavart.set_points(self.surface.gamma().reshape((-1, 3)))\n        axis = self.axis\n\n        # compute J\n        surface = self.surface\n        nphi = surface.quadpoints_phi.size\n        ntheta = surface.quadpoints_theta.size\n\n        B = self.biotsavart.B()\n        B = B.reshape((nphi, ntheta, 3))\n        modB = np.sqrt(B[:, :, 0]**2 + B[:, :, 1]**2 + B[:, :, 2]**2)\n\n        nor = surface.normal()\n        dS = np.sqrt(nor[:, :, 0]**2 + nor[:, :, 1]**2 + nor[:, :, 2]**2)\n\n        B_QS = np.mean(modB * dS, axis=axis) / np.mean(dS, axis=axis)\n\n        if axis == 0:\n            B_QS = B_QS[None, :]\n        else:\n            B_QS = B_QS[:, None]\n\n        B_nonQS = modB - B_QS\n        self._J = np.mean(dS * B_nonQS**2) / np.mean(dS * B_QS**2)\n\n        booz_surf = self.boozer_surface\n        iota = booz_surf.res['iota']\n        G = booz_surf.res['G']\n        P, L, U = booz_surf.res['PLU']\n        dconstraint_dcoils_vjp = boozer_surface_dexactresidual_dcoils_dcurrents_vjp\n\n        dJ_by_dB = self.dJ_by_dB().reshape((-1, 3))\n        dJ_by_dcoils = self.biotsavart.B_vjp(dJ_by_dB)\n\n        # tack on dJ_diota = dJ_dG = 0 to the end of dJ_ds\n        dJ_ds = np.concatenate((self.dJ_by_dsurfacecoefficients(), [0., 0.]))\n        adj = forward_backward(P, L, U, dJ_ds)\n\n        adj_times_dg_dcoil = dconstraint_dcoils_vjp(adj, booz_surf, iota, G)\n        self._dJ = dJ_by_dcoils-adj_times_dg_dcoil\n\n    def dJ_by_dB(self):\n        \"\"\"\n        Return the partial derivative of the objective with respect to the magnetic field\n        \"\"\"\n        surface = self.surface\n        nphi = surface.quadpoints_phi.size\n        ntheta = surface.quadpoints_theta.size\n        axis = self.axis\n\n        B = self.biotsavart.B()\n        B = B.reshape((nphi, ntheta, 3))\n\n        modB = np.sqrt(B[:, :, 0]**2 + B[:, :, 1]**2 + B[:, :, 2]**2)\n        nor = surface.normal()\n        dS = np.sqrt(nor[:, :, 0]**2 + nor[:, :, 1]**2 + nor[:, :, 2]**2)\n\n        denom = np.mean(dS, axis=axis)\n        B_QS = np.mean(modB * dS, axis=axis) / denom\n\n        if axis == 0:\n            B_QS = B_QS[None, :]\n        else:\n            B_QS = B_QS[:, None]\n\n        B_nonQS = modB - B_QS\n\n        dmodB_dB = B / modB[..., None]\n        dnum_by_dB = B_nonQS[..., None] * dmodB_dB * dS[:, :, None] / (nphi * ntheta)  # d J_nonQS / dB_ijk\n        ddenom_by_dB = B_QS[..., None] * dmodB_dB * dS[:, :, None] / (nphi * ntheta)  # dJ_QS/dB_ijk\n        num = 0.5*np.mean(dS * B_nonQS**2)\n        denom = 0.5*np.mean(dS * B_QS**2)\n        return (denom * dnum_by_dB - num * ddenom_by_dB) / denom**2 \n\n    def dJ_by_dsurfacecoefficients(self):\n        \"\"\"\n        Return the partial derivative of the objective with respect to the surface coefficients\n        \"\"\"\n        surface = self.surface\n        nphi = surface.quadpoints_phi.size\n        ntheta = surface.quadpoints_theta.size\n        axis = self.axis\n\n        B = self.biotsavart.B()\n        B = B.reshape((nphi, ntheta, 3))\n        modB = np.sqrt(B[:, :, 0]**2 + B[:, :, 1]**2 + B[:, :, 2]**2)\n\n        nor = surface.normal()\n        dnor_dc = surface.dnormal_by_dcoeff()\n        dS = np.sqrt(nor[:, :, 0]**2 + nor[:, :, 1]**2 + nor[:, :, 2]**2)\n        dS_dc = (nor[:, :, 0, None]*dnor_dc[:, :, 0, :] + nor[:, :, 1, None]*dnor_dc[:, :, 1, :] + nor[:, :, 2, None]*dnor_dc[:, :, 2, :])/dS[:, :, None]\n\n        B_QS = np.mean(modB * dS, axis=axis) / np.mean(dS, axis=axis)\n\n        if axis == 0:\n            B_QS = B_QS[None, :]\n        else:\n            B_QS = B_QS[:, None]\n\n        B_nonQS = modB - B_QS\n\n        dB_by_dX = self.biotsavart.dB_by_dX().reshape((nphi, ntheta, 3, 3))\n        dx_dc = surface.dgamma_by_dcoeff()\n        dB_dc = np.einsum('ijkl,ijkm->ijlm', dB_by_dX, dx_dc, optimize=True)\n\n        modB = np.sqrt(B[:, :, 0]**2 + B[:, :, 1]**2 + B[:, :, 2]**2)\n        dmodB_dc = (B[:, :, 0, None] * dB_dc[:, :, 0, :] + B[:, :, 1, None] * dB_dc[:, :, 1, :] + B[:, :, 2, None] * dB_dc[:, :, 2, :])/modB[:, :, None]\n\n        num = np.mean(modB * dS, axis=axis)\n        denom = np.mean(dS, axis=axis)\n        dnum_dc = np.mean(dmodB_dc * dS[..., None] + modB[..., None] * dS_dc, axis=axis) \n        ddenom_dc = np.mean(dS_dc, axis=axis)\n        B_QS_dc = (dnum_dc * denom[:, None] - ddenom_dc * num[:, None])/denom[:, None]**2\n\n        if axis == 0:\n            B_QS_dc = B_QS_dc[None, :, :]\n        else:\n            B_QS_dc = B_QS_dc[:, None, :]\n\n        B_nonQS_dc = dmodB_dc - B_QS_dc\n\n        num = 0.5*np.mean(dS * B_nonQS**2)\n        denom = 0.5*np.mean(dS * B_QS**2)\n        dnum_by_dc = np.mean(0.5*dS_dc * B_nonQS[..., None]**2 + dS[..., None] * B_nonQS[..., None] * B_nonQS_dc, axis=(0, 1)) \n        ddenom_by_dc = np.mean(0.5*dS_dc * B_QS[..., None]**2 + dS[..., None] * B_QS[..., None] * B_QS_dc, axis=(0, 1)) \n        dJ_by_dc = (denom * dnum_by_dc - num * ddenom_by_dc) / denom**2 \n        return dJ_by_dc",
  "class Iotas(Optimizable):\n    \"\"\"\n    This term returns the rotational transform on a boozer surface as well as its derivative\n    with respect to the coil degrees of freedom.\n    \"\"\"\n\n    def __init__(self, boozer_surface):\n        Optimizable.__init__(self, x0=np.asarray([]), depends_on=[boozer_surface])\n        self.boozer_surface = boozer_surface\n        self.biotsavart = boozer_surface.biotsavart \n        self.recompute_bell()\n\n    def J(self):\n        if self._J is None:\n            self.compute()\n        return self._J\n\n    @derivative_dec\n    def dJ(self):\n        if self._dJ is None:\n            self.compute()\n        return self._dJ\n\n    def recompute_bell(self, parent=None):\n        self._J = None\n        self._dJ_by_dcoefficients = None\n        self._dJ_by_dcoilcurrents = None\n\n    def compute(self):\n        if self.boozer_surface.need_to_run_code:\n            res = self.boozer_surface.res\n            res = self.boozer_surface.solve_residual_equation_exactly_newton(tol=1e-13, maxiter=20, iota=res['iota'], G=res['G'])\n\n        self._J = self.boozer_surface.res['iota']\n\n        booz_surf = self.boozer_surface\n        iota = booz_surf.res['iota']\n        G = booz_surf.res['G']\n        P, L, U = booz_surf.res['PLU']\n        dconstraint_dcoils_vjp = boozer_surface_dexactresidual_dcoils_dcurrents_vjp\n\n        # tack on dJ_diota = dJ_dG = 0 to the end of dJ_ds\n        dJ_ds = np.zeros(L.shape[0])\n        dJ_ds[-2] = 1.\n        adj = forward_backward(P, L, U, dJ_ds)\n\n        adj_times_dg_dcoil = dconstraint_dcoils_vjp(adj, booz_surf, iota, G)\n        self._dJ = -1.*adj_times_dg_dcoil",
  "def boozer_surface_dexactresidual_dcoils_dcurrents_vjp(lm, booz_surf, iota, G):\n    r\"\"\"\n    For a given surface with points :math:`x` on it, this function computes the\n    vector-Jacobian product of:\n\n    .. math::\n        \\lambda^T \\frac{d\\mathbf{r}}{d\\text{coils   }} &= [G\\lambda - 2\\lambda\\|\\mathbf B(\\mathbf x)\\| (\\mathbf{x}_\\varphi + \\iota \\mathbf{x}_\\theta) ]^T \\frac{d\\mathbf B}{d\\text{coils}} \\\\ \n        \\lambda^T \\frac{d\\mathbf{r}}{d\\text{currents}} &= [G\\lambda - 2\\lambda\\|\\mathbf B(\\mathbf x)\\| (\\mathbf{x}_\\varphi + \\iota \\mathbf{x}_\\theta) ]^T \\frac{d\\mathbf B}{d\\text{currents}}\n\n    where :math:`\\mathbf{r}` is the Boozer residual.\n    G is known for exact boozer surfaces, so if G=None is passed, then that\n    value is used instead.\n\n    Args:\n        lm: adjoint variable,\n        booz_surf: boozer surface,\n        iota: rotational transform on the boozer surface,\n        G: constant on boozer surface,\n    \"\"\"\n    surface = booz_surf.surface\n    biotsavart = booz_surf.biotsavart\n    user_provided_G = G is not None\n    if not user_provided_G:\n        G = 2. * np.pi * np.sum(np.abs(biotsavart.coil_currents)) * (4 * np.pi * 10**(-7) / (2 * np.pi))\n\n    res, dres_dB = boozer_surface_residual_dB(surface, iota, G, biotsavart)\n    dres_dB = dres_dB.reshape((-1, 3, 3))\n\n    lm_label = lm[-1]\n    lmask = np.zeros(booz_surf.res[\"mask\"].shape)\n    lmask[booz_surf.res[\"mask\"]] = lm[:-1]\n    lm_cons = lmask.reshape((-1, 3))\n\n    lm_times_dres_dB = np.sum(lm_cons[:, :, None] * dres_dB, axis=1).reshape((-1, 3))\n    lm_times_dres_dcoils = biotsavart.B_vjp(lm_times_dres_dB)\n    lm_times_dlabel_dcoils = lm_label*booz_surf.label.dJ(partials=True)(biotsavart, as_derivative=True)\n\n    return lm_times_dres_dcoils+lm_times_dlabel_dcoils",
  "def boozer_surface_residual_dB(surface, iota, G, biotsavart):\n    r\"\"\"\n    For a given surface with points x on it, this function computes the\n    differentiated residual\n\n    .. math::\n        \\frac{d}{dB_{i,j,k}}[ G B_{i,j,k} - \\|\\mathbf{B}_{i,j}\\|^2  (\\mathbf{x}_{\\varphi} + \\iota  \\mathbf{x}_{\\theta}) ]\n\n    where :math:`B_{i,j,k}` is the kth component of the magnetic field :math:`\\mathbf B_{i,j}` at quadrature point :math:`(i,j)` \n    as well as the derivatives of this residual with respect to surface dofs,\n    :math:`\\iota`, and :math:`G`. :math:`G` is known for exact boozer surfaces, so if \n    G=None is passed, then that value is used instead.\n    \"\"\"\n\n    user_provided_G = G is not None\n    if not user_provided_G:\n        G = 2. * np.pi * np.sum(np.abs(biotsavart.coil_currents)) * (4 * np.pi * 10**(-7) / (2 * np.pi))\n\n    x = surface.gamma()\n    xphi = surface.gammadash1()\n    xtheta = surface.gammadash2()\n    nphi = x.shape[0]\n    ntheta = x.shape[1]\n\n    xsemiflat = x.reshape((x.size//3, 3)).copy()\n\n    biotsavart.set_points(xsemiflat)\n\n    B = biotsavart.B().reshape((nphi, ntheta, 3))\n\n    tang = xphi + iota * xtheta\n    residual = G*B - np.sum(B**2, axis=2)[..., None] * tang\n\n    GI = np.eye(3, 3) * G\n    dresidual_dB = GI[None, None, :, :] - 2. * tang[:, :, :, None] * B[:, :, None, :]\n\n    residual_flattened = residual.reshape((nphi*ntheta*3, ))\n    dresidual_dB_flattened = dresidual_dB.reshape((nphi*ntheta*3, 3))\n    r = residual_flattened\n    dr_dB = dresidual_dB_flattened\n\n    return r, dr_dB",
  "def __init__(self, surface, range=None, nphi=None, ntheta=None):\n\n        if range is not None or nphi is not None or ntheta is not None:\n            if range is None:\n                if surface.stellsym:\n                    range = Surface.RANGE_HALF_PERIOD\n                else:\n                    range = Surface.RANGE_FIELD_PERIOD\n            if nphi is None:\n                nphi = len(surface.quadpoints_phi)\n            if ntheta is None:\n                ntheta = len(surface.quadpoints_theta)\n            self.surface = surface.__class__.from_nphi_ntheta(nphi=nphi, ntheta=ntheta, range=range, nfp=surface.nfp, stellsym=surface.stellsym, \\\n                                                              mpol=surface.mpol, ntor=surface.ntor, dofs=surface.dofs)\n        else:\n            self.surface = surface\n\n        self.range = range\n        self.nphi = nphi\n        self.ntheta = ntheta\n\n        super().__init__(depends_on=[self.surface])",
  "def J(self):\n        \"\"\"\n        Compute the area of a surface.\n        \"\"\"\n        return self.surface.area()",
  "def dJ(self):\n        return Derivative({self.surface: self.dJ_by_dsurfacecoefficients()})",
  "def dJ_by_dsurfacecoefficients(self):\n        \"\"\"\n        Calculate the partial derivatives with respect to the surface coefficients.\n        \"\"\"\n        return self.surface.darea_by_dcoeff()",
  "def d2J_by_dsurfacecoefficientsdsurfacecoefficients(self):\n        \"\"\"\n        Calculate the second partial derivatives with respect to the surface coefficients.\n        \"\"\"\n        return self.surface.d2area_by_dcoeffdcoeff()",
  "def __init__(self, surface, range=None, nphi=None, ntheta=None):\n\n        if range is not None or nphi is not None or ntheta is not None:\n            if range is None:\n                if surface.stellsym:\n                    range = Surface.RANGE_HALF_PERIOD\n                else:\n                    range = Surface.RANGE_FIELD_PERIOD\n            if nphi is None:\n                nphi = len(surface.quadpoints_phi)\n            if ntheta is None:\n                ntheta = len(surface.quadpoints_theta)\n            self.surface = surface.__class__.from_nphi_ntheta(nphi=nphi, ntheta=ntheta, range=range, nfp=surface.nfp, stellsym=surface.stellsym, \\\n                                                              mpol=surface.mpol, ntor=surface.ntor, dofs=surface.dofs)\n        else:\n            self.surface = surface\n\n        self.range = range\n        self.nphi = nphi\n        self.ntheta = ntheta\n\n        super().__init__(depends_on=[self.surface])",
  "def J(self):\n        \"\"\"\n        Compute the volume enclosed by the surface.\n        \"\"\"\n        return self.surface.volume()",
  "def dJ(self):\n        return Derivative({self.surface: self.dJ_by_dsurfacecoefficients()})",
  "def dJ_by_dsurfacecoefficients(self):\n        \"\"\"\n        Calculate the derivatives with respect to the surface coefficients.\n        \"\"\"\n        return self.surface.dvolume_by_dcoeff()",
  "def d2J_by_dsurfacecoefficientsdsurfacecoefficients(self):\n        \"\"\"\n        Calculate the second derivatives with respect to the surface coefficients.\n        \"\"\"\n        return self.surface.d2volume_by_dcoeffdcoeff()",
  "def __init__(self, surface, biotsavart, idx=0, range=None, nphi=None, ntheta=None):\n\n        if range is not None or nphi is not None or ntheta is not None:\n            if range is None:\n                if surface.stellsym:\n                    range = Surface.RANGE_HALF_PERIOD\n                else:\n                    range = Surface.RANGE_FIELD_PERIOD\n            if nphi is None:\n                nphi = len(surface.quadpoints_phi)\n            if ntheta is None:\n                ntheta = len(surface.quadpoints_theta)\n            self.surface = surface.__class__.from_nphi_ntheta(nphi=nphi, ntheta=ntheta, range=range, nfp=surface.nfp, stellsym=surface.stellsym, \\\n                                                              mpol=surface.mpol, ntor=surface.ntor, dofs=surface.dofs)\n        else:\n            self.surface = surface\n\n        self.biotsavart = biotsavart\n        self.idx = idx\n\n        self.range = range\n        self.nphi = nphi\n        self.ntheta = ntheta\n\n        super().__init__(depends_on=[self.surface, biotsavart])",
  "def recompute_bell(self, parent=None):\n        self.invalidate_cache()",
  "def invalidate_cache(self):\n        x = self.surface.gamma()[self.idx]\n        self.biotsavart.set_points(x)",
  "def J(self):\n        r\"\"\"\n        Compute the toroidal flux on the surface where\n        :math:`\\varphi = \\texttt{quadpoints_varphi}[\\texttt{idx}]`.\n        \"\"\"\n        xtheta = self.surface.gammadash2()[self.idx]\n        ntheta = self.surface.gamma().shape[1]\n        A = self.biotsavart.A()\n        tf = np.sum(A * xtheta)/ntheta\n        return tf",
  "def dJ(self):\n        d_s = Derivative({self.surface: self.dJ_by_dsurfacecoefficients()})\n        d_c = self.dJ_by_dcoils()\n        return d_s + d_c",
  "def dJ_by_dsurfacecoefficients(self):\n        \"\"\"\n        Calculate the partial derivatives with respect to the surface coefficients.\n        \"\"\"\n        ntheta = self.surface.gamma().shape[1]\n        dA_by_dX = self.biotsavart.dA_by_dX()\n        A = self.biotsavart.A()\n        dgammadash2 = self.surface.gammadash2()[self.idx, :]\n        dgammadash2_by_dc = self.surface.dgammadash2_by_dcoeff()[self.idx, :]\n\n        dx_dc = self.surface.dgamma_by_dcoeff()[self.idx]\n        dA_dc = np.sum(dA_by_dX[..., :, None] * dx_dc[..., None, :], axis=1)\n        term1 = np.sum(dA_dc * dgammadash2[..., None], axis=(0, 1))\n        term2 = np.sum(A[..., None] * dgammadash2_by_dc, axis=(0, 1))\n\n        out = (term1+term2)/ntheta\n        return out",
  "def d2J_by_dsurfacecoefficientsdsurfacecoefficients(self):\n        \"\"\"\n        Calculate the second partial derivatives with respect to the surface coefficients.\n        \"\"\"\n        ntheta = self.surface.gamma().shape[1]\n        dx_dc = self.surface.dgamma_by_dcoeff()[self.idx]\n        d2A_by_dXdX = self.biotsavart.d2A_by_dXdX().reshape((ntheta, 3, 3, 3))\n        dA_by_dX = self.biotsavart.dA_by_dX()\n        dA_dc = np.sum(dA_by_dX[..., :, None] * dx_dc[..., None, :], axis=1)\n        d2A_dcdc = np.einsum('jkpl,jpn,jkm->jlmn', d2A_by_dXdX, dx_dc, dx_dc)\n\n        dgammadash2 = self.surface.gammadash2()[self.idx]\n        dgammadash2_by_dc = self.surface.dgammadash2_by_dcoeff()[self.idx]\n\n        term1 = np.sum(d2A_dcdc * dgammadash2[..., None, None], axis=-3)\n        term2 = np.sum(dA_dc[..., :, None] * dgammadash2_by_dc[..., None, :], axis=-3)\n        term3 = np.sum(dA_dc[..., None, :] * dgammadash2_by_dc[..., :, None], axis=-3)\n\n        out = (1/ntheta) * np.sum(term1+term2+term3, axis=0)\n        return out",
  "def dJ_by_dcoils(self):\n        \"\"\"\n        Calculate the partial derivatives with respect to the coil coefficients.\n        \"\"\"\n        xtheta = self.surface.gammadash2()[self.idx]\n        ntheta = self.surface.gamma().shape[1]\n        dJ_by_dA = xtheta/ntheta\n        dJ_by_dcoils = self.biotsavart.A_vjp(dJ_by_dA)\n        return dJ_by_dcoils",
  "def __init__(self, surface, kappamax1=1, kappamax2=1, weight1=0.05, weight2=0.05):\n        super().__init__(depends_on=[surface])\n        self.surface = surface\n        self.kappamax1 = kappamax1\n        self.kappamax2 = kappamax2\n        self.weight1 = weight1\n        self.weight2 = weight2",
  "def J(self):\n        curvature = self.surface.surface_curvatures()\n        k1 = curvature[:, :, 2]  # larger\n        k2 = curvature[:, :, 3]  # smaller\n        normal = self.surface.normal()\n        norm_normal = np.sqrt(normal[:, :, 0]**2 + normal[:, :, 1]**2 + normal[:, :, 2]**2)\n        return np.sum(norm_normal * np.exp(-(k1 - self.kappamax1)/self.weight1)) + \\\n            np.sum(norm_normal * np.exp(-(-k2 - self.kappamax2)/self.weight2))",
  "def dJ(self):\n        curvature = self.surface.surface_curvatures()\n        k1 = curvature[:, :, 2]  # larger\n        k2 = curvature[:, :, 3]  # smaller\n        normal = self.surface.normal()\n        norm_normal = np.sqrt(normal[:, :, 0]**2 + normal[:, :, 1]**2 + normal[:, :, 2]**2)\n        dcurvature_dc = self.surface.dsurface_curvatures_by_dcoeff()\n        dk1_dc = dcurvature_dc[:, :, 2, :]\n        dk2_dc = dcurvature_dc[:, :, 3, :]\n        dnormal_dc = self.surface.dnormal_by_dcoeff()\n        dnorm_normal_dc = normal[:, :, 0, None]*dnormal_dc[:, :, 0, :]/norm_normal[:, :, None] + \\\n            normal[:, :, 1, None]*dnormal_dc[:, :, 1, :]/norm_normal[:, :, None] + \\\n            normal[:, :, 2, None]*dnormal_dc[:, :, 2, :]/norm_normal[:, :, None]\n        deriv = np.sum(dnorm_normal_dc * np.exp(-(k1[:, :, None] - self.kappamax1)/self.weight1), axis=(0, 1)) + \\\n            np.sum(norm_normal[:, :, None] * np.exp(-(k1[:, :, None] - self.kappamax1)/self.weight1) * (- dk1_dc/self.weight1), axis=(0, 1)) + \\\n            np.sum(dnorm_normal_dc * np.exp(-(-k2[:, :, None] - self.kappamax2)/self.weight2), axis=(0, 1)) + \\\n            np.sum(norm_normal[:, :, None] * np.exp(-(-k2[:, :, None] - self.kappamax2)/self.weight2) * (dk2_dc/self.weight2), axis=(0, 1))\n        return Derivative({self.surface: deriv})",
  "def __init__(self, surface, biotsavart):\n        self.surface = surface\n        self.biotsavart = biotsavart\n        self.biotsavart.append_parent(self.surface)\n        super().__init__(depends_on=[surface, biotsavart])",
  "def recompute_bell(self, parent=None):\n        self.invalidate_cache()",
  "def invalidate_cache(self):\n        x = self.surface.gamma()\n        xsemiflat = x.reshape((-1, 3))\n        self.biotsavart.set_points(xsemiflat)",
  "def J(self):\n        N = self.surface.normal()\n        norm_N = np.linalg.norm(N, axis=2)\n        n = N/norm_N[:, :, None]\n        x = self.surface.gamma()\n        nphi = x.shape[0]\n        ntheta = x.shape[1]\n        B = self.biotsavart.B().reshape((nphi, ntheta, 3))\n        B_n = np.sum(B * n, axis=2)\n        norm_B = np.linalg.norm(B, axis=2)\n        return np.sum(B_n**2 * norm_N)/np.sum(norm_B**2 * norm_N)",
  "def dJ_by_dsurfacecoefficients(self):\n        \"\"\"\n        Calculate the derivatives with respect to the surface coefficients\n        \"\"\"\n\n        # we write the objective as J = J1/J2, then we compute the partial derivatives\n        # dJ1_by_dgamma, dJ1_by_dN, dJ2_by_dgamma, dJ2_by_dN and then use the vjp functions\n        # to get the derivatives wrt to the surface dofs\n        x = self.surface.gamma()\n        nphi = x.shape[0]\n        ntheta = x.shape[1]\n        dB_by_dX = self.biotsavart.dB_by_dX().reshape((nphi, ntheta, 3, 3))\n        B = self.biotsavart.B().reshape((nphi, ntheta, 3))\n        N = self.surface.normal()\n        norm_N = np.linalg.norm(N, axis=2)\n\n        B_N = np.sum(B * N, axis=2)\n        dJ1dx = (2*B_N/norm_N)[:, :, None] * (np.sum(dB_by_dX*N[:, :, None, :], axis=3))\n        dJ1dN = (2*B_N/norm_N)[:, :, None] * B - (B_N**2/norm_N**3)[:, :, None] * N\n\n        dJ2dx = 2 * np.sum(dB_by_dX*B[:, :, None, :], axis=3) * norm_N[:, :, None]\n        dJ2dN = (np.sum(B*B, axis=2)/norm_N)[:, :, None] * N\n\n        J1 = np.sum(B_N**2 / norm_N)  # same as np.sum(B_n**2 * norm_N)\n        J2 = np.sum(B**2 * norm_N[:, :, None])\n\n        # d_J1 = self.surface.dnormal_by_dcoeff_vjp(dJ1dN) + self.surface.dgamma_by_dcoeff_vjp(dJ1dx)\n        # d_J2 = self.surface.dnormal_by_dcoeff_vjp(dJ2dN) + self.surface.dgamma_by_dcoeff_vjp(dJ2dx)\n        # deriv = d_J1/J2 - d_J2*J1/(J2*J2)\n\n        deriv = self.surface.dnormal_by_dcoeff_vjp(dJ1dN/J2 - dJ2dN*J1/(J2*J2)) \\\n            + self.surface.dgamma_by_dcoeff_vjp(dJ1dx/J2 - dJ2dx*J1/(J2*J2))\n        return deriv",
  "def __init__(self, boozer_surface):\n        super().__init__(depends_on=[boozer_surface])\n        self.boozer_surface = boozer_surface\n        self.surface = boozer_surface.surface\n        self.recompute_bell()",
  "def J(self):\n        if self._J is None:\n            self.compute()\n        return self._J",
  "def dJ(self):\n        if self._dJ is None:\n            self.compute()\n        return self._dJ",
  "def recompute_bell(self, parent=None):\n        self._J = None\n        self._dJ = None",
  "def compute(self):\n        if self.boozer_surface.need_to_run_code:\n            res = self.boozer_surface.res\n            res = self.boozer_surface.solve_residual_equation_exactly_newton(tol=1e-13, maxiter=20, iota=res['iota'], G=res['G'])\n\n        surface = self.surface\n        self._J = surface.major_radius()\n\n        booz_surf = self.boozer_surface\n        iota = booz_surf.res['iota']\n        G = booz_surf.res['G']\n        P, L, U = booz_surf.res['PLU']\n        dconstraint_dcoils_vjp = boozer_surface_dexactresidual_dcoils_dcurrents_vjp\n\n        # tack on dJ_diota = dJ_dG = 0 to the end of dJ_ds\n        dJ_ds = np.zeros(L.shape[0])\n        dj_ds = surface.dmajor_radius_by_dcoeff()\n        dJ_ds[:dj_ds.size] = dj_ds\n        adj = forward_backward(P, L, U, dJ_ds)\n\n        adj_times_dg_dcoil = dconstraint_dcoils_vjp(adj, booz_surf, iota, G)\n        self._dJ = -1 * adj_times_dg_dcoil",
  "def __init__(self, boozer_surface, bs, sDIM=20, quasi_poloidal=False):\n        # only BoozerExact surfaces work for now\n        assert boozer_surface.res['type'] == 'exact'\n        # only SurfaceXYZTensorFourier for now\n        assert type(boozer_surface.surface) is SurfaceXYZTensorFourier \n\n        Optimizable.__init__(self, depends_on=[boozer_surface])\n        in_surface = boozer_surface.surface\n        self.boozer_surface = boozer_surface\n\n        surface = in_surface\n        phis = np.linspace(0, 1/in_surface.nfp, 2*sDIM, endpoint=False)\n        thetas = np.linspace(0, 1., 2*sDIM, endpoint=False)\n        surface = SurfaceXYZTensorFourier(mpol=in_surface.mpol, ntor=in_surface.ntor, stellsym=in_surface.stellsym, nfp=in_surface.nfp, quadpoints_phi=phis, quadpoints_theta=thetas, dofs=in_surface.dofs)\n\n        self.axis = 1 if quasi_poloidal else 0\n        self.in_surface = in_surface\n        self.surface = surface\n        self.biotsavart = bs\n        self.recompute_bell()",
  "def recompute_bell(self, parent=None):\n        self._J = None\n        self._dJ = None",
  "def J(self):\n        if self._J is None:\n            self.compute()\n        return self._J",
  "def dJ(self):\n        if self._dJ is None:\n            self.compute()\n        return self._dJ",
  "def compute(self):\n        if self.boozer_surface.need_to_run_code:\n            res = self.boozer_surface.res\n            res = self.boozer_surface.solve_residual_equation_exactly_newton(tol=1e-13, maxiter=20, iota=res['iota'], G=res['G'])\n\n        self.biotsavart.set_points(self.surface.gamma().reshape((-1, 3)))\n        axis = self.axis\n\n        # compute J\n        surface = self.surface\n        nphi = surface.quadpoints_phi.size\n        ntheta = surface.quadpoints_theta.size\n\n        B = self.biotsavart.B()\n        B = B.reshape((nphi, ntheta, 3))\n        modB = np.sqrt(B[:, :, 0]**2 + B[:, :, 1]**2 + B[:, :, 2]**2)\n\n        nor = surface.normal()\n        dS = np.sqrt(nor[:, :, 0]**2 + nor[:, :, 1]**2 + nor[:, :, 2]**2)\n\n        B_QS = np.mean(modB * dS, axis=axis) / np.mean(dS, axis=axis)\n\n        if axis == 0:\n            B_QS = B_QS[None, :]\n        else:\n            B_QS = B_QS[:, None]\n\n        B_nonQS = modB - B_QS\n        self._J = np.mean(dS * B_nonQS**2) / np.mean(dS * B_QS**2)\n\n        booz_surf = self.boozer_surface\n        iota = booz_surf.res['iota']\n        G = booz_surf.res['G']\n        P, L, U = booz_surf.res['PLU']\n        dconstraint_dcoils_vjp = boozer_surface_dexactresidual_dcoils_dcurrents_vjp\n\n        dJ_by_dB = self.dJ_by_dB().reshape((-1, 3))\n        dJ_by_dcoils = self.biotsavart.B_vjp(dJ_by_dB)\n\n        # tack on dJ_diota = dJ_dG = 0 to the end of dJ_ds\n        dJ_ds = np.concatenate((self.dJ_by_dsurfacecoefficients(), [0., 0.]))\n        adj = forward_backward(P, L, U, dJ_ds)\n\n        adj_times_dg_dcoil = dconstraint_dcoils_vjp(adj, booz_surf, iota, G)\n        self._dJ = dJ_by_dcoils-adj_times_dg_dcoil",
  "def dJ_by_dB(self):\n        \"\"\"\n        Return the partial derivative of the objective with respect to the magnetic field\n        \"\"\"\n        surface = self.surface\n        nphi = surface.quadpoints_phi.size\n        ntheta = surface.quadpoints_theta.size\n        axis = self.axis\n\n        B = self.biotsavart.B()\n        B = B.reshape((nphi, ntheta, 3))\n\n        modB = np.sqrt(B[:, :, 0]**2 + B[:, :, 1]**2 + B[:, :, 2]**2)\n        nor = surface.normal()\n        dS = np.sqrt(nor[:, :, 0]**2 + nor[:, :, 1]**2 + nor[:, :, 2]**2)\n\n        denom = np.mean(dS, axis=axis)\n        B_QS = np.mean(modB * dS, axis=axis) / denom\n\n        if axis == 0:\n            B_QS = B_QS[None, :]\n        else:\n            B_QS = B_QS[:, None]\n\n        B_nonQS = modB - B_QS\n\n        dmodB_dB = B / modB[..., None]\n        dnum_by_dB = B_nonQS[..., None] * dmodB_dB * dS[:, :, None] / (nphi * ntheta)  # d J_nonQS / dB_ijk\n        ddenom_by_dB = B_QS[..., None] * dmodB_dB * dS[:, :, None] / (nphi * ntheta)  # dJ_QS/dB_ijk\n        num = 0.5*np.mean(dS * B_nonQS**2)\n        denom = 0.5*np.mean(dS * B_QS**2)\n        return (denom * dnum_by_dB - num * ddenom_by_dB) / denom**2",
  "def dJ_by_dsurfacecoefficients(self):\n        \"\"\"\n        Return the partial derivative of the objective with respect to the surface coefficients\n        \"\"\"\n        surface = self.surface\n        nphi = surface.quadpoints_phi.size\n        ntheta = surface.quadpoints_theta.size\n        axis = self.axis\n\n        B = self.biotsavart.B()\n        B = B.reshape((nphi, ntheta, 3))\n        modB = np.sqrt(B[:, :, 0]**2 + B[:, :, 1]**2 + B[:, :, 2]**2)\n\n        nor = surface.normal()\n        dnor_dc = surface.dnormal_by_dcoeff()\n        dS = np.sqrt(nor[:, :, 0]**2 + nor[:, :, 1]**2 + nor[:, :, 2]**2)\n        dS_dc = (nor[:, :, 0, None]*dnor_dc[:, :, 0, :] + nor[:, :, 1, None]*dnor_dc[:, :, 1, :] + nor[:, :, 2, None]*dnor_dc[:, :, 2, :])/dS[:, :, None]\n\n        B_QS = np.mean(modB * dS, axis=axis) / np.mean(dS, axis=axis)\n\n        if axis == 0:\n            B_QS = B_QS[None, :]\n        else:\n            B_QS = B_QS[:, None]\n\n        B_nonQS = modB - B_QS\n\n        dB_by_dX = self.biotsavart.dB_by_dX().reshape((nphi, ntheta, 3, 3))\n        dx_dc = surface.dgamma_by_dcoeff()\n        dB_dc = np.einsum('ijkl,ijkm->ijlm', dB_by_dX, dx_dc, optimize=True)\n\n        modB = np.sqrt(B[:, :, 0]**2 + B[:, :, 1]**2 + B[:, :, 2]**2)\n        dmodB_dc = (B[:, :, 0, None] * dB_dc[:, :, 0, :] + B[:, :, 1, None] * dB_dc[:, :, 1, :] + B[:, :, 2, None] * dB_dc[:, :, 2, :])/modB[:, :, None]\n\n        num = np.mean(modB * dS, axis=axis)\n        denom = np.mean(dS, axis=axis)\n        dnum_dc = np.mean(dmodB_dc * dS[..., None] + modB[..., None] * dS_dc, axis=axis) \n        ddenom_dc = np.mean(dS_dc, axis=axis)\n        B_QS_dc = (dnum_dc * denom[:, None] - ddenom_dc * num[:, None])/denom[:, None]**2\n\n        if axis == 0:\n            B_QS_dc = B_QS_dc[None, :, :]\n        else:\n            B_QS_dc = B_QS_dc[:, None, :]\n\n        B_nonQS_dc = dmodB_dc - B_QS_dc\n\n        num = 0.5*np.mean(dS * B_nonQS**2)\n        denom = 0.5*np.mean(dS * B_QS**2)\n        dnum_by_dc = np.mean(0.5*dS_dc * B_nonQS[..., None]**2 + dS[..., None] * B_nonQS[..., None] * B_nonQS_dc, axis=(0, 1)) \n        ddenom_by_dc = np.mean(0.5*dS_dc * B_QS[..., None]**2 + dS[..., None] * B_QS[..., None] * B_QS_dc, axis=(0, 1)) \n        dJ_by_dc = (denom * dnum_by_dc - num * ddenom_by_dc) / denom**2 \n        return dJ_by_dc",
  "def __init__(self, boozer_surface):\n        Optimizable.__init__(self, x0=np.asarray([]), depends_on=[boozer_surface])\n        self.boozer_surface = boozer_surface\n        self.biotsavart = boozer_surface.biotsavart \n        self.recompute_bell()",
  "def J(self):\n        if self._J is None:\n            self.compute()\n        return self._J",
  "def dJ(self):\n        if self._dJ is None:\n            self.compute()\n        return self._dJ",
  "def recompute_bell(self, parent=None):\n        self._J = None\n        self._dJ_by_dcoefficients = None\n        self._dJ_by_dcoilcurrents = None",
  "def compute(self):\n        if self.boozer_surface.need_to_run_code:\n            res = self.boozer_surface.res\n            res = self.boozer_surface.solve_residual_equation_exactly_newton(tol=1e-13, maxiter=20, iota=res['iota'], G=res['G'])\n\n        self._J = self.boozer_surface.res['iota']\n\n        booz_surf = self.boozer_surface\n        iota = booz_surf.res['iota']\n        G = booz_surf.res['G']\n        P, L, U = booz_surf.res['PLU']\n        dconstraint_dcoils_vjp = boozer_surface_dexactresidual_dcoils_dcurrents_vjp\n\n        # tack on dJ_diota = dJ_dG = 0 to the end of dJ_ds\n        dJ_ds = np.zeros(L.shape[0])\n        dJ_ds[-2] = 1.\n        adj = forward_backward(P, L, U, dJ_ds)\n\n        adj_times_dg_dcoil = dconstraint_dcoils_vjp(adj, booz_surf, iota, G)\n        self._dJ = -1.*adj_times_dg_dcoil",
  "def incremental_arclength_pure(d1gamma):\n    \"\"\"\n    This function is used in a Python+Jax implementation of the curve arc length formula.\n    \"\"\"\n\n    return jnp.linalg.norm(d1gamma, axis=1)",
  "def kappa_pure(d1gamma, d2gamma):\n    \"\"\"\n    This function is used in a Python+Jax implementation of formula for curvature.\n    \"\"\"\n\n    return jnp.linalg.norm(jnp.cross(d1gamma, d2gamma), axis=1)/jnp.linalg.norm(d1gamma, axis=1)**3",
  "def torsion_pure(d1gamma, d2gamma, d3gamma):\n    \"\"\"\n    This function is used in a Python+Jax implementation of formula for torsion.\n    \"\"\"\n\n    return jnp.sum(jnp.cross(d1gamma, d2gamma, axis=1) * d3gamma, axis=1) / jnp.sum(jnp.cross(d1gamma, d2gamma, axis=1)**2, axis=1)",
  "class Curve(Optimizable):\n    \"\"\"\n    Curve  is a base class for various representations of curves in SIMSOPT\n    using the graph based Optimizable framework with external handling of DOFS\n    as well.\n    \"\"\"\n\n    def __init__(self, **kwargs):\n        Optimizable.__init__(self, **kwargs)\n\n    def recompute_bell(self, parent=None):\n        \"\"\"\n        For derivative classes of Curve, all of which also subclass\n        from C++ Curve class, call invalidate_cache which is implemented\n        in C++ side.\n        \"\"\"\n        self.invalidate_cache()\n\n    def plot(self, engine=\"matplotlib\", ax=None, show=True, plot_derivative=False, close=False, axis_equal=True, **kwargs):\n        \"\"\"\n        Plot the curve in 3D using ``matplotlib.pyplot``, ``mayavi``, or ``plotly``.\n\n        Args:\n            engine: The graphics engine to use. Available settings are ``\"matplotlib\"``, ``\"mayavi\"``, and ``\"plotly\"``.\n            ax: The axis object on which to plot. This argument is useful when plotting multiple\n              objects on the same axes. If equal to the default ``None``, a new axis will be created.\n            show: Whether to call the ``show()`` function of the graphics engine. Should be set to\n              ``False`` if more objects will be plotted on the same axes.\n            plot_derivative: Whether to plot the tangent of the curve too. Not implemented for plotly.\n            close: Whether to connect the first and last point on the\n              curve. Can lead to surprising results when only quadrature points\n              on a part of the curve are considered, e.g. when exploting rotational symmetry.\n            axis_equal: For matplotlib, whether all three dimensions should be scaled equally.\n            kwargs: Any additional arguments to pass to the plotting function, like ``color='r'``.\n\n        Returns:\n            An axis which could be passed to a further call to the graphics engine\n            so multiple objects are shown together.\n        \"\"\"\n\n        def rep(data):\n            if close:\n                return np.concatenate((data, [data[0]]))\n            else:\n                return data\n\n        x = rep(self.gamma()[:, 0])\n        y = rep(self.gamma()[:, 1])\n        z = rep(self.gamma()[:, 2])\n        if plot_derivative:\n            xt = rep(self.gammadash()[:, 0])\n            yt = rep(self.gammadash()[:, 1])\n            zt = rep(self.gammadash()[:, 2])\n\n        if engine == \"matplotlib\":\n            # plot in matplotlib.pyplot\n            import matplotlib.pyplot as plt \n\n            if ax is None or ax.name != \"3d\":\n                fig = plt.figure()\n                ax = fig.add_subplot(projection='3d')\n            ax.plot(x, y, z, **kwargs)\n            if plot_derivative:\n                ax.quiver(x, y, z, 0.1 * xt, 0.1 * yt, 0.1 * zt, arrow_length_ratio=0.1, color=\"r\")\n            if axis_equal:\n                fix_matplotlib_3d(ax)\n            if show:\n                plt.show()\n\n        elif engine == \"mayavi\":\n            # plot 3D curve in mayavi.mlab\n            from mayavi import mlab\n\n            mlab.plot3d(x, y, z, **kwargs)\n            if plot_derivative:\n                mlab.quiver3d(x, y, z, 0.1*xt, 0.1*yt, 0.1*zt)\n            if show:\n                mlab.show()\n\n        elif engine == \"plotly\":\n            import plotly.graph_objects as go\n\n            if \"color\" in list(kwargs.keys()):\n                color = kwargs[\"color\"]\n                del kwargs[\"color\"]\n            else:\n                color = \"blue\"\n            kwargs.setdefault(\"line\", go.scatter3d.Line(color=color, width=4))\n            if ax is None:\n                ax = go.Figure()\n            ax.add_trace(\n                go.Scatter3d(\n                    x=x, y=y, z=z, mode=\"lines\", **kwargs\n                )\n            )\n            ax.update_layout(scene_aspectmode=\"data\")\n            if show:\n                ax.show()\n        else:\n            raise ValueError(\"Invalid engine option! Please use one of {matplotlib, mayavi, plotly}.\")\n        return ax\n\n    def dgamma_by_dcoeff_vjp(self, v):\n        return Derivative({self: self.dgamma_by_dcoeff_vjp_impl(v)})\n\n    def dgammadash_by_dcoeff_vjp(self, v):\n        return Derivative({self: self.dgammadash_by_dcoeff_vjp_impl(v)})\n\n    def dgammadashdash_by_dcoeff_vjp(self, v):\n        return Derivative({self: self.dgammadashdash_by_dcoeff_vjp_impl(v)})\n\n    def dgammadashdashdash_by_dcoeff_vjp(self, v):\n        return Derivative({self: self.dgammadashdashdash_by_dcoeff_vjp_impl(v)})\n\n    def dincremental_arclength_by_dcoeff_vjp(self, v):\n        r\"\"\"\n        This function returns the vector Jacobian product\n\n        .. math::\n            v^T \\frac{\\partial \\|\\Gamma'\\|}{\\partial \\mathbf{c}}\n\n        where :math:`\\|\\Gamma'\\|` is the incremental arclength, :math:`\\Gamma'` is the tangent \n        to the curve and :math:`\\mathbf{c}` are the curve dofs.\n        \"\"\"\n\n        return self.dgammadash_by_dcoeff_vjp(\n            incremental_arclength_vjp(self.gammadash(), v))\n\n    def kappa_impl(self, kappa):\n        r\"\"\"\n        This function implements the curvature, :math:`\\kappa(\\varphi)`.\n        \"\"\"\n        kappa[:] = np.asarray(kappa_pure(\n            self.gammadash(), self.gammadashdash()))\n\n    def dkappa_by_dcoeff_impl(self, dkappa_by_dcoeff):\n        r\"\"\"\n        This function computes the derivative of the curvature with respect to the curve coefficients.\n\n        .. math::\n            \\frac{\\partial \\kappa}{\\partial \\mathbf c}\n\n        where :math:`\\mathbf c` are the curve dofs, :math:`\\kappa` is the curvature.\n        \"\"\"\n\n        dgamma_by_dphi = self.gammadash()\n        dgamma_by_dphidphi = self.gammadashdash()\n        dgamma_by_dphidcoeff = self.dgammadash_by_dcoeff()\n        dgamma_by_dphidphidcoeff = self.dgammadashdash_by_dcoeff()\n        num_coeff = dgamma_by_dphidcoeff.shape[2]\n\n        norm = lambda a: np.linalg.norm(a, axis=1)\n        inner = lambda a, b: np.sum(a*b, axis=1)\n        numerator = np.cross(dgamma_by_dphi, dgamma_by_dphidphi)\n        denominator = self.incremental_arclength()\n        dkappa_by_dcoeff[:, :] = (1 / (denominator**3*norm(numerator)))[:, None] * np.sum(numerator[:, :, None] * (\n            np.cross(dgamma_by_dphidcoeff[:, :, :], dgamma_by_dphidphi[:, :, None], axis=1) +\n            np.cross(dgamma_by_dphi[:, :, None], dgamma_by_dphidphidcoeff[:, :, :], axis=1)), axis=1) \\\n            - (norm(numerator) * 3 / denominator**5)[:, None] * np.sum(dgamma_by_dphi[:, :, None] * dgamma_by_dphidcoeff[:, :, :], axis=1)\n\n    def torsion_impl(self, torsion):\n        r\"\"\"\n        This function returns the torsion, :math:`\\tau`, of a curve.\n        \"\"\"\n        torsion[:] = torsion_pure(self.gammadash(), self.gammadashdash(),\n                                  self.gammadashdashdash())\n\n    def dtorsion_by_dcoeff_impl(self, dtorsion_by_dcoeff):\n        r\"\"\"\n        This function returns the derivative of torsion with respect to the curve dofs.\n\n        .. math::\n            \\frac{\\partial \\tau}{\\partial \\mathbf c}\n\n        where :math:`\\mathbf c` are the curve dofs, and :math:`\\tau` is the torsion.\n        \"\"\"\n        d1gamma = self.gammadash()\n        d2gamma = self.gammadashdash()\n        d3gamma = self.gammadashdashdash()\n        d1gammadcoeff = self.dgammadash_by_dcoeff()\n        d2gammadcoeff = self.dgammadashdash_by_dcoeff()\n        d3gammadcoeff = self.dgammadashdashdash_by_dcoeff()\n        dtorsion_by_dcoeff[:, :] = (\n            np.sum(np.cross(d1gamma, d2gamma, axis=1)[:, :, None] * d3gammadcoeff, axis=1)\n            + np.sum((np.cross(d1gammadcoeff, d2gamma[:, :, None], axis=1) + np.cross(d1gamma[:, :, None], d2gammadcoeff, axis=1)) * d3gamma[:, :, None], axis=1)\n        )/np.sum(np.cross(d1gamma, d2gamma, axis=1)**2, axis=1)[:, None]\n        dtorsion_by_dcoeff[:, :] -= np.sum(np.cross(d1gamma, d2gamma, axis=1) * d3gamma, axis=1)[:, None] * np.sum(2 * np.cross(d1gamma, d2gamma, axis=1)[:, :, None] * (np.cross(d1gammadcoeff, d2gamma[:, :, None], axis=1) + np.cross(d1gamma[:, :, None], d2gammadcoeff, axis=1)), axis=1)/np.sum(np.cross(d1gamma, d2gamma, axis=1)**2, axis=1)[:, None]**2\n\n    def dkappa_by_dcoeff_vjp(self, v):\n        r\"\"\"\n        This function returns the vector Jacobian product\n\n        .. math::\n            v^T \\frac{\\partial \\kappa}{\\partial \\mathbf{c}} \n\n        where :math:`\\mathbf c` are the curve dofs and :math:`\\kappa` is the curvature.\n        \"\"\"\n\n        return self.dgammadash_by_dcoeff_vjp(kappavjp0(self.gammadash(), self.gammadashdash(), v)) \\\n            + self.dgammadashdash_by_dcoeff_vjp(kappavjp1(self.gammadash(), self.gammadashdash(), v))\n\n    def dtorsion_by_dcoeff_vjp(self, v):\n        r\"\"\"\n        This function returns the vector Jacobian product\n\n        .. math::\n            v^T  \\frac{\\partial \\tau}{\\partial \\mathbf{c}} \n\n        where :math:`\\mathbf c` are the curve dofs, and :math:`\\tau` is the torsion.\n        \"\"\"\n\n        return self.dgammadash_by_dcoeff_vjp(torsionvjp0(self.gammadash(), self.gammadashdash(), self.gammadashdashdash(), v)) \\\n            + self.dgammadashdash_by_dcoeff_vjp(torsionvjp1(self.gammadash(), self.gammadashdash(), self.gammadashdashdash(), v)) \\\n            + self.dgammadashdashdash_by_dcoeff_vjp(torsionvjp2(self.gammadash(), self.gammadashdash(), self.gammadashdashdash(), v))\n\n    def frenet_frame(self):\n        r\"\"\"\n        This function returns the Frenet frame, :math:`(\\mathbf{t}, \\mathbf{n}, \\mathbf{b})`,\n        associated to the curve.\n        \"\"\"\n\n        gammadash = self.gammadash()\n        gammadashdash = self.gammadashdash()\n        l = self.incremental_arclength()\n        norm = lambda a: np.linalg.norm(a, axis=1)\n        inner = lambda a, b: np.sum(a*b, axis=1)\n        N = len(self.quadpoints)\n        t, n, b = (np.zeros((N, 3)), np.zeros((N, 3)), np.zeros((N, 3)))\n        t[:, :] = (1./l[:, None]) * gammadash\n\n        tdash = (1./l[:, None])**2 * (l[:, None] * gammadashdash\n                                      - (inner(gammadash, gammadashdash)/l)[:, None] * gammadash\n                                      )\n        kappa = self.kappa\n        n[:, :] = (1./norm(tdash))[:, None] * tdash\n        b[:, :] = np.cross(t, n, axis=1)\n        return t, n, b\n\n    def kappadash(self):\n        r\"\"\"\n        This function returns :math:`\\kappa'(\\phi)`, where :math:`\\kappa` is the curvature.\n        \"\"\"\n        dkappa_by_dphi = np.zeros((len(self.quadpoints), ))\n        dgamma = self.gammadash()\n        d2gamma = self.gammadashdash()\n        d3gamma = self.gammadashdashdash()\n        norm = lambda a: np.linalg.norm(a, axis=1)\n        inner = lambda a, b: np.sum(a*b, axis=1)\n        cross = lambda a, b: np.cross(a, b, axis=1)\n        dkappa_by_dphi[:] = inner(cross(dgamma, d2gamma), cross(dgamma, d3gamma))/(norm(cross(dgamma, d2gamma)) * norm(dgamma)**3) \\\n            - 3 * inner(dgamma, d2gamma) * norm(cross(dgamma, d2gamma))/norm(dgamma)**5\n        return dkappa_by_dphi\n\n    def dfrenet_frame_by_dcoeff(self):\n        r\"\"\"\n        This function returns the derivative of the curve's Frenet frame, \n\n        .. math::\n            \\left(\\frac{\\partial \\mathbf{t}}{\\partial \\mathbf{c}}, \\frac{\\partial \\mathbf{n}}{\\partial \\mathbf{c}}, \\frac{\\partial \\mathbf{b}}{\\partial \\mathbf{c}}\\right),\n\n        with respect to the curve dofs, where :math:`(\\mathbf t, \\mathbf n, \\mathbf b)` correspond to the Frenet frame, and :math:`\\mathbf c` are the curve dofs.\n        \"\"\"\n        dgamma_by_dphi = self.gammadash()\n        d2gamma_by_dphidphi = self.gammadashdash()\n        d2gamma_by_dphidcoeff = self.dgammadash_by_dcoeff()\n        d3gamma_by_dphidphidcoeff = self.dgammadashdash_by_dcoeff()\n\n        l = self.incremental_arclength()\n        dl_by_dcoeff = self.dincremental_arclength_by_dcoeff()\n\n        norm = lambda a: np.linalg.norm(a, axis=1)\n        inner = lambda a, b: np.sum(a*b, axis=1)\n        inner2 = lambda a, b: np.sum(a*b, axis=2)\n\n        N = len(self.quadpoints)\n        dt_by_dcoeff, dn_by_dcoeff, db_by_dcoeff = (np.zeros((N, 3, self.num_dofs())), np.zeros((N, 3, self.num_dofs())), np.zeros((N, 3, self.num_dofs())))\n        t, n, b = self.frenet_frame()\n\n        dt_by_dcoeff[:, :, :] = -(dl_by_dcoeff[:, None, :]/l[:, None, None]**2) * dgamma_by_dphi[:, :, None] \\\n            + d2gamma_by_dphidcoeff / l[:, None, None]\n\n        tdash = (1./l[:, None])**2 * (\n            l[:, None] * d2gamma_by_dphidphi\n            - (inner(dgamma_by_dphi, d2gamma_by_dphidphi)/l)[:, None] * dgamma_by_dphi\n        )\n\n        dtdash_by_dcoeff = (-2 * dl_by_dcoeff[:, None, :] / l[:, None, None]**3) * (l[:, None] * d2gamma_by_dphidphi - (inner(dgamma_by_dphi, d2gamma_by_dphidphi)/l)[:, None] * dgamma_by_dphi)[:, :, None] \\\n            + (1./l[:, None, None])**2 * (\n                dl_by_dcoeff[:, None, :] * d2gamma_by_dphidphi[:, :, None] + l[:, None, None] * d3gamma_by_dphidphidcoeff\n                - (inner(d2gamma_by_dphidcoeff, d2gamma_by_dphidphi[:, :, None])[:, None, :]/l[:, None, None]) * dgamma_by_dphi[:, :, None]\n                - (inner(dgamma_by_dphi[:, :, None], d3gamma_by_dphidphidcoeff)[:, None, :]/l[:, None, None]) * dgamma_by_dphi[:, :, None]\n                + (inner(dgamma_by_dphi, d2gamma_by_dphidphi)[:, None, None] * dl_by_dcoeff[:, None, :]/l[:, None, None]**2) * dgamma_by_dphi[:, :, None]\n                - (inner(dgamma_by_dphi, d2gamma_by_dphidphi)/l)[:, None, None] * d2gamma_by_dphidcoeff\n        )\n        dn_by_dcoeff[:, :, :] = (1./norm(tdash))[:, None, None] * dtdash_by_dcoeff \\\n            - (inner(tdash[:, :, None], dtdash_by_dcoeff)[:, None, :]/inner(tdash, tdash)[:, None, None]**1.5) * tdash[:, :, None]\n\n        db_by_dcoeff[:, :, :] = np.cross(dt_by_dcoeff, n[:, :, None], axis=1) + np.cross(t[:, :, None], dn_by_dcoeff, axis=1)\n        return dt_by_dcoeff, dn_by_dcoeff, db_by_dcoeff\n\n    def dkappadash_by_dcoeff(self):\n        r\"\"\"\n        This function returns \n\n        .. math::\n            \\frac{\\partial \\kappa'(\\phi)}{\\partial \\mathbf{c}}.\n\n        where :math:`\\mathbf{c}` are the curve dofs, and :math:`\\kappa` is the curvature.\n        \"\"\"\n\n        dkappadash_by_dcoeff = np.zeros((len(self.quadpoints), self.num_dofs()))\n        dgamma = self.gammadash()\n        d2gamma = self.gammadashdash()\n        d3gamma = self.gammadashdashdash()\n\n        norm = lambda a: np.linalg.norm(a, axis=1)\n        inner = lambda a, b: np.sum(a*b, axis=1)\n        cross = lambda a, b: np.cross(a, b, axis=1)\n        d1_dot_d2 = inner(dgamma, d2gamma)\n        d1_x_d2 = cross(dgamma, d2gamma)\n        d1_x_d3 = cross(dgamma, d3gamma)\n        normdgamma = norm(dgamma)\n        norm_d1_x_d2 = norm(d1_x_d2)\n        dgamma_dcoeff_ = self.dgammadash_by_dcoeff()\n        d2gamma_dcoeff_ = self.dgammadashdash_by_dcoeff()\n        d3gamma_dcoeff_ = self.dgammadashdashdash_by_dcoeff()\n        for i in range(self.num_dofs()):\n            dgamma_dcoeff = dgamma_dcoeff_[:, :, i]\n            d2gamma_dcoeff = d2gamma_dcoeff_[:, :, i]\n            d3gamma_dcoeff = d3gamma_dcoeff_[:, :, i]\n\n            d1coeff_x_d2 = cross(dgamma_dcoeff, d2gamma)\n            d1coeff_dot_d2 = inner(dgamma_dcoeff, d2gamma)\n            d1coeff_x_d3 = cross(dgamma_dcoeff, d3gamma)\n            d1_x_d2coeff = cross(dgamma, d2gamma_dcoeff)\n            d1_dot_d2coeff = inner(dgamma, d2gamma_dcoeff)\n            d1_dot_d1coeff = inner(dgamma, dgamma_dcoeff)\n            d1_x_d3coeff = cross(dgamma, d3gamma_dcoeff)\n\n            dkappadash_by_dcoeff[:, i] = (\n                +inner(d1coeff_x_d2 + d1_x_d2coeff, d1_x_d3)\n                + inner(d1_x_d2, d1coeff_x_d3 + d1_x_d3coeff)\n            )/(norm_d1_x_d2 * normdgamma**3) \\\n                - inner(d1_x_d2, d1_x_d3) * (\n                    (\n                        inner(d1coeff_x_d2 + d1_x_d2coeff, d1_x_d2)/(norm_d1_x_d2**3 * normdgamma**3)\n                        + 3 * inner(dgamma, dgamma_dcoeff)/(norm_d1_x_d2 * normdgamma**5)\n                    )\n            ) \\\n                - 3 * (\n                    + (d1coeff_dot_d2 + d1_dot_d2coeff) * norm_d1_x_d2/normdgamma**5\n                    + d1_dot_d2 * inner(d1coeff_x_d2 + d1_x_d2coeff, d1_x_d2)/(norm_d1_x_d2 * normdgamma**5)\n                    - 5 * d1_dot_d2 * norm_d1_x_d2 * d1_dot_d1coeff/normdgamma**7\n            )\n        return dkappadash_by_dcoeff",
  "class JaxCurve(sopp.Curve, Curve):\n    def __init__(self, quadpoints, gamma_pure, **kwargs):\n        if isinstance(quadpoints, np.ndarray):\n            quadpoints = list(quadpoints)\n        sopp.Curve.__init__(self, quadpoints)\n        if \"external_dof_setter\" not in kwargs:\n            kwargs[\"external_dof_setter\"] = sopp.Curve.set_dofs_impl\n        # We are not doing the same search for x0\n        Curve.__init__(self, **kwargs)\n        self.gamma_pure = gamma_pure\n        points = np.asarray(self.quadpoints)\n        ones = jnp.ones_like(points)\n\n        self.gamma_jax = jit(lambda dofs: self.gamma_pure(dofs, points))\n        self.gamma_impl_jax = jit(lambda dofs, p: self.gamma_pure(dofs, p))\n        self.dgamma_by_dcoeff_jax = jit(jacfwd(self.gamma_jax))\n        self.dgamma_by_dcoeff_vjp_jax = jit(lambda x, v: vjp(self.gamma_jax, x)[1](v)[0])\n\n        self.gammadash_pure = lambda x, q: jvp(lambda p: self.gamma_pure(x, p), (q,), (ones,))[1]\n        self.gammadash_jax = jit(lambda x: self.gammadash_pure(x, points))\n        self.dgammadash_by_dcoeff_jax = jit(jacfwd(self.gammadash_jax))\n        self.dgammadash_by_dcoeff_vjp_jax = jit(lambda x, v: vjp(self.gammadash_jax, x)[1](v)[0])\n\n        self.gammadashdash_pure = lambda x, q: jvp(lambda p: self.gammadash_pure(x, p), (q,), (ones,))[1]\n        self.gammadashdash_jax = jit(lambda x: self.gammadashdash_pure(x, points))\n        self.dgammadashdash_by_dcoeff_jax = jit(jacfwd(self.gammadashdash_jax))\n        self.dgammadashdash_by_dcoeff_vjp_jax = jit(lambda x, v: vjp(self.gammadashdash_jax, x)[1](v)[0])\n\n        self.gammadashdashdash_pure = lambda x, q: jvp(lambda p: self.gammadashdash_pure(x, p), (q,), (ones,))[1]\n        self.gammadashdashdash_jax = jit(lambda x: self.gammadashdashdash_pure(x, points))\n        self.dgammadashdashdash_by_dcoeff_jax = jit(jacfwd(self.gammadashdashdash_jax))\n        self.dgammadashdashdash_by_dcoeff_vjp_jax = jit(lambda x, v: vjp(self.gammadashdashdash_jax, x)[1](v)[0])\n\n        self.dkappa_by_dcoeff_vjp_jax = jit(lambda x, v: vjp(lambda d: kappa_pure(self.gammadash_jax(d), self.gammadashdash_jax(d)), x)[1](v)[0])\n\n        self.dtorsion_by_dcoeff_vjp_jax = jit(lambda x, v: vjp(lambda d: torsion_pure(self.gammadash_jax(d), self.gammadashdash_jax(d), self.gammadashdashdash_jax(d)), x)[1](v)[0])\n\n    def set_dofs(self, dofs):\n        self.local_x = dofs\n        sopp.Curve.set_dofs(self, dofs)\n\n    def gamma_impl(self, gamma, quadpoints):\n        r\"\"\"\n        This function returns the x,y,z coordinates of the curve :math:`\\Gamma`.\n        \"\"\"\n\n        gamma[:, :] = self.gamma_impl_jax(self.get_dofs(), quadpoints)\n\n    def dgamma_by_dcoeff_impl(self, dgamma_by_dcoeff):\n        r\"\"\"\n        This function returns \n\n        .. math::\n            \\frac{\\partial \\Gamma}{\\partial \\mathbf c}\n\n        where :math:`\\mathbf{c}` are the curve dofs, and :math:`\\Gamma` are the x, y, z coordinates\n        of the curve.\n        \"\"\"\n        dgamma_by_dcoeff[:, :, :] = self.dgamma_by_dcoeff_jax(self.get_dofs())\n\n    def dgamma_by_dcoeff_vjp_impl(self, v):\n        r\"\"\"\n        This function returns the vector Jacobian product\n\n        .. math::\n            v^T  \\frac{\\partial \\Gamma}{\\partial \\mathbf c} \n\n        where :math:`\\mathbf{c}` are the curve dofs, and :math:`\\Gamma` are the x, y, z coordinates\n        of the curve.\n        \"\"\"\n\n        return self.dgamma_by_dcoeff_vjp_jax(self.get_dofs(), v)\n\n    def gammadash_impl(self, gammadash):\n        r\"\"\"\n        This function returns :math:`\\Gamma'(\\varphi)`, where :math:`\\Gamma` are the x, y, z coordinates\n        of the curve.\n        \"\"\"\n\n        gammadash[:, :] = self.gammadash_jax(self.get_dofs())\n\n    def dgammadash_by_dcoeff_impl(self, dgammadash_by_dcoeff):\n        r\"\"\"\n        This function returns \n\n        .. math::\n            \\frac{\\partial \\Gamma'}{\\partial \\mathbf c}\n\n        where :math:`\\mathbf{c}` are the curve dofs, and :math:`\\Gamma` are the x, y, z coordinates\n        of the curve.\n        \"\"\"\n\n        dgammadash_by_dcoeff[:, :, :] = self.dgammadash_by_dcoeff_jax(self.get_dofs())\n\n    def dgammadash_by_dcoeff_vjp_impl(self, v):\n        r\"\"\"\n        This function returns \n\n        .. math::\n            \\mathbf v^T \\frac{\\partial \\Gamma'}{\\partial \\mathbf c}\n\n        where :math:`\\mathbf{c}` are the curve dofs, and :math:`\\Gamma` are the x, y, z coordinates\n        of the curve.\n        \"\"\"\n\n        return self.dgammadash_by_dcoeff_vjp_jax(self.get_dofs(), v)\n\n    def gammadashdash_impl(self, gammadashdash):\n        r\"\"\"\n        This function returns :math:`\\Gamma''(\\varphi)`, and :math:`\\Gamma` are the x, y, z coordinates\n        of the curve.\n        \"\"\"\n\n        gammadashdash[:, :] = self.gammadashdash_jax(self.get_dofs())\n\n    def dgammadashdash_by_dcoeff_impl(self, dgammadashdash_by_dcoeff):\n        r\"\"\"\n        This function returns \n\n        .. math::\n            \\frac{\\partial \\Gamma''}{\\partial \\mathbf c}\n\n        where :math:`\\mathbf{c}` are the curve dofs, and :math:`\\Gamma` are the x, y, z coordinates\n        of the curve.\n        \"\"\"\n\n        dgammadashdash_by_dcoeff[:, :, :] = self.dgammadashdash_by_dcoeff_jax(self.get_dofs())\n\n    def dgammadashdash_by_dcoeff_vjp_impl(self, v):\n        r\"\"\"\n        This function returns the vector Jacobian product\n\n        .. math::\n            v^T  \\frac{\\partial \\Gamma''}{\\partial \\mathbf c} \n\n        where :math:`\\mathbf{c}` are the curve dofs, and :math:`\\Gamma` are the x, y, z coordinates\n        of the curve.\n\n        \"\"\"\n\n        return self.dgammadashdash_by_dcoeff_vjp_jax(self.get_dofs(), v)\n\n    def gammadashdashdash_impl(self, gammadashdashdash):\n        r\"\"\"\n        This function returns :math:`\\Gamma'''(\\varphi)`, and :math:`\\Gamma` are the x, y, z coordinates\n        of the curve.\n        \"\"\"\n\n        gammadashdashdash[:, :] = self.gammadashdashdash_jax(self.get_dofs())\n\n    def dgammadashdashdash_by_dcoeff_impl(self, dgammadashdashdash_by_dcoeff):\n        r\"\"\"\n        This function returns \n\n        .. math::\n            \\frac{\\partial \\Gamma'''}{\\partial \\mathbf c}\n\n        where :math:`\\mathbf{c}` are the curve dofs, and :math:`\\Gamma` are the x, y, z coordinates\n        of the curve.\n        \"\"\"\n\n        dgammadashdashdash_by_dcoeff[:, :, :] = self.dgammadashdashdash_by_dcoeff_jax(self.get_dofs())\n\n    def dgammadashdashdash_by_dcoeff_vjp_impl(self, v):\n        r\"\"\"\n        This function returns the vector Jacobian product\n\n        .. math::\n            v^T  \\frac{\\partial \\Gamma'''}{\\partial \\mathbf c} \n\n        where :math:`\\mathbf{c}` are the curve dofs, and :math:`\\Gamma` are the x, y, z coordinates\n        of the curve.\n\n        \"\"\"\n\n        return self.dgammadashdashdash_by_dcoeff_vjp_jax(self.get_dofs(), v)\n\n    def dkappa_by_dcoeff_vjp(self, v):\n        r\"\"\"\n        This function returns the vector Jacobian product\n\n        .. math::\n            v^T \\frac{\\partial \\kappa}{\\partial \\mathbf{c}}\n\n        where :math:`\\mathbf{c}` are the curve dofs and :math:`\\kappa` is the curvature.\n\n        \"\"\"\n        return Derivative({self: self.dkappa_by_dcoeff_vjp_jax(self.get_dofs(), v)})\n\n    def dtorsion_by_dcoeff_vjp(self, v):\n        r\"\"\"\n        This function returns the vector Jacobian product\n\n        .. math::\n            v^T \\frac{\\partial \\tau}{\\partial \\mathbf{c}} \n\n        where :math:`\\mathbf{c}` are the curve dofs, and :math:`\\tau` is the torsion.\n\n        \"\"\"\n\n        return Derivative({self: self.dtorsion_by_dcoeff_vjp_jax(self.get_dofs(), v)})",
  "class RotatedCurve(sopp.Curve, Curve):\n    \"\"\"\n    RotatedCurve inherits from the Curve base class.  It takes an\n    input a Curve, rotates it about the ``z`` axis by a toroidal angle\n    ``phi``, and optionally completes a reflection when ``flip=True``.\n    \"\"\"\n\n    def __init__(self, curve, phi, flip):\n        self.curve = curve\n        sopp.Curve.__init__(self, curve.quadpoints)\n        Curve.__init__(self, depends_on=[curve])\n        self._phi = phi\n        self.rotmat = np.asarray(\n            [[cos(phi), -sin(phi), 0],\n             [sin(phi), cos(phi), 0],\n             [0, 0, 1]]).T\n        if flip:\n            self.rotmat = self.rotmat @ np.asarray(\n                [[1, 0, 0],\n                 [0, -1, 0],\n                 [0, 0, -1]])\n        self.rotmatT = self.rotmat.T.copy()\n\n    def get_dofs(self):\n        \"\"\"\n        RotatedCurve does not have any dofs of its own.\n        This function returns null array\n        \"\"\"\n        return np.array([])\n\n    def set_dofs_impl(self, d):\n        \"\"\"\n        RotatedCurve does not have any dofs of its own.\n        This function does nothing.\n        \"\"\"\n        pass\n\n    def num_dofs(self):\n        \"\"\"\n        This function returns the number of dofs associated to the curve.\n        \"\"\"\n        return self.curve.num_dofs()\n\n    def gamma_impl(self, gamma, quadpoints):\n        r\"\"\"\n        This function returns the x,y,z coordinates of the curve, :math:`\\Gamma`, where :math:`\\Gamma` are the x, y, z\n        coordinates of the curve.\n\n        \"\"\"\n\n        if len(quadpoints) == len(self.curve.quadpoints) \\\n                and np.sum((quadpoints-self.curve.quadpoints)**2) < 1e-15:\n            gamma[:] = self.curve.gamma() @ self.rotmat\n        else:\n            self.curve.gamma_impl(gamma, quadpoints)\n            gamma[:] = gamma @ self.rotmat\n\n    def gammadash_impl(self, gammadash):\n        r\"\"\"\n        This function returns :math:`\\Gamma'(\\varphi)`, where :math:`\\Gamma` are the x, y, z\n        coordinates of the curve.\n\n        \"\"\"\n\n        gammadash[:] = self.curve.gammadash() @ self.rotmat\n\n    def gammadashdash_impl(self, gammadashdash):\n        r\"\"\"\n        This function returns :math:`\\Gamma''(\\varphi)`, where :math:`\\Gamma` are the x, y, z\n        coordinates of the curve.\n\n        \"\"\"\n\n        gammadashdash[:] = self.curve.gammadashdash() @ self.rotmat\n\n    def gammadashdashdash_impl(self, gammadashdashdash):\n        r\"\"\"\n        This function returns :math:`\\Gamma'''(\\varphi)`, where :math:`\\Gamma` are the x, y, z\n        coordinates of the curve.\n\n        \"\"\"\n\n        gammadashdashdash[:] = self.curve.gammadashdashdash() @ self.rotmat\n\n    def dgamma_by_dcoeff_impl(self, dgamma_by_dcoeff):\n        r\"\"\"\n        This function returns\n\n        .. math::\n            \\frac{\\partial \\Gamma}{\\partial \\mathbf c}\n\n        where :math:`\\mathbf{c}` are the curve dofs, and :math:`\\Gamma` are the x, y, z\n        coordinates of the curve.\n\n        \"\"\"\n\n        dgamma_by_dcoeff[:] = self.rotmatT @ self.curve.dgamma_by_dcoeff()\n\n    def dgammadash_by_dcoeff_impl(self, dgammadash_by_dcoeff):\n        r\"\"\"\n        This function returns \n\n        .. math::\n            \\frac{\\partial \\Gamma'}{\\partial \\mathbf c}\n\n        where :math:`\\mathbf{c}` are the curve dofs, and :math:`\\Gamma` are the x, y, z\n        coordinates of the curve.\n        \"\"\"\n\n        dgammadash_by_dcoeff[:] = self.rotmatT @ self.curve.dgammadash_by_dcoeff()\n\n    def dgammadashdash_by_dcoeff_impl(self, dgammadashdash_by_dcoeff):\n        r\"\"\"\n        This function returns \n\n        .. math::\n            \\frac{\\partial \\Gamma''}{\\partial \\mathbf c}\n\n        where :math:`\\mathbf{c}` are the curve dofs, and :math:`\\Gamma` are the x, y, z\n        coordinates of the curve.\n\n        \"\"\"\n\n        dgammadashdash_by_dcoeff[:] = self.rotmatT @ self.curve.dgammadashdash_by_dcoeff()\n\n    def dgammadashdashdash_by_dcoeff_impl(self, dgammadashdashdash_by_dcoeff):\n        r\"\"\"\n        This function returns \n\n        .. math::\n            \\frac{\\partial \\Gamma'''}{\\partial \\mathbf c}\n\n        where :math:`\\mathbf{c}` are the curve dofs, and :math:`\\Gamma` are the x, y, z\n        coordinates of the curve.\n\n        \"\"\"\n\n        dgammadashdashdash_by_dcoeff[:] = self.rotmatT @ self.curve.dgammadashdashdash_by_dcoeff()\n\n    def dgamma_by_dcoeff_vjp(self, v):\n        r\"\"\"\n        This function returns the vector Jacobian product\n\n        .. math::\n            v^T \\frac{\\partial \\Gamma}{\\partial \\mathbf c} \n\n        where :math:`\\mathbf{c}` are the curve dofs, and :math:`\\Gamma` are the x, y, z\n        coordinates of the curve.\n\n        \"\"\"\n        v = sopp.matmult(v, self.rotmatT)  # v = v @ self.rotmatT\n        return self.curve.dgamma_by_dcoeff_vjp(v)\n\n    def dgammadash_by_dcoeff_vjp(self, v):\n        r\"\"\"\n        This function returns the vector Jacobian product\n\n        .. math::\n            v^T \\frac{\\partial \\Gamma'}{\\partial \\mathbf c} \n\n        where :math:`\\mathbf{c}` are the curve dofs, and :math:`\\Gamma` are the x, y, z\n        coordinates of the curve.\n\n        \"\"\"\n        v = sopp.matmult(v, self.rotmatT)  # v = v @ self.rotmatT\n        return self.curve.dgammadash_by_dcoeff_vjp(v)\n\n    def dgammadashdash_by_dcoeff_vjp(self, v):\n        r\"\"\"\n        This function returns the vector Jacobian product\n\n        .. math::\n            v^T \\frac{\\partial \\Gamma''}{\\partial \\mathbf c} \n\n        where :math:`\\mathbf{c}` are the curve dofs, and :math:`\\Gamma` are the x, y, z\n        coordinates of the curve.\n\n        \"\"\"\n\n        v = sopp.matmult(v, self.rotmatT)  # v = v @ self.rotmatT\n        return self.curve.dgammadashdash_by_dcoeff_vjp(v)\n\n    def dgammadashdashdash_by_dcoeff_vjp(self, v):\n        r\"\"\"\n        This function returns the vector Jacobian product\n\n        .. math::\n            v^T \\frac{\\partial \\Gamma'''}{\\partial \\mathbf c} \n\n        where :math:`\\mathbf{c}` are the curve dofs, and :math:`\\Gamma` are the x, y, z\n        coordinates of the curve.\n\n        \"\"\"\n\n        v = sopp.matmult(v, self.rotmatT)  # v = v @ self.rotmatT\n        return self.curve.dgammadashdashdash_by_dcoeff_vjp(v)\n\n    @property\n    def flip(self):\n        return True if self.rotmat[2][2] == -1 else False",
  "def curves_to_vtk(curves, filename, close=False):\n    \"\"\"\n    Export a list of Curve objects in VTK format, so they can be\n    viewed using Paraview. This function requires the python package ``pyevtk``,\n    which can be installed using ``pip install pyevtk``.\n\n    Args:\n        curves: A python list of Curve objects.\n        filename: Name of the file to write.\n        close: Whether to draw the segment from the last quadrature point back to the first.\n    \"\"\"\n    from pyevtk.hl import polyLinesToVTK\n\n    def wrap(data):\n        return np.concatenate([data, [data[0]]])\n\n    if close:\n        x = np.concatenate([wrap(c.gamma()[:, 0]) for c in curves])\n        y = np.concatenate([wrap(c.gamma()[:, 1]) for c in curves])\n        z = np.concatenate([wrap(c.gamma()[:, 2]) for c in curves])\n        ppl = np.asarray([c.gamma().shape[0]+1 for c in curves])\n    else:\n        x = np.concatenate([c.gamma()[:, 0] for c in curves])\n        y = np.concatenate([c.gamma()[:, 1] for c in curves])\n        z = np.concatenate([c.gamma()[:, 2] for c in curves])\n        ppl = np.asarray([c.gamma().shape[0] for c in curves])\n    data = np.concatenate([i*np.ones((ppl[i], )) for i in range(len(curves))])\n    polyLinesToVTK(str(filename), x, y, z, pointsPerLine=ppl, pointData={'idx': data})",
  "def create_equally_spaced_curves(ncurves, nfp, stellsym, R0=1.0, R1=0.5, order=6, numquadpoints=None):\n    \"\"\"\n    Create ``ncurves`` curves of type\n    :obj:`~simsopt.geo.curvexyzfourier.CurveXYZFourier` of order\n    ``order`` that will result in circular equally spaced coils (major\n    radius ``R0`` and minor radius ``R1``) after applying\n    :obj:`~simsopt.field.coil.coils_via_symmetries`.\n\n    Usage example: create 4 base curves, which are then rotated 3 times and\n    flipped for stellarator symmetry:\n\n    .. code-block::\n\n        base_curves = create_equally_spaced_curves(4, 3, stellsym=True)\n        base_currents = [Current(1e5) for c in base_curves]\n        coils = coils_via_symmetries(base_curves, base_currents, 3, stellsym=True)\n    \"\"\"\n    if numquadpoints is None:\n        numquadpoints = 15 * order\n    curves = []\n    from simsopt.geo.curvexyzfourier import CurveXYZFourier\n    for i in range(ncurves):\n        curve = CurveXYZFourier(numquadpoints, order)\n        angle = (i+0.5)*(2*np.pi)/((1+int(stellsym))*nfp*ncurves)\n        curve.set(\"xc(0)\", cos(angle)*R0)\n        curve.set(\"xc(1)\", cos(angle)*R1)\n        curve.set(\"yc(0)\", sin(angle)*R0)\n        curve.set(\"yc(1)\", sin(angle)*R1)\n        # The the next line, the minus sign is for consistency with\n        # Vmec.external_current(), so the coils create a toroidal field of the\n        # proper sign and free-boundary equilibrium works following stage-2 optimization.\n        curve.set(\"zs(1)\", -R1)\n        curve.x = curve.x  # need to do this to transfer data to C++\n        curves.append(curve)\n    return curves",
  "def __init__(self, **kwargs):\n        Optimizable.__init__(self, **kwargs)",
  "def recompute_bell(self, parent=None):\n        \"\"\"\n        For derivative classes of Curve, all of which also subclass\n        from C++ Curve class, call invalidate_cache which is implemented\n        in C++ side.\n        \"\"\"\n        self.invalidate_cache()",
  "def plot(self, engine=\"matplotlib\", ax=None, show=True, plot_derivative=False, close=False, axis_equal=True, **kwargs):\n        \"\"\"\n        Plot the curve in 3D using ``matplotlib.pyplot``, ``mayavi``, or ``plotly``.\n\n        Args:\n            engine: The graphics engine to use. Available settings are ``\"matplotlib\"``, ``\"mayavi\"``, and ``\"plotly\"``.\n            ax: The axis object on which to plot. This argument is useful when plotting multiple\n              objects on the same axes. If equal to the default ``None``, a new axis will be created.\n            show: Whether to call the ``show()`` function of the graphics engine. Should be set to\n              ``False`` if more objects will be plotted on the same axes.\n            plot_derivative: Whether to plot the tangent of the curve too. Not implemented for plotly.\n            close: Whether to connect the first and last point on the\n              curve. Can lead to surprising results when only quadrature points\n              on a part of the curve are considered, e.g. when exploting rotational symmetry.\n            axis_equal: For matplotlib, whether all three dimensions should be scaled equally.\n            kwargs: Any additional arguments to pass to the plotting function, like ``color='r'``.\n\n        Returns:\n            An axis which could be passed to a further call to the graphics engine\n            so multiple objects are shown together.\n        \"\"\"\n\n        def rep(data):\n            if close:\n                return np.concatenate((data, [data[0]]))\n            else:\n                return data\n\n        x = rep(self.gamma()[:, 0])\n        y = rep(self.gamma()[:, 1])\n        z = rep(self.gamma()[:, 2])\n        if plot_derivative:\n            xt = rep(self.gammadash()[:, 0])\n            yt = rep(self.gammadash()[:, 1])\n            zt = rep(self.gammadash()[:, 2])\n\n        if engine == \"matplotlib\":\n            # plot in matplotlib.pyplot\n            import matplotlib.pyplot as plt \n\n            if ax is None or ax.name != \"3d\":\n                fig = plt.figure()\n                ax = fig.add_subplot(projection='3d')\n            ax.plot(x, y, z, **kwargs)\n            if plot_derivative:\n                ax.quiver(x, y, z, 0.1 * xt, 0.1 * yt, 0.1 * zt, arrow_length_ratio=0.1, color=\"r\")\n            if axis_equal:\n                fix_matplotlib_3d(ax)\n            if show:\n                plt.show()\n\n        elif engine == \"mayavi\":\n            # plot 3D curve in mayavi.mlab\n            from mayavi import mlab\n\n            mlab.plot3d(x, y, z, **kwargs)\n            if plot_derivative:\n                mlab.quiver3d(x, y, z, 0.1*xt, 0.1*yt, 0.1*zt)\n            if show:\n                mlab.show()\n\n        elif engine == \"plotly\":\n            import plotly.graph_objects as go\n\n            if \"color\" in list(kwargs.keys()):\n                color = kwargs[\"color\"]\n                del kwargs[\"color\"]\n            else:\n                color = \"blue\"\n            kwargs.setdefault(\"line\", go.scatter3d.Line(color=color, width=4))\n            if ax is None:\n                ax = go.Figure()\n            ax.add_trace(\n                go.Scatter3d(\n                    x=x, y=y, z=z, mode=\"lines\", **kwargs\n                )\n            )\n            ax.update_layout(scene_aspectmode=\"data\")\n            if show:\n                ax.show()\n        else:\n            raise ValueError(\"Invalid engine option! Please use one of {matplotlib, mayavi, plotly}.\")\n        return ax",
  "def dgamma_by_dcoeff_vjp(self, v):\n        return Derivative({self: self.dgamma_by_dcoeff_vjp_impl(v)})",
  "def dgammadash_by_dcoeff_vjp(self, v):\n        return Derivative({self: self.dgammadash_by_dcoeff_vjp_impl(v)})",
  "def dgammadashdash_by_dcoeff_vjp(self, v):\n        return Derivative({self: self.dgammadashdash_by_dcoeff_vjp_impl(v)})",
  "def dgammadashdashdash_by_dcoeff_vjp(self, v):\n        return Derivative({self: self.dgammadashdashdash_by_dcoeff_vjp_impl(v)})",
  "def dincremental_arclength_by_dcoeff_vjp(self, v):\n        r\"\"\"\n        This function returns the vector Jacobian product\n\n        .. math::\n            v^T \\frac{\\partial \\|\\Gamma'\\|}{\\partial \\mathbf{c}}\n\n        where :math:`\\|\\Gamma'\\|` is the incremental arclength, :math:`\\Gamma'` is the tangent \n        to the curve and :math:`\\mathbf{c}` are the curve dofs.\n        \"\"\"\n\n        return self.dgammadash_by_dcoeff_vjp(\n            incremental_arclength_vjp(self.gammadash(), v))",
  "def kappa_impl(self, kappa):\n        r\"\"\"\n        This function implements the curvature, :math:`\\kappa(\\varphi)`.\n        \"\"\"\n        kappa[:] = np.asarray(kappa_pure(\n            self.gammadash(), self.gammadashdash()))",
  "def dkappa_by_dcoeff_impl(self, dkappa_by_dcoeff):\n        r\"\"\"\n        This function computes the derivative of the curvature with respect to the curve coefficients.\n\n        .. math::\n            \\frac{\\partial \\kappa}{\\partial \\mathbf c}\n\n        where :math:`\\mathbf c` are the curve dofs, :math:`\\kappa` is the curvature.\n        \"\"\"\n\n        dgamma_by_dphi = self.gammadash()\n        dgamma_by_dphidphi = self.gammadashdash()\n        dgamma_by_dphidcoeff = self.dgammadash_by_dcoeff()\n        dgamma_by_dphidphidcoeff = self.dgammadashdash_by_dcoeff()\n        num_coeff = dgamma_by_dphidcoeff.shape[2]\n\n        norm = lambda a: np.linalg.norm(a, axis=1)\n        inner = lambda a, b: np.sum(a*b, axis=1)\n        numerator = np.cross(dgamma_by_dphi, dgamma_by_dphidphi)\n        denominator = self.incremental_arclength()\n        dkappa_by_dcoeff[:, :] = (1 / (denominator**3*norm(numerator)))[:, None] * np.sum(numerator[:, :, None] * (\n            np.cross(dgamma_by_dphidcoeff[:, :, :], dgamma_by_dphidphi[:, :, None], axis=1) +\n            np.cross(dgamma_by_dphi[:, :, None], dgamma_by_dphidphidcoeff[:, :, :], axis=1)), axis=1) \\\n            - (norm(numerator) * 3 / denominator**5)[:, None] * np.sum(dgamma_by_dphi[:, :, None] * dgamma_by_dphidcoeff[:, :, :], axis=1)",
  "def torsion_impl(self, torsion):\n        r\"\"\"\n        This function returns the torsion, :math:`\\tau`, of a curve.\n        \"\"\"\n        torsion[:] = torsion_pure(self.gammadash(), self.gammadashdash(),\n                                  self.gammadashdashdash())",
  "def dtorsion_by_dcoeff_impl(self, dtorsion_by_dcoeff):\n        r\"\"\"\n        This function returns the derivative of torsion with respect to the curve dofs.\n\n        .. math::\n            \\frac{\\partial \\tau}{\\partial \\mathbf c}\n\n        where :math:`\\mathbf c` are the curve dofs, and :math:`\\tau` is the torsion.\n        \"\"\"\n        d1gamma = self.gammadash()\n        d2gamma = self.gammadashdash()\n        d3gamma = self.gammadashdashdash()\n        d1gammadcoeff = self.dgammadash_by_dcoeff()\n        d2gammadcoeff = self.dgammadashdash_by_dcoeff()\n        d3gammadcoeff = self.dgammadashdashdash_by_dcoeff()\n        dtorsion_by_dcoeff[:, :] = (\n            np.sum(np.cross(d1gamma, d2gamma, axis=1)[:, :, None] * d3gammadcoeff, axis=1)\n            + np.sum((np.cross(d1gammadcoeff, d2gamma[:, :, None], axis=1) + np.cross(d1gamma[:, :, None], d2gammadcoeff, axis=1)) * d3gamma[:, :, None], axis=1)\n        )/np.sum(np.cross(d1gamma, d2gamma, axis=1)**2, axis=1)[:, None]\n        dtorsion_by_dcoeff[:, :] -= np.sum(np.cross(d1gamma, d2gamma, axis=1) * d3gamma, axis=1)[:, None] * np.sum(2 * np.cross(d1gamma, d2gamma, axis=1)[:, :, None] * (np.cross(d1gammadcoeff, d2gamma[:, :, None], axis=1) + np.cross(d1gamma[:, :, None], d2gammadcoeff, axis=1)), axis=1)/np.sum(np.cross(d1gamma, d2gamma, axis=1)**2, axis=1)[:, None]**2",
  "def dkappa_by_dcoeff_vjp(self, v):\n        r\"\"\"\n        This function returns the vector Jacobian product\n\n        .. math::\n            v^T \\frac{\\partial \\kappa}{\\partial \\mathbf{c}} \n\n        where :math:`\\mathbf c` are the curve dofs and :math:`\\kappa` is the curvature.\n        \"\"\"\n\n        return self.dgammadash_by_dcoeff_vjp(kappavjp0(self.gammadash(), self.gammadashdash(), v)) \\\n            + self.dgammadashdash_by_dcoeff_vjp(kappavjp1(self.gammadash(), self.gammadashdash(), v))",
  "def dtorsion_by_dcoeff_vjp(self, v):\n        r\"\"\"\n        This function returns the vector Jacobian product\n\n        .. math::\n            v^T  \\frac{\\partial \\tau}{\\partial \\mathbf{c}} \n\n        where :math:`\\mathbf c` are the curve dofs, and :math:`\\tau` is the torsion.\n        \"\"\"\n\n        return self.dgammadash_by_dcoeff_vjp(torsionvjp0(self.gammadash(), self.gammadashdash(), self.gammadashdashdash(), v)) \\\n            + self.dgammadashdash_by_dcoeff_vjp(torsionvjp1(self.gammadash(), self.gammadashdash(), self.gammadashdashdash(), v)) \\\n            + self.dgammadashdashdash_by_dcoeff_vjp(torsionvjp2(self.gammadash(), self.gammadashdash(), self.gammadashdashdash(), v))",
  "def frenet_frame(self):\n        r\"\"\"\n        This function returns the Frenet frame, :math:`(\\mathbf{t}, \\mathbf{n}, \\mathbf{b})`,\n        associated to the curve.\n        \"\"\"\n\n        gammadash = self.gammadash()\n        gammadashdash = self.gammadashdash()\n        l = self.incremental_arclength()\n        norm = lambda a: np.linalg.norm(a, axis=1)\n        inner = lambda a, b: np.sum(a*b, axis=1)\n        N = len(self.quadpoints)\n        t, n, b = (np.zeros((N, 3)), np.zeros((N, 3)), np.zeros((N, 3)))\n        t[:, :] = (1./l[:, None]) * gammadash\n\n        tdash = (1./l[:, None])**2 * (l[:, None] * gammadashdash\n                                      - (inner(gammadash, gammadashdash)/l)[:, None] * gammadash\n                                      )\n        kappa = self.kappa\n        n[:, :] = (1./norm(tdash))[:, None] * tdash\n        b[:, :] = np.cross(t, n, axis=1)\n        return t, n, b",
  "def kappadash(self):\n        r\"\"\"\n        This function returns :math:`\\kappa'(\\phi)`, where :math:`\\kappa` is the curvature.\n        \"\"\"\n        dkappa_by_dphi = np.zeros((len(self.quadpoints), ))\n        dgamma = self.gammadash()\n        d2gamma = self.gammadashdash()\n        d3gamma = self.gammadashdashdash()\n        norm = lambda a: np.linalg.norm(a, axis=1)\n        inner = lambda a, b: np.sum(a*b, axis=1)\n        cross = lambda a, b: np.cross(a, b, axis=1)\n        dkappa_by_dphi[:] = inner(cross(dgamma, d2gamma), cross(dgamma, d3gamma))/(norm(cross(dgamma, d2gamma)) * norm(dgamma)**3) \\\n            - 3 * inner(dgamma, d2gamma) * norm(cross(dgamma, d2gamma))/norm(dgamma)**5\n        return dkappa_by_dphi",
  "def dfrenet_frame_by_dcoeff(self):\n        r\"\"\"\n        This function returns the derivative of the curve's Frenet frame, \n\n        .. math::\n            \\left(\\frac{\\partial \\mathbf{t}}{\\partial \\mathbf{c}}, \\frac{\\partial \\mathbf{n}}{\\partial \\mathbf{c}}, \\frac{\\partial \\mathbf{b}}{\\partial \\mathbf{c}}\\right),\n\n        with respect to the curve dofs, where :math:`(\\mathbf t, \\mathbf n, \\mathbf b)` correspond to the Frenet frame, and :math:`\\mathbf c` are the curve dofs.\n        \"\"\"\n        dgamma_by_dphi = self.gammadash()\n        d2gamma_by_dphidphi = self.gammadashdash()\n        d2gamma_by_dphidcoeff = self.dgammadash_by_dcoeff()\n        d3gamma_by_dphidphidcoeff = self.dgammadashdash_by_dcoeff()\n\n        l = self.incremental_arclength()\n        dl_by_dcoeff = self.dincremental_arclength_by_dcoeff()\n\n        norm = lambda a: np.linalg.norm(a, axis=1)\n        inner = lambda a, b: np.sum(a*b, axis=1)\n        inner2 = lambda a, b: np.sum(a*b, axis=2)\n\n        N = len(self.quadpoints)\n        dt_by_dcoeff, dn_by_dcoeff, db_by_dcoeff = (np.zeros((N, 3, self.num_dofs())), np.zeros((N, 3, self.num_dofs())), np.zeros((N, 3, self.num_dofs())))\n        t, n, b = self.frenet_frame()\n\n        dt_by_dcoeff[:, :, :] = -(dl_by_dcoeff[:, None, :]/l[:, None, None]**2) * dgamma_by_dphi[:, :, None] \\\n            + d2gamma_by_dphidcoeff / l[:, None, None]\n\n        tdash = (1./l[:, None])**2 * (\n            l[:, None] * d2gamma_by_dphidphi\n            - (inner(dgamma_by_dphi, d2gamma_by_dphidphi)/l)[:, None] * dgamma_by_dphi\n        )\n\n        dtdash_by_dcoeff = (-2 * dl_by_dcoeff[:, None, :] / l[:, None, None]**3) * (l[:, None] * d2gamma_by_dphidphi - (inner(dgamma_by_dphi, d2gamma_by_dphidphi)/l)[:, None] * dgamma_by_dphi)[:, :, None] \\\n            + (1./l[:, None, None])**2 * (\n                dl_by_dcoeff[:, None, :] * d2gamma_by_dphidphi[:, :, None] + l[:, None, None] * d3gamma_by_dphidphidcoeff\n                - (inner(d2gamma_by_dphidcoeff, d2gamma_by_dphidphi[:, :, None])[:, None, :]/l[:, None, None]) * dgamma_by_dphi[:, :, None]\n                - (inner(dgamma_by_dphi[:, :, None], d3gamma_by_dphidphidcoeff)[:, None, :]/l[:, None, None]) * dgamma_by_dphi[:, :, None]\n                + (inner(dgamma_by_dphi, d2gamma_by_dphidphi)[:, None, None] * dl_by_dcoeff[:, None, :]/l[:, None, None]**2) * dgamma_by_dphi[:, :, None]\n                - (inner(dgamma_by_dphi, d2gamma_by_dphidphi)/l)[:, None, None] * d2gamma_by_dphidcoeff\n        )\n        dn_by_dcoeff[:, :, :] = (1./norm(tdash))[:, None, None] * dtdash_by_dcoeff \\\n            - (inner(tdash[:, :, None], dtdash_by_dcoeff)[:, None, :]/inner(tdash, tdash)[:, None, None]**1.5) * tdash[:, :, None]\n\n        db_by_dcoeff[:, :, :] = np.cross(dt_by_dcoeff, n[:, :, None], axis=1) + np.cross(t[:, :, None], dn_by_dcoeff, axis=1)\n        return dt_by_dcoeff, dn_by_dcoeff, db_by_dcoeff",
  "def dkappadash_by_dcoeff(self):\n        r\"\"\"\n        This function returns \n\n        .. math::\n            \\frac{\\partial \\kappa'(\\phi)}{\\partial \\mathbf{c}}.\n\n        where :math:`\\mathbf{c}` are the curve dofs, and :math:`\\kappa` is the curvature.\n        \"\"\"\n\n        dkappadash_by_dcoeff = np.zeros((len(self.quadpoints), self.num_dofs()))\n        dgamma = self.gammadash()\n        d2gamma = self.gammadashdash()\n        d3gamma = self.gammadashdashdash()\n\n        norm = lambda a: np.linalg.norm(a, axis=1)\n        inner = lambda a, b: np.sum(a*b, axis=1)\n        cross = lambda a, b: np.cross(a, b, axis=1)\n        d1_dot_d2 = inner(dgamma, d2gamma)\n        d1_x_d2 = cross(dgamma, d2gamma)\n        d1_x_d3 = cross(dgamma, d3gamma)\n        normdgamma = norm(dgamma)\n        norm_d1_x_d2 = norm(d1_x_d2)\n        dgamma_dcoeff_ = self.dgammadash_by_dcoeff()\n        d2gamma_dcoeff_ = self.dgammadashdash_by_dcoeff()\n        d3gamma_dcoeff_ = self.dgammadashdashdash_by_dcoeff()\n        for i in range(self.num_dofs()):\n            dgamma_dcoeff = dgamma_dcoeff_[:, :, i]\n            d2gamma_dcoeff = d2gamma_dcoeff_[:, :, i]\n            d3gamma_dcoeff = d3gamma_dcoeff_[:, :, i]\n\n            d1coeff_x_d2 = cross(dgamma_dcoeff, d2gamma)\n            d1coeff_dot_d2 = inner(dgamma_dcoeff, d2gamma)\n            d1coeff_x_d3 = cross(dgamma_dcoeff, d3gamma)\n            d1_x_d2coeff = cross(dgamma, d2gamma_dcoeff)\n            d1_dot_d2coeff = inner(dgamma, d2gamma_dcoeff)\n            d1_dot_d1coeff = inner(dgamma, dgamma_dcoeff)\n            d1_x_d3coeff = cross(dgamma, d3gamma_dcoeff)\n\n            dkappadash_by_dcoeff[:, i] = (\n                +inner(d1coeff_x_d2 + d1_x_d2coeff, d1_x_d3)\n                + inner(d1_x_d2, d1coeff_x_d3 + d1_x_d3coeff)\n            )/(norm_d1_x_d2 * normdgamma**3) \\\n                - inner(d1_x_d2, d1_x_d3) * (\n                    (\n                        inner(d1coeff_x_d2 + d1_x_d2coeff, d1_x_d2)/(norm_d1_x_d2**3 * normdgamma**3)\n                        + 3 * inner(dgamma, dgamma_dcoeff)/(norm_d1_x_d2 * normdgamma**5)\n                    )\n            ) \\\n                - 3 * (\n                    + (d1coeff_dot_d2 + d1_dot_d2coeff) * norm_d1_x_d2/normdgamma**5\n                    + d1_dot_d2 * inner(d1coeff_x_d2 + d1_x_d2coeff, d1_x_d2)/(norm_d1_x_d2 * normdgamma**5)\n                    - 5 * d1_dot_d2 * norm_d1_x_d2 * d1_dot_d1coeff/normdgamma**7\n            )\n        return dkappadash_by_dcoeff",
  "def __init__(self, quadpoints, gamma_pure, **kwargs):\n        if isinstance(quadpoints, np.ndarray):\n            quadpoints = list(quadpoints)\n        sopp.Curve.__init__(self, quadpoints)\n        if \"external_dof_setter\" not in kwargs:\n            kwargs[\"external_dof_setter\"] = sopp.Curve.set_dofs_impl\n        # We are not doing the same search for x0\n        Curve.__init__(self, **kwargs)\n        self.gamma_pure = gamma_pure\n        points = np.asarray(self.quadpoints)\n        ones = jnp.ones_like(points)\n\n        self.gamma_jax = jit(lambda dofs: self.gamma_pure(dofs, points))\n        self.gamma_impl_jax = jit(lambda dofs, p: self.gamma_pure(dofs, p))\n        self.dgamma_by_dcoeff_jax = jit(jacfwd(self.gamma_jax))\n        self.dgamma_by_dcoeff_vjp_jax = jit(lambda x, v: vjp(self.gamma_jax, x)[1](v)[0])\n\n        self.gammadash_pure = lambda x, q: jvp(lambda p: self.gamma_pure(x, p), (q,), (ones,))[1]\n        self.gammadash_jax = jit(lambda x: self.gammadash_pure(x, points))\n        self.dgammadash_by_dcoeff_jax = jit(jacfwd(self.gammadash_jax))\n        self.dgammadash_by_dcoeff_vjp_jax = jit(lambda x, v: vjp(self.gammadash_jax, x)[1](v)[0])\n\n        self.gammadashdash_pure = lambda x, q: jvp(lambda p: self.gammadash_pure(x, p), (q,), (ones,))[1]\n        self.gammadashdash_jax = jit(lambda x: self.gammadashdash_pure(x, points))\n        self.dgammadashdash_by_dcoeff_jax = jit(jacfwd(self.gammadashdash_jax))\n        self.dgammadashdash_by_dcoeff_vjp_jax = jit(lambda x, v: vjp(self.gammadashdash_jax, x)[1](v)[0])\n\n        self.gammadashdashdash_pure = lambda x, q: jvp(lambda p: self.gammadashdash_pure(x, p), (q,), (ones,))[1]\n        self.gammadashdashdash_jax = jit(lambda x: self.gammadashdashdash_pure(x, points))\n        self.dgammadashdashdash_by_dcoeff_jax = jit(jacfwd(self.gammadashdashdash_jax))\n        self.dgammadashdashdash_by_dcoeff_vjp_jax = jit(lambda x, v: vjp(self.gammadashdashdash_jax, x)[1](v)[0])\n\n        self.dkappa_by_dcoeff_vjp_jax = jit(lambda x, v: vjp(lambda d: kappa_pure(self.gammadash_jax(d), self.gammadashdash_jax(d)), x)[1](v)[0])\n\n        self.dtorsion_by_dcoeff_vjp_jax = jit(lambda x, v: vjp(lambda d: torsion_pure(self.gammadash_jax(d), self.gammadashdash_jax(d), self.gammadashdashdash_jax(d)), x)[1](v)[0])",
  "def set_dofs(self, dofs):\n        self.local_x = dofs\n        sopp.Curve.set_dofs(self, dofs)",
  "def gamma_impl(self, gamma, quadpoints):\n        r\"\"\"\n        This function returns the x,y,z coordinates of the curve :math:`\\Gamma`.\n        \"\"\"\n\n        gamma[:, :] = self.gamma_impl_jax(self.get_dofs(), quadpoints)",
  "def dgamma_by_dcoeff_impl(self, dgamma_by_dcoeff):\n        r\"\"\"\n        This function returns \n\n        .. math::\n            \\frac{\\partial \\Gamma}{\\partial \\mathbf c}\n\n        where :math:`\\mathbf{c}` are the curve dofs, and :math:`\\Gamma` are the x, y, z coordinates\n        of the curve.\n        \"\"\"\n        dgamma_by_dcoeff[:, :, :] = self.dgamma_by_dcoeff_jax(self.get_dofs())",
  "def dgamma_by_dcoeff_vjp_impl(self, v):\n        r\"\"\"\n        This function returns the vector Jacobian product\n\n        .. math::\n            v^T  \\frac{\\partial \\Gamma}{\\partial \\mathbf c} \n\n        where :math:`\\mathbf{c}` are the curve dofs, and :math:`\\Gamma` are the x, y, z coordinates\n        of the curve.\n        \"\"\"\n\n        return self.dgamma_by_dcoeff_vjp_jax(self.get_dofs(), v)",
  "def gammadash_impl(self, gammadash):\n        r\"\"\"\n        This function returns :math:`\\Gamma'(\\varphi)`, where :math:`\\Gamma` are the x, y, z coordinates\n        of the curve.\n        \"\"\"\n\n        gammadash[:, :] = self.gammadash_jax(self.get_dofs())",
  "def dgammadash_by_dcoeff_impl(self, dgammadash_by_dcoeff):\n        r\"\"\"\n        This function returns \n\n        .. math::\n            \\frac{\\partial \\Gamma'}{\\partial \\mathbf c}\n\n        where :math:`\\mathbf{c}` are the curve dofs, and :math:`\\Gamma` are the x, y, z coordinates\n        of the curve.\n        \"\"\"\n\n        dgammadash_by_dcoeff[:, :, :] = self.dgammadash_by_dcoeff_jax(self.get_dofs())",
  "def dgammadash_by_dcoeff_vjp_impl(self, v):\n        r\"\"\"\n        This function returns \n\n        .. math::\n            \\mathbf v^T \\frac{\\partial \\Gamma'}{\\partial \\mathbf c}\n\n        where :math:`\\mathbf{c}` are the curve dofs, and :math:`\\Gamma` are the x, y, z coordinates\n        of the curve.\n        \"\"\"\n\n        return self.dgammadash_by_dcoeff_vjp_jax(self.get_dofs(), v)",
  "def gammadashdash_impl(self, gammadashdash):\n        r\"\"\"\n        This function returns :math:`\\Gamma''(\\varphi)`, and :math:`\\Gamma` are the x, y, z coordinates\n        of the curve.\n        \"\"\"\n\n        gammadashdash[:, :] = self.gammadashdash_jax(self.get_dofs())",
  "def dgammadashdash_by_dcoeff_impl(self, dgammadashdash_by_dcoeff):\n        r\"\"\"\n        This function returns \n\n        .. math::\n            \\frac{\\partial \\Gamma''}{\\partial \\mathbf c}\n\n        where :math:`\\mathbf{c}` are the curve dofs, and :math:`\\Gamma` are the x, y, z coordinates\n        of the curve.\n        \"\"\"\n\n        dgammadashdash_by_dcoeff[:, :, :] = self.dgammadashdash_by_dcoeff_jax(self.get_dofs())",
  "def dgammadashdash_by_dcoeff_vjp_impl(self, v):\n        r\"\"\"\n        This function returns the vector Jacobian product\n\n        .. math::\n            v^T  \\frac{\\partial \\Gamma''}{\\partial \\mathbf c} \n\n        where :math:`\\mathbf{c}` are the curve dofs, and :math:`\\Gamma` are the x, y, z coordinates\n        of the curve.\n\n        \"\"\"\n\n        return self.dgammadashdash_by_dcoeff_vjp_jax(self.get_dofs(), v)",
  "def gammadashdashdash_impl(self, gammadashdashdash):\n        r\"\"\"\n        This function returns :math:`\\Gamma'''(\\varphi)`, and :math:`\\Gamma` are the x, y, z coordinates\n        of the curve.\n        \"\"\"\n\n        gammadashdashdash[:, :] = self.gammadashdashdash_jax(self.get_dofs())",
  "def dgammadashdashdash_by_dcoeff_impl(self, dgammadashdashdash_by_dcoeff):\n        r\"\"\"\n        This function returns \n\n        .. math::\n            \\frac{\\partial \\Gamma'''}{\\partial \\mathbf c}\n\n        where :math:`\\mathbf{c}` are the curve dofs, and :math:`\\Gamma` are the x, y, z coordinates\n        of the curve.\n        \"\"\"\n\n        dgammadashdashdash_by_dcoeff[:, :, :] = self.dgammadashdashdash_by_dcoeff_jax(self.get_dofs())",
  "def dgammadashdashdash_by_dcoeff_vjp_impl(self, v):\n        r\"\"\"\n        This function returns the vector Jacobian product\n\n        .. math::\n            v^T  \\frac{\\partial \\Gamma'''}{\\partial \\mathbf c} \n\n        where :math:`\\mathbf{c}` are the curve dofs, and :math:`\\Gamma` are the x, y, z coordinates\n        of the curve.\n\n        \"\"\"\n\n        return self.dgammadashdashdash_by_dcoeff_vjp_jax(self.get_dofs(), v)",
  "def dkappa_by_dcoeff_vjp(self, v):\n        r\"\"\"\n        This function returns the vector Jacobian product\n\n        .. math::\n            v^T \\frac{\\partial \\kappa}{\\partial \\mathbf{c}}\n\n        where :math:`\\mathbf{c}` are the curve dofs and :math:`\\kappa` is the curvature.\n\n        \"\"\"\n        return Derivative({self: self.dkappa_by_dcoeff_vjp_jax(self.get_dofs(), v)})",
  "def dtorsion_by_dcoeff_vjp(self, v):\n        r\"\"\"\n        This function returns the vector Jacobian product\n\n        .. math::\n            v^T \\frac{\\partial \\tau}{\\partial \\mathbf{c}} \n\n        where :math:`\\mathbf{c}` are the curve dofs, and :math:`\\tau` is the torsion.\n\n        \"\"\"\n\n        return Derivative({self: self.dtorsion_by_dcoeff_vjp_jax(self.get_dofs(), v)})",
  "def __init__(self, curve, phi, flip):\n        self.curve = curve\n        sopp.Curve.__init__(self, curve.quadpoints)\n        Curve.__init__(self, depends_on=[curve])\n        self._phi = phi\n        self.rotmat = np.asarray(\n            [[cos(phi), -sin(phi), 0],\n             [sin(phi), cos(phi), 0],\n             [0, 0, 1]]).T\n        if flip:\n            self.rotmat = self.rotmat @ np.asarray(\n                [[1, 0, 0],\n                 [0, -1, 0],\n                 [0, 0, -1]])\n        self.rotmatT = self.rotmat.T.copy()",
  "def get_dofs(self):\n        \"\"\"\n        RotatedCurve does not have any dofs of its own.\n        This function returns null array\n        \"\"\"\n        return np.array([])",
  "def set_dofs_impl(self, d):\n        \"\"\"\n        RotatedCurve does not have any dofs of its own.\n        This function does nothing.\n        \"\"\"\n        pass",
  "def num_dofs(self):\n        \"\"\"\n        This function returns the number of dofs associated to the curve.\n        \"\"\"\n        return self.curve.num_dofs()",
  "def gamma_impl(self, gamma, quadpoints):\n        r\"\"\"\n        This function returns the x,y,z coordinates of the curve, :math:`\\Gamma`, where :math:`\\Gamma` are the x, y, z\n        coordinates of the curve.\n\n        \"\"\"\n\n        if len(quadpoints) == len(self.curve.quadpoints) \\\n                and np.sum((quadpoints-self.curve.quadpoints)**2) < 1e-15:\n            gamma[:] = self.curve.gamma() @ self.rotmat\n        else:\n            self.curve.gamma_impl(gamma, quadpoints)\n            gamma[:] = gamma @ self.rotmat",
  "def gammadash_impl(self, gammadash):\n        r\"\"\"\n        This function returns :math:`\\Gamma'(\\varphi)`, where :math:`\\Gamma` are the x, y, z\n        coordinates of the curve.\n\n        \"\"\"\n\n        gammadash[:] = self.curve.gammadash() @ self.rotmat",
  "def gammadashdash_impl(self, gammadashdash):\n        r\"\"\"\n        This function returns :math:`\\Gamma''(\\varphi)`, where :math:`\\Gamma` are the x, y, z\n        coordinates of the curve.\n\n        \"\"\"\n\n        gammadashdash[:] = self.curve.gammadashdash() @ self.rotmat",
  "def gammadashdashdash_impl(self, gammadashdashdash):\n        r\"\"\"\n        This function returns :math:`\\Gamma'''(\\varphi)`, where :math:`\\Gamma` are the x, y, z\n        coordinates of the curve.\n\n        \"\"\"\n\n        gammadashdashdash[:] = self.curve.gammadashdashdash() @ self.rotmat",
  "def dgamma_by_dcoeff_impl(self, dgamma_by_dcoeff):\n        r\"\"\"\n        This function returns\n\n        .. math::\n            \\frac{\\partial \\Gamma}{\\partial \\mathbf c}\n\n        where :math:`\\mathbf{c}` are the curve dofs, and :math:`\\Gamma` are the x, y, z\n        coordinates of the curve.\n\n        \"\"\"\n\n        dgamma_by_dcoeff[:] = self.rotmatT @ self.curve.dgamma_by_dcoeff()",
  "def dgammadash_by_dcoeff_impl(self, dgammadash_by_dcoeff):\n        r\"\"\"\n        This function returns \n\n        .. math::\n            \\frac{\\partial \\Gamma'}{\\partial \\mathbf c}\n\n        where :math:`\\mathbf{c}` are the curve dofs, and :math:`\\Gamma` are the x, y, z\n        coordinates of the curve.\n        \"\"\"\n\n        dgammadash_by_dcoeff[:] = self.rotmatT @ self.curve.dgammadash_by_dcoeff()",
  "def dgammadashdash_by_dcoeff_impl(self, dgammadashdash_by_dcoeff):\n        r\"\"\"\n        This function returns \n\n        .. math::\n            \\frac{\\partial \\Gamma''}{\\partial \\mathbf c}\n\n        where :math:`\\mathbf{c}` are the curve dofs, and :math:`\\Gamma` are the x, y, z\n        coordinates of the curve.\n\n        \"\"\"\n\n        dgammadashdash_by_dcoeff[:] = self.rotmatT @ self.curve.dgammadashdash_by_dcoeff()",
  "def dgammadashdashdash_by_dcoeff_impl(self, dgammadashdashdash_by_dcoeff):\n        r\"\"\"\n        This function returns \n\n        .. math::\n            \\frac{\\partial \\Gamma'''}{\\partial \\mathbf c}\n\n        where :math:`\\mathbf{c}` are the curve dofs, and :math:`\\Gamma` are the x, y, z\n        coordinates of the curve.\n\n        \"\"\"\n\n        dgammadashdashdash_by_dcoeff[:] = self.rotmatT @ self.curve.dgammadashdashdash_by_dcoeff()",
  "def dgamma_by_dcoeff_vjp(self, v):\n        r\"\"\"\n        This function returns the vector Jacobian product\n\n        .. math::\n            v^T \\frac{\\partial \\Gamma}{\\partial \\mathbf c} \n\n        where :math:`\\mathbf{c}` are the curve dofs, and :math:`\\Gamma` are the x, y, z\n        coordinates of the curve.\n\n        \"\"\"\n        v = sopp.matmult(v, self.rotmatT)  # v = v @ self.rotmatT\n        return self.curve.dgamma_by_dcoeff_vjp(v)",
  "def dgammadash_by_dcoeff_vjp(self, v):\n        r\"\"\"\n        This function returns the vector Jacobian product\n\n        .. math::\n            v^T \\frac{\\partial \\Gamma'}{\\partial \\mathbf c} \n\n        where :math:`\\mathbf{c}` are the curve dofs, and :math:`\\Gamma` are the x, y, z\n        coordinates of the curve.\n\n        \"\"\"\n        v = sopp.matmult(v, self.rotmatT)  # v = v @ self.rotmatT\n        return self.curve.dgammadash_by_dcoeff_vjp(v)",
  "def dgammadashdash_by_dcoeff_vjp(self, v):\n        r\"\"\"\n        This function returns the vector Jacobian product\n\n        .. math::\n            v^T \\frac{\\partial \\Gamma''}{\\partial \\mathbf c} \n\n        where :math:`\\mathbf{c}` are the curve dofs, and :math:`\\Gamma` are the x, y, z\n        coordinates of the curve.\n\n        \"\"\"\n\n        v = sopp.matmult(v, self.rotmatT)  # v = v @ self.rotmatT\n        return self.curve.dgammadashdash_by_dcoeff_vjp(v)",
  "def dgammadashdashdash_by_dcoeff_vjp(self, v):\n        r\"\"\"\n        This function returns the vector Jacobian product\n\n        .. math::\n            v^T \\frac{\\partial \\Gamma'''}{\\partial \\mathbf c} \n\n        where :math:`\\mathbf{c}` are the curve dofs, and :math:`\\Gamma` are the x, y, z\n        coordinates of the curve.\n\n        \"\"\"\n\n        v = sopp.matmult(v, self.rotmatT)  # v = v @ self.rotmatT\n        return self.curve.dgammadashdashdash_by_dcoeff_vjp(v)",
  "def flip(self):\n        return True if self.rotmat[2][2] == -1 else False",
  "def wrap(data):\n        return np.concatenate([data, [data[0]]])",
  "def rep(data):\n            if close:\n                return np.concatenate((data, [data[0]]))\n            else:\n                return data",
  "class CurveXYZFourier(sopp.CurveXYZFourier, Curve):\n\n    r\"\"\"\n       ``CurveXYZFourier`` is a curve that is represented in Cartesian\n       coordinates using the following Fourier series:\n\n        .. math::\n           x(\\theta) &= \\sum_{m=0}^{\\text{order}} x_{c,m}\\cos(m\\theta) + \\sum_{m=1}^{\\text{order}} x_{s,m}\\sin(m\\theta) \\\\\n           y(\\theta) &= \\sum_{m=0}^{\\text{order}} y_{c,m}\\cos(m\\theta) + \\sum_{m=1}^{\\text{order}} y_{s,m}\\sin(m\\theta) \\\\\n           z(\\theta) &= \\sum_{m=0}^{\\text{order}} z_{c,m}\\cos(m\\theta) + \\sum_{m=1}^{\\text{order}} z_{s,m}\\sin(m\\theta)\n\n       The dofs are stored in the order\n\n        .. math::\n           [x_{c,0}, x_{s,1}, x_{c,1},\\cdots x_{s,\\text{order}}, x_{c,\\text{order}},y_{c,0},y_{s,1},y_{c,1},\\cdots]\n\n    \"\"\"\n\n    def __init__(self, quadpoints, order, dofs=None):\n        if isinstance(quadpoints, int):\n            quadpoints = list(np.linspace(0, 1, quadpoints, endpoint=False))\n        elif isinstance(quadpoints, np.ndarray):\n            quadpoints = list(quadpoints)\n        sopp.CurveXYZFourier.__init__(self, quadpoints, order)\n        if dofs is None:\n            Curve.__init__(self, x0=self.get_dofs(), names=self._make_names(order),\n                           external_dof_setter=CurveXYZFourier.set_dofs_impl)\n        else:\n            Curve.__init__(self, dofs=dofs,\n                           external_dof_setter=CurveXYZFourier.set_dofs_impl)\n\n    def _make_names(self, order):\n        x_names = ['xc(0)']\n        x_cos_names = [f'xc({i})' for i in range(1, order + 1)]\n        x_sin_names = [f'xs({i})' for i in range(1, order + 1)]\n        x_names += list(chain.from_iterable(zip(x_sin_names, x_cos_names)))\n        y_names = ['yc(0)']\n        y_cos_names = [f'yc({i})' for i in range(1, order + 1)]\n        y_sin_names = [f'ys({i})' for i in range(1, order + 1)]\n        y_names += list(chain.from_iterable(zip(y_sin_names, y_cos_names)))\n        z_names = ['zc(0)']\n        z_cos_names = [f'zc({i})' for i in range(1, order + 1)]\n        z_sin_names = [f'zs({i})' for i in range(1, order + 1)]\n        z_names += list(chain.from_iterable(zip(z_sin_names, z_cos_names)))\n\n        return x_names + y_names + z_names\n\n    def get_dofs(self):\n        \"\"\"\n        This function returns the dofs associated to this object.\n        \"\"\"\n        return np.asarray(sopp.CurveXYZFourier.get_dofs(self))\n\n    def set_dofs(self, dofs):\n        \"\"\"\n        This function sets the dofs associated to this object.\n        \"\"\"\n        self.local_x = dofs\n        sopp.CurveXYZFourier.set_dofs(self, dofs)\n\n    @staticmethod\n    def load_curves_from_file(filename, order=None, ppp=20, delimiter=','):\n        \"\"\"\n        This function loads a file containing Fourier coefficients for several coils.\n        The file is expected to have :mod:`6*num_coils` many columns, and :mod:`order+1` many rows.\n        The columns are in the following order,\n\n            sin_x_coil1, cos_x_coil1, sin_y_coil1, cos_y_coil1, sin_z_coil1, cos_z_coil1, sin_x_coil2, cos_x_coil2, sin_y_coil2, cos_y_coil2, sin_z_coil2, cos_z_coil2,  ...\n\n        \"\"\"\n        coil_data = np.loadtxt(filename, delimiter=delimiter)\n\n        assert coil_data.shape[1] % 6 == 0\n        assert order <= coil_data.shape[0]-1\n\n        num_coils = coil_data.shape[1]//6\n        coils = [CurveXYZFourier(order*ppp, order) for i in range(num_coils)]\n        for ic in range(num_coils):\n            dofs = coils[ic].dofs_matrix\n            dofs[0][0] = coil_data[0, 6*ic + 1]\n            dofs[1][0] = coil_data[0, 6*ic + 3]\n            dofs[2][0] = coil_data[0, 6*ic + 5]\n            for io in range(0, min(order, coil_data.shape[0]-1)):\n                dofs[0][2*io+1] = coil_data[io+1, 6*ic + 0]\n                dofs[0][2*io+2] = coil_data[io+1, 6*ic + 1]\n                dofs[1][2*io+1] = coil_data[io+1, 6*ic + 2]\n                dofs[1][2*io+2] = coil_data[io+1, 6*ic + 3]\n                dofs[2][2*io+1] = coil_data[io+1, 6*ic + 4]\n                dofs[2][2*io+2] = coil_data[io+1, 6*ic + 5]\n            coils[ic].local_x = np.concatenate(dofs)\n        return coils\n\n    @staticmethod\n    def load_curves_from_makegrid_file(filename: str, order: int, ppp=20):\n        \"\"\"\n        This function loads a Makegrid input file containing the Cartesian\n        coordinates for several coils and finds the corresponding Fourier\n        coefficients through an fft. The format is described at\n        https://princetonuniversity.github.io/STELLOPT/MAKEGRID\n\n        Args:\n            filename: file to load.\n            order: maximum mode number in the Fourier series. \n            ppp: points-per-period: number of quadrature points per period.\n\n        Returns:\n            A list of ``CurveXYZFourier`` objects.\n        \"\"\"\n\n        with open(filename, 'r') as f:\n            file_lines = f.read().splitlines()[3:] \n\n        curve_data = []\n        single_curve_data = []\n        for j_line in range(len(file_lines)):\n            vals = file_lines[j_line].split()\n            n_vals = len(vals)\n            if n_vals == 4:\n                float_vals = [float(val) for val in vals[:3]]\n                single_curve_data.append(float_vals)\n            elif n_vals == 6:\n                # This must be the last line of the coil\n                curve_data.append(single_curve_data)\n                single_curve_data = []\n            elif n_vals == 1:\n                # Presumably the line that is just \"end\"\n                break\n            else:\n                raise RuntimeError(\"Should not get here\")\n\n        coil_data = []\n\n        # Compute the Fourier coefficients for each coil\n        for curve in curve_data:\n            xArr, yArr, zArr = np.transpose(curve)\n\n            curves_Fourier = []\n\n            # Compute the Fourier coefficients\n            for x in [xArr, yArr, zArr]:\n                assert len(x) >= 2*order  # the order of the fft is limited by the number of samples\n                xf = rfft(x) / len(x)\n\n                fft_0 = [xf[0].real]  # find the 0 order coefficient\n                fft_cos = 2 * xf[1:order + 1].real  # find the cosine coefficients\n                fft_sin = -2 * xf[:order + 1].imag  # find the sine coefficients\n\n                combined_fft = np.concatenate([fft_sin, fft_0, fft_cos])\n                curves_Fourier.append(combined_fft)\n\n            coil_data.append(np.concatenate(curves_Fourier))\n\n        coil_data = np.asarray(coil_data)\n        coil_data = coil_data.reshape(6 * len(curve_data), order + 1)  # There are 6 * order coefficients per coil\n        coil_data = np.transpose(coil_data)\n\n        assert coil_data.shape[1] % 6 == 0\n        assert order <= coil_data.shape[0]-1\n\n        num_coils = coil_data.shape[1] // 6\n        coils = [CurveXYZFourier(order*ppp, order) for i in range(num_coils)]\n        for ic in range(num_coils):\n            dofs = coils[ic].dofs_matrix\n            dofs[0][0] = coil_data[0, 6*ic + 1]\n            dofs[1][0] = coil_data[0, 6*ic + 3]\n            dofs[2][0] = coil_data[0, 6*ic + 5]\n            for io in range(0, min(order, coil_data.shape[0] - 1)):\n                dofs[0][2*io+1] = coil_data[io+1, 6*ic + 0]\n                dofs[0][2*io+2] = coil_data[io+1, 6*ic + 1]\n                dofs[1][2*io+1] = coil_data[io+1, 6*ic + 2]\n                dofs[1][2*io+2] = coil_data[io+1, 6*ic + 3]\n                dofs[2][2*io+1] = coil_data[io+1, 6*ic + 4]\n                dofs[2][2*io+2] = coil_data[io+1, 6*ic + 5]\n            coils[ic].local_x = np.concatenate(dofs)\n        return coils",
  "def jaxfouriercurve_pure(dofs, quadpoints, order):\n    k = len(dofs)//3\n    coeffs = [dofs[:k], dofs[k:(2*k)], dofs[(2*k):]]\n    points = quadpoints\n    gamma = jnp.zeros((len(points), 3))\n    for i in range(3):\n        gamma = gamma.at[:, i].add(coeffs[i][0])\n        for j in range(1, order+1):\n            gamma = gamma.at[:, i].add(coeffs[i][2 * j - 1] * jnp.sin(2 * pi * j * points))\n            gamma = gamma.at[:, i].add(coeffs[i][2 * j] * jnp.cos(2 * pi * j * points))\n    return gamma",
  "class JaxCurveXYZFourier(JaxCurve):\n\n    \"\"\"\n    A Python+Jax implementation of the CurveXYZFourier class.  There is\n    actually no reason why one should use this over the C++ implementation in\n    :mod:`simsoptpp`, but the point of this class is to illustrate how jax can be used\n    to define a geometric object class and calculate all the derivatives (both\n    with respect to dofs and with respect to the angle :math:`\\theta`) automatically.\n    \"\"\"\n\n    def __init__(self, quadpoints, order, dofs=None):\n        if isinstance(quadpoints, int):\n            quadpoints = np.linspace(0, 1, quadpoints, endpoint=False)\n        pure = lambda dofs, points: jaxfouriercurve_pure(dofs, points, order)\n        self.order = order\n        self.coefficients = [np.zeros((2*order+1,)), np.zeros((2*order+1,)), np.zeros((2*order+1,))]\n        if dofs is None:\n            super().__init__(quadpoints, pure, x0=np.concatenate(self.coefficients),\n                             external_dof_setter=JaxCurveXYZFourier.set_dofs_impl)\n        else:\n            super().__init__(quadpoints, pure, dofs=dofs,\n                             external_dof_setter=JaxCurveXYZFourier.set_dofs_impl)\n\n    def num_dofs(self):\n        \"\"\"\n        This function returns the number of dofs associated to this object.\n        \"\"\"\n        return 3*(2*self.order+1)\n\n    def get_dofs(self):\n        \"\"\"\n        This function returns the dofs associated to this object.\n        \"\"\"\n        return np.concatenate(self.coefficients)\n\n    def set_dofs_impl(self, dofs):\n        \"\"\"\n        This function sets the dofs associated to this object.\n        \"\"\"\n        counter = 0\n        for i in range(3):\n            self.coefficients[i][0] = dofs[counter]\n            counter += 1\n            for j in range(1, self.order+1):\n                self.coefficients[i][2*j-1] = dofs[counter]\n                counter += 1\n                self.coefficients[i][2*j] = dofs[counter]\n                counter += 1",
  "def __init__(self, quadpoints, order, dofs=None):\n        if isinstance(quadpoints, int):\n            quadpoints = list(np.linspace(0, 1, quadpoints, endpoint=False))\n        elif isinstance(quadpoints, np.ndarray):\n            quadpoints = list(quadpoints)\n        sopp.CurveXYZFourier.__init__(self, quadpoints, order)\n        if dofs is None:\n            Curve.__init__(self, x0=self.get_dofs(), names=self._make_names(order),\n                           external_dof_setter=CurveXYZFourier.set_dofs_impl)\n        else:\n            Curve.__init__(self, dofs=dofs,\n                           external_dof_setter=CurveXYZFourier.set_dofs_impl)",
  "def _make_names(self, order):\n        x_names = ['xc(0)']\n        x_cos_names = [f'xc({i})' for i in range(1, order + 1)]\n        x_sin_names = [f'xs({i})' for i in range(1, order + 1)]\n        x_names += list(chain.from_iterable(zip(x_sin_names, x_cos_names)))\n        y_names = ['yc(0)']\n        y_cos_names = [f'yc({i})' for i in range(1, order + 1)]\n        y_sin_names = [f'ys({i})' for i in range(1, order + 1)]\n        y_names += list(chain.from_iterable(zip(y_sin_names, y_cos_names)))\n        z_names = ['zc(0)']\n        z_cos_names = [f'zc({i})' for i in range(1, order + 1)]\n        z_sin_names = [f'zs({i})' for i in range(1, order + 1)]\n        z_names += list(chain.from_iterable(zip(z_sin_names, z_cos_names)))\n\n        return x_names + y_names + z_names",
  "def get_dofs(self):\n        \"\"\"\n        This function returns the dofs associated to this object.\n        \"\"\"\n        return np.asarray(sopp.CurveXYZFourier.get_dofs(self))",
  "def set_dofs(self, dofs):\n        \"\"\"\n        This function sets the dofs associated to this object.\n        \"\"\"\n        self.local_x = dofs\n        sopp.CurveXYZFourier.set_dofs(self, dofs)",
  "def load_curves_from_file(filename, order=None, ppp=20, delimiter=','):\n        \"\"\"\n        This function loads a file containing Fourier coefficients for several coils.\n        The file is expected to have :mod:`6*num_coils` many columns, and :mod:`order+1` many rows.\n        The columns are in the following order,\n\n            sin_x_coil1, cos_x_coil1, sin_y_coil1, cos_y_coil1, sin_z_coil1, cos_z_coil1, sin_x_coil2, cos_x_coil2, sin_y_coil2, cos_y_coil2, sin_z_coil2, cos_z_coil2,  ...\n\n        \"\"\"\n        coil_data = np.loadtxt(filename, delimiter=delimiter)\n\n        assert coil_data.shape[1] % 6 == 0\n        assert order <= coil_data.shape[0]-1\n\n        num_coils = coil_data.shape[1]//6\n        coils = [CurveXYZFourier(order*ppp, order) for i in range(num_coils)]\n        for ic in range(num_coils):\n            dofs = coils[ic].dofs_matrix\n            dofs[0][0] = coil_data[0, 6*ic + 1]\n            dofs[1][0] = coil_data[0, 6*ic + 3]\n            dofs[2][0] = coil_data[0, 6*ic + 5]\n            for io in range(0, min(order, coil_data.shape[0]-1)):\n                dofs[0][2*io+1] = coil_data[io+1, 6*ic + 0]\n                dofs[0][2*io+2] = coil_data[io+1, 6*ic + 1]\n                dofs[1][2*io+1] = coil_data[io+1, 6*ic + 2]\n                dofs[1][2*io+2] = coil_data[io+1, 6*ic + 3]\n                dofs[2][2*io+1] = coil_data[io+1, 6*ic + 4]\n                dofs[2][2*io+2] = coil_data[io+1, 6*ic + 5]\n            coils[ic].local_x = np.concatenate(dofs)\n        return coils",
  "def load_curves_from_makegrid_file(filename: str, order: int, ppp=20):\n        \"\"\"\n        This function loads a Makegrid input file containing the Cartesian\n        coordinates for several coils and finds the corresponding Fourier\n        coefficients through an fft. The format is described at\n        https://princetonuniversity.github.io/STELLOPT/MAKEGRID\n\n        Args:\n            filename: file to load.\n            order: maximum mode number in the Fourier series. \n            ppp: points-per-period: number of quadrature points per period.\n\n        Returns:\n            A list of ``CurveXYZFourier`` objects.\n        \"\"\"\n\n        with open(filename, 'r') as f:\n            file_lines = f.read().splitlines()[3:] \n\n        curve_data = []\n        single_curve_data = []\n        for j_line in range(len(file_lines)):\n            vals = file_lines[j_line].split()\n            n_vals = len(vals)\n            if n_vals == 4:\n                float_vals = [float(val) for val in vals[:3]]\n                single_curve_data.append(float_vals)\n            elif n_vals == 6:\n                # This must be the last line of the coil\n                curve_data.append(single_curve_data)\n                single_curve_data = []\n            elif n_vals == 1:\n                # Presumably the line that is just \"end\"\n                break\n            else:\n                raise RuntimeError(\"Should not get here\")\n\n        coil_data = []\n\n        # Compute the Fourier coefficients for each coil\n        for curve in curve_data:\n            xArr, yArr, zArr = np.transpose(curve)\n\n            curves_Fourier = []\n\n            # Compute the Fourier coefficients\n            for x in [xArr, yArr, zArr]:\n                assert len(x) >= 2*order  # the order of the fft is limited by the number of samples\n                xf = rfft(x) / len(x)\n\n                fft_0 = [xf[0].real]  # find the 0 order coefficient\n                fft_cos = 2 * xf[1:order + 1].real  # find the cosine coefficients\n                fft_sin = -2 * xf[:order + 1].imag  # find the sine coefficients\n\n                combined_fft = np.concatenate([fft_sin, fft_0, fft_cos])\n                curves_Fourier.append(combined_fft)\n\n            coil_data.append(np.concatenate(curves_Fourier))\n\n        coil_data = np.asarray(coil_data)\n        coil_data = coil_data.reshape(6 * len(curve_data), order + 1)  # There are 6 * order coefficients per coil\n        coil_data = np.transpose(coil_data)\n\n        assert coil_data.shape[1] % 6 == 0\n        assert order <= coil_data.shape[0]-1\n\n        num_coils = coil_data.shape[1] // 6\n        coils = [CurveXYZFourier(order*ppp, order) for i in range(num_coils)]\n        for ic in range(num_coils):\n            dofs = coils[ic].dofs_matrix\n            dofs[0][0] = coil_data[0, 6*ic + 1]\n            dofs[1][0] = coil_data[0, 6*ic + 3]\n            dofs[2][0] = coil_data[0, 6*ic + 5]\n            for io in range(0, min(order, coil_data.shape[0] - 1)):\n                dofs[0][2*io+1] = coil_data[io+1, 6*ic + 0]\n                dofs[0][2*io+2] = coil_data[io+1, 6*ic + 1]\n                dofs[1][2*io+1] = coil_data[io+1, 6*ic + 2]\n                dofs[1][2*io+2] = coil_data[io+1, 6*ic + 3]\n                dofs[2][2*io+1] = coil_data[io+1, 6*ic + 4]\n                dofs[2][2*io+2] = coil_data[io+1, 6*ic + 5]\n            coils[ic].local_x = np.concatenate(dofs)\n        return coils",
  "def __init__(self, quadpoints, order, dofs=None):\n        if isinstance(quadpoints, int):\n            quadpoints = np.linspace(0, 1, quadpoints, endpoint=False)\n        pure = lambda dofs, points: jaxfouriercurve_pure(dofs, points, order)\n        self.order = order\n        self.coefficients = [np.zeros((2*order+1,)), np.zeros((2*order+1,)), np.zeros((2*order+1,))]\n        if dofs is None:\n            super().__init__(quadpoints, pure, x0=np.concatenate(self.coefficients),\n                             external_dof_setter=JaxCurveXYZFourier.set_dofs_impl)\n        else:\n            super().__init__(quadpoints, pure, dofs=dofs,\n                             external_dof_setter=JaxCurveXYZFourier.set_dofs_impl)",
  "def num_dofs(self):\n        \"\"\"\n        This function returns the number of dofs associated to this object.\n        \"\"\"\n        return 3*(2*self.order+1)",
  "def get_dofs(self):\n        \"\"\"\n        This function returns the dofs associated to this object.\n        \"\"\"\n        return np.concatenate(self.coefficients)",
  "def set_dofs_impl(self, dofs):\n        \"\"\"\n        This function sets the dofs associated to this object.\n        \"\"\"\n        counter = 0\n        for i in range(3):\n            self.coefficients[i][0] = dofs[counter]\n            counter += 1\n            for j in range(1, self.order+1):\n                self.coefficients[i][2*j-1] = dofs[counter]\n                counter += 1\n                self.coefficients[i][2*j] = dofs[counter]\n                counter += 1",
  "def create_multifilament_grid(curve, numfilaments_n, numfilaments_b, gapsize_n, gapsize_b, rotation_order=None, rotation_scaling=None):\n    \"\"\"\n    Create a regular grid of ``numfilaments_n * numfilaments_b`` many\n    filaments to approximate a finite-build coil.\n\n    Note that \"normal\" and \"binormal\" in the function arguments here\n    refer not to the Frenet frame but rather to the \"coil centroid\n    frame\" defined by Singh et al., before rotation.\n\n    Args:\n        curve: The underlying curve.\n        numfilaments_n: number of filaments in normal direction.\n        numfilaments_b: number of filaments in bi-normal direction.\n        gapsize_n: gap between filaments in normal direction.\n        gapsize_b: gap between filaments in bi-normal direction.\n        rotation_order: Fourier order (maximum mode number) to use in the expression for the rotation\n                        of the filament pack. ``None`` means that the rotation is not optimized.\n        rotation_scaling: scaling for the rotation degrees of freedom. good\n                           scaling improves the convergence of first order optimization\n                           algorithms. If ``None``, then the default of ``1 / max(gapsize_n, gapsize_b)``\n                           is used.\n    \"\"\"\n    if numfilaments_n % 2 == 1:\n        shifts_n = np.arange(numfilaments_n) - numfilaments_n//2\n    else:\n        shifts_n = np.arange(numfilaments_n) - numfilaments_n/2 + 0.5\n    shifts_n = shifts_n * gapsize_n\n    if numfilaments_b % 2 == 1:\n        shifts_b = np.arange(numfilaments_b) - numfilaments_b//2\n    else:\n        shifts_b = np.arange(numfilaments_b) - numfilaments_b/2 + 0.5\n    shifts_b = shifts_b * gapsize_b\n\n    if rotation_scaling is None:\n        rotation_scaling = 1/max(gapsize_n, gapsize_b)\n    if rotation_order is None:\n        rotation = ZeroRotation(curve.quadpoints)\n    else:\n        rotation = FilamentRotation(curve.quadpoints, rotation_order, scale=rotation_scaling)\n    filaments = []\n    for i in range(numfilaments_n):\n        for j in range(numfilaments_b):\n            filaments.append(CurveFilament(curve, shifts_n[i], shifts_b[j], rotation))\n    return filaments",
  "class CurveFilament(sopp.Curve, Curve):\n\n    def __init__(self, curve, dn, db, rotation=None):\n        \"\"\"\n        Implementation of the centroid frame introduced in\n        Singh et al, \"Optimization of finite-build stellarator coils\",\n        Journal of Plasma Physics 86 (2020),\n        doi:10.1017/S0022377820000756. Given a curve, one defines a normal and\n        binormal vector and then creates a grid of curves by shifting along the\n        normal and binormal vector. In addition, we specify an angle along the\n        curve that allows us to optimise for the rotation of the winding pack.\n\n        The idea is explained well in Figure 1 in the reference above.\n\n        Note that \"normal\" and \"binormal\" in the function arguments here\n        refer not to the Frenet frame but rather to the \"coil centroid\n        frame\" defined by Singh et al., before rotation.\n\n        Args:\n            curve: the underlying curve\n            dn: how far to move in normal direction\n            db: how far to move in binormal direction\n            rotation: angle along the curve to rotate the frame.\n        \"\"\"\n        self.curve = curve\n        sopp.Curve.__init__(self, curve.quadpoints)\n        deps = [curve]\n        if rotation is not None:\n            deps.append(rotation)\n        Curve.__init__(self, depends_on=deps)\n        self.curve = curve\n        self.dn = dn\n        self.db = db\n        if rotation is None:\n            rotation = ZeroRotation(curve.quadpoints)\n        self.rotation = rotation\n\n    def recompute_bell(self, parent=None):\n        self.invalidate_cache()\n\n    def gamma_impl(self, gamma, quadpoints):\n        assert quadpoints.shape[0] == self.curve.quadpoints.shape[0]\n        assert np.linalg.norm(quadpoints - self.curve.quadpoints) < 1e-15\n        c = self.curve\n        t, n, b = rotated_centroid_frame(c.gamma(), c.gammadash(), self.rotation.alpha(c.quadpoints))\n        gamma[:] = self.curve.gamma() + self.dn * n + self.db * b\n\n    def gammadash_impl(self, gammadash):\n        c = self.curve\n        td, nd, bd = rotated_centroid_frame_dash(\n            c.gamma(), c.gammadash(), c.gammadashdash(),\n            self.rotation.alpha(c.quadpoints), self.rotation.alphadash(c.quadpoints)\n        )\n        gammadash[:] = self.curve.gammadash() + self.dn * nd + self.db * bd\n\n    def dgamma_by_dcoeff_vjp(self, v):\n        g = self.curve.gamma()\n        gd = self.curve.gammadash()\n        a = self.rotation.alpha(self.curve.quadpoints)\n        zero = np.zeros_like(v)\n        vg = rotated_centroid_frame_dcoeff_vjp0(g, gd, a, (zero, self.dn*v, self.db*v))\n        vgd = rotated_centroid_frame_dcoeff_vjp1(g, gd, a, (zero, self.dn*v, self.db*v))\n        va = rotated_centroid_frame_dcoeff_vjp2(g, gd, a, (zero, self.dn*v, self.db*v))\n        return self.curve.dgamma_by_dcoeff_vjp(v + vg) \\\n            + self.curve.dgammadash_by_dcoeff_vjp(vgd) \\\n            + self.rotation.dalpha_by_dcoeff_vjp(self.curve.quadpoints, va)\n\n    def dgammadash_by_dcoeff_vjp(self, v):\n        g = self.curve.gamma()\n        gd = self.curve.gammadash()\n        gdd = self.curve.gammadashdash()\n        a = self.rotation.alpha(self.curve.quadpoints)\n        ad = self.rotation.alphadash(self.curve.quadpoints)\n        zero = np.zeros_like(v)\n\n        vg = rotated_centroid_frame_dash_dcoeff_vjp0(g, gd, gdd, a, ad, (zero, self.dn*v, self.db*v))\n        vgd = rotated_centroid_frame_dash_dcoeff_vjp1(g, gd, gdd, a, ad, (zero, self.dn*v, self.db*v))\n        vgdd = rotated_centroid_frame_dash_dcoeff_vjp2(g, gd, gdd, a, ad, (zero, self.dn*v, self.db*v))\n        va = rotated_centroid_frame_dash_dcoeff_vjp3(g, gd, gdd, a, ad, (zero, self.dn*v, self.db*v))\n        vad = rotated_centroid_frame_dash_dcoeff_vjp4(g, gd, gdd, a, ad, (zero, self.dn*v, self.db*v))\n        return self.curve.dgamma_by_dcoeff_vjp(vg) \\\n            + self.curve.dgammadash_by_dcoeff_vjp(v+vgd) \\\n            + self.curve.dgammadashdash_by_dcoeff_vjp(vgdd) \\\n            + self.rotation.dalpha_by_dcoeff_vjp(self.curve.quadpoints, va) \\\n            + self.rotation.dalphadash_by_dcoeff_vjp(self.curve.quadpoints, vad)",
  "class FilamentRotation(Optimizable):\n\n    def __init__(self, quadpoints, order, scale=1., dofs=None):\n        \"\"\"\n        The rotation of the multifilament pack; alpha in Figure 1 of\n        Singh et al, \"Optimization of finite-build stellarator coils\",\n        Journal of Plasma Physics 86 (2020),\n        doi:10.1017/S0022377820000756\n        \"\"\"\n        self.order = order\n        if dofs is None:\n            super().__init__(x0=np.zeros((2*order+1, )))\n        else:\n            super().__init__(dofs=dofs)\n        self.quadpoints = quadpoints\n        self.scale = scale\n        self.jac = rotation_dcoeff(quadpoints, order)\n        self.jacdash = rotationdash_dcoeff(quadpoints, order)\n        self.jax_alpha = jit(lambda dofs, points: jaxrotation_pure(dofs, points, self.order))\n        self.jax_alphadash = jit(lambda dofs, points: jaxrotationdash_pure(dofs, points, self.order))\n\n    def alpha(self, quadpoints):\n        return self.scale * self.jax_alpha(self._dofs.full_x, quadpoints)\n\n    def alphadash(self, quadpoints):\n        return self.scale * self.jax_alphadash(self._dofs.full_x, quadpoints)\n\n    def dalpha_by_dcoeff_vjp(self, quadpoints, v):\n        return Derivative({self: self.scale * sopp.vjp(v, self.jac)})\n\n    def dalphadash_by_dcoeff_vjp(self, quadpoints, v):\n        return Derivative({self: self.scale * sopp.vjp(v, self.jacdash)})",
  "class ZeroRotation(Optimizable):\n\n    def __init__(self, quadpoints):\n        \"\"\"\n        Dummy class that just returns zero for the rotation angle. Equivalent to using\n\n        .. code-block:: python\n\n            rot = FilamentRotation(...)\n            rot.fix_all()\n\n        \"\"\"\n        super().__init__()\n        self.zero = np.zeros((quadpoints.size, ))\n\n    def alpha(self, quadpoints):\n        return self.zero\n\n    def alphadash(self, quadpoints):\n        return self.zero\n\n    def dalpha_by_dcoeff_vjp(self, quadpoints, v):\n        return Derivative({})\n\n    def dalphadash_by_dcoeff_vjp(self, quadpoints, v):\n        return Derivative({})",
  "def rotated_centroid_frame(gamma, gammadash, alpha):\n    t = gammadash\n    t *= 1./jnp.linalg.norm(gammadash, axis=1)[:, None]\n    R = jnp.mean(gamma, axis=0)  # centroid\n    delta = gamma - R[None, :]\n    n = delta - jnp.sum(delta * t, axis=1)[:, None] * t\n    n *= 1./jnp.linalg.norm(n, axis=1)[:, None]\n    b = jnp.cross(t, n, axis=1)\n\n    # now rotate the frame by alpha\n    nn = jnp.cos(alpha)[:, None] * n - jnp.sin(alpha)[:, None] * b\n    bb = jnp.sin(alpha)[:, None] * n + jnp.cos(alpha)[:, None] * b\n    return t, nn, bb",
  "def jaxrotation_pure(dofs, points, order):\n    rotation = jnp.zeros((len(points), ))\n    rotation += dofs[0]\n    for j in range(1, order+1):\n        rotation += dofs[2*j-1] * jnp.sin(2*np.pi*j*points)\n        rotation += dofs[2*j] * jnp.cos(2*np.pi*j*points)\n    return rotation",
  "def jaxrotationdash_pure(dofs, points, order):\n    rotation = jnp.zeros((len(points), ))\n    for j in range(1, order+1):\n        rotation += dofs[2*j-1] * 2*np.pi*j*jnp.cos(2*np.pi*j*points)\n        rotation -= dofs[2*j] * 2*np.pi*j*jnp.sin(2*np.pi*j*points)\n    return rotation",
  "def rotation_dcoeff(points, order):\n    jac = np.zeros((len(points), 2*order+1))\n    jac[:, 0] = 1\n    for j in range(1, order+1):\n        jac[:, 2*j-1] = np.sin(2*np.pi*j*points)\n        jac[:, 2*j+0] = np.cos(2*np.pi*j*points)\n    return jac",
  "def rotationdash_dcoeff(points, order):\n    jac = np.zeros((len(points), 2*order+1))\n    for j in range(1, order+1):\n        jac[:, 2*j-1] = +2*np.pi*j*np.cos(2*np.pi*j*points)\n        jac[:, 2*j+0] = -2*np.pi*j*np.sin(2*np.pi*j*points)\n    return jac",
  "def __init__(self, curve, dn, db, rotation=None):\n        \"\"\"\n        Implementation of the centroid frame introduced in\n        Singh et al, \"Optimization of finite-build stellarator coils\",\n        Journal of Plasma Physics 86 (2020),\n        doi:10.1017/S0022377820000756. Given a curve, one defines a normal and\n        binormal vector and then creates a grid of curves by shifting along the\n        normal and binormal vector. In addition, we specify an angle along the\n        curve that allows us to optimise for the rotation of the winding pack.\n\n        The idea is explained well in Figure 1 in the reference above.\n\n        Note that \"normal\" and \"binormal\" in the function arguments here\n        refer not to the Frenet frame but rather to the \"coil centroid\n        frame\" defined by Singh et al., before rotation.\n\n        Args:\n            curve: the underlying curve\n            dn: how far to move in normal direction\n            db: how far to move in binormal direction\n            rotation: angle along the curve to rotate the frame.\n        \"\"\"\n        self.curve = curve\n        sopp.Curve.__init__(self, curve.quadpoints)\n        deps = [curve]\n        if rotation is not None:\n            deps.append(rotation)\n        Curve.__init__(self, depends_on=deps)\n        self.curve = curve\n        self.dn = dn\n        self.db = db\n        if rotation is None:\n            rotation = ZeroRotation(curve.quadpoints)\n        self.rotation = rotation",
  "def recompute_bell(self, parent=None):\n        self.invalidate_cache()",
  "def gamma_impl(self, gamma, quadpoints):\n        assert quadpoints.shape[0] == self.curve.quadpoints.shape[0]\n        assert np.linalg.norm(quadpoints - self.curve.quadpoints) < 1e-15\n        c = self.curve\n        t, n, b = rotated_centroid_frame(c.gamma(), c.gammadash(), self.rotation.alpha(c.quadpoints))\n        gamma[:] = self.curve.gamma() + self.dn * n + self.db * b",
  "def gammadash_impl(self, gammadash):\n        c = self.curve\n        td, nd, bd = rotated_centroid_frame_dash(\n            c.gamma(), c.gammadash(), c.gammadashdash(),\n            self.rotation.alpha(c.quadpoints), self.rotation.alphadash(c.quadpoints)\n        )\n        gammadash[:] = self.curve.gammadash() + self.dn * nd + self.db * bd",
  "def dgamma_by_dcoeff_vjp(self, v):\n        g = self.curve.gamma()\n        gd = self.curve.gammadash()\n        a = self.rotation.alpha(self.curve.quadpoints)\n        zero = np.zeros_like(v)\n        vg = rotated_centroid_frame_dcoeff_vjp0(g, gd, a, (zero, self.dn*v, self.db*v))\n        vgd = rotated_centroid_frame_dcoeff_vjp1(g, gd, a, (zero, self.dn*v, self.db*v))\n        va = rotated_centroid_frame_dcoeff_vjp2(g, gd, a, (zero, self.dn*v, self.db*v))\n        return self.curve.dgamma_by_dcoeff_vjp(v + vg) \\\n            + self.curve.dgammadash_by_dcoeff_vjp(vgd) \\\n            + self.rotation.dalpha_by_dcoeff_vjp(self.curve.quadpoints, va)",
  "def dgammadash_by_dcoeff_vjp(self, v):\n        g = self.curve.gamma()\n        gd = self.curve.gammadash()\n        gdd = self.curve.gammadashdash()\n        a = self.rotation.alpha(self.curve.quadpoints)\n        ad = self.rotation.alphadash(self.curve.quadpoints)\n        zero = np.zeros_like(v)\n\n        vg = rotated_centroid_frame_dash_dcoeff_vjp0(g, gd, gdd, a, ad, (zero, self.dn*v, self.db*v))\n        vgd = rotated_centroid_frame_dash_dcoeff_vjp1(g, gd, gdd, a, ad, (zero, self.dn*v, self.db*v))\n        vgdd = rotated_centroid_frame_dash_dcoeff_vjp2(g, gd, gdd, a, ad, (zero, self.dn*v, self.db*v))\n        va = rotated_centroid_frame_dash_dcoeff_vjp3(g, gd, gdd, a, ad, (zero, self.dn*v, self.db*v))\n        vad = rotated_centroid_frame_dash_dcoeff_vjp4(g, gd, gdd, a, ad, (zero, self.dn*v, self.db*v))\n        return self.curve.dgamma_by_dcoeff_vjp(vg) \\\n            + self.curve.dgammadash_by_dcoeff_vjp(v+vgd) \\\n            + self.curve.dgammadashdash_by_dcoeff_vjp(vgdd) \\\n            + self.rotation.dalpha_by_dcoeff_vjp(self.curve.quadpoints, va) \\\n            + self.rotation.dalphadash_by_dcoeff_vjp(self.curve.quadpoints, vad)",
  "def __init__(self, quadpoints, order, scale=1., dofs=None):\n        \"\"\"\n        The rotation of the multifilament pack; alpha in Figure 1 of\n        Singh et al, \"Optimization of finite-build stellarator coils\",\n        Journal of Plasma Physics 86 (2020),\n        doi:10.1017/S0022377820000756\n        \"\"\"\n        self.order = order\n        if dofs is None:\n            super().__init__(x0=np.zeros((2*order+1, )))\n        else:\n            super().__init__(dofs=dofs)\n        self.quadpoints = quadpoints\n        self.scale = scale\n        self.jac = rotation_dcoeff(quadpoints, order)\n        self.jacdash = rotationdash_dcoeff(quadpoints, order)\n        self.jax_alpha = jit(lambda dofs, points: jaxrotation_pure(dofs, points, self.order))\n        self.jax_alphadash = jit(lambda dofs, points: jaxrotationdash_pure(dofs, points, self.order))",
  "def alpha(self, quadpoints):\n        return self.scale * self.jax_alpha(self._dofs.full_x, quadpoints)",
  "def alphadash(self, quadpoints):\n        return self.scale * self.jax_alphadash(self._dofs.full_x, quadpoints)",
  "def dalpha_by_dcoeff_vjp(self, quadpoints, v):\n        return Derivative({self: self.scale * sopp.vjp(v, self.jac)})",
  "def dalphadash_by_dcoeff_vjp(self, quadpoints, v):\n        return Derivative({self: self.scale * sopp.vjp(v, self.jacdash)})",
  "def __init__(self, quadpoints):\n        \"\"\"\n        Dummy class that just returns zero for the rotation angle. Equivalent to using\n\n        .. code-block:: python\n\n            rot = FilamentRotation(...)\n            rot.fix_all()\n\n        \"\"\"\n        super().__init__()\n        self.zero = np.zeros((quadpoints.size, ))",
  "def alpha(self, quadpoints):\n        return self.zero",
  "def alphadash(self, quadpoints):\n        return self.zero",
  "def dalpha_by_dcoeff_vjp(self, quadpoints, v):\n        return Derivative({})",
  "def dalphadash_by_dcoeff_vjp(self, quadpoints, v):\n        return Derivative({})",
  "def fix_matplotlib_3d(ax):\n    '''\n    Make axes of 3D plot have equal scale so that spheres appear as spheres,\n    cubes as cubes, etc..  This is one possible solution to Matplotlib's\n    ``ax.set_aspect('equal')`` and ``ax.axis('equal')`` not working for 3D.\n    This function is to be called after objects have been plotted.\n\n    This function was taken from\n    `<https://stackoverflow.com/questions/13685386/matplotlib-equal-unit-length-with-equal-aspect-ratio-z-axis-is-not-equal-to>`_\n\n    Args:\n      ax: a matplotlib axis, e.g., as output from ``plt.gca()``.\n    '''\n    x_limits = ax.get_xlim3d()\n    y_limits = ax.get_ylim3d()\n    z_limits = ax.get_zlim3d()\n\n    x_range = abs(x_limits[1] - x_limits[0])\n    x_middle = np.mean(x_limits)\n    y_range = abs(y_limits[1] - y_limits[0])\n    y_middle = np.mean(y_limits)\n    z_range = abs(z_limits[1] - z_limits[0])\n    z_middle = np.mean(z_limits)\n\n    # The plot bounding box is a sphere in the sense of the infinity\n    # norm, hence call half the max range the plot radius.\n    plot_radius = 0.5 * max([x_range, y_range, z_range])\n\n    ax.set_xlim3d([x_middle - plot_radius, x_middle + plot_radius])\n    ax.set_ylim3d([y_middle - plot_radius, y_middle + plot_radius])\n    ax.set_zlim3d([z_middle - plot_radius, z_middle + plot_radius])",
  "def plot(items, ax=None, show=True, **kwargs):\n    \"\"\"\n    Plot multiple Coil, Curve, and/or Surface objects together on the\n    same axes. Any keyword arguments other than the ones listed here\n    are passed to the ``plot()`` method of each item. A particularly\n    useful argument is ``engine``, which can be set to\n    ``\"matplotlib\"``, ``\"mayavi\"``, or ``\"plotly\"``.\n\n    Args:\n        items: A list of objects to plot, consisting of :obj:`~simsopt.field.coil.Coil`,\n            :obj:`~simsopt.geo.curve.Curve`, and :obj:`~simsopt.geo.surface.Surface` objects.\n        ax: The axis object on which to plot. If equal to the default ``None``, a new axis will be created.\n        show: Whether to call the ``show()`` function of the graphics engine. Should be set to\n            ``False`` if more objects will be plotted on the same axes.\n\n    Returns:\n      The axis object used.\n    \"\"\"\n    n = len(items)\n    for j in range(n):\n        if j == n - 1:\n            this_show = show\n        else:\n            this_show = False\n        ax = items[j].plot(ax=ax, show=this_show, **kwargs)\n    return ax",
  "class GaussianSampler(GSONable):\n    r\"\"\"\n    Generate a periodic gaussian process on the interval [0, 1] on a given list of quadrature points.\n    The process has standard deviation ``sigma`` a correlation length scale ``length_scale``.\n    Large values of ``length_scale`` correspond to smooth processes, small values result in highly oscillatory\n    functions.\n    Also has the ability to sample the derivatives of the function.\n\n    We consider the kernel\n\n    .. math::\n\n        \\kappa(d) = \\sigma^2 \\exp(-d^2/l^2)\n\n    and then consider a Gaussian process with covariance\n\n    .. math::\n\n        Cov(X(s), X(t)) = \\sum_{i=-\\infty}^\\infty \\sigma^2 \\exp(-(s-t+i)^2/l^2)\n\n    the sum is used to make the kernel periodic and in practice the infinite sum is truncated.\n\n    Args:\n        points: the quadrature points along which the perturbation should be computed.\n        sigma: standard deviation of the underlying gaussian process\n               (measure for the magnitude of the perturbation).\n        length_scale: length scale of the underlying gaussian process\n                      (measure for the smoothness of the perturbation).\n        n_derivs: number of derivatives of the gaussian process to sample.\n    \"\"\"\n\n    points: RealArray\n    sigma: float\n    length_scale: float\n    n_derivs: int = 1\n\n    def __post_init__(self):\n        xs = self.points\n        n = len(xs)\n        cov_mat = np.zeros((n*(self.n_derivs+1), n*(self.n_derivs+1)))\n\n        def kernel(x, y):\n            return sum((self.sigma**2)*exp(-(x-y+i)**2/(self.length_scale**2)) for i in range(-5, 6))\n\n        XX, YY = np.meshgrid(xs, xs, indexing='ij')\n        x = Symbol(\"x\")\n        y = Symbol(\"y\")\n        f = kernel(x, y)\n        for ii in range(self.n_derivs+1):\n            for jj in range(self.n_derivs+1):\n                if ii + jj == 0:\n                    lam = lambdify((x, y), f, \"numpy\")\n                else:\n                    lam = lambdify((x, y), f.diff(*(ii * [x] + jj * [y])), \"numpy\")\n                cov_mat[(ii*n):((ii+1)*n), (jj*n):((jj+1)*n)] = lam(XX, YY)\n\n        # we need to compute the sqrt of the covariance matrix. we used to do this using scipy.linalg.sqrtm,\n        # but it seems sometime between scipy 1.11.1 and 1.11.2 that function broke/changed behaviour.\n        # So we use a LDLT decomposition instead. See als https://github.com/hiddenSymmetries/simsopt/issues/349\n        # from scipy.linalg import sqrtm, ldl\n        # self.L = np.real(sqrtm(cov_mat))\n        from scipy.linalg import ldl\n        lu, d, _ = ldl(cov_mat)\n        self.L = lu @ np.sqrt(np.maximum(d, 0))\n\n    def draw_sample(self, randomgen=None):\n        \"\"\"\n        Returns a list of ``n_derivs+1`` arrays of size ``(len(points), 3)``, containing the\n        perturbation and the derivatives.\n        \"\"\"\n        n = len(self.points)\n        n_derivs = self.n_derivs\n        if randomgen is None:\n            randomgen = np.random\n        z = randomgen.standard_normal(size=(n*(n_derivs+1), 3))\n        curve_and_derivs = self.L@z\n        return [curve_and_derivs[(i*n):((i+1)*n), :] for i in range(n_derivs+1)]",
  "class PerturbationSample(GSONable):\n    \"\"\"\n    This class represents a single sample of a perturbation.  The point of\n    having a dedicated class for this is so that we can apply the same\n    perturbation to multipe curves (e.g. in the case of multifilament\n    approximations to finite build coils).\n    The main way to interact with this class is via the overloaded ``__getitem__``\n    (i.e. ``[ ]`` indexing).\n    For example::\n\n        sample = PerturbationSample(...)\n        g = sample[0] # get the values of the perturbation\n        gd = sample[1] # get the first derivative of the perturbation\n    \"\"\"\n\n    def __init__(self, sampler, randomgen=None, sample=None):\n        self.sampler = sampler\n        self.randomgen = randomgen   # If not None, most likely fail with serialization\n        if sample:\n            self._sample = sample\n        else:\n            self.resample()\n\n    def resample(self):\n        self._sample = self.sampler.draw_sample(self.randomgen)\n\n    def __getitem__(self, deriv):\n        \"\"\"\n        Get the perturbation (if ``deriv=0``) or its ``deriv``-th derivative.\n        \"\"\"\n        assert isinstance(deriv, int)\n        if deriv >= len(self._sample):\n            raise ValueError(\"\"\"\nThe sample on has {len(self._sample)-1} derivatives.\nAdjust the `n_derivs` parameter of the sampler to access higher derivatives.\n\"\"\")\n        return self._sample[deriv]",
  "class CurvePerturbed(sopp.Curve, Curve):\n\n    \"\"\"A perturbed curve.\"\"\"\n\n    def __init__(self, curve, sample):\n        r\"\"\"\n        Perturb a underlying :mod:`simsopt.geo.curve.Curve` object by drawing a perturbation from a\n        :obj:`GaussianSampler`.\n\n        Comment:\n        Doing anything involving randomness in a reproducible way requires care.\n        Even more so, when doing things in parallel.\n        Let's say we have a list of :mod:`simsopt.geo.curve.Curve` objects ``curves`` that represent a stellarator,\n        and now we want to consider ``N`` perturbed stellarators. Let's also say we have multiple MPI ranks.\n        To avoid the same thing happening on the different MPI ranks, we could pick a different seed on each rank.\n        However, then we get different results depending on the number of MPI ranks that we run on. Not ideal.\n        Instead, we should pick a new seed for each :math:`1\\le i\\le N`. e.g.\n\n        .. code-block:: python\n\n            from randomgen import SeedSequence, PCG64\n            import numpy as np\n            curves = ...\n            sigma = 0.01\n            length_scale = 0.2\n            sampler = GaussianSampler(curves[0].quadpoints, sigma, length_scale, n_derivs=1)\n            globalseed = 1\n            N = 10 # number of perturbed stellarators\n            seeds = SeedSequence(globalseed).spawn(N)\n            idx_start, idx_end = split_range_between_mpi_rank(N) # e.g. [0, 5) on rank 0, [5, 10) on rank 1\n            perturbed_curves = [] # this will be a List[List[Curve]], with perturbed_curves[i] containing the perturbed curves for the i-th stellarator\n            for i in range(idx_start, idx_end):\n                rg = np.random.Generator(PCG64(seeds_sys[j], inc=0))\n                stell = []\n                for c in curves:\n                    pert = PerturbationSample(sampler_systematic, randomgen=rg)\n                    stell.append(CurvePerturbed(c, pert))\n                perturbed_curves.append(stell)\n        \"\"\"\n        self.curve = curve\n        sopp.Curve.__init__(self, curve.quadpoints)\n        Curve.__init__(self, depends_on=[curve])\n        self.sample = sample\n\n    def resample(self):\n        self.sample.resample()\n        self.recompute_bell()\n\n    def recompute_bell(self, parent=None):\n        self.invalidate_cache()\n\n    def gamma_impl(self, gamma, quadpoints):\n        assert quadpoints.shape[0] == self.curve.quadpoints.shape[0]\n        assert np.linalg.norm(quadpoints - self.curve.quadpoints) < 1e-15\n        gamma[:] = self.curve.gamma() + self.sample[0]\n\n    def gammadash_impl(self, gammadash):\n        gammadash[:] = self.curve.gammadash() + self.sample[1]\n\n    def gammadashdash_impl(self, gammadashdash):\n        gammadashdash[:] = self.curve.gammadashdash() + self.sample[2]\n\n    def gammadashdashdash_impl(self, gammadashdashdash):\n        gammadashdashdash[:] = self.curve.gammadashdashdash() + self.sample[3]\n\n    def dgamma_by_dcoeff_vjp(self, v):\n        return self.curve.dgamma_by_dcoeff_vjp(v)\n\n    def dgammadash_by_dcoeff_vjp(self, v):\n        return self.curve.dgammadash_by_dcoeff_vjp(v)\n\n    def dgammadashdash_by_dcoeff_vjp(self, v):\n        return self.curve.dgammadashdash_by_dcoeff_vjp(v)\n\n    def dgammadashdashdash_by_dcoeff_vjp(self, v):\n        return self.curve.dgammadashdashdash_by_dcoeff_vjp(v)",
  "def __post_init__(self):\n        xs = self.points\n        n = len(xs)\n        cov_mat = np.zeros((n*(self.n_derivs+1), n*(self.n_derivs+1)))\n\n        def kernel(x, y):\n            return sum((self.sigma**2)*exp(-(x-y+i)**2/(self.length_scale**2)) for i in range(-5, 6))\n\n        XX, YY = np.meshgrid(xs, xs, indexing='ij')\n        x = Symbol(\"x\")\n        y = Symbol(\"y\")\n        f = kernel(x, y)\n        for ii in range(self.n_derivs+1):\n            for jj in range(self.n_derivs+1):\n                if ii + jj == 0:\n                    lam = lambdify((x, y), f, \"numpy\")\n                else:\n                    lam = lambdify((x, y), f.diff(*(ii * [x] + jj * [y])), \"numpy\")\n                cov_mat[(ii*n):((ii+1)*n), (jj*n):((jj+1)*n)] = lam(XX, YY)\n\n        # we need to compute the sqrt of the covariance matrix. we used to do this using scipy.linalg.sqrtm,\n        # but it seems sometime between scipy 1.11.1 and 1.11.2 that function broke/changed behaviour.\n        # So we use a LDLT decomposition instead. See als https://github.com/hiddenSymmetries/simsopt/issues/349\n        # from scipy.linalg import sqrtm, ldl\n        # self.L = np.real(sqrtm(cov_mat))\n        from scipy.linalg import ldl\n        lu, d, _ = ldl(cov_mat)\n        self.L = lu @ np.sqrt(np.maximum(d, 0))",
  "def draw_sample(self, randomgen=None):\n        \"\"\"\n        Returns a list of ``n_derivs+1`` arrays of size ``(len(points), 3)``, containing the\n        perturbation and the derivatives.\n        \"\"\"\n        n = len(self.points)\n        n_derivs = self.n_derivs\n        if randomgen is None:\n            randomgen = np.random\n        z = randomgen.standard_normal(size=(n*(n_derivs+1), 3))\n        curve_and_derivs = self.L@z\n        return [curve_and_derivs[(i*n):((i+1)*n), :] for i in range(n_derivs+1)]",
  "def __init__(self, sampler, randomgen=None, sample=None):\n        self.sampler = sampler\n        self.randomgen = randomgen   # If not None, most likely fail with serialization\n        if sample:\n            self._sample = sample\n        else:\n            self.resample()",
  "def resample(self):\n        self._sample = self.sampler.draw_sample(self.randomgen)",
  "def __getitem__(self, deriv):\n        \"\"\"\n        Get the perturbation (if ``deriv=0``) or its ``deriv``-th derivative.\n        \"\"\"\n        assert isinstance(deriv, int)\n        if deriv >= len(self._sample):\n            raise ValueError(\"\"\"\nThe sample on has {len(self._sample)-1} derivatives.\nAdjust the `n_derivs` parameter of the sampler to access higher derivatives.\n\"\"\")\n        return self._sample[deriv]",
  "def __init__(self, curve, sample):\n        r\"\"\"\n        Perturb a underlying :mod:`simsopt.geo.curve.Curve` object by drawing a perturbation from a\n        :obj:`GaussianSampler`.\n\n        Comment:\n        Doing anything involving randomness in a reproducible way requires care.\n        Even more so, when doing things in parallel.\n        Let's say we have a list of :mod:`simsopt.geo.curve.Curve` objects ``curves`` that represent a stellarator,\n        and now we want to consider ``N`` perturbed stellarators. Let's also say we have multiple MPI ranks.\n        To avoid the same thing happening on the different MPI ranks, we could pick a different seed on each rank.\n        However, then we get different results depending on the number of MPI ranks that we run on. Not ideal.\n        Instead, we should pick a new seed for each :math:`1\\le i\\le N`. e.g.\n\n        .. code-block:: python\n\n            from randomgen import SeedSequence, PCG64\n            import numpy as np\n            curves = ...\n            sigma = 0.01\n            length_scale = 0.2\n            sampler = GaussianSampler(curves[0].quadpoints, sigma, length_scale, n_derivs=1)\n            globalseed = 1\n            N = 10 # number of perturbed stellarators\n            seeds = SeedSequence(globalseed).spawn(N)\n            idx_start, idx_end = split_range_between_mpi_rank(N) # e.g. [0, 5) on rank 0, [5, 10) on rank 1\n            perturbed_curves = [] # this will be a List[List[Curve]], with perturbed_curves[i] containing the perturbed curves for the i-th stellarator\n            for i in range(idx_start, idx_end):\n                rg = np.random.Generator(PCG64(seeds_sys[j], inc=0))\n                stell = []\n                for c in curves:\n                    pert = PerturbationSample(sampler_systematic, randomgen=rg)\n                    stell.append(CurvePerturbed(c, pert))\n                perturbed_curves.append(stell)\n        \"\"\"\n        self.curve = curve\n        sopp.Curve.__init__(self, curve.quadpoints)\n        Curve.__init__(self, depends_on=[curve])\n        self.sample = sample",
  "def resample(self):\n        self.sample.resample()\n        self.recompute_bell()",
  "def recompute_bell(self, parent=None):\n        self.invalidate_cache()",
  "def gamma_impl(self, gamma, quadpoints):\n        assert quadpoints.shape[0] == self.curve.quadpoints.shape[0]\n        assert np.linalg.norm(quadpoints - self.curve.quadpoints) < 1e-15\n        gamma[:] = self.curve.gamma() + self.sample[0]",
  "def gammadash_impl(self, gammadash):\n        gammadash[:] = self.curve.gammadash() + self.sample[1]",
  "def gammadashdash_impl(self, gammadashdash):\n        gammadashdash[:] = self.curve.gammadashdash() + self.sample[2]",
  "def gammadashdashdash_impl(self, gammadashdashdash):\n        gammadashdashdash[:] = self.curve.gammadashdashdash() + self.sample[3]",
  "def dgamma_by_dcoeff_vjp(self, v):\n        return self.curve.dgamma_by_dcoeff_vjp(v)",
  "def dgammadash_by_dcoeff_vjp(self, v):\n        return self.curve.dgammadash_by_dcoeff_vjp(v)",
  "def dgammadashdash_by_dcoeff_vjp(self, v):\n        return self.curve.dgammadashdash_by_dcoeff_vjp(v)",
  "def dgammadashdashdash_by_dcoeff_vjp(self, v):\n        return self.curve.dgammadashdashdash_by_dcoeff_vjp(v)",
  "def kernel(x, y):\n            return sum((self.sigma**2)*exp(-(x-y+i)**2/(self.length_scale**2)) for i in range(-5, 6))",
  "class BoozerSurface(Optimizable):\n    r\"\"\"\n    BoozerSurface and its associated methods can be used to compute the Boozer\n    angles on a surface. It takes a Surface representation (e.g. SurfaceXYZFourier,\n    or SurfaceXYZTensorFourier), a magnetic field evaluator, surface label evaluator,\n    and a target surface label.\n\n    The Boozer angles are computed by solving a constrained least squares problem.\n    The least squares objective is given by :math:`J(x) = \\frac{1}{2} \\mathbf r^T(x) \\mathbf r(x)`, \n    where :math:`\\mathbf r` is a vector of residuals computed by :mod:`boozer_surface_residual` \n    (see :mod:`surfaceobjectives.py`), and some constraints.  This objective is zero when the surface corresponds \n    to a magnetic surface of the field and :math:`(\\phi,\\theta)` that parametrize the surface correspond to \n    Boozer angles, and the constraints are satisfied.\n\n    The surface label can be area, volume, or toroidal flux. The label on the computed surface will be equal or close\n    to the user-provided ``targetlabel``, depending on how the label constraint is imposed.  This \n    constrained least squares problem can be solved by scalarizing and adding the constraint as \n    an additional penalty term to the objective.  This is done in\n\n        #. :mod:`minimize_boozer_penalty_constraints_LBFGS`\n        #. :mod:`minimize_boozer_penalty_constraints_newton`\n        #. :mod:`minimize_boozer_penalty_constraints_ls`\n\n    where LBFGS, Newton, or :mod:`scipy.optimize.least_squares` optimizers are used, respectively.\n    Alternatively, the exactly constrained least squares optimization problem can be solved.\n    This is done in\n\n        #. :mod:`minimize_boozer_exact_constraints_newton`\n\n    where Newton is used to solve the first order necessary conditions for optimality.\n    \"\"\"\n\n    def __init__(self, biotsavart, surface, label, targetlabel):\n        super().__init__(depends_on=[biotsavart])\n        self.biotsavart = biotsavart\n        self.surface = surface\n        self.label = label\n        self.targetlabel = targetlabel\n        self.need_to_run_code = True\n\n    def recompute_bell(self, parent=None):\n        self.need_to_run_code = True\n\n    def boozer_penalty_constraints(self, x, derivatives=0, constraint_weight=1., scalarize=True, optimize_G=False):\n        r\"\"\"\n        Define the residual\n\n        .. math::\n            \\mathbf r(x) = [r_1(x),...,r_n(x), \\sqrt{w_c}  (l-l_0), \\sqrt{w_c}  (z(\\varphi=0, \\theta=0) - 0)]\n\n        where :math:`w_c` is the constraint weight, :math:`r_i` are the Boozer residuals \n        at quadrature points :math:`1,\\dots,n`, :math:`l` is the surface label, and :math:`l_0` is\n        the target surface label.\n\n        For ``scalarized=False``, this function returns :math:`\\mathbf r(x)` and optionally the Jacobian \n        of :math:`\\mathbf r(x)`.\n\n        for ``scalarized=True``, this function returns\n\n        .. math::\n            J(x) = \\frac{1}{2}\\mathbf r(x)^T \\mathbf r(x),\n\n        i.e. the least squares residual and optionally the gradient and the Hessian of :math:`J(x)`.\n        \"\"\"\n\n        assert derivatives in [0, 1, 2]\n        if optimize_G:\n            sdofs = x[:-2]\n            iota = x[-2]\n            G = x[-1]\n        else:\n            sdofs = x[:-1]\n            iota = x[-1]\n            G = None\n\n        nsurfdofs = sdofs.size\n        s = self.surface\n        biotsavart = self.biotsavart\n\n        s.set_dofs(sdofs)\n\n        boozer = boozer_surface_residual(s, iota, G, biotsavart, derivatives=derivatives)\n\n        r = boozer[0]\n\n        l = self.label.J()\n        rl = (l-self.targetlabel)\n        rz = (s.gamma()[0, 0, 2] - 0.)\n        r = np.concatenate((r, [\n            np.sqrt(constraint_weight) * rl,\n            np.sqrt(constraint_weight) * rz\n        ]))\n\n        val = 0.5 * np.sum(r**2)\n        if derivatives == 0:\n            if scalarize:\n                return val\n            else:\n                return r\n\n        J = boozer[1]\n\n        dl = np.zeros(x.shape)\n        drz = np.zeros(x.shape)\n\n        dl[:nsurfdofs] = self.label.dJ(partials=True)(s)\n\n        drz[:nsurfdofs] = s.dgamma_by_dcoeff()[0, 0, 2, :]\n        J = np.concatenate((\n            J,\n            np.sqrt(constraint_weight) * dl[None, :],\n            np.sqrt(constraint_weight) * drz[None, :]), axis=0)\n        dval = np.sum(r[:, None]*J, axis=0)\n        if derivatives == 1:\n            if scalarize:\n                return val, dval\n            else:\n                return r, J\n        if not scalarize:\n            raise NotImplementedError('Can only return Hessian for scalarized version.')\n\n        H = boozer[2]\n\n        d2l = np.zeros((x.shape[0], x.shape[0]))\n        d2l[:nsurfdofs, :nsurfdofs] = self.label.d2J_by_dsurfacecoefficientsdsurfacecoefficients()\n\n        H = np.concatenate((\n            H,\n            np.sqrt(constraint_weight) * d2l[None, :, :],\n            np.zeros(d2l[None, :, :].shape)), axis=0)\n        d2val = J.T @ J + np.sum(r[:, None, None] * H, axis=0)\n        return val, dval, d2val\n\n    def boozer_exact_constraints(self, xl, derivatives=0, optimize_G=True):\n        r\"\"\"\n        This function returns the optimality conditions corresponding to the minimization problem\n\n        .. math::\n            \\text{min}_x ~J(x)\n\n        subject to \n\n        .. math::\n            l - l_0 &= 0 \\\\\n            z(\\varphi=0,\\theta=0) - 0 &= 0\n\n        where :math:`l` is the surface label and :math:`l_0` is the target surface label, \n        :math:`J(x) = \\frac{1}{2}\\mathbf r(x)^T \\mathbf r(x)`, and :math:`\\mathbf r(x)` contains\n        the Boozer residuals at quadrature points :math:`1,\\dots,n`.\n        We can also optionally return the first derivatives of these optimality conditions.\n        \"\"\"\n        assert derivatives in [0, 1]\n        if optimize_G:\n            sdofs = xl[:-4]\n            iota = xl[-4]\n            G = xl[-3]\n        else:\n            sdofs = xl[:-3]\n            iota = xl[-3]\n            G = None\n        lm = xl[-2:]\n        s = self.surface\n        biotsavart = self.biotsavart\n        s.set_dofs(sdofs)\n        nsurfdofs = sdofs.size\n\n        boozer = boozer_surface_residual(s, iota, G, biotsavart, derivatives=derivatives+1)\n        r, J = boozer[0:2]\n\n        dl = np.zeros((xl.shape[0]-2,))\n\n        l = self.label.J()\n        dl[:nsurfdofs] = self.label.dJ(partials=True)(s)\n        drz = np.zeros((xl.shape[0]-2,))\n        g = [l-self.targetlabel]\n        rz = (s.gamma()[0, 0, 2] - 0.)\n        drz[:nsurfdofs] = s.dgamma_by_dcoeff()[0, 0, 2, :]\n\n        res = np.zeros(xl.shape)\n        res[:-2] = np.sum(r[:, None]*J, axis=0) - lm[-2] * dl - lm[-1] * drz\n        res[-2] = g[0]\n        res[-1] = rz\n        if derivatives == 0:\n            return res\n\n        H = boozer[2]\n\n        d2l = np.zeros((xl.shape[0]-2, xl.shape[0]-2))\n        d2l[:nsurfdofs, :nsurfdofs] = self.label.d2J_by_dsurfacecoefficientsdsurfacecoefficients()\n\n        dres = np.zeros((xl.shape[0], xl.shape[0]))\n        dres[:-2, :-2] = J.T @ J + np.sum(r[:, None, None] * H, axis=0) - lm[-2]*d2l\n        dres[:-2, -2] = -dl\n        dres[:-2, -1] = -drz\n\n        dres[-2, :-2] = dl\n        dres[-1, :-2] = drz\n        return res, dres\n\n    def minimize_boozer_penalty_constraints_LBFGS(self, tol=1e-3, maxiter=1000, constraint_weight=1., iota=0., G=None):\n        r\"\"\"\n        This function tries to find the surface that approximately solves\n\n        .. math::\n            \\text{min}_x ~J(x) + \\frac{1}{2} w_c (l - l_0)^2\n                                 + \\frac{1}{2} w_c (z(\\varphi=0, \\theta=0) - 0)^2\n\n        where :math:`J(x) = \\frac{1}{2}\\mathbf r(x)^T \\mathbf r(x)`, and :math:`\\mathbf r(x)` contains\n        the Boozer residuals at quadrature points :math:`1,\\dots,n`.\n        This is done using LBFGS.\n        \"\"\"\n\n        if not self.need_to_run_code:\n            return self.res\n\n        s = self.surface\n        if G is None:\n            x = np.concatenate((s.get_dofs(), [iota]))\n        else:\n            x = np.concatenate((s.get_dofs(), [iota, G]))\n        fun = lambda x: self.boozer_penalty_constraints(\n            x, derivatives=1, constraint_weight=constraint_weight, optimize_G=G is not None)\n        res = minimize(\n            fun, x, jac=True, method='L-BFGS-B',\n            options={'maxiter': maxiter, 'ftol': tol, 'gtol': tol, 'maxcor': 200})\n\n        resdict = {\n            \"fun\": res.fun, \"gradient\": res.jac, \"iter\": res.nit, \"info\": res, \"success\": res.success, \"G\": None,\n        }\n        if G is None:\n            s.set_dofs(res.x[:-1])\n            iota = res.x[-1]\n        else:\n            s.set_dofs(res.x[:-2])\n            iota = res.x[-2]\n            G = res.x[-1]\n            resdict['G'] = G\n        resdict['s'] = s\n        resdict['iota'] = iota\n\n        self.res = resdict\n        self.need_to_run_code = False\n        return resdict\n\n    def minimize_boozer_penalty_constraints_newton(self, tol=1e-12, maxiter=10, constraint_weight=1., iota=0., G=None, stab=0.):\n        \"\"\"\n        This function does the same as :mod:`minimize_boozer_penalty_constraints_LBFGS`, but instead of LBFGS it uses\n        Newton's method.\n        \"\"\"\n        if not self.need_to_run_code:\n            return self.res\n\n        s = self.surface\n        if G is None:\n            x = np.concatenate((s.get_dofs(), [iota]))\n        else:\n            x = np.concatenate((s.get_dofs(), [iota, G]))\n        i = 0\n\n        val, dval, d2val = self.boozer_penalty_constraints(\n            x, derivatives=2, constraint_weight=constraint_weight, optimize_G=G is not None)\n        norm = np.linalg.norm(dval)\n        while i < maxiter and norm > tol:\n            d2val += stab*np.identity(d2val.shape[0])\n            dx = np.linalg.solve(d2val, dval)\n            if norm < 1e-9:\n                dx += np.linalg.solve(d2val, dval - d2val@dx)\n            x = x - dx\n            val, dval, d2val = self.boozer_penalty_constraints(\n                x, derivatives=2, constraint_weight=constraint_weight, optimize_G=G is not None)\n            norm = np.linalg.norm(dval)\n            i = i+1\n\n        r = self.boozer_penalty_constraints(\n            x, derivatives=0, constraint_weight=constraint_weight, scalarize=False, optimize_G=G is not None)\n        res = {\n            \"residual\": r, \"jacobian\": dval, \"hessian\": d2val, \"iter\": i, \"success\": norm <= tol, \"G\": None,\n        }\n        if G is None:\n            s.set_dofs(x[:-1])\n            iota = x[-1]\n        else:\n            s.set_dofs(x[:-2])\n            iota = x[-2]\n            G = x[-1]\n            res['G'] = G\n        res['s'] = s\n        res['iota'] = iota\n\n        self.res = res\n        self.need_to_run_code = False\n        return res\n\n    def minimize_boozer_penalty_constraints_ls(self, tol=1e-12, maxiter=10, constraint_weight=1., iota=0., G=None, method='lm'):\n        \"\"\"\n        This function does the same as :mod:`minimize_boozer_penalty_constraints_LBFGS`, but instead of LBFGS it\n        uses a nonlinear least squares algorithm when ``method='lm'``.  Options for the method \n        are the same as for :mod:`scipy.optimize.least_squares`. If ``method='manual'``, then a \n        damped Gauss-Newton method is used.\n        \"\"\"\n\n        if not self.need_to_run_code:\n            return self.res\n\n        s = self.surface\n        if G is None:\n            x = np.concatenate((s.get_dofs(), [iota]))\n        else:\n            x = np.concatenate((s.get_dofs(), [iota, G]))\n        norm = 1e10\n        if method == 'manual':\n            i = 0\n            lam = 1.\n            r, J = self.boozer_penalty_constraints(\n                x, derivatives=1, constraint_weight=constraint_weight, scalarize=False, optimize_G=G is not None)\n            b = J.T@r\n            JTJ = J.T@J\n            while i < maxiter and norm > tol:\n                dx = np.linalg.solve(JTJ + lam * np.diag(np.diag(JTJ)), b)\n                x -= dx\n                r, J = self.boozer_penalty_constraints(\n                    x, derivatives=1, constraint_weight=constraint_weight, scalarize=False, optimize_G=G is not None)\n                b = J.T@r\n                JTJ = J.T@J\n                norm = np.linalg.norm(b)\n                lam *= 1/3\n                i += 1\n            resdict = {\n                \"residual\": r, \"gradient\": b, \"jacobian\": JTJ, \"success\": norm <= tol\n            }\n            if G is None:\n                s.set_dofs(x[:-1])\n                iota = x[-1]\n            else:\n                s.set_dofs(x[:-2])\n                iota = x[-2]\n                G = x[-1]\n                resdict['G'] = G\n            resdict['s'] = s\n            resdict['iota'] = iota\n            return resdict\n        fun = lambda x: self.boozer_penalty_constraints(\n            x, derivatives=0, constraint_weight=constraint_weight, scalarize=False, optimize_G=G is not None)\n        jac = lambda x: self.boozer_penalty_constraints(\n            x, derivatives=1, constraint_weight=constraint_weight, scalarize=False, optimize_G=G is not None)[1]\n        res = least_squares(fun, x, jac=jac, method=method, ftol=tol, xtol=tol, gtol=tol, x_scale=1.0, max_nfev=maxiter)\n        resdict = {\n            \"info\": res, \"residual\": res.fun, \"gradient\": res.grad, \"jacobian\": res.jac, \"success\": res.status > 0,\n            \"G\": None,\n        }\n        if G is None:\n            s.set_dofs(res.x[:-1])\n            iota = res.x[-1]\n        else:\n            s.set_dofs(res.x[:-2])\n            iota = res.x[-2]\n            G = res.x[-1]\n            resdict['G'] = G\n        resdict['s'] = s\n        resdict['iota'] = iota\n\n        self.res = resdict\n        self.need_to_run_code = False\n        return resdict\n\n    def minimize_boozer_exact_constraints_newton(self, tol=1e-12, maxiter=10, iota=0., G=None, lm=[0., 0.]):\n        r\"\"\"\n        This function solves the constrained optimization problem\n\n        .. math::\n            \\text{min}_x ~ J(x)\n\n        subject to\n\n        .. math::\n            l - l_0 &= 0 \\\\\n            z(\\varphi=0,\\theta=0) - 0 &= 0\n\n        using Lagrange multipliers and Newton's method. In the above,\n        :math:`J(x) = \\frac{1}{2}\\mathbf r(x)^T \\mathbf r(x)`, and :math:`\\mathbf r(x)` contains\n        the Boozer residuals at quadrature points :math:`1,\\dots,n`.\n\n        The final constraint is not necessary for stellarator symmetric surfaces as it is automatically\n        satisfied by the stellarator symmetric surface parametrization.\n        \"\"\"\n\n        if not self.need_to_run_code:\n            return self.res\n\n        s = self.surface\n        if G is not None:\n            xl = np.concatenate((s.get_dofs(), [iota, G], lm))\n        else:\n            xl = np.concatenate((s.get_dofs(), [iota], lm))\n        val, dval = self.boozer_exact_constraints(xl, derivatives=1, optimize_G=G is not None)\n        norm = np.linalg.norm(val)\n        i = 0\n        while i < maxiter and norm > tol:\n            if s.stellsym:\n                A = dval[:-1, :-1]\n                b = val[:-1]\n                dx = np.linalg.solve(A, b)\n                if norm < 1e-9:  # iterative refinement for higher accuracy. TODO: cache LU factorisation\n                    dx += np.linalg.solve(A, b-A@dx)\n                xl[:-1] = xl[:-1] - dx\n            else:\n                dx = np.linalg.solve(dval, val)\n                if norm < 1e-9:  # iterative refinement for higher accuracy. TODO: cache LU factorisation\n                    dx += np.linalg.solve(dval, val-dval@dx)\n                xl = xl - dx\n            val, dval = self.boozer_exact_constraints(xl, derivatives=1, optimize_G=G is not None)\n            norm = np.linalg.norm(val)\n            i = i + 1\n\n        if s.stellsym:\n            lm = xl[-2]\n        else:\n            lm = xl[-2:]\n\n        res = {\n            \"residual\": val, \"jacobian\": dval, \"iter\": i, \"success\": norm <= tol, \"lm\": lm, \"G\": None,\n        }\n        if G is not None:\n            s.set_dofs(xl[:-4])\n            iota = xl[-4]\n            G = xl[-3]\n            res['G'] = G\n        else:\n            s.set_dofs(xl[:-3])\n            iota = xl[-3]\n        res['s'] = s\n        res['iota'] = iota\n\n        self.res = res\n        self.need_to_run_code = False\n        return res\n\n    def solve_residual_equation_exactly_newton(self, tol=1e-10, maxiter=10, iota=0., G=None):\n        \"\"\"\n        This function solves the Boozer Surface residual equation exactly.  For\n        this to work, we need the right balance of quadrature points, degrees\n        of freedom and constraints.  For this reason, this only works for\n        surfaces of type SurfaceXYZTensorFourier right now.\n\n        Given ntor, mpol, nfp and stellsym, the surface is expected to be\n        created in the following way::\n\n            phis = np.linspace(0, 1/nfp, 2*ntor+1, endpoint=False)\n            thetas = np.linspace(0, 1, 2*mpol+1, endpoint=False)\n            s = SurfaceXYZTensorFourier(\n                mpol=mpol, ntor=ntor, stellsym=stellsym, nfp=nfp,\n                quadpoints_phi=phis, quadpoints_theta=thetas)\n\n        Or the following two are also possible in the stellsym case::\n\n            phis = np.linspace(0, 1/nfp, 2*ntor+1, endpoint=False)\n            thetas = np.linspace(0, 0.5, mpol+1, endpoint=False)\n\n        or::\n\n            phis = np.linspace(0, 1/(2*nfp), ntor+1, endpoint=False)\n            thetas = np.linspace(0, 1, 2*mpol+1, endpoint=False)\n\n        and then::\n\n            s = SurfaceXYZTensorFourier(\n                mpol=mpol, ntor=ntor, stellsym=stellsym, nfp=nfp,\n                quadpoints_phi=phis, quadpoints_theta=thetas)\n\n        For the stellsym case, there is some redundancy between dofs.  This is\n        taken care of inside this function.\n\n        In the non-stellarator-symmetric case, the surface has\n        ``(2*ntor+1)*(2*mpol+1)`` many quadrature points and\n        ``3*(2*ntor+1)*(2*mpol+1)`` many dofs.\n\n        Equations:\n            - Boozer residual in x, y, and z at all quadrature points\n            - z(0, 0) = 0\n            - label constraint (e.g. volume or flux)\n\n        Unknowns:\n            - Surface dofs\n            - iota\n            - G\n\n        So we end up having ``3*(2*ntor+1)*(2*mpol+1) + 2`` equations and the\n        same number of unknowns.\n\n        In the stellarator-symmetric case, we have\n        ``D = (ntor+1)*(mpol+1)+ ntor*mpol + 2*(ntor+1)*mpol + 2*ntor*(mpol+1)\n        = 6*ntor*mpol + 3*ntor + 3*mpol + 1``\n        many dofs in the surface. After calling ``surface.get_stellsym_mask()`` we have kicked out\n        ``2*ntor*mpol + ntor + mpol``\n        quadrature points, i.e. we have\n        ``2*ntor*mpol + ntor + mpol + 1``\n        quadrature points remaining. In addition we know that the x coordinate of the\n        residual at phi=0=theta is also always satisfied. In total this\n        leaves us with\n        ``3*(2*ntor*mpol + ntor + mpol) + 2`` equations for the boozer residual, plus\n        1 equation for the label,\n        which is the same as the number of surface dofs + 2 extra unknowns\n        given by iota and G.\n        \"\"\"\n        if not self.need_to_run_code:\n            return self.res\n\n        from simsopt.geo.surfacexyztensorfourier import SurfaceXYZTensorFourier\n        s = self.surface\n        if not isinstance(s, SurfaceXYZTensorFourier):\n            raise RuntimeError('Exact solution of Boozer Surfaces only supported for SurfaceXYZTensorFourier')\n\n        # In the case of stellarator symmetry, some of the information is\n        # redundant, since the coordinates at (-phi, -theta) are the same (up\n        # to sign changes) to those at (phi, theta). In addition, for stellsym\n        # surfaces and stellsym magnetic fields, the residual in the x\n        # component is always satisfied at phi=theta=0, so we ignore that one\n        # too. The mask object below is True for those parts of the residual\n        # that we need to keep, and False for those that we ignore.\n        m = s.get_stellsym_mask()\n        mask = np.concatenate((m[..., None], m[..., None], m[..., None]), axis=2)\n        if s.stellsym:\n            mask[0, 0, 0] = False\n        mask = mask.flatten()\n\n        label = self.label\n        if G is None:\n            G = 2. * np.pi * np.sum(np.abs(self.biotsavart.coil_currents)) * (4 * np.pi * 10**(-7) / (2 * np.pi))\n        x = np.concatenate((s.get_dofs(), [iota, G]))\n        i = 0\n        r, J = boozer_surface_residual(s, iota, G, self.biotsavart, derivatives=1)\n        norm = 1e6\n        while i < maxiter:\n            if s.stellsym:\n                b = np.concatenate((r[mask], [(label.J()-self.targetlabel)]))\n            else:\n                b = np.concatenate((r[mask], [(label.J()-self.targetlabel), s.gamma()[0, 0, 2]]))\n            norm = np.linalg.norm(b)\n            if norm <= tol:\n                break\n            if s.stellsym:\n                J = np.vstack((\n                    J[mask, :],\n                    np.concatenate((label.dJ(partials=True)(s), [0., 0.])),\n                ))\n            else:\n                J = np.vstack((\n                    J[mask, :],\n                    np.concatenate((label.dJ(partials=True)(s), [0., 0.])),\n                    np.concatenate((s.dgamma_by_dcoeff()[0, 0, 2, :], [0., 0.]))\n                ))\n            dx = np.linalg.solve(J, b)\n            dx += np.linalg.solve(J, b-J@dx)\n            x -= dx\n            s.set_dofs(x[:-2])\n            iota = x[-2]\n            G = x[-1]\n            i += 1\n            r, J = boozer_surface_residual(s, iota, G, self.biotsavart, derivatives=1)\n\n        if s.stellsym:\n            J = np.vstack((\n                J[mask, :],\n                np.concatenate((label.dJ(partials=True)(s), [0., 0.])),\n            ))\n        else:\n            J = np.vstack((\n                J[mask, :],\n                np.concatenate((label.dJ(partials=True)(s), [0., 0.])),\n                np.concatenate((s.dgamma_by_dcoeff()[0, 0, 2, :], [0., 0.]))\n            ))\n\n        P, L, U = lu(J)\n        res = {\n            \"residual\": r, \"jacobian\": J, \"iter\": i, \"success\": norm <= tol, \"G\": G, \"s\": s, \"iota\": iota, \"PLU\": (P, L, U),\n            \"mask\": mask, 'type': 'exact'\n        }\n        self.res = res\n        self.need_to_run_code = False\n        return res",
  "def __init__(self, biotsavart, surface, label, targetlabel):\n        super().__init__(depends_on=[biotsavart])\n        self.biotsavart = biotsavart\n        self.surface = surface\n        self.label = label\n        self.targetlabel = targetlabel\n        self.need_to_run_code = True",
  "def recompute_bell(self, parent=None):\n        self.need_to_run_code = True",
  "def boozer_penalty_constraints(self, x, derivatives=0, constraint_weight=1., scalarize=True, optimize_G=False):\n        r\"\"\"\n        Define the residual\n\n        .. math::\n            \\mathbf r(x) = [r_1(x),...,r_n(x), \\sqrt{w_c}  (l-l_0), \\sqrt{w_c}  (z(\\varphi=0, \\theta=0) - 0)]\n\n        where :math:`w_c` is the constraint weight, :math:`r_i` are the Boozer residuals \n        at quadrature points :math:`1,\\dots,n`, :math:`l` is the surface label, and :math:`l_0` is\n        the target surface label.\n\n        For ``scalarized=False``, this function returns :math:`\\mathbf r(x)` and optionally the Jacobian \n        of :math:`\\mathbf r(x)`.\n\n        for ``scalarized=True``, this function returns\n\n        .. math::\n            J(x) = \\frac{1}{2}\\mathbf r(x)^T \\mathbf r(x),\n\n        i.e. the least squares residual and optionally the gradient and the Hessian of :math:`J(x)`.\n        \"\"\"\n\n        assert derivatives in [0, 1, 2]\n        if optimize_G:\n            sdofs = x[:-2]\n            iota = x[-2]\n            G = x[-1]\n        else:\n            sdofs = x[:-1]\n            iota = x[-1]\n            G = None\n\n        nsurfdofs = sdofs.size\n        s = self.surface\n        biotsavart = self.biotsavart\n\n        s.set_dofs(sdofs)\n\n        boozer = boozer_surface_residual(s, iota, G, biotsavart, derivatives=derivatives)\n\n        r = boozer[0]\n\n        l = self.label.J()\n        rl = (l-self.targetlabel)\n        rz = (s.gamma()[0, 0, 2] - 0.)\n        r = np.concatenate((r, [\n            np.sqrt(constraint_weight) * rl,\n            np.sqrt(constraint_weight) * rz\n        ]))\n\n        val = 0.5 * np.sum(r**2)\n        if derivatives == 0:\n            if scalarize:\n                return val\n            else:\n                return r\n\n        J = boozer[1]\n\n        dl = np.zeros(x.shape)\n        drz = np.zeros(x.shape)\n\n        dl[:nsurfdofs] = self.label.dJ(partials=True)(s)\n\n        drz[:nsurfdofs] = s.dgamma_by_dcoeff()[0, 0, 2, :]\n        J = np.concatenate((\n            J,\n            np.sqrt(constraint_weight) * dl[None, :],\n            np.sqrt(constraint_weight) * drz[None, :]), axis=0)\n        dval = np.sum(r[:, None]*J, axis=0)\n        if derivatives == 1:\n            if scalarize:\n                return val, dval\n            else:\n                return r, J\n        if not scalarize:\n            raise NotImplementedError('Can only return Hessian for scalarized version.')\n\n        H = boozer[2]\n\n        d2l = np.zeros((x.shape[0], x.shape[0]))\n        d2l[:nsurfdofs, :nsurfdofs] = self.label.d2J_by_dsurfacecoefficientsdsurfacecoefficients()\n\n        H = np.concatenate((\n            H,\n            np.sqrt(constraint_weight) * d2l[None, :, :],\n            np.zeros(d2l[None, :, :].shape)), axis=0)\n        d2val = J.T @ J + np.sum(r[:, None, None] * H, axis=0)\n        return val, dval, d2val",
  "def boozer_exact_constraints(self, xl, derivatives=0, optimize_G=True):\n        r\"\"\"\n        This function returns the optimality conditions corresponding to the minimization problem\n\n        .. math::\n            \\text{min}_x ~J(x)\n\n        subject to \n\n        .. math::\n            l - l_0 &= 0 \\\\\n            z(\\varphi=0,\\theta=0) - 0 &= 0\n\n        where :math:`l` is the surface label and :math:`l_0` is the target surface label, \n        :math:`J(x) = \\frac{1}{2}\\mathbf r(x)^T \\mathbf r(x)`, and :math:`\\mathbf r(x)` contains\n        the Boozer residuals at quadrature points :math:`1,\\dots,n`.\n        We can also optionally return the first derivatives of these optimality conditions.\n        \"\"\"\n        assert derivatives in [0, 1]\n        if optimize_G:\n            sdofs = xl[:-4]\n            iota = xl[-4]\n            G = xl[-3]\n        else:\n            sdofs = xl[:-3]\n            iota = xl[-3]\n            G = None\n        lm = xl[-2:]\n        s = self.surface\n        biotsavart = self.biotsavart\n        s.set_dofs(sdofs)\n        nsurfdofs = sdofs.size\n\n        boozer = boozer_surface_residual(s, iota, G, biotsavart, derivatives=derivatives+1)\n        r, J = boozer[0:2]\n\n        dl = np.zeros((xl.shape[0]-2,))\n\n        l = self.label.J()\n        dl[:nsurfdofs] = self.label.dJ(partials=True)(s)\n        drz = np.zeros((xl.shape[0]-2,))\n        g = [l-self.targetlabel]\n        rz = (s.gamma()[0, 0, 2] - 0.)\n        drz[:nsurfdofs] = s.dgamma_by_dcoeff()[0, 0, 2, :]\n\n        res = np.zeros(xl.shape)\n        res[:-2] = np.sum(r[:, None]*J, axis=0) - lm[-2] * dl - lm[-1] * drz\n        res[-2] = g[0]\n        res[-1] = rz\n        if derivatives == 0:\n            return res\n\n        H = boozer[2]\n\n        d2l = np.zeros((xl.shape[0]-2, xl.shape[0]-2))\n        d2l[:nsurfdofs, :nsurfdofs] = self.label.d2J_by_dsurfacecoefficientsdsurfacecoefficients()\n\n        dres = np.zeros((xl.shape[0], xl.shape[0]))\n        dres[:-2, :-2] = J.T @ J + np.sum(r[:, None, None] * H, axis=0) - lm[-2]*d2l\n        dres[:-2, -2] = -dl\n        dres[:-2, -1] = -drz\n\n        dres[-2, :-2] = dl\n        dres[-1, :-2] = drz\n        return res, dres",
  "def minimize_boozer_penalty_constraints_LBFGS(self, tol=1e-3, maxiter=1000, constraint_weight=1., iota=0., G=None):\n        r\"\"\"\n        This function tries to find the surface that approximately solves\n\n        .. math::\n            \\text{min}_x ~J(x) + \\frac{1}{2} w_c (l - l_0)^2\n                                 + \\frac{1}{2} w_c (z(\\varphi=0, \\theta=0) - 0)^2\n\n        where :math:`J(x) = \\frac{1}{2}\\mathbf r(x)^T \\mathbf r(x)`, and :math:`\\mathbf r(x)` contains\n        the Boozer residuals at quadrature points :math:`1,\\dots,n`.\n        This is done using LBFGS.\n        \"\"\"\n\n        if not self.need_to_run_code:\n            return self.res\n\n        s = self.surface\n        if G is None:\n            x = np.concatenate((s.get_dofs(), [iota]))\n        else:\n            x = np.concatenate((s.get_dofs(), [iota, G]))\n        fun = lambda x: self.boozer_penalty_constraints(\n            x, derivatives=1, constraint_weight=constraint_weight, optimize_G=G is not None)\n        res = minimize(\n            fun, x, jac=True, method='L-BFGS-B',\n            options={'maxiter': maxiter, 'ftol': tol, 'gtol': tol, 'maxcor': 200})\n\n        resdict = {\n            \"fun\": res.fun, \"gradient\": res.jac, \"iter\": res.nit, \"info\": res, \"success\": res.success, \"G\": None,\n        }\n        if G is None:\n            s.set_dofs(res.x[:-1])\n            iota = res.x[-1]\n        else:\n            s.set_dofs(res.x[:-2])\n            iota = res.x[-2]\n            G = res.x[-1]\n            resdict['G'] = G\n        resdict['s'] = s\n        resdict['iota'] = iota\n\n        self.res = resdict\n        self.need_to_run_code = False\n        return resdict",
  "def minimize_boozer_penalty_constraints_newton(self, tol=1e-12, maxiter=10, constraint_weight=1., iota=0., G=None, stab=0.):\n        \"\"\"\n        This function does the same as :mod:`minimize_boozer_penalty_constraints_LBFGS`, but instead of LBFGS it uses\n        Newton's method.\n        \"\"\"\n        if not self.need_to_run_code:\n            return self.res\n\n        s = self.surface\n        if G is None:\n            x = np.concatenate((s.get_dofs(), [iota]))\n        else:\n            x = np.concatenate((s.get_dofs(), [iota, G]))\n        i = 0\n\n        val, dval, d2val = self.boozer_penalty_constraints(\n            x, derivatives=2, constraint_weight=constraint_weight, optimize_G=G is not None)\n        norm = np.linalg.norm(dval)\n        while i < maxiter and norm > tol:\n            d2val += stab*np.identity(d2val.shape[0])\n            dx = np.linalg.solve(d2val, dval)\n            if norm < 1e-9:\n                dx += np.linalg.solve(d2val, dval - d2val@dx)\n            x = x - dx\n            val, dval, d2val = self.boozer_penalty_constraints(\n                x, derivatives=2, constraint_weight=constraint_weight, optimize_G=G is not None)\n            norm = np.linalg.norm(dval)\n            i = i+1\n\n        r = self.boozer_penalty_constraints(\n            x, derivatives=0, constraint_weight=constraint_weight, scalarize=False, optimize_G=G is not None)\n        res = {\n            \"residual\": r, \"jacobian\": dval, \"hessian\": d2val, \"iter\": i, \"success\": norm <= tol, \"G\": None,\n        }\n        if G is None:\n            s.set_dofs(x[:-1])\n            iota = x[-1]\n        else:\n            s.set_dofs(x[:-2])\n            iota = x[-2]\n            G = x[-1]\n            res['G'] = G\n        res['s'] = s\n        res['iota'] = iota\n\n        self.res = res\n        self.need_to_run_code = False\n        return res",
  "def minimize_boozer_penalty_constraints_ls(self, tol=1e-12, maxiter=10, constraint_weight=1., iota=0., G=None, method='lm'):\n        \"\"\"\n        This function does the same as :mod:`minimize_boozer_penalty_constraints_LBFGS`, but instead of LBFGS it\n        uses a nonlinear least squares algorithm when ``method='lm'``.  Options for the method \n        are the same as for :mod:`scipy.optimize.least_squares`. If ``method='manual'``, then a \n        damped Gauss-Newton method is used.\n        \"\"\"\n\n        if not self.need_to_run_code:\n            return self.res\n\n        s = self.surface\n        if G is None:\n            x = np.concatenate((s.get_dofs(), [iota]))\n        else:\n            x = np.concatenate((s.get_dofs(), [iota, G]))\n        norm = 1e10\n        if method == 'manual':\n            i = 0\n            lam = 1.\n            r, J = self.boozer_penalty_constraints(\n                x, derivatives=1, constraint_weight=constraint_weight, scalarize=False, optimize_G=G is not None)\n            b = J.T@r\n            JTJ = J.T@J\n            while i < maxiter and norm > tol:\n                dx = np.linalg.solve(JTJ + lam * np.diag(np.diag(JTJ)), b)\n                x -= dx\n                r, J = self.boozer_penalty_constraints(\n                    x, derivatives=1, constraint_weight=constraint_weight, scalarize=False, optimize_G=G is not None)\n                b = J.T@r\n                JTJ = J.T@J\n                norm = np.linalg.norm(b)\n                lam *= 1/3\n                i += 1\n            resdict = {\n                \"residual\": r, \"gradient\": b, \"jacobian\": JTJ, \"success\": norm <= tol\n            }\n            if G is None:\n                s.set_dofs(x[:-1])\n                iota = x[-1]\n            else:\n                s.set_dofs(x[:-2])\n                iota = x[-2]\n                G = x[-1]\n                resdict['G'] = G\n            resdict['s'] = s\n            resdict['iota'] = iota\n            return resdict\n        fun = lambda x: self.boozer_penalty_constraints(\n            x, derivatives=0, constraint_weight=constraint_weight, scalarize=False, optimize_G=G is not None)\n        jac = lambda x: self.boozer_penalty_constraints(\n            x, derivatives=1, constraint_weight=constraint_weight, scalarize=False, optimize_G=G is not None)[1]\n        res = least_squares(fun, x, jac=jac, method=method, ftol=tol, xtol=tol, gtol=tol, x_scale=1.0, max_nfev=maxiter)\n        resdict = {\n            \"info\": res, \"residual\": res.fun, \"gradient\": res.grad, \"jacobian\": res.jac, \"success\": res.status > 0,\n            \"G\": None,\n        }\n        if G is None:\n            s.set_dofs(res.x[:-1])\n            iota = res.x[-1]\n        else:\n            s.set_dofs(res.x[:-2])\n            iota = res.x[-2]\n            G = res.x[-1]\n            resdict['G'] = G\n        resdict['s'] = s\n        resdict['iota'] = iota\n\n        self.res = resdict\n        self.need_to_run_code = False\n        return resdict",
  "def minimize_boozer_exact_constraints_newton(self, tol=1e-12, maxiter=10, iota=0., G=None, lm=[0., 0.]):\n        r\"\"\"\n        This function solves the constrained optimization problem\n\n        .. math::\n            \\text{min}_x ~ J(x)\n\n        subject to\n\n        .. math::\n            l - l_0 &= 0 \\\\\n            z(\\varphi=0,\\theta=0) - 0 &= 0\n\n        using Lagrange multipliers and Newton's method. In the above,\n        :math:`J(x) = \\frac{1}{2}\\mathbf r(x)^T \\mathbf r(x)`, and :math:`\\mathbf r(x)` contains\n        the Boozer residuals at quadrature points :math:`1,\\dots,n`.\n\n        The final constraint is not necessary for stellarator symmetric surfaces as it is automatically\n        satisfied by the stellarator symmetric surface parametrization.\n        \"\"\"\n\n        if not self.need_to_run_code:\n            return self.res\n\n        s = self.surface\n        if G is not None:\n            xl = np.concatenate((s.get_dofs(), [iota, G], lm))\n        else:\n            xl = np.concatenate((s.get_dofs(), [iota], lm))\n        val, dval = self.boozer_exact_constraints(xl, derivatives=1, optimize_G=G is not None)\n        norm = np.linalg.norm(val)\n        i = 0\n        while i < maxiter and norm > tol:\n            if s.stellsym:\n                A = dval[:-1, :-1]\n                b = val[:-1]\n                dx = np.linalg.solve(A, b)\n                if norm < 1e-9:  # iterative refinement for higher accuracy. TODO: cache LU factorisation\n                    dx += np.linalg.solve(A, b-A@dx)\n                xl[:-1] = xl[:-1] - dx\n            else:\n                dx = np.linalg.solve(dval, val)\n                if norm < 1e-9:  # iterative refinement for higher accuracy. TODO: cache LU factorisation\n                    dx += np.linalg.solve(dval, val-dval@dx)\n                xl = xl - dx\n            val, dval = self.boozer_exact_constraints(xl, derivatives=1, optimize_G=G is not None)\n            norm = np.linalg.norm(val)\n            i = i + 1\n\n        if s.stellsym:\n            lm = xl[-2]\n        else:\n            lm = xl[-2:]\n\n        res = {\n            \"residual\": val, \"jacobian\": dval, \"iter\": i, \"success\": norm <= tol, \"lm\": lm, \"G\": None,\n        }\n        if G is not None:\n            s.set_dofs(xl[:-4])\n            iota = xl[-4]\n            G = xl[-3]\n            res['G'] = G\n        else:\n            s.set_dofs(xl[:-3])\n            iota = xl[-3]\n        res['s'] = s\n        res['iota'] = iota\n\n        self.res = res\n        self.need_to_run_code = False\n        return res",
  "def solve_residual_equation_exactly_newton(self, tol=1e-10, maxiter=10, iota=0., G=None):\n        \"\"\"\n        This function solves the Boozer Surface residual equation exactly.  For\n        this to work, we need the right balance of quadrature points, degrees\n        of freedom and constraints.  For this reason, this only works for\n        surfaces of type SurfaceXYZTensorFourier right now.\n\n        Given ntor, mpol, nfp and stellsym, the surface is expected to be\n        created in the following way::\n\n            phis = np.linspace(0, 1/nfp, 2*ntor+1, endpoint=False)\n            thetas = np.linspace(0, 1, 2*mpol+1, endpoint=False)\n            s = SurfaceXYZTensorFourier(\n                mpol=mpol, ntor=ntor, stellsym=stellsym, nfp=nfp,\n                quadpoints_phi=phis, quadpoints_theta=thetas)\n\n        Or the following two are also possible in the stellsym case::\n\n            phis = np.linspace(0, 1/nfp, 2*ntor+1, endpoint=False)\n            thetas = np.linspace(0, 0.5, mpol+1, endpoint=False)\n\n        or::\n\n            phis = np.linspace(0, 1/(2*nfp), ntor+1, endpoint=False)\n            thetas = np.linspace(0, 1, 2*mpol+1, endpoint=False)\n\n        and then::\n\n            s = SurfaceXYZTensorFourier(\n                mpol=mpol, ntor=ntor, stellsym=stellsym, nfp=nfp,\n                quadpoints_phi=phis, quadpoints_theta=thetas)\n\n        For the stellsym case, there is some redundancy between dofs.  This is\n        taken care of inside this function.\n\n        In the non-stellarator-symmetric case, the surface has\n        ``(2*ntor+1)*(2*mpol+1)`` many quadrature points and\n        ``3*(2*ntor+1)*(2*mpol+1)`` many dofs.\n\n        Equations:\n            - Boozer residual in x, y, and z at all quadrature points\n            - z(0, 0) = 0\n            - label constraint (e.g. volume or flux)\n\n        Unknowns:\n            - Surface dofs\n            - iota\n            - G\n\n        So we end up having ``3*(2*ntor+1)*(2*mpol+1) + 2`` equations and the\n        same number of unknowns.\n\n        In the stellarator-symmetric case, we have\n        ``D = (ntor+1)*(mpol+1)+ ntor*mpol + 2*(ntor+1)*mpol + 2*ntor*(mpol+1)\n        = 6*ntor*mpol + 3*ntor + 3*mpol + 1``\n        many dofs in the surface. After calling ``surface.get_stellsym_mask()`` we have kicked out\n        ``2*ntor*mpol + ntor + mpol``\n        quadrature points, i.e. we have\n        ``2*ntor*mpol + ntor + mpol + 1``\n        quadrature points remaining. In addition we know that the x coordinate of the\n        residual at phi=0=theta is also always satisfied. In total this\n        leaves us with\n        ``3*(2*ntor*mpol + ntor + mpol) + 2`` equations for the boozer residual, plus\n        1 equation for the label,\n        which is the same as the number of surface dofs + 2 extra unknowns\n        given by iota and G.\n        \"\"\"\n        if not self.need_to_run_code:\n            return self.res\n\n        from simsopt.geo.surfacexyztensorfourier import SurfaceXYZTensorFourier\n        s = self.surface\n        if not isinstance(s, SurfaceXYZTensorFourier):\n            raise RuntimeError('Exact solution of Boozer Surfaces only supported for SurfaceXYZTensorFourier')\n\n        # In the case of stellarator symmetry, some of the information is\n        # redundant, since the coordinates at (-phi, -theta) are the same (up\n        # to sign changes) to those at (phi, theta). In addition, for stellsym\n        # surfaces and stellsym magnetic fields, the residual in the x\n        # component is always satisfied at phi=theta=0, so we ignore that one\n        # too. The mask object below is True for those parts of the residual\n        # that we need to keep, and False for those that we ignore.\n        m = s.get_stellsym_mask()\n        mask = np.concatenate((m[..., None], m[..., None], m[..., None]), axis=2)\n        if s.stellsym:\n            mask[0, 0, 0] = False\n        mask = mask.flatten()\n\n        label = self.label\n        if G is None:\n            G = 2. * np.pi * np.sum(np.abs(self.biotsavart.coil_currents)) * (4 * np.pi * 10**(-7) / (2 * np.pi))\n        x = np.concatenate((s.get_dofs(), [iota, G]))\n        i = 0\n        r, J = boozer_surface_residual(s, iota, G, self.biotsavart, derivatives=1)\n        norm = 1e6\n        while i < maxiter:\n            if s.stellsym:\n                b = np.concatenate((r[mask], [(label.J()-self.targetlabel)]))\n            else:\n                b = np.concatenate((r[mask], [(label.J()-self.targetlabel), s.gamma()[0, 0, 2]]))\n            norm = np.linalg.norm(b)\n            if norm <= tol:\n                break\n            if s.stellsym:\n                J = np.vstack((\n                    J[mask, :],\n                    np.concatenate((label.dJ(partials=True)(s), [0., 0.])),\n                ))\n            else:\n                J = np.vstack((\n                    J[mask, :],\n                    np.concatenate((label.dJ(partials=True)(s), [0., 0.])),\n                    np.concatenate((s.dgamma_by_dcoeff()[0, 0, 2, :], [0., 0.]))\n                ))\n            dx = np.linalg.solve(J, b)\n            dx += np.linalg.solve(J, b-J@dx)\n            x -= dx\n            s.set_dofs(x[:-2])\n            iota = x[-2]\n            G = x[-1]\n            i += 1\n            r, J = boozer_surface_residual(s, iota, G, self.biotsavart, derivatives=1)\n\n        if s.stellsym:\n            J = np.vstack((\n                J[mask, :],\n                np.concatenate((label.dJ(partials=True)(s), [0., 0.])),\n            ))\n        else:\n            J = np.vstack((\n                J[mask, :],\n                np.concatenate((label.dJ(partials=True)(s), [0., 0.])),\n                np.concatenate((s.dgamma_by_dcoeff()[0, 0, 2, :], [0., 0.]))\n            ))\n\n        P, L, U = lu(J)\n        res = {\n            \"residual\": r, \"jacobian\": J, \"iter\": i, \"success\": norm <= tol, \"G\": G, \"s\": s, \"iota\": iota, \"PLU\": (P, L, U),\n            \"mask\": mask, 'type': 'exact'\n        }\n        self.res = res\n        self.need_to_run_code = False\n        return res",
  "def jit(fun):\n    if parameters['jit']:\n        return jaxjit(fun)\n    else:\n        return fun",
  "class Surface(Optimizable):\n    r\"\"\"\n    ``Surface`` is a base class for various representations of toroidal\n    surfaces in simsopt.\n\n    A ``Surface`` is modelled as a function\n    :math:`\\Gamma:[0, 1] \\times [0, 1] \\to R^3` and is evaluated at\n    quadrature points :math:`\\{\\phi_1, \\ldots, \\phi_{n_\\phi}\\}\\times\\{\\theta_1, \\ldots, \\theta_{n_\\theta}\\}`.\n    \"\"\"\n\n    # Options for the 'range' parameter for setting quadpoints_phi:\n    RANGE_FULL_TORUS = \"full torus\"\n    RANGE_FIELD_PERIOD = \"field period\"\n    RANGE_HALF_PERIOD = \"half period\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n\n    @classmethod\n    def from_nphi_ntheta(cls, nphi=61, ntheta=62, range=\"full torus\", nfp=1,\n                         **kwargs):\n        r\"\"\"\n        Initializes surface classes from the specified number of grid\n        points along toroidal, :math:`\\phi`, and poloidal, :math:`\\theta`,\n        directions. Additional parameters required for surface initialization\n        could be supplied as keyword arguments.\n\n        Args:\n            nphi: Number of grid points :math:`\\phi_j` in the toroidal angle\n              :math:`\\phi`.\n            ntheta: Number of grid points :math:`\\theta_i` in the poloidal angle\n              :math:`\\theta`.\n            range: Toroidal extent of the :math:`\\phi` grid.\n              Set to ``\"full torus\"`` (or equivalently ``SurfaceRZFourier.RANGE_FULL_TORUS``)\n              to generate quadrature points up to 1 (with no point at 1).\n              Set to ``\"field period\"`` (or equivalently ``SurfaceRZFourier.RANGE_FIELD_PERIOD``)\n              to generate points up to :math:`1/n_{fp}` (with no point at :math:`1/n_{fp}`).\n              Set to ``\"half period\"`` (or equivalently ``SurfaceRZFourier.RANGE_HALF_PERIOD``)\n              to generate points up to :math:`1/(2 n_{fp})`, with all grid points shifted by half\n              of the grid spacing in order to provide spectral convergence of integrals.\n            nfp: The number of field periods.\n            kwargs: Additional arguments to initialize the surface classes. Look\n              at the docstrings of the specific class you are interested in.\n\n        \"\"\"\n        quadpoints_phi, quadpoints_theta = Surface.get_quadpoints(\n            nphi, ntheta, nfp=nfp, range=range)\n        return cls(quadpoints_phi=quadpoints_phi,\n                   quadpoints_theta=quadpoints_theta, nfp=nfp, **kwargs)\n\n    def get_quadpoints(nphi=None,\n                       ntheta=None,\n                       range=None,\n                       nfp=1):\n        r\"\"\"\n        Sets the theta and phi grid points for Surface subclasses.\n        It is typically called in when constructing Surface subclasses.\n\n        For more information about the arguments ``nphi``, ``ntheta``,\n        ``range``, ``quadpoints_phi``, and ``quadpoints_theta``, see the\n        general documentation on :ref:`surfaces`.\n\n        Args:\n            nfp: The number of field periods.\n            nphi: Number of grid points :math:`\\phi_j` in the toroidal angle :math:`\\phi`.\n            ntheta: Number of grid points :math:`\\theta_j` in the toroidal angle :math:`\\theta`.\n            range: Toroidal extent of the :math:`\\phi` grid.\n              Set to ``\"full torus\"`` (or equivalently ``Surface.RANGE_FULL_TORUS``)\n              to generate points up to 1 (with no point at 1).\n              Set to ``\"field period\"`` (or equivalently ``Surface.RANGE_FIELD_PERIOD``)\n              to generate points up to :math:`1/n_{fp}` (with no point at :math:`1/n_{fp}`).\n              Set to ``\"half period\"`` (or equivalently ``Surface.RANGE_HALF_PERIOD``)\n              to generate points up to :math:`1/(2 n_{fp})`, with all grid points shifted by half\n              of the grid spacing in order to provide spectral convergence of integrals.\n\n        Returns:\n            Tuple containing\n\n            - **quadpoints_phi**: List of grid points :math:`\\phi_j`.\n            - **quadpoints_theta**: List of grid points :math:`\\theta_j`.\n        \"\"\"\n        return (Surface.get_phi_quadpoints(nphi=nphi, range=range, nfp=nfp),\n                Surface.get_theta_quadpoints(ntheta=ntheta))\n\n    def get_theta_quadpoints(ntheta=None):\n        r\"\"\"\n        Sets the theta grid points for Surface subclasses.\n\n        Args:\n            ntheta: Number of grid points :math:`\\theta_j` in the toroidal angle :math:`\\theta`.\n\n        Returns:\n            List of grid points :math:`\\theta_j`.\n        \"\"\"\n        # Handle theta:\n        if ntheta is None:\n            ntheta = 62\n        return list(np.linspace(0.0, 1.0, ntheta, endpoint=False))\n\n    def get_phi_quadpoints(nphi=None, range=None, nfp=1):\n        r\"\"\"\n        Sets the phi grid points for Surface subclasses.\n\n        Args:\n            nphi: Number of grid points :math:`\\phi_j` in the toroidal angle :math:`\\phi`.\n            range: Toroidal extent of the :math:`\\phi` grid.\n              Set to ``\"full torus\"`` (or equivalently ``Surface.RANGE_FULL_TORUS``)\n              to generate points up to 1 (with no point at 1).\n              Set to ``\"field period\"`` (or equivalently ``Surface.RANGE_FIELD_PERIOD``)\n              to generate points up to :math:`1/n_{fp}` (with no point at :math:`1/n_{fp}`).\n              Set to ``\"half period\"`` (or equivalently ``Surface.RANGE_HALF_PERIOD``)\n              to generate points up to :math:`1/(2 n_{fp})`, with all grid points shifted by half\n              of the grid spacing in order to provide spectral convergence of integrals.\n            nfp: The number of field periods.\n\n        Returns:\n            List of grid points :math:`\\phi_j`.\n        \"\"\"\n\n        if range is None:\n            range = Surface.RANGE_FULL_TORUS\n        assert range in (Surface.RANGE_FULL_TORUS, Surface.RANGE_HALF_PERIOD,\n                         Surface.RANGE_FIELD_PERIOD)\n        if range == Surface.RANGE_FULL_TORUS:\n            div = 1\n        else:\n            div = nfp\n        if range == Surface.RANGE_HALF_PERIOD:\n            end_val = 0.5\n        else:\n            end_val = 1.0\n\n        if nphi is None:\n            nphi = 61\n        quadpoints_phi = np.linspace(0.0, end_val / div, nphi, endpoint=False)\n        # Shift by half of the grid spacing:\n        if range == Surface.RANGE_HALF_PERIOD:\n            dphi = quadpoints_phi[1] - quadpoints_phi[0]\n            quadpoints_phi += 0.5 * dphi\n\n        return list(quadpoints_phi)\n\n    def plot(self, engine=\"matplotlib\", ax=None, show=True, close=False, axis_equal=True,\n             plot_normal=False, plot_derivative=False, wireframe=True, **kwargs):\n        \"\"\"\n        Plot the surface in 3D using matplotlib/mayavi/plotly.\n\n        Args:\n            engine: Selects the graphics engine. Currently supported options are ``\"matplotlib\"`` (default),\n              ``\"mayavi\"``, and ``\"plotly\"``.\n            ax: The figure/axis to be plotted on. This argument is useful when plotting multiple\n              objects on the same axes. If equal to the default ``None``, a new axis will be created.\n            show: Whether to call the ``show()`` function of the graphics engine.\n              Should be set to ``False`` if more objects will be plotted on the same axes.\n            close: Whether to close the seams in the surface where the angles jump back to 0.\n            axis_equal: For matplotlib, whether to adjust the scales of the x, y, and z axes so\n              distances in each direction appear equal.\n            plot_normal: Whether to plot the surface normal vectors. Only implemented for mayavi.\n            plot_derivative: Whether to plot the surface derivatives. Only implemented for mayavi.\n            wireframe: Whether to plot the wireframe in Mayavi.\n            kwargs: Any additional arguments to pass to the plotting function, like ``color='r'``.\n        Note: the ``ax`` and ``show`` parameters can be used to plot more than one surface:\n\n        .. code-block:: python\n\n            ax = surface1.plot(show=False)\n            ax = surface2.plot(ax=ax, show=False)\n            surface3.plot(ax=ax, show=True)\n\n        Returns:\n            An axis which could be passed to a further call to the graphics engine\n            so multiple objects are shown together.\n        \"\"\"\n        gamma = self.gamma()\n\n        if plot_derivative:\n            dg1 = 0.05 * self.gammadash1()\n            dg2 = 0.05 * self.gammadash2()\n        else:\n            # No need to calculate derivatives.\n            dg1 = np.array([[[1.0]]])\n            dg2 = np.array([[[1.0]]])\n\n        if plot_normal:\n            normal = 0.005 * self.normal()\n        else:\n            # No need to calculate the normal\n            normal = np.array([[[1.0]]])\n\n        if close:\n            # Always close in theta:\n            gamma = np.concatenate((gamma, gamma[:, :1, :]), axis=1)\n            dg1 = np.concatenate((dg1, dg1[:, :1, :]), axis=1)\n            dg2 = np.concatenate((dg2, dg2[:, :1, :]), axis=1)\n            normal = np.concatenate((normal, normal[:, :1, :]), axis=1)\n\n            # Only close in phi if range == 'full torus':\n            dphi = self.quadpoints_phi[1] - self.quadpoints_phi[0]\n            if 1 - self.quadpoints_phi[-1] < 1.1 * dphi:\n                gamma = np.concatenate((gamma, gamma[:1, :, :]), axis=0)\n                dg1 = np.concatenate((dg1, dg1[:1, :, :]), axis=0)\n                dg2 = np.concatenate((dg2, dg2[:1, :, :]), axis=0)\n                normal = np.concatenate((normal, normal[:1, :, :]), axis=0)\n\n        if engine == \"matplotlib\":\n            # plot in matplotlib.pyplot\n            import matplotlib.pyplot as plt\n\n            if ax is None or ax.name != \"3d\":\n                fig = plt.figure()\n                ax = fig.add_subplot(111, projection=\"3d\")\n            ax.plot_surface(gamma[:, :, 0], gamma[:, :, 1], gamma[:, :, 2], **kwargs)\n            if axis_equal:\n                fix_matplotlib_3d(ax)\n            if show:\n                plt.show()\n\n        elif engine == \"mayavi\":\n            # plot 3D surface in mayavi.mlab\n            from mayavi import mlab\n\n            mlab.mesh(gamma[:, :, 0], gamma[:, :, 1], gamma[:, :, 2], **kwargs)\n            if wireframe:\n                mlab.mesh(gamma[:, :, 0], gamma[:, :, 1], gamma[:, :, 2], representation='wireframe', color=(0, 0, 0),\n                          opacity=0.5)\n\n            if plot_derivative:\n                mlab.quiver3d(gamma[:, :, 0], gamma[:, :, 1], gamma[:, :, 2], dg1[:, :, 0], dg1[:, :, 1], dg1[:, :, 2])\n                mlab.quiver3d(gamma[:, :, 0], gamma[:, :, 1], gamma[:, :, 2], dg2[:, :, 0], dg2[:, :, 1], dg2[:, :, 2])\n            if plot_normal:\n                mlab.quiver3d(gamma[:, :, 0], gamma[:, :, 1], gamma[:, :, 2], normal[:, :, 0], normal[:, :, 1],\n                              normal[:, :, 2])\n            if show:\n                mlab.show()\n\n        elif engine == \"plotly\":\n            # plot in plotly\n            import plotly.graph_objects as go\n\n            if \"color\" in list(kwargs.keys()):\n                color = kwargs[\"color\"]\n                del kwargs[\"color\"]\n                kwargs[\"colorscale\"] = [[0, color], [1, color]]\n            # for plotly, ax is actually the figure\n            if ax is None:\n                ax = go.Figure()\n            ax.add_trace(go.Surface(x=gamma[:, :, 0], y=gamma[:, :, 1], z=gamma[:, :, 2], **kwargs))\n            ax.update_layout(scene_aspectmode=\"data\")\n            if show:\n                ax.show()\n        else:\n            raise ValueError(\"Invalid engine option! Please use one of {matplotlib, mayavi, plotly}.\")\n        return ax\n\n    @SimsoptRequires(gridToVTK is not None, \"to_vtk method requires pyevtk module\")\n    def to_vtk(self, filename, extra_data=None):\n        \"\"\"\n        Export the surface to a VTK format file, which can be read with\n        Paraview. This function requires the ``pyevtk`` python\n        package, which can be installed using ``pip install pyevtk``.\n\n        Args:\n            filename: Name of the file to write\n            extra_data: An optional data field on the surface, which can be associated with a colormap in Paraview.\n        \"\"\"\n        g = self.gamma()\n        ntor = g.shape[0]\n        npol = g.shape[1]\n        x = self.gamma()[:, :, 0].reshape((1, ntor, npol)).copy()\n        y = self.gamma()[:, :, 1].reshape((1, ntor, npol)).copy()\n        z = self.gamma()[:, :, 2].reshape((1, ntor, npol)).copy()\n        n = self.normal().reshape((1, ntor, npol, 3))\n        dphi = self.gammadash1().reshape((1, ntor, npol, 3))\n        dtheta = self.gammadash2().reshape((1, ntor, npol, 3))\n        contig = np.ascontiguousarray\n        pointData = {\n            \"dphi x dtheta\": (contig(n[..., 0]), contig(n[..., 1]), contig(n[..., 2])),\n            \"dphi\": (contig(dphi[..., 0]), contig(dphi[..., 1]), contig(dphi[..., 2])),\n            \"dtheta\": (contig(dtheta[..., 0]), contig(dtheta[..., 1]), contig(dtheta[..., 2])),\n        }\n        if extra_data is not None:\n            pointData = {**pointData, **extra_data}\n\n        gridToVTK(str(filename), x, y, z, pointData=pointData)\n\n    @abc.abstractmethod\n    def to_RZFourier(self):\n        \"\"\"\n        Return a :obj:`simsopt.geo.surfacerzfourier.SurfaceRZFourier` instance\n        corresponding to the shape of this surface. All subclasses should\n        implement this abstract method.\n        \"\"\"\n        raise NotImplementedError\n\n    def cross_section(self, phi, thetas=None):\n        \"\"\"\n        This function takes in a cylindrical angle :math:`\\phi` and returns the cross\n        section of the surface in that plane evaluated at `thetas`. This is\n        done using the method of bisection.\n        This function takes in a cylindrical angle :math:`\\phi` and returns\n        the cross section of the surface in that plane evaluated at `thetas`.\n        This is done using the method of bisection.\n\n        This function assumes that the surface intersection with the plane is a\n        single curve.\n        \"\"\"\n\n        # phi is assumed to be between [-pi, pi], so if it does not lie on that interval\n        # we shift it by multiples of 2pi until it does\n        phi = phi - np.sign(phi) * np.floor(np.abs(phi) / (2 * np.pi)) * (2. * np.pi)\n        if phi > np.pi:\n            phi = phi - 2. * np.pi\n        if phi < -np.pi:\n            phi = phi + 2. * np.pi\n\n        # varphi are the search intervals on which we look for the cross section in\n        # at constant cylindrical phi\n        # The cross section is sampled at a number of points (theta_resolution) poloidally.\n        varphi = np.asarray([0., 0.5, 1.0])\n\n        if thetas is None:\n            theta = np.asarray(self.quadpoints_theta)\n        elif isinstance(thetas, np.ndarray):\n            theta = thetas\n        elif isinstance(thetas, int):\n            theta = np.linspace(0, 1, thetas, endpoint=False)\n        else:\n            raise NotImplementedError('Need to pass int or 1d np.array to thetas')\n\n        varphigrid, thetagrid = np.meshgrid(varphi, theta)\n        varphigrid = varphigrid.T\n        thetagrid = thetagrid.T\n\n        # sample the surface at the varphi and theta points\n        gamma = np.zeros((varphigrid.shape[0], varphigrid.shape[1], 3))\n        self.gamma_lin(gamma, varphigrid.flatten(), thetagrid.flatten())\n\n        # compute the cylindrical phi coordinate of each sampled point on the surface\n        cyl_phi = np.arctan2(gamma[:, :, 1], gamma[:, :, 0])\n\n        # reorder varphi, theta with respect to increasing cylindrical phi\n        idx = np.argsort(cyl_phi, axis=0)\n        cyl_phi = np.take_along_axis(cyl_phi, idx, axis=0)\n        varphigrid = np.take_along_axis(varphigrid, idx, axis=0)\n\n        # In case the target cylindrical angle \"phi\" lies above the first row or below the last row,\n        # we must concatenate the lower row above the top row and the top row below the lower row.\n        # This is allowable since the data in the matrices are periodic\n        cyl_phi = np.concatenate((cyl_phi[-1, :][None, :] - 2. * np.pi, cyl_phi, cyl_phi[0, :][None, :] + 2. * np.pi),\n                                 axis=0)\n        varphigrid = np.concatenate((varphigrid[-1, :][None, :] - 1., varphigrid, varphigrid[0, :][None, :] + 1.),\n                                    axis=0)\n\n        # ensure that varphi does not have massive jumps.\n        diff = varphigrid[1:] - varphigrid[:-1]\n        pinc = np.abs(diff + 1) < np.abs(diff)\n        minc = np.abs(diff - 1) < np.abs(diff)\n        inc = pinc.astype(int) - minc.astype(int)\n        prefix_sum = np.cumsum(inc, axis=0)\n        varphigrid[1:] = varphigrid[1:] + prefix_sum\n\n        # find the subintervals in varphi on which the desired cross section lies.\n        # if idx_right == 0, then the subinterval must be idx_left = 0 and idx_right = 1\n        idx_right = np.argmax(phi <= cyl_phi, axis=0)\n        idx_right = np.where(idx_right == 0, 1, idx_right)\n        idx_left = idx_right - 1\n\n        varphi_left = varphigrid[idx_left, np.arange(idx_left.size)]\n        varphi_right = varphigrid[idx_right, np.arange(idx_right.size)]\n        cyl_phi_left = cyl_phi[idx_left, np.arange(idx_left.size)]\n        cyl_phi_right = cyl_phi[idx_right, np.arange(idx_right.size)]\n\n        # this function converts varphi to cylindrical phi, ensuring that the returned angle\n        # lies between left_bound and right_bound.\n        def varphi2phi(varphi_in, left_bound, right_bound):\n            gamma = np.zeros((varphi_in.size, 3))\n            self.gamma_lin(gamma, varphi_in, theta)\n            phi = np.arctan2(gamma[:, 1], gamma[:, 0])\n            pinc = (phi < left_bound).astype(int)\n            minc = (phi > right_bound).astype(int)\n            phi = phi + 2. * np.pi * (pinc - minc)\n            return phi\n\n        def bisection(phia, a, phic, c):\n            err = 1.\n            while err > 1e-13:\n                b = (a + c) / 2.\n                phib = varphi2phi(b, phia, phic)\n\n                flag = (phib - phi) * (phic - phi) > 0\n                # if flag is true,  then root lies on interval [a,b)\n                # if flag is false, then root lies on interval [b,c]\n                phia = np.where(flag, phia, phib)\n                phic = np.where(flag, phib, phic)\n                a = np.where(flag, a, b)\n                c = np.where(flag, b, c)\n                err = np.max(np.abs(a - c))\n            b = (a + c) / 2.\n            return b\n\n        # bisect cyl_phi to compute the cross section\n        sol = bisection(cyl_phi_left, varphi_left, cyl_phi_right, varphi_right)\n        cross_section = np.zeros((sol.size, 3))\n        self.gamma_lin(cross_section, sol, theta)\n        return cross_section\n\n    def aspect_ratio(self):\n        r\"\"\"\n        Note: cylindrical coordinates are :math:`(R, \\phi, Z)`, where\n        :math:`\\phi \\in [-\\pi,\\pi)` and the angles that parametrize the\n        surface are :math:`(\\varphi, \\theta) \\in [0,1)^2`\n        For a given surface, this function computes its aspect ratio using\n        the VMEC definition:\n\n        .. math::\n            AR = R_{\\text{major}} / R_{\\text{minor}}\n\n        where\n\n        .. math::\n            R_{\\text{minor}} &= \\sqrt{ \\overline{A} / \\pi } \\\\\n            R_{\\text{major}} &= \\frac{V}{2 \\pi^2  R_{\\text{minor}}^2}\n\n        and :math:`V` is the volume enclosed by the surface, and\n        :math:`\\overline{A}` is the average cross sectional area.\n\n        \"\"\"\n\n        R_minor = self.minor_radius()\n        R_major = np.abs(self.volume()) / (2. * np.pi**2 * R_minor**2)\n        AR = R_major/R_minor\n        return AR\n\n    def daspect_ratio_by_dcoeff(self):\n        \"\"\"\n        Return the derivative of the aspect ratio with respect to the surface coefficients\n        \"\"\"\n\n        R_minor = self.minor_radius()\n        R_major = self.major_radius()\n        dAR_ds = (self.dmajor_radius_by_dcoeff()*R_minor - self.dminor_radius_by_dcoeff() * R_major)/R_minor**2\n        return dAR_ds\n\n    def minor_radius(self):\n        r\"\"\"\n        Return the minor radius of the surface using the formula\n\n        .. math::\n            R_{\\text{minor}} &= \\sqrt{ \\overline{A} / \\pi }\n\n        where :math:`\\overline{A}` is the average cross sectional area.\n\n        \"\"\"\n\n        R_minor = np.sqrt(self.mean_cross_sectional_area() / np.pi)\n        return R_minor\n\n    def dminor_radius_by_dcoeff(self):\n        \"\"\"\n        Return the derivative of the minor radius wrt surface coefficients\n\n        \"\"\"\n\n        return (0.5/np.pi)*self.dmean_cross_sectional_area_by_dcoeff()/np.sqrt(self.mean_cross_sectional_area() / np.pi)\n\n    def major_radius(self):\n        r\"\"\"\n        Return the major radius of the surface using the formula\n\n        .. math::\n            R_{\\text{major}} = \\frac{V}{2 \\pi^2  R_{\\text{minor}}^2}\n\n        where :math:`\\overline{A}` is the average cross sectional area,\n        and :math:`R_{\\text{minor}}` is the minor radius of the surface.\n\n        \"\"\"\n\n        R_minor = self.minor_radius()\n        R_major = np.abs(self.volume()) / (2. * np.pi**2 * R_minor**2)\n        return R_major\n\n    def dmajor_radius_by_dcoeff(self):\n        \"\"\"\n        Return the derivative of the major radius wrt surface coefficients\n        \"\"\"\n\n        mean_area = self.mean_cross_sectional_area()\n        dmean_area_ds = self.dmean_cross_sectional_area_by_dcoeff()\n\n        dR_major_ds = (-self.volume() * dmean_area_ds + self.dvolume_by_dcoeff() * mean_area) / mean_area**2\n        return dR_major_ds * np.sign(self.volume()) / (2. * np.pi)\n\n    def mean_cross_sectional_area(self):\n        r\"\"\"\n        Note: cylindrical coordinates are :math:`(R, \\phi, Z)`, where\n        :math:`\\phi \\in [-\\pi,\\pi)` and the angles that parametrize the\n        surface are :math:`(\\varphi, \\theta) \\in [0,1)^2`.\n        The mean cross sectional area is given by the integral\n\n        .. math::\n            \\overline{A} = \\frac{1}{2\\pi} \\int_{S_{\\phi}} ~dS ~d\\phi\n\n        where :math:`S_\\phi` is the cross section of the surface at the\n        cylindrical angle :math:`\\phi`.\n        Note that :math:`\\int_{S_\\phi} ~dS` can be rewritten as a line integral\n\n        .. math::\n            \\int_{S_\\phi}~dS &= \\int_{S_\\phi} ~dR dZ \\\\\n            &= \\int_{\\partial S_\\phi}  [R,0] \\cdot \\mathbf n/\\|\\mathbf n\\| ~dl \\\\\n            &= \\int^1_{0} R \\frac{\\partial Z}{\\partial \\theta}~d\\theta\n\n        where :math:`\\mathbf n = [n_R, n_Z] = [\\partial Z/\\partial \\theta, -\\partial R/\\partial \\theta]`\n        is the outward pointing normal.\n        Consider the surface in cylindrical coordinates terms of its angles\n        :math:`[R(\\varphi,\\theta), \\phi(\\varphi,\\theta), Z(\\varphi,\\theta)]`.\n        The boundary of the cross section :math:`\\partial S_\\phi` is given\n        by the points :math:`\\theta\\rightarrow[R(\\varphi(\\phi,\\theta),\\theta),\\phi,\n        Z(\\varphi(\\phi,\\theta),\\theta)]` for fixed :math:`\\phi`. The cross\n        sectional area of :math:`S_\\phi` becomes\n\n        .. math::\n            \\int^{1}_{0} R(\\varphi(\\phi,\\theta),\\theta)\n            \\frac{\\partial}{\\partial \\theta}[Z(\\varphi(\\phi,\\theta),\\theta)] ~d\\theta\n\n        Now, substituting this into the formula for the mean cross sectional\n        area, we have\n\n        .. math::\n            \\overline{A} = \\frac{1}{2\\pi}\\int^{\\pi}_{-\\pi}\\int^{1}_{0} R(\\varphi(\\phi,\\theta),\\theta)\n                \\frac{\\partial}{\\partial \\theta}[Z(\\varphi(\\phi,\\theta),\\theta)] ~d\\theta ~d\\phi\n\n        Instead of integrating over cylindrical :math:`\\phi`, let's complete\n        the change of variables and integrate over :math:`\\varphi` using the\n        mapping:\n\n        .. math::\n            [\\phi,\\theta] \\leftarrow [\\text{atan2}(y(\\varphi,\\theta), x(\\varphi,\\theta)), \\theta]\n\n        After the change of variables, the integral becomes:\n\n        .. math::\n            \\overline{A} = \\frac{1}{2\\pi}\\int^{1}_{0}\\int^{1}_{0} R(\\varphi,\\theta) \\left[\\frac{\\partial Z}{\\partial \\varphi}\n            \\frac{\\partial \\varphi}{d \\theta} + \\frac{\\partial Z}{\\partial \\theta} \\right] \\text{det} J ~d\\theta ~d\\varphi\n\n        where :math:`\\text{det}J` is the determinant of the mapping's Jacobian.\n\n        \"\"\"\n\n        xyz = self.gamma()\n        x2y2 = xyz[:, :, 0] ** 2 + xyz[:, :, 1] ** 2\n        dgamma1 = self.gammadash1()\n        dgamma2 = self.gammadash2()\n\n        # compute the average cross sectional area\n        J = np.zeros((xyz.shape[0], xyz.shape[1], 2, 2))\n        J[:, :, 0, 0] = (xyz[:, :, 0] * dgamma1[:, :, 1] - xyz[:, :, 1] * dgamma1[:, :, 0]) / x2y2\n        J[:, :, 0, 1] = (xyz[:, :, 0] * dgamma2[:, :, 1] - xyz[:, :, 1] * dgamma2[:, :, 0]) / x2y2\n        J[:, :, 1, 0] = 0.\n        J[:, :, 1, 1] = 1.\n\n        detJ = np.linalg.det(J)\n        Jinv = np.linalg.inv(J)\n\n        dZ_dtheta = dgamma1[:, :, 2] * Jinv[:, :, 0, 1] + dgamma2[:, :, 2] * Jinv[:, :, 1, 1]\n        mean_cross_sectional_area = np.abs(np.mean(np.sqrt(x2y2) * dZ_dtheta * detJ))/(2 * np.pi)\n        return mean_cross_sectional_area\n\n    def dmean_cross_sectional_area_by_dcoeff(self):\n        \"\"\"\n        Return the derivative of the mean cross sectional area wrt surface coefficients\n        \"\"\"\n\n        g = self.gamma()\n        g1 = self.gammadash1()\n        g2 = self.gammadash2()\n\n        dg_ds = self.dgamma_by_dcoeff()\n        dg1_ds = self.dgammadash1_by_dcoeff()\n        dg2_ds = self.dgammadash2_by_dcoeff()\n\n        x = g[:, :, 0, None]\n        y = g[:, :, 1, None]\n\n        dx_ds = dg_ds[:, :, 0, :]\n        dy_ds = dg_ds[:, :, 1, :]\n\n        r = np.sqrt(x**2+y**2)\n        dr_ds = (x*dx_ds+y*dy_ds)/r\n\n        xvarphi = g1[:, :, 0, None]\n        yvarphi = g1[:, :, 1, None]\n        zvarphi = g1[:, :, 2, None]\n\n        xtheta = g2[:, :, 0, None]\n        ytheta = g2[:, :, 1, None]\n        ztheta = g2[:, :, 2, None]\n\n        dxvarphi_ds = dg1_ds[:, :, 0, :]\n        dyvarphi_ds = dg1_ds[:, :, 1, :]\n        dzvarphi_ds = dg1_ds[:, :, 2, :]\n\n        dxtheta_ds = dg2_ds[:, :, 0, :]\n        dytheta_ds = dg2_ds[:, :, 1, :]\n        dztheta_ds = dg2_ds[:, :, 2, :]\n\n        mean_area = np.mean((1/r) * (ztheta*(x*yvarphi-y*xvarphi)-zvarphi*(x*ytheta-y*xtheta)))/(2.*np.pi)\n        dmean_area_ds = np.mean((1/(r**2))*((xvarphi * y * ztheta - xtheta * y * zvarphi + x * (-yvarphi * ztheta + ytheta * zvarphi)) * dr_ds + r * (-zvarphi * (ytheta * dx_ds - y * dxtheta_ds - xtheta * dy_ds + x * dytheta_ds) + ztheta * (yvarphi * dx_ds - y * dxvarphi_ds - xvarphi * dy_ds + x * dyvarphi_ds) + (-xvarphi * y + x * yvarphi) * dztheta_ds + (xtheta * y - x * ytheta) * dzvarphi_ds)), axis=(0, 1))\n        return np.sign(mean_area) * dmean_area_ds/(2*np.pi)\n\n    def arclength_poloidal_angle(self):\n        \"\"\"\n        Computes poloidal angle based on arclenth along magnetic surface at\n        constant phi. The resulting angle is in the range [0,1]. This is required\n        for evaluating the adjoint shape gradient for free-boundary calculations.\n\n        Returns:\n            2d array of shape ``(numquadpoints_phi, numquadpoints_theta)``\n            containing the arclength poloidal angle\n        \"\"\"\n        gamma = self.gamma()\n        X = gamma[:, :, 0]\n        Y = gamma[:, :, 1]\n        Z = gamma[:, :, 2]\n        R = np.sqrt(X ** 2 + Y ** 2)\n\n        theta_arclength = np.zeros_like(gamma[:, :, 0])\n        nphi = len(theta_arclength[:, 0])\n        ntheta = len(theta_arclength[0, :])\n        for iphi in range(nphi):\n            for itheta in range(1, ntheta):\n                dr = np.sqrt((R[iphi, itheta] - R[iphi, itheta - 1]) ** 2\n                             + (Z[iphi, itheta] - Z[iphi, itheta - 1]) ** 2)\n                theta_arclength[iphi, itheta] = \\\n                    theta_arclength[iphi, itheta - 1] + dr\n            dr = np.sqrt((R[iphi, 0] - R[iphi, -1]) ** 2\n                         + (Z[iphi, 0] - Z[iphi, -1]) ** 2)\n            L = theta_arclength[iphi, -1] + dr\n            theta_arclength[iphi, :] = theta_arclength[iphi, :] / L\n        return theta_arclength\n\n    def interpolate_on_arclength_grid(self, function, theta_evaluate):\n        \"\"\"\n        Interpolate function onto the theta_evaluate grid in the arclength\n        poloidal angle. This is required for evaluating the adjoint shape gradient\n        for free-boundary calculations.\n\n        Returns:\n            function_interpolated: 2d array (numquadpoints_phi,numquadpoints_theta)\n                defining interpolated function on arclength angle along curve\n                at constant phi\n        \"\"\"\n        from scipy import interpolate\n\n        theta_arclength = self.arclength_poloidal_angle()\n        function_interpolated = np.zeros_like(function)\n        nphi = len(theta_arclength[:, 0])\n        for iphi in range(nphi):\n            f = interpolate.InterpolatedUnivariateSpline(\n                theta_arclength[iphi, :], function[iphi, :])\n            function_interpolated[iphi, :] = f(theta_evaluate[iphi, :])\n\n        return function_interpolated",
  "def signed_distance_from_surface(xyz, surface):\n    \"\"\"\n    Compute the signed distances from points ``xyz`` to a surface.  The sign is\n    positive for points inside the volume surrounded by the surface.\n    \"\"\"\n    gammas = surface.gamma().reshape((-1, 3))\n    from scipy.spatial import KDTree\n    tree = KDTree(gammas)\n    _, mins = tree.query(xyz, k=1)  # find closest points on the surface\n\n    n = surface.unitnormal().reshape((-1, 3))\n    nmins = n[mins]\n    gammamins = gammas[mins]\n\n    # Now that we have found the closest node, we approximate the surface with\n    # a plane through that node with the appropriate normal and then compute\n    # the distance from the point to that plane\n    # https://stackoverflow.com/questions/55189333/how-to-get-distance-from-point-to-plane-in-3d\n    mindist = np.sum((xyz-gammamins) * nmins, axis=1)\n\n    a_point_in_the_surface = np.mean(surface.gamma()[0, :, :], axis=0)\n    sign_of_interiorpoint = np.sign(np.sum((a_point_in_the_surface-gammas[0, :])*n[0, :]))\n\n    signed_dists = mindist * sign_of_interiorpoint\n    return signed_dists",
  "class SurfaceClassifier():\n    r\"\"\"\n    Takes in a toroidal surface and constructs an interpolant of the signed distance function\n    :math:`f:R^3\\to R` that is positive inside the volume contained by the surface,\n    (approximately) zero on the surface, and negative outisde the volume contained by the surface.\n    \"\"\"\n\n    def __init__(self, surface, p=1, h=0.05):\n        \"\"\"\n        Args:\n            surface: the surface to contruct the distance from.\n            p: degree of the interpolant\n            h: grid resolution of the interpolant\n        \"\"\"\n        gammas = surface.gamma()\n        r = np.linalg.norm(gammas[:, :, :2], axis=2)\n        z = gammas[:, :, 2]\n        rmin = max(np.min(r) - 0.1, 0.)\n        rmax = np.max(r) + 0.1\n        zmin = np.min(z) - 0.1\n        zmax = np.max(z) + 0.1\n\n        self.zrange = (zmin, zmax)\n        self.rrange = (rmin, rmax)\n\n        nr = int((self.rrange[1]-self.rrange[0])/h)\n        nphi = int(2*np.pi/h)\n        nz = int((self.zrange[1]-self.zrange[0])/h)\n\n        def fbatch(rs, phis, zs):\n            xyz = np.zeros((len(rs), 3))\n            xyz[:, 0] = rs * np.cos(phis)\n            xyz[:, 1] = rs * np.sin(phis)\n            xyz[:, 2] = zs\n            return list(signed_distance_from_surface(xyz, surface))\n\n        rule = sopp.UniformInterpolationRule(p)\n        self.dist = sopp.RegularGridInterpolant3D(\n            rule, [rmin, rmax, nr], [0., 2*np.pi, nphi], [zmin, zmax, nz], 1, True)\n        self.dist.interpolate_batch(fbatch)\n\n    def evaluate_xyz(self, xyz):\n        rphiz = np.zeros_like(xyz)\n        rphiz[:, 0] = np.linalg.norm(xyz[:, :2], axis=1)\n        rphiz[:, 1] = np.mod(np.arctan2(xyz[:, 1], xyz[:, 0]), 2*np.pi)\n        rphiz[:, 2] = xyz[:, 2]\n        # initialize to -1 since the regular grid interpolant will just keep\n        # that value when evaluated outside of bounds\n        d = -np.ones((xyz.shape[0], 1))\n        self.dist.evaluate_batch(rphiz, d)\n        return d\n\n    def evaluate_rphiz(self, rphiz):\n        # initialize to -1 since the regular grid interpolant will just keep\n        # that value when evaluated outside of bounds\n        d = -np.ones((rphiz.shape[0], 1))\n        self.dist.evaluate_batch(rphiz, d)\n        return d\n\n    @SimsoptRequires(gridToVTK is not None,\n                     \"to_vtk method requires pyevtk module\")\n    def to_vtk(self, filename, h=0.01):\n\n        nr = int((self.rrange[1]-self.rrange[0])/h)\n        nphi = int(2*np.pi/h)\n        nz = int((self.zrange[1]-self.zrange[0])/h)\n        rs = np.linspace(self.rrange[0], self.rrange[1], nr)\n        phis = np.linspace(0, 2*np.pi, nphi)\n        zs = np.linspace(self.zrange[0], self.zrange[1], nz)\n\n        R, Phi, Z = np.meshgrid(rs, phis, zs)\n        X = R * np.cos(Phi)\n        Y = R * np.sin(Phi)\n        Z = Z\n\n        RPhiZ = np.zeros((R.size, 3))\n        RPhiZ[:, 0] = R.flatten()\n        RPhiZ[:, 1] = Phi.flatten()\n        RPhiZ[:, 2] = Z.flatten()\n        vals = -np.ones((R.size, 1))\n        self.dist.evaluate_batch(RPhiZ, vals)\n        vals = vals.reshape(R.shape)\n        gridToVTK(filename, X, Y, Z, pointData={\"levelset\": vals})",
  "class SurfaceScaled(Optimizable):\n    \"\"\"\n    Allows you to take any Surface class and scale the dofs. This is\n    useful for stage-1 optimization.\n    \"\"\"\n\n    def __init__(self, surf, scale_factors):\n        self.surf = surf\n        self.scale_factors = scale_factors\n        super().__init__(x0=surf.x / scale_factors, names=surf.local_dof_names)\n\n    def recompute_bell(self, parent=None):\n        self.surf.local_full_x = self.local_full_x * self.scale_factors\n\n    def to_RZFourier(self):\n        return self.surf.to_RZFourier()\n\n    def update_fixed(self):\n        \"\"\"\n        Copy the fixed status from self.surf to self.\n        \"\"\"\n        for j, is_free in enumerate(self.surf.local_dofs_free_status):\n            if is_free:\n                self.unfix(j)\n            else:\n                self.fix(j)\n\n    def as_dict(self, serial_objs_dict) -> dict:\n        return GSONable.as_dict(self, serial_objs_dict=serial_objs_dict)",
  "def best_nphi_over_ntheta(surf):\n    \"\"\"\n    Given a surface, estimate the ratio of ``nphi / ntheta`` that\n    minimizes the mesh anisotropy. This is useful for improving speed\n    and accuracy of the virtual casing calculation. The result refers\n    to the number of grid points in ``phi`` covering the full torus,\n    not just one field period or half a field period. The input\n    surface need not have ``range==\"full torus\"`` however; any\n    ``range`` will work.\n\n    The result of this function will depend somewhat on the quadrature\n    points of the input surface, but the dependence should be weak.\n\n    Args:\n        surf: A surface object.\n\n    Returns:\n        float with the best ratio ``nphi / ntheta``.\n    \"\"\"\n    gammadash1 = np.linalg.norm(surf.gammadash1(), axis=2)\n    gammadash2 = np.linalg.norm(surf.gammadash2(), axis=2)\n    ratio = gammadash1 / gammadash2\n    return np.sqrt(np.max(ratio) / np.max(1 / ratio))",
  "def __init__(self, **kwargs):\n        super().__init__(**kwargs)",
  "def from_nphi_ntheta(cls, nphi=61, ntheta=62, range=\"full torus\", nfp=1,\n                         **kwargs):\n        r\"\"\"\n        Initializes surface classes from the specified number of grid\n        points along toroidal, :math:`\\phi`, and poloidal, :math:`\\theta`,\n        directions. Additional parameters required for surface initialization\n        could be supplied as keyword arguments.\n\n        Args:\n            nphi: Number of grid points :math:`\\phi_j` in the toroidal angle\n              :math:`\\phi`.\n            ntheta: Number of grid points :math:`\\theta_i` in the poloidal angle\n              :math:`\\theta`.\n            range: Toroidal extent of the :math:`\\phi` grid.\n              Set to ``\"full torus\"`` (or equivalently ``SurfaceRZFourier.RANGE_FULL_TORUS``)\n              to generate quadrature points up to 1 (with no point at 1).\n              Set to ``\"field period\"`` (or equivalently ``SurfaceRZFourier.RANGE_FIELD_PERIOD``)\n              to generate points up to :math:`1/n_{fp}` (with no point at :math:`1/n_{fp}`).\n              Set to ``\"half period\"`` (or equivalently ``SurfaceRZFourier.RANGE_HALF_PERIOD``)\n              to generate points up to :math:`1/(2 n_{fp})`, with all grid points shifted by half\n              of the grid spacing in order to provide spectral convergence of integrals.\n            nfp: The number of field periods.\n            kwargs: Additional arguments to initialize the surface classes. Look\n              at the docstrings of the specific class you are interested in.\n\n        \"\"\"\n        quadpoints_phi, quadpoints_theta = Surface.get_quadpoints(\n            nphi, ntheta, nfp=nfp, range=range)\n        return cls(quadpoints_phi=quadpoints_phi,\n                   quadpoints_theta=quadpoints_theta, nfp=nfp, **kwargs)",
  "def get_quadpoints(nphi=None,\n                       ntheta=None,\n                       range=None,\n                       nfp=1):\n        r\"\"\"\n        Sets the theta and phi grid points for Surface subclasses.\n        It is typically called in when constructing Surface subclasses.\n\n        For more information about the arguments ``nphi``, ``ntheta``,\n        ``range``, ``quadpoints_phi``, and ``quadpoints_theta``, see the\n        general documentation on :ref:`surfaces`.\n\n        Args:\n            nfp: The number of field periods.\n            nphi: Number of grid points :math:`\\phi_j` in the toroidal angle :math:`\\phi`.\n            ntheta: Number of grid points :math:`\\theta_j` in the toroidal angle :math:`\\theta`.\n            range: Toroidal extent of the :math:`\\phi` grid.\n              Set to ``\"full torus\"`` (or equivalently ``Surface.RANGE_FULL_TORUS``)\n              to generate points up to 1 (with no point at 1).\n              Set to ``\"field period\"`` (or equivalently ``Surface.RANGE_FIELD_PERIOD``)\n              to generate points up to :math:`1/n_{fp}` (with no point at :math:`1/n_{fp}`).\n              Set to ``\"half period\"`` (or equivalently ``Surface.RANGE_HALF_PERIOD``)\n              to generate points up to :math:`1/(2 n_{fp})`, with all grid points shifted by half\n              of the grid spacing in order to provide spectral convergence of integrals.\n\n        Returns:\n            Tuple containing\n\n            - **quadpoints_phi**: List of grid points :math:`\\phi_j`.\n            - **quadpoints_theta**: List of grid points :math:`\\theta_j`.\n        \"\"\"\n        return (Surface.get_phi_quadpoints(nphi=nphi, range=range, nfp=nfp),\n                Surface.get_theta_quadpoints(ntheta=ntheta))",
  "def get_theta_quadpoints(ntheta=None):\n        r\"\"\"\n        Sets the theta grid points for Surface subclasses.\n\n        Args:\n            ntheta: Number of grid points :math:`\\theta_j` in the toroidal angle :math:`\\theta`.\n\n        Returns:\n            List of grid points :math:`\\theta_j`.\n        \"\"\"\n        # Handle theta:\n        if ntheta is None:\n            ntheta = 62\n        return list(np.linspace(0.0, 1.0, ntheta, endpoint=False))",
  "def get_phi_quadpoints(nphi=None, range=None, nfp=1):\n        r\"\"\"\n        Sets the phi grid points for Surface subclasses.\n\n        Args:\n            nphi: Number of grid points :math:`\\phi_j` in the toroidal angle :math:`\\phi`.\n            range: Toroidal extent of the :math:`\\phi` grid.\n              Set to ``\"full torus\"`` (or equivalently ``Surface.RANGE_FULL_TORUS``)\n              to generate points up to 1 (with no point at 1).\n              Set to ``\"field period\"`` (or equivalently ``Surface.RANGE_FIELD_PERIOD``)\n              to generate points up to :math:`1/n_{fp}` (with no point at :math:`1/n_{fp}`).\n              Set to ``\"half period\"`` (or equivalently ``Surface.RANGE_HALF_PERIOD``)\n              to generate points up to :math:`1/(2 n_{fp})`, with all grid points shifted by half\n              of the grid spacing in order to provide spectral convergence of integrals.\n            nfp: The number of field periods.\n\n        Returns:\n            List of grid points :math:`\\phi_j`.\n        \"\"\"\n\n        if range is None:\n            range = Surface.RANGE_FULL_TORUS\n        assert range in (Surface.RANGE_FULL_TORUS, Surface.RANGE_HALF_PERIOD,\n                         Surface.RANGE_FIELD_PERIOD)\n        if range == Surface.RANGE_FULL_TORUS:\n            div = 1\n        else:\n            div = nfp\n        if range == Surface.RANGE_HALF_PERIOD:\n            end_val = 0.5\n        else:\n            end_val = 1.0\n\n        if nphi is None:\n            nphi = 61\n        quadpoints_phi = np.linspace(0.0, end_val / div, nphi, endpoint=False)\n        # Shift by half of the grid spacing:\n        if range == Surface.RANGE_HALF_PERIOD:\n            dphi = quadpoints_phi[1] - quadpoints_phi[0]\n            quadpoints_phi += 0.5 * dphi\n\n        return list(quadpoints_phi)",
  "def plot(self, engine=\"matplotlib\", ax=None, show=True, close=False, axis_equal=True,\n             plot_normal=False, plot_derivative=False, wireframe=True, **kwargs):\n        \"\"\"\n        Plot the surface in 3D using matplotlib/mayavi/plotly.\n\n        Args:\n            engine: Selects the graphics engine. Currently supported options are ``\"matplotlib\"`` (default),\n              ``\"mayavi\"``, and ``\"plotly\"``.\n            ax: The figure/axis to be plotted on. This argument is useful when plotting multiple\n              objects on the same axes. If equal to the default ``None``, a new axis will be created.\n            show: Whether to call the ``show()`` function of the graphics engine.\n              Should be set to ``False`` if more objects will be plotted on the same axes.\n            close: Whether to close the seams in the surface where the angles jump back to 0.\n            axis_equal: For matplotlib, whether to adjust the scales of the x, y, and z axes so\n              distances in each direction appear equal.\n            plot_normal: Whether to plot the surface normal vectors. Only implemented for mayavi.\n            plot_derivative: Whether to plot the surface derivatives. Only implemented for mayavi.\n            wireframe: Whether to plot the wireframe in Mayavi.\n            kwargs: Any additional arguments to pass to the plotting function, like ``color='r'``.\n        Note: the ``ax`` and ``show`` parameters can be used to plot more than one surface:\n\n        .. code-block:: python\n\n            ax = surface1.plot(show=False)\n            ax = surface2.plot(ax=ax, show=False)\n            surface3.plot(ax=ax, show=True)\n\n        Returns:\n            An axis which could be passed to a further call to the graphics engine\n            so multiple objects are shown together.\n        \"\"\"\n        gamma = self.gamma()\n\n        if plot_derivative:\n            dg1 = 0.05 * self.gammadash1()\n            dg2 = 0.05 * self.gammadash2()\n        else:\n            # No need to calculate derivatives.\n            dg1 = np.array([[[1.0]]])\n            dg2 = np.array([[[1.0]]])\n\n        if plot_normal:\n            normal = 0.005 * self.normal()\n        else:\n            # No need to calculate the normal\n            normal = np.array([[[1.0]]])\n\n        if close:\n            # Always close in theta:\n            gamma = np.concatenate((gamma, gamma[:, :1, :]), axis=1)\n            dg1 = np.concatenate((dg1, dg1[:, :1, :]), axis=1)\n            dg2 = np.concatenate((dg2, dg2[:, :1, :]), axis=1)\n            normal = np.concatenate((normal, normal[:, :1, :]), axis=1)\n\n            # Only close in phi if range == 'full torus':\n            dphi = self.quadpoints_phi[1] - self.quadpoints_phi[0]\n            if 1 - self.quadpoints_phi[-1] < 1.1 * dphi:\n                gamma = np.concatenate((gamma, gamma[:1, :, :]), axis=0)\n                dg1 = np.concatenate((dg1, dg1[:1, :, :]), axis=0)\n                dg2 = np.concatenate((dg2, dg2[:1, :, :]), axis=0)\n                normal = np.concatenate((normal, normal[:1, :, :]), axis=0)\n\n        if engine == \"matplotlib\":\n            # plot in matplotlib.pyplot\n            import matplotlib.pyplot as plt\n\n            if ax is None or ax.name != \"3d\":\n                fig = plt.figure()\n                ax = fig.add_subplot(111, projection=\"3d\")\n            ax.plot_surface(gamma[:, :, 0], gamma[:, :, 1], gamma[:, :, 2], **kwargs)\n            if axis_equal:\n                fix_matplotlib_3d(ax)\n            if show:\n                plt.show()\n\n        elif engine == \"mayavi\":\n            # plot 3D surface in mayavi.mlab\n            from mayavi import mlab\n\n            mlab.mesh(gamma[:, :, 0], gamma[:, :, 1], gamma[:, :, 2], **kwargs)\n            if wireframe:\n                mlab.mesh(gamma[:, :, 0], gamma[:, :, 1], gamma[:, :, 2], representation='wireframe', color=(0, 0, 0),\n                          opacity=0.5)\n\n            if plot_derivative:\n                mlab.quiver3d(gamma[:, :, 0], gamma[:, :, 1], gamma[:, :, 2], dg1[:, :, 0], dg1[:, :, 1], dg1[:, :, 2])\n                mlab.quiver3d(gamma[:, :, 0], gamma[:, :, 1], gamma[:, :, 2], dg2[:, :, 0], dg2[:, :, 1], dg2[:, :, 2])\n            if plot_normal:\n                mlab.quiver3d(gamma[:, :, 0], gamma[:, :, 1], gamma[:, :, 2], normal[:, :, 0], normal[:, :, 1],\n                              normal[:, :, 2])\n            if show:\n                mlab.show()\n\n        elif engine == \"plotly\":\n            # plot in plotly\n            import plotly.graph_objects as go\n\n            if \"color\" in list(kwargs.keys()):\n                color = kwargs[\"color\"]\n                del kwargs[\"color\"]\n                kwargs[\"colorscale\"] = [[0, color], [1, color]]\n            # for plotly, ax is actually the figure\n            if ax is None:\n                ax = go.Figure()\n            ax.add_trace(go.Surface(x=gamma[:, :, 0], y=gamma[:, :, 1], z=gamma[:, :, 2], **kwargs))\n            ax.update_layout(scene_aspectmode=\"data\")\n            if show:\n                ax.show()\n        else:\n            raise ValueError(\"Invalid engine option! Please use one of {matplotlib, mayavi, plotly}.\")\n        return ax",
  "def to_vtk(self, filename, extra_data=None):\n        \"\"\"\n        Export the surface to a VTK format file, which can be read with\n        Paraview. This function requires the ``pyevtk`` python\n        package, which can be installed using ``pip install pyevtk``.\n\n        Args:\n            filename: Name of the file to write\n            extra_data: An optional data field on the surface, which can be associated with a colormap in Paraview.\n        \"\"\"\n        g = self.gamma()\n        ntor = g.shape[0]\n        npol = g.shape[1]\n        x = self.gamma()[:, :, 0].reshape((1, ntor, npol)).copy()\n        y = self.gamma()[:, :, 1].reshape((1, ntor, npol)).copy()\n        z = self.gamma()[:, :, 2].reshape((1, ntor, npol)).copy()\n        n = self.normal().reshape((1, ntor, npol, 3))\n        dphi = self.gammadash1().reshape((1, ntor, npol, 3))\n        dtheta = self.gammadash2().reshape((1, ntor, npol, 3))\n        contig = np.ascontiguousarray\n        pointData = {\n            \"dphi x dtheta\": (contig(n[..., 0]), contig(n[..., 1]), contig(n[..., 2])),\n            \"dphi\": (contig(dphi[..., 0]), contig(dphi[..., 1]), contig(dphi[..., 2])),\n            \"dtheta\": (contig(dtheta[..., 0]), contig(dtheta[..., 1]), contig(dtheta[..., 2])),\n        }\n        if extra_data is not None:\n            pointData = {**pointData, **extra_data}\n\n        gridToVTK(str(filename), x, y, z, pointData=pointData)",
  "def to_RZFourier(self):\n        \"\"\"\n        Return a :obj:`simsopt.geo.surfacerzfourier.SurfaceRZFourier` instance\n        corresponding to the shape of this surface. All subclasses should\n        implement this abstract method.\n        \"\"\"\n        raise NotImplementedError",
  "def cross_section(self, phi, thetas=None):\n        \"\"\"\n        This function takes in a cylindrical angle :math:`\\phi` and returns the cross\n        section of the surface in that plane evaluated at `thetas`. This is\n        done using the method of bisection.\n        This function takes in a cylindrical angle :math:`\\phi` and returns\n        the cross section of the surface in that plane evaluated at `thetas`.\n        This is done using the method of bisection.\n\n        This function assumes that the surface intersection with the plane is a\n        single curve.\n        \"\"\"\n\n        # phi is assumed to be between [-pi, pi], so if it does not lie on that interval\n        # we shift it by multiples of 2pi until it does\n        phi = phi - np.sign(phi) * np.floor(np.abs(phi) / (2 * np.pi)) * (2. * np.pi)\n        if phi > np.pi:\n            phi = phi - 2. * np.pi\n        if phi < -np.pi:\n            phi = phi + 2. * np.pi\n\n        # varphi are the search intervals on which we look for the cross section in\n        # at constant cylindrical phi\n        # The cross section is sampled at a number of points (theta_resolution) poloidally.\n        varphi = np.asarray([0., 0.5, 1.0])\n\n        if thetas is None:\n            theta = np.asarray(self.quadpoints_theta)\n        elif isinstance(thetas, np.ndarray):\n            theta = thetas\n        elif isinstance(thetas, int):\n            theta = np.linspace(0, 1, thetas, endpoint=False)\n        else:\n            raise NotImplementedError('Need to pass int or 1d np.array to thetas')\n\n        varphigrid, thetagrid = np.meshgrid(varphi, theta)\n        varphigrid = varphigrid.T\n        thetagrid = thetagrid.T\n\n        # sample the surface at the varphi and theta points\n        gamma = np.zeros((varphigrid.shape[0], varphigrid.shape[1], 3))\n        self.gamma_lin(gamma, varphigrid.flatten(), thetagrid.flatten())\n\n        # compute the cylindrical phi coordinate of each sampled point on the surface\n        cyl_phi = np.arctan2(gamma[:, :, 1], gamma[:, :, 0])\n\n        # reorder varphi, theta with respect to increasing cylindrical phi\n        idx = np.argsort(cyl_phi, axis=0)\n        cyl_phi = np.take_along_axis(cyl_phi, idx, axis=0)\n        varphigrid = np.take_along_axis(varphigrid, idx, axis=0)\n\n        # In case the target cylindrical angle \"phi\" lies above the first row or below the last row,\n        # we must concatenate the lower row above the top row and the top row below the lower row.\n        # This is allowable since the data in the matrices are periodic\n        cyl_phi = np.concatenate((cyl_phi[-1, :][None, :] - 2. * np.pi, cyl_phi, cyl_phi[0, :][None, :] + 2. * np.pi),\n                                 axis=0)\n        varphigrid = np.concatenate((varphigrid[-1, :][None, :] - 1., varphigrid, varphigrid[0, :][None, :] + 1.),\n                                    axis=0)\n\n        # ensure that varphi does not have massive jumps.\n        diff = varphigrid[1:] - varphigrid[:-1]\n        pinc = np.abs(diff + 1) < np.abs(diff)\n        minc = np.abs(diff - 1) < np.abs(diff)\n        inc = pinc.astype(int) - minc.astype(int)\n        prefix_sum = np.cumsum(inc, axis=0)\n        varphigrid[1:] = varphigrid[1:] + prefix_sum\n\n        # find the subintervals in varphi on which the desired cross section lies.\n        # if idx_right == 0, then the subinterval must be idx_left = 0 and idx_right = 1\n        idx_right = np.argmax(phi <= cyl_phi, axis=0)\n        idx_right = np.where(idx_right == 0, 1, idx_right)\n        idx_left = idx_right - 1\n\n        varphi_left = varphigrid[idx_left, np.arange(idx_left.size)]\n        varphi_right = varphigrid[idx_right, np.arange(idx_right.size)]\n        cyl_phi_left = cyl_phi[idx_left, np.arange(idx_left.size)]\n        cyl_phi_right = cyl_phi[idx_right, np.arange(idx_right.size)]\n\n        # this function converts varphi to cylindrical phi, ensuring that the returned angle\n        # lies between left_bound and right_bound.\n        def varphi2phi(varphi_in, left_bound, right_bound):\n            gamma = np.zeros((varphi_in.size, 3))\n            self.gamma_lin(gamma, varphi_in, theta)\n            phi = np.arctan2(gamma[:, 1], gamma[:, 0])\n            pinc = (phi < left_bound).astype(int)\n            minc = (phi > right_bound).astype(int)\n            phi = phi + 2. * np.pi * (pinc - minc)\n            return phi\n\n        def bisection(phia, a, phic, c):\n            err = 1.\n            while err > 1e-13:\n                b = (a + c) / 2.\n                phib = varphi2phi(b, phia, phic)\n\n                flag = (phib - phi) * (phic - phi) > 0\n                # if flag is true,  then root lies on interval [a,b)\n                # if flag is false, then root lies on interval [b,c]\n                phia = np.where(flag, phia, phib)\n                phic = np.where(flag, phib, phic)\n                a = np.where(flag, a, b)\n                c = np.where(flag, b, c)\n                err = np.max(np.abs(a - c))\n            b = (a + c) / 2.\n            return b\n\n        # bisect cyl_phi to compute the cross section\n        sol = bisection(cyl_phi_left, varphi_left, cyl_phi_right, varphi_right)\n        cross_section = np.zeros((sol.size, 3))\n        self.gamma_lin(cross_section, sol, theta)\n        return cross_section",
  "def aspect_ratio(self):\n        r\"\"\"\n        Note: cylindrical coordinates are :math:`(R, \\phi, Z)`, where\n        :math:`\\phi \\in [-\\pi,\\pi)` and the angles that parametrize the\n        surface are :math:`(\\varphi, \\theta) \\in [0,1)^2`\n        For a given surface, this function computes its aspect ratio using\n        the VMEC definition:\n\n        .. math::\n            AR = R_{\\text{major}} / R_{\\text{minor}}\n\n        where\n\n        .. math::\n            R_{\\text{minor}} &= \\sqrt{ \\overline{A} / \\pi } \\\\\n            R_{\\text{major}} &= \\frac{V}{2 \\pi^2  R_{\\text{minor}}^2}\n\n        and :math:`V` is the volume enclosed by the surface, and\n        :math:`\\overline{A}` is the average cross sectional area.\n\n        \"\"\"\n\n        R_minor = self.minor_radius()\n        R_major = np.abs(self.volume()) / (2. * np.pi**2 * R_minor**2)\n        AR = R_major/R_minor\n        return AR",
  "def daspect_ratio_by_dcoeff(self):\n        \"\"\"\n        Return the derivative of the aspect ratio with respect to the surface coefficients\n        \"\"\"\n\n        R_minor = self.minor_radius()\n        R_major = self.major_radius()\n        dAR_ds = (self.dmajor_radius_by_dcoeff()*R_minor - self.dminor_radius_by_dcoeff() * R_major)/R_minor**2\n        return dAR_ds",
  "def minor_radius(self):\n        r\"\"\"\n        Return the minor radius of the surface using the formula\n\n        .. math::\n            R_{\\text{minor}} &= \\sqrt{ \\overline{A} / \\pi }\n\n        where :math:`\\overline{A}` is the average cross sectional area.\n\n        \"\"\"\n\n        R_minor = np.sqrt(self.mean_cross_sectional_area() / np.pi)\n        return R_minor",
  "def dminor_radius_by_dcoeff(self):\n        \"\"\"\n        Return the derivative of the minor radius wrt surface coefficients\n\n        \"\"\"\n\n        return (0.5/np.pi)*self.dmean_cross_sectional_area_by_dcoeff()/np.sqrt(self.mean_cross_sectional_area() / np.pi)",
  "def major_radius(self):\n        r\"\"\"\n        Return the major radius of the surface using the formula\n\n        .. math::\n            R_{\\text{major}} = \\frac{V}{2 \\pi^2  R_{\\text{minor}}^2}\n\n        where :math:`\\overline{A}` is the average cross sectional area,\n        and :math:`R_{\\text{minor}}` is the minor radius of the surface.\n\n        \"\"\"\n\n        R_minor = self.minor_radius()\n        R_major = np.abs(self.volume()) / (2. * np.pi**2 * R_minor**2)\n        return R_major",
  "def dmajor_radius_by_dcoeff(self):\n        \"\"\"\n        Return the derivative of the major radius wrt surface coefficients\n        \"\"\"\n\n        mean_area = self.mean_cross_sectional_area()\n        dmean_area_ds = self.dmean_cross_sectional_area_by_dcoeff()\n\n        dR_major_ds = (-self.volume() * dmean_area_ds + self.dvolume_by_dcoeff() * mean_area) / mean_area**2\n        return dR_major_ds * np.sign(self.volume()) / (2. * np.pi)",
  "def mean_cross_sectional_area(self):\n        r\"\"\"\n        Note: cylindrical coordinates are :math:`(R, \\phi, Z)`, where\n        :math:`\\phi \\in [-\\pi,\\pi)` and the angles that parametrize the\n        surface are :math:`(\\varphi, \\theta) \\in [0,1)^2`.\n        The mean cross sectional area is given by the integral\n\n        .. math::\n            \\overline{A} = \\frac{1}{2\\pi} \\int_{S_{\\phi}} ~dS ~d\\phi\n\n        where :math:`S_\\phi` is the cross section of the surface at the\n        cylindrical angle :math:`\\phi`.\n        Note that :math:`\\int_{S_\\phi} ~dS` can be rewritten as a line integral\n\n        .. math::\n            \\int_{S_\\phi}~dS &= \\int_{S_\\phi} ~dR dZ \\\\\n            &= \\int_{\\partial S_\\phi}  [R,0] \\cdot \\mathbf n/\\|\\mathbf n\\| ~dl \\\\\n            &= \\int^1_{0} R \\frac{\\partial Z}{\\partial \\theta}~d\\theta\n\n        where :math:`\\mathbf n = [n_R, n_Z] = [\\partial Z/\\partial \\theta, -\\partial R/\\partial \\theta]`\n        is the outward pointing normal.\n        Consider the surface in cylindrical coordinates terms of its angles\n        :math:`[R(\\varphi,\\theta), \\phi(\\varphi,\\theta), Z(\\varphi,\\theta)]`.\n        The boundary of the cross section :math:`\\partial S_\\phi` is given\n        by the points :math:`\\theta\\rightarrow[R(\\varphi(\\phi,\\theta),\\theta),\\phi,\n        Z(\\varphi(\\phi,\\theta),\\theta)]` for fixed :math:`\\phi`. The cross\n        sectional area of :math:`S_\\phi` becomes\n\n        .. math::\n            \\int^{1}_{0} R(\\varphi(\\phi,\\theta),\\theta)\n            \\frac{\\partial}{\\partial \\theta}[Z(\\varphi(\\phi,\\theta),\\theta)] ~d\\theta\n\n        Now, substituting this into the formula for the mean cross sectional\n        area, we have\n\n        .. math::\n            \\overline{A} = \\frac{1}{2\\pi}\\int^{\\pi}_{-\\pi}\\int^{1}_{0} R(\\varphi(\\phi,\\theta),\\theta)\n                \\frac{\\partial}{\\partial \\theta}[Z(\\varphi(\\phi,\\theta),\\theta)] ~d\\theta ~d\\phi\n\n        Instead of integrating over cylindrical :math:`\\phi`, let's complete\n        the change of variables and integrate over :math:`\\varphi` using the\n        mapping:\n\n        .. math::\n            [\\phi,\\theta] \\leftarrow [\\text{atan2}(y(\\varphi,\\theta), x(\\varphi,\\theta)), \\theta]\n\n        After the change of variables, the integral becomes:\n\n        .. math::\n            \\overline{A} = \\frac{1}{2\\pi}\\int^{1}_{0}\\int^{1}_{0} R(\\varphi,\\theta) \\left[\\frac{\\partial Z}{\\partial \\varphi}\n            \\frac{\\partial \\varphi}{d \\theta} + \\frac{\\partial Z}{\\partial \\theta} \\right] \\text{det} J ~d\\theta ~d\\varphi\n\n        where :math:`\\text{det}J` is the determinant of the mapping's Jacobian.\n\n        \"\"\"\n\n        xyz = self.gamma()\n        x2y2 = xyz[:, :, 0] ** 2 + xyz[:, :, 1] ** 2\n        dgamma1 = self.gammadash1()\n        dgamma2 = self.gammadash2()\n\n        # compute the average cross sectional area\n        J = np.zeros((xyz.shape[0], xyz.shape[1], 2, 2))\n        J[:, :, 0, 0] = (xyz[:, :, 0] * dgamma1[:, :, 1] - xyz[:, :, 1] * dgamma1[:, :, 0]) / x2y2\n        J[:, :, 0, 1] = (xyz[:, :, 0] * dgamma2[:, :, 1] - xyz[:, :, 1] * dgamma2[:, :, 0]) / x2y2\n        J[:, :, 1, 0] = 0.\n        J[:, :, 1, 1] = 1.\n\n        detJ = np.linalg.det(J)\n        Jinv = np.linalg.inv(J)\n\n        dZ_dtheta = dgamma1[:, :, 2] * Jinv[:, :, 0, 1] + dgamma2[:, :, 2] * Jinv[:, :, 1, 1]\n        mean_cross_sectional_area = np.abs(np.mean(np.sqrt(x2y2) * dZ_dtheta * detJ))/(2 * np.pi)\n        return mean_cross_sectional_area",
  "def dmean_cross_sectional_area_by_dcoeff(self):\n        \"\"\"\n        Return the derivative of the mean cross sectional area wrt surface coefficients\n        \"\"\"\n\n        g = self.gamma()\n        g1 = self.gammadash1()\n        g2 = self.gammadash2()\n\n        dg_ds = self.dgamma_by_dcoeff()\n        dg1_ds = self.dgammadash1_by_dcoeff()\n        dg2_ds = self.dgammadash2_by_dcoeff()\n\n        x = g[:, :, 0, None]\n        y = g[:, :, 1, None]\n\n        dx_ds = dg_ds[:, :, 0, :]\n        dy_ds = dg_ds[:, :, 1, :]\n\n        r = np.sqrt(x**2+y**2)\n        dr_ds = (x*dx_ds+y*dy_ds)/r\n\n        xvarphi = g1[:, :, 0, None]\n        yvarphi = g1[:, :, 1, None]\n        zvarphi = g1[:, :, 2, None]\n\n        xtheta = g2[:, :, 0, None]\n        ytheta = g2[:, :, 1, None]\n        ztheta = g2[:, :, 2, None]\n\n        dxvarphi_ds = dg1_ds[:, :, 0, :]\n        dyvarphi_ds = dg1_ds[:, :, 1, :]\n        dzvarphi_ds = dg1_ds[:, :, 2, :]\n\n        dxtheta_ds = dg2_ds[:, :, 0, :]\n        dytheta_ds = dg2_ds[:, :, 1, :]\n        dztheta_ds = dg2_ds[:, :, 2, :]\n\n        mean_area = np.mean((1/r) * (ztheta*(x*yvarphi-y*xvarphi)-zvarphi*(x*ytheta-y*xtheta)))/(2.*np.pi)\n        dmean_area_ds = np.mean((1/(r**2))*((xvarphi * y * ztheta - xtheta * y * zvarphi + x * (-yvarphi * ztheta + ytheta * zvarphi)) * dr_ds + r * (-zvarphi * (ytheta * dx_ds - y * dxtheta_ds - xtheta * dy_ds + x * dytheta_ds) + ztheta * (yvarphi * dx_ds - y * dxvarphi_ds - xvarphi * dy_ds + x * dyvarphi_ds) + (-xvarphi * y + x * yvarphi) * dztheta_ds + (xtheta * y - x * ytheta) * dzvarphi_ds)), axis=(0, 1))\n        return np.sign(mean_area) * dmean_area_ds/(2*np.pi)",
  "def arclength_poloidal_angle(self):\n        \"\"\"\n        Computes poloidal angle based on arclenth along magnetic surface at\n        constant phi. The resulting angle is in the range [0,1]. This is required\n        for evaluating the adjoint shape gradient for free-boundary calculations.\n\n        Returns:\n            2d array of shape ``(numquadpoints_phi, numquadpoints_theta)``\n            containing the arclength poloidal angle\n        \"\"\"\n        gamma = self.gamma()\n        X = gamma[:, :, 0]\n        Y = gamma[:, :, 1]\n        Z = gamma[:, :, 2]\n        R = np.sqrt(X ** 2 + Y ** 2)\n\n        theta_arclength = np.zeros_like(gamma[:, :, 0])\n        nphi = len(theta_arclength[:, 0])\n        ntheta = len(theta_arclength[0, :])\n        for iphi in range(nphi):\n            for itheta in range(1, ntheta):\n                dr = np.sqrt((R[iphi, itheta] - R[iphi, itheta - 1]) ** 2\n                             + (Z[iphi, itheta] - Z[iphi, itheta - 1]) ** 2)\n                theta_arclength[iphi, itheta] = \\\n                    theta_arclength[iphi, itheta - 1] + dr\n            dr = np.sqrt((R[iphi, 0] - R[iphi, -1]) ** 2\n                         + (Z[iphi, 0] - Z[iphi, -1]) ** 2)\n            L = theta_arclength[iphi, -1] + dr\n            theta_arclength[iphi, :] = theta_arclength[iphi, :] / L\n        return theta_arclength",
  "def interpolate_on_arclength_grid(self, function, theta_evaluate):\n        \"\"\"\n        Interpolate function onto the theta_evaluate grid in the arclength\n        poloidal angle. This is required for evaluating the adjoint shape gradient\n        for free-boundary calculations.\n\n        Returns:\n            function_interpolated: 2d array (numquadpoints_phi,numquadpoints_theta)\n                defining interpolated function on arclength angle along curve\n                at constant phi\n        \"\"\"\n        from scipy import interpolate\n\n        theta_arclength = self.arclength_poloidal_angle()\n        function_interpolated = np.zeros_like(function)\n        nphi = len(theta_arclength[:, 0])\n        for iphi in range(nphi):\n            f = interpolate.InterpolatedUnivariateSpline(\n                theta_arclength[iphi, :], function[iphi, :])\n            function_interpolated[iphi, :] = f(theta_evaluate[iphi, :])\n\n        return function_interpolated",
  "def __init__(self, surface, p=1, h=0.05):\n        \"\"\"\n        Args:\n            surface: the surface to contruct the distance from.\n            p: degree of the interpolant\n            h: grid resolution of the interpolant\n        \"\"\"\n        gammas = surface.gamma()\n        r = np.linalg.norm(gammas[:, :, :2], axis=2)\n        z = gammas[:, :, 2]\n        rmin = max(np.min(r) - 0.1, 0.)\n        rmax = np.max(r) + 0.1\n        zmin = np.min(z) - 0.1\n        zmax = np.max(z) + 0.1\n\n        self.zrange = (zmin, zmax)\n        self.rrange = (rmin, rmax)\n\n        nr = int((self.rrange[1]-self.rrange[0])/h)\n        nphi = int(2*np.pi/h)\n        nz = int((self.zrange[1]-self.zrange[0])/h)\n\n        def fbatch(rs, phis, zs):\n            xyz = np.zeros((len(rs), 3))\n            xyz[:, 0] = rs * np.cos(phis)\n            xyz[:, 1] = rs * np.sin(phis)\n            xyz[:, 2] = zs\n            return list(signed_distance_from_surface(xyz, surface))\n\n        rule = sopp.UniformInterpolationRule(p)\n        self.dist = sopp.RegularGridInterpolant3D(\n            rule, [rmin, rmax, nr], [0., 2*np.pi, nphi], [zmin, zmax, nz], 1, True)\n        self.dist.interpolate_batch(fbatch)",
  "def evaluate_xyz(self, xyz):\n        rphiz = np.zeros_like(xyz)\n        rphiz[:, 0] = np.linalg.norm(xyz[:, :2], axis=1)\n        rphiz[:, 1] = np.mod(np.arctan2(xyz[:, 1], xyz[:, 0]), 2*np.pi)\n        rphiz[:, 2] = xyz[:, 2]\n        # initialize to -1 since the regular grid interpolant will just keep\n        # that value when evaluated outside of bounds\n        d = -np.ones((xyz.shape[0], 1))\n        self.dist.evaluate_batch(rphiz, d)\n        return d",
  "def evaluate_rphiz(self, rphiz):\n        # initialize to -1 since the regular grid interpolant will just keep\n        # that value when evaluated outside of bounds\n        d = -np.ones((rphiz.shape[0], 1))\n        self.dist.evaluate_batch(rphiz, d)\n        return d",
  "def to_vtk(self, filename, h=0.01):\n\n        nr = int((self.rrange[1]-self.rrange[0])/h)\n        nphi = int(2*np.pi/h)\n        nz = int((self.zrange[1]-self.zrange[0])/h)\n        rs = np.linspace(self.rrange[0], self.rrange[1], nr)\n        phis = np.linspace(0, 2*np.pi, nphi)\n        zs = np.linspace(self.zrange[0], self.zrange[1], nz)\n\n        R, Phi, Z = np.meshgrid(rs, phis, zs)\n        X = R * np.cos(Phi)\n        Y = R * np.sin(Phi)\n        Z = Z\n\n        RPhiZ = np.zeros((R.size, 3))\n        RPhiZ[:, 0] = R.flatten()\n        RPhiZ[:, 1] = Phi.flatten()\n        RPhiZ[:, 2] = Z.flatten()\n        vals = -np.ones((R.size, 1))\n        self.dist.evaluate_batch(RPhiZ, vals)\n        vals = vals.reshape(R.shape)\n        gridToVTK(filename, X, Y, Z, pointData={\"levelset\": vals})",
  "def __init__(self, surf, scale_factors):\n        self.surf = surf\n        self.scale_factors = scale_factors\n        super().__init__(x0=surf.x / scale_factors, names=surf.local_dof_names)",
  "def recompute_bell(self, parent=None):\n        self.surf.local_full_x = self.local_full_x * self.scale_factors",
  "def to_RZFourier(self):\n        return self.surf.to_RZFourier()",
  "def update_fixed(self):\n        \"\"\"\n        Copy the fixed status from self.surf to self.\n        \"\"\"\n        for j, is_free in enumerate(self.surf.local_dofs_free_status):\n            if is_free:\n                self.unfix(j)\n            else:\n                self.fix(j)",
  "def as_dict(self, serial_objs_dict) -> dict:\n        return GSONable.as_dict(self, serial_objs_dict=serial_objs_dict)",
  "def varphi2phi(varphi_in, left_bound, right_bound):\n            gamma = np.zeros((varphi_in.size, 3))\n            self.gamma_lin(gamma, varphi_in, theta)\n            phi = np.arctan2(gamma[:, 1], gamma[:, 0])\n            pinc = (phi < left_bound).astype(int)\n            minc = (phi > right_bound).astype(int)\n            phi = phi + 2. * np.pi * (pinc - minc)\n            return phi",
  "def bisection(phia, a, phic, c):\n            err = 1.\n            while err > 1e-13:\n                b = (a + c) / 2.\n                phib = varphi2phi(b, phia, phic)\n\n                flag = (phib - phi) * (phic - phi) > 0\n                # if flag is true,  then root lies on interval [a,b)\n                # if flag is false, then root lies on interval [b,c]\n                phia = np.where(flag, phia, phib)\n                phic = np.where(flag, phib, phic)\n                a = np.where(flag, a, b)\n                c = np.where(flag, b, c)\n                err = np.max(np.abs(a - c))\n            b = (a + c) / 2.\n            return b",
  "def fbatch(rs, phis, zs):\n            xyz = np.zeros((len(rs), 3))\n            xyz[:, 0] = rs * np.cos(phis)\n            xyz[:, 1] = rs * np.sin(phis)\n            xyz[:, 2] = zs\n            return list(signed_distance_from_surface(xyz, surface))",
  "def curve_length_pure(l):\n    \"\"\"\n    This function is used in a Python+Jax implementation of the curve length formula.\n    \"\"\"\n    return jnp.mean(l)",
  "class CurveLength(Optimizable):\n    r\"\"\"\n    CurveLength is a class that computes the length of a curve, i.e.\n\n    .. math::\n        J = \\int_{\\text{curve}}~dl.\n\n    \"\"\"\n\n    def __init__(self, curve):\n        self.curve = curve\n        self.thisgrad = jit(lambda l: grad(curve_length_pure)(l))\n        super().__init__(depends_on=[curve])\n\n    def J(self):\n        \"\"\"\n        This returns the value of the quantity.\n        \"\"\"\n        return curve_length_pure(self.curve.incremental_arclength())\n\n    @derivative_dec\n    def dJ(self):\n        \"\"\"\n        This returns the derivative of the quantity with respect to the curve dofs.\n        \"\"\"\n\n        return self.curve.dincremental_arclength_by_dcoeff_vjp(\n            self.thisgrad(self.curve.incremental_arclength()))\n\n    return_fn_map = {'J': J, 'dJ': dJ}",
  "def Lp_curvature_pure(kappa, gammadash, p, desired_kappa):\n    \"\"\"\n    This function is used in a Python+Jax implementation of the curvature penalty term.\n    \"\"\"\n    arc_length = jnp.linalg.norm(gammadash, axis=1)\n    return (1./p)*jnp.mean(jnp.maximum(kappa-desired_kappa, 0)**p * arc_length)",
  "class LpCurveCurvature(Optimizable):\n    r\"\"\"\n    This class computes a penalty term based on the :math:`L_p` norm\n    of the curve's curvature, and penalizes where the local curve curvature exceeds a threshold\n\n    .. math::\n        J = \\frac{1}{p} \\int_{\\text{curve}} \\text{max}(\\kappa - \\kappa_0, 0)^p ~dl\n\n    where :math:`\\kappa_0` is a threshold curvature, given by the argument ``threshold``.\n    \"\"\"\n\n    def __init__(self, curve, p, threshold=0.0):\n        self.curve = curve\n        self.p = p\n        self.threshold = threshold\n        super().__init__(depends_on=[curve])\n        self.J_jax = jit(lambda kappa, gammadash: Lp_curvature_pure(kappa, gammadash, p, threshold))\n        self.thisgrad0 = jit(lambda kappa, gammadash: grad(self.J_jax, argnums=0)(kappa, gammadash))\n        self.thisgrad1 = jit(lambda kappa, gammadash: grad(self.J_jax, argnums=1)(kappa, gammadash))\n\n    def J(self):\n        \"\"\"\n        This returns the value of the quantity.\n        \"\"\"\n        return self.J_jax(self.curve.kappa(), self.curve.gammadash())\n\n    @derivative_dec\n    def dJ(self):\n        \"\"\"\n        This returns the derivative of the quantity with respect to the curve dofs.\n        \"\"\"\n        grad0 = self.thisgrad0(self.curve.kappa(), self.curve.gammadash())\n        grad1 = self.thisgrad1(self.curve.kappa(), self.curve.gammadash())\n        return self.curve.dkappa_by_dcoeff_vjp(grad0) + self.curve.dgammadash_by_dcoeff_vjp(grad1)\n\n    return_fn_map = {'J': J, 'dJ': dJ}",
  "def Lp_torsion_pure(torsion, gammadash, p, threshold):\n    \"\"\"\n    This function is used in a Python+Jax implementation of the formula for the torsion penalty term.\n    \"\"\"\n    arc_length = jnp.linalg.norm(gammadash, axis=1)\n    return (1./p)*jnp.mean(jnp.maximum(jnp.abs(torsion)-threshold, 0)**p * arc_length)",
  "class LpCurveTorsion(Optimizable):\n    r\"\"\"\n    LpCurveTorsion is a class that computes a penalty term based on the :math:`L_p` norm\n    of the curve's torsion:\n\n    .. math::\n        J = \\frac{1}{p} \\int_{\\text{curve}} \\max(|\\tau|-\\tau_0, 0)^p ~dl.\n\n    \"\"\"\n\n    def __init__(self, curve, p, threshold=0.0):\n        self.curve = curve\n        self.p = p\n        self.threshold = threshold\n        super().__init__(depends_on=[curve])\n        self.J_jax = jit(lambda torsion, gammadash: Lp_torsion_pure(torsion, gammadash, p, threshold))\n        self.thisgrad0 = jit(lambda torsion, gammadash: grad(self.J_jax, argnums=0)(torsion, gammadash))\n        self.thisgrad1 = jit(lambda torsion, gammadash: grad(self.J_jax, argnums=1)(torsion, gammadash))\n\n    def J(self):\n        \"\"\"\n        This returns the value of the quantity.\n        \"\"\"\n        return self.J_jax(self.curve.torsion(), self.curve.gammadash())\n\n    @derivative_dec\n    def dJ(self):\n        \"\"\"\n        This returns the derivative of the quantity with respect to the curve dofs.\n        \"\"\"\n        grad0 = self.thisgrad0(self.curve.torsion(), self.curve.gammadash())\n        grad1 = self.thisgrad1(self.curve.torsion(), self.curve.gammadash())\n        return self.curve.dtorsion_by_dcoeff_vjp(grad0) + self.curve.dgammadash_by_dcoeff_vjp(grad1)\n\n    return_fn_map = {'J': J, 'dJ': dJ}",
  "def cc_distance_pure(gamma1, l1, gamma2, l2, minimum_distance):\n    \"\"\"\n    This function is used in a Python+Jax implementation of the curve-curve distance formula.\n    \"\"\"\n    dists = jnp.sqrt(jnp.sum((gamma1[:, None, :] - gamma2[None, :, :])**2, axis=2))\n    alen = jnp.linalg.norm(l1, axis=1)[:, None] * jnp.linalg.norm(l2, axis=1)[None, :]\n    return jnp.sum(alen * jnp.maximum(minimum_distance-dists, 0)**2)/(gamma1.shape[0]*gamma2.shape[0])",
  "class CurveCurveDistance(Optimizable):\n    r\"\"\"\n    CurveCurveDistance is a class that computes\n\n    .. math::\n        J = \\sum_{i = 1}^{\\text{num_coils}} \\sum_{j = 1}^{i-1} d_{i,j}\n\n    where \n\n    .. math::\n        d_{i,j} = \\int_{\\text{curve}_i} \\int_{\\text{curve}_j} \\max(0, d_{\\min} - \\| \\mathbf{r}_i - \\mathbf{r}_j \\|_2)^2 ~dl_j ~dl_i\\\\\n\n    and :math:`\\mathbf{r}_i`, :math:`\\mathbf{r}_j` are points on coils :math:`i` and :math:`j`, respectively.\n    :math:`d_\\min` is a desired threshold minimum intercoil distance.  This penalty term is zero when the points on coil :math:`i` and \n    coil :math:`j` lie more than :math:`d_\\min` away from one another, for :math:`i, j \\in \\{1, \\cdots, \\text{num_coils}\\}`\n\n    If num_basecurves is passed, then the code only computes the distance to\n    the first `num_basecurves` many curves, which is useful when the coils\n    satisfy symmetries that can be exploited.\n\n    \"\"\"\n\n    def __init__(self, curves, minimum_distance, num_basecurves=None):\n        self.curves = curves\n        self.minimum_distance = minimum_distance\n\n        self.J_jax = jit(lambda gamma1, l1, gamma2, l2: cc_distance_pure(gamma1, l1, gamma2, l2, minimum_distance))\n        self.thisgrad0 = jit(lambda gamma1, l1, gamma2, l2: grad(self.J_jax, argnums=0)(gamma1, l1, gamma2, l2))\n        self.thisgrad1 = jit(lambda gamma1, l1, gamma2, l2: grad(self.J_jax, argnums=1)(gamma1, l1, gamma2, l2))\n        self.thisgrad2 = jit(lambda gamma1, l1, gamma2, l2: grad(self.J_jax, argnums=2)(gamma1, l1, gamma2, l2))\n        self.thisgrad3 = jit(lambda gamma1, l1, gamma2, l2: grad(self.J_jax, argnums=3)(gamma1, l1, gamma2, l2))\n        self.candidates = None\n        self.num_basecurves = num_basecurves or len(curves)\n        super().__init__(depends_on=curves)\n\n    def recompute_bell(self, parent=None):\n        self.candidates = None\n\n    def compute_candidates(self):\n        if self.candidates is None:\n            candidates = sopp.get_pointclouds_closer_than_threshold_within_collection(\n                [c.gamma() for c in self.curves], self.minimum_distance, self.num_basecurves)\n            self.candidates = candidates\n\n    def shortest_distance_among_candidates(self):\n        self.compute_candidates()\n        from scipy.spatial.distance import cdist\n        return min([self.minimum_distance] + [np.min(cdist(self.curves[i].gamma(), self.curves[j].gamma())) for i, j in self.candidates])\n\n    def shortest_distance(self):\n        self.compute_candidates()\n        if len(self.candidates) > 0:\n            return self.shortest_distance_among_candidates()\n        from scipy.spatial.distance import cdist\n        return min([np.min(cdist(self.curves[i].gamma(), self.curves[j].gamma())) for i in range(len(self.curves)) for j in range(i)])\n\n    def J(self):\n        \"\"\"\n        This returns the value of the quantity.\n        \"\"\"\n        self.compute_candidates()\n        res = 0\n        for i, j in self.candidates:\n            gamma1 = self.curves[i].gamma()\n            l1 = self.curves[i].gammadash()\n            gamma2 = self.curves[j].gamma()\n            l2 = self.curves[j].gammadash()\n            res += self.J_jax(gamma1, l1, gamma2, l2)\n\n        return res\n\n    @derivative_dec\n    def dJ(self):\n        \"\"\"\n        This returns the derivative of the quantity with respect to the curve dofs.\n        \"\"\"\n        self.compute_candidates()\n        dgamma_by_dcoeff_vjp_vecs = [np.zeros_like(c.gamma()) for c in self.curves]\n        dgammadash_by_dcoeff_vjp_vecs = [np.zeros_like(c.gammadash()) for c in self.curves]\n\n        for i, j in self.candidates:\n            gamma1 = self.curves[i].gamma()\n            l1 = self.curves[i].gammadash()\n            gamma2 = self.curves[j].gamma()\n            l2 = self.curves[j].gammadash()\n            dgamma_by_dcoeff_vjp_vecs[i] += self.thisgrad0(gamma1, l1, gamma2, l2)\n            dgammadash_by_dcoeff_vjp_vecs[i] += self.thisgrad1(gamma1, l1, gamma2, l2)\n            dgamma_by_dcoeff_vjp_vecs[j] += self.thisgrad2(gamma1, l1, gamma2, l2)\n            dgammadash_by_dcoeff_vjp_vecs[j] += self.thisgrad3(gamma1, l1, gamma2, l2)\n\n        res = [self.curves[i].dgamma_by_dcoeff_vjp(dgamma_by_dcoeff_vjp_vecs[i]) + self.curves[i].dgammadash_by_dcoeff_vjp(dgammadash_by_dcoeff_vjp_vecs[i]) for i in range(len(self.curves))]\n        return sum(res)\n\n    return_fn_map = {'J': J, 'dJ': dJ}",
  "def cs_distance_pure(gammac, lc, gammas, ns, minimum_distance):\n    \"\"\"\n    This function is used in a Python+Jax implementation of the curve-surface distance\n    formula.\n    \"\"\"\n    dists = jnp.sqrt(jnp.sum(\n        (gammac[:, None, :] - gammas[None, :, :])**2, axis=2))\n    integralweight = jnp.linalg.norm(lc, axis=1)[:, None] \\\n        * jnp.linalg.norm(ns, axis=1)[None, :]\n    return jnp.mean(integralweight * jnp.maximum(minimum_distance-dists, 0)**2)",
  "class CurveSurfaceDistance(Optimizable):\n    r\"\"\"\n    CurveSurfaceDistance is a class that computes\n\n    .. math::\n        J = \\sum_{i = 1}^{\\text{num_coils}} d_{i}\n\n    where\n\n    .. math::\n        d_{i} = \\int_{\\text{curve}_i} \\int_{surface} \\max(0, d_{\\min} - \\| \\mathbf{r}_i - \\mathbf{s} \\|_2)^2 ~dl_i ~ds\\\\\n\n    and :math:`\\mathbf{r}_i`, :math:`\\mathbf{s}` are points on coil :math:`i`\n    and the surface, respectively. :math:`d_\\min` is a desired threshold\n    minimum coil-to-surface distance.  This penalty term is zero when the\n    points on all coils :math:`i` and on the surface lie more than\n    :math:`d_\\min` away from one another.\n\n    \"\"\"\n\n    def __init__(self, curves, surface, minimum_distance):\n        self.curves = curves\n        self.surface = surface\n        self.minimum_distance = minimum_distance\n\n        self.J_jax = jit(lambda gammac, lc, gammas, ns: cs_distance_pure(gammac, lc, gammas, ns, minimum_distance))\n        self.thisgrad0 = jit(lambda gammac, lc, gammas, ns: grad(self.J_jax, argnums=0)(gammac, lc, gammas, ns))\n        self.thisgrad1 = jit(lambda gammac, lc, gammas, ns: grad(self.J_jax, argnums=1)(gammac, lc, gammas, ns))\n        self.candidates = None\n        super().__init__(depends_on=curves)  # Bharat's comment: Shouldn't we add surface here\n\n    def recompute_bell(self, parent=None):\n        self.candidates = None\n\n    def compute_candidates(self):\n        if self.candidates is None:\n            candidates = sopp.get_pointclouds_closer_than_threshold_between_two_collections(\n                [c.gamma() for c in self.curves], [self.surface.gamma().reshape((-1, 3))], self.minimum_distance)\n            self.candidates = candidates\n\n    def shortest_distance_among_candidates(self):\n        self.compute_candidates()\n        from scipy.spatial.distance import cdist\n        xyz_surf = self.surface.gamma().reshape((-1, 3))\n        return min([self.minimum_distance] + [np.min(cdist(self.curves[i].gamma(), xyz_surf)) for i, _ in self.candidates])\n\n    def shortest_distance(self):\n        self.compute_candidates()\n        if len(self.candidates) > 0:\n            return self.shortest_distance_among_candidates()\n        from scipy.spatial.distance import cdist\n        xyz_surf = self.surface.gamma().reshape((-1, 3))\n        return min([np.min(cdist(self.curves[i].gamma(), xyz_surf)) for i in range(len(self.curves))])\n\n    def J(self):\n        \"\"\"\n        This returns the value of the quantity.\n        \"\"\"\n        self.compute_candidates()\n        res = 0\n        gammas = self.surface.gamma().reshape((-1, 3))\n        ns = self.surface.normal().reshape((-1, 3))\n        for i, _ in self.candidates:\n            gammac = self.curves[i].gamma()\n            lc = self.curves[i].gammadash()\n            res += self.J_jax(gammac, lc, gammas, ns)\n        return res\n\n    @derivative_dec\n    def dJ(self):\n        \"\"\"\n        This returns the derivative of the quantity with respect to the curve dofs.\n        \"\"\"\n        self.compute_candidates()\n        dgamma_by_dcoeff_vjp_vecs = [np.zeros_like(c.gamma()) for c in self.curves]\n        dgammadash_by_dcoeff_vjp_vecs = [np.zeros_like(c.gammadash()) for c in self.curves]\n        gammas = self.surface.gamma().reshape((-1, 3))\n\n        gammas = self.surface.gamma().reshape((-1, 3))\n        ns = self.surface.normal().reshape((-1, 3))\n        for i, _ in self.candidates:\n            gammac = self.curves[i].gamma()\n            lc = self.curves[i].gammadash()\n            dgamma_by_dcoeff_vjp_vecs[i] += self.thisgrad0(gammac, lc, gammas, ns)\n            dgammadash_by_dcoeff_vjp_vecs[i] += self.thisgrad1(gammac, lc, gammas, ns)\n        res = [self.curves[i].dgamma_by_dcoeff_vjp(dgamma_by_dcoeff_vjp_vecs[i]) + self.curves[i].dgammadash_by_dcoeff_vjp(dgammadash_by_dcoeff_vjp_vecs[i]) for i in range(len(self.curves))]\n        return sum(res)\n\n    return_fn_map = {'J': J, 'dJ': dJ}",
  "def curve_arclengthvariation_pure(l, mat):\n    \"\"\"\n    This function is used in a Python+Jax implementation of the curve arclength variation.\n    \"\"\"\n    return jnp.var(mat @ l)",
  "class ArclengthVariation(Optimizable):\n\n    def __init__(self, curve, nintervals=\"full\"):\n        r\"\"\"\n        This class penalizes variation of the arclength along a curve.\n        The idea of this class is to avoid ill-posedness of curve objectives due to\n        non-uniqueness of the underlying parametrization. Essentially we want to\n        achieve constant arclength along the curve. Since we can not expect\n        perfectly constant arclength along the entire curve, this class has\n        some support to relax this notion. Consider a partition of the :math:`[0, 1]`\n        interval into intervals :math:`\\{I_i\\}_{i=1}^L`, and tenote the average incremental arclength\n        on interval :math:`I_i` by :math:`\\ell_i`. This objective then penalises the variance\n\n        .. math::\n            J = \\mathrm{Var}(\\ell_i)\n\n        it remains to choose the number of intervals :math:`L` that :math:`[0, 1]` is split into.\n        If ``nintervals=\"full\"``, then the number of intervals :math:`L` is equal to the number of quadrature\n        points of the curve. If ``nintervals=\"partial\"``, then the argument is as follows:\n\n        A curve in 3d space is defined uniquely by an initial point, an initial\n        direction, and the arclength, curvature, and torsion along the curve. For a\n        :mod:`simsopt.geo.curvexyzfourier.CurveXYZFourier`, the intuition is now as\n        follows: assuming that the curve has order :math:`p`, that means we have\n        :math:`3*(2p+1)` degrees of freedom in total. Assuming that three each are\n        required for both the initial position and direction, :math:`6p-3` are left\n        over for curvature, torsion, and arclength. We want to fix the arclength,\n        so we can afford :math:`2p-1` constraints, which corresponds to\n        :math:`L=2p`.\n\n        Finally, the user can also provide an integer value for `nintervals`\n        and thus specify the number of intervals directly.\n        \"\"\"\n        super().__init__(depends_on=[curve])\n\n        assert nintervals in [\"full\", \"partial\"] \\\n            or (isinstance(nintervals, int) and 0 < nintervals <= curve.gamma().shape[0])\n        self.curve = curve\n        nquadpoints = len(curve.quadpoints)\n        if nintervals == \"full\":\n            nintervals = curve.gamma().shape[0]\n        elif nintervals == \"partial\":\n            from simsopt.geo.curvexyzfourier import CurveXYZFourier, JaxCurveXYZFourier\n            if isinstance(curve, CurveXYZFourier) or isinstance(curve, JaxCurveXYZFourier):\n                nintervals = 2*curve.order\n            else:\n                raise RuntimeError(\"Please provide a value other than `partial` for `nintervals`. We only have a default for `CurveXYZFourier` and `JaxCurveXYZFourier`.\")\n\n        self.nintervals = nintervals\n        indices = np.floor(np.linspace(0, nquadpoints, nintervals+1, endpoint=True)).astype(int)\n        mat = np.zeros((nintervals, nquadpoints))\n        for i in range(nintervals):\n            mat[i, indices[i]:indices[i+1]] = 1/(indices[i+1]-indices[i])\n        self.mat = mat\n        self.thisgrad = jit(lambda l: grad(lambda x: curve_arclengthvariation_pure(x, mat))(l))\n\n    def J(self):\n        return float(curve_arclengthvariation_pure(self.curve.incremental_arclength(), self.mat))\n\n    @derivative_dec\n    def dJ(self):\n        \"\"\"\n        This returns the derivative of the quantity with respect to the curve dofs.\n        \"\"\"\n        return self.curve.dincremental_arclength_by_dcoeff_vjp(\n            self.thisgrad(self.curve.incremental_arclength()))\n\n    return_fn_map = {'J': J, 'dJ': dJ}",
  "def curve_msc_pure(kappa, gammadash):\n    \"\"\"\n    This function is used in a Python+Jax implementation of the mean squared curvature objective.\n    \"\"\"\n    arc_length = jnp.linalg.norm(gammadash, axis=1)\n    return jnp.mean(kappa**2 * arc_length)/jnp.mean(arc_length)",
  "class MeanSquaredCurvature(Optimizable):\n\n    def __init__(self, curve):\n        r\"\"\"\n        Compute the mean of the squared curvature of a curve.\n\n        .. math::\n            J = (1/L) \\int_{\\text{curve}} \\kappa^2 ~dl\n\n        where :math:`L` is the curve length, :math:`\\ell` is the incremental\n        arclength, and :math:`\\kappa` is the curvature.\n\n        Args:\n            curve: the curve of which the curvature should be computed.\n        \"\"\"\n        super().__init__(depends_on=[curve])\n        self.curve = curve\n        self.thisgrad0 = jit(lambda kappa, gammadash: grad(curve_msc_pure, argnums=0)(kappa, gammadash))\n        self.thisgrad1 = jit(lambda kappa, gammadash: grad(curve_msc_pure, argnums=1)(kappa, gammadash))\n\n    def J(self):\n        return float(curve_msc_pure(self.curve.kappa(), self.curve.gammadash()))\n\n    @derivative_dec\n    def dJ(self):\n        grad0 = self.thisgrad0(self.curve.kappa(), self.curve.gammadash())\n        grad1 = self.thisgrad1(self.curve.kappa(), self.curve.gammadash())\n        return self.curve.dkappa_by_dcoeff_vjp(grad0) + self.curve.dgammadash_by_dcoeff_vjp(grad1)",
  "class MinimumDistance(CurveCurveDistance):\n    pass",
  "class LinkingNumber(Optimizable):\n\n    def __init__(self, curves):\n        Optimizable.__init__(self, depends_on=curves)\n        self.curves = curves\n        r\"\"\"\n        Compute the Linking number of a set of curves (whether the curves \n        are interlocked or not).\n\n        The value is 1 if the are interlocked, 0 if not.\n        \n        .. math::\n            Link(c1,c2) = \\frac{1}{4\\pi} \\oint_{c1}\\oint_{c2}\\frac{\\textbf{R1} - \\textbf{R2}}{|\\textbf{R1}-\\textbf{R2}|^3} (d\\textbf{R1} \\times d\\textbf{R2})\n            \n        where :math:`c1` is the first curve and :math:`c2` is the second curve, \n        :math:`\\textbf{R1}` is the radius vector of the first curve, and \n        :math:`\\textbf{R2}` is the radius vector of the second curve\n\n        Args:\n            curves: the set of curves on which the linking number should be computed.\n        \n        \"\"\"\n\n    def J(self):\n        ncoils = len(self.curves)\n        linkNum = np.zeros([ncoils + 1, ncoils + 1])\n        i = 0\n        for c1 in self.curves[:(ncoils + 1)]:\n            j = 0\n            i = i + 1\n            for c2 in self.curves[:(ncoils + 1)]:\n                j = j + 1\n                if i < j:\n                    R1 = c1.gamma()\n                    R2 = c2.gamma()\n                    dS = c1.quadpoints[1] - c1.quadpoints[0]\n                    dT = c2.quadpoints[1] - c1.quadpoints[0]\n                    dR1 = c1.gammadash()\n                    dR2 = c2.gammadash()\n\n                    integrals = sopp.linkNumber(R1, R2, dR1, dR2) * dS * dT\n                    linkNum[i-1][j-1] = 1/(4*np.pi) * (integrals)\n        linkNumSum = sum(sum(abs(linkNum)))\n        return linkNumSum\n\n    @derivative_dec\n    def dJ(self):\n        return Derivative({})",
  "def __init__(self, curve):\n        self.curve = curve\n        self.thisgrad = jit(lambda l: grad(curve_length_pure)(l))\n        super().__init__(depends_on=[curve])",
  "def J(self):\n        \"\"\"\n        This returns the value of the quantity.\n        \"\"\"\n        return curve_length_pure(self.curve.incremental_arclength())",
  "def dJ(self):\n        \"\"\"\n        This returns the derivative of the quantity with respect to the curve dofs.\n        \"\"\"\n\n        return self.curve.dincremental_arclength_by_dcoeff_vjp(\n            self.thisgrad(self.curve.incremental_arclength()))",
  "def __init__(self, curve, p, threshold=0.0):\n        self.curve = curve\n        self.p = p\n        self.threshold = threshold\n        super().__init__(depends_on=[curve])\n        self.J_jax = jit(lambda kappa, gammadash: Lp_curvature_pure(kappa, gammadash, p, threshold))\n        self.thisgrad0 = jit(lambda kappa, gammadash: grad(self.J_jax, argnums=0)(kappa, gammadash))\n        self.thisgrad1 = jit(lambda kappa, gammadash: grad(self.J_jax, argnums=1)(kappa, gammadash))",
  "def J(self):\n        \"\"\"\n        This returns the value of the quantity.\n        \"\"\"\n        return self.J_jax(self.curve.kappa(), self.curve.gammadash())",
  "def dJ(self):\n        \"\"\"\n        This returns the derivative of the quantity with respect to the curve dofs.\n        \"\"\"\n        grad0 = self.thisgrad0(self.curve.kappa(), self.curve.gammadash())\n        grad1 = self.thisgrad1(self.curve.kappa(), self.curve.gammadash())\n        return self.curve.dkappa_by_dcoeff_vjp(grad0) + self.curve.dgammadash_by_dcoeff_vjp(grad1)",
  "def __init__(self, curve, p, threshold=0.0):\n        self.curve = curve\n        self.p = p\n        self.threshold = threshold\n        super().__init__(depends_on=[curve])\n        self.J_jax = jit(lambda torsion, gammadash: Lp_torsion_pure(torsion, gammadash, p, threshold))\n        self.thisgrad0 = jit(lambda torsion, gammadash: grad(self.J_jax, argnums=0)(torsion, gammadash))\n        self.thisgrad1 = jit(lambda torsion, gammadash: grad(self.J_jax, argnums=1)(torsion, gammadash))",
  "def J(self):\n        \"\"\"\n        This returns the value of the quantity.\n        \"\"\"\n        return self.J_jax(self.curve.torsion(), self.curve.gammadash())",
  "def dJ(self):\n        \"\"\"\n        This returns the derivative of the quantity with respect to the curve dofs.\n        \"\"\"\n        grad0 = self.thisgrad0(self.curve.torsion(), self.curve.gammadash())\n        grad1 = self.thisgrad1(self.curve.torsion(), self.curve.gammadash())\n        return self.curve.dtorsion_by_dcoeff_vjp(grad0) + self.curve.dgammadash_by_dcoeff_vjp(grad1)",
  "def __init__(self, curves, minimum_distance, num_basecurves=None):\n        self.curves = curves\n        self.minimum_distance = minimum_distance\n\n        self.J_jax = jit(lambda gamma1, l1, gamma2, l2: cc_distance_pure(gamma1, l1, gamma2, l2, minimum_distance))\n        self.thisgrad0 = jit(lambda gamma1, l1, gamma2, l2: grad(self.J_jax, argnums=0)(gamma1, l1, gamma2, l2))\n        self.thisgrad1 = jit(lambda gamma1, l1, gamma2, l2: grad(self.J_jax, argnums=1)(gamma1, l1, gamma2, l2))\n        self.thisgrad2 = jit(lambda gamma1, l1, gamma2, l2: grad(self.J_jax, argnums=2)(gamma1, l1, gamma2, l2))\n        self.thisgrad3 = jit(lambda gamma1, l1, gamma2, l2: grad(self.J_jax, argnums=3)(gamma1, l1, gamma2, l2))\n        self.candidates = None\n        self.num_basecurves = num_basecurves or len(curves)\n        super().__init__(depends_on=curves)",
  "def recompute_bell(self, parent=None):\n        self.candidates = None",
  "def compute_candidates(self):\n        if self.candidates is None:\n            candidates = sopp.get_pointclouds_closer_than_threshold_within_collection(\n                [c.gamma() for c in self.curves], self.minimum_distance, self.num_basecurves)\n            self.candidates = candidates",
  "def shortest_distance_among_candidates(self):\n        self.compute_candidates()\n        from scipy.spatial.distance import cdist\n        return min([self.minimum_distance] + [np.min(cdist(self.curves[i].gamma(), self.curves[j].gamma())) for i, j in self.candidates])",
  "def shortest_distance(self):\n        self.compute_candidates()\n        if len(self.candidates) > 0:\n            return self.shortest_distance_among_candidates()\n        from scipy.spatial.distance import cdist\n        return min([np.min(cdist(self.curves[i].gamma(), self.curves[j].gamma())) for i in range(len(self.curves)) for j in range(i)])",
  "def J(self):\n        \"\"\"\n        This returns the value of the quantity.\n        \"\"\"\n        self.compute_candidates()\n        res = 0\n        for i, j in self.candidates:\n            gamma1 = self.curves[i].gamma()\n            l1 = self.curves[i].gammadash()\n            gamma2 = self.curves[j].gamma()\n            l2 = self.curves[j].gammadash()\n            res += self.J_jax(gamma1, l1, gamma2, l2)\n\n        return res",
  "def dJ(self):\n        \"\"\"\n        This returns the derivative of the quantity with respect to the curve dofs.\n        \"\"\"\n        self.compute_candidates()\n        dgamma_by_dcoeff_vjp_vecs = [np.zeros_like(c.gamma()) for c in self.curves]\n        dgammadash_by_dcoeff_vjp_vecs = [np.zeros_like(c.gammadash()) for c in self.curves]\n\n        for i, j in self.candidates:\n            gamma1 = self.curves[i].gamma()\n            l1 = self.curves[i].gammadash()\n            gamma2 = self.curves[j].gamma()\n            l2 = self.curves[j].gammadash()\n            dgamma_by_dcoeff_vjp_vecs[i] += self.thisgrad0(gamma1, l1, gamma2, l2)\n            dgammadash_by_dcoeff_vjp_vecs[i] += self.thisgrad1(gamma1, l1, gamma2, l2)\n            dgamma_by_dcoeff_vjp_vecs[j] += self.thisgrad2(gamma1, l1, gamma2, l2)\n            dgammadash_by_dcoeff_vjp_vecs[j] += self.thisgrad3(gamma1, l1, gamma2, l2)\n\n        res = [self.curves[i].dgamma_by_dcoeff_vjp(dgamma_by_dcoeff_vjp_vecs[i]) + self.curves[i].dgammadash_by_dcoeff_vjp(dgammadash_by_dcoeff_vjp_vecs[i]) for i in range(len(self.curves))]\n        return sum(res)",
  "def __init__(self, curves, surface, minimum_distance):\n        self.curves = curves\n        self.surface = surface\n        self.minimum_distance = minimum_distance\n\n        self.J_jax = jit(lambda gammac, lc, gammas, ns: cs_distance_pure(gammac, lc, gammas, ns, minimum_distance))\n        self.thisgrad0 = jit(lambda gammac, lc, gammas, ns: grad(self.J_jax, argnums=0)(gammac, lc, gammas, ns))\n        self.thisgrad1 = jit(lambda gammac, lc, gammas, ns: grad(self.J_jax, argnums=1)(gammac, lc, gammas, ns))\n        self.candidates = None\n        super().__init__(depends_on=curves)",
  "def recompute_bell(self, parent=None):\n        self.candidates = None",
  "def compute_candidates(self):\n        if self.candidates is None:\n            candidates = sopp.get_pointclouds_closer_than_threshold_between_two_collections(\n                [c.gamma() for c in self.curves], [self.surface.gamma().reshape((-1, 3))], self.minimum_distance)\n            self.candidates = candidates",
  "def shortest_distance_among_candidates(self):\n        self.compute_candidates()\n        from scipy.spatial.distance import cdist\n        xyz_surf = self.surface.gamma().reshape((-1, 3))\n        return min([self.minimum_distance] + [np.min(cdist(self.curves[i].gamma(), xyz_surf)) for i, _ in self.candidates])",
  "def shortest_distance(self):\n        self.compute_candidates()\n        if len(self.candidates) > 0:\n            return self.shortest_distance_among_candidates()\n        from scipy.spatial.distance import cdist\n        xyz_surf = self.surface.gamma().reshape((-1, 3))\n        return min([np.min(cdist(self.curves[i].gamma(), xyz_surf)) for i in range(len(self.curves))])",
  "def J(self):\n        \"\"\"\n        This returns the value of the quantity.\n        \"\"\"\n        self.compute_candidates()\n        res = 0\n        gammas = self.surface.gamma().reshape((-1, 3))\n        ns = self.surface.normal().reshape((-1, 3))\n        for i, _ in self.candidates:\n            gammac = self.curves[i].gamma()\n            lc = self.curves[i].gammadash()\n            res += self.J_jax(gammac, lc, gammas, ns)\n        return res",
  "def dJ(self):\n        \"\"\"\n        This returns the derivative of the quantity with respect to the curve dofs.\n        \"\"\"\n        self.compute_candidates()\n        dgamma_by_dcoeff_vjp_vecs = [np.zeros_like(c.gamma()) for c in self.curves]\n        dgammadash_by_dcoeff_vjp_vecs = [np.zeros_like(c.gammadash()) for c in self.curves]\n        gammas = self.surface.gamma().reshape((-1, 3))\n\n        gammas = self.surface.gamma().reshape((-1, 3))\n        ns = self.surface.normal().reshape((-1, 3))\n        for i, _ in self.candidates:\n            gammac = self.curves[i].gamma()\n            lc = self.curves[i].gammadash()\n            dgamma_by_dcoeff_vjp_vecs[i] += self.thisgrad0(gammac, lc, gammas, ns)\n            dgammadash_by_dcoeff_vjp_vecs[i] += self.thisgrad1(gammac, lc, gammas, ns)\n        res = [self.curves[i].dgamma_by_dcoeff_vjp(dgamma_by_dcoeff_vjp_vecs[i]) + self.curves[i].dgammadash_by_dcoeff_vjp(dgammadash_by_dcoeff_vjp_vecs[i]) for i in range(len(self.curves))]\n        return sum(res)",
  "def __init__(self, curve, nintervals=\"full\"):\n        r\"\"\"\n        This class penalizes variation of the arclength along a curve.\n        The idea of this class is to avoid ill-posedness of curve objectives due to\n        non-uniqueness of the underlying parametrization. Essentially we want to\n        achieve constant arclength along the curve. Since we can not expect\n        perfectly constant arclength along the entire curve, this class has\n        some support to relax this notion. Consider a partition of the :math:`[0, 1]`\n        interval into intervals :math:`\\{I_i\\}_{i=1}^L`, and tenote the average incremental arclength\n        on interval :math:`I_i` by :math:`\\ell_i`. This objective then penalises the variance\n\n        .. math::\n            J = \\mathrm{Var}(\\ell_i)\n\n        it remains to choose the number of intervals :math:`L` that :math:`[0, 1]` is split into.\n        If ``nintervals=\"full\"``, then the number of intervals :math:`L` is equal to the number of quadrature\n        points of the curve. If ``nintervals=\"partial\"``, then the argument is as follows:\n\n        A curve in 3d space is defined uniquely by an initial point, an initial\n        direction, and the arclength, curvature, and torsion along the curve. For a\n        :mod:`simsopt.geo.curvexyzfourier.CurveXYZFourier`, the intuition is now as\n        follows: assuming that the curve has order :math:`p`, that means we have\n        :math:`3*(2p+1)` degrees of freedom in total. Assuming that three each are\n        required for both the initial position and direction, :math:`6p-3` are left\n        over for curvature, torsion, and arclength. We want to fix the arclength,\n        so we can afford :math:`2p-1` constraints, which corresponds to\n        :math:`L=2p`.\n\n        Finally, the user can also provide an integer value for `nintervals`\n        and thus specify the number of intervals directly.\n        \"\"\"\n        super().__init__(depends_on=[curve])\n\n        assert nintervals in [\"full\", \"partial\"] \\\n            or (isinstance(nintervals, int) and 0 < nintervals <= curve.gamma().shape[0])\n        self.curve = curve\n        nquadpoints = len(curve.quadpoints)\n        if nintervals == \"full\":\n            nintervals = curve.gamma().shape[0]\n        elif nintervals == \"partial\":\n            from simsopt.geo.curvexyzfourier import CurveXYZFourier, JaxCurveXYZFourier\n            if isinstance(curve, CurveXYZFourier) or isinstance(curve, JaxCurveXYZFourier):\n                nintervals = 2*curve.order\n            else:\n                raise RuntimeError(\"Please provide a value other than `partial` for `nintervals`. We only have a default for `CurveXYZFourier` and `JaxCurveXYZFourier`.\")\n\n        self.nintervals = nintervals\n        indices = np.floor(np.linspace(0, nquadpoints, nintervals+1, endpoint=True)).astype(int)\n        mat = np.zeros((nintervals, nquadpoints))\n        for i in range(nintervals):\n            mat[i, indices[i]:indices[i+1]] = 1/(indices[i+1]-indices[i])\n        self.mat = mat\n        self.thisgrad = jit(lambda l: grad(lambda x: curve_arclengthvariation_pure(x, mat))(l))",
  "def J(self):\n        return float(curve_arclengthvariation_pure(self.curve.incremental_arclength(), self.mat))",
  "def dJ(self):\n        \"\"\"\n        This returns the derivative of the quantity with respect to the curve dofs.\n        \"\"\"\n        return self.curve.dincremental_arclength_by_dcoeff_vjp(\n            self.thisgrad(self.curve.incremental_arclength()))",
  "def __init__(self, curve):\n        r\"\"\"\n        Compute the mean of the squared curvature of a curve.\n\n        .. math::\n            J = (1/L) \\int_{\\text{curve}} \\kappa^2 ~dl\n\n        where :math:`L` is the curve length, :math:`\\ell` is the incremental\n        arclength, and :math:`\\kappa` is the curvature.\n\n        Args:\n            curve: the curve of which the curvature should be computed.\n        \"\"\"\n        super().__init__(depends_on=[curve])\n        self.curve = curve\n        self.thisgrad0 = jit(lambda kappa, gammadash: grad(curve_msc_pure, argnums=0)(kappa, gammadash))\n        self.thisgrad1 = jit(lambda kappa, gammadash: grad(curve_msc_pure, argnums=1)(kappa, gammadash))",
  "def J(self):\n        return float(curve_msc_pure(self.curve.kappa(), self.curve.gammadash()))",
  "def dJ(self):\n        grad0 = self.thisgrad0(self.curve.kappa(), self.curve.gammadash())\n        grad1 = self.thisgrad1(self.curve.kappa(), self.curve.gammadash())\n        return self.curve.dkappa_by_dcoeff_vjp(grad0) + self.curve.dgammadash_by_dcoeff_vjp(grad1)",
  "def __init__(self, curves):\n        Optimizable.__init__(self, depends_on=curves)\n        self.curves = curves\n        r\"\"\"\n        Compute the Linking number of a set of curves (whether the curves \n        are interlocked or not).\n\n        The value is 1 if the are interlocked, 0 if not.\n        \n        .. math::\n            Link(c1,c2) = \\frac{1}{4\\pi} \\oint_{c1}\\oint_{c2}\\frac{\\textbf{R1} - \\textbf{R2}}{|\\textbf{R1}-\\textbf{R2}|^3} (d\\textbf{R1} \\times d\\textbf{R2})\n            \n        where :math:`c1` is the first curve and :math:`c2` is the second curve, \n        :math:`\\textbf{R1}` is the radius vector of the first curve, and \n        :math:`\\textbf{R2}` is the radius vector of the second curve\n\n        Args:\n            curves: the set of curves on which the linking number should be computed.\n        \n        \"\"\"",
  "def J(self):\n        ncoils = len(self.curves)\n        linkNum = np.zeros([ncoils + 1, ncoils + 1])\n        i = 0\n        for c1 in self.curves[:(ncoils + 1)]:\n            j = 0\n            i = i + 1\n            for c2 in self.curves[:(ncoils + 1)]:\n                j = j + 1\n                if i < j:\n                    R1 = c1.gamma()\n                    R2 = c2.gamma()\n                    dS = c1.quadpoints[1] - c1.quadpoints[0]\n                    dT = c2.quadpoints[1] - c1.quadpoints[0]\n                    dR1 = c1.gammadash()\n                    dR2 = c2.gammadash()\n\n                    integrals = sopp.linkNumber(R1, R2, dR1, dR2) * dS * dT\n                    linkNum[i-1][j-1] = 1/(4*np.pi) * (integrals)\n        linkNumSum = sum(sum(abs(linkNum)))\n        return linkNumSum",
  "def dJ(self):\n        return Derivative({})",
  "class SurfaceXYZTensorFourier(sopp.SurfaceXYZTensorFourier, Surface):\n\n    r\"\"\"\n    `SurfaceXYZTensorFourier` is a surface that is represented in cartesian\n    coordinates using the following Fourier series:\n\n    .. math::\n        \\hat x(\\theta, \\phi) &= \\sum_{i=0}^{2m_\\text{pol}} \\sum_{j=0}^{2n_\\text{tor}} x_{ij} w_i(\\theta)v_j(\\phi)\\\\\n        \\hat y(\\theta, \\phi) &= \\sum_{i=0}^{2m_\\text{pol}} \\sum_{j=0}^{2n_\\text{tor}} y_{ij} w_i(\\theta)v_j(\\phi)\\\\\n        x(\\phi, \\theta) &= \\hat x(\\phi, \\theta)  \\cos(\\phi) - \\hat y(\\phi, \\theta)  \\sin(\\phi)\\\\\n        y(\\phi, \\theta) &= \\hat x(\\phi, \\theta)  \\sin(\\phi) + \\hat y(\\phi, \\theta)  \\cos(\\phi)\\\\\n        z(\\theta, \\phi) &= \\sum_{i=0}^{2m_\\text{pol}} \\sum_{j=0}^{2n_\\text{tor}} z_{ij} w_i(\\theta)v_j(\\phi)\n\n    where the basis functions :math:`{v_j}` are given by\n\n    .. math::\n        \\{1, \\cos(1\\,\\mathrm{nfp}\\,\\phi), \\ldots, \\cos(n_\\text{tor}\\,\\mathrm{nfp}\\,\\phi), \\sin(1\\,\\mathrm{nfp}\\,\\phi), \\ldots, \\sin(n_\\text{tor}\\,\\mathrm{nfp}\\,\\phi)\\}\n\n    and :math:`{w_i}` are given by\n\n    .. math::\n        \\{1, \\cos(1\\theta), \\ldots, \\cos(m_\\text{pol}\\theta), \\sin(1\\theta), \\ldots, \\sin(m_\\text{pol}\\theta)\\}\n\n    When `stellsym=True` the sums above change as follows:\n\n    .. math::\n        \\hat x(\\theta, \\phi) &= \\sum_{i=0}^{m_\\text{pol}} \\sum_{j=0}^{n_\\text{tor}} x_{ij} w_i(\\theta)v_j(\\phi) + \\sum_{i=m_\\text{pol}+1}^{2m_\\text{pol}} \\sum_{j=n_\\text{tor}+1}^{2n_\\text{tor}} x_{ij} w_i(\\theta)v_j(\\phi)\\\\\n        \\hat y(\\theta, \\phi) &= \\sum_{i=0}^{m_\\text{pol}} \\sum_{j=n_\\text{tor}+1}^{2n_\\text{tor}} y_{ij} w_i(\\theta)v_j(\\phi) + \\sum_{i=m_\\text{pol}+1}^{2m_\\text{pol}} \\sum_{j=0}^{n_\\text{tor}} y_{ij} w_i(\\theta)v_j(\\phi)\\\\\\\\\n        z(\\theta, \\phi) &= \\sum_{i=0}^{m_\\text{pol}} \\sum_{j=n_\\text{tor}+1}^{2n_\\text{tor}} z_{ij} w_i(\\theta)v_j(\\phi) + \\sum_{i=m_\\text{pol}+1}^{2m_\\text{pol}} \\sum_{j=0}^{n_\\text{tor}} z_{ij} w_i(\\theta)v_j(\\phi)\n\n    For more information about the arguments ``quadpoints_phi``, and\n    ``quadpoints_theta``, see the general documentation on :ref:`surfaces`.\n    Instead of supplying the quadrature point arrays along :math:`\\phi` and\n    :math:`\\theta` directions, one could also specify the number of\n    quadrature points for :math:`\\phi` and :math:`\\theta` using the\n    class method :py:meth:`~simsopt.geo.surface.Surface.from_nphi_ntheta`.\n\n    Args:\n        nfp: The number of field periods.\n        stellsym: Whether the surface is stellarator-symmetric, i.e.\n          symmetry under rotation by :math:`\\pi` about the x-axis.\n        mpol: Maximum poloidal mode number included.\n        ntor: Maximum toroidal mode number included, divided by ``nfp``.\n        clamped_dims: ???\n        quadpoints_phi: Set this to a list or 1D array to set the :math:`\\phi_j` grid points directly.\n        quadpoints_theta: Set this to a list or 1D array to set the :math:`\\theta_j` grid points directly.\n    \"\"\"\n\n    def __init__(self, nfp=1, stellsym=True, mpol=1, ntor=1,\n                 clamped_dims=[False, False, False],\n                 quadpoints_phi=None, quadpoints_theta=None,\n                 dofs=None):\n\n        if quadpoints_theta is None:\n            quadpoints_theta = Surface.get_theta_quadpoints()\n        if quadpoints_phi is None:\n            quadpoints_phi = Surface.get_phi_quadpoints(nfp=nfp)\n\n        sopp.SurfaceXYZTensorFourier.__init__(self, mpol, ntor, nfp, stellsym,\n                                              clamped_dims, quadpoints_phi,\n                                              quadpoints_theta)\n        self.xcs[0, 0] = 1.0\n        self.xcs[1, 0] = 0.1\n        self.zcs[mpol+1, 0] = 0.1\n        if dofs is None:\n            Surface.__init__(self, x0=self.get_dofs(),\n                             external_dof_setter=SurfaceXYZTensorFourier.set_dofs_impl)\n        else:\n            Surface.__init__(self, dofs=dofs,\n                             external_dof_setter=SurfaceXYZTensorFourier.set_dofs_impl)\n\n    def get_dofs(self):\n        \"\"\"\n        Return the dofs associated to this surface.\n        \"\"\"\n        return np.asarray(sopp.SurfaceXYZTensorFourier.get_dofs(self))\n\n    def set_dofs(self, dofs):\n        \"\"\"\n        Set the dofs associated to this surface.\n        \"\"\"\n        self.local_full_x = dofs\n\n    def recompute_bell(self, parent=None):\n        self.invalidate_cache()\n\n    def to_RZFourier(self):\n        \"\"\"\n        Return a SurfaceRZFourier instance corresponding to the shape of this\n        surface.\n        \"\"\"\n        ntor = self.ntor\n        mpol = self.mpol \n        surf = SurfaceRZFourier(nfp=self.nfp, \n                                stellsym=self.stellsym, \n                                mpol=mpol, \n                                ntor=ntor, \n                                quadpoints_phi=self.quadpoints_phi, \n                                quadpoints_theta=self.quadpoints_theta)\n\n        gamma = np.zeros((surf.quadpoints_phi.size, surf.quadpoints_theta.size, 3))\n        for idx in range(gamma.shape[0]):\n            gamma[idx, :, :] = self.cross_section(surf.quadpoints_phi[idx]*2*np.pi)\n\n        surf.least_squares_fit(gamma)\n        return surf\n\n    def get_stellsym_mask(self):\n        \"\"\"\n        In the case of stellarator symmetry, some of the information is\n        redundant, since the coordinates at (-phi, -theta) are the same (up\n        to sign changes) to those at (phi, theta).\n        The point of this function is to identify those angles phi and theta\n        that we can ignore. This is difficult to do in general, so we focus on\n        the following three common cases below:\n\n            phis = np.linspace(0, 1/self.nfp, 2*ntor+1, endpoint=False)\n            thetas = np.linspace(0, 1, 2*mpol+1, endpoint=False)\n\n        or\n\n            phis = np.linspace(0, 1/self.nfp, 2*ntor+1, endpoint=False)\n            thetas = np.linspace(0, 0.5, 2*mpol, endpoint=False)\n\n        or\n\n            phis = np.linspace(0, 1/(2*self.nfp), ntor+1, endpoint=False)\n            thetas = np.linspace(0, 1, 2*mpol+1, endpoint=False)\n\n        This function could be extended to be aware of rotational symmetry as\n        well.  So far we assume that that redundancy was removed already (hence\n        the phis only go to 1/nfp or 1/(2*nfp)).\n\n        \"\"\"\n\n        phis = self.quadpoints_phi\n        thetas = self.quadpoints_theta\n        nphi = len(phis)\n        ntheta = len(thetas)\n        mask = np.ones((nphi, ntheta), dtype=bool)\n        if not self.stellsym:\n            return mask\n        ntor = self.ntor\n        mpol = self.mpol\n\n        def npsame(a, b):\n            return a.shape == b.shape and np.allclose(a, b)\n\n        if npsame(phis, np.linspace(0, 1/self.nfp, 2*ntor+1, endpoint=False)) and \\\n                npsame(thetas, np.linspace(0, 1, 2*mpol+1, endpoint=False)):\n            mask[:, mpol+1:] = False\n            mask[ntor+1:, 0] = False\n        if npsame(phis, np.linspace(0, 1/self.nfp, 2*ntor+1, endpoint=False)) and \\\n                npsame(thetas, np.linspace(0, 0.5, mpol+1, endpoint=False)):\n            mask[ntor+1:, 0] = False\n        if npsame(phis, np.linspace(0, 1/(2*self.nfp), ntor+1, endpoint=False)) and \\\n                npsame(thetas, np.linspace(0, 1, 2*mpol+1, endpoint=False)):\n            mask[0, mpol+1:] = False\n        return mask",
  "def __init__(self, nfp=1, stellsym=True, mpol=1, ntor=1,\n                 clamped_dims=[False, False, False],\n                 quadpoints_phi=None, quadpoints_theta=None,\n                 dofs=None):\n\n        if quadpoints_theta is None:\n            quadpoints_theta = Surface.get_theta_quadpoints()\n        if quadpoints_phi is None:\n            quadpoints_phi = Surface.get_phi_quadpoints(nfp=nfp)\n\n        sopp.SurfaceXYZTensorFourier.__init__(self, mpol, ntor, nfp, stellsym,\n                                              clamped_dims, quadpoints_phi,\n                                              quadpoints_theta)\n        self.xcs[0, 0] = 1.0\n        self.xcs[1, 0] = 0.1\n        self.zcs[mpol+1, 0] = 0.1\n        if dofs is None:\n            Surface.__init__(self, x0=self.get_dofs(),\n                             external_dof_setter=SurfaceXYZTensorFourier.set_dofs_impl)\n        else:\n            Surface.__init__(self, dofs=dofs,\n                             external_dof_setter=SurfaceXYZTensorFourier.set_dofs_impl)",
  "def get_dofs(self):\n        \"\"\"\n        Return the dofs associated to this surface.\n        \"\"\"\n        return np.asarray(sopp.SurfaceXYZTensorFourier.get_dofs(self))",
  "def set_dofs(self, dofs):\n        \"\"\"\n        Set the dofs associated to this surface.\n        \"\"\"\n        self.local_full_x = dofs",
  "def recompute_bell(self, parent=None):\n        self.invalidate_cache()",
  "def to_RZFourier(self):\n        \"\"\"\n        Return a SurfaceRZFourier instance corresponding to the shape of this\n        surface.\n        \"\"\"\n        ntor = self.ntor\n        mpol = self.mpol \n        surf = SurfaceRZFourier(nfp=self.nfp, \n                                stellsym=self.stellsym, \n                                mpol=mpol, \n                                ntor=ntor, \n                                quadpoints_phi=self.quadpoints_phi, \n                                quadpoints_theta=self.quadpoints_theta)\n\n        gamma = np.zeros((surf.quadpoints_phi.size, surf.quadpoints_theta.size, 3))\n        for idx in range(gamma.shape[0]):\n            gamma[idx, :, :] = self.cross_section(surf.quadpoints_phi[idx]*2*np.pi)\n\n        surf.least_squares_fit(gamma)\n        return surf",
  "def get_stellsym_mask(self):\n        \"\"\"\n        In the case of stellarator symmetry, some of the information is\n        redundant, since the coordinates at (-phi, -theta) are the same (up\n        to sign changes) to those at (phi, theta).\n        The point of this function is to identify those angles phi and theta\n        that we can ignore. This is difficult to do in general, so we focus on\n        the following three common cases below:\n\n            phis = np.linspace(0, 1/self.nfp, 2*ntor+1, endpoint=False)\n            thetas = np.linspace(0, 1, 2*mpol+1, endpoint=False)\n\n        or\n\n            phis = np.linspace(0, 1/self.nfp, 2*ntor+1, endpoint=False)\n            thetas = np.linspace(0, 0.5, 2*mpol, endpoint=False)\n\n        or\n\n            phis = np.linspace(0, 1/(2*self.nfp), ntor+1, endpoint=False)\n            thetas = np.linspace(0, 1, 2*mpol+1, endpoint=False)\n\n        This function could be extended to be aware of rotational symmetry as\n        well.  So far we assume that that redundancy was removed already (hence\n        the phis only go to 1/nfp or 1/(2*nfp)).\n\n        \"\"\"\n\n        phis = self.quadpoints_phi\n        thetas = self.quadpoints_theta\n        nphi = len(phis)\n        ntheta = len(thetas)\n        mask = np.ones((nphi, ntheta), dtype=bool)\n        if not self.stellsym:\n            return mask\n        ntor = self.ntor\n        mpol = self.mpol\n\n        def npsame(a, b):\n            return a.shape == b.shape and np.allclose(a, b)\n\n        if npsame(phis, np.linspace(0, 1/self.nfp, 2*ntor+1, endpoint=False)) and \\\n                npsame(thetas, np.linspace(0, 1, 2*mpol+1, endpoint=False)):\n            mask[:, mpol+1:] = False\n            mask[ntor+1:, 0] = False\n        if npsame(phis, np.linspace(0, 1/self.nfp, 2*ntor+1, endpoint=False)) and \\\n                npsame(thetas, np.linspace(0, 0.5, mpol+1, endpoint=False)):\n            mask[ntor+1:, 0] = False\n        if npsame(phis, np.linspace(0, 1/(2*self.nfp), ntor+1, endpoint=False)) and \\\n                npsame(thetas, np.linspace(0, 1, 2*mpol+1, endpoint=False)):\n            mask[0, mpol+1:] = False\n        return mask",
  "def npsame(a, b):\n            return a.shape == b.shape and np.allclose(a, b)",
  "class SurfaceRZFourier(sopp.SurfaceRZFourier, Surface):\n    r\"\"\"\n    ``SurfaceRZFourier`` is a surface that is represented in\n    cylindrical coordinates using the following Fourier series:\n\n    .. math::\n           r(\\theta, \\phi) = \\sum_{m=0}^{m_{\\text{pol}}}\n               \\sum_{n=-n_{\\text{tor}}}^{n_\\text{tor}} [\n               r_{c,m,n} \\cos(m \\theta - n_{\\text{fp}} n \\phi)\n               + r_{s,m,n} \\sin(m \\theta - n_{\\text{fp}} n \\phi) ]\n\n    and the same for :math:`z(\\theta, \\phi)`.\n\n    Here, :math:`(r,\\phi, z)` are standard cylindrical coordinates, and theta\n    is any poloidal angle.\n\n    Note that for :math:`m=0` we skip the :math:`n<0` term for the cos terms,\n    and the :math:`n \\leq 0` for the sin terms.\n\n    In addition, in the ``stellsym=True`` case, we skip the sin terms for\n    :math:`r`, and the cos terms for :math:`z`.\n\n    For more information about the arguments ``quadpoints_phi``, and\n    ``quadpoints_theta``, see the general documentation on :ref:`surfaces`.\n    Instead of supplying the quadrature point arrays along :math:`\\phi` and\n    :math:`\\theta` directions, one could also specify the number of\n    quadrature points for :math:`\\phi` and :math:`\\theta` using the\n    class method :py:meth:`~simsopt.geo.surface.Surface.from_nphi_ntheta`.\n\n    Args:\n        nfp: The number of field periods.\n        stellsym: Whether the surface is stellarator-symmetric, i.e.\n          symmetry under rotation by :math:`\\pi` about the x-axis.\n        mpol: Maximum poloidal mode number included.\n        ntor: Maximum toroidal mode number included, divided by ``nfp``.\n        quadpoints_phi: Set this to a list or 1D array to set the :math:`\\phi_j` grid points directly.\n        quadpoints_theta: Set this to a list or 1D array to set the :math:`\\theta_j` grid points directly.\n    \"\"\"\n\n    def __init__(self, nfp=1, stellsym=True, mpol=1, ntor=0,\n                 quadpoints_phi=None, quadpoints_theta=None,\n                 dofs=None):\n\n        if quadpoints_theta is None:\n            quadpoints_theta = Surface.get_theta_quadpoints()\n        if quadpoints_phi is None:\n            quadpoints_phi = Surface.get_phi_quadpoints(nfp=nfp)\n\n        sopp.SurfaceRZFourier.__init__(self, mpol, ntor, nfp, stellsym,\n                                       quadpoints_phi, quadpoints_theta)\n        self.rc[0, ntor] = 1.0\n        self.rc[1, ntor] = 0.1\n        self.zs[1, ntor] = 0.1\n        if dofs is None:\n            Surface.__init__(self, x0=self.get_dofs(),\n                             external_dof_setter=SurfaceRZFourier.set_dofs_impl,\n                             names=self._make_names())\n        else:\n            Surface.__init__(self, dofs=dofs,\n                             external_dof_setter=SurfaceRZFourier.set_dofs_impl)\n        self._make_mn()\n\n    def get_dofs(self):\n        \"\"\"\n        Return the dofs associated to this surface.\n        \"\"\"\n        return np.asarray(sopp.SurfaceRZFourier.get_dofs(self))\n\n    def set_dofs(self, dofs):\n        self.local_full_x = dofs\n\n    def _make_names(self):\n        \"\"\"\n        Form a list of names of the ``rc``, ``zs``, ``rs``, or ``zc``\n        array elements.  The order of these four arrays here must\n        match the order in ``set_dofs_impl()`` and ``get_dofs()`` in\n        ``src/simsoptpp/surfacerzfourier.h``.\n        \"\"\"\n        if self.stellsym:\n            names = self._make_names_helper('rc', True) + self._make_names_helper('zs', False)\n        else:\n            names = self._make_names_helper('rc', True) \\\n                + self._make_names_helper('rs', False) \\\n                + self._make_names_helper('zc', True) \\\n                + self._make_names_helper('zs', False)\n        return names\n\n    def _make_names_helper(self, prefix, include0):\n        if include0:\n            names = [prefix + \"(0,0)\"]\n        else:\n            names = []\n\n        names += [prefix + '(0,' + str(n) + ')' for n in range(1, self.ntor + 1)]\n        for m in range(1, self.mpol + 1):\n            names += [prefix + '(' + str(m) + ',' + str(n) + ')' for n in range(-self.ntor, self.ntor + 1)]\n        return names\n\n    def _make_mn(self):\n        \"\"\"\n        Make the list of m and n values.\n        \"\"\"\n        m1d = np.arange(self.mpol + 1)\n        n1d = np.arange(-self.ntor, self.ntor + 1)\n        n2d, m2d = np.meshgrid(n1d, m1d)\n        m0 = m2d.flatten()[self.ntor:]\n        n0 = n2d.flatten()[self.ntor:]\n        m = np.concatenate((m0, m0[1:]))\n        n = np.concatenate((n0, n0[1:]))\n        if not self.stellsym:\n            m = np.concatenate((m, m))\n            n = np.concatenate((n, n))\n        self.m = m\n        self.n = n\n\n    @classmethod\n    def from_wout(cls, filename: str, s: float = 1.0,\n                  interp_kind: str = 'linear',\n                  **kwargs):\n        \"\"\"\n        Read in a surface from a VMEC wout output file. Note that this\n        function does not require the VMEC python module.\n\n        Args:\n            filename: Name of the ``wout_*.nc`` file to read.\n            s: Value of normalized toroidal flux to use for the surface.\n              The default value of 1.0 corresponds to the VMEC plasma boundary.\n              Must lie in the interval [0, 1].\n            interp_kind: Interpolation method in s. The available options correspond to\n              the ``kind`` argument of\n              `scipy.interpolate.interp1d <https://docs.scipy.org/doc/scipy/reference/generated/scipy.interpolate.interp1d.html#scipy-interpolate-interp1d>`_.\n            kwargs: Any other arguments to pass to the ``SurfaceRZFourier`` constructor.\n              You can specify ``quadpoints_theta`` and ``quadpoints_phi`` here.\n        \"\"\"\n\n        if s < 0 or s > 1:\n            raise ValueError('s must lie in the interval [0, 1]')\n\n        f = netcdf_file(filename, mmap=False)\n        nfp = f.variables['nfp'][()]\n        ns = f.variables['ns'][()]\n        xm = f.variables['xm'][()]\n        xn = f.variables['xn'][()]\n        rmnc = f.variables['rmnc'][()]\n        zmns = f.variables['zmns'][()]\n        lasym = bool(f.variables['lasym__logical__'][()])\n        stellsym = not lasym\n        if lasym:\n            rmns = f.variables['rmns'][()]\n            zmnc = f.variables['zmnc'][()]\n        f.close()\n\n        # Interpolate in s:\n        s_full_grid = np.linspace(0.0, 1.0, ns)\n\n        interp = interp1d(s_full_grid, rmnc, kind=interp_kind, axis=0)\n        rbc = interp(s)\n\n        interp = interp1d(s_full_grid, zmns, kind=interp_kind, axis=0)\n        zbs = interp(s)\n\n        if lasym:\n            interp = interp1d(s_full_grid, rmns, kind=interp_kind, axis=0)\n            rbs = interp(s)\n\n            interp = interp1d(s_full_grid, zmnc, kind=interp_kind, axis=0)\n            zbc = interp(s)\n\n        mpol = int(np.max(xm))\n        ntor = int(np.max(np.abs(xn)) / nfp)\n\n        ntheta = kwargs.pop(\"ntheta\", None)\n        nphi = kwargs.pop(\"nphi\", None)\n        grid_range = kwargs.pop(\"range\", None)\n\n        if ntheta is not None or nphi is not None:\n            kwargs[\"quadpoints_phi\"], kwargs[\"quadpoints_theta\"] = Surface.get_quadpoints(\n                ntheta=ntheta, nphi=nphi, nfp=nfp, range=grid_range)\n\n        surf = cls(mpol=mpol, ntor=ntor, nfp=nfp, stellsym=stellsym,\n                   **kwargs)\n\n        for j in range(len(xm)):\n            m = int(xm[j])\n            n = int(xn[j] / nfp)\n            surf.rc[m, n + ntor] = rbc[j]\n            surf.zs[m, n + ntor] = zbs[j]\n            if not stellsym:\n                surf.rs[m, n + ntor] = rbs[j]\n                surf.zc[m, n + ntor] = zbc[j]\n\n        surf.local_full_x = surf.get_dofs()\n        return surf\n\n    @classmethod\n    def from_vmec_input(cls, filename: str, **kwargs):\n        \"\"\"\n        Read in a surface from a VMEC input file. The ``INDATA`` namelist\n        of this file will be read using `f90nml\n        <https://f90nml.readthedocs.io/en/latest/index.html>`_. Note\n        that this function does not require the VMEC python module.\n\n        Args:\n            filename: Name of the ``input.*`` file to read.\n            kwargs: Any other arguments to pass to the ``SurfaceRZFourier`` constructor.\n              You can specify ``quadpoints_theta`` and ``quadpoints_phi`` here.\n        \"\"\"\n\n        all_namelists = f90nml.read(filename)\n        # We only care about the 'indata' namelist\n        nml = all_namelists['indata']\n        if 'nfp' in nml:\n            nfp = nml['nfp']\n        else:\n            nfp = 1\n\n        if 'lasym' in nml:\n            lasym = nml['lasym']\n        else:\n            lasym = False\n        stellsym = not lasym\n\n        # We can assume rbc and zbs are specified in the namelist.\n        # f90nml returns rbc and zbs as a list of lists where the\n        # inner lists do not necessarily all have the same\n        # dimension. Hence we need to be careful when converting to\n        # numpy arrays.\n        rc = nested_lists_to_array(nml['rbc'])\n        zs = nested_lists_to_array(nml['zbs'])\n        if lasym:\n            rs = nested_lists_to_array(nml['rbs'])\n            zc = nested_lists_to_array(nml['zbc'])\n\n        rbc_first_n = nml.start_index['rbc'][0]\n        rbc_last_n = rbc_first_n + rc.shape[1] - 1\n        zbs_first_n = nml.start_index['zbs'][0]\n        zbs_last_n = zbs_first_n + zs.shape[1] - 1\n        if lasym:\n            rbs_first_n = nml.start_index['rbs'][0]\n            rbs_last_n = rbs_first_n + rs.shape[1] - 1\n            zbc_first_n = nml.start_index['zbc'][0]\n            zbc_last_n = zbc_first_n + zc.shape[1] - 1\n        else:\n            rbs_first_n = 0\n            rbs_last_n = 0\n            zbc_first_n = 0\n            zbc_last_n = 0\n        ntor_boundary = np.max(np.abs(np.array([rbc_first_n, rbc_last_n,\n                                                zbs_first_n, zbs_last_n,\n                                                rbs_first_n, rbs_last_n,\n                                                zbc_first_n, zbc_last_n], dtype='i')))\n\n        rbc_first_m = nml.start_index['rbc'][1]\n        rbc_last_m = rbc_first_m + rc.shape[0] - 1\n        zbs_first_m = nml.start_index['zbs'][1]\n        zbs_last_m = zbs_first_m + zs.shape[0] - 1\n        if lasym:\n            rbs_first_m = nml.start_index['rbs'][1]\n            rbs_last_m = rbs_first_m + rs.shape[0] - 1\n            zbc_first_m = nml.start_index['zbc'][1]\n            zbc_last_m = zbc_first_m + zc.shape[0] - 1\n        else:\n            rbs_first_m = 0\n            rbs_last_m = 0\n            zbc_first_m = 0\n            zbc_last_m = 0\n        mpol_boundary = np.max((rbc_last_m, zbs_last_m, rbs_last_m, zbc_last_m))\n        logger.debug('Input file has ntor_boundary={} mpol_boundary={}' \\\n                     .format(ntor_boundary, mpol_boundary))\n\n        ntheta = kwargs.pop(\"ntheta\", None)\n        nphi = kwargs.pop(\"nphi\", None)\n        grid_range = kwargs.pop(\"range\", None)\n\n        if ntheta is not None or nphi is not None:\n            kwargs[\"quadpoints_phi\"], kwargs[\"quadpoints_theta\"] = Surface.get_quadpoints(\n                ntheta=ntheta, nphi=nphi, nfp=nfp, range=grid_range)\n\n        surf = cls(mpol=mpol_boundary, ntor=ntor_boundary, nfp=nfp, stellsym=stellsym,\n                   **kwargs)\n\n        # Transfer boundary shape data from the namelist to the surface object:\n        # In these loops, we set surf.rc/zs rather than call surf.set_rc() for speed.\n        for jm in range(rc.shape[0]):\n            m = jm + nml.start_index['rbc'][1]\n            for jn in range(rc.shape[1]):\n                n = jn + nml.start_index['rbc'][0]\n                surf.rc[m, n + ntor_boundary] = rc[jm, jn]\n\n        for jm in range(zs.shape[0]):\n            m = jm + nml.start_index['zbs'][1]\n            for jn in range(zs.shape[1]):\n                n = jn + nml.start_index['zbs'][0]\n                surf.zs[m, n + ntor_boundary] = zs[jm, jn]\n\n        if lasym:\n            for jm in range(rs.shape[0]):\n                m = jm + nml.start_index['rbs'][1]\n                for jn in range(rs.shape[1]):\n                    n = jn + nml.start_index['rbs'][0]\n                    surf.rs[m, n + ntor_boundary] = rs[jm, jn]\n\n            for jm in range(zc.shape[0]):\n                m = jm + nml.start_index['zbc'][1]\n                for jn in range(zc.shape[1]):\n                    n = jn + nml.start_index['zbc'][0]\n                    surf.zc[m, n + ntor_boundary] = zc[jm, jn]\n\n        # Sync the dofs:\n        surf.local_full_x = surf.get_dofs()\n        return surf\n\n    @classmethod\n    def from_focus(cls, filename, **kwargs):\n        \"\"\"\n        Read in a surface from a FOCUS-format file.\n        \"\"\"\n        with open(filename, 'r') as f:\n            lines = f.readlines()\n\n        # Read the line containing Nfou and nfp:\n        splitline = lines[1].split()\n        errmsg = \"This does not appear to be a FOCUS-format file.\"\n        assert len(splitline) == 3, errmsg\n        Nfou = int(splitline[0])\n        nfp = int(splitline[1])\n\n        # Now read the Fourier amplitudes:\n        n = np.full(Nfou, 0)\n        m = np.full(Nfou, 0)\n        rc = np.zeros(Nfou)\n        rs = np.zeros(Nfou)\n        zc = np.zeros(Nfou)\n        zs = np.zeros(Nfou)\n        for j in range(Nfou):\n            splitline = lines[j + 4].split()\n            n[j] = int(splitline[0])\n            m[j] = int(splitline[1])\n            rc[j] = float(splitline[2])\n            rs[j] = float(splitline[3])\n            zc[j] = float(splitline[4])\n            zs[j] = float(splitline[5])\n        assert np.min(m) == 0\n        stellsym = np.max(np.abs(rs)) == 0 and np.max(np.abs(zc)) == 0\n        mpol = int(np.max(m))\n        ntor = int(np.max(np.abs(n)))\n\n        ntheta = kwargs.pop(\"ntheta\", None)\n        nphi = kwargs.pop(\"nphi\", None)\n        grid_range = kwargs.pop(\"range\", None)\n\n        if ntheta is not None or nphi is not None:\n            kwargs[\"quadpoints_phi\"], kwargs[\"quadpoints_theta\"] = Surface.get_quadpoints(\n                ntheta=ntheta, nphi=nphi, nfp=nfp, range=grid_range)\n\n        surf = cls(mpol=mpol, ntor=ntor, nfp=nfp, stellsym=stellsym, **kwargs)\n\n        for j in range(Nfou):\n            surf.rc[m[j], n[j] + ntor] = rc[j]\n            surf.zs[m[j], n[j] + ntor] = zs[j]\n            if not stellsym:\n                surf.rs[m[j], n[j] + ntor] = rs[j]\n                surf.zc[m[j], n[j] + ntor] = zc[j]\n\n        surf.local_full_x = surf.get_dofs()\n        return surf\n\n    @classmethod\n    @SimsoptRequires(Qsc is not None, \"from_pyQSC method requires pyQSC module\")\n    def from_pyQSC(cls, stel: Qsc, r: float = 0.1, ntheta=20, mpol=10, ntor=20, **kwargs):\n        \"\"\"\n        Initialize the surface from a pyQSC object. This creates a surface\n        from a near-axis equilibrium with a specified minor radius `r` (in meters).\n\n        Args:\n            stel: Qsc object with a near-axis equilibrium.\n            r: the near-axis coordinate radius (in meters).\n            ntheta: number of points in the theta direction for the Fourier transform.\n            mpol: number of poloidal Fourier modes for the surface.\n            ntor: number of toroidal Fourier modes for the surface.\n            kwargs: Any other arguments to pass to the ``SurfaceRZFourier`` constructor.\n              You can specify ``quadpoints_theta`` and ``quadpoints_phi`` here.\n        \"\"\"\n        # Get surface shape at fixed off-axis toroidal angle phi\n        R_2D, Z_2D, _ = stel.Frenet_to_cylindrical(r, ntheta)\n\n        # Fourier transform the result.\n        RBC, RBS, ZBC, ZBS = to_Fourier(R_2D, Z_2D, stel.nfp, mpol, ntor, stel.lasym)\n\n        surf = cls(mpol=mpol, ntor=ntor, nfp=stel.nfp, stellsym=not stel.lasym, **kwargs)\n\n        surf.rc[:, :] = RBC.transpose()\n        surf.zs[:, :] = ZBS.transpose()\n        if stel.lasym:\n            surf.rs[:, :] = RBS.transpose()\n            surf.zc[:, :] = ZBC.transpose()\n\n        surf.local_full_x = surf.get_dofs()\n        return surf\n\n    def change_resolution(self, mpol, ntor):\n        \"\"\"\n        Change the values of `mpol` and `ntor`. Any new Fourier amplitudes\n        will have a magnitude of zero.  Any previous nonzero Fourier\n        amplitudes that are not within the new range will be\n        discarded.\n        \"\"\"\n        old_mpol = self.mpol\n        old_ntor = self.ntor\n        old_rc = self.rc\n        old_zs = self.zs\n        if not self.stellsym:\n            old_rs = self.rs\n            old_zc = self.zc\n        self.mpol = mpol\n        self.ntor = ntor\n        self.allocate()\n        if mpol < old_mpol or ntor < old_ntor:\n            self.invalidate_cache()\n\n        min_mpol = np.min((mpol, old_mpol))\n        min_ntor = np.min((ntor, old_ntor))\n        for m in range(min_mpol + 1):\n            for n in range(-min_ntor, min_ntor + 1):\n                self.rc[m, n + ntor] = old_rc[m, n + old_ntor]\n                self.zs[m, n + ntor] = old_zs[m, n + old_ntor]\n                if not self.stellsym:\n                    self.rs[m, n + ntor] = old_rs[m, n + old_ntor]\n                    self.zc[m, n + ntor] = old_zc[m, n + old_ntor]\n        self._make_mn()\n\n        # Update the dofs object\n        self.replace_dofs(DOFs(self.get_dofs(), self._make_names()))\n\n    def to_RZFourier(self):\n        \"\"\"\n        No conversion necessary.\n        \"\"\"\n        return self\n\n    def __repr__(self):\n        return self.name + f\" (nfp={self.nfp}, stellsym={self.stellsym}, \" + \\\n            f\"mpol={self.mpol}, ntor={self.ntor})\"\n\n    def _validate_mn(self, m, n):\n        \"\"\"\n        Check whether `m` and `n` are in the allowed range.\n        \"\"\"\n        if m < 0:\n            raise IndexError('m must be >= 0')\n        if m > self.mpol:\n            raise IndexError('m must be <= mpol')\n        if n > self.ntor:\n            raise IndexError('n must be <= ntor')\n        if n < -self.ntor:\n            raise IndexError('n must be >= -ntor')\n\n    def get_rc(self, m, n):\n        \"\"\"\n        Return a particular `rc` Parameter.\n        \"\"\"\n        self._validate_mn(m, n)\n        return self.rc[m, n + self.ntor]\n\n    def get_rs(self, m, n):\n        \"\"\"\n        Return a particular `rs` Parameter.\n        \"\"\"\n        if self.stellsym:\n            return ValueError(\n                'rs does not exist for this stellarator-symmetric surface.')\n        self._validate_mn(m, n)\n        return self.rs[m, n + self.ntor]\n\n    def get_zc(self, m, n):\n        \"\"\"\n        Return a particular `zc` Parameter.\n        \"\"\"\n        if self.stellsym:\n            return ValueError(\n                'zc does not exist for this stellarator-symmetric surface.')\n        self._validate_mn(m, n)\n        return self.zc[m, n + self.ntor]\n\n    def get_zs(self, m, n):\n        \"\"\"\n        Return a particular `zs` Parameter.\n        \"\"\"\n        self._validate_mn(m, n)\n        return self.zs[m, n + self.ntor]\n\n    def set_rc(self, m, n, val):\n        \"\"\"\n        Set a particular `rc` Parameter.\n        \"\"\"\n        self._validate_mn(m, n)\n        self.rc[m, n + self.ntor] = val\n        self.local_full_x = self.get_dofs()\n\n    def set_rs(self, m, n, val):\n        \"\"\"\n        Set a particular `rs` Parameter.\n        \"\"\"\n        if self.stellsym:\n            return ValueError(\n                'rs does not exist for this stellarator-symmetric surface.')\n        self._validate_mn(m, n)\n        self.rs[m, n + self.ntor] = val\n        self.local_full_x = self.get_dofs()\n\n    def set_zc(self, m, n, val):\n        \"\"\"\n        Set a particular `zc` Parameter.\n        \"\"\"\n        if self.stellsym:\n            return ValueError(\n                'zc does not exist for this stellarator-symmetric surface.')\n        self._validate_mn(m, n)\n        self.zc[m, n + self.ntor] = val\n        self.local_full_x = self.get_dofs()\n\n    def set_zs(self, m, n, val):\n        \"\"\"\n        Set a particular `zs` Parameter.\n        \"\"\"\n        self._validate_mn(m, n)\n        self.zs[m, n + self.ntor] = val\n        self.local_full_x = self.get_dofs()\n\n    def fixed_range(self, mmin, mmax, nmin, nmax, fixed=True):\n        \"\"\"\n        Set the 'fixed' property for a range of `m` and `n` values.\n\n        All modes with `m` in the interval [`mmin`, `mmax`] and `n` in the\n        interval [`nmin`, `nmax`] will have their fixed property set to\n        the value of the `fixed` parameter. Note that `mmax` and `nmax`\n        are included (unlike the upper bound in python's range(min,\n        max).)\n        \"\"\"\n        # TODO: This will be slow because free dof indices are evaluated all\n        # TODO: the time in the loop\n        fn = self.fix if fixed else self.unfix\n        for m in range(mmin, mmax + 1):\n            this_nmin = nmin\n            if m == 0 and nmin < 0:\n                this_nmin = 0\n            for n in range(this_nmin, nmax + 1):\n                fn(f'rc({m},{n})')\n                if m > 0 or n != 0:\n                    fn(f'zs({m},{n})')\n                if not self.stellsym:\n                    fn(f'zc({m},{n})')\n                    if m > 0 or n != 0:\n                        fn(f'rs({m},{n})')\n\n    def recompute_bell(self, parent=None):\n        self.invalidate_cache()\n\n    def darea(self):\n        \"\"\"\n        Short hand for `Surface.darea_by_dcoeff()`\n        \"\"\"\n        return self.darea_by_dcoeff()\n\n    def dvolume(self):\n        \"\"\"\n        Short hand for `Surface.dvolume_by_dcoeff()`\n        \"\"\"\n        return self.dvolume_by_dcoeff()\n\n    def get_nml(self):\n        \"\"\"\n        Generates a fortran namelist file containing the RBC/RBS/ZBC/ZBS\n        coefficients, in the form used in VMEC and SPEC input\n        files. The result will be returned as a string. For saving a\n        file, see the ``write_nml()`` function.\n        \"\"\"\n        nml = ''\n        nml += '&INDATA\\n'\n        if self.stellsym:\n            nml += 'LASYM = .FALSE.\\n'\n        else:\n            nml += 'LASYM = .TRUE.\\n'\n        nml += f'NFP = {self.nfp}\\n'\n\n        for m in range(self.mpol + 1):\n            nmin = -self.ntor\n            if m == 0:\n                nmin = 0\n            for n in range(nmin, self.ntor + 1):\n                rc = self.get_rc(m, n)\n                zs = self.get_zs(m, n)\n                if np.abs(rc) > 0 or np.abs(zs) > 0:\n                    nml += f\"RBC({n:4d},{m:4d}) ={rc:23.15e},    ZBS({n:4d},{m:4d}) ={zs:23.15e}\\n\"\n                if (not self.stellsym):\n                    rs = self.get_rs(m, n)\n                    zc = self.get_zc(m, n)\n                    if np.abs(rs) > 0 or np.abs(zc) > 0:\n                        nml += f\"RBS({n:4d},{m:4d}) ={rs:23.15e},    ZBC({n:4d},{m:4d}) ={zc:23.15e}\\n\"\n        nml += '/\\n'\n        return nml\n\n    def write_nml(self, filename: str):\n        \"\"\"\n        Writes a fortran namelist file containing the RBC/RBS/ZBC/ZBS\n        coefficients, in the form used in VMEC and SPEC input\n        files. To just generate the namelist as a string without\n        saving a file, see the ``get_nml()`` function.\n\n        Args:\n            filename: Name of the file to write.\n        \"\"\"\n        with open(filename, 'w') as f:\n            f.write(self.get_nml())\n\n    return_fn_map = {'area': sopp.SurfaceRZFourier.area,\n                     'volume': sopp.SurfaceRZFourier.volume,\n                     'aspect-ratio': Surface.aspect_ratio}",
  "class SurfaceRZPseudospectral(Optimizable):\n    \"\"\"\n    This class is used to replace the Fourier-space dofs of\n    :obj:`SurfaceRZFourier` with real-space dofs, corresponding to the\n    position of the surface on grid points.  The advantage of having\n    the dofs in real-space is that they are all of the same magnitude,\n    so it is easier to know what reasonable box constraints are. This\n    class may therefore be useful for stage-1 optimization using\n    algorithms that require box constraints.\n\n    Presently, ``SurfaceRZPseudospectral`` assumes stellarator\n    symmetry.\n\n    In this class, the position vector on the surface is specified on\n    a tensor product grid of ``ntheta * nphi`` points per half period,\n    where ``ntheta`` and ``nphi`` are both odd, ``phi`` is the\n    standard toroidal angle, and ``theta`` is any poloidal angle. The\n    maximum Fourier mode numbers that can be represented by this grid\n    are ``mpol`` in the poloidal angle and ``ntor * nfp`` in the\n    toroidal angle, where ``ntheta = 1 + 2 * mpol`` and ``nphi = 1 + 2\n    * ntor``. However, due to stellarator symmetry, roughly half of\n    the grid points are redundant. Therefore the dofs only correspond\n    to the non-redundant points, and the remaining points are computed\n    from the dofs using symmetry.\n\n    A ``SurfaceRZPseudospectral`` object with resolution parameters\n    ``mpol`` and ``ntor`` has exactly the same number of dofs as a\n    :obj:`SurfaceRZFourier` object with the same ``mpol`` and\n    ``ntor``.  Specifically,\n\n    .. code-block::\n\n        ndofs = 1 + 2 * (mpol + ntor + 2 * mpol * ntor)\n\n    This class also allows the coordinates ``r`` and ``z`` to be\n    shifted and scaled, which may help to keep the dofs all of order\n    1. Letting ``r_dofs`` and ``z_dofs`` denote the dofs in this\n    class, the actual ``r`` and ``z`` coordinates are determined via\n\n    .. code-block::\n\n        r = r_dofs * a_scale + r_shift\n        z = z_dofs * a_scale\n\n    where ``r_shift`` and ``a_scale`` are optional arguments to the\n    constructor, which would be set to roughly the major and minor\n    radius.\n\n    Typical usage::\n\n        vmec = Vmec(\"input.your_filename_here\")\n        vmec.boundary = SurfaceRZPseudospectral.from_RZFourier(vmec.boundary)\n\n    The dofs in this class are named ``r(jphi,jtheta)`` and\n    ``z(jphi,jtheta)``, where ``jphi`` and ``jtheta`` are integer\n    indices into the ``phi`` and ``theta`` grids.\n\n    This class does not presently implement the\n    :obj:`simsopt.geo.surface.Surface` interface, e.g. there is not a\n    ``gamma()`` function.\n\n    Args:\n        mpol: Maximum poloidal Fourier mode number represented.\n        ntor: The maximum toroidal Fourier mode number represented, divided by ``nfp``.\n        nfp: Number of field periods.\n        r_shift: Constant added to the ``r(jphi,jtheta)`` dofs to get the actual major radius.\n        a_scale: Dofs are multiplied by this factor to get the actual cylindrical coordinates.\n    \"\"\"\n\n    def __init__(self, mpol, ntor, nfp, r_shift=1.0, a_scale=1.0, **kwargs):\n        self.mpol = mpol\n        self.ntor = ntor\n        self.nfp = nfp\n        self.r_shift = r_shift\n        self.a_scale = a_scale\n        ndofs = 1 + 2 * (ntor + mpol * (2 * ntor + 1))\n        if \"dofs\" not in kwargs:\n            if \"x0\" not in kwargs:\n                kwargs[\"x0\"] = np.zeros(ndofs)\n            else:\n                assert (len(kwargs[\"x0\"]) == ndofs)\n            if \"names\" not in kwargs:\n                kwargs[\"names\"] = self._make_names()\n            else:\n                assert (len(kwargs[\"names\"]) == ndofs)\n        else:\n            assert (len(kwargs[\"dofs\"]) == ndofs)\n        super().__init__(**kwargs)\n\n    def _make_names(self):\n        \"\"\"\n        Create the list of names for the dofs.\n        \"\"\"\n        names = ['r(0,0)']\n        for dimension in ['r', 'z']:\n            for jtheta in range(1, self.mpol + 1):\n                names.append(dimension + f'(0,{jtheta})')\n            for jphi in range(1, self.ntor + 1):\n                for jtheta in range(2 * self.mpol + 1):\n                    names.append(dimension + f'({jphi},{jtheta})')\n        return names\n\n    @classmethod\n    def from_RZFourier(cls, surff, **kwargs):\n        \"\"\"\n        Convert a :obj:`SurfaceRZFourier` object to a\n        ``SurfaceRZPseudospectral`` object.\n\n        Args:\n            surff: The :obj:`SurfaceRZFourier` object to convert.\n            kwargs: You can optionally provide the ``r_shift`` or ``a_scale`` arguments\n              to the ``SurfaceRZPseudospectral`` constructor here.\n        \"\"\"\n        if not surff.stellsym:\n            raise RuntimeError('SurfaceRZPseudospectral presently only '\n                               'supports stellarator-symmetric surfaces')\n\n        # shorthand:\n        mpol = surff.mpol\n        ntor = surff.ntor\n        ntheta = 2 * mpol + 1\n        nphi = 2 * ntor + 1\n\n        # Make a copy of surff with the desired theta and phi points.\n        surf_copy = SurfaceRZFourier.from_nphi_ntheta(\n            mpol=mpol, ntor=ntor, nfp=surff.nfp,\n            range='field period', ntheta=ntheta, nphi=nphi)\n        surf_copy.x = surff.local_full_x\n\n        surf_new = cls(mpol=mpol, ntor=ntor, nfp=surff.nfp, **kwargs)\n        gamma = surf_copy.gamma()\n        r0 = np.sqrt(gamma[:, :, 0] ** 2 + gamma[:, :, 1] ** 2)\n        r = (r0 - surf_new.r_shift) / surf_new.a_scale\n        z = gamma[:, :, 2] / surf_new.a_scale\n\n        dofs = np.zeros_like(surf_new.full_x)\n        ndofs = len(dofs)\n        index = 0\n        for jtheta in range(mpol + 1):\n            dofs[index] = r[0, jtheta]\n            index += 1\n        for jphi in range(1, ntor + 1):\n            for jtheta in range(ntheta):\n                dofs[index] = r[jphi, jtheta]\n                index += 1\n        for jtheta in range(1, mpol + 1):\n            dofs[index] = z[0, jtheta]\n            index += 1\n        for jphi in range(1, ntor + 1):\n            for jtheta in range(ntheta):\n                dofs[index] = z[jphi, jtheta]\n                index += 1\n        assert index == ndofs\n        surf_new.x = dofs\n        return surf_new\n\n    def _complete_grid(self):\n        \"\"\"\n        Using stellarator symmetry, copy the real-space dofs to cover a\n        full 2d ``(theta, phi)`` grid.\n        \"\"\"\n\n        # shorthand:\n        mpol = self.mpol\n        ntor = self.ntor\n        ntheta = 2 * mpol + 1\n        nphi = 2 * ntor + 1\n\n        r = np.zeros((ntheta, nphi))\n        z = np.zeros((ntheta, nphi))\n        r[0, 0] = self.x[0]\n        shift = mpol + ntor * (2 * mpol + 1)  # = mpol + ntor + 2 * mpol * ntor\n        assert 2 * shift + 1 == len(self.x)\n        for jtheta in range(1, mpol + 1):\n            r[jtheta, 0] = self.x[jtheta]\n            r[ntheta - jtheta, 0] = self.x[jtheta]\n            assert self.local_dof_names[jtheta + shift] == f'z(0,{jtheta})'\n            z[jtheta, 0] = self.x[jtheta + shift]\n            z[ntheta - jtheta, 0] = -self.x[jtheta + shift]\n        for jphi in range(1, ntor + 1):\n            for jtheta in range(ntheta):\n                index = (jphi - 1) * ntheta + jtheta + mpol + 1\n                assert self.local_dof_names[index] == f'r({jphi},{jtheta})'\n                assert self.local_dof_names[index + shift] == f'z({jphi},{jtheta})'\n                r[jtheta, jphi] = self.x[index]\n                z[jtheta, jphi] = self.x[index + shift]\n                if jtheta == 0:\n                    r[0, nphi - jphi] = self.x[index]\n                    z[0, nphi - jphi] = -self.x[index + shift]\n                else:\n                    r[ntheta - jtheta, nphi - jphi] = self.x[index]\n                    z[ntheta - jtheta, nphi - jphi] = -self.x[index + shift]\n\n        r2 = self.r_shift + self.a_scale * r\n        z2 = self.a_scale * z\n        return r2, z2\n\n    def to_RZFourier(self, **kwargs):\n        \"\"\"\n        Convert to a :obj:`SurfaceRZFourier` describing the same shape.\n\n        Args:\n            kwargs: You can optionally provide the ``range``, ``nphi``,\n              and/or ``ntheta`` arguments to the :obj:`SurfaceRZFourier` constructor here.\n        \"\"\"\n        # shorthand:\n        mpol = self.mpol\n        ntor = self.ntor\n\n        r, z = self._complete_grid()\n        # What follows is a Fourier transform. We could use an FFT,\n        # but since speed is not a concern here for now, the Fourier\n        # transform is just done \"by hand\" so there is no uncertainty\n        # about normalizations etc.\n\n        ntheta = kwargs.pop(\"ntheta\", None)\n        nphi = kwargs.pop(\"nphi\", None)\n        grid_range = kwargs.pop(\"range\", None)\n\n        if ntheta is not None or nphi is not None:\n            kwargs[\"quadpoints_phi\"], kwargs[\"quadpoints_theta\"] = Surface.get_quadpoints(\n                ntheta=ntheta, nphi=nphi, nfp=self.nfp, range=grid_range)\n\n        surf = SurfaceRZFourier(mpol=mpol, ntor=ntor, nfp=self.nfp, **kwargs)\n        surf.set_rc(0, 0, np.mean(r))\n        ntheta = 2 * mpol + 1\n        nphi = 2 * ntor + 1\n        theta1d = np.linspace(0, 2 * np.pi, ntheta, endpoint=False)\n        phi1d = np.linspace(0, 2 * np.pi, nphi, endpoint=False)\n        phi, theta = np.meshgrid(phi1d, theta1d)\n        for n in range(1, ntor + 1):\n            surf.set_rc(0, n, 2 * np.mean(r * np.cos(-n * phi)))\n            surf.set_zs(0, n, 2 * np.mean(z * np.sin(-n * phi)))\n        for m in range(1, mpol + 1):\n            for n in range(-ntor, ntor + 1):\n                surf.set_rc(m, n, 2 * np.mean(r * np.cos(m * theta - n * phi)))\n                surf.set_zs(m, n, 2 * np.mean(z * np.sin(m * theta - n * phi)))\n\n        return surf\n\n    def change_resolution(self, mpol, ntor):\n        \"\"\"\n        Increase or decrease the number of degrees of freedom.  The new\n        real-space dofs are obtained using Fourier interpolation. This\n        function is useful for increasing the size of the parameter\n        space during stage-1 optimization. If ``mpol`` and ``ntor``\n        are increased or unchanged, there is no loss of information.\n        If ``mpol`` or ``ntor`` are decreased, information is lost.\n\n        Args:\n            mpol: The new maximum poloidal mode number.\n            ntor: The new maximum toroidal mode number, divided by ``nfp``.\n        \"\"\"\n        # Map to Fourier space:\n        surf2 = self.to_RZFourier()\n        # Change the resolution in Fourier space, by truncating the modes or padding 0s:\n        surf2.change_resolution(mpol=mpol, ntor=ntor)\n        # Map from Fourier space back to real space:\n        surf3 = SurfaceRZPseudospectral.from_RZFourier(surf2,\n                                                       r_shift=self.r_shift,\n                                                       a_scale=self.a_scale)\n        return surf3",
  "def __init__(self, nfp=1, stellsym=True, mpol=1, ntor=0,\n                 quadpoints_phi=None, quadpoints_theta=None,\n                 dofs=None):\n\n        if quadpoints_theta is None:\n            quadpoints_theta = Surface.get_theta_quadpoints()\n        if quadpoints_phi is None:\n            quadpoints_phi = Surface.get_phi_quadpoints(nfp=nfp)\n\n        sopp.SurfaceRZFourier.__init__(self, mpol, ntor, nfp, stellsym,\n                                       quadpoints_phi, quadpoints_theta)\n        self.rc[0, ntor] = 1.0\n        self.rc[1, ntor] = 0.1\n        self.zs[1, ntor] = 0.1\n        if dofs is None:\n            Surface.__init__(self, x0=self.get_dofs(),\n                             external_dof_setter=SurfaceRZFourier.set_dofs_impl,\n                             names=self._make_names())\n        else:\n            Surface.__init__(self, dofs=dofs,\n                             external_dof_setter=SurfaceRZFourier.set_dofs_impl)\n        self._make_mn()",
  "def get_dofs(self):\n        \"\"\"\n        Return the dofs associated to this surface.\n        \"\"\"\n        return np.asarray(sopp.SurfaceRZFourier.get_dofs(self))",
  "def set_dofs(self, dofs):\n        self.local_full_x = dofs",
  "def _make_names(self):\n        \"\"\"\n        Form a list of names of the ``rc``, ``zs``, ``rs``, or ``zc``\n        array elements.  The order of these four arrays here must\n        match the order in ``set_dofs_impl()`` and ``get_dofs()`` in\n        ``src/simsoptpp/surfacerzfourier.h``.\n        \"\"\"\n        if self.stellsym:\n            names = self._make_names_helper('rc', True) + self._make_names_helper('zs', False)\n        else:\n            names = self._make_names_helper('rc', True) \\\n                + self._make_names_helper('rs', False) \\\n                + self._make_names_helper('zc', True) \\\n                + self._make_names_helper('zs', False)\n        return names",
  "def _make_names_helper(self, prefix, include0):\n        if include0:\n            names = [prefix + \"(0,0)\"]\n        else:\n            names = []\n\n        names += [prefix + '(0,' + str(n) + ')' for n in range(1, self.ntor + 1)]\n        for m in range(1, self.mpol + 1):\n            names += [prefix + '(' + str(m) + ',' + str(n) + ')' for n in range(-self.ntor, self.ntor + 1)]\n        return names",
  "def _make_mn(self):\n        \"\"\"\n        Make the list of m and n values.\n        \"\"\"\n        m1d = np.arange(self.mpol + 1)\n        n1d = np.arange(-self.ntor, self.ntor + 1)\n        n2d, m2d = np.meshgrid(n1d, m1d)\n        m0 = m2d.flatten()[self.ntor:]\n        n0 = n2d.flatten()[self.ntor:]\n        m = np.concatenate((m0, m0[1:]))\n        n = np.concatenate((n0, n0[1:]))\n        if not self.stellsym:\n            m = np.concatenate((m, m))\n            n = np.concatenate((n, n))\n        self.m = m\n        self.n = n",
  "def from_wout(cls, filename: str, s: float = 1.0,\n                  interp_kind: str = 'linear',\n                  **kwargs):\n        \"\"\"\n        Read in a surface from a VMEC wout output file. Note that this\n        function does not require the VMEC python module.\n\n        Args:\n            filename: Name of the ``wout_*.nc`` file to read.\n            s: Value of normalized toroidal flux to use for the surface.\n              The default value of 1.0 corresponds to the VMEC plasma boundary.\n              Must lie in the interval [0, 1].\n            interp_kind: Interpolation method in s. The available options correspond to\n              the ``kind`` argument of\n              `scipy.interpolate.interp1d <https://docs.scipy.org/doc/scipy/reference/generated/scipy.interpolate.interp1d.html#scipy-interpolate-interp1d>`_.\n            kwargs: Any other arguments to pass to the ``SurfaceRZFourier`` constructor.\n              You can specify ``quadpoints_theta`` and ``quadpoints_phi`` here.\n        \"\"\"\n\n        if s < 0 or s > 1:\n            raise ValueError('s must lie in the interval [0, 1]')\n\n        f = netcdf_file(filename, mmap=False)\n        nfp = f.variables['nfp'][()]\n        ns = f.variables['ns'][()]\n        xm = f.variables['xm'][()]\n        xn = f.variables['xn'][()]\n        rmnc = f.variables['rmnc'][()]\n        zmns = f.variables['zmns'][()]\n        lasym = bool(f.variables['lasym__logical__'][()])\n        stellsym = not lasym\n        if lasym:\n            rmns = f.variables['rmns'][()]\n            zmnc = f.variables['zmnc'][()]\n        f.close()\n\n        # Interpolate in s:\n        s_full_grid = np.linspace(0.0, 1.0, ns)\n\n        interp = interp1d(s_full_grid, rmnc, kind=interp_kind, axis=0)\n        rbc = interp(s)\n\n        interp = interp1d(s_full_grid, zmns, kind=interp_kind, axis=0)\n        zbs = interp(s)\n\n        if lasym:\n            interp = interp1d(s_full_grid, rmns, kind=interp_kind, axis=0)\n            rbs = interp(s)\n\n            interp = interp1d(s_full_grid, zmnc, kind=interp_kind, axis=0)\n            zbc = interp(s)\n\n        mpol = int(np.max(xm))\n        ntor = int(np.max(np.abs(xn)) / nfp)\n\n        ntheta = kwargs.pop(\"ntheta\", None)\n        nphi = kwargs.pop(\"nphi\", None)\n        grid_range = kwargs.pop(\"range\", None)\n\n        if ntheta is not None or nphi is not None:\n            kwargs[\"quadpoints_phi\"], kwargs[\"quadpoints_theta\"] = Surface.get_quadpoints(\n                ntheta=ntheta, nphi=nphi, nfp=nfp, range=grid_range)\n\n        surf = cls(mpol=mpol, ntor=ntor, nfp=nfp, stellsym=stellsym,\n                   **kwargs)\n\n        for j in range(len(xm)):\n            m = int(xm[j])\n            n = int(xn[j] / nfp)\n            surf.rc[m, n + ntor] = rbc[j]\n            surf.zs[m, n + ntor] = zbs[j]\n            if not stellsym:\n                surf.rs[m, n + ntor] = rbs[j]\n                surf.zc[m, n + ntor] = zbc[j]\n\n        surf.local_full_x = surf.get_dofs()\n        return surf",
  "def from_vmec_input(cls, filename: str, **kwargs):\n        \"\"\"\n        Read in a surface from a VMEC input file. The ``INDATA`` namelist\n        of this file will be read using `f90nml\n        <https://f90nml.readthedocs.io/en/latest/index.html>`_. Note\n        that this function does not require the VMEC python module.\n\n        Args:\n            filename: Name of the ``input.*`` file to read.\n            kwargs: Any other arguments to pass to the ``SurfaceRZFourier`` constructor.\n              You can specify ``quadpoints_theta`` and ``quadpoints_phi`` here.\n        \"\"\"\n\n        all_namelists = f90nml.read(filename)\n        # We only care about the 'indata' namelist\n        nml = all_namelists['indata']\n        if 'nfp' in nml:\n            nfp = nml['nfp']\n        else:\n            nfp = 1\n\n        if 'lasym' in nml:\n            lasym = nml['lasym']\n        else:\n            lasym = False\n        stellsym = not lasym\n\n        # We can assume rbc and zbs are specified in the namelist.\n        # f90nml returns rbc and zbs as a list of lists where the\n        # inner lists do not necessarily all have the same\n        # dimension. Hence we need to be careful when converting to\n        # numpy arrays.\n        rc = nested_lists_to_array(nml['rbc'])\n        zs = nested_lists_to_array(nml['zbs'])\n        if lasym:\n            rs = nested_lists_to_array(nml['rbs'])\n            zc = nested_lists_to_array(nml['zbc'])\n\n        rbc_first_n = nml.start_index['rbc'][0]\n        rbc_last_n = rbc_first_n + rc.shape[1] - 1\n        zbs_first_n = nml.start_index['zbs'][0]\n        zbs_last_n = zbs_first_n + zs.shape[1] - 1\n        if lasym:\n            rbs_first_n = nml.start_index['rbs'][0]\n            rbs_last_n = rbs_first_n + rs.shape[1] - 1\n            zbc_first_n = nml.start_index['zbc'][0]\n            zbc_last_n = zbc_first_n + zc.shape[1] - 1\n        else:\n            rbs_first_n = 0\n            rbs_last_n = 0\n            zbc_first_n = 0\n            zbc_last_n = 0\n        ntor_boundary = np.max(np.abs(np.array([rbc_first_n, rbc_last_n,\n                                                zbs_first_n, zbs_last_n,\n                                                rbs_first_n, rbs_last_n,\n                                                zbc_first_n, zbc_last_n], dtype='i')))\n\n        rbc_first_m = nml.start_index['rbc'][1]\n        rbc_last_m = rbc_first_m + rc.shape[0] - 1\n        zbs_first_m = nml.start_index['zbs'][1]\n        zbs_last_m = zbs_first_m + zs.shape[0] - 1\n        if lasym:\n            rbs_first_m = nml.start_index['rbs'][1]\n            rbs_last_m = rbs_first_m + rs.shape[0] - 1\n            zbc_first_m = nml.start_index['zbc'][1]\n            zbc_last_m = zbc_first_m + zc.shape[0] - 1\n        else:\n            rbs_first_m = 0\n            rbs_last_m = 0\n            zbc_first_m = 0\n            zbc_last_m = 0\n        mpol_boundary = np.max((rbc_last_m, zbs_last_m, rbs_last_m, zbc_last_m))\n        logger.debug('Input file has ntor_boundary={} mpol_boundary={}' \\\n                     .format(ntor_boundary, mpol_boundary))\n\n        ntheta = kwargs.pop(\"ntheta\", None)\n        nphi = kwargs.pop(\"nphi\", None)\n        grid_range = kwargs.pop(\"range\", None)\n\n        if ntheta is not None or nphi is not None:\n            kwargs[\"quadpoints_phi\"], kwargs[\"quadpoints_theta\"] = Surface.get_quadpoints(\n                ntheta=ntheta, nphi=nphi, nfp=nfp, range=grid_range)\n\n        surf = cls(mpol=mpol_boundary, ntor=ntor_boundary, nfp=nfp, stellsym=stellsym,\n                   **kwargs)\n\n        # Transfer boundary shape data from the namelist to the surface object:\n        # In these loops, we set surf.rc/zs rather than call surf.set_rc() for speed.\n        for jm in range(rc.shape[0]):\n            m = jm + nml.start_index['rbc'][1]\n            for jn in range(rc.shape[1]):\n                n = jn + nml.start_index['rbc'][0]\n                surf.rc[m, n + ntor_boundary] = rc[jm, jn]\n\n        for jm in range(zs.shape[0]):\n            m = jm + nml.start_index['zbs'][1]\n            for jn in range(zs.shape[1]):\n                n = jn + nml.start_index['zbs'][0]\n                surf.zs[m, n + ntor_boundary] = zs[jm, jn]\n\n        if lasym:\n            for jm in range(rs.shape[0]):\n                m = jm + nml.start_index['rbs'][1]\n                for jn in range(rs.shape[1]):\n                    n = jn + nml.start_index['rbs'][0]\n                    surf.rs[m, n + ntor_boundary] = rs[jm, jn]\n\n            for jm in range(zc.shape[0]):\n                m = jm + nml.start_index['zbc'][1]\n                for jn in range(zc.shape[1]):\n                    n = jn + nml.start_index['zbc'][0]\n                    surf.zc[m, n + ntor_boundary] = zc[jm, jn]\n\n        # Sync the dofs:\n        surf.local_full_x = surf.get_dofs()\n        return surf",
  "def from_focus(cls, filename, **kwargs):\n        \"\"\"\n        Read in a surface from a FOCUS-format file.\n        \"\"\"\n        with open(filename, 'r') as f:\n            lines = f.readlines()\n\n        # Read the line containing Nfou and nfp:\n        splitline = lines[1].split()\n        errmsg = \"This does not appear to be a FOCUS-format file.\"\n        assert len(splitline) == 3, errmsg\n        Nfou = int(splitline[0])\n        nfp = int(splitline[1])\n\n        # Now read the Fourier amplitudes:\n        n = np.full(Nfou, 0)\n        m = np.full(Nfou, 0)\n        rc = np.zeros(Nfou)\n        rs = np.zeros(Nfou)\n        zc = np.zeros(Nfou)\n        zs = np.zeros(Nfou)\n        for j in range(Nfou):\n            splitline = lines[j + 4].split()\n            n[j] = int(splitline[0])\n            m[j] = int(splitline[1])\n            rc[j] = float(splitline[2])\n            rs[j] = float(splitline[3])\n            zc[j] = float(splitline[4])\n            zs[j] = float(splitline[5])\n        assert np.min(m) == 0\n        stellsym = np.max(np.abs(rs)) == 0 and np.max(np.abs(zc)) == 0\n        mpol = int(np.max(m))\n        ntor = int(np.max(np.abs(n)))\n\n        ntheta = kwargs.pop(\"ntheta\", None)\n        nphi = kwargs.pop(\"nphi\", None)\n        grid_range = kwargs.pop(\"range\", None)\n\n        if ntheta is not None or nphi is not None:\n            kwargs[\"quadpoints_phi\"], kwargs[\"quadpoints_theta\"] = Surface.get_quadpoints(\n                ntheta=ntheta, nphi=nphi, nfp=nfp, range=grid_range)\n\n        surf = cls(mpol=mpol, ntor=ntor, nfp=nfp, stellsym=stellsym, **kwargs)\n\n        for j in range(Nfou):\n            surf.rc[m[j], n[j] + ntor] = rc[j]\n            surf.zs[m[j], n[j] + ntor] = zs[j]\n            if not stellsym:\n                surf.rs[m[j], n[j] + ntor] = rs[j]\n                surf.zc[m[j], n[j] + ntor] = zc[j]\n\n        surf.local_full_x = surf.get_dofs()\n        return surf",
  "def from_pyQSC(cls, stel: Qsc, r: float = 0.1, ntheta=20, mpol=10, ntor=20, **kwargs):\n        \"\"\"\n        Initialize the surface from a pyQSC object. This creates a surface\n        from a near-axis equilibrium with a specified minor radius `r` (in meters).\n\n        Args:\n            stel: Qsc object with a near-axis equilibrium.\n            r: the near-axis coordinate radius (in meters).\n            ntheta: number of points in the theta direction for the Fourier transform.\n            mpol: number of poloidal Fourier modes for the surface.\n            ntor: number of toroidal Fourier modes for the surface.\n            kwargs: Any other arguments to pass to the ``SurfaceRZFourier`` constructor.\n              You can specify ``quadpoints_theta`` and ``quadpoints_phi`` here.\n        \"\"\"\n        # Get surface shape at fixed off-axis toroidal angle phi\n        R_2D, Z_2D, _ = stel.Frenet_to_cylindrical(r, ntheta)\n\n        # Fourier transform the result.\n        RBC, RBS, ZBC, ZBS = to_Fourier(R_2D, Z_2D, stel.nfp, mpol, ntor, stel.lasym)\n\n        surf = cls(mpol=mpol, ntor=ntor, nfp=stel.nfp, stellsym=not stel.lasym, **kwargs)\n\n        surf.rc[:, :] = RBC.transpose()\n        surf.zs[:, :] = ZBS.transpose()\n        if stel.lasym:\n            surf.rs[:, :] = RBS.transpose()\n            surf.zc[:, :] = ZBC.transpose()\n\n        surf.local_full_x = surf.get_dofs()\n        return surf",
  "def change_resolution(self, mpol, ntor):\n        \"\"\"\n        Change the values of `mpol` and `ntor`. Any new Fourier amplitudes\n        will have a magnitude of zero.  Any previous nonzero Fourier\n        amplitudes that are not within the new range will be\n        discarded.\n        \"\"\"\n        old_mpol = self.mpol\n        old_ntor = self.ntor\n        old_rc = self.rc\n        old_zs = self.zs\n        if not self.stellsym:\n            old_rs = self.rs\n            old_zc = self.zc\n        self.mpol = mpol\n        self.ntor = ntor\n        self.allocate()\n        if mpol < old_mpol or ntor < old_ntor:\n            self.invalidate_cache()\n\n        min_mpol = np.min((mpol, old_mpol))\n        min_ntor = np.min((ntor, old_ntor))\n        for m in range(min_mpol + 1):\n            for n in range(-min_ntor, min_ntor + 1):\n                self.rc[m, n + ntor] = old_rc[m, n + old_ntor]\n                self.zs[m, n + ntor] = old_zs[m, n + old_ntor]\n                if not self.stellsym:\n                    self.rs[m, n + ntor] = old_rs[m, n + old_ntor]\n                    self.zc[m, n + ntor] = old_zc[m, n + old_ntor]\n        self._make_mn()\n\n        # Update the dofs object\n        self.replace_dofs(DOFs(self.get_dofs(), self._make_names()))",
  "def to_RZFourier(self):\n        \"\"\"\n        No conversion necessary.\n        \"\"\"\n        return self",
  "def __repr__(self):\n        return self.name + f\" (nfp={self.nfp}, stellsym={self.stellsym}, \" + \\\n            f\"mpol={self.mpol}, ntor={self.ntor})\"",
  "def _validate_mn(self, m, n):\n        \"\"\"\n        Check whether `m` and `n` are in the allowed range.\n        \"\"\"\n        if m < 0:\n            raise IndexError('m must be >= 0')\n        if m > self.mpol:\n            raise IndexError('m must be <= mpol')\n        if n > self.ntor:\n            raise IndexError('n must be <= ntor')\n        if n < -self.ntor:\n            raise IndexError('n must be >= -ntor')",
  "def get_rc(self, m, n):\n        \"\"\"\n        Return a particular `rc` Parameter.\n        \"\"\"\n        self._validate_mn(m, n)\n        return self.rc[m, n + self.ntor]",
  "def get_rs(self, m, n):\n        \"\"\"\n        Return a particular `rs` Parameter.\n        \"\"\"\n        if self.stellsym:\n            return ValueError(\n                'rs does not exist for this stellarator-symmetric surface.')\n        self._validate_mn(m, n)\n        return self.rs[m, n + self.ntor]",
  "def get_zc(self, m, n):\n        \"\"\"\n        Return a particular `zc` Parameter.\n        \"\"\"\n        if self.stellsym:\n            return ValueError(\n                'zc does not exist for this stellarator-symmetric surface.')\n        self._validate_mn(m, n)\n        return self.zc[m, n + self.ntor]",
  "def get_zs(self, m, n):\n        \"\"\"\n        Return a particular `zs` Parameter.\n        \"\"\"\n        self._validate_mn(m, n)\n        return self.zs[m, n + self.ntor]",
  "def set_rc(self, m, n, val):\n        \"\"\"\n        Set a particular `rc` Parameter.\n        \"\"\"\n        self._validate_mn(m, n)\n        self.rc[m, n + self.ntor] = val\n        self.local_full_x = self.get_dofs()",
  "def set_rs(self, m, n, val):\n        \"\"\"\n        Set a particular `rs` Parameter.\n        \"\"\"\n        if self.stellsym:\n            return ValueError(\n                'rs does not exist for this stellarator-symmetric surface.')\n        self._validate_mn(m, n)\n        self.rs[m, n + self.ntor] = val\n        self.local_full_x = self.get_dofs()",
  "def set_zc(self, m, n, val):\n        \"\"\"\n        Set a particular `zc` Parameter.\n        \"\"\"\n        if self.stellsym:\n            return ValueError(\n                'zc does not exist for this stellarator-symmetric surface.')\n        self._validate_mn(m, n)\n        self.zc[m, n + self.ntor] = val\n        self.local_full_x = self.get_dofs()",
  "def set_zs(self, m, n, val):\n        \"\"\"\n        Set a particular `zs` Parameter.\n        \"\"\"\n        self._validate_mn(m, n)\n        self.zs[m, n + self.ntor] = val\n        self.local_full_x = self.get_dofs()",
  "def fixed_range(self, mmin, mmax, nmin, nmax, fixed=True):\n        \"\"\"\n        Set the 'fixed' property for a range of `m` and `n` values.\n\n        All modes with `m` in the interval [`mmin`, `mmax`] and `n` in the\n        interval [`nmin`, `nmax`] will have their fixed property set to\n        the value of the `fixed` parameter. Note that `mmax` and `nmax`\n        are included (unlike the upper bound in python's range(min,\n        max).)\n        \"\"\"\n        # TODO: This will be slow because free dof indices are evaluated all\n        # TODO: the time in the loop\n        fn = self.fix if fixed else self.unfix\n        for m in range(mmin, mmax + 1):\n            this_nmin = nmin\n            if m == 0 and nmin < 0:\n                this_nmin = 0\n            for n in range(this_nmin, nmax + 1):\n                fn(f'rc({m},{n})')\n                if m > 0 or n != 0:\n                    fn(f'zs({m},{n})')\n                if not self.stellsym:\n                    fn(f'zc({m},{n})')\n                    if m > 0 or n != 0:\n                        fn(f'rs({m},{n})')",
  "def recompute_bell(self, parent=None):\n        self.invalidate_cache()",
  "def darea(self):\n        \"\"\"\n        Short hand for `Surface.darea_by_dcoeff()`\n        \"\"\"\n        return self.darea_by_dcoeff()",
  "def dvolume(self):\n        \"\"\"\n        Short hand for `Surface.dvolume_by_dcoeff()`\n        \"\"\"\n        return self.dvolume_by_dcoeff()",
  "def get_nml(self):\n        \"\"\"\n        Generates a fortran namelist file containing the RBC/RBS/ZBC/ZBS\n        coefficients, in the form used in VMEC and SPEC input\n        files. The result will be returned as a string. For saving a\n        file, see the ``write_nml()`` function.\n        \"\"\"\n        nml = ''\n        nml += '&INDATA\\n'\n        if self.stellsym:\n            nml += 'LASYM = .FALSE.\\n'\n        else:\n            nml += 'LASYM = .TRUE.\\n'\n        nml += f'NFP = {self.nfp}\\n'\n\n        for m in range(self.mpol + 1):\n            nmin = -self.ntor\n            if m == 0:\n                nmin = 0\n            for n in range(nmin, self.ntor + 1):\n                rc = self.get_rc(m, n)\n                zs = self.get_zs(m, n)\n                if np.abs(rc) > 0 or np.abs(zs) > 0:\n                    nml += f\"RBC({n:4d},{m:4d}) ={rc:23.15e},    ZBS({n:4d},{m:4d}) ={zs:23.15e}\\n\"\n                if (not self.stellsym):\n                    rs = self.get_rs(m, n)\n                    zc = self.get_zc(m, n)\n                    if np.abs(rs) > 0 or np.abs(zc) > 0:\n                        nml += f\"RBS({n:4d},{m:4d}) ={rs:23.15e},    ZBC({n:4d},{m:4d}) ={zc:23.15e}\\n\"\n        nml += '/\\n'\n        return nml",
  "def write_nml(self, filename: str):\n        \"\"\"\n        Writes a fortran namelist file containing the RBC/RBS/ZBC/ZBS\n        coefficients, in the form used in VMEC and SPEC input\n        files. To just generate the namelist as a string without\n        saving a file, see the ``get_nml()`` function.\n\n        Args:\n            filename: Name of the file to write.\n        \"\"\"\n        with open(filename, 'w') as f:\n            f.write(self.get_nml())",
  "def __init__(self, mpol, ntor, nfp, r_shift=1.0, a_scale=1.0, **kwargs):\n        self.mpol = mpol\n        self.ntor = ntor\n        self.nfp = nfp\n        self.r_shift = r_shift\n        self.a_scale = a_scale\n        ndofs = 1 + 2 * (ntor + mpol * (2 * ntor + 1))\n        if \"dofs\" not in kwargs:\n            if \"x0\" not in kwargs:\n                kwargs[\"x0\"] = np.zeros(ndofs)\n            else:\n                assert (len(kwargs[\"x0\"]) == ndofs)\n            if \"names\" not in kwargs:\n                kwargs[\"names\"] = self._make_names()\n            else:\n                assert (len(kwargs[\"names\"]) == ndofs)\n        else:\n            assert (len(kwargs[\"dofs\"]) == ndofs)\n        super().__init__(**kwargs)",
  "def _make_names(self):\n        \"\"\"\n        Create the list of names for the dofs.\n        \"\"\"\n        names = ['r(0,0)']\n        for dimension in ['r', 'z']:\n            for jtheta in range(1, self.mpol + 1):\n                names.append(dimension + f'(0,{jtheta})')\n            for jphi in range(1, self.ntor + 1):\n                for jtheta in range(2 * self.mpol + 1):\n                    names.append(dimension + f'({jphi},{jtheta})')\n        return names",
  "def from_RZFourier(cls, surff, **kwargs):\n        \"\"\"\n        Convert a :obj:`SurfaceRZFourier` object to a\n        ``SurfaceRZPseudospectral`` object.\n\n        Args:\n            surff: The :obj:`SurfaceRZFourier` object to convert.\n            kwargs: You can optionally provide the ``r_shift`` or ``a_scale`` arguments\n              to the ``SurfaceRZPseudospectral`` constructor here.\n        \"\"\"\n        if not surff.stellsym:\n            raise RuntimeError('SurfaceRZPseudospectral presently only '\n                               'supports stellarator-symmetric surfaces')\n\n        # shorthand:\n        mpol = surff.mpol\n        ntor = surff.ntor\n        ntheta = 2 * mpol + 1\n        nphi = 2 * ntor + 1\n\n        # Make a copy of surff with the desired theta and phi points.\n        surf_copy = SurfaceRZFourier.from_nphi_ntheta(\n            mpol=mpol, ntor=ntor, nfp=surff.nfp,\n            range='field period', ntheta=ntheta, nphi=nphi)\n        surf_copy.x = surff.local_full_x\n\n        surf_new = cls(mpol=mpol, ntor=ntor, nfp=surff.nfp, **kwargs)\n        gamma = surf_copy.gamma()\n        r0 = np.sqrt(gamma[:, :, 0] ** 2 + gamma[:, :, 1] ** 2)\n        r = (r0 - surf_new.r_shift) / surf_new.a_scale\n        z = gamma[:, :, 2] / surf_new.a_scale\n\n        dofs = np.zeros_like(surf_new.full_x)\n        ndofs = len(dofs)\n        index = 0\n        for jtheta in range(mpol + 1):\n            dofs[index] = r[0, jtheta]\n            index += 1\n        for jphi in range(1, ntor + 1):\n            for jtheta in range(ntheta):\n                dofs[index] = r[jphi, jtheta]\n                index += 1\n        for jtheta in range(1, mpol + 1):\n            dofs[index] = z[0, jtheta]\n            index += 1\n        for jphi in range(1, ntor + 1):\n            for jtheta in range(ntheta):\n                dofs[index] = z[jphi, jtheta]\n                index += 1\n        assert index == ndofs\n        surf_new.x = dofs\n        return surf_new",
  "def _complete_grid(self):\n        \"\"\"\n        Using stellarator symmetry, copy the real-space dofs to cover a\n        full 2d ``(theta, phi)`` grid.\n        \"\"\"\n\n        # shorthand:\n        mpol = self.mpol\n        ntor = self.ntor\n        ntheta = 2 * mpol + 1\n        nphi = 2 * ntor + 1\n\n        r = np.zeros((ntheta, nphi))\n        z = np.zeros((ntheta, nphi))\n        r[0, 0] = self.x[0]\n        shift = mpol + ntor * (2 * mpol + 1)  # = mpol + ntor + 2 * mpol * ntor\n        assert 2 * shift + 1 == len(self.x)\n        for jtheta in range(1, mpol + 1):\n            r[jtheta, 0] = self.x[jtheta]\n            r[ntheta - jtheta, 0] = self.x[jtheta]\n            assert self.local_dof_names[jtheta + shift] == f'z(0,{jtheta})'\n            z[jtheta, 0] = self.x[jtheta + shift]\n            z[ntheta - jtheta, 0] = -self.x[jtheta + shift]\n        for jphi in range(1, ntor + 1):\n            for jtheta in range(ntheta):\n                index = (jphi - 1) * ntheta + jtheta + mpol + 1\n                assert self.local_dof_names[index] == f'r({jphi},{jtheta})'\n                assert self.local_dof_names[index + shift] == f'z({jphi},{jtheta})'\n                r[jtheta, jphi] = self.x[index]\n                z[jtheta, jphi] = self.x[index + shift]\n                if jtheta == 0:\n                    r[0, nphi - jphi] = self.x[index]\n                    z[0, nphi - jphi] = -self.x[index + shift]\n                else:\n                    r[ntheta - jtheta, nphi - jphi] = self.x[index]\n                    z[ntheta - jtheta, nphi - jphi] = -self.x[index + shift]\n\n        r2 = self.r_shift + self.a_scale * r\n        z2 = self.a_scale * z\n        return r2, z2",
  "def to_RZFourier(self, **kwargs):\n        \"\"\"\n        Convert to a :obj:`SurfaceRZFourier` describing the same shape.\n\n        Args:\n            kwargs: You can optionally provide the ``range``, ``nphi``,\n              and/or ``ntheta`` arguments to the :obj:`SurfaceRZFourier` constructor here.\n        \"\"\"\n        # shorthand:\n        mpol = self.mpol\n        ntor = self.ntor\n\n        r, z = self._complete_grid()\n        # What follows is a Fourier transform. We could use an FFT,\n        # but since speed is not a concern here for now, the Fourier\n        # transform is just done \"by hand\" so there is no uncertainty\n        # about normalizations etc.\n\n        ntheta = kwargs.pop(\"ntheta\", None)\n        nphi = kwargs.pop(\"nphi\", None)\n        grid_range = kwargs.pop(\"range\", None)\n\n        if ntheta is not None or nphi is not None:\n            kwargs[\"quadpoints_phi\"], kwargs[\"quadpoints_theta\"] = Surface.get_quadpoints(\n                ntheta=ntheta, nphi=nphi, nfp=self.nfp, range=grid_range)\n\n        surf = SurfaceRZFourier(mpol=mpol, ntor=ntor, nfp=self.nfp, **kwargs)\n        surf.set_rc(0, 0, np.mean(r))\n        ntheta = 2 * mpol + 1\n        nphi = 2 * ntor + 1\n        theta1d = np.linspace(0, 2 * np.pi, ntheta, endpoint=False)\n        phi1d = np.linspace(0, 2 * np.pi, nphi, endpoint=False)\n        phi, theta = np.meshgrid(phi1d, theta1d)\n        for n in range(1, ntor + 1):\n            surf.set_rc(0, n, 2 * np.mean(r * np.cos(-n * phi)))\n            surf.set_zs(0, n, 2 * np.mean(z * np.sin(-n * phi)))\n        for m in range(1, mpol + 1):\n            for n in range(-ntor, ntor + 1):\n                surf.set_rc(m, n, 2 * np.mean(r * np.cos(m * theta - n * phi)))\n                surf.set_zs(m, n, 2 * np.mean(z * np.sin(m * theta - n * phi)))\n\n        return surf",
  "def change_resolution(self, mpol, ntor):\n        \"\"\"\n        Increase or decrease the number of degrees of freedom.  The new\n        real-space dofs are obtained using Fourier interpolation. This\n        function is useful for increasing the size of the parameter\n        space during stage-1 optimization. If ``mpol`` and ``ntor``\n        are increased or unchanged, there is no loss of information.\n        If ``mpol`` or ``ntor`` are decreased, information is lost.\n\n        Args:\n            mpol: The new maximum poloidal mode number.\n            ntor: The new maximum toroidal mode number, divided by ``nfp``.\n        \"\"\"\n        # Map to Fourier space:\n        surf2 = self.to_RZFourier()\n        # Change the resolution in Fourier space, by truncating the modes or padding 0s:\n        surf2.change_resolution(mpol=mpol, ntor=ntor)\n        # Map from Fourier space back to real space:\n        surf3 = SurfaceRZPseudospectral.from_RZFourier(surf2,\n                                                       r_shift=self.r_shift,\n                                                       a_scale=self.a_scale)\n        return surf3",
  "class SurfaceGarabedian(sopp.Surface, Surface):\n    r\"\"\"\n    ``SurfaceGarabedian`` represents a toroidal surface for which the\n    shape is parameterized using Garabedian's :math:`\\Delta_{m,n}`\n    coefficients:\n\n    .. math::\n      R + i Z = e^{i u} \\sum_{m = m_\\min}^{m_\\max} \\sum_{n = n_\\min}^{n_\\max} \\Delta_{m,n} e^{-i m u + i n v}\n\n    where :math:`u = 2 \\pi \\theta` is a poloidal angle on :math:`[0, 2\\pi]`, and\n    :math:`v` is the standard toroidal angle on :math:`[0, 2\\pi]`.\n\n    The present implementation assumes stellarator symmetry. Note that\n    non-stellarator-symmetric surfaces require that the :math:`\\Delta_{m,n}`\n    coefficients be imaginary.\n\n    For more information about the arguments ``quadpoints_phi``, and\n    ``quadpoints_theta``, see the general documentation on :ref:`surfaces`.\n    Instead of supplying the quadrature point arrays along :math:`\\phi` and\n    :math:`\\theta` directions, one could also specify the number of\n    quadrature points for :math:`\\phi` and :math:`\\theta` using the\n    class method :py:meth:`~simsopt.geo.surface.Surface.from_nphi_ntheta`.\n\n    Args:\n        nfp: The number of field periods.\n        mmin: Minimum poloidal mode number :math:`m` included (usually 0 or negative).\n        mmax: Maximum poloidal mode number :math:`m` included.\n        nmin: Minimum toroidal mode number :math:`n` included (usually negative).\n          If ``None``, ``nmin = -nmax`` will be used.\n        nmax: Maximum toroidal mode number :math:`n` included.\n        quadpoints_phi: Set this to a list or 1D array to set the :math:`\\phi_j` grid points directly.\n        quadpoints_theta: Set this to a list or 1D array to set the :math:`\\theta_j` grid points directly.\n    \"\"\"\n    mmin = Integer(max_value=0)\n    mmax = Integer(min_value=1)\n    nfp = Integer()\n    nmin = Integer()\n    nmax = Integer()\n\n    def __init__(self, nfp=1, mmax=1, mmin=0, nmax=0, nmin=None,\n                 quadpoints_phi=None, quadpoints_theta=None,\n                 dofs=None):\n        if nmin is None:\n            nmin = -nmax\n        # Perform some validation.\n        if mmax < mmin:\n            raise ValueError(\"mmin must be >= mmax\")\n        if nmax < nmin:\n            raise ValueError(\"nmin must be >= nmax\")\n        self.mmin = mmin\n        self.mmax = mmax\n        self.nmin = nmin\n        self.nmax = nmax\n        self.nfp = nfp\n        self.stellsym = True\n\n        self.mdim = self.mmax - self.mmin + 1\n        self.ndim = self.nmax - self.nmin + 1\n        self.shape = (self.mdim, self.ndim)\n\n        if quadpoints_theta is None:\n            quadpoints_theta = Surface.get_theta_quadpoints()\n        if quadpoints_phi is None:\n            quadpoints_phi = Surface.get_phi_quadpoints(nfp=nfp)\n\n        sopp.Surface.__init__(self, quadpoints_phi, quadpoints_theta)\n        if dofs is None:\n            Delta = np.zeros(self.shape)\n            Surface.__init__(self, x0=Delta.ravel(),\n                             names=self._make_dof_names())\n        else:\n            Surface.__init__(self, dofs=dofs)\n\n        # Initialize to an axisymmetric torus with major radius 1m and\n        # minor radius 0.1m\n        self.set_Delta(1, 0, 1.0)\n        self.set_Delta(0, 0, 0.1)\n\n    def _make_dof_names(self):\n        names = []\n        for m in range(self.mmin, self.mmax + 1):\n            for n in range(self.nmin, self.nmax + 1):\n                names.append(f'Delta({m},{n})')\n        return names\n\n    def __repr__(self):\n        return self.name + f\" (nfp={self.nfp}, \" + \\\n            f\"mmin={self.mmin}, mmax={self.mmax}\" + \\\n            f\", nmin={self.nmin}, nmax={self.nmax})\"\n\n    @property\n    def Delta(self):\n        return self.local_full_x.reshape(self.shape)\n\n    @Delta.setter\n    def Delta(self, Delta):\n        assert (self.shape == Delta.shape)\n        self.local_full_x = Delta.flatten()\n\n    def get_Delta(self, m, n):\n        \"\"\"\n        Return a particular :math:`\\Delta_{m,n}` coefficient.\n        \"\"\"\n        return self.Delta[m - self.mmin, n - self.nmin]\n\n    def set_Delta(self, m, n, val):\n        \"\"\"\n        Set a particular :math:`\\Delta_{m,n}` coefficient.\n        \"\"\"\n        i = self.ndim * (m - self.mmin) + n - self.nmin\n        self.set(i, val)\n\n    def get_dofs(self):\n        \"\"\"\n        Return a 1D numpy array with all the degrees of freedom.\n        \"\"\"\n        self.local_full_x\n\n    def set_dofs(self, x):\n        \"\"\"\n        Set the shape coefficients from a 1D list/array\n        \"\"\"\n        # Check whether any elements actually change:\n        if np.all(np.abs(self.get_dofs() - np.array(x)) == 0):\n            logger.info('set_dofs called, but no dofs actually changed')\n            return\n\n        logger.info('set_dofs called, and at least one dof changed')\n\n        self.local_full_x = x\n\n    def fix_range(self, mmin, mmax, nmin, nmax, fixed=True):\n        \"\"\"\n        Fix the DOFs for a range of m and n values.\n\n        All modes with m in the interval [mmin, mmax] and n in the\n        interval [nmin, nmax] will have their fixed property set to\n        the value of the 'fixed' parameter. Note that mmax and nmax\n        are included (unlike the upper bound in python's range(min,\n        max).)\n        \"\"\"\n        fn = self.fix if fixed else self.unfix\n        for m in range(mmin, mmax + 1):\n            for n in range(nmin, nmax + 1):\n                fn(f'Delta({m},{n})')\n\n    def to_RZFourier(self):\n        \"\"\"\n        Return a SurfaceRZFourier object with the identical shape.\n\n        For a derivation of the transformation here, see \n        https://terpconnect.umd.edu/~mattland/assets/notes/toroidal_surface_parameterizations.pdf\n        \"\"\"\n        mpol = int(np.max((1, self.mmax - 1, 1 - self.mmin)))\n        ntor = int(np.max((self.nmax, -self.nmin)))\n        s = SurfaceRZFourier(nfp=self.nfp, stellsym=True, mpol=mpol, ntor=ntor)\n        s.set_rc(0, 0, self.get_Delta(1, 0))\n        for m in range(mpol + 1):\n            nmin = -ntor\n            if m == 0:\n                nmin = 1\n            for n in range(nmin, ntor + 1):\n                Delta1 = 0\n                Delta2 = 0\n                if 1 - m >= self.mmin and -n >= self.nmin and -n <= self.nmax:\n                    Delta1 = self.get_Delta(1 - m, -n)\n                if 1 + m <= self.mmax and n >= self.nmin and n <= self.nmax:\n                    Delta2 = self.get_Delta(1 + m, n)\n                s.set_rc(m, n, Delta1 + Delta2)\n                s.set_zs(m, n, Delta1 - Delta2)\n\n        return s\n\n    # TODO: Reimplement by passing all Delta values once\n    @classmethod\n    def from_RZFourier(cls, surf):\n        \"\"\"\n        Create a `SurfaceGarabedian` from a `SurfaceRZFourier` object of the identical shape.\n\n        For a derivation of the transformation here, see\n        https://terpconnect.umd.edu/~mattland/assets/notes/toroidal_surface_parameterizations.pdf\n        \"\"\"\n        if not surf.stellsym:\n            raise RuntimeError('Non-stellarator-symmetric SurfaceGarabedian '\n                               'objects have not been implemented')\n        mmax = surf.mpol + 1\n        mmin = np.min((0, 1 - surf.mpol))\n        s = cls(nfp=surf.nfp, mmin=mmin, mmax=mmax,\n                nmin=-surf.ntor, nmax=surf.ntor)\n        for n in range(-surf.ntor, surf.ntor + 1):\n            for m in range(mmin, mmax + 1):\n                Delta = 0\n                if m - 1 >= 0:\n                    Delta = 0.5 * (surf.get_rc(m - 1, n) - surf.get_zs(m - 1, n))\n                if 1 - m >= 0:\n                    Delta += 0.5 * (surf.get_rc(1 - m, -n) + surf.get_zs(1 - m, -n))\n                s.set_Delta(m, n, Delta)\n\n        return s\n\n    def area_volume(self):\n        \"\"\"\n        Compute the surface area and the volume enclosed by the surface.\n        \"\"\"\n        if self.new_x:\n            logger.info('Running calculation of area and volume')\n        else:\n            logger.info('area_volume called, but no need to recalculate')\n            return\n\n        self.new_x = False\n\n        # Delegate to the area and volume calculations of SurfaceRZFourier():\n        s = self.to_RZFourier()\n        self._area = s.area()\n        self._volume = s.volume()\n\n    def area(self):\n        \"\"\"\n        Return the area of the surface.\n        \"\"\"\n        self.area_volume()\n        return self._area\n\n    def volume(self):\n        \"\"\"\n        Return the volume of the surface.\n        \"\"\"\n        self.area_volume()\n        return self._volume\n\n    return_fn_map = {'area': area,\n                     'volume': volume,\n                     'aspect-ratio': Surface.aspect_ratio}",
  "def __init__(self, nfp=1, mmax=1, mmin=0, nmax=0, nmin=None,\n                 quadpoints_phi=None, quadpoints_theta=None,\n                 dofs=None):\n        if nmin is None:\n            nmin = -nmax\n        # Perform some validation.\n        if mmax < mmin:\n            raise ValueError(\"mmin must be >= mmax\")\n        if nmax < nmin:\n            raise ValueError(\"nmin must be >= nmax\")\n        self.mmin = mmin\n        self.mmax = mmax\n        self.nmin = nmin\n        self.nmax = nmax\n        self.nfp = nfp\n        self.stellsym = True\n\n        self.mdim = self.mmax - self.mmin + 1\n        self.ndim = self.nmax - self.nmin + 1\n        self.shape = (self.mdim, self.ndim)\n\n        if quadpoints_theta is None:\n            quadpoints_theta = Surface.get_theta_quadpoints()\n        if quadpoints_phi is None:\n            quadpoints_phi = Surface.get_phi_quadpoints(nfp=nfp)\n\n        sopp.Surface.__init__(self, quadpoints_phi, quadpoints_theta)\n        if dofs is None:\n            Delta = np.zeros(self.shape)\n            Surface.__init__(self, x0=Delta.ravel(),\n                             names=self._make_dof_names())\n        else:\n            Surface.__init__(self, dofs=dofs)\n\n        # Initialize to an axisymmetric torus with major radius 1m and\n        # minor radius 0.1m\n        self.set_Delta(1, 0, 1.0)\n        self.set_Delta(0, 0, 0.1)",
  "def _make_dof_names(self):\n        names = []\n        for m in range(self.mmin, self.mmax + 1):\n            for n in range(self.nmin, self.nmax + 1):\n                names.append(f'Delta({m},{n})')\n        return names",
  "def __repr__(self):\n        return self.name + f\" (nfp={self.nfp}, \" + \\\n            f\"mmin={self.mmin}, mmax={self.mmax}\" + \\\n            f\", nmin={self.nmin}, nmax={self.nmax})\"",
  "def Delta(self):\n        return self.local_full_x.reshape(self.shape)",
  "def Delta(self, Delta):\n        assert (self.shape == Delta.shape)\n        self.local_full_x = Delta.flatten()",
  "def get_Delta(self, m, n):\n        \"\"\"\n        Return a particular :math:`\\Delta_{m,n}` coefficient.\n        \"\"\"\n        return self.Delta[m - self.mmin, n - self.nmin]",
  "def set_Delta(self, m, n, val):\n        \"\"\"\n        Set a particular :math:`\\Delta_{m,n}` coefficient.\n        \"\"\"\n        i = self.ndim * (m - self.mmin) + n - self.nmin\n        self.set(i, val)",
  "def get_dofs(self):\n        \"\"\"\n        Return a 1D numpy array with all the degrees of freedom.\n        \"\"\"\n        self.local_full_x",
  "def set_dofs(self, x):\n        \"\"\"\n        Set the shape coefficients from a 1D list/array\n        \"\"\"\n        # Check whether any elements actually change:\n        if np.all(np.abs(self.get_dofs() - np.array(x)) == 0):\n            logger.info('set_dofs called, but no dofs actually changed')\n            return\n\n        logger.info('set_dofs called, and at least one dof changed')\n\n        self.local_full_x = x",
  "def fix_range(self, mmin, mmax, nmin, nmax, fixed=True):\n        \"\"\"\n        Fix the DOFs for a range of m and n values.\n\n        All modes with m in the interval [mmin, mmax] and n in the\n        interval [nmin, nmax] will have their fixed property set to\n        the value of the 'fixed' parameter. Note that mmax and nmax\n        are included (unlike the upper bound in python's range(min,\n        max).)\n        \"\"\"\n        fn = self.fix if fixed else self.unfix\n        for m in range(mmin, mmax + 1):\n            for n in range(nmin, nmax + 1):\n                fn(f'Delta({m},{n})')",
  "def to_RZFourier(self):\n        \"\"\"\n        Return a SurfaceRZFourier object with the identical shape.\n\n        For a derivation of the transformation here, see \n        https://terpconnect.umd.edu/~mattland/assets/notes/toroidal_surface_parameterizations.pdf\n        \"\"\"\n        mpol = int(np.max((1, self.mmax - 1, 1 - self.mmin)))\n        ntor = int(np.max((self.nmax, -self.nmin)))\n        s = SurfaceRZFourier(nfp=self.nfp, stellsym=True, mpol=mpol, ntor=ntor)\n        s.set_rc(0, 0, self.get_Delta(1, 0))\n        for m in range(mpol + 1):\n            nmin = -ntor\n            if m == 0:\n                nmin = 1\n            for n in range(nmin, ntor + 1):\n                Delta1 = 0\n                Delta2 = 0\n                if 1 - m >= self.mmin and -n >= self.nmin and -n <= self.nmax:\n                    Delta1 = self.get_Delta(1 - m, -n)\n                if 1 + m <= self.mmax and n >= self.nmin and n <= self.nmax:\n                    Delta2 = self.get_Delta(1 + m, n)\n                s.set_rc(m, n, Delta1 + Delta2)\n                s.set_zs(m, n, Delta1 - Delta2)\n\n        return s",
  "def from_RZFourier(cls, surf):\n        \"\"\"\n        Create a `SurfaceGarabedian` from a `SurfaceRZFourier` object of the identical shape.\n\n        For a derivation of the transformation here, see\n        https://terpconnect.umd.edu/~mattland/assets/notes/toroidal_surface_parameterizations.pdf\n        \"\"\"\n        if not surf.stellsym:\n            raise RuntimeError('Non-stellarator-symmetric SurfaceGarabedian '\n                               'objects have not been implemented')\n        mmax = surf.mpol + 1\n        mmin = np.min((0, 1 - surf.mpol))\n        s = cls(nfp=surf.nfp, mmin=mmin, mmax=mmax,\n                nmin=-surf.ntor, nmax=surf.ntor)\n        for n in range(-surf.ntor, surf.ntor + 1):\n            for m in range(mmin, mmax + 1):\n                Delta = 0\n                if m - 1 >= 0:\n                    Delta = 0.5 * (surf.get_rc(m - 1, n) - surf.get_zs(m - 1, n))\n                if 1 - m >= 0:\n                    Delta += 0.5 * (surf.get_rc(1 - m, -n) + surf.get_zs(1 - m, -n))\n                s.set_Delta(m, n, Delta)\n\n        return s",
  "def area_volume(self):\n        \"\"\"\n        Compute the surface area and the volume enclosed by the surface.\n        \"\"\"\n        if self.new_x:\n            logger.info('Running calculation of area and volume')\n        else:\n            logger.info('area_volume called, but no need to recalculate')\n            return\n\n        self.new_x = False\n\n        # Delegate to the area and volume calculations of SurfaceRZFourier():\n        s = self.to_RZFourier()\n        self._area = s.area()\n        self._volume = s.volume()",
  "def area(self):\n        \"\"\"\n        Return the area of the surface.\n        \"\"\"\n        self.area_volume()\n        return self._area",
  "def volume(self):\n        \"\"\"\n        Return the volume of the surface.\n        \"\"\"\n        self.area_volume()\n        return self._volume",
  "class QfmSurface(GSONable):\n    r\"\"\"\n    QfmSurface is used to compute a quadratic-flux minimizing surface, defined\n    as the minimum of the objective function,\n\n    .. math::\n        f(S) = \\frac{\\int_{S} d^2 x \\, \\left(\\textbf{B} \\cdot \\hat{\\textbf{n}}\\right)^2}{\\int_{S} d^2 x \\, B^2}\n\n    subject to a constraint on the surface label, such as the area, volume,\n    or toroidal flux. This objective, :math:`f`, is computed in :class:`QfmResidual`\n    (see :mod:`surfaceobjectives.py`). If magnetic surfaces exists, :math:`f`\n    will be zero. If not, QFM surfaces approximate flux surfaces.\n\n    The label constraint can be enforced with a penalty formulation, defined\n    in :func:`qfm_penalty_constraints()`, and whose minimium is computed with\n    LBFGS-B by :func:`minimize_qfm_penalty_constraints_LBFGS()`.\n\n    Alternatively, the label constraint can be enforced with a constrained\n    optimization algorithm. This constrained optimization problem is\n    solved with the SLSQP algorithm by :func:`minimize_qfm_exact_constraints_SLSQP()`.\n    \"\"\"\n\n    def __init__(self, biotsavart, surface, label, targetlabel):\n        self.biotsavart = biotsavart\n        self.surface = surface\n        self.label = label\n        self.targetlabel = targetlabel\n        self.qfm = QfmResidual(surface, biotsavart)\n        self.name = str(id(self))\n\n    def qfm_label_constraint(self, x, derivatives=0):\n        r\"\"\"\n        Returns the residual\n\n        .. math::\n            0.5 (\\texttt{label} - \\texttt{labeltarget})^2\n\n        and optionally the gradient wrt surface params.\n        \"\"\"\n        assert derivatives in [0, 1]\n        self.surface.x = x\n        l = self.label.J()\n        rl = l - self.targetlabel\n        val = 0.5 * rl ** 2\n\n        if derivatives:\n            dl = self.label.dJ_by_dsurfacecoefficients()\n            dval = rl * dl\n            return val, dval\n        else:\n            return val\n\n    def qfm_objective(self, x, derivatives=0):\n        r\"\"\"\n        Returns the residual\n\n        .. math::\n            f(S)\n\n        and optionally the gradient wrt surface params where :math:`f(S)`` is\n        the QFM residual defined in surfaceobjectives.py.\n        \"\"\"\n\n        assert derivatives in [0, 1]\n        self.surface.x = x\n        qfm = self.qfm\n\n        r = qfm.J()\n\n        if not derivatives:\n            return r\n        else:\n            dr = qfm.dJ_by_dsurfacecoefficients()\n            return r, dr\n\n    def qfm_penalty_constraints(self, x, derivatives=0, constraint_weight=1):\n        r\"\"\"\n        Returns the residual\n\n        .. math::\n            f(S) + 0.5 \\texttt{constraint_weight} (\\texttt{label} - \\texttt{labeltarget})^2\n\n        and optionally the gradient and Hessian wrt surface params where\n        :math:`f(S)` is the QFM residual defined in :mod:`surfaceobjectives.py`.\n        \"\"\"\n\n        assert derivatives in [0, 1]\n        s = self.surface\n        s.x = x\n\n        qfm = self.qfm\n\n        r = qfm.J()\n\n        l = self.label.J()\n        rl = l - self.targetlabel\n\n        val = r + 0.5 * constraint_weight * rl**2\n        if derivatives == 0:\n            return val\n\n        dr = qfm.dJ_by_dsurfacecoefficients()\n\n        dl = self.label.dJ_by_dsurfacecoefficients()\n\n        dval = dr + constraint_weight*rl*dl\n        return val, dval\n\n    def minimize_qfm_penalty_constraints_LBFGS(self, tol=1e-3, maxiter=1000,\n                                               constraint_weight=1.):\n        r\"\"\"\n        This function tries to find the surface that approximately solves\n\n        .. math::\n            \\min_S f(S) + 0.5 \\texttt{constraint_weight} (\\texttt{label} - \\texttt{labeltarget})^2\n\n        where :math:`f(S)` is the QFM residual defined in :mod:`surfaceobjectives.py.`\n        This is done using LBFGS.\n        \"\"\"\n\n        s = self.surface\n        x = s.x\n        fn = lambda x: self.qfm_penalty_constraints(\n            x, derivatives=1, constraint_weight=constraint_weight)\n        res = minimize(\n            fn, x, jac=True, method='L-BFGS-B',\n            options={'maxiter': maxiter, 'ftol': tol, 'gtol': tol,\n                     'maxcor': 200})\n\n        resdict = {\n            \"fun\": res.fun, \"gradient\": res.jac, \"iter\": res.nit, \"info\": res,\n            \"success\": res.success,\n        }\n        s.x = res.x\n        resdict['s'] = s\n\n        return resdict\n\n    def minimize_qfm_exact_constraints_SLSQP(self, tol=1e-3, maxiter=1000):\n        r\"\"\"\n        This function tries to find the surface that approximately solves\n\n        .. math::\n            \\min_{S} f(S)\n\n        subject to\n\n        .. math::\n            \\texttt{label} = \\texttt{labeltarget}\n\n        where :math:`f(S)` is the QFM residual. This is done using SLSQP.\n        \"\"\"\n        s = self.surface\n        x = s.x\n\n        fun = lambda x: self.qfm_objective(x, derivatives=1)\n        con = lambda x: self.qfm_label_constraint(x, derivatives=1)[0]\n        dcon = lambda x: self.qfm_label_constraint(x, derivatives=1)[1]\n\n        nlc = NonlinearConstraint(con, 0, 0)\n        eq_constraints = [{'type': 'eq', 'fun': con, 'jac': dcon}]\n        res = minimize(\n            fun, x, jac=True, method='SLSQP', constraints=eq_constraints,\n            options={'maxiter': maxiter, 'ftol': tol})\n\n        resdict = {\n            \"fun\": res.fun, \"gradient\": res.jac, \"iter\": res.nit, \"info\": res,\n            \"success\": res.success,\n        }\n        s.x = res.x\n        resdict['s'] = s\n\n        return resdict\n\n    def minimize_qfm(self, tol=1e-3, maxiter=1000, method='SLSQP',\n                     constraint_weight=1.):\n        r\"\"\"\n        This function tries to find the surface that approximately solves\n\n        .. math::\n            \\min_{S} f(S)\n\n        subject to\n\n        .. math::\n            \\texttt{label} = \\texttt{labeltarget}\n\n        where :math:`f(S)` is the QFM residual. This is done using method,\n        either 'SLSQP' or 'LBFGS'. If 'LBFGS' is chosen, a penalized formulation\n        is used defined by constraint_weight. If 'SLSQP' is chosen, constraint_weight\n        is not used, and the constrained optimization problem is solved.\n        \"\"\"\n        if method == 'SLSQP':\n            return self.minimize_qfm_exact_constraints_SLSQP(\n                tol=tol, maxiter=maxiter)\n        elif method == 'LBFGS':\n            return self.minimize_qfm_penalty_constraints_LBFGS(\n                tol=tol, maxiter=maxiter, constraint_weight=constraint_weight)\n        else:\n            raise ValueError",
  "def __init__(self, biotsavart, surface, label, targetlabel):\n        self.biotsavart = biotsavart\n        self.surface = surface\n        self.label = label\n        self.targetlabel = targetlabel\n        self.qfm = QfmResidual(surface, biotsavart)\n        self.name = str(id(self))",
  "def qfm_label_constraint(self, x, derivatives=0):\n        r\"\"\"\n        Returns the residual\n\n        .. math::\n            0.5 (\\texttt{label} - \\texttt{labeltarget})^2\n\n        and optionally the gradient wrt surface params.\n        \"\"\"\n        assert derivatives in [0, 1]\n        self.surface.x = x\n        l = self.label.J()\n        rl = l - self.targetlabel\n        val = 0.5 * rl ** 2\n\n        if derivatives:\n            dl = self.label.dJ_by_dsurfacecoefficients()\n            dval = rl * dl\n            return val, dval\n        else:\n            return val",
  "def qfm_objective(self, x, derivatives=0):\n        r\"\"\"\n        Returns the residual\n\n        .. math::\n            f(S)\n\n        and optionally the gradient wrt surface params where :math:`f(S)`` is\n        the QFM residual defined in surfaceobjectives.py.\n        \"\"\"\n\n        assert derivatives in [0, 1]\n        self.surface.x = x\n        qfm = self.qfm\n\n        r = qfm.J()\n\n        if not derivatives:\n            return r\n        else:\n            dr = qfm.dJ_by_dsurfacecoefficients()\n            return r, dr",
  "def qfm_penalty_constraints(self, x, derivatives=0, constraint_weight=1):\n        r\"\"\"\n        Returns the residual\n\n        .. math::\n            f(S) + 0.5 \\texttt{constraint_weight} (\\texttt{label} - \\texttt{labeltarget})^2\n\n        and optionally the gradient and Hessian wrt surface params where\n        :math:`f(S)` is the QFM residual defined in :mod:`surfaceobjectives.py`.\n        \"\"\"\n\n        assert derivatives in [0, 1]\n        s = self.surface\n        s.x = x\n\n        qfm = self.qfm\n\n        r = qfm.J()\n\n        l = self.label.J()\n        rl = l - self.targetlabel\n\n        val = r + 0.5 * constraint_weight * rl**2\n        if derivatives == 0:\n            return val\n\n        dr = qfm.dJ_by_dsurfacecoefficients()\n\n        dl = self.label.dJ_by_dsurfacecoefficients()\n\n        dval = dr + constraint_weight*rl*dl\n        return val, dval",
  "def minimize_qfm_penalty_constraints_LBFGS(self, tol=1e-3, maxiter=1000,\n                                               constraint_weight=1.):\n        r\"\"\"\n        This function tries to find the surface that approximately solves\n\n        .. math::\n            \\min_S f(S) + 0.5 \\texttt{constraint_weight} (\\texttt{label} - \\texttt{labeltarget})^2\n\n        where :math:`f(S)` is the QFM residual defined in :mod:`surfaceobjectives.py.`\n        This is done using LBFGS.\n        \"\"\"\n\n        s = self.surface\n        x = s.x\n        fn = lambda x: self.qfm_penalty_constraints(\n            x, derivatives=1, constraint_weight=constraint_weight)\n        res = minimize(\n            fn, x, jac=True, method='L-BFGS-B',\n            options={'maxiter': maxiter, 'ftol': tol, 'gtol': tol,\n                     'maxcor': 200})\n\n        resdict = {\n            \"fun\": res.fun, \"gradient\": res.jac, \"iter\": res.nit, \"info\": res,\n            \"success\": res.success,\n        }\n        s.x = res.x\n        resdict['s'] = s\n\n        return resdict",
  "def minimize_qfm_exact_constraints_SLSQP(self, tol=1e-3, maxiter=1000):\n        r\"\"\"\n        This function tries to find the surface that approximately solves\n\n        .. math::\n            \\min_{S} f(S)\n\n        subject to\n\n        .. math::\n            \\texttt{label} = \\texttt{labeltarget}\n\n        where :math:`f(S)` is the QFM residual. This is done using SLSQP.\n        \"\"\"\n        s = self.surface\n        x = s.x\n\n        fun = lambda x: self.qfm_objective(x, derivatives=1)\n        con = lambda x: self.qfm_label_constraint(x, derivatives=1)[0]\n        dcon = lambda x: self.qfm_label_constraint(x, derivatives=1)[1]\n\n        nlc = NonlinearConstraint(con, 0, 0)\n        eq_constraints = [{'type': 'eq', 'fun': con, 'jac': dcon}]\n        res = minimize(\n            fun, x, jac=True, method='SLSQP', constraints=eq_constraints,\n            options={'maxiter': maxiter, 'ftol': tol})\n\n        resdict = {\n            \"fun\": res.fun, \"gradient\": res.jac, \"iter\": res.nit, \"info\": res,\n            \"success\": res.success,\n        }\n        s.x = res.x\n        resdict['s'] = s\n\n        return resdict",
  "def minimize_qfm(self, tol=1e-3, maxiter=1000, method='SLSQP',\n                     constraint_weight=1.):\n        r\"\"\"\n        This function tries to find the surface that approximately solves\n\n        .. math::\n            \\min_{S} f(S)\n\n        subject to\n\n        .. math::\n            \\texttt{label} = \\texttt{labeltarget}\n\n        where :math:`f(S)` is the QFM residual. This is done using method,\n        either 'SLSQP' or 'LBFGS'. If 'LBFGS' is chosen, a penalized formulation\n        is used defined by constraint_weight. If 'SLSQP' is chosen, constraint_weight\n        is not used, and the constrained optimization problem is solved.\n        \"\"\"\n        if method == 'SLSQP':\n            return self.minimize_qfm_exact_constraints_SLSQP(\n                tol=tol, maxiter=maxiter)\n        elif method == 'LBFGS':\n            return self.minimize_qfm_penalty_constraints_LBFGS(\n                tol=tol, maxiter=maxiter, constraint_weight=constraint_weight)\n        else:\n            raise ValueError",
  "def isbool(val):\n    \"\"\"\n    Test whether val is any boolean type, either the native python\n    ``bool`` or numpy's ``bool_``.\n    \"\"\"\n    return isinstance(val, (bool, np.bool_))",
  "def isnumber(val):\n    \"\"\"\n    Test whether val is any kind of number, including both native\n    python types or numpy types.\n    \"\"\"\n    return isinstance(val, Number)",
  "class Struct:\n    \"\"\"\n    This class is just a dummy mutable object to which we can add attributes.\n    \"\"\"",
  "def unique(inlist):\n    \"\"\"\n    Given a list or tuple, return a list in which all duplicate\n    entries have been removed. Unlike a python set, the order of\n    entries in the original list will be preserved.  There is surely\n    a faster algorithm than the one used here, but this function will\n    not be used in performance-critical code.\n    \"\"\"\n\n    outlist = []\n    seen = set()\n    for j in inlist:\n        if j not in seen:\n            outlist.append(j)\n            seen.add(j)\n    return outlist",
  "class ImmutableId:\n    \"\"\"\n    Immutable class with a single attribute id to represent instance ids. Used\n    in conjuction with InstanceCounterMeta metaclass to generate immutable\n    instance ids starting with 1 for each of the different classes sublcassing\n    InstanceCounterMeta\n    \"\"\"\n    id: Integral",
  "class InstanceCounterMeta(type):\n    \"\"\"\n    Metaclass to make instance counter not share count with descendants\n\n    Ref: https://stackoverflow.com/questions/8628123/counting-instances-of-a-class\n    Credits: https://stackoverflow.com/users/3246302/ratiotile\n    \"\"\"\n    def __init__(cls, name, bases, attrs):\n        super().__init__(name, bases, attrs)\n        cls._ids = itertools.count(1)",
  "class RegisterMeta(type):\n    \"\"\"\n    RegisterMeta class can be used to register functions with easy to identify\n    names.\n\n    Note:\n        The class is not used anymore, but kept to explore the idea 3 explained\n        below\n\n\n    The functionality of RegisterMeta is explained with the Spec class\n    defined in simsopt.mhd.spec module. Spec class, which is a subclass\n    of Optimizable, implements two functions volume and iota, which are\n    used by child Optimizables nodes.\n\n    One could register the two functions of Spec class in a couple of ways.\n\n    1. .. code-block:: python\n\n            Spec.return_fn_map = {'volume': Spec.volume, 'iota': Spec.iota}\n\n    2. .. code-block:: python\n\n            Spec.volume = Spec.register_return_fn(\"volume\")(Spec.volume)\n            Spec.iota = Spec.register_return_fn(\"iota\")(Spec.iota)\n\n    3. TO BE IMPLEMENTED\n\n       .. code-block:: python\n\n            class Spec\n                ...\n\n                @register_return_fn(\"volume\")\n                def volume(self, ...):\n                    ...\n\n                @register_return_fn(\"iota\")\n                def iota(self, ...):\n                    ...\n    \"\"\"\n    def __init__(cls, name, bases, attrs):\n        super().__init__(name, bases, attrs)\n        cls.return_fn_map = {}\n\n        def _register_return_fn(name):\n            def inner_register(f):\n                cls.return_fn_map[name] = f\n                return f\n            return inner_register\n\n        cls.register_return_fn = _register_return_fn",
  "class OptimizableMeta(InstanceCounterMeta, ABCMeta, type(Curve)):\n    \"\"\"\n    Meta class for Optimizable class that works with pybind11. Here\n    type(simsoptpp.Curve) is used to obtain the pybind11_type, which can\n    be a parent class from py37\n    \"\"\"\n    pass",
  "class ObjectiveFailure(Exception):\n    \"\"\"\n    Defines a custom exception used to indicate failure when\n    evaluating the objective function. For example, if Vmec or Spec\n    fail to converge, this exception will be thrown. The simsopt\n    solvers will catch this specific exception (not others) and set\n    the objective function to a large number.\n    \"\"\"\n    pass",
  "class DofLengthMismatchError(Exception):\n    \"\"\"\n    Exception raised for errors where the length of supplied DOFs does\n    not match with the length of free DOFs.\n    Especially useful to prevent fully fixed DOFs from not raising Error\n    and to prevent broadcasting of a single DOF\n    \"\"\"\n\n    def __init__(self,\n                 input_dof_length: Integral,\n                 optim_dof_length: Integral,\n                 message: str = None):\n        if message is None:\n            message = f\"Input dof proerpty size, {input_dof_length}, does not \" + \\\n                      f\"match with Optimizable dof size {optim_dof_length}\"\n        super().__init__(message)",
  "def finite_difference_steps(x: RealArray,\n                            abs_step: Real = 1.0e-7,\n                            rel_step: Real = 0.0\n                            ) -> RealArray:\n    \"\"\"\n    Determine an array of step sizes for calculating finite-difference\n    derivatives, using absolute or relative step sizes, or a mixture\n    thereof.\n\n    For each element ``x_j`` of the state vector ``x``, the step size\n    ``s_j`` is determined from\n\n    ``s_j = max(abs(x_j) * rel_step, abs_step)``\n\n    So, if you want to use the same absolute step size for all\n    elements of ``x``, set ``rel_step = 0`` and set ``abs_step``\n    positive. Or, if you want to use the same relative step size for\n    all elements of ``x``, set ``abs_step = 0`` and ``rel_step``\n    positive. If both ``abs_step`` and ``rel_step`` are positive, then\n    ``abs_step`` effectively gives the lower bound on the step size.\n\n    It is dangerous to set ``abs_step`` to exactly 0, since then if\n    any elements of ``x`` are 0, the step size will be 0. In this\n    situation, ``ValueError`` will be raised. It is preferable for\n    ``abs_step`` to be a small positive value.\n\n    For one-sided finite differences, the values of ``x_j`` used will\n    be ``x_j + s_j``. For centered finite differences, the values of\n    ``x_j`` used will be ``x_j + s_j`` and ``x_j - s_j``.\n\n    This routine is used by :func:`simsopt._core.dofs.fd_jac()` and\n    :func:`simsopt.solve.mpi.fd_jac_mpi()`.\n\n    Args:\n        x: The state vector at which you wish to compute the gradient\n          or Jacobian. Must be a 1D array.\n        abs_step: The absolute step size.\n        rel_step: The relative step size.\n\n    Returns:\n        A 1D numpy array of the same size as ``x``, with each element\n        being the step size used for each corresponding element of\n        ``x``.\n    \"\"\"\n    if abs_step < 0:\n        raise ValueError('abs_step must be >= 0')\n    if rel_step < 0:\n        raise ValueError('rel_step must be >= 0')\n\n    steps = np.max((np.abs(x) * rel_step, np.full(len(x), abs_step)),\n                   axis=0)\n\n    # If abs_step == 0 and any elements of x are 0, we could end up\n    # with a step of size 0:\n    if np.any(steps == 0.0):\n        raise ValueError('Finite difference step size cannot be 0. ' \\\n                         'Increase abs_step.')\n\n    return steps",
  "def nested_lists_to_array(ll):\n    \"\"\"\n    Convert a ragged list of lists to a 2D numpy array.  Any entries\n    that are None are replaced by 0. This routine is useful for\n    parsing fortran namelists that include 2D arrays using f90nml.\n\n    Args:\n        ll: A list of lists to convert.\n    \"\"\"\n    mdim = len(ll)\n    ndim = np.max([len(x) for x in ll])\n    arr = np.zeros((mdim, ndim))\n    for jm, l in enumerate(ll):\n        for jn, x in enumerate(l):\n            if x is not None:\n                arr[jm, jn] = x\n    return arr",
  "class WeakKeyDefaultDict(WeakKeyDictionary):\n    \"\"\"\n    A simple implementation of defaultdict that uses WeakKeyDictionary as its\n    parent class instead of standard dictionary.\n    \"\"\"\n\n    def __init__(self, default_factory=None, *args, **kwargs):\n        self.default_factory = default_factory\n        super().__init__(*args, **kwargs)\n\n    def __missing__(self, key):\n        if self.default_factory:\n            self[key] = self.default_factory()\n            return self[key]\n        else:\n            raise KeyError(key)\n\n    def __getitem__(self, key):\n        try:\n            return super().__getitem__(key)\n        except:\n            return self.__missing__(key)",
  "def parallel_loop_bounds(comm, n):\n    \"\"\"\n    Split up an array [0, 1, ..., n-1] across an mpi communicator.  Example: n\n    = 8, comm with size=2 will return (0, 4) on core 0, (4, 8) on core 1,\n    meaning that the array is split up as [0, 1, 2, 3] + [4, 5, 6, 7].\n    \"\"\"\n\n    if comm is None:\n        return 0, n\n    else:\n        size = comm.size\n        idxs = [i*n//size for i in range(size+1)]\n        assert idxs[0] == 0\n        assert idxs[-1] == n\n        return idxs[comm.rank], idxs[comm.rank+1]",
  "def __init__(cls, name, bases, attrs):\n        super().__init__(name, bases, attrs)\n        cls._ids = itertools.count(1)",
  "def __init__(cls, name, bases, attrs):\n        super().__init__(name, bases, attrs)\n        cls.return_fn_map = {}\n\n        def _register_return_fn(name):\n            def inner_register(f):\n                cls.return_fn_map[name] = f\n                return f\n            return inner_register\n\n        cls.register_return_fn = _register_return_fn",
  "def __init__(self,\n                 input_dof_length: Integral,\n                 optim_dof_length: Integral,\n                 message: str = None):\n        if message is None:\n            message = f\"Input dof proerpty size, {input_dof_length}, does not \" + \\\n                      f\"match with Optimizable dof size {optim_dof_length}\"\n        super().__init__(message)",
  "def __init__(self, default_factory=None, *args, **kwargs):\n        self.default_factory = default_factory\n        super().__init__(*args, **kwargs)",
  "def __missing__(self, key):\n        if self.default_factory:\n            self[key] = self.default_factory()\n            return self[key]\n        else:\n            raise KeyError(key)",
  "def __getitem__(self, key):\n        try:\n            return super().__getitem__(key)\n        except:\n            return self.__missing__(key)",
  "def _register_return_fn(name):\n            def inner_register(f):\n                cls.return_fn_map[name] = f\n                return f\n            return inner_register",
  "def inner_register(f):\n                cls.return_fn_map[name] = f\n                return f",
  "def _load_redirect(redirect_file):\n    try:\n        with open(redirect_file) as f:\n            yaml = YAML()\n            d = yaml.load(f)\n    except OSError:\n        # If we can't find the file\n        # Just use an empty redirect dict\n        return {}\n\n    # Convert the full paths to module/class\n    redirect_dict = defaultdict(dict)\n    for old_path, new_path in d.items():\n        old_class = old_path.split(\".\")[-1]\n        old_module = \".\".join(old_path.split(\".\")[:-1])\n\n        new_class = new_path.split(\".\")[-1]\n        new_module = \".\".join(new_path.split(\".\")[:-1])\n\n        redirect_dict[old_module][old_class] = {\n            \"@module\": new_module,\n            \"@class\": new_class,\n        }\n\n    return dict(redirect_dict)",
  "class GSONable:\n    \"\"\"\n    This is a mix-in base class specifying an API for GSONable objects. GSON\n    is Graph JSON. This class aims to overcome the limitation of JSON in\n    serializing/deserializing of objects whose compositional pattern resembles\n    a direct acyclic graph (DAG). Essentially, GSONable objects must implement an as_dict\n    method, which must return a json serializable dict and also a unique path\n    within the json document plus a unique identifier,\n    and a from_dict class method that regenerates the object from the dict\n    generated by the as_dict method. The as_dict method should contain the\n    \"@module\", \"@class\", and \"@name\" keys which will allow the GSONEncoder to\n    dynamically deserialize the class. E.g.::\n        d[\"@module\"] = self.__class__.__module__\n        d[\"@class\"] = self.__class__.__name__\n        d[\"@name\"] = self.name\n    The \"@name\" should provide a unique id to represent the instance.\n    A default implementation is provided in GSONable, which automatically\n    determines if the class already contains self.argname or self._argname\n    attributes for every arg. If so, these will be used for serialization in\n    the dict format. Similarly, the default from_dict will deserialization\n    classes of such form. An example is given below::\n        class GSONClass(GSONable):\n        def __init__(self, a, b, c, d=1, **kwargs):\n            self.a = a\n            self.b = b\n            self._c = c\n            self._d = d\n            self.kwargs = kwargs\n    For such classes, you merely need to inherit from GSONable and you do not\n    need to implement your own as_dict or from_dict protocol.\n    GSONable objects need to have a `name` attribute that is unique.\n    Classes can be redirected to moved implementations by putting in the old\n    fully qualified path and new fully qualified path into .simsopt.yaml in the\n    home folder\n    Example:\n    old_module.old_class: new_module.new_class\n    \"\"\"\n\n    REDIRECT = _load_redirect(\n        os.path.join(os.path.expanduser(\"~\"), \".simsopt.yaml\"))\n\n    def as_dict(self, serial_objs_dict):\n        \"\"\"\n        A JSON serializable dict representation of an object.\n        \"\"\"\n        name = getattr(self, \"name\", str(id(self)))\n        d = {\"@module\": self.__class__.__module__,\n             \"@class\": self.__class__.__name__,\n             \"@name\": name}\n\n        try:\n            parent_module = \\\n                self.__class__.__module__.split(\".\", maxsplit=1)[0]\n            module_version = import_module(\n                parent_module).__version__  # type: ignore\n            d[\"@version\"] = str(module_version)\n        except (AttributeError, ImportError):\n            d[\"@version\"] = None  # type: ignore\n\n        spec = getfullargspec(self.__class__.__init__)\n        args = spec.args\n\n        def recursive_as_dict(obj):\n            if isinstance(obj, (list, tuple)):\n                return [recursive_as_dict(it) for it in obj]\n            if isinstance(obj, dict):\n                return {kk: recursive_as_dict(vv) for kk, vv in obj.items()}\n            if callable(obj) and not isinstance(obj, GSONable):\n                return _serialize_callable(obj, serial_objs_dict=serial_objs_dict)\n            if hasattr(obj, \"as_dict\"):\n                name = getattr(obj, \"name\", str(id(obj)))\n                if name not in serial_objs_dict:  # Add the path\n                    serial_obj = obj.as_dict(serial_objs_dict)  # serial_objs is modified in place\n                    serial_objs_dict[name] = serial_obj\n                return {\"$type\": \"ref\", \"value\": name}\n            return obj\n\n        for c in args:\n            if c != \"self\":\n                try:\n                    a = getattr(self, c)\n                except AttributeError:\n                    try:\n                        a = getattr(self, \"_\" + c)\n                    except AttributeError:\n                        print(f\"Missing attribute is {c}\")\n                        raise NotImplementedError(\n                            \"Unable to automatically determine as_dict \"\n                            \"format from class. GSONAble requires all \"\n                            \"args to be present as either self.argname or \"\n                            \"self._argname, and kwargs to be present under\"\n                            \"a self.kwargs variable to automatically \"\n                            \"determine the dict format. Alternatively, \"\n                            \"you can implement both as_dict and from_dict.\"\n                        )\n                d[c] = recursive_as_dict(a)\n        if hasattr(self, \"kwargs\"):\n            # type: ignore\n            d.update(**getattr(self, \"kwargs\"))  # pylint: disable=E1101\n        if spec.varargs is not None and getattr(self, spec.varargs,\n                                                None) is not None:\n            d.update({spec.varargs: getattr(self, spec.varargs)})\n        if hasattr(self, \"_kwargs\"):\n            d.update(**getattr(self, \"_kwargs\"))  # pylint: disable=E1101\n        if isinstance(self, Enum):\n            d.update({\"value\": self.value})  # pylint: disable=E1101\n        return d  # , serial_objs_dict\n\n    def as_dict2(self, serial_objs_dict):\n        \"\"\"\n        This is a slightly modified version of as_dict method to deal with the cases\n        where the supplied object itself needs to be added to serial_objs_dict.\n        \"\"\"\n        def recursive_as_dict(obj):\n            if isinstance(obj, (list, tuple)):\n                return [recursive_as_dict(it) for it in obj]\n            if isinstance(obj, dict):\n                return {kk: recursive_as_dict(vv) for kk, vv in obj.items()}\n            if callable(obj) and not isinstance(obj, GSONable):\n                return _serialize_callable(obj, serial_objs_dict=serial_objs_dict)\n            if hasattr(obj, \"as_dict\"):\n                name = getattr(obj, \"name\", str(id(obj)))\n                if name not in serial_objs_dict:  # Add the path\n                    serial_obj = obj.as_dict(serial_objs_dict)  # serial_objs is modified in place\n                    serial_objs_dict[name] = serial_obj\n                return {\"$type\": \"ref\", \"value\": name}\n            return obj\n\n        return recursive_as_dict(self)\n\n    @classmethod\n    def from_dict(cls, d, serial_objs_dict, recon_objs):\n        \"\"\"\n        :param d: Dict representation.\n        :return: GSONable class.\n        \"\"\"\n        decoded = {k: GSONDecoder().process_decoded(v, serial_objs_dict, recon_objs) for k, v in\n                   d.items() if not k.startswith(\"@\")}\n        return cls(**decoded)\n\n    def to_json(self) -> str:\n        \"\"\"\n        Returns a json string representation of the GSONable object.\n        \"\"\"\n        return json.dumps(SIMSON(self), cls=GSONEncoder)\n\n    @classmethod\n    def __get_validators__(cls):\n        \"\"\"Return validators for use in pydantic\"\"\"\n        yield cls.validate_gson\n\n    @classmethod\n    def validate_gson(cls, v):\n        \"\"\"\n        pydantic Validator for GSONable pattern\n        \"\"\"\n        if isinstance(v, cls):\n            return v\n        if isinstance(v, dict):\n            new_obj = GSONDecoder().process_decoded(v)\n            if isinstance(new_obj, cls):\n                return new_obj\n\n            new_obj = cls(**v)\n            return new_obj\n\n        raise ValueError(\n            f\"Must provide {cls.__name__}, the as_dict form, or the proper\")\n\n    @classmethod\n    def __modify_schema__(cls, field_schema):\n        \"\"\"JSON schema for GSONable pattern\"\"\"\n        field_schema.update(\n            {\n                \"type\": \"object\",\n                \"properties\": {\n                    \"@class\": {\"enum\": [cls.__name__], \"type\": \"string\"},\n                    \"@module\": {\"enum\": [cls.__module__], \"type\": \"string\"},\n                    \"@version\": {\"type\": \"string\"},\n                },\n                \"required\": [\"@class\", \"@module\"],\n            }\n        )",
  "class SIMSON:\n    \"\"\"\n    Wrapper class providing a scaffolding for serializing the graph\n    framework implemented in simsopt. This class aims to overcome the\n    limitation of JSON in serializing/deserializing of objects whose\n    compositional pattern resembles a direct acyclic graph (DAG). This\n    class is used to wrap the simsopt graph just before passing the simsopt\n    graph to serializing functions. Essentially, SIMSON generates an extra\n    dictionary that contains only serialized GSONable objects and the\n    conventionally generated JSON doc contains only references (by the way of\n    keys in the extra dictionary) for serialized GSONable objects.\n    Only one instance should be used to enclose the entire graph.\n    This class implements an as_dict method, which returns a json serializable\n    dict with two subdicts with keys: \"graph\" and \"simsopt_objs\". The \"graph\"\n    subdict consists of the json doc typically produced where all simsopt objs\n    replaced by their references in the \"simsopt_objs\" subdict. \"simsopt_objs\"\n    is a dict whose keys are the unique identifiers for simsopt objects and\n    the values are the serialized simsopt objects.\n    For deserialization a from_dict class method is implemented that\n    regenerates the object from the dicts\n    generated by the as_dict method. The as_dict method should contain the\n    \"@module\" and \"@class\" keys which will allow the GSONEncoder to\n    dynamically deserialize the class. E.g.::\n        d[\"@module\"] = self.__class__.__module__\n        d[\"@class\"] = self.__class__.__name__\n    \"\"\"\n\n    def __init__(self, simsopt_objs):\n        self.simsopt_objs = simsopt_objs\n\n    def as_dict(self, serial_objs_dict=None):\n        \"\"\"\n        A JSON serializable dict representation of an object.\n        \"\"\"\n        d = {\"@module\": self.__class__.__module__,\n             \"@class\": self.__class__.__name__}\n\n        try:\n            parent_module = \\\n                self.__class__.__module__.split(\".\", maxsplit=1)[0]\n            module_version = import_module(\n                parent_module).__version__  # type: ignore\n            d[\"@version\"] = str(module_version)\n        except (AttributeError, ImportError):\n            d[\"@version\"] = None  # type: ignore\n\n        serial_objs_dict = {}\n\n        def recursive_as_dict(obj):\n            if isinstance(obj, (list, tuple)):\n                return [recursive_as_dict(it) for it in obj]\n            if isinstance(obj, dict):\n                return {kk: recursive_as_dict(vv) for kk, vv in obj.items()}\n            if callable(obj) and not isinstance(obj, GSONable):\n                return _serialize_callable(obj, serial_objs_dict=serial_objs_dict)\n            if hasattr(obj, \"as_dict\"):\n                name = getattr(obj, \"name\", str(id(obj)))\n                if name not in serial_objs_dict:  # Add the path\n                    serial_obj = obj.as_dict(\n                        serial_objs_dict=serial_objs_dict)  # serial_objs is modified in place\n                    serial_objs_dict[name] = serial_obj\n                return {\"$type\": \"ref\", \"value\": name}\n            return obj\n\n        d[\"graph\"] = recursive_as_dict(self.simsopt_objs)\n        d[\"simsopt_objs\"] = serial_objs_dict\n        return d\n\n    @classmethod\n    def from_dict(cls, d, serial_objs_dict=None, recon_objs=None):\n        graph_subdict = d[\"graph\"]\n        serial_objs_dict = d[\"simsopt_objs\"]\n        gson_decoder = GSONDecoder()\n        recon_objs = {}\n        return gson_decoder.process_decoded(\n            graph_subdict, serial_objs_dict, recon_objs)",
  "class GSONEncoder(json.JSONEncoder):\n    \"\"\"\n    A Json Encoder which supports the GSONable API, plus adds support for\n    numpy arrays, datetime objects, bson ObjectIds (requires bson).\n    Usage::\n        # Add it as a *cls* keyword when using json.dump\n        json.dumps(object, cls=GSONEncoder)\n    \"\"\"\n\n    def default(self, o) -> dict:  # pylint: disable=E0202\n        \"\"\"\n        Overriding default method for JSON encoding. This method does two\n        things: (a) If an object has a to_dict property, return the to_dict\n        output. (b) If the @module and @class keys are not in the to_dict,\n        add them to the output automatically. If the object has no to_dict\n        property, the default Python json encoder default method is called.\n        Args:\n            o: Python object.\n        Return:\n            Python dict representation.\n        \"\"\"\n        if isinstance(o, datetime.datetime):\n            return {\"@module\": \"datetime\", \"@class\": \"datetime\",\n                    \"string\": str(o)}\n        if isinstance(o, UUID):\n            return {\"@module\": \"uuid\", \"@class\": \"UUID\", \"string\": str(o)}\n\n        if jax is not None and isinstance(o, jax.Array):\n            o = np.asarray(o)\n\n        if isinstance(o, np.ndarray):\n            if str(o.dtype).startswith(\"complex\"):\n                return {\n                    \"@module\": \"numpy\",\n                    \"@class\": \"array\",\n                    \"dtype\": str(o.dtype),\n                    \"data\": [o.real.tolist(), o.imag.tolist()],\n                }\n            return {\n                \"@module\": \"numpy\",\n                \"@class\": \"array\",\n                \"dtype\": str(o.dtype),\n                \"data\": o.tolist(),\n            }\n        if isinstance(o, np.generic):\n            return o.item()\n\n        if pd is not None:\n            if isinstance(o, pd.DataFrame):\n                return {\n                    \"@module\": \"pandas\",\n                    \"@class\": \"DataFrame\",\n                    \"data\": o.to_json(\n                        default_handler=GSONEncoder().encode),\n                }\n            if isinstance(o, pd.Series):\n                return {\n                    \"@module\": \"pandas\",\n                    \"@class\": \"Series\",\n                    \"data\": o.to_json(\n                        default_handler=GSONEncoder().encode),\n                }\n\n        if bson is not None:\n            if isinstance(o, bson.objectid.ObjectId):\n                return {\"@module\": \"bson.objectid\", \"@class\": \"ObjectId\",\n                        \"oid\": str(o)}\n\n        if callable(o) and not isinstance(o, GSONable):\n            return _serialize_callable(o)\n\n        try:\n            d = o.as_dict()\n            if hasattr(o, \"name\") and \"@name\" not in d:\n                d[\"@name\"] = o.name\n\n            if \"@module\" not in d:\n                d[\"@module\"] = str(o.__class__.__module__)\n            if \"@class\" not in d:\n                d[\"@class\"] = str(o.__class__.__name__)\n            if \"@version\" not in d:\n                try:\n                    parent_module = o.__class__.__module__.split(\".\")[0]\n                    module_version = import_module(\n                        parent_module).__version__  # type: ignore\n                    d[\"@version\"] = str(module_version)\n                except (AttributeError, ImportError):\n                    d[\"@version\"] = None\n            return d\n        except AttributeError:\n            return json.JSONEncoder.default(self, o)",
  "class GSONDecoder(json.JSONDecoder):\n    \"\"\"\n    A Json Decoder which supports the GSONable API. By default, the\n    decoder attempts to find a module and name associated with a dict. If\n    found, the decoder will generate a SIMSOPT object as a priority.  If that fails,\n    the original decoded dictionary from the string is returned. Note that\n    nested lists and dicts containing pymatgen object will be decoded correctly\n    as well.\n    Usage:\n        # Add it as a *cls* keyword when using json.load\n        json.loads(json_string, cls=GSONDecoder)\n    \"\"\"\n\n    def process_decoded(self, d, serial_objs_dict=None, recon_objs=None):\n        \"\"\"\n        Recursive method to support decoding dicts and lists containing\n        GSONable objects.\n        \"\"\"\n        if isinstance(d, dict):\n            if \"$type\" in d.keys():\n                if d[\"$type\"] == \"ref\":\n                    if d[\"value\"] not in recon_objs:\n                        sub_dict = serial_objs_dict[d[\"value\"]]\n                        recon_obj = self.process_decoded(sub_dict,\n                                                         serial_objs_dict, recon_objs)\n                        recon_objs[d[\"value\"]] = recon_obj\n                    return recon_objs[d[\"value\"]]\n            if \"@module\" in d and \"@class\" in d:\n                modname = d[\"@module\"]\n                classname = d[\"@class\"]\n                if classname in GSONable.REDIRECT.get(modname, {}):\n                    modname = GSONable.REDIRECT[modname][classname][\n                        \"@module\"]\n                    classname = GSONable.REDIRECT[modname][classname][\n                        \"@class\"]\n            elif \"@module\" in d and \"@callable\" in d:\n                modname = d[\"@module\"]\n                objname = d[\"@callable\"]\n                classname = None\n                if d.get(\"@bound\", None) is not None:\n                    # if the function is bound to an instance or class, first\n                    # deserialize the bound object and then remove the object name\n                    # from the function name.\n                    obj = self.process_decoded(d[\"@bound\"], serial_objs_dict=serial_objs_dict,\n                                               recon_objs=recon_objs)\n                    objname = objname.split(\".\")[1:]\n                else:\n                    # if the function is not bound to an object, import the\n                    # function from the module name\n                    obj = __import__(modname, globals(), locals(),\n                                     [objname], 0)\n                    objname = objname.split(\".\")\n                try:\n                    # the function could be nested. e.g., MyClass.NestedClass.function\n                    # so iteratively access the nesting\n                    for attr in objname:\n                        obj = getattr(obj, attr)\n\n                    return obj\n\n                except AttributeError:\n                    pass\n            else:\n                modname = None\n                classname = None\n\n            if classname:\n\n                if modname and modname not in [\"bson.objectid\", \"numpy\",\n                                               \"pandas\"]:\n                    if modname == \"datetime\" and classname == \"datetime\":\n                        try:\n                            dt = datetime.datetime.strptime(d[\"string\"],\n                                                            \"%Y-%m-%d %H:%M:%S.%f\")\n                        except ValueError:\n                            dt = datetime.datetime.strptime(d[\"string\"],\n                                                            \"%Y-%m-%d %H:%M:%S\")\n                        return dt\n\n                    if modname == \"uuid\" and classname == \"UUID\":\n                        return UUID(d[\"string\"])\n\n                    mod = __import__(modname, globals(), locals(),\n                                     [classname], 0)\n                    if hasattr(mod, classname):\n                        cls_ = getattr(mod, classname)\n                        data = {k: v for k, v in d.items() if\n                                not k.startswith(\"@\")}\n                        if hasattr(cls_, \"from_dict\"):\n                            obj = cls_.from_dict(data, serial_objs_dict, recon_objs)\n                            if \"@name\" in d:\n                                recon_objs[d[\"@name\"]] = obj\n                            return obj\n                elif np is not None and modname == \"numpy\" and classname == \"array\":\n                    if d[\"dtype\"].startswith(\"complex\"):\n                        return np.array(\n                            [np.array(r) + np.array(i) * 1j for r, i in\n                             zip(*d[\"data\"])],\n                            dtype=d[\"dtype\"],\n                        )\n                    return np.array(d[\"data\"], dtype=d[\"dtype\"])\n                elif pd is not None and modname == \"pandas\":\n                    if classname == \"DataFrame\":\n                        decoded_data = GSONDecoder().decode(d[\"data\"])\n                        return pd.DataFrame(decoded_data)\n                    if classname == \"Series\":\n                        decoded_data = GSONDecoder().decode(d[\"data\"])\n                        return pd.Series(decoded_data)\n                elif (\n                        bson is not None) and modname == \"bson.objectid\" and classname == \"ObjectId\":\n                    return bson.objectid.ObjectId(d[\"oid\"])\n\n            return {self.process_decoded(k, serial_objs_dict, recon_objs): self.process_decoded(v, serial_objs_dict, recon_objs) for\n                    k, v in d.items()}\n\n        if isinstance(d, list):\n            return [self.process_decoded(x, serial_objs_dict, recon_objs) for x in d]\n\n        return d\n\n    def decode(self, s):\n        \"\"\"\n        Overrides decode from JSONDecoder.\n        :param s: string\n        :return: Object.\n        \"\"\"\n        if orjson is not None:\n            try:\n                d = orjson.loads(s)  # pylint: disable=E1101\n            except orjson.JSONDecodeError:  # pylint: disable=E1101\n                d = json.loads(s)\n        else:\n            d = json.loads(s)\n        return self.process_decoded(d)",
  "class GSONError(Exception):\n    \"\"\"\n    Exception class for serialization errors.\n    \"\"\"",
  "def jsanitize(obj, strict=False, allow_bson=False, enum_values=False,\n              recursive_gsonable=False, serial_objs_dict=None):\n    \"\"\"\n    This method cleans an input json-like object, either a list or a dict or\n    some sequence, nested or otherwise, by converting all non-string\n    dictionary keys (such as int and float) to strings, and also recursively\n    encodes all objects using GSON's as_dict() protocol.\n    Args:\n        obj: input json-like object.\n        strict (bool): This parameters sets the behavior when jsanitize\n            encounters an object it does not understand. If strict is True,\n            jsanitize will try to get the as_dict() attribute of the object. If\n            no such attribute is found, an attribute error will be thrown. If\n            strict is False, jsanitize will simply call str(object) to convert\n            the object to a string representation.\n        allow_bson (bool): This parameters sets the behavior when jsanitize\n            encounters a bson supported type such as objectid and datetime. If\n            True, such bson types will be ignored, allowing for proper\n            insertion into MongoDB databases.\n        enum_values (bool): Convert Enums to their values.\n        recursive_gsonable (bool): If True, uses .as_dict() for GSONables regardless\n            of the value of strict.\n        serial_objs_dict: Dictionary of serialized objects produced during jsonification\n    Returns:\n        Sanitized dict that can be json serialized.\n    \"\"\"\n    if serial_objs_dict is None:\n        serial_objs_dict = {}\n    if isinstance(obj, Enum) and enum_values:\n        return obj.value\n\n    if allow_bson and (\n            isinstance(obj, (datetime.datetime, bytes)) or (\n            bson is not None and isinstance(obj, bson.objectid.ObjectId))\n    ):\n        return obj\n    if isinstance(obj, (list, tuple)):\n        return [jsanitize(i, strict=strict, allow_bson=allow_bson,\n                          enum_values=enum_values) for i in obj]\n    if np is not None and isinstance(obj, np.ndarray):\n        return [jsanitize(i, strict=strict, allow_bson=allow_bson,\n                          enum_values=enum_values) for i in obj.tolist()]\n    if np is not None and isinstance(obj, np.generic):\n        return obj.item()\n    if pd is not None and isinstance(obj, (pd.Series, pd.DataFrame)):\n        return obj.to_dict()\n    if isinstance(obj, dict):\n        return {\n            str(k): jsanitize(\n                v,\n                strict=strict,\n                allow_bson=allow_bson,\n                enum_values=enum_values,\n                recursive_gsonable=recursive_gsonable,\n            )\n            for k, v in obj.items()\n        }\n    if isinstance(obj, (int, float)):\n        return obj\n    if obj is None:\n        return None\n    if isinstance(obj, pathlib.Path):\n        return str(obj)\n\n    if callable(obj) and not isinstance(obj, GSONable):\n        try:\n            return _serialize_callable(obj)\n        except TypeError:\n            pass\n\n    if recursive_gsonable and isinstance(obj, GSONable):\n        return obj.as_dict(serial_objs_dict=serial_objs_dict)\n\n    if not strict:\n        return str(obj)\n\n    if isinstance(obj, str):\n        return obj\n\n    return jsanitize(\n        obj.as_dict(serial_objs_dict=serial_objs_dict),\n        strict=strict,\n        allow_bson=allow_bson,\n        enum_values=enum_values,\n        recursive_gsonable=recursive_gsonable,\n    )",
  "def _serialize_callable(o, serial_objs_dict={}):\n    if isinstance(o, types.BuiltinFunctionType):\n        # don't care about what builtin functions (sum, open, etc) are bound to\n        bound = None\n    else:\n        # bound methods (i.e., instance methods) have a __self__ attribute\n        # that points to the class/module/instance\n        bound = getattr(o, \"__self__\", None)\n\n    # we are only able to serialize bound methods if the object the method is\n    # bound to is itself serializable\n    if bound is not None:\n        if isinstance(bound, GSONable):\n            bound = bound.as_dict(serial_objs_dict=serial_objs_dict)\n        else:\n            try:\n                bound = GSONEncoder().default(bound)\n            except TypeError:\n                raise TypeError(\n                    \"Only bound methods of classes or GSONable instances are supported.\")\n\n    return {\n        \"@module\": o.__module__,\n        \"@callable\": getattr(o, \"__qualname__\", o.__name__),\n        \"@bound\": bound,\n    }",
  "def as_dict(self, serial_objs_dict):\n        \"\"\"\n        A JSON serializable dict representation of an object.\n        \"\"\"\n        name = getattr(self, \"name\", str(id(self)))\n        d = {\"@module\": self.__class__.__module__,\n             \"@class\": self.__class__.__name__,\n             \"@name\": name}\n\n        try:\n            parent_module = \\\n                self.__class__.__module__.split(\".\", maxsplit=1)[0]\n            module_version = import_module(\n                parent_module).__version__  # type: ignore\n            d[\"@version\"] = str(module_version)\n        except (AttributeError, ImportError):\n            d[\"@version\"] = None  # type: ignore\n\n        spec = getfullargspec(self.__class__.__init__)\n        args = spec.args\n\n        def recursive_as_dict(obj):\n            if isinstance(obj, (list, tuple)):\n                return [recursive_as_dict(it) for it in obj]\n            if isinstance(obj, dict):\n                return {kk: recursive_as_dict(vv) for kk, vv in obj.items()}\n            if callable(obj) and not isinstance(obj, GSONable):\n                return _serialize_callable(obj, serial_objs_dict=serial_objs_dict)\n            if hasattr(obj, \"as_dict\"):\n                name = getattr(obj, \"name\", str(id(obj)))\n                if name not in serial_objs_dict:  # Add the path\n                    serial_obj = obj.as_dict(serial_objs_dict)  # serial_objs is modified in place\n                    serial_objs_dict[name] = serial_obj\n                return {\"$type\": \"ref\", \"value\": name}\n            return obj\n\n        for c in args:\n            if c != \"self\":\n                try:\n                    a = getattr(self, c)\n                except AttributeError:\n                    try:\n                        a = getattr(self, \"_\" + c)\n                    except AttributeError:\n                        print(f\"Missing attribute is {c}\")\n                        raise NotImplementedError(\n                            \"Unable to automatically determine as_dict \"\n                            \"format from class. GSONAble requires all \"\n                            \"args to be present as either self.argname or \"\n                            \"self._argname, and kwargs to be present under\"\n                            \"a self.kwargs variable to automatically \"\n                            \"determine the dict format. Alternatively, \"\n                            \"you can implement both as_dict and from_dict.\"\n                        )\n                d[c] = recursive_as_dict(a)\n        if hasattr(self, \"kwargs\"):\n            # type: ignore\n            d.update(**getattr(self, \"kwargs\"))  # pylint: disable=E1101\n        if spec.varargs is not None and getattr(self, spec.varargs,\n                                                None) is not None:\n            d.update({spec.varargs: getattr(self, spec.varargs)})\n        if hasattr(self, \"_kwargs\"):\n            d.update(**getattr(self, \"_kwargs\"))  # pylint: disable=E1101\n        if isinstance(self, Enum):\n            d.update({\"value\": self.value})  # pylint: disable=E1101\n        return d",
  "def as_dict2(self, serial_objs_dict):\n        \"\"\"\n        This is a slightly modified version of as_dict method to deal with the cases\n        where the supplied object itself needs to be added to serial_objs_dict.\n        \"\"\"\n        def recursive_as_dict(obj):\n            if isinstance(obj, (list, tuple)):\n                return [recursive_as_dict(it) for it in obj]\n            if isinstance(obj, dict):\n                return {kk: recursive_as_dict(vv) for kk, vv in obj.items()}\n            if callable(obj) and not isinstance(obj, GSONable):\n                return _serialize_callable(obj, serial_objs_dict=serial_objs_dict)\n            if hasattr(obj, \"as_dict\"):\n                name = getattr(obj, \"name\", str(id(obj)))\n                if name not in serial_objs_dict:  # Add the path\n                    serial_obj = obj.as_dict(serial_objs_dict)  # serial_objs is modified in place\n                    serial_objs_dict[name] = serial_obj\n                return {\"$type\": \"ref\", \"value\": name}\n            return obj\n\n        return recursive_as_dict(self)",
  "def from_dict(cls, d, serial_objs_dict, recon_objs):\n        \"\"\"\n        :param d: Dict representation.\n        :return: GSONable class.\n        \"\"\"\n        decoded = {k: GSONDecoder().process_decoded(v, serial_objs_dict, recon_objs) for k, v in\n                   d.items() if not k.startswith(\"@\")}\n        return cls(**decoded)",
  "def to_json(self) -> str:\n        \"\"\"\n        Returns a json string representation of the GSONable object.\n        \"\"\"\n        return json.dumps(SIMSON(self), cls=GSONEncoder)",
  "def __get_validators__(cls):\n        \"\"\"Return validators for use in pydantic\"\"\"\n        yield cls.validate_gson",
  "def validate_gson(cls, v):\n        \"\"\"\n        pydantic Validator for GSONable pattern\n        \"\"\"\n        if isinstance(v, cls):\n            return v\n        if isinstance(v, dict):\n            new_obj = GSONDecoder().process_decoded(v)\n            if isinstance(new_obj, cls):\n                return new_obj\n\n            new_obj = cls(**v)\n            return new_obj\n\n        raise ValueError(\n            f\"Must provide {cls.__name__}, the as_dict form, or the proper\")",
  "def __modify_schema__(cls, field_schema):\n        \"\"\"JSON schema for GSONable pattern\"\"\"\n        field_schema.update(\n            {\n                \"type\": \"object\",\n                \"properties\": {\n                    \"@class\": {\"enum\": [cls.__name__], \"type\": \"string\"},\n                    \"@module\": {\"enum\": [cls.__module__], \"type\": \"string\"},\n                    \"@version\": {\"type\": \"string\"},\n                },\n                \"required\": [\"@class\", \"@module\"],\n            }\n        )",
  "def __init__(self, simsopt_objs):\n        self.simsopt_objs = simsopt_objs",
  "def as_dict(self, serial_objs_dict=None):\n        \"\"\"\n        A JSON serializable dict representation of an object.\n        \"\"\"\n        d = {\"@module\": self.__class__.__module__,\n             \"@class\": self.__class__.__name__}\n\n        try:\n            parent_module = \\\n                self.__class__.__module__.split(\".\", maxsplit=1)[0]\n            module_version = import_module(\n                parent_module).__version__  # type: ignore\n            d[\"@version\"] = str(module_version)\n        except (AttributeError, ImportError):\n            d[\"@version\"] = None  # type: ignore\n\n        serial_objs_dict = {}\n\n        def recursive_as_dict(obj):\n            if isinstance(obj, (list, tuple)):\n                return [recursive_as_dict(it) for it in obj]\n            if isinstance(obj, dict):\n                return {kk: recursive_as_dict(vv) for kk, vv in obj.items()}\n            if callable(obj) and not isinstance(obj, GSONable):\n                return _serialize_callable(obj, serial_objs_dict=serial_objs_dict)\n            if hasattr(obj, \"as_dict\"):\n                name = getattr(obj, \"name\", str(id(obj)))\n                if name not in serial_objs_dict:  # Add the path\n                    serial_obj = obj.as_dict(\n                        serial_objs_dict=serial_objs_dict)  # serial_objs is modified in place\n                    serial_objs_dict[name] = serial_obj\n                return {\"$type\": \"ref\", \"value\": name}\n            return obj\n\n        d[\"graph\"] = recursive_as_dict(self.simsopt_objs)\n        d[\"simsopt_objs\"] = serial_objs_dict\n        return d",
  "def from_dict(cls, d, serial_objs_dict=None, recon_objs=None):\n        graph_subdict = d[\"graph\"]\n        serial_objs_dict = d[\"simsopt_objs\"]\n        gson_decoder = GSONDecoder()\n        recon_objs = {}\n        return gson_decoder.process_decoded(\n            graph_subdict, serial_objs_dict, recon_objs)",
  "def default(self, o) -> dict:  # pylint: disable=E0202\n        \"\"\"\n        Overriding default method for JSON encoding. This method does two\n        things: (a) If an object has a to_dict property, return the to_dict\n        output. (b) If the @module and @class keys are not in the to_dict,\n        add them to the output automatically. If the object has no to_dict\n        property, the default Python json encoder default method is called.\n        Args:\n            o: Python object.\n        Return:\n            Python dict representation.\n        \"\"\"\n        if isinstance(o, datetime.datetime):\n            return {\"@module\": \"datetime\", \"@class\": \"datetime\",\n                    \"string\": str(o)}\n        if isinstance(o, UUID):\n            return {\"@module\": \"uuid\", \"@class\": \"UUID\", \"string\": str(o)}\n\n        if jax is not None and isinstance(o, jax.Array):\n            o = np.asarray(o)\n\n        if isinstance(o, np.ndarray):\n            if str(o.dtype).startswith(\"complex\"):\n                return {\n                    \"@module\": \"numpy\",\n                    \"@class\": \"array\",\n                    \"dtype\": str(o.dtype),\n                    \"data\": [o.real.tolist(), o.imag.tolist()],\n                }\n            return {\n                \"@module\": \"numpy\",\n                \"@class\": \"array\",\n                \"dtype\": str(o.dtype),\n                \"data\": o.tolist(),\n            }\n        if isinstance(o, np.generic):\n            return o.item()\n\n        if pd is not None:\n            if isinstance(o, pd.DataFrame):\n                return {\n                    \"@module\": \"pandas\",\n                    \"@class\": \"DataFrame\",\n                    \"data\": o.to_json(\n                        default_handler=GSONEncoder().encode),\n                }\n            if isinstance(o, pd.Series):\n                return {\n                    \"@module\": \"pandas\",\n                    \"@class\": \"Series\",\n                    \"data\": o.to_json(\n                        default_handler=GSONEncoder().encode),\n                }\n\n        if bson is not None:\n            if isinstance(o, bson.objectid.ObjectId):\n                return {\"@module\": \"bson.objectid\", \"@class\": \"ObjectId\",\n                        \"oid\": str(o)}\n\n        if callable(o) and not isinstance(o, GSONable):\n            return _serialize_callable(o)\n\n        try:\n            d = o.as_dict()\n            if hasattr(o, \"name\") and \"@name\" not in d:\n                d[\"@name\"] = o.name\n\n            if \"@module\" not in d:\n                d[\"@module\"] = str(o.__class__.__module__)\n            if \"@class\" not in d:\n                d[\"@class\"] = str(o.__class__.__name__)\n            if \"@version\" not in d:\n                try:\n                    parent_module = o.__class__.__module__.split(\".\")[0]\n                    module_version = import_module(\n                        parent_module).__version__  # type: ignore\n                    d[\"@version\"] = str(module_version)\n                except (AttributeError, ImportError):\n                    d[\"@version\"] = None\n            return d\n        except AttributeError:\n            return json.JSONEncoder.default(self, o)",
  "def process_decoded(self, d, serial_objs_dict=None, recon_objs=None):\n        \"\"\"\n        Recursive method to support decoding dicts and lists containing\n        GSONable objects.\n        \"\"\"\n        if isinstance(d, dict):\n            if \"$type\" in d.keys():\n                if d[\"$type\"] == \"ref\":\n                    if d[\"value\"] not in recon_objs:\n                        sub_dict = serial_objs_dict[d[\"value\"]]\n                        recon_obj = self.process_decoded(sub_dict,\n                                                         serial_objs_dict, recon_objs)\n                        recon_objs[d[\"value\"]] = recon_obj\n                    return recon_objs[d[\"value\"]]\n            if \"@module\" in d and \"@class\" in d:\n                modname = d[\"@module\"]\n                classname = d[\"@class\"]\n                if classname in GSONable.REDIRECT.get(modname, {}):\n                    modname = GSONable.REDIRECT[modname][classname][\n                        \"@module\"]\n                    classname = GSONable.REDIRECT[modname][classname][\n                        \"@class\"]\n            elif \"@module\" in d and \"@callable\" in d:\n                modname = d[\"@module\"]\n                objname = d[\"@callable\"]\n                classname = None\n                if d.get(\"@bound\", None) is not None:\n                    # if the function is bound to an instance or class, first\n                    # deserialize the bound object and then remove the object name\n                    # from the function name.\n                    obj = self.process_decoded(d[\"@bound\"], serial_objs_dict=serial_objs_dict,\n                                               recon_objs=recon_objs)\n                    objname = objname.split(\".\")[1:]\n                else:\n                    # if the function is not bound to an object, import the\n                    # function from the module name\n                    obj = __import__(modname, globals(), locals(),\n                                     [objname], 0)\n                    objname = objname.split(\".\")\n                try:\n                    # the function could be nested. e.g., MyClass.NestedClass.function\n                    # so iteratively access the nesting\n                    for attr in objname:\n                        obj = getattr(obj, attr)\n\n                    return obj\n\n                except AttributeError:\n                    pass\n            else:\n                modname = None\n                classname = None\n\n            if classname:\n\n                if modname and modname not in [\"bson.objectid\", \"numpy\",\n                                               \"pandas\"]:\n                    if modname == \"datetime\" and classname == \"datetime\":\n                        try:\n                            dt = datetime.datetime.strptime(d[\"string\"],\n                                                            \"%Y-%m-%d %H:%M:%S.%f\")\n                        except ValueError:\n                            dt = datetime.datetime.strptime(d[\"string\"],\n                                                            \"%Y-%m-%d %H:%M:%S\")\n                        return dt\n\n                    if modname == \"uuid\" and classname == \"UUID\":\n                        return UUID(d[\"string\"])\n\n                    mod = __import__(modname, globals(), locals(),\n                                     [classname], 0)\n                    if hasattr(mod, classname):\n                        cls_ = getattr(mod, classname)\n                        data = {k: v for k, v in d.items() if\n                                not k.startswith(\"@\")}\n                        if hasattr(cls_, \"from_dict\"):\n                            obj = cls_.from_dict(data, serial_objs_dict, recon_objs)\n                            if \"@name\" in d:\n                                recon_objs[d[\"@name\"]] = obj\n                            return obj\n                elif np is not None and modname == \"numpy\" and classname == \"array\":\n                    if d[\"dtype\"].startswith(\"complex\"):\n                        return np.array(\n                            [np.array(r) + np.array(i) * 1j for r, i in\n                             zip(*d[\"data\"])],\n                            dtype=d[\"dtype\"],\n                        )\n                    return np.array(d[\"data\"], dtype=d[\"dtype\"])\n                elif pd is not None and modname == \"pandas\":\n                    if classname == \"DataFrame\":\n                        decoded_data = GSONDecoder().decode(d[\"data\"])\n                        return pd.DataFrame(decoded_data)\n                    if classname == \"Series\":\n                        decoded_data = GSONDecoder().decode(d[\"data\"])\n                        return pd.Series(decoded_data)\n                elif (\n                        bson is not None) and modname == \"bson.objectid\" and classname == \"ObjectId\":\n                    return bson.objectid.ObjectId(d[\"oid\"])\n\n            return {self.process_decoded(k, serial_objs_dict, recon_objs): self.process_decoded(v, serial_objs_dict, recon_objs) for\n                    k, v in d.items()}\n\n        if isinstance(d, list):\n            return [self.process_decoded(x, serial_objs_dict, recon_objs) for x in d]\n\n        return d",
  "def decode(self, s):\n        \"\"\"\n        Overrides decode from JSONDecoder.\n        :param s: string\n        :return: Object.\n        \"\"\"\n        if orjson is not None:\n            try:\n                d = orjson.loads(s)  # pylint: disable=E1101\n            except orjson.JSONDecodeError:  # pylint: disable=E1101\n                d = json.loads(s)\n        else:\n            d = json.loads(s)\n        return self.process_decoded(d)",
  "def recursive_as_dict(obj):\n            if isinstance(obj, (list, tuple)):\n                return [recursive_as_dict(it) for it in obj]\n            if isinstance(obj, dict):\n                return {kk: recursive_as_dict(vv) for kk, vv in obj.items()}\n            if callable(obj) and not isinstance(obj, GSONable):\n                return _serialize_callable(obj, serial_objs_dict=serial_objs_dict)\n            if hasattr(obj, \"as_dict\"):\n                name = getattr(obj, \"name\", str(id(obj)))\n                if name not in serial_objs_dict:  # Add the path\n                    serial_obj = obj.as_dict(serial_objs_dict)  # serial_objs is modified in place\n                    serial_objs_dict[name] = serial_obj\n                return {\"$type\": \"ref\", \"value\": name}\n            return obj",
  "def recursive_as_dict(obj):\n            if isinstance(obj, (list, tuple)):\n                return [recursive_as_dict(it) for it in obj]\n            if isinstance(obj, dict):\n                return {kk: recursive_as_dict(vv) for kk, vv in obj.items()}\n            if callable(obj) and not isinstance(obj, GSONable):\n                return _serialize_callable(obj, serial_objs_dict=serial_objs_dict)\n            if hasattr(obj, \"as_dict\"):\n                name = getattr(obj, \"name\", str(id(obj)))\n                if name not in serial_objs_dict:  # Add the path\n                    serial_obj = obj.as_dict(serial_objs_dict)  # serial_objs is modified in place\n                    serial_objs_dict[name] = serial_obj\n                return {\"$type\": \"ref\", \"value\": name}\n            return obj",
  "def recursive_as_dict(obj):\n            if isinstance(obj, (list, tuple)):\n                return [recursive_as_dict(it) for it in obj]\n            if isinstance(obj, dict):\n                return {kk: recursive_as_dict(vv) for kk, vv in obj.items()}\n            if callable(obj) and not isinstance(obj, GSONable):\n                return _serialize_callable(obj, serial_objs_dict=serial_objs_dict)\n            if hasattr(obj, \"as_dict\"):\n                name = getattr(obj, \"name\", str(id(obj)))\n                if name not in serial_objs_dict:  # Add the path\n                    serial_obj = obj.as_dict(\n                        serial_objs_dict=serial_objs_dict)  # serial_objs is modified in place\n                    serial_objs_dict[name] = serial_obj\n                return {\"$type\": \"ref\", \"value\": name}\n            return obj",
  "class Validator(ABC):\n    \"\"\"\n    Validator is the abstract base class implementing the descriptor protocol.\n    It implements the ``__get__`` and ``__set__`` methods as well as the\n    ``__set_name__`` method of the descriptor protocol. The implementation\n    follows the strategy outlined in the official python documentation.\n    \"\"\"\n\n    def __set_name__(self, owner, name):\n        self.public_name = name\n        self.private_name = f\"_{name}\"\n\n    def __get__(self, obj, objtype=None):\n        return getattr(obj, self.private_name)\n\n    def __set__(self, obj, value):\n        self.validate(value)\n        setattr(obj, self.private_name, value)\n\n    @abstractmethod\n    def validate(self, value):\n        \"\"\"\n        All subclasses implement validate method to check for various constraints\n        \"\"\"\n        pass",
  "class OneOf(Validator):\n    \"\"\"\n    OneOf is used to define descriptors which take only specific values\n    as inputs.\n\n    Args:\n        args: All the specific values that the descriptor can accept\n    \"\"\"\n\n    def __init__(self, *args):\n        self.options = set(args)\n\n    def validate(self, value):\n        if value not in self.options:\n            raise ValueError(f'{value!r} is not a valid option for {self.public_name!r}.\\n'\n                             f'Valid options are one of {self.options!r}')\n        super().validate(value)",
  "class String(Validator):\n    \"\"\"\n    Validates that the input is a string and implements some other checks\n    for string object.\n\n    Args:\n        minsize: Minimum size of the input string\n        maxsize: Maximum size of the input string\n        predicate: Callable function that is used to do any other checks\n            on the string\n    \"\"\"\n    minsize: int = None\n    maxsize: int = None\n    predicate: Callable[[str], bool] = None\n\n    def validate(self, value):\n        if not isinstance(value, str):\n            raise TypeError(f'Expected {value!r} to be an str')\n        if self.minsize is not None and len(value) < self.minsize:\n            raise ValueError(\n                f'Expected {value!r} to be no smaller than {self.minsize!r}')\n        if self.maxsize is not None and len(value) > self.maxsize:\n            raise ValueError(\n                f'Expected {value!r} to be no bigger than {self.maxsize!r}')\n        if self.predicate is not None and not self.predicate(value):\n            raise ValueError(\n                f'Expected {self.predicate} to be true for {value!r}')\n        super().validate(value)",
  "class _Real(Validator):\n    \"\"\"\n    Validates that the input is a real number.\n    \"\"\"\n\n    def validate(self, value):\n        if not isinstance(value, numbers.Real):\n            raise TypeError(\n                f'Expected {value!r} should be of Real type')\n        super().validate(value)",
  "class _Integral(Validator):\n    \"\"\"\n    Validates that the input is an integer.\n    \"\"\"\n\n    def validate(self, value):\n        if not isinstance(value, numbers.Integral):\n            raise TypeError(\n                f'Expected {value!r} should be of Integer type')\n        super().validate(value)",
  "class RangeChecker(Validator):\n    \"\"\"\n    Validates that the input number is within specific bounds.\n\n    Args:\n        min_value: Minimum acceptable value\n        max_value: Maximum acceptable value\n    \"\"\"\n    min_value: numbers.Real = None\n    max_value: numbers.Real = None\n\n    def validate(self, value):\n        if self.min_value is not None and value < self.min_value:\n            raise ValueError(\n                f'Expected {value!r} to be at least {self.min_value!r}')\n        if self.max_value is not None and value > self.max_value:\n            raise ValueError(\n                f'Expected {value!r} to be no more than {self.max_value!r}')\n        super().validate(value)",
  "class PositiveChecker(RangeChecker):\n    \"\"\"\n    Validates that the input number is a positive number.\n    \"\"\"\n\n    def __init__(self):\n        super().__init__(min_value=0)",
  "class Integer(_Integral, RangeChecker):\n    \"\"\"\n    Validates that the input number is an integer. Optionally the user can specify\n    the bounds for the number.\n    \"\"\"\n\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n\n    def validate(self, value):\n        super().validate(value)",
  "class PositiveInteger(Integer, PositiveChecker):\n    \"\"\"\n    Validates that the input number is a positive integer number.\n    \"\"\"\n\n    def validate(self, value):\n        super().validate(value)",
  "class Float(_Real, RangeChecker):\n    \"\"\"\n    Validates that the input number is a real number. Optionally the user can specify\n    the bounds for the number\n    \"\"\"\n\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n\n    def validate(self, value):\n        super().validate(value)",
  "class PositiveFloat(_Real, PositiveChecker):\n    \"\"\"\n    Validates that the input number is a positive real number.\n    \"\"\"\n\n    def validate(self, value):\n        super().validate(value)",
  "class OneofStrings(String, OneOf):\n    \"\"\"\n    Validates that the input is among the specified strings.\n\n    Args:\n        *args: All the acceptable values for the string\n    \"\"\"\n\n    def __init__(self, *args):\n        OneOf.__init__(self, *args)\n\n    def validate(self, value):\n        super().validate(value)",
  "class OneofIntegers(_Integral, OneOf):\n    \"\"\"\n    Validates that the input is among the specified integers.\n\n    Args:\n        *args: All the acceptable values for the integer\n    \"\"\"\n\n    def __init__(self, *args):\n        OneOf.__init__(self, *args)\n\n    def validate(self, value):\n        super().validate(value)",
  "def __set_name__(self, owner, name):\n        self.public_name = name\n        self.private_name = f\"_{name}\"",
  "def __get__(self, obj, objtype=None):\n        return getattr(obj, self.private_name)",
  "def __set__(self, obj, value):\n        self.validate(value)\n        setattr(obj, self.private_name, value)",
  "def validate(self, value):\n        \"\"\"\n        All subclasses implement validate method to check for various constraints\n        \"\"\"\n        pass",
  "def __init__(self, *args):\n        self.options = set(args)",
  "def validate(self, value):\n        if value not in self.options:\n            raise ValueError(f'{value!r} is not a valid option for {self.public_name!r}.\\n'\n                             f'Valid options are one of {self.options!r}')\n        super().validate(value)",
  "def validate(self, value):\n        if not isinstance(value, str):\n            raise TypeError(f'Expected {value!r} to be an str')\n        if self.minsize is not None and len(value) < self.minsize:\n            raise ValueError(\n                f'Expected {value!r} to be no smaller than {self.minsize!r}')\n        if self.maxsize is not None and len(value) > self.maxsize:\n            raise ValueError(\n                f'Expected {value!r} to be no bigger than {self.maxsize!r}')\n        if self.predicate is not None and not self.predicate(value):\n            raise ValueError(\n                f'Expected {self.predicate} to be true for {value!r}')\n        super().validate(value)",
  "def validate(self, value):\n        if not isinstance(value, numbers.Real):\n            raise TypeError(\n                f'Expected {value!r} should be of Real type')\n        super().validate(value)",
  "def validate(self, value):\n        if not isinstance(value, numbers.Integral):\n            raise TypeError(\n                f'Expected {value!r} should be of Integer type')\n        super().validate(value)",
  "def validate(self, value):\n        if self.min_value is not None and value < self.min_value:\n            raise ValueError(\n                f'Expected {value!r} to be at least {self.min_value!r}')\n        if self.max_value is not None and value > self.max_value:\n            raise ValueError(\n                f'Expected {value!r} to be no more than {self.max_value!r}')\n        super().validate(value)",
  "def __init__(self):\n        super().__init__(min_value=0)",
  "def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)",
  "def validate(self, value):\n        super().validate(value)",
  "def validate(self, value):\n        super().validate(value)",
  "def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)",
  "def validate(self, value):\n        super().validate(value)",
  "def validate(self, value):\n        super().validate(value)",
  "def __init__(self, *args):\n        OneOf.__init__(self, *args)",
  "def validate(self, value):\n        super().validate(value)",
  "def __init__(self, *args):\n        OneOf.__init__(self, *args)",
  "def validate(self, value):\n        super().validate(value)",
  "class SimsoptRequires(requires):\n    def __call__(self, _callable):\n        \"\"\"\n        :param _callable: Callable function or class.\n        \"\"\"\n        self._callable = _callable\n\n        @functools.wraps(_callable)\n        def decorated(*args, **kwargs):\n            if not self.condition:\n                raise RuntimeError(self.message)\n            return _callable(*args, **kwargs)\n\n        return decorated\n\n    @property\n    def __class(self):\n        return self._callable\n\n    def __instancecheck__(self, other):\n        return isinstance(other, self._callable)",
  "def deprecated(replacement=None, message=None, category=FutureWarning):\n    \"\"\"\n    Decorator to mark classes or functions as deprecated,\n    with a possible replacement.\n    Credits: monty.dev package from Materials Virtual Lab\n\n    Args:\n        replacement (callable): A replacement class or method.\n        message (str): A warning message to be displayed.\n        category (Warning): Choose the category of the warning to issue. Defaults\n            to FutureWarning. Another choice can be DeprecationWarning. NOte that\n            FutureWarning is meant for end users and is always shown unless silenced.\n            DeprecationWarning is meant for developers and is never shown unless\n            python is run in developmental mode or the filter is changed. Make\n            the choice accordingly.\n\n    Returns:\n        Original function, but with a warning to use the updated class.\n    \"\"\"\n\n    def wrap(old):\n        @functools.wraps(old)\n        def wrapped(*args, **kwargs):\n            msg = \"%s is deprecated\" % old.__name__\n            if replacement is not None:\n                if isinstance(replacement, property):\n                    r = replacement.fget\n                elif isinstance(replacement, (classmethod, staticmethod)):\n                    r = replacement.__func__\n                else:\n                    r = replacement\n                msg += \"; use %s in %s instead.\" % (r.__name__, r.__module__)\n            if message is not None:\n                msg += \"\\n\" + message\n            warnings.warn(msg, category=category, stacklevel=2)\n            return old(*args, **kwargs)\n\n        return wrapped\n\n    return wrap",
  "def __call__(self, _callable):\n        \"\"\"\n        :param _callable: Callable function or class.\n        \"\"\"\n        self._callable = _callable\n\n        @functools.wraps(_callable)\n        def decorated(*args, **kwargs):\n            if not self.condition:\n                raise RuntimeError(self.message)\n            return _callable(*args, **kwargs)\n\n        return decorated",
  "def __class(self):\n        return self._callable",
  "def __instancecheck__(self, other):\n        return isinstance(other, self._callable)",
  "def wrap(old):\n        @functools.wraps(old)\n        def wrapped(*args, **kwargs):\n            msg = \"%s is deprecated\" % old.__name__\n            if replacement is not None:\n                if isinstance(replacement, property):\n                    r = replacement.fget\n                elif isinstance(replacement, (classmethod, staticmethod)):\n                    r = replacement.__func__\n                else:\n                    r = replacement\n                msg += \"; use %s in %s instead.\" % (r.__name__, r.__module__)\n            if message is not None:\n                msg += \"\\n\" + message\n            warnings.warn(msg, category=category, stacklevel=2)\n            return old(*args, **kwargs)\n\n        return wrapped",
  "def decorated(*args, **kwargs):\n            if not self.condition:\n                raise RuntimeError(self.message)\n            return _callable(*args, **kwargs)",
  "def wrapped(*args, **kwargs):\n            msg = \"%s is deprecated\" % old.__name__\n            if replacement is not None:\n                if isinstance(replacement, property):\n                    r = replacement.fget\n                elif isinstance(replacement, (classmethod, staticmethod)):\n                    r = replacement.__func__\n                else:\n                    r = replacement\n                msg += \"; use %s in %s instead.\" % (r.__name__, r.__module__)\n            if message is not None:\n                msg += \"\\n\" + message\n            warnings.warn(msg, category=category, stacklevel=2)\n            return old(*args, **kwargs)",
  "class OptimizableDefaultDict(collections.defaultdict):\n    \"\"\"\n    Custom defaultdict that automatically returns a numpy array of zeros of\n    size equal to the number of free dofs when the key wasn't found.\n    \"\"\"\n\n    def __init__(self, d):\n        super().__init__(None, d)\n\n    def __missing__(self, key):\n        from .optimizable import Optimizable  # Import here to avoid circular import\n        assert isinstance(key, Optimizable)\n        self[key] = value = np.zeros((key.local_full_dof_size, ))\n        return value",
  "def copy_numpy_dict(d):\n    res = OptimizableDefaultDict({})\n    for k, v in d.items():\n        res[k] = v.copy()\n    return res",
  "class Derivative:\n\n    \"\"\"\n    This class stores the derivative of a scalar output wrt to the individual\n    ``Optimizable`` classes that are required to compute this output.\n\n    The idea of this class is as follows:\n\n    Consider a situation\n\n    .. code-block::\n\n        inA = OptimA()\n        inB = OptimB()\n        inter1 = Intermediate1(inA, inB)\n        inter2 = Intermediate2(inA, inB)\n        obj = Objective(inter1, inter2)\n\n    Then ``obj.dJ(partials=True)`` will return a ``Derivative`` object containing a dictionary\n\n    .. code-block::\n\n        {\n            inA : dobj/dinA,\n            inB : dobj/dinB,\n        }\n\n    with\n\n    .. code-block::\n\n        dobj/dinA = dobj/dinter1 * dinter1/dinA + dobj/dinter2 * dinter2/dinA\n        dobj/dinB = dobj/dinter1 * dinter1/dinB + dobj/dinter2 * dinter2/dinB\n\n    SIMSOPT computes these derivatives by first computing ``dobj/dinter1`` and ``dobj/dinter2``\n    and then passing this vector to ``Intermediate1.vjp`` and ``Intermediate2.vjp``, which returns\n\n    .. code-block::\n\n        {\n            inA: dobj/dinter1 * dinter1/dinA\n            inB: dobj/dinter1 * dinter1/dinB\n        }\n\n    and \n\n    .. code-block::\n\n        {\n            inA: dobj/dinter2 * dinter2/dinA\n            inB: dobj/dinter2 * dinter2/dinB\n        }\n\n    respectively. Due to the overloaded ``__add__`` and ``__iadd__`` functions adding the ``Derivative`` objects then results in the desired\n\n    .. code-block::\n\n        {\n            inA: dobj/dinter1 * dinter1/dinA + dobj/dinter2 * dinter2/dinA\n            inB: dobj/dinter1 * dinter1/dinB + dobj/dinter2 * dinter2/dinB\n        }\n\n    This ``Derivative`` can then be used to obtain partial derivatives or the full gradient of ``J``, via\n\n    .. code-block::\n\n        dJ = obj.dJ(partials=True)\n        dJ_by_dinA = dJ(inA) # derivative of Objective w.r.t. to OptimA\n        dJ_by_dinB = dJ(inB) # derivative of Objective w.r.t. to OptimB\n        gradJ = dJ(obj) # gradient of Objective\n\n    For the common case in which you just want the gradient of\n    ``obj.J`` and do not need the individual partial derivatives, the\n    argument ``partials=True`` can be omitted in ``obj.dJ()``. In this\n    case, ``obj.dJ()`` directly returns the gradient rather than\n    returning the ``Derivative`` object, acting as a shorthand for\n    ``obj.dJ(partials=True)(obj)``. This behavior is implemented with\n    the decorator :obj:`derivative_dec`.\n    \"\"\"\n\n    def __init__(self, data=OptimizableDefaultDict({})):\n        self.data = OptimizableDefaultDict(data)\n\n    def __add__(self, other):\n        x = self.data\n        y = other.data\n        z = copy_numpy_dict(x)\n        for k in y:\n            if k in z:\n                z[k] += y[k]\n            else:\n                z[k] = y[k].copy()\n        return Derivative(z)\n\n    def __sub__(self, other):\n        x = self.data\n        y = other.data\n        z = copy_numpy_dict(x)\n        for k, yk in y.items():\n            if k in z:\n                z[k] -= yk\n            else:\n                z[k] = -yk\n        return Derivative(z)\n\n    def __iadd__(self, other):\n        x = self.data\n        y = other.data\n        for k, yk in y.items():\n            if k in x:\n                x[k] += yk\n            else:\n                x[k] = yk.copy()\n        return self\n\n    def __isub__(self, other):\n        x = self.data\n        y = other.data\n        for k, yk in y.items():\n            if k in x:\n                x[k] -= yk\n            else:\n                x[k] = -yk\n        return self\n\n    def __mul__(self, other):\n        assert isinstance(other, numbers.Number)\n        x = copy_numpy_dict(self.data)\n        for k in x:\n            x[k] *= other\n        return Derivative(x)\n\n    def __rmul__(self, other):\n        assert isinstance(other, numbers.Number)\n        x = copy_numpy_dict(self.data)\n        for k in x:\n            x[k] *= other\n        return Derivative(x)\n\n    def __call__(self, optim, as_derivative=False):\n        \"\"\"\n        Get the derivative with respect to all DOFs that ``optim`` depends on.\n\n        Args:\n            optim: An Optimizable object\n        \"\"\"\n        from .optimizable import Optimizable  # Import here to avoid circular import\n        assert isinstance(optim, Optimizable)\n        derivs = []\n        keys = []\n        for k in optim.unique_dof_lineage:\n            if np.any(k.dofs_free_status):\n                local_derivs = np.zeros(k.local_dof_size)\n                for opt in k.dofs.dep_opts():\n                    local_derivs += self.data[opt][opt.local_dofs_free_status]\n                    keys.append(opt)\n                derivs.append(local_derivs)\n\n        if as_derivative:\n            return Derivative({k: d for k, d in zip(keys, derivs)})\n        else:\n            return np.concatenate(derivs)\n\n    # https://stackoverflow.com/questions/11624955/avoiding-python-sum-default-start-arg-behavior\n    def __radd__(self, other):\n        # This allows sum() to work (the default start value is zero)\n        if other == 0:\n            return self\n        return self.__add__(other)",
  "def derivative_dec(func):\n    \"\"\"\n    This decorator is applied to functions of Optimizable objects that\n    return a derivative, typically named ``dJ()``. This allows\n    ``obj.dJ()`` to provide a shorthand for the full gradient,\n    equivalent to ``obj.dJ(partials=True)(obj)``. If\n    ``partials=True``, the underlying :obj:`Derivative` object will be\n    returned, so partial derivatives can be accessed and combined to\n    assemble gradients.\n    \"\"\"\n\n    def _derivative_dec(self, *args, partials=False, **kwargs):\n        if partials:\n            return func(self, *args, **kwargs)\n        else:\n            return func(self, *args, **kwargs)(self)\n    return _derivative_dec",
  "def __init__(self, d):\n        super().__init__(None, d)",
  "def __missing__(self, key):\n        from .optimizable import Optimizable  # Import here to avoid circular import\n        assert isinstance(key, Optimizable)\n        self[key] = value = np.zeros((key.local_full_dof_size, ))\n        return value",
  "def __init__(self, data=OptimizableDefaultDict({})):\n        self.data = OptimizableDefaultDict(data)",
  "def __add__(self, other):\n        x = self.data\n        y = other.data\n        z = copy_numpy_dict(x)\n        for k in y:\n            if k in z:\n                z[k] += y[k]\n            else:\n                z[k] = y[k].copy()\n        return Derivative(z)",
  "def __sub__(self, other):\n        x = self.data\n        y = other.data\n        z = copy_numpy_dict(x)\n        for k, yk in y.items():\n            if k in z:\n                z[k] -= yk\n            else:\n                z[k] = -yk\n        return Derivative(z)",
  "def __iadd__(self, other):\n        x = self.data\n        y = other.data\n        for k, yk in y.items():\n            if k in x:\n                x[k] += yk\n            else:\n                x[k] = yk.copy()\n        return self",
  "def __isub__(self, other):\n        x = self.data\n        y = other.data\n        for k, yk in y.items():\n            if k in x:\n                x[k] -= yk\n            else:\n                x[k] = -yk\n        return self",
  "def __mul__(self, other):\n        assert isinstance(other, numbers.Number)\n        x = copy_numpy_dict(self.data)\n        for k in x:\n            x[k] *= other\n        return Derivative(x)",
  "def __rmul__(self, other):\n        assert isinstance(other, numbers.Number)\n        x = copy_numpy_dict(self.data)\n        for k in x:\n            x[k] *= other\n        return Derivative(x)",
  "def __call__(self, optim, as_derivative=False):\n        \"\"\"\n        Get the derivative with respect to all DOFs that ``optim`` depends on.\n\n        Args:\n            optim: An Optimizable object\n        \"\"\"\n        from .optimizable import Optimizable  # Import here to avoid circular import\n        assert isinstance(optim, Optimizable)\n        derivs = []\n        keys = []\n        for k in optim.unique_dof_lineage:\n            if np.any(k.dofs_free_status):\n                local_derivs = np.zeros(k.local_dof_size)\n                for opt in k.dofs.dep_opts():\n                    local_derivs += self.data[opt][opt.local_dofs_free_status]\n                    keys.append(opt)\n                derivs.append(local_derivs)\n\n        if as_derivative:\n            return Derivative({k: d for k, d in zip(keys, derivs)})\n        else:\n            return np.concatenate(derivs)",
  "def __radd__(self, other):\n        # This allows sum() to work (the default start value is zero)\n        if other == 0:\n            return self\n        return self.__add__(other)",
  "def _derivative_dec(self, *args, partials=False, **kwargs):\n        if partials:\n            return func(self, *args, **kwargs)\n        else:\n            return func(self, *args, **kwargs)(self)",
  "class DOFs(GSONable, Hashable):\n    \"\"\"\n    Defines the (D)egrees (O)f (F)reedom(s) associated with optimization\n\n    This class holds data related to the degrees of freedom\n    associated with an Optimizable object. To access the data stored in\n    the DOFs class, use the labels shown shown in the table below.\n\n    =============  =============\n    External name  Internal name\n    =============  =============\n    x              _x\n    free           _free\n    lower_bounds   _lower_bounds\n    upper_bounds   _upper_bounds\n    names          _names\n    =============  =============\n\n    The class implements the external name column properties in the above\n    table as properties. Additional methods to update bounds, fix/unfix DOFs,\n    etc. are also defined.\n    \"\"\"\n    __slots__ = [\"_x\", \"_free\", \"_lower_bounds\", \"_upper_bounds\", \"_names\", \"_dep_opts\"]\n\n    def __init__(self,\n                 x: RealArray = None,  # To enable empty DOFs object\n                 names: StrArray = None,\n                 free: BoolArray = None,\n                 lower_bounds: RealArray = None,\n                 upper_bounds: RealArray = None) -> None:\n        \"\"\"\n        Args:\n            x: Numeric values of the DOFs\n            names: Names of the dofs\n            free: Array of boolean values denoting if the DOFs is are free.\n                  False values implies the corresponding DOFs are fixed\n            lower_bounds: Lower bounds for the DOFs. Meaningful only if\n                DOF is not fixed. Default is np.NINF\n            upper_bounds: Upper bounds for the DOFs. Meaningful only if\n                DOF is not fixed. Default is np.inf\n        \"\"\"\n        if x is None:\n            x = np.array([])\n        else:\n            x = np.asarray(x, dtype=np.double)\n\n        if names is None:\n            names = [f\"x{i}\" for i in range(len(x))]\n        assert (len(np.unique(names)) == len(names))  # DOF names should be unique\n\n        if free is None:\n            free = np.full(len(x), True)\n        else:\n            free = np.asarray(free, dtype=np.bool_)\n\n        if lower_bounds is None:\n            lower_bounds = np.full(len(x), np.NINF)\n        else:\n            lower_bounds = np.asarray(lower_bounds, np.double)\n\n        if upper_bounds is None:\n            upper_bounds = np.full(len(x), np.inf)\n        else:\n            upper_bounds = np.asarray(upper_bounds, np.double)\n\n        assert (len(x) == len(free) == len(lower_bounds) == len(upper_bounds) \\\n                == len(names))\n        self._x = x\n        self._free = free\n        self._lower_bounds = lower_bounds\n        self._upper_bounds = upper_bounds\n        self._names = list(names)\n        self._dep_opts = []\n        self._hash = id(self) % 10**32  # 32 digit int as hash\n        self.name = str(id(self))   # For serialization\n\n    def __hash__(self):\n        return self._hash\n\n    def add_opt(self, opt):\n        \"\"\"\n        Adds the Optimizable object to the list of dependent Optimizable objects\n        \"\"\"\n        weakref_opt = weakref.ref(opt)\n        if weakref_opt not in self._dep_opts:\n            self._dep_opts.append(weakref_opt)\n\n    def remove_opt(self, opt):\n        weakref_opt = weakref.ref(opt)\n        if weakref_opt in self._dep_opts:\n            self._dep_opts.remove(weakref_opt)\n\n    def dep_opts(self):\n        opts = []\n        for opt_ref in self._dep_opts:\n            opt = opt_ref()\n            if opt is not None:\n                # yield opt\n                opts.append(opt)\n        return opts\n\n    def _flag_recompute_opt(self):\n        \"\"\"\n        Sets the recompute flag in the dependent Optimizable objects.\n        This function is called whenever the DOF values are changed.\n        \"\"\"\n        for opt_ref in self._dep_opts:\n            opt = opt_ref()\n            if opt is not None:\n                if opt.local_dof_setter is not None:\n                    # opt.local_dof_setter(opt, list(self._x))\n                    opt.local_dof_setter(opt, self._x)\n                opt.set_recompute_flag()\n\n    def _update_opt_indices(self):\n        \"\"\"\n        Updates the free DOF indices in the dependent Optimizable objects.\n        This function is called whenever a DOF is fixed or set free.\n        \"\"\"\n        for opt_ref in self._dep_opts:\n            opt = opt_ref()\n            if opt is not None:\n                opt.update_free_dof_size_indices()\n\n    def __len__(self):\n        return len(self._free)\n\n    def fix(self, key: Key) -> None:\n        \"\"\"\n        Fixes the specified DOF\n\n        Args:\n            key: Key to identify the DOF\n        \"\"\"\n        if isinstance(key, str):\n            key = self._names.index(key)\n        self._free[key] = False\n        self._update_opt_indices()\n\n    def unfix(self, key: Key) -> None:\n        \"\"\"\n        Unfixes the specified DOF\n\n        Args:\n            key: Key to identify the DOF\n        \"\"\"\n        if isinstance(key, str):\n            key = self._names.index(key)\n        self._free[key] = True\n        self._update_opt_indices()\n\n    def all_free(self) -> bool:\n        \"\"\"\n        Checks if all DOFs are allowed to be varied\n\n        Returns:\n            True if all DOFs are free to changed\n        \"\"\"\n        return self._free.all()\n\n    def all_fixed(self) -> bool:\n        \"\"\"\n        Checks if all the DOFs are fixed\n\n        Returns:\n            True if all DOFs are fixed\n        \"\"\"\n        return not self._free.any()\n\n    @property\n    def free_status(self) -> BoolArray:\n        return self._free\n\n    def get(self, key: Key) -> Real:\n        \"\"\"\n        Get the value of specified DOF. Even fixed DOFs can\n        be obtained with this method\n\n        Args:\n        key: Key to identify the DOF\n        Returns:\n            Value of the DOF\n        \"\"\"\n        if isinstance(key, str):\n            key = self._names.index(key)\n        return self._x[key]\n\n    def set(self, key: Key, val: Real):\n        \"\"\"\n        Modify the value of specified DOF. Even fixed DOFs can\n        modified with this method\n\n        Args:\n        key: Key to identify the DOF\n        val: Value of the DOF\n        \"\"\"\n        if isinstance(key, str):\n            key = self._names.index(key)\n        self._x[key] = val\n        self._flag_recompute_opt()\n\n    def is_free(self, key: Key) -> bool:\n        \"\"\"\n        Get the status of the specified DOF.\n\n        Args:\n        key: Key to identify the DOF\n        Returns:\n            Status of the DOF\n        \"\"\"\n        if isinstance(key, str):\n            key = self._names.index(key)\n        return self._free[key]\n\n    def fix_all(self) -> None:\n        \"\"\"\n        Fixes all the DOFs\n        \"\"\"\n        self._free.fill(False)\n        self._update_opt_indices()\n\n    def unfix_all(self) -> None:\n        \"\"\"\n        Makes all DOFs variable\n        Caution: Make sure the bounds are well defined\n        \"\"\"\n        self._free.fill(True)\n        self._update_opt_indices()\n\n    def any_free(self) -> bool:\n        \"\"\"\n        Checks for any free DOFs\n\n        Returns:\n            True if any free DOF is found, else False\n        \"\"\"\n        return self._free.any()\n\n    def any_fixed(self) -> bool:\n        \"\"\"\n        Checks for any free DOFs\n\n        Returns:\n            True if any fixed DOF is found, else False\n        \"\"\"\n        return not self._free.all()\n\n    @property\n    def free_x(self) -> RealArray:\n        \"\"\"\n\n        Returns:\n            The values of the free DOFs.\n        \"\"\"\n        return self._x[self._free]\n\n    @free_x.setter\n    def free_x(self, x: RealArray) -> None:\n        \"\"\"\n        Update the values of the free DOFs with the supplied values\n\n        Args:\n            x: Array of new DOF values\n               (word of caution: This setter blindly broadcasts a single value.\n               So don't supply a single value unless you really desire.)\n        \"\"\"\n        # To prevent fully fixed DOFs from not raising Error\n        # And to prevent broadcasting of a single DOF\n        if self.reduced_len != len(x):\n            raise DofLengthMismatchError(len(x), self.reduced_len)\n        self._x[self._free] = np.asarray(x, dtype=np.double)\n        self._flag_recompute_opt()\n\n    @property\n    def full_x(self) -> RealArray:\n        \"\"\"\n        Return all x even the fixed ones\n\n        Returns:\n            The values of full DOFs without any restrictions\n        \"\"\"\n        return self._x\n\n    @full_x.setter\n    def full_x(self, x: RealArray) -> None:\n        \"\"\"\n        Update the values of the all DOFs with the supplied values\n\n        Args:\n            x: Array of new DOF values\n        .. warning::\n               Even fixed DOFs are assinged\n        \"\"\"\n        # To prevent broadcasting of a single DOF\n        if len(self._x) != len(x):\n            raise DofLengthMismatchError(len(x), len(self._x))\n        self._x = np.asarray(x, dtype=np.double)\n        self._flag_recompute_opt()\n\n    @property\n    def reduced_len(self) -> Integral:\n        \"\"\"\n        The number of free DOFs.\n\n        The standard len function returns the full length of DOFs.\n\n        Returns:\n            The number of free DOFs\n        \"\"\"\n        return len(self._free[self._free])\n\n    @property\n    def free_lower_bounds(self) -> RealArray:\n        \"\"\"\n        Lower bounds of the DOFs\n\n        Returns:\n            Lower bounds of the DOFs\n        \"\"\"\n        return self._lower_bounds[self._free]\n\n    @free_lower_bounds.setter\n    def free_lower_bounds(self, lower_bounds: RealArray) -> None:\n        \"\"\"\n\n        Args:\n            lower_bounds: Lower bounds of the DOFs\n        \"\"\"\n        # To prevent fully fixed DOFs from not raising Error\n        # and to prevent broadcasting of a single DOF\n        if self.reduced_len != len(lower_bounds):\n            raise DofLengthMismatchError(len(lower_bounds), self.reduced_len)\n        self._lower_bounds[self._free] = np.asarray(lower_bounds, dtype=np.double)\n\n    @property\n    def full_lower_bounds(self) -> RealArray:\n        return self._lower_bounds\n\n    @full_lower_bounds.setter\n    def full_lower_bounds(self, lower_bounds: RealArray) -> None:\n        \"\"\"\n        Set the full lower bounds\n\n        Args:\n            lower_bounds: Lower bounds of the DOFs\n        \"\"\"\n        if len(self.lower_bounds) != len(lower_bounds):\n            raise DofLengthMismatchError(len(lower_bounds), len(self.lower_bounds))\n        self._lower_bounds = np.asarray(lower_bounds, dtype=np.double)\n\n    @property\n    def free_upper_bounds(self) -> RealArray:\n        \"\"\"\n\n        Returns:\n            Upper bounds of the DOFs\n        \"\"\"\n        return self._upper_bounds[self._free]\n\n    @free_upper_bounds.setter\n    def free_upper_bounds(self, upper_bounds: RealArray) -> None:\n        \"\"\"\n\n        Args:\n            upper_bounds: Upper bounds of the DOFs\n        \"\"\"\n        # To prevent fully fixed DOFs from not raising Error\n        # and to prevent broadcasting of a single DOF\n        if self.reduced_len != len(upper_bounds):\n            raise DofLengthMismatchError(len(upper_bounds), self.reduced_len)\n        self._upper_bounds[self._free] = np.asarray(upper_bounds, dtype=np.double)\n\n    @property\n    def full_upper_bounds(self) -> RealArray:\n        return self._upper_bounds\n\n    @full_upper_bounds.setter\n    def full_upper_bounds(self, upper_bounds: RealArray) -> None:\n        \"\"\"\n        Set the full upper bounds\n\n        Args:\n            upper_bounds: Upper bounds of the DOFs\n        \"\"\"\n        if len(self.upper_bounds) != len(upper_bounds):\n            raise DofLengthMismatchError(len(upper_bounds), len(self.upper_bounds))\n        self._upper_bounds = np.asarray(upper_bounds, dtype=np.double)\n\n    @property\n    def bounds(self) -> Tuple[RealArray, RealArray]:\n        \"\"\"\n\n        Returns:\n            (Lower bounds list, Upper bounds list)\n        \"\"\"\n        return (self.free_lower_bounds, self.free_upper_bounds)\n\n    @property\n    def full_bounds(self) -> Tuple[RealArray, RealArray]:\n        return (self.full_lower_bounds, self.full_upper_bounds)\n\n    def update_lower_bound(self, key: Key, val: Real) -> None:\n        \"\"\"\n        Updates the lower bound of the specified DOF to the given value\n\n        Args:\n            key: DOF identifier\n            val: Numeric lower bound of the DOF\n        \"\"\"\n        if isinstance(key, str):\n            key = self._names.index(key)\n        self._lower_bounds[key] = val\n\n    def update_upper_bound(self, key: Key, val: Real) -> None:\n        \"\"\"\n        Updates the upper bound of the specified DOF to the given value\n\n        Args:\n            key: DOF identifier\n            val: Numeric upper bound of the DOF\n        \"\"\"\n        if isinstance(key, str):\n            key = self._names.index(key)\n        self._upper_bounds[key] = val\n\n    def update_bounds(self, key: Key, val: Tuple[Real, Real]) -> None:\n        \"\"\"\n        Updates the bounds of the specified DOF to the given value\n\n        Args:\n            key: DOF identifier\n            val: (lower, upper) bounds of the DOF\n        \"\"\"\n        if isinstance(key, str):\n            key = self._names.index(key)\n        self._lower_bounds[key] = val[0]\n        self._upper_bounds[key] = val[1]\n\n    @property\n    def free_names(self):\n        \"\"\"\n\n        Returns:\n            string identifiers of the DOFs\n        \"\"\"\n        @lru_cache()\n        def red_names(free):\n            rnames = []\n            for i, f in enumerate((free)):\n                if f:\n                    rnames.append(self._names[i])\n            return rnames\n        return red_names(tuple(self._free))\n\n    @property\n    def full_names(self):\n        return self._names",
  "class Optimizable(ABC_Callable, Hashable, GSONable, metaclass=OptimizableMeta):\n    \"\"\"\n    Experimental callable ABC that provides lego-like optimizable objects\n    that can be used to partition the optimization problem into a graph.\n\n    The class provides many features that simplify defining the optimization\n    problem.\n\n    1. Optimizable and its subclasses define the optimization problem. The\n       optimization problem can be thought of as a directed acycling graph (DAG),\n       with each instance of Optimizable being a vertex (node) in the DAG.\n       Each Optimizable object can take other Optimizable objects as inputs and\n       through this container logic, the edges of the DAG are defined.\n\n       Alternatively, the input Optimizable objects can be thought of as parents\n       to the current Optimizable object. In this approach, the last grand-child\n       defines the optimization problem by embodying all the elements of the\n       parents and grand-parents.\n\n       Each call to child instance gets in turn propagated to the parent. In this\n       way, the last child acts as the final optimization problem to be solved.\n       For an example of the final optimization node, refer to\n       simsopt.objectives.least_squares.LeastSquaresProblem\n\n    2. The class automatically partitions degrees of freedoms (DOFs) of\n       the optimization problem to the associated Optimizable nodes. Each DOF\n       defined in a parent gets passed down to the children as a needed DOF for\n       the child. So a DOF needed by parent node can be given as an input to\n       the methods in the child node. Any of the DOFs could be fixed in which\n       case, it should be removed as an argument to the call-back\n       function from the final Optimizable node.\n\n    3. The class implements a callable hook that provides minimal caching.\n       All derived classes have to register methods that return objective function\n       type values. This is done by implementing the following class attribute\n       in the class definition:\n       .. code-block:: python\n\n           return_fn_map = {'name1': method1, 'name2': method, ...}\n\n       The Optimizable class maintains the list of return functions needed by each\n       of the calling Optimizable objects either during child initialization or\n       later using the provided methods. The calling optimizable object could then\n       call the Optimizable object directly using the `__call__` hook or could\n       call the individual methods.\n\n       This back and forth propagation of DOFs partitioning and function\n       calls happens dynamically.\n\n    4. The class is hashable and the names of the instances are unique. So\n       instances of Optimizable class can be used as keys.\n\n    Note:\n        1. If the Optimizable object is called using the `__call__` hook, make\n           sure to supply the argument `child=self`\n\n        2. __init__ takes instances of subclasses of Optimizable as\n           input and modifies them to add the current object as a child for\n           input objects. The return fns of the parent object needed by the child\n           could be specified by using `opt_return_fns` argument\n    \"\"\"\n    return_fn_map: Dict[str, Callable] = NotImplemented\n\n    def __init__(self,\n                 x0: RealArray = None,\n                 names: StrArray = None,\n                 fixed: BoolArray = None,\n                 lower_bounds: RealArray = None,\n                 upper_bounds: RealArray = None, *,\n                 dofs: DOFs = None,\n                 external_dof_setter: Callable[..., None] = None,\n                 depends_on: Sequence[Optimizable] = None,\n                 opt_return_fns: Sequence[Sequence[str]] = None,\n                 funcs_in: Sequence[Callable[..., Union[RealArray, Real]]] = None,\n                 **kwargs):\n        \"\"\"\n        Args:\n            x0: Initial state (or initial values of DOFs)\n            names: Human identifiable names for the DOFs\n            fixed: Array describing whether the DOFs are free or fixed\n            lower_bounds: Lower bounds for the DOFs\n            upper_bounds: Upper bounds for the DOFs\n            dofs: Degrees of freedoms as DOFs object\n            external_dof_setter: Function used by derivative classes to\n                handle DOFs outside of the dofs object within the class.\n                Mainly used when the DOFs are primarily handled by C++ code.\n                In that case, for all intents and purposes, the internal dofs\n                object is a duplication of the DOFs stored elsewhere. In such\n                cases, the internal dofs object is used to handle the dof\n                partitioning, but external dofs are\n                used for computation of the objective function.\n            depends_on: Sequence of Optimizable objects on which the current\n                Optimizable object depends on to define the optimization\n                problem in conjuction with the DOFs. If the optimizable problem\n                can be thought of as a direct acyclic graph based on\n                dependencies, the optimizable objects\n                supplied with depends_on act as parent nodes to the current\n                Optimizable object in such an optimization graph\n            opt_return_fns: Specifies the return value for each of the\n                Optimizable object. Used in the case, where Optimizable object\n                can return different return values. Typically return values are\n                computed by different functions defined in the Optimizable\n                object. The return values are selected by choosing the\n                functions. To know the various return values, use the\n                Optimizable.get_return_fn_names function. If the list is\n                empty, default return value is used. If the Optimizable\n                object can return multiple values, the default is the array\n                of all possible return values.\n            funcs_in: Instead of specifying depends_on and opt_return_fns, specify\n                the methods of the Optimizable objects directly. The parent\n                objects are identified automatically. Doesn't work with\n                funcs_in with a property decorator\n        \"\"\"\n        if dofs is None:\n            dofs = DOFs(x0,\n                        names,\n                        np.logical_not(fixed) if fixed is not None else None,\n                        lower_bounds,\n                        upper_bounds)\n        else:\n            # If a DOFs object is supplied, call external dof setter if present\n            if external_dof_setter is not None:\n                external_dof_setter(self, dofs.full_x)\n\n        self._dofs = dofs\n        self.local_dof_setter = external_dof_setter\n\n        # Generate unique and immutable representation for different\n        # instances of same class\n        self._id = ImmutableId(next(self.__class__._ids))\n        self.name = self.__class__.__name__ + str(self._id.id)\n        hash_str = hashlib.sha256(self.name.encode('utf-8')).hexdigest()\n        self._hash = int(hash_str, 16) % 10**32  # 32 digit int as hash\n        self._children = set()  # This gets populated when the object is passed\n        # as argument to another Optimizable object\n        self.return_fns = WeakKeyDefaultDict(list)  # Store return fn's required by each child\n\n        # Assign self as child to parents\n        funcs_in = list(funcs_in) if funcs_in is not None else []\n        depends_on = list(depends_on) if depends_on is not None else []\n        assert (not ((len(funcs_in) > 0) and (len(depends_on) > 0)))\n\n        def binder(fn, inst):\n            def func(*args, **kwargs):\n                return fn(inst, *args, **kwargs)\n            return func\n\n        if len(depends_on):\n            self.parents = depends_on\n            for i, parent in enumerate(self.parents):\n                parent._add_child(self)\n                return_fns = opt_return_fns[i] if opt_return_fns else []\n                try:\n                    if not len(return_fns) and len(parent.return_fn_map.values()):\n                        return_fns = parent.return_fn_map.values()\n                except:\n                    pass\n                for fn in return_fns:\n                    parent.add_return_fn(self, fn)\n                    funcs_in.append(binder(fn, parent))\n        else:  # Process funcs_in (Assumes depends_on is empty)\n            for fn in funcs_in:\n                opt_in = fn.__self__\n                depends_on.append(opt_in)\n                opt_in.add_return_fn(self, fn.__func__)\n            self.parents = list(dict.fromkeys(depends_on))\n            for i, parent in enumerate(self.parents):\n                parent._add_child(self)\n\n        self.funcs_in = funcs_in\n\n        # Obtain unique list of the ancestors\n        self.ancestors = self._get_ancestors()\n\n        # Compute the indices of all the DOFs\n        self._update_full_dof_size_indices()\n        self.update_free_dof_size_indices()\n        # Inform the object that it doesn't have valid cache\n        self.set_recompute_flag()\n        log.debug(f\"Unused arguments for {self.__class__} are {kwargs}\")\n        super().__init__()\n\n        # Keep this at the end because the function refers to Optimizable object\n        self._dofs.add_opt(self)\n\n    def replace_dofs(self, dofs):\n        \"\"\"\n        Calls all the required functions in correct order if the DOFs object\n        is replaced manually by the user\n        Args:\n            dofs: DOFs object\n        \"\"\"\n        self._dofs.remove_opt(self)\n        self._dofs = dofs\n        self._update_full_dof_size_indices()\n        self.update_free_dof_size_indices()\n        self.set_recompute_flag()\n        self._dofs.add_opt(self)\n\n    def __str__(self):\n        return self.name\n\n    def __hash__(self) -> int:\n        return self._hash\n\n    def __eq__(self, other: Optimizable) -> bool:\n        \"\"\"\n        Checks the equality condition\n\n        Args:\n            other: Another object of subclass of Optimizable\n\n        Returns: True only if both are the same objects.\n\n        \"\"\"\n        return self.name == other.name\n\n    def __call__(self, x: RealArray = None, *args, child=None, **kwargs):\n        if x is not None:\n            self.x = x\n        return_fn_map = self.__class__.return_fn_map\n\n        if child:\n            return_fns = self.return_fns[child] if self.return_fns[child] else \\\n                return_fn_map.values()\n        else:\n            return_fns = return_fn_map.values()\n\n        result = []\n        for fn in return_fns:\n            result.append(fn(self, *args, **kwargs))\n\n        return result if len(result) > 1 else result[0]\n\n    def get_return_fn_names(self) -> List[str]:\n        \"\"\"\n        Return the names of the functions that could be used as objective\n        functions.\n\n        Returns:\n            List of function names that could be used as objective functions\n        \"\"\"\n        return list(self.__class__.return_fn_map.keys())\n\n    def add_return_fn(self, child: Optimizable, fn: Union[str, Callable]) -> None:\n        \"\"\"\n        Add return function to the list of the return functions called by\n        the child Optimizable object\n\n        Args:\n            child: an Optimizable object that is direct dependent of the current\n                Optimizable instance\n            fn: method of the Optimizable object needed by the child\n        \"\"\"\n        self._add_child(child)\n\n        if isinstance(fn, str):\n            fn = self.__class__.return_fn_map[fn]\n        self.return_fns[child].append(fn)\n\n    def get_return_fns(self, child: Optimizable) -> List[Callable]:\n        \"\"\"\n        Gets return functions from this Optimizable object used by the child\n        Optimizable object\n\n        Args:\n            child: Dependent Optimizable object\n\n        Returns:\n            List of methods that return a value when the current Optimizable\n            object is called from the child\n        \"\"\"\n        return self.return_fns[child]\n\n    def get_return_fn_list(self) -> List[List[Callable]]:\n        \"\"\"\n        Gets return functions from this Optimizable object used by all the child\n        Optimizable objects\n\n        Returns:\n            List of methods that return a value when the current Optimizable\n            object is called from the children.\n        \"\"\"\n        return list(self.return_fns.values())\n\n    def get_parent_return_fns_list(self) -> List[List[Callable]]:\n        \"\"\"\n        Get a list of the funcs returned by the parents as list of lists\n\n        Returns:\n            The funcs returned by all the parents of the Optimizable object\n        \"\"\"\n        return_fn_list = []\n        for parent in self.parents:\n            return_fn_list.append(parent.get_return_fns(self))\n        return return_fn_list\n\n    @property\n    def parent_return_fns_no(self) -> int:\n        \"\"\"\n        Compute the total number of the return funcs of all the parents\n        of the Optimizable object\n\n        Returns:\n            The total number of the return funcs  of the Optimizable object's\n            parents.\n        \"\"\"\n        return_fn_no = 0\n        for parent in self.parents:\n            return_fn_no += len(parent.get_return_fns(self))\n        return return_fn_no\n\n    def _add_child(self, child: Optimizable) -> None:\n        \"\"\"\n        Adds another Optimizable object as child. All the\n        required processing of the dependencies is done in the child node.\n        This method is used mainly to maintain 2-way link between parent\n        and child.\n\n        Args:\n            child: Direct dependent (child) of the Optimizable object\n        \"\"\"\n        weakref_child = weakref.ref(child)\n        if weakref_child not in self._children:\n            self._children.add(weakref_child)\n\n    def _remove_child(self, other: Optimizable) -> None:\n        \"\"\"\n        Remove the specific Optimizable object from the children list.\n\n        Args:\n            child: Direct dependent (child) of the Optimizable object\n        \"\"\"\n        weakref_other = weakref.ref(other)\n        self._children.remove(weakref_other)\n        if other in self.return_fns:\n            del self.return_fns[other]\n\n    def add_parent(self, index: int, other: Optimizable) -> None:\n        \"\"\"\n        Adds another Optimizable object as parent at specified index.\n\n        Args:\n            int: Index of the parent's list\n            other: Another Optimizable object to be added as parent\n        \"\"\"\n        if other not in self.parents:\n            self.parents.insert(index, other)\n            other._add_child(self)\n            self._update_full_dof_size_indices()  # Updates ancestors as well\n            self.update_free_dof_size_indices()\n            self.set_recompute_flag()\n        else:\n            log.debug(\"The given Optimizable object is already a parent\")\n\n    def append_parent(self, other: Optimizable) -> None:\n        \"\"\"\n        Appends another Optimizable object to parents list\n\n        Args:\n            other: New parent Optimizable object\n        \"\"\"\n        self.add_parent(len(self.parents), other)\n\n    def pop_parent(self, index: int = -1) -> Optimizable:\n        \"\"\"\n        Removes the parent Optimizable object at specified index.\n\n        Args:\n            index: Index of the list of the parents\n\n        Returns:\n            The removed parent Optimizable object\n        \"\"\"\n        discarded_parent = self.parents.pop(index)\n        discarded_parent._remove_child(self)\n        self._update_full_dof_size_indices()  # Updates ancestors as well\n        self.update_free_dof_size_indices()\n        self.set_recompute_flag()\n\n        return discarded_parent\n\n    def remove_parent(self, other: Optimizable):\n        \"\"\"\n        Removes the specified Optimizable object from the list of parents.\n\n        Args:\n            other: The Optimizable object to be removed from the list of parents\n        \"\"\"\n        self.parents.remove(other)\n        other._remove_child(self)\n        self._update_full_dof_size_indices()  # updates ancestors as well\n        self.update_free_dof_size_indices()\n        self.set_recompute_flag()\n\n    def _get_ancestors(self) -> list[Optimizable]:\n        \"\"\"\n        Get all the ancestors of the current Optimizable object\n\n        Returns:\n            List of Optimizable objects that are parents of current\n            Optimizable objects\n        \"\"\"\n        ancestors = []\n        for parent in self.parents:\n            ancestors += parent.ancestors\n        ancestors += self.parents\n        return sorted(dict.fromkeys(ancestors), key=lambda a: a.name)\n\n    @property\n    def unique_dof_lineage(self):\n        return self._unique_dof_opts\n\n    def update_free_dof_size_indices(self) -> None:\n        \"\"\"\n        Updates the DOFs lengths for the Optimizable object as well as\n        those of the descendent (dependent) Optimizable objects.\n\n        Call this function whenever DOFs are fixed or unfixed or when parents\n        are added/deleted. Recursively calls the same function in children\n        \"\"\"\n        # TODO: This is slow because it walks through the graph repeatedly\n        # TODO: Develop a faster scheme.\n        # TODO: Alternatively ask the user to call this manually from the end\n        # TODO: node after fixing/unfixing any DOF\n        dof_indices = [0]\n        free_dof_size = 0\n        dof_objs = set()\n        for opt in self._unique_dof_opts:\n            dof_objs.add(opt.dofs)\n            size = opt.local_dof_size\n            free_dof_size += size\n            dof_indices.append(free_dof_size)\n\n        self._free_dof_size = free_dof_size\n        self.dof_indices = dict(zip(self._unique_dof_opts,\n                                    zip(dof_indices[:-1], dof_indices[1:])))\n\n        # Update the reduced dof length of children\n        for weakref_child in self._children:\n            child = weakref_child()\n            if child is not None:\n                child.update_free_dof_size_indices()\n\n    def _update_full_dof_size_indices(self) -> None:\n        \"\"\"\n        Updates the full DOFs lengths for this instance and\n        those of the children. Updates the ancestors attribute as well.\n\n        Call this function whenever parents are added or removed. Recursively\n        calls the same function in children.\n        \"\"\"\n\n        # TODO: This is slow because it walks through the graph repeatedly\n        # TODO: Develop a faster scheme.\n        # TODO: Alternatively ask the user to call this manually from the end\n        # TODO: node after fixing/unfixing any DOF\n        dof_indices = [0]\n        full_dof_size = 0\n        dof_objs = set()\n        self.ancestors = self._get_ancestors()\n        self._unique_dof_opts = []\n        for opt in (self.ancestors + [self]):\n            if opt.dofs not in dof_objs:\n                dof_objs.add(opt.dofs)\n                full_dof_size += opt.local_full_dof_size\n                dof_indices.append(full_dof_size)\n                self._unique_dof_opts.append(opt)\n\n        self._full_dof_size = full_dof_size\n        self._full_dof_indices = dict(zip(self._unique_dof_opts,\n                                          zip(dof_indices[:-1], dof_indices[1:])))\n\n        # Update the full dof length of children\n        for weakref_child in self._children:\n            child = weakref_child()\n            if child is not None:\n                child._update_full_dof_size_indices()\n\n    @property\n    def dofs(self) -> DOFs:\n        \"\"\"\n        Return all the attributes of local degrees of freedom via DOFs object.\n        Mainly used to conform with the default as_dict method of GSONable\n        and to share DOFs object between multiple Optimizable objects\n        \"\"\"\n        return self._dofs\n\n    @property\n    def full_dof_size(self) -> Integral:\n        \"\"\"\n        Total number of all (free and fixed) DOFs associated with the\n        Optimizable object as well as parent Optimizable objects.\n        \"\"\"\n        return self._full_dof_size\n\n    @property\n    def dof_size(self) -> Integral:\n        \"\"\"\n        Total number of free DOFs associated with the Optimizable object\n        as well as parent Optimizable objects.\n        \"\"\"\n        return self._free_dof_size\n\n    @property\n    def local_full_dof_size(self) -> Integral:\n        \"\"\"\n        Number of all (free and fixed) DOFs associated with the Optimizable\n        object.\n\n        Returns:\n            Total number of free and fixed DOFs associated with the Optimizable\n            object.\n        \"\"\"\n        return len(self._dofs)\n\n    @property\n    def local_dof_size(self) -> Integral:\n        \"\"\"\n        Number of free DOFs associated with the Optimizable object.\n\n        Returns:\n            Number of free DOFs associated with the Optimizable object.\n        \"\"\"\n        return self._dofs.reduced_len\n\n    @property\n    def x(self) -> RealArray:\n        \"\"\"\n        Numeric values of the free DOFs associated with the current\n        Optimizable object and those of its ancestors\n        \"\"\"\n        return np.concatenate([opt._dofs.free_x for\n                               opt in self._unique_dof_opts])\n\n    @x.setter\n    def x(self, x: RealArray) -> None:\n        if list(self.dof_indices.values())[-1][-1] != len(x):\n            raise ValueError\n        for opt, indices in self.dof_indices.items():\n            opt.local_x = x[indices[0]:indices[1]]\n\n    @property\n    def full_x(self) -> RealArray:\n        \"\"\"\n        Numeric values of all the DOFs (both free and fixed) associated\n        with the current Optimizable object and those of its ancestors\n        \"\"\"\n        return np.concatenate([opt._dofs.full_x for\n                               opt in self._unique_dof_opts])\n\n    @full_x.setter\n    def full_x(self, x: RealArray) -> None:\n        \"\"\"\n        Setter used to set all the global DOF values\n        \"\"\"\n        for opt, indices in self._full_dof_indices.items():\n            opt.local_full_x = x[indices[0]:indices[1]]\n\n    @property\n    def local_x(self) -> RealArray:\n        \"\"\"\n        Numeric values of the free DOFs associated with this\n        Optimizable object\n        \"\"\"\n        return self._dofs.free_x\n\n    @local_x.setter\n    def local_x(self, x: RealArray) -> None:\n        \"\"\"\n        Setter for local dofs.\n        \"\"\"\n        if self.local_dof_size != len(x):\n            raise ValueError\n        self._dofs.free_x = x\n\n    @property\n    def local_full_x(self):\n        \"\"\"\n        Numeric values of all DOFs (both free and fixed) associated with\n        this Optimizable object\n        \"\"\"\n        return self._dofs.full_x\n\n    @property\n    def x0(self):\n        \"\"\"\n        Mimics dataclass behavior for Optimizable\n        \"\"\"\n        return self.local_full_x\n\n    @local_full_x.setter\n    def local_full_x(self, x: RealArray) -> None:\n        \"\"\"\n        For those cases, where one wants to assign all DOFs including fixed\n\n        .. warning:: Even fixed DOFs are assigned.\n        \"\"\"\n        self._dofs.full_x = x\n\n    def set_recompute_flag(self, parent=None):\n        self.new_x = True\n        self.recompute_bell(parent=parent)\n\n        # for child in self._children:\n        for weakref_child in self._children:\n            child = weakref_child()\n            if child is not None:\n                child.set_recompute_flag(parent=self)\n\n    def get(self, key: Key) -> Real:\n        \"\"\"\n        Get the value of specified DOF.\n        Even fixed dofs can be obtained individually.\n\n        Args:\n            key: DOF identifier\n        \"\"\"\n        return self._dofs.get(key)\n\n    def set(self, key: Key, new_val: Real) -> None:\n        \"\"\"\n        Update the value held the specified DOF.\n        Even fixed dofs can be set this way\n\n        Args:\n            key: DOF identifier\n            new_val: New value of the DOF\n        \"\"\"\n        self._dofs.set(key, new_val)\n\n    def recompute_bell(self, parent=None):\n        \"\"\"\n        Function to be called whenever new DOFs input is given or if the\n        parent Optimizable's data changed, so the output from the current\n        Optimizable object is invalid.\n\n        This method gets called by various DOF setters. If only the local\n        DOFs of an object are being set, the recompute_bell method is called\n        in that object and also in the descendent objects that have a dependency\n        on the object, whose local DOFs are being changed. If gloabl DOFs\n        of an object are being set, the recompute_bell method is called in\n        the object, ancestors of the object, as well as the descendents of\n        the object.\n\n        Need to be implemented by classes that provide a dof_setter for\n        external handling of DOFs.\n        \"\"\"\n        pass\n\n    @property\n    def bounds(self) -> Tuple[RealArray, RealArray]:\n        \"\"\"\n        Lower and upper bounds of the free DOFs associated with the current\n        Optimizable object and those of its ancestors\n        \"\"\"\n        return (self.lower_bounds, self.upper_bounds)\n\n    @property\n    def full_bounds(self) -> Tuple[RealArray, RealArray]:\n        \"\"\"\n        Lower and upper bounds of the fixed and free DOFs associated with the current\n        Optimizable object and those of its ancestors\n        \"\"\"\n        return (self.full_lower_bounds, self.full_upper_bounds)\n\n    @property\n    def local_bounds(self) -> Tuple[RealArray, RealArray]:\n        \"\"\"\n        Lower and upper bounds of the free DOFs associated with\n        this Optimizable object\n        \"\"\"\n        return self._dofs.bounds\n\n    @property\n    def full_lower_bounds(self) -> RealArray:\n        \"\"\"\n        Lower bounds of the fixed and free DOFs associated with the current\n        Optimizable object and those of its ancestors\n        \"\"\"\n        return np.concatenate([opt._dofs.full_lower_bounds for opt in self.unique_dof_lineage])\n\n    @full_lower_bounds.setter\n    def full_lower_bounds(self, lb) -> None:\n        \"\"\"\n        Set the lower bounds of the fixed and free DOFS associated with the\n        current Optimizable object and its ancestors.\n        \"\"\"\n        if list(self.dof_indices.values())[-1][-1] != len(lb):\n            raise ValueError\n        for opt, indices in self.dof_indices.items():\n            opt._dofs.full_lower_bounds = lb[indices[0]:indices[1]]\n\n    @property\n    def lower_bounds(self) -> RealArray:\n        \"\"\"\n        Lower bounds of the free DOFs associated with the current\n        Optimizable object and those of its ancestors\n        \"\"\"\n        return np.concatenate([opt._dofs.free_lower_bounds for opt in self.unique_dof_lineage])\n\n    @lower_bounds.setter\n    def lower_bounds(self, lb) -> None:\n        \"\"\"\n        Set the lower bounds of the free DOFS associated with the\n        current Optimizable object and its ancestors.\n        \"\"\"\n        if list(self.dof_indices.values())[-1][-1] != len(lb):\n            raise ValueError\n        for opt, indices in self.dof_indices.items():\n            opt._dofs.free_lower_bounds = lb[indices[0]:indices[1]]\n\n    def set_lower_bound(self, key: Key, new_val: Real) -> None:\n        \"\"\"\n        Update the value of the lower bound of a specified DOF.\n        Even lower bounds of fixed dofs can be set this way\n\n        Args:\n            key: DOF identifier\n            new_val: New value of the lower bound\n        \"\"\"\n        self._dofs.update_lower_bound(key, new_val)\n\n    @property\n    def local_lower_bounds(self) -> RealArray:\n        \"\"\"\n        Lower bounds of the free DOFs associated with this Optimizable\n        object\n        \"\"\"\n        return self._dofs.free_lower_bounds\n\n    @local_lower_bounds.setter\n    def local_lower_bounds(self, llb: RealArray) -> None:\n        \"\"\"\n        Set the lower bounds of the free dofs of this\n        Optimizable object.\n        \"\"\"\n        self._dofs.free_lower_bounds = llb\n\n    @property\n    def local_full_lower_bounds(self) -> RealArray:\n        \"\"\"\n        Get the lower bounds of the free and fixed dofs of this\n        Optimizable object.\n        \"\"\"\n        return self._dofs.full_lower_bounds\n\n    @local_full_lower_bounds.setter\n    def local_full_lower_bounds(self, llb: RealArray) -> None:\n        \"\"\"\n        Set the lower bounds of the free and fixed dofs of this\n        Optimizable object.\n        \"\"\"\n        self._dofs.full_lower_bounds = llb\n\n    @property\n    def full_upper_bounds(self) -> RealArray:\n        \"\"\"\n        Upper bounds of the fixed and free DOFs associated with the current\n        Optimizable object and those of its ancestors\n        \"\"\"\n        return np.concatenate([opt._dofs.full_upper_bounds for opt in self.unique_dof_lineage])\n\n    @full_upper_bounds.setter\n    def full_upper_bounds(self, ub) -> None:\n        \"\"\"\n        Set the upper bounds of the fixed and free DOFS associated with the\n        current Optimizable object and its ancestors.\n        \"\"\"\n        if list(self.dof_indices.values())[-1][-1] != len(ub):\n            raise ValueError\n        for opt, indices in self.dof_indices.items():\n            opt._dofs.full_upper_bounds = ub[indices[0]:indices[1]]\n\n    @property\n    def upper_bounds(self) -> RealArray:\n        \"\"\"\n        Upper bounds of the free DOFs associated with the current\n        Optimizable object and those of its ancestors\n        \"\"\"\n        opts = self.ancestors + [self]\n        return np.concatenate([opt._dofs.free_upper_bounds for opt in self.unique_dof_lineage])\n\n    @upper_bounds.setter\n    def upper_bounds(self, ub) -> None:\n        \"\"\"\n        Set the upper bounds of the free DOFS associated with the\n        current Optimizable object and its ancestors.\n        \"\"\"\n        if list(self.dof_indices.values())[-1][-1] != len(ub):\n            raise ValueError\n        for opt, indices in self.dof_indices.items():\n            opt._dofs.free_upper_bounds = ub[indices[0]:indices[1]]\n\n    def set_upper_bound(self, key: Key, new_val: Real) -> None:\n        \"\"\"\n        Update the value of the upper bound of a specified DOF.\n        Even upper bounds of fixed dofs can be set this way\n\n        Args:\n            key: DOF identifier\n            new_val: New value of the upper bound\n        \"\"\"\n        self._dofs.update_upper_bound(key, new_val)\n\n    @property\n    def local_upper_bounds(self) -> RealArray:\n        \"\"\"\n        Upper bounds of the free DOFs associated with this Optimizable\n        object\n        \"\"\"\n        return self._dofs.free_upper_bounds\n\n    @local_upper_bounds.setter\n    def local_upper_bounds(self, lub: RealArray) -> None:\n        \"\"\"\n        Set the upper bounds of the free dofs of this\n        Optimizable object.\n        \"\"\"\n        self._dofs.free_upper_bounds = lub\n\n    @property\n    def local_full_upper_bounds(self) -> RealArray:\n        \"\"\"\n        Get the upper bounds of the free and fixed dofs of this\n        Optimizable object.\n        \"\"\"\n        return self._dofs.full_upper_bounds\n\n    @local_full_upper_bounds.setter\n    def local_full_upper_bounds(self, lub: RealArray) -> None:\n        \"\"\"\n        Set the upper bounds of the free and fixed dofs of this\n        Optimizable object.\n        \"\"\"\n        self._dofs.full_upper_bounds = lub\n\n    @property\n    def dof_names(self) -> StrArray:\n        \"\"\"\n        Names (Identifiers) of the DOFs associated with the current\n        Optimizable object and those of its ancestors\n        \"\"\"\n        names = []\n        for opt in self.unique_dof_lineage:\n            names += [opt.name + \":\" + dname for dname in opt._dofs.free_names]\n        return names\n\n    @property\n    def full_dof_names(self) -> StrArray:\n        \"\"\"\n        Names (Identifiers) of the DOFs associated with the current\n        Optimizable object and those of its ancestors\n        \"\"\"\n        names = []\n        for opt in self.unique_dof_lineage:\n            names += [opt.name + \":\" + dname for dname in opt._dofs.full_names]\n        return names\n\n    @property\n    def local_dof_names(self) -> StrArray:\n        \"\"\"\n        Names (Identifiers) of the DOFs associated with this Optimizable\n        object\n        \"\"\"\n        return self._dofs.free_names\n\n    @property\n    def local_full_dof_names(self) -> StrArray:\n        \"\"\"\n        Names (Identifiers) of the DOFs associated with this Optimizable\n        object\n        \"\"\"\n        return self._dofs.full_names\n\n    @property\n    def dofs_free_status(self) -> BoolArray:\n        \"\"\"\n        Boolean array denoting whether the DOFs associated with the\n        current and ancestors Optimizable objects are free or not\n        \"\"\"\n        return np.concatenate(\n            [opt._dofs.free_status for opt in self.unique_dof_lineage])\n\n    @property\n    def local_dofs_free_status(self) -> BoolArray:\n        \"\"\"\n        Boolean array denoting whether the DOFs associated with the\n        current Optimizable object are free or not\n        \"\"\"\n        return self._dofs.free_status\n\n    def is_fixed(self, key: Key) -> bool:\n        \"\"\"\n        Checks if the specified dof is fixed\n\n        Args:\n            key: DOF identifier\n        \"\"\"\n        return not self.is_free(key)\n\n    def is_free(self, key: Key) -> bool:\n        \"\"\"\n        Checks if the specified dof is free\n\n        Args:\n            key: DOF identifier\n        \"\"\"\n        return self._dofs.is_free(key)\n\n    def fix(self, key: Key) -> None:\n        \"\"\"\n        Set the fixed attribute for the given degree of freedom.\n\n        Args:\n            key: DOF identifier\n        \"\"\"\n        # TODO: Question: Should we use ifix similar to pandas' loc and iloc?\n\n        self._dofs.fix(key)\n        self.update_free_dof_size_indices()\n\n    def unfix(self, key: Key) -> None:\n        \"\"\"\n        Unset the fixed attribute for the given degree of freedom\n\n        Args:\n            key: DOF identifier\n        \"\"\"\n        self._dofs.unfix(key)\n        self.update_free_dof_size_indices()\n\n    def full_fix(self, arr: Key) -> None:\n        \"\"\"\n        Set the fixed/free attribute for all dofs on which this Optimizable object\n        depends. \n\n        Args:\n            arr: List or array of the same length as ``full_x``, containing\n                booleans. For each array entry that is ``True``, the corresponding dof will be set\n                to fixed.\n        \"\"\"\n        for opt, indices in self._full_dof_indices.items():\n            opt._dofs._free[:] = np.logical_not(arr[indices[0]:indices[1]])\n            opt._dofs._update_opt_indices()\n\n    def full_unfix(self, arr: Key) -> None:\n        \"\"\"\n        Set the fixed/free attribute for all dofs on which this Optimizable object\n        depends. \n\n        Args:\n            arr: List or array of the same length as ``full_x``, containing\n                booleans. For each array entry that is ``True``, the corresponding dof will be set\n                to free.\n        \"\"\"\n        for opt, indices in self._full_dof_indices.items():\n            opt._dofs._free[:] = arr[indices[0]:indices[1]]\n            opt._dofs._update_opt_indices()\n\n    def local_fix_all(self) -> None:\n        \"\"\"\n        Set the 'fixed' attribute for all local degrees of freedom associated\n        with the current Optimizable object.\n        \"\"\"\n        self._dofs.fix_all()\n        self.update_free_dof_size_indices()\n\n    def fix_all(self) -> None:\n        \"\"\"\n        Set the 'fixed' attribute for all the degrees of freedom associated\n        with the current Optimizable object including those of ancestors.\n        \"\"\"\n        for opt in self.unique_dof_lineage:\n            opt.local_fix_all()\n\n    def local_unfix_all(self) -> None:\n        \"\"\"\n        Unset the 'fixed' attribute for all local degrees of freedom associated\n        with the current Optimizable object.\n        \"\"\"\n        self._dofs.unfix_all()\n        self.update_free_dof_size_indices()\n\n    def unfix_all(self) -> None:\n        \"\"\"\n        Unset the 'fixed' attribute for all local degrees of freedom associated\n        with the current Optimizable object including those of the ancestors.\n        \"\"\"\n        for opt in self.unique_dof_lineage:\n            opt.local_unfix_all()\n\n    def __add__(self, other):\n        \"\"\" Add two Optimizable objects \"\"\"\n        return OptimizableSum([self, other])\n\n    def __mul__(self, other):\n        \"\"\" Multiply an Optimizable object by a scalar \"\"\"\n        return ScaledOptimizable(other, self)\n\n    def __rmul__(self, other):\n        \"\"\" Multiply an Optimizable object by a scalar \"\"\"\n        return ScaledOptimizable(other, self)\n\n    # https://stackoverflow.com/questions/11624955/avoiding-python-sum-default-start-arg-behavior\n    def __radd__(self, other):\n        # This allows sum() to work (the default start value is zero)\n        if other == 0:\n            return self\n        return self.__add__(other)\n\n    @SimsoptRequires(nx is not None, \"print method for DAG requires networkx\")\n    @SimsoptRequires(pygraphviz is not None, \"print method for DAG requires pygraphviz\")\n    @SimsoptRequires(plt is not None, \"print method for DAG requires matplotlib\")\n    def plot_graph(self, show=True):\n        \"\"\"\n        Plot the directed acyclical graph that represents the dependencies of an \n        ``Optimizable`` on its parents. The workflow is as follows: generate a ``networkx``\n        ``DiGraph`` using the ``traversal`` function defined below.  Next, call ``graphviz_layout``\n        which determines sensible positions for the nodes of the graph using the ``dot``\n        program of ``graphviz``. Finally, ``networkx`` plots the graph using ``matplotlib``.\n\n        Note that the tool ``network2tikz`` at `https://github.com/hackl/network2tikz <https://github.com/hackl/network2tikz>`_\n        can be used to convert the networkx ``DiGraph`` and positions to a \n        latex file for publication.\n\n        Args:\n            show: Whether to call the ``show()`` function of matplotlib.\n\n        Returns:\n            The ``networkx`` graph corresponding to this ``Optimizable``'s directed acyclical graph\n            and a dictionary of node names that map to sensible x, y positions determined by ``graphviz``\n        \"\"\"\n\n        G = nx.DiGraph()\n        G.add_node(self.name) \n\n        def traversal(root):\n            for p in root.parents:\n                n1 = root.name\n                n2 = p.name\n                G.add_edge(n1, n2)\n                traversal(p)\n\n        traversal(self)\n\n        # this command generates sensible positions for nodes of the DAG\n        # using the \"dot\" program\n        pos = graphviz_layout(G, prog='dot')\n        options = {\n            'node_color': 'white',\n            'arrowstyle': '-|>',\n            'arrowsize': 12,\n            'font_size': 12}\n        nx.draw_networkx(G, pos=pos, arrows=True, **options)\n        if show:\n            plt.show()\n\n        return G, pos\n\n    def as_dict(self, serial_objs_dict=None) -> dict:\n        d = super().as_dict(serial_objs_dict)\n        if len(self.local_full_x):\n            d[\"dofs\"] = self._dofs.as_dict2(serial_objs_dict=serial_objs_dict)\n\n        return d\n\n    def save(self, filename=None, fmt=None, **kwargs):\n        filename = filename or \"\"\n        fmt = \"\" if fmt is None else fmt.lower()\n        fname = Path(filename).name\n\n        if fmt == \"json\" or fnmatch(fname.lower(), \"*.json\"):\n            if \"cls\" not in kwargs:\n                kwargs[\"cls\"] = GSONEncoder\n            if \"indent\" not in kwargs:\n                kwargs[\"indent\"] = 2\n            simson = SIMSON(self)\n            s = json.dumps(simson, **kwargs)\n            if filename:\n                with zopen(filename, \"wt\") as f:\n                    f.write(s)\n            return s\n        else:\n            raise ValueError(f\"Invalid format: `{str(fmt)}`\")\n\n    @classmethod\n    def from_str(cls, input_str: str, fmt=\"json\"):\n        fmt_low = fmt.lower()\n        if fmt_low == \"json\":\n            return json.loads(input_str, cls=GSONDecoder)\n        else:\n            raise ValueError(f\"Invalid format: `{str(fmt)}`\")\n\n    @classmethod\n    def from_file(cls, filename: str):\n        fname = Path(filename).name\n        if fnmatch(filename, \"*.json*\") or fnmatch(fname, \"*.bson*\"):\n            with zopen(filename, \"rt\") as f:\n                contents = f.read()\n            return cls.from_str(contents, fmt=\"json\")",
  "def load(filename, *args, **kwargs):\n    \"\"\"\n    Function to load simsopt object from a file.\n    Only JSON format is supported at this time. Support for additional\n    formats will be added in future\n    Args:\n        filename:\n            Name of file from which simsopt object has to be initialized\n    Returns:\n        Simsopt object\n    \"\"\"\n    fname = Path(filename).suffix.lower()\n    if (not fname == '.json'):\n        raise ValueError(f\"Invalid format: `{str(fname[1:])}`\")\n\n    with zopen(filename, \"rt\") as fp:\n        if \"cls\" not in kwargs:\n            kwargs[\"cls\"] = GSONDecoder\n        return json.load(fp, *args, **kwargs)",
  "def save(simsopt_objects, filename, *args, **kwargs):\n    fname = Path(filename).suffix.lower()\n    if (not fname == '.json'):\n        raise ValueError(f\"Invalid format: `{str(fname[1:])}`\")\n\n    with zopen(filename, \"wt\") as fp:\n        if \"cls\" not in kwargs:\n            kwargs[\"cls\"] = GSONEncoder\n        if \"indent\" not in kwargs:\n            kwargs[\"indent\"] = 2\n        simson = SIMSON(simsopt_objects)\n        return json.dump(simson, fp, *args, **kwargs)",
  "def make_optimizable(func, *args, dof_indicators=None, **kwargs):\n    \"\"\"\n    Factory function to generate an Optimizable instance from a function\n    to be used with the graph framework.\n\n    Args:\n        func: Callable to be used in the optimization\n        args: Positional arguments to pass to \"func\".\n        dof_indicators: List of strings that match with the length of the\n            args and kwargs. Each string can be either of\n            \"opt\" - to indicate the argument is optimizable object\n            \"dof\" - argument that is a degree of freedom for optimization\n            \"non-dof\" - argument that is not part of optimization.\n            Here ordered property of the dict is used to map kwargs to\n            dof_indicators. Another important thing to consider is dofs related\n            to optimizable objects supplied as arguments should not be given.\n        kwargs: Keyword arguments to pass to \"func\".\n    Returns:\n        Optimizable object to be used in the graph based optimization.\n        This object has a bound function ``J()`` that calls the originally\n        supplied ``func()``.\n        If ``obj`` is the returned object, pass ``obj.J`` to the\n        ``LeastSquaresProblem``\n    \"\"\"\n    class TempOptimizable(Optimizable):\n        \"\"\"\n        Subclass of Optimizable class to create optimizable objects dynamically.\n        dof_indicators argument is used to filter out dofs and\n        \"\"\"\n\n        def __init__(self, func, *args, dof_indicators=None, **kwargs):\n\n            self.func = func\n            self.arg_len = len(args)\n            self.kwarg_len = len(kwargs)\n            self.kwarg_keys = []\n            if dof_indicators is not None:\n                assert (self.arg_len + self.kwarg_len == len(dof_indicators))\n                # Using dof_indicators, map args and kwargs to\n                # dofs, non_dofs, and opts\n                dofs, non_dofs, opts = [], [], []\n                for i, arg in enumerate(args):\n                    if dof_indicators[i] == 'opt':\n                        opts.append(arg)\n                    elif dof_indicators[i] == \"non-dof\":\n                        non_dofs.append(arg)\n                    elif dof_indicators[i] == \"dof\":\n                        dofs.append(arg)\n                    else:\n                        raise ValueError\n                for i, k in enumerate(kwargs.keys()):\n                    self.kwarg_keys.append(k)\n                    if dof_indicators[i + self.arg_len] == 'opt':\n                        opts.append(kwargs[k])\n                    elif dof_indicators[i + self.arg_len] == \"non-dof\":\n                        non_dofs.append(kwargs[k])\n                    elif dof_indicators[i + self.arg_len] == \"dof\":\n                        dofs.append(kwargs[k])\n                    else:\n                        raise ValueError\n            else:\n                # nonlocal dof_indicators\n                dofs, non_dofs, opts, dof_indicators = [], [], [], []\n                for i, arg in enumerate(args):\n                    if isinstance(arg, Optimizable):\n                        opts.append(arg)\n                        dof_indicators.append(\"opt\")\n                    else:\n                        non_dofs.append(arg)\n                        dof_indicators.append(\"non-dof\")\n                for k, v in kwargs.items():\n                    self.kwarg_keys.append(k)\n                    if isinstance(v, Optimizable):\n                        opts.append(v)\n                        dof_indicators.append(\"opt\")\n                    else:\n                        non_dofs.append(v)\n                        dof_indicators.append(\"non-dof\")\n\n            # Create args map and kwargs map\n            super().__init__(x0=dofs, depends_on=opts)\n            self.non_dofs = non_dofs\n            self.dof_indicators = dof_indicators\n\n        def J(self):\n            dofs = self.local_full_x\n            # Re-Assemble dofs, non_dofs and opts to args, kwargs\n            args = []\n            kwargs = {}\n            i = 0\n            opt_ind = 0\n            non_dof_ind = 0\n            dof_ind = 0\n            for i in range(self.arg_len):\n                if self.dof_indicators[i] == 'opt':\n                    args.append(self.parents[opt_ind])\n                    opt_ind += 1\n                elif self.dof_indicators[i] == 'dof':\n                    args.append(dofs[dof_ind])\n                    dof_ind += 1\n                elif self.dof_indicators[i] == 'non-dof':\n                    args.append(self.non_dofs[non_dof_ind])\n                    non_dof_ind += 1\n                else:\n                    raise ValueError\n                i += 1\n\n            for j in range(self.kwarg_len):\n                i = j + self.arg_len\n                if self.dof_indicators[i] == 'opt':\n                    kwargs[self.kwarg_keys[j]] = self.parents[opt_ind]\n                    opt_ind += 1\n                elif self.dof_indicators[i] == 'dof':\n                    kwargs[self.kwarg_keys[j]] = dofs[dof_ind]\n                    dof_ind += 1\n                elif self.dof_indicators[i] == 'non-dof':\n                    kwargs[self.kwarg_keys[j]] = self.non_dofs[non_dof_ind]\n                    non_dof_ind += 1\n                else:\n                    raise ValueError\n                j += 1\n            log.info(f'reassembled args len is {len(args)}')\n\n            return self.func(*args, **kwargs)\n\n    return TempOptimizable(func, *args, dof_indicators=dof_indicators, **kwargs)",
  "class ScaledOptimizable(Optimizable):\n    \"\"\"\n    Represents an :obj:`~simsopt._core.optimizable.Optimizable`\n    object scaled by a constant factor. This class is useful for\n    including a weight in front of terms in an objective function. For\n    now, this feature works on classes for which ``.J()`` returns an\n    objective value and ``.dJ()`` returns the gradient, e.g. coil\n    optimization.\n\n    Args:\n        factor: (float) The constant scale factor.\n        opt: An :obj:`~simsopt._core.optimizable.Optimizable` object to scale.\n    \"\"\"\n\n    def __init__(self, factor, opt):\n        self.factor = factor\n        self.opt = opt\n        super().__init__(depends_on=[opt])\n\n    def J(self):\n        return float(self.factor) * self.opt.J()\n\n    @derivative_dec\n    def dJ(self):\n        # Next line uses __rmul__ function for the Derivative class\n        return float(self.factor) * self.opt.dJ(partials=True)",
  "class OptimizableSum(Optimizable):\n    \"\"\"\n    Represents a sum of\n    :obj:`~simsopt._core.optimizable.Optimizable` objects. This\n    class is useful for combining terms in an objective function. For\n    now, this feature works on classes for which ``.J()`` returns an\n    objective value and ``.dJ()`` returns the gradient, e.g. coil\n    optimization.\n\n    Args:\n        opts: A python list of :obj:`~simsopt._core.optimizable.Optimizable` object to sum.\n    \"\"\"\n\n    def __init__(self, opts):\n        self.opts = opts\n        super().__init__(depends_on=opts)\n\n    def J(self):\n        return sum([opt.J() for opt in self.opts])\n\n    @derivative_dec\n    def dJ(self):\n        # Next line uses __add__ function for the Derivative class\n        return sum(opt.dJ(partials=True) for opt in self.opts)",
  "def __init__(self,\n                 x: RealArray = None,  # To enable empty DOFs object\n                 names: StrArray = None,\n                 free: BoolArray = None,\n                 lower_bounds: RealArray = None,\n                 upper_bounds: RealArray = None) -> None:\n        \"\"\"\n        Args:\n            x: Numeric values of the DOFs\n            names: Names of the dofs\n            free: Array of boolean values denoting if the DOFs is are free.\n                  False values implies the corresponding DOFs are fixed\n            lower_bounds: Lower bounds for the DOFs. Meaningful only if\n                DOF is not fixed. Default is np.NINF\n            upper_bounds: Upper bounds for the DOFs. Meaningful only if\n                DOF is not fixed. Default is np.inf\n        \"\"\"\n        if x is None:\n            x = np.array([])\n        else:\n            x = np.asarray(x, dtype=np.double)\n\n        if names is None:\n            names = [f\"x{i}\" for i in range(len(x))]\n        assert (len(np.unique(names)) == len(names))  # DOF names should be unique\n\n        if free is None:\n            free = np.full(len(x), True)\n        else:\n            free = np.asarray(free, dtype=np.bool_)\n\n        if lower_bounds is None:\n            lower_bounds = np.full(len(x), np.NINF)\n        else:\n            lower_bounds = np.asarray(lower_bounds, np.double)\n\n        if upper_bounds is None:\n            upper_bounds = np.full(len(x), np.inf)\n        else:\n            upper_bounds = np.asarray(upper_bounds, np.double)\n\n        assert (len(x) == len(free) == len(lower_bounds) == len(upper_bounds) \\\n                == len(names))\n        self._x = x\n        self._free = free\n        self._lower_bounds = lower_bounds\n        self._upper_bounds = upper_bounds\n        self._names = list(names)\n        self._dep_opts = []\n        self._hash = id(self) % 10**32  # 32 digit int as hash\n        self.name = str(id(self))",
  "def __hash__(self):\n        return self._hash",
  "def add_opt(self, opt):\n        \"\"\"\n        Adds the Optimizable object to the list of dependent Optimizable objects\n        \"\"\"\n        weakref_opt = weakref.ref(opt)\n        if weakref_opt not in self._dep_opts:\n            self._dep_opts.append(weakref_opt)",
  "def remove_opt(self, opt):\n        weakref_opt = weakref.ref(opt)\n        if weakref_opt in self._dep_opts:\n            self._dep_opts.remove(weakref_opt)",
  "def dep_opts(self):\n        opts = []\n        for opt_ref in self._dep_opts:\n            opt = opt_ref()\n            if opt is not None:\n                # yield opt\n                opts.append(opt)\n        return opts",
  "def _flag_recompute_opt(self):\n        \"\"\"\n        Sets the recompute flag in the dependent Optimizable objects.\n        This function is called whenever the DOF values are changed.\n        \"\"\"\n        for opt_ref in self._dep_opts:\n            opt = opt_ref()\n            if opt is not None:\n                if opt.local_dof_setter is not None:\n                    # opt.local_dof_setter(opt, list(self._x))\n                    opt.local_dof_setter(opt, self._x)\n                opt.set_recompute_flag()",
  "def _update_opt_indices(self):\n        \"\"\"\n        Updates the free DOF indices in the dependent Optimizable objects.\n        This function is called whenever a DOF is fixed or set free.\n        \"\"\"\n        for opt_ref in self._dep_opts:\n            opt = opt_ref()\n            if opt is not None:\n                opt.update_free_dof_size_indices()",
  "def __len__(self):\n        return len(self._free)",
  "def fix(self, key: Key) -> None:\n        \"\"\"\n        Fixes the specified DOF\n\n        Args:\n            key: Key to identify the DOF\n        \"\"\"\n        if isinstance(key, str):\n            key = self._names.index(key)\n        self._free[key] = False\n        self._update_opt_indices()",
  "def unfix(self, key: Key) -> None:\n        \"\"\"\n        Unfixes the specified DOF\n\n        Args:\n            key: Key to identify the DOF\n        \"\"\"\n        if isinstance(key, str):\n            key = self._names.index(key)\n        self._free[key] = True\n        self._update_opt_indices()",
  "def all_free(self) -> bool:\n        \"\"\"\n        Checks if all DOFs are allowed to be varied\n\n        Returns:\n            True if all DOFs are free to changed\n        \"\"\"\n        return self._free.all()",
  "def all_fixed(self) -> bool:\n        \"\"\"\n        Checks if all the DOFs are fixed\n\n        Returns:\n            True if all DOFs are fixed\n        \"\"\"\n        return not self._free.any()",
  "def free_status(self) -> BoolArray:\n        return self._free",
  "def get(self, key: Key) -> Real:\n        \"\"\"\n        Get the value of specified DOF. Even fixed DOFs can\n        be obtained with this method\n\n        Args:\n        key: Key to identify the DOF\n        Returns:\n            Value of the DOF\n        \"\"\"\n        if isinstance(key, str):\n            key = self._names.index(key)\n        return self._x[key]",
  "def set(self, key: Key, val: Real):\n        \"\"\"\n        Modify the value of specified DOF. Even fixed DOFs can\n        modified with this method\n\n        Args:\n        key: Key to identify the DOF\n        val: Value of the DOF\n        \"\"\"\n        if isinstance(key, str):\n            key = self._names.index(key)\n        self._x[key] = val\n        self._flag_recompute_opt()",
  "def is_free(self, key: Key) -> bool:\n        \"\"\"\n        Get the status of the specified DOF.\n\n        Args:\n        key: Key to identify the DOF\n        Returns:\n            Status of the DOF\n        \"\"\"\n        if isinstance(key, str):\n            key = self._names.index(key)\n        return self._free[key]",
  "def fix_all(self) -> None:\n        \"\"\"\n        Fixes all the DOFs\n        \"\"\"\n        self._free.fill(False)\n        self._update_opt_indices()",
  "def unfix_all(self) -> None:\n        \"\"\"\n        Makes all DOFs variable\n        Caution: Make sure the bounds are well defined\n        \"\"\"\n        self._free.fill(True)\n        self._update_opt_indices()",
  "def any_free(self) -> bool:\n        \"\"\"\n        Checks for any free DOFs\n\n        Returns:\n            True if any free DOF is found, else False\n        \"\"\"\n        return self._free.any()",
  "def any_fixed(self) -> bool:\n        \"\"\"\n        Checks for any free DOFs\n\n        Returns:\n            True if any fixed DOF is found, else False\n        \"\"\"\n        return not self._free.all()",
  "def free_x(self) -> RealArray:\n        \"\"\"\n\n        Returns:\n            The values of the free DOFs.\n        \"\"\"\n        return self._x[self._free]",
  "def free_x(self, x: RealArray) -> None:\n        \"\"\"\n        Update the values of the free DOFs with the supplied values\n\n        Args:\n            x: Array of new DOF values\n               (word of caution: This setter blindly broadcasts a single value.\n               So don't supply a single value unless you really desire.)\n        \"\"\"\n        # To prevent fully fixed DOFs from not raising Error\n        # And to prevent broadcasting of a single DOF\n        if self.reduced_len != len(x):\n            raise DofLengthMismatchError(len(x), self.reduced_len)\n        self._x[self._free] = np.asarray(x, dtype=np.double)\n        self._flag_recompute_opt()",
  "def full_x(self) -> RealArray:\n        \"\"\"\n        Return all x even the fixed ones\n\n        Returns:\n            The values of full DOFs without any restrictions\n        \"\"\"\n        return self._x",
  "def full_x(self, x: RealArray) -> None:\n        \"\"\"\n        Update the values of the all DOFs with the supplied values\n\n        Args:\n            x: Array of new DOF values\n        .. warning::\n               Even fixed DOFs are assinged\n        \"\"\"\n        # To prevent broadcasting of a single DOF\n        if len(self._x) != len(x):\n            raise DofLengthMismatchError(len(x), len(self._x))\n        self._x = np.asarray(x, dtype=np.double)\n        self._flag_recompute_opt()",
  "def reduced_len(self) -> Integral:\n        \"\"\"\n        The number of free DOFs.\n\n        The standard len function returns the full length of DOFs.\n\n        Returns:\n            The number of free DOFs\n        \"\"\"\n        return len(self._free[self._free])",
  "def free_lower_bounds(self) -> RealArray:\n        \"\"\"\n        Lower bounds of the DOFs\n\n        Returns:\n            Lower bounds of the DOFs\n        \"\"\"\n        return self._lower_bounds[self._free]",
  "def free_lower_bounds(self, lower_bounds: RealArray) -> None:\n        \"\"\"\n\n        Args:\n            lower_bounds: Lower bounds of the DOFs\n        \"\"\"\n        # To prevent fully fixed DOFs from not raising Error\n        # and to prevent broadcasting of a single DOF\n        if self.reduced_len != len(lower_bounds):\n            raise DofLengthMismatchError(len(lower_bounds), self.reduced_len)\n        self._lower_bounds[self._free] = np.asarray(lower_bounds, dtype=np.double)",
  "def full_lower_bounds(self) -> RealArray:\n        return self._lower_bounds",
  "def full_lower_bounds(self, lower_bounds: RealArray) -> None:\n        \"\"\"\n        Set the full lower bounds\n\n        Args:\n            lower_bounds: Lower bounds of the DOFs\n        \"\"\"\n        if len(self.lower_bounds) != len(lower_bounds):\n            raise DofLengthMismatchError(len(lower_bounds), len(self.lower_bounds))\n        self._lower_bounds = np.asarray(lower_bounds, dtype=np.double)",
  "def free_upper_bounds(self) -> RealArray:\n        \"\"\"\n\n        Returns:\n            Upper bounds of the DOFs\n        \"\"\"\n        return self._upper_bounds[self._free]",
  "def free_upper_bounds(self, upper_bounds: RealArray) -> None:\n        \"\"\"\n\n        Args:\n            upper_bounds: Upper bounds of the DOFs\n        \"\"\"\n        # To prevent fully fixed DOFs from not raising Error\n        # and to prevent broadcasting of a single DOF\n        if self.reduced_len != len(upper_bounds):\n            raise DofLengthMismatchError(len(upper_bounds), self.reduced_len)\n        self._upper_bounds[self._free] = np.asarray(upper_bounds, dtype=np.double)",
  "def full_upper_bounds(self) -> RealArray:\n        return self._upper_bounds",
  "def full_upper_bounds(self, upper_bounds: RealArray) -> None:\n        \"\"\"\n        Set the full upper bounds\n\n        Args:\n            upper_bounds: Upper bounds of the DOFs\n        \"\"\"\n        if len(self.upper_bounds) != len(upper_bounds):\n            raise DofLengthMismatchError(len(upper_bounds), len(self.upper_bounds))\n        self._upper_bounds = np.asarray(upper_bounds, dtype=np.double)",
  "def bounds(self) -> Tuple[RealArray, RealArray]:\n        \"\"\"\n\n        Returns:\n            (Lower bounds list, Upper bounds list)\n        \"\"\"\n        return (self.free_lower_bounds, self.free_upper_bounds)",
  "def full_bounds(self) -> Tuple[RealArray, RealArray]:\n        return (self.full_lower_bounds, self.full_upper_bounds)",
  "def update_lower_bound(self, key: Key, val: Real) -> None:\n        \"\"\"\n        Updates the lower bound of the specified DOF to the given value\n\n        Args:\n            key: DOF identifier\n            val: Numeric lower bound of the DOF\n        \"\"\"\n        if isinstance(key, str):\n            key = self._names.index(key)\n        self._lower_bounds[key] = val",
  "def update_upper_bound(self, key: Key, val: Real) -> None:\n        \"\"\"\n        Updates the upper bound of the specified DOF to the given value\n\n        Args:\n            key: DOF identifier\n            val: Numeric upper bound of the DOF\n        \"\"\"\n        if isinstance(key, str):\n            key = self._names.index(key)\n        self._upper_bounds[key] = val",
  "def update_bounds(self, key: Key, val: Tuple[Real, Real]) -> None:\n        \"\"\"\n        Updates the bounds of the specified DOF to the given value\n\n        Args:\n            key: DOF identifier\n            val: (lower, upper) bounds of the DOF\n        \"\"\"\n        if isinstance(key, str):\n            key = self._names.index(key)\n        self._lower_bounds[key] = val[0]\n        self._upper_bounds[key] = val[1]",
  "def free_names(self):\n        \"\"\"\n\n        Returns:\n            string identifiers of the DOFs\n        \"\"\"\n        @lru_cache()\n        def red_names(free):\n            rnames = []\n            for i, f in enumerate((free)):\n                if f:\n                    rnames.append(self._names[i])\n            return rnames\n        return red_names(tuple(self._free))",
  "def full_names(self):\n        return self._names",
  "def __init__(self,\n                 x0: RealArray = None,\n                 names: StrArray = None,\n                 fixed: BoolArray = None,\n                 lower_bounds: RealArray = None,\n                 upper_bounds: RealArray = None, *,\n                 dofs: DOFs = None,\n                 external_dof_setter: Callable[..., None] = None,\n                 depends_on: Sequence[Optimizable] = None,\n                 opt_return_fns: Sequence[Sequence[str]] = None,\n                 funcs_in: Sequence[Callable[..., Union[RealArray, Real]]] = None,\n                 **kwargs):\n        \"\"\"\n        Args:\n            x0: Initial state (or initial values of DOFs)\n            names: Human identifiable names for the DOFs\n            fixed: Array describing whether the DOFs are free or fixed\n            lower_bounds: Lower bounds for the DOFs\n            upper_bounds: Upper bounds for the DOFs\n            dofs: Degrees of freedoms as DOFs object\n            external_dof_setter: Function used by derivative classes to\n                handle DOFs outside of the dofs object within the class.\n                Mainly used when the DOFs are primarily handled by C++ code.\n                In that case, for all intents and purposes, the internal dofs\n                object is a duplication of the DOFs stored elsewhere. In such\n                cases, the internal dofs object is used to handle the dof\n                partitioning, but external dofs are\n                used for computation of the objective function.\n            depends_on: Sequence of Optimizable objects on which the current\n                Optimizable object depends on to define the optimization\n                problem in conjuction with the DOFs. If the optimizable problem\n                can be thought of as a direct acyclic graph based on\n                dependencies, the optimizable objects\n                supplied with depends_on act as parent nodes to the current\n                Optimizable object in such an optimization graph\n            opt_return_fns: Specifies the return value for each of the\n                Optimizable object. Used in the case, where Optimizable object\n                can return different return values. Typically return values are\n                computed by different functions defined in the Optimizable\n                object. The return values are selected by choosing the\n                functions. To know the various return values, use the\n                Optimizable.get_return_fn_names function. If the list is\n                empty, default return value is used. If the Optimizable\n                object can return multiple values, the default is the array\n                of all possible return values.\n            funcs_in: Instead of specifying depends_on and opt_return_fns, specify\n                the methods of the Optimizable objects directly. The parent\n                objects are identified automatically. Doesn't work with\n                funcs_in with a property decorator\n        \"\"\"\n        if dofs is None:\n            dofs = DOFs(x0,\n                        names,\n                        np.logical_not(fixed) if fixed is not None else None,\n                        lower_bounds,\n                        upper_bounds)\n        else:\n            # If a DOFs object is supplied, call external dof setter if present\n            if external_dof_setter is not None:\n                external_dof_setter(self, dofs.full_x)\n\n        self._dofs = dofs\n        self.local_dof_setter = external_dof_setter\n\n        # Generate unique and immutable representation for different\n        # instances of same class\n        self._id = ImmutableId(next(self.__class__._ids))\n        self.name = self.__class__.__name__ + str(self._id.id)\n        hash_str = hashlib.sha256(self.name.encode('utf-8')).hexdigest()\n        self._hash = int(hash_str, 16) % 10**32  # 32 digit int as hash\n        self._children = set()  # This gets populated when the object is passed\n        # as argument to another Optimizable object\n        self.return_fns = WeakKeyDefaultDict(list)  # Store return fn's required by each child\n\n        # Assign self as child to parents\n        funcs_in = list(funcs_in) if funcs_in is not None else []\n        depends_on = list(depends_on) if depends_on is not None else []\n        assert (not ((len(funcs_in) > 0) and (len(depends_on) > 0)))\n\n        def binder(fn, inst):\n            def func(*args, **kwargs):\n                return fn(inst, *args, **kwargs)\n            return func\n\n        if len(depends_on):\n            self.parents = depends_on\n            for i, parent in enumerate(self.parents):\n                parent._add_child(self)\n                return_fns = opt_return_fns[i] if opt_return_fns else []\n                try:\n                    if not len(return_fns) and len(parent.return_fn_map.values()):\n                        return_fns = parent.return_fn_map.values()\n                except:\n                    pass\n                for fn in return_fns:\n                    parent.add_return_fn(self, fn)\n                    funcs_in.append(binder(fn, parent))\n        else:  # Process funcs_in (Assumes depends_on is empty)\n            for fn in funcs_in:\n                opt_in = fn.__self__\n                depends_on.append(opt_in)\n                opt_in.add_return_fn(self, fn.__func__)\n            self.parents = list(dict.fromkeys(depends_on))\n            for i, parent in enumerate(self.parents):\n                parent._add_child(self)\n\n        self.funcs_in = funcs_in\n\n        # Obtain unique list of the ancestors\n        self.ancestors = self._get_ancestors()\n\n        # Compute the indices of all the DOFs\n        self._update_full_dof_size_indices()\n        self.update_free_dof_size_indices()\n        # Inform the object that it doesn't have valid cache\n        self.set_recompute_flag()\n        log.debug(f\"Unused arguments for {self.__class__} are {kwargs}\")\n        super().__init__()\n\n        # Keep this at the end because the function refers to Optimizable object\n        self._dofs.add_opt(self)",
  "def replace_dofs(self, dofs):\n        \"\"\"\n        Calls all the required functions in correct order if the DOFs object\n        is replaced manually by the user\n        Args:\n            dofs: DOFs object\n        \"\"\"\n        self._dofs.remove_opt(self)\n        self._dofs = dofs\n        self._update_full_dof_size_indices()\n        self.update_free_dof_size_indices()\n        self.set_recompute_flag()\n        self._dofs.add_opt(self)",
  "def __str__(self):\n        return self.name",
  "def __hash__(self) -> int:\n        return self._hash",
  "def __eq__(self, other: Optimizable) -> bool:\n        \"\"\"\n        Checks the equality condition\n\n        Args:\n            other: Another object of subclass of Optimizable\n\n        Returns: True only if both are the same objects.\n\n        \"\"\"\n        return self.name == other.name",
  "def __call__(self, x: RealArray = None, *args, child=None, **kwargs):\n        if x is not None:\n            self.x = x\n        return_fn_map = self.__class__.return_fn_map\n\n        if child:\n            return_fns = self.return_fns[child] if self.return_fns[child] else \\\n                return_fn_map.values()\n        else:\n            return_fns = return_fn_map.values()\n\n        result = []\n        for fn in return_fns:\n            result.append(fn(self, *args, **kwargs))\n\n        return result if len(result) > 1 else result[0]",
  "def get_return_fn_names(self) -> List[str]:\n        \"\"\"\n        Return the names of the functions that could be used as objective\n        functions.\n\n        Returns:\n            List of function names that could be used as objective functions\n        \"\"\"\n        return list(self.__class__.return_fn_map.keys())",
  "def add_return_fn(self, child: Optimizable, fn: Union[str, Callable]) -> None:\n        \"\"\"\n        Add return function to the list of the return functions called by\n        the child Optimizable object\n\n        Args:\n            child: an Optimizable object that is direct dependent of the current\n                Optimizable instance\n            fn: method of the Optimizable object needed by the child\n        \"\"\"\n        self._add_child(child)\n\n        if isinstance(fn, str):\n            fn = self.__class__.return_fn_map[fn]\n        self.return_fns[child].append(fn)",
  "def get_return_fns(self, child: Optimizable) -> List[Callable]:\n        \"\"\"\n        Gets return functions from this Optimizable object used by the child\n        Optimizable object\n\n        Args:\n            child: Dependent Optimizable object\n\n        Returns:\n            List of methods that return a value when the current Optimizable\n            object is called from the child\n        \"\"\"\n        return self.return_fns[child]",
  "def get_return_fn_list(self) -> List[List[Callable]]:\n        \"\"\"\n        Gets return functions from this Optimizable object used by all the child\n        Optimizable objects\n\n        Returns:\n            List of methods that return a value when the current Optimizable\n            object is called from the children.\n        \"\"\"\n        return list(self.return_fns.values())",
  "def get_parent_return_fns_list(self) -> List[List[Callable]]:\n        \"\"\"\n        Get a list of the funcs returned by the parents as list of lists\n\n        Returns:\n            The funcs returned by all the parents of the Optimizable object\n        \"\"\"\n        return_fn_list = []\n        for parent in self.parents:\n            return_fn_list.append(parent.get_return_fns(self))\n        return return_fn_list",
  "def parent_return_fns_no(self) -> int:\n        \"\"\"\n        Compute the total number of the return funcs of all the parents\n        of the Optimizable object\n\n        Returns:\n            The total number of the return funcs  of the Optimizable object's\n            parents.\n        \"\"\"\n        return_fn_no = 0\n        for parent in self.parents:\n            return_fn_no += len(parent.get_return_fns(self))\n        return return_fn_no",
  "def _add_child(self, child: Optimizable) -> None:\n        \"\"\"\n        Adds another Optimizable object as child. All the\n        required processing of the dependencies is done in the child node.\n        This method is used mainly to maintain 2-way link between parent\n        and child.\n\n        Args:\n            child: Direct dependent (child) of the Optimizable object\n        \"\"\"\n        weakref_child = weakref.ref(child)\n        if weakref_child not in self._children:\n            self._children.add(weakref_child)",
  "def _remove_child(self, other: Optimizable) -> None:\n        \"\"\"\n        Remove the specific Optimizable object from the children list.\n\n        Args:\n            child: Direct dependent (child) of the Optimizable object\n        \"\"\"\n        weakref_other = weakref.ref(other)\n        self._children.remove(weakref_other)\n        if other in self.return_fns:\n            del self.return_fns[other]",
  "def add_parent(self, index: int, other: Optimizable) -> None:\n        \"\"\"\n        Adds another Optimizable object as parent at specified index.\n\n        Args:\n            int: Index of the parent's list\n            other: Another Optimizable object to be added as parent\n        \"\"\"\n        if other not in self.parents:\n            self.parents.insert(index, other)\n            other._add_child(self)\n            self._update_full_dof_size_indices()  # Updates ancestors as well\n            self.update_free_dof_size_indices()\n            self.set_recompute_flag()\n        else:\n            log.debug(\"The given Optimizable object is already a parent\")",
  "def append_parent(self, other: Optimizable) -> None:\n        \"\"\"\n        Appends another Optimizable object to parents list\n\n        Args:\n            other: New parent Optimizable object\n        \"\"\"\n        self.add_parent(len(self.parents), other)",
  "def pop_parent(self, index: int = -1) -> Optimizable:\n        \"\"\"\n        Removes the parent Optimizable object at specified index.\n\n        Args:\n            index: Index of the list of the parents\n\n        Returns:\n            The removed parent Optimizable object\n        \"\"\"\n        discarded_parent = self.parents.pop(index)\n        discarded_parent._remove_child(self)\n        self._update_full_dof_size_indices()  # Updates ancestors as well\n        self.update_free_dof_size_indices()\n        self.set_recompute_flag()\n\n        return discarded_parent",
  "def remove_parent(self, other: Optimizable):\n        \"\"\"\n        Removes the specified Optimizable object from the list of parents.\n\n        Args:\n            other: The Optimizable object to be removed from the list of parents\n        \"\"\"\n        self.parents.remove(other)\n        other._remove_child(self)\n        self._update_full_dof_size_indices()  # updates ancestors as well\n        self.update_free_dof_size_indices()\n        self.set_recompute_flag()",
  "def _get_ancestors(self) -> list[Optimizable]:\n        \"\"\"\n        Get all the ancestors of the current Optimizable object\n\n        Returns:\n            List of Optimizable objects that are parents of current\n            Optimizable objects\n        \"\"\"\n        ancestors = []\n        for parent in self.parents:\n            ancestors += parent.ancestors\n        ancestors += self.parents\n        return sorted(dict.fromkeys(ancestors), key=lambda a: a.name)",
  "def unique_dof_lineage(self):\n        return self._unique_dof_opts",
  "def update_free_dof_size_indices(self) -> None:\n        \"\"\"\n        Updates the DOFs lengths for the Optimizable object as well as\n        those of the descendent (dependent) Optimizable objects.\n\n        Call this function whenever DOFs are fixed or unfixed or when parents\n        are added/deleted. Recursively calls the same function in children\n        \"\"\"\n        # TODO: This is slow because it walks through the graph repeatedly\n        # TODO: Develop a faster scheme.\n        # TODO: Alternatively ask the user to call this manually from the end\n        # TODO: node after fixing/unfixing any DOF\n        dof_indices = [0]\n        free_dof_size = 0\n        dof_objs = set()\n        for opt in self._unique_dof_opts:\n            dof_objs.add(opt.dofs)\n            size = opt.local_dof_size\n            free_dof_size += size\n            dof_indices.append(free_dof_size)\n\n        self._free_dof_size = free_dof_size\n        self.dof_indices = dict(zip(self._unique_dof_opts,\n                                    zip(dof_indices[:-1], dof_indices[1:])))\n\n        # Update the reduced dof length of children\n        for weakref_child in self._children:\n            child = weakref_child()\n            if child is not None:\n                child.update_free_dof_size_indices()",
  "def _update_full_dof_size_indices(self) -> None:\n        \"\"\"\n        Updates the full DOFs lengths for this instance and\n        those of the children. Updates the ancestors attribute as well.\n\n        Call this function whenever parents are added or removed. Recursively\n        calls the same function in children.\n        \"\"\"\n\n        # TODO: This is slow because it walks through the graph repeatedly\n        # TODO: Develop a faster scheme.\n        # TODO: Alternatively ask the user to call this manually from the end\n        # TODO: node after fixing/unfixing any DOF\n        dof_indices = [0]\n        full_dof_size = 0\n        dof_objs = set()\n        self.ancestors = self._get_ancestors()\n        self._unique_dof_opts = []\n        for opt in (self.ancestors + [self]):\n            if opt.dofs not in dof_objs:\n                dof_objs.add(opt.dofs)\n                full_dof_size += opt.local_full_dof_size\n                dof_indices.append(full_dof_size)\n                self._unique_dof_opts.append(opt)\n\n        self._full_dof_size = full_dof_size\n        self._full_dof_indices = dict(zip(self._unique_dof_opts,\n                                          zip(dof_indices[:-1], dof_indices[1:])))\n\n        # Update the full dof length of children\n        for weakref_child in self._children:\n            child = weakref_child()\n            if child is not None:\n                child._update_full_dof_size_indices()",
  "def dofs(self) -> DOFs:\n        \"\"\"\n        Return all the attributes of local degrees of freedom via DOFs object.\n        Mainly used to conform with the default as_dict method of GSONable\n        and to share DOFs object between multiple Optimizable objects\n        \"\"\"\n        return self._dofs",
  "def full_dof_size(self) -> Integral:\n        \"\"\"\n        Total number of all (free and fixed) DOFs associated with the\n        Optimizable object as well as parent Optimizable objects.\n        \"\"\"\n        return self._full_dof_size",
  "def dof_size(self) -> Integral:\n        \"\"\"\n        Total number of free DOFs associated with the Optimizable object\n        as well as parent Optimizable objects.\n        \"\"\"\n        return self._free_dof_size",
  "def local_full_dof_size(self) -> Integral:\n        \"\"\"\n        Number of all (free and fixed) DOFs associated with the Optimizable\n        object.\n\n        Returns:\n            Total number of free and fixed DOFs associated with the Optimizable\n            object.\n        \"\"\"\n        return len(self._dofs)",
  "def local_dof_size(self) -> Integral:\n        \"\"\"\n        Number of free DOFs associated with the Optimizable object.\n\n        Returns:\n            Number of free DOFs associated with the Optimizable object.\n        \"\"\"\n        return self._dofs.reduced_len",
  "def x(self) -> RealArray:\n        \"\"\"\n        Numeric values of the free DOFs associated with the current\n        Optimizable object and those of its ancestors\n        \"\"\"\n        return np.concatenate([opt._dofs.free_x for\n                               opt in self._unique_dof_opts])",
  "def x(self, x: RealArray) -> None:\n        if list(self.dof_indices.values())[-1][-1] != len(x):\n            raise ValueError\n        for opt, indices in self.dof_indices.items():\n            opt.local_x = x[indices[0]:indices[1]]",
  "def full_x(self) -> RealArray:\n        \"\"\"\n        Numeric values of all the DOFs (both free and fixed) associated\n        with the current Optimizable object and those of its ancestors\n        \"\"\"\n        return np.concatenate([opt._dofs.full_x for\n                               opt in self._unique_dof_opts])",
  "def full_x(self, x: RealArray) -> None:\n        \"\"\"\n        Setter used to set all the global DOF values\n        \"\"\"\n        for opt, indices in self._full_dof_indices.items():\n            opt.local_full_x = x[indices[0]:indices[1]]",
  "def local_x(self) -> RealArray:\n        \"\"\"\n        Numeric values of the free DOFs associated with this\n        Optimizable object\n        \"\"\"\n        return self._dofs.free_x",
  "def local_x(self, x: RealArray) -> None:\n        \"\"\"\n        Setter for local dofs.\n        \"\"\"\n        if self.local_dof_size != len(x):\n            raise ValueError\n        self._dofs.free_x = x",
  "def local_full_x(self):\n        \"\"\"\n        Numeric values of all DOFs (both free and fixed) associated with\n        this Optimizable object\n        \"\"\"\n        return self._dofs.full_x",
  "def x0(self):\n        \"\"\"\n        Mimics dataclass behavior for Optimizable\n        \"\"\"\n        return self.local_full_x",
  "def local_full_x(self, x: RealArray) -> None:\n        \"\"\"\n        For those cases, where one wants to assign all DOFs including fixed\n\n        .. warning:: Even fixed DOFs are assigned.\n        \"\"\"\n        self._dofs.full_x = x",
  "def set_recompute_flag(self, parent=None):\n        self.new_x = True\n        self.recompute_bell(parent=parent)\n\n        # for child in self._children:\n        for weakref_child in self._children:\n            child = weakref_child()\n            if child is not None:\n                child.set_recompute_flag(parent=self)",
  "def get(self, key: Key) -> Real:\n        \"\"\"\n        Get the value of specified DOF.\n        Even fixed dofs can be obtained individually.\n\n        Args:\n            key: DOF identifier\n        \"\"\"\n        return self._dofs.get(key)",
  "def set(self, key: Key, new_val: Real) -> None:\n        \"\"\"\n        Update the value held the specified DOF.\n        Even fixed dofs can be set this way\n\n        Args:\n            key: DOF identifier\n            new_val: New value of the DOF\n        \"\"\"\n        self._dofs.set(key, new_val)",
  "def recompute_bell(self, parent=None):\n        \"\"\"\n        Function to be called whenever new DOFs input is given or if the\n        parent Optimizable's data changed, so the output from the current\n        Optimizable object is invalid.\n\n        This method gets called by various DOF setters. If only the local\n        DOFs of an object are being set, the recompute_bell method is called\n        in that object and also in the descendent objects that have a dependency\n        on the object, whose local DOFs are being changed. If gloabl DOFs\n        of an object are being set, the recompute_bell method is called in\n        the object, ancestors of the object, as well as the descendents of\n        the object.\n\n        Need to be implemented by classes that provide a dof_setter for\n        external handling of DOFs.\n        \"\"\"\n        pass",
  "def bounds(self) -> Tuple[RealArray, RealArray]:\n        \"\"\"\n        Lower and upper bounds of the free DOFs associated with the current\n        Optimizable object and those of its ancestors\n        \"\"\"\n        return (self.lower_bounds, self.upper_bounds)",
  "def full_bounds(self) -> Tuple[RealArray, RealArray]:\n        \"\"\"\n        Lower and upper bounds of the fixed and free DOFs associated with the current\n        Optimizable object and those of its ancestors\n        \"\"\"\n        return (self.full_lower_bounds, self.full_upper_bounds)",
  "def local_bounds(self) -> Tuple[RealArray, RealArray]:\n        \"\"\"\n        Lower and upper bounds of the free DOFs associated with\n        this Optimizable object\n        \"\"\"\n        return self._dofs.bounds",
  "def full_lower_bounds(self) -> RealArray:\n        \"\"\"\n        Lower bounds of the fixed and free DOFs associated with the current\n        Optimizable object and those of its ancestors\n        \"\"\"\n        return np.concatenate([opt._dofs.full_lower_bounds for opt in self.unique_dof_lineage])",
  "def full_lower_bounds(self, lb) -> None:\n        \"\"\"\n        Set the lower bounds of the fixed and free DOFS associated with the\n        current Optimizable object and its ancestors.\n        \"\"\"\n        if list(self.dof_indices.values())[-1][-1] != len(lb):\n            raise ValueError\n        for opt, indices in self.dof_indices.items():\n            opt._dofs.full_lower_bounds = lb[indices[0]:indices[1]]",
  "def lower_bounds(self) -> RealArray:\n        \"\"\"\n        Lower bounds of the free DOFs associated with the current\n        Optimizable object and those of its ancestors\n        \"\"\"\n        return np.concatenate([opt._dofs.free_lower_bounds for opt in self.unique_dof_lineage])",
  "def lower_bounds(self, lb) -> None:\n        \"\"\"\n        Set the lower bounds of the free DOFS associated with the\n        current Optimizable object and its ancestors.\n        \"\"\"\n        if list(self.dof_indices.values())[-1][-1] != len(lb):\n            raise ValueError\n        for opt, indices in self.dof_indices.items():\n            opt._dofs.free_lower_bounds = lb[indices[0]:indices[1]]",
  "def set_lower_bound(self, key: Key, new_val: Real) -> None:\n        \"\"\"\n        Update the value of the lower bound of a specified DOF.\n        Even lower bounds of fixed dofs can be set this way\n\n        Args:\n            key: DOF identifier\n            new_val: New value of the lower bound\n        \"\"\"\n        self._dofs.update_lower_bound(key, new_val)",
  "def local_lower_bounds(self) -> RealArray:\n        \"\"\"\n        Lower bounds of the free DOFs associated with this Optimizable\n        object\n        \"\"\"\n        return self._dofs.free_lower_bounds",
  "def local_lower_bounds(self, llb: RealArray) -> None:\n        \"\"\"\n        Set the lower bounds of the free dofs of this\n        Optimizable object.\n        \"\"\"\n        self._dofs.free_lower_bounds = llb",
  "def local_full_lower_bounds(self) -> RealArray:\n        \"\"\"\n        Get the lower bounds of the free and fixed dofs of this\n        Optimizable object.\n        \"\"\"\n        return self._dofs.full_lower_bounds",
  "def local_full_lower_bounds(self, llb: RealArray) -> None:\n        \"\"\"\n        Set the lower bounds of the free and fixed dofs of this\n        Optimizable object.\n        \"\"\"\n        self._dofs.full_lower_bounds = llb",
  "def full_upper_bounds(self) -> RealArray:\n        \"\"\"\n        Upper bounds of the fixed and free DOFs associated with the current\n        Optimizable object and those of its ancestors\n        \"\"\"\n        return np.concatenate([opt._dofs.full_upper_bounds for opt in self.unique_dof_lineage])",
  "def full_upper_bounds(self, ub) -> None:\n        \"\"\"\n        Set the upper bounds of the fixed and free DOFS associated with the\n        current Optimizable object and its ancestors.\n        \"\"\"\n        if list(self.dof_indices.values())[-1][-1] != len(ub):\n            raise ValueError\n        for opt, indices in self.dof_indices.items():\n            opt._dofs.full_upper_bounds = ub[indices[0]:indices[1]]",
  "def upper_bounds(self) -> RealArray:\n        \"\"\"\n        Upper bounds of the free DOFs associated with the current\n        Optimizable object and those of its ancestors\n        \"\"\"\n        opts = self.ancestors + [self]\n        return np.concatenate([opt._dofs.free_upper_bounds for opt in self.unique_dof_lineage])",
  "def upper_bounds(self, ub) -> None:\n        \"\"\"\n        Set the upper bounds of the free DOFS associated with the\n        current Optimizable object and its ancestors.\n        \"\"\"\n        if list(self.dof_indices.values())[-1][-1] != len(ub):\n            raise ValueError\n        for opt, indices in self.dof_indices.items():\n            opt._dofs.free_upper_bounds = ub[indices[0]:indices[1]]",
  "def set_upper_bound(self, key: Key, new_val: Real) -> None:\n        \"\"\"\n        Update the value of the upper bound of a specified DOF.\n        Even upper bounds of fixed dofs can be set this way\n\n        Args:\n            key: DOF identifier\n            new_val: New value of the upper bound\n        \"\"\"\n        self._dofs.update_upper_bound(key, new_val)",
  "def local_upper_bounds(self) -> RealArray:\n        \"\"\"\n        Upper bounds of the free DOFs associated with this Optimizable\n        object\n        \"\"\"\n        return self._dofs.free_upper_bounds",
  "def local_upper_bounds(self, lub: RealArray) -> None:\n        \"\"\"\n        Set the upper bounds of the free dofs of this\n        Optimizable object.\n        \"\"\"\n        self._dofs.free_upper_bounds = lub",
  "def local_full_upper_bounds(self) -> RealArray:\n        \"\"\"\n        Get the upper bounds of the free and fixed dofs of this\n        Optimizable object.\n        \"\"\"\n        return self._dofs.full_upper_bounds",
  "def local_full_upper_bounds(self, lub: RealArray) -> None:\n        \"\"\"\n        Set the upper bounds of the free and fixed dofs of this\n        Optimizable object.\n        \"\"\"\n        self._dofs.full_upper_bounds = lub",
  "def dof_names(self) -> StrArray:\n        \"\"\"\n        Names (Identifiers) of the DOFs associated with the current\n        Optimizable object and those of its ancestors\n        \"\"\"\n        names = []\n        for opt in self.unique_dof_lineage:\n            names += [opt.name + \":\" + dname for dname in opt._dofs.free_names]\n        return names",
  "def full_dof_names(self) -> StrArray:\n        \"\"\"\n        Names (Identifiers) of the DOFs associated with the current\n        Optimizable object and those of its ancestors\n        \"\"\"\n        names = []\n        for opt in self.unique_dof_lineage:\n            names += [opt.name + \":\" + dname for dname in opt._dofs.full_names]\n        return names",
  "def local_dof_names(self) -> StrArray:\n        \"\"\"\n        Names (Identifiers) of the DOFs associated with this Optimizable\n        object\n        \"\"\"\n        return self._dofs.free_names",
  "def local_full_dof_names(self) -> StrArray:\n        \"\"\"\n        Names (Identifiers) of the DOFs associated with this Optimizable\n        object\n        \"\"\"\n        return self._dofs.full_names",
  "def dofs_free_status(self) -> BoolArray:\n        \"\"\"\n        Boolean array denoting whether the DOFs associated with the\n        current and ancestors Optimizable objects are free or not\n        \"\"\"\n        return np.concatenate(\n            [opt._dofs.free_status for opt in self.unique_dof_lineage])",
  "def local_dofs_free_status(self) -> BoolArray:\n        \"\"\"\n        Boolean array denoting whether the DOFs associated with the\n        current Optimizable object are free or not\n        \"\"\"\n        return self._dofs.free_status",
  "def is_fixed(self, key: Key) -> bool:\n        \"\"\"\n        Checks if the specified dof is fixed\n\n        Args:\n            key: DOF identifier\n        \"\"\"\n        return not self.is_free(key)",
  "def is_free(self, key: Key) -> bool:\n        \"\"\"\n        Checks if the specified dof is free\n\n        Args:\n            key: DOF identifier\n        \"\"\"\n        return self._dofs.is_free(key)",
  "def fix(self, key: Key) -> None:\n        \"\"\"\n        Set the fixed attribute for the given degree of freedom.\n\n        Args:\n            key: DOF identifier\n        \"\"\"\n        # TODO: Question: Should we use ifix similar to pandas' loc and iloc?\n\n        self._dofs.fix(key)\n        self.update_free_dof_size_indices()",
  "def unfix(self, key: Key) -> None:\n        \"\"\"\n        Unset the fixed attribute for the given degree of freedom\n\n        Args:\n            key: DOF identifier\n        \"\"\"\n        self._dofs.unfix(key)\n        self.update_free_dof_size_indices()",
  "def full_fix(self, arr: Key) -> None:\n        \"\"\"\n        Set the fixed/free attribute for all dofs on which this Optimizable object\n        depends. \n\n        Args:\n            arr: List or array of the same length as ``full_x``, containing\n                booleans. For each array entry that is ``True``, the corresponding dof will be set\n                to fixed.\n        \"\"\"\n        for opt, indices in self._full_dof_indices.items():\n            opt._dofs._free[:] = np.logical_not(arr[indices[0]:indices[1]])\n            opt._dofs._update_opt_indices()",
  "def full_unfix(self, arr: Key) -> None:\n        \"\"\"\n        Set the fixed/free attribute for all dofs on which this Optimizable object\n        depends. \n\n        Args:\n            arr: List or array of the same length as ``full_x``, containing\n                booleans. For each array entry that is ``True``, the corresponding dof will be set\n                to free.\n        \"\"\"\n        for opt, indices in self._full_dof_indices.items():\n            opt._dofs._free[:] = arr[indices[0]:indices[1]]\n            opt._dofs._update_opt_indices()",
  "def local_fix_all(self) -> None:\n        \"\"\"\n        Set the 'fixed' attribute for all local degrees of freedom associated\n        with the current Optimizable object.\n        \"\"\"\n        self._dofs.fix_all()\n        self.update_free_dof_size_indices()",
  "def fix_all(self) -> None:\n        \"\"\"\n        Set the 'fixed' attribute for all the degrees of freedom associated\n        with the current Optimizable object including those of ancestors.\n        \"\"\"\n        for opt in self.unique_dof_lineage:\n            opt.local_fix_all()",
  "def local_unfix_all(self) -> None:\n        \"\"\"\n        Unset the 'fixed' attribute for all local degrees of freedom associated\n        with the current Optimizable object.\n        \"\"\"\n        self._dofs.unfix_all()\n        self.update_free_dof_size_indices()",
  "def unfix_all(self) -> None:\n        \"\"\"\n        Unset the 'fixed' attribute for all local degrees of freedom associated\n        with the current Optimizable object including those of the ancestors.\n        \"\"\"\n        for opt in self.unique_dof_lineage:\n            opt.local_unfix_all()",
  "def __add__(self, other):\n        \"\"\" Add two Optimizable objects \"\"\"\n        return OptimizableSum([self, other])",
  "def __mul__(self, other):\n        \"\"\" Multiply an Optimizable object by a scalar \"\"\"\n        return ScaledOptimizable(other, self)",
  "def __rmul__(self, other):\n        \"\"\" Multiply an Optimizable object by a scalar \"\"\"\n        return ScaledOptimizable(other, self)",
  "def __radd__(self, other):\n        # This allows sum() to work (the default start value is zero)\n        if other == 0:\n            return self\n        return self.__add__(other)",
  "def plot_graph(self, show=True):\n        \"\"\"\n        Plot the directed acyclical graph that represents the dependencies of an \n        ``Optimizable`` on its parents. The workflow is as follows: generate a ``networkx``\n        ``DiGraph`` using the ``traversal`` function defined below.  Next, call ``graphviz_layout``\n        which determines sensible positions for the nodes of the graph using the ``dot``\n        program of ``graphviz``. Finally, ``networkx`` plots the graph using ``matplotlib``.\n\n        Note that the tool ``network2tikz`` at `https://github.com/hackl/network2tikz <https://github.com/hackl/network2tikz>`_\n        can be used to convert the networkx ``DiGraph`` and positions to a \n        latex file for publication.\n\n        Args:\n            show: Whether to call the ``show()`` function of matplotlib.\n\n        Returns:\n            The ``networkx`` graph corresponding to this ``Optimizable``'s directed acyclical graph\n            and a dictionary of node names that map to sensible x, y positions determined by ``graphviz``\n        \"\"\"\n\n        G = nx.DiGraph()\n        G.add_node(self.name) \n\n        def traversal(root):\n            for p in root.parents:\n                n1 = root.name\n                n2 = p.name\n                G.add_edge(n1, n2)\n                traversal(p)\n\n        traversal(self)\n\n        # this command generates sensible positions for nodes of the DAG\n        # using the \"dot\" program\n        pos = graphviz_layout(G, prog='dot')\n        options = {\n            'node_color': 'white',\n            'arrowstyle': '-|>',\n            'arrowsize': 12,\n            'font_size': 12}\n        nx.draw_networkx(G, pos=pos, arrows=True, **options)\n        if show:\n            plt.show()\n\n        return G, pos",
  "def as_dict(self, serial_objs_dict=None) -> dict:\n        d = super().as_dict(serial_objs_dict)\n        if len(self.local_full_x):\n            d[\"dofs\"] = self._dofs.as_dict2(serial_objs_dict=serial_objs_dict)\n\n        return d",
  "def save(self, filename=None, fmt=None, **kwargs):\n        filename = filename or \"\"\n        fmt = \"\" if fmt is None else fmt.lower()\n        fname = Path(filename).name\n\n        if fmt == \"json\" or fnmatch(fname.lower(), \"*.json\"):\n            if \"cls\" not in kwargs:\n                kwargs[\"cls\"] = GSONEncoder\n            if \"indent\" not in kwargs:\n                kwargs[\"indent\"] = 2\n            simson = SIMSON(self)\n            s = json.dumps(simson, **kwargs)\n            if filename:\n                with zopen(filename, \"wt\") as f:\n                    f.write(s)\n            return s\n        else:\n            raise ValueError(f\"Invalid format: `{str(fmt)}`\")",
  "def from_str(cls, input_str: str, fmt=\"json\"):\n        fmt_low = fmt.lower()\n        if fmt_low == \"json\":\n            return json.loads(input_str, cls=GSONDecoder)\n        else:\n            raise ValueError(f\"Invalid format: `{str(fmt)}`\")",
  "def from_file(cls, filename: str):\n        fname = Path(filename).name\n        if fnmatch(filename, \"*.json*\") or fnmatch(fname, \"*.bson*\"):\n            with zopen(filename, \"rt\") as f:\n                contents = f.read()\n            return cls.from_str(contents, fmt=\"json\")",
  "class TempOptimizable(Optimizable):\n        \"\"\"\n        Subclass of Optimizable class to create optimizable objects dynamically.\n        dof_indicators argument is used to filter out dofs and\n        \"\"\"\n\n        def __init__(self, func, *args, dof_indicators=None, **kwargs):\n\n            self.func = func\n            self.arg_len = len(args)\n            self.kwarg_len = len(kwargs)\n            self.kwarg_keys = []\n            if dof_indicators is not None:\n                assert (self.arg_len + self.kwarg_len == len(dof_indicators))\n                # Using dof_indicators, map args and kwargs to\n                # dofs, non_dofs, and opts\n                dofs, non_dofs, opts = [], [], []\n                for i, arg in enumerate(args):\n                    if dof_indicators[i] == 'opt':\n                        opts.append(arg)\n                    elif dof_indicators[i] == \"non-dof\":\n                        non_dofs.append(arg)\n                    elif dof_indicators[i] == \"dof\":\n                        dofs.append(arg)\n                    else:\n                        raise ValueError\n                for i, k in enumerate(kwargs.keys()):\n                    self.kwarg_keys.append(k)\n                    if dof_indicators[i + self.arg_len] == 'opt':\n                        opts.append(kwargs[k])\n                    elif dof_indicators[i + self.arg_len] == \"non-dof\":\n                        non_dofs.append(kwargs[k])\n                    elif dof_indicators[i + self.arg_len] == \"dof\":\n                        dofs.append(kwargs[k])\n                    else:\n                        raise ValueError\n            else:\n                # nonlocal dof_indicators\n                dofs, non_dofs, opts, dof_indicators = [], [], [], []\n                for i, arg in enumerate(args):\n                    if isinstance(arg, Optimizable):\n                        opts.append(arg)\n                        dof_indicators.append(\"opt\")\n                    else:\n                        non_dofs.append(arg)\n                        dof_indicators.append(\"non-dof\")\n                for k, v in kwargs.items():\n                    self.kwarg_keys.append(k)\n                    if isinstance(v, Optimizable):\n                        opts.append(v)\n                        dof_indicators.append(\"opt\")\n                    else:\n                        non_dofs.append(v)\n                        dof_indicators.append(\"non-dof\")\n\n            # Create args map and kwargs map\n            super().__init__(x0=dofs, depends_on=opts)\n            self.non_dofs = non_dofs\n            self.dof_indicators = dof_indicators\n\n        def J(self):\n            dofs = self.local_full_x\n            # Re-Assemble dofs, non_dofs and opts to args, kwargs\n            args = []\n            kwargs = {}\n            i = 0\n            opt_ind = 0\n            non_dof_ind = 0\n            dof_ind = 0\n            for i in range(self.arg_len):\n                if self.dof_indicators[i] == 'opt':\n                    args.append(self.parents[opt_ind])\n                    opt_ind += 1\n                elif self.dof_indicators[i] == 'dof':\n                    args.append(dofs[dof_ind])\n                    dof_ind += 1\n                elif self.dof_indicators[i] == 'non-dof':\n                    args.append(self.non_dofs[non_dof_ind])\n                    non_dof_ind += 1\n                else:\n                    raise ValueError\n                i += 1\n\n            for j in range(self.kwarg_len):\n                i = j + self.arg_len\n                if self.dof_indicators[i] == 'opt':\n                    kwargs[self.kwarg_keys[j]] = self.parents[opt_ind]\n                    opt_ind += 1\n                elif self.dof_indicators[i] == 'dof':\n                    kwargs[self.kwarg_keys[j]] = dofs[dof_ind]\n                    dof_ind += 1\n                elif self.dof_indicators[i] == 'non-dof':\n                    kwargs[self.kwarg_keys[j]] = self.non_dofs[non_dof_ind]\n                    non_dof_ind += 1\n                else:\n                    raise ValueError\n                j += 1\n            log.info(f'reassembled args len is {len(args)}')\n\n            return self.func(*args, **kwargs)",
  "def __init__(self, factor, opt):\n        self.factor = factor\n        self.opt = opt\n        super().__init__(depends_on=[opt])",
  "def J(self):\n        return float(self.factor) * self.opt.J()",
  "def dJ(self):\n        # Next line uses __rmul__ function for the Derivative class\n        return float(self.factor) * self.opt.dJ(partials=True)",
  "def __init__(self, opts):\n        self.opts = opts\n        super().__init__(depends_on=opts)",
  "def J(self):\n        return sum([opt.J() for opt in self.opts])",
  "def dJ(self):\n        # Next line uses __add__ function for the Derivative class\n        return sum(opt.dJ(partials=True) for opt in self.opts)",
  "def red_names(free):\n            rnames = []\n            for i, f in enumerate((free)):\n                if f:\n                    rnames.append(self._names[i])\n            return rnames",
  "def binder(fn, inst):\n            def func(*args, **kwargs):\n                return fn(inst, *args, **kwargs)\n            return func",
  "def traversal(root):\n            for p in root.parents:\n                n1 = root.name\n                n2 = p.name\n                G.add_edge(n1, n2)\n                traversal(p)",
  "def __init__(self, func, *args, dof_indicators=None, **kwargs):\n\n            self.func = func\n            self.arg_len = len(args)\n            self.kwarg_len = len(kwargs)\n            self.kwarg_keys = []\n            if dof_indicators is not None:\n                assert (self.arg_len + self.kwarg_len == len(dof_indicators))\n                # Using dof_indicators, map args and kwargs to\n                # dofs, non_dofs, and opts\n                dofs, non_dofs, opts = [], [], []\n                for i, arg in enumerate(args):\n                    if dof_indicators[i] == 'opt':\n                        opts.append(arg)\n                    elif dof_indicators[i] == \"non-dof\":\n                        non_dofs.append(arg)\n                    elif dof_indicators[i] == \"dof\":\n                        dofs.append(arg)\n                    else:\n                        raise ValueError\n                for i, k in enumerate(kwargs.keys()):\n                    self.kwarg_keys.append(k)\n                    if dof_indicators[i + self.arg_len] == 'opt':\n                        opts.append(kwargs[k])\n                    elif dof_indicators[i + self.arg_len] == \"non-dof\":\n                        non_dofs.append(kwargs[k])\n                    elif dof_indicators[i + self.arg_len] == \"dof\":\n                        dofs.append(kwargs[k])\n                    else:\n                        raise ValueError\n            else:\n                # nonlocal dof_indicators\n                dofs, non_dofs, opts, dof_indicators = [], [], [], []\n                for i, arg in enumerate(args):\n                    if isinstance(arg, Optimizable):\n                        opts.append(arg)\n                        dof_indicators.append(\"opt\")\n                    else:\n                        non_dofs.append(arg)\n                        dof_indicators.append(\"non-dof\")\n                for k, v in kwargs.items():\n                    self.kwarg_keys.append(k)\n                    if isinstance(v, Optimizable):\n                        opts.append(v)\n                        dof_indicators.append(\"opt\")\n                    else:\n                        non_dofs.append(v)\n                        dof_indicators.append(\"non-dof\")\n\n            # Create args map and kwargs map\n            super().__init__(x0=dofs, depends_on=opts)\n            self.non_dofs = non_dofs\n            self.dof_indicators = dof_indicators",
  "def J(self):\n            dofs = self.local_full_x\n            # Re-Assemble dofs, non_dofs and opts to args, kwargs\n            args = []\n            kwargs = {}\n            i = 0\n            opt_ind = 0\n            non_dof_ind = 0\n            dof_ind = 0\n            for i in range(self.arg_len):\n                if self.dof_indicators[i] == 'opt':\n                    args.append(self.parents[opt_ind])\n                    opt_ind += 1\n                elif self.dof_indicators[i] == 'dof':\n                    args.append(dofs[dof_ind])\n                    dof_ind += 1\n                elif self.dof_indicators[i] == 'non-dof':\n                    args.append(self.non_dofs[non_dof_ind])\n                    non_dof_ind += 1\n                else:\n                    raise ValueError\n                i += 1\n\n            for j in range(self.kwarg_len):\n                i = j + self.arg_len\n                if self.dof_indicators[i] == 'opt':\n                    kwargs[self.kwarg_keys[j]] = self.parents[opt_ind]\n                    opt_ind += 1\n                elif self.dof_indicators[i] == 'dof':\n                    kwargs[self.kwarg_keys[j]] = dofs[dof_ind]\n                    dof_ind += 1\n                elif self.dof_indicators[i] == 'non-dof':\n                    kwargs[self.kwarg_keys[j]] = self.non_dofs[non_dof_ind]\n                    non_dof_ind += 1\n                else:\n                    raise ValueError\n                j += 1\n            log.info(f'reassembled args len is {len(args)}')\n\n            return self.func(*args, **kwargs)",
  "def func(*args, **kwargs):\n                return fn(inst, *args, **kwargs)",
  "class FiniteDifference:\n    \"\"\"\n    Provides Jacobian evaluated with finite difference scheme.\n    Supplies a method named jac to be used with optimizers. Use\n    the initialization to customize the finite difference scheme\n    \"\"\"\n\n    def __init__(self, func: Callable,\n                 x0: RealArray = None,\n                 abs_step: Real = 1.0e-7,\n                 rel_step: Real = 0.0,\n                 diff_method: str = \"forward\") -> None:\n\n        try:\n            if not isinstance(func.__self__, Optimizable):\n                raise TypeError(\"Function supplied should be a method of Optimizable\")\n        except:\n            raise TypeError(\"Function supplied should be a method of Optimizable\")\n\n        self.fn = func\n        self.opt = func.__self__\n\n        self.abs_step = abs_step\n        self.rel_step = rel_step\n        if diff_method not in ['centered', 'forward']:\n            raise ValueError(f\"Finite difference method {diff_method} not implemented. \"\n                             \"Supported methods are 'centered' and 'forward'.\")\n        self.diff_method = diff_method\n\n        self.x0 = np.asarray(x0) if x0 is not None else x0\n\n        self.jac_size = None\n\n    def jac(self, x: RealArray = None) -> RealArray:\n        if x is not None:\n            self.x0 = np.asarray(x)\n        x0 = self.x0 if self.x0 is not None else self.opt.x\n        opt_x0 = self.opt.x\n\n        if self.jac_size is None:\n            out = self.fn()\n            if not isinstance(out, (np.ndarray, collections.abc.Sequence)):\n                out = [out]\n            self.jac_size = (len(out), self.opt.dof_size)\n\n        jac = np.zeros(self.jac_size)\n        steps = finite_difference_steps(x0, abs_step=self.abs_step,\n                                        rel_step=self.rel_step)\n        if self.diff_method == \"centered\":\n            # Centered differences:\n            for j in range(len(x0)):\n                x = np.copy(x0)\n\n                x[j] = x0[j] + steps[j]\n                self.opt.x = x\n                fplus = np.asarray(self.fn())\n\n                x[j] = x0[j] - steps[j]\n                self.opt.x = x\n                fminus = np.asarray(self.fn())\n\n                jac[:, j] = (fplus - fminus) / (2 * steps[j])\n\n        elif self.diff_method == \"forward\":\n            # 1-sided differences\n            self.opt.x = x0\n            f0 = np.asarray(self.fn())\n            for j in range(len(x0)):\n                x = np.copy(x0)\n                x[j] = x0[j] + steps[j]\n                self.opt.x = x\n                fplus = np.asarray(self.fn())\n\n                jac[:, j] = (fplus - f0) / steps[j]\n\n        # Set the opt.x to the original x\n        self.opt.x = opt_x0\n\n        return jac",
  "class MPIFiniteDifference:\n    \"\"\"\n    Provides Jacobian evaluated with finite difference scheme.\n    Use MPI to parallelize the function evaluations needed for the\n    finite difference scheme.\n    Supplies a method named jac to be used with optimizers. Use\n    the initialization to customize the finite difference scheme\n    \"\"\"\n\n    def __init__(self, func: Callable,\n                 mpi,  # Specifying the type MpiPartition here would require initializing MPI\n                 x0: RealArray = None,\n                 abs_step: Real = 1.0e-7,\n                 rel_step: Real = 0.0,\n                 diff_method: str = \"forward\",\n                 log_file: Union[str, IO] = \"jac_log\") -> None:\n\n        try:\n            if not isinstance(func.__self__, Optimizable):\n                raise TypeError(\n                    \"Function supplied should be a method of Optimizable\")\n        except:\n            raise TypeError(\n                \"Function supplied should be a method of Optimizable\")\n\n        self.fn = func\n        self.mpi = mpi\n        self.opt = func.__self__\n\n        self.abs_step = abs_step\n        self.rel_step = rel_step\n        if diff_method not in ['centered', 'forward']:\n            raise ValueError(\n                f\"Finite difference method {diff_method} not implemented. \"\n                \"Supported methods are 'centered' and 'forward'.\")\n        self.diff_method = diff_method\n        self.log_file = log_file\n        self.new_log_file = False\n        self.log_header_written = False\n\n        x0 = np.asarray(x0) if x0 is not None else x0\n        self.x0 = x0 if x0 else self.opt.x\n\n        self.jac_size = None\n        self.eval_cnt = 1\n\n        # initialize cache\n        self.x_cache = None\n        self.jac_cache = None\n\n    def __enter__(self):\n        self.mpi_apart()\n        self.init_log()\n        return self\n\n    def mpi_apart(self):\n        self.mpi.apart(lambda mpi, data: self.mpi_leaders_task(),\n                       lambda mpi, data: self.mpi_workers_task())\n\n    def init_log(self):\n        if self.mpi.proc0_world:\n            if isinstance(self.log_file, str):\n                datestr = datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n                log_file = self.log_file + \"_\" + datestr + \".dat\"\n                self.log_file = open(log_file, 'w')\n                self.new_log_file = True\n        self.start_time = time()\n\n    def __exit__(self, exc_type, exc_value, tb):\n        self.mpi.together()\n        if self.mpi.proc0_world and self.new_log_file:\n            self.log_file.close()\n\n    # Called by MPI leaders\n    def _jac(self, x: RealArray = None):\n        # Use shortcuts for class variables\n        opt = self.opt\n        mpi = self.mpi\n        if not mpi.is_apart:\n            mpi.worker_loop(lambda mpi, data: self.mpi_workers_task())\n        if not mpi.proc0_groups:  # This condition shouldn't  be  triggered\n            return (None, None, None)\n\n        if x is not None:\n            opt.x = x\n\n        logger.info('Beginning parallel finite difference gradient calculation')\n\n        x0 = np.copy(opt.x)\n        nparams = opt.dof_size\n        # Make sure all leaders have the same x0.\n        mpi.comm_leaders.Bcast(x0)\n        logger.info(f'nparams: {nparams}')\n        logger.info(f'x0:  {x0}')\n\n        # Set up the list of parameter values to try\n        steps = finite_difference_steps(x0, abs_step=self.abs_step,\n                                        rel_step=self.rel_step)\n        mpi.comm_leaders.Bcast(steps)\n        diff_method = mpi.comm_leaders.bcast(self.diff_method)\n        if diff_method == \"centered\":\n            nevals_jac = 2 * nparams\n            xs = np.zeros((nparams, nevals_jac))\n            for j in range(nparams):\n                xs[:, 2 * j] = x0[:]  # I don't think I need np.copy(), but not 100% sure.\n                xs[j, 2 * j] = x0[j] + steps[j]\n                xs[:, 2 * j + 1] = x0[:]\n                xs[j, 2 * j + 1] = x0[j] - steps[j]\n        else:  # diff_method == \"forward\":\n            # 1-sided differences\n            nevals_jac = nparams + 1\n            xs = np.zeros((nparams, nevals_jac))\n            xs[:, 0] = x0[:]\n            for j in range(nparams):\n                xs[:, j + 1] = x0[:]\n                xs[j, j + 1] = x0[j] + steps[j]\n\n        evals = None\n        # nvals = None # Work on this later\n        if not mpi.proc0_world:\n            # All procs other than proc0_world should initialize evals before\n            # the nevals_jac loop, since they may not have any evals.\n            self.jac_size = np.zeros(2, dtype=np.int32)\n            self.jac_size = mpi.comm_leaders.bcast(self.jac_size)\n            evals = np.zeros((self.jac_size[0], nevals_jac))\n        # Do the hard work of evaluating the functions.\n        logger.info(f'size of evals is ({self.jac_size[0]}, {nevals_jac})')\n\n        ARB_VAL = 100\n        for j in range(nevals_jac):\n            # Handle only this group's share of the work:\n            if np.mod(j, mpi.ngroups) == mpi.rank_leaders:\n                mpi.mobilize_workers(ARB_VAL)\n                x = xs[:, j]\n                mpi.comm_groups.bcast(x, root=0)\n                opt.x = x\n                out = np.asarray(self.fn())\n\n                if evals is None and mpi.proc0_world:\n                    self.jac_size = mpi.comm_leaders.bcast(self.jac_size)\n                    evals = np.zeros((self.jac_size[0], nevals_jac))\n\n                evals[:, j] = out\n                # evals[:, j] = np.array([f() for f in dofs.funcs])\n\n        # Combine the results from all groups:\n        evals = mpi.comm_leaders.reduce(evals, op=mpi4py.MPI.SUM, root=0)\n\n        if not mpi.is_apart:\n            mpi.stop_workers()\n        # Only proc0_world will actually have the Jacobian.\n        if not mpi.proc0_world:\n            return (None, None, None)\n\n        # Use the evals to form the Jacobian\n        jac = np.zeros(self.jac_size)\n        if diff_method == \"centered\":\n            for j in range(nparams):\n                jac[:, j] = (evals[:, 2 * j] - evals[:, 2 * j + 1]) / (\n                    2 * steps[j])\n        else:  # diff_method == \"forward\":\n            # 1-sided differences:\n            for j in range(nparams):\n                jac[:, j] = (evals[:, j + 1] - evals[:, 0]) / steps[j]\n\n        # Weird things may happen if we do not reset the state vector\n        # to x0:\n        opt.x = x0\n        return jac, xs, evals\n\n    def mpi_leaders_task(self, *args):\n        \"\"\"\n            This function is called by group leaders when\n            MpiPartition.leaders_loop() receives a signal to do something.\n\n            We have to take a \"data\" argument, but there is only 1 task we\n            would do, so we don't use it.\n            \"\"\"\n        logger.debug('mpi leaders task')\n\n        # x is a buffer for receiving the state vector:\n        full_x = np.empty(self.opt.full_dof_size, dtype='d')\n        # If we make it here, we must be doing a fd_jac_par\n        # calculation, so receive the state vector: mpi4py has\n        # separate bcast and Bcast functions!!  comm.Bcast(x,\n        # root=0)\n        full_x = self.mpi.comm_leaders.bcast(full_x, root=0)\n        logger.debug(f'mpi leaders loop full_x={full_x}')\n        self.opt.full_x = full_x\n        self._jac()\n\n    def mpi_workers_task(self, *args):\n        \"\"\"\n            Note: func is a method of opt.\n            \"\"\"\n        logger.debug('mpi workers task')\n\n        # x is a buffer for receiving the state vector:\n        x = np.empty(self.opt.dof_size, dtype='d')\n        # If we make it here, we must be doing a fd_jac_par\n        # calculation, so receive the state vector: mpi4py has\n        # separate bcast and Bcast functions!!  comm.Bcast(x, root=0)\n        x = self.mpi.comm_groups.bcast(x, root=0)\n        logger.debug(f'worker loop worker x={x}')\n        self.opt.x = x\n\n        # We don't store or do anything with f() or jac(), because\n        # the group leader will handle that.\n        try:\n            return self.fn()\n        except:\n            logger.warning(\"Exception caught by worker during residual \"\n                           \"evaluation in worker loop\")\n            traceback.print_exc()  # Print traceback\n\n    # Call to jac function is made in proc0\n    def jac(self, x: RealArray = None, *args, **kwargs):\n        \"\"\"\n        Called by proc0\n        \"\"\"\n        if np.all(x == self.x_cache) and (self.jac_cache is not None):\n            return self.jac_cache\n\n        ARB_VAL = 100\n        logger.debug(\"Entering jac evaluation\")\n\n        if self.jac_size is None:  # Do one evaluation of code\n            if x is None:\n                x = self.x0\n            self.mpi.mobilize_workers(ARB_VAL)\n            self.mpi.comm_groups.bcast(x, root=0)\n            self.opt.x = x\n            out = self.fn()\n            if not isinstance(out, (np.ndarray, collections.abc.Sequence)):\n                out = np.array([out])\n            else:\n                out = np.asarray(out)\n            self.jac_size = np.array((len(out), self.opt.dof_size),\n                                     dtype=np.int32)\n\n        self.mpi.mobilize_leaders(ARB_VAL)  # Any value not equal to STOP\n        full_x = self.opt.full_x\n        self.mpi.comm_leaders.bcast(full_x, root=0)\n        self.opt.full_x = full_x\n\n        jac, xs, evals = self._jac(x)\n        logger.debug(f'jac is {jac}')\n\n        # Write to the log file:\n        logfile = self.log_file\n        if not self.log_header_written:\n            logfile.write(f'Problem type:\\nleast_squares\\nnparams:\\n{len(x)}\\n')\n            logfile.write('function_evaluation,seconds')\n            for j in range(len(x)):\n                logfile.write(f',x({j})')\n            logfile.write('\\n')\n            self.log_header_written = True\n        nevals = evals.shape[1]\n        for j in range(nevals):\n            del_t = time() - self.start_time\n            j_eval = j + self.eval_cnt - 1\n            logfile.write(f'{j_eval:6d},{del_t:12.4e}')\n            for xj in xs[:, j]:\n                logfile.write(f',{xj:24.16e}')\n            logfile.write('\\n')\n            logfile.flush()\n\n        self.eval_cnt += nevals\n\n        # cache it\n        self.x_cache = x\n        self.jac_cache = jac\n\n        return jac",
  "def __init__(self, func: Callable,\n                 x0: RealArray = None,\n                 abs_step: Real = 1.0e-7,\n                 rel_step: Real = 0.0,\n                 diff_method: str = \"forward\") -> None:\n\n        try:\n            if not isinstance(func.__self__, Optimizable):\n                raise TypeError(\"Function supplied should be a method of Optimizable\")\n        except:\n            raise TypeError(\"Function supplied should be a method of Optimizable\")\n\n        self.fn = func\n        self.opt = func.__self__\n\n        self.abs_step = abs_step\n        self.rel_step = rel_step\n        if diff_method not in ['centered', 'forward']:\n            raise ValueError(f\"Finite difference method {diff_method} not implemented. \"\n                             \"Supported methods are 'centered' and 'forward'.\")\n        self.diff_method = diff_method\n\n        self.x0 = np.asarray(x0) if x0 is not None else x0\n\n        self.jac_size = None",
  "def jac(self, x: RealArray = None) -> RealArray:\n        if x is not None:\n            self.x0 = np.asarray(x)\n        x0 = self.x0 if self.x0 is not None else self.opt.x\n        opt_x0 = self.opt.x\n\n        if self.jac_size is None:\n            out = self.fn()\n            if not isinstance(out, (np.ndarray, collections.abc.Sequence)):\n                out = [out]\n            self.jac_size = (len(out), self.opt.dof_size)\n\n        jac = np.zeros(self.jac_size)\n        steps = finite_difference_steps(x0, abs_step=self.abs_step,\n                                        rel_step=self.rel_step)\n        if self.diff_method == \"centered\":\n            # Centered differences:\n            for j in range(len(x0)):\n                x = np.copy(x0)\n\n                x[j] = x0[j] + steps[j]\n                self.opt.x = x\n                fplus = np.asarray(self.fn())\n\n                x[j] = x0[j] - steps[j]\n                self.opt.x = x\n                fminus = np.asarray(self.fn())\n\n                jac[:, j] = (fplus - fminus) / (2 * steps[j])\n\n        elif self.diff_method == \"forward\":\n            # 1-sided differences\n            self.opt.x = x0\n            f0 = np.asarray(self.fn())\n            for j in range(len(x0)):\n                x = np.copy(x0)\n                x[j] = x0[j] + steps[j]\n                self.opt.x = x\n                fplus = np.asarray(self.fn())\n\n                jac[:, j] = (fplus - f0) / steps[j]\n\n        # Set the opt.x to the original x\n        self.opt.x = opt_x0\n\n        return jac",
  "def __init__(self, func: Callable,\n                 mpi,  # Specifying the type MpiPartition here would require initializing MPI\n                 x0: RealArray = None,\n                 abs_step: Real = 1.0e-7,\n                 rel_step: Real = 0.0,\n                 diff_method: str = \"forward\",\n                 log_file: Union[str, IO] = \"jac_log\") -> None:\n\n        try:\n            if not isinstance(func.__self__, Optimizable):\n                raise TypeError(\n                    \"Function supplied should be a method of Optimizable\")\n        except:\n            raise TypeError(\n                \"Function supplied should be a method of Optimizable\")\n\n        self.fn = func\n        self.mpi = mpi\n        self.opt = func.__self__\n\n        self.abs_step = abs_step\n        self.rel_step = rel_step\n        if diff_method not in ['centered', 'forward']:\n            raise ValueError(\n                f\"Finite difference method {diff_method} not implemented. \"\n                \"Supported methods are 'centered' and 'forward'.\")\n        self.diff_method = diff_method\n        self.log_file = log_file\n        self.new_log_file = False\n        self.log_header_written = False\n\n        x0 = np.asarray(x0) if x0 is not None else x0\n        self.x0 = x0 if x0 else self.opt.x\n\n        self.jac_size = None\n        self.eval_cnt = 1\n\n        # initialize cache\n        self.x_cache = None\n        self.jac_cache = None",
  "def __enter__(self):\n        self.mpi_apart()\n        self.init_log()\n        return self",
  "def mpi_apart(self):\n        self.mpi.apart(lambda mpi, data: self.mpi_leaders_task(),\n                       lambda mpi, data: self.mpi_workers_task())",
  "def init_log(self):\n        if self.mpi.proc0_world:\n            if isinstance(self.log_file, str):\n                datestr = datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n                log_file = self.log_file + \"_\" + datestr + \".dat\"\n                self.log_file = open(log_file, 'w')\n                self.new_log_file = True\n        self.start_time = time()",
  "def __exit__(self, exc_type, exc_value, tb):\n        self.mpi.together()\n        if self.mpi.proc0_world and self.new_log_file:\n            self.log_file.close()",
  "def _jac(self, x: RealArray = None):\n        # Use shortcuts for class variables\n        opt = self.opt\n        mpi = self.mpi\n        if not mpi.is_apart:\n            mpi.worker_loop(lambda mpi, data: self.mpi_workers_task())\n        if not mpi.proc0_groups:  # This condition shouldn't  be  triggered\n            return (None, None, None)\n\n        if x is not None:\n            opt.x = x\n\n        logger.info('Beginning parallel finite difference gradient calculation')\n\n        x0 = np.copy(opt.x)\n        nparams = opt.dof_size\n        # Make sure all leaders have the same x0.\n        mpi.comm_leaders.Bcast(x0)\n        logger.info(f'nparams: {nparams}')\n        logger.info(f'x0:  {x0}')\n\n        # Set up the list of parameter values to try\n        steps = finite_difference_steps(x0, abs_step=self.abs_step,\n                                        rel_step=self.rel_step)\n        mpi.comm_leaders.Bcast(steps)\n        diff_method = mpi.comm_leaders.bcast(self.diff_method)\n        if diff_method == \"centered\":\n            nevals_jac = 2 * nparams\n            xs = np.zeros((nparams, nevals_jac))\n            for j in range(nparams):\n                xs[:, 2 * j] = x0[:]  # I don't think I need np.copy(), but not 100% sure.\n                xs[j, 2 * j] = x0[j] + steps[j]\n                xs[:, 2 * j + 1] = x0[:]\n                xs[j, 2 * j + 1] = x0[j] - steps[j]\n        else:  # diff_method == \"forward\":\n            # 1-sided differences\n            nevals_jac = nparams + 1\n            xs = np.zeros((nparams, nevals_jac))\n            xs[:, 0] = x0[:]\n            for j in range(nparams):\n                xs[:, j + 1] = x0[:]\n                xs[j, j + 1] = x0[j] + steps[j]\n\n        evals = None\n        # nvals = None # Work on this later\n        if not mpi.proc0_world:\n            # All procs other than proc0_world should initialize evals before\n            # the nevals_jac loop, since they may not have any evals.\n            self.jac_size = np.zeros(2, dtype=np.int32)\n            self.jac_size = mpi.comm_leaders.bcast(self.jac_size)\n            evals = np.zeros((self.jac_size[0], nevals_jac))\n        # Do the hard work of evaluating the functions.\n        logger.info(f'size of evals is ({self.jac_size[0]}, {nevals_jac})')\n\n        ARB_VAL = 100\n        for j in range(nevals_jac):\n            # Handle only this group's share of the work:\n            if np.mod(j, mpi.ngroups) == mpi.rank_leaders:\n                mpi.mobilize_workers(ARB_VAL)\n                x = xs[:, j]\n                mpi.comm_groups.bcast(x, root=0)\n                opt.x = x\n                out = np.asarray(self.fn())\n\n                if evals is None and mpi.proc0_world:\n                    self.jac_size = mpi.comm_leaders.bcast(self.jac_size)\n                    evals = np.zeros((self.jac_size[0], nevals_jac))\n\n                evals[:, j] = out\n                # evals[:, j] = np.array([f() for f in dofs.funcs])\n\n        # Combine the results from all groups:\n        evals = mpi.comm_leaders.reduce(evals, op=mpi4py.MPI.SUM, root=0)\n\n        if not mpi.is_apart:\n            mpi.stop_workers()\n        # Only proc0_world will actually have the Jacobian.\n        if not mpi.proc0_world:\n            return (None, None, None)\n\n        # Use the evals to form the Jacobian\n        jac = np.zeros(self.jac_size)\n        if diff_method == \"centered\":\n            for j in range(nparams):\n                jac[:, j] = (evals[:, 2 * j] - evals[:, 2 * j + 1]) / (\n                    2 * steps[j])\n        else:  # diff_method == \"forward\":\n            # 1-sided differences:\n            for j in range(nparams):\n                jac[:, j] = (evals[:, j + 1] - evals[:, 0]) / steps[j]\n\n        # Weird things may happen if we do not reset the state vector\n        # to x0:\n        opt.x = x0\n        return jac, xs, evals",
  "def mpi_leaders_task(self, *args):\n        \"\"\"\n            This function is called by group leaders when\n            MpiPartition.leaders_loop() receives a signal to do something.\n\n            We have to take a \"data\" argument, but there is only 1 task we\n            would do, so we don't use it.\n            \"\"\"\n        logger.debug('mpi leaders task')\n\n        # x is a buffer for receiving the state vector:\n        full_x = np.empty(self.opt.full_dof_size, dtype='d')\n        # If we make it here, we must be doing a fd_jac_par\n        # calculation, so receive the state vector: mpi4py has\n        # separate bcast and Bcast functions!!  comm.Bcast(x,\n        # root=0)\n        full_x = self.mpi.comm_leaders.bcast(full_x, root=0)\n        logger.debug(f'mpi leaders loop full_x={full_x}')\n        self.opt.full_x = full_x\n        self._jac()",
  "def mpi_workers_task(self, *args):\n        \"\"\"\n            Note: func is a method of opt.\n            \"\"\"\n        logger.debug('mpi workers task')\n\n        # x is a buffer for receiving the state vector:\n        x = np.empty(self.opt.dof_size, dtype='d')\n        # If we make it here, we must be doing a fd_jac_par\n        # calculation, so receive the state vector: mpi4py has\n        # separate bcast and Bcast functions!!  comm.Bcast(x, root=0)\n        x = self.mpi.comm_groups.bcast(x, root=0)\n        logger.debug(f'worker loop worker x={x}')\n        self.opt.x = x\n\n        # We don't store or do anything with f() or jac(), because\n        # the group leader will handle that.\n        try:\n            return self.fn()\n        except:\n            logger.warning(\"Exception caught by worker during residual \"\n                           \"evaluation in worker loop\")\n            traceback.print_exc()",
  "def jac(self, x: RealArray = None, *args, **kwargs):\n        \"\"\"\n        Called by proc0\n        \"\"\"\n        if np.all(x == self.x_cache) and (self.jac_cache is not None):\n            return self.jac_cache\n\n        ARB_VAL = 100\n        logger.debug(\"Entering jac evaluation\")\n\n        if self.jac_size is None:  # Do one evaluation of code\n            if x is None:\n                x = self.x0\n            self.mpi.mobilize_workers(ARB_VAL)\n            self.mpi.comm_groups.bcast(x, root=0)\n            self.opt.x = x\n            out = self.fn()\n            if not isinstance(out, (np.ndarray, collections.abc.Sequence)):\n                out = np.array([out])\n            else:\n                out = np.asarray(out)\n            self.jac_size = np.array((len(out), self.opt.dof_size),\n                                     dtype=np.int32)\n\n        self.mpi.mobilize_leaders(ARB_VAL)  # Any value not equal to STOP\n        full_x = self.opt.full_x\n        self.mpi.comm_leaders.bcast(full_x, root=0)\n        self.opt.full_x = full_x\n\n        jac, xs, evals = self._jac(x)\n        logger.debug(f'jac is {jac}')\n\n        # Write to the log file:\n        logfile = self.log_file\n        if not self.log_header_written:\n            logfile.write(f'Problem type:\\nleast_squares\\nnparams:\\n{len(x)}\\n')\n            logfile.write('function_evaluation,seconds')\n            for j in range(len(x)):\n                logfile.write(f',x({j})')\n            logfile.write('\\n')\n            self.log_header_written = True\n        nevals = evals.shape[1]\n        for j in range(nevals):\n            del_t = time() - self.start_time\n            j_eval = j + self.eval_cnt - 1\n            logfile.write(f'{j_eval:6d},{del_t:12.4e}')\n            for xj in xs[:, j]:\n                logfile.write(f',{xj:24.16e}')\n            logfile.write('\\n')\n            logfile.flush()\n\n        self.eval_cnt += nevals\n\n        # cache it\n        self.x_cache = x\n        self.jac_cache = jac\n\n        return jac",
  "class QuasisymmetryRatioResidual(Optimizable):\n    r\"\"\"\n    This class provides a measure of the deviation from quasisymmetry,\n    one that can be computed without Boozer coordinates.  This metric\n    is based on the fact that for quasisymmetry, the ratio\n\n    .. math::\n        (\\vec{B}\\times\\nabla B \\cdot\\nabla\\psi) / (\\vec{B} \\cdot\\nabla B)\n\n    is constant on flux surfaces.\n\n    Specifically, this class represents the objective function\n\n    .. math::\n        f = \\sum_{s_j} w_j \\left< \\left[ \\frac{1}{B^3} \\left( (N - \\iota M)\\vec{B}\\times\\nabla B\\cdot\\nabla\\psi - (MG+NI)\\vec{B}\\cdot\\nabla B \\right) \\right]^2 \\right>\n\n    where the sum is over a set of flux surfaces with normalized\n    toroidal flux :math:`s_j`, the coefficients :math:`w_j` are\n    user-supplied weights, :math:`\\left< \\ldots \\right>` denotes a\n    flux surface average, :math:`G(s)` is :math:`\\mu_0/(2\\pi)` times\n    the poloidal current outside the surface, :math:`I(s)` is\n    :math:`\\mu_0/(2\\pi)` times the toroidal current inside the\n    surface, :math:`\\mu_0` is the permeability of free space,\n    :math:`2\\pi\\psi` is the toroidal flux, and :math:`(M,N)` are\n    user-supplied integers that specify the desired helicity of\n    symmetry. If the magnetic field is quasisymmetric, so\n    :math:`B=B(\\psi,\\chi)` where :math:`\\chi=M\\vartheta - N\\varphi`\n    where :math:`(\\vartheta,\\varphi)` are the poloidal and toroidal\n    Boozer angles, then :math:`\\vec{B}\\times\\nabla B\\cdot\\nabla\\psi\n    \\to -(MG+NI)(\\vec{B}\\cdot\\nabla\\varphi)\\partial B/\\partial \\chi`\n    and :math:`\\vec{B}\\cdot\\nabla B \\to (-N+\\iota\n    M)(\\vec{B}\\cdot\\nabla\\varphi)\\partial B/\\partial \\chi`, implying\n    the metric :math:`f` vanishes. The flux surface average is\n    discretized using a uniform grid in the VMEC poloidal and toroidal\n    angles :math:`(\\theta,\\phi)`. In this case :math:`f` can be\n    written as a finite sum of squares:\n\n    .. math::\n        f = \\sum_{s_j, \\theta_j, \\phi_j} R(s_j, \\theta_k, \\phi_{\\ell})^2\n\n    where the :math:`\\phi_{\\ell}` grid covers a single field period.\n    Here, each residual term is\n\n    .. math::\n        R(\\theta, \\phi) = \\sqrt{w_j \\frac{n_{fp} \\Delta_{\\theta} \\Delta_{\\phi}}{V'}|\\sqrt{g}|}\n        \\frac{1}{B^3} \\left( (N-\\iota M)\\vec{B}\\times\\nabla B\\cdot\\nabla\\psi - (MG+NI)\\vec{B}\\cdot\\nabla B \\right).\n\n    Here, :math:`n_{fp}` is the number of field periods,\n    :math:`\\Delta_{\\theta}` and :math:`\\Delta_{\\phi}` are the spacing\n    of grid points in the poloidal and toroidal angles,\n    :math:`\\sqrt{g} = 1/(\\nabla s\\cdot\\nabla\\theta \\times\n    \\nabla\\phi)` is the Jacobian of the :math:`(s,\\theta,\\phi)`\n    coordinates, and :math:`V' = \\int_0^{2\\pi} d\\theta \\int_0^{2\\pi}d\\phi |\\sqrt{g}| = dV/d\\psi`\n    where :math:`V` is the volume enclosed by a flux surface.\n\n    Args:\n        vmec: A :obj:`simsopt.mhd.vmec.Vmec` object from which the\n          quasisymmetry error will be calculated.\n        surfaces: Value of normalized toroidal flux at which you want the\n          quasisymmetry error evaluated, or a list of values. Each\n          value must be in the interval [0, 1], with 0 corresponding\n          to the magnetic axis and 1 to the VMEC plasma boundary.\n          This parameter corresponds to :math:`s_j` above.\n        helicity_m: Desired poloidal mode number :math:`M` in the magnetic field\n          strength :math:`B`, so\n          :math:`B = B(s, M \\vartheta - n_{fp} \\hat{N} \\varphi)`\n          where :math:`\\vartheta` and :math:`\\varphi` are Boozer angles.\n        helicity_n: Desired toroidal mode number :math:`\\hat{N} = N / n_{fp}` in the magnetic field\n          strength :math:`B`, so\n          :math:`B = B(s, M \\vartheta - n_{fp} \\hat{N} \\varphi)`\n          where :math:`\\vartheta` and :math:`\\varphi` are Boozer angles.\n          Note that the supplied value of ``helicity_n`` will be multiplied by\n          the number of field periods :math:`n_{fp}`, so typically\n          ``helicity_n`` should be +1 or -1 for quasi-helical symmetry.\n        weights: The list of weights :math:`w_j` for each flux surface.\n          If ``None``, a weight of :math:`w_j=1` will be used for\n          all surfaces.\n        ntheta: Number of grid points in :math:`\\theta` used to\n          discretize the flux surface average.\n        nphi: Number of grid points per field period in :math:`\\phi` used to\n          discretize the flux surface average.\n    \"\"\"\n\n    def __init__(self,\n                 vmec: Vmec,\n                 surfaces: Union[float, RealArray],\n                 helicity_m: int = 1,\n                 helicity_n: int = 0,\n                 weights: RealArray = None,\n                 ntheta: int = 63,\n                 nphi: int = 64) -> None:\n\n        self.vmec = vmec\n        #self.depends_on = [\"vmec\"]\n        self.ntheta = ntheta\n        self.nphi = nphi\n        self.helicity_m = helicity_m\n        self.helicity_n = helicity_n\n\n        # Make sure surfaces is a list:\n        try:\n            self.surfaces = list(surfaces)\n        except:\n            self.surfaces = [surfaces]\n\n        if weights is None:\n            self.weights = np.ones(len(self.surfaces))\n        else:\n            self.weights = weights\n        assert len(self.weights) == len(self.surfaces)\n        super().__init__(depends_on=[vmec])\n\n    # def recompute_bell(self, parent=None):\n    #     self.need_to_run_code = True\n\n    def compute(self):\n        \"\"\"\n        Compute the quasisymmetry metric. This function returns an object\n        that contains (as attributes) all the intermediate quantities\n        for the calculation. Users do not need to call this function\n        for optimization; instead the :func:`residuals()` function can be\n        used. However, this function can be useful if users wish to\n        inspect the quantities going into the calculation.\n        \"\"\"\n        vmec = self.vmec\n        vmec.run()\n        if vmec.wout.lasym:\n            raise RuntimeError('Quasisymmetry class cannot yet handle non-stellarator-symmetric configs')\n\n        logger.debug('Evaluating quasisymmetry residuals')\n        ns = len(self.surfaces)\n        ntheta = self.ntheta\n        nphi = self.nphi\n        nfp = vmec.wout.nfp\n        d_psi_d_s = -self.vmec.wout.phi[-1] / (2 * np.pi)\n\n        # First, interpolate in s to get the quantities we need on the surfaces we need.\n        method = 'linear'\n\n        interp = interp1d(vmec.s_half_grid, vmec.wout.iotas[1:], fill_value=\"extrapolate\")\n        iota = interp(self.surfaces)\n\n        interp = interp1d(vmec.s_half_grid, vmec.wout.bvco[1:], fill_value=\"extrapolate\")\n        G = interp(self.surfaces)\n\n        interp = interp1d(vmec.s_half_grid, vmec.wout.buco[1:], fill_value=\"extrapolate\")\n        I = interp(self.surfaces)\n\n        interp = interp1d(vmec.s_half_grid, vmec.wout.gmnc[:, 1:], fill_value=\"extrapolate\")\n        gmnc = interp(self.surfaces)\n\n        interp = interp1d(vmec.s_half_grid, vmec.wout.bmnc[:, 1:], fill_value=\"extrapolate\")\n        bmnc = interp(self.surfaces)\n\n        interp = interp1d(vmec.s_half_grid, vmec.wout.bsubumnc[:, 1:], fill_value=\"extrapolate\")\n        bsubumnc = interp(self.surfaces)\n\n        interp = interp1d(vmec.s_half_grid, vmec.wout.bsubvmnc[:, 1:], fill_value=\"extrapolate\")\n        bsubvmnc = interp(self.surfaces)\n\n        interp = interp1d(vmec.s_half_grid, vmec.wout.bsupumnc[:, 1:], fill_value=\"extrapolate\")\n        bsupumnc = interp(self.surfaces)\n\n        interp = interp1d(vmec.s_half_grid, vmec.wout.bsupvmnc[:, 1:], fill_value=\"extrapolate\")\n        bsupvmnc = interp(self.surfaces)\n\n        theta1d = np.linspace(0, 2 * np.pi, ntheta, endpoint=False)\n        phi1d = np.linspace(0, 2 * np.pi / nfp, nphi, endpoint=False)\n        phi2d, theta2d = np.meshgrid(phi1d, theta1d)\n        phi3d = phi2d.reshape((1, ntheta, nphi))\n        theta3d = theta2d.reshape((1, ntheta, nphi))\n\n        myshape = (ns, ntheta, nphi)\n        modB = np.zeros(myshape)\n        d_B_d_theta = np.zeros(myshape)\n        d_B_d_phi = np.zeros(myshape)\n        sqrtg = np.zeros(myshape)\n        bsubu = np.zeros(myshape)\n        bsubv = np.zeros(myshape)\n        bsupu = np.zeros(myshape)\n        bsupv = np.zeros(myshape)\n        residuals3d = np.zeros(myshape)\n        for jmn in range(len(vmec.wout.xm_nyq)):\n            m = vmec.wout.xm_nyq[jmn]\n            n = vmec.wout.xn_nyq[jmn]\n            angle = m * theta3d - n * phi3d\n            cosangle = np.cos(angle)\n            sinangle = np.sin(angle)\n            modB += np.kron(bmnc[jmn, :].reshape((ns, 1, 1)), cosangle)\n            d_B_d_theta += np.kron(bmnc[jmn, :].reshape((ns, 1, 1)), -m * sinangle)\n            d_B_d_phi += np.kron(bmnc[jmn, :].reshape((ns, 1, 1)), n * sinangle)\n            sqrtg += np.kron(gmnc[jmn, :].reshape((ns, 1, 1)), cosangle)\n            bsubu += np.kron(bsubumnc[jmn, :].reshape((ns, 1, 1)), cosangle)\n            bsubv += np.kron(bsubvmnc[jmn, :].reshape((ns, 1, 1)), cosangle)\n            bsupu += np.kron(bsupumnc[jmn, :].reshape((ns, 1, 1)), cosangle)\n            bsupv += np.kron(bsupvmnc[jmn, :].reshape((ns, 1, 1)), cosangle)\n\n        B_dot_grad_B = bsupu * d_B_d_theta + bsupv * d_B_d_phi\n        B_cross_grad_B_dot_grad_psi = d_psi_d_s * (bsubu * d_B_d_phi - bsubv * d_B_d_theta) / sqrtg\n\n        dtheta = theta1d[1] - theta1d[0]\n        dphi = phi1d[1] - phi1d[0]\n        V_prime = nfp * dtheta * dphi * np.sum(sqrtg, axis=(1, 2))\n        # Check that we can evaluate the flux surface average <1> and the result is 1:\n        assert np.sum(np.abs(np.sqrt((1 / V_prime) * nfp * dtheta * dphi * np.sum(sqrtg, axis=(1, 2))) - 1)) < 1e-12\n\n        nn = self.helicity_n * nfp\n        for js in range(ns):\n            residuals3d[js, :, :] = np.sqrt(self.weights[js] * nfp * dtheta * dphi / V_prime[js] * sqrtg[js, :, :]) \\\n                * (B_cross_grad_B_dot_grad_psi[js, :, :] * (nn - iota[js] * self.helicity_m) \\\n                   - B_dot_grad_B[js, :, :] * (self.helicity_m * G[js] + nn * I[js])) \\\n                / (modB[js, :, :] ** 3)\n\n        residuals1d = residuals3d.reshape((ns * ntheta * nphi,))\n        profile = np.sum(residuals3d * residuals3d, axis=(1, 2))\n        total = np.sum(residuals1d * residuals1d)\n\n        # Form a structure with all the intermediate data as attributes:\n        results = Struct()\n        variables = ['ns', 'ntheta', 'nphi', 'dtheta', 'dphi', 'nfp', 'V_prime', 'theta1d', 'phi1d',\n                     'theta2d', 'phi2d', 'theta3d', 'phi3d', 'd_psi_d_s', 'B_dot_grad_B',\n                     'B_cross_grad_B_dot_grad_psi', 'modB', 'd_B_d_theta', 'd_B_d_phi', 'sqrtg',\n                     'bsubu', 'bsubv', 'bsupu', 'bsupv', 'G', 'I', 'iota',\n                     'residuals3d', 'residuals1d', 'profile', 'total']\n        for v in variables:\n            results.__setattr__(v, eval(v))\n\n        logger.debug('Done evaluating quasisymmetry residuals')\n        return results\n\n    def residuals(self):\n        \"\"\"\n        Evaluate the quasisymmetry metric in terms of a 1D numpy vector of\n        residuals, corresponding to :math:`R` in the documentation\n        for this class. This is the function to use when forming a\n        least-squares objective function.\n        \"\"\"\n        results = self.compute()\n        return results.residuals1d\n\n    def profile(self):\n        \"\"\"\n        Return the quasisymmetry metric in terms of a 1D radial\n        profile. The residuals :math:`R` are squared and summed over\n        theta and phi, but not over s. The total quasisymmetry error\n        :math:`f` returned by the :func:`total()` function is the sum\n        of the values in the profile returned by this function.\n        \"\"\"\n        results = self.compute()\n        return results.profile\n\n    def total(self):\n        \"\"\"\n        Evaluate the quasisymmetry metric in terms of the scalar total\n        :math:`f`.\n        \"\"\"\n        results = self.compute()\n        return results.total",
  "def B_cartesian(vmec,\n                quadpoints_phi=None,\n                quadpoints_theta=None,\n                range=Surface.RANGE_FULL_TORUS,\n                nphi=None,\n                ntheta=None):\n    r\"\"\"\n    Computes Cartesian vector components of the magnetic field on the\n    Vmec boundary.  The results are returned on a grid in the Vmec\n    toroidal and poloidal angles. This routine is required to compute\n    adjoint-based shape gradients and for the virtual casing\n    calculation.\n\n    There are two ways to define the grid points in the poloidal and\n    toroidal angles on which the field is returned.  The default\n    option, if ``quadpoints_phi``, ``quadpoints_theta``, ``nphi``, and\n    ``ntheta`` are all unspecified, is to use the quadrature grid\n    associated with the ``Surface`` object attached to\n    ``vmec.boundary``.  The second option is that you can specify\n    custom ``phi`` and ``theta`` grids using the arguments\n    ``quadpoints_phi``, ``quadpoints_theta``, ``nphi``, ``ntheta``,\n    and ``range``, exactly as when initializing a ``Surface`` object.\n    For more details, see the documentation on :ref:`surfaces`.  Note\n    that both angles go up to 1, not :math:`2\\pi`.\n\n    For now, this routine only works for stellarator symmetry.\n\n    Args:\n        vmec: instance of Vmec\n\n    Returns:\n        Tuple containing ``(Bx, By, Bz)``. Each of these three entries is a\n        2D array of size ``(numquadpoints_phi, numquadpoints_theta)``\n        containing the Cartesian component of the magnetic field on the Vmec boundary surface.\n    \"\"\"\n    vmec.run()\n    nfp = vmec.wout.nfp\n    if vmec.wout.lasym:\n        raise RuntimeError('B_cartesian presently only works for stellarator symmetry')\n\n    if nphi is None and quadpoints_phi is None:\n        phi1D_1 = vmec.boundary.quadpoints_phi\n    elif quadpoints_phi is None:\n        phi1D_1 = Surface.get_phi_quadpoints(range=range, nphi=nphi, nfp=vmec.wout.nfp)\n    else:\n        phi1D_1 = quadpoints_phi\n\n    if ntheta is None and quadpoints_theta is None:\n        theta1D_1 = vmec.boundary.quadpoints_theta\n    elif quadpoints_theta is None:\n        theta1D_1 = Surface.get_theta_quadpoints(ntheta=ntheta)\n    else:\n        theta1D_1 = quadpoints_theta\n\n    theta1D = np.array(theta1D_1) * 2 * np.pi\n    phi1D = np.array(phi1D_1) * 2 * np.pi\n\n    theta, phi = np.meshgrid(theta1D, phi1D)\n\n    # Get the tangent vectors using the gammadash1/2 functions from SurfaceRZFourier:\n    surf = SurfaceRZFourier(mpol=vmec.wout.mpol, ntor=vmec.wout.ntor, nfp=vmec.wout.nfp,\n                            quadpoints_phi=phi1D_1, quadpoints_theta=theta1D_1)\n    for jmn in np.arange(vmec.wout.mnmax):\n        surf.set_rc(int(vmec.wout.xm[jmn]), int(vmec.wout.xn[jmn] / nfp), vmec.wout.rmnc[jmn, -1])\n        surf.set_zs(int(vmec.wout.xm[jmn]), int(vmec.wout.xn[jmn] / nfp), vmec.wout.zmns[jmn, -1])\n    dgamma1 = surf.gammadash1()\n    dgamma2 = surf.gammadash2()\n\n    bsupumnc = 1.5 * vmec.wout.bsupumnc[:, -1] - 0.5 * vmec.wout.bsupumnc[:, -2]\n    bsupvmnc = 1.5 * vmec.wout.bsupvmnc[:, -1] - 0.5 * vmec.wout.bsupvmnc[:, -2]\n    angle = vmec.wout.xm_nyq[:, None, None] * theta[None, :, :] \\\n        - vmec.wout.xn_nyq[:, None, None] * phi[None, :, :]\n    Bsupu = np.sum(bsupumnc[:, None, None] * np.cos(angle), axis=0)\n    Bsupv = np.sum(bsupvmnc[:, None, None] * np.cos(angle), axis=0)\n\n    Bx = (Bsupv * dgamma1[:, :, 0] + Bsupu * dgamma2[:, :, 0])/(2*np.pi)\n    By = (Bsupv * dgamma1[:, :, 1] + Bsupu * dgamma2[:, :, 1])/(2*np.pi)\n    Bz = (Bsupv * dgamma1[:, :, 2] + Bsupu * dgamma2[:, :, 2])/(2*np.pi)\n\n    return Bx, By, Bz",
  "class IotaTargetMetric(Optimizable):\n    r\"\"\"\n    IotaTargetMetric is a class that computes a metric quantifying the\n    deviation of the rotational transform :math:`\\iota` in from a\n    prescribed target profile in a Vmec equilibrium:\n\n    .. math::\n        J = \\frac{1}{2} \\int ds \\, (\\iota - \\iota_{target})^2\n\n    where the integral is over the normalized toroidal flux :math:`s`,\n    and the function :math:`\\iota_{target}(s)` corresponds to the\n    argument ``iota_target``. This class also can compute the\n    derivatives of :math:`J` using an adjoint method.\n\n    Args:\n        vmec : instance of Vmec\n        iota_target : function handle which takes a single argument, s,\n            the normalized toroidal flux, and returns the target rotational\n            transform.\n        adjoint_epsilon : sets the amplitude of the toroidal\n            current perturbation required for the adjoint solve.\n    \"\"\"\n\n    def __init__(self, vmec, iota_target, adjoint_epsilon=1.e-1):\n        self.vmec = vmec\n        self.boundary = vmec.boundary\n        self.iota_target = iota_target\n        self.adjoint_epsilon = adjoint_epsilon\n        super().__init__(depends_on=[vmec])\n\n    def J(self):\n        \"\"\"\n        Computes the quantity :math:`J` described in the class definition.\n        \"\"\"\n        # if self.vmec.runnable:\n        #     self.vmec.need_to_run_code = True\n        self.vmec.run()\n        return 0.5 * np.sum((self.vmec.wout.iotas[1::]\n                             - self.iota_target(self.vmec.s_half_grid))**2) * self.vmec.ds\n\n    def dJ(self):\n        \"\"\"\n        Computes derivatives of :math:`J` with respect to surface\n        parameters using an adjoint method.\n        \"\"\"\n        if self.vmec.indata.ncurr != 1:\n            raise RuntimeError('''dJ cannot be computed without\n                running vmec with ncurr = 1''')\n\n        shape_gradient = self.shape_gradient()\n        return parameter_derivatives(self.vmec.boundary, shape_gradient)\n\n    def shape_gradient(self):\n        r\"\"\"\n        Computes the shape gradient of the quantity :math:`J` described in\n        the class definition.  For a perturbation to the surface\n        :math:`\\delta \\vec{x}`, the resulting perturbation to the\n        objective function is\n\n        .. math::\n          \\delta J(\\delta \\vec{x}) = \\int d^2 x \\, G \\delta \\vec{x} \\cdot \\vec{n}\n\n        where the integral is over the VMEC boundary surface,\n        :math:`G` is the shape gradient, and :math:`\\vec{n}` is the\n        unit normal.\n\n        Returns:\n            :math:`G` : 2d array of size (numquadpoints_phi,numquadpoints_theta)\n        \"\"\"\n        vmec = self.vmec\n        vmec.run()\n\n        Bx0, By0, Bz0 = B_cartesian(vmec)\n\n        mu0 = 4*np.pi*1e-7\n        It_half = vmec.wout.signgs * 2*np.pi * vmec.wout.bsubumnc[0, 1::] / mu0\n        ac_aux_f_prev = np.copy(vmec.indata.ac_aux_f)\n        ac_aux_s_prev = np.copy(vmec.indata.ac_aux_s)\n        pcurr_type_prev = np.copy(vmec.indata.pcurr_type)\n        curtor_prev = np.copy(vmec.indata.curtor)\n\n        perturbation = (vmec.wout.iotas[1::]-self.iota_target(vmec.s_half_grid)) \\\n            / (vmec.wout.phi[-1]*vmec.wout.signgs/(2*np.pi))\n\n        # Perturbed toroidal current profile\n        It_new = It_half + self.adjoint_epsilon*perturbation\n        curtor = 1.5*It_new[-1] - 0.5*It_new[-2]\n        vmec.indata.ac_aux_f = -1.*np.ones_like(vmec.indata.ac_aux_f)\n        vmec.indata.ac_aux_s = -1.*np.ones_like(vmec.indata.ac_aux_s)\n        vmec.indata.ac_aux_f[0:vmec.wout.ns-1] = It_new\n        vmec.indata.ac_aux_s[0:vmec.wout.ns-1] = vmec.s_half_grid\n        vmec.indata.curtor = curtor\n        vmec.indata.pcurr_type = b'line_segment_I'\n        vmec.need_to_run_code = True\n\n        vmec.run()\n\n        It_half = vmec.wout.signgs * 2*np.pi * vmec.wout.bsubumnc[0, 1::] / mu0\n\n        Bx, By, Bz = B_cartesian(vmec)\n\n        # Reset input values\n        vmec.indata.ac_aux_f = ac_aux_f_prev\n        vmec.indata.ac_aux_s = ac_aux_s_prev\n        vmec.indata.pcurr_type = pcurr_type_prev\n        vmec.indata.curtor = curtor_prev\n        vmec.need_to_run_code = True\n\n        deltaB_dot_B = ((Bx-Bx0)*Bx0 + (By-By0)*By0 + (Bz-Bz0)*Bz0)/self.adjoint_epsilon\n\n        return deltaB_dot_B/(2*np.pi*mu0)",
  "class IotaWeighted(Optimizable):\n    r\"\"\"\n    Computes a weighted average of the rotational transform for a VMEC\n    configuration.  The quantity computed is defined by\n\n    .. math::\n        J = \\frac{ \\int ds \\, \\iota(s) w(s)}\n                 { \\int ds \\, w(s)}\n\n    where :math:`w(s)` is a prescribed weight function, corresponding\n    to the argument ``weight_function``. This class also can compute the\n    derivatives of :math:`J` using an adjoint method.\n\n    Args:\n        vmec : instance of Vmec\n        weight_function : function handle which takes a single argument, s,\n            the normalized toroidal flux\n        adjoint_epsilon : sets the amplitude of the toroidal\n            current perturbation required for the adjoint solve.\n    \"\"\"\n\n    def __init__(self, vmec, weight_function, adjoint_epsilon=1.e-1):\n        self.vmec = vmec\n        self.boundary = vmec.boundary\n        self.weight_function = weight_function\n        self.adjoint_epsilon = adjoint_epsilon\n        super().__init__(depends_on=[vmec])\n\n    def J(self):\n        \"\"\"\n        Computes the quantity :math:`J` described in the class definition.\n        \"\"\"\n        vmec = self.vmec\n        vmec.run()\n        return np.sum(self.weight_function(vmec.s_half_grid) * vmec.wout.iotas[1:]) \\\n            / np.sum(self.weight_function(vmec.s_half_grid))\n\n    def dJ(self):\n        \"\"\"\n        Computes derivatives of :math:`J` with respect to surface\n        parameters using an adjoint method.\n        \"\"\"\n        if self.vmec.indata.ncurr != 1:\n            raise RuntimeError('''dJ cannot be computed without\n                running vmec with ncurr = 1''')\n\n        shape_gradient = self.shape_gradient()\n        return parameter_derivatives(self.vmec.boundary, shape_gradient)\n\n    def shape_gradient(self):\n        r\"\"\"\n        Computes the shape gradient of the quantity :math:`J` described in\n        the class definition.  For a perturbation to the surface\n        :math:`\\delta \\vec{x}`, the resulting perturbation to the\n        objective function is\n\n        .. math::\n          \\delta J(\\delta \\vec{x}) = \\int d^2 x \\, G \\delta \\vec{x} \\cdot \\vec{n}\n\n        where the integral is over the VMEC boundary surface,\n        :math:`G` is the shape gradient, and :math:`\\vec{n}` is the\n        unit normal.\n\n        Returns:\n            :math:`G` : 2d array of size (numquadpoints_phi,numquadpoints_theta)\n        \"\"\"\n        vmec = self.vmec\n        vmec.run()\n\n        Bx0, By0, Bz0 = B_cartesian(vmec)\n\n        mu0 = 4*np.pi*1e-7\n        It_half = vmec.wout.signgs * 2*np.pi * vmec.wout.bsubumnc[0, 1::] / mu0\n        ac_aux_f_prev = np.copy(vmec.indata.ac_aux_f)\n        ac_aux_s_prev = np.copy(vmec.indata.ac_aux_s)\n        pcurr_type_prev = np.copy(vmec.indata.pcurr_type)\n        curtor_prev = np.copy(vmec.indata.curtor)\n\n        perturbation = self.weight_function(vmec.s_half_grid)\n\n        # Perturbed toroidal current profile\n        It_new = It_half + self.adjoint_epsilon*perturbation\n        curtor = 1.5*It_new[-1] - 0.5*It_new[-2]\n        vmec.indata.ac_aux_f = -1.*np.ones_like(vmec.indata.ac_aux_f)\n        vmec.indata.ac_aux_s = -1.*np.ones_like(vmec.indata.ac_aux_s)\n        vmec.indata.ac_aux_f[0:vmec.wout.ns-1] = It_new\n        vmec.indata.ac_aux_s[0:vmec.wout.ns-1] = vmec.s_half_grid\n        vmec.indata.curtor = curtor\n        vmec.indata.pcurr_type = b'line_segment_I'\n        vmec.need_to_run_code = True\n\n        vmec.run()\n\n        It_half = vmec.wout.signgs * 2*np.pi * vmec.wout.bsubumnc[0, 1::] / mu0\n\n        Bx, By, Bz = B_cartesian(vmec)\n\n        # Reset input values\n        vmec.indata.ac_aux_f = ac_aux_f_prev\n        vmec.indata.ac_aux_s = ac_aux_s_prev\n        vmec.indata.pcurr_type = pcurr_type_prev\n        vmec.indata.curtor = curtor_prev\n        vmec.need_to_run_code = True\n\n        deltaB_dot_B = ((Bx-Bx0)*Bx0 + (By-By0)*By0 + (Bz-Bz0)*Bz0)/self.adjoint_epsilon\n\n        return deltaB_dot_B/(mu0*vmec.ds*vmec.wout.phi[-1]*vmec.wout.signgs*np.sum(self.weight_function(vmec.s_half_grid)))",
  "class WellWeighted(Optimizable):\n    r\"\"\"\n    WellWeighted is a class that computes a measure of magnetic well\n    for a vmec equilibrium. The magnetic well measure is\n\n    .. math::\n        J = \\frac{ \\int ds \\, V'(s) [w_1(s) - w_2(s)]}\n            { \\int ds \\, V'(s) [w_1(s) + w_2(s)]},\n\n    where :math:`w_1(s)` and :math:`w_2(s)` correspond to the\n    arguments ``weight_function1`` and ``weight_function2``, and\n    :math:`V(s)` is the volume enclosed by the flux surface with\n    normalized toroidal flux :math:`s`.  Typically, :math:`w_1` would\n    be peaked on the edge while :math:`w_2` would be peaked on the\n    axis, such that :math:`J < 0` corresonds to :math:`V''(s) < 0`,\n    which is favorable for stability.\n\n    This class also provides calculations of the derivatives of\n    :math:`J` using an adjoint method.\n\n    Args:\n        vmec : instance of Vmec\n        weight_function1 : function handle which takes a single argument, s,\n            the normalized toroidal flux\n        weight_function2 : function handle which takes a single argument, s,\n            the normalized toroidal flux\n        adjoint_epsilon : sets the amplitude of the toroidal\n            current perturbation required for the adjoint solve.\n    \"\"\"\n\n    def __init__(self, vmec, weight_function1, weight_function2, adjoint_epsilon=1.e-1):\n        self.vmec = vmec\n        self.boundary = vmec.boundary\n        self.weight_function1 = weight_function1\n        self.weight_function2 = weight_function2\n        self.adjoint_epsilon = adjoint_epsilon\n        # self.depends_on = [\"boundary\"]\n        super().__init__(depends_on=[vmec])\n\n    def J(self):\n        \"\"\"\n        Computes the quantity :math:`J` described in the class definition.\n        \"\"\"\n        vmec = self.vmec\n        vmec.run()\n        return np.sum((self.weight_function1(vmec.s_half_grid)-self.weight_function2(vmec.s_half_grid)) * vmec.wout.vp[1:]) \\\n            / np.sum((self.weight_function1(vmec.s_half_grid)+self.weight_function2(vmec.s_half_grid)) * vmec.wout.vp[1:])\n\n    def dJ(self):\n        \"\"\"\n        Computes derivatives of :math:`J` with respect to surface\n        parameters using an adjoint method.\n        \"\"\"\n\n        self.vmec.need_to_run_code = True\n        shape_gradient = self.shape_gradient()\n        return parameter_derivatives(self.vmec.boundary, shape_gradient)\n\n    def shape_gradient(self):\n        r\"\"\"\n        Computes the shape gradient of the quantity :math:`J` described in\n        the class definition.  For a perturbation to the surface\n        :math:`\\delta \\vec{x}`, the resulting perturbation to the\n        objective function is\n\n        .. math::\n          \\delta J(\\delta \\vec{x}) = \\int d^2 x \\, G \\delta \\vec{x} \\cdot \\vec{n}\n\n        where the integral is over the VMEC boundary surface,\n        :math:`G` is the shape gradient, and :math:`\\vec{n}` is the\n        unit normal.\n\n        Returns:\n            :math:`G` : 2d array of size (numquadpoints_phi,numquadpoints_theta)\n        \"\"\"\n        vmec = self.vmec\n        vmec.run()\n\n        Bx0, By0, Bz0 = B_cartesian(self.vmec)\n\n        mu0 = 4*np.pi*1e-7\n        am_aux_f_prev = np.copy(vmec.indata.am_aux_f)\n        am_aux_s_prev = np.copy(vmec.indata.am_aux_s)\n        pmass_type_prev = np.copy(vmec.indata.pmass_type)\n\n        pres = vmec.wout.pres[1::]\n        weight1 = self.weight_function1(vmec.s_half_grid) - self.weight_function2(vmec.s_half_grid)\n        weight2 = self.weight_function1(vmec.s_half_grid) + self.weight_function2(vmec.s_half_grid)\n        numerator = np.sum(weight1 * vmec.wout.vp[1::])\n        denominator = np.sum(weight2 * vmec.wout.vp[1::])\n        fW = numerator/denominator\n        perturbation = (weight1 - fW * weight2) / (denominator * vmec.ds * 4 * np.pi * np.pi)\n\n        # Perturbed pressure profile\n        pres_new = pres + self.adjoint_epsilon*perturbation\n\n        vmec.indata.am_aux_f = -1.*np.ones_like(vmec.indata.am_aux_f)\n        vmec.indata.am_aux_s = -1.*np.ones_like(vmec.indata.am_aux_s)\n        vmec.indata.am_aux_f[0:vmec.wout.ns-1] = pres_new\n        vmec.indata.am_aux_s[0:vmec.wout.ns-1] = vmec.s_half_grid\n        vmec.indata.pmass_type = b'cubic_spline'\n        vmec.need_to_run_code = True\n\n        vmec.run()\n\n        Bx, By, Bz = B_cartesian(self.vmec)\n\n        # Reset input values\n        vmec.indata.am_aux_f = am_aux_f_prev\n        vmec.indata.am_aux_s = am_aux_s_prev\n        vmec.indata.pmass_type = pmass_type_prev\n        vmec.need_to_run_code = True\n\n        deltaB_dot_B = ((Bx-Bx0)*Bx0 + (By-By0)*By0 + (Bz-Bz0)*Bz0)/self.adjoint_epsilon\n\n        return deltaB_dot_B/(mu0) + perturbation[-1]",
  "def vmec_splines(vmec):\n    \"\"\"\n    Initialize radial splines for a VMEC equilibrium.\n\n    Args:\n        vmec: An instance of :obj:`simsopt.mhd.vmec.Vmec`.\n\n    Returns:\n        A structure with the splines as attributes.\n    \"\"\"\n    vmec.run()\n    results = Struct()\n    if vmec.wout.lasym:\n        raise ValueError(\"vmec_splines is not yet set up for non-stellarator-symmetric cases.\")\n\n    rmnc = []\n    zmns = []\n    lmns = []\n    d_rmnc_d_s = []\n    d_zmns_d_s = []\n    d_lmns_d_s = []\n    for jmn in range(vmec.wout.mnmax):\n        rmnc.append(InterpolatedUnivariateSpline(vmec.s_full_grid, vmec.wout.rmnc[jmn, :]))\n        zmns.append(InterpolatedUnivariateSpline(vmec.s_full_grid, vmec.wout.zmns[jmn, :]))\n        lmns.append(InterpolatedUnivariateSpline(vmec.s_half_grid, vmec.wout.lmns[jmn, 1:]))\n        d_rmnc_d_s.append(rmnc[-1].derivative())\n        d_zmns_d_s.append(zmns[-1].derivative())\n        d_lmns_d_s.append(lmns[-1].derivative())\n\n    gmnc = []\n    bmnc = []\n    bsupumnc = []\n    bsupvmnc = []\n    bsubsmns = []\n    bsubumnc = []\n    bsubvmnc = []\n    d_bmnc_d_s = []\n    d_bsupumnc_d_s = []\n    d_bsupvmnc_d_s = []\n    for jmn in range(vmec.wout.mnmax_nyq):\n        gmnc.append(InterpolatedUnivariateSpline(vmec.s_half_grid, vmec.wout.gmnc[jmn, 1:]))\n        bmnc.append(InterpolatedUnivariateSpline(vmec.s_half_grid, vmec.wout.bmnc[jmn, 1:]))\n        bsupumnc.append(InterpolatedUnivariateSpline(vmec.s_half_grid, vmec.wout.bsupumnc[jmn, 1:]))\n        bsupvmnc.append(InterpolatedUnivariateSpline(vmec.s_half_grid, vmec.wout.bsupvmnc[jmn, 1:]))\n        # Note that bsubsmns is on the full mesh, unlike the other components:\n        bsubsmns.append(InterpolatedUnivariateSpline(vmec.s_full_grid, vmec.wout.bsubsmns[jmn, :]))\n        bsubumnc.append(InterpolatedUnivariateSpline(vmec.s_half_grid, vmec.wout.bsubumnc[jmn, 1:]))\n        bsubvmnc.append(InterpolatedUnivariateSpline(vmec.s_half_grid, vmec.wout.bsubvmnc[jmn, 1:]))\n        d_bmnc_d_s.append(bmnc[-1].derivative())\n        d_bsupumnc_d_s.append(bsupumnc[-1].derivative())\n        d_bsupvmnc_d_s.append(bsupvmnc[-1].derivative())\n\n    # Handle 1d profiles:\n    results.pressure = InterpolatedUnivariateSpline(vmec.s_half_grid, vmec.wout.pres[1:])\n    results.d_pressure_d_s = results.pressure.derivative()\n    results.iota = InterpolatedUnivariateSpline(vmec.s_half_grid, vmec.wout.iotas[1:])\n    results.d_iota_d_s = results.iota.derivative()\n\n    # Save other useful quantities:\n    results.phiedge = vmec.wout.phi[-1]\n    variables = ['Aminor_p', 'mnmax', 'xm', 'xn', 'mnmax_nyq', 'xm_nyq', 'xn_nyq', 'nfp']\n    for v in variables:\n        results.__setattr__(v, eval('vmec.wout.' + v))\n\n    variables = ['rmnc', 'zmns', 'lmns', 'd_rmnc_d_s', 'd_zmns_d_s', 'd_lmns_d_s',\n                 'gmnc', 'bmnc', 'd_bmnc_d_s', 'bsupumnc', 'bsupvmnc', 'd_bsupumnc_d_s', 'd_bsupvmnc_d_s',\n                 'bsubsmns', 'bsubumnc', 'bsubvmnc']\n    for v in variables:\n        results.__setattr__(v, eval(v))\n\n    return results",
  "def vmec_compute_geometry(vs, s, theta, phi, phi_center=0):\n    r\"\"\"\n    Compute many geometric quantities of interest from a vmec configuration.\n\n    Some of the quantities computed by this function refer to\n    ``alpha``, a field line label coordinate defined by\n\n    .. math::\n\n        \\alpha = \\theta_{pest} - \\iota (\\phi - \\phi_{center}).\n\n    Here, :math:`\\phi_{center}` is a constant, usually 0, which can be\n    set to a nonzero value if desired so the magnetic shear\n    contribution to :math:`\\nabla\\alpha` vanishes at a toroidal angle\n    different than 0.  Also, wherever the term ``psi`` appears in\n    variable names in this function and the returned arrays, it means\n    :math:`\\psi =` the toroidal flux divided by :math:`2\\pi`, so\n\n    .. math::\n\n        \\vec{B} = \\nabla\\psi\\times\\nabla\\theta_{pest} + \\iota\\nabla\\phi\\times\\nabla\\psi = \\nabla\\psi\\times\\nabla\\alpha.\n\n    Most of the arrays that are returned by this function have shape\n    ``(ns, ntheta, nphi)``, where ``ns`` is the number of flux\n    surfaces, ``ntheta`` is the number of grid points in VMEC's\n    poloidal angle, and ``nphi`` is the number of grid points in the\n    standard toroidal angle. For the arguments ``theta`` and ``phi``,\n    you can either provide 1D arrays, in which case a tensor product\n    grid is used, or you can provide 3D arrays of shape ``(ns, ntheta,\n    nphi)``. In this latter case, the grids are not necessarily\n    tensor-product grids.  Note that all angles in this function have\n    period :math:`2\\pi`, not period 1.\n\n    The output arrays are returned as attributes of the\n    returned object. Many intermediate quantities are included, such\n    as the Cartesian components of the covariant and contravariant\n    basis vectors. Some of the most useful of these output arrays are (all with SI units):\n\n    - ``phi``: The standard toroidal angle :math:`\\phi`.\n    - ``theta_vmec``: VMEC's poloidal angle :math:`\\theta_{vmec}`.\n    - ``theta_pest``: The straight-field-line angle :math:`\\theta_{pest}` associated with :math:`\\phi`.\n    - ``modB``: The magnetic field magnitude :math:`|B|`.\n    - ``B_sup_theta_vmec``: :math:`\\vec{B}\\cdot\\nabla\\theta_{vmec}`.\n    - ``B_sup_phi``: :math:`\\vec{B}\\cdot\\nabla\\phi`.\n    - ``B_cross_grad_B_dot_grad_alpha``: :math:`\\vec{B}\\times\\nabla|B|\\cdot\\nabla\\alpha`.\n    - ``B_cross_grad_B_dot_grad_psi``: :math:`\\vec{B}\\times\\nabla|B|\\cdot\\nabla\\psi`.\n    - ``B_cross_kappa_dot_grad_alpha``: :math:`\\vec{B}\\times\\vec{\\kappa}\\cdot\\nabla\\alpha`,\n      where :math:`\\vec{\\kappa}=\\vec{b}\\cdot\\nabla\\vec{b}` is the curvature and :math:`\\vec{b}=|B|^{-1}\\vec{B}`.\n    - ``B_cross_kappa_dot_grad_psi``: :math:`\\vec{B}\\times\\vec{\\kappa}\\cdot\\nabla\\psi`.\n    - ``grad_alpha_dot_grad_alpha``: :math:`|\\nabla\\alpha|^2 = \\nabla\\alpha\\cdot\\nabla\\alpha`.\n    - ``grad_alpha_dot_grad_psi``: :math:`\\nabla\\alpha\\cdot\\nabla\\psi`.\n    - ``grad_psi_dot_grad_psi``: :math:`|\\nabla\\psi|^2 = \\nabla\\psi\\cdot\\nabla\\psi`.\n    - ``iota``: The rotational transform :math:`\\iota`. This array has shape ``(ns,)``.\n    - ``shat``: The magnetic shear :math:`\\hat s= (x/q) (d q / d x)` where \n      :math:`x = \\mathrm{Aminor_p} \\, \\sqrt{s}` and :math:`q=1/\\iota`. This array has shape ``(ns,)``.\n\n    The following normalized versions of these quantities used in the\n    gyrokinetic codes ``stella``, ``gs2``, and ``GX`` are also\n    returned: ``bmag``, ``gbdrift``, ``gbdrift0``, ``cvdrift``,\n    ``cvdrift0``, ``gds2``, ``gds21``, and ``gds22``, along with\n    ``L_reference`` and ``B_reference``.  Instead of ``gradpar``, two\n    variants are returned, ``gradpar_theta_pest`` and ``gradpar_phi``,\n    corresponding to choosing either :math:`\\theta_{pest}` or\n    :math:`\\phi` as the parallel coordinate.\n\n    The value(s) of ``s`` provided as input need not coincide with the\n    full grid or half grid in VMEC, as spline interpolation will be\n    used radially.\n\n    The implementation in this routine is similar to the one in the\n    gyrokinetic code ``stella``.\n\n    Example usage::\n\n        import numpy as np\n        from simsopt.mhd import Vmec, vmec_compute_geometry\n\n        v = Vmec(\"wout_li383_1.4m.nc\")\n        s = 1\n        theta = np.linspace(0, 2 * np.pi, 50)\n        phi = np.linspace(0, 2 * np.pi / 3, 60)\n        data = vmec_compute_geometry(v, s, theta, phi)\n        print(data.grad_s_dot_grad_s)\n\n    Args:\n        vs: Either an instance of :obj:`simsopt.mhd.vmec.Vmec`\n          or the structure returned by :func:`vmec_splines`.\n        s: Values of normalized toroidal flux on which to construct the field lines.\n          You can give a single number, or a list or numpy array.\n        theta: Values of vmec's poloidal angle. You can provide a float, a 1d array of size\n          ``(ntheta,)``, or a 3d array of size ``(ns, ntheta, nphi)``.\n        phi: Values of the standard toroidal angle. You can provide a float, a 1d array of size\n          ``(nphi,)`` or a 3d array of size ``(ns, ntheta, nphi)``.\n        phi_center: :math:`\\phi_{center}`, an optional shift to the toroidal angle\n          in the definition of :math:`\\alpha`.\n    \"\"\"\n    # If given a Vmec object, convert it to vmec_splines:\n    if isinstance(vs, Vmec):\n        vs = vmec_splines(vs)\n\n    # Make sure s is an array:\n    try:\n        ns = len(s)\n    except:\n        s = [s]\n    s = np.array(s)\n    ns = len(s)\n\n    # Handle theta\n    try:\n        ntheta = len(theta)\n    except:\n        theta = [theta]\n    theta_vmec = np.array(theta)\n    if theta_vmec.ndim == 1:\n        ntheta = len(theta_vmec)\n    elif theta_vmec.ndim == 3:\n        ntheta = theta_vmec.shape[1]\n    else:\n        raise ValueError(\"theta argument must be a float, 1d array, or 3d array.\")\n\n    # Handle phi\n    try:\n        nphi = len(phi)\n    except:\n        phi = [phi]\n    phi = np.array(phi)\n    if phi.ndim == 1:\n        nphi = len(phi)\n    elif phi.ndim == 3:\n        nphi = phi.shape[2]\n    else:\n        raise ValueError(\"phi argument must be a float, 1d array, or 3d array.\")\n\n    # If theta and phi are not already 3D, make them 3D:\n    if theta_vmec.ndim == 1:\n        theta_vmec = np.kron(np.ones((ns, 1, nphi)), theta_vmec.reshape(1, ntheta, 1))\n    if phi.ndim == 1:\n        phi = np.kron(np.ones((ns, ntheta, 1)), phi.reshape(1, 1, nphi))\n\n    # Shorthand:\n    mnmax = vs.mnmax\n    xm = vs.xm\n    xn = vs.xn\n    mnmax_nyq = vs.mnmax_nyq\n    xm_nyq = vs.xm_nyq\n    xn_nyq = vs.xn_nyq\n\n    # Now that we have an s grid, evaluate everything on that grid:\n    d_pressure_d_s = vs.d_pressure_d_s(s)\n    iota = vs.iota(s)\n    d_iota_d_s = vs.d_iota_d_s(s)\n    # shat = (r/q)(dq/dr) where r = a sqrt(s)\n    #      = - (r/iota) (d iota / d r) = -2 (s/iota) (d iota / d s)\n    shat = (-2 * s / iota) * d_iota_d_s\n\n    rmnc = np.zeros((ns, mnmax))\n    zmns = np.zeros((ns, mnmax))\n    lmns = np.zeros((ns, mnmax))\n    d_rmnc_d_s = np.zeros((ns, mnmax))\n    d_zmns_d_s = np.zeros((ns, mnmax))\n    d_lmns_d_s = np.zeros((ns, mnmax))\n    for jmn in range(mnmax):\n        rmnc[:, jmn] = vs.rmnc[jmn](s)\n        zmns[:, jmn] = vs.zmns[jmn](s)\n        lmns[:, jmn] = vs.lmns[jmn](s)\n        d_rmnc_d_s[:, jmn] = vs.d_rmnc_d_s[jmn](s)\n        d_zmns_d_s[:, jmn] = vs.d_zmns_d_s[jmn](s)\n        d_lmns_d_s[:, jmn] = vs.d_lmns_d_s[jmn](s)\n\n    gmnc = np.zeros((ns, mnmax_nyq))\n    bmnc = np.zeros((ns, mnmax_nyq))\n    d_bmnc_d_s = np.zeros((ns, mnmax_nyq))\n    bsupumnc = np.zeros((ns, mnmax_nyq))\n    bsupvmnc = np.zeros((ns, mnmax_nyq))\n    bsubsmns = np.zeros((ns, mnmax_nyq))\n    bsubumnc = np.zeros((ns, mnmax_nyq))\n    bsubvmnc = np.zeros((ns, mnmax_nyq))\n    for jmn in range(mnmax_nyq):\n        gmnc[:, jmn] = vs.gmnc[jmn](s)\n        bmnc[:, jmn] = vs.bmnc[jmn](s)\n        d_bmnc_d_s[:, jmn] = vs.d_bmnc_d_s[jmn](s)\n        bsupumnc[:, jmn] = vs.bsupumnc[jmn](s)\n        bsupvmnc[:, jmn] = vs.bsupvmnc[jmn](s)\n        bsubsmns[:, jmn] = vs.bsubsmns[jmn](s)\n        bsubumnc[:, jmn] = vs.bsubumnc[jmn](s)\n        bsubvmnc[:, jmn] = vs.bsubvmnc[jmn](s)\n\n    # Now that we know theta_vmec, compute all the geometric quantities\n    angle = xm[:, None, None, None] * theta_vmec[None, :, :, :] - xn[:, None, None, None] * phi[None, :, :, :]\n    cosangle = np.cos(angle)\n    sinangle = np.sin(angle)\n    mcosangle = xm[:, None, None, None] * cosangle\n    ncosangle = xn[:, None, None, None] * cosangle\n    msinangle = xm[:, None, None, None] * sinangle\n    nsinangle = xn[:, None, None, None] * sinangle\n    # Order of indices in cosangle and sinangle: mn, s, theta, phi\n    # Order of indices in rmnc, bmnc, etc: s, mn\n    R = np.einsum('ij,jikl->ikl', rmnc, cosangle)\n    d_R_d_s = np.einsum('ij,jikl->ikl', d_rmnc_d_s, cosangle)\n    d_R_d_theta_vmec = -np.einsum('ij,jikl->ikl', rmnc, msinangle)\n    d_R_d_phi = np.einsum('ij,jikl->ikl', rmnc, nsinangle)\n\n    Z = np.einsum('ij,jikl->ikl', zmns, sinangle)\n    d_Z_d_s = np.einsum('ij,jikl->ikl', d_zmns_d_s, sinangle)\n    d_Z_d_theta_vmec = np.einsum('ij,jikl->ikl', zmns, mcosangle)\n    d_Z_d_phi = -np.einsum('ij,jikl->ikl', zmns, ncosangle)\n\n    lambd = np.einsum('ij,jikl->ikl', lmns, sinangle)\n    d_lambda_d_s = np.einsum('ij,jikl->ikl', d_lmns_d_s, sinangle)\n    d_lambda_d_theta_vmec = np.einsum('ij,jikl->ikl', lmns, mcosangle)\n    d_lambda_d_phi = -np.einsum('ij,jikl->ikl', lmns, ncosangle)\n    theta_pest = theta_vmec + lambd\n\n    # Now handle the Nyquist quantities:\n    angle = xm_nyq[:, None, None, None] * theta_vmec[None, :, :, :] - xn_nyq[:, None, None, None] * phi[None, :, :, :]\n    cosangle = np.cos(angle)\n    sinangle = np.sin(angle)\n    mcosangle = xm_nyq[:, None, None, None] * cosangle\n    ncosangle = xn_nyq[:, None, None, None] * cosangle\n    msinangle = xm_nyq[:, None, None, None] * sinangle\n    nsinangle = xn_nyq[:, None, None, None] * sinangle\n\n    sqrt_g_vmec = np.einsum('ij,jikl->ikl', gmnc, cosangle)\n    modB = np.einsum('ij,jikl->ikl', bmnc, cosangle)\n    d_B_d_s = np.einsum('ij,jikl->ikl', d_bmnc_d_s, cosangle)\n    d_B_d_theta_vmec = -np.einsum('ij,jikl->ikl', bmnc, msinangle)\n    d_B_d_phi = np.einsum('ij,jikl->ikl', bmnc, nsinangle)\n\n    B_sup_theta_vmec = np.einsum('ij,jikl->ikl', bsupumnc, cosangle)\n    B_sup_phi = np.einsum('ij,jikl->ikl', bsupvmnc, cosangle)\n    B_sub_s = np.einsum('ij,jikl->ikl', bsubsmns, sinangle)\n    B_sub_theta_vmec = np.einsum('ij,jikl->ikl', bsubumnc, cosangle)\n    B_sub_phi = np.einsum('ij,jikl->ikl', bsubvmnc, cosangle)\n    B_sup_theta_pest = iota[:, None, None] * B_sup_phi\n\n    sqrt_g_vmec_alt = R * (d_Z_d_s * d_R_d_theta_vmec - d_R_d_s * d_Z_d_theta_vmec)\n\n    # Note the minus sign. psi in the straight-field-line relation seems to have opposite sign to vmec's phi array.\n    edge_toroidal_flux_over_2pi = -vs.phiedge / (2 * np.pi)\n\n    # *********************************************************************\n    # Using R(theta,phi) and Z(theta,phi), compute the Cartesian\n    # components of the gradient basis vectors using the dual relations:\n    # *********************************************************************\n    sinphi = np.sin(phi)\n    cosphi = np.cos(phi)\n    X = R * cosphi\n    d_X_d_theta_vmec = d_R_d_theta_vmec * cosphi\n    d_X_d_phi = d_R_d_phi * cosphi - R * sinphi\n    d_X_d_s = d_R_d_s * cosphi\n    Y = R * sinphi\n    d_Y_d_theta_vmec = d_R_d_theta_vmec * sinphi\n    d_Y_d_phi = d_R_d_phi * sinphi + R * cosphi\n    d_Y_d_s = d_R_d_s * sinphi\n\n    # Now use the dual relations to get the Cartesian components of grad s, grad theta_vmec, and grad phi:\n    grad_s_X = (d_Y_d_theta_vmec * d_Z_d_phi - d_Z_d_theta_vmec * d_Y_d_phi) / sqrt_g_vmec\n    grad_s_Y = (d_Z_d_theta_vmec * d_X_d_phi - d_X_d_theta_vmec * d_Z_d_phi) / sqrt_g_vmec\n    grad_s_Z = (d_X_d_theta_vmec * d_Y_d_phi - d_Y_d_theta_vmec * d_X_d_phi) / sqrt_g_vmec\n\n    grad_theta_vmec_X = (d_Y_d_phi * d_Z_d_s - d_Z_d_phi * d_Y_d_s) / sqrt_g_vmec\n    grad_theta_vmec_Y = (d_Z_d_phi * d_X_d_s - d_X_d_phi * d_Z_d_s) / sqrt_g_vmec\n    grad_theta_vmec_Z = (d_X_d_phi * d_Y_d_s - d_Y_d_phi * d_X_d_s) / sqrt_g_vmec\n\n    grad_phi_X = (d_Y_d_s * d_Z_d_theta_vmec - d_Z_d_s * d_Y_d_theta_vmec) / sqrt_g_vmec\n    grad_phi_Y = (d_Z_d_s * d_X_d_theta_vmec - d_X_d_s * d_Z_d_theta_vmec) / sqrt_g_vmec\n    grad_phi_Z = (d_X_d_s * d_Y_d_theta_vmec - d_Y_d_s * d_X_d_theta_vmec) / sqrt_g_vmec\n    # End of dual relations.\n\n    # *********************************************************************\n    # Compute the Cartesian components of other quantities we need:\n    # *********************************************************************\n\n    grad_psi_X = grad_s_X * edge_toroidal_flux_over_2pi\n    grad_psi_Y = grad_s_Y * edge_toroidal_flux_over_2pi\n    grad_psi_Z = grad_s_Z * edge_toroidal_flux_over_2pi\n\n    # Form grad alpha = grad (theta_vmec + lambda - iota * phi)\n    grad_alpha_X = (d_lambda_d_s - (phi - phi_center) * d_iota_d_s[:, None, None]) * grad_s_X\n    grad_alpha_Y = (d_lambda_d_s - (phi - phi_center) * d_iota_d_s[:, None, None]) * grad_s_Y\n    grad_alpha_Z = (d_lambda_d_s - (phi - phi_center) * d_iota_d_s[:, None, None]) * grad_s_Z\n\n    grad_alpha_X += (1 + d_lambda_d_theta_vmec) * grad_theta_vmec_X + (-iota[:, None, None] + d_lambda_d_phi) * grad_phi_X\n    grad_alpha_Y += (1 + d_lambda_d_theta_vmec) * grad_theta_vmec_Y + (-iota[:, None, None] + d_lambda_d_phi) * grad_phi_Y\n    grad_alpha_Z += (1 + d_lambda_d_theta_vmec) * grad_theta_vmec_Z + (-iota[:, None, None] + d_lambda_d_phi) * grad_phi_Z\n\n    grad_B_X = d_B_d_s * grad_s_X + d_B_d_theta_vmec * grad_theta_vmec_X + d_B_d_phi * grad_phi_X\n    grad_B_Y = d_B_d_s * grad_s_Y + d_B_d_theta_vmec * grad_theta_vmec_Y + d_B_d_phi * grad_phi_Y\n    grad_B_Z = d_B_d_s * grad_s_Z + d_B_d_theta_vmec * grad_theta_vmec_Z + d_B_d_phi * grad_phi_Z\n\n    B_X = edge_toroidal_flux_over_2pi * ((1 + d_lambda_d_theta_vmec) * d_X_d_phi + (iota[:, None, None] - d_lambda_d_phi) * d_X_d_theta_vmec) / sqrt_g_vmec\n    B_Y = edge_toroidal_flux_over_2pi * ((1 + d_lambda_d_theta_vmec) * d_Y_d_phi + (iota[:, None, None] - d_lambda_d_phi) * d_Y_d_theta_vmec) / sqrt_g_vmec\n    B_Z = edge_toroidal_flux_over_2pi * ((1 + d_lambda_d_theta_vmec) * d_Z_d_phi + (iota[:, None, None] - d_lambda_d_phi) * d_Z_d_theta_vmec) / sqrt_g_vmec\n\n    # *********************************************************************\n    # For gbdrift, we need \\vect{B} cross grad |B| dot grad alpha.\n    # For cvdrift, we also need \\vect{B} cross grad s dot grad alpha.\n    # Let us compute both of these quantities 2 ways, and make sure the two\n    # approaches give the same answer (within some tolerance).\n    # *********************************************************************\n\n    B_cross_grad_s_dot_grad_alpha = (B_sub_phi * (1 + d_lambda_d_theta_vmec) \\\n                                     - B_sub_theta_vmec * (d_lambda_d_phi - iota[:, None, None])) / sqrt_g_vmec\n\n    B_cross_grad_s_dot_grad_alpha_alternate = 0 \\\n        + B_X * grad_s_Y * grad_alpha_Z \\\n        + B_Y * grad_s_Z * grad_alpha_X \\\n        + B_Z * grad_s_X * grad_alpha_Y \\\n        - B_Z * grad_s_Y * grad_alpha_X \\\n        - B_X * grad_s_Z * grad_alpha_Y \\\n        - B_Y * grad_s_X * grad_alpha_Z\n\n    B_cross_grad_B_dot_grad_alpha = 0 \\\n        + (B_sub_s * d_B_d_theta_vmec * (d_lambda_d_phi - iota[:, None, None]) \\\n           + B_sub_theta_vmec * d_B_d_phi * (d_lambda_d_s - (phi - phi_center) * d_iota_d_s[:, None, None]) \\\n           + B_sub_phi * d_B_d_s * (1 + d_lambda_d_theta_vmec) \\\n           - B_sub_phi * d_B_d_theta_vmec * (d_lambda_d_s - (phi - phi_center) * d_iota_d_s[:, None, None]) \\\n           - B_sub_theta_vmec * d_B_d_s * (d_lambda_d_phi - iota[:, None, None]) \\\n           - B_sub_s * d_B_d_phi * (1 + d_lambda_d_theta_vmec)) / sqrt_g_vmec\n\n    B_cross_grad_B_dot_grad_alpha_alternate = 0 \\\n        + B_X * grad_B_Y * grad_alpha_Z \\\n        + B_Y * grad_B_Z * grad_alpha_X \\\n        + B_Z * grad_B_X * grad_alpha_Y \\\n        - B_Z * grad_B_Y * grad_alpha_X \\\n        - B_X * grad_B_Z * grad_alpha_Y \\\n        - B_Y * grad_B_X * grad_alpha_Z\n\n    grad_alpha_dot_grad_alpha = grad_alpha_X * grad_alpha_X + grad_alpha_Y * grad_alpha_Y + grad_alpha_Z * grad_alpha_Z\n\n    grad_alpha_dot_grad_psi = grad_alpha_X * grad_psi_X + grad_alpha_Y * grad_psi_Y + grad_alpha_Z * grad_psi_Z\n\n    grad_psi_dot_grad_psi = grad_psi_X * grad_psi_X + grad_psi_Y * grad_psi_Y + grad_psi_Z * grad_psi_Z\n\n    grad_s_dot_grad_s = grad_s_X * grad_s_X + grad_s_Y * grad_s_Y + grad_s_Z * grad_s_Z\n\n    B_cross_grad_B_dot_grad_psi = (B_sub_theta_vmec * d_B_d_phi - B_sub_phi * d_B_d_theta_vmec) / sqrt_g_vmec * edge_toroidal_flux_over_2pi\n\n    B_cross_kappa_dot_grad_psi = B_cross_grad_B_dot_grad_psi / modB\n\n    mu_0 = 4 * np.pi * (1.0e-7)\n    B_cross_kappa_dot_grad_alpha = B_cross_grad_B_dot_grad_alpha / modB + mu_0 * d_pressure_d_s[:, None, None] / edge_toroidal_flux_over_2pi\n\n    # stella / gs2 / gx quantities:\n\n    L_reference = vs.Aminor_p\n    B_reference = 2 * abs(edge_toroidal_flux_over_2pi) / (L_reference * L_reference)\n    toroidal_flux_sign = np.sign(edge_toroidal_flux_over_2pi)\n    sqrt_s = np.sqrt(s)\n\n    bmag = modB / B_reference\n\n    gradpar_theta_pest = L_reference * B_sup_theta_pest / modB\n\n    gradpar_phi = L_reference * B_sup_phi / modB\n\n    gds2 = grad_alpha_dot_grad_alpha * L_reference * L_reference * s[:, None, None]\n\n    gds21 = grad_alpha_dot_grad_psi * shat[:, None, None] / B_reference\n\n    gds22 = grad_psi_dot_grad_psi * shat[:, None, None] * shat[:, None, None] / (L_reference * L_reference * B_reference * B_reference * s[:, None, None])\n\n    # temporary fix. Please see issue #238 and the discussion therein\n    gbdrift = -1 * 2 * B_reference * L_reference * L_reference * sqrt_s[:, None, None] * B_cross_grad_B_dot_grad_alpha / (modB * modB * modB) * toroidal_flux_sign\n\n    gbdrift0 = B_cross_grad_B_dot_grad_psi * 2 * shat[:, None, None] / (modB * modB * modB * sqrt_s[:, None, None]) * toroidal_flux_sign\n\n    # temporary fix. Please see issue #238 and the discussion therein\n    cvdrift = gbdrift - 2 * B_reference * L_reference * L_reference * sqrt_s[:, None, None] * mu_0 * d_pressure_d_s[:, None, None] * toroidal_flux_sign / (edge_toroidal_flux_over_2pi * modB * modB)\n\n    cvdrift0 = gbdrift0\n\n    # Package results into a structure to return:\n    results = Struct()\n    variables = ['ns', 'ntheta', 'nphi', 's', 'iota', 'd_iota_d_s', 'd_pressure_d_s', 'shat',\n                 'theta_vmec', 'phi', 'theta_pest',\n                 'd_lambda_d_s', 'd_lambda_d_theta_vmec', 'd_lambda_d_phi', 'sqrt_g_vmec', 'sqrt_g_vmec_alt',\n                 'modB', 'd_B_d_s', 'd_B_d_theta_vmec', 'd_B_d_phi', 'B_sup_theta_vmec', 'B_sup_theta_pest', 'B_sup_phi',\n                 'B_sub_s', 'B_sub_theta_vmec', 'B_sub_phi', 'edge_toroidal_flux_over_2pi', 'sinphi', 'cosphi',\n                 'R', 'd_R_d_s', 'd_R_d_theta_vmec', 'd_R_d_phi', 'X', 'Y', 'Z', 'd_Z_d_s', 'd_Z_d_theta_vmec', 'd_Z_d_phi',\n                 'd_X_d_theta_vmec', 'd_X_d_phi', 'd_X_d_s', 'd_Y_d_theta_vmec', 'd_Y_d_phi', 'd_Y_d_s',\n                 'grad_s_X', 'grad_s_Y', 'grad_s_Z', 'grad_theta_vmec_X', 'grad_theta_vmec_Y', 'grad_theta_vmec_Z',\n                 'grad_phi_X', 'grad_phi_Y', 'grad_phi_Z', 'grad_psi_X', 'grad_psi_Y', 'grad_psi_Z',\n                 'grad_alpha_X', 'grad_alpha_Y', 'grad_alpha_Z', 'grad_B_X', 'grad_B_Y', 'grad_B_Z',\n                 'B_X', 'B_Y', 'B_Z', \"grad_s_dot_grad_s\",\n                 'B_cross_grad_s_dot_grad_alpha', 'B_cross_grad_s_dot_grad_alpha_alternate',\n                 'B_cross_grad_B_dot_grad_alpha', 'B_cross_grad_B_dot_grad_alpha_alternate',\n                 'B_cross_grad_B_dot_grad_psi', 'B_cross_kappa_dot_grad_psi', 'B_cross_kappa_dot_grad_alpha',\n                 'grad_alpha_dot_grad_alpha', 'grad_alpha_dot_grad_psi', 'grad_psi_dot_grad_psi',\n                 'L_reference', 'B_reference', 'toroidal_flux_sign',\n                 'bmag', 'gradpar_theta_pest', 'gradpar_phi', 'gds2', 'gds21', 'gds22', 'gbdrift', 'gbdrift0', 'cvdrift', 'cvdrift0']\n    for v in variables:\n        results.__setattr__(v, eval(v))\n\n    return results",
  "def vmec_fieldlines(vs, s, alpha, theta1d=None, phi1d=None, phi_center=0, plot=False, show=True):\n    r\"\"\"\n    Compute field lines in a vmec configuration, and compute many\n    geometric quantities of interest along the field lines. In\n    particular, this routine computes the geometric quantities that\n    enter the gyrokinetic equation.\n\n    One task performed by this function is to convert between\n    the poloidal angles :math:`\\theta_{vmec}` and\n    :math:`\\theta_{pest}`. The latter is the angle in which the field\n    lines are straight when used in combination with the standard\n    toroidal angle :math:`\\phi`. Note that all angles in this function\n    have period :math:`2\\pi`, not period 1.\n\n    To specify the parallel extent of the field lines, you can provide\n    either a grid of :math:`\\theta_{pest}` values or a grid of\n    :math:`\\phi` values. If you specify both or neither, ``ValueError``\n    will be raised.\n\n    The geometric quanties computed by this function are the same as for\n    :func:`vmec_compute_geometry()`. See the documentation of that\n    function for details.\n\n    Most of the arrays that are returned by this function have shape\n    ``(ns, nalpha, nl)``, where ``ns`` is the number of flux surfaces,\n    ``nalpha`` is the number of field lines on each flux surface, and\n    ``nl`` is the number of grid points along each field line. In\n    other words, ``ns`` is the size of the input ``s`` array,\n    ``nalpha`` is the size of the input ``alpha`` array, and ``nl`` is\n    the size of the input ``theta1d`` or ``phi1d`` array. The output\n    arrays are returned as attributes of the returned object.\n\n    The value(s) of ``s`` provided as input need not coincide with the\n    full grid or half grid in VMEC, as spline interpolation will be\n    used radially.\n\n    Example usage::\n\n        import numpy as np\n        from simsopt.mhd import Vmec, vmec_fieldlines\n\n        v = Vmec('wout_li383_1.4m.nc')\n        theta = np.linspace(-np.pi, np.pi, 50)\n        fl = vmec_fieldlines(v, 0.5, 0, theta1d=theta)\n        print(fl.B_cross_grad_B_dot_grad_alpha)\n\n    Args:\n        vs: Either an instance of :obj:`simsopt.mhd.vmec.Vmec`\n          or the structure returned by :func:`vmec_splines`.\n        s: Values of normalized toroidal flux on which to construct the field lines.\n          You can give a single number, or a list or numpy array.\n        alpha: Values of the field line label :math:`\\alpha` on which to construct the field lines.\n          You can give a single number, or a list or numpy array.\n        theta1d: 1D array of :math:`\\theta_{pest}` values, setting the grid points\n          along the field line and the parallel extent of the field line.\n        phi1d: 1D array of :math:`\\phi` values, setting the grid points along the\n          field line and the parallel extent of the field line.\n        phi_center: :math:`\\phi_{center}`, an optional shift to the toroidal angle\n          in the definition of :math:`\\alpha`.\n        plot: Whether to create a plot of the main geometric quantities. Only one field line will\n          be plotted, corresponding to the leading elements of ``s`` and ``alpha``.\n        show: Only matters if ``plot==True``. Whether to call matplotlib's ``show()`` function\n          after creating the plot.\n    \"\"\"\n    # If given a Vmec object, convert it to vmec_splines:\n    if isinstance(vs, Vmec):\n        vs = vmec_splines(vs)\n\n    # Make sure s is an array:\n    try:\n        ns = len(s)\n    except:\n        s = [s]\n    s = np.array(s)\n    ns = len(s)\n\n    # Make sure alpha is an array\n    try:\n        nalpha = len(alpha)\n    except:\n        alpha = [alpha]\n    alpha = np.array(alpha)\n    nalpha = len(alpha)\n\n    if (theta1d is not None) and (phi1d is not None):\n        raise ValueError('You cannot specify both theta and phi')\n    if (theta1d is None) and (phi1d is None):\n        raise ValueError('You must specify either theta or phi')\n    if theta1d is None:\n        nl = len(phi1d)\n    else:\n        nl = len(theta1d)\n\n    # Shorthand:\n    mnmax = vs.mnmax\n    xm = vs.xm\n    xn = vs.xn\n    mnmax_nyq = vs.mnmax_nyq\n    xm_nyq = vs.xm_nyq\n    xn_nyq = vs.xn_nyq\n\n    # Now that we have an s grid, evaluate everything on that grid:\n    iota = vs.iota(s)\n    lmns = np.zeros((ns, mnmax))\n    for jmn in range(mnmax):\n        lmns[:, jmn] = vs.lmns[jmn](s)\n\n    theta_pest = np.zeros((ns, nalpha, nl))\n    phi = np.zeros((ns, nalpha, nl))\n\n    if theta1d is None:\n        # We are given phi. Compute theta_pest:\n        for js in range(ns):\n            phi[js, :, :] = phi1d[None, :]\n            theta_pest[js, :, :] = alpha[:, None] + iota[js] * (phi1d[None, :] - phi_center)\n    else:\n        # We are given theta_pest. Compute phi:\n        for js in range(ns):\n            theta_pest[js, :, :] = theta1d[None, :]\n            phi[js, :, :] = phi_center + (theta1d[None, :] - alpha[:, None]) / iota[js]\n\n    def residual(theta_v, phi0, theta_p_target, jradius):\n        \"\"\"\n        This function is used for computing an array of values of theta_vmec that\n        give a desired theta_pest array.\n        \"\"\"\n        return theta_p_target - (theta_v + np.sum(lmns[jradius, :, None] * np.sin(xm[:, None] * theta_v - xn[:, None] * phi0), axis=0))\n\n    theta_vmec = np.zeros((ns, nalpha, nl))\n    for js in range(ns):\n        for jalpha in range(nalpha):\n            theta_guess = theta_pest[js, jalpha, :]\n            solution = newton(\n                residual,\n                x0=theta_guess,\n                x1=theta_guess + 0.1,\n                args=(phi[js, jalpha, :], theta_pest[js, jalpha, :], js),\n            )\n            theta_vmec[js, jalpha, :] = solution\n\n    # Now that we have theta_vmec, compute all the geometric quantities:\n    results = vmec_compute_geometry(vs, s, theta_vmec, phi, phi_center)\n\n    # Add a few more quantities to the results:\n    variables = [\"nalpha\", \"nl\", \"alpha\", \"theta1d\", \"phi1d\"]\n    for v in variables:\n        results.__setattr__(v, eval(v))\n\n    if plot:\n        import matplotlib.pyplot as plt\n        plt.figure(figsize=(13, 7))\n        nrows = 4\n        ncols = 5\n        variables = ['modB', 'B_sup_theta_pest', 'B_sup_phi', 'B_cross_grad_B_dot_grad_alpha', 'B_cross_grad_B_dot_grad_psi',\n                     'B_cross_kappa_dot_grad_alpha', 'B_cross_kappa_dot_grad_psi',\n                     'grad_alpha_dot_grad_alpha', 'grad_alpha_dot_grad_psi', 'grad_psi_dot_grad_psi',\n                     'bmag', 'gradpar_theta_pest', 'gradpar_phi', 'gbdrift', 'gbdrift0', 'cvdrift', 'cvdrift0', 'gds2', 'gds21', 'gds22']\n        for j, variable in enumerate(variables):\n            plt.subplot(nrows, ncols, j + 1)\n            plt.plot(phi[0, 0, :], eval(\"results.\" + variable + '[0, 0, :]'))\n            plt.xlabel('Standard toroidal angle $\\phi$')\n            plt.title(variable)\n\n        plt.figtext(0.5, 0.995, f's={s[0]}, alpha={alpha[0]}', ha='center', va='top')\n        plt.tight_layout()\n        if show:\n            plt.show()\n\n    return results",
  "def __init__(self,\n                 vmec: Vmec,\n                 surfaces: Union[float, RealArray],\n                 helicity_m: int = 1,\n                 helicity_n: int = 0,\n                 weights: RealArray = None,\n                 ntheta: int = 63,\n                 nphi: int = 64) -> None:\n\n        self.vmec = vmec\n        #self.depends_on = [\"vmec\"]\n        self.ntheta = ntheta\n        self.nphi = nphi\n        self.helicity_m = helicity_m\n        self.helicity_n = helicity_n\n\n        # Make sure surfaces is a list:\n        try:\n            self.surfaces = list(surfaces)\n        except:\n            self.surfaces = [surfaces]\n\n        if weights is None:\n            self.weights = np.ones(len(self.surfaces))\n        else:\n            self.weights = weights\n        assert len(self.weights) == len(self.surfaces)\n        super().__init__(depends_on=[vmec])",
  "def compute(self):\n        \"\"\"\n        Compute the quasisymmetry metric. This function returns an object\n        that contains (as attributes) all the intermediate quantities\n        for the calculation. Users do not need to call this function\n        for optimization; instead the :func:`residuals()` function can be\n        used. However, this function can be useful if users wish to\n        inspect the quantities going into the calculation.\n        \"\"\"\n        vmec = self.vmec\n        vmec.run()\n        if vmec.wout.lasym:\n            raise RuntimeError('Quasisymmetry class cannot yet handle non-stellarator-symmetric configs')\n\n        logger.debug('Evaluating quasisymmetry residuals')\n        ns = len(self.surfaces)\n        ntheta = self.ntheta\n        nphi = self.nphi\n        nfp = vmec.wout.nfp\n        d_psi_d_s = -self.vmec.wout.phi[-1] / (2 * np.pi)\n\n        # First, interpolate in s to get the quantities we need on the surfaces we need.\n        method = 'linear'\n\n        interp = interp1d(vmec.s_half_grid, vmec.wout.iotas[1:], fill_value=\"extrapolate\")\n        iota = interp(self.surfaces)\n\n        interp = interp1d(vmec.s_half_grid, vmec.wout.bvco[1:], fill_value=\"extrapolate\")\n        G = interp(self.surfaces)\n\n        interp = interp1d(vmec.s_half_grid, vmec.wout.buco[1:], fill_value=\"extrapolate\")\n        I = interp(self.surfaces)\n\n        interp = interp1d(vmec.s_half_grid, vmec.wout.gmnc[:, 1:], fill_value=\"extrapolate\")\n        gmnc = interp(self.surfaces)\n\n        interp = interp1d(vmec.s_half_grid, vmec.wout.bmnc[:, 1:], fill_value=\"extrapolate\")\n        bmnc = interp(self.surfaces)\n\n        interp = interp1d(vmec.s_half_grid, vmec.wout.bsubumnc[:, 1:], fill_value=\"extrapolate\")\n        bsubumnc = interp(self.surfaces)\n\n        interp = interp1d(vmec.s_half_grid, vmec.wout.bsubvmnc[:, 1:], fill_value=\"extrapolate\")\n        bsubvmnc = interp(self.surfaces)\n\n        interp = interp1d(vmec.s_half_grid, vmec.wout.bsupumnc[:, 1:], fill_value=\"extrapolate\")\n        bsupumnc = interp(self.surfaces)\n\n        interp = interp1d(vmec.s_half_grid, vmec.wout.bsupvmnc[:, 1:], fill_value=\"extrapolate\")\n        bsupvmnc = interp(self.surfaces)\n\n        theta1d = np.linspace(0, 2 * np.pi, ntheta, endpoint=False)\n        phi1d = np.linspace(0, 2 * np.pi / nfp, nphi, endpoint=False)\n        phi2d, theta2d = np.meshgrid(phi1d, theta1d)\n        phi3d = phi2d.reshape((1, ntheta, nphi))\n        theta3d = theta2d.reshape((1, ntheta, nphi))\n\n        myshape = (ns, ntheta, nphi)\n        modB = np.zeros(myshape)\n        d_B_d_theta = np.zeros(myshape)\n        d_B_d_phi = np.zeros(myshape)\n        sqrtg = np.zeros(myshape)\n        bsubu = np.zeros(myshape)\n        bsubv = np.zeros(myshape)\n        bsupu = np.zeros(myshape)\n        bsupv = np.zeros(myshape)\n        residuals3d = np.zeros(myshape)\n        for jmn in range(len(vmec.wout.xm_nyq)):\n            m = vmec.wout.xm_nyq[jmn]\n            n = vmec.wout.xn_nyq[jmn]\n            angle = m * theta3d - n * phi3d\n            cosangle = np.cos(angle)\n            sinangle = np.sin(angle)\n            modB += np.kron(bmnc[jmn, :].reshape((ns, 1, 1)), cosangle)\n            d_B_d_theta += np.kron(bmnc[jmn, :].reshape((ns, 1, 1)), -m * sinangle)\n            d_B_d_phi += np.kron(bmnc[jmn, :].reshape((ns, 1, 1)), n * sinangle)\n            sqrtg += np.kron(gmnc[jmn, :].reshape((ns, 1, 1)), cosangle)\n            bsubu += np.kron(bsubumnc[jmn, :].reshape((ns, 1, 1)), cosangle)\n            bsubv += np.kron(bsubvmnc[jmn, :].reshape((ns, 1, 1)), cosangle)\n            bsupu += np.kron(bsupumnc[jmn, :].reshape((ns, 1, 1)), cosangle)\n            bsupv += np.kron(bsupvmnc[jmn, :].reshape((ns, 1, 1)), cosangle)\n\n        B_dot_grad_B = bsupu * d_B_d_theta + bsupv * d_B_d_phi\n        B_cross_grad_B_dot_grad_psi = d_psi_d_s * (bsubu * d_B_d_phi - bsubv * d_B_d_theta) / sqrtg\n\n        dtheta = theta1d[1] - theta1d[0]\n        dphi = phi1d[1] - phi1d[0]\n        V_prime = nfp * dtheta * dphi * np.sum(sqrtg, axis=(1, 2))\n        # Check that we can evaluate the flux surface average <1> and the result is 1:\n        assert np.sum(np.abs(np.sqrt((1 / V_prime) * nfp * dtheta * dphi * np.sum(sqrtg, axis=(1, 2))) - 1)) < 1e-12\n\n        nn = self.helicity_n * nfp\n        for js in range(ns):\n            residuals3d[js, :, :] = np.sqrt(self.weights[js] * nfp * dtheta * dphi / V_prime[js] * sqrtg[js, :, :]) \\\n                * (B_cross_grad_B_dot_grad_psi[js, :, :] * (nn - iota[js] * self.helicity_m) \\\n                   - B_dot_grad_B[js, :, :] * (self.helicity_m * G[js] + nn * I[js])) \\\n                / (modB[js, :, :] ** 3)\n\n        residuals1d = residuals3d.reshape((ns * ntheta * nphi,))\n        profile = np.sum(residuals3d * residuals3d, axis=(1, 2))\n        total = np.sum(residuals1d * residuals1d)\n\n        # Form a structure with all the intermediate data as attributes:\n        results = Struct()\n        variables = ['ns', 'ntheta', 'nphi', 'dtheta', 'dphi', 'nfp', 'V_prime', 'theta1d', 'phi1d',\n                     'theta2d', 'phi2d', 'theta3d', 'phi3d', 'd_psi_d_s', 'B_dot_grad_B',\n                     'B_cross_grad_B_dot_grad_psi', 'modB', 'd_B_d_theta', 'd_B_d_phi', 'sqrtg',\n                     'bsubu', 'bsubv', 'bsupu', 'bsupv', 'G', 'I', 'iota',\n                     'residuals3d', 'residuals1d', 'profile', 'total']\n        for v in variables:\n            results.__setattr__(v, eval(v))\n\n        logger.debug('Done evaluating quasisymmetry residuals')\n        return results",
  "def residuals(self):\n        \"\"\"\n        Evaluate the quasisymmetry metric in terms of a 1D numpy vector of\n        residuals, corresponding to :math:`R` in the documentation\n        for this class. This is the function to use when forming a\n        least-squares objective function.\n        \"\"\"\n        results = self.compute()\n        return results.residuals1d",
  "def profile(self):\n        \"\"\"\n        Return the quasisymmetry metric in terms of a 1D radial\n        profile. The residuals :math:`R` are squared and summed over\n        theta and phi, but not over s. The total quasisymmetry error\n        :math:`f` returned by the :func:`total()` function is the sum\n        of the values in the profile returned by this function.\n        \"\"\"\n        results = self.compute()\n        return results.profile",
  "def total(self):\n        \"\"\"\n        Evaluate the quasisymmetry metric in terms of the scalar total\n        :math:`f`.\n        \"\"\"\n        results = self.compute()\n        return results.total",
  "def __init__(self, vmec, iota_target, adjoint_epsilon=1.e-1):\n        self.vmec = vmec\n        self.boundary = vmec.boundary\n        self.iota_target = iota_target\n        self.adjoint_epsilon = adjoint_epsilon\n        super().__init__(depends_on=[vmec])",
  "def J(self):\n        \"\"\"\n        Computes the quantity :math:`J` described in the class definition.\n        \"\"\"\n        # if self.vmec.runnable:\n        #     self.vmec.need_to_run_code = True\n        self.vmec.run()\n        return 0.5 * np.sum((self.vmec.wout.iotas[1::]\n                             - self.iota_target(self.vmec.s_half_grid))**2) * self.vmec.ds",
  "def dJ(self):\n        \"\"\"\n        Computes derivatives of :math:`J` with respect to surface\n        parameters using an adjoint method.\n        \"\"\"\n        if self.vmec.indata.ncurr != 1:\n            raise RuntimeError('''dJ cannot be computed without\n                running vmec with ncurr = 1''')\n\n        shape_gradient = self.shape_gradient()\n        return parameter_derivatives(self.vmec.boundary, shape_gradient)",
  "def shape_gradient(self):\n        r\"\"\"\n        Computes the shape gradient of the quantity :math:`J` described in\n        the class definition.  For a perturbation to the surface\n        :math:`\\delta \\vec{x}`, the resulting perturbation to the\n        objective function is\n\n        .. math::\n          \\delta J(\\delta \\vec{x}) = \\int d^2 x \\, G \\delta \\vec{x} \\cdot \\vec{n}\n\n        where the integral is over the VMEC boundary surface,\n        :math:`G` is the shape gradient, and :math:`\\vec{n}` is the\n        unit normal.\n\n        Returns:\n            :math:`G` : 2d array of size (numquadpoints_phi,numquadpoints_theta)\n        \"\"\"\n        vmec = self.vmec\n        vmec.run()\n\n        Bx0, By0, Bz0 = B_cartesian(vmec)\n\n        mu0 = 4*np.pi*1e-7\n        It_half = vmec.wout.signgs * 2*np.pi * vmec.wout.bsubumnc[0, 1::] / mu0\n        ac_aux_f_prev = np.copy(vmec.indata.ac_aux_f)\n        ac_aux_s_prev = np.copy(vmec.indata.ac_aux_s)\n        pcurr_type_prev = np.copy(vmec.indata.pcurr_type)\n        curtor_prev = np.copy(vmec.indata.curtor)\n\n        perturbation = (vmec.wout.iotas[1::]-self.iota_target(vmec.s_half_grid)) \\\n            / (vmec.wout.phi[-1]*vmec.wout.signgs/(2*np.pi))\n\n        # Perturbed toroidal current profile\n        It_new = It_half + self.adjoint_epsilon*perturbation\n        curtor = 1.5*It_new[-1] - 0.5*It_new[-2]\n        vmec.indata.ac_aux_f = -1.*np.ones_like(vmec.indata.ac_aux_f)\n        vmec.indata.ac_aux_s = -1.*np.ones_like(vmec.indata.ac_aux_s)\n        vmec.indata.ac_aux_f[0:vmec.wout.ns-1] = It_new\n        vmec.indata.ac_aux_s[0:vmec.wout.ns-1] = vmec.s_half_grid\n        vmec.indata.curtor = curtor\n        vmec.indata.pcurr_type = b'line_segment_I'\n        vmec.need_to_run_code = True\n\n        vmec.run()\n\n        It_half = vmec.wout.signgs * 2*np.pi * vmec.wout.bsubumnc[0, 1::] / mu0\n\n        Bx, By, Bz = B_cartesian(vmec)\n\n        # Reset input values\n        vmec.indata.ac_aux_f = ac_aux_f_prev\n        vmec.indata.ac_aux_s = ac_aux_s_prev\n        vmec.indata.pcurr_type = pcurr_type_prev\n        vmec.indata.curtor = curtor_prev\n        vmec.need_to_run_code = True\n\n        deltaB_dot_B = ((Bx-Bx0)*Bx0 + (By-By0)*By0 + (Bz-Bz0)*Bz0)/self.adjoint_epsilon\n\n        return deltaB_dot_B/(2*np.pi*mu0)",
  "def __init__(self, vmec, weight_function, adjoint_epsilon=1.e-1):\n        self.vmec = vmec\n        self.boundary = vmec.boundary\n        self.weight_function = weight_function\n        self.adjoint_epsilon = adjoint_epsilon\n        super().__init__(depends_on=[vmec])",
  "def J(self):\n        \"\"\"\n        Computes the quantity :math:`J` described in the class definition.\n        \"\"\"\n        vmec = self.vmec\n        vmec.run()\n        return np.sum(self.weight_function(vmec.s_half_grid) * vmec.wout.iotas[1:]) \\\n            / np.sum(self.weight_function(vmec.s_half_grid))",
  "def dJ(self):\n        \"\"\"\n        Computes derivatives of :math:`J` with respect to surface\n        parameters using an adjoint method.\n        \"\"\"\n        if self.vmec.indata.ncurr != 1:\n            raise RuntimeError('''dJ cannot be computed without\n                running vmec with ncurr = 1''')\n\n        shape_gradient = self.shape_gradient()\n        return parameter_derivatives(self.vmec.boundary, shape_gradient)",
  "def shape_gradient(self):\n        r\"\"\"\n        Computes the shape gradient of the quantity :math:`J` described in\n        the class definition.  For a perturbation to the surface\n        :math:`\\delta \\vec{x}`, the resulting perturbation to the\n        objective function is\n\n        .. math::\n          \\delta J(\\delta \\vec{x}) = \\int d^2 x \\, G \\delta \\vec{x} \\cdot \\vec{n}\n\n        where the integral is over the VMEC boundary surface,\n        :math:`G` is the shape gradient, and :math:`\\vec{n}` is the\n        unit normal.\n\n        Returns:\n            :math:`G` : 2d array of size (numquadpoints_phi,numquadpoints_theta)\n        \"\"\"\n        vmec = self.vmec\n        vmec.run()\n\n        Bx0, By0, Bz0 = B_cartesian(vmec)\n\n        mu0 = 4*np.pi*1e-7\n        It_half = vmec.wout.signgs * 2*np.pi * vmec.wout.bsubumnc[0, 1::] / mu0\n        ac_aux_f_prev = np.copy(vmec.indata.ac_aux_f)\n        ac_aux_s_prev = np.copy(vmec.indata.ac_aux_s)\n        pcurr_type_prev = np.copy(vmec.indata.pcurr_type)\n        curtor_prev = np.copy(vmec.indata.curtor)\n\n        perturbation = self.weight_function(vmec.s_half_grid)\n\n        # Perturbed toroidal current profile\n        It_new = It_half + self.adjoint_epsilon*perturbation\n        curtor = 1.5*It_new[-1] - 0.5*It_new[-2]\n        vmec.indata.ac_aux_f = -1.*np.ones_like(vmec.indata.ac_aux_f)\n        vmec.indata.ac_aux_s = -1.*np.ones_like(vmec.indata.ac_aux_s)\n        vmec.indata.ac_aux_f[0:vmec.wout.ns-1] = It_new\n        vmec.indata.ac_aux_s[0:vmec.wout.ns-1] = vmec.s_half_grid\n        vmec.indata.curtor = curtor\n        vmec.indata.pcurr_type = b'line_segment_I'\n        vmec.need_to_run_code = True\n\n        vmec.run()\n\n        It_half = vmec.wout.signgs * 2*np.pi * vmec.wout.bsubumnc[0, 1::] / mu0\n\n        Bx, By, Bz = B_cartesian(vmec)\n\n        # Reset input values\n        vmec.indata.ac_aux_f = ac_aux_f_prev\n        vmec.indata.ac_aux_s = ac_aux_s_prev\n        vmec.indata.pcurr_type = pcurr_type_prev\n        vmec.indata.curtor = curtor_prev\n        vmec.need_to_run_code = True\n\n        deltaB_dot_B = ((Bx-Bx0)*Bx0 + (By-By0)*By0 + (Bz-Bz0)*Bz0)/self.adjoint_epsilon\n\n        return deltaB_dot_B/(mu0*vmec.ds*vmec.wout.phi[-1]*vmec.wout.signgs*np.sum(self.weight_function(vmec.s_half_grid)))",
  "def __init__(self, vmec, weight_function1, weight_function2, adjoint_epsilon=1.e-1):\n        self.vmec = vmec\n        self.boundary = vmec.boundary\n        self.weight_function1 = weight_function1\n        self.weight_function2 = weight_function2\n        self.adjoint_epsilon = adjoint_epsilon\n        # self.depends_on = [\"boundary\"]\n        super().__init__(depends_on=[vmec])",
  "def J(self):\n        \"\"\"\n        Computes the quantity :math:`J` described in the class definition.\n        \"\"\"\n        vmec = self.vmec\n        vmec.run()\n        return np.sum((self.weight_function1(vmec.s_half_grid)-self.weight_function2(vmec.s_half_grid)) * vmec.wout.vp[1:]) \\\n            / np.sum((self.weight_function1(vmec.s_half_grid)+self.weight_function2(vmec.s_half_grid)) * vmec.wout.vp[1:])",
  "def dJ(self):\n        \"\"\"\n        Computes derivatives of :math:`J` with respect to surface\n        parameters using an adjoint method.\n        \"\"\"\n\n        self.vmec.need_to_run_code = True\n        shape_gradient = self.shape_gradient()\n        return parameter_derivatives(self.vmec.boundary, shape_gradient)",
  "def shape_gradient(self):\n        r\"\"\"\n        Computes the shape gradient of the quantity :math:`J` described in\n        the class definition.  For a perturbation to the surface\n        :math:`\\delta \\vec{x}`, the resulting perturbation to the\n        objective function is\n\n        .. math::\n          \\delta J(\\delta \\vec{x}) = \\int d^2 x \\, G \\delta \\vec{x} \\cdot \\vec{n}\n\n        where the integral is over the VMEC boundary surface,\n        :math:`G` is the shape gradient, and :math:`\\vec{n}` is the\n        unit normal.\n\n        Returns:\n            :math:`G` : 2d array of size (numquadpoints_phi,numquadpoints_theta)\n        \"\"\"\n        vmec = self.vmec\n        vmec.run()\n\n        Bx0, By0, Bz0 = B_cartesian(self.vmec)\n\n        mu0 = 4*np.pi*1e-7\n        am_aux_f_prev = np.copy(vmec.indata.am_aux_f)\n        am_aux_s_prev = np.copy(vmec.indata.am_aux_s)\n        pmass_type_prev = np.copy(vmec.indata.pmass_type)\n\n        pres = vmec.wout.pres[1::]\n        weight1 = self.weight_function1(vmec.s_half_grid) - self.weight_function2(vmec.s_half_grid)\n        weight2 = self.weight_function1(vmec.s_half_grid) + self.weight_function2(vmec.s_half_grid)\n        numerator = np.sum(weight1 * vmec.wout.vp[1::])\n        denominator = np.sum(weight2 * vmec.wout.vp[1::])\n        fW = numerator/denominator\n        perturbation = (weight1 - fW * weight2) / (denominator * vmec.ds * 4 * np.pi * np.pi)\n\n        # Perturbed pressure profile\n        pres_new = pres + self.adjoint_epsilon*perturbation\n\n        vmec.indata.am_aux_f = -1.*np.ones_like(vmec.indata.am_aux_f)\n        vmec.indata.am_aux_s = -1.*np.ones_like(vmec.indata.am_aux_s)\n        vmec.indata.am_aux_f[0:vmec.wout.ns-1] = pres_new\n        vmec.indata.am_aux_s[0:vmec.wout.ns-1] = vmec.s_half_grid\n        vmec.indata.pmass_type = b'cubic_spline'\n        vmec.need_to_run_code = True\n\n        vmec.run()\n\n        Bx, By, Bz = B_cartesian(self.vmec)\n\n        # Reset input values\n        vmec.indata.am_aux_f = am_aux_f_prev\n        vmec.indata.am_aux_s = am_aux_s_prev\n        vmec.indata.pmass_type = pmass_type_prev\n        vmec.need_to_run_code = True\n\n        deltaB_dot_B = ((Bx-Bx0)*Bx0 + (By-By0)*By0 + (Bz-Bz0)*Bz0)/self.adjoint_epsilon\n\n        return deltaB_dot_B/(mu0) + perturbation[-1]",
  "def residual(theta_v, phi0, theta_p_target, jradius):\n        \"\"\"\n        This function is used for computing an array of values of theta_vmec that\n        give a desired theta_pest array.\n        \"\"\"\n        return theta_p_target - (theta_v + np.sum(lmns[jradius, :, None] * np.sin(xm[:, None] * theta_v - xn[:, None] * phi0), axis=0))",
  "class VirtualCasing:\n    r\"\"\"\n    Use the virtual casing principle to compute the contribution to\n    the total magnetic field due to current outside a bounded surface.\n\n    Usually, an instance of this class is created using the\n    :func:`from_vmec()` class method, which also drives the\n    computationally demanding part of the calculation (solving the\n    integral equation).  In the future, interfaces to other\n    equilibrium codes may be added.\n\n    In the standard 2-stage approach to stellarator optimization, the\n    virtual casing calculation is run once, at the end of stage 1\n    (optimizing the plasma shape), with the result provided as input\n    to stage 2 (optimizing the coil shapes). In this case, you can use\n    the :func:`save()` function or the ``filename`` argument of\n    :func:`from_vmec()` to save the results of the virtual casing\n    calculation.  These saved results can then be loaded in later\n    using the :func:`load()` class method, when needed for solving the\n    stage-2 problem.\n\n    In order to compute the external field accurately, one requires\n    fairly high grid resolution. For the stage-2 problem however, a\n    lower resolution is often sufficient. To deal with this, we\n    consider two grids, one denoted by the prefix ``src_`` and the\n    other one denoted by ``trgt_``. ``src_nphi`` and ``src_ntheta``\n    refer to the resolution of the grid for the input data, i.e. the\n    total magnetic field and shape of the surface. ``trgt_nphi`` and\n    ``trgt_ntheta`` refer to the resolution of the grid where the\n    external field is computed, i.e. the output of the virtual casing\n    calculation that is provided as input to the stage 2 problem).\n\n    To set the grid resolutions ``src_nphi`` and ``src_ntheta``, it can be\n    convenient to use the function\n    :func:`simsopt.geo.surface.best_nphi_over_ntheta`.\n\n    An instance of this class has the following attributes. For all\n    vector quantites, Cartesian coordinates are used, corresponding to\n    array dimensions of size 3:\n\n    - ``src_nphi``: The number of grid points in the toroidal angle :math:`\\phi`, for a half field period (or a full field period if use_stellsym=False)\n    - ``src_ntheta``: The number of grid points in the poloidal angle :math:`\\theta`.\n    - ``src_phi``: An array of size ``(src_nphi,)`` with the grid points of :math:`\\phi`.\n    - ``src_theta``: An array of size ``(src_ntheta,)`` with the grid points of :math:`\\theta`.\n    - ``trgt_nphi``: The number of grid points in the toroidal angle :math:`\\phi`, for a half field period (or a full field period if use_stellsym=False)\n    - ``trgt_ntheta``: The number of grid points in the poloidal angle :math:`\\theta`.\n    - ``trgt_phi``: An array of size ``(trgt_nphi,)`` with the grid points of :math:`\\phi`.\n    - ``trgt_theta``: An array of size ``(trgt_ntheta,)`` with the grid points of :math:`\\theta`.\n\n    - ``gamma``: An array of size ``(src_nphi, src_ntheta, 3)`` with the position vector on the surface.\n    - ``B_total``: An array of size ``(src_nphi, src_ntheta, 3)`` with the total magnetic field vector on the surface.\n    - ``unit_normal``: An array of size ``(trgt_nphi, trgt_ntheta, 3)`` with the unit normal vector on the surface.\n    - ``B_external``: An array of size ``(trgt_nphi, trgt_ntheta, 3)`` with the contribution\n      to the magnetic field due to current outside the surface.\n    - ``B_external_normal``: An array of size ``(trgt_nphi, trgt_ntheta)`` with the contribution\n      to the magnetic field due to current outside the surface, taking just the component\n      normal to the surface.\n\n    The :math:`\\phi` and :math:`\\theta` grids for these data are both\n    uniformly spaced, and are the same as for\n    :obj:`~simsopt.geo.surface.Surface` classes with ``range=\"half\n    period\"`` or ``range=\"full period\"``, for the case of\n    stellarator-symmetry or non-stellarator-symmetry respectively.\n    (See the description of the ``range`` parameter in the\n    documentation on :ref:`surfaces`.)  For the usual case of\n    stellarator symmetry, all the virtual casing data are given on\n    half a field period. There is no grid point at :math:`\\phi=0`,\n    rather the grid is shifted in :math:`\\phi` by half the grid\n    spacing. Thus, the ``src_phi`` grid is ``np.linspace(1 / (2 * nfp\n    * src_nphi), (src_nphi - 0.5) / (src_nphi * nfp), src_nphi)``\n    (recalling the simsopt convention that :math:`\\phi` and :math:`\\theta` have period 1,\n    not :math:`2\\pi`). For a non-stellarator-symmetric calculation,\n    the ``src_phi`` grid is ``np.linspace(0, 1 / nfp, src_nphi,\n    endpoint=False)``.  The ``trgt_phi`` grid follows the same logic as\n    the ``src_phi`` grid.  Note that for stellarator symmetry, if\n    ``src_nphi != trgt_nphi``, then the shift (i.e. first grid point)\n    in ``src_phi`` and ``trgt_phi`` will be different. For both\n    stellarator symmetry and non-stellarator-symmetry, the\n    ``src_theta`` grid is ``np.linspace(0, 1, src_ntheta,\n    endpoint=False)``, and the ``trgt_theta`` grid is the same but with\n    ``trgt_ntheta``.\n\n    In particular, ``B_external_normal`` is given on the grid that\n    would be naturally used for stage-2 coil optimization, so no\n    resampling is required.\n    \"\"\"\n\n    @classmethod\n    def from_vmec(cls, vmec, src_nphi, src_ntheta=None, trgt_nphi=None, trgt_ntheta=None, use_stellsym=True, digits=6, filename=\"auto\"):\n        \"\"\"\n        Given a :obj:`~simsopt.mhd.vmec.Vmec` object, compute the contribution\n        to the total magnetic field due to currents outside the plasma.\n\n        This function requires the python ``virtual_casing`` package to be\n        installed.\n\n        The argument ``src_nphi`` refers to the number of points around a half\n        field period if stellarator symmetry is exploited, or a full field\n        period if not.\n\n        To set the grid resolutions ``src_nphi`` and ``src_ntheta``, it can be\n        convenient to use the function\n        :func:`simsopt.geo.surface.best_nphi_over_ntheta`. This is\n        done automatically if you omit the ``src_ntheta`` argument.\n\n        For now, this routine only works for stellarator symmetry.\n\n        Args:\n            vmec: Either an instance of :obj:`simsopt.mhd.vmec.Vmec`, or the name of a\n              Vmec ``input.*`` or ``wout*`` file.\n            src_nphi: Number of grid points toroidally for the input of the calculation.\n            src_ntheta: Number of grid points poloidally for the input of the calculation. If ``None``,\n              the number of grid points will be calculated automatically using\n              :func:`simsopt.geo.surface.best_nphi_over_ntheta()` to minimize\n              the grid anisotropy, given the specified ``nphi``.\n            trgt_nphi: Number of grid points toroidally for the output of the calculation.\n              If unspecified, ``src_nphi`` will be used.\n            trgt_ntheta: Number of grid points poloidally for the output of the calculation.\n              If unspecified, ``src_ntheta`` will be used.\n            use_stellsym: whether to exploit stellarator symmetry in the calculation.\n            digits: Approximate number of digits of precision for the calculation.\n            filename: If not ``None``, the results of the virtual casing calculation\n              will be saved in this file. For the default value of ``\"auto\"``, the\n              filename will automatically be set to ``\"vcasing_<extension>.nc\"``\n              where ``<extension>`` is the string associated with Vmec input and output\n              files, analogous to the Vmec output file ``\"wout_<extension>.nc\"``.\n        \"\"\"\n        import virtual_casing as vc_module\n\n        if not isinstance(vmec, Vmec):\n            vmec = Vmec(vmec)\n\n        vmec.run()\n        nfp = vmec.wout.nfp\n        stellsym = (not bool(vmec.wout.lasym)) and use_stellsym\n        if vmec.wout.lasym:\n            raise RuntimeError('virtual casing presently only works for stellarator symmetry')\n\n        if src_ntheta is None:\n            src_ntheta = int((1+int(stellsym)) * nfp * src_nphi / best_nphi_over_ntheta(vmec.boundary))\n            logger.info(f'new src_ntheta: {src_ntheta}')\n\n        # The requested nphi and ntheta may not match the quadrature\n        # points in vmec.boundary, and the range may not be \"full torus\",\n        # so generate a SurfaceRZFourier with the desired resolution:\n        if stellsym:\n            ran = \"half period\"\n        else:\n            ran = \"field period\"\n        surf = SurfaceRZFourier.from_nphi_ntheta(mpol=vmec.wout.mpol, ntor=vmec.wout.ntor, nfp=nfp,\n                                                 nphi=src_nphi, ntheta=src_ntheta, range=ran)\n        for jmn in range(vmec.wout.mnmax):\n            surf.set_rc(int(vmec.wout.xm[jmn]), int(vmec.wout.xn[jmn] / nfp), vmec.wout.rmnc[jmn, -1])\n            surf.set_zs(int(vmec.wout.xm[jmn]), int(vmec.wout.xn[jmn] / nfp), vmec.wout.zmns[jmn, -1])\n        Bxyz = B_cartesian(vmec, nphi=src_nphi, ntheta=src_ntheta, range=ran)\n        gamma = surf.gamma()\n        logger.debug(f'gamma.shape: {gamma.shape}')\n        logger.debug(f'Bxyz[0].shape: {Bxyz[0].shape}')\n\n        if trgt_nphi is None:\n            trgt_nphi = src_nphi\n        if trgt_ntheta is None:\n            trgt_ntheta = src_ntheta\n        trgt_surf = SurfaceRZFourier.from_nphi_ntheta(mpol=vmec.wout.mpol, ntor=vmec.wout.ntor, nfp=nfp,\n                                                      nphi=trgt_nphi, ntheta=trgt_ntheta, range=ran)\n        trgt_surf.x = surf.x\n\n        unit_normal = trgt_surf.unitnormal()\n        logger.debug(f'unit_normal.shape: {unit_normal.shape}')\n\n        # virtual_casing wants all input arrays to be 1D. The order is\n        # {x11, x12, ..., x1Np, x21, x22, ... , xNtNp, y11, ... , z11, ...}\n        # where Nt is toroidal (not theta!) and Np is poloidal (not phi!)\n        gamma1d = np.zeros(src_nphi * src_ntheta * 3)\n        B1d = np.zeros(src_nphi * src_ntheta * 3)\n        B3d = np.zeros((src_nphi, src_ntheta, 3))\n        for jxyz in range(3):\n            gamma1d[jxyz * src_nphi * src_ntheta: (jxyz + 1) * src_nphi * src_ntheta] = gamma[:, :, jxyz].flatten(order='C')\n            B1d[jxyz * src_nphi * src_ntheta: (jxyz + 1) * src_nphi * src_ntheta] = Bxyz[jxyz].flatten(order='C')\n            B3d[:, :, jxyz] = Bxyz[jxyz]\n\n        \"\"\"\n        # Check order:\n        index = 0\n        for jxyz in range(3):\n            for jphi in range(src_nphi):\n                for jtheta in range(src_ntheta):\n                    np.testing.assert_allclose(gamma1d[index], gamma[jphi, jtheta, jxyz])\n                    np.testing.assert_allclose(B1d[index], Bxyz[jxyz][jphi, jtheta])\n                    index += 1\n        \"\"\"\n\n        vcasing = vc_module.VirtualCasing()\n        vcasing.setup(\n            digits, nfp, stellsym,\n            src_nphi, src_ntheta, gamma1d,\n            src_nphi, src_ntheta,\n            trgt_nphi, trgt_ntheta)\n        # This next line launches the main computation:\n        Bexternal1d = np.array(vcasing.compute_external_B(B1d))\n\n        # Unpack 1D array results:\n        Bexternal3d = np.zeros((trgt_nphi, trgt_ntheta, 3))\n        for jxyz in range(3):\n            Bexternal3d[:, :, jxyz] = Bexternal1d[jxyz * trgt_nphi * trgt_ntheta: (jxyz + 1) * trgt_nphi * trgt_ntheta].reshape((trgt_nphi, trgt_ntheta), order='C')\n\n        \"\"\"\n        # Check order:\n        index = 0\n        for jxyz in range(3):\n            for jphi in range(trgt_nphi):\n                for jtheta in range(trgt_ntheta):\n                    np.testing.assert_allclose(Bexternal1d[index], Bexternal3d[jphi, jtheta, jxyz])\n                    index += 1\n        \"\"\"\n\n        Bexternal_normal = np.sum(Bexternal3d * unit_normal, axis=2)\n\n        vc = cls()\n        vc.src_ntheta = src_ntheta\n        vc.src_nphi = src_nphi\n        vc.src_theta = surf.quadpoints_theta\n        vc.src_phi = surf.quadpoints_phi\n\n        vc.trgt_ntheta = trgt_ntheta\n        vc.trgt_nphi = trgt_nphi\n        vc.trgt_theta = trgt_surf.quadpoints_theta\n        vc.trgt_phi = trgt_surf.quadpoints_phi\n\n        vc.nfp = nfp\n        vc.B_total = B3d\n        vc.gamma = gamma\n        vc.unit_normal = unit_normal\n        vc.B_external = Bexternal3d\n        vc.B_external_normal = Bexternal_normal\n\n        if filename is not None:\n            if filename == 'auto':\n                directory, basefile = os.path.split(vmec.output_file)\n                filename = os.path.join(directory, 'vcasing' + basefile[4:])\n                logger.debug(f'New filename: {filename}')\n            vc.save(filename)\n\n        return vc\n\n    def save(self, filename=\"vcasing.nc\"):\n        \"\"\"\n        Save the results of a virtual casing calculation in a NetCDF file.\n\n        Args:\n            filename: Name of the file to create.\n        \"\"\"\n        with netcdf_file(filename, 'w') as f:\n            f.history = 'This file created by simsopt on ' + datetime.now().strftime(\"%B %d %Y, %H:%M:%S\")\n            f.createDimension('src_ntheta', self.src_ntheta)\n            f.createDimension('src_nphi', self.src_nphi)\n            f.createDimension('trgt_ntheta', self.trgt_ntheta)\n            f.createDimension('trgt_nphi', self.trgt_nphi)\n            f.createDimension('xyz', 3)\n\n            src_ntheta = f.createVariable('src_ntheta', 'i', tuple())\n            src_ntheta.assignValue(self.src_ntheta)\n            src_ntheta.description = 'Number of grid points in the poloidal angle theta for source B field and surface shape'\n            src_ntheta.units = 'Dimensionless'\n\n            trgt_ntheta = f.createVariable('trgt_ntheta', 'i', tuple())\n            trgt_ntheta.assignValue(self.trgt_ntheta)\n            trgt_ntheta.description = 'Number of grid points in the poloidal angle theta for resulting B_external'\n            trgt_ntheta.units = 'Dimensionless'\n\n            src_nphi = f.createVariable('src_nphi', 'i', tuple())\n            src_nphi.assignValue(self.src_nphi)\n            src_nphi.description = 'Number of grid points in the toroidal angle phi for source B field and surface shape'\n            src_nphi.units = 'Dimensionless'\n\n            trgt_nphi = f.createVariable('trgt_nphi', 'i', tuple())\n            trgt_nphi.assignValue(self.trgt_nphi)\n            trgt_nphi.description = 'Number of grid points in the toroidal angle phi for resulting B_external'\n            trgt_nphi.units = 'Dimensionless'\n\n            nfp = f.createVariable('nfp', 'i', tuple())\n            nfp.assignValue(self.nfp)\n            nfp.description = 'Periodicity in toroidal direction'\n            nfp.units = 'Dimensionless'\n\n            src_theta = f.createVariable('src_theta', 'd', ('src_ntheta',))\n            src_theta[:] = self.src_theta\n            src_theta.description = 'Grid points in the poloidal angle theta for source B field and surface shape. Note that theta extends over [0, 1) not [0, 2pi).'\n            src_theta.units = 'Dimensionless'\n\n            trgt_theta = f.createVariable('trgt_theta', 'd', ('trgt_ntheta',))\n            trgt_theta[:] = self.trgt_theta\n            trgt_theta.description = 'Grid points in the poloidal angle theta for resulting B_external. Note that theta extends over [0, 1) not [0, 2pi).'\n            trgt_theta.units = 'Dimensionless'\n\n            src_phi = f.createVariable('src_phi', 'd', ('src_nphi',))\n            src_phi[:] = self.src_phi\n            src_phi.description = 'Grid points in the toroidal angle phi for source B field and surface shape. Note that phi extends over [0, 1) not [0, 2pi).'\n            src_phi.units = 'Dimensionless'\n\n            trgt_phi = f.createVariable('trgt_phi', 'd', ('trgt_nphi',))\n            trgt_phi[:] = self.trgt_phi\n            trgt_phi.description = 'Grid points in the toroidal angle phi for resulting B_external. Note that phi extends over [0, 1) not [0, 2pi).'\n            trgt_phi.units = 'Dimensionless'\n\n            gamma = f.createVariable('gamma', 'd', ('src_nphi', 'src_ntheta', 'xyz'))\n            gamma[:, :, :] = self.gamma\n            gamma.description = 'Position vector on the boundary surface'\n            gamma.units = 'meter'\n\n            unit_normal = f.createVariable('unit_normal', 'd', ('trgt_nphi', 'trgt_ntheta', 'xyz'))\n            unit_normal[:, :, :] = self.unit_normal\n            unit_normal.description = 'Unit-length normal vector on the boundary surface'\n            unit_normal.units = 'Dimensionless'\n\n            B_total = f.createVariable('B_total', 'd', ('src_nphi', 'src_ntheta', 'xyz'))\n            B_total[:, :, :] = self.B_total\n            B_total.description = 'Total magnetic field vector on the surface, including currents both inside and outside of the surface'\n            B_total.units = 'Tesla'\n\n            B_external = f.createVariable('B_external', 'd', ('trgt_nphi', 'trgt_ntheta', 'xyz'))\n            B_external[:, :, :] = self.B_external\n            B_external.description = 'Contribution to the magnetic field vector on the surface due only to currents outside the surface'\n            B_external.units = 'Tesla'\n\n            B_external_normal = f.createVariable('B_external_normal', 'd', ('trgt_nphi', 'trgt_ntheta'))\n            B_external_normal[:, :] = self.B_external_normal\n            B_external_normal.description = 'Component of B_external normal to the surface'\n            B_external_normal.units = 'Tesla'\n\n    @classmethod\n    def load(cls, filename):\n        \"\"\"\n        Load in the results of a previous virtual casing calculation,\n        previously saved in NetCDF format.\n\n        Args:\n            filename: Name of the file to load.\n        \"\"\"\n        vc = cls()\n        with netcdf_file(filename, mmap=False) as f:\n            for key, val in f.variables.items():\n                val2 = val[()]  # Convert to numpy array\n                vc.__setattr__(key, val2)\n        return vc\n\n    def plot(self, ax=None, show=True):\n        \"\"\"\n        Plot ``B_external_normal``, the component normal to the surface of\n        the magnetic field generated by currents outside the surface.\n        This routine requires ``matplotlib``.\n\n        Args:\n            ax: The axis object on which to plot. This argument is useful when plotting multiple\n              objects on the same axes. If equal to the default ``None``, a new axis will be created.\n            show: Whether to call matplotlib's ``show()`` function.\n\n        Returns:\n            An axis which could be passed to a further call to matplotlib if desired.\n        \"\"\"\n        import matplotlib.pyplot as plt\n        if ax is None:\n            fig, ax = plt.subplots()\n        else:\n            fig = plt.gcf()\n        contours = ax.contourf(self.trgt_phi, self.trgt_theta, self.B_external_normal.T, 25)\n        ax.set_xlabel(r'$\\phi$')\n        ax.set_ylabel(r'$\\theta$')\n        ax.set_title('B_external_normal [Tesla]')\n        fig.colorbar(contours)\n        fig.tight_layout()\n        if show:\n            plt.show()\n        return ax",
  "def from_vmec(cls, vmec, src_nphi, src_ntheta=None, trgt_nphi=None, trgt_ntheta=None, use_stellsym=True, digits=6, filename=\"auto\"):\n        \"\"\"\n        Given a :obj:`~simsopt.mhd.vmec.Vmec` object, compute the contribution\n        to the total magnetic field due to currents outside the plasma.\n\n        This function requires the python ``virtual_casing`` package to be\n        installed.\n\n        The argument ``src_nphi`` refers to the number of points around a half\n        field period if stellarator symmetry is exploited, or a full field\n        period if not.\n\n        To set the grid resolutions ``src_nphi`` and ``src_ntheta``, it can be\n        convenient to use the function\n        :func:`simsopt.geo.surface.best_nphi_over_ntheta`. This is\n        done automatically if you omit the ``src_ntheta`` argument.\n\n        For now, this routine only works for stellarator symmetry.\n\n        Args:\n            vmec: Either an instance of :obj:`simsopt.mhd.vmec.Vmec`, or the name of a\n              Vmec ``input.*`` or ``wout*`` file.\n            src_nphi: Number of grid points toroidally for the input of the calculation.\n            src_ntheta: Number of grid points poloidally for the input of the calculation. If ``None``,\n              the number of grid points will be calculated automatically using\n              :func:`simsopt.geo.surface.best_nphi_over_ntheta()` to minimize\n              the grid anisotropy, given the specified ``nphi``.\n            trgt_nphi: Number of grid points toroidally for the output of the calculation.\n              If unspecified, ``src_nphi`` will be used.\n            trgt_ntheta: Number of grid points poloidally for the output of the calculation.\n              If unspecified, ``src_ntheta`` will be used.\n            use_stellsym: whether to exploit stellarator symmetry in the calculation.\n            digits: Approximate number of digits of precision for the calculation.\n            filename: If not ``None``, the results of the virtual casing calculation\n              will be saved in this file. For the default value of ``\"auto\"``, the\n              filename will automatically be set to ``\"vcasing_<extension>.nc\"``\n              where ``<extension>`` is the string associated with Vmec input and output\n              files, analogous to the Vmec output file ``\"wout_<extension>.nc\"``.\n        \"\"\"\n        import virtual_casing as vc_module\n\n        if not isinstance(vmec, Vmec):\n            vmec = Vmec(vmec)\n\n        vmec.run()\n        nfp = vmec.wout.nfp\n        stellsym = (not bool(vmec.wout.lasym)) and use_stellsym\n        if vmec.wout.lasym:\n            raise RuntimeError('virtual casing presently only works for stellarator symmetry')\n\n        if src_ntheta is None:\n            src_ntheta = int((1+int(stellsym)) * nfp * src_nphi / best_nphi_over_ntheta(vmec.boundary))\n            logger.info(f'new src_ntheta: {src_ntheta}')\n\n        # The requested nphi and ntheta may not match the quadrature\n        # points in vmec.boundary, and the range may not be \"full torus\",\n        # so generate a SurfaceRZFourier with the desired resolution:\n        if stellsym:\n            ran = \"half period\"\n        else:\n            ran = \"field period\"\n        surf = SurfaceRZFourier.from_nphi_ntheta(mpol=vmec.wout.mpol, ntor=vmec.wout.ntor, nfp=nfp,\n                                                 nphi=src_nphi, ntheta=src_ntheta, range=ran)\n        for jmn in range(vmec.wout.mnmax):\n            surf.set_rc(int(vmec.wout.xm[jmn]), int(vmec.wout.xn[jmn] / nfp), vmec.wout.rmnc[jmn, -1])\n            surf.set_zs(int(vmec.wout.xm[jmn]), int(vmec.wout.xn[jmn] / nfp), vmec.wout.zmns[jmn, -1])\n        Bxyz = B_cartesian(vmec, nphi=src_nphi, ntheta=src_ntheta, range=ran)\n        gamma = surf.gamma()\n        logger.debug(f'gamma.shape: {gamma.shape}')\n        logger.debug(f'Bxyz[0].shape: {Bxyz[0].shape}')\n\n        if trgt_nphi is None:\n            trgt_nphi = src_nphi\n        if trgt_ntheta is None:\n            trgt_ntheta = src_ntheta\n        trgt_surf = SurfaceRZFourier.from_nphi_ntheta(mpol=vmec.wout.mpol, ntor=vmec.wout.ntor, nfp=nfp,\n                                                      nphi=trgt_nphi, ntheta=trgt_ntheta, range=ran)\n        trgt_surf.x = surf.x\n\n        unit_normal = trgt_surf.unitnormal()\n        logger.debug(f'unit_normal.shape: {unit_normal.shape}')\n\n        # virtual_casing wants all input arrays to be 1D. The order is\n        # {x11, x12, ..., x1Np, x21, x22, ... , xNtNp, y11, ... , z11, ...}\n        # where Nt is toroidal (not theta!) and Np is poloidal (not phi!)\n        gamma1d = np.zeros(src_nphi * src_ntheta * 3)\n        B1d = np.zeros(src_nphi * src_ntheta * 3)\n        B3d = np.zeros((src_nphi, src_ntheta, 3))\n        for jxyz in range(3):\n            gamma1d[jxyz * src_nphi * src_ntheta: (jxyz + 1) * src_nphi * src_ntheta] = gamma[:, :, jxyz].flatten(order='C')\n            B1d[jxyz * src_nphi * src_ntheta: (jxyz + 1) * src_nphi * src_ntheta] = Bxyz[jxyz].flatten(order='C')\n            B3d[:, :, jxyz] = Bxyz[jxyz]\n\n        \"\"\"\n        # Check order:\n        index = 0\n        for jxyz in range(3):\n            for jphi in range(src_nphi):\n                for jtheta in range(src_ntheta):\n                    np.testing.assert_allclose(gamma1d[index], gamma[jphi, jtheta, jxyz])\n                    np.testing.assert_allclose(B1d[index], Bxyz[jxyz][jphi, jtheta])\n                    index += 1\n        \"\"\"\n\n        vcasing = vc_module.VirtualCasing()\n        vcasing.setup(\n            digits, nfp, stellsym,\n            src_nphi, src_ntheta, gamma1d,\n            src_nphi, src_ntheta,\n            trgt_nphi, trgt_ntheta)\n        # This next line launches the main computation:\n        Bexternal1d = np.array(vcasing.compute_external_B(B1d))\n\n        # Unpack 1D array results:\n        Bexternal3d = np.zeros((trgt_nphi, trgt_ntheta, 3))\n        for jxyz in range(3):\n            Bexternal3d[:, :, jxyz] = Bexternal1d[jxyz * trgt_nphi * trgt_ntheta: (jxyz + 1) * trgt_nphi * trgt_ntheta].reshape((trgt_nphi, trgt_ntheta), order='C')\n\n        \"\"\"\n        # Check order:\n        index = 0\n        for jxyz in range(3):\n            for jphi in range(trgt_nphi):\n                for jtheta in range(trgt_ntheta):\n                    np.testing.assert_allclose(Bexternal1d[index], Bexternal3d[jphi, jtheta, jxyz])\n                    index += 1\n        \"\"\"\n\n        Bexternal_normal = np.sum(Bexternal3d * unit_normal, axis=2)\n\n        vc = cls()\n        vc.src_ntheta = src_ntheta\n        vc.src_nphi = src_nphi\n        vc.src_theta = surf.quadpoints_theta\n        vc.src_phi = surf.quadpoints_phi\n\n        vc.trgt_ntheta = trgt_ntheta\n        vc.trgt_nphi = trgt_nphi\n        vc.trgt_theta = trgt_surf.quadpoints_theta\n        vc.trgt_phi = trgt_surf.quadpoints_phi\n\n        vc.nfp = nfp\n        vc.B_total = B3d\n        vc.gamma = gamma\n        vc.unit_normal = unit_normal\n        vc.B_external = Bexternal3d\n        vc.B_external_normal = Bexternal_normal\n\n        if filename is not None:\n            if filename == 'auto':\n                directory, basefile = os.path.split(vmec.output_file)\n                filename = os.path.join(directory, 'vcasing' + basefile[4:])\n                logger.debug(f'New filename: {filename}')\n            vc.save(filename)\n\n        return vc",
  "def save(self, filename=\"vcasing.nc\"):\n        \"\"\"\n        Save the results of a virtual casing calculation in a NetCDF file.\n\n        Args:\n            filename: Name of the file to create.\n        \"\"\"\n        with netcdf_file(filename, 'w') as f:\n            f.history = 'This file created by simsopt on ' + datetime.now().strftime(\"%B %d %Y, %H:%M:%S\")\n            f.createDimension('src_ntheta', self.src_ntheta)\n            f.createDimension('src_nphi', self.src_nphi)\n            f.createDimension('trgt_ntheta', self.trgt_ntheta)\n            f.createDimension('trgt_nphi', self.trgt_nphi)\n            f.createDimension('xyz', 3)\n\n            src_ntheta = f.createVariable('src_ntheta', 'i', tuple())\n            src_ntheta.assignValue(self.src_ntheta)\n            src_ntheta.description = 'Number of grid points in the poloidal angle theta for source B field and surface shape'\n            src_ntheta.units = 'Dimensionless'\n\n            trgt_ntheta = f.createVariable('trgt_ntheta', 'i', tuple())\n            trgt_ntheta.assignValue(self.trgt_ntheta)\n            trgt_ntheta.description = 'Number of grid points in the poloidal angle theta for resulting B_external'\n            trgt_ntheta.units = 'Dimensionless'\n\n            src_nphi = f.createVariable('src_nphi', 'i', tuple())\n            src_nphi.assignValue(self.src_nphi)\n            src_nphi.description = 'Number of grid points in the toroidal angle phi for source B field and surface shape'\n            src_nphi.units = 'Dimensionless'\n\n            trgt_nphi = f.createVariable('trgt_nphi', 'i', tuple())\n            trgt_nphi.assignValue(self.trgt_nphi)\n            trgt_nphi.description = 'Number of grid points in the toroidal angle phi for resulting B_external'\n            trgt_nphi.units = 'Dimensionless'\n\n            nfp = f.createVariable('nfp', 'i', tuple())\n            nfp.assignValue(self.nfp)\n            nfp.description = 'Periodicity in toroidal direction'\n            nfp.units = 'Dimensionless'\n\n            src_theta = f.createVariable('src_theta', 'd', ('src_ntheta',))\n            src_theta[:] = self.src_theta\n            src_theta.description = 'Grid points in the poloidal angle theta for source B field and surface shape. Note that theta extends over [0, 1) not [0, 2pi).'\n            src_theta.units = 'Dimensionless'\n\n            trgt_theta = f.createVariable('trgt_theta', 'd', ('trgt_ntheta',))\n            trgt_theta[:] = self.trgt_theta\n            trgt_theta.description = 'Grid points in the poloidal angle theta for resulting B_external. Note that theta extends over [0, 1) not [0, 2pi).'\n            trgt_theta.units = 'Dimensionless'\n\n            src_phi = f.createVariable('src_phi', 'd', ('src_nphi',))\n            src_phi[:] = self.src_phi\n            src_phi.description = 'Grid points in the toroidal angle phi for source B field and surface shape. Note that phi extends over [0, 1) not [0, 2pi).'\n            src_phi.units = 'Dimensionless'\n\n            trgt_phi = f.createVariable('trgt_phi', 'd', ('trgt_nphi',))\n            trgt_phi[:] = self.trgt_phi\n            trgt_phi.description = 'Grid points in the toroidal angle phi for resulting B_external. Note that phi extends over [0, 1) not [0, 2pi).'\n            trgt_phi.units = 'Dimensionless'\n\n            gamma = f.createVariable('gamma', 'd', ('src_nphi', 'src_ntheta', 'xyz'))\n            gamma[:, :, :] = self.gamma\n            gamma.description = 'Position vector on the boundary surface'\n            gamma.units = 'meter'\n\n            unit_normal = f.createVariable('unit_normal', 'd', ('trgt_nphi', 'trgt_ntheta', 'xyz'))\n            unit_normal[:, :, :] = self.unit_normal\n            unit_normal.description = 'Unit-length normal vector on the boundary surface'\n            unit_normal.units = 'Dimensionless'\n\n            B_total = f.createVariable('B_total', 'd', ('src_nphi', 'src_ntheta', 'xyz'))\n            B_total[:, :, :] = self.B_total\n            B_total.description = 'Total magnetic field vector on the surface, including currents both inside and outside of the surface'\n            B_total.units = 'Tesla'\n\n            B_external = f.createVariable('B_external', 'd', ('trgt_nphi', 'trgt_ntheta', 'xyz'))\n            B_external[:, :, :] = self.B_external\n            B_external.description = 'Contribution to the magnetic field vector on the surface due only to currents outside the surface'\n            B_external.units = 'Tesla'\n\n            B_external_normal = f.createVariable('B_external_normal', 'd', ('trgt_nphi', 'trgt_ntheta'))\n            B_external_normal[:, :] = self.B_external_normal\n            B_external_normal.description = 'Component of B_external normal to the surface'\n            B_external_normal.units = 'Tesla'",
  "def load(cls, filename):\n        \"\"\"\n        Load in the results of a previous virtual casing calculation,\n        previously saved in NetCDF format.\n\n        Args:\n            filename: Name of the file to load.\n        \"\"\"\n        vc = cls()\n        with netcdf_file(filename, mmap=False) as f:\n            for key, val in f.variables.items():\n                val2 = val[()]  # Convert to numpy array\n                vc.__setattr__(key, val2)\n        return vc",
  "def plot(self, ax=None, show=True):\n        \"\"\"\n        Plot ``B_external_normal``, the component normal to the surface of\n        the magnetic field generated by currents outside the surface.\n        This routine requires ``matplotlib``.\n\n        Args:\n            ax: The axis object on which to plot. This argument is useful when plotting multiple\n              objects on the same axes. If equal to the default ``None``, a new axis will be created.\n            show: Whether to call matplotlib's ``show()`` function.\n\n        Returns:\n            An axis which could be passed to a further call to matplotlib if desired.\n        \"\"\"\n        import matplotlib.pyplot as plt\n        if ax is None:\n            fig, ax = plt.subplots()\n        else:\n            fig = plt.gcf()\n        contours = ax.contourf(self.trgt_phi, self.trgt_theta, self.B_external_normal.T, 25)\n        ax.set_xlabel(r'$\\phi$')\n        ax.set_ylabel(r'$\\theta$')\n        ax.set_title('B_external_normal [Tesla]')\n        fig.colorbar(contours)\n        fig.tight_layout()\n        if show:\n            plt.show()\n        return ax",
  "def to_namelist_bool(bool_in):\n    \"\"\" Convert a boolean to a format suitable for fortran namelist input \"\"\"\n    return \"T\" if bool_in else \"F\"",
  "def array_to_namelist(arr, aux_s=False):\n    \"\"\"\n    This routine writes an array to a string, stopping after the last\n    nonzero or nonnegative entry.  This is used for writing the array\n    data in vmec input files.\n    \"\"\"\n    if aux_s:\n        if np.all(arr < 0):\n            index = 0\n        else:\n            index = np.max(np.where(arr >= 0))\n    else:\n        if np.all(arr == 0):\n            index = 0\n        else:\n            index = np.max(np.nonzero(arr))\n    nml = ''\n    for j in range(index + 1):\n        nml += f'{arr[j]} '\n    nml += '\\n'\n    return nml",
  "class Vmec(Optimizable):\n    r\"\"\"\n    This class represents the VMEC equilibrium code.\n\n    You can initialize this class either from a VMEC\n    ``input.<extension>`` file or from a ``wout_<extension>.nc`` output\n    file. If neither is provided, a default input file is used. When\n    this class is initialized from an input file, it is possible to\n    modify the input parameters and run the VMEC code. When this class\n    is initialized from a ``wout`` file, all the data from the\n    ``wout`` file is available in memory but the VMEC code cannot be\n    re-run, since some of the input data (e.g. radial multigrid\n    parameters) is not available in the wout file.\n\n    The input parameters to VMEC are all accessible as attributes of\n    the ``indata`` attribute. For example, if ``vmec`` is an instance\n    of ``Vmec``, then you can read or write the input resolution\n    parameters using ``vmec.indata.mpol``, ``vmec.indata.ntor``,\n    ``vmec.indata.ns_array``, etc. However, the boundary surface is\n    different: ``rbc``, ``rbs``, ``zbc``, and ``zbs`` from the\n    ``indata`` attribute are always ignored, and these arrays are\n    instead taken from the simsopt surface object associated to the\n    ``boundary`` attribute. If ``boundary`` is a surface based on some\n    other representation than VMEC's Fourier representation, the\n    surface will automatically be converted to VMEC's representation\n    (:obj:`~simsopt.geo.surfacerzfourier.SurfaceRZFourier`) before\n    each run of VMEC. You can replace ``boundary`` with a new surface\n    object, of any type that implements the conversion function\n    ``to_RZFourier()``.\n\n    VMEC is run either when the :meth:`run()` function is called, or when\n    any of the output functions like :meth:`aspect()` or :meth:`iota_axis()`\n    are called.\n\n    A caching mechanism is implemented, using the attribute\n    ``need_to_run_code``. Whenever VMEC is run, or if the class is\n    initialized from a ``wout`` file, this attribute is set to\n    ``False``. Subsequent calls to :meth:`run()` or output functions\n    like :meth:`aspect()` will not actually run VMEC again, until\n    ``need_to_run_code`` is changed to ``True``. The attribute\n    ``need_to_run_code`` is automatically set to ``True`` whenever the\n    state vector ``.x`` is changed, and when dofs of the ``boundary``\n    are changed. However, ``need_to_run_code`` is not automatically\n    set to ``True`` when entries of ``indata`` are modified.\n\n    Once VMEC has run at least once, or if the class is initialized\n    from a ``wout`` file, all of the quantities in the ``wout`` output\n    file are available as attributes of the ``wout`` attribute.  For\n    example, if ``vmec`` is an instance of ``Vmec``, then the flux\n    surface shapes can be obtained from ``vmec.wout.rmnc`` and\n    ``vmec.wout.zmns``.\n\n    Since the underlying fortran implementation of VMEC uses global\n    module variables, it is not possible to have more than one python\n    Vmec object with different parameters; changing the parameters of\n    one would change the parameters of the other.\n\n    An instance of this class owns just a few optimizable degrees of\n    freedom, particularly ``phiedge`` and ``curtor``. The optimizable\n    degrees of freedom associated with the boundary surface are owned\n    by that surface object.\n\n    To run VMEC, two input profiles must be specified: pressure and\n    either iota or toroidal current.  Each of these profiles can be\n    specified in several ways. One way is to specify the profile in\n    the input file used to initialize the ``Vmec`` object. For\n    instance, the pressure profile is determined by the variables\n    ``pmass_type``, ``am``, ``am_aux_s``, and ``am_aux_f``. You can\n    also modify these variables from python via the ``indata``\n    attribute, e.g. ``vmec.indata.am = [1.0e5, -1.0e5]``. Another\n    option is to assign a :obj:`simsopt.mhd.profiles.Profile` object\n    to the attributes ``pressure_profile``, ``current_profile``, or\n    ``iota_profile``. This approach allows for the profiles to be\n    optimized, and it allows you to use profile shapes defined in\n    python that are not available in the fortran VMEC code. To explain\n    this approach we focus here on the pressure profile; the iota and\n    current profiles are analogous. If the ``pressure_profile``\n    attribute of a ``Vmec`` object is ``None`` (the default), then a\n    simsopt :obj:`~simsopt.mhd.profiles.Profile` object is not used,\n    and instead the settings from ``Vmec.indata`` (initialized from\n    the input file) are used. If a\n    :obj:`~simsopt.mhd.profiles.Profile` object is assigned to the\n    ``pressure_profile`` attribute, then an :ref:`edge in the\n    dependency graph <dependecies>` is introduced, so the ``Vmec``\n    object then depends on the dofs of the\n    :obj:`~simsopt.mhd.profiles.Profile` object. Whenever VMEC is run,\n    the simsopt :obj:`~simsopt.mhd.profiles.Profile` is converted to\n    either a polynomial (power series) or cubic spline in the\n    normalized toroidal flux :math:`s`, depending on whether\n    ``indata.pmass_type`` is ``\"power_series\"`` or\n    ``\"cubic_spline\"``. (The current profile is different in that\n    either ``\"cubic_spline_ip\"`` or ``\"cubic_spline_i\"`` is specified\n    instead of ``\"cubic_spline\"``.) The number of terms in the power\n    series or number of spline nodes is determined by the attributes\n    ``n_pressure``, ``n_current``, and ``n_iota``.  If a cubic spline\n    is used, the spline nodes are uniformly spaced from :math:`s=0` to\n    1. Note that the choice of whether a polynomial or spline is used\n    for the VMEC calculation is independent of the subclass of\n    :obj:`~simsopt.mhd.profiles.Profile` used. Also, whether the iota\n    or current profile is used is always determined by the\n    ``indata.ncurr`` attribute: 0 for iota, 1 for current. Example::\n\n        from sismopt.mhd.profiles import ProfilePolynomial, ProfileSpline, ProfilePressure, ProfileScaled\n        from simsopt.util.constants import ELEMENTARY_CHARGE\n\n        ne = ProfilePolynomial(1.0e20 * np.array([1, 0, 0, 0, -0.9]))\n        Te = ProfilePolynomial(8.0e3 * np.array([1, -0.9]))\n        Ti = ProfileSpline([0, 0.5, 0.8, 1], 7.0e3 * np.array([1, 0.9, 0.8, 0.1]))\n        ni = ne\n        pressure = ProfilePressure(ne, Te, ni, Ti)  # p = ne * Te + ni * Ti\n        pressure_Pa = ProfileScaled(pressure, ELEMENTARY_CHARGE)  # Te and Ti profiles were in eV, so convert to SI here.\n        vmec = Vmec(filename)\n        vmec.pressure_profile = pressure_Pa\n        vmec.indata.pmass_type = \"cubic_spline\"\n        vmec.n_pressure = 8  # Use 8 spline nodes\n\n    When VMEC is run multiple times, the default behavior is that all\n    ``wout`` output files will be deleted except for the first and\n    most recent iteration on worker group 0. If you wish to keep all\n    the ``wout`` files, you can set ``keep_all_files = True``. If you\n    want to save the ``wout`` file for a certain intermediate\n    iteration, you can set the ``files_to_delete`` attribute to ``[]``\n    after that run of VMEC.\n\n    Args:\n        filename: Name of a VMEC ``input.<extension>`` file or ``wout_<extension>.nc``\n          output file to use for loading the\n          initial parameters. If ``None``, default parameters will be used.\n        mpi: A :obj:`simsopt.util.mpi.MpiPartition` instance, from which\n          the worker groups will be used for VMEC calculations. If ``None``,\n          each MPI process will run VMEC independently.\n        keep_all_files: If ``False``, all ``wout`` output files will be deleted\n          except for the first and most recent ones from worker group 0. If\n          ``True``, all ``wout`` files will be kept.\n        verbose: Whether to print to stdout when running vmec.\n\n    Attributes:\n        iter: Number of times VMEC has run.\n        s_full_grid: The \"full\" grid in the radial coordinate s (normalized\n          toroidal flux), including points at s=0 and s=1. Used for the output\n          arrays and ``zmns``.\n        s_half_grid: The \"half\" grid in the radial coordinate s, used for\n          ``bmnc``, ``lmns``, and other output arrays. In contrast to\n          wout files, this array has only ns-1 entries, so there is no\n          leading 0.\n        ds: The spacing between grid points for the radial coordinate s.\n    \"\"\"\n\n    def __init__(self,\n                 filename: Optional[str] = None,\n                 mpi: Optional[MpiPartition] = None,\n                 keep_all_files: bool = False,\n                 verbose: bool = True,\n                 ntheta=50,\n                 nphi=50,\n                 range_surface='full torus'):\n\n        if filename is None:\n            # Read default input file, which should be in the same\n            # directory as this file:\n            filename = os.path.join(os.path.dirname(__file__), 'input.default')\n            logger.info(f\"Initializing a VMEC object from defaults in {filename}\")\n\n        basename = os.path.basename(filename)\n        if basename[:5] == 'input':\n            logger.info(f\"Initializing a VMEC object from input file: {filename}\")\n            self.input_file = filename\n            self.runnable = True\n        elif basename[:4] == 'wout':\n            logger.info(f\"Initializing a VMEC object from wout file: {filename}\")\n            self.runnable = False\n        else:\n            raise ValueError('Invalid filename')\n\n        self.wout = Struct()\n        self.verbose = verbose\n\n        # Get MPI communicator:\n        if (mpi is None and MPI is not None):\n            self.mpi = MpiPartition(ngroups=1)\n        else:\n            self.mpi = mpi\n\n        self._pressure_profile = None\n        self._current_profile = None\n        self._iota_profile = None\n        self.n_pressure = 10\n        self.n_current = 10\n        self.n_iota = 10\n\n        if self.runnable:\n            if MPI is None:\n                raise RuntimeError(\"mpi4py needs to be installed for running VMEC\")\n            if vmec is None:\n                raise RuntimeError(\n                    \"Running VMEC from simsopt requires VMEC python extension. \"\n                    \"Install the VMEC python extension from \"\n                    \"https://https://github.com/hiddenSymmetries/VMEC2000\")\n\n            comm = self.mpi.comm_groups\n            self.fcomm = comm.py2f()\n\n            self.ictrl = np.zeros(5, dtype=np.int32)\n            self.iter = -1\n            self.keep_all_files = keep_all_files\n            self.files_to_delete = []\n\n            self.indata = vmec.vmec_input  # Shorthand\n            vi = vmec.vmec_input  # Shorthand\n\n            self.ictrl[0] = restart_flag + readin_flag\n            self.ictrl[1] = 0  # ierr\n            self.ictrl[2] = 0  # numsteps\n            self.ictrl[3] = 0  # ns_index\n            self.ictrl[4] = 0  # iseq\n            reset_file = ''\n            logger.info('About to call runvmec to readin')\n            vmec.runvmec(self.ictrl, filename, self.verbose, self.fcomm, reset_file)\n            ierr = self.ictrl[1]\n            logger.info('Done with runvmec. ierr={}. Calling cleanup next.'.format(ierr))\n            # Deallocate arrays allocated by VMEC's fixaray():\n            vmec.cleanup(False)\n            if ierr != 0:\n                raise RuntimeError(\"Failed to initialize VMEC from input file {}. \"\n                                   \"error code {}\".format(filename, ierr))\n\n            objstr = \" for Vmec \" + str(hex(id(self)))\n\n            # A vmec object has mpol and ntor attributes independent of\n            # the boundary. The boundary surface object is initialized\n            # with mpol and ntor values that match those of the vmec\n            # object, but the mpol/ntor values of either the vmec object\n            # or the boundary surface object can be changed independently\n            # by the user.\n            self._boundary = SurfaceRZFourier.from_nphi_ntheta(nfp=vi.nfp,\n                                                               stellsym=not vi.lasym,\n                                                               mpol=vi.mpol,\n                                                               ntor=vi.ntor,\n                                                               ntheta=ntheta,\n                                                               nphi=nphi,\n                                                               range=range_surface)\n            self.free_boundary = bool(vi.lfreeb)\n\n            # Transfer boundary shape data from fortran to the ParameterArray:\n            for m in range(vi.mpol + 1):\n                for n in range(-vi.ntor, vi.ntor + 1):\n                    self._boundary.rc[m, n + vi.ntor] = vi.rbc[101 + n, m]\n                    self._boundary.zs[m, n + vi.ntor] = vi.zbs[101 + n, m]\n                    if vi.lasym:\n                        self._boundary.rs[m, n + vi.ntor] = vi.rbs[101 + n, m]\n                        self._boundary.zc[m, n + vi.ntor] = vi.zbc[101 + n, m]\n            self._boundary.local_full_x = self._boundary.get_dofs()\n\n            self.need_to_run_code = True\n        else:\n            # Initialized from a wout file, so not runnable.\n            self._boundary = SurfaceRZFourier.from_wout(filename, nphi=nphi, ntheta=ntheta, range=range_surface)\n            self.output_file = filename\n            self.load_wout()\n\n        # Handle a few variables that are not Parameters:\n        x0 = self.get_dofs()\n        fixed = np.full(len(x0), True)\n        names = ['delt', 'tcon0', 'phiedge', 'curtor', 'gamma']\n        super().__init__(x0=x0, fixed=fixed, names=names,\n                         depends_on=[self._boundary],\n                         external_dof_setter=Vmec.set_dofs)\n\n        if not self.runnable:\n            # This next line must come after Optimizable.__init__\n            # since that calls recompute_bell()\n            self.need_to_run_code = False\n\n    @property\n    def boundary(self):\n        return self._boundary\n\n    @boundary.setter\n    def boundary(self, boundary):\n        if not boundary is self._boundary:\n            logging.debug('Replacing surface in boundary setter')\n            self.remove_parent(self._boundary)\n            self._boundary = boundary\n            self.append_parent(boundary)\n            self.need_to_run_code = True\n\n    @property\n    def pressure_profile(self):\n        return self._pressure_profile\n\n    @pressure_profile.setter\n    def pressure_profile(self, pressure_profile):\n        if not pressure_profile is self._pressure_profile:\n            logging.debug('Replacing pressure_profile in setter')\n            if self._pressure_profile is not None:\n                self.remove_parent(self._pressure_profile)\n            self._pressure_profile = pressure_profile\n            if pressure_profile is not None:\n                self.append_parent(pressure_profile)\n                self.need_to_run_code = True\n\n    @property\n    def current_profile(self):\n        return self._current_profile\n\n    @current_profile.setter\n    def current_profile(self, current_profile):\n        if not current_profile is self._current_profile:\n            logging.debug('Replacing current_profile in setter')\n            if self._current_profile is not None:\n                self.remove_parent(self._current_profile)\n            self._current_profile = current_profile\n            if current_profile is not None:\n                self.append_parent(current_profile)\n                self.need_to_run_code = True\n\n    @property\n    def iota_profile(self):\n        return self._iota_profile\n\n    @iota_profile.setter\n    def iota_profile(self, iota_profile):\n        if not iota_profile is self._iota_profile:\n            logging.debug('Replacing iota_profile in setter')\n            if self._iota_profile is not None:\n                self.remove_parent(self._iota_profile)\n            self._iota_profile = iota_profile\n            if iota_profile is not None:\n                self.append_parent(iota_profile)\n                self.need_to_run_code = True\n\n    def get_dofs(self):\n        if not self.runnable:\n            # Use default values from vmec_input\n            return np.array([1, 1, 1, 0, 0])\n        else:\n            return np.array([self.indata.delt, self.indata.tcon0,\n                             self.indata.phiedge, self.indata.curtor,\n                             self.indata.gamma])\n\n    def set_dofs(self, x):\n        if self.runnable:\n            self.need_to_run_code = True\n            self.indata.delt = x[0]\n            self.indata.tcon0 = x[1]\n            self.indata.phiedge = x[2]\n            self.indata.curtor = x[3]\n            self.indata.gamma = x[4]\n\n    def recompute_bell(self, parent=None):\n        self.need_to_run_code = True\n\n    def set_profile(self, longname, shortname, letter):\n        \"\"\"\n        This function is used to set the pressure, current, and/or iota\n        profiles.\n        \"\"\"\n        profile = self.__getattribute__(longname + \"_profile\")\n        if profile is None:\n            return\n\n        n = self.__getattribute__(\"n_\" + longname)\n        vmec_profile_type = self.indata.__getattribute__(\"p\" + shortname + \"_type\").lower()\n        if vmec_profile_type[:12] == b'power_series':\n            # Evaluate the new Profile on a Gauss-Legendre grid in s,\n            # so the polynomial fit is well conditioned.\n            nodes, weights = np.polynomial.legendre.leggauss(n)\n            x = nodes * 0.5 + 0.5  # So x is in (0, 1)\n            y = profile(x)\n            poly = np.polynomial.polynomial.Polynomial.fit(x, y, n - 1, domain=[0, 1]).convert().coef\n            logger.debug('Setting vmec ' + longname + f' profile using power series.  x: {x}  y: {y}  poly: {poly}')\n            ax = self.indata.__getattribute__(\"a\" + letter)\n            ax[:] = 0.0\n            ax[:n] = poly\n\n        elif vmec_profile_type[:12] == b'cubic_spline' \\\n                or vmec_profile_type[:12] == b'akima_spline' \\\n                or vmec_profile_type[:12] == b'line_segment':\n            x = np.linspace(0, 1, n)\n            y = profile(x)\n            logger.debug('Setting vmec ' + longname + f' profile using splines. x: {x}  y: {y}')\n            aux_s = self.indata.__getattribute__(\"a\" + letter + \"_aux_s\")\n            aux_f = self.indata.__getattribute__(\"a\" + letter + \"_aux_f\")\n            aux_s[:] = 0.0\n            aux_f[:] = 0.0\n            aux_s[:n] = x\n            aux_f[:n] = y\n\n        else:\n            raise RuntimeError('To use a simsopt Profile class with vmec, vmec profile type must be power_series, '\n                               'cubic_spline, akima_spline, or line_segment. For current profiles, _i or _ip can be appended.')\n\n    def set_indata(self):\n        \"\"\"\n        Transfer data from simsopt objects to Vmec's fortran module data.\n        Presently, this function sets the boundary shape and magnetic\n        axis shape.  In the future, the input profiles will be set\n        here as well. This data transfer is performed before writing a\n        Vmec input file or running Vmec. The boundary surface object\n        converted to ``SurfaceRZFourier`` is returned.\n        \"\"\"\n        if not self.runnable:\n            raise RuntimeError('Cannot access indata for a Vmec object that was initialized from a wout file.')\n        vi = vmec.vmec_input  # Shorthand\n        # Convert boundary to RZFourier if needed:\n        boundary_RZFourier = self.boundary.to_RZFourier()\n        # VMEC does not allow mpol or ntor above 101:\n        if vi.mpol > 101:\n            raise ValueError(\"VMEC does not allow mpol > 101\")\n        if vi.ntor > 101:\n            raise ValueError(\"VMEC does not allow ntor > 101\")\n        vi.rbc[:, :] = 0\n        vi.zbs[:, :] = 0\n        mpol_capped = np.min([boundary_RZFourier.mpol, 101])\n        ntor_capped = np.min([boundary_RZFourier.ntor, 101])\n        # Transfer boundary shape data from the surface object to VMEC:\n        for m in range(mpol_capped + 1):\n            for n in range(-ntor_capped, ntor_capped + 1):\n                vi.rbc[101 + n, m] = boundary_RZFourier.get_rc(m, n)\n                vi.zbs[101 + n, m] = boundary_RZFourier.get_zs(m, n)\n\n        # Set axis shape to something that is obviously wrong (R=0) to\n        # trigger vmec's internal guess_axis.f to run. Otherwise the\n        # initial axis shape for run N will be the final axis shape\n        # from run N-1, which makes VMEC results depend slightly on\n        # the history of previous evaluations, confusing the finite\n        # differencing.\n        vi.raxis_cc[:] = 0\n        vi.raxis_cs[:] = 0\n        vi.zaxis_cc[:] = 0\n        vi.zaxis_cs[:] = 0\n\n        # Set profiles, if they are not None:\n        self.set_profile(\"pressure\", \"mass\", \"m\")\n        self.set_profile(\"current\", \"curr\", \"c\")\n        self.set_profile(\"iota\", \"iota\", \"i\")\n        if self.pressure_profile is not None:\n            vi.pres_scale = 1.0\n        if self.current_profile is not None:\n            integral, _ = quad(self.current_profile, 0, 1)\n            vi.curtor = integral\n\n        return boundary_RZFourier\n\n    def get_input(self):\n        \"\"\"\n        Generate a VMEC input file. The result will be returned as a\n        string. To save a file, see the ``write_input()`` function.\n        \"\"\"\n        boundary_RZFourier = self.set_indata()  # Transfer the boundary from simsopt to fortran.\n        vi = vmec.vmec_input  # Shorthand\n        nml = '&INDATA\\n'\n        nml += '! This file created by simsopt on ' + datetime.now().strftime(\"%B %d %Y, %H:%M:%S\") + '\\n\\n'\n        nml += '! ---- Geometric parameters ----\\n'\n        nml += f'NFP = {vi.nfp}\\n'\n        nml += f'LASYM = {to_namelist_bool(vi.lasym)}\\n'\n\n        if vi.lfreeb:\n            nml += '\\n! ---- Free-boundary parameters ----\\n'\n            nml += 'LFREEB = T\\n'\n            nml += f\"MGRID_FILE = '{vi.mgrid_file.decode('utf-8')}'\\n\"\n            nml += 'EXTCUR = ' + array_to_namelist(vi.extcur)\n            nml += '\\n'\n\n        nml += '\\n! ---- Resolution parameters ----\\n'\n        nml += f'MPOL = {vi.mpol}\\n'\n        nml += f'NTOR = {vi.ntor}\\n'\n        if vi.ntheta != 0:\n            nml += f'NTHETA = {vi.ntheta}\\n'\n        if vi.nzeta != 0:\n            nml += f'NZETA = {vi.nzeta}\\n'\n        index = np.max(np.nonzero(vi.ns_array))\n        nml += f'NS_ARRAY    ='\n        for j in range(index + 1):\n            nml += f'{vi.ns_array[j]:7}'\n        nml += '\\n'\n        index = np.max(np.where(vi.niter_array > 0))\n        nml += f'NITER_ARRAY ='\n        for j in range(index + 1):\n            nml += f'{vi.niter_array[j]:7}'\n        nml += '\\n'\n        index = np.max(np.nonzero(vi.ftol_array))\n        nml += f'FTOL_ARRAY  ='\n        for j in range(index + 1):\n            nml += f'{vi.ftol_array[j]:7}'\n        nml += '\\n'\n\n        nml += '\\n! ---- Boundary toroidal flux ----\\n'\n        nml += f'PHIEDGE = {vi.phiedge}\\n'\n\n        nml += '\\n! ---- Pressure profile specification ----\\n'\n        profile_type = vi.pmass_type.decode().strip()\n        nml += f'PMASS_TYPE = \"{profile_type}\"\\n'\n        nml += 'AM = ' + array_to_namelist(vi.am)\n        if np.any(vi.am_aux_s >= 0):\n            nml += 'AM_AUX_S = ' + array_to_namelist(vi.am_aux_s, True)\n            nml += 'AM_AUX_F = ' + array_to_namelist(vi.am_aux_f)\n        nml += f'PRES_SCALE = {vi.pres_scale}\\n'\n\n        nml += '\\n! ---- Profile specification of iota or current ----\\n'\n        nml += f'NCURR = {vi.ncurr}\\n'\n        if vi.ncurr == 0:\n            # Iota profile specified\n            profile_type = vi.piota_type.decode().strip()\n            nml += f'PIOTA_TYPE = \"{profile_type}\"\\n'\n            nml += 'AI = ' + array_to_namelist(vi.ai)\n            if np.any(vi.ai_aux_s >= 0):\n                nml += 'AI_AUX_S = ' + array_to_namelist(vi.ai_aux_s, True)\n                nml += 'AI_AUX_F = ' + array_to_namelist(vi.ai_aux_f)\n        else:\n            # Current profile specified\n            nml += f'CURTOR = {vi.curtor}\\n'\n            profile_type = vi.pcurr_type.decode().strip()\n            nml += f'PCURR_TYPE = \"{profile_type}\"\\n'\n            nml += 'AC = ' + array_to_namelist(vi.ac)\n            if np.any(vi.ac_aux_s >= 0):\n                nml += 'AC_AUX_S = ' + array_to_namelist(vi.ac_aux_s, True)\n                nml += 'AC_AUX_F = ' + array_to_namelist(vi.ac_aux_f)\n\n        nml += '\\n! ---- Other numerical parameters ----\\n'\n        nml += f'DELT = {vi.delt}\\n'\n        nml += f'NSTEP = {vi.nstep}\\n'\n\n        nml += '\\n! ---- Boundary shape. Array index order is (n, m) ----\\n'\n        surf_str = boundary_RZFourier.get_nml().split('\\n')\n        for j in range(3, len(surf_str)):\n            nml += surf_str[j] + '\\n'\n\n        return nml\n\n    def write_input(self, filename):\n        \"\"\"\n        Write a VMEC input file. To just get the result as a string\n        without saving a file, see the ``get_input()`` function.\n\n        Args:\n            filename: Name of the file to write. Selected MPI processes can pass\n              ``None`` if you wish for these processes to not write a file.\n        \"\"\"\n        # All procs should call self.get_input() so set_indata() gets\n        # called, even procs that do not directly write the file:\n        input_namelist = self.get_input()\n        if self.mpi.proc0_groups and (filename is not None):\n            with open(filename, 'w') as f:\n                f.write(input_namelist)\n\n    def run(self):\n        \"\"\"\n        Run VMEC, if ``need_to_run_code`` is ``True``.\n        \"\"\"\n        if not self.need_to_run_code:\n            logger.info(\"run() called but no need to re-run VMEC.\")\n            return\n\n        if not self.runnable:\n            raise RuntimeError('Cannot run a Vmec object that was initialized from a wout file.')\n\n        logger.info(\"Preparing to run VMEC.\")\n\n        self.iter += 1\n        base_filename = self.input_file + '_{:03d}_{:06d}'.format(\n            self.mpi.group, self.iter)\n        input_file = os.path.join(\n            os.getcwd(),\n            os.path.basename(base_filename))\n        self.output_file = os.path.join(\n            os.getcwd(),\n            os.path.basename(base_filename).replace('input.', 'wout_') + '.nc')\n        mercier_file = os.path.join(\n            os.getcwd(),\n            os.path.basename(base_filename).replace('input.', 'mercier.'))\n        jxbout_file = os.path.join(\n            os.getcwd(),\n            os.path.basename(base_filename).replace('input.', 'jxbout_') + '.nc')\n\n        file_to_write = input_file if (self.mpi.proc0_world or self.keep_all_files) else None\n        # This next line also calls set_indata():\n        self.write_input(file_to_write)\n\n        logger.info(\"Calling VMEC reinit().\")\n        vmec.reinit()\n\n        logger.info(\"Calling runvmec().\")\n        self.ictrl[0] = restart_flag + reset_jacdt_flag \\\n            + timestep_flag + output_flag\n        self.ictrl[1] = 0  # ierr\n        self.ictrl[2] = 0  # numsteps\n        self.ictrl[3] = 0  # ns_index\n        self.ictrl[4] = 0  # iseq\n        reset_file = ''\n        vmec.runvmec(self.ictrl, input_file, self.verbose, self.fcomm, reset_file)\n        ierr = self.ictrl[1]\n\n        # Deallocate arrays, even if vmec did not converge:\n        logger.info(\"Calling VMEC cleanup().\")\n        vmec.cleanup(True)\n\n        # See VMEC2000/Sources/General/vmec_params.f for ierr codes.\n        # 11 = successful_term_flag.\n        # Error codes that are expected to occur due to lack of\n        # convergence cause ObjectiveFailure, which the optimizer\n        # handles gracefully by treating the point as bad. But the\n        # user/developer should know if an error codes arises that\n        # should logically never occur, so these codes raise a\n        # different exception.\n        if ierr in [0, 5]:\n            raise RuntimeError(f\"runvmec returned an error code that should \" \\\n                               \"never occur: ierr={ierr}\")\n        if ierr != 11:\n            raise ObjectiveFailure(f\"VMEC did not converge. ierr={ierr}\")\n\n        logger.info(\"VMEC run complete. Now loading output.\")\n        self.load_wout()\n        # Make sure all procs have finished loading the wout file before we delete it:\n        self.mpi.comm_groups.barrier()\n        logger.info(\"Done loading VMEC output.\")\n\n        # Group leaders handle deletion of files:\n        if self.mpi.proc0_groups:\n            # Delete some files produced by VMEC that we never care\n            # about. For some reason the os.remove statements give a 'file\n            # not found' error in the CI, hence the try-except blocks.\n            try:\n                os.remove(mercier_file)\n            except FileNotFoundError:\n                logger.debug(f'Tried to delete the file {mercier_file} but it was not found')\n                raise\n\n            try:\n                os.remove(jxbout_file)\n            except FileNotFoundError:\n                logger.debug(f'Tried to delete the file {jxbout_file} but it was not found')\n                raise\n\n            try:\n                os.remove(\"fort.9\")\n            except FileNotFoundError:\n                logger.debug('Tried to delete the file fort.9 but it was not found')\n\n            # If the worker group is not 0, delete all wout files, unless\n            # keep_all_files is True:\n            if (not self.keep_all_files) and (self.mpi.group > 0):\n                os.remove(self.output_file)\n\n            # Delete the previous output file, if desired:\n            for filename in self.files_to_delete:\n                os.remove(filename)\n            self.files_to_delete = []\n\n            # Record the latest output file to delete if we run again:\n            if (self.mpi.group == 0) and (self.iter > 0) and (not self.keep_all_files):\n                self.files_to_delete += [input_file, self.output_file]\n\n        self.need_to_run_code = False\n\n    def load_wout(self):\n        \"\"\"\n        Read in the most recent ``wout`` file created, and store all the\n        data in a ``wout`` attribute of this Vmec object.\n        \"\"\"\n        ierr = 0\n        logger.info(f\"Attempting to read file {self.output_file}\")\n\n        with netcdf_file(self.output_file, mmap=False) as f:\n            for key, val in f.variables.items():\n                # 2D arrays need to be transposed.\n                val2 = val[()]  # Convert to numpy array\n                val3 = val2.T if len(val2.shape) == 2 else val2\n                self.wout.__setattr__(key, val3)\n\n            if self.wout.ier_flag != 0:\n                logger.info(\"VMEC did not succeed!\")\n                raise ObjectiveFailure(\"VMEC did not succeed\")\n\n            # Shorthand for a long variable name:\n            self.wout.lasym = f.variables['lasym__logical__'][()]\n            self.wout.volume = self.wout.volume_p\n\n        self.s_full_grid = np.linspace(0, 1, self.wout.ns)\n        self.ds = self.s_full_grid[1] - self.s_full_grid[0]\n        self.s_half_grid = self.s_full_grid[1:] - 0.5 * self.ds\n\n        return ierr\n\n    def update_mpi(self, new_mpi):\n        \"\"\"\n        Replace the :obj:`~simsopt.util.mpi.MpiPartition` with a new one.\n\n        Args:\n            new_mpi: A new :obj:`simsopt.util.mpi.MpiPartition` object.\n        \"\"\"\n        self.mpi = new_mpi\n        self.fcomm = self.mpi.comm_groups.py2f()\n        # Synchronize iteration counters. If we don't do this,\n        # different procs within a group may have different values of\n        # ``iter``, causing them to look for different wout files.\n        self.iter = self.mpi.comm_world.bcast(self.iter)\n\n    def aspect(self):\n        \"\"\"\n        Return the plasma aspect ratio.\n        \"\"\"\n        self.run()\n        return self.wout.aspect\n\n    def volume(self):\n        \"\"\"\n        Return the volume inside the VMEC last closed flux surface.\n        \"\"\"\n        self.run()\n        return self.wout.volume\n\n    def iota_axis(self):\n        \"\"\"\n        Return the rotational transform on axis\n        \"\"\"\n        self.run()\n        return self.wout.iotaf[0]\n\n    def iota_edge(self):\n        \"\"\"\n        Return the rotational transform at the boundary\n        \"\"\"\n        self.run()\n        return self.wout.iotaf[-1]\n\n    def mean_iota(self):\n        \"\"\"\n        Return the mean rotational transform. The average is taken over\n        the normalized toroidal flux s.\n        \"\"\"\n        self.run()\n        return np.mean(self.wout.iotas[1:])\n\n    def mean_shear(self):\n        \"\"\"\n        Return an average magnetic shear, d(iota)/ds, where s is the\n        normalized toroidal flux. This is computed by fitting the\n        rotational transform to a linear (plus constant) function in\n        s. The slope of this fit function is returned.\n        \"\"\"\n        self.run()\n\n        # Fit a linear polynomial:\n        poly = np.polynomial.Polynomial.fit(self.s_half_grid,\n                                            self.wout.iotas[1:], deg=1)\n        # Return the slope:\n        return poly.deriv()(0)\n\n    def get_max_mn(self):\n        \"\"\"\n        Look through the rbc and zbs data in fortran to determine the\n        largest m and n for which rbc or zbs is nonzero.\n        \"\"\"\n        max_m = 0\n        max_n = 0\n        for m in range(1, 101):\n            for n in range(1, 101):\n                if np.abs(vmec.vmec_input.rbc[101 + n, m]) > 0 \\\n                        or np.abs(vmec.vmec_input.zbs[101 + n, m]) > 0 \\\n                        or np.abs(vmec.vmec_input.rbs[101 + n, m]) > 0 \\\n                        or np.abs(vmec.vmec_input.zbc[101 + n, m]) > 0 \\\n                        or np.abs(vmec.vmec_input.rbc[101 - n, m]) > 0 \\\n                        or np.abs(vmec.vmec_input.zbs[101 - n, m]) > 0 \\\n                        or np.abs(vmec.vmec_input.rbs[101 - n, m]) > 0 \\\n                        or np.abs(vmec.vmec_input.zbc[101 - n, m]) > 0:\n                    max_m = np.max((max_m, m))\n                    max_n = np.max((max_n, n))\n        # It may happen that mpol or ntor exceed the max_m or max_n\n        # according to rbc/zbs. In this case, go with the larger\n        # value.\n        max_m = np.max((max_m, vmec.vmec_input.mpol))\n        max_n = np.max((max_n, vmec.vmec_input.ntor))\n        return (max_m, max_n)\n\n    def __repr__(self):\n        \"\"\"\n        Print the object in an informative way.\n        \"\"\"\n        return f\"{self.name} (nfp={self.indata.nfp} mpol={self.indata.mpol}\" + \\\n               f\" ntor={self.indata.ntor})\"\n\n    def external_current(self):\n        \"\"\"\n        Return the total electric current associated with external\n        currents, i.e. the current through the \"doughnut hole\". This\n        number is useful for coil optimization, to know what the sum\n        of the coil currents must be.\n\n        Returns:\n            float with the total external electric current in Amperes.\n        \"\"\"\n        self.run()\n        bvco = self.wout.bvco[-1] * 1.5 - self.wout.bvco[-2] * 0.5\n        mu0 = 4 * np.pi * (1.0e-7)\n        # The formula in the next line follows from Ampere's law:\n        # \\int \\vec{B} dot (d\\vec{r} / d phi) d phi = mu_0 I.\n        return 2 * np.pi * bvco / mu0\n\n    def vacuum_well(self):\n        \"\"\"\n        Compute a single number W that summarizes the vacuum magnetic well,\n        given by the formula\n\n        W = (dV/ds(s=0) - dV/ds(s=1)) / (dV/ds(s=0)\n\n        where dVds is the derivative of the flux surface volume with\n        respect to the radial coordinate s. Positive values of W are\n        favorable for stability to interchange modes. This formula for\n        W is motivated by the fact that\n\n        d^2 V / d s^2 < 0\n\n        is favorable for stability. Integrating over s from 0 to 1\n        and normalizing gives the above formula for W. Notice that W\n        is dimensionless, and it scales as the square of the minor\n        radius. To compute dV/ds, we use\n\n        dV/ds = 4 * pi**2 * abs(sqrt(g)_{0,0})\n\n        where sqrt(g) is the Jacobian of (s, theta, phi) coordinates,\n        computed by VMEC in the gmnc array, and _{0,0} indicates the\n        m=n=0 Fourier component. Since gmnc is reported by VMEC on the\n        half mesh, we extrapolate by half of a radial grid point to s\n        = 0 and 1.\n        \"\"\"\n        self.run()\n\n        # gmnc is on the half mesh, so drop the 0th radial entry:\n        dVds = 4 * np.pi * np.pi * np.abs(self.wout.gmnc[0, 1:])\n\n        # To get from the half grid to s=0 and s=1, we must\n        # extrapolate by 1/2 of a radial grid point:\n        dVds_s0 = 1.5 * dVds[0] - 0.5 * dVds[1]\n        dVds_s1 = 1.5 * dVds[-1] - 0.5 * dVds[-2]\n\n        well = (dVds_s0 - dVds_s1) / dVds_s0\n        return well\n\n    return_fn_map = {'aspect': aspect, 'volume': volume, 'iota_axis': iota_axis,\n                     'iota_edge': iota_edge, 'mean_iota': mean_iota,\n                     'mean_shear': mean_shear, 'vacuum_well': vacuum_well}",
  "def __init__(self,\n                 filename: Optional[str] = None,\n                 mpi: Optional[MpiPartition] = None,\n                 keep_all_files: bool = False,\n                 verbose: bool = True,\n                 ntheta=50,\n                 nphi=50,\n                 range_surface='full torus'):\n\n        if filename is None:\n            # Read default input file, which should be in the same\n            # directory as this file:\n            filename = os.path.join(os.path.dirname(__file__), 'input.default')\n            logger.info(f\"Initializing a VMEC object from defaults in {filename}\")\n\n        basename = os.path.basename(filename)\n        if basename[:5] == 'input':\n            logger.info(f\"Initializing a VMEC object from input file: {filename}\")\n            self.input_file = filename\n            self.runnable = True\n        elif basename[:4] == 'wout':\n            logger.info(f\"Initializing a VMEC object from wout file: {filename}\")\n            self.runnable = False\n        else:\n            raise ValueError('Invalid filename')\n\n        self.wout = Struct()\n        self.verbose = verbose\n\n        # Get MPI communicator:\n        if (mpi is None and MPI is not None):\n            self.mpi = MpiPartition(ngroups=1)\n        else:\n            self.mpi = mpi\n\n        self._pressure_profile = None\n        self._current_profile = None\n        self._iota_profile = None\n        self.n_pressure = 10\n        self.n_current = 10\n        self.n_iota = 10\n\n        if self.runnable:\n            if MPI is None:\n                raise RuntimeError(\"mpi4py needs to be installed for running VMEC\")\n            if vmec is None:\n                raise RuntimeError(\n                    \"Running VMEC from simsopt requires VMEC python extension. \"\n                    \"Install the VMEC python extension from \"\n                    \"https://https://github.com/hiddenSymmetries/VMEC2000\")\n\n            comm = self.mpi.comm_groups\n            self.fcomm = comm.py2f()\n\n            self.ictrl = np.zeros(5, dtype=np.int32)\n            self.iter = -1\n            self.keep_all_files = keep_all_files\n            self.files_to_delete = []\n\n            self.indata = vmec.vmec_input  # Shorthand\n            vi = vmec.vmec_input  # Shorthand\n\n            self.ictrl[0] = restart_flag + readin_flag\n            self.ictrl[1] = 0  # ierr\n            self.ictrl[2] = 0  # numsteps\n            self.ictrl[3] = 0  # ns_index\n            self.ictrl[4] = 0  # iseq\n            reset_file = ''\n            logger.info('About to call runvmec to readin')\n            vmec.runvmec(self.ictrl, filename, self.verbose, self.fcomm, reset_file)\n            ierr = self.ictrl[1]\n            logger.info('Done with runvmec. ierr={}. Calling cleanup next.'.format(ierr))\n            # Deallocate arrays allocated by VMEC's fixaray():\n            vmec.cleanup(False)\n            if ierr != 0:\n                raise RuntimeError(\"Failed to initialize VMEC from input file {}. \"\n                                   \"error code {}\".format(filename, ierr))\n\n            objstr = \" for Vmec \" + str(hex(id(self)))\n\n            # A vmec object has mpol and ntor attributes independent of\n            # the boundary. The boundary surface object is initialized\n            # with mpol and ntor values that match those of the vmec\n            # object, but the mpol/ntor values of either the vmec object\n            # or the boundary surface object can be changed independently\n            # by the user.\n            self._boundary = SurfaceRZFourier.from_nphi_ntheta(nfp=vi.nfp,\n                                                               stellsym=not vi.lasym,\n                                                               mpol=vi.mpol,\n                                                               ntor=vi.ntor,\n                                                               ntheta=ntheta,\n                                                               nphi=nphi,\n                                                               range=range_surface)\n            self.free_boundary = bool(vi.lfreeb)\n\n            # Transfer boundary shape data from fortran to the ParameterArray:\n            for m in range(vi.mpol + 1):\n                for n in range(-vi.ntor, vi.ntor + 1):\n                    self._boundary.rc[m, n + vi.ntor] = vi.rbc[101 + n, m]\n                    self._boundary.zs[m, n + vi.ntor] = vi.zbs[101 + n, m]\n                    if vi.lasym:\n                        self._boundary.rs[m, n + vi.ntor] = vi.rbs[101 + n, m]\n                        self._boundary.zc[m, n + vi.ntor] = vi.zbc[101 + n, m]\n            self._boundary.local_full_x = self._boundary.get_dofs()\n\n            self.need_to_run_code = True\n        else:\n            # Initialized from a wout file, so not runnable.\n            self._boundary = SurfaceRZFourier.from_wout(filename, nphi=nphi, ntheta=ntheta, range=range_surface)\n            self.output_file = filename\n            self.load_wout()\n\n        # Handle a few variables that are not Parameters:\n        x0 = self.get_dofs()\n        fixed = np.full(len(x0), True)\n        names = ['delt', 'tcon0', 'phiedge', 'curtor', 'gamma']\n        super().__init__(x0=x0, fixed=fixed, names=names,\n                         depends_on=[self._boundary],\n                         external_dof_setter=Vmec.set_dofs)\n\n        if not self.runnable:\n            # This next line must come after Optimizable.__init__\n            # since that calls recompute_bell()\n            self.need_to_run_code = False",
  "def boundary(self):\n        return self._boundary",
  "def boundary(self, boundary):\n        if not boundary is self._boundary:\n            logging.debug('Replacing surface in boundary setter')\n            self.remove_parent(self._boundary)\n            self._boundary = boundary\n            self.append_parent(boundary)\n            self.need_to_run_code = True",
  "def pressure_profile(self):\n        return self._pressure_profile",
  "def pressure_profile(self, pressure_profile):\n        if not pressure_profile is self._pressure_profile:\n            logging.debug('Replacing pressure_profile in setter')\n            if self._pressure_profile is not None:\n                self.remove_parent(self._pressure_profile)\n            self._pressure_profile = pressure_profile\n            if pressure_profile is not None:\n                self.append_parent(pressure_profile)\n                self.need_to_run_code = True",
  "def current_profile(self):\n        return self._current_profile",
  "def current_profile(self, current_profile):\n        if not current_profile is self._current_profile:\n            logging.debug('Replacing current_profile in setter')\n            if self._current_profile is not None:\n                self.remove_parent(self._current_profile)\n            self._current_profile = current_profile\n            if current_profile is not None:\n                self.append_parent(current_profile)\n                self.need_to_run_code = True",
  "def iota_profile(self):\n        return self._iota_profile",
  "def iota_profile(self, iota_profile):\n        if not iota_profile is self._iota_profile:\n            logging.debug('Replacing iota_profile in setter')\n            if self._iota_profile is not None:\n                self.remove_parent(self._iota_profile)\n            self._iota_profile = iota_profile\n            if iota_profile is not None:\n                self.append_parent(iota_profile)\n                self.need_to_run_code = True",
  "def get_dofs(self):\n        if not self.runnable:\n            # Use default values from vmec_input\n            return np.array([1, 1, 1, 0, 0])\n        else:\n            return np.array([self.indata.delt, self.indata.tcon0,\n                             self.indata.phiedge, self.indata.curtor,\n                             self.indata.gamma])",
  "def set_dofs(self, x):\n        if self.runnable:\n            self.need_to_run_code = True\n            self.indata.delt = x[0]\n            self.indata.tcon0 = x[1]\n            self.indata.phiedge = x[2]\n            self.indata.curtor = x[3]\n            self.indata.gamma = x[4]",
  "def recompute_bell(self, parent=None):\n        self.need_to_run_code = True",
  "def set_profile(self, longname, shortname, letter):\n        \"\"\"\n        This function is used to set the pressure, current, and/or iota\n        profiles.\n        \"\"\"\n        profile = self.__getattribute__(longname + \"_profile\")\n        if profile is None:\n            return\n\n        n = self.__getattribute__(\"n_\" + longname)\n        vmec_profile_type = self.indata.__getattribute__(\"p\" + shortname + \"_type\").lower()\n        if vmec_profile_type[:12] == b'power_series':\n            # Evaluate the new Profile on a Gauss-Legendre grid in s,\n            # so the polynomial fit is well conditioned.\n            nodes, weights = np.polynomial.legendre.leggauss(n)\n            x = nodes * 0.5 + 0.5  # So x is in (0, 1)\n            y = profile(x)\n            poly = np.polynomial.polynomial.Polynomial.fit(x, y, n - 1, domain=[0, 1]).convert().coef\n            logger.debug('Setting vmec ' + longname + f' profile using power series.  x: {x}  y: {y}  poly: {poly}')\n            ax = self.indata.__getattribute__(\"a\" + letter)\n            ax[:] = 0.0\n            ax[:n] = poly\n\n        elif vmec_profile_type[:12] == b'cubic_spline' \\\n                or vmec_profile_type[:12] == b'akima_spline' \\\n                or vmec_profile_type[:12] == b'line_segment':\n            x = np.linspace(0, 1, n)\n            y = profile(x)\n            logger.debug('Setting vmec ' + longname + f' profile using splines. x: {x}  y: {y}')\n            aux_s = self.indata.__getattribute__(\"a\" + letter + \"_aux_s\")\n            aux_f = self.indata.__getattribute__(\"a\" + letter + \"_aux_f\")\n            aux_s[:] = 0.0\n            aux_f[:] = 0.0\n            aux_s[:n] = x\n            aux_f[:n] = y\n\n        else:\n            raise RuntimeError('To use a simsopt Profile class with vmec, vmec profile type must be power_series, '\n                               'cubic_spline, akima_spline, or line_segment. For current profiles, _i or _ip can be appended.')",
  "def set_indata(self):\n        \"\"\"\n        Transfer data from simsopt objects to Vmec's fortran module data.\n        Presently, this function sets the boundary shape and magnetic\n        axis shape.  In the future, the input profiles will be set\n        here as well. This data transfer is performed before writing a\n        Vmec input file or running Vmec. The boundary surface object\n        converted to ``SurfaceRZFourier`` is returned.\n        \"\"\"\n        if not self.runnable:\n            raise RuntimeError('Cannot access indata for a Vmec object that was initialized from a wout file.')\n        vi = vmec.vmec_input  # Shorthand\n        # Convert boundary to RZFourier if needed:\n        boundary_RZFourier = self.boundary.to_RZFourier()\n        # VMEC does not allow mpol or ntor above 101:\n        if vi.mpol > 101:\n            raise ValueError(\"VMEC does not allow mpol > 101\")\n        if vi.ntor > 101:\n            raise ValueError(\"VMEC does not allow ntor > 101\")\n        vi.rbc[:, :] = 0\n        vi.zbs[:, :] = 0\n        mpol_capped = np.min([boundary_RZFourier.mpol, 101])\n        ntor_capped = np.min([boundary_RZFourier.ntor, 101])\n        # Transfer boundary shape data from the surface object to VMEC:\n        for m in range(mpol_capped + 1):\n            for n in range(-ntor_capped, ntor_capped + 1):\n                vi.rbc[101 + n, m] = boundary_RZFourier.get_rc(m, n)\n                vi.zbs[101 + n, m] = boundary_RZFourier.get_zs(m, n)\n\n        # Set axis shape to something that is obviously wrong (R=0) to\n        # trigger vmec's internal guess_axis.f to run. Otherwise the\n        # initial axis shape for run N will be the final axis shape\n        # from run N-1, which makes VMEC results depend slightly on\n        # the history of previous evaluations, confusing the finite\n        # differencing.\n        vi.raxis_cc[:] = 0\n        vi.raxis_cs[:] = 0\n        vi.zaxis_cc[:] = 0\n        vi.zaxis_cs[:] = 0\n\n        # Set profiles, if they are not None:\n        self.set_profile(\"pressure\", \"mass\", \"m\")\n        self.set_profile(\"current\", \"curr\", \"c\")\n        self.set_profile(\"iota\", \"iota\", \"i\")\n        if self.pressure_profile is not None:\n            vi.pres_scale = 1.0\n        if self.current_profile is not None:\n            integral, _ = quad(self.current_profile, 0, 1)\n            vi.curtor = integral\n\n        return boundary_RZFourier",
  "def get_input(self):\n        \"\"\"\n        Generate a VMEC input file. The result will be returned as a\n        string. To save a file, see the ``write_input()`` function.\n        \"\"\"\n        boundary_RZFourier = self.set_indata()  # Transfer the boundary from simsopt to fortran.\n        vi = vmec.vmec_input  # Shorthand\n        nml = '&INDATA\\n'\n        nml += '! This file created by simsopt on ' + datetime.now().strftime(\"%B %d %Y, %H:%M:%S\") + '\\n\\n'\n        nml += '! ---- Geometric parameters ----\\n'\n        nml += f'NFP = {vi.nfp}\\n'\n        nml += f'LASYM = {to_namelist_bool(vi.lasym)}\\n'\n\n        if vi.lfreeb:\n            nml += '\\n! ---- Free-boundary parameters ----\\n'\n            nml += 'LFREEB = T\\n'\n            nml += f\"MGRID_FILE = '{vi.mgrid_file.decode('utf-8')}'\\n\"\n            nml += 'EXTCUR = ' + array_to_namelist(vi.extcur)\n            nml += '\\n'\n\n        nml += '\\n! ---- Resolution parameters ----\\n'\n        nml += f'MPOL = {vi.mpol}\\n'\n        nml += f'NTOR = {vi.ntor}\\n'\n        if vi.ntheta != 0:\n            nml += f'NTHETA = {vi.ntheta}\\n'\n        if vi.nzeta != 0:\n            nml += f'NZETA = {vi.nzeta}\\n'\n        index = np.max(np.nonzero(vi.ns_array))\n        nml += f'NS_ARRAY    ='\n        for j in range(index + 1):\n            nml += f'{vi.ns_array[j]:7}'\n        nml += '\\n'\n        index = np.max(np.where(vi.niter_array > 0))\n        nml += f'NITER_ARRAY ='\n        for j in range(index + 1):\n            nml += f'{vi.niter_array[j]:7}'\n        nml += '\\n'\n        index = np.max(np.nonzero(vi.ftol_array))\n        nml += f'FTOL_ARRAY  ='\n        for j in range(index + 1):\n            nml += f'{vi.ftol_array[j]:7}'\n        nml += '\\n'\n\n        nml += '\\n! ---- Boundary toroidal flux ----\\n'\n        nml += f'PHIEDGE = {vi.phiedge}\\n'\n\n        nml += '\\n! ---- Pressure profile specification ----\\n'\n        profile_type = vi.pmass_type.decode().strip()\n        nml += f'PMASS_TYPE = \"{profile_type}\"\\n'\n        nml += 'AM = ' + array_to_namelist(vi.am)\n        if np.any(vi.am_aux_s >= 0):\n            nml += 'AM_AUX_S = ' + array_to_namelist(vi.am_aux_s, True)\n            nml += 'AM_AUX_F = ' + array_to_namelist(vi.am_aux_f)\n        nml += f'PRES_SCALE = {vi.pres_scale}\\n'\n\n        nml += '\\n! ---- Profile specification of iota or current ----\\n'\n        nml += f'NCURR = {vi.ncurr}\\n'\n        if vi.ncurr == 0:\n            # Iota profile specified\n            profile_type = vi.piota_type.decode().strip()\n            nml += f'PIOTA_TYPE = \"{profile_type}\"\\n'\n            nml += 'AI = ' + array_to_namelist(vi.ai)\n            if np.any(vi.ai_aux_s >= 0):\n                nml += 'AI_AUX_S = ' + array_to_namelist(vi.ai_aux_s, True)\n                nml += 'AI_AUX_F = ' + array_to_namelist(vi.ai_aux_f)\n        else:\n            # Current profile specified\n            nml += f'CURTOR = {vi.curtor}\\n'\n            profile_type = vi.pcurr_type.decode().strip()\n            nml += f'PCURR_TYPE = \"{profile_type}\"\\n'\n            nml += 'AC = ' + array_to_namelist(vi.ac)\n            if np.any(vi.ac_aux_s >= 0):\n                nml += 'AC_AUX_S = ' + array_to_namelist(vi.ac_aux_s, True)\n                nml += 'AC_AUX_F = ' + array_to_namelist(vi.ac_aux_f)\n\n        nml += '\\n! ---- Other numerical parameters ----\\n'\n        nml += f'DELT = {vi.delt}\\n'\n        nml += f'NSTEP = {vi.nstep}\\n'\n\n        nml += '\\n! ---- Boundary shape. Array index order is (n, m) ----\\n'\n        surf_str = boundary_RZFourier.get_nml().split('\\n')\n        for j in range(3, len(surf_str)):\n            nml += surf_str[j] + '\\n'\n\n        return nml",
  "def write_input(self, filename):\n        \"\"\"\n        Write a VMEC input file. To just get the result as a string\n        without saving a file, see the ``get_input()`` function.\n\n        Args:\n            filename: Name of the file to write. Selected MPI processes can pass\n              ``None`` if you wish for these processes to not write a file.\n        \"\"\"\n        # All procs should call self.get_input() so set_indata() gets\n        # called, even procs that do not directly write the file:\n        input_namelist = self.get_input()\n        if self.mpi.proc0_groups and (filename is not None):\n            with open(filename, 'w') as f:\n                f.write(input_namelist)",
  "def run(self):\n        \"\"\"\n        Run VMEC, if ``need_to_run_code`` is ``True``.\n        \"\"\"\n        if not self.need_to_run_code:\n            logger.info(\"run() called but no need to re-run VMEC.\")\n            return\n\n        if not self.runnable:\n            raise RuntimeError('Cannot run a Vmec object that was initialized from a wout file.')\n\n        logger.info(\"Preparing to run VMEC.\")\n\n        self.iter += 1\n        base_filename = self.input_file + '_{:03d}_{:06d}'.format(\n            self.mpi.group, self.iter)\n        input_file = os.path.join(\n            os.getcwd(),\n            os.path.basename(base_filename))\n        self.output_file = os.path.join(\n            os.getcwd(),\n            os.path.basename(base_filename).replace('input.', 'wout_') + '.nc')\n        mercier_file = os.path.join(\n            os.getcwd(),\n            os.path.basename(base_filename).replace('input.', 'mercier.'))\n        jxbout_file = os.path.join(\n            os.getcwd(),\n            os.path.basename(base_filename).replace('input.', 'jxbout_') + '.nc')\n\n        file_to_write = input_file if (self.mpi.proc0_world or self.keep_all_files) else None\n        # This next line also calls set_indata():\n        self.write_input(file_to_write)\n\n        logger.info(\"Calling VMEC reinit().\")\n        vmec.reinit()\n\n        logger.info(\"Calling runvmec().\")\n        self.ictrl[0] = restart_flag + reset_jacdt_flag \\\n            + timestep_flag + output_flag\n        self.ictrl[1] = 0  # ierr\n        self.ictrl[2] = 0  # numsteps\n        self.ictrl[3] = 0  # ns_index\n        self.ictrl[4] = 0  # iseq\n        reset_file = ''\n        vmec.runvmec(self.ictrl, input_file, self.verbose, self.fcomm, reset_file)\n        ierr = self.ictrl[1]\n\n        # Deallocate arrays, even if vmec did not converge:\n        logger.info(\"Calling VMEC cleanup().\")\n        vmec.cleanup(True)\n\n        # See VMEC2000/Sources/General/vmec_params.f for ierr codes.\n        # 11 = successful_term_flag.\n        # Error codes that are expected to occur due to lack of\n        # convergence cause ObjectiveFailure, which the optimizer\n        # handles gracefully by treating the point as bad. But the\n        # user/developer should know if an error codes arises that\n        # should logically never occur, so these codes raise a\n        # different exception.\n        if ierr in [0, 5]:\n            raise RuntimeError(f\"runvmec returned an error code that should \" \\\n                               \"never occur: ierr={ierr}\")\n        if ierr != 11:\n            raise ObjectiveFailure(f\"VMEC did not converge. ierr={ierr}\")\n\n        logger.info(\"VMEC run complete. Now loading output.\")\n        self.load_wout()\n        # Make sure all procs have finished loading the wout file before we delete it:\n        self.mpi.comm_groups.barrier()\n        logger.info(\"Done loading VMEC output.\")\n\n        # Group leaders handle deletion of files:\n        if self.mpi.proc0_groups:\n            # Delete some files produced by VMEC that we never care\n            # about. For some reason the os.remove statements give a 'file\n            # not found' error in the CI, hence the try-except blocks.\n            try:\n                os.remove(mercier_file)\n            except FileNotFoundError:\n                logger.debug(f'Tried to delete the file {mercier_file} but it was not found')\n                raise\n\n            try:\n                os.remove(jxbout_file)\n            except FileNotFoundError:\n                logger.debug(f'Tried to delete the file {jxbout_file} but it was not found')\n                raise\n\n            try:\n                os.remove(\"fort.9\")\n            except FileNotFoundError:\n                logger.debug('Tried to delete the file fort.9 but it was not found')\n\n            # If the worker group is not 0, delete all wout files, unless\n            # keep_all_files is True:\n            if (not self.keep_all_files) and (self.mpi.group > 0):\n                os.remove(self.output_file)\n\n            # Delete the previous output file, if desired:\n            for filename in self.files_to_delete:\n                os.remove(filename)\n            self.files_to_delete = []\n\n            # Record the latest output file to delete if we run again:\n            if (self.mpi.group == 0) and (self.iter > 0) and (not self.keep_all_files):\n                self.files_to_delete += [input_file, self.output_file]\n\n        self.need_to_run_code = False",
  "def load_wout(self):\n        \"\"\"\n        Read in the most recent ``wout`` file created, and store all the\n        data in a ``wout`` attribute of this Vmec object.\n        \"\"\"\n        ierr = 0\n        logger.info(f\"Attempting to read file {self.output_file}\")\n\n        with netcdf_file(self.output_file, mmap=False) as f:\n            for key, val in f.variables.items():\n                # 2D arrays need to be transposed.\n                val2 = val[()]  # Convert to numpy array\n                val3 = val2.T if len(val2.shape) == 2 else val2\n                self.wout.__setattr__(key, val3)\n\n            if self.wout.ier_flag != 0:\n                logger.info(\"VMEC did not succeed!\")\n                raise ObjectiveFailure(\"VMEC did not succeed\")\n\n            # Shorthand for a long variable name:\n            self.wout.lasym = f.variables['lasym__logical__'][()]\n            self.wout.volume = self.wout.volume_p\n\n        self.s_full_grid = np.linspace(0, 1, self.wout.ns)\n        self.ds = self.s_full_grid[1] - self.s_full_grid[0]\n        self.s_half_grid = self.s_full_grid[1:] - 0.5 * self.ds\n\n        return ierr",
  "def update_mpi(self, new_mpi):\n        \"\"\"\n        Replace the :obj:`~simsopt.util.mpi.MpiPartition` with a new one.\n\n        Args:\n            new_mpi: A new :obj:`simsopt.util.mpi.MpiPartition` object.\n        \"\"\"\n        self.mpi = new_mpi\n        self.fcomm = self.mpi.comm_groups.py2f()\n        # Synchronize iteration counters. If we don't do this,\n        # different procs within a group may have different values of\n        # ``iter``, causing them to look for different wout files.\n        self.iter = self.mpi.comm_world.bcast(self.iter)",
  "def aspect(self):\n        \"\"\"\n        Return the plasma aspect ratio.\n        \"\"\"\n        self.run()\n        return self.wout.aspect",
  "def volume(self):\n        \"\"\"\n        Return the volume inside the VMEC last closed flux surface.\n        \"\"\"\n        self.run()\n        return self.wout.volume",
  "def iota_axis(self):\n        \"\"\"\n        Return the rotational transform on axis\n        \"\"\"\n        self.run()\n        return self.wout.iotaf[0]",
  "def iota_edge(self):\n        \"\"\"\n        Return the rotational transform at the boundary\n        \"\"\"\n        self.run()\n        return self.wout.iotaf[-1]",
  "def mean_iota(self):\n        \"\"\"\n        Return the mean rotational transform. The average is taken over\n        the normalized toroidal flux s.\n        \"\"\"\n        self.run()\n        return np.mean(self.wout.iotas[1:])",
  "def mean_shear(self):\n        \"\"\"\n        Return an average magnetic shear, d(iota)/ds, where s is the\n        normalized toroidal flux. This is computed by fitting the\n        rotational transform to a linear (plus constant) function in\n        s. The slope of this fit function is returned.\n        \"\"\"\n        self.run()\n\n        # Fit a linear polynomial:\n        poly = np.polynomial.Polynomial.fit(self.s_half_grid,\n                                            self.wout.iotas[1:], deg=1)\n        # Return the slope:\n        return poly.deriv()(0)",
  "def get_max_mn(self):\n        \"\"\"\n        Look through the rbc and zbs data in fortran to determine the\n        largest m and n for which rbc or zbs is nonzero.\n        \"\"\"\n        max_m = 0\n        max_n = 0\n        for m in range(1, 101):\n            for n in range(1, 101):\n                if np.abs(vmec.vmec_input.rbc[101 + n, m]) > 0 \\\n                        or np.abs(vmec.vmec_input.zbs[101 + n, m]) > 0 \\\n                        or np.abs(vmec.vmec_input.rbs[101 + n, m]) > 0 \\\n                        or np.abs(vmec.vmec_input.zbc[101 + n, m]) > 0 \\\n                        or np.abs(vmec.vmec_input.rbc[101 - n, m]) > 0 \\\n                        or np.abs(vmec.vmec_input.zbs[101 - n, m]) > 0 \\\n                        or np.abs(vmec.vmec_input.rbs[101 - n, m]) > 0 \\\n                        or np.abs(vmec.vmec_input.zbc[101 - n, m]) > 0:\n                    max_m = np.max((max_m, m))\n                    max_n = np.max((max_n, n))\n        # It may happen that mpol or ntor exceed the max_m or max_n\n        # according to rbc/zbs. In this case, go with the larger\n        # value.\n        max_m = np.max((max_m, vmec.vmec_input.mpol))\n        max_n = np.max((max_n, vmec.vmec_input.ntor))\n        return (max_m, max_n)",
  "def __repr__(self):\n        \"\"\"\n        Print the object in an informative way.\n        \"\"\"\n        return f\"{self.name} (nfp={self.indata.nfp} mpol={self.indata.mpol}\" + \\\n               f\" ntor={self.indata.ntor})\"",
  "def external_current(self):\n        \"\"\"\n        Return the total electric current associated with external\n        currents, i.e. the current through the \"doughnut hole\". This\n        number is useful for coil optimization, to know what the sum\n        of the coil currents must be.\n\n        Returns:\n            float with the total external electric current in Amperes.\n        \"\"\"\n        self.run()\n        bvco = self.wout.bvco[-1] * 1.5 - self.wout.bvco[-2] * 0.5\n        mu0 = 4 * np.pi * (1.0e-7)\n        # The formula in the next line follows from Ampere's law:\n        # \\int \\vec{B} dot (d\\vec{r} / d phi) d phi = mu_0 I.\n        return 2 * np.pi * bvco / mu0",
  "def vacuum_well(self):\n        \"\"\"\n        Compute a single number W that summarizes the vacuum magnetic well,\n        given by the formula\n\n        W = (dV/ds(s=0) - dV/ds(s=1)) / (dV/ds(s=0)\n\n        where dVds is the derivative of the flux surface volume with\n        respect to the radial coordinate s. Positive values of W are\n        favorable for stability to interchange modes. This formula for\n        W is motivated by the fact that\n\n        d^2 V / d s^2 < 0\n\n        is favorable for stability. Integrating over s from 0 to 1\n        and normalizing gives the above formula for W. Notice that W\n        is dimensionless, and it scales as the square of the minor\n        radius. To compute dV/ds, we use\n\n        dV/ds = 4 * pi**2 * abs(sqrt(g)_{0,0})\n\n        where sqrt(g) is the Jacobian of (s, theta, phi) coordinates,\n        computed by VMEC in the gmnc array, and _{0,0} indicates the\n        m=n=0 Fourier component. Since gmnc is reported by VMEC on the\n        half mesh, we extrapolate by half of a radial grid point to s\n        = 0 and 1.\n        \"\"\"\n        self.run()\n\n        # gmnc is on the half mesh, so drop the 0th radial entry:\n        dVds = 4 * np.pi * np.pi * np.abs(self.wout.gmnc[0, 1:])\n\n        # To get from the half grid to s=0 and s=1, we must\n        # extrapolate by 1/2 of a radial grid point:\n        dVds_s0 = 1.5 * dVds[0] - 0.5 * dVds[1]\n        dVds_s1 = 1.5 * dVds[-1] - 0.5 * dVds[-2]\n\n        well = (dVds_s0 - dVds_s1) / dVds_s0\n        return well",
  "class Spec(Optimizable):\n    \"\"\"\n    This class represents the SPEC equilibrium code.\n\n    Philosophy regarding mpol and ntor: The Spec object keeps track of\n    mpol and ntor values that are independent of those for the\n    boundary Surface object. If the Surface object has different\n    mpol/ntor values, the Surface's rbc/zbs arrays are first copied,\n    then truncated or expanded to fit the mpol/ntor values of the Spec\n    object to before Spec is run. Therefore, you may sometimes need to\n    manually change the mpol and ntor values for the Spec object.\n\n    The default behavior is that all  output files will be\n    deleted except for the first and most recent iteration on worker\n    group 0. If you wish to keep all the output files, you can set\n    ``keep_all_files = True``. If you want to save the output files\n    for a certain intermediate iteration, you can set the\n    ``files_to_delete`` attribute to ``[]`` after that run of SPEC.\n\n    Args:\n        filename: SPEC input file to use for initialization. It should end\n          in ``.sp``. Or, if None, default values will be used.\n        mpi: A :obj:`simsopt.util.mpi.MpiPartition` instance, from which\n          the worker groups will be used for SPEC calculations. If ``None``,\n          each MPI process will run SPEC independently.\n        verbose: Whether to print SPEC output to stdout.\n        keep_all_files: If ``False``, all output files will be deleted\n          except for the first and most recent ones from worker group 0. If\n          ``True``, all output files will be kept.\n        tolerance: Max force balance residue to consider the equilibrium as\n          converged; if :math:`|f|>` tolerance, raise ``ObjectiveFailure`` exception. By\n          default set to 1E-12.\n    \"\"\"\n\n    def __init__(self,\n                 filename: Optional[str] = None,\n                 mpi: Optional[MpiPartition] = None,\n                 verbose: bool = True,\n                 keep_all_files: bool = False,\n                 tolerance: float = 1e-12):\n\n        if spec is None:\n            raise RuntimeError(\n                \"Using Spec requires spec python wrapper to be installed.\")\n        if py_spec is None:\n            raise RuntimeError(\n                \"Using Spec requires py_spec to be installed.\")\n\n        self.lib = spec\n        # For the most commonly accessed fortran modules, provide a\n        # shorthand so \".lib\" is not needed:\n        modules = [\n            \"inputlist\",\n            \"allglobal\",\n        ]\n        for key in modules:\n            setattr(self, key, getattr(spec, key))\n\n        self.verbose = verbose\n        # mute screen output if necessary\n        # TODO: relies on /dev/null being accessible (Windows!)\n        if not self.verbose:\n            self.lib.fileunits.mute(1)\n\n        # python wrapper does not need to write files along the run\n        #self.lib.allglobal.skip_write = True\n\n        # If mpi is not specified, use a single worker group:\n        if mpi is None:\n            self.mpi = MpiPartition(ngroups=1)\n        else:\n            self.mpi = mpi\n        # SPEC will use the \"groups\" communicator from the MpiPartition:\n        self.lib.allglobal.set_mpi_comm(self.mpi.comm_groups.py2f())\n\n        if filename is None:\n            # Read default input file, which should be in the same\n            # directory as this file:\n            filename = os.path.join(os.path.dirname(__file__), 'defaults.sp')\n            logger.info(\n                f\"Initializing a SPEC object from defaults in {filename}\")\n        else:\n            if not filename.endswith('.sp'):\n                filename = f\"{filename}.sp\"\n            logger.info(f\"Initializing a SPEC object from file: {filename}\")\n\n        if tolerance <= 0:\n            raise ValueError(\n                'tolerance should be greater than zero'\n            )\n        self.tolerance = tolerance\n\n        self.init(filename)\n        si = spec.inputlist  # Shorthand\n\n        # Read number of (plasma) volumes\n        self.nvol = si.nvol\n\n        # Read number of (plasma+vacuum) volumes\n        if si.lfreebound:\n            self.mvol = self.nvol + 1 \n        else:\n            self.mvol = self.nvol\n\n        # Store initial guess data\n        # The initial guess is a collection of SurfaceRZFourier instances,\n        # stored in a list of size Mvol-1 (the number of inner interfaces)\n        nmodes = self.allglobal.num_modes\n        stellsym = bool(si.istellsym)\n        if nmodes > 0 and self.nvol > 1:\n            self.initial_guess = [ \n                SurfaceRZFourier(nfp=si.nfp, stellsym=stellsym, mpol=si.mpol, ntor=si.ntor) for n in range(0, self.mvol-1)\n            ]\n            for imode in range(0, nmodes):\n                mm = self.allglobal.mmrzrz[imode]\n                nn = self.allglobal.nnrzrz[imode]\n                if mm > si.mpol:\n                    continue\n                if abs(nn) > si.ntor:\n                    continue\n\n                # Populate SurfaceRZFourier instances, except plasma boundary\n                for lvol in range(0, self.nvol-1):\n                    self.initial_guess[lvol].set_rc(mm, nn, self.allglobal.allrzrz[0, lvol, imode])\n                    self.initial_guess[lvol].set_zs(mm, nn, self.allglobal.allrzrz[1, lvol, imode])\n\n                    if not si.istellsym:\n                        self.initial_guess[lvol].set_rs(mm, nn, self.allglobal.allrzrz[2, lvol, imode])\n                        self.initial_guess[lvol].set_zc(mm, nn, self.allglobal.allrzrz[3, lvol, imode])\n\n                if si.lfreebound:  # Populate plasma boundary as well\n                    self.initial_guess[self.nvol-1].set_rc(mm, nn, si.rbc[si.mntor+nn, si.mmpol+mm])\n                    self.initial_guess[self.nvol-1].set_zs(mm, nn, si.zbs[si.mntor+nn, si.mmpol+mm])\n\n                    if not si.istellsym:\n                        self.initial_guess[self.nvol-1].set_rs(mm, nn, si.rbs[si.mntor+nn, si.mmpol+mm])\n                        self.initial_guess[self.nvol-1].set_zc(mm, nn, si.zbc[si.mntor+nn, si.mmpol+mm])\n\n            # In general, initial guess is NOT a degree of freedom for the\n            # optimization - we thus fix them.\n            for lvol in range(0, self.mvol-1):\n                self.initial_guess[lvol].fix_all()\n\n        else: \n            # There is no initial guess - in this case, we let SPEC handle\n            # the construction of the initial guess. This generally means\n            # that the geometry of the inner interfaces will be constructed\n            # by interpolation between the plasma (or computational) boundary\n            # and the magnetic axis\n\n            self.initial_guess = None\n\n        # Store axis data\n        self.axis = {}\n        self.axis['rac'] = copy.copy(si.rac[0:si.ntor+1])\n        self.axis['zas'] = copy.copy(si.zas[0:si.ntor+1])\n        if si.istellsym == 0:\n            self.axis['ras'] = copy.copy(si.ras[0:si.ntor+1])\n            self.axis['zac'] = copy.copy(si.zac[0:si.ntor+1])\n\n        self.extension = filename[:-3]\n        self.keep_all_files = keep_all_files\n        self.files_to_delete = []\n\n        # Create a surface object for the boundary:\n        logger.debug(f\"In __init__, si.istellsym={si.istellsym} stellsym={stellsym}\")\n        self._boundary = SurfaceRZFourier(nfp=si.nfp,\n                                          stellsym=stellsym,\n                                          mpol=si.mpol,\n                                          ntor=si.ntor)\n\n        # Transfer the boundary shape from fortran to the boundary\n        # surface object:\n        for m in range(si.mpol + 1):\n            for n in range(-si.ntor, si.ntor + 1):\n                self._boundary.rc[m,\n                                  n + si.ntor] = si.rbc[n + si.mntor,\n                                                        m + si.mmpol]\n                self._boundary.zs[m,\n                                  n + si.ntor] = si.zbs[n + si.mntor,\n                                                        m + si.mmpol]\n                if not stellsym:\n                    self._boundary.rs[m,\n                                      n + si.ntor] = si.rbs[n + si.mntor,\n                                                            m + si.mmpol]\n                    self._boundary.zc[m,\n                                      n + si.ntor] = si.zbc[n + si.mntor,\n                                                            m + si.mmpol]\n        self._boundary.local_full_x = self._boundary.get_dofs()\n\n        self.need_to_run_code = True\n        self.counter = -1\n\n        # Set profiles as None - these have to be defined in a script if the user\n        # wish to use them as degrees of freedom\n        self._volume_current_profile = None\n        self._interface_current_profile = None\n        self._pressure_profile = None\n        self._iota_profile = None\n        self._oita_profile = None\n        self._mu_profile = None\n        self._pflux_profile = None\n        self._tflux_profile = None\n        self._helicity_profile = None\n\n        # Define normal field - these are the Vns, Vnc harmonics. Can be used as\n        # dofs in an optimization\n        if si.lfreebound:\n            self.normal_field = NormalField.from_spec(filename)\n        else:\n            self.normal_field = None\n\n        # By default, all dofs owned by SPEC directly, as opposed to\n        # dofs owned by the boundary surface object, are fixed.\n        x0 = self.get_dofs()\n        fixed = np.full(len(x0), True)\n        names = ['phiedge', 'curtor']\n        if si.lfreebound:\n            depends_on = [self.normal_field]\n        else:\n            depends_on = [self._boundary]\n\n        super().__init__(x0=x0, fixed=fixed, names=names,\n                         depends_on=depends_on,\n                         external_dof_setter=Spec.set_dofs)\n\n    @property\n    def boundary(self):\n        \"\"\"\n        Getter for the plasma boundary\n\n        Returns:\n            SurfaceRZFourier instance representing the plasma boundary\n        \"\"\"\n        return self._boundary\n\n    @property\n    def pressure_profile(self):\n        \"\"\"\n        Getter for the pressure profile\n\n        Returns:\n            ProfileSpec instance representing the pressure profile\n        \"\"\"\n        return self._pressure_profile\n\n    @pressure_profile.setter\n    def pressure_profile(self, pressure_profile):\n        \"\"\"\n        Setter for the pressure profile\n\n        Args:\n            ProfileSpec instance for the pressure profile\n        \"\"\"\n\n        # Check inputs\n        if not isinstance(pressure_profile, ProfileSpec):\n            ValueError('Input should be a ProfileSpec')\n\n        # Check size\n        if pressure_profile.dofs.full_x.size != self.mvol:\n            ValueError('Invalid number of dofs. Shoudl be equal to Mvol!')\n\n        # Update pressure profile\n        if pressure_profile is not self._pressure_profile:\n            logging.debug('Replacing pressure_profile in setter')\n            if self._pressure_profile is not None:\n                self.remove_parent(self._pressure_profile)\n            self._pressure_profile = pressure_profile\n            if pressure_profile is not None:\n                self.append_parent(pressure_profile)\n                self.need_to_run_code = True\n\n    @property\n    def volume_current_profile(self):\n        \"\"\"\n        Getter for the volume current profile (Ivolume)\n\n        Returns:\n            ProfileSpec instance representing the volume current profile\n        \"\"\"\n        return self._volume_current_profile\n\n    @volume_current_profile.setter\n    def volume_current_profile(self, volume_current_profile):\n        \"\"\"\n        Setter for the volume current profile\n\n        Args:\n            ProfileSpec instance for the volume current profile\n        \"\"\"\n\n        if not isinstance(volume_current_profile, ProfileSpec):\n            ValueError('Input should be a ProfileSpec')\n\n        # Check size\n        if volume_current_profile.dofs.full_x.size != self.mvol:\n            ValueError('Invalid number of dofs. Shoudl be equal to Mvol!')\n\n        # Volume current is a cumulative property\n        volume_current_profile.cumulative = True\n\n        if volume_current_profile is not self._volume_current_profile:\n            logging.debug('Replacing pressure_profile in setter')\n            if self._volume_current_profile is not None:\n                self.remove_parent(self._volume_current_profile)\n            self._volume_current_profile = volume_current_profile\n            if volume_current_profile is not None:\n                self.append_parent(volume_current_profile)\n                self.need_to_run_code = True\n\n    @property\n    def interface_current_profile(self):\n        \"\"\"\n        Getter for the surface current profile (Isurf)\n\n        Returns:\n            ProfileSpec instance representing the surface current profile\n        \"\"\"\n        return self._interface_current_profile\n\n    @interface_current_profile.setter\n    def interface_current_profile(self, interface_current_profile):\n        \"\"\"\n        Setter for the surface current profile\n\n        Args:\n            ProfileSpec instance for the surface current profile\n        \"\"\"\n\n        if not isinstance(interface_current_profile, ProfileSpec):\n            ValueError('Input should be a ProfileSpec')\n\n        # Check size\n        if interface_current_profile.dofs.full_x.size != self.mvol:\n            ValueError('Invalid number of dofs. Shoudl be equal to Mvol!')\n\n        if interface_current_profile is not self._interface_current_profile:\n            logging.debug('Replacing pressure_profile in setter')\n            if self._interface_current_profile is not None:\n                self.remove_parent(self._interface_current_profile)\n            self._interface_current_profile = interface_current_profile\n            if interface_current_profile is not None:\n                self.append_parent(interface_current_profile)\n                self.need_to_run_code = True\n\n    @property\n    def iota_profile(self):\n        \"\"\"\n        Getter for the inner rotational transform profile (iota)\n\n        Returns:\n            ProfileSpec instance representing the iota profile\n        \"\"\"\n        return self._iota_profile\n\n    @iota_profile.setter\n    def iota_profile(self, iota_profile):\n        \"\"\"\n        Setter for the inner rotational transform profile (iota)\n\n        Args:\n            ProfileSpec instance for the inner rotational transform profile\n        \"\"\"\n\n        if not isinstance(iota_profile, ProfileSpec):\n            ValueError('Input should be a ProfileSpec')\n\n        # Check size\n        if iota_profile.dofs.full_x.size != self.mvol:\n            ValueError('Invalid number of dofs. Shoudl be equal to Mvol!')\n\n        if iota_profile is not self._iota_profile:\n            logging.debug('Replacing pressure_profile in setter')\n            if self._iota_profile is not None:\n                self.remove_parent(self._iota_profile)\n            self._iota_profile = iota_profile\n            if iota_profile is not None:\n                self.append_parent(iota_profile)\n                self.need_to_run_code = True\n\n    @property\n    def oita_profile(self):\n        \"\"\"\n        Getter for the outer rotational transform profile (oita)\n\n        Returns:\n            ProfileSpec instance representing the oita profile\n        \"\"\"\n        return self._oita_profile\n\n    @oita_profile.setter\n    def oita_profile(self, oita_profile):\n        \"\"\"\n        Setter for the outer rotational transform profile (oita)\n\n        Args:\n            ProfileSpec instance for the outer rotational transform profile\n        \"\"\"\n\n        if not isinstance(oita_profile, ProfileSpec):\n            ValueError('Input should be a ProfileSpec')\n\n        # Check size\n        if oita_profile.dofs.full_x.size != self.mvol:\n            ValueError('Invalid number of dofs. Shoudl be equal to Mvol!')\n\n        if oita_profile is not self._oita_profile:\n            logging.debug('Replacing pressure_profile in setter')\n            if self._oita_profile is not None:\n                self.remove_parent(self._oita_profile)\n            self._oita_profile = oita_profile\n            if oita_profile is not None:\n                self.append_parent(oita_profile)\n                self.need_to_run_code = True\n\n    @property\n    def mu_profile(self):\n        \"\"\"\n        Getter for the mu-profile\n\n        Returns:\n            ProfileSpec instance representing the mu profile\n        \"\"\"\n        return self._mu_profile\n\n    @mu_profile.setter\n    def mu_profile(self, mu_profile):\n        \"\"\"\n        Setter for the mu profile (oita)\n\n        Args:\n            ProfileSpec instance for the outer rotational transform profile\n        \"\"\"\n\n        if not isinstance(mu_profile, ProfileSpec):\n            ValueError('Input should be a ProfileSpec')\n\n        # Check size\n        if mu_profile.dofs.full_x.size != self.mvol:\n            ValueError('Invalid number of dofs. Shoudl be equal to Mvol!')\n\n        if mu_profile is not self._mu_profile:\n            logging.debug('Replacing pressure_profile in setter')\n            if self._mu_profile is not None:\n                self.remove_parent(self._mu_profile)\n            self._mu_profile = mu_profile\n            if mu_profile is not None:\n                self.append_parent(mu_profile)\n                self.need_to_run_code = True\n\n    @property\n    def pflux_profile(self):\n        \"\"\"\n        Getter for the poloidal flux profile (pflux)\n\n        Returns:\n            ProfileSpec instance representing the poloidal flux profile\n        \"\"\"\n        return self._pflux_profile\n\n    @pflux_profile.setter\n    def pflux_profile(self, pflux_profile):\n        \"\"\"\n        Setter for the poloidal flux profile (pflux)\n\n        Args:\n            ProfileSpec instance for the poloidal flux profile\n        \"\"\"\n\n        if not isinstance(pflux_profile, ProfileSpec):\n            ValueError('Input should be a ProfileSpec')\n\n        # Check size\n        if pflux_profile.dofs.full_x.size != self.mvol:\n            ValueError('Invalid number of dofs. Shoudl be equal to Mvol!')\n\n        # pflux is a cumulative property\n        pflux_profile.cumulative = True\n\n        if pflux_profile is not self._pflux_profile:\n            logging.debug('Replacing pressure_profile in setter')\n            if self._pflux_profile is not None:\n                self.remove_parent(self._pflux_profile)\n            self._pflux_profile = pflux_profile\n            if pflux_profile is not None:\n                self.append_parent(pflux_profile)\n                self.need_to_run_code = True\n\n    @property\n    def tflux_profile(self):\n        \"\"\"\n        Getter for the toroidal flux profile (tflux)\n\n        Returns:\n            ProfileSpec instance representing the toroidal flux profile\n        \"\"\"\n        return self._tflux_profile\n\n    @tflux_profile.setter\n    def tflux_profile(self, tflux_profile):\n        \"\"\"\n        Setter for the toroidal flux profile (tflux)\n\n        Args:\n            ProfileSpec instance for the toroidal flux profile\n        \"\"\"\n\n        if not isinstance(tflux_profile, ProfileSpec):\n            ValueError('Input should be a ProfileSpec')\n\n        # Check size\n        if tflux_profile.dofs.full_x.size != self.mvol:\n            ValueError('Invalid number of dofs. Shoudl be equal to Mvol!')\n\n        # pflux is a cumulative property\n        tflux_profile.cumulative = True\n\n        if tflux_profile is not self._tflux_profile:\n            logging.debug('Replacing pressure_profile in setter')\n            if self._tflux_profile is not None:\n                self.remove_parent(self._tflux_profile)\n            self._tflux_profile = tflux_profile\n            if tflux_profile is not None:\n                self.append_parent(tflux_profile)\n                self.need_to_run_code = True\n\n    @property\n    def helicity_profile(self):\n        \"\"\"\n        Getter for the magnetic helicity profile (helicity)\n\n        Returns:\n            ProfileSpec instance representing the magnetic helicity profile\n        \"\"\"\n        return self._helicity_profile\n\n    @helicity_profile.setter\n    def helicity_profile(self, helicity_profile):\n        \"\"\"\n        Setter for the toroidal flux profile (tflux)\n\n        Args:\n            ProfileSpec instance for the toroidal flux profile\n        \"\"\"\n\n        if not isinstance(helicity_profile, ProfileSpec):\n            ValueError('Input should be a ProfileSpec')\n\n        # Check size\n        if helicity_profile.dofs.full_x.size != self.mvol:\n            ValueError('Invalid number of dofs. Shoudl be equal to Mvol!')\n\n        if helicity_profile is not self._helicity_profile:\n            logging.debug('Replacing pressure_profile in setter')\n            if self._helicity_profile is not None:\n                self.remove_parent(self._tflux_profile)\n            self._helicity_profile = helicity_profile\n            if helicity_profile is not None:\n                self.append_parent(helicity_profile)\n                self.need_to_run_code = True\n\n    def set_profile(self, longname, lvol, value):\n        \"\"\"\n        This function is used to set the pressure, currents, iota, oita,\n        mu pflux and/or tflux in volume lvol\n\n        Args:\n            longname: string, either \n                - 'pressure'\n                - 'volume_current'\n                - 'surface_current'\n                - 'iota'\n                - 'oita'\n                - 'mu'\n                - 'pflux'\n                - 'tflux'\n                - 'helicity'\n            lvol: integer, from 0 to Mvol-1\n            value: real, new value\n        \"\"\"\n        profile = self.__getattribute__(longname + \"_profile\")\n        if profile is None:\n            return\n\n        # If the profile is cumulative, values in lvol to Mvol-1 are modified.\n        # If it is not cumulative, only the value in lvol is modified.\n        if profile.cumulative: \n            old_value = profile.f(lvol)\n\n            profile.set(lvol, value)\n            for ivol in range(lvol + 1, self.mvol):\n                profile.set(ivol, profile.f(ivol) - old_value + value)\n        else:\n            profile.set(lvol, value)\n\n    def get_profile(self, longname, lvol):\n        \"\"\"\n        This function is used to get the pressure, currents, iota, oita,\n        mu pflux and/or tflux profiles.\n\n        Args:\n            longname: string, either\n                - 'pressure'\n                - 'volume_current'\n                - 'surface_current'\n                - 'iota'\n                - 'oita'\n                - 'mu'\n                - 'pflux'\n                - 'tflux'\n                - 'helicity'\n            lvol: integer, list or np.array of volume indices, from 0 to Mvol-1\n        Returns:\n            np.array of length lvol, with the profiles values.\n        \"\"\"\n\n        profile = self.__getattribute__(longname + \"_profile\")\n        if profile is None:\n            return\n\n        return profile.f(lvol)\n\n    @boundary.setter\n    def boundary(self, boundary):\n        \"\"\"\n        Setter for the geometry of the plasma boundary\n        \"\"\"\n\n        if self._boundary is not boundary:\n            self.remove_parent(self._boundary)\n            self._boundary = boundary\n            self.append_parent(boundary)\n\n    def recompute_bell(self, parent=None):\n        self.need_to_run_code = True\n\n    def get_dofs(self):\n        return np.array([self.inputlist.phiedge,\n                         self.inputlist.curtor])\n\n    def set_dofs(self, x):\n        self.need_to_run_code = True\n        self.inputlist.phiedge = x[0]\n        self.inputlist.curtor = x[1]\n\n        profiles = [\n            self._volume_current_profile,\n            self._interface_current_profile,\n            self._pressure_profile,\n            self._iota_profile,\n            self._oita_profile,\n            self._mu_profile,\n            self._pflux_profile,\n            self._tflux_profile,\n            self._helicity_profile\n        ]\n        for p in profiles:\n            if p is not None:\n                p.phiedge = x[0]\n\n    def init(self, filename: str):\n        \"\"\"\n        Initialize SPEC fortran state from an input file.\n\n        Args:\n            filename: Name of the file to load. It should end in ``.sp``.\n        \"\"\"\n        logger.debug(\"Entering init\")\n        if self.mpi.proc0_groups:\n            spec.inputlist.initialize_inputs()\n            logger.debug(\"Done with initialize_inputs\")\n            self.extension = filename[:-3]  # Remove the \".sp\"\n            spec.allglobal.ext = self.extension\n            spec.allglobal.read_inputlists_from_file()\n            logger.debug(\"Done with read_inputlists_from_file\")\n            spec.allglobal.check_inputs()\n\n        logger.debug('About to call broadcast_inputs')\n        spec.allglobal.broadcast_inputs()\n        logger.debug('About to call preset')\n        spec.preset()\n        logger.debug(\"Done with init\")\n\n    def run(self, update_guess: bool = True):\n        \"\"\"\n        Run SPEC, if needed.\n\n        Args:\n            - update_guess: boolean. If True, initial guess will be updated with\n              the geometry of the interfaces found at equilibrium. Default is \n              True\n        \"\"\"\n        if not self.need_to_run_code:\n            logger.info(\"run() called but no need to re-run SPEC.\")\n            return\n        logger.info(\"Preparing to run SPEC.\")\n        self.counter += 1\n\n        si = self.inputlist  # Shorthand\n\n        # Check that number of volumes in internal memory is consistent with\n        # the input file\n        if self.nvol != si.nvol:\n            ValueError('Inconsistent Nvol')\n\n        # nfp must be consistent between the surface and SPEC. The surface's\n        # value trumps.\n        si.nfp = self.boundary.nfp\n        si.istellsym = int(self.boundary.stellsym)\n\n        # Convert boundary to RZFourier if needed:\n        boundary_RZFourier = self.boundary.to_RZFourier()\n\n        # Transfer boundary data to fortran:\n        si.rbc[:, :] = 0.0\n        si.zbs[:, :] = 0.0\n        si.rbs[:, :] = 0.0\n        si.zbc[:, :] = 0.0\n        mpol_capped = np.min([boundary_RZFourier.mpol, si.mmpol])\n        ntor_capped = np.min([boundary_RZFourier.ntor, si.mntor])\n        stellsym = bool(si.istellsym)\n        logger.debug(f\"In run, si.istellsym = {si.istellsym} stellsym = {stellsym}\")\n        for m in range(mpol_capped + 1):\n            for n in range(-ntor_capped, ntor_capped + 1):\n                si.rbc[n + si.mntor, m + si.mmpol] = boundary_RZFourier.get_rc(m, n)\n                si.zbs[n + si.mntor, m + si.mmpol] = boundary_RZFourier.get_zs(m, n)\n                if not stellsym:\n                    si.rbs[n + si.mntor, m + si.mmpol] = boundary_RZFourier.get_rs(m, n)\n                    si.zbc[n + si.mntor, m + si.mmpol] = boundary_RZFourier.get_zc(m, n)\n\n        # Set the coordinate axis using the lrzaxis=2 feature:\n        si.lrzaxis = 2\n\n        # Set axis from latest converged state\n        mn = self.axis['rac'].size\n        si.rac[0:mn] = self.axis['rac']\n        si.zas[0:mn] = self.axis['zas']\n        if si.istellsym == 0:\n            si.ras[0:mn] = self.axis['ras']\n            si.zac[0:mn] = self.axis['zac']\n\n        # Set initial guess\n        if not self.initial_guess is None:        \n            # Set all modes to zero\n            spec.allglobal.mmrzrz[:] = 0\n            spec.allglobal.nnrzrz[:] = 0\n            spec.allglobal.allrzrz[:] = 0\n\n            # transform to SurfaceRZFourier if necessary\n            initial_guess = [s.to_RZFourier() for s in self.initial_guess]\n\n            # Loop on modes\n            imn = -1  # counter\n            for mm in range(0, si.mpol+1):\n                for nn in range(-si.ntor, si.ntor+1):\n                    if mm == 0 and nn < 0:\n                        continue\n\n                    imn += 1\n\n                    spec.allglobal.mmrzrz[imn] = mm\n                    spec.allglobal.nnrzrz[imn] = nn\n\n                    # Populate inner plasma boundaries\n                    for lvol in range(0, self.nvol-1):\n                        spec.allglobal.allrzrz[0, lvol, imn] = initial_guess[lvol].get_rc(mm, nn)\n                        spec.allglobal.allrzrz[1, lvol, imn] = initial_guess[lvol].get_zs(mm, nn)\n\n                        if not si.istellsym:\n                            spec.allglobal.allrzrz[2, lvol, imn] = initial_guess[lvol].get_rs(mm, nn)\n                            spec.allglobal.allrzrz[3, lvol, imn] = initial_guess[lvol].get_zc(mm, nn)\n\n                    # Populate plasma boundary\n                    if si.lfreebound:\n                        si.rbc[si.mntor+nn, si.mmpol+mm] = initial_guess[self.nvol-1].get_rc(mm, nn)\n                        si.zbs[si.mntor+nn, si.mmpol+mm] = initial_guess[self.nvol-1].get_zs(mm, nn)\n\n                        if not si.istellsym:\n                            si.rbs[si.mntor+nn, si.mmpol+mm] = initial_guess[self.nvol-1].get_rs(mm, nn)\n                            si.zbc[si.mntor+nn, si.mmpol+mm] = initial_guess[self.nvol-1].get_zc(mm, nn)\n\n            spec.allglobal.num_modes = imn + 1\n\n        # Set profiles from dofs\n        if self.pressure_profile is not None:\n            si.pressure[0:self.nvol] = self.pressure_profile.get(\n                np.arange(0, self.nvol))\n            if si.lfreebound:\n                si.pressure[self.nvol] = 0\n\n        if self.volume_current_profile is not None:\n            # Volume current is a cumulative profile; special care is required\n            # when a dofs is changed in order to keep fixed dofs fixed!\n            old_ivolume = copy.copy(si.ivolume)\n            for lvol in range(0, self.mvol):\n                if self.volume_current_profile.is_fixed(lvol):\n                    if lvol != 0:\n                        si.ivolume[lvol] = si.ivolume[lvol] - \\\n                            old_ivolume[lvol - 1] + si.ivolume[lvol - 1]\n                        self.set_profile(\n                            'volume_current', lvol=lvol, value=si.ivolume[lvol])\n                else:\n                    si.ivolume[lvol] = self.get_profile('volume_current', lvol)\n\n            if si.lfreebound:\n                si.ivolume[self.nvol] = si.ivolume[self.nvol - 1]\n                self.volume_current_profile.set(\n                    key=self.mvol - 1, new_val=si.ivolume[self.nvol - 1])\n\n        if self.interface_current_profile is not None:\n            si.isurf[0:self.mvol - 1] = \\\n                self.interface_current_profile.get(np.arange(0, self.mvol-1))\n\n        # Update total plasma toroidal current in case of freeboundary\n        # calculation\n        if ((self.volume_current_profile is not None) or\n            (self.interface_current_profile is not None)) and \\\n                si.lfreebound:\n            si.curtor = si.ivolume[self.nvol - 1] + np.sum(si.isurf)\n\n        if self.iota_profile is not None:\n            si.iota[0:self.nvol+1] = self.iota_profile.get(np.arange(0, self.nvol))\n\n        if self.oita_profile is not None:\n            si.oita[0:self.nvol+1] = self.oita_profile.get(np.arange(0, self.nvol))\n\n        if self.mu_profile is not None:\n            si.mu[0:self.nvol] = self.mu_profile.get(np.arange(0, self.nvol))\n            if si.lfreebound:\n                si.mu[self.mvol] = 0\n\n        if self.pflux_profile is not None:\n            # Pflux is a cumulative profile; special care is required\n            # when a dofs is changed in order to keep fixed dofs fixed!\n            old_pflux = copy.copy(si.pflux)\n            for lvol in range(0, self.mvol):\n                if self.pflux_profile.is_fixed(lvol):\n                    if lvol != 0:\n                        si.pflux[lvol] = si.pflux[lvol] - \\\n                            old_pflux[lvol - 1] + si.pflux[lvol - 1]\n                        self.pflux_profile.set(\n                            key=lvol, new_val=si.pflux[lvol])\n                else:\n                    si.pflux[lvol] = self.pflux_profile.get(lvol)\n\n        if self.tflux_profile is not None:\n            # tflux is a cumulative profile; special care is required\n            # when a dofs is changed in order to keep fixed dofs fixed!\n            old_tflux = copy.copy(si.tflux)\n            for lvol in range(0, self.mvol):\n                if self.tflux_profile.is_fixed(lvol):\n                    if lvol != 0:\n                        si.tflux[lvol] = si.tflux[lvol] - \\\n                            old_tflux[lvol - 1] + si.tflux[lvol - 1]\n                        self.tflux_profile.set(\n                            key=lvol, new_val=si.tflux[lvol])\n                else:\n                    si.tflux[lvol] = self.tflux_profile.get(lvol)\n\n        if self.helicity_profile is not None:\n            si.helicity[0:self.nvol] = self.helicity_profile.get(np.arange(0, self.nvol))\n            if si.lfreebound:\n                si.helicity[self.mvol] = 0\n\n        # Another possible way to initialize the coordinate axis: use\n        # the m=0 modes of the boundary.\n        # m = 0\n        # for n in range(2):\n        #     si.rac[n] = si.rbc[n + si.mntor, m + si.mmpol]\n        #     si.zas[n] = si.zbs[n + si.mntor, m + si.mmpol]\n        filename = self.extension + \\\n            '_{:03}_{:06}'.format(self.mpi.group, self.counter)\n        logger.info(\"Running SPEC using filename \" + filename)\n        self.allglobal.ext = filename\n        try:\n            # Here is where we actually run SPEC:\n            if self.mpi.proc0_groups:\n                logger.debug('About to call check_inputs')\n                spec.allglobal.check_inputs()\n            logger.debug('About to call broadcast_inputs')\n            spec.allglobal.broadcast_inputs()\n            logger.debug('About to call preset')\n            spec.preset()\n            logger.debug(f'About to call init_outfile')\n            spec.sphdf5.init_outfile()\n            logger.debug('About to call mirror_input_to_outfile')\n            spec.sphdf5.mirror_input_to_outfile()\n            if self.mpi.proc0_groups:\n                logger.debug('About to call wrtend')\n                spec.allglobal.wrtend()\n            logger.debug('About to call init_convergence_output')\n            spec.sphdf5.init_convergence_output()\n            logger.debug(f'About to call spec')\n            spec.spec()\n            logger.debug('About to call diagnostics')\n            spec.final_diagnostics()\n            logger.debug('About to call write_grid')\n            spec.sphdf5.write_grid()\n            if self.mpi.proc0_groups:\n                logger.debug('About to call wrtend')\n                spec.allglobal.wrtend()\n            logger.debug('About to call hdfint')\n            spec.sphdf5.hdfint()\n            logger.debug('About to call finish_outfile')\n            spec.sphdf5.finish_outfile()\n            logger.debug('About to call ending')\n            spec.ending()\n\n        except BaseException:\n            if self.verbose:\n                traceback.print_exc()\n            raise ObjectiveFailure(\"SPEC did not run successfully.\")\n\n        logger.info(\"SPEC run complete.\")\n        # Barrier so workers do not try to read the .h5 file before it\n        # is finished:\n        self.mpi.comm_groups.Barrier()\n\n        # Try to read SPEC output. \n        try:\n            self.results = py_spec.SPECout(filename + '.sp.h5')\n        except BaseException:\n            if self.verbose:\n                traceback.print_exc()\n            raise ObjectiveFailure(\n                \"Unable to read results following SPEC execution\")\n\n        logger.info(\"Successfully loaded SPEC results.\")\n        self.need_to_run_code = False\n\n        # Deal with unconverged equilibria - these are excluded by \n        # the optimizer, and the objective function is set to a large number\n        if self.results.output.ForceErr > self.tolerance:\n            raise ObjectiveFailure(\n                'SPEC could not find force balance'\n            )\n\n        # Save geometry as initial guess for next iterations\n        if update_guess:\n            new_guess = None\n            if self.mvol > 1:\n                new_guess = [\n                    SurfaceRZFourier(nfp=si.nfp, stellsym=si.istellsym, mpol=si.mpol, ntor=si.ntor) for n in range(0, self.mvol-1)\n                ]\n\n                for ii, (mm, nn) in enumerate(zip(self.results.output.im, self.results.output.in_)):\n                    nnorm = (nn / si.nfp).astype('int')\n                    for lvol in range(0, self.mvol-1):\n                        new_guess[lvol].set_rc(mm, nnorm, self.results.output.Rbc[lvol+1, ii])\n                        new_guess[lvol].set_zs(mm, nnorm, self.results.output.Zbs[lvol+1, ii])\n\n                        if not si.istellsym:\n                            new_guess[lvol].set_rs(mm, nnorm, self.results.output.Rbs[lvol+1, ii])\n                            new_guess[lvol].set_zc(mm, nnorm, self.results.output.Zbc[lvol+1, ii])\n\n                axis = {}\n                axis['rac'] = self.results.output.Rbc[0, 0:si.ntor+1]\n                axis['zas'] = self.results.output.Zbs[0, 0:si.ntor+1]\n                self.axis = copy.copy(axis)\n\n            # Enforce SPEC to use initial guess\n            self.initial_guess = new_guess\n            self.inputlist.linitialize = 0\n\n        # Group leaders handle deletion of files:\n        if self.mpi.proc0_groups:\n            # If the worker group is not 0, delete all wout files, unless\n            # keep_all_files is True:\n            if (not self.keep_all_files) and (self.mpi.group > 0):\n                os.remove(filename + '.sp.h5')\n                os.remove(filename + '.sp.end')\n\n            # Delete the previous output file, if desired:\n            for file_to_delete in self.files_to_delete:\n                os.remove(file_to_delete)\n            self.files_to_delete = []\n\n            # Record the latest output file to delete if we run again:\n            if (self.mpi.group == 0) and (\n                    self.counter > 0) and (not self.keep_all_files):\n                self.files_to_delete.append(filename + '.sp.h5')\n                self.files_to_delete.append(filename + '.sp.end')\n\n    def volume(self):\n        \"\"\"\n        Return the volume inside the boundary flux surface.\n        \"\"\"\n        self.run()\n        return self.results.output.volume * self.results.input.physics.Nfp\n\n    def iota(self):\n        \"\"\"\n        Return the rotational transform in the middle of the volume.\n        \"\"\"\n        self.run()\n        return self.results.transform.fiota[1, 0]",
  "class Residue(Optimizable):\n    \"\"\"\n    Greene's residue, evaluated from a Spec equilibrum\n\n    Args:\n        spec: a Spec object\n        pp, qq: Numerator and denominator for the resonant iota = pp / qq\n        vol: Index of the Spec volume to consider\n        theta: Spec's theta coordinate at the periodic field line\n        s_guess: Guess for the value of Spec's s coordinate at the periodic\n                field line\n        s_min, s_max: bounds on s for the search\n        rtol: the relative tolerance of the integrator\n    \"\"\"\n\n    def __init__(self, spec, pp, qq, vol=1, theta=0, s_guess=None, s_min=-1.0,\n                 s_max=1.0, rtol=1e-9):\n        # if not spec_found:\n        if spec is None:\n            raise RuntimeError(\n                \"Residue requires spec package to be installed.\")\n        # if not pyoculus_found:\n        if pyoculus is None:\n            raise RuntimeError(\n                \"Residue requires pyoculus package to be installed.\")\n\n        self.spec = spec\n        self.pp = pp\n        self.qq = qq\n        self.vol = vol\n        self.theta = theta\n        self.rtol = rtol\n        if s_guess is None:\n            self.s_guess = 0.0\n        else:\n            self.s_guess = s_guess\n        self.s_min = s_min\n        self.s_max = s_max\n        self.depends_on = ['spec']\n        self.need_to_run_code = True\n        self.fixed_point = None\n        # We may at some point want to allow Residue to use a\n        # different MpiPartition than the Spec object it is attached\n        # to, but for now we'll use the same MpiPartition for\n        # simplicity.\n        self.mpi = spec.mpi\n        super().__init__(depends_on=[spec])\n\n    def recompute_bell(self, parent=None):\n        self.need_to_run_code = True\n\n    def J(self):\n        \"\"\"\n        Run Spec if needed, find the periodic field line, and return the residue\n        \"\"\"\n        if not self.mpi.proc0_groups:\n            logger.info(\n                \"This proc is skipping Residue.J() since it is not a group leader.\")\n            return\n\n        if self.need_to_run_code:\n            self.spec.run()\n            specb = pyoculus.problems.SPECBfield(self.spec.results, self.vol)\n            # Set nrestart=0 because otherwise the random guesses in\n            # pyoculus can cause examples/tests to be\n            # non-reproducible.\n            fp = pyoculus.solvers.FixedPoint(\n                specb, {\n                    'theta': self.theta, 'nrestart': 0}, integrator_params={\n                    'rtol': self.rtol})\n            self.fixed_point = fp.compute(self.s_guess,\n                                          sbegin=self.s_min,\n                                          send=self.s_max,\n                                          pp=self.pp, qq=self.qq)\n            self.need_to_run_code = False\n\n        if self.fixed_point is None:\n            raise ObjectiveFailure(\"Residue calculation failed\")\n\n        return self.fixed_point.GreenesResidue",
  "def __init__(self,\n                 filename: Optional[str] = None,\n                 mpi: Optional[MpiPartition] = None,\n                 verbose: bool = True,\n                 keep_all_files: bool = False,\n                 tolerance: float = 1e-12):\n\n        if spec is None:\n            raise RuntimeError(\n                \"Using Spec requires spec python wrapper to be installed.\")\n        if py_spec is None:\n            raise RuntimeError(\n                \"Using Spec requires py_spec to be installed.\")\n\n        self.lib = spec\n        # For the most commonly accessed fortran modules, provide a\n        # shorthand so \".lib\" is not needed:\n        modules = [\n            \"inputlist\",\n            \"allglobal\",\n        ]\n        for key in modules:\n            setattr(self, key, getattr(spec, key))\n\n        self.verbose = verbose\n        # mute screen output if necessary\n        # TODO: relies on /dev/null being accessible (Windows!)\n        if not self.verbose:\n            self.lib.fileunits.mute(1)\n\n        # python wrapper does not need to write files along the run\n        #self.lib.allglobal.skip_write = True\n\n        # If mpi is not specified, use a single worker group:\n        if mpi is None:\n            self.mpi = MpiPartition(ngroups=1)\n        else:\n            self.mpi = mpi\n        # SPEC will use the \"groups\" communicator from the MpiPartition:\n        self.lib.allglobal.set_mpi_comm(self.mpi.comm_groups.py2f())\n\n        if filename is None:\n            # Read default input file, which should be in the same\n            # directory as this file:\n            filename = os.path.join(os.path.dirname(__file__), 'defaults.sp')\n            logger.info(\n                f\"Initializing a SPEC object from defaults in {filename}\")\n        else:\n            if not filename.endswith('.sp'):\n                filename = f\"{filename}.sp\"\n            logger.info(f\"Initializing a SPEC object from file: {filename}\")\n\n        if tolerance <= 0:\n            raise ValueError(\n                'tolerance should be greater than zero'\n            )\n        self.tolerance = tolerance\n\n        self.init(filename)\n        si = spec.inputlist  # Shorthand\n\n        # Read number of (plasma) volumes\n        self.nvol = si.nvol\n\n        # Read number of (plasma+vacuum) volumes\n        if si.lfreebound:\n            self.mvol = self.nvol + 1 \n        else:\n            self.mvol = self.nvol\n\n        # Store initial guess data\n        # The initial guess is a collection of SurfaceRZFourier instances,\n        # stored in a list of size Mvol-1 (the number of inner interfaces)\n        nmodes = self.allglobal.num_modes\n        stellsym = bool(si.istellsym)\n        if nmodes > 0 and self.nvol > 1:\n            self.initial_guess = [ \n                SurfaceRZFourier(nfp=si.nfp, stellsym=stellsym, mpol=si.mpol, ntor=si.ntor) for n in range(0, self.mvol-1)\n            ]\n            for imode in range(0, nmodes):\n                mm = self.allglobal.mmrzrz[imode]\n                nn = self.allglobal.nnrzrz[imode]\n                if mm > si.mpol:\n                    continue\n                if abs(nn) > si.ntor:\n                    continue\n\n                # Populate SurfaceRZFourier instances, except plasma boundary\n                for lvol in range(0, self.nvol-1):\n                    self.initial_guess[lvol].set_rc(mm, nn, self.allglobal.allrzrz[0, lvol, imode])\n                    self.initial_guess[lvol].set_zs(mm, nn, self.allglobal.allrzrz[1, lvol, imode])\n\n                    if not si.istellsym:\n                        self.initial_guess[lvol].set_rs(mm, nn, self.allglobal.allrzrz[2, lvol, imode])\n                        self.initial_guess[lvol].set_zc(mm, nn, self.allglobal.allrzrz[3, lvol, imode])\n\n                if si.lfreebound:  # Populate plasma boundary as well\n                    self.initial_guess[self.nvol-1].set_rc(mm, nn, si.rbc[si.mntor+nn, si.mmpol+mm])\n                    self.initial_guess[self.nvol-1].set_zs(mm, nn, si.zbs[si.mntor+nn, si.mmpol+mm])\n\n                    if not si.istellsym:\n                        self.initial_guess[self.nvol-1].set_rs(mm, nn, si.rbs[si.mntor+nn, si.mmpol+mm])\n                        self.initial_guess[self.nvol-1].set_zc(mm, nn, si.zbc[si.mntor+nn, si.mmpol+mm])\n\n            # In general, initial guess is NOT a degree of freedom for the\n            # optimization - we thus fix them.\n            for lvol in range(0, self.mvol-1):\n                self.initial_guess[lvol].fix_all()\n\n        else: \n            # There is no initial guess - in this case, we let SPEC handle\n            # the construction of the initial guess. This generally means\n            # that the geometry of the inner interfaces will be constructed\n            # by interpolation between the plasma (or computational) boundary\n            # and the magnetic axis\n\n            self.initial_guess = None\n\n        # Store axis data\n        self.axis = {}\n        self.axis['rac'] = copy.copy(si.rac[0:si.ntor+1])\n        self.axis['zas'] = copy.copy(si.zas[0:si.ntor+1])\n        if si.istellsym == 0:\n            self.axis['ras'] = copy.copy(si.ras[0:si.ntor+1])\n            self.axis['zac'] = copy.copy(si.zac[0:si.ntor+1])\n\n        self.extension = filename[:-3]\n        self.keep_all_files = keep_all_files\n        self.files_to_delete = []\n\n        # Create a surface object for the boundary:\n        logger.debug(f\"In __init__, si.istellsym={si.istellsym} stellsym={stellsym}\")\n        self._boundary = SurfaceRZFourier(nfp=si.nfp,\n                                          stellsym=stellsym,\n                                          mpol=si.mpol,\n                                          ntor=si.ntor)\n\n        # Transfer the boundary shape from fortran to the boundary\n        # surface object:\n        for m in range(si.mpol + 1):\n            for n in range(-si.ntor, si.ntor + 1):\n                self._boundary.rc[m,\n                                  n + si.ntor] = si.rbc[n + si.mntor,\n                                                        m + si.mmpol]\n                self._boundary.zs[m,\n                                  n + si.ntor] = si.zbs[n + si.mntor,\n                                                        m + si.mmpol]\n                if not stellsym:\n                    self._boundary.rs[m,\n                                      n + si.ntor] = si.rbs[n + si.mntor,\n                                                            m + si.mmpol]\n                    self._boundary.zc[m,\n                                      n + si.ntor] = si.zbc[n + si.mntor,\n                                                            m + si.mmpol]\n        self._boundary.local_full_x = self._boundary.get_dofs()\n\n        self.need_to_run_code = True\n        self.counter = -1\n\n        # Set profiles as None - these have to be defined in a script if the user\n        # wish to use them as degrees of freedom\n        self._volume_current_profile = None\n        self._interface_current_profile = None\n        self._pressure_profile = None\n        self._iota_profile = None\n        self._oita_profile = None\n        self._mu_profile = None\n        self._pflux_profile = None\n        self._tflux_profile = None\n        self._helicity_profile = None\n\n        # Define normal field - these are the Vns, Vnc harmonics. Can be used as\n        # dofs in an optimization\n        if si.lfreebound:\n            self.normal_field = NormalField.from_spec(filename)\n        else:\n            self.normal_field = None\n\n        # By default, all dofs owned by SPEC directly, as opposed to\n        # dofs owned by the boundary surface object, are fixed.\n        x0 = self.get_dofs()\n        fixed = np.full(len(x0), True)\n        names = ['phiedge', 'curtor']\n        if si.lfreebound:\n            depends_on = [self.normal_field]\n        else:\n            depends_on = [self._boundary]\n\n        super().__init__(x0=x0, fixed=fixed, names=names,\n                         depends_on=depends_on,\n                         external_dof_setter=Spec.set_dofs)",
  "def boundary(self):\n        \"\"\"\n        Getter for the plasma boundary\n\n        Returns:\n            SurfaceRZFourier instance representing the plasma boundary\n        \"\"\"\n        return self._boundary",
  "def pressure_profile(self):\n        \"\"\"\n        Getter for the pressure profile\n\n        Returns:\n            ProfileSpec instance representing the pressure profile\n        \"\"\"\n        return self._pressure_profile",
  "def pressure_profile(self, pressure_profile):\n        \"\"\"\n        Setter for the pressure profile\n\n        Args:\n            ProfileSpec instance for the pressure profile\n        \"\"\"\n\n        # Check inputs\n        if not isinstance(pressure_profile, ProfileSpec):\n            ValueError('Input should be a ProfileSpec')\n\n        # Check size\n        if pressure_profile.dofs.full_x.size != self.mvol:\n            ValueError('Invalid number of dofs. Shoudl be equal to Mvol!')\n\n        # Update pressure profile\n        if pressure_profile is not self._pressure_profile:\n            logging.debug('Replacing pressure_profile in setter')\n            if self._pressure_profile is not None:\n                self.remove_parent(self._pressure_profile)\n            self._pressure_profile = pressure_profile\n            if pressure_profile is not None:\n                self.append_parent(pressure_profile)\n                self.need_to_run_code = True",
  "def volume_current_profile(self):\n        \"\"\"\n        Getter for the volume current profile (Ivolume)\n\n        Returns:\n            ProfileSpec instance representing the volume current profile\n        \"\"\"\n        return self._volume_current_profile",
  "def volume_current_profile(self, volume_current_profile):\n        \"\"\"\n        Setter for the volume current profile\n\n        Args:\n            ProfileSpec instance for the volume current profile\n        \"\"\"\n\n        if not isinstance(volume_current_profile, ProfileSpec):\n            ValueError('Input should be a ProfileSpec')\n\n        # Check size\n        if volume_current_profile.dofs.full_x.size != self.mvol:\n            ValueError('Invalid number of dofs. Shoudl be equal to Mvol!')\n\n        # Volume current is a cumulative property\n        volume_current_profile.cumulative = True\n\n        if volume_current_profile is not self._volume_current_profile:\n            logging.debug('Replacing pressure_profile in setter')\n            if self._volume_current_profile is not None:\n                self.remove_parent(self._volume_current_profile)\n            self._volume_current_profile = volume_current_profile\n            if volume_current_profile is not None:\n                self.append_parent(volume_current_profile)\n                self.need_to_run_code = True",
  "def interface_current_profile(self):\n        \"\"\"\n        Getter for the surface current profile (Isurf)\n\n        Returns:\n            ProfileSpec instance representing the surface current profile\n        \"\"\"\n        return self._interface_current_profile",
  "def interface_current_profile(self, interface_current_profile):\n        \"\"\"\n        Setter for the surface current profile\n\n        Args:\n            ProfileSpec instance for the surface current profile\n        \"\"\"\n\n        if not isinstance(interface_current_profile, ProfileSpec):\n            ValueError('Input should be a ProfileSpec')\n\n        # Check size\n        if interface_current_profile.dofs.full_x.size != self.mvol:\n            ValueError('Invalid number of dofs. Shoudl be equal to Mvol!')\n\n        if interface_current_profile is not self._interface_current_profile:\n            logging.debug('Replacing pressure_profile in setter')\n            if self._interface_current_profile is not None:\n                self.remove_parent(self._interface_current_profile)\n            self._interface_current_profile = interface_current_profile\n            if interface_current_profile is not None:\n                self.append_parent(interface_current_profile)\n                self.need_to_run_code = True",
  "def iota_profile(self):\n        \"\"\"\n        Getter for the inner rotational transform profile (iota)\n\n        Returns:\n            ProfileSpec instance representing the iota profile\n        \"\"\"\n        return self._iota_profile",
  "def iota_profile(self, iota_profile):\n        \"\"\"\n        Setter for the inner rotational transform profile (iota)\n\n        Args:\n            ProfileSpec instance for the inner rotational transform profile\n        \"\"\"\n\n        if not isinstance(iota_profile, ProfileSpec):\n            ValueError('Input should be a ProfileSpec')\n\n        # Check size\n        if iota_profile.dofs.full_x.size != self.mvol:\n            ValueError('Invalid number of dofs. Shoudl be equal to Mvol!')\n\n        if iota_profile is not self._iota_profile:\n            logging.debug('Replacing pressure_profile in setter')\n            if self._iota_profile is not None:\n                self.remove_parent(self._iota_profile)\n            self._iota_profile = iota_profile\n            if iota_profile is not None:\n                self.append_parent(iota_profile)\n                self.need_to_run_code = True",
  "def oita_profile(self):\n        \"\"\"\n        Getter for the outer rotational transform profile (oita)\n\n        Returns:\n            ProfileSpec instance representing the oita profile\n        \"\"\"\n        return self._oita_profile",
  "def oita_profile(self, oita_profile):\n        \"\"\"\n        Setter for the outer rotational transform profile (oita)\n\n        Args:\n            ProfileSpec instance for the outer rotational transform profile\n        \"\"\"\n\n        if not isinstance(oita_profile, ProfileSpec):\n            ValueError('Input should be a ProfileSpec')\n\n        # Check size\n        if oita_profile.dofs.full_x.size != self.mvol:\n            ValueError('Invalid number of dofs. Shoudl be equal to Mvol!')\n\n        if oita_profile is not self._oita_profile:\n            logging.debug('Replacing pressure_profile in setter')\n            if self._oita_profile is not None:\n                self.remove_parent(self._oita_profile)\n            self._oita_profile = oita_profile\n            if oita_profile is not None:\n                self.append_parent(oita_profile)\n                self.need_to_run_code = True",
  "def mu_profile(self):\n        \"\"\"\n        Getter for the mu-profile\n\n        Returns:\n            ProfileSpec instance representing the mu profile\n        \"\"\"\n        return self._mu_profile",
  "def mu_profile(self, mu_profile):\n        \"\"\"\n        Setter for the mu profile (oita)\n\n        Args:\n            ProfileSpec instance for the outer rotational transform profile\n        \"\"\"\n\n        if not isinstance(mu_profile, ProfileSpec):\n            ValueError('Input should be a ProfileSpec')\n\n        # Check size\n        if mu_profile.dofs.full_x.size != self.mvol:\n            ValueError('Invalid number of dofs. Shoudl be equal to Mvol!')\n\n        if mu_profile is not self._mu_profile:\n            logging.debug('Replacing pressure_profile in setter')\n            if self._mu_profile is not None:\n                self.remove_parent(self._mu_profile)\n            self._mu_profile = mu_profile\n            if mu_profile is not None:\n                self.append_parent(mu_profile)\n                self.need_to_run_code = True",
  "def pflux_profile(self):\n        \"\"\"\n        Getter for the poloidal flux profile (pflux)\n\n        Returns:\n            ProfileSpec instance representing the poloidal flux profile\n        \"\"\"\n        return self._pflux_profile",
  "def pflux_profile(self, pflux_profile):\n        \"\"\"\n        Setter for the poloidal flux profile (pflux)\n\n        Args:\n            ProfileSpec instance for the poloidal flux profile\n        \"\"\"\n\n        if not isinstance(pflux_profile, ProfileSpec):\n            ValueError('Input should be a ProfileSpec')\n\n        # Check size\n        if pflux_profile.dofs.full_x.size != self.mvol:\n            ValueError('Invalid number of dofs. Shoudl be equal to Mvol!')\n\n        # pflux is a cumulative property\n        pflux_profile.cumulative = True\n\n        if pflux_profile is not self._pflux_profile:\n            logging.debug('Replacing pressure_profile in setter')\n            if self._pflux_profile is not None:\n                self.remove_parent(self._pflux_profile)\n            self._pflux_profile = pflux_profile\n            if pflux_profile is not None:\n                self.append_parent(pflux_profile)\n                self.need_to_run_code = True",
  "def tflux_profile(self):\n        \"\"\"\n        Getter for the toroidal flux profile (tflux)\n\n        Returns:\n            ProfileSpec instance representing the toroidal flux profile\n        \"\"\"\n        return self._tflux_profile",
  "def tflux_profile(self, tflux_profile):\n        \"\"\"\n        Setter for the toroidal flux profile (tflux)\n\n        Args:\n            ProfileSpec instance for the toroidal flux profile\n        \"\"\"\n\n        if not isinstance(tflux_profile, ProfileSpec):\n            ValueError('Input should be a ProfileSpec')\n\n        # Check size\n        if tflux_profile.dofs.full_x.size != self.mvol:\n            ValueError('Invalid number of dofs. Shoudl be equal to Mvol!')\n\n        # pflux is a cumulative property\n        tflux_profile.cumulative = True\n\n        if tflux_profile is not self._tflux_profile:\n            logging.debug('Replacing pressure_profile in setter')\n            if self._tflux_profile is not None:\n                self.remove_parent(self._tflux_profile)\n            self._tflux_profile = tflux_profile\n            if tflux_profile is not None:\n                self.append_parent(tflux_profile)\n                self.need_to_run_code = True",
  "def helicity_profile(self):\n        \"\"\"\n        Getter for the magnetic helicity profile (helicity)\n\n        Returns:\n            ProfileSpec instance representing the magnetic helicity profile\n        \"\"\"\n        return self._helicity_profile",
  "def helicity_profile(self, helicity_profile):\n        \"\"\"\n        Setter for the toroidal flux profile (tflux)\n\n        Args:\n            ProfileSpec instance for the toroidal flux profile\n        \"\"\"\n\n        if not isinstance(helicity_profile, ProfileSpec):\n            ValueError('Input should be a ProfileSpec')\n\n        # Check size\n        if helicity_profile.dofs.full_x.size != self.mvol:\n            ValueError('Invalid number of dofs. Shoudl be equal to Mvol!')\n\n        if helicity_profile is not self._helicity_profile:\n            logging.debug('Replacing pressure_profile in setter')\n            if self._helicity_profile is not None:\n                self.remove_parent(self._tflux_profile)\n            self._helicity_profile = helicity_profile\n            if helicity_profile is not None:\n                self.append_parent(helicity_profile)\n                self.need_to_run_code = True",
  "def set_profile(self, longname, lvol, value):\n        \"\"\"\n        This function is used to set the pressure, currents, iota, oita,\n        mu pflux and/or tflux in volume lvol\n\n        Args:\n            longname: string, either \n                - 'pressure'\n                - 'volume_current'\n                - 'surface_current'\n                - 'iota'\n                - 'oita'\n                - 'mu'\n                - 'pflux'\n                - 'tflux'\n                - 'helicity'\n            lvol: integer, from 0 to Mvol-1\n            value: real, new value\n        \"\"\"\n        profile = self.__getattribute__(longname + \"_profile\")\n        if profile is None:\n            return\n\n        # If the profile is cumulative, values in lvol to Mvol-1 are modified.\n        # If it is not cumulative, only the value in lvol is modified.\n        if profile.cumulative: \n            old_value = profile.f(lvol)\n\n            profile.set(lvol, value)\n            for ivol in range(lvol + 1, self.mvol):\n                profile.set(ivol, profile.f(ivol) - old_value + value)\n        else:\n            profile.set(lvol, value)",
  "def get_profile(self, longname, lvol):\n        \"\"\"\n        This function is used to get the pressure, currents, iota, oita,\n        mu pflux and/or tflux profiles.\n\n        Args:\n            longname: string, either\n                - 'pressure'\n                - 'volume_current'\n                - 'surface_current'\n                - 'iota'\n                - 'oita'\n                - 'mu'\n                - 'pflux'\n                - 'tflux'\n                - 'helicity'\n            lvol: integer, list or np.array of volume indices, from 0 to Mvol-1\n        Returns:\n            np.array of length lvol, with the profiles values.\n        \"\"\"\n\n        profile = self.__getattribute__(longname + \"_profile\")\n        if profile is None:\n            return\n\n        return profile.f(lvol)",
  "def boundary(self, boundary):\n        \"\"\"\n        Setter for the geometry of the plasma boundary\n        \"\"\"\n\n        if self._boundary is not boundary:\n            self.remove_parent(self._boundary)\n            self._boundary = boundary\n            self.append_parent(boundary)",
  "def recompute_bell(self, parent=None):\n        self.need_to_run_code = True",
  "def get_dofs(self):\n        return np.array([self.inputlist.phiedge,\n                         self.inputlist.curtor])",
  "def set_dofs(self, x):\n        self.need_to_run_code = True\n        self.inputlist.phiedge = x[0]\n        self.inputlist.curtor = x[1]\n\n        profiles = [\n            self._volume_current_profile,\n            self._interface_current_profile,\n            self._pressure_profile,\n            self._iota_profile,\n            self._oita_profile,\n            self._mu_profile,\n            self._pflux_profile,\n            self._tflux_profile,\n            self._helicity_profile\n        ]\n        for p in profiles:\n            if p is not None:\n                p.phiedge = x[0]",
  "def init(self, filename: str):\n        \"\"\"\n        Initialize SPEC fortran state from an input file.\n\n        Args:\n            filename: Name of the file to load. It should end in ``.sp``.\n        \"\"\"\n        logger.debug(\"Entering init\")\n        if self.mpi.proc0_groups:\n            spec.inputlist.initialize_inputs()\n            logger.debug(\"Done with initialize_inputs\")\n            self.extension = filename[:-3]  # Remove the \".sp\"\n            spec.allglobal.ext = self.extension\n            spec.allglobal.read_inputlists_from_file()\n            logger.debug(\"Done with read_inputlists_from_file\")\n            spec.allglobal.check_inputs()\n\n        logger.debug('About to call broadcast_inputs')\n        spec.allglobal.broadcast_inputs()\n        logger.debug('About to call preset')\n        spec.preset()\n        logger.debug(\"Done with init\")",
  "def run(self, update_guess: bool = True):\n        \"\"\"\n        Run SPEC, if needed.\n\n        Args:\n            - update_guess: boolean. If True, initial guess will be updated with\n              the geometry of the interfaces found at equilibrium. Default is \n              True\n        \"\"\"\n        if not self.need_to_run_code:\n            logger.info(\"run() called but no need to re-run SPEC.\")\n            return\n        logger.info(\"Preparing to run SPEC.\")\n        self.counter += 1\n\n        si = self.inputlist  # Shorthand\n\n        # Check that number of volumes in internal memory is consistent with\n        # the input file\n        if self.nvol != si.nvol:\n            ValueError('Inconsistent Nvol')\n\n        # nfp must be consistent between the surface and SPEC. The surface's\n        # value trumps.\n        si.nfp = self.boundary.nfp\n        si.istellsym = int(self.boundary.stellsym)\n\n        # Convert boundary to RZFourier if needed:\n        boundary_RZFourier = self.boundary.to_RZFourier()\n\n        # Transfer boundary data to fortran:\n        si.rbc[:, :] = 0.0\n        si.zbs[:, :] = 0.0\n        si.rbs[:, :] = 0.0\n        si.zbc[:, :] = 0.0\n        mpol_capped = np.min([boundary_RZFourier.mpol, si.mmpol])\n        ntor_capped = np.min([boundary_RZFourier.ntor, si.mntor])\n        stellsym = bool(si.istellsym)\n        logger.debug(f\"In run, si.istellsym = {si.istellsym} stellsym = {stellsym}\")\n        for m in range(mpol_capped + 1):\n            for n in range(-ntor_capped, ntor_capped + 1):\n                si.rbc[n + si.mntor, m + si.mmpol] = boundary_RZFourier.get_rc(m, n)\n                si.zbs[n + si.mntor, m + si.mmpol] = boundary_RZFourier.get_zs(m, n)\n                if not stellsym:\n                    si.rbs[n + si.mntor, m + si.mmpol] = boundary_RZFourier.get_rs(m, n)\n                    si.zbc[n + si.mntor, m + si.mmpol] = boundary_RZFourier.get_zc(m, n)\n\n        # Set the coordinate axis using the lrzaxis=2 feature:\n        si.lrzaxis = 2\n\n        # Set axis from latest converged state\n        mn = self.axis['rac'].size\n        si.rac[0:mn] = self.axis['rac']\n        si.zas[0:mn] = self.axis['zas']\n        if si.istellsym == 0:\n            si.ras[0:mn] = self.axis['ras']\n            si.zac[0:mn] = self.axis['zac']\n\n        # Set initial guess\n        if not self.initial_guess is None:        \n            # Set all modes to zero\n            spec.allglobal.mmrzrz[:] = 0\n            spec.allglobal.nnrzrz[:] = 0\n            spec.allglobal.allrzrz[:] = 0\n\n            # transform to SurfaceRZFourier if necessary\n            initial_guess = [s.to_RZFourier() for s in self.initial_guess]\n\n            # Loop on modes\n            imn = -1  # counter\n            for mm in range(0, si.mpol+1):\n                for nn in range(-si.ntor, si.ntor+1):\n                    if mm == 0 and nn < 0:\n                        continue\n\n                    imn += 1\n\n                    spec.allglobal.mmrzrz[imn] = mm\n                    spec.allglobal.nnrzrz[imn] = nn\n\n                    # Populate inner plasma boundaries\n                    for lvol in range(0, self.nvol-1):\n                        spec.allglobal.allrzrz[0, lvol, imn] = initial_guess[lvol].get_rc(mm, nn)\n                        spec.allglobal.allrzrz[1, lvol, imn] = initial_guess[lvol].get_zs(mm, nn)\n\n                        if not si.istellsym:\n                            spec.allglobal.allrzrz[2, lvol, imn] = initial_guess[lvol].get_rs(mm, nn)\n                            spec.allglobal.allrzrz[3, lvol, imn] = initial_guess[lvol].get_zc(mm, nn)\n\n                    # Populate plasma boundary\n                    if si.lfreebound:\n                        si.rbc[si.mntor+nn, si.mmpol+mm] = initial_guess[self.nvol-1].get_rc(mm, nn)\n                        si.zbs[si.mntor+nn, si.mmpol+mm] = initial_guess[self.nvol-1].get_zs(mm, nn)\n\n                        if not si.istellsym:\n                            si.rbs[si.mntor+nn, si.mmpol+mm] = initial_guess[self.nvol-1].get_rs(mm, nn)\n                            si.zbc[si.mntor+nn, si.mmpol+mm] = initial_guess[self.nvol-1].get_zc(mm, nn)\n\n            spec.allglobal.num_modes = imn + 1\n\n        # Set profiles from dofs\n        if self.pressure_profile is not None:\n            si.pressure[0:self.nvol] = self.pressure_profile.get(\n                np.arange(0, self.nvol))\n            if si.lfreebound:\n                si.pressure[self.nvol] = 0\n\n        if self.volume_current_profile is not None:\n            # Volume current is a cumulative profile; special care is required\n            # when a dofs is changed in order to keep fixed dofs fixed!\n            old_ivolume = copy.copy(si.ivolume)\n            for lvol in range(0, self.mvol):\n                if self.volume_current_profile.is_fixed(lvol):\n                    if lvol != 0:\n                        si.ivolume[lvol] = si.ivolume[lvol] - \\\n                            old_ivolume[lvol - 1] + si.ivolume[lvol - 1]\n                        self.set_profile(\n                            'volume_current', lvol=lvol, value=si.ivolume[lvol])\n                else:\n                    si.ivolume[lvol] = self.get_profile('volume_current', lvol)\n\n            if si.lfreebound:\n                si.ivolume[self.nvol] = si.ivolume[self.nvol - 1]\n                self.volume_current_profile.set(\n                    key=self.mvol - 1, new_val=si.ivolume[self.nvol - 1])\n\n        if self.interface_current_profile is not None:\n            si.isurf[0:self.mvol - 1] = \\\n                self.interface_current_profile.get(np.arange(0, self.mvol-1))\n\n        # Update total plasma toroidal current in case of freeboundary\n        # calculation\n        if ((self.volume_current_profile is not None) or\n            (self.interface_current_profile is not None)) and \\\n                si.lfreebound:\n            si.curtor = si.ivolume[self.nvol - 1] + np.sum(si.isurf)\n\n        if self.iota_profile is not None:\n            si.iota[0:self.nvol+1] = self.iota_profile.get(np.arange(0, self.nvol))\n\n        if self.oita_profile is not None:\n            si.oita[0:self.nvol+1] = self.oita_profile.get(np.arange(0, self.nvol))\n\n        if self.mu_profile is not None:\n            si.mu[0:self.nvol] = self.mu_profile.get(np.arange(0, self.nvol))\n            if si.lfreebound:\n                si.mu[self.mvol] = 0\n\n        if self.pflux_profile is not None:\n            # Pflux is a cumulative profile; special care is required\n            # when a dofs is changed in order to keep fixed dofs fixed!\n            old_pflux = copy.copy(si.pflux)\n            for lvol in range(0, self.mvol):\n                if self.pflux_profile.is_fixed(lvol):\n                    if lvol != 0:\n                        si.pflux[lvol] = si.pflux[lvol] - \\\n                            old_pflux[lvol - 1] + si.pflux[lvol - 1]\n                        self.pflux_profile.set(\n                            key=lvol, new_val=si.pflux[lvol])\n                else:\n                    si.pflux[lvol] = self.pflux_profile.get(lvol)\n\n        if self.tflux_profile is not None:\n            # tflux is a cumulative profile; special care is required\n            # when a dofs is changed in order to keep fixed dofs fixed!\n            old_tflux = copy.copy(si.tflux)\n            for lvol in range(0, self.mvol):\n                if self.tflux_profile.is_fixed(lvol):\n                    if lvol != 0:\n                        si.tflux[lvol] = si.tflux[lvol] - \\\n                            old_tflux[lvol - 1] + si.tflux[lvol - 1]\n                        self.tflux_profile.set(\n                            key=lvol, new_val=si.tflux[lvol])\n                else:\n                    si.tflux[lvol] = self.tflux_profile.get(lvol)\n\n        if self.helicity_profile is not None:\n            si.helicity[0:self.nvol] = self.helicity_profile.get(np.arange(0, self.nvol))\n            if si.lfreebound:\n                si.helicity[self.mvol] = 0\n\n        # Another possible way to initialize the coordinate axis: use\n        # the m=0 modes of the boundary.\n        # m = 0\n        # for n in range(2):\n        #     si.rac[n] = si.rbc[n + si.mntor, m + si.mmpol]\n        #     si.zas[n] = si.zbs[n + si.mntor, m + si.mmpol]\n        filename = self.extension + \\\n            '_{:03}_{:06}'.format(self.mpi.group, self.counter)\n        logger.info(\"Running SPEC using filename \" + filename)\n        self.allglobal.ext = filename\n        try:\n            # Here is where we actually run SPEC:\n            if self.mpi.proc0_groups:\n                logger.debug('About to call check_inputs')\n                spec.allglobal.check_inputs()\n            logger.debug('About to call broadcast_inputs')\n            spec.allglobal.broadcast_inputs()\n            logger.debug('About to call preset')\n            spec.preset()\n            logger.debug(f'About to call init_outfile')\n            spec.sphdf5.init_outfile()\n            logger.debug('About to call mirror_input_to_outfile')\n            spec.sphdf5.mirror_input_to_outfile()\n            if self.mpi.proc0_groups:\n                logger.debug('About to call wrtend')\n                spec.allglobal.wrtend()\n            logger.debug('About to call init_convergence_output')\n            spec.sphdf5.init_convergence_output()\n            logger.debug(f'About to call spec')\n            spec.spec()\n            logger.debug('About to call diagnostics')\n            spec.final_diagnostics()\n            logger.debug('About to call write_grid')\n            spec.sphdf5.write_grid()\n            if self.mpi.proc0_groups:\n                logger.debug('About to call wrtend')\n                spec.allglobal.wrtend()\n            logger.debug('About to call hdfint')\n            spec.sphdf5.hdfint()\n            logger.debug('About to call finish_outfile')\n            spec.sphdf5.finish_outfile()\n            logger.debug('About to call ending')\n            spec.ending()\n\n        except BaseException:\n            if self.verbose:\n                traceback.print_exc()\n            raise ObjectiveFailure(\"SPEC did not run successfully.\")\n\n        logger.info(\"SPEC run complete.\")\n        # Barrier so workers do not try to read the .h5 file before it\n        # is finished:\n        self.mpi.comm_groups.Barrier()\n\n        # Try to read SPEC output. \n        try:\n            self.results = py_spec.SPECout(filename + '.sp.h5')\n        except BaseException:\n            if self.verbose:\n                traceback.print_exc()\n            raise ObjectiveFailure(\n                \"Unable to read results following SPEC execution\")\n\n        logger.info(\"Successfully loaded SPEC results.\")\n        self.need_to_run_code = False\n\n        # Deal with unconverged equilibria - these are excluded by \n        # the optimizer, and the objective function is set to a large number\n        if self.results.output.ForceErr > self.tolerance:\n            raise ObjectiveFailure(\n                'SPEC could not find force balance'\n            )\n\n        # Save geometry as initial guess for next iterations\n        if update_guess:\n            new_guess = None\n            if self.mvol > 1:\n                new_guess = [\n                    SurfaceRZFourier(nfp=si.nfp, stellsym=si.istellsym, mpol=si.mpol, ntor=si.ntor) for n in range(0, self.mvol-1)\n                ]\n\n                for ii, (mm, nn) in enumerate(zip(self.results.output.im, self.results.output.in_)):\n                    nnorm = (nn / si.nfp).astype('int')\n                    for lvol in range(0, self.mvol-1):\n                        new_guess[lvol].set_rc(mm, nnorm, self.results.output.Rbc[lvol+1, ii])\n                        new_guess[lvol].set_zs(mm, nnorm, self.results.output.Zbs[lvol+1, ii])\n\n                        if not si.istellsym:\n                            new_guess[lvol].set_rs(mm, nnorm, self.results.output.Rbs[lvol+1, ii])\n                            new_guess[lvol].set_zc(mm, nnorm, self.results.output.Zbc[lvol+1, ii])\n\n                axis = {}\n                axis['rac'] = self.results.output.Rbc[0, 0:si.ntor+1]\n                axis['zas'] = self.results.output.Zbs[0, 0:si.ntor+1]\n                self.axis = copy.copy(axis)\n\n            # Enforce SPEC to use initial guess\n            self.initial_guess = new_guess\n            self.inputlist.linitialize = 0\n\n        # Group leaders handle deletion of files:\n        if self.mpi.proc0_groups:\n            # If the worker group is not 0, delete all wout files, unless\n            # keep_all_files is True:\n            if (not self.keep_all_files) and (self.mpi.group > 0):\n                os.remove(filename + '.sp.h5')\n                os.remove(filename + '.sp.end')\n\n            # Delete the previous output file, if desired:\n            for file_to_delete in self.files_to_delete:\n                os.remove(file_to_delete)\n            self.files_to_delete = []\n\n            # Record the latest output file to delete if we run again:\n            if (self.mpi.group == 0) and (\n                    self.counter > 0) and (not self.keep_all_files):\n                self.files_to_delete.append(filename + '.sp.h5')\n                self.files_to_delete.append(filename + '.sp.end')",
  "def volume(self):\n        \"\"\"\n        Return the volume inside the boundary flux surface.\n        \"\"\"\n        self.run()\n        return self.results.output.volume * self.results.input.physics.Nfp",
  "def iota(self):\n        \"\"\"\n        Return the rotational transform in the middle of the volume.\n        \"\"\"\n        self.run()\n        return self.results.transform.fiota[1, 0]",
  "def __init__(self, spec, pp, qq, vol=1, theta=0, s_guess=None, s_min=-1.0,\n                 s_max=1.0, rtol=1e-9):\n        # if not spec_found:\n        if spec is None:\n            raise RuntimeError(\n                \"Residue requires spec package to be installed.\")\n        # if not pyoculus_found:\n        if pyoculus is None:\n            raise RuntimeError(\n                \"Residue requires pyoculus package to be installed.\")\n\n        self.spec = spec\n        self.pp = pp\n        self.qq = qq\n        self.vol = vol\n        self.theta = theta\n        self.rtol = rtol\n        if s_guess is None:\n            self.s_guess = 0.0\n        else:\n            self.s_guess = s_guess\n        self.s_min = s_min\n        self.s_max = s_max\n        self.depends_on = ['spec']\n        self.need_to_run_code = True\n        self.fixed_point = None\n        # We may at some point want to allow Residue to use a\n        # different MpiPartition than the Spec object it is attached\n        # to, but for now we'll use the same MpiPartition for\n        # simplicity.\n        self.mpi = spec.mpi\n        super().__init__(depends_on=[spec])",
  "def recompute_bell(self, parent=None):\n        self.need_to_run_code = True",
  "def J(self):\n        \"\"\"\n        Run Spec if needed, find the periodic field line, and return the residue\n        \"\"\"\n        if not self.mpi.proc0_groups:\n            logger.info(\n                \"This proc is skipping Residue.J() since it is not a group leader.\")\n            return\n\n        if self.need_to_run_code:\n            self.spec.run()\n            specb = pyoculus.problems.SPECBfield(self.spec.results, self.vol)\n            # Set nrestart=0 because otherwise the random guesses in\n            # pyoculus can cause examples/tests to be\n            # non-reproducible.\n            fp = pyoculus.solvers.FixedPoint(\n                specb, {\n                    'theta': self.theta, 'nrestart': 0}, integrator_params={\n                    'rtol': self.rtol})\n            self.fixed_point = fp.compute(self.s_guess,\n                                          sbegin=self.s_min,\n                                          send=self.s_max,\n                                          pp=self.pp, qq=self.qq)\n            self.need_to_run_code = False\n\n        if self.fixed_point is None:\n            raise ObjectiveFailure(\"Residue calculation failed\")\n\n        return self.fixed_point.GreenesResidue",
  "class Boozer(Optimizable):\n    \"\"\"\n    This class handles the transformation to Boozer coordinates.\n\n    A Boozer instance maintains a set \"s\", which is a registry of the\n    surfaces on which other objects want Boozer-coordinate data. When\n    the run() method is called, the Boozer transformation is carried\n    out on all these surfaces. The registry can be cleared at any time\n    by setting the s attribute to {}.\n    \"\"\"\n\n    mpol = Integer()\n    ntor = Integer()\n\n    def __init__(self,\n                 equil: Vmec,\n                 mpol: int = 32,\n                 ntor: int = 32,\n                 verbose: bool = False) -> None:\n        \"\"\"\n        Constructor\n        \"\"\"\n        if booz_xform is None:\n            raise RuntimeError(\n                \"To use a Boozer object, the booz_xform package \"\n                \"must be installed. Run 'pip install -v booz_xform'\")\n\n        self.equil = equil\n        self.mpol = mpol\n        self.ntor = ntor\n        self.bx = booz_xform.Booz_xform()\n        self.bx.verbose = verbose\n        self.s = set()\n        self.need_to_run_code = True\n        self._calls = 0  # For testing, keep track of how many times we call bx.run()\n\n        # We may at some point want to allow booz_xform to use a\n        # different partitioning of the MPI processors compared to the\n        # equilibrium code. But for simplicity, we'll use the same mpi\n        # partition for now. For unit tests, we allow equil to be None,\n        # so we have to allow for this case here.\n        self.mpi = None\n        if equil is not None:\n            self.mpi = equil.mpi\n        if equil is not None:\n            super().__init__(depends_on=[equil])\n        else:\n            super().__init__()\n\n    def recompute_bell(self, parent=None):\n        self.need_to_run_code = True\n\n    def register(self, s: Union[float, Iterable[float]]) -> None:\n        \"\"\"\n        This function is called by objects that depend on this Boozer\n        object, to indicate that they will want Boozer data on the\n        given set of surfaces.\n\n        Args:\n            s: 1 or more surfaces on which Boozer data will be requested.\n        \"\"\"\n        # Force input surface data to be a set:\n        try:\n            ss = set(s)\n        except:\n            ss = {s}\n\n        for new_s in ss:\n            if new_s < 0 or new_s > 1:\n                raise ValueError(\"Normalized toroidal flux values s must lie\"\n                                 \"in the interval [0, 1]\")\n        logger.info(\"Adding entries to Boozer registry: {}\".format(ss))\n        self.s = self.s.union(ss)\n        self.need_to_run_code = True\n\n    def run(self):\n        \"\"\"\n        Run booz_xform on all the surfaces that have been registered.\n        \"\"\"\n\n        if (self.mpi is not None) and (not self.mpi.proc0_groups):\n            logger.info(\"This proc is skipping Boozer.run since it is not a group leader.\")\n            return\n\n        if not self.need_to_run_code:\n            logger.info(\"Boozer.run() called but no need to re-run Boozer transformation.\")\n            return\n\n        s = sorted(list(self.s))\n        logger.info(\"Preparing to run Boozer transformation. Registry:{}\".format(s))\n\n        if isinstance(self.equil, Vmec):\n            self.equil.run()\n            wout = self.equil.wout  # Shorthand\n\n            # Get the half-grid points that are closest to the requested values\n            ns = wout.ns\n            s_full = np.linspace(0, 1, ns)\n            ds = s_full[1] - s_full[0]\n            s_half = s_full[1:] - 0.5 * ds\n\n            # For each float value of s at which the Boozer results\n            # have been requested, we need to find the corresponding\n            # radial index of the booz_xform results. The result is\n            # self.s_to_index. Computing this is tricky because\n            # multiple values of s may get rounded to the same\n            # half-grid surface. The solution here is done in two\n            # steps. First we find a map from each float value of s to\n            # the corresponding radial index among all half-grid\n            # surfaces (even ones where we won't compute the Boozer\n            # transformation.) This resulting map is\n            # s_to_index_all_surfs. In a second step,\n            # s_to_index_all_surfs and the list of compute_surfs are\n            # used to find s_to_index.\n\n            compute_surfs = []\n            s_to_index_all_surfs = dict()\n            self.s_used = dict()\n            for ss in s:\n                index = np.argmin(np.abs(s_half - ss))\n                compute_surfs.append(index)\n                s_to_index_all_surfs[ss] = index\n                self.s_used[ss] = s_half[index]\n\n            # Eliminate any duplicates\n            compute_surfs = sorted(list(set(compute_surfs)))\n            logger.info(\"compute_surfs={}\".format(compute_surfs))\n            logger.info(\"s_to_index_all_surfs={}\".format(s_to_index_all_surfs))\n            self.s_to_index = dict()\n            for ss in s:\n                self.s_to_index[ss] = compute_surfs.index(s_to_index_all_surfs[ss])\n            logger.info(\"s_to_index={}\".format(self.s_to_index))\n\n            # Transfer data in memory from VMEC to booz_xform\n            self.bx.asym = bool(wout.lasym)\n            self.bx.nfp = wout.nfp\n\n            self.bx.mpol = wout.mpol\n            self.bx.ntor = wout.ntor\n            self.bx.mnmax = wout.mnmax\n            self.bx.xm = wout.xm\n            self.bx.xn = wout.xn\n            logger.info('mnmax:', wout.mnmax, ' len(xm):', len(wout.xm), ' len(xn):', len(wout.xn))\n            logger.info('mnmax_nyq:', wout.mnmax_nyq, ' len(xm_nyq):', len(wout.xm_nyq), ' len(xn_nyq):', len(wout.xn_nyq))\n            assert len(wout.xm) == wout.mnmax\n            assert len(wout.xn) == wout.mnmax\n            assert len(self.bx.xm) == self.bx.mnmax\n            assert len(self.bx.xn) == self.bx.mnmax\n\n            self.bx.mpol_nyq = int(wout.xm_nyq[-1])\n            self.bx.ntor_nyq = int(wout.xn_nyq[-1] / wout.nfp)\n            self.bx.mnmax_nyq = wout.mnmax_nyq\n            self.bx.xm_nyq = wout.xm_nyq\n            self.bx.xn_nyq = wout.xn_nyq\n            assert len(wout.xm_nyq) == wout.mnmax_nyq\n            assert len(wout.xn_nyq) == wout.mnmax_nyq\n            assert len(self.bx.xm_nyq) == self.bx.mnmax_nyq\n            assert len(self.bx.xn_nyq) == self.bx.mnmax_nyq\n\n            if wout.lasym:\n                rmns = wout.rmns\n                zmnc = wout.zmnc\n                lmnc = wout.lmnc\n                bmns = wout.bmns\n                bsubumns = wout.bsubumns\n                bsubvmns = wout.bsubvmns\n            else:\n                # For stellarator-symmetric configs, the asymmetric\n                # arrays have not been initialized.\n                arr = np.array([[]])\n                rmns = arr\n                zmnc = arr\n                lmnc = arr\n                bmns = arr\n                bsubumns = arr\n                bsubvmns = arr\n\n            # For quantities that depend on radius, booz_xform handles\n            # interpolation and discarding the rows of zeros:\n            self.bx.init_from_vmec(wout.ns,\n                                   wout.iotas,\n                                   wout.rmnc,\n                                   rmns,\n                                   zmnc,\n                                   wout.zmns,\n                                   lmnc,\n                                   wout.lmns,\n                                   wout.bmnc,\n                                   bmns,\n                                   wout.bsubumnc,\n                                   bsubumns,\n                                   wout.bsubvmnc,\n                                   bsubvmns)\n            self.bx.compute_surfs = compute_surfs\n            self.bx.mboz = self.mpol\n            self.bx.nboz = self.ntor\n\n        else:\n            # Cases for SPEC, GVEC, etc could be added here.\n            raise ValueError(\"equil is not an equilibrium type supported by\"\n                             \"Boozer\")\n\n        logger.info(\"About to call booz_xform.Booz_xform.run().\")\n        self.bx.run()\n        self._calls += 1\n        logger.info(\"Returned from calling booz_xform.Booz_xform.run().\")\n        self.need_to_run_code = False",
  "class Quasisymmetry(Optimizable):\n    \"\"\"\n    This class is used to compute the departure from quasisymmetry on\n    a given flux surface based on the Boozer spectrum.\n\n    Args:\n        boozer: A Boozer object on which the calculation will be based.\n        s: The normalized toroidal magnetic flux for the flux surface to analyze. Should be in the range [0, 1].\n        helicity_m: The poloidal mode number of the symmetry you want to achive.\n           The departure from symmetry ``B(helicity_m * theta - nfp * helicity_n * zeta)`` will be reported.\n        helicity_n: The toroidal mode number of the symmetry you want to achieve.\n           The departure from symmetry ``B(helicity_m * theta - nfp * helicity_n * zeta)`` will be reported.\n        normalization: A uniform normalization applied to all bmnc harmonics.\n           If ``\"B00\"``, the symmetry-breaking modes will be divided by the m=n=0 mode amplitude\n           on the same surface. If ``\"symmetric\"``, the symmetry-breaking modes will be\n           divided by the square root of the sum of the squares of all the symmetric\n           modes on the same surface. This is the normalization used in stellopt.\n        weight: An option for a m- or n-dependent weight to be applied to the bmnc amplitudes.\n    \"\"\"\n\n    helicity_m = Integer()\n    helicity_n = Integer()\n\n    def __init__(self,\n                 boozer: Boozer,\n                 s: Union[float, Iterable[float]],\n                 helicity_m: int,\n                 helicity_n: int,\n                 normalization: str = \"B00\",\n                 weight: str = \"even\") -> None:\n        \"\"\"\n        Constructor\n\n        \"\"\"\n        self.boozer = boozer\n        self.helicity_m = helicity_m\n        self.helicity_n = helicity_n\n        self.normalization = normalization\n        self.weight = weight\n\n        # If s is not already iterable, make it so:\n        try:\n            iter(s)\n        except:\n            s = [s]\n        self.s = s\n        boozer.register(s)\n        super().__init__(depends_on=[boozer])\n\n    def recompute_bell(self, parent=None):\n        self.need_to_run_code = True\n\n    def J(self) -> RealArray:\n        \"\"\"\n        Carry out the calculation of the quasisymmetry error.\n\n        Returns:\n            1D numpy array listing all the normalized mode amplitudes of\n            symmetry-breaking Fourier modes of ``|B|``.\n        \"\"\"\n\n        # Only group leaders do anything:\n        if (self.boozer.mpi is not None) and (not self.boozer.mpi.proc0_groups):\n            logger.info(\"This proc is skipping Quasisymmetry.J since it is not a group leader.\")\n            return np.array([])\n\n        # The next line is the expensive part of the calculation:\n        self.boozer.run()\n\n        symmetry_error = []\n        for js, s in enumerate(self.s):\n            index = self.boozer.s_to_index[s]\n            bmnc = self.boozer.bx.bmnc_b[:, index]\n            xm = self.boozer.bx.xm_b\n            xn = self.boozer.bx.xn_b / self.boozer.bx.nfp\n\n            if self.helicity_m != 0 and self.helicity_m != 1:\n                raise ValueError(\"m for quasisymmetry should be 0 or 1.\")\n\n            # Find the indices of the symmetric modes:\n            if self.helicity_n == 0:\n                # Quasi-axisymmetry\n                symmetric = (xn == 0)\n\n            elif self.helicity_m == 0:\n                # Quasi-poloidal symmetry\n                symmetric = (xm == 0)\n\n            else:\n                # Quasi-helical symmetry\n                symmetric = (xm * self.helicity_n + xn * self.helicity_m == 0)\n                # Stellopt takes the \"and\" of this with mod(xm, self.helicity_m),\n                # which does not seem necessary since self.helicity_m must be 1 to\n                # get here.\n            nonsymmetric = np.logical_not(symmetric)\n\n            # Scale all bmnc modes so the average |B| is 1 or close to 1:\n\n            if self.normalization == \"B00\":\n                # Normalize by the (m,n) = (0,0) mode amplitude:\n                assert xm[0] == 0\n                assert xn[0] == 0\n                bnorm = bmnc[0]\n\n            elif self.normalization == \"symmetric\":\n                # Normalize by sqrt(sum_{symmetric modes} B{m,n}^2)\n                temp = bmnc[symmetric]\n                bnorm = np.sqrt(np.dot(temp, temp))\n\n            else:\n                raise ValueError(\"Unrecognized value for normalization in Quasisymmetry\")\n\n            logger.info(\"For s={}, bnorm={}\".format(s, bnorm))\n            bmnc = bmnc / bnorm\n\n            # Apply any weight that depends on m and/or n:\n\n            if self.weight == \"even\":\n                # Evenly weight each bmnc mode. Normalize by the m=n=0 mode on that surface.\n                symmetry_error.append(bmnc[nonsymmetric])\n\n            elif self.weight == \"stellopt\":\n                # Stellopt appears to apply a m-dependent radial\n                # weight, assuming sigma > 0. However, the m is\n                # evaluated outside of any loop over m, so m ends up\n                # taking the value mboz instead of the actual m for\n                # each mode. As a result, there is an even weight by s_used**2.\n\n                s_used = self.boozer.s_used[s]\n                logger.info('s_used, in Quasisymmetry: {}'.format(s_used))\n                \"\"\"\n                rad_sigma = np.full(len(xm), s_used * s_used)\n                rad_sigma[xm < 3] = s_used\n                rad_sigma[xm == 3] = s_used ** 1.5\n                \"\"\"\n                rad_sigma = s_used * s_used\n                temp = bmnc / rad_sigma\n                symmetry_error.append(temp[nonsymmetric])\n\n            elif self.weight == \"stellopt_ornl\":\n                # This option is similar to \"stellopt\" except we\n                # return a single number for the residual instead of a\n                # vector of residuals.\n\n                # For this option, stellopt applies a m-dependent\n                # radial weight only when sigma < 0, the opposite of\n                # when using the non-ORNL helicity! Here, we do not\n                # apply such a weight.\n\n                temp = bmnc[nonsymmetric]\n                symmetry_error.append(np.array([np.sqrt(np.sum(temp * temp))]))\n\n            else:\n                raise ValueError(\"Unrecognized value for weight in Quasisymmetry\")\n\n        return np.array(symmetry_error).flatten()\n\n    return_fn_map = {'J': J}",
  "def __init__(self,\n                 equil: Vmec,\n                 mpol: int = 32,\n                 ntor: int = 32,\n                 verbose: bool = False) -> None:\n        \"\"\"\n        Constructor\n        \"\"\"\n        if booz_xform is None:\n            raise RuntimeError(\n                \"To use a Boozer object, the booz_xform package \"\n                \"must be installed. Run 'pip install -v booz_xform'\")\n\n        self.equil = equil\n        self.mpol = mpol\n        self.ntor = ntor\n        self.bx = booz_xform.Booz_xform()\n        self.bx.verbose = verbose\n        self.s = set()\n        self.need_to_run_code = True\n        self._calls = 0  # For testing, keep track of how many times we call bx.run()\n\n        # We may at some point want to allow booz_xform to use a\n        # different partitioning of the MPI processors compared to the\n        # equilibrium code. But for simplicity, we'll use the same mpi\n        # partition for now. For unit tests, we allow equil to be None,\n        # so we have to allow for this case here.\n        self.mpi = None\n        if equil is not None:\n            self.mpi = equil.mpi\n        if equil is not None:\n            super().__init__(depends_on=[equil])\n        else:\n            super().__init__()",
  "def recompute_bell(self, parent=None):\n        self.need_to_run_code = True",
  "def register(self, s: Union[float, Iterable[float]]) -> None:\n        \"\"\"\n        This function is called by objects that depend on this Boozer\n        object, to indicate that they will want Boozer data on the\n        given set of surfaces.\n\n        Args:\n            s: 1 or more surfaces on which Boozer data will be requested.\n        \"\"\"\n        # Force input surface data to be a set:\n        try:\n            ss = set(s)\n        except:\n            ss = {s}\n\n        for new_s in ss:\n            if new_s < 0 or new_s > 1:\n                raise ValueError(\"Normalized toroidal flux values s must lie\"\n                                 \"in the interval [0, 1]\")\n        logger.info(\"Adding entries to Boozer registry: {}\".format(ss))\n        self.s = self.s.union(ss)\n        self.need_to_run_code = True",
  "def run(self):\n        \"\"\"\n        Run booz_xform on all the surfaces that have been registered.\n        \"\"\"\n\n        if (self.mpi is not None) and (not self.mpi.proc0_groups):\n            logger.info(\"This proc is skipping Boozer.run since it is not a group leader.\")\n            return\n\n        if not self.need_to_run_code:\n            logger.info(\"Boozer.run() called but no need to re-run Boozer transformation.\")\n            return\n\n        s = sorted(list(self.s))\n        logger.info(\"Preparing to run Boozer transformation. Registry:{}\".format(s))\n\n        if isinstance(self.equil, Vmec):\n            self.equil.run()\n            wout = self.equil.wout  # Shorthand\n\n            # Get the half-grid points that are closest to the requested values\n            ns = wout.ns\n            s_full = np.linspace(0, 1, ns)\n            ds = s_full[1] - s_full[0]\n            s_half = s_full[1:] - 0.5 * ds\n\n            # For each float value of s at which the Boozer results\n            # have been requested, we need to find the corresponding\n            # radial index of the booz_xform results. The result is\n            # self.s_to_index. Computing this is tricky because\n            # multiple values of s may get rounded to the same\n            # half-grid surface. The solution here is done in two\n            # steps. First we find a map from each float value of s to\n            # the corresponding radial index among all half-grid\n            # surfaces (even ones where we won't compute the Boozer\n            # transformation.) This resulting map is\n            # s_to_index_all_surfs. In a second step,\n            # s_to_index_all_surfs and the list of compute_surfs are\n            # used to find s_to_index.\n\n            compute_surfs = []\n            s_to_index_all_surfs = dict()\n            self.s_used = dict()\n            for ss in s:\n                index = np.argmin(np.abs(s_half - ss))\n                compute_surfs.append(index)\n                s_to_index_all_surfs[ss] = index\n                self.s_used[ss] = s_half[index]\n\n            # Eliminate any duplicates\n            compute_surfs = sorted(list(set(compute_surfs)))\n            logger.info(\"compute_surfs={}\".format(compute_surfs))\n            logger.info(\"s_to_index_all_surfs={}\".format(s_to_index_all_surfs))\n            self.s_to_index = dict()\n            for ss in s:\n                self.s_to_index[ss] = compute_surfs.index(s_to_index_all_surfs[ss])\n            logger.info(\"s_to_index={}\".format(self.s_to_index))\n\n            # Transfer data in memory from VMEC to booz_xform\n            self.bx.asym = bool(wout.lasym)\n            self.bx.nfp = wout.nfp\n\n            self.bx.mpol = wout.mpol\n            self.bx.ntor = wout.ntor\n            self.bx.mnmax = wout.mnmax\n            self.bx.xm = wout.xm\n            self.bx.xn = wout.xn\n            logger.info('mnmax:', wout.mnmax, ' len(xm):', len(wout.xm), ' len(xn):', len(wout.xn))\n            logger.info('mnmax_nyq:', wout.mnmax_nyq, ' len(xm_nyq):', len(wout.xm_nyq), ' len(xn_nyq):', len(wout.xn_nyq))\n            assert len(wout.xm) == wout.mnmax\n            assert len(wout.xn) == wout.mnmax\n            assert len(self.bx.xm) == self.bx.mnmax\n            assert len(self.bx.xn) == self.bx.mnmax\n\n            self.bx.mpol_nyq = int(wout.xm_nyq[-1])\n            self.bx.ntor_nyq = int(wout.xn_nyq[-1] / wout.nfp)\n            self.bx.mnmax_nyq = wout.mnmax_nyq\n            self.bx.xm_nyq = wout.xm_nyq\n            self.bx.xn_nyq = wout.xn_nyq\n            assert len(wout.xm_nyq) == wout.mnmax_nyq\n            assert len(wout.xn_nyq) == wout.mnmax_nyq\n            assert len(self.bx.xm_nyq) == self.bx.mnmax_nyq\n            assert len(self.bx.xn_nyq) == self.bx.mnmax_nyq\n\n            if wout.lasym:\n                rmns = wout.rmns\n                zmnc = wout.zmnc\n                lmnc = wout.lmnc\n                bmns = wout.bmns\n                bsubumns = wout.bsubumns\n                bsubvmns = wout.bsubvmns\n            else:\n                # For stellarator-symmetric configs, the asymmetric\n                # arrays have not been initialized.\n                arr = np.array([[]])\n                rmns = arr\n                zmnc = arr\n                lmnc = arr\n                bmns = arr\n                bsubumns = arr\n                bsubvmns = arr\n\n            # For quantities that depend on radius, booz_xform handles\n            # interpolation and discarding the rows of zeros:\n            self.bx.init_from_vmec(wout.ns,\n                                   wout.iotas,\n                                   wout.rmnc,\n                                   rmns,\n                                   zmnc,\n                                   wout.zmns,\n                                   lmnc,\n                                   wout.lmns,\n                                   wout.bmnc,\n                                   bmns,\n                                   wout.bsubumnc,\n                                   bsubumns,\n                                   wout.bsubvmnc,\n                                   bsubvmns)\n            self.bx.compute_surfs = compute_surfs\n            self.bx.mboz = self.mpol\n            self.bx.nboz = self.ntor\n\n        else:\n            # Cases for SPEC, GVEC, etc could be added here.\n            raise ValueError(\"equil is not an equilibrium type supported by\"\n                             \"Boozer\")\n\n        logger.info(\"About to call booz_xform.Booz_xform.run().\")\n        self.bx.run()\n        self._calls += 1\n        logger.info(\"Returned from calling booz_xform.Booz_xform.run().\")\n        self.need_to_run_code = False",
  "def __init__(self,\n                 boozer: Boozer,\n                 s: Union[float, Iterable[float]],\n                 helicity_m: int,\n                 helicity_n: int,\n                 normalization: str = \"B00\",\n                 weight: str = \"even\") -> None:\n        \"\"\"\n        Constructor\n\n        \"\"\"\n        self.boozer = boozer\n        self.helicity_m = helicity_m\n        self.helicity_n = helicity_n\n        self.normalization = normalization\n        self.weight = weight\n\n        # If s is not already iterable, make it so:\n        try:\n            iter(s)\n        except:\n            s = [s]\n        self.s = s\n        boozer.register(s)\n        super().__init__(depends_on=[boozer])",
  "def recompute_bell(self, parent=None):\n        self.need_to_run_code = True",
  "def J(self) -> RealArray:\n        \"\"\"\n        Carry out the calculation of the quasisymmetry error.\n\n        Returns:\n            1D numpy array listing all the normalized mode amplitudes of\n            symmetry-breaking Fourier modes of ``|B|``.\n        \"\"\"\n\n        # Only group leaders do anything:\n        if (self.boozer.mpi is not None) and (not self.boozer.mpi.proc0_groups):\n            logger.info(\"This proc is skipping Quasisymmetry.J since it is not a group leader.\")\n            return np.array([])\n\n        # The next line is the expensive part of the calculation:\n        self.boozer.run()\n\n        symmetry_error = []\n        for js, s in enumerate(self.s):\n            index = self.boozer.s_to_index[s]\n            bmnc = self.boozer.bx.bmnc_b[:, index]\n            xm = self.boozer.bx.xm_b\n            xn = self.boozer.bx.xn_b / self.boozer.bx.nfp\n\n            if self.helicity_m != 0 and self.helicity_m != 1:\n                raise ValueError(\"m for quasisymmetry should be 0 or 1.\")\n\n            # Find the indices of the symmetric modes:\n            if self.helicity_n == 0:\n                # Quasi-axisymmetry\n                symmetric = (xn == 0)\n\n            elif self.helicity_m == 0:\n                # Quasi-poloidal symmetry\n                symmetric = (xm == 0)\n\n            else:\n                # Quasi-helical symmetry\n                symmetric = (xm * self.helicity_n + xn * self.helicity_m == 0)\n                # Stellopt takes the \"and\" of this with mod(xm, self.helicity_m),\n                # which does not seem necessary since self.helicity_m must be 1 to\n                # get here.\n            nonsymmetric = np.logical_not(symmetric)\n\n            # Scale all bmnc modes so the average |B| is 1 or close to 1:\n\n            if self.normalization == \"B00\":\n                # Normalize by the (m,n) = (0,0) mode amplitude:\n                assert xm[0] == 0\n                assert xn[0] == 0\n                bnorm = bmnc[0]\n\n            elif self.normalization == \"symmetric\":\n                # Normalize by sqrt(sum_{symmetric modes} B{m,n}^2)\n                temp = bmnc[symmetric]\n                bnorm = np.sqrt(np.dot(temp, temp))\n\n            else:\n                raise ValueError(\"Unrecognized value for normalization in Quasisymmetry\")\n\n            logger.info(\"For s={}, bnorm={}\".format(s, bnorm))\n            bmnc = bmnc / bnorm\n\n            # Apply any weight that depends on m and/or n:\n\n            if self.weight == \"even\":\n                # Evenly weight each bmnc mode. Normalize by the m=n=0 mode on that surface.\n                symmetry_error.append(bmnc[nonsymmetric])\n\n            elif self.weight == \"stellopt\":\n                # Stellopt appears to apply a m-dependent radial\n                # weight, assuming sigma > 0. However, the m is\n                # evaluated outside of any loop over m, so m ends up\n                # taking the value mboz instead of the actual m for\n                # each mode. As a result, there is an even weight by s_used**2.\n\n                s_used = self.boozer.s_used[s]\n                logger.info('s_used, in Quasisymmetry: {}'.format(s_used))\n                \"\"\"\n                rad_sigma = np.full(len(xm), s_used * s_used)\n                rad_sigma[xm < 3] = s_used\n                rad_sigma[xm == 3] = s_used ** 1.5\n                \"\"\"\n                rad_sigma = s_used * s_used\n                temp = bmnc / rad_sigma\n                symmetry_error.append(temp[nonsymmetric])\n\n            elif self.weight == \"stellopt_ornl\":\n                # This option is similar to \"stellopt\" except we\n                # return a single number for the residual instead of a\n                # vector of residuals.\n\n                # For this option, stellopt applies a m-dependent\n                # radial weight only when sigma < 0, the opposite of\n                # when using the non-ORNL helicity! Here, we do not\n                # apply such a weight.\n\n                temp = bmnc[nonsymmetric]\n                symmetry_error.append(np.array([np.sqrt(np.sum(temp * temp))]))\n\n            else:\n                raise ValueError(\"Unrecognized value for weight in Quasisymmetry\")\n\n        return np.array(symmetry_error).flatten()",
  "class Profile(Optimizable):\n    \"\"\"\n    Base class for radial profiles. This class should not be used\n    directly - use subclasses instead.\n    \"\"\"\n\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n\n    def __call__(self, *args, **kwargs):\n        \"\"\" Shortcut for calling f(s) \"\"\"\n        return self.f(*args, **kwargs)\n\n    def plot(self, ax=None, show=True, n=100):\n        \"\"\"\n        Plot the profile using matplotlib.\n\n        Args:\n            ax: The axis object on which to plot. If ``None``, a new figure will be created.\n            show: Whether to call matplotlib's ``show()`` function.\n            n: The number of grid points in s to show.\n        \"\"\"\n        import matplotlib.pyplot as plt\n        if ax is None:\n            fig = plt.figure()\n            ax = fig.add_subplot()\n\n        s = np.linspace(0, 1, n)\n        ax.plot(s, self.f(s))\n        plt.xlabel('Normalized toroidal flux $s$')\n        if show:\n            plt.show()",
  "class ProfileSpec(Profile):\n    \"\"\"\n    A profile described by an array of size Nvol\n\n    Args:\n        data: 1D numpy array containing the profile value in each volume\n        cumulative: Set to True if the profile is cumulative, i.e. if the value \n            in volume lvol is the integrated quantity from the axis to volume lvol.\n            Only the toroidal flux, poloidal flux and the volume currents are \n            cumulative quantities in SPEC input file. False by default.\n    \"\"\"\n\n    def __init__(self, data, cumulative: bool = False, psi_edge: float = None):\n        super().__init__(x0=np.array(data))\n        self.local_fix_all()\n        self.cumulative = cumulative\n        self.psi_edge = psi_edge\n\n    def f(self, lvol: int):\n        \"\"\"\n        Return the value of the profile in volume lvol\n\n        Args:\n            lvol: int, list or np.array of int, between 0 and Mvol\n        \"\"\"\n\n        # If input is a integer, make an np.array\n        if isinstance(lvol, numbers.Number):\n            lvol = np.array([lvol])\n\n        # If input are floats, make integer out of them\n        lvol = np.array([int(l) for l in lvol])\n\n        # Check that volume index is within bounds\n        if (lvol < 0).any():\n            raise ValueError('lvol should be larger or equal than zero')\n        if (lvol >= self.local_full_x.size).any():\n            raise ValueError('lvol should be smaller than Mvol')\n\n        # Return value\n        return self.local_full_x[lvol]\n\n    def dfds(self, lvol):\n        \"\"\"\n        Returns the derivative of the profile w.r.t s accross interface. \n        The derivative is returned at the interface lvol, with\n        the innermost interface being lvol=1. (Volume lvol is bounded\n        by interface lvol and lvol+1, with innermost volume being lvol=0)\n\n        Here :math:`s` is defined as :math:`s = \\psi_t/\\psi_{edge}`. Thus,\n\n        .. math::\n\n            dp/ds = \\sum_l [[p]]_l \\psi_{edge} \\delta(\\psi_t-\\psi_{t,l})\n\n        with p the profile, and the sum is on the interfaces.\n\n        Args:\n            lvol: int, list or np.array of int, between 1 and Mvol-1. \n        \"\"\"\n        # If input is a integer, make an np.array\n        if isinstance(lvol, numbers.Number):\n            lvol = np.array([lvol])\n\n        # If input are floats, make integer out of them\n        lvol = np.array([int(l) for l in lvol])\n\n        # Check that volume index is within bounds\n        if (lvol < 0).any():\n            raise ValueError('lvol should be larger or equal than zero')\n        if (lvol >= self.local_full_x.size-1).any():\n            raise ValueError('lvol should be smaller than Mvol-1')\n        if self.psi_edge is None:\n            raise ValueError('Need to provide psi_edge to perform derivatives')\n\n        lvolin = [l-1 for l in lvol]\n        x_out = self.local_full_x[lvol]\n        x_in = self.local_full_x[lvolin]\n\n        return (x_out-x_in) * self.psi_edge",
  "class ProfilePolynomial(Profile):\n    \"\"\"\n    A profile described by a polynomial in the normalized toroidal\n    flux s.  The polynomial coefficients are dofs that are fixed by\n    default.\n\n    Args:\n        data: 1D numpy array of the polynomial coefficients.\n            The first coefficient is the constant term, the next coefficient\n            is the linear term, etc.\n    \"\"\"\n\n    def __init__(self, data):\n        super().__init__(x0=np.array(data))\n        self.local_fix_all()\n\n    def f(self, s):\n        \"\"\" Return the value of the profile at specified points in s. \"\"\"\n        return poly.polyval(s, self.local_full_x)\n\n    def dfds(self, s):\n        \"\"\" Return the d/ds derivative of the profile at specified points in s. \"\"\"\n        return poly.polyval(s, poly.polyder(self.local_full_x))",
  "class ProfileScaled(Profile):\n    \"\"\"\n    A Profile which is equivalent to another Profile object but scaled\n    by a constant. This constant is an optimizable dof, which is fixed by default.\n\n    Args:\n        base: A Profile object to scale\n        scalefac: A number by which the base profile will be scaled.\n    \"\"\"\n\n    def __init__(self, base, scalefac):\n        self.base = base\n        super().__init__(\n            x0=np.array(\n                [scalefac]),\n            names=['scalefac'],\n            depends_on=[base])\n        self.local_fix_all()\n\n    def f(self, s):\n        \"\"\" Return the value of the profile at specified points in s. \"\"\"\n        return self.local_full_x[0] * self.base.f(s)\n\n    def dfds(self, s):\n        \"\"\" Return the d/ds derivative of the profile at specified points in s. \"\"\"\n        return self.local_full_x[0] * self.base.dfds(s)",
  "class ProfileSpline(Profile):\n    \"\"\"\n    A Profile that uses spline interpolation via\n    `scipy.interpolate.InterpolatedUnivariateSpline\n    <https://docs.scipy.org/doc/scipy/reference/generated/scipy.interpolate.InterpolatedUnivariateSpline.html>`_\n\n    The ``f`` data are optimizable dofs, which are fixed by default.\n\n    Args:\n        s: A 1d array with the x coordinates for the spline.\n        f: A 1d array with the y coordinates for the spline.\n        degree: The polynomial degree of the spline. Must be in ``[1, 2, 3, 4, 5]``.\n    \"\"\"\n\n    degree = PositiveInteger()\n\n    def __init__(self, s, f, degree=3):\n        self.s = s\n        self.degree = degree\n        super().__init__(x0=f)\n        self.local_fix_all()\n\n    def f(self, s):\n        \"\"\" Return the value of the profile at specified points in s. \"\"\"\n        return InterpolatedUnivariateSpline(\n            self.s, self.full_x, k=self.degree)(s)\n\n    def dfds(self, s):\n        \"\"\" Return the d/ds derivative of the profile at specified points in s. \"\"\"\n        return InterpolatedUnivariateSpline(\n            self.s, self.full_x, k=self.degree).derivative()(s)\n\n    def resample(self, new_s, degree=None):\n        \"\"\"\n        Return a new ``ProfileSpline`` object that has different grid points (spline nodes).\n        The data from the old s grid will be interpolated onto the new s grid.\n\n        Args:\n            new_s: A 1d array representing the x coordinates of the new ``ProfileSpline``.\n            degree: The polynomial degree used for the new ``ProfileSpline`` object.\n                If ``None``, the degree of the original ``ProfileSpline`` will be used.\n\n        Returns:\n            A new :obj:`ProfileSpline` object, in which the data have been resampled onto ``new_s``.\n        \"\"\"\n        new_degree = self.degree\n        if degree is not None:\n            new_degree = degree\n        return ProfileSpline(new_s, self.f(new_s), degree=new_degree)",
  "class ProfilePressure(Profile):\n    r\"\"\"\n    A Profile :math:`f(s)` which is determined by other profiles :math:`f_j(s)` as follows:\n\n    .. math::\n\n        f(s) = \\sum_j f_{2j}(s) f_{2j+1}(s).\n\n    This is useful for creating a pressure profile in terms of density\n    and temperature profiles, with any number of species. Typical\n    usage is as follows::\n\n        ne = ProfilePolynomial(1.0e20 * np.array([1.0, 0.0, 0.0, 0.0, -1.0]))\n        Te = ProfilePolynomial(8.0e3 * np.array([1.0, -1.0]))\n        nH = ne\n        TH = ProfilePolynomial(7.0e3 * np.array([1.0, -1.0]))\n        pressure = ProfilePressure(ne, Te, nH, TH)\n\n    This class does not have any optimizable dofs.\n\n    Args:\n        args: An even number of Profile objects.\n    \"\"\"\n\n    def __init__(self, *args):\n        if len(args) == 0:\n            raise ValueError(\n                'At least one density and temperature profile must be provided.')\n        if len(args) % 2 == 1:\n            raise ValueError(\n                'The number of input profiles for a ProfilePressure object must be even')\n        super().__init__(depends_on=args)\n\n    def f(self, s):\n        \"\"\" Return the value of the profile at specified points in s. \"\"\"\n        total = 0\n        for j in range(int(len(self.parents) / 2)):\n            total += self.parents[2 * j](s) * self.parents[2 * j + 1](s)\n        return total\n\n    def dfds(self, s):\n        \"\"\" Return the d/ds derivative of the profile at specified points in s. \"\"\"\n        total = 0\n        for j in range(int(len(self.parents) / 2)):\n            total += self.parents[2 * j].f(s) * self.parents[2 * j + 1].dfds(s)\\\n                + self.parents[2 * j].dfds(s) * self.parents[2 * j + 1](s)\n        return total",
  "def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)",
  "def __call__(self, *args, **kwargs):\n        \"\"\" Shortcut for calling f(s) \"\"\"\n        return self.f(*args, **kwargs)",
  "def plot(self, ax=None, show=True, n=100):\n        \"\"\"\n        Plot the profile using matplotlib.\n\n        Args:\n            ax: The axis object on which to plot. If ``None``, a new figure will be created.\n            show: Whether to call matplotlib's ``show()`` function.\n            n: The number of grid points in s to show.\n        \"\"\"\n        import matplotlib.pyplot as plt\n        if ax is None:\n            fig = plt.figure()\n            ax = fig.add_subplot()\n\n        s = np.linspace(0, 1, n)\n        ax.plot(s, self.f(s))\n        plt.xlabel('Normalized toroidal flux $s$')\n        if show:\n            plt.show()",
  "def __init__(self, data, cumulative: bool = False, psi_edge: float = None):\n        super().__init__(x0=np.array(data))\n        self.local_fix_all()\n        self.cumulative = cumulative\n        self.psi_edge = psi_edge",
  "def f(self, lvol: int):\n        \"\"\"\n        Return the value of the profile in volume lvol\n\n        Args:\n            lvol: int, list or np.array of int, between 0 and Mvol\n        \"\"\"\n\n        # If input is a integer, make an np.array\n        if isinstance(lvol, numbers.Number):\n            lvol = np.array([lvol])\n\n        # If input are floats, make integer out of them\n        lvol = np.array([int(l) for l in lvol])\n\n        # Check that volume index is within bounds\n        if (lvol < 0).any():\n            raise ValueError('lvol should be larger or equal than zero')\n        if (lvol >= self.local_full_x.size).any():\n            raise ValueError('lvol should be smaller than Mvol')\n\n        # Return value\n        return self.local_full_x[lvol]",
  "def dfds(self, lvol):\n        \"\"\"\n        Returns the derivative of the profile w.r.t s accross interface. \n        The derivative is returned at the interface lvol, with\n        the innermost interface being lvol=1. (Volume lvol is bounded\n        by interface lvol and lvol+1, with innermost volume being lvol=0)\n\n        Here :math:`s` is defined as :math:`s = \\psi_t/\\psi_{edge}`. Thus,\n\n        .. math::\n\n            dp/ds = \\sum_l [[p]]_l \\psi_{edge} \\delta(\\psi_t-\\psi_{t,l})\n\n        with p the profile, and the sum is on the interfaces.\n\n        Args:\n            lvol: int, list or np.array of int, between 1 and Mvol-1. \n        \"\"\"\n        # If input is a integer, make an np.array\n        if isinstance(lvol, numbers.Number):\n            lvol = np.array([lvol])\n\n        # If input are floats, make integer out of them\n        lvol = np.array([int(l) for l in lvol])\n\n        # Check that volume index is within bounds\n        if (lvol < 0).any():\n            raise ValueError('lvol should be larger or equal than zero')\n        if (lvol >= self.local_full_x.size-1).any():\n            raise ValueError('lvol should be smaller than Mvol-1')\n        if self.psi_edge is None:\n            raise ValueError('Need to provide psi_edge to perform derivatives')\n\n        lvolin = [l-1 for l in lvol]\n        x_out = self.local_full_x[lvol]\n        x_in = self.local_full_x[lvolin]\n\n        return (x_out-x_in) * self.psi_edge",
  "def __init__(self, data):\n        super().__init__(x0=np.array(data))\n        self.local_fix_all()",
  "def f(self, s):\n        \"\"\" Return the value of the profile at specified points in s. \"\"\"\n        return poly.polyval(s, self.local_full_x)",
  "def dfds(self, s):\n        \"\"\" Return the d/ds derivative of the profile at specified points in s. \"\"\"\n        return poly.polyval(s, poly.polyder(self.local_full_x))",
  "def __init__(self, base, scalefac):\n        self.base = base\n        super().__init__(\n            x0=np.array(\n                [scalefac]),\n            names=['scalefac'],\n            depends_on=[base])\n        self.local_fix_all()",
  "def f(self, s):\n        \"\"\" Return the value of the profile at specified points in s. \"\"\"\n        return self.local_full_x[0] * self.base.f(s)",
  "def dfds(self, s):\n        \"\"\" Return the d/ds derivative of the profile at specified points in s. \"\"\"\n        return self.local_full_x[0] * self.base.dfds(s)",
  "def __init__(self, s, f, degree=3):\n        self.s = s\n        self.degree = degree\n        super().__init__(x0=f)\n        self.local_fix_all()",
  "def f(self, s):\n        \"\"\" Return the value of the profile at specified points in s. \"\"\"\n        return InterpolatedUnivariateSpline(\n            self.s, self.full_x, k=self.degree)(s)",
  "def dfds(self, s):\n        \"\"\" Return the d/ds derivative of the profile at specified points in s. \"\"\"\n        return InterpolatedUnivariateSpline(\n            self.s, self.full_x, k=self.degree).derivative()(s)",
  "def resample(self, new_s, degree=None):\n        \"\"\"\n        Return a new ``ProfileSpline`` object that has different grid points (spline nodes).\n        The data from the old s grid will be interpolated onto the new s grid.\n\n        Args:\n            new_s: A 1d array representing the x coordinates of the new ``ProfileSpline``.\n            degree: The polynomial degree used for the new ``ProfileSpline`` object.\n                If ``None``, the degree of the original ``ProfileSpline`` will be used.\n\n        Returns:\n            A new :obj:`ProfileSpline` object, in which the data have been resampled onto ``new_s``.\n        \"\"\"\n        new_degree = self.degree\n        if degree is not None:\n            new_degree = degree\n        return ProfileSpline(new_s, self.f(new_s), degree=new_degree)",
  "def __init__(self, *args):\n        if len(args) == 0:\n            raise ValueError(\n                'At least one density and temperature profile must be provided.')\n        if len(args) % 2 == 1:\n            raise ValueError(\n                'The number of input profiles for a ProfilePressure object must be even')\n        super().__init__(depends_on=args)",
  "def f(self, s):\n        \"\"\" Return the value of the profile at specified points in s. \"\"\"\n        total = 0\n        for j in range(int(len(self.parents) / 2)):\n            total += self.parents[2 * j](s) * self.parents[2 * j + 1](s)\n        return total",
  "def dfds(self, s):\n        \"\"\" Return the d/ds derivative of the profile at specified points in s. \"\"\"\n        total = 0\n        for j in range(int(len(self.parents) / 2)):\n            total += self.parents[2 * j].f(s) * self.parents[2 * j + 1].dfds(s)\\\n                + self.parents[2 * j].dfds(s) * self.parents[2 * j + 1](s)\n        return total",
  "def compute_trapped_fraction(modB, sqrtg):\n    r\"\"\"\n    Compute the effective fraction of trapped particles, which enters\n    several formulae for neoclassical transport, as well as several\n    quantities that go into its calculation.  The input data can be\n    provided on a uniform grid of arbitrary toroidal and poloidal\n    angles that need not be straight-field-line angles.\n\n    The trapped fraction ``f_t`` has a standard definition in neoclassical theory:\n\n    .. math::\n        f_t = 1 - \\frac{3}{4} \\left< B^2 \\right> \\int_0^{1/Bmax}\n            \\frac{\\lambda\\; d\\lambda}{\\left< \\sqrt{1 - \\lambda B} \\right>}\n\n    where :math:`\\left< \\ldots \\right>` is a flux surface average.\n\n    The effective inverse aspect ratio epsilon is defined by\n\n    .. math::\n        \\frac{Bmax}{Bmin} = \\frac{1 + \\epsilon}{1 - \\epsilon}\n\n    This definition is motivated by the fact that this formula would\n    be true in the case of circular cross-section surfaces in\n    axisymmetry with :math:`B \\propto 1/R` and :math:`R = (1 +\n    \\epsilon \\cos\\theta) R_0`.\n\n    Args:\n        modB: 2D array of size (ntheta, ns) or 3D array of size\n            (ntheta, nphi, ns) with :math:`|B|` on the grid points.\n        sqrtg: 2D array of size (ntheta, ns) or 3D array of size\n            (ntheta, nphi, ns) with the Jacobian\n            :math:`1/(\\nabla s \\times\\nabla\\theta\\cdot\\nabla\\phi)`\n            on the grid points.\n\n    Returns:\n        Tuple containing\n\n        - **Bmin**: A 1D array, with the minimum of :math:`|B|` on each surface.\n        - **Bmax**: A 1D array, with the maximum of :math:`|B|` on each surface.\n        - **epsilon**: A 1D array, with the effective inverse aspect ratio on each surface.\n        - **fsa_B2**: A 1D array with :math:`\\left<B^2\\right>` on each surface,\n          where :math:`\\left< \\ldots \\right>` denotes a flux surface average.\n        - **fsa_1overB**: A 1D array with :math:`\\left<1/B\\right>` on each surface,\n          where :math:`\\left< \\ldots \\right>` denotes a flux surface average.\n        - **f_t**: A 1D array, with the effective trapped fraction on each surface.\n    \"\"\"\n    assert modB.shape == sqrtg.shape\n    ntheta = modB.shape[0]\n    ns = modB.shape[-1]\n    epsilon = np.zeros(ns)\n    f_t = np.zeros(ns)\n    Bmin = np.zeros(ns)\n    Bmax = np.zeros(ns)\n\n    if modB.ndim == 3:\n        # Input arrays are 3D, with phi dependence.\n\n        nphi = modB.shape[1]\n        fourpisq = 4 * np.pi * np.pi\n        dVds = np.mean(sqrtg, axis=(0, 1)) / fourpisq\n        fsa_B2 = np.mean(modB * modB * sqrtg, axis=(0, 1)) / (fourpisq * dVds)\n        fsa_1overB = np.mean(sqrtg / modB, axis=(0, 1)) / (fourpisq * dVds)\n\n        # Make a slightly enlarged version of the input array with the\n        # first row and column appended at the ends, for periodicity.\n        modB_big = np.zeros((ntheta + 1, nphi + 1, ns))\n        modB_big[:ntheta, :nphi, :] = modB\n        modB_big[-1, :nphi, :] = modB[0, :, :]\n        modB_big[:, -1, :] = modB_big[:, 0, :]\n\n        theta = np.arange(ntheta + 1)\n        phi = np.arange(nphi + 1)\n        for js in range(ns):\n            index_of_min = np.unravel_index(np.argmin(modB_big[:, :, js]), modB_big.shape[:2])\n            index_of_max = np.unravel_index(np.argmax(modB_big[:, :, js]), modB_big.shape[:2])\n            modB_spline = RectBivariateSpline(theta, phi, modB_big[:, :, js])\n            soln = minimize(lambda x: np.ravel(modB_spline(x[0], x[1])),\n                            index_of_min,\n                            bounds=((0, ntheta), (0, nphi)))\n            modBmin = soln.fun\n            soln = minimize(lambda x: -np.ravel(modB_spline(x[0], x[1])),\n                            index_of_max,\n                            bounds=((0, ntheta), (0, nphi)))\n            modBmax = -soln.fun\n            Bmin[js] = modBmin\n            Bmax[js] = modBmax\n            w = modBmax / modBmin\n            epsilon[js] = (w - 1) / (w + 1)\n\n            def integrand(lambd):\n                # This function gives lambda / <sqrt(1 - lambda B)>:\n                return lambd / (np.mean(np.sqrt(1 - lambd * modB[:, :, js]) * sqrtg[:, :, js]) \\\n                                / (fourpisq * dVds[js]))\n\n            integral = quad(integrand, 0, 1 / modBmax)\n            f_t[js] = 1 - 0.75 * fsa_B2[js] * integral[0]\n\n    elif modB.ndim == 2:\n        # Input arrays are 2D, with no phi dependence.\n\n        twopi = 2 * np.pi\n        dVds = np.mean(sqrtg, axis=0) / twopi\n        fsa_B2 = np.mean(modB * modB * sqrtg, axis=0) / (twopi * dVds)\n        fsa_1overB = np.mean(sqrtg / modB, axis=0) / (twopi * dVds)\n\n        # Make a slightly enlarged version of the input array with the\n        # first row and column appended at the ends, for periodicity.\n        modB_big = np.zeros((ntheta + 1, ns))\n        modB_big[:ntheta, :] = modB\n        modB_big[-1, :] = modB[0, :]\n\n        theta = np.arange(ntheta + 1)\n        for js in range(ns):\n            index_of_min = np.argmin(modB_big[:, js])\n            index_of_max = np.argmax(modB_big[:, js])\n            modB_spline = interp1d(theta, modB_big[:, js], kind='cubic')\n            bounds = Bounds(0, ntheta)\n            soln = minimize(modB_spline,\n                            [index_of_min],\n                            bounds=bounds)\n            modBmin = soln.fun\n            soln = minimize(lambda x: -modB_spline(x[0]),\n                            [index_of_max],\n                            bounds=bounds)\n            modBmax = -soln.fun\n            Bmin[js] = modBmin\n            Bmax[js] = modBmax\n            w = modBmax / modBmin\n            epsilon[js] = (w - 1) / (w + 1)\n\n            def integrand(lambd):\n                # This function gives lambda / <sqrt(1 - lambda B)>:\n                return lambd / (np.mean(np.sqrt(1 - lambd * modB[:, js]) * sqrtg[:, js]) \\\n                                / (twopi * dVds[js]))\n\n            integral = quad(integrand, 0, 1 / modBmax)\n            f_t[js] = 1 - 0.75 * fsa_B2[js] * integral[0]\n\n    else:\n        raise ValueError('Input arrays must be 2D or 3D')\n\n    logging.debug(f'Bmin: {Bmin}  Bmax: {Bmax}  epsilon: {epsilon}  '\n                  f'fsa_B2: {fsa_B2}  fsa_1overB: {fsa_1overB}  f_t: {f_t}')\n    return Bmin, Bmax, epsilon, fsa_B2, fsa_1overB, f_t",
  "def j_dot_B_Redl(ne, Te, Ti, Zeff, helicity_n=None, s=None, G=None, R=None, iota=None,\n                 epsilon=None, f_t=None, psi_edge=None, nfp=None,\n                 geom=None, plot=False):\n    r\"\"\"\n    Compute the bootstrap current (specifically\n    :math:`\\left<\\vec{J}\\cdot\\vec{B}\\right>`) using the formulae in\n    Redl et al, Physics of Plasmas 28, 022502 (2021).\n\n    The profiles of ne, Te, Ti, and Zeff should all be instances of\n    subclasses of :obj:`simsopt.mhd.profiles.Profile`, i.e. they should\n    have ``__call__()`` and ``dfds()`` functions. If ``Zeff == None``, a\n    constant 1 is assumed. If ``Zeff`` is a float, a constant profile will\n    be assumed.\n\n    ``ne`` should have units of 1/m^3. ``Ti`` and ``Te`` should have\n    units of eV.\n\n    Geometric data can be specified in one of two ways. In the first\n    approach, the arguments ``s``, ``G``, ``R``, ``iota``,\n    ``epsilon``, ``f_t``, ``psi_edge``, and ``nfp`` are specified,\n    while the argument ``geom`` is not. In the second approach, the\n    argument ``geom`` is set to an instance of either\n    :obj:`RedlGeomVmec` or :obj:`RedlGeomBoozer`, and this object will\n    be used to set all the other geometric quantities. In this case,\n    the arguments ``s``, ``G``, ``R``, ``iota``, ``epsilon``, ``f_t``,\n    ``psi_edge``, and ``nfp`` should not be specified.\n\n    The input variable ``s`` is a 1D array of values of normalized\n    toroidal flux.  The input arrays ``G``, ``R``, ``iota``,\n    ``epsilon``, and ``f_t``, should be 1d arrays evaluated on this\n    same ``s`` grid. The bootstrap current\n    :math:`\\left<\\vec{J}\\cdot\\vec{B}\\right>` will be computed on this\n    same set of flux surfaces.\n\n    If you provide a :obj:`RedlGeomBoozer` object for ``geom``, then\n    it is not necessary to specify the argument ``helicity_n`` here,\n    in which case ``helicity_n`` will be taken from ``geom``.\n\n    Args:\n        ne: A :obj:`~simsopt.mhd.profiles.Profile` object with the electron density profile.\n        Te: A :obj:`~simsopt.mhd.profiles.Profile` object with the electron temperature profile.\n        Ti: A :obj:`~simsopt.mhd.profiles.Profile` object with the ion temperature profile.\n        Zeff: A :obj:`~simsopt.mhd.profiles.Profile` object with the profile of the average\n            impurity charge :math:`Z_{eff}`. Or, a single number can be provided if this profile is constant.\n            Or, if ``None``, Zeff = 1 will be used.\n        helicity_n: 0 for quasi-axisymmetry, or +/- 1 for quasi-helical symmetry.\n            This quantity is used to apply the quasisymmetry isomorphism to map the collisionality\n            and bootstrap current from the tokamak expressions to quasi-helical symmetry.\n        s: A 1D array of values of normalized toroidal flux.\n        G: A 1D array with the flux function multiplying :math:`\\nabla\\varphi` in the Boozer covariant representation,\n            equivalent to :math:`R B_{toroidal}` in axisymmetry.\n        R: A 1D array with the effective major radius to use when evaluating\n            the collisionality in the Sauter/Redl formulae.\n        iota: A 1D array with the rotational transform.\n        epsilon: A 1D array with the effective inverse aspect ratio to use for\n            evaluating the collisionality in the Sauter/Redl formulae.\n        f_t: A 1D array with the effective trapped fraction.\n        psi_edge: The toroidal flux (in Webers) divided by (2pi) at the boundary s=1\n        nfp: The number of field periods. Irrelevant for axisymmetry or quasi-axisymmetry;\n            matters only if ``helicity_n`` is not 0.\n        geom: Optional. An instance of either :obj:`RedlGeomVmec` or :obj:`RedlGeomBoozer`.\n        plot: Whether to make a plot of many of the quantities computed.\n\n    Returns:\n        Tuple containing\n\n        - **jdotB**: A 1D array containing the bootstrap current :math:`\\left<\\vec{J}\\cdot\\vec{B}\\right>`\n          on the specified flux surfaces.\n        - **details**: An object holding intermediate quantities from the computation\n          (e.g. L31, L32, alpha) as attributes\n    \"\"\"\n    if geom is not None:\n        if (s is not None) or (G is not None) or (R is not None) \\\n           or (iota is not None) or (epsilon is not None) or (psi_edge is not None) \\\n           or (f_t is not None) or (nfp is not None):\n            raise ValueError('Geometry is being specified two ways. Pick one or the other.')\n        geom_data = geom()\n        s = geom_data.surfaces\n        G = geom_data.G\n        R = geom_data.R\n        iota = geom_data.iota\n        epsilon = geom_data.epsilon\n        psi_edge = geom_data.psi_edge\n        f_t = geom_data.f_t\n        nfp = geom_data.nfp\n\n    if helicity_n is None:\n        helicity_n = geom.helicity_n\n\n    helicity_N = nfp * helicity_n\n    if Zeff is None:\n        Zeff = ProfilePolynomial(1.0)\n    if not isinstance(Zeff, Profile):\n        # Zeff is presumably a number. Convert it to a constant profile.\n        Zeff = ProfilePolynomial([Zeff])\n\n    # Evaluate profiles on the grid:\n    ne_s = ne(s)\n    Te_s = Te(s)\n    Ti_s = Ti(s)\n    Zeff_s = Zeff(s)\n    ni_s = ne_s / Zeff_s\n    pe_s = ne_s * Te_s\n    pi_s = ni_s * Ti_s\n    d_ne_d_s = ne.dfds(s)\n    d_Te_d_s = Te.dfds(s)\n    d_Ti_d_s = Ti.dfds(s)\n\n    # Profiles may go to 0 at s=1, so exclude the last 2 grid points:\n    if np.any(ne_s[:-2] < 1e17):\n        logging.warning('ne is surprisingly low. It should have units 1/meters^3')\n    if np.any(Te_s[:-2] < 50):\n        logging.warning('Te is surprisingly low. It should have units of eV')\n    if np.any(Ti_s[:-2] < 50):\n        logging.warning('Ti is surprisingly low. It should have units of eV')\n\n    # Eq (18d)-(18e) in Sauter.\n    # Check that we do not need to convert units of n or T!\n    ln_Lambda_e = 31.3 - np.log(np.sqrt(ne_s) / Te_s)\n    ln_Lambda_ii = 30 - np.log(Zeff_s ** 3 * np.sqrt(ni_s) / (Ti_s ** 1.5))\n    logging.debug(f'ln Lambda_e: {ln_Lambda_e}')\n    logging.debug(f'ln Lambda_ii: {ln_Lambda_ii}')\n\n    # Eq (18b)-(18c) in Sauter:\n    geometry_factor = abs(R / (iota - helicity_N))\n    nu_e = geometry_factor * (6.921e-18) * ne_s * Zeff_s * ln_Lambda_e \\\n        / (Te_s * Te_s * (epsilon ** 1.5))\n    nu_i = geometry_factor * (4.90e-18) * ni_s * (Zeff_s ** 4) * ln_Lambda_ii \\\n        / (Ti_s * Ti_s * (epsilon ** 1.5))\n    if np.any(nu_e[:-2] < 1e-6):\n        logging.warning('nu_*e is surprisingly low. Check that the density and temperature are correct.')\n    if np.any(nu_i[:-2] < 1e-6):\n        logging.warning('nu_*i is surprisingly low. Check that the density and temperature are correct.')\n    if np.any(nu_e[:-2] > 1e5):\n        logging.warning('nu_*e is surprisingly large. Check that the density and temperature are correct.')\n    if np.any(nu_i[:-2] > 1e5):\n        logging.warning('nu_*i is surprisingly large. Check that the density and temperature are correct.')\n\n    # Redl eq (11):\n    X31 = f_t / (1 + (0.67 * (1 - 0.7 * f_t) * np.sqrt(nu_e)) / (0.56 + 0.44 * Zeff_s) \\\n                 + (0.52 + 0.086 * np.sqrt(nu_e)) * (1 + 0.87 * f_t) * nu_e / (1 + 1.13 * np.sqrt(Zeff_s - 1)))\n\n    # Redl eq (10):\n    Zfac = Zeff_s ** 1.2 - 0.71\n    L31 = (1 + 0.15 / Zfac) * X31 \\\n        - 0.22 / Zfac * (X31 ** 2) \\\n        + 0.01 / Zfac * (X31 ** 3) \\\n        + 0.06 / Zfac * (X31 ** 4)\n\n    # Redl eq (14):\n    X32e = f_t / ((1 + 0.23 * (1 - 0.96 * f_t) * np.sqrt(nu_e) / np.sqrt(Zeff_s) \\\n                   + 0.13 * (1 - 0.38 * f_t) * nu_e / (Zeff_s * Zeff_s) \\\n                   * (np.sqrt(1 + 2 * np.sqrt(Zeff_s - 1)) \\\n                      + f_t * f_t * np.sqrt((0.075 + 0.25 * (Zeff_s - 1) ** 2) * nu_e))))\n\n    # Redl eq (13):\n    F32ee = (0.1 + 0.6 * Zeff_s) * (X32e - X32e ** 4) \\\n        / (Zeff_s * (0.77 + 0.63 * (1 + (Zeff_s - 1) ** 1.1))) \\\n        + 0.7 / (1 + 0.2 * Zeff_s) * (X32e ** 2 - X32e ** 4 - 1.2 * (X32e ** 3 - X32e ** 4)) \\\n        + 1.3 / (1 + 0.5 * Zeff_s) * (X32e ** 4)\n\n    # Redl eq (16):\n    X32ei = f_t / (1 + 0.87 * (1 + 0.39 * f_t) * np.sqrt(nu_e) / (1 + 2.95 * (Zeff_s - 1) ** 2) \\\n                   + 1.53 * (1 - 0.37 * f_t) * nu_e * (2 + 0.375 * (Zeff_s - 1)))\n\n    # Redl eq (15):\n    F32ei = -(0.4 + 1.93 * Zeff_s) / (Zeff_s * (0.8 + 0.6 * Zeff_s)) * (X32ei - X32ei ** 4) \\\n        + 5.5 / (1.5 + 2 * Zeff_s) * (X32ei ** 2 - X32ei ** 4 - 0.8 * (X32ei ** 3 - X32ei ** 4)) \\\n        - 1.3 / (1 + 0.5 * Zeff_s) * (X32ei ** 4)\n\n    # Redl eq (12):\n    L32 = F32ei + F32ee\n\n    # Redl eq (19):\n    L34 = L31\n\n    # Redl eq (20):\n    alpha0 = -(0.62 + 0.055 * (Zeff_s - 1)) * (1 - f_t) \\\n        / ((0.53 + 0.17 * (Zeff_s - 1)) * (1 - (0.31 - 0.065 * (Zeff_s - 1)) * f_t - 0.25 * f_t * f_t))\n    # Redl eq (21):    \n    alpha = ((alpha0 + 0.7 * Zeff_s * np.sqrt(f_t * nu_i)) / (1 + 0.18 * np.sqrt(nu_i)) \\\n             - 0.002 * nu_i * nu_i * (f_t ** 6)) \\\n        / (1 + 0.004 * nu_i * nu_i * (f_t ** 6))\n\n    # Factor of ELEMENTARY_CHARGE is included below to convert temperatures from eV to J\n    dnds_term = -G * ELEMENTARY_CHARGE * (ne_s * Te_s + ni_s * Ti_s) * L31 * (d_ne_d_s / ne_s) / (psi_edge * (iota - helicity_N))\n    dTeds_term = -G * ELEMENTARY_CHARGE * pe_s * (L31 + L32) * (d_Te_d_s / Te_s) / (psi_edge * (iota - helicity_N))\n    dTids_term = -G * ELEMENTARY_CHARGE * pi_s * (L31 + L34 * alpha) * (d_Ti_d_s / Ti_s) / (psi_edge * (iota - helicity_N))\n    jdotB = dnds_term + dTeds_term + dTids_term\n\n    details = Struct()\n    nu_e_star = nu_e\n    nu_i_star = nu_i\n    variables = ['s', 'ne_s', 'ni_s', 'Zeff_s', 'Te_s', 'Ti_s',\n                 'd_ne_d_s', 'd_Te_d_s', 'd_Ti_d_s',\n                 'ln_Lambda_e', 'ln_Lambda_ii', 'nu_e_star', 'nu_i_star',\n                 'X31', 'X32e', 'X32ei', 'F32ee', 'F32ei',\n                 'L31', 'L32', 'L34', 'alpha0', 'alpha',\n                 'dnds_term', 'dTeds_term', 'dTids_term', 'jdotB']\n    for v in variables:\n        details.__setattr__(v, eval(v))\n\n    if geom is not None:\n        # Copy geom_data into details:\n        for v in dir(geom_data):\n            if v[0] != '_':\n                details.__setattr__(v, eval(\"geom_data.\" + v))\n\n    if plot:\n        import matplotlib.pyplot as plt\n        plt.figure(figsize=(14, 7))\n        plt.rcParams.update({'font.size': 8})\n        nrows = 5\n        ncols = 5\n        variables = ['Bmax', 'Bmin', 'epsilon', 'fsa_B2', 'fsa_1overB',\n                     'f_t', 'iota', 'G', 'R',\n                     'ne_s', 'ni_s', 'Zeff_s', 'Te_s', 'Ti_s',\n                     'ln_Lambda_e', 'ln_Lambda_ii',\n                     'nu_e_star', 'nu_i_star',\n                     'dnds_term', 'dTeds_term', 'dTids_term',\n                     'L31', 'L32', 'alpha', 'jdotB']\n        for j, variable in enumerate(variables):\n            plt.subplot(nrows, ncols, j + 1)\n            plt.plot(details.s, eval(\"details.\" + variable))\n            plt.title(variable)\n            plt.xlabel('s')\n        plt.tight_layout()\n        plt.show()\n\n    return jdotB, details",
  "class RedlGeomVmec(Optimizable):\n    \"\"\"\n    This class evaluates geometry data needed to evaluate the Redl\n    bootstrap current formula from a vmec configuration, such as the\n    effective fraction of trapped particles.  The advantage of this\n    class over :obj:`RedlGeomBoozer` is that no transformation to\n    Boozer coordinates is involved in this method. However, the\n    approach here may over-estimate ``epsilon``.\n\n    Args:\n        vmec: An instance of :obj:`simsopt.mhd.vmec.Vmec`.\n        surfaces: A 1D array of values of s (normalized toroidal flux) on which\n            to compute the geometric quantities. If ``None``, the half grid points from the\n            VMEC solution will be used.\n        ntheta: Number of grid points in the poloidal angle for evaluating geometric quantities in the Redl formulae.\n        nphi: Number of grid points in the toroidal angle for evaluating geometric quantities in the Redl formulae.\n        plot: Whether to make a plot of many of the quantities computed.\n    \"\"\"\n\n    def __init__(self, vmec, surfaces=None, ntheta=64, nphi=65, plot=False):\n        self.vmec = vmec\n        self.surfaces = surfaces\n        self.ntheta = ntheta\n        self.nphi = nphi\n        self.plot = plot\n        super().__init__(depends_on=[vmec])\n\n    def __call__(self):\n        \"\"\"\n        Evaluate the geometric quantities needed for the Redl bootstrap\n        current formula.\n        \"\"\"\n        self.vmec.run()\n\n        if self.surfaces is None:\n            self.surfaces = self.vmec.s_half_grid\n        surfaces = self.surfaces\n        ntheta = self.ntheta\n        nphi = self.nphi\n\n        ns = len(surfaces)\n        nfp = self.vmec.wout.nfp\n        psi_edge = -self.vmec.wout.phi[-1] / (2 * np.pi)\n\n        # First, interpolate in s to get the quantities we need on the surfaces we need.\n        method = 'linear'\n\n        interp = interp1d(self.vmec.s_half_grid, self.vmec.wout.iotas[1:], fill_value=\"extrapolate\")\n        iota = interp(surfaces)\n\n        interp = interp1d(self.vmec.s_half_grid, self.vmec.wout.bvco[1:], fill_value=\"extrapolate\")\n        G = interp(surfaces)\n\n        interp = interp1d(self.vmec.s_half_grid, self.vmec.wout.buco[1:], fill_value=\"extrapolate\")\n        I = interp(surfaces)\n\n        interp = interp1d(self.vmec.s_half_grid, self.vmec.wout.gmnc[:, 1:], fill_value=\"extrapolate\")\n        gmnc = interp(surfaces)\n\n        interp = interp1d(self.vmec.s_half_grid, self.vmec.wout.bmnc[:, 1:], fill_value=\"extrapolate\")\n        bmnc = interp(surfaces)\n\n        theta1d = np.linspace(0, 2 * np.pi, ntheta, endpoint=False)\n        phi1d = np.linspace(0, 2 * np.pi / nfp, nphi, endpoint=False)\n        phi2d, theta2d = np.meshgrid(phi1d, theta1d)\n        phi3d = phi2d.reshape((ntheta, nphi, 1))\n        theta3d = theta2d.reshape((ntheta, nphi, 1))\n\n        myshape = (ntheta, nphi, ns)\n        modB = np.zeros(myshape)\n        sqrtg = np.zeros(myshape)\n        for jmn in range(len(self.vmec.wout.xm_nyq)):\n            m = self.vmec.wout.xm_nyq[jmn]\n            n = self.vmec.wout.xn_nyq[jmn]\n            angle = m * theta3d - n * phi3d\n            cosangle = np.cos(angle)\n            sinangle = np.sin(angle)\n            modB += np.kron(bmnc[jmn, :].reshape((1, 1, ns)), cosangle)\n            sqrtg += np.kron(gmnc[jmn, :].reshape((1, 1, ns)), cosangle)\n\n        Bmin, Bmax, epsilon, fsa_B2, fsa_1overB, f_t = compute_trapped_fraction(modB, sqrtg)\n\n        # There are several ways we could define an effective R for shaped geometry:\n        R = (G + iota * I) * fsa_1overB\n        #R = self.vmec.wout.RMajor_p\n\n        # Pack data into a return structure\n        data = Struct()\n        data.vmec = self.vmec\n        variables = ['nfp', 'surfaces', 'Bmin', 'Bmax', 'epsilon', 'fsa_B2', 'fsa_1overB', 'f_t',\n                     'modB', 'sqrtg', 'G', 'R', 'I', 'iota', 'psi_edge', 'theta1d', 'phi1d']\n        for v in variables:\n            data.__setattr__(v, eval(v))\n\n        if self.plot:\n            import matplotlib.pyplot as plt\n            plt.figure(figsize=(14, 7))\n            plt.rcParams.update({'font.size': 8})\n            nrows = 3\n            ncols = 4\n            variables = ['Bmax', 'Bmin', 'epsilon', 'fsa_B2', 'fsa_1overB', 'f_t', 'iota', 'G', 'I', 'R']\n            for j, variable in enumerate(variables):\n                plt.subplot(nrows, ncols, j + 1)\n                plt.plot(surfaces, eval(variable))\n                plt.title(variable)\n                plt.xlabel('s')\n            plt.tight_layout()\n            plt.show()\n\n        return data",
  "class RedlGeomBoozer(Optimizable):\n    \"\"\"\n    Evaluate geometry data needed to evaluate the Redl bootstrap\n    current formula, such as the effective fraction of trapped\n    particles.  In the approach here, Boozer coordinates are computed,\n    and all the symmetry-breaking Bmn harmonics are discarded to\n    obtain an effectively perfectly quasisymmetric configuration.\n\n    Args:\n        booz: An instance of :obj:`simsopt.mhd.boozer.Boozer`\n        surfaces: A 1D array with the values of normalized toroidal flux\n            to use for the bootstrap current calculation.\n        helicity_n: 0 for quasi-axisymmetry, or +/- 1 for quasi-helical symmetry.\n            This quantity is used to discard symmetry-breaking :math:`B_{mn}` harmonics.\n        ntheta: Number of grid points in the poloidal angle for evaluating geometric quantities in the Redl formulae.\n        plot: Make a plot of many of the quantities computed.\n    \"\"\"\n\n    def __init__(self, booz, surfaces, helicity_n, ntheta=64, plot=False):\n        booz.register(surfaces)\n        self.booz = booz\n        self.surfaces = surfaces\n        self.helicity_n = helicity_n\n        self.ntheta = ntheta\n        self.plot = plot\n        super().__init__(depends_on=[booz])\n\n    def __call__(self):\n        \"\"\"\n        Evaluate the geometric quantities needed for the Redl bootstrap\n        current formula.\n        \"\"\"\n        booz = self.booz\n        booz.run()\n\n        # self.surfaces = self.booz.bx.s_b\n        surfaces = self.surfaces\n        ns = len(surfaces)\n        ntheta = self.ntheta\n        theta1d = np.linspace(0, 2 * np.pi, ntheta, endpoint=False)\n        vmec = self.booz.equil\n        self.vmec = vmec\n        nfp = vmec.wout.nfp\n        psi_edge = -vmec.wout.phi[-1] / (2 * np.pi)\n        logger.info(f'Surfaces from booz_xform: {self.booz.bx.s_b}  '\n                    f'Surfaces for RedlGeomBoozer: {surfaces}')\n\n        # First, interpolate in s to get the quantities we need on the surfaces we need.\n        method = 'linear'\n\n        interp = interp1d(self.vmec.s_half_grid, self.vmec.wout.iotas[1:], fill_value=\"extrapolate\")\n        iota = interp(surfaces)\n\n        interp = interp1d(self.vmec.s_half_grid, self.vmec.wout.bvco[1:], fill_value=\"extrapolate\")\n        G = interp(surfaces)\n\n        interp = interp1d(self.vmec.s_half_grid, self.vmec.wout.buco[1:], fill_value=\"extrapolate\")\n        I = interp(surfaces)\n\n        if self.vmec.mpi.proc0_groups:\n            interp = interp1d(self.booz.bx.s_b, self.booz.bx.bmnc_b, fill_value=\"extrapolate\")\n            bmnc_b = interp(surfaces)\n            logger.info(f'Original bmnc_b.shape: {self.booz.bx.bmnc_b.shape}  Interpolated bmnc_b.shape: {bmnc_b.shape}')\n\n            interp = interp1d(self.booz.bx.s_b, self.booz.bx.gmnc_b, fill_value=\"extrapolate\")\n            gmnc_b = interp(surfaces)\n\n            # Evaluate modB and sqrtg on a uniform grid in theta,\n            # including only the modes that match the desired symmetry:\n            modB = np.zeros((ntheta, ns))\n            sqrtg = np.zeros((ntheta, ns))\n            s, theta = np.meshgrid(surfaces, theta1d)\n            for jmn in range(booz.bx.mnboz):\n                if booz.bx.xm_b[jmn] * self.helicity_n * nfp == booz.bx.xn_b[jmn]:\n                    # modB += cos(m * theta) * bmnc:\n                    modB += np.cos(booz.bx.xm_b[jmn] * theta) \\\n                        * np.kron(np.ones((ntheta, 1)), bmnc_b[jmn, None, :])\n                    sqrtg += np.cos(booz.bx.xm_b[jmn] * theta) \\\n                        * np.kron(np.ones((ntheta, 1)), gmnc_b[jmn, None, :])\n        else:\n            modB = 0\n            sqrtg = 0\n\n        modB = self.vmec.mpi.comm_groups.bcast(modB)\n        sqrtg = self.vmec.mpi.comm_groups.bcast(sqrtg)\n\n        Bmin, Bmax, epsilon, fsa_B2, fsa_1overB, f_t = compute_trapped_fraction(modB, sqrtg)\n\n        # There are several ways we could define an effective R for shaped geometry:\n        R = (G + iota * I) * fsa_1overB\n        #R = self.vmec.wout.RMajor_p\n\n        # Pack data into a return structure\n        data = Struct()\n        data.vmec = vmec\n        variables = ['nfp', 'surfaces', 'Bmin', 'Bmax', 'epsilon', 'fsa_B2', 'fsa_1overB', 'f_t',\n                     'modB', 'sqrtg', 'G', 'R', 'I', 'iota', 'psi_edge', 'theta1d']\n        for v in variables:\n            data.__setattr__(v, eval(v))\n\n        if self.plot:\n            import matplotlib.pyplot as plt\n            plt.figure(figsize=(14, 7))\n            plt.rcParams.update({'font.size': 8})\n            nrows = 3\n            ncols = 4\n            variables = ['Bmax', 'Bmin', 'epsilon', 'fsa_B2', 'fsa_1overB', 'f_t', 'iota', 'G', 'I', 'R']\n            for j, variable in enumerate(variables):\n                plt.subplot(nrows, ncols, j + 1)\n                plt.plot(surfaces, eval(variable))\n                plt.title(variable)\n                plt.xlabel('s')\n            plt.tight_layout()\n            plt.show()\n\n        return data",
  "class VmecRedlBootstrapMismatch(Optimizable):\n    r\"\"\"\n    This class is used to obtain quasi-axisymmetric or quasi-helically\n    symmetric VMEC configurations with self-consistent bootstrap\n    current. This class represents the objective function\n\n    .. math::\n\n        f = \\frac{\\int ds \\left[\\left<\\vec{J}\\cdot\\vec{B}\\right>_{vmec}\n                                - \\left<\\vec{J}\\cdot\\vec{B}\\right>_{Redl} \\right]^2}\n                 {\\int ds \\left[\\left<\\vec{J}\\cdot\\vec{B}\\right>_{vmec}\n                                + \\left<\\vec{J}\\cdot\\vec{B}\\right>_{Redl} \\right]^2}\n\n    where :math:`\\left<\\vec{J}\\cdot\\vec{B}\\right>_{vmec}` is the\n    bootstrap current profile in a VMEC equilibrium, and\n    :math:`\\left<\\vec{J}\\cdot\\vec{B}\\right>_{Redl}` is the bootstrap\n    current profile computed from the fit formulae in Redl et al,\n    Physics of Plasmas 28, 022502 (2021).\n\n    Args:\n        geom: An instance of either :obj:`RedlGeomVmec` or :obj:`RedlGeomBoozer`.\n        ne: A :obj:`~simsopt.mhd.profiles.Profile` object representing the electron density profile.\n        Te: A :obj:`~simsopt.mhd.profiles.Profile` object representing the electron temperature profile.\n        Ti: A :obj:`~simsopt.mhd.profiles.Profile` object representing the ion temperature profile.\n        Zeff: A :obj:`~simsopt.mhd.profiles.Profile` object representing the :math:`Z_{eff}` profile.\n            A single number can also be provided, in which case a constant :math:`Z_{eff}` profile will be used.\n        helicity_n: 0 for quasi-axisymmetry, or +/- 1 for quasi-helical symmetry.\n    \"\"\"\n\n    def __init__(self, geom, ne, Te, Ti, Zeff, helicity_n, logfile=None):\n        if not isinstance(Zeff, Profile):\n            # If we get here then Zeff is presumably a number. Convert it to a constant profile.\n            Zeff = ProfilePolynomial([Zeff])\n        self.geom = geom\n        self.ne = ne\n        self.Te = Te\n        self.Ti = Ti\n        self.Zeff = Zeff\n        self.helicity_n = helicity_n\n        self.iteration = 0\n        self.logfile = logfile\n\n        super().__init__(depends_on=[geom, ne, Te, Ti, Zeff])\n\n    def residuals(self):\n        r\"\"\"\n        This function returns a 1d array of residuals, useful for\n        representing the objective function as a nonlinear\n        least-squares problem.  This is the function handle to use\n        with a\n        :obj:`~simsopt.objectives.least_squares.LeastSquaresProblem`.\n\n        Specifically, this function returns\n\n        .. math::\n\n            R_j = \\frac{\\left<\\vec{J}\\cdot\\vec{B}\\right>_{vmec}(s_j)\n                      - \\left<\\vec{J}\\cdot\\vec{B}\\right>_{Redl}(s_j)}\n                       {\\sqrt{\\sum_{k=1}^N \\left[\\left<\\vec{J}\\cdot\\vec{B}\\right>_{vmec}(s_k)\n                                    + \\left<\\vec{J}\\cdot\\vec{B}\\right>_{Redl}(s_k) \\right]^2}}\n\n        where :math:`j` and :math:`k` range over the surfaces for the\n        supplied ``geom`` object (typically the half-grid points for\n        the VMEC configuration), :math:`j, k \\in \\{1, 2, \\ldots, N\\}`\n        and :math:`N` is the number of surfaces for the supplied\n        ``geom`` object. This corresponds to approximating the\n        :math:`\\int ds` integrals in the objective function with\n        Riemann integration. The vector of residuals returned has\n        length :math:`N`.\n\n        The sum of the squares of these residuals equals the objective\n        function. The total scalar objective is approximately\n        independent of the number of surfaces.\n        \"\"\"\n        jdotB_Redl, _ = j_dot_B_Redl(self.ne,\n                                     self.Te,\n                                     self.Ti,\n                                     self.Zeff,\n                                     self.helicity_n,\n                                     geom=self.geom)\n        # Interpolate vmec's <J dot B> profile from the full grid to the desired surfaces:\n        vmec = self.geom.vmec\n        interp = interp1d(vmec.s_full_grid, vmec.wout.jdotb)  # VMEC's \"jdotb\" is on the full grid.\n        jdotB_vmec = interp(self.geom.surfaces)\n\n        if self.logfile is not None:\n            if self.iteration == 0:\n                # Write header\n                with open(self.logfile, 'w') as f:\n                    f.write('s\\n')\n                    f.write(str(self.geom.surfaces[0]))\n                    for j in range(1, len(self.geom.surfaces)):\n                        f.write(', ' + str(self.geom.surfaces[j]))\n                    f.write('\\n')\n                    f.write('iteration, j dot B Redl, j dot B vmec\\n')\n\n            with open(self.logfile, 'a') as f:\n                f.write(str(self.iteration))\n                for j in range(len(self.geom.surfaces)):\n                    f.write(', ' + str(jdotB_Redl[j]))\n                for j in range(len(self.geom.surfaces)):\n                    f.write(', ' + str(jdotB_vmec[j]))\n                f.write('\\n')\n\n        self.iteration += 1\n        denominator = np.sum((jdotB_vmec + jdotB_Redl) ** 2)\n        return (jdotB_vmec - jdotB_Redl) / np.sqrt(denominator)\n\n    def J(self):\n        \"\"\"\n        Return the scalar objective function, given by the sum of the\n        squares of the residuals.\n        \"\"\"\n        return np.sum(self.residuals() ** 2)",
  "def __init__(self, vmec, surfaces=None, ntheta=64, nphi=65, plot=False):\n        self.vmec = vmec\n        self.surfaces = surfaces\n        self.ntheta = ntheta\n        self.nphi = nphi\n        self.plot = plot\n        super().__init__(depends_on=[vmec])",
  "def __call__(self):\n        \"\"\"\n        Evaluate the geometric quantities needed for the Redl bootstrap\n        current formula.\n        \"\"\"\n        self.vmec.run()\n\n        if self.surfaces is None:\n            self.surfaces = self.vmec.s_half_grid\n        surfaces = self.surfaces\n        ntheta = self.ntheta\n        nphi = self.nphi\n\n        ns = len(surfaces)\n        nfp = self.vmec.wout.nfp\n        psi_edge = -self.vmec.wout.phi[-1] / (2 * np.pi)\n\n        # First, interpolate in s to get the quantities we need on the surfaces we need.\n        method = 'linear'\n\n        interp = interp1d(self.vmec.s_half_grid, self.vmec.wout.iotas[1:], fill_value=\"extrapolate\")\n        iota = interp(surfaces)\n\n        interp = interp1d(self.vmec.s_half_grid, self.vmec.wout.bvco[1:], fill_value=\"extrapolate\")\n        G = interp(surfaces)\n\n        interp = interp1d(self.vmec.s_half_grid, self.vmec.wout.buco[1:], fill_value=\"extrapolate\")\n        I = interp(surfaces)\n\n        interp = interp1d(self.vmec.s_half_grid, self.vmec.wout.gmnc[:, 1:], fill_value=\"extrapolate\")\n        gmnc = interp(surfaces)\n\n        interp = interp1d(self.vmec.s_half_grid, self.vmec.wout.bmnc[:, 1:], fill_value=\"extrapolate\")\n        bmnc = interp(surfaces)\n\n        theta1d = np.linspace(0, 2 * np.pi, ntheta, endpoint=False)\n        phi1d = np.linspace(0, 2 * np.pi / nfp, nphi, endpoint=False)\n        phi2d, theta2d = np.meshgrid(phi1d, theta1d)\n        phi3d = phi2d.reshape((ntheta, nphi, 1))\n        theta3d = theta2d.reshape((ntheta, nphi, 1))\n\n        myshape = (ntheta, nphi, ns)\n        modB = np.zeros(myshape)\n        sqrtg = np.zeros(myshape)\n        for jmn in range(len(self.vmec.wout.xm_nyq)):\n            m = self.vmec.wout.xm_nyq[jmn]\n            n = self.vmec.wout.xn_nyq[jmn]\n            angle = m * theta3d - n * phi3d\n            cosangle = np.cos(angle)\n            sinangle = np.sin(angle)\n            modB += np.kron(bmnc[jmn, :].reshape((1, 1, ns)), cosangle)\n            sqrtg += np.kron(gmnc[jmn, :].reshape((1, 1, ns)), cosangle)\n\n        Bmin, Bmax, epsilon, fsa_B2, fsa_1overB, f_t = compute_trapped_fraction(modB, sqrtg)\n\n        # There are several ways we could define an effective R for shaped geometry:\n        R = (G + iota * I) * fsa_1overB\n        #R = self.vmec.wout.RMajor_p\n\n        # Pack data into a return structure\n        data = Struct()\n        data.vmec = self.vmec\n        variables = ['nfp', 'surfaces', 'Bmin', 'Bmax', 'epsilon', 'fsa_B2', 'fsa_1overB', 'f_t',\n                     'modB', 'sqrtg', 'G', 'R', 'I', 'iota', 'psi_edge', 'theta1d', 'phi1d']\n        for v in variables:\n            data.__setattr__(v, eval(v))\n\n        if self.plot:\n            import matplotlib.pyplot as plt\n            plt.figure(figsize=(14, 7))\n            plt.rcParams.update({'font.size': 8})\n            nrows = 3\n            ncols = 4\n            variables = ['Bmax', 'Bmin', 'epsilon', 'fsa_B2', 'fsa_1overB', 'f_t', 'iota', 'G', 'I', 'R']\n            for j, variable in enumerate(variables):\n                plt.subplot(nrows, ncols, j + 1)\n                plt.plot(surfaces, eval(variable))\n                plt.title(variable)\n                plt.xlabel('s')\n            plt.tight_layout()\n            plt.show()\n\n        return data",
  "def __init__(self, booz, surfaces, helicity_n, ntheta=64, plot=False):\n        booz.register(surfaces)\n        self.booz = booz\n        self.surfaces = surfaces\n        self.helicity_n = helicity_n\n        self.ntheta = ntheta\n        self.plot = plot\n        super().__init__(depends_on=[booz])",
  "def __call__(self):\n        \"\"\"\n        Evaluate the geometric quantities needed for the Redl bootstrap\n        current formula.\n        \"\"\"\n        booz = self.booz\n        booz.run()\n\n        # self.surfaces = self.booz.bx.s_b\n        surfaces = self.surfaces\n        ns = len(surfaces)\n        ntheta = self.ntheta\n        theta1d = np.linspace(0, 2 * np.pi, ntheta, endpoint=False)\n        vmec = self.booz.equil\n        self.vmec = vmec\n        nfp = vmec.wout.nfp\n        psi_edge = -vmec.wout.phi[-1] / (2 * np.pi)\n        logger.info(f'Surfaces from booz_xform: {self.booz.bx.s_b}  '\n                    f'Surfaces for RedlGeomBoozer: {surfaces}')\n\n        # First, interpolate in s to get the quantities we need on the surfaces we need.\n        method = 'linear'\n\n        interp = interp1d(self.vmec.s_half_grid, self.vmec.wout.iotas[1:], fill_value=\"extrapolate\")\n        iota = interp(surfaces)\n\n        interp = interp1d(self.vmec.s_half_grid, self.vmec.wout.bvco[1:], fill_value=\"extrapolate\")\n        G = interp(surfaces)\n\n        interp = interp1d(self.vmec.s_half_grid, self.vmec.wout.buco[1:], fill_value=\"extrapolate\")\n        I = interp(surfaces)\n\n        if self.vmec.mpi.proc0_groups:\n            interp = interp1d(self.booz.bx.s_b, self.booz.bx.bmnc_b, fill_value=\"extrapolate\")\n            bmnc_b = interp(surfaces)\n            logger.info(f'Original bmnc_b.shape: {self.booz.bx.bmnc_b.shape}  Interpolated bmnc_b.shape: {bmnc_b.shape}')\n\n            interp = interp1d(self.booz.bx.s_b, self.booz.bx.gmnc_b, fill_value=\"extrapolate\")\n            gmnc_b = interp(surfaces)\n\n            # Evaluate modB and sqrtg on a uniform grid in theta,\n            # including only the modes that match the desired symmetry:\n            modB = np.zeros((ntheta, ns))\n            sqrtg = np.zeros((ntheta, ns))\n            s, theta = np.meshgrid(surfaces, theta1d)\n            for jmn in range(booz.bx.mnboz):\n                if booz.bx.xm_b[jmn] * self.helicity_n * nfp == booz.bx.xn_b[jmn]:\n                    # modB += cos(m * theta) * bmnc:\n                    modB += np.cos(booz.bx.xm_b[jmn] * theta) \\\n                        * np.kron(np.ones((ntheta, 1)), bmnc_b[jmn, None, :])\n                    sqrtg += np.cos(booz.bx.xm_b[jmn] * theta) \\\n                        * np.kron(np.ones((ntheta, 1)), gmnc_b[jmn, None, :])\n        else:\n            modB = 0\n            sqrtg = 0\n\n        modB = self.vmec.mpi.comm_groups.bcast(modB)\n        sqrtg = self.vmec.mpi.comm_groups.bcast(sqrtg)\n\n        Bmin, Bmax, epsilon, fsa_B2, fsa_1overB, f_t = compute_trapped_fraction(modB, sqrtg)\n\n        # There are several ways we could define an effective R for shaped geometry:\n        R = (G + iota * I) * fsa_1overB\n        #R = self.vmec.wout.RMajor_p\n\n        # Pack data into a return structure\n        data = Struct()\n        data.vmec = vmec\n        variables = ['nfp', 'surfaces', 'Bmin', 'Bmax', 'epsilon', 'fsa_B2', 'fsa_1overB', 'f_t',\n                     'modB', 'sqrtg', 'G', 'R', 'I', 'iota', 'psi_edge', 'theta1d']\n        for v in variables:\n            data.__setattr__(v, eval(v))\n\n        if self.plot:\n            import matplotlib.pyplot as plt\n            plt.figure(figsize=(14, 7))\n            plt.rcParams.update({'font.size': 8})\n            nrows = 3\n            ncols = 4\n            variables = ['Bmax', 'Bmin', 'epsilon', 'fsa_B2', 'fsa_1overB', 'f_t', 'iota', 'G', 'I', 'R']\n            for j, variable in enumerate(variables):\n                plt.subplot(nrows, ncols, j + 1)\n                plt.plot(surfaces, eval(variable))\n                plt.title(variable)\n                plt.xlabel('s')\n            plt.tight_layout()\n            plt.show()\n\n        return data",
  "def __init__(self, geom, ne, Te, Ti, Zeff, helicity_n, logfile=None):\n        if not isinstance(Zeff, Profile):\n            # If we get here then Zeff is presumably a number. Convert it to a constant profile.\n            Zeff = ProfilePolynomial([Zeff])\n        self.geom = geom\n        self.ne = ne\n        self.Te = Te\n        self.Ti = Ti\n        self.Zeff = Zeff\n        self.helicity_n = helicity_n\n        self.iteration = 0\n        self.logfile = logfile\n\n        super().__init__(depends_on=[geom, ne, Te, Ti, Zeff])",
  "def residuals(self):\n        r\"\"\"\n        This function returns a 1d array of residuals, useful for\n        representing the objective function as a nonlinear\n        least-squares problem.  This is the function handle to use\n        with a\n        :obj:`~simsopt.objectives.least_squares.LeastSquaresProblem`.\n\n        Specifically, this function returns\n\n        .. math::\n\n            R_j = \\frac{\\left<\\vec{J}\\cdot\\vec{B}\\right>_{vmec}(s_j)\n                      - \\left<\\vec{J}\\cdot\\vec{B}\\right>_{Redl}(s_j)}\n                       {\\sqrt{\\sum_{k=1}^N \\left[\\left<\\vec{J}\\cdot\\vec{B}\\right>_{vmec}(s_k)\n                                    + \\left<\\vec{J}\\cdot\\vec{B}\\right>_{Redl}(s_k) \\right]^2}}\n\n        where :math:`j` and :math:`k` range over the surfaces for the\n        supplied ``geom`` object (typically the half-grid points for\n        the VMEC configuration), :math:`j, k \\in \\{1, 2, \\ldots, N\\}`\n        and :math:`N` is the number of surfaces for the supplied\n        ``geom`` object. This corresponds to approximating the\n        :math:`\\int ds` integrals in the objective function with\n        Riemann integration. The vector of residuals returned has\n        length :math:`N`.\n\n        The sum of the squares of these residuals equals the objective\n        function. The total scalar objective is approximately\n        independent of the number of surfaces.\n        \"\"\"\n        jdotB_Redl, _ = j_dot_B_Redl(self.ne,\n                                     self.Te,\n                                     self.Ti,\n                                     self.Zeff,\n                                     self.helicity_n,\n                                     geom=self.geom)\n        # Interpolate vmec's <J dot B> profile from the full grid to the desired surfaces:\n        vmec = self.geom.vmec\n        interp = interp1d(vmec.s_full_grid, vmec.wout.jdotb)  # VMEC's \"jdotb\" is on the full grid.\n        jdotB_vmec = interp(self.geom.surfaces)\n\n        if self.logfile is not None:\n            if self.iteration == 0:\n                # Write header\n                with open(self.logfile, 'w') as f:\n                    f.write('s\\n')\n                    f.write(str(self.geom.surfaces[0]))\n                    for j in range(1, len(self.geom.surfaces)):\n                        f.write(', ' + str(self.geom.surfaces[j]))\n                    f.write('\\n')\n                    f.write('iteration, j dot B Redl, j dot B vmec\\n')\n\n            with open(self.logfile, 'a') as f:\n                f.write(str(self.iteration))\n                for j in range(len(self.geom.surfaces)):\n                    f.write(', ' + str(jdotB_Redl[j]))\n                for j in range(len(self.geom.surfaces)):\n                    f.write(', ' + str(jdotB_vmec[j]))\n                f.write('\\n')\n\n        self.iteration += 1\n        denominator = np.sum((jdotB_vmec + jdotB_Redl) ** 2)\n        return (jdotB_vmec - jdotB_Redl) / np.sqrt(denominator)",
  "def J(self):\n        \"\"\"\n        Return the scalar objective function, given by the sum of the\n        squares of the residuals.\n        \"\"\"\n        return np.sum(self.residuals() ** 2)",
  "def integrand(lambd):\n                # This function gives lambda / <sqrt(1 - lambda B)>:\n                return lambd / (np.mean(np.sqrt(1 - lambd * modB[:, :, js]) * sqrtg[:, :, js]) \\\n                                / (fourpisq * dVds[js]))",
  "def integrand(lambd):\n                # This function gives lambda / <sqrt(1 - lambda B)>:\n                return lambd / (np.mean(np.sqrt(1 - lambd * modB[:, js]) * sqrtg[:, js]) \\\n                                / (twopi * dVds[js]))",
  "class LeastSquaresProblem(Optimizable):\n    \"\"\"\n    Represents a nonlinear-least-squares problem implemented using the \n    graph based optimization framework. A LeastSquaresProblem instance has\n    3 basic attributes: a set of functions (`f_in`), target values for each\n    of the functions (`goal`), and weights.  The residual\n    (`f_out`) for each of the `f_in` is defined as:\n\n    .. math::\n\n        f_{out} = weight * (f_{in} - goal) ^ 2\n\n    Args:\n        goals: Targets for residuals in optimization\n        weights: Weight associated with each of the residual\n        funcs_in: Input functions (Generally one of the output functions of\n                  the Optimizable instances\n        depends_on: (Alternative initialization) Instead of specifying funcs_in,\n                one could specify the Optimizable objects\n        opt_return_fns:  (Alternative initialization) If using *depends_on*,\n                specify the return functions associated with each Optimizable\n                object\n    \"\"\"\n\n    def __init__(self,\n                 goals: Union[Real, RealArray],\n                 weights: Union[Real, RealArray],\n                 funcs_in: Sequence[Callable] = None,\n                 depends_on: Union[Optimizable, Sequence[Optimizable]] = None,\n                 opt_return_fns: StrSeq = None,\n                 fail: Union[None, float] = 1.0e12):\n\n        if isinstance(goals, Real):\n            goals = [goals]\n        if isinstance(weights, Real):\n            weights = [weights]\n        if np.any(np.asarray(weights) < 0):\n            raise ValueError('Weight cannot be negative')\n        self.goals = np.asarray(goals)\n        self.inp_weights = np.asarray(weights)\n        self.fail = fail\n\n        # Attributes for function evaluation\n        self.nvals = 0\n        self.first_eval = True\n\n        if depends_on is not None:\n            if not isinstance(depends_on, ABC_Sequence):\n                depends_on = [depends_on]\n                if opt_return_fns is not None:\n                    opt_return_fns = [opt_return_fns]\n\n        super().__init__(depends_on=depends_on, opt_return_fns=opt_return_fns,\n                         funcs_in=funcs_in)\n\n    @classmethod\n    def from_sigma(cls,\n                   goals: Union[Real, RealArray],\n                   sigma: Union[Real, RealArray],\n                   funcs_in: Sequence[Callable] = None,\n                   depends_on: Union[Optimizable, Sequence[Optimizable]] = None,\n                   opt_return_fns: StrSeq = None,\n                   fail: Union[None, float] = 1.0e12) -> LeastSquaresProblem:\n        r\"\"\"\n        Define the LeastSquaresProblem with\n\n        .. math::\n            \\sigma = 1/\\sqrt{weight}, \\text{so} \\\\\n            f_{out} = \\left(\\frac{f_{in} - goal}{\\sigma}\\right) ^ 2.\n\n        Args:\n            goals: Targets for residuals in optimization\n            sigma: Inverse of the sqrt of the weight associated with each\n                of the residual\n            funcs_in: Input functions (Generally one of the output functions of\n                the Optimizable instances\n            depends_on: (Alternative initialization) Instead of specifying\n                funcs_in, one could specify the Optimizable objects\n            opt_return_fns: (Alternative initialization) If using *depends_on*,\n                specify the return functions associated with each Optimizable\n                object\n        \"\"\"\n        if np.any(np.array(sigma) == 0):\n            raise ValueError('sigma cannot be 0')\n        if not isinstance(sigma, Real):\n            sigma = np.array(sigma)\n\n        return cls(goals, 1.0 / (sigma * sigma),\n                   depends_on=depends_on,\n                   opt_return_fns=opt_return_fns,\n                   funcs_in=funcs_in,\n                   fail=fail)\n\n    @classmethod\n    def from_tuples(cls,\n                    tuples: Sequence[Tuple[Callable, Real, Real]],\n                    fail: Union[None, float] = 1.0e12) -> LeastSquaresProblem:\n        \"\"\"\n        Initializes graph based LeastSquaresProblem from a sequence of tuples\n        containing *f_in*, *goal*, and *weight*.\n\n        Args:\n            tuples: A sequence of tuples containing (f_in, goal, weight) in\n                each tuple (the specified order matters).\n        \"\"\"\n        funcs_in, goals, weights = zip(*tuples)\n        return cls(goals, weights, funcs_in=funcs_in, fail=fail)\n\n    def unweighted_residuals(self, x=None, *args, **kwargs):\n        \"\"\"\n        Return the unweighted residuals (f_in - goal)\n\n        Args:\n            x: Degrees of freedom or state\n            args: Any additional arguments\n            kwargs: Keyword arguments\n        \"\"\"\n        if x is not None:\n            self.x = x\n\n        if self.new_x:\n            outputs = []\n            new_weights = []\n            for i, fn in enumerate(self.funcs_in):\n                try:\n                    out = fn(*args, **kwargs)\n                except ObjectiveFailure:\n                    logger.warning(f\"Function evaluation failed for {fn}\")\n                    if self.fail is None or self.first_eval:\n                        raise\n\n                    break\n\n                output = np.array([out]) if not np.ndim(out) else np.asarray(out)\n                output = output - self.goals[i]\n                if self.first_eval:\n                    self.nvals += len(output)\n                    logger.debug(f\"{i}: first eval {self.nvals}\")\n                new_weights += [self.inp_weights[i]] * len(output)\n                outputs += [output]\n            else:\n                if self.first_eval:\n                    self.first_eval = False\n                self.weights = np.asarray(new_weights)\n                self.cache = np.concatenate(outputs)\n                self.new_x = False\n                return self.cache\n\n            # Reached here after encountering break in for loop\n            self.cache = np.full(self.nvals, self.fail)\n            self.new_x = False\n            return self.cache\n        else:\n            return self.cache\n\n    def residuals(self, x=None, *args, **kwargs):\n        \"\"\"\n        Return the weighted residuals\n\n        Args:\n            x: Degrees of freedom or state\n            args: Any additional arguments\n            kwargs: Keyword arguments\n        \"\"\"\n        unweighted_residuals = self.unweighted_residuals(x, *args, **kwargs)\n        return unweighted_residuals * np.sqrt(self.weights)\n\n    def objective(self, x=None, *args, **kwargs):\n        \"\"\"\n        Return the least squares sum\n\n        Args:\n            x: Degrees of freedom or state\n            args: Any additional arguments\n            kwargs: Keyword arguments\n        \"\"\"\n        logger.info(f\"objective() called with x={x}\")\n        unweighted_residuals = self.unweighted_residuals(x, *args, **kwargs)\n\n        s = 0\n        for i, val in enumerate(unweighted_residuals):\n            s += np.dot(val, val) * self.weights[i]\n\n        logger.info(f\"objective(): {s}\")\n        return s\n\n    return_fn_map = {'residuals': residuals, 'objective': objective}\n\n    def __add__(self, other: LeastSquaresProblem) -> LeastSquaresProblem:\n        return LeastSquaresProblem(\n            np.concatenate([self.goals, other.goals]),\n            np.concatenate([self.inp_weights, other.inp_weights]),\n            depends_on=(self.parents + other.parents),\n            opt_return_fns=(self.get_parent_return_fns_list() +\n                            other.get_parent_return_fns_list()),\n            fail=max(self.fail, other.fail)\n        )",
  "def __init__(self,\n                 goals: Union[Real, RealArray],\n                 weights: Union[Real, RealArray],\n                 funcs_in: Sequence[Callable] = None,\n                 depends_on: Union[Optimizable, Sequence[Optimizable]] = None,\n                 opt_return_fns: StrSeq = None,\n                 fail: Union[None, float] = 1.0e12):\n\n        if isinstance(goals, Real):\n            goals = [goals]\n        if isinstance(weights, Real):\n            weights = [weights]\n        if np.any(np.asarray(weights) < 0):\n            raise ValueError('Weight cannot be negative')\n        self.goals = np.asarray(goals)\n        self.inp_weights = np.asarray(weights)\n        self.fail = fail\n\n        # Attributes for function evaluation\n        self.nvals = 0\n        self.first_eval = True\n\n        if depends_on is not None:\n            if not isinstance(depends_on, ABC_Sequence):\n                depends_on = [depends_on]\n                if opt_return_fns is not None:\n                    opt_return_fns = [opt_return_fns]\n\n        super().__init__(depends_on=depends_on, opt_return_fns=opt_return_fns,\n                         funcs_in=funcs_in)",
  "def from_sigma(cls,\n                   goals: Union[Real, RealArray],\n                   sigma: Union[Real, RealArray],\n                   funcs_in: Sequence[Callable] = None,\n                   depends_on: Union[Optimizable, Sequence[Optimizable]] = None,\n                   opt_return_fns: StrSeq = None,\n                   fail: Union[None, float] = 1.0e12) -> LeastSquaresProblem:\n        r\"\"\"\n        Define the LeastSquaresProblem with\n\n        .. math::\n            \\sigma = 1/\\sqrt{weight}, \\text{so} \\\\\n            f_{out} = \\left(\\frac{f_{in} - goal}{\\sigma}\\right) ^ 2.\n\n        Args:\n            goals: Targets for residuals in optimization\n            sigma: Inverse of the sqrt of the weight associated with each\n                of the residual\n            funcs_in: Input functions (Generally one of the output functions of\n                the Optimizable instances\n            depends_on: (Alternative initialization) Instead of specifying\n                funcs_in, one could specify the Optimizable objects\n            opt_return_fns: (Alternative initialization) If using *depends_on*,\n                specify the return functions associated with each Optimizable\n                object\n        \"\"\"\n        if np.any(np.array(sigma) == 0):\n            raise ValueError('sigma cannot be 0')\n        if not isinstance(sigma, Real):\n            sigma = np.array(sigma)\n\n        return cls(goals, 1.0 / (sigma * sigma),\n                   depends_on=depends_on,\n                   opt_return_fns=opt_return_fns,\n                   funcs_in=funcs_in,\n                   fail=fail)",
  "def from_tuples(cls,\n                    tuples: Sequence[Tuple[Callable, Real, Real]],\n                    fail: Union[None, float] = 1.0e12) -> LeastSquaresProblem:\n        \"\"\"\n        Initializes graph based LeastSquaresProblem from a sequence of tuples\n        containing *f_in*, *goal*, and *weight*.\n\n        Args:\n            tuples: A sequence of tuples containing (f_in, goal, weight) in\n                each tuple (the specified order matters).\n        \"\"\"\n        funcs_in, goals, weights = zip(*tuples)\n        return cls(goals, weights, funcs_in=funcs_in, fail=fail)",
  "def unweighted_residuals(self, x=None, *args, **kwargs):\n        \"\"\"\n        Return the unweighted residuals (f_in - goal)\n\n        Args:\n            x: Degrees of freedom or state\n            args: Any additional arguments\n            kwargs: Keyword arguments\n        \"\"\"\n        if x is not None:\n            self.x = x\n\n        if self.new_x:\n            outputs = []\n            new_weights = []\n            for i, fn in enumerate(self.funcs_in):\n                try:\n                    out = fn(*args, **kwargs)\n                except ObjectiveFailure:\n                    logger.warning(f\"Function evaluation failed for {fn}\")\n                    if self.fail is None or self.first_eval:\n                        raise\n\n                    break\n\n                output = np.array([out]) if not np.ndim(out) else np.asarray(out)\n                output = output - self.goals[i]\n                if self.first_eval:\n                    self.nvals += len(output)\n                    logger.debug(f\"{i}: first eval {self.nvals}\")\n                new_weights += [self.inp_weights[i]] * len(output)\n                outputs += [output]\n            else:\n                if self.first_eval:\n                    self.first_eval = False\n                self.weights = np.asarray(new_weights)\n                self.cache = np.concatenate(outputs)\n                self.new_x = False\n                return self.cache\n\n            # Reached here after encountering break in for loop\n            self.cache = np.full(self.nvals, self.fail)\n            self.new_x = False\n            return self.cache\n        else:\n            return self.cache",
  "def residuals(self, x=None, *args, **kwargs):\n        \"\"\"\n        Return the weighted residuals\n\n        Args:\n            x: Degrees of freedom or state\n            args: Any additional arguments\n            kwargs: Keyword arguments\n        \"\"\"\n        unweighted_residuals = self.unweighted_residuals(x, *args, **kwargs)\n        return unweighted_residuals * np.sqrt(self.weights)",
  "def objective(self, x=None, *args, **kwargs):\n        \"\"\"\n        Return the least squares sum\n\n        Args:\n            x: Degrees of freedom or state\n            args: Any additional arguments\n            kwargs: Keyword arguments\n        \"\"\"\n        logger.info(f\"objective() called with x={x}\")\n        unweighted_residuals = self.unweighted_residuals(x, *args, **kwargs)\n\n        s = 0\n        for i, val in enumerate(unweighted_residuals):\n            s += np.dot(val, val) * self.weights[i]\n\n        logger.info(f\"objective(): {s}\")\n        return s",
  "def __add__(self, other: LeastSquaresProblem) -> LeastSquaresProblem:\n        return LeastSquaresProblem(\n            np.concatenate([self.goals, other.goals]),\n            np.concatenate([self.inp_weights, other.inp_weights]),\n            depends_on=(self.parents + other.parents),\n            opt_return_fns=(self.get_parent_return_fns_list() +\n                            other.get_parent_return_fns_list()),\n            fail=max(self.fail, other.fail)\n        )",
  "def forward_backward(P, L, U, rhs, iterative_refinement=False):\n    \"\"\"\n    Solve a linear system of the form (PLU)^T*adj = rhs for adj.\n\n\n    Args:\n        P: permutation matrix\n        L: lower triangular matrix\n        U: upper triangular matrix\n        iterative_refinement: when true, applies iterative refinement which can improve\n                              the accuracy of the computed solution when the matrix is\n                              particularly ill-conditioned.\n    \"\"\"\n    y = scipy.linalg.solve_triangular(U.T, rhs, lower=True)\n    z = scipy.linalg.solve_triangular(L.T, y, lower=False)\n    adj = P@z\n\n    if iterative_refinement:\n        yp = scipy.linalg.solve_triangular(U.T, rhs-(P@L@U).T@adj, lower=True)\n        zp = scipy.linalg.solve_triangular(L.T, yp, lower=False)\n        adj += P@zp\n\n    return adj",
  "def sum_across_comm(derivative, comm):\n    r\"\"\"\n    Compute the sum of :mod:`simsopt._core.derivative.Derivative` objects from\n    several MPI ranks. This implementation is fairly basic and requires that\n    the derivative dictionaries contain the same keys on all ranks.\n    \"\"\"\n    newdict = {}\n    for k in derivative.data.keys():\n        data = derivative.data[k]\n        alldata = sum(comm.allgather(data))\n        if isinstance(alldata, float):\n            alldata = np.asarray([alldata])\n        newdict[k] = alldata\n    return Derivative(newdict)",
  "class MPIObjective(Optimizable):\n\n    def __init__(self, objectives, comm, needs_splitting=False):\n        r\"\"\"\n        Compute the mean of a list of objectives in parallel using MPI.\n\n        Args:\n            objectives: A python list of objectives that provide ``.J()`` and ``.dJ()`` functions.\n            comm: The MPI communicator to use.\n            needs_splitting: if set to ``True``, then the list of objectives is\n                             split into disjoint partitions and only one part is worked on per\n                             mpi rank. If set to ``False``, then we assume that the user\n                             constructed the list of ``objectives`` so that it only contains the\n                             objectives relevant to that mpi rank.\n        \"\"\"\n\n        if needs_splitting:\n            from simsopt._core.util import parallel_loop_bounds\n            startidx, endidx = parallel_loop_bounds(comm, len(objectives))\n            objectives = objectives[startidx:endidx]\n        Optimizable.__init__(self, x0=np.asarray([]), depends_on=objectives)\n        self.objectives = objectives\n        self.comm = comm\n        self.n = len(self.objectives) if comm is None else np.sum(self.comm.allgather(len(self.objectives)))\n\n    def J(self):\n        local_vals = [J.J() for J in self.objectives]\n        global_vals = local_vals if self.comm is None else [i for o in self.comm.allgather(local_vals) for i in o]\n        res = np.sum(global_vals)\n        return res/self.n\n\n    @derivative_dec\n    def dJ(self):\n        if len(self.objectives) == 0:\n            raise NotImplementedError(\"`MPIObjective.dJ` currently requires that there is at least one objective per process.\")\n        local_derivs = sum([J.dJ(partials=True) for J in self.objectives])\n        all_derivs = local_derivs if self.comm is None else sum_across_comm(local_derivs, self.comm)\n        all_derivs *= 1./self.n\n        return all_derivs",
  "class QuadraticPenalty(Optimizable):\n\n    def __init__(self, obj, cons=0., f=\"identity\"):\n        r\"\"\"\n        A quadratic penalty function of the form :math:`0.5f(\\text{obj}.J() - \\text{cons})^2` for an underlying objective ``obj``\n        and wrapping function ``f``. This can be used to implement a barrier penalty function for (in)equality\n        constrained optimization problem. The wrapping function defaults to ``\"identity\"``.\n\n        Args:\n            obj: the underlying objective. It should provide a ``.J()`` and ``.dJ()`` function.\n            cons: constant\n            f: the function that wraps the difference :math:`obj-\\text{cons}`.  The options are ``\"min\"``, ``\"max\"``, or ``\"identity\"``.\n               which respectively return :math:`\\min(\\text{obj}-\\text{cons}, 0)`, :math:`\\max(\\text{obj}-\\text{cons}, 0)`, and :math:`\\text{obj}-\\text{cons}`.\n        \"\"\"\n        Optimizable.__init__(self, x0=np.asarray([]), depends_on=[obj])\n        self.obj = obj\n        self.cons = cons\n        self.f = f\n\n    def J(self):\n        val = self.obj.J()\n        diff = float(val - self.cons)\n\n        if self.f == 'max':\n            return 0.5*np.maximum(diff, 0)**2\n        elif self.f == 'min':\n            return 0.5*np.minimum(diff, 0)**2\n        elif self.f == 'identity':\n            return 0.5*diff**2\n        else:\n            raise Exception('incorrect wrapping function f provided')\n\n    @derivative_dec\n    def dJ(self):\n        val = self.obj.J()\n        dval = self.obj.dJ(partials=True)\n        diff = float(val - self.cons)\n\n        if self.f == 'max':\n            return np.maximum(diff, 0)*dval\n        elif self.f == 'min':\n            return np.minimum(diff, 0)*dval\n        elif self.f == 'identity':\n            return diff*dval\n        else:\n            raise Exception('incorrect wrapping function f provided')\n\n    return_fn_map = {'J': J, 'dJ': dJ}",
  "class Weight(object):\n\n    def __init__(self, value):\n        self.value = float(value)\n\n    def __float__(self):\n        return float(self.value)\n\n    def __imul__(self, alpha):\n        self.value *= alpha\n        return self",
  "def __init__(self, objectives, comm, needs_splitting=False):\n        r\"\"\"\n        Compute the mean of a list of objectives in parallel using MPI.\n\n        Args:\n            objectives: A python list of objectives that provide ``.J()`` and ``.dJ()`` functions.\n            comm: The MPI communicator to use.\n            needs_splitting: if set to ``True``, then the list of objectives is\n                             split into disjoint partitions and only one part is worked on per\n                             mpi rank. If set to ``False``, then we assume that the user\n                             constructed the list of ``objectives`` so that it only contains the\n                             objectives relevant to that mpi rank.\n        \"\"\"\n\n        if needs_splitting:\n            from simsopt._core.util import parallel_loop_bounds\n            startidx, endidx = parallel_loop_bounds(comm, len(objectives))\n            objectives = objectives[startidx:endidx]\n        Optimizable.__init__(self, x0=np.asarray([]), depends_on=objectives)\n        self.objectives = objectives\n        self.comm = comm\n        self.n = len(self.objectives) if comm is None else np.sum(self.comm.allgather(len(self.objectives)))",
  "def J(self):\n        local_vals = [J.J() for J in self.objectives]\n        global_vals = local_vals if self.comm is None else [i for o in self.comm.allgather(local_vals) for i in o]\n        res = np.sum(global_vals)\n        return res/self.n",
  "def dJ(self):\n        if len(self.objectives) == 0:\n            raise NotImplementedError(\"`MPIObjective.dJ` currently requires that there is at least one objective per process.\")\n        local_derivs = sum([J.dJ(partials=True) for J in self.objectives])\n        all_derivs = local_derivs if self.comm is None else sum_across_comm(local_derivs, self.comm)\n        all_derivs *= 1./self.n\n        return all_derivs",
  "def __init__(self, obj, cons=0., f=\"identity\"):\n        r\"\"\"\n        A quadratic penalty function of the form :math:`0.5f(\\text{obj}.J() - \\text{cons})^2` for an underlying objective ``obj``\n        and wrapping function ``f``. This can be used to implement a barrier penalty function for (in)equality\n        constrained optimization problem. The wrapping function defaults to ``\"identity\"``.\n\n        Args:\n            obj: the underlying objective. It should provide a ``.J()`` and ``.dJ()`` function.\n            cons: constant\n            f: the function that wraps the difference :math:`obj-\\text{cons}`.  The options are ``\"min\"``, ``\"max\"``, or ``\"identity\"``.\n               which respectively return :math:`\\min(\\text{obj}-\\text{cons}, 0)`, :math:`\\max(\\text{obj}-\\text{cons}, 0)`, and :math:`\\text{obj}-\\text{cons}`.\n        \"\"\"\n        Optimizable.__init__(self, x0=np.asarray([]), depends_on=[obj])\n        self.obj = obj\n        self.cons = cons\n        self.f = f",
  "def J(self):\n        val = self.obj.J()\n        diff = float(val - self.cons)\n\n        if self.f == 'max':\n            return 0.5*np.maximum(diff, 0)**2\n        elif self.f == 'min':\n            return 0.5*np.minimum(diff, 0)**2\n        elif self.f == 'identity':\n            return 0.5*diff**2\n        else:\n            raise Exception('incorrect wrapping function f provided')",
  "def dJ(self):\n        val = self.obj.J()\n        dval = self.obj.dJ(partials=True)\n        diff = float(val - self.cons)\n\n        if self.f == 'max':\n            return np.maximum(diff, 0)*dval\n        elif self.f == 'min':\n            return np.minimum(diff, 0)*dval\n        elif self.f == 'identity':\n            return diff*dval\n        else:\n            raise Exception('incorrect wrapping function f provided')",
  "def __init__(self, value):\n        self.value = float(value)",
  "def __float__(self):\n        return float(self.value)",
  "def __imul__(self, alpha):\n        self.value *= alpha\n        return self",
  "class ConstrainedProblem(Optimizable):\n    \"\"\"\n    Represents a nonlinear, constrained optimization problem implemented using the \n    graph based optimization framework. A ConstrainedProblem instance has\n    4 basic attributes: an objective (`f`), nonlinear constraints (`c`), \n    linear constraints, and bound constraints. Problems take the general form:\n\n    .. math::\n\n        \\min_x f(x) \n        s.t. \n          l_{nlc} \\le c(x) \\le u_{nlc}\n          l_{lc} \\le Ax \\le u_{lc}\n\n    Bound constraints should be specified directly through the Optimizable objects. \n    For instance, with an optimizable object `v` we can set the \n    upper bounds of the free DOFs associated with the current Optimizable object \n    and those of its ancestors via `v.upper_bounds = ub` where ub is a 1d-array. \n    To set the upper bounds on the free dofs of a single optimizable object (and not\n    it's ancestors) use `v.local_upper_bounds = ub`.\n    The upper bound of a single dof can be set with `v.set_upper_bound(dof_name,value)`.\n\n    Args:\n        f_obj: objective function handle (generally one of the output functions of\n            the Optimizable instances)\n        tuples_nlc: Nonlinear constraints as a sequence of triples containing \n                    the nonlinear constraint function c with lower and upper bounds\n                    i.e. `[(c,l_{nlc},u_{nlc}), ...]`.\n                    Constraint handle can (`c`) can be vector-valued or scalar-valued.\n                    Constraint bounds can also be array or scalar.\n                    Use +- np.inf to indicate unbounded components.\n                    Define equality constraints by using equal upper and lower bounds.\n        tuple_lc: Linear constraints as a triple containing the 2d-array A,\n                  lower bound `l_{lc}`, and upper bound `u_{lc}`, \n                  i.e. `(A,l_{lc},u_{lc})`.\n                  Constraint bounds can be 1d arrays or scalars.\n                  Use +- np.inf in the bounds to indicate unbounded components.\n                  Define equality constraints by using equal upper and lower bounds.\n    \"\"\"\n\n    def __init__(self,\n                 f_obj: Callable,\n                 tuples_nlc: Sequence[Tuple[Callable, Real, Real]] = None,\n                 tuple_lc: Tuple[RealArray, Union[RealArray, Real], Union[RealArray, Real]] = None,\n                 fail: Optional[float] = 1.0e12):\n\n        self.fail = fail\n\n        # Attributes for function evaluation\n        self.nvals = 0\n        self.first_eval_obj = True\n        self.first_eval_con = True\n\n        # unpack the nonlinear constraints\n        if tuples_nlc is not None:\n            f_nlc, lhs_nlc, rhs_nlc = zip(*tuples_nlc)\n            funcs_in = [f_obj, *f_nlc]\n            self.has_nlc = True\n            self.lhs_nlc = lhs_nlc\n            self.rhs_nlc = rhs_nlc\n        else:\n            funcs_in = [f_obj]  \n            self.has_nlc = False\n\n        # unpack the linear constraints\n        if tuple_lc:\n            self.A_lc = np.asarray(tuple_lc[0])\n            self.l_lc = np.asarray(tuple_lc[1]) if np.ndim(tuple_lc[1]) else float(tuple_lc[1])\n            self.u_lc = np.asarray(tuple_lc[2]) if np.ndim(tuple_lc[2]) else float(tuple_lc[2])\n            self.has_lc = True\n        else:\n            self.has_lc = False\n\n        # make our class Optimizable\n        super().__init__(funcs_in=funcs_in)\n\n    def nonlinear_constraints(self, x=None, *args, **kwargs):\n        \"\"\"\n        Evaluates the Nonlinear constraints, l_c <= c(x) <= u_c.\n        Returns an array [l_c - c(x), c(x) - u_c,...].\n\n        Args:\n            x: Degrees of freedom or state\n            args: Any additional arguments\n            kwargs: Keyword arguments\n        \"\"\"\n        if x is not None:\n            # only change x if different than last evaluated\n            if np.any(self.x != x):\n                self.x = x\n\n        if self.new_x:\n            # empty the cache for objective and constraint\n            self.objective_cache = None\n            self.constraint_cache = None\n\n        # get the constraint funcs\n        fn_nlc = self.funcs_in[1:]\n        if not self.has_nlc:\n            # No nonlinear constraints to evaluate\n            raise RuntimeError\n\n        if (self.constraint_cache is None):\n            outputs = []\n            for i, fn in enumerate(fn_nlc):\n\n                try:\n                    out = fn(*args, **kwargs)\n                except ObjectiveFailure:\n                    logger.warning(f\"Function evaluation failed for {fn}\")\n                    if self.fail is None or self.first_eval_con:\n                        raise\n\n                    break\n\n                # evaluate lhs as lhs - c(x) <= 0\n                if np.any(np.isfinite(self.lhs_nlc[i])):\n                    diff = np.array(self.lhs_nlc[i]) - out\n                    output = np.array([diff]) if not np.ndim(diff) else np.asarray(diff)\n                    outputs += [output]\n                    if self.first_eval_con:\n                        self.nvals += len(output)\n                        logger.debug(f\"{i}: first eval {self.nvals}\")\n\n                # evaluate rhs as c(x) - rhs <= 0\n                if np.any(np.isfinite(self.rhs_nlc[i])):\n                    diff = out - np.array(self.rhs_nlc[i]) \n                    output = np.array([diff]) if not np.ndim(diff) else np.asarray(diff)\n                    outputs += [output]\n                    if self.first_eval_con:\n                        self.nvals += len(output)\n                        logger.debug(f\"{i}: first eval {self.nvals}\")\n\n            else:\n                if self.first_eval_con:\n                    self.first_eval_con = False\n                self.constraint_cache = np.concatenate(outputs)\n                self.new_x = False\n                return self.constraint_cache\n\n            # Reached here after encountering break in for loop\n            self.constraint_cache = np.full(self.nvals, self.fail)\n            self.new_x = False\n            return self.constraint_cache\n        else:\n            return self.constraint_cache\n\n    def objective(self, x=None, *args, **kwargs):\n        \"\"\"\n        Return the objective function\n\n        Args:\n            x: Degrees of freedom or state\n            args: Any additional arguments\n            kwargs: Keyword arguments\n        \"\"\"\n        if x is not None:\n            # only change x if different than last evaluated\n            if np.any(self.x != x):\n                self.x = x\n\n        if self.new_x:\n            # empty the cache for objective and constraint\n            self.objective_cache = None\n            self.constraint_cache = None\n\n        if (self.objective_cache is None):\n            fn = self.funcs_in[0]\n            try:\n                out = fn(*args, **kwargs)\n            except ObjectiveFailure:\n                logger.warning(f\"Function evaluation failed for {fn}\")\n                if self.fail is None or self.first_eval_obj:\n                    raise\n                out = self.fail\n\n            self.objective_cache = out\n            self.new_x = False\n\n            if self.first_eval_obj:\n                self.first_eval_obj = False\n\n            return self.objective_cache\n        else:\n            return self.objective_cache\n\n    def all_funcs(self, x=None, *args, **kwargs):\n        \"\"\"\n        Evaluate the objective and nonlinear constraints.\n\n        Args:\n            x: Degrees of freedom or state\n            args: Any additional arguments\n            kwargs: Keyword arguments\n        \"\"\"\n        f_obj = self.objective(x, *args, **kwargs)\n        out = np.array([f_obj])\n        if self.has_nlc:\n            f_nlc = self.nonlinear_constraints(x, *args, **kwargs)\n            out = np.concatenate((out, f_nlc))\n        return out",
  "def __init__(self,\n                 f_obj: Callable,\n                 tuples_nlc: Sequence[Tuple[Callable, Real, Real]] = None,\n                 tuple_lc: Tuple[RealArray, Union[RealArray, Real], Union[RealArray, Real]] = None,\n                 fail: Optional[float] = 1.0e12):\n\n        self.fail = fail\n\n        # Attributes for function evaluation\n        self.nvals = 0\n        self.first_eval_obj = True\n        self.first_eval_con = True\n\n        # unpack the nonlinear constraints\n        if tuples_nlc is not None:\n            f_nlc, lhs_nlc, rhs_nlc = zip(*tuples_nlc)\n            funcs_in = [f_obj, *f_nlc]\n            self.has_nlc = True\n            self.lhs_nlc = lhs_nlc\n            self.rhs_nlc = rhs_nlc\n        else:\n            funcs_in = [f_obj]  \n            self.has_nlc = False\n\n        # unpack the linear constraints\n        if tuple_lc:\n            self.A_lc = np.asarray(tuple_lc[0])\n            self.l_lc = np.asarray(tuple_lc[1]) if np.ndim(tuple_lc[1]) else float(tuple_lc[1])\n            self.u_lc = np.asarray(tuple_lc[2]) if np.ndim(tuple_lc[2]) else float(tuple_lc[2])\n            self.has_lc = True\n        else:\n            self.has_lc = False\n\n        # make our class Optimizable\n        super().__init__(funcs_in=funcs_in)",
  "def nonlinear_constraints(self, x=None, *args, **kwargs):\n        \"\"\"\n        Evaluates the Nonlinear constraints, l_c <= c(x) <= u_c.\n        Returns an array [l_c - c(x), c(x) - u_c,...].\n\n        Args:\n            x: Degrees of freedom or state\n            args: Any additional arguments\n            kwargs: Keyword arguments\n        \"\"\"\n        if x is not None:\n            # only change x if different than last evaluated\n            if np.any(self.x != x):\n                self.x = x\n\n        if self.new_x:\n            # empty the cache for objective and constraint\n            self.objective_cache = None\n            self.constraint_cache = None\n\n        # get the constraint funcs\n        fn_nlc = self.funcs_in[1:]\n        if not self.has_nlc:\n            # No nonlinear constraints to evaluate\n            raise RuntimeError\n\n        if (self.constraint_cache is None):\n            outputs = []\n            for i, fn in enumerate(fn_nlc):\n\n                try:\n                    out = fn(*args, **kwargs)\n                except ObjectiveFailure:\n                    logger.warning(f\"Function evaluation failed for {fn}\")\n                    if self.fail is None or self.first_eval_con:\n                        raise\n\n                    break\n\n                # evaluate lhs as lhs - c(x) <= 0\n                if np.any(np.isfinite(self.lhs_nlc[i])):\n                    diff = np.array(self.lhs_nlc[i]) - out\n                    output = np.array([diff]) if not np.ndim(diff) else np.asarray(diff)\n                    outputs += [output]\n                    if self.first_eval_con:\n                        self.nvals += len(output)\n                        logger.debug(f\"{i}: first eval {self.nvals}\")\n\n                # evaluate rhs as c(x) - rhs <= 0\n                if np.any(np.isfinite(self.rhs_nlc[i])):\n                    diff = out - np.array(self.rhs_nlc[i]) \n                    output = np.array([diff]) if not np.ndim(diff) else np.asarray(diff)\n                    outputs += [output]\n                    if self.first_eval_con:\n                        self.nvals += len(output)\n                        logger.debug(f\"{i}: first eval {self.nvals}\")\n\n            else:\n                if self.first_eval_con:\n                    self.first_eval_con = False\n                self.constraint_cache = np.concatenate(outputs)\n                self.new_x = False\n                return self.constraint_cache\n\n            # Reached here after encountering break in for loop\n            self.constraint_cache = np.full(self.nvals, self.fail)\n            self.new_x = False\n            return self.constraint_cache\n        else:\n            return self.constraint_cache",
  "def objective(self, x=None, *args, **kwargs):\n        \"\"\"\n        Return the objective function\n\n        Args:\n            x: Degrees of freedom or state\n            args: Any additional arguments\n            kwargs: Keyword arguments\n        \"\"\"\n        if x is not None:\n            # only change x if different than last evaluated\n            if np.any(self.x != x):\n                self.x = x\n\n        if self.new_x:\n            # empty the cache for objective and constraint\n            self.objective_cache = None\n            self.constraint_cache = None\n\n        if (self.objective_cache is None):\n            fn = self.funcs_in[0]\n            try:\n                out = fn(*args, **kwargs)\n            except ObjectiveFailure:\n                logger.warning(f\"Function evaluation failed for {fn}\")\n                if self.fail is None or self.first_eval_obj:\n                    raise\n                out = self.fail\n\n            self.objective_cache = out\n            self.new_x = False\n\n            if self.first_eval_obj:\n                self.first_eval_obj = False\n\n            return self.objective_cache\n        else:\n            return self.objective_cache",
  "def all_funcs(self, x=None, *args, **kwargs):\n        \"\"\"\n        Evaluate the objective and nonlinear constraints.\n\n        Args:\n            x: Degrees of freedom or state\n            args: Any additional arguments\n            kwargs: Keyword arguments\n        \"\"\"\n        f_obj = self.objective(x, *args, **kwargs)\n        out = np.array([f_obj])\n        if self.has_nlc:\n            f_nlc = self.nonlinear_constraints(x, *args, **kwargs)\n            out = np.concatenate((out, f_nlc))\n        return out",
  "class Identity(Optimizable):\n    \"\"\"\n    Represents a term in an objective function which is just\n    the identity. It has one degree of freedom. Conforms to the \n    graph based Optimizable framework.\n\n    The output of the method `f` is equal to this degree of freedom.\n    The call hook internally calls method f. It does not have any parent\n    Optimizable nodes\n\n    Args:\n        x: Value of the DOF\n        dof_name: Identifier for the DOF\n        dof_fixed: To specify if the dof is fixed\n    \"\"\"\n\n    def __init__(self,\n                 x: Real = 0.0,\n                 dof_name: str = None,\n                 dof_fixed: bool = False):\n        super().__init__([x],\n                         [dof_name] if dof_name is not None else None,\n                         [dof_fixed])\n\n    def f(self):\n        \"\"\"\n        Returns the value of the DOF\n        \"\"\"\n        return self.full_x[0]\n\n    def dJ(self, x: RealArray = None):\n        if x is not None:\n            if isinstance(x, Real):\n                self.x = [x]\n            else:\n                self.x = x\n        return np.array([1.0])\n\n    return_fn_map = {'f': f}\n\n    def as_dict(self, serial_objs_dict: dict) -> dict:\n        d = {}\n        d[\"@class\"] = self.__class__.__name__\n        d[\"@module\"] = self.__class__.__module__\n        d[\"@name\"] = self.name\n        d[\"x\"] = self.local_full_x[0]\n        d[\"dof_name\"] = self.local_full_dof_names[0]\n        d[\"dof_fixed\"] = np.logical_not(self.local_dofs_free_status)[0]\n        return d\n\n    @classmethod\n    def from_dict(cls, d, serial_objs_dict, recon_objs):\n        return cls(d[\"x\"], d[\"dof_name\"], d[\"dof_fixed\"])",
  "class Adder(Optimizable):\n    \"\"\"\n    Defines a minimal graphe based Optimizable object that can be optimized.\n    It has n degrees of freedom.\n\n    The method `sum` returns the sum of these dofs. The call hook internally\n    calls the `sum` method.\n\n    Args:\n        n: Number of degrees of freedom (DOFs)\n        x0: Initial values of the DOFs. If not given, equal to zeroes\n        dof_names: Identifiers for the DOFs\n    \"\"\"\n\n    def __init__(self, n=3, **kwargs):\n        self.n = n\n        super().__init__(**kwargs)\n\n    def sum(self):\n        \"\"\"\n        Sums the DOFs\n        \"\"\"\n        return np.sum(self._dofs.full_x)\n\n    def J(self):\n        return self.sum()\n\n    def dJ(self):\n        return np.ones(self.n)\n\n    @property\n    def df(self):\n        \"\"\"\n        Same as the function dJ(), but a property instead of a function.\n        \"\"\"\n        return self.dJ()\n\n    return_fn_map = {'sum': sum}",
  "class Rosenbrock(Optimizable):\n    \"\"\"\n    Implements Rosenbrock function using the graph based optimization\n    framework. The Rosenbrock function is defined as\n\n    .. math::\n        f(x,y) = (a-x)^2 + b(y-x^2)^2\n\n    The parameter *a* is fixed to 1. And the *b* parameter can be given as\n    input.\n\n    Args:\n        b: The *b* parameter of Rosenbrock function\n        x0: *x, y* coordinates\n    \"\"\"\n\n    def __init__(self, b=100.0, x0=[0.0, 0.0], **kwargs):\n        self._sqrtb = np.sqrt(b)\n        if \"names\" not in kwargs:\n            kwargs[\"names\"] = [\"x\", \"y\"]\n        super().__init__(x0=x0, **kwargs)\n\n    @property\n    def term1(self):\n        \"\"\"\n        Returns the first of the two quantities that is squared and summed.\n        \"\"\"\n        return self.local_full_x[0] - 1\n\n    @property\n    def term2(self):\n        \"\"\"\n        Returns the second of the two quantities that is squared and summed.\n        \"\"\"\n        x = self.local_full_x[0]\n        y = self.local_full_x[1]\n        return (x * x - y) / self._sqrtb\n\n    @property\n    def dterm1(self):\n        \"\"\"\n        Returns the gradient of term1\n        \"\"\"\n        return np.array([1.0, 0.0])\n\n    @property\n    def dterm2(self):\n        \"\"\"\n        Returns the gradient of term2\n        \"\"\"\n        return np.array([2 * self.local_full_x[0], -1.0]) / self._sqrtb\n\n    def f(self, x=None):\n        \"\"\"\n        Returns the total function, squaring and summing the two terms.\n        \"\"\"\n        if x is not None:\n            self.x = x\n        t1 = self.term1\n        t2 = self.term2\n        return t1 * t1 + t2 * t2\n\n    return_fn_map = {'f': f}\n\n    @property\n    def terms(self):\n        \"\"\"\n        Returns term1 and term2 together as a 2-element numpy vector.\n        \"\"\"\n        return np.array([self.term1, self.term2])\n\n    def dterms(self):\n        \"\"\"\n        Returns the 2x2 Jacobian for term1 and term2.\n        \"\"\"\n        return np.array([[1.0, 0.0],\n                         [2 * self.local_full_x['x'] / self._sqrtb, -1.0 / self._sqrtb]])\n\n    @property\n    def b(self):\n        return self._sqrtb * self._sqrtb",
  "class TestObject1(Optimizable):\n    \"\"\"\n    Implements a graph based optimizable with a single degree of freedom and has\n    parent optimizable nodes. Mainly used for testing.\n\n    The output method is named `f`. Call hook internally calls method `f`.\n\n    Args:\n        val: Degree of freedom\n        opts: Parent optimizable objects. If not given, two Adder objects are\n              added as parents\n    \"\"\"\n\n    def __init__(self, x0: Real, depends_on: Sequence[Optimizable] = None,\n                 **kwargs):\n        if depends_on is None:\n            depends_on = [Adder(3), Adder(2)]\n        if isinstance(x0, Number):\n            x0 = [x0]\n        if \"names\" not in kwargs:\n            kwargs[\"names\"] = [\"val\"]\n        super().__init__(x0=x0, depends_on=depends_on,\n                         **kwargs)\n\n    def f(self):\n        \"\"\"\n        Implements an objective function\n        \"\"\"\n        return (self.local_full_x[0] + 2 * self.parents[0]()) / \\\n               (10.0 + self.parents[1]())\n\n    return_fn_map = {'f': f}\n\n    def dJ(self):\n        \"\"\"\n        Same as dJ() but a property instead of a function.\n        \"\"\"\n        v = self._dofs.full_x[0]\n        a1 = self.parents[0]()\n        a2 = self.parents[1]()\n        return np.concatenate(\n            (np.array([1.0 / (10.0 + a2)]),\n             np.full(self.parents[0].n, 2.0 / (10.0 + a2)),\n             np.full(self.parents[1].n, -(v + 2 * a1) / ((10.0 + a2) ** 2))))\n\n    @property\n    def depends_on(self):\n        return self.parents",
  "class TestObject2(Optimizable):\n    \"\"\"\n    Implements a graph based optimizable with two single degree of freedom\n    and has two parent optimizable nodes. Mainly used for testing.\n\n    The output method is named `f`. Call hook internally calls method `f`.\n\n    Args:\n        val1: First degree of freedom\n        val2: Second degree of freedom\n    \"\"\"\n\n    def __init__(self, val1, val2):\n        x = [val1, val2]\n        names = ['val1', 'val2']\n        funcs = [TestObject1(0.0), Adder(2)]\n        super().__init__(x0=x, names=names, funcs_in=funcs)\n\n    def f(self):\n        x = self.local_full_x\n        v1 = x[0]\n        v2 = x[1]\n        t = self.parents[0]()\n        a = self.parents[1]()\n        return v1 + a * np.cos(v2 + t)\n\n    return_fn_map = {'f': f}\n\n    def dJ(self):\n        x = self.local_full_x\n        v1 = x[0]\n        v2 = x[1]\n        t = self.parents[0]()\n        a = self.parents[1]()\n        cosat = np.cos(v2 + t)\n        sinat = np.sin(v2 + t)\n        # Order of terms in the gradient: v1, v2, t, a\n        return np.concatenate((np.array([1.0, -a * sinat]),\n                               -a * sinat * self.parents[0].dJ(),\n                               cosat * self.parents[1].dJ()))",
  "class Affine(Optimizable):\n    \"\"\"\n    Implements a random affine (i.e. linear plus constant)\n    transformation from R^n to R^m. The n inputs to the transformation are\n    initially set to zeroes.\n\n    Args:\n        nparams: number of independent variables.\n        nvals: number of dependent variables.\n    \"\"\"\n\n    def __init__(self, nparams, nvals):\n        self.nparams = nparams\n        self.nvals = nvals\n        self.A = (np.random.rand(nvals, nparams) - 0.5) * 4\n        self.B = (np.random.rand(nvals) - 0.5) * 4\n        super().__init__(np.zeros(nparams))\n\n    def f(self):\n        return np.matmul(self.A, self.full_x) + self.B\n\n    return_fn_map = {'f': f}\n\n    def dJ(self):\n        return self.A",
  "class Failer(Optimizable):\n    \"\"\"\n    This class is used for testing failures of the objective\n    function. This function always returns a vector with entries all\n    1.0, except that ObjectiveFailure will be raised on a specified\n    evaluation.\n\n    Args:\n        nparams: Number of input values.\n        nvals: Number of entries in the return vector.\n        fail_index: Which function evaluation to fail on.\n    \"\"\"\n\n    def __init__(self,\n                 nparams: int = 2,\n                 nvals: int = 3,\n                 fail_index: int = 2):\n        self.nparams = nparams\n        self.nvals = nvals\n        self.fail_index = fail_index\n        self.nevals = 0\n        super().__init__(np.zeros(nparams))\n        self.x = np.zeros(self.nparams)\n\n    def J(self):\n        self.nevals += 1\n        if self.nevals == self.fail_index:\n            raise ObjectiveFailure(\"nevals == fail_index\")\n        else:\n            if self.nvals == 0: \n                # return scalar\n                return 1.0\n            else:\n                # return vector\n                return np.full(self.nvals, 1.0)\n\n    def get_dofs(self):\n        return self.x\n\n    def set_dofs(self, x):\n        self.x = x",
  "class Beale(Optimizable):\n    \"\"\"\n    This is a test function which does not supply derivatives. It is\n    taken from\n    https://en.wikipedia.org/wiki/Test_functions_for_optimization\n    \"\"\"\n\n    def __init__(self, x0=None, **kwargs):\n        x = np.zeros(2) if x0 is None else x0\n        super().__init__(x0=x, **kwargs)\n\n    def J(self):\n        x = self.local_full_x[0]\n        y = self.local_full_x[1]\n        return np.array([1.5 - x + x * y,\n                         2.25 - x + x * y * y,\n                         2.625 - x + x * y * y * y])",
  "def __init__(self,\n                 x: Real = 0.0,\n                 dof_name: str = None,\n                 dof_fixed: bool = False):\n        super().__init__([x],\n                         [dof_name] if dof_name is not None else None,\n                         [dof_fixed])",
  "def f(self):\n        \"\"\"\n        Returns the value of the DOF\n        \"\"\"\n        return self.full_x[0]",
  "def dJ(self, x: RealArray = None):\n        if x is not None:\n            if isinstance(x, Real):\n                self.x = [x]\n            else:\n                self.x = x\n        return np.array([1.0])",
  "def as_dict(self, serial_objs_dict: dict) -> dict:\n        d = {}\n        d[\"@class\"] = self.__class__.__name__\n        d[\"@module\"] = self.__class__.__module__\n        d[\"@name\"] = self.name\n        d[\"x\"] = self.local_full_x[0]\n        d[\"dof_name\"] = self.local_full_dof_names[0]\n        d[\"dof_fixed\"] = np.logical_not(self.local_dofs_free_status)[0]\n        return d",
  "def from_dict(cls, d, serial_objs_dict, recon_objs):\n        return cls(d[\"x\"], d[\"dof_name\"], d[\"dof_fixed\"])",
  "def __init__(self, n=3, **kwargs):\n        self.n = n\n        super().__init__(**kwargs)",
  "def sum(self):\n        \"\"\"\n        Sums the DOFs\n        \"\"\"\n        return np.sum(self._dofs.full_x)",
  "def J(self):\n        return self.sum()",
  "def dJ(self):\n        return np.ones(self.n)",
  "def df(self):\n        \"\"\"\n        Same as the function dJ(), but a property instead of a function.\n        \"\"\"\n        return self.dJ()",
  "def __init__(self, b=100.0, x0=[0.0, 0.0], **kwargs):\n        self._sqrtb = np.sqrt(b)\n        if \"names\" not in kwargs:\n            kwargs[\"names\"] = [\"x\", \"y\"]\n        super().__init__(x0=x0, **kwargs)",
  "def term1(self):\n        \"\"\"\n        Returns the first of the two quantities that is squared and summed.\n        \"\"\"\n        return self.local_full_x[0] - 1",
  "def term2(self):\n        \"\"\"\n        Returns the second of the two quantities that is squared and summed.\n        \"\"\"\n        x = self.local_full_x[0]\n        y = self.local_full_x[1]\n        return (x * x - y) / self._sqrtb",
  "def dterm1(self):\n        \"\"\"\n        Returns the gradient of term1\n        \"\"\"\n        return np.array([1.0, 0.0])",
  "def dterm2(self):\n        \"\"\"\n        Returns the gradient of term2\n        \"\"\"\n        return np.array([2 * self.local_full_x[0], -1.0]) / self._sqrtb",
  "def f(self, x=None):\n        \"\"\"\n        Returns the total function, squaring and summing the two terms.\n        \"\"\"\n        if x is not None:\n            self.x = x\n        t1 = self.term1\n        t2 = self.term2\n        return t1 * t1 + t2 * t2",
  "def terms(self):\n        \"\"\"\n        Returns term1 and term2 together as a 2-element numpy vector.\n        \"\"\"\n        return np.array([self.term1, self.term2])",
  "def dterms(self):\n        \"\"\"\n        Returns the 2x2 Jacobian for term1 and term2.\n        \"\"\"\n        return np.array([[1.0, 0.0],\n                         [2 * self.local_full_x['x'] / self._sqrtb, -1.0 / self._sqrtb]])",
  "def b(self):\n        return self._sqrtb * self._sqrtb",
  "def __init__(self, x0: Real, depends_on: Sequence[Optimizable] = None,\n                 **kwargs):\n        if depends_on is None:\n            depends_on = [Adder(3), Adder(2)]\n        if isinstance(x0, Number):\n            x0 = [x0]\n        if \"names\" not in kwargs:\n            kwargs[\"names\"] = [\"val\"]\n        super().__init__(x0=x0, depends_on=depends_on,\n                         **kwargs)",
  "def f(self):\n        \"\"\"\n        Implements an objective function\n        \"\"\"\n        return (self.local_full_x[0] + 2 * self.parents[0]()) / \\\n               (10.0 + self.parents[1]())",
  "def dJ(self):\n        \"\"\"\n        Same as dJ() but a property instead of a function.\n        \"\"\"\n        v = self._dofs.full_x[0]\n        a1 = self.parents[0]()\n        a2 = self.parents[1]()\n        return np.concatenate(\n            (np.array([1.0 / (10.0 + a2)]),\n             np.full(self.parents[0].n, 2.0 / (10.0 + a2)),\n             np.full(self.parents[1].n, -(v + 2 * a1) / ((10.0 + a2) ** 2))))",
  "def depends_on(self):\n        return self.parents",
  "def __init__(self, val1, val2):\n        x = [val1, val2]\n        names = ['val1', 'val2']\n        funcs = [TestObject1(0.0), Adder(2)]\n        super().__init__(x0=x, names=names, funcs_in=funcs)",
  "def f(self):\n        x = self.local_full_x\n        v1 = x[0]\n        v2 = x[1]\n        t = self.parents[0]()\n        a = self.parents[1]()\n        return v1 + a * np.cos(v2 + t)",
  "def dJ(self):\n        x = self.local_full_x\n        v1 = x[0]\n        v2 = x[1]\n        t = self.parents[0]()\n        a = self.parents[1]()\n        cosat = np.cos(v2 + t)\n        sinat = np.sin(v2 + t)\n        # Order of terms in the gradient: v1, v2, t, a\n        return np.concatenate((np.array([1.0, -a * sinat]),\n                               -a * sinat * self.parents[0].dJ(),\n                               cosat * self.parents[1].dJ()))",
  "def __init__(self, nparams, nvals):\n        self.nparams = nparams\n        self.nvals = nvals\n        self.A = (np.random.rand(nvals, nparams) - 0.5) * 4\n        self.B = (np.random.rand(nvals) - 0.5) * 4\n        super().__init__(np.zeros(nparams))",
  "def f(self):\n        return np.matmul(self.A, self.full_x) + self.B",
  "def dJ(self):\n        return self.A",
  "def __init__(self,\n                 nparams: int = 2,\n                 nvals: int = 3,\n                 fail_index: int = 2):\n        self.nparams = nparams\n        self.nvals = nvals\n        self.fail_index = fail_index\n        self.nevals = 0\n        super().__init__(np.zeros(nparams))\n        self.x = np.zeros(self.nparams)",
  "def J(self):\n        self.nevals += 1\n        if self.nevals == self.fail_index:\n            raise ObjectiveFailure(\"nevals == fail_index\")\n        else:\n            if self.nvals == 0: \n                # return scalar\n                return 1.0\n            else:\n                # return vector\n                return np.full(self.nvals, 1.0)",
  "def get_dofs(self):\n        return self.x",
  "def set_dofs(self, x):\n        self.x = x",
  "def __init__(self, x0=None, **kwargs):\n        x = np.zeros(2) if x0 is None else x0\n        super().__init__(x0=x, **kwargs)",
  "def J(self):\n        x = self.local_full_x[0]\n        y = self.local_full_x[1]\n        return np.array([1.5 - x + x * y,\n                         2.25 - x + x * y * y,\n                         2.625 - x + x * y * y * y])",
  "class SquaredFlux(Optimizable):\n\n    r\"\"\"\n    Objective representing quadratic-flux-like quantities, useful for stage-2\n    coil optimization. Several variations are available, which can be selected\n    using the ``definition`` argument. For ``definition=\"quadratic flux\"`` \n    (the default), the objective is defined as\n\n    .. math::\n        J = \\frac12 \\int_{S} (\\mathbf{B}\\cdot \\mathbf{n} - B_T)^2 ds,\n\n    where :math:`\\mathbf{n}` is the surface unit normal vector and\n    :math:`B_T` is an optional (zero by default) target value for the\n    magnetic field. Also :math:`\\int_{S} ds` indicates a surface integral.\n    For ``definition=\"normalized\"``, the objective is defined as\n\n    .. math::\n        J = \\frac12 \\frac{\\int_{S} (\\mathbf{B}\\cdot \\mathbf{n} - B_T)^2 ds}\n                         {\\int_{S} |\\mathbf{B}|^2 ds}.\n\n    For ``definition=\"local\"``, the objective is defined as\n\n    .. math::\n        J = \\frac12 \\int_{S} \\frac{(\\mathbf{B}\\cdot \\mathbf{n} - B_T)^2}{|\\mathbf{B}|^2} ds.\n\n    The definition ``\"quadratic flux\"`` has the advantage of simplicity, and it\n    is used in other contexts such as REGCOIL. However for stage-2 optimization,\n    the optimizer can \"cheat\", lowering this objective by reducing the magnitude\n    of the field. The definitions ``\"normalized\"`` and ``\"local\"`` close this loophole.\n\n    Args:\n        surface: A :obj:`simsopt.geo.surface.Surface` object on which to compute the flux\n        field: A :obj:`simsopt.field.magneticfield.MagneticField` for which to compute the flux.\n        target: A ``nphi x ntheta`` numpy array containing target values for the flux. Here \n          ``nphi`` and ``ntheta`` correspond to the number of quadrature points on `surface` \n          in ``phi`` and ``theta`` direction.\n        definition: A string to select among the definitions above. The\n          available options are ``\"quadratic flux\"``, ``\"normalized\"``, and ``\"local\"``.\n    \"\"\"\n\n    def __init__(self, surface, field, target=None, definition=\"quadratic flux\"):\n        self.surface = surface\n        if target is not None:\n            self.target = np.ascontiguousarray(target)\n        else:\n            self.target = np.zeros(self.surface.normal().shape[:2])\n        self.field = field\n        xyz = self.surface.gamma()\n        self.field.set_points(xyz.reshape((-1, 3)))\n        if definition not in [\"quadratic flux\", \"normalized\", \"local\"]:\n            raise ValueError(\"Unrecognized option for 'definition'.\")\n        self.definition = definition\n        Optimizable.__init__(self, x0=np.asarray([]), depends_on=[field])\n\n    def J(self):\n        n = self.surface.normal()\n        Bcoil = self.field.B().reshape(n.shape)\n        return sopp.integral_BdotN(Bcoil, self.target, n, self.definition)\n\n    @derivative_dec\n    def dJ(self):\n        n = self.surface.normal()\n        absn = np.linalg.norm(n, axis=2)\n        unitn = n * (1. / absn)[:, :, None]\n        Bcoil = self.field.B().reshape(n.shape)\n        Bcoil_n = np.sum(Bcoil * unitn, axis=2)\n        if self.target is not None:\n            B_n = (Bcoil_n - self.target)\n        else:\n            B_n = Bcoil_n\n\n        if self.definition == \"quadratic flux\":\n            dJdB = (B_n[..., None] * unitn * absn[..., None]) / absn.size\n            dJdB = dJdB.reshape((-1, 3))\n\n        elif self.definition == \"local\":\n            mod_Bcoil = np.linalg.norm(Bcoil, axis=2)\n            dJdB = ((\n                (B_n/mod_Bcoil)[..., None] * (\n                    unitn / mod_Bcoil[..., None] - (B_n / mod_Bcoil**3)[..., None] * Bcoil\n                )) * absn[..., None]) / absn.size\n\n        elif self.definition == \"normalized\":\n            mod_Bcoil = np.linalg.norm(Bcoil, axis=2)\n            num = np.mean(B_n**2 * absn)\n            denom = np.mean(mod_Bcoil**2 * absn)\n\n            dnum = 2 * (B_n[..., None] * unitn * absn[..., None]) / absn.size\n            ddenom = 2 * (Bcoil * absn[..., None]) / absn.size\n            dJdB = 0.5 * (dnum / denom - num * ddenom / denom**2)\n\n        else:\n            raise ValueError(\"Should never get here\")\n\n        dJdB = dJdB.reshape((-1, 3))\n        return self.field.B_vjp(dJdB)",
  "def __init__(self, surface, field, target=None, definition=\"quadratic flux\"):\n        self.surface = surface\n        if target is not None:\n            self.target = np.ascontiguousarray(target)\n        else:\n            self.target = np.zeros(self.surface.normal().shape[:2])\n        self.field = field\n        xyz = self.surface.gamma()\n        self.field.set_points(xyz.reshape((-1, 3)))\n        if definition not in [\"quadratic flux\", \"normalized\", \"local\"]:\n            raise ValueError(\"Unrecognized option for 'definition'.\")\n        self.definition = definition\n        Optimizable.__init__(self, x0=np.asarray([]), depends_on=[field])",
  "def J(self):\n        n = self.surface.normal()\n        Bcoil = self.field.B().reshape(n.shape)\n        return sopp.integral_BdotN(Bcoil, self.target, n, self.definition)",
  "def dJ(self):\n        n = self.surface.normal()\n        absn = np.linalg.norm(n, axis=2)\n        unitn = n * (1. / absn)[:, :, None]\n        Bcoil = self.field.B().reshape(n.shape)\n        Bcoil_n = np.sum(Bcoil * unitn, axis=2)\n        if self.target is not None:\n            B_n = (Bcoil_n - self.target)\n        else:\n            B_n = Bcoil_n\n\n        if self.definition == \"quadratic flux\":\n            dJdB = (B_n[..., None] * unitn * absn[..., None]) / absn.size\n            dJdB = dJdB.reshape((-1, 3))\n\n        elif self.definition == \"local\":\n            mod_Bcoil = np.linalg.norm(Bcoil, axis=2)\n            dJdB = ((\n                (B_n/mod_Bcoil)[..., None] * (\n                    unitn / mod_Bcoil[..., None] - (B_n / mod_Bcoil**3)[..., None] * Bcoil\n                )) * absn[..., None]) / absn.size\n\n        elif self.definition == \"normalized\":\n            mod_Bcoil = np.linalg.norm(Bcoil, axis=2)\n            num = np.mean(B_n**2 * absn)\n            denom = np.mean(mod_Bcoil**2 * absn)\n\n            dnum = 2 * (B_n[..., None] * unitn * absn[..., None]) / absn.size\n            ddenom = 2 * (Bcoil * absn[..., None]) / absn.size\n            dJdB = 0.5 * (dnum / denom - num * ddenom / denom**2)\n\n        else:\n            raise ValueError(\"Should never get here\")\n\n        dJdB = dJdB.reshape((-1, 3))\n        return self.field.B_vjp(dJdB)",
  "class BiotSavart(sopp.BiotSavart, MagneticField):\n    r\"\"\"\n    Computes the MagneticField induced by a list of closed curves :math:`\\Gamma_k` with electric currents :math:`I_k`.\n    The field is given by\n\n    .. math::\n\n        B(\\mathbf{x}) = \\frac{\\mu_0}{4\\pi} \\sum_{k=1}^{n_\\mathrm{coils}} I_k \\int_0^1 \\frac{(\\Gamma_k(\\phi)-\\mathbf{x})\\times \\Gamma_k'(\\phi)}{\\|\\Gamma_k(\\phi)-\\mathbf{x}\\|^3} d\\phi\n\n    where :math:`\\mu_0=4\\pi 10^{-7}` is the magnetic constant.\n\n    Args:\n        coils: A list of :obj:`simsopt.field.coil.Coil` objects.\n    \"\"\"\n\n    def __init__(self, coils):\n        self._coils = coils\n        sopp.BiotSavart.__init__(self, coils)\n        MagneticField.__init__(self, depends_on=coils)\n\n    def dB_by_dcoilcurrents(self, compute_derivatives=0):\n        points = self.get_points_cart_ref()\n        npoints = len(points)\n        ncoils = len(self._coils)\n        if any([not self.fieldcache_get_status(f'B_{i}') for i in range(ncoils)]):\n            assert compute_derivatives >= 0\n            self.compute(compute_derivatives)\n        self._dB_by_dcoilcurrents = [self.fieldcache_get_or_create(f'B_{i}', [npoints, 3]) for i in range(ncoils)]\n        return self._dB_by_dcoilcurrents\n\n    def d2B_by_dXdcoilcurrents(self, compute_derivatives=1):\n        points = self.get_points_cart_ref()\n        npoints = len(points)\n        ncoils = len(self._coils)\n        if any([not self.fieldcache_get_status(f'dB_{i}') for i in range(ncoils)]):\n            assert compute_derivatives >= 1\n            self.compute(compute_derivatives)\n        self._d2B_by_dXdcoilcurrents = [self.fieldcache_get_or_create(f'dB_{i}', [npoints, 3, 3]) for i in range(ncoils)]\n        return self._d2B_by_dXdcoilcurrents\n\n    def d3B_by_dXdXdcoilcurrents(self, compute_derivatives=2):\n        points = self.get_points_cart_ref()\n        npoints = len(points)\n        ncoils = len(self._coils)\n        if any([not self.fieldcache_get_status(f'ddB_{i}') for i in range(ncoils)]):\n            assert compute_derivatives >= 2\n            self.compute(compute_derivatives)\n        self._d3B_by_dXdXdcoilcurrents = [self.fieldcache_get_or_create(f'ddB_{i}', [npoints, 3, 3, 3]) for i in range(ncoils)]\n        return self._d3B_by_dXdXdcoilcurrents\n\n    def B_and_dB_vjp(self, v, vgrad):\n        r\"\"\"\n        Same as :obj:`simsopt.geo.biotsavart.BiotSavart.B_vjp` but returns the vector Jacobian product for :math:`B` and :math:`\\nabla B`, i.e. it returns\n\n        .. math::\n\n            \\{ \\sum_{i=1}^{n} \\mathbf{v}_i \\cdot \\partial_{\\mathbf{c}_k} \\mathbf{B}_i \\}_k, \\{ \\sum_{i=1}^{n} {\\mathbf{v}_\\mathrm{grad}}_i \\cdot \\partial_{\\mathbf{c}_k} \\nabla \\mathbf{B}_i \\}_k.\n        \"\"\"\n\n        coils = self._coils\n        gammas = [coil.curve.gamma() for coil in coils]\n        gammadashs = [coil.curve.gammadash() for coil in coils]\n        currents = [coil.current.get_value() for coil in coils]\n        res_gamma = [np.zeros_like(gamma) for gamma in gammas]\n        res_gammadash = [np.zeros_like(gammadash) for gammadash in gammadashs]\n        res_grad_gamma = [np.zeros_like(gamma) for gamma in gammas]\n        res_grad_gammadash = [np.zeros_like(gammadash) for gammadash in gammadashs]\n\n        points = self.get_points_cart_ref()\n        sopp.biot_savart_vjp_graph(points, gammas, gammadashs, currents, v,\n                                   res_gamma, res_gammadash, vgrad, res_grad_gamma, res_grad_gammadash)\n\n        dB_by_dcoilcurrents = self.dB_by_dcoilcurrents()\n        res_current = [np.sum(v * dB_by_dcoilcurrents[i]) for i in range(len(dB_by_dcoilcurrents))]\n        d2B_by_dXdcoilcurrents = self.d2B_by_dXdcoilcurrents()\n        res_grad_current = [np.sum(vgrad * d2B_by_dXdcoilcurrents[i]) for i in range(len(d2B_by_dXdcoilcurrents))]\n\n        res = (\n            sum([coils[i].vjp(res_gamma[i], res_gammadash[i], np.asarray([res_current[i]])) for i in range(len(coils))]),\n            sum([coils[i].vjp(res_grad_gamma[i], res_grad_gammadash[i], np.asarray([res_grad_current[i]])) for i in range(len(coils))])\n        )\n\n        return res\n\n    def B_vjp(self, v):\n        r\"\"\"\n        Assume the field was evaluated at points :math:`\\mathbf{x}_i, i\\in \\{1, \\ldots, n\\}` and denote the value of the field at those points by\n        :math:`\\{\\mathbf{B}_i\\}_{i=1}^n`.\n        These values depend on the shape of the coils, i.e. on the dofs :math:`\\mathbf{c}_k` of each coil.\n        This function returns the vector Jacobian product of this dependency, i.e.\n\n        .. math::\n\n            \\{ \\sum_{i=1}^{n} \\mathbf{v}_i \\cdot \\partial_{\\mathbf{c}_k} \\mathbf{B}_i \\}_k.\n\n        \"\"\"\n\n        coils = self._coils\n        gammas = [coil.curve.gamma() for coil in coils]\n        gammadashs = [coil.curve.gammadash() for coil in coils]\n        currents = [coil.current.get_value() for coil in coils]\n        res_gamma = [np.zeros_like(gamma) for gamma in gammas]\n        res_gammadash = [np.zeros_like(gammadash) for gammadash in gammadashs]\n\n        points = self.get_points_cart_ref()\n        sopp.biot_savart_vjp_graph(points, gammas, gammadashs, currents, v,\n                                   res_gamma, res_gammadash, [], [], [])\n        dB_by_dcoilcurrents = self.dB_by_dcoilcurrents()\n        res_current = [np.sum(v * dB_by_dcoilcurrents[i]) for i in range(len(dB_by_dcoilcurrents))]\n        return sum([coils[i].vjp(res_gamma[i], res_gammadash[i], np.asarray([res_current[i]])) for i in range(len(coils))])\n\n    def dA_by_dcoilcurrents(self, compute_derivatives=0):\n        points = self.get_points_cart_ref()\n        npoints = len(points)\n        ncoils = len(self._coils)\n        if any([not self.fieldcache_get_status(f'A_{i}') for i in range(ncoils)]):\n            assert compute_derivatives >= 0\n            self.compute(compute_derivatives)\n        self._dA_by_dcoilcurrents = [self.fieldcache_get_or_create(f'A_{i}', [npoints, 3]) for i in range(ncoils)]\n        return self._dA_by_dcoilcurrents\n\n    def d2A_by_dXdcoilcurrents(self, compute_derivatives=1):\n        points = self.get_points_cart_ref()\n        npoints = len(points)\n        ncoils = len(self._coils)\n        if any([not self.fieldcache_get_status(f'dA_{i}') for i in range(ncoils)]):\n            assert compute_derivatives >= 1\n            self.compute(compute_derivatives)\n        self._d2A_by_dXdcoilcurrents = [self.fieldcache_get_or_create(f'dA_{i}', [npoints, 3, 3]) for i in range(ncoils)]\n        return self._d2A_by_dXdcoilcurrents\n\n    def d3A_by_dXdXdcoilcurrents(self, compute_derivatives=2):\n        points = self.get_points_cart_ref()\n        npoints = len(points)\n        ncoils = len(self._coils)\n        if any([not self.fieldcache_get_status(f'ddA_{i}') for i in range(ncoils)]):\n            assert compute_derivatives >= 2\n            self.compute(compute_derivatives)\n        self._d3A_by_dXdXdcoilcurrents = [self.fieldcache_get_or_create(f'ddA_{i}', [npoints, 3, 3, 3]) for i in range(ncoils)]\n        return self._d3A_by_dXdXdcoilcurrents\n\n    def A_and_dA_vjp(self, v, vgrad):\n        r\"\"\"\n        Same as :obj:`simsopt.geo.biotsavart.BiotSavart.A_vjp` but returns the vector Jacobian product for :math:`A` and :math:`\\nabla A`, i.e. it returns\n\n        .. math::\n\n            \\{ \\sum_{i=1}^{n} \\mathbf{v}_i \\cdot \\partial_{\\mathbf{c}_k} \\mathbf{A}_i \\}_k, \\{ \\sum_{i=1}^{n} {\\mathbf{v}_\\mathrm{grad}}_i \\cdot \\partial_{\\mathbf{c}_k} \\nabla \\mathbf{A}_i \\}_k.\n        \"\"\"\n\n        coils = self._coils\n        gammas = [coil.curve.gamma() for coil in coils]\n        gammadashs = [coil.curve.gammadash() for coil in coils]\n        currents = [coil.current.get_value() for coil in coils]\n        res_gamma = [np.zeros_like(gamma) for gamma in gammas]\n        res_gammadash = [np.zeros_like(gammadash) for gammadash in gammadashs]\n        res_grad_gamma = [np.zeros_like(gamma) for gamma in gammas]\n        res_grad_gammadash = [np.zeros_like(gammadash) for gammadash in gammadashs]\n\n        points = self.get_points_cart_ref()\n        sopp.biot_savart_vector_potential_vjp_graph(points, gammas, gammadashs, currents, v,\n                                                    res_gamma, res_gammadash, vgrad, res_grad_gamma, res_grad_gammadash)\n\n        dA_by_dcoilcurrents = self.dA_by_dcoilcurrents()\n        res_current = [np.sum(v * dA_by_dcoilcurrents[i]) for i in range(len(dA_by_dcoilcurrents))]\n        d2A_by_dXdcoilcurrents = self.d2A_by_dXdcoilcurrents()\n        res_grad_current = [np.sum(vgrad * d2A_by_dXdcoilcurrents[i]) for i in range(len(d2A_by_dXdcoilcurrents))]\n\n        res = (\n            sum([coils[i].vjp(res_gamma[i], res_gammadash[i], np.asarray([res_current[i]])) for i in range(len(coils))]),\n            sum([coils[i].vjp(res_grad_gamma[i], res_grad_gammadash[i], np.asarray([res_grad_current[i]])) for i in range(len(coils))])\n        )\n\n        return res\n\n    def A_vjp(self, v):\n        r\"\"\"\n        Assume the field was evaluated at points :math:`\\mathbf{x}_i, i\\in \\{1, \\ldots, n\\}` and denote the value of the field at those points by\n        :math:`\\{\\mathbf{A}_i\\}_{i=1}^n`.\n        These values depend on the shape of the coils, i.e. on the dofs :math:`\\mathbf{c}_k` of each coil.\n        This function returns the vector Jacobian product of this dependency, i.e.\n\n        .. math::\n\n            \\{ \\sum_{i=1}^{n} \\mathbf{v}_i \\cdot \\partial_{\\mathbf{c}_k} \\mathbf{A}_i \\}_k.\n\n        \"\"\"\n\n        coils = self._coils\n        gammas = [coil.curve.gamma() for coil in coils]\n        gammadashs = [coil.curve.gammadash() for coil in coils]\n        currents = [coil.current.get_value() for coil in coils]\n        res_gamma = [np.zeros_like(gamma) for gamma in gammas]\n        res_gammadash = [np.zeros_like(gammadash) for gammadash in gammadashs]\n\n        points = self.get_points_cart_ref()\n        sopp.biot_savart_vector_potential_vjp_graph(points, gammas, gammadashs, currents, v,\n                                                    res_gamma, res_gammadash, [], [], [])\n        dA_by_dcoilcurrents = self.dA_by_dcoilcurrents()\n        res_current = [np.sum(v * dA_by_dcoilcurrents[i]) for i in range(len(dA_by_dcoilcurrents))]\n        return sum([coils[i].vjp(res_gamma[i], res_gammadash[i], np.asarray([res_current[i]])) for i in range(len(coils))])\n\n    def as_dict(self, serial_objs_dict) -> dict:\n        d = super().as_dict(serial_objs_dict=serial_objs_dict)\n        d[\"points\"] = self.get_points_cart()\n        return d\n\n    @classmethod\n    def from_dict(cls, d, serial_objs_dict, recon_objs):\n        decoder = GSONDecoder()\n        xyz = decoder.process_decoded(d[\"points\"],\n                                      serial_objs_dict=serial_objs_dict,\n                                      recon_objs=recon_objs)\n        coils = decoder.process_decoded(d[\"coils\"],\n                                        serial_objs_dict=serial_objs_dict,\n                                        recon_objs=recon_objs)\n        bs = cls(coils)\n        bs.set_points_cart(xyz)\n        return bs",
  "def __init__(self, coils):\n        self._coils = coils\n        sopp.BiotSavart.__init__(self, coils)\n        MagneticField.__init__(self, depends_on=coils)",
  "def dB_by_dcoilcurrents(self, compute_derivatives=0):\n        points = self.get_points_cart_ref()\n        npoints = len(points)\n        ncoils = len(self._coils)\n        if any([not self.fieldcache_get_status(f'B_{i}') for i in range(ncoils)]):\n            assert compute_derivatives >= 0\n            self.compute(compute_derivatives)\n        self._dB_by_dcoilcurrents = [self.fieldcache_get_or_create(f'B_{i}', [npoints, 3]) for i in range(ncoils)]\n        return self._dB_by_dcoilcurrents",
  "def d2B_by_dXdcoilcurrents(self, compute_derivatives=1):\n        points = self.get_points_cart_ref()\n        npoints = len(points)\n        ncoils = len(self._coils)\n        if any([not self.fieldcache_get_status(f'dB_{i}') for i in range(ncoils)]):\n            assert compute_derivatives >= 1\n            self.compute(compute_derivatives)\n        self._d2B_by_dXdcoilcurrents = [self.fieldcache_get_or_create(f'dB_{i}', [npoints, 3, 3]) for i in range(ncoils)]\n        return self._d2B_by_dXdcoilcurrents",
  "def d3B_by_dXdXdcoilcurrents(self, compute_derivatives=2):\n        points = self.get_points_cart_ref()\n        npoints = len(points)\n        ncoils = len(self._coils)\n        if any([not self.fieldcache_get_status(f'ddB_{i}') for i in range(ncoils)]):\n            assert compute_derivatives >= 2\n            self.compute(compute_derivatives)\n        self._d3B_by_dXdXdcoilcurrents = [self.fieldcache_get_or_create(f'ddB_{i}', [npoints, 3, 3, 3]) for i in range(ncoils)]\n        return self._d3B_by_dXdXdcoilcurrents",
  "def B_and_dB_vjp(self, v, vgrad):\n        r\"\"\"\n        Same as :obj:`simsopt.geo.biotsavart.BiotSavart.B_vjp` but returns the vector Jacobian product for :math:`B` and :math:`\\nabla B`, i.e. it returns\n\n        .. math::\n\n            \\{ \\sum_{i=1}^{n} \\mathbf{v}_i \\cdot \\partial_{\\mathbf{c}_k} \\mathbf{B}_i \\}_k, \\{ \\sum_{i=1}^{n} {\\mathbf{v}_\\mathrm{grad}}_i \\cdot \\partial_{\\mathbf{c}_k} \\nabla \\mathbf{B}_i \\}_k.\n        \"\"\"\n\n        coils = self._coils\n        gammas = [coil.curve.gamma() for coil in coils]\n        gammadashs = [coil.curve.gammadash() for coil in coils]\n        currents = [coil.current.get_value() for coil in coils]\n        res_gamma = [np.zeros_like(gamma) for gamma in gammas]\n        res_gammadash = [np.zeros_like(gammadash) for gammadash in gammadashs]\n        res_grad_gamma = [np.zeros_like(gamma) for gamma in gammas]\n        res_grad_gammadash = [np.zeros_like(gammadash) for gammadash in gammadashs]\n\n        points = self.get_points_cart_ref()\n        sopp.biot_savart_vjp_graph(points, gammas, gammadashs, currents, v,\n                                   res_gamma, res_gammadash, vgrad, res_grad_gamma, res_grad_gammadash)\n\n        dB_by_dcoilcurrents = self.dB_by_dcoilcurrents()\n        res_current = [np.sum(v * dB_by_dcoilcurrents[i]) for i in range(len(dB_by_dcoilcurrents))]\n        d2B_by_dXdcoilcurrents = self.d2B_by_dXdcoilcurrents()\n        res_grad_current = [np.sum(vgrad * d2B_by_dXdcoilcurrents[i]) for i in range(len(d2B_by_dXdcoilcurrents))]\n\n        res = (\n            sum([coils[i].vjp(res_gamma[i], res_gammadash[i], np.asarray([res_current[i]])) for i in range(len(coils))]),\n            sum([coils[i].vjp(res_grad_gamma[i], res_grad_gammadash[i], np.asarray([res_grad_current[i]])) for i in range(len(coils))])\n        )\n\n        return res",
  "def B_vjp(self, v):\n        r\"\"\"\n        Assume the field was evaluated at points :math:`\\mathbf{x}_i, i\\in \\{1, \\ldots, n\\}` and denote the value of the field at those points by\n        :math:`\\{\\mathbf{B}_i\\}_{i=1}^n`.\n        These values depend on the shape of the coils, i.e. on the dofs :math:`\\mathbf{c}_k` of each coil.\n        This function returns the vector Jacobian product of this dependency, i.e.\n\n        .. math::\n\n            \\{ \\sum_{i=1}^{n} \\mathbf{v}_i \\cdot \\partial_{\\mathbf{c}_k} \\mathbf{B}_i \\}_k.\n\n        \"\"\"\n\n        coils = self._coils\n        gammas = [coil.curve.gamma() for coil in coils]\n        gammadashs = [coil.curve.gammadash() for coil in coils]\n        currents = [coil.current.get_value() for coil in coils]\n        res_gamma = [np.zeros_like(gamma) for gamma in gammas]\n        res_gammadash = [np.zeros_like(gammadash) for gammadash in gammadashs]\n\n        points = self.get_points_cart_ref()\n        sopp.biot_savart_vjp_graph(points, gammas, gammadashs, currents, v,\n                                   res_gamma, res_gammadash, [], [], [])\n        dB_by_dcoilcurrents = self.dB_by_dcoilcurrents()\n        res_current = [np.sum(v * dB_by_dcoilcurrents[i]) for i in range(len(dB_by_dcoilcurrents))]\n        return sum([coils[i].vjp(res_gamma[i], res_gammadash[i], np.asarray([res_current[i]])) for i in range(len(coils))])",
  "def dA_by_dcoilcurrents(self, compute_derivatives=0):\n        points = self.get_points_cart_ref()\n        npoints = len(points)\n        ncoils = len(self._coils)\n        if any([not self.fieldcache_get_status(f'A_{i}') for i in range(ncoils)]):\n            assert compute_derivatives >= 0\n            self.compute(compute_derivatives)\n        self._dA_by_dcoilcurrents = [self.fieldcache_get_or_create(f'A_{i}', [npoints, 3]) for i in range(ncoils)]\n        return self._dA_by_dcoilcurrents",
  "def d2A_by_dXdcoilcurrents(self, compute_derivatives=1):\n        points = self.get_points_cart_ref()\n        npoints = len(points)\n        ncoils = len(self._coils)\n        if any([not self.fieldcache_get_status(f'dA_{i}') for i in range(ncoils)]):\n            assert compute_derivatives >= 1\n            self.compute(compute_derivatives)\n        self._d2A_by_dXdcoilcurrents = [self.fieldcache_get_or_create(f'dA_{i}', [npoints, 3, 3]) for i in range(ncoils)]\n        return self._d2A_by_dXdcoilcurrents",
  "def d3A_by_dXdXdcoilcurrents(self, compute_derivatives=2):\n        points = self.get_points_cart_ref()\n        npoints = len(points)\n        ncoils = len(self._coils)\n        if any([not self.fieldcache_get_status(f'ddA_{i}') for i in range(ncoils)]):\n            assert compute_derivatives >= 2\n            self.compute(compute_derivatives)\n        self._d3A_by_dXdXdcoilcurrents = [self.fieldcache_get_or_create(f'ddA_{i}', [npoints, 3, 3, 3]) for i in range(ncoils)]\n        return self._d3A_by_dXdXdcoilcurrents",
  "def A_and_dA_vjp(self, v, vgrad):\n        r\"\"\"\n        Same as :obj:`simsopt.geo.biotsavart.BiotSavart.A_vjp` but returns the vector Jacobian product for :math:`A` and :math:`\\nabla A`, i.e. it returns\n\n        .. math::\n\n            \\{ \\sum_{i=1}^{n} \\mathbf{v}_i \\cdot \\partial_{\\mathbf{c}_k} \\mathbf{A}_i \\}_k, \\{ \\sum_{i=1}^{n} {\\mathbf{v}_\\mathrm{grad}}_i \\cdot \\partial_{\\mathbf{c}_k} \\nabla \\mathbf{A}_i \\}_k.\n        \"\"\"\n\n        coils = self._coils\n        gammas = [coil.curve.gamma() for coil in coils]\n        gammadashs = [coil.curve.gammadash() for coil in coils]\n        currents = [coil.current.get_value() for coil in coils]\n        res_gamma = [np.zeros_like(gamma) for gamma in gammas]\n        res_gammadash = [np.zeros_like(gammadash) for gammadash in gammadashs]\n        res_grad_gamma = [np.zeros_like(gamma) for gamma in gammas]\n        res_grad_gammadash = [np.zeros_like(gammadash) for gammadash in gammadashs]\n\n        points = self.get_points_cart_ref()\n        sopp.biot_savart_vector_potential_vjp_graph(points, gammas, gammadashs, currents, v,\n                                                    res_gamma, res_gammadash, vgrad, res_grad_gamma, res_grad_gammadash)\n\n        dA_by_dcoilcurrents = self.dA_by_dcoilcurrents()\n        res_current = [np.sum(v * dA_by_dcoilcurrents[i]) for i in range(len(dA_by_dcoilcurrents))]\n        d2A_by_dXdcoilcurrents = self.d2A_by_dXdcoilcurrents()\n        res_grad_current = [np.sum(vgrad * d2A_by_dXdcoilcurrents[i]) for i in range(len(d2A_by_dXdcoilcurrents))]\n\n        res = (\n            sum([coils[i].vjp(res_gamma[i], res_gammadash[i], np.asarray([res_current[i]])) for i in range(len(coils))]),\n            sum([coils[i].vjp(res_grad_gamma[i], res_grad_gammadash[i], np.asarray([res_grad_current[i]])) for i in range(len(coils))])\n        )\n\n        return res",
  "def A_vjp(self, v):\n        r\"\"\"\n        Assume the field was evaluated at points :math:`\\mathbf{x}_i, i\\in \\{1, \\ldots, n\\}` and denote the value of the field at those points by\n        :math:`\\{\\mathbf{A}_i\\}_{i=1}^n`.\n        These values depend on the shape of the coils, i.e. on the dofs :math:`\\mathbf{c}_k` of each coil.\n        This function returns the vector Jacobian product of this dependency, i.e.\n\n        .. math::\n\n            \\{ \\sum_{i=1}^{n} \\mathbf{v}_i \\cdot \\partial_{\\mathbf{c}_k} \\mathbf{A}_i \\}_k.\n\n        \"\"\"\n\n        coils = self._coils\n        gammas = [coil.curve.gamma() for coil in coils]\n        gammadashs = [coil.curve.gammadash() for coil in coils]\n        currents = [coil.current.get_value() for coil in coils]\n        res_gamma = [np.zeros_like(gamma) for gamma in gammas]\n        res_gammadash = [np.zeros_like(gammadash) for gammadash in gammadashs]\n\n        points = self.get_points_cart_ref()\n        sopp.biot_savart_vector_potential_vjp_graph(points, gammas, gammadashs, currents, v,\n                                                    res_gamma, res_gammadash, [], [], [])\n        dA_by_dcoilcurrents = self.dA_by_dcoilcurrents()\n        res_current = [np.sum(v * dA_by_dcoilcurrents[i]) for i in range(len(dA_by_dcoilcurrents))]\n        return sum([coils[i].vjp(res_gamma[i], res_gammadash[i], np.asarray([res_current[i]])) for i in range(len(coils))])",
  "def as_dict(self, serial_objs_dict) -> dict:\n        d = super().as_dict(serial_objs_dict=serial_objs_dict)\n        d[\"points\"] = self.get_points_cart()\n        return d",
  "def from_dict(cls, d, serial_objs_dict, recon_objs):\n        decoder = GSONDecoder()\n        xyz = decoder.process_decoded(d[\"points\"],\n                                      serial_objs_dict=serial_objs_dict,\n                                      recon_objs=recon_objs)\n        coils = decoder.process_decoded(d[\"coils\"],\n                                        serial_objs_dict=serial_objs_dict,\n                                        recon_objs=recon_objs)\n        bs = cls(coils)\n        bs.set_points_cart(xyz)\n        return bs",
  "class ToroidalField(MagneticField):\n    \"\"\"\n    Magnetic field purely in the toroidal direction, that is, in the phi\n    direction with (R,phi,Z) the standard cylindrical coordinates.\n    Its modulus is given by B = B0*R0/R where R0 is the first input and B0 the second input to the function.\n\n    Args:\n        B0:  modulus of the magnetic field at R0\n        R0:  radius of normalization\n    \"\"\"\n\n    def __init__(self, R0, B0):\n        MagneticField.__init__(self)\n        self.R0 = R0\n        self.B0 = B0\n\n    def _B_impl(self, B):\n        points = self.get_points_cart_ref()\n        phi = np.arctan2(points[:, 1], points[:, 0])\n        R = np.sqrt(np.square(points[:, 0]) + np.square(points[:, 1]))\n        phiUnitVectorOverR = np.vstack((np.divide(-np.sin(phi), R), np.divide(np.cos(phi), R), np.zeros(len(phi)))).T\n        B[:] = np.multiply(self.B0*self.R0, phiUnitVectorOverR)\n\n    def _dB_by_dX_impl(self, dB):\n        points = self.get_points_cart_ref()\n        phi = np.arctan2(points[:, 1], points[:, 0])\n        R = np.sqrt(np.square(points[:, 0]) + np.square(points[:, 1]))\n\n        x = points[:, 0]\n        y = points[:, 1]\n\n        dB_by_dX1 = np.vstack((\n            np.multiply(np.divide(self.B0*self.R0, R**4), 2*np.multiply(x, y)),\n            np.multiply(np.divide(self.B0*self.R0, R**4), y**2-x**2),\n            0*R))\n        dB_by_dX2 = np.vstack((\n            np.multiply(np.divide(self.B0*self.R0, R**4), y**2-x**2),\n            np.multiply(np.divide(self.B0*self.R0, R**4), -2*np.multiply(x, y)),\n            0*R))\n        dB_by_dX3 = np.vstack((0*R, 0*R, 0*R))\n\n        dB[:] = np.array([dB_by_dX1, dB_by_dX2, dB_by_dX3]).T\n\n    def _d2B_by_dXdX_impl(self, ddB):\n        points = self.get_points_cart_ref()\n        x = points[:, 0]\n        y = points[:, 1]\n        ddB[:] = 2*self.B0*self.R0*np.multiply(\n            1/(points[:, 0]**2+points[:, 1]**2)**3, np.array([\n                [[3*points[:, 0]**2+points[:, 1]**3, points[:, 0]**3-3*points[:, 0]*points[:, 1]**2, np.zeros((len(points)))], [\n                    points[:, 0]**3-3*points[:, 0]*points[:, 1]**2, 3*points[:, 0]**2*points[:, 1]-points[:, 1]**3,\n                    np.zeros((len(points)))],\n                 np.zeros((3, len(points)))],\n                [[points[:, 0]**3-3*points[:, 0]*points[:, 1]**2, 3*points[:, 0]**2*points[:, 1]-points[:, 1]**3,\n                  np.zeros((len(points)))],\n                 [3*points[:, 0]**2*points[:, 1]-points[:, 1]**3, -points[:, 0]**3+3*points[:, 0]*points[:, 1]**2,\n                  np.zeros((len(points)))], np.zeros((3, len(points)))],\n                np.zeros((3, 3, len(points)))])).T\n\n    def _A_impl(self, A):\n        points = self.get_points_cart_ref()\n        A[:] = self.B0*self.R0*np.array([\n            points[:, 2]*points[:, 0]/(points[:, 0]**2+points[:, 1]**2),\n            points[:, 2]*points[:, 1]/(points[:, 0]**2+points[:, 1]**2),\n            0*points[:, 2]]).T\n\n    def _dA_by_dX_impl(self, dA):\n        points = self.get_points_cart_ref()\n        dA[:] = self.B0*self.R0*np.array((points[:, 2]/(points[:, 0]**2+points[:, 1]**2)**2)*np.array(\n            [[-points[:, 0]**2+points[:, 1]**2, -2*points[:, 0]*points[:, 1], np.zeros((len(points)))],\n             [-2*points[:, 0]*points[:, 1], points[:, 0]**2-points[:, 1]**2, np.zeros((len(points)))],\n             [points[:, 0]*(points[:, 0]**2+points[:, 1]**2)/points[:, 2],\n              points[:, 1]*(points[:, 0]**2+points[:, 1]**2)/points[:, 2], np.zeros((len(points)))]])).T\n\n    def _d2A_by_dXdX_impl(self, ddA):\n        points = self.get_points_cart_ref()\n        ddA[:] = 2*self.B0*self.R0*np.array(\n            (points[:, 2]/(points[:, 0]**2+points[:, 1]**2)**3)*np.array([\n                [[points[:, 0]**3-3*points[:, 0]*points[:, 1]**2, 3*points[:, 0]**2*points[:, 1]-points[:, 1]**3,\n                  (-points[:, 0]**4+points[:, 1]**4)/(2*points[:, 2])],\n                 [3*points[:, 0]**2*points[:, 1]-points[:, 1]**3, -points[:, 0]**3+3*points[:, 0]*points[:, 1]**2, -points[:, 0]*points[:, 1]*(\n                     points[:, 0]**2+points[:, 1]**2)/points[:, 2]],\n                 [(-points[:, 0]**4+points[:, 1]**4)/(2*points[:, 2]),\n                  -points[:, 0]*points[:, 1]*(points[:, 0]**2+points[:, 1]**2)/points[:, 2],\n                  np.zeros((len(points)))]],\n                [[3*points[:, 0]**2*points[:, 1]-points[:, 1]**3, -points[:, 0]**3+3*points[:, 0]*points[:, 1]**2,\n                  -points[:, 0]*points[:, 1]*(points[:, 0]**2+points[:, 1]**2)/points[:, 2]],\n                 [-points[:, 0]**3+3*points[:, 0]*points[:, 1]**2, -3*points[:, 0]**2*points[:, 1]+points[:, 1]**3, (\n                     points[:, 0]**4-points[:, 1]**4)/(2*points[:, 2])],\n                 [-points[:, 0]*points[:, 1]*(points[:, 0]**2+points[:, 1]**2)/points[:, 2],\n                  (points[:, 0]**4-points[:, 1]**4)/(2*points[:, 2]), np.zeros((len(points)))]],\n                np.zeros((3, 3, len(points)))])).transpose((3, 0, 1, 2))\n\n    def as_dict(self, serial_objs_dict) -> dict:\n        d = super().as_dict(serial_objs_dict=serial_objs_dict)\n        d[\"points\"] = self.get_points_cart()\n        return d\n\n    @classmethod\n    def from_dict(cls, d, serial_objs_dict, recon_objs):\n        field = cls(d[\"R0\"], d[\"B0\"])\n        decoder = GSONDecoder()\n        xyz = decoder.process_decoded(d[\"points\"], serial_objs_dict, recon_objs)\n        field.set_points_cart(xyz)\n        return field",
  "class PoloidalField(MagneticField):\n    '''\n    Magnetic field purely in the poloidal direction, that is, in the\n    theta direction of a poloidal-toroidal coordinate system.  Its\n    modulus is given by B = B0 * r / (R0 * q) so that, together with\n    the toroidal field, it creates a safety factor equals to q\n\n    Args:\n        B0: modulus of the magnetic field at R0\n        R0: major radius of the magnetic axis\n        q: safety factor/pitch angle of the magnetic field lines\n    '''\n\n    def __init__(self, R0, B0, q):\n        MagneticField.__init__(self)\n        self.R0 = R0\n        self.B0 = B0\n        self.q = q\n\n    def _B_impl(self, B):\n        points = self.get_points_cart_ref()\n\n        x = points[:, 0]\n        y = points[:, 1]\n        z = points[:, 2]\n\n        phi = np.arctan2(y, x)\n        theta = np.arctan2(z, np.sqrt(x**2+y**2)-self.R0)\n        r = np.sqrt((np.sqrt(x**2+y**2)-self.R0)**2+z**2)\n        thetaUnitVectorOver_times_r = np.vstack((-np.multiply(np.sin(theta), r)*np.cos(phi), -np.multiply(np.sin(theta), r)*np.sin(phi), np.multiply(np.cos(theta), r))).T\n        B[:] = self.B0/self.R0/self.q*thetaUnitVectorOver_times_r\n\n    def _dB_by_dX_impl(self, dB):\n        points = self.get_points_cart_ref()\n\n        x = points[:, 0]\n        y = points[:, 1]\n        z = points[:, 2]\n\n        phi = np.arctan2(y, x)\n        theta = np.arctan2(z, np.sqrt(x**2+y**2)-self.R0)\n        r = np.sqrt((np.sqrt(x**2+y**2)-self.R0)**2+z**2)\n\n        dtheta_by_dX1 = -((x*z)/(np.sqrt(x**2+y**2)*(x**2+y**2+z**2-2*np.sqrt(x**2+y**2)*self.R0+(self.R0)**2)))\n        dtheta_by_dX2 = -((y*z)/(np.sqrt(x**2+y**2)*(x**2+y**2+z**2-2*np.sqrt(x**2+y**2)*self.R0+(self.R0)**2)))\n        dtheta_by_dX3 = 1/((-self.R0+np.sqrt(x**2+y**2))*(1+z**2/(self.R0-np.sqrt(x**2+y**2))**2))\n\n        dphi_by_dX1 = -(y/(x**2 + y**2))\n        dphi_by_dX2 = x/(x**2 + y**2)\n        dphi_by_dX3 = 0.*z\n\n        dthetaunitvector_by_dX1 = np.vstack((\n            -np.cos(theta)*np.cos(phi)*dtheta_by_dX1+np.sin(theta)*np.sin(phi)*dphi_by_dX1,\n            -np.cos(theta)*np.sin(phi)*dtheta_by_dX1-np.sin(theta)*np.cos(phi)*dphi_by_dX1,\n            -np.sin(theta)*dtheta_by_dX1\n        )).T\n        dthetaunitvector_by_dX2 = np.vstack((\n            -np.cos(theta)*np.cos(phi)*dtheta_by_dX2+np.sin(theta)*np.sin(phi)*dphi_by_dX2,\n            -np.cos(theta)*np.sin(phi)*dtheta_by_dX2-np.sin(theta)*np.cos(phi)*dphi_by_dX2,\n            -np.sin(theta)*dtheta_by_dX2\n        )).T\n        dthetaunitvector_by_dX3 = np.vstack((\n            -np.cos(theta)*np.cos(phi)*dtheta_by_dX3+np.sin(theta)*np.sin(phi)*dphi_by_dX3,\n            -np.cos(theta)*np.sin(phi)*dtheta_by_dX3-np.sin(theta)*np.cos(phi)*dphi_by_dX3,\n            -np.sin(theta)*dtheta_by_dX3\n        )).T\n\n        dB_by_dX1_term1 = np.multiply(dthetaunitvector_by_dX1.T, r)\n        dB_by_dX2_term1 = np.multiply(dthetaunitvector_by_dX2.T, r)\n        dB_by_dX3_term1 = np.multiply(dthetaunitvector_by_dX3.T, r)\n\n        thetaUnitVector_1 = -np.sin(theta)*np.cos(phi)\n        thetaUnitVector_2 = -np.sin(theta)*np.sin(phi)\n        thetaUnitVector_3 = np.cos(theta)\n\n        dr_by_dX1 = (x*(-self.R0+np.sqrt(x**2+y**2)))/(np.sqrt(x**2+y**2)*np.sqrt((self.R0-np.sqrt(x**2+y**2))**2+z**2))\n        dr_by_dX2 = (y*(-self.R0+np.sqrt(x**2+y**2)))/(np.sqrt(x**2+y**2)*np.sqrt((self.R0-np.sqrt(x**2+y**2))**2+z**2))\n        dr_by_dX3 = z/np.sqrt((self.R0-np.sqrt(x**2+y**2))**2+z**2)\n\n        dB_by_dX1_term2 = np.vstack((\n            thetaUnitVector_1*dr_by_dX1,\n            thetaUnitVector_2*dr_by_dX1,\n            thetaUnitVector_3*dr_by_dX1))\n        dB_by_dX2_term2 = np.vstack((\n            thetaUnitVector_1*dr_by_dX2,\n            thetaUnitVector_2*dr_by_dX2,\n            thetaUnitVector_3*dr_by_dX2))\n        dB_by_dX3_term2 = np.vstack((\n            thetaUnitVector_1*dr_by_dX3,\n            thetaUnitVector_2*dr_by_dX3,\n            thetaUnitVector_3*dr_by_dX3))\n\n        dB[:] = self.B0/self.R0/self.q*np.array([dB_by_dX1_term1+dB_by_dX1_term2, dB_by_dX2_term1+dB_by_dX2_term2, dB_by_dX3_term1+dB_by_dX3_term2]).T\n\n    def as_dict(self, serial_objs_dict) -> dict:\n        d = super().as_dict(serial_objs_dict=serial_objs_dict)\n        d[\"points\"] = self.get_points_cart()\n        return d\n\n    @classmethod\n    def from_dict(cls, d, serial_objs_dict, recon_objs):\n        field = cls(d[\"R0\"], d[\"B0\"], d[\"q\"])\n        decoder = GSONDecoder()\n        xyz = decoder.process_decoded(d[\"points\"], serial_objs_dict, recon_objs)\n        field.set_points_cart(xyz)\n        return field",
  "class ScalarPotentialRZMagneticField(MagneticField):\n    \"\"\"\n    Vacuum magnetic field as a solution of B = grad(Phi) where Phi is the\n    magnetic field scalar potential.  It takes Phi as an input string, which\n    should contain an expression involving the standard cylindrical coordinates\n    (R, phi, Z) Example: ScalarPotentialRZMagneticField(\"2*phi\") yields a\n    magnetic field B = grad(2*phi) = (0,2/R,0). In order for the analytical\n    derivatives to be performed by sympy, a term 1e-30*Phi*R*Z is added\n    to every entry. Note: this function needs sympy.\n\n    Args:\n        phi_str:  string containing vacuum scalar potential expression as a function of R, Z and phi\n    \"\"\"\n\n    ## TRY to add C*R*phi*Z in all entries and then put C=0\n\n    def __init__(self, phi_str):\n        MagneticField.__init__(self)\n        if not sympy_found:\n            raise RuntimeError(\"Sympy is required for the ScalarPotentialRZMagneticField class\")\n        self.phi_str = phi_str\n        self.phi_parsed = parse_expr(phi_str)\n        R, Z, Phi = sp.symbols('R Z phi')\n        self.Blambdify = sp.lambdify((R, Z, Phi), [self.phi_parsed.diff(R)+1e-30*Phi*R*Z, \\\n                                                   self.phi_parsed.diff(Phi)/R+1e-30*Phi*R*Z, \\\n                                                   self.phi_parsed.diff(Z)+1e-30*Phi*R*Z])\n        self.dBlambdify_by_dX = sp.lambdify(\n            (R, Z, Phi),\n            [[1e-30*Phi*R*Z+sp.cos(Phi)*self.phi_parsed.diff(R).diff(R)-(sp.sin(Phi)/R)*self.phi_parsed.diff(R).diff(Phi),\n              1e-30*Phi*R*Z+sp.cos(Phi)*(self.phi_parsed.diff(Phi)/R).diff(R)-(sp.sin(Phi)/R)*(self.phi_parsed.diff(Phi)/R).diff(Phi),\n              1e-30*Phi*R*Z+sp.cos(Phi)*self.phi_parsed.diff(Z).diff(R)-(sp.sin(Phi)/R)*self.phi_parsed.diff(Z).diff(Phi)],\n             [1e-30*Phi*R*Z+sp.sin(Phi)*self.phi_parsed.diff(R).diff(R)+(sp.cos(Phi)/R)*self.phi_parsed.diff(R).diff(Phi),\n              1e-30*Phi*R*Z+sp.sin(Phi)*(self.phi_parsed.diff(Phi)/R).diff(R)+(sp.cos(Phi)/R)*(self.phi_parsed.diff(Phi)/R).diff(Phi),\n              1e-30*Phi*R*Z+sp.sin(Phi)*self.phi_parsed.diff(Z).diff(R)+(sp.cos(Phi)/R)*self.phi_parsed.diff(Z).diff(Phi)],\n             [1e-30*Phi*R*Z+self.phi_parsed.diff(R).diff(Z),\n              1e-30*Phi*R*Z+(self.phi_parsed.diff(Phi)/R).diff(Z),\n              1e-30*Phi*R*Z+self.phi_parsed.diff(Z).diff(Z)]])\n\n    def _B_impl(self, B):\n        points = self.get_points_cart_ref()\n        r = np.sqrt(np.square(points[:, 0]) + np.square(points[:, 1]))\n        z = points[:, 2]\n        phi = np.arctan2(points[:, 1], points[:, 0])\n        B_cyl = np.array(self.Blambdify(r, z, phi)).T\n        # Bx = Br cos(phi) - Bphi sin(phi)\n        B[:, 0] = B_cyl[:, 0] * np.cos(phi) - B_cyl[:, 1] * np.sin(phi)\n        # By = Br sin(phi) + Bphi cos(phi)\n        B[:, 1] = B_cyl[:, 0] * np.sin(phi) + B_cyl[:, 1] * np.cos(phi)\n        B[:, 2] = B_cyl[:, 2]\n\n    def _dB_by_dX_impl(self, dB):\n        points = self.get_points_cart_ref()\n        r = np.sqrt(np.square(points[:, 0]) + np.square(points[:, 1]))\n        z = points[:, 2]\n        phi = np.arctan2(points[:, 1], points[:, 0])\n        dB_cyl = np.array(self.dBlambdify_by_dX(r, z, phi)).transpose((2, 0, 1))\n        dBrdx = dB_cyl[:, 0, 0]\n        dBrdy = dB_cyl[:, 1, 0]\n        dBrdz = dB_cyl[:, 2, 0]\n        dBphidx = dB_cyl[:, 0, 1]\n        dBphidy = dB_cyl[:, 1, 1]\n        dBphidz = dB_cyl[:, 2, 1]\n        dB[:, 0, 2] = dB_cyl[:, 0, 2]\n        dB[:, 1, 2] = dB_cyl[:, 1, 2]\n        dB[:, 2, 2] = dB_cyl[:, 2, 2]\n        dcosphidx = -points[:, 0]**2/r**3 + 1/r\n        dsinphidx = -points[:, 0]*points[:, 1]/r**3\n        dcosphidy = -points[:, 0]*points[:, 1]/r**3\n        dsinphidy = -points[:, 1]**2/r**3 + 1/r\n        B_cyl = np.array(self.Blambdify(r, z, phi)).T\n        Br = B_cyl[:, 0]\n        Bphi = B_cyl[:, 1]\n        # Bx = Br cos(phi) - Bphi sin(phi)\n        dB[:, 0, 0] = dBrdx * np.cos(phi) + Br * dcosphidx - dBphidx * np.sin(phi) \\\n            - Bphi * dsinphidx\n        dB[:, 1, 0] = dBrdy * np.cos(phi) + Br * dcosphidy - dBphidy * np.sin(phi) \\\n            - Bphi * dsinphidy\n        dB[:, 2, 0] = dBrdz * np.cos(phi) - dBphidz * np.sin(phi)\n        # By = Br sin(phi) + Bphi cos(phi)\n        dB[:, 0, 1] = dBrdx * np.sin(phi) + Br * dsinphidx + dBphidx * np.cos(phi) \\\n            + Bphi * dcosphidx\n        dB[:, 1, 1] = dBrdy * np.sin(phi) + Br * dsinphidy + dBphidy * np.cos(phi) \\\n            + Bphi * dcosphidy\n        dB[:, 2, 1] = dBrdz * np.sin(phi) + dBphidz * np.cos(phi)\n\n    def as_dict(self, serial_objs_dict) -> dict:\n        d = super().as_dict(serial_objs_dict=serial_objs_dict)\n        d[\"points\"] = self.get_points_cart()\n        return d\n\n    @classmethod\n    def from_dict(cls, d, serial_objs_dict, recon_objs):\n        field = cls(d[\"phi_str\"])\n        decoder = GSONDecoder()\n        xyz = decoder.process_decoded(d[\"points\"], serial_objs_dict, recon_objs)\n        field.set_points_cart(xyz)\n        return field",
  "class CircularCoil(MagneticField):\n    '''\n    Magnetic field created by a single circular coil evaluated using analytical\n    functions, including complete elliptic integrals of the first and second\n    kind.  As inputs, it takes the radius of the coil (r0), its center, current\n    (I) and its normal vector [either spherical angle components\n    (normal=[theta,phi]) or (x,y,z) components of a vector (normal=[x,y,z])]).\n    The (theta,phi) angles are related to the (x,y,z) components of the normal vector via\n    theta = np.arctan2(normal[1], normal[0]) and phi = np.arctan2(np.sqrt(normal[0]**2+normal[1]**2), normal[2]).\n    Sign convention: CircularCoil with a positive current produces a magnetic field\n    vector in the same direction as the normal when evaluated at the center of the coil.a\n\n    Args:\n        r0: radius of the coil\n        center: point at the coil center\n        I: current of the coil in Ampere's\n        normal: if list with two values treats it as spherical angles theta and\n                phi of the normal vector to the plane of the coil centered at the coil\n                center, if list with three values treats it a vector\n    '''\n\n    def __init__(self, r0=0.1, center=[0, 0, 0], I=5e5/np.pi, normal=[0, 0]):\n        MagneticField.__init__(self)\n        self.r0 = r0\n        self.Inorm = I*4e-7\n        self.center = center\n        self.normal = normal\n        if len(normal) == 2:\n            theta = normal[0]\n            phi = normal[1]\n        else:\n            theta = np.arctan2(normal[1], normal[0])\n            phi = np.arctan2(np.sqrt(normal[0]**2+normal[1]**2), normal[2])\n\n        self.rotMatrix = np.array([\n            [np.cos(phi) * np.cos(theta)**2 + np.sin(theta)**2,\n             -np.sin(phi / 2)**2 * np.sin(2 * theta),\n             np.cos(theta) * np.sin(phi)],\n            [-np.sin(phi / 2)**2 * np.sin(2 * theta),\n             np.cos(theta)**2 + np.cos(phi) * np.sin(theta)**2,\n             np.sin(phi) * np.sin(theta)],\n            [-np.cos(theta) * np.sin(phi),\n             -np.sin(phi) * np.sin(theta),\n             np.cos(phi)]\n        ])\n\n        self.rotMatrixInv = np.array(self.rotMatrix.T)\n\n    @property\n    def I(self):\n        return self.Inorm * 25e5\n\n    def _B_impl(self, B):\n        points = self.get_points_cart_ref()\n        points = np.array(np.dot(self.rotMatrixInv, np.array(np.subtract(points, self.center)).T).T)\n        rho = np.sqrt(np.square(points[:, 0]) + np.square(points[:, 1]))\n        r = np.sqrt(np.square(points[:, 0]) + np.square(points[:, 1]) + np.square(points[:, 2]))\n        alpha = np.sqrt(self.r0**2 + np.square(r) - 2*self.r0*rho)\n        beta = np.sqrt(self.r0**2 + np.square(r) + 2*self.r0*rho)\n        k = np.sqrt(1-np.divide(np.square(alpha), np.square(beta)))\n        ellipek2 = ellipe(k**2)\n        ellipkk2 = ellipk(k**2)\n        gamma = np.square(points[:, 0]) - np.square(points[:, 1])\n        B[:] = np.dot(self.rotMatrix, np.array(\n            [self.Inorm*points[:, 0]*points[:, 2]/(2*alpha**2*beta*rho**2+1e-31)*((self.r0**2+r**2)*ellipek2-alpha**2*ellipkk2),\n             self.Inorm*points[:, 1]*points[:, 2]/(2*alpha**2*beta*rho**2+1e-31)*((self.r0**2+r**2)*ellipek2-alpha**2*ellipkk2),\n             self.Inorm/(2*alpha**2*beta+1e-31)*((self.r0**2-r**2)*ellipek2+alpha**2*ellipkk2)])).T\n\n    def _dB_by_dX_impl(self, dB):\n        points = self.get_points_cart_ref()\n        points = np.array(np.dot(self.rotMatrixInv, np.array(np.subtract(points, self.center)).T).T)\n        rho = np.sqrt(np.square(points[:, 0]) + np.square(points[:, 1]))\n        r = np.sqrt(np.square(points[:, 0]) + np.square(points[:, 1]) + np.square(points[:, 2]))\n        alpha = np.sqrt(self.r0**2 + np.square(r) - 2*self.r0*rho)\n        beta = np.sqrt(self.r0**2 + np.square(r) + 2*self.r0*rho)\n        k = np.sqrt(1-np.divide(np.square(alpha), np.square(beta)))\n        ellipek2 = ellipe(k**2)\n        ellipkk2 = ellipk(k**2)\n        gamma = np.square(points[:, 0]) - np.square(points[:, 1])\n        dBxdx = (self.Inorm*points[:, 2]*(\n            ellipkk2*alpha**2*((2*points[:, 0]**4 + gamma*(\n                points[:, 1]**2 + points[:, 2]**2))*r**2 + self.r0**2*(\n                    gamma*(self.r0**2 + 2*points[:, 2]**2) - (3*points[:, 0]**2 - 2*points[:, 1]**2)*rho**2))\n            + ellipek2*(-((2*points[:, 0]**4 + gamma*(points[:, 1]**2 + points[:, 2]**2))*r**4)\n                        + self.r0**4*(-(gamma*(self.r0**2 + 3*points[:, 2]**2)) + (8*points[:, 0]**2 - points[:, 1]**2)*rho**2)\n                        - self.r0**2*(\n                            3*gamma*points[:, 2]**4 - 2*(2*points[:, 0]**2 + points[:, 1]**2)*points[:, 2]**2 * rho**2\n                            + (5*points[:, 0]**2 + points[:, 1]**2)*rho**4\n            ))\n        ))/(2*alpha**4*beta**3*rho**4+1e-31)\n\n        dBydx = (self.Inorm*points[:, 0]*points[:, 1]*points[:, 2]*(\n            ellipkk2*alpha**2*(\n                2*self.r0**4 + r**2*(2*r**2 + rho**2) - self.r0**2*(-4*points[:, 2]**2 + 5*rho**2))\n            + ellipek2*(-2*self.r0**6 - r**4*(2*r**2 + rho**2) + 3*self.r0**4*(-2*points[:, 2]**2 + 3*rho**2) - 2*self.r0**2*(3*points[:, 2]**4 - points[:, 2]**2*rho**2 + 2*rho**4))\n        ))/(2*alpha**4*beta**3*rho**4+1e-31)\n\n        dBzdx = (self.Inorm*points[:, 0]*(\n            - (ellipkk2*alpha**2*((-self.r0**2 + rho**2)**2 + points[:, 2]**2*(self.r0**2 + rho**2)))\n            + ellipek2*(\n                points[:, 2]**4*(self.r0**2 + rho**2) + (-self.r0**2 + rho**2)**2*(self.r0**2 + rho**2)\n                + 2*points[:, 2]**2*(self.r0**4 - 6*self.r0**2*rho**2 + rho**4))\n        ))/(2*alpha**4*beta**3*rho**2+1e-31)\n        dBxdy = dBydx\n\n        dBydy = (self.Inorm*points[:, 2]*(\n            ellipkk2*alpha**2*((2*points[:, 1]**4 - gamma*(points[:, 0]**2 + points[:, 2]**2))*r**2 +\n                               self.r0**2*(-(gamma*(self.r0**2 + 2*points[:, 2]**2)) - (-2*points[:, 0]**2 + 3*points[:, 1]**2)*rho**2)) +\n            ellipek2*(-((2*points[:, 1]**4 - gamma*(points[:, 0]**2 + points[:, 2]**2))*r**4) +\n                      self.r0**4*(gamma*(self.r0**2 + 3*points[:, 2]**2) + (-points[:, 0]**2 + 8*points[:, 1]**2)*rho**2) -\n                      self.r0**2*(-3*gamma*points[:, 2]**4 - 2*(points[:, 0]**2 + 2*points[:, 1]**2)*points[:, 2]**2*rho**2 +\n                                  (points[:, 0]**2 + 5*points[:, 1]**2)*rho**4))))/(2*alpha**4*beta**3*rho**4+1e-31)\n\n        dBzdy = dBzdx*points[:, 1]/(points[:, 0]+1e-31)\n\n        dBxdz = dBzdx\n\n        dBydz = dBzdy\n\n        dBzdz = (self.Inorm*points[:, 2]*(ellipkk2*alpha**2*(self.r0**2 - r**2) +\n                                          ellipek2*(-7*self.r0**4 + r**4 + 6*self.r0**2*(-points[:, 2]**2 + rho**2))))/(2*alpha**4*beta**3+1e-31)\n\n        dB_by_dXm = np.array([\n            [dBxdx, dBydx, dBzdx],\n            [dBxdy, dBydy, dBzdy],\n            [dBxdz, dBydz, dBzdz]])\n\n        dB[:] = np.array([\n            [np.dot(self.rotMatrixInv[:, 0], np.dot(self.rotMatrix[0, :], dB_by_dXm)),\n             np.dot(self.rotMatrixInv[:, 1], np.dot(self.rotMatrix[0, :], dB_by_dXm)),\n             np.dot(self.rotMatrixInv[:, 2], np.dot(self.rotMatrix[0, :], dB_by_dXm))],\n            [np.dot(self.rotMatrixInv[:, 0], np.dot(self.rotMatrix[1, :], dB_by_dXm)),\n             np.dot(self.rotMatrixInv[:, 1], np.dot(self.rotMatrix[1, :], dB_by_dXm)),\n             np.dot(self.rotMatrixInv[:, 2], np.dot(self.rotMatrix[1, :], dB_by_dXm))],\n            [np.dot(self.rotMatrixInv[:, 0], np.dot(self.rotMatrix[2, :], dB_by_dXm)),\n             np.dot(self.rotMatrixInv[:, 1], np.dot(self.rotMatrix[2, :], dB_by_dXm)),\n             np.dot(self.rotMatrixInv[:, 2], np.dot(self.rotMatrix[2, :], dB_by_dXm))]]).T\n\n    def _A_impl(self, A):\n        points = self.get_points_cart_ref()\n        points = np.array(np.dot(self.rotMatrixInv, np.array(np.subtract(points, self.center)).T).T)\n        rho = np.sqrt(np.square(points[:, 0]) + np.square(points[:, 1]))\n        r = np.sqrt(np.square(points[:, 0]) + np.square(points[:, 1]) + np.square(points[:, 2]))\n        alpha = np.sqrt(self.r0**2 + np.square(r) - 2*self.r0*rho)\n        beta = np.sqrt(self.r0**2 + np.square(r) + 2*self.r0*rho)\n        k = np.sqrt(1-np.divide(np.square(alpha), np.square(beta)))\n        ellipek2 = ellipe(k**2)\n        ellipkk2 = ellipk(k**2)\n\n        num = (2*self.r0+np.sqrt(points[:, 0]**2+points[:, 1]**2)*ellipek2+(self.r0**2+points[:, 0]**2+points[:, 1]**2+points[:, 2]**2)*(ellipe(k**2)-ellipkk2))\n        denom = ((points[:, 0]**2+points[:, 1]**2+1e-31)*np.sqrt(self.r0**2+points[:, 0]**2+points[:, 1]**2+2*self.r0*np.sqrt(points[:, 0]**2+points[:, 1]**2)+points[:, 2]**2+1e-31))\n        fak = num/denom\n        pts = fak[:, None]*np.concatenate((-points[:, 1][:, None], points[:, 0][:, None], np.zeros((points.shape[0], 1))), axis=-1)\n        A[:] = -self.Inorm/2*np.dot(self.rotMatrix, pts.T).T\n\n    def as_dict(self, serial_objs_dict):\n        d = super().as_dict(serial_objs_dict=serial_objs_dict)\n        d[\"points\"] = self.get_points_cart()\n        return d\n\n    @classmethod\n    def from_dict(cls, d, serial_objs_dict, recon_objs):\n        field = cls(d[\"r0\"], d[\"center\"], d[\"I\"], d[\"normal\"])\n        decoder = GSONDecoder()\n        xyz = decoder.process_decoded(d[\"points\"], serial_objs_dict, recon_objs)\n        field.set_points_cart(xyz)\n        return field",
  "class DipoleField(MagneticField):\n    r\"\"\"\n    Computes the MagneticField induced by N dipoles. The field is given by\n\n    .. math::\n\n        B(\\mathbf{x}) = \\frac{\\mu_0}{4\\pi} \\sum_{i=1}^{N} \\left(\\frac{3\\mathbf{r}_i\\cdot \\mathbf{m}_i}{|\\mathbf{r}_i|^5}\\mathbf{r}_i - \\frac{\\mathbf{m}_i}{|\\mathbf{r}_i|^3}\\right)\n\n    where :math:`\\mu_0=4\\pi\\times 10^{-7}\\;N/A^2` is the permeability of free space\n    and :math:`\\mathbf{r_i} = \\mathbf{x} - \\mathbf{x}^{dipole}_i` is the\n    vector between the field evaluation point and the dipole :math:`i`\n    position.\n\n    Args:\n        dipole_grid: 2D numpy array, shape (ndipoles, 3).\n            A set of points corresponding to the locations of magnetic dipoles.\n        dipole_vectors: 2D numpy array, shape (ndipoles, 3).\n            The dipole vectors of each of the dipoles in the grid.\n        stellsym: bool (default True).\n            Whether or not the dipole grid is stellarator symmetric.\n        nfp: int (default 1).\n            The field-period symmetry of the dipole-grid.\n        coordinate_flag: string (default \"cartesian\").\n            The global coordinate system that should be considered grid-aligned in the calculation.\n            The options are \"cartesian\" (rectangular bricks), \"cylindrical\" (cylindrical bricks),\n            and \"toroidal\" (uniform grid in simple toroidal coordinates). Note that this ASSUMES\n            that the global coordinate system for the dipole locations is one of these three\n            choices, so be careful if your permanent magnets are shaped/arranged differently!\n        m_maxima: 1D numpy array, shape (ndipoles,).\n            The maximum dipole strengths of each magnet in the grid. If not specified, defaults\n            to using the largest dipole strength of the magnets in dipole_grid, and using this\n            value for all the dipoles. Needed for plotting normalized dipole magnitudes in the\n            vtk functionality.\n        R0: double.\n            The value of the major radius of the stellarator needed only for simple toroidal\n            coordinates.\n    \"\"\"\n\n    def __init__(self, dipole_grid, dipole_vectors, stellsym=True, nfp=1, coordinate_flag='cartesian', m_maxima=None, R0=1):\n        super().__init__()        \n        if coordinate_flag == 'toroidal':\n            warnings.warn('Note that if using simple toroidal coordinates, '\n                          'the major radius must be specified through R0 argument.')\n        self.R0 = R0\n        self._dipole_fields_from_symmetries(dipole_grid, dipole_vectors, stellsym, nfp, coordinate_flag, m_maxima, R0)\n\n    def _B_impl(self, B):\n        points = self.get_points_cart_ref()\n        B[:] = sopp.dipole_field_B(points, self.dipole_grid, self.m_vec)\n\n    def _dB_by_dX_impl(self, dB):\n        points = self.get_points_cart_ref()\n        dB[:] = sopp.dipole_field_dB(points, self.dipole_grid, self.m_vec)\n\n    def _A_impl(self, A):\n        points = self.get_points_cart_ref()\n        A[:] = sopp.dipole_field_A(points, self.dipole_grid, self.m_vec)\n\n    def _dA_by_dX_impl(self, dA):\n        points = self.get_points_cart_ref()\n        dA[:] = sopp.dipole_field_dA(points, self.dipole_grid, self.m_vec)\n\n    def _dipole_fields_from_symmetries(self, dipole_grid, dipole_vectors, stellsym=True, nfp=1, coordinate_flag='cartesian', m_maxima=None, R0=1):\n        \"\"\"\n        Takes the dipoles and grid initialized in a PermanentMagnetOptimizer (for a half-period surface)\n        and generates the full dipole manifold so that the call to B() (the magnetic field from\n        the dipoles) correctly returns contributions from all the dipoles from symmetries.\n        \"\"\"\n        self.dipole_grid = dipole_grid\n\n        # Read in the required fields from pm_opt object\n        ndipoles = dipole_grid.shape[0]\n        if m_maxima is None:\n            m_maxima = np.max(np.linalg.norm(dipole_vectors, axis=-1)) * np.ones(ndipoles)\n        if stellsym:\n            stell_list = [1, -1]\n            nsym = nfp * 2\n        else:\n            stell_list = [1]\n            nsym = nfp\n        m = dipole_vectors.reshape(ndipoles, 3)\n\n        # Initialize new grid and dipole vectors for all the dipoles\n        # after we account for the symmetries below.\n        dipole_grid_x = np.zeros(ndipoles * nsym)\n        dipole_grid_y = np.zeros(ndipoles * nsym)\n        dipole_grid_z = np.zeros(ndipoles * nsym)\n        m_vec = np.zeros((ndipoles * nsym, 3))\n        m_max = np.zeros(ndipoles * nsym)\n\n        # Load in the dipole locations for a half-period surface\n        ox = dipole_grid[:, 0]\n        oy = dipole_grid[:, 1]\n        oz = dipole_grid[:, 2]\n\n        # loop through the dipoles and repeat for fp and stellarator symmetries\n        index = 0\n        n = ndipoles\n\n        # get the components in Cartesian, converting if needed\n        mmx = m[:, 0]\n        mmy = m[:, 1]\n        mmz = m[:, 2]\n        if coordinate_flag == 'cylindrical':\n            phi_dipole = np.arctan2(oy, ox)\n            mmx_temp = mmx * np.cos(phi_dipole) - mmy * np.sin(phi_dipole)\n            mmy_temp = mmx * np.sin(phi_dipole) + mmy * np.cos(phi_dipole)\n            mmx = mmx_temp\n            mmy = mmy_temp\n        if coordinate_flag == 'toroidal':\n            phi_dipole = np.arctan2(oy, ox)\n            theta_dipole = np.arctan2(oz, np.sqrt(ox ** 2 + oy ** 2) - R0)\n            mmx_temp = mmx * np.cos(phi_dipole) * np.cos(theta_dipole) - mmy * np.sin(phi_dipole) - mmz * np.cos(phi_dipole) * np.sin(theta_dipole)\n            mmy_temp = mmx * np.sin(phi_dipole) * np.cos(theta_dipole) + mmy * np.cos(phi_dipole) - mmz * np.sin(phi_dipole) * np.sin(theta_dipole)\n            mmz_temp = mmx * np.sin(theta_dipole) + mmz * np.cos(theta_dipole)\n            mmx = mmx_temp\n            mmy = mmy_temp\n            mmz = mmz_temp\n\n        # Loop over stellarator and field-period symmetry contributions\n        for stell in stell_list:\n            for fp in range(nfp):\n                phi0 = (2 * np.pi / nfp) * fp\n\n                # get new dipoles locations by flipping the y and z components, then rotating by phi0\n                dipole_grid_x[index:index + n] = ox * np.cos(phi0) - oy * np.sin(phi0) * stell\n                dipole_grid_y[index:index + n] = ox * np.sin(phi0) + oy * np.cos(phi0) * stell\n                dipole_grid_z[index:index + n] = oz * stell\n\n                # get new dipole vectors by flipping the x component, then rotating by phi0\n                m_vec[index:index + n, 0] = mmx * np.cos(phi0) * stell - mmy * np.sin(phi0)\n                m_vec[index:index + n, 1] = mmx * np.sin(phi0) * stell + mmy * np.cos(phi0)\n                m_vec[index:index + n, 2] = mmz\n\n                m_max[index:index + n] = m_maxima\n                index += n\n\n        contig = np.ascontiguousarray\n        self.dipole_grid = contig(np.array([dipole_grid_x, dipole_grid_y, dipole_grid_z]).T)\n        self.m_vec = contig(m_vec)\n        self.m_maxima = contig(m_max)\n\n    def _toVTK(self, vtkname):\n        \"\"\"\n            Write dipole data into a VTK file (acknowledgements to Caoxiang's CoilPy code).\n\n        Args:\n            vtkname (str): VTK filename, will be appended with .vts or .vtu.\n        \"\"\"\n\n        # get the coordinates\n        ox = np.ascontiguousarray(self.dipole_grid[:, 0])\n        oy = np.ascontiguousarray(self.dipole_grid[:, 1])\n        oz = np.ascontiguousarray(self.dipole_grid[:, 2])\n        ophi = np.arctan2(oy, ox)\n        otheta = np.arctan2(oz, np.sqrt(ox ** 2 + oy ** 2) - self.R0)\n\n        # define the m vectors and the normalized m vectors\n        # in Cartesian, cylindrical, and simple toroidal coordinates.\n        mx = np.ascontiguousarray(self.m_vec[:, 0])\n        my = np.ascontiguousarray(self.m_vec[:, 1])\n        mz = np.ascontiguousarray(self.m_vec[:, 2])\n        mmag = np.sqrt(mx ** 2 + my ** 2 + mz ** 2)\n        mx_normalized = np.ascontiguousarray(mx / self.m_maxima)\n        my_normalized = np.ascontiguousarray(my / self.m_maxima)\n        mz_normalized = np.ascontiguousarray(mz / self.m_maxima)\n        mr = np.ascontiguousarray(mx * np.cos(ophi) + my * np.sin(ophi))\n        mrminor = np.ascontiguousarray(mx * np.cos(ophi) * np.cos(otheta) + my * np.sin(ophi) * np.cos(otheta) + np.sin(otheta) * mz)\n        mphi = np.ascontiguousarray(-mx * np.sin(ophi) + my * np.cos(ophi))\n        mtheta = np.ascontiguousarray(-mx * np.cos(ophi) * np.sin(otheta) - my * np.sin(ophi) * np.sin(otheta) + np.cos(otheta) * mz)\n        mr_normalized = np.ascontiguousarray(mr / self.m_maxima)\n        mrminor_normalized = np.ascontiguousarray(mrminor / self.m_maxima)\n        mphi_normalized = np.ascontiguousarray(mphi / self.m_maxima)\n        mtheta_normalized = np.ascontiguousarray(mtheta / self.m_maxima)\n\n        # Save all the data to a vtk file which can be visualized nicely with ParaView\n        data = {\"m\": (mx, my, mz), \"m_normalized\": (mx_normalized, my_normalized, mz_normalized), \"m_rphiz\": (mr, mphi, mz), \"m_rphiz_normalized\": (mr_normalized, mphi_normalized, mz_normalized), \"m_rphitheta\": (mrminor, mphi, mtheta), \"m_rphitheta_normalized\": (mrminor_normalized, mphi_normalized, mtheta_normalized)}\n        from pyevtk.hl import pointsToVTK\n        pointsToVTK(\n            str(vtkname), ox, oy, oz, data=data\n        )",
  "class Dommaschk(MagneticField):\n    \"\"\"\n    Vacuum magnetic field created by an explicit representation of the magnetic\n    field scalar potential as proposed by W. Dommaschk (1986), Computer Physics\n    Communications 40, 203-218. As inputs, it takes the arrays for the harmonics\n    m, n and its corresponding coefficients.\n\n    Args:\n        m: first harmonic array\n        n: second harmonic array\n        coeffs: coefficient for Vml for each of the ith index of the harmonics m and n\n    \"\"\"\n\n    def __init__(self, mn=[[0, 0]], coeffs=[[0, 0]]):\n        MagneticField.__init__(self)\n        self.m = np.array(mn, dtype=np.int16)[:, 0]\n        self.n = np.array(mn, dtype=np.int16)[:, 1]\n        self.coeffs = coeffs\n        self.Btor = ToroidalField(1, 1)\n\n    def _set_points_cb(self):\n        self.Btor.set_points_cart(self.get_points_cart_ref())\n\n    def _B_impl(self, B):\n        points = self.get_points_cart_ref()\n        B[:] = np.add.reduce(sopp.DommaschkB(self.m, self.n, self.coeffs, points))+self.Btor.B()\n\n    def _dB_by_dX_impl(self, dB):\n        points = self.get_points_cart_ref()\n        dB[:] = np.add.reduce(sopp.DommaschkdB(self.m, self.n, self.coeffs, points))+self.Btor.dB_by_dX()\n\n    @property\n    def mn(self):\n        return np.column_stack((self.m, self.n))\n\n    def as_dict(self, serial_objs_dict) -> dict:\n        d = super().as_dict(serial_objs_dict=serial_objs_dict)\n        d[\"points\"] = self.get_points_cart()\n        return d\n\n    @classmethod\n    def from_dict(cls, d, serial_objs_dict, recon_objs):\n        decoder = GSONDecoder()\n        mn = decoder.process_decoded(d[\"mn\"], serial_objs_dict, recon_objs)\n        field = cls(mn, d[\"coeffs\"])\n        xyz = decoder.process_decoded(d[\"points\"], serial_objs_dict, recon_objs)\n        field.set_points_cart(xyz)\n        return field",
  "class Reiman(MagneticField):\n    '''\n    Magnetic field model in section 5 of Reiman and Greenside, Computer Physics Communications 43 (1986) 157\u2014167.\n    This field allows for an analytical expression of the magnetic island width\n    that can be used for island optimization.  However, the field is not\n    completely physical as it does not have nested flux surfaces.\n\n    Args:\n        iota0: unperturbed rotational transform\n        iota1: unperturbed global magnetic shear\n        k: integer array specifying the Fourier modes used\n        epsilonk: coefficient of the Fourier modes\n        m0: toroidal symmetry parameter (normally m0=1)\n    '''\n\n    def __init__(self, iota0=0.15, iota1=0.38, k=[6], epsilonk=[0.01], m0=1):\n        MagneticField.__init__(self)\n        self.iota0 = iota0\n        self.iota1 = iota1\n        self.k = k\n        self.epsilonk = epsilonk\n        self.m0 = m0\n\n    def _B_impl(self, B):\n        points = self.get_points_cart_ref()\n        B[:] = sopp.ReimanB(self.iota0, self.iota1, self.k, self.epsilonk, self.m0, points)\n\n    def _dB_by_dX_impl(self, dB):\n        points = self.get_points_cart_ref()\n        dB[:] = sopp.ReimandB(self.iota0, self.iota1, self.k, self.epsilonk, self.m0, points)\n\n    def as_dict(self, serial_objs_dict):\n        d = super().as_dict(serial_objs_dict=serial_objs_dict)\n        d[\"points\"] = self.get_points_cart()\n        return d\n\n    @classmethod\n    def from_dict(cls, d, serial_objs_dict, recon_objs):\n        field = cls(d[\"iota0\"], d[\"iota1\"], d[\"k\"], d[\"epsilonk\"], d[\"m0\"])\n        decoder = GSONDecoder()\n        xyz = decoder.process_decoded(d[\"points\"], serial_objs_dict, recon_objs)\n        field.set_points_cart(xyz)\n        return field",
  "class UniformInterpolationRule(sopp.UniformInterpolationRule):\n    pass",
  "class ChebyshevInterpolationRule(sopp.ChebyshevInterpolationRule):\n    pass",
  "class InterpolatedField(sopp.InterpolatedField, MagneticField):\n    r\"\"\"\n    This field takes an existing field and interpolates it on a regular grid in :math:`r,\\phi,z`.\n    This resulting interpolant can then be evaluated very quickly.\n    \"\"\"\n\n    def __init__(self, field, degree, rrange, phirange, zrange, extrapolate=True, nfp=1, stellsym=False, skip=None):\n        r\"\"\"\n        Args:\n            field: the underlying :mod:`simsopt.field.magneticfield.MagneticField` to be interpolated.\n            degree: the degree of the piecewise polynomial interpolant.\n            rrange: a 3-tuple of the form ``(rmin, rmax, nr)``. This mean that the interval :math:`[rmin, rmax]` is\n                    split into ``nr`` many subintervals.\n            phirange: a 3-tuple of the form ``(phimin, phimax, nphi)``.\n            zrange: a 3-tuple of the form ``(zmin, zmax, nz)``.\n            extrapolate: whether to extrapolate the field when evaluate outside\n                         the integration domain or to throw an error.\n            nfp: Whether to exploit rotational symmetry. In this case any angle\n                 is always mapped into the interval :math:`[0, 2\\pi/\\mathrm{nfp})`,\n                 hence it makes sense to use ``phimin=0`` and\n                 ``phimax=2*np.pi/nfp``.\n            stellsym: Whether to exploit stellarator symmetry. In this case\n                      ``z`` is always mapped to be positive, hence it makes sense to use\n                      ``zmin=0``.\n            skip: a function that takes in a point (in cylindrical (r,phi,z)\n                  coordinates) and returns whether to skip that location when\n                  building the interpolant or not. The signature should be\n\n                  .. code-block:: Python\n\n                      def skip(r: double, phi: double, z: double) -> bool:\n                          ...\n\n                  See also here\n                  https://github.com/hiddenSymmetries/simsopt/pull/227 for a\n                  graphical illustration.\n\n        \"\"\"\n        MagneticField.__init__(self)\n        if stellsym and zrange[0] != 0:\n            logger.warning(fr\"Sure about zrange[0]={zrange[0]}? When exploiting stellarator symmetry, the interpolant is never evaluated for z<0.\")\n        if nfp > 1 and abs(phirange[1] - 2*np.pi/nfp) > 1e-14:\n            logger.warning(fr\"Sure about phirange[1]={phirange[1]}? When exploiting rotational symmetry, the interpolant is never evaluated for phi>2\\pi/nfp.\")\n\n        if skip is None:\n            def skip(xs, ys, zs):\n                return [False for _ in xs]\n\n        sopp.InterpolatedField.__init__(self, field, degree, rrange, phirange, zrange, extrapolate, nfp, stellsym, skip)\n        self.__field = field\n\n    def to_vtk(self, filename):\n        \"\"\"Export the field evaluated on a regular grid for visualisation with e.g. Paraview.\"\"\"\n        degree = self.rule.degree\n        MagneticField.to_vtk(\n            self, filename,\n            nr=self.r_range[2]*degree+1,\n            nphi=self.phi_range[2]*degree+1,\n            nz=self.z_range[2]*degree+1,\n            rmin=self.r_range[0], rmax=self.r_range[1],\n            zmin=self.z_range[0], zmax=self.z_range[1]\n        )",
  "class MirrorModel(MagneticField):\n    r\"\"\"\n    Model magnetic field employed in https://arxiv.org/abs/2305.06372 to study\n    the magnetic mirror experiment WHAM. The\n    magnetic field is given by :math:`\\vec{B}=B_R \\vec{e}_R + B_Z \\vec{e}_Z`, where \n    :math:`\\vec{e}_R` and :math:`\\vec{e}_Z` are\n    the cylindrical radial and axial unit vectors, respectively, and\n    :math:`B_R` and :math:`B_Z` are given by\n\n    .. math::\n\n        B_R = -\\frac{1}{R} \\frac{\\partial\\psi}{\\partial Z}, \\; B_Z = \\frac{1}{R}.\n        \\frac{\\partial\\psi}{\\partial R}\n\n    In this model, the magnetic flux function :math:`\\psi` is written as a double\n    Lorentzian function\n\n    .. math::\n\n        \\psi = \\frac{R^2 \\mathcal{B}}{2 \\pi \\gamma}\\left(\\left[1+\\left(\\frac{Z-Z_m}{\\gamma}\\right)^2\\right]^{-1}+\\left[1+\\left(\\frac{Z+Z_m}{\\gamma}\\right)^2\\right]^{-1}\\right).\n\n    Note that this field is neither a vacuum field nor a solution of MHD force balance.\n    The input parameters are ``B0``, ``gamma`` and ``Z_m`` with the standard values the\n    ones used in https://arxiv.org/abs/2305.06372, that is, ``B0 = 6.51292``,\n    ``gamma = 0.124904``, and ``Z_m = 0.98``.\n\n    Args:\n        B0:  parameter :math:`\\mathcal{B}` of the flux surface function\n        gamma:  parameter :math:`\\gamma` of the flux surface function\n        Z_m:  parameter :math:`Z_m` of the flux surface function\n    \"\"\"\n\n    def __init__(self, B0=6.51292, gamma=0.124904, Z_m=0.98):\n        MagneticField.__init__(self)\n        self.B0 = B0\n        self.gamma = gamma\n        self.Z_m = Z_m\n\n    def _psi(self, R, Z):\n        factor1 = 1+((Z-self.Z_m)/(self.gamma))**2\n        factor2 = 1+((Z+self.Z_m)/(self.gamma))**2\n        psi = (R*R*self.B0/(2*np.pi*self.gamma))*(1/factor1+1/factor2)\n        return psi\n\n    def _B_impl(self, B):\n        points = self.get_points_cart_ref()\n        r = np.sqrt(np.square(points[:, 0]) + np.square(points[:, 1]))\n        z = points[:, 2]\n        phi = np.arctan2(points[:, 1], points[:, 0])\n        # BR = -(1/R)dpsi/dZ, BZ=(1/R)dpsi/dR\n        factor1 = (1+((z-self.Z_m)/(self.gamma))**2)**2\n        factor2 = (1+((z+self.Z_m)/(self.gamma))**2)**2\n        Br = (r*self.B0/(np.pi*self.gamma**3))*((z-self.Z_m)/factor1+(z+self.Z_m)/factor2)\n        Bz = self._psi(r, z)*2/r/r\n        B[:, 0] = Br * np.cos(phi)\n        B[:, 1] = Br * np.sin(phi)\n        B[:, 2] = Bz\n\n    def _dB_by_dX_impl(self, dB):\n        points = self.get_points_cart_ref()\n        r = np.sqrt(np.square(points[:, 0]) + np.square(points[:, 1]))\n        z = points[:, 2]\n        phi = np.arctan2(points[:, 1], points[:, 0])\n\n        factor1 = (1+((z-self.Z_m)/(self.gamma))**2)**2\n        factor2 = (1+((z+self.Z_m)/(self.gamma))**2)**2\n        Br = (r*self.B0/(np.pi*self.gamma**3))*((z-self.Z_m)/factor1+(z+self.Z_m)/factor2)\n        # Bz = self._psi(r,z)*2/r/r\n        dBrdr = (self.B0/(np.pi*self.gamma**3))*((z-self.Z_m)/factor1+(z+self.Z_m)/factor2)\n        dBzdz = -2*dBrdr\n        dBrdz = (self.B0*r/(np.pi*self.gamma**3))*(1/factor1+1/factor2\n                                                   - 4*self.gamma**4*((z-self.Z_m)**2/((z-self.Z_m)**2+self.gamma**2)**3+(z+self.Z_m)**2/((z+self.Z_m)**2+self.gamma**2)**3))\n        cosphi = np.cos(phi)\n        sinphi = np.sin(phi)\n        dcosphidx = -points[:, 0]**2/r**3 + 1/r\n        dsinphidx = -points[:, 0]*points[:, 1]/r**3\n        dcosphidy = -points[:, 0]*points[:, 1]/r**3\n        dsinphidy = -points[:, 1]**2/r**3 + 1/r\n        drdx = points[:, 0]/r\n        drdy = points[:, 1]/r\n        dBxdx = dBrdr*drdx*cosphi + Br*dcosphidx\n        dBxdy = dBrdr*drdy*cosphi + Br*dcosphidy\n        dBxdz = dBrdz*cosphi\n        dBydx = dBrdr*drdx*sinphi + Br*dsinphidx\n        dBydy = dBrdr*drdy*sinphi + Br*dsinphidy\n        dBydz = dBrdz*sinphi\n\n        dB[:, 0, 0] = dBxdx\n        dB[:, 1, 0] = dBxdy\n        dB[:, 2, 0] = dBxdz\n        dB[:, 0, 1] = dBydx\n        dB[:, 1, 1] = dBydy\n        dB[:, 2, 1] = dBydz\n        dB[:, 0, 2] = 0\n        dB[:, 1, 2] = 0\n        dB[:, 2, 2] = dBzdz\n\n    def as_dict(self, serial_objs_dict) -> dict:\n        d = super().as_dict(serial_objs_dict=serial_objs_dict)\n        d[\"points\"] = self.get_points_cart()\n        return d\n\n    @classmethod\n    def from_dict(cls, d, serial_objs_dict, recon_objs):\n        field = cls(d[\"B0\"], d[\"gamma\"], d[\"Z_m\"])\n        decoder = GSONDecoder()\n        xyz = decoder.process_decoded(d[\"points\"], serial_objs_dict, recon_objs)\n        field.set_points_cart(xyz)\n        return field",
  "def __init__(self, R0, B0):\n        MagneticField.__init__(self)\n        self.R0 = R0\n        self.B0 = B0",
  "def _B_impl(self, B):\n        points = self.get_points_cart_ref()\n        phi = np.arctan2(points[:, 1], points[:, 0])\n        R = np.sqrt(np.square(points[:, 0]) + np.square(points[:, 1]))\n        phiUnitVectorOverR = np.vstack((np.divide(-np.sin(phi), R), np.divide(np.cos(phi), R), np.zeros(len(phi)))).T\n        B[:] = np.multiply(self.B0*self.R0, phiUnitVectorOverR)",
  "def _dB_by_dX_impl(self, dB):\n        points = self.get_points_cart_ref()\n        phi = np.arctan2(points[:, 1], points[:, 0])\n        R = np.sqrt(np.square(points[:, 0]) + np.square(points[:, 1]))\n\n        x = points[:, 0]\n        y = points[:, 1]\n\n        dB_by_dX1 = np.vstack((\n            np.multiply(np.divide(self.B0*self.R0, R**4), 2*np.multiply(x, y)),\n            np.multiply(np.divide(self.B0*self.R0, R**4), y**2-x**2),\n            0*R))\n        dB_by_dX2 = np.vstack((\n            np.multiply(np.divide(self.B0*self.R0, R**4), y**2-x**2),\n            np.multiply(np.divide(self.B0*self.R0, R**4), -2*np.multiply(x, y)),\n            0*R))\n        dB_by_dX3 = np.vstack((0*R, 0*R, 0*R))\n\n        dB[:] = np.array([dB_by_dX1, dB_by_dX2, dB_by_dX3]).T",
  "def _d2B_by_dXdX_impl(self, ddB):\n        points = self.get_points_cart_ref()\n        x = points[:, 0]\n        y = points[:, 1]\n        ddB[:] = 2*self.B0*self.R0*np.multiply(\n            1/(points[:, 0]**2+points[:, 1]**2)**3, np.array([\n                [[3*points[:, 0]**2+points[:, 1]**3, points[:, 0]**3-3*points[:, 0]*points[:, 1]**2, np.zeros((len(points)))], [\n                    points[:, 0]**3-3*points[:, 0]*points[:, 1]**2, 3*points[:, 0]**2*points[:, 1]-points[:, 1]**3,\n                    np.zeros((len(points)))],\n                 np.zeros((3, len(points)))],\n                [[points[:, 0]**3-3*points[:, 0]*points[:, 1]**2, 3*points[:, 0]**2*points[:, 1]-points[:, 1]**3,\n                  np.zeros((len(points)))],\n                 [3*points[:, 0]**2*points[:, 1]-points[:, 1]**3, -points[:, 0]**3+3*points[:, 0]*points[:, 1]**2,\n                  np.zeros((len(points)))], np.zeros((3, len(points)))],\n                np.zeros((3, 3, len(points)))])).T",
  "def _A_impl(self, A):\n        points = self.get_points_cart_ref()\n        A[:] = self.B0*self.R0*np.array([\n            points[:, 2]*points[:, 0]/(points[:, 0]**2+points[:, 1]**2),\n            points[:, 2]*points[:, 1]/(points[:, 0]**2+points[:, 1]**2),\n            0*points[:, 2]]).T",
  "def _dA_by_dX_impl(self, dA):\n        points = self.get_points_cart_ref()\n        dA[:] = self.B0*self.R0*np.array((points[:, 2]/(points[:, 0]**2+points[:, 1]**2)**2)*np.array(\n            [[-points[:, 0]**2+points[:, 1]**2, -2*points[:, 0]*points[:, 1], np.zeros((len(points)))],\n             [-2*points[:, 0]*points[:, 1], points[:, 0]**2-points[:, 1]**2, np.zeros((len(points)))],\n             [points[:, 0]*(points[:, 0]**2+points[:, 1]**2)/points[:, 2],\n              points[:, 1]*(points[:, 0]**2+points[:, 1]**2)/points[:, 2], np.zeros((len(points)))]])).T",
  "def _d2A_by_dXdX_impl(self, ddA):\n        points = self.get_points_cart_ref()\n        ddA[:] = 2*self.B0*self.R0*np.array(\n            (points[:, 2]/(points[:, 0]**2+points[:, 1]**2)**3)*np.array([\n                [[points[:, 0]**3-3*points[:, 0]*points[:, 1]**2, 3*points[:, 0]**2*points[:, 1]-points[:, 1]**3,\n                  (-points[:, 0]**4+points[:, 1]**4)/(2*points[:, 2])],\n                 [3*points[:, 0]**2*points[:, 1]-points[:, 1]**3, -points[:, 0]**3+3*points[:, 0]*points[:, 1]**2, -points[:, 0]*points[:, 1]*(\n                     points[:, 0]**2+points[:, 1]**2)/points[:, 2]],\n                 [(-points[:, 0]**4+points[:, 1]**4)/(2*points[:, 2]),\n                  -points[:, 0]*points[:, 1]*(points[:, 0]**2+points[:, 1]**2)/points[:, 2],\n                  np.zeros((len(points)))]],\n                [[3*points[:, 0]**2*points[:, 1]-points[:, 1]**3, -points[:, 0]**3+3*points[:, 0]*points[:, 1]**2,\n                  -points[:, 0]*points[:, 1]*(points[:, 0]**2+points[:, 1]**2)/points[:, 2]],\n                 [-points[:, 0]**3+3*points[:, 0]*points[:, 1]**2, -3*points[:, 0]**2*points[:, 1]+points[:, 1]**3, (\n                     points[:, 0]**4-points[:, 1]**4)/(2*points[:, 2])],\n                 [-points[:, 0]*points[:, 1]*(points[:, 0]**2+points[:, 1]**2)/points[:, 2],\n                  (points[:, 0]**4-points[:, 1]**4)/(2*points[:, 2]), np.zeros((len(points)))]],\n                np.zeros((3, 3, len(points)))])).transpose((3, 0, 1, 2))",
  "def as_dict(self, serial_objs_dict) -> dict:\n        d = super().as_dict(serial_objs_dict=serial_objs_dict)\n        d[\"points\"] = self.get_points_cart()\n        return d",
  "def from_dict(cls, d, serial_objs_dict, recon_objs):\n        field = cls(d[\"R0\"], d[\"B0\"])\n        decoder = GSONDecoder()\n        xyz = decoder.process_decoded(d[\"points\"], serial_objs_dict, recon_objs)\n        field.set_points_cart(xyz)\n        return field",
  "def __init__(self, R0, B0, q):\n        MagneticField.__init__(self)\n        self.R0 = R0\n        self.B0 = B0\n        self.q = q",
  "def _B_impl(self, B):\n        points = self.get_points_cart_ref()\n\n        x = points[:, 0]\n        y = points[:, 1]\n        z = points[:, 2]\n\n        phi = np.arctan2(y, x)\n        theta = np.arctan2(z, np.sqrt(x**2+y**2)-self.R0)\n        r = np.sqrt((np.sqrt(x**2+y**2)-self.R0)**2+z**2)\n        thetaUnitVectorOver_times_r = np.vstack((-np.multiply(np.sin(theta), r)*np.cos(phi), -np.multiply(np.sin(theta), r)*np.sin(phi), np.multiply(np.cos(theta), r))).T\n        B[:] = self.B0/self.R0/self.q*thetaUnitVectorOver_times_r",
  "def _dB_by_dX_impl(self, dB):\n        points = self.get_points_cart_ref()\n\n        x = points[:, 0]\n        y = points[:, 1]\n        z = points[:, 2]\n\n        phi = np.arctan2(y, x)\n        theta = np.arctan2(z, np.sqrt(x**2+y**2)-self.R0)\n        r = np.sqrt((np.sqrt(x**2+y**2)-self.R0)**2+z**2)\n\n        dtheta_by_dX1 = -((x*z)/(np.sqrt(x**2+y**2)*(x**2+y**2+z**2-2*np.sqrt(x**2+y**2)*self.R0+(self.R0)**2)))\n        dtheta_by_dX2 = -((y*z)/(np.sqrt(x**2+y**2)*(x**2+y**2+z**2-2*np.sqrt(x**2+y**2)*self.R0+(self.R0)**2)))\n        dtheta_by_dX3 = 1/((-self.R0+np.sqrt(x**2+y**2))*(1+z**2/(self.R0-np.sqrt(x**2+y**2))**2))\n\n        dphi_by_dX1 = -(y/(x**2 + y**2))\n        dphi_by_dX2 = x/(x**2 + y**2)\n        dphi_by_dX3 = 0.*z\n\n        dthetaunitvector_by_dX1 = np.vstack((\n            -np.cos(theta)*np.cos(phi)*dtheta_by_dX1+np.sin(theta)*np.sin(phi)*dphi_by_dX1,\n            -np.cos(theta)*np.sin(phi)*dtheta_by_dX1-np.sin(theta)*np.cos(phi)*dphi_by_dX1,\n            -np.sin(theta)*dtheta_by_dX1\n        )).T\n        dthetaunitvector_by_dX2 = np.vstack((\n            -np.cos(theta)*np.cos(phi)*dtheta_by_dX2+np.sin(theta)*np.sin(phi)*dphi_by_dX2,\n            -np.cos(theta)*np.sin(phi)*dtheta_by_dX2-np.sin(theta)*np.cos(phi)*dphi_by_dX2,\n            -np.sin(theta)*dtheta_by_dX2\n        )).T\n        dthetaunitvector_by_dX3 = np.vstack((\n            -np.cos(theta)*np.cos(phi)*dtheta_by_dX3+np.sin(theta)*np.sin(phi)*dphi_by_dX3,\n            -np.cos(theta)*np.sin(phi)*dtheta_by_dX3-np.sin(theta)*np.cos(phi)*dphi_by_dX3,\n            -np.sin(theta)*dtheta_by_dX3\n        )).T\n\n        dB_by_dX1_term1 = np.multiply(dthetaunitvector_by_dX1.T, r)\n        dB_by_dX2_term1 = np.multiply(dthetaunitvector_by_dX2.T, r)\n        dB_by_dX3_term1 = np.multiply(dthetaunitvector_by_dX3.T, r)\n\n        thetaUnitVector_1 = -np.sin(theta)*np.cos(phi)\n        thetaUnitVector_2 = -np.sin(theta)*np.sin(phi)\n        thetaUnitVector_3 = np.cos(theta)\n\n        dr_by_dX1 = (x*(-self.R0+np.sqrt(x**2+y**2)))/(np.sqrt(x**2+y**2)*np.sqrt((self.R0-np.sqrt(x**2+y**2))**2+z**2))\n        dr_by_dX2 = (y*(-self.R0+np.sqrt(x**2+y**2)))/(np.sqrt(x**2+y**2)*np.sqrt((self.R0-np.sqrt(x**2+y**2))**2+z**2))\n        dr_by_dX3 = z/np.sqrt((self.R0-np.sqrt(x**2+y**2))**2+z**2)\n\n        dB_by_dX1_term2 = np.vstack((\n            thetaUnitVector_1*dr_by_dX1,\n            thetaUnitVector_2*dr_by_dX1,\n            thetaUnitVector_3*dr_by_dX1))\n        dB_by_dX2_term2 = np.vstack((\n            thetaUnitVector_1*dr_by_dX2,\n            thetaUnitVector_2*dr_by_dX2,\n            thetaUnitVector_3*dr_by_dX2))\n        dB_by_dX3_term2 = np.vstack((\n            thetaUnitVector_1*dr_by_dX3,\n            thetaUnitVector_2*dr_by_dX3,\n            thetaUnitVector_3*dr_by_dX3))\n\n        dB[:] = self.B0/self.R0/self.q*np.array([dB_by_dX1_term1+dB_by_dX1_term2, dB_by_dX2_term1+dB_by_dX2_term2, dB_by_dX3_term1+dB_by_dX3_term2]).T",
  "def as_dict(self, serial_objs_dict) -> dict:\n        d = super().as_dict(serial_objs_dict=serial_objs_dict)\n        d[\"points\"] = self.get_points_cart()\n        return d",
  "def from_dict(cls, d, serial_objs_dict, recon_objs):\n        field = cls(d[\"R0\"], d[\"B0\"], d[\"q\"])\n        decoder = GSONDecoder()\n        xyz = decoder.process_decoded(d[\"points\"], serial_objs_dict, recon_objs)\n        field.set_points_cart(xyz)\n        return field",
  "def __init__(self, phi_str):\n        MagneticField.__init__(self)\n        if not sympy_found:\n            raise RuntimeError(\"Sympy is required for the ScalarPotentialRZMagneticField class\")\n        self.phi_str = phi_str\n        self.phi_parsed = parse_expr(phi_str)\n        R, Z, Phi = sp.symbols('R Z phi')\n        self.Blambdify = sp.lambdify((R, Z, Phi), [self.phi_parsed.diff(R)+1e-30*Phi*R*Z, \\\n                                                   self.phi_parsed.diff(Phi)/R+1e-30*Phi*R*Z, \\\n                                                   self.phi_parsed.diff(Z)+1e-30*Phi*R*Z])\n        self.dBlambdify_by_dX = sp.lambdify(\n            (R, Z, Phi),\n            [[1e-30*Phi*R*Z+sp.cos(Phi)*self.phi_parsed.diff(R).diff(R)-(sp.sin(Phi)/R)*self.phi_parsed.diff(R).diff(Phi),\n              1e-30*Phi*R*Z+sp.cos(Phi)*(self.phi_parsed.diff(Phi)/R).diff(R)-(sp.sin(Phi)/R)*(self.phi_parsed.diff(Phi)/R).diff(Phi),\n              1e-30*Phi*R*Z+sp.cos(Phi)*self.phi_parsed.diff(Z).diff(R)-(sp.sin(Phi)/R)*self.phi_parsed.diff(Z).diff(Phi)],\n             [1e-30*Phi*R*Z+sp.sin(Phi)*self.phi_parsed.diff(R).diff(R)+(sp.cos(Phi)/R)*self.phi_parsed.diff(R).diff(Phi),\n              1e-30*Phi*R*Z+sp.sin(Phi)*(self.phi_parsed.diff(Phi)/R).diff(R)+(sp.cos(Phi)/R)*(self.phi_parsed.diff(Phi)/R).diff(Phi),\n              1e-30*Phi*R*Z+sp.sin(Phi)*self.phi_parsed.diff(Z).diff(R)+(sp.cos(Phi)/R)*self.phi_parsed.diff(Z).diff(Phi)],\n             [1e-30*Phi*R*Z+self.phi_parsed.diff(R).diff(Z),\n              1e-30*Phi*R*Z+(self.phi_parsed.diff(Phi)/R).diff(Z),\n              1e-30*Phi*R*Z+self.phi_parsed.diff(Z).diff(Z)]])",
  "def _B_impl(self, B):\n        points = self.get_points_cart_ref()\n        r = np.sqrt(np.square(points[:, 0]) + np.square(points[:, 1]))\n        z = points[:, 2]\n        phi = np.arctan2(points[:, 1], points[:, 0])\n        B_cyl = np.array(self.Blambdify(r, z, phi)).T\n        # Bx = Br cos(phi) - Bphi sin(phi)\n        B[:, 0] = B_cyl[:, 0] * np.cos(phi) - B_cyl[:, 1] * np.sin(phi)\n        # By = Br sin(phi) + Bphi cos(phi)\n        B[:, 1] = B_cyl[:, 0] * np.sin(phi) + B_cyl[:, 1] * np.cos(phi)\n        B[:, 2] = B_cyl[:, 2]",
  "def _dB_by_dX_impl(self, dB):\n        points = self.get_points_cart_ref()\n        r = np.sqrt(np.square(points[:, 0]) + np.square(points[:, 1]))\n        z = points[:, 2]\n        phi = np.arctan2(points[:, 1], points[:, 0])\n        dB_cyl = np.array(self.dBlambdify_by_dX(r, z, phi)).transpose((2, 0, 1))\n        dBrdx = dB_cyl[:, 0, 0]\n        dBrdy = dB_cyl[:, 1, 0]\n        dBrdz = dB_cyl[:, 2, 0]\n        dBphidx = dB_cyl[:, 0, 1]\n        dBphidy = dB_cyl[:, 1, 1]\n        dBphidz = dB_cyl[:, 2, 1]\n        dB[:, 0, 2] = dB_cyl[:, 0, 2]\n        dB[:, 1, 2] = dB_cyl[:, 1, 2]\n        dB[:, 2, 2] = dB_cyl[:, 2, 2]\n        dcosphidx = -points[:, 0]**2/r**3 + 1/r\n        dsinphidx = -points[:, 0]*points[:, 1]/r**3\n        dcosphidy = -points[:, 0]*points[:, 1]/r**3\n        dsinphidy = -points[:, 1]**2/r**3 + 1/r\n        B_cyl = np.array(self.Blambdify(r, z, phi)).T\n        Br = B_cyl[:, 0]\n        Bphi = B_cyl[:, 1]\n        # Bx = Br cos(phi) - Bphi sin(phi)\n        dB[:, 0, 0] = dBrdx * np.cos(phi) + Br * dcosphidx - dBphidx * np.sin(phi) \\\n            - Bphi * dsinphidx\n        dB[:, 1, 0] = dBrdy * np.cos(phi) + Br * dcosphidy - dBphidy * np.sin(phi) \\\n            - Bphi * dsinphidy\n        dB[:, 2, 0] = dBrdz * np.cos(phi) - dBphidz * np.sin(phi)\n        # By = Br sin(phi) + Bphi cos(phi)\n        dB[:, 0, 1] = dBrdx * np.sin(phi) + Br * dsinphidx + dBphidx * np.cos(phi) \\\n            + Bphi * dcosphidx\n        dB[:, 1, 1] = dBrdy * np.sin(phi) + Br * dsinphidy + dBphidy * np.cos(phi) \\\n            + Bphi * dcosphidy\n        dB[:, 2, 1] = dBrdz * np.sin(phi) + dBphidz * np.cos(phi)",
  "def as_dict(self, serial_objs_dict) -> dict:\n        d = super().as_dict(serial_objs_dict=serial_objs_dict)\n        d[\"points\"] = self.get_points_cart()\n        return d",
  "def from_dict(cls, d, serial_objs_dict, recon_objs):\n        field = cls(d[\"phi_str\"])\n        decoder = GSONDecoder()\n        xyz = decoder.process_decoded(d[\"points\"], serial_objs_dict, recon_objs)\n        field.set_points_cart(xyz)\n        return field",
  "def __init__(self, r0=0.1, center=[0, 0, 0], I=5e5/np.pi, normal=[0, 0]):\n        MagneticField.__init__(self)\n        self.r0 = r0\n        self.Inorm = I*4e-7\n        self.center = center\n        self.normal = normal\n        if len(normal) == 2:\n            theta = normal[0]\n            phi = normal[1]\n        else:\n            theta = np.arctan2(normal[1], normal[0])\n            phi = np.arctan2(np.sqrt(normal[0]**2+normal[1]**2), normal[2])\n\n        self.rotMatrix = np.array([\n            [np.cos(phi) * np.cos(theta)**2 + np.sin(theta)**2,\n             -np.sin(phi / 2)**2 * np.sin(2 * theta),\n             np.cos(theta) * np.sin(phi)],\n            [-np.sin(phi / 2)**2 * np.sin(2 * theta),\n             np.cos(theta)**2 + np.cos(phi) * np.sin(theta)**2,\n             np.sin(phi) * np.sin(theta)],\n            [-np.cos(theta) * np.sin(phi),\n             -np.sin(phi) * np.sin(theta),\n             np.cos(phi)]\n        ])\n\n        self.rotMatrixInv = np.array(self.rotMatrix.T)",
  "def I(self):\n        return self.Inorm * 25e5",
  "def _B_impl(self, B):\n        points = self.get_points_cart_ref()\n        points = np.array(np.dot(self.rotMatrixInv, np.array(np.subtract(points, self.center)).T).T)\n        rho = np.sqrt(np.square(points[:, 0]) + np.square(points[:, 1]))\n        r = np.sqrt(np.square(points[:, 0]) + np.square(points[:, 1]) + np.square(points[:, 2]))\n        alpha = np.sqrt(self.r0**2 + np.square(r) - 2*self.r0*rho)\n        beta = np.sqrt(self.r0**2 + np.square(r) + 2*self.r0*rho)\n        k = np.sqrt(1-np.divide(np.square(alpha), np.square(beta)))\n        ellipek2 = ellipe(k**2)\n        ellipkk2 = ellipk(k**2)\n        gamma = np.square(points[:, 0]) - np.square(points[:, 1])\n        B[:] = np.dot(self.rotMatrix, np.array(\n            [self.Inorm*points[:, 0]*points[:, 2]/(2*alpha**2*beta*rho**2+1e-31)*((self.r0**2+r**2)*ellipek2-alpha**2*ellipkk2),\n             self.Inorm*points[:, 1]*points[:, 2]/(2*alpha**2*beta*rho**2+1e-31)*((self.r0**2+r**2)*ellipek2-alpha**2*ellipkk2),\n             self.Inorm/(2*alpha**2*beta+1e-31)*((self.r0**2-r**2)*ellipek2+alpha**2*ellipkk2)])).T",
  "def _dB_by_dX_impl(self, dB):\n        points = self.get_points_cart_ref()\n        points = np.array(np.dot(self.rotMatrixInv, np.array(np.subtract(points, self.center)).T).T)\n        rho = np.sqrt(np.square(points[:, 0]) + np.square(points[:, 1]))\n        r = np.sqrt(np.square(points[:, 0]) + np.square(points[:, 1]) + np.square(points[:, 2]))\n        alpha = np.sqrt(self.r0**2 + np.square(r) - 2*self.r0*rho)\n        beta = np.sqrt(self.r0**2 + np.square(r) + 2*self.r0*rho)\n        k = np.sqrt(1-np.divide(np.square(alpha), np.square(beta)))\n        ellipek2 = ellipe(k**2)\n        ellipkk2 = ellipk(k**2)\n        gamma = np.square(points[:, 0]) - np.square(points[:, 1])\n        dBxdx = (self.Inorm*points[:, 2]*(\n            ellipkk2*alpha**2*((2*points[:, 0]**4 + gamma*(\n                points[:, 1]**2 + points[:, 2]**2))*r**2 + self.r0**2*(\n                    gamma*(self.r0**2 + 2*points[:, 2]**2) - (3*points[:, 0]**2 - 2*points[:, 1]**2)*rho**2))\n            + ellipek2*(-((2*points[:, 0]**4 + gamma*(points[:, 1]**2 + points[:, 2]**2))*r**4)\n                        + self.r0**4*(-(gamma*(self.r0**2 + 3*points[:, 2]**2)) + (8*points[:, 0]**2 - points[:, 1]**2)*rho**2)\n                        - self.r0**2*(\n                            3*gamma*points[:, 2]**4 - 2*(2*points[:, 0]**2 + points[:, 1]**2)*points[:, 2]**2 * rho**2\n                            + (5*points[:, 0]**2 + points[:, 1]**2)*rho**4\n            ))\n        ))/(2*alpha**4*beta**3*rho**4+1e-31)\n\n        dBydx = (self.Inorm*points[:, 0]*points[:, 1]*points[:, 2]*(\n            ellipkk2*alpha**2*(\n                2*self.r0**4 + r**2*(2*r**2 + rho**2) - self.r0**2*(-4*points[:, 2]**2 + 5*rho**2))\n            + ellipek2*(-2*self.r0**6 - r**4*(2*r**2 + rho**2) + 3*self.r0**4*(-2*points[:, 2]**2 + 3*rho**2) - 2*self.r0**2*(3*points[:, 2]**4 - points[:, 2]**2*rho**2 + 2*rho**4))\n        ))/(2*alpha**4*beta**3*rho**4+1e-31)\n\n        dBzdx = (self.Inorm*points[:, 0]*(\n            - (ellipkk2*alpha**2*((-self.r0**2 + rho**2)**2 + points[:, 2]**2*(self.r0**2 + rho**2)))\n            + ellipek2*(\n                points[:, 2]**4*(self.r0**2 + rho**2) + (-self.r0**2 + rho**2)**2*(self.r0**2 + rho**2)\n                + 2*points[:, 2]**2*(self.r0**4 - 6*self.r0**2*rho**2 + rho**4))\n        ))/(2*alpha**4*beta**3*rho**2+1e-31)\n        dBxdy = dBydx\n\n        dBydy = (self.Inorm*points[:, 2]*(\n            ellipkk2*alpha**2*((2*points[:, 1]**4 - gamma*(points[:, 0]**2 + points[:, 2]**2))*r**2 +\n                               self.r0**2*(-(gamma*(self.r0**2 + 2*points[:, 2]**2)) - (-2*points[:, 0]**2 + 3*points[:, 1]**2)*rho**2)) +\n            ellipek2*(-((2*points[:, 1]**4 - gamma*(points[:, 0]**2 + points[:, 2]**2))*r**4) +\n                      self.r0**4*(gamma*(self.r0**2 + 3*points[:, 2]**2) + (-points[:, 0]**2 + 8*points[:, 1]**2)*rho**2) -\n                      self.r0**2*(-3*gamma*points[:, 2]**4 - 2*(points[:, 0]**2 + 2*points[:, 1]**2)*points[:, 2]**2*rho**2 +\n                                  (points[:, 0]**2 + 5*points[:, 1]**2)*rho**4))))/(2*alpha**4*beta**3*rho**4+1e-31)\n\n        dBzdy = dBzdx*points[:, 1]/(points[:, 0]+1e-31)\n\n        dBxdz = dBzdx\n\n        dBydz = dBzdy\n\n        dBzdz = (self.Inorm*points[:, 2]*(ellipkk2*alpha**2*(self.r0**2 - r**2) +\n                                          ellipek2*(-7*self.r0**4 + r**4 + 6*self.r0**2*(-points[:, 2]**2 + rho**2))))/(2*alpha**4*beta**3+1e-31)\n\n        dB_by_dXm = np.array([\n            [dBxdx, dBydx, dBzdx],\n            [dBxdy, dBydy, dBzdy],\n            [dBxdz, dBydz, dBzdz]])\n\n        dB[:] = np.array([\n            [np.dot(self.rotMatrixInv[:, 0], np.dot(self.rotMatrix[0, :], dB_by_dXm)),\n             np.dot(self.rotMatrixInv[:, 1], np.dot(self.rotMatrix[0, :], dB_by_dXm)),\n             np.dot(self.rotMatrixInv[:, 2], np.dot(self.rotMatrix[0, :], dB_by_dXm))],\n            [np.dot(self.rotMatrixInv[:, 0], np.dot(self.rotMatrix[1, :], dB_by_dXm)),\n             np.dot(self.rotMatrixInv[:, 1], np.dot(self.rotMatrix[1, :], dB_by_dXm)),\n             np.dot(self.rotMatrixInv[:, 2], np.dot(self.rotMatrix[1, :], dB_by_dXm))],\n            [np.dot(self.rotMatrixInv[:, 0], np.dot(self.rotMatrix[2, :], dB_by_dXm)),\n             np.dot(self.rotMatrixInv[:, 1], np.dot(self.rotMatrix[2, :], dB_by_dXm)),\n             np.dot(self.rotMatrixInv[:, 2], np.dot(self.rotMatrix[2, :], dB_by_dXm))]]).T",
  "def _A_impl(self, A):\n        points = self.get_points_cart_ref()\n        points = np.array(np.dot(self.rotMatrixInv, np.array(np.subtract(points, self.center)).T).T)\n        rho = np.sqrt(np.square(points[:, 0]) + np.square(points[:, 1]))\n        r = np.sqrt(np.square(points[:, 0]) + np.square(points[:, 1]) + np.square(points[:, 2]))\n        alpha = np.sqrt(self.r0**2 + np.square(r) - 2*self.r0*rho)\n        beta = np.sqrt(self.r0**2 + np.square(r) + 2*self.r0*rho)\n        k = np.sqrt(1-np.divide(np.square(alpha), np.square(beta)))\n        ellipek2 = ellipe(k**2)\n        ellipkk2 = ellipk(k**2)\n\n        num = (2*self.r0+np.sqrt(points[:, 0]**2+points[:, 1]**2)*ellipek2+(self.r0**2+points[:, 0]**2+points[:, 1]**2+points[:, 2]**2)*(ellipe(k**2)-ellipkk2))\n        denom = ((points[:, 0]**2+points[:, 1]**2+1e-31)*np.sqrt(self.r0**2+points[:, 0]**2+points[:, 1]**2+2*self.r0*np.sqrt(points[:, 0]**2+points[:, 1]**2)+points[:, 2]**2+1e-31))\n        fak = num/denom\n        pts = fak[:, None]*np.concatenate((-points[:, 1][:, None], points[:, 0][:, None], np.zeros((points.shape[0], 1))), axis=-1)\n        A[:] = -self.Inorm/2*np.dot(self.rotMatrix, pts.T).T",
  "def as_dict(self, serial_objs_dict):\n        d = super().as_dict(serial_objs_dict=serial_objs_dict)\n        d[\"points\"] = self.get_points_cart()\n        return d",
  "def from_dict(cls, d, serial_objs_dict, recon_objs):\n        field = cls(d[\"r0\"], d[\"center\"], d[\"I\"], d[\"normal\"])\n        decoder = GSONDecoder()\n        xyz = decoder.process_decoded(d[\"points\"], serial_objs_dict, recon_objs)\n        field.set_points_cart(xyz)\n        return field",
  "def __init__(self, dipole_grid, dipole_vectors, stellsym=True, nfp=1, coordinate_flag='cartesian', m_maxima=None, R0=1):\n        super().__init__()        \n        if coordinate_flag == 'toroidal':\n            warnings.warn('Note that if using simple toroidal coordinates, '\n                          'the major radius must be specified through R0 argument.')\n        self.R0 = R0\n        self._dipole_fields_from_symmetries(dipole_grid, dipole_vectors, stellsym, nfp, coordinate_flag, m_maxima, R0)",
  "def _B_impl(self, B):\n        points = self.get_points_cart_ref()\n        B[:] = sopp.dipole_field_B(points, self.dipole_grid, self.m_vec)",
  "def _dB_by_dX_impl(self, dB):\n        points = self.get_points_cart_ref()\n        dB[:] = sopp.dipole_field_dB(points, self.dipole_grid, self.m_vec)",
  "def _A_impl(self, A):\n        points = self.get_points_cart_ref()\n        A[:] = sopp.dipole_field_A(points, self.dipole_grid, self.m_vec)",
  "def _dA_by_dX_impl(self, dA):\n        points = self.get_points_cart_ref()\n        dA[:] = sopp.dipole_field_dA(points, self.dipole_grid, self.m_vec)",
  "def _dipole_fields_from_symmetries(self, dipole_grid, dipole_vectors, stellsym=True, nfp=1, coordinate_flag='cartesian', m_maxima=None, R0=1):\n        \"\"\"\n        Takes the dipoles and grid initialized in a PermanentMagnetOptimizer (for a half-period surface)\n        and generates the full dipole manifold so that the call to B() (the magnetic field from\n        the dipoles) correctly returns contributions from all the dipoles from symmetries.\n        \"\"\"\n        self.dipole_grid = dipole_grid\n\n        # Read in the required fields from pm_opt object\n        ndipoles = dipole_grid.shape[0]\n        if m_maxima is None:\n            m_maxima = np.max(np.linalg.norm(dipole_vectors, axis=-1)) * np.ones(ndipoles)\n        if stellsym:\n            stell_list = [1, -1]\n            nsym = nfp * 2\n        else:\n            stell_list = [1]\n            nsym = nfp\n        m = dipole_vectors.reshape(ndipoles, 3)\n\n        # Initialize new grid and dipole vectors for all the dipoles\n        # after we account for the symmetries below.\n        dipole_grid_x = np.zeros(ndipoles * nsym)\n        dipole_grid_y = np.zeros(ndipoles * nsym)\n        dipole_grid_z = np.zeros(ndipoles * nsym)\n        m_vec = np.zeros((ndipoles * nsym, 3))\n        m_max = np.zeros(ndipoles * nsym)\n\n        # Load in the dipole locations for a half-period surface\n        ox = dipole_grid[:, 0]\n        oy = dipole_grid[:, 1]\n        oz = dipole_grid[:, 2]\n\n        # loop through the dipoles and repeat for fp and stellarator symmetries\n        index = 0\n        n = ndipoles\n\n        # get the components in Cartesian, converting if needed\n        mmx = m[:, 0]\n        mmy = m[:, 1]\n        mmz = m[:, 2]\n        if coordinate_flag == 'cylindrical':\n            phi_dipole = np.arctan2(oy, ox)\n            mmx_temp = mmx * np.cos(phi_dipole) - mmy * np.sin(phi_dipole)\n            mmy_temp = mmx * np.sin(phi_dipole) + mmy * np.cos(phi_dipole)\n            mmx = mmx_temp\n            mmy = mmy_temp\n        if coordinate_flag == 'toroidal':\n            phi_dipole = np.arctan2(oy, ox)\n            theta_dipole = np.arctan2(oz, np.sqrt(ox ** 2 + oy ** 2) - R0)\n            mmx_temp = mmx * np.cos(phi_dipole) * np.cos(theta_dipole) - mmy * np.sin(phi_dipole) - mmz * np.cos(phi_dipole) * np.sin(theta_dipole)\n            mmy_temp = mmx * np.sin(phi_dipole) * np.cos(theta_dipole) + mmy * np.cos(phi_dipole) - mmz * np.sin(phi_dipole) * np.sin(theta_dipole)\n            mmz_temp = mmx * np.sin(theta_dipole) + mmz * np.cos(theta_dipole)\n            mmx = mmx_temp\n            mmy = mmy_temp\n            mmz = mmz_temp\n\n        # Loop over stellarator and field-period symmetry contributions\n        for stell in stell_list:\n            for fp in range(nfp):\n                phi0 = (2 * np.pi / nfp) * fp\n\n                # get new dipoles locations by flipping the y and z components, then rotating by phi0\n                dipole_grid_x[index:index + n] = ox * np.cos(phi0) - oy * np.sin(phi0) * stell\n                dipole_grid_y[index:index + n] = ox * np.sin(phi0) + oy * np.cos(phi0) * stell\n                dipole_grid_z[index:index + n] = oz * stell\n\n                # get new dipole vectors by flipping the x component, then rotating by phi0\n                m_vec[index:index + n, 0] = mmx * np.cos(phi0) * stell - mmy * np.sin(phi0)\n                m_vec[index:index + n, 1] = mmx * np.sin(phi0) * stell + mmy * np.cos(phi0)\n                m_vec[index:index + n, 2] = mmz\n\n                m_max[index:index + n] = m_maxima\n                index += n\n\n        contig = np.ascontiguousarray\n        self.dipole_grid = contig(np.array([dipole_grid_x, dipole_grid_y, dipole_grid_z]).T)\n        self.m_vec = contig(m_vec)\n        self.m_maxima = contig(m_max)",
  "def _toVTK(self, vtkname):\n        \"\"\"\n            Write dipole data into a VTK file (acknowledgements to Caoxiang's CoilPy code).\n\n        Args:\n            vtkname (str): VTK filename, will be appended with .vts or .vtu.\n        \"\"\"\n\n        # get the coordinates\n        ox = np.ascontiguousarray(self.dipole_grid[:, 0])\n        oy = np.ascontiguousarray(self.dipole_grid[:, 1])\n        oz = np.ascontiguousarray(self.dipole_grid[:, 2])\n        ophi = np.arctan2(oy, ox)\n        otheta = np.arctan2(oz, np.sqrt(ox ** 2 + oy ** 2) - self.R0)\n\n        # define the m vectors and the normalized m vectors\n        # in Cartesian, cylindrical, and simple toroidal coordinates.\n        mx = np.ascontiguousarray(self.m_vec[:, 0])\n        my = np.ascontiguousarray(self.m_vec[:, 1])\n        mz = np.ascontiguousarray(self.m_vec[:, 2])\n        mmag = np.sqrt(mx ** 2 + my ** 2 + mz ** 2)\n        mx_normalized = np.ascontiguousarray(mx / self.m_maxima)\n        my_normalized = np.ascontiguousarray(my / self.m_maxima)\n        mz_normalized = np.ascontiguousarray(mz / self.m_maxima)\n        mr = np.ascontiguousarray(mx * np.cos(ophi) + my * np.sin(ophi))\n        mrminor = np.ascontiguousarray(mx * np.cos(ophi) * np.cos(otheta) + my * np.sin(ophi) * np.cos(otheta) + np.sin(otheta) * mz)\n        mphi = np.ascontiguousarray(-mx * np.sin(ophi) + my * np.cos(ophi))\n        mtheta = np.ascontiguousarray(-mx * np.cos(ophi) * np.sin(otheta) - my * np.sin(ophi) * np.sin(otheta) + np.cos(otheta) * mz)\n        mr_normalized = np.ascontiguousarray(mr / self.m_maxima)\n        mrminor_normalized = np.ascontiguousarray(mrminor / self.m_maxima)\n        mphi_normalized = np.ascontiguousarray(mphi / self.m_maxima)\n        mtheta_normalized = np.ascontiguousarray(mtheta / self.m_maxima)\n\n        # Save all the data to a vtk file which can be visualized nicely with ParaView\n        data = {\"m\": (mx, my, mz), \"m_normalized\": (mx_normalized, my_normalized, mz_normalized), \"m_rphiz\": (mr, mphi, mz), \"m_rphiz_normalized\": (mr_normalized, mphi_normalized, mz_normalized), \"m_rphitheta\": (mrminor, mphi, mtheta), \"m_rphitheta_normalized\": (mrminor_normalized, mphi_normalized, mtheta_normalized)}\n        from pyevtk.hl import pointsToVTK\n        pointsToVTK(\n            str(vtkname), ox, oy, oz, data=data\n        )",
  "def __init__(self, mn=[[0, 0]], coeffs=[[0, 0]]):\n        MagneticField.__init__(self)\n        self.m = np.array(mn, dtype=np.int16)[:, 0]\n        self.n = np.array(mn, dtype=np.int16)[:, 1]\n        self.coeffs = coeffs\n        self.Btor = ToroidalField(1, 1)",
  "def _set_points_cb(self):\n        self.Btor.set_points_cart(self.get_points_cart_ref())",
  "def _B_impl(self, B):\n        points = self.get_points_cart_ref()\n        B[:] = np.add.reduce(sopp.DommaschkB(self.m, self.n, self.coeffs, points))+self.Btor.B()",
  "def _dB_by_dX_impl(self, dB):\n        points = self.get_points_cart_ref()\n        dB[:] = np.add.reduce(sopp.DommaschkdB(self.m, self.n, self.coeffs, points))+self.Btor.dB_by_dX()",
  "def mn(self):\n        return np.column_stack((self.m, self.n))",
  "def as_dict(self, serial_objs_dict) -> dict:\n        d = super().as_dict(serial_objs_dict=serial_objs_dict)\n        d[\"points\"] = self.get_points_cart()\n        return d",
  "def from_dict(cls, d, serial_objs_dict, recon_objs):\n        decoder = GSONDecoder()\n        mn = decoder.process_decoded(d[\"mn\"], serial_objs_dict, recon_objs)\n        field = cls(mn, d[\"coeffs\"])\n        xyz = decoder.process_decoded(d[\"points\"], serial_objs_dict, recon_objs)\n        field.set_points_cart(xyz)\n        return field",
  "def __init__(self, iota0=0.15, iota1=0.38, k=[6], epsilonk=[0.01], m0=1):\n        MagneticField.__init__(self)\n        self.iota0 = iota0\n        self.iota1 = iota1\n        self.k = k\n        self.epsilonk = epsilonk\n        self.m0 = m0",
  "def _B_impl(self, B):\n        points = self.get_points_cart_ref()\n        B[:] = sopp.ReimanB(self.iota0, self.iota1, self.k, self.epsilonk, self.m0, points)",
  "def _dB_by_dX_impl(self, dB):\n        points = self.get_points_cart_ref()\n        dB[:] = sopp.ReimandB(self.iota0, self.iota1, self.k, self.epsilonk, self.m0, points)",
  "def as_dict(self, serial_objs_dict):\n        d = super().as_dict(serial_objs_dict=serial_objs_dict)\n        d[\"points\"] = self.get_points_cart()\n        return d",
  "def from_dict(cls, d, serial_objs_dict, recon_objs):\n        field = cls(d[\"iota0\"], d[\"iota1\"], d[\"k\"], d[\"epsilonk\"], d[\"m0\"])\n        decoder = GSONDecoder()\n        xyz = decoder.process_decoded(d[\"points\"], serial_objs_dict, recon_objs)\n        field.set_points_cart(xyz)\n        return field",
  "def __init__(self, field, degree, rrange, phirange, zrange, extrapolate=True, nfp=1, stellsym=False, skip=None):\n        r\"\"\"\n        Args:\n            field: the underlying :mod:`simsopt.field.magneticfield.MagneticField` to be interpolated.\n            degree: the degree of the piecewise polynomial interpolant.\n            rrange: a 3-tuple of the form ``(rmin, rmax, nr)``. This mean that the interval :math:`[rmin, rmax]` is\n                    split into ``nr`` many subintervals.\n            phirange: a 3-tuple of the form ``(phimin, phimax, nphi)``.\n            zrange: a 3-tuple of the form ``(zmin, zmax, nz)``.\n            extrapolate: whether to extrapolate the field when evaluate outside\n                         the integration domain or to throw an error.\n            nfp: Whether to exploit rotational symmetry. In this case any angle\n                 is always mapped into the interval :math:`[0, 2\\pi/\\mathrm{nfp})`,\n                 hence it makes sense to use ``phimin=0`` and\n                 ``phimax=2*np.pi/nfp``.\n            stellsym: Whether to exploit stellarator symmetry. In this case\n                      ``z`` is always mapped to be positive, hence it makes sense to use\n                      ``zmin=0``.\n            skip: a function that takes in a point (in cylindrical (r,phi,z)\n                  coordinates) and returns whether to skip that location when\n                  building the interpolant or not. The signature should be\n\n                  .. code-block:: Python\n\n                      def skip(r: double, phi: double, z: double) -> bool:\n                          ...\n\n                  See also here\n                  https://github.com/hiddenSymmetries/simsopt/pull/227 for a\n                  graphical illustration.\n\n        \"\"\"\n        MagneticField.__init__(self)\n        if stellsym and zrange[0] != 0:\n            logger.warning(fr\"Sure about zrange[0]={zrange[0]}? When exploiting stellarator symmetry, the interpolant is never evaluated for z<0.\")\n        if nfp > 1 and abs(phirange[1] - 2*np.pi/nfp) > 1e-14:\n            logger.warning(fr\"Sure about phirange[1]={phirange[1]}? When exploiting rotational symmetry, the interpolant is never evaluated for phi>2\\pi/nfp.\")\n\n        if skip is None:\n            def skip(xs, ys, zs):\n                return [False for _ in xs]\n\n        sopp.InterpolatedField.__init__(self, field, degree, rrange, phirange, zrange, extrapolate, nfp, stellsym, skip)\n        self.__field = field",
  "def to_vtk(self, filename):\n        \"\"\"Export the field evaluated on a regular grid for visualisation with e.g. Paraview.\"\"\"\n        degree = self.rule.degree\n        MagneticField.to_vtk(\n            self, filename,\n            nr=self.r_range[2]*degree+1,\n            nphi=self.phi_range[2]*degree+1,\n            nz=self.z_range[2]*degree+1,\n            rmin=self.r_range[0], rmax=self.r_range[1],\n            zmin=self.z_range[0], zmax=self.z_range[1]\n        )",
  "def __init__(self, B0=6.51292, gamma=0.124904, Z_m=0.98):\n        MagneticField.__init__(self)\n        self.B0 = B0\n        self.gamma = gamma\n        self.Z_m = Z_m",
  "def _psi(self, R, Z):\n        factor1 = 1+((Z-self.Z_m)/(self.gamma))**2\n        factor2 = 1+((Z+self.Z_m)/(self.gamma))**2\n        psi = (R*R*self.B0/(2*np.pi*self.gamma))*(1/factor1+1/factor2)\n        return psi",
  "def _B_impl(self, B):\n        points = self.get_points_cart_ref()\n        r = np.sqrt(np.square(points[:, 0]) + np.square(points[:, 1]))\n        z = points[:, 2]\n        phi = np.arctan2(points[:, 1], points[:, 0])\n        # BR = -(1/R)dpsi/dZ, BZ=(1/R)dpsi/dR\n        factor1 = (1+((z-self.Z_m)/(self.gamma))**2)**2\n        factor2 = (1+((z+self.Z_m)/(self.gamma))**2)**2\n        Br = (r*self.B0/(np.pi*self.gamma**3))*((z-self.Z_m)/factor1+(z+self.Z_m)/factor2)\n        Bz = self._psi(r, z)*2/r/r\n        B[:, 0] = Br * np.cos(phi)\n        B[:, 1] = Br * np.sin(phi)\n        B[:, 2] = Bz",
  "def _dB_by_dX_impl(self, dB):\n        points = self.get_points_cart_ref()\n        r = np.sqrt(np.square(points[:, 0]) + np.square(points[:, 1]))\n        z = points[:, 2]\n        phi = np.arctan2(points[:, 1], points[:, 0])\n\n        factor1 = (1+((z-self.Z_m)/(self.gamma))**2)**2\n        factor2 = (1+((z+self.Z_m)/(self.gamma))**2)**2\n        Br = (r*self.B0/(np.pi*self.gamma**3))*((z-self.Z_m)/factor1+(z+self.Z_m)/factor2)\n        # Bz = self._psi(r,z)*2/r/r\n        dBrdr = (self.B0/(np.pi*self.gamma**3))*((z-self.Z_m)/factor1+(z+self.Z_m)/factor2)\n        dBzdz = -2*dBrdr\n        dBrdz = (self.B0*r/(np.pi*self.gamma**3))*(1/factor1+1/factor2\n                                                   - 4*self.gamma**4*((z-self.Z_m)**2/((z-self.Z_m)**2+self.gamma**2)**3+(z+self.Z_m)**2/((z+self.Z_m)**2+self.gamma**2)**3))\n        cosphi = np.cos(phi)\n        sinphi = np.sin(phi)\n        dcosphidx = -points[:, 0]**2/r**3 + 1/r\n        dsinphidx = -points[:, 0]*points[:, 1]/r**3\n        dcosphidy = -points[:, 0]*points[:, 1]/r**3\n        dsinphidy = -points[:, 1]**2/r**3 + 1/r\n        drdx = points[:, 0]/r\n        drdy = points[:, 1]/r\n        dBxdx = dBrdr*drdx*cosphi + Br*dcosphidx\n        dBxdy = dBrdr*drdy*cosphi + Br*dcosphidy\n        dBxdz = dBrdz*cosphi\n        dBydx = dBrdr*drdx*sinphi + Br*dsinphidx\n        dBydy = dBrdr*drdy*sinphi + Br*dsinphidy\n        dBydz = dBrdz*sinphi\n\n        dB[:, 0, 0] = dBxdx\n        dB[:, 1, 0] = dBxdy\n        dB[:, 2, 0] = dBxdz\n        dB[:, 0, 1] = dBydx\n        dB[:, 1, 1] = dBydy\n        dB[:, 2, 1] = dBydz\n        dB[:, 0, 2] = 0\n        dB[:, 1, 2] = 0\n        dB[:, 2, 2] = dBzdz",
  "def as_dict(self, serial_objs_dict) -> dict:\n        d = super().as_dict(serial_objs_dict=serial_objs_dict)\n        d[\"points\"] = self.get_points_cart()\n        return d",
  "def from_dict(cls, d, serial_objs_dict, recon_objs):\n        field = cls(d[\"B0\"], d[\"gamma\"], d[\"Z_m\"])\n        decoder = GSONDecoder()\n        xyz = decoder.process_decoded(d[\"points\"], serial_objs_dict, recon_objs)\n        field.set_points_cart(xyz)\n        return field",
  "def skip(xs, ys, zs):\n                return [False for _ in xs]",
  "class BoozerMagneticField(sopp.BoozerMagneticField):\n    r\"\"\"\n    Generic class that represents a magnetic field in Boozer coordinates\n    :math:`(s,\\theta,\\zeta)`. Here :math:`s = \\psi/\\psi_0` is the normalized\n    toroidal flux where :math:`2\\pi\\psi_0` is the toroidal flux at the boundary.\n    The magnetic field in the covariant form is,\n\n    .. math::\n        \\textbf B(s,\\theta,\\zeta) = G(s) \\nabla \\zeta + I(s) \\nabla \\theta + K(s,\\theta,\\zeta) \\nabla \\psi,\n\n    and the contravariant form is,\n\n    .. math::\n        \\textbf B(s,\\theta,\\zeta) = \\frac{1}{\\sqrt{g}} \\left(\\frac{\\partial \\mathbf r}{\\partial \\zeta} + \\iota(s)\\frac{\\partial \\mathbf r}{\\partial \\theta}\\right),\n\n    where,\n\n    .. math::\n        \\sqrt{g}(s,\\theta,\\zeta) = \\frac{G(s) + \\iota(s)I(s)}{B^2}.\n\n    Here :math:`\\iota(s) = \\psi_P'(\\psi)` where :math:`2\\pi\\psi_P` is the\n    poloidal flux and :math:`2\\pi\\psi` is the toroidal flux. Each subclass of\n    :class:`BoozerMagneticField` implements functions to compute\n    :math:`B`, :math:`G`, :math:`I`, :math:`\\iota`, :math:`\\psi_P`, and their\n    derivatives. The cylindrical coordinates :math:`R(s,\\theta,\\zeta)` and\n    :math:`Z(s,\\theta,\\zeta)` in addition to :math:`K(s,\\theta,\\zeta)` and\n    :math:`\\nu` where :math:`\\zeta = \\phi + \\nu(s,\\theta,\\zeta)` and :math:`\\phi`\n    is the cylindrical azimuthal angle are also implemented by\n    :class:`BoozerRadialInterpolant` and :class:`InterpolatedBoozerField`.\n    The usage is similar to the :class:`MagneticField` class.\n\n    The usage of :class:`BoozerMagneticField`` is as follows:\n\n    .. code-block::\n\n        booz = BoozerAnalytic(etabar,B0,N,G0,psi0,iota0) # An instance of BoozerMagneticField\n        points = ... # points is a (n, 3) numpy array defining :math:`(s,\\theta,\\zeta)`\n        booz.set_points(points)\n        modB = bfield.modB() # returns the magnetic field strength at `points`\n\n    :class:`BoozerMagneticField` has a cache to avoid repeated calculations.\n    To clear this cache manually, call the :func:`clear_cached_properties()` function.\n    The cache is automatically cleared when :func:`set_points` is called or one of the dependencies\n    changes.\n    \"\"\"\n\n    def __init__(self, psi0):\n        self.psi0 = psi0\n        sopp.BoozerMagneticField.__init__(self, psi0)\n\n    def clear_cached_properties(self):\n        \"\"\"Clear the cache.\"\"\"\n        sopp.BoozerMagneticField.invalidate_cache(self)\n\n    def recompute_bell(self, parent=None):\n        if np.any(self.dofs_free_status):\n            self.clear_cached_properties()\n\n    def _modB_derivs_impl(self, modB_derivs):\n        self._dmodBds_impl(np.reshape(modB_derivs[:, 0], (len(modB_derivs[:, 0]), 1)))\n        self._dmodBdtheta_impl(np.reshape(modB_derivs[:, 1], (len(modB_derivs[:, 0]), 1)))\n        self._dmodBdzeta_impl(np.reshape(modB_derivs[:, 2], (len(modB_derivs[:, 0]), 1)))\n\n    def _K_derivs_impl(self, K_derivs):\n        self._dKdtheta_impl(np.reshape(K_derivs[:, 0], (len(K_derivs[:, 0]), 1)))\n        self._dKdzeta_impl(np.reshape(K_derivs[:, 1], (len(K_derivs[:, 0]), 1)))\n\n    def _nu_derivs_impl(self, nu_derivs):\n        self._dnuds_impl(np.reshape(nu_derivs[:, 0], (len(nu_derivs[:, 0]), 1)))\n        self._dnudtheta_impl(np.reshape(nu_derivs[:, 1], (len(nu_derivs[:, 0]), 1)))\n        self._dnudzeta_impl(np.reshape(nu_derivs[:, 2], (len(nu_derivs[:, 0]), 1)))\n\n    def _R_derivs_impl(self, R_derivs):\n        self._dRds_impl(np.reshape(R_derivs[:, 0], (len(R_derivs[:, 0]), 1)))\n        self._dRdtheta_impl(np.reshape(R_derivs[:, 1], (len(R_derivs[:, 0]), 1)))\n        self._dRdzeta_impl(np.reshape(R_derivs[:, 2], (len(R_derivs[:, 0]), 1)))\n\n    def _Z_derivs_impl(self, Z_derivs):\n        self._dZds_impl(np.reshape(Z_derivs[:, 0], (len(Z_derivs[:, 0]), 1)))\n        self._dZdtheta_impl(np.reshape(Z_derivs[:, 1], (len(Z_derivs[:, 0]), 1)))\n        self._dZdzeta_impl(np.reshape(Z_derivs[:, 2], (len(Z_derivs[:, 0]), 1)))",
  "class BoozerAnalytic(BoozerMagneticField):\n    r\"\"\"\n    Computes a :class:`BoozerMagneticField` based on a first-order expansion in\n    distance from the magnetic axis (Landreman & Sengupta, Journal of Plasma\n    Physics 2018). Here the magnetic field strength is expressed as,\n\n    .. math::\n        B(s,\\theta,\\zeta) = B_0 \\left(1 + \\overline{\\eta} \\sqrt{2s\\psi_0/\\overline{B}}\\cos(\\theta - N \\zeta)\\right),\n\n    the covariant components are,\n\n    .. math::\n        G(s) = G_0 + \\sqrt{2s\\psi_0/\\overline{B}} G_1\n\n        I(s) = I_0 + \\sqrt{2s\\psi_0/\\overline{B}} I_1\n\n        K(s,\\theta,\\zeta) = \\sqrt{2s\\psi_0/\\overline{B}} K_1 \\sin(\\theta - N \\zeta),\n\n    and the rotational transform is,\n\n    .. math::\n        \\iota(s) = \\iota_0.\n\n    While formally :math:`I_0 = I_1 = G_1 = K_1 = 0`, these terms have been included\n    in order to test the guiding center equations at finite beta.\n\n    Args:\n        etabar: magnitude of first order correction to magnetic field strength\n        B0: magnetic field strength on the axis\n        N: helicity of symmetry (integer)\n        G0: lowest order toroidal covariant component\n        psi0: (toroidal flux)/ (2*pi) on the boundary\n        iota0: lowest order rotational transform\n        Bbar: normalizing magnetic field strength (defaults to 1)\n        I0: lowest order poloidal covariant component (defaults to 0)\n        G1: first order correction to toroidal covariant component (defaults to 0)\n        I1: first order correction to poloidal covariant component (defaults to 0)\n        K1: first order correction to radial covariant component (defaults to 0)\n    \"\"\"\n\n    def __init__(self, etabar, B0, N, G0, psi0, iota0, Bbar=1., I0=0., G1=0.,\n                 I1=0., K1=0.):\n        self.etabar = etabar\n        self.B0 = B0\n        self.Bbar = Bbar\n        self.N = N\n        self.G0 = G0\n        self.I0 = I0\n        self.I1 = I1\n        self.G1 = G1\n        self.K1 = K1\n        self.iota0 = iota0\n        self.psi0 = psi0\n        BoozerMagneticField.__init__(self, psi0)\n\n    def set_etabar(self, etabar):\n        self.invalidate_cache()\n        self.etabar = etabar\n\n    def set_B0(self, B0):\n        self.invalidate_cache()\n        self.B0 = B0\n\n    def set_Bbar(self, Bbar):\n        self.invalidate_cache()\n        self.Bbar = Bbar\n\n    def set_N(self, N):\n        self.invalidate_cache()\n        self.N = N\n\n    def set_G0(self, G0):\n        self.invalidate_cache()\n        self.G0 = G0\n\n    def set_I0(self, I0):\n        self.invalidate_cache()\n        self.I0 = I0\n\n    def set_G1(self, G1):\n        self.invalidate_cache()\n        self.G1 = G1\n\n    def set_I1(self, I1):\n        self.invalidate_cache()\n        self.I1 = I1\n\n    def set_K1(self, K1):\n        self.invalidate_cache()\n        self.K1 = K1\n\n    def set_iota0(self, iota0):\n        self.invalidate_cache()\n        self.iota0 = iota0\n\n    def set_psi0(self, psi0):\n        self.invalidate_cache()\n        self.psi0 = psi0\n\n    def _psip_impl(self, psip):\n        points = self.get_points_ref()\n        s = points[:, 0]\n        psip[:, 0] = self.psi0*s*self.iota0\n\n    def _iota_impl(self, iota):\n        iota[:, 0] = self.iota0\n\n    def _diotads_impl(self, diotads):\n        diotads[:, 0] = 0\n\n    def _G_impl(self, G):\n        points = self.get_points_ref()\n        s = points[:, 0]\n        G[:, 0] = self.G0 + s*self.G1\n\n    def _dGds_impl(self, dGds):\n        dGds[:, 0] = self.G1\n\n    def _I_impl(self, I):\n        points = self.get_points_ref()\n        s = points[:, 0]\n        I[:, 0] = self.I0 + s*self.I1\n\n    def _dIds_impl(self, dIds):\n        dIds[:, 0] = self.I1\n\n    def _modB_impl(self, modB):\n        points = self.get_points_ref()\n        s = points[:, 0]\n        thetas = points[:, 1]\n        zetas = points[:, 2]\n        psi = s*self.psi0\n        r = np.sqrt(np.abs(2*psi/self.Bbar))\n        modB[:, 0] = self.B0*(1 + self.etabar*r*np.cos(thetas-self.N*zetas))\n\n    def _dmodBds_impl(self, dmodBds):\n        points = self.get_points_ref()\n        s = points[:, 0]\n        thetas = points[:, 1]\n        zetas = points[:, 2]\n        psi = s*self.psi0\n        r = np.sqrt(np.abs(2*psi/self.Bbar))\n        drdpsi = 0.5*r/psi\n        drds = drdpsi*self.psi0\n        dmodBds[:, 0] = self.B0*self.etabar*drds*np.cos(thetas-self.N*zetas)\n\n    def _dmodBdtheta_impl(self, dmodBdtheta):\n        points = self.get_points_ref()\n        s = points[:, 0]\n        thetas = points[:, 1]\n        zetas = points[:, 2]\n        psi = s*self.psi0\n        r = np.sqrt(np.abs(2*psi/self.Bbar))\n        dmodBdtheta[:, 0] = -self.B0*self.etabar*r*np.sin(thetas-self.N*zetas)\n\n    def _dmodBdzeta_impl(self, dmodBdzeta):\n        points = self.get_points_ref()\n        s = points[:, 0]\n        thetas = points[:, 1]\n        zetas = points[:, 2]\n        psi = s*self.psi0\n        r = np.sqrt(np.abs(2*psi/self.Bbar))\n        dmodBdzeta[:, 0] = self.N*self.B0*self.etabar*r*np.sin(thetas-self.N*zetas)\n\n    def _K_impl(self, K):\n        points = self.get_points_ref()\n        s = points[:, 0]\n        thetas = points[:, 1]\n        zetas = points[:, 2]\n        psi = s*self.psi0\n        r = np.sqrt(np.abs(2*psi/self.Bbar))\n        K[:, 0] = self.K1*r*np.sin(thetas-self.N*zetas)\n\n    def _dKdtheta_impl(self, dKdtheta):\n        points = self.get_points_ref()\n        s = points[:, 0]\n        thetas = points[:, 1]\n        zetas = points[:, 2]\n        psi = s*self.psi0\n        r = np.sqrt(np.abs(2*psi/self.Bbar))\n        dKdtheta[:, 0] = self.K1*r*np.cos(thetas-self.N*zetas)\n\n    def _dKdzeta_impl(self, dKdzeta):\n        points = self.get_points_ref()\n        s = points[:, 0]\n        thetas = points[:, 1]\n        zetas = points[:, 2]\n        psi = s*self.psi0\n        r = np.sqrt(np.abs(2*psi/self.Bbar))\n        dKdzeta[:, 0] = -self.N*self.K1*r*np.cos(thetas-self.N*zetas)",
  "class BoozerRadialInterpolant(BoozerMagneticField):\n    r\"\"\"\n    Given a :class:`Vmec` instance, performs a Boozer coordinate transformation using\n    ``BOOZXFORM``.\n    The magnetic field can be computed at any point in Boozer\n    coordinates using radial spline interpolation (``scipy.interpolate.InterpolatedUnivariateSpline``)\n    and an inverse Fourier transform in the two angles.\n    Throughout stellarator symmetry is assumed.\n\n    Args:\n        equil: instance of :class:`simsopt.mhd.vmec.Vmec` or :class:`simsopt.mhd.boozer.Boozer`.\n            If it is an instance of :class:`simsopt.mhd.boozer.Boozer`, the\n            `compute_surfs` needs to include all of the grid points in the\n            half-radius grid of the corresponding Vmec equilibrium.\n        order: (int) order for radial interpolation. Must satisfy 1 <= order <= 5.\n        mpol: (int) number of poloidal mode numbers for BOOZXFORM (defaults to 32)\n        ntor: (int) number of toroidal mode numbers for BOOZXFORM (defaults to 32)\n        N: Helicity of quasisymmetry to enforce. If specified, then the non-symmetric Fourier\n            harmonics of :math:`B` and :math:`K` are filtered out. Otherwise, all harmonics are kept.\n            (defaults to ``None``)\n        enforce_vacuum: If True, a vacuum field is assumed, :math:`G` is\n            set to its mean value, :math:`I = 0`, and :math:`K = 0`.\n        rescale: If True, use the interpolation method in the DELTA5D code. Here, a few\n            of the first radial grid points or (``bmnc``, ``rmnc``, ``zmns``, ``numns``, ``kmns``)\n            are deleted (determined by ``ns_delete``). The Fourier harmonics are then rescaled as:\n\n            bmnc(s)/s^(1/2) for m = 1\n\n            bmnc(s)/s for m even and >= 2\n\n            bmnc(s)/s^(3/2) for m odd and >=3\n\n            before performing interpolation and spline differentiation to\n            obtain ``dbmncds``. If ``False``, interpolation of the unscaled Fourier\n            harmonics and its finite-difference derivative wrt ``s`` is performed\n            instead (defaults to ``False``)\n        ns_delete: (see ``rescale``) (defaults to 0)\n    \"\"\"\n\n    def __init__(self, equil, order, mpol=32, ntor=32, N=None, enforce_vacuum=False, rescale=False,\n                 ns_delete=0, no_K=False):\n\n        if isinstance(equil, Vmec):\n            equil.run()\n            self.booz = Boozer(equil, mpol, ntor)\n            self.booz.register(self.booz.equil.s_half_grid)\n            self.booz.run()\n        elif isinstance(equil, Boozer):\n            self.booz = equil\n            # Determine if radial grid for Boozer needs to be updated\n\n            # Grid not initialized\n            if len(self.booz.bx.s_in) == 0:\n                self.booz.register(self.booz.equil.s_half_grid)\n            # Grid does not have correct size\n            elif (len(self.booz.bx.s_in) != len(self.booz.bx.s_b)):\n                self.booz.register(self.booz.equil.s_half_grid)\n            # Grid does not match Vmec half grid\n            elif (np.any(self.booz.bx.s_in != self.booz.bx.s_b)):\n                self.booz.register(self.booz.equil.s_half_grid)\n\n            # Run booz_xform if needed\n            if self.booz.need_to_run_code:\n                self.booz.run()\n\n        self.stellsym = not self.booz.bx.asym\n        self.order = order\n        self.enforce_qs = False\n        self.enforce_vacuum = enforce_vacuum\n        self.no_K = no_K\n        if (self.enforce_vacuum):\n            self.no_K = True\n        self.ns_delete = ns_delete\n        self.rescale = rescale\n        if (N is not None):\n            self.N = N\n            self.enforce_qs = True\n\n        self.mpi = self.booz.mpi\n\n        BoozerMagneticField.__init__(self, self.booz.equil.wout.phi[-1]/(2*np.pi))\n\n        if self.mpi is not None:\n            if self.mpi.proc0_groups:\n                self.init_splines()\n                if (not self.no_K):\n                    self.compute_K()\n            else:\n                self.psip_spline = None\n                self.G_spline = None\n                self.I_spline = None\n                self.dGds_spline = None\n                self.dIds_spline = None\n                self.iota_spline = None\n                self.diotads_spline = None\n                self.numns_splines = None\n                self.rmnc_splines = None\n                self.zmns_splines = None\n                self.dnumnsds_splines = None\n                self.drmncds_splines = None\n                self.dzmnsds_splines = None\n                self.bmnc_splines = None\n                self.dbmncds_splines = None\n                self.d_mn_factor_splines = None\n                self.mn_factor_splines = None\n                self.xm_b = None\n                self.xn_b = None\n                if not self.stellsym:\n                    self.numnc_splines = None\n                    self.rmns_splines = None\n                    self.zmnc_splines = None\n                    self.dnumncds_splines = None\n                    self.drmnsds_splines = None\n                    self.dzmncds_splines = None\n                    self.bmns_splines = None\n                    self.dbmnsds_splines = None\n\n            self.psip_spline = self.mpi.comm_world.bcast(self.psip_spline, root=0)\n            self.G_spline = self.mpi.comm_world.bcast(self.G_spline, root=0)\n            self.I_spline = self.mpi.comm_world.bcast(self.I_spline, root=0)\n            self.dGds_spline = self.mpi.comm_world.bcast(self.dGds_spline, root=0)\n            self.dIds_spline = self.mpi.comm_world.bcast(self.dIds_spline, root=0)\n            self.iota_spline = self.mpi.comm_world.bcast(self.iota_spline, root=0)\n            self.diotads_spline = self.mpi.comm_world.bcast(self.diotads_spline, root=0)\n            self.numns_splines = self.mpi.comm_world.bcast(self.numns_splines, root=0)\n            self.rmnc_splines = self.mpi.comm_world.bcast(self.rmnc_splines, root=0)\n            self.zmns_splines = self.mpi.comm_world.bcast(self.zmns_splines, root=0)\n            self.dnumnsds_splines = self.mpi.comm_world.bcast(self.dnumnsds_splines, root=0)\n            self.drmncds_splines = self.mpi.comm_world.bcast(self.drmncds_splines, root=0)\n            self.dzmnsds_splines = self.mpi.comm_world.bcast(self.dzmnsds_splines, root=0)\n            self.bmnc_splines = self.mpi.comm_world.bcast(self.bmnc_splines, root=0)\n            self.dbmncds_splines = self.mpi.comm_world.bcast(self.dbmncds_splines, root=0)\n            self.d_mn_factor_splines = self.mpi.comm_world.bcast(self.d_mn_factor_splines, root=0)\n            self.mn_factor_splines = self.mpi.comm_world.bcast(self.mn_factor_splines, root=0)\n            self.xm_b = self.mpi.comm_world.bcast(self.xm_b, root=0)\n            self.xn_b = self.mpi.comm_world.bcast(self.xn_b, root=0)\n            if not self.stellsym:\n                self.numnc_splines = self.mpi.comm_world.bcast(self.numnc_splines, root=0)\n                self.rmns_splines = self.mpi.comm_world.bcast(self.rmns_splines, root=0)\n                self.zmnc_splines = self.mpi.comm_world.bcast(self.zmnc_splines, root=0)\n                self.dnumncds_splines = self.mpi.comm_world.bcast(self.dnumncds_splines, root=0)\n                self.drmnsds_splines = self.mpi.comm_world.bcast(self.drmnsds_splines, root=0)\n                self.dzmncds_splines = self.mpi.comm_world.bcast(self.dzmncds_splines, root=0)\n                self.bmns_splines = self.mpi.comm_world.bcast(self.bmns_splines, root=0)\n                self.dbmnsds_splines = self.mpi.comm_world.bcast(self.dbmnsds_splines, root=0)\n        else:\n            self.init_splines()\n            if (not self.no_K):\n                self.compute_K()\n\n    def init_splines(self):\n        self.xm_b = self.booz.bx.xm_b\n        self.xn_b = self.booz.bx.xn_b\n\n        # Define quantities on extended half grid\n        iota = np.zeros((self.booz.bx.ns_b+2))\n        G = np.zeros((self.booz.bx.ns_b+2))\n        I = np.zeros((self.booz.bx.ns_b+2))\n\n        self.s_half_ext = np.zeros((self.booz.bx.ns_b+2))\n        self.s_half_ext[1:-1] = self.booz.bx.s_in\n        self.s_half_ext[-1] = 1\n\n        ds = self.booz.bx.s_in[1]-self.booz.bx.s_in[0]\n\n        s_full = np.linspace(0, 1, self.booz.bx.ns_in+1)\n\n        psip = self.booz.equil.wout.chi/(2*np.pi)\n        iota[1:-1] = self.booz.bx.iota\n        G[1:-1] = self.booz.bx.Boozer_G\n        I[1:-1] = self.booz.bx.Boozer_I\n        if self.rescale:\n            s_half_mn = self.booz.bx.s_in[self.ns_delete::]\n            bmnc = np.zeros((len(self.xm_b), self.booz.bx.ns_in-self.ns_delete))\n            rmnc = np.zeros((len(self.xm_b), self.booz.bx.ns_in-self.ns_delete))\n            zmns = np.zeros((len(self.xm_b), self.booz.bx.ns_in-self.ns_delete))\n            numns = np.zeros((len(self.xm_b), self.booz.bx.ns_in-self.ns_delete))\n\n            bmnc = self.booz.bx.bmnc_b[:, self.ns_delete::]\n            rmnc = self.booz.bx.rmnc_b[:, self.ns_delete::]\n            zmns = self.booz.bx.zmns_b[:, self.ns_delete::]\n            numns = self.booz.bx.numns_b[:, self.ns_delete::]\n\n            if not self.stellsym:\n                bmns = np.zeros((len(self.xm_b), self.booz.bx.ns_in-self.ns_delete))\n                rmns = np.zeros((len(self.xm_b), self.booz.bx.ns_in-self.ns_delete))\n                zmnc = np.zeros((len(self.xm_b), self.booz.bx.ns_in-self.ns_delete))\n                numnc = np.zeros((len(self.xm_b), self.booz.bx.ns_in-self.ns_delete))\n\n                bmns = self.booz.bx.bmns_b[:, self.ns_delete::]\n                rmns = self.booz.bx.rmns_b[:, self.ns_delete::]\n                zmnc = self.booz.bx.zmnc_b[:, self.ns_delete::]\n                numnc = self.booz.bx.numnc_b[:, self.ns_delete::]\n\n            mn_factor = np.ones_like(bmnc)\n            d_mn_factor = np.zeros_like(bmnc)\n            mn_factor[self.xm_b == 1, :] = s_half_mn[None, :]**(-0.5)\n            d_mn_factor[self.xm_b == 1, :] = -0.5*s_half_mn[None, :]**(-1.5)\n            mn_factor[(self.xm_b % 2 == 1)*(self.xm_b > 1), :] = s_half_mn[None, :]**(-1.5)\n            d_mn_factor[(self.xm_b % 2 == 1)*(self.xm_b > 1), :] = -1.5*s_half_mn[None, :]**(-2.5)\n            mn_factor[(self.xm_b % 2 == 0)*(self.xm_b > 1), :] = s_half_mn[None, :]**(-1.)\n            d_mn_factor[(self.xm_b % 2 == 0)*(self.xm_b > 1), :] = -s_half_mn[None, :]**(-2.)\n        else:\n            s_half_mn = self.s_half_ext\n            bmnc = np.zeros((len(self.xm_b), self.booz.bx.ns_in+2))\n            bmnc[:, 1:-1] = self.booz.bx.bmnc_b\n            bmnc[:, 0] = 1.5*bmnc[:, 1] - 0.5*bmnc[:, 2]\n            bmnc[:, -1] = 1.5*bmnc[:, -2] - 0.5*bmnc[:, -3]\n            dbmncds = (bmnc[:, 2:-1] - bmnc[:, 1:-2])/ds\n            mn_factor = np.ones_like(bmnc)\n            d_mn_factor = np.zeros_like(bmnc)\n\n            numns = np.zeros((len(self.xm_b), self.booz.bx.ns_in+2))\n            rmnc = np.zeros((len(self.xm_b), self.booz.bx.ns_in+2))\n            zmns = np.zeros((len(self.xm_b), self.booz.bx.ns_in+2))\n            numns[:, 1:-1] = self.booz.bx.numns_b\n            numns[:, 0] = 1.5*numns[:, 1] - 0.5*numns[:, 2]\n            numns[:, -1] = 1.5*numns[:, -2] - 0.5*numns[:, -3]\n            rmnc[:, 1:-1] = self.booz.bx.rmnc_b\n            rmnc[:, 0] = 1.5*rmnc[:, 1] - 0.5*rmnc[:, 2]\n            rmnc[:, -1] = 1.5*rmnc[:, -2] - 0.5*rmnc[:, -3]\n            zmns[:, 1:-1] = self.booz.bx.zmns_b\n            zmns[:, 0] = 1.5*zmns[:, 1] - 0.5*zmns[:, 2]\n            zmns[:, -1] = 1.5*zmns[:, -2] - 0.5*zmns[:, -3]\n\n            drmncds = (rmnc[:, 2:-1] - rmnc[:, 1:-2])/ds\n            dzmnsds = (zmns[:, 2:-1] - zmns[:, 1:-2])/ds\n            dnumnsds = (numns[:, 2:-1] - numns[:, 1:-2])/ds\n\n            if not self.stellsym:\n                bmns = np.zeros((len(self.xm_b), self.booz.bx.ns_in+2))\n                bmns[:, 1:-1] = self.booz.bx.bmns_b\n                bmns[:, 0] = 1.5*bmns[:, 1] - 0.5*bmns[:, 2]\n                bmns[:, -1] = 1.5*bmns[:, -2] - 0.5*bmns[:, -3]\n                dbmnsds = (bmns[:, 2:-1] - bmns[:, 1:-2])/ds\n\n                numnc = np.zeros((len(self.xm_b), self.booz.bx.ns_in+2))\n                rmns = np.zeros((len(self.xm_b), self.booz.bx.ns_in+2))\n                zmnc = np.zeros((len(self.xm_b), self.booz.bx.ns_in+2))\n                numnc[:, 1:-1] = self.booz.bx.numnc_b\n                numnc[:, 0] = 1.5*numnc[:, 1] - 0.5*numnc[:, 2]\n                numnc[:, -1] = 1.5*numnc[:, -2] - 0.5*numnc[:, -3]\n                rmns[:, 1:-1] = self.booz.bx.rmns_b\n                rmns[:, 0] = 1.5*rmns[:, 1] - 0.5*rmns[:, 2]\n                rmns[:, -1] = 1.5*rmns[:, -2] - 0.5*rmns[:, -3]\n                zmnc[:, 1:-1] = self.booz.bx.zmnc_b\n                zmnc[:, 0] = 1.5*zmnc[:, 1] - 0.5*zmnc[:, 2]\n                zmnc[:, -1] = 1.5*zmnc[:, -2] - 0.5*zmnc[:, -3]\n\n                drmnsds = (rmns[:, 2:-1] - rmns[:, 1:-2])/ds\n                dzmncds = (zmnc[:, 2:-1] - zmnc[:, 1:-2])/ds\n                dnumncds = (numnc[:, 2:-1] - numnc[:, 1:-2])/ds\n\n        # Extrapolate to get points at s = 0 and s = 1\n        iota[0] = 1.5*iota[1] - 0.5*iota[2]\n        G[0] = 1.5*G[1] - 0.5*G[2]\n        I[0] = 1.5*I[1] - 0.5*I[2]\n        iota[-1] = 1.5*iota[-2] - 0.5*iota[-3]\n        G[-1] = 1.5*G[-2] - 0.5*G[-3]\n        I[-1] = 1.5*I[-2] - 0.5*I[-3]\n        # Compute first derivatives - on full grid points in [1,ns-1]\n        dGds = (G[2:-1] - G[1:-2])/ds\n        dIds = (I[2:-1] - I[1:-2])/ds\n        diotads = (iota[2:-1] - iota[1:-2])/ds\n\n        self.psip_spline = InterpolatedUnivariateSpline(s_full, psip, k=self.order)\n        if not self.enforce_vacuum:\n            self.G_spline = InterpolatedUnivariateSpline(self.s_half_ext, G, k=self.order)\n            self.I_spline = InterpolatedUnivariateSpline(self.s_half_ext, I, k=self.order)\n            self.dGds_spline = InterpolatedUnivariateSpline(s_full[1:-1], dGds, k=self.order)\n            self.dIds_spline = InterpolatedUnivariateSpline(s_full[1:-1], dIds, k=self.order)\n        else:\n            self.G_spline = InterpolatedUnivariateSpline(self.s_half_ext, np.mean(G)*np.ones_like(self.s_half_ext), k=self.order)\n            self.I_spline = InterpolatedUnivariateSpline(self.s_half_ext, np.zeros_like(self.s_half_ext), k=self.order)\n            self.dGds_spline = InterpolatedUnivariateSpline(s_full[1:-1], np.zeros_like(s_full[1:-1]), k=self.order)\n            self.dIds_spline = InterpolatedUnivariateSpline(s_full[1:-1], np.zeros_like(s_full[1:-1]), k=self.order)\n        self.iota_spline = InterpolatedUnivariateSpline(self.s_half_ext, iota, k=self.order)\n        self.diotads_spline = InterpolatedUnivariateSpline(s_full[1:-1], diotads, k=self.order)\n\n        self.numns_splines = []\n        self.rmnc_splines = []\n        self.zmns_splines = []\n        self.dnumnsds_splines = []\n        self.drmncds_splines = []\n        self.dzmnsds_splines = []\n        self.bmnc_splines = []\n        self.dbmncds_splines = []\n        self.d_mn_factor_splines = []\n        self.mn_factor_splines = []\n        for im in range(len(self.xm_b)):\n            self.numns_splines.append(InterpolatedUnivariateSpline(s_half_mn, mn_factor[im, :]*numns[im, :], k=self.order))\n            self.rmnc_splines.append(InterpolatedUnivariateSpline(s_half_mn, mn_factor[im, :]*rmnc[im, :], k=self.order))\n            self.zmns_splines.append(InterpolatedUnivariateSpline(s_half_mn, mn_factor[im, :]*zmns[im, :], k=self.order))\n            self.mn_factor_splines.append(InterpolatedUnivariateSpline(s_half_mn, mn_factor[im, :], k=self.order))\n            self.d_mn_factor_splines.append(InterpolatedUnivariateSpline(s_half_mn, d_mn_factor[im, :], k=self.order))\n            if (self.enforce_qs and (self.xn_b[im] != self.N * self.xm_b[im])):\n                self.bmnc_splines.append(InterpolatedUnivariateSpline(s_half_mn, 0*bmnc[im, :], k=self.order))\n                self.dbmncds_splines.append(InterpolatedUnivariateSpline(s_full[1:-1], 0*dbmncds[im, :], k=self.order))\n            else:\n                self.bmnc_splines.append(InterpolatedUnivariateSpline(s_half_mn, mn_factor[im, :]*bmnc[im, :], k=self.order))\n                if self.rescale:\n                    self.dbmncds_splines.append(self.bmnc_splines[-1].derivative())\n                else:\n                    self.dbmncds_splines.append(InterpolatedUnivariateSpline(s_full[1:-1], dbmncds[im, :], k=self.order))\n\n            if self.rescale:\n                self.dnumnsds_splines.append(self.numns_splines[-1].derivative())\n                self.drmncds_splines.append(self.rmnc_splines[-1].derivative())\n                self.dzmnsds_splines.append(self.zmns_splines[-1].derivative())\n            else:\n                self.dnumnsds_splines.append(InterpolatedUnivariateSpline(s_full[1:-1], dnumnsds[im, :], k=self.order))\n                self.drmncds_splines.append(InterpolatedUnivariateSpline(s_full[1:-1], drmncds[im, :], k=self.order))\n                self.dzmnsds_splines.append(InterpolatedUnivariateSpline(s_full[1:-1], dzmnsds[im, :], k=self.order))\n\n        if not self.stellsym:\n            self.numnc_splines = []\n            self.rmns_splines = []\n            self.zmnc_splines = []\n            self.dnumncds_splines = []\n            self.drmnsds_splines = []\n            self.dzmncds_splines = []\n            self.bmns_splines = []\n            self.dbmnsds_splines = []\n            for im in range(len(self.xm_b)):\n                self.numnc_splines.append(InterpolatedUnivariateSpline(s_half_mn, mn_factor[im, :]*numnc[im, :], k=self.order))\n                self.rmns_splines.append(InterpolatedUnivariateSpline(s_half_mn, mn_factor[im, :]*rmns[im, :], k=self.order))\n                self.zmnc_splines.append(InterpolatedUnivariateSpline(s_half_mn, mn_factor[im, :]*zmnc[im, :], k=self.order))\n                if (self.enforce_qs and (self.xn_b[im] != self.N * self.xm_b[im])):\n                    self.bmns_splines.append(InterpolatedUnivariateSpline(s_half_mn, 0*bmns[im, :], k=self.order))\n                    self.dbmnsds_splines.append(InterpolatedUnivariateSpline(s_full[1:-1], 0*dbmnsds[im, :], k=self.order))\n                else:\n                    self.bmns_splines.append(InterpolatedUnivariateSpline(s_half_mn, mn_factor[im, :]*bmns[im, :], k=self.order))\n                    if self.rescale:\n                        self.dbmnsds_splines.append(self.bmns_splines[-1].derivative())\n                    else:\n                        self.dbmnsds_splines.append(InterpolatedUnivariateSpline(s_full[1:-1], dbmnsds[im, :], k=self.order))\n\n                if self.rescale:\n                    self.dnumncds_splines.append(self.numnc_splines[-1].derivative())\n                    self.drmnsds_splines.append(self.rmns_splines[-1].derivative())\n                    self.dzmncds_splines.append(self.zmnc_splines[-1].derivative())\n                else:\n                    self.dnumncds_splines.append(InterpolatedUnivariateSpline(s_full[1:-1], dnumncds[im, :], k=self.order))\n                    self.drmnsds_splines.append(InterpolatedUnivariateSpline(s_full[1:-1], drmnsds[im, :], k=self.order))\n                    self.dzmncds_splines.append(InterpolatedUnivariateSpline(s_full[1:-1], dzmncds[im, :], k=self.order))\n\n    def compute_K(self):\n        ntheta = 2 * (2 * self.booz.bx.mboz + 1)\n        nzeta = 2 * (2 * self.booz.bx.nboz + 1)\n        thetas = np.linspace(0, 2*np.pi, ntheta, endpoint=False)\n        dtheta = thetas[1]-thetas[0]\n        zetas = np.linspace(0, 2*np.pi/self.booz.bx.nfp, nzeta, endpoint=False)\n        dzeta = zetas[1]-zetas[0]\n        thetas, zetas = np.meshgrid(thetas, zetas)\n        thetas = thetas.flatten()\n        zetas = zetas.flatten()\n\n        dzmnsds_half = np.zeros((len(self.xm_b), len(self.s_half_ext)))\n        drmncds_half = np.zeros((len(self.xm_b), len(self.s_half_ext)))\n        dnumnsds_half = np.zeros((len(self.xm_b), len(self.s_half_ext)))\n        bmnc_half = np.zeros((len(self.xm_b), len(self.s_half_ext)))\n        rmnc_half = np.zeros((len(self.xm_b), len(self.s_half_ext)))\n        zmns_half = np.zeros((len(self.xm_b), len(self.s_half_ext)))\n        numns_half = np.zeros((len(self.xm_b), len(self.s_half_ext)))\n        if not self.stellsym:\n            dzmncds_half = np.zeros((len(self.xm_b), len(self.s_half_ext)))\n            drmnsds_half = np.zeros((len(self.xm_b), len(self.s_half_ext)))\n            dnumncds_half = np.zeros((len(self.xm_b), len(self.s_half_ext)))\n            bmns_half = np.zeros((len(self.xm_b), len(self.s_half_ext)))\n            rmns_half = np.zeros((len(self.xm_b), len(self.s_half_ext)))\n            zmnc_half = np.zeros((len(self.xm_b), len(self.s_half_ext)))\n            numnc_half = np.zeros((len(self.xm_b), len(self.s_half_ext)))\n        for im in range(len(self.xm_b)):\n            mn_factor = self.mn_factor_splines[im](self.s_half_ext)\n            d_mn_factor = self.d_mn_factor_splines[im](self.s_half_ext)\n            dnumnsds_half[im, :] = ((self.dnumnsds_splines[im](self.s_half_ext) - self.numns_splines[im](self.s_half_ext)*d_mn_factor/mn_factor)/mn_factor)\n            drmncds_half[im, :] = ((self.drmncds_splines[im](self.s_half_ext) - self.rmnc_splines[im](self.s_half_ext)*d_mn_factor/mn_factor)/mn_factor)\n            dzmnsds_half[im, :] = ((self.dzmnsds_splines[im](self.s_half_ext) - self.zmns_splines[im](self.s_half_ext)*d_mn_factor/mn_factor)/mn_factor)\n            bmnc_half[im, :] = self.bmnc_splines[im](self.s_half_ext)/mn_factor\n            rmnc_half[im, :] = self.rmnc_splines[im](self.s_half_ext)/mn_factor\n            zmns_half[im, :] = self.zmns_splines[im](self.s_half_ext)/mn_factor\n            numns_half[im, :] = self.numns_splines[im](self.s_half_ext)/mn_factor\n            if not self.stellsym:\n                dnumncds_half[im, :] = ((self.dnumncds_splines[im](self.s_half_ext) - self.numnc_splines[im](self.s_half_ext)*d_mn_factor/mn_factor)/mn_factor)\n                drmnsds_half[im, :] = ((self.drmnsds_splines[im](self.s_half_ext) - self.rmns_splines[im](self.s_half_ext)*d_mn_factor/mn_factor)/mn_factor)\n                dzmncds_half[im, :] = ((self.dzmncds_splines[im](self.s_half_ext) - self.zmnc_splines[im](self.s_half_ext)*d_mn_factor/mn_factor)/mn_factor)\n                bmns_half[im, :] = self.bmns_splines[im](self.s_half_ext)/mn_factor\n                rmns_half[im, :] = self.rmns_splines[im](self.s_half_ext)/mn_factor\n                zmnc_half[im, :] = self.zmnc_splines[im](self.s_half_ext)/mn_factor\n                numnc_half[im, :] = self.numnc_splines[im](self.s_half_ext)/mn_factor\n\n        G_half = self.G_spline(self.s_half_ext)\n        I_half = self.I_spline(self.s_half_ext)\n        iota_half = self.iota_spline(self.s_half_ext)\n\n        if not self.stellsym:\n            kmnc_kmns = sopp.compute_kmnc_kmns(rmnc_half, drmncds_half, zmns_half, dzmnsds_half,\n                                               numns_half, dnumnsds_half, bmnc_half,\n                                               rmns_half, drmnsds_half, zmnc_half, dzmncds_half,\n                                               numnc_half, dnumncds_half, bmns_half,\n                                               iota_half, G_half, I_half, self.xm_b, self.xn_b, thetas, zetas)\n            kmnc = kmnc_kmns[0, :, :]\n            kmns = kmnc_kmns[1, :, :]\n            kmnc = kmnc*dtheta*dzeta*self.booz.bx.nfp/self.psi0\n        else:\n            kmns = sopp.compute_kmns(rmnc_half, drmncds_half, zmns_half, dzmnsds_half,\n                                     numns_half, dnumnsds_half, bmnc_half, iota_half, G_half, I_half,\n                                     self.xm_b, self.xn_b, thetas, zetas)\n        kmns = kmns*dtheta*dzeta*self.booz.bx.nfp/self.psi0\n\n        self.kmns_splines = []\n        if not self.stellsym:\n            self.kmnc_splines = []\n        for im in range(len(self.xm_b)):\n            if (self.enforce_qs and (self.xn_b[im] != self.N * self.xm_b[im])):\n                self.kmns_splines.append(InterpolatedUnivariateSpline(self.s_half_ext, 0*kmns[im, :], k=self.order))\n                if not self.stellsym:\n                    self.kmnc_splines.append(InterpolatedUnivariateSpline(self.s_half_ext, 0*kmnc[im, :], k=self.order))\n            else:\n                self.kmns_splines.append(InterpolatedUnivariateSpline(self.s_half_ext, self.mn_factor_splines[im](self.s_half_ext)*kmns[im, :], k=self.order))\n                if not self.stellsym:\n                    self.kmnc_splines.append(InterpolatedUnivariateSpline(self.s_half_ext, self.mn_factor_splines[im](self.s_half_ext)*kmnc[im, :], k=self.order))\n\n    def _K_impl(self, K):\n        points = self.get_points_ref()\n        s = points[:, 0]\n        thetas = points[:, 1]\n        zetas = points[:, 2]\n        K[:, 0] = 0.\n        if self.no_K:\n            return\n        kmns = np.zeros((len(self.xm_b), len(s)))\n        for im in range(len(self.xm_b)):\n            kmns[im, :] = self.kmns_splines[im](s)/self.mn_factor_splines[im](s)\n        sopp.inverse_fourier_transform_odd(K[:, 0], kmns, self.xm_b, self.xn_b, thetas, zetas)\n        if not self.stellsym:\n            kmnc = np.zeros((len(self.xm_b), len(s)))\n            for im in range(len(self.xm_b)):\n                kmnc[im, :] = self.kmnc_splines[im](s)/self.mn_factor_splines[im](s)\n            sopp.inverse_fourier_transform_even(K[:, 0], kmnc, self.xm_b, self.xn_b, thetas, zetas)\n\n    def _dKdtheta_impl(self, dKdtheta):\n        points = self.get_points_ref()\n        s = points[:, 0]\n        thetas = points[:, 1]\n        zetas = points[:, 2]\n        dKdtheta[:, 0] = 0.\n        if self.no_K:\n            return\n        kmns = np.zeros((len(self.xm_b), len(s)))\n        for im in range(len(self.xm_b)):\n            kmns[im, :] = self.kmns_splines[im](s) * self.xm_b[im]/self.mn_factor_splines[im](s)\n        sopp.inverse_fourier_transform_even(dKdtheta[:, 0], kmns, self.xm_b, self.xn_b, thetas, zetas)\n        if not self.stellsym:\n            kmnc = np.zeros((len(self.xm_b), len(s)))\n            for im in range(len(self.xm_b)):\n                kmnc[im, :] = -self.kmnc_splines[im](s) * self.xm_b[im]/self.mn_factor_splines[im](s)\n            sopp.inverse_fourier_transform_odd(dKdtheta[:, 0], kmnc, self.xm_b, self.xn_b, thetas, zetas)\n\n    def _dKdzeta_impl(self, dKdzeta):\n        points = self.get_points_ref()\n        s = points[:, 0]\n        thetas = points[:, 1]\n        zetas = points[:, 2]\n        dKdzeta[:, 0] = 0.\n        if (self.no_K):\n            return\n        kmns = np.zeros((len(self.xm_b), len(s)))\n        for im in range(len(self.xm_b)):\n            kmns[im, :] = -self.kmns_splines[im](s) * self.xn_b[im]/self.mn_factor_splines[im](s)\n        sopp.inverse_fourier_transform_even(dKdzeta[:, 0], kmns, self.xm_b, self.xn_b, thetas, zetas)\n        if not self.stellsym:\n            kmnc = np.zeros((len(self.xm_b), len(s)))\n            for im in range(len(self.xm_b)):\n                kmnc[im, :] = self.kmnc_splines[im](s) * self.xn_b[im]/self.mn_factor_splines[im](s)\n            sopp.inverse_fourier_transform_odd(dKdzeta[:, 0], kmnc, self.xm_b, self.xn_b, thetas, zetas)\n\n    def _nu_impl(self, nu):\n        points = self.get_points_ref()\n        s = points[:, 0]\n        thetas = points[:, 1]\n        zetas = points[:, 2]\n        numns = np.zeros((len(self.xm_b), len(s)))\n        for im in range(len(self.xm_b)):\n            numns[im, :] = self.numns_splines[im](s)/self.mn_factor_splines[im](s)\n        nu[:, 0] = 0.\n        sopp.inverse_fourier_transform_odd(nu[:, 0], numns, self.xm_b, self.xn_b, thetas, zetas)\n        if not self.stellsym:\n            numnc = np.zeros((len(self.xm_b), len(s)))\n            for im in range(len(self.xm_b)):\n                numnc[im, :] = self.numnc_splines[im](s)/self.mn_factor_splines[im](s)\n            sopp.inverse_fourier_transform_even(nu[:, 0], numnc, self.xm_b, self.xn_b, thetas, zetas)\n\n    def _dnudtheta_impl(self, dnudtheta):\n        points = self.get_points_ref()\n        s = points[:, 0]\n        thetas = points[:, 1]\n        zetas = points[:, 2]\n        numns = np.zeros((len(self.xm_b), len(s)))\n        for im in range(len(self.xm_b)):\n            numns[im, :] = self.numns_splines[im](s)*self.xm_b[im]/self.mn_factor_splines[im](s)\n        dnudtheta[:, 0] = 0.\n        sopp.inverse_fourier_transform_even(dnudtheta[:, 0], numns, self.xm_b, self.xn_b, thetas, zetas)\n        if not self.stellsym:\n            numnc = np.zeros((len(self.xm_b), len(s)))\n            for im in range(len(self.xm_b)):\n                numnc[im, :] = -self.numnc_splines[im](s)*self.xm_b[im]/self.mn_factor_splines[im](s)\n            sopp.inverse_fourier_transform_odd(dnudtheta[:, 0], numnc, self.xm_b, self.xn_b, thetas, zetas)\n\n    def _dnudzeta_impl(self, dnudzeta):\n        points = self.get_points_ref()\n        s = points[:, 0]\n        thetas = points[:, 1]\n        zetas = points[:, 2]\n        numns = np.zeros((len(self.xm_b), len(s)))\n        for im in range(len(self.xm_b)):\n            numns[im, :] = -self.numns_splines[im](s)*self.xn_b[im]/self.mn_factor_splines[im](s)\n        dnudzeta[:, 0] = 0.\n        sopp.inverse_fourier_transform_even(dnudzeta[:, 0], numns, self.xm_b, self.xn_b, thetas, zetas)\n        if not self.stellsym:\n            numnc = np.zeros((len(self.xm_b), len(s)))\n            for im in range(len(self.xm_b)):\n                numnc[im, :] = self.numnc_splines[im](s)*self.xn_b[im]/self.mn_factor_splines[im](s)\n            sopp.inverse_fourier_transform_odd(dnudzeta[:, 0], numnc, self.xm_b, self.xn_b, thetas, zetas)\n\n    def _dnuds_impl(self, dnuds):\n        points = self.get_points_ref()\n        s = points[:, 0]\n        thetas = points[:, 1]\n        zetas = points[:, 2]\n        numns = np.zeros((len(self.xm_b), len(s)))\n        for im in range(len(self.xm_b)):\n            d_mn_factor = self.d_mn_factor_splines[im](s)\n            mn_factor = self.mn_factor_splines[im](s)\n            numns[im, :] = ((self.dnumnsds_splines[im](s) - self.numns_splines[im](s)*d_mn_factor/mn_factor)/mn_factor)\n        dnuds[:, 0] = 0.\n        sopp.inverse_fourier_transform_odd(dnuds[:, 0], numns, self.xm_b, self.xn_b, thetas, zetas)\n        if not self.stellsym:\n            numnc = np.zeros((len(self.xm_b), len(s)))\n            for im in range(len(self.xm_b)):\n                d_mn_factor = self.d_mn_factor_splines[im](s)\n                mn_factor = self.mn_factor_splines[im](s)\n                numnc[im, :] = ((self.dnumncds_splines[im](s) - self.numnc_splines[im](s)*d_mn_factor/mn_factor)/mn_factor)\n            sopp.inverse_fourier_transform_even(dnuds[:, 0], numnc, self.xm_b, self.xn_b, thetas, zetas)\n\n    def _dRdtheta_impl(self, dRdtheta):\n        points = self.get_points_ref()\n        s = points[:, 0]\n        thetas = points[:, 1]\n        zetas = points[:, 2]\n        rmnc = np.zeros((len(self.xm_b), len(s)))\n        for im in range(len(self.xm_b)):\n            rmnc[im, :] = -self.rmnc_splines[im](s)*self.xm_b[im]/self.mn_factor_splines[im](s)\n        dRdtheta[:, 0] = 0.\n        sopp.inverse_fourier_transform_odd(dRdtheta[:, 0], rmnc, self.xm_b, self.xn_b, thetas, zetas)\n        if not self.stellsym:\n            rmns = np.zeros((len(self.xm_b), len(s)))\n            for im in range(len(self.xm_b)):\n                rmns[im, :] = self.rmns_splines[im](s)*self.xm_b[im]/self.mn_factor_splines[im](s)\n            sopp.inverse_fourier_transform_even(dRdtheta[:, 0], rmns, self.xm_b, self.xn_b, thetas, zetas)\n\n    def _dRdzeta_impl(self, dRdzeta):\n        points = self.get_points_ref()\n        s = points[:, 0]\n        thetas = points[:, 1]\n        zetas = points[:, 2]\n        rmnc = np.zeros((len(self.xm_b), len(s)))\n        for im in range(len(self.xm_b)):\n            rmnc[im, :] = self.rmnc_splines[im](s)*self.xn_b[im]/self.mn_factor_splines[im](s)\n        dRdzeta[:, 0] = 0.\n        sopp.inverse_fourier_transform_odd(dRdzeta[:, 0], rmnc, self.xm_b, self.xn_b, thetas, zetas)\n        if not self.stellsym:\n            rmns = np.zeros((len(self.xm_b), len(s)))\n            for im in range(len(self.xm_b)):\n                rmns[im, :] = -self.rmns_splines[im](s)*self.xn_b[im]/self.mn_factor_splines[im](s)\n            sopp.inverse_fourier_transform_even(dRdzeta[:, 0], rmns, self.xm_b, self.xn_b, thetas, zetas)\n\n    def _dRds_impl(self, dRds):\n        points = self.get_points_ref()\n        s = points[:, 0]\n        thetas = points[:, 1]\n        zetas = points[:, 2]\n        rmnc = np.zeros((len(self.xm_b), len(s)))\n        for im in range(len(self.xm_b)):\n            d_mn_factor = self.d_mn_factor_splines[im](s)\n            mn_factor = self.mn_factor_splines[im](s)\n            rmnc[im, :] = ((self.drmncds_splines[im](s) - self.rmnc_splines[im](s)*d_mn_factor/mn_factor)/mn_factor)\n        dRds[:, 0] = 0.\n        sopp.inverse_fourier_transform_even(dRds[:, 0], rmnc, self.xm_b, self.xn_b, thetas, zetas)\n        if not self.stellsym:\n            rmns = np.zeros((len(self.xm_b), len(s)))\n            for im in range(len(self.xm_b)):\n                d_mn_factor = self.d_mn_factor_splines[im](s)\n                mn_factor = self.mn_factor_splines[im](s)\n                rmns[im, :] = ((self.drmnsds_splines[im](s) - self.rmns_splines[im](s)*d_mn_factor/mn_factor)/mn_factor)\n            sopp.inverse_fourier_transform_odd(dRds[:, 0], rmns, self.xm_b, self.xn_b, thetas, zetas)\n\n    def _R_impl(self, R):\n        points = self.get_points_ref()\n        s = points[:, 0]\n        thetas = points[:, 1]\n        zetas = points[:, 2]\n        rmnc = np.zeros((len(self.xm_b), len(s)))\n        for im in range(len(self.xm_b)):\n            rmnc[im, :] = self.rmnc_splines[im](s)/self.mn_factor_splines[im](s)\n        R[:, 0] = 0.\n        sopp.inverse_fourier_transform_even(R[:, 0], rmnc, self.xm_b, self.xn_b, thetas, zetas)\n        if not self.stellsym:\n            rmns = np.zeros((len(self.xm_b), len(s)))\n            for im in range(len(self.xm_b)):\n                rmns[im, :] = self.rmns_splines[im](s)/self.mn_factor_splines[im](s)\n            sopp.inverse_fourier_transform_odd(R[:, 0], rmns, self.xm_b, self.xn_b, thetas, zetas)\n\n    def _dZdtheta_impl(self, dZdtheta):\n        points = self.get_points_ref()\n        s = points[:, 0]\n        thetas = points[:, 1]\n        zetas = points[:, 2]\n        zmns = np.zeros((len(self.xm_b), len(s)))\n        for im in range(len(self.xm_b)):\n            zmns[im, :] = self.zmns_splines[im](s)*self.xm_b[im]/self.mn_factor_splines[im](s)\n        dZdtheta[:, 0] = 0.\n        sopp.inverse_fourier_transform_even(dZdtheta[:, 0], zmns, self.xm_b, self.xn_b, thetas, zetas)\n        if not self.stellsym:\n            zmnc = np.zeros((len(self.xm_b), len(s)))\n            for im in range(len(self.xm_b)):\n                zmnc[im, :] = -self.zmnc_splines[im](s)*self.xm_b[im]/self.mn_factor_splines[im](s)\n            sopp.inverse_fourier_transform_odd(dZdtheta[:, 0], zmnc, self.xm_b, self.xn_b, thetas, zetas)\n\n    def _dZdzeta_impl(self, dZdzeta):\n        points = self.get_points_ref()\n        s = points[:, 0]\n        thetas = points[:, 1]\n        zetas = points[:, 2]\n        zmns = np.zeros((len(self.xm_b), len(s)))\n        for im in range(len(self.xm_b)):\n            zmns[im, :] = -self.zmns_splines[im](s)*self.xn_b[im]/self.mn_factor_splines[im](s)\n        dZdzeta[:, 0] = 0.\n        sopp.inverse_fourier_transform_even(dZdzeta[:, 0], zmns, self.xm_b, self.xn_b, thetas, zetas)\n        if not self.stellsym:\n            zmnc = np.zeros((len(self.xm_b), len(s)))\n            for im in range(len(self.xm_b)):\n                zmnc[im, :] = self.zmnc_splines[im](s)*self.xn_b[im]/self.mn_factor_splines[im](s)\n            sopp.inverse_fourier_transform_odd(dZdzeta[:, 0], zmnc, self.xm_b, self.xn_b, thetas, zetas)\n\n    def _dZds_impl(self, dZds):\n        points = self.get_points_ref()\n        s = points[:, 0]\n        thetas = points[:, 1]\n        zetas = points[:, 2]\n        zmns = np.zeros((len(self.xm_b), len(s)))\n        for im in range(len(self.xm_b)):\n            d_mn_factor = self.d_mn_factor_splines[im](s)\n            mn_factor = self.mn_factor_splines[im](s)\n            zmns[im, :] = ((self.dzmnsds_splines[im](s) - self.zmns_splines[im](s)*d_mn_factor/mn_factor)/mn_factor)\n        dZds[:, 0] = 0.\n        sopp.inverse_fourier_transform_odd(dZds[:, 0], zmns, self.xm_b, self.xn_b, thetas, zetas)\n        if not self.stellsym:\n            zmnc = np.zeros((len(self.xm_b), len(s)))\n            for im in range(len(self.xm_b)):\n                d_mn_factor = self.d_mn_factor_splines[im](s)\n                mn_factor = self.mn_factor_splines[im](s)\n                zmnc[im, :] = ((self.dzmncds_splines[im](s) - self.zmnc_splines[im](s)*d_mn_factor/mn_factor)/mn_factor)\n            sopp.inverse_fourier_transform_even(dZds[:, 0], zmnc, self.xm_b, self.xn_b, thetas, zetas)\n\n    def _Z_impl(self, Z):\n        points = self.get_points_ref()\n        s = points[:, 0]\n        thetas = points[:, 1]\n        zetas = points[:, 2]\n        zmns = np.zeros((len(self.xm_b), len(s)))\n        for im in range(len(self.xm_b)):\n            zmns[im, :] = self.zmns_splines[im](s)/self.mn_factor_splines[im](s)\n        Z[:, 0] = 0.\n        sopp.inverse_fourier_transform_odd(Z[:, 0], zmns, self.xm_b, self.xn_b, thetas, zetas)\n        if not self.stellsym:\n            zmnc = np.zeros((len(self.xm_b), len(s)))\n            for im in range(len(self.xm_b)):\n                zmnc[im, :] = self.zmnc_splines[im](s)/self.mn_factor_splines[im](s)\n            sopp.inverse_fourier_transform_even(Z[:, 0], zmnc, self.xm_b, self.xn_b, thetas, zetas)\n\n    def _psip_impl(self, psip):\n        points = self.get_points_ref()\n        s = points[:, 0]\n        psip[:] = self.psip_spline(s)[:, None]\n\n    def _G_impl(self, G):\n        points = self.get_points_ref()\n        s = points[:, 0]\n        G[:] = self.G_spline(s)[:, None]\n\n    def _I_impl(self, I):\n        points = self.get_points_ref()\n        s = points[:, 0]\n        I[:] = self.I_spline(s)[:, None]\n\n    def _iota_impl(self, iota):\n        points = self.get_points_ref()\n        s = points[:, 0]\n        iota[:] = self.iota_spline(s)[:, None]\n\n    def _dGds_impl(self, dGds):\n        points = self.get_points_ref()\n        s = points[:, 0]\n        dGds[:] = self.dGds_spline(s)[:, None]\n\n    def _dIds_impl(self, dIds):\n        points = self.get_points_ref()\n        s = points[:, 0]\n        dIds[:] = self.dIds_spline(s)[:, None]\n\n    def _diotads_impl(self, diotads):\n        points = self.get_points_ref()\n        s = points[:, 0]\n        diotads[:] = self.diotads_spline(s)[:, None]\n\n    def _modB_impl(self, modB):\n        points = self.get_points_ref()\n        s = points[:, 0]\n        thetas = points[:, 1]\n        zetas = points[:, 2]\n        bmnc = np.zeros((len(self.xm_b), len(s)))\n        for im in range(len(self.xm_b)):\n            bmnc[im, :] = self.bmnc_splines[im](s)/self.mn_factor_splines[im](s)\n        modB[:, 0] = 0.\n        sopp.inverse_fourier_transform_even(modB[:, 0], bmnc, self.xm_b, self.xn_b, thetas, zetas)\n        if not self.stellsym:\n            bmns = np.zeros((len(self.xm_b), len(s)))\n            for im in range(len(self.xm_b)):\n                bmns[im, :] = self.bmns_splines[im](s)/self.mn_factor_splines[im](s)\n            sopp.inverse_fourier_transform_odd(modB[:, 0], bmns, self.xm_b, self.xn_b, thetas, zetas)\n\n    def _dmodBdtheta_impl(self, dmodBdtheta):\n        points = self.get_points_ref()\n        s = points[:, 0]\n        thetas = points[:, 1]\n        zetas = points[:, 2]\n        bmnc = np.zeros((len(self.xm_b), len(s)))\n        for im in range(len(self.xm_b)):\n            bmnc[im, :] = -self.xm_b[im]*self.bmnc_splines[im](s)/self.mn_factor_splines[im](s)\n        dmodBdtheta[:, 0] = 0.\n        sopp.inverse_fourier_transform_odd(dmodBdtheta[:, 0], bmnc, self.xm_b, self.xn_b, thetas, zetas)\n        if not self.stellsym:\n            bmns = np.zeros((len(self.xm_b), len(s)))\n            for im in range(len(self.xm_b)):\n                bmns[im, :] = self.xm_b[im]*self.bmns_splines[im](s)/self.mn_factor_splines[im](s)\n            sopp.inverse_fourier_transform_even(dmodBdtheta[:, 0], bmns, self.xm_b, self.xn_b, thetas, zetas)\n\n    def _dmodBdzeta_impl(self, dmodBdzeta):\n        points = self.get_points_ref()\n        s = points[:, 0]\n        thetas = points[:, 1]\n        zetas = points[:, 2]\n        bmnc = np.zeros((len(self.xm_b), len(s)))\n        for im in range(len(self.xm_b)):\n            bmnc[im, :] = self.xn_b[im]*self.bmnc_splines[im](s)/self.mn_factor_splines[im](s)\n        dmodBdzeta[:, 0] = 0.\n        sopp.inverse_fourier_transform_odd(dmodBdzeta[:, 0], bmnc, self.xm_b, self.xn_b, thetas, zetas)\n        if not self.stellsym:\n            bmns = np.zeros((len(self.xm_b), len(s)))\n            for im in range(len(self.xm_b)):\n                bmns[im, :] = -self.xn_b[im]*self.bmns_splines[im](s)/self.mn_factor_splines[im](s)\n            sopp.inverse_fourier_transform_even(dmodBdzeta[:, 0], bmns, self.xm_b, self.xn_b, thetas, zetas)\n\n    def _dmodBds_impl(self, dmodBds):\n        points = self.get_points_ref()\n        s = points[:, 0]\n        thetas = points[:, 1]\n        zetas = points[:, 2]\n        bmnc = np.zeros((len(self.xm_b), len(s)))\n        for im in range(len(self.xm_b)):\n            mn_factor = self.mn_factor_splines[im](s)\n            d_mn_factor = self.d_mn_factor_splines[im](s)\n            bmnc[im, :] = ((self.dbmncds_splines[im](s) - self.bmnc_splines[im](s)*d_mn_factor/mn_factor)/mn_factor)\n        dmodBds[:, 0] = 0.\n        sopp.inverse_fourier_transform_even(dmodBds[:, 0], bmnc, self.xm_b, self.xn_b, thetas, zetas)\n        if not self.stellsym:\n            bmns = np.zeros((len(self.xm_b), len(s)))\n            for im in range(len(self.xm_b)):\n                mn_factor = self.mn_factor_splines[im](s)\n                d_mn_factor = self.d_mn_factor_splines[im](s)\n                bmns[im, :] = ((self.dbmnsds_splines[im](s) - self.bmns_splines[im](s)*d_mn_factor/mn_factor)/mn_factor)\n            sopp.inverse_fourier_transform_odd(dmodBds[:, 0], bmns, self.xm_b, self.xn_b, thetas, zetas)",
  "class InterpolatedBoozerField(sopp.InterpolatedBoozerField, BoozerMagneticField):\n    r\"\"\"\n    This field takes an existing :class:`BoozerMagneticField` and interpolates it on a\n    regular grid in :math:`s,\\theta,\\zeta`. This resulting interpolant can then\n    be evaluated very quickly. This is modeled after :class:`InterpolatedField`.\n    \"\"\"\n\n    def __init__(self, field, degree, srange, thetarange, zetarange, extrapolate=True, nfp=1, stellsym=True):\n        r\"\"\"\n        Args:\n            field: the underlying :class:`simsopt.field.boozermagneticfield.BoozerMagneticField` to be interpolated.\n            degree: the degree of the piecewise polynomial interpolant.\n            srange: a 3-tuple of the form ``(smin, smax, ns)``. This mean that\n                the interval ``[smin, smax]`` is split into ``ns`` many subintervals.\n            thetarange: a 3-tuple of the form ``(thetamin, thetamax, ntheta)``.\n                thetamin must be >= 0, and thetamax must be <=2*pi.\n            zetarange: a 3-tuple of the form ``(zetamin, zetamax, nzeta)``.\n                zetamin must be >= 0, and thetamax must be <=2*pi.\n            extrapolate: whether to extrapolate the field when evaluate outside\n                         the integration domain or to throw an error.\n            nfp: Whether to exploit rotational symmetry. In this case any toroidal angle\n                 is always mapped into the interval :math:`[0, 2\\pi/\\mathrm{nfp})`,\n                 hence it makes sense to use ``zetamin=0`` and\n                 ``zetamax=2*np.pi/nfp``.\n            stellsym: Whether to exploit stellarator symmetry. In this case\n                      ``theta`` is always mapped to the interval :math:`[0, \\pi]`,\n                      hence it makes sense to use ``thetamin=0`` and ``thetamax=np.pi``.\n        \"\"\"\n        BoozerMagneticField.__init__(self, field.psi0)\n        if (np.any(np.asarray(thetarange[0:2]) < 0) or np.any(np.asarray(thetarange[0:2]) > 2*np.pi)):\n            raise ValueError(\"thetamin and thetamax must be in [0,2*pi]\")\n        if (np.any(np.asarray(zetarange[0:2]) < 0) or np.any(np.asarray(zetarange[0:2]) > 2*np.pi)):\n            raise ValueError(\"zetamin and zetamax must be in [0,2*pi]\")\n        if stellsym and (np.any(np.asarray(thetarange[0:2]) < 0) or np.any(np.asarray(thetarange[0:2]) > np.pi)):\n            logger.warning(fr\"Sure about thetarange=[{thetarange[0]},{thetarange[1]}]? When exploiting stellarator symmetry, the interpolant is only evaluated for theta in [0,pi].\")\n        if nfp > 1 and (np.any(np.asarray(zetarange[0:2]) < 0) or np.any(np.asarray(zetarange[0:2]) > 2*np.pi/nfp)):\n            logger.warning(fr\"Sure about zetarange=[{zetarange[0]},{zetarange[1]}]? When exploiting rotational symmetry, the interpolant is only evaluated for zeta in [0,2\\pi/nfp].\")\n\n        sopp.InterpolatedBoozerField.__init__(self, field, degree, srange, thetarange, zetarange, extrapolate, nfp, stellsym)",
  "def __init__(self, psi0):\n        self.psi0 = psi0\n        sopp.BoozerMagneticField.__init__(self, psi0)",
  "def clear_cached_properties(self):\n        \"\"\"Clear the cache.\"\"\"\n        sopp.BoozerMagneticField.invalidate_cache(self)",
  "def recompute_bell(self, parent=None):\n        if np.any(self.dofs_free_status):\n            self.clear_cached_properties()",
  "def _modB_derivs_impl(self, modB_derivs):\n        self._dmodBds_impl(np.reshape(modB_derivs[:, 0], (len(modB_derivs[:, 0]), 1)))\n        self._dmodBdtheta_impl(np.reshape(modB_derivs[:, 1], (len(modB_derivs[:, 0]), 1)))\n        self._dmodBdzeta_impl(np.reshape(modB_derivs[:, 2], (len(modB_derivs[:, 0]), 1)))",
  "def _K_derivs_impl(self, K_derivs):\n        self._dKdtheta_impl(np.reshape(K_derivs[:, 0], (len(K_derivs[:, 0]), 1)))\n        self._dKdzeta_impl(np.reshape(K_derivs[:, 1], (len(K_derivs[:, 0]), 1)))",
  "def _nu_derivs_impl(self, nu_derivs):\n        self._dnuds_impl(np.reshape(nu_derivs[:, 0], (len(nu_derivs[:, 0]), 1)))\n        self._dnudtheta_impl(np.reshape(nu_derivs[:, 1], (len(nu_derivs[:, 0]), 1)))\n        self._dnudzeta_impl(np.reshape(nu_derivs[:, 2], (len(nu_derivs[:, 0]), 1)))",
  "def _R_derivs_impl(self, R_derivs):\n        self._dRds_impl(np.reshape(R_derivs[:, 0], (len(R_derivs[:, 0]), 1)))\n        self._dRdtheta_impl(np.reshape(R_derivs[:, 1], (len(R_derivs[:, 0]), 1)))\n        self._dRdzeta_impl(np.reshape(R_derivs[:, 2], (len(R_derivs[:, 0]), 1)))",
  "def _Z_derivs_impl(self, Z_derivs):\n        self._dZds_impl(np.reshape(Z_derivs[:, 0], (len(Z_derivs[:, 0]), 1)))\n        self._dZdtheta_impl(np.reshape(Z_derivs[:, 1], (len(Z_derivs[:, 0]), 1)))\n        self._dZdzeta_impl(np.reshape(Z_derivs[:, 2], (len(Z_derivs[:, 0]), 1)))",
  "def __init__(self, etabar, B0, N, G0, psi0, iota0, Bbar=1., I0=0., G1=0.,\n                 I1=0., K1=0.):\n        self.etabar = etabar\n        self.B0 = B0\n        self.Bbar = Bbar\n        self.N = N\n        self.G0 = G0\n        self.I0 = I0\n        self.I1 = I1\n        self.G1 = G1\n        self.K1 = K1\n        self.iota0 = iota0\n        self.psi0 = psi0\n        BoozerMagneticField.__init__(self, psi0)",
  "def set_etabar(self, etabar):\n        self.invalidate_cache()\n        self.etabar = etabar",
  "def set_B0(self, B0):\n        self.invalidate_cache()\n        self.B0 = B0",
  "def set_Bbar(self, Bbar):\n        self.invalidate_cache()\n        self.Bbar = Bbar",
  "def set_N(self, N):\n        self.invalidate_cache()\n        self.N = N",
  "def set_G0(self, G0):\n        self.invalidate_cache()\n        self.G0 = G0",
  "def set_I0(self, I0):\n        self.invalidate_cache()\n        self.I0 = I0",
  "def set_G1(self, G1):\n        self.invalidate_cache()\n        self.G1 = G1",
  "def set_I1(self, I1):\n        self.invalidate_cache()\n        self.I1 = I1",
  "def set_K1(self, K1):\n        self.invalidate_cache()\n        self.K1 = K1",
  "def set_iota0(self, iota0):\n        self.invalidate_cache()\n        self.iota0 = iota0",
  "def set_psi0(self, psi0):\n        self.invalidate_cache()\n        self.psi0 = psi0",
  "def _psip_impl(self, psip):\n        points = self.get_points_ref()\n        s = points[:, 0]\n        psip[:, 0] = self.psi0*s*self.iota0",
  "def _iota_impl(self, iota):\n        iota[:, 0] = self.iota0",
  "def _diotads_impl(self, diotads):\n        diotads[:, 0] = 0",
  "def _G_impl(self, G):\n        points = self.get_points_ref()\n        s = points[:, 0]\n        G[:, 0] = self.G0 + s*self.G1",
  "def _dGds_impl(self, dGds):\n        dGds[:, 0] = self.G1",
  "def _I_impl(self, I):\n        points = self.get_points_ref()\n        s = points[:, 0]\n        I[:, 0] = self.I0 + s*self.I1",
  "def _dIds_impl(self, dIds):\n        dIds[:, 0] = self.I1",
  "def _modB_impl(self, modB):\n        points = self.get_points_ref()\n        s = points[:, 0]\n        thetas = points[:, 1]\n        zetas = points[:, 2]\n        psi = s*self.psi0\n        r = np.sqrt(np.abs(2*psi/self.Bbar))\n        modB[:, 0] = self.B0*(1 + self.etabar*r*np.cos(thetas-self.N*zetas))",
  "def _dmodBds_impl(self, dmodBds):\n        points = self.get_points_ref()\n        s = points[:, 0]\n        thetas = points[:, 1]\n        zetas = points[:, 2]\n        psi = s*self.psi0\n        r = np.sqrt(np.abs(2*psi/self.Bbar))\n        drdpsi = 0.5*r/psi\n        drds = drdpsi*self.psi0\n        dmodBds[:, 0] = self.B0*self.etabar*drds*np.cos(thetas-self.N*zetas)",
  "def _dmodBdtheta_impl(self, dmodBdtheta):\n        points = self.get_points_ref()\n        s = points[:, 0]\n        thetas = points[:, 1]\n        zetas = points[:, 2]\n        psi = s*self.psi0\n        r = np.sqrt(np.abs(2*psi/self.Bbar))\n        dmodBdtheta[:, 0] = -self.B0*self.etabar*r*np.sin(thetas-self.N*zetas)",
  "def _dmodBdzeta_impl(self, dmodBdzeta):\n        points = self.get_points_ref()\n        s = points[:, 0]\n        thetas = points[:, 1]\n        zetas = points[:, 2]\n        psi = s*self.psi0\n        r = np.sqrt(np.abs(2*psi/self.Bbar))\n        dmodBdzeta[:, 0] = self.N*self.B0*self.etabar*r*np.sin(thetas-self.N*zetas)",
  "def _K_impl(self, K):\n        points = self.get_points_ref()\n        s = points[:, 0]\n        thetas = points[:, 1]\n        zetas = points[:, 2]\n        psi = s*self.psi0\n        r = np.sqrt(np.abs(2*psi/self.Bbar))\n        K[:, 0] = self.K1*r*np.sin(thetas-self.N*zetas)",
  "def _dKdtheta_impl(self, dKdtheta):\n        points = self.get_points_ref()\n        s = points[:, 0]\n        thetas = points[:, 1]\n        zetas = points[:, 2]\n        psi = s*self.psi0\n        r = np.sqrt(np.abs(2*psi/self.Bbar))\n        dKdtheta[:, 0] = self.K1*r*np.cos(thetas-self.N*zetas)",
  "def _dKdzeta_impl(self, dKdzeta):\n        points = self.get_points_ref()\n        s = points[:, 0]\n        thetas = points[:, 1]\n        zetas = points[:, 2]\n        psi = s*self.psi0\n        r = np.sqrt(np.abs(2*psi/self.Bbar))\n        dKdzeta[:, 0] = -self.N*self.K1*r*np.cos(thetas-self.N*zetas)",
  "def __init__(self, equil, order, mpol=32, ntor=32, N=None, enforce_vacuum=False, rescale=False,\n                 ns_delete=0, no_K=False):\n\n        if isinstance(equil, Vmec):\n            equil.run()\n            self.booz = Boozer(equil, mpol, ntor)\n            self.booz.register(self.booz.equil.s_half_grid)\n            self.booz.run()\n        elif isinstance(equil, Boozer):\n            self.booz = equil\n            # Determine if radial grid for Boozer needs to be updated\n\n            # Grid not initialized\n            if len(self.booz.bx.s_in) == 0:\n                self.booz.register(self.booz.equil.s_half_grid)\n            # Grid does not have correct size\n            elif (len(self.booz.bx.s_in) != len(self.booz.bx.s_b)):\n                self.booz.register(self.booz.equil.s_half_grid)\n            # Grid does not match Vmec half grid\n            elif (np.any(self.booz.bx.s_in != self.booz.bx.s_b)):\n                self.booz.register(self.booz.equil.s_half_grid)\n\n            # Run booz_xform if needed\n            if self.booz.need_to_run_code:\n                self.booz.run()\n\n        self.stellsym = not self.booz.bx.asym\n        self.order = order\n        self.enforce_qs = False\n        self.enforce_vacuum = enforce_vacuum\n        self.no_K = no_K\n        if (self.enforce_vacuum):\n            self.no_K = True\n        self.ns_delete = ns_delete\n        self.rescale = rescale\n        if (N is not None):\n            self.N = N\n            self.enforce_qs = True\n\n        self.mpi = self.booz.mpi\n\n        BoozerMagneticField.__init__(self, self.booz.equil.wout.phi[-1]/(2*np.pi))\n\n        if self.mpi is not None:\n            if self.mpi.proc0_groups:\n                self.init_splines()\n                if (not self.no_K):\n                    self.compute_K()\n            else:\n                self.psip_spline = None\n                self.G_spline = None\n                self.I_spline = None\n                self.dGds_spline = None\n                self.dIds_spline = None\n                self.iota_spline = None\n                self.diotads_spline = None\n                self.numns_splines = None\n                self.rmnc_splines = None\n                self.zmns_splines = None\n                self.dnumnsds_splines = None\n                self.drmncds_splines = None\n                self.dzmnsds_splines = None\n                self.bmnc_splines = None\n                self.dbmncds_splines = None\n                self.d_mn_factor_splines = None\n                self.mn_factor_splines = None\n                self.xm_b = None\n                self.xn_b = None\n                if not self.stellsym:\n                    self.numnc_splines = None\n                    self.rmns_splines = None\n                    self.zmnc_splines = None\n                    self.dnumncds_splines = None\n                    self.drmnsds_splines = None\n                    self.dzmncds_splines = None\n                    self.bmns_splines = None\n                    self.dbmnsds_splines = None\n\n            self.psip_spline = self.mpi.comm_world.bcast(self.psip_spline, root=0)\n            self.G_spline = self.mpi.comm_world.bcast(self.G_spline, root=0)\n            self.I_spline = self.mpi.comm_world.bcast(self.I_spline, root=0)\n            self.dGds_spline = self.mpi.comm_world.bcast(self.dGds_spline, root=0)\n            self.dIds_spline = self.mpi.comm_world.bcast(self.dIds_spline, root=0)\n            self.iota_spline = self.mpi.comm_world.bcast(self.iota_spline, root=0)\n            self.diotads_spline = self.mpi.comm_world.bcast(self.diotads_spline, root=0)\n            self.numns_splines = self.mpi.comm_world.bcast(self.numns_splines, root=0)\n            self.rmnc_splines = self.mpi.comm_world.bcast(self.rmnc_splines, root=0)\n            self.zmns_splines = self.mpi.comm_world.bcast(self.zmns_splines, root=0)\n            self.dnumnsds_splines = self.mpi.comm_world.bcast(self.dnumnsds_splines, root=0)\n            self.drmncds_splines = self.mpi.comm_world.bcast(self.drmncds_splines, root=0)\n            self.dzmnsds_splines = self.mpi.comm_world.bcast(self.dzmnsds_splines, root=0)\n            self.bmnc_splines = self.mpi.comm_world.bcast(self.bmnc_splines, root=0)\n            self.dbmncds_splines = self.mpi.comm_world.bcast(self.dbmncds_splines, root=0)\n            self.d_mn_factor_splines = self.mpi.comm_world.bcast(self.d_mn_factor_splines, root=0)\n            self.mn_factor_splines = self.mpi.comm_world.bcast(self.mn_factor_splines, root=0)\n            self.xm_b = self.mpi.comm_world.bcast(self.xm_b, root=0)\n            self.xn_b = self.mpi.comm_world.bcast(self.xn_b, root=0)\n            if not self.stellsym:\n                self.numnc_splines = self.mpi.comm_world.bcast(self.numnc_splines, root=0)\n                self.rmns_splines = self.mpi.comm_world.bcast(self.rmns_splines, root=0)\n                self.zmnc_splines = self.mpi.comm_world.bcast(self.zmnc_splines, root=0)\n                self.dnumncds_splines = self.mpi.comm_world.bcast(self.dnumncds_splines, root=0)\n                self.drmnsds_splines = self.mpi.comm_world.bcast(self.drmnsds_splines, root=0)\n                self.dzmncds_splines = self.mpi.comm_world.bcast(self.dzmncds_splines, root=0)\n                self.bmns_splines = self.mpi.comm_world.bcast(self.bmns_splines, root=0)\n                self.dbmnsds_splines = self.mpi.comm_world.bcast(self.dbmnsds_splines, root=0)\n        else:\n            self.init_splines()\n            if (not self.no_K):\n                self.compute_K()",
  "def init_splines(self):\n        self.xm_b = self.booz.bx.xm_b\n        self.xn_b = self.booz.bx.xn_b\n\n        # Define quantities on extended half grid\n        iota = np.zeros((self.booz.bx.ns_b+2))\n        G = np.zeros((self.booz.bx.ns_b+2))\n        I = np.zeros((self.booz.bx.ns_b+2))\n\n        self.s_half_ext = np.zeros((self.booz.bx.ns_b+2))\n        self.s_half_ext[1:-1] = self.booz.bx.s_in\n        self.s_half_ext[-1] = 1\n\n        ds = self.booz.bx.s_in[1]-self.booz.bx.s_in[0]\n\n        s_full = np.linspace(0, 1, self.booz.bx.ns_in+1)\n\n        psip = self.booz.equil.wout.chi/(2*np.pi)\n        iota[1:-1] = self.booz.bx.iota\n        G[1:-1] = self.booz.bx.Boozer_G\n        I[1:-1] = self.booz.bx.Boozer_I\n        if self.rescale:\n            s_half_mn = self.booz.bx.s_in[self.ns_delete::]\n            bmnc = np.zeros((len(self.xm_b), self.booz.bx.ns_in-self.ns_delete))\n            rmnc = np.zeros((len(self.xm_b), self.booz.bx.ns_in-self.ns_delete))\n            zmns = np.zeros((len(self.xm_b), self.booz.bx.ns_in-self.ns_delete))\n            numns = np.zeros((len(self.xm_b), self.booz.bx.ns_in-self.ns_delete))\n\n            bmnc = self.booz.bx.bmnc_b[:, self.ns_delete::]\n            rmnc = self.booz.bx.rmnc_b[:, self.ns_delete::]\n            zmns = self.booz.bx.zmns_b[:, self.ns_delete::]\n            numns = self.booz.bx.numns_b[:, self.ns_delete::]\n\n            if not self.stellsym:\n                bmns = np.zeros((len(self.xm_b), self.booz.bx.ns_in-self.ns_delete))\n                rmns = np.zeros((len(self.xm_b), self.booz.bx.ns_in-self.ns_delete))\n                zmnc = np.zeros((len(self.xm_b), self.booz.bx.ns_in-self.ns_delete))\n                numnc = np.zeros((len(self.xm_b), self.booz.bx.ns_in-self.ns_delete))\n\n                bmns = self.booz.bx.bmns_b[:, self.ns_delete::]\n                rmns = self.booz.bx.rmns_b[:, self.ns_delete::]\n                zmnc = self.booz.bx.zmnc_b[:, self.ns_delete::]\n                numnc = self.booz.bx.numnc_b[:, self.ns_delete::]\n\n            mn_factor = np.ones_like(bmnc)\n            d_mn_factor = np.zeros_like(bmnc)\n            mn_factor[self.xm_b == 1, :] = s_half_mn[None, :]**(-0.5)\n            d_mn_factor[self.xm_b == 1, :] = -0.5*s_half_mn[None, :]**(-1.5)\n            mn_factor[(self.xm_b % 2 == 1)*(self.xm_b > 1), :] = s_half_mn[None, :]**(-1.5)\n            d_mn_factor[(self.xm_b % 2 == 1)*(self.xm_b > 1), :] = -1.5*s_half_mn[None, :]**(-2.5)\n            mn_factor[(self.xm_b % 2 == 0)*(self.xm_b > 1), :] = s_half_mn[None, :]**(-1.)\n            d_mn_factor[(self.xm_b % 2 == 0)*(self.xm_b > 1), :] = -s_half_mn[None, :]**(-2.)\n        else:\n            s_half_mn = self.s_half_ext\n            bmnc = np.zeros((len(self.xm_b), self.booz.bx.ns_in+2))\n            bmnc[:, 1:-1] = self.booz.bx.bmnc_b\n            bmnc[:, 0] = 1.5*bmnc[:, 1] - 0.5*bmnc[:, 2]\n            bmnc[:, -1] = 1.5*bmnc[:, -2] - 0.5*bmnc[:, -3]\n            dbmncds = (bmnc[:, 2:-1] - bmnc[:, 1:-2])/ds\n            mn_factor = np.ones_like(bmnc)\n            d_mn_factor = np.zeros_like(bmnc)\n\n            numns = np.zeros((len(self.xm_b), self.booz.bx.ns_in+2))\n            rmnc = np.zeros((len(self.xm_b), self.booz.bx.ns_in+2))\n            zmns = np.zeros((len(self.xm_b), self.booz.bx.ns_in+2))\n            numns[:, 1:-1] = self.booz.bx.numns_b\n            numns[:, 0] = 1.5*numns[:, 1] - 0.5*numns[:, 2]\n            numns[:, -1] = 1.5*numns[:, -2] - 0.5*numns[:, -3]\n            rmnc[:, 1:-1] = self.booz.bx.rmnc_b\n            rmnc[:, 0] = 1.5*rmnc[:, 1] - 0.5*rmnc[:, 2]\n            rmnc[:, -1] = 1.5*rmnc[:, -2] - 0.5*rmnc[:, -3]\n            zmns[:, 1:-1] = self.booz.bx.zmns_b\n            zmns[:, 0] = 1.5*zmns[:, 1] - 0.5*zmns[:, 2]\n            zmns[:, -1] = 1.5*zmns[:, -2] - 0.5*zmns[:, -3]\n\n            drmncds = (rmnc[:, 2:-1] - rmnc[:, 1:-2])/ds\n            dzmnsds = (zmns[:, 2:-1] - zmns[:, 1:-2])/ds\n            dnumnsds = (numns[:, 2:-1] - numns[:, 1:-2])/ds\n\n            if not self.stellsym:\n                bmns = np.zeros((len(self.xm_b), self.booz.bx.ns_in+2))\n                bmns[:, 1:-1] = self.booz.bx.bmns_b\n                bmns[:, 0] = 1.5*bmns[:, 1] - 0.5*bmns[:, 2]\n                bmns[:, -1] = 1.5*bmns[:, -2] - 0.5*bmns[:, -3]\n                dbmnsds = (bmns[:, 2:-1] - bmns[:, 1:-2])/ds\n\n                numnc = np.zeros((len(self.xm_b), self.booz.bx.ns_in+2))\n                rmns = np.zeros((len(self.xm_b), self.booz.bx.ns_in+2))\n                zmnc = np.zeros((len(self.xm_b), self.booz.bx.ns_in+2))\n                numnc[:, 1:-1] = self.booz.bx.numnc_b\n                numnc[:, 0] = 1.5*numnc[:, 1] - 0.5*numnc[:, 2]\n                numnc[:, -1] = 1.5*numnc[:, -2] - 0.5*numnc[:, -3]\n                rmns[:, 1:-1] = self.booz.bx.rmns_b\n                rmns[:, 0] = 1.5*rmns[:, 1] - 0.5*rmns[:, 2]\n                rmns[:, -1] = 1.5*rmns[:, -2] - 0.5*rmns[:, -3]\n                zmnc[:, 1:-1] = self.booz.bx.zmnc_b\n                zmnc[:, 0] = 1.5*zmnc[:, 1] - 0.5*zmnc[:, 2]\n                zmnc[:, -1] = 1.5*zmnc[:, -2] - 0.5*zmnc[:, -3]\n\n                drmnsds = (rmns[:, 2:-1] - rmns[:, 1:-2])/ds\n                dzmncds = (zmnc[:, 2:-1] - zmnc[:, 1:-2])/ds\n                dnumncds = (numnc[:, 2:-1] - numnc[:, 1:-2])/ds\n\n        # Extrapolate to get points at s = 0 and s = 1\n        iota[0] = 1.5*iota[1] - 0.5*iota[2]\n        G[0] = 1.5*G[1] - 0.5*G[2]\n        I[0] = 1.5*I[1] - 0.5*I[2]\n        iota[-1] = 1.5*iota[-2] - 0.5*iota[-3]\n        G[-1] = 1.5*G[-2] - 0.5*G[-3]\n        I[-1] = 1.5*I[-2] - 0.5*I[-3]\n        # Compute first derivatives - on full grid points in [1,ns-1]\n        dGds = (G[2:-1] - G[1:-2])/ds\n        dIds = (I[2:-1] - I[1:-2])/ds\n        diotads = (iota[2:-1] - iota[1:-2])/ds\n\n        self.psip_spline = InterpolatedUnivariateSpline(s_full, psip, k=self.order)\n        if not self.enforce_vacuum:\n            self.G_spline = InterpolatedUnivariateSpline(self.s_half_ext, G, k=self.order)\n            self.I_spline = InterpolatedUnivariateSpline(self.s_half_ext, I, k=self.order)\n            self.dGds_spline = InterpolatedUnivariateSpline(s_full[1:-1], dGds, k=self.order)\n            self.dIds_spline = InterpolatedUnivariateSpline(s_full[1:-1], dIds, k=self.order)\n        else:\n            self.G_spline = InterpolatedUnivariateSpline(self.s_half_ext, np.mean(G)*np.ones_like(self.s_half_ext), k=self.order)\n            self.I_spline = InterpolatedUnivariateSpline(self.s_half_ext, np.zeros_like(self.s_half_ext), k=self.order)\n            self.dGds_spline = InterpolatedUnivariateSpline(s_full[1:-1], np.zeros_like(s_full[1:-1]), k=self.order)\n            self.dIds_spline = InterpolatedUnivariateSpline(s_full[1:-1], np.zeros_like(s_full[1:-1]), k=self.order)\n        self.iota_spline = InterpolatedUnivariateSpline(self.s_half_ext, iota, k=self.order)\n        self.diotads_spline = InterpolatedUnivariateSpline(s_full[1:-1], diotads, k=self.order)\n\n        self.numns_splines = []\n        self.rmnc_splines = []\n        self.zmns_splines = []\n        self.dnumnsds_splines = []\n        self.drmncds_splines = []\n        self.dzmnsds_splines = []\n        self.bmnc_splines = []\n        self.dbmncds_splines = []\n        self.d_mn_factor_splines = []\n        self.mn_factor_splines = []\n        for im in range(len(self.xm_b)):\n            self.numns_splines.append(InterpolatedUnivariateSpline(s_half_mn, mn_factor[im, :]*numns[im, :], k=self.order))\n            self.rmnc_splines.append(InterpolatedUnivariateSpline(s_half_mn, mn_factor[im, :]*rmnc[im, :], k=self.order))\n            self.zmns_splines.append(InterpolatedUnivariateSpline(s_half_mn, mn_factor[im, :]*zmns[im, :], k=self.order))\n            self.mn_factor_splines.append(InterpolatedUnivariateSpline(s_half_mn, mn_factor[im, :], k=self.order))\n            self.d_mn_factor_splines.append(InterpolatedUnivariateSpline(s_half_mn, d_mn_factor[im, :], k=self.order))\n            if (self.enforce_qs and (self.xn_b[im] != self.N * self.xm_b[im])):\n                self.bmnc_splines.append(InterpolatedUnivariateSpline(s_half_mn, 0*bmnc[im, :], k=self.order))\n                self.dbmncds_splines.append(InterpolatedUnivariateSpline(s_full[1:-1], 0*dbmncds[im, :], k=self.order))\n            else:\n                self.bmnc_splines.append(InterpolatedUnivariateSpline(s_half_mn, mn_factor[im, :]*bmnc[im, :], k=self.order))\n                if self.rescale:\n                    self.dbmncds_splines.append(self.bmnc_splines[-1].derivative())\n                else:\n                    self.dbmncds_splines.append(InterpolatedUnivariateSpline(s_full[1:-1], dbmncds[im, :], k=self.order))\n\n            if self.rescale:\n                self.dnumnsds_splines.append(self.numns_splines[-1].derivative())\n                self.drmncds_splines.append(self.rmnc_splines[-1].derivative())\n                self.dzmnsds_splines.append(self.zmns_splines[-1].derivative())\n            else:\n                self.dnumnsds_splines.append(InterpolatedUnivariateSpline(s_full[1:-1], dnumnsds[im, :], k=self.order))\n                self.drmncds_splines.append(InterpolatedUnivariateSpline(s_full[1:-1], drmncds[im, :], k=self.order))\n                self.dzmnsds_splines.append(InterpolatedUnivariateSpline(s_full[1:-1], dzmnsds[im, :], k=self.order))\n\n        if not self.stellsym:\n            self.numnc_splines = []\n            self.rmns_splines = []\n            self.zmnc_splines = []\n            self.dnumncds_splines = []\n            self.drmnsds_splines = []\n            self.dzmncds_splines = []\n            self.bmns_splines = []\n            self.dbmnsds_splines = []\n            for im in range(len(self.xm_b)):\n                self.numnc_splines.append(InterpolatedUnivariateSpline(s_half_mn, mn_factor[im, :]*numnc[im, :], k=self.order))\n                self.rmns_splines.append(InterpolatedUnivariateSpline(s_half_mn, mn_factor[im, :]*rmns[im, :], k=self.order))\n                self.zmnc_splines.append(InterpolatedUnivariateSpline(s_half_mn, mn_factor[im, :]*zmnc[im, :], k=self.order))\n                if (self.enforce_qs and (self.xn_b[im] != self.N * self.xm_b[im])):\n                    self.bmns_splines.append(InterpolatedUnivariateSpline(s_half_mn, 0*bmns[im, :], k=self.order))\n                    self.dbmnsds_splines.append(InterpolatedUnivariateSpline(s_full[1:-1], 0*dbmnsds[im, :], k=self.order))\n                else:\n                    self.bmns_splines.append(InterpolatedUnivariateSpline(s_half_mn, mn_factor[im, :]*bmns[im, :], k=self.order))\n                    if self.rescale:\n                        self.dbmnsds_splines.append(self.bmns_splines[-1].derivative())\n                    else:\n                        self.dbmnsds_splines.append(InterpolatedUnivariateSpline(s_full[1:-1], dbmnsds[im, :], k=self.order))\n\n                if self.rescale:\n                    self.dnumncds_splines.append(self.numnc_splines[-1].derivative())\n                    self.drmnsds_splines.append(self.rmns_splines[-1].derivative())\n                    self.dzmncds_splines.append(self.zmnc_splines[-1].derivative())\n                else:\n                    self.dnumncds_splines.append(InterpolatedUnivariateSpline(s_full[1:-1], dnumncds[im, :], k=self.order))\n                    self.drmnsds_splines.append(InterpolatedUnivariateSpline(s_full[1:-1], drmnsds[im, :], k=self.order))\n                    self.dzmncds_splines.append(InterpolatedUnivariateSpline(s_full[1:-1], dzmncds[im, :], k=self.order))",
  "def compute_K(self):\n        ntheta = 2 * (2 * self.booz.bx.mboz + 1)\n        nzeta = 2 * (2 * self.booz.bx.nboz + 1)\n        thetas = np.linspace(0, 2*np.pi, ntheta, endpoint=False)\n        dtheta = thetas[1]-thetas[0]\n        zetas = np.linspace(0, 2*np.pi/self.booz.bx.nfp, nzeta, endpoint=False)\n        dzeta = zetas[1]-zetas[0]\n        thetas, zetas = np.meshgrid(thetas, zetas)\n        thetas = thetas.flatten()\n        zetas = zetas.flatten()\n\n        dzmnsds_half = np.zeros((len(self.xm_b), len(self.s_half_ext)))\n        drmncds_half = np.zeros((len(self.xm_b), len(self.s_half_ext)))\n        dnumnsds_half = np.zeros((len(self.xm_b), len(self.s_half_ext)))\n        bmnc_half = np.zeros((len(self.xm_b), len(self.s_half_ext)))\n        rmnc_half = np.zeros((len(self.xm_b), len(self.s_half_ext)))\n        zmns_half = np.zeros((len(self.xm_b), len(self.s_half_ext)))\n        numns_half = np.zeros((len(self.xm_b), len(self.s_half_ext)))\n        if not self.stellsym:\n            dzmncds_half = np.zeros((len(self.xm_b), len(self.s_half_ext)))\n            drmnsds_half = np.zeros((len(self.xm_b), len(self.s_half_ext)))\n            dnumncds_half = np.zeros((len(self.xm_b), len(self.s_half_ext)))\n            bmns_half = np.zeros((len(self.xm_b), len(self.s_half_ext)))\n            rmns_half = np.zeros((len(self.xm_b), len(self.s_half_ext)))\n            zmnc_half = np.zeros((len(self.xm_b), len(self.s_half_ext)))\n            numnc_half = np.zeros((len(self.xm_b), len(self.s_half_ext)))\n        for im in range(len(self.xm_b)):\n            mn_factor = self.mn_factor_splines[im](self.s_half_ext)\n            d_mn_factor = self.d_mn_factor_splines[im](self.s_half_ext)\n            dnumnsds_half[im, :] = ((self.dnumnsds_splines[im](self.s_half_ext) - self.numns_splines[im](self.s_half_ext)*d_mn_factor/mn_factor)/mn_factor)\n            drmncds_half[im, :] = ((self.drmncds_splines[im](self.s_half_ext) - self.rmnc_splines[im](self.s_half_ext)*d_mn_factor/mn_factor)/mn_factor)\n            dzmnsds_half[im, :] = ((self.dzmnsds_splines[im](self.s_half_ext) - self.zmns_splines[im](self.s_half_ext)*d_mn_factor/mn_factor)/mn_factor)\n            bmnc_half[im, :] = self.bmnc_splines[im](self.s_half_ext)/mn_factor\n            rmnc_half[im, :] = self.rmnc_splines[im](self.s_half_ext)/mn_factor\n            zmns_half[im, :] = self.zmns_splines[im](self.s_half_ext)/mn_factor\n            numns_half[im, :] = self.numns_splines[im](self.s_half_ext)/mn_factor\n            if not self.stellsym:\n                dnumncds_half[im, :] = ((self.dnumncds_splines[im](self.s_half_ext) - self.numnc_splines[im](self.s_half_ext)*d_mn_factor/mn_factor)/mn_factor)\n                drmnsds_half[im, :] = ((self.drmnsds_splines[im](self.s_half_ext) - self.rmns_splines[im](self.s_half_ext)*d_mn_factor/mn_factor)/mn_factor)\n                dzmncds_half[im, :] = ((self.dzmncds_splines[im](self.s_half_ext) - self.zmnc_splines[im](self.s_half_ext)*d_mn_factor/mn_factor)/mn_factor)\n                bmns_half[im, :] = self.bmns_splines[im](self.s_half_ext)/mn_factor\n                rmns_half[im, :] = self.rmns_splines[im](self.s_half_ext)/mn_factor\n                zmnc_half[im, :] = self.zmnc_splines[im](self.s_half_ext)/mn_factor\n                numnc_half[im, :] = self.numnc_splines[im](self.s_half_ext)/mn_factor\n\n        G_half = self.G_spline(self.s_half_ext)\n        I_half = self.I_spline(self.s_half_ext)\n        iota_half = self.iota_spline(self.s_half_ext)\n\n        if not self.stellsym:\n            kmnc_kmns = sopp.compute_kmnc_kmns(rmnc_half, drmncds_half, zmns_half, dzmnsds_half,\n                                               numns_half, dnumnsds_half, bmnc_half,\n                                               rmns_half, drmnsds_half, zmnc_half, dzmncds_half,\n                                               numnc_half, dnumncds_half, bmns_half,\n                                               iota_half, G_half, I_half, self.xm_b, self.xn_b, thetas, zetas)\n            kmnc = kmnc_kmns[0, :, :]\n            kmns = kmnc_kmns[1, :, :]\n            kmnc = kmnc*dtheta*dzeta*self.booz.bx.nfp/self.psi0\n        else:\n            kmns = sopp.compute_kmns(rmnc_half, drmncds_half, zmns_half, dzmnsds_half,\n                                     numns_half, dnumnsds_half, bmnc_half, iota_half, G_half, I_half,\n                                     self.xm_b, self.xn_b, thetas, zetas)\n        kmns = kmns*dtheta*dzeta*self.booz.bx.nfp/self.psi0\n\n        self.kmns_splines = []\n        if not self.stellsym:\n            self.kmnc_splines = []\n        for im in range(len(self.xm_b)):\n            if (self.enforce_qs and (self.xn_b[im] != self.N * self.xm_b[im])):\n                self.kmns_splines.append(InterpolatedUnivariateSpline(self.s_half_ext, 0*kmns[im, :], k=self.order))\n                if not self.stellsym:\n                    self.kmnc_splines.append(InterpolatedUnivariateSpline(self.s_half_ext, 0*kmnc[im, :], k=self.order))\n            else:\n                self.kmns_splines.append(InterpolatedUnivariateSpline(self.s_half_ext, self.mn_factor_splines[im](self.s_half_ext)*kmns[im, :], k=self.order))\n                if not self.stellsym:\n                    self.kmnc_splines.append(InterpolatedUnivariateSpline(self.s_half_ext, self.mn_factor_splines[im](self.s_half_ext)*kmnc[im, :], k=self.order))",
  "def _K_impl(self, K):\n        points = self.get_points_ref()\n        s = points[:, 0]\n        thetas = points[:, 1]\n        zetas = points[:, 2]\n        K[:, 0] = 0.\n        if self.no_K:\n            return\n        kmns = np.zeros((len(self.xm_b), len(s)))\n        for im in range(len(self.xm_b)):\n            kmns[im, :] = self.kmns_splines[im](s)/self.mn_factor_splines[im](s)\n        sopp.inverse_fourier_transform_odd(K[:, 0], kmns, self.xm_b, self.xn_b, thetas, zetas)\n        if not self.stellsym:\n            kmnc = np.zeros((len(self.xm_b), len(s)))\n            for im in range(len(self.xm_b)):\n                kmnc[im, :] = self.kmnc_splines[im](s)/self.mn_factor_splines[im](s)\n            sopp.inverse_fourier_transform_even(K[:, 0], kmnc, self.xm_b, self.xn_b, thetas, zetas)",
  "def _dKdtheta_impl(self, dKdtheta):\n        points = self.get_points_ref()\n        s = points[:, 0]\n        thetas = points[:, 1]\n        zetas = points[:, 2]\n        dKdtheta[:, 0] = 0.\n        if self.no_K:\n            return\n        kmns = np.zeros((len(self.xm_b), len(s)))\n        for im in range(len(self.xm_b)):\n            kmns[im, :] = self.kmns_splines[im](s) * self.xm_b[im]/self.mn_factor_splines[im](s)\n        sopp.inverse_fourier_transform_even(dKdtheta[:, 0], kmns, self.xm_b, self.xn_b, thetas, zetas)\n        if not self.stellsym:\n            kmnc = np.zeros((len(self.xm_b), len(s)))\n            for im in range(len(self.xm_b)):\n                kmnc[im, :] = -self.kmnc_splines[im](s) * self.xm_b[im]/self.mn_factor_splines[im](s)\n            sopp.inverse_fourier_transform_odd(dKdtheta[:, 0], kmnc, self.xm_b, self.xn_b, thetas, zetas)",
  "def _dKdzeta_impl(self, dKdzeta):\n        points = self.get_points_ref()\n        s = points[:, 0]\n        thetas = points[:, 1]\n        zetas = points[:, 2]\n        dKdzeta[:, 0] = 0.\n        if (self.no_K):\n            return\n        kmns = np.zeros((len(self.xm_b), len(s)))\n        for im in range(len(self.xm_b)):\n            kmns[im, :] = -self.kmns_splines[im](s) * self.xn_b[im]/self.mn_factor_splines[im](s)\n        sopp.inverse_fourier_transform_even(dKdzeta[:, 0], kmns, self.xm_b, self.xn_b, thetas, zetas)\n        if not self.stellsym:\n            kmnc = np.zeros((len(self.xm_b), len(s)))\n            for im in range(len(self.xm_b)):\n                kmnc[im, :] = self.kmnc_splines[im](s) * self.xn_b[im]/self.mn_factor_splines[im](s)\n            sopp.inverse_fourier_transform_odd(dKdzeta[:, 0], kmnc, self.xm_b, self.xn_b, thetas, zetas)",
  "def _nu_impl(self, nu):\n        points = self.get_points_ref()\n        s = points[:, 0]\n        thetas = points[:, 1]\n        zetas = points[:, 2]\n        numns = np.zeros((len(self.xm_b), len(s)))\n        for im in range(len(self.xm_b)):\n            numns[im, :] = self.numns_splines[im](s)/self.mn_factor_splines[im](s)\n        nu[:, 0] = 0.\n        sopp.inverse_fourier_transform_odd(nu[:, 0], numns, self.xm_b, self.xn_b, thetas, zetas)\n        if not self.stellsym:\n            numnc = np.zeros((len(self.xm_b), len(s)))\n            for im in range(len(self.xm_b)):\n                numnc[im, :] = self.numnc_splines[im](s)/self.mn_factor_splines[im](s)\n            sopp.inverse_fourier_transform_even(nu[:, 0], numnc, self.xm_b, self.xn_b, thetas, zetas)",
  "def _dnudtheta_impl(self, dnudtheta):\n        points = self.get_points_ref()\n        s = points[:, 0]\n        thetas = points[:, 1]\n        zetas = points[:, 2]\n        numns = np.zeros((len(self.xm_b), len(s)))\n        for im in range(len(self.xm_b)):\n            numns[im, :] = self.numns_splines[im](s)*self.xm_b[im]/self.mn_factor_splines[im](s)\n        dnudtheta[:, 0] = 0.\n        sopp.inverse_fourier_transform_even(dnudtheta[:, 0], numns, self.xm_b, self.xn_b, thetas, zetas)\n        if not self.stellsym:\n            numnc = np.zeros((len(self.xm_b), len(s)))\n            for im in range(len(self.xm_b)):\n                numnc[im, :] = -self.numnc_splines[im](s)*self.xm_b[im]/self.mn_factor_splines[im](s)\n            sopp.inverse_fourier_transform_odd(dnudtheta[:, 0], numnc, self.xm_b, self.xn_b, thetas, zetas)",
  "def _dnudzeta_impl(self, dnudzeta):\n        points = self.get_points_ref()\n        s = points[:, 0]\n        thetas = points[:, 1]\n        zetas = points[:, 2]\n        numns = np.zeros((len(self.xm_b), len(s)))\n        for im in range(len(self.xm_b)):\n            numns[im, :] = -self.numns_splines[im](s)*self.xn_b[im]/self.mn_factor_splines[im](s)\n        dnudzeta[:, 0] = 0.\n        sopp.inverse_fourier_transform_even(dnudzeta[:, 0], numns, self.xm_b, self.xn_b, thetas, zetas)\n        if not self.stellsym:\n            numnc = np.zeros((len(self.xm_b), len(s)))\n            for im in range(len(self.xm_b)):\n                numnc[im, :] = self.numnc_splines[im](s)*self.xn_b[im]/self.mn_factor_splines[im](s)\n            sopp.inverse_fourier_transform_odd(dnudzeta[:, 0], numnc, self.xm_b, self.xn_b, thetas, zetas)",
  "def _dnuds_impl(self, dnuds):\n        points = self.get_points_ref()\n        s = points[:, 0]\n        thetas = points[:, 1]\n        zetas = points[:, 2]\n        numns = np.zeros((len(self.xm_b), len(s)))\n        for im in range(len(self.xm_b)):\n            d_mn_factor = self.d_mn_factor_splines[im](s)\n            mn_factor = self.mn_factor_splines[im](s)\n            numns[im, :] = ((self.dnumnsds_splines[im](s) - self.numns_splines[im](s)*d_mn_factor/mn_factor)/mn_factor)\n        dnuds[:, 0] = 0.\n        sopp.inverse_fourier_transform_odd(dnuds[:, 0], numns, self.xm_b, self.xn_b, thetas, zetas)\n        if not self.stellsym:\n            numnc = np.zeros((len(self.xm_b), len(s)))\n            for im in range(len(self.xm_b)):\n                d_mn_factor = self.d_mn_factor_splines[im](s)\n                mn_factor = self.mn_factor_splines[im](s)\n                numnc[im, :] = ((self.dnumncds_splines[im](s) - self.numnc_splines[im](s)*d_mn_factor/mn_factor)/mn_factor)\n            sopp.inverse_fourier_transform_even(dnuds[:, 0], numnc, self.xm_b, self.xn_b, thetas, zetas)",
  "def _dRdtheta_impl(self, dRdtheta):\n        points = self.get_points_ref()\n        s = points[:, 0]\n        thetas = points[:, 1]\n        zetas = points[:, 2]\n        rmnc = np.zeros((len(self.xm_b), len(s)))\n        for im in range(len(self.xm_b)):\n            rmnc[im, :] = -self.rmnc_splines[im](s)*self.xm_b[im]/self.mn_factor_splines[im](s)\n        dRdtheta[:, 0] = 0.\n        sopp.inverse_fourier_transform_odd(dRdtheta[:, 0], rmnc, self.xm_b, self.xn_b, thetas, zetas)\n        if not self.stellsym:\n            rmns = np.zeros((len(self.xm_b), len(s)))\n            for im in range(len(self.xm_b)):\n                rmns[im, :] = self.rmns_splines[im](s)*self.xm_b[im]/self.mn_factor_splines[im](s)\n            sopp.inverse_fourier_transform_even(dRdtheta[:, 0], rmns, self.xm_b, self.xn_b, thetas, zetas)",
  "def _dRdzeta_impl(self, dRdzeta):\n        points = self.get_points_ref()\n        s = points[:, 0]\n        thetas = points[:, 1]\n        zetas = points[:, 2]\n        rmnc = np.zeros((len(self.xm_b), len(s)))\n        for im in range(len(self.xm_b)):\n            rmnc[im, :] = self.rmnc_splines[im](s)*self.xn_b[im]/self.mn_factor_splines[im](s)\n        dRdzeta[:, 0] = 0.\n        sopp.inverse_fourier_transform_odd(dRdzeta[:, 0], rmnc, self.xm_b, self.xn_b, thetas, zetas)\n        if not self.stellsym:\n            rmns = np.zeros((len(self.xm_b), len(s)))\n            for im in range(len(self.xm_b)):\n                rmns[im, :] = -self.rmns_splines[im](s)*self.xn_b[im]/self.mn_factor_splines[im](s)\n            sopp.inverse_fourier_transform_even(dRdzeta[:, 0], rmns, self.xm_b, self.xn_b, thetas, zetas)",
  "def _dRds_impl(self, dRds):\n        points = self.get_points_ref()\n        s = points[:, 0]\n        thetas = points[:, 1]\n        zetas = points[:, 2]\n        rmnc = np.zeros((len(self.xm_b), len(s)))\n        for im in range(len(self.xm_b)):\n            d_mn_factor = self.d_mn_factor_splines[im](s)\n            mn_factor = self.mn_factor_splines[im](s)\n            rmnc[im, :] = ((self.drmncds_splines[im](s) - self.rmnc_splines[im](s)*d_mn_factor/mn_factor)/mn_factor)\n        dRds[:, 0] = 0.\n        sopp.inverse_fourier_transform_even(dRds[:, 0], rmnc, self.xm_b, self.xn_b, thetas, zetas)\n        if not self.stellsym:\n            rmns = np.zeros((len(self.xm_b), len(s)))\n            for im in range(len(self.xm_b)):\n                d_mn_factor = self.d_mn_factor_splines[im](s)\n                mn_factor = self.mn_factor_splines[im](s)\n                rmns[im, :] = ((self.drmnsds_splines[im](s) - self.rmns_splines[im](s)*d_mn_factor/mn_factor)/mn_factor)\n            sopp.inverse_fourier_transform_odd(dRds[:, 0], rmns, self.xm_b, self.xn_b, thetas, zetas)",
  "def _R_impl(self, R):\n        points = self.get_points_ref()\n        s = points[:, 0]\n        thetas = points[:, 1]\n        zetas = points[:, 2]\n        rmnc = np.zeros((len(self.xm_b), len(s)))\n        for im in range(len(self.xm_b)):\n            rmnc[im, :] = self.rmnc_splines[im](s)/self.mn_factor_splines[im](s)\n        R[:, 0] = 0.\n        sopp.inverse_fourier_transform_even(R[:, 0], rmnc, self.xm_b, self.xn_b, thetas, zetas)\n        if not self.stellsym:\n            rmns = np.zeros((len(self.xm_b), len(s)))\n            for im in range(len(self.xm_b)):\n                rmns[im, :] = self.rmns_splines[im](s)/self.mn_factor_splines[im](s)\n            sopp.inverse_fourier_transform_odd(R[:, 0], rmns, self.xm_b, self.xn_b, thetas, zetas)",
  "def _dZdtheta_impl(self, dZdtheta):\n        points = self.get_points_ref()\n        s = points[:, 0]\n        thetas = points[:, 1]\n        zetas = points[:, 2]\n        zmns = np.zeros((len(self.xm_b), len(s)))\n        for im in range(len(self.xm_b)):\n            zmns[im, :] = self.zmns_splines[im](s)*self.xm_b[im]/self.mn_factor_splines[im](s)\n        dZdtheta[:, 0] = 0.\n        sopp.inverse_fourier_transform_even(dZdtheta[:, 0], zmns, self.xm_b, self.xn_b, thetas, zetas)\n        if not self.stellsym:\n            zmnc = np.zeros((len(self.xm_b), len(s)))\n            for im in range(len(self.xm_b)):\n                zmnc[im, :] = -self.zmnc_splines[im](s)*self.xm_b[im]/self.mn_factor_splines[im](s)\n            sopp.inverse_fourier_transform_odd(dZdtheta[:, 0], zmnc, self.xm_b, self.xn_b, thetas, zetas)",
  "def _dZdzeta_impl(self, dZdzeta):\n        points = self.get_points_ref()\n        s = points[:, 0]\n        thetas = points[:, 1]\n        zetas = points[:, 2]\n        zmns = np.zeros((len(self.xm_b), len(s)))\n        for im in range(len(self.xm_b)):\n            zmns[im, :] = -self.zmns_splines[im](s)*self.xn_b[im]/self.mn_factor_splines[im](s)\n        dZdzeta[:, 0] = 0.\n        sopp.inverse_fourier_transform_even(dZdzeta[:, 0], zmns, self.xm_b, self.xn_b, thetas, zetas)\n        if not self.stellsym:\n            zmnc = np.zeros((len(self.xm_b), len(s)))\n            for im in range(len(self.xm_b)):\n                zmnc[im, :] = self.zmnc_splines[im](s)*self.xn_b[im]/self.mn_factor_splines[im](s)\n            sopp.inverse_fourier_transform_odd(dZdzeta[:, 0], zmnc, self.xm_b, self.xn_b, thetas, zetas)",
  "def _dZds_impl(self, dZds):\n        points = self.get_points_ref()\n        s = points[:, 0]\n        thetas = points[:, 1]\n        zetas = points[:, 2]\n        zmns = np.zeros((len(self.xm_b), len(s)))\n        for im in range(len(self.xm_b)):\n            d_mn_factor = self.d_mn_factor_splines[im](s)\n            mn_factor = self.mn_factor_splines[im](s)\n            zmns[im, :] = ((self.dzmnsds_splines[im](s) - self.zmns_splines[im](s)*d_mn_factor/mn_factor)/mn_factor)\n        dZds[:, 0] = 0.\n        sopp.inverse_fourier_transform_odd(dZds[:, 0], zmns, self.xm_b, self.xn_b, thetas, zetas)\n        if not self.stellsym:\n            zmnc = np.zeros((len(self.xm_b), len(s)))\n            for im in range(len(self.xm_b)):\n                d_mn_factor = self.d_mn_factor_splines[im](s)\n                mn_factor = self.mn_factor_splines[im](s)\n                zmnc[im, :] = ((self.dzmncds_splines[im](s) - self.zmnc_splines[im](s)*d_mn_factor/mn_factor)/mn_factor)\n            sopp.inverse_fourier_transform_even(dZds[:, 0], zmnc, self.xm_b, self.xn_b, thetas, zetas)",
  "def _Z_impl(self, Z):\n        points = self.get_points_ref()\n        s = points[:, 0]\n        thetas = points[:, 1]\n        zetas = points[:, 2]\n        zmns = np.zeros((len(self.xm_b), len(s)))\n        for im in range(len(self.xm_b)):\n            zmns[im, :] = self.zmns_splines[im](s)/self.mn_factor_splines[im](s)\n        Z[:, 0] = 0.\n        sopp.inverse_fourier_transform_odd(Z[:, 0], zmns, self.xm_b, self.xn_b, thetas, zetas)\n        if not self.stellsym:\n            zmnc = np.zeros((len(self.xm_b), len(s)))\n            for im in range(len(self.xm_b)):\n                zmnc[im, :] = self.zmnc_splines[im](s)/self.mn_factor_splines[im](s)\n            sopp.inverse_fourier_transform_even(Z[:, 0], zmnc, self.xm_b, self.xn_b, thetas, zetas)",
  "def _psip_impl(self, psip):\n        points = self.get_points_ref()\n        s = points[:, 0]\n        psip[:] = self.psip_spline(s)[:, None]",
  "def _G_impl(self, G):\n        points = self.get_points_ref()\n        s = points[:, 0]\n        G[:] = self.G_spline(s)[:, None]",
  "def _I_impl(self, I):\n        points = self.get_points_ref()\n        s = points[:, 0]\n        I[:] = self.I_spline(s)[:, None]",
  "def _iota_impl(self, iota):\n        points = self.get_points_ref()\n        s = points[:, 0]\n        iota[:] = self.iota_spline(s)[:, None]",
  "def _dGds_impl(self, dGds):\n        points = self.get_points_ref()\n        s = points[:, 0]\n        dGds[:] = self.dGds_spline(s)[:, None]",
  "def _dIds_impl(self, dIds):\n        points = self.get_points_ref()\n        s = points[:, 0]\n        dIds[:] = self.dIds_spline(s)[:, None]",
  "def _diotads_impl(self, diotads):\n        points = self.get_points_ref()\n        s = points[:, 0]\n        diotads[:] = self.diotads_spline(s)[:, None]",
  "def _modB_impl(self, modB):\n        points = self.get_points_ref()\n        s = points[:, 0]\n        thetas = points[:, 1]\n        zetas = points[:, 2]\n        bmnc = np.zeros((len(self.xm_b), len(s)))\n        for im in range(len(self.xm_b)):\n            bmnc[im, :] = self.bmnc_splines[im](s)/self.mn_factor_splines[im](s)\n        modB[:, 0] = 0.\n        sopp.inverse_fourier_transform_even(modB[:, 0], bmnc, self.xm_b, self.xn_b, thetas, zetas)\n        if not self.stellsym:\n            bmns = np.zeros((len(self.xm_b), len(s)))\n            for im in range(len(self.xm_b)):\n                bmns[im, :] = self.bmns_splines[im](s)/self.mn_factor_splines[im](s)\n            sopp.inverse_fourier_transform_odd(modB[:, 0], bmns, self.xm_b, self.xn_b, thetas, zetas)",
  "def _dmodBdtheta_impl(self, dmodBdtheta):\n        points = self.get_points_ref()\n        s = points[:, 0]\n        thetas = points[:, 1]\n        zetas = points[:, 2]\n        bmnc = np.zeros((len(self.xm_b), len(s)))\n        for im in range(len(self.xm_b)):\n            bmnc[im, :] = -self.xm_b[im]*self.bmnc_splines[im](s)/self.mn_factor_splines[im](s)\n        dmodBdtheta[:, 0] = 0.\n        sopp.inverse_fourier_transform_odd(dmodBdtheta[:, 0], bmnc, self.xm_b, self.xn_b, thetas, zetas)\n        if not self.stellsym:\n            bmns = np.zeros((len(self.xm_b), len(s)))\n            for im in range(len(self.xm_b)):\n                bmns[im, :] = self.xm_b[im]*self.bmns_splines[im](s)/self.mn_factor_splines[im](s)\n            sopp.inverse_fourier_transform_even(dmodBdtheta[:, 0], bmns, self.xm_b, self.xn_b, thetas, zetas)",
  "def _dmodBdzeta_impl(self, dmodBdzeta):\n        points = self.get_points_ref()\n        s = points[:, 0]\n        thetas = points[:, 1]\n        zetas = points[:, 2]\n        bmnc = np.zeros((len(self.xm_b), len(s)))\n        for im in range(len(self.xm_b)):\n            bmnc[im, :] = self.xn_b[im]*self.bmnc_splines[im](s)/self.mn_factor_splines[im](s)\n        dmodBdzeta[:, 0] = 0.\n        sopp.inverse_fourier_transform_odd(dmodBdzeta[:, 0], bmnc, self.xm_b, self.xn_b, thetas, zetas)\n        if not self.stellsym:\n            bmns = np.zeros((len(self.xm_b), len(s)))\n            for im in range(len(self.xm_b)):\n                bmns[im, :] = -self.xn_b[im]*self.bmns_splines[im](s)/self.mn_factor_splines[im](s)\n            sopp.inverse_fourier_transform_even(dmodBdzeta[:, 0], bmns, self.xm_b, self.xn_b, thetas, zetas)",
  "def _dmodBds_impl(self, dmodBds):\n        points = self.get_points_ref()\n        s = points[:, 0]\n        thetas = points[:, 1]\n        zetas = points[:, 2]\n        bmnc = np.zeros((len(self.xm_b), len(s)))\n        for im in range(len(self.xm_b)):\n            mn_factor = self.mn_factor_splines[im](s)\n            d_mn_factor = self.d_mn_factor_splines[im](s)\n            bmnc[im, :] = ((self.dbmncds_splines[im](s) - self.bmnc_splines[im](s)*d_mn_factor/mn_factor)/mn_factor)\n        dmodBds[:, 0] = 0.\n        sopp.inverse_fourier_transform_even(dmodBds[:, 0], bmnc, self.xm_b, self.xn_b, thetas, zetas)\n        if not self.stellsym:\n            bmns = np.zeros((len(self.xm_b), len(s)))\n            for im in range(len(self.xm_b)):\n                mn_factor = self.mn_factor_splines[im](s)\n                d_mn_factor = self.d_mn_factor_splines[im](s)\n                bmns[im, :] = ((self.dbmnsds_splines[im](s) - self.bmns_splines[im](s)*d_mn_factor/mn_factor)/mn_factor)\n            sopp.inverse_fourier_transform_odd(dmodBds[:, 0], bmns, self.xm_b, self.xn_b, thetas, zetas)",
  "def __init__(self, field, degree, srange, thetarange, zetarange, extrapolate=True, nfp=1, stellsym=True):\n        r\"\"\"\n        Args:\n            field: the underlying :class:`simsopt.field.boozermagneticfield.BoozerMagneticField` to be interpolated.\n            degree: the degree of the piecewise polynomial interpolant.\n            srange: a 3-tuple of the form ``(smin, smax, ns)``. This mean that\n                the interval ``[smin, smax]`` is split into ``ns`` many subintervals.\n            thetarange: a 3-tuple of the form ``(thetamin, thetamax, ntheta)``.\n                thetamin must be >= 0, and thetamax must be <=2*pi.\n            zetarange: a 3-tuple of the form ``(zetamin, zetamax, nzeta)``.\n                zetamin must be >= 0, and thetamax must be <=2*pi.\n            extrapolate: whether to extrapolate the field when evaluate outside\n                         the integration domain or to throw an error.\n            nfp: Whether to exploit rotational symmetry. In this case any toroidal angle\n                 is always mapped into the interval :math:`[0, 2\\pi/\\mathrm{nfp})`,\n                 hence it makes sense to use ``zetamin=0`` and\n                 ``zetamax=2*np.pi/nfp``.\n            stellsym: Whether to exploit stellarator symmetry. In this case\n                      ``theta`` is always mapped to the interval :math:`[0, \\pi]`,\n                      hence it makes sense to use ``thetamin=0`` and ``thetamax=np.pi``.\n        \"\"\"\n        BoozerMagneticField.__init__(self, field.psi0)\n        if (np.any(np.asarray(thetarange[0:2]) < 0) or np.any(np.asarray(thetarange[0:2]) > 2*np.pi)):\n            raise ValueError(\"thetamin and thetamax must be in [0,2*pi]\")\n        if (np.any(np.asarray(zetarange[0:2]) < 0) or np.any(np.asarray(zetarange[0:2]) > 2*np.pi)):\n            raise ValueError(\"zetamin and zetamax must be in [0,2*pi]\")\n        if stellsym and (np.any(np.asarray(thetarange[0:2]) < 0) or np.any(np.asarray(thetarange[0:2]) > np.pi)):\n            logger.warning(fr\"Sure about thetarange=[{thetarange[0]},{thetarange[1]}]? When exploiting stellarator symmetry, the interpolant is only evaluated for theta in [0,pi].\")\n        if nfp > 1 and (np.any(np.asarray(zetarange[0:2]) < 0) or np.any(np.asarray(zetarange[0:2]) > 2*np.pi/nfp)):\n            logger.warning(fr\"Sure about zetarange=[{zetarange[0]},{zetarange[1]}]? When exploiting rotational symmetry, the interpolant is only evaluated for zeta in [0,2\\pi/nfp].\")\n\n        sopp.InterpolatedBoozerField.__init__(self, field, degree, srange, thetarange, zetarange, extrapolate, nfp, stellsym)",
  "def draw_uniform_on_curve(curve, nsamples, safetyfactor=10):\n    r\"\"\"\n    Uses rejection sampling to sample points on a curve. *Warning*: assumes that\n    the underlying quadrature points on the Curve are uniformly distributed.\n\n    Args:\n        curve: The :mod:`simsopt.geo.curve.Curve` to spawn the particles on.\n        nsamples: number of samples.\n        safetyfactor: how many more samples than ``nsamples`` to generate for\n                      rejection/acceptance.\n    \"\"\"\n    alen = curve.incremental_arclength()\n    M = np.max(alen)\n    nattempts = 10 * nsamples\n    idxs = np.random.randint(0, alen.shape[0], size=(nattempts, ))\n    accept = np.where(np.random.uniform(low=0, high=1, size=(nattempts, )) < alen[idxs]/M)[0]\n    assert len(accept) > nsamples\n    idxs = np.sort(idxs[accept[:nsamples]])\n    xyz = curve.gamma()[idxs, :]\n    return xyz, idxs",
  "def draw_uniform_on_surface(surface, nsamples, safetyfactor=10):\n    r\"\"\"\n    Uses rejection sampling to sample points on a surface. *Warning*: assumes that\n    the underlying quadrature points on the surface are uniformly distributed.\n\n    Args:\n        surface: The :mod:`simsopt.geo.surface.Surface` to spawn the particles\n                 on.\n        nsamples: number of samples.\n        safetyfactor: how many more samples than ``nsamples`` to generate for\n                      rejection/acceptance.\n    \"\"\"\n    jac = np.linalg.norm(surface.normal().reshape((-1, 3)), axis=1)\n    M = np.max(jac)\n    nattempts = 10 * nsamples\n    idxs = np.random.randint(0, jac.shape[0], size=(nattempts, ))\n    accept = np.where(np.random.uniform(low=0, high=1, size=(nattempts, )) < jac[idxs]/M)[0]\n    assert len(accept) > nsamples\n    idxs = np.sort(idxs[accept[:nsamples]])\n    gamma = surface.gamma()\n    order = 'F' if np.isfortran(gamma) else 'C'\n    idxs = np.unravel_index(idxs, gamma.shape[:2], order)\n    xyz = gamma[idxs[0], idxs[1], :]\n    return xyz, idxs",
  "class MagneticField(sopp.MagneticField, Optimizable):\n\n    '''\n    Generic class that represents any magnetic field from which each magnetic\n    field class inherits. The usage of ``MagneticField`` is as follows:\n\n    .. code-block::\n\n        bfield = BiotSavart(coils) # An instance of a MagneticField\n        points = ... # points is a (n, 3) numpy array\n        bfield.set_points(points)\n        B = bfield.B() # returns the Magnetic field at `points`\n        dA = bfield.dA_by_dX() # returns the gradient of the potential of the field at `points`\n\n    ``MagneticField`` has a cache to avoid repeated calculations.\n    To clear this cache manually, call the `clear_cached_properties()` function.\n    The cache is automatically cleared when ``set_points`` is called or one of the dependencies\n    changes.\n\n    '''\n\n    def set_points(self, xyz):\n        return self.set_points_cart(xyz)\n\n    def set_points_cart(self, xyz):\n        if len(xyz.shape) != 2 or xyz.shape[1] != 3:\n            raise ValueError(f\"xyz array should have shape (n, 3), but has shape {xyz.shape}\")\n        if not xyz.flags['C_CONTIGUOUS']:\n            raise ValueError(\"xyz array should be C contiguous. Consider using `numpy.ascontiguousarray`.\")\n        return sopp.MagneticField.set_points_cart(self, xyz)\n\n    def set_points_cyl(self, rphiz):\n        if len(rphiz.shape) != 2 or rphiz.shape[1] != 3:\n            raise ValueError(f\"rphiz array should have shape (n, 3), but has shape {rphiz.shape}\")\n        if not rphiz.flags['C_CONTIGUOUS']:\n            raise ValueError(\"rphiz array should be C contiguous. Consider using `numpy.ascontiguousarray`.\")\n        return sopp.MagneticField.set_points_cyl(self, rphiz)\n\n    def __init__(self, **kwargs):\n        sopp.MagneticField.__init__(self)\n        Optimizable.__init__(self, **kwargs)\n\n    def clear_cached_properties(self):\n        \"\"\"Clear the cache.\"\"\"\n        sopp.MagneticField.invalidate_cache(self)\n\n    def recompute_bell(self, parent=None):\n        if np.any(self.dofs_free_status):\n            self.clear_cached_properties()\n\n    def __add__(self, other):\n        \"\"\"Add two magnetic fields.\"\"\"\n        return MagneticFieldSum([self, other])\n\n    def __mul__(self, other):\n        \"\"\"Multiply a field with a scalar.\"\"\"\n        return MagneticFieldMultiply(other, self)\n\n    def __rmul__(self, other):\n        \"\"\"Multiply a field with a scalar.\"\"\"\n        return MagneticFieldMultiply(other, self)\n\n    def to_vtk(self, filename, nr=10, nphi=10, nz=10, rmin=1.0, rmax=2.0, zmin=-0.5, zmax=0.5):\n        \"\"\"Export the field evaluated on a regular grid for visualisation with e.g. Paraview.\"\"\"\n        from pyevtk.hl import gridToVTK\n        rs = np.linspace(rmin, rmax, nr, endpoint=True)\n        phis = np.linspace(0, 2*np.pi, nphi, endpoint=True)\n        zs = np.linspace(zmin, zmax, nz, endpoint=True)\n\n        R, Phi, Z = np.meshgrid(rs, phis, zs)\n        X = R * np.cos(Phi)\n        Y = R * np.sin(Phi)\n        Z = Z\n\n        RPhiZ = np.zeros((R.size, 3))\n        RPhiZ[:, 0] = R.flatten()\n        RPhiZ[:, 1] = Phi.flatten()\n        RPhiZ[:, 2] = Z.flatten()\n\n        self.set_points_cyl(RPhiZ)\n        vals = self.B().reshape((R.shape[0], R.shape[1], R.shape[2], 3))\n        contig = np.ascontiguousarray\n        gridToVTK(filename, X, Y, Z, pointData={\"B\": (contig(vals[..., 0]), contig(vals[..., 1]), contig(vals[..., 2]))})\n\n    def to_mgrid(self, filename, nr=10, nphi=4, nz=12, rmin=1.0, rmax=2.0, zmin=-0.5, zmax=0.5, nfp=1):\n        \"\"\"Export the field to the mgrid format for free boundary calculations.\n\n        The field data is represented as a single \"current group\". For\n        free-boundary vmec, the \"extcur\" array should have a single nonzero\n        element, set to 1.0.\n\n        In the future, we may want to implement multiple current groups.\n\n        Args:\n            filename: Name of the NetCDF file to save.\n            nr: Number of grid points in the major radius dimension.\n            nphi: Number of planes in the toroidal angle.\n            nz: Number of grid points in the z coordinate.\n            rmin: Minimum value of major radius for the grid.\n            rmax: Maximum value of major radius for the grid.\n            zmin: Minimum value of z for the grid.\n            zmax: Maximum value of z for the grid.\n            nfp: Number of field periods.\n        \"\"\"\n\n        rs = np.linspace(rmin, rmax, nr, endpoint=True)\n        phis = np.linspace(0, 2 * np.pi / nfp, nphi, endpoint=False)\n        zs = np.linspace(zmin, zmax, nz, endpoint=True)\n\n        Phi, Z, R = np.meshgrid(phis, zs, rs, indexing='ij')\n        X = R * np.cos(Phi)\n        Y = R * np.sin(Phi)\n        Z = Z\n\n        RPhiZ = np.zeros((R.size, 3))\n        RPhiZ[:, 0] = R.flatten()\n        RPhiZ[:, 1] = Phi.flatten()  \n        RPhiZ[:, 2] = Z.flatten()\n\n        # get field on the grid\n        self.set_points_cyl(RPhiZ)\n        B = self.B_cyl()\n\n        # shape the components\n        br, bp, bz = B.T\n        br_3 = br.reshape((nphi, nz, nr))\n        bp_3 = bp.reshape((nphi, nz, nr))\n        bz_3 = bz.reshape((nphi, nz, nr))\n\n        mgrid = MGrid(nfp=nfp,\n                      nr=nr, nz=nz, nphi=nphi,\n                      rmin=rmin, rmax=rmax, zmin=zmin, zmax=zmax)\n        mgrid.add_field_cylindrical(br_3, bp_3, bz_3, name='simsopt_coils')  \n\n        mgrid.write(filename)",
  "class MagneticFieldMultiply(MagneticField):\n    \"\"\"\n    Class used to multiply a magnetic field by a scalar.  It takes as input a\n    MagneticField class and a scalar and multiplies B, A and their derivatives\n    by that value.\n    \"\"\"\n\n    def __init__(self, scalar, Bfield):\n        MagneticField.__init__(self, depends_on=[Bfield])\n        self.scalar = scalar\n        self.Bfield = Bfield\n\n    def _set_points_cb(self):\n        self.Bfield.set_points_cart(self.get_points_cart_ref())\n\n    def _B_impl(self, B):\n        B[:] = self.scalar*self.Bfield.B()\n\n    def _dB_by_dX_impl(self, dB):\n        dB[:] = self.scalar*self.Bfield.dB_by_dX()\n\n    def _d2B_by_dXdX_impl(self, ddB):\n        ddB[:] = self.scalar*self.Bfield.d2B_by_dXdX()\n\n    def _A_impl(self, A):\n        A[:] = self.scalar*self.Bfield.A()\n\n    def _dA_by_dX_impl(self, dA):\n        dA[:] = self.scalar*self.Bfield.dA_by_dX()\n\n    def _d2A_by_dXdX_impl(self, ddA):\n        ddA[:] = self.scalar*self.Bfield.d2A_by_dXdX()\n\n    def as_dict(self, serial_objs_dict) -> dict:\n        d = super().as_dict(serial_objs_dict=serial_objs_dict)\n        d[\"points\"] = self.get_points_cart()\n        return d\n\n    @classmethod\n    def from_dict(cls, d, serial_objs_dict, recon_objs):\n        decoder = GSONDecoder()\n        Bfield = decoder.process_decoded(d[\"Bfield\"], serial_objs_dict, recon_objs)\n        field = cls(d[\"scalar\"], Bfield)\n        xyz = decoder.process_decoded(d[\"points\"], serial_objs_dict, recon_objs)\n        field.set_points_cart(xyz)\n        return field",
  "class MagneticFieldSum(MagneticField):\n    \"\"\"\n    Class used to sum two or more magnetic field together.  It can either be\n    called directly with a list of magnetic fields given as input and outputing\n    another magnetic field with B, A and its derivatives added together or it\n    can be called by summing magnetic fields classes as Bfield1 + Bfield1\n    \"\"\"\n\n    def __init__(self, Bfields):\n        MagneticField.__init__(self, depends_on=Bfields)\n        self.Bfields = Bfields\n\n    def _set_points_cb(self):\n        for bf in self.Bfields:\n            bf.set_points_cart(self.get_points_cart_ref())\n\n    def _B_impl(self, B):\n        B[:] = np.sum([bf.B() for bf in self.Bfields], axis=0)\n\n    def _dB_by_dX_impl(self, dB):\n        dB[:] = np.sum([bf.dB_by_dX() for bf in self.Bfields], axis=0)\n\n    def _d2B_by_dXdX_impl(self, ddB):\n        ddB[:] = np.sum([bf.d2B_by_dXdX() for bf in self.Bfields], axis=0)\n\n    def _A_impl(self, A):\n        A[:] = np.sum([bf.A() for bf in self.Bfields], axis=0)\n\n    def _dA_by_dX_impl(self, dA):\n        dA[:] = np.sum([bf.dA_by_dX() for bf in self.Bfields], axis=0)\n\n    def _d2A_by_dXdX_impl(self, ddA):\n        ddA[:] = np.sum([bf.d2A_by_dXdX() for bf in self.Bfields], axis=0)\n\n    def B_vjp(self, v):\n        return sum([bf.B_vjp(v) for bf in self.Bfields if np.any(bf.dofs_free_status)])\n\n    def as_dict(self, serial_objs_dict) -> dict:\n        d = super().as_dict(serial_objs_dict=serial_objs_dict)\n        d[\"points\"] = self.get_points_cart()\n        return d\n\n    @classmethod\n    def from_dict(cls, d, serial_objs_dict, recon_objs):\n        decoder = GSONDecoder()\n        Bfields = decoder.process_decoded(d[\"Bfields\"], serial_objs_dict, recon_objs)\n        field_sum = cls(Bfields)\n        xyz = decoder.process_decoded(d[\"points\"], serial_objs_dict, recon_objs)\n        field_sum.set_points_cart(xyz)\n        return field_sum",
  "def set_points(self, xyz):\n        return self.set_points_cart(xyz)",
  "def set_points_cart(self, xyz):\n        if len(xyz.shape) != 2 or xyz.shape[1] != 3:\n            raise ValueError(f\"xyz array should have shape (n, 3), but has shape {xyz.shape}\")\n        if not xyz.flags['C_CONTIGUOUS']:\n            raise ValueError(\"xyz array should be C contiguous. Consider using `numpy.ascontiguousarray`.\")\n        return sopp.MagneticField.set_points_cart(self, xyz)",
  "def set_points_cyl(self, rphiz):\n        if len(rphiz.shape) != 2 or rphiz.shape[1] != 3:\n            raise ValueError(f\"rphiz array should have shape (n, 3), but has shape {rphiz.shape}\")\n        if not rphiz.flags['C_CONTIGUOUS']:\n            raise ValueError(\"rphiz array should be C contiguous. Consider using `numpy.ascontiguousarray`.\")\n        return sopp.MagneticField.set_points_cyl(self, rphiz)",
  "def __init__(self, **kwargs):\n        sopp.MagneticField.__init__(self)\n        Optimizable.__init__(self, **kwargs)",
  "def clear_cached_properties(self):\n        \"\"\"Clear the cache.\"\"\"\n        sopp.MagneticField.invalidate_cache(self)",
  "def recompute_bell(self, parent=None):\n        if np.any(self.dofs_free_status):\n            self.clear_cached_properties()",
  "def __add__(self, other):\n        \"\"\"Add two magnetic fields.\"\"\"\n        return MagneticFieldSum([self, other])",
  "def __mul__(self, other):\n        \"\"\"Multiply a field with a scalar.\"\"\"\n        return MagneticFieldMultiply(other, self)",
  "def __rmul__(self, other):\n        \"\"\"Multiply a field with a scalar.\"\"\"\n        return MagneticFieldMultiply(other, self)",
  "def to_vtk(self, filename, nr=10, nphi=10, nz=10, rmin=1.0, rmax=2.0, zmin=-0.5, zmax=0.5):\n        \"\"\"Export the field evaluated on a regular grid for visualisation with e.g. Paraview.\"\"\"\n        from pyevtk.hl import gridToVTK\n        rs = np.linspace(rmin, rmax, nr, endpoint=True)\n        phis = np.linspace(0, 2*np.pi, nphi, endpoint=True)\n        zs = np.linspace(zmin, zmax, nz, endpoint=True)\n\n        R, Phi, Z = np.meshgrid(rs, phis, zs)\n        X = R * np.cos(Phi)\n        Y = R * np.sin(Phi)\n        Z = Z\n\n        RPhiZ = np.zeros((R.size, 3))\n        RPhiZ[:, 0] = R.flatten()\n        RPhiZ[:, 1] = Phi.flatten()\n        RPhiZ[:, 2] = Z.flatten()\n\n        self.set_points_cyl(RPhiZ)\n        vals = self.B().reshape((R.shape[0], R.shape[1], R.shape[2], 3))\n        contig = np.ascontiguousarray\n        gridToVTK(filename, X, Y, Z, pointData={\"B\": (contig(vals[..., 0]), contig(vals[..., 1]), contig(vals[..., 2]))})",
  "def to_mgrid(self, filename, nr=10, nphi=4, nz=12, rmin=1.0, rmax=2.0, zmin=-0.5, zmax=0.5, nfp=1):\n        \"\"\"Export the field to the mgrid format for free boundary calculations.\n\n        The field data is represented as a single \"current group\". For\n        free-boundary vmec, the \"extcur\" array should have a single nonzero\n        element, set to 1.0.\n\n        In the future, we may want to implement multiple current groups.\n\n        Args:\n            filename: Name of the NetCDF file to save.\n            nr: Number of grid points in the major radius dimension.\n            nphi: Number of planes in the toroidal angle.\n            nz: Number of grid points in the z coordinate.\n            rmin: Minimum value of major radius for the grid.\n            rmax: Maximum value of major radius for the grid.\n            zmin: Minimum value of z for the grid.\n            zmax: Maximum value of z for the grid.\n            nfp: Number of field periods.\n        \"\"\"\n\n        rs = np.linspace(rmin, rmax, nr, endpoint=True)\n        phis = np.linspace(0, 2 * np.pi / nfp, nphi, endpoint=False)\n        zs = np.linspace(zmin, zmax, nz, endpoint=True)\n\n        Phi, Z, R = np.meshgrid(phis, zs, rs, indexing='ij')\n        X = R * np.cos(Phi)\n        Y = R * np.sin(Phi)\n        Z = Z\n\n        RPhiZ = np.zeros((R.size, 3))\n        RPhiZ[:, 0] = R.flatten()\n        RPhiZ[:, 1] = Phi.flatten()  \n        RPhiZ[:, 2] = Z.flatten()\n\n        # get field on the grid\n        self.set_points_cyl(RPhiZ)\n        B = self.B_cyl()\n\n        # shape the components\n        br, bp, bz = B.T\n        br_3 = br.reshape((nphi, nz, nr))\n        bp_3 = bp.reshape((nphi, nz, nr))\n        bz_3 = bz.reshape((nphi, nz, nr))\n\n        mgrid = MGrid(nfp=nfp,\n                      nr=nr, nz=nz, nphi=nphi,\n                      rmin=rmin, rmax=rmax, zmin=zmin, zmax=zmax)\n        mgrid.add_field_cylindrical(br_3, bp_3, bz_3, name='simsopt_coils')  \n\n        mgrid.write(filename)",
  "def __init__(self, scalar, Bfield):\n        MagneticField.__init__(self, depends_on=[Bfield])\n        self.scalar = scalar\n        self.Bfield = Bfield",
  "def _set_points_cb(self):\n        self.Bfield.set_points_cart(self.get_points_cart_ref())",
  "def _B_impl(self, B):\n        B[:] = self.scalar*self.Bfield.B()",
  "def _dB_by_dX_impl(self, dB):\n        dB[:] = self.scalar*self.Bfield.dB_by_dX()",
  "def _d2B_by_dXdX_impl(self, ddB):\n        ddB[:] = self.scalar*self.Bfield.d2B_by_dXdX()",
  "def _A_impl(self, A):\n        A[:] = self.scalar*self.Bfield.A()",
  "def _dA_by_dX_impl(self, dA):\n        dA[:] = self.scalar*self.Bfield.dA_by_dX()",
  "def _d2A_by_dXdX_impl(self, ddA):\n        ddA[:] = self.scalar*self.Bfield.d2A_by_dXdX()",
  "def as_dict(self, serial_objs_dict) -> dict:\n        d = super().as_dict(serial_objs_dict=serial_objs_dict)\n        d[\"points\"] = self.get_points_cart()\n        return d",
  "def from_dict(cls, d, serial_objs_dict, recon_objs):\n        decoder = GSONDecoder()\n        Bfield = decoder.process_decoded(d[\"Bfield\"], serial_objs_dict, recon_objs)\n        field = cls(d[\"scalar\"], Bfield)\n        xyz = decoder.process_decoded(d[\"points\"], serial_objs_dict, recon_objs)\n        field.set_points_cart(xyz)\n        return field",
  "def __init__(self, Bfields):\n        MagneticField.__init__(self, depends_on=Bfields)\n        self.Bfields = Bfields",
  "def _set_points_cb(self):\n        for bf in self.Bfields:\n            bf.set_points_cart(self.get_points_cart_ref())",
  "def _B_impl(self, B):\n        B[:] = np.sum([bf.B() for bf in self.Bfields], axis=0)",
  "def _dB_by_dX_impl(self, dB):\n        dB[:] = np.sum([bf.dB_by_dX() for bf in self.Bfields], axis=0)",
  "def _d2B_by_dXdX_impl(self, ddB):\n        ddB[:] = np.sum([bf.d2B_by_dXdX() for bf in self.Bfields], axis=0)",
  "def _A_impl(self, A):\n        A[:] = np.sum([bf.A() for bf in self.Bfields], axis=0)",
  "def _dA_by_dX_impl(self, dA):\n        dA[:] = np.sum([bf.dA_by_dX() for bf in self.Bfields], axis=0)",
  "def _d2A_by_dXdX_impl(self, ddA):\n        ddA[:] = np.sum([bf.d2A_by_dXdX() for bf in self.Bfields], axis=0)",
  "def B_vjp(self, v):\n        return sum([bf.B_vjp(v) for bf in self.Bfields if np.any(bf.dofs_free_status)])",
  "def as_dict(self, serial_objs_dict) -> dict:\n        d = super().as_dict(serial_objs_dict=serial_objs_dict)\n        d[\"points\"] = self.get_points_cart()\n        return d",
  "def from_dict(cls, d, serial_objs_dict, recon_objs):\n        decoder = GSONDecoder()\n        Bfields = decoder.process_decoded(d[\"Bfields\"], serial_objs_dict, recon_objs)\n        field_sum = cls(Bfields)\n        xyz = decoder.process_decoded(d[\"points\"], serial_objs_dict, recon_objs)\n        field_sum.set_points_cart(xyz)\n        return field_sum",
  "class Coil(sopp.Coil, Optimizable):\n    \"\"\"\n    A :obj:`Coil` combines a :obj:`~simsopt.geo.curve.Curve` and a\n    :obj:`Current` and is used as input for a\n    :obj:`~simsopt.field.biotsavart.BiotSavart` field.\n    \"\"\"\n\n    def __init__(self, curve, current):\n        self._curve = curve\n        self._current = current\n        sopp.Coil.__init__(self, curve, current)\n        Optimizable.__init__(self, depends_on=[curve, current])\n\n    def vjp(self, v_gamma, v_gammadash, v_current):\n        return self.curve.dgamma_by_dcoeff_vjp(v_gamma) \\\n            + self.curve.dgammadash_by_dcoeff_vjp(v_gammadash) \\\n            + self.current.vjp(v_current)\n\n    def plot(self, **kwargs):\n        \"\"\"\n        Plot the coil's curve. This method is just shorthand for calling\n        the :obj:`~simsopt.geo.curve.Curve.plot()` function on the\n        underlying Curve. All arguments are passed to\n        :obj:`simsopt.geo.curve.Curve.plot()`\n        \"\"\"\n        return self.curve.plot(**kwargs)",
  "class CurrentBase(Optimizable):\n\n    def __init__(self, **kwargs):\n        Optimizable.__init__(self, **kwargs)\n\n    def __mul__(self, other):\n        assert isinstance(other, float) or isinstance(other, int)\n        return ScaledCurrent(self, other)\n\n    def __rmul__(self, other):\n        assert isinstance(other, float) or isinstance(other, int)\n        return ScaledCurrent(self, other)\n\n    def __truediv__(self, other):\n        assert isinstance(other, float) or isinstance(other, int)\n        return ScaledCurrent(self, 1.0/other)\n\n    def __neg__(self):\n        return ScaledCurrent(self, -1.)\n\n    def __add__(self, other):\n        return CurrentSum(self, other)\n\n    def __sub__(self, other):\n        return CurrentSum(self, -other)\n\n    # https://stackoverflow.com/questions/11624955/avoiding-python-sum-default-start-arg-behavior\n    def __radd__(self, other):\n        # This allows sum() to work (the default start value is zero)\n        if other == 0:\n            return self\n        return self.__add__(other)",
  "class Current(sopp.Current, CurrentBase):\n    \"\"\"\n    An optimizable object that wraps around a single scalar degree of\n    freedom. It represents the electric current in a coil, or in a set\n    of coils that are constrained to use the same current.\n    \"\"\"\n\n    def __init__(self, current, dofs=None, **kwargs):\n        sopp.Current.__init__(self, current)\n        if dofs is None:\n            CurrentBase.__init__(self, external_dof_setter=sopp.Current.set_dofs,\n                                 x0=self.get_dofs(), **kwargs)\n        else:\n            CurrentBase.__init__(self, external_dof_setter=sopp.Current.set_dofs,\n                                 dofs=dofs, **kwargs)\n\n    def vjp(self, v_current):\n        return Derivative({self: v_current})\n\n    @property\n    def current(self):\n        return self.get_value()",
  "class ScaledCurrent(sopp.CurrentBase, CurrentBase):\n    \"\"\"\n    Scales :mod:`Current` by a factor. To be used for example to flip currents\n    for stellarator symmetric coils.\n    \"\"\"\n\n    def __init__(self, current_to_scale, scale, **kwargs):\n        self.current_to_scale = current_to_scale\n        self.scale = scale\n        sopp.CurrentBase.__init__(self)\n        CurrentBase.__init__(self, depends_on=[current_to_scale], **kwargs)\n\n    def vjp(self, v_current):\n        return self.scale * self.current_to_scale.vjp(v_current)\n\n    def get_value(self):\n        return self.scale * self.current_to_scale.get_value()",
  "class CurrentSum(sopp.CurrentBase, CurrentBase):\n    \"\"\"\n    Take the sum of two :mod:`Current` objects.\n    \"\"\"\n\n    def __init__(self, current_a, current_b):\n        self.current_a = current_a\n        self.current_b = current_b\n        sopp.CurrentBase.__init__(self)\n        CurrentBase.__init__(self, depends_on=[current_a, current_b])\n\n    def vjp(self, v_current):\n        return self.current_a.vjp(v_current) + self.current_b.vjp(v_current)\n\n    def get_value(self):\n        return self.current_a.get_value() + self.current_b.get_value()",
  "def apply_symmetries_to_curves(base_curves, nfp, stellsym):\n    \"\"\"\n    Take a list of ``n`` :mod:`simsopt.geo.curve.Curve`s and return ``n * nfp *\n    (1+int(stellsym))`` :mod:`simsopt.geo.curve.Curve` objects obtained by\n    applying rotations and flipping corresponding to ``nfp`` fold rotational\n    symmetry and optionally stellarator symmetry.\n    \"\"\"\n    flip_list = [False, True] if stellsym else [False]\n    curves = []\n    for k in range(0, nfp):\n        for flip in flip_list:\n            for i in range(len(base_curves)):\n                if k == 0 and not flip:\n                    curves.append(base_curves[i])\n                else:\n                    rotcurve = RotatedCurve(base_curves[i], 2*pi*k/nfp, flip)\n                    curves.append(rotcurve)\n    return curves",
  "def apply_symmetries_to_currents(base_currents, nfp, stellsym):\n    \"\"\"\n    Take a list of ``n`` :mod:`Current`s and return ``n * nfp * (1+int(stellsym))``\n    :mod:`Current` objects obtained by copying (for ``nfp`` rotations) and\n    sign-flipping (optionally for stellarator symmetry).\n    \"\"\"\n    flip_list = [False, True] if stellsym else [False]\n    currents = []\n    for k in range(0, nfp):\n        for flip in flip_list:\n            for i in range(len(base_currents)):\n                current = ScaledCurrent(base_currents[i], -1.) if flip else base_currents[i]\n                currents.append(current)\n    return currents",
  "def coils_via_symmetries(curves, currents, nfp, stellsym):\n    \"\"\"\n    Take a list of ``n`` curves and return ``n * nfp * (1+int(stellsym))``\n    ``Coil`` objects obtained by applying rotations and flipping corresponding\n    to ``nfp`` fold rotational symmetry and optionally stellarator symmetry.\n    \"\"\"\n\n    assert len(curves) == len(currents)\n    curves = apply_symmetries_to_curves(curves, nfp, stellsym)\n    currents = apply_symmetries_to_currents(currents, nfp, stellsym)\n    coils = [Coil(curv, curr) for (curv, curr) in zip(curves, currents)]\n    return coils",
  "def load_coils_from_makegrid_file(filename, order, ppp=20):\n    \"\"\"\n    This function loads a file in MAKEGRID input format containing the Cartesian coordinates \n    and the currents for several coils and returns an array with the corresponding coils. \n    The format is described at\n    https://princetonuniversity.github.io/STELLOPT/MAKEGRID\n\n    Args:\n        filename: file to load.\n        order: maximum mode number in the Fourier expansion.\n        ppp: points-per-period: number of quadrature points per period.\n\n    Returns:\n        A list of ``Coil`` objects with the Fourier coefficients and currents given by the file.\n    \"\"\"\n    with open(filename, 'r') as f:\n        all_coils_values = f.read().splitlines()[3:] \n\n    currents = []\n    flag = True\n    for j in range(len(all_coils_values)-1):\n        vals = all_coils_values[j].split()\n        if flag:\n            currents.append(float(vals[3]))\n            flag = False\n        if len(vals) > 4:\n            flag = True\n\n    curves = CurveXYZFourier.load_curves_from_makegrid_file(filename, order=order, ppp=ppp)\n    coils = [Coil(curves[i], Current(currents[i])) for i in range(len(curves))]\n\n    return coils",
  "def coils_to_makegrid(filename, curves, currents, groups=None, nfp=1, stellsym=False):\n    \"\"\"\n    Export a list of Curve objects together with currents in MAKEGRID input format, so they can \n    be used by MAKEGRID and FOCUS. The format is introduced at\n    https://princetonuniversity.github.io/STELLOPT/MAKEGRID\n    Note that this function does not generate files with MAKEGRID's *output* format.\n\n    Args:\n        filename: Name of the file to write.\n        curves: A python list of Curve objects.\n        currents: Coil current of each curve.\n        groups: Coil current group. Coils in the same group will be assembled together. Defaults to None.\n        nfp: The number of field periodicity. Defaults to 1.\n        stellsym: Whether or not following stellarator symmetry. Defaults to False.\n    \"\"\"\n\n    assert len(curves) == len(currents)\n    coils = coils_via_symmetries(curves, currents, nfp, stellsym)\n    ncoils = len(coils)\n    if groups is None:\n        groups = np.arange(ncoils) + 1\n    else:\n        assert len(groups) == ncoils\n        # should be careful. SIMSOPT flips the current, but actually should change coil order\n    with open(filename, \"w\") as wfile:\n        wfile.write(\"periods {:3d} \\n\".format(nfp)) \n        wfile.write(\"begin filament \\n\")\n        wfile.write(\"mirror NIL \\n\")\n        for icoil in range(ncoils):\n            x = coils[icoil].curve.gamma()[:, 0]\n            y = coils[icoil].curve.gamma()[:, 1]\n            z = coils[icoil].curve.gamma()[:, 2]\n            for iseg in range(len(x)):  # the last point matches the first one;\n                wfile.write(\n                    \"{:23.15E} {:23.15E} {:23.15E} {:23.15E}\\n\".format(\n                        x[iseg], y[iseg], z[iseg], coils[icoil].current.get_value()\n                    )\n                )\n            wfile.write(\n                \"{:23.15E} {:23.15E} {:23.15E} {:23.15E} {:} {:10} \\n\".format(\n                    x[0], y[0], z[0], 0.0, groups[icoil], coils[icoil].curve.name\n                )\n            )\n        wfile.write(\"end \\n\")\n    return",
  "def coils_to_focus(filename, curves, currents, nfp=1, stellsym=False, Ifree=False, Lfree=False):\n    \"\"\"\n    Export a list of Curve objects together with currents in FOCUS format, so they can \n    be used by FOCUS. The format is introduced at\n    https://princetonuniversity.github.io/FOCUS/rdcoils.pdf\n    This routine only works with curves of type CurveXYZFourier,\n    not other curve types.\n\n    Args:\n        filename: Name of the file to write.\n        curves: A python list of CurveXYZFourier objects.\n        currents: Coil current of each curve.\n        nfp: The number of field periodicity. Defaults to 1.      \n        stellsym: Whether or not following stellarator symmetry. Defaults to False.\n        Ifree: Flag specifying whether the coil current is free. Defaults to False.\n        Lfree: Flag specifying whether the coil geometry is free. Defaults to False.\n    \"\"\"\n    from simsopt.geo import CurveLength\n\n    assert len(curves) == len(currents)\n    ncoils = len(curves)\n    if stellsym:\n        symm = 2  # both periodic and symmetric\n    elif nfp > 1 and not stellsym:\n        symm = 1  # only periodicity\n    else:\n        symm = 0  # no periodicity or symmetry\n    if nfp > 1:\n        print('Please note: FOCUS sets Nfp in the plasma file.')\n    with open(filename, 'w') as f:\n        f.write('# Total number of coils \\n')\n        f.write('  {:d} \\n'.format(ncoils))\n        for i in range(ncoils):\n            assert isinstance(curves[i], CurveXYZFourier)\n            nf = curves[i].order\n            xyz = curves[i].full_x.reshape((3, -1))\n            xc = xyz[0, ::2]\n            xs = np.concatenate(([0.], xyz[0, 1::2]))\n            yc = xyz[1, ::2]\n            ys = np.concatenate(([0.], xyz[1, 1::2]))\n            zc = xyz[2, ::2]\n            zs = np.concatenate(([0.], xyz[2, 1::2]))\n            length = CurveLength(curves[i]).J()\n            nseg = len(curves[i].quadpoints)\n            f.write('#------------{:d}----------- \\n'.format(i+1))\n            f.write('# coil_type  symm  coil_name \\n')\n            f.write('  {:d}   {:d}  {:} \\n'.format(1, symm, curves[i].name))\n            f.write('# Nseg current Ifree Length Lfree target_length \\n')\n            f.write('  {:d} {:23.15E} {:d} {:23.15E} {:d} {:23.15E} \\n'.format(nseg, currents[i].get_value(), Ifree, length, Lfree, length))\n            f.write('# NFcoil \\n')\n            f.write('  {:d} \\n'.format(nf))\n            f.write('# Fourier harmonics for coils ( xc; xs; yc; ys; zc; zs) \\n')\n            for r in [xc, xs, yc, ys, zc, zs]:  # 6 lines\n                for k in range(nf+1):\n                    f.write('{:23.15E} '.format(r[k]))\n                f.write('\\n')\n        f.write('\\n')\n    return",
  "def __init__(self, curve, current):\n        self._curve = curve\n        self._current = current\n        sopp.Coil.__init__(self, curve, current)\n        Optimizable.__init__(self, depends_on=[curve, current])",
  "def vjp(self, v_gamma, v_gammadash, v_current):\n        return self.curve.dgamma_by_dcoeff_vjp(v_gamma) \\\n            + self.curve.dgammadash_by_dcoeff_vjp(v_gammadash) \\\n            + self.current.vjp(v_current)",
  "def plot(self, **kwargs):\n        \"\"\"\n        Plot the coil's curve. This method is just shorthand for calling\n        the :obj:`~simsopt.geo.curve.Curve.plot()` function on the\n        underlying Curve. All arguments are passed to\n        :obj:`simsopt.geo.curve.Curve.plot()`\n        \"\"\"\n        return self.curve.plot(**kwargs)",
  "def __init__(self, **kwargs):\n        Optimizable.__init__(self, **kwargs)",
  "def __mul__(self, other):\n        assert isinstance(other, float) or isinstance(other, int)\n        return ScaledCurrent(self, other)",
  "def __rmul__(self, other):\n        assert isinstance(other, float) or isinstance(other, int)\n        return ScaledCurrent(self, other)",
  "def __truediv__(self, other):\n        assert isinstance(other, float) or isinstance(other, int)\n        return ScaledCurrent(self, 1.0/other)",
  "def __neg__(self):\n        return ScaledCurrent(self, -1.)",
  "def __add__(self, other):\n        return CurrentSum(self, other)",
  "def __sub__(self, other):\n        return CurrentSum(self, -other)",
  "def __radd__(self, other):\n        # This allows sum() to work (the default start value is zero)\n        if other == 0:\n            return self\n        return self.__add__(other)",
  "def __init__(self, current, dofs=None, **kwargs):\n        sopp.Current.__init__(self, current)\n        if dofs is None:\n            CurrentBase.__init__(self, external_dof_setter=sopp.Current.set_dofs,\n                                 x0=self.get_dofs(), **kwargs)\n        else:\n            CurrentBase.__init__(self, external_dof_setter=sopp.Current.set_dofs,\n                                 dofs=dofs, **kwargs)",
  "def vjp(self, v_current):\n        return Derivative({self: v_current})",
  "def current(self):\n        return self.get_value()",
  "def __init__(self, current_to_scale, scale, **kwargs):\n        self.current_to_scale = current_to_scale\n        self.scale = scale\n        sopp.CurrentBase.__init__(self)\n        CurrentBase.__init__(self, depends_on=[current_to_scale], **kwargs)",
  "def vjp(self, v_current):\n        return self.scale * self.current_to_scale.vjp(v_current)",
  "def get_value(self):\n        return self.scale * self.current_to_scale.get_value()",
  "def __init__(self, current_a, current_b):\n        self.current_a = current_a\n        self.current_b = current_b\n        sopp.CurrentBase.__init__(self)\n        CurrentBase.__init__(self, depends_on=[current_a, current_b])",
  "def vjp(self, v_current):\n        return self.current_a.vjp(v_current) + self.current_b.vjp(v_current)",
  "def get_value(self):\n        return self.current_a.get_value() + self.current_b.get_value()",
  "class NormalField(Optimizable):\n    r\"\"\"\n    ``NormalField`` represents the magnetic field normal to a toroidal surface, for example the\n    computational boundary of SPEC free-boundary.\n\n    Args:\n        nfp: The number of field period\n        stellsym: Whether (=True) or not (=False) stellarator symmetry is enforced.\n        mpol: Poloidal Fourier resolution\n        ntor: Toroidal Fourier resolution\n        vns: Odd fourier modes of :math:`\\mathbf{B}\\cdot\\mathbf{\\hat{n}}`. 2D array of size\n          (mpol+1)x(2ntor+1). Set to None to fill with zeros\n\n            vns( mm, self.ntor+nn ) is the mode (mm,nn)\n\n        vnc: Even fourier modes of :math:`\\mathbf{B}\\cdot\\mathbf{\\hat{n}}`. 2D array of size\n          (mpol+1)x(2ntor+1). Ignored if stellsym if True. Set to None to fill with zeros\n\n            vnc( mm, self.ntor+nn ) is the mode (mm,nn)\n    \"\"\"\n\n    def __init__(self, nfp=1, stellsym=True, mpol=1, ntor=0,\n                 vns=None, vnc=None):\n\n        self.nfp = nfp\n        self.stellsym = stellsym\n        self.mpol = mpol\n        self.ntor = ntor\n\n        if vns is None:\n            vns = np.zeros((self.mpol + 1, 2 * self.ntor + 1))\n\n        if vnc is None and not stellsym:\n            vnc = np.zeros((self.mpol + 1, 2 * self.ntor + 1))\n\n        if self.stellsym:\n            self.ndof = self.ntor + self.mpol * (2 * self.ntor + 1)\n        else:\n            self.ndof = 2 * (self.ntor + self.mpol * (2 * self.ntor + 1)) + 1\n\n        # Pack in a single array\n        dofs = np.zeros((self.ndof,))\n\n        # Populate dofs array\n        vns_shape = vns.shape\n        input_mpol = int(vns_shape[0]-1)\n        input_ntor = int((vns_shape[1]-1)/2)\n        for mm in range(0, self.mpol+1):\n            for nn in range(-self.ntor, self.ntor+1):\n                if mm == 0 and nn < 0: continue\n                if mm > input_mpol: continue\n                if nn > input_ntor: continue\n\n                if not (mm == 0 and nn == 0):\n                    ii = self.get_index_in_dofs(mm, nn, even=False)\n                    dofs[ii] = vns[mm, input_ntor+nn]\n\n                if not self.stellsym:\n                    ii = self.get_index_in_dofs(mm, nn, even=True)\n                    dofs[ii] = vnc[mm, input_ntor+nn]\n\n        Optimizable.__init__(\n            self,\n            x0=dofs,\n            names=self._make_names())\n\n    @classmethod\n    def from_spec(cls, filename):\n        \"\"\"\n        Initialize using the harmonics in SPEC input file\n        \"\"\"\n\n        # Test if py_spec is available\n        if py_spec is None:\n            raise RuntimeError(\n                \"Initialization from Spec requires py_spec to be installed.\")\n\n        # Read Namelist\n        nm = py_spec.SPECNamelist(filename)\n        ph = nm['physicslist']\n\n        # Read modes from SPEC input file\n        vns = np.asarray(ph['vns'])\n        if ph['istellsym']:\n            vnc = None\n        else:\n            vnc = np.asarray(ph['vnc'][1:])\n\n        nf = cls(\n            nfp=ph['nfp'], \n            stellsym=ph['istellsym'], \n            mpol=ph['Mpol'], \n            ntor=ph['Ntor'],\n            vns=vns,\n            vnc=vnc\n        )\n\n        return nf\n\n    def get_index_in_dofs(self, m, n, mpol=None, ntor=None, even=False):\n        \"\"\"\n        Returns position of mode (m,n) in dofs array\n\n        Args:\n        - m: poloidal mode number\n        - n: toroidal mode number (normalized by Nfp)\n        - mpol: resolution of dofs array. If None (by default), use self.mpol\n        - ntor: resolution of dofs array. If None (by default), use self.ntor\n        - even: set to True to get vnc. Default is False\n        \"\"\"\n\n        if mpol is None:\n            mpol = self.mpol\n        if ntor is None:\n            ntor = self.ntor\n\n        if m < 0 or m > mpol:\n            raise ValueError('m out of bound')\n        if abs(n) > ntor:\n            raise ValueError('n out of bound')\n        if m == 0 and n < 0:\n            raise ValueError('n has to be positive if m==0')\n        if not even and m == 0 and n == 0:\n            raise ValueError('m=n=0 not supported for odd series')\n\n        ii = -1\n        if m == 0:\n            ii = n\n        else:\n            ii = m * (2*ntor+1) + n\n\n        nvns = ntor + mpol * (ntor * 2 + 1)\n        if not even:  # Vns\n            ii = ii - 1  # remove (0,0) element\n        else:  # Vnc\n            ii = ii + nvns\n\n        return ii\n\n    def get_vns(self, m, n):\n        self.check_mn(m, n)\n        ii = self.get_index_in_dofs(m, n)\n        return self.local_full_x[ii]\n\n    def set_vns(self, m, n, value):\n        self.check_mn(m, n)\n        ii = self.get_index_in_dofs(m, n)\n        self.local_full_x[ii] = value\n\n    def get_vnc(self, m, n):\n        self.check_mn(m, n)\n        ii = self.get_index_in_dofs(m, n, even=True)\n        if self.stellsym:\n            return 0.0\n        else:\n            return self.local_full_x[ii]\n\n    def set_vnc(self, m, n, value):\n        self.check_mn(m, n)\n        ii = self.get_index_in_dofs(m, n, even=True)\n        if self.stellsym:\n            raise ValueError('Stellarator symmetric has no vnc')\n        else:\n            self.local_full_x[ii] = value\n\n    def check_mn(self, m, n):\n        if m < 0 or m > self.mpol:\n            raise ValueError('m out of bound')\n        if n < -self.ntor or n > self.ntor:\n            raise ValueError('n out of bound')\n        if m == 0 and n < 0:\n            raise ValueError('n has to be positive if m==0')\n\n    def _make_names(self):\n        \"\"\"\n        Form a list of names of the ``vns``, ``vnc``\n        \"\"\"\n        if self.stellsym:\n            names = self._make_names_helper(False)\n        else:\n            names = np.append(self._make_names_helper(False),\n                              self._make_names_helper(True))\n\n        return names\n\n    def _make_names_helper(self, even=False):\n        names = []\n        indices = []\n\n        if even:\n            prefix = 'vnc'\n        else:\n            prefix = 'vns'\n\n        for mm in range(0, self.mpol+1):\n            for nn in range(-self.ntor, self.ntor+1):\n                if mm == 0 and nn < 0:\n                    continue\n                if not even and mm == 0 and nn == 0:\n                    continue\n\n                ind = self.get_index_in_dofs(mm, nn, even=even)\n                names.append(prefix + '({m},{n})'.format(m=mm, n=nn))\n                indices.append(ind)\n\n        # Sort names\n        ind = np.argsort(np.asarray(indices))\n        sorted_names = [names[ii] for ii in ind]\n\n        return sorted_names\n\n    def change_resolution(self, mpol, ntor):\n        \"\"\"\n        Change the values of `mpol` and `ntor`. Any new Fourier amplitudes\n        will have a magnitude of zero.  Any previous nonzero Fourier\n        amplitudes that are not within the new range will be\n        discarded.\n        \"\"\"\n\n        # Set new number of dofs\n        if self.stellsym:\n            ndof = ntor + mpol * (2 * ntor + 1)  # Only Vns - odd series\n        else:\n            ndof = 2 * (ntor + mpol * (2 * ntor + 1)) + 1  # Vns and Vns\n\n        # Fill relevant modes\n        min_mpol = np.min((mpol, self.mpol))\n        min_ntor = np.min((ntor, self.ntor))\n\n        dofs = np.zeros((ndof,))\n        for m in range(min_mpol + 1):\n            for n in range(-min_ntor, min_ntor + 1):\n                if m == 0 and n < 0: continue\n\n                if m > 0 or n > 0:\n                    ind = self.get_index_in_dofs(m, n, mpol=mpol, ntor=ntor, even=False)\n                    dofs[ind] = self.get_vns(m, n)\n\n                if not self.stellsym:\n                    ind = self.get_index_in_dofs(m, n, mpol=mpol, ntor=ntor, even=True)\n                    dofs[ind] = self.get_vnc(m, n)\n\n        # Update attributes\n        self.mpol = mpol\n        self.ntor = ntor\n        self.ndof = ndof\n        self._dofs = DOFs(dofs, self._make_names())\n\n    def fixed_range(self, mmin, mmax, nmin, nmax, fixed=True):\n        \"\"\"\n        Set the 'fixed' property for a range of `m` and `n` values.\n\n        All modes with `m` in the interval [`mmin`, `mmax`] and `n` in the\n        interval [`nmin`, `nmax`] will have their fixed property set to\n        the value of the `fixed` parameter. Note that `mmax` and `nmax`\n        are included (unlike the upper bound in python's range(min,\n        max).)\n\n        In case of non stellarator symmetric field, both vns and vnc will be\n        fixed (or unfixed)\n        \"\"\"\n\n        fn = self.fix if fixed else self.unfix\n        for m in range(mmin, mmax + 1):\n            this_nmin = nmin\n            if m == 0 and nmin < 0:\n                this_nmin = 0\n            for n in range(this_nmin, nmax + 1):\n                if m > 0 or n != 0:\n                    fn(f'vns({m},{n})')\n                if not self.stellsym:\n                    fn(f'vnc({m},{n})')",
  "def __init__(self, nfp=1, stellsym=True, mpol=1, ntor=0,\n                 vns=None, vnc=None):\n\n        self.nfp = nfp\n        self.stellsym = stellsym\n        self.mpol = mpol\n        self.ntor = ntor\n\n        if vns is None:\n            vns = np.zeros((self.mpol + 1, 2 * self.ntor + 1))\n\n        if vnc is None and not stellsym:\n            vnc = np.zeros((self.mpol + 1, 2 * self.ntor + 1))\n\n        if self.stellsym:\n            self.ndof = self.ntor + self.mpol * (2 * self.ntor + 1)\n        else:\n            self.ndof = 2 * (self.ntor + self.mpol * (2 * self.ntor + 1)) + 1\n\n        # Pack in a single array\n        dofs = np.zeros((self.ndof,))\n\n        # Populate dofs array\n        vns_shape = vns.shape\n        input_mpol = int(vns_shape[0]-1)\n        input_ntor = int((vns_shape[1]-1)/2)\n        for mm in range(0, self.mpol+1):\n            for nn in range(-self.ntor, self.ntor+1):\n                if mm == 0 and nn < 0: continue\n                if mm > input_mpol: continue\n                if nn > input_ntor: continue\n\n                if not (mm == 0 and nn == 0):\n                    ii = self.get_index_in_dofs(mm, nn, even=False)\n                    dofs[ii] = vns[mm, input_ntor+nn]\n\n                if not self.stellsym:\n                    ii = self.get_index_in_dofs(mm, nn, even=True)\n                    dofs[ii] = vnc[mm, input_ntor+nn]\n\n        Optimizable.__init__(\n            self,\n            x0=dofs,\n            names=self._make_names())",
  "def from_spec(cls, filename):\n        \"\"\"\n        Initialize using the harmonics in SPEC input file\n        \"\"\"\n\n        # Test if py_spec is available\n        if py_spec is None:\n            raise RuntimeError(\n                \"Initialization from Spec requires py_spec to be installed.\")\n\n        # Read Namelist\n        nm = py_spec.SPECNamelist(filename)\n        ph = nm['physicslist']\n\n        # Read modes from SPEC input file\n        vns = np.asarray(ph['vns'])\n        if ph['istellsym']:\n            vnc = None\n        else:\n            vnc = np.asarray(ph['vnc'][1:])\n\n        nf = cls(\n            nfp=ph['nfp'], \n            stellsym=ph['istellsym'], \n            mpol=ph['Mpol'], \n            ntor=ph['Ntor'],\n            vns=vns,\n            vnc=vnc\n        )\n\n        return nf",
  "def get_index_in_dofs(self, m, n, mpol=None, ntor=None, even=False):\n        \"\"\"\n        Returns position of mode (m,n) in dofs array\n\n        Args:\n        - m: poloidal mode number\n        - n: toroidal mode number (normalized by Nfp)\n        - mpol: resolution of dofs array. If None (by default), use self.mpol\n        - ntor: resolution of dofs array. If None (by default), use self.ntor\n        - even: set to True to get vnc. Default is False\n        \"\"\"\n\n        if mpol is None:\n            mpol = self.mpol\n        if ntor is None:\n            ntor = self.ntor\n\n        if m < 0 or m > mpol:\n            raise ValueError('m out of bound')\n        if abs(n) > ntor:\n            raise ValueError('n out of bound')\n        if m == 0 and n < 0:\n            raise ValueError('n has to be positive if m==0')\n        if not even and m == 0 and n == 0:\n            raise ValueError('m=n=0 not supported for odd series')\n\n        ii = -1\n        if m == 0:\n            ii = n\n        else:\n            ii = m * (2*ntor+1) + n\n\n        nvns = ntor + mpol * (ntor * 2 + 1)\n        if not even:  # Vns\n            ii = ii - 1  # remove (0,0) element\n        else:  # Vnc\n            ii = ii + nvns\n\n        return ii",
  "def get_vns(self, m, n):\n        self.check_mn(m, n)\n        ii = self.get_index_in_dofs(m, n)\n        return self.local_full_x[ii]",
  "def set_vns(self, m, n, value):\n        self.check_mn(m, n)\n        ii = self.get_index_in_dofs(m, n)\n        self.local_full_x[ii] = value",
  "def get_vnc(self, m, n):\n        self.check_mn(m, n)\n        ii = self.get_index_in_dofs(m, n, even=True)\n        if self.stellsym:\n            return 0.0\n        else:\n            return self.local_full_x[ii]",
  "def set_vnc(self, m, n, value):\n        self.check_mn(m, n)\n        ii = self.get_index_in_dofs(m, n, even=True)\n        if self.stellsym:\n            raise ValueError('Stellarator symmetric has no vnc')\n        else:\n            self.local_full_x[ii] = value",
  "def check_mn(self, m, n):\n        if m < 0 or m > self.mpol:\n            raise ValueError('m out of bound')\n        if n < -self.ntor or n > self.ntor:\n            raise ValueError('n out of bound')\n        if m == 0 and n < 0:\n            raise ValueError('n has to be positive if m==0')",
  "def _make_names(self):\n        \"\"\"\n        Form a list of names of the ``vns``, ``vnc``\n        \"\"\"\n        if self.stellsym:\n            names = self._make_names_helper(False)\n        else:\n            names = np.append(self._make_names_helper(False),\n                              self._make_names_helper(True))\n\n        return names",
  "def _make_names_helper(self, even=False):\n        names = []\n        indices = []\n\n        if even:\n            prefix = 'vnc'\n        else:\n            prefix = 'vns'\n\n        for mm in range(0, self.mpol+1):\n            for nn in range(-self.ntor, self.ntor+1):\n                if mm == 0 and nn < 0:\n                    continue\n                if not even and mm == 0 and nn == 0:\n                    continue\n\n                ind = self.get_index_in_dofs(mm, nn, even=even)\n                names.append(prefix + '({m},{n})'.format(m=mm, n=nn))\n                indices.append(ind)\n\n        # Sort names\n        ind = np.argsort(np.asarray(indices))\n        sorted_names = [names[ii] for ii in ind]\n\n        return sorted_names",
  "def change_resolution(self, mpol, ntor):\n        \"\"\"\n        Change the values of `mpol` and `ntor`. Any new Fourier amplitudes\n        will have a magnitude of zero.  Any previous nonzero Fourier\n        amplitudes that are not within the new range will be\n        discarded.\n        \"\"\"\n\n        # Set new number of dofs\n        if self.stellsym:\n            ndof = ntor + mpol * (2 * ntor + 1)  # Only Vns - odd series\n        else:\n            ndof = 2 * (ntor + mpol * (2 * ntor + 1)) + 1  # Vns and Vns\n\n        # Fill relevant modes\n        min_mpol = np.min((mpol, self.mpol))\n        min_ntor = np.min((ntor, self.ntor))\n\n        dofs = np.zeros((ndof,))\n        for m in range(min_mpol + 1):\n            for n in range(-min_ntor, min_ntor + 1):\n                if m == 0 and n < 0: continue\n\n                if m > 0 or n > 0:\n                    ind = self.get_index_in_dofs(m, n, mpol=mpol, ntor=ntor, even=False)\n                    dofs[ind] = self.get_vns(m, n)\n\n                if not self.stellsym:\n                    ind = self.get_index_in_dofs(m, n, mpol=mpol, ntor=ntor, even=True)\n                    dofs[ind] = self.get_vnc(m, n)\n\n        # Update attributes\n        self.mpol = mpol\n        self.ntor = ntor\n        self.ndof = ndof\n        self._dofs = DOFs(dofs, self._make_names())",
  "def fixed_range(self, mmin, mmax, nmin, nmax, fixed=True):\n        \"\"\"\n        Set the 'fixed' property for a range of `m` and `n` values.\n\n        All modes with `m` in the interval [`mmin`, `mmax`] and `n` in the\n        interval [`nmin`, `nmax`] will have their fixed property set to\n        the value of the `fixed` parameter. Note that `mmax` and `nmax`\n        are included (unlike the upper bound in python's range(min,\n        max).)\n\n        In case of non stellarator symmetric field, both vns and vnc will be\n        fixed (or unfixed)\n        \"\"\"\n\n        fn = self.fix if fixed else self.unfix\n        for m in range(mmin, mmax + 1):\n            this_nmin = nmin\n            if m == 0 and nmin < 0:\n                this_nmin = 0\n            for n in range(this_nmin, nmax + 1):\n                if m > 0 or n != 0:\n                    fn(f'vns({m},{n})')\n                if not self.stellsym:\n                    fn(f'vnc({m},{n})')",
  "def _pad_string(string): \n    '''\n    Pads a string with 30 underscores (for writing coil group names).\n    '''\n    return '{:^30}'.format(string).replace(' ', '_')",
  "def _unpack(binary_array):\n    '''\n    Decrypt binary char array into a string.\n    This function is used for reading coil group names.\n    '''\n    return \"\".join(np.char.decode(binary_array)).strip()",
  "class MGrid():\n\n    '''\n    This class reads and writes mgrid files for use in free boundary VMEC and other codes.\n\n    The mgrid representation consists of the cylindrical components of B on a\n    tensor product grid in cylindrical coordinates. Mgrid files are saved in\n    NetCDF format.\n\n    Args:\n        nr: number of radial points\n        nz: number of axial points\n        nphi: number of azimuthal points, in one field period\n        nfp: number of field periods\n        rmin: minimum r grid point\n        rmax: maximum r grid point\n        zmin: minimum z grid point\n        zmax: maximum z grid point\n\n    Note the (r,z) dimensions include both end points. The (phi) dimension includes the start point and excludes the end point.\n    '''\n\n    def __init__(self,  # fname='temp', #binary=False,\n                 nr: int = 51, \n                 nz: int = 51, \n                 nphi: int = 24, \n                 nfp: int = 2,\n                 rmin: float = 0.20, \n                 rmax: float = 0.40, \n                 zmin: float = -0.10, \n                 zmax: float = 0.10,\n                 ):\n\n        self.nr = nr\n        self.nz = nz\n        self.nphi = nphi\n        self.nfp = nfp\n\n        self.rmin = rmin\n        self.rmax = rmax\n        self.zmin = zmin\n        self.zmax = zmax\n\n        self.n_ext_cur = 0\n        self.coil_names = []\n\n        self.br_arr = [] \n        self.bz_arr = [] \n        self.bp_arr = [] \n\n    def add_field_cylindrical(self, br, bp, bz, name=None):\n        '''\n        This function saves the vector field B.\n        B is defined by cylindrical components.\n\n        The Mgrid array assumes B is sampled linearly first in r, then z, and last phi.\n        Python arrays use the opposite convention such that B[0] gives a (r,z) square at const phi\n        and B[0,0] gives a radial line and const phi and z.\n\n        It is assumed that the (br,bp,bz) inputs for this function is already in a\n        (nphi, nz, nr) shaped array.\n\n        This function may be called once for each coil group, \n        to save sets of fields that can be scaled using EXTCUR in VMEC.\n\n        Args:\n            br: the radial component of B field\n            bp: the azimuthal component of B field\n            bz: the axial component of B field\n            name: Name of the coil group\n        '''\n\n        # appending B field to an array for all coil groups.\n        self.br_arr.append(br)\n        self.bz_arr.append(bz)\n        self.bp_arr.append(bp)\n\n        # add coil label\n        if (name is None):\n            label = _pad_string('magnet_%i' % self.n_ext_cur)\n        else:\n            label = _pad_string(name)\n        self.coil_names.append(label)\n        self.n_ext_cur = self.n_ext_cur + 1\n\n        # TO-DO: this function could check for size consistency, between different fields, and for the (nr,nphi,nz) settings of a given instance\n\n    def write(self, filename):\n        '''\n        Export class data as a netCDF binary.\n\n        The field data is represented as a single \"current group\". For\n        free-boundary vmec, the \"extcur\" array should have a single nonzero\n        element, set to 1.0.\n\n        Args:\n            filename: output file name\n        '''\n\n        with netcdf_file(filename, 'w', mmap=False) as ds:\n\n            # set netcdf dimensions\n            ds.createDimension('stringsize', 30)\n            ds.createDimension('dim_00001', 1)\n            ds.createDimension('external_coil_groups', self.n_ext_cur)\n            ds.createDimension('external_coils', self.n_ext_cur)\n            ds.createDimension('rad', self.nr)\n            ds.createDimension('zee', self.nz)\n            ds.createDimension('phi', self.nphi)\n\n            # declare netcdf variables\n            var_ir = ds.createVariable('ir', 'i4', tuple())\n            var_jz = ds.createVariable('jz', 'i4', tuple())\n            var_kp = ds.createVariable('kp', 'i4', tuple())\n            var_nfp = ds.createVariable('nfp', 'i4', tuple())\n            var_nextcur = ds.createVariable('nextcur', 'i4', tuple())\n\n            var_rmin = ds.createVariable('rmin', 'f8', tuple())\n            var_zmin = ds.createVariable('zmin', 'f8', tuple())\n            var_rmax = ds.createVariable('rmax', 'f8', tuple())\n            var_zmax = ds.createVariable('zmax', 'f8', tuple())\n\n            if self.n_ext_cur == 1:\n                var_coil_group = ds.createVariable('coil_group', 'c', ('stringsize',))\n                var_coil_group[:] = self.coil_names[0]\n            else:\n                var_coil_group = ds.createVariable('coil_group', 'c', ('external_coil_groups', 'stringsize',))\n                var_coil_group[:] = self.coil_names\n            var_mgrid_mode = ds.createVariable('mgrid_mode', 'c', ('dim_00001',))\n            var_raw_coil_cur = ds.createVariable('raw_coil_cur', 'f8', ('external_coils',))\n\n            # assign values\n            var_ir.assignValue(self.nr)\n            var_jz.assignValue(self.nz)\n            var_kp.assignValue(self.nphi)\n            var_nfp.assignValue(self.nfp)\n            var_nextcur.assignValue(self.n_ext_cur)\n\n            var_rmin.assignValue(self.rmin)\n            var_zmin.assignValue(self.zmin)\n            var_rmax.assignValue(self.rmax)\n            var_zmax.assignValue(self.zmax)\n\n            var_mgrid_mode[:] = 'N'  # R - Raw, S - scaled, N - none (old version)\n            var_raw_coil_cur[:] = np.ones(self.n_ext_cur)\n\n            # add fields\n            for j in np.arange(self.n_ext_cur):\n\n                tag = '_%.3i' % (j+1)\n                var_br_001 = ds.createVariable('br'+tag, 'f8', ('phi', 'zee', 'rad'))\n                var_bp_001 = ds.createVariable('bp'+tag, 'f8', ('phi', 'zee', 'rad'))\n                var_bz_001 = ds.createVariable('bz'+tag, 'f8', ('phi', 'zee', 'rad'))\n\n                var_br_001[:, :, :] = self.br_arr[j]\n                var_bz_001[:, :, :] = self.bz_arr[j]\n                var_bp_001[:, :, :] = self.bp_arr[j]\n\n    @classmethod \n    def from_file(cls, filename):\n        '''\n        This method reads MGrid data from file.\n\n        Args:\n            filename: mgrid netCDF input file name\n        '''\n\n        with netcdf_file(filename, 'r', mmap=False) as f:\n\n            # load grid\n            nr = f.variables['ir'].getValue()\n            nphi = f.variables['kp'].getValue()\n            nz = f.variables['jz'].getValue()\n            rmin = f.variables['rmin'].getValue()\n            rmax = f.variables['rmax'].getValue()\n            zmin = f.variables['zmin'].getValue()\n            zmax = f.variables['zmax'].getValue()\n            kwargs = {\"nr\": nr, \"nphi\": nphi, \"nz\": nz, \n                      \"rmin\": rmin, \"rmax\": rmax, \"zmin\": zmin, \"zmax\": zmax}\n\n            mgrid = cls(**kwargs)\n            mgrid.filename = filename\n            mgrid.n_ext_cur = int(f.variables['nextcur'].getValue())\n            coil_data = f.variables['coil_group'][:]\n            mgrid.coil_names = [_unpack(coil_data[j]) for j in range(mgrid.n_ext_cur)] \n\n            mgrid.mode = f.variables['mgrid_mode'][:][0].decode()\n            mgrid.raw_coil_current = np.array(f.variables['raw_coil_cur'][:])\n\n            br_arr = []\n            bp_arr = []\n            bz_arr = []\n\n            nextcur = mgrid.n_ext_cur\n            for j in range(nextcur):\n                idx = '{:03d}'.format(j+1)\n                br = f.variables['br_'+idx][:]  # phi z r\n                bp = f.variables['bp_'+idx][:]\n                bz = f.variables['bz_'+idx][:]\n\n                if (mgrid.mode == 'S'):\n                    br_arr.append(br * mgrid.raw_coil_current[j])\n                    bp_arr.append(bp * mgrid.raw_coil_current[j])\n                    bz_arr.append(bz * mgrid.raw_coil_current[j])\n                else:\n                    br_arr.append(br)\n                    bp_arr.append(bp)\n                    bz_arr.append(bz)\n\n            mgrid.br_arr = np.array(br_arr)\n            mgrid.bp_arr = np.array(bp_arr)\n            mgrid.bz_arr = np.array(bz_arr)\n\n            # sum over coil groups\n            if nextcur > 1:\n                br = np.sum(br_arr, axis=0)\n                bp = np.sum(bp_arr, axis=0)\n                bz = np.sum(bz_arr, axis=0)\n            else:\n                br = br_arr[0]\n                bp = bp_arr[0]\n                bz = bz_arr[0]\n\n            mgrid.br = br\n            mgrid.bp = bp\n            mgrid.bz = bz\n\n            mgrid.bvec = np.transpose([br, bp, bz])\n\n        return mgrid\n\n    def plot(self, jphi=0, bscale=0, show=True):\n        '''\n        Creates a plot of the mgrid data.\n        Shows the three components (br,bphi,bz) in a 2D plot for a fixed toroidal plane.\n\n        Args: \n            jphi: integer index for a toroidal slice.\n            bscale: sets saturation scale for colorbar. (This is useful, because\n                the mgrid domain often includes coil currents, and arbitrarily\n                close to the current source the Bfield values become singular.)\n            show: Whether to call matplotlib's ``show()`` function.\n\n        Returns:\n            2-element tuple ``(fig, axs)`` with the Matplotlib figure and axes handles.\n        '''\n\n        import matplotlib.pyplot as plt\n        fig, axs = plt.subplots(3, 1, figsize=(5, 10))\n\n        rax = np.linspace(self.rmin, self.rmax, self.nr)\n        zax = np.linspace(self.zmin, self.zmax, self.nz)\n\n        def subplot_slice(s, data, rax, zax, bscale=0.3, tag=''):\n\n            if bscale > 0:\n                cf = axs[s].contourf(rax, zax, data, np.linspace(-bscale, bscale, 11), extend='both')\n            else:\n                cf = axs[s].contourf(rax, zax, data)\n            axs[s].plot([], [], '.', label=tag)\n            axs[s].legend()\n            fig.colorbar(cf, ax=axs[s])\n\n        subplot_slice(np.s_[0], self.br[jphi], rax, zax, tag='br', bscale=bscale)\n        subplot_slice(np.s_[1], self.bp[jphi], rax, zax, tag='bp', bscale=bscale)\n        subplot_slice(np.s_[2], self.bz[jphi], rax, zax, tag='bz', bscale=bscale)\n\n        axs[1].set_title(f\"nextcur = {self.n_ext_cur}, mode {self.mode}\", fontsize=10)\n        axs[2].set_title(f\"nr,np,nz = ({self.nr},{self.nphi},{self.nz})\", fontsize=10)\n\n        if (show): plt.show()\n\n        return fig, axs",
  "def __init__(self,  # fname='temp', #binary=False,\n                 nr: int = 51, \n                 nz: int = 51, \n                 nphi: int = 24, \n                 nfp: int = 2,\n                 rmin: float = 0.20, \n                 rmax: float = 0.40, \n                 zmin: float = -0.10, \n                 zmax: float = 0.10,\n                 ):\n\n        self.nr = nr\n        self.nz = nz\n        self.nphi = nphi\n        self.nfp = nfp\n\n        self.rmin = rmin\n        self.rmax = rmax\n        self.zmin = zmin\n        self.zmax = zmax\n\n        self.n_ext_cur = 0\n        self.coil_names = []\n\n        self.br_arr = [] \n        self.bz_arr = [] \n        self.bp_arr = []",
  "def add_field_cylindrical(self, br, bp, bz, name=None):\n        '''\n        This function saves the vector field B.\n        B is defined by cylindrical components.\n\n        The Mgrid array assumes B is sampled linearly first in r, then z, and last phi.\n        Python arrays use the opposite convention such that B[0] gives a (r,z) square at const phi\n        and B[0,0] gives a radial line and const phi and z.\n\n        It is assumed that the (br,bp,bz) inputs for this function is already in a\n        (nphi, nz, nr) shaped array.\n\n        This function may be called once for each coil group, \n        to save sets of fields that can be scaled using EXTCUR in VMEC.\n\n        Args:\n            br: the radial component of B field\n            bp: the azimuthal component of B field\n            bz: the axial component of B field\n            name: Name of the coil group\n        '''\n\n        # appending B field to an array for all coil groups.\n        self.br_arr.append(br)\n        self.bz_arr.append(bz)\n        self.bp_arr.append(bp)\n\n        # add coil label\n        if (name is None):\n            label = _pad_string('magnet_%i' % self.n_ext_cur)\n        else:\n            label = _pad_string(name)\n        self.coil_names.append(label)\n        self.n_ext_cur = self.n_ext_cur + 1",
  "def write(self, filename):\n        '''\n        Export class data as a netCDF binary.\n\n        The field data is represented as a single \"current group\". For\n        free-boundary vmec, the \"extcur\" array should have a single nonzero\n        element, set to 1.0.\n\n        Args:\n            filename: output file name\n        '''\n\n        with netcdf_file(filename, 'w', mmap=False) as ds:\n\n            # set netcdf dimensions\n            ds.createDimension('stringsize', 30)\n            ds.createDimension('dim_00001', 1)\n            ds.createDimension('external_coil_groups', self.n_ext_cur)\n            ds.createDimension('external_coils', self.n_ext_cur)\n            ds.createDimension('rad', self.nr)\n            ds.createDimension('zee', self.nz)\n            ds.createDimension('phi', self.nphi)\n\n            # declare netcdf variables\n            var_ir = ds.createVariable('ir', 'i4', tuple())\n            var_jz = ds.createVariable('jz', 'i4', tuple())\n            var_kp = ds.createVariable('kp', 'i4', tuple())\n            var_nfp = ds.createVariable('nfp', 'i4', tuple())\n            var_nextcur = ds.createVariable('nextcur', 'i4', tuple())\n\n            var_rmin = ds.createVariable('rmin', 'f8', tuple())\n            var_zmin = ds.createVariable('zmin', 'f8', tuple())\n            var_rmax = ds.createVariable('rmax', 'f8', tuple())\n            var_zmax = ds.createVariable('zmax', 'f8', tuple())\n\n            if self.n_ext_cur == 1:\n                var_coil_group = ds.createVariable('coil_group', 'c', ('stringsize',))\n                var_coil_group[:] = self.coil_names[0]\n            else:\n                var_coil_group = ds.createVariable('coil_group', 'c', ('external_coil_groups', 'stringsize',))\n                var_coil_group[:] = self.coil_names\n            var_mgrid_mode = ds.createVariable('mgrid_mode', 'c', ('dim_00001',))\n            var_raw_coil_cur = ds.createVariable('raw_coil_cur', 'f8', ('external_coils',))\n\n            # assign values\n            var_ir.assignValue(self.nr)\n            var_jz.assignValue(self.nz)\n            var_kp.assignValue(self.nphi)\n            var_nfp.assignValue(self.nfp)\n            var_nextcur.assignValue(self.n_ext_cur)\n\n            var_rmin.assignValue(self.rmin)\n            var_zmin.assignValue(self.zmin)\n            var_rmax.assignValue(self.rmax)\n            var_zmax.assignValue(self.zmax)\n\n            var_mgrid_mode[:] = 'N'  # R - Raw, S - scaled, N - none (old version)\n            var_raw_coil_cur[:] = np.ones(self.n_ext_cur)\n\n            # add fields\n            for j in np.arange(self.n_ext_cur):\n\n                tag = '_%.3i' % (j+1)\n                var_br_001 = ds.createVariable('br'+tag, 'f8', ('phi', 'zee', 'rad'))\n                var_bp_001 = ds.createVariable('bp'+tag, 'f8', ('phi', 'zee', 'rad'))\n                var_bz_001 = ds.createVariable('bz'+tag, 'f8', ('phi', 'zee', 'rad'))\n\n                var_br_001[:, :, :] = self.br_arr[j]\n                var_bz_001[:, :, :] = self.bz_arr[j]\n                var_bp_001[:, :, :] = self.bp_arr[j]",
  "def from_file(cls, filename):\n        '''\n        This method reads MGrid data from file.\n\n        Args:\n            filename: mgrid netCDF input file name\n        '''\n\n        with netcdf_file(filename, 'r', mmap=False) as f:\n\n            # load grid\n            nr = f.variables['ir'].getValue()\n            nphi = f.variables['kp'].getValue()\n            nz = f.variables['jz'].getValue()\n            rmin = f.variables['rmin'].getValue()\n            rmax = f.variables['rmax'].getValue()\n            zmin = f.variables['zmin'].getValue()\n            zmax = f.variables['zmax'].getValue()\n            kwargs = {\"nr\": nr, \"nphi\": nphi, \"nz\": nz, \n                      \"rmin\": rmin, \"rmax\": rmax, \"zmin\": zmin, \"zmax\": zmax}\n\n            mgrid = cls(**kwargs)\n            mgrid.filename = filename\n            mgrid.n_ext_cur = int(f.variables['nextcur'].getValue())\n            coil_data = f.variables['coil_group'][:]\n            mgrid.coil_names = [_unpack(coil_data[j]) for j in range(mgrid.n_ext_cur)] \n\n            mgrid.mode = f.variables['mgrid_mode'][:][0].decode()\n            mgrid.raw_coil_current = np.array(f.variables['raw_coil_cur'][:])\n\n            br_arr = []\n            bp_arr = []\n            bz_arr = []\n\n            nextcur = mgrid.n_ext_cur\n            for j in range(nextcur):\n                idx = '{:03d}'.format(j+1)\n                br = f.variables['br_'+idx][:]  # phi z r\n                bp = f.variables['bp_'+idx][:]\n                bz = f.variables['bz_'+idx][:]\n\n                if (mgrid.mode == 'S'):\n                    br_arr.append(br * mgrid.raw_coil_current[j])\n                    bp_arr.append(bp * mgrid.raw_coil_current[j])\n                    bz_arr.append(bz * mgrid.raw_coil_current[j])\n                else:\n                    br_arr.append(br)\n                    bp_arr.append(bp)\n                    bz_arr.append(bz)\n\n            mgrid.br_arr = np.array(br_arr)\n            mgrid.bp_arr = np.array(bp_arr)\n            mgrid.bz_arr = np.array(bz_arr)\n\n            # sum over coil groups\n            if nextcur > 1:\n                br = np.sum(br_arr, axis=0)\n                bp = np.sum(bp_arr, axis=0)\n                bz = np.sum(bz_arr, axis=0)\n            else:\n                br = br_arr[0]\n                bp = bp_arr[0]\n                bz = bz_arr[0]\n\n            mgrid.br = br\n            mgrid.bp = bp\n            mgrid.bz = bz\n\n            mgrid.bvec = np.transpose([br, bp, bz])\n\n        return mgrid",
  "def plot(self, jphi=0, bscale=0, show=True):\n        '''\n        Creates a plot of the mgrid data.\n        Shows the three components (br,bphi,bz) in a 2D plot for a fixed toroidal plane.\n\n        Args: \n            jphi: integer index for a toroidal slice.\n            bscale: sets saturation scale for colorbar. (This is useful, because\n                the mgrid domain often includes coil currents, and arbitrarily\n                close to the current source the Bfield values become singular.)\n            show: Whether to call matplotlib's ``show()`` function.\n\n        Returns:\n            2-element tuple ``(fig, axs)`` with the Matplotlib figure and axes handles.\n        '''\n\n        import matplotlib.pyplot as plt\n        fig, axs = plt.subplots(3, 1, figsize=(5, 10))\n\n        rax = np.linspace(self.rmin, self.rmax, self.nr)\n        zax = np.linspace(self.zmin, self.zmax, self.nz)\n\n        def subplot_slice(s, data, rax, zax, bscale=0.3, tag=''):\n\n            if bscale > 0:\n                cf = axs[s].contourf(rax, zax, data, np.linspace(-bscale, bscale, 11), extend='both')\n            else:\n                cf = axs[s].contourf(rax, zax, data)\n            axs[s].plot([], [], '.', label=tag)\n            axs[s].legend()\n            fig.colorbar(cf, ax=axs[s])\n\n        subplot_slice(np.s_[0], self.br[jphi], rax, zax, tag='br', bscale=bscale)\n        subplot_slice(np.s_[1], self.bp[jphi], rax, zax, tag='bp', bscale=bscale)\n        subplot_slice(np.s_[2], self.bz[jphi], rax, zax, tag='bz', bscale=bscale)\n\n        axs[1].set_title(f\"nextcur = {self.n_ext_cur}, mode {self.mode}\", fontsize=10)\n        axs[2].set_title(f\"nr,np,nz = ({self.nr},{self.nphi},{self.nz})\", fontsize=10)\n\n        if (show): plt.show()\n\n        return fig, axs",
  "def subplot_slice(s, data, rax, zax, bscale=0.3, tag=''):\n\n            if bscale > 0:\n                cf = axs[s].contourf(rax, zax, data, np.linspace(-bscale, bscale, 11), extend='both')\n            else:\n                cf = axs[s].contourf(rax, zax, data)\n            axs[s].plot([], [], '.', label=tag)\n            axs[s].legend()\n            fig.colorbar(cf, ax=axs[s])",
  "def compute_gc_radius(m, vperp, q, absb):\n    \"\"\"\n    Computes the gyro radius of a particle in a field with strenght ``absb```,\n    that is ``r=m*vperp/(abs(q)*absb)``.\n    \"\"\"\n\n    return m*vperp/(abs(q)*absb)",
  "def gc_to_fullorbit_initial_guesses(field, xyz_inits, speed_pars, speed_total, m, q, eta=0):\n    \"\"\"\n    Takes in guiding center positions ``xyz_inits`` as well as a parallel\n    speeds ``speed_pars`` and total velocities ``speed_total`` to compute orbit\n    positions for a full orbit calculation that matches the given guiding\n    center. The phase angle can be controll via the `eta` parameter\n    \"\"\"\n\n    nparticles = xyz_inits.shape[0]\n    xyz_inits_full = np.zeros_like(xyz_inits)\n    v_inits = np.zeros((nparticles, 3))\n    rgs = np.zeros((nparticles, ))\n    field.set_points(xyz_inits)\n    Bs = field.B()\n    AbsBs = field.AbsB()\n    eB = Bs/AbsBs\n    for i in range(nparticles):\n        p1 = eB[i, :]\n        p2 = np.asarray([0, 0, 1])\n        p3 = -np.cross(p1, p2)\n        p3 *= 1./np.linalg.norm(p3)\n        q1 = p1\n        q2 = p2 - np.sum(q1*p2)*q1\n        q2 = q2/np.sum(q2**2)**0.5\n        q3 = p3 - np.sum(q1*p3)*q1 - np.sum(q2*p3)*q2\n        q3 = q3/np.sum(q3**2)**0.5\n        speed_perp = np.sqrt(speed_total**2 - speed_pars[i]**2)\n        rgs[i] = compute_gc_radius(m, speed_perp, q, AbsBs[i, 0])\n\n        xyz_inits_full[i, :] = xyz_inits[i, :] + rgs[i] * np.sin(eta) * q2 + rgs[i] * np.cos(eta) * q3\n        vperp = -speed_perp * np.cos(eta) * q2 + speed_perp * np.sin(eta) * q3\n        v_inits[i, :] = speed_pars[i] * q1 + vperp\n    return xyz_inits_full, v_inits, rgs",
  "def trace_particles_boozer(field: BoozerMagneticField,\n                           stz_inits: RealArray,  \n                           parallel_speeds: RealArray,\n                           tmax=1e-4,\n                           mass=ALPHA_PARTICLE_MASS, charge=ALPHA_PARTICLE_CHARGE, Ekin=FUSION_ALPHA_PARTICLE_ENERGY,\n                           tol=1e-9, comm=None, zetas=[], stopping_criteria=[], mode='gc_vac', forget_exact_path=False):\n    r\"\"\"\n    Follow particles in a :class:`BoozerMagneticField`. This is modeled after\n    :func:`trace_particles`.\n\n\n    In the case of ``mod='gc_vac'`` we solve the guiding center equations under\n    the vacuum assumption, i.e :math:`G =` const. and :math:`I = 0`:\n\n    .. math::\n\n        \\dot s = -|B|_{,\\theta} m(v_{||}^2/|B| + \\mu)/(q \\psi_0)\n\n        \\dot \\theta = |B|_{,s} m(v_{||}^2/|B| + \\mu)/(q \\psi_0) + \\iota v_{||} |B|/G\n\n        \\dot \\zeta = v_{||}|B|/G\n\n        \\dot v_{||} = -(\\iota |B|_{,\\theta} + |B|_{,\\zeta})\\mu |B|/G,\n\n    where :math:`q` is the charge, :math:`m` is the mass, and :math:`v_\\perp^2 = 2\\mu|B|`.\n\n    In the case of ``mode='gc'`` we solve the general guiding center equations\n    for an MHD equilibrium:\n\n    .. math::\n\n        \\dot s = (I |B|_{,\\zeta} - G |B|_{,\\theta})m(v_{||}^2/|B| + \\mu)/(\\iota D \\psi_0)\n\n        \\dot \\theta = ((G |B|_{,\\psi} - K |B|_{,\\zeta}) m(v_{||}^2/|B| + \\mu) - C v_{||} |B|)/(\\iota D)\n\n        \\dot \\zeta = (F v_{||} |B| - (|B|_{,\\psi} I - |B|_{,\\theta} K) m(\\rho_{||}^2 |B| + \\mu) )/(\\iota D)\n\n        \\dot v_{||} = (C|B|_{,\\theta} - F|B|_{,\\zeta})\\mu |B|/(\\iota D)\n\n        C = - m v_{||} K_{,\\zeta}/|B|  - q \\iota + m v_{||}G'/|B|\n\n        F = - m v_{||} K_{,\\theta}/|B| + q + m v_{||}I'/|B|\n\n        D = (F G - C I))/\\iota\n\n    where primes indicate differentiation wrt :math:`\\psi`. In the case ``mod='gc_noK'``,\n    the above equations are used with :math:`K=0`.\n\n    Args:\n        field: The :class:`BoozerMagneticField` instance\n        stz_inits: A ``(nparticles, 3)`` array with the initial positions of\n            the particles in Boozer coordinates :math:`(s,\\theta,\\zeta)`.\n        parallel_speeds: A ``(nparticles, )`` array containing the speed in\n            direction of the B field for each particle.\n        tmax: integration time\n        mass: particle mass in kg, defaults to the mass of an alpha particle\n        charge: charge in Coulomb, defaults to the charge of an alpha particle\n        Ekin: kinetic energy in Joule, defaults to 3.52MeV\n        tol: tolerance for the adaptive ode solver\n        comm: MPI communicator to parallelize over\n        zetas: list of angles in [0, 2pi] for which intersection with the plane\n            corresponding to that zeta should be computed\n        stopping_criteria: list of stopping criteria, mostly used in\n            combination with the ``LevelsetStoppingCriterion``\n            accessed via :obj:`simsopt.field.tracing.SurfaceClassifier`.\n        mode: how to trace the particles. Options are\n            `gc`: general guiding center equations.\n            `gc_vac`: simplified guiding center equations for the case :math:`G` = const.,\n            :math:`I = 0`, and :math:`K = 0`.\n            `gc_noK`: simplified guiding center equations for the case :math:`K = 0`.\n        forget_exact_path: return only the first and last position of each\n            particle for the ``res_tys``. To be used when only res_zeta_hits is of\n            interest or one wants to reduce memory usage.\n\n    Returns: 2 element tuple containing\n        - ``res_tys``:\n            A list of numpy arrays (one for each particle) describing the\n            solution over time. The numpy array is of shape (ntimesteps, M)\n            with M depending on the ``mode``.  Each row contains the time and\n            the state.  So for `mode='gc'` and `mode='gc_vac'` the state\n            consists of the :math:`(s,\\theta,\\zeta)` position and the parallel speed, hence\n            each row contains `[t, s, t, z, v_par]`.\n\n        - ``res_zeta_hits``:\n            A list of numpy arrays (one for each particle) containing\n            information on each time the particle hits one of the zeta planes or\n            one of the stopping criteria. Each row of the array contains\n            `[time] + [idx] + state`, where `idx` tells us which of the `zetas`\n            or `stopping_criteria` was hit.  If `idx>=0`, then `zetas[int(idx)]`\n            was hit. If `idx<0`, then `stopping_criteria[int(-idx)-1]` was hit.\n    \"\"\"\n\n    nparticles = stz_inits.shape[0]\n    assert stz_inits.shape[0] == len(parallel_speeds)\n    speed_par = parallel_speeds\n    m = mass\n    speed_total = sqrt(2*Ekin/m)  # Ekin = 0.5 * m * v^2 <=> v = sqrt(2*Ekin/m)\n    mode = mode.lower()\n    assert mode in ['gc', 'gc_vac', 'gc_nok']\n\n    res_tys = []\n    res_zeta_hits = []\n    loss_ctr = 0\n    first, last = parallel_loop_bounds(comm, nparticles)\n    for i in range(first, last):\n        res_ty, res_zeta_hit = sopp.particle_guiding_center_boozer_tracing(\n            field, stz_inits[i, :],\n            m, charge, speed_total, speed_par[i], tmax, tol, vacuum=(mode == 'gc_vac'),\n            noK=(mode == 'gc_nok'), zetas=zetas, stopping_criteria=stopping_criteria)\n        if not forget_exact_path:\n            res_tys.append(np.asarray(res_ty))\n        else:\n            res_tys.append(np.asarray([res_ty[0], res_ty[-1]]))\n        res_zeta_hits.append(np.asarray(res_zeta_hit))\n        dtavg = res_ty[-1][0]/len(res_ty)\n        logger.debug(f\"{i+1:3d}/{nparticles}, t_final={res_ty[-1][0]}, average timestep {1000*dtavg:.10f}ms\")\n        if res_ty[-1][0] < tmax - 1e-15:\n            loss_ctr += 1\n    if comm is not None:\n        loss_ctr = comm.allreduce(loss_ctr)\n    if comm is not None:\n        res_tys = [i for o in comm.allgather(res_tys) for i in o]\n        res_zeta_hits = [i for o in comm.allgather(res_zeta_hits) for i in o]\n    logger.debug(f'Particles lost {loss_ctr}/{nparticles}={(100*loss_ctr)//nparticles:d}%')\n    return res_tys, res_zeta_hits",
  "def trace_particles(field: MagneticField,\n                    xyz_inits: RealArray,\n                    parallel_speeds: RealArray,  \n                    tmax=1e-4,\n                    mass=ALPHA_PARTICLE_MASS, charge=ALPHA_PARTICLE_CHARGE, Ekin=FUSION_ALPHA_PARTICLE_ENERGY,\n                    tol=1e-9, comm=None, phis=[], stopping_criteria=[], mode='gc_vac', forget_exact_path=False,\n                    phase_angle=0):\n    r\"\"\"\n    Follow particles in a magnetic field.\n\n    In the case of ``mod='full'`` we solve\n\n    .. math::\n\n        [\\ddot x, \\ddot y, \\ddot z] = \\frac{q}{m}  [\\dot x, \\dot y, \\dot z] \\times B\n\n    in the case of ``mod='gc_vac'`` we solve the guiding center equations under\n    the assumption :math:`\\nabla p=0`, that is\n\n    .. math::\n\n        [\\dot x, \\dot y, \\dot z] &= v_{||}\\frac{B}{|B|} + \\frac{m}{q|B|^3}  (0.5v_\\perp^2 + v_{||}^2)  B\\times \\nabla(|B|)\\\\\n        \\dot v_{||}    &= -\\mu  (B \\cdot \\nabla(|B|))\n\n    where :math:`v_\\perp = 2\\mu|B|`. See equations (12) and (13) of\n    [Guiding Center Motion, H.J. de Blank, https://doi.org/10.13182/FST04-A468].\n\n    Args:\n        field: The magnetic field :math:`B`.\n        xyz_inits: A (nparticles, 3) array with the initial positions of the particles.\n        parallel_speeds: A (nparticles, ) array containing the speed in direction of the B field\n                         for each particle.\n        tmax: integration time\n        mass: particle mass in kg, defaults to the mass of an alpha particle\n        charge: charge in Coulomb, defaults to the charge of an alpha particle\n        Ekin: kinetic energy in Joule, defaults to 3.52MeV\n        tol: tolerance for the adaptive ode solver\n        comm: MPI communicator to parallelize over\n        phis: list of angles in [0, 2pi] for which intersection with the plane\n              corresponding to that phi should be computed\n        stopping_criteria: list of stopping criteria, mostly used in\n                           combination with the ``LevelsetStoppingCriterion``\n                           accessed via :obj:`simsopt.field.tracing.SurfaceClassifier`.\n        mode: how to trace the particles. options are\n            `gc`: general guiding center equations,\n            `gc_vac`: simplified guiding center equations for the case :math:`\\nabla p=0`,\n            `full`: full orbit calculation (slow!)\n        forget_exact_path: return only the first and last position of each\n                           particle for the ``res_tys``. To be used when only res_phi_hits is of\n                           interest or one wants to reduce memory usage.\n        phase_angle: the phase angle to use in the case of full orbit calculations\n\n    Returns: 2 element tuple containing\n        - ``res_tys``:\n            A list of numpy arrays (one for each particle) describing the\n            solution over time. The numpy array is of shape (ntimesteps, M)\n            with M depending on the ``mode``.  Each row contains the time and\n            the state.  So for `mode='gc'` and `mode='gc_vac'` the state\n            consists of the xyz position and the parallel speed, hence\n            each row contains `[t, x, y, z, v_par]`.  For `mode='full'`, the\n            state consists of position and velocity vector, i.e. each row\n            contains `[t, x, y, z, vx, vy, vz]`.\n\n        - ``res_phi_hits``:\n            A list of numpy arrays (one for each particle) containing\n            information on each time the particle hits one of the phi planes or\n            one of the stopping criteria. Each row of the array contains\n            `[time] + [idx] + state`, where `idx` tells us which of the `phis`\n            or `stopping_criteria` was hit.  If `idx>=0`, then `phis[int(idx)]`\n            was hit. If `idx<0`, then `stopping_criteria[int(-idx)-1]` was hit.\n    \"\"\"\n\n    nparticles = xyz_inits.shape[0]\n    assert xyz_inits.shape[0] == len(parallel_speeds)\n    speed_par = parallel_speeds\n    mode = mode.lower()\n    assert mode in ['gc', 'gc_vac', 'full']\n    m = mass\n    speed_total = sqrt(2*Ekin/m)  # Ekin = 0.5 * m * v^2 <=> v = sqrt(2*Ekin/m)\n\n    if mode == 'full':\n        xyz_inits, v_inits, _ = gc_to_fullorbit_initial_guesses(field, xyz_inits, speed_par, speed_total, m, charge, eta=phase_angle)\n    res_tys = []\n    res_phi_hits = []\n    loss_ctr = 0\n    first, last = parallel_loop_bounds(comm, nparticles)\n    for i in range(first, last):\n        if 'gc' in mode:\n            res_ty, res_phi_hit = sopp.particle_guiding_center_tracing(\n                field, xyz_inits[i, :],\n                m, charge, speed_total, speed_par[i], tmax, tol,\n                vacuum=(mode == 'gc_vac'), phis=phis, stopping_criteria=stopping_criteria)\n        else:\n            res_ty, res_phi_hit = sopp.particle_fullorbit_tracing(\n                field, xyz_inits[i, :], v_inits[i, :],\n                m, charge, tmax, tol, phis=phis, stopping_criteria=stopping_criteria)\n        if not forget_exact_path:\n            res_tys.append(np.asarray(res_ty))\n        else:\n            res_tys.append(np.asarray([res_ty[0], res_ty[-1]]))\n        res_phi_hits.append(np.asarray(res_phi_hit))\n        dtavg = res_ty[-1][0]/len(res_ty)\n        logger.debug(f\"{i+1:3d}/{nparticles}, t_final={res_ty[-1][0]}, average timestep {1000*dtavg:.10f}ms\")\n        if res_ty[-1][0] < tmax - 1e-15:\n            loss_ctr += 1\n    if comm is not None:\n        loss_ctr = comm.allreduce(loss_ctr)\n    if comm is not None:\n        res_tys = [i for o in comm.allgather(res_tys) for i in o]\n        res_phi_hits = [i for o in comm.allgather(res_phi_hits) for i in o]\n    logger.debug(f'Particles lost {loss_ctr}/{nparticles}={(100*loss_ctr)//nparticles:d}%')\n    return res_tys, res_phi_hits",
  "def trace_particles_starting_on_curve(curve, field, nparticles, tmax=1e-4,\n                                      mass=ALPHA_PARTICLE_MASS, charge=ALPHA_PARTICLE_CHARGE,\n                                      Ekin=FUSION_ALPHA_PARTICLE_ENERGY,\n                                      tol=1e-9, comm=None, seed=1, umin=-1, umax=+1,\n                                      phis=[], stopping_criteria=[], mode='gc_vac', forget_exact_path=False,\n                                      phase_angle=0):\n    r\"\"\"\n    Follows particles spawned at random locations on the magnetic axis with random pitch angle.\n    See :mod:`simsopt.field.tracing.trace_particles` for the governing equations.\n\n    Args:\n        curve: The :mod:`simsopt.geo.curve.Curve` to spawn the particles on. Uses rejection sampling\n               to sample points on the curve. *Warning*: assumes that the underlying\n               quadrature points on the Curve are uniformly distributed.\n        field: The magnetic field :math:`B`.\n        nparticles: number of particles to follow.\n        tmax: integration time\n        mass: particle mass in kg, defaults to the mass of an alpha particle\n        charge: charge in Coulomb, defaults to the charge of an alpha particle\n        Ekin: kinetic energy in Joule, defaults to 3.52MeV\n        tol: tolerance for the adaptive ode solver\n        comm: MPI communicator to parallelize over\n        seed: random seed\n        umin: the parallel speed is defined as  ``v_par = u * speed_total``\n              where  ``u`` is drawn uniformly in ``[umin, umax]``\n        umax: see ``umin``\n        phis: list of angles in [0, 2pi] for which intersection with the plane\n              corresponding to that phi should be computed\n        stopping_criteria: list of stopping criteria, mostly used in\n                           combination with the ``LevelsetStoppingCriterion``\n                           accessed via :obj:`simsopt.field.tracing.SurfaceClassifier`.\n        mode: how to trace the particles. options are\n            `gc`: general guiding center equations,\n            `gc_vac`: simplified guiding center equations for the case :math:`\\nabla p=0`,\n            `full`: full orbit calculation (slow!)\n        forget_exact_path: return only the first and last position of each\n                           particle for the ``res_tys``. To be used when only res_phi_hits is of\n                           interest or one wants to reduce memory usage.\n        phase_angle: the phase angle to use in the case of full orbit calculations\n\n    Returns: see :mod:`simsopt.field.tracing.trace_particles`\n    \"\"\"\n    m = mass\n    speed_total = sqrt(2*Ekin/m)  # Ekin = 0.5 * m * v^2 <=> v = sqrt(2*Ekin/m)\n    np.random.seed(seed)\n    us = np.random.uniform(low=umin, high=umax, size=(nparticles, ))\n    speed_par = us*speed_total\n    xyz, _ = draw_uniform_on_curve(curve, nparticles, safetyfactor=10)\n    return trace_particles(\n        field, xyz, speed_par, tmax=tmax, mass=mass, charge=charge,\n        Ekin=Ekin, tol=tol, comm=comm, phis=phis,\n        stopping_criteria=stopping_criteria, mode=mode, forget_exact_path=forget_exact_path,\n        phase_angle=phase_angle)",
  "def trace_particles_starting_on_surface(surface, field, nparticles, tmax=1e-4,\n                                        mass=ALPHA_PARTICLE_MASS, charge=ALPHA_PARTICLE_CHARGE,\n                                        Ekin=FUSION_ALPHA_PARTICLE_ENERGY,\n                                        tol=1e-9, comm=None, seed=1, umin=-1, umax=+1,\n                                        phis=[], stopping_criteria=[], mode='gc_vac', forget_exact_path=False,\n                                        phase_angle=0):\n    r\"\"\"\n    Follows particles spawned at random locations on the magnetic axis with random pitch angle.\n    See :mod:`simsopt.field.tracing.trace_particles` for the governing equations.\n\n    Args:\n        surface: The :mod:`simsopt.geo.surface.Surface` to spawn the particles\n                 on. Uses rejection sampling to sample points on the curve. *Warning*:\n                 assumes that the underlying quadrature points on the Curve as uniformly\n                 distributed.\n        field: The magnetic field :math:`B`.\n        nparticles: number of particles to follow.\n        tmax: integration time\n        mass: particle mass in kg, defaults to the mass of an alpha particle\n        charge: charge in Coulomb, defaults to the charge of an alpha particle\n        Ekin: kinetic energy in Joule, defaults to 3.52MeV\n        tol: tolerance for the adaptive ode solver\n        comm: MPI communicator to parallelize over\n        seed: random seed\n        umin: the parallel speed is defined as  ``v_par = u * speed_total``\n              where  ``u`` is drawn uniformly in ``[umin, umax]``.\n        umax: see ``umin``\n        phis: list of angles in [0, 2pi] for which intersection with the plane\n              corresponding to that phi should be computed\n        stopping_criteria: list of stopping criteria, mostly used in\n                           combination with the ``LevelsetStoppingCriterion``\n                           accessed via :obj:`simsopt.field.tracing.SurfaceClassifier`.\n        mode: how to trace the particles. options are\n            `gc`: general guiding center equations,\n            `gc_vac`: simplified guiding center equations for the case :math:`\\nabla p=0`,\n            `full`: full orbit calculation (slow!)\n        forget_exact_path: return only the first and last position of each\n                           particle for the ``res_tys``. To be used when only res_phi_hits is of\n                           interest or one wants to reduce memory usage.\n        phase_angle: the phase angle to use in the case of full orbit calculations\n\n    Returns: see :mod:`simsopt.field.tracing.trace_particles`\n    \"\"\"\n    m = mass\n    speed_total = sqrt(2*Ekin/m)  # Ekin = 0.5 * m * v^2 <=> v = sqrt(2*Ekin/m)\n    np.random.seed(seed)\n    us = np.random.uniform(low=umin, high=umax, size=(nparticles, ))\n    speed_par = us*speed_total\n    xyz, _ = draw_uniform_on_surface(surface, nparticles, safetyfactor=10)\n    return trace_particles(\n        field, xyz, speed_par, tmax=tmax, mass=mass, charge=charge,\n        Ekin=Ekin, tol=tol, comm=comm, phis=phis,\n        stopping_criteria=stopping_criteria, mode=mode, forget_exact_path=forget_exact_path,\n        phase_angle=phase_angle)",
  "def compute_resonances(res_tys, res_phi_hits, ma=None, delta=1e-2):\n    r\"\"\"\n    Computes resonant particle orbits given the output of either\n    :func:`trace_particles` or :func:`trace_particles_boozer`, ``res_tys`` and\n    ``res_phi_hits``/``res_zeta_hits``, with ``forget_exact_path=False``.\n    Resonance indicates a trajectory which returns to the same position\n    at the :math:`\\zeta = 0` plane after ``mpol`` poloidal turns and\n    ``ntor`` toroidal turns. For the case of particles traced in a\n    :class:`MagneticField` (not a :class:`BoozerMagneticField`), the poloidal\n    angle is computed using the arctangent angle in the poloidal plane with\n    respect to the coordinate axis, ``ma``,\n\n    .. math::\n        \\theta = \\tan^{-1} \\left( \\frac{R(\\phi)-R_{\\mathrm{ma}}(\\phi)}{Z(\\phi)-Z_{\\mathrm{ma}}(\\phi)} \\right),\n\n    where :math:`(R,\\phi,Z)` are the cylindrical coordinates of the trajectory\n    and :math:`(R_{\\mathrm{ma}}(\\phi),Z_{\\mathrm{ma}(\\phi)})` is the position\n    of the coordinate axis.\n\n    Args:\n        res_tys: trajectory solution computed from :func:`trace_particles` or\n                :func:`trace_particles_boozer` with ``forget_exact_path=False``\n        res_phi_hits: output of :func:`trace_particles` or\n                :func:`trace_particles_boozer` with `phis/zetas = [0]`\n        ma: an instance of :class:`Curve` representing the coordinate axis with\n                respect to which the poloidal angle is computed. If the orbit is\n                computed in flux coordinates, ``ma`` should be ``None``. (defaults to None)\n        delta: the distance tolerance in the poloidal plane used to compute\n                a resonant orbit. (defaults to 1e-2)\n\n    Returns:\n        resonances: list of 7d arrays containing resonant particle orbits. The\n                elements of each array is ``[s0, theta0, zeta0, vpar0, t, mpol, ntor]``\n                if ``ma=None``, and ``[R0, Z0, phi0, vpar0, t, mpol, ntor]`` otherwise.\n                Here ``(s0, theta0, zeta0, vpar0)/(R0, Z0, phi0, vpar0)`` indicates the\n                initial position and parallel velocity of the particle, ``t``\n                indicates the time of the  resonance, ``mpol`` is the number of\n                poloidal turns of the orbit, and ``ntor`` is the number of toroidal turns.\n    \"\"\"\n    flux = False\n    if ma is None:\n        flux = True\n    nparticles = len(res_tys)\n    resonances = []\n    gamma = np.zeros((1, 3))\n    # Iterate over particles\n    for ip in range(nparticles):\n        nhits = len(res_phi_hits[ip])\n        if (flux):\n            s0 = res_tys[ip][0, 1]\n            theta0 = res_tys[ip][0, 2]\n            zeta0 = res_tys[ip][0, 3]\n            theta0_mod = theta0 % (2*np.pi)\n            zeta0_mod = zeta0 % (2*np.pi)\n            x0 = s0 * np.cos(theta0)\n            y0 = s0 * np.sin(theta0)\n        else:\n            X0 = res_tys[ip][0, 1]\n            Y0 = res_tys[ip][0, 2]\n            Z0 = res_tys[ip][0, 3]\n            R0 = np.sqrt(X0**2 + Y0**2)\n            phi0 = np.arctan2(Y0, X0)\n            ma.gamma_impl(gamma, phi0/(2*np.pi))\n            R_ma0 = np.sqrt(gamma[0, 0]**2 + gamma[0, 1]**2)\n            Z_ma0 = gamma[0, 2]\n            theta0 = np.arctan2(Z0-Z_ma0, R0-R_ma0)\n        vpar0 = res_tys[ip][0, 4]\n        for it in range(1, nhits):\n            # Check whether phi hit or stopping criteria achieved\n            if int(res_phi_hits[ip][it, 1]) >= 0:\n                if (flux):\n                    s = res_phi_hits[ip][it, 2]\n                    theta = res_phi_hits[ip][it, 3]\n                    zeta = res_phi_hits[ip][it, 4]\n                    theta_mod = theta % 2*np.pi\n                    x = s * np.cos(theta)\n                    y = s * np.sin(theta)\n                    dist = np.sqrt((x-x0)**2 + (y-y0)**2)\n                else:\n                    # Check that distance is less than delta\n                    X = res_phi_hits[ip][it, 2]\n                    Y = res_phi_hits[ip][it, 3]\n                    R = np.sqrt(X**2 + Y**2)\n                    Z = res_phi_hits[ip][it, 4]\n                    dist = np.sqrt((R-R0)**2 + (Z-Z0)**2)\n                t = res_phi_hits[ip][it, 0]\n                if dist < delta:\n                    logger.debug('Resonance found.')\n                    if flux:\n                        logger.debug(f'theta = {theta_mod}, theta0 = {theta0_mod}, s = {s}, s0 = {s0}')\n                        mpol = np.rint((theta-theta0)/(2*np.pi))\n                        ntor = np.rint((zeta-zeta0)/(2*np.pi))\n                        resonances.append(np.asarray([s0, theta0, zeta0, vpar0, t, mpol, ntor]))\n                    else:\n                        # Find index of closest point along trajectory\n                        indexm = np.argmin(np.abs(res_tys[ip][:, 0]-t))\n                        # Compute mpol and ntor for neighboring points as well\n                        indexl = indexm-1\n                        indexr = indexm+1\n                        dtl = np.abs(res_tys[ip][indexl, 0]-t)\n                        trajlistl = []\n                        trajlistl.append(res_tys[ip][0:indexl+1, :])\n                        mpoll = np.abs(compute_poloidal_transits(trajlistl, ma, flux))\n                        ntorl = np.abs(compute_toroidal_transits(trajlistl, flux))\n                        logger.debug(f'dtl ={dtl}, mpoll = {mpoll}, ntorl = {ntorl}, tl={res_tys[ip][indexl,0]}')\n                        logger.debug(f'(R,Z)l = {np.sqrt(res_tys[ip][indexl,1]**2 + res_tys[ip][indexl,2]**2),res_tys[ip][indexl,3]}')\n\n                        trajlistm = []\n                        dtm = np.abs(res_tys[ip][indexm, 0]-t)\n                        trajlistm.append(res_tys[ip][0:indexm+1, :])\n                        mpolm = np.abs(compute_poloidal_transits(trajlistm, ma, flux))\n                        ntorm = np.abs(compute_toroidal_transits(trajlistm, flux))\n                        logger.debug(f'dtm ={dtm}, mpolm = {mpolm}, ntorm = {ntorm}, tm={res_tys[ip][indexm,0]}')\n                        logger.debug(f'(R,Z)m = {np.sqrt(res_tys[ip][indexm,1]**2 + res_tys[ip][indexm,2]**2),res_tys[ip][indexm,3]}')\n\n                        mpolr = 0\n                        ntorr = 0\n                        if indexr < len(res_tys[ip][:, 0]):\n                            trajlistr = []\n                            dtr = np.abs(res_tys[ip][indexr, 0]-t)\n                            trajlistr.append(res_tys[ip][0:indexr+1, :])\n                            # Take maximum over neighboring points to catch near resonances\n                            mpolr = np.abs(compute_poloidal_transits(trajlistr, ma, flux))\n                            ntorr = np.abs(compute_toroidal_transits(trajlistr, flux))\n                            logger.debug(f'dtr ={dtr}, mpolr = {mpolr}, ntorr = {ntorr}, tr={res_tys[ip][indexr,0]}')\n                            logger.debug(f'(R,Z)r = {np.sqrt(res_tys[ip][indexr,1]**2 + res_tys[ip][indexr,2]**2),res_tys[ip][indexr,3]}')\n\n                        mpol = np.amax([mpoll, mpolm, mpolr])\n                        index_mpol = np.argmax([mpoll, mpolm, mpolr])\n                        ntor = np.amax([ntorl, ntorm, ntorr])\n                        index_ntor = np.argmax([ntorl, ntorm, ntorr])\n                        index = np.amax([index_mpol, index_ntor])\n                        resonances.append(np.asarray([R0, Z0, phi0, vpar0, t, mpol, ntor]))\n    return resonances",
  "def compute_toroidal_transits(res_tys, flux=True):\n    r\"\"\"\n    Computes the number of toroidal transits of an orbit.\n\n    Args:\n        res_tys: trajectory solution computed from :func:`trace_particles` or\n                :func:`trace_particles_boozer` with ``forget_exact_path=False``.\n        flux: if ``True``, ``res_tys`` represents the position in flux coordinates\n                (should be ``True`` if computed from :func:`trace_particles_boozer`)\n    Returns:\n        ntransits: array with length ``len(res_tys)``. Each element contains the\n                number of toroidal transits of the orbit.\n    \"\"\"\n    nparticles = len(res_tys)\n    ntransits = np.zeros((nparticles,))\n    for ip in range(nparticles):\n        ntraj = len(res_tys[ip][:, 0])\n        if flux:\n            phi_init = res_tys[ip][0, 3]\n        else:\n            phi_init = sopp.get_phi(res_tys[ip][0, 1], res_tys[ip][0, 2], np.pi)\n        phi_prev = phi_init\n        for it in range(1, ntraj):\n            if flux:\n                phi = res_tys[ip][it, 3]\n            else:\n                phi = sopp.get_phi(res_tys[ip][it, 1], res_tys[ip][it, 2], phi_prev)\n            phi_prev = phi\n        if ntraj > 1:\n            ntransits[ip] = np.round((phi - phi_init)/(2*np.pi))\n    return ntransits",
  "def compute_poloidal_transits(res_tys, ma=None, flux=True):\n    r\"\"\"\n    Computes the number of poloidal transits of an orbit. For the case of\n    particles traced in a :class:`MagneticField` (not a :class:`BoozerMagneticField`),\n    the poloidal angle is computed using the arctangent angle in the poloidal plane with\n    respect to the coordinate axis, ``ma``,\n\n    .. math::\n        \\theta = \\tan^{-1} \\left( \\frac{R(\\phi)-R_{\\mathrm{ma}}(\\phi)}{Z(\\phi)-Z_{\\mathrm{ma}}(\\phi)} \\right),\n\n    where :math:`(R,\\phi,Z)` are the cylindrical coordinates of the trajectory\n    and :math:`(R_{\\mathrm{ma}}(\\phi),Z_{\\mathrm{ma}(\\phi)})` is the position\n    of the coordinate axis.\n\n    Args:\n        res_tys: trajectory solution computed from :func:`trace_particles` or\n                :func:`trace_particles_boozer` with ``forget_exact_path=False``.\n        ma: an instance of :class:`Curve` representing the coordinate axis with\n                respect to which the poloidal angle is computed. If orbit is\n                computed in Boozer coordinates, ``ma`` should be ``None``.\n        flux: if ``True``, ``res_tys`` represents the position in flux coordinates\n                (should be ``True`` if computed from :func:`trace_particles_boozer`).\n                If ``True``, ``ma`` is not used.\n    Returns:\n        ntransits: array with length ``len(res_tys)``. Each element contains the\n                number of poloidal transits of the orbit.\n    \"\"\"\n    if not flux:\n        assert (ma is not None)\n    nparticles = len(res_tys)\n    ntransits = np.zeros((nparticles,))\n    gamma = np.zeros((1, 3))\n    for ip in range(nparticles):\n        ntraj = len(res_tys[ip][:, 0])\n        if flux:\n            theta_init = res_tys[ip][0, 2]\n        else:\n            R_init = np.sqrt(res_tys[ip][0, 1]**2 + res_tys[ip][0, 2]**2)\n            Z_init = res_tys[ip][0, 3]\n            phi_init = np.arctan2(res_tys[ip][0, 2], res_tys[ip][0, 1])\n            ma.gamma_impl(gamma, phi_init/(2*np.pi))\n            R_ma = np.sqrt(gamma[0, 0]**2 + gamma[0, 1]**2)\n            Z_ma = gamma[0, 2]\n            theta_init = sopp.get_phi(R_init-R_ma, Z_init-Z_ma, np.pi)\n        theta_prev = theta_init\n        for it in range(1, ntraj):\n            if flux:\n                theta = res_tys[ip][it, 2]\n            else:\n                phi = np.arctan2(res_tys[ip][it, 2], res_tys[ip][it, 1])\n                ma.gamma_impl(gamma, phi/(2*np.pi))\n                R_ma = np.sqrt(gamma[0, 0]**2 + gamma[0, 1]**2)\n                Z_ma = gamma[0, 2]\n                R = np.sqrt(res_tys[ip][it, 1]**2 + res_tys[ip][it, 2]**2)\n                Z = res_tys[ip][it, 3]\n                theta = sopp.get_phi(R-R_ma, Z-Z_ma, theta_prev)\n            theta_prev = theta\n        if ntraj > 1:\n            ntransits[ip] = np.round((theta - theta_init)/(2*np.pi))\n    return ntransits",
  "def compute_fieldlines(field, R0, Z0, tmax=200, tol=1e-7, phis=[], stopping_criteria=[], comm=None):\n    r\"\"\"\n    Compute magnetic field lines by solving\n\n    .. math::\n\n        [\\dot x, \\dot y, \\dot z] = B(x, y, z)\n\n    Args:\n        field: the magnetic field :math:`B`\n        R0: list of radial components of initial points\n        Z0: list of vertical components of initial points\n        tmax: for how long to trace. will do roughly ``|B|*tmax/(2*pi*r0)`` revolutions of the device\n        tol: tolerance for the adaptive ode solver\n        phis: list of angles in [0, 2pi] for which intersection with the plane\n              corresponding to that phi should be computed\n        stopping_criteria: list of stopping criteria, mostly used in\n                           combination with the ``LevelsetStoppingCriterion``\n                           accessed via :obj:`simsopt.field.tracing.SurfaceClassifier`.\n\n    Returns: 2 element tuple containing\n        - ``res_tys``:\n            A list of numpy arrays (one for each particle) describing the\n            solution over time. The numpy array is of shape (ntimesteps, 4).\n            Each row contains the time and\n            the position, i.e.`[t, x, y, z]`.\n        - ``res_phi_hits``:\n            A list of numpy arrays (one for each particle) containing\n            information on each time the particle hits one of the phi planes or\n            one of the stopping criteria. Each row of the array contains\n            `[time, idx, x, y, z]`, where `idx` tells us which of the `phis`\n            or `stopping_criteria` was hit.  If `idx>=0`, then `phis[int(idx)]`\n            was hit. If `idx<0`, then `stopping_criteria[int(-idx)-1]` was hit.\n    \"\"\"\n    assert len(R0) == len(Z0)\n    nlines = len(R0)\n    xyz_inits = np.zeros((nlines, 3))\n    xyz_inits[:, 0] = np.asarray(R0)\n    xyz_inits[:, 2] = np.asarray(Z0)\n    res_tys = []\n    res_phi_hits = []\n    first, last = parallel_loop_bounds(comm, nlines)\n    for i in range(first, last):\n        res_ty, res_phi_hit = sopp.fieldline_tracing(\n            field, xyz_inits[i, :],\n            tmax, tol, phis=phis, stopping_criteria=stopping_criteria)\n        res_tys.append(np.asarray(res_ty))\n        res_phi_hits.append(np.asarray(res_phi_hit))\n        dtavg = res_ty[-1][0]/len(res_ty)\n        logger.debug(f\"{i+1:3d}/{nlines}, t_final={res_ty[-1][0]}, average timestep {dtavg:.10f}s\")\n    if comm is not None:\n        res_tys = [i for o in comm.allgather(res_tys) for i in o]\n        res_phi_hits = [i for o in comm.allgather(res_phi_hits) for i in o]\n    return res_tys, res_phi_hits",
  "def particles_to_vtk(res_tys, filename):\n    \"\"\"\n    Export particle tracing or field lines to a vtk file.\n    Expects that the xyz positions can be obtained by ``xyz[:, 1:4]``.\n    \"\"\"\n    from pyevtk.hl import polyLinesToVTK\n    x = np.concatenate([xyz[:, 1] for xyz in res_tys])\n    y = np.concatenate([xyz[:, 2] for xyz in res_tys])\n    z = np.concatenate([xyz[:, 3] for xyz in res_tys])\n    ppl = np.asarray([xyz.shape[0] for xyz in res_tys])\n    data = np.concatenate([i*np.ones((res_tys[i].shape[0], )) for i in range(len(res_tys))])\n    polyLinesToVTK(filename, x, y, z, pointsPerLine=ppl, pointData={'idx': data})",
  "class LevelsetStoppingCriterion(sopp.LevelsetStoppingCriterion):\n    r\"\"\"\n    Based on a scalar function :math:`f:R^3\\to R`, this criterion checks whether\n    :math:`f(x, y, z) < 0` and stops the iteration once this is true.\n\n    The idea is to use this for example with signed distance functions to a surface.\n    \"\"\"\n\n    def __init__(self, classifier):\n        assert isinstance(classifier, SurfaceClassifier) \\\n            or isinstance(classifier, sopp.RegularGridInterpolant3D)\n        if isinstance(classifier, SurfaceClassifier):\n            sopp.LevelsetStoppingCriterion.__init__(self, classifier.dist)\n        else:\n            sopp.LevelsetStoppingCriterion.__init__(self, classifier)",
  "class MinToroidalFluxStoppingCriterion(sopp.MinToroidalFluxStoppingCriterion):\n    \"\"\"\n    Stop the iteration once a particle falls below a critical value of\n    ``s``, the normalized toroidal flux. This :class:`StoppingCriterion` is\n    important to use when tracing particles in flux coordinates, as the poloidal\n    angle becomes ill-defined at the magnetic axis. This should only be used\n    when tracing trajectories in a flux coordinate system (i.e., :class:`trace_particles_boozer`).\n\n    Usage:\n\n    .. code-block::\n\n        stopping_criteria=[MinToroidalFluxStopingCriterion(s)]\n\n    where ``s`` is the value of the minimum normalized toroidal flux.\n    \"\"\"\n    pass",
  "class MaxToroidalFluxStoppingCriterion(sopp.MaxToroidalFluxStoppingCriterion):\n    \"\"\"\n    Stop the iteration once a particle falls above a critical value of\n    ``s``, the normalized toroidal flux. This should only be used when tracing\n    trajectories in a flux coordinate system (i.e., :class:`trace_particles_boozer`).\n\n    Usage:\n\n    .. code-block::\n\n        stopping_criteria=[MaxToroidalFluxStopingCriterion(s)]\n\n    where ``s`` is the value of the maximum normalized toroidal flux.\n    \"\"\"\n    pass",
  "class ToroidalTransitStoppingCriterion(sopp.ToroidalTransitStoppingCriterion):\n    \"\"\"\n    Stop the iteration once the maximum number of toroidal transits is reached.\n\n    Usage:\n\n    .. code-block::\n\n        stopping_criteria=[ToroidalTransitStoppingCriterion(ntransits,flux)]\n\n    where ``ntransits`` is the maximum number of toroidal transits and ``flux``\n    is a boolean indicating whether tracing is being performed in a flux coordinate system.\n    \"\"\"\n    pass",
  "class IterationStoppingCriterion(sopp.IterationStoppingCriterion):\n    \"\"\"\n    Stop the iteration once the maximum number of iterations is reached.\n    \"\"\"\n    pass",
  "def plot_poincare_data(fieldlines_phi_hits, phis, filename, mark_lost=False, aspect='equal', dpi=300, xlims=None, ylims=None, surf=None):\n    \"\"\"\n    Create a poincare plot. Usage:\n\n    .. code-block::\n\n        phis = np.linspace(0, 2*np.pi/nfp, nphis, endpoint=False)\n        res_tys, res_phi_hits = compute_fieldlines(\n            bsh, R0, Z0, tmax=1000, phis=phis, stopping_criteria=[])\n        plot_poincare_data(res_phi_hits, phis, '/tmp/fieldlines.png')\n\n    Requires matplotlib to be installed.\n\n    \"\"\"\n    import matplotlib.pyplot as plt\n    from math import ceil, sqrt\n    nrowcol = ceil(sqrt(len(phis)))\n    plt.figure()\n    fig, axs = plt.subplots(nrowcol, nrowcol, figsize=(8, 5))\n    color = None\n    for i in range(len(phis)):\n        row = i//nrowcol\n        col = i % nrowcol\n        if i != len(phis) - 1:\n            axs[row, col].set_title(f\"$\\\\phi = {phis[i]/np.pi:.2f}\\\\pi$ \", loc='left', y=0.0)\n        else:\n            axs[row, col].set_title(f\"$\\\\phi = {phis[i]/np.pi:.2f}\\\\pi$ \", loc='right', y=0.0)\n        if row == nrowcol - 1:\n            axs[row, col].set_xlabel(\"$r$\")\n        if col == 0:\n            axs[row, col].set_ylabel(\"$z$\")\n        if col == 1:\n            axs[row, col].set_yticklabels([])\n        if xlims is not None:\n            axs[row, col].set_xlim(xlims)\n        if ylims is not None:\n            axs[row, col].set_ylim(ylims)\n        for j in range(len(fieldlines_phi_hits)):\n            lost = fieldlines_phi_hits[j][-1, 1] < 0\n            if mark_lost:\n                color = 'r' if lost else 'g'\n            data_this_phi = fieldlines_phi_hits[j][np.where(fieldlines_phi_hits[j][:, 1] == i)[0], :]\n            if data_this_phi.size == 0:\n                continue\n            r = np.sqrt(data_this_phi[:, 2]**2+data_this_phi[:, 3]**2)\n            axs[row, col].scatter(r, data_this_phi[:, 4], marker='o', s=2, linewidths=0, c=color)\n\n        plt.rc('axes', axisbelow=True)\n        axs[row, col].grid(True, linewidth=0.5)\n\n        # if passed a surface, plot the plasma surface outline\n        if surf is not None:\n            cross_section = surf.cross_section(phi=phis[i])\n            r_interp = np.sqrt(cross_section[:, 0] ** 2 + cross_section[:, 1] ** 2)\n            z_interp = cross_section[:, 2]\n            axs[row, col].plot(r_interp, z_interp, linewidth=1, c='k')\n\n    plt.tight_layout()\n    plt.savefig(filename, dpi=dpi)\n    plt.close()",
  "def __init__(self, classifier):\n        assert isinstance(classifier, SurfaceClassifier) \\\n            or isinstance(classifier, sopp.RegularGridInterpolant3D)\n        if isinstance(classifier, SurfaceClassifier):\n            sopp.LevelsetStoppingCriterion.__init__(self, classifier.dist)\n        else:\n            sopp.LevelsetStoppingCriterion.__init__(self, classifier)",
  "def get_ncsx_data(Nt_coils=25, Nt_ma=10, ppp=10):\n    \"\"\"\n    Get a configuration that corresponds to the modular coils of the NCSX experiment (circular coils are not included).\n\n    Args:\n        Nt_coils: order of the curves representing the coils.\n        Nt_ma: order of the curve representing the magnetic axis.\n        ppp: point-per-period: number of quadrature points per period\n\n    Returns: 3 element tuple containing the coils, currents, and the magnetic axis.\n    \"\"\"\n    filename = THIS_DIR / 'NCSX.dat'\n    curves = CurveXYZFourier.load_curves_from_file(filename, order=Nt_coils, ppp=ppp)\n    nfp = 3\n    currents = [Current(c) for c in [6.52271941985300E+05, 6.51868569367400E+05, 5.37743588647300E+05]]\n    cR = [\n        1.471415400740515, 0.1205306261840785, 0.008016125223436036, -0.000508473952304439,\n        -0.0003025251710853062, -0.0001587936004797397, 3.223984137937924e-06, 3.524618949869718e-05,\n        2.539719080181871e-06, -9.172247073731266e-06, -5.9091166854661e-06, -2.161311017656597e-06,\n        -5.160802127332585e-07, -4.640848016990162e-08, 2.649427979914062e-08, 1.501510332041489e-08,\n        3.537451979994735e-09, 3.086168230692632e-10, 2.188407398004411e-11, 5.175282424829675e-11,\n        1.280947310028369e-11, -1.726293760717645e-11, -1.696747733634374e-11, -7.139212832019126e-12,\n        -1.057727690156884e-12, 5.253991686160475e-13]\n    sZ = [\n        0.06191774986623827, 0.003997436991295509, -0.0001973128955021696, -0.0001892615088404824,\n        -2.754694372995494e-05, -1.106933185883972e-05, 9.313743937823742e-06, 9.402864564707521e-06,\n        2.353424962024579e-06, -1.910411249403388e-07, -3.699572817752344e-07, -1.691375323357308e-07,\n        -5.082041581362814e-08, -8.14564855367364e-09, 1.410153957667715e-09, 1.23357552926813e-09,\n        2.484591855376312e-10, -3.803223187770488e-11, -2.909708414424068e-11, -2.009192074867161e-12,\n        1.775324360447656e-12, -7.152058893039603e-13, -1.311461207101523e-12, -6.141224681566193e-13,\n        -6.897549209312209e-14]\n\n    numpoints = Nt_ma*ppp+1 if ((Nt_ma*ppp) % 2 == 0) else Nt_ma*ppp\n    ma = CurveRZFourier(numpoints, Nt_ma, nfp, True)\n    ma.rc[:] = cR[0:(Nt_ma+1)]\n    ma.zs[:] = sZ[0:Nt_ma]\n    ma.x = ma.get_dofs()\n    return (curves, currents, ma)",
  "def get_hsx_data(Nt_coils=16, Nt_ma=10, ppp=10):\n    \"\"\"\n    Get a configuration that corresponds to the modular coils of the HSX experiment.\n\n    Args:\n        Nt_coils: order of the curves representing the coils.\n        Nt_ma: order of the curve representing the magnetic axis.\n        ppp: point-per-period: number of quadrature points per period\n\n    Returns: 3 element tuple containing the coils, currents, and the magnetic axis.\n    \"\"\"\n    filename = THIS_DIR / 'HSX.dat'\n    curves = CurveXYZFourier.load_curves_from_file(filename, order=Nt_coils, ppp=ppp)\n    nfp = 4\n    currents = [Current(c) for c in [-1.500725500000000e+05, -1.500725500000000e+05, -1.500725500000000e+05, -1.500725500000000e+05, -1.500725500000000e+05, -1.500725500000000e+05]]\n    cR = [1.221168734647426701e+00, 2.069298947130969735e-01, 1.819037041932574511e-02, 4.787659822787012774e-05,\n          -3.394778038757981920e-05, 4.051690884402789139e-05, 1.066865447680375597e-05, -1.418831703321225589e-05, \n          2.041664078576817539e-05, 2.407340923216046553e-05, -1.281275289727263035e-05, -2.712941403326357315e-05, \n          1.828622086757983125e-06, 1.945955315401206440e-05, 1.409134021563425399e-05, 4.572199318143535127e-06, \n          3.136573559452139703e-07, -3.918158977823491866e-07, -2.204187636324686728e-07, -4.532041599796651056e-08, \n          2.878479243210971143e-08, 2.102768080992785704e-08, -1.267816940685333911e-08, -2.268541399245120326e-08, \n          -8.015316098897114283e-09, 6.401201778979550964e-09]\n    sZ = [1.670393448410154857e-01, 1.638250511845155272e-02, 1.656424673977177490e-04, -1.506417857585283353e-04, \n          8.367238367133577161e-05, -1.386982370447437845e-05, -7.536154112897463947e-06, -1.533108076767641072e-05, \n          -9.966838351213697000e-06, 2.561158318745738406e-05, -1.212668371257951164e-06, -1.476513099369021112e-05, \n          -3.716380502156798402e-06, 3.381104573944970371e-06, 2.605458694352088474e-06, 5.701177408478323677e-07, \n          -1.056254779440627595e-07, -1.112799365280694501e-07, -5.381768314066269919e-08, -1.484193645281248712e-08, \n          1.160936870766209295e-08, 1.466392841646290274e-08, 1.531935984912975004e-09, -6.857347022910395347e-09, \n          -4.082678667917087128e-09]\n\n    numpoints = Nt_ma*ppp+1 if ((Nt_ma*ppp) % 2 == 0) else Nt_ma*ppp\n    ma = CurveRZFourier(numpoints, Nt_ma, nfp, True)\n    ma.rc[:] = cR[0:(Nt_ma+1)]\n    ma.zs[:] = sZ[0:Nt_ma]\n    ma.x = ma.get_dofs()\n    return (curves, currents, ma)",
  "def get_giuliani_data(Nt_coils=16, Nt_ma=10, ppp=10, length=18, nsurfaces=5):\n    \"\"\"\n\n    This example simply loads the coils after the nine stage optimization runs discussed in\n\n       A. Giuliani, F. Wechsung, M. Landreman, G. Stadler, A. Cerfon, Direct computation of magnetic surfaces in Boozer coordinates and coil optimization for quasi-symmetry. Journal of Plasma Physics.\n\n    Args:\n        Nt_coils: order of the curves representing the coils.\n        Nt_ma: order of the curve representing the magnetic axis.\n        ppp: point-per-period: number of quadrature points per period\n\n    Returns: 3 element tuple containing the coils, currents, and the magnetic axis.\n    \"\"\"\n    assert length in [18, 20, 22, 24]\n    assert nsurfaces in [5, 9]\n\n    filename = THIS_DIR / f'GIULIANI_length{length}_nsurfaces{nsurfaces}'\n    curves = CurveXYZFourier.load_curves_from_file(filename.with_suffix('.curves'), order=Nt_coils, ppp=ppp)\n    currents = [Current(c) for c in np.loadtxt(filename.with_suffix('.currents'))]\n    ma_dofs = np.loadtxt(filename.with_suffix('.ma'))\n    cR = ma_dofs[:26]\n    sZ = ma_dofs[26:]\n    nfp = 2\n\n    numpoints = Nt_ma*ppp+1 if ((Nt_ma*ppp) % 2 == 0) else Nt_ma*ppp\n    ma = CurveRZFourier(numpoints, Nt_ma, nfp, True)\n    ma.rc[:] = cR[:(Nt_ma+1)]\n    ma.zs[:] = sZ[:Nt_ma]\n    ma.x = ma.get_dofs()\n    return (curves, currents, ma)",
  "def get_w7x_data(Nt_coils=48, Nt_ma=10, ppp=2):\n    \"\"\"\n    Get the W7-X coils and magnetic axis.\n\n    Note that this function returns 7 coils: the 5 unique nonplanar\n    modular coils, and the 2 planar (A and B) coils. The coil currents\n    returned by this function correspond to the \"Standard\n    configuration\", in which the planar A and B coils carry no current.\n\n    The coils shapes here came from Fourier-transforming the xgrid\n    input file coils.w7x_v001, obtained from Joachim Geiger in an\n    email to Florian Wechsung and others on Sept 27, 2022.  With 96\n    quadrature points, the Fourier modes here reproduce the Cartesian\n    coordinate data from coils.w7x_v001 to ~ 1e-13 meters. Some\n    description from Joachim:\n\n    \"I have attached two coils-files which contain the filaments\n    suitable for generating the mgrid-file for VMEC with xgrid. They\n    contain the non-planar and the planar coils in a one-filament\n    approximation as used here for equilibrium calculations.  The two\n    coil-sets are slightly different with respect to the planar coils\n    (the non-planar coil geometry is the same), the w7x_v001 being the\n    CAD-coil-set while the w7x-set has slightly older planar coils\n    which I had used in a large number of calculations. The difference\n    is small, but, depending on what accuracy is needed, noticeable.\n    In case you want only one coil-set, I would suggest to use the\n    CAD-coils, i.e. w7x_v001, although the other coil-set had been\n    used in the PPCF-paper for citation.  If there are any further\n    questions, do not hesitate to contact me.\"\n\n    Args:\n        Nt_coils: order of the curves representing the coils.\n        Nt_ma: order of the curve representing the magnetic axis.\n        ppp: point-per-period: number of quadrature points per period.\n\n    Returns: 3 element tuple containing the coils, currents, and the magnetic axis.\n    \"\"\"\n    filename = THIS_DIR / \"W7-X.dat\"\n    curves = CurveXYZFourier.load_curves_from_file(filename, order=Nt_coils, ppp=ppp)\n    nfp = 5\n    amperes = 15000.0\n    # Non-planar coils have 108 turns. Planar coils have 36 turns.\n    turns = 108\n    currents = [Current(c) for c in [amperes * turns] * 5 + [0.0, 0.0]]\n    # The axis shape here is taken from a free-boundary VMEC\n    # calculation for the standard configuration at beta=0.\n    cR = [\n        5.56069066955626, 0.370739830964738, 0.0161526928867275, \n        0.0011820724983052, 3.43773868380292e-06, -4.71423775536881e-05, \n        -6.23133271265022e-05, 2.06622580616597e-06, -0.000113256675159501, \n        5.0296895894932e-07, 7.02308687052046e-05, 5.13479338167885e-05, \n        1.90731007856885e-05\n    ]\n    sZ = [\n        0, -0.308156954586225, -0.0186374002410851, \n        -0.000261743895528833, 5.78207516751575e-05, -0.000129121205314107, \n        3.08849630026052e-05, 1.95450172782866e-05, -8.32136392792337e-05, \n        6.19785500011441e-05, 1.36521157246782e-05, -1.46281683516623e-05, \n        -1.5142136543872e-06\n    ]\n\n    numpoints = Nt_ma * ppp+1 if ((Nt_ma * ppp) % 2 == 0) else Nt_ma * ppp\n    ma = CurveRZFourier(numpoints, Nt_ma, nfp, True)\n    ma.rc[:] = cR[0:(Nt_ma+1)]\n    ma.zs[:] = sZ[0:Nt_ma]\n    ma.x = ma.get_dofs()\n    return (curves, currents, ma)",
  "def _mpi_workers_task(mpi: MpiPartition,\n                      prob: Optimizable):\n    \"\"\"\n    This function is called by worker processes when\n    MpiPartition.workers_loop() receives a signal to do something.\n\n    Args:\n        mpi: A :obj:`simsopt.util.mpi.MpiPartition` object, storing\n          the information about how the pool of MPI processes is\n          divided into worker groups.\n        prob: Optimizable object\n        data: Integer with a value from 1 to 3\n    \"\"\"\n    logger.debug('mpi workers task')\n\n    # x is a buffer for receiving the state vector:\n    x = np.empty(prob.dof_size, dtype='d')\n    # If we make it here, we must be doing a fd_jac_par\n    # calculation, so receive the state vector: mpi4py has\n    # separate bcast and Bcast functions!!  comm.Bcast(x, root=0)\n    x = mpi.comm_groups.bcast(x, root=0)\n    logger.debug(f'worker loop worker x={x}')\n    prob.x = x\n\n    # We don't store or do anything with f() or jac(), because\n    # the group leader will handle that.\n    try:\n        prob.unweighted_residuals()\n    except:\n        logger.warning(\"Exception caught by worker during residual \"\n                       \"evaluation in worker loop\")\n        traceback.print_exc()",
  "def least_squares_mpi_solve(prob: LeastSquaresProblem,\n                            mpi: MpiPartition,\n                            grad: bool = False,\n                            abs_step: float = 1.0e-7,\n                            rel_step: float = 0.0,\n                            diff_method: str = \"forward\",\n                            **kwargs):\n    \"\"\"\n    Solve a nonlinear-least-squares minimization problem using\n    MPI. All MPI processes (including group leaders and workers)\n    should call this function.\n\n    Args:\n        prob: Optimizable object defining the objective function(s) and\n             parameter space.\n        mpi: A MpiPartition object, storing the information about how\n             the pool of MPI processes is divided into worker groups.\n        grad: Whether to use a gradient-based optimization algorithm, as\n             opposed to a gradient-free algorithm. If unspecified, a\n             a gradient-free algorithm\n             will be used by default. If you set ``grad=True``\n             finite-difference gradients will be used.\n        abs_step: Absolute step size for finite difference jac evaluation\n        rel_step: Relative step size for finite difference jac evaluation\n        diff_method: Differentiation strategy. Options are \"centered\", and\n             \"forward\". If ``centered``, centered finite differences will\n             be used. If ``forward``, one-sided finite differences will\n             be used. Else, error is raised.\n        kwargs: Any arguments to pass to\n                `scipy.optimize.least_squares <https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.least_squares.html>`_.\n                For instance, you can supply ``max_nfev=100`` to set\n                the maximum number of function evaluations (not counting\n                finite-difference gradient evaluations) to 100. Or, you\n                can supply ``method`` to choose the optimization algorithm.\n    \"\"\"\n    if MPI is None:\n        raise RuntimeError(\n            \"least_squares_mpi_solve requires the mpi4py package.\")\n    logger.info(\"Beginning solve.\")\n\n    x = np.copy(prob.x)  # For use in Bcast later.\n\n    objective_file = None\n    residuals_file = None\n    datalog_started = False\n    nevals = 0\n    start_time = time()\n\n    def _f_proc0(x):\n        \"\"\"\n        This function is used for least_squares_mpi_solve.  It is similar\n        to LeastSquaresProblem.f(), except this version is called only by\n        proc 0 while workers are in the worker loop.\n        \"\"\"\n        logger.debug(\"Entering _f_proc0\")\n        mpi.mobilize_workers(CALCULATE_F)\n        # Send workers the state vector:\n        mpi.comm_groups.bcast(x, root=0)\n        logger.debug(\"Past bcast in _f_proc0\")\n\n        try:\n            unweighted_residuals = prob.unweighted_residuals(x)\n            logger.debug(f\"unweighted residuals in _f_proc0:\\n {unweighted_residuals}\")\n            residuals = prob.residuals()\n            logger.debug(f\"residuals in _f_proc0:\\n {residuals}\")\n        except:\n            unweighted_residuals = np.full(prob.parent_return_fns_no, 1.0e12)\n            residuals = np.full(prob.parent_return_fns_no, 1.0e12)\n            logger.info(\"Exception caught during function evaluation.\")\n\n        objective_val = prob.objective()\n\n        nonlocal datalog_started, objective_file, residuals_file, nevals\n\n        # Since the number of terms is not known until the first\n        # evaluation of the objective function, we cannot write the\n        # header of the output file until this first evaluation is\n        # done.\n        if not datalog_started:\n            # Initialize log file\n            datalog_started = True\n            datestr = datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n            objective_file = open(f\"objective_{datestr}.dat\", 'w')\n            objective_file.write(f\"Problem type:\\nleast_squares\\nnparams:\\n{prob.dof_size}\\n\")\n            objective_file.write(\"function_evaluation,seconds\")\n\n            residuals_file = open(f\"residuals_{datestr}.dat\", 'w')\n            residuals_file.write(f\"Problem type:\\nleast_squares\\nnparams:\\n{prob.dof_size}\\n\")\n            residuals_file.write(\"function_evaluation,seconds\")\n\n            for j in range(prob.dof_size):\n                objective_file.write(f\",x({j})\")\n            objective_file.write(\",objective_function\\n\")\n\n            for j in range(prob.dof_size):\n                residuals_file.write(f\",x({j})\")\n            residuals_file.write(\",objective_function\")\n            for j in range(len(residuals)):\n                residuals_file.write(f\",F({j})\")\n            residuals_file.write(\"\\n\")\n\n        del_t = time() - start_time\n        objective_file.write(f\"{nevals:6d},{del_t:12.4e}\")\n        for xj in x:\n            objective_file.write(f\",{xj:24.16e}\")\n        objective_file.write(f\",{objective_val:24.16e}\\n\")\n        objective_file.flush()\n\n        residuals_file.write(f\"{nevals:6d},{del_t:12.4e}\")\n        for xj in x:\n            residuals_file.write(f\",{xj:24.16e}\")\n        residuals_file.write(f\",{objective_val:24.16e}\")\n        for fj in unweighted_residuals:\n            residuals_file.write(f\",{fj:24.16e}\")\n        residuals_file.write(\"\\n\")\n        residuals_file.flush()\n        nevals += 1\n        logger.debug(f\"residuals are {residuals}\")\n        return residuals\n\n    # For MPI finite difference gradient, get the worker and leader action from\n    # MPIFiniteDifference\n    if grad:\n        with MPIFiniteDifference(prob.residuals, mpi, abs_step=abs_step,\n                                 rel_step=rel_step, diff_method=diff_method) as fd:\n            if mpi.proc0_world:\n                # proc0_world does this block, running the optimization.\n                x0 = np.copy(prob.x)\n                logger.info(\"Using finite difference method implemented in \"\n                            \"SIMSOPT for evaluating gradient\")\n                result = least_squares(_f_proc0, x0, jac=fd.jac, verbose=2,\n                                       **kwargs)\n\n    else:\n        leaders_action = lambda mpi, data: None\n        workers_action = lambda mpi, data: _mpi_workers_task(mpi, prob)\n        # Send group leaders and workers into their respective loops:\n        mpi.apart(leaders_action, workers_action)\n\n        if mpi.proc0_world:\n            # proc0_world does this block, running the optimization.\n            x0 = np.copy(prob.x)\n            logger.info(\"Using derivative-free method\")\n            result = least_squares(_f_proc0, x0, verbose=2, **kwargs)\n\n        # Stop loops for workers and group leaders:\n        mpi.together()\n\n    if mpi.proc0_world:\n        x = result.x\n\n        objective_file.close()\n        residuals_file.close()\n\n    datalog_started = False\n    logger.info(\"Completed solve.\")\n\n    # Finally, make sure all procs get the optimal state vector.\n    mpi.comm_world.Bcast(x)\n    logger.debug(f'After Bcast, x={x}')\n    # Set Parameters to their values for the optimum\n    prob.x = x",
  "def _constrained_mpi_workers_task(mpi: MpiPartition,\n                                  prob: Optimizable,\n                                  data: int):\n    \"\"\"\n    This function is called by worker processes when\n    MpiPartition.workers_loop() receives a signal to do something.\n\n    Args:\n        mpi: A :obj:`simsopt.util.mpi.MpiPartition` object, storing\n          the information about how the pool of MPI processes is\n          divided into worker groups.\n        prob: Optimizable object\n        data: Integer with a value from 1 to 3\n    \"\"\"\n    logger.debug('mpi workers task')\n\n    # x is a buffer for receiving the state vector:\n    x = np.empty(prob.dof_size, dtype='d')\n    # If we make it here, we must be doing a fd_jac_par\n    # calculation, so receive the state vector: mpi4py has\n    # separate bcast and Bcast functions!!  comm.Bcast(x, root=0)\n    x = mpi.comm_groups.bcast(x, root=0)\n    logger.debug(f'worker loop worker x={x}')\n    prob.x = x\n\n    # We don't store or do anything with f() or jac(), because\n    # the group leader will handle that.\n    if data == CALCULATE_F:\n        try:\n            prob.objective()\n        except:\n            logger.warning(\"Exception caught by worker during objective\"\n                           \"evaluation in worker loop\")\n            traceback.print_exc()  # Print traceback\n    elif data == CALCULATE_NLC:\n        try:\n            prob.nonlinear_constraints()\n        except:\n            logger.warning(\"Exception caught by worker during constraint\"\n                           \"evaluation in worker loop\")\n            traceback.print_exc()",
  "def constrained_mpi_solve(prob: ConstrainedProblem,\n                          mpi: MpiPartition,\n                          grad: bool = False,\n                          abs_step: float = 1.0e-7,\n                          rel_step: float = 0.0,\n                          diff_method: str = \"forward\",\n                          opt_method: str = \"SLSQP\",\n                          options: dict = None):\n    r\"\"\"\n    Solve a constrained minimization problem using\n    MPI. All MPI processes (including group leaders and workers)\n    should call this function.\n\n    Args:\n        prob: :obj:`~simsopt.objectives.ConstrainedProblem` object defining the\n            objective function, parameter space, and constraints.\n        mpi: A MpiPartition object, storing the information about how\n            the pool of MPI processes is divided into worker groups.\n        grad: Whether to use a gradient-based optimization algorithm, as\n            opposed to a gradient-free algorithm. If unspecified, a\n            a gradient-free algorithm\n            will be used by default. If you set ``grad=True``\n            finite-difference gradients will be used.\n        abs_step: Absolute step size for finite difference jac evaluation\n        rel_step: Relative step size for finite difference jac evaluation\n        diff_method: Differentiation strategy. Options are ``\"centered\"`` and\n            ``\"forward\"``. If ``\"centered\"``, centered finite differences will\n            be used. If ``\"forward\"``, one-sided finite differences will\n            be used. For other values, an error is raised.\n        opt_method: Constrained solver to use: One of ``\"SLSQP\"``,\n            ``\"trust-constr\"``, or ``\"COBYLA\"``. Use ``\"COBYLA\"`` for\n            derivative-free optimization. See\n            `scipy.optimize.minimize <https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html#scipy.optimize.minimize>`_\n            for a description of the methods.\n        options: dict, ``options`` keyword which is passed to\n            `scipy.optimize.minimize <https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html#scipy.optimize.minimize>`_.\n    \"\"\"\n    if MPI is None:\n        raise RuntimeError(\n            \"cosntrained_mpi_solve requires the mpi4py package.\")\n    logger.info(\"Beginning solve.\")\n\n    x = np.copy(prob.x)  # For use in Bcast later.\n\n    objective_file = None\n    constraint_file = None\n    objective_datalog_started = False\n    constraint_datalog_started = False\n    n_objective_evals = 0\n    n_constraint_evals = 0\n    start_time = time()\n\n    def _f_proc0(x):\n        \"\"\"\n        This function is used for constrained_mpi_solve.  It is called only by\n        proc 0 while workers are in the worker loop.\n        \"\"\"\n        logger.debug(\"Entering _f_proc0\")\n        mpi.mobilize_workers(CALCULATE_F)\n        # Send workers the state vector:\n        mpi.comm_groups.bcast(x, root=0)\n        logger.debug(\"Past bcast in _f_proc0\")\n\n        try:\n            objective_val = prob.objective(x)\n            logger.debug(f\"objective in _f_proc0:\\n {objective_val}\")\n        except:\n            objective_val = prob.fail\n            logger.info(\"Exception caught during function evaluation.\")\n\n        nonlocal objective_datalog_started, objective_file, n_objective_evals\n\n        # Since the number of terms is not known until the first\n        # evaluation of the objective function, we cannot write the\n        # header of the output file until this first evaluation is\n        # done.\n        if not objective_datalog_started:\n            # Initialize log file\n            objective_datalog_started = True\n            datestr = datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n            objective_file = open(f\"objective_{datestr}.dat\", 'w')\n            objective_file.write(f\"Problem type:\\nconstrained\\nnparams:\\n{prob.dof_size}\\n\")\n            objective_file.write(\"function_evaluation,seconds\")\n\n            for j in range(prob.dof_size):\n                objective_file.write(f\",x({j})\")\n            objective_file.write(\",objective_function\\n\")\n\n        del_t = time() - start_time\n        objective_file.write(f\"{n_objective_evals:6d},{del_t:12.4e}\")\n        for xj in x:\n            objective_file.write(f\",{xj:24.16e}\")\n        objective_file.write(f\",{objective_val:24.16e}\\n\")\n        objective_file.flush()\n\n        n_objective_evals += 1\n        logger.debug(f\"objective is {objective_val}\")\n        return objective_val\n\n    # wrap the constraints for logging\n    def _nlc_proc0(x):\n        \"\"\"\n        This function is used for constrained_mpi_solve.  It is called only by\n        proc 0 while workers are in the worker loop.\n        \"\"\"\n        logger.debug(\"Entering _nlc_proc0\")\n        mpi.mobilize_workers(CALCULATE_NLC)\n        # Send workers the state vector:\n        mpi.comm_groups.bcast(x, root=0)\n        logger.debug(\"Past bcast in _nlc_proc0\")\n\n        try:\n            constraint_val = prob.nonlinear_constraints(x)\n            logger.debug(f\"constraints in _nlc_proc0:\\n {constraint_val}\")\n        except:\n            constraint_val = np.full(prob.nvals, 1.0e12)\n            logger.info(\"Exception caught during function evaluation.\")\n\n        nonlocal constraint_datalog_started, constraint_file, n_constraint_evals\n\n        # Since the number of terms is not known until the first\n        # evaluation of the objective function, we cannot write the\n        # header of the output file until this first evaluation is\n        # done.\n        if not constraint_datalog_started:\n            # Initialize log file\n            constraint_datalog_started = True\n            datestr = datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n            constraint_file = open(f\"constraint_{datestr}.dat\", 'w')\n            constraint_file.write(f\"Problem type:\\nconstrained\\nnparams:\\n{prob.dof_size}\\n\")\n            constraint_file.write(\"function_evaluation,seconds\")\n\n            for j in range(prob.dof_size):\n                constraint_file.write(f\",x({j})\")\n            constraint_file.write(\",constraint_function\\n\")\n            for j in range(len(constraint_val)):\n                constraint_file.write(f\",F({j})\")\n            constraint_file.write(\"\\n\")\n\n        del_t = time() - start_time\n        constraint_file.write(f\"{n_constraint_evals:6d},{del_t:12.4e}\")\n        for xj in x:\n            constraint_file.write(f\",{xj:24.16e}\")\n        for fj in constraint_val:\n            constraint_file.write(f\",{fj:24.16e}\")\n        constraint_file.write(\"\\n\")\n        constraint_file.flush()\n\n        n_constraint_evals += 1\n        logger.debug(f\"constraints are {constraint_val}\")\n        return constraint_val\n\n    # prepare bounds\n    bounds = list(zip(*prob.bounds))\n\n    # prepare linear constraints\n    constraints = []\n    if prob.has_lc:\n        constraints.append(LinearConstraint(prob.A_lc, lb=prob.l_lc, ub=prob.u_lc))\n\n    # For MPI finite difference gradient, get the worker and leader action from\n    # MPIFiniteDifference\n    if grad:\n        with MPIFiniteDifference(prob.all_funcs, mpi, abs_step=abs_step,\n                                 rel_step=rel_step, diff_method=diff_method) as fd:\n\n            def obj_jac(x):\n                # dummy wrapper for batch finite difference\n                return fd.jac(x)[0]\n\n            if mpi.proc0_world:\n                if prob.has_nlc:\n                    def nlc_jac(x):\n                        # dummy wrapper for batch finite difference\n                        return fd.jac(x)[1:]\n                    nlc = NonlinearConstraint(_nlc_proc0, lb=-np.inf, ub=0.0, jac=nlc_jac)\n                    constraints.append(nlc)\n\n                # proc0_world does this block, running the optimization.\n                x0 = np.copy(prob.x)\n                logger.info(\"Using finite difference method implemented in \"\n                            \"SIMSOPT for evaluating gradient\")\n                result = minimize(_f_proc0, x0, jac=obj_jac,\n                                  bounds=bounds, constraints=constraints,\n                                  method=opt_method, options=options)\n\n    else:\n\n        leaders_action = lambda mpi, data: None\n        workers_action = lambda mpi, data: _constrained_mpi_workers_task(mpi, prob, data)\n        # Send group leaders and workers into their respective loops:\n        mpi.apart(leaders_action, workers_action)\n\n        if mpi.proc0_world:\n            # proc0_world does this block, running the optimization.\n            if prob.has_nlc:\n                nlc = NonlinearConstraint(_nlc_proc0, lb=-np.inf, ub=0.0)\n                constraints.append(nlc)\n            x0 = np.copy(prob.x)\n            logger.info(\"Using derivative-free method\")\n            result = minimize(_f_proc0, x0,\n                              bounds=bounds, constraints=constraints,\n                              method=opt_method, options=options)\n\n        # Stop loops for workers and group leaders:\n        mpi.together()\n\n    if mpi.proc0_world:\n        x = result.x\n\n        objective_file.close()\n        if prob.has_nlc:\n            constraint_file.close()\n\n    datalog_started = False\n    logger.info(\"Completed solve.\")\n\n    # Finally, make sure all procs get the optimal state vector.\n    mpi.comm_world.Bcast(x)\n    logger.debug(f'After Bcast, x={x}')\n    # Set Parameters to their values for the optimum\n    prob.x = x",
  "def _f_proc0(x):\n        \"\"\"\n        This function is used for least_squares_mpi_solve.  It is similar\n        to LeastSquaresProblem.f(), except this version is called only by\n        proc 0 while workers are in the worker loop.\n        \"\"\"\n        logger.debug(\"Entering _f_proc0\")\n        mpi.mobilize_workers(CALCULATE_F)\n        # Send workers the state vector:\n        mpi.comm_groups.bcast(x, root=0)\n        logger.debug(\"Past bcast in _f_proc0\")\n\n        try:\n            unweighted_residuals = prob.unweighted_residuals(x)\n            logger.debug(f\"unweighted residuals in _f_proc0:\\n {unweighted_residuals}\")\n            residuals = prob.residuals()\n            logger.debug(f\"residuals in _f_proc0:\\n {residuals}\")\n        except:\n            unweighted_residuals = np.full(prob.parent_return_fns_no, 1.0e12)\n            residuals = np.full(prob.parent_return_fns_no, 1.0e12)\n            logger.info(\"Exception caught during function evaluation.\")\n\n        objective_val = prob.objective()\n\n        nonlocal datalog_started, objective_file, residuals_file, nevals\n\n        # Since the number of terms is not known until the first\n        # evaluation of the objective function, we cannot write the\n        # header of the output file until this first evaluation is\n        # done.\n        if not datalog_started:\n            # Initialize log file\n            datalog_started = True\n            datestr = datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n            objective_file = open(f\"objective_{datestr}.dat\", 'w')\n            objective_file.write(f\"Problem type:\\nleast_squares\\nnparams:\\n{prob.dof_size}\\n\")\n            objective_file.write(\"function_evaluation,seconds\")\n\n            residuals_file = open(f\"residuals_{datestr}.dat\", 'w')\n            residuals_file.write(f\"Problem type:\\nleast_squares\\nnparams:\\n{prob.dof_size}\\n\")\n            residuals_file.write(\"function_evaluation,seconds\")\n\n            for j in range(prob.dof_size):\n                objective_file.write(f\",x({j})\")\n            objective_file.write(\",objective_function\\n\")\n\n            for j in range(prob.dof_size):\n                residuals_file.write(f\",x({j})\")\n            residuals_file.write(\",objective_function\")\n            for j in range(len(residuals)):\n                residuals_file.write(f\",F({j})\")\n            residuals_file.write(\"\\n\")\n\n        del_t = time() - start_time\n        objective_file.write(f\"{nevals:6d},{del_t:12.4e}\")\n        for xj in x:\n            objective_file.write(f\",{xj:24.16e}\")\n        objective_file.write(f\",{objective_val:24.16e}\\n\")\n        objective_file.flush()\n\n        residuals_file.write(f\"{nevals:6d},{del_t:12.4e}\")\n        for xj in x:\n            residuals_file.write(f\",{xj:24.16e}\")\n        residuals_file.write(f\",{objective_val:24.16e}\")\n        for fj in unweighted_residuals:\n            residuals_file.write(f\",{fj:24.16e}\")\n        residuals_file.write(\"\\n\")\n        residuals_file.flush()\n        nevals += 1\n        logger.debug(f\"residuals are {residuals}\")\n        return residuals",
  "def _f_proc0(x):\n        \"\"\"\n        This function is used for constrained_mpi_solve.  It is called only by\n        proc 0 while workers are in the worker loop.\n        \"\"\"\n        logger.debug(\"Entering _f_proc0\")\n        mpi.mobilize_workers(CALCULATE_F)\n        # Send workers the state vector:\n        mpi.comm_groups.bcast(x, root=0)\n        logger.debug(\"Past bcast in _f_proc0\")\n\n        try:\n            objective_val = prob.objective(x)\n            logger.debug(f\"objective in _f_proc0:\\n {objective_val}\")\n        except:\n            objective_val = prob.fail\n            logger.info(\"Exception caught during function evaluation.\")\n\n        nonlocal objective_datalog_started, objective_file, n_objective_evals\n\n        # Since the number of terms is not known until the first\n        # evaluation of the objective function, we cannot write the\n        # header of the output file until this first evaluation is\n        # done.\n        if not objective_datalog_started:\n            # Initialize log file\n            objective_datalog_started = True\n            datestr = datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n            objective_file = open(f\"objective_{datestr}.dat\", 'w')\n            objective_file.write(f\"Problem type:\\nconstrained\\nnparams:\\n{prob.dof_size}\\n\")\n            objective_file.write(\"function_evaluation,seconds\")\n\n            for j in range(prob.dof_size):\n                objective_file.write(f\",x({j})\")\n            objective_file.write(\",objective_function\\n\")\n\n        del_t = time() - start_time\n        objective_file.write(f\"{n_objective_evals:6d},{del_t:12.4e}\")\n        for xj in x:\n            objective_file.write(f\",{xj:24.16e}\")\n        objective_file.write(f\",{objective_val:24.16e}\\n\")\n        objective_file.flush()\n\n        n_objective_evals += 1\n        logger.debug(f\"objective is {objective_val}\")\n        return objective_val",
  "def _nlc_proc0(x):\n        \"\"\"\n        This function is used for constrained_mpi_solve.  It is called only by\n        proc 0 while workers are in the worker loop.\n        \"\"\"\n        logger.debug(\"Entering _nlc_proc0\")\n        mpi.mobilize_workers(CALCULATE_NLC)\n        # Send workers the state vector:\n        mpi.comm_groups.bcast(x, root=0)\n        logger.debug(\"Past bcast in _nlc_proc0\")\n\n        try:\n            constraint_val = prob.nonlinear_constraints(x)\n            logger.debug(f\"constraints in _nlc_proc0:\\n {constraint_val}\")\n        except:\n            constraint_val = np.full(prob.nvals, 1.0e12)\n            logger.info(\"Exception caught during function evaluation.\")\n\n        nonlocal constraint_datalog_started, constraint_file, n_constraint_evals\n\n        # Since the number of terms is not known until the first\n        # evaluation of the objective function, we cannot write the\n        # header of the output file until this first evaluation is\n        # done.\n        if not constraint_datalog_started:\n            # Initialize log file\n            constraint_datalog_started = True\n            datestr = datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n            constraint_file = open(f\"constraint_{datestr}.dat\", 'w')\n            constraint_file.write(f\"Problem type:\\nconstrained\\nnparams:\\n{prob.dof_size}\\n\")\n            constraint_file.write(\"function_evaluation,seconds\")\n\n            for j in range(prob.dof_size):\n                constraint_file.write(f\",x({j})\")\n            constraint_file.write(\",constraint_function\\n\")\n            for j in range(len(constraint_val)):\n                constraint_file.write(f\",F({j})\")\n            constraint_file.write(\"\\n\")\n\n        del_t = time() - start_time\n        constraint_file.write(f\"{n_constraint_evals:6d},{del_t:12.4e}\")\n        for xj in x:\n            constraint_file.write(f\",{xj:24.16e}\")\n        for fj in constraint_val:\n            constraint_file.write(f\",{fj:24.16e}\")\n        constraint_file.write(\"\\n\")\n        constraint_file.flush()\n\n        n_constraint_evals += 1\n        logger.debug(f\"constraints are {constraint_val}\")\n        return constraint_val",
  "def obj_jac(x):\n                # dummy wrapper for batch finite difference\n                return fd.jac(x)[0]",
  "def nlc_jac(x):\n                        # dummy wrapper for batch finite difference\n                        return fd.jac(x)[1:]",
  "def prox_l0(m: RealArray,\n            mmax: RealArray,\n            reg_l0: float,\n            nu: float):\n    r\"\"\"\n    Proximal operator for L0 regularization.\n\n    Note that the m values are normalized before hard\n    thresholding to avoid only truncating the magnets on the\n    inner side of the configuration (which are often important!).\n    Note also the in principle the hard threshold here should be:\n    :math:`hard\\_threshold = \\sqrt{2 * \\text{reg_l0} * \\nu}`. But we can always imagine\n    rescaling :math:`\\nu` (or reg_l0) such that :math:`hard\\_threshold = 2 * \\text{reg_l0} * \\nu`\n    instead (for instance :math:`\\nu -> 2 * \\nu^2` and :math:`\\text{reg_l0} -> \\text{reg_l0}^ 2)`.\n\n    Args:\n        m: The permanent magnet dipole vectors with shape (ndipoles, 3).\n        mmax: The maximal dipole strengths of each of the permanent magnets of shape (ndipoles,)\n        reg_l0: The amount of L0 regularization used in the problem.\n        nu: The strength of the \"relaxing\" term in the relax-and-split algorithm\n            used for permanent magnet optimization.\n    \"\"\"\n    ndipoles = len(m) // 3\n    mmax_vec = np.array([mmax, mmax, mmax]).T\n    m_normalized = (np.abs(m).reshape(ndipoles, 3) / mmax_vec).reshape(ndipoles * 3)\n    # in principle, hard threshold should be sqrt(2 * reg_l0 * nu) but can always renormalize everything\n    return m * (m_normalized > 2 * reg_l0 * nu)",
  "def prox_l1(m, mmax, reg_l1, nu):\n    \"\"\"\n    Proximal operator for L1 regularization.\n\n    Note that the m values are normalized before soft\n    thresholding to avoid only truncating the magnets on the\n    inner side of the configuration (which are often important!).\n\n    Args:\n        m: 2D numpy array, shape (ndipoles, 3)\n            The permanent magnet dipole vectors.\n        mmax: 1D numpy array, shape (ndipoles)\n            The maximal dipole strengths of each of the permanent magnets.\n        reg_l1: double\n            The amount of L1 regularization used in the problem.\n        nu: double\n            The strength of the \"relaxing\" term in the relax-and-split algorithm\n            used for permanent magnet optimization.\n    \"\"\"\n    ndipoles = len(m) // 3\n    mmax_vec = np.array([mmax, mmax, mmax]).T\n    m_normalized = (np.abs(m).reshape(ndipoles, 3) / mmax_vec).reshape(ndipoles * 3)\n    return np.sign(m) * np.maximum(np.abs(m_normalized) - reg_l1 * nu, 0) * np.ravel(mmax_vec)",
  "def projection_L2_balls(x, mmax):\n    \"\"\"\n    Project the vector x onto a series of L2 balls in R3.\n    Only used here for checking if the initial guess for the\n    permanent magnets is inside the feasible region\n    before optimization begins.\n\n    Args:\n        x: 1D numpy array, shape (ndipoles * 3)\n            The current solution vector for the dipole vectors of the magnets.\n        mmax: 1D numpy array, shape (ndipoles)\n            The maximal dipole strength of each of the magnets.\n    \"\"\"\n    N = len(x) // 3\n    x_shaped = x.reshape(N, 3)\n    denom_fac = np.sqrt(np.sum(x_shaped ** 2, axis=-1)) / mmax\n    denom = np.maximum(np.ones(len(denom_fac)), denom_fac)\n    return np.divide(x_shaped, np.array([denom, denom, denom]).T).reshape(3 * N)",
  "def setup_initial_condition(pm_opt, m0=None):\n    \"\"\"\n    If an initial guess for the dipole moments is specified,\n    checks the initial condition lies in the allowed hypersurface.\n    If an initial guess is not specified, defaults to initializing\n    the permanent magnet dipole moments to all zeros.\n\n    Args:\n        pm_opt: PermanentMagnetGrid class object\n            Permanent magnet grid for optimization.\n        m0: 1D numpy array, shape (ndipoles * 3)\n            Initial guess for the dipole vectors.\n    \"\"\"\n    # Initialize initial guess for the dipole strengths\n    if m0 is not None:\n        if len(m0) != pm_opt.ndipoles * 3:\n            raise ValueError(\n                'Initial dipole guess is incorrect shape --'\n                ' guess must be 1D with shape (ndipoles * 3).'\n            )\n        m0_temp = projection_L2_balls(m0, pm_opt.m_maxima)\n        # check if m0 lies inside the hypersurface spanned by\n        # L2 balls, which we require it does\n        if not np.allclose(m0, m0_temp):\n            raise ValueError(\n                'Initial dipole guess must contain values '\n                'that are satisfy the maximum bound constraints.'\n            )\n        pm_opt.m0 = m0",
  "def relax_and_split(pm_opt, m0=None, **kwargs):\n    \"\"\"\n    Uses a relax-and-split algorithm for solving the permanent\n    magnet optimization problem, which solves a convex and nonconvex\n    part separately.\n\n    Defaults to the MwPGP convex step and no\n    nonconvex step.  If a nonconvexity is specified, the associated\n    prox function must be defined in this file.  Relax-and-split\n    allows for speedy algorithms for both steps and the imposition of\n    convex equality and inequality constraints (including the required\n    constraint on the strengths of the dipole moments).\n\n    Args:\n        pm_opt: The grid of permanent magnets to optimize.\n        m0: Initial guess for the permanent magnet dipole moments. Defaults\n            to a starting guess of all zeros. This vector must lie in the\n            hypersurface spanned by the L2 ball constraints. Note that if\n            algorithm is being used properly, the end result should be\n            independent of the choice of initial condition.\n        kwargs: Keyword arguments to pass to the algorithm. The following\n            arguments can be passed to the MwPGP algorithm:\n\n            epsilon:\n                Error tolerance for the convex part of the algorithm (MwPGP).\n            nu:\n                Hyperparameter used for the relax-and-split\n                least-squares. Set nu >> 1 to reduce the\n                importance of nonconvexity in the problem.\n            reg_l0:\n                Regularization value for the L0 nonconvex term in the\n                optimization. This value is automatically scaled based on\n                the max dipole moment values, so that reg_l0 = 1 corresponds\n                to reg_l0 = np.max(m_maxima). It follows that users should\n                choose reg_l0 in [0, 1].\n            reg_l1:\n                Regularization value for the L1 nonsmooth term in the\n                optimization,\n            reg_l2:\n                Regularization value for any convex regularizers in the\n                optimization problem, such as the often-used L2 norm.\n            max_iter_MwPGP:\n                Maximum iterations to perform during a run of the convex\n                part of the relax-and-split algorithm (MwPGP).\n            max_iter_RS:\n                Maximum iterations to perform of the overall relax-and-split\n                algorithm. Therefore, also the number of times that MwPGP is\n                called, and the number of times a prox is computed.\n            verbose:\n                Prints out all the loss term errors separately.\n\n    Returns:\n        A tuple of optimization loss, solution at each step, and sparse solution.\n\n        The tuple contains\n\n        errors:\n            Total optimization loss after each convex sub-problem is solved.\n        m_history:\n            Solution for the permanent magnets after each convex\n            sub-problem is solved.\n        m_proxy_history:\n            Sparse solution for the permanent magnets after each convex\n            sub-problem is solved.\n\n    \"\"\"\n    # change to row-major order for the C++ code\n    A_obj = np.ascontiguousarray(pm_opt.A_obj)\n    ATb = np.ascontiguousarray(np.reshape(pm_opt.ATb, (pm_opt.ndipoles, 3)))\n\n    # print initial errors and values before optimization\n    pm_opt._print_initial_opt()\n\n    # Begin the various algorithms\n    errors = []\n    m_history = []\n    m_proxy_history = []\n\n    # get optimal alpha value for the MwPGP algorithm\n    alpha_max = 2.0 / pm_opt.ATA_scale\n    alpha_max = alpha_max * (1 - 1e-5)\n    convex_step = sopp.MwPGP_algorithm\n\n    # set the nonconvex step in the algorithm\n    reg_rs = 0.0\n    nu = kwargs.pop(\"nu\", 1e100)\n    reg_l0 = kwargs.pop(\"reg_l0\", 0.0)\n    reg_l1 = kwargs.pop(\"reg_l1\", 0.0)\n    max_iter_RS = kwargs.pop('max_iter_RS', 1)\n    epsilon_RS = kwargs.pop('epsilon_RS', 1e-3)\n\n    if (not np.isclose(reg_l0, 0.0, atol=1e-16)) and (not np.isclose(reg_l1, 0.0, atol=1e-16)):\n        raise ValueError(' L0 and L1 loss terms cannot be used concurrently.')\n    elif not np.isclose(reg_l0, 0.0, atol=1e-16):\n        prox = prox_l0\n        reg_rs = reg_l0\n    elif not np.isclose(reg_l1, 0.0, atol=1e-16):\n        prox = prox_l1\n        reg_rs = reg_l1\n\n    # Auxiliary variable in relax-and-split can be initialized\n    # to prox(m0), where m0 is the initial guess for m.\n    if m0 is not None:\n        setup_initial_condition(pm_opt, m0)\n    m0 = pm_opt.m0\n    m_proxy = pm_opt.m0\n    mmax = pm_opt.m_maxima\n    if reg_rs > 0.0:\n        m_proxy = prox(m_proxy, mmax, reg_rs, nu)\n    kwargs['alpha'] = alpha_max\n\n    # Begin optimization\n    if reg_rs > 0.0:\n        # Relax-and-split algorithm\n        m = pm_opt.m0\n        for i in range(max_iter_RS):\n            # update m with the CONVEX part of the algorithm\n            algorithm_history, _, _, m = convex_step(\n                A_obj=pm_opt.A_obj,\n                b_obj=pm_opt.b_obj,\n                ATb=ATb,\n                m_proxy=np.ascontiguousarray(m_proxy.reshape(pm_opt.ndipoles, 3)),\n                m0=np.ascontiguousarray(m.reshape(pm_opt.ndipoles, 3)),  # note updated m is new guess\n                m_maxima=mmax,\n                **kwargs\n            )\n            m_history.append(m)\n            m = np.ravel(m)\n            algorithm_history = algorithm_history[algorithm_history != 0]\n            errors.append(algorithm_history[-1])\n\n            # Solve the nonconvex optimization -- i.e. take a prox\n            m_proxy = prox(m, mmax, reg_rs, nu)\n            m_proxy_history.append(m_proxy)\n            if np.linalg.norm(m - m_proxy) < epsilon_RS:\n                print('Relax-and-split finished early, at iteration ', i)\n                break\n    else:\n        m0 = np.ascontiguousarray(m0.reshape(pm_opt.ndipoles, 3))\n        # no nonconvex terms being used, so just need one round of the\n        # convex algorithm called MwPGP\n        algorithm_history, _, m_history, m = convex_step(\n            A_obj=pm_opt.A_obj,\n            b_obj=pm_opt.b_obj,\n            ATb=ATb,\n            m_proxy=m0,\n            m0=m0,\n            m_maxima=mmax,\n            **kwargs\n        )\n        m = np.ravel(m)\n        m_proxy = m\n\n    # note m = m_proxy if not using relax-and-split (i.e. problem is convex)\n    pm_opt.m = m\n    pm_opt.m_proxy = m_proxy\n    return errors, m_history, m_proxy_history",
  "def GPMO(pm_opt, algorithm='baseline', **kwargs):\n    r\"\"\"\n    GPMO is a greedy algorithm for the permanent magnet optimization problem.\n\n    GPMO is an alternative to to the relax-and-split algorithm.\n    Full-strength magnets are placed one-by-one according to minimize the\n    MSE (fB). Allows for a number of keyword arguments that facilitate some\n    basic backtracking (error correction) and placing magnets together so no\n    isolated magnets occur.\n\n    Args:\n        pm_opt: The grid of permanent magnets to optimize.\n            PermanentMagnetGrid instance\n        algorithm:\n            The type of greedy algorithm to use. Options are\n\n            baseline:\n                the simple implementation of GPMO,\n            multi:\n                GPMO, but placing multiple magnets per iteration,\n            backtracking:\n                backtrack every few hundred iterations to improve the\n                solution,\n            ArbVec:\n                the simple implementation of GPMO, but with arbitrary\n                oriented polarization vectors,\n            ArbVec_backtracking:\n                same as above but w/ backtracking.\n\n            Easiest algorithm to use is 'baseline' but most effective \n            algorithm is 'ArbVec_backtracking'.\n        kwargs:\n            Keyword arguments for the GPMO algorithm and its variants.\n            The following variables can be passed:\n\n            K: integer\n                Maximum number of GPMO iterations to run.\n            nhistory: integer\n                Every 'nhistory' iterations, the loss terms are recorded.\n            Nadjacent: integer\n                Number of neighbor cells to consider 'adjacent' to one\n                another, for the purposes of placing multiple magnets or\n                doing backtracking. Not to be used with 'baseline' and 'ArbVec'.\n            dipole_grid_xyz: 2D numpy array, shape (ndipoles, 3).\n                XYZ coordinates of the permanent magnet locations. Needed for\n                figuring out which permanent magnets are adjacent to one another.\n                Not a keyword argument for 'baseline' and 'ArbVec'.\n            max_nMagnets: integer.\n                Maximum number of magnets to place before algorithm quits. Only\n                a keyword argument for 'backtracking' and 'ArbVec_backtracking'\n                since without any backtracking, this is the same parameter as 'K'.\n            backtracking: integer.\n                Every 'backtracking' iterations, a backtracking is performed to\n                remove suboptimal magnets. Only a keyword argument for\n                'backtracking' and 'ArbVec_backtracking' algorithms.\n            thresh_angle: float.\n                If the angle between adjacent dipole moments > thresh_angle,\n                these dipoles are considered suboptimal and liable to removed\n                during a backtracking step. Only a keyword argument for\n                'ArbVec_backtracking' algorithm.\n            single_direction: int, must be = 0, 1, or 2.\n                Specify to only place magnets with orientations in a single\n                direction, e.g. only magnets pointed in the +- x direction.\n                Keyword argument only for 'baseline', 'multi', and 'backtracking'\n                since the 'ArbVec...' algorithms have local coordinate systems\n                and therefore can specify the same constraint and much more\n                via the 'pol_vectors' argument.\n            reg_l2: float.\n                L2 regularization value, applied through the mmax argument in\n                the GPMO algorithm. See the paper for how this works.\n            verbose: bool.\n                If True, print out the algorithm progress every 'nhistory'\n                iterations. Also needed to record the algorithm history.\n\n    Returns:\n        Tuple of (errors, Bn_errors, m_history)\n\n        errors:\n            Total optimization loss values, recorded every 'nhistory'\n            iterations.\n        Bn_errors:\n            :math:`|Bn|` errors, recorded every 'nhistory' iterations.\n        m_history:\n            Solution for the permanent magnets, recorded after 'nhistory'\n            iterations.\n\n    \"\"\"\n    if not hasattr(pm_opt, \"A_obj\"):\n        raise ValueError(\"The PermanentMagnetClass needs to use geo_setup() or \"\n                         \"geo_setup_from_famus() before calling optimization routines.\")\n\n    # Begin the various algorithms\n    errors = []\n    m_history = []\n\n    # Need to normalize the m, so have\n    # || A * m - b||^2 = || ( A * mmax) * m / mmax - b||^2\n    mmax = pm_opt.m_maxima\n    contig = np.ascontiguousarray\n    mmax_vec = contig(np.array([mmax, mmax, mmax]).T.reshape(pm_opt.ndipoles * 3))\n    A_obj = pm_opt.A_obj * mmax_vec\n\n    if (algorithm != 'baseline' and algorithm != 'mutual_coherence' and algorithm != 'ArbVec') and 'dipole_grid_xyz' not in kwargs:\n        raise ValueError('GPMO variants require dipole_grid_xyz to be defined.')\n\n    # Set the L2 regularization if it is included in the kwargs \n    reg_l2 = kwargs.pop(\"reg_l2\", 0.0)\n\n    # check that algorithm can generate K binary dipoles\n    if \"K\" in kwargs:\n        if kwargs[\"K\"] > pm_opt.ndipoles:\n            warnings.warn(\n                'Parameter K to GPMO algorithm is greater than the total number of dipole locations '\n                ' so the algorithm will set K = the total number and proceed.')\n            kwargs[\"K\"] = pm_opt.ndipoles\n        print('Number of binary dipoles to use in GPMO algorithm = ', kwargs[\"K\"])\n\n    if \"nhistory\" in kwargs and \"K\" in kwargs:\n        if kwargs['nhistory'] > kwargs['K']:\n            raise ValueError('nhistory must be less than K for the GPMO algorithm.')\n\n    Nnorms = contig(np.ravel(np.sqrt(np.sum(pm_opt.plasma_boundary.normal() ** 2, axis=-1))))\n\n    # Note, only baseline method has the f_m loss term implemented! \n    if algorithm == 'baseline':  # GPMO\n        algorithm_history, Bn_history, m_history, m = sopp.GPMO_baseline(\n            A_obj=contig(A_obj.T),\n            b_obj=contig(pm_opt.b_obj),\n            mmax=np.sqrt(reg_l2)*mmax_vec,\n            normal_norms=Nnorms,\n            **kwargs\n        )\n    elif algorithm == 'ArbVec':  # GPMO with arbitrary polarization vectors\n        algorithm_history, Bn_history, m_history, m = sopp.GPMO_ArbVec(\n            A_obj=contig(A_obj.T),\n            b_obj=contig(pm_opt.b_obj),\n            mmax=np.sqrt(reg_l2)*mmax_vec,\n            normal_norms=Nnorms,\n            pol_vectors=contig(pm_opt.pol_vectors),\n            **kwargs\n        )\n    elif algorithm == 'backtracking':  # GPMOb\n        algorithm_history, Bn_history, m_history, num_nonzeros, m = sopp.GPMO_backtracking(\n            A_obj=contig(A_obj.T),\n            b_obj=contig(pm_opt.b_obj),\n            mmax=np.sqrt(reg_l2)*mmax_vec,\n            normal_norms=Nnorms,\n            **kwargs\n        )\n        pm_opt.num_nonzeros = num_nonzeros[num_nonzeros != 0]\n    elif algorithm == 'ArbVec_backtracking':  # GPMOb with arbitrary vectors\n        if pm_opt.coordinate_flag != 'cartesian':\n            raise ValueError('ArbVec_backtracking algorithm currently ' \\\n                             'only supports dipole grids with \\n'\n                             'moment vectors in the Cartesian basis.')\n        algorithm_history, Bn_history, m_history, num_nonzeros, m = sopp.GPMO_ArbVec_backtracking(\n            A_obj=contig(A_obj.T),\n            b_obj=contig(pm_opt.b_obj),\n            mmax=np.sqrt(reg_l2)*mmax_vec,\n            normal_norms=Nnorms,\n            pol_vectors=contig(pm_opt.pol_vectors),\n            **kwargs\n        )\n    elif algorithm == 'multi':  # GPMOm\n        algorithm_history, Bn_history, m_history, m = sopp.GPMO_multi(\n            A_obj=contig(A_obj.T),\n            b_obj=contig(pm_opt.b_obj),\n            mmax=np.sqrt(reg_l2)*mmax_vec,\n            normal_norms=Nnorms,\n            **kwargs\n        )\n    else:\n        raise NotImplementedError('Requested algorithm variant is incorrect or not yet implemented')\n\n    # rescale m and m_history\n    m = m * (mmax_vec.reshape(pm_opt.ndipoles, 3))\n    print('Number of binary dipoles returned by GPMO algorithm = ',\n          np.count_nonzero(np.sum(m, axis=-1)))\n\n    # rescale the m that have been saved every Nhistory iterations\n    for i in range(m_history.shape[-1]):\n        m_history[:, :, i] = m_history[:, :, i] * (mmax_vec.reshape(pm_opt.ndipoles, 3))\n    errors = algorithm_history[algorithm_history != 0]\n    Bn_errors = Bn_history[Bn_history != 0]\n\n    # note m = m_proxy for GPMO because this is not using relax-and-split\n    pm_opt.m = np.ravel(m)\n    pm_opt.m_proxy = pm_opt.m\n    return errors, Bn_errors, m_history",
  "def least_squares_serial_solve(prob: LeastSquaresProblem,\n                               grad: bool = None,\n                               abs_step: float = 1.0e-7,\n                               rel_step: float = 0.0,\n                               diff_method: str = \"forward\",\n                               **kwargs):\n    \"\"\"\n    Solve a nonlinear-least-squares minimization problem using\n    scipy.optimize, and without using any parallelization.\n\n    Args:\n        prob: LeastSquaresProblem object defining the objective function(s)\n             and parameter space.\n        grad: Whether to use a gradient-based optimization algorithm, as\n             opposed to a gradient-free algorithm. If unspecified, a\n             a gradient-free algorithm\n             will be used by default. If you set ``grad=True`` for a problem,\n             finite-difference gradients will be used.\n        abs_step: Absolute step size for finite difference jac evaluation\n        rel_step: Relative step size for finite difference jac evaluation\n        diff_method: Differentiation strategy. Options are ``\"centered\"``, and\n             ``\"forward\"``. If ``\"centered\"``, centered finite differences will\n             be used. If ``\"forward\"``, one-sided finite differences will\n             be used. Else, error is raised.\n        kwargs: Any arguments to pass to\n                `scipy.optimize.least_squares <https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.least_squares.html>`_.\n                For instance, you can supply ``max_nfev=100`` to set\n                the maximum number of function evaluations (not counting\n                finite-difference gradient evaluations) to 100. Or, you\n                can supply ``method`` to choose the optimization algorithm.\n    \"\"\"\n\n    datestr = datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n    objective_file = open(f\"simsopt_{datestr}.dat\", 'w')\n    residuals_file = open(f\"residuals_{datestr}.dat\", 'w')\n\n    nevals = 0\n    start_time = time()\n    datalogging_started = False\n\n    def objective(x):\n        nonlocal datalogging_started, objective_file, residuals_file, nevals\n        #success = True\n        try:\n            residuals = prob.residuals(x)\n        except:\n            logger.info(\"Exception caught during function evaluation\")\n            residuals = np.full(prob.parent_return_fns_no, 1.0e12)\n            #success = False\n\n        objective_val = prob.objective()\n\n        # Check that 2 ways of computing the objective give same\n        # answer within roundoff:\n        #if success:\n        #    objective2 = prob.objective()\n        #    logger.info(\"objective_from_f={} objective={} diff={}\".format(\n        #        objective_val, objective2, objective_val - objective2))\n        #    abs_diff = np.abs(objective_val - objective2)\n        #    rel_diff = abs_diff / (1e-12 + np.abs(objective_val + objective2))\n        #    assert (abs_diff < 1e-12) or (rel_diff < 1e-12)\n\n        # Since the number of terms is not known until the first\n        # evaluation of the objective function, we cannot write the\n        # header of the output file until this first evaluation is\n        # done.\n        if not datalogging_started:\n            # Initialize log file\n            datalogging_started = True\n            ndofs = prob.dof_size\n            objective_file.write(\n                f\"Problem type:\\nleast_squares\\nnparams:\\n{ndofs}\\n\")\n            objective_file.write(\"function_evaluation,seconds\")\n            for j in range(ndofs):\n                objective_file.write(f\",x({j})\")\n            objective_file.write(\",objective_function\\n\")\n\n            residuals_file.write(\n                f\"Problem type:\\nleast_squares\\nnparams:\\n{ndofs}\\n\")\n            residuals_file.write(\"function_evaluation,seconds\")\n            for j in range(ndofs):\n                residuals_file.write(f\",x({j})\")\n            residuals_file.write(\",objective_function\")\n            for j in range(len(residuals)):\n                residuals_file.write(f\",F({j})\")\n            residuals_file.write(\"\\n\")\n\n        elapsed_t = time() - start_time\n        objective_file.write(f\"{nevals:6d},{elapsed_t:12.4e}\")\n        for xj in x:\n            objective_file.write(f\",{xj:24.16e}\")\n        objective_file.write(f\",{objective_val:24.16e}\")\n        objective_file.write(\"\\n\")\n        objective_file.flush()\n\n        residuals_file.write(f\"{nevals:6d},{elapsed_t:12.4e}\")\n        for xj in x:\n            residuals_file.write(f\",{xj:24.16e}\")\n        residuals_file.write(f\",{objective_val:24.16e}\")\n        for fj in residuals:\n            residuals_file.write(f\",{fj:24.16e}\")\n        residuals_file.write(\"\\n\")\n        residuals_file.flush()\n\n        nevals += 1\n        return residuals\n\n    logger.info(\"Beginning solve.\")\n    #if grad is None:\n    #    grad = prob.dofs.grad_avail\n\n    #if not 'verbose' in kwargs:\n\n    print('prob is ', prob)\n    x0 = np.copy(prob.x)\n    if grad:\n        fd = FiniteDifference(prob.residuals, abs_step=abs_step,\n                              rel_step=rel_step, diff_method=diff_method)\n        logger.info(\"Using derivatives\")\n        result = least_squares(objective, x0, verbose=2, jac=fd.jac, **kwargs)\n    else:\n        logger.info(\"Using derivative-free method\")\n        result = least_squares(objective, x0, verbose=2, **kwargs)\n\n    datalogging_started = False\n    objective_file.close()\n    residuals_file.close()\n    logger.info(\"Completed solve.\")\n\n    prob.x = result.x",
  "def serial_solve(prob: Union[Optimizable, Callable],\n                 grad: bool = None,\n                 abs_step: float = 1.0e-7,\n                 rel_step: float = 0.0,\n                 diff_method: str = \"centered\",\n                 **kwargs):\n    \"\"\"\n    Solve a general minimization problem (i.e. one that need not be of\n    least-squares form) using scipy.optimize.minimize, and without using any\n    parallelization.\n\n    Args:\n        prob: Optimizable object defining the objective function(s)\n             and parameter space.\n        grad: Whether to use a gradient-based optimization algorithm, as\n             opposed to a gradient-free algorithm. If unspecified, a\n             gradient-based algorithm will be used if ``prob`` has gradient\n             information available, otherwise a gradient-free algorithm\n             will be used by default. If you set ``grad=True``\n             in which gradient information is not available,\n             finite-difference gradients will be used.\n        abs_step: Absolute step size for finite difference jac evaluation\n        rel_step: Relative step size for finite difference jac evaluation\n        diff_method: Differentiation strategy. Options are ``\"centered\"``, and\n             ``\"forward\"``. If ``\"centered\"``, centered finite differences will\n             be used. If ``\"forward\"``, one-sided finite differences will\n             be used. Else, error is raised.\n        kwargs: Any arguments to pass to\n                `scipy.optimize.least_squares <https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.least_squares.html>`_.\n                For instance, you can supply ``max_nfev=100`` to set\n                the maximum number of function evaluations (not counting\n                finite-difference gradient evaluations) to 100. Or, you\n                can supply ``method`` to choose the optimization algorithm.\n    \"\"\"\n\n    filename = \"simsopt_\" + datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\") \\\n               + \".dat\"\n    with open(filename, 'w') as objective_file:\n        datalogging_started = False\n        nevals = 0\n        start_time = time()\n\n        def objective(x):\n            nonlocal datalogging_started, objective_file, nevals\n            try:\n                result = prob(x)\n            except:\n                result = 1e+12\n\n            # Since the number of terms is not known until the first\n            # evaluation of the objective function, we cannot write the\n            # header of the output file until this first evaluation is\n            # done.\n            if not datalogging_started:\n                # Initialize log file\n                datalogging_started = True\n                objective_file.write(\n                    f\"Problem type:\\ngeneral\\nnparams:\\n{prob.dof_size}\\n\")\n                objective_file.write(\"function_evaluation,seconds\")\n                for j in range(prob.dof_size):\n                    objective_file.write(f\",x({j})\")\n                objective_file.write(\",objective_function\")\n                objective_file.write(\"\\n\")\n\n            del_t = time() - start_time\n            objective_file.write(f\"{nevals:6d},{del_t:12.4e}\")\n            for xj in x:\n                objective_file.write(f\",{xj:24.16e}\")\n            # objective_file.write(f\",{result:24.16e}\")\n            objective_file.write(f\",{result}\")\n            objective_file.write(\"\\n\")\n            objective_file.flush()\n\n            nevals += 1\n            return result\n\n        # Need to fix up this next line for non-least-squares problems:\n        #if grad is None:\n        #    grad = prob.dofs.grad_avail\n\n        #if not 'verbose' in kwargs:\n\n        logger.info(\"Beginning solve.\")\n        x0 = np.copy(prob.x)\n        if grad:\n            raise RuntimeError(\"Need to convert least-squares Jacobian to \"\n                               \"gradient of the scalar objective function\")\n            logger.info(\"Using derivatives\")\n            fd = FiniteDifference(prob, abs_step=abs_step,\n                                  rel_step=rel_step, diff_method=diff_method)\n            result = least_squares(objective, x0, verbose=2, jac=fd.jac,\n                                   **kwargs)\n        else:\n            logger.info(\"Using derivative-free method\")\n            result = minimize(objective, x0, options={'disp': True}, **kwargs)\n\n        datalogging_started = False\n        logger.info(\"Completed solve.\")\n\n    prob.x = result.x",
  "def constrained_serial_solve(prob: ConstrainedProblem,\n                             grad: bool = None,\n                             abs_step: float = 1.0e-7,\n                             rel_step: float = 0.0,\n                             diff_method: str = \"forward\",\n                             opt_method: str = \"SLSQP\",\n                             options: dict = None):\n    \"\"\"\n    Solve a constrained minimization problem using\n    scipy.optimize, and without using any parallelization.\n\n    Args:\n        prob: :obj:`~simsopt.objectives.ConstrainedProblem` object defining the\n            objective function, parameter space, and constraints.\n        grad: Whether to use a gradient-based optimization algorithm, as\n            opposed to a gradient-free algorithm. If unspecified, a\n            a gradient-free algorithm\n            will be used by default. If you set ``grad=True`` for a problem,\n            finite-difference gradients will be used.\n        abs_step: Absolute step size for finite difference jac evaluation\n        rel_step: Relative step size for finite difference jac evaluation\n        diff_method: Differentiation strategy. Options are ``\"centered\"`` and\n            ``\"forward\"``. If ``\"centered\"``, centered finite differences will\n            be used. If ``\"forward\"``, one-sided finite differences will\n            be used. For other settings, an error is raised.\n        opt_method: Constrained solver to use: One of ``\"SLSQP\"``,\n            ``\"trust-constr\"``, or ``\"COBYLA\"``. Use ``\"COBYLA\"`` for\n            derivative-free optimization. See\n            `scipy.optimize.minimize <https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html#scipy.optimize.minimize>`_\n            for a description of the methods.\n        options: dict, ``options`` keyword which is passed to\n            `scipy.optimize.minimize <https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html#scipy.optimize.minimize>`_.\n    \"\"\"\n\n    datestr = datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n    objective_file = open(f\"simsopt_{datestr}.dat\", 'w')\n    constraint_file = open(f\"constraints_{datestr}.dat\", 'w')\n\n    objective_datalog_started = False\n    constraint_datalog_started = False\n    n_objective_evals = 0\n    n_constraint_evals = 0\n    start_time = time()\n\n    def _obj(x):\n        nonlocal objective_datalog_started, objective_file, n_objective_evals\n        try:\n            objective_val = prob.objective(x)\n        except:\n            logger.info(\"Exception caught during objective evaluation\")\n            objective_val = prob.fail\n\n        # Since the number of terms is not known until the first\n        # evaluation of the objective function, we cannot write the\n        # header of the output file until this first evaluation is\n        # done.\n        if not objective_datalog_started:\n            # Initialize log file\n            objective_datalog_started = True\n            ndofs = prob.dof_size\n            objective_file.write(\n                f\"Problem type:\\nconstrained\\nnparams:\\n{ndofs}\\n\")\n            objective_file.write(\"function_evaluation,seconds\")\n            for j in range(ndofs):\n                objective_file.write(f\",x({j})\")\n            objective_file.write(\",objective_function\\n\")\n\n        elapsed_t = time() - start_time\n        objective_file.write(f\"{n_objective_evals:6d},{elapsed_t:12.4e}\")\n        for xj in x:\n            objective_file.write(f\",{xj:24.16e}\")\n        objective_file.write(f\",{objective_val:24.16e}\")\n        objective_file.write(\"\\n\")\n        objective_file.flush()\n\n        n_objective_evals += 1\n        return objective_val\n\n    def _nlc(x):\n        nonlocal constraint_datalog_started, constraint_file, n_constraint_evals\n        try:\n            constraint_val = prob.nonlinear_constraints(x)\n        except:\n            logger.info(\"Exception caught during objective evaluation\")\n            constraint_val = np.full(prob.nvals, prob.fail)\n\n        # Since the number of terms is not known until the first\n        # evaluation of the objective function, we cannot write the\n        # header of the output file until this first evaluation is\n        # done.\n        if not constraint_datalog_started:\n            # Initialize log file\n            constraint_datalog_started = True\n            ndofs = prob.dof_size\n            constraint_file.write(\n                f\"Problem type:\\nconstrained\\nnparams:\\n{ndofs}\\n\")\n            constraint_file.write(\"function_evaluation,seconds\")\n            for j in range(ndofs):\n                constraint_file.write(f\",x({j})\")\n            constraint_file.write(\",constraint_function\\n\")\n            for j in range(len(constraint_val)):\n                constraint_file.write(f\",F({j})\")\n            constraint_file.write(\"\\n\")\n\n        elapsed_t = time() - start_time\n        constraint_file.write(f\"{n_constraint_evals:6d},{elapsed_t:12.4e}\")\n        for xj in x:\n            constraint_file.write(f\",{xj:24.16e}\")\n        for fj in constraint_val:\n            constraint_file.write(f\",{fj:24.16e}\")\n        constraint_file.write(\"\\n\")\n        constraint_file.flush()\n\n        n_constraint_evals += 1\n        return constraint_val\n\n    # prepare linear constraints\n    constraints = []\n    if prob.has_lc:\n        constraints.append(LinearConstraint(prob.A_lc, lb=prob.l_lc, ub=prob.u_lc))\n\n    # prepare bounds\n    bounds = list(zip(*prob.bounds))\n\n    logger.info(\"Beginning solve.\")\n\n    x0 = np.copy(prob.x)\n    if grad:\n        logger.info(\"Using finite-difference derivatives\")\n        fd_obj = FiniteDifference(prob.objective, abs_step=abs_step,\n                                  rel_step=rel_step, diff_method=diff_method)\n        if prob.has_nlc:\n            fd_nlc = FiniteDifference(prob.nonlinear_constraints, abs_step=abs_step,\n                                      rel_step=rel_step, diff_method=diff_method)\n            nlc = NonlinearConstraint(_nlc, lb=-np.inf, ub=0.0, jac=fd_nlc.jac)\n            constraints.append(nlc)\n        # optimize\n        result = minimize(_obj, x0, jac=fd_obj,\n                          bounds=bounds, constraints=constraints,\n                          method=opt_method, options=options)\n    else:\n        logger.info(\"Using derivative-free method\")\n        if prob.has_nlc:\n            nlc = NonlinearConstraint(_nlc, lb=-np.inf, ub=0.0)\n            constraints.append(nlc)\n        # optimize\n        result = minimize(_obj, x0,\n                          bounds=bounds, constraints=constraints,\n                          method=opt_method, options=options)\n\n    objective_datalog_started = False\n    constraint_datalog_started = False\n    objective_file.close()\n    constraint_file.close()\n    logger.info(\"Completed solve.\")\n\n    prob.x = result.x",
  "def objective(x):\n        nonlocal datalogging_started, objective_file, residuals_file, nevals\n        #success = True\n        try:\n            residuals = prob.residuals(x)\n        except:\n            logger.info(\"Exception caught during function evaluation\")\n            residuals = np.full(prob.parent_return_fns_no, 1.0e12)\n            #success = False\n\n        objective_val = prob.objective()\n\n        # Check that 2 ways of computing the objective give same\n        # answer within roundoff:\n        #if success:\n        #    objective2 = prob.objective()\n        #    logger.info(\"objective_from_f={} objective={} diff={}\".format(\n        #        objective_val, objective2, objective_val - objective2))\n        #    abs_diff = np.abs(objective_val - objective2)\n        #    rel_diff = abs_diff / (1e-12 + np.abs(objective_val + objective2))\n        #    assert (abs_diff < 1e-12) or (rel_diff < 1e-12)\n\n        # Since the number of terms is not known until the first\n        # evaluation of the objective function, we cannot write the\n        # header of the output file until this first evaluation is\n        # done.\n        if not datalogging_started:\n            # Initialize log file\n            datalogging_started = True\n            ndofs = prob.dof_size\n            objective_file.write(\n                f\"Problem type:\\nleast_squares\\nnparams:\\n{ndofs}\\n\")\n            objective_file.write(\"function_evaluation,seconds\")\n            for j in range(ndofs):\n                objective_file.write(f\",x({j})\")\n            objective_file.write(\",objective_function\\n\")\n\n            residuals_file.write(\n                f\"Problem type:\\nleast_squares\\nnparams:\\n{ndofs}\\n\")\n            residuals_file.write(\"function_evaluation,seconds\")\n            for j in range(ndofs):\n                residuals_file.write(f\",x({j})\")\n            residuals_file.write(\",objective_function\")\n            for j in range(len(residuals)):\n                residuals_file.write(f\",F({j})\")\n            residuals_file.write(\"\\n\")\n\n        elapsed_t = time() - start_time\n        objective_file.write(f\"{nevals:6d},{elapsed_t:12.4e}\")\n        for xj in x:\n            objective_file.write(f\",{xj:24.16e}\")\n        objective_file.write(f\",{objective_val:24.16e}\")\n        objective_file.write(\"\\n\")\n        objective_file.flush()\n\n        residuals_file.write(f\"{nevals:6d},{elapsed_t:12.4e}\")\n        for xj in x:\n            residuals_file.write(f\",{xj:24.16e}\")\n        residuals_file.write(f\",{objective_val:24.16e}\")\n        for fj in residuals:\n            residuals_file.write(f\",{fj:24.16e}\")\n        residuals_file.write(\"\\n\")\n        residuals_file.flush()\n\n        nevals += 1\n        return residuals",
  "def _obj(x):\n        nonlocal objective_datalog_started, objective_file, n_objective_evals\n        try:\n            objective_val = prob.objective(x)\n        except:\n            logger.info(\"Exception caught during objective evaluation\")\n            objective_val = prob.fail\n\n        # Since the number of terms is not known until the first\n        # evaluation of the objective function, we cannot write the\n        # header of the output file until this first evaluation is\n        # done.\n        if not objective_datalog_started:\n            # Initialize log file\n            objective_datalog_started = True\n            ndofs = prob.dof_size\n            objective_file.write(\n                f\"Problem type:\\nconstrained\\nnparams:\\n{ndofs}\\n\")\n            objective_file.write(\"function_evaluation,seconds\")\n            for j in range(ndofs):\n                objective_file.write(f\",x({j})\")\n            objective_file.write(\",objective_function\\n\")\n\n        elapsed_t = time() - start_time\n        objective_file.write(f\"{n_objective_evals:6d},{elapsed_t:12.4e}\")\n        for xj in x:\n            objective_file.write(f\",{xj:24.16e}\")\n        objective_file.write(f\",{objective_val:24.16e}\")\n        objective_file.write(\"\\n\")\n        objective_file.flush()\n\n        n_objective_evals += 1\n        return objective_val",
  "def _nlc(x):\n        nonlocal constraint_datalog_started, constraint_file, n_constraint_evals\n        try:\n            constraint_val = prob.nonlinear_constraints(x)\n        except:\n            logger.info(\"Exception caught during objective evaluation\")\n            constraint_val = np.full(prob.nvals, prob.fail)\n\n        # Since the number of terms is not known until the first\n        # evaluation of the objective function, we cannot write the\n        # header of the output file until this first evaluation is\n        # done.\n        if not constraint_datalog_started:\n            # Initialize log file\n            constraint_datalog_started = True\n            ndofs = prob.dof_size\n            constraint_file.write(\n                f\"Problem type:\\nconstrained\\nnparams:\\n{ndofs}\\n\")\n            constraint_file.write(\"function_evaluation,seconds\")\n            for j in range(ndofs):\n                constraint_file.write(f\",x({j})\")\n            constraint_file.write(\",constraint_function\\n\")\n            for j in range(len(constraint_val)):\n                constraint_file.write(f\",F({j})\")\n            constraint_file.write(\"\\n\")\n\n        elapsed_t = time() - start_time\n        constraint_file.write(f\"{n_constraint_evals:6d},{elapsed_t:12.4e}\")\n        for xj in x:\n            constraint_file.write(f\",{xj:24.16e}\")\n        for fj in constraint_val:\n            constraint_file.write(f\",{fj:24.16e}\")\n        constraint_file.write(\"\\n\")\n        constraint_file.flush()\n\n        n_constraint_evals += 1\n        return constraint_val",
  "def objective(x):\n            nonlocal datalogging_started, objective_file, nevals\n            try:\n                result = prob(x)\n            except:\n                result = 1e+12\n\n            # Since the number of terms is not known until the first\n            # evaluation of the objective function, we cannot write the\n            # header of the output file until this first evaluation is\n            # done.\n            if not datalogging_started:\n                # Initialize log file\n                datalogging_started = True\n                objective_file.write(\n                    f\"Problem type:\\ngeneral\\nnparams:\\n{prob.dof_size}\\n\")\n                objective_file.write(\"function_evaluation,seconds\")\n                for j in range(prob.dof_size):\n                    objective_file.write(f\",x({j})\")\n                objective_file.write(\",objective_function\")\n                objective_file.write(\"\\n\")\n\n            del_t = time() - start_time\n            objective_file.write(f\"{nevals:6d},{del_t:12.4e}\")\n            for xj in x:\n                objective_file.write(f\",{xj:24.16e}\")\n            # objective_file.write(f\",{result:24.16e}\")\n            objective_file.write(f\",{result}\")\n            objective_file.write(\"\\n\")\n            objective_file.flush()\n\n            nevals += 1\n            return result",
  "class FocusPlasmaBnormal(object):\n\n    def __init__(self, fname):\n\n        with open(fname, 'r') as f:\n            lines = f.readlines()\n\n        # Read numbers of modes and nfp from the header\n        position = FOCUS_PLASMAFILE_NHEADER_TOP\n        splitline = lines[position].split()\n        errmsg = \"This does not appear to be a FOCUS-format \" \\\n                 + \"plasma boundary file\"\n        assert len(splitline) == 3, errmsg\n\n        Nfou = int(splitline[0])\n        nfp = int(splitline[1])\n        NfouBn = int(splitline[2])\n\n        # Read Fourier harmonics of the normal field on the plasma boundary\n        position = position + 1 + FOCUS_PLASMAFILE_NHEADER_BDRY + Nfou + \\\n            FOCUS_PLASMAFILE_NHEADER_BNORM\n\n        self.n = np.zeros(NfouBn)\n        self.m = np.zeros(NfouBn)\n        self.bnc = np.zeros(NfouBn)\n        self.bns = np.zeros(NfouBn)\n        for i in range(NfouBn):\n            splitline = lines[position + i].split()\n            self.n[i] = int(splitline[0])\n            self.m[i] = int(splitline[1])\n            self.bnc[i] = float(splitline[2])\n            self.bns[i] = float(splitline[3])\n        assert np.min(self.m) == 0\n\n        self.nfp = nfp\n        self.NfouBn = NfouBn\n        self.stellsym = np.max(np.abs(self.bnc)) == 0\n\n    def bnormal_grid(self, nphi, ntheta, range):\n        '''\n        Calculates the normal component of the magnetic field on a\n        regularly-spaced 2D grid of points on the surface with a specified\n        resolution.\n\n        Parameters\n        ----------\n          nphi: int\n            Number of grid points in the toroidal dimension per field period.\n          ntheta: int\n            Number of grid points in the poloidal dimension.\n          range: str\n            Extent of the grid in the toroidal dimension. Choices include\n            `half period`, `field period`, or `full torus`.\n\n        Returns\n        -------\n          bnormal: 2D array\n            Normal component of the magnetic field evaluated at each of the\n            grid points.\n        '''\n        # Determine the theta and phi points using Simsopt Surface class methods\n        phi = Surface.get_phi_quadpoints(nphi=nphi, range=range, nfp=self.nfp)\n        theta = Surface.get_theta_quadpoints(ntheta=ntheta)\n        # Rescale the angles\n        phi = 2.*np.pi*np.array(phi)\n        theta = 2.*np.pi*np.array(theta)\n\n        # Prepare 3D arrays with mode numbers and coefficients\n        Theta, Phi, Mode = np.meshgrid(theta, phi, np.arange(0, self.NfouBn))\n        M = self.m[Mode]\n        N = self.n[Mode]\n        BNS = self.bns[Mode]\n        if not self.stellsym:\n            BNC = self.bnc[Mode]\n\n        # Calculate the values of each mode at each grid point\n        SinGrid = BNS*np.sin(M*Theta - self.nfp*N*Phi)\n        if not self.stellsym:\n            CosGrid = BNC*np.cos(M*Theta - self.nfp*N*Phi)\n\n        # Add the contributions of each mode\n        bnormal = np.sum(SinGrid, axis=2)\n        if not self.stellsym:\n            bnormal = bnormal + np.sum(CosGrid, axis=2)\n\n        return bnormal",
  "class FocusData(object):\n    \"\"\"\n    Class object for reading in FOCUS-style data files.\n\n    Args:\n        filename: a FOCUS file\n    \"\"\"\n    propNames = ['type', 'symm', 'coilname', 'ox', 'oy', 'oz', 'Ic', 'M_0', \\\n                 'pho', 'Lc', 'mp', 'mt', 'op']\n\n    float_inds = [3, 4, 5, 7, 8, 10, 11]\n\n    def __init__(self, filename, downsample=1):\n\n        self.nMagnets = 0\n        self.nPol = 0\n\n        # initialize to # of mandatory properties ('op' is currently optional)\n        self.nProps = len(FocusData.propNames) - 1\n\n        self.read_from_file(filename, downsample)\n\n    def read_from_file(self, filename, downsample):\n\n        with open(str(filename), 'r') as focusfile: \n            # Ignore the first line in the file\n            line1 = focusfile.readline()\n\n            # Record the number of magnets and the momentq\n            line2data = [int(number) for number in \\\n                         focusfile.readline().strip().split()]\n            self.nMagnets = line2data[0]\n            if len(line2data) > 1:\n                self.momentq = line2data[1]\n                self.has_momentq = True\n            else:\n                self.has_momentq = False\n\n            # Initialize the property data arrays\n            self.magtype = np.zeros(self.nMagnets)\n            self.symm = np.zeros(self.nMagnets)\n            self.coilname = []\n            self.ox = np.zeros(self.nMagnets)\n            self.oy = np.zeros(self.nMagnets)\n            self.oz = np.zeros(self.nMagnets)\n            self.Ic = np.zeros(self.nMagnets)\n            self.M_0 = np.zeros(self.nMagnets)\n            self.pho = np.zeros(self.nMagnets)\n            self.Lc = np.zeros(self.nMagnets)\n            self.mp = np.zeros(self.nMagnets)\n            self.mt = np.zeros(self.nMagnets)\n            self.op = np.zeros(self.nMagnets)\n\n            # Ignore the third line in the file\n            line3 = focusfile.readline()\n\n            # Read the data for each magnet from the file\n            count = 0\n            self.max_float_length = 0\n            self.min_float_val = 0\n            for i in range(self.nMagnets):\n\n                linedata = focusfile.readline().strip().split(',')\n                if len(linedata) < self.nProps:\n                    raise Exception(('Problem accessing data for magnet %d in ' \\\n                                     + 'file ' + filename) % (i))\n\n                self.magtype[i] = int(linedata[0])\n                self.symm[i] = int(linedata[1])\n                self.coilname.append(linedata[2].strip())\n                self.ox[i] = np.double(linedata[3])\n                self.oy[i] = np.double(linedata[4])\n                self.oz[i] = np.double(linedata[5])\n                self.Ic[i] = int(float(linedata[6].strip()))\n                self.M_0[i] = np.double(linedata[7])\n                self.pho[i] = np.double(linedata[8])\n                self.Lc[i] = int(float(linedata[9].strip()))\n                self.mp[i] = np.double(linedata[10])\n                self.mt[i] = np.double(linedata[11])    \n\n                # Check for presence of op parameter\n                if i == 0:\n                    if len(linedata) > self.nProps:\n                        try:\n                            testnum = np.double(linedata[12])\n                            self.has_op = True\n                            self.nProps = self.nProps + 1\n                        except:\n                            self.has_op = False\n                    else:\n                        self.has_op = False\n\n                # Record op parameter if applicable\n                if self.has_op:\n                    self.op[i] = np.double(linedata[12])\n\n                # Keep track of the longest and lowest-valued floats recorded\n                max_float_length = max([len(linedata[i].strip()) for i \\\n                                        in FocusData.float_inds])\n                if max_float_length > self.max_float_length:\n                    self.max_float_length = max_float_length\n                min_float_val = min([np.double(linedata[i]) for i \\\n                                     in FocusData.float_inds])\n                if min_float_val < self.min_float_val:\n                    self.min_float_val = min_float_val\n\n                count += 1\n\n        self.max_name_length = max([len(string) for string in self.coilname])\n\n        # Add space for a negative sign in the max float length if necessary\n        if self.min_float_val >= 0:\n            self.max_float_length = self.max_float_length+1\n\n        # Drop magnets from downsample and port locations\n        inds_total = np.arange(self.nMagnets)\n        inds_downsampled = inds_total[::downsample]\n\n        # also remove any dipoles where the diagnostic ports should be\n        nonzero_inds = np.intersect1d(np.ravel(np.where(self.Ic == 1.0)), inds_downsampled) \n        self.ox = self.ox[nonzero_inds]\n        self.oy = self.oy[nonzero_inds]\n        self.oz = self.oz[nonzero_inds]\n        self.magtype = self.magtype[nonzero_inds]\n        self.symm = self.symm[nonzero_inds]\n        self.coilname = np.array(self.coilname)[nonzero_inds]\n        self.coilname = self.coilname.tolist()\n        self.M_0 = self.M_0[nonzero_inds] \n        self.pho = self.pho[nonzero_inds] \n        self.Lc = self.Lc[nonzero_inds] \n        self.mp = self.mp[nonzero_inds] \n        self.mt = self.mt[nonzero_inds]\n        self.nMagnets = len(nonzero_inds)\n\n    def unit_vector(self, inds):\n        \"\"\"\n        Returns the x, y, and z components of a Cartesian unit vector in the \n        polarizaton direction of the nth magnet\n        \"\"\"\n        if len(inds) > 0 and max(inds) > self.nMagnets-1:\n            raise Exception('unit_vector: requested magnet %d does not exist' \\\n                            % (max(inds)))\n\n        return np.cos(self.mp[inds])*np.sin(self.mt[inds]), \\\n            np.sin(self.mp[inds])*np.sin(self.mt[inds]), \\\n            np.cos(self.mt[inds])\n\n    def perp_vector(self, inds):\n        \"\"\"\n        Returns the x, y, and z components of a Cartesian unit vector \n        perpendicular to the polarizaton direction of the nth magnet\n        \"\"\"\n        if len(inds) > 0 and max(inds) > self.nMagnets-1:\n            raise Exception('unit_vector: requested magnet %d does not exist' \\\n                            % (max(inds)))\n\n        mt_perp = self.mt[inds] + np.pi / 2.0\n        return np.cos(self.mp[inds])*np.sin(mt_perp), \\\n            np.sin(self.mp[inds])*np.sin(mt_perp), \\\n            np.cos(mt_perp)\n\n    def flip_negative_magnets(self):\n        \"\"\"\n        For magnets with negative rho values, adjust the orientation angles\n        (mt and mp) so that the rho value can be negated to a positive value\n        \"\"\"\n        # Indices of magnets with negative rho values\n        neg_inds = np.where(self.pho < 0)[0]\n\n        if len(neg_inds) == 0:\n            return\n\n        # x, y, and z components of unit vectors for the negative magnets\n        ux, uy, uz = self.unit_vector(neg_inds)\n\n        # Calculate azimuthal and polar angles for negated unit vectors\n        mp_neg = np.arctan2(-uy, -ux)\n        mt_neg = np.arctan2(np.sqrt(ux**2 + uy**2), -uz)\n\n        # Replace relevant values for the (initially) negative magnets\n        self.pho[neg_inds] = -self.pho[neg_inds]\n        self.mp[neg_inds] = mp_neg\n        self.mt[neg_inds] = mt_neg\n\n    def adjust_rho(self, q_new):\n        \"\"\"\n        Adjust rho according to the desired momentq\n\n        Args:\n            q_new: New exponent to use for FAMUS representation\n              of dipole magnitudes.\n        \"\"\"\n        if min(self.pho) < 0:\n            raise RuntimeError('adjust_rho: rho contains negative values')\n\n        if self.has_momentq:\n            self.pho = self.pho**(float(self.momentq)/float(q_new))\n            self.momentq = q_new\n\n        # If no momentq currently specified, assume to be one\n        else:\n            self.pho = self.pho**(1./float(q_new))\n            self.momentq = q_new\n            self.has_momentq = True\n\n    def print_to_file(self, filename):\n        \"\"\"\n        Write the FocusData class object information to a FOCUS\n        style file.\n\n        Args:\n            filename: string denoting the name of the output file.\n        \"\"\"\n        if self.nMagnets < 1:\n            raise RuntimeError('print_to_file: no magnets to print')\n\n        with open(str(filename), 'w') as focusfile: \n\n            if self.has_momentq:\n                focusfile.write('Total number of dipoles, momentq\\n')\n                focusfile.write('%10d %5g\\n' % (self.nMagnets, self.momentq))\n            else:\n                focusfile.write('Total number of dipoles\\n')\n                focusfile.write('%10d\\n' % (self.nMagnets))\n\n            # String format specifiers: float length, decimal precision, name length\n            lf = '%s' % (self.max_float_length) \n            nd = '%s' % (self.max_float_length - 7)\n            ln = '%s' % (self.max_name_length)\n\n            # Write the header line for the individual magnet data\n            focusfile.write(('%s, ' * 2 + '%' + ln + 's, ' + ('%' + lf + 's, ') * 3 + \\\n                             '%s, ' + ('%' + lf + 's, ') * 2 + '%s, ' + \\\n                             ('%' + lf + 's, ') * 2) % \\\n                            tuple(FocusData.propNames[:12]))\n            if self.has_op:\n                focusfile.write(('%' + lf + 's, \\n') % (FocusData.propNames[12]))\n            else:\n                focusfile.write('\\n')\n\n            # Write the data for each magnet to the file\n            for i in range(self.nMagnets):\n\n                lineStr = ('%4d, ' * 2 + '%' + ln + 's, ' + \\\n                           ('%' + lf + '.' + nd + 'E, ') * 3 + '%2d, ' + \\\n                           ('%' + lf + '.' + nd + 'E, ') * 2 + '%2d, ' + \\\n                           ('%' + lf + '.' + nd + 'E, ') * 2) %  \\\n                    (self.magtype[i], self.symm[i], self.coilname[i], \\\n                     self.ox[i], self.oy[i], self.oz[i], self.Ic[i],  \\\n                     self.M_0[i], self.pho[i], self.Lc[i], \\\n                     self.mp[i], self.mt[i])\n\n                if self.has_op:\n                    lineStr = lineStr + ('%' + lf + '.' + nd + 'E, \\n') % self.op[i]\n                else:\n                    lineStr = lineStr + '\\n'\n\n                focusfile.write(lineStr)\n\n    def init_pol_vecs(self, n_pol):\n        \"\"\"\n        Initializes arrays for the x, y, and z components of allowable\n        polarization vectors, as an array giving the ID of the polarization\n        vector actually used for the respective magnet (0 means magnet is off)\n\n        Args:\n            n_pol: int\n                Number of allowed polarization vectors, typically 3 or 12.\n        \"\"\"\n        self.nPol = n_pol\n        self.pol_x = np.zeros((self.nMagnets, n_pol))\n        self.pol_y = np.zeros((self.nMagnets, n_pol))\n        self.pol_z = np.zeros((self.nMagnets, n_pol))\n        self.pol_id = np.zeros(self.nMagnets, dtype=int)\n        self.pol_type = np.zeros(self.nMagnets, dtype=int)\n        self.pol_type_key = np.zeros(n_pol, dtype=int)\n        self.cyl_r = np.zeros(self.nMagnets)\n        self.cyl_p = np.zeros(self.nMagnets)\n        self.cyl_z = np.zeros(self.nMagnets)\n\n    def repeat_hp_to_fp(self, nfp, magnet_sector=1):\n        '''\n        Duplicates the magnets to the adjacent half-period, implementing the\n        appropriate transformations to uphold stellarator symmetry.\n\n        NOTES: \n            - At the present time, duplicate magnets will have the same pol_id\n              as their corresponding originals\n            - At the present time, duplicate magnets will have the same name\n              their corresponding originals.\n\n        Parameters\n        ----------\n            nfp: integer\n                Number of field periods in the configuration\n            magnet_sector: integer (optional)\n                Sector (half-period) of the torus in which the magnets are \n                assumed to be located. Must be between 1 and 2*nfp, inclusive.\n                Sector 1 starts at toroidal angle 0.\n        '''\n        symm_inds = np.where(self.symm == 2)[0]\n        n_symm = len(symm_inds)\n        if n_symm == 0:\n            raise ValueError('repeat_hp_to_fp is only valid for magnets ' \\\n                             'that are stellarator symmetric (symm=2)')\n\n        # Toroidal angle of the symmetry plane between the adjacent half-periods\n        if magnet_sector > 2*nfp or magnet_sector < 1:\n            raise ValueError('magnet_sector must be positive and less than ' \\\n                             '2*nfp')\n        phi = magnet_sector * np.pi/nfp\n\n        nx, ny, nz = self.unit_vector(symm_inds)\n\n        # Reflect polarization vector origins and directions\n        nx2, ny2, nz2 = stell_vector_transform('reflect', phi, nx, ny, nz)\n        ox2, oy2, oz2 = \\\n            stell_point_transform('reflect', phi, self.ox, self.oy, self.oz)\n        mp2 = np.arctan2(ny2, nx2)\n        mt2 = np.arctan2(np.sqrt(nx2**2 + ny2**2), nz2)\n        op2 = 2*phi - self.op[symm_inds]\n\n        # Update the number of magnets\n        self.nMagnets = self.nMagnets + n_symm\n\n        # Update the symmetry coding for magnets that have been duplicated\n        self.symm[symm_inds] = 1\n\n        # Extend the dipole moment data to the new half-period\n        self.magtype = np.concatenate((self.magtype, self.magtype[symm_inds]))\n        self.symm = np.concatenate((self.symm, self.symm[symm_inds]))\n        self.coilname = self.coilname + [self.coilname[i] for i in symm_inds]\n        self.ox = np.concatenate((self.ox, ox2))\n        self.oy = np.concatenate((self.oy, oy2))\n        self.oz = np.concatenate((self.oz, oz2))\n        self.Ic = np.concatenate((self.Ic, self.Ic[symm_inds]))\n        self.M_0 = np.concatenate((self.M_0, self.M_0[symm_inds]))\n        self.pho = np.concatenate((self.pho, self.pho[symm_inds]))\n        self.Lc = np.concatenate((self.Lc, self.Lc[symm_inds]))\n        self.mp = np.concatenate((self.mp, mp2))\n        self.mt = np.concatenate((self.mt, mt2))\n        self.op = np.concatenate((self.op, op2))\n\n        # Update discrete polarization properties if they exist\n        if self.nPol > 0:\n            pol_x2, pol_y2, pol_z2 = \\\n                stell_vector_transform('reflect', phi, \\\n                                       self.pol_x[symm_inds, :], self.pol_y[symm_inds, :], \\\n                                       self.pol_z[symm_inds, :])\n            pol_type2 = self.pol_type[symm_inds]\n            pol_id2 = self.pol_id[symm_inds]\n            cyl_r2 = -self.cyl_r[symm_inds]\n            cyl_p2 = self.cyl_p[symm_inds]\n            cyl_z2 = self.cyl_z[symm_inds]\n\n            self.pol_x = np.concatenate((self.pol_x, pol_x2), axis=0)\n            self.pol_y = np.concatenate((self.pol_y, pol_y2), axis=0)\n            self.pol_z = np.concatenate((self.pol_z, pol_z2), axis=0)\n            self.pol_type = np.concatenate((self.pol_type, pol_type2))\n            self.pol_id = np.concatenate((self.pol_id, pol_id2))\n            self.cyl_r = np.concatenate((self.cyl_r, cyl_r2))\n            self.cyl_p = np.concatenate((self.cyl_p, cyl_p2))\n            self.cyl_z = np.concatenate((self.cyl_z, cyl_z2))",
  "def stell_vector_transform(mode, phi, vx_in, vy_in, vz_in):\n    '''\n    Transforms a vector in one of two ways, depending on the mode selected:\n        reflect:   Reflects a vector, with a defined origin point, in a given \n                   poloidal plane that is presumed to form the boundary between\n                   two stellarator-symmetryc half-periods. The output vector \n                   will have the equivalent origin point and direction \n                   associated with the target half-period. Vector magnitude\n                   is preserved.\n        translate: Translates a vector, with a defined origin point, in the \n                   toroidal direction. The origin thus moves along a circle\n                   of fixed radius about the z axis by a given angle. The\n                   azimuthal components of the vector change in order to \n                   preserve the radial and toroidal components. The vertical\n                   component of the vector, as well as its length, are held\n                   fixed.\n\n    Parameters\n    ----------\n        mode: string\n            'translate' or 'reflect' (see description above)\n        phi: double\n            'reflect' mode: toroidal angle (rad.) of the symmetry plane\n            'translate' mode: toroidal interval (rad.) along which to translate\n        vx_in, vy_in, vz_in: double (possibly arrays of equal dimensions)\n            x, y, z components of the input vectors\n\n    Returns\n    -------\n        vx_out, vy_out, vz_out: \n            x, y, z components of the output transformed vector(s)\n    '''\n\n    # Check input mode\n    if mode == 'reflect':\n        refl = True\n    elif mode == 'translate':\n        refl = False\n    else:\n        raise ValueError('Unrecognized mode for stell_vector_transform')\n\n    if refl:\n        vx_out = -np.cos(2*phi)*vx_in - np.sin(2*phi)*vy_in\n        vy_out = -np.sin(2*phi)*vx_in + np.cos(2*phi)*vy_in\n        vz_out = vz_in\n    else:\n        vx_out = np.cos(phi)*vx_in - np.sin(phi)*vy_in\n        vy_out = np.sin(phi)*vx_in + np.cos(phi)*vy_in\n        vz_out = vz_in\n\n    return vx_out, vy_out, vz_out",
  "def stell_point_transform(mode, phi, x_in, y_in, z_in):\n    '''\n    Transforms a point in one of two ways, depending on the mode selected:\n        reflect:   Reflects a point in a given poloidal plane presumed to form \n                   the boundary between two stellarator-symmetryc half-periods. \n                   The output point will have the equivalent location associated\n                   with the adjacent half-period. \n        translate: Translates a point in the toroidal direction (i.e., along\n                   a circle with a fixed radius about the z axis) by a given\n                   angle.\n\n    Parameters\n    ----------\n        mode: string\n            'translate' or 'reflect' (see description above)\n        phi: double\n            'reflect' mode: toroidal angle (rad.) of the symmetry plane\n            'translate' mode: toroidal interval (rad.) along which to translate\n        x_in, y_in, z_in: double (possibly arrays of equal dimensions)\n            x, y, z coordinates of the point(s) to be transformed\n\n    Returns\n    -------\n        x_out, y_out, z_out: double (possibly arrays)\n            x, y, z coordinates of the transformed point(s)\n    '''\n\n    # Check input mode\n    if mode == 'reflect':\n        refl = True\n    elif mode == 'translate':\n        refl = False\n    else:\n        raise ValueError('Unrecognized mode for stell_vector_transform')\n\n    if refl:\n        x_out = np.cos(2*phi)*x_in + np.sin(2*phi)*y_in\n        y_out = np.sin(2*phi)*x_in - np.cos(2*phi)*y_in\n        z_out = -z_in\n    else:\n        x_out = np.cos(phi)*x_in - np.sin(phi)*y_in\n        y_out = np.sin(phi)*x_in + np.cos(phi)*y_in\n        z_out = z_in\n\n    return x_out, y_out, z_out",
  "def __init__(self, fname):\n\n        with open(fname, 'r') as f:\n            lines = f.readlines()\n\n        # Read numbers of modes and nfp from the header\n        position = FOCUS_PLASMAFILE_NHEADER_TOP\n        splitline = lines[position].split()\n        errmsg = \"This does not appear to be a FOCUS-format \" \\\n                 + \"plasma boundary file\"\n        assert len(splitline) == 3, errmsg\n\n        Nfou = int(splitline[0])\n        nfp = int(splitline[1])\n        NfouBn = int(splitline[2])\n\n        # Read Fourier harmonics of the normal field on the plasma boundary\n        position = position + 1 + FOCUS_PLASMAFILE_NHEADER_BDRY + Nfou + \\\n            FOCUS_PLASMAFILE_NHEADER_BNORM\n\n        self.n = np.zeros(NfouBn)\n        self.m = np.zeros(NfouBn)\n        self.bnc = np.zeros(NfouBn)\n        self.bns = np.zeros(NfouBn)\n        for i in range(NfouBn):\n            splitline = lines[position + i].split()\n            self.n[i] = int(splitline[0])\n            self.m[i] = int(splitline[1])\n            self.bnc[i] = float(splitline[2])\n            self.bns[i] = float(splitline[3])\n        assert np.min(self.m) == 0\n\n        self.nfp = nfp\n        self.NfouBn = NfouBn\n        self.stellsym = np.max(np.abs(self.bnc)) == 0",
  "def bnormal_grid(self, nphi, ntheta, range):\n        '''\n        Calculates the normal component of the magnetic field on a\n        regularly-spaced 2D grid of points on the surface with a specified\n        resolution.\n\n        Parameters\n        ----------\n          nphi: int\n            Number of grid points in the toroidal dimension per field period.\n          ntheta: int\n            Number of grid points in the poloidal dimension.\n          range: str\n            Extent of the grid in the toroidal dimension. Choices include\n            `half period`, `field period`, or `full torus`.\n\n        Returns\n        -------\n          bnormal: 2D array\n            Normal component of the magnetic field evaluated at each of the\n            grid points.\n        '''\n        # Determine the theta and phi points using Simsopt Surface class methods\n        phi = Surface.get_phi_quadpoints(nphi=nphi, range=range, nfp=self.nfp)\n        theta = Surface.get_theta_quadpoints(ntheta=ntheta)\n        # Rescale the angles\n        phi = 2.*np.pi*np.array(phi)\n        theta = 2.*np.pi*np.array(theta)\n\n        # Prepare 3D arrays with mode numbers and coefficients\n        Theta, Phi, Mode = np.meshgrid(theta, phi, np.arange(0, self.NfouBn))\n        M = self.m[Mode]\n        N = self.n[Mode]\n        BNS = self.bns[Mode]\n        if not self.stellsym:\n            BNC = self.bnc[Mode]\n\n        # Calculate the values of each mode at each grid point\n        SinGrid = BNS*np.sin(M*Theta - self.nfp*N*Phi)\n        if not self.stellsym:\n            CosGrid = BNC*np.cos(M*Theta - self.nfp*N*Phi)\n\n        # Add the contributions of each mode\n        bnormal = np.sum(SinGrid, axis=2)\n        if not self.stellsym:\n            bnormal = bnormal + np.sum(CosGrid, axis=2)\n\n        return bnormal",
  "def __init__(self, filename, downsample=1):\n\n        self.nMagnets = 0\n        self.nPol = 0\n\n        # initialize to # of mandatory properties ('op' is currently optional)\n        self.nProps = len(FocusData.propNames) - 1\n\n        self.read_from_file(filename, downsample)",
  "def read_from_file(self, filename, downsample):\n\n        with open(str(filename), 'r') as focusfile: \n            # Ignore the first line in the file\n            line1 = focusfile.readline()\n\n            # Record the number of magnets and the momentq\n            line2data = [int(number) for number in \\\n                         focusfile.readline().strip().split()]\n            self.nMagnets = line2data[0]\n            if len(line2data) > 1:\n                self.momentq = line2data[1]\n                self.has_momentq = True\n            else:\n                self.has_momentq = False\n\n            # Initialize the property data arrays\n            self.magtype = np.zeros(self.nMagnets)\n            self.symm = np.zeros(self.nMagnets)\n            self.coilname = []\n            self.ox = np.zeros(self.nMagnets)\n            self.oy = np.zeros(self.nMagnets)\n            self.oz = np.zeros(self.nMagnets)\n            self.Ic = np.zeros(self.nMagnets)\n            self.M_0 = np.zeros(self.nMagnets)\n            self.pho = np.zeros(self.nMagnets)\n            self.Lc = np.zeros(self.nMagnets)\n            self.mp = np.zeros(self.nMagnets)\n            self.mt = np.zeros(self.nMagnets)\n            self.op = np.zeros(self.nMagnets)\n\n            # Ignore the third line in the file\n            line3 = focusfile.readline()\n\n            # Read the data for each magnet from the file\n            count = 0\n            self.max_float_length = 0\n            self.min_float_val = 0\n            for i in range(self.nMagnets):\n\n                linedata = focusfile.readline().strip().split(',')\n                if len(linedata) < self.nProps:\n                    raise Exception(('Problem accessing data for magnet %d in ' \\\n                                     + 'file ' + filename) % (i))\n\n                self.magtype[i] = int(linedata[0])\n                self.symm[i] = int(linedata[1])\n                self.coilname.append(linedata[2].strip())\n                self.ox[i] = np.double(linedata[3])\n                self.oy[i] = np.double(linedata[4])\n                self.oz[i] = np.double(linedata[5])\n                self.Ic[i] = int(float(linedata[6].strip()))\n                self.M_0[i] = np.double(linedata[7])\n                self.pho[i] = np.double(linedata[8])\n                self.Lc[i] = int(float(linedata[9].strip()))\n                self.mp[i] = np.double(linedata[10])\n                self.mt[i] = np.double(linedata[11])    \n\n                # Check for presence of op parameter\n                if i == 0:\n                    if len(linedata) > self.nProps:\n                        try:\n                            testnum = np.double(linedata[12])\n                            self.has_op = True\n                            self.nProps = self.nProps + 1\n                        except:\n                            self.has_op = False\n                    else:\n                        self.has_op = False\n\n                # Record op parameter if applicable\n                if self.has_op:\n                    self.op[i] = np.double(linedata[12])\n\n                # Keep track of the longest and lowest-valued floats recorded\n                max_float_length = max([len(linedata[i].strip()) for i \\\n                                        in FocusData.float_inds])\n                if max_float_length > self.max_float_length:\n                    self.max_float_length = max_float_length\n                min_float_val = min([np.double(linedata[i]) for i \\\n                                     in FocusData.float_inds])\n                if min_float_val < self.min_float_val:\n                    self.min_float_val = min_float_val\n\n                count += 1\n\n        self.max_name_length = max([len(string) for string in self.coilname])\n\n        # Add space for a negative sign in the max float length if necessary\n        if self.min_float_val >= 0:\n            self.max_float_length = self.max_float_length+1\n\n        # Drop magnets from downsample and port locations\n        inds_total = np.arange(self.nMagnets)\n        inds_downsampled = inds_total[::downsample]\n\n        # also remove any dipoles where the diagnostic ports should be\n        nonzero_inds = np.intersect1d(np.ravel(np.where(self.Ic == 1.0)), inds_downsampled) \n        self.ox = self.ox[nonzero_inds]\n        self.oy = self.oy[nonzero_inds]\n        self.oz = self.oz[nonzero_inds]\n        self.magtype = self.magtype[nonzero_inds]\n        self.symm = self.symm[nonzero_inds]\n        self.coilname = np.array(self.coilname)[nonzero_inds]\n        self.coilname = self.coilname.tolist()\n        self.M_0 = self.M_0[nonzero_inds] \n        self.pho = self.pho[nonzero_inds] \n        self.Lc = self.Lc[nonzero_inds] \n        self.mp = self.mp[nonzero_inds] \n        self.mt = self.mt[nonzero_inds]\n        self.nMagnets = len(nonzero_inds)",
  "def unit_vector(self, inds):\n        \"\"\"\n        Returns the x, y, and z components of a Cartesian unit vector in the \n        polarizaton direction of the nth magnet\n        \"\"\"\n        if len(inds) > 0 and max(inds) > self.nMagnets-1:\n            raise Exception('unit_vector: requested magnet %d does not exist' \\\n                            % (max(inds)))\n\n        return np.cos(self.mp[inds])*np.sin(self.mt[inds]), \\\n            np.sin(self.mp[inds])*np.sin(self.mt[inds]), \\\n            np.cos(self.mt[inds])",
  "def perp_vector(self, inds):\n        \"\"\"\n        Returns the x, y, and z components of a Cartesian unit vector \n        perpendicular to the polarizaton direction of the nth magnet\n        \"\"\"\n        if len(inds) > 0 and max(inds) > self.nMagnets-1:\n            raise Exception('unit_vector: requested magnet %d does not exist' \\\n                            % (max(inds)))\n\n        mt_perp = self.mt[inds] + np.pi / 2.0\n        return np.cos(self.mp[inds])*np.sin(mt_perp), \\\n            np.sin(self.mp[inds])*np.sin(mt_perp), \\\n            np.cos(mt_perp)",
  "def flip_negative_magnets(self):\n        \"\"\"\n        For magnets with negative rho values, adjust the orientation angles\n        (mt and mp) so that the rho value can be negated to a positive value\n        \"\"\"\n        # Indices of magnets with negative rho values\n        neg_inds = np.where(self.pho < 0)[0]\n\n        if len(neg_inds) == 0:\n            return\n\n        # x, y, and z components of unit vectors for the negative magnets\n        ux, uy, uz = self.unit_vector(neg_inds)\n\n        # Calculate azimuthal and polar angles for negated unit vectors\n        mp_neg = np.arctan2(-uy, -ux)\n        mt_neg = np.arctan2(np.sqrt(ux**2 + uy**2), -uz)\n\n        # Replace relevant values for the (initially) negative magnets\n        self.pho[neg_inds] = -self.pho[neg_inds]\n        self.mp[neg_inds] = mp_neg\n        self.mt[neg_inds] = mt_neg",
  "def adjust_rho(self, q_new):\n        \"\"\"\n        Adjust rho according to the desired momentq\n\n        Args:\n            q_new: New exponent to use for FAMUS representation\n              of dipole magnitudes.\n        \"\"\"\n        if min(self.pho) < 0:\n            raise RuntimeError('adjust_rho: rho contains negative values')\n\n        if self.has_momentq:\n            self.pho = self.pho**(float(self.momentq)/float(q_new))\n            self.momentq = q_new\n\n        # If no momentq currently specified, assume to be one\n        else:\n            self.pho = self.pho**(1./float(q_new))\n            self.momentq = q_new\n            self.has_momentq = True",
  "def print_to_file(self, filename):\n        \"\"\"\n        Write the FocusData class object information to a FOCUS\n        style file.\n\n        Args:\n            filename: string denoting the name of the output file.\n        \"\"\"\n        if self.nMagnets < 1:\n            raise RuntimeError('print_to_file: no magnets to print')\n\n        with open(str(filename), 'w') as focusfile: \n\n            if self.has_momentq:\n                focusfile.write('Total number of dipoles, momentq\\n')\n                focusfile.write('%10d %5g\\n' % (self.nMagnets, self.momentq))\n            else:\n                focusfile.write('Total number of dipoles\\n')\n                focusfile.write('%10d\\n' % (self.nMagnets))\n\n            # String format specifiers: float length, decimal precision, name length\n            lf = '%s' % (self.max_float_length) \n            nd = '%s' % (self.max_float_length - 7)\n            ln = '%s' % (self.max_name_length)\n\n            # Write the header line for the individual magnet data\n            focusfile.write(('%s, ' * 2 + '%' + ln + 's, ' + ('%' + lf + 's, ') * 3 + \\\n                             '%s, ' + ('%' + lf + 's, ') * 2 + '%s, ' + \\\n                             ('%' + lf + 's, ') * 2) % \\\n                            tuple(FocusData.propNames[:12]))\n            if self.has_op:\n                focusfile.write(('%' + lf + 's, \\n') % (FocusData.propNames[12]))\n            else:\n                focusfile.write('\\n')\n\n            # Write the data for each magnet to the file\n            for i in range(self.nMagnets):\n\n                lineStr = ('%4d, ' * 2 + '%' + ln + 's, ' + \\\n                           ('%' + lf + '.' + nd + 'E, ') * 3 + '%2d, ' + \\\n                           ('%' + lf + '.' + nd + 'E, ') * 2 + '%2d, ' + \\\n                           ('%' + lf + '.' + nd + 'E, ') * 2) %  \\\n                    (self.magtype[i], self.symm[i], self.coilname[i], \\\n                     self.ox[i], self.oy[i], self.oz[i], self.Ic[i],  \\\n                     self.M_0[i], self.pho[i], self.Lc[i], \\\n                     self.mp[i], self.mt[i])\n\n                if self.has_op:\n                    lineStr = lineStr + ('%' + lf + '.' + nd + 'E, \\n') % self.op[i]\n                else:\n                    lineStr = lineStr + '\\n'\n\n                focusfile.write(lineStr)",
  "def init_pol_vecs(self, n_pol):\n        \"\"\"\n        Initializes arrays for the x, y, and z components of allowable\n        polarization vectors, as an array giving the ID of the polarization\n        vector actually used for the respective magnet (0 means magnet is off)\n\n        Args:\n            n_pol: int\n                Number of allowed polarization vectors, typically 3 or 12.\n        \"\"\"\n        self.nPol = n_pol\n        self.pol_x = np.zeros((self.nMagnets, n_pol))\n        self.pol_y = np.zeros((self.nMagnets, n_pol))\n        self.pol_z = np.zeros((self.nMagnets, n_pol))\n        self.pol_id = np.zeros(self.nMagnets, dtype=int)\n        self.pol_type = np.zeros(self.nMagnets, dtype=int)\n        self.pol_type_key = np.zeros(n_pol, dtype=int)\n        self.cyl_r = np.zeros(self.nMagnets)\n        self.cyl_p = np.zeros(self.nMagnets)\n        self.cyl_z = np.zeros(self.nMagnets)",
  "def repeat_hp_to_fp(self, nfp, magnet_sector=1):\n        '''\n        Duplicates the magnets to the adjacent half-period, implementing the\n        appropriate transformations to uphold stellarator symmetry.\n\n        NOTES: \n            - At the present time, duplicate magnets will have the same pol_id\n              as their corresponding originals\n            - At the present time, duplicate magnets will have the same name\n              their corresponding originals.\n\n        Parameters\n        ----------\n            nfp: integer\n                Number of field periods in the configuration\n            magnet_sector: integer (optional)\n                Sector (half-period) of the torus in which the magnets are \n                assumed to be located. Must be between 1 and 2*nfp, inclusive.\n                Sector 1 starts at toroidal angle 0.\n        '''\n        symm_inds = np.where(self.symm == 2)[0]\n        n_symm = len(symm_inds)\n        if n_symm == 0:\n            raise ValueError('repeat_hp_to_fp is only valid for magnets ' \\\n                             'that are stellarator symmetric (symm=2)')\n\n        # Toroidal angle of the symmetry plane between the adjacent half-periods\n        if magnet_sector > 2*nfp or magnet_sector < 1:\n            raise ValueError('magnet_sector must be positive and less than ' \\\n                             '2*nfp')\n        phi = magnet_sector * np.pi/nfp\n\n        nx, ny, nz = self.unit_vector(symm_inds)\n\n        # Reflect polarization vector origins and directions\n        nx2, ny2, nz2 = stell_vector_transform('reflect', phi, nx, ny, nz)\n        ox2, oy2, oz2 = \\\n            stell_point_transform('reflect', phi, self.ox, self.oy, self.oz)\n        mp2 = np.arctan2(ny2, nx2)\n        mt2 = np.arctan2(np.sqrt(nx2**2 + ny2**2), nz2)\n        op2 = 2*phi - self.op[symm_inds]\n\n        # Update the number of magnets\n        self.nMagnets = self.nMagnets + n_symm\n\n        # Update the symmetry coding for magnets that have been duplicated\n        self.symm[symm_inds] = 1\n\n        # Extend the dipole moment data to the new half-period\n        self.magtype = np.concatenate((self.magtype, self.magtype[symm_inds]))\n        self.symm = np.concatenate((self.symm, self.symm[symm_inds]))\n        self.coilname = self.coilname + [self.coilname[i] for i in symm_inds]\n        self.ox = np.concatenate((self.ox, ox2))\n        self.oy = np.concatenate((self.oy, oy2))\n        self.oz = np.concatenate((self.oz, oz2))\n        self.Ic = np.concatenate((self.Ic, self.Ic[symm_inds]))\n        self.M_0 = np.concatenate((self.M_0, self.M_0[symm_inds]))\n        self.pho = np.concatenate((self.pho, self.pho[symm_inds]))\n        self.Lc = np.concatenate((self.Lc, self.Lc[symm_inds]))\n        self.mp = np.concatenate((self.mp, mp2))\n        self.mt = np.concatenate((self.mt, mt2))\n        self.op = np.concatenate((self.op, op2))\n\n        # Update discrete polarization properties if they exist\n        if self.nPol > 0:\n            pol_x2, pol_y2, pol_z2 = \\\n                stell_vector_transform('reflect', phi, \\\n                                       self.pol_x[symm_inds, :], self.pol_y[symm_inds, :], \\\n                                       self.pol_z[symm_inds, :])\n            pol_type2 = self.pol_type[symm_inds]\n            pol_id2 = self.pol_id[symm_inds]\n            cyl_r2 = -self.cyl_r[symm_inds]\n            cyl_p2 = self.cyl_p[symm_inds]\n            cyl_z2 = self.cyl_z[symm_inds]\n\n            self.pol_x = np.concatenate((self.pol_x, pol_x2), axis=0)\n            self.pol_y = np.concatenate((self.pol_y, pol_y2), axis=0)\n            self.pol_z = np.concatenate((self.pol_z, pol_z2), axis=0)\n            self.pol_type = np.concatenate((self.pol_type, pol_type2))\n            self.pol_id = np.concatenate((self.pol_id, pol_id2))\n            self.cyl_r = np.concatenate((self.cyl_r, cyl_r2))\n            self.cyl_p = np.concatenate((self.cyl_p, cyl_p2))\n            self.cyl_z = np.concatenate((self.cyl_z, cyl_z2))",
  "def log(level: int = logging.INFO):\n    \"\"\"\n    Turn on logging. If MPI is available, the processor number will be\n    added to all logging entries.\n\n    Args:\n        level: Typically ``logging.INFO`` for regular output, or \n          ``logging.DEBUG`` for more extensive output.\n    \"\"\"\n    format = \"%(levelname)s:%(name)s:%(lineno)d %(message)s\"\n    if MPI is not None:\n        format = \"[{}] \".format(MPI.COMM_WORLD.Get_rank()) + format\n\n    logging.basicConfig(level=level, format=format)",
  "def proc0_print(*args, **kwargs):\n    if MPI is None:\n        print(*args, **kwargs)\n    else:\n        if MPI.COMM_WORLD.rank == 0:\n            print(*args, **kwargs)",
  "class MpiPartition:\n    \"\"\"\n    This module contains functions related to dividing up the set of\n    MPI processes into groups, each of which can work together. For\n    more information, see :ref:`mpi`.\n\n    Args:\n        ngroups: The number of worker groups desired. If ``None``, a worker\n          group will be created for each MPI process. If a value is supplied\n          that is larger than the number of processes, the number will be\n          lowered to the number of processes.\n        comm_world: The MPI communicator containing all processes to split into\n          worker groups.\n\n    Attributes:\n        ngroups (int): The number of worker groups.\n        group (int): Index giving the worker group that this MPI process belongs to.\n        comm_world (mpi4py.MPI.Intracomm): The MPI communicator that includes all processes together.\n        comm_groups (mpi4py.MPI.Intracomm): The MPI communicator representing the worker groups.\n        comm_leaders (mpi4py.MPI.Intracomm): The MPI communicator that includes only leaders of worker groups.\n        rank_world (int): The MPI rank in the ``comm_world`` communicator.\n        rank_groups (int): The MPI rank in the ``comm_groups`` communicator.\n        rank_leaders (int): The MPI rank in the ``comm_leaders`` communicator, or -1 for processes that are not group leaders.\n        nprocs_world (int): The number of MPI processes in the ``comm_world`` communicator.\n        nprocs_groups (int): The number of MPI processes in this process's worker group.\n        nprocs_leaders (int): The number of group leaders, if this process is a group leader, otherwise -1.\n        proc0_world (bool): Whether this MPI process has rank 0 in ``comm_world``.\n        proc0_groups (bool): Whether this MPI process has rank 0 in ``comm_groups``, i.e. whether this process is a group leader.\n    .\n    \"\"\"\n\n    def __init__(self,\n                 ngroups=None,\n                 comm_world=None):\n\n        self.is_apart = False\n        self.comm_world = comm_world if comm_world is not None else MPI.COMM_WORLD\n\n        self.rank_world = self.comm_world.Get_rank()\n        self.nprocs_world = self.comm_world.Get_size()\n        self.proc0_world = (self.rank_world == 0)\n\n        if ngroups is None:\n            ngroups = self.nprocs_world\n        # Force ngroups to be in the range [1, nprocs_world]\n        if ngroups < 1:\n            ngroups = 1\n            logger.info('Raising ngroups to 1')\n        if ngroups > self.nprocs_world:\n            ngroups = self.nprocs_world\n            logger.info('Lowering ngroups to {}'.format(ngroups))\n        self.ngroups = ngroups\n\n        self.group = int(\n            np.floor((self.rank_world * ngroups) / self.nprocs_world))\n\n        # Set up the \"groups\" communicator:\n        self.comm_groups = self.comm_world.Split(color=self.group,\n                                                 key=self.rank_world)\n        self.rank_groups = self.comm_groups.Get_rank()\n        self.nprocs_groups = self.comm_groups.Get_size()\n        self.proc0_groups = (self.rank_groups == 0)\n\n        # Set up the \"leaders\" communicator:\n        if self.proc0_groups:\n            color = 0\n        else:\n            color = MPI.UNDEFINED\n        self.comm_leaders = self.comm_world.Split(color=color,\n                                                  key=self.rank_world)\n        if self.proc0_groups:\n            self.rank_leaders = self.comm_leaders.Get_rank()\n            self.nprocs_leaders = self.comm_leaders.Get_size()\n        else:\n            # We are not allowed to query the rank from procs that are\n            # not members of comm_leaders.\n            self.rank_leaders = -1\n            self.nprocs_leaders = -1\n\n    def write(self):\n        \"\"\" Print info about the MPI configuration \"\"\"\n        columns = [\"rank_world\", \"nprocs_world\", \"group\", \"ngroups\",\n                   \"rank_groups\", \"nprocs_groups\", \"rank_leaders\",\n                   \"nprocs_leaders\"]\n        data = [self.rank_world, self.nprocs_world, self.group, self.ngroups,\n                self.rank_groups, self.nprocs_groups, self.rank_leaders,\n                self.nprocs_leaders]\n\n        # Each processor sends their data to proc0_world, and\n        # proc0_world writes the result to the file in order.\n        if self.proc0_world:\n            # Print header row\n            width = max(len(s) for s in columns) + 1\n            print(\",\".join(s.rjust(width) for s in columns))\n            print(\",\".join(str(s).rjust(width) for s in data))\n            for tag in range(1, self.nprocs_world):\n                data = self.comm_world.recv(tag=tag)\n                print(\",\".join(str(s).rjust(width) for s in data))\n        else:\n            tag = self.rank_world\n            self.comm_world.send(data, 0, tag)\n\n    def mobilize_leaders(self, action_const):\n        \"\"\"\n        This function is called by ``proc0_world`` to tell the other\n        group leaders that it is time to begin some action,\n        e.g. starting to calculat a finite difference Jacobian.\n        \"\"\"\n        logger.debug('mobilize_leaders, action_const={}'.format(action_const))\n        if not self.proc0_world:\n            raise RuntimeError(\n                'Only proc0_world should call mobilize_leaders()')\n\n        self.comm_leaders.bcast(action_const, root=0)\n\n    def mobilize_workers(self, action_const):\n        logger.debug('mobilize_workers, action_const={}'.format(action_const))\n        if not self.proc0_groups:\n            raise RuntimeError(\n                'Only group leaders should call mobilize_workers()')\n\n        self.comm_groups.bcast(action_const, root=0)\n\n    def stop_leaders(self):\n        logger.debug('stop_leaders')\n        if not self.proc0_world:\n            raise RuntimeError('Only proc0_world should call stop_leaders()')\n\n        data = STOP\n        self.comm_leaders.bcast(data, root=0)\n\n    def stop_workers(self):\n        logger.debug('stop_workers')\n        if not self.proc0_groups:\n            raise RuntimeError('Only proc0_groups should call stop_workers()')\n\n        data = STOP\n        self.comm_groups.bcast(data, root=0)\n\n    def leaders_loop(self, action):\n        \"\"\"\n        actions should be a dict where the keys are possible integer\n        constants, and the values are callable functions that are\n        called when the corresponding key is sent from\n        mobilize_leaders.\n        \"\"\"\n        if self.proc0_world:\n            logger.debug('proc0_world bypassing leaders_loop')\n            return\n\n        logger.debug('entering leaders_loop')\n\n        while True:\n            # Wait for proc 0 to send us something:\n            data = None\n            data = self.comm_leaders.bcast(data, root=0)\n            logger.debug(f\"leaders_loop received {data}\")\n            if data == STOP:\n                # Tell workers to stop\n                break\n\n            # Call the requested function:\n            action(self, data)\n\n        logger.debug('leaders_loop end')\n\n    def worker_loop(self, action):\n        \"\"\"\n        actions should be a dict where the keys are possible integer\n        constants, and the values are callable functions that are\n        called when the corresponding key is sent from\n        mobilize_workers.\n        \"\"\"\n        if self.proc0_groups:\n            logger.debug('bypassing worker_loop since proc0_groups')\n            return\n\n        logger.debug('entering worker_loop')\n\n        while True:\n            # Wait for the group leader to send us something:\n            data = None\n            data = self.comm_groups.bcast(data, root=0)\n            logger.debug(f'worker_loop worker received {data}')\n            if data == STOP:\n                break\n\n            # Call the requested function:\n            action(self, data)\n\n        logger.debug('worker_loop end')\n\n    def apart(self, leaders_action, workers_action):\n        \"\"\"\n        Send workers and group leaders off to their respective loops to\n        wait for instructions from their group leader or\n        proc0_world, respectively.\n        \"\"\"\n        self.is_apart = True\n        if self.proc0_world:\n            pass\n        elif self.proc0_groups:\n            self.leaders_loop(leaders_action)\n        else:\n            self.worker_loop(workers_action)\n\n    def together(self):\n        \"\"\"\n        Bring workers and group leaders back from their respective loops.\n        \"\"\"\n        if self.proc0_world:\n            self.stop_leaders()  # Proc0_world stops the leaders.\n\n        if self.proc0_groups:\n            self.stop_workers()  # All group leaders stop their workers.\n\n        self.is_apart = False",
  "def __init__(self,\n                 ngroups=None,\n                 comm_world=None):\n\n        self.is_apart = False\n        self.comm_world = comm_world if comm_world is not None else MPI.COMM_WORLD\n\n        self.rank_world = self.comm_world.Get_rank()\n        self.nprocs_world = self.comm_world.Get_size()\n        self.proc0_world = (self.rank_world == 0)\n\n        if ngroups is None:\n            ngroups = self.nprocs_world\n        # Force ngroups to be in the range [1, nprocs_world]\n        if ngroups < 1:\n            ngroups = 1\n            logger.info('Raising ngroups to 1')\n        if ngroups > self.nprocs_world:\n            ngroups = self.nprocs_world\n            logger.info('Lowering ngroups to {}'.format(ngroups))\n        self.ngroups = ngroups\n\n        self.group = int(\n            np.floor((self.rank_world * ngroups) / self.nprocs_world))\n\n        # Set up the \"groups\" communicator:\n        self.comm_groups = self.comm_world.Split(color=self.group,\n                                                 key=self.rank_world)\n        self.rank_groups = self.comm_groups.Get_rank()\n        self.nprocs_groups = self.comm_groups.Get_size()\n        self.proc0_groups = (self.rank_groups == 0)\n\n        # Set up the \"leaders\" communicator:\n        if self.proc0_groups:\n            color = 0\n        else:\n            color = MPI.UNDEFINED\n        self.comm_leaders = self.comm_world.Split(color=color,\n                                                  key=self.rank_world)\n        if self.proc0_groups:\n            self.rank_leaders = self.comm_leaders.Get_rank()\n            self.nprocs_leaders = self.comm_leaders.Get_size()\n        else:\n            # We are not allowed to query the rank from procs that are\n            # not members of comm_leaders.\n            self.rank_leaders = -1\n            self.nprocs_leaders = -1",
  "def write(self):\n        \"\"\" Print info about the MPI configuration \"\"\"\n        columns = [\"rank_world\", \"nprocs_world\", \"group\", \"ngroups\",\n                   \"rank_groups\", \"nprocs_groups\", \"rank_leaders\",\n                   \"nprocs_leaders\"]\n        data = [self.rank_world, self.nprocs_world, self.group, self.ngroups,\n                self.rank_groups, self.nprocs_groups, self.rank_leaders,\n                self.nprocs_leaders]\n\n        # Each processor sends their data to proc0_world, and\n        # proc0_world writes the result to the file in order.\n        if self.proc0_world:\n            # Print header row\n            width = max(len(s) for s in columns) + 1\n            print(\",\".join(s.rjust(width) for s in columns))\n            print(\",\".join(str(s).rjust(width) for s in data))\n            for tag in range(1, self.nprocs_world):\n                data = self.comm_world.recv(tag=tag)\n                print(\",\".join(str(s).rjust(width) for s in data))\n        else:\n            tag = self.rank_world\n            self.comm_world.send(data, 0, tag)",
  "def mobilize_leaders(self, action_const):\n        \"\"\"\n        This function is called by ``proc0_world`` to tell the other\n        group leaders that it is time to begin some action,\n        e.g. starting to calculat a finite difference Jacobian.\n        \"\"\"\n        logger.debug('mobilize_leaders, action_const={}'.format(action_const))\n        if not self.proc0_world:\n            raise RuntimeError(\n                'Only proc0_world should call mobilize_leaders()')\n\n        self.comm_leaders.bcast(action_const, root=0)",
  "def mobilize_workers(self, action_const):\n        logger.debug('mobilize_workers, action_const={}'.format(action_const))\n        if not self.proc0_groups:\n            raise RuntimeError(\n                'Only group leaders should call mobilize_workers()')\n\n        self.comm_groups.bcast(action_const, root=0)",
  "def stop_leaders(self):\n        logger.debug('stop_leaders')\n        if not self.proc0_world:\n            raise RuntimeError('Only proc0_world should call stop_leaders()')\n\n        data = STOP\n        self.comm_leaders.bcast(data, root=0)",
  "def stop_workers(self):\n        logger.debug('stop_workers')\n        if not self.proc0_groups:\n            raise RuntimeError('Only proc0_groups should call stop_workers()')\n\n        data = STOP\n        self.comm_groups.bcast(data, root=0)",
  "def leaders_loop(self, action):\n        \"\"\"\n        actions should be a dict where the keys are possible integer\n        constants, and the values are callable functions that are\n        called when the corresponding key is sent from\n        mobilize_leaders.\n        \"\"\"\n        if self.proc0_world:\n            logger.debug('proc0_world bypassing leaders_loop')\n            return\n\n        logger.debug('entering leaders_loop')\n\n        while True:\n            # Wait for proc 0 to send us something:\n            data = None\n            data = self.comm_leaders.bcast(data, root=0)\n            logger.debug(f\"leaders_loop received {data}\")\n            if data == STOP:\n                # Tell workers to stop\n                break\n\n            # Call the requested function:\n            action(self, data)\n\n        logger.debug('leaders_loop end')",
  "def worker_loop(self, action):\n        \"\"\"\n        actions should be a dict where the keys are possible integer\n        constants, and the values are callable functions that are\n        called when the corresponding key is sent from\n        mobilize_workers.\n        \"\"\"\n        if self.proc0_groups:\n            logger.debug('bypassing worker_loop since proc0_groups')\n            return\n\n        logger.debug('entering worker_loop')\n\n        while True:\n            # Wait for the group leader to send us something:\n            data = None\n            data = self.comm_groups.bcast(data, root=0)\n            logger.debug(f'worker_loop worker received {data}')\n            if data == STOP:\n                break\n\n            # Call the requested function:\n            action(self, data)\n\n        logger.debug('worker_loop end')",
  "def apart(self, leaders_action, workers_action):\n        \"\"\"\n        Send workers and group leaders off to their respective loops to\n        wait for instructions from their group leader or\n        proc0_world, respectively.\n        \"\"\"\n        self.is_apart = True\n        if self.proc0_world:\n            pass\n        elif self.proc0_groups:\n            self.leaders_loop(leaders_action)\n        else:\n            self.worker_loop(workers_action)",
  "def together(self):\n        \"\"\"\n        Bring workers and group leaders back from their respective loops.\n        \"\"\"\n        if self.proc0_world:\n            self.stop_leaders()  # Proc0_world stops the leaders.\n\n        if self.proc0_groups:\n            self.stop_workers()  # All group leaders stop their workers.\n\n        self.is_apart = False",
  "def initialize_logging(filename: str = None,\n                       level: str = None,\n                       mpi: bool = False) -> None:\n    \"\"\"\n    Initializes logging in a simple way for both serial and MPI jobs.\n    The MPI logging uses MPILogger package.\n\n    Args:\n        filename: Name of file to store the logging info\n        level: Logging level. Could be 'INFO', 'DEBUG', 'WARNING', etc.\n        mpi: If True MPI logging is used provided mpi4py is installed.\n    \"\"\"\n    yaml = YAML(typ='safe')\n    config_dict = yaml.load(Path(__file__).parent / 'log_config.yaml')\n    if filename:\n        config_dict['handlers']['file_handler'].update({'filename': filename})\n        config_dict['handlers']['mpi_file_handler'].update({'logfile': filename})\n    if level:\n        config_dict['handlers']['file_handler'].update({'level': level})\n        config_dict['handlers']['mpi_file_handler'].update({'level': level})\n    if mpi and MPI is not None:\n        config_dict['root']['handlers'].pop(2)  # Remove file hander\n    else:\n        config_dict['root']['handlers'].pop(3)  # Remove mpi hander\n        del config_dict['handlers']['mpi_file_handler']\n\n    logging.config.dictConfig(config_dict)\n\n    if mpi and MPI is None:\n        logging.warning(\"mpi4py not installed. Not able to log MPI info\")",
  "def fourier_interpolation(fk, x):\n    \"\"\"\n    Interpolate data that is known on a uniform grid in [0, 2pi).\n\n    This routine is based on the\n    matlab routine fourint.m in the DMSuite package by S.C. Reddy and J.A.C. Weideman, available at\n    http://www.mathworks.com/matlabcentral/fileexchange/29\n    or here:\n    http://dip.sun.ac.za/~weideman/research/differ.html\n\n    Args:\n        fk:  Vector of y-coordinates of data, at equidistant points\n             x(k) = (k-1)*2*pi/N,  k = 1...N\n        x:   Vector of x-values where interpolant is to be evaluated.\n\n    Returns:\n        Array of length ``len(x)`` with the interpolated values.\n    \"\"\"\n\n    N = len(fk)\n    M = len(x)\n\n    # Compute equidistant points\n    xk = (np.arange(N) * 2 * np.pi) / N\n\n    # Weights for trig interpolation\n    w = (-1.0) ** np.arange(0, N)\n\n    D = 0.5 * (np.outer(x, np.ones(N)) - np.outer(np.ones(M), xk))\n\n    if np.mod(N, 2) == 0:\n        # Formula for N even\n        D = 1 / np.tan(D + eps * (D == 0))\n    else:\n        # Formula for N odd\n        D = 1 / np.sin(D + eps * (D == 0))\n\n    # Evaluate interpolant as matrix-vector products\n    return np.dot(D, w * fk) / np.dot(D, w)",
  "def _destroy_log_comm():\n    for lc in _log_comm_list:\n        if lc.rank == 0:\n            lc.Isend([None, MPI.INT], dest=0, tag=1)\n        lc.Disconnect()",
  "class MPILogHandler(logging.Handler):\n    \"\"\"A Handler which logs messages over MPI to a single process\n    which then write them to a file.\n\n    This uses MPI-2's Dynamic Process Management to spawn a child process\n    which listens for log messages and then writes them to the specified file.\n    It checks for new messages every 0.01s.\n\n    Note\n    ----\n    This Handler also makes `rank` and `size` available in the `logger.Record`\n    for any formatter to use.\n\n    \"\"\"\n\n    def __init__(self, logfile, comm=None, *args, **kwargs):\n        \"\"\"Create the logger.\n\n        Parameters\n        ----------\n        logfile : string\n            Name of file to write.\n        comm : MPI.Intracomm\n            MPI communicator used by this logger.\n        \"\"\"\n\n        super().__init__(*args, **kwargs)\n\n        self._logfile = logfile\n\n        self._comm = MPI.COMM_WORLD if comm is None else comm\n\n        # Spawn new process for logging\n        self._log_comm = self._comm.Spawn(sys.executable, args=[__file__, self._logfile])\n\n        # Add the communicator to the list of ones to keep track of.\n        _log_comm_list.append(self._log_comm)\n\n    def __del__(self):\n        # Note this does not get called unless the Handler has been removed\n        # from the logger.\n\n        _log_comm_list.remove(self._log_comm)\n\n        if self._log_comm.rank == 0:\n            self._log_comm.Isend([None, MPI.INT], dest=0, tag=1)\n        self._log_comm.Disconnect()\n\n    def emit(self, record):\n        \"\"\"Emit the log message.\n\n        Parameters\n        ----------\n        record : logging.Record\n            logging record that will get written to disk.\n        \"\"\"\n\n        try:\n\n            record.rank = self._comm.rank\n            record.size = self._comm.size            \n\n            msg = self.format(record)\n\n            # If message too long, truncate it\n            if len(msg) > _message_maxlen:\n                msg = msg[:_message_maxlen]\n\n            msg_buf = array.array('b', msg.encode())\n\n            # Send message to the logging process\n            self._request = self._log_comm.Issend([msg_buf, MPI.CHAR], dest=0, tag=0)\n            s = MPI.Status()\n            self._request.Wait(status=s)\n\n        except (KeyboardInterrupt, SystemExit):\n            raise\n        except:\n            self.handleError(record)",
  "def __init__(self, logfile, comm=None, *args, **kwargs):\n        \"\"\"Create the logger.\n\n        Parameters\n        ----------\n        logfile : string\n            Name of file to write.\n        comm : MPI.Intracomm\n            MPI communicator used by this logger.\n        \"\"\"\n\n        super().__init__(*args, **kwargs)\n\n        self._logfile = logfile\n\n        self._comm = MPI.COMM_WORLD if comm is None else comm\n\n        # Spawn new process for logging\n        self._log_comm = self._comm.Spawn(sys.executable, args=[__file__, self._logfile])\n\n        # Add the communicator to the list of ones to keep track of.\n        _log_comm_list.append(self._log_comm)",
  "def __del__(self):\n        # Note this does not get called unless the Handler has been removed\n        # from the logger.\n\n        _log_comm_list.remove(self._log_comm)\n\n        if self._log_comm.rank == 0:\n            self._log_comm.Isend([None, MPI.INT], dest=0, tag=1)\n        self._log_comm.Disconnect()",
  "def emit(self, record):\n        \"\"\"Emit the log message.\n\n        Parameters\n        ----------\n        record : logging.Record\n            logging record that will get written to disk.\n        \"\"\"\n\n        try:\n\n            record.rank = self._comm.rank\n            record.size = self._comm.size            \n\n            msg = self.format(record)\n\n            # If message too long, truncate it\n            if len(msg) > _message_maxlen:\n                msg = msg[:_message_maxlen]\n\n            msg_buf = array.array('b', msg.encode())\n\n            # Send message to the logging process\n            self._request = self._log_comm.Issend([msg_buf, MPI.CHAR], dest=0, tag=0)\n            s = MPI.Status()\n            self._request.Wait(status=s)\n\n        except (KeyboardInterrupt, SystemExit):\n            raise\n        except:\n            self.handleError(record)",
  "def read_focus_coils(filename):\n    \"\"\"\n    Reads in the coils from a FOCUS file. For instance, this is\n    used for loading in the MUSE phased TF coils.\n\n    Args:\n        filename: String denoting the name of the coils file. \n\n    Returns:\n        coils: List of CurveXYZFourier class objects.\n        base_currents: List of Current class objects.\n        ncoils: Integer representing the number of coils.\n    \"\"\"\n    from simsopt.geo import CurveXYZFourier\n    from simsopt.field import Current\n\n    ncoils = np.loadtxt(filename, skiprows=1, max_rows=1, dtype=int)\n    order = int(np.loadtxt(filename, skiprows=8, max_rows=1, dtype=int))\n    coilcurrents = np.zeros(ncoils)\n    xc = np.zeros((ncoils, order + 1))\n    xs = np.zeros((ncoils, order + 1))\n    yc = np.zeros((ncoils, order + 1))\n    ys = np.zeros((ncoils, order + 1))\n    zc = np.zeros((ncoils, order + 1))\n    zs = np.zeros((ncoils, order + 1))\n    # load in coil currents and fourier representations of (x, y, z)\n    for i in range(ncoils):\n        coilcurrents[i] = np.loadtxt(filename, skiprows=6 + 14 * i, max_rows=1, usecols=1)\n        xc[i, :] = np.loadtxt(filename, skiprows=10 + 14 * i, max_rows=1, usecols=range(order + 1))\n        xs[i, :] = np.loadtxt(filename, skiprows=11 + 14 * i, max_rows=1, usecols=range(order + 1))\n        yc[i, :] = np.loadtxt(filename, skiprows=12 + 14 * i, max_rows=1, usecols=range(order + 1))\n        ys[i, :] = np.loadtxt(filename, skiprows=13 + 14 * i, max_rows=1, usecols=range(order + 1))\n        zc[i, :] = np.loadtxt(filename, skiprows=14 + 14 * i, max_rows=1, usecols=range(order + 1))\n        zs[i, :] = np.loadtxt(filename, skiprows=15 + 14 * i, max_rows=1, usecols=range(order + 1))\n\n    # CurveXYZFourier wants data in order sin_x, cos_x, sin_y, cos_y, ...\n    coil_data = np.zeros((order + 1, ncoils * 6))\n    for i in range(ncoils):\n        coil_data[:, i * 6 + 0] = xs[i, :]\n        coil_data[:, i * 6 + 1] = xc[i, :]\n        coil_data[:, i * 6 + 2] = ys[i, :]\n        coil_data[:, i * 6 + 3] = yc[i, :]\n        coil_data[:, i * 6 + 4] = zs[i, :]\n        coil_data[:, i * 6 + 5] = zc[i, :]\n\n    # Set the degrees of freedom in the coil objects\n    base_currents = [Current(coilcurrents[i]) for i in range(ncoils)]\n    ppp = 20\n    coils = [CurveXYZFourier(order*ppp, order) for i in range(ncoils)]\n    for ic in range(ncoils):\n        dofs = coils[ic].dofs_matrix\n        dofs[0][0] = coil_data[0, 6*ic + 1]\n        dofs[1][0] = coil_data[0, 6*ic + 3]\n        dofs[2][0] = coil_data[0, 6*ic + 5]\n        for io in range(0, min(order, coil_data.shape[0]-1)):\n            dofs[0][2*io+1] = coil_data[io+1, 6*ic + 0]\n            dofs[0][2*io+2] = coil_data[io+1, 6*ic + 1]\n            dofs[1][2*io+1] = coil_data[io+1, 6*ic + 2]\n            dofs[1][2*io+2] = coil_data[io+1, 6*ic + 3]\n            dofs[2][2*io+1] = coil_data[io+1, 6*ic + 4]\n            dofs[2][2*io+2] = coil_data[io+1, 6*ic + 5]\n        coils[ic].local_x = np.concatenate(dofs)\n    return coils, base_currents, ncoils",
  "def coil_optimization(s, bs, base_curves, curves, out_dir=''):\n    \"\"\"\n    Optimize the coils for the QA, QH, or other configurations.\n\n    Args:\n        s: plasma boundary.\n        bs: Biot Savart class object, presumably representing the\n          magnetic fields generated by the coils.\n        base_curves: List of CurveXYZFourier class objects.\n        curves: List of Curve class objects.\n        out_dir: Path or string for the output directory for saved files.\n\n    Returns:\n        bs: Biot Savart class object, presumably representing the\n          OPTIMIZED magnetic fields generated by the coils.\n    \"\"\"\n\n    from simsopt.geo import CurveLength, CurveCurveDistance, \\\n        MeanSquaredCurvature, LpCurveCurvature, CurveSurfaceDistance\n    from simsopt.objectives import QuadraticPenalty\n    from simsopt.geo import curves_to_vtk\n    from simsopt.objectives import SquaredFlux\n\n    out_dir = Path(out_dir)\n    nphi = len(s.quadpoints_phi)\n    ntheta = len(s.quadpoints_theta)\n    ncoils = len(base_curves)\n\n    # Weight on the curve lengths in the objective function:\n    LENGTH_WEIGHT = 1e-4\n\n    # Threshold and weight for the coil-to-coil distance penalty in the objective function:\n    CC_THRESHOLD = 0.1\n    CC_WEIGHT = 1e-1\n\n    # Threshold and weight for the coil-to-surface distance penalty in the objective function:\n    CS_THRESHOLD = 0.1\n    CS_WEIGHT = 1e-2\n\n    # Threshold and weight for the curvature penalty in the objective function:\n    CURVATURE_THRESHOLD = 0.1\n    CURVATURE_WEIGHT = 1e-9\n\n    # Threshold and weight for the mean squared curvature penalty in the objective function:\n    MSC_THRESHOLD = 0.1\n    MSC_WEIGHT = 1e-9\n\n    MAXITER = 500  # number of iterations for minimize\n\n    # Define the objective function:\n    Jf = SquaredFlux(s, bs)\n    Jls = [CurveLength(c) for c in base_curves]\n    Jccdist = CurveCurveDistance(curves, CC_THRESHOLD, num_basecurves=ncoils)\n    Jcsdist = CurveSurfaceDistance(curves, s, CS_THRESHOLD)\n    Jcs = [LpCurveCurvature(c, 2, CURVATURE_THRESHOLD) for c in base_curves]\n    Jmscs = [MeanSquaredCurvature(c) for c in base_curves]\n\n    # Form the total objective function.\n    JF = Jf \\\n        + LENGTH_WEIGHT * sum(Jls) \\\n        + CC_WEIGHT * Jccdist \\\n        + CS_WEIGHT * Jcsdist \\\n        + CURVATURE_WEIGHT * sum(Jcs) \\\n        + MSC_WEIGHT * sum(QuadraticPenalty(J, MSC_THRESHOLD) for J in Jmscs)\n\n    def fun(dofs):\n        \"\"\" Function for coil optimization grabbed from stage_two_optimization.py \"\"\"\n        JF.x = dofs\n        J = JF.J()\n        grad = JF.dJ()\n        jf = Jf.J()\n        BdotN = np.mean(np.abs(np.sum(bs.B().reshape((nphi, ntheta, 3)) * s.unitnormal(), axis=2)))\n        outstr = f\"J={J:.1e}, Jf={jf:.1e}, \u27e8B\u00b7n\u27e9={BdotN:.1e}\"\n        cl_string = \", \".join([f\"{J.J():.1f}\" for J in Jls])\n        kap_string = \", \".join(f\"{np.max(c.kappa()):.1f}\" for c in base_curves)\n        msc_string = \", \".join(f\"{J.J():.1f}\" for J in Jmscs)\n        outstr += f\", Len=sum([{cl_string}])={sum(J.J() for J in Jls):.1f}, \u03f0=[{kap_string}], \u222b\u03f0\u00b2/L=[{msc_string}]\"\n        outstr += f\", C-C-Sep={Jccdist.shortest_distance():.2f}, C-S-Sep={Jcsdist.shortest_distance():.2f}\"\n        outstr += f\", \u2551\u2207J\u2551={np.linalg.norm(grad):.1e}\"\n        print(outstr)\n        return J, grad\n\n    print(\"\"\"\n    ################################################################################\n    ### Perform a Taylor test ######################################################\n    ################################################################################\n    \"\"\")\n    f = fun\n    dofs = JF.x\n    np.random.seed(1)\n    h = np.random.uniform(size=dofs.shape)\n\n    J0, dJ0 = f(dofs)\n    dJh = sum(dJ0 * h)\n    for eps in [1e-3, 1e-4, 1e-5, 1e-6, 1e-7]:\n        J1, _ = f(dofs + eps*h)\n        J2, _ = f(dofs - eps*h)\n        print(\"err\", (J1-J2)/(2*eps) - dJh)\n\n    print(\"\"\"\n    ################################################################################\n    ### Run the optimisation #######################################################\n    ################################################################################\n    \"\"\")\n    res = minimize(fun, dofs, jac=True, method='L-BFGS-B', options={'maxiter': MAXITER, 'maxcor': 300}, tol=1e-15)\n    curves_to_vtk(curves, out_dir / \"curves_opt\")\n    bs.set_points(s.gamma().reshape((-1, 3)))\n    return bs",
  "def trace_fieldlines(bfield, label, s, comm, out_dir=''):\n    \"\"\"\n    Make Poincare plots on a surface as in the trace_fieldlines\n    example in the examples/1_Simple/ directory.\n\n    Args:\n        bfield: MagneticField or InterpolatedField class object.\n        label: Name of the file to write to.\n        s: plasma boundary surface.\n        comm: MPI COMM_WORLD object for using MPI for tracing.\n        out_dir: Path or string for the output directory for saved files.\n    \"\"\"\n    from simsopt.field.tracing import particles_to_vtk, compute_fieldlines, \\\n        LevelsetStoppingCriterion, plot_poincare_data, \\\n        IterationStoppingCriterion, SurfaceClassifier\n\n    out_dir = Path(out_dir)\n\n    # set fieldline tracer parameters\n    nfieldlines = 4\n    tmax_fl = 10000\n\n    R0 = np.linspace(s.get_rc(0, 0), s.get_rc(0, 0) + s.get_rc(1, 0) / 2.0, nfieldlines)\n    Z0 = np.zeros(nfieldlines)\n    phis = [(i / 4) * (2 * np.pi / s.nfp) for i in range(4)]\n\n    # compute the fieldlines from the initial locations specified above\n    sc_fieldline = SurfaceClassifier(s, h=0.05, p=2)\n    sc_fieldline.to_vtk(str(out_dir) + 'levelset', h=0.02)\n\n    fieldlines_tys, fieldlines_phi_hits = compute_fieldlines(\n        bfield, R0, Z0, tmax=tmax_fl, tol=1e-16, comm=comm,\n        phis=phis,  # stopping_criteria=[LevelsetStoppingCriterion(sc_fieldline.dist)])\n        stopping_criteria=[IterationStoppingCriterion(20000)])\n\n    # make the poincare plots\n    if comm is None or comm.rank == 0:\n        plot_poincare_data(fieldlines_phi_hits, phis, out_dir / f'poincare_fieldline_{label}.png', dpi=100, surf=s)",
  "def make_qfm(s, Bfield):\n    \"\"\"\n    Given some Bfield generated by dipoles AND a set of TF coils, \n    compute a quadratic flux-minimizing surface (QFMS)\n    for the total field configuration on the surface s.\n\n    Args:\n        s: plasma boundary surface.\n        Bfield: MagneticField or inherited MagneticField class object.\n\n    Returns:\n        qfm_surface: The identified QfmSurface class object.\n    \"\"\"\n    from simsopt.geo.qfmsurface import QfmSurface\n    from simsopt.geo.surfaceobjectives import QfmResidual, ToroidalFlux, Area, Volume\n\n    # weight for the optimization\n    constraint_weight = 1e0\n\n    # First optimize at fixed volume\n    qfm = QfmResidual(s, Bfield)\n    qfm.J()\n\n    # s.change_resolution(16, 16)\n    vol = Volume(s)\n    vol_target = vol.J()\n    qfm_surface = QfmSurface(Bfield, s, vol, vol_target)\n\n    res = qfm_surface.minimize_qfm_penalty_constraints_LBFGS(tol=1e-20, maxiter=50,\n                                                             constraint_weight=constraint_weight)\n    print(f\"||vol constraint||={0.5*(s.volume()-vol_target)**2:.8e}, ||residual||={np.linalg.norm(qfm.J()):.8e}\")\n\n    # repeat the optimization for further convergence\n    res = qfm_surface.minimize_qfm_penalty_constraints_LBFGS(tol=1e-20, maxiter=200,\n                                                             constraint_weight=constraint_weight)\n    print(f\"||vol constraint||={0.5*(s.volume()-vol_target)**2:.8e}, ||residual||={np.linalg.norm(qfm.J()):.8e}\")\n    return qfm_surface",
  "def initialize_coils(config_flag, TEST_DIR, s, out_dir=''):\n    \"\"\"\n    Initializes coils for each of the target configurations that are\n    used for permanent magnet optimization.\n\n    Args:\n        config_flag: String denoting the stellarator configuration \n          being initialized.\n        TEST_DIR: String denoting where to find the input files.\n        out_dir: Path or string for the output directory for saved files.\n        s: plasma boundary surface.\n    Returns:\n        base_curves: List of CurveXYZ class objects.\n        curves: List of Curve class objects.\n        coils: List of Coil class objects.\n    \"\"\"\n    from simsopt.geo import create_equally_spaced_curves\n    from simsopt.field import Current, Coil, coils_via_symmetries\n    from simsopt.geo import curves_to_vtk\n\n    out_dir = Path(out_dir)\n    if 'muse' in config_flag:\n        # Load in pre-optimized coils\n        coils_filename = TEST_DIR / 'muse_tf_coils.focus'\n        base_curves, base_currents, ncoils = read_focus_coils(coils_filename)\n        coils = []\n        for i in range(ncoils):\n            coils.append(Coil(base_curves[i], base_currents[i]))\n        base_currents[0].fix_all()\n\n        # fix all the coil shapes\n        for i in range(ncoils):\n            base_curves[i].fix_all()\n    elif config_flag == 'qh':\n        # generate planar TF coils\n        ncoils = 4\n        R0 = s.get_rc(0, 0)\n        R1 = s.get_rc(1, 0) * 2\n        order = 5\n\n        # qh needs to be scaled to 0.1 T on-axis magnetic field strength\n        from simsopt.mhd.vmec import Vmec\n        vmec_file = 'wout_LandremanPaul2021_QH_reactorScale_lowres_reference.nc'\n        total_current = Vmec(TEST_DIR / vmec_file).external_current() / (2 * s.nfp) / 8.75 / 5.69674966667\n        base_curves = create_equally_spaced_curves(ncoils, s.nfp, stellsym=True, R0=R0, R1=R1, order=order, numquadpoints=128)\n        base_currents = [(Current(total_current / ncoils * 1e-5) * 1e5) for _ in range(ncoils-1)]\n        total_current = Current(total_current)\n        total_current.fix_all()\n        base_currents += [total_current - sum(base_currents)]\n        coils = coils_via_symmetries(base_curves, base_currents, s.nfp, True)\n\n        # fix all the coil shapes so only the currents are optimized\n        for i in range(ncoils):\n            base_curves[i].fix_all()\n    elif config_flag == 'qa':\n        # generate planar TF coils\n        ncoils = 8\n        R0 = 1.0\n        R1 = 0.65\n        order = 5\n\n        # qa needs to be scaled to 0.1 T on-axis magnetic field strength\n        from simsopt.mhd.vmec import Vmec\n        vmec_file = 'wout_LandremanPaul2021_QA_lowres.nc'\n        total_current = Vmec(TEST_DIR / vmec_file).external_current() / (2 * s.nfp) / 7.131\n        base_curves = create_equally_spaced_curves(ncoils, s.nfp, stellsym=True, R0=R0, R1=R1, order=order, numquadpoints=128)\n        base_currents = [(Current(total_current / ncoils * 1e-5) * 1e5) for _ in range(ncoils-1)]\n        total_current = Current(total_current)\n        total_current.fix_all()\n        base_currents += [total_current - sum(base_currents)]\n        coils = coils_via_symmetries(base_curves, base_currents, s.nfp, True)\n        # fix all the coil shapes so only the currents are optimized\n        for i in range(ncoils):\n            base_curves[i].fix_all()\n\n    # Initialize the coil curves and save the data to vtk\n    curves = [c.curve for c in coils]\n    curves_to_vtk(curves, out_dir / \"curves_init\")\n    return base_curves, curves, coils",
  "def calculate_on_axis_B(bs, s):\n    \"\"\"\n    Check the average, approximate, on-axis\n    magnetic field strength to make sure the\n    configuration is scaled correctly.\n\n    Args:\n        bs: MagneticField or BiotSavart class object.\n        s: plasma boundary surface.\n\n    Returns:\n        B0avg: Average magnetic field strength along \n          the major radius of the device.\n    \"\"\"\n    nphi = len(s.quadpoints_phi)\n    bspoints = np.zeros((nphi, 3))\n\n    # rescale phi from [0, 1) to [0, 2 * pi)\n    phi = s.quadpoints_phi * 2 * np.pi\n\n    R0 = s.get_rc(0, 0)\n    for i in range(nphi):\n        bspoints[i] = np.array([R0 * np.cos(phi[i]),\n                                R0 * np.sin(phi[i]),\n                                0.0]\n                               )\n    bs.set_points(bspoints)\n    B0 = np.linalg.norm(bs.B(), axis=-1)\n    B0avg = np.mean(np.linalg.norm(bs.B(), axis=-1))\n    surface_area = s.area()\n    bnormalization = B0avg * surface_area\n    print(\"Bmag at R = \", R0, \", Z = 0: \", B0)\n    print(\"toroidally averaged Bmag at R = \", R0, \", Z = 0: \", B0avg)\n    return B0avg",
  "def make_optimization_plots(RS_history, m_history, m_proxy_history, pm_opt, out_dir=''):\n    \"\"\"\n    Make line plots of the algorithm convergence and make histograms\n    of m, m_proxy, and if available, the FAMUS solution.\n\n    Args:\n        RS_history: List of the relax-and-split optimization progress.\n        m_history: List of the permanent magnet solutions generated\n          as the relax-and-split optimization progresses.\n        m_proxy_history: Same but for the 'proxy' variable in the\n          relax-and-split optimization.\n        pm_opt: PermanentMagnetGrid class object that was optimized.\n        out_dir: Path or string for the output directory for saved files.\n    \"\"\"\n    out_dir = Path(out_dir)\n\n    # Make plot of the relax-and-split convergence\n    plt.figure()\n    plt.plot(RS_history)\n    plt.yscale('log')\n    plt.grid(True)\n    plt.savefig(out_dir / 'RS_objective_history.png')\n\n    # make histogram of the dipoles, normalized by their maximum values\n    plt.figure()\n    m0_abs = np.sqrt(np.sum(pm_opt.m.reshape(pm_opt.ndipoles, 3) ** 2, axis=-1)) / pm_opt.m_maxima\n    mproxy_abs = np.sqrt(np.sum(pm_opt.m_proxy.reshape(pm_opt.ndipoles, 3) ** 2, axis=-1)) / pm_opt.m_maxima\n\n    # get FAMUS rho values for making comparison histograms\n    if hasattr(pm_opt, 'famus_filename'):\n        m0, p = np.loadtxt(\n            pm_opt.famus_filename, skiprows=3,\n            usecols=[7, 8],\n            delimiter=',', unpack=True\n        )\n        # momentq = 4 for NCSX but always = 1 for MUSE and recent FAMUS runs\n        momentq = np.loadtxt(pm_opt.famus_filename, skiprows=1, max_rows=1, usecols=[1])\n        rho = p ** momentq\n        rho = rho[pm_opt.Ic_inds]\n        x_multi = [m0_abs, mproxy_abs, abs(rho)]\n    else:\n        x_multi = [m0_abs, mproxy_abs]\n        rho = None\n    plt.hist(x_multi, bins=np.linspace(0, 1, 40), log=True, histtype='bar')\n    plt.grid(True)\n    plt.legend(['m', 'w', 'FAMUS'])\n    plt.xlabel('Normalized magnitudes')\n    plt.ylabel('Number of dipoles')\n    plt.savefig(out_dir / 'm_histograms.png')\n\n    # If relax-and-split was used with l0 norm,\n    # make a nice histogram of the algorithm progress\n    if len(RS_history) != 0:\n\n        m_history = np.array(m_history)\n        m_history = m_history.reshape(m_history.shape[0] * m_history.shape[1], pm_opt.ndipoles, 3)\n        m_proxy_history = np.array(m_proxy_history).reshape(m_history.shape[0], pm_opt.ndipoles, 3)\n\n        for i, datum in enumerate([m_history, m_proxy_history]):\n            # Code from https://matplotlib.org/stable/gallery/animation/animated_histogram.html\n            def prepare_animation(bar_container):\n                def animate(frame_number):\n                    plt.title(frame_number)\n                    data = np.sqrt(np.sum(datum[frame_number, :] ** 2, axis=-1)) / pm_opt.m_maxima\n                    n, _ = np.histogram(data, np.linspace(0, 1, 40))\n                    for count, rect in zip(n, bar_container.patches):\n                        rect.set_height(count)\n                    return bar_container.patches\n                return animate\n\n            # make histogram animation of the dipoles at each relax-and-split save\n            fig, ax = plt.subplots()\n            data = np.sqrt(np.sum(datum[0, :] ** 2, axis=-1)) / pm_opt.m_maxima\n            if rho is not None:\n                ax.hist(abs(rho), bins=np.linspace(0, 1, 40), log=True, alpha=0.6, color='g')\n            _, _, bar_container = ax.hist(data, bins=np.linspace(0, 1, 40), log=True, alpha=0.6, color='r')\n            ax.set_ylim(top=1e5)  # set safe limit to ensure that all data is visible.\n            plt.grid(True)\n            if rho is not None:\n                plt.legend(['FAMUS', np.array([r'm$^*$', r'w$^*$'])[i]])\n            else:\n                plt.legend([np.array([r'm$^*$', r'w$^*$'])[i]])\n\n            plt.xlabel('Normalized magnitudes')\n            plt.ylabel('Number of dipoles')\n            ani = animation.FuncAnimation(\n                fig, prepare_animation(bar_container),\n                range(0, m_history.shape[0], 2),\n                repeat=False, blit=True\n            )",
  "def run_Poincare_plots(s_plot, bs, b_dipole, comm, filename_poincare, out_dir=''):\n    \"\"\"\n    Wrapper function for making Poincare plots.\n\n    Args:\n        s_plot: plasma boundary surface with range = 'full torus'.\n        bs: MagneticField class object.\n        b_dipole: DipoleField class object.\n        comm: MPI COMM_WORLD object for using MPI for tracing.\n        filename_poincare: Filename for the output poincare picture.\n        out_dir: Path or string for the output directory for saved files.\n    \"\"\"\n    from simsopt.field.magneticfieldclasses import InterpolatedField\n    from simsopt.objectives import SquaredFlux\n\n    out_dir = Path(out_dir)\n\n    n = 32\n    rs = np.linalg.norm(s_plot.gamma()[:, :, 0:2], axis=2)\n    zs = s_plot.gamma()[:, :, 2]\n    r_margin = 0.05\n    rrange = (np.min(rs) - r_margin, np.max(rs) + r_margin, n)\n    phirange = (0, 2 * np.pi / s_plot.nfp, n * 2)\n    zrange = (0, np.max(zs), n // 2)\n    degree = 4  # 2 is sufficient sometimes\n    nphi = len(s_plot.quadpoints_phi)\n    ntheta = len(s_plot.quadpoints_theta)\n    bs.set_points(s_plot.gamma().reshape((-1, 3)))\n    b_dipole.set_points(s_plot.gamma().reshape((-1, 3)))\n    Bnormal = np.sum(bs.B().reshape((nphi, ntheta, 3)) * s_plot.unitnormal(), axis=2)\n    Bnormal_dipole = np.sum(b_dipole.B().reshape((nphi, ntheta, 3)) * s_plot.unitnormal(), axis=2)\n    f_B = SquaredFlux(s_plot, b_dipole, -Bnormal).J()\n    make_Bnormal_plots(bs, s_plot, out_dir, \"biot_savart_pre_poincare_check\")\n    make_Bnormal_plots(b_dipole, s_plot, out_dir, \"dipole_pre_poincare_check\")\n    make_Bnormal_plots(bs + b_dipole, s_plot, out_dir, \"total_pre_poincare_check\")\n\n    bsh = InterpolatedField(\n        bs + b_dipole, degree, rrange, phirange, zrange, True, nfp=s_plot.nfp, stellsym=s_plot.stellsym\n    )\n    bsh.set_points(s_plot.gamma().reshape((-1, 3)))\n    trace_fieldlines(bsh, 'bsh_PMs_' + filename_poincare, s_plot, comm, out_dir)",
  "def make_Bnormal_plots(bs, s_plot, out_dir='', bs_filename=\"Bnormal\"):\n    \"\"\"\n    Plot Bnormal on plasma surface from a MagneticField object.\n    Do this quite a bit in the permanent magnet optimization\n    and initialization so this is a wrapper function to reduce\n    the amount of code.\n\n    Args:\n        bs: MagneticField class object.\n        s_plot: plasma boundary surface with range = 'full torus'.\n        out_dir: Path or string for the output directory for saved files.\n        bs_filename: String denoting the name of the output file. \n    \"\"\"\n    out_dir = Path(out_dir)\n    nphi = len(s_plot.quadpoints_phi)\n    ntheta = len(s_plot.quadpoints_theta)\n    bs.set_points(s_plot.gamma().reshape((-1, 3)))\n    pointData = {\"B_N\": np.sum(bs.B().reshape((nphi, ntheta, 3)) * s_plot.unitnormal(), axis=2)[:, :, None]}\n    s_plot.to_vtk(out_dir / bs_filename, extra_data=pointData)",
  "def initialize_default_kwargs(algorithm='RS'):\n    \"\"\"\n    Keywords to the permanent magnet optimizers are now passed\n    by the kwargs dictionary. Default dictionaries are initialized\n    here.\n\n    Args:\n        algorithm: String denoting which algorithm is being used\n          for permanent magnet optimization. Options are 'RS'\n          (relax and split), 'GPMO' (greedy placement), \n          'backtracking' (GPMO with backtracking), \n          'multi' (GPMO, placing multiple magnets each iteration),\n          'ArbVec' (GPMO with arbitrary dipole orientiations),\n          'ArbVec_backtracking' (GPMO with backtracking and \n          arbitrary dipole orientations).\n\n    Returns:\n        kwargs: Dictionary of keywords to pass to a permanent magnet \n          optimizer.\n    \"\"\"\n\n    kwargs = {}\n    kwargs['verbose'] = True   # print out errors every few iterations\n    if algorithm == 'RS':\n        kwargs['nu'] = 1e100  # Strength of the \"relaxation\" part of relax-and-split\n        kwargs['max_iter'] = 100  # Number of iterations to take in a convex step\n        kwargs['reg_l0'] = 0.0\n        kwargs['reg_l1'] = 0.0\n        kwargs['alpha'] = 0.0\n        kwargs['min_fb'] = 0.0\n        kwargs['epsilon'] = 1e-3\n        kwargs['epsilon_RS'] = 1e-3\n        kwargs['max_iter_RS'] = 2  # Number of total iterations of the relax-and-split algorithm\n        kwargs['reg_l2'] = 0.0\n    elif 'GPMO' in algorithm or 'ArbVec' in algorithm:\n        kwargs['K'] = 1000\n        kwargs[\"reg_l2\"] = 0.0 \n        kwargs['nhistory'] = 500  # K > nhistory and nhistory must be divisor of K\n    return kwargs",
  "def fun(dofs):\n        \"\"\" Function for coil optimization grabbed from stage_two_optimization.py \"\"\"\n        JF.x = dofs\n        J = JF.J()\n        grad = JF.dJ()\n        jf = Jf.J()\n        BdotN = np.mean(np.abs(np.sum(bs.B().reshape((nphi, ntheta, 3)) * s.unitnormal(), axis=2)))\n        outstr = f\"J={J:.1e}, Jf={jf:.1e}, \u27e8B\u00b7n\u27e9={BdotN:.1e}\"\n        cl_string = \", \".join([f\"{J.J():.1f}\" for J in Jls])\n        kap_string = \", \".join(f\"{np.max(c.kappa()):.1f}\" for c in base_curves)\n        msc_string = \", \".join(f\"{J.J():.1f}\" for J in Jmscs)\n        outstr += f\", Len=sum([{cl_string}])={sum(J.J() for J in Jls):.1f}, \u03f0=[{kap_string}], \u222b\u03f0\u00b2/L=[{msc_string}]\"\n        outstr += f\", C-C-Sep={Jccdist.shortest_distance():.2f}, C-S-Sep={Jcsdist.shortest_distance():.2f}\"\n        outstr += f\", \u2551\u2207J\u2551={np.linalg.norm(grad):.1e}\"\n        print(outstr)\n        return J, grad",
  "def prepare_animation(bar_container):\n                def animate(frame_number):\n                    plt.title(frame_number)\n                    data = np.sqrt(np.sum(datum[frame_number, :] ** 2, axis=-1)) / pm_opt.m_maxima\n                    n, _ = np.histogram(data, np.linspace(0, 1, 40))\n                    for count, rect in zip(n, bar_container.patches):\n                        rect.set_height(count)\n                    return bar_container.patches\n                return animate",
  "def animate(frame_number):\n                    plt.title(frame_number)\n                    data = np.sqrt(np.sum(datum[frame_number, :] ** 2, axis=-1)) / pm_opt.m_maxima\n                    n, _ = np.histogram(data, np.linspace(0, 1, 40))\n                    for count, rect in zip(n, bar_container.patches):\n                        rect.set_height(count)\n                    return bar_container.patches",
  "def faceedge_vectors(theta):\n    \"\"\"\n    Generates an array of unit vectors for a set of face-edge polarizations\n    defined by the polar angle theta with respect to the nearest face-normal\n    vector.\n\n    Args:\n        theta: double\n            Polar angle theta between polarizations and nearest face-normal vector\n    \"\"\"\n\n    # Unique vector component magnitudes\n    comp_1 = np.sin(theta)\n    comp_2 = np.cos(theta)\n\n    vectors_pos = np.array([[comp_1, comp_2, 0],\n                            [comp_1, -comp_2, 0],\n                            [comp_1, 0, comp_2],\n                            [comp_1, 0, -comp_2],\n                            [comp_2, comp_1, 0],\n                            [-comp_2, comp_1, 0],\n                            [0, comp_1, comp_2],\n                            [0, comp_1, -comp_2],\n                            [comp_2, 0, comp_1],\n                            [-comp_2, 0, comp_1],\n                            [0, comp_2, comp_1],\n                            [0, -comp_2, comp_1]]\n                           ) \n\n    return np.concatenate((vectors_pos, -vectors_pos), axis=0)",
  "def facecorner_vectors(theta):\n    \"\"\"\n    Generates an array of unit vectors for a set of face-corner polarizations\n    defined by the polar angle theta with respect to the nearest face-normal\n    vector.\n\n    Args:\n        theta: polar angle theta with respect to the nearest face-normal vector.\n    \"\"\"\n\n    # Unique vector component magnitudes\n    comp_1 = np.sin(theta) / np.sqrt(2.0)\n    comp_2 = np.cos(theta)\n\n    vectors_pos = np.array([[comp_1, comp_1, comp_2],\n                            [comp_1, -comp_1, comp_2],\n                            [-comp_1, -comp_1, comp_2],\n                            [-comp_1, comp_1, comp_2],\n                            [comp_1, comp_2, comp_1],\n                            [comp_1, comp_2, -comp_1],\n                            [-comp_1, comp_2, -comp_1],\n                            [-comp_1, comp_2, comp_1],\n                            [comp_2, comp_1, comp_1],\n                            [comp_2, comp_1, -comp_1],\n                            [comp_2, -comp_1, -comp_1],\n                            [comp_2, -comp_1, comp_1]]\n                           )\n\n    return np.concatenate((vectors_pos, -vectors_pos), axis=0)",
  "def face_triplet(theta_fe, theta_fc):\n    \"\"\"\n    Generates a set of vectors corresponding to the \"face-triplet\" set of \n    polarization types: face, face-edge, and face-corner.\n\n    Args: \n        theta_fe: double\n            Angle with respect to the nearest face-normal for the face-edge type\n        theta_fc: double\n            Angle with respect to the nearest face-normal for face-corner type\n\n    Returns:\n        vectors: double array\n            3-column array in which each row is one unit vector in the full set\n    \"\"\"\n    return np.concatenate((pol_f, faceedge_vectors(theta_fe),\n                           facecorner_vectors(theta_fc)), \n                          axis=0\n                          )",
  "def edge_triplet(theta_fe, theta_fc):\n    \"\"\"\n    Generates a set of vectors corresponding to the \"edge-triplet\" set of \n    polarization types: edge, face-edge, and face-corner.\n\n    Args:\n        theta_fe: double\n            Angle with respect to the nearest face-normal for the face-edge type\n        theta_fc: double\n            Angle with respect to the nearest face-normal for face-corner type\n\n    Returns:\n        vectors: double array\n            3-column array in which each row is one unit vector in the full set\n    \"\"\"\n    return np.concatenate((pol_e, faceedge_vectors(theta_fe),\n                           facecorner_vectors(theta_fc)), \n                          axis=0\n                          )",
  "def orientation_phi(corners_fname):\n    \"\"\"\n    Determines the azimuthal (phi) angle that sets the orientations of\n    rectangular prisms from an arrangement based on data from the corners file\n\n    Phi is the azimuthal angle of the normal vector of the face whose normal\n    vector is in the \"radial-like\" direction with a polar angle of pi/2 radians\n    (i.e., parallel to the x-y plane). The remaining faces will be assumed to\n    have normal vectors in either:\n\n        #. the z-direction, or\n        #. parallel to the x-y plane with an azimuthal angle equal to the \n           orientation phi plus pi/2 radians (the \"phi-like\" direction).\n\n    Args:\n        corners_fname (string): Corners file\n\n    Returns:\n        orientation_phi (double array): Orientation phi angle (radians) of each prism in the arrangement\n    \"\"\"\n\n    corners_data = np.loadtxt(corners_fname, delimiter=',')\n\n    xib = corners_data[:, ind_xib]\n    yib = corners_data[:, ind_yib]\n    xob = corners_data[:, ind_xob]\n    yob = corners_data[:, ind_yob]\n\n    dx = xob-xib\n    dy = yob-yib\n\n    return np.arctan2(dy, dx)",
  "def polarization_axes(polarizations):\n    \"\"\"\n    Populates an array of allowable polarization vectors based on an input\n    list of names. Also outputs a 1D array with an integer corresponding\n    to the polarization type in the order it appears in the list of names.\n\n    Args:\n        polarizations: list of strings\n            List of names of polarization types. Each type should not be listed\n            more than once\n\n    Returns:\n        pol_axes: 2d double array\n            Allowable axes for the magnets expressed as unit vectors in local\n            cylindrical coordinates. The first, second, and third columns \n            contain the r, phi, and z components, respectively.\n        pol_type: 1d integer array\n            ID number for the polarization type associated with each row\n            in pol_axes. The ID corresponds to the order in which the type\n            appears in the input list (polarizations). The first type is given\n            an ID of 1.\n    \"\"\"\n\n    pol_axes = np.zeros((0, 3))\n    pol_type = np.zeros(0, dtype=int)\n    first_row = 0\n    i = 0\n    if not isinstance(polarizations, list):\n        polarizations = [polarizations]\n    for pol_name in polarizations:\n        if pol_name.lower() == 'face':\n            pol_axes = np.concatenate((pol_axes, pol_f), axis=0)\n            n_polarizations = np.shape(pol_f)[0]\n        elif pol_name.lower() == 'edge':\n            pol_axes = np.concatenate((pol_axes, pol_e), axis=0)\n            n_polarizations = np.shape(pol_e)[0]\n        elif pol_name.lower() == 'corner':\n            pol_axes = np.concatenate((pol_axes, pol_c), axis=0)\n            n_polarizations = np.shape(pol_c)[0]\n        elif pol_name.lower() == 'faceedge':\n            pol_axes = np.concatenate((pol_axes, pol_fe), axis=0)\n            n_polarizations = np.shape(pol_fe)[0]\n        elif pol_name.lower() == 'facecorner':\n            pol_axes = np.concatenate((pol_axes, pol_fc), axis=0)\n            n_polarizations = np.shape(pol_fc)[0]\n        elif pol_name.lower() == 'edgecorner':\n            pol_axes = np.concatenate((pol_axes, pol_ec), axis=0)\n            n_polarizations = np.shape(pol_ec)[0]\n        elif pol_name.lower() == 'fe17':\n            pol_axes = np.concatenate((pol_axes, pol_fe17), axis=0)\n            n_polarizations = np.shape(pol_fe17)[0]\n        elif pol_name.lower() == 'fe23':\n            pol_axes = np.concatenate((pol_axes, pol_fe23), axis=0)\n            n_polarizations = np.shape(pol_fe23)[0]\n        elif pol_name.lower() == 'fe30':\n            pol_axes = np.concatenate((pol_axes, pol_fe30), axis=0)\n            n_polarizations = np.shape(pol_fe30)[0]\n        elif pol_name.lower() == 'fc27':\n            pol_axes = np.concatenate((pol_axes, pol_fc27), axis=0)\n            n_polarizations = np.shape(pol_fc27)[0]\n        elif pol_name.lower() == 'fc39':\n            pol_axes = np.concatenate((pol_axes, pol_fc39), axis=0)\n            n_polarizations = np.shape(pol_fc39)[0]\n        elif pol_name.lower() == 'ec23':\n            pol_axes = np.concatenate((pol_axes, pol_ec23), axis=0)\n            n_polarizations = np.shape(pol_ec23)[0]\n        elif pol_name.lower() == 'fe_ftri':\n            vectors = faceedge_vectors(theta_fe_ftri)\n            pol_axes = np.concatenate((pol_axes, vectors), axis=0)\n            n_polarizations = np.shape(vectors)[0]\n        elif pol_name.lower() == 'fc_ftri':\n            vectors = facecorner_vectors(theta_fc_ftri)\n            pol_axes = np.concatenate((pol_axes, vectors), axis=0)\n            n_polarizations = np.shape(vectors)[0]\n        elif pol_name.lower() == 'fe_etri':\n            vectors = faceedge_vectors(theta_fe_etri)\n            pol_axes = np.concatenate((pol_axes, vectors), axis=0)\n            n_polarizations = np.shape(vectors)[0]\n        elif pol_name.lower() == 'fc_etri':\n            vectors = facecorner_vectors(theta_fc_etri)\n            pol_axes = np.concatenate((pol_axes, vectors), axis=0)\n            n_polarizations = np.shape(vectors)[0]\n        else:\n            raise ValueError('polarization_axes: Polarization type ' + \n                             pol_name + ' is not recognized or supported.')\n\n        i = i + 1\n        pol_type = np.concatenate((pol_type, i * np.ones(n_polarizations)))\n\n    return pol_axes, pol_type",
  "def discretize_polarizations(mag_data, orientation_phi, pol_axes, pol_type):\n    \"\"\"\n    Adjusts the polarization axes of a set of dipole moments to the closest\n    from a set of allowable axes. \n\n    Also populates the pol_x, pol_y, pol_z, and pol_id arrays within the\n    input instance of the mag_data class, providing all of the allowable \n    polarization vectors for each magnet in the lab frame.\n\n    Args:\n        mag_data: mag_data object\n            Instance of the mag_data class characterizing the dipole moments\n            of a set of magnets, whose orientations are to be updated.\n        orientation_phi: double array\n            Orientation angle defining a reference axes for the allowable axes\n            for each respective magnet (as described in the documentation for \n            orientation_phi().) Number of elements must agree with the number\n            of magnets in mag_data.\n        pol_axes: double array with 3 columns \n            Set of Cartesian unit vectors defining the allowable polarization\n            vectors for each magnet. The first, second, and third columns \n            contain the x, y, and z components, respectively.\n        pol_type: integer array\n            Type IDs corresponding to each row in pol_axes.\n    \"\"\"\n\n    nMagnets = mag_data.nMagnets\n    nPol = pol_axes.shape[0]\n    mag_data.init_pol_vecs(nPol)\n\n    # Unit vector components for the \"r\" and \"phi\" faces of each magnet    \n    rhat_x = np.cos(orientation_phi).reshape((nMagnets, 1))\n    rhat_y = np.sin(orientation_phi).reshape((nMagnets, 1))\n    phat_x = -np.sin(orientation_phi).reshape((nMagnets, 1))\n    phat_y = np.cos(orientation_phi).reshape((nMagnets, 1))\n\n    # Allowable axes for each magnet in the magnet frame\n    pol_r = ml.repmat(np.reshape(pol_axes[:, 0], (1, nPol)), mag_data.nMagnets, 1)\n    pol_p = ml.repmat(np.reshape(pol_axes[:, 1], (1, nPol)), mag_data.nMagnets, 1)\n    pol_z = ml.repmat(np.reshape(pol_axes[:, 2], (1, nPol)), mag_data.nMagnets, 1)\n\n    # Populate allowable axes for each magnet in the lab frame\n    mag_data.pol_x[:, :] = pol_r*rhat_x + pol_p*phat_x\n    mag_data.pol_y[:, :] = pol_r*rhat_y + pol_p*phat_y\n    mag_data.pol_z[:, :] = pol_z\n    mag_data.pol_type_key[:] = pol_type[:]\n\n    # Concatenate with column zeros to the left, representing a null magnet\n    pol_x = np.concatenate((np.zeros((nMagnets, 1)), mag_data.pol_x), axis=1)\n    pol_y = np.concatenate((np.zeros((nMagnets, 1)), mag_data.pol_y), axis=1)\n    pol_z = np.concatenate((np.zeros((nMagnets, 1)), mag_data.pol_z), axis=1)\n    pol_r = np.concatenate((np.zeros((nMagnets, 1)), pol_r), axis=1)\n    pol_p = np.concatenate((np.zeros((nMagnets, 1)), pol_p), axis=1)\n    pol_type0 = np.concatenate(([0], pol_type))\n\n    # Original polarization axes for each magnet\n    nx_orig = np.cos(mag_data.mp)*np.sin(mag_data.mt)\n    ny_orig = np.sin(mag_data.mp)*np.sin(mag_data.mt)\n    nz_orig = np.cos(mag_data.mt)\n\n    # Scale orig axes by magnet density and copy for each allowable polarization\n    rho = mag_data.pho**mag_data.momentq\n    rmx_orig = ml.repmat(np.reshape(rho*nx_orig, (nMagnets, 1)), 1, nPol+1)\n    rmy_orig = ml.repmat(np.reshape(rho*ny_orig, (nMagnets, 1)), 1, nPol+1)\n    rmz_orig = ml.repmat(np.reshape(rho*nz_orig, (nMagnets, 1)), 1, nPol+1)\n\n    # 2-norm of differences between allowable vectors and scaled orig vectors\n    resid2 = (pol_x-rmx_orig)**2 + (pol_y-rmy_orig)**2 + (pol_z-rmz_orig)**2\n\n    # Choose allowable polarization vectors that minimize the residual 2-norm\n    min_ind = np.argmin(resid2, axis=1)\n\n    # Record indices of the residual-minimizing polarizations\n    mag_data.pol_id[:] = min_ind\n\n    # Arrays of the residual-minimizing polarizations for each magnet\n    pol_x_min = pol_x[np.arange(nMagnets), min_ind]\n    pol_y_min = pol_y[np.arange(nMagnets), min_ind]\n    pol_z_min = pol_z[np.arange(nMagnets), min_ind]\n    pol_r_min = pol_r[np.arange(nMagnets), min_ind]\n    pol_p_min = pol_p[np.arange(nMagnets), min_ind]\n\n    # Determine lab-frame polar angles for the resid-minimizing polarizations\n    mag_data.mp = np.arctan2(pol_y_min, pol_x_min)\n    mag_data.mt = np.arctan2(np.sqrt(pol_x_min**2 + pol_y_min**2), pol_z_min)\n\n    # Magnet-frame cylindrical coordinates for resid-minimizing polarizations\n    mag_data.cyl_r[:] = pol_r_min\n    mag_data.cyl_p[:] = pol_p_min\n    mag_data.cyl_z[:] = pol_z_min\n\n    # Type ID of the residual-minimizing polarization\n    mag_data.pol_type[:] = pol_type0[min_ind]\n\n    # Set pho to 0 if min_ind is 0; 1 otherwise\n    pho_0_inds = np.where(min_ind == 0)\n    pho_1_inds = np.where(min_ind != 0)\n    mag_data.pho[pho_0_inds] = 0.0\n    mag_data.pho[pho_1_inds] = 1.0"
]