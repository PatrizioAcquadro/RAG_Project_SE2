[
  "def get_global_dir(files):\n    tacs_root = os.path.abspath(os.path.dirname(__file__))\n    new = []\n    for f in files:\n        new.append(os.path.join(tacs_root, f))\n    return new",
  "def get_mpi_flags():\n    # Split the output from the mpicxx command\n    args = check_output([\"mpicxx\", \"-show\"]).decode(\"utf-8\").split()\n\n    # Determine whether the output is an include/link/lib command\n    inc_dirs, lib_dirs, libs = [], [], []\n    for flag in args:\n        if flag[:2] == \"-I\":\n            inc_dirs.append(flag[2:])\n        elif flag[:2] == \"-L\":\n            lib_dirs.append(flag[2:])\n        elif flag[:2] == \"-l\":\n            libs.append(flag[2:])\n\n    return inc_dirs, lib_dirs, libs",
  "class TACSSystem(BaseUI):\n    \"\"\"\n    Base class for TACS problem/constraint types. Contains methods common to all TACS systems dealing with design variables.\n    \"\"\"\n\n    def __init__(\n        self, assembler, comm=None, options=None, outputViewer=None, meshLoader=None\n    ):\n        \"\"\"\n        Parameters\n        ----------\n        assembler : tacs.TACS.Assembler\n            Cython object responsible for creating and setting tacs objects used to solve problem\n\n        comm : mpi4py.MPI.Intracomm\n            The comm object on which to create the pyTACS object.\n\n        options : dict\n            Dictionary holding problem-specific option parameters (case-insensitive).\n\n        outputViewer : tacs.TACS.TACSToFH5\n            Cython object used to write out f5 files that can be converted and used for postprocessing.\n\n        meshLoader : tacs.pymeshloader.pyMeshLoader\n            pyMeshLoader object used to create the assembler.\n        \"\"\"\n        # TACS assembler object\n        self.assembler = assembler\n        # TACS F5 output writer\n        self.outputViewer = outputViewer\n        # TACS pyMeshLoader object\n        self.meshLoader = meshLoader\n        # pyNastran BDF object\n        if self.meshLoader:\n            self.bdfInfo = self.meshLoader.getBDFInfo()\n\n        # Create Design variable vector\n        self.x = self.assembler.createDesignVec()\n        self.assembler.getDesignVars(self.x)\n        self.varName = \"struct\"\n        # Create Nodal coordinate vector\n        self.Xpts = self.assembler.createNodeVec()\n        self.assembler.getNodes(self.Xpts)\n        self.coordName = \"Xpts\"\n\n        # Setup comm and options\n        BaseUI.__init__(self, options=options, comm=comm)\n\n        return\n\n    ####### Design variable methods ########\n\n    def setVarName(self, varName):\n        \"\"\"\n        Set a name for the structural variables in pyOpt. Only needs\n        to be changed if more than 1 pytacs object is used in an\n        optimization\n\n        Parameters\n        ----------\n        varName : str\n            Name of the structural variable used in addVarGroup().\n        \"\"\"\n        self.varName = varName\n\n    def getDesignVars(self):\n        \"\"\"\n        Get the current set of  design variables for this problem.\n\n        Returns\n        ----------\n        x : numpy.ndarray\n            The current design variable vector set in tacs.\n\n        \"\"\"\n        return self.x.getArray().copy()\n\n    def setDesignVars(self, x):\n        \"\"\"\n        Update the design variables used by tacs.\n\n        Parameters\n        ----------\n        x : numpy.ndarray or dict or tacs.TACS.Vec\n            The variables (typically from the optimizer) to set. It\n            looks for variable in the ``self.varName`` attribute if in dict.\n\n        \"\"\"\n        # Check if the design variables are being handed in a dict\n        if isinstance(x, dict):\n            if self.varName in x:\n                self.x.getArray()[:] = x[self.varName]\n        # or array\n        elif isinstance(x, np.ndarray):\n            self.x.getArray()[:] = x\n        # Or TACS BVec\n        elif isinstance(x, tacs.TACS.Vec):\n            self.x.copyValues(x)\n        else:\n            raise ValueError(\n                \"setDesignVars must be called with either a numpy array, dict, or TACS Vec as input.\"\n            )\n\n        # Set the variables in tacs\n        self.assembler.setDesignVars(self.x)\n\n    def getDesignVarRange(self):\n        \"\"\"\n        get the lower/upper bounds for the design variables.\n\n        Returns\n        ----------\n        xlb : numpy.ndarray\n            The design variable lower bound.\n        xub : numpy.ndarray\n            The design variable upper bound.\n\n        \"\"\"\n        xlb = self.assembler.createDesignVec()\n        xub = self.assembler.createDesignVec()\n        self.assembler.getDesignVarRange(xlb, xub)\n        return xlb.getArray(), xub.getArray()\n\n    def _arrayToDesignVec(self, dvArray):\n        \"\"\"\n        Converts a distributed numpy array into a TACS design variable BVec.\n\n        Parameters\n        ----------\n        dvArray : numpy.ndarray\n                  Numpy array for which to convert to TACS designVec.\n\n        Returns\n        -------\n        xVec : tacs.TACS.Vec\n               Converted TACS designVec.\n\n        Notes\n        -----\n        dvArray must have correct size on each processor.\n        \"\"\"\n        xVec = self.assembler.createDesignVec()\n\n        # Set values\n        xVec.getArray()[:] = dvArray\n\n        # Return as tacs bvec object\n        return xVec\n\n    def getNumDesignVars(self):\n        \"\"\"\n        Return the number of design variables on this processor.\n\n        Returns\n        -------\n        ndvs : int\n            Number of design variables on this processor.\n        \"\"\"\n        return self.x.getSize()\n\n    def getNodes(self):\n        \"\"\"\n        Return the mesh coordinates of this problem.\n\n        Returns\n        -------\n        coords : numpy.ndarray\n            Structural coordinate in array of size (N * 3) where N is\n            the number of structural nodes on this processor.\n        \"\"\"\n        return self.Xpts.getArray().copy()\n\n    def setNodes(self, Xpts):\n        \"\"\"\n        Set the mesh coordinates of the structure.\n\n        Parameters\n        ----------\n        coords : numpy.ndarray\n            Structural coordinate in array of size (N * 3) where N is\n            the number of structural nodes on this processor.\n        \"\"\"\n        # Check if the design variables are being handed in a dict\n        if isinstance(Xpts, dict):\n            if self.coordName in Xpts:\n                self.Xpts.getArray()[:] = Xpts[self.coordName]\n        # or array\n        elif isinstance(Xpts, np.ndarray):\n            self.Xpts.getArray()[:] = Xpts\n        # Or TACS BVec\n        elif isinstance(Xpts, tacs.TACS.Vec):\n            self.Xpts.copyValues(Xpts)\n        else:\n            raise ValueError(\n                \"setNodes must be called with either a numpy array, dict, or TACS Vec as input.\"\n            )\n        self.assembler.setNodes(self.Xpts)\n\n    def _arrayToNodeVec(self, xptsArray):\n        \"\"\"\n        Converts a distributed numpy array into a TACS node BVec.\n\n        Parameters\n        ----------\n        xptsArray : numpy.ndarray\n                    Numpy array for which to convert to TACS nodeVec.\n\n        Returns\n        -------\n        Xptsvec : tacs.TACS.Vec\n                  Converted TACS nodeVec.\n\n        Notes\n        -----\n        xptsArray must have correct size on each processor.\n        \"\"\"\n        Xptsvec = self.assembler.createNodeVec()\n\n        # Set values\n        Xptsvec.getArray()[:] = xptsArray\n\n        # Return as tacs bvec object\n        return Xptsvec\n\n    def getNumCoordinates(self):\n        \"\"\"\n        Return the number of mesh coordinates on this processor.\n\n        Returns\n        -------\n        ncoords : int\n            Number of mesh coordinates on this processor.\n        \"\"\"\n        return self.Xpts.getSize()\n\n    ####### Variable methods ########\n\n    def getVarsPerNode(self):\n        \"\"\"\n        Get the number of variables per node for the model.\n\n        Returns\n        -------\n        vpn : int\n            Number of variables per node.\n        \"\"\"\n        return self.assembler.getVarsPerNode()\n\n    def getNumOwnedNodes(self):\n        \"\"\"\n        Get the number of nodes owned by this processor.\n\n        Returns\n        -------\n        nnodes : int\n            Number of nodes on this processor.\n        \"\"\"\n        return self.assembler.getNumOwnedNodes()\n\n    def _arrayToVec(self, varArray):\n        \"\"\"\n        Converts a distributed numpy array into a TACS state variable BVec.\n\n        Parameters\n        ----------\n        varArray : numpy.ndarray\n                   Numpy array for which to convert to TACS Vec.\n\n        Returns\n        -------\n        varVec : tacs.TACS.Vec\n                 Converted TACS Vec.\n\n        Notes\n        -----\n        varArray must have correct size on each processor.\n        \"\"\"\n        varVec = self.assembler.createVec()\n\n        # Set values\n        varVec.getArray()[:] = varArray\n\n        # Return as tacs bvec object\n        return varVec\n\n    def getNumVariables(self):\n        \"\"\"\n        Return the number of degrees of freedom (states) that are\n        on this processor\n\n        Returns\n        -------\n        nstate : int\n            number of states.\n        \"\"\"\n        vpn = self.getVarsPerNode()\n        nnodes = self.getNumOwnedNodes()\n        return vpn * nnodes",
  "def __init__(\n        self, assembler, comm=None, options=None, outputViewer=None, meshLoader=None\n    ):\n        \"\"\"\n        Parameters\n        ----------\n        assembler : tacs.TACS.Assembler\n            Cython object responsible for creating and setting tacs objects used to solve problem\n\n        comm : mpi4py.MPI.Intracomm\n            The comm object on which to create the pyTACS object.\n\n        options : dict\n            Dictionary holding problem-specific option parameters (case-insensitive).\n\n        outputViewer : tacs.TACS.TACSToFH5\n            Cython object used to write out f5 files that can be converted and used for postprocessing.\n\n        meshLoader : tacs.pymeshloader.pyMeshLoader\n            pyMeshLoader object used to create the assembler.\n        \"\"\"\n        # TACS assembler object\n        self.assembler = assembler\n        # TACS F5 output writer\n        self.outputViewer = outputViewer\n        # TACS pyMeshLoader object\n        self.meshLoader = meshLoader\n        # pyNastran BDF object\n        if self.meshLoader:\n            self.bdfInfo = self.meshLoader.getBDFInfo()\n\n        # Create Design variable vector\n        self.x = self.assembler.createDesignVec()\n        self.assembler.getDesignVars(self.x)\n        self.varName = \"struct\"\n        # Create Nodal coordinate vector\n        self.Xpts = self.assembler.createNodeVec()\n        self.assembler.getNodes(self.Xpts)\n        self.coordName = \"Xpts\"\n\n        # Setup comm and options\n        BaseUI.__init__(self, options=options, comm=comm)\n\n        return",
  "def setVarName(self, varName):\n        \"\"\"\n        Set a name for the structural variables in pyOpt. Only needs\n        to be changed if more than 1 pytacs object is used in an\n        optimization\n\n        Parameters\n        ----------\n        varName : str\n            Name of the structural variable used in addVarGroup().\n        \"\"\"\n        self.varName = varName",
  "def getDesignVars(self):\n        \"\"\"\n        Get the current set of  design variables for this problem.\n\n        Returns\n        ----------\n        x : numpy.ndarray\n            The current design variable vector set in tacs.\n\n        \"\"\"\n        return self.x.getArray().copy()",
  "def setDesignVars(self, x):\n        \"\"\"\n        Update the design variables used by tacs.\n\n        Parameters\n        ----------\n        x : numpy.ndarray or dict or tacs.TACS.Vec\n            The variables (typically from the optimizer) to set. It\n            looks for variable in the ``self.varName`` attribute if in dict.\n\n        \"\"\"\n        # Check if the design variables are being handed in a dict\n        if isinstance(x, dict):\n            if self.varName in x:\n                self.x.getArray()[:] = x[self.varName]\n        # or array\n        elif isinstance(x, np.ndarray):\n            self.x.getArray()[:] = x\n        # Or TACS BVec\n        elif isinstance(x, tacs.TACS.Vec):\n            self.x.copyValues(x)\n        else:\n            raise ValueError(\n                \"setDesignVars must be called with either a numpy array, dict, or TACS Vec as input.\"\n            )\n\n        # Set the variables in tacs\n        self.assembler.setDesignVars(self.x)",
  "def getDesignVarRange(self):\n        \"\"\"\n        get the lower/upper bounds for the design variables.\n\n        Returns\n        ----------\n        xlb : numpy.ndarray\n            The design variable lower bound.\n        xub : numpy.ndarray\n            The design variable upper bound.\n\n        \"\"\"\n        xlb = self.assembler.createDesignVec()\n        xub = self.assembler.createDesignVec()\n        self.assembler.getDesignVarRange(xlb, xub)\n        return xlb.getArray(), xub.getArray()",
  "def _arrayToDesignVec(self, dvArray):\n        \"\"\"\n        Converts a distributed numpy array into a TACS design variable BVec.\n\n        Parameters\n        ----------\n        dvArray : numpy.ndarray\n                  Numpy array for which to convert to TACS designVec.\n\n        Returns\n        -------\n        xVec : tacs.TACS.Vec\n               Converted TACS designVec.\n\n        Notes\n        -----\n        dvArray must have correct size on each processor.\n        \"\"\"\n        xVec = self.assembler.createDesignVec()\n\n        # Set values\n        xVec.getArray()[:] = dvArray\n\n        # Return as tacs bvec object\n        return xVec",
  "def getNumDesignVars(self):\n        \"\"\"\n        Return the number of design variables on this processor.\n\n        Returns\n        -------\n        ndvs : int\n            Number of design variables on this processor.\n        \"\"\"\n        return self.x.getSize()",
  "def getNodes(self):\n        \"\"\"\n        Return the mesh coordinates of this problem.\n\n        Returns\n        -------\n        coords : numpy.ndarray\n            Structural coordinate in array of size (N * 3) where N is\n            the number of structural nodes on this processor.\n        \"\"\"\n        return self.Xpts.getArray().copy()",
  "def setNodes(self, Xpts):\n        \"\"\"\n        Set the mesh coordinates of the structure.\n\n        Parameters\n        ----------\n        coords : numpy.ndarray\n            Structural coordinate in array of size (N * 3) where N is\n            the number of structural nodes on this processor.\n        \"\"\"\n        # Check if the design variables are being handed in a dict\n        if isinstance(Xpts, dict):\n            if self.coordName in Xpts:\n                self.Xpts.getArray()[:] = Xpts[self.coordName]\n        # or array\n        elif isinstance(Xpts, np.ndarray):\n            self.Xpts.getArray()[:] = Xpts\n        # Or TACS BVec\n        elif isinstance(Xpts, tacs.TACS.Vec):\n            self.Xpts.copyValues(Xpts)\n        else:\n            raise ValueError(\n                \"setNodes must be called with either a numpy array, dict, or TACS Vec as input.\"\n            )\n        self.assembler.setNodes(self.Xpts)",
  "def _arrayToNodeVec(self, xptsArray):\n        \"\"\"\n        Converts a distributed numpy array into a TACS node BVec.\n\n        Parameters\n        ----------\n        xptsArray : numpy.ndarray\n                    Numpy array for which to convert to TACS nodeVec.\n\n        Returns\n        -------\n        Xptsvec : tacs.TACS.Vec\n                  Converted TACS nodeVec.\n\n        Notes\n        -----\n        xptsArray must have correct size on each processor.\n        \"\"\"\n        Xptsvec = self.assembler.createNodeVec()\n\n        # Set values\n        Xptsvec.getArray()[:] = xptsArray\n\n        # Return as tacs bvec object\n        return Xptsvec",
  "def getNumCoordinates(self):\n        \"\"\"\n        Return the number of mesh coordinates on this processor.\n\n        Returns\n        -------\n        ncoords : int\n            Number of mesh coordinates on this processor.\n        \"\"\"\n        return self.Xpts.getSize()",
  "def getVarsPerNode(self):\n        \"\"\"\n        Get the number of variables per node for the model.\n\n        Returns\n        -------\n        vpn : int\n            Number of variables per node.\n        \"\"\"\n        return self.assembler.getVarsPerNode()",
  "def getNumOwnedNodes(self):\n        \"\"\"\n        Get the number of nodes owned by this processor.\n\n        Returns\n        -------\n        nnodes : int\n            Number of nodes on this processor.\n        \"\"\"\n        return self.assembler.getNumOwnedNodes()",
  "def _arrayToVec(self, varArray):\n        \"\"\"\n        Converts a distributed numpy array into a TACS state variable BVec.\n\n        Parameters\n        ----------\n        varArray : numpy.ndarray\n                   Numpy array for which to convert to TACS Vec.\n\n        Returns\n        -------\n        varVec : tacs.TACS.Vec\n                 Converted TACS Vec.\n\n        Notes\n        -----\n        varArray must have correct size on each processor.\n        \"\"\"\n        varVec = self.assembler.createVec()\n\n        # Set values\n        varVec.getArray()[:] = varArray\n\n        # Return as tacs bvec object\n        return varVec",
  "def getNumVariables(self):\n        \"\"\"\n        Return the number of degrees of freedom (states) that are\n        on this processor\n\n        Returns\n        -------\n        nstate : int\n            number of states.\n        \"\"\"\n        vpn = self.getVarsPerNode()\n        nnodes = self.getNumOwnedNodes()\n        return vpn * nnodes",
  "def preinitialize_method(method):\n    @wraps(method)\n    def wrapped_method(self, *args, **kwargs):\n        if self.assembler is not None:\n            raise self._TACSError(\n                f\"`{method.__name__}` is a pre-initialize method. \"\n                \"It may only be called before the 'initialize' method has been called.\"\n            )\n        else:\n            return method(self, *args, **kwargs)\n\n    return wrapped_method",
  "def postinitialize_method(method):\n    @wraps(method)\n    def wrapped_method(self, *args, **kwargs):\n        if self.assembler is None:\n            raise self._TACSError(\n                f\"`{method.__name__}` is a post-initialize method. \"\n                \"It may only be called after the 'initialize' method has been called.\"\n            )\n        else:\n            return method(self, *args, **kwargs)\n\n    return wrapped_method",
  "class pyTACS(BaseUI):\n    \"\"\"\n    The class for working with a TACS structure\n    \"\"\"\n\n    # Default class options\n    defaultOptions = {\n        # Meshloader options\n        \"printDebug\": [\n            bool,\n            False,\n            \"Flag for whether to print debug information while loading file.\",\n        ],\n        # Output Options\n        \"outputElement\": [\n            int,\n            None,\n            \"Specifies which element type should be written out in the f5 file.\\n\"\n            \"\\t If None, the type will be inferred from the first element in the model.\\n\"\n            \"\\t Acceptable values are:\\n\"\n            f\"\\t\\t tacs.TACS.ELEMENT_NONE = {tacs.TACS.ELEMENT_NONE}\\n\"\n            f\"\\t\\t tacs.TACS.SCALAR_2D_ELEMENT = {tacs.TACS.SCALAR_2D_ELEMENT}\\n\"\n            f\"\\t\\t tacs.TACS.SCALAR_3D_ELEMENT = {tacs.TACS.SCALAR_3D_ELEMENT}\\n\"\n            f\"\\t\\t tacs.TACS.BEAM_OR_SHELL_ELEMENT = {tacs.TACS.BEAM_OR_SHELL_ELEMENT}\\n\"\n            f\"\\t\\t tacs.TACS.PLANE_STRESS_ELEMENT = {tacs.TACS.PLANE_STRESS_ELEMENT}\\n\"\n            f\"\\t\\t tacs.TACS.SOLID_ELEMENT = {tacs.TACS.SOLID_ELEMENT}\\n\"\n            f\"\\t\\t tacs.TACS.RIGID_ELEMENT = {tacs.TACS.RIGID_ELEMENT}\\n\"\n            f\"\\t\\t tacs.TACS.MASS_ELEMENT = {tacs.TACS.MASS_ELEMENT}\\n\"\n            f\"\\t\\t tacs.TACS.SPRING_ELEMENT = {tacs.TACS.SPRING_ELEMENT}\\n\"\n            f\"\\t\\t tacs.TACS.PCM_ELEMENT = {tacs.TACS.PCM_ELEMENT}\",\n        ],\n        \"writeConnectivity\": [\n            bool,\n            True,\n            \"Flag for whether to include element connectivity in f5 file.\",\n        ],\n        \"writeNodes\": [bool, True, \"Flag for whether to include nodes in f5 file.\"],\n        \"writeDisplacements\": [\n            bool,\n            True,\n            \"Flag for whether to include nodal displacements in f5 file.\",\n        ],\n        \"writeStrains\": [\n            bool,\n            True,\n            \"Flag for whether to include element strains in f5 file.\",\n        ],\n        \"writeStresses\": [\n            bool,\n            True,\n            \"Flag for whether to include element stresses in f5 file.\",\n        ],\n        \"writeExtras\": [\n            bool,\n            True,\n            \"Flag for whether to include element extra variables in f5 file.\",\n        ],\n        \"writeLoads\": [\n            bool,\n            True,\n            \"Flag for whether to include external nodal loads in f5 file.\",\n        ],\n        \"writeCoordinateFrame\": [\n            bool,\n            False,\n            \"Flag for whether to include element coordinate frames in f5 file.\",\n        ],\n        \"familySeparator\": [\n            str,\n            \"/\",\n            \"Family separator character used for condensing groups in f5 file.\",\n        ],\n        \"printTiming\": [\n            bool,\n            False,\n            \"Flag for printing out timing information for class procedures.\",\n        ],\n    }\n\n    def __init__(self, fileName, comm=None, dvNum=0, scaleList=None, options=None):\n        \"\"\"\n\n        Parameters\n        ----------\n        fileName : str\n            The filename of the BDF file to load.\n\n        comm : mpi4py.MPI.Intracomm\n            The comm object on which to create the pyTACS object.\n\n        dvNum : int\n            A user-supplied offset to the design variable\n            numbering. This is typically used with tacs+tripan when\n            geometric variables have already been added and assigned\n            global tacs numberings.\n\n        scaleList: list\n            when dvNum is non-zero, the scaleList must be same size\n            as the number of design variables already added. i.e.\n            len(scaleList) = dvNum\n\n        options : dict\n            Dictionary holding model-specific option parameters (case-insensitive).\n        \"\"\"\n\n        startTime = time.time()\n\n        # Setup comm and options\n        BaseUI.__init__(self, options=options, comm=comm)\n\n        importTime = time.time()\n\n        # Create and load mesh loader object.\n        debugFlag = self.getOption(\"printDebug\")\n        self.meshLoader = pyMeshLoader(self.comm, debugFlag)\n        self.meshLoader.scanBdfFile(fileName)\n        self.bdfName = fileName\n        # Save pynastran bdf object\n        self.bdfInfo = self.meshLoader.getBDFInfo()\n\n        meshLoadTime = time.time()\n\n        # Retrieve the number of components. This is the maximum\n        # number of unique constitutive objects possible in this model.\n        self.nComp = self.meshLoader.getNumComponents()\n\n        # Load all the component descriptions\n        self.compDescripts = self.meshLoader.getComponentDescripts()\n        self.elemDescripts = self.meshLoader.getElementDescripts()\n\n        # Set the starting dvNum and scaleList\n        self.dvNum = dvNum\n        self.scaleList = scaleList\n        if scaleList is None:\n            self.scaleList = []\n\n        DVPreprocTime = time.time()\n\n        # List of DV groups\n        self.globalDVs = {}\n        self.massDVs = {}\n        self.compIDBounds = {}\n        self.addedCompIDs = set()\n\n        # List of initial coordinates\n        self.Xpts0 = None\n        # List of initial designvars\n        self.x0 = None\n        # Design var upper/lower-bounds\n        self.xub = None\n        self.xlb = None\n\n        # Variables per node for model\n        self.varsPerNode = None\n\n        # TACS assembler object\n        self.assembler = None\n\n        initFinishTime = time.time()\n        if self.getOption(\"printTiming\"):\n            self._pp(\"+--------------------------------------------------+\")\n            self._pp(\"|\")\n            self._pp(\"| TACS Init Times:\")\n            self._pp(\"|\")\n            self._pp(\n                \"| %-30s: %10.3f sec\" % (\"TACS Module Time\", importTime - startTime)\n            )\n            self._pp(\n                \"| %-30s: %10.3f sec\"\n                % (\"TACS Meshload Time\", meshLoadTime - importTime)\n            )\n            self._pp(\n                \"| %-30s: %10.3f sec\"\n                % (\"TACS DV Processing Time\", DVPreprocTime - meshLoadTime)\n            )\n            self._pp(\n                \"| %-30s: %10.3f sec\"\n                % (\"TACS Finalize Initialization Time\", initFinishTime - DVPreprocTime)\n            )\n            self._pp(\"|\")\n            self._pp(\n                \"| %-30s: %10.3f sec\"\n                % (\"TACS Total Initialization Time\", initFinishTime - startTime)\n            )\n            self._pp(\"+--------------------------------------------------+\")\n\n    @preinitialize_method\n    def addGlobalDV(self, descript, value, lower=None, upper=None, scale=1.0):\n        \"\"\"\n        Add a global design variable that can affect multiple components.\n\n        This function allows adding design variables that are not\n        cleanly associated with a particular constitutive object. One\n        example is the pitch of the stiffeners for blade-stiffened\n        panels. It is often the same for many different constitutive\n        objects. By calling this function, the internal dvNum counter\n        is incremented, and the user doesn't have to worry about\n        it.\n\n        Parameters\n        ----------\n        descript : str\n            A user-supplied string that can be used to retrieve the\n            variable number and value elemCallBackFunction.\n        value : float\n            Initial value for variable.\n        lower : float\n            Lower bound. This may be None for unbounded\n        upper : float\n            Upper bound. This may be None for unbounded\n        scale : float\n            Scale factor for variable\n        \"\"\"\n        self.globalDVs[descript] = {\n            \"num\": self.dvNum,\n            \"value\": value,\n            \"lowerBound\": lower,\n            \"upperBound\": upper,\n            \"isMassDV\": False,\n        }\n        self.dvNum += 1\n        self.scaleList.append(scale)\n\n    def getGlobalDVs(self):\n        \"\"\"\n        Return dict holding info about all current global DVs.\n\n        Returns\n        -------\n        globalDVs : dict\n            Dictionary holding global dv information.\n        \"\"\"\n        return self.globalDVs.copy()\n\n    def getGlobalDVKeys(self):\n        \"\"\"\n        Get key names for all current global DVs.\n\n        Returns\n        -------\n        globalDVKeys : list[str]\n            List holding global dv names.\n        \"\"\"\n        return list(self.globalDVs.keys())\n\n    def getGlobalDVNums(self):\n        \"\"\"\n        Get the dv nums corresponding to global DVs.\n\n        Returns\n        -------\n        globalDVNums : list[int]\n            List holding dv nums corresponding to global DVs.\n        \"\"\"\n        return [self.globalDVs[descript][\"num\"] for descript in self.globalDVs]\n\n    def getTotalNumGlobalDVs(self):\n        \"\"\"\n        Get the total number of global DVs across all processors.\n\n        Returns\n        -------\n        globalDVs : dict\n            Dictionary holding global dv information.\n        \"\"\"\n        return len(self.globalDVs)\n\n    @preinitialize_method\n    def assignMassDV(self, descript, eIDs, dvName=\"m\"):\n        \"\"\"\n        Assign a global DV to a point mass element.\n\n        Parameters\n        ----------\n        descript : str\n            Global DV key to assign mass design variable to. If the key is does not exist,\n            it will automatically be created and added to global DVs.\n\n        eIDs : int or list[int]\n            Element IDs of concentrated mass to assign DV to (NASTRAN ordering)\n\n        dvName : str\n            Name of mass property to apply DV to.\n            May be `m` for mass, `I11`, `I22`, `I12`, etc. for moment of inertia components.\n            Defaults to `m` (mass).\n\n        Notes\n        -----\n        Currently only CONM2 cards are supported.\n        \"\"\"\n        # Make sure eID is an array\n        eIDs = np.atleast_1d(eIDs)\n\n        # Check if referenced element ID is a CONM2 element\n        for eID in eIDs:\n            is_mass_element = False\n            if eID in self.bdfInfo.masses:\n                if self.bdfInfo.masses[eID].type in [\"CONM2\"]:\n                    is_mass_element = True\n\n            if not is_mass_element:\n                raise self._TACSError(\n                    f\"Element ID '{eID}' does not correspond to a `CONM2` element. \"\n                    \"Only `CONM2` elements are supported for this method.\"\n                )\n\n        # Check if descript already exists in global dvs, if not add it\n        if descript not in self.globalDVs:\n            self.addGlobalDV(descript, None)\n\n        dv_dict = self.globalDVs[descript]\n\n        # Flag this global dv as being a mass dv\n        dv_dict[\"isMassDV\"] = True\n\n        massDV = dv_dict[\"num\"]\n        value = dv_dict[\"value\"]\n        ub = dv_dict[\"upperBound\"]\n        lb = dv_dict[\"lowerBound\"]\n\n        for eID in eIDs:\n            # If the element ID hasn't already been added to massDVs, add it\n            if eID not in self.massDVs:\n                self.massDVs[eID] = {}\n\n            # Update the element entry with the dv num\n            self.massDVs[eID][f\"{dvName}Num\"] = massDV\n\n            # Update the element entry with the dv name\n            if value is not None:\n                self.massDVs[eID][dvName] = value\n            # If value was defined from previous call, remove it\n            elif dvName in self.massDVs[eID]:\n                self.massDVs[eID].pop(dvName)\n\n            # Update the element entry with the dv upper bound\n            if ub is not None:\n                self.massDVs[eID][f\"{dvName}ub\"] = ub\n            # If upper bound was defined from previous call, remove it\n            elif f\"{dvName}ub\" in self.massDVs[eID]:\n                self.massDVs[eID].pop(f\"{dvName}ub\")\n\n            # Update the element entry with the dv lower bound\n            if lb is not None:\n                self.massDVs[eID][f\"{dvName}lb\"] = lb\n            # If lower bound was defined from previous call, remove it\n            elif f\"{dvName}lb\" in self.massDVs[eID]:\n                self.massDVs[eID].pop(f\"{dvName}lb\")\n\n    def selectCompIDs(\n        self,\n        include=None,\n        exclude=None,\n        includeBounds=None,\n        nGroup=1,\n        includeOp=\"or\",\n        excludeOp=\"or\",\n        projectVector=None,\n        **kwargs,\n    ):\n        \"\"\"\n        This is the most important function of the entire setup\n        process.\n        The basic idea is as follows: We have a list of nComp\n        which are the component descriptions.\n        What we need is a way of\n        generating subgroups of these for the purposes of adding\n        design variables, constitutive objects, KS domains, and mass\n        domains.\n        All of these operations boil down to selecting a\n        subset of the compIDs.\n\n        This function attempts to support as many ways as possible to\n        select parts of the structure.\n        Easy and efficient selection of\n        parts is critical to the end user.\n\n        Methods of selection:\n\n        1. include, integer, string, list of integers and/or strings: The\n        simplest and most direct way of selecting a component.\n        The\n        user supplies the index of the componentID, a name or partial\n        name, or a list containing a combination of both.\n\n        For example::\n\n            # Select the 11th component\n            selectCompIDs(include=10)\n\n            # Select the first and fifth component\n            selectCompIDs(include=[0, 4])\n\n            # Select any component containing 'rib.00'\n            selectCompIDs(include='rib.00')\n\n            # Select any components containing 'rib.00' and 'rib.10'\n            selectCompIDs(include=['rib.00', 'rib.10'])\n\n            # Select any component containing 'rib.00', the 11th\n            # component and any component containing 'spar'\n            # (This is probably not advisable!)\n            selectCompIDs(include=['rib.00', 10, 'spar'])\n\n        2. Exclude, operates similarly to 'include'.\n        The behaviour of exclude is identical to include above, except that\n        component ID's that are found using 'exclude' are\n        'subtracted' from those found using include.\n        A special case is treated if 'include' is NOT given: if only an\n        exclude list is given, this implies the selection of all\n        compID's EXCEPT the those in exclude.\n\n        For example::\n\n            # This will return will [0, 1, 2, 3, 5, ..., nComp-1]\n            selectCompIDs(exclude = 4)\n\n            # This will return [0, 1, 4, 5, ..., nComp-1]\n            selectCompIDs(exclude = [2, 3]) will return\n\n            # This will return components that have 'ribs' in the\n            # component ID, but not those that have 'le_ribs' in the\n            # component id.\n            selectCompIDs(include='ribs', exclude='le_ribs')\n\n        3. includeBounds, list of components defining a region inside\n        which 'include' components will be selected.\n        This functionality uses a geometric approach to select the compIDs.\n        All components within the project 2D convex hull are included.\n        Therefore, it is essential to split up concave include regions\n        into smaller convex regions.\n        Use multiple calls to selectCompIDs to accumulate multiple regions.\n\n        For example::\n\n            # This will select upper skin components between the\n            # leading and trailing edge spars and between ribs 1 and 4.\n            selectCompIDs(include='U_SKIN', includeBound=\n                ['LE_SPAR', 'TE_SPAR', 'RIB.01', 'RIB.04'])\n\n        4. nGroup: The number of groups to divide the found components\n        into.\n        Generally this will be 1. However, in certain cases, it\n        is convenient to create multiple groups in one pass.\n\n        For example::\n\n            # This will 'evenly' create 10 groups on all components\n            # containing LE_SPAR.\n            Note that once the components are\n            # selected, they are sorted **alphabetically** and assigned\n            # sequentially.\n            selectCompIDs(include='LE_SPAR', nGroup=10)\n\n        nGroup can also be negative.\n        If it is negative, then a single\n        design variable group is added to each of the found\n        components.\n\n        For example::\n\n            # will select all components and assign a design variable\n            # group to each one.\n            selectCompIDs(nGroup=-1)\n\n        includeOp, str: 'and' or 'or'.\n        Selects the logical operation\n        used for item in 'include' option.\n        For example:\n\n        selectCompIDs(include=['LE_SPAR', 'TE_SPAR'],\n        includeOpt='or') will select the LE_SPAR and TE_SPAR\n        components (default behaviour).\n\n        selectCompIDs(include=['RIB', 'SEG.01'], includeOpt='and')\n        will select any component with 'RIB' in the description AND\n        'SEG.01' in the description.\n        \"\"\"\n\n        # Defaults\n        includeIDs = np.arange(self.nComp)\n        excludeIDs = []\n        includeBoundIDs = None\n\n        if include is not None:\n            includeIDs = self._getCompIDs(includeOp, include)\n\n        if exclude is not None:\n            excludeIDs = self._getCompIDs(excludeOp, exclude)\n\n        iSet = set(includeIDs)\n        eSet = set(excludeIDs)\n\n        # First take the intersection of iSet and ibSet\n        if includeBoundIDs is not None:\n            tmp = iSet.intersection(set(includeBoundIDs))\n        else:\n            tmp = iSet\n\n        # Next take the difference between tmp and eSet\n        compIDs = tmp.difference(eSet)\n\n        # Convert back to a list:\n        compIDs = list(compIDs)\n\n        # If we only want a single group, we're done, otherwise, we\n        # have a bit more work to do...\n        if nGroup > 1:\n            # The user wants to have nGroups returned from compIDs.\n\n            # First check that nGroup <= len(compIDs), print warning\n            # and clip if not\n            if nGroup > len(compIDs):\n                self._TACSWarning(\n                    f\"nGroup={nGroup} is larger than the number of\\\n                selected components={len(compIDs)}. nGroup will be clipped to {nGroup}\"\n                )\n                nGroup = len(compIDs)\n\n            # Pluck out the component descriptions again and we will\n            # sort them\n            compDescript = []\n            for i in range(len(compIDs)):\n                compDescript.append(self.compDescripts[compIDs[i]])\n\n            # define a general argsort\n            def argsort(seq):\n                return sorted(range(len(seq)), key=seq.__getitem__)\n\n            # ind is the index that would result in a sorted list.\n            ind = argsort(compDescript)\n\n            # Now simply divide 'ind' into 'nGroups' as evenly as\n            # possible, in the integer sense.\n            def split_list(alist, wanted_parts=1):\n                length = len(alist)\n                return [\n                    alist[i * length // wanted_parts : (i + 1) * length // wanted_parts]\n                    for i in range(wanted_parts)\n                ]\n\n            ind = split_list(ind, nGroup)\n\n            # Finally assemble the nested list of component IDs\n            tmp = []\n            for i in range(len(ind)):\n                tmp.append([])\n                for j in range(len(ind[i])):\n                    tmp[-1].append(compIDs[ind[i][j]])\n            compIDs = tmp\n        elif nGroup < 0:\n            # Negative number signifies 'add one dv to each component'\n            tmp = []\n            for comp in compIDs:\n                tmp.append([comp])\n            compIDs = tmp\n        else:\n            # Otherwise, just put the current list of compIDs in a\n            # list of length 1.\n            compIDs = [compIDs]\n\n        return compIDs\n\n    def getBDFInfo(self):\n        \"\"\"\n        Return a pynastran bdf object.\n        This object can be used interactively\n        to parse information (nodes, elements, loads, etc.) included in the bdf file.\n\n        Returns\n        -------\n        bdfInfo : pyNastran.bdf.bdf.BDF\n            pyNastran bdf object.\n        \"\"\"\n        return self.bdfInfo\n\n    def getCompNames(self, compIDs=None):\n        \"\"\"\n        Return a list of component descriptions for the given component\n        IDs. compIDs should come from a call to selectCompIDs\n\n        Parameters\n        ----------\n        compIDs : int or list[int] or None\n            List of integers containing the compIDs numbers. If None, returns names for all components.\n            Defaults to None.\n\n        Returns\n        -------\n        compDescript : list[str]\n            List of strings containing the names of the corresponding compIDs\n        \"\"\"\n        # Return all component names\n        if compIDs is None:\n            return copy.deepcopy(self.compDescripts)\n        # Convert to list\n        elif isinstance(compIDs, int):\n            compIDs = [compIDs]\n        # Make sure list is flat\n        else:\n            compIDs = self._flatten(compIDs)\n\n        compDescripts = []\n        for i in range(len(compIDs)):\n            compDescripts.append(self.compDescripts[compIDs[i]])\n\n        return compDescripts\n\n    def getGlobalNodeIDsForComps(self, compIDs, nastranOrdering=False):\n        \"\"\"\n        Return the global (non-partitioned) node IDs belonging to a given list of component IDs\n\n        Parameters\n        ----------\n        compIDs : int or list[int] or None\n            List of integers containing the compIDs numbers.\n            If None, returns nodeIDs for all components.\n            Defaults to None.\n\n        nastranOrdering : bool\n            Flag signaling whether nodeIDs are in TACS (default) or NASTRAN (grid IDs in bdf file) ordering\n            Defaults to False.\n\n        Returns\n        -------\n        nodeIDs : list[int]\n            List of unique nodeIDs that belong to the given list of compIDs\n        \"\"\"\n        # Return all component ids\n        if compIDs is None:\n            compIDs = list(range(self.nComp))\n\n        return self.meshLoader.getGlobalNodeIDsForComps(compIDs, nastranOrdering)\n\n    @postinitialize_method\n    def getLocalNodeIDsForComps(self, compIDs):\n        \"\"\"\n        Return the local (partitioned) node IDs belonging to a given list of component IDs\n\n        Parameters\n        ----------\n         compIDs : int or list[int] or None\n            List of integers containing the compIDs numbers.\n            If None, returns nodeIDs for all components.\n            Defaults to None.\n\n        Returns\n        -------\n        nodeIDs : list[int]\n            List of unique nodeIDs that belong to the given list of compIDs\n        \"\"\"\n        # Return all component ids\n        if compIDs is None:\n            compIDs = list(range(self.nComp))\n\n        return self.meshLoader.getLocalNodeIDsForComps(compIDs)\n\n    def initialize(self, elemCallBack=None):\n        \"\"\"\n        This is the 'last' method to be called during the setup. The\n        user should have already added all the design variables,\n        domains, etc. Before this function is called. This function\n        finalizes the problem initialization and cannot be changed at\n        later time. If the user does not provide an elemCallBack function,\n        we will use pyNastran to generate one automatically from element\n        properties provided in the BDF file.\n\n        Parameters\n        ----------\n        elemCallBack : callable\n\n           The calling sequence for elemCallBack **must** be as\n           follows::\n\n             def elemCallBack(dvNum, compID, compDescript, elemDescripts,\n                             globalDVs, **kwargs):\n\n           The dvNum is the current counter which must be used by the\n           user when creating a constitutive object with design\n           variables.\n\n           compID is the ID number used by tacs to reference this property group.\n           Use kwargs['propID'] to get the corresponding Nastran property ID that\n           is read in from the BDF.\n\n           compDescript is the component description label read in from optional\n           formatted comments in BDF file\n\n           elemDescripts are the name of the elements belonging to this group\n           (e.g. CQUAD4, CTRIA3, CTETRA, etc). This value will be a list since\n           one component may contain multiple compatible element types.\n           Example: ['CQUAD4', CTRIA3']\n\n           globalDVs is a dictionary containing information about any\n           global DVs that have been added.\n\n           elemCallBack must return a list containing as many TACS element\n           objects as there are element types in elemDescripts (one for each).\n\n        \"\"\"\n\n        if elemCallBack is None:\n            elemCallBack = self._elemCallBackFromBDF()\n        self._createOutputGroups()\n        self._createElements(elemCallBack)\n\n        self.assembler = self.meshLoader.createTACSAssembler(\n            self.varsPerNode, self.massDVs\n        )\n\n        self._createOutputViewer()\n\n        # Store original node locations read in from bdf file\n        self.Xpts0 = self.assembler.createNodeVec()\n        self.assembler.getNodes(self.Xpts0)\n\n        # Store initial design variable values\n        self.x0 = self.assembler.createDesignVec()\n        self.assembler.getDesignVars(self.x0)\n\n        # Store design variable upper/lower-bounds\n        self.xub = self.assembler.createDesignVec()\n        self.xlb = self.assembler.createDesignVec()\n        self.assembler.getDesignVarRange(self.xlb, self.xub)\n\n    def _elemCallBackFromBDF(self):\n        \"\"\"\n        Automatically setup elemCallBack using information contained in BDF file.\n        This function assumes all material properties are specified in the BDF.\n        \"\"\"\n\n        # Check if any properties are in the BDF\n        if self.bdfInfo.missing_properties:\n            raise self._TACSError(\n                f\"BDF file '{self.bdfName}' has missing properties cards. \"\n                \"Set 'printDebug' option to True for more information. \"\n                \"User must define own elemCallBack function.\"\n            )\n\n        # Make sure cross-referencing is turned on in pynastran\n        if self.bdfInfo.is_xrefed is False:\n            self.bdfInfo.cross_reference()\n            self.bdfInfo.is_xrefed = True\n\n        # Create a dictionary to sort all elements by property number\n        elemDict = {}\n        for elementID in self.bdfInfo.elements:\n            element = self.bdfInfo.elements[elementID]\n            propertyID = element.pid\n            if propertyID not in elemDict:\n                elemDict[propertyID] = {}\n                elemDict[propertyID][\"elements\"] = []\n                elemDict[propertyID][\"dvs\"] = {}\n            elemDict[propertyID][\"elements\"].append(element)\n\n        # Create a dictionary to sort all design variables\n        for dv in self.bdfInfo.dvprels:\n            propertyID = self.bdfInfo.dvprels[dv].pid\n            dvName = self.bdfInfo.dvprels[dv].pname_fid\n            self.dvNum = max(self.dvNum, self.bdfInfo.dvprels[dv].dvids[0])\n            elemDict[propertyID][\"dvs\"][dvName] = self.bdfInfo.dvprels[dv]\n        # Create option for user to specify scale values in BDF\n        self.scaleList = [1.0] * self.dvNum\n\n        # Callback function to return appropriate tacs MaterialProperties object\n        # For a pynastran mat card\n        def matCallBack(matInfo):\n            # Nastran isotropic material card\n            if matInfo.type == \"MAT1\":\n                mat = tacs.constitutive.MaterialProperties(\n                    rho=matInfo.rho,\n                    E=matInfo.e,\n                    nu=matInfo.nu,\n                    ys=matInfo.St,\n                    alpha=matInfo.a,\n                )\n            # Nastran orthotropic material card\n            elif matInfo.type == \"MAT8\":\n                E1 = matInfo.e11\n                E2 = matInfo.e22\n                nu12 = matInfo.nu12\n                G12 = matInfo.g12\n                G13 = matInfo.g1z\n                G23 = matInfo.g2z\n                # If out-of-plane shear values are 0, Nastran defaults them to the in-plane\n                if G13 == 0.0:\n                    G13 = G12\n                if G23 == 0.0:\n                    G23 = G12\n                rho = matInfo.rho\n                Xt = matInfo.Xt\n                Xc = matInfo.Xc\n                Yt = matInfo.Yt\n                Yc = matInfo.Yc\n                S12 = matInfo.S\n                # TODO: add alpha\n                mat = tacs.constitutive.MaterialProperties(\n                    rho=rho,\n                    E1=E1,\n                    E2=E2,\n                    nu12=nu12,\n                    G12=G12,\n                    G13=G13,\n                    G23=G23,\n                    Xt=Xt,\n                    Xc=Xc,\n                    Yt=Yt,\n                    Yc=Yc,\n                    S12=S12,\n                )\n            # Nastran 2D anisotropic material card\n            elif matInfo.type == \"MAT2\":\n                C11 = matInfo.G11\n                C12 = matInfo.G12\n                C22 = matInfo.G22\n                C13 = matInfo.G13\n                C23 = matInfo.G23\n                C33 = matInfo.G33\n                rho = matInfo.rho\n                # See if this card features anisotropic coupling terms (which we don't support yet)\n                if (\n                    np.abs(C13) / (C11 + C22) >= 1e-8\n                    or np.abs(C23) / (C11 + C22) >= 1e-8\n                ):\n                    self._TACSWarning(\n                        f\"MAT2 card {matInfo.mid} has anisotropic stiffness components that are not currently supported. \"\n                        \"These terms will be dropped and the material treated as orthotropic. \"\n                        \"Result accuracy may be affected.\"\n                    )\n                nu12 = C12 / C22\n                nu21 = C12 / C11\n                E1 = C11 * (1 - nu12 * nu21)\n                E2 = C22 * (1 - nu12 * nu21)\n                G12 = G13 = G23 = C33\n                # TODO: add alpha\n                mat = tacs.constitutive.MaterialProperties(\n                    rho=rho, E1=E1, E2=E2, nu12=nu12, G12=G12, G13=G13, G23=G23\n                )\n\n            else:\n                raise self._TACSError(\n                    f\"Unsupported material type '{matInfo.type}' for material number {matInfo.mid}.\"\n                )\n\n            return mat\n\n        def elemCallBack(\n            dvNum, compID, compDescript, elemDescripts, globalDVs, **kwargs\n        ):\n            # Initialize scale list for design variables we will add\n            scaleList = []\n\n            # Get the Nastran property ID\n            propertyID = kwargs[\"propID\"]\n            propInfo = self.bdfInfo.properties[propertyID]\n            elemInfo = elemDict[propertyID][\"elements\"][0]\n\n            # First we define the material object\n            mat = None\n            # This property only references one material\n            if hasattr(propInfo, \"mid_ref\"):\n                matInfo = propInfo.mid_ref\n                mat = matCallBack(matInfo)\n            # This property references multiple materials (maybe a laminate)\n            elif hasattr(propInfo, \"mids_ref\"):\n                mat = []\n                for matInfo in propInfo.mids_ref:\n                    mat.append(matCallBack(matInfo))\n\n            # Next we define the constitutive object\n            if propInfo.type == \"PSHELL\":  # Nastran isotropic shell\n                kcorr = propInfo.tst\n\n                if \"T\" in elemDict[propertyID][\"dvs\"]:\n                    thickness = elemDict[propertyID][\"dvs\"][\"T\"].dvids_ref[0].xinit\n                    tNum = elemDict[propertyID][\"dvs\"][\"T\"].dvids[0] - 1\n                    minThickness = elemDict[propertyID][\"dvs\"][\"T\"].dvids_ref[0].xlb\n                    maxThickness = elemDict[propertyID][\"dvs\"][\"T\"].dvids_ref[0].xub\n                    name = elemDict[propertyID][\"dvs\"][\"T\"].dvids_ref[0].label\n                    self.scaleList[tNum - 1] = elemDict[propertyID][\"dvs\"][\"T\"].coeffs[\n                        0\n                    ]\n                else:\n                    thickness = propInfo.t\n                    tNum = -1\n                    minThickness = 0.0\n                    maxThickness = 1e20\n\n                con = tacs.constitutive.IsoShellConstitutive(\n                    mat, t=thickness, tlb=minThickness, tub=maxThickness, tNum=tNum\n                )\n\n            elif propInfo.type == \"PCOMP\":  # Nastran composite shell\n                numPlies = propInfo.nplies\n                plyThicknesses = []\n                plyAngles = []\n                plyMats = []\n\n                # if the laminate is symmetric, mirror the ply indices\n                if propInfo.lam == \"SYM\":\n                    plyIndices = list(range(numPlies // 2))\n                    plyIndices.extend(plyIndices[::-1])\n                else:\n                    plyIndices = range(numPlies)\n\n                # Loop through plies and setup each entry in layup\n                for ply_i in plyIndices:\n                    plyThicknesses.append(propInfo.thicknesses[ply_i])\n                    plyMat = tacs.constitutive.OrthotropicPly(\n                        plyThicknesses[ply_i], mat[ply_i]\n                    )\n                    plyMats.append(plyMat)\n                    plyAngles.append(np.deg2rad(propInfo.thetas[ply_i]))\n\n                # Convert thickness/angles to appropriate numpy array\n                plyThicknesses = np.array(plyThicknesses, dtype=self.dtype)\n                plyAngles = np.array(plyAngles, dtype=self.dtype)\n\n                if propInfo.lam is None or propInfo.lam in [\"SYM\", \"MEM\"]:\n                    # Discrete laminate class (not for optimization)\n                    con = tacs.constitutive.CompositeShellConstitutive(\n                        plyMats, plyThicknesses, plyAngles\n                    )\n\n                elif propInfo.lam == \"SMEAR\":\n                    lamThickness = sum(plyThicknesses)\n                    plyFractions = plyThicknesses / lamThickness\n                    con = tacs.constitutive.SmearedCompositeShellConstitutive(\n                        plyMats, lamThickness, plyAngles, plyFractions\n                    )\n\n                # Need to add functionality to consider only membrane in TACS for type = MEM\n                else:\n                    raise self._TACSError(\n                        f\"Unrecognized LAM type '{propInfo.lam}' for PCOMP number {propertyID}.\"\n                    )\n\n            elif propInfo.type == \"PSOLID\":  # Nastran solid property\n                if \"T\" in elemDict[propertyID][\"dvs\"]:\n                    thickness = elemDict[propertyID][\"dvs\"][\"T\"].dvids_ref[0].xinit\n                    tNum = elemDict[propertyID][\"dvs\"][\"T\"].dvids[0] - 1\n                    minThickness = elemDict[propertyID][\"dvs\"][\"T\"].dvids_ref[0].xlb\n                    maxThickness = elemDict[propertyID][\"dvs\"][\"T\"].dvids_ref[0].xub\n                    name = elemDict[propertyID][\"dvs\"][\"T\"].dvids_ref[0].label\n                    self.scaleList[tNum - 1] = elemDict[propertyID][\"dvs\"][\"T\"].coeffs[\n                        0\n                    ]\n                else:\n                    thickness = 1.0\n                    tNum = -1\n                    minThickness = 0.0\n                    maxThickness = 10.0\n\n                con = tacs.constitutive.SolidConstitutive(\n                    mat, t=thickness, tlb=minThickness, tub=maxThickness, tNum=tNum\n                )\n\n            elif propInfo.type == \"PBUSH\":  # Nastran spring\n                k = np.zeros(6)\n                for j in range(len(k)):\n                    if propInfo.Ki[j]:\n                        k[j] = propInfo.Ki[j]\n                con = tacs.constitutive.DOFSpringConstitutive(k=k)\n\n            elif propInfo.type == \"PBAR\":  # Nastran bar\n                area = propInfo.A\n                I1 = propInfo.i1\n                I2 = propInfo.i2\n                I12 = propInfo.i12\n                J = propInfo.j\n                k1 = propInfo.k1\n                k2 = propInfo.k2\n\n                # pynastran defaults these values to 1e8,\n                # which can lead to scaling issues in the stiffness matrix\n                # We truncate this value to 1e3 to prevent this\n                if k1 is None or k1 > 1e3:\n                    k1 = 1e3\n\n                if k2 is None or k2 > 1e3:\n                    k2 = 1e3\n\n                con = tacs.constitutive.BasicBeamConstitutive(\n                    mat, A=area, Iy=I2, Iz=I1, Iyz=I12, J=J, ky=k1, kz=k2\n                )\n\n            elif propInfo.type == \"PROD\":  # Nastran rod\n                area = propInfo.A\n                J = propInfo.j\n                k1 = 0.0\n                k2 = 0.0\n\n                con = tacs.constitutive.BasicBeamConstitutive(\n                    mat, A=area, J=J, ky=k1, kz=k2\n                )\n\n            else:\n                raise self._TACSError(\n                    f\"Unsupported property type '{propInfo.type}' for property number {propertyID}. \"\n                )\n\n            # Set up transform object which may be required for certain elements\n            transform = None\n            if propInfo.type in [\"PSHELL\", \"PCOMP\"]:\n                mcid = elemDict[propertyID][\"elements\"][0].theta_mcid_ref\n                if mcid:\n                    if mcid.type == \"CORD2R\":\n                        refAxis = mcid.i\n                        transform = tacs.elements.ShellRefAxisTransform(refAxis)\n                    else:  # Don't support spherical/cylindrical yet\n                        raise self._TACSError(\n                            \"Unsupported material coordinate system type \"\n                            f\"'{mcid.type}' for property number {propertyID}.\"\n                        )\n            elif propInfo.type in [\"PBAR\"]:\n                refAxis = elemDict[propertyID][\"elements\"][0].g0_vector\n                transform = tacs.elements.BeamRefAxisTransform(refAxis)\n            elif propInfo.type == \"PROD\":\n                refAxis = np.array(\n                    [1.0, -1.0, 1.0]\n                )  # dummy ref_axis, not really needed for rods\n                transform = tacs.elements.BeamRefAxisTransform(refAxis)\n            elif propInfo.type == \"PBUSH\":\n                if elemDict[propertyID][\"elements\"][0].cid_ref:\n                    refAxis_i = elemDict[propertyID][\"elements\"][0].cid_ref.i\n                    refAxis_j = elemDict[propertyID][\"elements\"][0].cid_ref.j\n                    transform = tacs.elements.SpringRefFrameTransform(\n                        refAxis_i, refAxis_j\n                    )\n                elif elemDict[propertyID][\"elements\"][0].x[0]:\n                    refAxis = (\n                        np.array(elemDict[propertyID][\"elements\"][0].x)\n                        - elemDict[propertyID][\"elements\"][0]\n                        .nodes_ref[0]\n                        .get_position()\n                    )\n                    transform = tacs.elements.SpringRefAxisTransform(refAxis)\n                elif elemDict[propertyID][\"elements\"][0].g0_ref:\n                    refAxis = (\n                        elemDict[propertyID][\"elements\"][0].g0_ref.get_position()\n                        - elemDict[propertyID][\"elements\"][0]\n                        .nodes_ref[0]\n                        .get_position()\n                    )\n                    transform = tacs.elements.SpringRefAxisTransform(refAxis)\n\n            # Finally set up the element objects belonging to this component\n            elemList = []\n            for descript in elemDescripts:\n                if descript in [\"CQUAD4\", \"CQUADR\"]:\n                    elem = tacs.elements.Quad4Shell(transform, con)\n                elif descript in [\"CQUAD9\", \"CQUAD\"]:\n                    elem = tacs.elements.Quad9Shell(transform, con)\n                elif descript in [\"CTRIA3\", \"CTRIAR\"]:\n                    elem = tacs.elements.Tri3Shell(transform, con)\n                elif descript in [\"CBAR\", \"CROD\"]:\n                    elem = tacs.elements.Beam2(transform, con)\n                elif \"CTETRA\" in descript:\n                    # May have variable number of nodes in card\n                    nnodes = len(elemInfo.nodes)\n                    if nnodes == 4:\n                        basis = tacs.elements.LinearTetrahedralBasis()\n                    elif nnodes == 10:\n                        basis = tacs.elements.QuadraticTetrahedralBasis()\n                    else:\n                        raise self._TACSError(\n                            f\"TACS does not currently support CTETRA elements with {nnodes} nodes.\"\n                        )\n                    model = tacs.elements.LinearElasticity3D(con)\n                    elem = tacs.elements.Element3D(model, basis)\n                elif descript in [\"CHEXA8\", \"CHEXA\"]:\n                    basis = tacs.elements.LinearHexaBasis()\n                    model = tacs.elements.LinearElasticity3D(con)\n                    elem = tacs.elements.Element3D(model, basis)\n                elif descript == \"CBUSH\":\n                    elem = tacs.elements.SpringElement(transform, con)\n                else:\n                    raise self._TACSError(\n                        \"Unsupported element type \"\n                        f\"'{descript}' specified for property number {propertyID}.\"\n                    )\n                elemList.append(elem)\n\n            return elemList, scaleList\n\n        return elemCallBack\n\n    @postinitialize_method\n    def getOrigDesignVars(self):\n        \"\"\"\n        get the original design variables that were specified with\n        during assembler creation.\n\n        Returns\n        -------\n        x : numpy.ndarray\n            The original design variable vector set in tacs.\n\n        \"\"\"\n        return self.x0.getArray().copy()\n\n    @postinitialize_method\n    def getDesignVarRange(self):\n        \"\"\"\n        get the lower/upper bounds for the design variables.\n\n        Returns\n        -------\n        xlb : numpy.ndarray\n            The design variable lower bound.\n        xub : numpy.ndarray\n            The design variable upper bound.\n\n        \"\"\"\n        return self.xlb.getArray().copy(), self.xub.getArray().copy()\n\n    @postinitialize_method\n    def createDesignVec(self, asBVec=False):\n        \"\"\"\n        Create a new tacs distributed design vector.\n        Values are initialized to zero.\n\n        Parameters\n        ----------\n        asBVec : bool\n            Flag that determines whether to return\n            design vector as tacs :class:`~TACS.Vec` (True) or numpy array (False).\n            Defaults to False.\n\n        Returns\n        -------\n        x : numpy.ndarray or tacs.TACS.Vec\n            Distributed design variable vector\n        \"\"\"\n        xVec = self.assembler.createDesignVec()\n        if asBVec:\n            return xVec\n        else:\n            return xVec.getArray()\n\n    @postinitialize_method\n    def getNumDesignVars(self):\n        \"\"\"\n        Return the number of design variables on this processor.\n\n        Returns\n        -------\n        ndvs : int\n            Number of design variables on this processor.\n        \"\"\"\n        return self.x0.getSize()\n\n    @postinitialize_method\n    def getTotalNumDesignVars(self):\n        \"\"\"\n        Return the number of design variables across all processors.\n\n        Returns\n        -------\n        ndvs : int\n            Total number of design variables across all processors.\n        \"\"\"\n        return self.dvNum\n\n    @postinitialize_method\n    def getOrigNodes(self):\n        \"\"\"\n        Return the original mesh coordinates read in from the meshLoader.\n\n        Returns\n        -------\n        coords : numpy.ndarray\n            Structural coordinate in array of size (N * 3) where N is\n            the number of structural nodes on this processor.\n        \"\"\"\n        return self.Xpts0.getArray().copy()\n\n    @postinitialize_method\n    def createNodeVec(self, asBVec=False):\n        \"\"\"\n        Create a new tacs distributed node vector.\n        Values are initialized to zero.\n\n        Parameters\n        ----------\n        asBVec : bool\n            Flag that determines whether to return\n            node vector as tacs :class:`~TACS.Vec` (True) or numpy array (False).\n            Defaults to False.\n\n        Returns\n        -------\n        xpts : numpy.ndarray or tacs.TACS.Vec\n            Distributed node coordinate vector\n        \"\"\"\n\n        xptVec = self.assembler.createNodeVec()\n        if asBVec:\n            return xptVec\n        else:\n            return xptVec.getArray()\n\n    @postinitialize_method\n    def getNumOwnedNodes(self):\n        \"\"\"\n        Get the number of nodes owned by this processor.\n\n        Returns\n        -------\n        nNodes : int\n            Number of nodes owned by this proc.\n        \"\"\"\n        return self.assembler.getNumOwnedNodes()\n\n    @postinitialize_method\n    def getNumOwnedMultiplierNodes(self):\n        \"\"\"\n        Get the number of lagrange multiplier nodes owned by this processor.\n\n        Returns\n        -------\n        nMultNodes : int\n            Number of multiplier nodes owned by this proc.\n        \"\"\"\n        return len(self.meshLoader.getLocalMultiplierNodeIDs())\n\n    @postinitialize_method\n    def getLocalMultiplierNodeIDs(self):\n        \"\"\"\n        Get the tacs indices of multiplier nodes used to hold lagrange multipliers on this processor.\n\n        Returns\n        -------\n        nodeIDs : list[int]\n            List of multiplier node ID's owned by this proc.\n        \"\"\"\n        return self.meshLoader.getLocalMultiplierNodeIDs()\n\n    @postinitialize_method\n    def createVec(self, asBVec=False):\n        \"\"\"\n        Create a new tacs distributed state variable vector.\n        Values are initialized to zero.\n\n        Parameters\n        ----------\n        asBVec : bool\n            Flag that determines whether to return\n            state vector as tacs :class:`~TACS.Vec` (True) or numpy array (False).\n            Defaults to False.\n\n        Returns\n        -------\n        vars : numpy.ndarray or tacs.TACS.Vec\n            Distributed state variable vector\n        \"\"\"\n        vars = self.assembler.createVec()\n        if asBVec:\n            return vars\n        else:\n            return vars.getArray()\n\n    @postinitialize_method\n    def getVarsPerNode(self):\n        \"\"\"\n        Get the number of variables per node for the model.\n\n        Returns\n        -------\n        vpn : int\n            Number of variables per node.\n        \"\"\"\n        return self.assembler.getVarsPerNode()\n\n    @postinitialize_method\n    def applyBCsToVec(self, vec):\n        \"\"\"\n        Applies zeros to boundary condition DOFs in input vector.\n\n        Parameters\n        ----------\n        vec : numpy.ndarray or tacs.TACS.Vec\n            Vector to apply boundary conditions to.\n        \"\"\"\n        # Check if input is a BVec or numpy array\n        if isinstance(vec, tacs.TACS.Vec):\n            self.assembler.applyBCs(vec)\n        elif isinstance(vec, np.ndarray):\n            array = vec\n            # Create temporary BVec\n            vec = self.assembler.createVec()\n            # Copy array values to BVec\n            vec.getArray()[:] = array\n            # Apply BCs\n            self.assembler.applyBCs(vec)\n            # Copy values back to array\n            array[:] = vec.getArray()\n\n    @postinitialize_method\n    def createStaticProblem(self, name, options=None):\n        \"\"\"\n        Create a new staticProblem for modeling a static load cases.\n        This object can be used to set loads, evalFunctions as well as perform\n        solutions and sensitivities related to static problems\n\n        Parameters\n        ----------\n        name : str\n            Name to assign problem.\n        options : dict\n            Problem-specific options to pass to StaticProblem instance (case-insensitive).\n            Defaults to None.\n\n        Returns\n        -------\n        problem : tacs.problems.StaticProblem\n            StaticProblem object used for modeling and solving static cases.\n        \"\"\"\n        problem = tacs.problems.static.StaticProblem(\n            name, self.assembler, self.comm, self.outputViewer, self.meshLoader, options\n        )\n        # Set with original design vars and coordinates, in case they have changed\n        problem.setDesignVars(self.x0)\n        problem.setNodes(self.Xpts0)\n        return problem\n\n    @postinitialize_method\n    def createTransientProblem(self, name, tInit, tFinal, numSteps, options=None):\n        \"\"\"\n        Create a new TransientProblem for modeling a transient load cases.\n        This object can be used to set loads, evalFunctions as well as perform\n        solutions and sensitivities related to transient problems\n\n        Parameters\n        ----------\n        name : str\n            Name to assign problem.\n        tInit : float\n            Starting time for transient time integration\n        tFinal : float\n            Ending time for transient time integration\n        numSteps : int\n            Number of time steps for transient time integration\n        options : dict\n            Problem-specific options to pass to TransientProblem instance (case-insensitive).\n            Defaults to None.\n\n        Returns\n        -------\n        problem : tacs.problems.TransientProblem\n            TransientProblem object used for modeling and solving transient cases.\n        \"\"\"\n        problem = tacs.problems.transient.TransientProblem(\n            name,\n            tInit,\n            tFinal,\n            numSteps,\n            self.assembler,\n            self.comm,\n            self.outputViewer,\n            self.meshLoader,\n            options,\n        )\n        # Set with original design vars and coordinates, in case they have changed\n        problem.setDesignVars(self.x0)\n        problem.setNodes(self.Xpts0)\n        return problem\n\n    @postinitialize_method\n    def createModalProblem(self, name, sigma, numEigs, options=None):\n        \"\"\"\n        Create a new ModalProblem for performing modal analysis.\n        This problem can be used to identify the natural frequencies and mode\n        shapes of the model through eigenvalue analysis.\n\n        Parameters\n        ----------\n        name : str\n            Name to assign problem.\n        sigma : float\n            Guess for the lowest eigenvalue.\n            This corresponds to the lowest expected frequency squared. (rad^2/s^2)\n        numEigs : int\n            Number of eigenvalues to solve for.\n        options : dict\n            Problem-specific options to pass to ModalProblem instance (case-insensitive).\n            Defaults to None.\n\n        Returns\n        -------\n        problem : tacs.problems.ModalProblem\n            ModalProblem object used for performing modal eigenvalue analysis.\n        \"\"\"\n        problem = tacs.problems.modal.ModalProblem(\n            name,\n            sigma,\n            numEigs,\n            self.assembler,\n            self.comm,\n            self.outputViewer,\n            self.meshLoader,\n            options,\n        )\n        # Set with original design vars and coordinates, in case they have changed\n        problem.setDesignVars(self.x0)\n        problem.setNodes(self.Xpts0)\n        return problem\n\n    @postinitialize_method\n    def createBucklingProblem(self, name, sigma, numEigs, options=None):\n        \"\"\"\n        Create a new BucklingProblem for performing linearized buckling analysis.\n        This problem can be used to identify the buckling load factors and mode\n        shapes of the model through eigenvalue analysis.\n\n        Parameters\n        ----------\n        name : str\n            Name to assign problem.\n        sigma : float\n            Guess for the lowest eigenvalue.\n            This corresponds to the lowest expected buckling load factor.\n        numEigs : int\n            Number of eigenvalues to solve for.\n        options : dict\n            Problem-specific options to pass to ModalProblem instance (case-insensitive).\n            Defaults to None.\n\n        Returns\n        -------\n        problem : tacs.problems.BucklingProblem\n            BucklingProblem object used for performing buckling eigenvalue analysis.\n        \"\"\"\n        problem = tacs.problems.buckling.BucklingProblem(\n            name,\n            sigma,\n            numEigs,\n            self.assembler,\n            self.comm,\n            self.outputViewer,\n            self.meshLoader,\n            options,\n        )\n        # Set with original design vars and coordinates, in case they have changed\n        problem.setDesignVars(self.x0)\n        problem.setNodes(self.Xpts0)\n        return problem\n\n    @postinitialize_method\n    def createTACSProbsFromBDF(self):\n        \"\"\"\n        Automatically define tacs problem classes with loads using information contained in BDF file.\n        This function assumes all loads are specified in the BDF and allows users to\n        skip setting loads in Python.\n\n        Returns\n        -------\n        structProblems : dict[int, tacs.problems.TACSProblem]\n            Dictionary containing a predefined TACSProblem for every loadcase found in the BDF.\n            The dictionary keys are the loadcase IDs from the BDF.\n\n        Notes\n        -----\n        Currently only supports LOAD, FORCE, MOMENT, GRAV, RFORCE, PLOAD2, PLOAD4, TLOAD1, TLOAD2, and DLOAD cards.\n        Currently only supports staticProblem (SOL 101), transientProblem (SOL 109), and modalProblems (SOL 103)\n        \"\"\"\n        # Make sure cross-referencing is turned on in pynastran\n        if self.bdfInfo.is_xrefed is False:\n            self.bdfInfo.cross_reference()\n            self.bdfInfo.is_xrefed = True\n\n        structProblems = {}\n\n        # If subcases have been added in Nastran, then subCase 0 should not be run\n        if len(self.bdfInfo.subcases) > 1:\n            skipCaseZero = True\n        else:\n            skipCaseZero = False\n\n        # Loop through every load set and create a corresponding structural problem\n        for subCase in self.bdfInfo.subcases.values():\n            if skipCaseZero and subCase.id == 0:\n                continue\n\n            if \"SUBTITLE\" in subCase:\n                name = subCase[\"SUBTITLE\"][0]\n            else:\n                name = \"load_set_%.3d\" % (subCase.id)\n\n            if self.bdfInfo.sol == 103:\n                methodID = subCase[\"METHOD\"][0]\n                methodInfo = self.bdfInfo.methods[methodID]\n                if methodInfo.v1 is not None:\n                    sigma = (2 * np.pi * methodInfo.v1) ** 2\n                elif methodInfo.v2 is not None:\n                    sigma = (2 * np.pi * methodInfo.v2) ** 2\n                else:\n                    sigma = 1.0\n                if methodInfo.nd is not None:\n                    nEigs = methodInfo.nd\n                else:\n                    nEigs = 20\n                problem = self.createModalProblem(name, sigma, nEigs)\n\n            elif self.bdfInfo.sol == 109:\n                # Get time step info\n                if \"TSTEP\" in subCase:\n                    tStepID = subCase[\"TSTEP\"][0]\n                    tStep = self.bdfInfo.tsteps[tStepID]\n                    nSteps = tStep.N[0]\n                    dt = tStep.DT[0]\n                # If no time step info was included, we'll skip this case\n                else:\n                    self._TACSWarning(\n                        f\"No TSTEP entry found in control deck for subcase number {subCase.id}, \"\n                        \"skipping case.\"\n                    )\n                    continue\n                problem = self.createTransientProblem(\n                    name, tInit=0.0, tFinal=dt * nSteps, numSteps=nSteps\n                )\n\n                # Find dynamic load specified for this subcase\n                if \"DLOAD\" in subCase:\n                    dloadsID = subCase[\"DLOAD\"][0]\n                    dloadSet, dloadScale = self.bdfInfo.get_reduced_dloads(dloadsID)\n                    for dloadInfo, dscale in zip(dloadSet, dloadScale):\n                        timeSteps = problem.getTimeSteps()\n                        if dloadInfo.type in [\"TLOAD1\", \"TLOAD2\"]:\n                            if dloadInfo.type == \"TLOAD1\":\n                                loadScales = dloadInfo.get_load_at_time(\n                                    timeSteps, dscale\n                                )\n                            elif dloadInfo.type == \"TLOAD2\":\n                                loadScales = _tload2_get_load_at_time(\n                                    dloadInfo, timeSteps, dscale\n                                )\n                            if dloadInfo.Type != \"LOAD\":\n                                self._TACSWarning(\n                                    \"Only 'LOAD' types are supported for \"\n                                    f\"'{dloadInfo.type}' card, but '{dloadInfo.type}' {dloadInfo.sid}, \"\n                                    f\"was specified as {dloadInfo.Type} type\"\n                                )\n                            loadsID = dloadInfo.excite_id\n                        else:\n                            self._TACSWarning(\n                                \"Unsupported dload type \"\n                                f\"'{dloadInfo.type}' specified for load set number {dloadInfo.sid},\"\n                                f\" skipping load\"\n                            )\n                            continue\n                        # Loop through each time step and add loads to problem\n                        for timeIndex, scale in enumerate(loadScales):\n                            problem.addLoadFromBDF(timeIndex, loadsID, scale=scale)\n\n            else:\n                problem = self.createStaticProblem(name)\n\n                # Find the static load specified for this test case\n                if \"LOAD\" in subCase:\n                    # Add loads to problem\n                    loadsID = subCase[\"LOAD\"][0]\n                    problem.addLoadFromBDF(loadsID)\n\n            # append to list of structural problems\n            structProblems[subCase.id] = problem\n\n        return structProblems\n\n    @postinitialize_method\n    def writeBDF(self, fileName, problems):\n        \"\"\"\n        Write NASTRAN BDF file from problem class.\n        Assumes all supplied Problems share the same nodal and design variable values.\n\n        NOTE: Only supports writing loads from StaticProblem types.\n\n        Parameters\n        ----------\n        fileName: str\n            Name of file to write BDF file to.\n        problems: tacs.problems.TACSProblem or list[tacs.problems.TACSProblem]\n            List of pytacs Problem classes to write BDF file from.\n        \"\"\"\n        # Make sure problems is in a list\n        if hasattr(problems, \"__iter__\") == False:\n            problems = [problems]\n        elif isinstance(problems, dict):\n            problems = list(problems.values())\n        else:\n            problems = list(problems)\n\n        # Check that each problem was created by this pyTACS instance\n        for problem in problems:\n            if problem.assembler != self.assembler:\n                raise self._TACSError(\n                    f\"This problem instance ({problem.name}) is not associated with this instance of pyTACS.\"\n                )\n\n        # Make sure design variables are up-to-date\n        dv_bvec = self.createDesignVec(asBVec=True)\n        dv_bvec.getArray()[:] = problems[0].getDesignVars()\n        # Transfer all non-local dvs\n        dv_bvec.beginDistributeValues()\n        dv_bvec.endDistributeValues()\n\n        # Get local node info for each processor\n        multNodes = self.getLocalMultiplierNodeIDs()\n        globalToLocalNodeIDDict = self.meshLoader.getGlobalToLocalNodeIDDict()\n        Xpts_bvec = np.real(problems[0].getNodes())\n\n        # Gather local info to root processor\n        allMultNodes = self.comm.gather(multNodes, root=0)\n        allGlobalToLocalNodeIDDict = self.comm.gather(globalToLocalNodeIDDict, root=0)\n        allXpts = self.comm.gather(Xpts_bvec, root=0)\n\n        # Assemble new BDF file for mesh on root\n        if self.comm.rank == 0:\n            newBDFInfo = pn.bdf.BDF(debug=False)\n\n            # Write out updated node locations\n            nastranNodeIDs = list(self.bdfInfo.node_ids)\n            # Loop through each proc and pull out new node locations\n            for proc_i in range(self.comm.size):\n                xyz = allXpts[proc_i].reshape(-1, 3)\n                for tacsGNodeID in allGlobalToLocalNodeIDDict[proc_i]:\n                    # Get local node ID\n                    tacsLNodeID = allGlobalToLocalNodeIDDict[proc_i][tacsGNodeID]\n                    # Get Global nastran ID\n                    nastranGNodeID = nastranNodeIDs[tacsGNodeID]\n                    # Add node to bdf file (if its not a multiplier node)\n                    if tacsLNodeID not in allMultNodes[proc_i]:\n                        newBDFInfo.add_grid(nastranGNodeID, xyz[tacsLNodeID])\n\n            # Copy over boundary conditions\n            # Set all con IDs to one\n            newBDFInfo.spcs[1] = []\n            for spcID in self.bdfInfo.spcs:\n                for spcCard in self.bdfInfo.spcs[spcID]:\n                    newCard = copy.deepcopy(spcCard)\n                    newCard.conid = 1\n                    newBDFInfo.spcs[1].append(newCard)\n\n            # Write updated properties and elements\n            transObjs = {}\n            matObjs = []\n            conObjs = []\n            for compID, propID in enumerate(self.bdfInfo.properties):\n                # Get TACS element object\n                elemObj = self.meshLoader.getElementObject(compID, 0)\n                # get dv nums for element\n                dvNums = elemObj.getDesignVarNums(0)\n                # Update design variable values\n                dvVals = dv_bvec.getValues(dvNums)\n                elemObj.setDesignVars(0, dvVals)\n                # Get TACS constitutive object for element (if applicable)\n                conObj = elemObj.getConstitutive()\n                if conObj is not None:\n                    # Set the property ID number for the class to be used in the Nastran card\n                    conObj.setNastranID(propID)\n                    conObjs.append(conObj)\n                    # Get TACS material properties object for constitutive (if applicable)\n                    matObj = conObj.getMaterialProperties()\n                    # May be a single object...\n                    if isinstance(matObj, tacs.constitutive.MaterialProperties):\n                        if matObj not in matObjs:\n                            matObjs.append(matObj)\n                    # or a list (plys for composite classes)\n                    elif isinstance(matObj, list):\n                        for mat_i in matObj:\n                            if mat_i not in matObjs:\n                                matObjs.append(mat_i)\n                # Get TACS transform object for element (if applicable)\n                transObj = elemObj.getTransform()\n                if transObj is not None:\n                    transObjs[compID] = transObj\n\n            # Write material cards from TACS MaterialProperties class\n            for i, matObj in enumerate(matObjs):\n                matID = i + 1\n                matObj.setNastranID(matID)\n                newBDFInfo.materials[matID] = matObj.generateBDFCard()\n\n            # Write property/element cards from TACSConstitutive/TACSElement classes\n            curCoordID = 1\n            for compID, conObj in enumerate(conObjs):\n                propID = conObj.getNastranID()\n                propCard = conObj.generateBDFCard()\n                if propCard is not None:\n                    # Copy property comment (may include component name info)\n                    # Make sure to remove comment `$` from string\n                    propCard.comment = self.bdfInfo.properties[propID].comment[1:]\n                    # Add property card to BDF\n                    newBDFInfo.properties[propID] = propCard\n                elemIDs = self.meshLoader.getGlobalElementIDsForComps(\n                    [compID], nastranOrdering=True\n                )\n                # Convert any transform objects to nastran COORD2R cards, if necessary\n                transObj = transObjs.get(compID, None)\n                if isinstance(\n                    transObj, tacs.elements.ShellRefAxisTransform\n                ) or isinstance(transObj, tacs.elements.SpringRefFrameTransform):\n                    coordID = curCoordID\n                    origin = np.zeros(3)\n                    if isinstance(transObj, tacs.elements.SpringRefFrameTransform):\n                        vec1, vec2 = transObj.getRefAxes()\n                    else:\n                        vec1 = transObj.getRefAxis()\n                        vec2 = np.random.random(3)\n                    # Add COORD2R card to BDF\n                    pn.cards.coordinate_systems.define_coord_e123(\n                        newBDFInfo,\n                        \"CORD2R\",\n                        coordID,\n                        origin,\n                        xaxis=np.real(vec1),\n                        xzplane=np.real(vec2),\n                        add=True,\n                    )\n                    curCoordID += 1\n                # We just need the ref vector for these types\n                elif isinstance(\n                    transObj, tacs.elements.BeamRefAxisTransform\n                ) or isinstance(transObj, tacs.elements.SpringRefAxisTransform):\n                    vec = transObj.getRefAxis()\n                    vec = np.real(vec)\n                # Otherwise, there's no transform associated with this element, use default\n                else:\n                    coordID = None\n                # Copy and update element cards\n                for elemID in elemIDs:\n                    # Create copy of card\n                    newCard = copy.deepcopy(self.bdfInfo.elements[elemID])\n                    # Copy element comment (may include component name info)\n                    # Make sure to remove comment `$` from string\n                    newCard.comment = self.bdfInfo.elements[elemID].comment[1:]\n                    # Update element coordinate frame info, if necessary\n                    if \"CQUAD\" in newCard.type or \"CTRI\" in newCard.type:\n                        newCard.theta_mcid = coordID\n                    elif \"CBAR\" in newCard.type:\n                        newCard.x = vec\n                        newCard.g0 = None\n                    elif \"CBEAM\" in newCard.type:\n                        newCard.x = vec\n                        newCard.g0 = None\n                        if propCard.type != \"PBEAM\":\n                            # TACS wrote out a PBAR card that we must convert\n                            newPropCard = (\n                                pn.cards.properties.beam.PBEAM_init_from_empty()\n                            )\n                            newPropCard.A[0] = propCard.Area()\n                            newPropCard.i1[0] = propCard.I11()\n                            newPropCard.i2[0] = propCard.I22()\n                            newPropCard.i12[0] = propCard.I12()\n                            if hasattr(propCard, \"J\"):\n                                newPropCard.j[0] = propCard.J()\n                            else:\n                                newPropCard.j[0] = propCard.j\n                            newPropCard.comment = propCard.comment\n                            propCard = newPropCard\n                    elif \"CROD\" in newCard.type and propCard.type != \"PROD\":\n                        # TACS wrote out a PBAR card that we must convert\n                        if hasattr(propCard, \"J\"):\n                            J = propCard.J()\n                        else:\n                            J = propCard.j\n                        newPropCard = pn.cards.properties.rods.PROD(\n                            propCard.pid, propCard.mid, propCard.Area(), J\n                        )\n                        newBDFInfo.properties[propID] = newPropCard\n                        newPropCard.comment = propCard.comment\n                        propCard = newPropCard\n                    elif newCard.type == \"CBUSH\":\n                        if isinstance(transObj, tacs.elements.SpringRefAxisTransform):\n                            newCard.x = vec\n                            newCard.g0 = None\n                        else:\n                            newCard.cid = coordID\n                    # Add element card to bdf\n                    newBDFInfo.elements[elemID] = newCard\n\n            # Copy over masses elements\n            for massCard in self.bdfInfo.masses.values():\n                elemID = massCard.eid\n                # We'll have to create a new CONM2 card in case the point mass is associated with tacs dvs\n                if massCard.type == \"CONM2\":\n                    nodeID = massCard.nid\n                    elemObj = self.meshLoader.getElementObjectForElemID(\n                        elemID, nastranOrdering=True\n                    )\n                    conObj = elemObj.getConstitutive()\n                    M = conObj.evalMassMatrix()\n                    mass = np.real(M[0])\n                    I11 = np.real(M[15])\n                    I22 = np.real(M[18])\n                    I33 = np.real(M[20])\n                    # Nastran uses negative convention for POI's\n                    I12 = -np.real(M[16])\n                    I13 = -np.real(M[17])\n                    I23 = -np.real(M[19])\n                    newBDFInfo.add_conm2(\n                        elemID, nodeID, mass, I=[I11, I12, I22, I13, I23, I33]\n                    )\n                # CONM1's can't be updated by TACS, so we can just copy the original value\n                else:\n                    newBDFInfo.masses[elemID] = copy.deepcopy(massCard)\n                # Copy over comments\n                newBDFInfo.masses[elemID].comment = massCard.comment\n\n            # Copy over rigid elements\n            newBDFInfo.rigid_elements.update(self.bdfInfo.rigid_elements)\n\n            # Add case control deck for loads\n            caseConLines = [\n                \"TITLE = TACS Analysis Set\",\n                \"ECHO = NONE\",\n                \"DISPLACEMENT(PLOT) = ALL\",\n                \"SPCFORCE(PLOT) = ALL\",\n                \"OLOAD(PLOT) = ALL\",\n                \"FORCE(PLOT,CORNER) = ALL\",\n                \"STRESS(PLOT,CORNER) = ALL\",\n                \"SPC = 1\",\n            ]\n            newBDFInfo.case_control_deck = pn.case_control_deck.CaseControlDeck(\n                caseConLines\n            )\n            # Set solution type to static (101)\n            newBDFInfo.sol = 101\n\n        else:\n            newBDFInfo = None\n\n        # All procs should wait for root\n        self.comm.barrier()\n\n        # Append forces from problem classes\n        for i, problem in enumerate(problems):\n            if isinstance(problem, tacs.problems.StaticProblem):\n                loadCase = i + 1\n                problem.writeLoadToBDF(newBDFInfo, loadCase)\n\n        # Write out BDF file\n        if self.comm.rank == 0:\n            newBDFInfo.write_bdf(\n                fileName, size=16, is_double=True, write_header=False, enddata=True\n            )\n\n        # All procs should wait for root\n        self.comm.barrier()\n\n    @postinitialize_method\n    def createAdjacencyConstraint(self, name, options=None):\n        \"\"\"\n        Create a new AdjacencyConstraint for calculating\n        design variable differences across adjacent components.\n        This constraint can be used to ensure that the design variables\n        do not change too abruptly across components.\n        The formulation is a linear constraint that takes the following form:\n\n        c = dv_i - dv_j\n\n        Where dv_i and dv_j are two design variables in adjacent components.\n\n        Parameters\n        ----------\n        name : str\n            Name to assign constraint.\n        options : dict\n            Class-specific options to pass to AdjacencyConstraint instance (case-insensitive).\n            Defaults to None.\n\n        Returns\n        -------\n        constraint : tacs.constraints.AdjacencyConstraint\n            AdjacencyConstraint object used for calculating constraints.\n        \"\"\"\n        constr = tacs.constraints.AdjacencyConstraint(\n            name,\n            self.assembler,\n            self.comm,\n            self.outputViewer,\n            self.meshLoader,\n            options,\n        )\n        # Set with original design vars and coordinates, in case they have changed\n        constr.setDesignVars(self.x0)\n        constr.setNodes(self.Xpts0)\n        return constr\n\n    @postinitialize_method\n    def createDVConstraint(self, name, options=None):\n        \"\"\"\n        Create a new DVConstraint for calculating linear constraints based\n        on design variables within the same component.\n\n        The constraints are of the form:\n\n            c = a_0 * dv_0 + a_1 * dv_1 + ... + a_n * dv_n\n\n        Where which design variables to include (dv_0, dv_1, etc.)\n        and the corresponding weights (a_0, a_1, etc.) are defined by the user.\n\n        Parameters\n        ----------\n        name : str\n            Name to assign constraint.\n        options : dict\n            Class-specific options to pass to DVConstraint instance (case-insensitive).\n            Defaults to None.\n\n        Returns\n        -------\n        constraint : tacs.constraints.DVConstraint\n            DVConstraint object used for calculating constraints.\n        \"\"\"\n        constr = tacs.constraints.DVConstraint(\n            name,\n            self.assembler,\n            self.comm,\n            self.outputViewer,\n            self.meshLoader,\n            options,\n        )\n        # Set with original design vars and coordinates, in case they have changed\n        constr.setDesignVars(self.x0)\n        constr.setNodes(self.Xpts0)\n        return constr\n\n    @postinitialize_method\n    def createPanelLengthConstraint(self, name, options=None):\n        \"\"\"Create a new PanelLengthConstraint for enforcing that the panel\n        length DV values passed to components match the actual panel lengths.\n\n        Parameters\n        ----------\n        name : str\n            Name to assign constraint.\n        options : dict\n            Class-specific options to pass to DVConstraint instance (case-insensitive).\n\n        Returns\n        ----------\n        constraint : tacs.constraints.PanelLengthConstraint\n            PanelLengthConstraint object used for calculating constraints.\n        \"\"\"\n        constr = tacs.constraints.PanelLengthConstraint(\n            name,\n            self.assembler,\n            self.comm,\n            self.outputViewer,\n            self.meshLoader,\n            options,\n        )\n        # Set with original design vars and coordinates, in case they have changed\n        constr.setDesignVars(self.x0)\n        constr.setNodes(self.Xpts0)\n        return constr\n\n    @postinitialize_method\n    def createVolumeConstraint(self, name, options=None):\n        \"\"\"\n        Create a new VolumeConstraint for constraining the size of a closed volume.\n        Only shell and solid elements are supported for this constraint.\n        For shell elements, the enclosed volume MUST be manifold and water-tight (no missing/internal faces).\n        The formulation is a nonlinear constraint based on the nodal coordinates.\n\n        A common example of this is ensuring enough volume in the wingbox for fuel:\n\n            vol_wing >= vol_fuel\n\n        Parameters\n        ----------\n        name : str\n            Name to assign constraint.\n        options : dict\n            Class-specific options to pass to VolumeConstraint instance (case-insensitive).\n            Defaults to None.\n\n        Returns\n        -------\n        constraint : tacs.constraints.VolumeConstraint\n            VolumeConstraint object used for calculating constraints.\n        \"\"\"\n        constr = tacs.constraints.VolumeConstraint(\n            name,\n            self.assembler,\n            self.comm,\n            self.outputViewer,\n            self.meshLoader,\n            options,\n        )\n        # Set with original design vars and coordinates, in case they have changed\n        constr.setDesignVars(self.x0)\n        constr.setNodes(self.Xpts0)\n        return constr\n\n    def getNumComponents(self):\n        \"\"\"\n        Return number of components (property) groups found in bdf.\n\n        Returns\n        -------\n        nComp : int\n            Number of components in model\n        \"\"\"\n        return self.nComp\n\n    def _createOutputGroups(self):\n        \"\"\"Automatically determine how to split out the output file\n        for easier viewing\"\"\"\n\n        self.fam = []\n        for i in range(self.nComp):\n            aux = self.compDescripts[i].split(self.getOption(\"familySeparator\"))\n            self.fam.append(aux[0])\n\n        # Uniqify them and sort\n        self.fam = sorted(np.unique(self.fam))\n\n        self.compFam = np.zeros(self.nComp, dtype=\"intc\")\n        for i in range(self.nComp):\n            aux = self.compDescripts[i].split(self.getOption(\"familySeparator\"))\n            self.compFam[i] = self.fam.index(aux[0])\n\n    def _createOutputViewer(self):\n        \"\"\"\n        Internal method to create the appropriate output viewer\n        (TACSToFH5 object) for TACS.\n        \"\"\"\n\n        # Depending on the user-supplied options generate the\n        # write_flag\n        write_flag = 0\n        if self.getOption(\"writeConnectivity\"):\n            write_flag |= tacs.TACS.OUTPUT_CONNECTIVITY\n        if self.getOption(\"writeNodes\"):\n            write_flag |= tacs.TACS.OUTPUT_NODES\n        if self.getOption(\"writeDisplacements\"):\n            write_flag |= tacs.TACS.OUTPUT_DISPLACEMENTS\n        if self.getOption(\"writeStrains\"):\n            write_flag |= tacs.TACS.OUTPUT_STRAINS\n        if self.getOption(\"writeStresses\"):\n            write_flag |= tacs.TACS.OUTPUT_STRESSES\n        if self.getOption(\"writeExtras\"):\n            write_flag |= tacs.TACS.OUTPUT_EXTRAS\n        if self.getOption(\"writeLoads\"):\n            write_flag |= tacs.TACS.OUTPUT_LOADS\n        if self.getOption(\"writeCoordinateFrame\"):\n            write_flag |= tacs.TACS.OUTPUT_COORDINATES\n\n        # Create actual viewer\n        if self.getOption(\"outputElement\") is not None:\n            elementType = self.getOption(\"outputElement\")\n        else:\n            # Set the output type based on the first element in the model\n            elem = self.meshLoader.getElementObjectForElemID(0, nastranOrdering=False)\n            elementType = elem.getElementType()\n\n        self.outputViewer = tacs.TACS.ToFH5(self.assembler, elementType, write_flag)\n\n        # Set the names of each of the output families\n        for i in range(len(self.fam)):\n            self.outputViewer.setComponentName(i, self.fam[i])\n\n    def _getCompIDs(self, op, *inList):\n        \"\"\"Internal method to return the component IDs mathing\n        information in inList\"\"\"\n\n        # First recursively flatten the inList in case it was nested:\n        inList = self._flatten(inList)\n\n        # Neste list container for compIDs\n        compIDs = []\n\n        # Look at each item in list (which is a list because of the *)\n        for item in inList:\n            compIDs.append([])\n            if isinstance(item, int):\n                # Integers are easy, just check if in bounds and add:\n                if item >= 0 and item < self.nComp:\n                    compIDs[-1].append(item)\n                else:\n                    self._TACSWarning(\n                        f\"Trying to add component ID of {item}, which\\\n                    is out of the range 0 <= compID < {self.nComp}\"\n                    )\n\n            elif isinstance(item, str):\n                # This is a little inefficient here; loop over\n                # self.compDescripts and see if 'item' (a string) in\n                # part of the description. if so add.\n                item = item.upper()\n                for i in range(self.nComp):\n                    if item in self.compDescripts[i].upper():\n                        compIDs[-1].append(i)\n            else:\n                self._TACSWarning(\n                    f\"Unidentifiable information given for 'include'\\\n                or 'exclude'. Valid data are integers 0 <= i < {self.nComp}, or \\\n                strings.\"\n                )\n\n        if op == \"and\":\n            # First convert each entry to a set:\n            for i in range(len(compIDs)):\n                compIDs[i] = set(compIDs[i])\n\n            # We want to go through and take only the intersection of\n            # each of the sets we have found:\n            tmp = copy.deepcopy(compIDs[0])\n\n            for i in range(1, len(compIDs)):\n                tmp = tmp.intersection(compIDs[i])\n            compIDs = tmp\n\n        # Finally, convert to a list\n        compIDs = self._flatten(list(compIDs))\n\n        return compIDs\n\n    def _createElements(self, elemCallBack):\n        \"\"\"\n        Create all the constitutive objects by calling the\n        userSupplied or default callback function\n\n        Parameters\n        ----------\n        elemCallBack : callable\n            Element callback function provided by user or pyTACS\n            to set up TACS element objects.\n        \"\"\"\n\n        for i in range(self.nComp):\n            # Get a list of compDescripts to help the user\n            compDescript = self.compDescripts[i]\n            numElements = len(self.elemDescripts[i])\n            # TACS component ID\n            compID = i\n            # Nastran property ID\n            propID = list(self.bdfInfo.property_ids)[i]\n\n            # Call the user function\n            result = elemCallBack(\n                self.dvNum,\n                compID,\n                compDescript,\n                self.elemDescripts[i],\n                self.globalDVs,\n                propID=propID,\n            )\n\n            # For maximum flexibility, multiple pieces of information\n            # can be returned. At a minimum, the element objects\n            # must be returned!\n\n            # Note: If two objects are returned, the\n            # first one is used as the element object list and the\n            # second one is treated as a scale list for the added dvs.\n\n            # Check that result is an element object instance or .\n            numFoundElements = 0\n            scaleList = None\n\n            if isinstance(result, tuple):\n                elemObjects = result[0]\n                if hasattr(result[1], \"__iter__\"):\n                    # Iterable item, the scale list:\n                    scaleList = result[1]\n                elif isinstance(result[1], numbers.Number):\n                    scaleList = [result[1]]\n                else:\n                    print(result[1])\n                    # Don't know what it is:\n                    self._TACSWarning(\n                        \"Could not identify objects returned \\\n                    from elemCallBack. Valid return objects are: \\\n                    A list of TACS element objects (required, first), \\\n                    an iterable object \\\n                    (eg, list or array) containing the scaling parameters \\\n                    for the added design variables (optional, second). The \\\n                    string representation of the offending object is: \\\n                    '%s'\"\n                        % repr(result[1])\n                    )\n\n            else:\n                elemObjects = result\n\n            if isinstance(elemObjects, tacs.TACS.Element):\n                # There was only one element, recast it as a list and continue\n                elemObjects = [elemObjects]\n                numFoundElements += 1\n            elif isinstance(elemObjects, list):\n                # Multiple elements were returned, count how many\n                for object in elemObjects:\n                    if isinstance(object, tacs.TACS.Element):\n                        numFoundElements += 1\n                    else:\n                        self._TACSError(\n                            f\"Object of type {type(object)} returned in elemCallBack function \"\n                            f\"is not a valid TACS element object. The \\\n                               string representation of the offending object is: \\\n                               '{repr(object)}'\"\n                        )\n\n            if numFoundElements != numElements:\n                raise self._TACSError(\n                    f\"Unexpected number of element objects \\\n                    returned from user-supplied elemCallBack function. \\\n                    {numElements} element types ({repr(self.elemDescripts[i])}) are contained in Component {i}, \\\n                    but {numFoundElements} element objects were returned by elemCallback.\"\n                )\n\n            # Now determine the number of design variables. This is\n            # NOT as simple as just getting the number of design\n            # variables; Not all variables added in the conObject are\n            # 'new' variables, some of the variable number may have\n            # been already used.\n            newVars = []\n            for elemObject in elemObjects:\n                dvs = elemObject.getDesignVarNums(0)\n\n                if len(dvs) > 0:\n                    # We will also check if the user screwed up. That is\n                    # make sure that for added variables, the are\n                    # continuous starting at self.dvNum\n                    for var in dvs:\n                        if var >= self.dvNum:\n                            newVars.append(var)\n\n            # Remove repeated dv nums from list\n            newVars = np.unique(newVars)\n            newVars.sort()\n\n            if len(newVars) > 0:\n                # Now the length of newVars must the same as\n                # newVars[-1]-newVars[0] + 1\n                if not len(newVars) == newVars[-1] - newVars[0] + 1:\n                    raise self._TACSError(\n                        \"Inconsistent design variables detected. \"\n                        \"The added design variables are not continuous.\"\n                        f\" The added design variables are {repr(newVars)}.\"\n                    )\n\n            # Finally, increment the dv counter\n            self.dvNum += len(newVars)\n\n            if len(newVars) > 0:\n                if scaleList is None:\n                    self.scaleList.extend(np.ones(len(newVars)))\n                else:\n                    # Make sure that the scaleList is the correct length.\n                    if len(scaleList) != len(newVars):\n                        self._TACSWarning(\n                            f\"An incorrect number of scale variables \\\n                        were returned. There were {len(newVars)} variables added, but only \\\n                        {len(scaleList)} scale variables returned. The scale for these \\\n                        variables will be set to 1.0. The scale variables are {repr(scaleList)}.\"\n                        )\n                        self.scaleList.extend(np.ones(len(newVars)))\n                    else:\n                        self.scaleList.extend(scaleList)\n\n            # Loop through every element type in this component,\n            # there may be multiple (e.g CQUAD4 + CTRIA3)\n            for j, elemObject in enumerate(elemObjects):\n                # Set component-specific family id\n                elemObject.setComponentNum(self.compFam[i])\n                # Set each of the elements for this component\n                self.meshLoader.setElementObject(i, j, elemObject)\n                # set varsPerNode\n                elemVarsPerNode = elemObject.getVarsPerNode()\n                if self.varsPerNode is None:\n                    self.varsPerNode = elemVarsPerNode\n                elif self.varsPerNode != elemVarsPerNode:\n                    raise self._TACSError(\n                        \"Model references elements with differing numbers of variables per node \"\n                        f\"({self.varsPerNode} and {elemVarsPerNode}). \"\n                        \"All elements must use same number of variables to be compatible.\"\n                    )\n\n        # If varsPerNode still hasn't been set (because there were no elements added in the callback)\n        # Default to 6\n        if self.varsPerNode is None:\n            self.varsPerNode = 6",
  "def _tload2_get_load_at_time(tload2, time, scale=1.0):\n    \"\"\"\n    This is a function for interpolating the time series for the NASTRAN TLOAD2 card.\n    Usually, this would be done through pyNastran, but there's bug in its implementation\n    that prevents it from being run.\n    \"\"\"\n    if isinstance(time, float):\n        time = np.array([time])\n    else:\n        time = np.asarray(time)\n\n    if isinstance(tload2.delay, float):\n        tau = tload2.delay\n    elif tload2.delay == 0 or tload2.delay is None:\n        tau = 0.0\n    else:\n        tau = tload2.delay_ref.get_delay_at_time(time)\n\n    t1 = tload2.T1 + tau\n    t2 = tload2.T2 + tau\n    freq = tload2.frequency\n    p = tload2.phase\n    f = np.zeros(time.shape, dtype=time.dtype)\n\n    i = np.where(t1 <= time)[0]\n    j = np.where(time[i] <= t2)[0]\n    i = i[j]\n    f[i] = (\n        scale\n        * time[i] ** tload2.b\n        * np.exp(tload2.c * time[i])\n        * np.cos(2 * np.pi * freq * time[i] + p)\n    )\n\n    is_spcd = False\n    # resp = f\n    if tload2.Type == \"VELO\" and is_spcd:\n        f[0] = tload2.us0\n    if tload2.Type == \"ACCE\" and is_spcd:\n        f[0] = tload2.vs0\n    return f",
  "def wrapped_method(self, *args, **kwargs):\n        if self.assembler is not None:\n            raise self._TACSError(\n                f\"`{method.__name__}` is a pre-initialize method. \"\n                \"It may only be called before the 'initialize' method has been called.\"\n            )\n        else:\n            return method(self, *args, **kwargs)",
  "def wrapped_method(self, *args, **kwargs):\n        if self.assembler is None:\n            raise self._TACSError(\n                f\"`{method.__name__}` is a post-initialize method. \"\n                \"It may only be called after the 'initialize' method has been called.\"\n            )\n        else:\n            return method(self, *args, **kwargs)",
  "def __init__(self, fileName, comm=None, dvNum=0, scaleList=None, options=None):\n        \"\"\"\n\n        Parameters\n        ----------\n        fileName : str\n            The filename of the BDF file to load.\n\n        comm : mpi4py.MPI.Intracomm\n            The comm object on which to create the pyTACS object.\n\n        dvNum : int\n            A user-supplied offset to the design variable\n            numbering. This is typically used with tacs+tripan when\n            geometric variables have already been added and assigned\n            global tacs numberings.\n\n        scaleList: list\n            when dvNum is non-zero, the scaleList must be same size\n            as the number of design variables already added. i.e.\n            len(scaleList) = dvNum\n\n        options : dict\n            Dictionary holding model-specific option parameters (case-insensitive).\n        \"\"\"\n\n        startTime = time.time()\n\n        # Setup comm and options\n        BaseUI.__init__(self, options=options, comm=comm)\n\n        importTime = time.time()\n\n        # Create and load mesh loader object.\n        debugFlag = self.getOption(\"printDebug\")\n        self.meshLoader = pyMeshLoader(self.comm, debugFlag)\n        self.meshLoader.scanBdfFile(fileName)\n        self.bdfName = fileName\n        # Save pynastran bdf object\n        self.bdfInfo = self.meshLoader.getBDFInfo()\n\n        meshLoadTime = time.time()\n\n        # Retrieve the number of components. This is the maximum\n        # number of unique constitutive objects possible in this model.\n        self.nComp = self.meshLoader.getNumComponents()\n\n        # Load all the component descriptions\n        self.compDescripts = self.meshLoader.getComponentDescripts()\n        self.elemDescripts = self.meshLoader.getElementDescripts()\n\n        # Set the starting dvNum and scaleList\n        self.dvNum = dvNum\n        self.scaleList = scaleList\n        if scaleList is None:\n            self.scaleList = []\n\n        DVPreprocTime = time.time()\n\n        # List of DV groups\n        self.globalDVs = {}\n        self.massDVs = {}\n        self.compIDBounds = {}\n        self.addedCompIDs = set()\n\n        # List of initial coordinates\n        self.Xpts0 = None\n        # List of initial designvars\n        self.x0 = None\n        # Design var upper/lower-bounds\n        self.xub = None\n        self.xlb = None\n\n        # Variables per node for model\n        self.varsPerNode = None\n\n        # TACS assembler object\n        self.assembler = None\n\n        initFinishTime = time.time()\n        if self.getOption(\"printTiming\"):\n            self._pp(\"+--------------------------------------------------+\")\n            self._pp(\"|\")\n            self._pp(\"| TACS Init Times:\")\n            self._pp(\"|\")\n            self._pp(\n                \"| %-30s: %10.3f sec\" % (\"TACS Module Time\", importTime - startTime)\n            )\n            self._pp(\n                \"| %-30s: %10.3f sec\"\n                % (\"TACS Meshload Time\", meshLoadTime - importTime)\n            )\n            self._pp(\n                \"| %-30s: %10.3f sec\"\n                % (\"TACS DV Processing Time\", DVPreprocTime - meshLoadTime)\n            )\n            self._pp(\n                \"| %-30s: %10.3f sec\"\n                % (\"TACS Finalize Initialization Time\", initFinishTime - DVPreprocTime)\n            )\n            self._pp(\"|\")\n            self._pp(\n                \"| %-30s: %10.3f sec\"\n                % (\"TACS Total Initialization Time\", initFinishTime - startTime)\n            )\n            self._pp(\"+--------------------------------------------------+\")",
  "def addGlobalDV(self, descript, value, lower=None, upper=None, scale=1.0):\n        \"\"\"\n        Add a global design variable that can affect multiple components.\n\n        This function allows adding design variables that are not\n        cleanly associated with a particular constitutive object. One\n        example is the pitch of the stiffeners for blade-stiffened\n        panels. It is often the same for many different constitutive\n        objects. By calling this function, the internal dvNum counter\n        is incremented, and the user doesn't have to worry about\n        it.\n\n        Parameters\n        ----------\n        descript : str\n            A user-supplied string that can be used to retrieve the\n            variable number and value elemCallBackFunction.\n        value : float\n            Initial value for variable.\n        lower : float\n            Lower bound. This may be None for unbounded\n        upper : float\n            Upper bound. This may be None for unbounded\n        scale : float\n            Scale factor for variable\n        \"\"\"\n        self.globalDVs[descript] = {\n            \"num\": self.dvNum,\n            \"value\": value,\n            \"lowerBound\": lower,\n            \"upperBound\": upper,\n            \"isMassDV\": False,\n        }\n        self.dvNum += 1\n        self.scaleList.append(scale)",
  "def getGlobalDVs(self):\n        \"\"\"\n        Return dict holding info about all current global DVs.\n\n        Returns\n        -------\n        globalDVs : dict\n            Dictionary holding global dv information.\n        \"\"\"\n        return self.globalDVs.copy()",
  "def getGlobalDVKeys(self):\n        \"\"\"\n        Get key names for all current global DVs.\n\n        Returns\n        -------\n        globalDVKeys : list[str]\n            List holding global dv names.\n        \"\"\"\n        return list(self.globalDVs.keys())",
  "def getGlobalDVNums(self):\n        \"\"\"\n        Get the dv nums corresponding to global DVs.\n\n        Returns\n        -------\n        globalDVNums : list[int]\n            List holding dv nums corresponding to global DVs.\n        \"\"\"\n        return [self.globalDVs[descript][\"num\"] for descript in self.globalDVs]",
  "def getTotalNumGlobalDVs(self):\n        \"\"\"\n        Get the total number of global DVs across all processors.\n\n        Returns\n        -------\n        globalDVs : dict\n            Dictionary holding global dv information.\n        \"\"\"\n        return len(self.globalDVs)",
  "def assignMassDV(self, descript, eIDs, dvName=\"m\"):\n        \"\"\"\n        Assign a global DV to a point mass element.\n\n        Parameters\n        ----------\n        descript : str\n            Global DV key to assign mass design variable to. If the key is does not exist,\n            it will automatically be created and added to global DVs.\n\n        eIDs : int or list[int]\n            Element IDs of concentrated mass to assign DV to (NASTRAN ordering)\n\n        dvName : str\n            Name of mass property to apply DV to.\n            May be `m` for mass, `I11`, `I22`, `I12`, etc. for moment of inertia components.\n            Defaults to `m` (mass).\n\n        Notes\n        -----\n        Currently only CONM2 cards are supported.\n        \"\"\"\n        # Make sure eID is an array\n        eIDs = np.atleast_1d(eIDs)\n\n        # Check if referenced element ID is a CONM2 element\n        for eID in eIDs:\n            is_mass_element = False\n            if eID in self.bdfInfo.masses:\n                if self.bdfInfo.masses[eID].type in [\"CONM2\"]:\n                    is_mass_element = True\n\n            if not is_mass_element:\n                raise self._TACSError(\n                    f\"Element ID '{eID}' does not correspond to a `CONM2` element. \"\n                    \"Only `CONM2` elements are supported for this method.\"\n                )\n\n        # Check if descript already exists in global dvs, if not add it\n        if descript not in self.globalDVs:\n            self.addGlobalDV(descript, None)\n\n        dv_dict = self.globalDVs[descript]\n\n        # Flag this global dv as being a mass dv\n        dv_dict[\"isMassDV\"] = True\n\n        massDV = dv_dict[\"num\"]\n        value = dv_dict[\"value\"]\n        ub = dv_dict[\"upperBound\"]\n        lb = dv_dict[\"lowerBound\"]\n\n        for eID in eIDs:\n            # If the element ID hasn't already been added to massDVs, add it\n            if eID not in self.massDVs:\n                self.massDVs[eID] = {}\n\n            # Update the element entry with the dv num\n            self.massDVs[eID][f\"{dvName}Num\"] = massDV\n\n            # Update the element entry with the dv name\n            if value is not None:\n                self.massDVs[eID][dvName] = value\n            # If value was defined from previous call, remove it\n            elif dvName in self.massDVs[eID]:\n                self.massDVs[eID].pop(dvName)\n\n            # Update the element entry with the dv upper bound\n            if ub is not None:\n                self.massDVs[eID][f\"{dvName}ub\"] = ub\n            # If upper bound was defined from previous call, remove it\n            elif f\"{dvName}ub\" in self.massDVs[eID]:\n                self.massDVs[eID].pop(f\"{dvName}ub\")\n\n            # Update the element entry with the dv lower bound\n            if lb is not None:\n                self.massDVs[eID][f\"{dvName}lb\"] = lb\n            # If lower bound was defined from previous call, remove it\n            elif f\"{dvName}lb\" in self.massDVs[eID]:\n                self.massDVs[eID].pop(f\"{dvName}lb\")",
  "def selectCompIDs(\n        self,\n        include=None,\n        exclude=None,\n        includeBounds=None,\n        nGroup=1,\n        includeOp=\"or\",\n        excludeOp=\"or\",\n        projectVector=None,\n        **kwargs,\n    ):\n        \"\"\"\n        This is the most important function of the entire setup\n        process.\n        The basic idea is as follows: We have a list of nComp\n        which are the component descriptions.\n        What we need is a way of\n        generating subgroups of these for the purposes of adding\n        design variables, constitutive objects, KS domains, and mass\n        domains.\n        All of these operations boil down to selecting a\n        subset of the compIDs.\n\n        This function attempts to support as many ways as possible to\n        select parts of the structure.\n        Easy and efficient selection of\n        parts is critical to the end user.\n\n        Methods of selection:\n\n        1. include, integer, string, list of integers and/or strings: The\n        simplest and most direct way of selecting a component.\n        The\n        user supplies the index of the componentID, a name or partial\n        name, or a list containing a combination of both.\n\n        For example::\n\n            # Select the 11th component\n            selectCompIDs(include=10)\n\n            # Select the first and fifth component\n            selectCompIDs(include=[0, 4])\n\n            # Select any component containing 'rib.00'\n            selectCompIDs(include='rib.00')\n\n            # Select any components containing 'rib.00' and 'rib.10'\n            selectCompIDs(include=['rib.00', 'rib.10'])\n\n            # Select any component containing 'rib.00', the 11th\n            # component and any component containing 'spar'\n            # (This is probably not advisable!)\n            selectCompIDs(include=['rib.00', 10, 'spar'])\n\n        2. Exclude, operates similarly to 'include'.\n        The behaviour of exclude is identical to include above, except that\n        component ID's that are found using 'exclude' are\n        'subtracted' from those found using include.\n        A special case is treated if 'include' is NOT given: if only an\n        exclude list is given, this implies the selection of all\n        compID's EXCEPT the those in exclude.\n\n        For example::\n\n            # This will return will [0, 1, 2, 3, 5, ..., nComp-1]\n            selectCompIDs(exclude = 4)\n\n            # This will return [0, 1, 4, 5, ..., nComp-1]\n            selectCompIDs(exclude = [2, 3]) will return\n\n            # This will return components that have 'ribs' in the\n            # component ID, but not those that have 'le_ribs' in the\n            # component id.\n            selectCompIDs(include='ribs', exclude='le_ribs')\n\n        3. includeBounds, list of components defining a region inside\n        which 'include' components will be selected.\n        This functionality uses a geometric approach to select the compIDs.\n        All components within the project 2D convex hull are included.\n        Therefore, it is essential to split up concave include regions\n        into smaller convex regions.\n        Use multiple calls to selectCompIDs to accumulate multiple regions.\n\n        For example::\n\n            # This will select upper skin components between the\n            # leading and trailing edge spars and between ribs 1 and 4.\n            selectCompIDs(include='U_SKIN', includeBound=\n                ['LE_SPAR', 'TE_SPAR', 'RIB.01', 'RIB.04'])\n\n        4. nGroup: The number of groups to divide the found components\n        into.\n        Generally this will be 1. However, in certain cases, it\n        is convenient to create multiple groups in one pass.\n\n        For example::\n\n            # This will 'evenly' create 10 groups on all components\n            # containing LE_SPAR.\n            Note that once the components are\n            # selected, they are sorted **alphabetically** and assigned\n            # sequentially.\n            selectCompIDs(include='LE_SPAR', nGroup=10)\n\n        nGroup can also be negative.\n        If it is negative, then a single\n        design variable group is added to each of the found\n        components.\n\n        For example::\n\n            # will select all components and assign a design variable\n            # group to each one.\n            selectCompIDs(nGroup=-1)\n\n        includeOp, str: 'and' or 'or'.\n        Selects the logical operation\n        used for item in 'include' option.\n        For example:\n\n        selectCompIDs(include=['LE_SPAR', 'TE_SPAR'],\n        includeOpt='or') will select the LE_SPAR and TE_SPAR\n        components (default behaviour).\n\n        selectCompIDs(include=['RIB', 'SEG.01'], includeOpt='and')\n        will select any component with 'RIB' in the description AND\n        'SEG.01' in the description.\n        \"\"\"\n\n        # Defaults\n        includeIDs = np.arange(self.nComp)\n        excludeIDs = []\n        includeBoundIDs = None\n\n        if include is not None:\n            includeIDs = self._getCompIDs(includeOp, include)\n\n        if exclude is not None:\n            excludeIDs = self._getCompIDs(excludeOp, exclude)\n\n        iSet = set(includeIDs)\n        eSet = set(excludeIDs)\n\n        # First take the intersection of iSet and ibSet\n        if includeBoundIDs is not None:\n            tmp = iSet.intersection(set(includeBoundIDs))\n        else:\n            tmp = iSet\n\n        # Next take the difference between tmp and eSet\n        compIDs = tmp.difference(eSet)\n\n        # Convert back to a list:\n        compIDs = list(compIDs)\n\n        # If we only want a single group, we're done, otherwise, we\n        # have a bit more work to do...\n        if nGroup > 1:\n            # The user wants to have nGroups returned from compIDs.\n\n            # First check that nGroup <= len(compIDs), print warning\n            # and clip if not\n            if nGroup > len(compIDs):\n                self._TACSWarning(\n                    f\"nGroup={nGroup} is larger than the number of\\\n                selected components={len(compIDs)}. nGroup will be clipped to {nGroup}\"\n                )\n                nGroup = len(compIDs)\n\n            # Pluck out the component descriptions again and we will\n            # sort them\n            compDescript = []\n            for i in range(len(compIDs)):\n                compDescript.append(self.compDescripts[compIDs[i]])\n\n            # define a general argsort\n            def argsort(seq):\n                return sorted(range(len(seq)), key=seq.__getitem__)\n\n            # ind is the index that would result in a sorted list.\n            ind = argsort(compDescript)\n\n            # Now simply divide 'ind' into 'nGroups' as evenly as\n            # possible, in the integer sense.\n            def split_list(alist, wanted_parts=1):\n                length = len(alist)\n                return [\n                    alist[i * length // wanted_parts : (i + 1) * length // wanted_parts]\n                    for i in range(wanted_parts)\n                ]\n\n            ind = split_list(ind, nGroup)\n\n            # Finally assemble the nested list of component IDs\n            tmp = []\n            for i in range(len(ind)):\n                tmp.append([])\n                for j in range(len(ind[i])):\n                    tmp[-1].append(compIDs[ind[i][j]])\n            compIDs = tmp\n        elif nGroup < 0:\n            # Negative number signifies 'add one dv to each component'\n            tmp = []\n            for comp in compIDs:\n                tmp.append([comp])\n            compIDs = tmp\n        else:\n            # Otherwise, just put the current list of compIDs in a\n            # list of length 1.\n            compIDs = [compIDs]\n\n        return compIDs",
  "def getBDFInfo(self):\n        \"\"\"\n        Return a pynastran bdf object.\n        This object can be used interactively\n        to parse information (nodes, elements, loads, etc.) included in the bdf file.\n\n        Returns\n        -------\n        bdfInfo : pyNastran.bdf.bdf.BDF\n            pyNastran bdf object.\n        \"\"\"\n        return self.bdfInfo",
  "def getCompNames(self, compIDs=None):\n        \"\"\"\n        Return a list of component descriptions for the given component\n        IDs. compIDs should come from a call to selectCompIDs\n\n        Parameters\n        ----------\n        compIDs : int or list[int] or None\n            List of integers containing the compIDs numbers. If None, returns names for all components.\n            Defaults to None.\n\n        Returns\n        -------\n        compDescript : list[str]\n            List of strings containing the names of the corresponding compIDs\n        \"\"\"\n        # Return all component names\n        if compIDs is None:\n            return copy.deepcopy(self.compDescripts)\n        # Convert to list\n        elif isinstance(compIDs, int):\n            compIDs = [compIDs]\n        # Make sure list is flat\n        else:\n            compIDs = self._flatten(compIDs)\n\n        compDescripts = []\n        for i in range(len(compIDs)):\n            compDescripts.append(self.compDescripts[compIDs[i]])\n\n        return compDescripts",
  "def getGlobalNodeIDsForComps(self, compIDs, nastranOrdering=False):\n        \"\"\"\n        Return the global (non-partitioned) node IDs belonging to a given list of component IDs\n\n        Parameters\n        ----------\n        compIDs : int or list[int] or None\n            List of integers containing the compIDs numbers.\n            If None, returns nodeIDs for all components.\n            Defaults to None.\n\n        nastranOrdering : bool\n            Flag signaling whether nodeIDs are in TACS (default) or NASTRAN (grid IDs in bdf file) ordering\n            Defaults to False.\n\n        Returns\n        -------\n        nodeIDs : list[int]\n            List of unique nodeIDs that belong to the given list of compIDs\n        \"\"\"\n        # Return all component ids\n        if compIDs is None:\n            compIDs = list(range(self.nComp))\n\n        return self.meshLoader.getGlobalNodeIDsForComps(compIDs, nastranOrdering)",
  "def getLocalNodeIDsForComps(self, compIDs):\n        \"\"\"\n        Return the local (partitioned) node IDs belonging to a given list of component IDs\n\n        Parameters\n        ----------\n         compIDs : int or list[int] or None\n            List of integers containing the compIDs numbers.\n            If None, returns nodeIDs for all components.\n            Defaults to None.\n\n        Returns\n        -------\n        nodeIDs : list[int]\n            List of unique nodeIDs that belong to the given list of compIDs\n        \"\"\"\n        # Return all component ids\n        if compIDs is None:\n            compIDs = list(range(self.nComp))\n\n        return self.meshLoader.getLocalNodeIDsForComps(compIDs)",
  "def initialize(self, elemCallBack=None):\n        \"\"\"\n        This is the 'last' method to be called during the setup. The\n        user should have already added all the design variables,\n        domains, etc. Before this function is called. This function\n        finalizes the problem initialization and cannot be changed at\n        later time. If the user does not provide an elemCallBack function,\n        we will use pyNastran to generate one automatically from element\n        properties provided in the BDF file.\n\n        Parameters\n        ----------\n        elemCallBack : callable\n\n           The calling sequence for elemCallBack **must** be as\n           follows::\n\n             def elemCallBack(dvNum, compID, compDescript, elemDescripts,\n                             globalDVs, **kwargs):\n\n           The dvNum is the current counter which must be used by the\n           user when creating a constitutive object with design\n           variables.\n\n           compID is the ID number used by tacs to reference this property group.\n           Use kwargs['propID'] to get the corresponding Nastran property ID that\n           is read in from the BDF.\n\n           compDescript is the component description label read in from optional\n           formatted comments in BDF file\n\n           elemDescripts are the name of the elements belonging to this group\n           (e.g. CQUAD4, CTRIA3, CTETRA, etc). This value will be a list since\n           one component may contain multiple compatible element types.\n           Example: ['CQUAD4', CTRIA3']\n\n           globalDVs is a dictionary containing information about any\n           global DVs that have been added.\n\n           elemCallBack must return a list containing as many TACS element\n           objects as there are element types in elemDescripts (one for each).\n\n        \"\"\"\n\n        if elemCallBack is None:\n            elemCallBack = self._elemCallBackFromBDF()\n        self._createOutputGroups()\n        self._createElements(elemCallBack)\n\n        self.assembler = self.meshLoader.createTACSAssembler(\n            self.varsPerNode, self.massDVs\n        )\n\n        self._createOutputViewer()\n\n        # Store original node locations read in from bdf file\n        self.Xpts0 = self.assembler.createNodeVec()\n        self.assembler.getNodes(self.Xpts0)\n\n        # Store initial design variable values\n        self.x0 = self.assembler.createDesignVec()\n        self.assembler.getDesignVars(self.x0)\n\n        # Store design variable upper/lower-bounds\n        self.xub = self.assembler.createDesignVec()\n        self.xlb = self.assembler.createDesignVec()\n        self.assembler.getDesignVarRange(self.xlb, self.xub)",
  "def _elemCallBackFromBDF(self):\n        \"\"\"\n        Automatically setup elemCallBack using information contained in BDF file.\n        This function assumes all material properties are specified in the BDF.\n        \"\"\"\n\n        # Check if any properties are in the BDF\n        if self.bdfInfo.missing_properties:\n            raise self._TACSError(\n                f\"BDF file '{self.bdfName}' has missing properties cards. \"\n                \"Set 'printDebug' option to True for more information. \"\n                \"User must define own elemCallBack function.\"\n            )\n\n        # Make sure cross-referencing is turned on in pynastran\n        if self.bdfInfo.is_xrefed is False:\n            self.bdfInfo.cross_reference()\n            self.bdfInfo.is_xrefed = True\n\n        # Create a dictionary to sort all elements by property number\n        elemDict = {}\n        for elementID in self.bdfInfo.elements:\n            element = self.bdfInfo.elements[elementID]\n            propertyID = element.pid\n            if propertyID not in elemDict:\n                elemDict[propertyID] = {}\n                elemDict[propertyID][\"elements\"] = []\n                elemDict[propertyID][\"dvs\"] = {}\n            elemDict[propertyID][\"elements\"].append(element)\n\n        # Create a dictionary to sort all design variables\n        for dv in self.bdfInfo.dvprels:\n            propertyID = self.bdfInfo.dvprels[dv].pid\n            dvName = self.bdfInfo.dvprels[dv].pname_fid\n            self.dvNum = max(self.dvNum, self.bdfInfo.dvprels[dv].dvids[0])\n            elemDict[propertyID][\"dvs\"][dvName] = self.bdfInfo.dvprels[dv]\n        # Create option for user to specify scale values in BDF\n        self.scaleList = [1.0] * self.dvNum\n\n        # Callback function to return appropriate tacs MaterialProperties object\n        # For a pynastran mat card\n        def matCallBack(matInfo):\n            # Nastran isotropic material card\n            if matInfo.type == \"MAT1\":\n                mat = tacs.constitutive.MaterialProperties(\n                    rho=matInfo.rho,\n                    E=matInfo.e,\n                    nu=matInfo.nu,\n                    ys=matInfo.St,\n                    alpha=matInfo.a,\n                )\n            # Nastran orthotropic material card\n            elif matInfo.type == \"MAT8\":\n                E1 = matInfo.e11\n                E2 = matInfo.e22\n                nu12 = matInfo.nu12\n                G12 = matInfo.g12\n                G13 = matInfo.g1z\n                G23 = matInfo.g2z\n                # If out-of-plane shear values are 0, Nastran defaults them to the in-plane\n                if G13 == 0.0:\n                    G13 = G12\n                if G23 == 0.0:\n                    G23 = G12\n                rho = matInfo.rho\n                Xt = matInfo.Xt\n                Xc = matInfo.Xc\n                Yt = matInfo.Yt\n                Yc = matInfo.Yc\n                S12 = matInfo.S\n                # TODO: add alpha\n                mat = tacs.constitutive.MaterialProperties(\n                    rho=rho,\n                    E1=E1,\n                    E2=E2,\n                    nu12=nu12,\n                    G12=G12,\n                    G13=G13,\n                    G23=G23,\n                    Xt=Xt,\n                    Xc=Xc,\n                    Yt=Yt,\n                    Yc=Yc,\n                    S12=S12,\n                )\n            # Nastran 2D anisotropic material card\n            elif matInfo.type == \"MAT2\":\n                C11 = matInfo.G11\n                C12 = matInfo.G12\n                C22 = matInfo.G22\n                C13 = matInfo.G13\n                C23 = matInfo.G23\n                C33 = matInfo.G33\n                rho = matInfo.rho\n                # See if this card features anisotropic coupling terms (which we don't support yet)\n                if (\n                    np.abs(C13) / (C11 + C22) >= 1e-8\n                    or np.abs(C23) / (C11 + C22) >= 1e-8\n                ):\n                    self._TACSWarning(\n                        f\"MAT2 card {matInfo.mid} has anisotropic stiffness components that are not currently supported. \"\n                        \"These terms will be dropped and the material treated as orthotropic. \"\n                        \"Result accuracy may be affected.\"\n                    )\n                nu12 = C12 / C22\n                nu21 = C12 / C11\n                E1 = C11 * (1 - nu12 * nu21)\n                E2 = C22 * (1 - nu12 * nu21)\n                G12 = G13 = G23 = C33\n                # TODO: add alpha\n                mat = tacs.constitutive.MaterialProperties(\n                    rho=rho, E1=E1, E2=E2, nu12=nu12, G12=G12, G13=G13, G23=G23\n                )\n\n            else:\n                raise self._TACSError(\n                    f\"Unsupported material type '{matInfo.type}' for material number {matInfo.mid}.\"\n                )\n\n            return mat\n\n        def elemCallBack(\n            dvNum, compID, compDescript, elemDescripts, globalDVs, **kwargs\n        ):\n            # Initialize scale list for design variables we will add\n            scaleList = []\n\n            # Get the Nastran property ID\n            propertyID = kwargs[\"propID\"]\n            propInfo = self.bdfInfo.properties[propertyID]\n            elemInfo = elemDict[propertyID][\"elements\"][0]\n\n            # First we define the material object\n            mat = None\n            # This property only references one material\n            if hasattr(propInfo, \"mid_ref\"):\n                matInfo = propInfo.mid_ref\n                mat = matCallBack(matInfo)\n            # This property references multiple materials (maybe a laminate)\n            elif hasattr(propInfo, \"mids_ref\"):\n                mat = []\n                for matInfo in propInfo.mids_ref:\n                    mat.append(matCallBack(matInfo))\n\n            # Next we define the constitutive object\n            if propInfo.type == \"PSHELL\":  # Nastran isotropic shell\n                kcorr = propInfo.tst\n\n                if \"T\" in elemDict[propertyID][\"dvs\"]:\n                    thickness = elemDict[propertyID][\"dvs\"][\"T\"].dvids_ref[0].xinit\n                    tNum = elemDict[propertyID][\"dvs\"][\"T\"].dvids[0] - 1\n                    minThickness = elemDict[propertyID][\"dvs\"][\"T\"].dvids_ref[0].xlb\n                    maxThickness = elemDict[propertyID][\"dvs\"][\"T\"].dvids_ref[0].xub\n                    name = elemDict[propertyID][\"dvs\"][\"T\"].dvids_ref[0].label\n                    self.scaleList[tNum - 1] = elemDict[propertyID][\"dvs\"][\"T\"].coeffs[\n                        0\n                    ]\n                else:\n                    thickness = propInfo.t\n                    tNum = -1\n                    minThickness = 0.0\n                    maxThickness = 1e20\n\n                con = tacs.constitutive.IsoShellConstitutive(\n                    mat, t=thickness, tlb=minThickness, tub=maxThickness, tNum=tNum\n                )\n\n            elif propInfo.type == \"PCOMP\":  # Nastran composite shell\n                numPlies = propInfo.nplies\n                plyThicknesses = []\n                plyAngles = []\n                plyMats = []\n\n                # if the laminate is symmetric, mirror the ply indices\n                if propInfo.lam == \"SYM\":\n                    plyIndices = list(range(numPlies // 2))\n                    plyIndices.extend(plyIndices[::-1])\n                else:\n                    plyIndices = range(numPlies)\n\n                # Loop through plies and setup each entry in layup\n                for ply_i in plyIndices:\n                    plyThicknesses.append(propInfo.thicknesses[ply_i])\n                    plyMat = tacs.constitutive.OrthotropicPly(\n                        plyThicknesses[ply_i], mat[ply_i]\n                    )\n                    plyMats.append(plyMat)\n                    plyAngles.append(np.deg2rad(propInfo.thetas[ply_i]))\n\n                # Convert thickness/angles to appropriate numpy array\n                plyThicknesses = np.array(plyThicknesses, dtype=self.dtype)\n                plyAngles = np.array(plyAngles, dtype=self.dtype)\n\n                if propInfo.lam is None or propInfo.lam in [\"SYM\", \"MEM\"]:\n                    # Discrete laminate class (not for optimization)\n                    con = tacs.constitutive.CompositeShellConstitutive(\n                        plyMats, plyThicknesses, plyAngles\n                    )\n\n                elif propInfo.lam == \"SMEAR\":\n                    lamThickness = sum(plyThicknesses)\n                    plyFractions = plyThicknesses / lamThickness\n                    con = tacs.constitutive.SmearedCompositeShellConstitutive(\n                        plyMats, lamThickness, plyAngles, plyFractions\n                    )\n\n                # Need to add functionality to consider only membrane in TACS for type = MEM\n                else:\n                    raise self._TACSError(\n                        f\"Unrecognized LAM type '{propInfo.lam}' for PCOMP number {propertyID}.\"\n                    )\n\n            elif propInfo.type == \"PSOLID\":  # Nastran solid property\n                if \"T\" in elemDict[propertyID][\"dvs\"]:\n                    thickness = elemDict[propertyID][\"dvs\"][\"T\"].dvids_ref[0].xinit\n                    tNum = elemDict[propertyID][\"dvs\"][\"T\"].dvids[0] - 1\n                    minThickness = elemDict[propertyID][\"dvs\"][\"T\"].dvids_ref[0].xlb\n                    maxThickness = elemDict[propertyID][\"dvs\"][\"T\"].dvids_ref[0].xub\n                    name = elemDict[propertyID][\"dvs\"][\"T\"].dvids_ref[0].label\n                    self.scaleList[tNum - 1] = elemDict[propertyID][\"dvs\"][\"T\"].coeffs[\n                        0\n                    ]\n                else:\n                    thickness = 1.0\n                    tNum = -1\n                    minThickness = 0.0\n                    maxThickness = 10.0\n\n                con = tacs.constitutive.SolidConstitutive(\n                    mat, t=thickness, tlb=minThickness, tub=maxThickness, tNum=tNum\n                )\n\n            elif propInfo.type == \"PBUSH\":  # Nastran spring\n                k = np.zeros(6)\n                for j in range(len(k)):\n                    if propInfo.Ki[j]:\n                        k[j] = propInfo.Ki[j]\n                con = tacs.constitutive.DOFSpringConstitutive(k=k)\n\n            elif propInfo.type == \"PBAR\":  # Nastran bar\n                area = propInfo.A\n                I1 = propInfo.i1\n                I2 = propInfo.i2\n                I12 = propInfo.i12\n                J = propInfo.j\n                k1 = propInfo.k1\n                k2 = propInfo.k2\n\n                # pynastran defaults these values to 1e8,\n                # which can lead to scaling issues in the stiffness matrix\n                # We truncate this value to 1e3 to prevent this\n                if k1 is None or k1 > 1e3:\n                    k1 = 1e3\n\n                if k2 is None or k2 > 1e3:\n                    k2 = 1e3\n\n                con = tacs.constitutive.BasicBeamConstitutive(\n                    mat, A=area, Iy=I2, Iz=I1, Iyz=I12, J=J, ky=k1, kz=k2\n                )\n\n            elif propInfo.type == \"PROD\":  # Nastran rod\n                area = propInfo.A\n                J = propInfo.j\n                k1 = 0.0\n                k2 = 0.0\n\n                con = tacs.constitutive.BasicBeamConstitutive(\n                    mat, A=area, J=J, ky=k1, kz=k2\n                )\n\n            else:\n                raise self._TACSError(\n                    f\"Unsupported property type '{propInfo.type}' for property number {propertyID}. \"\n                )\n\n            # Set up transform object which may be required for certain elements\n            transform = None\n            if propInfo.type in [\"PSHELL\", \"PCOMP\"]:\n                mcid = elemDict[propertyID][\"elements\"][0].theta_mcid_ref\n                if mcid:\n                    if mcid.type == \"CORD2R\":\n                        refAxis = mcid.i\n                        transform = tacs.elements.ShellRefAxisTransform(refAxis)\n                    else:  # Don't support spherical/cylindrical yet\n                        raise self._TACSError(\n                            \"Unsupported material coordinate system type \"\n                            f\"'{mcid.type}' for property number {propertyID}.\"\n                        )\n            elif propInfo.type in [\"PBAR\"]:\n                refAxis = elemDict[propertyID][\"elements\"][0].g0_vector\n                transform = tacs.elements.BeamRefAxisTransform(refAxis)\n            elif propInfo.type == \"PROD\":\n                refAxis = np.array(\n                    [1.0, -1.0, 1.0]\n                )  # dummy ref_axis, not really needed for rods\n                transform = tacs.elements.BeamRefAxisTransform(refAxis)\n            elif propInfo.type == \"PBUSH\":\n                if elemDict[propertyID][\"elements\"][0].cid_ref:\n                    refAxis_i = elemDict[propertyID][\"elements\"][0].cid_ref.i\n                    refAxis_j = elemDict[propertyID][\"elements\"][0].cid_ref.j\n                    transform = tacs.elements.SpringRefFrameTransform(\n                        refAxis_i, refAxis_j\n                    )\n                elif elemDict[propertyID][\"elements\"][0].x[0]:\n                    refAxis = (\n                        np.array(elemDict[propertyID][\"elements\"][0].x)\n                        - elemDict[propertyID][\"elements\"][0]\n                        .nodes_ref[0]\n                        .get_position()\n                    )\n                    transform = tacs.elements.SpringRefAxisTransform(refAxis)\n                elif elemDict[propertyID][\"elements\"][0].g0_ref:\n                    refAxis = (\n                        elemDict[propertyID][\"elements\"][0].g0_ref.get_position()\n                        - elemDict[propertyID][\"elements\"][0]\n                        .nodes_ref[0]\n                        .get_position()\n                    )\n                    transform = tacs.elements.SpringRefAxisTransform(refAxis)\n\n            # Finally set up the element objects belonging to this component\n            elemList = []\n            for descript in elemDescripts:\n                if descript in [\"CQUAD4\", \"CQUADR\"]:\n                    elem = tacs.elements.Quad4Shell(transform, con)\n                elif descript in [\"CQUAD9\", \"CQUAD\"]:\n                    elem = tacs.elements.Quad9Shell(transform, con)\n                elif descript in [\"CTRIA3\", \"CTRIAR\"]:\n                    elem = tacs.elements.Tri3Shell(transform, con)\n                elif descript in [\"CBAR\", \"CROD\"]:\n                    elem = tacs.elements.Beam2(transform, con)\n                elif \"CTETRA\" in descript:\n                    # May have variable number of nodes in card\n                    nnodes = len(elemInfo.nodes)\n                    if nnodes == 4:\n                        basis = tacs.elements.LinearTetrahedralBasis()\n                    elif nnodes == 10:\n                        basis = tacs.elements.QuadraticTetrahedralBasis()\n                    else:\n                        raise self._TACSError(\n                            f\"TACS does not currently support CTETRA elements with {nnodes} nodes.\"\n                        )\n                    model = tacs.elements.LinearElasticity3D(con)\n                    elem = tacs.elements.Element3D(model, basis)\n                elif descript in [\"CHEXA8\", \"CHEXA\"]:\n                    basis = tacs.elements.LinearHexaBasis()\n                    model = tacs.elements.LinearElasticity3D(con)\n                    elem = tacs.elements.Element3D(model, basis)\n                elif descript == \"CBUSH\":\n                    elem = tacs.elements.SpringElement(transform, con)\n                else:\n                    raise self._TACSError(\n                        \"Unsupported element type \"\n                        f\"'{descript}' specified for property number {propertyID}.\"\n                    )\n                elemList.append(elem)\n\n            return elemList, scaleList\n\n        return elemCallBack",
  "def getOrigDesignVars(self):\n        \"\"\"\n        get the original design variables that were specified with\n        during assembler creation.\n\n        Returns\n        -------\n        x : numpy.ndarray\n            The original design variable vector set in tacs.\n\n        \"\"\"\n        return self.x0.getArray().copy()",
  "def getDesignVarRange(self):\n        \"\"\"\n        get the lower/upper bounds for the design variables.\n\n        Returns\n        -------\n        xlb : numpy.ndarray\n            The design variable lower bound.\n        xub : numpy.ndarray\n            The design variable upper bound.\n\n        \"\"\"\n        return self.xlb.getArray().copy(), self.xub.getArray().copy()",
  "def createDesignVec(self, asBVec=False):\n        \"\"\"\n        Create a new tacs distributed design vector.\n        Values are initialized to zero.\n\n        Parameters\n        ----------\n        asBVec : bool\n            Flag that determines whether to return\n            design vector as tacs :class:`~TACS.Vec` (True) or numpy array (False).\n            Defaults to False.\n\n        Returns\n        -------\n        x : numpy.ndarray or tacs.TACS.Vec\n            Distributed design variable vector\n        \"\"\"\n        xVec = self.assembler.createDesignVec()\n        if asBVec:\n            return xVec\n        else:\n            return xVec.getArray()",
  "def getNumDesignVars(self):\n        \"\"\"\n        Return the number of design variables on this processor.\n\n        Returns\n        -------\n        ndvs : int\n            Number of design variables on this processor.\n        \"\"\"\n        return self.x0.getSize()",
  "def getTotalNumDesignVars(self):\n        \"\"\"\n        Return the number of design variables across all processors.\n\n        Returns\n        -------\n        ndvs : int\n            Total number of design variables across all processors.\n        \"\"\"\n        return self.dvNum",
  "def getOrigNodes(self):\n        \"\"\"\n        Return the original mesh coordinates read in from the meshLoader.\n\n        Returns\n        -------\n        coords : numpy.ndarray\n            Structural coordinate in array of size (N * 3) where N is\n            the number of structural nodes on this processor.\n        \"\"\"\n        return self.Xpts0.getArray().copy()",
  "def createNodeVec(self, asBVec=False):\n        \"\"\"\n        Create a new tacs distributed node vector.\n        Values are initialized to zero.\n\n        Parameters\n        ----------\n        asBVec : bool\n            Flag that determines whether to return\n            node vector as tacs :class:`~TACS.Vec` (True) or numpy array (False).\n            Defaults to False.\n\n        Returns\n        -------\n        xpts : numpy.ndarray or tacs.TACS.Vec\n            Distributed node coordinate vector\n        \"\"\"\n\n        xptVec = self.assembler.createNodeVec()\n        if asBVec:\n            return xptVec\n        else:\n            return xptVec.getArray()",
  "def getNumOwnedNodes(self):\n        \"\"\"\n        Get the number of nodes owned by this processor.\n\n        Returns\n        -------\n        nNodes : int\n            Number of nodes owned by this proc.\n        \"\"\"\n        return self.assembler.getNumOwnedNodes()",
  "def getNumOwnedMultiplierNodes(self):\n        \"\"\"\n        Get the number of lagrange multiplier nodes owned by this processor.\n\n        Returns\n        -------\n        nMultNodes : int\n            Number of multiplier nodes owned by this proc.\n        \"\"\"\n        return len(self.meshLoader.getLocalMultiplierNodeIDs())",
  "def getLocalMultiplierNodeIDs(self):\n        \"\"\"\n        Get the tacs indices of multiplier nodes used to hold lagrange multipliers on this processor.\n\n        Returns\n        -------\n        nodeIDs : list[int]\n            List of multiplier node ID's owned by this proc.\n        \"\"\"\n        return self.meshLoader.getLocalMultiplierNodeIDs()",
  "def createVec(self, asBVec=False):\n        \"\"\"\n        Create a new tacs distributed state variable vector.\n        Values are initialized to zero.\n\n        Parameters\n        ----------\n        asBVec : bool\n            Flag that determines whether to return\n            state vector as tacs :class:`~TACS.Vec` (True) or numpy array (False).\n            Defaults to False.\n\n        Returns\n        -------\n        vars : numpy.ndarray or tacs.TACS.Vec\n            Distributed state variable vector\n        \"\"\"\n        vars = self.assembler.createVec()\n        if asBVec:\n            return vars\n        else:\n            return vars.getArray()",
  "def getVarsPerNode(self):\n        \"\"\"\n        Get the number of variables per node for the model.\n\n        Returns\n        -------\n        vpn : int\n            Number of variables per node.\n        \"\"\"\n        return self.assembler.getVarsPerNode()",
  "def applyBCsToVec(self, vec):\n        \"\"\"\n        Applies zeros to boundary condition DOFs in input vector.\n\n        Parameters\n        ----------\n        vec : numpy.ndarray or tacs.TACS.Vec\n            Vector to apply boundary conditions to.\n        \"\"\"\n        # Check if input is a BVec or numpy array\n        if isinstance(vec, tacs.TACS.Vec):\n            self.assembler.applyBCs(vec)\n        elif isinstance(vec, np.ndarray):\n            array = vec\n            # Create temporary BVec\n            vec = self.assembler.createVec()\n            # Copy array values to BVec\n            vec.getArray()[:] = array\n            # Apply BCs\n            self.assembler.applyBCs(vec)\n            # Copy values back to array\n            array[:] = vec.getArray()",
  "def createStaticProblem(self, name, options=None):\n        \"\"\"\n        Create a new staticProblem for modeling a static load cases.\n        This object can be used to set loads, evalFunctions as well as perform\n        solutions and sensitivities related to static problems\n\n        Parameters\n        ----------\n        name : str\n            Name to assign problem.\n        options : dict\n            Problem-specific options to pass to StaticProblem instance (case-insensitive).\n            Defaults to None.\n\n        Returns\n        -------\n        problem : tacs.problems.StaticProblem\n            StaticProblem object used for modeling and solving static cases.\n        \"\"\"\n        problem = tacs.problems.static.StaticProblem(\n            name, self.assembler, self.comm, self.outputViewer, self.meshLoader, options\n        )\n        # Set with original design vars and coordinates, in case they have changed\n        problem.setDesignVars(self.x0)\n        problem.setNodes(self.Xpts0)\n        return problem",
  "def createTransientProblem(self, name, tInit, tFinal, numSteps, options=None):\n        \"\"\"\n        Create a new TransientProblem for modeling a transient load cases.\n        This object can be used to set loads, evalFunctions as well as perform\n        solutions and sensitivities related to transient problems\n\n        Parameters\n        ----------\n        name : str\n            Name to assign problem.\n        tInit : float\n            Starting time for transient time integration\n        tFinal : float\n            Ending time for transient time integration\n        numSteps : int\n            Number of time steps for transient time integration\n        options : dict\n            Problem-specific options to pass to TransientProblem instance (case-insensitive).\n            Defaults to None.\n\n        Returns\n        -------\n        problem : tacs.problems.TransientProblem\n            TransientProblem object used for modeling and solving transient cases.\n        \"\"\"\n        problem = tacs.problems.transient.TransientProblem(\n            name,\n            tInit,\n            tFinal,\n            numSteps,\n            self.assembler,\n            self.comm,\n            self.outputViewer,\n            self.meshLoader,\n            options,\n        )\n        # Set with original design vars and coordinates, in case they have changed\n        problem.setDesignVars(self.x0)\n        problem.setNodes(self.Xpts0)\n        return problem",
  "def createModalProblem(self, name, sigma, numEigs, options=None):\n        \"\"\"\n        Create a new ModalProblem for performing modal analysis.\n        This problem can be used to identify the natural frequencies and mode\n        shapes of the model through eigenvalue analysis.\n\n        Parameters\n        ----------\n        name : str\n            Name to assign problem.\n        sigma : float\n            Guess for the lowest eigenvalue.\n            This corresponds to the lowest expected frequency squared. (rad^2/s^2)\n        numEigs : int\n            Number of eigenvalues to solve for.\n        options : dict\n            Problem-specific options to pass to ModalProblem instance (case-insensitive).\n            Defaults to None.\n\n        Returns\n        -------\n        problem : tacs.problems.ModalProblem\n            ModalProblem object used for performing modal eigenvalue analysis.\n        \"\"\"\n        problem = tacs.problems.modal.ModalProblem(\n            name,\n            sigma,\n            numEigs,\n            self.assembler,\n            self.comm,\n            self.outputViewer,\n            self.meshLoader,\n            options,\n        )\n        # Set with original design vars and coordinates, in case they have changed\n        problem.setDesignVars(self.x0)\n        problem.setNodes(self.Xpts0)\n        return problem",
  "def createBucklingProblem(self, name, sigma, numEigs, options=None):\n        \"\"\"\n        Create a new BucklingProblem for performing linearized buckling analysis.\n        This problem can be used to identify the buckling load factors and mode\n        shapes of the model through eigenvalue analysis.\n\n        Parameters\n        ----------\n        name : str\n            Name to assign problem.\n        sigma : float\n            Guess for the lowest eigenvalue.\n            This corresponds to the lowest expected buckling load factor.\n        numEigs : int\n            Number of eigenvalues to solve for.\n        options : dict\n            Problem-specific options to pass to ModalProblem instance (case-insensitive).\n            Defaults to None.\n\n        Returns\n        -------\n        problem : tacs.problems.BucklingProblem\n            BucklingProblem object used for performing buckling eigenvalue analysis.\n        \"\"\"\n        problem = tacs.problems.buckling.BucklingProblem(\n            name,\n            sigma,\n            numEigs,\n            self.assembler,\n            self.comm,\n            self.outputViewer,\n            self.meshLoader,\n            options,\n        )\n        # Set with original design vars and coordinates, in case they have changed\n        problem.setDesignVars(self.x0)\n        problem.setNodes(self.Xpts0)\n        return problem",
  "def createTACSProbsFromBDF(self):\n        \"\"\"\n        Automatically define tacs problem classes with loads using information contained in BDF file.\n        This function assumes all loads are specified in the BDF and allows users to\n        skip setting loads in Python.\n\n        Returns\n        -------\n        structProblems : dict[int, tacs.problems.TACSProblem]\n            Dictionary containing a predefined TACSProblem for every loadcase found in the BDF.\n            The dictionary keys are the loadcase IDs from the BDF.\n\n        Notes\n        -----\n        Currently only supports LOAD, FORCE, MOMENT, GRAV, RFORCE, PLOAD2, PLOAD4, TLOAD1, TLOAD2, and DLOAD cards.\n        Currently only supports staticProblem (SOL 101), transientProblem (SOL 109), and modalProblems (SOL 103)\n        \"\"\"\n        # Make sure cross-referencing is turned on in pynastran\n        if self.bdfInfo.is_xrefed is False:\n            self.bdfInfo.cross_reference()\n            self.bdfInfo.is_xrefed = True\n\n        structProblems = {}\n\n        # If subcases have been added in Nastran, then subCase 0 should not be run\n        if len(self.bdfInfo.subcases) > 1:\n            skipCaseZero = True\n        else:\n            skipCaseZero = False\n\n        # Loop through every load set and create a corresponding structural problem\n        for subCase in self.bdfInfo.subcases.values():\n            if skipCaseZero and subCase.id == 0:\n                continue\n\n            if \"SUBTITLE\" in subCase:\n                name = subCase[\"SUBTITLE\"][0]\n            else:\n                name = \"load_set_%.3d\" % (subCase.id)\n\n            if self.bdfInfo.sol == 103:\n                methodID = subCase[\"METHOD\"][0]\n                methodInfo = self.bdfInfo.methods[methodID]\n                if methodInfo.v1 is not None:\n                    sigma = (2 * np.pi * methodInfo.v1) ** 2\n                elif methodInfo.v2 is not None:\n                    sigma = (2 * np.pi * methodInfo.v2) ** 2\n                else:\n                    sigma = 1.0\n                if methodInfo.nd is not None:\n                    nEigs = methodInfo.nd\n                else:\n                    nEigs = 20\n                problem = self.createModalProblem(name, sigma, nEigs)\n\n            elif self.bdfInfo.sol == 109:\n                # Get time step info\n                if \"TSTEP\" in subCase:\n                    tStepID = subCase[\"TSTEP\"][0]\n                    tStep = self.bdfInfo.tsteps[tStepID]\n                    nSteps = tStep.N[0]\n                    dt = tStep.DT[0]\n                # If no time step info was included, we'll skip this case\n                else:\n                    self._TACSWarning(\n                        f\"No TSTEP entry found in control deck for subcase number {subCase.id}, \"\n                        \"skipping case.\"\n                    )\n                    continue\n                problem = self.createTransientProblem(\n                    name, tInit=0.0, tFinal=dt * nSteps, numSteps=nSteps\n                )\n\n                # Find dynamic load specified for this subcase\n                if \"DLOAD\" in subCase:\n                    dloadsID = subCase[\"DLOAD\"][0]\n                    dloadSet, dloadScale = self.bdfInfo.get_reduced_dloads(dloadsID)\n                    for dloadInfo, dscale in zip(dloadSet, dloadScale):\n                        timeSteps = problem.getTimeSteps()\n                        if dloadInfo.type in [\"TLOAD1\", \"TLOAD2\"]:\n                            if dloadInfo.type == \"TLOAD1\":\n                                loadScales = dloadInfo.get_load_at_time(\n                                    timeSteps, dscale\n                                )\n                            elif dloadInfo.type == \"TLOAD2\":\n                                loadScales = _tload2_get_load_at_time(\n                                    dloadInfo, timeSteps, dscale\n                                )\n                            if dloadInfo.Type != \"LOAD\":\n                                self._TACSWarning(\n                                    \"Only 'LOAD' types are supported for \"\n                                    f\"'{dloadInfo.type}' card, but '{dloadInfo.type}' {dloadInfo.sid}, \"\n                                    f\"was specified as {dloadInfo.Type} type\"\n                                )\n                            loadsID = dloadInfo.excite_id\n                        else:\n                            self._TACSWarning(\n                                \"Unsupported dload type \"\n                                f\"'{dloadInfo.type}' specified for load set number {dloadInfo.sid},\"\n                                f\" skipping load\"\n                            )\n                            continue\n                        # Loop through each time step and add loads to problem\n                        for timeIndex, scale in enumerate(loadScales):\n                            problem.addLoadFromBDF(timeIndex, loadsID, scale=scale)\n\n            else:\n                problem = self.createStaticProblem(name)\n\n                # Find the static load specified for this test case\n                if \"LOAD\" in subCase:\n                    # Add loads to problem\n                    loadsID = subCase[\"LOAD\"][0]\n                    problem.addLoadFromBDF(loadsID)\n\n            # append to list of structural problems\n            structProblems[subCase.id] = problem\n\n        return structProblems",
  "def writeBDF(self, fileName, problems):\n        \"\"\"\n        Write NASTRAN BDF file from problem class.\n        Assumes all supplied Problems share the same nodal and design variable values.\n\n        NOTE: Only supports writing loads from StaticProblem types.\n\n        Parameters\n        ----------\n        fileName: str\n            Name of file to write BDF file to.\n        problems: tacs.problems.TACSProblem or list[tacs.problems.TACSProblem]\n            List of pytacs Problem classes to write BDF file from.\n        \"\"\"\n        # Make sure problems is in a list\n        if hasattr(problems, \"__iter__\") == False:\n            problems = [problems]\n        elif isinstance(problems, dict):\n            problems = list(problems.values())\n        else:\n            problems = list(problems)\n\n        # Check that each problem was created by this pyTACS instance\n        for problem in problems:\n            if problem.assembler != self.assembler:\n                raise self._TACSError(\n                    f\"This problem instance ({problem.name}) is not associated with this instance of pyTACS.\"\n                )\n\n        # Make sure design variables are up-to-date\n        dv_bvec = self.createDesignVec(asBVec=True)\n        dv_bvec.getArray()[:] = problems[0].getDesignVars()\n        # Transfer all non-local dvs\n        dv_bvec.beginDistributeValues()\n        dv_bvec.endDistributeValues()\n\n        # Get local node info for each processor\n        multNodes = self.getLocalMultiplierNodeIDs()\n        globalToLocalNodeIDDict = self.meshLoader.getGlobalToLocalNodeIDDict()\n        Xpts_bvec = np.real(problems[0].getNodes())\n\n        # Gather local info to root processor\n        allMultNodes = self.comm.gather(multNodes, root=0)\n        allGlobalToLocalNodeIDDict = self.comm.gather(globalToLocalNodeIDDict, root=0)\n        allXpts = self.comm.gather(Xpts_bvec, root=0)\n\n        # Assemble new BDF file for mesh on root\n        if self.comm.rank == 0:\n            newBDFInfo = pn.bdf.BDF(debug=False)\n\n            # Write out updated node locations\n            nastranNodeIDs = list(self.bdfInfo.node_ids)\n            # Loop through each proc and pull out new node locations\n            for proc_i in range(self.comm.size):\n                xyz = allXpts[proc_i].reshape(-1, 3)\n                for tacsGNodeID in allGlobalToLocalNodeIDDict[proc_i]:\n                    # Get local node ID\n                    tacsLNodeID = allGlobalToLocalNodeIDDict[proc_i][tacsGNodeID]\n                    # Get Global nastran ID\n                    nastranGNodeID = nastranNodeIDs[tacsGNodeID]\n                    # Add node to bdf file (if its not a multiplier node)\n                    if tacsLNodeID not in allMultNodes[proc_i]:\n                        newBDFInfo.add_grid(nastranGNodeID, xyz[tacsLNodeID])\n\n            # Copy over boundary conditions\n            # Set all con IDs to one\n            newBDFInfo.spcs[1] = []\n            for spcID in self.bdfInfo.spcs:\n                for spcCard in self.bdfInfo.spcs[spcID]:\n                    newCard = copy.deepcopy(spcCard)\n                    newCard.conid = 1\n                    newBDFInfo.spcs[1].append(newCard)\n\n            # Write updated properties and elements\n            transObjs = {}\n            matObjs = []\n            conObjs = []\n            for compID, propID in enumerate(self.bdfInfo.properties):\n                # Get TACS element object\n                elemObj = self.meshLoader.getElementObject(compID, 0)\n                # get dv nums for element\n                dvNums = elemObj.getDesignVarNums(0)\n                # Update design variable values\n                dvVals = dv_bvec.getValues(dvNums)\n                elemObj.setDesignVars(0, dvVals)\n                # Get TACS constitutive object for element (if applicable)\n                conObj = elemObj.getConstitutive()\n                if conObj is not None:\n                    # Set the property ID number for the class to be used in the Nastran card\n                    conObj.setNastranID(propID)\n                    conObjs.append(conObj)\n                    # Get TACS material properties object for constitutive (if applicable)\n                    matObj = conObj.getMaterialProperties()\n                    # May be a single object...\n                    if isinstance(matObj, tacs.constitutive.MaterialProperties):\n                        if matObj not in matObjs:\n                            matObjs.append(matObj)\n                    # or a list (plys for composite classes)\n                    elif isinstance(matObj, list):\n                        for mat_i in matObj:\n                            if mat_i not in matObjs:\n                                matObjs.append(mat_i)\n                # Get TACS transform object for element (if applicable)\n                transObj = elemObj.getTransform()\n                if transObj is not None:\n                    transObjs[compID] = transObj\n\n            # Write material cards from TACS MaterialProperties class\n            for i, matObj in enumerate(matObjs):\n                matID = i + 1\n                matObj.setNastranID(matID)\n                newBDFInfo.materials[matID] = matObj.generateBDFCard()\n\n            # Write property/element cards from TACSConstitutive/TACSElement classes\n            curCoordID = 1\n            for compID, conObj in enumerate(conObjs):\n                propID = conObj.getNastranID()\n                propCard = conObj.generateBDFCard()\n                if propCard is not None:\n                    # Copy property comment (may include component name info)\n                    # Make sure to remove comment `$` from string\n                    propCard.comment = self.bdfInfo.properties[propID].comment[1:]\n                    # Add property card to BDF\n                    newBDFInfo.properties[propID] = propCard\n                elemIDs = self.meshLoader.getGlobalElementIDsForComps(\n                    [compID], nastranOrdering=True\n                )\n                # Convert any transform objects to nastran COORD2R cards, if necessary\n                transObj = transObjs.get(compID, None)\n                if isinstance(\n                    transObj, tacs.elements.ShellRefAxisTransform\n                ) or isinstance(transObj, tacs.elements.SpringRefFrameTransform):\n                    coordID = curCoordID\n                    origin = np.zeros(3)\n                    if isinstance(transObj, tacs.elements.SpringRefFrameTransform):\n                        vec1, vec2 = transObj.getRefAxes()\n                    else:\n                        vec1 = transObj.getRefAxis()\n                        vec2 = np.random.random(3)\n                    # Add COORD2R card to BDF\n                    pn.cards.coordinate_systems.define_coord_e123(\n                        newBDFInfo,\n                        \"CORD2R\",\n                        coordID,\n                        origin,\n                        xaxis=np.real(vec1),\n                        xzplane=np.real(vec2),\n                        add=True,\n                    )\n                    curCoordID += 1\n                # We just need the ref vector for these types\n                elif isinstance(\n                    transObj, tacs.elements.BeamRefAxisTransform\n                ) or isinstance(transObj, tacs.elements.SpringRefAxisTransform):\n                    vec = transObj.getRefAxis()\n                    vec = np.real(vec)\n                # Otherwise, there's no transform associated with this element, use default\n                else:\n                    coordID = None\n                # Copy and update element cards\n                for elemID in elemIDs:\n                    # Create copy of card\n                    newCard = copy.deepcopy(self.bdfInfo.elements[elemID])\n                    # Copy element comment (may include component name info)\n                    # Make sure to remove comment `$` from string\n                    newCard.comment = self.bdfInfo.elements[elemID].comment[1:]\n                    # Update element coordinate frame info, if necessary\n                    if \"CQUAD\" in newCard.type or \"CTRI\" in newCard.type:\n                        newCard.theta_mcid = coordID\n                    elif \"CBAR\" in newCard.type:\n                        newCard.x = vec\n                        newCard.g0 = None\n                    elif \"CBEAM\" in newCard.type:\n                        newCard.x = vec\n                        newCard.g0 = None\n                        if propCard.type != \"PBEAM\":\n                            # TACS wrote out a PBAR card that we must convert\n                            newPropCard = (\n                                pn.cards.properties.beam.PBEAM_init_from_empty()\n                            )\n                            newPropCard.A[0] = propCard.Area()\n                            newPropCard.i1[0] = propCard.I11()\n                            newPropCard.i2[0] = propCard.I22()\n                            newPropCard.i12[0] = propCard.I12()\n                            if hasattr(propCard, \"J\"):\n                                newPropCard.j[0] = propCard.J()\n                            else:\n                                newPropCard.j[0] = propCard.j\n                            newPropCard.comment = propCard.comment\n                            propCard = newPropCard\n                    elif \"CROD\" in newCard.type and propCard.type != \"PROD\":\n                        # TACS wrote out a PBAR card that we must convert\n                        if hasattr(propCard, \"J\"):\n                            J = propCard.J()\n                        else:\n                            J = propCard.j\n                        newPropCard = pn.cards.properties.rods.PROD(\n                            propCard.pid, propCard.mid, propCard.Area(), J\n                        )\n                        newBDFInfo.properties[propID] = newPropCard\n                        newPropCard.comment = propCard.comment\n                        propCard = newPropCard\n                    elif newCard.type == \"CBUSH\":\n                        if isinstance(transObj, tacs.elements.SpringRefAxisTransform):\n                            newCard.x = vec\n                            newCard.g0 = None\n                        else:\n                            newCard.cid = coordID\n                    # Add element card to bdf\n                    newBDFInfo.elements[elemID] = newCard\n\n            # Copy over masses elements\n            for massCard in self.bdfInfo.masses.values():\n                elemID = massCard.eid\n                # We'll have to create a new CONM2 card in case the point mass is associated with tacs dvs\n                if massCard.type == \"CONM2\":\n                    nodeID = massCard.nid\n                    elemObj = self.meshLoader.getElementObjectForElemID(\n                        elemID, nastranOrdering=True\n                    )\n                    conObj = elemObj.getConstitutive()\n                    M = conObj.evalMassMatrix()\n                    mass = np.real(M[0])\n                    I11 = np.real(M[15])\n                    I22 = np.real(M[18])\n                    I33 = np.real(M[20])\n                    # Nastran uses negative convention for POI's\n                    I12 = -np.real(M[16])\n                    I13 = -np.real(M[17])\n                    I23 = -np.real(M[19])\n                    newBDFInfo.add_conm2(\n                        elemID, nodeID, mass, I=[I11, I12, I22, I13, I23, I33]\n                    )\n                # CONM1's can't be updated by TACS, so we can just copy the original value\n                else:\n                    newBDFInfo.masses[elemID] = copy.deepcopy(massCard)\n                # Copy over comments\n                newBDFInfo.masses[elemID].comment = massCard.comment\n\n            # Copy over rigid elements\n            newBDFInfo.rigid_elements.update(self.bdfInfo.rigid_elements)\n\n            # Add case control deck for loads\n            caseConLines = [\n                \"TITLE = TACS Analysis Set\",\n                \"ECHO = NONE\",\n                \"DISPLACEMENT(PLOT) = ALL\",\n                \"SPCFORCE(PLOT) = ALL\",\n                \"OLOAD(PLOT) = ALL\",\n                \"FORCE(PLOT,CORNER) = ALL\",\n                \"STRESS(PLOT,CORNER) = ALL\",\n                \"SPC = 1\",\n            ]\n            newBDFInfo.case_control_deck = pn.case_control_deck.CaseControlDeck(\n                caseConLines\n            )\n            # Set solution type to static (101)\n            newBDFInfo.sol = 101\n\n        else:\n            newBDFInfo = None\n\n        # All procs should wait for root\n        self.comm.barrier()\n\n        # Append forces from problem classes\n        for i, problem in enumerate(problems):\n            if isinstance(problem, tacs.problems.StaticProblem):\n                loadCase = i + 1\n                problem.writeLoadToBDF(newBDFInfo, loadCase)\n\n        # Write out BDF file\n        if self.comm.rank == 0:\n            newBDFInfo.write_bdf(\n                fileName, size=16, is_double=True, write_header=False, enddata=True\n            )\n\n        # All procs should wait for root\n        self.comm.barrier()",
  "def createAdjacencyConstraint(self, name, options=None):\n        \"\"\"\n        Create a new AdjacencyConstraint for calculating\n        design variable differences across adjacent components.\n        This constraint can be used to ensure that the design variables\n        do not change too abruptly across components.\n        The formulation is a linear constraint that takes the following form:\n\n        c = dv_i - dv_j\n\n        Where dv_i and dv_j are two design variables in adjacent components.\n\n        Parameters\n        ----------\n        name : str\n            Name to assign constraint.\n        options : dict\n            Class-specific options to pass to AdjacencyConstraint instance (case-insensitive).\n            Defaults to None.\n\n        Returns\n        -------\n        constraint : tacs.constraints.AdjacencyConstraint\n            AdjacencyConstraint object used for calculating constraints.\n        \"\"\"\n        constr = tacs.constraints.AdjacencyConstraint(\n            name,\n            self.assembler,\n            self.comm,\n            self.outputViewer,\n            self.meshLoader,\n            options,\n        )\n        # Set with original design vars and coordinates, in case they have changed\n        constr.setDesignVars(self.x0)\n        constr.setNodes(self.Xpts0)\n        return constr",
  "def createDVConstraint(self, name, options=None):\n        \"\"\"\n        Create a new DVConstraint for calculating linear constraints based\n        on design variables within the same component.\n\n        The constraints are of the form:\n\n            c = a_0 * dv_0 + a_1 * dv_1 + ... + a_n * dv_n\n\n        Where which design variables to include (dv_0, dv_1, etc.)\n        and the corresponding weights (a_0, a_1, etc.) are defined by the user.\n\n        Parameters\n        ----------\n        name : str\n            Name to assign constraint.\n        options : dict\n            Class-specific options to pass to DVConstraint instance (case-insensitive).\n            Defaults to None.\n\n        Returns\n        -------\n        constraint : tacs.constraints.DVConstraint\n            DVConstraint object used for calculating constraints.\n        \"\"\"\n        constr = tacs.constraints.DVConstraint(\n            name,\n            self.assembler,\n            self.comm,\n            self.outputViewer,\n            self.meshLoader,\n            options,\n        )\n        # Set with original design vars and coordinates, in case they have changed\n        constr.setDesignVars(self.x0)\n        constr.setNodes(self.Xpts0)\n        return constr",
  "def createPanelLengthConstraint(self, name, options=None):\n        \"\"\"Create a new PanelLengthConstraint for enforcing that the panel\n        length DV values passed to components match the actual panel lengths.\n\n        Parameters\n        ----------\n        name : str\n            Name to assign constraint.\n        options : dict\n            Class-specific options to pass to DVConstraint instance (case-insensitive).\n\n        Returns\n        ----------\n        constraint : tacs.constraints.PanelLengthConstraint\n            PanelLengthConstraint object used for calculating constraints.\n        \"\"\"\n        constr = tacs.constraints.PanelLengthConstraint(\n            name,\n            self.assembler,\n            self.comm,\n            self.outputViewer,\n            self.meshLoader,\n            options,\n        )\n        # Set with original design vars and coordinates, in case they have changed\n        constr.setDesignVars(self.x0)\n        constr.setNodes(self.Xpts0)\n        return constr",
  "def createVolumeConstraint(self, name, options=None):\n        \"\"\"\n        Create a new VolumeConstraint for constraining the size of a closed volume.\n        Only shell and solid elements are supported for this constraint.\n        For shell elements, the enclosed volume MUST be manifold and water-tight (no missing/internal faces).\n        The formulation is a nonlinear constraint based on the nodal coordinates.\n\n        A common example of this is ensuring enough volume in the wingbox for fuel:\n\n            vol_wing >= vol_fuel\n\n        Parameters\n        ----------\n        name : str\n            Name to assign constraint.\n        options : dict\n            Class-specific options to pass to VolumeConstraint instance (case-insensitive).\n            Defaults to None.\n\n        Returns\n        -------\n        constraint : tacs.constraints.VolumeConstraint\n            VolumeConstraint object used for calculating constraints.\n        \"\"\"\n        constr = tacs.constraints.VolumeConstraint(\n            name,\n            self.assembler,\n            self.comm,\n            self.outputViewer,\n            self.meshLoader,\n            options,\n        )\n        # Set with original design vars and coordinates, in case they have changed\n        constr.setDesignVars(self.x0)\n        constr.setNodes(self.Xpts0)\n        return constr",
  "def getNumComponents(self):\n        \"\"\"\n        Return number of components (property) groups found in bdf.\n\n        Returns\n        -------\n        nComp : int\n            Number of components in model\n        \"\"\"\n        return self.nComp",
  "def _createOutputGroups(self):\n        \"\"\"Automatically determine how to split out the output file\n        for easier viewing\"\"\"\n\n        self.fam = []\n        for i in range(self.nComp):\n            aux = self.compDescripts[i].split(self.getOption(\"familySeparator\"))\n            self.fam.append(aux[0])\n\n        # Uniqify them and sort\n        self.fam = sorted(np.unique(self.fam))\n\n        self.compFam = np.zeros(self.nComp, dtype=\"intc\")\n        for i in range(self.nComp):\n            aux = self.compDescripts[i].split(self.getOption(\"familySeparator\"))\n            self.compFam[i] = self.fam.index(aux[0])",
  "def _createOutputViewer(self):\n        \"\"\"\n        Internal method to create the appropriate output viewer\n        (TACSToFH5 object) for TACS.\n        \"\"\"\n\n        # Depending on the user-supplied options generate the\n        # write_flag\n        write_flag = 0\n        if self.getOption(\"writeConnectivity\"):\n            write_flag |= tacs.TACS.OUTPUT_CONNECTIVITY\n        if self.getOption(\"writeNodes\"):\n            write_flag |= tacs.TACS.OUTPUT_NODES\n        if self.getOption(\"writeDisplacements\"):\n            write_flag |= tacs.TACS.OUTPUT_DISPLACEMENTS\n        if self.getOption(\"writeStrains\"):\n            write_flag |= tacs.TACS.OUTPUT_STRAINS\n        if self.getOption(\"writeStresses\"):\n            write_flag |= tacs.TACS.OUTPUT_STRESSES\n        if self.getOption(\"writeExtras\"):\n            write_flag |= tacs.TACS.OUTPUT_EXTRAS\n        if self.getOption(\"writeLoads\"):\n            write_flag |= tacs.TACS.OUTPUT_LOADS\n        if self.getOption(\"writeCoordinateFrame\"):\n            write_flag |= tacs.TACS.OUTPUT_COORDINATES\n\n        # Create actual viewer\n        if self.getOption(\"outputElement\") is not None:\n            elementType = self.getOption(\"outputElement\")\n        else:\n            # Set the output type based on the first element in the model\n            elem = self.meshLoader.getElementObjectForElemID(0, nastranOrdering=False)\n            elementType = elem.getElementType()\n\n        self.outputViewer = tacs.TACS.ToFH5(self.assembler, elementType, write_flag)\n\n        # Set the names of each of the output families\n        for i in range(len(self.fam)):\n            self.outputViewer.setComponentName(i, self.fam[i])",
  "def _getCompIDs(self, op, *inList):\n        \"\"\"Internal method to return the component IDs mathing\n        information in inList\"\"\"\n\n        # First recursively flatten the inList in case it was nested:\n        inList = self._flatten(inList)\n\n        # Neste list container for compIDs\n        compIDs = []\n\n        # Look at each item in list (which is a list because of the *)\n        for item in inList:\n            compIDs.append([])\n            if isinstance(item, int):\n                # Integers are easy, just check if in bounds and add:\n                if item >= 0 and item < self.nComp:\n                    compIDs[-1].append(item)\n                else:\n                    self._TACSWarning(\n                        f\"Trying to add component ID of {item}, which\\\n                    is out of the range 0 <= compID < {self.nComp}\"\n                    )\n\n            elif isinstance(item, str):\n                # This is a little inefficient here; loop over\n                # self.compDescripts and see if 'item' (a string) in\n                # part of the description. if so add.\n                item = item.upper()\n                for i in range(self.nComp):\n                    if item in self.compDescripts[i].upper():\n                        compIDs[-1].append(i)\n            else:\n                self._TACSWarning(\n                    f\"Unidentifiable information given for 'include'\\\n                or 'exclude'. Valid data are integers 0 <= i < {self.nComp}, or \\\n                strings.\"\n                )\n\n        if op == \"and\":\n            # First convert each entry to a set:\n            for i in range(len(compIDs)):\n                compIDs[i] = set(compIDs[i])\n\n            # We want to go through and take only the intersection of\n            # each of the sets we have found:\n            tmp = copy.deepcopy(compIDs[0])\n\n            for i in range(1, len(compIDs)):\n                tmp = tmp.intersection(compIDs[i])\n            compIDs = tmp\n\n        # Finally, convert to a list\n        compIDs = self._flatten(list(compIDs))\n\n        return compIDs",
  "def _createElements(self, elemCallBack):\n        \"\"\"\n        Create all the constitutive objects by calling the\n        userSupplied or default callback function\n\n        Parameters\n        ----------\n        elemCallBack : callable\n            Element callback function provided by user or pyTACS\n            to set up TACS element objects.\n        \"\"\"\n\n        for i in range(self.nComp):\n            # Get a list of compDescripts to help the user\n            compDescript = self.compDescripts[i]\n            numElements = len(self.elemDescripts[i])\n            # TACS component ID\n            compID = i\n            # Nastran property ID\n            propID = list(self.bdfInfo.property_ids)[i]\n\n            # Call the user function\n            result = elemCallBack(\n                self.dvNum,\n                compID,\n                compDescript,\n                self.elemDescripts[i],\n                self.globalDVs,\n                propID=propID,\n            )\n\n            # For maximum flexibility, multiple pieces of information\n            # can be returned. At a minimum, the element objects\n            # must be returned!\n\n            # Note: If two objects are returned, the\n            # first one is used as the element object list and the\n            # second one is treated as a scale list for the added dvs.\n\n            # Check that result is an element object instance or .\n            numFoundElements = 0\n            scaleList = None\n\n            if isinstance(result, tuple):\n                elemObjects = result[0]\n                if hasattr(result[1], \"__iter__\"):\n                    # Iterable item, the scale list:\n                    scaleList = result[1]\n                elif isinstance(result[1], numbers.Number):\n                    scaleList = [result[1]]\n                else:\n                    print(result[1])\n                    # Don't know what it is:\n                    self._TACSWarning(\n                        \"Could not identify objects returned \\\n                    from elemCallBack. Valid return objects are: \\\n                    A list of TACS element objects (required, first), \\\n                    an iterable object \\\n                    (eg, list or array) containing the scaling parameters \\\n                    for the added design variables (optional, second). The \\\n                    string representation of the offending object is: \\\n                    '%s'\"\n                        % repr(result[1])\n                    )\n\n            else:\n                elemObjects = result\n\n            if isinstance(elemObjects, tacs.TACS.Element):\n                # There was only one element, recast it as a list and continue\n                elemObjects = [elemObjects]\n                numFoundElements += 1\n            elif isinstance(elemObjects, list):\n                # Multiple elements were returned, count how many\n                for object in elemObjects:\n                    if isinstance(object, tacs.TACS.Element):\n                        numFoundElements += 1\n                    else:\n                        self._TACSError(\n                            f\"Object of type {type(object)} returned in elemCallBack function \"\n                            f\"is not a valid TACS element object. The \\\n                               string representation of the offending object is: \\\n                               '{repr(object)}'\"\n                        )\n\n            if numFoundElements != numElements:\n                raise self._TACSError(\n                    f\"Unexpected number of element objects \\\n                    returned from user-supplied elemCallBack function. \\\n                    {numElements} element types ({repr(self.elemDescripts[i])}) are contained in Component {i}, \\\n                    but {numFoundElements} element objects were returned by elemCallback.\"\n                )\n\n            # Now determine the number of design variables. This is\n            # NOT as simple as just getting the number of design\n            # variables; Not all variables added in the conObject are\n            # 'new' variables, some of the variable number may have\n            # been already used.\n            newVars = []\n            for elemObject in elemObjects:\n                dvs = elemObject.getDesignVarNums(0)\n\n                if len(dvs) > 0:\n                    # We will also check if the user screwed up. That is\n                    # make sure that for added variables, the are\n                    # continuous starting at self.dvNum\n                    for var in dvs:\n                        if var >= self.dvNum:\n                            newVars.append(var)\n\n            # Remove repeated dv nums from list\n            newVars = np.unique(newVars)\n            newVars.sort()\n\n            if len(newVars) > 0:\n                # Now the length of newVars must the same as\n                # newVars[-1]-newVars[0] + 1\n                if not len(newVars) == newVars[-1] - newVars[0] + 1:\n                    raise self._TACSError(\n                        \"Inconsistent design variables detected. \"\n                        \"The added design variables are not continuous.\"\n                        f\" The added design variables are {repr(newVars)}.\"\n                    )\n\n            # Finally, increment the dv counter\n            self.dvNum += len(newVars)\n\n            if len(newVars) > 0:\n                if scaleList is None:\n                    self.scaleList.extend(np.ones(len(newVars)))\n                else:\n                    # Make sure that the scaleList is the correct length.\n                    if len(scaleList) != len(newVars):\n                        self._TACSWarning(\n                            f\"An incorrect number of scale variables \\\n                        were returned. There were {len(newVars)} variables added, but only \\\n                        {len(scaleList)} scale variables returned. The scale for these \\\n                        variables will be set to 1.0. The scale variables are {repr(scaleList)}.\"\n                        )\n                        self.scaleList.extend(np.ones(len(newVars)))\n                    else:\n                        self.scaleList.extend(scaleList)\n\n            # Loop through every element type in this component,\n            # there may be multiple (e.g CQUAD4 + CTRIA3)\n            for j, elemObject in enumerate(elemObjects):\n                # Set component-specific family id\n                elemObject.setComponentNum(self.compFam[i])\n                # Set each of the elements for this component\n                self.meshLoader.setElementObject(i, j, elemObject)\n                # set varsPerNode\n                elemVarsPerNode = elemObject.getVarsPerNode()\n                if self.varsPerNode is None:\n                    self.varsPerNode = elemVarsPerNode\n                elif self.varsPerNode != elemVarsPerNode:\n                    raise self._TACSError(\n                        \"Model references elements with differing numbers of variables per node \"\n                        f\"({self.varsPerNode} and {elemVarsPerNode}). \"\n                        \"All elements must use same number of variables to be compatible.\"\n                    )\n\n        # If varsPerNode still hasn't been set (because there were no elements added in the callback)\n        # Default to 6\n        if self.varsPerNode is None:\n            self.varsPerNode = 6",
  "def matCallBack(matInfo):\n            # Nastran isotropic material card\n            if matInfo.type == \"MAT1\":\n                mat = tacs.constitutive.MaterialProperties(\n                    rho=matInfo.rho,\n                    E=matInfo.e,\n                    nu=matInfo.nu,\n                    ys=matInfo.St,\n                    alpha=matInfo.a,\n                )\n            # Nastran orthotropic material card\n            elif matInfo.type == \"MAT8\":\n                E1 = matInfo.e11\n                E2 = matInfo.e22\n                nu12 = matInfo.nu12\n                G12 = matInfo.g12\n                G13 = matInfo.g1z\n                G23 = matInfo.g2z\n                # If out-of-plane shear values are 0, Nastran defaults them to the in-plane\n                if G13 == 0.0:\n                    G13 = G12\n                if G23 == 0.0:\n                    G23 = G12\n                rho = matInfo.rho\n                Xt = matInfo.Xt\n                Xc = matInfo.Xc\n                Yt = matInfo.Yt\n                Yc = matInfo.Yc\n                S12 = matInfo.S\n                # TODO: add alpha\n                mat = tacs.constitutive.MaterialProperties(\n                    rho=rho,\n                    E1=E1,\n                    E2=E2,\n                    nu12=nu12,\n                    G12=G12,\n                    G13=G13,\n                    G23=G23,\n                    Xt=Xt,\n                    Xc=Xc,\n                    Yt=Yt,\n                    Yc=Yc,\n                    S12=S12,\n                )\n            # Nastran 2D anisotropic material card\n            elif matInfo.type == \"MAT2\":\n                C11 = matInfo.G11\n                C12 = matInfo.G12\n                C22 = matInfo.G22\n                C13 = matInfo.G13\n                C23 = matInfo.G23\n                C33 = matInfo.G33\n                rho = matInfo.rho\n                # See if this card features anisotropic coupling terms (which we don't support yet)\n                if (\n                    np.abs(C13) / (C11 + C22) >= 1e-8\n                    or np.abs(C23) / (C11 + C22) >= 1e-8\n                ):\n                    self._TACSWarning(\n                        f\"MAT2 card {matInfo.mid} has anisotropic stiffness components that are not currently supported. \"\n                        \"These terms will be dropped and the material treated as orthotropic. \"\n                        \"Result accuracy may be affected.\"\n                    )\n                nu12 = C12 / C22\n                nu21 = C12 / C11\n                E1 = C11 * (1 - nu12 * nu21)\n                E2 = C22 * (1 - nu12 * nu21)\n                G12 = G13 = G23 = C33\n                # TODO: add alpha\n                mat = tacs.constitutive.MaterialProperties(\n                    rho=rho, E1=E1, E2=E2, nu12=nu12, G12=G12, G13=G13, G23=G23\n                )\n\n            else:\n                raise self._TACSError(\n                    f\"Unsupported material type '{matInfo.type}' for material number {matInfo.mid}.\"\n                )\n\n            return mat",
  "def elemCallBack(\n            dvNum, compID, compDescript, elemDescripts, globalDVs, **kwargs\n        ):\n            # Initialize scale list for design variables we will add\n            scaleList = []\n\n            # Get the Nastran property ID\n            propertyID = kwargs[\"propID\"]\n            propInfo = self.bdfInfo.properties[propertyID]\n            elemInfo = elemDict[propertyID][\"elements\"][0]\n\n            # First we define the material object\n            mat = None\n            # This property only references one material\n            if hasattr(propInfo, \"mid_ref\"):\n                matInfo = propInfo.mid_ref\n                mat = matCallBack(matInfo)\n            # This property references multiple materials (maybe a laminate)\n            elif hasattr(propInfo, \"mids_ref\"):\n                mat = []\n                for matInfo in propInfo.mids_ref:\n                    mat.append(matCallBack(matInfo))\n\n            # Next we define the constitutive object\n            if propInfo.type == \"PSHELL\":  # Nastran isotropic shell\n                kcorr = propInfo.tst\n\n                if \"T\" in elemDict[propertyID][\"dvs\"]:\n                    thickness = elemDict[propertyID][\"dvs\"][\"T\"].dvids_ref[0].xinit\n                    tNum = elemDict[propertyID][\"dvs\"][\"T\"].dvids[0] - 1\n                    minThickness = elemDict[propertyID][\"dvs\"][\"T\"].dvids_ref[0].xlb\n                    maxThickness = elemDict[propertyID][\"dvs\"][\"T\"].dvids_ref[0].xub\n                    name = elemDict[propertyID][\"dvs\"][\"T\"].dvids_ref[0].label\n                    self.scaleList[tNum - 1] = elemDict[propertyID][\"dvs\"][\"T\"].coeffs[\n                        0\n                    ]\n                else:\n                    thickness = propInfo.t\n                    tNum = -1\n                    minThickness = 0.0\n                    maxThickness = 1e20\n\n                con = tacs.constitutive.IsoShellConstitutive(\n                    mat, t=thickness, tlb=minThickness, tub=maxThickness, tNum=tNum\n                )\n\n            elif propInfo.type == \"PCOMP\":  # Nastran composite shell\n                numPlies = propInfo.nplies\n                plyThicknesses = []\n                plyAngles = []\n                plyMats = []\n\n                # if the laminate is symmetric, mirror the ply indices\n                if propInfo.lam == \"SYM\":\n                    plyIndices = list(range(numPlies // 2))\n                    plyIndices.extend(plyIndices[::-1])\n                else:\n                    plyIndices = range(numPlies)\n\n                # Loop through plies and setup each entry in layup\n                for ply_i in plyIndices:\n                    plyThicknesses.append(propInfo.thicknesses[ply_i])\n                    plyMat = tacs.constitutive.OrthotropicPly(\n                        plyThicknesses[ply_i], mat[ply_i]\n                    )\n                    plyMats.append(plyMat)\n                    plyAngles.append(np.deg2rad(propInfo.thetas[ply_i]))\n\n                # Convert thickness/angles to appropriate numpy array\n                plyThicknesses = np.array(plyThicknesses, dtype=self.dtype)\n                plyAngles = np.array(plyAngles, dtype=self.dtype)\n\n                if propInfo.lam is None or propInfo.lam in [\"SYM\", \"MEM\"]:\n                    # Discrete laminate class (not for optimization)\n                    con = tacs.constitutive.CompositeShellConstitutive(\n                        plyMats, plyThicknesses, plyAngles\n                    )\n\n                elif propInfo.lam == \"SMEAR\":\n                    lamThickness = sum(plyThicknesses)\n                    plyFractions = plyThicknesses / lamThickness\n                    con = tacs.constitutive.SmearedCompositeShellConstitutive(\n                        plyMats, lamThickness, plyAngles, plyFractions\n                    )\n\n                # Need to add functionality to consider only membrane in TACS for type = MEM\n                else:\n                    raise self._TACSError(\n                        f\"Unrecognized LAM type '{propInfo.lam}' for PCOMP number {propertyID}.\"\n                    )\n\n            elif propInfo.type == \"PSOLID\":  # Nastran solid property\n                if \"T\" in elemDict[propertyID][\"dvs\"]:\n                    thickness = elemDict[propertyID][\"dvs\"][\"T\"].dvids_ref[0].xinit\n                    tNum = elemDict[propertyID][\"dvs\"][\"T\"].dvids[0] - 1\n                    minThickness = elemDict[propertyID][\"dvs\"][\"T\"].dvids_ref[0].xlb\n                    maxThickness = elemDict[propertyID][\"dvs\"][\"T\"].dvids_ref[0].xub\n                    name = elemDict[propertyID][\"dvs\"][\"T\"].dvids_ref[0].label\n                    self.scaleList[tNum - 1] = elemDict[propertyID][\"dvs\"][\"T\"].coeffs[\n                        0\n                    ]\n                else:\n                    thickness = 1.0\n                    tNum = -1\n                    minThickness = 0.0\n                    maxThickness = 10.0\n\n                con = tacs.constitutive.SolidConstitutive(\n                    mat, t=thickness, tlb=minThickness, tub=maxThickness, tNum=tNum\n                )\n\n            elif propInfo.type == \"PBUSH\":  # Nastran spring\n                k = np.zeros(6)\n                for j in range(len(k)):\n                    if propInfo.Ki[j]:\n                        k[j] = propInfo.Ki[j]\n                con = tacs.constitutive.DOFSpringConstitutive(k=k)\n\n            elif propInfo.type == \"PBAR\":  # Nastran bar\n                area = propInfo.A\n                I1 = propInfo.i1\n                I2 = propInfo.i2\n                I12 = propInfo.i12\n                J = propInfo.j\n                k1 = propInfo.k1\n                k2 = propInfo.k2\n\n                # pynastran defaults these values to 1e8,\n                # which can lead to scaling issues in the stiffness matrix\n                # We truncate this value to 1e3 to prevent this\n                if k1 is None or k1 > 1e3:\n                    k1 = 1e3\n\n                if k2 is None or k2 > 1e3:\n                    k2 = 1e3\n\n                con = tacs.constitutive.BasicBeamConstitutive(\n                    mat, A=area, Iy=I2, Iz=I1, Iyz=I12, J=J, ky=k1, kz=k2\n                )\n\n            elif propInfo.type == \"PROD\":  # Nastran rod\n                area = propInfo.A\n                J = propInfo.j\n                k1 = 0.0\n                k2 = 0.0\n\n                con = tacs.constitutive.BasicBeamConstitutive(\n                    mat, A=area, J=J, ky=k1, kz=k2\n                )\n\n            else:\n                raise self._TACSError(\n                    f\"Unsupported property type '{propInfo.type}' for property number {propertyID}. \"\n                )\n\n            # Set up transform object which may be required for certain elements\n            transform = None\n            if propInfo.type in [\"PSHELL\", \"PCOMP\"]:\n                mcid = elemDict[propertyID][\"elements\"][0].theta_mcid_ref\n                if mcid:\n                    if mcid.type == \"CORD2R\":\n                        refAxis = mcid.i\n                        transform = tacs.elements.ShellRefAxisTransform(refAxis)\n                    else:  # Don't support spherical/cylindrical yet\n                        raise self._TACSError(\n                            \"Unsupported material coordinate system type \"\n                            f\"'{mcid.type}' for property number {propertyID}.\"\n                        )\n            elif propInfo.type in [\"PBAR\"]:\n                refAxis = elemDict[propertyID][\"elements\"][0].g0_vector\n                transform = tacs.elements.BeamRefAxisTransform(refAxis)\n            elif propInfo.type == \"PROD\":\n                refAxis = np.array(\n                    [1.0, -1.0, 1.0]\n                )  # dummy ref_axis, not really needed for rods\n                transform = tacs.elements.BeamRefAxisTransform(refAxis)\n            elif propInfo.type == \"PBUSH\":\n                if elemDict[propertyID][\"elements\"][0].cid_ref:\n                    refAxis_i = elemDict[propertyID][\"elements\"][0].cid_ref.i\n                    refAxis_j = elemDict[propertyID][\"elements\"][0].cid_ref.j\n                    transform = tacs.elements.SpringRefFrameTransform(\n                        refAxis_i, refAxis_j\n                    )\n                elif elemDict[propertyID][\"elements\"][0].x[0]:\n                    refAxis = (\n                        np.array(elemDict[propertyID][\"elements\"][0].x)\n                        - elemDict[propertyID][\"elements\"][0]\n                        .nodes_ref[0]\n                        .get_position()\n                    )\n                    transform = tacs.elements.SpringRefAxisTransform(refAxis)\n                elif elemDict[propertyID][\"elements\"][0].g0_ref:\n                    refAxis = (\n                        elemDict[propertyID][\"elements\"][0].g0_ref.get_position()\n                        - elemDict[propertyID][\"elements\"][0]\n                        .nodes_ref[0]\n                        .get_position()\n                    )\n                    transform = tacs.elements.SpringRefAxisTransform(refAxis)\n\n            # Finally set up the element objects belonging to this component\n            elemList = []\n            for descript in elemDescripts:\n                if descript in [\"CQUAD4\", \"CQUADR\"]:\n                    elem = tacs.elements.Quad4Shell(transform, con)\n                elif descript in [\"CQUAD9\", \"CQUAD\"]:\n                    elem = tacs.elements.Quad9Shell(transform, con)\n                elif descript in [\"CTRIA3\", \"CTRIAR\"]:\n                    elem = tacs.elements.Tri3Shell(transform, con)\n                elif descript in [\"CBAR\", \"CROD\"]:\n                    elem = tacs.elements.Beam2(transform, con)\n                elif \"CTETRA\" in descript:\n                    # May have variable number of nodes in card\n                    nnodes = len(elemInfo.nodes)\n                    if nnodes == 4:\n                        basis = tacs.elements.LinearTetrahedralBasis()\n                    elif nnodes == 10:\n                        basis = tacs.elements.QuadraticTetrahedralBasis()\n                    else:\n                        raise self._TACSError(\n                            f\"TACS does not currently support CTETRA elements with {nnodes} nodes.\"\n                        )\n                    model = tacs.elements.LinearElasticity3D(con)\n                    elem = tacs.elements.Element3D(model, basis)\n                elif descript in [\"CHEXA8\", \"CHEXA\"]:\n                    basis = tacs.elements.LinearHexaBasis()\n                    model = tacs.elements.LinearElasticity3D(con)\n                    elem = tacs.elements.Element3D(model, basis)\n                elif descript == \"CBUSH\":\n                    elem = tacs.elements.SpringElement(transform, con)\n                else:\n                    raise self._TACSError(\n                        \"Unsupported element type \"\n                        f\"'{descript}' specified for property number {propertyID}.\"\n                    )\n                elemList.append(elem)\n\n            return elemList, scaleList",
  "def argsort(seq):\n                return sorted(range(len(seq)), key=seq.__getitem__)",
  "def split_list(alist, wanted_parts=1):\n                length = len(alist)\n                return [\n                    alist[i * length // wanted_parts : (i + 1) * length // wanted_parts]\n                    for i in range(wanted_parts)\n                ]",
  "class pyMeshLoader(BaseUI):\n    def __init__(self, comm, printDebug=False):\n        # Set MPI communicator\n        BaseUI.__init__(self, comm=comm)\n        # Debug printing flag\n        self.printDebug = printDebug\n        self.bdfInfo = None\n\n    def scanBdfFile(self, fileName):\n        \"\"\"\n        Scan nastran bdf file using pyNastran's bdf parser.\n        We also set up arrays that will be require later to build tacs.\n        \"\"\"\n\n        # Only print debug info on root, if requested\n        if self.comm.rank == 0:\n            debugPrint = self.printDebug\n        else:\n            debugPrint = False\n\n        # Read in bdf file as pynastran object\n        # By default we avoid cross-referencing unless we actually need it,\n        # since its expensive for large models\n        self.bdfInfo = read_bdf(fileName, validate=False, xref=False, debug=debugPrint)\n        # Set flag letting us know model is not xrefed yet\n        self.bdfInfo.is_xrefed = False\n\n        # If any property cards are missing in the bdf, we have to add dummy cards\n        # so pynastran doesn't through errors when cross-referencing\n        # Loop through all elements and add dummy property, as necessary\n        self.bdfInfo.missing_properties = False\n        for element_id in self.bdfInfo.elements:\n            element = self.bdfInfo.elements[element_id]\n            if element.pid not in self.bdfInfo.property_ids:\n                # If no material properties were found,\n                # add dummy properties and materials\n                matID = 1\n                E = 70.0\n                G = 35.0\n                nu = 0.3\n                self.bdfInfo.add_mat1(matID, E, G, nu)\n                self.bdfInfo.add_pbar(element.pid, matID)\n                # Warn the user that the property card is missing\n                # and should not be read in using pytacs elemCallBackFromBDF method\n                self.bdfInfo.missing_properties = True\n                if self.printDebug:\n                    self._TACSWarning(\n                        \"Element ID %d references undefined property ID %d in bdf file. \"\n                        \"A user-defined elemCallBack function will need to be provided.\"\n                        % (element_id, element.pid)\n                    )\n\n        # We have to remove any empty property groups that may have been read in from the BDF\n        self.propertyIDToElementIDDict = (\n            self.bdfInfo.get_property_id_to_element_ids_map()\n        )\n        for pid in self.propertyIDToElementIDDict:\n            # If there are no elements referencing this property card, remove it\n            if len(self.propertyIDToElementIDDict[pid]) == 0:\n                self.bdfInfo.properties.pop(pid)\n                self.propertyIDToElementIDDict.pop(pid)\n\n        # Create dictionaries for mapping between tacs and nastran id numbering\n        self._updateNastranToTACSDicts()\n\n        # Try to get the node x,y,z locations from bdf file\n        try:\n            self.bdfXpts = self.bdfInfo.get_xyz_in_coord(\n                fdtype=self.dtype, sort_ids=False\n            )\n        # If this fails, the file may reference multiple coordinate systems\n        # and will have to be cross-referenced to work\n        except:\n            self.bdfInfo.cross_reference()\n            self.bdfInfo.is_xrefed = True\n            self.bdfXpts = self.bdfInfo.get_xyz_in_coord(\n                fdtype=self.dtype, sort_ids=False\n            )\n\n        # element card contained within each property group (may contain multiple per group)\n        # Each entry will eventually have its own tacs element object assigned to it\n        # (ex. self.elemDescripts = [['CQUAD4', 'CTRIA3'], ['CQUAD9', 'CQUAD4'], ['CBAR']])\n        self.elemDescripts = []\n        # Pointer index used to map elemDescript entries into flat list\n        # (ex. self.elementObjectNumByComp = [[0, 1], [2, 3], [4]])\n        self.elemObjectNumByComp = []\n        # User-defined name for property/component group,\n        # this may be read in through ICEMCFD/FEMAP format comments in BDF\n        self.compDescripts = []\n\n        # Populate list entries with default values\n        for pID in self.bdfInfo.property_ids:\n            self.elemDescripts.append([])\n            self.elemObjectNumByComp.append([])\n            # Check if there is a Femap/HyperMesh/Patran label for this component\n            propComment = self.bdfInfo.properties[pID].comment\n            # Femap format\n            if \"$ Femap Property\" in propComment:\n                # Pick off last word from comment, this is the name\n                propName = propComment.split()[-1]\n                self.compDescripts.append(propName)\n            # HyperMesh format\n            elif \"$HMNAME PROP\" in propComment:\n                # Locate property name line\n                loc = propComment.find(\"HMNAME PROP\")\n                compLine = propComment[loc:]\n                # The component name is between double quotes\n                propName = compLine.split('\"')[1]\n                self.compDescripts.append(propName)\n            # Patran format\n            elif \"$ Elements and Element Properties for region\" in propComment:\n                # The component name is after the colon\n                propName = propComment.split(\":\")[1]\n                self.compDescripts.append(propName)\n\n            # No format, default component name\n            else:\n                self.compDescripts.append(f\"Property group {pID}\")\n\n        # Element connectivity information\n        self.elemConnectivity = [None] * self.bdfInfo.nelements\n        self.elemConnectivityPointer = [None] * (self.bdfInfo.nelements + 1)\n        self.elemConnectivityPointer[0] = 0\n        elementObjectCounter = 0\n        # List specifying which tacs element object each element in bdf should point to\n        self.elemObjectNumByElem = [None] * (self.bdfInfo.nelements)\n\n        # Loop through every element and record information needed for tacs\n        for tacsElementID, nastranElementID in enumerate(self.bdfInfo.element_ids):\n            element = self.bdfInfo.elements[nastranElementID]\n            elementType = element.type.upper()\n            propertyID = element.pid\n            componentID = self.idMap(propertyID, self.nastranToTACSCompIDDict)\n\n            # This element type has not been added to the list for the component group yet, so we append it\n            if elementType not in self.elemDescripts[componentID]:\n                self.elemDescripts[componentID].append(elementType)\n                self.elemObjectNumByComp[componentID].append(elementObjectCounter)\n                elementObjectCounter += 1\n\n            # Find the index number corresponding to the element object number for this component\n            componentTypeIndex = self.elemDescripts[componentID].index(elementType)\n            self.elemObjectNumByElem[tacsElementID] = self.elemObjectNumByComp[\n                componentID\n            ][componentTypeIndex]\n\n            # We've identified a ICEM property label\n            if \"Shell element data for family\" in element.comment:\n                componentName = element.comment.split()[-1]\n                self.compDescripts[componentID] = componentName\n\n            conn = element.nodes.copy()\n\n            # TACS has a different node ordering than Nastran for certain elements,\n            # we now perform the reordering (if necessary)\n            if elementType in [\"CQUAD4\", \"CQUADR\"]:\n                conn = [conn[0], conn[1], conn[3], conn[2]]\n            elif elementType in [\"CQUAD9\", \"CQUAD\"]:\n                conn = [\n                    conn[0],\n                    conn[4],\n                    conn[1],\n                    conn[7],\n                    conn[8],\n                    conn[5],\n                    conn[3],\n                    conn[6],\n                    conn[2],\n                ]\n            elif elementType in [\"CHEXA8\", \"CHEXA\"]:\n                conn = [\n                    conn[0],\n                    conn[1],\n                    conn[3],\n                    conn[2],\n                    conn[4],\n                    conn[5],\n                    conn[7],\n                    conn[6],\n                ]\n\n            # Map node ids in connectivity from Nastran numbering to TACS numbering\n            self.elemConnectivity[tacsElementID] = self.idMap(\n                conn, self.nastranToTACSNodeIDDict\n            )\n            self.elemConnectivityPointer[\n                tacsElementID + 1\n            ] = self.elemConnectivityPointer[tacsElementID] + len(element.nodes)\n\n        # Allocate list for user-specified tacs element objects\n        self.elemObjects = [None] * elementObjectCounter\n\n        # Total number of nodes used to hold lagrange multiplier variables\n        self.numMultiplierNodes = 0\n        # List to hold ID numbers (TACS ordering) of multiplier nodes added to the problem later\n        self.multiplierNodeIDs = []\n\n    def _updateNastranToTACSDicts(self):\n        \"\"\"\n        Create dictionaries responsible for mapping over\n        global node, global element, and property/component ID numbers\n        from NASTRAN (as read in from BDF) to TACS (contiguous, 0-based).\n        The keys of each dictionary are the NASTRAN ID and the entry the TACS ID,\n        such that:\n            tacsNodeID = self.nastranToTACSNodeIDDict[nastranNodeID]\n            tacsComponentID = self.nastranToTACSCompIDDict[nastranPropertyID]\n            tacsElementID = self.nastranToTACSNodeIDDict[nastranElementID]\n        The dictionaries contain all elements/nodes found in the BDF,\n        not just those *owned* by this processor\n        \"\"\"\n        # Create Node ID map\n        nastranIDs = self.bdfInfo.node_ids\n        tacsIDs = range(self.bdfInfo.nnodes)\n        nodeTuple = zip(nastranIDs, tacsIDs)\n        self.nastranToTACSNodeIDDict = dict(nodeTuple)\n\n        # Create Property/Component ID map\n        nastranIDs = self.bdfInfo.property_ids\n        tacsIDs = range(self.bdfInfo.nproperties)\n        propTuple = zip(nastranIDs, tacsIDs)\n        self.nastranToTACSCompIDDict = dict(propTuple)\n\n        # Create Element ID map\n        nastranIDs = self.bdfInfo.element_ids\n        tacsIDs = range(self.bdfInfo.nelements)\n        elemTuple = zip(nastranIDs, tacsIDs)\n        self.nastranToTACSElemIDDict = dict(elemTuple)\n\n    def getBDFInfo(self):\n        \"\"\"\n        Return pynastran bdf object.\n\n        Returns\n        -------\n        bdfInfo : pyNastran.bdf.bdf.BDF\n            pyNastran bdf object.\n        \"\"\"\n        return self.bdfInfo\n\n    def getNumComponents(self):\n        \"\"\"\n        Return number of components (properties) found in bdf.\n\n        Returns\n        -------\n        nComps : int\n            Number of components (properties) found in bdf file.\n        \"\"\"\n        return self.bdfInfo.nproperties\n\n    def getNumBDFNodes(self):\n        \"\"\"\n        Return number of nodes found in bdf.\n\n        Returns\n        -------\n        nNodes : int\n            Number of nodes found in bdf file.\n        \"\"\"\n        return self.bdfInfo.nnodes\n\n    def getNumOwnedNodes(self):\n        \"\"\"\n        Return number of nodes owned by this processor.\n\n        Returns\n        -------\n        nNodes : int\n            Number of nodes owned by this proc.\n        \"\"\"\n        return self.assembler.getNumOwnedNodes()\n\n    def getNumBDFElements(self):\n        \"\"\"\n        Return number of elements found in bdf.\n\n        Returns\n        -------\n        nElems : int\n            Number of elements found in bdf file.\n        \"\"\"\n        return self.bdfInfo.nelements\n\n    def getBDFNodes(self, nodeIDs, nastranOrdering=False):\n        \"\"\"\n        Return x,y,z location of specified node in bdf file.\n\n        Returns\n        -------\n        xyz : numpy.ndarray\n            Coordinates of specified nodes.\n        \"\"\"\n        # Convert to tacs numbering, if necessary\n        if nastranOrdering:\n            nodeIDs = self.idMap(nodeIDs, self.nastranToTACSNodeIDDict)\n        return self.bdfXpts[nodeIDs]\n\n    def getElementComponents(self):\n        \"\"\"\n        Get a list specifying the component ID of each element.\n\n        Returns\n        -------\n        compIDList : list[int]\n            List containing componentID of each element found in the bdf file.\n        \"\"\"\n        elements = self.bdfInfo.elements\n        propertyIDList = [elements[eID].pid for eID in self.bdfInfo.element_ids]\n        compIDList = self.idMap(propertyIDList, self.nastranToTACSCompIDDict)\n        return compIDList\n\n    def getConnectivityForComp(self, componentID, nastranOrdering=False):\n        \"\"\"\n        Get a nodal connectivities of each element belonging to the specified component.\n\n        Parameters\n        ----------\n        componentID : int\n            Component ID number.\n\n        nastranOrdering : bool\n            Flag signaling whether nodeIDs should be returned in TACS (default) or NASTRAN (grid IDs in bdf file) ordering\n            Defaults to False.\n\n        Returns\n        -------\n        elemConns : list[list[int]]\n            List of nodal connectivities of each element belonging to this component.\n        \"\"\"\n        # Find all of the element IDs belonging to this property group\n        propertyID = list(self.bdfInfo.property_ids)[componentID]\n        elementIDs = self.propertyIDToElementIDDict[propertyID]\n        compConn = []\n        for elementID in elementIDs:\n            # We've now got the connectivity for this element, but it is in nastrans node numbering\n            nastranConn = self.bdfInfo.elements[elementID].nodes\n            if nastranOrdering:\n                compConn.append(nastranConn)\n            else:\n                # Convert Nastran node numbering back to tacs numbering\n                tacsConn = self.idMap(nastranConn, self.nastranToTACSNodeIDDict)\n                # Append element connectivity to list for component\n                compConn.append(tacsConn)\n        return compConn\n\n    def getElementObjectNumsForComp(self, componentID):\n        \"\"\"\n        Return tacs element object number for each element type\n        belonging to this component.\n\n        Parameters\n        ----------\n        componentID : int\n            Component ID number.\n\n        Returns\n        -------\n        objNums : list[int]\n            List holding element object nums for the specifed component.\n        \"\"\"\n        return self.elemObjectNumByComp[componentID][:]\n\n    def getElementDescripts(self):\n        \"\"\"\n        Get nested list containing all element types owned by each component group\n        example: [['CQUAD4', 'CTRIA3], ['CQUAD4'], ['CQUAD4', CQUAD9']]\n\n        Returns\n        -------\n        elemDescripts : list[list[str]]\n            Nested list holding all element types owned by each component group.\n        \"\"\"\n        return self.elemDescripts\n\n    def getComponentDescripts(self):\n        \"\"\"\n        Get user-defined labels for each component read in from the BDF.\n\n        Returns\n        -------\n        compDescripts : list[str]\n            List holding description strings for each component.\n        \"\"\"\n        return self.compDescripts\n\n    def getLocalNodeIDsFromGlobal(self, globalIDs, nastranOrdering=False):\n        \"\"\"\n        Given a list of node IDs in global (non-partitioned) ordering\n        returns the local (partitioned) node IDs on each processor.\n        If a requested node is not included on this processor,\n        an entry of -1 will be returned.\n\n        Parameters\n        ----------\n        globalIDs : int or list[int]\n            List of global node IDs.\n\n        nastranOrdering : bool\n            Flag signaling whether globalIDs is in TACS (default) or NASTRAN (grid IDs in bdf file) ordering\n            Defaults to False.\n\n        Returns\n        -------\n        localIDs : list[int]\n            List of local node IDs for each entry in globalIDs.\n            If the node is not owned by this processor, its index is filled with a value of -1.\n        \"\"\"\n        # Convert to tacs node numbering, if necessary\n        if nastranOrdering:\n            globalIDs = self.idMap(globalIDs, self.nastranToTACSNodeIDDict)\n\n        # Ensure input is list-like\n        globalIDs = np.atleast_1d(globalIDs)\n\n        # Get the node id offset for this processor\n        OwnerRange = self.assembler.getOwnerRange()\n        nodeOffset = OwnerRange[self.comm.rank]\n\n        # Get the local ID numbers for this proc\n        tacsLocalIDs = []\n        for gID in globalIDs:\n            lIDs = self.creator.getAssemblerNodeNums(\n                self.assembler, np.array([gID], dtype=np.intc)\n            )\n            # Node was not found on this proc, return -1\n            if len(lIDs) == 0:\n                tacsLocalIDs.append(-1)\n            # Node was found on this proc, shift by nodeOffset to get local index for node\n            else:\n                tacsLocalIDs.append(lIDs[0] - nodeOffset)\n\n        return tacsLocalIDs\n\n    def getLocalElementIDsFromGlobal(self, globalIDs, nastranOrdering=False):\n        \"\"\"\n        Given a list of element IDs in global (non-partitioned) ordering\n        returns the local (partitioned) element IDs on each processor.\n        If a requested element is not included on this processor,\n        an entry of -1 will be returned.\n\n        Parameters\n        ----------\n        globalIDs : int or list[int]\n            List of global element IDs.\n\n        nastranOrdering : bool\n            Flag signaling whether globalIDs is in TACS (default) or NASTRAN (element IDs in bdf file) ordering\n            Defaults to False.\n\n        Returns\n        -------\n        localIDs : list[int]\n            List of local element IDs for each entry in globalIDs.\n            If the element is not owned by this processor, its index is filled with a value of -1.\n        \"\"\"\n        # Convert to tacs node numbering, if necessary\n        if nastranOrdering:\n            globalIDs = self.idMap(globalIDs, self.nastranToTACSElemIDDict)\n\n        # Ensure input is list-like\n        globalIDs = np.atleast_1d(globalIDs)\n\n        # Get the local ID numbers for this proc\n        tacsLocalIDs = []\n        for gID in globalIDs:\n            # element was found on this proc, get local ID num\n            if gID in self.globalToLocalElementIDDict:\n                lID = self.globalToLocalElementIDDict[gID]\n            # element was not found on this proc, return -1\n            else:\n                lID = -1\n            tacsLocalIDs.append(lID)\n\n        return tacsLocalIDs\n\n    def getGlobalNodeIDsForComps(self, componentIDs, nastranOrdering=False):\n        \"\"\"\n        Return the global (non-partitioned) node IDs belonging to a given list of component IDs\n\n        Parameters\n        ----------\n        componentIDs : int or list[int]\n            List of integers of the compIDs numbers.\n\n        nastranOrdering : bool\n            Flag signaling whether nodeIDs should be returned in TACS (default) or NASTRAN (grid IDs in bdf file) ordering\n            Defaults to False.\n\n        Returns\n        -------\n        nodeIDs : list[int]\n            List of unique nodeIDs that belong to the given list of compIDs\n        \"\"\"\n        # First determine the actual physical locations\n        # of the nodes we want to add forces\n        # to. Only the root rank need do this:\n        uniqueNodes = None\n        if self.comm.rank == 0:\n            allNodes = []\n            componentIDs = self._flatten(componentIDs)\n            componentIDs = set(componentIDs)\n            for cID in componentIDs:\n                tmp = self.getConnectivityForComp(cID, nastranOrdering=nastranOrdering)\n                allNodes.extend(self._flatten(tmp))\n\n            # Now just unique all the nodes:\n            uniqueNodes = np.unique(allNodes)\n\n        uniqueNodes = self.comm.bcast(uniqueNodes, root=0)\n\n        return list(uniqueNodes)\n\n    def getLocalNodeIDsForComps(self, componentIDs):\n        \"\"\"\n        return the local (partitioned) node IDs belonging to a given list of component IDs\n\n        Parameters\n        ----------\n        componentIDs : int or list[int]\n            List of integers of the compIDs numbers.\n\n        Returns\n        -------\n        nodeIDs : list[int]\n            List of unique nodeIDs that belong to the given list of compIDs\n        \"\"\"\n        # Get the global nodes for this component (TACS ordering)\n        globalNodeIDs = self.getGlobalNodeIDsForComps(\n            componentIDs, nastranOrdering=False\n        )\n\n        # get the corresponding local IDs on each proc\n        localNodeIDs = self.getLocalNodeIDsFromGlobal(globalNodeIDs, nastranOrdering=False)\n        # If the returned index is > 0 then it is owned by this proc, otherwise remove it\n        localNodeIDs = [localID for localID in localNodeIDs if localID >= 0]\n\n        return localNodeIDs\n\n    def getGlobalElementIDsForComps(self, componentIDs, nastranOrdering=False):\n        \"\"\"\n        Returns a list of element IDs belonging to specified components\n\n        Parameters\n        ----------\n        componentIDs : list[int]\n            Component ID numbers.\n\n        nastranOrdering : bool\n            Flag signaling whether elemIDs should be returned in TACS (default) or NASTRAN (grid IDs in bdf file) ordering\n            Defaults to False\n\n        Returns\n        -------\n        elemIDs : list[int]\n            List of global element IDs belonging to the specified components.\n        \"\"\"\n        # Make sure list is flat\n        componentIDs = self._flatten(componentIDs)\n        # Convert tacs component IDs to nastran property IDs\n        propertyIDs = [0] * len(componentIDs)\n        for i, componentID in enumerate(componentIDs):\n            propertyIDs[i] = list(self.bdfInfo.property_ids)[componentID]\n        # Get dictionary whose values are the element ids we are looking for\n        elementIDDict = self.bdfInfo.get_element_ids_dict_with_pids(propertyIDs)\n        # Convert to list\n        elementIDs = list(elementIDDict.values())\n        # Make sure list is flat\n        elementIDs = self._flatten(elementIDs)\n        # Convert to tacs element numbering, if necessary\n        if not nastranOrdering:\n            elementIDs = self.idMap(elementIDs, self.nastranToTACSElemIDDict)\n        return elementIDs\n\n    def getLocalElementIDsForComps(self, componentIDs):\n        \"\"\"\n        Get the local element numbers on each proc used by tacs\n        corresponding to the component groups in componentIDs.\n\n        Parameters\n        ----------\n        componentIDs : list[int]\n            Component ID numbers.\n\n        Returns\n        -------\n        elemIDs : list[int]\n            List of local element IDs on this proc belonging to the specified components.\n        \"\"\"\n        if self.creator is None:\n            raise self._TACSError(\n                \"TACS assembler has not been created. \"\n                \"Assembler must created first by running 'createTACS' method.\"\n            )\n        # Make sure list is flat\n        componentIDs = self._flatten(componentIDs)\n        # Get the element object IDs belonging to each of these components\n        objIDs = []\n        for componentID in componentIDs:\n            tmp = self.getElementObjectNumsForComp(componentID)\n            objIDs.extend(tmp)\n        objIDs = np.array(objIDs, dtype=np.intc)\n        # Get the local element IDs corresponding to the object IDs on this processor (if any)\n        localElemIDs = self.creator.getElementIdNums(objIDs)\n        return list(localElemIDs)\n\n    def getLocalMultiplierNodeIDs(self):\n        \"\"\"\n        Get the tacs indices of multiplier nodes used to hold lagrange multipliers on this processor.\n\n        Returns\n        -------\n        nodeIDs : list[int]\n            List of multiplier node ID's owned by this proc.\n        \"\"\"\n        return self.ownedMultiplierNodeIDs\n\n    def getGlobalToLocalNodeIDDict(self):\n        \"\"\"\n        Creates a dictionary who's keys correspond to the global ID of each node (tacs ordering)\n        owned by this processor and whose values correspond to the local node index for this proc.\n        The dictionary can be used to convert from a global node ID to local using the assignment below*:\n        localNodeID = globalToLocalNodeIDDict[globalNodeID]\n\n        * assuming globalNodeID is owned on this processor\n\n        Returns\n        -------\n        globalToLocalNodeIDDict : dict[int,int]\n            Dictionary holding mapping from global to local node IDs for this proc\n        \"\"\"\n        globalToLocalNodeIDDict = {}\n        for tacsNodeID in range(self.bdfInfo.nnodes):\n            # Get the local ID corresponding to the global ID (if owned by this proc)\n            lID = self.getLocalNodeIDsFromGlobal(tacsNodeID, nastranOrdering=False)[0]\n            # Add the local node ID to the dict if its owned by this proc\n            if lID >= 0:\n                globalToLocalNodeIDDict[tacsNodeID] = lID\n\n        return globalToLocalNodeIDDict\n\n    def getGlobalToLocalElementIDDict(self):\n        \"\"\"\n        Creates a dictionary who's keys correspond to the global ID of each element (tacs ordering)\n        owned by this processor and whose values correspond to the local element index for this proc.\n        The dictionary can be used to convert from a global element ID to local using the assignment below*:\n        localElementID = globalToLocalElementIDDict[globalElementID]\n\n        * assuming globalElementID is owned on this processor\n\n        Returns\n        -------\n        globalToLocalElementIDDict : dict[int,int]\n            Dictionary holding mapping from global to local element IDs for this proc\n        \"\"\"\n        # Do sorting on root proc\n        if self.comm.rank == 0:\n            # List containing which poc every element belongs to\n            elemPartition = self.creator.getElementPartition()\n            # Create an empty list that we will use to sort what elements are on what procs\n            allOwnedElementIDs = [[] for proc_i in range(self.comm.size)]\n            for elemGlobalID in range(len(elemPartition)):\n                ownerProc = elemPartition[elemGlobalID]\n                allOwnedElementIDs[ownerProc].append(elemGlobalID)\n        else:\n            allOwnedElementIDs = None\n\n        # Scatter the list from the root so each proc knows what element ID it owns\n        ownedElementIDs = self.comm.scatter(allOwnedElementIDs, root=0)\n        # Create dictionary that gives the corresponding local ID for each global ID owned by this proc\n        globalToLocalElementIDDict = {\n            gID: lID for lID, gID in enumerate(ownedElementIDs)\n        }\n\n        return globalToLocalElementIDDict\n\n    def getElementObject(self, componentID, objectIndex):\n        \"\"\"\n        Return TACS element object corresponding to component ID and object index.\n\n        Parameters\n        ----------\n        componentID : int\n            Component ID number\n\n        objectIndex : int\n            Object index number.\n            Some components may have multiple TACS element types associated with them.\n            This index specifies which object should be returned.\n\n        Returns\n        -------\n        elemObj : tacs.TACS.Element\n            TACS element object.\n        \"\"\"\n        pointer = self.elemObjectNumByComp[componentID][objectIndex]\n        return self.elemObjects[pointer]\n\n    def setElementObject(self, componentID, objectIndex, elemObject):\n        \"\"\"\n        Set TACS element object to component ID and object index.\n\n        Parameters\n        ----------\n        componentID : int\n            Component ID number\n\n        objectIndex : int\n            Object index number.\n            Some components may have multiple TACS element types associated with them.\n            This index specifies which object should be assigned.\n\n        elemObject : tacs.TACS.Element\n            TACS element object.\n        \"\"\"\n        pointer = self.elemObjectNumByComp[componentID][objectIndex]\n        self.elemObjects[pointer] = elemObject\n\n    def getElementObjectForElemID(self, elemID, nastranOrdering=False):\n        \"\"\"\n        Return TACS element object corresponding to specified element ID.\n\n        Parameters\n        ----------\n        elemID : int\n            Element ID number\n\n        nastranOrdering : bool\n            Flag signaling whether elemIDs are in TACS (default) or NASTRAN (grid IDs in bdf file) ordering\n            Defaults to False.\n\n        Returns\n        -------\n        elemObj : tacs.TACS.Element\n            TACS element object.\n        \"\"\"\n        # Convert to tacs numbering, if necessary\n        if nastranOrdering:\n            elemID = self.idMap(elemID, self.nastranToTACSElemIDDict)\n        # Get the pointer for the tacs element object for this element\n        elemObjNum = self.elemObjectNumByElem[elemID]\n        elemObj = self.elemObjects[elemObjNum]\n        return elemObj\n\n    def createTACSAssembler(self, varsPerNode, massDVs):\n        \"\"\"\n        Setup TACSCreator object responsible for creating TACSAssembler\n\n        Parameters\n        ----------\n        varsPerNode : int\n            Number of variables per node for the model.\n\n        massDVs : dict\n            Dictionary holding dv info for point masses.\n        \"\"\"\n        self.creator = tacs.TACS.Creator(self.comm, varsPerNode)\n\n        # Append RBE elements to element list, these are not setup by the user\n        for rbe in self.bdfInfo.rigid_elements.values():\n            if rbe.type == \"RBE2\":\n                self._addTACSRBE2(rbe, varsPerNode)\n            elif rbe.type == \"RBE3\":\n                self._addTACSRBE3(rbe, varsPerNode)\n            else:\n                raise NotImplementedError(\n                    f\"Rigid element of type '{rbe.type}' is not supported\"\n                )\n\n        # Append point mass elements to element list, these are not setup by the user\n        for massInfo in self.bdfInfo.masses.values():\n            # Find the dv dict for this mass element, if not found return empty\n            dvDict = massDVs.get(massInfo.eid, {})\n            self._addTACSMassElement(massInfo, varsPerNode, dvDict)\n\n        # Check for any nodes that aren't attached to at least one element\n        self._unattachedNodeCheck()\n\n        # Setup element connectivity and boundary condition info on root processor\n        if self.comm.rank == 0:\n            # Set connectivity for all elements\n            ptr = np.array(self.elemConnectivityPointer, dtype=np.intc)\n            # Flatten nested connectivity list to single list\n            conn = it.chain.from_iterable(self.elemConnectivity)\n            conn = np.array([*conn], dtype=np.intc)\n            objectNums = np.array(self.elemObjectNumByElem, dtype=np.intc)\n            self.creator.setGlobalConnectivity(\n                self.bdfInfo.nnodes, ptr, conn, objectNums\n            )\n\n            # Set up the boundary conditions\n            bcDict = {}\n            for spc_id in self.bdfInfo.spcs:\n                for spc in self.bdfInfo.spcs[spc_id]:\n                    # Loop through every node specifed in this spc and record bc info\n                    for j, nastranNode in enumerate(spc.nodes):\n                        # If constrained node doesn't exist in bdf\n                        if nastranNode not in self.bdfInfo.node_ids:\n                            self._TACSWarning(\n                                f\"Node ID {nastranNode} (Nastran ordering) is referenced by an SPC,  \"\n                                \"but the node was not defined in the BDF file. Skipping SPC.\"\n                            )\n                            continue\n\n                        # Convert to TACS node ID\n                        tacsNode = self.idMap(nastranNode, self.nastranToTACSNodeIDDict)\n\n                        # If node hasn't been added to bc dict yet, add it\n                        if tacsNode not in bcDict:\n                            bcDict[tacsNode] = {}\n\n                        # Loop through each dof and record bc info if it is included in this spc\n                        for dof in range(varsPerNode):\n                            # Add 1 to get nastran dof number\n                            nastranDOF = dof + 1\n                            if spc.type == \"SPC\":\n                                # each node may have its own dofs uniquely constrained\n                                constrainedDOFs = spc.components[j]\n                                # The boundary condition may be forced to a non-zero value\n                                constrainedVal = spc.enforced[j]\n                            else:  # SPC1?\n                                # All nodes always have the same dofs constrained\n                                constrainedDOFs = spc.components\n                                # This boundary condition is always 0\n                                constrainedVal = 0.0\n                            # if nastran dof is in spc components string, add it to the bc dict\n                            if self._isDOFInString(constrainedDOFs, nastranDOF):\n                                bcDict[tacsNode][dof] = constrainedVal\n\n            # Convert bc information from dict to list\n            bcnodes = []\n            bcdofs = []\n            bcptr = [0]\n            bcvals = []\n            numbcs = 0\n            for tacsNode in bcDict:\n                bcnodes.append(tacsNode)\n                # Store constrained dofs for this node\n                dofs = bcDict[tacsNode].keys()\n                bcdofs.extend(dofs)\n                # Store enforced bc value\n                vals = bcDict[tacsNode].values()\n                bcvals.extend(vals)\n                # Increment bc pointer with how many constraints weve added for this node\n                numbcs += len(bcDict[tacsNode])\n                bcptr.append(numbcs)\n\n            # Recast lists as numpy arrays\n            bcnodes = np.array(bcnodes, dtype=np.intc)\n            bcdofs = np.array(bcdofs, dtype=np.intc)\n            bcptr = np.array(bcptr, dtype=np.intc)\n            bcvals = np.array(bcvals, dtype=self.dtype)\n            # Set boundary conditions in tacs\n            self.creator.setBoundaryConditions(bcnodes, bcptr, bcdofs, bcvals)\n\n            # Set node locations\n            Xpts = self.bdfInfo.get_xyz_in_coord(fdtype=self.dtype, sort_ids=False)\n            self.creator.setNodes(Xpts.flatten())\n\n        # Set the elements for each component\n        self.creator.setElements(self.elemObjects)\n\n        self.assembler = self.creator.createTACS()\n\n        self.globalToLocalElementIDDict = self.getGlobalToLocalElementIDDict()\n\n        # If any multiplier nodes were added, record their local processor indices\n        localIDs = self.getLocalNodeIDsFromGlobal(\n            self.multiplierNodeIDs, nastranOrdering=False\n        )\n        self.ownedMultiplierNodeIDs = [localID for localID in localIDs if localID >= 0]\n\n        return self.assembler\n\n    def _isDOFInString(self, constrained_dofs, dof):\n        \"\"\"\n        Determine if dof number (nastran numbering) occurs in constraint string.\n\n        Parameters\n        ----------\n        constrained_dofs : string\n            String containing list of dofs (ex. '123456')\n\n        dof : int or string\n            nastran dof number to check for\n\n        Returns\n        -------\n        found : bool\n            Flag indicating if specified dof is in string.\n        \"\"\"\n        # Convert to string, if necessary\n        if isinstance(dof, int):\n            dof = \"%d\" % dof\n        # pyNastran only supports 0,1,2,3,4,5,6 as valid dof components\n        # For this reason, we'll treat 0 as if its 7, since it's traditionally never used in nastran\n        if dof == \"7\":\n            dof = \"0\"\n        location = constrained_dofs.find(dof)\n        # if dof is found, return true\n        if location > -1:\n            return True\n        else:\n            return False\n\n    def _addTACSRBE2(self, rbeInfo, varsPerNode):\n        \"\"\"\n        Method to automatically set up RBE2 element from bdf file for user.\n        User should *NOT* set these up in their elemCallBack function.\n\n        Parameters\n        ----------\n        rbeInfo : pyNastran.bdf.cards.elements.rigid.RBE2\n            pyNastran object holding rbe info.\n\n        varsPerNode : int\n            Number of variables per node for the model.\n        \"\"\"\n        indepNode = rbeInfo.independent_nodes\n        depNodes = []\n        depConstrainedDOFs = []\n        dummyNodes = []\n        dofsAsString = rbeInfo.cm\n        dofsAsList = self.dofStringToList(dofsAsString, varsPerNode)\n        for node in rbeInfo.dependent_nodes:\n            depNodes.append(node)\n            depConstrainedDOFs.extend(dofsAsList)\n            # add dummy nodes for all lagrange multiplier\n            dummyNodeNum = (\n                max(self.bdfInfo.node_ids) + 1\n            )  # Next available nastran node number\n            # Add the dummy node coincident to the dependent node in x,y,z\n            self.bdfInfo.add_grid(dummyNodeNum, self.bdfInfo.nodes[node].xyz)\n            # Update Nastran to TACS ID mapping dicts, since we just added new nodes to model\n            self.nastranToTACSNodeIDDict[dummyNodeNum] = self.bdfInfo.nnodes - 1\n            dummyNodes.append(dummyNodeNum)\n\n        conn = indepNode + depNodes + dummyNodes\n        nTotalNodes = len(conn)\n        # Add dummy nodes to lagrange multiplier node list\n        self.numMultiplierNodes += len(dummyNodes)\n        tacsIDs = self.idMap(dummyNodes, self.nastranToTACSNodeIDDict)\n        self.multiplierNodeIDs.extend(tacsIDs)\n        # Append RBE information to the end of the element lists\n        self.elemConnectivity.append(self.idMap(conn, self.nastranToTACSNodeIDDict))\n        self.elemConnectivityPointer.append(\n            self.elemConnectivityPointer[-1] + nTotalNodes\n        )\n        rbeObj = tacs.elements.RBE2(\n            nTotalNodes, np.array(depConstrainedDOFs, dtype=np.intc)\n        )\n        self.elemObjectNumByElem.append(len(self.elemObjects))\n        self.elemObjects.append(rbeObj)\n        return\n\n    def _addTACSRBE3(self, rbeInfo, varsPerNode):\n        \"\"\"\n        Method to automatically set up RBE3 element from bdf file for user.\n        User should *NOT* set these up in their elemCallBack function.\n\n        Parameters\n        ----------\n        rbeInfo : pyNastran.bdf.cards.elements.rigid.RBE3\n            pyNastran object holding rbe info.\n\n        varsPerNode : int\n            Number of variables per node for the model.\n        \"\"\"\n        depNode = rbeInfo.dependent_nodes\n        depConstrainedDOFs = self.dofStringToList(rbeInfo.refc, varsPerNode)\n\n        # add dummy node for lagrange multipliers\n        dummyNodeNum = max(self.bdfInfo.node_ids) + 1  # Next available node number\n        # Add the dummy node coincident to the dependent node in x,y,z\n        self.bdfInfo.add_grid(dummyNodeNum, self.bdfInfo.nodes[depNode[0]].xyz)\n        # Update Nastran to TACS ID mapping dicts, since we just added new nodes to model\n        self.nastranToTACSNodeIDDict[dummyNodeNum] = self.bdfInfo.nnodes - 1\n        dummyNodes = [dummyNodeNum]\n        # Add dummy node to lagrange multiplier node list\n        self.numMultiplierNodes += len(dummyNodes)\n        tacsIDs = self.idMap(dummyNodes, self.nastranToTACSNodeIDDict)\n        self.multiplierNodeIDs.extend(tacsIDs)\n\n        # Get node and rbe3 weight info\n        indepNodes = []\n        indepWeights = []\n        indepConstrainedDOFs = []\n        for depNodeGroup in rbeInfo.wt_cg_groups:\n            wt = depNodeGroup[0]\n            dofsAsString = depNodeGroup[1]\n            dofsAsList = self.dofStringToList(dofsAsString, varsPerNode)\n            for node in depNodeGroup[2]:\n                indepNodes.append(node)\n                indepWeights.append(wt)\n                indepConstrainedDOFs.extend(dofsAsList)\n\n        conn = depNode + indepNodes + dummyNodes\n        nTotalNodes = len(conn)\n        # Append RBE information to the end of the element lists\n        self.elemConnectivity.append(self.idMap(conn, self.nastranToTACSNodeIDDict))\n        self.elemConnectivityPointer.append(\n            self.elemConnectivityPointer[-1] + nTotalNodes\n        )\n        rbeObj = tacs.elements.RBE3(\n            nTotalNodes,\n            np.array(depConstrainedDOFs, dtype=np.intc),\n            np.array(indepWeights),\n            np.array(indepConstrainedDOFs, dtype=np.intc),\n        )\n        self.elemObjectNumByElem.append(len(self.elemObjects))\n        self.elemObjects.append(rbeObj)\n        return\n\n    def _addTACSMassElement(self, massInfo, varsPerNode, dvDict):\n        \"\"\"\n        Method to automatically set up TACS mass elements from bdf file for user.\n        User should *NOT* set these up in their elemCallBack function.\n\n        Parameters\n        ----------\n        massInfo : pyNastran.bdf.cards.elements.mass.PointMassElement\n            pyNastran object holding rbe info.\n\n        varsPerNode : int\n            Number of variables per node for the model.\n\n        dvDict : dict\n            Dictionary holding dv info for point mass.\n        \"\"\"\n        if massInfo.type == \"CONM2\":\n            m = massInfo.mass\n            I11, I12, I22, I13, I23, I33 = massInfo.I\n            # Create dict with input args for PointMassConstitutive\n            massArgs = {\n                \"m\": m,\n                \"I11\": I11,\n                \"I22\": I22,\n                \"I33\": I33,\n                \"I12\": I12,\n                \"I13\": I13,\n                \"I23\": I23,\n            }\n            # Update mass arguments with user-defined dv info\n            massArgs.update(dvDict)\n            con = tacs.constitutive.PointMassConstitutive(**massArgs)\n        elif massInfo.type == \"CONM1\":\n            M = np.zeros(21)\n            M[0:6] = massInfo.mass_matrix[0:, 0]\n            M[6:11] = massInfo.mass_matrix[1:, 1]\n            M[11:15] = massInfo.mass_matrix[2:, 2]\n            M[15:18] = massInfo.mass_matrix[3:, 3]\n            M[18:20] = massInfo.mass_matrix[4:, 4]\n            M[20] = massInfo.mass_matrix[5, 5]\n            # off-diagonal moment of inertia terms have to be negated, since they aren't in nastran convention\n            M[16] *= -1.0\n            M[17] *= -1.0\n            M[19] *= -1.0\n            con = tacs.constitutive.GeneralMassConstitutive(M=M)\n        else:\n            raise NotImplementedError(\n                f\"Mass element of type '{massInfo.type}' is not supported\"\n            )\n\n        # Append point mass information to the end of the element lists\n        conn = [massInfo.node_ids[0]]\n        self.elemConnectivity.append(self.idMap(conn, self.nastranToTACSNodeIDDict))\n        self.elemConnectivityPointer.append(self.elemConnectivityPointer[-1] + 1)\n        # Create tacs object for mass element\n        massObj = tacs.elements.MassElement(con)\n        self.elemObjectNumByElem.append(len(self.elemObjects))\n        self.elemObjects.append(massObj)\n        return\n\n    def _unattachedNodeCheck(self):\n        \"\"\"\n        Check for any nodes that aren't attached to an element.\n        Notify the user and throw an error if we find any.\n        This must be checked before creating the TACS assembler or a SegFault may occur.\n        \"\"\"\n        numUnattached = 0\n        if self.comm.rank == 0:\n            # Flatten connectivity to a single list\n            flattenedConn = it.chain.from_iterable(self.elemConnectivity)\n            # uniqueify and order all element-attached nodes\n            attachedNodes = set(flattenedConn)\n            # Loop through each node in the bdf and check if it's in the element node set\n            for nastranNodeID in self.bdfInfo.node_ids:\n                tacsNodeID = self.idMap(nastranNodeID, self.nastranToTACSNodeIDDict)\n                if tacsNodeID not in attachedNodes:\n                    if numUnattached < 100:\n                        self._TACSWarning(\n                            f\"Node ID {nastranNodeID} (Nastran ordering) is not attached to any element in the model. \"\n                            f\"Please remove this node from the mesh and try again.\"\n                        )\n                    numUnattached += 1\n\n        # Broadcast number of found unattached nodes\n        numUnattached = self.comm.bcast(numUnattached, root=0)\n        # Raise an error if any unattached nodes were found\n        if numUnattached > 0:\n            raise self._TACSError(\n                f\"{numUnattached} unattached node(s) were detected in model. \"\n                f\"Please make sure that all nodes are attached to at least one element.\"\n            )\n\n    def dofStringToList(self, dofString, numDOFs):\n        \"\"\"\n        Converts a dof string to a boolean list.\n        Examples:\n            '123' -> [1, 1, 1, 0, 0, 0]\n            '1346' -> [1, 0, 1, 1, 0, 1]\n\n        Parameters\n        ----------\n        dofString : string\n            String containing list of dofs (ex. '123456')\n\n        numDOFs : int\n            Number of dofs in model\n\n        Returns\n        -------\n        dofList : list[int]\n            List of booleans indicating which dofs are present in input string.\n        \"\"\"\n        dofList = []\n        for dof in range(numDOFs):\n            dof = str(dof + 1)\n            loc = dofString.find(dof)\n            if loc > -1:\n                dofList.append(1)\n            else:\n                dofList.append(0)\n        return dofList\n\n    def idMap(self, fromIDs, tacsIDDict):\n        \"\"\"\n        Translate fromIDs numbering from nastran numbering to tacs numbering.\n        If node ID doesn't exist in nastranIDList, return -1 for entry\n\n        Parameters\n        ----------\n        fromIDs : int or list[int]\n            IDs in Nastran numbering\n\n        tacsIDDict : dict[int, int]\n            ID mapping dict generated by `_updateNastranToTACSDicts`\n\n        Returns\n        -------\n        toIDs : int or list[int]\n            IDs in TACS numbering\n        \"\"\"\n        # Input is a list return a list\n        if hasattr(fromIDs, \"__iter__\"):\n            toIDs = [None] * len(fromIDs)\n            # Iterate through list and call function recursively one element at a time\n            for i, id in enumerate(fromIDs):\n                toIDs[i] = self.idMap(id, tacsIDDict)\n            return toIDs\n        # Input is a int, return an int\n        else:\n            if fromIDs in tacsIDDict:\n                return tacsIDDict[fromIDs]\n            else:\n                return -1\n\n    @property\n    def allLocalNodeIDs(self):\n        \"\"\"\n        get list of tacs_ids for each nastran node owned across all processors\n        nastran_node = array_idx + 1\n        tacs_idx = output id\n        nastran_node - 1 => tacs_idx owned by this proc\n        \"\"\"\n\n        self._nastranToLocalNodeIDMap()\n        local_maps = self.comm.gather(self._local_map, root=0)\n        full_map_list = []\n        for local_map in local_maps:\n            full_map_list += local_map\n        all_struct_ids = None\n        if self.comm.rank == 0:\n            all_struct_ids = np.zeros((self.bdfInfo.nnodes), dtype=int)\n            for map in full_map_list:\n                for key in map:\n                    all_struct_ids[int(key)] = map[int(key)]\n            all_struct_ids = list(all_struct_ids)\n        # broadcast to other procs\n        all_struct_ids = self.comm.bcast(all_struct_ids, root=0)\n        return all_struct_ids\n\n    def _getLocalNodeIDs(self):\n        \"\"\"\n        get the local struct ids owned by this processor, full list when comm is None\n        -1 for each idx not owned by this processor\n        \"\"\"\n        num_nodes = self.bdfInfo.nnodes\n        bdf_nodes = [_ for _ in range(num_nodes)]\n        return self.getLocalNodeIDsFromGlobal(bdf_nodes, nastranOrdering=False)\n\n    def _nastranToLocalNodeIDMap(self):\n        \"\"\"\n        write the map nastran_node - 1 => tacs_idx on each processor\n        \"\"\"\n        local_struct_ids = self._getLocalNodeIDs()\n        id_map = []\n        for arr_idx, struct_id in enumerate(local_struct_ids):\n            if struct_id != -1:\n                id_map.append({arr_idx: struct_id})\n        self._local_map = id_map\n        return id_map",
  "def __init__(self, comm, printDebug=False):\n        # Set MPI communicator\n        BaseUI.__init__(self, comm=comm)\n        # Debug printing flag\n        self.printDebug = printDebug\n        self.bdfInfo = None",
  "def scanBdfFile(self, fileName):\n        \"\"\"\n        Scan nastran bdf file using pyNastran's bdf parser.\n        We also set up arrays that will be require later to build tacs.\n        \"\"\"\n\n        # Only print debug info on root, if requested\n        if self.comm.rank == 0:\n            debugPrint = self.printDebug\n        else:\n            debugPrint = False\n\n        # Read in bdf file as pynastran object\n        # By default we avoid cross-referencing unless we actually need it,\n        # since its expensive for large models\n        self.bdfInfo = read_bdf(fileName, validate=False, xref=False, debug=debugPrint)\n        # Set flag letting us know model is not xrefed yet\n        self.bdfInfo.is_xrefed = False\n\n        # If any property cards are missing in the bdf, we have to add dummy cards\n        # so pynastran doesn't through errors when cross-referencing\n        # Loop through all elements and add dummy property, as necessary\n        self.bdfInfo.missing_properties = False\n        for element_id in self.bdfInfo.elements:\n            element = self.bdfInfo.elements[element_id]\n            if element.pid not in self.bdfInfo.property_ids:\n                # If no material properties were found,\n                # add dummy properties and materials\n                matID = 1\n                E = 70.0\n                G = 35.0\n                nu = 0.3\n                self.bdfInfo.add_mat1(matID, E, G, nu)\n                self.bdfInfo.add_pbar(element.pid, matID)\n                # Warn the user that the property card is missing\n                # and should not be read in using pytacs elemCallBackFromBDF method\n                self.bdfInfo.missing_properties = True\n                if self.printDebug:\n                    self._TACSWarning(\n                        \"Element ID %d references undefined property ID %d in bdf file. \"\n                        \"A user-defined elemCallBack function will need to be provided.\"\n                        % (element_id, element.pid)\n                    )\n\n        # We have to remove any empty property groups that may have been read in from the BDF\n        self.propertyIDToElementIDDict = (\n            self.bdfInfo.get_property_id_to_element_ids_map()\n        )\n        for pid in self.propertyIDToElementIDDict:\n            # If there are no elements referencing this property card, remove it\n            if len(self.propertyIDToElementIDDict[pid]) == 0:\n                self.bdfInfo.properties.pop(pid)\n                self.propertyIDToElementIDDict.pop(pid)\n\n        # Create dictionaries for mapping between tacs and nastran id numbering\n        self._updateNastranToTACSDicts()\n\n        # Try to get the node x,y,z locations from bdf file\n        try:\n            self.bdfXpts = self.bdfInfo.get_xyz_in_coord(\n                fdtype=self.dtype, sort_ids=False\n            )\n        # If this fails, the file may reference multiple coordinate systems\n        # and will have to be cross-referenced to work\n        except:\n            self.bdfInfo.cross_reference()\n            self.bdfInfo.is_xrefed = True\n            self.bdfXpts = self.bdfInfo.get_xyz_in_coord(\n                fdtype=self.dtype, sort_ids=False\n            )\n\n        # element card contained within each property group (may contain multiple per group)\n        # Each entry will eventually have its own tacs element object assigned to it\n        # (ex. self.elemDescripts = [['CQUAD4', 'CTRIA3'], ['CQUAD9', 'CQUAD4'], ['CBAR']])\n        self.elemDescripts = []\n        # Pointer index used to map elemDescript entries into flat list\n        # (ex. self.elementObjectNumByComp = [[0, 1], [2, 3], [4]])\n        self.elemObjectNumByComp = []\n        # User-defined name for property/component group,\n        # this may be read in through ICEMCFD/FEMAP format comments in BDF\n        self.compDescripts = []\n\n        # Populate list entries with default values\n        for pID in self.bdfInfo.property_ids:\n            self.elemDescripts.append([])\n            self.elemObjectNumByComp.append([])\n            # Check if there is a Femap/HyperMesh/Patran label for this component\n            propComment = self.bdfInfo.properties[pID].comment\n            # Femap format\n            if \"$ Femap Property\" in propComment:\n                # Pick off last word from comment, this is the name\n                propName = propComment.split()[-1]\n                self.compDescripts.append(propName)\n            # HyperMesh format\n            elif \"$HMNAME PROP\" in propComment:\n                # Locate property name line\n                loc = propComment.find(\"HMNAME PROP\")\n                compLine = propComment[loc:]\n                # The component name is between double quotes\n                propName = compLine.split('\"')[1]\n                self.compDescripts.append(propName)\n            # Patran format\n            elif \"$ Elements and Element Properties for region\" in propComment:\n                # The component name is after the colon\n                propName = propComment.split(\":\")[1]\n                self.compDescripts.append(propName)\n\n            # No format, default component name\n            else:\n                self.compDescripts.append(f\"Property group {pID}\")\n\n        # Element connectivity information\n        self.elemConnectivity = [None] * self.bdfInfo.nelements\n        self.elemConnectivityPointer = [None] * (self.bdfInfo.nelements + 1)\n        self.elemConnectivityPointer[0] = 0\n        elementObjectCounter = 0\n        # List specifying which tacs element object each element in bdf should point to\n        self.elemObjectNumByElem = [None] * (self.bdfInfo.nelements)\n\n        # Loop through every element and record information needed for tacs\n        for tacsElementID, nastranElementID in enumerate(self.bdfInfo.element_ids):\n            element = self.bdfInfo.elements[nastranElementID]\n            elementType = element.type.upper()\n            propertyID = element.pid\n            componentID = self.idMap(propertyID, self.nastranToTACSCompIDDict)\n\n            # This element type has not been added to the list for the component group yet, so we append it\n            if elementType not in self.elemDescripts[componentID]:\n                self.elemDescripts[componentID].append(elementType)\n                self.elemObjectNumByComp[componentID].append(elementObjectCounter)\n                elementObjectCounter += 1\n\n            # Find the index number corresponding to the element object number for this component\n            componentTypeIndex = self.elemDescripts[componentID].index(elementType)\n            self.elemObjectNumByElem[tacsElementID] = self.elemObjectNumByComp[\n                componentID\n            ][componentTypeIndex]\n\n            # We've identified a ICEM property label\n            if \"Shell element data for family\" in element.comment:\n                componentName = element.comment.split()[-1]\n                self.compDescripts[componentID] = componentName\n\n            conn = element.nodes.copy()\n\n            # TACS has a different node ordering than Nastran for certain elements,\n            # we now perform the reordering (if necessary)\n            if elementType in [\"CQUAD4\", \"CQUADR\"]:\n                conn = [conn[0], conn[1], conn[3], conn[2]]\n            elif elementType in [\"CQUAD9\", \"CQUAD\"]:\n                conn = [\n                    conn[0],\n                    conn[4],\n                    conn[1],\n                    conn[7],\n                    conn[8],\n                    conn[5],\n                    conn[3],\n                    conn[6],\n                    conn[2],\n                ]\n            elif elementType in [\"CHEXA8\", \"CHEXA\"]:\n                conn = [\n                    conn[0],\n                    conn[1],\n                    conn[3],\n                    conn[2],\n                    conn[4],\n                    conn[5],\n                    conn[7],\n                    conn[6],\n                ]\n\n            # Map node ids in connectivity from Nastran numbering to TACS numbering\n            self.elemConnectivity[tacsElementID] = self.idMap(\n                conn, self.nastranToTACSNodeIDDict\n            )\n            self.elemConnectivityPointer[\n                tacsElementID + 1\n            ] = self.elemConnectivityPointer[tacsElementID] + len(element.nodes)\n\n        # Allocate list for user-specified tacs element objects\n        self.elemObjects = [None] * elementObjectCounter\n\n        # Total number of nodes used to hold lagrange multiplier variables\n        self.numMultiplierNodes = 0\n        # List to hold ID numbers (TACS ordering) of multiplier nodes added to the problem later\n        self.multiplierNodeIDs = []",
  "def _updateNastranToTACSDicts(self):\n        \"\"\"\n        Create dictionaries responsible for mapping over\n        global node, global element, and property/component ID numbers\n        from NASTRAN (as read in from BDF) to TACS (contiguous, 0-based).\n        The keys of each dictionary are the NASTRAN ID and the entry the TACS ID,\n        such that:\n            tacsNodeID = self.nastranToTACSNodeIDDict[nastranNodeID]\n            tacsComponentID = self.nastranToTACSCompIDDict[nastranPropertyID]\n            tacsElementID = self.nastranToTACSNodeIDDict[nastranElementID]\n        The dictionaries contain all elements/nodes found in the BDF,\n        not just those *owned* by this processor\n        \"\"\"\n        # Create Node ID map\n        nastranIDs = self.bdfInfo.node_ids\n        tacsIDs = range(self.bdfInfo.nnodes)\n        nodeTuple = zip(nastranIDs, tacsIDs)\n        self.nastranToTACSNodeIDDict = dict(nodeTuple)\n\n        # Create Property/Component ID map\n        nastranIDs = self.bdfInfo.property_ids\n        tacsIDs = range(self.bdfInfo.nproperties)\n        propTuple = zip(nastranIDs, tacsIDs)\n        self.nastranToTACSCompIDDict = dict(propTuple)\n\n        # Create Element ID map\n        nastranIDs = self.bdfInfo.element_ids\n        tacsIDs = range(self.bdfInfo.nelements)\n        elemTuple = zip(nastranIDs, tacsIDs)\n        self.nastranToTACSElemIDDict = dict(elemTuple)",
  "def getBDFInfo(self):\n        \"\"\"\n        Return pynastran bdf object.\n\n        Returns\n        -------\n        bdfInfo : pyNastran.bdf.bdf.BDF\n            pyNastran bdf object.\n        \"\"\"\n        return self.bdfInfo",
  "def getNumComponents(self):\n        \"\"\"\n        Return number of components (properties) found in bdf.\n\n        Returns\n        -------\n        nComps : int\n            Number of components (properties) found in bdf file.\n        \"\"\"\n        return self.bdfInfo.nproperties",
  "def getNumBDFNodes(self):\n        \"\"\"\n        Return number of nodes found in bdf.\n\n        Returns\n        -------\n        nNodes : int\n            Number of nodes found in bdf file.\n        \"\"\"\n        return self.bdfInfo.nnodes",
  "def getNumOwnedNodes(self):\n        \"\"\"\n        Return number of nodes owned by this processor.\n\n        Returns\n        -------\n        nNodes : int\n            Number of nodes owned by this proc.\n        \"\"\"\n        return self.assembler.getNumOwnedNodes()",
  "def getNumBDFElements(self):\n        \"\"\"\n        Return number of elements found in bdf.\n\n        Returns\n        -------\n        nElems : int\n            Number of elements found in bdf file.\n        \"\"\"\n        return self.bdfInfo.nelements",
  "def getBDFNodes(self, nodeIDs, nastranOrdering=False):\n        \"\"\"\n        Return x,y,z location of specified node in bdf file.\n\n        Returns\n        -------\n        xyz : numpy.ndarray\n            Coordinates of specified nodes.\n        \"\"\"\n        # Convert to tacs numbering, if necessary\n        if nastranOrdering:\n            nodeIDs = self.idMap(nodeIDs, self.nastranToTACSNodeIDDict)\n        return self.bdfXpts[nodeIDs]",
  "def getElementComponents(self):\n        \"\"\"\n        Get a list specifying the component ID of each element.\n\n        Returns\n        -------\n        compIDList : list[int]\n            List containing componentID of each element found in the bdf file.\n        \"\"\"\n        elements = self.bdfInfo.elements\n        propertyIDList = [elements[eID].pid for eID in self.bdfInfo.element_ids]\n        compIDList = self.idMap(propertyIDList, self.nastranToTACSCompIDDict)\n        return compIDList",
  "def getConnectivityForComp(self, componentID, nastranOrdering=False):\n        \"\"\"\n        Get a nodal connectivities of each element belonging to the specified component.\n\n        Parameters\n        ----------\n        componentID : int\n            Component ID number.\n\n        nastranOrdering : bool\n            Flag signaling whether nodeIDs should be returned in TACS (default) or NASTRAN (grid IDs in bdf file) ordering\n            Defaults to False.\n\n        Returns\n        -------\n        elemConns : list[list[int]]\n            List of nodal connectivities of each element belonging to this component.\n        \"\"\"\n        # Find all of the element IDs belonging to this property group\n        propertyID = list(self.bdfInfo.property_ids)[componentID]\n        elementIDs = self.propertyIDToElementIDDict[propertyID]\n        compConn = []\n        for elementID in elementIDs:\n            # We've now got the connectivity for this element, but it is in nastrans node numbering\n            nastranConn = self.bdfInfo.elements[elementID].nodes\n            if nastranOrdering:\n                compConn.append(nastranConn)\n            else:\n                # Convert Nastran node numbering back to tacs numbering\n                tacsConn = self.idMap(nastranConn, self.nastranToTACSNodeIDDict)\n                # Append element connectivity to list for component\n                compConn.append(tacsConn)\n        return compConn",
  "def getElementObjectNumsForComp(self, componentID):\n        \"\"\"\n        Return tacs element object number for each element type\n        belonging to this component.\n\n        Parameters\n        ----------\n        componentID : int\n            Component ID number.\n\n        Returns\n        -------\n        objNums : list[int]\n            List holding element object nums for the specifed component.\n        \"\"\"\n        return self.elemObjectNumByComp[componentID][:]",
  "def getElementDescripts(self):\n        \"\"\"\n        Get nested list containing all element types owned by each component group\n        example: [['CQUAD4', 'CTRIA3], ['CQUAD4'], ['CQUAD4', CQUAD9']]\n\n        Returns\n        -------\n        elemDescripts : list[list[str]]\n            Nested list holding all element types owned by each component group.\n        \"\"\"\n        return self.elemDescripts",
  "def getComponentDescripts(self):\n        \"\"\"\n        Get user-defined labels for each component read in from the BDF.\n\n        Returns\n        -------\n        compDescripts : list[str]\n            List holding description strings for each component.\n        \"\"\"\n        return self.compDescripts",
  "def getLocalNodeIDsFromGlobal(self, globalIDs, nastranOrdering=False):\n        \"\"\"\n        Given a list of node IDs in global (non-partitioned) ordering\n        returns the local (partitioned) node IDs on each processor.\n        If a requested node is not included on this processor,\n        an entry of -1 will be returned.\n\n        Parameters\n        ----------\n        globalIDs : int or list[int]\n            List of global node IDs.\n\n        nastranOrdering : bool\n            Flag signaling whether globalIDs is in TACS (default) or NASTRAN (grid IDs in bdf file) ordering\n            Defaults to False.\n\n        Returns\n        -------\n        localIDs : list[int]\n            List of local node IDs for each entry in globalIDs.\n            If the node is not owned by this processor, its index is filled with a value of -1.\n        \"\"\"\n        # Convert to tacs node numbering, if necessary\n        if nastranOrdering:\n            globalIDs = self.idMap(globalIDs, self.nastranToTACSNodeIDDict)\n\n        # Ensure input is list-like\n        globalIDs = np.atleast_1d(globalIDs)\n\n        # Get the node id offset for this processor\n        OwnerRange = self.assembler.getOwnerRange()\n        nodeOffset = OwnerRange[self.comm.rank]\n\n        # Get the local ID numbers for this proc\n        tacsLocalIDs = []\n        for gID in globalIDs:\n            lIDs = self.creator.getAssemblerNodeNums(\n                self.assembler, np.array([gID], dtype=np.intc)\n            )\n            # Node was not found on this proc, return -1\n            if len(lIDs) == 0:\n                tacsLocalIDs.append(-1)\n            # Node was found on this proc, shift by nodeOffset to get local index for node\n            else:\n                tacsLocalIDs.append(lIDs[0] - nodeOffset)\n\n        return tacsLocalIDs",
  "def getLocalElementIDsFromGlobal(self, globalIDs, nastranOrdering=False):\n        \"\"\"\n        Given a list of element IDs in global (non-partitioned) ordering\n        returns the local (partitioned) element IDs on each processor.\n        If a requested element is not included on this processor,\n        an entry of -1 will be returned.\n\n        Parameters\n        ----------\n        globalIDs : int or list[int]\n            List of global element IDs.\n\n        nastranOrdering : bool\n            Flag signaling whether globalIDs is in TACS (default) or NASTRAN (element IDs in bdf file) ordering\n            Defaults to False.\n\n        Returns\n        -------\n        localIDs : list[int]\n            List of local element IDs for each entry in globalIDs.\n            If the element is not owned by this processor, its index is filled with a value of -1.\n        \"\"\"\n        # Convert to tacs node numbering, if necessary\n        if nastranOrdering:\n            globalIDs = self.idMap(globalIDs, self.nastranToTACSElemIDDict)\n\n        # Ensure input is list-like\n        globalIDs = np.atleast_1d(globalIDs)\n\n        # Get the local ID numbers for this proc\n        tacsLocalIDs = []\n        for gID in globalIDs:\n            # element was found on this proc, get local ID num\n            if gID in self.globalToLocalElementIDDict:\n                lID = self.globalToLocalElementIDDict[gID]\n            # element was not found on this proc, return -1\n            else:\n                lID = -1\n            tacsLocalIDs.append(lID)\n\n        return tacsLocalIDs",
  "def getGlobalNodeIDsForComps(self, componentIDs, nastranOrdering=False):\n        \"\"\"\n        Return the global (non-partitioned) node IDs belonging to a given list of component IDs\n\n        Parameters\n        ----------\n        componentIDs : int or list[int]\n            List of integers of the compIDs numbers.\n\n        nastranOrdering : bool\n            Flag signaling whether nodeIDs should be returned in TACS (default) or NASTRAN (grid IDs in bdf file) ordering\n            Defaults to False.\n\n        Returns\n        -------\n        nodeIDs : list[int]\n            List of unique nodeIDs that belong to the given list of compIDs\n        \"\"\"\n        # First determine the actual physical locations\n        # of the nodes we want to add forces\n        # to. Only the root rank need do this:\n        uniqueNodes = None\n        if self.comm.rank == 0:\n            allNodes = []\n            componentIDs = self._flatten(componentIDs)\n            componentIDs = set(componentIDs)\n            for cID in componentIDs:\n                tmp = self.getConnectivityForComp(cID, nastranOrdering=nastranOrdering)\n                allNodes.extend(self._flatten(tmp))\n\n            # Now just unique all the nodes:\n            uniqueNodes = np.unique(allNodes)\n\n        uniqueNodes = self.comm.bcast(uniqueNodes, root=0)\n\n        return list(uniqueNodes)",
  "def getLocalNodeIDsForComps(self, componentIDs):\n        \"\"\"\n        return the local (partitioned) node IDs belonging to a given list of component IDs\n\n        Parameters\n        ----------\n        componentIDs : int or list[int]\n            List of integers of the compIDs numbers.\n\n        Returns\n        -------\n        nodeIDs : list[int]\n            List of unique nodeIDs that belong to the given list of compIDs\n        \"\"\"\n        # Get the global nodes for this component (TACS ordering)\n        globalNodeIDs = self.getGlobalNodeIDsForComps(\n            componentIDs, nastranOrdering=False\n        )\n\n        # get the corresponding local IDs on each proc\n        localNodeIDs = self.getLocalNodeIDsFromGlobal(globalNodeIDs, nastranOrdering=False)\n        # If the returned index is > 0 then it is owned by this proc, otherwise remove it\n        localNodeIDs = [localID for localID in localNodeIDs if localID >= 0]\n\n        return localNodeIDs",
  "def getGlobalElementIDsForComps(self, componentIDs, nastranOrdering=False):\n        \"\"\"\n        Returns a list of element IDs belonging to specified components\n\n        Parameters\n        ----------\n        componentIDs : list[int]\n            Component ID numbers.\n\n        nastranOrdering : bool\n            Flag signaling whether elemIDs should be returned in TACS (default) or NASTRAN (grid IDs in bdf file) ordering\n            Defaults to False\n\n        Returns\n        -------\n        elemIDs : list[int]\n            List of global element IDs belonging to the specified components.\n        \"\"\"\n        # Make sure list is flat\n        componentIDs = self._flatten(componentIDs)\n        # Convert tacs component IDs to nastran property IDs\n        propertyIDs = [0] * len(componentIDs)\n        for i, componentID in enumerate(componentIDs):\n            propertyIDs[i] = list(self.bdfInfo.property_ids)[componentID]\n        # Get dictionary whose values are the element ids we are looking for\n        elementIDDict = self.bdfInfo.get_element_ids_dict_with_pids(propertyIDs)\n        # Convert to list\n        elementIDs = list(elementIDDict.values())\n        # Make sure list is flat\n        elementIDs = self._flatten(elementIDs)\n        # Convert to tacs element numbering, if necessary\n        if not nastranOrdering:\n            elementIDs = self.idMap(elementIDs, self.nastranToTACSElemIDDict)\n        return elementIDs",
  "def getLocalElementIDsForComps(self, componentIDs):\n        \"\"\"\n        Get the local element numbers on each proc used by tacs\n        corresponding to the component groups in componentIDs.\n\n        Parameters\n        ----------\n        componentIDs : list[int]\n            Component ID numbers.\n\n        Returns\n        -------\n        elemIDs : list[int]\n            List of local element IDs on this proc belonging to the specified components.\n        \"\"\"\n        if self.creator is None:\n            raise self._TACSError(\n                \"TACS assembler has not been created. \"\n                \"Assembler must created first by running 'createTACS' method.\"\n            )\n        # Make sure list is flat\n        componentIDs = self._flatten(componentIDs)\n        # Get the element object IDs belonging to each of these components\n        objIDs = []\n        for componentID in componentIDs:\n            tmp = self.getElementObjectNumsForComp(componentID)\n            objIDs.extend(tmp)\n        objIDs = np.array(objIDs, dtype=np.intc)\n        # Get the local element IDs corresponding to the object IDs on this processor (if any)\n        localElemIDs = self.creator.getElementIdNums(objIDs)\n        return list(localElemIDs)",
  "def getLocalMultiplierNodeIDs(self):\n        \"\"\"\n        Get the tacs indices of multiplier nodes used to hold lagrange multipliers on this processor.\n\n        Returns\n        -------\n        nodeIDs : list[int]\n            List of multiplier node ID's owned by this proc.\n        \"\"\"\n        return self.ownedMultiplierNodeIDs",
  "def getGlobalToLocalNodeIDDict(self):\n        \"\"\"\n        Creates a dictionary who's keys correspond to the global ID of each node (tacs ordering)\n        owned by this processor and whose values correspond to the local node index for this proc.\n        The dictionary can be used to convert from a global node ID to local using the assignment below*:\n        localNodeID = globalToLocalNodeIDDict[globalNodeID]\n\n        * assuming globalNodeID is owned on this processor\n\n        Returns\n        -------\n        globalToLocalNodeIDDict : dict[int,int]\n            Dictionary holding mapping from global to local node IDs for this proc\n        \"\"\"\n        globalToLocalNodeIDDict = {}\n        for tacsNodeID in range(self.bdfInfo.nnodes):\n            # Get the local ID corresponding to the global ID (if owned by this proc)\n            lID = self.getLocalNodeIDsFromGlobal(tacsNodeID, nastranOrdering=False)[0]\n            # Add the local node ID to the dict if its owned by this proc\n            if lID >= 0:\n                globalToLocalNodeIDDict[tacsNodeID] = lID\n\n        return globalToLocalNodeIDDict",
  "def getGlobalToLocalElementIDDict(self):\n        \"\"\"\n        Creates a dictionary who's keys correspond to the global ID of each element (tacs ordering)\n        owned by this processor and whose values correspond to the local element index for this proc.\n        The dictionary can be used to convert from a global element ID to local using the assignment below*:\n        localElementID = globalToLocalElementIDDict[globalElementID]\n\n        * assuming globalElementID is owned on this processor\n\n        Returns\n        -------\n        globalToLocalElementIDDict : dict[int,int]\n            Dictionary holding mapping from global to local element IDs for this proc\n        \"\"\"\n        # Do sorting on root proc\n        if self.comm.rank == 0:\n            # List containing which poc every element belongs to\n            elemPartition = self.creator.getElementPartition()\n            # Create an empty list that we will use to sort what elements are on what procs\n            allOwnedElementIDs = [[] for proc_i in range(self.comm.size)]\n            for elemGlobalID in range(len(elemPartition)):\n                ownerProc = elemPartition[elemGlobalID]\n                allOwnedElementIDs[ownerProc].append(elemGlobalID)\n        else:\n            allOwnedElementIDs = None\n\n        # Scatter the list from the root so each proc knows what element ID it owns\n        ownedElementIDs = self.comm.scatter(allOwnedElementIDs, root=0)\n        # Create dictionary that gives the corresponding local ID for each global ID owned by this proc\n        globalToLocalElementIDDict = {\n            gID: lID for lID, gID in enumerate(ownedElementIDs)\n        }\n\n        return globalToLocalElementIDDict",
  "def getElementObject(self, componentID, objectIndex):\n        \"\"\"\n        Return TACS element object corresponding to component ID and object index.\n\n        Parameters\n        ----------\n        componentID : int\n            Component ID number\n\n        objectIndex : int\n            Object index number.\n            Some components may have multiple TACS element types associated with them.\n            This index specifies which object should be returned.\n\n        Returns\n        -------\n        elemObj : tacs.TACS.Element\n            TACS element object.\n        \"\"\"\n        pointer = self.elemObjectNumByComp[componentID][objectIndex]\n        return self.elemObjects[pointer]",
  "def setElementObject(self, componentID, objectIndex, elemObject):\n        \"\"\"\n        Set TACS element object to component ID and object index.\n\n        Parameters\n        ----------\n        componentID : int\n            Component ID number\n\n        objectIndex : int\n            Object index number.\n            Some components may have multiple TACS element types associated with them.\n            This index specifies which object should be assigned.\n\n        elemObject : tacs.TACS.Element\n            TACS element object.\n        \"\"\"\n        pointer = self.elemObjectNumByComp[componentID][objectIndex]\n        self.elemObjects[pointer] = elemObject",
  "def getElementObjectForElemID(self, elemID, nastranOrdering=False):\n        \"\"\"\n        Return TACS element object corresponding to specified element ID.\n\n        Parameters\n        ----------\n        elemID : int\n            Element ID number\n\n        nastranOrdering : bool\n            Flag signaling whether elemIDs are in TACS (default) or NASTRAN (grid IDs in bdf file) ordering\n            Defaults to False.\n\n        Returns\n        -------\n        elemObj : tacs.TACS.Element\n            TACS element object.\n        \"\"\"\n        # Convert to tacs numbering, if necessary\n        if nastranOrdering:\n            elemID = self.idMap(elemID, self.nastranToTACSElemIDDict)\n        # Get the pointer for the tacs element object for this element\n        elemObjNum = self.elemObjectNumByElem[elemID]\n        elemObj = self.elemObjects[elemObjNum]\n        return elemObj",
  "def createTACSAssembler(self, varsPerNode, massDVs):\n        \"\"\"\n        Setup TACSCreator object responsible for creating TACSAssembler\n\n        Parameters\n        ----------\n        varsPerNode : int\n            Number of variables per node for the model.\n\n        massDVs : dict\n            Dictionary holding dv info for point masses.\n        \"\"\"\n        self.creator = tacs.TACS.Creator(self.comm, varsPerNode)\n\n        # Append RBE elements to element list, these are not setup by the user\n        for rbe in self.bdfInfo.rigid_elements.values():\n            if rbe.type == \"RBE2\":\n                self._addTACSRBE2(rbe, varsPerNode)\n            elif rbe.type == \"RBE3\":\n                self._addTACSRBE3(rbe, varsPerNode)\n            else:\n                raise NotImplementedError(\n                    f\"Rigid element of type '{rbe.type}' is not supported\"\n                )\n\n        # Append point mass elements to element list, these are not setup by the user\n        for massInfo in self.bdfInfo.masses.values():\n            # Find the dv dict for this mass element, if not found return empty\n            dvDict = massDVs.get(massInfo.eid, {})\n            self._addTACSMassElement(massInfo, varsPerNode, dvDict)\n\n        # Check for any nodes that aren't attached to at least one element\n        self._unattachedNodeCheck()\n\n        # Setup element connectivity and boundary condition info on root processor\n        if self.comm.rank == 0:\n            # Set connectivity for all elements\n            ptr = np.array(self.elemConnectivityPointer, dtype=np.intc)\n            # Flatten nested connectivity list to single list\n            conn = it.chain.from_iterable(self.elemConnectivity)\n            conn = np.array([*conn], dtype=np.intc)\n            objectNums = np.array(self.elemObjectNumByElem, dtype=np.intc)\n            self.creator.setGlobalConnectivity(\n                self.bdfInfo.nnodes, ptr, conn, objectNums\n            )\n\n            # Set up the boundary conditions\n            bcDict = {}\n            for spc_id in self.bdfInfo.spcs:\n                for spc in self.bdfInfo.spcs[spc_id]:\n                    # Loop through every node specifed in this spc and record bc info\n                    for j, nastranNode in enumerate(spc.nodes):\n                        # If constrained node doesn't exist in bdf\n                        if nastranNode not in self.bdfInfo.node_ids:\n                            self._TACSWarning(\n                                f\"Node ID {nastranNode} (Nastran ordering) is referenced by an SPC,  \"\n                                \"but the node was not defined in the BDF file. Skipping SPC.\"\n                            )\n                            continue\n\n                        # Convert to TACS node ID\n                        tacsNode = self.idMap(nastranNode, self.nastranToTACSNodeIDDict)\n\n                        # If node hasn't been added to bc dict yet, add it\n                        if tacsNode not in bcDict:\n                            bcDict[tacsNode] = {}\n\n                        # Loop through each dof and record bc info if it is included in this spc\n                        for dof in range(varsPerNode):\n                            # Add 1 to get nastran dof number\n                            nastranDOF = dof + 1\n                            if spc.type == \"SPC\":\n                                # each node may have its own dofs uniquely constrained\n                                constrainedDOFs = spc.components[j]\n                                # The boundary condition may be forced to a non-zero value\n                                constrainedVal = spc.enforced[j]\n                            else:  # SPC1?\n                                # All nodes always have the same dofs constrained\n                                constrainedDOFs = spc.components\n                                # This boundary condition is always 0\n                                constrainedVal = 0.0\n                            # if nastran dof is in spc components string, add it to the bc dict\n                            if self._isDOFInString(constrainedDOFs, nastranDOF):\n                                bcDict[tacsNode][dof] = constrainedVal\n\n            # Convert bc information from dict to list\n            bcnodes = []\n            bcdofs = []\n            bcptr = [0]\n            bcvals = []\n            numbcs = 0\n            for tacsNode in bcDict:\n                bcnodes.append(tacsNode)\n                # Store constrained dofs for this node\n                dofs = bcDict[tacsNode].keys()\n                bcdofs.extend(dofs)\n                # Store enforced bc value\n                vals = bcDict[tacsNode].values()\n                bcvals.extend(vals)\n                # Increment bc pointer with how many constraints weve added for this node\n                numbcs += len(bcDict[tacsNode])\n                bcptr.append(numbcs)\n\n            # Recast lists as numpy arrays\n            bcnodes = np.array(bcnodes, dtype=np.intc)\n            bcdofs = np.array(bcdofs, dtype=np.intc)\n            bcptr = np.array(bcptr, dtype=np.intc)\n            bcvals = np.array(bcvals, dtype=self.dtype)\n            # Set boundary conditions in tacs\n            self.creator.setBoundaryConditions(bcnodes, bcptr, bcdofs, bcvals)\n\n            # Set node locations\n            Xpts = self.bdfInfo.get_xyz_in_coord(fdtype=self.dtype, sort_ids=False)\n            self.creator.setNodes(Xpts.flatten())\n\n        # Set the elements for each component\n        self.creator.setElements(self.elemObjects)\n\n        self.assembler = self.creator.createTACS()\n\n        self.globalToLocalElementIDDict = self.getGlobalToLocalElementIDDict()\n\n        # If any multiplier nodes were added, record their local processor indices\n        localIDs = self.getLocalNodeIDsFromGlobal(\n            self.multiplierNodeIDs, nastranOrdering=False\n        )\n        self.ownedMultiplierNodeIDs = [localID for localID in localIDs if localID >= 0]\n\n        return self.assembler",
  "def _isDOFInString(self, constrained_dofs, dof):\n        \"\"\"\n        Determine if dof number (nastran numbering) occurs in constraint string.\n\n        Parameters\n        ----------\n        constrained_dofs : string\n            String containing list of dofs (ex. '123456')\n\n        dof : int or string\n            nastran dof number to check for\n\n        Returns\n        -------\n        found : bool\n            Flag indicating if specified dof is in string.\n        \"\"\"\n        # Convert to string, if necessary\n        if isinstance(dof, int):\n            dof = \"%d\" % dof\n        # pyNastran only supports 0,1,2,3,4,5,6 as valid dof components\n        # For this reason, we'll treat 0 as if its 7, since it's traditionally never used in nastran\n        if dof == \"7\":\n            dof = \"0\"\n        location = constrained_dofs.find(dof)\n        # if dof is found, return true\n        if location > -1:\n            return True\n        else:\n            return False",
  "def _addTACSRBE2(self, rbeInfo, varsPerNode):\n        \"\"\"\n        Method to automatically set up RBE2 element from bdf file for user.\n        User should *NOT* set these up in their elemCallBack function.\n\n        Parameters\n        ----------\n        rbeInfo : pyNastran.bdf.cards.elements.rigid.RBE2\n            pyNastran object holding rbe info.\n\n        varsPerNode : int\n            Number of variables per node for the model.\n        \"\"\"\n        indepNode = rbeInfo.independent_nodes\n        depNodes = []\n        depConstrainedDOFs = []\n        dummyNodes = []\n        dofsAsString = rbeInfo.cm\n        dofsAsList = self.dofStringToList(dofsAsString, varsPerNode)\n        for node in rbeInfo.dependent_nodes:\n            depNodes.append(node)\n            depConstrainedDOFs.extend(dofsAsList)\n            # add dummy nodes for all lagrange multiplier\n            dummyNodeNum = (\n                max(self.bdfInfo.node_ids) + 1\n            )  # Next available nastran node number\n            # Add the dummy node coincident to the dependent node in x,y,z\n            self.bdfInfo.add_grid(dummyNodeNum, self.bdfInfo.nodes[node].xyz)\n            # Update Nastran to TACS ID mapping dicts, since we just added new nodes to model\n            self.nastranToTACSNodeIDDict[dummyNodeNum] = self.bdfInfo.nnodes - 1\n            dummyNodes.append(dummyNodeNum)\n\n        conn = indepNode + depNodes + dummyNodes\n        nTotalNodes = len(conn)\n        # Add dummy nodes to lagrange multiplier node list\n        self.numMultiplierNodes += len(dummyNodes)\n        tacsIDs = self.idMap(dummyNodes, self.nastranToTACSNodeIDDict)\n        self.multiplierNodeIDs.extend(tacsIDs)\n        # Append RBE information to the end of the element lists\n        self.elemConnectivity.append(self.idMap(conn, self.nastranToTACSNodeIDDict))\n        self.elemConnectivityPointer.append(\n            self.elemConnectivityPointer[-1] + nTotalNodes\n        )\n        rbeObj = tacs.elements.RBE2(\n            nTotalNodes, np.array(depConstrainedDOFs, dtype=np.intc)\n        )\n        self.elemObjectNumByElem.append(len(self.elemObjects))\n        self.elemObjects.append(rbeObj)\n        return",
  "def _addTACSRBE3(self, rbeInfo, varsPerNode):\n        \"\"\"\n        Method to automatically set up RBE3 element from bdf file for user.\n        User should *NOT* set these up in their elemCallBack function.\n\n        Parameters\n        ----------\n        rbeInfo : pyNastran.bdf.cards.elements.rigid.RBE3\n            pyNastran object holding rbe info.\n\n        varsPerNode : int\n            Number of variables per node for the model.\n        \"\"\"\n        depNode = rbeInfo.dependent_nodes\n        depConstrainedDOFs = self.dofStringToList(rbeInfo.refc, varsPerNode)\n\n        # add dummy node for lagrange multipliers\n        dummyNodeNum = max(self.bdfInfo.node_ids) + 1  # Next available node number\n        # Add the dummy node coincident to the dependent node in x,y,z\n        self.bdfInfo.add_grid(dummyNodeNum, self.bdfInfo.nodes[depNode[0]].xyz)\n        # Update Nastran to TACS ID mapping dicts, since we just added new nodes to model\n        self.nastranToTACSNodeIDDict[dummyNodeNum] = self.bdfInfo.nnodes - 1\n        dummyNodes = [dummyNodeNum]\n        # Add dummy node to lagrange multiplier node list\n        self.numMultiplierNodes += len(dummyNodes)\n        tacsIDs = self.idMap(dummyNodes, self.nastranToTACSNodeIDDict)\n        self.multiplierNodeIDs.extend(tacsIDs)\n\n        # Get node and rbe3 weight info\n        indepNodes = []\n        indepWeights = []\n        indepConstrainedDOFs = []\n        for depNodeGroup in rbeInfo.wt_cg_groups:\n            wt = depNodeGroup[0]\n            dofsAsString = depNodeGroup[1]\n            dofsAsList = self.dofStringToList(dofsAsString, varsPerNode)\n            for node in depNodeGroup[2]:\n                indepNodes.append(node)\n                indepWeights.append(wt)\n                indepConstrainedDOFs.extend(dofsAsList)\n\n        conn = depNode + indepNodes + dummyNodes\n        nTotalNodes = len(conn)\n        # Append RBE information to the end of the element lists\n        self.elemConnectivity.append(self.idMap(conn, self.nastranToTACSNodeIDDict))\n        self.elemConnectivityPointer.append(\n            self.elemConnectivityPointer[-1] + nTotalNodes\n        )\n        rbeObj = tacs.elements.RBE3(\n            nTotalNodes,\n            np.array(depConstrainedDOFs, dtype=np.intc),\n            np.array(indepWeights),\n            np.array(indepConstrainedDOFs, dtype=np.intc),\n        )\n        self.elemObjectNumByElem.append(len(self.elemObjects))\n        self.elemObjects.append(rbeObj)\n        return",
  "def _addTACSMassElement(self, massInfo, varsPerNode, dvDict):\n        \"\"\"\n        Method to automatically set up TACS mass elements from bdf file for user.\n        User should *NOT* set these up in their elemCallBack function.\n\n        Parameters\n        ----------\n        massInfo : pyNastran.bdf.cards.elements.mass.PointMassElement\n            pyNastran object holding rbe info.\n\n        varsPerNode : int\n            Number of variables per node for the model.\n\n        dvDict : dict\n            Dictionary holding dv info for point mass.\n        \"\"\"\n        if massInfo.type == \"CONM2\":\n            m = massInfo.mass\n            I11, I12, I22, I13, I23, I33 = massInfo.I\n            # Create dict with input args for PointMassConstitutive\n            massArgs = {\n                \"m\": m,\n                \"I11\": I11,\n                \"I22\": I22,\n                \"I33\": I33,\n                \"I12\": I12,\n                \"I13\": I13,\n                \"I23\": I23,\n            }\n            # Update mass arguments with user-defined dv info\n            massArgs.update(dvDict)\n            con = tacs.constitutive.PointMassConstitutive(**massArgs)\n        elif massInfo.type == \"CONM1\":\n            M = np.zeros(21)\n            M[0:6] = massInfo.mass_matrix[0:, 0]\n            M[6:11] = massInfo.mass_matrix[1:, 1]\n            M[11:15] = massInfo.mass_matrix[2:, 2]\n            M[15:18] = massInfo.mass_matrix[3:, 3]\n            M[18:20] = massInfo.mass_matrix[4:, 4]\n            M[20] = massInfo.mass_matrix[5, 5]\n            # off-diagonal moment of inertia terms have to be negated, since they aren't in nastran convention\n            M[16] *= -1.0\n            M[17] *= -1.0\n            M[19] *= -1.0\n            con = tacs.constitutive.GeneralMassConstitutive(M=M)\n        else:\n            raise NotImplementedError(\n                f\"Mass element of type '{massInfo.type}' is not supported\"\n            )\n\n        # Append point mass information to the end of the element lists\n        conn = [massInfo.node_ids[0]]\n        self.elemConnectivity.append(self.idMap(conn, self.nastranToTACSNodeIDDict))\n        self.elemConnectivityPointer.append(self.elemConnectivityPointer[-1] + 1)\n        # Create tacs object for mass element\n        massObj = tacs.elements.MassElement(con)\n        self.elemObjectNumByElem.append(len(self.elemObjects))\n        self.elemObjects.append(massObj)\n        return",
  "def _unattachedNodeCheck(self):\n        \"\"\"\n        Check for any nodes that aren't attached to an element.\n        Notify the user and throw an error if we find any.\n        This must be checked before creating the TACS assembler or a SegFault may occur.\n        \"\"\"\n        numUnattached = 0\n        if self.comm.rank == 0:\n            # Flatten connectivity to a single list\n            flattenedConn = it.chain.from_iterable(self.elemConnectivity)\n            # uniqueify and order all element-attached nodes\n            attachedNodes = set(flattenedConn)\n            # Loop through each node in the bdf and check if it's in the element node set\n            for nastranNodeID in self.bdfInfo.node_ids:\n                tacsNodeID = self.idMap(nastranNodeID, self.nastranToTACSNodeIDDict)\n                if tacsNodeID not in attachedNodes:\n                    if numUnattached < 100:\n                        self._TACSWarning(\n                            f\"Node ID {nastranNodeID} (Nastran ordering) is not attached to any element in the model. \"\n                            f\"Please remove this node from the mesh and try again.\"\n                        )\n                    numUnattached += 1\n\n        # Broadcast number of found unattached nodes\n        numUnattached = self.comm.bcast(numUnattached, root=0)\n        # Raise an error if any unattached nodes were found\n        if numUnattached > 0:\n            raise self._TACSError(\n                f\"{numUnattached} unattached node(s) were detected in model. \"\n                f\"Please make sure that all nodes are attached to at least one element.\"\n            )",
  "def dofStringToList(self, dofString, numDOFs):\n        \"\"\"\n        Converts a dof string to a boolean list.\n        Examples:\n            '123' -> [1, 1, 1, 0, 0, 0]\n            '1346' -> [1, 0, 1, 1, 0, 1]\n\n        Parameters\n        ----------\n        dofString : string\n            String containing list of dofs (ex. '123456')\n\n        numDOFs : int\n            Number of dofs in model\n\n        Returns\n        -------\n        dofList : list[int]\n            List of booleans indicating which dofs are present in input string.\n        \"\"\"\n        dofList = []\n        for dof in range(numDOFs):\n            dof = str(dof + 1)\n            loc = dofString.find(dof)\n            if loc > -1:\n                dofList.append(1)\n            else:\n                dofList.append(0)\n        return dofList",
  "def idMap(self, fromIDs, tacsIDDict):\n        \"\"\"\n        Translate fromIDs numbering from nastran numbering to tacs numbering.\n        If node ID doesn't exist in nastranIDList, return -1 for entry\n\n        Parameters\n        ----------\n        fromIDs : int or list[int]\n            IDs in Nastran numbering\n\n        tacsIDDict : dict[int, int]\n            ID mapping dict generated by `_updateNastranToTACSDicts`\n\n        Returns\n        -------\n        toIDs : int or list[int]\n            IDs in TACS numbering\n        \"\"\"\n        # Input is a list return a list\n        if hasattr(fromIDs, \"__iter__\"):\n            toIDs = [None] * len(fromIDs)\n            # Iterate through list and call function recursively one element at a time\n            for i, id in enumerate(fromIDs):\n                toIDs[i] = self.idMap(id, tacsIDDict)\n            return toIDs\n        # Input is a int, return an int\n        else:\n            if fromIDs in tacsIDDict:\n                return tacsIDDict[fromIDs]\n            else:\n                return -1",
  "def allLocalNodeIDs(self):\n        \"\"\"\n        get list of tacs_ids for each nastran node owned across all processors\n        nastran_node = array_idx + 1\n        tacs_idx = output id\n        nastran_node - 1 => tacs_idx owned by this proc\n        \"\"\"\n\n        self._nastranToLocalNodeIDMap()\n        local_maps = self.comm.gather(self._local_map, root=0)\n        full_map_list = []\n        for local_map in local_maps:\n            full_map_list += local_map\n        all_struct_ids = None\n        if self.comm.rank == 0:\n            all_struct_ids = np.zeros((self.bdfInfo.nnodes), dtype=int)\n            for map in full_map_list:\n                for key in map:\n                    all_struct_ids[int(key)] = map[int(key)]\n            all_struct_ids = list(all_struct_ids)\n        # broadcast to other procs\n        all_struct_ids = self.comm.bcast(all_struct_ids, root=0)\n        return all_struct_ids",
  "def _getLocalNodeIDs(self):\n        \"\"\"\n        get the local struct ids owned by this processor, full list when comm is None\n        -1 for each idx not owned by this processor\n        \"\"\"\n        num_nodes = self.bdfInfo.nnodes\n        bdf_nodes = [_ for _ in range(num_nodes)]\n        return self.getLocalNodeIDsFromGlobal(bdf_nodes, nastranOrdering=False)",
  "def _nastranToLocalNodeIDMap(self):\n        \"\"\"\n        write the map nastran_node - 1 => tacs_idx on each processor\n        \"\"\"\n        local_struct_ids = self._getLocalNodeIDs()\n        id_map = []\n        for arr_idx, struct_id in enumerate(local_struct_ids):\n            if struct_id != -1:\n                id_map.append({arr_idx: struct_id})\n        self._local_map = id_map\n        return id_map",
  "class BaseUI:\n    \"\"\"\n    Base class to be inherited by all pyTACS classes.\n    Contains common methods useful for many classes.\n    \"\"\"\n\n    defaultOptions = {}\n\n    # Set common data type for all pyTACS classes to inherit (real or complex)\n    dtype = tacs.TACS.dtype\n\n    def __init__(self, options=None, comm=None) -> None:\n        \"\"\"Setup the communicator and options for a pyTACS object\n\n        Parameters\n        ----------\n        options : dict, optional\n            Object-specific option parameters (case-insensitive), by default None\n        comm : mpi4py.MPI.Intracomm, optional\n            The comm object on which to create the pyTACS object., by default MPI.COMM_WORLD\n        \"\"\"\n        # Set the communicator and rank\n        if comm is None:\n            comm = MPI.COMM_WORLD\n        self.comm = comm\n        self.rank = comm.rank\n\n        # Process the default options which are added to self.options\n        # under the 'defaults' key. Make sure the key are lower case\n        self.options = {}\n        def_keys = self.defaultOptions.keys()\n        self.options[\"defaults\"] = {}\n        for key in def_keys:\n            self.options[\"defaults\"][key.lower()] = self.defaultOptions[key]\n            self.options[key.lower()] = self.defaultOptions[key]\n\n        # Process the user-supplied options\n        userOptions = options if options is not None else {}\n        optKeys = userOptions.keys()\n        for key in optKeys:\n            self.setOption(key, userOptions[key])\n\n    def setOption(self, name, value):\n        \"\"\"\n        Set a solver option value. The name is not case sensitive.\n\n        Parameters\n        ----------\n        name : str\n            Name of option to modify\n\n        value : depends on option\n            New option value to set\n        \"\"\"\n        name = name.lower()\n\n        # Try to the option in the option dictionary\n        defOptions = self.options[\"defaults\"]\n        try:\n            defOptions[name]\n        except KeyError:\n            self._TACSWarning(f\"'{name}' is not a valid option\")\n            return\n\n        # Now we know the option exists, lets check if the type is ok:\n        #        if type(value) == self.options[name][0]:\n        if isinstance(value, self.options[name][0]):\n            # Just set:\n            description = defOptions[name][2]\n            self.options[name] = [type(value), value, description]\n        else:\n            raise self._TACSError(\n                \"Datatype for Option %s was not valid. \"\n                \"Expected data type is %s. Received data type \"\n                \" is %s.\" % (name, self.options[name][0], type(value))\n            )\n\n    def getOption(self, name):\n        \"\"\"\n        Get a solver option value. The name is not case sensitive.\n\n        Parameters\n        ----------\n        name : str\n            Name of option to get\n        \"\"\"\n\n        # Redefine the getOption def from the base class so we can\n        # mane sure the name is lowercase\n\n        def_options = self.options[\"defaults\"]\n        if name.lower() in def_options:\n            return self.options[name.lower()][1]\n        else:\n            raise AttributeError(repr(name) + \" is not a valid option name\")\n\n    def printOptions(self):\n        \"\"\"\n        Prints a nicely formatted dictionary of all the current solver\n        options to the stdout on the root processor\n        \"\"\"\n        # Class name\n        header = type(self).__name__\n        if hasattr(self, \"name\"):\n            # Append problem name, if TACSProblem\n            header += f\" ('{self.name}')\"\n        self._pp(\"+----------------------------------------+\")\n        self._pp(\"|\" + f\"{header} options:\".center(40) + \"|\")\n        self._pp(\"+----------------------------------------+\")\n        for name in self.options:\n            if name != \"defaults\":\n                if self.options[name][0] == str:\n                    self._pp(f\"'{name}': '{self.options[name][1]}'\")\n                else:\n                    self._pp(f\"'{name}': {self.options[name][1]}\")\n                # print description\n                self._pp(f\"\\t {self.options[name][2]}\")\n\n    @classmethod\n    def printDefaultOptions(cls):\n        \"\"\"\n        Prints a nicely formatted dictionary of all the default solver\n        options to the stdout\n        \"\"\"\n        # Class name\n        header = cls.__name__\n        print(\"+----------------------------------------+\")\n        print(\"|\" + f\"{header} default options:\".center(40) + \"|\")\n        print(\"+----------------------------------------+\")\n        if hasattr(cls, \"defaultOptions\"):\n            for name in cls.defaultOptions:\n                if cls.defaultOptions[name][0] == str:\n                    print(f\"'{name}': '{cls.defaultOptions[name][1]}'\")\n                else:\n                    print(f\"'{name}': {cls.defaultOptions[name][1]}\")\n                # print description\n                print(f\"\\t {cls.defaultOptions[name][2]}\")\n\n    # ----------------------------------------------------------------------------\n    #                      Utility Functions\n    # ---------------------------------------------------------------------------\n    def _pp(self, printStr):\n        \"\"\"Simple parallel print\"\"\"\n        if self.comm.rank == 0:\n            print(printStr)\n\n    def _info(self, message, maxLen=80, box=False):\n        \"\"\"Generic function for writing an info message.\"\"\"\n\n        try:\n            printLevel = self.getOption(\"printLevel\")\n            if printLevel <= 0:\n                # Don't print out info\n                return\n        except AttributeError:\n            # printLevel option doesn't exist\n            pass\n\n        if self.comm.rank == 0:\n            # Class name\n            header = type(self).__name__\n            if hasattr(self, \"name\"):\n                # Append problem name, if TACSProblem\n                header += f\" ('{self.name}')\"\n            if not box:\n                objectInfo = f\"{header} Info: \"\n                print(objectInfo, end=\"\")\n                i = len(objectInfo) + 1\n                aux = message.split()\n                for word in aux:\n                    if len(word) + i > 120:\n                        print(\" \")\n                        print(\" \" * 6, end=\"\")\n                        i = 0\n\n                    print(word, end=\" \")\n                    i += len(word) + 1\n\n                print()\n            else:\n                print(\"+\" + \"-\" * (maxLen - 2) + \"+\")\n                objectInfo = f\"| {header} Info: \"\n                print(objectInfo, end=\"\")\n                i = len(objectInfo) + 1\n                aux = message.split()\n                for word in aux:\n                    if len(word) + i > maxLen - 2:\n                        print(\" \" * (80 - i) + \"|\")\n                        print(\"|\", end=\"\")\n                        i = 2\n                        print(word, end=\" \")\n                        i += len(word) + 1\n                    else:\n                        print(word, end=\" \")\n                        i += len(word) + 1\n\n                print(\" \" * (maxLen - i) + \"|\")\n                print(\n                    \"+\" + \"-\" * (maxLen - 2) + \"+\",\n                )\n\n    # Misc Functions\n    def _flatten(self, l, ltypes=(list, tuple)):\n        ltype = type(l)\n        l = list(l)\n        i = 0\n        while i < len(l):\n            while isinstance(l[i], ltypes):\n                if not l[i]:\n                    l.pop(i)\n                    i -= 1\n                    break\n                else:\n                    l[i : i + 1] = l[i]\n            i += 1\n        return ltype(l)\n\n    def _TACSWarning(self, message):\n        \"\"\"\n        Format a class-specific warning for message\n\n        Parameters\n        ----------\n        message : str\n            Warning message to print to user.\n        \"\"\"\n        if self.comm.rank == 0:\n            # Class name\n            header = type(self).__name__\n            if hasattr(self, \"name\"):\n                # Append problem name, if TACSProblem\n                header += f\" ('{self.name}')\"\n            msg = \"\\n+\" + \"-\" * 78 + \"+\" + \"\\n\"\n            objectWarning = f\"| {header} Warning: \"\n            msg += objectWarning\n            i = len(objectWarning) - 1\n            for word in message.split():\n                if len(word) + i + 1 > 78:  # Finish line and start new one\n                    msg += \" \" * (78 - i) + \"|\\n| \" + word + \" \"\n                    i = 1 + len(word) + 1\n                else:\n                    msg += word + \" \"\n                    i += len(word) + 1\n            msg += \" \" * (78 - i) + \"|\\n\" + \"+\" + \"-\" * 78 + \"+\" + \"\\n\"\n            print(msg)\n\n    def _TACSError(self, message):\n        \"\"\"\n        Format a class-specific error for message\n\n        Parameters\n        ----------\n        message : str\n            Error message to print to user.\n        \"\"\"\n        # Class name\n        header = type(self).__name__\n        if hasattr(self, \"name\"):\n            # Append problem name, if TACSProblem\n            header += f\" ('{self.name}')\"\n        return Error(header, message)",
  "class Error(Exception):\n    \"\"\"\n    Format the error message in a box to make it clear this\n    was an explicitly raised exception.\n    \"\"\"\n\n    def __init__(self, objName, message):\n        msg = \"\\n+\" + \"-\" * 78 + \"+\" + \"\\n\"\n        objectError = \"| %s Error: \" % (objName)\n        msg += objectError\n        i = len(objectError) - 1\n        for word in message.split():\n            if len(word) + i + 1 > 78:  # Finish line and start new one\n                msg += \" \" * (78 - i) + \"|\\n| \" + word + \" \"\n                i = 1 + len(word) + 1\n            else:\n                msg += word + \" \"\n                i += len(word) + 1\n        msg += \" \" * (78 - i) + \"|\\n\" + \"+\" + \"-\" * 78 + \"+\" + \"\\n\"\n        print(msg)\n        Exception.__init__(self)",
  "def __init__(self, options=None, comm=None) -> None:\n        \"\"\"Setup the communicator and options for a pyTACS object\n\n        Parameters\n        ----------\n        options : dict, optional\n            Object-specific option parameters (case-insensitive), by default None\n        comm : mpi4py.MPI.Intracomm, optional\n            The comm object on which to create the pyTACS object., by default MPI.COMM_WORLD\n        \"\"\"\n        # Set the communicator and rank\n        if comm is None:\n            comm = MPI.COMM_WORLD\n        self.comm = comm\n        self.rank = comm.rank\n\n        # Process the default options which are added to self.options\n        # under the 'defaults' key. Make sure the key are lower case\n        self.options = {}\n        def_keys = self.defaultOptions.keys()\n        self.options[\"defaults\"] = {}\n        for key in def_keys:\n            self.options[\"defaults\"][key.lower()] = self.defaultOptions[key]\n            self.options[key.lower()] = self.defaultOptions[key]\n\n        # Process the user-supplied options\n        userOptions = options if options is not None else {}\n        optKeys = userOptions.keys()\n        for key in optKeys:\n            self.setOption(key, userOptions[key])",
  "def setOption(self, name, value):\n        \"\"\"\n        Set a solver option value. The name is not case sensitive.\n\n        Parameters\n        ----------\n        name : str\n            Name of option to modify\n\n        value : depends on option\n            New option value to set\n        \"\"\"\n        name = name.lower()\n\n        # Try to the option in the option dictionary\n        defOptions = self.options[\"defaults\"]\n        try:\n            defOptions[name]\n        except KeyError:\n            self._TACSWarning(f\"'{name}' is not a valid option\")\n            return\n\n        # Now we know the option exists, lets check if the type is ok:\n        #        if type(value) == self.options[name][0]:\n        if isinstance(value, self.options[name][0]):\n            # Just set:\n            description = defOptions[name][2]\n            self.options[name] = [type(value), value, description]\n        else:\n            raise self._TACSError(\n                \"Datatype for Option %s was not valid. \"\n                \"Expected data type is %s. Received data type \"\n                \" is %s.\" % (name, self.options[name][0], type(value))\n            )",
  "def getOption(self, name):\n        \"\"\"\n        Get a solver option value. The name is not case sensitive.\n\n        Parameters\n        ----------\n        name : str\n            Name of option to get\n        \"\"\"\n\n        # Redefine the getOption def from the base class so we can\n        # mane sure the name is lowercase\n\n        def_options = self.options[\"defaults\"]\n        if name.lower() in def_options:\n            return self.options[name.lower()][1]\n        else:\n            raise AttributeError(repr(name) + \" is not a valid option name\")",
  "def printOptions(self):\n        \"\"\"\n        Prints a nicely formatted dictionary of all the current solver\n        options to the stdout on the root processor\n        \"\"\"\n        # Class name\n        header = type(self).__name__\n        if hasattr(self, \"name\"):\n            # Append problem name, if TACSProblem\n            header += f\" ('{self.name}')\"\n        self._pp(\"+----------------------------------------+\")\n        self._pp(\"|\" + f\"{header} options:\".center(40) + \"|\")\n        self._pp(\"+----------------------------------------+\")\n        for name in self.options:\n            if name != \"defaults\":\n                if self.options[name][0] == str:\n                    self._pp(f\"'{name}': '{self.options[name][1]}'\")\n                else:\n                    self._pp(f\"'{name}': {self.options[name][1]}\")\n                # print description\n                self._pp(f\"\\t {self.options[name][2]}\")",
  "def printDefaultOptions(cls):\n        \"\"\"\n        Prints a nicely formatted dictionary of all the default solver\n        options to the stdout\n        \"\"\"\n        # Class name\n        header = cls.__name__\n        print(\"+----------------------------------------+\")\n        print(\"|\" + f\"{header} default options:\".center(40) + \"|\")\n        print(\"+----------------------------------------+\")\n        if hasattr(cls, \"defaultOptions\"):\n            for name in cls.defaultOptions:\n                if cls.defaultOptions[name][0] == str:\n                    print(f\"'{name}': '{cls.defaultOptions[name][1]}'\")\n                else:\n                    print(f\"'{name}': {cls.defaultOptions[name][1]}\")\n                # print description\n                print(f\"\\t {cls.defaultOptions[name][2]}\")",
  "def _pp(self, printStr):\n        \"\"\"Simple parallel print\"\"\"\n        if self.comm.rank == 0:\n            print(printStr)",
  "def _info(self, message, maxLen=80, box=False):\n        \"\"\"Generic function for writing an info message.\"\"\"\n\n        try:\n            printLevel = self.getOption(\"printLevel\")\n            if printLevel <= 0:\n                # Don't print out info\n                return\n        except AttributeError:\n            # printLevel option doesn't exist\n            pass\n\n        if self.comm.rank == 0:\n            # Class name\n            header = type(self).__name__\n            if hasattr(self, \"name\"):\n                # Append problem name, if TACSProblem\n                header += f\" ('{self.name}')\"\n            if not box:\n                objectInfo = f\"{header} Info: \"\n                print(objectInfo, end=\"\")\n                i = len(objectInfo) + 1\n                aux = message.split()\n                for word in aux:\n                    if len(word) + i > 120:\n                        print(\" \")\n                        print(\" \" * 6, end=\"\")\n                        i = 0\n\n                    print(word, end=\" \")\n                    i += len(word) + 1\n\n                print()\n            else:\n                print(\"+\" + \"-\" * (maxLen - 2) + \"+\")\n                objectInfo = f\"| {header} Info: \"\n                print(objectInfo, end=\"\")\n                i = len(objectInfo) + 1\n                aux = message.split()\n                for word in aux:\n                    if len(word) + i > maxLen - 2:\n                        print(\" \" * (80 - i) + \"|\")\n                        print(\"|\", end=\"\")\n                        i = 2\n                        print(word, end=\" \")\n                        i += len(word) + 1\n                    else:\n                        print(word, end=\" \")\n                        i += len(word) + 1\n\n                print(\" \" * (maxLen - i) + \"|\")\n                print(\n                    \"+\" + \"-\" * (maxLen - 2) + \"+\",\n                )",
  "def _flatten(self, l, ltypes=(list, tuple)):\n        ltype = type(l)\n        l = list(l)\n        i = 0\n        while i < len(l):\n            while isinstance(l[i], ltypes):\n                if not l[i]:\n                    l.pop(i)\n                    i -= 1\n                    break\n                else:\n                    l[i : i + 1] = l[i]\n            i += 1\n        return ltype(l)",
  "def _TACSWarning(self, message):\n        \"\"\"\n        Format a class-specific warning for message\n\n        Parameters\n        ----------\n        message : str\n            Warning message to print to user.\n        \"\"\"\n        if self.comm.rank == 0:\n            # Class name\n            header = type(self).__name__\n            if hasattr(self, \"name\"):\n                # Append problem name, if TACSProblem\n                header += f\" ('{self.name}')\"\n            msg = \"\\n+\" + \"-\" * 78 + \"+\" + \"\\n\"\n            objectWarning = f\"| {header} Warning: \"\n            msg += objectWarning\n            i = len(objectWarning) - 1\n            for word in message.split():\n                if len(word) + i + 1 > 78:  # Finish line and start new one\n                    msg += \" \" * (78 - i) + \"|\\n| \" + word + \" \"\n                    i = 1 + len(word) + 1\n                else:\n                    msg += word + \" \"\n                    i += len(word) + 1\n            msg += \" \" * (78 - i) + \"|\\n\" + \"+\" + \"-\" * 78 + \"+\" + \"\\n\"\n            print(msg)",
  "def _TACSError(self, message):\n        \"\"\"\n        Format a class-specific error for message\n\n        Parameters\n        ----------\n        message : str\n            Error message to print to user.\n        \"\"\"\n        # Class name\n        header = type(self).__name__\n        if hasattr(self, \"name\"):\n            # Append problem name, if TACSProblem\n            header += f\" ('{self.name}')\"\n        return Error(header, message)",
  "def __init__(self, objName, message):\n        msg = \"\\n+\" + \"-\" * 78 + \"+\" + \"\\n\"\n        objectError = \"| %s Error: \" % (objName)\n        msg += objectError\n        i = len(objectError) - 1\n        for word in message.split():\n            if len(word) + i + 1 > 78:  # Finish line and start new one\n                msg += \" \" * (78 - i) + \"|\\n| \" + word + \" \"\n                i = 1 + len(word) + 1\n            else:\n                msg += word + \" \"\n                i += len(word) + 1\n        msg += \" \" * (78 - i) + \"|\\n\" + \"+\" + \"-\" * 78 + \"+\" + \"\\n\"\n        print(msg)\n        Exception.__init__(self)",
  "def get_cython_include():\n    \"\"\"\n    Get the include directory for the Cython .pxd files in TACS\n    \"\"\"\n    return [os.path.abspath(os.path.dirname(__file__))]",
  "def get_include():\n    \"\"\"\n    Get the include directory for the Cython .pxd files in TACS\n    \"\"\"\n    root_path, tail = os.path.split(os.path.abspath(os.path.dirname(__file__)))\n\n    rel_inc_dirs = [\n        \"src\",\n        \"src/bpmat\",\n        \"src/elements\",\n        \"src/elements/dynamics\",\n        \"src/elements/basis\",\n        \"src/constitutive\",\n        \"src/functions\",\n        \"src/io\",\n        \"extern/AMD/Include\",\n        \"extern/UFconfig\",\n        \"extern/metis/include\",\n    ]\n\n    inc_dirs = []\n    for path in rel_inc_dirs:\n        inc_dirs.append(os.path.join(root_path, path))\n\n    return inc_dirs",
  "def get_libraries():\n    \"\"\"\n    Get the library directories\n    \"\"\"\n    root_path, tail = os.path.split(os.path.abspath(os.path.dirname(__file__)))\n\n    rel_lib_dirs = [\"lib\"]\n    libs = [\"tacs\"]\n    lib_dirs = []\n    for path in rel_lib_dirs:\n        lib_dirs.append(os.path.join(root_path, path))\n\n    return lib_dirs, libs",
  "class TACSProblem(TACSSystem):\n    \"\"\"\n    Base class for TACS problem types. Contains methods common to all TACS problems.\n    \"\"\"\n\n    def __init__(\n        self, assembler, comm=None, options=None, outputViewer=None, meshLoader=None\n    ):\n        \"\"\"\n        Parameters\n        ----------\n        assembler : tacs.TACS.Assembler\n            Cython object responsible for creating and setting tacs objects used to solve problem\n\n        comm : mpi4py.MPI.Intracomm\n            The comm object on which to create the pyTACS object.\n\n        options : dict\n            Dictionary holding problem-specific option parameters (case-insensitive).\n\n        outputViewer : tacs.TACS.TACSToFH5\n            Cython object used to write out f5 files that can be converted and used for postprocessing.\n\n        meshLoader : tacs.pymeshloader.pyMeshLoader\n            pyMeshLoader object used to create the assembler.\n        \"\"\"\n        # Set attributes and options\n        TACSSystem.__init__(self, assembler, comm, options, outputViewer, meshLoader)\n\n        # List of functions\n        self.functionList = OrderedDict()\n\n        return\n\n    ####### Eval function methods ########\n\n    def addFunction(self, funcName, funcHandle, compIDs=None, **kwargs):\n        \"\"\"\n        Generic method to add a function for TACS. It is intended to\n        be reasonably generic since the user supplies the actual\n        function handle to use. See the :py:mod:`~tacs.functions` module\n        for supported TACS eval functions.\n\n        Parameters\n        ----------\n        funcName : str\n            The user-supplied name for the function. This will\n            typically be a string that is meaningful to the user\n\n        funcHandle : TACS.Function\n            The function handle to use for creation. This must come\n            from the functions module in tacs.\n\n        compIDs: list\n            List of compIDs to select.\n\n        **kwargs:\n            Any keyword arguments to be passed to the TACS function during setup.\n        \"\"\"\n\n        # We try to setup the function, if it fails it may not be implemented:\n        try:\n            # pass assembler an function-specific kwargs straight to tacs function\n            self.functionList[funcName] = funcHandle(self.assembler, **kwargs)\n        except:\n            self._TACSWarning(\n                f\"Function type {funcHandle} is not currently supported. \"\n                \"in pyTACS. Skipping function.\"\n            )\n            return False\n\n        # First we will get the required domain, but only if compIDs\n        # was specified. If not, just use the entire domain by default\n        if compIDs is not None:\n            # Make sure CompIDs is flat and get element numbers on each proc corresponding to specified compIDs\n            compIDs = self._flatten(compIDs)\n            elemIDs = self.meshLoader.getLocalElementIDsForComps(compIDs)\n            # Finally set the domain information\n            self.functionList[funcName].setDomain(elemIDs)\n\n        return True\n\n    def getFunctionKeys(self):\n        \"\"\"\n        Return a list of the current function key names\n\n        Returns\n        -------\n        funcNames : list[str]\n            List containing user-defined names for functions added so far.\n        \"\"\"\n        return list(self.functionList.keys())\n\n    ####### Load adding methods ########\n\n    def _addLoadToComponents(self, FVec, compIDs, F, averageLoad=False):\n        \"\"\"\n        This is an internal helper function for doing the addLoadToComponents method for\n        inherited TACSProblem classes. The function should NOT be called by the user should\n        use the addLoadToComponents method for the respective problem class. The function is\n        used to add a *FIXED TOTAL LOAD* on one or more components, defined by COMPIDs.\n        The purpose of this routine is to add loads that remain fixed throughout an optimization.\n        An example would be an engine load. This routine determines all the unqiue nodes in the\n        FE model that are part of the requested components, then takes the total 'force' by F and\n        divides by the number of nodes. This average load is then applied to the nodes.\n\n        Parameters\n        ----------\n\n        FVec : tacs.TACS.Vec\n            TACS BVec to add loads to.\n\n        compIDs : list[int] or int\n            The components with added loads. Use pyTACS.selectCompIDs method\n            to determine this.\n\n        F : numpy.ndarray 1d or 2d length (varsPerNodes) or (numCompIDs, varsPerNodes)\n            Vector(s) of 'force' to apply to each component.  If only one force vector is provided,\n            force will be copied uniformly across all components.\n\n        averageLoad : bool\n            Flag to determine whether load should be split evenly across all components (True)\n            or copied and applied individually to each component (False). Defaults to False.\n\n        Notes\n        -----\n\n        The units of the entries of the 'force' vector F are not\n        necessarily physical forces and their interpretation depends\n        on the physics problem being solved and the dofs included\n        in the model.\n\n        A couple of examples of force vector components for common problems are listed below:\n\n            In Heat Conduction with varsPerNode = 1\n                F = [Qdot] # heat rate\n            In Elasticity with varsPerNode = 3,\n                F = [fx, fy, fz] # forces\n            In Elasticity with varsPerNode = 6,\n                F = [fx, fy, fz, mx, my, mz] # forces + moments\n            In Thermoelasticity with varsPerNode = 4,\n                F = [fx, fy, fz, Qdot] # forces + heat rate\n            In Thermoelasticity with varsPerNode = 7,\n                F = [fx, fy, fz, mx, my, mz, Qdot] # forces + moments + heat rate\n        \"\"\"\n        # Make sure CompIDs are flat\n        compIDs = self._flatten([compIDs])\n\n        # Apply a unique force vector to each component\n        if not averageLoad:\n            F = np.atleast_2d(F)\n\n            # If the user only specified one force vector,\n            # we assume the force should be the same for each component\n            if F.shape[0] == 1:\n                F = np.repeat(F, [len(compIDs)], axis=0)\n            # If the dimensions still don't match, raise an error\n            elif F.shape[0] != len(compIDs):\n                raise self._TACSError(\n                    \"Number of forces must match number of compIDs,\"\n                    \" {} forces were specified for {} compIDs\".format(\n                        F.shape[0], len(compIDs)\n                    )\n                )\n\n            # Call addLoadToComponents again, once for each compID\n            for i, compID in enumerate(compIDs):\n                self._addLoadToComponents(FVec, compID, F[i], averageLoad=True)\n\n        # Average one force vector over all components\n        else:\n            F = np.atleast_1d(F)\n\n            # First determine the unique global node IDs corresponding to components:\n            uniqueNodes = self.meshLoader.getGlobalNodeIDsForComps(\n                compIDs, nastranOrdering=False\n            )\n\n            # Now generate the final average force vector\n            Favg = F / len(uniqueNodes)\n\n            self._addLoadToNodes(FVec, uniqueNodes, Favg, nastranOrdering=False)\n\n            # Write out a message of what we did:\n            self._info(\n                \"Added a fixed load of %s to %d components, \"\n                \"distributed over %d nodes.\"\n                % (repr(F), len(compIDs), len(uniqueNodes)),\n                maxLen=80,\n                box=True,\n            )\n\n    def _addLoadToNodes(self, FVec, nodeIDs, F, nastranOrdering=False):\n        \"\"\"\n        This is an internal helper function for doing the addLoadToNodes method for\n        inherited TACSProblem classes. The function should NOT be called by the user should\n        use the addLoadToNodes method for the respective problem class. The function is\n        used to add a fixed point load of F to the selected node IDs.\n\n        Parameters\n        ----------\n\n        FVec : tacs.TACS.Vec\n            TACS BVec to add loads to.\n\n        nodeIDs : list[int]\n            The nodes IDs with added loads.\n\n        F : Numpy 1d or 2d array length (varsPerNodes) or (numNodeIDs, varsPerNodes)\n            Array of force vectors, one for each node. If only one force vector is provided,\n            force will be copied uniformly across all nodes.\n\n        nastranOrdering : bool\n            Flag signaling whether nodeIDs are in TACS (default)\n            or NASTRAN (grid IDs in bdf file) ordering\n\n        Notes\n        -----\n\n        The units of the entries of the 'force' vector F are not\n        necessarily physical forces and their interpretation depends\n        on the physics problem being solved and the dofs included\n        in the model.\n\n        A couple of examples of force vector components for common problems are listed below:\n\n            In Heat Conduction with varsPerNode = 1\n                F = [Qdot] # heat rate\n            In Elasticity with varsPerNode = 3,\n                F = [fx, fy, fz] # forces\n            In Elasticity with varsPerNode = 6,\n                F = [fx, fy, fz, mx, my, mz] # forces + moments\n            In Thermoelasticity with varsPerNode = 4,\n                F = [fx, fy, fz, Qdot] # forces + heat rate\n            In Thermoelasticity with varsPerNode = 7,\n                F = [fx, fy, fz, mx, my, mz, Qdot] # forces + moments + heat rate\n        \"\"\"\n\n        # Make sure the inputs are the correct shape\n        nodeIDs = np.atleast_1d(nodeIDs)\n        F = np.atleast_2d(F)\n\n        numNodes = len(nodeIDs)\n\n        # If the user only specified one force vector,\n        # we assume the force should be the same for each node\n        if F.shape[0] == 1:\n            F = np.repeat(F, [numNodes], axis=0)\n        # If the dimensions still don't match, raise an error\n        elif F.shape[0] != numNodes:\n            raise self._TACSError(\n                \"Number of forces must match number of nodes,\"\n                \" {} forces were specified for {} node IDs\".format(F.shape[0], numNodes)\n            )\n\n        vpn = self.assembler.getVarsPerNode()\n        if len(F[0]) != vpn:\n            raise self._TACSError(\n                \"Length of force vector must match varsPerNode specified \"\n                \"for problem, which is {}, \"\n                \"but length of vector provided was {}\".format(vpn, len(F[0]))\n            )\n\n        # First find the corresponding local node ID on each processor\n        localNodeIDs = self.meshLoader.getLocalNodeIDsFromGlobal(\n            nodeIDs, nastranOrdering\n        )\n\n        # Flag to make sure we find all user-specified nodes\n        nodeFound = np.zeros(numNodes, dtype=int)\n\n        F_array = FVec.getArray()\n        nnodes = self.assembler.getNumOwnedNodes()\n        vpn = self.assembler.getVarsPerNode()\n        F_array = F_array.reshape(nnodes, vpn)\n\n        # Loop through every node and if it's owned by this processor, add the load\n        for i, nodeID in enumerate(localNodeIDs):\n            # The node was found on this proc\n            if nodeID >= 0:\n                # Add contribution to global force array\n                F_array[nodeID, :] += F[i]\n                nodeFound[i] = 1\n\n        # Reduce the node flag and make sure that every node was found on exactly 1 proc\n        nodeFound = self.comm.allreduce(nodeFound, op=MPI.SUM)\n\n        # Warn the user if any nodes weren't found\n        if nastranOrdering:\n            orderString = \"Nastran\"\n        else:\n            orderString = \"TACS\"\n\n        for i in range(numNodes):\n            if not nodeFound[i]:\n                self._TACSWarning(\n                    \"Can't add load to node ID {} ({} ordering), node not found in model. \"\n                    \"Double check BDF file.\".format(nodeIDs[i], orderString)\n                )\n\n    def _addLoadToRHS(self, Frhs, Fapplied):\n        \"\"\"\n        This is an internal helper function for doing the addLoadToRHS method for\n        inherited TACSProblem classes. The function should NOT be called by the user should\n        use the addLoadToRHS method for the respective problem class.\n        The function is used to add a *FIXED TOTAL LOAD* directly to the\n        right hand side vector given the equation below:\n\n            K*u = f\n\n        Where:\n            K : Stiffness matrix for problem\n            u : State variables for problem\n            f : Right-hand side vector to add loads to\n\n        Parameters\n        ----------\n\n        Fapplied : numpy.ndarray or tacs.TACS.Vec\n            Distributed array containing loads to applied to RHS of the problem.\n\n        \"\"\"\n        if isinstance(Fapplied, tacs.TACS.Vec):\n            Frhs.axpy(1.0, Fapplied)\n        elif isinstance(Fapplied, np.ndarray):\n            if len(Fapplied) != Frhs.getSize():\n                raise self._TACSError(\n                    \"User-supplied distributed vector not correct length, \"\n                    \"expected size of {} on processor {}, but got length {}.\".format(\n                        Frhs.getSize(), self.comm.rank, len(Fapplied)\n                    )\n                )\n            rhsArray = Frhs.getArray()\n            rhsArray[:] = rhsArray[:] + Fapplied[:]\n\n    def _addTractionToComponents(self, auxElems, compIDs, tractions, faceIndex=0):\n        \"\"\"\n        This is an internal helper function for doing the addTractionToComponents method for\n        inherited TACSProblem classes. The function should NOT be called by the user should\n        use the addTractionToComponents method for the respective problem class. The function is used\n        to add a *FIXED TOTAL TRACTION* on one or more components, defined by COMPIDs. The purpose of\n        this routine is to add loads that remain fixed throughout an optimization.\n\n        Parameters\n        ----------\n\n         auxElems : tacs.TACS.AuxElements\n            AuxElements object to add loads to.\n\n        compIDs : list[int] or int\n            The components with added loads. Use pyTACS.selectCompIDs method\n            to determine this.\n\n        tractions : numpy.ndarray\n            Array of traction vectors for each component\n\n        faceIndex : int\n            Indicates which face (side) of the element to apply traction to.\n            Note: not required for certain elements (i.e. shells)\n        \"\"\"\n        # Make sure compIDs is flat and unique\n        compIDs = set(self._flatten(compIDs))\n        tractions = np.atleast_1d(tractions)\n\n        # Get global element IDs for the elements we're applying tractions to\n        elemIDs = self.meshLoader.getGlobalElementIDsForComps(\n            compIDs, nastranOrdering=False\n        )\n        # Add tractions element by element\n        self._addTractionToElements(\n            auxElems, elemIDs, tractions, faceIndex, nastranOrdering=False\n        )\n\n        # Write out a message of what we did:\n        self._info(\n            \"Added a fixed traction of %s to %d components, \"\n            \"distributed over %d elements.\"\n            % (repr(tractions), len(compIDs), len(elemIDs)),\n            maxLen=80,\n            box=True,\n        )\n\n    def _addTractionToElements(\n        self, auxElems, elemIDs, tractions, faceIndex=0, nastranOrdering=False\n    ):\n        \"\"\"\n        This is an internal helper function for doing the addTractionToElements method for\n        inherited TACSProblem classes. The function should NOT be called by the user should\n        use the addTractionToElements method for the respective problem class. The function\n        is used to add a fixed traction to the selected element IDs. Tractions can be specified on an\n        element by element basis (if tractions is a 2d array) or set to a uniform value (if tractions is a 1d array)\n\n        Parameters\n        ----------\n\n        auxElems : tacs.TACS.AuxElements\n            AuxElements object to add loads to.\n\n        elemIDs : list[int]\n            The global element ID numbers for which to apply the traction.\n\n        tractions : Numpy 1d or 2d array length varsPerNodes or (elemIDs, varsPerNodes)\n            Array of traction vectors for each element\n\n        faceIndex : int\n            Indicates which face (side) of element to apply traction to.\n            Note: not required for certain elements (i.e. shells)\n\n        nastranOrdering : bool\n            Flag signaling whether elemIDs are in TACS (default)\n            or NASTRAN ordering\n        \"\"\"\n\n        # Make sure the inputs are the correct shape\n        elemIDs = np.atleast_1d(elemIDs)\n        tractions = np.atleast_2d(tractions).astype(dtype=self.dtype)\n\n        numElems = len(elemIDs)\n\n        # If the user only specified one traction vector,\n        # we assume the force should be the same for each element\n        if tractions.shape[0] == 1:\n            tractions = np.repeat(tractions, [numElems], axis=0)\n        # If the dimensions still don't match, raise an error\n        elif tractions.shape[0] != numElems:\n            raise self._TACSError(\n                \"Number of tractions must match number of elements,\"\n                \" {} tractions were specified for {} element IDs\".format(\n                    tractions.shape[0], numElems\n                )\n            )\n\n        # First find the corresponding local element ID on each processor\n        localElemIDs = self.meshLoader.getLocalElementIDsFromGlobal(\n            elemIDs, nastranOrdering=nastranOrdering\n        )\n\n        # Flag to make sure we find all user-specified elements\n        elemFound = np.zeros(numElems, dtype=int)\n\n        # Loop through every element and if it's owned by this processor, add the traction\n        for i, elemID in enumerate(localElemIDs):\n            # The element was found on this proc\n            if elemID >= 0:\n                # Mark element as found\n                elemFound[i] = 1\n                # Get the pointer for the tacs element object for this element\n                elemObj = self.meshLoader.getElementObjectForElemID(\n                    elemIDs[i], nastranOrdering=nastranOrdering\n                )\n                # Create an appropriate traction object for this element type\n                tracObj = elemObj.createElementTraction(faceIndex, tractions[i])\n                # Traction not implemented for this element\n                if tracObj is None:\n                    self._TACSWarning(\n                        \"TACS element of type {} does not hav a traction implementation. \"\n                        \"Skipping element in addTractionToElement procedure.\".format(\n                            elemObj.getObjectName()\n                        )\n                    )\n                # Traction implemented\n                else:\n                    # Add new traction to the auxiliary element object\n                    auxElems.addElement(elemID, tracObj)\n\n        # Reduce the element flag and make sure that every element was found on exactly 1 proc\n        elemFound = self.comm.allreduce(elemFound, op=MPI.SUM)\n\n        # Warn the user if any elements weren't found\n        if nastranOrdering:\n            orderString = \"Nastran\"\n        else:\n            orderString = \"TACS\"\n\n        for i in range(numElems):\n            if not elemFound[i]:\n                self._TACSWarning(\n                    \"Can't add traction to element ID {} ({} ordering), element not found in model. \"\n                    \"Double check BDF file.\".format(elemIDs[i], orderString)\n                )\n\n    def _addPressureToComponents(self, auxElems, compIDs, pressures, faceIndex=0):\n        \"\"\"\n        This is an internal helper function for doing the addPressureToComponents method for\n        inherited TACSProblem classes. The function should NOT be called by the user should\n        use the addPressureToComponents method for the respective problem class. The function\n        is used to add a *FIXED TOTAL PRESSURE* on one or more components, defined by COMPIds.\n        The purpose of this routine is to add loads that remain fixed throughout an optimization.\n        An example would be a fuel load.\n\n        Parameters\n        ----------\n\n        auxElems : tacs.TACS.AuxElements\n            AuxElements object to add loads to.\n\n        compIDs : list[int] or int\n            The components with added loads. Use pyTACS.selectCompIDs method\n            to determine this.\n\n        pressures : Numpy array length 1 or compIDs\n            Array of pressure values for each component\n\n        faceIndex : int\n            Indicates which face (side) of the element to apply pressure to.\n            Note: not required for certain elements (i.e. shells)\n        \"\"\"\n        # Make sure compIDs is flat and unique\n        compIDs = set(self._flatten(compIDs))\n        pressures = np.atleast_1d(pressures)\n\n        # Get global element IDs for the elements we're applying pressure to\n        elemIDs = self.meshLoader.getGlobalElementIDsForComps(\n            compIDs, nastranOrdering=False\n        )\n        # Add pressure element by element\n        self._addPressureToElements(\n            auxElems, elemIDs, pressures, faceIndex, nastranOrdering=False\n        )\n\n        # Write out a message of what we did:\n        self._info(\n            \"Added a fixed pressure of %s to %d components, \"\n            \"distributed over %d elements.\"\n            % (repr(pressures), len(compIDs), len(elemIDs)),\n            maxLen=80,\n            box=True,\n        )\n\n    def _addPressureToElements(\n        self, auxElems, elemIDs, pressures, faceIndex=0, nastranOrdering=False\n    ):\n        \"\"\"\n        This is an internal helper function for doing the addPressureToElements method for\n        inherited TACSProblem classes. The function should NOT be called by the user should\n        use the addPressureToElements method for the respective problem class. The function\n        is used to add a fixed presure to the selected element IDs. Pressures can be specified on an\n        element by element basis (if pressures is an array) or set to a uniform value (if pressures is a scalar)\n\n        Parameters\n        ----------\n\n        auxElems : tacs.TACS.AuxElements\n            AuxElements object to add loads to.\n\n        elemIDs : list[int]\n            The global element ID numbers for which to apply the pressure.\n\n        pressures : Numpy array length 1 or elemIDs\n            Array of pressure values for each element\n\n        faceIndex : int\n            Indicates which face (side) of element to apply pressure to.\n            Note: not required for certain elements (i.e. shells)\n\n        nastranOrdering : bool\n            Flag signaling whether elemIDs are in TACS (default)\n            or NASTRAN ordering\n        \"\"\"\n\n        # Make sure the inputs are the correct shape\n        elemIDs = np.atleast_1d(elemIDs)\n        pressures = np.atleast_1d(pressures)\n\n        numElems = len(elemIDs)\n\n        # If the user only specified one pressure,\n        # we assume the force should be the same for each element\n        if pressures.shape[0] == 1:\n            pressures = np.repeat(pressures, [numElems], axis=0)\n        # If the dimensions still don't match, raise an error\n        elif pressures.shape[0] != numElems:\n            raise self._TACSError(\n                \"Number of pressures must match number of elements,\"\n                \" {} pressures were specified for {} element IDs\".format(\n                    pressures.shape[0], numElems\n                )\n            )\n\n        # First find the corresponding local element ID on each processor\n        localElemIDs = self.meshLoader.getLocalElementIDsFromGlobal(\n            elemIDs, nastranOrdering=nastranOrdering\n        )\n\n        # Flag to make sure we find all user-specified elements\n        elemFound = np.zeros(numElems, dtype=int)\n\n        # Loop through every element and if it's owned by this processor, add the pressure\n        for i, elemID in enumerate(localElemIDs):\n            # The element was found on this proc\n            if elemID >= 0:\n                elemFound[i] = 1\n                # Get the pointer for the tacs element object for this element\n                elemObj = self.meshLoader.getElementObjectForElemID(\n                    elemIDs[i], nastranOrdering=nastranOrdering\n                )\n                # Create appropriate pressure object for this element type\n                pressObj = elemObj.createElementPressure(faceIndex, pressures[i])\n                # Pressure not implemented for element\n                if pressObj is None:\n                    self._TACSWarning(\n                        \"TACS element of type {} does not hav a pressure implementation. \"\n                        \"Skipping element in addPressureToElement procedure.\".format(\n                            elemObj.getObjectName()\n                        )\n                    )\n                # Pressure implemented\n                else:\n                    # Add new pressure to auxiliary element object\n                    auxElems.addElement(elemID, pressObj)\n\n        # Reduce the element flag and make sure that every element was found on exactly 1 proc\n        elemFound = self.comm.allreduce(elemFound, op=MPI.SUM)\n\n        # Warn the user if any elements weren't found\n        if nastranOrdering:\n            orderString = \"Nastran\"\n        else:\n            orderString = \"TACS\"\n\n        for i in range(numElems):\n            if not elemFound[i]:\n                self._TACSWarning(\n                    \"Can't add pressure to element ID {} ({} ordering), element not found in model. \"\n                    \"Double check BDF file.\".format(elemIDs[i], orderString)\n                )\n\n    def _addInertialLoad(self, auxElems, inertiaVector):\n        \"\"\"\n        This is an internal helper function for doing the addInertialLoad method for\n        inherited TACSProblem classes. The function should NOT be called by the user should\n        use the addInertialLoad method for the respective problem class. The function\n        is used to add a fixed inertial load due to a uniform acceleration over the entire model.\n        This is most commonly used to model gravity loads on a model.\n\n        Parameters\n        ----------\n\n         auxElems : tacs.TACS.AuxElements\n            AuxElements object to add loads to.\n\n        inertiaVector : numpy.ndarray\n            Acceleration vector used to define inertial load.\n        \"\"\"\n        # Make sure vector is right type\n        inertiaVector = np.atleast_1d(inertiaVector).astype(self.dtype)\n        # Get elements on this processor\n        localElements = self.assembler.getElements()\n        # Loop through every element and apply inertial load\n        for elemID, elemObj in enumerate(localElements):\n            # Create appropriate inertial force object for this element type\n            inertiaObj = elemObj.createElementInertialForce(inertiaVector)\n            # Inertial force is implemented for element\n            if inertiaObj is not None:\n                # Add new inertial force to auxiliary element object\n                auxElems.addElement(elemID, inertiaObj)\n\n    def _addCentrifugalLoad(self, auxElems, omegaVector, rotCenter, firstOrder=False):\n        \"\"\"\n        This is an internal helper function for doing the addCentrifugalLoad method for\n        inherited TACSProblem classes. The function should NOT be called by the user should\n        use the addCentrifugalLoad method for the respective problem class. The function\n        is used to add a fixed centrifugal load due to a uniform rotational velocity over the entire model.\n        This is most commonly used to model rotors, rolling aircraft, etc.\n\n        Parameters\n        ----------\n\n        auxElems : tacs.TACS.AuxElements\n            AuxElements object to add loads to.\n\n        omegaVector : numpy.ndarray\n            Rotational velocity vector (rad/s) used to define centrifugal load.\n\n        rotCenter : numpy.ndarray\n            Location of center of rotation used to define centrifugal load.\n\n        firstOrder : bool, optional\n            Whether to use first order approximation for centrifugal load,\n            which computes the force in the displaced position. By default False\n        \"\"\"\n        # Make sure vector is right type\n        omegaVector = np.atleast_1d(omegaVector).astype(self.dtype)\n        rotCenter = np.atleast_1d(rotCenter).astype(self.dtype)\n        # Get elements on this processor\n        localElements = self.assembler.getElements()\n        # Loop through every element and apply centrifugal load\n        for elemID, elemObj in enumerate(localElements):\n            # Create appropriate centrifugal force object for this element type\n            centrifugalObj = elemObj.createElementCentrifugalForce(\n                omegaVector, rotCenter, firstOrder=firstOrder\n            )\n            # Centrifugal force is implemented for element\n            if centrifugalObj is not None:\n                # Add new centrifugal force to auxiliary element object\n                auxElems.addElement(elemID, centrifugalObj)\n\n    def _addLoadFromBDF(self, FVec, auxElems, loadID, setScale=1.0):\n        \"\"\"\n        This is an internal helper function for doing the addLoadFromBDF method for\n        inherited TACSProblem classes. The function should NOT be called by the user should\n        use the addLoadFromBDF method for the respective problem class. This method is\n        used to add a fixed load set defined in the BDF file to the problem.\n        Currently, only supports LOAD, FORCE, MOMENT, GRAV, RFORCE, PLOAD2, and PLOAD4.\n\n        Parameters\n        ----------\n\n        FVec : tacs.TACS.Vec\n            TACS BVec to add loads to.\n\n        auxElems : tacs.TACS.AuxElements\n            AuxElements object to add loads to.\n\n        loadID : int\n            Load identification number of load set in BDF file user wishes to add to problem.\n\n        setScale : float\n            Factor to scale the BDF loads by before adding to problem.\n        \"\"\"\n        # Make sure bdf is cross-referenced\n        if self.bdfInfo.is_xrefed is False:\n            self.bdfInfo.cross_reference()\n            self.bdfInfo.is_xrefed = True\n\n        vpn = self.assembler.getVarsPerNode()\n        # Get loads and scalers for this load case ID\n        loadSet, loadScale, _ = self.bdfInfo.get_reduced_loads(loadID)\n        # Loop through every load in set and add it to problem\n        for loadInfo, scale in zip(loadSet, loadScale):\n            scale *= setScale\n            # Add any point force or moment cards\n            if loadInfo.type == \"FORCE\" or loadInfo.type == \"MOMENT\":\n                nodeID = loadInfo.node_ref.nid\n\n                loadArray = np.zeros(vpn)\n                if loadInfo.type == \"FORCE\" and vpn >= 3:\n                    F = scale * loadInfo.scaled_vector\n                    loadArray[:3] += loadInfo.cid_ref.transform_vector_to_global(F)\n                elif loadInfo.type == \"MOMENT\" and vpn >= 6:\n                    M = scale * loadInfo.scaled_vector\n                    loadArray[3:6] += loadInfo.cid_ref.transform_vector_to_global(M)\n                self._addLoadToNodes(FVec, nodeID, loadArray, nastranOrdering=True)\n\n            # Add any gravity loads\n            elif loadInfo.type == \"GRAV\":\n                inertiaVec = np.zeros(3, dtype=self.dtype)\n                inertiaVec[:3] = scale * loadInfo.scale * loadInfo.N\n                # Convert acceleration to global coordinate system\n                inertiaVec = loadInfo.cid_ref.transform_vector_to_global(inertiaVec)\n                self._addInertialLoad(auxElems, inertiaVec)\n\n            # Add any centrifugal loads\n            elif loadInfo.type == \"RFORCE\":\n                omegaVec = np.zeros(3, dtype=self.dtype)\n                if loadInfo.nid_ref:\n                    rotCenter = loadInfo.nid_ref.get_position()\n                else:\n                    rotCenter = np.zeros(3, dtype=self.dtype)\n                omegaVec[:3] = scale * loadInfo.scale * np.array(loadInfo.r123)\n                # Convert omega from rev/s to rad/s\n                omegaVec *= 2 * np.pi\n                # Convert omega to global coordinate system\n                omegaVec = loadInfo.cid_ref.transform_vector_to_global(omegaVec)\n                self._addCentrifugalLoad(auxElems, omegaVec, rotCenter)\n\n            # Add any pressure loads\n            # Pressure load card specific to shell elements\n            elif loadInfo.type == \"PLOAD2\":\n                elemIDs = loadInfo.eids\n                pressure = scale * loadInfo.pressure\n                self._addPressureToElements(\n                    auxElems, elemIDs, pressure, nastranOrdering=True\n                )\n\n            # Alternate more general pressure load type\n            elif loadInfo.type == \"PLOAD4\":\n                self._addPressureFromPLOAD4(auxElems, loadInfo, scale)\n\n            else:\n                self._TACSWarning(\n                    \"Unsupported load type \"\n                    f\" '{loadInfo.type}' specified for load set number {loadInfo.sid}, skipping load\"\n                )\n\n    def _addPressureFromPLOAD4(self, auxElems, loadInfo, scale=1.0):\n        \"\"\"\n        Add pressure to tacs static/transient problem from pynastran PLOAD4 card.\n        Should only be called by createTACSProbsFromBDF and not directly by user.\n        \"\"\"\n        # Dictionary mapping nastran element face indices to TACS equivalent numbering\n        nastranToTACSFaceIDDict = {\n            \"CTETRA4\": {1: 1, 2: 3, 3: 2, 4: 0},\n            \"CTETRA\": {2: 1, 4: 3, 3: 2, 1: 0},\n            \"CHEXA\": {1: 4, 2: 2, 3: 1, 4: 3, 5: 0, 6: 5},\n        }\n\n        # We don't support pressure variation across elements, for now just average it\n        pressure = scale * np.mean(loadInfo.pressures)\n        for elemInfo in loadInfo.eids_ref:\n            elemID = elemInfo.eid\n\n            # Get the correct face index number based on element type\n            if \"CTETRA\" in elemInfo.type:\n                for faceIndex in elemInfo.faces:\n                    if (\n                        loadInfo.g1 in elemInfo.faces[faceIndex]\n                        and loadInfo.g34 not in elemInfo.faces[faceIndex]\n                    ):\n                        # For some reason CTETRA4 is the only element that doesn't\n                        # use ANSYS face numbering convention by default\n                        if len(elemInfo.nodes) == 4:\n                            faceIndex = nastranToTACSFaceIDDict[\"CTETRA4\"][faceIndex]\n                        else:\n                            faceIndex = nastranToTACSFaceIDDict[\"CTETRA\"][faceIndex]\n                        # Positive pressure is inward for solid elements, flip pressure if necessary\n                        # We don't flip it for face 0, because the normal for that face points inward by convention\n                        # while the rest point outward\n                        if faceIndex != 0:\n                            pressure *= -1.0\n                        break\n\n            elif \"CHEXA\" in elemInfo.type:\n                for faceIndex in elemInfo.faces:\n                    if (\n                        loadInfo.g1 in elemInfo.faces[faceIndex]\n                        and loadInfo.g34 in elemInfo.faces[faceIndex]\n                    ):\n                        faceIndex = nastranToTACSFaceIDDict[\"CHEXA\"][faceIndex]\n                        # Pressure orientation is flipped for solid elements per Nastran convention\n                        pressure *= -1.0\n                        break\n\n            elif \"CQUAD\" in elemInfo.type or \"CTRIA\" in elemInfo.type:\n                # Face index doesn't matter for shells, just use 0\n                faceIndex = 0\n\n            else:\n                raise self._TACSError(\n                    \"Unsupported element type \"\n                    f\"'{elemInfo.type}' specified for PLOAD4 load set number {loadInfo.sid}.\"\n                )\n\n            # Figure out whether or not this is a traction based on if a vector is defined\n            if np.linalg.norm(loadInfo.nvector) == 0.0:\n                self._addPressureToElements(\n                    auxElems, elemID, pressure, faceIndex, nastranOrdering=True\n                )\n            else:\n                trac = pressure * loadInfo.nvector\n                self._addTractionToElements(\n                    auxElems, elemID, trac, faceIndex, nastranOrdering=True\n                )\n\n    def writeSensFile(self, evalFuncs, tacsAim):\n        \"\"\"\n        write an ESP/CAPS .sens file from the tacs aim\n        Optional tacs_aim arg for TacsAim wrapper class object in root/tacs/caps2tacs/\n\n        Parameters\n        ----------\n        evalFuncs : list[str]\n            names of TACS functions to be evaluated\n        tacsAim : tacs.caps2tacs.TacsAIM\n            class which handles the sensitivity file writing for ESP/CAPS shape derivatives\n\n        \"\"\"\n\n        # obtain the functions and sensitivities from TACS assembler\n        tacs_funcs = {}\n        tacs_sens = {}\n        self.evalFunctions(tacs_funcs, evalFuncs=evalFuncs)\n        self.evalFunctionsSens(tacs_sens, evalFuncs=evalFuncs)\n\n        num_funcs = len(evalFuncs)\n        assert tacsAim is not None\n        num_struct_dvs = len(tacsAim.thickness_variables)\n        num_nodes = self.meshLoader.bdfInfo.nnodes\n        node_ids = self.meshLoader.allLocalNodeIDs\n\n        if self.comm.rank == 0:\n            # open the sens file nastran_CAPS.sens and write coordinate derivatives\n            # and any other struct derivatives to it\n            with open(tacsAim.sens_file_path, \"w\") as hdl:\n                for func_name in evalFuncs:\n                    hdl.write(f\"{num_funcs} {num_struct_dvs}\\n\")\n\n                    # for each function write the values and coordinate derivatives\n                    for func_name in evalFuncs:\n                        # get the tacs key\n                        for tacs_key in tacs_funcs:\n                            if func_name in tacs_key:\n                                break\n\n                        # get the tacs coordinate derivatives\n                        xpts_sens = tacs_sens[tacs_key][\"Xpts\"]\n\n                        # write the func name, value and nnodes\n                        hdl.write(f\"{func_name}\\n\")\n                        hdl.write(f\"{tacs_funcs[tacs_key].real}\\n\")\n                        hdl.write(f\"{num_nodes}\\n\")\n\n                        # write the coordinate derivatives for the given function\n                        for bdf_ind in range(num_nodes):\n                            tacs_ind = node_ids[bdf_ind]\n                            nastran_node = bdf_ind + 1\n                            hdl.write(\n                                f\"{nastran_node} {xpts_sens[3*tacs_ind].real} {xpts_sens[3*tacs_ind+1].real} {xpts_sens[3*tacs_ind+2].real}\\n\"\n                            )\n\n                        # write any struct derivatives if there are struct derivatives\n                        if num_struct_dvs > 0:\n                            struct_sens = tacs_sens[tacs_key][\"struct\"]\n                            for idx, thick_var in enumerate(\n                                tacsAim.thickness_variables\n                            ):\n                                # assumes these are sorted in tacs aim wrapper\n                                hdl.write(f\"{thick_var.name}\\n\")\n                                hdl.write(\"1\\n\")\n                                hdl.write(f\"{struct_sens[idx].real}\\n\")\n            return",
  "def __init__(\n        self, assembler, comm=None, options=None, outputViewer=None, meshLoader=None\n    ):\n        \"\"\"\n        Parameters\n        ----------\n        assembler : tacs.TACS.Assembler\n            Cython object responsible for creating and setting tacs objects used to solve problem\n\n        comm : mpi4py.MPI.Intracomm\n            The comm object on which to create the pyTACS object.\n\n        options : dict\n            Dictionary holding problem-specific option parameters (case-insensitive).\n\n        outputViewer : tacs.TACS.TACSToFH5\n            Cython object used to write out f5 files that can be converted and used for postprocessing.\n\n        meshLoader : tacs.pymeshloader.pyMeshLoader\n            pyMeshLoader object used to create the assembler.\n        \"\"\"\n        # Set attributes and options\n        TACSSystem.__init__(self, assembler, comm, options, outputViewer, meshLoader)\n\n        # List of functions\n        self.functionList = OrderedDict()\n\n        return",
  "def addFunction(self, funcName, funcHandle, compIDs=None, **kwargs):\n        \"\"\"\n        Generic method to add a function for TACS. It is intended to\n        be reasonably generic since the user supplies the actual\n        function handle to use. See the :py:mod:`~tacs.functions` module\n        for supported TACS eval functions.\n\n        Parameters\n        ----------\n        funcName : str\n            The user-supplied name for the function. This will\n            typically be a string that is meaningful to the user\n\n        funcHandle : TACS.Function\n            The function handle to use for creation. This must come\n            from the functions module in tacs.\n\n        compIDs: list\n            List of compIDs to select.\n\n        **kwargs:\n            Any keyword arguments to be passed to the TACS function during setup.\n        \"\"\"\n\n        # We try to setup the function, if it fails it may not be implemented:\n        try:\n            # pass assembler an function-specific kwargs straight to tacs function\n            self.functionList[funcName] = funcHandle(self.assembler, **kwargs)\n        except:\n            self._TACSWarning(\n                f\"Function type {funcHandle} is not currently supported. \"\n                \"in pyTACS. Skipping function.\"\n            )\n            return False\n\n        # First we will get the required domain, but only if compIDs\n        # was specified. If not, just use the entire domain by default\n        if compIDs is not None:\n            # Make sure CompIDs is flat and get element numbers on each proc corresponding to specified compIDs\n            compIDs = self._flatten(compIDs)\n            elemIDs = self.meshLoader.getLocalElementIDsForComps(compIDs)\n            # Finally set the domain information\n            self.functionList[funcName].setDomain(elemIDs)\n\n        return True",
  "def getFunctionKeys(self):\n        \"\"\"\n        Return a list of the current function key names\n\n        Returns\n        -------\n        funcNames : list[str]\n            List containing user-defined names for functions added so far.\n        \"\"\"\n        return list(self.functionList.keys())",
  "def _addLoadToComponents(self, FVec, compIDs, F, averageLoad=False):\n        \"\"\"\n        This is an internal helper function for doing the addLoadToComponents method for\n        inherited TACSProblem classes. The function should NOT be called by the user should\n        use the addLoadToComponents method for the respective problem class. The function is\n        used to add a *FIXED TOTAL LOAD* on one or more components, defined by COMPIDs.\n        The purpose of this routine is to add loads that remain fixed throughout an optimization.\n        An example would be an engine load. This routine determines all the unqiue nodes in the\n        FE model that are part of the requested components, then takes the total 'force' by F and\n        divides by the number of nodes. This average load is then applied to the nodes.\n\n        Parameters\n        ----------\n\n        FVec : tacs.TACS.Vec\n            TACS BVec to add loads to.\n\n        compIDs : list[int] or int\n            The components with added loads. Use pyTACS.selectCompIDs method\n            to determine this.\n\n        F : numpy.ndarray 1d or 2d length (varsPerNodes) or (numCompIDs, varsPerNodes)\n            Vector(s) of 'force' to apply to each component.  If only one force vector is provided,\n            force will be copied uniformly across all components.\n\n        averageLoad : bool\n            Flag to determine whether load should be split evenly across all components (True)\n            or copied and applied individually to each component (False). Defaults to False.\n\n        Notes\n        -----\n\n        The units of the entries of the 'force' vector F are not\n        necessarily physical forces and their interpretation depends\n        on the physics problem being solved and the dofs included\n        in the model.\n\n        A couple of examples of force vector components for common problems are listed below:\n\n            In Heat Conduction with varsPerNode = 1\n                F = [Qdot] # heat rate\n            In Elasticity with varsPerNode = 3,\n                F = [fx, fy, fz] # forces\n            In Elasticity with varsPerNode = 6,\n                F = [fx, fy, fz, mx, my, mz] # forces + moments\n            In Thermoelasticity with varsPerNode = 4,\n                F = [fx, fy, fz, Qdot] # forces + heat rate\n            In Thermoelasticity with varsPerNode = 7,\n                F = [fx, fy, fz, mx, my, mz, Qdot] # forces + moments + heat rate\n        \"\"\"\n        # Make sure CompIDs are flat\n        compIDs = self._flatten([compIDs])\n\n        # Apply a unique force vector to each component\n        if not averageLoad:\n            F = np.atleast_2d(F)\n\n            # If the user only specified one force vector,\n            # we assume the force should be the same for each component\n            if F.shape[0] == 1:\n                F = np.repeat(F, [len(compIDs)], axis=0)\n            # If the dimensions still don't match, raise an error\n            elif F.shape[0] != len(compIDs):\n                raise self._TACSError(\n                    \"Number of forces must match number of compIDs,\"\n                    \" {} forces were specified for {} compIDs\".format(\n                        F.shape[0], len(compIDs)\n                    )\n                )\n\n            # Call addLoadToComponents again, once for each compID\n            for i, compID in enumerate(compIDs):\n                self._addLoadToComponents(FVec, compID, F[i], averageLoad=True)\n\n        # Average one force vector over all components\n        else:\n            F = np.atleast_1d(F)\n\n            # First determine the unique global node IDs corresponding to components:\n            uniqueNodes = self.meshLoader.getGlobalNodeIDsForComps(\n                compIDs, nastranOrdering=False\n            )\n\n            # Now generate the final average force vector\n            Favg = F / len(uniqueNodes)\n\n            self._addLoadToNodes(FVec, uniqueNodes, Favg, nastranOrdering=False)\n\n            # Write out a message of what we did:\n            self._info(\n                \"Added a fixed load of %s to %d components, \"\n                \"distributed over %d nodes.\"\n                % (repr(F), len(compIDs), len(uniqueNodes)),\n                maxLen=80,\n                box=True,\n            )",
  "def _addLoadToNodes(self, FVec, nodeIDs, F, nastranOrdering=False):\n        \"\"\"\n        This is an internal helper function for doing the addLoadToNodes method for\n        inherited TACSProblem classes. The function should NOT be called by the user should\n        use the addLoadToNodes method for the respective problem class. The function is\n        used to add a fixed point load of F to the selected node IDs.\n\n        Parameters\n        ----------\n\n        FVec : tacs.TACS.Vec\n            TACS BVec to add loads to.\n\n        nodeIDs : list[int]\n            The nodes IDs with added loads.\n\n        F : Numpy 1d or 2d array length (varsPerNodes) or (numNodeIDs, varsPerNodes)\n            Array of force vectors, one for each node. If only one force vector is provided,\n            force will be copied uniformly across all nodes.\n\n        nastranOrdering : bool\n            Flag signaling whether nodeIDs are in TACS (default)\n            or NASTRAN (grid IDs in bdf file) ordering\n\n        Notes\n        -----\n\n        The units of the entries of the 'force' vector F are not\n        necessarily physical forces and their interpretation depends\n        on the physics problem being solved and the dofs included\n        in the model.\n\n        A couple of examples of force vector components for common problems are listed below:\n\n            In Heat Conduction with varsPerNode = 1\n                F = [Qdot] # heat rate\n            In Elasticity with varsPerNode = 3,\n                F = [fx, fy, fz] # forces\n            In Elasticity with varsPerNode = 6,\n                F = [fx, fy, fz, mx, my, mz] # forces + moments\n            In Thermoelasticity with varsPerNode = 4,\n                F = [fx, fy, fz, Qdot] # forces + heat rate\n            In Thermoelasticity with varsPerNode = 7,\n                F = [fx, fy, fz, mx, my, mz, Qdot] # forces + moments + heat rate\n        \"\"\"\n\n        # Make sure the inputs are the correct shape\n        nodeIDs = np.atleast_1d(nodeIDs)\n        F = np.atleast_2d(F)\n\n        numNodes = len(nodeIDs)\n\n        # If the user only specified one force vector,\n        # we assume the force should be the same for each node\n        if F.shape[0] == 1:\n            F = np.repeat(F, [numNodes], axis=0)\n        # If the dimensions still don't match, raise an error\n        elif F.shape[0] != numNodes:\n            raise self._TACSError(\n                \"Number of forces must match number of nodes,\"\n                \" {} forces were specified for {} node IDs\".format(F.shape[0], numNodes)\n            )\n\n        vpn = self.assembler.getVarsPerNode()\n        if len(F[0]) != vpn:\n            raise self._TACSError(\n                \"Length of force vector must match varsPerNode specified \"\n                \"for problem, which is {}, \"\n                \"but length of vector provided was {}\".format(vpn, len(F[0]))\n            )\n\n        # First find the corresponding local node ID on each processor\n        localNodeIDs = self.meshLoader.getLocalNodeIDsFromGlobal(\n            nodeIDs, nastranOrdering\n        )\n\n        # Flag to make sure we find all user-specified nodes\n        nodeFound = np.zeros(numNodes, dtype=int)\n\n        F_array = FVec.getArray()\n        nnodes = self.assembler.getNumOwnedNodes()\n        vpn = self.assembler.getVarsPerNode()\n        F_array = F_array.reshape(nnodes, vpn)\n\n        # Loop through every node and if it's owned by this processor, add the load\n        for i, nodeID in enumerate(localNodeIDs):\n            # The node was found on this proc\n            if nodeID >= 0:\n                # Add contribution to global force array\n                F_array[nodeID, :] += F[i]\n                nodeFound[i] = 1\n\n        # Reduce the node flag and make sure that every node was found on exactly 1 proc\n        nodeFound = self.comm.allreduce(nodeFound, op=MPI.SUM)\n\n        # Warn the user if any nodes weren't found\n        if nastranOrdering:\n            orderString = \"Nastran\"\n        else:\n            orderString = \"TACS\"\n\n        for i in range(numNodes):\n            if not nodeFound[i]:\n                self._TACSWarning(\n                    \"Can't add load to node ID {} ({} ordering), node not found in model. \"\n                    \"Double check BDF file.\".format(nodeIDs[i], orderString)\n                )",
  "def _addLoadToRHS(self, Frhs, Fapplied):\n        \"\"\"\n        This is an internal helper function for doing the addLoadToRHS method for\n        inherited TACSProblem classes. The function should NOT be called by the user should\n        use the addLoadToRHS method for the respective problem class.\n        The function is used to add a *FIXED TOTAL LOAD* directly to the\n        right hand side vector given the equation below:\n\n            K*u = f\n\n        Where:\n            K : Stiffness matrix for problem\n            u : State variables for problem\n            f : Right-hand side vector to add loads to\n\n        Parameters\n        ----------\n\n        Fapplied : numpy.ndarray or tacs.TACS.Vec\n            Distributed array containing loads to applied to RHS of the problem.\n\n        \"\"\"\n        if isinstance(Fapplied, tacs.TACS.Vec):\n            Frhs.axpy(1.0, Fapplied)\n        elif isinstance(Fapplied, np.ndarray):\n            if len(Fapplied) != Frhs.getSize():\n                raise self._TACSError(\n                    \"User-supplied distributed vector not correct length, \"\n                    \"expected size of {} on processor {}, but got length {}.\".format(\n                        Frhs.getSize(), self.comm.rank, len(Fapplied)\n                    )\n                )\n            rhsArray = Frhs.getArray()\n            rhsArray[:] = rhsArray[:] + Fapplied[:]",
  "def _addTractionToComponents(self, auxElems, compIDs, tractions, faceIndex=0):\n        \"\"\"\n        This is an internal helper function for doing the addTractionToComponents method for\n        inherited TACSProblem classes. The function should NOT be called by the user should\n        use the addTractionToComponents method for the respective problem class. The function is used\n        to add a *FIXED TOTAL TRACTION* on one or more components, defined by COMPIDs. The purpose of\n        this routine is to add loads that remain fixed throughout an optimization.\n\n        Parameters\n        ----------\n\n         auxElems : tacs.TACS.AuxElements\n            AuxElements object to add loads to.\n\n        compIDs : list[int] or int\n            The components with added loads. Use pyTACS.selectCompIDs method\n            to determine this.\n\n        tractions : numpy.ndarray\n            Array of traction vectors for each component\n\n        faceIndex : int\n            Indicates which face (side) of the element to apply traction to.\n            Note: not required for certain elements (i.e. shells)\n        \"\"\"\n        # Make sure compIDs is flat and unique\n        compIDs = set(self._flatten(compIDs))\n        tractions = np.atleast_1d(tractions)\n\n        # Get global element IDs for the elements we're applying tractions to\n        elemIDs = self.meshLoader.getGlobalElementIDsForComps(\n            compIDs, nastranOrdering=False\n        )\n        # Add tractions element by element\n        self._addTractionToElements(\n            auxElems, elemIDs, tractions, faceIndex, nastranOrdering=False\n        )\n\n        # Write out a message of what we did:\n        self._info(\n            \"Added a fixed traction of %s to %d components, \"\n            \"distributed over %d elements.\"\n            % (repr(tractions), len(compIDs), len(elemIDs)),\n            maxLen=80,\n            box=True,\n        )",
  "def _addTractionToElements(\n        self, auxElems, elemIDs, tractions, faceIndex=0, nastranOrdering=False\n    ):\n        \"\"\"\n        This is an internal helper function for doing the addTractionToElements method for\n        inherited TACSProblem classes. The function should NOT be called by the user should\n        use the addTractionToElements method for the respective problem class. The function\n        is used to add a fixed traction to the selected element IDs. Tractions can be specified on an\n        element by element basis (if tractions is a 2d array) or set to a uniform value (if tractions is a 1d array)\n\n        Parameters\n        ----------\n\n        auxElems : tacs.TACS.AuxElements\n            AuxElements object to add loads to.\n\n        elemIDs : list[int]\n            The global element ID numbers for which to apply the traction.\n\n        tractions : Numpy 1d or 2d array length varsPerNodes or (elemIDs, varsPerNodes)\n            Array of traction vectors for each element\n\n        faceIndex : int\n            Indicates which face (side) of element to apply traction to.\n            Note: not required for certain elements (i.e. shells)\n\n        nastranOrdering : bool\n            Flag signaling whether elemIDs are in TACS (default)\n            or NASTRAN ordering\n        \"\"\"\n\n        # Make sure the inputs are the correct shape\n        elemIDs = np.atleast_1d(elemIDs)\n        tractions = np.atleast_2d(tractions).astype(dtype=self.dtype)\n\n        numElems = len(elemIDs)\n\n        # If the user only specified one traction vector,\n        # we assume the force should be the same for each element\n        if tractions.shape[0] == 1:\n            tractions = np.repeat(tractions, [numElems], axis=0)\n        # If the dimensions still don't match, raise an error\n        elif tractions.shape[0] != numElems:\n            raise self._TACSError(\n                \"Number of tractions must match number of elements,\"\n                \" {} tractions were specified for {} element IDs\".format(\n                    tractions.shape[0], numElems\n                )\n            )\n\n        # First find the corresponding local element ID on each processor\n        localElemIDs = self.meshLoader.getLocalElementIDsFromGlobal(\n            elemIDs, nastranOrdering=nastranOrdering\n        )\n\n        # Flag to make sure we find all user-specified elements\n        elemFound = np.zeros(numElems, dtype=int)\n\n        # Loop through every element and if it's owned by this processor, add the traction\n        for i, elemID in enumerate(localElemIDs):\n            # The element was found on this proc\n            if elemID >= 0:\n                # Mark element as found\n                elemFound[i] = 1\n                # Get the pointer for the tacs element object for this element\n                elemObj = self.meshLoader.getElementObjectForElemID(\n                    elemIDs[i], nastranOrdering=nastranOrdering\n                )\n                # Create an appropriate traction object for this element type\n                tracObj = elemObj.createElementTraction(faceIndex, tractions[i])\n                # Traction not implemented for this element\n                if tracObj is None:\n                    self._TACSWarning(\n                        \"TACS element of type {} does not hav a traction implementation. \"\n                        \"Skipping element in addTractionToElement procedure.\".format(\n                            elemObj.getObjectName()\n                        )\n                    )\n                # Traction implemented\n                else:\n                    # Add new traction to the auxiliary element object\n                    auxElems.addElement(elemID, tracObj)\n\n        # Reduce the element flag and make sure that every element was found on exactly 1 proc\n        elemFound = self.comm.allreduce(elemFound, op=MPI.SUM)\n\n        # Warn the user if any elements weren't found\n        if nastranOrdering:\n            orderString = \"Nastran\"\n        else:\n            orderString = \"TACS\"\n\n        for i in range(numElems):\n            if not elemFound[i]:\n                self._TACSWarning(\n                    \"Can't add traction to element ID {} ({} ordering), element not found in model. \"\n                    \"Double check BDF file.\".format(elemIDs[i], orderString)\n                )",
  "def _addPressureToComponents(self, auxElems, compIDs, pressures, faceIndex=0):\n        \"\"\"\n        This is an internal helper function for doing the addPressureToComponents method for\n        inherited TACSProblem classes. The function should NOT be called by the user should\n        use the addPressureToComponents method for the respective problem class. The function\n        is used to add a *FIXED TOTAL PRESSURE* on one or more components, defined by COMPIds.\n        The purpose of this routine is to add loads that remain fixed throughout an optimization.\n        An example would be a fuel load.\n\n        Parameters\n        ----------\n\n        auxElems : tacs.TACS.AuxElements\n            AuxElements object to add loads to.\n\n        compIDs : list[int] or int\n            The components with added loads. Use pyTACS.selectCompIDs method\n            to determine this.\n\n        pressures : Numpy array length 1 or compIDs\n            Array of pressure values for each component\n\n        faceIndex : int\n            Indicates which face (side) of the element to apply pressure to.\n            Note: not required for certain elements (i.e. shells)\n        \"\"\"\n        # Make sure compIDs is flat and unique\n        compIDs = set(self._flatten(compIDs))\n        pressures = np.atleast_1d(pressures)\n\n        # Get global element IDs for the elements we're applying pressure to\n        elemIDs = self.meshLoader.getGlobalElementIDsForComps(\n            compIDs, nastranOrdering=False\n        )\n        # Add pressure element by element\n        self._addPressureToElements(\n            auxElems, elemIDs, pressures, faceIndex, nastranOrdering=False\n        )\n\n        # Write out a message of what we did:\n        self._info(\n            \"Added a fixed pressure of %s to %d components, \"\n            \"distributed over %d elements.\"\n            % (repr(pressures), len(compIDs), len(elemIDs)),\n            maxLen=80,\n            box=True,\n        )",
  "def _addPressureToElements(\n        self, auxElems, elemIDs, pressures, faceIndex=0, nastranOrdering=False\n    ):\n        \"\"\"\n        This is an internal helper function for doing the addPressureToElements method for\n        inherited TACSProblem classes. The function should NOT be called by the user should\n        use the addPressureToElements method for the respective problem class. The function\n        is used to add a fixed presure to the selected element IDs. Pressures can be specified on an\n        element by element basis (if pressures is an array) or set to a uniform value (if pressures is a scalar)\n\n        Parameters\n        ----------\n\n        auxElems : tacs.TACS.AuxElements\n            AuxElements object to add loads to.\n\n        elemIDs : list[int]\n            The global element ID numbers for which to apply the pressure.\n\n        pressures : Numpy array length 1 or elemIDs\n            Array of pressure values for each element\n\n        faceIndex : int\n            Indicates which face (side) of element to apply pressure to.\n            Note: not required for certain elements (i.e. shells)\n\n        nastranOrdering : bool\n            Flag signaling whether elemIDs are in TACS (default)\n            or NASTRAN ordering\n        \"\"\"\n\n        # Make sure the inputs are the correct shape\n        elemIDs = np.atleast_1d(elemIDs)\n        pressures = np.atleast_1d(pressures)\n\n        numElems = len(elemIDs)\n\n        # If the user only specified one pressure,\n        # we assume the force should be the same for each element\n        if pressures.shape[0] == 1:\n            pressures = np.repeat(pressures, [numElems], axis=0)\n        # If the dimensions still don't match, raise an error\n        elif pressures.shape[0] != numElems:\n            raise self._TACSError(\n                \"Number of pressures must match number of elements,\"\n                \" {} pressures were specified for {} element IDs\".format(\n                    pressures.shape[0], numElems\n                )\n            )\n\n        # First find the corresponding local element ID on each processor\n        localElemIDs = self.meshLoader.getLocalElementIDsFromGlobal(\n            elemIDs, nastranOrdering=nastranOrdering\n        )\n\n        # Flag to make sure we find all user-specified elements\n        elemFound = np.zeros(numElems, dtype=int)\n\n        # Loop through every element and if it's owned by this processor, add the pressure\n        for i, elemID in enumerate(localElemIDs):\n            # The element was found on this proc\n            if elemID >= 0:\n                elemFound[i] = 1\n                # Get the pointer for the tacs element object for this element\n                elemObj = self.meshLoader.getElementObjectForElemID(\n                    elemIDs[i], nastranOrdering=nastranOrdering\n                )\n                # Create appropriate pressure object for this element type\n                pressObj = elemObj.createElementPressure(faceIndex, pressures[i])\n                # Pressure not implemented for element\n                if pressObj is None:\n                    self._TACSWarning(\n                        \"TACS element of type {} does not hav a pressure implementation. \"\n                        \"Skipping element in addPressureToElement procedure.\".format(\n                            elemObj.getObjectName()\n                        )\n                    )\n                # Pressure implemented\n                else:\n                    # Add new pressure to auxiliary element object\n                    auxElems.addElement(elemID, pressObj)\n\n        # Reduce the element flag and make sure that every element was found on exactly 1 proc\n        elemFound = self.comm.allreduce(elemFound, op=MPI.SUM)\n\n        # Warn the user if any elements weren't found\n        if nastranOrdering:\n            orderString = \"Nastran\"\n        else:\n            orderString = \"TACS\"\n\n        for i in range(numElems):\n            if not elemFound[i]:\n                self._TACSWarning(\n                    \"Can't add pressure to element ID {} ({} ordering), element not found in model. \"\n                    \"Double check BDF file.\".format(elemIDs[i], orderString)\n                )",
  "def _addInertialLoad(self, auxElems, inertiaVector):\n        \"\"\"\n        This is an internal helper function for doing the addInertialLoad method for\n        inherited TACSProblem classes. The function should NOT be called by the user should\n        use the addInertialLoad method for the respective problem class. The function\n        is used to add a fixed inertial load due to a uniform acceleration over the entire model.\n        This is most commonly used to model gravity loads on a model.\n\n        Parameters\n        ----------\n\n         auxElems : tacs.TACS.AuxElements\n            AuxElements object to add loads to.\n\n        inertiaVector : numpy.ndarray\n            Acceleration vector used to define inertial load.\n        \"\"\"\n        # Make sure vector is right type\n        inertiaVector = np.atleast_1d(inertiaVector).astype(self.dtype)\n        # Get elements on this processor\n        localElements = self.assembler.getElements()\n        # Loop through every element and apply inertial load\n        for elemID, elemObj in enumerate(localElements):\n            # Create appropriate inertial force object for this element type\n            inertiaObj = elemObj.createElementInertialForce(inertiaVector)\n            # Inertial force is implemented for element\n            if inertiaObj is not None:\n                # Add new inertial force to auxiliary element object\n                auxElems.addElement(elemID, inertiaObj)",
  "def _addCentrifugalLoad(self, auxElems, omegaVector, rotCenter, firstOrder=False):\n        \"\"\"\n        This is an internal helper function for doing the addCentrifugalLoad method for\n        inherited TACSProblem classes. The function should NOT be called by the user should\n        use the addCentrifugalLoad method for the respective problem class. The function\n        is used to add a fixed centrifugal load due to a uniform rotational velocity over the entire model.\n        This is most commonly used to model rotors, rolling aircraft, etc.\n\n        Parameters\n        ----------\n\n        auxElems : tacs.TACS.AuxElements\n            AuxElements object to add loads to.\n\n        omegaVector : numpy.ndarray\n            Rotational velocity vector (rad/s) used to define centrifugal load.\n\n        rotCenter : numpy.ndarray\n            Location of center of rotation used to define centrifugal load.\n\n        firstOrder : bool, optional\n            Whether to use first order approximation for centrifugal load,\n            which computes the force in the displaced position. By default False\n        \"\"\"\n        # Make sure vector is right type\n        omegaVector = np.atleast_1d(omegaVector).astype(self.dtype)\n        rotCenter = np.atleast_1d(rotCenter).astype(self.dtype)\n        # Get elements on this processor\n        localElements = self.assembler.getElements()\n        # Loop through every element and apply centrifugal load\n        for elemID, elemObj in enumerate(localElements):\n            # Create appropriate centrifugal force object for this element type\n            centrifugalObj = elemObj.createElementCentrifugalForce(\n                omegaVector, rotCenter, firstOrder=firstOrder\n            )\n            # Centrifugal force is implemented for element\n            if centrifugalObj is not None:\n                # Add new centrifugal force to auxiliary element object\n                auxElems.addElement(elemID, centrifugalObj)",
  "def _addLoadFromBDF(self, FVec, auxElems, loadID, setScale=1.0):\n        \"\"\"\n        This is an internal helper function for doing the addLoadFromBDF method for\n        inherited TACSProblem classes. The function should NOT be called by the user should\n        use the addLoadFromBDF method for the respective problem class. This method is\n        used to add a fixed load set defined in the BDF file to the problem.\n        Currently, only supports LOAD, FORCE, MOMENT, GRAV, RFORCE, PLOAD2, and PLOAD4.\n\n        Parameters\n        ----------\n\n        FVec : tacs.TACS.Vec\n            TACS BVec to add loads to.\n\n        auxElems : tacs.TACS.AuxElements\n            AuxElements object to add loads to.\n\n        loadID : int\n            Load identification number of load set in BDF file user wishes to add to problem.\n\n        setScale : float\n            Factor to scale the BDF loads by before adding to problem.\n        \"\"\"\n        # Make sure bdf is cross-referenced\n        if self.bdfInfo.is_xrefed is False:\n            self.bdfInfo.cross_reference()\n            self.bdfInfo.is_xrefed = True\n\n        vpn = self.assembler.getVarsPerNode()\n        # Get loads and scalers for this load case ID\n        loadSet, loadScale, _ = self.bdfInfo.get_reduced_loads(loadID)\n        # Loop through every load in set and add it to problem\n        for loadInfo, scale in zip(loadSet, loadScale):\n            scale *= setScale\n            # Add any point force or moment cards\n            if loadInfo.type == \"FORCE\" or loadInfo.type == \"MOMENT\":\n                nodeID = loadInfo.node_ref.nid\n\n                loadArray = np.zeros(vpn)\n                if loadInfo.type == \"FORCE\" and vpn >= 3:\n                    F = scale * loadInfo.scaled_vector\n                    loadArray[:3] += loadInfo.cid_ref.transform_vector_to_global(F)\n                elif loadInfo.type == \"MOMENT\" and vpn >= 6:\n                    M = scale * loadInfo.scaled_vector\n                    loadArray[3:6] += loadInfo.cid_ref.transform_vector_to_global(M)\n                self._addLoadToNodes(FVec, nodeID, loadArray, nastranOrdering=True)\n\n            # Add any gravity loads\n            elif loadInfo.type == \"GRAV\":\n                inertiaVec = np.zeros(3, dtype=self.dtype)\n                inertiaVec[:3] = scale * loadInfo.scale * loadInfo.N\n                # Convert acceleration to global coordinate system\n                inertiaVec = loadInfo.cid_ref.transform_vector_to_global(inertiaVec)\n                self._addInertialLoad(auxElems, inertiaVec)\n\n            # Add any centrifugal loads\n            elif loadInfo.type == \"RFORCE\":\n                omegaVec = np.zeros(3, dtype=self.dtype)\n                if loadInfo.nid_ref:\n                    rotCenter = loadInfo.nid_ref.get_position()\n                else:\n                    rotCenter = np.zeros(3, dtype=self.dtype)\n                omegaVec[:3] = scale * loadInfo.scale * np.array(loadInfo.r123)\n                # Convert omega from rev/s to rad/s\n                omegaVec *= 2 * np.pi\n                # Convert omega to global coordinate system\n                omegaVec = loadInfo.cid_ref.transform_vector_to_global(omegaVec)\n                self._addCentrifugalLoad(auxElems, omegaVec, rotCenter)\n\n            # Add any pressure loads\n            # Pressure load card specific to shell elements\n            elif loadInfo.type == \"PLOAD2\":\n                elemIDs = loadInfo.eids\n                pressure = scale * loadInfo.pressure\n                self._addPressureToElements(\n                    auxElems, elemIDs, pressure, nastranOrdering=True\n                )\n\n            # Alternate more general pressure load type\n            elif loadInfo.type == \"PLOAD4\":\n                self._addPressureFromPLOAD4(auxElems, loadInfo, scale)\n\n            else:\n                self._TACSWarning(\n                    \"Unsupported load type \"\n                    f\" '{loadInfo.type}' specified for load set number {loadInfo.sid}, skipping load\"\n                )",
  "def _addPressureFromPLOAD4(self, auxElems, loadInfo, scale=1.0):\n        \"\"\"\n        Add pressure to tacs static/transient problem from pynastran PLOAD4 card.\n        Should only be called by createTACSProbsFromBDF and not directly by user.\n        \"\"\"\n        # Dictionary mapping nastran element face indices to TACS equivalent numbering\n        nastranToTACSFaceIDDict = {\n            \"CTETRA4\": {1: 1, 2: 3, 3: 2, 4: 0},\n            \"CTETRA\": {2: 1, 4: 3, 3: 2, 1: 0},\n            \"CHEXA\": {1: 4, 2: 2, 3: 1, 4: 3, 5: 0, 6: 5},\n        }\n\n        # We don't support pressure variation across elements, for now just average it\n        pressure = scale * np.mean(loadInfo.pressures)\n        for elemInfo in loadInfo.eids_ref:\n            elemID = elemInfo.eid\n\n            # Get the correct face index number based on element type\n            if \"CTETRA\" in elemInfo.type:\n                for faceIndex in elemInfo.faces:\n                    if (\n                        loadInfo.g1 in elemInfo.faces[faceIndex]\n                        and loadInfo.g34 not in elemInfo.faces[faceIndex]\n                    ):\n                        # For some reason CTETRA4 is the only element that doesn't\n                        # use ANSYS face numbering convention by default\n                        if len(elemInfo.nodes) == 4:\n                            faceIndex = nastranToTACSFaceIDDict[\"CTETRA4\"][faceIndex]\n                        else:\n                            faceIndex = nastranToTACSFaceIDDict[\"CTETRA\"][faceIndex]\n                        # Positive pressure is inward for solid elements, flip pressure if necessary\n                        # We don't flip it for face 0, because the normal for that face points inward by convention\n                        # while the rest point outward\n                        if faceIndex != 0:\n                            pressure *= -1.0\n                        break\n\n            elif \"CHEXA\" in elemInfo.type:\n                for faceIndex in elemInfo.faces:\n                    if (\n                        loadInfo.g1 in elemInfo.faces[faceIndex]\n                        and loadInfo.g34 in elemInfo.faces[faceIndex]\n                    ):\n                        faceIndex = nastranToTACSFaceIDDict[\"CHEXA\"][faceIndex]\n                        # Pressure orientation is flipped for solid elements per Nastran convention\n                        pressure *= -1.0\n                        break\n\n            elif \"CQUAD\" in elemInfo.type or \"CTRIA\" in elemInfo.type:\n                # Face index doesn't matter for shells, just use 0\n                faceIndex = 0\n\n            else:\n                raise self._TACSError(\n                    \"Unsupported element type \"\n                    f\"'{elemInfo.type}' specified for PLOAD4 load set number {loadInfo.sid}.\"\n                )\n\n            # Figure out whether or not this is a traction based on if a vector is defined\n            if np.linalg.norm(loadInfo.nvector) == 0.0:\n                self._addPressureToElements(\n                    auxElems, elemID, pressure, faceIndex, nastranOrdering=True\n                )\n            else:\n                trac = pressure * loadInfo.nvector\n                self._addTractionToElements(\n                    auxElems, elemID, trac, faceIndex, nastranOrdering=True\n                )",
  "def writeSensFile(self, evalFuncs, tacsAim):\n        \"\"\"\n        write an ESP/CAPS .sens file from the tacs aim\n        Optional tacs_aim arg for TacsAim wrapper class object in root/tacs/caps2tacs/\n\n        Parameters\n        ----------\n        evalFuncs : list[str]\n            names of TACS functions to be evaluated\n        tacsAim : tacs.caps2tacs.TacsAIM\n            class which handles the sensitivity file writing for ESP/CAPS shape derivatives\n\n        \"\"\"\n\n        # obtain the functions and sensitivities from TACS assembler\n        tacs_funcs = {}\n        tacs_sens = {}\n        self.evalFunctions(tacs_funcs, evalFuncs=evalFuncs)\n        self.evalFunctionsSens(tacs_sens, evalFuncs=evalFuncs)\n\n        num_funcs = len(evalFuncs)\n        assert tacsAim is not None\n        num_struct_dvs = len(tacsAim.thickness_variables)\n        num_nodes = self.meshLoader.bdfInfo.nnodes\n        node_ids = self.meshLoader.allLocalNodeIDs\n\n        if self.comm.rank == 0:\n            # open the sens file nastran_CAPS.sens and write coordinate derivatives\n            # and any other struct derivatives to it\n            with open(tacsAim.sens_file_path, \"w\") as hdl:\n                for func_name in evalFuncs:\n                    hdl.write(f\"{num_funcs} {num_struct_dvs}\\n\")\n\n                    # for each function write the values and coordinate derivatives\n                    for func_name in evalFuncs:\n                        # get the tacs key\n                        for tacs_key in tacs_funcs:\n                            if func_name in tacs_key:\n                                break\n\n                        # get the tacs coordinate derivatives\n                        xpts_sens = tacs_sens[tacs_key][\"Xpts\"]\n\n                        # write the func name, value and nnodes\n                        hdl.write(f\"{func_name}\\n\")\n                        hdl.write(f\"{tacs_funcs[tacs_key].real}\\n\")\n                        hdl.write(f\"{num_nodes}\\n\")\n\n                        # write the coordinate derivatives for the given function\n                        for bdf_ind in range(num_nodes):\n                            tacs_ind = node_ids[bdf_ind]\n                            nastran_node = bdf_ind + 1\n                            hdl.write(\n                                f\"{nastran_node} {xpts_sens[3*tacs_ind].real} {xpts_sens[3*tacs_ind+1].real} {xpts_sens[3*tacs_ind+2].real}\\n\"\n                            )\n\n                        # write any struct derivatives if there are struct derivatives\n                        if num_struct_dvs > 0:\n                            struct_sens = tacs_sens[tacs_key][\"struct\"]\n                            for idx, thick_var in enumerate(\n                                tacsAim.thickness_variables\n                            ):\n                                # assumes these are sorted in tacs aim wrapper\n                                hdl.write(f\"{thick_var.name}\\n\")\n                                hdl.write(\"1\\n\")\n                                hdl.write(f\"{struct_sens[idx].real}\\n\")\n            return",
  "class ModalProblem(TACSProblem):\n    # Default Option List\n    defaultOptions = {\n        \"outputDir\": [str, \"./\", \"Output directory for F5 file writer.\"],\n        # Solution Options\n        \"L2Convergence\": [\n            float,\n            1e-12,\n            \"Absolute convergence tolerance for Eigenvalue solver based on l2 norm of residual.\",\n        ],\n        \"L2ConvergenceRel\": [\n            float,\n            1e-12,\n            \"Relative convergence tolerance for Eigenvalue solver based on l2 norm of residual.\",\n        ],\n        \"RBEStiffnessScaleFactor\": [\n            float,\n            1e3,\n            \"Constraint matrix scaling factor used in RBE Lagrange multiplier stiffness matrix.\",\n        ],\n        \"RBEArtificialStiffness\": [\n            float,\n            1e-3,\n            \"Artificial constant added to diagonals of RBE Lagrange multiplier stiffness matrix \\n\"\n            \"\\t to stabilize preconditioner.\",\n        ],\n        \"subSpaceSize\": [\n            int,\n            10,\n            \"Subspace size for Krylov solver used by Eigenvalue solver.\",\n        ],\n        \"nRestarts\": [\n            int,\n            15,\n            \"Max number of resets for Krylov solver used by Eigenvalue solver.\",\n        ],\n        # Output Options\n        \"writeSolution\": [bool, True, \"Flag for suppressing all f5 file writing.\"],\n        \"numberSolutions\": [\n            bool,\n            True,\n            \"Flag for attaching solution counter index to f5 files.\",\n        ],\n        \"printTiming\": [\n            bool,\n            False,\n            \"Flag for printing out timing information for class procedures.\",\n        ],\n        \"printLevel\": [\n            int,\n            0,\n            \"Print level for Eigenvalue solver.\\n\"\n            \"\\t Accepts:\\n\"\n            \"\\t\\t   0 : No printing.\\n\"\n            \"\\t\\t   1 : Print major iterations.\\n\"\n            \"\\t\\t > 1 : Print major + minor iterations.\",\n        ],\n    }\n\n    def __init__(\n        self,\n        name,\n        sigma,\n        numEigs,\n        assembler,\n        comm,\n        outputViewer=None,\n        meshLoader=None,\n        options=None,\n    ):\n        \"\"\"\n        NOTE: This class should not be initialized directly by the user.\n        Use pyTACS.createModalProblem instead.\n\n        Parameters\n        ----------\n        name : str\n            Name of this tacs problem\n\n        sigma : float\n            Guess for the lowest eigenvalue. This corresponds to the lowest frequency squared. (rad^2/s^2)\n\n        numEigs : int\n            Number of eigenvalues to solve for\n\n        assembler : TACS.Assembler\n            Cython object responsible for creating and setting tacs objects used to solve problem\n\n        comm : mpi4py.MPI.Intracomm\n            The comm object on which to create the pyTACS object.\n\n        outputViewer : TACS.TACSToFH5\n            Cython object used to write out f5 files that can be converted and used for postprocessing.\n\n        meshLoader : pymeshloader.pyMeshLoader\n            pyMeshLoader object used to create the assembler.\n\n        options : dict\n            Dictionary holding problem-specific option parameters (case-insensitive).\n        \"\"\"\n\n        # Problem name\n        self.name = name\n\n        # Default setup for common problem class objects, sets up comm and options\n        TACSProblem.__init__(self, assembler, comm, options, outputViewer, meshLoader)\n\n        # Set time eigenvalue parameters\n        self.sigma = sigma\n        self.numEigs = numEigs\n\n        # String name used in evalFunctions\n        self.valName = \"eigsm\"\n        self._initializeFunctionList()\n\n        # Create problem-specific variables\n        self._createVariables()\n\n    def _createVariables(self):\n        \"\"\"\n        Internal to create the objects required by TACS Integrator\n        \"\"\"\n\n        self.callCounter = -1\n\n        # Solve the eigenvalue problem\n        self.M = self.assembler.createSchurMat()\n        self.K = self.assembler.createSchurMat()\n\n        self.pc = tacs.TACS.Pc(self.K)\n\n        # Set artificial stiffness factors in rbe class\n        c1 = self.getOption(\"RBEStiffnessScaleFactor\")\n        c2 = self.getOption(\"RBEArtificialStiffness\")\n        tacs.elements.RBE2.setScalingParameters(c1, c2)\n        tacs.elements.RBE3.setScalingParameters(c1, c2)\n\n        # Assemble and factor the stiffness/Jacobian matrix. Factor the\n        # Jacobian and solve the linear system for the displacements\n        self.assembler.assembleMatType(tacs.TACS.STIFFNESS_MATRIX, self.K)\n        self.assembler.assembleMatType(tacs.TACS.MASS_MATRIX, self.M)\n\n        subspace = self.getOption(\"subSpaceSize\")\n        restarts = self.getOption(\"nRestarts\")\n        self.gmres = tacs.TACS.KSM(self.K, self.pc, subspace, restarts)\n\n        atol = self.getOption(\"L2Convergence\")\n        rtol = self.getOption(\"L2ConvergenceRel\")\n\n        # Create the frequency analysis object\n        self.freqSolver = tacs.TACS.FrequencyAnalysis(\n            self.assembler,\n            self.sigma,\n            self.M,\n            self.K,\n            self.gmres,\n            num_eigs=self.numEigs,\n            eig_tol=atol,\n            eig_atol=atol,\n            eig_rtol=rtol,\n        )\n\n    def _initializeFunctionList(self):\n        \"\"\"\n        Create FunctionList dict which maps eigenvalue strings\n        to mode indices used in evalFunctions method.\n        \"\"\"\n        self.functionList = {}\n        for mode_i in range(self.numEigs):\n            self.functionList[f\"{self.valName}.{mode_i}\"] = mode_i\n\n    def setOption(self, name, value):\n        \"\"\"\n        Set a solver option value. The name is not case sensitive.\n\n        Parameters\n        ----------\n        name : str\n            Name of option to modify\n\n        value : depends on option\n            New option value to set\n        \"\"\"\n        # Default setOption for common problem class objects\n        TACSProblem.setOption(self, name, value)\n\n        # No need to reset solver for output options\n        if name.lower() in [\n            \"writesolution\",\n            \"printtiming\",\n            \"numbersolutions\",\n            \"outputdir\",\n        ]:\n            pass\n        # Reset solver for all other option changes\n        else:\n            self._createVariables()\n\n    def setValName(self, valName):\n        \"\"\"\n        Set a name for the eigenvalues. Only needs\n        to be changed if more than 1 pytacs object is used in an\n        optimization\n\n        Parameters\n        ----------\n        valName : str\n            Name of the eigenvalue output used in evalFunctions().\n        \"\"\"\n        self.valName = valName\n        self._initializeFunctionList()\n\n    def getNumEigs(self):\n        \"\"\"\n        Get the number of eigenvalues requested from solver for this problem.\n\n        Returns\n        ----------\n        numEigs : int\n            Number of eigenvalues.\n        \"\"\"\n        return self.numEigs\n\n    def addFunction(self, funcName, funcHandle, compIDs=None, **kwargs):\n        \"\"\"\n        NOT SUPPORTED FOR THIS PROBLEM\n        \"\"\"\n        self._TACSWarning(\"addFunction method not supported for this class.\")\n\n    def evalFunctions(self, funcs, evalFuncs=None, ignoreMissing=False):\n        \"\"\"\n        Evaluate eigenvalues for problem. The functions corresponding to\n        the integers in evalFuncs are evaluated and updated into\n        the provided dictionary.\n\n        Parameters\n        ----------\n        funcs : dict\n            Dictionary into which the functions are saved.\n        evalFuncs : iterable object containing strings.\n            If not none, use these functions to evaluate.\n        ignoreMissing : bool\n            Flag to supress checking for a valid function. Please use\n            this option with caution.\n\n        Examples\n        --------\n        >>> funcs = {}\n        >>> modalProblem.solve()\n        >>> modalProblem.evalFunctions(funcs, 'eigsm.0')\n        >>> funcs\n        >>> # Result will look like (if ModalProblem has name of 'c1'):\n        >>> # {'c1_eigsm.0':12354.10}\n        \"\"\"\n        # Make sure assembler variables are up to date\n        self._updateAssemblerVars()\n\n        # Check if user specified which eigvals to output\n        # Otherwise, output them all\n        if evalFuncs is None:\n            evalFuncs = self.functionList\n        else:\n            userFuncs = sorted(list(evalFuncs))\n            evalFuncs = {}\n            for func in userFuncs:\n                if func in self.functionList:\n                    evalFuncs[func] = self.functionList[func]\n\n        if not ignoreMissing:\n            for f in evalFuncs:\n                if f not in self.functionList:\n                    raise self._TACSError(\n                        f\"Supplied function '{f}' has not been added \"\n                        \"using addFunction().\"\n                    )\n\n        # Loop through each requested eigenvalue\n        for funcName in evalFuncs:\n            mode_i = evalFuncs[funcName]\n            key = f\"{self.name}_{funcName}\"\n            funcs[key], _ = self.getVariables(mode_i)\n\n    def evalFunctionsSens(self, funcsSens, evalFuncs=None):\n        \"\"\"\n        This is the main routine for returning useful (sensitivity)\n        information from problem. The derivatives of the functions\n        corresponding to the strings in evalFuncs are evaluated and\n        updated into the provided dictionary. The derivitives with\n        respect to all design variables and node locations are computed.\n\n        Parameters\n        ----------\n        funcsSens : dict\n            Dictionary into which the derivatives are saved.\n        evalFuncs : iterable object containing strings\n            The functions the user wants returned\n\n        Examples\n        --------\n        >>> funcsSens = {}\n        >>> modalProblem.evalFunctionsSens(funcsSens, 'eigsm.0')\n        >>> funcsSens\n        >>> # Result will look like (if ModalProblem has name of 'c1'):\n        >>> # {'c1_eigsm.0':{'struct':[1.234, ..., 7.89], 'Xpts':[3.14, ..., 1.59]}}\n        \"\"\"\n        # Make sure assembler variables are up to date\n        self._updateAssemblerVars()\n\n        # Check if user specified which eigvals to output\n        # Otherwise, output them all\n        if evalFuncs is None:\n            evalFuncs = self.functionList\n        else:\n            userFuncs = sorted(list(evalFuncs))\n            evalFuncs = {}\n            for func in userFuncs:\n                if func in self.functionList:\n                    evalFuncs[func] = self.functionList[func]\n\n        dvSens = self.assembler.createDesignVec()\n        xptSens = self.assembler.createNodeVec()\n\n        # Loop through each requested eigenvalue\n        for funcName in evalFuncs:\n            mode_i = evalFuncs[funcName]\n            key = f\"{self.name}_{funcName}\"\n            funcsSens[key] = {}\n            # Evaluate dv sens\n            self.freqSolver.evalEigenDVSens(mode_i, dvSens)\n            funcsSens[key][self.varName] = dvSens.getArray().copy()\n            # Evaluate nodal sens\n            self.freqSolver.evalEigenXptSens(mode_i, xptSens)\n            funcsSens[key][self.coordName] = xptSens.getArray().copy()\n\n    ####### Modal solver methods ########\n\n    def _updateAssemblerVars(self):\n        \"\"\"\n        Make sure that the assembler is using\n        the input variables associated with this problem\n        \"\"\"\n\n        self.assembler.setDesignVars(self.x)\n        self.assembler.setNodes(self.Xpts)\n        # Make sure previous auxiliary loads are removed\n        self.assembler.setAuxElements(None)\n        # Set artificial stiffness factors in rbe class\n        c1 = self.getOption(\"RBEStiffnessScaleFactor\")\n        c2 = self.getOption(\"RBEArtificialStiffness\")\n        tacs.elements.RBE2.setScalingParameters(c1, c2)\n        tacs.elements.RBE3.setScalingParameters(c1, c2)\n\n    def solve(self):\n        \"\"\"\n        Solve the eigenvalue problem.\n        \"\"\"\n        startTime = time.time()\n\n        self.callCounter += 1\n\n        setupProblemTime = time.time()\n\n        # Set problem vars to assembler\n        self._updateAssemblerVars()\n\n        initSolveTime = time.time()\n\n        # Solve the frequency analysis problem\n        self.freqSolver.solve(\n            print_flag=self.getOption(\"printLevel\"),\n            print_level=self.getOption(\"printLevel\"),\n        )\n\n        solveTime = time.time()\n\n        # If timing was was requested print it, if the solution is nonlinear\n        # print this information automatically if prinititerations was requested.\n        if self.getOption(\"printTiming\"):\n            self._pp(\"+--------------------------------------------------+\")\n            self._pp(\"|\")\n            self._pp(\"| TACS Solve Times:\")\n            self._pp(\"|\")\n            self._pp(\n                \"| %-30s: %10.3f sec\"\n                % (\"TACS Setup Time\", setupProblemTime - startTime)\n            )\n            self._pp(\n                \"| %-30s: %10.3f sec\"\n                % (\"TACS Solve Init Time\", initSolveTime - setupProblemTime)\n            )\n            self._pp(\n                \"| %-30s: %10.3f sec\" % (\"TACS Solve Time\", solveTime - initSolveTime)\n            )\n            self._pp(\"|\")\n            self._pp(\n                \"| %-30s: %10.3f sec\"\n                % (\"TACS Total Solution Time\", solveTime - startTime)\n            )\n            self._pp(\"+--------------------------------------------------+\")\n\n        return\n\n    def getVariables(self, index, states=None):\n        \"\"\"\n        Return the current state values for one mode of the current problem\n\n        Parameters\n        ----------\n        index : int\n            Mode index to return solution for.\n\n        states : tacs.TACS.Vec or numpy.ndarray or None\n            Place eigenvector for mode into this array (optional).\n\n        Returns\n        --------\n        eigVal: float\n            Eigenvalue for mode corresponds to square of eigenfrequency (rad^2/s^2)\n\n        states : numpy.ndarray\n            Eigenvector for mode\n        \"\"\"\n        eigVal, err = self.freqSolver.extractEigenvalue(index)\n        eigVector = self.assembler.createVec()\n        self.freqSolver.extractEigenvector(index, eigVector)\n        # Inplace assignment if vectors were provided\n        if isinstance(states, tacs.TACS.Vec):\n            states.copyValues(eigVector)\n        elif isinstance(states, np.ndarray):\n            states[:] = eigVector.getArray()\n        return eigVal, eigVector.getArray()\n\n    def writeSolution(self, outputDir=None, baseName=None, number=None, indices=None):\n        \"\"\"\n        This is a generic shell function that writes the output\n        file(s).  The intent is that the user or calling program can\n        call this function and pyTACS writes all the files that the\n        user has defined. It is recommended that this function is used\n        along with the associated logical flags in the options to\n        determine the desired writing procedure\n\n        Parameters\n        ----------\n        outputDir : str or None\n            Use the supplied output directory\n        baseName : str or None\n            Use this supplied string for the base filename. Typically\n            only used from an external solver.\n        number : int or None\n            Use the user supplied number to index solution. Again, only\n            typically used from an external solver\n        indices : int or list[int] or None\n            Mode index or indices to get state variables for.\n            If None, returns a solution for all modes.\n            Defaults to None.\n        \"\"\"\n        # Make sure assembler variables are up-to-date\n        self._updateAssemblerVars()\n\n        # Check input\n        if outputDir is None:\n            outputDir = self.getOption(\"outputDir\")\n\n        if baseName is None:\n            baseName = self.name\n\n        # If we are numbering solution, it saving the sequence of\n        # calls, add the call number\n        if number is not None:\n            # We need number based on the provided number:\n            baseName = baseName + \"_%3.3d\" % number\n        else:\n            # if number is none, i.e. standalone, but we need to\n            # number solutions, use internal counter\n            if self.getOption(\"numberSolutions\"):\n                baseName = baseName + \"_%3.3d\" % self.callCounter\n\n        # Unless the writeSolution option is off write actual file:\n        if self.getOption(\"writeSolution\"):\n            # If indices is None, output all modes\n            if indices is None:\n                indices = np.arange(self.numEigs)\n\n            # Write out each specified mode\n            indices = np.atleast_1d(indices)\n            vec = self.assembler.createVec()\n            for index in indices:\n                # Extract eigenvector\n                eig, _ = self.getVariables(index, states=vec)\n                # Set eigen mode in assembler\n                self.assembler.setVariables(vec)\n                # Write out mode shape as f5 file\n                modeName = baseName + \"_%3.3d\" % index\n                fileName = os.path.join(outputDir, modeName) + \".f5\"\n                self.outputViewer.writeToFile(fileName)",
  "def __init__(\n        self,\n        name,\n        sigma,\n        numEigs,\n        assembler,\n        comm,\n        outputViewer=None,\n        meshLoader=None,\n        options=None,\n    ):\n        \"\"\"\n        NOTE: This class should not be initialized directly by the user.\n        Use pyTACS.createModalProblem instead.\n\n        Parameters\n        ----------\n        name : str\n            Name of this tacs problem\n\n        sigma : float\n            Guess for the lowest eigenvalue. This corresponds to the lowest frequency squared. (rad^2/s^2)\n\n        numEigs : int\n            Number of eigenvalues to solve for\n\n        assembler : TACS.Assembler\n            Cython object responsible for creating and setting tacs objects used to solve problem\n\n        comm : mpi4py.MPI.Intracomm\n            The comm object on which to create the pyTACS object.\n\n        outputViewer : TACS.TACSToFH5\n            Cython object used to write out f5 files that can be converted and used for postprocessing.\n\n        meshLoader : pymeshloader.pyMeshLoader\n            pyMeshLoader object used to create the assembler.\n\n        options : dict\n            Dictionary holding problem-specific option parameters (case-insensitive).\n        \"\"\"\n\n        # Problem name\n        self.name = name\n\n        # Default setup for common problem class objects, sets up comm and options\n        TACSProblem.__init__(self, assembler, comm, options, outputViewer, meshLoader)\n\n        # Set time eigenvalue parameters\n        self.sigma = sigma\n        self.numEigs = numEigs\n\n        # String name used in evalFunctions\n        self.valName = \"eigsm\"\n        self._initializeFunctionList()\n\n        # Create problem-specific variables\n        self._createVariables()",
  "def _createVariables(self):\n        \"\"\"\n        Internal to create the objects required by TACS Integrator\n        \"\"\"\n\n        self.callCounter = -1\n\n        # Solve the eigenvalue problem\n        self.M = self.assembler.createSchurMat()\n        self.K = self.assembler.createSchurMat()\n\n        self.pc = tacs.TACS.Pc(self.K)\n\n        # Set artificial stiffness factors in rbe class\n        c1 = self.getOption(\"RBEStiffnessScaleFactor\")\n        c2 = self.getOption(\"RBEArtificialStiffness\")\n        tacs.elements.RBE2.setScalingParameters(c1, c2)\n        tacs.elements.RBE3.setScalingParameters(c1, c2)\n\n        # Assemble and factor the stiffness/Jacobian matrix. Factor the\n        # Jacobian and solve the linear system for the displacements\n        self.assembler.assembleMatType(tacs.TACS.STIFFNESS_MATRIX, self.K)\n        self.assembler.assembleMatType(tacs.TACS.MASS_MATRIX, self.M)\n\n        subspace = self.getOption(\"subSpaceSize\")\n        restarts = self.getOption(\"nRestarts\")\n        self.gmres = tacs.TACS.KSM(self.K, self.pc, subspace, restarts)\n\n        atol = self.getOption(\"L2Convergence\")\n        rtol = self.getOption(\"L2ConvergenceRel\")\n\n        # Create the frequency analysis object\n        self.freqSolver = tacs.TACS.FrequencyAnalysis(\n            self.assembler,\n            self.sigma,\n            self.M,\n            self.K,\n            self.gmres,\n            num_eigs=self.numEigs,\n            eig_tol=atol,\n            eig_atol=atol,\n            eig_rtol=rtol,\n        )",
  "def _initializeFunctionList(self):\n        \"\"\"\n        Create FunctionList dict which maps eigenvalue strings\n        to mode indices used in evalFunctions method.\n        \"\"\"\n        self.functionList = {}\n        for mode_i in range(self.numEigs):\n            self.functionList[f\"{self.valName}.{mode_i}\"] = mode_i",
  "def setOption(self, name, value):\n        \"\"\"\n        Set a solver option value. The name is not case sensitive.\n\n        Parameters\n        ----------\n        name : str\n            Name of option to modify\n\n        value : depends on option\n            New option value to set\n        \"\"\"\n        # Default setOption for common problem class objects\n        TACSProblem.setOption(self, name, value)\n\n        # No need to reset solver for output options\n        if name.lower() in [\n            \"writesolution\",\n            \"printtiming\",\n            \"numbersolutions\",\n            \"outputdir\",\n        ]:\n            pass\n        # Reset solver for all other option changes\n        else:\n            self._createVariables()",
  "def setValName(self, valName):\n        \"\"\"\n        Set a name for the eigenvalues. Only needs\n        to be changed if more than 1 pytacs object is used in an\n        optimization\n\n        Parameters\n        ----------\n        valName : str\n            Name of the eigenvalue output used in evalFunctions().\n        \"\"\"\n        self.valName = valName\n        self._initializeFunctionList()",
  "def getNumEigs(self):\n        \"\"\"\n        Get the number of eigenvalues requested from solver for this problem.\n\n        Returns\n        ----------\n        numEigs : int\n            Number of eigenvalues.\n        \"\"\"\n        return self.numEigs",
  "def addFunction(self, funcName, funcHandle, compIDs=None, **kwargs):\n        \"\"\"\n        NOT SUPPORTED FOR THIS PROBLEM\n        \"\"\"\n        self._TACSWarning(\"addFunction method not supported for this class.\")",
  "def evalFunctions(self, funcs, evalFuncs=None, ignoreMissing=False):\n        \"\"\"\n        Evaluate eigenvalues for problem. The functions corresponding to\n        the integers in evalFuncs are evaluated and updated into\n        the provided dictionary.\n\n        Parameters\n        ----------\n        funcs : dict\n            Dictionary into which the functions are saved.\n        evalFuncs : iterable object containing strings.\n            If not none, use these functions to evaluate.\n        ignoreMissing : bool\n            Flag to supress checking for a valid function. Please use\n            this option with caution.\n\n        Examples\n        --------\n        >>> funcs = {}\n        >>> modalProblem.solve()\n        >>> modalProblem.evalFunctions(funcs, 'eigsm.0')\n        >>> funcs\n        >>> # Result will look like (if ModalProblem has name of 'c1'):\n        >>> # {'c1_eigsm.0':12354.10}\n        \"\"\"\n        # Make sure assembler variables are up to date\n        self._updateAssemblerVars()\n\n        # Check if user specified which eigvals to output\n        # Otherwise, output them all\n        if evalFuncs is None:\n            evalFuncs = self.functionList\n        else:\n            userFuncs = sorted(list(evalFuncs))\n            evalFuncs = {}\n            for func in userFuncs:\n                if func in self.functionList:\n                    evalFuncs[func] = self.functionList[func]\n\n        if not ignoreMissing:\n            for f in evalFuncs:\n                if f not in self.functionList:\n                    raise self._TACSError(\n                        f\"Supplied function '{f}' has not been added \"\n                        \"using addFunction().\"\n                    )\n\n        # Loop through each requested eigenvalue\n        for funcName in evalFuncs:\n            mode_i = evalFuncs[funcName]\n            key = f\"{self.name}_{funcName}\"\n            funcs[key], _ = self.getVariables(mode_i)",
  "def evalFunctionsSens(self, funcsSens, evalFuncs=None):\n        \"\"\"\n        This is the main routine for returning useful (sensitivity)\n        information from problem. The derivatives of the functions\n        corresponding to the strings in evalFuncs are evaluated and\n        updated into the provided dictionary. The derivitives with\n        respect to all design variables and node locations are computed.\n\n        Parameters\n        ----------\n        funcsSens : dict\n            Dictionary into which the derivatives are saved.\n        evalFuncs : iterable object containing strings\n            The functions the user wants returned\n\n        Examples\n        --------\n        >>> funcsSens = {}\n        >>> modalProblem.evalFunctionsSens(funcsSens, 'eigsm.0')\n        >>> funcsSens\n        >>> # Result will look like (if ModalProblem has name of 'c1'):\n        >>> # {'c1_eigsm.0':{'struct':[1.234, ..., 7.89], 'Xpts':[3.14, ..., 1.59]}}\n        \"\"\"\n        # Make sure assembler variables are up to date\n        self._updateAssemblerVars()\n\n        # Check if user specified which eigvals to output\n        # Otherwise, output them all\n        if evalFuncs is None:\n            evalFuncs = self.functionList\n        else:\n            userFuncs = sorted(list(evalFuncs))\n            evalFuncs = {}\n            for func in userFuncs:\n                if func in self.functionList:\n                    evalFuncs[func] = self.functionList[func]\n\n        dvSens = self.assembler.createDesignVec()\n        xptSens = self.assembler.createNodeVec()\n\n        # Loop through each requested eigenvalue\n        for funcName in evalFuncs:\n            mode_i = evalFuncs[funcName]\n            key = f\"{self.name}_{funcName}\"\n            funcsSens[key] = {}\n            # Evaluate dv sens\n            self.freqSolver.evalEigenDVSens(mode_i, dvSens)\n            funcsSens[key][self.varName] = dvSens.getArray().copy()\n            # Evaluate nodal sens\n            self.freqSolver.evalEigenXptSens(mode_i, xptSens)\n            funcsSens[key][self.coordName] = xptSens.getArray().copy()",
  "def _updateAssemblerVars(self):\n        \"\"\"\n        Make sure that the assembler is using\n        the input variables associated with this problem\n        \"\"\"\n\n        self.assembler.setDesignVars(self.x)\n        self.assembler.setNodes(self.Xpts)\n        # Make sure previous auxiliary loads are removed\n        self.assembler.setAuxElements(None)\n        # Set artificial stiffness factors in rbe class\n        c1 = self.getOption(\"RBEStiffnessScaleFactor\")\n        c2 = self.getOption(\"RBEArtificialStiffness\")\n        tacs.elements.RBE2.setScalingParameters(c1, c2)\n        tacs.elements.RBE3.setScalingParameters(c1, c2)",
  "def solve(self):\n        \"\"\"\n        Solve the eigenvalue problem.\n        \"\"\"\n        startTime = time.time()\n\n        self.callCounter += 1\n\n        setupProblemTime = time.time()\n\n        # Set problem vars to assembler\n        self._updateAssemblerVars()\n\n        initSolveTime = time.time()\n\n        # Solve the frequency analysis problem\n        self.freqSolver.solve(\n            print_flag=self.getOption(\"printLevel\"),\n            print_level=self.getOption(\"printLevel\"),\n        )\n\n        solveTime = time.time()\n\n        # If timing was was requested print it, if the solution is nonlinear\n        # print this information automatically if prinititerations was requested.\n        if self.getOption(\"printTiming\"):\n            self._pp(\"+--------------------------------------------------+\")\n            self._pp(\"|\")\n            self._pp(\"| TACS Solve Times:\")\n            self._pp(\"|\")\n            self._pp(\n                \"| %-30s: %10.3f sec\"\n                % (\"TACS Setup Time\", setupProblemTime - startTime)\n            )\n            self._pp(\n                \"| %-30s: %10.3f sec\"\n                % (\"TACS Solve Init Time\", initSolveTime - setupProblemTime)\n            )\n            self._pp(\n                \"| %-30s: %10.3f sec\" % (\"TACS Solve Time\", solveTime - initSolveTime)\n            )\n            self._pp(\"|\")\n            self._pp(\n                \"| %-30s: %10.3f sec\"\n                % (\"TACS Total Solution Time\", solveTime - startTime)\n            )\n            self._pp(\"+--------------------------------------------------+\")\n\n        return",
  "def getVariables(self, index, states=None):\n        \"\"\"\n        Return the current state values for one mode of the current problem\n\n        Parameters\n        ----------\n        index : int\n            Mode index to return solution for.\n\n        states : tacs.TACS.Vec or numpy.ndarray or None\n            Place eigenvector for mode into this array (optional).\n\n        Returns\n        --------\n        eigVal: float\n            Eigenvalue for mode corresponds to square of eigenfrequency (rad^2/s^2)\n\n        states : numpy.ndarray\n            Eigenvector for mode\n        \"\"\"\n        eigVal, err = self.freqSolver.extractEigenvalue(index)\n        eigVector = self.assembler.createVec()\n        self.freqSolver.extractEigenvector(index, eigVector)\n        # Inplace assignment if vectors were provided\n        if isinstance(states, tacs.TACS.Vec):\n            states.copyValues(eigVector)\n        elif isinstance(states, np.ndarray):\n            states[:] = eigVector.getArray()\n        return eigVal, eigVector.getArray()",
  "def writeSolution(self, outputDir=None, baseName=None, number=None, indices=None):\n        \"\"\"\n        This is a generic shell function that writes the output\n        file(s).  The intent is that the user or calling program can\n        call this function and pyTACS writes all the files that the\n        user has defined. It is recommended that this function is used\n        along with the associated logical flags in the options to\n        determine the desired writing procedure\n\n        Parameters\n        ----------\n        outputDir : str or None\n            Use the supplied output directory\n        baseName : str or None\n            Use this supplied string for the base filename. Typically\n            only used from an external solver.\n        number : int or None\n            Use the user supplied number to index solution. Again, only\n            typically used from an external solver\n        indices : int or list[int] or None\n            Mode index or indices to get state variables for.\n            If None, returns a solution for all modes.\n            Defaults to None.\n        \"\"\"\n        # Make sure assembler variables are up-to-date\n        self._updateAssemblerVars()\n\n        # Check input\n        if outputDir is None:\n            outputDir = self.getOption(\"outputDir\")\n\n        if baseName is None:\n            baseName = self.name\n\n        # If we are numbering solution, it saving the sequence of\n        # calls, add the call number\n        if number is not None:\n            # We need number based on the provided number:\n            baseName = baseName + \"_%3.3d\" % number\n        else:\n            # if number is none, i.e. standalone, but we need to\n            # number solutions, use internal counter\n            if self.getOption(\"numberSolutions\"):\n                baseName = baseName + \"_%3.3d\" % self.callCounter\n\n        # Unless the writeSolution option is off write actual file:\n        if self.getOption(\"writeSolution\"):\n            # If indices is None, output all modes\n            if indices is None:\n                indices = np.arange(self.numEigs)\n\n            # Write out each specified mode\n            indices = np.atleast_1d(indices)\n            vec = self.assembler.createVec()\n            for index in indices:\n                # Extract eigenvector\n                eig, _ = self.getVariables(index, states=vec)\n                # Set eigen mode in assembler\n                self.assembler.setVariables(vec)\n                # Write out mode shape as f5 file\n                modeName = baseName + \"_%3.3d\" % index\n                fileName = os.path.join(outputDir, modeName) + \".f5\"\n                self.outputViewer.writeToFile(fileName)",
  "class BucklingProblem(TACSProblem):\n    # Default Option List\n    defaultOptions = {\n        \"outputDir\": [str, \"./\", \"Output directory for F5 file writer.\"],\n        # Solution Options\n        \"L2Convergence\": [\n            float,\n            1e-12,\n            \"Absolute convergence tolerance for Eigenvalue solver based on l2 norm of residual.\",\n        ],\n        \"L2ConvergenceRel\": [\n            float,\n            1e-12,\n            \"Relative convergence tolerance for Eigenvalue solver based on l2 norm of residual.\",\n        ],\n        \"RBEStiffnessScaleFactor\": [\n            float,\n            1e3,\n            \"Constraint matrix scaling factor used in RBE Lagrange multiplier stiffness matrix.\",\n        ],\n        \"RBEArtificialStiffness\": [\n            float,\n            1e-3,\n            \"Artificial constant added to diagonals of RBE Lagrange multiplier stiffness matrix \\n\"\n            \"\\t to stabilize preconditioner.\",\n        ],\n        \"subSpaceSize\": [\n            int,\n            10,\n            \"Subspace size for Krylov solver used by Eigenvalue solver.\",\n        ],\n        \"nRestarts\": [\n            int,\n            15,\n            \"Max number of resets for Krylov solver used by Eigenvalue solver.\",\n        ],\n        # Output Options\n        \"writeSolution\": [bool, True, \"Flag for suppressing all f5 file writing.\"],\n        \"numberSolutions\": [\n            bool,\n            True,\n            \"Flag for attaching solution counter index to f5 files.\",\n        ],\n        \"printTiming\": [\n            bool,\n            False,\n            \"Flag for printing out timing information for class procedures.\",\n        ],\n        \"printLevel\": [\n            int,\n            0,\n            \"Print level for Eigenvalue solver.\\n\"\n            \"\\t Accepts:\\n\"\n            \"\\t\\t   0 : No printing.\\n\"\n            \"\\t\\t   1 : Print major iterations.\\n\"\n            \"\\t\\t > 1 : Print major + minor iterations.\",\n        ],\n    }\n\n    def __init__(\n        self,\n        name,\n        sigma,\n        numEigs,\n        assembler,\n        comm,\n        outputViewer=None,\n        meshLoader=None,\n        options=None,\n    ):\n        \"\"\"\n        NOTE: This class should not be initialized directly by the user.\n        Use pyTACS.createBucklingProblem instead.\n\n        Parameters\n        ----------\n        name : str\n            Name of this tacs problem\n\n        sigma : float\n            Guess for the lowest eigenvalue. This corresponds to the lowest buckling load factor.\n\n        numEigs : int\n            Number of eigenvalues to solve for\n\n        assembler : TACS.Assembler\n            Cython object responsible for creating and setting tacs objects used to solve problem\n\n        comm : mpi4py.MPI.Intracomm\n            The comm object on which to create the pyTACS object.\n\n        outputViewer : TACS.TACSToFH5\n            Cython object used to write out f5 files that can be converted and used for postprocessing.\n\n        meshLoader : pymeshloader.pyMeshLoader\n            pyMeshLoader object used to create the assembler.\n\n        options : dict\n            Dictionary holding problem-specific option parameters (case-insensitive).\n        \"\"\"\n\n        # Problem name\n        self.name = name\n\n        # Default setup for common problem class objects, sets up comm and options\n        TACSProblem.__init__(self, assembler, comm, options, outputViewer, meshLoader)\n\n        # Set time eigenvalue parameters\n        self.sigma = sigma\n        self.numEigs = numEigs\n\n        # String name used in evalFunctions\n        self.valName = \"eigsb\"\n        self._initializeFunctionList()\n\n        # Create problem-specific variables\n        self._createVariables()\n\n    def _createVariables(self):\n        \"\"\"\n        Internal to create the objects required by TACS Integrator\n        \"\"\"\n\n        self.callCounter = -1\n\n        # Buckling load state\n        self.u0 = self.assembler.createVec()\n        # Load vector\n        self.F = self.assembler.createVec()\n        self.F_array = self.F.getArray()\n        # RHS vector\n        self.rhs = self.assembler.createVec()\n        # Auxiliary element object for applying tractions/pressure\n        self.auxElems = tacs.TACS.AuxElements()\n\n        self.aux = self.assembler.createSchurMat()\n        self.G = self.assembler.createSchurMat()\n        self.K = self.assembler.createSchurMat()\n\n        self.pc = tacs.TACS.Pc(self.K)\n\n        # Set artificial stiffness factors in rbe class\n        c1 = self.getOption(\"RBEStiffnessScaleFactor\")\n        c2 = self.getOption(\"RBEArtificialStiffness\")\n        tacs.elements.RBE2.setScalingParameters(c1, c2)\n        tacs.elements.RBE3.setScalingParameters(c1, c2)\n\n        # Assemble and factor the stiffness/Jacobian matrix. Factor the\n        # Jacobian and solve the linear system for the displacements\n        self.assembler.assembleMatType(tacs.TACS.STIFFNESS_MATRIX, self.K)\n        self.assembler.assembleMatType(tacs.TACS.GEOMETRIC_STIFFNESS_MATRIX, self.G)\n\n        subspace = self.getOption(\"subSpaceSize\")\n        restarts = self.getOption(\"nRestarts\")\n        atol = self.getOption(\"L2Convergence\")\n        rtol = self.getOption(\"L2ConvergenceRel\")\n        self.gmres = tacs.TACS.KSM(self.aux, self.pc, subspace, restarts)\n        self.gmres.setTolerances(rtol, atol)\n\n        # Create the buckling analysis object\n        self.buckleSolver = tacs.TACS.BucklingAnalysis(\n            self.assembler,\n            self.sigma,\n            self.G,\n            self.K,\n            self.gmres,\n            num_eigs=self.numEigs,\n            eig_tol=rtol,\n        )\n\n    def _initializeFunctionList(self):\n        \"\"\"\n        Create FunctionList dict which maps eigenvalue strings\n        to mode indices used in evalFunctions method.\n        \"\"\"\n        self.functionList = {}\n        for mode_i in range(self.numEigs):\n            self.functionList[f\"{self.valName}.{mode_i}\"] = mode_i\n\n    def setOption(self, name, value):\n        \"\"\"\n        Set a solver option value. The name is not case sensitive.\n\n        Parameters\n        ----------\n        name : str\n            Name of option to modify\n\n        value : depends on option\n            New option value to set\n        \"\"\"\n        # Default setOption for common problem class objects\n        TACSProblem.setOption(self, name, value)\n\n        # No need to reset solver for output options\n        if name.lower() in [\n            \"writesolution\",\n            \"printtiming\",\n            \"numbersolutions\",\n            \"outputdir\",\n        ]:\n            pass\n        # Reset solver for all other option changes\n        else:\n            self._createVariables()\n\n    def setValName(self, valName):\n        \"\"\"\n        Set a name for the eigenvalues. Only needs\n        to be changed if more than 1 pytacs object is used in an\n        optimization\n\n        Parameters\n        ----------\n        valName : str\n            Name of the eigenvalue output used in evalFunctions().\n        \"\"\"\n        self.valName = valName\n        self._initializeFunctionList()\n\n    def getNumEigs(self):\n        \"\"\"\n        Get the number of eigenvalues requested from solver for this problem.\n\n        Returns\n        ----------\n        numEigs : int\n            Number of eigenvalues.\n        \"\"\"\n        return self.numEigs\n\n    def addFunction(self, funcName, funcHandle, compIDs=None, **kwargs):\n        \"\"\"\n        NOT SUPPORTED FOR THIS PROBLEM\n        \"\"\"\n        self._TACSWarning(\"addFunction method not supported for this class.\")\n\n    def evalFunctions(self, funcs, evalFuncs=None, ignoreMissing=False):\n        \"\"\"\n        Evaluate eigenvalues for problem. The functions corresponding to\n        the integers in evalFuncs are evaluated and updated into\n        the provided dictionary.\n\n        Parameters\n        ----------\n        funcs : dict\n            Dictionary into which the functions are saved.\n        evalFuncs : iterable object containing strings.\n            If not none, use these functions to evaluate.\n        ignoreMissing : bool\n            Flag to supress checking for a valid function. Please use\n            this option with caution.\n\n        Examples\n        --------\n        >>> funcs = {}\n        >>> bucklingProblem.solve()\n        >>> bucklingProblem.evalFunctions(funcs, 'eigsm.0')\n        >>> funcs\n        >>> # Result will look like (if bucklingProblem has name of 'c1'):\n        >>> # {'c1_eigsm.0':12354.10}\n        \"\"\"\n        # Make sure assembler variables are up to date\n        self._updateAssemblerVars()\n\n        # Check if user specified which eigvals to output\n        # Otherwise, output them all\n        if evalFuncs is None:\n            evalFuncs = self.functionList\n        else:\n            userFuncs = sorted(list(evalFuncs))\n            evalFuncs = {}\n            for func in userFuncs:\n                if func in self.functionList:\n                    evalFuncs[func] = self.functionList[func]\n\n        if not ignoreMissing:\n            for f in evalFuncs:\n                if f not in self.functionList:\n                    raise self._TACSError(\n                        f\"Supplied function '{f}' has not been added \"\n                        \"using addFunction().\"\n                    )\n\n        # Loop through each requested eigenvalue\n        for funcName in evalFuncs:\n            mode_i = evalFuncs[funcName]\n            key = f\"{self.name}_{funcName}\"\n            funcs[key], _ = self.getVariables(mode_i)\n\n    def evalFunctionsSens(self, funcsSens, evalFuncs=None):\n        \"\"\"\n        This is the main routine for returning useful (sensitivity)\n        information from problem. The derivatives of the functions\n        corresponding to the strings in evalFuncs are evaluated and\n        updated into the provided dictionary. The derivitives with\n        respect to all design variables and node locations are computed.\n\n        Parameters\n        ----------\n        funcsSens : dict\n            Dictionary into which the derivatives are saved.\n        evalFuncs : iterable object containing strings\n            The functions the user wants returned\n\n        Examples\n        --------\n        >>> funcsSens = {}\n        >>> bucklingProblem.evalFunctionsSens(funcsSens, 'eigsm.0')\n        >>> funcsSens\n        >>> # Result will look like (if bucklingProblem has name of 'c1'):\n        >>> # {'c1_eigsm.0':{'struct':[1.234, ..., 7.89], 'Xpts':[3.14, ..., 1.59]}}\n        \"\"\"\n        # Make sure assembler variables are up to date\n        self._updateAssemblerVars()\n\n        # Check if user specified which eigvals to output\n        # Otherwise, output them all\n        if evalFuncs is None:\n            evalFuncs = self.functionList\n        else:\n            userFuncs = sorted(list(evalFuncs))\n            evalFuncs = {}\n            for func in userFuncs:\n                if func in self.functionList:\n                    evalFuncs[func] = self.functionList[func]\n\n        dvSens = self.assembler.createDesignVec()\n        xptSens = self.assembler.createNodeVec()\n\n        indices = [evalFuncs[funcName] for funcName in evalFuncs]\n        dvSensList = [self.assembler.createDesignVec() for funcName in evalFuncs]\n        xptSensList = [self.assembler.createNodeVec() for funcName in evalFuncs]\n        svSensList = [self.assembler.createVec() for funcName in evalFuncs]\n        adjointList = [self.assembler.createVec() for funcName in evalFuncs]\n\n        self.addDVSens(indices, dvSensList, scale=1.0)\n        self.addXptSens(indices, xptSensList, scale=1.0)\n        self.evalSVSens(indices, svSensList)\n\n        self.aux.copyValues(self.K)\n        self.pc.factor()\n\n        # Loop through each requested eigenvalue\n        for i, funcName in enumerate(evalFuncs):\n            rhs = svSensList[i]\n            adjoint = adjointList[i]\n            self.gmres.solve(rhs, adjoint)\n\n            # Evaluate adjoint contribution to nodal sens\n            xptSens = xptSensList[i]\n            self.assembler.addAdjointResXptSensProducts([adjoint], [xptSens], -1.0)\n            xptSens.beginSetValues()\n            xptSens.endSetValues()\n            # Evaluate adjoint contribution to dv sens\n            dvSens = dvSensList[i]\n            self.assembler.addAdjointResProducts([adjoint], [dvSens], -1.0)\n            dvSens.beginSetValues()\n            dvSens.endSetValues()\n\n            key = f\"{self.name}_{funcName}\"\n            funcsSens[key] = {}\n            funcsSens[key][self.varName] = dvSens.getArray().copy()\n            funcsSens[key][self.coordName] = xptSens.getArray().copy()\n\n    def addLoadToComponents(self, compIDs, F, averageLoad=False):\n        \"\"\"\n        This method is used to add a *FIXED TOTAL LOAD* on one or more\n        components, defined by COMPIDs. The purpose of this routine is to add loads that\n        remain fixed throughout an optimization. An example would be an engine load.\n        This routine determines all the unique nodes in the FE model that are part of the\n        requested components, then takes the total 'force' by F and divides by the\n        number of nodes. This average load is then applied to the nodes.\n\n        Parameters\n        ----------\n\n        compIDs : list[int] or int\n            The components with added loads. Use pyTACS selectCompIDs method\n            to determine this.\n\n        F : numpy.ndarray 1d or 2d length (varsPerNodes) or (numCompIDs, varsPerNodes)\n            Vector(s) of 'force' to apply to each component.  If only one force vector is provided,\n            force will be copied uniformly across all components.\n\n        averageLoad : bool\n            Flag to determine whether load should be split evenly across all components (True)\n            or copied and applied individually to each component (False). Defaults to False.\n\n        Notes\n        -----\n\n        The units of the entries of the 'force' vector F are not\n        necessarily physical forces and their interpretation depends\n        on the physics problem being solved and the dofs included\n        in the model.\n\n        A couple of examples of force vector components for common problems are listed below:\n\n            In Heat Conduction with varsPerNode = 1\n                F = [Qdot] # heat rate\n            In Elasticity with varsPerNode = 3,\n                F = [fx, fy, fz] # forces\n            In Elasticity with varsPerNode = 6,\n                F = [fx, fy, fz, mx, my, mz] # forces + moments\n            In Thermoelasticity with varsPerNode = 4,\n                F = [fx, fy, fz, Qdot] # forces + heat rate\n            In Thermoelasticity with varsPerNode = 7,\n                F = [fx, fy, fz, mx, my, mz, Qdot] # forces + moments + heat rate\n        \"\"\"\n        self._addLoadToComponents(self.F, compIDs, F, averageLoad)\n\n    def addLoadToNodes(self, nodeIDs, F, nastranOrdering=False):\n        \"\"\"\n        This method is used to add a fixed point load of F to the\n        selected node IDs.\n\n        Parameters\n        ----------\n\n        nodeIDs : list[int]\n            The nodes IDs with added loads.\n\n        F : Numpy 1d or 2d array length (varsPerNodes) or (numNodeIDs, varsPerNodes)\n            Array of force vectors, one for each node. If only one force vector is provided,\n            force will be copied uniformly across all nodes.\n\n        nastranOrdering : bool\n            Flag signaling whether nodeIDs are in TACS (default)\n            or NASTRAN (grid IDs in bdf file) ordering\n\n        Notes\n        -----\n\n        The units of the entries of the 'force' vector F are not\n        necessarily physical forces and their interpretation depends\n        on the physics problem being solved and the dofs included\n        in the model.\n\n        A couple of examples of force vector components for common problems are listed below:\n\n            In Heat Conduction with varsPerNode = 1\n                F = [Qdot] # heat rate\n            In Elasticity with varsPerNode = 3,\n                F = [fx, fy, fz] # forces\n            In Elasticity with varsPerNode = 6,\n                F = [fx, fy, fz, mx, my, mz] # forces + moments\n            In Thermoelasticity with varsPerNode = 4,\n                F = [fx, fy, fz, Qdot] # forces + heat rate\n            In Thermoelasticity with varsPerNode = 7,\n                F = [fx, fy, fz, mx, my, mz, Qdot] # forces + moments + heat rate\n        \"\"\"\n\n        self._addLoadToNodes(self.F, nodeIDs, F, nastranOrdering)\n\n    def addLoadToRHS(self, Fapplied):\n        \"\"\"\n        This method is used to add a *FIXED TOTAL LOAD* directly to the\n        right hand side vector given the equation below:\n\n            K*u = f\n\n        Where:\n            - K : Stiffness matrix for problem\n            - u : State variables for problem\n            - f : Right-hand side vector to add loads to\n\n        Parameters\n        ----------\n\n        Fapplied : numpy.ndarray or tacs.TACS.Vec\n            Distributed array containing loads to applied to RHS of the problem.\n\n        \"\"\"\n        self._addLoadToRHS(self.F, Fapplied)\n\n    def addTractionToComponents(self, compIDs, tractions, faceIndex=0):\n        \"\"\"\n        This method is used to add a *FIXED TOTAL TRACTION* on one or more\n        components, defined by COMPIDs. The purpose of this routine is\n        to add loads that remain fixed throughout an optimization.\n\n        Parameters\n        ----------\n\n        compIDs : list[int] or int\n            The components with added loads. Use pyTACS selectCompIDs method\n            to determine this.\n\n        tractions : Numpy array length 1 or compIDs\n            Array of traction vectors for each component\n\n        faceIndex : int\n            Indicates which face (side) of element to apply traction to.\n            Note: not required for certain elements (i.e. shells)\n        \"\"\"\n        self._addTractionToComponents(self.auxElems, compIDs, tractions, faceIndex)\n\n    def addTractionToElements(\n        self, elemIDs, tractions, faceIndex=0, nastranOrdering=False\n    ):\n        \"\"\"\n        This method is used to add a fixed traction to the\n        selected element IDs. Tractions can be specified on an\n        element by element basis (if tractions is a 2d array) or\n        set to a uniform value (if tractions is a 1d array)\n\n        Parameters\n        ----------\n\n        elemIDs : list[int]\n            The global element ID numbers for which to apply the traction.\n\n        tractions : Numpy 1d or 2d array length varsPerNodes or (elemIDs, varsPerNodes)\n            Array of traction vectors for each element\n\n        faceIndex : int\n            Indicates which face (side) of element to apply traction to.\n            Note: not required for certain elements (i.e. shells)\n\n        nastranOrdering : bool\n            Flag signaling whether elemIDs are in TACS (default)\n            or NASTRAN ordering\n        \"\"\"\n\n        self._addTractionToElements(\n            self.auxElems, elemIDs, tractions, faceIndex, nastranOrdering\n        )\n\n    def addPressureToComponents(self, compIDs, pressures, faceIndex=0):\n        \"\"\"\n        This method is used to add a *FIXED TOTAL PRESSURE* on one or more\n        components, defined by COMPIds. The purpose of this routine is\n        to add loads that remain fixed throughout an optimization. An example\n        would be a fuel load.\n\n        Parameters\n        ----------\n\n        compIDs : list[int] or int\n            The components with added loads. Use pyTACS selectCompIDs method\n            to determine this.\n\n        pressures : Numpy array length 1 or compIDs\n            Array of pressure values for each component\n\n        faceIndex : int\n            Indicates which face (side) of element to apply pressure to.\n            Note: not required for certain elements (i.e. shells)\n        \"\"\"\n        self._addPressureToComponents(self.auxElems, compIDs, pressures, faceIndex)\n\n    def addPressureToElements(\n        self, elemIDs, pressures, faceIndex=0, nastranOrdering=False\n    ):\n        \"\"\"\n        This method is used to add a fixed presure to the\n        selected element IDs. Pressures can be specified on an\n        element by element basis (if pressures is an array) or\n        set to a uniform value (if pressures is a scalar)\n\n        Parameters\n        ----------\n\n        elemIDs : list[int]\n            The global element ID numbers for which to apply the pressure.\n\n        pressures : Numpy array length 1 or elemIDs\n            Array of pressure values for each element\n\n        faceIndex : int\n            Indicates which face (side) of element to apply pressure to.\n            Note: not required for certain elements (i.e. shells)\n\n        nastranOrdering : bool\n            Flag signaling whether elemIDs are in TACS (default)\n            or NASTRAN ordering\n        \"\"\"\n\n        self._addPressureToElements(\n            self.auxElems, elemIDs, pressures, faceIndex, nastranOrdering\n        )\n\n    def addInertialLoad(self, inertiaVector):\n        \"\"\"\n        This method is used to add a fixed inertial load due to\n        a uniform acceleration over the entire model.\n        This is most commonly used to model gravity loads on a model.\n\n        Parameters\n        ----------\n        inertiaVector : numpy.ndarray\n            Acceleration vector used to define inertial load.\n        \"\"\"\n        self._addInertialLoad(self.auxElems, inertiaVector)\n\n    def addCentrifugalLoad(self, omegaVector, rotCenter, firstOrder=False):\n        \"\"\"\n        This method is used to add a fixed centrifugal load due to a\n        uniform rotational velocity over the entire model.\n        This is most commonly used to model rotors, rolling aircraft, etc.\n\n        Parameters\n        ----------\n\n        omegaVector : numpy.ndarray\n            Rotational velocity vector (rad/s) used to define centrifugal load.\n\n        rotCenter : numpy.ndarray\n            Location of center of rotation used to define centrifugal load.\n\n        firstOrder : bool, optional\n            Whether to use first order approximation for centrifugal load,\n            which computes the force in the displaced position. By default False\n        \"\"\"\n        self._addCentrifugalLoad(self.auxElems, omegaVector, rotCenter, firstOrder)\n\n    def addLoadFromBDF(self, loadID, scale=1.0):\n        \"\"\"\n        This method is used to add a fixed load set defined in the BDF file to the problem.\n        Currently, only supports LOAD, FORCE, MOMENT, GRAV, RFORCE, PLOAD2, and PLOAD4.\n\n        Parameters\n        ----------\n\n        loadID : int\n            Load identification number of load set in BDF file user wishes to add to problem.\n\n        scale : float\n            Factor to scale the BDF loads by before adding to problem.\n        \"\"\"\n        self._addLoadFromBDF(self.F, self.auxElems, loadID, scale)\n\n    def zeroLoads(self):\n        \"\"\"\n        Zero all applied loads\n        \"\"\"\n        self.F.zeroEntries()\n        self.auxElems = tacs.TACS.AuxElements()\n\n    ####### Buckling solver methods ########\n\n    def _updateAssemblerVars(self):\n        \"\"\"\n        Make sure that the assembler is using\n        the input variables associated with this problem\n        \"\"\"\n\n        self.assembler.setDesignVars(self.x)\n        self.assembler.setNodes(self.Xpts)\n        # Set state variables\n        self.assembler.setVariables(self.u0)\n        # Zero any time derivative terms\n        self.assembler.zeroDotVariables()\n        self.assembler.zeroDDotVariables()\n        # Make sure previous auxiliary loads are removed\n        self.assembler.setAuxElements(self.auxElems)\n        # Set artificial stiffness factors in rbe class\n        c1 = self.getOption(\"RBEStiffnessScaleFactor\")\n        c2 = self.getOption(\"RBEArtificialStiffness\")\n        tacs.elements.RBE2.setScalingParameters(c1, c2)\n        tacs.elements.RBE3.setScalingParameters(c1, c2)\n\n    def solve(self, Fext=None, u0=None):\n        \"\"\"\n        Solve the eigenvalue problem. The\n        forces must already be set.\n\n        Parameters\n        ----------\n        Fext : tacs.TACS.Vec or numpy.ndarray, optional\n            Distributed array containing additional loads (ex. aerodynamic forces for aerostructural coupling)\n            to applied to RHS of the static problem.\n\n        u0 : tacs.TACS.Vec or numpy.ndarray, optional\n            Distributed array containing additional loads (ex. aerodynamic forces for aerostructural coupling)\n            to applied to RHS of the static problem. Alternate to Fext.\n        \"\"\"\n        startTime = time.time()\n\n        self.callCounter += 1\n\n        setupProblemTime = time.time()\n\n        # Set problem vars to assembler\n        self._updateAssemblerVars()\n\n        # states were not prescribed, pass in forces\n        if u0 is None:\n            # Sum the forces from the loads not handled by TACS\n            self.rhs.copyValues(self.F)  # Fixed loads\n\n            # Add external loads, if specified\n            if Fext is not None:\n                if isinstance(Fext, tacs.TACS.Vec):\n                    self.rhs.axpy(1.0, Fext)\n                elif isinstance(Fext, np.ndarray):\n                    rhsArray = self.rhs.getArray()\n                    rhsArray[:] = rhsArray[:] + Fext[:]\n\n            force = self.rhs\n            path = None\n\n        # states already prescribed, we don't need forces\n        else:\n            # Convert to bvec\n            if isinstance(u0, np.ndarray):\n                path = self._arrayToVec(u0)\n            else:\n                path = u0\n            force = None\n\n        initSolveTime = time.time()\n\n        # Solve the buckling analysis problem\n        self.buckleSolver.solve(\n            force=force, path=path, print_flag=self.getOption(\"printLevel\")\n        )\n\n        # Save state vars\n        self.assembler.getVariables(self.u0)\n\n        solveTime = time.time()\n\n        # If timing was was requested print it, if the solution is nonlinear\n        # print this information automatically if prinititerations was requested.\n        if self.getOption(\"printTiming\"):\n            self._pp(\"+--------------------------------------------------+\")\n            self._pp(\"|\")\n            self._pp(\"| TACS Solve Times:\")\n            self._pp(\"|\")\n            self._pp(\n                \"| %-30s: %10.3f sec\"\n                % (\"TACS Setup Time\", setupProblemTime - startTime)\n            )\n            self._pp(\n                \"| %-30s: %10.3f sec\"\n                % (\"TACS Solve Init Time\", initSolveTime - setupProblemTime)\n            )\n            self._pp(\n                \"| %-30s: %10.3f sec\" % (\"TACS Solve Time\", solveTime - initSolveTime)\n            )\n            self._pp(\"|\")\n            self._pp(\n                \"| %-30s: %10.3f sec\"\n                % (\"TACS Total Solution Time\", solveTime - startTime)\n            )\n            self._pp(\"+--------------------------------------------------+\")\n\n        return\n\n    def getVariables(self, index, states=None):\n        \"\"\"\n        Return the current state values for one mode of the current problem\n\n        Parameters\n        ----------\n        index : int\n            Mode index to return solution for.\n\n        states : tacs.TACS.Vec or numpy.ndarray or None\n            Place eigenvector for mode into this array (optional).\n\n        Returns\n        --------\n        eigVal: float\n            Eigenvalue for mode corresponds to buckling load factor\n\n        states : numpy.ndarray\n            Eigenvector for mode\n        \"\"\"\n        eigVal, err = self.buckleSolver.extractEigenvalue(index)\n        eigVector = self.assembler.createVec()\n        self.buckleSolver.extractEigenvector(index, eigVector)\n        # Inplace assignment if vectors were provided\n        if isinstance(states, tacs.TACS.Vec):\n            states.copyValues(eigVector)\n        elif isinstance(states, np.ndarray):\n            states[:] = eigVector.getArray()\n        return eigVal, eigVector.getArray()\n\n    def addXptSens(self, indices, xptSensList, scale=1.0):\n        \"\"\"\n        Add partial sensitivity contribution due to nodal coordinates for eigenvalue\n\n        Parameters\n        ----------\n        indices : list[int]\n            Mode indices to return sensitivity for.\n\n        xptSensList : list[tacs.TACS.Vec] or list[numpy.ndarray]\n            List of sensitivity vectors to add partial sensitivity to\n\n        scale : float\n            Scalar to multiply partial sensitivity by. Defaults to 1.0\n        \"\"\"\n        # Set problem vars to assembler\n        self._updateAssemblerVars()\n\n        for index, xptSens in zip(indices, xptSensList):\n            # Create a tacs BVec copy for the operation if the output is a numpy array\n            if isinstance(xptSens, np.ndarray):\n                xptSensBVec = self._arrayToNodeVec(xptSens)\n            # Otherwise the input is already a BVec and we can do the operation in place\n            else:\n                xptSensBVec = xptSens\n\n            self.buckleSolver.addEigenXptSens(scale, index, xptSensBVec)\n\n            # Finalize sensitivity arrays across all procs\n            xptSensBVec.beginSetValues()\n            xptSensBVec.endSetValues()\n\n            # Update from the BVec values, if the input was a numpy array\n            if isinstance(xptSens, np.ndarray):\n                # Copy values to numpy array\n                xptSens[:] = xptSensBVec.getArray()\n\n    def addDVSens(self, indices, dvSensList, scale=1.0):\n        \"\"\"\n        Add partial sensitivity contribution due to design variables for eigenvalue\n\n        Parameters\n        ----------\n        indices : list[int]\n            Mode indices to return sensitivity for.\n\n        dvSensList : list[tacs.TACS.Vec] or list[numpy.ndarray]\n            List of sensitivity vectors to add partial sensitivity to\n\n        scale : float\n            Scalar to multiply partial sensitivity by. Defaults to 1.0\n        \"\"\"\n        # Set problem vars to assembler\n        self._updateAssemblerVars()\n\n        for index, dvSens in zip(indices, dvSensList):\n            # Create a tacs BVec copy for the operation if the output is a numpy array\n            if isinstance(dvSens, np.ndarray):\n                dvSensBVec = self._arrayToDesignVec(dvSens)\n            # Otherwise the input is already a BVec and we can do the operation in place\n            else:\n                dvSensBVec = dvSens\n\n            self.buckleSolver.addEigenDVSens(scale, index, dvSensBVec)\n\n            # Finalize sensitivity arrays across all procs\n            dvSensBVec.beginSetValues()\n            dvSensBVec.endSetValues()\n\n            # Update from the BVec values, if the input was a numpy array\n            if isinstance(dvSens, np.ndarray):\n                # Copy values to numpy array\n                dvSens[:] = dvSensBVec.getArray()\n\n    def evalSVSens(self, indices, svSensList):\n        \"\"\"\n        Add partial sensitivity contribution due to state variables for eigenvalue\n\n        Parameters\n        ----------\n        indices : list[int]\n            Mode indices to return sensitivity for.\n\n        svSensList : list[tacs.TACS.Vec] or list[numpy.ndarray]\n            List of sensitivity vectors to add partial sensitivity to\n        \"\"\"\n        # Set problem vars to assembler\n        self._updateAssemblerVars()\n\n        for index, svSens in zip(indices, svSensList):\n            # Create a tacs BVec copy for the operation if the output is a numpy array\n            if isinstance(svSens, np.ndarray):\n                svSensBVec = self._arrayToVec(svSens)\n            # Otherwise the input is already a BVec and we can do the operation in place\n            else:\n                svSensBVec = svSens\n\n            self.buckleSolver.evalEigenSVSens(index, svSensBVec)\n\n            # Finalize sensitivity arrays across all procs\n            svSensBVec.beginSetValues()\n            svSensBVec.endSetValues()\n\n            # Update from the BVec values, if the input was a numpy array\n            if isinstance(svSens, np.ndarray):\n                # Copy values to numpy array\n                svSens[:] = svSensBVec.getArray()\n\n    def writeSolution(self, outputDir=None, baseName=None, number=None, indices=None):\n        \"\"\"\n        This is a generic shell function that writes the output\n        file(s).  The intent is that the user or calling program can\n        call this function and pyTACS writes all the files that the\n        user has defined. It is recommended that this function is used\n        along with the associated logical flags in the options to\n        determine the desired writing procedure\n\n        Parameters\n        ----------\n        outputDir : str or None\n            Use the supplied output directory\n        baseName : str or None\n            Use this supplied string for the base filename. Typically\n            only used from an external solver.\n        number : int or None\n            Use the user supplied number to index solution. Again, only\n            typically used from an external solver\n        indices : int or list[int] or None\n            Mode index or indices to get state variables for.\n            If None, returns a solution for all modes.\n            Defaults to None.\n        \"\"\"\n        # Make sure assembler variables are up-to-date\n        self._updateAssemblerVars()\n\n        # Check input\n        if outputDir is None:\n            outputDir = self.getOption(\"outputDir\")\n\n        if baseName is None:\n            baseName = self.name\n\n        # If we are numbering solution, it saving the sequence of\n        # calls, add the call number\n        if number is not None:\n            # We need number based on the provided number:\n            baseName = baseName + \"_%3.3d\" % number\n        else:\n            # if number is none, i.e. standalone, but we need to\n            # number solutions, use internal counter\n            if self.getOption(\"numberSolutions\"):\n                baseName = baseName + \"_%3.3d\" % self.callCounter\n\n        # Unless the writeSolution option is off write actual file:\n        if self.getOption(\"writeSolution\"):\n            # If indices is None, output all modes\n            if indices is None:\n                indices = np.arange(self.numEigs)\n\n            # Write out each specified mode\n            indices = np.atleast_1d(indices)\n            vec = self.assembler.createVec()\n            for index in indices:\n                # Extract eigenvector\n                eig, _ = self.getVariables(index, states=vec)\n                # Set eigen mode in assembler\n                self.assembler.setVariables(vec)\n                # Write out mode shape as f5 file\n                modeName = baseName + \"_%3.3d\" % index\n                fileName = os.path.join(outputDir, modeName) + \".f5\"\n                self.outputViewer.writeToFile(fileName)",
  "def __init__(\n        self,\n        name,\n        sigma,\n        numEigs,\n        assembler,\n        comm,\n        outputViewer=None,\n        meshLoader=None,\n        options=None,\n    ):\n        \"\"\"\n        NOTE: This class should not be initialized directly by the user.\n        Use pyTACS.createBucklingProblem instead.\n\n        Parameters\n        ----------\n        name : str\n            Name of this tacs problem\n\n        sigma : float\n            Guess for the lowest eigenvalue. This corresponds to the lowest buckling load factor.\n\n        numEigs : int\n            Number of eigenvalues to solve for\n\n        assembler : TACS.Assembler\n            Cython object responsible for creating and setting tacs objects used to solve problem\n\n        comm : mpi4py.MPI.Intracomm\n            The comm object on which to create the pyTACS object.\n\n        outputViewer : TACS.TACSToFH5\n            Cython object used to write out f5 files that can be converted and used for postprocessing.\n\n        meshLoader : pymeshloader.pyMeshLoader\n            pyMeshLoader object used to create the assembler.\n\n        options : dict\n            Dictionary holding problem-specific option parameters (case-insensitive).\n        \"\"\"\n\n        # Problem name\n        self.name = name\n\n        # Default setup for common problem class objects, sets up comm and options\n        TACSProblem.__init__(self, assembler, comm, options, outputViewer, meshLoader)\n\n        # Set time eigenvalue parameters\n        self.sigma = sigma\n        self.numEigs = numEigs\n\n        # String name used in evalFunctions\n        self.valName = \"eigsb\"\n        self._initializeFunctionList()\n\n        # Create problem-specific variables\n        self._createVariables()",
  "def _createVariables(self):\n        \"\"\"\n        Internal to create the objects required by TACS Integrator\n        \"\"\"\n\n        self.callCounter = -1\n\n        # Buckling load state\n        self.u0 = self.assembler.createVec()\n        # Load vector\n        self.F = self.assembler.createVec()\n        self.F_array = self.F.getArray()\n        # RHS vector\n        self.rhs = self.assembler.createVec()\n        # Auxiliary element object for applying tractions/pressure\n        self.auxElems = tacs.TACS.AuxElements()\n\n        self.aux = self.assembler.createSchurMat()\n        self.G = self.assembler.createSchurMat()\n        self.K = self.assembler.createSchurMat()\n\n        self.pc = tacs.TACS.Pc(self.K)\n\n        # Set artificial stiffness factors in rbe class\n        c1 = self.getOption(\"RBEStiffnessScaleFactor\")\n        c2 = self.getOption(\"RBEArtificialStiffness\")\n        tacs.elements.RBE2.setScalingParameters(c1, c2)\n        tacs.elements.RBE3.setScalingParameters(c1, c2)\n\n        # Assemble and factor the stiffness/Jacobian matrix. Factor the\n        # Jacobian and solve the linear system for the displacements\n        self.assembler.assembleMatType(tacs.TACS.STIFFNESS_MATRIX, self.K)\n        self.assembler.assembleMatType(tacs.TACS.GEOMETRIC_STIFFNESS_MATRIX, self.G)\n\n        subspace = self.getOption(\"subSpaceSize\")\n        restarts = self.getOption(\"nRestarts\")\n        atol = self.getOption(\"L2Convergence\")\n        rtol = self.getOption(\"L2ConvergenceRel\")\n        self.gmres = tacs.TACS.KSM(self.aux, self.pc, subspace, restarts)\n        self.gmres.setTolerances(rtol, atol)\n\n        # Create the buckling analysis object\n        self.buckleSolver = tacs.TACS.BucklingAnalysis(\n            self.assembler,\n            self.sigma,\n            self.G,\n            self.K,\n            self.gmres,\n            num_eigs=self.numEigs,\n            eig_tol=rtol,\n        )",
  "def _initializeFunctionList(self):\n        \"\"\"\n        Create FunctionList dict which maps eigenvalue strings\n        to mode indices used in evalFunctions method.\n        \"\"\"\n        self.functionList = {}\n        for mode_i in range(self.numEigs):\n            self.functionList[f\"{self.valName}.{mode_i}\"] = mode_i",
  "def setOption(self, name, value):\n        \"\"\"\n        Set a solver option value. The name is not case sensitive.\n\n        Parameters\n        ----------\n        name : str\n            Name of option to modify\n\n        value : depends on option\n            New option value to set\n        \"\"\"\n        # Default setOption for common problem class objects\n        TACSProblem.setOption(self, name, value)\n\n        # No need to reset solver for output options\n        if name.lower() in [\n            \"writesolution\",\n            \"printtiming\",\n            \"numbersolutions\",\n            \"outputdir\",\n        ]:\n            pass\n        # Reset solver for all other option changes\n        else:\n            self._createVariables()",
  "def setValName(self, valName):\n        \"\"\"\n        Set a name for the eigenvalues. Only needs\n        to be changed if more than 1 pytacs object is used in an\n        optimization\n\n        Parameters\n        ----------\n        valName : str\n            Name of the eigenvalue output used in evalFunctions().\n        \"\"\"\n        self.valName = valName\n        self._initializeFunctionList()",
  "def getNumEigs(self):\n        \"\"\"\n        Get the number of eigenvalues requested from solver for this problem.\n\n        Returns\n        ----------\n        numEigs : int\n            Number of eigenvalues.\n        \"\"\"\n        return self.numEigs",
  "def addFunction(self, funcName, funcHandle, compIDs=None, **kwargs):\n        \"\"\"\n        NOT SUPPORTED FOR THIS PROBLEM\n        \"\"\"\n        self._TACSWarning(\"addFunction method not supported for this class.\")",
  "def evalFunctions(self, funcs, evalFuncs=None, ignoreMissing=False):\n        \"\"\"\n        Evaluate eigenvalues for problem. The functions corresponding to\n        the integers in evalFuncs are evaluated and updated into\n        the provided dictionary.\n\n        Parameters\n        ----------\n        funcs : dict\n            Dictionary into which the functions are saved.\n        evalFuncs : iterable object containing strings.\n            If not none, use these functions to evaluate.\n        ignoreMissing : bool\n            Flag to supress checking for a valid function. Please use\n            this option with caution.\n\n        Examples\n        --------\n        >>> funcs = {}\n        >>> bucklingProblem.solve()\n        >>> bucklingProblem.evalFunctions(funcs, 'eigsm.0')\n        >>> funcs\n        >>> # Result will look like (if bucklingProblem has name of 'c1'):\n        >>> # {'c1_eigsm.0':12354.10}\n        \"\"\"\n        # Make sure assembler variables are up to date\n        self._updateAssemblerVars()\n\n        # Check if user specified which eigvals to output\n        # Otherwise, output them all\n        if evalFuncs is None:\n            evalFuncs = self.functionList\n        else:\n            userFuncs = sorted(list(evalFuncs))\n            evalFuncs = {}\n            for func in userFuncs:\n                if func in self.functionList:\n                    evalFuncs[func] = self.functionList[func]\n\n        if not ignoreMissing:\n            for f in evalFuncs:\n                if f not in self.functionList:\n                    raise self._TACSError(\n                        f\"Supplied function '{f}' has not been added \"\n                        \"using addFunction().\"\n                    )\n\n        # Loop through each requested eigenvalue\n        for funcName in evalFuncs:\n            mode_i = evalFuncs[funcName]\n            key = f\"{self.name}_{funcName}\"\n            funcs[key], _ = self.getVariables(mode_i)",
  "def evalFunctionsSens(self, funcsSens, evalFuncs=None):\n        \"\"\"\n        This is the main routine for returning useful (sensitivity)\n        information from problem. The derivatives of the functions\n        corresponding to the strings in evalFuncs are evaluated and\n        updated into the provided dictionary. The derivitives with\n        respect to all design variables and node locations are computed.\n\n        Parameters\n        ----------\n        funcsSens : dict\n            Dictionary into which the derivatives are saved.\n        evalFuncs : iterable object containing strings\n            The functions the user wants returned\n\n        Examples\n        --------\n        >>> funcsSens = {}\n        >>> bucklingProblem.evalFunctionsSens(funcsSens, 'eigsm.0')\n        >>> funcsSens\n        >>> # Result will look like (if bucklingProblem has name of 'c1'):\n        >>> # {'c1_eigsm.0':{'struct':[1.234, ..., 7.89], 'Xpts':[3.14, ..., 1.59]}}\n        \"\"\"\n        # Make sure assembler variables are up to date\n        self._updateAssemblerVars()\n\n        # Check if user specified which eigvals to output\n        # Otherwise, output them all\n        if evalFuncs is None:\n            evalFuncs = self.functionList\n        else:\n            userFuncs = sorted(list(evalFuncs))\n            evalFuncs = {}\n            for func in userFuncs:\n                if func in self.functionList:\n                    evalFuncs[func] = self.functionList[func]\n\n        dvSens = self.assembler.createDesignVec()\n        xptSens = self.assembler.createNodeVec()\n\n        indices = [evalFuncs[funcName] for funcName in evalFuncs]\n        dvSensList = [self.assembler.createDesignVec() for funcName in evalFuncs]\n        xptSensList = [self.assembler.createNodeVec() for funcName in evalFuncs]\n        svSensList = [self.assembler.createVec() for funcName in evalFuncs]\n        adjointList = [self.assembler.createVec() for funcName in evalFuncs]\n\n        self.addDVSens(indices, dvSensList, scale=1.0)\n        self.addXptSens(indices, xptSensList, scale=1.0)\n        self.evalSVSens(indices, svSensList)\n\n        self.aux.copyValues(self.K)\n        self.pc.factor()\n\n        # Loop through each requested eigenvalue\n        for i, funcName in enumerate(evalFuncs):\n            rhs = svSensList[i]\n            adjoint = adjointList[i]\n            self.gmres.solve(rhs, adjoint)\n\n            # Evaluate adjoint contribution to nodal sens\n            xptSens = xptSensList[i]\n            self.assembler.addAdjointResXptSensProducts([adjoint], [xptSens], -1.0)\n            xptSens.beginSetValues()\n            xptSens.endSetValues()\n            # Evaluate adjoint contribution to dv sens\n            dvSens = dvSensList[i]\n            self.assembler.addAdjointResProducts([adjoint], [dvSens], -1.0)\n            dvSens.beginSetValues()\n            dvSens.endSetValues()\n\n            key = f\"{self.name}_{funcName}\"\n            funcsSens[key] = {}\n            funcsSens[key][self.varName] = dvSens.getArray().copy()\n            funcsSens[key][self.coordName] = xptSens.getArray().copy()",
  "def addLoadToComponents(self, compIDs, F, averageLoad=False):\n        \"\"\"\n        This method is used to add a *FIXED TOTAL LOAD* on one or more\n        components, defined by COMPIDs. The purpose of this routine is to add loads that\n        remain fixed throughout an optimization. An example would be an engine load.\n        This routine determines all the unique nodes in the FE model that are part of the\n        requested components, then takes the total 'force' by F and divides by the\n        number of nodes. This average load is then applied to the nodes.\n\n        Parameters\n        ----------\n\n        compIDs : list[int] or int\n            The components with added loads. Use pyTACS selectCompIDs method\n            to determine this.\n\n        F : numpy.ndarray 1d or 2d length (varsPerNodes) or (numCompIDs, varsPerNodes)\n            Vector(s) of 'force' to apply to each component.  If only one force vector is provided,\n            force will be copied uniformly across all components.\n\n        averageLoad : bool\n            Flag to determine whether load should be split evenly across all components (True)\n            or copied and applied individually to each component (False). Defaults to False.\n\n        Notes\n        -----\n\n        The units of the entries of the 'force' vector F are not\n        necessarily physical forces and their interpretation depends\n        on the physics problem being solved and the dofs included\n        in the model.\n\n        A couple of examples of force vector components for common problems are listed below:\n\n            In Heat Conduction with varsPerNode = 1\n                F = [Qdot] # heat rate\n            In Elasticity with varsPerNode = 3,\n                F = [fx, fy, fz] # forces\n            In Elasticity with varsPerNode = 6,\n                F = [fx, fy, fz, mx, my, mz] # forces + moments\n            In Thermoelasticity with varsPerNode = 4,\n                F = [fx, fy, fz, Qdot] # forces + heat rate\n            In Thermoelasticity with varsPerNode = 7,\n                F = [fx, fy, fz, mx, my, mz, Qdot] # forces + moments + heat rate\n        \"\"\"\n        self._addLoadToComponents(self.F, compIDs, F, averageLoad)",
  "def addLoadToNodes(self, nodeIDs, F, nastranOrdering=False):\n        \"\"\"\n        This method is used to add a fixed point load of F to the\n        selected node IDs.\n\n        Parameters\n        ----------\n\n        nodeIDs : list[int]\n            The nodes IDs with added loads.\n\n        F : Numpy 1d or 2d array length (varsPerNodes) or (numNodeIDs, varsPerNodes)\n            Array of force vectors, one for each node. If only one force vector is provided,\n            force will be copied uniformly across all nodes.\n\n        nastranOrdering : bool\n            Flag signaling whether nodeIDs are in TACS (default)\n            or NASTRAN (grid IDs in bdf file) ordering\n\n        Notes\n        -----\n\n        The units of the entries of the 'force' vector F are not\n        necessarily physical forces and their interpretation depends\n        on the physics problem being solved and the dofs included\n        in the model.\n\n        A couple of examples of force vector components for common problems are listed below:\n\n            In Heat Conduction with varsPerNode = 1\n                F = [Qdot] # heat rate\n            In Elasticity with varsPerNode = 3,\n                F = [fx, fy, fz] # forces\n            In Elasticity with varsPerNode = 6,\n                F = [fx, fy, fz, mx, my, mz] # forces + moments\n            In Thermoelasticity with varsPerNode = 4,\n                F = [fx, fy, fz, Qdot] # forces + heat rate\n            In Thermoelasticity with varsPerNode = 7,\n                F = [fx, fy, fz, mx, my, mz, Qdot] # forces + moments + heat rate\n        \"\"\"\n\n        self._addLoadToNodes(self.F, nodeIDs, F, nastranOrdering)",
  "def addLoadToRHS(self, Fapplied):\n        \"\"\"\n        This method is used to add a *FIXED TOTAL LOAD* directly to the\n        right hand side vector given the equation below:\n\n            K*u = f\n\n        Where:\n            - K : Stiffness matrix for problem\n            - u : State variables for problem\n            - f : Right-hand side vector to add loads to\n\n        Parameters\n        ----------\n\n        Fapplied : numpy.ndarray or tacs.TACS.Vec\n            Distributed array containing loads to applied to RHS of the problem.\n\n        \"\"\"\n        self._addLoadToRHS(self.F, Fapplied)",
  "def addTractionToComponents(self, compIDs, tractions, faceIndex=0):\n        \"\"\"\n        This method is used to add a *FIXED TOTAL TRACTION* on one or more\n        components, defined by COMPIDs. The purpose of this routine is\n        to add loads that remain fixed throughout an optimization.\n\n        Parameters\n        ----------\n\n        compIDs : list[int] or int\n            The components with added loads. Use pyTACS selectCompIDs method\n            to determine this.\n\n        tractions : Numpy array length 1 or compIDs\n            Array of traction vectors for each component\n\n        faceIndex : int\n            Indicates which face (side) of element to apply traction to.\n            Note: not required for certain elements (i.e. shells)\n        \"\"\"\n        self._addTractionToComponents(self.auxElems, compIDs, tractions, faceIndex)",
  "def addTractionToElements(\n        self, elemIDs, tractions, faceIndex=0, nastranOrdering=False\n    ):\n        \"\"\"\n        This method is used to add a fixed traction to the\n        selected element IDs. Tractions can be specified on an\n        element by element basis (if tractions is a 2d array) or\n        set to a uniform value (if tractions is a 1d array)\n\n        Parameters\n        ----------\n\n        elemIDs : list[int]\n            The global element ID numbers for which to apply the traction.\n\n        tractions : Numpy 1d or 2d array length varsPerNodes or (elemIDs, varsPerNodes)\n            Array of traction vectors for each element\n\n        faceIndex : int\n            Indicates which face (side) of element to apply traction to.\n            Note: not required for certain elements (i.e. shells)\n\n        nastranOrdering : bool\n            Flag signaling whether elemIDs are in TACS (default)\n            or NASTRAN ordering\n        \"\"\"\n\n        self._addTractionToElements(\n            self.auxElems, elemIDs, tractions, faceIndex, nastranOrdering\n        )",
  "def addPressureToComponents(self, compIDs, pressures, faceIndex=0):\n        \"\"\"\n        This method is used to add a *FIXED TOTAL PRESSURE* on one or more\n        components, defined by COMPIds. The purpose of this routine is\n        to add loads that remain fixed throughout an optimization. An example\n        would be a fuel load.\n\n        Parameters\n        ----------\n\n        compIDs : list[int] or int\n            The components with added loads. Use pyTACS selectCompIDs method\n            to determine this.\n\n        pressures : Numpy array length 1 or compIDs\n            Array of pressure values for each component\n\n        faceIndex : int\n            Indicates which face (side) of element to apply pressure to.\n            Note: not required for certain elements (i.e. shells)\n        \"\"\"\n        self._addPressureToComponents(self.auxElems, compIDs, pressures, faceIndex)",
  "def addPressureToElements(\n        self, elemIDs, pressures, faceIndex=0, nastranOrdering=False\n    ):\n        \"\"\"\n        This method is used to add a fixed presure to the\n        selected element IDs. Pressures can be specified on an\n        element by element basis (if pressures is an array) or\n        set to a uniform value (if pressures is a scalar)\n\n        Parameters\n        ----------\n\n        elemIDs : list[int]\n            The global element ID numbers for which to apply the pressure.\n\n        pressures : Numpy array length 1 or elemIDs\n            Array of pressure values for each element\n\n        faceIndex : int\n            Indicates which face (side) of element to apply pressure to.\n            Note: not required for certain elements (i.e. shells)\n\n        nastranOrdering : bool\n            Flag signaling whether elemIDs are in TACS (default)\n            or NASTRAN ordering\n        \"\"\"\n\n        self._addPressureToElements(\n            self.auxElems, elemIDs, pressures, faceIndex, nastranOrdering\n        )",
  "def addInertialLoad(self, inertiaVector):\n        \"\"\"\n        This method is used to add a fixed inertial load due to\n        a uniform acceleration over the entire model.\n        This is most commonly used to model gravity loads on a model.\n\n        Parameters\n        ----------\n        inertiaVector : numpy.ndarray\n            Acceleration vector used to define inertial load.\n        \"\"\"\n        self._addInertialLoad(self.auxElems, inertiaVector)",
  "def addCentrifugalLoad(self, omegaVector, rotCenter, firstOrder=False):\n        \"\"\"\n        This method is used to add a fixed centrifugal load due to a\n        uniform rotational velocity over the entire model.\n        This is most commonly used to model rotors, rolling aircraft, etc.\n\n        Parameters\n        ----------\n\n        omegaVector : numpy.ndarray\n            Rotational velocity vector (rad/s) used to define centrifugal load.\n\n        rotCenter : numpy.ndarray\n            Location of center of rotation used to define centrifugal load.\n\n        firstOrder : bool, optional\n            Whether to use first order approximation for centrifugal load,\n            which computes the force in the displaced position. By default False\n        \"\"\"\n        self._addCentrifugalLoad(self.auxElems, omegaVector, rotCenter, firstOrder)",
  "def addLoadFromBDF(self, loadID, scale=1.0):\n        \"\"\"\n        This method is used to add a fixed load set defined in the BDF file to the problem.\n        Currently, only supports LOAD, FORCE, MOMENT, GRAV, RFORCE, PLOAD2, and PLOAD4.\n\n        Parameters\n        ----------\n\n        loadID : int\n            Load identification number of load set in BDF file user wishes to add to problem.\n\n        scale : float\n            Factor to scale the BDF loads by before adding to problem.\n        \"\"\"\n        self._addLoadFromBDF(self.F, self.auxElems, loadID, scale)",
  "def zeroLoads(self):\n        \"\"\"\n        Zero all applied loads\n        \"\"\"\n        self.F.zeroEntries()\n        self.auxElems = tacs.TACS.AuxElements()",
  "def _updateAssemblerVars(self):\n        \"\"\"\n        Make sure that the assembler is using\n        the input variables associated with this problem\n        \"\"\"\n\n        self.assembler.setDesignVars(self.x)\n        self.assembler.setNodes(self.Xpts)\n        # Set state variables\n        self.assembler.setVariables(self.u0)\n        # Zero any time derivative terms\n        self.assembler.zeroDotVariables()\n        self.assembler.zeroDDotVariables()\n        # Make sure previous auxiliary loads are removed\n        self.assembler.setAuxElements(self.auxElems)\n        # Set artificial stiffness factors in rbe class\n        c1 = self.getOption(\"RBEStiffnessScaleFactor\")\n        c2 = self.getOption(\"RBEArtificialStiffness\")\n        tacs.elements.RBE2.setScalingParameters(c1, c2)\n        tacs.elements.RBE3.setScalingParameters(c1, c2)",
  "def solve(self, Fext=None, u0=None):\n        \"\"\"\n        Solve the eigenvalue problem. The\n        forces must already be set.\n\n        Parameters\n        ----------\n        Fext : tacs.TACS.Vec or numpy.ndarray, optional\n            Distributed array containing additional loads (ex. aerodynamic forces for aerostructural coupling)\n            to applied to RHS of the static problem.\n\n        u0 : tacs.TACS.Vec or numpy.ndarray, optional\n            Distributed array containing additional loads (ex. aerodynamic forces for aerostructural coupling)\n            to applied to RHS of the static problem. Alternate to Fext.\n        \"\"\"\n        startTime = time.time()\n\n        self.callCounter += 1\n\n        setupProblemTime = time.time()\n\n        # Set problem vars to assembler\n        self._updateAssemblerVars()\n\n        # states were not prescribed, pass in forces\n        if u0 is None:\n            # Sum the forces from the loads not handled by TACS\n            self.rhs.copyValues(self.F)  # Fixed loads\n\n            # Add external loads, if specified\n            if Fext is not None:\n                if isinstance(Fext, tacs.TACS.Vec):\n                    self.rhs.axpy(1.0, Fext)\n                elif isinstance(Fext, np.ndarray):\n                    rhsArray = self.rhs.getArray()\n                    rhsArray[:] = rhsArray[:] + Fext[:]\n\n            force = self.rhs\n            path = None\n\n        # states already prescribed, we don't need forces\n        else:\n            # Convert to bvec\n            if isinstance(u0, np.ndarray):\n                path = self._arrayToVec(u0)\n            else:\n                path = u0\n            force = None\n\n        initSolveTime = time.time()\n\n        # Solve the buckling analysis problem\n        self.buckleSolver.solve(\n            force=force, path=path, print_flag=self.getOption(\"printLevel\")\n        )\n\n        # Save state vars\n        self.assembler.getVariables(self.u0)\n\n        solveTime = time.time()\n\n        # If timing was was requested print it, if the solution is nonlinear\n        # print this information automatically if prinititerations was requested.\n        if self.getOption(\"printTiming\"):\n            self._pp(\"+--------------------------------------------------+\")\n            self._pp(\"|\")\n            self._pp(\"| TACS Solve Times:\")\n            self._pp(\"|\")\n            self._pp(\n                \"| %-30s: %10.3f sec\"\n                % (\"TACS Setup Time\", setupProblemTime - startTime)\n            )\n            self._pp(\n                \"| %-30s: %10.3f sec\"\n                % (\"TACS Solve Init Time\", initSolveTime - setupProblemTime)\n            )\n            self._pp(\n                \"| %-30s: %10.3f sec\" % (\"TACS Solve Time\", solveTime - initSolveTime)\n            )\n            self._pp(\"|\")\n            self._pp(\n                \"| %-30s: %10.3f sec\"\n                % (\"TACS Total Solution Time\", solveTime - startTime)\n            )\n            self._pp(\"+--------------------------------------------------+\")\n\n        return",
  "def getVariables(self, index, states=None):\n        \"\"\"\n        Return the current state values for one mode of the current problem\n\n        Parameters\n        ----------\n        index : int\n            Mode index to return solution for.\n\n        states : tacs.TACS.Vec or numpy.ndarray or None\n            Place eigenvector for mode into this array (optional).\n\n        Returns\n        --------\n        eigVal: float\n            Eigenvalue for mode corresponds to buckling load factor\n\n        states : numpy.ndarray\n            Eigenvector for mode\n        \"\"\"\n        eigVal, err = self.buckleSolver.extractEigenvalue(index)\n        eigVector = self.assembler.createVec()\n        self.buckleSolver.extractEigenvector(index, eigVector)\n        # Inplace assignment if vectors were provided\n        if isinstance(states, tacs.TACS.Vec):\n            states.copyValues(eigVector)\n        elif isinstance(states, np.ndarray):\n            states[:] = eigVector.getArray()\n        return eigVal, eigVector.getArray()",
  "def addXptSens(self, indices, xptSensList, scale=1.0):\n        \"\"\"\n        Add partial sensitivity contribution due to nodal coordinates for eigenvalue\n\n        Parameters\n        ----------\n        indices : list[int]\n            Mode indices to return sensitivity for.\n\n        xptSensList : list[tacs.TACS.Vec] or list[numpy.ndarray]\n            List of sensitivity vectors to add partial sensitivity to\n\n        scale : float\n            Scalar to multiply partial sensitivity by. Defaults to 1.0\n        \"\"\"\n        # Set problem vars to assembler\n        self._updateAssemblerVars()\n\n        for index, xptSens in zip(indices, xptSensList):\n            # Create a tacs BVec copy for the operation if the output is a numpy array\n            if isinstance(xptSens, np.ndarray):\n                xptSensBVec = self._arrayToNodeVec(xptSens)\n            # Otherwise the input is already a BVec and we can do the operation in place\n            else:\n                xptSensBVec = xptSens\n\n            self.buckleSolver.addEigenXptSens(scale, index, xptSensBVec)\n\n            # Finalize sensitivity arrays across all procs\n            xptSensBVec.beginSetValues()\n            xptSensBVec.endSetValues()\n\n            # Update from the BVec values, if the input was a numpy array\n            if isinstance(xptSens, np.ndarray):\n                # Copy values to numpy array\n                xptSens[:] = xptSensBVec.getArray()",
  "def addDVSens(self, indices, dvSensList, scale=1.0):\n        \"\"\"\n        Add partial sensitivity contribution due to design variables for eigenvalue\n\n        Parameters\n        ----------\n        indices : list[int]\n            Mode indices to return sensitivity for.\n\n        dvSensList : list[tacs.TACS.Vec] or list[numpy.ndarray]\n            List of sensitivity vectors to add partial sensitivity to\n\n        scale : float\n            Scalar to multiply partial sensitivity by. Defaults to 1.0\n        \"\"\"\n        # Set problem vars to assembler\n        self._updateAssemblerVars()\n\n        for index, dvSens in zip(indices, dvSensList):\n            # Create a tacs BVec copy for the operation if the output is a numpy array\n            if isinstance(dvSens, np.ndarray):\n                dvSensBVec = self._arrayToDesignVec(dvSens)\n            # Otherwise the input is already a BVec and we can do the operation in place\n            else:\n                dvSensBVec = dvSens\n\n            self.buckleSolver.addEigenDVSens(scale, index, dvSensBVec)\n\n            # Finalize sensitivity arrays across all procs\n            dvSensBVec.beginSetValues()\n            dvSensBVec.endSetValues()\n\n            # Update from the BVec values, if the input was a numpy array\n            if isinstance(dvSens, np.ndarray):\n                # Copy values to numpy array\n                dvSens[:] = dvSensBVec.getArray()",
  "def evalSVSens(self, indices, svSensList):\n        \"\"\"\n        Add partial sensitivity contribution due to state variables for eigenvalue\n\n        Parameters\n        ----------\n        indices : list[int]\n            Mode indices to return sensitivity for.\n\n        svSensList : list[tacs.TACS.Vec] or list[numpy.ndarray]\n            List of sensitivity vectors to add partial sensitivity to\n        \"\"\"\n        # Set problem vars to assembler\n        self._updateAssemblerVars()\n\n        for index, svSens in zip(indices, svSensList):\n            # Create a tacs BVec copy for the operation if the output is a numpy array\n            if isinstance(svSens, np.ndarray):\n                svSensBVec = self._arrayToVec(svSens)\n            # Otherwise the input is already a BVec and we can do the operation in place\n            else:\n                svSensBVec = svSens\n\n            self.buckleSolver.evalEigenSVSens(index, svSensBVec)\n\n            # Finalize sensitivity arrays across all procs\n            svSensBVec.beginSetValues()\n            svSensBVec.endSetValues()\n\n            # Update from the BVec values, if the input was a numpy array\n            if isinstance(svSens, np.ndarray):\n                # Copy values to numpy array\n                svSens[:] = svSensBVec.getArray()",
  "def writeSolution(self, outputDir=None, baseName=None, number=None, indices=None):\n        \"\"\"\n        This is a generic shell function that writes the output\n        file(s).  The intent is that the user or calling program can\n        call this function and pyTACS writes all the files that the\n        user has defined. It is recommended that this function is used\n        along with the associated logical flags in the options to\n        determine the desired writing procedure\n\n        Parameters\n        ----------\n        outputDir : str or None\n            Use the supplied output directory\n        baseName : str or None\n            Use this supplied string for the base filename. Typically\n            only used from an external solver.\n        number : int or None\n            Use the user supplied number to index solution. Again, only\n            typically used from an external solver\n        indices : int or list[int] or None\n            Mode index or indices to get state variables for.\n            If None, returns a solution for all modes.\n            Defaults to None.\n        \"\"\"\n        # Make sure assembler variables are up-to-date\n        self._updateAssemblerVars()\n\n        # Check input\n        if outputDir is None:\n            outputDir = self.getOption(\"outputDir\")\n\n        if baseName is None:\n            baseName = self.name\n\n        # If we are numbering solution, it saving the sequence of\n        # calls, add the call number\n        if number is not None:\n            # We need number based on the provided number:\n            baseName = baseName + \"_%3.3d\" % number\n        else:\n            # if number is none, i.e. standalone, but we need to\n            # number solutions, use internal counter\n            if self.getOption(\"numberSolutions\"):\n                baseName = baseName + \"_%3.3d\" % self.callCounter\n\n        # Unless the writeSolution option is off write actual file:\n        if self.getOption(\"writeSolution\"):\n            # If indices is None, output all modes\n            if indices is None:\n                indices = np.arange(self.numEigs)\n\n            # Write out each specified mode\n            indices = np.atleast_1d(indices)\n            vec = self.assembler.createVec()\n            for index in indices:\n                # Extract eigenvector\n                eig, _ = self.getVariables(index, states=vec)\n                # Set eigen mode in assembler\n                self.assembler.setVariables(vec)\n                # Write out mode shape as f5 file\n                modeName = baseName + \"_%3.3d\" % index\n                fileName = os.path.join(outputDir, modeName) + \".f5\"\n                self.outputViewer.writeToFile(fileName)",
  "class TransientProblem(TACSProblem):\n    # Default Option List\n    defaultOptions = {\n        \"outputDir\": [str, \"./\", \"Output directory for F5 file writer.\"],\n        # Solution Options\n        \"timeIntegrator\": [\n            str,\n            \"BDF\",\n            \"Time integration scheme to use. Currently supports 'BDF' and 'DIRK'.\",\n        ],\n        \"integrationOrder\": [int, 2, \"Integration order for time marching scheme.\"],\n        \"L2Convergence\": [\n            float,\n            1e-12,\n            \"Absolute convergence tolerance for integrator based on l2 norm of residual.\",\n        ],\n        \"L2ConvergenceRel\": [\n            float,\n            1e-12,\n            \"Relative convergence tolerance for integrator based on l2 norm of residual.\",\n        ],\n        \"RBEStiffnessScaleFactor\": [\n            float,\n            1e3,\n            \"Constraint matrix scaling factor used in RBE Lagrange multiplier stiffness matrix.\",\n        ],\n        \"RBEArtificialStiffness\": [\n            float,\n            1e-3,\n            \"Artificial constant added to diagonals of RBE Lagrange multiplier stiffness matrix \\n\"\n            \"\\t to stabilize preconditioner.\",\n        ],\n        \"jacAssemblyFreq\": [\n            int,\n            1,\n            \"How frequently to reassemble Jacobian during time integration process.\",\n        ],\n        # Output Options\n        \"writeSolution\": [bool, True, \"Flag for suppressing all f5 file writing.\"],\n        \"numberSolutions\": [\n            bool,\n            True,\n            \"Flag for attaching solution counter index to f5 files.\",\n        ],\n        \"printTiming\": [\n            bool,\n            False,\n            \"Flag for printing out timing information for class procedures.\",\n        ],\n        \"printLevel\": [\n            int,\n            0,\n            \"Print level for integration solver.\\n\"\n            \"\\t Accepts:\\n\"\n            \"\\t\\t   0 : No printing.\\n\"\n            \"\\t\\t   1 : Print major iterations.\\n\"\n            \"\\t\\t > 1 : Print major + minor iterations.\",\n        ],\n    }\n\n    def __init__(\n        self,\n        name,\n        tInit,\n        tFinal,\n        numSteps,\n        assembler,\n        comm,\n        outputViewer=None,\n        meshLoader=None,\n        options=None,\n    ):\n        \"\"\"\n        NOTE: This class should not be initialized directly by the user.\n        Use pyTACS.createTransientProblem instead.\n\n        Parameters\n        ----------\n        name : str\n            Name of this tacs problem\n\n        tInit : float\n            Starting time for transient problem integration\n\n        tFinal : float\n            Ending time for transient problem integration\n\n        numSteps : int\n            Number of time steps for transient problem integration\n\n        assembler : TACS.Assembler\n            Cython object responsible for creating and setting tacs objects used to solve problem\n\n        comm : mpi4py.MPI.Intracomm\n            The comm object on which to create the pyTACS object.\n\n        outputViewer : TACS.TACSToFH5\n            Cython object used to write out f5 files that can be converted and used for postprocessing.\n\n        meshLoader : pymeshloader.pyMeshLoader\n            pyMeshLoader object used to create the assembler.\n\n        options : dict\n            Dictionary holding problem-specific option parameters (case-insensitive).\n        \"\"\"\n\n        # Problem name\n        self.name = name\n\n        # Set time interval parameters\n        self.tInit = tInit\n        self.tFinal = tFinal\n        self.numSteps = numSteps\n        self.numStages = None\n\n        # Set integrator to None, until we set it up later\n        self.integrator = None\n\n        # Default setup for common problem class objects, sets up comm and options\n        TACSProblem.__init__(self, assembler, comm, options, outputViewer, meshLoader)\n\n        # Create problem-specific variables\n        self._createVariables()\n\n    def _createVariables(self):\n        \"\"\"\n        Internal to create the objects required by TACS Integrator\n        \"\"\"\n\n        self.callCounter = -1\n\n        # Initialize the initial conditions tacs vectors\n        self.vars0 = self.assembler.createVec()\n        self.dvars0 = self.assembler.createVec()\n        self.ddvars0 = self.assembler.createVec()\n\n        # Get time integration solver attributes\n        order = self.getOption(\"integrationOrder\")\n        solverType = self.getOption(\"timeIntegrator\")\n\n        # dictionary for converting integration order to number of stages\n        DIRK_order_to_stages = {2: 1, 3: 2, 4: 3}\n        ESDIRK_order_to_stages = {3: 4, 4: 6, 5: 8}\n\n        # Create the time integrator and allocate the load data structures\n        if solverType.upper() == \"BDF\":\n            self.integrator = tacs.TACS.BDFIntegrator(\n                self.assembler, self.tInit, self.tFinal, float(self.numSteps), order\n            )\n            # Create a force vector for each time step\n            self.F = [self.assembler.createVec() for i in range(self.numSteps + 1)]\n            # Auxillary element object for applying tractions/pressure\n            self.auxElems = [tacs.TACS.AuxElements() for i in range(self.numSteps + 1)]\n\n        elif solverType.upper() == \"DIRK\":\n            self.numStages = DIRK_order_to_stages[order]\n            self.integrator = tacs.TACS.DIRKIntegrator(\n                self.assembler,\n                self.tInit,\n                self.tFinal,\n                float(self.numSteps),\n                self.numStages,\n            )\n            # Create a force vector for each time stage\n            self.F = [\n                self.assembler.createVec()\n                for i in range((self.numSteps + 1) * self.numStages)\n            ]\n            # Auxiliary element object for applying tractions/pressure at each time stage\n            self.auxElems = [\n                tacs.TACS.AuxElements()\n                for i in range((self.numSteps + 1) * self.numStages)\n            ]\n\n        elif solverType.upper() == \"ESDIRK\":\n            self.numStages = ESDIRK_order_to_stages[order]\n            self.integrator = tacs.TACS.ESDIRKIntegrator(\n                self.assembler,\n                self.tInit,\n                self.tFinal,\n                float(self.numSteps),\n                self.numStages,\n            )\n            # Create a force vector for each time stage\n            self.F = [\n                self.assembler.createVec()\n                for i in range((self.numSteps + 1) * self.numStages)\n            ]\n            # Auxiliary element object for applying tractions/pressure at each time stage\n            self.auxElems = [\n                tacs.TACS.AuxElements()\n                for i in range((self.numSteps + 1) * self.numStages)\n            ]\n\n        printLevel = self.getOption(\"printLevel\")\n        self.integrator.setPrintLevel(printLevel)\n        # Set solver tolerances\n        atol = self.getOption(\"L2Convergence\")\n        self.integrator.setAbsTol(atol)\n        rtol = self.getOption(\"L2ConvergenceRel\")\n        self.integrator.setRelTol(rtol)\n        # Jacobian assembly frequency\n        jacFreq = self.getOption(\"jacAssemblyFreq\")\n        self.integrator.setJacAssemblyFreq(jacFreq)\n\n        # Set output viewer for integrator\n        self.integrator.setFH5(self.outputViewer)\n        outputDir = self.getOption(\"outputDir\")\n        self.integrator.setOutputPrefix(outputDir)\n\n    def setOption(self, name, value):\n        \"\"\"\n        Set a solver option value. The name is not case sensitive.\n\n        Parameters\n        ----------\n        name : str\n            Name of option to modify\n\n        value : depends on option\n            New option value to set\n        \"\"\"\n        # Default setOption for common problem class objects\n        TACSProblem.setOption(self, name, value)\n\n        # Update tolerances\n        if self.integrator is not None:\n            if \"l2convergence\" in name.lower():\n                # Set solver tolerances\n                atol = self.getOption(\"L2Convergence\")\n                self.integrator.setAbsTol(atol)\n                rtol = self.getOption(\"L2ConvergenceRel\")\n                self.integrator.setRelTol(rtol)\n            elif name.lower() == \"printlevel\":\n                printLevel = self.getOption(\"printLevel\")\n                self.integrator.setPrintLevel(printLevel)\n            elif name.lower() == \"jacassemblyfreq\":\n                # Jacobian assembly frequency\n                jacFreq = self.getOption(\"jacAssemblyFreq\")\n                self.integrator.setJacAssemblyFreq(jacFreq)\n            # No need to reset solver for output options\n            elif name.lower() in [\n                \"writesolution\",\n                \"printtiming\",\n                \"numbersolutions\",\n                \"outputdir\",\n            ]:\n                pass\n            # Reset solver for all other option changes\n            else:\n                self._createVariables()\n\n    def getNumTimeSteps(self):\n        \"\"\"\n        Get the number of time steps used in time integration for this problem.\n\n        Returns\n        ----------\n        numSteps : int\n            Number of time steps.\n        \"\"\"\n        # Should this really be numSteps + 1 ?\n        return self.numSteps\n\n    def getTimeSteps(self):\n        \"\"\"\n        Get the discrete time step slices used in time integration.\n\n        Returns\n        ----------\n        timeSteps : numpy.ndarray[float]\n            Discrete time step slices used in time integration.\n        \"\"\"\n        timeSteps = np.linspace(self.tInit, self.tFinal, self.numSteps + 1)\n        return timeSteps\n\n    def getNumTimeStages(self):\n        \"\"\"\n        Get the number of time stages used for multi-stage time integration for this problem.\n\n        Returns\n        ----------\n        numStages : int\n            Number of time stages.\n        \"\"\"\n        # Check if this is a multi-stage problem\n        if self.numStages:\n            return self.numStages\n        # Otherwise its zero stage\n        return 0\n\n    def getTimeStages(self, timeStep):\n        \"\"\"\n        Get the discrete time stage sub-intervals used in a multi-stage integration scheme.\n\n        Parameters\n        ----------\n\n        timeStep : int\n            Time step index to get stage times for.\n\n        Returns\n        ----------\n        timeStages : numpy.ndarray[float]\n            Time step slices used to discretize this time step.\n        \"\"\"\n        # Check if this is a multi-stage problem and if this isn't the first time step\n        if timeStep > 0 and self.numStages:\n            timeStages = np.zeros(self.numStages)\n            for stage in range(self.numStages):\n                timeStages[stage], _, _, _ = self.integrator.getStageStates(\n                    timeStep, stage\n                )\n        # Otherwise, there are no subintervals\n        else:\n            timeStages = np.empty(1)\n        return timeStages\n\n    ####### Load adding methods ########\n\n    def addLoadToComponents(\n        self, timeStep, compIDs, F, timeStage=None, averageLoad=False\n    ):\n        \"\"\"\n        This method is used to add a *FIXED TOTAL LOAD* on one or more\n        components, defined by COMPIDs, at a specific time instance.\n        The purpose of this routine is to add loads that remain fixed throughout\n        an optimization. An example would be an engine load. This routine determines\n        all the unique nodes in the FE model that are part of the requested components,\n        then takes the total 'force' by F and divides by the number of nodes.\n        This average load is then applied to the nodes.\n\n        Parameters\n        ----------\n\n        timeStep : int\n            Time step index to apply load to.\n\n        compIDs : list[int] or int\n            The components with added loads. Use pyTACS.selectCompIDs method\n            to determine this.\n\n        F : Numpy 1d or 2d array length (varsPerNodes) or (numCompIDs, varsPerNodes)\n            Vector(s) of 'force' to apply to each component.  If only one force vector is provided,\n            force will be copied uniformly across all components.\n\n        timeStage : int or None\n            Time stage index to apply load to. Default is None, which is applicable only for\n            multi-step methods like BDF. For multi-stage methods like DIRK, this index must\n            be specified.\n\n        averageLoad : bool\n            Flag to determine whether load should be split evenly across all components (True)\n            or copied and applied individually to each component (False). Defaults to False.\n\n        Notes\n        -----\n\n        The units of the entries of the 'force' vector F are not\n        necessarily physical forces and their interpretation depends\n        on the physics problem being solved and the dofs included\n        in the model.\n\n        A couple of examples of force vector components for common problems are listed below:\n\n            In Heat Conduction with varsPerNode = 1\n                F = [Qdot] # heat rate\n            In Elasticity with varsPerNode = 3,\n                F = [fx, fy, fz] # forces\n            In Elasticity with varsPerNode = 6,\n                F = [fx, fy, fz, mx, my, mz] # forces + moments\n            In Thermoelasticity with varsPerNode = 4,\n                F = [fx, fy, fz, Qdot] # forces + heat rate\n            In Thermoelasticity with varsPerNode = 7,\n                F = [fx, fy, fz, mx, my, mz, Qdot] # forces + moments + heat rate\n        \"\"\"\n        timeIndex = 0\n        if self.numStages is None:\n            timeIndex = timeStep\n        else:\n            assert timeStage is not None, (\n                \"Time stage index must be specified for %s integrator type\"\n                % self.getOption(\"timeIntegrator\").upper()\n            )\n            timeIndex = timeStep * self.numStages + timeStage\n\n        self._addLoadToComponents(self.F[timeIndex], compIDs, F, averageLoad)\n\n    def addLoadToNodes(\n        self, timeStep, nodeIDs, F, timeStage=None, nastranOrdering=False\n    ):\n        \"\"\"\n        This method is used to add a fixed point load of F to the\n        selected node IDs at a specified time instance.\n\n        Parameters\n        ----------\n\n        timeStep : int\n            Time step index to apply load to.\n\n        nodeIDs : list[int]\n            The nodes IDs with added loads.\n\n        F : Numpy 1d or 2d array length (varsPerNodes) or (numNodeIDs, varsPerNodes)\n            Array of force vectors, one for each node. If only one force vector is provided,\n            force will be copied uniformly across all nodes.\n\n        timeStage : int or None\n            Time stage index to apply load to. Default is None, which is applicable only for\n            multi-step methods like BDF. For multi-stage methods like DIRK, this index must\n            be specified.\n\n        nastranOrdering : bool\n            Flag signaling whether nodeIDs are in TACS (default)\n            or NASTRAN (grid IDs in bdf file) ordering\n\n        Notes\n        -----\n\n        The units of the entries of the 'force' vector F are not\n        necessarily physical forces and their interpretation depends\n        on the physics problem being solved and the dofs included\n        in the model.\n\n        A couple of examples of force vector components for common problems are listed below:\n\n            In Heat Conduction with varsPerNode = 1\n                F = [Qdot] # heat rate\n            In Elasticity with varsPerNode = 3,\n                F = [fx, fy, fz] # forces\n            In Elasticity with varsPerNode = 6,\n                F = [fx, fy, fz, mx, my, mz] # forces + moments\n            In Thermoelasticity with varsPerNode = 4,\n                F = [fx, fy, fz, Qdot] # forces + heat rate\n            In Thermoelasticity with varsPerNode = 7,\n                F = [fx, fy, fz, mx, my, mz, Qdot] # forces + moments + heat rate\n        \"\"\"\n        timeIndex = 0\n        if self.numStages is None:\n            timeIndex = timeStep\n        else:\n            assert timeStage is not None, (\n                \"Time stage index must be specified for %s integrator type\"\n                % self.getOption(\"timeIntegrator\").upper()\n            )\n            timeIndex = timeStep * self.numStages + timeStage\n\n        self._addLoadToNodes(self.F[timeIndex], nodeIDs, F, nastranOrdering)\n\n    def addLoadToRHS(self, timeStep, Fapplied, timeStage=None):\n        \"\"\"\n        This method is used to add a *FIXED TOTAL LOAD* directly to the\n        right hand side vector given the equation below:\n\n            M*udotdot + K*u = f\n\n        Where:\n            - K : Stiffness matrix for problem\n            - u : State variables for problem\n            - M : Mass matrix for problem\n            - udotdot : Second time derivitive of state variables for problem\n            - f : Right-hand side vector to add loads to\n\n        Parameters\n        ----------\n\n        timeStep : int\n            Time step index to apply load to.\n\n        Fapplied : numpy.ndarray or tacs.TACS.Vec\n            Distributed array containing loads to applied to RHS of the problem.\n\n        timeStage : int or None\n            Time stage index to apply load to. Default is None, which is applicable only for\n            multi-step methods like BDF. For multi-stage methods like DIRK, this index must\n            be specified.\n\n        \"\"\"\n        timeIndex = 0\n        if self.numStages is None:\n            timeIndex = timeStep\n        else:\n            assert timeStage is not None, (\n                \"Time stage index must be specified for %s integrator type\"\n                % self.getOption(\"timeIntegrator\").upper()\n            )\n            timeIndex = timeStep * self.numStages + timeStage\n\n        self._addLoadToRHS(self.F[timeIndex], Fapplied)\n\n    def addTractionToComponents(\n        self, timeStep, compIDs, tractions, timeStage=None, faceIndex=0\n    ):\n        \"\"\"\n        This method is used to add a *FIXED TOTAL TRACTION* on one or more\n        components, defined by COMPIDs, at specified time instance. The purpose of\n        this routine is to add loads that remain fixed throughout an optimization.\n\n        Parameters\n        ----------\n\n        timeStep : int\n            Time step index to apply load to.\n\n        compIDs : list[int] or int\n            The components with added loads. Use pyTACS.selectCompIDs method\n            to determine this.\n\n        tractions : numpy.ndarray length 1 or compIDs\n            Array of traction vectors for each component\n\n        timeStage : int or None\n            Time stage index to apply load to. Default is None, which is applicable only for\n            multi-step methods like BDF. For multi-stage methods like DIRK, this index must\n            be specified.\n\n        faceIndex : int\n            Indicates which face (side) of element to apply traction to.\n            Note: not required for certain elements (i.e. shells)\n        \"\"\"\n        timeIndex = 0\n        if self.numStages is None:\n            timeIndex = timeStep\n        else:\n            assert timeStage is not None, (\n                \"Time stage index must be specified for %s integrator type\"\n                % self.getOption(\"timeIntegrator\").upper()\n            )\n            timeIndex = timeStep * self.numStages + timeStage\n\n        self._addTractionToComponents(\n            self.auxElems[timeIndex], compIDs, tractions, faceIndex\n        )\n\n    def addTractionToElements(\n        self,\n        timeStep,\n        elemIDs,\n        tractions,\n        timeStage=None,\n        faceIndex=0,\n        nastranOrdering=False,\n    ):\n        \"\"\"\n        This method is used to add a fixed traction to the\n        selected element IDs at specified time instance.\n        Tractions can be specified on an element by element basis\n        (if tractions is a 2d array) or set to a uniform value (if tractions is a 1d array)\n\n        Parameters\n        ----------\n\n        timeStep : int\n            Time step index to apply load to.\n\n        elemIDs : list[int]\n            The global element ID numbers for which to apply the traction.\n\n        tractions : numpy.ndarray 1d or 2d length varsPerNodes or (elemIDs, varsPerNodes)\n            Array of traction vectors for each element\n\n        timeStage : int or None\n            Time stage index to apply load to. Default is None, which is applicable only for\n            multi-step methods like BDF. For multi-stage methods like DIRK, this index must\n            be specified.\n\n        faceIndex : int\n            Indicates which face (side) of element to apply traction to.\n            Note: not required for certain elements (i.e. shells)\n\n        nastranOrdering : bool\n            Flag signaling whether elemIDs are in TACS (default)\n            or NASTRAN ordering\n        \"\"\"\n        timeIndex = 0\n        if self.numStages is None:\n            timeIndex = timeStep\n        else:\n            assert timeStage is not None, (\n                \"Time stage index must be specified for %s integrator type\"\n                % self.getOption(\"timeIntegrator\").upper()\n            )\n            timeIndex = timeStep * self.numStages + timeStage\n\n        self._addTractionToElements(\n            self.auxElems[timeIndex], elemIDs, tractions, faceIndex, nastranOrdering\n        )\n\n    def addPressureToComponents(\n        self, timeStep, compIDs, pressures, timeStage=None, faceIndex=0\n    ):\n        \"\"\"\n        This method is used to add a *FIXED TOTAL PRESSURE* on one or more\n        components, defined by COMPIDs, at specified time instance. The purpose of this routine is\n        to add loads that remain fixed throughout an optimization. An example\n        would be a fuel load.\n\n        Parameters\n        ----------\n\n        timeStep : int\n            Time step index to apply load to.\n\n        compIDs : list[int] or int\n            The components with added loads. Use pyTACS.selectCompIDs method\n            to determine this.\n\n        pressures : Numpy array length 1 or compIDs\n            Array of pressure values for each component\n\n        timeStage : int or None\n            Time stage index to apply load to. Default is None, which is applicable only for\n            multi-step methods like BDF. For multi-stage methods like DIRK, this index must\n            be specified.\n\n        faceIndex : int\n            Indicates which face (side) of element to apply pressure to.\n            Note: not required for certain elements (i.e. shells)\n        \"\"\"\n        timeIndex = 0\n        if self.numStages is None:\n            timeIndex = timeStep\n        else:\n            assert timeStage is not None, (\n                \"Time stage index must be specified for %s integrator type\"\n                % self.getOption(\"timeIntegrator\").upper()\n            )\n            timeIndex = timeStep * self.numStages + timeStage\n\n        self._addPressureToComponents(\n            self.auxElems[timeIndex], compIDs, pressures, faceIndex\n        )\n\n    def addPressureToElements(\n        self,\n        timeStep,\n        elemIDs,\n        pressures,\n        timeStage=None,\n        faceIndex=0,\n        nastranOrdering=False,\n    ):\n        \"\"\"\n        This method is used to add a fixed presure to the\n        selected element IDs at specified time instance.\n        Pressures can be specified on an element by element\n        basis (if pressures is an array) or set to a uniform value (if pressures is a scalar)\n\n        Parameters\n        ----------\n\n        timeStep : int\n            Time step index to apply load to.\n\n        elemIDs : list[int]\n            The global element ID numbers for which to apply the pressure.\n\n        pressures : Numpy array length 1 or elemIDs\n            Array of pressure values for each element\n\n        timeStage : int or None\n            Time stage index to apply load to. Default is None, which is applicable only for\n            multi-step methods like BDF. For multi-stage methods like DIRK, this index must\n            be specified.\n\n        faceIndex : int\n            Indicates which face (side) of element to apply pressure to.\n            Note: not required for certain elements (i.e. shells)\n\n        nastranOrdering : bool\n            Flag signaling whether elemIDs are in TACS (default)\n            or NASTRAN ordering\n        \"\"\"\n        timeIndex = 0\n        if self.numStages is None:\n            timeIndex = timeStep\n        else:\n            assert timeStage is not None, (\n                \"Time stage index must be specified for %s integrator type\"\n                % self.getOption(\"timeIntegrator\").upper()\n            )\n            timeIndex = timeStep * self.numStages + timeStage\n\n        self._addPressureToElements(\n            self.auxElems[timeIndex], elemIDs, pressures, faceIndex, nastranOrdering\n        )\n\n    def addInertialLoad(self, timeStep, inertiaVector, timeStage=None):\n        \"\"\"\n        This method is used to add a fixed inertial load at a specified time step\n        due to a uniform acceleration over the entire model.\n        This is most commonly used to model gravity loads on a model.\n\n        Parameters\n        ----------\n\n        timeStep : int\n            Time step index to apply load to.\n\n        inertiaVector : numpy.ndarray\n            Acceleration vector used to define inertial load.\n\n        timeStage : int or None\n            Time stage index to apply load to. Default is None, which is applicable only for\n            multi-step methods like BDF. For multi-stage methods like DIRK, this index must\n            be specified.\n        \"\"\"\n        timeIndex = 0\n        if self.numStages is None:\n            timeIndex = timeStep\n        else:\n            assert timeStage is not None, (\n                \"Time stage index must be specified for %s integrator type\"\n                % self.getOption(\"timeIntegrator\").upper()\n            )\n            timeIndex = timeStep * self.numStages + timeStage\n\n        self._addInertialLoad(self.auxElems[timeIndex], inertiaVector)\n\n    def addCentrifugalLoad(self, timeStep, omegaVector, rotCenter, timeStage=None):\n        \"\"\"\n        This method is used to add a fixed centrifugal load at at specified time step\n        due to a uniform rotational velocity over the entire model.\n        This is most commonly used to model rotors, rolling aircraft, etc.\n\n        Parameters\n        ----------\n\n        timeStep : int\n            Time step index to apply load to.\n\n        omegaVector : numpy.ndarray\n            Rotational velocity vector (rad/s) used to define centrifugal load.\n\n        rotCenter : numpy.ndarray\n            Location of center of rotation used to define centrifugal load.\n\n        timeStage : int or None\n            Time stage index to apply load to. Default is None, which is applicable only for\n            multi-step methods like BDF. For multi-stage methods like DIRK, this index must\n            be specified.\n        \"\"\"\n        timeIndex = 0\n        if self.numStages is None:\n            timeIndex = timeStep\n        else:\n            assert timeStage is not None, (\n                \"Time stage index must be specified for %s integrator type\"\n                % self.getOption(\"timeIntegrator\").upper()\n            )\n            timeIndex = timeStep * self.numStages + timeStage\n\n        self._addCentrifugalLoad(self.auxElems[timeIndex], omegaVector, rotCenter)\n\n    def addLoadFromBDF(self, timeStep, loadID, timeStage=None, scale=1.0):\n        \"\"\"\n        This method is used to add a fixed load set defined in the BDF file to the problem\n        at a specified time instance. Currently, only supports LOAD, FORCE, MOMENT, GRAV,\n        RFORCE, PLOAD2, and PLOAD4.\n\n        Parameters\n        ----------\n\n        timeStep : int\n            Time step index to apply load to.\n\n        loadID : int\n            Load identification number of load set in BDF file user wishes to add to problem.\n\n        timeStage : int or None\n            Time stage index to apply load to. Default is None, which is applicable only for\n            multi-step methods like BDF. For multi-stage methods like DIRK, this index must\n            be specified.\n\n        scale : float\n            Factor to scale the BDF loads by before adding to problem.\n        \"\"\"\n        timeIndex = 0\n        if self.numStages is None:\n            timeIndex = timeStep\n        else:\n            assert timeStage is not None, (\n                \"Time stage index must be specified for %s integrator type\"\n                % self.getOption(\"timeIntegrator\").upper()\n            )\n            timeIndex = timeStep * self.numStages + timeStage\n\n        self._addLoadFromBDF(self.F[timeIndex], self.auxElems[timeIndex], loadID, scale)\n\n    ####### Transient solver methods ########\n\n    def setInitConditions(self, vars=None, dvars=None, ddvars=None):\n        \"\"\"\n        Set the initial conditions associated with this problem\n\n        Parameters\n        ----------\n        vars : float or numpy.ndarray or tacs.TACS.Vec\n            Initial conditions of the state variables\n        dvars : float or numpy.ndarray or tacs.TACS.Vec\n            Initial conditions of the first time-derivative of the state variables\n        ddvars : float or numpy.ndarray or tacs.TACS.Vec\n            Initial conditions of the second time-derivative of the state variables\n        \"\"\"\n\n        if vars is not None:\n            if isinstance(vars, np.ndarray):\n                vars0Array = self.vars0.getArray()\n                vars0Array[:] = vars[:]\n            elif isinstance(vars, tacs.TACS.Vec):\n                self.vars0.copyValues(vars)\n            else:  # assume type=float\n                vars0Array = self.vars0.getArray()\n                vars0Array[:] = vars\n\n        if dvars is not None:\n            if isinstance(dvars, np.ndarray):\n                dvars0Array = self.dvars0.getArray()\n                dvars0Array[:] = dvars[:]\n            elif isinstance(dvars, tacs.TACS.Vec):\n                self.dvars0.copyValues(dvars)\n            else:  # assume type=float\n                dvars0Array = self.dvars0.getArray()\n                dvars0Array[:] = dvars\n\n        if ddvars is not None:\n            if isinstance(ddvars, np.ndarray):\n                ddvars0Array = self.ddvars0.getArray()\n                ddvars0Array[:] = ddvars[:]\n            elif isinstance(ddvars, tacs.TACS.Vec):\n                self.ddvars0.copyValues(ddvars)\n            else:  # assume type=float\n                ddvars0Array = self.ddvars0.getArray()\n                ddvars0Array[:] = ddvars\n\n    def _updateAssemblerVars(self):\n        \"\"\"\n        Make sure that the assembler is using\n        the input variables associated with this problem\n        \"\"\"\n\n        self.assembler.setDesignVars(self.x)\n        self.assembler.setNodes(self.Xpts)\n        self.assembler.setInitConditions(\n            vec=self.vars0, dvec=self.dvars0, ddvec=self.ddvars0\n        )\n        # Set artificial stiffness factors in rbe class\n        c1 = self.getOption(\"RBEStiffnessScaleFactor\")\n        c2 = self.getOption(\"RBEArtificialStiffness\")\n        tacs.elements.RBE2.setScalingParameters(c1, c2)\n        tacs.elements.RBE3.setScalingParameters(c1, c2)\n\n    def solve(self):\n        \"\"\"\n        Solve the time integrated transient problem. The\n        forces must already be set.\n        \"\"\"\n        startTime = time.time()\n\n        self.callCounter += 1\n\n        setupProblemTime = time.time()\n\n        # Set problem vars to assembler\n        self._updateAssemblerVars()\n\n        initSolveTime = time.time()\n\n        # Loop over every time instance and solve transient problem\n        if self.numStages is None:\n            for i in range(self.numSteps + 1):\n                # Set the auxiliary elements for this time step (tractions/pressures)\n                self.assembler.setAuxElements(self.auxElems[i])\n                self.integrator.iterate(i, forces=self.F[i])\n        else:\n            for i in range(self.numSteps + 1):\n                for j in range(self.numStages):\n                    # Set the auxiliary elements for this time step (tractions/pressures)\n                    timeIndex = i * self.numStages + j\n                    self.assembler.setAuxElements(self.auxElems[timeIndex])\n                    self.integrator.iterateStage(i, j, forces=self.F[timeIndex])\n\n        solveTime = time.time()\n\n        # If timing was was requested print it, if the solution is nonlinear\n        # print this information automatically if printTiming was requested.\n        if self.getOption(\"printTiming\"):\n            self._pp(\"+--------------------------------------------------+\")\n            self._pp(\"|\")\n            self._pp(\"| TACS Solve Times:\")\n            self._pp(\"|\")\n            self._pp(\n                \"| %-30s: %10.3f sec\"\n                % (\"TACS Setup Time\", setupProblemTime - startTime)\n            )\n            self._pp(\n                \"| %-30s: %10.3f sec\"\n                % (\"TACS Solve Init Time\", initSolveTime - setupProblemTime)\n            )\n            self._pp(\n                \"| %-30s: %10.3f sec\" % (\"TACS Solve Time\", solveTime - initSolveTime)\n            )\n            self._pp(\"|\")\n            self._pp(\n                \"| %-30s: %10.3f sec\"\n                % (\"TACS Total Solution Time\", solveTime - startTime)\n            )\n            self._pp(\"+--------------------------------------------------+\")\n\n        return\n\n    def prepIterativeSolve(self):\n        \"\"\"\n        Prepare to solve the time integrated transient problem.\n        \"\"\"\n        self.callCounter += 1\n\n        # set problem vars to assembler\n        self._updateAssemblerVars()\n\n        return\n\n    def iterate(self, timeStep, timeStage=None, Fext=None):\n        \"\"\"\n        Iterate a single time instance in the time integrated transient problem.\n        Useful for iterating an aeroelastic problem that is tightly coupled,\n        where intermediate structural states need to be passed to an external\n        fluid solver.\n\n        Requires the user to use an outer for-loop over the number of time\n        steps/stages of the problem.\n\n        Parameters\n        ----------\n        timeStep : int\n            Time step index to iterate\n\n        timeStage : int or None\n            Time stage index to iterate. If not None, solver must be multistage\n\n        Fext : tacs.TACS.Vec or numpy.ndarray or None\n            If Fext is not None, add this force vector to the loads applied at\n            this time instance. Fext must be sized such that the flattened array\n            is (numOwnedNodes*numVarsPerNode) in length. Useful for applying\n            aerodynamic loads which change at every time instance in a tighly\n            coupled aeroelastic solution.\n\n        Examples\n        --------\n        >>> transientProblem.prepIterativeSolve()\n        >>> for step in range(transientProblem.numSteps + 1):\n        >>>     for stage in range(transientProblem.numStages):\n        >>>         # assume load array comes from an external CFD solver...\n        >>>         Fext = externalCFDSolver.solve(step, stage)\n        >>>         # iterate the transient problem in TACS\n        >>>         transientProblem.iterate(timeStep=step, timeStage=stage, Fext=Fext)\n        >>>         # get the necessary structural states for coupling\n        >>>         time, states, dstates, ddstates = transientProblem.getVariables(timeStep=step, timeStage=stage)\n        \"\"\"\n        # evaluate the time index\n        if timeStage is None:\n            timeIndex = timeStep\n        else:\n            # check that the integrator is multistage\n            assert (\n                self.numStages is not None\n            ), f\"current integrator type {self.getOption('timeIntegrator').upper()} is not multistage, choose a multistage integrator from {['DIRK','ESDIRK']}\"\n            timeIndex = timeStep * self.numStages + timeStage\n\n        # set the loads - do not change self.F[timeIndex] in place\n        FVec = self.assembler.createVec()\n        FVec.copyValues(self.F[timeIndex])\n        if Fext is not None:\n            if isinstance(Fext, tacs.TACS.Vec):\n                FVec.axpy(1.0, Fext)\n            elif isinstance(Fext, np.ndarray):\n                if Fext.ndim > 1:\n                    Fext = Fext.ravel()\n                FextVec = self.assembler.createVec()\n                Fext_array = FextVec.getArray()\n                Fext_array[:] = Fext\n                FVec.axpy(1.0, FextVec)\n\n        # set the auxiliary elements for this time step (tractions/pressures)\n        self.assembler.setAuxElements(self.auxElems[timeIndex])\n\n        # iterate this time instance\n        if timeStage is None:\n            self.integrator.iterate(timeIndex, forces=FVec)\n        else:\n            self.integrator.iterateStage(timeStep, timeStage, forces=FVec)\n\n        return\n\n    ####### Function eval/sensitivity methods ########\n\n    def addFunction(self, funcName, funcHandle, compIDs=None, **kwargs):\n        \"\"\"\n        Generic method to add a function for TACS. It is intended to\n        be reasonably generic since the user supplies the actual\n        function handle to use. See the :py:mod:`~tacs.functions` module\n        for supported TACS eval functions.\n\n        Parameters\n        ----------\n        funcName : str\n            The user-supplied name for the function. This will\n            typically be a string that is meaningful to the user\n\n        funcHandle : tacs.TACS.Function\n            The function handle to use for creation. This must come\n            from the functions module in tacs.\n\n        compIDs: list\n            List of compIDs to select.\n\n        **kwargs:\n            Any keyword arguments to be passed to the TACS function during setup.\n        \"\"\"\n\n        # Warn the users if these functions are attempted to be passed.\n        if funcHandle in [tacs.functions.MomentOfInertia, tacs.functions.CenterOfMass]:\n            self._TACSWarning(\n                f\"{funcHandle.__name__} is not supported for {type(self).__name__} problem types\"\n                f\" and may not give consistent results.\"\n            )\n\n        return TACSProblem.addFunction(self, funcName, funcHandle, compIDs, **kwargs)\n\n    def evalFunctions(self, funcs, evalFuncs=None, ignoreMissing=False):\n        \"\"\"\n        This is the main routine for returning useful information from\n        pytacs. The functions corresponding to the strings in\n        evalFuncs are evaluated and updated into the provided\n        dictionary.\n\n        Parameters\n        ----------\n        funcs : dict\n            Dictionary into which the functions are saved.\n        evalFuncs : iterable object containing strings.\n            If not none, use these functions to evaluate.\n        ignoreMissing : bool\n            Flag to supress checking for a valid function. Please use\n            this option with caution.\n\n        Examples\n        --------\n        >>> funcs = {}\n        >>> transientProblem.solve()\n        >>> transientProblem.evalFunctions(funcs, ['mass'])\n        >>> funcs\n        >>> # Result will look like (if TransientProblem has name of 'c1'):\n        >>> # {'cl_mass':12354.10}\n        \"\"\"\n        startTime = time.time()\n\n        # Set problem vars to assembler\n        self._updateAssemblerVars()\n\n        if evalFuncs is None:\n            evalFuncs = sorted(list(self.functionList))\n        else:\n            evalFuncs = sorted(list(evalFuncs))\n\n        if not ignoreMissing:\n            for f in evalFuncs:\n                if f not in self.functionList:\n                    raise self._TACSError(\n                        f\"Supplied function '{f}' has not been added \"\n                        \"using addFunction().\"\n                    )\n\n        setupProblemTime = time.time()\n\n        # Fast parallel function evaluation of structural funcs:\n        handles = [self.functionList[f] for f in evalFuncs if f in self.functionList]\n        # Set functions for integrator\n        self.integrator.setFunctions(handles)\n        # Evaluate functions\n        funcVals = self.integrator.evalFunctions(handles)\n\n        functionEvalTime = time.time()\n\n        # Assign function values to appropriate dictionary\n        i = 0\n        for f in evalFuncs:\n            if f in self.functionList:\n                key = self.name + \"_%s\" % f\n                funcs[key] = funcVals[i]\n                i += 1\n\n        dictAssignTime = time.time()\n\n        if self.getOption(\"printTiming\"):\n            self._pp(\"+--------------------------------------------------+\")\n            self._pp(\"|\")\n            self._pp(\"| TACS Function Times:\")\n            self._pp(\"|\")\n            self._pp(\n                \"| %-30s: %10.3f sec\"\n                % (\"TACS Function Setup Time\", setupProblemTime - startTime)\n            )\n            self._pp(\n                \"| %-30s: %10.3f sec\"\n                % (\"TACS Function Eval Time\", functionEvalTime - setupProblemTime)\n            )\n            self._pp(\n                \"| %-30s: %10.3f sec\"\n                % (\"TACS Dict Time\", dictAssignTime - functionEvalTime)\n            )\n            self._pp(\"|\")\n            self._pp(\n                \"| %-30s: %10.3f sec\"\n                % (\"TACS Function Time\", dictAssignTime - startTime)\n            )\n            self._pp(\"+--------------------------------------------------+\")\n\n    def evalFunctionsSens(self, funcsSens, evalFuncs=None):\n        \"\"\"\n        This is the main routine for returning useful (sensitivity)\n        information from problem. The derivatives of the functions\n        corresponding to the strings in evalFuncs are evaluated and\n        updated into the provided dictionary. The derivitives with\n        respect to all design variables and node locations are computed.\n\n        Parameters\n        ----------\n        funcsSens : dict\n            Dictionary into which the derivatives are saved.\n        evalFuncs : iterable object containing strings\n            The functions the user wants returned\n\n        Examples\n        --------\n        >>> funcsSens = {}\n        >>> transientProblem.evalFunctionsSens(funcsSens, ['mass'])\n        >>> funcsSens\n        >>> # Result will look like (if TransientProblem has name of 'c1'):\n        >>> # {'c1_mass':{'struct':[1.234, ..., 7.89], 'Xpts':[3.14, ..., 1.59]}}\n        \"\"\"\n\n        startTime = time.time()\n\n        # Set problem vars to assembler\n        self._updateAssemblerVars()\n\n        if evalFuncs is None:\n            evalFuncs = sorted(list(self.functionList))\n        else:\n            evalFuncs = sorted(list(evalFuncs))\n\n        for f in evalFuncs:\n            if f not in self.functionList:\n                raise self._TACSError(\n                    \"Supplied function has not been added \" \"using addFunction()\"\n                )\n\n        # Fast parallel function evaluation of structural funcs:\n        handles = [self.functionList[f] for f in evalFuncs if f in self.functionList]\n        # Set functions for integrator\n        self.integrator.setFunctions(handles)\n\n        # integrate adjoints backwards in time from step = numSteps\n        # to step = 0\n        for i in range(self.numSteps, -1, -1):\n            self.assembler.setAuxElements(self.auxElems[i])\n            self.integrator.initAdjoint(i)\n            self.integrator.iterateAdjoint(i)\n            self.integrator.postAdjoint(i)\n\n        adjointFinishedTime = time.time()\n\n        # Recast sensitivities into dict for user\n        for i, f in enumerate(evalFuncs):\n            key = self.name + \"_%s\" % f\n            # Finalize sensitivity arrays across all procs\n            dvSens = self.integrator.getGradient(i)\n            dvSens.beginSetValues()\n            dvSens.endSetValues()\n            xptSens = self.integrator.getXptGradient(i)\n            xptSens.beginSetValues()\n            xptSens.endSetValues()\n            # Return sensitivities as array in sens dict\n            funcsSens[key] = {\n                self.varName: dvSens.getArray().copy(),\n                self.coordName: xptSens.getArray().copy(),\n            }\n\n        totalSensitivityTime = time.time()\n\n        if self.getOption(\"printTiming\"):\n            self._pp(\"+--------------------------------------------------+\")\n            self._pp(\"|\")\n            self._pp(\"| TACS Adjoint Times:\")\n            print(\"|\")\n            print(\n                \"| %-30s: %10.3f sec\"\n                % (\"Adjoint solve time\", adjointFinishedTime - startTime)\n            )\n            print(\"|\")\n            print(\n                \"| %-30s: %10.3f sec\"\n                % (\"Complete Sensitivity Time\", totalSensitivityTime - startTime)\n            )\n            print(\"+--------------------------------------------------+\")\n\n    ####### Post processing methods ########\n\n    def getVariables(\n        self, timeStep, timeStage=None, states=None, dstates=None, ddstates=None\n    ):\n        \"\"\"\n        Return the current state values for the current problem\n\n        Parameters\n        ----------\n        timeStep : int\n            Time step index to get state variables for.\n\n        timeStage : int or None\n            Time stage index to get state variables for.\n\n        states : tacs.TACS.Vec or numpy.ndarray or None\n            If states is not None, place the state variables into this array (optional).\n\n        dstates : tacs.TACS.Vec or numpy.ndarray or None\n            If dstates is not None, place the time derivative of the state variables into this array (optional).\n\n        ddstates : tacs.TACS.Vec or numpy.ndarray or None\n            If ddstates is not None, place the second time derivative of the state variables into this array (optional).\n\n        Returns\n        --------\n        time: float\n            The time at specified time instance\n\n        states : tacs.TACS.Vec or numpy.ndarray\n            The state variables.\n\n        dstates : tacs.TACS.Vec or numpy.ndarray or None\n            The time derivative of the state variables.\n\n        ddstates : tacs.TACS.Vec or numpy.ndarray or None\n            The second time derivative of the state variables.\n\n        \"\"\"\n\n        # Get BVecs for time instance\n        if timeStage is None:\n            time, q, qdot, qddot = self.integrator.getStates(timeStep)\n        else:\n            # check that the integrator is multistage\n            assert (\n                self.numStages is not None\n            ), f\"current integrator type {self.getOption('timeIntegrator').upper()} is not multistage, choose a multistage integrator from {['DIRK','ESDIRK']}\"\n            time, q, qdot, qddot = self.integrator.getStageStates(timeStep, timeStage)\n\n        # Convert to arrays\n        qArray = q.getArray()\n        qdotArray = qdot.getArray()\n        qddotArray = qddot.getArray()\n\n        # Inplace assignment if vectors were provided\n        if isinstance(states, tacs.TACS.Vec):\n            states.copyValues(q)\n        elif isinstance(states, np.ndarray):\n            states[:] = qArray\n\n        if isinstance(dstates, tacs.TACS.Vec):\n            dstates.copyValues(qdot)\n        elif isinstance(dstates, np.ndarray):\n            dstates[:] = qdotArray\n\n        if isinstance(ddstates, tacs.TACS.Vec):\n            ddstates.copyValues(qddot)\n        elif isinstance(ddstates, np.ndarray):\n            ddstates[:] = qddotArray\n\n        # Return arrays\n        return time, qArray, qdotArray, qddotArray\n\n    def zeroLoads(self):\n        \"\"\"\n        Zero all applied loads\n        \"\"\"\n        for Fvec in self.F:\n            Fvec.zeroEntries()\n        for i in range(len(self.auxElems)):\n            self.auxElems[i] = tacs.TACS.AuxElements()\n\n    def writeSolution(self, outputDir=None, baseName=None, number=None, timeSteps=None):\n        \"\"\"\n        This is a generic shell function that writes the output\n        file(s).  The intent is that the user or calling program can\n        call this function and pyTACS writes all the files that the\n        user has defined. It is recommended that this function is used\n        along with the associated logical flags in the options to\n        determine the desired writing procedure\n\n        Parameters\n        ----------\n        outputDir : str or None\n            Use the supplied output directory\n        baseName : str or None\n            Use this supplied string for the base filename. Typically\n            only used from an external solver.\n        number : int or None\n            Use the user supplied number to index solution. Again, only\n            typically used from an external solver\n        timeSteps : int or list[int] or None\n            Time step index or indices to get state variables for.\n            If None, returns a solution for all time steps.\n            Defaults to None.\n        \"\"\"\n        # Make sure assembler variables are up-to-date\n        self._updateAssemblerVars()\n\n        # Check input\n        if outputDir is None:\n            outputDir = self.getOption(\"outputDir\")\n\n        if baseName is None:\n            baseName = self.name\n\n        # If we are numbering solution, it saving the sequence of\n        # calls, add the call number\n        if number is not None:\n            # We need number based on the provided number:\n            baseName = baseName + \"_%3.3d\" % number\n        else:\n            # if number is none, i.e. standalone, but we need to\n            # number solutions, use internal counter\n            if self.getOption(\"numberSolutions\"):\n                baseName = baseName + \"_%3.3d\" % self.callCounter\n\n        # Unless the writeSolution option is off write actual file:\n        if self.getOption(\"writeSolution\"):\n            # If timeSteps is None, output all timesteps\n            if timeSteps is None:\n                timeSteps = np.arange(self.numSteps + 1)\n\n            # Write out each specified timestep\n            timeSteps = np.atleast_1d(timeSteps)\n            vec = self.assembler.createVec()\n            dvec = self.assembler.createVec()\n            ddvec = self.assembler.createVec()\n            for timeStep in timeSteps:\n                # Extract solution for timestep\n                self.getVariables(timeStep, states=vec, dstates=dvec, ddstates=ddvec)\n                # Set timestep solution in assembler\n                self.assembler.setVariables(vec, dvec, ddvec)\n                # Write out timestep as f5 file\n                stepName = baseName + \"_%3.3d\" % timeStep\n                fileName = os.path.join(outputDir, stepName) + \".f5\"\n                self.outputViewer.writeToFile(fileName)",
  "def __init__(\n        self,\n        name,\n        tInit,\n        tFinal,\n        numSteps,\n        assembler,\n        comm,\n        outputViewer=None,\n        meshLoader=None,\n        options=None,\n    ):\n        \"\"\"\n        NOTE: This class should not be initialized directly by the user.\n        Use pyTACS.createTransientProblem instead.\n\n        Parameters\n        ----------\n        name : str\n            Name of this tacs problem\n\n        tInit : float\n            Starting time for transient problem integration\n\n        tFinal : float\n            Ending time for transient problem integration\n\n        numSteps : int\n            Number of time steps for transient problem integration\n\n        assembler : TACS.Assembler\n            Cython object responsible for creating and setting tacs objects used to solve problem\n\n        comm : mpi4py.MPI.Intracomm\n            The comm object on which to create the pyTACS object.\n\n        outputViewer : TACS.TACSToFH5\n            Cython object used to write out f5 files that can be converted and used for postprocessing.\n\n        meshLoader : pymeshloader.pyMeshLoader\n            pyMeshLoader object used to create the assembler.\n\n        options : dict\n            Dictionary holding problem-specific option parameters (case-insensitive).\n        \"\"\"\n\n        # Problem name\n        self.name = name\n\n        # Set time interval parameters\n        self.tInit = tInit\n        self.tFinal = tFinal\n        self.numSteps = numSteps\n        self.numStages = None\n\n        # Set integrator to None, until we set it up later\n        self.integrator = None\n\n        # Default setup for common problem class objects, sets up comm and options\n        TACSProblem.__init__(self, assembler, comm, options, outputViewer, meshLoader)\n\n        # Create problem-specific variables\n        self._createVariables()",
  "def _createVariables(self):\n        \"\"\"\n        Internal to create the objects required by TACS Integrator\n        \"\"\"\n\n        self.callCounter = -1\n\n        # Initialize the initial conditions tacs vectors\n        self.vars0 = self.assembler.createVec()\n        self.dvars0 = self.assembler.createVec()\n        self.ddvars0 = self.assembler.createVec()\n\n        # Get time integration solver attributes\n        order = self.getOption(\"integrationOrder\")\n        solverType = self.getOption(\"timeIntegrator\")\n\n        # dictionary for converting integration order to number of stages\n        DIRK_order_to_stages = {2: 1, 3: 2, 4: 3}\n        ESDIRK_order_to_stages = {3: 4, 4: 6, 5: 8}\n\n        # Create the time integrator and allocate the load data structures\n        if solverType.upper() == \"BDF\":\n            self.integrator = tacs.TACS.BDFIntegrator(\n                self.assembler, self.tInit, self.tFinal, float(self.numSteps), order\n            )\n            # Create a force vector for each time step\n            self.F = [self.assembler.createVec() for i in range(self.numSteps + 1)]\n            # Auxillary element object for applying tractions/pressure\n            self.auxElems = [tacs.TACS.AuxElements() for i in range(self.numSteps + 1)]\n\n        elif solverType.upper() == \"DIRK\":\n            self.numStages = DIRK_order_to_stages[order]\n            self.integrator = tacs.TACS.DIRKIntegrator(\n                self.assembler,\n                self.tInit,\n                self.tFinal,\n                float(self.numSteps),\n                self.numStages,\n            )\n            # Create a force vector for each time stage\n            self.F = [\n                self.assembler.createVec()\n                for i in range((self.numSteps + 1) * self.numStages)\n            ]\n            # Auxiliary element object for applying tractions/pressure at each time stage\n            self.auxElems = [\n                tacs.TACS.AuxElements()\n                for i in range((self.numSteps + 1) * self.numStages)\n            ]\n\n        elif solverType.upper() == \"ESDIRK\":\n            self.numStages = ESDIRK_order_to_stages[order]\n            self.integrator = tacs.TACS.ESDIRKIntegrator(\n                self.assembler,\n                self.tInit,\n                self.tFinal,\n                float(self.numSteps),\n                self.numStages,\n            )\n            # Create a force vector for each time stage\n            self.F = [\n                self.assembler.createVec()\n                for i in range((self.numSteps + 1) * self.numStages)\n            ]\n            # Auxiliary element object for applying tractions/pressure at each time stage\n            self.auxElems = [\n                tacs.TACS.AuxElements()\n                for i in range((self.numSteps + 1) * self.numStages)\n            ]\n\n        printLevel = self.getOption(\"printLevel\")\n        self.integrator.setPrintLevel(printLevel)\n        # Set solver tolerances\n        atol = self.getOption(\"L2Convergence\")\n        self.integrator.setAbsTol(atol)\n        rtol = self.getOption(\"L2ConvergenceRel\")\n        self.integrator.setRelTol(rtol)\n        # Jacobian assembly frequency\n        jacFreq = self.getOption(\"jacAssemblyFreq\")\n        self.integrator.setJacAssemblyFreq(jacFreq)\n\n        # Set output viewer for integrator\n        self.integrator.setFH5(self.outputViewer)\n        outputDir = self.getOption(\"outputDir\")\n        self.integrator.setOutputPrefix(outputDir)",
  "def setOption(self, name, value):\n        \"\"\"\n        Set a solver option value. The name is not case sensitive.\n\n        Parameters\n        ----------\n        name : str\n            Name of option to modify\n\n        value : depends on option\n            New option value to set\n        \"\"\"\n        # Default setOption for common problem class objects\n        TACSProblem.setOption(self, name, value)\n\n        # Update tolerances\n        if self.integrator is not None:\n            if \"l2convergence\" in name.lower():\n                # Set solver tolerances\n                atol = self.getOption(\"L2Convergence\")\n                self.integrator.setAbsTol(atol)\n                rtol = self.getOption(\"L2ConvergenceRel\")\n                self.integrator.setRelTol(rtol)\n            elif name.lower() == \"printlevel\":\n                printLevel = self.getOption(\"printLevel\")\n                self.integrator.setPrintLevel(printLevel)\n            elif name.lower() == \"jacassemblyfreq\":\n                # Jacobian assembly frequency\n                jacFreq = self.getOption(\"jacAssemblyFreq\")\n                self.integrator.setJacAssemblyFreq(jacFreq)\n            # No need to reset solver for output options\n            elif name.lower() in [\n                \"writesolution\",\n                \"printtiming\",\n                \"numbersolutions\",\n                \"outputdir\",\n            ]:\n                pass\n            # Reset solver for all other option changes\n            else:\n                self._createVariables()",
  "def getNumTimeSteps(self):\n        \"\"\"\n        Get the number of time steps used in time integration for this problem.\n\n        Returns\n        ----------\n        numSteps : int\n            Number of time steps.\n        \"\"\"\n        # Should this really be numSteps + 1 ?\n        return self.numSteps",
  "def getTimeSteps(self):\n        \"\"\"\n        Get the discrete time step slices used in time integration.\n\n        Returns\n        ----------\n        timeSteps : numpy.ndarray[float]\n            Discrete time step slices used in time integration.\n        \"\"\"\n        timeSteps = np.linspace(self.tInit, self.tFinal, self.numSteps + 1)\n        return timeSteps",
  "def getNumTimeStages(self):\n        \"\"\"\n        Get the number of time stages used for multi-stage time integration for this problem.\n\n        Returns\n        ----------\n        numStages : int\n            Number of time stages.\n        \"\"\"\n        # Check if this is a multi-stage problem\n        if self.numStages:\n            return self.numStages\n        # Otherwise its zero stage\n        return 0",
  "def getTimeStages(self, timeStep):\n        \"\"\"\n        Get the discrete time stage sub-intervals used in a multi-stage integration scheme.\n\n        Parameters\n        ----------\n\n        timeStep : int\n            Time step index to get stage times for.\n\n        Returns\n        ----------\n        timeStages : numpy.ndarray[float]\n            Time step slices used to discretize this time step.\n        \"\"\"\n        # Check if this is a multi-stage problem and if this isn't the first time step\n        if timeStep > 0 and self.numStages:\n            timeStages = np.zeros(self.numStages)\n            for stage in range(self.numStages):\n                timeStages[stage], _, _, _ = self.integrator.getStageStates(\n                    timeStep, stage\n                )\n        # Otherwise, there are no subintervals\n        else:\n            timeStages = np.empty(1)\n        return timeStages",
  "def addLoadToComponents(\n        self, timeStep, compIDs, F, timeStage=None, averageLoad=False\n    ):\n        \"\"\"\n        This method is used to add a *FIXED TOTAL LOAD* on one or more\n        components, defined by COMPIDs, at a specific time instance.\n        The purpose of this routine is to add loads that remain fixed throughout\n        an optimization. An example would be an engine load. This routine determines\n        all the unique nodes in the FE model that are part of the requested components,\n        then takes the total 'force' by F and divides by the number of nodes.\n        This average load is then applied to the nodes.\n\n        Parameters\n        ----------\n\n        timeStep : int\n            Time step index to apply load to.\n\n        compIDs : list[int] or int\n            The components with added loads. Use pyTACS.selectCompIDs method\n            to determine this.\n\n        F : Numpy 1d or 2d array length (varsPerNodes) or (numCompIDs, varsPerNodes)\n            Vector(s) of 'force' to apply to each component.  If only one force vector is provided,\n            force will be copied uniformly across all components.\n\n        timeStage : int or None\n            Time stage index to apply load to. Default is None, which is applicable only for\n            multi-step methods like BDF. For multi-stage methods like DIRK, this index must\n            be specified.\n\n        averageLoad : bool\n            Flag to determine whether load should be split evenly across all components (True)\n            or copied and applied individually to each component (False). Defaults to False.\n\n        Notes\n        -----\n\n        The units of the entries of the 'force' vector F are not\n        necessarily physical forces and their interpretation depends\n        on the physics problem being solved and the dofs included\n        in the model.\n\n        A couple of examples of force vector components for common problems are listed below:\n\n            In Heat Conduction with varsPerNode = 1\n                F = [Qdot] # heat rate\n            In Elasticity with varsPerNode = 3,\n                F = [fx, fy, fz] # forces\n            In Elasticity with varsPerNode = 6,\n                F = [fx, fy, fz, mx, my, mz] # forces + moments\n            In Thermoelasticity with varsPerNode = 4,\n                F = [fx, fy, fz, Qdot] # forces + heat rate\n            In Thermoelasticity with varsPerNode = 7,\n                F = [fx, fy, fz, mx, my, mz, Qdot] # forces + moments + heat rate\n        \"\"\"\n        timeIndex = 0\n        if self.numStages is None:\n            timeIndex = timeStep\n        else:\n            assert timeStage is not None, (\n                \"Time stage index must be specified for %s integrator type\"\n                % self.getOption(\"timeIntegrator\").upper()\n            )\n            timeIndex = timeStep * self.numStages + timeStage\n\n        self._addLoadToComponents(self.F[timeIndex], compIDs, F, averageLoad)",
  "def addLoadToNodes(\n        self, timeStep, nodeIDs, F, timeStage=None, nastranOrdering=False\n    ):\n        \"\"\"\n        This method is used to add a fixed point load of F to the\n        selected node IDs at a specified time instance.\n\n        Parameters\n        ----------\n\n        timeStep : int\n            Time step index to apply load to.\n\n        nodeIDs : list[int]\n            The nodes IDs with added loads.\n\n        F : Numpy 1d or 2d array length (varsPerNodes) or (numNodeIDs, varsPerNodes)\n            Array of force vectors, one for each node. If only one force vector is provided,\n            force will be copied uniformly across all nodes.\n\n        timeStage : int or None\n            Time stage index to apply load to. Default is None, which is applicable only for\n            multi-step methods like BDF. For multi-stage methods like DIRK, this index must\n            be specified.\n\n        nastranOrdering : bool\n            Flag signaling whether nodeIDs are in TACS (default)\n            or NASTRAN (grid IDs in bdf file) ordering\n\n        Notes\n        -----\n\n        The units of the entries of the 'force' vector F are not\n        necessarily physical forces and their interpretation depends\n        on the physics problem being solved and the dofs included\n        in the model.\n\n        A couple of examples of force vector components for common problems are listed below:\n\n            In Heat Conduction with varsPerNode = 1\n                F = [Qdot] # heat rate\n            In Elasticity with varsPerNode = 3,\n                F = [fx, fy, fz] # forces\n            In Elasticity with varsPerNode = 6,\n                F = [fx, fy, fz, mx, my, mz] # forces + moments\n            In Thermoelasticity with varsPerNode = 4,\n                F = [fx, fy, fz, Qdot] # forces + heat rate\n            In Thermoelasticity with varsPerNode = 7,\n                F = [fx, fy, fz, mx, my, mz, Qdot] # forces + moments + heat rate\n        \"\"\"\n        timeIndex = 0\n        if self.numStages is None:\n            timeIndex = timeStep\n        else:\n            assert timeStage is not None, (\n                \"Time stage index must be specified for %s integrator type\"\n                % self.getOption(\"timeIntegrator\").upper()\n            )\n            timeIndex = timeStep * self.numStages + timeStage\n\n        self._addLoadToNodes(self.F[timeIndex], nodeIDs, F, nastranOrdering)",
  "def addLoadToRHS(self, timeStep, Fapplied, timeStage=None):\n        \"\"\"\n        This method is used to add a *FIXED TOTAL LOAD* directly to the\n        right hand side vector given the equation below:\n\n            M*udotdot + K*u = f\n\n        Where:\n            - K : Stiffness matrix for problem\n            - u : State variables for problem\n            - M : Mass matrix for problem\n            - udotdot : Second time derivitive of state variables for problem\n            - f : Right-hand side vector to add loads to\n\n        Parameters\n        ----------\n\n        timeStep : int\n            Time step index to apply load to.\n\n        Fapplied : numpy.ndarray or tacs.TACS.Vec\n            Distributed array containing loads to applied to RHS of the problem.\n\n        timeStage : int or None\n            Time stage index to apply load to. Default is None, which is applicable only for\n            multi-step methods like BDF. For multi-stage methods like DIRK, this index must\n            be specified.\n\n        \"\"\"\n        timeIndex = 0\n        if self.numStages is None:\n            timeIndex = timeStep\n        else:\n            assert timeStage is not None, (\n                \"Time stage index must be specified for %s integrator type\"\n                % self.getOption(\"timeIntegrator\").upper()\n            )\n            timeIndex = timeStep * self.numStages + timeStage\n\n        self._addLoadToRHS(self.F[timeIndex], Fapplied)",
  "def addTractionToComponents(\n        self, timeStep, compIDs, tractions, timeStage=None, faceIndex=0\n    ):\n        \"\"\"\n        This method is used to add a *FIXED TOTAL TRACTION* on one or more\n        components, defined by COMPIDs, at specified time instance. The purpose of\n        this routine is to add loads that remain fixed throughout an optimization.\n\n        Parameters\n        ----------\n\n        timeStep : int\n            Time step index to apply load to.\n\n        compIDs : list[int] or int\n            The components with added loads. Use pyTACS.selectCompIDs method\n            to determine this.\n\n        tractions : numpy.ndarray length 1 or compIDs\n            Array of traction vectors for each component\n\n        timeStage : int or None\n            Time stage index to apply load to. Default is None, which is applicable only for\n            multi-step methods like BDF. For multi-stage methods like DIRK, this index must\n            be specified.\n\n        faceIndex : int\n            Indicates which face (side) of element to apply traction to.\n            Note: not required for certain elements (i.e. shells)\n        \"\"\"\n        timeIndex = 0\n        if self.numStages is None:\n            timeIndex = timeStep\n        else:\n            assert timeStage is not None, (\n                \"Time stage index must be specified for %s integrator type\"\n                % self.getOption(\"timeIntegrator\").upper()\n            )\n            timeIndex = timeStep * self.numStages + timeStage\n\n        self._addTractionToComponents(\n            self.auxElems[timeIndex], compIDs, tractions, faceIndex\n        )",
  "def addTractionToElements(\n        self,\n        timeStep,\n        elemIDs,\n        tractions,\n        timeStage=None,\n        faceIndex=0,\n        nastranOrdering=False,\n    ):\n        \"\"\"\n        This method is used to add a fixed traction to the\n        selected element IDs at specified time instance.\n        Tractions can be specified on an element by element basis\n        (if tractions is a 2d array) or set to a uniform value (if tractions is a 1d array)\n\n        Parameters\n        ----------\n\n        timeStep : int\n            Time step index to apply load to.\n\n        elemIDs : list[int]\n            The global element ID numbers for which to apply the traction.\n\n        tractions : numpy.ndarray 1d or 2d length varsPerNodes or (elemIDs, varsPerNodes)\n            Array of traction vectors for each element\n\n        timeStage : int or None\n            Time stage index to apply load to. Default is None, which is applicable only for\n            multi-step methods like BDF. For multi-stage methods like DIRK, this index must\n            be specified.\n\n        faceIndex : int\n            Indicates which face (side) of element to apply traction to.\n            Note: not required for certain elements (i.e. shells)\n\n        nastranOrdering : bool\n            Flag signaling whether elemIDs are in TACS (default)\n            or NASTRAN ordering\n        \"\"\"\n        timeIndex = 0\n        if self.numStages is None:\n            timeIndex = timeStep\n        else:\n            assert timeStage is not None, (\n                \"Time stage index must be specified for %s integrator type\"\n                % self.getOption(\"timeIntegrator\").upper()\n            )\n            timeIndex = timeStep * self.numStages + timeStage\n\n        self._addTractionToElements(\n            self.auxElems[timeIndex], elemIDs, tractions, faceIndex, nastranOrdering\n        )",
  "def addPressureToComponents(\n        self, timeStep, compIDs, pressures, timeStage=None, faceIndex=0\n    ):\n        \"\"\"\n        This method is used to add a *FIXED TOTAL PRESSURE* on one or more\n        components, defined by COMPIDs, at specified time instance. The purpose of this routine is\n        to add loads that remain fixed throughout an optimization. An example\n        would be a fuel load.\n\n        Parameters\n        ----------\n\n        timeStep : int\n            Time step index to apply load to.\n\n        compIDs : list[int] or int\n            The components with added loads. Use pyTACS.selectCompIDs method\n            to determine this.\n\n        pressures : Numpy array length 1 or compIDs\n            Array of pressure values for each component\n\n        timeStage : int or None\n            Time stage index to apply load to. Default is None, which is applicable only for\n            multi-step methods like BDF. For multi-stage methods like DIRK, this index must\n            be specified.\n\n        faceIndex : int\n            Indicates which face (side) of element to apply pressure to.\n            Note: not required for certain elements (i.e. shells)\n        \"\"\"\n        timeIndex = 0\n        if self.numStages is None:\n            timeIndex = timeStep\n        else:\n            assert timeStage is not None, (\n                \"Time stage index must be specified for %s integrator type\"\n                % self.getOption(\"timeIntegrator\").upper()\n            )\n            timeIndex = timeStep * self.numStages + timeStage\n\n        self._addPressureToComponents(\n            self.auxElems[timeIndex], compIDs, pressures, faceIndex\n        )",
  "def addPressureToElements(\n        self,\n        timeStep,\n        elemIDs,\n        pressures,\n        timeStage=None,\n        faceIndex=0,\n        nastranOrdering=False,\n    ):\n        \"\"\"\n        This method is used to add a fixed presure to the\n        selected element IDs at specified time instance.\n        Pressures can be specified on an element by element\n        basis (if pressures is an array) or set to a uniform value (if pressures is a scalar)\n\n        Parameters\n        ----------\n\n        timeStep : int\n            Time step index to apply load to.\n\n        elemIDs : list[int]\n            The global element ID numbers for which to apply the pressure.\n\n        pressures : Numpy array length 1 or elemIDs\n            Array of pressure values for each element\n\n        timeStage : int or None\n            Time stage index to apply load to. Default is None, which is applicable only for\n            multi-step methods like BDF. For multi-stage methods like DIRK, this index must\n            be specified.\n\n        faceIndex : int\n            Indicates which face (side) of element to apply pressure to.\n            Note: not required for certain elements (i.e. shells)\n\n        nastranOrdering : bool\n            Flag signaling whether elemIDs are in TACS (default)\n            or NASTRAN ordering\n        \"\"\"\n        timeIndex = 0\n        if self.numStages is None:\n            timeIndex = timeStep\n        else:\n            assert timeStage is not None, (\n                \"Time stage index must be specified for %s integrator type\"\n                % self.getOption(\"timeIntegrator\").upper()\n            )\n            timeIndex = timeStep * self.numStages + timeStage\n\n        self._addPressureToElements(\n            self.auxElems[timeIndex], elemIDs, pressures, faceIndex, nastranOrdering\n        )",
  "def addInertialLoad(self, timeStep, inertiaVector, timeStage=None):\n        \"\"\"\n        This method is used to add a fixed inertial load at a specified time step\n        due to a uniform acceleration over the entire model.\n        This is most commonly used to model gravity loads on a model.\n\n        Parameters\n        ----------\n\n        timeStep : int\n            Time step index to apply load to.\n\n        inertiaVector : numpy.ndarray\n            Acceleration vector used to define inertial load.\n\n        timeStage : int or None\n            Time stage index to apply load to. Default is None, which is applicable only for\n            multi-step methods like BDF. For multi-stage methods like DIRK, this index must\n            be specified.\n        \"\"\"\n        timeIndex = 0\n        if self.numStages is None:\n            timeIndex = timeStep\n        else:\n            assert timeStage is not None, (\n                \"Time stage index must be specified for %s integrator type\"\n                % self.getOption(\"timeIntegrator\").upper()\n            )\n            timeIndex = timeStep * self.numStages + timeStage\n\n        self._addInertialLoad(self.auxElems[timeIndex], inertiaVector)",
  "def addCentrifugalLoad(self, timeStep, omegaVector, rotCenter, timeStage=None):\n        \"\"\"\n        This method is used to add a fixed centrifugal load at at specified time step\n        due to a uniform rotational velocity over the entire model.\n        This is most commonly used to model rotors, rolling aircraft, etc.\n\n        Parameters\n        ----------\n\n        timeStep : int\n            Time step index to apply load to.\n\n        omegaVector : numpy.ndarray\n            Rotational velocity vector (rad/s) used to define centrifugal load.\n\n        rotCenter : numpy.ndarray\n            Location of center of rotation used to define centrifugal load.\n\n        timeStage : int or None\n            Time stage index to apply load to. Default is None, which is applicable only for\n            multi-step methods like BDF. For multi-stage methods like DIRK, this index must\n            be specified.\n        \"\"\"\n        timeIndex = 0\n        if self.numStages is None:\n            timeIndex = timeStep\n        else:\n            assert timeStage is not None, (\n                \"Time stage index must be specified for %s integrator type\"\n                % self.getOption(\"timeIntegrator\").upper()\n            )\n            timeIndex = timeStep * self.numStages + timeStage\n\n        self._addCentrifugalLoad(self.auxElems[timeIndex], omegaVector, rotCenter)",
  "def addLoadFromBDF(self, timeStep, loadID, timeStage=None, scale=1.0):\n        \"\"\"\n        This method is used to add a fixed load set defined in the BDF file to the problem\n        at a specified time instance. Currently, only supports LOAD, FORCE, MOMENT, GRAV,\n        RFORCE, PLOAD2, and PLOAD4.\n\n        Parameters\n        ----------\n\n        timeStep : int\n            Time step index to apply load to.\n\n        loadID : int\n            Load identification number of load set in BDF file user wishes to add to problem.\n\n        timeStage : int or None\n            Time stage index to apply load to. Default is None, which is applicable only for\n            multi-step methods like BDF. For multi-stage methods like DIRK, this index must\n            be specified.\n\n        scale : float\n            Factor to scale the BDF loads by before adding to problem.\n        \"\"\"\n        timeIndex = 0\n        if self.numStages is None:\n            timeIndex = timeStep\n        else:\n            assert timeStage is not None, (\n                \"Time stage index must be specified for %s integrator type\"\n                % self.getOption(\"timeIntegrator\").upper()\n            )\n            timeIndex = timeStep * self.numStages + timeStage\n\n        self._addLoadFromBDF(self.F[timeIndex], self.auxElems[timeIndex], loadID, scale)",
  "def setInitConditions(self, vars=None, dvars=None, ddvars=None):\n        \"\"\"\n        Set the initial conditions associated with this problem\n\n        Parameters\n        ----------\n        vars : float or numpy.ndarray or tacs.TACS.Vec\n            Initial conditions of the state variables\n        dvars : float or numpy.ndarray or tacs.TACS.Vec\n            Initial conditions of the first time-derivative of the state variables\n        ddvars : float or numpy.ndarray or tacs.TACS.Vec\n            Initial conditions of the second time-derivative of the state variables\n        \"\"\"\n\n        if vars is not None:\n            if isinstance(vars, np.ndarray):\n                vars0Array = self.vars0.getArray()\n                vars0Array[:] = vars[:]\n            elif isinstance(vars, tacs.TACS.Vec):\n                self.vars0.copyValues(vars)\n            else:  # assume type=float\n                vars0Array = self.vars0.getArray()\n                vars0Array[:] = vars\n\n        if dvars is not None:\n            if isinstance(dvars, np.ndarray):\n                dvars0Array = self.dvars0.getArray()\n                dvars0Array[:] = dvars[:]\n            elif isinstance(dvars, tacs.TACS.Vec):\n                self.dvars0.copyValues(dvars)\n            else:  # assume type=float\n                dvars0Array = self.dvars0.getArray()\n                dvars0Array[:] = dvars\n\n        if ddvars is not None:\n            if isinstance(ddvars, np.ndarray):\n                ddvars0Array = self.ddvars0.getArray()\n                ddvars0Array[:] = ddvars[:]\n            elif isinstance(ddvars, tacs.TACS.Vec):\n                self.ddvars0.copyValues(ddvars)\n            else:  # assume type=float\n                ddvars0Array = self.ddvars0.getArray()\n                ddvars0Array[:] = ddvars",
  "def _updateAssemblerVars(self):\n        \"\"\"\n        Make sure that the assembler is using\n        the input variables associated with this problem\n        \"\"\"\n\n        self.assembler.setDesignVars(self.x)\n        self.assembler.setNodes(self.Xpts)\n        self.assembler.setInitConditions(\n            vec=self.vars0, dvec=self.dvars0, ddvec=self.ddvars0\n        )\n        # Set artificial stiffness factors in rbe class\n        c1 = self.getOption(\"RBEStiffnessScaleFactor\")\n        c2 = self.getOption(\"RBEArtificialStiffness\")\n        tacs.elements.RBE2.setScalingParameters(c1, c2)\n        tacs.elements.RBE3.setScalingParameters(c1, c2)",
  "def solve(self):\n        \"\"\"\n        Solve the time integrated transient problem. The\n        forces must already be set.\n        \"\"\"\n        startTime = time.time()\n\n        self.callCounter += 1\n\n        setupProblemTime = time.time()\n\n        # Set problem vars to assembler\n        self._updateAssemblerVars()\n\n        initSolveTime = time.time()\n\n        # Loop over every time instance and solve transient problem\n        if self.numStages is None:\n            for i in range(self.numSteps + 1):\n                # Set the auxiliary elements for this time step (tractions/pressures)\n                self.assembler.setAuxElements(self.auxElems[i])\n                self.integrator.iterate(i, forces=self.F[i])\n        else:\n            for i in range(self.numSteps + 1):\n                for j in range(self.numStages):\n                    # Set the auxiliary elements for this time step (tractions/pressures)\n                    timeIndex = i * self.numStages + j\n                    self.assembler.setAuxElements(self.auxElems[timeIndex])\n                    self.integrator.iterateStage(i, j, forces=self.F[timeIndex])\n\n        solveTime = time.time()\n\n        # If timing was was requested print it, if the solution is nonlinear\n        # print this information automatically if printTiming was requested.\n        if self.getOption(\"printTiming\"):\n            self._pp(\"+--------------------------------------------------+\")\n            self._pp(\"|\")\n            self._pp(\"| TACS Solve Times:\")\n            self._pp(\"|\")\n            self._pp(\n                \"| %-30s: %10.3f sec\"\n                % (\"TACS Setup Time\", setupProblemTime - startTime)\n            )\n            self._pp(\n                \"| %-30s: %10.3f sec\"\n                % (\"TACS Solve Init Time\", initSolveTime - setupProblemTime)\n            )\n            self._pp(\n                \"| %-30s: %10.3f sec\" % (\"TACS Solve Time\", solveTime - initSolveTime)\n            )\n            self._pp(\"|\")\n            self._pp(\n                \"| %-30s: %10.3f sec\"\n                % (\"TACS Total Solution Time\", solveTime - startTime)\n            )\n            self._pp(\"+--------------------------------------------------+\")\n\n        return",
  "def prepIterativeSolve(self):\n        \"\"\"\n        Prepare to solve the time integrated transient problem.\n        \"\"\"\n        self.callCounter += 1\n\n        # set problem vars to assembler\n        self._updateAssemblerVars()\n\n        return",
  "def iterate(self, timeStep, timeStage=None, Fext=None):\n        \"\"\"\n        Iterate a single time instance in the time integrated transient problem.\n        Useful for iterating an aeroelastic problem that is tightly coupled,\n        where intermediate structural states need to be passed to an external\n        fluid solver.\n\n        Requires the user to use an outer for-loop over the number of time\n        steps/stages of the problem.\n\n        Parameters\n        ----------\n        timeStep : int\n            Time step index to iterate\n\n        timeStage : int or None\n            Time stage index to iterate. If not None, solver must be multistage\n\n        Fext : tacs.TACS.Vec or numpy.ndarray or None\n            If Fext is not None, add this force vector to the loads applied at\n            this time instance. Fext must be sized such that the flattened array\n            is (numOwnedNodes*numVarsPerNode) in length. Useful for applying\n            aerodynamic loads which change at every time instance in a tighly\n            coupled aeroelastic solution.\n\n        Examples\n        --------\n        >>> transientProblem.prepIterativeSolve()\n        >>> for step in range(transientProblem.numSteps + 1):\n        >>>     for stage in range(transientProblem.numStages):\n        >>>         # assume load array comes from an external CFD solver...\n        >>>         Fext = externalCFDSolver.solve(step, stage)\n        >>>         # iterate the transient problem in TACS\n        >>>         transientProblem.iterate(timeStep=step, timeStage=stage, Fext=Fext)\n        >>>         # get the necessary structural states for coupling\n        >>>         time, states, dstates, ddstates = transientProblem.getVariables(timeStep=step, timeStage=stage)\n        \"\"\"\n        # evaluate the time index\n        if timeStage is None:\n            timeIndex = timeStep\n        else:\n            # check that the integrator is multistage\n            assert (\n                self.numStages is not None\n            ), f\"current integrator type {self.getOption('timeIntegrator').upper()} is not multistage, choose a multistage integrator from {['DIRK','ESDIRK']}\"\n            timeIndex = timeStep * self.numStages + timeStage\n\n        # set the loads - do not change self.F[timeIndex] in place\n        FVec = self.assembler.createVec()\n        FVec.copyValues(self.F[timeIndex])\n        if Fext is not None:\n            if isinstance(Fext, tacs.TACS.Vec):\n                FVec.axpy(1.0, Fext)\n            elif isinstance(Fext, np.ndarray):\n                if Fext.ndim > 1:\n                    Fext = Fext.ravel()\n                FextVec = self.assembler.createVec()\n                Fext_array = FextVec.getArray()\n                Fext_array[:] = Fext\n                FVec.axpy(1.0, FextVec)\n\n        # set the auxiliary elements for this time step (tractions/pressures)\n        self.assembler.setAuxElements(self.auxElems[timeIndex])\n\n        # iterate this time instance\n        if timeStage is None:\n            self.integrator.iterate(timeIndex, forces=FVec)\n        else:\n            self.integrator.iterateStage(timeStep, timeStage, forces=FVec)\n\n        return",
  "def addFunction(self, funcName, funcHandle, compIDs=None, **kwargs):\n        \"\"\"\n        Generic method to add a function for TACS. It is intended to\n        be reasonably generic since the user supplies the actual\n        function handle to use. See the :py:mod:`~tacs.functions` module\n        for supported TACS eval functions.\n\n        Parameters\n        ----------\n        funcName : str\n            The user-supplied name for the function. This will\n            typically be a string that is meaningful to the user\n\n        funcHandle : tacs.TACS.Function\n            The function handle to use for creation. This must come\n            from the functions module in tacs.\n\n        compIDs: list\n            List of compIDs to select.\n\n        **kwargs:\n            Any keyword arguments to be passed to the TACS function during setup.\n        \"\"\"\n\n        # Warn the users if these functions are attempted to be passed.\n        if funcHandle in [tacs.functions.MomentOfInertia, tacs.functions.CenterOfMass]:\n            self._TACSWarning(\n                f\"{funcHandle.__name__} is not supported for {type(self).__name__} problem types\"\n                f\" and may not give consistent results.\"\n            )\n\n        return TACSProblem.addFunction(self, funcName, funcHandle, compIDs, **kwargs)",
  "def evalFunctions(self, funcs, evalFuncs=None, ignoreMissing=False):\n        \"\"\"\n        This is the main routine for returning useful information from\n        pytacs. The functions corresponding to the strings in\n        evalFuncs are evaluated and updated into the provided\n        dictionary.\n\n        Parameters\n        ----------\n        funcs : dict\n            Dictionary into which the functions are saved.\n        evalFuncs : iterable object containing strings.\n            If not none, use these functions to evaluate.\n        ignoreMissing : bool\n            Flag to supress checking for a valid function. Please use\n            this option with caution.\n\n        Examples\n        --------\n        >>> funcs = {}\n        >>> transientProblem.solve()\n        >>> transientProblem.evalFunctions(funcs, ['mass'])\n        >>> funcs\n        >>> # Result will look like (if TransientProblem has name of 'c1'):\n        >>> # {'cl_mass':12354.10}\n        \"\"\"\n        startTime = time.time()\n\n        # Set problem vars to assembler\n        self._updateAssemblerVars()\n\n        if evalFuncs is None:\n            evalFuncs = sorted(list(self.functionList))\n        else:\n            evalFuncs = sorted(list(evalFuncs))\n\n        if not ignoreMissing:\n            for f in evalFuncs:\n                if f not in self.functionList:\n                    raise self._TACSError(\n                        f\"Supplied function '{f}' has not been added \"\n                        \"using addFunction().\"\n                    )\n\n        setupProblemTime = time.time()\n\n        # Fast parallel function evaluation of structural funcs:\n        handles = [self.functionList[f] for f in evalFuncs if f in self.functionList]\n        # Set functions for integrator\n        self.integrator.setFunctions(handles)\n        # Evaluate functions\n        funcVals = self.integrator.evalFunctions(handles)\n\n        functionEvalTime = time.time()\n\n        # Assign function values to appropriate dictionary\n        i = 0\n        for f in evalFuncs:\n            if f in self.functionList:\n                key = self.name + \"_%s\" % f\n                funcs[key] = funcVals[i]\n                i += 1\n\n        dictAssignTime = time.time()\n\n        if self.getOption(\"printTiming\"):\n            self._pp(\"+--------------------------------------------------+\")\n            self._pp(\"|\")\n            self._pp(\"| TACS Function Times:\")\n            self._pp(\"|\")\n            self._pp(\n                \"| %-30s: %10.3f sec\"\n                % (\"TACS Function Setup Time\", setupProblemTime - startTime)\n            )\n            self._pp(\n                \"| %-30s: %10.3f sec\"\n                % (\"TACS Function Eval Time\", functionEvalTime - setupProblemTime)\n            )\n            self._pp(\n                \"| %-30s: %10.3f sec\"\n                % (\"TACS Dict Time\", dictAssignTime - functionEvalTime)\n            )\n            self._pp(\"|\")\n            self._pp(\n                \"| %-30s: %10.3f sec\"\n                % (\"TACS Function Time\", dictAssignTime - startTime)\n            )\n            self._pp(\"+--------------------------------------------------+\")",
  "def evalFunctionsSens(self, funcsSens, evalFuncs=None):\n        \"\"\"\n        This is the main routine for returning useful (sensitivity)\n        information from problem. The derivatives of the functions\n        corresponding to the strings in evalFuncs are evaluated and\n        updated into the provided dictionary. The derivitives with\n        respect to all design variables and node locations are computed.\n\n        Parameters\n        ----------\n        funcsSens : dict\n            Dictionary into which the derivatives are saved.\n        evalFuncs : iterable object containing strings\n            The functions the user wants returned\n\n        Examples\n        --------\n        >>> funcsSens = {}\n        >>> transientProblem.evalFunctionsSens(funcsSens, ['mass'])\n        >>> funcsSens\n        >>> # Result will look like (if TransientProblem has name of 'c1'):\n        >>> # {'c1_mass':{'struct':[1.234, ..., 7.89], 'Xpts':[3.14, ..., 1.59]}}\n        \"\"\"\n\n        startTime = time.time()\n\n        # Set problem vars to assembler\n        self._updateAssemblerVars()\n\n        if evalFuncs is None:\n            evalFuncs = sorted(list(self.functionList))\n        else:\n            evalFuncs = sorted(list(evalFuncs))\n\n        for f in evalFuncs:\n            if f not in self.functionList:\n                raise self._TACSError(\n                    \"Supplied function has not been added \" \"using addFunction()\"\n                )\n\n        # Fast parallel function evaluation of structural funcs:\n        handles = [self.functionList[f] for f in evalFuncs if f in self.functionList]\n        # Set functions for integrator\n        self.integrator.setFunctions(handles)\n\n        # integrate adjoints backwards in time from step = numSteps\n        # to step = 0\n        for i in range(self.numSteps, -1, -1):\n            self.assembler.setAuxElements(self.auxElems[i])\n            self.integrator.initAdjoint(i)\n            self.integrator.iterateAdjoint(i)\n            self.integrator.postAdjoint(i)\n\n        adjointFinishedTime = time.time()\n\n        # Recast sensitivities into dict for user\n        for i, f in enumerate(evalFuncs):\n            key = self.name + \"_%s\" % f\n            # Finalize sensitivity arrays across all procs\n            dvSens = self.integrator.getGradient(i)\n            dvSens.beginSetValues()\n            dvSens.endSetValues()\n            xptSens = self.integrator.getXptGradient(i)\n            xptSens.beginSetValues()\n            xptSens.endSetValues()\n            # Return sensitivities as array in sens dict\n            funcsSens[key] = {\n                self.varName: dvSens.getArray().copy(),\n                self.coordName: xptSens.getArray().copy(),\n            }\n\n        totalSensitivityTime = time.time()\n\n        if self.getOption(\"printTiming\"):\n            self._pp(\"+--------------------------------------------------+\")\n            self._pp(\"|\")\n            self._pp(\"| TACS Adjoint Times:\")\n            print(\"|\")\n            print(\n                \"| %-30s: %10.3f sec\"\n                % (\"Adjoint solve time\", adjointFinishedTime - startTime)\n            )\n            print(\"|\")\n            print(\n                \"| %-30s: %10.3f sec\"\n                % (\"Complete Sensitivity Time\", totalSensitivityTime - startTime)\n            )\n            print(\"+--------------------------------------------------+\")",
  "def getVariables(\n        self, timeStep, timeStage=None, states=None, dstates=None, ddstates=None\n    ):\n        \"\"\"\n        Return the current state values for the current problem\n\n        Parameters\n        ----------\n        timeStep : int\n            Time step index to get state variables for.\n\n        timeStage : int or None\n            Time stage index to get state variables for.\n\n        states : tacs.TACS.Vec or numpy.ndarray or None\n            If states is not None, place the state variables into this array (optional).\n\n        dstates : tacs.TACS.Vec or numpy.ndarray or None\n            If dstates is not None, place the time derivative of the state variables into this array (optional).\n\n        ddstates : tacs.TACS.Vec or numpy.ndarray or None\n            If ddstates is not None, place the second time derivative of the state variables into this array (optional).\n\n        Returns\n        --------\n        time: float\n            The time at specified time instance\n\n        states : tacs.TACS.Vec or numpy.ndarray\n            The state variables.\n\n        dstates : tacs.TACS.Vec or numpy.ndarray or None\n            The time derivative of the state variables.\n\n        ddstates : tacs.TACS.Vec or numpy.ndarray or None\n            The second time derivative of the state variables.\n\n        \"\"\"\n\n        # Get BVecs for time instance\n        if timeStage is None:\n            time, q, qdot, qddot = self.integrator.getStates(timeStep)\n        else:\n            # check that the integrator is multistage\n            assert (\n                self.numStages is not None\n            ), f\"current integrator type {self.getOption('timeIntegrator').upper()} is not multistage, choose a multistage integrator from {['DIRK','ESDIRK']}\"\n            time, q, qdot, qddot = self.integrator.getStageStates(timeStep, timeStage)\n\n        # Convert to arrays\n        qArray = q.getArray()\n        qdotArray = qdot.getArray()\n        qddotArray = qddot.getArray()\n\n        # Inplace assignment if vectors were provided\n        if isinstance(states, tacs.TACS.Vec):\n            states.copyValues(q)\n        elif isinstance(states, np.ndarray):\n            states[:] = qArray\n\n        if isinstance(dstates, tacs.TACS.Vec):\n            dstates.copyValues(qdot)\n        elif isinstance(dstates, np.ndarray):\n            dstates[:] = qdotArray\n\n        if isinstance(ddstates, tacs.TACS.Vec):\n            ddstates.copyValues(qddot)\n        elif isinstance(ddstates, np.ndarray):\n            ddstates[:] = qddotArray\n\n        # Return arrays\n        return time, qArray, qdotArray, qddotArray",
  "def zeroLoads(self):\n        \"\"\"\n        Zero all applied loads\n        \"\"\"\n        for Fvec in self.F:\n            Fvec.zeroEntries()\n        for i in range(len(self.auxElems)):\n            self.auxElems[i] = tacs.TACS.AuxElements()",
  "def writeSolution(self, outputDir=None, baseName=None, number=None, timeSteps=None):\n        \"\"\"\n        This is a generic shell function that writes the output\n        file(s).  The intent is that the user or calling program can\n        call this function and pyTACS writes all the files that the\n        user has defined. It is recommended that this function is used\n        along with the associated logical flags in the options to\n        determine the desired writing procedure\n\n        Parameters\n        ----------\n        outputDir : str or None\n            Use the supplied output directory\n        baseName : str or None\n            Use this supplied string for the base filename. Typically\n            only used from an external solver.\n        number : int or None\n            Use the user supplied number to index solution. Again, only\n            typically used from an external solver\n        timeSteps : int or list[int] or None\n            Time step index or indices to get state variables for.\n            If None, returns a solution for all time steps.\n            Defaults to None.\n        \"\"\"\n        # Make sure assembler variables are up-to-date\n        self._updateAssemblerVars()\n\n        # Check input\n        if outputDir is None:\n            outputDir = self.getOption(\"outputDir\")\n\n        if baseName is None:\n            baseName = self.name\n\n        # If we are numbering solution, it saving the sequence of\n        # calls, add the call number\n        if number is not None:\n            # We need number based on the provided number:\n            baseName = baseName + \"_%3.3d\" % number\n        else:\n            # if number is none, i.e. standalone, but we need to\n            # number solutions, use internal counter\n            if self.getOption(\"numberSolutions\"):\n                baseName = baseName + \"_%3.3d\" % self.callCounter\n\n        # Unless the writeSolution option is off write actual file:\n        if self.getOption(\"writeSolution\"):\n            # If timeSteps is None, output all timesteps\n            if timeSteps is None:\n                timeSteps = np.arange(self.numSteps + 1)\n\n            # Write out each specified timestep\n            timeSteps = np.atleast_1d(timeSteps)\n            vec = self.assembler.createVec()\n            dvec = self.assembler.createVec()\n            ddvec = self.assembler.createVec()\n            for timeStep in timeSteps:\n                # Extract solution for timestep\n                self.getVariables(timeStep, states=vec, dstates=dvec, ddstates=ddvec)\n                # Set timestep solution in assembler\n                self.assembler.setVariables(vec, dvec, ddvec)\n                # Write out timestep as f5 file\n                stepName = baseName + \"_%3.3d\" % timeStep\n                fileName = os.path.join(outputDir, stepName) + \".f5\"\n                self.outputViewer.writeToFile(fileName)",
  "class StaticProblem(TACSProblem):\n    # Default options for class\n    defaultOptions = {\n        \"outputDir\": [str, \"./\", \"Output directory for F5 file writer.\"],\n        # Solution Options\n        \"KSMSolver\": [\n            str,\n            \"GMRES\",\n            \"Krylov subspace method to use for linear solver. Currently only supports 'GMRES'\",\n        ],\n        \"orderingType\": [\n            int,\n            tacs.TACS.ND_ORDER,\n            \"Ordering type to use for matrix partitioning.\\n\"\n            \"\\t Acceptable values are:\\n\"\n            f\"\\t\\t tacs.TACS.NATURAL_ORDER = {tacs.TACS.NATURAL_ORDER}\\n\"\n            f\"\\t\\t tacs.TACS.RCM_ORDER = {tacs.TACS.RCM_ORDER}\\n\"\n            f\"\\t\\t tacs.TACS.ND_ORDER = {tacs.TACS.ND_ORDER}\\n\"\n            f\"\\t\\t tacs.TACS.TACS_AMD_ORDER = {tacs.TACS.TACS_AMD_ORDER}\\n\"\n            f\"\\t\\t tacs.TACS.MULTICOLOR_ORDER = {tacs.TACS.MULTICOLOR_ORDER}\",\n        ],\n        \"PCFillLevel\": [int, 1000, \"Preconditioner fill level.\"],\n        \"PCFillRatio\": [float, 20.0, \"Preconditioner fill ratio.\"],\n        \"subSpaceSize\": [int, 10, \"Subspace size for Krylov solver.\"],\n        \"nRestarts\": [int, 15, \"Max number of restarts for Krylov solver.\"],\n        \"flexible\": [\n            bool,\n            True,\n            \"Flag for whether the preconditioner is flexible.\",\n        ],\n        \"L2Convergence\": [\n            float,\n            1e-12,\n            \"Absolute convergence tolerance for linear solver based on l2 norm of residual.\",\n        ],\n        \"L2ConvergenceRel\": [\n            float,\n            1e-12,\n            \"Relative convergence tolerance for linear solver based on l2 norm of residual.\",\n        ],\n        \"RBEStiffnessScaleFactor\": [\n            float,\n            1e3,\n            \"Constraint matrix scaling factor used in RBE Lagrange multiplier stiffness matrix.\",\n        ],\n        \"RBEArtificialStiffness\": [\n            float,\n            1e-3,\n            \"Artificial constant added to diagonals of RBE Lagrange multiplier stiffness matrix \\n\"\n            \"\\t to stabilize preconditioner.\",\n        ],\n        \"useMonitor\": [\n            bool,\n            False,\n            \"Flag for whether to attach a debug monitor to the linear solver.\",\n        ],\n        \"monitorFrequency\": [\n            int,\n            10,\n            \"Print frequency for sub iterations of linear solver.\",\n        ],\n        # Output Options\n        \"writeSolution\": [\n            bool,\n            True,\n            \"Flag for suppressing all f5 file writing.\",\n        ],\n        \"numberSolutions\": [\n            bool,\n            True,\n            \"Flag for attaching solution counter index to f5 files.\",\n        ],\n        \"printTiming\": [\n            bool,\n            False,\n            \"Flag for printing out timing information for class procedures.\",\n        ],\n    }\n\n    def __init__(\n        self,\n        name,\n        assembler,\n        comm,\n        outputViewer=None,\n        meshLoader=None,\n        options=None,\n    ):\n        \"\"\"\n        NOTE: This class should not be initialized directly by the user.\n        Use pyTACS.createStaticProblem instead.\n\n        Parameters\n        ----------\n        name : str\n            Name of this tacs problem\n\n        assembler : tacs.TACS.Assembler\n            Cython object responsible for creating and setting tacs objects used to solve problem\n\n        comm : mpi4py.MPI.Intracomm\n            The comm object on which to create the pyTACS object.\n\n        outputViewer : tacs.TACS.TACSToFH5\n            Cython object used to write out f5 files that can be converted and used for postprocessing.\n\n        meshLoader : tacs.pymeshloader.pyMeshLoader\n            pyMeshLoader object used to create the assembler.\n\n        options : dict\n            Dictionary holding problem-specific option parameters (case-insensitive).\n\n        \"\"\"\n\n        # Problem name\n        self.name = name\n\n        # Set linear solver to None, until we set it up later\n        self.KSM = None\n\n        # Default setup for common problem class objects, sets up comm and options\n        TACSProblem.__init__(self, assembler, comm, options, outputViewer, meshLoader)\n\n        # Create problem-specific variables\n        self._createVariables()\n\n    def _createVariables(self):\n        \"\"\"Internal to create the variable required by TACS\"\"\"\n\n        # Generic residual vector\n        self.res = self.assembler.createVec()\n        self.rhs = self.assembler.createVec()\n\n        # Dictionaries to hold adjoint/sens vectors for each evalFunc\n        self.adjointList = OrderedDict()\n        self.dIduList = OrderedDict()\n        self.dvSensList = OrderedDict()\n        self.xptSensList = OrderedDict()\n        # Temporary vector for adjoint solve\n        self.phi = self.assembler.createVec()\n        self.adjRHS = self.assembler.createVec()\n\n        # Load vector\n        self.F = self.assembler.createVec()\n        self.F_array = self.F.getArray()\n        # State variable vector\n        self.u = self.assembler.createVec()\n        self.u_array = self.u.getArray()\n        # Auxiliary element object for applying tractions/pressure\n        self.auxElems = tacs.TACS.AuxElements()\n        # Counter for number of calls to `solve` method\n        self.callCounter = -1\n\n        # Norms\n        self.initNorm = 0.0\n        self.startNorm = 0.0\n        self.finalNorm = 0.0\n\n        # Load scaling factor\n        self._loadScale = 1.0\n\n        opt = self.getOption\n\n        # Tangent Stiffness --- process the ordering option here:\n        ordering = opt(\"orderingType\")\n\n        # True stiffness matrix\n        self.K = self.assembler.createSchurMat(ordering)\n        # Artificial stiffness for RBE numerical stabilization to stabilize PC\n        self.rbeArtificialStiffness = self.assembler.createSchurMat(ordering)\n\n        # Additional Vecs for updates\n        self.update = self.assembler.createVec()\n\n        # Setup PCScMat and KSM solver\n        self.alpha = 1.0\n        self.beta = 0.0\n        self.gamma = 0.0\n\n        # Computes stiffness matrix w/o art. terms\n        # Set artificial stiffness factors in rbe class to zero\n        tacs.elements.RBE2.setScalingParameters(opt(\"RBEStiffnessScaleFactor\"), 0.0)\n        tacs.elements.RBE3.setScalingParameters(opt(\"RBEStiffnessScaleFactor\"), 0.0)\n        self.assembler.assembleJacobian(\n            self.alpha,\n            self.beta,\n            self.gamma,\n            self.res,\n            self.K,\n            loadScale=self.loadScale,\n        )\n\n        # Now isolate art. terms\n        # Recompute stiffness with artificial terms included\n        tacs.elements.RBE2.setScalingParameters(\n            opt(\"RBEStiffnessScaleFactor\"), opt(\"RBEArtificialStiffness\")\n        )\n        tacs.elements.RBE3.setScalingParameters(\n            opt(\"RBEStiffnessScaleFactor\"), opt(\"RBEArtificialStiffness\")\n        )\n        self.assembler.assembleJacobian(\n            self.alpha, self.beta, self.gamma, None, self.rbeArtificialStiffness\n        )\n        # Subtract full stiffness w/o artificial terms from full stiffness w/ terms\n        # to isolate  artificial stiffness terms\n        self.rbeArtificialStiffness.axpy(-1.0, self.K)\n\n        reorderSchur = 1\n        self.PC = tacs.TACS.Pc(\n            self.K,\n            lev_fill=opt(\"PCFillLevel\"),\n            ratio_fill=opt(\"PCFillRatio\"),\n            reorder=reorderSchur,\n        )\n\n        # Operator, fill level, fill ratio, msub, rtol, ataol\n        if opt(\"KSMSolver\").upper() == \"GMRES\":\n            self.KSM = tacs.TACS.KSM(\n                self.K,\n                self.PC,\n                opt(\"subSpaceSize\"),\n                opt(\"nRestarts\"),\n                opt(\"flexible\"),\n            )\n        # TODO: Fix this\n        # elif opt('KSMSolver').upper() == 'GCROT':\n        #    self.KSM = tacs.TACS.GCROT(\n        #        self.K, self.PC, opt('subSpaceSize'), opt('subSpaceSize'),\n        #        opt('nRestarts'), opt('flexible'))\n        else:\n            raise self._TACSError(\n                \"Unknown KSMSolver option. Valid options are \" \"'GMRES' or 'GCROT'\"\n            )\n\n        self.KSM.setTolerances(\n            self.getOption(\"L2ConvergenceRel\"), self.getOption(\"L2Convergence\")\n        )\n\n        if opt(\"useMonitor\"):\n            self.KSM.setMonitor(\n                self.comm,\n                _descript=opt(\"KSMSolver\").upper(),\n                freq=opt(\"monitorFrequency\"),\n            )\n\n        # Linear solver factor flag\n        self._factorOnNext = True\n\n    def setOption(self, name, value):\n        \"\"\"\n        Set a solver option value. The name is not case sensitive.\n\n        Parameters\n        ----------\n        name : str\n            Name of option to modify\n\n        value : depends on option\n            New option value to set\n        \"\"\"\n        # Default setOption for common problem class objects\n        TACSProblem.setOption(self, name, value)\n\n        if self.KSM is not None:\n            # Update tolerances\n            if \"l2convergence\" in name.lower():\n                self.KSM.setTolerances(\n                    self.getOption(\"L2ConvergenceRel\"),\n                    self.getOption(\"L2Convergence\"),\n                )\n            # No need to reset solver for output options\n            elif name.lower() in [\n                \"writesolution\",\n                \"printtiming\",\n                \"numbersolutions\",\n                \"outputdir\",\n            ]:\n                pass\n            # Reset solver for all other option changes\n            else:\n                self._createVariables()\n\n    @property\n    def loadScale(self):\n        \"\"\"This is a scaling factor applied to all forcing terms\n\n        Forcing terms includes both the user supplied force vector and the forcing terms coming from aux elements in\n        the TACS assembler (e.g inertial, centrifugal forces)\n\n        Returns\n        -------\n        float or complex\n            The current load scale\n        \"\"\"\n        return self._loadScale\n\n    @loadScale.setter\n    def loadScale(self, value):\n        \"\"\"Set the scaling applied to external loads\n\n        This function exists so that calling `problem.loadScale = value` has the same effect as calling::\n\n            `problem.setLoadScale(value)`\n\n        This is important in case we want to update other things when the load scale is changed in future\n\n        Parameters\n        ----------\n        value : float or complex\n            Value to set the load scale to\n        \"\"\"\n        self.setLoadScale(value)\n\n    def setLoadScale(self, value):\n        \"\"\"Set the scaling applied to external loads\n\n        Parameters\n        ----------\n        value : float or complex\n            Value to set the load scale to\n        \"\"\"\n        if value != self._loadScale:\n            self._factorOnNext = True\n            self._loadScale = value\n\n    def addFunction(self, funcName, funcHandle, compIDs=None, **kwargs):\n        \"\"\"\n        Generic method to add a function for TACS. It is intended to\n        be reasonably generic since the user supplies the actual\n        function handle to use. See the :py:mod:`~tacs.functions` module\n        for supported TACS eval functions.\n\n        Parameters\n        ----------\n        funcName : str\n            The user-supplied name for the function. This will\n            typically be a string that is meaningful to the user\n\n        funcHandle : tacs.TACS.Function\n            The function handle to use for creation. This must come\n            from the functions module in tacs.\n\n        compIDs: list\n            List of compIDs to select.\n\n        **kwargs:\n            Any keyword arguments to be passed to the TACS function during setup.\n        \"\"\"\n        success = TACSProblem.addFunction(self, funcName, funcHandle, compIDs, **kwargs)\n        if success:\n            # Create additional tacs BVecs to hold adjoint and sens info\n            self.adjointList[funcName] = self.assembler.createVec()\n            self.dIduList[funcName] = self.assembler.createVec()\n            self.dvSensList[funcName] = self.assembler.createDesignVec()\n            self.xptSensList[funcName] = self.assembler.createNodeVec()\n        return success\n\n    def setDesignVars(self, x):\n        \"\"\"\n        Update the design variables used by tacs.\n\n        Parameters\n        ----------\n        x : numpy.ndarray or dict or tacs.TACS.Vec\n            The variables (typically from the optimizer) to set. It\n            looks for variable in the ``self.varName`` attribute.\n\n        \"\"\"\n        TACSProblem.setDesignVars(self, x)\n        self._factorOnNext = True\n\n    def setNodes(self, coords):\n        \"\"\"\n        Set the mesh coordinates of the structure.\n\n        Parameters\n        ----------\n        coords : numpy.ndarray\n            Structural coordinate in array of size (N * 3) where N is\n            the number of structural nodes on this processor.\n        \"\"\"\n        TACSProblem.setNodes(self, coords)\n        self._factorOnNext = True\n\n    ####### Load adding methods ########\n\n    def addLoadToComponents(self, compIDs, F, averageLoad=False):\n        \"\"\"\n        This method is used to add a *FIXED TOTAL LOAD* on one or more\n        components, defined by COMPIDs. The purpose of this routine is to add loads that\n        remain fixed throughout an optimization. An example would be an engine load.\n        This routine determines all the unique nodes in the FE model that are part of the\n        requested components, then takes the total 'force' by F and divides by the\n        number of nodes. This average load is then applied to the nodes.\n\n        Parameters\n        ----------\n\n        compIDs : list[int] or int\n            The components with added loads. Use pyTACS selectCompIDs method\n            to determine this.\n\n        F : numpy.ndarray 1d or 2d length (varsPerNodes) or (numCompIDs, varsPerNodes)\n            Vector(s) of 'force' to apply to each component.  If only one force vector is provided,\n            force will be copied uniformly across all components.\n\n        averageLoad : bool\n            Flag to determine whether load should be split evenly across all components (True)\n            or copied and applied individually to each component (False). Defaults to False.\n\n        Notes\n        -----\n\n        The units of the entries of the 'force' vector F are not\n        necessarily physical forces and their interpretation depends\n        on the physics problem being solved and the dofs included\n        in the model.\n\n        A couple of examples of force vector components for common problems are listed below:\n\n            In Heat Conduction with varsPerNode = 1\n                F = [Qdot] # heat rate\n            In Elasticity with varsPerNode = 3,\n                F = [fx, fy, fz] # forces\n            In Elasticity with varsPerNode = 6,\n                F = [fx, fy, fz, mx, my, mz] # forces + moments\n            In Thermoelasticity with varsPerNode = 4,\n                F = [fx, fy, fz, Qdot] # forces + heat rate\n            In Thermoelasticity with varsPerNode = 7,\n                F = [fx, fy, fz, mx, my, mz, Qdot] # forces + moments + heat rate\n        \"\"\"\n        self._addLoadToComponents(self.F, compIDs, F, averageLoad)\n\n    def addLoadToNodes(self, nodeIDs, F, nastranOrdering=False):\n        \"\"\"\n        This method is used to add a fixed point load of F to the\n        selected node IDs.\n\n        Parameters\n        ----------\n\n        nodeIDs : list[int]\n            The nodes IDs with added loads.\n\n        F : Numpy 1d or 2d array length (varsPerNodes) or (numNodeIDs, varsPerNodes)\n            Array of force vectors, one for each node. If only one force vector is provided,\n            force will be copied uniformly across all nodes.\n\n        nastranOrdering : bool\n            Flag signaling whether nodeIDs are in TACS (default)\n            or NASTRAN (grid IDs in bdf file) ordering\n\n        Notes\n        -----\n\n        The units of the entries of the 'force' vector F are not\n        necessarily physical forces and their interpretation depends\n        on the physics problem being solved and the dofs included\n        in the model.\n\n        A couple of examples of force vector components for common problems are listed below:\n\n            In Heat Conduction with varsPerNode = 1\n                F = [Qdot] # heat rate\n            In Elasticity with varsPerNode = 3,\n                F = [fx, fy, fz] # forces\n            In Elasticity with varsPerNode = 6,\n                F = [fx, fy, fz, mx, my, mz] # forces + moments\n            In Thermoelasticity with varsPerNode = 4,\n                F = [fx, fy, fz, Qdot] # forces + heat rate\n            In Thermoelasticity with varsPerNode = 7,\n                F = [fx, fy, fz, mx, my, mz, Qdot] # forces + moments + heat rate\n        \"\"\"\n\n        self._addLoadToNodes(self.F, nodeIDs, F, nastranOrdering)\n\n    def addLoadToRHS(self, Fapplied):\n        \"\"\"\n        This method is used to add a *FIXED TOTAL LOAD* directly to the\n        right hand side vector given the equation below:\n\n            K*u = f\n\n        Where:\n            - K : Stiffness matrix for problem\n            - u : State variables for problem\n            - f : Right-hand side vector to add loads to\n\n        Parameters\n        ----------\n\n        Fapplied : numpy.ndarray or tacs.TACS.Vec\n            Distributed array containing loads to applied to RHS of the problem.\n\n        \"\"\"\n        self._addLoadToRHS(self.F, Fapplied)\n\n    def addTractionToComponents(self, compIDs, tractions, faceIndex=0):\n        \"\"\"\n        This method is used to add a *FIXED TOTAL TRACTION* on one or more\n        components, defined by COMPIDs. The purpose of this routine is\n        to add loads that remain fixed throughout an optimization.\n\n        Parameters\n        ----------\n\n        compIDs : list[int] or int\n            The components with added loads. Use pyTACS selectCompIDs method\n            to determine this.\n\n        tractions : Numpy array length 1 or compIDs\n            Array of traction vectors for each component\n\n        faceIndex : int\n            Indicates which face (side) of element to apply traction to.\n            Note: not required for certain elements (i.e. shells)\n        \"\"\"\n        self._addTractionToComponents(self.auxElems, compIDs, tractions, faceIndex)\n\n    def addTractionToElements(\n        self, elemIDs, tractions, faceIndex=0, nastranOrdering=False\n    ):\n        \"\"\"\n        This method is used to add a fixed traction to the\n        selected element IDs. Tractions can be specified on an\n        element by element basis (if tractions is a 2d array) or\n        set to a uniform value (if tractions is a 1d array)\n\n        Parameters\n        ----------\n\n        elemIDs : list[int]\n            The global element ID numbers for which to apply the traction.\n\n        tractions : Numpy 1d or 2d array length varsPerNodes or (elemIDs, varsPerNodes)\n            Array of traction vectors for each element\n\n        faceIndex : int\n            Indicates which face (side) of element to apply traction to.\n            Note: not required for certain elements (i.e. shells)\n\n        nastranOrdering : bool\n            Flag signaling whether elemIDs are in TACS (default)\n            or NASTRAN ordering\n        \"\"\"\n\n        self._addTractionToElements(\n            self.auxElems, elemIDs, tractions, faceIndex, nastranOrdering\n        )\n\n    def addPressureToComponents(self, compIDs, pressures, faceIndex=0):\n        \"\"\"\n        This method is used to add a *FIXED TOTAL PRESSURE* on one or more\n        components, defined by COMPIds. The purpose of this routine is\n        to add loads that remain fixed throughout an optimization. An example\n        would be a fuel load.\n\n        Parameters\n        ----------\n\n        compIDs : list[int] or int\n            The components with added loads. Use pyTACS selectCompIDs method\n            to determine this.\n\n        pressures : Numpy array length 1 or compIDs\n            Array of pressure values for each component\n\n        faceIndex : int\n            Indicates which face (side) of element to apply pressure to.\n            Note: not required for certain elements (i.e. shells)\n        \"\"\"\n        self._addPressureToComponents(self.auxElems, compIDs, pressures, faceIndex)\n\n    def addPressureToElements(\n        self, elemIDs, pressures, faceIndex=0, nastranOrdering=False\n    ):\n        \"\"\"\n        This method is used to add a fixed presure to the\n        selected element IDs. Pressures can be specified on an\n        element by element basis (if pressures is an array) or\n        set to a uniform value (if pressures is a scalar)\n\n        Parameters\n        ----------\n\n        elemIDs : list[int]\n            The global element ID numbers for which to apply the pressure.\n\n        pressures : Numpy array length 1 or elemIDs\n            Array of pressure values for each element\n\n        faceIndex : int\n            Indicates which face (side) of element to apply pressure to.\n            Note: not required for certain elements (i.e. shells)\n\n        nastranOrdering : bool\n            Flag signaling whether elemIDs are in TACS (default)\n            or NASTRAN ordering\n        \"\"\"\n\n        self._addPressureToElements(\n            self.auxElems, elemIDs, pressures, faceIndex, nastranOrdering\n        )\n\n    def addInertialLoad(self, inertiaVector):\n        \"\"\"\n        This method is used to add a fixed inertial load due to\n        a uniform acceleration over the entire model.\n        This is most commonly used to model gravity loads on a model.\n\n        Parameters\n        ----------\n        inertiaVector : numpy.ndarray\n            Acceleration vector used to define inertial load.\n        \"\"\"\n        self._addInertialLoad(self.auxElems, inertiaVector)\n\n    def addCentrifugalLoad(self, omegaVector, rotCenter, firstOrder=False):\n        \"\"\"\n        This method is used to add a fixed centrifugal load due to a\n        uniform rotational velocity over the entire model.\n        This is most commonly used to model rotors, rolling aircraft, etc.\n\n        Parameters\n        ----------\n\n        omegaVector : numpy.ndarray\n            Rotational velocity vector (rad/s) used to define centrifugal load.\n\n        rotCenter : numpy.ndarray\n            Location of center of rotation used to define centrifugal load.\n\n        firstOrder : bool, optional\n            Whether to use first order approximation for centrifugal load,\n            which computes the force in the displaced position. By default False\n        \"\"\"\n        self._addCentrifugalLoad(self.auxElems, omegaVector, rotCenter, firstOrder)\n\n    def addLoadFromBDF(self, loadID, scale=1.0):\n        \"\"\"\n        This method is used to add a fixed load set defined in the BDF file to the problem.\n        Currently, only supports LOAD, FORCE, MOMENT, GRAV, RFORCE, PLOAD2, and PLOAD4.\n\n        Parameters\n        ----------\n\n        loadID : int\n            Load identification number of load set in BDF file user wishes to add to problem.\n\n        scale : float\n            Factor to scale the BDF loads by before adding to problem.\n        \"\"\"\n        self._addLoadFromBDF(self.F, self.auxElems, loadID, scale)\n\n    ####### Static solver methods ########\n\n    def _updateAssemblerVars(self):\n        \"\"\"\n        Make sure that the assembler is using\n        the input variables associated with this problem\n        \"\"\"\n\n        self.assembler.setDesignVars(self.x)\n        self.assembler.setNodes(self.Xpts)\n        self.assembler.setAuxElements(self.auxElems)\n        # Set state variables\n        self.assembler.setVariables(self.u)\n        # Zero any time derivative terms\n        self.assembler.zeroDotVariables()\n        self.assembler.zeroDDotVariables()\n        # Set artificial stiffness factors in rbe class to zero\n        tacs.elements.RBE2.setScalingParameters(\n            self.getOption(\"RBEStiffnessScaleFactor\"), 0.0\n        )\n        tacs.elements.RBE3.setScalingParameters(\n            self.getOption(\"RBEStiffnessScaleFactor\"), 0.0\n        )\n\n    def _initializeSolve(self):\n        \"\"\"\n        Initialize the solution of the structural system for the\n        loadCase. The stiffness matrix is assembled and factored.\n        \"\"\"\n\n        if self._factorOnNext:\n            # Assemble residual and stiffness matrix (w/o artificial terms)\n            self.assembler.assembleJacobian(\n                self.alpha,\n                self.beta,\n                self.gamma,\n                self.res,\n                self.K,\n                loadScale=self._loadScale,\n            )\n            # Stiffness matrix must include artificial terms before pc factor\n            # to prevent factorization issues w/ zero-diagonals\n            self.K.axpy(1.0, self.rbeArtificialStiffness)\n            self.PC.factor()\n            # Remove artificial stiffness terms to get true stiffness mat\n            self.K.axpy(-1.0, self.rbeArtificialStiffness)\n            self._factorOnNext = False\n\n    def solve(self, Fext=None):\n        \"\"\"\n        Solution of the static problem for current load set. The\n        forces must already be set.\n\n        Parameters\n        ----------\n        Optional Arguments:\n\n        Fext : numpy.ndarray or tacs.TACS.Vec\n            Distributed array containing additional loads (ex. aerodynamic forces for aerostructural coupling)\n            to applied to RHS of the static problem.\n\n        \"\"\"\n        startTime = time.time()\n\n        self.callCounter += 1\n\n        setupProblemTime = time.time()\n\n        # Set problem vars to assembler\n        self._updateAssemblerVars()\n\n        # Check if we need to initialize\n        self._initializeSolve()\n\n        initSolveTime = time.time()\n\n        # Get current residual\n        self.getResidual(self.res, Fext=Fext)\n\n        # Get rhs vector\n        self.K.mult(self.u, self.rhs)\n        self.rhs.axpy(-1.0, self.res)\n\n        # Set initnorm as the norm of rhs\n        self.initNorm = np.real(self.rhs.norm())\n\n        # Starting Norm for this computation\n        self.startNorm = np.real(self.res.norm())\n\n        initNormTime = time.time()\n\n        # Solve Linear System for the update\n        success = self.KSM.solve(self.res, self.update)\n\n        if not success:\n            self._TACSWarning(\n                \"Linear solver failed to converge. \"\n                \"This is likely a sign that the problem is ill-conditioned. \"\n                \"Check that the model is properly restrained.\"\n            )\n\n        self.update.scale(-1.0)\n\n        solveTime = time.time()\n\n        # Update State Variables\n        self.assembler.getVariables(self.u)\n        self.u.axpy(1.0, self.update)\n        self.assembler.setVariables(self.u)\n\n        stateUpdateTime = time.time()\n\n        # Get updated residual\n        self.getResidual(self.res, Fext)\n        self.finalNorm = np.real(self.res.norm())\n\n        finalNormTime = time.time()\n\n        # If timing was was requested print it, if the solution is nonlinear\n        # print this information automatically if print iterations was requested.\n        if self.getOption(\"printTiming\"):\n            self._pp(\"+--------------------------------------------------+\")\n            self._pp(\"|\")\n            self._pp(\"| TACS Solve Times:\")\n            self._pp(\"|\")\n            self._pp(\n                \"| %-30s: %10.3f sec\"\n                % (\"TACS Setup Time\", setupProblemTime - startTime)\n            )\n            self._pp(\n                \"| %-30s: %10.3f sec\"\n                % (\"TACS Solve Init Time\", initSolveTime - setupProblemTime)\n            )\n            self._pp(\n                \"| %-30s: %10.3f sec\"\n                % (\"TACS Init Norm Time\", initNormTime - initSolveTime)\n            )\n            self._pp(\n                \"| %-30s: %10.3f sec\" % (\"TACS Solve Time\", solveTime - initNormTime)\n            )\n            self._pp(\n                \"| %-30s: %10.3f sec\"\n                % (\"TACS State Update Time\", stateUpdateTime - solveTime)\n            )\n            self._pp(\n                \"| %-30s: %10.3f sec\"\n                % (\"TACS Final Norm Time\", finalNormTime - stateUpdateTime)\n            )\n            self._pp(\"|\")\n            self._pp(\n                \"| %-30s: %10.3f sec\"\n                % (\"TACS Total Solution Time\", finalNormTime - startTime)\n            )\n            self._pp(\"+--------------------------------------------------+\")\n\n        return\n\n    ####### Function eval/sensitivity methods ########\n\n    def evalFunctions(self, funcs, evalFuncs=None, ignoreMissing=False):\n        \"\"\"\n        This is the main routine for returning useful information from\n        pytacs. The functions corresponding to the strings in\n        evalFuncs are evaluated and updated into the provided\n        dictionary.\n\n        Parameters\n        ----------\n        funcs : dict\n            Dictionary into which the functions are saved.\n        evalFuncs : iterable object containing strings.\n            If not none, use these functions to evaluate.\n        ignoreMissing : bool\n            Flag to supress checking for a valid function. Please use\n            this option with caution.\n\n        Examples\n        --------\n        >>> funcs = {}\n        >>> staticProblem.solve()\n        >>> staticProblem.evalFunctions(funcs, ['mass'])\n        >>> funcs\n        >>> # Result will look like (if StaticProblem has name of 'c1'):\n        >>> # {'cl_mass':12354.10}\n        \"\"\"\n        startTime = time.time()\n\n        # Set problem vars to assembler\n        self._updateAssemblerVars()\n\n        if evalFuncs is None:\n            evalFuncs = sorted(list(self.functionList))\n        else:\n            evalFuncs = sorted(list(evalFuncs))\n\n        if not ignoreMissing:\n            for f in evalFuncs:\n                if f not in self.functionList:\n                    raise self._TACSError(\n                        f\"Supplied function '{f}' has not been added \"\n                        \"using addFunction().\"\n                    )\n\n        setupProblemTime = time.time()\n\n        # Fast parallel function evaluation of structural funcs:\n        handles = [self.functionList[f] for f in evalFuncs if f in self.functionList]\n        funcVals = self.assembler.evalFunctions(handles)\n\n        functionEvalTime = time.time()\n\n        # Assign function values to appropriate dictionary\n        i = 0\n        for f in evalFuncs:\n            if f in self.functionList:\n                key = self.name + \"_%s\" % f\n                funcs[key] = funcVals[i]\n                i += 1\n\n        dictAssignTime = time.time()\n\n        if self.getOption(\"printTiming\"):\n            self._pp(\"+--------------------------------------------------+\")\n            self._pp(\"|\")\n            self._pp(\"| TACS Function Times:\")\n            self._pp(\"|\")\n            self._pp(\n                \"| %-30s: %10.3f sec\"\n                % (\"TACS Function Setup Time\", setupProblemTime - startTime)\n            )\n            self._pp(\n                \"| %-30s: %10.3f sec\"\n                % (\n                    \"TACS Function Eval Time\",\n                    functionEvalTime - setupProblemTime,\n                )\n            )\n            self._pp(\n                \"| %-30s: %10.3f sec\"\n                % (\"TACS Dict Time\", dictAssignTime - functionEvalTime)\n            )\n            self._pp(\"|\")\n            self._pp(\n                \"| %-30s: %10.3f sec\"\n                % (\"TACS Function Time\", dictAssignTime - startTime)\n            )\n            self._pp(\"+--------------------------------------------------+\")\n\n    def evalFunctionsSens(self, funcsSens, evalFuncs=None):\n        \"\"\"\n        This is the main routine for returning useful (sensitivity)\n        information from problem. The derivatives of the functions\n        corresponding to the strings in evalFuncs are evaluated and\n        updated into the provided dictionary. The derivitives with\n        respect to all design variables and node locations are computed.\n\n        Parameters\n        ----------\n        funcsSens : dict\n            Dictionary into which the derivatives are saved.\n        evalFuncs : iterable object containing strings\n            The functions the user wants returned\n\n        Examples\n        --------\n        >>> funcsSens = {}\n        >>> staticProblem.evalFunctionsSens(funcsSens, ['mass'])\n        >>> funcsSens\n        >>> # Result will look like (if StaticProblem has name of 'c1'):\n        >>> # {'c1_mass':{'struct':[1.234, ..., 7.89], 'Xpts':[3.14, ..., 1.59]}}\n        \"\"\"\n\n        startTime = time.time()\n\n        # Set problem vars to assembler\n        self._updateAssemblerVars()\n\n        if evalFuncs is None:\n            evalFuncs = sorted(list(self.functionList))\n        else:\n            evalFuncs = sorted(list(evalFuncs))\n        # Check that the functions are all ok.\n        # and prepare tacs vecs for adjoint procedure\n        dvSenses = []\n        xptSenses = []\n        dIdus = []\n        adjoints = []\n        for f in evalFuncs:\n            if f not in self.functionList:\n                raise self._TACSError(\n                    \"Supplied function has not been added \" \"using addFunction()\"\n                )\n            else:\n                # Populate the lists with the tacs bvecs\n                # we'll need for each adjoint/sens calculation\n                dvSens = self.dvSensList[f]\n                dvSens.zeroEntries()\n                dvSenses.append(dvSens)\n\n                xptSens = self.xptSensList[f]\n                xptSens.zeroEntries()\n                xptSenses.append(xptSens)\n\n                dIdu = self.dIduList[f]\n                dIdu.zeroEntries()\n                dIdus.append(dIdu)\n\n                adjoint = self.adjointList[f]\n                adjoint.zeroEntries()\n                adjoints.append(adjoint)\n\n        setupProblemTime = time.time()\n\n        adjointStartTime = {}\n        adjointEndTime = {}\n\n        # Next we will solve all the adjoints\n        # Set adjoint rhs\n        self.addSVSens(evalFuncs, dIdus)\n        adjointRHSTime = time.time()\n        for i, f in enumerate(evalFuncs):\n            adjointStartTime[f] = time.time()\n            self.solveAdjoint(dIdus[i], adjoints[i])\n            adjointEndTime[f] = time.time()\n\n        adjointFinishedTime = time.time()\n        # Evaluate all the adoint res prooduct at the same time for\n        # efficiency:\n        self.addDVSens(evalFuncs, dvSenses)\n        self.addAdjointResProducts(adjoints, dvSenses)\n        self.addXptSens(evalFuncs, xptSenses)\n        self.addAdjointResXptSensProducts(adjoints, xptSenses)\n\n        # Recast sensititivities into dict for user\n        for i, f in enumerate(evalFuncs):\n            key = self.name + \"_%s\" % f\n            # Return sensitivities as array in sens dict\n            funcsSens[key] = {\n                self.varName: dvSenses[i].getArray().copy(),\n                self.coordName: xptSenses[i].getArray().copy(),\n            }\n\n        totalSensitivityTime = time.time()\n\n        if self.getOption(\"printTiming\"):\n            self._pp(\"+--------------------------------------------------+\")\n            self._pp(\"|\")\n            self._pp(\"| TACS Adjoint Times:\")\n            print(\"|\")\n            print(\n                \"| %-30s: %10.3f sec\"\n                % (\"TACS Sens Setup Problem Time\", setupProblemTime - startTime)\n            )\n            print(\n                \"| %-30s: %10.3f sec\"\n                % (\"TACS Adjoint RHS Time\", adjointRHSTime - setupProblemTime)\n            )\n            for f in evalFuncs:\n                print(\n                    \"| %-30s: %10.3f sec\"\n                    % (\n                        \"TACS Adjoint Solve Time - %s\" % (f),\n                        adjointEndTime[f] - adjointStartTime[f],\n                    )\n                )\n            print(\n                \"| %-30s: %10.3f sec\"\n                % (\n                    \"Total Sensitivity Time\",\n                    totalSensitivityTime - adjointFinishedTime,\n                )\n            )\n            print(\"|\")\n            print(\n                \"| %-30s: %10.3f sec\"\n                % (\n                    \"Complete Sensitivity Time\",\n                    totalSensitivityTime - startTime,\n                )\n            )\n            print(\"+--------------------------------------------------+\")\n\n    def addSVSens(self, evalFuncs, svSensList):\n        \"\"\"\n        Add the state variable partial sensitivity to the ADjoint RHS for given evalFuncs\n\n        Parameters\n        ----------\n        evalFuncs : list[str]\n            The functions the user wants returned\n\n        svSensList : list[tacs.TACS.Vec] or list[numpy.ndarray]\n            List of sensitivity vectors to add partial sensitivity to\n        \"\"\"\n        # Set problem vars to assembler\n        self._updateAssemblerVars()\n\n        # Get list of TACS function handles from evalFuncs\n        funcHandles = [\n            self.functionList[f] for f in evalFuncs if f in self.functionList\n        ]\n\n        # Create a tacs BVec copy for the operation if the output is a numpy array\n        if isinstance(svSensList[0], np.ndarray):\n            svSensBVecList = [\n                self._arrayToVec(svSensArray) for svSensArray in svSensList\n            ]\n        # Otherwise the input is already a BVec and we can do the operation in place\n        else:\n            svSensBVecList = svSensList\n\n        self.assembler.addSVSens(\n            funcHandles, svSensBVecList, self.alpha, self.beta, self.gamma\n        )\n\n        # Update from the BVec values, if the input was a numpy array\n        if isinstance(svSensList[0], np.ndarray):\n            for svSensArray, svSensBVec in zip(svSensList, svSensBVecList):\n                svSensArray[:] = svSensBVec.getArray()\n\n    def addDVSens(self, evalFuncs, dvSensList, scale=1.0):\n        \"\"\"\n        Add partial sensitivity contribution due to design vars for evalFuncs\n\n        Parameters\n        ----------\n        evalFuncs : list[str]\n            The functions the user wants returned\n\n        dvSensList : list[tacs.TACS.Vec] or list[numpy.ndarray]\n            List of sensitivity vectors to add partial sensitivity to\n\n        scale : float\n            Scalar to multiply partial sensitivity by. Defaults to 1.0\n        \"\"\"\n        # Set problem vars to assembler\n        self._updateAssemblerVars()\n\n        # Get list of TACS function handles from evalFuncs\n        funcHandles = [\n            self.functionList[f] for f in evalFuncs if f in self.functionList\n        ]\n\n        # Create a tacs BVec copy for the operation if the output is a numpy array\n        if isinstance(dvSensList[0], np.ndarray):\n            dvSensBVecList = [\n                self._arrayToDesignVec(dvSensArray) for dvSensArray in dvSensList\n            ]\n        # Otherwise the input is already a BVec and we can do the operation in place\n        else:\n            dvSensBVecList = dvSensList\n\n        self.assembler.addDVSens(funcHandles, dvSensBVecList, scale)\n\n        # Finalize sensitivity arrays across all procs\n        for dvSensBVec in dvSensBVecList:\n            dvSensBVec.beginSetValues()\n            dvSensBVec.endSetValues()\n\n        # Update the BVec values, if the input was a numpy array\n        if isinstance(dvSensList[0], np.ndarray):\n            for dvSensArray, dvSensBVec in zip(dvSensList, dvSensBVecList):\n                # Copy values to numpy array\n                dvSensArray[:] = dvSensBVec.getArray()\n\n    def addAdjointResProducts(self, adjointlist, dvSensList, scale=-1.0):\n        \"\"\"\n        Add the adjoint product contribution to the design variable sensitivity arrays\n\n        Parameters\n        ----------\n        adjointlist : list[tacs.TACS.Vec] or list[numpy.ndarray]\n            List of adjoint vectors for residual sensitivity product\n\n        dvSensList : list[tacs.TACS.Vec] or list[numpy.ndarray]\n            List of sensitivity vectors to add product to\n\n        scale : float\n            Scalar to multiply product by. Defaults to -1.0\n        \"\"\"\n        # Set problem vars to assembler\n        self._updateAssemblerVars()\n\n        # Create a tacs BVec copy for the operation if the output is a numpy array\n        if isinstance(adjointlist[0], np.ndarray):\n            adjointBVeclist = [\n                self._arrayToVec(adjointArray) for adjointArray in adjointlist\n            ]\n        # Otherwise the input is already a BVec and we can do the operation in place\n        else:\n            adjointBVeclist = adjointlist\n\n        # Make sure BC terms are zeroed out in adjoint\n        for adjoint in adjointBVeclist:\n            self.assembler.applyBCs(adjoint)\n\n        # Create a tacs BVec copy for the operation if the output is a numpy array\n        if isinstance(dvSensList[0], np.ndarray):\n            dvSensBVecList = [\n                self._arrayToDesignVec(dvSensArray) for dvSensArray in dvSensList\n            ]\n        # Otherwise the input is already a BVec and we can do the operation in place\n        else:\n            dvSensBVecList = dvSensList\n\n        self.assembler.addAdjointResProducts(adjointBVeclist, dvSensBVecList, scale)\n\n        # Finalize sensitivity arrays across all procs\n        for dvSensBVec in dvSensBVecList:\n            dvSensBVec.beginSetValues()\n            dvSensBVec.endSetValues()\n\n        # Update the BVec values, if the input was a numpy array\n        if isinstance(dvSensList[0], np.ndarray):\n            for dvSensArray, dvSensBVec in zip(dvSensList, dvSensBVecList):\n                # Copy values to numpy array\n                dvSensArray[:] = dvSensBVec.getArray()\n\n    def addXptSens(self, evalFuncs, xptSensList, scale=1.0):\n        \"\"\"\n        Add partial sensitivity contribution due to nodal coordinates for evalFuncs\n\n        Parameters\n        ----------\n        evalFuncs : list[str]\n            The functions the user wants returned\n\n        xptSensList : list[tacs.TACS.Vec] or list[numpy.ndarray]\n            List of sensitivity vectors to add partial sensitivity to\n\n        scale : float\n            Scalar to multiply partial sensitivity by. Defaults to 1.0\n        \"\"\"\n        # Set problem vars to assembler\n        self._updateAssemblerVars()\n\n        # Get list of TACS function handles from evalFuncs\n        funcHandles = [\n            self.functionList[f] for f in evalFuncs if f in self.functionList\n        ]\n\n        # Create a tacs BVec copy for the operation if the output is a numpy array\n        if isinstance(xptSensList[0], np.ndarray):\n            xptSensBVecList = [\n                self._arrayToNodeVec(xptSensArray) for xptSensArray in xptSensList\n            ]\n        # Otherwise the input is already a BVec and we can do the operation in place\n        else:\n            xptSensBVecList = xptSensList\n\n        self.assembler.addXptSens(funcHandles, xptSensBVecList, scale)\n\n        # Finalize sensitivity arrays across all procs\n        for xptSensBVec in xptSensBVecList:\n            xptSensBVec.beginSetValues()\n            xptSensBVec.endSetValues()\n\n        # Update from the BVec values, if the input was a numpy array\n        if isinstance(xptSensList[0], np.ndarray):\n            for xptSensArray, xptSensBVec in zip(xptSensList, xptSensBVecList):\n                # Copy values to numpy array\n                xptSensArray[:] = xptSensBVec.getArray()\n\n    def addAdjointResXptSensProducts(self, adjointlist, xptSensList, scale=-1.0):\n        \"\"\"\n        Add the adjoint product contribution to the nodal coordinates sensitivity arrays\n\n        Parameters\n        ----------\n        adjointlist : list[tacs.TACS.Vec] or list[numpy.ndarray]\n            List of adjoint vectors for residual sensitivity product\n\n        xptSensList : list[tacs.TACS.Vec] or list[numpy.ndarray]\n            List of sensitivity vectors to add product to\n\n        scale : float\n            Scalar to multiply product by. Defaults to -1.0\n        \"\"\"\n        # Set problem vars to assembler\n        self._updateAssemblerVars()\n\n        # Create a tacs BVec copy for the operation if the output is a numpy array\n        if isinstance(adjointlist[0], np.ndarray):\n            adjointBVeclist = [\n                self._arrayToVec(adjointArray) for adjointArray in adjointlist\n            ]\n        # Otherwise the input is already a BVec and we can do the operation in place\n        else:\n            adjointBVeclist = adjointlist\n\n        # Make sure BC terms are zeroed out in adjoint\n        for adjoint in adjointBVeclist:\n            self.assembler.applyBCs(adjoint)\n\n        # Create a tacs BVec copy for the operation if the output is a numpy array\n        if isinstance(xptSensList[0], np.ndarray):\n            xptSensBVecList = [\n                self._arrayToNodeVec(xptSensArray) for xptSensArray in xptSensList\n            ]\n        # Otherwise the input is already a BVec and we can do the operation in place\n        else:\n            xptSensBVecList = xptSensList\n\n        self.assembler.addAdjointResXptSensProducts(\n            adjointBVeclist, xptSensBVecList, scale\n        )\n\n        # Finalize sensitivity arrays across all procs\n        for xptSensBVec in xptSensBVecList:\n            xptSensBVec.beginSetValues()\n            xptSensBVec.endSetValues()\n\n        if isinstance(xptSensList[0], np.ndarray):\n            for xptSensArray, xptSensBVec in zip(xptSensList, xptSensBVecList):\n                # Copy values to numpy array\n                xptSensArray[:] = xptSensBVec.getArray()\n\n    def getResidual(self, res, Fext=None):\n        \"\"\"\n        This routine is used to evaluate directly the structural\n        residual. Only typically used with aerostructural analysis.\n\n        Parameters\n        ----------\n        res : tacs.TACS.Vec or numpy.ndarray\n            If res is not None, place the residuals into this array.\n\n        Fext : tacs.TACS.Vec or numpy.ndarray, optional\n            Distributed array containing additional loads (ex. aerodynamic forces for aerostructural coupling)\n            to applied to RHS of the static problem.\n\n        \"\"\"\n        # Make sure assembler variables are up-to-date\n        self._updateAssemblerVars()\n\n        # Determine if the user vector is a BVec or numpy array\n        if isinstance(res, tacs.TACS.Vec):\n            resArray = None\n        else:  # Input is a numpy array\n            resArray = res\n            res = self.res\n\n        # Sum the forces from the loads not handled by TACS\n        self.rhs.copyValues(self.F)  # Fixed loads\n\n        # Add external loads, if specified\n        if Fext is not None:\n            if isinstance(Fext, tacs.TACS.Vec):\n                self.rhs.axpy(1.0, Fext)\n            elif isinstance(Fext, np.ndarray):\n                rhsArray = self.rhs.getArray()\n                rhsArray[:] = rhsArray[:] + Fext[:]\n\n        # Zero out forces on DOF that are subject to BCs\n        self.assembler.applyBCs(self.rhs)\n\n        # Assemble the TACS residual and subtract the externally handled loads\n        self.assembler.assembleRes(res, self._loadScale)\n        res.axpy(-self._loadScale, self.rhs)\n\n        # If requested, copy the residual to the output array\n        if resArray is not None:\n            resArray[:] = res.getArray()\n\n    def getJacobian(self):\n        \"\"\"Get the problem's Jacobian in sciPy sparse matrix format\n\n        Returns\n        -------\n        K : (scipy.sparse.bsr_matrix, scipy.sparse.bsr_matrix) or (scipy.sparse.bsr_matrix, scipy.sparse.bsr_matrix, scipy.sparse.bsr_matrix, scipy.sparse.bsr_matrix)\n            A tuple of 2 scipy.sparse.bsr_matrices (A, B) if Jacobian is a TACSParallelMat, or 4\n            scipy.sparse.bsr_matrices (A, B, C, D) if Jacobian is a TACSSchurMat\n        \"\"\"\n        # Make sure stiffness mat is up-to-date\n        self._updateAssemblerVars()\n        self._initializeSolve()\n        # Return copy of scipy mat\n        return copy.deepcopy(self.K.getMat())\n\n    def addTransposeJacVecProduct(self, phi, prod, scale=1.0):\n        \"\"\"\n        Adds product of transpose Jacobian and input vector into output vector as shown below:\n        prod += scale * J^T . phi\n\n        Parameters\n        ----------\n        phi : tacs.TACS.Vec or numpy.ndarray\n            Input vector to product with the transpose Jacobian.\n\n        prod : tacs.TACS.Vec or numpy.ndarray\n            Output vector to add Jacobian product to.\n\n        scale : float\n            Scalar used to scale Jacobian product by.\n        \"\"\"\n        # Create a tacs bvec copy of the adjoint vector\n        if isinstance(phi, tacs.TACS.Vec):\n            self.phi.copyValues(phi)\n        elif isinstance(phi, np.ndarray):\n            self.phi.getArray()[:] = phi\n\n        # Tacs doesn't actually transpose the matrix here so keep track of\n        # RHS entries that TACS zeros out for BCs.\n        bcTerms = self.update\n        bcTerms.copyValues(self.phi)\n        self.assembler.applyBCs(self.phi)\n        bcTerms.axpy(-1.0, self.phi)\n\n        # Set problem vars to assembler\n        self._updateAssemblerVars()\n\n        self.K.mult(self.phi, self.res)\n        # Add bc terms back in\n        self.res.axpy(1.0, bcTerms)\n\n        # Output residual\n        if isinstance(prod, tacs.TACS.Vec):\n            prod.axpy(scale, self.res)\n        else:\n            prod[:] = prod + scale * self.res.getArray()\n\n    def zeroVariables(self):\n        \"\"\"\n        Zero all the tacs solution b-vecs\n        \"\"\"\n        self.res.zeroEntries()\n        self.u.zeroEntries()\n        self.assembler.setVariables(self.u)\n        self.update.zeroEntries()\n\n    def zeroLoads(self):\n        \"\"\"\n        Zero all applied loads\n        \"\"\"\n        self.F.zeroEntries()\n        self.auxElems = tacs.TACS.AuxElements()\n\n    def solveAdjoint(self, rhs, phi):\n        \"\"\"\n        Solve the structural adjoint.\n\n        Parameters\n        ----------\n        rhs : tacs.TACS.Vec or numpy.ndarray\n            right hand side vector for adjoint solve\n        phi : tacs.TACS.Vec or numpy.ndarray\n            BVec or numpy array into which the adjoint is saved\n        \"\"\"\n\n        # Set problem vars to assembler\n        self._updateAssemblerVars()\n\n        # Check if we need to initialize\n        self._initializeSolve()\n\n        # Create a copy of the adjoint/rhs guess\n        if isinstance(phi, tacs.TACS.Vec):\n            self.phi.copyValues(phi)\n        elif isinstance(phi, np.ndarray):\n            self.phi.getArray()[:] = phi\n\n        if isinstance(rhs, tacs.TACS.Vec):\n            self.adjRHS.copyValues(rhs)\n        elif isinstance(rhs, np.ndarray):\n            self.adjRHS.getArray()[:] = rhs\n\n        # Tacs doesn't actually transpose the matrix here so keep track of\n        # RHS entries that TACS zeros out for BCs.\n        bcTerms = self.update\n        bcTerms.copyValues(self.adjRHS)\n        self.assembler.applyBCs(self.adjRHS)\n        bcTerms.axpy(-1.0, self.adjRHS)\n\n        # Solve Linear System\n        self.KSM.solve(self.adjRHS, self.phi)\n        self.assembler.applyBCs(self.phi)\n        # Add bc terms back in\n        self.phi.axpy(1.0, bcTerms)\n\n        # Copy output values back to user vectors\n        if isinstance(phi, tacs.TACS.Vec):\n            phi.copyValues(self.phi)\n        elif isinstance(phi, np.ndarray):\n            phi[:] = self.phi.getArray()\n\n    def getVariables(self, states=None):\n        \"\"\"\n        Return the current state values for the\n        problem\n\n        Parameters\n        ----------\n        states : tacs.TACS.Vec or numpy.ndarray\n            Vector to place current state variables into (optional)\n\n        Returns\n        ----------\n        states : numpy.ndarray\n            current state vector\n        \"\"\"\n\n        if isinstance(states, tacs.TACS.Vec):\n            states.copyValues(self.u)\n        elif isinstance(states, np.ndarray):\n            states[:] = self.u_array[:]\n\n        return self.u_array.copy()\n\n    def setVariables(self, states):\n        \"\"\"\n        Set the structural states for current load case.\n\n        Parameters\n        ----------\n        states : numpy.ndarray\n            Values to set. Must be the size of getNumVariables()\n        \"\"\"\n        # Copy array values\n        if isinstance(states, tacs.TACS.Vec):\n            self.u.copyValues(states)\n        elif isinstance(states, np.ndarray):\n            self.u_array[:] = states[:]\n        # Apply boundary conditions\n        self.assembler.applyBCs(self.u)\n        # Set states to assembler\n        self.assembler.setVariables(self.u)\n\n    def writeSolution(self, outputDir=None, baseName=None, number=None):\n        \"\"\"\n        This is a generic shell function that writes the output\n        file(s).  The intent is that the user or calling program can\n        call this function and pyTACS writes all the files that the\n        user has defined. It is recommended that this function is used\n        along with the associated logical flags in the options to\n        determine the desired writing procedure\n\n        Parameters\n        ----------\n        outputDir : str or None\n            Use the supplied output directory\n        baseName : str or None\n            Use this supplied string for the base filename. Typically\n            only used from an external solver.\n        number : int or None\n            Use the user supplied number to index solution. Again, only\n            typically used from an external solver\n        \"\"\"\n        # Make sure assembler variables are up to date\n        self._updateAssemblerVars()\n\n        # Check input\n        if outputDir is None:\n            outputDir = self.getOption(\"outputDir\")\n\n        if baseName is None:\n            baseName = self.name\n\n        # If we are numbering solution, it saving the sequence of\n        # calls, add the call number\n        if number is not None:\n            # We need number based on the provided number:\n            baseName = baseName + \"_%3.3d\" % number\n        else:\n            # if number is none, i.e. standalone, but we need to\n            # number solutions, use internal counter\n            if self.getOption(\"numberSolutions\"):\n                baseName = baseName + \"_%3.3d\" % self.callCounter\n\n        # Unless the writeSolution option is off write actual file:\n        if self.getOption(\"writeSolution\"):\n            base = os.path.join(outputDir, baseName) + \".f5\"\n            self.outputViewer.writeToFile(base)\n\n    def writeLoadToBDF(self, bdfFile, loadCaseID):\n        \"\"\"\n        Write loads from problem to NASTRAN BDF file.\n        NOTE: To get correct loads, `solve` method should be called before this method.\n\n        Parameters\n        ----------\n        bdfFile: str or pyNastran.bdf.bdf.BDF or None\n            Name of file to write BDF file to. Only required on root proc,\n            can be None otherwise.\n        loadCaseID: int\n            NASTARAN loadcase ID to assign loads to in BDF.\n        \"\"\"\n\n        # Grab RHS vector from previous solve\n        F = self.rhs\n        F_array = np.real(F.getArray())\n\n        # Get local force info for each processor\n        multNodes = self.meshLoader.getLocalMultiplierNodeIDs()\n        globalToLocalNodeIDDict = self.meshLoader.getGlobalToLocalNodeIDDict()\n\n        # Gather local info to root processor\n        allMultNodes = self.comm.gather(multNodes, root=0)\n        allGlobalToLocalNodeIDDict = self.comm.gather(globalToLocalNodeIDDict, root=0)\n        allF = self.comm.gather(F_array, root=0)\n\n        vpn = self.getVarsPerNode()\n\n        # Assemble new BDF file on root\n        if self.comm.rank == 0:\n            if isinstance(bdfFile, str):\n                newBDFInfo = pn.bdf.BDF(debug=False)\n            elif isinstance(bdfFile, pn.bdf.BDF):\n                newBDFInfo = bdfFile\n\n            # Save subcase info to bdf\n            if newBDFInfo.case_control_deck is not None:\n                newBDFInfo.case_control_deck.create_new_subcase(loadCaseID)\n                newBDFInfo.case_control_deck.add_parameter_to_local_subcase(\n                    loadCaseID, f\"SUBTITLE={self.name}\"\n                )\n                newBDFInfo.case_control_deck.add_parameter_to_local_subcase(\n                    loadCaseID, f\"ANALYSIS=STATICS\"\n                )\n                newBDFInfo.case_control_deck.add_parameter_to_local_subcase(\n                    loadCaseID, f\"LOAD={loadCaseID}\"\n                )\n\n            # Tolerance for writing out point loads\n            zero_tol = 1e-6\n            # Write out force values\n            nastranNodeIDs = list(self.bdfInfo.node_ids)\n            # Loop through each proc and pull out nodal forces\n            for proc_i in range(self.comm.size):\n                Fxyz = allF[proc_i].reshape(-1, vpn)\n                for tacsGNodeID in allGlobalToLocalNodeIDDict[proc_i]:\n                    # Get local node ID\n                    tacsLNodeID = allGlobalToLocalNodeIDDict[proc_i][tacsGNodeID]\n                    # Get Global nastran ID\n                    nastranGNodeID = nastranNodeIDs[tacsGNodeID]\n                    # Add force to bdf file (if its not a multiplier node)\n                    if tacsLNodeID not in allMultNodes[proc_i]:\n                        # Check if force is above tolerance before adding to bdf\n                        if (\n                            vpn >= 3\n                            and np.linalg.norm(Fxyz[tacsLNodeID][:3]) > zero_tol\n                        ):\n                            f = np.zeros(3)\n                            for i in range(3):\n                                if abs(Fxyz[tacsLNodeID][i]) > zero_tol:\n                                    f[i] = Fxyz[tacsLNodeID][i]\n                            newBDFInfo.add_force(loadCaseID, nastranGNodeID, 1.0, f)\n                        if (\n                            vpn >= 6\n                            and np.linalg.norm(Fxyz[tacsLNodeID][3:6]) > zero_tol\n                        ):\n                            m = np.zeros(3)\n                            for i in range(3):\n                                if abs(Fxyz[tacsLNodeID][i + 3]) > zero_tol:\n                                    m[i] = Fxyz[tacsLNodeID][i + 3]\n                            newBDFInfo.add_moment(loadCaseID, nastranGNodeID, 1.0, m)\n\n            # If bdf file was provided as a file name save it directly\n            if isinstance(bdfFile, str):\n                newBDFInfo.write_bdf(\n                    bdfFile, size=16, is_double=True, write_header=False\n                )\n\n        # All procs should wait for root\n        self.comm.barrier()",
  "def __init__(\n        self,\n        name,\n        assembler,\n        comm,\n        outputViewer=None,\n        meshLoader=None,\n        options=None,\n    ):\n        \"\"\"\n        NOTE: This class should not be initialized directly by the user.\n        Use pyTACS.createStaticProblem instead.\n\n        Parameters\n        ----------\n        name : str\n            Name of this tacs problem\n\n        assembler : tacs.TACS.Assembler\n            Cython object responsible for creating and setting tacs objects used to solve problem\n\n        comm : mpi4py.MPI.Intracomm\n            The comm object on which to create the pyTACS object.\n\n        outputViewer : tacs.TACS.TACSToFH5\n            Cython object used to write out f5 files that can be converted and used for postprocessing.\n\n        meshLoader : tacs.pymeshloader.pyMeshLoader\n            pyMeshLoader object used to create the assembler.\n\n        options : dict\n            Dictionary holding problem-specific option parameters (case-insensitive).\n\n        \"\"\"\n\n        # Problem name\n        self.name = name\n\n        # Set linear solver to None, until we set it up later\n        self.KSM = None\n\n        # Default setup for common problem class objects, sets up comm and options\n        TACSProblem.__init__(self, assembler, comm, options, outputViewer, meshLoader)\n\n        # Create problem-specific variables\n        self._createVariables()",
  "def _createVariables(self):\n        \"\"\"Internal to create the variable required by TACS\"\"\"\n\n        # Generic residual vector\n        self.res = self.assembler.createVec()\n        self.rhs = self.assembler.createVec()\n\n        # Dictionaries to hold adjoint/sens vectors for each evalFunc\n        self.adjointList = OrderedDict()\n        self.dIduList = OrderedDict()\n        self.dvSensList = OrderedDict()\n        self.xptSensList = OrderedDict()\n        # Temporary vector for adjoint solve\n        self.phi = self.assembler.createVec()\n        self.adjRHS = self.assembler.createVec()\n\n        # Load vector\n        self.F = self.assembler.createVec()\n        self.F_array = self.F.getArray()\n        # State variable vector\n        self.u = self.assembler.createVec()\n        self.u_array = self.u.getArray()\n        # Auxiliary element object for applying tractions/pressure\n        self.auxElems = tacs.TACS.AuxElements()\n        # Counter for number of calls to `solve` method\n        self.callCounter = -1\n\n        # Norms\n        self.initNorm = 0.0\n        self.startNorm = 0.0\n        self.finalNorm = 0.0\n\n        # Load scaling factor\n        self._loadScale = 1.0\n\n        opt = self.getOption\n\n        # Tangent Stiffness --- process the ordering option here:\n        ordering = opt(\"orderingType\")\n\n        # True stiffness matrix\n        self.K = self.assembler.createSchurMat(ordering)\n        # Artificial stiffness for RBE numerical stabilization to stabilize PC\n        self.rbeArtificialStiffness = self.assembler.createSchurMat(ordering)\n\n        # Additional Vecs for updates\n        self.update = self.assembler.createVec()\n\n        # Setup PCScMat and KSM solver\n        self.alpha = 1.0\n        self.beta = 0.0\n        self.gamma = 0.0\n\n        # Computes stiffness matrix w/o art. terms\n        # Set artificial stiffness factors in rbe class to zero\n        tacs.elements.RBE2.setScalingParameters(opt(\"RBEStiffnessScaleFactor\"), 0.0)\n        tacs.elements.RBE3.setScalingParameters(opt(\"RBEStiffnessScaleFactor\"), 0.0)\n        self.assembler.assembleJacobian(\n            self.alpha,\n            self.beta,\n            self.gamma,\n            self.res,\n            self.K,\n            loadScale=self.loadScale,\n        )\n\n        # Now isolate art. terms\n        # Recompute stiffness with artificial terms included\n        tacs.elements.RBE2.setScalingParameters(\n            opt(\"RBEStiffnessScaleFactor\"), opt(\"RBEArtificialStiffness\")\n        )\n        tacs.elements.RBE3.setScalingParameters(\n            opt(\"RBEStiffnessScaleFactor\"), opt(\"RBEArtificialStiffness\")\n        )\n        self.assembler.assembleJacobian(\n            self.alpha, self.beta, self.gamma, None, self.rbeArtificialStiffness\n        )\n        # Subtract full stiffness w/o artificial terms from full stiffness w/ terms\n        # to isolate  artificial stiffness terms\n        self.rbeArtificialStiffness.axpy(-1.0, self.K)\n\n        reorderSchur = 1\n        self.PC = tacs.TACS.Pc(\n            self.K,\n            lev_fill=opt(\"PCFillLevel\"),\n            ratio_fill=opt(\"PCFillRatio\"),\n            reorder=reorderSchur,\n        )\n\n        # Operator, fill level, fill ratio, msub, rtol, ataol\n        if opt(\"KSMSolver\").upper() == \"GMRES\":\n            self.KSM = tacs.TACS.KSM(\n                self.K,\n                self.PC,\n                opt(\"subSpaceSize\"),\n                opt(\"nRestarts\"),\n                opt(\"flexible\"),\n            )\n        # TODO: Fix this\n        # elif opt('KSMSolver').upper() == 'GCROT':\n        #    self.KSM = tacs.TACS.GCROT(\n        #        self.K, self.PC, opt('subSpaceSize'), opt('subSpaceSize'),\n        #        opt('nRestarts'), opt('flexible'))\n        else:\n            raise self._TACSError(\n                \"Unknown KSMSolver option. Valid options are \" \"'GMRES' or 'GCROT'\"\n            )\n\n        self.KSM.setTolerances(\n            self.getOption(\"L2ConvergenceRel\"), self.getOption(\"L2Convergence\")\n        )\n\n        if opt(\"useMonitor\"):\n            self.KSM.setMonitor(\n                self.comm,\n                _descript=opt(\"KSMSolver\").upper(),\n                freq=opt(\"monitorFrequency\"),\n            )\n\n        # Linear solver factor flag\n        self._factorOnNext = True",
  "def setOption(self, name, value):\n        \"\"\"\n        Set a solver option value. The name is not case sensitive.\n\n        Parameters\n        ----------\n        name : str\n            Name of option to modify\n\n        value : depends on option\n            New option value to set\n        \"\"\"\n        # Default setOption for common problem class objects\n        TACSProblem.setOption(self, name, value)\n\n        if self.KSM is not None:\n            # Update tolerances\n            if \"l2convergence\" in name.lower():\n                self.KSM.setTolerances(\n                    self.getOption(\"L2ConvergenceRel\"),\n                    self.getOption(\"L2Convergence\"),\n                )\n            # No need to reset solver for output options\n            elif name.lower() in [\n                \"writesolution\",\n                \"printtiming\",\n                \"numbersolutions\",\n                \"outputdir\",\n            ]:\n                pass\n            # Reset solver for all other option changes\n            else:\n                self._createVariables()",
  "def loadScale(self):\n        \"\"\"This is a scaling factor applied to all forcing terms\n\n        Forcing terms includes both the user supplied force vector and the forcing terms coming from aux elements in\n        the TACS assembler (e.g inertial, centrifugal forces)\n\n        Returns\n        -------\n        float or complex\n            The current load scale\n        \"\"\"\n        return self._loadScale",
  "def loadScale(self, value):\n        \"\"\"Set the scaling applied to external loads\n\n        This function exists so that calling `problem.loadScale = value` has the same effect as calling::\n\n            `problem.setLoadScale(value)`\n\n        This is important in case we want to update other things when the load scale is changed in future\n\n        Parameters\n        ----------\n        value : float or complex\n            Value to set the load scale to\n        \"\"\"\n        self.setLoadScale(value)",
  "def setLoadScale(self, value):\n        \"\"\"Set the scaling applied to external loads\n\n        Parameters\n        ----------\n        value : float or complex\n            Value to set the load scale to\n        \"\"\"\n        if value != self._loadScale:\n            self._factorOnNext = True\n            self._loadScale = value",
  "def addFunction(self, funcName, funcHandle, compIDs=None, **kwargs):\n        \"\"\"\n        Generic method to add a function for TACS. It is intended to\n        be reasonably generic since the user supplies the actual\n        function handle to use. See the :py:mod:`~tacs.functions` module\n        for supported TACS eval functions.\n\n        Parameters\n        ----------\n        funcName : str\n            The user-supplied name for the function. This will\n            typically be a string that is meaningful to the user\n\n        funcHandle : tacs.TACS.Function\n            The function handle to use for creation. This must come\n            from the functions module in tacs.\n\n        compIDs: list\n            List of compIDs to select.\n\n        **kwargs:\n            Any keyword arguments to be passed to the TACS function during setup.\n        \"\"\"\n        success = TACSProblem.addFunction(self, funcName, funcHandle, compIDs, **kwargs)\n        if success:\n            # Create additional tacs BVecs to hold adjoint and sens info\n            self.adjointList[funcName] = self.assembler.createVec()\n            self.dIduList[funcName] = self.assembler.createVec()\n            self.dvSensList[funcName] = self.assembler.createDesignVec()\n            self.xptSensList[funcName] = self.assembler.createNodeVec()\n        return success",
  "def setDesignVars(self, x):\n        \"\"\"\n        Update the design variables used by tacs.\n\n        Parameters\n        ----------\n        x : numpy.ndarray or dict or tacs.TACS.Vec\n            The variables (typically from the optimizer) to set. It\n            looks for variable in the ``self.varName`` attribute.\n\n        \"\"\"\n        TACSProblem.setDesignVars(self, x)\n        self._factorOnNext = True",
  "def setNodes(self, coords):\n        \"\"\"\n        Set the mesh coordinates of the structure.\n\n        Parameters\n        ----------\n        coords : numpy.ndarray\n            Structural coordinate in array of size (N * 3) where N is\n            the number of structural nodes on this processor.\n        \"\"\"\n        TACSProblem.setNodes(self, coords)\n        self._factorOnNext = True",
  "def addLoadToComponents(self, compIDs, F, averageLoad=False):\n        \"\"\"\n        This method is used to add a *FIXED TOTAL LOAD* on one or more\n        components, defined by COMPIDs. The purpose of this routine is to add loads that\n        remain fixed throughout an optimization. An example would be an engine load.\n        This routine determines all the unique nodes in the FE model that are part of the\n        requested components, then takes the total 'force' by F and divides by the\n        number of nodes. This average load is then applied to the nodes.\n\n        Parameters\n        ----------\n\n        compIDs : list[int] or int\n            The components with added loads. Use pyTACS selectCompIDs method\n            to determine this.\n\n        F : numpy.ndarray 1d or 2d length (varsPerNodes) or (numCompIDs, varsPerNodes)\n            Vector(s) of 'force' to apply to each component.  If only one force vector is provided,\n            force will be copied uniformly across all components.\n\n        averageLoad : bool\n            Flag to determine whether load should be split evenly across all components (True)\n            or copied and applied individually to each component (False). Defaults to False.\n\n        Notes\n        -----\n\n        The units of the entries of the 'force' vector F are not\n        necessarily physical forces and their interpretation depends\n        on the physics problem being solved and the dofs included\n        in the model.\n\n        A couple of examples of force vector components for common problems are listed below:\n\n            In Heat Conduction with varsPerNode = 1\n                F = [Qdot] # heat rate\n            In Elasticity with varsPerNode = 3,\n                F = [fx, fy, fz] # forces\n            In Elasticity with varsPerNode = 6,\n                F = [fx, fy, fz, mx, my, mz] # forces + moments\n            In Thermoelasticity with varsPerNode = 4,\n                F = [fx, fy, fz, Qdot] # forces + heat rate\n            In Thermoelasticity with varsPerNode = 7,\n                F = [fx, fy, fz, mx, my, mz, Qdot] # forces + moments + heat rate\n        \"\"\"\n        self._addLoadToComponents(self.F, compIDs, F, averageLoad)",
  "def addLoadToNodes(self, nodeIDs, F, nastranOrdering=False):\n        \"\"\"\n        This method is used to add a fixed point load of F to the\n        selected node IDs.\n\n        Parameters\n        ----------\n\n        nodeIDs : list[int]\n            The nodes IDs with added loads.\n\n        F : Numpy 1d or 2d array length (varsPerNodes) or (numNodeIDs, varsPerNodes)\n            Array of force vectors, one for each node. If only one force vector is provided,\n            force will be copied uniformly across all nodes.\n\n        nastranOrdering : bool\n            Flag signaling whether nodeIDs are in TACS (default)\n            or NASTRAN (grid IDs in bdf file) ordering\n\n        Notes\n        -----\n\n        The units of the entries of the 'force' vector F are not\n        necessarily physical forces and their interpretation depends\n        on the physics problem being solved and the dofs included\n        in the model.\n\n        A couple of examples of force vector components for common problems are listed below:\n\n            In Heat Conduction with varsPerNode = 1\n                F = [Qdot] # heat rate\n            In Elasticity with varsPerNode = 3,\n                F = [fx, fy, fz] # forces\n            In Elasticity with varsPerNode = 6,\n                F = [fx, fy, fz, mx, my, mz] # forces + moments\n            In Thermoelasticity with varsPerNode = 4,\n                F = [fx, fy, fz, Qdot] # forces + heat rate\n            In Thermoelasticity with varsPerNode = 7,\n                F = [fx, fy, fz, mx, my, mz, Qdot] # forces + moments + heat rate\n        \"\"\"\n\n        self._addLoadToNodes(self.F, nodeIDs, F, nastranOrdering)",
  "def addLoadToRHS(self, Fapplied):\n        \"\"\"\n        This method is used to add a *FIXED TOTAL LOAD* directly to the\n        right hand side vector given the equation below:\n\n            K*u = f\n\n        Where:\n            - K : Stiffness matrix for problem\n            - u : State variables for problem\n            - f : Right-hand side vector to add loads to\n\n        Parameters\n        ----------\n\n        Fapplied : numpy.ndarray or tacs.TACS.Vec\n            Distributed array containing loads to applied to RHS of the problem.\n\n        \"\"\"\n        self._addLoadToRHS(self.F, Fapplied)",
  "def addTractionToComponents(self, compIDs, tractions, faceIndex=0):\n        \"\"\"\n        This method is used to add a *FIXED TOTAL TRACTION* on one or more\n        components, defined by COMPIDs. The purpose of this routine is\n        to add loads that remain fixed throughout an optimization.\n\n        Parameters\n        ----------\n\n        compIDs : list[int] or int\n            The components with added loads. Use pyTACS selectCompIDs method\n            to determine this.\n\n        tractions : Numpy array length 1 or compIDs\n            Array of traction vectors for each component\n\n        faceIndex : int\n            Indicates which face (side) of element to apply traction to.\n            Note: not required for certain elements (i.e. shells)\n        \"\"\"\n        self._addTractionToComponents(self.auxElems, compIDs, tractions, faceIndex)",
  "def addTractionToElements(\n        self, elemIDs, tractions, faceIndex=0, nastranOrdering=False\n    ):\n        \"\"\"\n        This method is used to add a fixed traction to the\n        selected element IDs. Tractions can be specified on an\n        element by element basis (if tractions is a 2d array) or\n        set to a uniform value (if tractions is a 1d array)\n\n        Parameters\n        ----------\n\n        elemIDs : list[int]\n            The global element ID numbers for which to apply the traction.\n\n        tractions : Numpy 1d or 2d array length varsPerNodes or (elemIDs, varsPerNodes)\n            Array of traction vectors for each element\n\n        faceIndex : int\n            Indicates which face (side) of element to apply traction to.\n            Note: not required for certain elements (i.e. shells)\n\n        nastranOrdering : bool\n            Flag signaling whether elemIDs are in TACS (default)\n            or NASTRAN ordering\n        \"\"\"\n\n        self._addTractionToElements(\n            self.auxElems, elemIDs, tractions, faceIndex, nastranOrdering\n        )",
  "def addPressureToComponents(self, compIDs, pressures, faceIndex=0):\n        \"\"\"\n        This method is used to add a *FIXED TOTAL PRESSURE* on one or more\n        components, defined by COMPIds. The purpose of this routine is\n        to add loads that remain fixed throughout an optimization. An example\n        would be a fuel load.\n\n        Parameters\n        ----------\n\n        compIDs : list[int] or int\n            The components with added loads. Use pyTACS selectCompIDs method\n            to determine this.\n\n        pressures : Numpy array length 1 or compIDs\n            Array of pressure values for each component\n\n        faceIndex : int\n            Indicates which face (side) of element to apply pressure to.\n            Note: not required for certain elements (i.e. shells)\n        \"\"\"\n        self._addPressureToComponents(self.auxElems, compIDs, pressures, faceIndex)",
  "def addPressureToElements(\n        self, elemIDs, pressures, faceIndex=0, nastranOrdering=False\n    ):\n        \"\"\"\n        This method is used to add a fixed presure to the\n        selected element IDs. Pressures can be specified on an\n        element by element basis (if pressures is an array) or\n        set to a uniform value (if pressures is a scalar)\n\n        Parameters\n        ----------\n\n        elemIDs : list[int]\n            The global element ID numbers for which to apply the pressure.\n\n        pressures : Numpy array length 1 or elemIDs\n            Array of pressure values for each element\n\n        faceIndex : int\n            Indicates which face (side) of element to apply pressure to.\n            Note: not required for certain elements (i.e. shells)\n\n        nastranOrdering : bool\n            Flag signaling whether elemIDs are in TACS (default)\n            or NASTRAN ordering\n        \"\"\"\n\n        self._addPressureToElements(\n            self.auxElems, elemIDs, pressures, faceIndex, nastranOrdering\n        )",
  "def addInertialLoad(self, inertiaVector):\n        \"\"\"\n        This method is used to add a fixed inertial load due to\n        a uniform acceleration over the entire model.\n        This is most commonly used to model gravity loads on a model.\n\n        Parameters\n        ----------\n        inertiaVector : numpy.ndarray\n            Acceleration vector used to define inertial load.\n        \"\"\"\n        self._addInertialLoad(self.auxElems, inertiaVector)",
  "def addCentrifugalLoad(self, omegaVector, rotCenter, firstOrder=False):\n        \"\"\"\n        This method is used to add a fixed centrifugal load due to a\n        uniform rotational velocity over the entire model.\n        This is most commonly used to model rotors, rolling aircraft, etc.\n\n        Parameters\n        ----------\n\n        omegaVector : numpy.ndarray\n            Rotational velocity vector (rad/s) used to define centrifugal load.\n\n        rotCenter : numpy.ndarray\n            Location of center of rotation used to define centrifugal load.\n\n        firstOrder : bool, optional\n            Whether to use first order approximation for centrifugal load,\n            which computes the force in the displaced position. By default False\n        \"\"\"\n        self._addCentrifugalLoad(self.auxElems, omegaVector, rotCenter, firstOrder)",
  "def addLoadFromBDF(self, loadID, scale=1.0):\n        \"\"\"\n        This method is used to add a fixed load set defined in the BDF file to the problem.\n        Currently, only supports LOAD, FORCE, MOMENT, GRAV, RFORCE, PLOAD2, and PLOAD4.\n\n        Parameters\n        ----------\n\n        loadID : int\n            Load identification number of load set in BDF file user wishes to add to problem.\n\n        scale : float\n            Factor to scale the BDF loads by before adding to problem.\n        \"\"\"\n        self._addLoadFromBDF(self.F, self.auxElems, loadID, scale)",
  "def _updateAssemblerVars(self):\n        \"\"\"\n        Make sure that the assembler is using\n        the input variables associated with this problem\n        \"\"\"\n\n        self.assembler.setDesignVars(self.x)\n        self.assembler.setNodes(self.Xpts)\n        self.assembler.setAuxElements(self.auxElems)\n        # Set state variables\n        self.assembler.setVariables(self.u)\n        # Zero any time derivative terms\n        self.assembler.zeroDotVariables()\n        self.assembler.zeroDDotVariables()\n        # Set artificial stiffness factors in rbe class to zero\n        tacs.elements.RBE2.setScalingParameters(\n            self.getOption(\"RBEStiffnessScaleFactor\"), 0.0\n        )\n        tacs.elements.RBE3.setScalingParameters(\n            self.getOption(\"RBEStiffnessScaleFactor\"), 0.0\n        )",
  "def _initializeSolve(self):\n        \"\"\"\n        Initialize the solution of the structural system for the\n        loadCase. The stiffness matrix is assembled and factored.\n        \"\"\"\n\n        if self._factorOnNext:\n            # Assemble residual and stiffness matrix (w/o artificial terms)\n            self.assembler.assembleJacobian(\n                self.alpha,\n                self.beta,\n                self.gamma,\n                self.res,\n                self.K,\n                loadScale=self._loadScale,\n            )\n            # Stiffness matrix must include artificial terms before pc factor\n            # to prevent factorization issues w/ zero-diagonals\n            self.K.axpy(1.0, self.rbeArtificialStiffness)\n            self.PC.factor()\n            # Remove artificial stiffness terms to get true stiffness mat\n            self.K.axpy(-1.0, self.rbeArtificialStiffness)\n            self._factorOnNext = False",
  "def solve(self, Fext=None):\n        \"\"\"\n        Solution of the static problem for current load set. The\n        forces must already be set.\n\n        Parameters\n        ----------\n        Optional Arguments:\n\n        Fext : numpy.ndarray or tacs.TACS.Vec\n            Distributed array containing additional loads (ex. aerodynamic forces for aerostructural coupling)\n            to applied to RHS of the static problem.\n\n        \"\"\"\n        startTime = time.time()\n\n        self.callCounter += 1\n\n        setupProblemTime = time.time()\n\n        # Set problem vars to assembler\n        self._updateAssemblerVars()\n\n        # Check if we need to initialize\n        self._initializeSolve()\n\n        initSolveTime = time.time()\n\n        # Get current residual\n        self.getResidual(self.res, Fext=Fext)\n\n        # Get rhs vector\n        self.K.mult(self.u, self.rhs)\n        self.rhs.axpy(-1.0, self.res)\n\n        # Set initnorm as the norm of rhs\n        self.initNorm = np.real(self.rhs.norm())\n\n        # Starting Norm for this computation\n        self.startNorm = np.real(self.res.norm())\n\n        initNormTime = time.time()\n\n        # Solve Linear System for the update\n        success = self.KSM.solve(self.res, self.update)\n\n        if not success:\n            self._TACSWarning(\n                \"Linear solver failed to converge. \"\n                \"This is likely a sign that the problem is ill-conditioned. \"\n                \"Check that the model is properly restrained.\"\n            )\n\n        self.update.scale(-1.0)\n\n        solveTime = time.time()\n\n        # Update State Variables\n        self.assembler.getVariables(self.u)\n        self.u.axpy(1.0, self.update)\n        self.assembler.setVariables(self.u)\n\n        stateUpdateTime = time.time()\n\n        # Get updated residual\n        self.getResidual(self.res, Fext)\n        self.finalNorm = np.real(self.res.norm())\n\n        finalNormTime = time.time()\n\n        # If timing was was requested print it, if the solution is nonlinear\n        # print this information automatically if print iterations was requested.\n        if self.getOption(\"printTiming\"):\n            self._pp(\"+--------------------------------------------------+\")\n            self._pp(\"|\")\n            self._pp(\"| TACS Solve Times:\")\n            self._pp(\"|\")\n            self._pp(\n                \"| %-30s: %10.3f sec\"\n                % (\"TACS Setup Time\", setupProblemTime - startTime)\n            )\n            self._pp(\n                \"| %-30s: %10.3f sec\"\n                % (\"TACS Solve Init Time\", initSolveTime - setupProblemTime)\n            )\n            self._pp(\n                \"| %-30s: %10.3f sec\"\n                % (\"TACS Init Norm Time\", initNormTime - initSolveTime)\n            )\n            self._pp(\n                \"| %-30s: %10.3f sec\" % (\"TACS Solve Time\", solveTime - initNormTime)\n            )\n            self._pp(\n                \"| %-30s: %10.3f sec\"\n                % (\"TACS State Update Time\", stateUpdateTime - solveTime)\n            )\n            self._pp(\n                \"| %-30s: %10.3f sec\"\n                % (\"TACS Final Norm Time\", finalNormTime - stateUpdateTime)\n            )\n            self._pp(\"|\")\n            self._pp(\n                \"| %-30s: %10.3f sec\"\n                % (\"TACS Total Solution Time\", finalNormTime - startTime)\n            )\n            self._pp(\"+--------------------------------------------------+\")\n\n        return",
  "def evalFunctions(self, funcs, evalFuncs=None, ignoreMissing=False):\n        \"\"\"\n        This is the main routine for returning useful information from\n        pytacs. The functions corresponding to the strings in\n        evalFuncs are evaluated and updated into the provided\n        dictionary.\n\n        Parameters\n        ----------\n        funcs : dict\n            Dictionary into which the functions are saved.\n        evalFuncs : iterable object containing strings.\n            If not none, use these functions to evaluate.\n        ignoreMissing : bool\n            Flag to supress checking for a valid function. Please use\n            this option with caution.\n\n        Examples\n        --------\n        >>> funcs = {}\n        >>> staticProblem.solve()\n        >>> staticProblem.evalFunctions(funcs, ['mass'])\n        >>> funcs\n        >>> # Result will look like (if StaticProblem has name of 'c1'):\n        >>> # {'cl_mass':12354.10}\n        \"\"\"\n        startTime = time.time()\n\n        # Set problem vars to assembler\n        self._updateAssemblerVars()\n\n        if evalFuncs is None:\n            evalFuncs = sorted(list(self.functionList))\n        else:\n            evalFuncs = sorted(list(evalFuncs))\n\n        if not ignoreMissing:\n            for f in evalFuncs:\n                if f not in self.functionList:\n                    raise self._TACSError(\n                        f\"Supplied function '{f}' has not been added \"\n                        \"using addFunction().\"\n                    )\n\n        setupProblemTime = time.time()\n\n        # Fast parallel function evaluation of structural funcs:\n        handles = [self.functionList[f] for f in evalFuncs if f in self.functionList]\n        funcVals = self.assembler.evalFunctions(handles)\n\n        functionEvalTime = time.time()\n\n        # Assign function values to appropriate dictionary\n        i = 0\n        for f in evalFuncs:\n            if f in self.functionList:\n                key = self.name + \"_%s\" % f\n                funcs[key] = funcVals[i]\n                i += 1\n\n        dictAssignTime = time.time()\n\n        if self.getOption(\"printTiming\"):\n            self._pp(\"+--------------------------------------------------+\")\n            self._pp(\"|\")\n            self._pp(\"| TACS Function Times:\")\n            self._pp(\"|\")\n            self._pp(\n                \"| %-30s: %10.3f sec\"\n                % (\"TACS Function Setup Time\", setupProblemTime - startTime)\n            )\n            self._pp(\n                \"| %-30s: %10.3f sec\"\n                % (\n                    \"TACS Function Eval Time\",\n                    functionEvalTime - setupProblemTime,\n                )\n            )\n            self._pp(\n                \"| %-30s: %10.3f sec\"\n                % (\"TACS Dict Time\", dictAssignTime - functionEvalTime)\n            )\n            self._pp(\"|\")\n            self._pp(\n                \"| %-30s: %10.3f sec\"\n                % (\"TACS Function Time\", dictAssignTime - startTime)\n            )\n            self._pp(\"+--------------------------------------------------+\")",
  "def evalFunctionsSens(self, funcsSens, evalFuncs=None):\n        \"\"\"\n        This is the main routine for returning useful (sensitivity)\n        information from problem. The derivatives of the functions\n        corresponding to the strings in evalFuncs are evaluated and\n        updated into the provided dictionary. The derivitives with\n        respect to all design variables and node locations are computed.\n\n        Parameters\n        ----------\n        funcsSens : dict\n            Dictionary into which the derivatives are saved.\n        evalFuncs : iterable object containing strings\n            The functions the user wants returned\n\n        Examples\n        --------\n        >>> funcsSens = {}\n        >>> staticProblem.evalFunctionsSens(funcsSens, ['mass'])\n        >>> funcsSens\n        >>> # Result will look like (if StaticProblem has name of 'c1'):\n        >>> # {'c1_mass':{'struct':[1.234, ..., 7.89], 'Xpts':[3.14, ..., 1.59]}}\n        \"\"\"\n\n        startTime = time.time()\n\n        # Set problem vars to assembler\n        self._updateAssemblerVars()\n\n        if evalFuncs is None:\n            evalFuncs = sorted(list(self.functionList))\n        else:\n            evalFuncs = sorted(list(evalFuncs))\n        # Check that the functions are all ok.\n        # and prepare tacs vecs for adjoint procedure\n        dvSenses = []\n        xptSenses = []\n        dIdus = []\n        adjoints = []\n        for f in evalFuncs:\n            if f not in self.functionList:\n                raise self._TACSError(\n                    \"Supplied function has not been added \" \"using addFunction()\"\n                )\n            else:\n                # Populate the lists with the tacs bvecs\n                # we'll need for each adjoint/sens calculation\n                dvSens = self.dvSensList[f]\n                dvSens.zeroEntries()\n                dvSenses.append(dvSens)\n\n                xptSens = self.xptSensList[f]\n                xptSens.zeroEntries()\n                xptSenses.append(xptSens)\n\n                dIdu = self.dIduList[f]\n                dIdu.zeroEntries()\n                dIdus.append(dIdu)\n\n                adjoint = self.adjointList[f]\n                adjoint.zeroEntries()\n                adjoints.append(adjoint)\n\n        setupProblemTime = time.time()\n\n        adjointStartTime = {}\n        adjointEndTime = {}\n\n        # Next we will solve all the adjoints\n        # Set adjoint rhs\n        self.addSVSens(evalFuncs, dIdus)\n        adjointRHSTime = time.time()\n        for i, f in enumerate(evalFuncs):\n            adjointStartTime[f] = time.time()\n            self.solveAdjoint(dIdus[i], adjoints[i])\n            adjointEndTime[f] = time.time()\n\n        adjointFinishedTime = time.time()\n        # Evaluate all the adoint res prooduct at the same time for\n        # efficiency:\n        self.addDVSens(evalFuncs, dvSenses)\n        self.addAdjointResProducts(adjoints, dvSenses)\n        self.addXptSens(evalFuncs, xptSenses)\n        self.addAdjointResXptSensProducts(adjoints, xptSenses)\n\n        # Recast sensititivities into dict for user\n        for i, f in enumerate(evalFuncs):\n            key = self.name + \"_%s\" % f\n            # Return sensitivities as array in sens dict\n            funcsSens[key] = {\n                self.varName: dvSenses[i].getArray().copy(),\n                self.coordName: xptSenses[i].getArray().copy(),\n            }\n\n        totalSensitivityTime = time.time()\n\n        if self.getOption(\"printTiming\"):\n            self._pp(\"+--------------------------------------------------+\")\n            self._pp(\"|\")\n            self._pp(\"| TACS Adjoint Times:\")\n            print(\"|\")\n            print(\n                \"| %-30s: %10.3f sec\"\n                % (\"TACS Sens Setup Problem Time\", setupProblemTime - startTime)\n            )\n            print(\n                \"| %-30s: %10.3f sec\"\n                % (\"TACS Adjoint RHS Time\", adjointRHSTime - setupProblemTime)\n            )\n            for f in evalFuncs:\n                print(\n                    \"| %-30s: %10.3f sec\"\n                    % (\n                        \"TACS Adjoint Solve Time - %s\" % (f),\n                        adjointEndTime[f] - adjointStartTime[f],\n                    )\n                )\n            print(\n                \"| %-30s: %10.3f sec\"\n                % (\n                    \"Total Sensitivity Time\",\n                    totalSensitivityTime - adjointFinishedTime,\n                )\n            )\n            print(\"|\")\n            print(\n                \"| %-30s: %10.3f sec\"\n                % (\n                    \"Complete Sensitivity Time\",\n                    totalSensitivityTime - startTime,\n                )\n            )\n            print(\"+--------------------------------------------------+\")",
  "def addSVSens(self, evalFuncs, svSensList):\n        \"\"\"\n        Add the state variable partial sensitivity to the ADjoint RHS for given evalFuncs\n\n        Parameters\n        ----------\n        evalFuncs : list[str]\n            The functions the user wants returned\n\n        svSensList : list[tacs.TACS.Vec] or list[numpy.ndarray]\n            List of sensitivity vectors to add partial sensitivity to\n        \"\"\"\n        # Set problem vars to assembler\n        self._updateAssemblerVars()\n\n        # Get list of TACS function handles from evalFuncs\n        funcHandles = [\n            self.functionList[f] for f in evalFuncs if f in self.functionList\n        ]\n\n        # Create a tacs BVec copy for the operation if the output is a numpy array\n        if isinstance(svSensList[0], np.ndarray):\n            svSensBVecList = [\n                self._arrayToVec(svSensArray) for svSensArray in svSensList\n            ]\n        # Otherwise the input is already a BVec and we can do the operation in place\n        else:\n            svSensBVecList = svSensList\n\n        self.assembler.addSVSens(\n            funcHandles, svSensBVecList, self.alpha, self.beta, self.gamma\n        )\n\n        # Update from the BVec values, if the input was a numpy array\n        if isinstance(svSensList[0], np.ndarray):\n            for svSensArray, svSensBVec in zip(svSensList, svSensBVecList):\n                svSensArray[:] = svSensBVec.getArray()",
  "def addDVSens(self, evalFuncs, dvSensList, scale=1.0):\n        \"\"\"\n        Add partial sensitivity contribution due to design vars for evalFuncs\n\n        Parameters\n        ----------\n        evalFuncs : list[str]\n            The functions the user wants returned\n\n        dvSensList : list[tacs.TACS.Vec] or list[numpy.ndarray]\n            List of sensitivity vectors to add partial sensitivity to\n\n        scale : float\n            Scalar to multiply partial sensitivity by. Defaults to 1.0\n        \"\"\"\n        # Set problem vars to assembler\n        self._updateAssemblerVars()\n\n        # Get list of TACS function handles from evalFuncs\n        funcHandles = [\n            self.functionList[f] for f in evalFuncs if f in self.functionList\n        ]\n\n        # Create a tacs BVec copy for the operation if the output is a numpy array\n        if isinstance(dvSensList[0], np.ndarray):\n            dvSensBVecList = [\n                self._arrayToDesignVec(dvSensArray) for dvSensArray in dvSensList\n            ]\n        # Otherwise the input is already a BVec and we can do the operation in place\n        else:\n            dvSensBVecList = dvSensList\n\n        self.assembler.addDVSens(funcHandles, dvSensBVecList, scale)\n\n        # Finalize sensitivity arrays across all procs\n        for dvSensBVec in dvSensBVecList:\n            dvSensBVec.beginSetValues()\n            dvSensBVec.endSetValues()\n\n        # Update the BVec values, if the input was a numpy array\n        if isinstance(dvSensList[0], np.ndarray):\n            for dvSensArray, dvSensBVec in zip(dvSensList, dvSensBVecList):\n                # Copy values to numpy array\n                dvSensArray[:] = dvSensBVec.getArray()",
  "def addAdjointResProducts(self, adjointlist, dvSensList, scale=-1.0):\n        \"\"\"\n        Add the adjoint product contribution to the design variable sensitivity arrays\n\n        Parameters\n        ----------\n        adjointlist : list[tacs.TACS.Vec] or list[numpy.ndarray]\n            List of adjoint vectors for residual sensitivity product\n\n        dvSensList : list[tacs.TACS.Vec] or list[numpy.ndarray]\n            List of sensitivity vectors to add product to\n\n        scale : float\n            Scalar to multiply product by. Defaults to -1.0\n        \"\"\"\n        # Set problem vars to assembler\n        self._updateAssemblerVars()\n\n        # Create a tacs BVec copy for the operation if the output is a numpy array\n        if isinstance(adjointlist[0], np.ndarray):\n            adjointBVeclist = [\n                self._arrayToVec(adjointArray) for adjointArray in adjointlist\n            ]\n        # Otherwise the input is already a BVec and we can do the operation in place\n        else:\n            adjointBVeclist = adjointlist\n\n        # Make sure BC terms are zeroed out in adjoint\n        for adjoint in adjointBVeclist:\n            self.assembler.applyBCs(adjoint)\n\n        # Create a tacs BVec copy for the operation if the output is a numpy array\n        if isinstance(dvSensList[0], np.ndarray):\n            dvSensBVecList = [\n                self._arrayToDesignVec(dvSensArray) for dvSensArray in dvSensList\n            ]\n        # Otherwise the input is already a BVec and we can do the operation in place\n        else:\n            dvSensBVecList = dvSensList\n\n        self.assembler.addAdjointResProducts(adjointBVeclist, dvSensBVecList, scale)\n\n        # Finalize sensitivity arrays across all procs\n        for dvSensBVec in dvSensBVecList:\n            dvSensBVec.beginSetValues()\n            dvSensBVec.endSetValues()\n\n        # Update the BVec values, if the input was a numpy array\n        if isinstance(dvSensList[0], np.ndarray):\n            for dvSensArray, dvSensBVec in zip(dvSensList, dvSensBVecList):\n                # Copy values to numpy array\n                dvSensArray[:] = dvSensBVec.getArray()",
  "def addXptSens(self, evalFuncs, xptSensList, scale=1.0):\n        \"\"\"\n        Add partial sensitivity contribution due to nodal coordinates for evalFuncs\n\n        Parameters\n        ----------\n        evalFuncs : list[str]\n            The functions the user wants returned\n\n        xptSensList : list[tacs.TACS.Vec] or list[numpy.ndarray]\n            List of sensitivity vectors to add partial sensitivity to\n\n        scale : float\n            Scalar to multiply partial sensitivity by. Defaults to 1.0\n        \"\"\"\n        # Set problem vars to assembler\n        self._updateAssemblerVars()\n\n        # Get list of TACS function handles from evalFuncs\n        funcHandles = [\n            self.functionList[f] for f in evalFuncs if f in self.functionList\n        ]\n\n        # Create a tacs BVec copy for the operation if the output is a numpy array\n        if isinstance(xptSensList[0], np.ndarray):\n            xptSensBVecList = [\n                self._arrayToNodeVec(xptSensArray) for xptSensArray in xptSensList\n            ]\n        # Otherwise the input is already a BVec and we can do the operation in place\n        else:\n            xptSensBVecList = xptSensList\n\n        self.assembler.addXptSens(funcHandles, xptSensBVecList, scale)\n\n        # Finalize sensitivity arrays across all procs\n        for xptSensBVec in xptSensBVecList:\n            xptSensBVec.beginSetValues()\n            xptSensBVec.endSetValues()\n\n        # Update from the BVec values, if the input was a numpy array\n        if isinstance(xptSensList[0], np.ndarray):\n            for xptSensArray, xptSensBVec in zip(xptSensList, xptSensBVecList):\n                # Copy values to numpy array\n                xptSensArray[:] = xptSensBVec.getArray()",
  "def addAdjointResXptSensProducts(self, adjointlist, xptSensList, scale=-1.0):\n        \"\"\"\n        Add the adjoint product contribution to the nodal coordinates sensitivity arrays\n\n        Parameters\n        ----------\n        adjointlist : list[tacs.TACS.Vec] or list[numpy.ndarray]\n            List of adjoint vectors for residual sensitivity product\n\n        xptSensList : list[tacs.TACS.Vec] or list[numpy.ndarray]\n            List of sensitivity vectors to add product to\n\n        scale : float\n            Scalar to multiply product by. Defaults to -1.0\n        \"\"\"\n        # Set problem vars to assembler\n        self._updateAssemblerVars()\n\n        # Create a tacs BVec copy for the operation if the output is a numpy array\n        if isinstance(adjointlist[0], np.ndarray):\n            adjointBVeclist = [\n                self._arrayToVec(adjointArray) for adjointArray in adjointlist\n            ]\n        # Otherwise the input is already a BVec and we can do the operation in place\n        else:\n            adjointBVeclist = adjointlist\n\n        # Make sure BC terms are zeroed out in adjoint\n        for adjoint in adjointBVeclist:\n            self.assembler.applyBCs(adjoint)\n\n        # Create a tacs BVec copy for the operation if the output is a numpy array\n        if isinstance(xptSensList[0], np.ndarray):\n            xptSensBVecList = [\n                self._arrayToNodeVec(xptSensArray) for xptSensArray in xptSensList\n            ]\n        # Otherwise the input is already a BVec and we can do the operation in place\n        else:\n            xptSensBVecList = xptSensList\n\n        self.assembler.addAdjointResXptSensProducts(\n            adjointBVeclist, xptSensBVecList, scale\n        )\n\n        # Finalize sensitivity arrays across all procs\n        for xptSensBVec in xptSensBVecList:\n            xptSensBVec.beginSetValues()\n            xptSensBVec.endSetValues()\n\n        if isinstance(xptSensList[0], np.ndarray):\n            for xptSensArray, xptSensBVec in zip(xptSensList, xptSensBVecList):\n                # Copy values to numpy array\n                xptSensArray[:] = xptSensBVec.getArray()",
  "def getResidual(self, res, Fext=None):\n        \"\"\"\n        This routine is used to evaluate directly the structural\n        residual. Only typically used with aerostructural analysis.\n\n        Parameters\n        ----------\n        res : tacs.TACS.Vec or numpy.ndarray\n            If res is not None, place the residuals into this array.\n\n        Fext : tacs.TACS.Vec or numpy.ndarray, optional\n            Distributed array containing additional loads (ex. aerodynamic forces for aerostructural coupling)\n            to applied to RHS of the static problem.\n\n        \"\"\"\n        # Make sure assembler variables are up-to-date\n        self._updateAssemblerVars()\n\n        # Determine if the user vector is a BVec or numpy array\n        if isinstance(res, tacs.TACS.Vec):\n            resArray = None\n        else:  # Input is a numpy array\n            resArray = res\n            res = self.res\n\n        # Sum the forces from the loads not handled by TACS\n        self.rhs.copyValues(self.F)  # Fixed loads\n\n        # Add external loads, if specified\n        if Fext is not None:\n            if isinstance(Fext, tacs.TACS.Vec):\n                self.rhs.axpy(1.0, Fext)\n            elif isinstance(Fext, np.ndarray):\n                rhsArray = self.rhs.getArray()\n                rhsArray[:] = rhsArray[:] + Fext[:]\n\n        # Zero out forces on DOF that are subject to BCs\n        self.assembler.applyBCs(self.rhs)\n\n        # Assemble the TACS residual and subtract the externally handled loads\n        self.assembler.assembleRes(res, self._loadScale)\n        res.axpy(-self._loadScale, self.rhs)\n\n        # If requested, copy the residual to the output array\n        if resArray is not None:\n            resArray[:] = res.getArray()",
  "def getJacobian(self):\n        \"\"\"Get the problem's Jacobian in sciPy sparse matrix format\n\n        Returns\n        -------\n        K : (scipy.sparse.bsr_matrix, scipy.sparse.bsr_matrix) or (scipy.sparse.bsr_matrix, scipy.sparse.bsr_matrix, scipy.sparse.bsr_matrix, scipy.sparse.bsr_matrix)\n            A tuple of 2 scipy.sparse.bsr_matrices (A, B) if Jacobian is a TACSParallelMat, or 4\n            scipy.sparse.bsr_matrices (A, B, C, D) if Jacobian is a TACSSchurMat\n        \"\"\"\n        # Make sure stiffness mat is up-to-date\n        self._updateAssemblerVars()\n        self._initializeSolve()\n        # Return copy of scipy mat\n        return copy.deepcopy(self.K.getMat())",
  "def addTransposeJacVecProduct(self, phi, prod, scale=1.0):\n        \"\"\"\n        Adds product of transpose Jacobian and input vector into output vector as shown below:\n        prod += scale * J^T . phi\n\n        Parameters\n        ----------\n        phi : tacs.TACS.Vec or numpy.ndarray\n            Input vector to product with the transpose Jacobian.\n\n        prod : tacs.TACS.Vec or numpy.ndarray\n            Output vector to add Jacobian product to.\n\n        scale : float\n            Scalar used to scale Jacobian product by.\n        \"\"\"\n        # Create a tacs bvec copy of the adjoint vector\n        if isinstance(phi, tacs.TACS.Vec):\n            self.phi.copyValues(phi)\n        elif isinstance(phi, np.ndarray):\n            self.phi.getArray()[:] = phi\n\n        # Tacs doesn't actually transpose the matrix here so keep track of\n        # RHS entries that TACS zeros out for BCs.\n        bcTerms = self.update\n        bcTerms.copyValues(self.phi)\n        self.assembler.applyBCs(self.phi)\n        bcTerms.axpy(-1.0, self.phi)\n\n        # Set problem vars to assembler\n        self._updateAssemblerVars()\n\n        self.K.mult(self.phi, self.res)\n        # Add bc terms back in\n        self.res.axpy(1.0, bcTerms)\n\n        # Output residual\n        if isinstance(prod, tacs.TACS.Vec):\n            prod.axpy(scale, self.res)\n        else:\n            prod[:] = prod + scale * self.res.getArray()",
  "def zeroVariables(self):\n        \"\"\"\n        Zero all the tacs solution b-vecs\n        \"\"\"\n        self.res.zeroEntries()\n        self.u.zeroEntries()\n        self.assembler.setVariables(self.u)\n        self.update.zeroEntries()",
  "def zeroLoads(self):\n        \"\"\"\n        Zero all applied loads\n        \"\"\"\n        self.F.zeroEntries()\n        self.auxElems = tacs.TACS.AuxElements()",
  "def solveAdjoint(self, rhs, phi):\n        \"\"\"\n        Solve the structural adjoint.\n\n        Parameters\n        ----------\n        rhs : tacs.TACS.Vec or numpy.ndarray\n            right hand side vector for adjoint solve\n        phi : tacs.TACS.Vec or numpy.ndarray\n            BVec or numpy array into which the adjoint is saved\n        \"\"\"\n\n        # Set problem vars to assembler\n        self._updateAssemblerVars()\n\n        # Check if we need to initialize\n        self._initializeSolve()\n\n        # Create a copy of the adjoint/rhs guess\n        if isinstance(phi, tacs.TACS.Vec):\n            self.phi.copyValues(phi)\n        elif isinstance(phi, np.ndarray):\n            self.phi.getArray()[:] = phi\n\n        if isinstance(rhs, tacs.TACS.Vec):\n            self.adjRHS.copyValues(rhs)\n        elif isinstance(rhs, np.ndarray):\n            self.adjRHS.getArray()[:] = rhs\n\n        # Tacs doesn't actually transpose the matrix here so keep track of\n        # RHS entries that TACS zeros out for BCs.\n        bcTerms = self.update\n        bcTerms.copyValues(self.adjRHS)\n        self.assembler.applyBCs(self.adjRHS)\n        bcTerms.axpy(-1.0, self.adjRHS)\n\n        # Solve Linear System\n        self.KSM.solve(self.adjRHS, self.phi)\n        self.assembler.applyBCs(self.phi)\n        # Add bc terms back in\n        self.phi.axpy(1.0, bcTerms)\n\n        # Copy output values back to user vectors\n        if isinstance(phi, tacs.TACS.Vec):\n            phi.copyValues(self.phi)\n        elif isinstance(phi, np.ndarray):\n            phi[:] = self.phi.getArray()",
  "def getVariables(self, states=None):\n        \"\"\"\n        Return the current state values for the\n        problem\n\n        Parameters\n        ----------\n        states : tacs.TACS.Vec or numpy.ndarray\n            Vector to place current state variables into (optional)\n\n        Returns\n        ----------\n        states : numpy.ndarray\n            current state vector\n        \"\"\"\n\n        if isinstance(states, tacs.TACS.Vec):\n            states.copyValues(self.u)\n        elif isinstance(states, np.ndarray):\n            states[:] = self.u_array[:]\n\n        return self.u_array.copy()",
  "def setVariables(self, states):\n        \"\"\"\n        Set the structural states for current load case.\n\n        Parameters\n        ----------\n        states : numpy.ndarray\n            Values to set. Must be the size of getNumVariables()\n        \"\"\"\n        # Copy array values\n        if isinstance(states, tacs.TACS.Vec):\n            self.u.copyValues(states)\n        elif isinstance(states, np.ndarray):\n            self.u_array[:] = states[:]\n        # Apply boundary conditions\n        self.assembler.applyBCs(self.u)\n        # Set states to assembler\n        self.assembler.setVariables(self.u)",
  "def writeSolution(self, outputDir=None, baseName=None, number=None):\n        \"\"\"\n        This is a generic shell function that writes the output\n        file(s).  The intent is that the user or calling program can\n        call this function and pyTACS writes all the files that the\n        user has defined. It is recommended that this function is used\n        along with the associated logical flags in the options to\n        determine the desired writing procedure\n\n        Parameters\n        ----------\n        outputDir : str or None\n            Use the supplied output directory\n        baseName : str or None\n            Use this supplied string for the base filename. Typically\n            only used from an external solver.\n        number : int or None\n            Use the user supplied number to index solution. Again, only\n            typically used from an external solver\n        \"\"\"\n        # Make sure assembler variables are up to date\n        self._updateAssemblerVars()\n\n        # Check input\n        if outputDir is None:\n            outputDir = self.getOption(\"outputDir\")\n\n        if baseName is None:\n            baseName = self.name\n\n        # If we are numbering solution, it saving the sequence of\n        # calls, add the call number\n        if number is not None:\n            # We need number based on the provided number:\n            baseName = baseName + \"_%3.3d\" % number\n        else:\n            # if number is none, i.e. standalone, but we need to\n            # number solutions, use internal counter\n            if self.getOption(\"numberSolutions\"):\n                baseName = baseName + \"_%3.3d\" % self.callCounter\n\n        # Unless the writeSolution option is off write actual file:\n        if self.getOption(\"writeSolution\"):\n            base = os.path.join(outputDir, baseName) + \".f5\"\n            self.outputViewer.writeToFile(base)",
  "def writeLoadToBDF(self, bdfFile, loadCaseID):\n        \"\"\"\n        Write loads from problem to NASTRAN BDF file.\n        NOTE: To get correct loads, `solve` method should be called before this method.\n\n        Parameters\n        ----------\n        bdfFile: str or pyNastran.bdf.bdf.BDF or None\n            Name of file to write BDF file to. Only required on root proc,\n            can be None otherwise.\n        loadCaseID: int\n            NASTARAN loadcase ID to assign loads to in BDF.\n        \"\"\"\n\n        # Grab RHS vector from previous solve\n        F = self.rhs\n        F_array = np.real(F.getArray())\n\n        # Get local force info for each processor\n        multNodes = self.meshLoader.getLocalMultiplierNodeIDs()\n        globalToLocalNodeIDDict = self.meshLoader.getGlobalToLocalNodeIDDict()\n\n        # Gather local info to root processor\n        allMultNodes = self.comm.gather(multNodes, root=0)\n        allGlobalToLocalNodeIDDict = self.comm.gather(globalToLocalNodeIDDict, root=0)\n        allF = self.comm.gather(F_array, root=0)\n\n        vpn = self.getVarsPerNode()\n\n        # Assemble new BDF file on root\n        if self.comm.rank == 0:\n            if isinstance(bdfFile, str):\n                newBDFInfo = pn.bdf.BDF(debug=False)\n            elif isinstance(bdfFile, pn.bdf.BDF):\n                newBDFInfo = bdfFile\n\n            # Save subcase info to bdf\n            if newBDFInfo.case_control_deck is not None:\n                newBDFInfo.case_control_deck.create_new_subcase(loadCaseID)\n                newBDFInfo.case_control_deck.add_parameter_to_local_subcase(\n                    loadCaseID, f\"SUBTITLE={self.name}\"\n                )\n                newBDFInfo.case_control_deck.add_parameter_to_local_subcase(\n                    loadCaseID, f\"ANALYSIS=STATICS\"\n                )\n                newBDFInfo.case_control_deck.add_parameter_to_local_subcase(\n                    loadCaseID, f\"LOAD={loadCaseID}\"\n                )\n\n            # Tolerance for writing out point loads\n            zero_tol = 1e-6\n            # Write out force values\n            nastranNodeIDs = list(self.bdfInfo.node_ids)\n            # Loop through each proc and pull out nodal forces\n            for proc_i in range(self.comm.size):\n                Fxyz = allF[proc_i].reshape(-1, vpn)\n                for tacsGNodeID in allGlobalToLocalNodeIDDict[proc_i]:\n                    # Get local node ID\n                    tacsLNodeID = allGlobalToLocalNodeIDDict[proc_i][tacsGNodeID]\n                    # Get Global nastran ID\n                    nastranGNodeID = nastranNodeIDs[tacsGNodeID]\n                    # Add force to bdf file (if its not a multiplier node)\n                    if tacsLNodeID not in allMultNodes[proc_i]:\n                        # Check if force is above tolerance before adding to bdf\n                        if (\n                            vpn >= 3\n                            and np.linalg.norm(Fxyz[tacsLNodeID][:3]) > zero_tol\n                        ):\n                            f = np.zeros(3)\n                            for i in range(3):\n                                if abs(Fxyz[tacsLNodeID][i]) > zero_tol:\n                                    f[i] = Fxyz[tacsLNodeID][i]\n                            newBDFInfo.add_force(loadCaseID, nastranGNodeID, 1.0, f)\n                        if (\n                            vpn >= 6\n                            and np.linalg.norm(Fxyz[tacsLNodeID][3:6]) > zero_tol\n                        ):\n                            m = np.zeros(3)\n                            for i in range(3):\n                                if abs(Fxyz[tacsLNodeID][i + 3]) > zero_tol:\n                                    m[i] = Fxyz[tacsLNodeID][i + 3]\n                            newBDFInfo.add_moment(loadCaseID, nastranGNodeID, 1.0, m)\n\n            # If bdf file was provided as a file name save it directly\n            if isinstance(bdfFile, str):\n                newBDFInfo.write_bdf(\n                    bdfFile, size=16, is_double=True, write_header=False\n                )\n\n        # All procs should wait for root\n        self.comm.barrier()",
  "class TacsCouplingGroup(om.Group):\n    def initialize(self):\n        self.options.declare(\"fea_assembler\", recordable=False)\n        self.options.declare(\"check_partials\")\n        self.options.declare(\"conduction\", default=False)\n        self.options.declare(\"coupled\", default=False)\n        self.options.declare(\"scenario_name\", default=None)\n        self.options.declare(\"problem_setup\", default=None)\n\n    def setup(self):\n        self.fea_assembler = self.options[\"fea_assembler\"]\n        self.check_partials = self.options[\"check_partials\"]\n        self.coupled = self.options[\"coupled\"]\n        self.conduction = self.options[\"conduction\"]\n\n        # Promote state variables/rhs with physics-specific tag that MPhys expects\n        promotes_inputs = [\n            (\"x_struct0\", \"unmasker.x_struct0\"),\n            (\"tacs_dvs\", \"distributor.tacs_dvs\"),\n        ]\n        if self.conduction:\n            self.states_name = \"T_conduct\"\n            self.rhs_name = \"q_conduct\"\n        else:\n            self.states_name = \"u_struct\"\n            self.rhs_name = \"f_struct\"\n\n        # Identify tacs nodes corresponding to lagrange multipliers. These are nodes that are typically added in tacs\n        # whenever an element using a lagrange multiplier formulation is used (such as an RBE). It is important that\n        # these nodes not be included included in the aerostructural coupling procedure, as they a purely mathematical constructs.\n        # We'll use this information later to create a mask for filtering out these nodes in the coupling procedure.\n        nnodes = self.fea_assembler.getNumOwnedNodes()\n        nmult = self.fea_assembler.getNumOwnedMultiplierNodes()\n        vpn = self.fea_assembler.getVarsPerNode()\n        mult_ids = self.fea_assembler.getLocalMultiplierNodeIDs()\n        mask = np.zeros([nnodes, vpn], dtype=bool)\n        mask[:, :] = True\n        mask[mult_ids, :] = False\n\n        # Create an unmasking component to process the coupled force vector from the aerostructural\n        # load transfer component. This component takes the masked load vector (length = vpn * (nnodes - nmult))\n        # and creates an unmasked load vector (length = vpn * nnodes), by inserting 0.0 for the forces on\n        # the multiplier nodes\n        if self.coupled:\n            unmask_output = MaskedVariableDescription(\n                self.rhs_name, shape=nnodes * vpn, tags=[\"mphys_coupling\"]\n            )\n            unmask_input = MaskedVariableDescription(\n                self.rhs_name + \"_masked\",\n                shape=(nnodes - nmult) * vpn,\n                tags=[\"mphys_coupling\"],\n            )\n            unmasker = UnmaskedConverter(\n                input=unmask_input,\n                output=unmask_output,\n                mask=mask.flatten(),\n                distributed=True,\n            )\n            self.add_subsystem(\n                \"unmasker\",\n                unmasker,\n                promotes_inputs=[(self.rhs_name + \"_masked\", self.rhs_name)],\n            )\n\n        self.add_subsystem(\n            \"solver\",\n            TacsSolver(\n                fea_assembler=self.fea_assembler,\n                check_partials=self.check_partials,\n                coupled=self.coupled,\n                conduction=self.conduction,\n            ),\n            promotes_inputs=promotes_inputs,\n        )\n\n        # Create a masking component to process the full structural displacement vector (length = vpn * nnodes)\n        # and remove indices corresponding to multiplier nodes (length = vpn*(nnodes - nmult)).\n        mask_input = MaskedVariableDescription(\n            self.states_name, shape=nnodes * vpn, tags=[\"mphys_coupling\"]\n        )\n        mask_output = MaskedVariableDescription(\n            self.states_name + \"_masked\",\n            shape=(nnodes - nmult) * vpn,\n            tags=[\"mphys_coupling\"],\n        )\n        masker = MaskedConverter(\n            input=mask_input,\n            output=mask_output,\n            mask=mask.flatten(),\n            distributed=True,\n            init_output=0.0,\n        )\n        self.add_subsystem(\n            \"masker\",\n            masker,\n            promotes_outputs=[(self.states_name + \"_masked\", self.states_name)],\n        )\n\n        self.connect(\"solver.\" + self.states_name, \"masker.\" + self.states_name)\n\n        if self.coupled:\n            self.connect(\"unmasker.\" + self.rhs_name, \"solver.\" + self.rhs_name)\n\n        # Name problem based on scenario that's calling builder\n        scenario_name = self.options[\"scenario_name\"]\n        if scenario_name is None:\n            # Default structural problem\n            name = \"default\"\n        else:\n            name = scenario_name\n        sp = self.fea_assembler.createStaticProblem(name=name)\n\n        # Setup TACS problem with user-defined structural loads\n        problem_setup = self.options[\"problem_setup\"]\n        if problem_setup is not None:\n            new_problem = problem_setup(scenario_name, self.fea_assembler, sp)\n            # Check if the user provided back a new problem to overwrite the default\n            if new_problem is not None:\n                sp = new_problem\n\n        # Set problem\n        self.solver.set_sp(sp)\n\n        self.sp = sp\n\n    def write_bdf(self, file_name):\n        \"\"\"\n        Write optimized structure and loads to BDF file.\n        \"\"\"\n        self.fea_assembler.writeBDF(file_name, self.sp)",
  "def initialize(self):\n        self.options.declare(\"fea_assembler\", recordable=False)\n        self.options.declare(\"check_partials\")\n        self.options.declare(\"conduction\", default=False)\n        self.options.declare(\"coupled\", default=False)\n        self.options.declare(\"scenario_name\", default=None)\n        self.options.declare(\"problem_setup\", default=None)",
  "def setup(self):\n        self.fea_assembler = self.options[\"fea_assembler\"]\n        self.check_partials = self.options[\"check_partials\"]\n        self.coupled = self.options[\"coupled\"]\n        self.conduction = self.options[\"conduction\"]\n\n        # Promote state variables/rhs with physics-specific tag that MPhys expects\n        promotes_inputs = [\n            (\"x_struct0\", \"unmasker.x_struct0\"),\n            (\"tacs_dvs\", \"distributor.tacs_dvs\"),\n        ]\n        if self.conduction:\n            self.states_name = \"T_conduct\"\n            self.rhs_name = \"q_conduct\"\n        else:\n            self.states_name = \"u_struct\"\n            self.rhs_name = \"f_struct\"\n\n        # Identify tacs nodes corresponding to lagrange multipliers. These are nodes that are typically added in tacs\n        # whenever an element using a lagrange multiplier formulation is used (such as an RBE). It is important that\n        # these nodes not be included included in the aerostructural coupling procedure, as they a purely mathematical constructs.\n        # We'll use this information later to create a mask for filtering out these nodes in the coupling procedure.\n        nnodes = self.fea_assembler.getNumOwnedNodes()\n        nmult = self.fea_assembler.getNumOwnedMultiplierNodes()\n        vpn = self.fea_assembler.getVarsPerNode()\n        mult_ids = self.fea_assembler.getLocalMultiplierNodeIDs()\n        mask = np.zeros([nnodes, vpn], dtype=bool)\n        mask[:, :] = True\n        mask[mult_ids, :] = False\n\n        # Create an unmasking component to process the coupled force vector from the aerostructural\n        # load transfer component. This component takes the masked load vector (length = vpn * (nnodes - nmult))\n        # and creates an unmasked load vector (length = vpn * nnodes), by inserting 0.0 for the forces on\n        # the multiplier nodes\n        if self.coupled:\n            unmask_output = MaskedVariableDescription(\n                self.rhs_name, shape=nnodes * vpn, tags=[\"mphys_coupling\"]\n            )\n            unmask_input = MaskedVariableDescription(\n                self.rhs_name + \"_masked\",\n                shape=(nnodes - nmult) * vpn,\n                tags=[\"mphys_coupling\"],\n            )\n            unmasker = UnmaskedConverter(\n                input=unmask_input,\n                output=unmask_output,\n                mask=mask.flatten(),\n                distributed=True,\n            )\n            self.add_subsystem(\n                \"unmasker\",\n                unmasker,\n                promotes_inputs=[(self.rhs_name + \"_masked\", self.rhs_name)],\n            )\n\n        self.add_subsystem(\n            \"solver\",\n            TacsSolver(\n                fea_assembler=self.fea_assembler,\n                check_partials=self.check_partials,\n                coupled=self.coupled,\n                conduction=self.conduction,\n            ),\n            promotes_inputs=promotes_inputs,\n        )\n\n        # Create a masking component to process the full structural displacement vector (length = vpn * nnodes)\n        # and remove indices corresponding to multiplier nodes (length = vpn*(nnodes - nmult)).\n        mask_input = MaskedVariableDescription(\n            self.states_name, shape=nnodes * vpn, tags=[\"mphys_coupling\"]\n        )\n        mask_output = MaskedVariableDescription(\n            self.states_name + \"_masked\",\n            shape=(nnodes - nmult) * vpn,\n            tags=[\"mphys_coupling\"],\n        )\n        masker = MaskedConverter(\n            input=mask_input,\n            output=mask_output,\n            mask=mask.flatten(),\n            distributed=True,\n            init_output=0.0,\n        )\n        self.add_subsystem(\n            \"masker\",\n            masker,\n            promotes_outputs=[(self.states_name + \"_masked\", self.states_name)],\n        )\n\n        self.connect(\"solver.\" + self.states_name, \"masker.\" + self.states_name)\n\n        if self.coupled:\n            self.connect(\"unmasker.\" + self.rhs_name, \"solver.\" + self.rhs_name)\n\n        # Name problem based on scenario that's calling builder\n        scenario_name = self.options[\"scenario_name\"]\n        if scenario_name is None:\n            # Default structural problem\n            name = \"default\"\n        else:\n            name = scenario_name\n        sp = self.fea_assembler.createStaticProblem(name=name)\n\n        # Setup TACS problem with user-defined structural loads\n        problem_setup = self.options[\"problem_setup\"]\n        if problem_setup is not None:\n            new_problem = problem_setup(scenario_name, self.fea_assembler, sp)\n            # Check if the user provided back a new problem to overwrite the default\n            if new_problem is not None:\n                sp = new_problem\n\n        # Set problem\n        self.solver.set_sp(sp)\n\n        self.sp = sp",
  "def write_bdf(self, file_name):\n        \"\"\"\n        Write optimized structure and loads to BDF file.\n        \"\"\"\n        self.fea_assembler.writeBDF(file_name, self.sp)",
  "class TacsPrecouplingGroup(om.Group):\n    def initialize(self):\n        self.options.declare(\n            \"fea_assembler\",\n            default=None,\n            desc=\"the pytacs object itself\",\n            recordable=False,\n        )\n        self.options.declare(\n            \"initial_dv_vals\",\n            default=None,\n            desc=\"initial values for global design variable vector\",\n        )\n        self.options.declare(\n            \"separate_mass_dvs\",\n            default=False,\n            desc=\"Flag for whether or not to separate out point mass dvs using user-defined names\",\n        )\n\n    def setup(self):\n        # Promote state variables/rhs with physics-specific tag that MPhys expects\n        promotes_inputs = [\"*\"]\n\n        fea_assembler = self.options[\"fea_assembler\"]\n        initial_dv_vals = self.options[\"initial_dv_vals\"]\n        separate_mass_dvs = self.options[\"separate_mass_dvs\"]\n\n        self.add_subsystem(\n            \"distributor\",\n            TacsDVComp(\n                fea_assembler=fea_assembler,\n                initial_dv_vals=initial_dv_vals,\n                separate_mass_dvs=separate_mass_dvs,\n            ),\n            promotes_inputs=promotes_inputs,\n        )\n\n        nnodes = fea_assembler.getNumOwnedNodes()\n        nmult = fea_assembler.getNumOwnedMultiplierNodes()\n        unmask_output = MaskedVariableDescription(\n            \"x_struct0\", shape=nnodes * 3, tags=[\"mphys_coordinates\"]\n        )\n        unmask_input = MaskedVariableDescription(\n            \"x_struct0_masked\", shape=(nnodes - nmult) * 3, tags=[\"mphys_coordinates\"]\n        )\n        mult_ids = fea_assembler.getLocalMultiplierNodeIDs()\n        mask = np.zeros([nnodes, 3], dtype=bool)\n        mask[:, :] = True\n        mask[mult_ids, :] = False\n        vals = fea_assembler.getOrigNodes()\n        unmasker = UnmaskedConverter(\n            input=unmask_input,\n            output=unmask_output,\n            mask=mask.flatten(),\n            default_values=vals,\n            distributed=True,\n        )\n        self.add_subsystem(\n            \"unmasker\", unmasker, promotes_inputs=[(\"x_struct0_masked\", \"x_struct0\")]\n        )",
  "def initialize(self):\n        self.options.declare(\n            \"fea_assembler\",\n            default=None,\n            desc=\"the pytacs object itself\",\n            recordable=False,\n        )\n        self.options.declare(\n            \"initial_dv_vals\",\n            default=None,\n            desc=\"initial values for global design variable vector\",\n        )\n        self.options.declare(\n            \"separate_mass_dvs\",\n            default=False,\n            desc=\"Flag for whether or not to separate out point mass dvs using user-defined names\",\n        )",
  "def setup(self):\n        # Promote state variables/rhs with physics-specific tag that MPhys expects\n        promotes_inputs = [\"*\"]\n\n        fea_assembler = self.options[\"fea_assembler\"]\n        initial_dv_vals = self.options[\"initial_dv_vals\"]\n        separate_mass_dvs = self.options[\"separate_mass_dvs\"]\n\n        self.add_subsystem(\n            \"distributor\",\n            TacsDVComp(\n                fea_assembler=fea_assembler,\n                initial_dv_vals=initial_dv_vals,\n                separate_mass_dvs=separate_mass_dvs,\n            ),\n            promotes_inputs=promotes_inputs,\n        )\n\n        nnodes = fea_assembler.getNumOwnedNodes()\n        nmult = fea_assembler.getNumOwnedMultiplierNodes()\n        unmask_output = MaskedVariableDescription(\n            \"x_struct0\", shape=nnodes * 3, tags=[\"mphys_coordinates\"]\n        )\n        unmask_input = MaskedVariableDescription(\n            \"x_struct0_masked\", shape=(nnodes - nmult) * 3, tags=[\"mphys_coordinates\"]\n        )\n        mult_ids = fea_assembler.getLocalMultiplierNodeIDs()\n        mask = np.zeros([nnodes, 3], dtype=bool)\n        mask[:, :] = True\n        mask[mult_ids, :] = False\n        vals = fea_assembler.getOrigNodes()\n        unmasker = UnmaskedConverter(\n            input=unmask_input,\n            output=unmask_output,\n            mask=mask.flatten(),\n            default_values=vals,\n            distributed=True,\n        )\n        self.add_subsystem(\n            \"unmasker\", unmasker, promotes_inputs=[(\"x_struct0_masked\", \"x_struct0\")]\n        )",
  "class TacsMesh(om.IndepVarComp):\n    \"\"\"\n    Component to read the initial mesh coordinates with TACS\n    \"\"\"\n\n    def initialize(self):\n        self.options.declare(\n            \"fea_assembler\",\n            default=None,\n            desc=\"the pytacs object itself\",\n            recordable=False,\n        )\n\n    def setup(self):\n        fea_assembler = self.options[\"fea_assembler\"]\n        xpts = fea_assembler.getOrigNodes()\n        self.add_output(\n            \"x_struct0\",\n            distributed=True,\n            val=xpts,\n            shape=xpts.size,\n            desc=\"structural node coordinates\",\n            tags=[\"mphys_coordinates\"],\n        )",
  "class TacsMeshGroup(om.Group):\n    def initialize(self):\n        self.options.declare(\n            \"fea_assembler\",\n            default=None,\n            desc=\"the pytacs object itself\",\n            recordable=False,\n        )\n\n    def setup(self):\n        fea_assembler = self.options[\"fea_assembler\"]\n        self.add_subsystem(\"fea_mesh\", TacsMesh(fea_assembler=fea_assembler))\n\n        # Identify tacs nodes corresponding to lagrange multipliers. These are nodes that are typically added in tacs\n        # whenever an element using a lagrange multiplier formulation is used (such as an RBE). It is important that\n        # these nodes not be included included in the aerostructural coupling procedure, as they a purely mathematical constructs.\n        # We'll use this information later to create a mask for filtering out these nodes in the coupling procedure.\n        nnodes = fea_assembler.getNumOwnedNodes()\n        nmult = fea_assembler.getNumOwnedMultiplierNodes()\n        mask_input = MaskedVariableDescription(\n            \"x_struct0\", shape=nnodes * 3, tags=[\"mphys_coordinates\"]\n        )\n        mask_output = MaskedVariableDescription(\n            \"x_struct0_masked\", shape=(nnodes - nmult) * 3, tags=[\"mphys_coordinates\"]\n        )\n        mult_ids = fea_assembler.getLocalMultiplierNodeIDs()\n        mask = np.zeros([nnodes, 3], dtype=bool)\n        mask[:, :] = True\n        mask[mult_ids, :] = False\n        x_orig = fea_assembler.getOrigNodes()\n        x_masked = x_orig[mask.flatten()]\n        masker = MaskedConverter(\n            input=mask_input,\n            output=mask_output,\n            mask=mask.flatten(),\n            init_output=x_masked,\n            distributed=True,\n        )\n        self.add_subsystem(\n            \"masker\", masker, promotes_outputs=[(\"x_struct0_masked\", \"x_struct0\")]\n        )\n\n        self.connect(\"fea_mesh.x_struct0\", \"masker.x_struct0\")",
  "def initialize(self):\n        self.options.declare(\n            \"fea_assembler\",\n            default=None,\n            desc=\"the pytacs object itself\",\n            recordable=False,\n        )",
  "def setup(self):\n        fea_assembler = self.options[\"fea_assembler\"]\n        xpts = fea_assembler.getOrigNodes()\n        self.add_output(\n            \"x_struct0\",\n            distributed=True,\n            val=xpts,\n            shape=xpts.size,\n            desc=\"structural node coordinates\",\n            tags=[\"mphys_coordinates\"],\n        )",
  "def initialize(self):\n        self.options.declare(\n            \"fea_assembler\",\n            default=None,\n            desc=\"the pytacs object itself\",\n            recordable=False,\n        )",
  "def setup(self):\n        fea_assembler = self.options[\"fea_assembler\"]\n        self.add_subsystem(\"fea_mesh\", TacsMesh(fea_assembler=fea_assembler))\n\n        # Identify tacs nodes corresponding to lagrange multipliers. These are nodes that are typically added in tacs\n        # whenever an element using a lagrange multiplier formulation is used (such as an RBE). It is important that\n        # these nodes not be included included in the aerostructural coupling procedure, as they a purely mathematical constructs.\n        # We'll use this information later to create a mask for filtering out these nodes in the coupling procedure.\n        nnodes = fea_assembler.getNumOwnedNodes()\n        nmult = fea_assembler.getNumOwnedMultiplierNodes()\n        mask_input = MaskedVariableDescription(\n            \"x_struct0\", shape=nnodes * 3, tags=[\"mphys_coordinates\"]\n        )\n        mask_output = MaskedVariableDescription(\n            \"x_struct0_masked\", shape=(nnodes - nmult) * 3, tags=[\"mphys_coordinates\"]\n        )\n        mult_ids = fea_assembler.getLocalMultiplierNodeIDs()\n        mask = np.zeros([nnodes, 3], dtype=bool)\n        mask[:, :] = True\n        mask[mult_ids, :] = False\n        x_orig = fea_assembler.getOrigNodes()\n        x_masked = x_orig[mask.flatten()]\n        masker = MaskedConverter(\n            input=mask_input,\n            output=mask_output,\n            mask=mask.flatten(),\n            init_output=x_masked,\n            distributed=True,\n        )\n        self.add_subsystem(\n            \"masker\", masker, promotes_outputs=[(\"x_struct0_masked\", \"x_struct0\")]\n        )\n\n        self.connect(\"fea_mesh.x_struct0\", \"masker.x_struct0\")",
  "class TacsDVComp(om.ExplicitComponent):\n    \"\"\"\n    Component for splitting serial tacs design variable from top level\n    into distributed vector used by tacs.\n    \"\"\"\n\n    def initialize(self):\n        self.options.declare(\n            \"fea_assembler\",\n            default=None,\n            desc=\"the pytacs object itself\",\n            recordable=False,\n        )\n        self.options.declare(\n            \"initial_dv_vals\",\n            default=None,\n            desc=\"initial values for global design variable vector\",\n        )\n        self.options.declare(\n            \"separate_mass_dvs\",\n            default=False,\n            desc=\"Flag for whether or not to separate out point mass dvs using user-defined names\",\n        )\n\n    def setup(self):\n        self.fea_assembler = self.options[\"fea_assembler\"]\n        self.src_indices = self.get_dv_src_indices()\n        vals = self.options[\"initial_dv_vals\"]\n        ndv = self.fea_assembler.getNumDesignVars()\n        # Keep a list of dvs corresponding to regular struct dvs and mass dvs\n        self.struct_dvs = list(range(len(vals)))\n        self.mass_dvs = {}\n        # Check if user wants to separate out point mass dvs by user-defined names\n        if self.options[\"separate_mass_dvs\"]:\n            g_dvs = self.fea_assembler.getGlobalDVs()\n            for dv_name in g_dvs:\n                dv_dict = g_dvs[dv_name]\n                if dv_dict[\"isMassDV\"]:\n                    dv_num = dv_dict[\"num\"]\n                    mass_val = vals[dv_num]\n                    # Store mass dv num with user-defined dv name\n                    self.mass_dvs[f\"dv_mass_{dv_name}\"] = dv_num\n                    # Remove mass dv from struct list\n                    self.struct_dvs.remove(dv_num)\n                    # Add user-defined dv name as input\n                    self.add_input(\n                        f\"dv_mass_{dv_name}\",\n                        desc=\"serial mass design variable holding one mass design variable instance for tacs\",\n                        val=mass_val,\n                        distributed=False,\n                        tags=[\"mphys_input\"],\n                    )\n            # Remove all mass dvs from vals\n            vals = vals[self.struct_dvs]\n\n        self.add_input(\n            \"dv_struct\",\n            desc=\"serial vector holding all structural tacs design variable values\",\n            val=vals,\n            distributed=False,\n            tags=[\"mphys_input\"],\n        )\n        self.add_output(\n            \"tacs_dvs\",\n            desc=\"distributed vector holding tacs design variable values\\\n                        for this proc\",\n            shape=ndv,\n            distributed=True,\n            tags=[\"mphys_coupling\"],\n        )\n\n    def compute(self, inputs, outputs):\n        # Create serial array to holding all dv vals\n        tot_ndv = len(self.struct_dvs) + len(self.mass_dvs)\n        full_dv_array = np.zeros(tot_ndv, dtype=inputs[\"dv_struct\"].dtype)\n        # Place struct dvs in full array\n        full_dv_array[self.struct_dvs] = inputs[\"dv_struct\"]\n        # Place mass dvs (if they were defined) in full array\n        for dv_name in self.mass_dvs:\n            full_dv_array[self.mass_dvs[dv_name]] = inputs[dv_name]\n        # Slice full array with src_indices to get distributed dv array\n        outputs[\"tacs_dvs\"] = full_dv_array[self.src_indices]\n\n    def compute_jacvec_product(self, inputs, d_inputs, d_outputs, mode):\n        tot_ndv = len(self.struct_dvs) + len(self.mass_dvs)\n        dfull_dv_array = np.zeros(tot_ndv, dtype=inputs[\"dv_struct\"].dtype)\n        if mode == \"fwd\":\n            if \"tacs_dvs\" in d_outputs:\n                if \"dv_struct\" in d_inputs:\n                    dfull_dv_array[self.struct_dvs] += d_inputs[\"dv_struct\"]\n                for dv_name in self.mass_dvs:\n                    if dv_name in d_inputs:\n                        dfull_dv_array[self.mass_dvs[dv_name]] += d_inputs[dv_name]\n                d_outputs[\"tacs_dvs\"] += dfull_dv_array[self.src_indices]\n        else:  # mode == 'rev'\n            if \"tacs_dvs\" in d_outputs:\n                dfull_dv_array[self.src_indices] += d_outputs[\"tacs_dvs\"]\n                if \"dv_struct\" in d_inputs:\n                    d_inputs[\"dv_struct\"] += self.comm.allreduce(\n                        dfull_dv_array[self.struct_dvs]\n                    )\n                for dv_name in self.mass_dvs:\n                    if dv_name in d_inputs:\n                        d_inputs[dv_name] += self.comm.allreduce(\n                            dfull_dv_array[self.mass_dvs[dv_name]]\n                        )\n\n    def get_dv_src_indices(self):\n        \"\"\"\n        Method to get src_indices on each processor\n        for tacs distributed design variable vec\n        \"\"\"\n        if MPI is not None and self.comm.size > 1:\n            local_ndvs = self.fea_assembler.getNumDesignVars()\n            all_proc_ndvs = self.comm.gather(local_ndvs, root=0)\n            all_proc_indices = []\n            if self.comm.rank == 0:\n                tot_ndvs = 0\n                for proc_i in range(self.comm.size):\n                    local_ndvs = all_proc_ndvs[proc_i]\n                    proc_indices = np.arange(tot_ndvs, tot_ndvs + local_ndvs)\n                    all_proc_indices.append(proc_indices)\n                    tot_ndvs += local_ndvs\n            local_dv_indices = self.comm.scatter(all_proc_indices, root=0)\n            return local_dv_indices\n        else:\n            ndvs = len(self.options[\"initial_dv_vals\"])\n            all_dv_indices = np.arange(ndvs)\n            return all_dv_indices",
  "def initialize(self):\n        self.options.declare(\n            \"fea_assembler\",\n            default=None,\n            desc=\"the pytacs object itself\",\n            recordable=False,\n        )\n        self.options.declare(\n            \"initial_dv_vals\",\n            default=None,\n            desc=\"initial values for global design variable vector\",\n        )\n        self.options.declare(\n            \"separate_mass_dvs\",\n            default=False,\n            desc=\"Flag for whether or not to separate out point mass dvs using user-defined names\",\n        )",
  "def setup(self):\n        self.fea_assembler = self.options[\"fea_assembler\"]\n        self.src_indices = self.get_dv_src_indices()\n        vals = self.options[\"initial_dv_vals\"]\n        ndv = self.fea_assembler.getNumDesignVars()\n        # Keep a list of dvs corresponding to regular struct dvs and mass dvs\n        self.struct_dvs = list(range(len(vals)))\n        self.mass_dvs = {}\n        # Check if user wants to separate out point mass dvs by user-defined names\n        if self.options[\"separate_mass_dvs\"]:\n            g_dvs = self.fea_assembler.getGlobalDVs()\n            for dv_name in g_dvs:\n                dv_dict = g_dvs[dv_name]\n                if dv_dict[\"isMassDV\"]:\n                    dv_num = dv_dict[\"num\"]\n                    mass_val = vals[dv_num]\n                    # Store mass dv num with user-defined dv name\n                    self.mass_dvs[f\"dv_mass_{dv_name}\"] = dv_num\n                    # Remove mass dv from struct list\n                    self.struct_dvs.remove(dv_num)\n                    # Add user-defined dv name as input\n                    self.add_input(\n                        f\"dv_mass_{dv_name}\",\n                        desc=\"serial mass design variable holding one mass design variable instance for tacs\",\n                        val=mass_val,\n                        distributed=False,\n                        tags=[\"mphys_input\"],\n                    )\n            # Remove all mass dvs from vals\n            vals = vals[self.struct_dvs]\n\n        self.add_input(\n            \"dv_struct\",\n            desc=\"serial vector holding all structural tacs design variable values\",\n            val=vals,\n            distributed=False,\n            tags=[\"mphys_input\"],\n        )\n        self.add_output(\n            \"tacs_dvs\",\n            desc=\"distributed vector holding tacs design variable values\\\n                        for this proc\",\n            shape=ndv,\n            distributed=True,\n            tags=[\"mphys_coupling\"],\n        )",
  "def compute(self, inputs, outputs):\n        # Create serial array to holding all dv vals\n        tot_ndv = len(self.struct_dvs) + len(self.mass_dvs)\n        full_dv_array = np.zeros(tot_ndv, dtype=inputs[\"dv_struct\"].dtype)\n        # Place struct dvs in full array\n        full_dv_array[self.struct_dvs] = inputs[\"dv_struct\"]\n        # Place mass dvs (if they were defined) in full array\n        for dv_name in self.mass_dvs:\n            full_dv_array[self.mass_dvs[dv_name]] = inputs[dv_name]\n        # Slice full array with src_indices to get distributed dv array\n        outputs[\"tacs_dvs\"] = full_dv_array[self.src_indices]",
  "def compute_jacvec_product(self, inputs, d_inputs, d_outputs, mode):\n        tot_ndv = len(self.struct_dvs) + len(self.mass_dvs)\n        dfull_dv_array = np.zeros(tot_ndv, dtype=inputs[\"dv_struct\"].dtype)\n        if mode == \"fwd\":\n            if \"tacs_dvs\" in d_outputs:\n                if \"dv_struct\" in d_inputs:\n                    dfull_dv_array[self.struct_dvs] += d_inputs[\"dv_struct\"]\n                for dv_name in self.mass_dvs:\n                    if dv_name in d_inputs:\n                        dfull_dv_array[self.mass_dvs[dv_name]] += d_inputs[dv_name]\n                d_outputs[\"tacs_dvs\"] += dfull_dv_array[self.src_indices]\n        else:  # mode == 'rev'\n            if \"tacs_dvs\" in d_outputs:\n                dfull_dv_array[self.src_indices] += d_outputs[\"tacs_dvs\"]\n                if \"dv_struct\" in d_inputs:\n                    d_inputs[\"dv_struct\"] += self.comm.allreduce(\n                        dfull_dv_array[self.struct_dvs]\n                    )\n                for dv_name in self.mass_dvs:\n                    if dv_name in d_inputs:\n                        d_inputs[dv_name] += self.comm.allreduce(\n                            dfull_dv_array[self.mass_dvs[dv_name]]\n                        )",
  "def get_dv_src_indices(self):\n        \"\"\"\n        Method to get src_indices on each processor\n        for tacs distributed design variable vec\n        \"\"\"\n        if MPI is not None and self.comm.size > 1:\n            local_ndvs = self.fea_assembler.getNumDesignVars()\n            all_proc_ndvs = self.comm.gather(local_ndvs, root=0)\n            all_proc_indices = []\n            if self.comm.rank == 0:\n                tot_ndvs = 0\n                for proc_i in range(self.comm.size):\n                    local_ndvs = all_proc_ndvs[proc_i]\n                    proc_indices = np.arange(tot_ndvs, tot_ndvs + local_ndvs)\n                    all_proc_indices.append(proc_indices)\n                    tot_ndvs += local_ndvs\n            local_dv_indices = self.comm.scatter(all_proc_indices, root=0)\n            return local_dv_indices\n        else:\n            ndvs = len(self.options[\"initial_dv_vals\"])\n            all_dv_indices = np.arange(ndvs)\n            return all_dv_indices",
  "class ConstraintComponent(om.ExplicitComponent):\n    \"\"\"\n    Component to compute TACS constraint functions\n    \"\"\"\n\n    def initialize(self):\n        self.options.declare(\"fea_assembler\", recordable=False)\n        self.options.declare(\"constraint_object\")\n\n        self.fea_assembler = None\n        self.constr = None\n\n        self.old_dvs = None\n        self.old_xs = None\n\n    def setup(self):\n        self.fea_assembler = self.options[\"fea_assembler\"]\n        self.constr = self.options[\"constraint_object\"]\n\n        # TACS part of setup\n        local_ndvs = self.fea_assembler.getNumDesignVars()\n\n        # OpenMDAO part of setup\n        self.add_input(\n            \"tacs_dvs\",\n            distributed=True,\n            shape=local_ndvs,\n            desc=\"tacs design variables\",\n            tags=[\"mphys_coupling\"],\n        )\n        self.add_input(\n            \"x_struct0\",\n            distributed=True,\n            shape_by_conn=True,\n            desc=\"structural node coordinates\",\n            tags=[\"mphys_coordinates\"],\n        )\n\n        # Add eval funcs as outputs\n        con_names = self.constr.getConstraintKeys()\n        con_sizes = {}\n        self.constr.getConstraintSizes(con_sizes)\n        for con_name in con_names:\n            con_key = f\"{self.constr.name}_{con_name}\"\n            ncon = con_sizes[con_key]\n            self.add_output(\n                con_name, distributed=False, shape=ncon, tags=[\"mphys_result\"]\n            )\n\n    def _update_internal(self, inputs):\n        dvsNeedUpdate, xsNeedUpdate = self._need_update(inputs)\n        if dvsNeedUpdate:\n            self.constr.setDesignVars(inputs[\"tacs_dvs\"])\n        if xsNeedUpdate:\n            self.constr.setNodes(inputs[\"x_struct0\"])\n\n    def _need_update(self, inputs):\n        \"\"\"Checks whether the design variables or coordinates being passed\n        in by OpenMDAO are different from those currently stored in TACS\n\n        Parameters\n        ----------\n        inputs : OpenMDAO input vector\n            _description_\n\n        Returns\n        -------\n        (bool, bool)\n            Whether the design variables or coordinates need to be updated\n            respectively\n        \"\"\"\n        dvsNeedUpdate = False\n        xsNeedUpdate = False\n\n        dvs = inputs[\"tacs_dvs\"]\n        xs = inputs[\"x_struct0\"]\n\n        if self.old_dvs is None:\n            self.old_dvs = inputs[\"tacs_dvs\"].copy()\n            dvsNeedUpdate = True\n\n        elif len(dvs) > 0:\n            if max(np.abs(dvs - self.old_dvs)) > 0.0:  # 1e-7:\n                self.old_dvs = inputs[\"tacs_dvs\"].copy()\n                dvsNeedUpdate = True\n\n        if self.old_xs is None:\n            self.old_xs = inputs[\"x_struct0\"].copy()\n            xsNeedUpdate = True\n\n        elif len(xs) > 0:\n            if max(np.abs(xs - self.old_xs)) > 0.0:  # 1e-7:\n                self.old_xs = inputs[\"x_struct0\"].copy()\n                xsNeedUpdate = True\n\n        tmp1 = dvsNeedUpdate\n        tmp2 = xsNeedUpdate\n        # Perform all reduce to check if any other procs came back True\n        dvsNeedUpdate = self.comm.allreduce(tmp1)\n        xsNeedUpdate = self.comm.allreduce(tmp2)\n        return dvsNeedUpdate, xsNeedUpdate\n\n    def compute(self, inputs, outputs):\n        self._update_internal(inputs)\n\n        # Evaluate functions\n        funcs = {}\n        self.constr.evalConstraints(funcs, evalCons=outputs.keys())\n        for con_name in outputs:\n            # Add struct problem name from key\n            key = self.constr.name + \"_\" + con_name\n            outputs[con_name] = funcs[key]\n\n    def compute_jacvec_product(self, inputs, d_inputs, d_outputs, mode):\n        # always update internal because same tacs object could be used by multiple scenarios\n        # and we need to load this scenario's state back into TACS before doing derivatives\n        self._update_internal(inputs)\n        funcs_sens = {}\n        self.constr.evalConstraintsSens(funcs_sens)\n\n        for out_name in d_outputs:\n            output_key = f\"{self.constr.name}_{out_name}\"\n            Jdv = funcs_sens[output_key][\"struct\"].astype(float)\n            Jxpt = funcs_sens[output_key][\"Xpts\"].astype(float)\n\n            if mode == \"fwd\":\n                if \"tacs_dvs\" in d_inputs:\n                    out = Jdv.dot(d_inputs[\"tacs_dvs\"])\n                    d_outputs[out_name] += self.comm.allreduce(out)\n\n                if \"x_struct0\" in d_inputs:\n                    out = Jxpt.dot(d_inputs[\"x_struct0\"])\n                    d_outputs[out_name] += self.comm.allreduce(out)\n\n            elif mode == \"rev\":\n                if \"tacs_dvs\" in d_inputs:\n                    d_inputs[\"tacs_dvs\"] += Jdv.T.dot(d_outputs[out_name])\n\n                if \"x_struct0\" in d_inputs:\n                    d_inputs[\"x_struct0\"] += Jxpt.T.dot(d_outputs[out_name])",
  "def initialize(self):\n        self.options.declare(\"fea_assembler\", recordable=False)\n        self.options.declare(\"constraint_object\")\n\n        self.fea_assembler = None\n        self.constr = None\n\n        self.old_dvs = None\n        self.old_xs = None",
  "def setup(self):\n        self.fea_assembler = self.options[\"fea_assembler\"]\n        self.constr = self.options[\"constraint_object\"]\n\n        # TACS part of setup\n        local_ndvs = self.fea_assembler.getNumDesignVars()\n\n        # OpenMDAO part of setup\n        self.add_input(\n            \"tacs_dvs\",\n            distributed=True,\n            shape=local_ndvs,\n            desc=\"tacs design variables\",\n            tags=[\"mphys_coupling\"],\n        )\n        self.add_input(\n            \"x_struct0\",\n            distributed=True,\n            shape_by_conn=True,\n            desc=\"structural node coordinates\",\n            tags=[\"mphys_coordinates\"],\n        )\n\n        # Add eval funcs as outputs\n        con_names = self.constr.getConstraintKeys()\n        con_sizes = {}\n        self.constr.getConstraintSizes(con_sizes)\n        for con_name in con_names:\n            con_key = f\"{self.constr.name}_{con_name}\"\n            ncon = con_sizes[con_key]\n            self.add_output(\n                con_name, distributed=False, shape=ncon, tags=[\"mphys_result\"]\n            )",
  "def _update_internal(self, inputs):\n        dvsNeedUpdate, xsNeedUpdate = self._need_update(inputs)\n        if dvsNeedUpdate:\n            self.constr.setDesignVars(inputs[\"tacs_dvs\"])\n        if xsNeedUpdate:\n            self.constr.setNodes(inputs[\"x_struct0\"])",
  "def _need_update(self, inputs):\n        \"\"\"Checks whether the design variables or coordinates being passed\n        in by OpenMDAO are different from those currently stored in TACS\n\n        Parameters\n        ----------\n        inputs : OpenMDAO input vector\n            _description_\n\n        Returns\n        -------\n        (bool, bool)\n            Whether the design variables or coordinates need to be updated\n            respectively\n        \"\"\"\n        dvsNeedUpdate = False\n        xsNeedUpdate = False\n\n        dvs = inputs[\"tacs_dvs\"]\n        xs = inputs[\"x_struct0\"]\n\n        if self.old_dvs is None:\n            self.old_dvs = inputs[\"tacs_dvs\"].copy()\n            dvsNeedUpdate = True\n\n        elif len(dvs) > 0:\n            if max(np.abs(dvs - self.old_dvs)) > 0.0:  # 1e-7:\n                self.old_dvs = inputs[\"tacs_dvs\"].copy()\n                dvsNeedUpdate = True\n\n        if self.old_xs is None:\n            self.old_xs = inputs[\"x_struct0\"].copy()\n            xsNeedUpdate = True\n\n        elif len(xs) > 0:\n            if max(np.abs(xs - self.old_xs)) > 0.0:  # 1e-7:\n                self.old_xs = inputs[\"x_struct0\"].copy()\n                xsNeedUpdate = True\n\n        tmp1 = dvsNeedUpdate\n        tmp2 = xsNeedUpdate\n        # Perform all reduce to check if any other procs came back True\n        dvsNeedUpdate = self.comm.allreduce(tmp1)\n        xsNeedUpdate = self.comm.allreduce(tmp2)\n        return dvsNeedUpdate, xsNeedUpdate",
  "def compute(self, inputs, outputs):\n        self._update_internal(inputs)\n\n        # Evaluate functions\n        funcs = {}\n        self.constr.evalConstraints(funcs, evalCons=outputs.keys())\n        for con_name in outputs:\n            # Add struct problem name from key\n            key = self.constr.name + \"_\" + con_name\n            outputs[con_name] = funcs[key]",
  "def compute_jacvec_product(self, inputs, d_inputs, d_outputs, mode):\n        # always update internal because same tacs object could be used by multiple scenarios\n        # and we need to load this scenario's state back into TACS before doing derivatives\n        self._update_internal(inputs)\n        funcs_sens = {}\n        self.constr.evalConstraintsSens(funcs_sens)\n\n        for out_name in d_outputs:\n            output_key = f\"{self.constr.name}_{out_name}\"\n            Jdv = funcs_sens[output_key][\"struct\"].astype(float)\n            Jxpt = funcs_sens[output_key][\"Xpts\"].astype(float)\n\n            if mode == \"fwd\":\n                if \"tacs_dvs\" in d_inputs:\n                    out = Jdv.dot(d_inputs[\"tacs_dvs\"])\n                    d_outputs[out_name] += self.comm.allreduce(out)\n\n                if \"x_struct0\" in d_inputs:\n                    out = Jxpt.dot(d_inputs[\"x_struct0\"])\n                    d_outputs[out_name] += self.comm.allreduce(out)\n\n            elif mode == \"rev\":\n                if \"tacs_dvs\" in d_inputs:\n                    d_inputs[\"tacs_dvs\"] += Jdv.T.dot(d_outputs[out_name])\n\n                if \"x_struct0\" in d_inputs:\n                    d_inputs[\"x_struct0\"] += Jxpt.T.dot(d_outputs[out_name])",
  "class TacsBuckling(om.ExplicitComponent):\n    \"\"\"\n    Component to compute non-mass TACS functions\n    \"\"\"\n\n    def initialize(self):\n        self.options.declare(\"fea_assembler\", recordable=False)\n        self.options.declare(\"conduction\", default=False)\n        self.options.declare(\"check_partials\")\n        self.options.declare(\"write_solution\")\n\n        self.fea_assembler = None\n\n        self.check_partials = False\n\n    def setup(self):\n        self.fea_assembler = self.options[\"fea_assembler\"]\n        self.check_partials = self.options[\"check_partials\"]\n        self.write_solution = self.options[\"write_solution\"]\n        self.conduction = self.options[\"conduction\"]\n        self.solution_counter = 0\n\n        if self.conduction:\n            self.states_name = \"T_conduct\"\n        else:\n            self.states_name = \"u_struct\"\n\n        # TACS part of setup\n        local_ndvs = self.fea_assembler.getNumDesignVars()\n\n        # OpenMDAO part of setup\n        self.add_input(\n            \"tacs_dvs\",\n            distributed=True,\n            shape=local_ndvs,\n            desc=\"tacs design variables\",\n            tags=[\"mphys_coupling\"],\n        )\n        self.add_input(\n            \"x_struct0\",\n            distributed=True,\n            shape_by_conn=True,\n            desc=\"structural node coordinates\",\n            tags=[\"mphys_coordinates\"],\n        )\n        self.add_input(\n            self.states_name,\n            distributed=True,\n            shape_by_conn=True,\n            desc=\"structural state vector\",\n            tags=[\"mphys_coupling\"],\n        )\n\n    def mphys_set_bp(self, bp):\n        # this is the external function to set the bp to this component\n        self.bp = bp\n\n        # Add eval funcs as outputs\n        for func_name in self.bp.functionList:\n            func_name = func_name.replace(\".\", \"_\")\n            self.add_output(\n                func_name, distributed=False, shape=1, tags=[\"mphys_result\"]\n            )\n\n    def _update_internal(self, inputs):\n        self.bp.setDesignVars(inputs[\"tacs_dvs\"])\n        self.bp.setNodes(inputs[\"x_struct0\"])\n\n    def compute(self, inputs, outputs):\n        self._update_internal(inputs)\n\n        # Solve\n        self.bp.solve(u0=inputs[self.states_name])\n\n        # Evaluate functions\n        funcs = {}\n        self.bp.evalFunctions(funcs, evalFuncs=outputs.keys())\n        for out_name in outputs:\n            eig_name = out_name.replace(\"_\", \".\")\n            func_key = f\"{self.bp.name}_{eig_name}\"\n            self.bp.evalFunctions(funcs, evalFuncs=[eig_name])\n            outputs[out_name] = funcs[func_key]\n\n        if self.write_solution:\n            # write the solution files.\n            self.bp.writeSolution(number=self.solution_counter)\n            self.solution_counter += 1\n\n    def compute_jacvec_product(self, inputs, d_inputs, d_outputs, mode):\n        if mode == \"fwd\":\n            if not self.check_partials:\n                raise ValueError(\"TACS forward mode requested but not implemented\")\n        if mode == \"rev\":\n            # always update internal because same tacs object could be used by multiple scenarios\n            # and we need to load this scenario's state back into TACS before doing derivatives\n            self._update_internal(inputs)\n\n            for func_name in d_outputs:\n                d_func = d_outputs[func_name]\n                eig_name = func_name.replace(\"_\", \".\")\n                mode_i = self.bp.functionList[eig_name]\n\n                if d_func[0] != 0.0:\n                    if \"tacs_dvs\" in d_inputs:\n                        self.bp.addDVSens(\n                            [mode_i], [d_inputs[\"tacs_dvs\"]], scale=d_func\n                        )\n\n                    if \"x_struct0\" in d_inputs:\n                        self.bp.addXptSens(\n                            [mode_i], [d_inputs[\"x_struct0\"]], scale=d_func\n                        )\n\n                    if self.states_name in d_inputs:\n                        sv_sens = np.zeros_like(d_inputs[self.states_name])\n                        self.bp.evalSVSens([mode_i], [sv_sens])\n                        d_inputs[self.states_name][:] += sv_sens * d_func",
  "def initialize(self):\n        self.options.declare(\"fea_assembler\", recordable=False)\n        self.options.declare(\"conduction\", default=False)\n        self.options.declare(\"check_partials\")\n        self.options.declare(\"write_solution\")\n\n        self.fea_assembler = None\n\n        self.check_partials = False",
  "def setup(self):\n        self.fea_assembler = self.options[\"fea_assembler\"]\n        self.check_partials = self.options[\"check_partials\"]\n        self.write_solution = self.options[\"write_solution\"]\n        self.conduction = self.options[\"conduction\"]\n        self.solution_counter = 0\n\n        if self.conduction:\n            self.states_name = \"T_conduct\"\n        else:\n            self.states_name = \"u_struct\"\n\n        # TACS part of setup\n        local_ndvs = self.fea_assembler.getNumDesignVars()\n\n        # OpenMDAO part of setup\n        self.add_input(\n            \"tacs_dvs\",\n            distributed=True,\n            shape=local_ndvs,\n            desc=\"tacs design variables\",\n            tags=[\"mphys_coupling\"],\n        )\n        self.add_input(\n            \"x_struct0\",\n            distributed=True,\n            shape_by_conn=True,\n            desc=\"structural node coordinates\",\n            tags=[\"mphys_coordinates\"],\n        )\n        self.add_input(\n            self.states_name,\n            distributed=True,\n            shape_by_conn=True,\n            desc=\"structural state vector\",\n            tags=[\"mphys_coupling\"],\n        )",
  "def mphys_set_bp(self, bp):\n        # this is the external function to set the bp to this component\n        self.bp = bp\n\n        # Add eval funcs as outputs\n        for func_name in self.bp.functionList:\n            func_name = func_name.replace(\".\", \"_\")\n            self.add_output(\n                func_name, distributed=False, shape=1, tags=[\"mphys_result\"]\n            )",
  "def _update_internal(self, inputs):\n        self.bp.setDesignVars(inputs[\"tacs_dvs\"])\n        self.bp.setNodes(inputs[\"x_struct0\"])",
  "def compute(self, inputs, outputs):\n        self._update_internal(inputs)\n\n        # Solve\n        self.bp.solve(u0=inputs[self.states_name])\n\n        # Evaluate functions\n        funcs = {}\n        self.bp.evalFunctions(funcs, evalFuncs=outputs.keys())\n        for out_name in outputs:\n            eig_name = out_name.replace(\"_\", \".\")\n            func_key = f\"{self.bp.name}_{eig_name}\"\n            self.bp.evalFunctions(funcs, evalFuncs=[eig_name])\n            outputs[out_name] = funcs[func_key]\n\n        if self.write_solution:\n            # write the solution files.\n            self.bp.writeSolution(number=self.solution_counter)\n            self.solution_counter += 1",
  "def compute_jacvec_product(self, inputs, d_inputs, d_outputs, mode):\n        if mode == \"fwd\":\n            if not self.check_partials:\n                raise ValueError(\"TACS forward mode requested but not implemented\")\n        if mode == \"rev\":\n            # always update internal because same tacs object could be used by multiple scenarios\n            # and we need to load this scenario's state back into TACS before doing derivatives\n            self._update_internal(inputs)\n\n            for func_name in d_outputs:\n                d_func = d_outputs[func_name]\n                eig_name = func_name.replace(\"_\", \".\")\n                mode_i = self.bp.functionList[eig_name]\n\n                if d_func[0] != 0.0:\n                    if \"tacs_dvs\" in d_inputs:\n                        self.bp.addDVSens(\n                            [mode_i], [d_inputs[\"tacs_dvs\"]], scale=d_func\n                        )\n\n                    if \"x_struct0\" in d_inputs:\n                        self.bp.addXptSens(\n                            [mode_i], [d_inputs[\"x_struct0\"]], scale=d_func\n                        )\n\n                    if self.states_name in d_inputs:\n                        sv_sens = np.zeros_like(d_inputs[self.states_name])\n                        self.bp.evalSVSens([mode_i], [sv_sens])\n                        d_inputs[self.states_name][:] += sv_sens * d_func",
  "class TacsBuilder(Builder):\n    def __init__(\n        self,\n        options,\n        check_partials=False,\n        conduction=False,\n        coupled=True,\n        write_solution=True,\n        separate_mass_dvs=False,\n    ):\n        self.options = copy.deepcopy(options)\n        self.check_partials = check_partials\n        # Flag to switch to tacs conduction solver (False->structural)\n        self.conduction = conduction\n        # Flag to turn on f5 file writer\n        self.write_solution = write_solution\n        # Flag to turn on coupling variables\n        self.coupled = coupled\n        # Flag to separate point mass dvs from struct dvs in openmdao input array\n        self.separate_mass_dvs = separate_mass_dvs\n\n    def initialize(self, comm):\n        pytacs_options = copy.deepcopy(self.options)\n        bdf_file = pytacs_options.pop(\"mesh_file\")\n\n        # Load optional user-defined callback function for setting up tacs elements\n        if \"assembler_setup\" in pytacs_options:\n            assembler_setup = pytacs_options.pop(\"assembler_setup\")\n        else:\n            assembler_setup = None\n\n        # Load optional user-defined callback function for setting up tacs elements\n        if \"element_callback\" in pytacs_options:\n            element_callback = pytacs_options.pop(\"element_callback\")\n        else:\n            element_callback = None\n\n        # Load optional user-defined callback function for setting up tacs elements\n        if \"problem_setup\" in pytacs_options:\n            self.problem_setup = pytacs_options.pop(\"problem_setup\")\n        else:\n            self.problem_setup = None\n\n        # Load optional user-defined callback function for setting up constraints\n        if \"constraint_setup\" in pytacs_options:\n            self.constraint_setup = pytacs_options.pop(\"constraint_setup\")\n        else:\n            self.constraint_setup = None\n\n        # Load optional user-defined callback function for setting up buckling problem\n        if \"buckling_setup\" in pytacs_options:\n            self.buckling_setup = pytacs_options.pop(\"buckling_setup\")\n        else:\n            self.buckling_setup = None\n\n        # Create pytacs instance\n        self.fea_assembler = pyTACS(bdf_file, options=pytacs_options, comm=comm)\n        self.comm = comm\n\n        # Do any pre-initialize setup requested by user\n        if assembler_setup is not None:\n            assembler_setup(self.fea_assembler)\n\n        # Set up elements and TACS assembler\n        self.fea_assembler.initialize(element_callback)\n\n    def get_coupling_group_subsystem(self, scenario_name=None):\n        return TacsCouplingGroup(\n            fea_assembler=self.fea_assembler,\n            conduction=self.conduction,\n            check_partials=self.check_partials,\n            coupled=self.coupled,\n            scenario_name=scenario_name,\n            problem_setup=self.problem_setup,\n        )\n\n    def get_mesh_coordinate_subsystem(self, scenario_name=None):\n        return TacsMeshGroup(fea_assembler=self.fea_assembler)\n\n    def get_pre_coupling_subsystem(self, scenario_name=None):\n        initial_dvs = self.get_initial_dvs()\n        return TacsPrecouplingGroup(\n            fea_assembler=self.fea_assembler,\n            initial_dv_vals=initial_dvs,\n            separate_mass_dvs=self.separate_mass_dvs,\n        )\n\n    def get_post_coupling_subsystem(self, scenario_name=None):\n        return TacsPostcouplingGroup(\n            fea_assembler=self.fea_assembler,\n            check_partials=self.check_partials,\n            conduction=self.conduction,\n            write_solution=self.write_solution,\n            scenario_name=scenario_name,\n            problem_setup=self.problem_setup,\n            constraint_setup=self.constraint_setup,\n            buckling_setup=self.buckling_setup,\n        )\n\n    def get_ndof(self):\n        return self.fea_assembler.getVarsPerNode()\n\n    def get_number_of_nodes(self):\n        \"\"\"\n        Get the number of nodes on this processor,\n        not including lagrange multiplier nodes\n        \"\"\"\n        nnodes = self.fea_assembler.getNumOwnedNodes()\n        nmult = self.fea_assembler.getNumOwnedMultiplierNodes()\n        return nnodes - nmult\n\n    def get_initial_dvs(self):\n        \"\"\"\n        Get an array holding all dvs values that have been added to TACS\n        \"\"\"\n        local_dvs = self.fea_assembler.getOrigDesignVars()\n        all_local_dvs = self.comm.allgather(local_dvs)\n        global_dvs = np.concatenate(all_local_dvs)\n        return global_dvs.astype(float)\n\n    def get_dv_bounds(self):\n        \"\"\"Get arrays containing the lower and upper bounds for the design variables,\n        in the form needed by OpenMDAO's `add_design_variable` method.\n\n        Returns\n        -------\n        list of ndarray\n            lower and upper bounds for the design variables\n        \"\"\"\n        local_lb, local_ub = self.fea_assembler.getDesignVarRange()\n        all_lb = self.comm.allgather(local_lb)\n        global_lbs = np.concatenate(all_lb)\n        all_ub = self.comm.allgather(local_ub)\n        global_ubs = np.concatenate(all_ub)\n        return global_lbs.astype(float), global_ubs.astype(float)\n\n    def get_dv_scalers(self):\n        \"\"\"Get an array containing the scaling factors for the design\n        variables, in the form needed by OpenMDAO's `add_design_variable`\n        method.\n\n        Returns\n        -------\n        array\n            Scaling values\n        \"\"\"\n        return np.array(self.fea_assembler.scaleList)\n\n    def get_ndv(self):\n        \"\"\"\n        Get total number of structural design variables across all procs\n        \"\"\"\n        return self.fea_assembler.getTotalNumDesignVars()\n\n    def get_solver(self):\n        # this method is only used by the RLT transfer scheme\n        return self.fea_assembler.assembler\n\n    def get_fea_assembler(self):\n        \"\"\"\n        Returns underlying pytacs object.\n        \"\"\"\n        return self.fea_assembler\n\n    def get_tagged_indices(self, tags):\n        \"\"\"\n        Method that returns grid IDs for a list of body/boundary tags.\n\n        Parameters\n        ----------\n        tags : list[str]\n\n        Returns\n        -------\n        grid_ids : list[int]\n            list of grid IDs that correspond to given body/boundary tags\n        \"\"\"\n        # Select all compIDs\n        if tags == -1 or tags == [-1]:\n            nnodes = self.fea_assembler.getNumOwnedNodes()\n            # Select all node IDs\n            masked_local_nodes = np.arange(nnodes)\n\n        # Get the compIDs associated with tags\n        else:\n            tagged_comps = self.fea_assembler.selectCompIDs(include=tags)\n            # Select local node IDs for tags\n            masked_local_nodes = self.fea_assembler.getLocalNodeIDsForComps(tagged_comps)\n\n        # Select local node IDs and multiplier node IDs\n        local_mnodes = self.fea_assembler.getLocalMultiplierNodeIDs()\n\n        # Loop through the multiplier nodes and remove them\n        masked_local_nodes = list(masked_local_nodes)\n        for mult_node in local_mnodes:\n            if mult_node in masked_local_nodes:\n                masked_local_nodes.remove(mult_node)\n        masked_local_nodes = np.array(masked_local_nodes)\n\n        # Loop through the multiplier nodes and offset for the multiplier nodes we removed\n        for mult_node in reversed(local_mnodes):\n            masked_local_nodes[masked_local_nodes > mult_node] -= 1\n\n        return list(masked_local_nodes)",
  "def __init__(\n        self,\n        options,\n        check_partials=False,\n        conduction=False,\n        coupled=True,\n        write_solution=True,\n        separate_mass_dvs=False,\n    ):\n        self.options = copy.deepcopy(options)\n        self.check_partials = check_partials\n        # Flag to switch to tacs conduction solver (False->structural)\n        self.conduction = conduction\n        # Flag to turn on f5 file writer\n        self.write_solution = write_solution\n        # Flag to turn on coupling variables\n        self.coupled = coupled\n        # Flag to separate point mass dvs from struct dvs in openmdao input array\n        self.separate_mass_dvs = separate_mass_dvs",
  "def initialize(self, comm):\n        pytacs_options = copy.deepcopy(self.options)\n        bdf_file = pytacs_options.pop(\"mesh_file\")\n\n        # Load optional user-defined callback function for setting up tacs elements\n        if \"assembler_setup\" in pytacs_options:\n            assembler_setup = pytacs_options.pop(\"assembler_setup\")\n        else:\n            assembler_setup = None\n\n        # Load optional user-defined callback function for setting up tacs elements\n        if \"element_callback\" in pytacs_options:\n            element_callback = pytacs_options.pop(\"element_callback\")\n        else:\n            element_callback = None\n\n        # Load optional user-defined callback function for setting up tacs elements\n        if \"problem_setup\" in pytacs_options:\n            self.problem_setup = pytacs_options.pop(\"problem_setup\")\n        else:\n            self.problem_setup = None\n\n        # Load optional user-defined callback function for setting up constraints\n        if \"constraint_setup\" in pytacs_options:\n            self.constraint_setup = pytacs_options.pop(\"constraint_setup\")\n        else:\n            self.constraint_setup = None\n\n        # Load optional user-defined callback function for setting up buckling problem\n        if \"buckling_setup\" in pytacs_options:\n            self.buckling_setup = pytacs_options.pop(\"buckling_setup\")\n        else:\n            self.buckling_setup = None\n\n        # Create pytacs instance\n        self.fea_assembler = pyTACS(bdf_file, options=pytacs_options, comm=comm)\n        self.comm = comm\n\n        # Do any pre-initialize setup requested by user\n        if assembler_setup is not None:\n            assembler_setup(self.fea_assembler)\n\n        # Set up elements and TACS assembler\n        self.fea_assembler.initialize(element_callback)",
  "def get_coupling_group_subsystem(self, scenario_name=None):\n        return TacsCouplingGroup(\n            fea_assembler=self.fea_assembler,\n            conduction=self.conduction,\n            check_partials=self.check_partials,\n            coupled=self.coupled,\n            scenario_name=scenario_name,\n            problem_setup=self.problem_setup,\n        )",
  "def get_mesh_coordinate_subsystem(self, scenario_name=None):\n        return TacsMeshGroup(fea_assembler=self.fea_assembler)",
  "def get_pre_coupling_subsystem(self, scenario_name=None):\n        initial_dvs = self.get_initial_dvs()\n        return TacsPrecouplingGroup(\n            fea_assembler=self.fea_assembler,\n            initial_dv_vals=initial_dvs,\n            separate_mass_dvs=self.separate_mass_dvs,\n        )",
  "def get_post_coupling_subsystem(self, scenario_name=None):\n        return TacsPostcouplingGroup(\n            fea_assembler=self.fea_assembler,\n            check_partials=self.check_partials,\n            conduction=self.conduction,\n            write_solution=self.write_solution,\n            scenario_name=scenario_name,\n            problem_setup=self.problem_setup,\n            constraint_setup=self.constraint_setup,\n            buckling_setup=self.buckling_setup,\n        )",
  "def get_ndof(self):\n        return self.fea_assembler.getVarsPerNode()",
  "def get_number_of_nodes(self):\n        \"\"\"\n        Get the number of nodes on this processor,\n        not including lagrange multiplier nodes\n        \"\"\"\n        nnodes = self.fea_assembler.getNumOwnedNodes()\n        nmult = self.fea_assembler.getNumOwnedMultiplierNodes()\n        return nnodes - nmult",
  "def get_initial_dvs(self):\n        \"\"\"\n        Get an array holding all dvs values that have been added to TACS\n        \"\"\"\n        local_dvs = self.fea_assembler.getOrigDesignVars()\n        all_local_dvs = self.comm.allgather(local_dvs)\n        global_dvs = np.concatenate(all_local_dvs)\n        return global_dvs.astype(float)",
  "def get_dv_bounds(self):\n        \"\"\"Get arrays containing the lower and upper bounds for the design variables,\n        in the form needed by OpenMDAO's `add_design_variable` method.\n\n        Returns\n        -------\n        list of ndarray\n            lower and upper bounds for the design variables\n        \"\"\"\n        local_lb, local_ub = self.fea_assembler.getDesignVarRange()\n        all_lb = self.comm.allgather(local_lb)\n        global_lbs = np.concatenate(all_lb)\n        all_ub = self.comm.allgather(local_ub)\n        global_ubs = np.concatenate(all_ub)\n        return global_lbs.astype(float), global_ubs.astype(float)",
  "def get_dv_scalers(self):\n        \"\"\"Get an array containing the scaling factors for the design\n        variables, in the form needed by OpenMDAO's `add_design_variable`\n        method.\n\n        Returns\n        -------\n        array\n            Scaling values\n        \"\"\"\n        return np.array(self.fea_assembler.scaleList)",
  "def get_ndv(self):\n        \"\"\"\n        Get total number of structural design variables across all procs\n        \"\"\"\n        return self.fea_assembler.getTotalNumDesignVars()",
  "def get_solver(self):\n        # this method is only used by the RLT transfer scheme\n        return self.fea_assembler.assembler",
  "def get_fea_assembler(self):\n        \"\"\"\n        Returns underlying pytacs object.\n        \"\"\"\n        return self.fea_assembler",
  "def get_tagged_indices(self, tags):\n        \"\"\"\n        Method that returns grid IDs for a list of body/boundary tags.\n\n        Parameters\n        ----------\n        tags : list[str]\n\n        Returns\n        -------\n        grid_ids : list[int]\n            list of grid IDs that correspond to given body/boundary tags\n        \"\"\"\n        # Select all compIDs\n        if tags == -1 or tags == [-1]:\n            nnodes = self.fea_assembler.getNumOwnedNodes()\n            # Select all node IDs\n            masked_local_nodes = np.arange(nnodes)\n\n        # Get the compIDs associated with tags\n        else:\n            tagged_comps = self.fea_assembler.selectCompIDs(include=tags)\n            # Select local node IDs for tags\n            masked_local_nodes = self.fea_assembler.getLocalNodeIDsForComps(tagged_comps)\n\n        # Select local node IDs and multiplier node IDs\n        local_mnodes = self.fea_assembler.getLocalMultiplierNodeIDs()\n\n        # Loop through the multiplier nodes and remove them\n        masked_local_nodes = list(masked_local_nodes)\n        for mult_node in local_mnodes:\n            if mult_node in masked_local_nodes:\n                masked_local_nodes.remove(mult_node)\n        masked_local_nodes = np.array(masked_local_nodes)\n\n        # Loop through the multiplier nodes and offset for the multiplier nodes we removed\n        for mult_node in reversed(local_mnodes):\n            masked_local_nodes[masked_local_nodes > mult_node] -= 1\n\n        return list(masked_local_nodes)",
  "class TacsFunctions(om.ExplicitComponent):\n    \"\"\"\n    Component to compute non-mass TACS functions\n    \"\"\"\n\n    def initialize(self):\n        self.options.declare(\"fea_assembler\", recordable=False)\n        self.options.declare(\"conduction\", default=False)\n        self.options.declare(\"check_partials\")\n        self.options.declare(\"write_solution\")\n\n        self.fea_assembler = None\n\n        self.check_partials = False\n\n    def setup(self):\n        self.fea_assembler = self.options[\"fea_assembler\"]\n        self.check_partials = self.options[\"check_partials\"]\n        self.write_solution = self.options[\"write_solution\"]\n        self.conduction = self.options[\"conduction\"]\n        self.solution_counter = 0\n\n        if self.conduction:\n            self.states_name = \"T_conduct\"\n        else:\n            self.states_name = \"u_struct\"\n\n        # TACS part of setup\n        local_ndvs = self.fea_assembler.getNumDesignVars()\n\n        # OpenMDAO part of setup\n        self.add_input(\n            \"tacs_dvs\",\n            distributed=True,\n            shape=local_ndvs,\n            desc=\"tacs design variables\",\n            tags=[\"mphys_coupling\"],\n        )\n        self.add_input(\n            \"x_struct0\",\n            distributed=True,\n            shape_by_conn=True,\n            desc=\"structural node coordinates\",\n            tags=[\"mphys_coordinates\"],\n        )\n        self.add_input(\n            self.states_name,\n            distributed=True,\n            shape_by_conn=True,\n            desc=\"structural state vector\",\n            tags=[\"mphys_coupling\"],\n        )\n\n    def mphys_set_sp(self, sp):\n        # this is the external function to set the sp to this component\n        self.sp = sp\n\n        # Add eval funcs as outputs\n        for func_name in self.sp.functionList:\n            func_handle = self.sp.functionList[func_name]\n            # Skip any mass functions\n            if type(func_handle) not in MASS_FUNCS_CLASSES:\n                self.add_output(\n                    func_name, distributed=False, shape=1, tags=[\"mphys_result\"]\n                )\n\n    def _update_internal(self, inputs):\n        self.sp.setDesignVars(inputs[\"tacs_dvs\"])\n        self.sp.setNodes(inputs[\"x_struct0\"])\n        self.sp.setVariables(inputs[self.states_name])\n\n    def compute(self, inputs, outputs):\n        self._update_internal(inputs)\n\n        # Evaluate functions\n        funcs = {}\n        self.sp.evalFunctions(funcs, evalFuncs=outputs.keys())\n        for func_name in outputs:\n            # Add struct problem name from key\n            key = self.sp.name + \"_\" + func_name\n            outputs[func_name] = funcs[key]\n\n        if self.write_solution:\n            # write the solution files.\n            self.sp.writeSolution(number=self.solution_counter)\n            self.solution_counter += 1\n\n    def compute_jacvec_product(self, inputs, d_inputs, d_outputs, mode):\n        if mode == \"fwd\":\n            if not self.check_partials:\n                raise ValueError(\"TACS forward mode requested but not implemented\")\n        if mode == \"rev\":\n            # always update internal because same tacs object could be used by multiple scenarios\n            # and we need to load this scenario's state back into TACS before doing derivatives\n            self._update_internal(inputs)\n\n            for func_name in d_outputs:\n                d_func = d_outputs[func_name]\n\n                if \"tacs_dvs\" in d_inputs:\n                    self.sp.addDVSens([func_name], [d_inputs[\"tacs_dvs\"]], scale=d_func)\n\n                if \"x_struct0\" in d_inputs:\n                    self.sp.addXptSens(\n                        [func_name], [d_inputs[\"x_struct0\"]], scale=d_func\n                    )\n\n                if self.states_name in d_inputs:\n                    sv_sens = np.zeros_like(d_inputs[self.states_name])\n                    self.sp.addSVSens([func_name], [sv_sens])\n                    d_inputs[self.states_name][:] += sv_sens * d_func",
  "class MassFunctions(om.ExplicitComponent):\n    \"\"\"\n    Component to compute TACS mass-specific functions\n    \"\"\"\n\n    def initialize(self):\n        self.options.declare(\"fea_assembler\", recordable=False)\n        self.options.declare(\"check_partials\")\n\n        self.fea_assembler = None\n        self.check_partials = False\n\n    def setup(self):\n        self.fea_assembler = self.options[\"fea_assembler\"]\n        self.check_partials = self.options[\"check_partials\"]\n\n        # TACS part of setup\n        local_ndvs = self.fea_assembler.getNumDesignVars()\n\n        # OpenMDAO part of setup\n        self.add_input(\n            \"tacs_dvs\",\n            distributed=True,\n            shape=local_ndvs,\n            desc=\"tacs design variables\",\n            tags=[\"mphys_coupling\"],\n        )\n        self.add_input(\n            \"x_struct0\",\n            distributed=True,\n            shape_by_conn=True,\n            desc=\"structural node coordinates\",\n            tags=[\"mphys_coordinates\"],\n        )\n\n    def mphys_set_sp(self, sp):\n        # this is the external function to set the sp to this component\n        self.sp = sp\n\n        # Add eval funcs as outputs\n        for func_name in self.sp.functionList:\n            func_handle = self.sp.functionList[func_name]\n            # Only include mass functions\n            if type(func_handle) in MASS_FUNCS_CLASSES:\n                self.add_output(\n                    func_name, distributed=False, shape=1, tags=[\"mphys_result\"]\n                )\n\n    def _update_internal(self, inputs):\n        self.sp.setDesignVars(inputs[\"tacs_dvs\"])\n        self.sp.setNodes(inputs[\"x_struct0\"])\n\n    def compute(self, inputs, outputs):\n        self._update_internal(inputs)\n\n        # Evaluate functions\n        funcs = {}\n        self.sp.evalFunctions(funcs, evalFuncs=outputs.keys())\n        for func_name in outputs:\n            # Add struct problem name from key\n            key = self.sp.name + \"_\" + func_name\n            outputs[func_name] = funcs[key]\n\n    def compute_jacvec_product(self, inputs, d_inputs, d_outputs, mode):\n        if mode == \"fwd\":\n            if not self.check_partials:\n                raise ValueError(\"TACS forward mode requested but not implemented\")\n        if mode == \"rev\":\n            # always update internal because same tacs object could be used by multiple scenarios\n            # and we need to load this scenario's state back into TACS before doing derivatives\n            self._update_internal(inputs)\n\n            for func_name in d_outputs:\n                d_func = d_outputs[func_name]\n\n                if \"tacs_dvs\" in d_inputs:\n                    self.sp.addDVSens([func_name], [d_inputs[\"tacs_dvs\"]], scale=d_func)\n\n                if \"x_struct0\" in d_inputs:\n                    self.sp.addXptSens(\n                        [func_name], [d_inputs[\"x_struct0\"]], scale=d_func\n                    )",
  "def initialize(self):\n        self.options.declare(\"fea_assembler\", recordable=False)\n        self.options.declare(\"conduction\", default=False)\n        self.options.declare(\"check_partials\")\n        self.options.declare(\"write_solution\")\n\n        self.fea_assembler = None\n\n        self.check_partials = False",
  "def setup(self):\n        self.fea_assembler = self.options[\"fea_assembler\"]\n        self.check_partials = self.options[\"check_partials\"]\n        self.write_solution = self.options[\"write_solution\"]\n        self.conduction = self.options[\"conduction\"]\n        self.solution_counter = 0\n\n        if self.conduction:\n            self.states_name = \"T_conduct\"\n        else:\n            self.states_name = \"u_struct\"\n\n        # TACS part of setup\n        local_ndvs = self.fea_assembler.getNumDesignVars()\n\n        # OpenMDAO part of setup\n        self.add_input(\n            \"tacs_dvs\",\n            distributed=True,\n            shape=local_ndvs,\n            desc=\"tacs design variables\",\n            tags=[\"mphys_coupling\"],\n        )\n        self.add_input(\n            \"x_struct0\",\n            distributed=True,\n            shape_by_conn=True,\n            desc=\"structural node coordinates\",\n            tags=[\"mphys_coordinates\"],\n        )\n        self.add_input(\n            self.states_name,\n            distributed=True,\n            shape_by_conn=True,\n            desc=\"structural state vector\",\n            tags=[\"mphys_coupling\"],\n        )",
  "def mphys_set_sp(self, sp):\n        # this is the external function to set the sp to this component\n        self.sp = sp\n\n        # Add eval funcs as outputs\n        for func_name in self.sp.functionList:\n            func_handle = self.sp.functionList[func_name]\n            # Skip any mass functions\n            if type(func_handle) not in MASS_FUNCS_CLASSES:\n                self.add_output(\n                    func_name, distributed=False, shape=1, tags=[\"mphys_result\"]\n                )",
  "def _update_internal(self, inputs):\n        self.sp.setDesignVars(inputs[\"tacs_dvs\"])\n        self.sp.setNodes(inputs[\"x_struct0\"])\n        self.sp.setVariables(inputs[self.states_name])",
  "def compute(self, inputs, outputs):\n        self._update_internal(inputs)\n\n        # Evaluate functions\n        funcs = {}\n        self.sp.evalFunctions(funcs, evalFuncs=outputs.keys())\n        for func_name in outputs:\n            # Add struct problem name from key\n            key = self.sp.name + \"_\" + func_name\n            outputs[func_name] = funcs[key]\n\n        if self.write_solution:\n            # write the solution files.\n            self.sp.writeSolution(number=self.solution_counter)\n            self.solution_counter += 1",
  "def compute_jacvec_product(self, inputs, d_inputs, d_outputs, mode):\n        if mode == \"fwd\":\n            if not self.check_partials:\n                raise ValueError(\"TACS forward mode requested but not implemented\")\n        if mode == \"rev\":\n            # always update internal because same tacs object could be used by multiple scenarios\n            # and we need to load this scenario's state back into TACS before doing derivatives\n            self._update_internal(inputs)\n\n            for func_name in d_outputs:\n                d_func = d_outputs[func_name]\n\n                if \"tacs_dvs\" in d_inputs:\n                    self.sp.addDVSens([func_name], [d_inputs[\"tacs_dvs\"]], scale=d_func)\n\n                if \"x_struct0\" in d_inputs:\n                    self.sp.addXptSens(\n                        [func_name], [d_inputs[\"x_struct0\"]], scale=d_func\n                    )\n\n                if self.states_name in d_inputs:\n                    sv_sens = np.zeros_like(d_inputs[self.states_name])\n                    self.sp.addSVSens([func_name], [sv_sens])\n                    d_inputs[self.states_name][:] += sv_sens * d_func",
  "def initialize(self):\n        self.options.declare(\"fea_assembler\", recordable=False)\n        self.options.declare(\"check_partials\")\n\n        self.fea_assembler = None\n        self.check_partials = False",
  "def setup(self):\n        self.fea_assembler = self.options[\"fea_assembler\"]\n        self.check_partials = self.options[\"check_partials\"]\n\n        # TACS part of setup\n        local_ndvs = self.fea_assembler.getNumDesignVars()\n\n        # OpenMDAO part of setup\n        self.add_input(\n            \"tacs_dvs\",\n            distributed=True,\n            shape=local_ndvs,\n            desc=\"tacs design variables\",\n            tags=[\"mphys_coupling\"],\n        )\n        self.add_input(\n            \"x_struct0\",\n            distributed=True,\n            shape_by_conn=True,\n            desc=\"structural node coordinates\",\n            tags=[\"mphys_coordinates\"],\n        )",
  "def mphys_set_sp(self, sp):\n        # this is the external function to set the sp to this component\n        self.sp = sp\n\n        # Add eval funcs as outputs\n        for func_name in self.sp.functionList:\n            func_handle = self.sp.functionList[func_name]\n            # Only include mass functions\n            if type(func_handle) in MASS_FUNCS_CLASSES:\n                self.add_output(\n                    func_name, distributed=False, shape=1, tags=[\"mphys_result\"]\n                )",
  "def _update_internal(self, inputs):\n        self.sp.setDesignVars(inputs[\"tacs_dvs\"])\n        self.sp.setNodes(inputs[\"x_struct0\"])",
  "def compute(self, inputs, outputs):\n        self._update_internal(inputs)\n\n        # Evaluate functions\n        funcs = {}\n        self.sp.evalFunctions(funcs, evalFuncs=outputs.keys())\n        for func_name in outputs:\n            # Add struct problem name from key\n            key = self.sp.name + \"_\" + func_name\n            outputs[func_name] = funcs[key]",
  "def compute_jacvec_product(self, inputs, d_inputs, d_outputs, mode):\n        if mode == \"fwd\":\n            if not self.check_partials:\n                raise ValueError(\"TACS forward mode requested but not implemented\")\n        if mode == \"rev\":\n            # always update internal because same tacs object could be used by multiple scenarios\n            # and we need to load this scenario's state back into TACS before doing derivatives\n            self._update_internal(inputs)\n\n            for func_name in d_outputs:\n                d_func = d_outputs[func_name]\n\n                if \"tacs_dvs\" in d_inputs:\n                    self.sp.addDVSens([func_name], [d_inputs[\"tacs_dvs\"]], scale=d_func)\n\n                if \"x_struct0\" in d_inputs:\n                    self.sp.addXptSens(\n                        [func_name], [d_inputs[\"x_struct0\"]], scale=d_func\n                    )",
  "class TacsSolver(om.ImplicitComponent):\n    \"\"\"\n    Component to perform TACS steady analysis\n\n    Assumptions:\n        - The TACS steady residual is R = K * u_s - f_s = 0\n\n    \"\"\"\n\n    def initialize(self):\n        self.options.declare(\"fea_assembler\", recordable=False)\n        self.options.declare(\"conduction\", default=False)\n        self.options.declare(\"check_partials\")\n        self.options.declare(\"coupled\", default=False)\n\n        self.fea_assembler = None\n\n        self.transposed = False\n        self.check_partials = False\n\n        self.old_dvs = None\n        self.old_xs = None\n\n    def setup(self):\n        self.check_partials = self.options[\"check_partials\"]\n        self.fea_assembler = self.options[\"fea_assembler\"]\n        self.conduction = self.options[\"conduction\"]\n        self.coupled = self.options[\"coupled\"]\n\n        if self.conduction:\n            self.states_name = \"T_conduct\"\n            self.rhs_name = \"q_conduct\"\n        else:\n            self.states_name = \"u_struct\"\n            self.rhs_name = \"f_struct\"\n\n        # OpenMDAO setup\n        local_ndvs = self.fea_assembler.getNumDesignVars()\n        self.ndof = self.fea_assembler.getVarsPerNode()\n        state_size = self.fea_assembler.getNumOwnedNodes() * self.ndof\n\n        # inputs\n        self.add_input(\n            \"tacs_dvs\",\n            distributed=True,\n            shape=local_ndvs,\n            desc=\"tacs distributed design variables\",\n            tags=[\"mphys_coupling\"],\n        )\n        self.add_input(\n            \"x_struct0\",\n            distributed=True,\n            shape_by_conn=True,\n            desc=\"distributed structural node coordinates\",\n            tags=[\"mphys_coordinates\"],\n        )\n        if self.coupled:\n            self.add_input(\n                self.rhs_name,\n                distributed=True,\n                shape=state_size,\n                val=0.0,\n                desc=\"coupling load vector\",\n                tags=[\"mphys_coupling\"],\n            )\n\n        # outputs\n        # its important that we set this to zero since this displacement value is used for the first iteration of the aero\n        self.add_output(\n            self.states_name,\n            distributed=True,\n            shape=state_size,\n            val=np.zeros(state_size),\n            desc=\"structural state vector\",\n            tags=[\"mphys_coupling\"],\n        )\n\n    def _need_update(self, inputs):\n        update = False\n\n        dvs = inputs[\"tacs_dvs\"]\n        xs = inputs[\"x_struct0\"]\n\n        if self.old_dvs is None:\n            self.old_dvs = inputs[\"tacs_dvs\"].copy()\n            update = True\n\n        elif len(dvs) > 0:\n            if max(np.abs(dvs - self.old_dvs)) > 0.0:  # 1e-7:\n                self.old_dvs = inputs[\"tacs_dvs\"].copy()\n                update = True\n\n        if self.old_xs is None:\n            self.old_xs = inputs[\"x_struct0\"].copy()\n            update = True\n\n        elif len(xs) > 0:\n            if max(np.abs(xs - self.old_xs)) > 0.0:  # 1e-7:\n                self.old_xs = inputs[\"x_struct0\"].copy()\n                update = True\n\n        tmp = update\n        # Perform all reduce to check if any other procs came back True\n        update = self.comm.allreduce(tmp)\n        return update\n\n    def _update_internal(self, inputs, outputs=None):\n        if self._need_update(inputs):\n            self.sp.setDesignVars(inputs[\"tacs_dvs\"])\n            self.sp.setNodes(inputs[\"x_struct0\"])\n        if outputs is not None:\n            self.sp.setVariables(outputs[self.states_name])\n        self.sp._updateAssemblerVars()\n\n    def apply_nonlinear(self, inputs, outputs, residuals):\n        self._update_internal(inputs, outputs)\n\n        if self.coupled:\n            Fext = inputs[self.rhs_name]\n        else:\n            Fext = None\n\n        self.sp.getResidual(res=residuals[self.states_name], Fext=Fext)\n\n    def solve_nonlinear(self, inputs, outputs):\n        self._update_internal(inputs)\n\n        if self.coupled:\n            Fext = inputs[self.rhs_name]\n        else:\n            Fext = None\n\n        self.sp.solve(Fext=Fext)\n        self.sp.getVariables(states=outputs[self.states_name])\n\n    def solve_linear(self, d_outputs, d_residuals, mode):\n        if mode == \"fwd\":\n            if self.check_partials:\n                print(\"solver fwd\")\n            else:\n                raise ValueError(\"forward mode requested but not implemented\")\n\n        if mode == \"rev\":\n            self.sp.solveAdjoint(\n                d_outputs[self.states_name], d_residuals[self.states_name]\n            )\n\n    def apply_linear(self, inputs, outputs, d_inputs, d_outputs, d_residuals, mode):\n        self._update_internal(inputs, outputs)\n        if mode == \"fwd\":\n            if not self.check_partials:\n                raise ValueError(\"TACS forward mode requested but not implemented\")\n\n        if mode == \"rev\":\n            if self.states_name in d_residuals:\n                if self.states_name in d_outputs:\n                    self.sp.addTransposeJacVecProduct(\n                        d_residuals[self.states_name], d_outputs[self.states_name]\n                    )\n\n                if self.rhs_name in d_inputs:\n                    array_w_bcs = d_residuals[self.states_name].copy()\n                    self.fea_assembler.applyBCsToVec(array_w_bcs)\n                    d_inputs[self.rhs_name] -= array_w_bcs\n\n                if \"x_struct0\" in d_inputs:\n                    self.sp.addAdjointResXptSensProducts(\n                        [d_residuals[self.states_name]],\n                        [d_inputs[\"x_struct0\"]],\n                        scale=1.0,\n                    )\n\n                if \"tacs_dvs\" in d_inputs:\n                    self.sp.addAdjointResProducts(\n                        [d_residuals[self.states_name]],\n                        [d_inputs[\"tacs_dvs\"]],\n                        scale=1.0,\n                    )\n\n    def set_sp(self, sp):\n        self.sp = sp",
  "def initialize(self):\n        self.options.declare(\"fea_assembler\", recordable=False)\n        self.options.declare(\"conduction\", default=False)\n        self.options.declare(\"check_partials\")\n        self.options.declare(\"coupled\", default=False)\n\n        self.fea_assembler = None\n\n        self.transposed = False\n        self.check_partials = False\n\n        self.old_dvs = None\n        self.old_xs = None",
  "def setup(self):\n        self.check_partials = self.options[\"check_partials\"]\n        self.fea_assembler = self.options[\"fea_assembler\"]\n        self.conduction = self.options[\"conduction\"]\n        self.coupled = self.options[\"coupled\"]\n\n        if self.conduction:\n            self.states_name = \"T_conduct\"\n            self.rhs_name = \"q_conduct\"\n        else:\n            self.states_name = \"u_struct\"\n            self.rhs_name = \"f_struct\"\n\n        # OpenMDAO setup\n        local_ndvs = self.fea_assembler.getNumDesignVars()\n        self.ndof = self.fea_assembler.getVarsPerNode()\n        state_size = self.fea_assembler.getNumOwnedNodes() * self.ndof\n\n        # inputs\n        self.add_input(\n            \"tacs_dvs\",\n            distributed=True,\n            shape=local_ndvs,\n            desc=\"tacs distributed design variables\",\n            tags=[\"mphys_coupling\"],\n        )\n        self.add_input(\n            \"x_struct0\",\n            distributed=True,\n            shape_by_conn=True,\n            desc=\"distributed structural node coordinates\",\n            tags=[\"mphys_coordinates\"],\n        )\n        if self.coupled:\n            self.add_input(\n                self.rhs_name,\n                distributed=True,\n                shape=state_size,\n                val=0.0,\n                desc=\"coupling load vector\",\n                tags=[\"mphys_coupling\"],\n            )\n\n        # outputs\n        # its important that we set this to zero since this displacement value is used for the first iteration of the aero\n        self.add_output(\n            self.states_name,\n            distributed=True,\n            shape=state_size,\n            val=np.zeros(state_size),\n            desc=\"structural state vector\",\n            tags=[\"mphys_coupling\"],\n        )",
  "def _need_update(self, inputs):\n        update = False\n\n        dvs = inputs[\"tacs_dvs\"]\n        xs = inputs[\"x_struct0\"]\n\n        if self.old_dvs is None:\n            self.old_dvs = inputs[\"tacs_dvs\"].copy()\n            update = True\n\n        elif len(dvs) > 0:\n            if max(np.abs(dvs - self.old_dvs)) > 0.0:  # 1e-7:\n                self.old_dvs = inputs[\"tacs_dvs\"].copy()\n                update = True\n\n        if self.old_xs is None:\n            self.old_xs = inputs[\"x_struct0\"].copy()\n            update = True\n\n        elif len(xs) > 0:\n            if max(np.abs(xs - self.old_xs)) > 0.0:  # 1e-7:\n                self.old_xs = inputs[\"x_struct0\"].copy()\n                update = True\n\n        tmp = update\n        # Perform all reduce to check if any other procs came back True\n        update = self.comm.allreduce(tmp)\n        return update",
  "def _update_internal(self, inputs, outputs=None):\n        if self._need_update(inputs):\n            self.sp.setDesignVars(inputs[\"tacs_dvs\"])\n            self.sp.setNodes(inputs[\"x_struct0\"])\n        if outputs is not None:\n            self.sp.setVariables(outputs[self.states_name])\n        self.sp._updateAssemblerVars()",
  "def apply_nonlinear(self, inputs, outputs, residuals):\n        self._update_internal(inputs, outputs)\n\n        if self.coupled:\n            Fext = inputs[self.rhs_name]\n        else:\n            Fext = None\n\n        self.sp.getResidual(res=residuals[self.states_name], Fext=Fext)",
  "def solve_nonlinear(self, inputs, outputs):\n        self._update_internal(inputs)\n\n        if self.coupled:\n            Fext = inputs[self.rhs_name]\n        else:\n            Fext = None\n\n        self.sp.solve(Fext=Fext)\n        self.sp.getVariables(states=outputs[self.states_name])",
  "def solve_linear(self, d_outputs, d_residuals, mode):\n        if mode == \"fwd\":\n            if self.check_partials:\n                print(\"solver fwd\")\n            else:\n                raise ValueError(\"forward mode requested but not implemented\")\n\n        if mode == \"rev\":\n            self.sp.solveAdjoint(\n                d_outputs[self.states_name], d_residuals[self.states_name]\n            )",
  "def apply_linear(self, inputs, outputs, d_inputs, d_outputs, d_residuals, mode):\n        self._update_internal(inputs, outputs)\n        if mode == \"fwd\":\n            if not self.check_partials:\n                raise ValueError(\"TACS forward mode requested but not implemented\")\n\n        if mode == \"rev\":\n            if self.states_name in d_residuals:\n                if self.states_name in d_outputs:\n                    self.sp.addTransposeJacVecProduct(\n                        d_residuals[self.states_name], d_outputs[self.states_name]\n                    )\n\n                if self.rhs_name in d_inputs:\n                    array_w_bcs = d_residuals[self.states_name].copy()\n                    self.fea_assembler.applyBCsToVec(array_w_bcs)\n                    d_inputs[self.rhs_name] -= array_w_bcs\n\n                if \"x_struct0\" in d_inputs:\n                    self.sp.addAdjointResXptSensProducts(\n                        [d_residuals[self.states_name]],\n                        [d_inputs[\"x_struct0\"]],\n                        scale=1.0,\n                    )\n\n                if \"tacs_dvs\" in d_inputs:\n                    self.sp.addAdjointResProducts(\n                        [d_residuals[self.states_name]],\n                        [d_inputs[\"tacs_dvs\"]],\n                        scale=1.0,\n                    )",
  "def set_sp(self, sp):\n        self.sp = sp",
  "class TacsPostcouplingGroup(om.Group):\n    def initialize(self):\n        self.options.declare(\"fea_assembler\", recordable=False)\n        self.options.declare(\"check_partials\")\n        self.options.declare(\"conduction\", default=False)\n        self.options.declare(\"scenario_name\", default=None)\n        self.options.declare(\"problem_setup\", default=None)\n        self.options.declare(\"write_solution\")\n        self.options.declare(\"constraint_setup\", default=None)\n        self.options.declare(\"buckling_setup\", default=None)\n\n    def setup(self):\n        self.fea_assembler = self.options[\"fea_assembler\"]\n        self.check_partials = self.options[\"check_partials\"]\n        self.conduction = self.options[\"conduction\"]\n        self.write_solution = self.options[\"write_solution\"]\n\n        # Setup problem based on scenario that's calling builder\n        scenario_name = self.options[\"scenario_name\"]\n        if scenario_name is None:\n            # Default structural problem\n            name = \"default\"\n        else:\n            name = scenario_name\n        sp = self.fea_assembler.createStaticProblem(name=name)\n\n        # Setup TACS problem with user-defined output functions\n        problem_setup = self.options[\"problem_setup\"]\n        if problem_setup is not None:\n            new_problem = problem_setup(scenario_name, self.fea_assembler, sp)\n            # Check if the user provided back a new problem to overwrite the default\n            if new_problem is not None:\n                sp = new_problem\n\n        # Promote state variables with physics-specific tag that MPhys expects\n        promotes_inputs = [\n            (\"x_struct0\", \"unmasker.x_struct0\"),\n            (\"tacs_dvs\", \"distributor.tacs_dvs\"),\n        ]\n        if self.conduction:\n            promotes_states = [(\"T_conduct\", \"solver.T_conduct\")]\n        else:\n            promotes_states = [(\"u_struct\", \"solver.u_struct\")]\n\n        # Add function evaluation component for non-mass outputs\n        self.add_subsystem(\n            \"eval_funcs\",\n            TacsFunctions(\n                fea_assembler=self.fea_assembler,\n                check_partials=self.check_partials,\n                conduction=self.conduction,\n                write_solution=self.write_solution,\n            ),\n            promotes_inputs=promotes_inputs + promotes_states,\n            promotes_outputs=[\"*\"],\n        )\n        self.eval_funcs.mphys_set_sp(sp)\n\n        # Check if there are any mass functions added by user\n        mass_funcs = False\n        for func_handle in sp.functionList.values():\n            if type(func_handle) in MASS_FUNCS_CLASSES:\n                mass_funcs = True\n\n        # Mass functions are handled in a separate component to prevent useless adjoint solves\n        if mass_funcs:\n            # Note: these functions do not depend on the states\n            self.add_subsystem(\n                \"mass_funcs\",\n                MassFunctions(\n                    fea_assembler=self.fea_assembler, check_partials=self.check_partials\n                ),\n                promotes_inputs=promotes_inputs,\n                promotes_outputs=[\"*\"],\n            )\n\n            self.mass_funcs.mphys_set_sp(sp)\n\n        # Setup TACS problem with user-defined output functions\n        buckling_setup = self.options[\"buckling_setup\"]\n        if buckling_setup is not None:\n            new_problem = buckling_setup(scenario_name, self.fea_assembler)\n            # Check if the user provided back a new problem to overwrite the default\n            if isinstance(new_problem, tacs.problems.BucklingProblem):\n                bp = new_problem\n\n                # Add buckling evaluation component for eigenvalue outputs\n                self.add_subsystem(\n                    \"buckling\",\n                    TacsBuckling(\n                        fea_assembler=self.fea_assembler,\n                        check_partials=self.check_partials,\n                        conduction=self.conduction,\n                        write_solution=self.write_solution,\n                    ),\n                    promotes_inputs=promotes_inputs + promotes_states,\n                    promotes_outputs=[\"*\"],\n                )\n                self.buckling.mphys_set_bp(bp)\n\n        # Check if there are any user-defined TACS constraints\n        # Constraints behave similar to \"mass\" functions (i.e. they don't depend on the solution state)\n        constraint_setup = self.options[\"constraint_setup\"]\n        tacs_constraints = []\n        if constraint_setup is not None:\n            new_constraints = constraint_setup(\n                scenario_name, self.fea_assembler, tacs_constraints\n            )\n            # Check if the user provided back new constraints to overwrite the default\n            if new_constraints is not None:\n                tacs_constraints = new_constraints\n\n        # Only add constraint group if there are constraints to add\n        if len(tacs_constraints) > 0:\n            con_group = self.add_subsystem(\"constraints\", om.Group(), promotes=[\"*\"])\n            # Loop through each constraint in lista and add to group\n            for constraint in tacs_constraints:\n                con_comp = ConstraintComponent(\n                    fea_assembler=self.fea_assembler,\n                    constraint_object=constraint,\n                )\n                con_group.add_subsystem(\n                    constraint.name, con_comp, promotes_inputs=promotes_inputs\n                )",
  "def initialize(self):\n        self.options.declare(\"fea_assembler\", recordable=False)\n        self.options.declare(\"check_partials\")\n        self.options.declare(\"conduction\", default=False)\n        self.options.declare(\"scenario_name\", default=None)\n        self.options.declare(\"problem_setup\", default=None)\n        self.options.declare(\"write_solution\")\n        self.options.declare(\"constraint_setup\", default=None)\n        self.options.declare(\"buckling_setup\", default=None)",
  "def setup(self):\n        self.fea_assembler = self.options[\"fea_assembler\"]\n        self.check_partials = self.options[\"check_partials\"]\n        self.conduction = self.options[\"conduction\"]\n        self.write_solution = self.options[\"write_solution\"]\n\n        # Setup problem based on scenario that's calling builder\n        scenario_name = self.options[\"scenario_name\"]\n        if scenario_name is None:\n            # Default structural problem\n            name = \"default\"\n        else:\n            name = scenario_name\n        sp = self.fea_assembler.createStaticProblem(name=name)\n\n        # Setup TACS problem with user-defined output functions\n        problem_setup = self.options[\"problem_setup\"]\n        if problem_setup is not None:\n            new_problem = problem_setup(scenario_name, self.fea_assembler, sp)\n            # Check if the user provided back a new problem to overwrite the default\n            if new_problem is not None:\n                sp = new_problem\n\n        # Promote state variables with physics-specific tag that MPhys expects\n        promotes_inputs = [\n            (\"x_struct0\", \"unmasker.x_struct0\"),\n            (\"tacs_dvs\", \"distributor.tacs_dvs\"),\n        ]\n        if self.conduction:\n            promotes_states = [(\"T_conduct\", \"solver.T_conduct\")]\n        else:\n            promotes_states = [(\"u_struct\", \"solver.u_struct\")]\n\n        # Add function evaluation component for non-mass outputs\n        self.add_subsystem(\n            \"eval_funcs\",\n            TacsFunctions(\n                fea_assembler=self.fea_assembler,\n                check_partials=self.check_partials,\n                conduction=self.conduction,\n                write_solution=self.write_solution,\n            ),\n            promotes_inputs=promotes_inputs + promotes_states,\n            promotes_outputs=[\"*\"],\n        )\n        self.eval_funcs.mphys_set_sp(sp)\n\n        # Check if there are any mass functions added by user\n        mass_funcs = False\n        for func_handle in sp.functionList.values():\n            if type(func_handle) in MASS_FUNCS_CLASSES:\n                mass_funcs = True\n\n        # Mass functions are handled in a separate component to prevent useless adjoint solves\n        if mass_funcs:\n            # Note: these functions do not depend on the states\n            self.add_subsystem(\n                \"mass_funcs\",\n                MassFunctions(\n                    fea_assembler=self.fea_assembler, check_partials=self.check_partials\n                ),\n                promotes_inputs=promotes_inputs,\n                promotes_outputs=[\"*\"],\n            )\n\n            self.mass_funcs.mphys_set_sp(sp)\n\n        # Setup TACS problem with user-defined output functions\n        buckling_setup = self.options[\"buckling_setup\"]\n        if buckling_setup is not None:\n            new_problem = buckling_setup(scenario_name, self.fea_assembler)\n            # Check if the user provided back a new problem to overwrite the default\n            if isinstance(new_problem, tacs.problems.BucklingProblem):\n                bp = new_problem\n\n                # Add buckling evaluation component for eigenvalue outputs\n                self.add_subsystem(\n                    \"buckling\",\n                    TacsBuckling(\n                        fea_assembler=self.fea_assembler,\n                        check_partials=self.check_partials,\n                        conduction=self.conduction,\n                        write_solution=self.write_solution,\n                    ),\n                    promotes_inputs=promotes_inputs + promotes_states,\n                    promotes_outputs=[\"*\"],\n                )\n                self.buckling.mphys_set_bp(bp)\n\n        # Check if there are any user-defined TACS constraints\n        # Constraints behave similar to \"mass\" functions (i.e. they don't depend on the solution state)\n        constraint_setup = self.options[\"constraint_setup\"]\n        tacs_constraints = []\n        if constraint_setup is not None:\n            new_constraints = constraint_setup(\n                scenario_name, self.fea_assembler, tacs_constraints\n            )\n            # Check if the user provided back new constraints to overwrite the default\n            if new_constraints is not None:\n                tacs_constraints = new_constraints\n\n        # Only add constraint group if there are constraints to add\n        if len(tacs_constraints) > 0:\n            con_group = self.add_subsystem(\"constraints\", om.Group(), promotes=[\"*\"])\n            # Loop through each constraint in lista and add to group\n            for constraint in tacs_constraints:\n                con_comp = ConstraintComponent(\n                    fea_assembler=self.fea_assembler,\n                    constraint_object=constraint,\n                )\n                con_group.add_subsystem(\n                    constraint.name, con_comp, promotes_inputs=promotes_inputs\n                )",
  "class TACSConstraint(TACSSystem):\n    \"\"\"\n    Base class for TACS constraint types. Contains methods common to all TACS constraints.\n    \"\"\"\n\n    def __init__(\n        self, assembler, comm=None, options=None, outputViewer=None, meshLoader=None\n    ):\n        \"\"\"\n        Parameters\n        ----------\n        assembler : tacs.TACS.Assembler\n            Cython object responsible for creating and setting tacs objects used to solve problem\n\n        comm : mpi4py.MPI.Intracomm\n            The comm object on which to create the pyTACS object.\n\n        options : dict\n            Dictionary holding problem-specific option parameters (case-insensitive).\n\n        outputViewer : tacs.TACS.TACSToFH5\n            Cython object used to write out f5 files that can be converted and used for postprocessing.\n\n        meshLoader : tacs.pymeshloader.pyMeshLoader\n            pyMeshLoader object used to create the assembler.\n        \"\"\"\n        # Set attributes and options\n        TACSSystem.__init__(self, assembler, comm, options, outputViewer, meshLoader)\n\n        # List of constraints\n        self.constraintList = OrderedDict()\n\n        # Setup global to local dv num map for each proc\n        self._initilaizeGlobalToLocalDVDict()\n\n        return\n\n    def _initilaizeGlobalToLocalDVDict(self):\n        size = self.comm.size\n        rank = self.comm.rank\n        nLocalDVs = self.getNumDesignVars()\n        nLocalDVsOnProc = self.comm.allgather(nLocalDVs)\n        # Figure out which DVNums belong to each processor\n        ownerRange = np.zeros(size + 1, dtype=int)\n        # Sum local dv ranges over each proc to get global dv ranges\n        ownerRange[1:] = np.cumsum(nLocalDVsOnProc)\n        self.globalToLocalDVNums = dict(\n            zip(range(ownerRange[rank], ownerRange[rank + 1]), range(nLocalDVs))\n        )\n\n    ####### Eval constraint methods ########\n\n    def addConstraint(self, conName, compIDs=None, lower=-1e20, upper=1e20, **kwargs):\n        \"\"\"\n        Generic method to adding a new constraint set for TACS.\n\n        Parameters\n        ----------\n        conName : str\n            The user-supplied name for the constraint set. This will\n            typically be a string that is meaningful to the user\n\n        compIDs: list[int] or None\n            List of compIDs to select. If None, all compIDs will be selected. Defaults to None.\n\n        lower: float or complex\n            lower bound for constraint. Defaults to -1e20.\n\n        upper: float or complex\n            upper bound for constraint. Defaults to 1e20.\n\n        \"\"\"\n        raise NotImplementedError(\n            f\"'addConstraint' method is not implemented for class '{type(self).__name__}'\"\n        )\n\n    def getConstraintBounds(self, bounds, evalCons=None):\n        \"\"\"\n        Get bounds for constraints. The constraints corresponding to the strings in\n        `evalCons` are evaluated and updated into the provided\n        dictionary.\n\n        Parameters\n        ----------\n        bounds : dict\n            Dictionary into which the constraint bounds are saved.\n            Bounds will be saved as a tuple: (lower, upper)\n        evalCons : iterable object containing strings.\n            If not none, use these constraints to evaluate.\n\n        Examples\n        --------\n        >>> conBounds = {}\n        >>> tacsConstraint.getConstraintBounds(conBounds, 'LE_SPAR')\n        >>> conBounds\n        >>> # Result will look like (if TACSConstraint has name of 'c1'):\n        >>> # {'c1_LE_SPAR': (array([-1e20]), array([1e20]))}\n        \"\"\"\n        # Check if user specified which constraints to output\n        # Otherwise, output them all\n        evalCons = self._processEvalCons(evalCons)\n\n        # Loop through each requested constraint set\n        for conName in evalCons:\n            key = f\"{self.name}_{conName}\"\n            if hasattr(self.constraintList[conName], \"getBounds\"):\n                bounds[key] = self.constraintList[conName].getBounds()\n            else:\n                bounds[key] = (None, None)\n\n    def getConstraintSizes(self, sizes, evalCons=None):\n        \"\"\"\n        Get number for constraint equations in each set.\n        The constraints corresponding to the strings in `evalCons`\n        are evaluated and updated into the provided dictionary.\n\n        Parameters\n        ----------\n        sizes : dict\n            Dictionary into which the constraint sizes are saved.\n        evalCons : iterable object containing strings.\n            If not none, use these constraints to evaluate.\n\n        Examples\n        --------\n        >>> conSizes = {}\n        >>> tacsConstraint.getConstraintSizes(conSizes, 'LE_SPAR')\n        >>> funconSizescs\n        >>> # Result will look like (if TACSConstraint has name of 'c1'):\n        >>> # {'c1_LE_SPAR': 10}\n        \"\"\"\n        # Check if user specified which constraints to output\n        # Otherwise, output them all\n        evalCons = self._processEvalCons(evalCons)\n\n        # Loop through each requested constraint set\n        for conName in evalCons:\n            key = f\"{self.name}_{conName}\"\n            if hasattr(self.constraintList[conName], \"nCon\"):\n                sizes[key] = self.constraintList[conName].nCon\n            else:\n                sizes[key] = 0\n\n    def getConstraintKeys(self):\n        \"\"\"\n        Return a list of the current constraint key names\n\n        Returns\n        -------\n        conNames : list[str]\n            List containing user-defined names for constraint groups added so far.\n        \"\"\"\n        return list(self.constraintList.keys())\n\n    def evalConstraints(self, funcs, evalCons=None, ignoreMissing=False):\n        \"\"\"\n        Evaluate values for constraints. The constraints corresponding to the strings in\n        evalCons are evaluated and updated into the provided\n        dictionary.\n\n        Parameters\n        ----------\n        funcs : dict\n            Dictionary into which the constraints are saved.\n        evalCons : iterable object containing strings.\n            If not none, use these constraints to evaluate.\n        ignoreMissing : bool\n            Flag to supress checking for a valid constraint. Please use\n            this option with caution.\n\n        Examples\n        --------\n        >>> funcs = {}\n        >>> tacsConstraint.evalConstraints(funcs, 'LE_SPAR')\n        >>> funcs\n        >>> # Result will look like (if TACSConstraint has name of 'c1'):\n        >>> # {'c1_LE_SPAR': array([12354.10])}\n        \"\"\"\n        raise NotImplementedError(\n            f\"'evalConstraints' method is not implemented for class '{type(self).__name__}'\"\n        )\n\n    def evalConstraintsSens(self, funcsSens, evalCons=None):\n        \"\"\"\n        This is the main routine for returning useful (sensitivity)\n        information from constraint. The derivatives of the constraints\n        corresponding to the strings in evalCons are evaluated and\n        updated into the provided dictionary. The derivitives with\n        respect to all design variables and node locations are computed.\n\n        Parameters\n        ----------\n        funcsSens : dict\n            Dictionary into which the derivatives are saved.\n        evalCons : iterable object containing strings\n            The constraints the user wants returned\n\n        Examples\n        --------\n        >>> funcsSens = {}\n        >>> tacsConstraint.evalConstraintsSens(funcsSens, 'LE_SPAR')\n        >>> funcsSens\n        >>> # Result will look like (if TACSConstraint has name of 'c1'):\n        >>> # {'c1_LE_SPAR':{'struct':<50x242 sparse matrix of type '<class 'numpy.float64'>' with 100 stored elements in Compressed Sparse Row format>}}\n        \"\"\"\n        raise NotImplementedError(\n            f\"'evalConstraintsSens' method is not implemented for class '{type(self).__name__}'\"\n        )\n\n    def _processEvalCons(self, evalCons, ignoreMissing=True):\n        \"\"\"\n        Internal method for processing user-provided evalCons\n\n        Parameters\n        ----------\n        evalCons : iterable object containing strings or None\n            The constraints the user wants returned\n        ignoreMissing : bool\n            Flag to supress checking for a valid constraint.\n            Defaults to True.\n\n        Returns\n        -------\n        conList : list[str]\n            List of constraints the user wants returned\n        \"\"\"\n        # Check if user specified which constraints to output\n        # Otherwise, output them all\n        if evalCons is None:\n            evalCons = self.constraintList\n        else:\n            userCons = sorted(list(evalCons))\n            evalCons = {}\n            for func in userCons:\n                if func in self.constraintList:\n                    evalCons[func] = self.constraintList[func]\n\n        if not ignoreMissing:\n            for f in evalCons:\n                if f not in self.constraintList:\n                    raise self._TACSError(\n                        f\"Supplied constraint '{f}' has not been added \"\n                        \"using addConstraint().\"\n                    )\n\n        return evalCons",
  "class SparseLinearConstraint(object):\n    dtype = TACSConstraint.dtype\n\n    def __init__(self, comm, rows, cols, vals, nrows, ncols, lb=-1e20, ub=1e20):\n        # Sparse Jacobian for constraint\n        self.A = sp.sparse.csr_matrix(\n            (vals, (rows, cols)), shape=(nrows, ncols), dtype=self.dtype\n        )\n        # Number of constraints\n        self.nCon = nrows\n        # MPI comm\n        self.comm = comm\n        # Save bound information\n        if isinstance(lb, np.ndarray) and len(lb) == self.nCon:\n            self.lb = lb.astype(self.dtype)\n        elif isinstance(lb, float) or isinstance(lb, complex):\n            self.lb = np.array([lb] * self.nCon, dtype=self.dtype)\n\n        if isinstance(ub, np.ndarray) and len(ub) == self.nCon:\n            self.ub = ub.astype(self.dtype)\n        elif isinstance(ub, float) or isinstance(ub, complex):\n            self.ub = np.array([ub] * self.nCon, dtype=self.dtype)\n\n    def evalCon(self, x):\n        conVals = self.comm.allreduce(self.A.dot(x))\n        return conVals\n\n    def evalConSens(self, x=None):\n        return self.A.copy()\n\n    def getBounds(self):\n        return self.lb.copy(), self.ub.copy()",
  "def __init__(\n        self, assembler, comm=None, options=None, outputViewer=None, meshLoader=None\n    ):\n        \"\"\"\n        Parameters\n        ----------\n        assembler : tacs.TACS.Assembler\n            Cython object responsible for creating and setting tacs objects used to solve problem\n\n        comm : mpi4py.MPI.Intracomm\n            The comm object on which to create the pyTACS object.\n\n        options : dict\n            Dictionary holding problem-specific option parameters (case-insensitive).\n\n        outputViewer : tacs.TACS.TACSToFH5\n            Cython object used to write out f5 files that can be converted and used for postprocessing.\n\n        meshLoader : tacs.pymeshloader.pyMeshLoader\n            pyMeshLoader object used to create the assembler.\n        \"\"\"\n        # Set attributes and options\n        TACSSystem.__init__(self, assembler, comm, options, outputViewer, meshLoader)\n\n        # List of constraints\n        self.constraintList = OrderedDict()\n\n        # Setup global to local dv num map for each proc\n        self._initilaizeGlobalToLocalDVDict()\n\n        return",
  "def _initilaizeGlobalToLocalDVDict(self):\n        size = self.comm.size\n        rank = self.comm.rank\n        nLocalDVs = self.getNumDesignVars()\n        nLocalDVsOnProc = self.comm.allgather(nLocalDVs)\n        # Figure out which DVNums belong to each processor\n        ownerRange = np.zeros(size + 1, dtype=int)\n        # Sum local dv ranges over each proc to get global dv ranges\n        ownerRange[1:] = np.cumsum(nLocalDVsOnProc)\n        self.globalToLocalDVNums = dict(\n            zip(range(ownerRange[rank], ownerRange[rank + 1]), range(nLocalDVs))\n        )",
  "def addConstraint(self, conName, compIDs=None, lower=-1e20, upper=1e20, **kwargs):\n        \"\"\"\n        Generic method to adding a new constraint set for TACS.\n\n        Parameters\n        ----------\n        conName : str\n            The user-supplied name for the constraint set. This will\n            typically be a string that is meaningful to the user\n\n        compIDs: list[int] or None\n            List of compIDs to select. If None, all compIDs will be selected. Defaults to None.\n\n        lower: float or complex\n            lower bound for constraint. Defaults to -1e20.\n\n        upper: float or complex\n            upper bound for constraint. Defaults to 1e20.\n\n        \"\"\"\n        raise NotImplementedError(\n            f\"'addConstraint' method is not implemented for class '{type(self).__name__}'\"\n        )",
  "def getConstraintBounds(self, bounds, evalCons=None):\n        \"\"\"\n        Get bounds for constraints. The constraints corresponding to the strings in\n        `evalCons` are evaluated and updated into the provided\n        dictionary.\n\n        Parameters\n        ----------\n        bounds : dict\n            Dictionary into which the constraint bounds are saved.\n            Bounds will be saved as a tuple: (lower, upper)\n        evalCons : iterable object containing strings.\n            If not none, use these constraints to evaluate.\n\n        Examples\n        --------\n        >>> conBounds = {}\n        >>> tacsConstraint.getConstraintBounds(conBounds, 'LE_SPAR')\n        >>> conBounds\n        >>> # Result will look like (if TACSConstraint has name of 'c1'):\n        >>> # {'c1_LE_SPAR': (array([-1e20]), array([1e20]))}\n        \"\"\"\n        # Check if user specified which constraints to output\n        # Otherwise, output them all\n        evalCons = self._processEvalCons(evalCons)\n\n        # Loop through each requested constraint set\n        for conName in evalCons:\n            key = f\"{self.name}_{conName}\"\n            if hasattr(self.constraintList[conName], \"getBounds\"):\n                bounds[key] = self.constraintList[conName].getBounds()\n            else:\n                bounds[key] = (None, None)",
  "def getConstraintSizes(self, sizes, evalCons=None):\n        \"\"\"\n        Get number for constraint equations in each set.\n        The constraints corresponding to the strings in `evalCons`\n        are evaluated and updated into the provided dictionary.\n\n        Parameters\n        ----------\n        sizes : dict\n            Dictionary into which the constraint sizes are saved.\n        evalCons : iterable object containing strings.\n            If not none, use these constraints to evaluate.\n\n        Examples\n        --------\n        >>> conSizes = {}\n        >>> tacsConstraint.getConstraintSizes(conSizes, 'LE_SPAR')\n        >>> funconSizescs\n        >>> # Result will look like (if TACSConstraint has name of 'c1'):\n        >>> # {'c1_LE_SPAR': 10}\n        \"\"\"\n        # Check if user specified which constraints to output\n        # Otherwise, output them all\n        evalCons = self._processEvalCons(evalCons)\n\n        # Loop through each requested constraint set\n        for conName in evalCons:\n            key = f\"{self.name}_{conName}\"\n            if hasattr(self.constraintList[conName], \"nCon\"):\n                sizes[key] = self.constraintList[conName].nCon\n            else:\n                sizes[key] = 0",
  "def getConstraintKeys(self):\n        \"\"\"\n        Return a list of the current constraint key names\n\n        Returns\n        -------\n        conNames : list[str]\n            List containing user-defined names for constraint groups added so far.\n        \"\"\"\n        return list(self.constraintList.keys())",
  "def evalConstraints(self, funcs, evalCons=None, ignoreMissing=False):\n        \"\"\"\n        Evaluate values for constraints. The constraints corresponding to the strings in\n        evalCons are evaluated and updated into the provided\n        dictionary.\n\n        Parameters\n        ----------\n        funcs : dict\n            Dictionary into which the constraints are saved.\n        evalCons : iterable object containing strings.\n            If not none, use these constraints to evaluate.\n        ignoreMissing : bool\n            Flag to supress checking for a valid constraint. Please use\n            this option with caution.\n\n        Examples\n        --------\n        >>> funcs = {}\n        >>> tacsConstraint.evalConstraints(funcs, 'LE_SPAR')\n        >>> funcs\n        >>> # Result will look like (if TACSConstraint has name of 'c1'):\n        >>> # {'c1_LE_SPAR': array([12354.10])}\n        \"\"\"\n        raise NotImplementedError(\n            f\"'evalConstraints' method is not implemented for class '{type(self).__name__}'\"\n        )",
  "def evalConstraintsSens(self, funcsSens, evalCons=None):\n        \"\"\"\n        This is the main routine for returning useful (sensitivity)\n        information from constraint. The derivatives of the constraints\n        corresponding to the strings in evalCons are evaluated and\n        updated into the provided dictionary. The derivitives with\n        respect to all design variables and node locations are computed.\n\n        Parameters\n        ----------\n        funcsSens : dict\n            Dictionary into which the derivatives are saved.\n        evalCons : iterable object containing strings\n            The constraints the user wants returned\n\n        Examples\n        --------\n        >>> funcsSens = {}\n        >>> tacsConstraint.evalConstraintsSens(funcsSens, 'LE_SPAR')\n        >>> funcsSens\n        >>> # Result will look like (if TACSConstraint has name of 'c1'):\n        >>> # {'c1_LE_SPAR':{'struct':<50x242 sparse matrix of type '<class 'numpy.float64'>' with 100 stored elements in Compressed Sparse Row format>}}\n        \"\"\"\n        raise NotImplementedError(\n            f\"'evalConstraintsSens' method is not implemented for class '{type(self).__name__}'\"\n        )",
  "def _processEvalCons(self, evalCons, ignoreMissing=True):\n        \"\"\"\n        Internal method for processing user-provided evalCons\n\n        Parameters\n        ----------\n        evalCons : iterable object containing strings or None\n            The constraints the user wants returned\n        ignoreMissing : bool\n            Flag to supress checking for a valid constraint.\n            Defaults to True.\n\n        Returns\n        -------\n        conList : list[str]\n            List of constraints the user wants returned\n        \"\"\"\n        # Check if user specified which constraints to output\n        # Otherwise, output them all\n        if evalCons is None:\n            evalCons = self.constraintList\n        else:\n            userCons = sorted(list(evalCons))\n            evalCons = {}\n            for func in userCons:\n                if func in self.constraintList:\n                    evalCons[func] = self.constraintList[func]\n\n        if not ignoreMissing:\n            for f in evalCons:\n                if f not in self.constraintList:\n                    raise self._TACSError(\n                        f\"Supplied constraint '{f}' has not been added \"\n                        \"using addConstraint().\"\n                    )\n\n        return evalCons",
  "def __init__(self, comm, rows, cols, vals, nrows, ncols, lb=-1e20, ub=1e20):\n        # Sparse Jacobian for constraint\n        self.A = sp.sparse.csr_matrix(\n            (vals, (rows, cols)), shape=(nrows, ncols), dtype=self.dtype\n        )\n        # Number of constraints\n        self.nCon = nrows\n        # MPI comm\n        self.comm = comm\n        # Save bound information\n        if isinstance(lb, np.ndarray) and len(lb) == self.nCon:\n            self.lb = lb.astype(self.dtype)\n        elif isinstance(lb, float) or isinstance(lb, complex):\n            self.lb = np.array([lb] * self.nCon, dtype=self.dtype)\n\n        if isinstance(ub, np.ndarray) and len(ub) == self.nCon:\n            self.ub = ub.astype(self.dtype)\n        elif isinstance(ub, float) or isinstance(ub, complex):\n            self.ub = np.array([ub] * self.nCon, dtype=self.dtype)",
  "def evalCon(self, x):\n        conVals = self.comm.allreduce(self.A.dot(x))\n        return conVals",
  "def evalConSens(self, x=None):\n        return self.A.copy()",
  "def getBounds(self):\n        return self.lb.copy(), self.ub.copy()",
  "class VolumeConstraint(TACSConstraint):\n    # Default options for class\n    defaultOptions = {\n        \"volCheckTol\": [\n            float,\n            1e-12,\n            \"Relative tolerance for surface closure check for shell elements.\",\n        ],\n        \"outputDir\": [str, \"./\", \"Output directory for F5 file writer.\"],\n        \"numberSolutions\": [\n            bool,\n            True,\n            \"Flag for attaching solution counter index to f5 files.\",\n        ],\n    }\n\n    def __init__(\n        self,\n        name,\n        assembler,\n        comm,\n        outputViewer=None,\n        meshLoader=None,\n        options=None,\n    ):\n        \"\"\"\n        NOTE: This class should not be initialized directly by the user.\n        Use pyTACS.createVolumeConstraint instead.\n\n        Parameters\n        ----------\n        name : str\n            Name of this tacs problem\n\n        assembler : TACS.Assembler\n            Cython object responsible for creating and setting tacs objects used to solve problem\n\n        comm : mpi4py.MPI.Intracomm\n            The comm object on which to create the pyTACS object.\n\n        outputViewer : TACS.TACSToFH5\n            Cython object used to write out f5 files that can be converted and used for postprocessing.\n\n        meshLoader : pymeshloader.pyMeshLoader\n            pyMeshLoader object used to create the assembler.\n\n        options : dict\n            Dictionary holding problem-specific option parameters (case-insensitive).\n        \"\"\"\n\n        # Problem name\n        self.name = name\n\n        # Default setup for common constraint class objects, sets up comm and options\n        TACSConstraint.__init__(\n            self, assembler, comm, options, outputViewer, meshLoader\n        )\n\n        # Create a list of all adjacent components on root proc\n        self._initializeAdjacencyList()\n\n        # Set call counter\n        self.callCounter = -1\n\n    def _initializeAdjacencyList(self):\n        \"\"\"\n        Create a list of all components with common edges.\n        \"\"\"\n\n        if self.comm.rank == 0:\n            # First, create a dictionary of common edges shared by components\n            edgeToFace = {}\n            for elemID in self.bdfInfo.elements:\n                elemInfo = self.bdfInfo.elements[elemID]\n                elemConn = elemInfo.nodes\n                compID = self.meshLoader.nastranToTACSCompIDDict[elemInfo.pid]\n                nnodes = len(elemConn)\n                if nnodes >= 2:\n                    for j in range(nnodes):\n                        nodeID1 = elemConn[j]\n                        nodeID2 = elemConn[(j + 1) % nnodes]\n\n                        key = (nodeID1, nodeID2)\n\n                        if key not in edgeToFace:\n                            edgeToFace[key] = [compID]\n                        elif compID not in edgeToFace[key]:\n                            edgeToFace[key].append(compID)\n\n            # Now we loop back over each element and each edge. By\n            # using the edgeToFace dictionary, we can now determine\n            # which components IDs (jComp) are connected to the\n            # current component ID (iComp).\n            nComp = self.meshLoader.getNumComponents()\n            self.adjacentOrientationMatch = {compID: {} for compID in range(nComp)}\n\n            # Loop through each shared edge and determine if\n            # components sharing the edge have matching orientations or not\n            for edgeKey in edgeToFace:\n                if len(edgeToFace[edgeKey]) >= 2:\n                    # If this component shares an edge with another component\n                    # that uses the same edge ordering, the normal orientations\n                    # will be inconsistent\n                    for i, iComp in enumerate(edgeToFace[edgeKey][:-1]):\n                        for jComp in edgeToFace[edgeKey][i + 1 :]:\n                            self.adjacentOrientationMatch[iComp][\n                                jComp\n                            ] = self.adjacentOrientationMatch[jComp][iComp] = False\n                # If this component shares an edge with another component\n                # but the edge ordering is reversed, the normal orientations\n                # will be consistent\n                flippedEdgeKey = (edgeKey[1], edgeKey[0])\n                if flippedEdgeKey in edgeToFace:\n                    for iComp in edgeToFace[edgeKey]:\n                        for jComp in edgeToFace[flippedEdgeKey]:\n                            self.adjacentOrientationMatch[iComp][\n                                jComp\n                            ] = self.adjacentOrientationMatch[jComp][iComp] = True\n\n        else:\n            self.adjacentOrientationMatch = None\n\n        # Wait for root\n        self.comm.barrier()\n\n    def addConstraint(self, conName, compIDs=None, lower=0, upper=1e20):\n        \"\"\"\n        Generic method to adding a new constraint set for TACS.\n\n        Parameters\n        ----------\n        conName : str\n            The user-supplied name for the constraint set. This will\n            typically be a string that is meaningful to the user\n\n        compIDs: list[int] or None\n            List of compIDs to select. If None, all compIDs will be selected. Defaults to None.\n\n        lower: float or complex\n            lower bound for constraint. Defaults to 0.0.\n\n        upper: float or complex\n            upper bound for constraint. Defaults to 1e20.\n\n        \"\"\"\n        if compIDs is not None:\n            # Make sure CompIDs is flat and get element numbers on each proc corresponding to specified compIDs\n            compIDs = self._flatten(compIDs)\n        else:\n            nComps = self.meshLoader.getNumComponents()\n            compIDs = list(range(nComps))\n\n        constrObj = self._createConstraint(compIDs, lower, upper)\n        if constrObj.nCon is not None:\n            self.constraintList[conName] = constrObj\n            success = True\n        else:\n            self._TACSWarning(\n                f\"No closed volume found in `compIDs`. Skipping {conName}.\"\n            )\n            success = False\n\n        return success\n\n    def _createConstraint(self, compIDs, lbound, ubound):\n        \"\"\"\n        Create a new constraint object for TACS.\n\n        Parameters\n        ----------\n        compIDs: list[int]\n            List of compIDs to select.\n\n        lbound: float or complex\n            lower bound for constraint. Defaults to 0.0.\n\n        ubound: float or complex\n            upper bound for constraint. Defaults to 1e20.\n\n        Returns\n        -------\n        constraint : ParallelVolumeConstraint or None\n            Constraint object if successful, None otherwise.\n\n        \"\"\"\n        # Check if elements in supplied compIDs are all shell elements or all solid elements\n        elemIDs = self.meshLoader.getGlobalElementIDsForComps(\n            compIDs, nastranOrdering=True\n        )\n        allShells = False\n        allSolids = False\n        for elemID in elemIDs:\n            elemInfo = self.bdfInfo.elements[elemID]\n            if isinstance(elemInfo, pn.cards.elements.shell.ShellElement):\n                if allShells is False:\n                    allShells = True\n\n            elif isinstance(elemInfo, pn.cards.elements.solid.SolidElement):\n                if allSolids is False:\n                    allSolids = True\n\n        if not (allShells or allSolids):\n            self._TACSWarning(\"No shell or solid elements found in provided compIDs.\")\n            return None\n        elif allShells and allSolids:\n            self._TACSWarning(\n                \"Both shell and solid elements were found in compIDs. \"\n                \"Only all-shell or all-solid element meshes are supported.\"\n            )\n            return None\n\n        # Assemble constraint info on root proc\n        if self.comm.rank == 0:\n            properNormalCompIDs = []\n            flippedNormalCompIDs = []\n            # For shell element meshes we have to take an additional step.\n            # All components must have consistent normal directions (normals pointing out)\n            # for the volume calculation to work correctly. In general, this won't be the case.\n            # So we'll need to loop through each component and figure out if their normals need\n            # to be flipped. We'll also need to make sure the provided volume is closed.\n            if allShells:\n                # First, make sure that every component is connected to at least one other component\n                for compID in compIDs:\n                    adjIDs = self.adjacentOrientationMatch[compID].keys()\n                    atLeastOneConnection = False\n                    for adjID in adjIDs:\n                        if adjID in compIDs:\n                            atLeastOneConnection = True\n                            break\n                    if len(compIDs) > 1 and atLeastOneConnection is False:\n                        self._TACSWarning(\n                            \"Provided compID's do not form a closed volume.\"\n                        )\n                        return None\n\n                # Assume that the first component is proper (we'll test this assumption later)\n                currCompID = compIDs[0]\n                properNormalCompIDs.append(currCompID)\n                # Sort the remaining components based on their connectivity and adjacentOrientationMatch dict\n                self._sortIDs(\n                    currCompID, compIDs, properNormalCompIDs, flippedNormalCompIDs\n                )\n\n                # Now we check to make sure the volume is closed\n                # This can be checked by integrating the normal over the surface of the volume.\n                # If the volume is closed, this integral should come out to the zero vector\n                avgNormal = np.zeros(3)\n                volSurfArea = 0.0\n\n                # Make sure bdf is cross-referenced\n                if self.bdfInfo.is_xrefed is False:\n                    self.bdfInfo.cross_reference()\n                    self.bdfInfo.is_xrefed = True\n\n                elemIDs = self.meshLoader.getGlobalElementIDsForComps(\n                    compIDs, nastranOrdering=True\n                )\n                for elemID in elemIDs:\n                    elemInfo = self.bdfInfo.elements[elemID]\n                    compID = self.meshLoader.nastranToTACSCompIDDict[elemInfo.pid]\n                    if compID in properNormalCompIDs:\n                        factor = 1.0\n                    else:  # compID in flippedNormalCompIDs\n                        factor = -1.0\n                    n = elemInfo.Normal()\n                    A = elemInfo.Area()\n                    volSurfArea += A\n                    avgNormal[:] += factor * n * A\n\n                avgNormal /= volSurfArea\n                if np.linalg.norm(avgNormal) > self.getOption(\"volCheckTol\"):\n                    self._TACSWarning(\"Specified volume may not be closed manifold.\")\n\n            # We can treat all components as being proper for solids,\n            # since their volumes don't depend on their normals\n            else:  # allSolids is True\n                properNormalCompIDs = compIDs\n\n        else:  # self.comm.rank != 0\n            properNormalCompIDs = None\n            flippedNormalCompIDs = None\n\n        # Broadcast CompID lists from root\n        properNormalCompIDs = self.comm.bcast(properNormalCompIDs, root=0)\n        flippedNormalCompIDs = self.comm.bcast(flippedNormalCompIDs, root=0)\n\n        return ParallelVolumeConstraint(\n            self.assembler,\n            self.meshLoader,\n            properNormalCompIDs,\n            flippedNormalCompIDs,\n            self.Xpts,\n            lb=lbound,\n            ub=ubound,\n        )\n\n    def _sortIDs(self, currID, compIDs, orient1, orient2):\n        \"\"\"\n        Sort all compIDs into one of two lists (orient1 or orient2), depending on\n        the orientation of their neighbor components. This operation is performed recursively.\n        \"\"\"\n        for adjID in self.adjacentOrientationMatch[currID]:\n            sameOrientation = self.adjacentOrientationMatch[currID][adjID]\n            if adjID not in compIDs:\n                continue\n            elif sameOrientation:\n                if currID in orient1 and adjID not in orient1:\n                    orient1.append(adjID)\n                elif currID in orient2 and adjID not in orient2:\n                    orient2.append(adjID)\n                else:\n                    continue\n            else:  # flipped orientations\n                if currID in orient1 and adjID not in orient2:\n                    orient2.append(adjID)\n                elif currID in orient2 and adjID not in orient1:\n                    orient1.append(adjID)\n                else:\n                    continue\n            self._sortIDs(adjID, compIDs, orient1, orient2)\n\n    def evalConstraints(self, funcs, evalCons=None, ignoreMissing=False):\n        \"\"\"\n        Evaluate values for constraints. The constraints corresponding to the strings in\n        evalCons are evaluated and updated into the provided\n        dictionary.\n\n        Parameters\n        ----------\n        funcs : dict\n            Dictionary into which the constraints are saved.\n        evalCons : iterable object containing strings.\n            If not none, use these constraints to evaluate.\n        ignoreMissing : bool\n            Flag to supress checking for a valid constraint. Please use\n            this option with caution.\n\n        Examples\n        --------\n        >>> funcs = {}\n        >>> volConstraint.evalConstraints(funcs, 'LE_SPAR')\n        >>> funcs\n        >>> # Result will look like (if VolumeConstraint has name of 'c1'):\n        >>> # {'c1_wing': array([12354.10])}\n        \"\"\"\n        # Check if user specified which constraints to output\n        # Otherwise, output them all\n        evalCons = self._processEvalCons(evalCons, ignoreMissing)\n\n        # Loop through each requested constraint set\n        for conName in evalCons:\n            key = f\"{self.name}_{conName}\"\n            funcs[key] = self.constraintList[conName].evalCon(self.Xpts)\n\n        # Update call counter\n        self.callCounter += 1\n\n    def evalConstraintsSens(self, funcsSens, evalCons=None):\n        \"\"\"\n        This is the main routine for returning useful (sensitivity)\n        information from constraint. The derivatives of the constraints\n        corresponding to the strings in evalCons are evaluated and\n        updated into the provided dictionary. The derivitives with\n        respect to all design variables and node locations are computed.\n\n        Parameters\n        ----------\n        funcsSens : dict\n            Dictionary into which the derivatives are saved.\n        evalCons : iterable object containing strings\n            The constraints the user wants returned\n\n        Examples\n        --------\n        >>> funcsSens = {}\n        >>> volConstraint.evalConstraintsSens(funcsSens, 'LE_SPAR')\n        >>> funcsSens\n        >>> # Result will look like (if VolumeConstraint has name of 'c1'):\n        >>> # {'c1_wing':{'struct':<50x242 sparse matrix of type '<class 'numpy.float64'>' with 100 stored elements in Compressed Sparse Row format>}}\n        \"\"\"\n        # Check if user specified which constraints to output\n        # Otherwise, output them all\n        evalCons = self._processEvalCons(evalCons)\n\n        # Get number of dvs/coords on this proc\n        nDVs = self.getNumDesignVars()\n        ncoords = self.getNumCoordinates()\n\n        # Loop through each requested constraint set\n        for conName in evalCons:\n            key = f\"{self.name}_{conName}\"\n            # DV sensitivities are always zero for this constraint,\n            funcsSens[key] = {}\n            funcsSens[key][self.varName] = sp.sparse.csr_matrix(\n                (1, nDVs), dtype=self.dtype\n            )\n\n            # Get nodal sensitivity\n            xptSens = self.constraintList[conName].evalConSens(self.Xpts)\n            xpt_array = xptSens.getArray()\n            # Reshape from 1d array to a 1 by N column vector\n            funcsSens[key][self.coordName] = xpt_array.reshape(1, ncoords)\n\n    def writeVisualization(self, outputDir=None, baseName=None, number=None):\n        \"\"\"\n        This function can be used to write a tecplot file for\n        the purposes of visualization.\n\n        Parameters\n        ----------\n        outputDir : str or None\n            Use the supplied output directory\n        baseName : str or None\n            Use this supplied string for the base filename. Typically\n            only used from an external solver.\n        number : int or None\n            Use the user supplied number to index output. Again, only\n            typically used from an external solver\n        \"\"\"\n\n        # Check input\n        if outputDir is None:\n            outputDir = self.getOption(\"outputDir\")\n\n        if baseName is None:\n            baseName = self.name\n\n        # If we are numbering output, it saving the sequence of\n        # calls, add the call number\n        if number is not None:\n            # We need number based on the provided number:\n            baseName = baseName + \"_%3.3d\" % number\n        else:\n            # if number is none, i.e. standalone, but we need to\n            # number solutions, use internal counter\n            if self.getOption(\"numberSolutions\"):\n                baseName = baseName + \"_%3.3d\" % self.callCounter\n\n        base = os.path.join(outputDir, baseName) + \".dat\"\n\n        # Get current TACS nodes bvec\n        localXpts = self.Xpts.getArray()\n        localXpts = localXpts.reshape(-1, 3)\n\n        # Setup tecplot writer on root\n        if self.comm.rank == 0:\n            tecInfo = tp.Tecplot(debug=None)\n\n        # Loop through each constraint group and write to tecplot zone\n        for constrName, constrObj in self.constraintList.items():\n            # Identify all constrained compIDs\n            posCompIDs = constrObj.posCompIDs\n            negCompIDs = constrObj.negCompIDs\n            allCompIDs = posCompIDs + negCompIDs\n            # Get all global nodeIDs for this constraint\n            allNodeIDsGlobal = self.meshLoader.getGlobalNodeIDsForComps(\n                allCompIDs, nastranOrdering=True\n            )\n            # Find the local node ID corresponding to each global ID on each proc\n            allNodeIDsLocal = self.meshLoader.getLocalNodeIDsFromGlobal(\n                allNodeIDsGlobal, nastranOrdering=True\n            )\n            # Pull the updated xyz values of each node from each proc\n            nodeXYZDict = {}\n            for gID, lID in zip(allNodeIDsGlobal, allNodeIDsLocal):\n                # Node is owned by this proc, add values to dict\n                if lID >= 0:\n                    nodeXYZDict[gID] = localXpts[lID]\n            # Gather node xyz values to root\n            nodeDicts = self.comm.gather(nodeXYZDict, root=0)\n\n            # Write zone data for this constraint\n            if self.comm.rank == 0:\n                # Combine all node dicts received from each proc into a single dict\n                allNodeXYZDict = {}\n                for nodeXYZDict in nodeDicts:\n                    allNodeXYZDict.update(nodeXYZDict)\n\n                # Get all global elemIDs for this constraint\n                allElemIDsGlobal = self.meshLoader.getGlobalElementIDsForComps(\n                    allCompIDs, nastranOrdering=True\n                )\n\n                # Create new zone\n                zoneInfo = Zone(tecInfo.log)\n\n                # Setup header info\n                zoneInfo.title = constrName\n                zoneInfo.headers_dict[\"VARIABLES\"] = [\"X\", \"Y\", \"Z\"]\n\n                # Initialize connectivity/node locations\n                nodeXYZ = []\n                quadConn = []\n                triConn = []\n                hexConn = []\n                tetConn = []\n\n                # Loop through and set up connectivity/node locations\n                currNodeID = 0\n                oldToNewNodeID = {}\n                for elemID in allElemIDsGlobal:\n                    elemInfo = self.bdfInfo.elements[elemID]\n                    compID = self.meshLoader.nastranToTACSCompIDDict[elemInfo.pid]\n                    # Reverse the connectivity if normal is facing inward\n                    if compID in negCompIDs:\n                        elemInfo = copy.deepcopy(elemInfo)\n                        elemInfo.flip_normal()\n                    # We'll need to renumber the nodes to be sequential\n                    oldConn = elemInfo.nodes\n                    newConn = []\n                    for oldNodeID in oldConn:\n                        if oldNodeID not in oldToNewNodeID:\n                            oldToNewNodeID[oldNodeID] = currNodeID\n                            nodeXYZ.append(allNodeXYZDict[oldNodeID])\n                            currNodeID += 1\n                        newNodeID = oldToNewNodeID[oldNodeID]\n                        newConn.append(newNodeID)\n\n                    # Append new connectivity to the appropriate list\n                    if \"CQUAD\" in elemInfo.type:\n                        quadConn.append(newConn)\n                    elif \"CTRI\" in elemInfo.type:\n                        triConn.append(newConn)\n                    elif \"CHEXA\" in elemInfo.type:\n                        hexConn.append(newConn)\n                    elif \"CTETRA\" in elemInfo.type:\n                        tetConn.append(newConn)\n\n                # Set all node/connectivity info to zone\n                zoneInfo.xyz = np.array(nodeXYZ, dtype=float)\n                zoneInfo.quad_elements = np.array(quadConn, dtype=np.intc)\n                zoneInfo.tri_elements = np.array(triConn, dtype=np.intc)\n                zoneInfo.hexa_elements = np.array(hexConn, dtype=np.intc)\n                zoneInfo.tet_elements = np.array(tetConn, dtype=np.intc)\n\n                # Add constraint zone to tecplot file\n                tecInfo.zones.append(zoneInfo)\n\n            # Wait for root\n            self.comm.barrier()\n\n        # Write out tecplot file\n        if self.comm.rank == 0:\n            tecInfo.write_tecplot(base)\n\n        # Wait for root\n        self.comm.barrier()",
  "class ParallelVolumeConstraint(object):\n    dtype = TACSConstraint.dtype\n\n    def __init__(\n        self, assembler, meshLoader, posCompIDs, negCompIDs, Xpts0, lb=0.0, ub=1e20\n    ):\n        # Number of constraints\n        self.nCon = 1\n        self.assembler = assembler\n\n        # Create two TACS Volume function domains,\n        # One for the properly oriented components...\n        if len(posCompIDs) > 0:\n            posVolFunc = EnclosedVolume(self.assembler)\n            elemIDs = meshLoader.getLocalElementIDsForComps(posCompIDs)\n            posVolFunc.setDomain(elemIDs)\n        else:\n            posVolFunc = None\n\n        # and one for the flipped components.\n        # The volumes computed by these components will be negative\n        if len(negCompIDs) > 0:\n            negVolFunc = EnclosedVolume(self.assembler)\n            elemIDs = meshLoader.getLocalElementIDsForComps(negCompIDs)\n            negVolFunc.setDomain(elemIDs)\n        else:\n            negVolFunc = None\n\n        # Compute the volume and check that we sorted the correct orientations\n        self.posCompIDs = posCompIDs\n        self.negCompIDs = negCompIDs\n        self.posVolFunc = posVolFunc\n        self.negVolFunc = negVolFunc\n        vol0 = self.evalCon(Xpts0)\n\n        # If the volume is negative, we need to flip the orientations\n        if vol0 < 0.0:\n            self.posVolFunc, self.negVolFunc = self.negVolFunc, self.posVolFunc\n            self.posCompIDs, self.negCompIDs = self.negCompIDs, self.posCompIDs\n\n        # Save bound information\n        if isinstance(lb, np.ndarray) and len(lb) == self.nCon:\n            self.lb = lb.astype(self.dtype)\n        elif isinstance(lb, float) or isinstance(lb, complex):\n            self.lb = np.array([lb] * self.nCon, dtype=self.dtype)\n\n        if isinstance(ub, np.ndarray) and len(ub) == self.nCon:\n            self.ub = ub.astype(self.dtype)\n        elif isinstance(ub, float) or isinstance(ub, complex):\n            self.ub = np.array([ub] * self.nCon, dtype=self.dtype)\n\n    def evalCon(self, x):\n        self.assembler.setNodes(x)\n        posVol, negVol = self.assembler.evalFunctions(\n            [self.posVolFunc, self.negVolFunc]\n        )\n        totVol = posVol - negVol\n        return totVol\n\n    def evalConSens(self, x):\n        self.assembler.setNodes(x)\n        totSens = self.assembler.createNodeVec()\n        # Compute positive and negative volumes contributions to sens\n        self.assembler.addXptSens([self.posVolFunc], [totSens], 1.0)\n        self.assembler.addXptSens([self.negVolFunc], [totSens], -1.0)\n        # Distribute non-local vals across procs\n        totSens.beginSetValues()\n        totSens.endSetValues()\n        return totSens\n\n    def getBounds(self):\n        return self.lb.copy(), self.ub.copy()",
  "class Zone(tp.Zone):\n    def write_unstructured_zone(\n        self,\n        tecplot_file,\n        ivars,\n        is_points,\n        nnodes,\n        nelements,\n        zone_type,\n        log,\n        is_tris,\n        is_quads,\n        is_tets,\n        is_hexas,\n        adjust_nids=True,\n    ):\n        msg = \"ZONE \"\n        self.log.info(\"is_points = %s\" % is_points)\n        datapacking = \"POINT\" if is_points else \"BLOCK\"\n        # Make sure to include title\n        msg += f' T=\"{self.title}\", n={nnodes:d}, e={nelements:d}, ZONETYPE={zone_type}, DATAPACKING={datapacking}\\n'\n        tecplot_file.write(msg)\n\n        self._write_xyz_results(tecplot_file, is_points, ivars)\n        self._write_elements(\n            tecplot_file,\n            nnodes,\n            is_tris,\n            is_quads,\n            is_tets,\n            is_hexas,\n            adjust_nids=adjust_nids,\n        )",
  "def __init__(\n        self,\n        name,\n        assembler,\n        comm,\n        outputViewer=None,\n        meshLoader=None,\n        options=None,\n    ):\n        \"\"\"\n        NOTE: This class should not be initialized directly by the user.\n        Use pyTACS.createVolumeConstraint instead.\n\n        Parameters\n        ----------\n        name : str\n            Name of this tacs problem\n\n        assembler : TACS.Assembler\n            Cython object responsible for creating and setting tacs objects used to solve problem\n\n        comm : mpi4py.MPI.Intracomm\n            The comm object on which to create the pyTACS object.\n\n        outputViewer : TACS.TACSToFH5\n            Cython object used to write out f5 files that can be converted and used for postprocessing.\n\n        meshLoader : pymeshloader.pyMeshLoader\n            pyMeshLoader object used to create the assembler.\n\n        options : dict\n            Dictionary holding problem-specific option parameters (case-insensitive).\n        \"\"\"\n\n        # Problem name\n        self.name = name\n\n        # Default setup for common constraint class objects, sets up comm and options\n        TACSConstraint.__init__(\n            self, assembler, comm, options, outputViewer, meshLoader\n        )\n\n        # Create a list of all adjacent components on root proc\n        self._initializeAdjacencyList()\n\n        # Set call counter\n        self.callCounter = -1",
  "def _initializeAdjacencyList(self):\n        \"\"\"\n        Create a list of all components with common edges.\n        \"\"\"\n\n        if self.comm.rank == 0:\n            # First, create a dictionary of common edges shared by components\n            edgeToFace = {}\n            for elemID in self.bdfInfo.elements:\n                elemInfo = self.bdfInfo.elements[elemID]\n                elemConn = elemInfo.nodes\n                compID = self.meshLoader.nastranToTACSCompIDDict[elemInfo.pid]\n                nnodes = len(elemConn)\n                if nnodes >= 2:\n                    for j in range(nnodes):\n                        nodeID1 = elemConn[j]\n                        nodeID2 = elemConn[(j + 1) % nnodes]\n\n                        key = (nodeID1, nodeID2)\n\n                        if key not in edgeToFace:\n                            edgeToFace[key] = [compID]\n                        elif compID not in edgeToFace[key]:\n                            edgeToFace[key].append(compID)\n\n            # Now we loop back over each element and each edge. By\n            # using the edgeToFace dictionary, we can now determine\n            # which components IDs (jComp) are connected to the\n            # current component ID (iComp).\n            nComp = self.meshLoader.getNumComponents()\n            self.adjacentOrientationMatch = {compID: {} for compID in range(nComp)}\n\n            # Loop through each shared edge and determine if\n            # components sharing the edge have matching orientations or not\n            for edgeKey in edgeToFace:\n                if len(edgeToFace[edgeKey]) >= 2:\n                    # If this component shares an edge with another component\n                    # that uses the same edge ordering, the normal orientations\n                    # will be inconsistent\n                    for i, iComp in enumerate(edgeToFace[edgeKey][:-1]):\n                        for jComp in edgeToFace[edgeKey][i + 1 :]:\n                            self.adjacentOrientationMatch[iComp][\n                                jComp\n                            ] = self.adjacentOrientationMatch[jComp][iComp] = False\n                # If this component shares an edge with another component\n                # but the edge ordering is reversed, the normal orientations\n                # will be consistent\n                flippedEdgeKey = (edgeKey[1], edgeKey[0])\n                if flippedEdgeKey in edgeToFace:\n                    for iComp in edgeToFace[edgeKey]:\n                        for jComp in edgeToFace[flippedEdgeKey]:\n                            self.adjacentOrientationMatch[iComp][\n                                jComp\n                            ] = self.adjacentOrientationMatch[jComp][iComp] = True\n\n        else:\n            self.adjacentOrientationMatch = None\n\n        # Wait for root\n        self.comm.barrier()",
  "def addConstraint(self, conName, compIDs=None, lower=0, upper=1e20):\n        \"\"\"\n        Generic method to adding a new constraint set for TACS.\n\n        Parameters\n        ----------\n        conName : str\n            The user-supplied name for the constraint set. This will\n            typically be a string that is meaningful to the user\n\n        compIDs: list[int] or None\n            List of compIDs to select. If None, all compIDs will be selected. Defaults to None.\n\n        lower: float or complex\n            lower bound for constraint. Defaults to 0.0.\n\n        upper: float or complex\n            upper bound for constraint. Defaults to 1e20.\n\n        \"\"\"\n        if compIDs is not None:\n            # Make sure CompIDs is flat and get element numbers on each proc corresponding to specified compIDs\n            compIDs = self._flatten(compIDs)\n        else:\n            nComps = self.meshLoader.getNumComponents()\n            compIDs = list(range(nComps))\n\n        constrObj = self._createConstraint(compIDs, lower, upper)\n        if constrObj.nCon is not None:\n            self.constraintList[conName] = constrObj\n            success = True\n        else:\n            self._TACSWarning(\n                f\"No closed volume found in `compIDs`. Skipping {conName}.\"\n            )\n            success = False\n\n        return success",
  "def _createConstraint(self, compIDs, lbound, ubound):\n        \"\"\"\n        Create a new constraint object for TACS.\n\n        Parameters\n        ----------\n        compIDs: list[int]\n            List of compIDs to select.\n\n        lbound: float or complex\n            lower bound for constraint. Defaults to 0.0.\n\n        ubound: float or complex\n            upper bound for constraint. Defaults to 1e20.\n\n        Returns\n        -------\n        constraint : ParallelVolumeConstraint or None\n            Constraint object if successful, None otherwise.\n\n        \"\"\"\n        # Check if elements in supplied compIDs are all shell elements or all solid elements\n        elemIDs = self.meshLoader.getGlobalElementIDsForComps(\n            compIDs, nastranOrdering=True\n        )\n        allShells = False\n        allSolids = False\n        for elemID in elemIDs:\n            elemInfo = self.bdfInfo.elements[elemID]\n            if isinstance(elemInfo, pn.cards.elements.shell.ShellElement):\n                if allShells is False:\n                    allShells = True\n\n            elif isinstance(elemInfo, pn.cards.elements.solid.SolidElement):\n                if allSolids is False:\n                    allSolids = True\n\n        if not (allShells or allSolids):\n            self._TACSWarning(\"No shell or solid elements found in provided compIDs.\")\n            return None\n        elif allShells and allSolids:\n            self._TACSWarning(\n                \"Both shell and solid elements were found in compIDs. \"\n                \"Only all-shell or all-solid element meshes are supported.\"\n            )\n            return None\n\n        # Assemble constraint info on root proc\n        if self.comm.rank == 0:\n            properNormalCompIDs = []\n            flippedNormalCompIDs = []\n            # For shell element meshes we have to take an additional step.\n            # All components must have consistent normal directions (normals pointing out)\n            # for the volume calculation to work correctly. In general, this won't be the case.\n            # So we'll need to loop through each component and figure out if their normals need\n            # to be flipped. We'll also need to make sure the provided volume is closed.\n            if allShells:\n                # First, make sure that every component is connected to at least one other component\n                for compID in compIDs:\n                    adjIDs = self.adjacentOrientationMatch[compID].keys()\n                    atLeastOneConnection = False\n                    for adjID in adjIDs:\n                        if adjID in compIDs:\n                            atLeastOneConnection = True\n                            break\n                    if len(compIDs) > 1 and atLeastOneConnection is False:\n                        self._TACSWarning(\n                            \"Provided compID's do not form a closed volume.\"\n                        )\n                        return None\n\n                # Assume that the first component is proper (we'll test this assumption later)\n                currCompID = compIDs[0]\n                properNormalCompIDs.append(currCompID)\n                # Sort the remaining components based on their connectivity and adjacentOrientationMatch dict\n                self._sortIDs(\n                    currCompID, compIDs, properNormalCompIDs, flippedNormalCompIDs\n                )\n\n                # Now we check to make sure the volume is closed\n                # This can be checked by integrating the normal over the surface of the volume.\n                # If the volume is closed, this integral should come out to the zero vector\n                avgNormal = np.zeros(3)\n                volSurfArea = 0.0\n\n                # Make sure bdf is cross-referenced\n                if self.bdfInfo.is_xrefed is False:\n                    self.bdfInfo.cross_reference()\n                    self.bdfInfo.is_xrefed = True\n\n                elemIDs = self.meshLoader.getGlobalElementIDsForComps(\n                    compIDs, nastranOrdering=True\n                )\n                for elemID in elemIDs:\n                    elemInfo = self.bdfInfo.elements[elemID]\n                    compID = self.meshLoader.nastranToTACSCompIDDict[elemInfo.pid]\n                    if compID in properNormalCompIDs:\n                        factor = 1.0\n                    else:  # compID in flippedNormalCompIDs\n                        factor = -1.0\n                    n = elemInfo.Normal()\n                    A = elemInfo.Area()\n                    volSurfArea += A\n                    avgNormal[:] += factor * n * A\n\n                avgNormal /= volSurfArea\n                if np.linalg.norm(avgNormal) > self.getOption(\"volCheckTol\"):\n                    self._TACSWarning(\"Specified volume may not be closed manifold.\")\n\n            # We can treat all components as being proper for solids,\n            # since their volumes don't depend on their normals\n            else:  # allSolids is True\n                properNormalCompIDs = compIDs\n\n        else:  # self.comm.rank != 0\n            properNormalCompIDs = None\n            flippedNormalCompIDs = None\n\n        # Broadcast CompID lists from root\n        properNormalCompIDs = self.comm.bcast(properNormalCompIDs, root=0)\n        flippedNormalCompIDs = self.comm.bcast(flippedNormalCompIDs, root=0)\n\n        return ParallelVolumeConstraint(\n            self.assembler,\n            self.meshLoader,\n            properNormalCompIDs,\n            flippedNormalCompIDs,\n            self.Xpts,\n            lb=lbound,\n            ub=ubound,\n        )",
  "def _sortIDs(self, currID, compIDs, orient1, orient2):\n        \"\"\"\n        Sort all compIDs into one of two lists (orient1 or orient2), depending on\n        the orientation of their neighbor components. This operation is performed recursively.\n        \"\"\"\n        for adjID in self.adjacentOrientationMatch[currID]:\n            sameOrientation = self.adjacentOrientationMatch[currID][adjID]\n            if adjID not in compIDs:\n                continue\n            elif sameOrientation:\n                if currID in orient1 and adjID not in orient1:\n                    orient1.append(adjID)\n                elif currID in orient2 and adjID not in orient2:\n                    orient2.append(adjID)\n                else:\n                    continue\n            else:  # flipped orientations\n                if currID in orient1 and adjID not in orient2:\n                    orient2.append(adjID)\n                elif currID in orient2 and adjID not in orient1:\n                    orient1.append(adjID)\n                else:\n                    continue\n            self._sortIDs(adjID, compIDs, orient1, orient2)",
  "def evalConstraints(self, funcs, evalCons=None, ignoreMissing=False):\n        \"\"\"\n        Evaluate values for constraints. The constraints corresponding to the strings in\n        evalCons are evaluated and updated into the provided\n        dictionary.\n\n        Parameters\n        ----------\n        funcs : dict\n            Dictionary into which the constraints are saved.\n        evalCons : iterable object containing strings.\n            If not none, use these constraints to evaluate.\n        ignoreMissing : bool\n            Flag to supress checking for a valid constraint. Please use\n            this option with caution.\n\n        Examples\n        --------\n        >>> funcs = {}\n        >>> volConstraint.evalConstraints(funcs, 'LE_SPAR')\n        >>> funcs\n        >>> # Result will look like (if VolumeConstraint has name of 'c1'):\n        >>> # {'c1_wing': array([12354.10])}\n        \"\"\"\n        # Check if user specified which constraints to output\n        # Otherwise, output them all\n        evalCons = self._processEvalCons(evalCons, ignoreMissing)\n\n        # Loop through each requested constraint set\n        for conName in evalCons:\n            key = f\"{self.name}_{conName}\"\n            funcs[key] = self.constraintList[conName].evalCon(self.Xpts)\n\n        # Update call counter\n        self.callCounter += 1",
  "def evalConstraintsSens(self, funcsSens, evalCons=None):\n        \"\"\"\n        This is the main routine for returning useful (sensitivity)\n        information from constraint. The derivatives of the constraints\n        corresponding to the strings in evalCons are evaluated and\n        updated into the provided dictionary. The derivitives with\n        respect to all design variables and node locations are computed.\n\n        Parameters\n        ----------\n        funcsSens : dict\n            Dictionary into which the derivatives are saved.\n        evalCons : iterable object containing strings\n            The constraints the user wants returned\n\n        Examples\n        --------\n        >>> funcsSens = {}\n        >>> volConstraint.evalConstraintsSens(funcsSens, 'LE_SPAR')\n        >>> funcsSens\n        >>> # Result will look like (if VolumeConstraint has name of 'c1'):\n        >>> # {'c1_wing':{'struct':<50x242 sparse matrix of type '<class 'numpy.float64'>' with 100 stored elements in Compressed Sparse Row format>}}\n        \"\"\"\n        # Check if user specified which constraints to output\n        # Otherwise, output them all\n        evalCons = self._processEvalCons(evalCons)\n\n        # Get number of dvs/coords on this proc\n        nDVs = self.getNumDesignVars()\n        ncoords = self.getNumCoordinates()\n\n        # Loop through each requested constraint set\n        for conName in evalCons:\n            key = f\"{self.name}_{conName}\"\n            # DV sensitivities are always zero for this constraint,\n            funcsSens[key] = {}\n            funcsSens[key][self.varName] = sp.sparse.csr_matrix(\n                (1, nDVs), dtype=self.dtype\n            )\n\n            # Get nodal sensitivity\n            xptSens = self.constraintList[conName].evalConSens(self.Xpts)\n            xpt_array = xptSens.getArray()\n            # Reshape from 1d array to a 1 by N column vector\n            funcsSens[key][self.coordName] = xpt_array.reshape(1, ncoords)",
  "def writeVisualization(self, outputDir=None, baseName=None, number=None):\n        \"\"\"\n        This function can be used to write a tecplot file for\n        the purposes of visualization.\n\n        Parameters\n        ----------\n        outputDir : str or None\n            Use the supplied output directory\n        baseName : str or None\n            Use this supplied string for the base filename. Typically\n            only used from an external solver.\n        number : int or None\n            Use the user supplied number to index output. Again, only\n            typically used from an external solver\n        \"\"\"\n\n        # Check input\n        if outputDir is None:\n            outputDir = self.getOption(\"outputDir\")\n\n        if baseName is None:\n            baseName = self.name\n\n        # If we are numbering output, it saving the sequence of\n        # calls, add the call number\n        if number is not None:\n            # We need number based on the provided number:\n            baseName = baseName + \"_%3.3d\" % number\n        else:\n            # if number is none, i.e. standalone, but we need to\n            # number solutions, use internal counter\n            if self.getOption(\"numberSolutions\"):\n                baseName = baseName + \"_%3.3d\" % self.callCounter\n\n        base = os.path.join(outputDir, baseName) + \".dat\"\n\n        # Get current TACS nodes bvec\n        localXpts = self.Xpts.getArray()\n        localXpts = localXpts.reshape(-1, 3)\n\n        # Setup tecplot writer on root\n        if self.comm.rank == 0:\n            tecInfo = tp.Tecplot(debug=None)\n\n        # Loop through each constraint group and write to tecplot zone\n        for constrName, constrObj in self.constraintList.items():\n            # Identify all constrained compIDs\n            posCompIDs = constrObj.posCompIDs\n            negCompIDs = constrObj.negCompIDs\n            allCompIDs = posCompIDs + negCompIDs\n            # Get all global nodeIDs for this constraint\n            allNodeIDsGlobal = self.meshLoader.getGlobalNodeIDsForComps(\n                allCompIDs, nastranOrdering=True\n            )\n            # Find the local node ID corresponding to each global ID on each proc\n            allNodeIDsLocal = self.meshLoader.getLocalNodeIDsFromGlobal(\n                allNodeIDsGlobal, nastranOrdering=True\n            )\n            # Pull the updated xyz values of each node from each proc\n            nodeXYZDict = {}\n            for gID, lID in zip(allNodeIDsGlobal, allNodeIDsLocal):\n                # Node is owned by this proc, add values to dict\n                if lID >= 0:\n                    nodeXYZDict[gID] = localXpts[lID]\n            # Gather node xyz values to root\n            nodeDicts = self.comm.gather(nodeXYZDict, root=0)\n\n            # Write zone data for this constraint\n            if self.comm.rank == 0:\n                # Combine all node dicts received from each proc into a single dict\n                allNodeXYZDict = {}\n                for nodeXYZDict in nodeDicts:\n                    allNodeXYZDict.update(nodeXYZDict)\n\n                # Get all global elemIDs for this constraint\n                allElemIDsGlobal = self.meshLoader.getGlobalElementIDsForComps(\n                    allCompIDs, nastranOrdering=True\n                )\n\n                # Create new zone\n                zoneInfo = Zone(tecInfo.log)\n\n                # Setup header info\n                zoneInfo.title = constrName\n                zoneInfo.headers_dict[\"VARIABLES\"] = [\"X\", \"Y\", \"Z\"]\n\n                # Initialize connectivity/node locations\n                nodeXYZ = []\n                quadConn = []\n                triConn = []\n                hexConn = []\n                tetConn = []\n\n                # Loop through and set up connectivity/node locations\n                currNodeID = 0\n                oldToNewNodeID = {}\n                for elemID in allElemIDsGlobal:\n                    elemInfo = self.bdfInfo.elements[elemID]\n                    compID = self.meshLoader.nastranToTACSCompIDDict[elemInfo.pid]\n                    # Reverse the connectivity if normal is facing inward\n                    if compID in negCompIDs:\n                        elemInfo = copy.deepcopy(elemInfo)\n                        elemInfo.flip_normal()\n                    # We'll need to renumber the nodes to be sequential\n                    oldConn = elemInfo.nodes\n                    newConn = []\n                    for oldNodeID in oldConn:\n                        if oldNodeID not in oldToNewNodeID:\n                            oldToNewNodeID[oldNodeID] = currNodeID\n                            nodeXYZ.append(allNodeXYZDict[oldNodeID])\n                            currNodeID += 1\n                        newNodeID = oldToNewNodeID[oldNodeID]\n                        newConn.append(newNodeID)\n\n                    # Append new connectivity to the appropriate list\n                    if \"CQUAD\" in elemInfo.type:\n                        quadConn.append(newConn)\n                    elif \"CTRI\" in elemInfo.type:\n                        triConn.append(newConn)\n                    elif \"CHEXA\" in elemInfo.type:\n                        hexConn.append(newConn)\n                    elif \"CTETRA\" in elemInfo.type:\n                        tetConn.append(newConn)\n\n                # Set all node/connectivity info to zone\n                zoneInfo.xyz = np.array(nodeXYZ, dtype=float)\n                zoneInfo.quad_elements = np.array(quadConn, dtype=np.intc)\n                zoneInfo.tri_elements = np.array(triConn, dtype=np.intc)\n                zoneInfo.hexa_elements = np.array(hexConn, dtype=np.intc)\n                zoneInfo.tet_elements = np.array(tetConn, dtype=np.intc)\n\n                # Add constraint zone to tecplot file\n                tecInfo.zones.append(zoneInfo)\n\n            # Wait for root\n            self.comm.barrier()\n\n        # Write out tecplot file\n        if self.comm.rank == 0:\n            tecInfo.write_tecplot(base)\n\n        # Wait for root\n        self.comm.barrier()",
  "def __init__(\n        self, assembler, meshLoader, posCompIDs, negCompIDs, Xpts0, lb=0.0, ub=1e20\n    ):\n        # Number of constraints\n        self.nCon = 1\n        self.assembler = assembler\n\n        # Create two TACS Volume function domains,\n        # One for the properly oriented components...\n        if len(posCompIDs) > 0:\n            posVolFunc = EnclosedVolume(self.assembler)\n            elemIDs = meshLoader.getLocalElementIDsForComps(posCompIDs)\n            posVolFunc.setDomain(elemIDs)\n        else:\n            posVolFunc = None\n\n        # and one for the flipped components.\n        # The volumes computed by these components will be negative\n        if len(negCompIDs) > 0:\n            negVolFunc = EnclosedVolume(self.assembler)\n            elemIDs = meshLoader.getLocalElementIDsForComps(negCompIDs)\n            negVolFunc.setDomain(elemIDs)\n        else:\n            negVolFunc = None\n\n        # Compute the volume and check that we sorted the correct orientations\n        self.posCompIDs = posCompIDs\n        self.negCompIDs = negCompIDs\n        self.posVolFunc = posVolFunc\n        self.negVolFunc = negVolFunc\n        vol0 = self.evalCon(Xpts0)\n\n        # If the volume is negative, we need to flip the orientations\n        if vol0 < 0.0:\n            self.posVolFunc, self.negVolFunc = self.negVolFunc, self.posVolFunc\n            self.posCompIDs, self.negCompIDs = self.negCompIDs, self.posCompIDs\n\n        # Save bound information\n        if isinstance(lb, np.ndarray) and len(lb) == self.nCon:\n            self.lb = lb.astype(self.dtype)\n        elif isinstance(lb, float) or isinstance(lb, complex):\n            self.lb = np.array([lb] * self.nCon, dtype=self.dtype)\n\n        if isinstance(ub, np.ndarray) and len(ub) == self.nCon:\n            self.ub = ub.astype(self.dtype)\n        elif isinstance(ub, float) or isinstance(ub, complex):\n            self.ub = np.array([ub] * self.nCon, dtype=self.dtype)",
  "def evalCon(self, x):\n        self.assembler.setNodes(x)\n        posVol, negVol = self.assembler.evalFunctions(\n            [self.posVolFunc, self.negVolFunc]\n        )\n        totVol = posVol - negVol\n        return totVol",
  "def evalConSens(self, x):\n        self.assembler.setNodes(x)\n        totSens = self.assembler.createNodeVec()\n        # Compute positive and negative volumes contributions to sens\n        self.assembler.addXptSens([self.posVolFunc], [totSens], 1.0)\n        self.assembler.addXptSens([self.negVolFunc], [totSens], -1.0)\n        # Distribute non-local vals across procs\n        totSens.beginSetValues()\n        totSens.endSetValues()\n        return totSens",
  "def getBounds(self):\n        return self.lb.copy(), self.ub.copy()",
  "def write_unstructured_zone(\n        self,\n        tecplot_file,\n        ivars,\n        is_points,\n        nnodes,\n        nelements,\n        zone_type,\n        log,\n        is_tris,\n        is_quads,\n        is_tets,\n        is_hexas,\n        adjust_nids=True,\n    ):\n        msg = \"ZONE \"\n        self.log.info(\"is_points = %s\" % is_points)\n        datapacking = \"POINT\" if is_points else \"BLOCK\"\n        # Make sure to include title\n        msg += f' T=\"{self.title}\", n={nnodes:d}, e={nelements:d}, ZONETYPE={zone_type}, DATAPACKING={datapacking}\\n'\n        tecplot_file.write(msg)\n\n        self._write_xyz_results(tecplot_file, is_points, ivars)\n        self._write_elements(\n            tecplot_file,\n            nnodes,\n            is_tris,\n            is_quads,\n            is_tets,\n            is_hexas,\n            adjust_nids=adjust_nids,\n        )",
  "class AdjacencyConstraint(TACSConstraint):\n    # Default options for class\n    defaultOptions = {\n        \"outputDir\": [str, \"./\", \"Output directory for F5 file writer.\"],\n        \"numberSolutions\": [\n            bool,\n            True,\n            \"Flag for attaching solution counter index to f5 files.\",\n        ],\n    }\n\n    def __init__(\n        self,\n        name,\n        assembler,\n        comm,\n        outputViewer=None,\n        meshLoader=None,\n        options=None,\n    ):\n        \"\"\"\n        NOTE: This class should not be initialized directly by the user.\n        Use pyTACS.createAdjacencyConstraint instead.\n\n        Parameters\n        ----------\n        name : str\n            Name of this tacs problem\n\n        assembler : TACS.Assembler\n            Cython object responsible for creating and setting tacs objects used to solve problem\n\n        comm : mpi4py.MPI.Intracomm\n            The comm object on which to create the pyTACS object.\n\n        outputViewer : TACS.TACSToFH5\n            Cython object used to write out f5 files that can be converted and used for postprocessing.\n\n        meshLoader : pymeshloader.pyMeshLoader\n            pyMeshLoader object used to create the assembler.\n\n        options : dict\n            Dictionary holding problem-specific option parameters (case-insensitive).\n        \"\"\"\n\n        # Problem name\n        self.name = name\n\n        # Default setup for common constraint class objects, sets up comm and options\n        TACSConstraint.__init__(\n            self, assembler, comm, options, outputViewer, meshLoader\n        )\n\n        # Create a list of all adjacent components on root proc\n        self._initializeAdjacencyList()\n\n        # Set call counter\n        self.callCounter = -1\n\n    def _initializeAdjacencyList(self):\n        \"\"\"\n        Create a list of all components with common edges.\n        \"\"\"\n\n        if self.comm.rank == 0:\n            # First, create a dictionary of common edges shared by components\n            edgeToFace = {}\n            for elemID in self.bdfInfo.elements:\n                elemInfo = self.bdfInfo.elements[elemID]\n                elemConn = elemInfo.nodes\n                compID = self.meshLoader.nastranToTACSCompIDDict[elemInfo.pid]\n                nnodes = len(elemConn)\n                if nnodes >= 2:\n                    for j in range(nnodes):\n                        nodeID1 = elemConn[j]\n                        nodeID2 = elemConn[(j + 1) % nnodes]\n\n                        if nodeID1 < nodeID2:\n                            key = (nodeID1, nodeID2)\n                        else:\n                            key = (nodeID2, nodeID1)\n\n                        if key not in edgeToFace:\n                            edgeToFace[key] = [compID]\n                        elif compID not in edgeToFace[key]:\n                            edgeToFace[key].append(compID)\n\n            # Now we loop back over each element and each edge. By\n            # using the edgeToFace dictionary, we can now determine\n            # which components IDs (jComp) are connected to the\n            # current component ID (iComp).\n            self.adjacentComps = []\n\n            for edgeKey in edgeToFace:\n                if len(edgeToFace[edgeKey]) >= 2:\n                    for i, iComp in enumerate(edgeToFace[edgeKey][:-1]):\n                        for jComp in edgeToFace[edgeKey][i + 1 :]:\n                            if iComp < jComp:\n                                dvKey = (iComp, jComp)\n                            else:\n                                dvKey = (jComp, iComp)\n                            if dvKey not in self.adjacentComps:\n                                self.adjacentComps.append(dvKey)\n\n        else:\n            self.adjacentComps = None\n\n        # Wait for root\n        self.comm.barrier()\n\n    def addConstraint(self, conName, compIDs=None, lower=-1e20, upper=1e20, dvIndex=0):\n        \"\"\"\n        Generic method to adding a new constraint set for TACS.\n\n        Parameters\n        ----------\n        conName : str\n            The user-supplied name for the constraint set. This will\n            typically be a string that is meaningful to the user\n\n        compIDs: list[int] or None\n            List of compIDs to select. If None, all compIDs will be selected. Defaults to None.\n\n        lower: float or complex\n            lower bound for constraint. Defaults to -1e20.\n\n        upper: float or complex\n            upper bound for constraint. Defaults to 1e20.\n\n        dvIndex : int\n            Index number of element DV to be used in constraint. Defaults to 0.\n\n        \"\"\"\n        if compIDs is not None:\n            # Make sure CompIDs is flat and get element numbers on each proc corresponding to specified compIDs\n            compIDs = self._flatten(compIDs)\n        else:\n            nComps = self.meshLoader.getNumComponents()\n            compIDs = list(range(nComps))\n\n        constrObj = self._createConstraint(dvIndex, compIDs, lower, upper)\n        if constrObj.nCon > 0:\n            self.constraintList[conName] = constrObj\n            success = True\n        else:\n            self._TACSWarning(\n                f\"No adjacent components found in `compIDs`. Skipping {conName}.\"\n            )\n            success = False\n\n        return success\n\n    def _createConstraint(self, dvIndex, compIDs, lbound, ubound):\n        \"\"\"\n        Create a new constraint object for TACS.\n\n        Parameters\n        ----------\n        dvIndex : int\n            Index number of element DV to be used in constraint.\n\n        compIDs: list[int]\n            List of compIDs to select.\n\n        lbound: float or complex\n            lower bound for constraint. Defaults to 0.0.\n\n        ubound: float or complex\n            upper bound for constraint. Defaults to 1e20.\n\n        Returns\n        -------\n        constraint : tacs.constraints.base.SparseLinearConstraint or None\n            Constraint object if successful, None otherwise.\n\n        \"\"\"\n        size = self.comm.size\n        rank = self.comm.rank\n        # Gather the dv mapping from each proc\n        globalToLocalDVNumsOnProc = self.comm.gather(self.globalToLocalDVNums, root=0)\n        # Assemble constraint info on root proc\n        if rank == 0:\n            # Create a list of lists that will hold the sparse data info on each proc\n            rowsOnProc = [[] for _ in range(size)]\n            colsOnProc = [[] for _ in range(size)]\n            valsOnProc = [[] for _ in range(size)]\n            conCount = 0\n            foundCompPairs = []\n            # Loop through all adjacent component pairs\n            for compPair in self.adjacentComps:\n                # Check if they are in the user provided compIDs\n                if compPair[0] in compIDs and compPair[1] in compIDs:\n                    # Add comp pair to list\n                    foundCompPairs.append(compPair)\n                    # We found a new constraint\n                    for i, comp in enumerate(compPair):\n                        # Get the TACS element object associated with this compID\n                        elemObj = self.meshLoader.getElementObject(comp, 0)\n                        elemIndex = 0\n                        # Get the dvs owned by this element\n                        globalDvNums = elemObj.getDesignVarNums(elemIndex)\n                        # Check if specified dv num is owned by each proc\n                        for proc_i in range(size):\n                            globalToLocalDVNums = globalToLocalDVNumsOnProc[proc_i]\n                            if globalDvNums[dvIndex] in globalToLocalDVNums:\n                                globalDVNum = globalDvNums[dvIndex]\n                                localDVNum = globalToLocalDVNums[globalDVNum]\n                                rowsOnProc[proc_i].append(conCount)\n                                colsOnProc[proc_i].append(localDVNum)\n                                if i == 0:\n                                    valsOnProc[proc_i].append(1.0)\n                                else:\n                                    valsOnProc[proc_i].append(-1.0)\n                                break\n                    conCount += 1\n\n        else:\n            rowsOnProc = None\n            colsOnProc = None\n            valsOnProc = None\n            conCount = 0\n            foundCompPairs = None\n\n        # Scatter local sparse indices/values to remaining procs\n        rows = self.comm.scatter(rowsOnProc, root=0)\n        cols = self.comm.scatter(colsOnProc, root=0)\n        vals = self.comm.scatter(valsOnProc, root=0)\n\n        # Get local sparse matrix dimensions\n        foundCompPairs = self.comm.bcast(foundCompPairs, root=0)\n        conCount = self.comm.bcast(conCount, root=0)\n        nLocalDVs = self.getNumDesignVars()\n\n        constrObj = SparseLinearConstraint(\n            self.comm, rows, cols, vals, conCount, nLocalDVs, lbound, ubound\n        )\n        constrObj.compPairs = foundCompPairs\n\n        # Create linear constraint object\n        return constrObj\n\n    def evalConstraints(self, funcs, evalCons=None, ignoreMissing=False):\n        \"\"\"\n        Evaluate values for constraints. The constraints corresponding to the strings in\n        evalCons are evaluated and updated into the provided\n        dictionary.\n\n        Parameters\n        ----------\n        funcs : dict\n            Dictionary into which the constraints are saved.\n        evalCons : iterable object containing strings.\n            If not none, use these constraints to evaluate.\n        ignoreMissing : bool\n            Flag to supress checking for a valid constraint. Please use\n            this option with caution.\n\n        Examples\n        --------\n        >>> funcs = {}\n        >>> adjConstraint.evalConstraints(funcs, 'LE_SPAR')\n        >>> funcs\n        >>> # Result will look like (if AdjacencyConstraint has name of 'c1'):\n        >>> # {'c1_LE_SPAR': array([12354.10])}\n        \"\"\"\n        # Check if user specified which constraints to output\n        # Otherwise, output them all\n        evalCons = self._processEvalCons(evalCons, ignoreMissing)\n\n        # Loop through each requested constraint set\n        for conName in evalCons:\n            key = f\"{self.name}_{conName}\"\n            funcs[key] = self.constraintList[conName].evalCon(self.x.getArray())\n\n        # Update call counter\n        self.callCounter += 1\n\n    def evalConstraintsSens(self, funcsSens, evalCons=None):\n        \"\"\"\n        This is the main routine for returning useful (sensitivity)\n        information from constraint. The derivatives of the constraints\n        corresponding to the strings in evalCons are evaluated and\n        updated into the provided dictionary. The derivitives with\n        respect to all design variables and node locations are computed.\n\n        Parameters\n        ----------\n        funcsSens : dict\n            Dictionary into which the derivatives are saved.\n        evalCons : iterable object containing strings\n            The constraints the user wants returned\n\n        Examples\n        --------\n        >>> funcsSens = {}\n        >>> adjConstraint.evalConstraintsSens(funcsSens, 'LE_SPAR')\n        >>> funcsSens\n        >>> # Result will look like (if AdjacencyConstraint has name of 'c1'):\n        >>> # {'c1_LE_SPAR':{'struct':<50x242 sparse matrix of type '<class 'numpy.float64'>' with 100 stored elements in Compressed Sparse Row format>}}\n        \"\"\"\n        # Check if user specified which constraints to output\n        # Otherwise, output them all\n        evalCons = self._processEvalCons(evalCons)\n\n        # Get number of nodes coords on this proc\n        nCoords = self.getNumCoordinates()\n\n        # Loop through each requested constraint set\n        for conName in evalCons:\n            key = f\"{self.name}_{conName}\"\n            # Get sparse Jacobian for dv sensitivity\n            funcsSens[key] = {}\n            funcsSens[key][self.varName] = self.constraintList[conName].evalConSens(\n                self.x.getArray()\n            )\n\n            # Nodal sensitivities are always zero for this constraint,\n            # Add an empty sparse matrix\n            nCon = self.constraintList[conName].nCon\n            funcsSens[key][self.coordName] = sp.sparse.csr_matrix(\n                (nCon, nCoords), dtype=self.dtype\n            )\n\n    def writeVisualization(self, outputDir=None, baseName=None, number=None):\n        \"\"\"\n        This function can be used to write a tecplot file for\n        the purposes of visualization.\n\n        Parameters\n        ----------\n        outputDir : str or None\n            Use the supplied output directory\n        baseName : str or None\n            Use this supplied string for the base filename. Typically\n            only used from an external solver.\n        number : int or None\n            Use the user supplied number to index output. Again, only\n            typically used from an external solver\n        \"\"\"\n        # Check input\n        if outputDir is None:\n            outputDir = self.getOption(\"outputDir\")\n\n        if baseName is None:\n            baseName = self.name\n\n        # If we are numbering output, it saving the sequence of\n        # calls, add the call number\n        if number is not None:\n            # We need number based on the provided number:\n            baseName = baseName + \"_%3.3d\" % number\n        else:\n            # if number is none, i.e. standalone, but we need to\n            # number solutions, use internal counter\n            if self.getOption(\"numberSolutions\"):\n                baseName = baseName + \"_%3.3d\" % self.callCounter\n\n        base = os.path.join(outputDir, baseName) + \".dat\"\n\n        if self.comm.rank == 0:\n            f = open(base, \"w\")\n            f.write('VARIABLES = \"X\", \"Y\", \"Z\"\\n')\n\n        # Get current node locations\n        Xpts_local = self.Xpts.getArray()\n        Xpts_local = Xpts_local.reshape(-1, 3)\n\n        for constrName, constrObj in self.constraintList.items():\n            i = 0\n            for compPair in constrObj.compPairs:\n                # Get the 'average' location for each component in the dvGroup\n                compCenters = np.zeros([2, 3], dtype=float)\n                for j, compID in enumerate(compPair):\n                    nodeIDsGlobal = self.meshLoader.getGlobalNodeIDsForComps(\n                        [compID], nastranOrdering=True\n                    )\n                    nodeIDsLocal = self.meshLoader.getLocalNodeIDsFromGlobal(\n                        nodeIDsGlobal, nastranOrdering=True\n                    )\n                    for lID in nodeIDsLocal:\n                        if lID >= 0:\n                            compCenters[j] += np.real(Xpts_local[lID])\n                    compCenters[j] = self.comm.allreduce(compCenters[j])\n                    nnodes = len(nodeIDsGlobal)\n                    compCenters[j] /= nnodes\n\n                if self.comm.rank == 0:\n                    f.write(f\"Zone T={constrName}_{i}\\n\")\n                    f.write(\"Nodes = 2, Elements = 1 ZONETYPE=FELINESEG\\n\")\n                    f.write(\"DATAPACKING=POINT\\n\")\n                    for ii in range(2):\n                        f.write(\n                            \"%g %g %g\\n\"\n                            % (\n                                compCenters[ii, 0],\n                                compCenters[ii, 1],\n                                compCenters[ii, 2],\n                            )\n                        )\n                    f.write(\"1 2\\n\")  # Connectivity\n\n                # Wait for root\n                self.comm.barrier()\n                i += 1\n\n        if self.comm.rank == 0:\n            f.close()\n\n        # Wait for root\n        self.comm.barrier()",
  "def __init__(\n        self,\n        name,\n        assembler,\n        comm,\n        outputViewer=None,\n        meshLoader=None,\n        options=None,\n    ):\n        \"\"\"\n        NOTE: This class should not be initialized directly by the user.\n        Use pyTACS.createAdjacencyConstraint instead.\n\n        Parameters\n        ----------\n        name : str\n            Name of this tacs problem\n\n        assembler : TACS.Assembler\n            Cython object responsible for creating and setting tacs objects used to solve problem\n\n        comm : mpi4py.MPI.Intracomm\n            The comm object on which to create the pyTACS object.\n\n        outputViewer : TACS.TACSToFH5\n            Cython object used to write out f5 files that can be converted and used for postprocessing.\n\n        meshLoader : pymeshloader.pyMeshLoader\n            pyMeshLoader object used to create the assembler.\n\n        options : dict\n            Dictionary holding problem-specific option parameters (case-insensitive).\n        \"\"\"\n\n        # Problem name\n        self.name = name\n\n        # Default setup for common constraint class objects, sets up comm and options\n        TACSConstraint.__init__(\n            self, assembler, comm, options, outputViewer, meshLoader\n        )\n\n        # Create a list of all adjacent components on root proc\n        self._initializeAdjacencyList()\n\n        # Set call counter\n        self.callCounter = -1",
  "def _initializeAdjacencyList(self):\n        \"\"\"\n        Create a list of all components with common edges.\n        \"\"\"\n\n        if self.comm.rank == 0:\n            # First, create a dictionary of common edges shared by components\n            edgeToFace = {}\n            for elemID in self.bdfInfo.elements:\n                elemInfo = self.bdfInfo.elements[elemID]\n                elemConn = elemInfo.nodes\n                compID = self.meshLoader.nastranToTACSCompIDDict[elemInfo.pid]\n                nnodes = len(elemConn)\n                if nnodes >= 2:\n                    for j in range(nnodes):\n                        nodeID1 = elemConn[j]\n                        nodeID2 = elemConn[(j + 1) % nnodes]\n\n                        if nodeID1 < nodeID2:\n                            key = (nodeID1, nodeID2)\n                        else:\n                            key = (nodeID2, nodeID1)\n\n                        if key not in edgeToFace:\n                            edgeToFace[key] = [compID]\n                        elif compID not in edgeToFace[key]:\n                            edgeToFace[key].append(compID)\n\n            # Now we loop back over each element and each edge. By\n            # using the edgeToFace dictionary, we can now determine\n            # which components IDs (jComp) are connected to the\n            # current component ID (iComp).\n            self.adjacentComps = []\n\n            for edgeKey in edgeToFace:\n                if len(edgeToFace[edgeKey]) >= 2:\n                    for i, iComp in enumerate(edgeToFace[edgeKey][:-1]):\n                        for jComp in edgeToFace[edgeKey][i + 1 :]:\n                            if iComp < jComp:\n                                dvKey = (iComp, jComp)\n                            else:\n                                dvKey = (jComp, iComp)\n                            if dvKey not in self.adjacentComps:\n                                self.adjacentComps.append(dvKey)\n\n        else:\n            self.adjacentComps = None\n\n        # Wait for root\n        self.comm.barrier()",
  "def addConstraint(self, conName, compIDs=None, lower=-1e20, upper=1e20, dvIndex=0):\n        \"\"\"\n        Generic method to adding a new constraint set for TACS.\n\n        Parameters\n        ----------\n        conName : str\n            The user-supplied name for the constraint set. This will\n            typically be a string that is meaningful to the user\n\n        compIDs: list[int] or None\n            List of compIDs to select. If None, all compIDs will be selected. Defaults to None.\n\n        lower: float or complex\n            lower bound for constraint. Defaults to -1e20.\n\n        upper: float or complex\n            upper bound for constraint. Defaults to 1e20.\n\n        dvIndex : int\n            Index number of element DV to be used in constraint. Defaults to 0.\n\n        \"\"\"\n        if compIDs is not None:\n            # Make sure CompIDs is flat and get element numbers on each proc corresponding to specified compIDs\n            compIDs = self._flatten(compIDs)\n        else:\n            nComps = self.meshLoader.getNumComponents()\n            compIDs = list(range(nComps))\n\n        constrObj = self._createConstraint(dvIndex, compIDs, lower, upper)\n        if constrObj.nCon > 0:\n            self.constraintList[conName] = constrObj\n            success = True\n        else:\n            self._TACSWarning(\n                f\"No adjacent components found in `compIDs`. Skipping {conName}.\"\n            )\n            success = False\n\n        return success",
  "def _createConstraint(self, dvIndex, compIDs, lbound, ubound):\n        \"\"\"\n        Create a new constraint object for TACS.\n\n        Parameters\n        ----------\n        dvIndex : int\n            Index number of element DV to be used in constraint.\n\n        compIDs: list[int]\n            List of compIDs to select.\n\n        lbound: float or complex\n            lower bound for constraint. Defaults to 0.0.\n\n        ubound: float or complex\n            upper bound for constraint. Defaults to 1e20.\n\n        Returns\n        -------\n        constraint : tacs.constraints.base.SparseLinearConstraint or None\n            Constraint object if successful, None otherwise.\n\n        \"\"\"\n        size = self.comm.size\n        rank = self.comm.rank\n        # Gather the dv mapping from each proc\n        globalToLocalDVNumsOnProc = self.comm.gather(self.globalToLocalDVNums, root=0)\n        # Assemble constraint info on root proc\n        if rank == 0:\n            # Create a list of lists that will hold the sparse data info on each proc\n            rowsOnProc = [[] for _ in range(size)]\n            colsOnProc = [[] for _ in range(size)]\n            valsOnProc = [[] for _ in range(size)]\n            conCount = 0\n            foundCompPairs = []\n            # Loop through all adjacent component pairs\n            for compPair in self.adjacentComps:\n                # Check if they are in the user provided compIDs\n                if compPair[0] in compIDs and compPair[1] in compIDs:\n                    # Add comp pair to list\n                    foundCompPairs.append(compPair)\n                    # We found a new constraint\n                    for i, comp in enumerate(compPair):\n                        # Get the TACS element object associated with this compID\n                        elemObj = self.meshLoader.getElementObject(comp, 0)\n                        elemIndex = 0\n                        # Get the dvs owned by this element\n                        globalDvNums = elemObj.getDesignVarNums(elemIndex)\n                        # Check if specified dv num is owned by each proc\n                        for proc_i in range(size):\n                            globalToLocalDVNums = globalToLocalDVNumsOnProc[proc_i]\n                            if globalDvNums[dvIndex] in globalToLocalDVNums:\n                                globalDVNum = globalDvNums[dvIndex]\n                                localDVNum = globalToLocalDVNums[globalDVNum]\n                                rowsOnProc[proc_i].append(conCount)\n                                colsOnProc[proc_i].append(localDVNum)\n                                if i == 0:\n                                    valsOnProc[proc_i].append(1.0)\n                                else:\n                                    valsOnProc[proc_i].append(-1.0)\n                                break\n                    conCount += 1\n\n        else:\n            rowsOnProc = None\n            colsOnProc = None\n            valsOnProc = None\n            conCount = 0\n            foundCompPairs = None\n\n        # Scatter local sparse indices/values to remaining procs\n        rows = self.comm.scatter(rowsOnProc, root=0)\n        cols = self.comm.scatter(colsOnProc, root=0)\n        vals = self.comm.scatter(valsOnProc, root=0)\n\n        # Get local sparse matrix dimensions\n        foundCompPairs = self.comm.bcast(foundCompPairs, root=0)\n        conCount = self.comm.bcast(conCount, root=0)\n        nLocalDVs = self.getNumDesignVars()\n\n        constrObj = SparseLinearConstraint(\n            self.comm, rows, cols, vals, conCount, nLocalDVs, lbound, ubound\n        )\n        constrObj.compPairs = foundCompPairs\n\n        # Create linear constraint object\n        return constrObj",
  "def evalConstraints(self, funcs, evalCons=None, ignoreMissing=False):\n        \"\"\"\n        Evaluate values for constraints. The constraints corresponding to the strings in\n        evalCons are evaluated and updated into the provided\n        dictionary.\n\n        Parameters\n        ----------\n        funcs : dict\n            Dictionary into which the constraints are saved.\n        evalCons : iterable object containing strings.\n            If not none, use these constraints to evaluate.\n        ignoreMissing : bool\n            Flag to supress checking for a valid constraint. Please use\n            this option with caution.\n\n        Examples\n        --------\n        >>> funcs = {}\n        >>> adjConstraint.evalConstraints(funcs, 'LE_SPAR')\n        >>> funcs\n        >>> # Result will look like (if AdjacencyConstraint has name of 'c1'):\n        >>> # {'c1_LE_SPAR': array([12354.10])}\n        \"\"\"\n        # Check if user specified which constraints to output\n        # Otherwise, output them all\n        evalCons = self._processEvalCons(evalCons, ignoreMissing)\n\n        # Loop through each requested constraint set\n        for conName in evalCons:\n            key = f\"{self.name}_{conName}\"\n            funcs[key] = self.constraintList[conName].evalCon(self.x.getArray())\n\n        # Update call counter\n        self.callCounter += 1",
  "def evalConstraintsSens(self, funcsSens, evalCons=None):\n        \"\"\"\n        This is the main routine for returning useful (sensitivity)\n        information from constraint. The derivatives of the constraints\n        corresponding to the strings in evalCons are evaluated and\n        updated into the provided dictionary. The derivitives with\n        respect to all design variables and node locations are computed.\n\n        Parameters\n        ----------\n        funcsSens : dict\n            Dictionary into which the derivatives are saved.\n        evalCons : iterable object containing strings\n            The constraints the user wants returned\n\n        Examples\n        --------\n        >>> funcsSens = {}\n        >>> adjConstraint.evalConstraintsSens(funcsSens, 'LE_SPAR')\n        >>> funcsSens\n        >>> # Result will look like (if AdjacencyConstraint has name of 'c1'):\n        >>> # {'c1_LE_SPAR':{'struct':<50x242 sparse matrix of type '<class 'numpy.float64'>' with 100 stored elements in Compressed Sparse Row format>}}\n        \"\"\"\n        # Check if user specified which constraints to output\n        # Otherwise, output them all\n        evalCons = self._processEvalCons(evalCons)\n\n        # Get number of nodes coords on this proc\n        nCoords = self.getNumCoordinates()\n\n        # Loop through each requested constraint set\n        for conName in evalCons:\n            key = f\"{self.name}_{conName}\"\n            # Get sparse Jacobian for dv sensitivity\n            funcsSens[key] = {}\n            funcsSens[key][self.varName] = self.constraintList[conName].evalConSens(\n                self.x.getArray()\n            )\n\n            # Nodal sensitivities are always zero for this constraint,\n            # Add an empty sparse matrix\n            nCon = self.constraintList[conName].nCon\n            funcsSens[key][self.coordName] = sp.sparse.csr_matrix(\n                (nCon, nCoords), dtype=self.dtype\n            )",
  "def writeVisualization(self, outputDir=None, baseName=None, number=None):\n        \"\"\"\n        This function can be used to write a tecplot file for\n        the purposes of visualization.\n\n        Parameters\n        ----------\n        outputDir : str or None\n            Use the supplied output directory\n        baseName : str or None\n            Use this supplied string for the base filename. Typically\n            only used from an external solver.\n        number : int or None\n            Use the user supplied number to index output. Again, only\n            typically used from an external solver\n        \"\"\"\n        # Check input\n        if outputDir is None:\n            outputDir = self.getOption(\"outputDir\")\n\n        if baseName is None:\n            baseName = self.name\n\n        # If we are numbering output, it saving the sequence of\n        # calls, add the call number\n        if number is not None:\n            # We need number based on the provided number:\n            baseName = baseName + \"_%3.3d\" % number\n        else:\n            # if number is none, i.e. standalone, but we need to\n            # number solutions, use internal counter\n            if self.getOption(\"numberSolutions\"):\n                baseName = baseName + \"_%3.3d\" % self.callCounter\n\n        base = os.path.join(outputDir, baseName) + \".dat\"\n\n        if self.comm.rank == 0:\n            f = open(base, \"w\")\n            f.write('VARIABLES = \"X\", \"Y\", \"Z\"\\n')\n\n        # Get current node locations\n        Xpts_local = self.Xpts.getArray()\n        Xpts_local = Xpts_local.reshape(-1, 3)\n\n        for constrName, constrObj in self.constraintList.items():\n            i = 0\n            for compPair in constrObj.compPairs:\n                # Get the 'average' location for each component in the dvGroup\n                compCenters = np.zeros([2, 3], dtype=float)\n                for j, compID in enumerate(compPair):\n                    nodeIDsGlobal = self.meshLoader.getGlobalNodeIDsForComps(\n                        [compID], nastranOrdering=True\n                    )\n                    nodeIDsLocal = self.meshLoader.getLocalNodeIDsFromGlobal(\n                        nodeIDsGlobal, nastranOrdering=True\n                    )\n                    for lID in nodeIDsLocal:\n                        if lID >= 0:\n                            compCenters[j] += np.real(Xpts_local[lID])\n                    compCenters[j] = self.comm.allreduce(compCenters[j])\n                    nnodes = len(nodeIDsGlobal)\n                    compCenters[j] /= nnodes\n\n                if self.comm.rank == 0:\n                    f.write(f\"Zone T={constrName}_{i}\\n\")\n                    f.write(\"Nodes = 2, Elements = 1 ZONETYPE=FELINESEG\\n\")\n                    f.write(\"DATAPACKING=POINT\\n\")\n                    for ii in range(2):\n                        f.write(\n                            \"%g %g %g\\n\"\n                            % (\n                                compCenters[ii, 0],\n                                compCenters[ii, 1],\n                                compCenters[ii, 2],\n                            )\n                        )\n                    f.write(\"1 2\\n\")  # Connectivity\n\n                # Wait for root\n                self.comm.barrier()\n                i += 1\n\n        if self.comm.rank == 0:\n            f.close()\n\n        # Wait for root\n        self.comm.barrier()",
  "class DVConstraint(TACSConstraint):\n    def __init__(\n        self,\n        name,\n        assembler,\n        comm,\n        outputViewer=None,\n        meshLoader=None,\n        options=None,\n    ):\n        \"\"\"\n        NOTE: This class should not be initialized directly by the user.\n        Use pyTACS.createDVConstraint instead.\n\n        Parameters\n        ----------\n        name : str\n            Name of this tacs problem\n\n        assembler : TACS.Assembler\n            Cython object responsible for creating and setting tacs objects used to solve problem\n\n        comm : mpi4py.MPI.Intracomm\n            The comm object on which to create the pyTACS object.\n\n        outputViewer : TACS.TACSToFH5\n            Cython object used to write out f5 files that can be converted and used for postprocessing.\n\n        meshLoader : pymeshloader.pyMeshLoader\n            pyMeshLoader object used to create the assembler.\n\n        options : dict\n            Dictionary holding problem-specific option parameters (case-insensitive).\n        \"\"\"\n\n        # Problem name\n        self.name = name\n\n        # Default setup for common constraint class objects, sets up comm and options\n        TACSConstraint.__init__(\n            self, assembler, comm, options, outputViewer, meshLoader\n        )\n\n    def addConstraint(\n        self, conName, compIDs=None, lower=-1e20, upper=1e20, dvIndices=0, dvWeights=1.0\n    ):\n        \"\"\"\n        Generic method to adding a new constraint set for TACS.\n\n        Parameters\n        ----------\n        conName : str\n            The user-supplied name for the constraint set. This will\n            typically be a string that is meaningful to the user\n\n        compIDs: list[int] or None\n            List of compIDs to select. One constraint will be added for each component.\n            If None, all compIDs will be selected. Defaults to None.\n\n        lower: float or complex\n            lower bound for constraint. Defaults to -1e20.\n\n        upper: float or complex\n            upper bound for constraint. Defaults to 1e20.\n\n        dvIndices : int or array-like[int]\n            Index numbers of element DVs to be used in constraint.\n            Defaults to 0.\n\n        dvWeights : float or complex or array-like[float] or array-like[complex]\n            Linear scaling factors for each DV used in constraint definition.\n            If list, should match length of dvIndices. Defaults to 1's.\n\n        \"\"\"\n        if compIDs is not None:\n            # Make sure CompIDs is flat and get element numbers on each proc corresponding to specified compIDs\n            compIDs = self._flatten(compIDs)\n        else:\n            nComps = self.meshLoader.getNumComponents()\n            compIDs = list(range(nComps))\n\n        if hasattr(dvIndices, \"__iter__\"):\n            dvIndices = list(dvIndices)\n        elif isinstance(dvIndices, int):\n            dvIndices = [dvIndices]\n\n        if hasattr(dvWeights, \"__iter__\"):\n            dvWeights = list(dvWeights)\n        elif isinstance(dvWeights, float) or isinstance(dvWeights, complex):\n            dvWeights = [dvWeights]\n\n        constrObj = self._createConstraint(dvIndices, dvWeights, compIDs, lower, upper)\n        if constrObj.nCon > 0:\n            self.constraintList[conName] = constrObj\n            success = True\n        else:\n            self._TACSWarning(f\"No valid `compIDs` provided. Skipping {conName}.\")\n            success = False\n\n        return success\n\n    def _createConstraint(self, dvIndices, dvWeights, compIDs, lbound, ubound):\n        \"\"\"\n        Create a new constraint object for TACS.\n\n        Parameters\n        ----------\n        dvIndices : list[int]\n            Index numbers of element DVs to be used in constraint.\n            Defaults to 0.\n\n        dvWeights : list[float or complex]\n            Linear scaling factors for each DV used in constraint definition.\n            If list, should match length of dvIndices. Defaults to 1's.\n\n        compIDs: list[int]\n            List of compIDs to select.\n\n        lbound: float or complex\n            lower bound for constraint. Defaults to 0.0.\n\n        ubound: float or complex\n            upper bound for constraint. Defaults to 1e20.\n\n        Returns\n        -------\n        constraint : tacs.constraints.base.SparseLinearConstraint or None\n            Constraint object if successful, None otherwise.\n\n        \"\"\"\n        # Assemble constraint info\n        conCount = 0\n        rows = []\n        cols = []\n        vals = []\n        for comp in compIDs:\n            # Get the TACS element object associated with this compID\n            elemObj = self.meshLoader.getElementObject(comp, 0)\n            elemIndex = 0\n            # Get the dvs owned by this element\n            globalDvNums = elemObj.getDesignVarNums(elemIndex)\n            # Check if each specified dv num is owned by this proc\n            for dvIndex, dvWeight in zip(dvIndices, dvWeights):\n                if globalDvNums[dvIndex] in self.globalToLocalDVNums:\n                    globalDVNum = globalDvNums[dvIndex]\n                    localDVNum = self.globalToLocalDVNums[globalDVNum]\n                    rows.append(conCount)\n                    cols.append(localDVNum)\n                    vals.append(dvWeight)\n            conCount += 1\n\n        nLocalDVs = self.getNumDesignVars()\n\n        return SparseLinearConstraint(\n            self.comm, rows, cols, vals, conCount, nLocalDVs, lbound, ubound\n        )\n\n    def evalConstraints(self, funcs, evalCons=None, ignoreMissing=False):\n        \"\"\"\n        Evaluate values for constraints. The constraints corresponding to the strings in\n        evalCons are evaluated and updated into the provided\n        dictionary.\n\n        Parameters\n        ----------\n        funcs : dict\n            Dictionary into which the constraints are saved.\n        evalCons : iterable object containing strings.\n            If not none, use these constraints to evaluate.\n        ignoreMissing : bool\n            Flag to supress checking for a valid constraint. Please use\n            this option with caution.\n\n        Examples\n        --------\n        >>> funcs = {}\n        >>> dvConstraint.evalConstraints(funcs, 'LE_SPAR')\n        >>> funcs\n        >>> # Result will look like (if DVConstraint has name of 'c1'):\n        >>> # {'c1_LE_SPAR': array([12354.10])}\n        \"\"\"\n        # Check if user specified which constraints to output\n        # Otherwise, output them all\n        evalCons = self._processEvalCons(evalCons, ignoreMissing)\n\n        # Loop through each requested constraint set\n        for conName in evalCons:\n            key = f\"{self.name}_{conName}\"\n            funcs[key] = self.constraintList[conName].evalCon(self.x.getArray())\n\n    def evalConstraintsSens(self, funcsSens, evalCons=None):\n        \"\"\"\n        This is the main routine for returning useful (sensitivity)\n        information from constraint. The derivatives of the constraints\n        corresponding to the strings in evalCons are evaluated and\n        updated into the provided dictionary. The derivitives with\n        respect to all design variables and node locations are computed.\n\n        Parameters\n        ----------\n        funcsSens : dict\n            Dictionary into which the derivatives are saved.\n        evalCons : iterable object containing strings\n            The constraints the user wants returned\n\n        Examples\n        --------\n        >>> funcsSens = {}\n        >>> dvConstraint.evalConstraintsSens(funcsSens, 'LE_SPAR')\n        >>> funcsSens\n        >>> # Result will look like (if DVConstraint has name of 'c1'):\n        >>> # {'c1_LE_SPAR':{'struct':<50x242 sparse matrix of type '<class 'numpy.float64'>' with 100 stored elements in Compressed Sparse Row format>}}\n        \"\"\"\n        # Check if user specified which constraints to output\n        # Otherwise, output them all\n        evalCons = self._processEvalCons(evalCons)\n\n        # Get number of nodes coords on this proc\n        nCoords = self.getNumCoordinates()\n\n        # Loop through each requested constraint set\n        for conName in evalCons:\n            key = f\"{self.name}_{conName}\"\n            # Get sparse Jacobian for dv sensitivity\n            funcsSens[key] = {}\n            funcsSens[key][self.varName] = self.constraintList[conName].evalConSens(\n                self.x.getArray()\n            )\n\n            # Nodal sensitivities are always zero for this constraint,\n            # Add an empty sparse matrix\n            nCon = self.constraintList[conName].nCon\n            funcsSens[key][self.coordName] = sp.sparse.csr_matrix(\n                (nCon, nCoords), dtype=self.dtype\n            )",
  "def __init__(\n        self,\n        name,\n        assembler,\n        comm,\n        outputViewer=None,\n        meshLoader=None,\n        options=None,\n    ):\n        \"\"\"\n        NOTE: This class should not be initialized directly by the user.\n        Use pyTACS.createDVConstraint instead.\n\n        Parameters\n        ----------\n        name : str\n            Name of this tacs problem\n\n        assembler : TACS.Assembler\n            Cython object responsible for creating and setting tacs objects used to solve problem\n\n        comm : mpi4py.MPI.Intracomm\n            The comm object on which to create the pyTACS object.\n\n        outputViewer : TACS.TACSToFH5\n            Cython object used to write out f5 files that can be converted and used for postprocessing.\n\n        meshLoader : pymeshloader.pyMeshLoader\n            pyMeshLoader object used to create the assembler.\n\n        options : dict\n            Dictionary holding problem-specific option parameters (case-insensitive).\n        \"\"\"\n\n        # Problem name\n        self.name = name\n\n        # Default setup for common constraint class objects, sets up comm and options\n        TACSConstraint.__init__(\n            self, assembler, comm, options, outputViewer, meshLoader\n        )",
  "def addConstraint(\n        self, conName, compIDs=None, lower=-1e20, upper=1e20, dvIndices=0, dvWeights=1.0\n    ):\n        \"\"\"\n        Generic method to adding a new constraint set for TACS.\n\n        Parameters\n        ----------\n        conName : str\n            The user-supplied name for the constraint set. This will\n            typically be a string that is meaningful to the user\n\n        compIDs: list[int] or None\n            List of compIDs to select. One constraint will be added for each component.\n            If None, all compIDs will be selected. Defaults to None.\n\n        lower: float or complex\n            lower bound for constraint. Defaults to -1e20.\n\n        upper: float or complex\n            upper bound for constraint. Defaults to 1e20.\n\n        dvIndices : int or array-like[int]\n            Index numbers of element DVs to be used in constraint.\n            Defaults to 0.\n\n        dvWeights : float or complex or array-like[float] or array-like[complex]\n            Linear scaling factors for each DV used in constraint definition.\n            If list, should match length of dvIndices. Defaults to 1's.\n\n        \"\"\"\n        if compIDs is not None:\n            # Make sure CompIDs is flat and get element numbers on each proc corresponding to specified compIDs\n            compIDs = self._flatten(compIDs)\n        else:\n            nComps = self.meshLoader.getNumComponents()\n            compIDs = list(range(nComps))\n\n        if hasattr(dvIndices, \"__iter__\"):\n            dvIndices = list(dvIndices)\n        elif isinstance(dvIndices, int):\n            dvIndices = [dvIndices]\n\n        if hasattr(dvWeights, \"__iter__\"):\n            dvWeights = list(dvWeights)\n        elif isinstance(dvWeights, float) or isinstance(dvWeights, complex):\n            dvWeights = [dvWeights]\n\n        constrObj = self._createConstraint(dvIndices, dvWeights, compIDs, lower, upper)\n        if constrObj.nCon > 0:\n            self.constraintList[conName] = constrObj\n            success = True\n        else:\n            self._TACSWarning(f\"No valid `compIDs` provided. Skipping {conName}.\")\n            success = False\n\n        return success",
  "def _createConstraint(self, dvIndices, dvWeights, compIDs, lbound, ubound):\n        \"\"\"\n        Create a new constraint object for TACS.\n\n        Parameters\n        ----------\n        dvIndices : list[int]\n            Index numbers of element DVs to be used in constraint.\n            Defaults to 0.\n\n        dvWeights : list[float or complex]\n            Linear scaling factors for each DV used in constraint definition.\n            If list, should match length of dvIndices. Defaults to 1's.\n\n        compIDs: list[int]\n            List of compIDs to select.\n\n        lbound: float or complex\n            lower bound for constraint. Defaults to 0.0.\n\n        ubound: float or complex\n            upper bound for constraint. Defaults to 1e20.\n\n        Returns\n        -------\n        constraint : tacs.constraints.base.SparseLinearConstraint or None\n            Constraint object if successful, None otherwise.\n\n        \"\"\"\n        # Assemble constraint info\n        conCount = 0\n        rows = []\n        cols = []\n        vals = []\n        for comp in compIDs:\n            # Get the TACS element object associated with this compID\n            elemObj = self.meshLoader.getElementObject(comp, 0)\n            elemIndex = 0\n            # Get the dvs owned by this element\n            globalDvNums = elemObj.getDesignVarNums(elemIndex)\n            # Check if each specified dv num is owned by this proc\n            for dvIndex, dvWeight in zip(dvIndices, dvWeights):\n                if globalDvNums[dvIndex] in self.globalToLocalDVNums:\n                    globalDVNum = globalDvNums[dvIndex]\n                    localDVNum = self.globalToLocalDVNums[globalDVNum]\n                    rows.append(conCount)\n                    cols.append(localDVNum)\n                    vals.append(dvWeight)\n            conCount += 1\n\n        nLocalDVs = self.getNumDesignVars()\n\n        return SparseLinearConstraint(\n            self.comm, rows, cols, vals, conCount, nLocalDVs, lbound, ubound\n        )",
  "def evalConstraints(self, funcs, evalCons=None, ignoreMissing=False):\n        \"\"\"\n        Evaluate values for constraints. The constraints corresponding to the strings in\n        evalCons are evaluated and updated into the provided\n        dictionary.\n\n        Parameters\n        ----------\n        funcs : dict\n            Dictionary into which the constraints are saved.\n        evalCons : iterable object containing strings.\n            If not none, use these constraints to evaluate.\n        ignoreMissing : bool\n            Flag to supress checking for a valid constraint. Please use\n            this option with caution.\n\n        Examples\n        --------\n        >>> funcs = {}\n        >>> dvConstraint.evalConstraints(funcs, 'LE_SPAR')\n        >>> funcs\n        >>> # Result will look like (if DVConstraint has name of 'c1'):\n        >>> # {'c1_LE_SPAR': array([12354.10])}\n        \"\"\"\n        # Check if user specified which constraints to output\n        # Otherwise, output them all\n        evalCons = self._processEvalCons(evalCons, ignoreMissing)\n\n        # Loop through each requested constraint set\n        for conName in evalCons:\n            key = f\"{self.name}_{conName}\"\n            funcs[key] = self.constraintList[conName].evalCon(self.x.getArray())",
  "def evalConstraintsSens(self, funcsSens, evalCons=None):\n        \"\"\"\n        This is the main routine for returning useful (sensitivity)\n        information from constraint. The derivatives of the constraints\n        corresponding to the strings in evalCons are evaluated and\n        updated into the provided dictionary. The derivitives with\n        respect to all design variables and node locations are computed.\n\n        Parameters\n        ----------\n        funcsSens : dict\n            Dictionary into which the derivatives are saved.\n        evalCons : iterable object containing strings\n            The constraints the user wants returned\n\n        Examples\n        --------\n        >>> funcsSens = {}\n        >>> dvConstraint.evalConstraintsSens(funcsSens, 'LE_SPAR')\n        >>> funcsSens\n        >>> # Result will look like (if DVConstraint has name of 'c1'):\n        >>> # {'c1_LE_SPAR':{'struct':<50x242 sparse matrix of type '<class 'numpy.float64'>' with 100 stored elements in Compressed Sparse Row format>}}\n        \"\"\"\n        # Check if user specified which constraints to output\n        # Otherwise, output them all\n        evalCons = self._processEvalCons(evalCons)\n\n        # Get number of nodes coords on this proc\n        nCoords = self.getNumCoordinates()\n\n        # Loop through each requested constraint set\n        for conName in evalCons:\n            key = f\"{self.name}_{conName}\"\n            # Get sparse Jacobian for dv sensitivity\n            funcsSens[key] = {}\n            funcsSens[key][self.varName] = self.constraintList[conName].evalConSens(\n                self.x.getArray()\n            )\n\n            # Nodal sensitivities are always zero for this constraint,\n            # Add an empty sparse matrix\n            nCon = self.constraintList[conName].nCon\n            funcsSens[key][self.coordName] = sp.sparse.csr_matrix(\n                (nCon, nCoords), dtype=self.dtype\n            )",
  "def computePanelLength(points, direction):\n    \"\"\"Given the sorted points around the perimeter of a panel, compute the length of the panel in a given direction\n\n    Note: This function is approximate, it works best when the length direction is close to parallel with the panel\n\n    Parameters\n    ----------\n    points : n x 3 array\n        Coordinates of the perimeter points of the panel, in sorted order, so that points[i] - points[i-1] is a vector\n        along the perimeter\n    direction : length 3 array\n        Direction in which to compute the panel length\n\n    Returns\n    -------\n    float or complex\n        The panel length in the given direction\n    \"\"\"\n    numPoints = points.shape[0]\n    length = 0.0\n    for pointInd in range(numPoints):\n        for edgeInd in range(numPoints):\n            startInd = edgeInd\n            endInd = (edgeInd + 1) % numPoints\n            # We only need to check edges that are not adjacent to the current point\n            if not (startInd == pointInd or endInd == pointInd):\n                # Find the intersection of a line through the point in the given\n                # direction with a line along the current edge\n                edge = points[endInd] - points[startInd]\n                mat = np.stack((direction, -edge), axis=1)\n                rhs = points[startInd] - points[pointInd]\n                sol, res, _, _ = np.linalg.lstsq(mat, rhs)\n                alpha = sol[0]\n                beta = sol[1]\n                # Only compute the length if the intersection occurs within the true bounds of the edge\n                if np.real(beta) - 1e-12 <= 1 and np.real(beta) + 1e-12 >= 0:\n                    # intersectionPoint = points[startInd] + beta * edge\n                    # newLength = np.sqrt(np.sum((intersectionPoint - points[pointInd]) ** 2))\n                    newLength = np.sqrt(np.sum((alpha * direction) ** 2))\n                    if (\n                        np.real(newLength) > np.real(length)\n                        and np.real(newLength) > res\n                    ):\n                        length = newLength\n    return length",
  "def computePanelLengthSens(points, direction):\n    \"\"\"Given the sorted points around the perimeter of a panel, compute the\n    sensitivitiy of the length of the panel in a given direction with\n    respect to the coordinates of the points\n\n    Parameters\n    ----------\n    points : n x 3 array\n        Coordinates of the perimeter points of the panel, in sorted order, so that points[i] - points[i-1] is a vector\n        along the perimeter\n    direction : length 3 array\n        Direction in which to compute the panel length\n\n    Returns\n    -------\n    n x 3 array\n        Panel length sensitivities\n    \"\"\"\n    sens = np.zeros_like(points)\n    pointsPert = np.zeros_like(points, dtype=np.complex128)\n    pointsPert[:] = points[:]\n    for ii in range(points.shape[0]):\n        for jj in range(points.shape[1]):\n            pointsPert[ii, jj] += 1e-200j\n            sens[ii, jj] = np.imag(computePanelLength(pointsPert, direction)) * 1e200\n            pointsPert[ii, jj] -= 1e-200j\n    return sens",
  "def simplifyPoly(nodeIDs, nodes, angleTol=18.0):\n    \"\"\"\n    Take a (closed) chain of nodes and remove any nodes that turn by less than angleTol degrees.\n    This simplifies the polygon by leaving only \"sharp\" corners\n    \"\"\"\n    cont = True\n    while cont:\n        newNodes = []\n        newNodeIDs = []\n        for i in range(len(nodes)):\n            im1 = i - 1\n            ip1 = i + 1\n            if i == 0:\n                im1 = len(nodes) - 1\n            if i == len(nodes) - 1:\n                ip1 = 0\n\n            v1 = nodes[ip1] - nodes[i]\n            v2 = nodes[im1] - nodes[i]\n            # Angle between vectors\n            arg = np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))\n            arg = max(-1, arg)\n            arg = min(1, arg)\n            theta = np.arccos(arg)\n\n            if theta < np.pi * (1 - angleTol / 180):\n                newNodes.append(nodes[i])\n                newNodeIDs.append(nodeIDs[i])\n\n        if len(newNodes) == len(nodes):\n            cont = False\n\n        nodes = np.array(newNodes)\n        nodeIDs = np.array(newNodeIDs)\n\n    return list(nodeIDs), nodes",
  "class PanelLengthConstraint(TACSConstraint):\n    def __init__(\n        self,\n        name,\n        assembler,\n        comm,\n        outputViewer=None,\n        meshLoader=None,\n        options=None,\n    ):\n        \"\"\"\n        NOTE: This class should not be initialized directly by the user.\n        Use pyTACS.createPanelLengthConstraint instead.\n\n        Parameters\n        ----------\n        name : str\n            Name of this tacs problem\n\n        assembler : TACS.Assembler\n            Cython object responsible for creating and setting tacs objects used to solve problem\n\n        comm : mpi4py.MPI.Intracomm\n            The comm object on which to create the pyTACS object.\n\n        outputViewer : TACS.TACSToFH5\n            Cython object used to write out f5 files that can be converted and used for postprocessing.\n\n        meshLoader : pymeshloader.pyMeshLoader\n            pyMeshLoader object used to create the assembler.\n\n        options : dict\n            Dictionary holding problem-specific option parameters (case-insensitive).\n        \"\"\"\n\n        # Problem name\n        self.name = name\n\n        # Default setup for common constraint class objects, sets up comm and options\n        TACSConstraint.__init__(\n            self, assembler, comm, options, outputViewer, meshLoader\n        )\n\n        # Create a map from the global DV index to the proc index that owns it and the local index on that proc\n        self.globalToLocalDVNumsOnProc = self.comm.gather(\n            self.globalToLocalDVNums, root=0\n        )\n        self.DVMap = {}\n        if self.rank == 0:\n            for procInd in range(self.comm.size):\n                for globalInd, localInd in self.globalToLocalDVNumsOnProc[\n                    procInd\n                ].items():\n                    self.DVMap[globalInd] = {\"proc\": procInd, \"localInd\": localInd}\n\n        # Now create the same thing for the nodes\n        nodeDict = self.meshLoader.getGlobalToLocalNodeIDDict()\n        nodeDicts = self.comm.gather(nodeDict, root=0)\n        self.nodeMap = {}\n        if self.rank == 0:\n            for procInd in range(self.comm.size):\n                for globalInd, localInd in nodeDicts[procInd].items():\n                    self.nodeMap[globalInd] = {\"proc\": procInd, \"localInd\": localInd}\n\n        # Store the number of DVs and nodes on each proc\n        self.numLocalDVs = self.getNumDesignVars()\n\n        self.computePanelLength = computePanelLength\n        self.computePanelLengthSens = computePanelLengthSens\n\n        # Store flags for whether or not we need to recompute the constraints and derivatives\n        self.constraintsUpToDate = {}\n        self.funcs = {}\n        self.constraintsSensUpToDate = {}\n        self.funcsSens = {}\n\n    def setDesignVars(self, x):\n        \"\"\"\n        Update the design variables used by tacs.\n\n        Parameters\n        ----------\n        x : numpy.ndarray or dict or tacs.TACS.Vec\n            The variables (typically from the optimizer) to set. It\n            looks for variable in the ``self.varName`` attribute if in dict.\n\n        \"\"\"\n        TACSConstraint.setDesignVars(self, x)\n        for key in self.constraintsUpToDate:\n            self.constraintsUpToDate[key] = False\n\n    def setNodes(self, Xpts):\n        \"\"\"\n        Set the mesh coordinates of the structure.\n\n        Parameters\n        ----------\n        coords : numpy.ndarray\n            Structural coordinate in array of size (N * 3) where N is\n            the number of structural nodes on this processor.\n        \"\"\"\n        TACSConstraint.setNodes(self, Xpts)\n        for key in self.constraintsUpToDate:\n            self.constraintsUpToDate[key] = False\n            self.constraintsSensUpToDate[key] = False\n\n    def addConstraint(self, conName, compIDs=None, lower=None, upper=None, dvIndex=0):\n        \"\"\"\n        Generic method to adding a new constraint set for TACS.\n\n        Parameters\n        ----------\n        conName : str\n            The user-supplied name for the constraint set. This will\n            typically be a string that is meaningful to the user\n\n        compIDs: list[int] or None\n            List of compIDs to apply constraints to. If None, all compIDs will be used. Defaults to None.\n\n        lower: float or complex\n            lower bound for constraint. Not used.\n\n        upper: float or complex\n            upper bound for constraint. Not used.\n\n        dvIndex : int\n            Index number of the panel length DV's. Defaults to 0.\n\n        \"\"\"\n        if compIDs is not None:\n            # Make sure CompIDs is flat and get element numbers on each proc corresponding to specified compIDs\n            compIDs = self._flatten(compIDs)\n        else:\n            nComps = self.meshLoader.getNumComponents()\n            compIDs = range(nComps)\n\n        dvGlobalInds = []\n        dvProcs = []\n        dvLocalInds = []\n        boundaryNodeGlobalInds = []\n        boundaryNodeLocalInds = []\n        boundaryNodeLocalProcs = []\n        refAxes = []\n        dvJacRows = []\n        dvJacCols = []\n        dvJacVals = []\n        coordJacRows = []\n        coordJacCols = []\n        for ii in range(self.comm.size):\n            dvJacRows.append([])\n            dvJacCols.append([])\n            dvJacVals.append([])\n            coordJacRows.append([])\n            coordJacCols.append([])\n\n        # Get the boundary node IDs for each component\n        boundaryNodeIDs, boundaryNodeCoords = self._getComponentBoundaryNodes(compIDs)\n\n        if self.rank == 0:\n            constraintInd = 0\n            for compID in compIDs:\n                # Get the TACS element object associated with this compID to\n                # get the ref axis\n                elemObj = self.meshLoader.getElementObject(compID, 0)\n                transObj = elemObj.getTransform()\n                try:\n                    refAxis = transObj.getRefAxis()\n                except AttributeError as e:\n                    raise AttributeError(\n                        f\"The elements in component {self.meshLoader.compDescripts[compID]} do not have a reference axis. Please define one by using the 'ShellRefAxisTransform' class with your elements\"\n                    ) from e\n\n                # For a more accurate length calculation, roject the ref axis\n                # onto the \"average\" plane of the baseline panel geometry by\n                # using an SVD to compute a normal vector\n                centroid = np.mean(boundaryNodeCoords[compID], axis=0, keepdims=True)\n                centredPoints = boundaryNodeCoords[compID] - centroid\n                _, _, VT = np.linalg.svd(centredPoints, full_matrices=False)\n                panelNormal = VT[-1]\n                refAxis -= np.dot(refAxis, panelNormal) * panelNormal\n                refAxis /= np.linalg.norm(refAxis)\n                refAxes.append(refAxis)\n\n                # Now figure out where the DV for this component lives\n                globalDvNums = elemObj.getDesignVarNums(0)\n                dvGlobalInds.append(globalDvNums[dvIndex])\n                dvProcs.append(self.DVMap[globalDvNums[dvIndex]][\"proc\"])\n                dvLocalInds.append(self.DVMap[globalDvNums[dvIndex]][\"localInd\"])\n\n                # Do the same for the boundary nodes, this is a little more\n                # complicated because each node may be on a different proc\n                GlobalInds = []\n                LocalInds = []\n                LocalProcs = []\n                for nodeID in boundaryNodeIDs[compID]:\n                    GlobalInds.append(nodeID)\n                    LocalInds.append(self.nodeMap[nodeID][\"localInd\"])\n                    LocalProcs.append(self.nodeMap[nodeID][\"proc\"])\n                boundaryNodeGlobalInds.append(GlobalInds)\n                boundaryNodeLocalInds.append(LocalInds)\n                boundaryNodeLocalProcs.append(LocalProcs)\n\n                # Figure out the jacobian sparsity for each proc\n                # The DV jacobian on the proc that owns this component's DV\n                # will have a -1 in the row corresponding to this constraint\n                # and the column corresponding to the local DV index\n                dvJacRows[dvProcs[-1]].append(constraintInd)\n                dvJacCols[dvProcs[-1]].append(dvLocalInds[-1])\n                dvJacVals[dvProcs[-1]].append(-1.0)\n\n                for ii in range(len(boundaryNodeIDs[compID])):\n                    # the coordinate jacobian on the proc that owns this node\n                    # will have 3 entries in the row corresponding to this\n                    # constraint and the columns corresponding to the local\n                    # node index on the proc\n                    proc = boundaryNodeLocalProcs[-1][ii]\n                    localNodeInd = boundaryNodeLocalInds[-1][ii]\n                    coordJacRows[proc] += [constraintInd] * 3\n                    coordJacCols[proc] += [\n                        3 * localNodeInd,\n                        3 * localNodeInd + 1,\n                        3 * localNodeInd + 2,\n                    ]\n\n                constraintInd += 1\n\n            # Add the constraint to the constraint list, we need to store:\n            # - The size of this constraint\n            # - The global index of each DV\n            # - The proc number that is in charge of each DV\n            # - The local index of each DV on the proc that is in charge of it\n            # - The global boundary node IDs for each component\n            # - The proc that owns each boundary node for each component\n            # - The local index of each boundary node on the proc that owns it\n            # - The reference axis direction for each component\n            # - The DV jacobian for each proc (because it's constant)\n            # - The coordinate jacobian sparsity pattern for each proc (because it's also constant)\n            self.constraintList[conName] = {\n                \"nCon\": len(compIDs),\n                \"compIDs\": compIDs,\n                \"dvGlobalInds\": dvGlobalInds,\n                \"dvProcs\": dvProcs,\n                \"dvLocalInds\": dvLocalInds,\n                \"boundaryNodeGlobalInds\": boundaryNodeGlobalInds,\n                \"boundaryNodeLocalInds\": boundaryNodeLocalInds,\n                \"boundaryNodeLocalProcs\": boundaryNodeLocalProcs,\n                \"refAxes\": refAxes,\n            }\n        else:\n            self.constraintList[conName] = {\"nCon\": len(compIDs)}\n            dvJacRows = None\n            dvJacCols = None\n            dvJacVals = None\n            coordJacRows = None\n            coordJacCols = None\n\n        # These constraints are linear w.r.t the DVs so we can just precompute\n        # the DV jacobian for each proc\n        dvJacRows = self.comm.scatter(dvJacRows, root=0)\n        dvJacCols = self.comm.scatter(dvJacCols, root=0)\n        dvJacVals = self.comm.scatter(dvJacVals, root=0)\n        coordJacRows = self.comm.scatter(coordJacRows, root=0)\n        coordJacCols = self.comm.scatter(coordJacCols, root=0)\n        self.constraintList[conName][\"dvJac\"] = sp.sparse.csr_matrix(\n            (dvJacVals, (dvJacRows, dvJacCols)),\n            shape=(len(compIDs), self.numLocalDVs),\n        )\n\n        # The constraints aren't linear w.r.t the coordinates, but the\n        # sparsity pattern is constant so we can store that\n        self.constraintList[conName][\"coordJacRows\"] = coordJacRows\n        self.constraintList[conName][\"coordJacCols\"] = coordJacCols\n\n        self.constraintsUpToDate[conName] = False\n        self.constraintsSensUpToDate[conName] = False\n        success = True\n\n        return success\n\n    def getConstraintBounds(self, bounds, evalCons=None):\n        \"\"\"\n        Get bounds for constraints. The constraints corresponding to the strings in\n        `evalCons` are evaluated and updated into the provided\n        dictionary.\n\n        The panel length constraints are equality constraints so both the upper and lower bounds are zero\n\n        Parameters\n        ----------\n        bounds : dict\n            Dictionary into which the constraint bounds are saved.\n            Bounds will be saved as a tuple: (lower, upper)\n        evalCons : iterable object containing strings.\n            If not none, use these constraints to evaluate.\n\n        Examples\n        --------\n        >>> conBounds = {}\n        >>> tacsConstraint.getConstraintBounds(conBounds, 'LE_SPAR')\n        >>> conBounds\n        >>> # Result will look like (if TACSConstraint has name of 'c1'):\n        >>> # {'c1_LE_SPAR': (array([-1e20]), array([1e20]))}\n        \"\"\"\n        # Check if user specified which constraints to output\n        # Otherwise, output them all\n        evalCons = self._processEvalCons(evalCons)\n\n        # Loop through each requested constraint set\n        for conName in evalCons:\n            key = f\"{self.name}_{conName}\"\n            nCon = self.constraintList[conName][\"nCon\"]\n            bounds[key] = (np.zeros(nCon), np.zeros(nCon))\n\n    def getConstraintSizes(self, sizes, evalCons=None):\n        \"\"\"\n        Get number for constraint equations in each set.\n        The constraints corresponding to the strings in `evalCons`\n        are evaluated and updated into the provided dictionary.\n\n        Parameters\n        ----------\n        sizes : dict\n            Dictionary into which the constraint sizes are saved.\n        evalCons : iterable object containing strings.\n            If not none, use these constraints to evaluate.\n\n        Examples\n        --------\n        >>> conSizes = {}\n        >>> tacsConstraint.getConstraintSizes(conSizes, 'LE_SPAR')\n        >>> funconSizescs\n        >>> # Result will look like (if TACSConstraint has name of 'c1'):\n        >>> # {'c1_LE_SPAR': 10}\n        \"\"\"\n        # Check if user specified which constraints to output\n        # Otherwise, output them all\n        evalCons = self._processEvalCons(evalCons)\n\n        # Loop through each requested constraint set\n        for conName in evalCons:\n            key = f\"{self.name}_{conName}\"\n            sizes[key] = self.constraintList[conName][\"nCon\"]\n\n    def evalConstraints(self, funcs, evalCons=None, ignoreMissing=False):\n        \"\"\"\n        Evaluate values for constraints. The constraints corresponding to the strings in\n        evalCons are evaluated and updated into the provided dictionary.\n\n        The same constraint arrays are returned on every proc\n\n        Parameters\n        ----------\n        funcs : dict\n            Dictionary into which the constraints are saved.\n        evalCons : iterable object containing strings.\n            If not none, use these constraints to evaluate.\n        ignoreMissing : bool\n            Flag to supress checking for a valid constraint. Please use\n            this option with caution.\n\n        Examples\n        --------\n        >>> funcs = {}\n        >>> adjConstraint.evalConstraints(funcs, 'LE_SPAR')\n        >>> funcs\n        >>> # Result will look like (if PanelLengthConstraint has name of 'c1'):\n        >>> # {'c1_LE_SPAR': array([1.325, 2.1983645, 3.1415926, ...])}\n        \"\"\"\n\n        # Check if user specified which constraints to output\n        # Otherwise, output them all\n        evalCons = self._processEvalCons(evalCons, ignoreMissing)\n\n        # We will compute everything on the root proc and then broadcast the\n        # results, this is definitely not the most efficient way to do this\n        # so we may want to re-do it in future, but this works for now\n\n        DVs = None\n        nodes = None\n\n        # Loop through each requested constraint set\n        for conName in evalCons:\n            key = f\"{self.name}_{conName}\"\n            nCon = self.constraintList[conName][\"nCon\"]\n            if self.constraintsUpToDate[conName]:\n                funcs[key] = np.copy(self.funcs[key])\n            else:\n                constraintValues = np.zeros(nCon, dtype=self.dtype)\n                if nodes is None:\n                    # Get all of the DVs and nodes on the root proc\n                    DVs = self.comm.gather(self.x.getArray(), root=0)\n                    nodes = self.comm.gather(self.Xpts.getArray(), root=0)\n                    if self.rank == 0:\n                        for ii in range(self.comm.size):\n                            nodes[ii] = nodes[ii].reshape(-1, 3)\n                if self.rank == 0:\n                    for ii in range(nCon):\n                        numPoints = len(\n                            self.constraintList[conName][\"boundaryNodeGlobalInds\"][ii]\n                        )\n                        boundaryPoints = np.zeros((numPoints, 3), dtype=self.dtype)\n                        for jj in range(numPoints):\n                            nodeProc = self.constraintList[conName][\n                                \"boundaryNodeLocalProcs\"\n                            ][ii][jj]\n                            localInd = self.constraintList[conName][\n                                \"boundaryNodeLocalInds\"\n                            ][ii][jj]\n                            boundaryPoints[jj] = nodes[nodeProc][localInd]\n                        refAxis = self.constraintList[conName][\"refAxes\"][ii]\n                        DVProc = self.constraintList[conName][\"dvProcs\"][ii]\n                        DVLocalInd = self.constraintList[conName][\"dvLocalInds\"][ii]\n                        constraintValues[ii] = (\n                            self.computePanelLength(boundaryPoints, refAxis)\n                            - DVs[DVProc][DVLocalInd]\n                        )\n                funcs[key] = self.comm.bcast(constraintValues, root=0)\n                self.funcs[key] = np.copy(funcs[key])\n                self.constraintsUpToDate[conName] = True\n\n    def evalConstraintsSens(self, funcsSens, evalCons=None):\n        \"\"\"This is the main routine for returning useful (sensitivity)\n        information from constraint. The derivatives of the constraints\n        corresponding to the strings in evalCons are evaluated and\n        updated into the provided dictionary. The derivitives with\n        respect to all design variables and node locations are computed.\n\n        The sensitivities returned on each proc are a sparse m x n matrix\n        where m is the number of constraints and n is the number of design\n        variables or 3x the number of nodes on this proc. The matrix contains\n        the sensitivities of all constraints w.r.t only the design\n        variables/node coordinates on this proc.\n\n        Parameters\n        ----------\n        funcsSens : dict\n            Dictionary into which the derivatives are saved.\n        evalCons : iterable object containing strings\n            The constraints the user wants returned\n\n        Examples\n        --------\n        >>> funcsSens = {}\n        >>> adjConstraint.evalConstraintsSens(funcsSens, 'LE_SPAR')\n        >>> funcsSens\n        >>> # Result will look like (if AdjacencyConstraint has name of 'c1'):\n        >>> # {'c1_LE_SPAR':{'struct':<50x242 sparse matrix of type '<class 'numpy.float64'>' with 100 stored elements in Compressed Sparse Row format>}}\n        \"\"\"\n\n        # Check if user specified which constraints to output\n        # Otherwise, output them all\n        evalCons = self._processEvalCons(evalCons)\n\n        # We will compute everything on the root proc and then broadcast the results,\n        # this is definitely not the most efficient way to do this so we may want to\n        # re-do it in future, but this works for now\n\n        nodes = None\n\n        # Get number of nodes coords on this proc\n        nCoords = self.getNumCoordinates()\n\n        # Loop through each requested constraint set\n        for conName in evalCons:\n            key = f\"{self.name}_{conName}\"\n            nCon = self.constraintList[conName][\"nCon\"]\n            funcsSens[key] = {}\n            funcsSens[key][self.varName] = self.constraintList[conName][\"dvJac\"]\n            if self.constraintsSensUpToDate[conName]:\n                funcsSens[key][self.coordName] = self.funcsSens[key].copy()\n            else:\n                # Get all of the nodes on the root proc\n                if nodes is None:\n                    nodes = self.comm.gather(self.Xpts.getArray(), root=0)\n                    if self.rank == 0:\n                        for ii in range(self.comm.size):\n                            nodes[ii] = nodes[ii].reshape(-1, 3)\n                funcsSens[key][self.coordName] = sp.sparse.csr_matrix(\n                    (nCon, nCoords), dtype=self.dtype\n                )\n                if self.rank == 0:\n                    coordJacVals = []\n                    for ii in range(self.comm.size):\n                        coordJacVals.append([])\n                    for ii in range(nCon):\n                        numPoints = len(\n                            self.constraintList[conName][\"boundaryNodeGlobalInds\"][ii]\n                        )\n                        boundaryPoints = np.zeros((numPoints, 3), dtype=self.dtype)\n\n                        for jj in range(numPoints):\n                            nodeProc = self.constraintList[conName][\n                                \"boundaryNodeLocalProcs\"\n                            ][ii][jj]\n                            localInd = self.constraintList[conName][\n                                \"boundaryNodeLocalInds\"\n                            ][ii][jj]\n                            boundaryPoints[jj] = nodes[nodeProc][localInd]\n                        refAxis = self.constraintList[conName][\"refAxes\"][ii]\n                        LSens = self.computePanelLengthSens(boundaryPoints, refAxis)\n                        for jj in range(numPoints):\n                            nodeProc = self.constraintList[conName][\n                                \"boundaryNodeLocalProcs\"\n                            ][ii][jj]\n                            coordJacVals[nodeProc] += LSens[jj].tolist()\n                else:\n                    coordJacVals = None\n                coordJacVals = self.comm.scatter(coordJacVals, root=0)\n                coordJacRows = self.constraintList[conName][\"coordJacRows\"]\n                coordJacCols = self.constraintList[conName][\"coordJacCols\"]\n                self.funcsSens[key] = sp.sparse.csr_matrix(\n                    (coordJacVals, (coordJacRows, coordJacCols)),\n                    (nCon, nCoords),\n                    dtype=self.dtype,\n                )\n                funcsSens[key][self.coordName] = self.funcsSens[key].copy()\n                self.constraintsSensUpToDate[conName] = True\n\n    def _getComponentBoundaryNodes(self, compIDs):\n        \"\"\"For a given list of components, find the nodes on the boundaries of\n        each of the components.\n\n        The results are broadcast to all procs\n\n        Parameters\n        ----------\n        compIDs: list[int]\n            List of compIDs to find boundaries of.\n\n        Returns\n        --------\n        dict[int, list[int]]\n            Dictionary where dict[compID] = sorted list of nodeIDs on the\n            boundary of the component\n        dict[int, np.array]\n            Dictionary where dict[compID] = array of node coordinates on the\n            boundary of the component\n        \"\"\"\n\n        boundaryNodeIDs = {}\n        boundaryNodeCoords = {}\n\n        if self.rank == 0:\n            for compID in compIDs:\n                allEdges = set()\n                dupEdges = set()\n                compConn = self.meshLoader.getConnectivityForComp(\n                    compID, nastranOrdering=False\n                )\n                # Go over all the elements in the component and add their edges to the sets of all and possibly duplicate edges\n                for elemConn in compConn:\n                    nnodes = len(elemConn)\n                    if nnodes >= 2:\n                        for j in range(nnodes):\n                            nodeID1 = elemConn[j]\n                            nodeID2 = elemConn[(j + 1) % nnodes]\n\n                            if nodeID1 < nodeID2:\n                                key = (nodeID1, nodeID2)\n                            else:\n                                key = (nodeID2, nodeID1)\n\n                            # Skip degenerate edges\n                            if key[0] != key[1]:\n                                # Either add to allEdges or dupEdges depending on whether we've seen this edge before\n                                if key not in allEdges:\n                                    allEdges.add(key)\n                                else:\n                                    dupEdges.add(key)\n                # Now get a list of all the edges that aren't duplicated, these are the boundary edges\n                boundaryEdges = list(allEdges - dupEdges)\n\n                # Create a nodeToElem Pointer using a dictionary:\n                nodeToElem = {}\n                for iEdge in range(len(boundaryEdges)):\n                    edge = boundaryEdges[iEdge]\n                    for ii in range(2):\n                        if edge[ii] in nodeToElem:\n                            nodeToElem[edge[ii]].append(iEdge)\n                        else:\n                            nodeToElem[edge[ii]] = [iEdge]\n\n                # Now check that each nodeToElem has a length of\n                # 2. This means we have a chance it is a\n                # closed curve\n                for key in nodeToElem:\n                    if len(nodeToElem[key]) != 2:\n                        raise ValueError(\n                            \"The topology of the geometry associated with \"\n                            \"a constitutive object is not manifold \"\n                            \"(There is a node with three or more edges \"\n                            \"attached. This constitutive object cannot \"\n                            \"use a panel-type constitutive object. \"\n                            f\"CompIDs are: {repr(compIDs)}\"\n                        )\n\n                # Now we will \"order\" the edges if possible. This\n                # will also allow us to detect multiple loops\n                # which isn't allowed, or a non-manifold local\n                # geometry - ie. in this context a node connected\n                # to three edges. This is also not allowed.\n\n                nodeChain = [boundaryEdges[0][0], boundaryEdges[0][1]]\n                cont = True\n                curElem = 0\n                while cont:\n                    # We arbitrarily pick the first 'element'\n                    # (edge) containing the first two nodes of our\n                    # chain. Next step is to find the next element\n                    # and node in the chain:\n                    nextElems = nodeToElem[nodeChain[-1]]\n                    # Get the 'nextElem' that isn't the current\n                    # one\n                    if nextElems[0] == curElem:\n                        nextElem = nextElems[1]\n                    else:\n                        nextElem = nextElems[0]\n\n                    # Now nextElem is the next in the chain. Get\n                    # the nodes for this elem:\n                    nextNodes = boundaryEdges[nextElem]\n\n                    # Append the node that isn't the last one\n                    # (that is already in the chain)\n                    if nextNodes[0] == nodeChain[-1]:\n                        nodeChain.append(nextNodes[1])\n                    else:\n                        nodeChain.append(nextNodes[0])\n\n                    # Exit condition:\n                    if nodeChain[-1] == nodeChain[0]:\n                        # We've made it all the way around!\n                        cont = False\n\n                    # Set current element\n                    curElem = nextElem\n\n                # Now check that we've *actually* used all of our\n                # nodes. Since we've determined it is manifold,\n                # this must mean we have multiple loops which\n                # *also* isn't allowed.\n                if len(nodeChain) - 1 != len(boundaryEdges):\n                    raise ValueError(\n                        \"Detected more than one closed loop for \"\n                        \"constitutive object. This is not allowed. \"\n                        \"This constitutive object cannot use a \"\n                        \"panel-type constitutive object. \"\n                        f\"CompIDs are: {repr(compIDs)}\"\n                    )\n                nodeChain = nodeChain[:-1]\n                nodeChainCoords = self.meshLoader.getBDFNodes(\n                    nodeChain, nastranOrdering=False\n                )\n                nodeIDs, coords = simplifyPoly(nodeChain, nodeChainCoords)\n                boundaryNodeIDs[compID] = nodeIDs\n                boundaryNodeCoords[compID] = coords\n\n        return self.comm.bcast(boundaryNodeIDs, root=0), self.comm.bcast(\n            boundaryNodeCoords, root=0\n        )",
  "def __init__(\n        self,\n        name,\n        assembler,\n        comm,\n        outputViewer=None,\n        meshLoader=None,\n        options=None,\n    ):\n        \"\"\"\n        NOTE: This class should not be initialized directly by the user.\n        Use pyTACS.createPanelLengthConstraint instead.\n\n        Parameters\n        ----------\n        name : str\n            Name of this tacs problem\n\n        assembler : TACS.Assembler\n            Cython object responsible for creating and setting tacs objects used to solve problem\n\n        comm : mpi4py.MPI.Intracomm\n            The comm object on which to create the pyTACS object.\n\n        outputViewer : TACS.TACSToFH5\n            Cython object used to write out f5 files that can be converted and used for postprocessing.\n\n        meshLoader : pymeshloader.pyMeshLoader\n            pyMeshLoader object used to create the assembler.\n\n        options : dict\n            Dictionary holding problem-specific option parameters (case-insensitive).\n        \"\"\"\n\n        # Problem name\n        self.name = name\n\n        # Default setup for common constraint class objects, sets up comm and options\n        TACSConstraint.__init__(\n            self, assembler, comm, options, outputViewer, meshLoader\n        )\n\n        # Create a map from the global DV index to the proc index that owns it and the local index on that proc\n        self.globalToLocalDVNumsOnProc = self.comm.gather(\n            self.globalToLocalDVNums, root=0\n        )\n        self.DVMap = {}\n        if self.rank == 0:\n            for procInd in range(self.comm.size):\n                for globalInd, localInd in self.globalToLocalDVNumsOnProc[\n                    procInd\n                ].items():\n                    self.DVMap[globalInd] = {\"proc\": procInd, \"localInd\": localInd}\n\n        # Now create the same thing for the nodes\n        nodeDict = self.meshLoader.getGlobalToLocalNodeIDDict()\n        nodeDicts = self.comm.gather(nodeDict, root=0)\n        self.nodeMap = {}\n        if self.rank == 0:\n            for procInd in range(self.comm.size):\n                for globalInd, localInd in nodeDicts[procInd].items():\n                    self.nodeMap[globalInd] = {\"proc\": procInd, \"localInd\": localInd}\n\n        # Store the number of DVs and nodes on each proc\n        self.numLocalDVs = self.getNumDesignVars()\n\n        self.computePanelLength = computePanelLength\n        self.computePanelLengthSens = computePanelLengthSens\n\n        # Store flags for whether or not we need to recompute the constraints and derivatives\n        self.constraintsUpToDate = {}\n        self.funcs = {}\n        self.constraintsSensUpToDate = {}\n        self.funcsSens = {}",
  "def setDesignVars(self, x):\n        \"\"\"\n        Update the design variables used by tacs.\n\n        Parameters\n        ----------\n        x : numpy.ndarray or dict or tacs.TACS.Vec\n            The variables (typically from the optimizer) to set. It\n            looks for variable in the ``self.varName`` attribute if in dict.\n\n        \"\"\"\n        TACSConstraint.setDesignVars(self, x)\n        for key in self.constraintsUpToDate:\n            self.constraintsUpToDate[key] = False",
  "def setNodes(self, Xpts):\n        \"\"\"\n        Set the mesh coordinates of the structure.\n\n        Parameters\n        ----------\n        coords : numpy.ndarray\n            Structural coordinate in array of size (N * 3) where N is\n            the number of structural nodes on this processor.\n        \"\"\"\n        TACSConstraint.setNodes(self, Xpts)\n        for key in self.constraintsUpToDate:\n            self.constraintsUpToDate[key] = False\n            self.constraintsSensUpToDate[key] = False",
  "def addConstraint(self, conName, compIDs=None, lower=None, upper=None, dvIndex=0):\n        \"\"\"\n        Generic method to adding a new constraint set for TACS.\n\n        Parameters\n        ----------\n        conName : str\n            The user-supplied name for the constraint set. This will\n            typically be a string that is meaningful to the user\n\n        compIDs: list[int] or None\n            List of compIDs to apply constraints to. If None, all compIDs will be used. Defaults to None.\n\n        lower: float or complex\n            lower bound for constraint. Not used.\n\n        upper: float or complex\n            upper bound for constraint. Not used.\n\n        dvIndex : int\n            Index number of the panel length DV's. Defaults to 0.\n\n        \"\"\"\n        if compIDs is not None:\n            # Make sure CompIDs is flat and get element numbers on each proc corresponding to specified compIDs\n            compIDs = self._flatten(compIDs)\n        else:\n            nComps = self.meshLoader.getNumComponents()\n            compIDs = range(nComps)\n\n        dvGlobalInds = []\n        dvProcs = []\n        dvLocalInds = []\n        boundaryNodeGlobalInds = []\n        boundaryNodeLocalInds = []\n        boundaryNodeLocalProcs = []\n        refAxes = []\n        dvJacRows = []\n        dvJacCols = []\n        dvJacVals = []\n        coordJacRows = []\n        coordJacCols = []\n        for ii in range(self.comm.size):\n            dvJacRows.append([])\n            dvJacCols.append([])\n            dvJacVals.append([])\n            coordJacRows.append([])\n            coordJacCols.append([])\n\n        # Get the boundary node IDs for each component\n        boundaryNodeIDs, boundaryNodeCoords = self._getComponentBoundaryNodes(compIDs)\n\n        if self.rank == 0:\n            constraintInd = 0\n            for compID in compIDs:\n                # Get the TACS element object associated with this compID to\n                # get the ref axis\n                elemObj = self.meshLoader.getElementObject(compID, 0)\n                transObj = elemObj.getTransform()\n                try:\n                    refAxis = transObj.getRefAxis()\n                except AttributeError as e:\n                    raise AttributeError(\n                        f\"The elements in component {self.meshLoader.compDescripts[compID]} do not have a reference axis. Please define one by using the 'ShellRefAxisTransform' class with your elements\"\n                    ) from e\n\n                # For a more accurate length calculation, roject the ref axis\n                # onto the \"average\" plane of the baseline panel geometry by\n                # using an SVD to compute a normal vector\n                centroid = np.mean(boundaryNodeCoords[compID], axis=0, keepdims=True)\n                centredPoints = boundaryNodeCoords[compID] - centroid\n                _, _, VT = np.linalg.svd(centredPoints, full_matrices=False)\n                panelNormal = VT[-1]\n                refAxis -= np.dot(refAxis, panelNormal) * panelNormal\n                refAxis /= np.linalg.norm(refAxis)\n                refAxes.append(refAxis)\n\n                # Now figure out where the DV for this component lives\n                globalDvNums = elemObj.getDesignVarNums(0)\n                dvGlobalInds.append(globalDvNums[dvIndex])\n                dvProcs.append(self.DVMap[globalDvNums[dvIndex]][\"proc\"])\n                dvLocalInds.append(self.DVMap[globalDvNums[dvIndex]][\"localInd\"])\n\n                # Do the same for the boundary nodes, this is a little more\n                # complicated because each node may be on a different proc\n                GlobalInds = []\n                LocalInds = []\n                LocalProcs = []\n                for nodeID in boundaryNodeIDs[compID]:\n                    GlobalInds.append(nodeID)\n                    LocalInds.append(self.nodeMap[nodeID][\"localInd\"])\n                    LocalProcs.append(self.nodeMap[nodeID][\"proc\"])\n                boundaryNodeGlobalInds.append(GlobalInds)\n                boundaryNodeLocalInds.append(LocalInds)\n                boundaryNodeLocalProcs.append(LocalProcs)\n\n                # Figure out the jacobian sparsity for each proc\n                # The DV jacobian on the proc that owns this component's DV\n                # will have a -1 in the row corresponding to this constraint\n                # and the column corresponding to the local DV index\n                dvJacRows[dvProcs[-1]].append(constraintInd)\n                dvJacCols[dvProcs[-1]].append(dvLocalInds[-1])\n                dvJacVals[dvProcs[-1]].append(-1.0)\n\n                for ii in range(len(boundaryNodeIDs[compID])):\n                    # the coordinate jacobian on the proc that owns this node\n                    # will have 3 entries in the row corresponding to this\n                    # constraint and the columns corresponding to the local\n                    # node index on the proc\n                    proc = boundaryNodeLocalProcs[-1][ii]\n                    localNodeInd = boundaryNodeLocalInds[-1][ii]\n                    coordJacRows[proc] += [constraintInd] * 3\n                    coordJacCols[proc] += [\n                        3 * localNodeInd,\n                        3 * localNodeInd + 1,\n                        3 * localNodeInd + 2,\n                    ]\n\n                constraintInd += 1\n\n            # Add the constraint to the constraint list, we need to store:\n            # - The size of this constraint\n            # - The global index of each DV\n            # - The proc number that is in charge of each DV\n            # - The local index of each DV on the proc that is in charge of it\n            # - The global boundary node IDs for each component\n            # - The proc that owns each boundary node for each component\n            # - The local index of each boundary node on the proc that owns it\n            # - The reference axis direction for each component\n            # - The DV jacobian for each proc (because it's constant)\n            # - The coordinate jacobian sparsity pattern for each proc (because it's also constant)\n            self.constraintList[conName] = {\n                \"nCon\": len(compIDs),\n                \"compIDs\": compIDs,\n                \"dvGlobalInds\": dvGlobalInds,\n                \"dvProcs\": dvProcs,\n                \"dvLocalInds\": dvLocalInds,\n                \"boundaryNodeGlobalInds\": boundaryNodeGlobalInds,\n                \"boundaryNodeLocalInds\": boundaryNodeLocalInds,\n                \"boundaryNodeLocalProcs\": boundaryNodeLocalProcs,\n                \"refAxes\": refAxes,\n            }\n        else:\n            self.constraintList[conName] = {\"nCon\": len(compIDs)}\n            dvJacRows = None\n            dvJacCols = None\n            dvJacVals = None\n            coordJacRows = None\n            coordJacCols = None\n\n        # These constraints are linear w.r.t the DVs so we can just precompute\n        # the DV jacobian for each proc\n        dvJacRows = self.comm.scatter(dvJacRows, root=0)\n        dvJacCols = self.comm.scatter(dvJacCols, root=0)\n        dvJacVals = self.comm.scatter(dvJacVals, root=0)\n        coordJacRows = self.comm.scatter(coordJacRows, root=0)\n        coordJacCols = self.comm.scatter(coordJacCols, root=0)\n        self.constraintList[conName][\"dvJac\"] = sp.sparse.csr_matrix(\n            (dvJacVals, (dvJacRows, dvJacCols)),\n            shape=(len(compIDs), self.numLocalDVs),\n        )\n\n        # The constraints aren't linear w.r.t the coordinates, but the\n        # sparsity pattern is constant so we can store that\n        self.constraintList[conName][\"coordJacRows\"] = coordJacRows\n        self.constraintList[conName][\"coordJacCols\"] = coordJacCols\n\n        self.constraintsUpToDate[conName] = False\n        self.constraintsSensUpToDate[conName] = False\n        success = True\n\n        return success",
  "def getConstraintBounds(self, bounds, evalCons=None):\n        \"\"\"\n        Get bounds for constraints. The constraints corresponding to the strings in\n        `evalCons` are evaluated and updated into the provided\n        dictionary.\n\n        The panel length constraints are equality constraints so both the upper and lower bounds are zero\n\n        Parameters\n        ----------\n        bounds : dict\n            Dictionary into which the constraint bounds are saved.\n            Bounds will be saved as a tuple: (lower, upper)\n        evalCons : iterable object containing strings.\n            If not none, use these constraints to evaluate.\n\n        Examples\n        --------\n        >>> conBounds = {}\n        >>> tacsConstraint.getConstraintBounds(conBounds, 'LE_SPAR')\n        >>> conBounds\n        >>> # Result will look like (if TACSConstraint has name of 'c1'):\n        >>> # {'c1_LE_SPAR': (array([-1e20]), array([1e20]))}\n        \"\"\"\n        # Check if user specified which constraints to output\n        # Otherwise, output them all\n        evalCons = self._processEvalCons(evalCons)\n\n        # Loop through each requested constraint set\n        for conName in evalCons:\n            key = f\"{self.name}_{conName}\"\n            nCon = self.constraintList[conName][\"nCon\"]\n            bounds[key] = (np.zeros(nCon), np.zeros(nCon))",
  "def getConstraintSizes(self, sizes, evalCons=None):\n        \"\"\"\n        Get number for constraint equations in each set.\n        The constraints corresponding to the strings in `evalCons`\n        are evaluated and updated into the provided dictionary.\n\n        Parameters\n        ----------\n        sizes : dict\n            Dictionary into which the constraint sizes are saved.\n        evalCons : iterable object containing strings.\n            If not none, use these constraints to evaluate.\n\n        Examples\n        --------\n        >>> conSizes = {}\n        >>> tacsConstraint.getConstraintSizes(conSizes, 'LE_SPAR')\n        >>> funconSizescs\n        >>> # Result will look like (if TACSConstraint has name of 'c1'):\n        >>> # {'c1_LE_SPAR': 10}\n        \"\"\"\n        # Check if user specified which constraints to output\n        # Otherwise, output them all\n        evalCons = self._processEvalCons(evalCons)\n\n        # Loop through each requested constraint set\n        for conName in evalCons:\n            key = f\"{self.name}_{conName}\"\n            sizes[key] = self.constraintList[conName][\"nCon\"]",
  "def evalConstraints(self, funcs, evalCons=None, ignoreMissing=False):\n        \"\"\"\n        Evaluate values for constraints. The constraints corresponding to the strings in\n        evalCons are evaluated and updated into the provided dictionary.\n\n        The same constraint arrays are returned on every proc\n\n        Parameters\n        ----------\n        funcs : dict\n            Dictionary into which the constraints are saved.\n        evalCons : iterable object containing strings.\n            If not none, use these constraints to evaluate.\n        ignoreMissing : bool\n            Flag to supress checking for a valid constraint. Please use\n            this option with caution.\n\n        Examples\n        --------\n        >>> funcs = {}\n        >>> adjConstraint.evalConstraints(funcs, 'LE_SPAR')\n        >>> funcs\n        >>> # Result will look like (if PanelLengthConstraint has name of 'c1'):\n        >>> # {'c1_LE_SPAR': array([1.325, 2.1983645, 3.1415926, ...])}\n        \"\"\"\n\n        # Check if user specified which constraints to output\n        # Otherwise, output them all\n        evalCons = self._processEvalCons(evalCons, ignoreMissing)\n\n        # We will compute everything on the root proc and then broadcast the\n        # results, this is definitely not the most efficient way to do this\n        # so we may want to re-do it in future, but this works for now\n\n        DVs = None\n        nodes = None\n\n        # Loop through each requested constraint set\n        for conName in evalCons:\n            key = f\"{self.name}_{conName}\"\n            nCon = self.constraintList[conName][\"nCon\"]\n            if self.constraintsUpToDate[conName]:\n                funcs[key] = np.copy(self.funcs[key])\n            else:\n                constraintValues = np.zeros(nCon, dtype=self.dtype)\n                if nodes is None:\n                    # Get all of the DVs and nodes on the root proc\n                    DVs = self.comm.gather(self.x.getArray(), root=0)\n                    nodes = self.comm.gather(self.Xpts.getArray(), root=0)\n                    if self.rank == 0:\n                        for ii in range(self.comm.size):\n                            nodes[ii] = nodes[ii].reshape(-1, 3)\n                if self.rank == 0:\n                    for ii in range(nCon):\n                        numPoints = len(\n                            self.constraintList[conName][\"boundaryNodeGlobalInds\"][ii]\n                        )\n                        boundaryPoints = np.zeros((numPoints, 3), dtype=self.dtype)\n                        for jj in range(numPoints):\n                            nodeProc = self.constraintList[conName][\n                                \"boundaryNodeLocalProcs\"\n                            ][ii][jj]\n                            localInd = self.constraintList[conName][\n                                \"boundaryNodeLocalInds\"\n                            ][ii][jj]\n                            boundaryPoints[jj] = nodes[nodeProc][localInd]\n                        refAxis = self.constraintList[conName][\"refAxes\"][ii]\n                        DVProc = self.constraintList[conName][\"dvProcs\"][ii]\n                        DVLocalInd = self.constraintList[conName][\"dvLocalInds\"][ii]\n                        constraintValues[ii] = (\n                            self.computePanelLength(boundaryPoints, refAxis)\n                            - DVs[DVProc][DVLocalInd]\n                        )\n                funcs[key] = self.comm.bcast(constraintValues, root=0)\n                self.funcs[key] = np.copy(funcs[key])\n                self.constraintsUpToDate[conName] = True",
  "def evalConstraintsSens(self, funcsSens, evalCons=None):\n        \"\"\"This is the main routine for returning useful (sensitivity)\n        information from constraint. The derivatives of the constraints\n        corresponding to the strings in evalCons are evaluated and\n        updated into the provided dictionary. The derivitives with\n        respect to all design variables and node locations are computed.\n\n        The sensitivities returned on each proc are a sparse m x n matrix\n        where m is the number of constraints and n is the number of design\n        variables or 3x the number of nodes on this proc. The matrix contains\n        the sensitivities of all constraints w.r.t only the design\n        variables/node coordinates on this proc.\n\n        Parameters\n        ----------\n        funcsSens : dict\n            Dictionary into which the derivatives are saved.\n        evalCons : iterable object containing strings\n            The constraints the user wants returned\n\n        Examples\n        --------\n        >>> funcsSens = {}\n        >>> adjConstraint.evalConstraintsSens(funcsSens, 'LE_SPAR')\n        >>> funcsSens\n        >>> # Result will look like (if AdjacencyConstraint has name of 'c1'):\n        >>> # {'c1_LE_SPAR':{'struct':<50x242 sparse matrix of type '<class 'numpy.float64'>' with 100 stored elements in Compressed Sparse Row format>}}\n        \"\"\"\n\n        # Check if user specified which constraints to output\n        # Otherwise, output them all\n        evalCons = self._processEvalCons(evalCons)\n\n        # We will compute everything on the root proc and then broadcast the results,\n        # this is definitely not the most efficient way to do this so we may want to\n        # re-do it in future, but this works for now\n\n        nodes = None\n\n        # Get number of nodes coords on this proc\n        nCoords = self.getNumCoordinates()\n\n        # Loop through each requested constraint set\n        for conName in evalCons:\n            key = f\"{self.name}_{conName}\"\n            nCon = self.constraintList[conName][\"nCon\"]\n            funcsSens[key] = {}\n            funcsSens[key][self.varName] = self.constraintList[conName][\"dvJac\"]\n            if self.constraintsSensUpToDate[conName]:\n                funcsSens[key][self.coordName] = self.funcsSens[key].copy()\n            else:\n                # Get all of the nodes on the root proc\n                if nodes is None:\n                    nodes = self.comm.gather(self.Xpts.getArray(), root=0)\n                    if self.rank == 0:\n                        for ii in range(self.comm.size):\n                            nodes[ii] = nodes[ii].reshape(-1, 3)\n                funcsSens[key][self.coordName] = sp.sparse.csr_matrix(\n                    (nCon, nCoords), dtype=self.dtype\n                )\n                if self.rank == 0:\n                    coordJacVals = []\n                    for ii in range(self.comm.size):\n                        coordJacVals.append([])\n                    for ii in range(nCon):\n                        numPoints = len(\n                            self.constraintList[conName][\"boundaryNodeGlobalInds\"][ii]\n                        )\n                        boundaryPoints = np.zeros((numPoints, 3), dtype=self.dtype)\n\n                        for jj in range(numPoints):\n                            nodeProc = self.constraintList[conName][\n                                \"boundaryNodeLocalProcs\"\n                            ][ii][jj]\n                            localInd = self.constraintList[conName][\n                                \"boundaryNodeLocalInds\"\n                            ][ii][jj]\n                            boundaryPoints[jj] = nodes[nodeProc][localInd]\n                        refAxis = self.constraintList[conName][\"refAxes\"][ii]\n                        LSens = self.computePanelLengthSens(boundaryPoints, refAxis)\n                        for jj in range(numPoints):\n                            nodeProc = self.constraintList[conName][\n                                \"boundaryNodeLocalProcs\"\n                            ][ii][jj]\n                            coordJacVals[nodeProc] += LSens[jj].tolist()\n                else:\n                    coordJacVals = None\n                coordJacVals = self.comm.scatter(coordJacVals, root=0)\n                coordJacRows = self.constraintList[conName][\"coordJacRows\"]\n                coordJacCols = self.constraintList[conName][\"coordJacCols\"]\n                self.funcsSens[key] = sp.sparse.csr_matrix(\n                    (coordJacVals, (coordJacRows, coordJacCols)),\n                    (nCon, nCoords),\n                    dtype=self.dtype,\n                )\n                funcsSens[key][self.coordName] = self.funcsSens[key].copy()\n                self.constraintsSensUpToDate[conName] = True",
  "def _getComponentBoundaryNodes(self, compIDs):\n        \"\"\"For a given list of components, find the nodes on the boundaries of\n        each of the components.\n\n        The results are broadcast to all procs\n\n        Parameters\n        ----------\n        compIDs: list[int]\n            List of compIDs to find boundaries of.\n\n        Returns\n        --------\n        dict[int, list[int]]\n            Dictionary where dict[compID] = sorted list of nodeIDs on the\n            boundary of the component\n        dict[int, np.array]\n            Dictionary where dict[compID] = array of node coordinates on the\n            boundary of the component\n        \"\"\"\n\n        boundaryNodeIDs = {}\n        boundaryNodeCoords = {}\n\n        if self.rank == 0:\n            for compID in compIDs:\n                allEdges = set()\n                dupEdges = set()\n                compConn = self.meshLoader.getConnectivityForComp(\n                    compID, nastranOrdering=False\n                )\n                # Go over all the elements in the component and add their edges to the sets of all and possibly duplicate edges\n                for elemConn in compConn:\n                    nnodes = len(elemConn)\n                    if nnodes >= 2:\n                        for j in range(nnodes):\n                            nodeID1 = elemConn[j]\n                            nodeID2 = elemConn[(j + 1) % nnodes]\n\n                            if nodeID1 < nodeID2:\n                                key = (nodeID1, nodeID2)\n                            else:\n                                key = (nodeID2, nodeID1)\n\n                            # Skip degenerate edges\n                            if key[0] != key[1]:\n                                # Either add to allEdges or dupEdges depending on whether we've seen this edge before\n                                if key not in allEdges:\n                                    allEdges.add(key)\n                                else:\n                                    dupEdges.add(key)\n                # Now get a list of all the edges that aren't duplicated, these are the boundary edges\n                boundaryEdges = list(allEdges - dupEdges)\n\n                # Create a nodeToElem Pointer using a dictionary:\n                nodeToElem = {}\n                for iEdge in range(len(boundaryEdges)):\n                    edge = boundaryEdges[iEdge]\n                    for ii in range(2):\n                        if edge[ii] in nodeToElem:\n                            nodeToElem[edge[ii]].append(iEdge)\n                        else:\n                            nodeToElem[edge[ii]] = [iEdge]\n\n                # Now check that each nodeToElem has a length of\n                # 2. This means we have a chance it is a\n                # closed curve\n                for key in nodeToElem:\n                    if len(nodeToElem[key]) != 2:\n                        raise ValueError(\n                            \"The topology of the geometry associated with \"\n                            \"a constitutive object is not manifold \"\n                            \"(There is a node with three or more edges \"\n                            \"attached. This constitutive object cannot \"\n                            \"use a panel-type constitutive object. \"\n                            f\"CompIDs are: {repr(compIDs)}\"\n                        )\n\n                # Now we will \"order\" the edges if possible. This\n                # will also allow us to detect multiple loops\n                # which isn't allowed, or a non-manifold local\n                # geometry - ie. in this context a node connected\n                # to three edges. This is also not allowed.\n\n                nodeChain = [boundaryEdges[0][0], boundaryEdges[0][1]]\n                cont = True\n                curElem = 0\n                while cont:\n                    # We arbitrarily pick the first 'element'\n                    # (edge) containing the first two nodes of our\n                    # chain. Next step is to find the next element\n                    # and node in the chain:\n                    nextElems = nodeToElem[nodeChain[-1]]\n                    # Get the 'nextElem' that isn't the current\n                    # one\n                    if nextElems[0] == curElem:\n                        nextElem = nextElems[1]\n                    else:\n                        nextElem = nextElems[0]\n\n                    # Now nextElem is the next in the chain. Get\n                    # the nodes for this elem:\n                    nextNodes = boundaryEdges[nextElem]\n\n                    # Append the node that isn't the last one\n                    # (that is already in the chain)\n                    if nextNodes[0] == nodeChain[-1]:\n                        nodeChain.append(nextNodes[1])\n                    else:\n                        nodeChain.append(nextNodes[0])\n\n                    # Exit condition:\n                    if nodeChain[-1] == nodeChain[0]:\n                        # We've made it all the way around!\n                        cont = False\n\n                    # Set current element\n                    curElem = nextElem\n\n                # Now check that we've *actually* used all of our\n                # nodes. Since we've determined it is manifold,\n                # this must mean we have multiple loops which\n                # *also* isn't allowed.\n                if len(nodeChain) - 1 != len(boundaryEdges):\n                    raise ValueError(\n                        \"Detected more than one closed loop for \"\n                        \"constitutive object. This is not allowed. \"\n                        \"This constitutive object cannot use a \"\n                        \"panel-type constitutive object. \"\n                        f\"CompIDs are: {repr(compIDs)}\"\n                    )\n                nodeChain = nodeChain[:-1]\n                nodeChainCoords = self.meshLoader.getBDFNodes(\n                    nodeChain, nastranOrdering=False\n                )\n                nodeIDs, coords = simplifyPoly(nodeChain, nodeChainCoords)\n                boundaryNodeIDs[compID] = nodeIDs\n                boundaryNodeCoords[compID] = coords\n\n        return self.comm.bcast(boundaryNodeIDs, root=0), self.comm.bcast(\n            boundaryNodeCoords, root=0\n        )",
  "class Load:\n    \"\"\"\n    Base class for FEA loads into the tacsAIM in ESP/CAPS\n    load = {\"groupName\" : \"plate\",\n            \"loadType\" : \"Pressure\",\n            \"pressureForce\" : pressload}\n    caps_load\n        matches caps load attribute in CSM file\n    \"\"\"\n\n    def __init__(self, name: str, caps_load: str, load_type: str):\n        assert load_type in [\n            \"GridForce\",\n            \"GridMoment\",\n            \"Rotational\",\n            \"Thermal\",\n            \"Pressure\",\n            \"PressureDistribute\",\n            \"PressureExternal\",\n            \"Gravity\",\n        ]\n        self._name = name\n        self._caps_load = caps_load\n        self._load_type = load_type\n\n    @property\n    def name(self) -> str:\n        return self._name\n\n    def register_to(self, tacs_aim):\n        \"\"\"\n        cascaded method to register this load to TacsAim\n        \"\"\"\n        tacs_aim.register(self)\n        return self",
  "class Pressure(Load):\n    \"\"\"\n    Apply pressure loads to the FEA structure\n    \"\"\"\n\n    def __init__(self, caps_load: str, name: str = None, force: float = 2.0e6):\n        if name is None:\n            name = f\"Pressure_{caps_load}\"\n        super(Pressure, self).__init__(\n            name=name, caps_load=caps_load, load_type=\"Pressure\"\n        )\n        self._pressure_force = force\n\n    @property\n    def dictionary(self) -> dict:\n        return {\n            \"groupName\": self._caps_load,\n            \"loadType\": self._load_type,\n            \"pressureForce\": self._pressure_force,\n        }",
  "class GridForce(Load):\n    \"\"\"\n    Apply body forces to the FEA problem in tacsAIM\n    \"\"\"\n\n    def __init__(\n        self,\n        caps_load: str,\n        name: str = None,\n        direction: List[float] = [0.0, 0.0, 1.0],\n        magnitude: float = 1.0e3,\n    ):\n        if name is None:\n            name = f\"GridForce_{caps_load}\"\n        super(GridForce, self).__init__(\n            name=name, caps_load=caps_load, load_type=\"GridForce\"\n        )\n        self._direction_vector = direction\n        self._force_scale_factor = magnitude\n\n    @property\n    def dictionary(self) -> dict:\n        return {\n            \"groupName\": self._caps_load,\n            \"loadType\": self._load_type,\n            \"directionVector\": self._direction_vector,\n            \"forceScaleFactor\": self._force_scale_factor,\n        }",
  "def __init__(self, name: str, caps_load: str, load_type: str):\n        assert load_type in [\n            \"GridForce\",\n            \"GridMoment\",\n            \"Rotational\",\n            \"Thermal\",\n            \"Pressure\",\n            \"PressureDistribute\",\n            \"PressureExternal\",\n            \"Gravity\",\n        ]\n        self._name = name\n        self._caps_load = caps_load\n        self._load_type = load_type",
  "def name(self) -> str:\n        return self._name",
  "def register_to(self, tacs_aim):\n        \"\"\"\n        cascaded method to register this load to TacsAim\n        \"\"\"\n        tacs_aim.register(self)\n        return self",
  "def __init__(self, caps_load: str, name: str = None, force: float = 2.0e6):\n        if name is None:\n            name = f\"Pressure_{caps_load}\"\n        super(Pressure, self).__init__(\n            name=name, caps_load=caps_load, load_type=\"Pressure\"\n        )\n        self._pressure_force = force",
  "def dictionary(self) -> dict:\n        return {\n            \"groupName\": self._caps_load,\n            \"loadType\": self._load_type,\n            \"pressureForce\": self._pressure_force,\n        }",
  "def __init__(\n        self,\n        caps_load: str,\n        name: str = None,\n        direction: List[float] = [0.0, 0.0, 1.0],\n        magnitude: float = 1.0e3,\n    ):\n        if name is None:\n            name = f\"GridForce_{caps_load}\"\n        super(GridForce, self).__init__(\n            name=name, caps_load=caps_load, load_type=\"GridForce\"\n        )\n        self._direction_vector = direction\n        self._force_scale_factor = magnitude",
  "def dictionary(self) -> dict:\n        return {\n            \"groupName\": self._caps_load,\n            \"loadType\": self._load_type,\n            \"directionVector\": self._direction_vector,\n            \"forceScaleFactor\": self._force_scale_factor,\n        }",
  "def root_proc(method):\n    @wraps(method)\n    def wrapped_method(self, *args, **kwargs):\n        if self.comm is None or self.comm.rank == 0:\n            return method(self, *args, **kwargs)\n        else:\n\n            def empty_function(self):\n                return\n\n            return empty_function\n\n    return wrapped_method",
  "def root_broadcast(method):\n    @wraps(method)\n    def wrapped_method(self, *args, **kwargs):\n        if self.comm is None:\n            return method(self, *args, **kwargs)\n        else:\n            output = None\n            if self.comm.rank == 0:\n                output = method(self, *args, **kwargs)\n            output = self.comm.bcast(output, root=0)\n            return output\n\n    return wrapped_method",
  "def wrapped_method(self, *args, **kwargs):\n        if self.comm is None or self.comm.rank == 0:\n            return method(self, *args, **kwargs)\n        else:\n\n            def empty_function(self):\n                return\n\n            return empty_function",
  "def wrapped_method(self, *args, **kwargs):\n        if self.comm is None:\n            return method(self, *args, **kwargs)\n        else:\n            output = None\n            if self.comm.rank == 0:\n                output = method(self, *args, **kwargs)\n            output = self.comm.bcast(output, root=0)\n            return output",
  "def empty_function(self):\n                return",
  "class Constraint:\n    def __init__(\n        self,\n        name: str,\n        caps_constraint: str,\n        dof_constraint: int,\n        grid_displacement: float = 0.0,\n    ):\n        \"\"\"\n        Base class for ESP/CAPS constraint wrapper class\n        \"\"\"\n        dof_str = str(dof_constraint)\n        for char in dof_str:\n            assert int(char) in range(\n                0, 7\n            )  # means only allow dof 0-6, see pyMeshLoader _isDOFinString for more info\n        self._name = name\n        self._caps_constraint = caps_constraint\n        self._dof_constraint = dof_constraint\n        self._grid_displacement = grid_displacement\n\n    @property\n    def name(self) -> str:\n        return self._name\n\n    @property\n    def dictionary(self) -> dict:\n        return {\n            \"groupName\": self._caps_constraint,\n            \"constraintType\": \"Displacement\",\n            \"dofConstraint\": self._dof_constraint,\n            \"gridDisplacement\": self._grid_displacement,\n        }\n\n    def register_to(self, tacs_aim):\n        \"\"\"\n        cascaded method to register this constraint to TacsAim\n        \"\"\"\n        tacs_aim.register(self)\n        return self",
  "class PinConstraint(Constraint):\n    def __init__(\n        self, caps_constraint: str, name: str = None, dof_constraint: int = 123\n    ):\n        \"\"\"\n        Elastic pin ESP/CAPS Constraint by default\n        Can change the dof to other than u=v=w=0 aka 123\n        \"\"\"\n        if name is None:\n            name = f\"elastic_{caps_constraint}\"\n        super(PinConstraint, self).__init__(\n            name=name,\n            caps_constraint=caps_constraint,\n            dof_constraint=dof_constraint,\n        )\n\n    @property\n    def dictionary(self) -> dict:\n        return {\n            \"groupName\": self._caps_constraint,\n            \"constraintType\": \"ZeroDisplacement\",\n            \"dofConstraint\": self._dof_constraint,\n        }",
  "class TemperatureConstraint(Constraint):\n    def __init__(\n        self, caps_constraint: str, name: str = None, temperature: float = 0.0\n    ):\n        \"\"\"\n        Isothermal constraints in ESP/CAPS for the TacsAim\n        \"\"\"\n        if name is None:\n            name = f\"thermal_{caps_constraint}\"\n        super(TemperatureConstraint, self).__init__(\n            name=name,\n            caps_constraint=caps_constraint,\n            dof_constraint=0,\n            grid_displacement=temperature,\n        )\n\n    @property\n    def dictionary(self) -> dict:\n        return super(TemperatureConstraint, self).dictionary",
  "def __init__(\n        self,\n        name: str,\n        caps_constraint: str,\n        dof_constraint: int,\n        grid_displacement: float = 0.0,\n    ):\n        \"\"\"\n        Base class for ESP/CAPS constraint wrapper class\n        \"\"\"\n        dof_str = str(dof_constraint)\n        for char in dof_str:\n            assert int(char) in range(\n                0, 7\n            )  # means only allow dof 0-6, see pyMeshLoader _isDOFinString for more info\n        self._name = name\n        self._caps_constraint = caps_constraint\n        self._dof_constraint = dof_constraint\n        self._grid_displacement = grid_displacement",
  "def name(self) -> str:\n        return self._name",
  "def dictionary(self) -> dict:\n        return {\n            \"groupName\": self._caps_constraint,\n            \"constraintType\": \"Displacement\",\n            \"dofConstraint\": self._dof_constraint,\n            \"gridDisplacement\": self._grid_displacement,\n        }",
  "def register_to(self, tacs_aim):\n        \"\"\"\n        cascaded method to register this constraint to TacsAim\n        \"\"\"\n        tacs_aim.register(self)\n        return self",
  "def __init__(\n        self, caps_constraint: str, name: str = None, dof_constraint: int = 123\n    ):\n        \"\"\"\n        Elastic pin ESP/CAPS Constraint by default\n        Can change the dof to other than u=v=w=0 aka 123\n        \"\"\"\n        if name is None:\n            name = f\"elastic_{caps_constraint}\"\n        super(PinConstraint, self).__init__(\n            name=name,\n            caps_constraint=caps_constraint,\n            dof_constraint=dof_constraint,\n        )",
  "def dictionary(self) -> dict:\n        return {\n            \"groupName\": self._caps_constraint,\n            \"constraintType\": \"ZeroDisplacement\",\n            \"dofConstraint\": self._dof_constraint,\n        }",
  "def __init__(\n        self, caps_constraint: str, name: str = None, temperature: float = 0.0\n    ):\n        \"\"\"\n        Isothermal constraints in ESP/CAPS for the TacsAim\n        \"\"\"\n        if name is None:\n            name = f\"thermal_{caps_constraint}\"\n        super(TemperatureConstraint, self).__init__(\n            name=name,\n            caps_constraint=caps_constraint,\n            dof_constraint=0,\n            grid_displacement=temperature,\n        )",
  "def dictionary(self) -> dict:\n        return super(TemperatureConstraint, self).dictionary",
  "class ShapeVariable:\n    \"\"\"\n    shape variables in ESP/CAPS are design parameters that affect the structural geometry\n    \"\"\"\n\n    def __init__(self, name: str, value=None):\n        \"\"\"\n        ESP/CAPS shape variable controls a design parameter in the CSM file\n            name: corresponds to the design parameter in the CSM file\n            value: can be used to modify the design parameter\n        \"\"\"\n        self.name = name\n        self._value = value\n\n    @property\n    def DV_dictionary(self) -> dict:\n        return {}\n\n    def register_to(self, tacs_aim):\n        \"\"\"\n        cascaded method to register this ShapeVariable to TacsAim\n        \"\"\"\n        tacs_aim.register(self)\n        return self\n\n    @property\n    def value(self) -> float:\n        return self._value\n\n    @value.setter\n    def value(self, new_value: float):\n        self._value = new_value",
  "class ThicknessVariable:\n    \"\"\"\n    Caps Thickness Variables control membrane thickness of shell elements\n    \"\"\"\n\n    def __init__(\n        self,\n        caps_group: str,\n        value: float = 1.0,\n        name: str = None,\n        lower_bound: float = None,\n        upper_bound: float = None,\n        max_delta: float = None,\n        material: Material = None,\n    ):\n        \"\"\"\n        ESP/CAPS Thickness variable sets the thickness over a portion of the geometry in the CSM file\n            caps_group: corresponds to the geometry attribute CapsGroup in the CSM file\n        Optional arguments\n            value: sets the membrane thickness of that section of the geometry's shell elements\n            material: corresponding material, can be used to auto-create a shell property\n            name: name of the variable, can be set to the same as caps_group\n            lower_bound, upper_bound, and max_delta are bounds for optimization\n        \"\"\"\n        self.caps_group = caps_group\n        self._value = value\n        if name is not None:  # copy caps_group to name if not specified\n            self.name = name\n        else:\n            self.name = caps_group\n        self.lower_bound = lower_bound\n        self.upper_bound = upper_bound\n        self.max_delta = max_delta\n\n        # private variables used to create shell property\n        self._material = material\n\n    def material(self, material: Material):\n        \"\"\"\n        method cascading setter method\n        \"\"\"\n        self._material = material\n        return self\n\n    def set_bounds(self, lower_bound: float, value: float, upper_bound: float):\n        self.lower_bound = lower_bound\n        self.value = value\n        self.upper_bound = upper_bound\n        return self\n\n    @property\n    def value(self) -> float:\n        return self._value\n\n    @value.setter\n    def value(self, new_value: float):\n        self.lower_bound = 0.5 * new_value\n        self._value = new_value\n        self.upper_bound = 2.0 * new_value\n        return\n\n    @property\n    def can_make_shell(self):\n        return self._material is not None and self.value is not None\n\n    @property\n    def DV_dictionary(self) -> dict:\n        \"\"\"\n        ESP/CAPS design variable dictionary\n        \"\"\"\n        return {\n            \"groupName\": self.caps_group,\n            \"initialValue\": self.value,\n            \"lowerBound\": self.lower_bound\n            if self.lower_bound is not None\n            else self.value * 0.5,\n            \"upperBound\": self.upper_bound\n            if self.upper_bound is not None\n            else self.value * 2.0,\n            \"maxDelta\": self.max_delta\n            if self.max_delta is not None\n            else self.value * 0.1,\n        }\n\n    @property\n    def DVR_dictionary(self) -> dict:\n        \"\"\"\n        ESP/CAPS design variable relations dictionary\n        \"\"\"\n        return {\n            \"componentType\": \"Property\",\n            \"fieldName\": \"T\",\n            \"componentName\": self.caps_group,\n            \"variableName\": self.name,\n        }\n\n    @property\n    def shell_property(self) -> ShellProperty:\n        assert self._material is not None\n        return ShellProperty(\n            caps_group=self.caps_group,\n            material=self._material,\n            membrane_thickness=self.value,\n        )\n\n    def register_to(self, tacs_aim):\n        \"\"\"\n        cascaded method to register this ThicknessVariable to TacsAim\n        \"\"\"\n        tacs_aim.register(self)\n        return self",
  "def __init__(self, name: str, value=None):\n        \"\"\"\n        ESP/CAPS shape variable controls a design parameter in the CSM file\n            name: corresponds to the design parameter in the CSM file\n            value: can be used to modify the design parameter\n        \"\"\"\n        self.name = name\n        self._value = value",
  "def DV_dictionary(self) -> dict:\n        return {}",
  "def register_to(self, tacs_aim):\n        \"\"\"\n        cascaded method to register this ShapeVariable to TacsAim\n        \"\"\"\n        tacs_aim.register(self)\n        return self",
  "def value(self) -> float:\n        return self._value",
  "def value(self, new_value: float):\n        self._value = new_value",
  "def __init__(\n        self,\n        caps_group: str,\n        value: float = 1.0,\n        name: str = None,\n        lower_bound: float = None,\n        upper_bound: float = None,\n        max_delta: float = None,\n        material: Material = None,\n    ):\n        \"\"\"\n        ESP/CAPS Thickness variable sets the thickness over a portion of the geometry in the CSM file\n            caps_group: corresponds to the geometry attribute CapsGroup in the CSM file\n        Optional arguments\n            value: sets the membrane thickness of that section of the geometry's shell elements\n            material: corresponding material, can be used to auto-create a shell property\n            name: name of the variable, can be set to the same as caps_group\n            lower_bound, upper_bound, and max_delta are bounds for optimization\n        \"\"\"\n        self.caps_group = caps_group\n        self._value = value\n        if name is not None:  # copy caps_group to name if not specified\n            self.name = name\n        else:\n            self.name = caps_group\n        self.lower_bound = lower_bound\n        self.upper_bound = upper_bound\n        self.max_delta = max_delta\n\n        # private variables used to create shell property\n        self._material = material",
  "def material(self, material: Material):\n        \"\"\"\n        method cascading setter method\n        \"\"\"\n        self._material = material\n        return self",
  "def set_bounds(self, lower_bound: float, value: float, upper_bound: float):\n        self.lower_bound = lower_bound\n        self.value = value\n        self.upper_bound = upper_bound\n        return self",
  "def value(self) -> float:\n        return self._value",
  "def value(self, new_value: float):\n        self.lower_bound = 0.5 * new_value\n        self._value = new_value\n        self.upper_bound = 2.0 * new_value\n        return",
  "def can_make_shell(self):\n        return self._material is not None and self.value is not None",
  "def DV_dictionary(self) -> dict:\n        \"\"\"\n        ESP/CAPS design variable dictionary\n        \"\"\"\n        return {\n            \"groupName\": self.caps_group,\n            \"initialValue\": self.value,\n            \"lowerBound\": self.lower_bound\n            if self.lower_bound is not None\n            else self.value * 0.5,\n            \"upperBound\": self.upper_bound\n            if self.upper_bound is not None\n            else self.value * 2.0,\n            \"maxDelta\": self.max_delta\n            if self.max_delta is not None\n            else self.value * 0.1,\n        }",
  "def DVR_dictionary(self) -> dict:\n        \"\"\"\n        ESP/CAPS design variable relations dictionary\n        \"\"\"\n        return {\n            \"componentType\": \"Property\",\n            \"fieldName\": \"T\",\n            \"componentName\": self.caps_group,\n            \"variableName\": self.name,\n        }",
  "def shell_property(self) -> ShellProperty:\n        assert self._material is not None\n        return ShellProperty(\n            caps_group=self.caps_group,\n            material=self._material,\n            membrane_thickness=self.value,\n        )",
  "def register_to(self, tacs_aim):\n        \"\"\"\n        cascaded method to register this ThicknessVariable to TacsAim\n        \"\"\"\n        tacs_aim.register(self)\n        return self",
  "class EgadsAim:\n    \"\"\"\n    Wrapper class for ESP/CAPS EgadsAim to build structure mesh for TacsAim\n    Controls the following inputs:\n    egadsAim.input.Edge_Point_Min = 15\n    egadsAim.input.Edge_Point_Max = 20\n    egadsAim.input.Mesh_Elements = \"Quad\"\n    egadsAim.input.Tess_Params = [.25,.01,15]\n    \"\"\"\n\n    def __init__(self, caps_problem, comm):\n        self.comm = comm\n\n        self._dictOptions = None\n\n        if comm is None or comm.rank == 0:\n            self._aim = caps_problem.analysis.create(aim=\"egadsTessAIM\")\n        self._is_setup = False\n\n    def set_mesh(\n        self,\n        edge_pt_min: int = 15,\n        edge_pt_max=20,\n        mesh_elements: str = \"Quad\",\n        global_mesh_size: float = 0.25,\n        max_surf_offset: float = 0.01,\n        max_dihedral_angle: float = 15,\n    ):\n        \"\"\"\n        cascaded method to set the mesh input settings to the egadsAim\n        \"\"\"\n        if self.comm.rank == 0:\n            self._aim.input.Edge_Point_Min = edge_pt_min\n            self._aim.input.Edge_Point_Max = edge_pt_max\n            self._aim.input.Mesh_Elements = mesh_elements\n            self._aim.input.Tess_Params = [\n                global_mesh_size,\n                max_surf_offset,\n                max_dihedral_angle,\n            ]\n        self._is_setup = True\n        return self\n\n    def save_dict_options(self, dictOptions: dict = None):\n        \"\"\"\n        Optional method to set EGADS mesh settings using dictionaries.\n        Call this before setting up the TACS model. The dictionary should take\n        the form of, e.g.:\n\n        dictOptions['egadsTessAIM']['myOption'] = myValue\n        \"\"\"\n        self._dictOptions = dictOptions\n\n        return self\n\n    def _set_dict_options(self):\n        \"\"\"\n        Set EGADS options via dictionaries.\n        \"\"\"\n        dictOptions = self._dictOptions\n\n        if self.root_proc:\n            for ind, option in enumerate(dictOptions[\"egadsTessAIM\"]):\n                self.aim.input[option].value = dictOptions[\"egadsTessAIM\"][option]\n\n        return self\n\n    @property\n    def is_setup(self) -> bool:\n        return self._is_setup\n\n    @property\n    def aim(self):\n        return self._aim\n\n    def register_to(self, tacs_aim):\n        \"\"\"\n        cascade method to register the egads aim to the tacs aim wrapper class\n        \"\"\"\n        tacs_aim.register(self)\n        return self",
  "def __init__(self, caps_problem, comm):\n        self.comm = comm\n\n        self._dictOptions = None\n\n        if comm is None or comm.rank == 0:\n            self._aim = caps_problem.analysis.create(aim=\"egadsTessAIM\")\n        self._is_setup = False",
  "def set_mesh(\n        self,\n        edge_pt_min: int = 15,\n        edge_pt_max=20,\n        mesh_elements: str = \"Quad\",\n        global_mesh_size: float = 0.25,\n        max_surf_offset: float = 0.01,\n        max_dihedral_angle: float = 15,\n    ):\n        \"\"\"\n        cascaded method to set the mesh input settings to the egadsAim\n        \"\"\"\n        if self.comm.rank == 0:\n            self._aim.input.Edge_Point_Min = edge_pt_min\n            self._aim.input.Edge_Point_Max = edge_pt_max\n            self._aim.input.Mesh_Elements = mesh_elements\n            self._aim.input.Tess_Params = [\n                global_mesh_size,\n                max_surf_offset,\n                max_dihedral_angle,\n            ]\n        self._is_setup = True\n        return self",
  "def save_dict_options(self, dictOptions: dict = None):\n        \"\"\"\n        Optional method to set EGADS mesh settings using dictionaries.\n        Call this before setting up the TACS model. The dictionary should take\n        the form of, e.g.:\n\n        dictOptions['egadsTessAIM']['myOption'] = myValue\n        \"\"\"\n        self._dictOptions = dictOptions\n\n        return self",
  "def _set_dict_options(self):\n        \"\"\"\n        Set EGADS options via dictionaries.\n        \"\"\"\n        dictOptions = self._dictOptions\n\n        if self.root_proc:\n            for ind, option in enumerate(dictOptions[\"egadsTessAIM\"]):\n                self.aim.input[option].value = dictOptions[\"egadsTessAIM\"][option]\n\n        return self",
  "def is_setup(self) -> bool:\n        return self._is_setup",
  "def aim(self):\n        return self._aim",
  "def register_to(self, tacs_aim):\n        \"\"\"\n        cascade method to register the egads aim to the tacs aim wrapper class\n        \"\"\"\n        tacs_aim.register(self)\n        return self",
  "class AflrAim:\n    def __init__(self, caps_problem, comm, root=0):\n        \"\"\"\n        MPI wrapper class for AflrAIM from ESP/CAPS.\n        \"\"\"\n\n        self.caps_problem = caps_problem\n        self.comm = comm\n        self.root = root\n\n        # holds aflr4 aim\n        self._aim = None\n\n        self._dictOptions = None\n\n        self._build_aim()\n        return\n\n    @property\n    def root_proc(self) -> bool:\n        return self.comm.rank == self.root\n\n    @property\n    def aim(self):\n        \"\"\"surface mesher aim aka aflr4 aim\"\"\"\n        return self._aim\n\n    @property\n    def analysis_dir(self):\n        _analysis_dir = None\n        if self.comm.rank == self.root:\n            _analysis_dir = self.aim.analysisDir\n        _analysis_dir = self.comm.bcast(_analysis_dir, root=self.root)\n        return _analysis_dir\n\n    def _build_aim(self):\n        if self.root_proc:\n            self._aim = self.caps_problem.analysis.create(aim=\"aflr4AIM\", name=\"aflr4\")\n        return\n\n    def set_mesh(self, min_scale=0.05, max_scale=0.5, AFLR4_Quad=False, no_prox=True):\n        \"\"\"\n        Set mesh properties for AFLR4 AIM. A few options are available in this routine.\n        To set other options for AFLR4, use the save_dict_options routine.\n\n        Parameters\n        ----------\n        min_scale: Relative scale of minimum spacing to reference length.\n            The relative scale of minimum spacing to reference length (ref_len) controls\n            the minimum spacing that can be set on any component/body surface.\n        max_scale: Relative scale of maximum spacing to reference length.\n            The relative scale of maximum spacing to reference length (ref_len) controls\n            the maximum spacing that can be set on any component/body surface.\n        AFLR4_Quad: Generate a mixed quad/tria-face grid.\n        no_prox: Disable proximity checking.\n            Proximity checking is automatically disabled if there is only one component/body defined.\n        \"\"\"\n\n        if self.root_proc:\n            self.aim.input.min_scale = min_scale\n            self.aim.input.max_scale = max_scale\n            self.aim.input.AFLR4_Quad = AFLR4_Quad\n            self._aim.input.no_prox = no_prox\n        return self\n\n    def save_dict_options(self, dictOptions: dict = None):\n        \"\"\"\n        Optional method to set AFLR4 mesh settings using dictionaries.\n        Call this before setting up the TACS model. The dictionary should take\n        the form of, e.g.:\n\n        dictOptions['aflr4AIM']['myOption'] = myValue\n        \"\"\"\n        self._dictOptions = dictOptions\n\n        return self\n\n    def _set_dict_options(self):\n        \"\"\"\n        Set AFLR4 options via dictionaries.\n        \"\"\"\n        dictOptions = self._dictOptions\n\n        if self.root_proc:\n            for ind, option in enumerate(dictOptions[\"aflr4AIM\"]):\n                self.aim.input[option].value = dictOptions[\"aflr4AIM\"][option]\n\n        return self\n\n    def register_to(self, tacs_aim):\n        \"\"\"\n        cascade method to register the egads aim to the tacs aim wrapper class\n        \"\"\"\n        tacs_aim.register(self)\n        return self",
  "def __init__(self, caps_problem, comm, root=0):\n        \"\"\"\n        MPI wrapper class for AflrAIM from ESP/CAPS.\n        \"\"\"\n\n        self.caps_problem = caps_problem\n        self.comm = comm\n        self.root = root\n\n        # holds aflr4 aim\n        self._aim = None\n\n        self._dictOptions = None\n\n        self._build_aim()\n        return",
  "def root_proc(self) -> bool:\n        return self.comm.rank == self.root",
  "def aim(self):\n        \"\"\"surface mesher aim aka aflr4 aim\"\"\"\n        return self._aim",
  "def analysis_dir(self):\n        _analysis_dir = None\n        if self.comm.rank == self.root:\n            _analysis_dir = self.aim.analysisDir\n        _analysis_dir = self.comm.bcast(_analysis_dir, root=self.root)\n        return _analysis_dir",
  "def _build_aim(self):\n        if self.root_proc:\n            self._aim = self.caps_problem.analysis.create(aim=\"aflr4AIM\", name=\"aflr4\")\n        return",
  "def set_mesh(self, min_scale=0.05, max_scale=0.5, AFLR4_Quad=False, no_prox=True):\n        \"\"\"\n        Set mesh properties for AFLR4 AIM. A few options are available in this routine.\n        To set other options for AFLR4, use the save_dict_options routine.\n\n        Parameters\n        ----------\n        min_scale: Relative scale of minimum spacing to reference length.\n            The relative scale of minimum spacing to reference length (ref_len) controls\n            the minimum spacing that can be set on any component/body surface.\n        max_scale: Relative scale of maximum spacing to reference length.\n            The relative scale of maximum spacing to reference length (ref_len) controls\n            the maximum spacing that can be set on any component/body surface.\n        AFLR4_Quad: Generate a mixed quad/tria-face grid.\n        no_prox: Disable proximity checking.\n            Proximity checking is automatically disabled if there is only one component/body defined.\n        \"\"\"\n\n        if self.root_proc:\n            self.aim.input.min_scale = min_scale\n            self.aim.input.max_scale = max_scale\n            self.aim.input.AFLR4_Quad = AFLR4_Quad\n            self._aim.input.no_prox = no_prox\n        return self",
  "def save_dict_options(self, dictOptions: dict = None):\n        \"\"\"\n        Optional method to set AFLR4 mesh settings using dictionaries.\n        Call this before setting up the TACS model. The dictionary should take\n        the form of, e.g.:\n\n        dictOptions['aflr4AIM']['myOption'] = myValue\n        \"\"\"\n        self._dictOptions = dictOptions\n\n        return self",
  "def _set_dict_options(self):\n        \"\"\"\n        Set AFLR4 options via dictionaries.\n        \"\"\"\n        dictOptions = self._dictOptions\n\n        if self.root_proc:\n            for ind, option in enumerate(dictOptions[\"aflr4AIM\"]):\n                self.aim.input[option].value = dictOptions[\"aflr4AIM\"][option]\n\n        return self",
  "def register_to(self, tacs_aim):\n        \"\"\"\n        cascade method to register the egads aim to the tacs aim wrapper class\n        \"\"\"\n        tacs_aim.register(self)\n        return self",
  "class TacsAimMetadata:\n    def __init__(self, analysis_dir, project_name):\n        self.analysis_dir = analysis_dir\n        self.project_name = project_name",
  "class TacsAim:\n    \"\"\"\n    Wrapper class for TacsAim with default build setting in different scenarios\n    applies default settings and spits it back out at the end\n    only supports shell properties at the moment\n    \"\"\"\n\n    def __init__(self, caps_problem, comm=None):\n        self.comm = comm\n\n        # geometry and design parameters to change the design of the CSM file during an optimization\n        self._aim = None\n        self._geometry = None\n        self._build_aim(caps_problem)\n\n        self._analysis_functions = []\n        self._materials = []\n        self._loads = []\n        self._properties = []\n        self._constraints = []\n        self._design_variables = []\n        self._mesh_aim = None\n\n        self._dict_options = None\n\n        # build flags\n        self._setup = False\n        self._first_setup = True\n\n        # broadcast TacsAimMetadata from root proc to other processors\n        self._metadata = None\n        self._broadcast_metadata()\n\n    @root_proc\n    def _build_aim(self, caps_problem):\n        \"\"\"\n        build the TacsAim pyCAPS object inside our wrapper class on root proc\n        \"\"\"\n        self._aim = caps_problem.analysis.create(aim=\"tacsAIM\", name=\"tacs\")\n        self._geometry = caps_problem.geometry\n\n    def _broadcast_metadata(self):\n        \"\"\"\n        broadcast any tacs aim metadata needed for this class from root proc to other processors\n        \"\"\"\n        if self.comm is None:\n            self._metadata = TacsAimMetadata(\n                analysis_dir=self._aim.analysisDir,\n                project_name=self._aim.input.Proj_Name,\n            )\n        else:\n            if self.comm.rank == 0:\n                self._metadata = TacsAimMetadata(\n                    analysis_dir=self._aim.analysisDir,\n                    project_name=self._aim.input.Proj_Name,\n                )\n            self._metadata = self.comm.bcast(self._metadata, root=0)\n\n    def register(self, obj):\n        \"\"\"\n        register any one of the available objects: Materials, Properties, Variables, etc.\n        \"\"\"\n        if isinstance(obj, Material):\n            self._materials.append(obj)\n        elif isinstance(obj, ThicknessVariable):\n            self._design_variables.append(obj)\n            if obj.can_make_shell:\n                self._properties.append(obj.shell_property)\n        elif isinstance(obj, ShapeVariable):\n            self._design_variables.append(obj)\n        elif isinstance(obj, Property):\n            self._properties.append(obj)\n        elif isinstance(obj, Constraint):\n            self._constraints.append(obj)\n        elif isinstance(obj, Load):\n            self._loads.append(obj)\n        elif isinstance(obj, EgadsAim):\n            self._mesh_aim = obj\n        elif isinstance(obj, AflrAim):\n            self._mesh_aim = obj\n        else:\n            raise AssertionError(\n                \"Object could not be registered to TacsAim as it is not an appropriate type.\"\n            )\n\n    def setup_aim(\n        self,\n        large_format: bool = True,\n        static: bool = True,\n        auto_shape_variables: bool = False,\n    ):\n        # make sure there is at least one material, property, constraint, etc.\n        assert len(self._materials) > 0\n        assert len(self._properties) > 0\n        assert len(self._constraints) > 0\n        assert self._mesh_aim is not None\n\n        # this part runs on serial\n        if self.comm is None or self.comm.rank == 0:\n            # write in the original shape variable values into the pyCAPS geometry\n            for shape_var in self.shape_variables:\n                if shape_var.value is not None:\n                    self.geometry.despmtr[shape_var.name].value = shape_var.value\n\n            # increase the precision in the BDF file\n            self.aim.input.File_Format = \"Large\" if large_format else \"Small\"\n            self.aim.input.Mesh_File_Format = \"Large\" if large_format else \"Small\"\n\n            # set the analysis type\n            if static:\n                self.aim.input.Analysis_Type = \"Static\"\n            else:\n                raise AssertionError(\n                    \"Analysis types other than static analyses for tacsAim are not supported yet.\"\n                )\n\n            # add materials to tacsAim\n            self.aim.input.Material = {\n                material.name: material.dictionary for material in self._materials\n            }\n\n            # add properties to tacsAim\n            self.aim.input.Property = {\n                prop.caps_group: prop.dictionary for prop in self._properties\n            }\n\n            # add constraints to tacsAim\n            self.aim.input.Constraint = {\n                con.name: con.dictionary for con in self._constraints\n            }\n\n            # add loads to tacsAim\n            if len(self._loads) > 0:\n                self.aim.input.Load = {\n                    load.name: load.dictionary for load in self._loads\n                }\n\n            if auto_shape_variables and self._first_setup:\n                for despmtr in self._metadata.design_parameters:\n                    # TODO : setup for dv arrays too but not yet\n                    new_value = self._geometry.despmtr[despmtr].value\n                    if isinstance(\n                        new_value, float\n                    ):  # make sure not a list despmtr, not supported yet\n                        shape_var = ShapeVariable(name=despmtr, value=new_value)\n                        self.add_variable(variable=shape_var)\n                self._first_setup = False\n\n            # link the egads aim to the tacs aim\n            self.aim.input[\"Mesh\"].link(self._mesh_aim.aim.output[\"Surface_Mesh\"])\n\n            # add the design variables to the DesignVariable and DesignVariableRelation properties\n            if len(self.thickness_variables) > 0:\n                self.aim.input.Design_Variable_Relation = {\n                    dv.name: dv.DVR_dictionary\n                    for dv in self._design_variables\n                    if isinstance(dv, ThicknessVariable)\n                }\n            if len(self.variables) > 0:\n                self.aim.input.Design_Variable = {\n                    dv.name: dv.DV_dictionary for dv in self._design_variables\n                }\n\n            if self._dict_options is not None:\n                self._set_dict_options()\n\n        # end of serial or root proc section\n\n        # note that setup is finished now\n        self._setup = True\n        return self  # return object for method cascading\n\n    @root_proc\n    def set_config_parameter(self, param_name: str, value: float):\n        self.geometry.cfgpmtr[param_name].value = value\n        return\n\n    @root_broadcast\n    def get_config_parameter(self, param_name: str):\n        return self.geometry.cfgpmtr[param_name].value\n\n    @root_broadcast\n    def get_output_parameter(self, out_name: str):\n        return self.geometry.outpmtr[out_name].value\n\n    @property\n    def geometry(self):\n        \"\"\"\n        caps problem geometry object pyCAPS.problem.geometry\n        \"\"\"\n        return self._geometry\n\n    @property\n    def variables(self) -> List[ShapeVariable or ThicknessVariable]:\n        return self._design_variables\n\n    @property\n    def shape_variables(self) -> List[ShapeVariable]:\n        return [dv for dv in self.variables if isinstance(dv, ShapeVariable)]\n\n    @property\n    def thickness_variables(self) -> List[ThicknessVariable]:\n        \"\"\"\n        return sorted thickness vars so that the TACS derivatives can be appropriately obtained\n        \"\"\"\n        thick_var_names = [\n            dv.name for dv in self.variables if isinstance(dv, ThicknessVariable)\n        ]\n        thick_sorted_names = np.sort(np.array(thick_var_names))\n        sorted_dvs = []\n        for sort_name in thick_sorted_names:\n            for var in self.variables:\n                if isinstance(var, ThicknessVariable) and var.name == sort_name:\n                    sorted_dvs.append(var)\n                    break\n        return sorted_dvs\n\n    @property\n    def analysis_dir(self) -> str:\n        return self._metadata.analysis_dir\n\n    @property\n    def dat_file(self) -> str:\n        return self.project_name + \".dat\"\n\n    @property\n    def dat_file_path(self) -> str:\n        return os.path.join(self.analysis_dir, self.dat_file)\n\n    @property\n    def sens_file(self) -> str:\n        return self.project_name + \".sens\"\n\n    @property\n    def sens_file_path(self) -> str:\n        return os.path.join(self.analysis_dir, self.sens_file)\n\n    @property\n    def project_name(self) -> str:\n        return self._metadata.project_name\n\n    @property\n    def is_setup(self) -> bool:\n        return self._setup\n\n    @property\n    def aim(self):\n        \"\"\"\n        returns the auto-built tacsAim object\n        \"\"\"\n        return self._aim\n\n    @property\n    def change_shape(self) -> bool:\n        \"\"\"\n        whether the aim will change shape (only if shape variables provided)\n        \"\"\"\n        return len(self.shape_variables) > 0\n\n    def update_properties(self):\n        \"\"\"\n        update thickness properties and design variables in ESP/CAPS inputs\n        if shape change w/ thickness variables\n        \"\"\"\n        # exit if no thickness variables\n        if len(self.thickness_variables) == 0:\n            return\n\n        # update property thicknesses by the modified thickness variables\n        for property in self._properties:\n            for dv in self._design_variables:\n                if isinstance(property, ShellProperty) and isinstance(\n                    dv, ThicknessVariable\n                ):\n                    if property.caps_group == dv.caps_group:\n                        property.membrane_thickness == dv.value\n                        break\n\n        if self.comm is None or self.comm.rank == 0:\n            # input new design var and property cards\n            self.aim.input.Design_Variable = {\n                dv.name: dv.DV_dictionary for dv in self._design_variables\n            }\n            self.aim.input.Property = {\n                prop.caps_group: prop.dictionary for prop in self._properties\n            }\n\n        return\n\n    def save_dict_options(self, aimOptions: dict = None):\n        \"\"\"\n        Optional method to set tacsAIM settings using dictionaries. Settings specified\n        through dictionaries take precedence over other methods. The dictionary should\n        take the form of, e.g.:\n\n        aimOptions['tacsAIM']['myOption'] = myValue\n        \"\"\"\n\n        self._dict_options = aimOptions\n\n        return self\n\n    @root_proc\n    def _set_dict_options(self):\n        \"\"\"\n        Set any options that were specified through dictionaries.\n        \"\"\"\n        aimOptions = self._dict_options\n\n        for ind, option in enumerate(aimOptions[\"tacsAim\"]):\n            self.aim.input[option].value = aimOptions[\"tacsAim\"][option]\n\n        return self\n\n    @root_proc\n    def pre_analysis(self):\n        \"\"\"\n        provide access to the tacs aim preAnalysis for generating TACS input files and mesh\n        \"\"\"\n        assert self._setup\n        self.aim.preAnalysis()\n\n        # return this object for method cascading\n        return self\n\n    @root_proc\n    def post_analysis(self):\n        \"\"\"\n        provide access to the tacs aim postAnalysis for collecting analysis outputs - functions and derivatives\n        \"\"\"\n        self.aim.postAnalysis()\n        return self",
  "def __init__(self, analysis_dir, project_name):\n        self.analysis_dir = analysis_dir\n        self.project_name = project_name",
  "def __init__(self, caps_problem, comm=None):\n        self.comm = comm\n\n        # geometry and design parameters to change the design of the CSM file during an optimization\n        self._aim = None\n        self._geometry = None\n        self._build_aim(caps_problem)\n\n        self._analysis_functions = []\n        self._materials = []\n        self._loads = []\n        self._properties = []\n        self._constraints = []\n        self._design_variables = []\n        self._mesh_aim = None\n\n        self._dict_options = None\n\n        # build flags\n        self._setup = False\n        self._first_setup = True\n\n        # broadcast TacsAimMetadata from root proc to other processors\n        self._metadata = None\n        self._broadcast_metadata()",
  "def _build_aim(self, caps_problem):\n        \"\"\"\n        build the TacsAim pyCAPS object inside our wrapper class on root proc\n        \"\"\"\n        self._aim = caps_problem.analysis.create(aim=\"tacsAIM\", name=\"tacs\")\n        self._geometry = caps_problem.geometry",
  "def _broadcast_metadata(self):\n        \"\"\"\n        broadcast any tacs aim metadata needed for this class from root proc to other processors\n        \"\"\"\n        if self.comm is None:\n            self._metadata = TacsAimMetadata(\n                analysis_dir=self._aim.analysisDir,\n                project_name=self._aim.input.Proj_Name,\n            )\n        else:\n            if self.comm.rank == 0:\n                self._metadata = TacsAimMetadata(\n                    analysis_dir=self._aim.analysisDir,\n                    project_name=self._aim.input.Proj_Name,\n                )\n            self._metadata = self.comm.bcast(self._metadata, root=0)",
  "def register(self, obj):\n        \"\"\"\n        register any one of the available objects: Materials, Properties, Variables, etc.\n        \"\"\"\n        if isinstance(obj, Material):\n            self._materials.append(obj)\n        elif isinstance(obj, ThicknessVariable):\n            self._design_variables.append(obj)\n            if obj.can_make_shell:\n                self._properties.append(obj.shell_property)\n        elif isinstance(obj, ShapeVariable):\n            self._design_variables.append(obj)\n        elif isinstance(obj, Property):\n            self._properties.append(obj)\n        elif isinstance(obj, Constraint):\n            self._constraints.append(obj)\n        elif isinstance(obj, Load):\n            self._loads.append(obj)\n        elif isinstance(obj, EgadsAim):\n            self._mesh_aim = obj\n        elif isinstance(obj, AflrAim):\n            self._mesh_aim = obj\n        else:\n            raise AssertionError(\n                \"Object could not be registered to TacsAim as it is not an appropriate type.\"\n            )",
  "def setup_aim(\n        self,\n        large_format: bool = True,\n        static: bool = True,\n        auto_shape_variables: bool = False,\n    ):\n        # make sure there is at least one material, property, constraint, etc.\n        assert len(self._materials) > 0\n        assert len(self._properties) > 0\n        assert len(self._constraints) > 0\n        assert self._mesh_aim is not None\n\n        # this part runs on serial\n        if self.comm is None or self.comm.rank == 0:\n            # write in the original shape variable values into the pyCAPS geometry\n            for shape_var in self.shape_variables:\n                if shape_var.value is not None:\n                    self.geometry.despmtr[shape_var.name].value = shape_var.value\n\n            # increase the precision in the BDF file\n            self.aim.input.File_Format = \"Large\" if large_format else \"Small\"\n            self.aim.input.Mesh_File_Format = \"Large\" if large_format else \"Small\"\n\n            # set the analysis type\n            if static:\n                self.aim.input.Analysis_Type = \"Static\"\n            else:\n                raise AssertionError(\n                    \"Analysis types other than static analyses for tacsAim are not supported yet.\"\n                )\n\n            # add materials to tacsAim\n            self.aim.input.Material = {\n                material.name: material.dictionary for material in self._materials\n            }\n\n            # add properties to tacsAim\n            self.aim.input.Property = {\n                prop.caps_group: prop.dictionary for prop in self._properties\n            }\n\n            # add constraints to tacsAim\n            self.aim.input.Constraint = {\n                con.name: con.dictionary for con in self._constraints\n            }\n\n            # add loads to tacsAim\n            if len(self._loads) > 0:\n                self.aim.input.Load = {\n                    load.name: load.dictionary for load in self._loads\n                }\n\n            if auto_shape_variables and self._first_setup:\n                for despmtr in self._metadata.design_parameters:\n                    # TODO : setup for dv arrays too but not yet\n                    new_value = self._geometry.despmtr[despmtr].value\n                    if isinstance(\n                        new_value, float\n                    ):  # make sure not a list despmtr, not supported yet\n                        shape_var = ShapeVariable(name=despmtr, value=new_value)\n                        self.add_variable(variable=shape_var)\n                self._first_setup = False\n\n            # link the egads aim to the tacs aim\n            self.aim.input[\"Mesh\"].link(self._mesh_aim.aim.output[\"Surface_Mesh\"])\n\n            # add the design variables to the DesignVariable and DesignVariableRelation properties\n            if len(self.thickness_variables) > 0:\n                self.aim.input.Design_Variable_Relation = {\n                    dv.name: dv.DVR_dictionary\n                    for dv in self._design_variables\n                    if isinstance(dv, ThicknessVariable)\n                }\n            if len(self.variables) > 0:\n                self.aim.input.Design_Variable = {\n                    dv.name: dv.DV_dictionary for dv in self._design_variables\n                }\n\n            if self._dict_options is not None:\n                self._set_dict_options()\n\n        # end of serial or root proc section\n\n        # note that setup is finished now\n        self._setup = True\n        return self",
  "def set_config_parameter(self, param_name: str, value: float):\n        self.geometry.cfgpmtr[param_name].value = value\n        return",
  "def get_config_parameter(self, param_name: str):\n        return self.geometry.cfgpmtr[param_name].value",
  "def get_output_parameter(self, out_name: str):\n        return self.geometry.outpmtr[out_name].value",
  "def geometry(self):\n        \"\"\"\n        caps problem geometry object pyCAPS.problem.geometry\n        \"\"\"\n        return self._geometry",
  "def variables(self) -> List[ShapeVariable or ThicknessVariable]:\n        return self._design_variables",
  "def shape_variables(self) -> List[ShapeVariable]:\n        return [dv for dv in self.variables if isinstance(dv, ShapeVariable)]",
  "def thickness_variables(self) -> List[ThicknessVariable]:\n        \"\"\"\n        return sorted thickness vars so that the TACS derivatives can be appropriately obtained\n        \"\"\"\n        thick_var_names = [\n            dv.name for dv in self.variables if isinstance(dv, ThicknessVariable)\n        ]\n        thick_sorted_names = np.sort(np.array(thick_var_names))\n        sorted_dvs = []\n        for sort_name in thick_sorted_names:\n            for var in self.variables:\n                if isinstance(var, ThicknessVariable) and var.name == sort_name:\n                    sorted_dvs.append(var)\n                    break\n        return sorted_dvs",
  "def analysis_dir(self) -> str:\n        return self._metadata.analysis_dir",
  "def dat_file(self) -> str:\n        return self.project_name + \".dat\"",
  "def dat_file_path(self) -> str:\n        return os.path.join(self.analysis_dir, self.dat_file)",
  "def sens_file(self) -> str:\n        return self.project_name + \".sens\"",
  "def sens_file_path(self) -> str:\n        return os.path.join(self.analysis_dir, self.sens_file)",
  "def project_name(self) -> str:\n        return self._metadata.project_name",
  "def is_setup(self) -> bool:\n        return self._setup",
  "def aim(self):\n        \"\"\"\n        returns the auto-built tacsAim object\n        \"\"\"\n        return self._aim",
  "def change_shape(self) -> bool:\n        \"\"\"\n        whether the aim will change shape (only if shape variables provided)\n        \"\"\"\n        return len(self.shape_variables) > 0",
  "def update_properties(self):\n        \"\"\"\n        update thickness properties and design variables in ESP/CAPS inputs\n        if shape change w/ thickness variables\n        \"\"\"\n        # exit if no thickness variables\n        if len(self.thickness_variables) == 0:\n            return\n\n        # update property thicknesses by the modified thickness variables\n        for property in self._properties:\n            for dv in self._design_variables:\n                if isinstance(property, ShellProperty) and isinstance(\n                    dv, ThicknessVariable\n                ):\n                    if property.caps_group == dv.caps_group:\n                        property.membrane_thickness == dv.value\n                        break\n\n        if self.comm is None or self.comm.rank == 0:\n            # input new design var and property cards\n            self.aim.input.Design_Variable = {\n                dv.name: dv.DV_dictionary for dv in self._design_variables\n            }\n            self.aim.input.Property = {\n                prop.caps_group: prop.dictionary for prop in self._properties\n            }\n\n        return",
  "def save_dict_options(self, aimOptions: dict = None):\n        \"\"\"\n        Optional method to set tacsAIM settings using dictionaries. Settings specified\n        through dictionaries take precedence over other methods. The dictionary should\n        take the form of, e.g.:\n\n        aimOptions['tacsAIM']['myOption'] = myValue\n        \"\"\"\n\n        self._dict_options = aimOptions\n\n        return self",
  "def _set_dict_options(self):\n        \"\"\"\n        Set any options that were specified through dictionaries.\n        \"\"\"\n        aimOptions = self._dict_options\n\n        for ind, option in enumerate(aimOptions[\"tacsAim\"]):\n            self.aim.input[option].value = aimOptions[\"tacsAim\"][option]\n\n        return self",
  "def pre_analysis(self):\n        \"\"\"\n        provide access to the tacs aim preAnalysis for generating TACS input files and mesh\n        \"\"\"\n        assert self._setup\n        self.aim.preAnalysis()\n\n        # return this object for method cascading\n        return self",
  "def post_analysis(self):\n        \"\"\"\n        provide access to the tacs aim postAnalysis for collecting analysis outputs - functions and derivatives\n        \"\"\"\n        self.aim.postAnalysis()\n        return self",
  "class TacsStaticComponent(om.ExplicitComponent):\n    \"\"\"\n    OpenMDAO component for sizing and/or shape optimization of TACS static analysis problems\n    TODO : future work could equivalent unsteady / modal analysis component\n    \"\"\"\n\n    def initialize(self):\n        \"\"\"\n        Declare the capsProblem to the openMdao component\n        Makes the __init__ construct : TacsStaticComponent(tacs_model, write_f5, track_history)\n        \"\"\"\n        self.options.declare(\n            \"tacs_model\", types=object\n        )  # takes in the TacsAim wrapper class\n\n        # whether to write f5 files of each iteration\n        self.options.declare(\"write_f5\", types=bool, default=True)\n\n        # whether to write history files and plot history\n        self.options.declare(\"track_history\", types=bool, default=True)\n\n        self._iteration = 0  # track iteration number\n\n    def setup(self):\n        tacs_model = self.options[\"tacs_model\"]\n        track_history = self.options[\"track_history\"]\n\n        # make sure we have more than zero tacs aim variables\n        assert len(tacs_model.variables) > 0\n\n        # add the thickness variables as openmdao inputs, with starting uniform thickness\n        for thick_var in tacs_model.thickness_variables:\n            self.add_input(thick_var.name, val=thick_var.value)\n\n        # add the shape variables as openmdao inputs\n        for shape_var in tacs_model.shape_variables:\n            self.add_input(shape_var.name, val=shape_var.value)\n\n        # add output analysis functions\n        assert (\n            len(tacs_model.analysis_functions) > 0\n        )  # makes sure we have some analysis functions before running an analysis)\n        for func in tacs_model.analysis_functions:\n            self.add_output(func.name)\n\n        if track_history:\n            # function histories\n            self._func_history = {\n                func_name: [] for func_name in tacs_model.function_names\n            }\n\n            # design history file\n            if tacs_model.root_proc:\n                self._design_hdl = open(\n                    os.path.join(tacs_model.analysis_dir, \"design_hist.txt\"), \"w\"\n                )\n\n    def setup_partials(self):\n        tacs_model = self.options[\"tacs_model\"]\n\n        for func in tacs_model.analysis_functions:\n            for var in tacs_model.variables:\n                self.declare_partials(func.name, var.name)\n\n    def compute(self, inputs, outputs):\n        \"\"\"\n        compute the objective functions\n        \"\"\"\n        # obtain the aim from openmdao storage\n        tacs_model = self.options[\"tacs_model\"]\n        track_history = self.options[\"track_history\"]\n        write_f5 = self.options[\"write_f5\"]\n\n        # update the design\n        new_design = tacs_model.update_design(inputs)\n\n        if new_design:\n            if track_history:\n                self._print_design(inputs)\n\n            # run a forward + adjoint analysis and apply any shape changes if necessary\n            tacs_model.pre_analysis()\n            tacs_model.run_analysis(write_f5=write_f5, iteration=self._iteration)\n            tacs_model.post_analysis()\n\n            self._iteration += 1\n\n            # update func history and report to design file\n            if track_history:\n                self._update_history()\n                self._function_report()\n\n        # Grab the function values and attach as openmdao outputs\n        for func in tacs_model.analysis_functions:\n            outputs[func.name] = func.value\n\n        return\n\n    def compute_partials(self, inputs, partials):\n        \"\"\"\n        the actual value of partial derivatives assigned here\n        \"\"\"\n        # obtain the aim from openmdao storage\n        tacs_model = self.options[\"tacs_model\"]\n        track_history = self.options[\"track_history\"]\n        write_f5 = self.options[\"write_f5\"]\n\n        # update the design\n        new_design = tacs_model.update_design(inputs)\n\n        if new_design:\n            if track_history:\n                self._print_design(inputs)\n\n            # run a forward + adjoint analysis and apply any shape changes if necessary\n            tacs_model.pre_analysis()\n            tacs_model.run_analysis(write_f5=write_f5, iteration=self._iteration)\n            tacs_model.post_analysis()\n\n            self._iteration += 1\n\n            # update func history and report to design file\n            if track_history:\n                self._update_history()\n                self._function_report()\n\n        # Grab the function values and attach as openmdao outputs\n        for func in tacs_model.analysis_functions:\n            for var in tacs_model.variables:\n                partials[func.name, var.name] = func.get_derivative(var)\n\n        return\n\n    # helper methods for writing history, plotting history, etc.\n    def _update_history(self):\n        tacs_model = self.options[\"tacs_model\"]\n        for func in tacs_model.analysis_functions:\n            self._func_history[func.name].append(func.value)\n\n        if tacs_model.root_proc:\n            self._plot_history(\n                directory=tacs_model.analysis_dir, filename=\"opt_history.png\"\n            )\n\n    def _function_report(self):\n        tacs_model = self.options[\"tacs_model\"]\n\n        if tacs_model.root_proc:\n            self._design_hdl.write(\"Analysis result:\\n\")\n            for func_name in tacs_model.function_names:\n                self._design_hdl.write(\n                    f\"\\tfunc {func_name} = {self._func_history[func_name][-1]}\\n\"\n                )\n            self._design_hdl.write(\"\\n\")\n            self._design_hdl.flush()\n\n    def _plot_history(self, directory, filename):\n        tacs_model = self.options[\"tacs_model\"]\n\n        if tacs_model.root_proc:\n            num_iterations = len(self._func_history[tacs_model.function_names[0]])\n            iterations = [_ for _ in range(num_iterations)]\n            plt.figure()\n            for func_name in tacs_model.function_names:\n                yvec = self._func_history[func_name]\n                yvec /= max(np.array(yvec))\n                plt.plot(iterations, yvec, linewidth=2, label=func_name)\n            plt.legend()\n            plt.xlabel(\"iterations\")\n            plt.ylabel(\"func values\")\n            plt.yscale(\"log\")\n            plot_filepath = os.path.join(directory, filename)\n            plt.savefig(plot_filepath)\n            plt.close(\"all\")\n\n    def _print_design(self, inputs):\n        tacs_model = self.options[\"tacs_model\"]\n\n        if tacs_model.root_proc:\n            self._design_hdl.write(\"New Design...\\n\")\n            self._design_hdl.write(\n                f\"\\tthick dvs = {[_.name for _ in tacs_model.variables]}\\n\"\n            )\n            real_xarray = [float(inputs[key]) for key in inputs]\n            self._design_hdl.write(f\"\\tvalues = {real_xarray}\\n\")\n            self._design_hdl.flush()",
  "def initialize(self):\n        \"\"\"\n        Declare the capsProblem to the openMdao component\n        Makes the __init__ construct : TacsStaticComponent(tacs_model, write_f5, track_history)\n        \"\"\"\n        self.options.declare(\n            \"tacs_model\", types=object\n        )  # takes in the TacsAim wrapper class\n\n        # whether to write f5 files of each iteration\n        self.options.declare(\"write_f5\", types=bool, default=True)\n\n        # whether to write history files and plot history\n        self.options.declare(\"track_history\", types=bool, default=True)\n\n        self._iteration = 0",
  "def setup(self):\n        tacs_model = self.options[\"tacs_model\"]\n        track_history = self.options[\"track_history\"]\n\n        # make sure we have more than zero tacs aim variables\n        assert len(tacs_model.variables) > 0\n\n        # add the thickness variables as openmdao inputs, with starting uniform thickness\n        for thick_var in tacs_model.thickness_variables:\n            self.add_input(thick_var.name, val=thick_var.value)\n\n        # add the shape variables as openmdao inputs\n        for shape_var in tacs_model.shape_variables:\n            self.add_input(shape_var.name, val=shape_var.value)\n\n        # add output analysis functions\n        assert (\n            len(tacs_model.analysis_functions) > 0\n        )  # makes sure we have some analysis functions before running an analysis)\n        for func in tacs_model.analysis_functions:\n            self.add_output(func.name)\n\n        if track_history:\n            # function histories\n            self._func_history = {\n                func_name: [] for func_name in tacs_model.function_names\n            }\n\n            # design history file\n            if tacs_model.root_proc:\n                self._design_hdl = open(\n                    os.path.join(tacs_model.analysis_dir, \"design_hist.txt\"), \"w\"\n                )",
  "def setup_partials(self):\n        tacs_model = self.options[\"tacs_model\"]\n\n        for func in tacs_model.analysis_functions:\n            for var in tacs_model.variables:\n                self.declare_partials(func.name, var.name)",
  "def compute(self, inputs, outputs):\n        \"\"\"\n        compute the objective functions\n        \"\"\"\n        # obtain the aim from openmdao storage\n        tacs_model = self.options[\"tacs_model\"]\n        track_history = self.options[\"track_history\"]\n        write_f5 = self.options[\"write_f5\"]\n\n        # update the design\n        new_design = tacs_model.update_design(inputs)\n\n        if new_design:\n            if track_history:\n                self._print_design(inputs)\n\n            # run a forward + adjoint analysis and apply any shape changes if necessary\n            tacs_model.pre_analysis()\n            tacs_model.run_analysis(write_f5=write_f5, iteration=self._iteration)\n            tacs_model.post_analysis()\n\n            self._iteration += 1\n\n            # update func history and report to design file\n            if track_history:\n                self._update_history()\n                self._function_report()\n\n        # Grab the function values and attach as openmdao outputs\n        for func in tacs_model.analysis_functions:\n            outputs[func.name] = func.value\n\n        return",
  "def compute_partials(self, inputs, partials):\n        \"\"\"\n        the actual value of partial derivatives assigned here\n        \"\"\"\n        # obtain the aim from openmdao storage\n        tacs_model = self.options[\"tacs_model\"]\n        track_history = self.options[\"track_history\"]\n        write_f5 = self.options[\"write_f5\"]\n\n        # update the design\n        new_design = tacs_model.update_design(inputs)\n\n        if new_design:\n            if track_history:\n                self._print_design(inputs)\n\n            # run a forward + adjoint analysis and apply any shape changes if necessary\n            tacs_model.pre_analysis()\n            tacs_model.run_analysis(write_f5=write_f5, iteration=self._iteration)\n            tacs_model.post_analysis()\n\n            self._iteration += 1\n\n            # update func history and report to design file\n            if track_history:\n                self._update_history()\n                self._function_report()\n\n        # Grab the function values and attach as openmdao outputs\n        for func in tacs_model.analysis_functions:\n            for var in tacs_model.variables:\n                partials[func.name, var.name] = func.get_derivative(var)\n\n        return",
  "def _update_history(self):\n        tacs_model = self.options[\"tacs_model\"]\n        for func in tacs_model.analysis_functions:\n            self._func_history[func.name].append(func.value)\n\n        if tacs_model.root_proc:\n            self._plot_history(\n                directory=tacs_model.analysis_dir, filename=\"opt_history.png\"\n            )",
  "def _function_report(self):\n        tacs_model = self.options[\"tacs_model\"]\n\n        if tacs_model.root_proc:\n            self._design_hdl.write(\"Analysis result:\\n\")\n            for func_name in tacs_model.function_names:\n                self._design_hdl.write(\n                    f\"\\tfunc {func_name} = {self._func_history[func_name][-1]}\\n\"\n                )\n            self._design_hdl.write(\"\\n\")\n            self._design_hdl.flush()",
  "def _plot_history(self, directory, filename):\n        tacs_model = self.options[\"tacs_model\"]\n\n        if tacs_model.root_proc:\n            num_iterations = len(self._func_history[tacs_model.function_names[0]])\n            iterations = [_ for _ in range(num_iterations)]\n            plt.figure()\n            for func_name in tacs_model.function_names:\n                yvec = self._func_history[func_name]\n                yvec /= max(np.array(yvec))\n                plt.plot(iterations, yvec, linewidth=2, label=func_name)\n            plt.legend()\n            plt.xlabel(\"iterations\")\n            plt.ylabel(\"func values\")\n            plt.yscale(\"log\")\n            plot_filepath = os.path.join(directory, filename)\n            plt.savefig(plot_filepath)\n            plt.close(\"all\")",
  "def _print_design(self, inputs):\n        tacs_model = self.options[\"tacs_model\"]\n\n        if tacs_model.root_proc:\n            self._design_hdl.write(\"New Design...\\n\")\n            self._design_hdl.write(\n                f\"\\tthick dvs = {[_.name for _ in tacs_model.variables]}\\n\"\n            )\n            real_xarray = [float(inputs[key]) for key in inputs]\n            self._design_hdl.write(f\"\\tvalues = {real_xarray}\\n\")\n            self._design_hdl.flush()",
  "class TacsModel:\n    MESH_AIMS = [\"egads\", \"aflr\"]\n\n    def __init__(self, tacs_aim: TacsAim, mesh_aim, comm=None):\n        self._tacs_aim = tacs_aim\n        self._mesh_aim = mesh_aim\n        self.comm = comm\n\n        self._analysis_functions = []\n        self.SPs = None\n        self._setup = False\n        self._first_analysis = True\n\n    @property\n    def tacs_aim(self) -> TacsAim:\n        return self._tacs_aim\n\n    @property\n    def mesh_aim(self) -> AflrAim:\n        return self._mesh_aim\n\n    @property\n    def uses_egads(self):\n        return isinstance(self.mesh_aim, EgadsAim)\n\n    @property\n    def uses_aflr(self):\n        return isinstance(self.mesh_aim, AflrAim)\n\n    @classmethod\n    def build(cls, csm_file, comm=None, mesh=\"egads\", problem_name: str = \"capsStruct\", verbosity=1):\n        \"\"\"\n        make a pyCAPS problem with the tacsAIM and egadsAIM on serial / root proc\n\n        Parameters\n        ---------------------------------\n        csm_file : filepath\n            filename / full path of ESP/CAPS Constructive Solid Model or .CSM file\n        comm : MPI.COMM\n            MPI communicator\n        \"\"\"\n\n        caps_problem = None\n        assert mesh in cls.MESH_AIMS\n        if comm is None or comm.rank == 0:\n            caps_problem = pyCAPS.Problem(\n                problemName=problem_name, capsFile=csm_file, outLevel=verbosity\n            )\n        tacs_aim = TacsAim(caps_problem, comm)\n        mesh_aim = None\n        if mesh == \"egads\":\n            mesh_aim = EgadsAim(caps_problem, comm)\n        elif mesh == \"aflr\":\n            mesh_aim = AflrAim(caps_problem, comm)\n        return cls(tacs_aim, mesh_aim, comm)\n\n    def get_config_parameter(self, param_name: str):\n        return self.tacs_aim.get_config_parameter(param_name=param_name)\n\n    def register(self, obj):\n        \"\"\"\n        register each of the objects to the tacs model\n        can also register any object for the tacs aim to the tacs model which passes it on\n        \"\"\"\n\n        if isinstance(obj, AnalysisFunction):\n            self._analysis_functions.append(obj)\n\n        tacs_aim_objects = [\n            Material,\n            ThicknessVariable,\n            ShapeVariable,\n            ShellProperty,\n            Constraint,\n            Load,\n            EgadsAim,\n            AflrAim,\n        ]\n        for tacs_aim_obj in tacs_aim_objects:\n            if isinstance(obj, tacs_aim_obj):\n                self.tacs_aim.register(obj)\n                return\n\n        return\n\n    def setup(self, include_aim: bool = True):\n        \"\"\"\n        setup the analysis functions to store derivatives\n\n        Parameters\n        --------------------------------------------\n        auto_tacs_aim : bool\n            automatically setup the tacs aim too\n        \"\"\"\n        # add each variable as a derivative object for each analysis function\n        for func in self.analysis_functions:\n            for var in self.variables:\n                func._derivatives.append(Derivative(name=var.name, value=0.0))\n\n        if include_aim:\n            self.tacs_aim.setup_aim()\n\n            # Set additional options for meshing AIM through dictionaries\n            if self.mesh_aim._dictOptions is not None:\n                self.mesh_aim._set_dict_options()\n\n            # go ahead and generate the first input files and mesh for TACS\n            if not self.tacs_aim.change_shape:\n                self.tacs_aim.pre_analysis()\n\n        self._setup = True\n\n        return self\n\n    @property\n    def analysis_functions(self) -> List[AnalysisFunction]:\n        \"\"\"\n        return the list of analysis function objects registered to the tacs aim wrapper class\n        to add more functions use Function.(...).register_to(tacs_aim) or tacs_aim.register(my_analysis_function)\n        \"\"\"\n        return self._analysis_functions\n\n    @property\n    def function_names(self) -> List[str]:\n        \"\"\"\n        list of names of each analysis function\n        \"\"\"\n        return [func.name for func in self.analysis_functions]\n\n    @property\n    def analysis_dir(self) -> str:\n        return self.tacs_aim.analysis_dir\n\n    @property\n    def geometry(self):\n        \"\"\"\n        link to pyCAPS geometry object to enable shape change in tacsAIM\n        \"\"\"\n        return self.tacs_aim.geometry\n\n    @property\n    def variables(self) -> List[ShapeVariable or ThicknessVariable]:\n        return self.tacs_aim.variables\n\n    @property\n    def variable_dict(self) -> dict:\n        return {var.name: var.value for var in self.variables}\n\n    @property\n    def shape_variables(self) -> List[ShapeVariable]:\n        return self.tacs_aim.shape_variables\n\n    @property\n    def thickness_variables(self) -> List[ThicknessVariable]:\n        return self.tacs_aim.thickness_variables\n\n    @property\n    def root_proc(self) -> bool:\n        return self.comm is None or self.comm.rank == 0\n\n    def update_design(self, input_dict: dict = None):\n        \"\"\"\n        method to change the values of each design variable in tacsAim wrapper and ESP/CAPS\n        \"\"\"\n\n        input_dict = input_dict if input_dict is not None else self.variable_dict\n\n        # track any design change to monitor capsDirty\n        changed_design = False\n\n        # change all shape variables in TacsAim and update CAD geometry\n        for shape_var in self.shape_variables:\n            if shape_var.name in input_dict:\n                if input_dict[shape_var.name] is not None:\n                    shape_var.value = float(input_dict[shape_var.name])\n\n                # update the CAD geometry on root proc / serial since ESP/CAPS doesn't handle MPI directly\n                if self.root_proc:\n                    if self.geometry.despmtr[shape_var.name].value != shape_var.value:\n                        changed_design = True\n                        if shape_var.value is not None:\n                            self.geometry.despmtr[\n                                shape_var.name\n                            ].value = shape_var.value\n                        else:\n                            shape_var.value = self.geometry.despmtr[\n                                shape_var.name\n                            ].value\n\n        # change all thickness variables in TacsAim\n        for thick_var in self.thickness_variables:\n            if thick_var.name in input_dict:\n                if thick_var.value != float(input_dict[thick_var.name]):\n                    thick_var.value = float(input_dict[thick_var.name])\n                    changed_design = True\n\n        # update thickness prop cards in t\n        if self.tacs_aim.change_shape:\n            self.tacs_aim.update_properties()\n\n        # record whether the design has changed & first analysis flag as well\n        if self._first_analysis:\n            self._first_analysis = False\n            changed_design = True\n\n        return changed_design\n\n    @property\n    def fea_solver(self) -> pyTACS:\n        \"\"\"\n        build pyTACS from nastran dat file and comm\n        \"\"\"\n        return pyTACS(self.tacs_aim.dat_file_path, self.comm)\n\n    def createTACSProbs(self, addFunctions: bool = True):\n        \"\"\"\n        creates TACS list of static, transient, or modal analysis TACS problems from the TacsAim class\n        most important call method from the tacsAim class: SPs = tacs_aim.createTACSProbs\n        \"\"\"\n        fea_solver = self.fea_solver\n        fea_solver.initialize()\n        SPs = fea_solver.createTACSProbsFromBDF()\n        self.SPs = SPs  # store the static problems as well\n\n        # add the analysis functions of the model into the static problems\n        # add each analysis function into the static problems\n        if addFunctions:\n            for caseID in self.SPs:\n                for analysis_function in self.analysis_functions:\n                    self.SPs[caseID].addFunction(\n                        funcName=analysis_function.name,\n                        funcHandle=analysis_function.handle,\n                        compIDs=analysis_function.compIDs,\n                        **(analysis_function.kwargs),\n                    )\n        return self.SPs\n\n    def pre_analysis(self):\n        \"\"\"\n        call tacs aim pre_analysis to build TACS input files and mesh\n        only regenerate the mesh each time if there are shape variables\n        \"\"\"\n        if self.tacs_aim.change_shape:\n            self.tacs_aim.pre_analysis()\n\n    def run_analysis(self, write_f5: bool = True, iteration: float = 0):\n        \"\"\"\n        run the static problem analysis\n        \"\"\"\n\n        assert self._setup\n\n        # create a new set of static problems for w/ or w/o shape change\n        self.SPs = self.createTACSProbs(addFunctions=True)\n\n        # solve the forward and adjoint analysis for each struct problem\n        self._tacs_funcs = {}\n        self._tacs_sens = {}\n        for caseID in self.SPs:\n            # write in the new thickness variables for sizing only case\n            if not self.tacs_aim.change_shape:\n                xarray = self.SPs[caseID].x.getArray()\n                for ithick, thick_var in enumerate(self.thickness_variables):\n                    xarray[ithick] = float(thick_var.value)\n\n            self.SPs[caseID].solve()\n\n            if (\n                self.tacs_aim.change_shape\n            ):  # if the shape changes write a sensitivity file to the tacsAim directory\n                self.SPs[caseID].writeSensFile(\n                    evalFuncs=self.function_names,\n                    tacsAim=self.tacs_aim,\n                )\n            else:  # only call evalFunctions and evalFunctionSens if not shape change else redundant\n                self.SPs[caseID].evalFunctions(\n                    self._tacs_funcs, evalFuncs=self.function_names\n                )\n                self.SPs[caseID].evalFunctionsSens(\n                    self._tacs_sens, evalFuncs=self.function_names\n                )\n\n            if write_f5:\n                self.SPs[caseID].writeSolution(\n                    baseName=\"tacs_output\",\n                    outputDir=self.tacs_aim.analysis_dir,\n                    number=iteration,\n                )\n\n        # return this object for method cascading\n        return self\n\n    def post_analysis(self):\n        \"\"\"\n        call tacs aim wrapper postAnalysis and update analysis functions and gradients\n        \"\"\"\n\n        if self.tacs_aim.change_shape:\n            # call serial tacsAim postAnalysis if shape changes\n            functions_dict = None\n            gradients_dict = None\n\n            if self.root_proc:\n                self.tacs_aim.post_analysis()\n                functions_dict = {}\n                gradients_dict = {}\n                # update functions and gradients on root proc from tacsAim dynout of ESP/CAPS serial\n                for func in self.analysis_functions:\n                    functions_dict[func.name] = self.tacs_aim.aim.dynout[\n                        func.name\n                    ].value\n                    gradients_dict[func.name] = {}\n                    for var in self.variables:\n                        gradients_dict[func.name][var.name] = self.tacs_aim.aim.dynout[\n                            func.name\n                        ].deriv(var.name)\n\n            # broadcast functions and gradients dict to all other processors from root proc\n            if self.comm is not None:\n                functions_dict = self.comm.bcast(functions_dict, root=0)\n                gradients_dict = self.comm.bcast(gradients_dict, root=0)\n\n            # update functions and gradients into the tacsAim analysis_functions\n            for func in self.analysis_functions:\n                func.value = functions_dict[func.name]\n                for var in self.variables:\n                    func.set_derivative(var, gradients_dict[func.name][var.name])\n\n        # otherwise use struct problems to read in function values and gradients\n        else:  # just thickness variable case\n            for func in self.analysis_functions:\n                # corresponding tacs key for single loadset (key=\"loadset#\" + \"func_name\")\n                for tacs_key in self._tacs_funcs:\n                    if func.name in tacs_key:\n                        break\n\n                # add the function and gradients to each analysis function\n                func.value = self._tacs_funcs[tacs_key].real\n\n                struct_derivs = self._tacs_sens[tacs_key][\"struct\"]\n                for ithick, thick_var in enumerate(self.thickness_variables):\n                    func.set_derivative(thick_var, struct_derivs[ithick].real)\n\n        return self",
  "def __init__(self, tacs_aim: TacsAim, mesh_aim, comm=None):\n        self._tacs_aim = tacs_aim\n        self._mesh_aim = mesh_aim\n        self.comm = comm\n\n        self._analysis_functions = []\n        self.SPs = None\n        self._setup = False\n        self._first_analysis = True",
  "def tacs_aim(self) -> TacsAim:\n        return self._tacs_aim",
  "def mesh_aim(self) -> AflrAim:\n        return self._mesh_aim",
  "def uses_egads(self):\n        return isinstance(self.mesh_aim, EgadsAim)",
  "def uses_aflr(self):\n        return isinstance(self.mesh_aim, AflrAim)",
  "def build(cls, csm_file, comm=None, mesh=\"egads\", problem_name: str = \"capsStruct\", verbosity=1):\n        \"\"\"\n        make a pyCAPS problem with the tacsAIM and egadsAIM on serial / root proc\n\n        Parameters\n        ---------------------------------\n        csm_file : filepath\n            filename / full path of ESP/CAPS Constructive Solid Model or .CSM file\n        comm : MPI.COMM\n            MPI communicator\n        \"\"\"\n\n        caps_problem = None\n        assert mesh in cls.MESH_AIMS\n        if comm is None or comm.rank == 0:\n            caps_problem = pyCAPS.Problem(\n                problemName=problem_name, capsFile=csm_file, outLevel=verbosity\n            )\n        tacs_aim = TacsAim(caps_problem, comm)\n        mesh_aim = None\n        if mesh == \"egads\":\n            mesh_aim = EgadsAim(caps_problem, comm)\n        elif mesh == \"aflr\":\n            mesh_aim = AflrAim(caps_problem, comm)\n        return cls(tacs_aim, mesh_aim, comm)",
  "def get_config_parameter(self, param_name: str):\n        return self.tacs_aim.get_config_parameter(param_name=param_name)",
  "def register(self, obj):\n        \"\"\"\n        register each of the objects to the tacs model\n        can also register any object for the tacs aim to the tacs model which passes it on\n        \"\"\"\n\n        if isinstance(obj, AnalysisFunction):\n            self._analysis_functions.append(obj)\n\n        tacs_aim_objects = [\n            Material,\n            ThicknessVariable,\n            ShapeVariable,\n            ShellProperty,\n            Constraint,\n            Load,\n            EgadsAim,\n            AflrAim,\n        ]\n        for tacs_aim_obj in tacs_aim_objects:\n            if isinstance(obj, tacs_aim_obj):\n                self.tacs_aim.register(obj)\n                return\n\n        return",
  "def setup(self, include_aim: bool = True):\n        \"\"\"\n        setup the analysis functions to store derivatives\n\n        Parameters\n        --------------------------------------------\n        auto_tacs_aim : bool\n            automatically setup the tacs aim too\n        \"\"\"\n        # add each variable as a derivative object for each analysis function\n        for func in self.analysis_functions:\n            for var in self.variables:\n                func._derivatives.append(Derivative(name=var.name, value=0.0))\n\n        if include_aim:\n            self.tacs_aim.setup_aim()\n\n            # Set additional options for meshing AIM through dictionaries\n            if self.mesh_aim._dictOptions is not None:\n                self.mesh_aim._set_dict_options()\n\n            # go ahead and generate the first input files and mesh for TACS\n            if not self.tacs_aim.change_shape:\n                self.tacs_aim.pre_analysis()\n\n        self._setup = True\n\n        return self",
  "def analysis_functions(self) -> List[AnalysisFunction]:\n        \"\"\"\n        return the list of analysis function objects registered to the tacs aim wrapper class\n        to add more functions use Function.(...).register_to(tacs_aim) or tacs_aim.register(my_analysis_function)\n        \"\"\"\n        return self._analysis_functions",
  "def function_names(self) -> List[str]:\n        \"\"\"\n        list of names of each analysis function\n        \"\"\"\n        return [func.name for func in self.analysis_functions]",
  "def analysis_dir(self) -> str:\n        return self.tacs_aim.analysis_dir",
  "def geometry(self):\n        \"\"\"\n        link to pyCAPS geometry object to enable shape change in tacsAIM\n        \"\"\"\n        return self.tacs_aim.geometry",
  "def variables(self) -> List[ShapeVariable or ThicknessVariable]:\n        return self.tacs_aim.variables",
  "def variable_dict(self) -> dict:\n        return {var.name: var.value for var in self.variables}",
  "def shape_variables(self) -> List[ShapeVariable]:\n        return self.tacs_aim.shape_variables",
  "def thickness_variables(self) -> List[ThicknessVariable]:\n        return self.tacs_aim.thickness_variables",
  "def root_proc(self) -> bool:\n        return self.comm is None or self.comm.rank == 0",
  "def update_design(self, input_dict: dict = None):\n        \"\"\"\n        method to change the values of each design variable in tacsAim wrapper and ESP/CAPS\n        \"\"\"\n\n        input_dict = input_dict if input_dict is not None else self.variable_dict\n\n        # track any design change to monitor capsDirty\n        changed_design = False\n\n        # change all shape variables in TacsAim and update CAD geometry\n        for shape_var in self.shape_variables:\n            if shape_var.name in input_dict:\n                if input_dict[shape_var.name] is not None:\n                    shape_var.value = float(input_dict[shape_var.name])\n\n                # update the CAD geometry on root proc / serial since ESP/CAPS doesn't handle MPI directly\n                if self.root_proc:\n                    if self.geometry.despmtr[shape_var.name].value != shape_var.value:\n                        changed_design = True\n                        if shape_var.value is not None:\n                            self.geometry.despmtr[\n                                shape_var.name\n                            ].value = shape_var.value\n                        else:\n                            shape_var.value = self.geometry.despmtr[\n                                shape_var.name\n                            ].value\n\n        # change all thickness variables in TacsAim\n        for thick_var in self.thickness_variables:\n            if thick_var.name in input_dict:\n                if thick_var.value != float(input_dict[thick_var.name]):\n                    thick_var.value = float(input_dict[thick_var.name])\n                    changed_design = True\n\n        # update thickness prop cards in t\n        if self.tacs_aim.change_shape:\n            self.tacs_aim.update_properties()\n\n        # record whether the design has changed & first analysis flag as well\n        if self._first_analysis:\n            self._first_analysis = False\n            changed_design = True\n\n        return changed_design",
  "def fea_solver(self) -> pyTACS:\n        \"\"\"\n        build pyTACS from nastran dat file and comm\n        \"\"\"\n        return pyTACS(self.tacs_aim.dat_file_path, self.comm)",
  "def createTACSProbs(self, addFunctions: bool = True):\n        \"\"\"\n        creates TACS list of static, transient, or modal analysis TACS problems from the TacsAim class\n        most important call method from the tacsAim class: SPs = tacs_aim.createTACSProbs\n        \"\"\"\n        fea_solver = self.fea_solver\n        fea_solver.initialize()\n        SPs = fea_solver.createTACSProbsFromBDF()\n        self.SPs = SPs  # store the static problems as well\n\n        # add the analysis functions of the model into the static problems\n        # add each analysis function into the static problems\n        if addFunctions:\n            for caseID in self.SPs:\n                for analysis_function in self.analysis_functions:\n                    self.SPs[caseID].addFunction(\n                        funcName=analysis_function.name,\n                        funcHandle=analysis_function.handle,\n                        compIDs=analysis_function.compIDs,\n                        **(analysis_function.kwargs),\n                    )\n        return self.SPs",
  "def pre_analysis(self):\n        \"\"\"\n        call tacs aim pre_analysis to build TACS input files and mesh\n        only regenerate the mesh each time if there are shape variables\n        \"\"\"\n        if self.tacs_aim.change_shape:\n            self.tacs_aim.pre_analysis()",
  "def run_analysis(self, write_f5: bool = True, iteration: float = 0):\n        \"\"\"\n        run the static problem analysis\n        \"\"\"\n\n        assert self._setup\n\n        # create a new set of static problems for w/ or w/o shape change\n        self.SPs = self.createTACSProbs(addFunctions=True)\n\n        # solve the forward and adjoint analysis for each struct problem\n        self._tacs_funcs = {}\n        self._tacs_sens = {}\n        for caseID in self.SPs:\n            # write in the new thickness variables for sizing only case\n            if not self.tacs_aim.change_shape:\n                xarray = self.SPs[caseID].x.getArray()\n                for ithick, thick_var in enumerate(self.thickness_variables):\n                    xarray[ithick] = float(thick_var.value)\n\n            self.SPs[caseID].solve()\n\n            if (\n                self.tacs_aim.change_shape\n            ):  # if the shape changes write a sensitivity file to the tacsAim directory\n                self.SPs[caseID].writeSensFile(\n                    evalFuncs=self.function_names,\n                    tacsAim=self.tacs_aim,\n                )\n            else:  # only call evalFunctions and evalFunctionSens if not shape change else redundant\n                self.SPs[caseID].evalFunctions(\n                    self._tacs_funcs, evalFuncs=self.function_names\n                )\n                self.SPs[caseID].evalFunctionsSens(\n                    self._tacs_sens, evalFuncs=self.function_names\n                )\n\n            if write_f5:\n                self.SPs[caseID].writeSolution(\n                    baseName=\"tacs_output\",\n                    outputDir=self.tacs_aim.analysis_dir,\n                    number=iteration,\n                )\n\n        # return this object for method cascading\n        return self",
  "def post_analysis(self):\n        \"\"\"\n        call tacs aim wrapper postAnalysis and update analysis functions and gradients\n        \"\"\"\n\n        if self.tacs_aim.change_shape:\n            # call serial tacsAim postAnalysis if shape changes\n            functions_dict = None\n            gradients_dict = None\n\n            if self.root_proc:\n                self.tacs_aim.post_analysis()\n                functions_dict = {}\n                gradients_dict = {}\n                # update functions and gradients on root proc from tacsAim dynout of ESP/CAPS serial\n                for func in self.analysis_functions:\n                    functions_dict[func.name] = self.tacs_aim.aim.dynout[\n                        func.name\n                    ].value\n                    gradients_dict[func.name] = {}\n                    for var in self.variables:\n                        gradients_dict[func.name][var.name] = self.tacs_aim.aim.dynout[\n                            func.name\n                        ].deriv(var.name)\n\n            # broadcast functions and gradients dict to all other processors from root proc\n            if self.comm is not None:\n                functions_dict = self.comm.bcast(functions_dict, root=0)\n                gradients_dict = self.comm.bcast(gradients_dict, root=0)\n\n            # update functions and gradients into the tacsAim analysis_functions\n            for func in self.analysis_functions:\n                func.value = functions_dict[func.name]\n                for var in self.variables:\n                    func.set_derivative(var, gradients_dict[func.name][var.name])\n\n        # otherwise use struct problems to read in function values and gradients\n        else:  # just thickness variable case\n            for func in self.analysis_functions:\n                # corresponding tacs key for single loadset (key=\"loadset#\" + \"func_name\")\n                for tacs_key in self._tacs_funcs:\n                    if func.name in tacs_key:\n                        break\n\n                # add the function and gradients to each analysis function\n                func.value = self._tacs_funcs[tacs_key].real\n\n                struct_derivs = self._tacs_sens[tacs_key][\"struct\"]\n                for ithick, thick_var in enumerate(self.thickness_variables):\n                    func.set_derivative(thick_var, struct_derivs[ithick].real)\n\n        return self",
  "class Material:\n    def __init__(\n        self,\n        name: str,\n        material_type: str,\n        young_modulus: float,\n        poisson_ratio: float,\n        density: float,\n        tension_allow: float,\n        compression_allow: float = None,\n        shear_allow: float = None,\n        yield_allow: float = None,\n        thermExpCoeff: float = None,\n    ):\n        \"\"\"\n        Material base class to wrap ESP/CAPS material inputs to TACS AIM\n        \"\"\"\n        assert material_type in [\n            \"Isotropic\",\n            \"Anisothotropic\",\n            \"Orthotropic\",\n            \"Anisotropic\",\n        ]\n        self._name = name\n        self._material_type = material_type\n        self._young_modulus = young_modulus\n        self._poisson_ratio = poisson_ratio\n        self._density = density\n        self._tension_allow = tension_allow\n        self._compression_allow = compression_allow\n        self._shear_allow = shear_allow\n        self._yield_allow = yield_allow\n        self._thermExpCoeff = thermExpCoeff\n\n    @property\n    def name(self) -> str:\n        return self._name\n\n    @name.setter\n    def name(self, new_name: str):\n        self._name = new_name\n\n    @property\n    def dictionary(self) -> dict:\n        \"\"\"\n        return dictionary of material settings\n        \"\"\"\n        m_dict = {}\n        m_dict[\"materialType\"] = self._material_type\n        m_dict[\"youngModulus\"] = self._young_modulus\n        m_dict[\"poissonRatio\"] = self._poisson_ratio\n        m_dict[\"density\"] = self._density\n        m_dict[\"thermalExpCoeff\"] = self._thermExpCoeff\n        m_dict[\"tensionAllow\"] = self._tension_allow\n        m_dict[\"compressionAllow\"] = self._compression_allow\n        m_dict[\"shearAllow\"] = self._shear_allow\n        m_dict[\"yieldAllow\"] = self._yield_allow\n\n        # return all items that are not None\n        return {k: v for k, v in m_dict.items() if v is not None}\n\n    @property\n    def young_modulus(self) -> float:\n        return self._young_modulus\n\n    @young_modulus.setter\n    def young_modulus(self, value: float):\n        self._young_modulus = value\n\n    def register_to(self, tacs_aim):\n        \"\"\"\n        cascaded method to register this constraint to TacsAim\n        \"\"\"\n        tacs_aim.register(self)\n        return self",
  "class Isotropic(Material):\n    def __init__(\n        self,\n        name: str,\n        young_modulus: float,\n        poisson_ratio: float,\n        density: float,\n        tension_allow: float,\n        compression_allow: float = None,\n        shear_allow: float = None,\n        yield_allow: float = None,\n        thermExpCoeff: float = None,\n    ):\n        \"\"\"\n        wrapper class for ESP/CAPS isotropic materials\n        \"\"\"\n        super(Isotropic, self).__init__(\n            name=name,\n            material_type=\"Isotropic\",\n            young_modulus=young_modulus,\n            poisson_ratio=poisson_ratio,\n            density=density,\n            tension_allow=tension_allow,\n            compression_allow=compression_allow,\n            shear_allow=shear_allow,\n            yield_allow=yield_allow,\n            thermExpCoeff=thermExpCoeff,\n        )\n\n    @classmethod\n    def madeupium(\n        cls,\n        young_modulus=72.0e9,\n        poisson_ratio=0.33,\n        density=2.8e3,\n        tension_allow=20.0e7,\n    ):\n        return cls(\n            name=\"Madeupium\",\n            young_modulus=young_modulus,\n            poisson_ratio=poisson_ratio,\n            density=density,\n            tension_allow=tension_allow,\n        )\n\n    @classmethod\n    def aluminum(cls):\n        return cls(\n            name=\"aluminum\",\n            young_modulus=70.0e9,\n            poisson_ratio=0.35,\n            density=2.7e3,\n            tension_allow=20.0e7,\n            compression_allow=20.0e7,\n            yield_allow=20.0e7,\n            thermExpCoeff=23.1e-6,\n        )\n\n    @classmethod\n    def steel(cls):\n        return cls(\n            name=\"steel\",\n            young_modulus=200.0e9,\n            poisson_ratio=0.30,\n            density=7.8e3,\n            tension_allow=1.0e9,\n            compression_allow=1.7e9,\n            yield_allow=0.9e9,\n            thermExpCoeff=11.5e-6,\n        )",
  "class Orthotropic(Material):\n    # TBD\n    pass",
  "def __init__(\n        self,\n        name: str,\n        material_type: str,\n        young_modulus: float,\n        poisson_ratio: float,\n        density: float,\n        tension_allow: float,\n        compression_allow: float = None,\n        shear_allow: float = None,\n        yield_allow: float = None,\n        thermExpCoeff: float = None,\n    ):\n        \"\"\"\n        Material base class to wrap ESP/CAPS material inputs to TACS AIM\n        \"\"\"\n        assert material_type in [\n            \"Isotropic\",\n            \"Anisothotropic\",\n            \"Orthotropic\",\n            \"Anisotropic\",\n        ]\n        self._name = name\n        self._material_type = material_type\n        self._young_modulus = young_modulus\n        self._poisson_ratio = poisson_ratio\n        self._density = density\n        self._tension_allow = tension_allow\n        self._compression_allow = compression_allow\n        self._shear_allow = shear_allow\n        self._yield_allow = yield_allow\n        self._thermExpCoeff = thermExpCoeff",
  "def name(self) -> str:\n        return self._name",
  "def name(self, new_name: str):\n        self._name = new_name",
  "def dictionary(self) -> dict:\n        \"\"\"\n        return dictionary of material settings\n        \"\"\"\n        m_dict = {}\n        m_dict[\"materialType\"] = self._material_type\n        m_dict[\"youngModulus\"] = self._young_modulus\n        m_dict[\"poissonRatio\"] = self._poisson_ratio\n        m_dict[\"density\"] = self._density\n        m_dict[\"thermalExpCoeff\"] = self._thermExpCoeff\n        m_dict[\"tensionAllow\"] = self._tension_allow\n        m_dict[\"compressionAllow\"] = self._compression_allow\n        m_dict[\"shearAllow\"] = self._shear_allow\n        m_dict[\"yieldAllow\"] = self._yield_allow\n\n        # return all items that are not None\n        return {k: v for k, v in m_dict.items() if v is not None}",
  "def young_modulus(self) -> float:\n        return self._young_modulus",
  "def young_modulus(self, value: float):\n        self._young_modulus = value",
  "def register_to(self, tacs_aim):\n        \"\"\"\n        cascaded method to register this constraint to TacsAim\n        \"\"\"\n        tacs_aim.register(self)\n        return self",
  "def __init__(\n        self,\n        name: str,\n        young_modulus: float,\n        poisson_ratio: float,\n        density: float,\n        tension_allow: float,\n        compression_allow: float = None,\n        shear_allow: float = None,\n        yield_allow: float = None,\n        thermExpCoeff: float = None,\n    ):\n        \"\"\"\n        wrapper class for ESP/CAPS isotropic materials\n        \"\"\"\n        super(Isotropic, self).__init__(\n            name=name,\n            material_type=\"Isotropic\",\n            young_modulus=young_modulus,\n            poisson_ratio=poisson_ratio,\n            density=density,\n            tension_allow=tension_allow,\n            compression_allow=compression_allow,\n            shear_allow=shear_allow,\n            yield_allow=yield_allow,\n            thermExpCoeff=thermExpCoeff,\n        )",
  "def madeupium(\n        cls,\n        young_modulus=72.0e9,\n        poisson_ratio=0.33,\n        density=2.8e3,\n        tension_allow=20.0e7,\n    ):\n        return cls(\n            name=\"Madeupium\",\n            young_modulus=young_modulus,\n            poisson_ratio=poisson_ratio,\n            density=density,\n            tension_allow=tension_allow,\n        )",
  "def aluminum(cls):\n        return cls(\n            name=\"aluminum\",\n            young_modulus=70.0e9,\n            poisson_ratio=0.35,\n            density=2.7e3,\n            tension_allow=20.0e7,\n            compression_allow=20.0e7,\n            yield_allow=20.0e7,\n            thermExpCoeff=23.1e-6,\n        )",
  "def steel(cls):\n        return cls(\n            name=\"steel\",\n            young_modulus=200.0e9,\n            poisson_ratio=0.30,\n            density=7.8e3,\n            tension_allow=1.0e9,\n            compression_allow=1.7e9,\n            yield_allow=0.9e9,\n            thermExpCoeff=11.5e-6,\n        )",
  "class Property:\n    def __init__(self, caps_group: str, material: Material, property_type: str):\n        self._caps_group = caps_group\n        self._material = material\n        self._property_type = property_type\n\n    @property\n    def caps_group(self) -> str:\n        \"\"\"\n        return capsGroup attribute associated with this property\n        \"\"\"\n        return self._caps_group\n\n    @property\n    def dictionary(self) -> dict:\n        \"\"\"\n        return property dictionary, however this is only fully defined in subclasses\n        \"\"\"\n        return {}\n\n    def register_to(self, tacs_aim):\n        \"\"\"\n        cascaded method to register this property to TacsAim\n        \"\"\"\n        tacs_aim.register(self)\n        return self",
  "class ShellProperty(Property):\n    \"\"\"\n    Example ShellProperty Dictionary\n    shell  = {\"propertyType\" : \"Shell\",\n                    \"membraneThickness\" : 0.006,\n                    \"material\"        : \"madeupium\",\n                    \"bendingInertiaRatio\" : 1.0, # Default\n                    \"shearMembraneRatio\"  : 5.0/6.0} # Default\n    self._aim.input.Property = {\"plate\": shell}\n    \"\"\"\n\n    # TODO : add other available settings for shell properties -> mass, inertias, etc.\n    def __init__(\n        self,\n        caps_group: str,\n        material: Material,\n        membrane_thickness: float,\n        bending_inertia: float = 20.0,\n        shear_membrane_ratio: float = 5.0 / 6.0,\n    ):\n        super(ShellProperty, self).__init__(\n            caps_group=caps_group, material=material, property_type=\"Shell\"\n        )\n        self._membrane_thickness = membrane_thickness\n        self._bending_inertia = bending_inertia\n        self._shear_membrane_ratio = shear_membrane_ratio\n\n        # bending inertia supposed to be 1.0 but boosted to 20.0 here\n\n    @property\n    def membrane_thickness(self) -> float:\n        return self._membrane_thickness\n\n    @membrane_thickness.setter\n    def membrane_thickness(self, new_thickness: float):\n        self._membrane_thickness = new_thickness\n\n    @property\n    def dictionary(self) -> dict:\n        \"\"\"\n        return property dictionary to pass into tacsAim\n        \"\"\"\n        return {\n            \"propertyType\": self._property_type,\n            \"membraneThickness\": self._membrane_thickness,\n            \"material\": self._material.name,\n            \"bendingInertiaRatio\": self._bending_inertia,  # Default\n            \"shearMembraneRatio\": self._shear_membrane_ratio,\n        }  # Default-\n\n    def register_to(self, tacs_aim):\n        \"\"\"\n        cascaded method to register this ShellProperty to TacsAim\n        \"\"\"\n        tacs_aim.register(self)\n        return self",
  "def __init__(self, caps_group: str, material: Material, property_type: str):\n        self._caps_group = caps_group\n        self._material = material\n        self._property_type = property_type",
  "def caps_group(self) -> str:\n        \"\"\"\n        return capsGroup attribute associated with this property\n        \"\"\"\n        return self._caps_group",
  "def dictionary(self) -> dict:\n        \"\"\"\n        return property dictionary, however this is only fully defined in subclasses\n        \"\"\"\n        return {}",
  "def register_to(self, tacs_aim):\n        \"\"\"\n        cascaded method to register this property to TacsAim\n        \"\"\"\n        tacs_aim.register(self)\n        return self",
  "def __init__(\n        self,\n        caps_group: str,\n        material: Material,\n        membrane_thickness: float,\n        bending_inertia: float = 20.0,\n        shear_membrane_ratio: float = 5.0 / 6.0,\n    ):\n        super(ShellProperty, self).__init__(\n            caps_group=caps_group, material=material, property_type=\"Shell\"\n        )\n        self._membrane_thickness = membrane_thickness\n        self._bending_inertia = bending_inertia\n        self._shear_membrane_ratio = shear_membrane_ratio",
  "def membrane_thickness(self) -> float:\n        return self._membrane_thickness",
  "def membrane_thickness(self, new_thickness: float):\n        self._membrane_thickness = new_thickness",
  "def dictionary(self) -> dict:\n        \"\"\"\n        return property dictionary to pass into tacsAim\n        \"\"\"\n        return {\n            \"propertyType\": self._property_type,\n            \"membraneThickness\": self._membrane_thickness,\n            \"material\": self._material.name,\n            \"bendingInertiaRatio\": self._bending_inertia,  # Default\n            \"shearMembraneRatio\": self._shear_membrane_ratio,\n        }",
  "def register_to(self, tacs_aim):\n        \"\"\"\n        cascaded method to register this ShellProperty to TacsAim\n        \"\"\"\n        tacs_aim.register(self)\n        return self",
  "class Derivative:\n    def __init__(self, name: str, value: float = None):\n        \"\"\"\n        used to track derivatives for d(function)/d(var) of each analysis function and variable in the tacs aim\n        \"\"\"\n        self.name = name\n        self.value = value",
  "class AnalysisFunction:\n    def __init__(self, name: str, handle, compIDs=None, scale: float = 1.0, **kwargs):\n        \"\"\"\n        Analysis functions/functionals for structural optimization\n            Every function is added to new structural analysis problems in each iteration if the design changes\n                with the TacsAim shape variables for instance.\n            Calls addFunction in each new staticProblem for now\n\n        Parameters\n        -----------------------------------------------------\n        name : str\n            the name of the function i.e. mass, ks_vmfailure, etc.\n        handle : TACS.function\n            the function handle of the cython TACS function, comes from tacs.functions module\n        compIDs : list\n            list of component IDs to select\n        scale : float\n            the scale used for optimization\n        **kwargs:\n            any keyword arguments to pass to the\n        \"\"\"\n\n        self.name = name\n        self.handle = handle\n        self.compIDs = compIDs\n        self.scale = scale\n        self.kwargs = kwargs\n\n        self.value = None\n        self._derivatives = []\n\n    def register_to(self, tacs_aim):\n        # register the analysis function to the TacsAim wrapper class\n        tacs_aim.register(self)\n        return\n\n    def set_derivative(self, var, value: float):\n        for deriv in self.derivatives:\n            if deriv.name == var.name:\n                deriv.value = value\n                return\n\n    def get_derivative(self, var):\n        value = None\n        for deriv in self.derivatives:\n            if deriv.name == var.name:\n                value = deriv.value\n\n        return value\n\n    @property\n    def derivatives(self) -> List[Derivative]:\n        return self._derivatives\n\n    @property\n    def gradient_dict(self) -> dict:\n        return {deriv.name: deriv.value for deriv in self.derivatives}\n\n    # class methods to add certain functions\n    @classmethod\n    def mass(cls, compIDs=None, scale: float = 1.0):\n        return cls(name=\"mass\", handle=StructuralMass, compIDs=compIDs, scale=scale)\n\n    @classmethod\n    def ksfailure(\n        cls,\n        compIDs=None,\n        safetyFactor: float = 1.0,\n        ksWeight: float = 50.0,\n        scale: float = 1.0,\n    ):\n        return cls(\n            name=\"ksfailure\",\n            handle=KSFailure,\n            compIDs=compIDs,\n            scale=scale,\n            safetyFactor=safetyFactor,\n            ksWeight=ksWeight,\n        )\n\n    @classmethod\n    def ks_temperature(\n        cls,\n        compIDs=None,\n        alpha: float = 1.0,\n        ksWeight: float = 50.0,\n        scale: float = 1.0,\n    ):\n        return cls(\n            name=\"ks_temperature\",\n            handle=KSTemperature,\n            compIDs=compIDs,\n            scale=scale,\n            alpha=alpha,\n            ksWeight=ksWeight,\n        )\n\n    @classmethod\n    def avg_temperature(cls, compIDs=None, volume: float = 1.0, scale: float = 1.0):\n        return cls(\n            name=\"avg_temperature\",\n            handle=AverageTemperature,\n            compIDs=compIDs,\n            scale=scale,\n            volume=volume,\n        )\n\n    @classmethod\n    def compliance(cls, compIDs=None, scale: float = 1.0):\n        return cls(name=\"compliance\", handle=Compliance, compIDs=compIDs, scale=scale)",
  "def __init__(self, name: str, value: float = None):\n        \"\"\"\n        used to track derivatives for d(function)/d(var) of each analysis function and variable in the tacs aim\n        \"\"\"\n        self.name = name\n        self.value = value",
  "def __init__(self, name: str, handle, compIDs=None, scale: float = 1.0, **kwargs):\n        \"\"\"\n        Analysis functions/functionals for structural optimization\n            Every function is added to new structural analysis problems in each iteration if the design changes\n                with the TacsAim shape variables for instance.\n            Calls addFunction in each new staticProblem for now\n\n        Parameters\n        -----------------------------------------------------\n        name : str\n            the name of the function i.e. mass, ks_vmfailure, etc.\n        handle : TACS.function\n            the function handle of the cython TACS function, comes from tacs.functions module\n        compIDs : list\n            list of component IDs to select\n        scale : float\n            the scale used for optimization\n        **kwargs:\n            any keyword arguments to pass to the\n        \"\"\"\n\n        self.name = name\n        self.handle = handle\n        self.compIDs = compIDs\n        self.scale = scale\n        self.kwargs = kwargs\n\n        self.value = None\n        self._derivatives = []",
  "def register_to(self, tacs_aim):\n        # register the analysis function to the TacsAim wrapper class\n        tacs_aim.register(self)\n        return",
  "def set_derivative(self, var, value: float):\n        for deriv in self.derivatives:\n            if deriv.name == var.name:\n                deriv.value = value\n                return",
  "def get_derivative(self, var):\n        value = None\n        for deriv in self.derivatives:\n            if deriv.name == var.name:\n                value = deriv.value\n\n        return value",
  "def derivatives(self) -> List[Derivative]:\n        return self._derivatives",
  "def gradient_dict(self) -> dict:\n        return {deriv.name: deriv.value for deriv in self.derivatives}",
  "def mass(cls, compIDs=None, scale: float = 1.0):\n        return cls(name=\"mass\", handle=StructuralMass, compIDs=compIDs, scale=scale)",
  "def ksfailure(\n        cls,\n        compIDs=None,\n        safetyFactor: float = 1.0,\n        ksWeight: float = 50.0,\n        scale: float = 1.0,\n    ):\n        return cls(\n            name=\"ksfailure\",\n            handle=KSFailure,\n            compIDs=compIDs,\n            scale=scale,\n            safetyFactor=safetyFactor,\n            ksWeight=ksWeight,\n        )",
  "def ks_temperature(\n        cls,\n        compIDs=None,\n        alpha: float = 1.0,\n        ksWeight: float = 50.0,\n        scale: float = 1.0,\n    ):\n        return cls(\n            name=\"ks_temperature\",\n            handle=KSTemperature,\n            compIDs=compIDs,\n            scale=scale,\n            alpha=alpha,\n            ksWeight=ksWeight,\n        )",
  "def avg_temperature(cls, compIDs=None, volume: float = 1.0, scale: float = 1.0):\n        return cls(\n            name=\"avg_temperature\",\n            handle=AverageTemperature,\n            compIDs=compIDs,\n            scale=scale,\n            volume=volume,\n        )",
  "def compliance(cls, compIDs=None, scale: float = 1.0):\n        return cls(name=\"compliance\", handle=Compliance, compIDs=compIDs, scale=scale)"
]